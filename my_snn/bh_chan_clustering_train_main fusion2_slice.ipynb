{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ssp.train.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch   \n",
    "import torch.nn as nn \n",
    "import torch.nn.functional as F   \n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import torch.optim as optim\n",
    "from scipy import io\n",
    "import itertools\n",
    "import math\n",
    "import datetime\n",
    "import wandb\n",
    "import pickle\n",
    "import json\n",
    "import time\n",
    "import sys\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import accuracy_score\n",
    "from scipy.optimize import linear_sum_assignment\n",
    "from snntorch import spikegen\n",
    "\n",
    "\n",
    "# my module import\n",
    "from modules import *\n",
    "\n",
    "# modules 폴더에 새모듈.py 만들면\n",
    "# modules/__init__py 파일에 form .새모듈 import * 하셈\n",
    "# 그리고 새모듈.py에서 from modules.새모듈 import * 하셈"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cluster_train_system( \n",
    "    gpu = '4',\n",
    "    Conv_net = True,\n",
    "    SAE_net = True,\n",
    "\n",
    "    # hyperparameter\n",
    "    dataset_num = 16,\n",
    "    spike_length = 50,\n",
    "    num_cluster = 4,  # 클러스터 수 설정 # 논문엔 4개라는데 여기서는 3개로 했네\n",
    "    training_cycle = 2400, # 그 초기 몇개까지만 cluster update할지\n",
    "\n",
    "\n",
    "    batch_size = 32,\n",
    "    max_epoch = 7000,\n",
    "    learning_rate = 0.001,\n",
    "    normalize_on = False, # True or False #이거 안 씀 # 이거 별로 안 좋은 normalize같음 # 쓸 거면 다른 거 써라.\n",
    "    need_bias = False,\n",
    "    # first_layer_no_train = False\n",
    "    lif_add_at_first = False,\n",
    "    my_seed = 42,\n",
    "\n",
    "    TIME = 10, # SAE일 때만 유효\n",
    "    v_decay = 0.5,\n",
    "    v_threshold = 0.5,\n",
    "    v_reset = 10000.0, # 10000이상 일 시 hard reset\n",
    "    BPTT_on = True,\n",
    "\n",
    "    SAE_hidden_nomean = True,\n",
    "    current_time = '20250101_210938_786',\n",
    "\n",
    "    optimizer = 'Adam',\n",
    "    coarse_com_mode = True,\n",
    "    coarse_com_config = (2.0, -2.0), # (max, min)\n",
    "\n",
    "    sae_l2_norm_bridge = True,\n",
    "    sae_lif_bridge = False,\n",
    "\n",
    "    accuracy_check_epoch_term = 5,\n",
    "    \n",
    "    lif_add_at_last = False,\n",
    "\n",
    "    two_channel_input = False,\n",
    "\n",
    "    lateral_feature_num = 4,\n",
    "\n",
    "    lc_adc_on = False, \n",
    "\n",
    "    converted_net_forward = False,\n",
    "\n",
    "    pretrained_net = None, \n",
    "\n",
    "    vth_mul_on = False,\n",
    "    batch_norm_on = False,\n",
    "\n",
    "    l2_norm_loss_weight = 0.0,\n",
    "\n",
    "    QCFS_neuron_on = False,\n",
    "\n",
    "    quantize_level_num = 0,\n",
    "\n",
    "    fusion_net = False, # True False\n",
    "    repeat_coding = False,\n",
    "    \n",
    "    sae_relu_on = False,\n",
    "\n",
    "    conv1d_scaling = False,\n",
    "\n",
    "    norm01 = True,\n",
    "    ):\n",
    "    if coarse_com_mode == True:\n",
    "        assert coarse_com_config[0] > coarse_com_config[1], 'coarse_com_config[0] > coarse_com_config[1]이어야 함'\n",
    "        assert converted_net_forward == False\n",
    "        # assert SAE_net == True, 'coarse_com_mode는 SAE_net이 True일 때만 가능'\n",
    "    if two_channel_input == True:\n",
    "        assert Conv_net and coarse_com_mode, 'two_channel_input는 Conv_net이 True일 때만 가능'\n",
    "    if lc_adc_on == True:\n",
    "        assert coarse_com_mode and SAE_net, 'lc_adc_on은 coarse_com_mode와 SAE_net이 True일 때만 가능'\n",
    "    if converted_net_forward == True:\n",
    "        assert SAE_net == False, 'converted_net_forward는 SAE_net이 False일 때만 가능'\n",
    "    if conv1d_scaling:\n",
    "        assert Conv_net and coarse_com_mode and normalize_on\n",
    "    seed_assign(my_seed)\n",
    "    ## 함수 내 모든 로컬 변수 저장 ########################################################\n",
    "    hyperparameters = locals()\n",
    "    print(hyperparameters)\n",
    "    # JSON으로 저장\n",
    "    with open(f\"result_save/cluster_accuracy_history_{current_time}.json\", 'w') as f:\n",
    "        json.dump(hyperparameters, f, indent=4)\n",
    "    ######################################################################################\n",
    "\n",
    "    \n",
    "    wandb.config.update(hyperparameters)\n",
    "    wandb.run.name = f'{current_time}_SAE_net_{SAE_net}_v_threshold_{v_threshold}'\n",
    "    wandb.define_metric(\"best_mean_cluster_accuracy_post_training_cycle_all_dataset2\", summary=\"max\")\n",
    "\n",
    "\n",
    "    my_path_ground_BH = '/data2/spike_sorting/quiroga/BH/'\n",
    "\n",
    "\n",
    "    filename = [\"C_Easy1_noise005.mat\", \"C_Easy1_noise01.mat\", \"C_Easy1_noise015.mat\", \"C_Easy1_noise02.mat\",\n",
    "                \"C_Easy2_noise005.mat\", \"C_Easy2_noise01.mat\", \"C_Easy2_noise015.mat\", \"C_Easy2_noise02.mat\",\n",
    "                \"C_Difficult1_noise005.mat\", \"C_Difficult1_noise01.mat\", \"C_Difficult1_noise015.mat\", \"C_Difficult1_noise02.mat\",\n",
    "                \"C_Difficult2_noise005.mat\", \"C_Difficult2_noise01.mat\", \"C_Difficult2_noise015.mat\", \"C_Difficult2_noise02.mat\"]\n",
    "\n",
    "\n",
    "    spike_tot = [\"BH_Spike_e1n005.npy\", \"BH_Spike_e1n010.npy\", \"BH_Spike_e1n015.npy\", \"BH_Spike_e1n020.npy\",\n",
    "                \"BH_Spike_e2n005.npy\", \"BH_Spike_e2n010.npy\", \"BH_Spike_e2n015.npy\", \"BH_Spike_e2n020.npy\",\n",
    "                \"BH_Spike_d1n005.npy\", \"BH_Spike_d1n010.npy\", \"BH_Spike_d1n015.npy\", \"BH_Spike_d1n020.npy\",\n",
    "                \"BH_Spike_d2n005.npy\", \"BH_Spike_d2n010.npy\", \"BH_Spike_d2n015.npy\", \"BH_Spike_d2n020.npy\"]\n",
    "\n",
    "    label_tot = [\"BH_Label_e1n005.npy\", \"BH_Label_e1n010.npy\", \"BH_Label_e1n015.npy\", \"BH_Label_e1n020.npy\",\n",
    "                \"BH_Label_e2n005.npy\", \"BH_Label_e2n010.npy\", \"BH_Label_e2n015.npy\", \"BH_Label_e2n020.npy\",\n",
    "                \"BH_Label_d1n005.npy\", \"BH_Label_d1n010.npy\", \"BH_Label_d1n015.npy\", \"BH_Label_d1n020.npy\",\n",
    "                \"BH_Label_d2n005.npy\", \"BH_Label_d2n010.npy\", \"BH_Label_d2n015.npy\", \"BH_Label_d2n020.npy\"]\n",
    "\n",
    "    template =  [\"BH_Spike_TEMPLATE_e1n005.npy\", \"BH_Spike_TEMPLATE_e1n010.npy\", \"BH_Spike_TEMPLATE_e1n015.npy\", \"BH_Spike_TEMPLATE_e1n020.npy\",\n",
    "                \"BH_Spike_TEMPLATE_e2n005.npy\", \"BH_Spike_TEMPLATE_e2n010.npy\", \"BH_Spike_TEMPLATE_e2n015.npy\", \"BH_Spike_TEMPLATE_e2n020.npy\",\n",
    "                \"BH_Spike_TEMPLATE_d1n005.npy\", \"BH_Spike_TEMPLATE_d1n010.npy\", \"BH_Spike_TEMPLATE_d1n015.npy\", \"BH_Spike_TEMPLATE_d1n020.npy\",\n",
    "                \"BH_Spike_TEMPLATE_d2n005.npy\", \"BH_Spike_TEMPLATE_d2n010.npy\", \"BH_Spike_TEMPLATE_d2n015.npy\", \"BH_Spike_TEMPLATE_d2n020.npy\"]\n",
    "\n",
    "    AE_train_path_gt_detect = 'BH_quiroga_training_dataset_gt_detect.pt' \n",
    "    AE_test_path_gt_detect = 'BH_quiroga_test_dataset_gt_detect.pt'\n",
    "\n",
    "    AE_train_path_real_detect = 'BH_quiroga_training_dataset_real_detect.pt'\n",
    "    AE_test_path_real_detect = 'BH_quiroga_test_dataset_real_detect.pt'\n",
    "\n",
    "    AE_train_data = AE_train_path_real_detect #AE_train_path_gt_detect #AE_train_path_real_detect\n",
    "    AE_test_data = AE_test_path_real_detect #AE_test_path_gt_detect  #AE_test_path_real_detect\n",
    "\n",
    "    # thr_tot = np.array([0.5, 0.5, 0.55, 0.7, 0.5, 0.5, 0.55, 0.7, 0.5, 0.5, 0.55, 0.7, 0.5, 0.5, 0.55, 0.7])\n",
    "    cos_thr = np.array([0.95, 0.95, 0.95, 0.95, 0.95, 0.95, 0.95, 0.85, 0.95, 0.9, 0.8, 0.95, 0.95, 0.95, 0.95, 0.8])\n",
    "    # tem=10\n",
    "    # cos_thr = np.array([tem, tem, tem, tem, tem, tem, tem, tem, tem, tem, tem, tem, tem, tem, tem, tem, ])\n",
    "\n",
    "    print('cos_thr', cos_thr)\n",
    "    \n",
    "    os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\" \n",
    "    os.environ[\"CUDA_VISIBLE_DEVICES\"]= gpu\n",
    "\n",
    "\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "\n",
    "    if coarse_com_mode == True:\n",
    "        level_num = TIME\n",
    "        TIME = spike_length\n",
    "        spike_length = level_num\n",
    "        level_interval = (coarse_com_config[0] - coarse_com_config[1]) / (level_num-1)  # max - min\n",
    "        levels = [coarse_com_config[1] + level_interval * i for i in range(level_num)]\n",
    "        levels = torch.tensor(levels).to(torch.float).to(device)\n",
    "        levels = levels.repeat(TIME,1) \n",
    "        # print('levels', levels, levels.shape) # TIME, level_num\n",
    "\n",
    "    n_sample = spike_length\n",
    "\n",
    "    class spikedataset(Dataset):\n",
    "        def __init__(self, path, transform = None):    \n",
    "            self.transform = transform\n",
    "            self.spike = torch.load(path)\n",
    "            \n",
    "        def __getitem__(self, index):\n",
    "            spike = self.spike[index]            \n",
    "            if self.transform is not None:\n",
    "                spike = self.transform(spike)\n",
    "            return spike\n",
    "        \n",
    "        def __len__(self):\n",
    "            return len(self.spike)\n",
    "\n",
    "    train_dataset = spikedataset(my_path_ground_BH + AE_train_data)\n",
    "    train_loader = DataLoader(dataset = train_dataset, batch_size = batch_size, shuffle = True)\n",
    "\n",
    "    test_dataset = spikedataset(my_path_ground_BH + AE_test_data)\n",
    "    test_loader = DataLoader(dataset = test_dataset, batch_size = batch_size, shuffle = False)\n",
    "\n",
    "\n",
    "    # vth_mul_on = True # True False\n",
    "    # batch_norm_on = True # True False\n",
    "\n",
    "\n",
    "    # 모델 초기화\n",
    "    if SAE_net == False: # 여기서는 l2norm, lif bridge 둘 다 true면 l2norm먼저\n",
    "        assert two_channel_input == False\n",
    "\n",
    "        if Conv_net == True:\n",
    "            # input_channels = 2 if two_channel_input else 1\n",
    "            input_channels = TIME if coarse_com_mode else 1\n",
    "            if fusion_net == True:\n",
    "                assert False, '이거 맞음? 다시 확인'\n",
    "                net = FUSION_net_conv1(input_channels=input_channels, input_length=n_sample, encoder_ch = [32, 64, 96], fc_dim = lateral_feature_num, padding = 0, stride = 2, kernel_size = 3, \n",
    "                                    synapse_fc_trace_const1=1, \n",
    "                                    synapse_fc_trace_const2=v_decay, #안씀 \n",
    "                                    TIME=TIME, v_init=0.0, v_decay=v_decay, v_threshold=v_threshold, v_reset=v_reset, \n",
    "                                    sg_width=4.0, surrogate='sigmoid', BPTT_on=BPTT_on, need_bias=need_bias, lif_add_at_first=lif_add_at_first,\n",
    "                                    sae_l2_norm_bridge = sae_l2_norm_bridge, sae_lif_bridge = sae_lif_bridge, lif_add_at_last=lif_add_at_last, repeat_coding=repeat_coding).to(device)\n",
    "            else: \n",
    "                net = Autoencoder_conv1(input_channels=input_channels, input_length=n_sample, encoder_ch = [32, 64, 96], fc_dim = lateral_feature_num, padding = 0, stride = 2, kernel_size = 3, need_bias=need_bias, l2norm_bridge=sae_l2_norm_bridge, relu_bridge=sae_lif_bridge, activation_collector_on=False,\n",
    "                                        batch_norm_on=batch_norm_on, QCFS_neuron_on=QCFS_neuron_on).to(device)\n",
    "            net = torch.nn.DataParallel(net)\n",
    "            if converted_net_forward:\n",
    "                converted_net = SAE_converted_conv1(input_channels=input_channels, input_length=n_sample, encoder_ch = [32, 64, 96], fc_dim = lateral_feature_num, padding = 0, stride = 2, kernel_size = 3, \n",
    "                                    synapse_fc_trace_const1=1, \n",
    "                                    synapse_fc_trace_const2=v_decay, #안씀 \n",
    "                                    TIME=TIME, v_init=0.0, v_decay=v_decay, v_threshold=v_threshold, v_reset=v_reset, \n",
    "                                    sg_width=4.0, surrogate='sigmoid', BPTT_on=BPTT_on, need_bias=need_bias, lif_add_at_first=lif_add_at_first,\n",
    "                                    sae_l2_norm_bridge = sae_l2_norm_bridge, sae_lif_bridge = sae_lif_bridge, lif_add_at_last=lif_add_at_last,\n",
    "                                    vth_mul_on=vth_mul_on, batch_norm_on=batch_norm_on).to(device) # lif bridge는 무조건 들어가게 해놨음.\n",
    "                converted_net = torch.nn.DataParallel(converted_net)\n",
    "                print('converted_net', converted_net)\n",
    "        else:\n",
    "            n_sample = n_sample * TIME if coarse_com_mode else n_sample\n",
    "            net = Autoencoder_only_FC(encoder_ch=[400, lateral_feature_num], decoder_ch=[400,n_sample], n_sample=n_sample, need_bias=need_bias, l2norm_bridge=sae_l2_norm_bridge, relu_bridge=sae_lif_bridge, activation_collector_on=False,\n",
    "                                    batch_norm_on=batch_norm_on, QCFS_neuron_on=QCFS_neuron_on).to(device)\n",
    "            net = torch.nn.DataParallel(net)\n",
    "            if converted_net_forward:\n",
    "                converted_net = SAE_converted_fc(encoder_ch=[400, lateral_feature_num], \n",
    "                                    decoder_ch=[400, n_sample], \n",
    "                                    in_channels=n_sample, # in_channel 이 여기선 걍 lenght.\n",
    "                                    synapse_fc_trace_const1=1,\n",
    "                                    synapse_fc_trace_const2=v_decay,  #안씀 \n",
    "                                    TIME=TIME, v_init=0.0, v_decay=v_decay, v_threshold=v_threshold, v_reset=v_reset, \n",
    "                                    sg_width=4.0, surrogate='sigmoid', BPTT_on=BPTT_on, need_bias=need_bias, lif_add_at_first=lif_add_at_first,\n",
    "                                    sae_l2_norm_bridge = sae_l2_norm_bridge, sae_lif_bridge = sae_lif_bridge, lif_add_at_last=lif_add_at_last,\n",
    "                                    vth_mul_on=vth_mul_on, batch_norm_on=batch_norm_on).to(device) # lif bridge는 무조건 들어가게 해놨음.\n",
    "                converted_net = torch.nn.DataParallel(converted_net)\n",
    "                # print('converted_net', converted_net)\n",
    "    else:\n",
    "        if Conv_net == True: \n",
    "            input_channels = 1\n",
    "            input_channels = 2 if two_channel_input else 1\n",
    "            if fusion_net == True:  \n",
    "                assert coarse_com_mode == True\n",
    "                net = SAE_FUSION2_net_conv1(input_channels=input_channels, input_length=n_sample, encoder_ch = [32, 64, 96], fc_dim = lateral_feature_num, padding = 0, stride = 2, kernel_size = 3, \n",
    "                                    synapse_fc_trace_const1=1, \n",
    "                                    synapse_fc_trace_const2=v_decay, #안씀 \n",
    "                                    TIME=TIME, v_init=0.0, v_decay=v_decay, v_threshold=v_threshold, v_reset=v_reset, \n",
    "                                    sg_width=4.0, surrogate='sigmoid', BPTT_on=BPTT_on, need_bias=need_bias, lif_add_at_first=lif_add_at_first,\n",
    "                                    sae_l2_norm_bridge = sae_l2_norm_bridge, sae_lif_bridge = sae_lif_bridge, lif_add_at_last=lif_add_at_last, batch_norm_on=batch_norm_on, sae_relu_on=sae_relu_on).to(device)\n",
    "                # net = SAE_FUSION3_net_conv1(input_channels=input_channels, input_length=n_sample, encoder_ch = [32, 64, 96], fc_dim = lateral_feature_num, padding = 0, stride = 2, kernel_size = 3, \n",
    "                #                     synapse_fc_trace_const1=1, \n",
    "                #                     synapse_fc_trace_const2=v_decay, #안씀 \n",
    "                #                     TIME=TIME, v_init=0.0, v_decay=v_decay, v_threshold=v_threshold, v_reset=v_reset, \n",
    "                #                     sg_width=4.0, surrogate='sigmoid', BPTT_on=BPTT_on, need_bias=need_bias, lif_add_at_first=lif_add_at_first,\n",
    "                #                     sae_l2_norm_bridge = sae_l2_norm_bridge, sae_lif_bridge = sae_lif_bridge, lif_add_at_last=lif_add_at_last, batch_norm_on=batch_norm_on, sae_relu_on=sae_relu_on).to(device)\n",
    "                # net = SAE_FUSION4_net_conv1(input_channels=input_channels, input_length=n_sample, encoder_ch = [32, 64, 96], fc_dim = lateral_feature_num, padding = 0, stride = 2, kernel_size = 3, \n",
    "                #                     synapse_fc_trace_const1=1, \n",
    "                #                     synapse_fc_trace_const2=v_decay, #안씀 \n",
    "                #                     TIME=TIME, v_init=0.0, v_decay=v_decay, v_threshold=v_threshold, v_reset=v_reset, \n",
    "                #                     sg_width=4.0, surrogate='sigmoid', BPTT_on=BPTT_on, need_bias=need_bias, lif_add_at_first=lif_add_at_first,\n",
    "                #                     sae_l2_norm_bridge = sae_l2_norm_bridge, sae_lif_bridge = sae_lif_bridge, lif_add_at_last=lif_add_at_last, batch_norm_on=batch_norm_on, sae_relu_on=sae_relu_on).to(device)\n",
    "            else:\n",
    "                net = SAE_conv1(input_channels=input_channels, input_length=n_sample, encoder_ch = [32, 64, 96], fc_dim = lateral_feature_num, padding = 0, stride = 2, kernel_size = 3, \n",
    "                                    synapse_fc_trace_const1=1, \n",
    "                                    synapse_fc_trace_const2=v_decay, #안씀 \n",
    "                                    TIME=TIME, v_init=0.0, v_decay=v_decay, v_threshold=v_threshold, v_reset=v_reset, \n",
    "                                    sg_width=4.0, surrogate='sigmoid', BPTT_on=BPTT_on, need_bias=need_bias, lif_add_at_first=lif_add_at_first,\n",
    "                                    sae_l2_norm_bridge = sae_l2_norm_bridge, sae_lif_bridge = sae_lif_bridge, lif_add_at_last=lif_add_at_last, batch_norm_on=batch_norm_on, sae_relu_on=sae_relu_on).to(device)\n",
    "            # net = SAE_conv1_DR(input_channels=input_channels, input_length=n_sample, encoder_ch = [32, 64, 96], fc_dim = lateral_feature_num, padding = 0, stride = 2, kernel_size = 3, \n",
    "            #                     synapse_fc_trace_const1=1, \n",
    "            #                     synapse_fc_trace_const2=v_decay, #안씀 \n",
    "            #                     TIME=TIME, v_init=0.0, v_decay=v_decay, v_threshold=v_threshold, v_reset=v_reset, \n",
    "            #                     sg_width=4.0, surrogate='sigmoid', BPTT_on=BPTT_on, need_bias=need_bias, lif_add_at_first=lif_add_at_first,\n",
    "            #                     sae_l2_norm_bridge = sae_l2_norm_bridge, sae_lif_bridge = sae_lif_bridge, lif_add_at_last=lif_add_at_last, batch_norm_on=batch_norm_on).to(device)\n",
    "            net = torch.nn.DataParallel(net)\n",
    "        else:\n",
    "            net = SAE_fc_only(encoder_ch=[400, lateral_feature_num], \n",
    "                                decoder_ch=[400, n_sample], \n",
    "                                in_channels=n_sample, # in_channel 이 여기선 걍 lenght.\n",
    "                                synapse_fc_trace_const1=1,\n",
    "                                synapse_fc_trace_const2=v_decay,  #안씀 \n",
    "                                TIME=TIME, v_init=0.0, v_decay=v_decay, v_threshold=v_threshold, v_reset=v_reset, \n",
    "                                sg_width=4.0, surrogate='sigmoid', BPTT_on=BPTT_on, need_bias=need_bias, lif_add_at_first=lif_add_at_first,\n",
    "                                sae_l2_norm_bridge = sae_l2_norm_bridge, sae_lif_bridge = sae_lif_bridge, lif_add_at_last=lif_add_at_last, batch_norm_on=batch_norm_on, sae_relu_on=sae_relu_on).to(device)\n",
    "            net = torch.nn.DataParallel(net)\n",
    "\n",
    "    # net = torch.load('/home/bhkim003/github_folder/ByeonghyeonKim/my_snn/net_save/save_now_net_AE_re_e7000.pth')\n",
    "    # net = torch.load('/home/bhkim003/github_folder/ByeonghyeonKim/my_snn/net_save/save_now_net_20250101_210938_786.pth')\n",
    "    # load했으면 torch.nn.DataParallel 하지마\n",
    "    # net.module.load_state_dict(torch.load('/home/bhkim003/github_folder/ByeonghyeonKim/my_snn/net_save/save_now_net_annbase_20250108_210641_941.pth'))\n",
    "    if pretrained_net != None:\n",
    "        ######################## 모델이 달라서 dict로 weight만 넣고싶을 때\n",
    "        # # 저장된 가중치 로드\n",
    "        saved_state_dict = torch.load(pretrained_net)\n",
    "        current_state_dict = net.module.state_dict()\n",
    "\n",
    "        # 함수 호출로 가중치 매핑\n",
    "        updated_state_dict = map_and_load_weights(saved_state_dict, current_state_dict)\n",
    "\n",
    "        # 업데이트된 state_dict를 네트워크에 로드\n",
    "        net.module.load_state_dict(updated_state_dict)\n",
    "        ######################## 모델이 달라서 dict로 weight만 넣고싶을 때\n",
    "\n",
    "        ############## 일반적일 때\n",
    "        # net.module.load_state_dict(torch.load(pretrained_net))\n",
    "        ############## 일반적일 때\n",
    "    \n",
    "        # pre_net = Autoencoder_conv1(input_channels=input_channels, input_length=n_sample, encoder_ch = [32, 64, 96], fc_dim = lateral_feature_num, padding = 0, stride = 2, kernel_size = 3, need_bias=need_bias, l2norm_bridge=sae_l2_norm_bridge, relu_bridge=sae_lif_bridge, activation_collector_on=False,\n",
    "        #                         batch_norm_on=batch_norm_on, QCFS_neuron_on=False).to(device)\n",
    "        # pre_net = torch.nn.DataParallel(net)\n",
    "        # pre_net.module.load_state_dict(torch.load(pretrained_net))\n",
    "        # copy_weights(pre_net.module.encoder , net.module.encoder )\n",
    "        # copy_weights(pre_net.module.decoder , net.module.decoder  )\n",
    "\n",
    "        \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    wandb.watch(net, log=\"all\", log_freq = 10)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    if SAE_net == True:\n",
    "        assert 'SAE' in net.module.__class__.__name__\n",
    "\n",
    "\n",
    "\n",
    "    net = net.to(device)\n",
    "    print(f\"Total number of encoder parameters: {sum(p.numel() for p in net.module.encoder.parameters())}\")\n",
    "    print(net)\n",
    "    print('Device:',device)\n",
    "\n",
    "    \n",
    "    if optimizer == 'Adam':\n",
    "        optimizer = optim.Adam(net.parameters(), lr=learning_rate)\n",
    "    elif optimizer == 'SGD':\n",
    "        optimizer = optim.SGD(net.parameters(), lr = learning_rate, momentum = 0.9)\n",
    "    else:\n",
    "        assert False, 'optimizer를 잘못 입력했습니다.'\n",
    "        \n",
    "    loss_history = []\n",
    "    mean_cluster_accuracy_during_training_cycle_all_dataset_history = []\n",
    "    mean_cluster_accuracy_post_training_cycle_all_dataset_history = []\n",
    "    mean_cluster_accuracy_total_all_dataset_history = []\n",
    "\n",
    "    tau = np.zeros(num_cluster)\n",
    "\n",
    "    print(f\"\\nStart Training, current_time = {current_time}\")\n",
    "    mean_cluster_accuracy_post_training_cycle_all_dataset = 0\n",
    "    best_mean_cluster_accuracy_post_training_cycle_all_dataset = 0\n",
    "\n",
    "    if SAE_net == True:\n",
    "        assert 'SAE' in net.module.__class__.__name__\n",
    "        \n",
    "    k_means_acc_best = 0\n",
    "    min_loss = 9999999\n",
    "    min_loss_normal = 9999999\n",
    "    min_loss_coarse = 9999999\n",
    "    for epoch in range(max_epoch):\n",
    "        print()\n",
    "        l2_loss_bin= 0\n",
    "        ae_train_start_time = time.time()\n",
    "        running_loss = 0.0\n",
    "        running_loss_normal = 0.0\n",
    "        running_loss_coarse = 0.0\n",
    "        iter = 0\n",
    "        net.train()\n",
    "        # if True or max_epoch != 1:\n",
    "        wrong_element_sum = 0\n",
    "        same_data_num = 0\n",
    "        total_data_num = 0\n",
    "        if max_epoch != 1:\n",
    "            for data in train_loader:\n",
    "                optimizer.zero_grad()\n",
    "                total_data_num += len(data)\n",
    "                data = data.to(device)\n",
    "                scaling = (level_num-3)/level_num if conv1d_scaling else 1.0\n",
    "                data = zero_to_one_normalize_features(data, level_num=quantize_level_num, coarse_com_config=coarse_com_config, scaling=scaling, norm01=norm01) if normalize_on else data\n",
    "                # plot_origin_spike(data[0].cpu().detach().numpy(), min_max_y_on = True)\n",
    "                # plot_origin_spike(data[1].cpu().detach().numpy(), min_max_y_on = True)\n",
    "                spike_backup = data\n",
    "                spike = data\n",
    "                spike = spike.to(device) # batch, feature\n",
    "                spike_for_fusion2_net = spike\n",
    "                if coarse_com_mode == True and 'SAE' in net.module.__class__.__name__:\n",
    "                    # print(spike[0])\n",
    "                    spike = spike.unsqueeze(2).repeat(1, 1, level_num) # spike_length == level_num # (batch, time, feature)로 변환 \n",
    "                    spike = (spike > levels).to(torch.float) \n",
    "\n",
    "                    spike = (spike == 0).cumsum(dim=-1).eq(1).to(torch.float) if lc_adc_on == True else spike\n",
    "\n",
    "                    # spike: batch, time, level_num\n",
    "                    # levels: time, level_num\n",
    "                    if Conv_net == True:\n",
    "                        spike = spike.unsqueeze(-2) # batch, time, in_channel, feature or batch in_channel,feature\n",
    "                        if two_channel_input == True:\n",
    "                            spike_backup = spike_backup.to(device)\n",
    "                            spike_backup = spike_backup.unsqueeze(2).repeat(1, 1, level_num) # spike_length == level_num # (batch, time, feature)로 변환 \n",
    "                            spike_backup = (spike_backup <= levels).to(torch.float) \n",
    "                            spike_backup = (spike_backup == 1).cumsum(dim=-1).eq(1).to(torch.float) if lc_adc_on == True else spike_backup\n",
    "                            spike_backup = spike_backup.unsqueeze(-2)\n",
    "                            spike = torch.cat((spike, spike_backup), dim=-2)\n",
    "                    assert spike.shape[0] == batch_size and spike.shape[1] == TIME\n",
    "                elif 'SAE' in net.module.__class__.__name__:\n",
    "                    spike = spike.unsqueeze(-1).repeat(1, 1, TIME).permute(0,2,1) # (batch, time, feature)로 변환\n",
    "                    if Conv_net == True:\n",
    "                        spike = spike.unsqueeze(-2) # batch, time, in_channel, feature or batch in_channel,feature\n",
    "                else:\n",
    "                    if Conv_net == True:\n",
    "                        if coarse_com_mode == False:\n",
    "                            spike = spike.unsqueeze(-2) #batch in_channel,feature\n",
    "                        else:\n",
    "                            spike = spike.unsqueeze(2).repeat(1, 1, level_num) # spike_length == level_num # (batch, time, feature)로 변환 \n",
    "                            spike = (spike > levels).to(torch.float) \n",
    "\n",
    "                            spike = (spike == 0).cumsum(dim=-1).eq(1).to(torch.float) if lc_adc_on == True else spike\n",
    "\n",
    "                    else:\n",
    "                        if coarse_com_mode == False:\n",
    "                            pass\n",
    "                        else:\n",
    "                            spike = spike.unsqueeze(2).repeat(1, 1, level_num) # spike_length == level_num # (batch, time, feature)로 변환 \n",
    "                            spike = (spike > levels).to(torch.float) \n",
    "\n",
    "                            spike = (spike == 0).cumsum(dim=-1).eq(1).to(torch.float) if lc_adc_on == True else spike\n",
    "\n",
    "                            # spike: batch, time, feature\n",
    "                            spike = spike.reshape(spike.shape[0], -1)\n",
    "\n",
    "                    \n",
    "\n",
    "\n",
    "                    # if fusion_net == True:\n",
    "                    #     spike = spikegen.rate(spike, num_steps=TIME).transpose(0, 1)\n",
    "\n",
    "                # spike_class = net(spike) # batch, time, feature\n",
    "                encoded_spike = net.module.encoder(spike)\n",
    "                spike_class = net.module.decoder(encoded_spike)\n",
    "\n",
    "                # for i in range (2):\n",
    "                #     plot_spike(spike[i,:,0,:].cpu().numpy())\n",
    "                #     # plot_spike(spike[i,:,1,:].cpu().numpy())\n",
    "                #     plot_origin_spike(spike_class.squeeze()[i].cpu().detach().numpy(), min_max_y_on = True)\n",
    "                # assert False\n",
    "                        \n",
    "\n",
    "                loss = 0\n",
    "                loss_normal = torch.tensor(0.0)\n",
    "                loss_coarse = torch.tensor(0.0)\n",
    "                if coarse_com_mode == True and 'SAE' in net.module.__class__.__name__:\n",
    "                    criterion = nn.MSELoss().to(device)\n",
    "                    # loss1 = nn.MSELoss()(spike_class[..., 5:25], spike[..., 5:25])\n",
    "                    # loss2 = nn.MSELoss()(spike_class[..., 0:5], spike[..., 0:5])\n",
    "                    # loss3 = nn.MSELoss()(spike_class[..., 25:spike_length], spike[..., 25:spike_length])\n",
    "                    # loss = loss1 * 2.125 + (loss2 + loss3)/4\n",
    "\n",
    "                    # loss1 = nn.MSELoss()(spike_class[..., 5:25, :], spike[..., 5:25, :])\n",
    "                    # loss2 = nn.MSELoss()(spike_class[..., 0:5, :], spike[..., 0:5, :])\n",
    "                    # loss3 = nn.MSELoss()(spike_class[..., 25:spike_length, :], spike[..., 25:spike_length, :])\n",
    "                    # loss = loss1 * 2.125 + (loss2 + loss3)/4\n",
    "                    if fusion_net:\n",
    "                        # print('1', spike.shape) # batch, time, in_channel, feature [32, 50, 1, 50]\n",
    "                        \n",
    "                        # ### coarse에서 ann loss 만들기 ######\n",
    "                        # spike = spike.squeeze()\n",
    "                        # assert two_channel_input == False\n",
    "                        # zero_mask = (spike == 0)  # 0이 있는 위치\n",
    "                        # first_zero_idx = torch.where(zero_mask, torch.arange(spike.shape[-1]).to(device), spike.shape[-1]-1).min(dim=-1).values\n",
    "                        # spike = levels[0][first_zero_idx]\n",
    "                        # # plot_origin_spike(spike[0].cpu().detach().numpy())\n",
    "                        # ### coarse에서 ann loss 만들기 ######\n",
    "\n",
    "                        ### 그냥 원래 스파이크로 ann loss 만들기 ######\n",
    "                        spike = spike_for_fusion2_net\n",
    "                        ### 그냥 원래 스파이크로 ann loss 만들기 ######\n",
    "\n",
    "                        spike = spike.squeeze()\n",
    "                        spike_class = spike_class.squeeze()\n",
    "                        # loss = criterion(spike_class, spike)\n",
    "                        loss1 = criterion(spike_class[..., 5:25], spike[..., 5:25])\n",
    "                        loss2 = criterion(spike_class[..., 0:5], spike[..., 0:5])\n",
    "                        loss3 = criterion(spike_class[..., 25:], spike[..., 25:])\n",
    "                        loss = loss1 * 2.125 + (loss2 + loss3)/4\n",
    "\n",
    "                        # #########################################\n",
    "                        # # 손실 함수 정의 (예: MSELoss 사용)\n",
    "                        # criterion_joke = torch.nn.MSELoss(reduction='none')  # 개별 요소별 손실을 유지\n",
    "\n",
    "                        # # 손실 계산\n",
    "                        # loss1_joke = criterion_joke(spike_class[..., 5:25], spike[..., 5:25]).mean(dim=-1)  # (batch,)\n",
    "                        # loss2_joke = criterion_joke(spike_class[..., 0:5], spike[..., 0:5]).mean(dim=-1)    # (batch,)\n",
    "                        # loss3_joke = criterion_joke(spike_class[..., 25:], spike[..., 25:]).mean(dim=-1)    # (batch,)\n",
    "\n",
    "                        # # 주어진 가중치를 적용한 최종 손실\n",
    "                        # loss_joke = loss1_joke * 2.125 + (loss2_joke + loss3_joke) / 4  # (batch,)\n",
    "\n",
    "                        # # 가장 큰 손실을 갖는 샘플의 인덱스 찾기\n",
    "                        # max_loss_idx_joke = torch.argmax(loss_joke)\n",
    "\n",
    "                        # # 해당 샘플 선택\n",
    "                        # selected_sample_class = spike_class[max_loss_idx_joke]\n",
    "                        # selected_sample_spike = spike[max_loss_idx_joke]\n",
    "\n",
    "                        # # 선택한 샘플의 손실 값 출력\n",
    "                        # print(\"Index of max loss sample:\", max_loss_idx_joke.item())\n",
    "                        # print(\"Max loss value:\", loss_joke[max_loss_idx_joke].item())\n",
    "                        # mean_loss_joke = loss_joke.mean().item()\n",
    "                        # print(\"Mean loss across the batch:\", mean_loss_joke)\n",
    "\n",
    "                        # # 선택한 샘플을 시각화\n",
    "                        # plot_origin_spike(selected_sample_class.cpu().detach().numpy())\n",
    "                        # plot_origin_spike(selected_sample_spike.cpu().detach().numpy())\n",
    "                        # #########################################\n",
    "\n",
    "                        # coarse loss ######################################################\n",
    "                        loss_normal = criterion(spike_class, spike)\n",
    "                        level_num_in_loss = spike_length\n",
    "                        level_interval = (coarse_com_config[0] - coarse_com_config[1]) / (level_num_in_loss-1)  # max - min\n",
    "                        levels = [coarse_com_config[1] + level_interval * i for i in range(level_num_in_loss)]\n",
    "                        levels = torch.tensor(levels).to(torch.float).to(device)\n",
    "                        # print('coarse leves', levels)\n",
    "                        levels = levels.repeat(spike_length,1) \n",
    "\n",
    "                        spike = spike.squeeze()\n",
    "                        spike_class = spike_class.squeeze()\n",
    "                        # plot_origin_spike(spike_class[0].cpu().detach().numpy())\n",
    "                        spike = spike.unsqueeze(2).repeat(1, 1, level_num_in_loss) \n",
    "                        spike = (spike > levels).to(torch.float) \n",
    "                        spike_class = spike_class.unsqueeze(2).repeat(1, 1, level_num_in_loss) \n",
    "                        spike_class = (spike_class > levels).to(torch.float) \n",
    "                        # spike = spike[..., 0:-3, :]\n",
    "                        # spike_class = spike_class[..., 0:-3, :]\n",
    "                        loss_coarse = criterion(spike_class, spike)\n",
    "                        wrong_element_sum += torch.sum(torch.abs(spike - spike_class)).item() \n",
    "\n",
    "                        # plot_spike(spike_class[0].cpu().detach().numpy())\n",
    "                        # assert False\n",
    "                        # coarse loss ######################################################\n",
    "                    else:\n",
    "                        spike = spike.squeeze()\n",
    "                        spike_class = spike_class.squeeze()\n",
    "                        loss = criterion(spike_class, spike)\n",
    "\n",
    "                    for iii in range(spike.shape[0]):\n",
    "                        same_data_num = same_data_num + 1 if torch.eq(spike[iii], spike_class[iii]).all() else same_data_num\n",
    "                    wrong_element_sum += torch.sum(torch.abs(spike - spike_class)).item() \n",
    "\n",
    "                    # spike = spike.squeeze()\n",
    "                    # spike_class = spike_class.squeeze()\n",
    "                    # plot_spike(spike[0].cpu().detach().numpy())\n",
    "                    # plot_spike(spike_class[0].cpu().detach().numpy())\n",
    "                    # print('손실 절대값 합',np.sum(np.abs(spike[0].cpu().detach().numpy() - spike_class[0].cpu().detach().numpy())))\n",
    "                    # # assert False\n",
    "                elif 'SAE' in net.module.__class__.__name__:\n",
    "                    criterion = nn.MSELoss().to(device)\n",
    "                    loss1 = criterion(spike_class[..., 5:25], spike[..., 5:25])\n",
    "                    loss2 = criterion(spike_class[..., 0:5], spike[..., 0:5])\n",
    "                    loss3 = criterion(spike_class[..., 25:spike_length], spike[..., 25:spike_length])\n",
    "                    loss = loss1 * 2.125 + (loss2 + loss3)/4\n",
    "                    assert spike_length > 25, 'spike_length가 25보다 작음'\n",
    "                    # wrong_element_sum += torch.sum(torch.abs(spike - spike_class)).item() \n",
    "                else:\n",
    "                    criterion = nn.MSELoss().to(device)\n",
    "                    loss1 = criterion(spike_class[..., 5:25], spike[..., 5:25])\n",
    "                    loss2 = criterion(spike_class[..., 0:5], spike[..., 0:5])\n",
    "                    loss3 = criterion(spike_class[..., 25:spike_length], spike[..., 25:spike_length])\n",
    "                    loss = loss1 * 2.125 + (loss2 + loss3)/4\n",
    "                    assert spike_length > 25, 'spike_length가 25보다 작음'\n",
    "                    # wrong_element_sum += torch.sum(torch.abs(spike - spike_class)).item() \n",
    "\n",
    "\n",
    "                    if l2_norm_loss_weight > 0:\n",
    "                        assert len(encoded_spike.shape) == 2, 'time 성분 없는 걸로'\n",
    "                        l2_loss = l2_norm_loss(encoded_spike, target_norm=1.0)  # L2Norm Loss 계산, l2 1.0되게.\n",
    "                        loss = loss + l2_loss*l2_norm_loss_weight\n",
    "                        l2_loss_bin += l2_loss.item()\n",
    "\n",
    "                    # coarse loss ######################################################\n",
    "                    loss_normal = criterion(spike_class, spike)\n",
    "                    level_num_in_loss = quantize_level_num\n",
    "                    level_interval = (coarse_com_config[0] - coarse_com_config[1]) / (level_num_in_loss-1)  # max - min\n",
    "                    levels = [coarse_com_config[1] + level_interval * i for i in range(level_num_in_loss)]\n",
    "                    levels = torch.tensor(levels).to(torch.float).to(device)\n",
    "                    levels = levels.repeat(spike_length,1) \n",
    "\n",
    "                    spike = spike.squeeze()\n",
    "                    spike_class = spike_class.squeeze()\n",
    "                    # plot_origin_spike(spike_class[0].cpu().detach().numpy())\n",
    "                    spike = spike.unsqueeze(2).repeat(1, 1, level_num_in_loss) \n",
    "                    spike = (spike > levels).to(torch.float) \n",
    "                    spike_class = spike_class.unsqueeze(2).repeat(1, 1, level_num_in_loss) \n",
    "                    spike_class = (spike_class > levels).to(torch.float) \n",
    "                    # spike = spike[..., 0:-3, :]\n",
    "                    # spike_class = spike_class[..., 0:-3, :]\n",
    "                    loss_coarse = criterion(spike_class, spike)\n",
    "                    wrong_element_sum += torch.sum(torch.abs(spike - spike_class)).item() \n",
    "\n",
    "                    # plot_spike(spike_class[0].cpu().detach().numpy())\n",
    "                    # assert False\n",
    "                    # coarse loss ######################################################\n",
    "\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                running_loss += loss.item()\n",
    "                running_loss_normal += loss_normal.item()\n",
    "                running_loss_coarse += loss_coarse.item()\n",
    "                # print(f'\\nepoch-{epoch}, running_loss : {running_loss:.5f}, iter percent {iter/len(train_loader)*100:.2f}%')\n",
    "                iter += 1\n",
    "        else:\n",
    "            print('\\n\\n\\n max_epoch 1이면 Train 안함!!!!!!!!!!!!!!!!!!!!!')\n",
    "        if l2_norm_loss_weight > 0:\n",
    "            print('l2_loss_bin', l2_loss_bin/len(train_loader))\n",
    "        avg_loss = running_loss / len(train_loader)\n",
    "        assert not np.isnan(avg_loss), f\"Error: avg_loss is NaN! Running loss: {running_loss}, Length of train_loader: {len(train_loader)}\"\n",
    "        loss_history.append((epoch, avg_loss))\n",
    "        min_loss = min(min_loss, avg_loss)\n",
    "        min_loss_normal = min(min_loss_normal, running_loss_normal/len(train_loader))\n",
    "        min_loss_coarse = min(min_loss_coarse, running_loss_coarse/len(train_loader))\n",
    "        print(f'\\nepoch-{epoch} loss : {avg_loss:.8f}, loss_normal : {running_loss_normal/len(train_loader):.8f}, loss_coarse : {running_loss_coarse/len(train_loader):.8f}, min_loss : {min_loss:.8f}, min_loss_normal : {min_loss_normal:.8f}, min_loss_coarse : {min_loss_coarse:.8f}, wrong_element_sum : {wrong_element_sum:.8f}, same_data : {100*same_data_num/(total_data_num+1e-12):.2f}%')\n",
    "        print(f\"ae train 실행 시간: {time.time()-ae_train_start_time:.3f}초, 전체 시작 시간 {current_time}\")\n",
    "\n",
    "        # plot_activation_distribution(net)\n",
    "\n",
    "        if SAE_net == False and converted_net_forward == True:\n",
    "            source_encoder = net.module.encoder \n",
    "            target_encoder = converted_net.module.encoder  \n",
    "            copy_weights(source_encoder, target_encoder)\n",
    "\n",
    "        cluster_accuracy_during_training_cycle_all_dataset = np.zeros(dataset_num)\n",
    "        cluster_accuracy_post_training_cycle_all_dataset = np.zeros(dataset_num)\n",
    "        cluster_accuracy_total_all_dataset = np.zeros(dataset_num)    \n",
    "\n",
    "        k_means_acc = 0\n",
    "        converted_k_means_acc = 0\n",
    "        if(epoch % accuracy_check_epoch_term == 0 or epoch == 1 or epoch == max_epoch-1): \n",
    "            accuracy_check_start_time = time.time()\n",
    "            print(f'\\nepoch-{epoch} accuracy check')\n",
    "            k_means_bin_origin_feature = []\n",
    "            k_means_bin = []\n",
    "            converted_k_means_bin = []\n",
    "            for ds in range(dataset_num):\n",
    "                # print('\\n', spike_tot[ds])\n",
    "\n",
    "                spike_template = np.load(my_path_ground_BH + template[ds])\n",
    "                spike = np.load(my_path_ground_BH + spike_tot[ds])\n",
    "                label = np.load(my_path_ground_BH + label_tot[ds])\n",
    "                spike_template = torch.from_numpy(spike_template).to(device)\n",
    "                spike = torch.from_numpy(spike).to(device)\n",
    "                scaling = (level_num-3)/level_num if conv1d_scaling else 1.0\n",
    "                spike_template = zero_to_one_normalize_features(spike_template, level_num=quantize_level_num, coarse_com_config=coarse_com_config, scaling=scaling, norm01=norm01) if normalize_on else spike_template\n",
    "                spike = zero_to_one_normalize_features(spike, level_num=quantize_level_num, coarse_com_config=coarse_com_config, scaling=scaling, norm01=norm01) if normalize_on else spike\n",
    "                \n",
    "                hidden_size = lateral_feature_num*TIME if 'SAE' in net.module.__class__.__name__ and SAE_hidden_nomean == True and fusion_net == False else lateral_feature_num\n",
    "                hidden_size = lateral_feature_num if '_DR' in net.module.__class__.__name__  else hidden_size\n",
    "\n",
    "                Cluster = np.zeros((num_cluster, hidden_size))\n",
    "                assert Cluster.shape[-1] == hidden_size, '이거 hidden dim 4 아니게 할 거면 잘 바꿔라'\n",
    "                \n",
    "\n",
    "\n",
    "                net.eval()\n",
    "                with torch.no_grad():\n",
    "                    spike_torch = spike_template.float()\n",
    "                    spike_torch = spike_torch[:num_cluster]\n",
    "                    spike_backup = spike_torch\n",
    "                    spike_torch = spike_torch.to(device)\n",
    "                    if coarse_com_mode == True and 'SAE' in net.module.__class__.__name__:\n",
    "                        spike_torch = spike_torch.unsqueeze(2).repeat(1, 1, level_num) # spike_length == level_num # (batch, time, feature)로 변환 \n",
    "                        spike_torch = (spike_torch > levels).to(torch.float) \n",
    "                        spike_torch = (spike_torch == 0).cumsum(dim=-1).eq(1).to(torch.float) if lc_adc_on == True else spike_torch\n",
    "                        if Conv_net == True:\n",
    "                            spike_torch = spike_torch.unsqueeze(-2) # batch, time, in_channel, feature or batch in_channel,feature\n",
    "                            if two_channel_input == True:\n",
    "                                spike_backup = spike_backup.to(device)\n",
    "                                spike_backup = spike_backup.unsqueeze(2).repeat(1, 1, level_num) # spike_length == level_num # (batch, time, feature)로 변환 \n",
    "                                spike_backup = (spike_backup <= levels).to(torch.float) \n",
    "                                spike_backup = (spike_backup == 1).cumsum(dim=-1).eq(1).to(torch.float) if lc_adc_on == True else spike_backup\n",
    "                                spike_backup = spike_backup.unsqueeze(-2) # batch, time, in_channel, feature\n",
    "                                spike_torch = torch.cat((spike_torch, spike_backup), dim=-2)\n",
    "                    elif 'SAE' in net.module.__class__.__name__:\n",
    "                        spike_torch = spike_torch.unsqueeze(1).repeat(1, TIME, 1) # (batch, time, feature)로 변환\n",
    "                        if Conv_net == True:\n",
    "                            spike_torch = spike_torch.unsqueeze(-2) # batch, time, in_channel, feature or batch in_channel,feature\n",
    "                    else:\n",
    "                        # if Conv_net == True:\n",
    "                        #     spike_torch = spike_torch.unsqueeze(-2) #batch in_channel,feature\n",
    "                        if Conv_net == True:\n",
    "                            if coarse_com_mode == False:\n",
    "                                spike_torch = spike_torch.unsqueeze(-2) #batch in_channel,feature\n",
    "                            else:\n",
    "                                spike_torch = spike_torch.unsqueeze(2).repeat(1, 1, level_num) # spike_length == level_num # (batch, time, feature)로 변환 \n",
    "                                spike_torch = (spike_torch > levels).to(torch.float) \n",
    "\n",
    "                                spike_torch = (spike_torch == 0).cumsum(dim=-1).eq(1).to(torch.float) if lc_adc_on == True else spike_torch\n",
    "\n",
    "                        else:\n",
    "                            if coarse_com_mode == False:\n",
    "                                pass\n",
    "                            else:\n",
    "                                spike_torch = spike_torch.unsqueeze(2).repeat(1, 1, level_num) # spike_length == level_num # (batch, time, feature)로 변환 \n",
    "                                spike_torch = (spike_torch > levels).to(torch.float) \n",
    "\n",
    "                                spike_torch = (spike_torch == 0).cumsum(dim=-1).eq(1).to(torch.float) if lc_adc_on == True else spike_torch\n",
    "\n",
    "                                # spike: batch, time, feature\n",
    "                                spike_torch = spike_torch.reshape(spike_torch.shape[0], -1)\n",
    "\n",
    "                        if converted_net_forward == True:\n",
    "                            spike_torch_spikegen = spikegen.rate(spike_torch, num_steps=TIME).transpose(0, 1)\n",
    "                        # if fusion_net == True:\n",
    "                        #     spike_torch = spikegen.rate(spike_torch, num_steps=TIME).transpose(0, 1)\n",
    "                    ### forward #######################################################\n",
    "                    inner_inf = net.module.encoder(spike_torch)\n",
    "                    if SAE_net == False and converted_net_forward == True:\n",
    "                        converted_inner_inf = converted_net.module.encoder(spike_torch_spikegen)\n",
    "                    ### forward #######################################################\n",
    "\n",
    "                    # for i in range(3):\n",
    "                    #     plot_spike(spike_torch[i,:,:].cpu().numpy())\n",
    "                    #     plot_spike(inner_inf[i,:].cpu().numpy())\n",
    "                    #     plot_spike(net.module.decoder(inner_inf)[i,:,:].cpu().numpy())\n",
    "                        \n",
    "                    # if 'SAE' in net.module.__class__.__name__:\n",
    "                    #     tensors = [inner_inf[0][i] for i in range(TIME)] \n",
    "                    #     all_equal = all(torch.equal(tensors[0], t) for t in tensors)\n",
    "                    #     print(all_equal, inner_inf)\n",
    "\n",
    "                    if 'SAE' in net.module.__class__.__name__:\n",
    "                        if SAE_hidden_nomean == True:\n",
    "                            inner_inf = inner_inf.reshape(inner_inf.shape[0],-1)# time*feature 펼치기\n",
    "                        else:\n",
    "                            inner_inf = inner_inf.mean(dim=1)# Time 방향으로 평균\n",
    "                        # inner_inf = F.normalize(inner_inf, p=2, dim=1)\n",
    "                    Cluster = inner_inf.cpu().detach().numpy()\n",
    "\n",
    "                encoder_batch = 128\n",
    "                spike_hidden = np.zeros((len(spike), hidden_size))\n",
    "                converted_spike_hidden = np.zeros((len(spike), hidden_size))\n",
    "                net.eval()\n",
    "                with torch.no_grad():\n",
    "                    now_index = 0\n",
    "                    while (1):\n",
    "                        now_end_index = now_index+encoder_batch if now_index+encoder_batch < len(spike) else len(spike)\n",
    "                        spike_batch = spike[now_index:now_end_index] \n",
    "                        spike_torch = spike_batch\n",
    "                        spike_torch = spike_torch.float()\n",
    "                        spike_backup = spike_torch\n",
    "                        spike_torch = spike_torch.to(device)\n",
    "                        if coarse_com_mode == True and 'SAE' in net.module.__class__.__name__:\n",
    "                            spike_torch = spike_torch.unsqueeze(2).repeat(1, 1, level_num) # spike_length == level_num # (batch, time, feature)로 변환 \n",
    "                            spike_torch = (spike_torch > levels).to(torch.float) \n",
    "                            spike_torch = (spike_torch == 0).cumsum(dim=-1).eq(1).to(torch.float) if lc_adc_on == True else spike_torch\n",
    "                            if Conv_net == True:\n",
    "                                spike_torch = spike_torch.unsqueeze(-2) # batch, time, in_channel, feature or batch in_channel,feature\n",
    "                                if two_channel_input == True:\n",
    "                                    spike_backup = spike_backup.to(device)\n",
    "                                    spike_backup = spike_backup.unsqueeze(2).repeat(1, 1, level_num) # spike_length == level_num # (batch, time, feature)로 변환 \n",
    "                                    spike_backup = (spike_backup <= levels).to(torch.float) \n",
    "                                    spike_backup = (spike_backup == 1).cumsum(dim=-1).eq(1).to(torch.float) if lc_adc_on == True else spike_backup\n",
    "                                    spike_backup = spike_backup.unsqueeze(-2)\n",
    "                                    spike_torch = torch.cat((spike_torch, spike_backup), dim=-2)\n",
    "                        elif 'SAE' in net.module.__class__.__name__:\n",
    "                            spike_torch = spike_torch.unsqueeze(1).repeat(1, TIME, 1) # (batch, time, feature)로 변환\n",
    "                            if Conv_net == True:\n",
    "                                spike_torch = spike_torch.unsqueeze(-2) # batch, time, in_channel, feature or batch in_channel,feature\n",
    "                        else:\n",
    "                            # if Conv_net == True:\n",
    "                            #     spike_torch = spike_torch.unsqueeze(-2) #batch in_channel,feature\n",
    "                            if Conv_net == True:\n",
    "                                if coarse_com_mode == False:\n",
    "                                    spike_torch = spike_torch.unsqueeze(-2) #batch in_channel,feature\n",
    "                                else:\n",
    "                                    spike_torch = spike_torch.unsqueeze(2).repeat(1, 1, level_num) # spike_length == level_num # (batch, time, feature)로 변환 \n",
    "                                    spike_torch = (spike_torch > levels).to(torch.float) \n",
    "\n",
    "                                    spike_torch = (spike_torch == 0).cumsum(dim=-1).eq(1).to(torch.float) if lc_adc_on == True else spike_torch\n",
    "\n",
    "                            else:\n",
    "                                if coarse_com_mode == False:\n",
    "                                    pass\n",
    "                                else:\n",
    "                                    spike_torch = spike_torch.unsqueeze(2).repeat(1, 1, level_num) # spike_length == level_num # (batch, time, feature)로 변환 \n",
    "                                    spike_torch = (spike_torch > levels).to(torch.float) \n",
    "\n",
    "                                    spike_torch = (spike_torch == 0).cumsum(dim=-1).eq(1).to(torch.float) if lc_adc_on == True else spike_torch\n",
    "\n",
    "                                    # spike: batch, time, feature\n",
    "                                    spike_torch = spike_torch.reshape(spike_torch.shape[0], -1)\n",
    "                            if converted_net_forward == True:\n",
    "                                spike_torch_spikegen = spikegen.rate(spike_torch, num_steps=TIME).transpose(0, 1)\n",
    "                            # if fusion_net == True:\n",
    "                            #     spike_torch = spikegen.rate(spike_torch, num_steps=TIME).transpose(0, 1)\n",
    "                        ### forward #######################################################\n",
    "                        inner_inf = net.module.encoder(spike_torch)\n",
    "                        if SAE_net == False and converted_net_forward == True:\n",
    "                            converted_inner_inf = converted_net.module.encoder(spike_torch_spikegen)\n",
    "                        ### forward #######################################################\n",
    "                            \n",
    "                        if 'SAE' in net.module.__class__.__name__:\n",
    "                            if SAE_hidden_nomean == True:\n",
    "                                inner_inf = inner_inf.reshape(spike_batch.shape[0],-1)# 펼치기\n",
    "                            else:\n",
    "                                inner_inf = inner_inf.mean(dim=1)# Time 방향으로 평균\n",
    "                            # inner_inf = F.normalize(inner_inf, p=2, dim=1)\n",
    "                        spike_hidden[now_index:now_end_index] = inner_inf.cpu().detach().numpy()\n",
    "                        if SAE_net == False and converted_net_forward == True:\n",
    "                            converted_spike_hidden[now_index:now_end_index] = converted_inner_inf.cpu().detach().numpy()\n",
    "                        now_index += encoder_batch\n",
    "                        if (now_index >= len(spike)):\n",
    "                            break\n",
    "                    \n",
    "                spike_id = np.zeros(len(spike))\n",
    "                distance_sm = np.zeros(num_cluster)\n",
    "                tau = np.zeros(num_cluster)\n",
    "                \n",
    "                plot_tau = []\n",
    "                plot_denominator = []\n",
    "                plot_m = []\n",
    "                plot_max_tau = []\n",
    "                for spike_index in range(len(spike)): \n",
    "                    for q in range(num_cluster):\n",
    "                        tau[q] = np.dot(spike_hidden[spike_index, :], Cluster[q, :]) # 이거 l2norm 거쳐서 나온 거니까 분모 1임.\n",
    "                        denominator =  np.linalg.norm(spike_hidden[spike_index, :])*np.linalg.norm(Cluster[q, :]) + 1e-12\n",
    "                        plot_denominator.append(denominator)\n",
    "                        if 'SAE' in net.module.__class__.__name__: # AE 때는 l2norm거쳐서 나와서 괜찮음\n",
    "                            tau[q] = tau[q] / denominator\n",
    "\n",
    "                        plot_tau.append(tau[q])\n",
    "\n",
    "                    # for i in range(num_cluster): # l2 distance\n",
    "                    #     distance_sm[i] = np.sum(np.power(np.abs(Cluster[i] - spike_hidden[spike_index, :]), 2))\n",
    "                    distance_sm = np.sum(np.power(np.abs(Cluster - spike_hidden[spike_index, :]), 2), axis=1)\n",
    "\n",
    "                    m = np.argmin(distance_sm)\n",
    "                    plot_m.append(m)\n",
    "                    spike_id[spike_index] = m + 1\n",
    "                    # print(spike_tot[ds], spike_index,np.max(tau))\n",
    "                    plot_max_tau.append(np.max(tau))\n",
    "                    if(np.max(tau) >= cos_thr[ds] and spike_index < training_cycle): # 원래 1400 아니냐?\n",
    "                        Cluster[m] = (Cluster[m] * 15 + spike_hidden[spike_index, :])/16\n",
    "\n",
    "\n",
    "                \n",
    "                origin_kmeans_accuracy = cluster_spikes_with_accuracy_torch(features= spike, true_labels=label-1, n_clusters=3, init_point=None)\n",
    "                kmeans_accuracy = cluster_spikes_with_accuracy_torch(features= torch.tensor(spike_hidden).to(device), true_labels=label-1, n_clusters=3, init_point=None)\n",
    "                k_means_bin_origin_feature.append(origin_kmeans_accuracy)\n",
    "                k_means_bin.append(kmeans_accuracy)\n",
    "                if SAE_net == False and converted_net_forward == True:\n",
    "                    converted_kmeans_accuracy = cluster_spikes_with_accuracy_torch(features= torch.tensor(converted_spike_hidden).to(device), true_labels=label-1, n_clusters=3, init_point=None)\n",
    "                    converted_k_means_bin.append(converted_kmeans_accuracy)\n",
    "                # sklearn kmeans인데 cpu많이먹어서 버림.\n",
    "                # origin_kmeans_accuracy = cluster_spikes_with_accuracy(features= spike.cpu().detach().numpy(), true_labels=label-1, n_clusters=3, init_point=None)\n",
    "                # kmeans_accuracy = cluster_spikes_with_accuracy(features= spike_hidden, true_labels=label-1, n_clusters=3, init_point=None)\n",
    "                # k_means_bin_origin_feature.append(origin_kmeans_accuracy)\n",
    "                # k_means_bin.append(kmeans_accuracy)\n",
    "                # if SAE_net == False and converted_net_forward == True:\n",
    "                #     converted_kmeans_accuracy = cluster_spikes_with_accuracy(features= converted_spike_hidden, true_labels=label-1, n_clusters=3, init_point=None)\n",
    "                #     converted_k_means_bin.append(converted_kmeans_accuracy)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "                # print('Cluster',Cluster)\n",
    "                # print('spike_id', spike_id)\n",
    "\n",
    "                # spike id 분포 확인하기\n",
    "                # unique_elements, counts = np.unique(spike_id, return_counts=True)\n",
    "                # print(\"Unique elements:\", unique_elements)\n",
    "                # print(\"Counts:\", counts)\n",
    "\n",
    "                cluster_accuracy_during_training_cycle = np.zeros(math.factorial(num_cluster))\n",
    "                cluster_accuracy_post_training_cycle = np.zeros(math.factorial(num_cluster))\n",
    "                cluster_accuracy_total = np.zeros(math.factorial(num_cluster))\n",
    "                \n",
    "                label_converter_ground = list(range(1, num_cluster + 1)) # [1, 2, 3, 4] 생성\n",
    "                label_converter_permutations = list(itertools.permutations(label_converter_ground)) # 모든 순열 구하기\n",
    "                perm_i = 0\n",
    "                perm_start_time = time.time() \n",
    "                for perm in label_converter_permutations:\n",
    "                    label_converter = list(perm)\n",
    "                    # print(label_converter)\n",
    "                    correct_during_training_cycle = 0\n",
    "                    correct_post_training_cycle = 0\n",
    "\n",
    "                    assert len(spike_id) == len(label), 'spike_id랑 label 길이 같아야 됨.'\n",
    "                    for i in range(len(spike_id)):\n",
    "                        if(label_converter[int(spike_id[i]-1)] == label[i]):\n",
    "                            if i < training_cycle:\n",
    "                                correct_during_training_cycle += 1\n",
    "                            else:\n",
    "                                correct_post_training_cycle += 1\n",
    "\n",
    "                    cluster_accuracy_during_training_cycle[perm_i] = correct_during_training_cycle/training_cycle\n",
    "                    cluster_accuracy_post_training_cycle[perm_i] = correct_post_training_cycle/(len(spike_id)-training_cycle)\n",
    "                    cluster_accuracy_total[perm_i] = (correct_during_training_cycle+correct_post_training_cycle)/(len(spike_id))\n",
    "                    perm_i += 1\n",
    "                # print(f\"perm 실행 시간: {time.time()-perm_start_time:.3f}초\")\n",
    "                \n",
    "                cluster_accuracy_during_training_cycle_all_dataset[ds] = np.max(cluster_accuracy_during_training_cycle)\n",
    "                cluster_accuracy_post_training_cycle_all_dataset[ds] = cluster_accuracy_post_training_cycle[np.argmax(cluster_accuracy_during_training_cycle)]\n",
    "                cluster_accuracy_total_all_dataset[ds] = cluster_accuracy_total[np.argmax(cluster_accuracy_during_training_cycle)]\n",
    "                # plot_distributions(ds, plot_tau, plot_denominator, plot_m, plot_max_tau, cos_thr[ds],\n",
    "                #                    cluster_accuracy_during_training_cycle_all_dataset[ds], cluster_accuracy_post_training_cycle_all_dataset[ds], cluster_accuracy_total_all_dataset[ds])\n",
    "            print(f'k_means origin feature average accuracy : {100*sum(k_means_bin_origin_feature)/(len(k_means_bin_origin_feature)+1e-12):.8f}%, total {k_means_bin_origin_feature}')\n",
    "            \n",
    "            mean_cluster_accuracy_during_training_cycle_all_dataset = np.mean(cluster_accuracy_during_training_cycle_all_dataset)\n",
    "            mean_cluster_accuracy_post_training_cycle_all_dataset = np.mean(cluster_accuracy_post_training_cycle_all_dataset)\n",
    "            mean_cluster_accuracy_total_all_dataset = np.mean(cluster_accuracy_total_all_dataset)\n",
    "            \n",
    "            if SAE_net == False and converted_net_forward == True:\n",
    "                converted_k_means_acc = 100*sum(converted_k_means_bin)/len(converted_k_means_bin)\n",
    "                print(f'converted_kmeans average accuracy : {converted_k_means_acc:.8f}%, total {converted_k_means_bin}')\n",
    "            k_means_acc = 100*sum(k_means_bin)/len(k_means_bin)\n",
    "            if k_means_acc > k_means_acc_best:\n",
    "                # torch.save(net, f\"net_save/save_now_net_{current_time}.pth\")\n",
    "                torch.save(net.module.state_dict(), f\"net_save/save_now_net_{current_time}.pth\")\n",
    "                print('save model')\n",
    "                best_mean_cluster_accuracy_post_training_cycle_all_dataset = mean_cluster_accuracy_post_training_cycle_all_dataset\n",
    "            \n",
    "            k_means_acc_best = max(k_means_acc_best, k_means_acc)\n",
    "            print(f'kmeans average accuracy best : {k_means_acc_best:.2f}%, kmeans average accuracy : {k_means_acc:.8f}%, total {k_means_bin}')\n",
    "            print(f'cluster_accuracy_post_training_cycle_all_dataset : {cluster_accuracy_post_training_cycle_all_dataset}')\n",
    "\n",
    "            \n",
    "            mean_cluster_accuracy_during_training_cycle_all_dataset_history.append((epoch, mean_cluster_accuracy_during_training_cycle_all_dataset*100))\n",
    "            mean_cluster_accuracy_post_training_cycle_all_dataset_history.append((epoch, mean_cluster_accuracy_post_training_cycle_all_dataset*100))\n",
    "            mean_cluster_accuracy_total_all_dataset_history.append((epoch, mean_cluster_accuracy_total_all_dataset*100))\n",
    "            print(f\"mean_cluster_accuracy_during_training_cycle : {mean_cluster_accuracy_during_training_cycle_all_dataset*100:.2f}%, post_traincycle_acc : {mean_cluster_accuracy_post_training_cycle_all_dataset*100:.2f}%, total_acc : {mean_cluster_accuracy_total_all_dataset*100:.8f}%\")\n",
    "\n",
    "            # kmeans accuracy기준으로 좋은 거 저장할 거임\n",
    "            # if mean_cluster_accuracy_post_training_cycle_all_dataset > best_mean_cluster_accuracy_post_training_cycle_all_dataset:\n",
    "            #     # torch.save(net, f\"net_save/save_now_net_{current_time}.pth\")\n",
    "            #     torch.save(net.module.state_dict(), f\"net_save/save_now_net_{current_time}.pth\")\n",
    "            #     print('save model')\n",
    "            #     best_mean_cluster_accuracy_post_training_cycle_all_dataset = mean_cluster_accuracy_post_training_cycle_all_dataset\n",
    "            print(f\"best_mean_cluster_accuracy_post_training_cycle_all_dataset : {best_mean_cluster_accuracy_post_training_cycle_all_dataset*100:.2f}%\")\n",
    "            print(f\"accuracy_check 실행 시간: {time.time()-accuracy_check_start_time:.3f}초\")\n",
    "\n",
    "        wandb.log({\"avg_loss\": avg_loss})\n",
    "        wandb.log({\"mean_cluster_accuracy_post_training_cycle_all_dataset\": mean_cluster_accuracy_post_training_cycle_all_dataset})\n",
    "        wandb.log({\"best_mean_cluster_accuracy_post_training_cycle_all_dataset\": best_mean_cluster_accuracy_post_training_cycle_all_dataset})\n",
    "        wandb.log({\"best_mean_cluster_accuracy_post_training_cycle_all_dataset2\": best_mean_cluster_accuracy_post_training_cycle_all_dataset})\n",
    "        wandb.log({\"k_means_acc\": k_means_acc})\n",
    "        wandb.log({\"k_means_acc_best\": k_means_acc_best})\n",
    "        wandb.log({\"converted_k_means_acc\": converted_k_means_acc})\n",
    "\n",
    "\n",
    "        # 저장\n",
    "        with open(f\"result_save/cluster_accuracy_history_{current_time}.pkl\", \"wb\") as f:\n",
    "            pickle.dump({\n",
    "                \"loss_history\": loss_history,\n",
    "                \"mean_cluster_accuracy_during_training_cycle_all_dataset_history\": mean_cluster_accuracy_during_training_cycle_all_dataset_history,\n",
    "                \"mean_cluster_accuracy_post_training_cycle_all_dataset_history\": mean_cluster_accuracy_post_training_cycle_all_dataset_history,\n",
    "                \"mean_cluster_accuracy_total_all_dataset_history\": mean_cluster_accuracy_total_all_dataset_history,\n",
    "            }, f)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mbhkim003\u001b[0m (\u001b[33mbhkim003-seoul-national-university\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.19.7 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.17.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/nfs/home/bhkim003/github_folder/ByeonghyeonKim/my_snn/wandb/run-20250304_194403-8rvczvjl</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/bhkim003-seoul-national-university/spike_sorting%20just%20run/runs/8rvczvjl' target=\"_blank\">visionary-firefly-1335</a></strong> to <a href='https://wandb.ai/bhkim003-seoul-national-university/spike_sorting%20just%20run' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/bhkim003-seoul-national-university/spike_sorting%20just%20run' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/spike_sorting%20just%20run</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/bhkim003-seoul-national-university/spike_sorting%20just%20run/runs/8rvczvjl' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/spike_sorting%20just%20run/runs/8rvczvjl</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'gpu': '5', 'Conv_net': True, 'SAE_net': True, 'dataset_num': 16, 'spike_length': 50, 'num_cluster': 4, 'training_cycle': 1400, 'batch_size': 32, 'max_epoch': 10000, 'learning_rate': 0.001, 'normalize_on': True, 'need_bias': False, 'lif_add_at_first': False, 'my_seed': 42, 'TIME': 50, 'v_decay': 0.5, 'v_threshold': 0.25, 'v_reset': 0.0, 'BPTT_on': True, 'SAE_hidden_nomean': True, 'current_time': '20250304_194401_700', 'optimizer': 'Adam', 'coarse_com_mode': True, 'sae_l2_norm_bridge': True, 'sae_lif_bridge': False, 'accuracy_check_epoch_term': 1, 'lif_add_at_last': False, 'two_channel_input': False, 'lateral_feature_num': 4, 'lc_adc_on': False, 'converted_net_forward': False, 'pretrained_net': None, 'vth_mul_on': False, 'batch_norm_on': False, 'l2_norm_loss_weight': 0, 'QCFS_neuron_on': False, 'quantize_level_num': 0, 'fusion_net': True, 'repeat_coding': False, 'sae_relu_on': False, 'conv1d_scaling': False, 'norm01': True, 'coarse_com_config': (0.999, -0.0)}\n",
      "cos_thr [0.95 0.95 0.95 0.95 0.95 0.95 0.95 0.85 0.95 0.9  0.8  0.95 0.95 0.95\n",
      " 0.95 0.8 ]\n",
      "conv length [50, 24, 11, 5]\n",
      "Total number of encoder parameters: 26592\n",
      "DataParallel(\n",
      "  (module): SAE_FUSION4_net_conv1(\n",
      "    (activation_function): LIF_layer()\n",
      "    (encoder): Sequential(\n",
      "      (0): SSBH_DimChanger_one_two()\n",
      "      (1): SSBH_DimChanger_for_one_two_coupling()\n",
      "      (2): Conv1d(1, 32, kernel_size=(3,), stride=(2,), bias=False)\n",
      "      (3): SSBH_DimChanger_for_one_two_decoupling()\n",
      "      (4): LIF_layer()\n",
      "      (5): SSBH_DimChanger_for_one_two_coupling()\n",
      "      (6): Conv1d(32, 64, kernel_size=(3,), stride=(2,), bias=False)\n",
      "      (7): SSBH_DimChanger_for_one_two_decoupling()\n",
      "      (8): LIF_layer()\n",
      "      (9): SSBH_DimChanger_for_one_two_coupling()\n",
      "      (10): Conv1d(64, 96, kernel_size=(3,), stride=(2,), bias=False)\n",
      "      (11): SSBH_DimChanger_for_one_two_decoupling()\n",
      "      (12): LIF_layer()\n",
      "      (13): SSBH_DimChanger_for_one_two_coupling()\n",
      "      (14): SSBH_DimChanger_for_fc()\n",
      "      (15): Linear(in_features=480, out_features=4, bias=False)\n",
      "      (16): SSBH_DimChanger_for_one_two_decoupling()\n",
      "      (17): SSBH_DimSum()\n",
      "    )\n",
      "    (decoder): Sequential(\n",
      "      (0): Linear(in_features=4, out_features=480, bias=False)\n",
      "      (1): ReLU()\n",
      "      (2): SSBH_DimChanger_for_conv1()\n",
      "      (3): ConvTranspose1d(96, 64, kernel_size=(3,), stride=(2,), bias=False)\n",
      "      (4): ReLU()\n",
      "      (5): ConvTranspose1d(64, 32, kernel_size=(3,), stride=(2,), output_padding=(1,), bias=False)\n",
      "      (6): ReLU()\n",
      "      (7): ConvTranspose1d(32, 1, kernel_size=(3,), stride=(2,), output_padding=(1,), bias=False)\n",
      "    )\n",
      "  )\n",
      ")\n",
      "Device: cuda\n",
      "\n",
      "Start Training, current_time = 20250304_194401_700\n",
      "\n",
      "\n",
      "epoch-0 loss : 0.06136866, loss_normal : 0.02767863, loss_coarse : 0.10887091, min_loss : 0.06136866, min_loss_normal : 0.02767863, min_loss_coarse : 0.10887091, wrong_element_sum : 20903216.00000000, same_data : 0.00%\n",
      "ae train 실행 시간: 92.153초, 전체 시작 시간 20250304_194401_700\n",
      "\n",
      "epoch-0 accuracy check\n",
      "k_means origin feature average accuracy : 82.25492108%, total [0.9746727376209448, 0.9733106189664963, 0.9700891573195284, 0.9530800230282096, 0.943108504398827, 0.9150568181818182, 0.801817648783348, 0.6625070901871809, 0.9488619568430388, 0.822215777262181, 0.5866935483870968, 0.5005858230814294, 0.9429250891795482, 0.8922588099364529, 0.673546511627907, 0.6000572573718866]\n",
      "save model\n",
      "kmeans average accuracy best : 72.22%, kmeans average accuracy : 72.21549447%, total [0.9499146272054638, 0.9545712663259511, 0.9416163359217716, 0.8983880253310305, 0.9407624633431085, 0.890625, 0.7725007329228966, 0.5972773681225184, 0.8182086905113805, 0.5652552204176334, 0.4772465437788018, 0.4206209724663152, 0.6391200951248514, 0.6112073945696129, 0.5572674418604651, 0.5198969367306041]\n",
      "cluster_accuracy_post_training_cycle_all_dataset : [0.94796594 0.95287465 0.93837265 0.90983607 0.94427861 0.875\n",
      " 0.78269518 0.57996237 0.82450832 0.52880859 0.47055985 0.40566038\n",
      " 0.77291242 0.63579049 0.56176471 0.52126135]\n",
      "mean_cluster_accuracy_during_training_cycle : 73.34%, post_traincycle_acc : 72.83%, total_acc : 73.03163824%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 72.83%\n",
      "accuracy_check 실행 시간: 20.858초\n",
      "\n",
      "\n",
      "epoch-1 loss : 0.03486603, loss_normal : 0.01945034, loss_coarse : 0.08866161, min_loss : 0.03486603, min_loss_normal : 0.01945034, min_loss_coarse : 0.08866161, wrong_element_sum : 17023030.00000000, same_data : 0.00%\n",
      "ae train 실행 시간: 94.545초, 전체 시작 시간 20250304_194401_700\n",
      "\n",
      "epoch-1 accuracy check\n",
      "k_means origin feature average accuracy : 82.25860333%, total [0.9746727376209448, 0.9733106189664963, 0.9700891573195284, 0.9530800230282096, 0.943108504398827, 0.9150568181818182, 0.801817648783348, 0.6622234826999432, 0.9488619568430388, 0.8219257540603249, 0.5866935483870968, 0.5005858230814294, 0.9429250891795482, 0.8922588099364529, 0.6747093023255814, 0.6000572573718866]\n",
      "save model\n",
      "kmeans average accuracy best : 74.28%, kmeans average accuracy : 74.28335302%, total [0.9573136027319294, 0.9585462805224304, 0.9442047742306586, 0.9349453080023028, 0.9416422287390029, 0.9113636363636364, 0.8038698328935796, 0.5870674985819626, 0.9225539462015963, 0.5690255220417634, 0.44527649769585254, 0.4130052724077329, 0.6501189060642093, 0.6409589832466782, 0.6154069767441861, 0.5900372172917263]\n",
      "cluster_accuracy_post_training_cycle_all_dataset : [0.95648061 0.95758718 0.94318729 0.92430087 0.94477612 0.89150943\n",
      " 0.83043262 0.56067733 0.92032274 0.55810547 0.45415058 0.41410129\n",
      " 0.74796334 0.62609117 0.63186275 0.60009556]\n",
      "mean_cluster_accuracy_during_training_cycle : 75.55%, post_traincycle_acc : 74.76%, total_acc : 75.07826950%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 74.76%\n",
      "accuracy_check 실행 시간: 22.248초\n",
      "\n",
      "\n",
      "epoch-2 loss : 0.03145727, loss_normal : 0.01843246, loss_coarse : 0.08520025, min_loss : 0.03145727, min_loss_normal : 0.01843246, min_loss_coarse : 0.08520025, wrong_element_sum : 16358448.00000000, same_data : 0.00%\n",
      "ae train 실행 시간: 92.826초, 전체 시작 시간 20250304_194401_700\n",
      "\n",
      "epoch-2 accuracy check\n",
      "k_means origin feature average accuracy : 82.25855480%, total [0.9746727376209448, 0.9733106189664963, 0.9700891573195284, 0.9530800230282096, 0.943108504398827, 0.9150568181818182, 0.801817648783348, 0.6625070901871809, 0.9488619568430388, 0.822215777262181, 0.5866935483870968, 0.5005858230814294, 0.9429250891795482, 0.8922588099364529, 0.6741279069767442, 0.6000572573718866]\n",
      "kmeans average accuracy best : 74.28%, kmeans average accuracy : 73.83097757%, total [0.9595902105862265, 0.9605337876206701, 0.9450675870002876, 0.9211283822682786, 0.9442815249266863, 0.9099431818181818, 0.8044561712107886, 0.5439591605218378, 0.916937629323086, 0.6325406032482599, 0.4835829493087558, 0.4144698301113064, 0.630499405469679, 0.6178509532062392, 0.5755813953488372, 0.5525336387059834]\n",
      "cluster_accuracy_post_training_cycle_all_dataset : [0.95742668 0.95852969 0.94126143 0.92092575 0.94278607 0.90235849\n",
      " 0.80954749 0.53010348 0.90267272 0.61328125 0.47007722 0.43843098\n",
      " 0.76527495 0.64839961 0.53627451 0.55279503]\n",
      "mean_cluster_accuracy_during_training_cycle : 75.62%, post_traincycle_acc : 74.31%, total_acc : 74.84092450%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 74.76%\n",
      "accuracy_check 실행 시간: 21.769초\n",
      "\n",
      "\n",
      "epoch-3 loss : 0.03020725, loss_normal : 0.01803410, loss_coarse : 0.08367589, min_loss : 0.03020725, min_loss_normal : 0.01803410, min_loss_coarse : 0.08367589, wrong_element_sum : 16065772.00000000, same_data : 0.00%\n",
      "ae train 실행 시간: 96.361초, 전체 시작 시간 20250304_194401_700\n",
      "\n",
      "epoch-3 accuracy check\n",
      "k_means origin feature average accuracy : 82.26764992%, total [0.9746727376209448, 0.9733106189664963, 0.9700891573195284, 0.9530800230282096, 0.943108504398827, 0.9150568181818182, 0.801817648783348, 0.6622234826999432, 0.9488619568430388, 0.822215777262181, 0.5872695852534562, 0.5005858230814294, 0.9429250891795482, 0.8922588099364529, 0.6752906976744186, 0.6000572573718866]\n",
      "save model\n",
      "kmeans average accuracy best : 74.73%, kmeans average accuracy : 74.73115296%, total [0.9561752988047809, 0.9585462805224304, 0.9488064423353466, 0.9260218767990789, 0.943108504398827, 0.9088068181818182, 0.8182351216652008, 0.655700510493477, 0.9163464380727165, 0.611368909512761, 0.47868663594470046, 0.4279437609841828, 0.6376337693222355, 0.6138070479491623, 0.5886627906976745, 0.5671342685370742]\n",
      "cluster_accuracy_post_training_cycle_all_dataset : [0.95648061 0.95758718 0.94318729 0.92574735 0.94527363 0.9009434\n",
      " 0.83391348 0.59877705 0.88653555 0.61767578 0.45704633 0.43445879\n",
      " 0.71181263 0.61202716 0.60833333 0.57525084]\n",
      "mean_cluster_accuracy_during_training_cycle : 76.13%, post_traincycle_acc : 74.78%, total_acc : 75.32820271%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 74.78%\n",
      "accuracy_check 실행 시간: 22.097초\n",
      "\n",
      "\n",
      "epoch-4 loss : 0.02832880, loss_normal : 0.01751716, loss_coarse : 0.08181976, min_loss : 0.02832880, min_loss_normal : 0.01751716, min_loss_coarse : 0.08181976, wrong_element_sum : 15709394.00000000, same_data : 0.00%\n",
      "ae train 실행 시간: 94.604초, 전체 시작 시간 20250304_194401_700\n",
      "\n",
      "epoch-4 accuracy check\n",
      "k_means origin feature average accuracy : 82.25498833%, total [0.9746727376209448, 0.9733106189664963, 0.9700891573195284, 0.9530800230282096, 0.943108504398827, 0.9150568181818182, 0.8015244796247435, 0.6625070901871809, 0.9488619568430388, 0.822215777262181, 0.5866935483870968, 0.5005858230814294, 0.9429250891795482, 0.8922588099364529, 0.6747093023255814, 0.5991983967935872]\n",
      "save model\n",
      "kmeans average accuracy best : 75.92%, kmeans average accuracy : 75.91897632%, total [0.9587364826408651, 0.9596819988642816, 0.9490940465918896, 0.92573402417962, 0.944574780058651, 0.9076704545454546, 0.8117854001759015, 0.5924560408394781, 0.9198935855749335, 0.6864849187935035, 0.4778225806451613, 0.4241359109548916, 0.6905469678953626, 0.659734257654535, 0.6363372093023256, 0.6023475522473518]\n",
      "cluster_accuracy_post_training_cycle_all_dataset : [0.95789972 0.9604147  0.94992778 0.93153327 0.94427861 0.90566038\n",
      " 0.83938339 0.56726246 0.91477559 0.68164062 0.47779923 0.4061569\n",
      " 0.78513238 0.67604268 0.66519608 0.60200669]\n",
      "mean_cluster_accuracy_during_training_cycle : 77.95%, post_traincycle_acc : 76.66%, total_acc : 77.17811970%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 76.66%\n",
      "accuracy_check 실행 시간: 21.212초\n",
      "\n",
      "\n",
      "epoch-5 loss : 0.02678508, loss_normal : 0.01715053, loss_coarse : 0.08040458, min_loss : 0.02678508, min_loss_normal : 0.01715053, min_loss_coarse : 0.08040458, wrong_element_sum : 15437680.00000000, same_data : 0.00%\n",
      "ae train 실행 시간: 94.391초, 전체 시작 시간 20250304_194401_700\n",
      "\n",
      "epoch-5 accuracy check\n",
      "k_means origin feature average accuracy : 82.24959751%, total [0.9746727376209448, 0.9733106189664963, 0.9700891573195284, 0.9530800230282096, 0.943108504398827, 0.9150568181818182, 0.801817648783348, 0.6622234826999432, 0.9488619568430388, 0.822215777262181, 0.5866935483870968, 0.5005858230814294, 0.9429250891795482, 0.8922588099364529, 0.6738372093023256, 0.5991983967935872]\n",
      "kmeans average accuracy best : 75.92%, kmeans average accuracy : 75.53145656%, total [0.9570290267501423, 0.9602498580352072, 0.9505320678746045, 0.9335060449050087, 0.9428152492668622, 0.9173295454545455, 0.8226326590442685, 0.6137266023823029, 0.9287614543304759, 0.6145591647331786, 0.4680299539170507, 0.44522554188635033, 0.6958977407847801, 0.6074523396880416, 0.6209302325581395, 0.606355568279416]\n",
      "cluster_accuracy_post_training_cycle_all_dataset : [0.95506149 0.95994345 0.95089071 0.93442623 0.94179104 0.91367925\n",
      " 0.82943809 0.60112888 0.91780131 0.63427734 0.48938224 0.40913605\n",
      " 0.7107943  0.62657614 0.61862745 0.59388438]\n",
      "mean_cluster_accuracy_during_training_cycle : 76.56%, post_traincycle_acc : 75.54%, total_acc : 75.95673005%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 76.66%\n",
      "accuracy_check 실행 시간: 21.557초\n",
      "\n",
      "\n",
      "epoch-6 loss : 0.02608379, loss_normal : 0.01696734, loss_coarse : 0.07983968, min_loss : 0.02608379, min_loss_normal : 0.01696734, min_loss_coarse : 0.07983968, wrong_element_sum : 15329218.00000000, same_data : 0.00%\n",
      "ae train 실행 시간: 96.498초, 전체 시작 시간 20250304_194401_700\n",
      "\n",
      "epoch-6 accuracy check\n",
      "k_means origin feature average accuracy : 82.25504809%, total [0.9746727376209448, 0.9733106189664963, 0.9700891573195284, 0.9530800230282096, 0.943108504398827, 0.9150568181818182, 0.801817648783348, 0.6622234826999432, 0.9488619568430388, 0.822215777262181, 0.5866935483870968, 0.5005858230814294, 0.9429250891795482, 0.8922588099364529, 0.6747093023255814, 0.5991983967935872]\n",
      "save model\n",
      "kmeans average accuracy best : 77.09%, kmeans average accuracy : 77.09314163%, total [0.9604439385315879, 0.9619534355479841, 0.9513948806442335, 0.9352331606217616, 0.9434017595307918, 0.9159090909090909, 0.8293755496921724, 0.653998865570051, 0.9423588530889743, 0.6438515081206496, 0.4835829493087558, 0.45225541886350323, 0.7199762187871581, 0.6689774696707106, 0.6558139534883721, 0.6163756083595763]\n",
      "cluster_accuracy_post_training_cycle_all_dataset : [0.95837275 0.96229972 0.94944632 0.93635487 0.94278607 0.90566038\n",
      " 0.83341621 0.58231421 0.92486132 0.64599609 0.46090734 0.45134062\n",
      " 0.74439919 0.69932105 0.67352941 0.60774009]\n",
      "mean_cluster_accuracy_during_training_cycle : 77.67%, post_traincycle_acc : 76.74%, total_acc : 77.11862536%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 76.74%\n",
      "accuracy_check 실행 시간: 20.629초\n",
      "\n",
      "\n",
      "epoch-7 loss : 0.02506137, loss_normal : 0.01672490, loss_coarse : 0.07862898, min_loss : 0.02506137, min_loss_normal : 0.01672490, min_loss_coarse : 0.07862898, wrong_element_sum : 15096764.00000000, same_data : 0.00%\n",
      "ae train 실행 시간: 91.748초, 전체 시작 시간 20250304_194401_700\n",
      "\n",
      "epoch-7 accuracy check\n",
      "k_means origin feature average accuracy : 82.25149115%, total [0.9746727376209448, 0.9733106189664963, 0.9700891573195284, 0.9530800230282096, 0.943108504398827, 0.9150568181818182, 0.801817648783348, 0.6622234826999432, 0.9488619568430388, 0.822215777262181, 0.5872695852534562, 0.5005858230814294, 0.9429250891795482, 0.8922588099364529, 0.6747093023255814, 0.5980532493558546]\n",
      "kmeans average accuracy best : 77.09%, kmeans average accuracy : 75.75690231%, total [0.9598747865680136, 0.9602498580352072, 0.9513948806442335, 0.932930339666091, 0.9436950146627566, 0.9107954545454545, 0.8155965992377602, 0.6236528644356211, 0.9240319243275199, 0.6142691415313225, 0.5172811059907834, 0.4844756883421207, 0.6664684898929846, 0.6311380704794917, 0.6241279069767441, 0.561122244488978]\n",
      "cluster_accuracy_post_training_cycle_all_dataset : [0.95742668 0.9594722  0.94126143 0.93394407 0.94179104 0.90943396\n",
      " 0.8264545  0.58748824 0.91124559 0.61523438 0.50868726 0.48857994\n",
      " 0.6089613  0.66488846 0.64656863 0.58002867]\n",
      "mean_cluster_accuracy_during_training_cycle : 76.21%, post_traincycle_acc : 75.51%, total_acc : 75.79519208%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 76.74%\n",
      "accuracy_check 실행 시간: 21.254초\n",
      "\n",
      "\n",
      "epoch-8 loss : 0.02441254, loss_normal : 0.01656725, loss_coarse : 0.07796638, min_loss : 0.02441254, min_loss_normal : 0.01656725, min_loss_coarse : 0.07796638, wrong_element_sum : 14969546.00000000, same_data : 0.00%\n",
      "ae train 실행 시간: 92.207초, 전체 시작 시간 20250304_194401_700\n",
      "\n",
      "epoch-8 accuracy check\n",
      "k_means origin feature average accuracy : 82.25851350%, total [0.9746727376209448, 0.9733106189664963, 0.9700891573195284, 0.9530800230282096, 0.943108504398827, 0.915340909090909, 0.801817648783348, 0.6625070901871809, 0.9488619568430388, 0.822215777262181, 0.5866935483870968, 0.5005858230814294, 0.9429250891795482, 0.8922588099364529, 0.6738372093023256, 0.6000572573718866]\n",
      "kmeans average accuracy best : 77.09%, kmeans average accuracy : 76.22907368%, total [0.9598747865680136, 0.9608177172061328, 0.9516824849007766, 0.932930339666091, 0.9416422287390029, 0.9082386363636363, 0.810905892700088, 0.5995462280204198, 0.9225539462015963, 0.654292343387471, 0.5279377880184332, 0.4997070884592853, 0.6489298454221165, 0.6366262276140959, 0.6357558139534883, 0.6052104208416834]\n",
      "cluster_accuracy_post_training_cycle_all_dataset : [0.95695364 0.96135721 0.94752046 0.93683703 0.94228856 0.9004717\n",
      " 0.82048732 0.60630292 0.90267272 0.68652344 0.51399614 0.47368421\n",
      " 0.63849287 0.65809893 0.65392157 0.60344004]\n",
      "mean_cluster_accuracy_during_training_cycle : 77.19%, post_traincycle_acc : 76.27%, total_acc : 76.64838812%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 76.74%\n",
      "accuracy_check 실행 시간: 20.345초\n",
      "\n",
      "\n",
      "epoch-9 loss : 0.02387307, loss_normal : 0.01643926, loss_coarse : 0.07746111, min_loss : 0.02387307, min_loss_normal : 0.01643926, min_loss_coarse : 0.07746111, wrong_element_sum : 14872534.00000000, same_data : 0.00%\n",
      "ae train 실행 시간: 93.047초, 전체 시작 시간 20250304_194401_700\n",
      "\n",
      "epoch-9 accuracy check\n",
      "k_means origin feature average accuracy : 82.25495484%, total [0.9746727376209448, 0.9733106189664963, 0.9700891573195284, 0.9530800230282096, 0.943108504398827, 0.9150568181818182, 0.8015244796247435, 0.6625070901871809, 0.9488619568430388, 0.822215777262181, 0.5872695852534562, 0.5005858230814294, 0.9429250891795482, 0.8922588099364529, 0.6741279069767442, 0.5991983967935872]\n",
      "kmeans average accuracy best : 77.09%, kmeans average accuracy : 75.86444182%, total [0.9567444507683551, 0.9611016467915957, 0.9511072763876905, 0.9317789291882557, 0.943108504398827, 0.9142045454545454, 0.8208736440926414, 0.6168462847419172, 0.9119125036949454, 0.6473317865429234, 0.5008640552995391, 0.4833040421792619, 0.6462544589774079, 0.6325823223570191, 0.6319767441860465, 0.5883194961351274]\n",
      "cluster_accuracy_post_training_cycle_all_dataset : [0.95648061 0.9604147  0.94752046 0.93635487 0.94378109 0.90613208\n",
      " 0.82595724 0.59313264 0.90368129 0.65087891 0.49227799 0.4632572\n",
      " 0.64409369 0.66294859 0.63970588 0.60296226]\n",
      "mean_cluster_accuracy_during_training_cycle : 77.13%, post_traincycle_acc : 75.81%, total_acc : 76.34804078%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 76.74%\n",
      "accuracy_check 실행 시간: 21.387초\n",
      "\n",
      "\n",
      "epoch-10 loss : 0.02348771, loss_normal : 0.01633516, loss_coarse : 0.07699834, min_loss : 0.02348771, min_loss_normal : 0.01633516, min_loss_coarse : 0.07699834, wrong_element_sum : 14783682.00000000, same_data : 0.00%\n",
      "ae train 실행 시간: 93.802초, 전체 시작 시간 20250304_194401_700\n",
      "\n",
      "epoch-10 accuracy check\n",
      "k_means origin feature average accuracy : 82.24225975%, total [0.9746727376209448, 0.9733106189664963, 0.9700891573195284, 0.9530800230282096, 0.943108504398827, 0.9150568181818182, 0.8006449721489299, 0.6625070901871809, 0.9488619568430388, 0.822215777262181, 0.5872695852534562, 0.5005858230814294, 0.9429250891795482, 0.89052570768342, 0.6747093023255814, 0.5991983967935872]\n",
      "kmeans average accuracy best : 77.09%, kmeans average accuracy : 76.39493560%, total [0.958451906659078, 0.9608177172061328, 0.9490940465918896, 0.927461139896373, 0.9419354838709677, 0.9130681818181818, 0.8173556141893873, 0.6213840045377198, 0.9266922849541827, 0.6760440835266821, 0.5144009216589862, 0.44698301113063854, 0.6816290130796671, 0.6504910456383594, 0.6447674418604651, 0.5926137990266247]\n",
      "cluster_accuracy_post_training_cycle_all_dataset : [0.95695364 0.96088596 0.94752046 0.93731919 0.94477612 0.90660377\n",
      " 0.8150174  0.59360301 0.92133132 0.67578125 0.50723938 0.42949355\n",
      " 0.69806517 0.65955383 0.66470588 0.60152891]\n",
      "mean_cluster_accuracy_during_training_cycle : 77.92%, post_traincycle_acc : 76.38%, total_acc : 77.00852122%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 76.74%\n",
      "accuracy_check 실행 시간: 20.927초\n",
      "\n",
      "\n",
      "epoch-11 loss : 0.02308253, loss_normal : 0.01624302, loss_coarse : 0.07647287, min_loss : 0.02308253, min_loss_normal : 0.01624302, min_loss_coarse : 0.07647287, wrong_element_sum : 14682792.00000000, same_data : 0.00%\n",
      "ae train 실행 시간: 95.035초, 전체 시작 시간 20250304_194401_700\n",
      "\n",
      "epoch-11 accuracy check\n",
      "k_means origin feature average accuracy : 82.26578875%, total [0.9746727376209448, 0.9733106189664963, 0.9700891573195284, 0.9530800230282096, 0.943108504398827, 0.9150568181818182, 0.801817648783348, 0.6625070901871809, 0.9488619568430388, 0.822215777262181, 0.5872695852534562, 0.5005858230814294, 0.9429250891795482, 0.8922588099364529, 0.6747093023255814, 0.6000572573718866]\n",
      "save model\n",
      "kmeans average accuracy best : 77.50%, kmeans average accuracy : 77.49933315%, total [0.9575981787137166, 0.9605337876206701, 0.9513948806442335, 0.9360967184801382, 0.9419354838709677, 0.9079545454545455, 0.8185282908238053, 0.6293250141803743, 0.9237363287023352, 0.6571925754060325, 0.5313940092165899, 0.4710017574692443, 0.9081450653983353, 0.6268053148469093, 0.6156976744186047, 0.5625536787861437]\n",
      "cluster_accuracy_post_training_cycle_all_dataset : [0.95648061 0.96088596 0.94752046 0.94117647 0.94328358 0.90188679\n",
      " 0.81302834 0.60583255 0.89914271 0.6796875  0.52992278 0.44985104\n",
      " 0.64205703 0.65227934 0.63529412 0.54706163]\n",
      "mean_cluster_accuracy_during_training_cycle : 76.83%, post_traincycle_acc : 75.66%, total_acc : 76.13397753%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 75.66%\n",
      "accuracy_check 실행 시간: 20.884초\n",
      "\n",
      "\n",
      "epoch-12 loss : 0.02310914, loss_normal : 0.01625310, loss_coarse : 0.07653473, min_loss : 0.02308253, min_loss_normal : 0.01624302, min_loss_coarse : 0.07647287, wrong_element_sum : 14694668.00000000, same_data : 0.00%\n",
      "ae train 실행 시간: 96.336초, 전체 시작 시간 20250304_194401_700\n",
      "\n",
      "epoch-12 accuracy check\n",
      "k_means origin feature average accuracy : 82.24955320%, total [0.9746727376209448, 0.9733106189664963, 0.9700891573195284, 0.9530800230282096, 0.943108504398827, 0.9150568181818182, 0.801817648783348, 0.6625070901871809, 0.9488619568430388, 0.822215777262181, 0.5866935483870968, 0.5005858230814294, 0.9429250891795482, 0.8922588099364529, 0.673546511627907, 0.5991983967935872]\n",
      "kmeans average accuracy best : 77.50%, kmeans average accuracy : 75.81554224%, total [0.9593056346044394, 0.9622373651334469, 0.9513948806442335, 0.9369602763385146, 0.9419354838709677, 0.9113636363636364, 0.8355321020228672, 0.6469086783891095, 0.9198935855749335, 0.6774941995359629, 0.5365783410138248, 0.4794961921499707, 0.6774673008323424, 0.5935875216637782, 0.5558139534883721, 0.5445176066418551]\n",
      "cluster_accuracy_post_training_cycle_all_dataset : [0.95648061 0.96229972 0.94559461 0.93828351 0.94228856 0.90283019\n",
      " 0.81849826 0.61382879 0.91124559 0.71142578 0.52123552 0.45332671\n",
      " 0.66293279 0.64112512 0.61960784 0.52699474]\n",
      "mean_cluster_accuracy_during_training_cycle : 76.81%, post_traincycle_acc : 75.80%, total_acc : 76.20938687%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 75.66%\n",
      "accuracy_check 실행 시간: 21.118초\n",
      "\n",
      "\n",
      "epoch-13 loss : 0.02242642, loss_normal : 0.01609899, loss_coarse : 0.07586131, min_loss : 0.02242642, min_loss_normal : 0.01609899, min_loss_coarse : 0.07586131, wrong_element_sum : 14565372.00000000, same_data : 0.00%\n",
      "ae train 실행 시간: 94.074초, 전체 시작 시간 20250304_194401_700\n",
      "\n",
      "epoch-13 accuracy check\n",
      "k_means origin feature average accuracy : 82.25856323%, total [0.9746727376209448, 0.9733106189664963, 0.9700891573195284, 0.9530800230282096, 0.943108504398827, 0.9150568181818182, 0.801817648783348, 0.6625070901871809, 0.9488619568430388, 0.8216357308584686, 0.5866935483870968, 0.5005858230814294, 0.9429250891795482, 0.8922588099364529, 0.6747093023255814, 0.6000572573718866]\n",
      "kmeans average accuracy best : 77.50%, kmeans average accuracy : 77.42581991%, total [0.9595902105862265, 0.9613855763770585, 0.9548461317227495, 0.9401266551525619, 0.9416422287390029, 0.9136363636363637, 0.8185282908238053, 0.6429381735677822, 0.9388117055867573, 0.6566125290023201, 0.5417626728110599, 0.46690099589923845, 0.7193816884661117, 0.6811091854419411, 0.6462209302325581, 0.6046378471228171]\n",
      "cluster_accuracy_post_training_cycle_all_dataset : [0.95648061 0.96229972 0.95426095 0.94503375 0.94278607 0.90801887\n",
      " 0.82894083 0.61994356 0.91679274 0.70654297 0.56370656 0.49354518\n",
      " 0.7688391  0.70174588 0.66813725 0.59101768]\n",
      "mean_cluster_accuracy_during_training_cycle : 78.83%, post_traincycle_acc : 78.30%, total_acc : 78.51849959%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 75.66%\n",
      "accuracy_check 실행 시간: 20.981초\n",
      "\n",
      "\n",
      "epoch-14 loss : 0.02212259, loss_normal : 0.01605771, loss_coarse : 0.07569440, min_loss : 0.02212259, min_loss_normal : 0.01605771, min_loss_coarse : 0.07569440, wrong_element_sum : 14533326.00000000, same_data : 0.00%\n",
      "ae train 실행 시간: 96.282초, 전체 시작 시간 20250304_194401_700\n",
      "\n",
      "epoch-14 accuracy check\n",
      "k_means origin feature average accuracy : 82.26401620%, total [0.9746727376209448, 0.9733106189664963, 0.9700891573195284, 0.9530800230282096, 0.943108504398827, 0.9150568181818182, 0.801817648783348, 0.6622234826999432, 0.9488619568430388, 0.822215777262181, 0.5872695852534562, 0.5005858230814294, 0.9429250891795482, 0.8922588099364529, 0.6747093023255814, 0.6000572573718866]\n",
      "kmeans average accuracy best : 77.50%, kmeans average accuracy : 77.06200701%, total [0.9581673306772909, 0.9608177172061328, 0.9462180040264596, 0.9217040875071963, 0.9419354838709677, 0.9082386363636363, 0.8185282908238053, 0.6298922291548497, 0.9184156074490097, 0.6780742459396751, 0.5515552995391705, 0.46865846514352666, 0.746730083234245, 0.67157712305026, 0.6313953488372093, 0.5780131691955339]\n",
      "cluster_accuracy_post_training_cycle_all_dataset : [0.95600757 0.9594722  0.94896485 0.92960463 0.94328358 0.90707547\n",
      " 0.81849826 0.62841016 0.90872416 0.69873047 0.52750965 0.4612711\n",
      " 0.72657841 0.6813773  0.65931373 0.60009556]\n",
      "mean_cluster_accuracy_during_training_cycle : 78.36%, post_traincycle_acc : 77.22%, total_acc : 77.68677671%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 75.66%\n",
      "accuracy_check 실행 시간: 21.035초\n",
      "\n",
      "\n",
      "epoch-15 loss : 0.02206637, loss_normal : 0.01607024, loss_coarse : 0.07573585, min_loss : 0.02206637, min_loss_normal : 0.01605771, min_loss_coarse : 0.07569440, wrong_element_sum : 14541284.00000000, same_data : 0.00%\n",
      "ae train 실행 시간: 86.781초, 전체 시작 시간 20250304_194401_700\n",
      "\n",
      "epoch-15 accuracy check\n",
      "k_means origin feature average accuracy : 82.24594995%, total [0.9746727376209448, 0.9733106189664963, 0.9700891573195284, 0.9530800230282096, 0.943108504398827, 0.9150568181818182, 0.801817648783348, 0.6622234826999432, 0.9488619568430388, 0.822215777262181, 0.5866935483870968, 0.5002929115407148, 0.9429250891795482, 0.8922588099364529, 0.673546511627907, 0.5991983967935872]\n",
      "kmeans average accuracy best : 77.50%, kmeans average accuracy : 77.19239158%, total [0.9581673306772909, 0.9613855763770585, 0.9519700891573195, 0.9335060449050087, 0.9413489736070382, 0.9073863636363636, 0.8161829375549692, 0.6259217243335224, 0.9269878805793674, 0.6342807424593968, 0.5253456221198156, 0.4906268306971295, 0.7660523186682521, 0.6941074523396881, 0.6372093023255814, 0.5803034640709991]\n",
      "cluster_accuracy_post_training_cycle_all_dataset : [0.95742668 0.96229972 0.94944632 0.94165863 0.94427861 0.89858491\n",
      " 0.81601193 0.61571025 0.9183056  0.71142578 0.51447876 0.48808342\n",
      " 0.76272912 0.70271581 0.67352941 0.57525084]\n",
      "mean_cluster_accuracy_during_training_cycle : 78.60%, post_traincycle_acc : 77.70%, total_acc : 78.06795684%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 75.66%\n",
      "accuracy_check 실행 시간: 21.050초\n",
      "\n",
      "\n",
      "epoch-16 loss : 0.02194527, loss_normal : 0.01604345, loss_coarse : 0.07555907, min_loss : 0.02194527, min_loss_normal : 0.01604345, min_loss_coarse : 0.07555907, wrong_element_sum : 14507342.00000000, same_data : 0.00%\n",
      "ae train 실행 시간: 90.054초, 전체 시작 시간 20250304_194401_700\n",
      "\n",
      "epoch-16 accuracy check\n",
      "k_means origin feature average accuracy : 82.26218852%, total [0.9746727376209448, 0.9733106189664963, 0.9700891573195284, 0.9530800230282096, 0.943108504398827, 0.9150568181818182, 0.801817648783348, 0.6625070901871809, 0.9488619568430388, 0.822215777262181, 0.5866935483870968, 0.5005858230814294, 0.9429250891795482, 0.8922588099364529, 0.6747093023255814, 0.6000572573718866]\n",
      "kmeans average accuracy best : 77.50%, kmeans average accuracy : 75.53018678%, total [0.9581673306772909, 0.9616695059625213, 0.9508196721311475, 0.9314910765687968, 0.9422287390029326, 0.9071022727272727, 0.830841395485195, 0.6511627906976745, 0.9086609518179131, 0.605568445475638, 0.513536866359447, 0.4956063268892794, 0.6429845422116528, 0.6412478336221837, 0.5866279069767442, 0.5571142284569138]\n",
      "cluster_accuracy_post_training_cycle_all_dataset : [0.95695364 0.96182846 0.94463168 0.93539055 0.94378109 0.89622642\n",
      " 0.80905022 0.62605833 0.89561271 0.61035156 0.49710425 0.49205561\n",
      " 0.6104888  0.66828322 0.64705882 0.55613951]\n",
      "mean_cluster_accuracy_during_training_cycle : 76.06%, post_traincycle_acc : 75.32%, total_acc : 75.61966666%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 75.66%\n",
      "accuracy_check 실행 시간: 23.458초\n",
      "\n",
      "\n",
      "epoch-17 loss : 0.02180320, loss_normal : 0.01602781, loss_coarse : 0.07554638, min_loss : 0.02180320, min_loss_normal : 0.01602781, min_loss_coarse : 0.07554638, wrong_element_sum : 14504906.00000000, same_data : 0.00%\n",
      "ae train 실행 시간: 97.448초, 전체 시작 시간 20250304_194401_700\n",
      "\n",
      "epoch-17 accuracy check\n",
      "k_means origin feature average accuracy : 82.26582224%, total [0.9746727376209448, 0.9733106189664963, 0.9700891573195284, 0.9530800230282096, 0.943108504398827, 0.9150568181818182, 0.801817648783348, 0.6625070901871809, 0.9488619568430388, 0.822215777262181, 0.5866935483870968, 0.5005858230814294, 0.9429250891795482, 0.8922588099364529, 0.6752906976744186, 0.6000572573718866]\n",
      "kmeans average accuracy best : 77.50%, kmeans average accuracy : 76.89048015%, total [0.960728514513375, 0.9616695059625213, 0.9531205061834915, 0.9378238341968912, 0.9419354838709677, 0.9085227272727273, 0.8296687188507769, 0.6310266591038003, 0.9317174105823234, 0.6084686774941995, 0.5345622119815668, 0.48154657293497366, 0.7303804994054697, 0.6735990756787984, 0.6311046511627907, 0.5866017749785285]\n",
      "cluster_accuracy_post_training_cycle_all_dataset : [0.95931883 0.96229972 0.95426095 0.94021215 0.94228856 0.89716981\n",
      " 0.82396818 0.62229539 0.93040847 0.67285156 0.54295367 0.47567031\n",
      " 0.73167006 0.68962173 0.64901961 0.57763975]\n",
      "mean_cluster_accuracy_during_training_cycle : 77.80%, post_traincycle_acc : 77.32%, total_acc : 77.51193147%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 75.66%\n",
      "accuracy_check 실행 시간: 21.566초\n",
      "\n",
      "\n",
      "epoch-18 loss : 0.02144991, loss_normal : 0.01591340, loss_coarse : 0.07505609, min_loss : 0.02144991, min_loss_normal : 0.01591340, min_loss_coarse : 0.07505609, wrong_element_sum : 14410770.00000000, same_data : 0.00%\n",
      "ae train 실행 시간: 96.268초, 전체 시작 시간 20250304_194401_700\n",
      "\n",
      "epoch-18 accuracy check\n",
      "k_means origin feature average accuracy : 82.25315343%, total [0.9746727376209448, 0.9733106189664963, 0.9700891573195284, 0.9530800230282096, 0.943108504398827, 0.9150568181818182, 0.801817648783348, 0.6625070901871809, 0.9488619568430388, 0.822215777262181, 0.5872695852534562, 0.5005858230814294, 0.9429250891795482, 0.8922588099364529, 0.673546511627907, 0.5991983967935872]\n",
      "kmeans average accuracy best : 77.50%, kmeans average accuracy : 77.12735993%, total [0.958451906659078, 0.9619534355479841, 0.9522576934138626, 0.9320667818077144, 0.9419354838709677, 0.912784090909091, 0.8273233655819408, 0.6202495745887692, 0.9367425362104641, 0.6513921113689095, 0.5325460829493087, 0.4727592267135325, 0.7253269916765755, 0.6672443674176777, 0.6409883720930233, 0.606355568279416]\n",
      "cluster_accuracy_post_training_cycle_all_dataset : [0.95600757 0.96229972 0.95137217 0.93539055 0.94278607 0.90330189\n",
      " 0.83242168 0.60442145 0.92133132 0.70996094 0.53667954 0.45630586\n",
      " 0.73268839 0.68816683 0.67598039 0.59961777]\n",
      "mean_cluster_accuracy_during_training_cycle : 79.29%, post_traincycle_acc : 77.55%, total_acc : 78.26705044%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 75.66%\n",
      "accuracy_check 실행 시간: 20.474초\n",
      "\n",
      "\n",
      "epoch-19 loss : 0.02112463, loss_normal : 0.01582987, loss_coarse : 0.07470081, min_loss : 0.02112463, min_loss_normal : 0.01582987, min_loss_coarse : 0.07470081, wrong_element_sum : 14342556.00000000, same_data : 0.00%\n",
      "ae train 실행 시간: 97.156초, 전체 시작 시간 20250304_194401_700\n",
      "\n",
      "epoch-19 accuracy check\n",
      "k_means origin feature average accuracy : 82.26034409%, total [0.9746727376209448, 0.9733106189664963, 0.9700891573195284, 0.9530800230282096, 0.943108504398827, 0.9150568181818182, 0.801817648783348, 0.6625070901871809, 0.9488619568430388, 0.822215777262181, 0.5866935483870968, 0.5005858230814294, 0.9429250891795482, 0.8922588099364529, 0.6741279069767442, 0.6003435442313197]\n",
      "save model\n",
      "kmeans average accuracy best : 77.94%, kmeans average accuracy : 77.93848306%, total [0.9598747865680136, 0.9611016467915957, 0.9508196721311475, 0.931203223949338, 0.9425219941348973, 0.9110795454545455, 0.8085605394312518, 0.6111741349971639, 0.9320130062075082, 0.6493619489559165, 0.5221774193548387, 0.4718804920913884, 0.8293697978596909, 0.7079722703639515, 0.6546511627906977, 0.6263956484397366]\n",
      "cluster_accuracy_post_training_cycle_all_dataset : [0.95742668 0.96135721 0.9523351  0.92767599 0.94278607 0.90849057\n",
      " 0.82446544 0.60818438 0.92284418 0.68945312 0.5265444  0.48460775\n",
      " 0.79582485 0.72308438 0.69803922 0.61060678]\n",
      "mean_cluster_accuracy_during_training_cycle : 79.51%, post_traincycle_acc : 78.34%, total_acc : 78.81456128%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 78.34%\n",
      "accuracy_check 실행 시간: 21.506초\n",
      "\n",
      "\n",
      "epoch-20 loss : 0.02112530, loss_normal : 0.01586524, loss_coarse : 0.07481351, min_loss : 0.02112463, min_loss_normal : 0.01582987, min_loss_coarse : 0.07470081, wrong_element_sum : 14364194.00000000, same_data : 0.00%\n",
      "ae train 실행 시간: 94.419초, 전체 시작 시간 20250304_194401_700\n",
      "\n",
      "epoch-20 accuracy check\n",
      "k_means origin feature average accuracy : 82.24958206%, total [0.9746727376209448, 0.9733106189664963, 0.9700891573195284, 0.9530800230282096, 0.943108504398827, 0.9150568181818182, 0.8015244796247435, 0.6622234826999432, 0.9488619568430388, 0.822215777262181, 0.5866935483870968, 0.5005858230814294, 0.9429250891795482, 0.8922588099364529, 0.6741279069767442, 0.5991983967935872]\n",
      "kmeans average accuracy best : 77.94%, kmeans average accuracy : 77.03929549%, total [0.9587364826408651, 0.9611016467915957, 0.9499568593615185, 0.9260218767990789, 0.9436950146627566, 0.9181818181818182, 0.8390501319261213, 0.6398184912081679, 0.9323086018326929, 0.6334106728538283, 0.5273617511520737, 0.47451669595782076, 0.6920332936979786, 0.6724436741767764, 0.6409883720930233, 0.6166618952190095]\n",
      "cluster_accuracy_post_training_cycle_all_dataset : [0.95837275 0.9604147  0.95185364 0.92960463 0.94527363 0.91603774\n",
      " 0.86524117 0.63311383 0.92133132 0.65332031 0.52027027 0.48857994\n",
      " 0.69297352 0.69350145 0.66666667 0.61777353]\n",
      "mean_cluster_accuracy_during_training_cycle : 78.54%, post_traincycle_acc : 77.59%, total_acc : 77.97489569%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 78.34%\n",
      "accuracy_check 실행 시간: 20.624초\n",
      "\n",
      "\n",
      "epoch-21 loss : 0.02097700, loss_normal : 0.01579644, loss_coarse : 0.07451832, min_loss : 0.02097700, min_loss_normal : 0.01579644, min_loss_coarse : 0.07451832, wrong_element_sum : 14307518.00000000, same_data : 0.00%\n",
      "ae train 실행 시간: 95.025초, 전체 시작 시간 20250304_194401_700\n",
      "\n",
      "epoch-21 accuracy check\n",
      "k_means origin feature average accuracy : 82.25141437%, total [0.9746727376209448, 0.9733106189664963, 0.9700891573195284, 0.9530800230282096, 0.943108504398827, 0.9150568181818182, 0.801817648783348, 0.6622234826999432, 0.9488619568430388, 0.822215777262181, 0.5866935483870968, 0.5005858230814294, 0.9429250891795482, 0.8922588099364529, 0.6741279069767442, 0.5991983967935872]\n",
      "kmeans average accuracy best : 77.94%, kmeans average accuracy : 77.14393682%, total [0.9598747865680136, 0.9602498580352072, 0.9516824849007766, 0.9349453080023028, 0.943108504398827, 0.9116477272727272, 0.8094400469070654, 0.608621667612025, 0.9411764705882353, 0.648491879350348, 0.5388824884792627, 0.45899238429994144, 0.7559453032104637, 0.6851530906990179, 0.645639534883721, 0.5891783567134269]\n",
      "cluster_accuracy_post_training_cycle_all_dataset : [0.95695364 0.9594722  0.95329803 0.92815815 0.94328358 0.91132075\n",
      " 0.81153655 0.60065851 0.93444276 0.71142578 0.51206564 0.46276068\n",
      " 0.71639511 0.69592629 0.67009804 0.58528428]\n",
      "mean_cluster_accuracy_during_training_cycle : 79.08%, post_traincycle_acc : 77.21%, total_acc : 77.96849258%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 78.34%\n",
      "accuracy_check 실행 시간: 21.465초\n",
      "\n",
      "\n",
      "epoch-22 loss : 0.02083371, loss_normal : 0.01576733, loss_coarse : 0.07446400, min_loss : 0.02083371, min_loss_normal : 0.01576733, min_loss_coarse : 0.07446400, wrong_element_sum : 14297088.00000000, same_data : 0.00%\n",
      "ae train 실행 시간: 96.397초, 전체 시작 시간 20250304_194401_700\n",
      "\n",
      "epoch-22 accuracy check\n",
      "k_means origin feature average accuracy : 82.24602975%, total [0.9746727376209448, 0.9733106189664963, 0.9700891573195284, 0.9530800230282096, 0.943108504398827, 0.9150568181818182, 0.801817648783348, 0.6625070901871809, 0.9488619568430388, 0.822215777262181, 0.5866935483870968, 0.5005858230814294, 0.9429250891795482, 0.8922588099364529, 0.6741279069767442, 0.5980532493558546]\n",
      "kmeans average accuracy best : 77.94%, kmeans average accuracy : 77.84786494%, total [0.9593056346044394, 0.9616695059625213, 0.9519700891573195, 0.9337938975244675, 0.9419354838709677, 0.9142045454545454, 0.8246848431545002, 0.6137266023823029, 0.9328997930830624, 0.6316705336426914, 0.5224654377880185, 0.46250732278851786, 0.8148038049940547, 0.720103986135182, 0.6569767441860465, 0.6129401660463785]\n",
      "cluster_accuracy_post_training_cycle_all_dataset : [0.95837275 0.96088596 0.9523351  0.93828351 0.94278607 0.90707547\n",
      " 0.8463451  0.60536218 0.92284418 0.63183594 0.53764479 0.49404171\n",
      " 0.77240326 0.73811833 0.69264706 0.60630674]\n",
      "mean_cluster_accuracy_during_training_cycle : 79.42%, post_traincycle_acc : 78.17%, total_acc : 78.68096134%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 78.34%\n",
      "accuracy_check 실행 시간: 21.037초\n",
      "\n",
      "\n",
      "epoch-23 loss : 0.02069211, loss_normal : 0.01575234, loss_coarse : 0.07437422, min_loss : 0.02069211, min_loss_normal : 0.01575234, min_loss_coarse : 0.07437422, wrong_element_sum : 14279850.00000000, same_data : 0.00%\n",
      "ae train 실행 시간: 94.644초, 전체 시작 시간 20250304_194401_700\n",
      "\n",
      "epoch-23 accuracy check\n",
      "k_means origin feature average accuracy : 82.25134249%, total [0.9746727376209448, 0.9733106189664963, 0.9700891573195284, 0.9530800230282096, 0.943108504398827, 0.9150568181818182, 0.801817648783348, 0.6625070901871809, 0.9488619568430388, 0.822215777262181, 0.5866935483870968, 0.5005858230814294, 0.9429250891795482, 0.8922588099364529, 0.673546511627907, 0.5994846836530203]\n",
      "save model\n",
      "kmeans average accuracy best : 77.96%, kmeans average accuracy : 77.96416711%, total [0.9601593625498008, 0.9625212947189097, 0.9534081104400345, 0.9358088658606794, 0.9425219941348973, 0.9133522727272727, 0.8249780123131046, 0.6057855927396484, 0.9272834762045522, 0.6310904872389791, 0.5625, 0.4797891036906854, 0.7931034482758621, 0.7001733102253033, 0.6659883720930233, 0.61580303464071]\n",
      "cluster_accuracy_post_training_cycle_all_dataset : [0.95789972 0.96135721 0.9523351  0.93972999 0.94278607 0.90518868\n",
      " 0.82496271 0.59830668 0.91729702 0.64160156 0.5492278  0.50496524\n",
      " 0.75916497 0.72017459 0.69068627 0.60487339]\n",
      "mean_cluster_accuracy_during_training_cycle : 79.37%, post_traincycle_acc : 77.94%, total_acc : 78.52053888%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 77.94%\n",
      "accuracy_check 실행 시간: 21.377초\n",
      "\n",
      "\n",
      "epoch-24 loss : 0.02066107, loss_normal : 0.01571559, loss_coarse : 0.07426926, min_loss : 0.02066107, min_loss_normal : 0.01571559, min_loss_coarse : 0.07426926, wrong_element_sum : 14259698.00000000, same_data : 0.00%\n",
      "ae train 실행 시간: 93.621초, 전체 시작 시간 20250304_194401_700\n",
      "\n",
      "epoch-24 accuracy check\n",
      "k_means origin feature average accuracy : 82.25853805%, total [0.9746727376209448, 0.9733106189664963, 0.9700891573195284, 0.9530800230282096, 0.943108504398827, 0.9150568181818182, 0.801817648783348, 0.6622234826999432, 0.9488619568430388, 0.822215777262181, 0.5872695852534562, 0.5005858230814294, 0.9429250891795482, 0.8922588099364529, 0.673546511627907, 0.6003435442313197]\n",
      "kmeans average accuracy best : 77.96%, kmeans average accuracy : 77.63063398%, total [0.9581673306772909, 0.9613855763770585, 0.9528329019269485, 0.9355210132412205, 0.9434017595307918, 0.9176136363636364, 0.8150102609205512, 0.6171298922291548, 0.9355601537097251, 0.7117169373549884, 0.5478110599078341, 0.47627416520210897, 0.6792508917954816, 0.6886192952050838, 0.6633720930232558, 0.6172344689378757]\n",
      "cluster_accuracy_post_training_cycle_all_dataset : [0.95695364 0.96229972 0.95522388 0.93828351 0.94328358 0.91367925\n",
      " 0.83689707 0.61853246 0.92839133 0.73681641 0.55791506 0.50893744\n",
      " 0.66904277 0.68331717 0.68529412 0.59483994]\n",
      "mean_cluster_accuracy_during_training_cycle : 78.56%, post_traincycle_acc : 78.06%, total_acc : 78.26030901%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 77.94%\n",
      "accuracy_check 실행 시간: 27.245초\n",
      "\n",
      "\n",
      "epoch-25 loss : 0.02071845, loss_normal : 0.01573410, loss_coarse : 0.07430259, min_loss : 0.02066107, min_loss_normal : 0.01571559, min_loss_coarse : 0.07426926, wrong_element_sum : 14266098.00000000, same_data : 0.00%\n",
      "ae train 실행 시간: 94.897초, 전체 시작 시간 20250304_194401_700\n",
      "\n",
      "epoch-25 accuracy check\n",
      "k_means origin feature average accuracy : 82.25313308%, total [0.9746727376209448, 0.9733106189664963, 0.9700891573195284, 0.9530800230282096, 0.943108504398827, 0.9150568181818182, 0.8015244796247435, 0.6622234826999432, 0.9488619568430388, 0.822215777262181, 0.5866935483870968, 0.5005858230814294, 0.9429250891795482, 0.8922588099364529, 0.6738372093023256, 0.6000572573718866]\n",
      "save model\n",
      "kmeans average accuracy best : 78.43%, kmeans average accuracy : 78.42717245%, total [0.9598747865680136, 0.9616695059625213, 0.9513948806442335, 0.9340817501439264, 0.9428152492668622, 0.9119318181818182, 0.8044561712107886, 0.5924560408394781, 0.9396984924623115, 0.6879350348027842, 0.5397465437788018, 0.46777973052138255, 0.8608799048751486, 0.707105719237435, 0.6758720930232558, 0.6106498711709133]\n",
      "cluster_accuracy_post_training_cycle_all_dataset : [0.95837275 0.96277097 0.95281656 0.93683703 0.94427861 0.90896226\n",
      " 0.81551467 0.59924741 0.92839133 0.73876953 0.56274131 0.43346574\n",
      " 0.84572301 0.73084384 0.71617647 0.61395127]\n",
      "mean_cluster_accuracy_during_training_cycle : 79.53%, post_traincycle_acc : 79.06%, total_acc : 79.24815488%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 79.06%\n",
      "accuracy_check 실행 시간: 21.215초\n",
      "\n",
      "\n",
      "epoch-26 loss : 0.02052206, loss_normal : 0.01569461, loss_coarse : 0.07403155, min_loss : 0.02052206, min_loss_normal : 0.01569461, min_loss_coarse : 0.07403155, wrong_element_sum : 14214058.00000000, same_data : 0.00%\n",
      "ae train 실행 시간: 89.428초, 전체 시작 시간 20250304_194401_700\n",
      "\n",
      "epoch-26 accuracy check\n",
      "k_means origin feature average accuracy : 82.25678225%, total [0.9746727376209448, 0.9733106189664963, 0.9700891573195284, 0.9530800230282096, 0.943108504398827, 0.9150568181818182, 0.801817648783348, 0.6622234826999432, 0.9488619568430388, 0.822215777262181, 0.5866935483870968, 0.5005858230814294, 0.9429250891795482, 0.8922588099364529, 0.6741279069767442, 0.6000572573718866]\n",
      "kmeans average accuracy best : 78.43%, kmeans average accuracy : 77.48227589%, total [0.9618668184405236, 0.9613855763770585, 0.9513948806442335, 0.9317789291882557, 0.9434017595307918, 0.9059659090909091, 0.7971269422456757, 0.5910380034032898, 0.9370381318356489, 0.6589327146171694, 0.5397465437788018, 0.4874048037492677, 0.753269916765755, 0.6943963027151935, 0.6694767441860465, 0.6129401660463785]\n",
      "cluster_accuracy_post_training_cycle_all_dataset : [0.95931883 0.96277097 0.95137217 0.93394407 0.94278607 0.90424528\n",
      " 0.81352561 0.60395108 0.92586989 0.73291016 0.50916988 0.49751738\n",
      " 0.73472505 0.72114452 0.70833333 0.61442905]\n",
      "mean_cluster_accuracy_during_training_cycle : 79.01%, post_traincycle_acc : 78.23%, total_acc : 78.54632165%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 79.06%\n",
      "accuracy_check 실행 시간: 21.198초\n",
      "\n",
      "\n",
      "epoch-27 loss : 0.02017420, loss_normal : 0.01558650, loss_coarse : 0.07364529, min_loss : 0.02017420, min_loss_normal : 0.01558650, min_loss_coarse : 0.07364529, wrong_element_sum : 14139896.00000000, same_data : 0.00%\n",
      "ae train 실행 시간: 92.752초, 전체 시작 시간 20250304_194401_700\n",
      "\n",
      "epoch-27 accuracy check\n",
      "k_means origin feature average accuracy : 82.24964802%, total [0.9746727376209448, 0.9733106189664963, 0.9700891573195284, 0.9530800230282096, 0.943108504398827, 0.9150568181818182, 0.8015244796247435, 0.6625070901871809, 0.9488619568430388, 0.822215777262181, 0.5866935483870968, 0.5005858230814294, 0.9429250891795482, 0.8922588099364529, 0.675, 0.5980532493558546]\n",
      "kmeans average accuracy best : 78.43%, kmeans average accuracy : 77.80272672%, total [0.9604439385315879, 0.9613855763770585, 0.9539833189531205, 0.9375359815774323, 0.9436950146627566, 0.9073863636363636, 0.8141307534447376, 0.5794100964265456, 0.9331953887082471, 0.6879350348027842, 0.5432027649769585, 0.47012302284710017, 0.8046967895362663, 0.6984402079722704, 0.6656976744186046, 0.5871743486973948]\n",
      "cluster_accuracy_post_training_cycle_all_dataset : [0.95931883 0.96088596 0.95426095 0.93972999 0.94427861 0.90707547\n",
      " 0.83938339 0.60583255 0.91578417 0.7578125  0.54295367 0.52780536\n",
      " 0.84674134 0.7114452  0.69166667 0.58528428]\n",
      "mean_cluster_accuracy_during_training_cycle : 79.76%, post_traincycle_acc : 79.31%, total_acc : 79.49542075%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 79.06%\n",
      "accuracy_check 실행 시간: 21.654초\n",
      "\n",
      "\n",
      "epoch-28 loss : 0.02025407, loss_normal : 0.01562259, loss_coarse : 0.07381190, min_loss : 0.02017420, min_loss_normal : 0.01558650, min_loss_coarse : 0.07364529, wrong_element_sum : 14171886.00000000, same_data : 0.00%\n",
      "ae train 실행 시간: 95.244초, 전체 시작 시간 20250304_194401_700\n",
      "\n",
      "epoch-28 accuracy check\n",
      "k_means origin feature average accuracy : 82.24959580%, total [0.9746727376209448, 0.9733106189664963, 0.9700891573195284, 0.9530800230282096, 0.943108504398827, 0.9150568181818182, 0.8015244796247435, 0.6622234826999432, 0.9488619568430388, 0.822215777262181, 0.5866935483870968, 0.5002929115407148, 0.9429250891795482, 0.8922588099364529, 0.6747093023255814, 0.598912109934154]\n",
      "kmeans average accuracy best : 78.43%, kmeans average accuracy : 77.29775274%, total [0.9593056346044394, 0.9616695059625213, 0.9505320678746045, 0.9294761082325849, 0.9422287390029326, 0.9113636363636364, 0.8117854001759015, 0.5995462280204198, 0.9308306237067692, 0.509860788863109, 0.5357142857142857, 0.47598125366139427, 0.8252080856123662, 0.7166377816291161, 0.6811046511627907, 0.6263956484397366]\n",
      "cluster_accuracy_post_training_cycle_all_dataset : [0.95931883 0.96182846 0.95040924 0.93394407 0.94278607 0.90801887\n",
      " 0.83441074 0.59454374 0.91729702 0.54736328 0.47972973 0.46375372\n",
      " 0.8503055  0.7356935  0.70833333 0.61968466]\n",
      "mean_cluster_accuracy_during_training_cycle : 79.32%, post_traincycle_acc : 77.55%, total_acc : 78.26755993%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 79.06%\n",
      "accuracy_check 실행 시간: 21.344초\n",
      "\n",
      "\n",
      "epoch-29 loss : 0.01996933, loss_normal : 0.01555373, loss_coarse : 0.07354562, min_loss : 0.01996933, min_loss_normal : 0.01555373, min_loss_coarse : 0.07354562, wrong_element_sum : 14120760.00000000, same_data : 0.00%\n",
      "ae train 실행 시간: 96.722초, 전체 시작 시간 20250304_194401_700\n",
      "\n",
      "epoch-29 accuracy check\n",
      "k_means origin feature average accuracy : 82.25859319%, total [0.9746727376209448, 0.9733106189664963, 0.9700891573195284, 0.9530800230282096, 0.943108504398827, 0.9150568181818182, 0.801817648783348, 0.6622234826999432, 0.9488619568430388, 0.822215777262181, 0.5872695852534562, 0.5005858230814294, 0.9429250891795482, 0.8922588099364529, 0.6741279069767442, 0.5997709705124534]\n",
      "kmeans average accuracy best : 78.43%, kmeans average accuracy : 77.79595183%, total [0.9632896983494593, 0.9628052243043725, 0.9539833189531205, 0.9409902130109384, 0.9448680351906158, 0.9053977272727273, 0.7757255936675461, 0.5717526942711287, 0.9358557493349099, 0.693445475638051, 0.5216013824884793, 0.44786174575278265, 0.8192627824019025, 0.7094165222414789, 0.6741279069767442, 0.6269682221586029]\n",
      "cluster_accuracy_post_training_cycle_all_dataset : [0.96073794 0.96371348 0.95377949 0.93876567 0.94477612 0.90235849\n",
      " 0.83689707 0.58137347 0.92839133 0.73730469 0.53185328 0.4612711\n",
      " 0.79582485 0.72308438 0.70147059 0.61060678]\n",
      "mean_cluster_accuracy_during_training_cycle : 78.98%, post_traincycle_acc : 78.58%, total_acc : 78.73513528%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 79.06%\n",
      "accuracy_check 실행 시간: 20.833초\n",
      "\n",
      "\n",
      "epoch-30 loss : 0.01990225, loss_normal : 0.01554883, loss_coarse : 0.07353271, min_loss : 0.01990225, min_loss_normal : 0.01554883, min_loss_coarse : 0.07353271, wrong_element_sum : 14118280.00000000, same_data : 0.00%\n",
      "ae train 실행 시간: 98.047초, 전체 시작 시간 20250304_194401_700\n",
      "\n",
      "epoch-30 accuracy check\n",
      "k_means origin feature average accuracy : 82.26218389%, total [0.9746727376209448, 0.9733106189664963, 0.9700891573195284, 0.9530800230282096, 0.943108504398827, 0.9150568181818182, 0.8015244796247435, 0.6622234826999432, 0.9488619568430388, 0.822215777262181, 0.5872695852534562, 0.5005858230814294, 0.9429250891795482, 0.8922588099364529, 0.6747093023255814, 0.6000572573718866]\n",
      "save model\n",
      "kmeans average accuracy best : 78.81%, kmeans average accuracy : 78.80623705%, total [0.960728514513375, 0.9613855763770585, 0.9542709232096636, 0.9424294761082326, 0.9434017595307918, 0.9133522727272727, 0.8161829375549692, 0.5663641520136131, 0.9388117055867573, 0.6975058004640371, 0.5368663594470046, 0.4844756883421207, 0.8546373365041617, 0.729636048526863, 0.6822674418604651, 0.6266819352991698]\n",
      "cluster_accuracy_post_training_cycle_all_dataset : [0.95837275 0.96135721 0.95426095 0.94117647 0.94378109 0.90660377\n",
      " 0.83689707 0.57902164 0.92738275 0.75927734 0.57432432 0.51489573\n",
      " 0.83044807 0.7356935  0.71323529 0.6043956 ]\n",
      "mean_cluster_accuracy_during_training_cycle : 80.56%, post_traincycle_acc : 79.63%, total_acc : 80.01114905%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 79.63%\n",
      "accuracy_check 실행 시간: 21.238초\n",
      "\n",
      "\n",
      "epoch-31 loss : 0.01994599, loss_normal : 0.01555241, loss_coarse : 0.07355302, min_loss : 0.01990225, min_loss_normal : 0.01554883, min_loss_coarse : 0.07353271, wrong_element_sum : 14122180.00000000, same_data : 0.00%\n",
      "ae train 실행 시간: 97.343초, 전체 시작 시간 20250304_194401_700\n",
      "\n",
      "epoch-31 accuracy check\n",
      "k_means origin feature average accuracy : 82.26219154%, total [0.9746727376209448, 0.9733106189664963, 0.9700891573195284, 0.9530800230282096, 0.943108504398827, 0.915340909090909, 0.801817648783348, 0.6622234826999432, 0.9488619568430388, 0.822215777262181, 0.5866935483870968, 0.5005858230814294, 0.9429250891795482, 0.8922588099364529, 0.6747093023255814, 0.6000572573718866]\n",
      "save model\n",
      "kmeans average accuracy best : 79.71%, kmeans average accuracy : 79.71445335%, total [0.9595902105862265, 0.9622373651334469, 0.9548461317227495, 0.9375359815774323, 0.9442815249266863, 0.912784090909091, 0.8053356786866022, 0.5745887691435054, 0.9417676618386048, 0.7824825986078886, 0.5748847926267281, 0.4862331575864089, 0.8570154577883472, 0.7299248989023686, 0.6886627906976744, 0.64214142570856]\n",
      "cluster_accuracy_post_training_cycle_all_dataset : [0.95884579 0.96135721 0.95618681 0.93731919 0.94477612 0.90754717\n",
      " 0.84733963 0.60395108 0.92687847 0.77929688 0.60086873 0.5387289\n",
      " 0.83401222 0.73375364 0.71617647 0.59770664]\n",
      "mean_cluster_accuracy_during_training_cycle : 80.94%, post_traincycle_acc : 80.28%, total_acc : 80.54456627%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 80.28%\n",
      "accuracy_check 실행 시간: 27.867초\n",
      "\n",
      "\n",
      "epoch-32 loss : 0.01987298, loss_normal : 0.01556215, loss_coarse : 0.07356015, min_loss : 0.01987298, min_loss_normal : 0.01554883, min_loss_coarse : 0.07353271, wrong_element_sum : 14123550.00000000, same_data : 0.00%\n",
      "ae train 실행 시간: 95.523초, 전체 시작 시간 20250304_194401_700\n",
      "\n",
      "epoch-32 accuracy check\n",
      "k_means origin feature average accuracy : 82.25857997%, total [0.9746727376209448, 0.9733106189664963, 0.9700891573195284, 0.9530800230282096, 0.943108504398827, 0.9150568181818182, 0.801817648783348, 0.6622234826999432, 0.9488619568430388, 0.8216357308584686, 0.5866935483870968, 0.5005858230814294, 0.9429250891795482, 0.8922588099364529, 0.6747093023255814, 0.6003435442313197]\n",
      "save model\n",
      "kmeans average accuracy best : 79.73%, kmeans average accuracy : 79.72784250%, total [0.9610130904951623, 0.9633730834752982, 0.9536957146965775, 0.941565918249856, 0.943108504398827, 0.9176136363636364, 0.819994136616828, 0.5726035167328417, 0.9411764705882353, 0.8196055684454756, 0.5578917050691244, 0.471294669009959, 0.9304399524375743, 0.6932409012131716, 0.670639534883721, 0.5991983967935872]\n",
      "cluster_accuracy_post_training_cycle_all_dataset : [0.9602649  0.96277097 0.95522388 0.93442623 0.94378109 0.91650943\n",
      " 0.84435604 0.60959548 0.93192133 0.83300781 0.60617761 0.51986097\n",
      " 0.90274949 0.7129001  0.70098039 0.58002867]\n",
      "mean_cluster_accuracy_during_training_cycle : 81.56%, post_traincycle_acc : 80.72%, total_acc : 81.05753505%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 80.72%\n",
      "accuracy_check 실행 시간: 20.676초\n",
      "\n",
      "\n",
      "epoch-33 loss : 0.01978764, loss_normal : 0.01555853, loss_coarse : 0.07356475, min_loss : 0.01978764, min_loss_normal : 0.01554883, min_loss_coarse : 0.07353271, wrong_element_sum : 14124432.00000000, same_data : 0.00%\n",
      "ae train 실행 시간: 97.689초, 전체 시작 시간 20250304_194401_700\n",
      "\n",
      "epoch-33 accuracy check\n",
      "k_means origin feature average accuracy : 82.24778065%, total [0.9746727376209448, 0.9733106189664963, 0.9700891573195284, 0.9530800230282096, 0.943108504398827, 0.9150568181818182, 0.801817648783348, 0.6622234826999432, 0.9488619568430388, 0.822215777262181, 0.5866935483870968, 0.5005858230814294, 0.9429250891795482, 0.8922588099364529, 0.673546511627907, 0.5991983967935872]\n",
      "kmeans average accuracy best : 79.73%, kmeans average accuracy : 79.45639381%, total [0.9615822424587365, 0.9628052243043725, 0.9539833189531205, 0.9424294761082326, 0.9439882697947214, 0.9144886363636363, 0.820580474934037, 0.6029495178672717, 0.9337865799586166, 0.7114269141531323, 0.5400345622119815, 0.46192149970708846, 0.9215219976218787, 0.7322357019064125, 0.6857558139534884, 0.6235327798454051]\n",
      "cluster_accuracy_post_training_cycle_all_dataset : [0.95979186 0.96277097 0.95426095 0.93972999 0.94328358 0.91226415\n",
      " 0.84336151 0.61100659 0.91477559 0.75439453 0.47442085 0.4980139\n",
      " 0.88645621 0.73617847 0.71911765 0.6043956 ]\n",
      "mean_cluster_accuracy_during_training_cycle : 80.50%, post_traincycle_acc : 79.46%, total_acc : 79.88633023%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 80.72%\n",
      "accuracy_check 실행 시간: 21.508초\n",
      "\n",
      "\n",
      "epoch-34 loss : 0.01938113, loss_normal : 0.01545694, loss_coarse : 0.07311447, min_loss : 0.01938113, min_loss_normal : 0.01545694, min_loss_coarse : 0.07311447, wrong_element_sum : 14037978.00000000, same_data : 0.00%\n",
      "ae train 실행 시간: 94.788초, 전체 시작 시간 20250304_194401_700\n",
      "\n",
      "epoch-34 accuracy check\n",
      "k_means origin feature average accuracy : 82.24599626%, total [0.9746727376209448, 0.9733106189664963, 0.9700891573195284, 0.9530800230282096, 0.943108504398827, 0.9150568181818182, 0.801817648783348, 0.6625070901871809, 0.9488619568430388, 0.822215777262181, 0.5872695852534562, 0.5005858230814294, 0.9429250891795482, 0.8922588099364529, 0.673546511627907, 0.5980532493558546]\n",
      "kmeans average accuracy best : 79.73%, kmeans average accuracy : 79.07466164%, total [0.9610130904951623, 0.9633730834752982, 0.9539833189531205, 0.9389752446747266, 0.9416422287390029, 0.9142045454545454, 0.8255643506303136, 0.6117413499716392, 0.9331953887082471, 0.732308584686775, 0.5892857142857143, 0.5035149384885764, 0.7987514863258026, 0.7097053726169844, 0.6694767441860465, 0.6052104208416834]\n",
      "cluster_accuracy_post_training_cycle_all_dataset : [0.95884579 0.96229972 0.95522388 0.94310511 0.94228856 0.90943396\n",
      " 0.8165092  0.61523989 0.92788704 0.76904297 0.53426641 0.51142006\n",
      " 0.85183299 0.71629486 0.7        0.64261825]\n",
      "mean_cluster_accuracy_during_training_cycle : 80.66%, post_traincycle_acc : 79.73%, total_acc : 80.10648880%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 80.72%\n",
      "accuracy_check 실행 시간: 21.816초\n",
      "\n",
      "\n",
      "epoch-35 loss : 0.01944664, loss_normal : 0.01544980, loss_coarse : 0.07312869, min_loss : 0.01938113, min_loss_normal : 0.01544980, min_loss_coarse : 0.07311447, wrong_element_sum : 14040708.00000000, same_data : 0.00%\n",
      "ae train 실행 시간: 95.237초, 전체 시작 시간 20250304_194401_700\n",
      "\n",
      "epoch-35 accuracy check\n",
      "k_means origin feature average accuracy : 82.24237097%, total [0.9746727376209448, 0.9733106189664963, 0.9700891573195284, 0.9530800230282096, 0.943108504398827, 0.9150568181818182, 0.801817648783348, 0.6625070901871809, 0.9488619568430388, 0.8216357308584686, 0.5872695852534562, 0.5005858230814294, 0.9429250891795482, 0.8922588099364529, 0.673546511627907, 0.5980532493558546]\n",
      "kmeans average accuracy best : 79.73%, kmeans average accuracy : 78.63617347%, total [0.960728514513375, 0.9619534355479841, 0.9534081104400345, 0.9412780656303973, 0.944574780058651, 0.9193181818181818, 0.8197009674582234, 0.6094724900737379, 0.9328997930830624, 0.7004060324825986, 0.5388824884792627, 0.45635618043350906, 0.7705112960760999, 0.7316580011554015, 0.6953488372093023, 0.6452905811623246]\n",
      "cluster_accuracy_post_training_cycle_all_dataset : [0.95884579 0.96277097 0.9523351  0.93780135 0.94527363 0.91462264\n",
      " 0.82943809 0.62041392 0.92385275 0.67138672 0.49951737 0.46425025\n",
      " 0.73523422 0.75024248 0.71813725 0.63162924]\n",
      "mean_cluster_accuracy_during_training_cycle : 79.78%, post_traincycle_acc : 78.22%, total_acc : 78.85909803%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 80.72%\n",
      "accuracy_check 실행 시간: 22.904초\n",
      "\n",
      "\n",
      "epoch-36 loss : 0.01955528, loss_normal : 0.01552140, loss_coarse : 0.07333176, min_loss : 0.01938113, min_loss_normal : 0.01544980, min_loss_coarse : 0.07311447, wrong_element_sum : 14079698.00000000, same_data : 0.00%\n",
      "ae train 실행 시간: 93.595초, 전체 시작 시간 20250304_194401_700\n",
      "\n",
      "epoch-36 accuracy check\n",
      "k_means origin feature average accuracy : 82.24947330%, total [0.9746727376209448, 0.9733106189664963, 0.9700891573195284, 0.9530800230282096, 0.943108504398827, 0.9150568181818182, 0.801817648783348, 0.6622234826999432, 0.9488619568430388, 0.822215777262181, 0.5866935483870968, 0.4997070884592853, 0.9429250891795482, 0.8922588099364529, 0.6738372093023256, 0.6000572573718866]\n",
      "kmeans average accuracy best : 79.73%, kmeans average accuracy : 78.86113028%, total [0.960728514513375, 0.9616695059625213, 0.9531205061834915, 0.934657455382844, 0.9436950146627566, 0.9139204545454546, 0.8402228085605394, 0.5927396483267158, 0.9361513449600946, 0.7038863109048724, 0.5198732718894009, 0.44815465729349735, 0.8451248513674198, 0.7385904101675332, 0.6997093023255814, 0.6255367878614372]\n",
      "cluster_accuracy_post_training_cycle_all_dataset : [0.9602649  0.96088596 0.95329803 0.93490839 0.94477612 0.90707547\n",
      " 0.85131775 0.61147695 0.92687847 0.75585938 0.48793436 0.51539225\n",
      " 0.84623218 0.75557711 0.73382353 0.61156235]\n",
      "mean_cluster_accuracy_during_training_cycle : 80.31%, post_traincycle_acc : 79.73%, total_acc : 79.96511888%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 80.72%\n",
      "accuracy_check 실행 시간: 20.581초\n",
      "\n",
      "\n",
      "epoch-37 loss : 0.01942004, loss_normal : 0.01547116, loss_coarse : 0.07315010, min_loss : 0.01938113, min_loss_normal : 0.01544980, min_loss_coarse : 0.07311447, wrong_element_sum : 14044820.00000000, same_data : 0.00%\n",
      "ae train 실행 시간: 96.179초, 전체 시작 시간 20250304_194401_700\n",
      "\n",
      "epoch-37 accuracy check\n",
      "k_means origin feature average accuracy : 82.26398401%, total [0.9746727376209448, 0.9733106189664963, 0.9700891573195284, 0.9530800230282096, 0.943108504398827, 0.9150568181818182, 0.8015244796247435, 0.6625070901871809, 0.9488619568430388, 0.822215777262181, 0.5872695852534562, 0.5005858230814294, 0.9429250891795482, 0.8922588099364529, 0.675, 0.5997709705124534]\n",
      "kmeans average accuracy best : 79.73%, kmeans average accuracy : 77.45037697%, total [0.9604439385315879, 0.9616695059625213, 0.9539833189531205, 0.9395509499136442, 0.9434017595307918, 0.9144886363636363, 0.8214599824098505, 0.5921724333522405, 0.9379249187112031, 0.6218097447795824, 0.5167050691244239, 0.45225541886350323, 0.8011296076099881, 0.6929520508376661, 0.6683139534883721, 0.6137990266246779]\n",
      "cluster_accuracy_post_training_cycle_all_dataset : [0.95931883 0.96229972 0.95474242 0.94165863 0.94378109 0.90801887\n",
      " 0.80755843 0.61053622 0.92536561 0.73388672 0.49372587 0.42899702\n",
      " 0.76171079 0.7114452  0.70147059 0.62255136]\n",
      "mean_cluster_accuracy_during_training_cycle : 79.57%, post_traincycle_acc : 77.92%, total_acc : 78.59264426%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 80.72%\n",
      "accuracy_check 실행 시간: 21.202초\n",
      "\n",
      "\n",
      "epoch-38 loss : 0.01937644, loss_normal : 0.01546631, loss_coarse : 0.07311848, min_loss : 0.01937644, min_loss_normal : 0.01544980, min_loss_coarse : 0.07311447, wrong_element_sum : 14038748.00000000, same_data : 0.00%\n",
      "ae train 실행 시간: 95.229초, 전체 시작 시간 20250304_194401_700\n",
      "\n",
      "epoch-38 accuracy check\n",
      "k_means origin feature average accuracy : 82.24966347%, total [0.9746727376209448, 0.9733106189664963, 0.9700891573195284, 0.9530800230282096, 0.943108504398827, 0.9150568181818182, 0.801817648783348, 0.6625070901871809, 0.9488619568430388, 0.822215777262181, 0.5866935483870968, 0.5005858230814294, 0.9429250891795482, 0.8922588099364529, 0.6747093023255814, 0.5980532493558546]\n",
      "kmeans average accuracy best : 79.73%, kmeans average accuracy : 77.47454615%, total [0.9604439385315879, 0.9622373651334469, 0.9511072763876905, 0.936384571099597, 0.943108504398827, 0.9164772727272728, 0.8082673702726473, 0.5768576290414067, 0.9343777712089861, 0.679814385150812, 0.532258064516129, 0.46133567662565905, 0.7410820451843044, 0.7117273252455228, 0.6718023255813953, 0.6086458631548812]\n",
      "cluster_accuracy_post_training_cycle_all_dataset : [0.95979186 0.96229972 0.95089071 0.93972999 0.94328358 0.90754717\n",
      " 0.8050721  0.5780809  0.92687847 0.75       0.49227799 0.49304866\n",
      " 0.70621181 0.72308438 0.7127451  0.62350693]\n",
      "mean_cluster_accuracy_during_training_cycle : 79.42%, post_traincycle_acc : 77.97%, total_acc : 78.56189903%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 80.72%\n",
      "accuracy_check 실행 시간: 21.441초\n",
      "\n",
      "\n",
      "epoch-39 loss : 0.01924589, loss_normal : 0.01543856, loss_coarse : 0.07296570, min_loss : 0.01924589, min_loss_normal : 0.01543856, min_loss_coarse : 0.07296570, wrong_element_sum : 14009414.00000000, same_data : 0.00%\n",
      "ae train 실행 시간: 94.239초, 전체 시작 시간 20250304_194401_700\n",
      "\n",
      "epoch-39 accuracy check\n",
      "k_means origin feature average accuracy : 82.24960241%, total [0.9746727376209448, 0.9733106189664963, 0.9700891573195284, 0.9530800230282096, 0.943108504398827, 0.9150568181818182, 0.801817648783348, 0.6625070901871809, 0.9488619568430388, 0.822215777262181, 0.5872695852534562, 0.5005858230814294, 0.9429250891795482, 0.8922588099364529, 0.6738372093023256, 0.5983395362152877]\n",
      "kmeans average accuracy best : 79.73%, kmeans average accuracy : 78.93457207%, total [0.9624359704040979, 0.9633730834752982, 0.9536957146965775, 0.936384571099597, 0.9434017595307918, 0.915340909090909, 0.7930225740252126, 0.5629608621667612, 0.9376293230860183, 0.7224477958236659, 0.5492511520737328, 0.45782073813708263, 0.869500594530321, 0.7388792605430387, 0.690406976744186, 0.6329802462066991]\n",
      "cluster_accuracy_post_training_cycle_all_dataset : [0.95979186 0.96277097 0.95185364 0.93490839 0.94378109 0.90849057\n",
      " 0.84087519 0.56773283 0.9293999  0.75048828 0.46621622 0.52184707\n",
      " 0.85081466 0.75363725 0.72941176 0.63736264]\n",
      "mean_cluster_accuracy_during_training_cycle : 80.26%, post_traincycle_acc : 79.43%, total_acc : 79.76538138%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 80.72%\n",
      "accuracy_check 실행 시간: 21.328초\n",
      "\n",
      "\n",
      "epoch-40 loss : 0.01916077, loss_normal : 0.01543636, loss_coarse : 0.07293973, min_loss : 0.01916077, min_loss_normal : 0.01543636, min_loss_coarse : 0.07293973, wrong_element_sum : 14004428.00000000, same_data : 0.00%\n",
      "ae train 실행 시간: 96.008초, 전체 시작 시간 20250304_194401_700\n",
      "\n",
      "epoch-40 accuracy check\n",
      "k_means origin feature average accuracy : 82.25854398%, total [0.9746727376209448, 0.9733106189664963, 0.9700891573195284, 0.9530800230282096, 0.943108504398827, 0.9150568181818182, 0.801817648783348, 0.6622234826999432, 0.9488619568430388, 0.822215777262181, 0.5866935483870968, 0.5005858230814294, 0.9429250891795482, 0.8922588099364529, 0.6738372093023256, 0.600629831090753]\n",
      "kmeans average accuracy best : 79.73%, kmeans average accuracy : 78.66759029%, total [0.9595902105862265, 0.9613855763770585, 0.9534081104400345, 0.9401266551525619, 0.9451612903225807, 0.9210227272727273, 0.8334799179126355, 0.581678956324447, 0.9402896837126811, 0.742169373549884, 0.5400345622119815, 0.479203280609256, 0.7719976218787158, 0.7160600808781051, 0.6813953488372093, 0.6198110506727741]\n",
      "cluster_accuracy_post_training_cycle_all_dataset : [0.95789972 0.96135721 0.95185364 0.93924783 0.94477612 0.91556604\n",
      " 0.85280955 0.60677328 0.93242562 0.74560547 0.48214286 0.54816286\n",
      " 0.76476578 0.72308438 0.71323529 0.60965122]\n",
      "mean_cluster_accuracy_during_training_cycle : 79.12%, post_traincycle_acc : 79.06%, total_acc : 79.07524430%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 80.72%\n",
      "accuracy_check 실행 시간: 21.058초\n",
      "\n",
      "\n",
      "epoch-41 loss : 0.01924171, loss_normal : 0.01546347, loss_coarse : 0.07312440, min_loss : 0.01916077, min_loss_normal : 0.01543636, min_loss_coarse : 0.07293973, wrong_element_sum : 14039886.00000000, same_data : 0.00%\n",
      "ae train 실행 시간: 97.425초, 전체 시작 시간 20250304_194401_700\n",
      "\n",
      "epoch-41 accuracy check\n",
      "k_means origin feature average accuracy : 82.26402702%, total [0.9746727376209448, 0.9733106189664963, 0.9700891573195284, 0.9530800230282096, 0.943108504398827, 0.9150568181818182, 0.801817648783348, 0.6625070901871809, 0.9488619568430388, 0.822215777262181, 0.5872695852534562, 0.5005858230814294, 0.9429250891795482, 0.8922588099364529, 0.675, 0.5994846836530203]\n",
      "kmeans average accuracy best : 79.73%, kmeans average accuracy : 79.04922425%, total [0.9604439385315879, 0.9602498580352072, 0.9516824849007766, 0.9355210132412205, 0.9454545454545454, 0.9142045454545454, 0.8293755496921724, 0.5657969370391378, 0.9337865799586166, 0.7178074245939675, 0.5668202764976958, 0.47685998828353837, 0.834423305588585, 0.744945118428654, 0.690406976744186, 0.6200973375322073]\n",
      "cluster_accuracy_post_training_cycle_all_dataset : [0.95931883 0.96135721 0.9523351  0.94069431 0.94477612 0.91037736\n",
      " 0.84137245 0.60348071 0.92435703 0.77050781 0.58397683 0.50794439\n",
      " 0.799389   0.75072745 0.71078431 0.60535117]\n",
      "mean_cluster_accuracy_during_training_cycle : 80.55%, post_traincycle_acc : 79.79%, total_acc : 80.10302083%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 80.72%\n",
      "accuracy_check 실행 시간: 21.580초\n",
      "\n",
      "\n",
      "epoch-42 loss : 0.01925390, loss_normal : 0.01545910, loss_coarse : 0.07309399, min_loss : 0.01916077, min_loss_normal : 0.01543636, min_loss_coarse : 0.07293973, wrong_element_sum : 14034046.00000000, same_data : 0.00%\n",
      "ae train 실행 시간: 93.051초, 전체 시작 시간 20250304_194401_700\n",
      "\n",
      "epoch-42 accuracy check\n",
      "k_means origin feature average accuracy : 82.25855480%, total [0.9746727376209448, 0.9733106189664963, 0.9700891573195284, 0.9530800230282096, 0.943108504398827, 0.9150568181818182, 0.801817648783348, 0.6625070901871809, 0.9488619568430388, 0.822215777262181, 0.5866935483870968, 0.5005858230814294, 0.9429250891795482, 0.8922588099364529, 0.6741279069767442, 0.6000572573718866]\n",
      "kmeans average accuracy best : 79.73%, kmeans average accuracy : 78.97592733%, total [0.9610130904951623, 0.9619534355479841, 0.9534081104400345, 0.9412780656303973, 0.9436950146627566, 0.9079545454545455, 0.8123717384931105, 0.5697674418604651, 0.9331953887082471, 0.7381090487238979, 0.5383064516129032, 0.46660808435852374, 0.880499405469679, 0.7489890236857308, 0.6895348837209302, 0.58946464357286]\n",
      "cluster_accuracy_post_training_cycle_all_dataset : [0.95979186 0.96182846 0.95377949 0.94117647 0.94427861 0.89858491\n",
      " 0.82148185 0.59360301 0.92284418 0.80419922 0.54488417 0.49056604\n",
      " 0.85794297 0.7628516  0.72401961 0.5876732 ]\n",
      "mean_cluster_accuracy_during_training_cycle : 80.46%, post_traincycle_acc : 79.81%, total_acc : 80.07590703%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 80.72%\n",
      "accuracy_check 실행 시간: 21.051초\n",
      "\n",
      "\n",
      "epoch-43 loss : 0.01927680, loss_normal : 0.01547020, loss_coarse : 0.07311921, min_loss : 0.01916077, min_loss_normal : 0.01543636, min_loss_coarse : 0.07293973, wrong_element_sum : 14038888.00000000, same_data : 0.00%\n",
      "ae train 실행 시간: 96.939초, 전체 시작 시간 20250304_194401_700\n",
      "\n",
      "epoch-43 accuracy check\n",
      "k_means origin feature average accuracy : 82.26211374%, total [0.9746727376209448, 0.9733106189664963, 0.9700891573195284, 0.9530800230282096, 0.943108504398827, 0.915340909090909, 0.801817648783348, 0.6625070901871809, 0.9488619568430388, 0.822215777262181, 0.5872695852534562, 0.5005858230814294, 0.9429250891795482, 0.8922588099364529, 0.6738372093023256, 0.6000572573718866]\n",
      "kmeans average accuracy best : 79.73%, kmeans average accuracy : 78.49348827%, total [0.9610130904951623, 0.9625212947189097, 0.9528329019269485, 0.9309153713298791, 0.9442815249266863, 0.9133522727272727, 0.8299618880093814, 0.5680657969370392, 0.9290570499556606, 0.7645011600928074, 0.568836405529954, 0.48125366139425896, 0.7719976218787158, 0.717793183131138, 0.6636627906976744, 0.598912109934154]\n",
      "cluster_accuracy_post_training_cycle_all_dataset : [0.95931883 0.96182846 0.9523351  0.93635487 0.94577114 0.91415094\n",
      " 0.85330681 0.57431797 0.91376702 0.79785156 0.57046332 0.52234359\n",
      " 0.75203666 0.72550921 0.69117647 0.63210702]\n",
      "mean_cluster_accuracy_during_training_cycle : 80.56%, post_traincycle_acc : 79.39%, total_acc : 79.86996631%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 80.72%\n",
      "accuracy_check 실행 시간: 21.460초\n",
      "\n",
      "\n",
      "epoch-44 loss : 0.01926130, loss_normal : 0.01547354, loss_coarse : 0.07306411, min_loss : 0.01916077, min_loss_normal : 0.01543636, min_loss_coarse : 0.07293973, wrong_element_sum : 14028310.00000000, same_data : 0.00%\n",
      "ae train 실행 시간: 95.415초, 전체 시작 시간 20250304_194401_700\n",
      "\n",
      "epoch-44 accuracy check\n",
      "k_means origin feature average accuracy : 82.26041597%, total [0.9746727376209448, 0.9733106189664963, 0.9700891573195284, 0.9530800230282096, 0.943108504398827, 0.9150568181818182, 0.801817648783348, 0.6622234826999432, 0.9488619568430388, 0.822215777262181, 0.5866935483870968, 0.5005858230814294, 0.9429250891795482, 0.8922588099364529, 0.6747093023255814, 0.6000572573718866]\n",
      "kmeans average accuracy best : 79.73%, kmeans average accuracy : 79.54557816%, total [0.960728514513375, 0.9616695059625213, 0.9522576934138626, 0.9360967184801382, 0.9463343108504398, 0.9204545454545454, 0.8367047786572852, 0.5629608621667612, 0.9456104049660065, 0.8071345707656613, 0.5368663594470046, 0.46309314586994726, 0.8109393579072532, 0.7507221259387638, 0.6918604651162791, 0.6438591468651589]\n",
      "cluster_accuracy_post_training_cycle_all_dataset : [0.9602649  0.96182846 0.94896485 0.93828351 0.94626866 0.91886792\n",
      " 0.84932869 0.59266228 0.93746848 0.83740234 0.51254826 0.52631579\n",
      " 0.80549898 0.75315228 0.72107843 0.59675108]\n",
      "mean_cluster_accuracy_during_training_cycle : 81.18%, post_traincycle_acc : 80.04%, total_acc : 80.50451283%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 80.72%\n",
      "accuracy_check 실행 시간: 20.974초\n",
      "\n",
      "\n",
      "epoch-45 loss : 0.01906532, loss_normal : 0.01543077, loss_coarse : 0.07296919, min_loss : 0.01906532, min_loss_normal : 0.01543077, min_loss_coarse : 0.07293973, wrong_element_sum : 14010084.00000000, same_data : 0.00%\n",
      "ae train 실행 시간: 94.405초, 전체 시작 시간 20250304_194401_700\n",
      "\n",
      "epoch-45 accuracy check\n",
      "k_means origin feature average accuracy : 82.25318692%, total [0.9746727376209448, 0.9733106189664963, 0.9700891573195284, 0.9530800230282096, 0.943108504398827, 0.9150568181818182, 0.801817648783348, 0.6625070901871809, 0.9488619568430388, 0.822215777262181, 0.5866935483870968, 0.5005858230814294, 0.9429250891795482, 0.8922588099364529, 0.6741279069767442, 0.5991983967935872]\n",
      "kmeans average accuracy best : 79.73%, kmeans average accuracy : 77.52111547%, total [0.9612976664769494, 0.9625212947189097, 0.9519700891573195, 0.9366724237190558, 0.9436950146627566, 0.9082386363636363, 0.802403987100557, 0.5649461145774248, 0.9349689624593556, 0.6435614849187935, 0.5092165898617511, 0.46367896895137667, 0.8159928656361475, 0.7322357019064125, 0.6796511627906977, 0.5923275121671915]\n",
      "cluster_accuracy_post_training_cycle_all_dataset : [0.95979186 0.96229972 0.95185364 0.93442623 0.94427861 0.90660377\n",
      " 0.8279463  0.59454374 0.92486132 0.63769531 0.51882239 0.45829196\n",
      " 0.75356415 0.74490786 0.72254902 0.59531773]\n",
      "mean_cluster_accuracy_during_training_cycle : 79.46%, post_traincycle_acc : 77.74%, total_acc : 78.44143187%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 80.72%\n",
      "accuracy_check 실행 시간: 28.119초\n",
      "\n",
      "\n",
      "epoch-46 loss : 0.01883105, loss_normal : 0.01534689, loss_coarse : 0.07265880, min_loss : 0.01883105, min_loss_normal : 0.01534689, min_loss_coarse : 0.07265880, wrong_element_sum : 13950490.00000000, same_data : 0.00%\n",
      "ae train 실행 시간: 93.280초, 전체 시작 시간 20250304_194401_700\n",
      "\n",
      "epoch-46 accuracy check\n",
      "k_means origin feature average accuracy : 82.24590825%, total [0.9746727376209448, 0.9733106189664963, 0.9700891573195284, 0.9530800230282096, 0.943108504398827, 0.9150568181818182, 0.8015244796247435, 0.6625070901871809, 0.9488619568430388, 0.8219257540603249, 0.5866935483870968, 0.5005858230814294, 0.9429250891795482, 0.8922588099364529, 0.673546511627907, 0.5991983967935872]\n",
      "kmeans average accuracy best : 79.73%, kmeans average accuracy : 77.58948136%, total [0.9612976664769494, 0.9625212947189097, 0.9534081104400345, 0.93811168681635, 0.9448680351906158, 0.9130681818181818, 0.7965406039284667, 0.5714690867838911, 0.9405852793378658, 0.5556844547563805, 0.4988479262672811, 0.46133567662565905, 0.8564209274673008, 0.7276140958983247, 0.6901162790697675, 0.6424277125679931]\n",
      "cluster_accuracy_post_training_cycle_all_dataset : [0.9602649  0.96135721 0.95426095 0.94069431 0.94427861 0.90990566\n",
      " 0.80855296 0.61476952 0.92788704 0.57470703 0.51496139 0.50148957\n",
      " 0.83452138 0.74733269 0.71372549 0.62732919]\n",
      "mean_cluster_accuracy_during_training_cycle : 80.12%, post_traincycle_acc : 78.35%, total_acc : 79.07355138%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 80.72%\n",
      "accuracy_check 실행 시간: 21.333초\n",
      "\n",
      "\n",
      "epoch-47 loss : 0.01901032, loss_normal : 0.01543493, loss_coarse : 0.07287478, min_loss : 0.01883105, min_loss_normal : 0.01534689, min_loss_coarse : 0.07265880, wrong_element_sum : 13991958.00000000, same_data : 0.00%\n",
      "ae train 실행 시간: 93.748초, 전체 시작 시간 20250304_194401_700\n",
      "\n",
      "epoch-47 accuracy check\n",
      "k_means origin feature average accuracy : 82.26042087%, total [0.9746727376209448, 0.9733106189664963, 0.9700891573195284, 0.9530800230282096, 0.943108504398827, 0.9150568181818182, 0.801817648783348, 0.6625070901871809, 0.9488619568430388, 0.822215777262181, 0.5872695852534562, 0.5005858230814294, 0.9429250891795482, 0.8922588099364529, 0.6747093023255814, 0.5991983967935872]\n",
      "kmeans average accuracy best : 79.73%, kmeans average accuracy : 78.36034937%, total [0.9621513944223108, 0.9628052243043725, 0.9511072763876905, 0.9335060449050087, 0.9436950146627566, 0.9085227272727273, 0.7842274992670771, 0.5595575723199092, 0.9216671593260419, 0.7192575406032483, 0.5348502304147466, 0.46690099589923845, 0.8852556480380499, 0.7068168688619295, 0.6715116279069767, 0.6258230747208703]\n",
      "cluster_accuracy_post_training_cycle_all_dataset : [0.96073794 0.96371348 0.95089071 0.93394407 0.94626866 0.90566038\n",
      " 0.8363998  0.56914393 0.9183056  0.7578125  0.51640927 0.52333664\n",
      " 0.85641548 0.73666343 0.71078431 0.62924032]\n",
      "mean_cluster_accuracy_during_training_cycle : 79.56%, post_traincycle_acc : 79.47%, total_acc : 79.50628279%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 80.72%\n",
      "accuracy_check 실행 시간: 21.710초\n",
      "\n",
      "\n",
      "epoch-48 loss : 0.01875862, loss_normal : 0.01534056, loss_coarse : 0.07253418, min_loss : 0.01875862, min_loss_normal : 0.01534056, min_loss_coarse : 0.07253418, wrong_element_sum : 13926562.00000000, same_data : 0.00%\n",
      "ae train 실행 시간: 94.942초, 전체 시작 시간 20250304_194401_700\n",
      "\n",
      "epoch-48 accuracy check\n",
      "k_means origin feature average accuracy : 82.24777182%, total [0.9746727376209448, 0.9733106189664963, 0.9700891573195284, 0.9530800230282096, 0.943108504398827, 0.915340909090909, 0.801817648783348, 0.6625070901871809, 0.9488619568430388, 0.822215777262181, 0.5872695852534562, 0.5005858230814294, 0.9429250891795482, 0.8922588099364529, 0.673546511627907, 0.5980532493558546]\n",
      "kmeans average accuracy best : 79.73%, kmeans average accuracy : 78.14109747%, total [0.9612976664769494, 0.9622373651334469, 0.9525452976704055, 0.9372481289579735, 0.943108504398827, 0.9088068181818182, 0.7859865142187042, 0.5592739648326716, 0.9370381318356489, 0.6525522041763341, 0.523905529953917, 0.45869947275922673, 0.843935790725327, 0.7530329289428076, 0.6965116279069767, 0.6263956484397366]\n",
      "cluster_accuracy_post_training_cycle_all_dataset : [0.95931883 0.96229972 0.95329803 0.93780135 0.94676617 0.9\n",
      " 0.83341621 0.5682032  0.93141704 0.72509766 0.53523166 0.51539225\n",
      " 0.80855397 0.76236663 0.71911765 0.65169613]\n",
      "mean_cluster_accuracy_during_training_cycle : 80.20%, post_traincycle_acc : 79.44%, total_acc : 79.74693728%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 80.72%\n",
      "accuracy_check 실행 시간: 23.258초\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "gpu = '1'\n",
    "Conv_net = True # True False\n",
    "SAE_net = True # True False\n",
    "\n",
    "# hyperparameter\n",
    "dataset_num = 16\n",
    "spike_length = 50 # coarse_com_mode일 때는 time step이 됨.\n",
    "num_cluster = 4  # 클러스터 수 설정 # 논문엔 4개라는데 여기서는 3개로 했네\n",
    "training_cycle = 1400 #1400 2400 # 그 초기 몇개까지만 cluster update할지\n",
    "\n",
    "\n",
    "batch_size = 32\n",
    "max_epoch = 10000\n",
    "learning_rate = 0.001\n",
    "normalize_on = True # True or False # 0부터1까지 normalize\n",
    "need_bias = False\n",
    "# first_layer_no_train = False\n",
    "lif_add_at_first = False\n",
    "my_seed = 42\n",
    "\n",
    "TIME = 50 # SAE일 때만 유효. coarse_com_mode일 때는 level_num이 됨. 즉 feature 개수.\n",
    "v_decay = 0.5 # -cor\n",
    "v_threshold = 0.25 # -cor\n",
    "v_reset = 0.0 # -cor # 10000이상 일 시 hard reset\n",
    "BPTT_on = True # +cor # True False\n",
    "\n",
    "SAE_hidden_nomean = True # True False\n",
    "\n",
    "current_time = datetime.datetime.now().strftime(\"%Y%m%d_%H%M%S\") + f\"_{str(int(datetime.datetime.now().microsecond / 1000)).zfill(3)}\"\n",
    "\n",
    "optimizer = 'Adam' #'Adam', 'SGD' # 둘다 준수함. loss 줄이는 거는 adam이 좋긴한데, cluster accuracy는 비슷함.\n",
    "\n",
    "coarse_com_mode = True # True False\n",
    "coarse_com_config = (0.999, -0.0) # (max, min) (0.999, -0.0) (1.0, -0.0) (2.0, -2.0) (3.0, -3.0)\n",
    "\n",
    "sae_l2_norm_bridge = True # True False\n",
    "sae_lif_bridge = False # True False\n",
    "\n",
    "accuracy_check_epoch_term = 1\n",
    "\n",
    "lif_add_at_last = False # True False\n",
    "\n",
    "two_channel_input = False # True False\n",
    "\n",
    "lateral_feature_num = 4\n",
    "\n",
    "lc_adc_on = False # True False\n",
    "\n",
    "converted_net_forward = False # True False\n",
    "\n",
    "pretrained_net = None\n",
    "# pretrained_net = '/home/bhkim003/github_folder/ByeonghyeonKim/my_snn/net_save/save_now_net_중요_20250110_203117_390.pth'\n",
    "# pretrained_net = '/home/bhkim003/github_folder/ByeonghyeonKim/my_snn/net_save/save_now_net_중요_20250113_134126_881_이거_94나오는거.pth'\n",
    "# pretrained_net =  '/home/bhkim003/github_folder/ByeonghyeonKim/my_snn/net_save/save_now_net_20250205_184901_132.pth'\n",
    "# pretrained_net =  '/home/bhkim003/github_folder/ByeonghyeonKim/my_snn/net_save/save_now_net_20250226_190044_204.pth'\n",
    "\n",
    "vth_mul_on = False # True False\n",
    "batch_norm_on = False # True False\n",
    "\n",
    "l2_norm_loss_weight = 0 #0.0001 #0.1 #  0 # 0초과면 작동\n",
    "\n",
    "QCFS_neuron_on = False # True False\n",
    "\n",
    "quantize_level_num = 0 # 0이면 quantize 안함. 1이상이면 그 수만큼 quantize함. # normalize_on 켜져야됨. 음수면 0~1norm안하고 quant함\n",
    "\n",
    "fusion_net = True # True False # SAE_net False, Conv_net True로 해라. TIME 적절하게 설정해주고.\n",
    "repeat_coding = False # True False #fusion_net에서 쓰이는 거임 # True면 repeat, False면 rate coding.\n",
    "\n",
    "sae_relu_on = False # True False\n",
    "\n",
    "conv1d_scaling = False # True False # conv1d때매 norm하고 (level_num-3)/level_num 곱해줌 # Conv_net and coarse_com_mode and normalize_on\n",
    "\n",
    "norm01 = True # True False # normalize_on = True일 때 01norm하는지 아님 걍 quant만 하는지.\n",
    "\n",
    "wandb.init(project= f'spike_sorting just run',save_code=False)\n",
    "\n",
    "\n",
    "cluster_train_system( \n",
    "    gpu = gpu,\n",
    "    Conv_net = Conv_net,\n",
    "    SAE_net = SAE_net,\n",
    "\n",
    "    # hyperparameter\n",
    "    dataset_num = dataset_num,\n",
    "    spike_length = spike_length,\n",
    "    num_cluster = num_cluster,  # 클러스터 수 설정 # 논문엔 4개라는데 여기서는 3개로 했네\n",
    "    training_cycle = training_cycle, # 그 초기 몇개까지만 cluster update할지\n",
    "\n",
    "\n",
    "    batch_size = batch_size,\n",
    "    max_epoch = max_epoch,\n",
    "    learning_rate = learning_rate,\n",
    "    normalize_on = normalize_on, # True or False #이거 안 씀 # 이거 별로 안 좋은 normalize같음 # 쓸 거면 다른 거 써라.\n",
    "    need_bias = need_bias,\n",
    "    # first_layer_no_train = False\n",
    "    lif_add_at_first = lif_add_at_first,\n",
    "    my_seed = my_seed,\n",
    "\n",
    "    TIME = TIME, # SAE일 때만 유효\n",
    "    v_decay = v_decay,\n",
    "    v_threshold = v_threshold,\n",
    "    v_reset = v_reset, # 10000이상 일 시 hard reset\n",
    "    BPTT_on = BPTT_on,\n",
    "\n",
    "    SAE_hidden_nomean = SAE_hidden_nomean,\n",
    "    \n",
    "    current_time = current_time,\n",
    "\n",
    "    optimizer = optimizer, #'Adam', 'SGD'\n",
    "\n",
    "    coarse_com_mode = coarse_com_mode,\n",
    "    coarse_com_config = coarse_com_config, # (max, min)\n",
    "\n",
    "    \n",
    "    sae_l2_norm_bridge = sae_l2_norm_bridge,\n",
    "    sae_lif_bridge = sae_lif_bridge,\n",
    "\n",
    "    accuracy_check_epoch_term = accuracy_check_epoch_term,\n",
    "    \n",
    "    lif_add_at_last = lif_add_at_last,\n",
    "\n",
    "    two_channel_input = two_channel_input,\n",
    "\n",
    "    lateral_feature_num = lateral_feature_num,\n",
    "\n",
    "    lc_adc_on = lc_adc_on, \n",
    "\n",
    "    converted_net_forward = converted_net_forward,\n",
    "\n",
    "    pretrained_net = pretrained_net,\n",
    "\n",
    "    vth_mul_on = vth_mul_on,\n",
    "    batch_norm_on = batch_norm_on,\n",
    "\n",
    "    l2_norm_loss_weight = l2_norm_loss_weight,\n",
    "    \n",
    "    QCFS_neuron_on = QCFS_neuron_on, # True False\n",
    "\n",
    "    quantize_level_num = quantize_level_num,\n",
    "\n",
    "    fusion_net = fusion_net, # True False\n",
    "    repeat_coding = repeat_coding,\n",
    "\n",
    "    sae_relu_on = sae_relu_on,\n",
    "\n",
    "    conv1d_scaling = conv1d_scaling,\n",
    "\n",
    "    norm01 = norm01,\n",
    "\n",
    "    )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m커널을 시작하지 못했습니다. \n",
      "\u001b[1;31m포트 사용 대기 시간 초과로 인해 'aedat2 (Python 3.8.18)' 커널을 시작할 수 없습니다. \n",
      "\u001b[1;31m자세한 내용은 Jupyter <a href='command:jupyter.viewOutput'>로그</a>를 참조하세요."
     ]
    }
   ],
   "source": [
    "# # Sweep code\n",
    "\n",
    "\n",
    "# from unittest import TextTestRunner\n",
    "\n",
    "\n",
    "# unique_name_hyper = 'cluster_train_system'\n",
    "# # run_name = 'spike_sorting'\n",
    "# sweep_start_time =  datetime.datetime.now().strftime(\"%Y%m%d_%H%M%S\") + f\"_{str(int(datetime.datetime.now().microsecond / 1000)).zfill(3)}\"\n",
    "# sweep_configuration = {\n",
    "#     'method': 'bayes', # 'random', 'bayes'\n",
    "#     'name': f'spike_sorting_{sweep_start_time}',\n",
    "#     'metric': {'goal': 'maximize', 'name': 'k_means_acc_best'},\n",
    "#     'parameters': \n",
    "#     {\n",
    "#         # \"gpu\": {\"values\": ['1']},  # 이건 sweep parameter아님. hyper_iter에서 직접 설정\n",
    "#         \"Conv_net\": {\"values\": [True]}, \n",
    "#         \"SAE_net\": {\"values\": [False]}, \n",
    "\n",
    "#         \"dataset_num\": {\"values\": [16]}, \n",
    "#         \"spike_length\": {\"values\": [50]},  \n",
    "#         \"num_cluster\": {\"values\": [4]}, \n",
    "#         \"training_cycle\": {\"values\": [2400]}, # [1400, 2400]\n",
    "\n",
    "#         \"batch_size\": {\"values\": [32]}, \n",
    "#         \"max_epoch\": {\"values\": [1]}, \n",
    "#         \"learning_rate\": {\"values\": [0.001, 0.0001]},\n",
    "#         \"normalize_on\": {\"values\": [True]},\n",
    "#         \"need_bias\": {\"values\": [False]}, # [True, False]\n",
    "\n",
    "#         \"lif_add_at_first\": {\"values\": [False]}, # [True, False]\n",
    "#         \"my_seed\": {\"values\": [42]}, \n",
    "\n",
    "#         \"TIME\": {\"values\": [10, 50, 100, 250, 500, 750, 1000, 1500, 2000, 2500]}, #  [4,6,8,10]\n",
    "#         \"v_decay\": {\"values\": [1.0]}, # [0.25,0.50,0.75]\n",
    "#         \"v_threshold\": {\"values\": [0.125, 0.25, 0.50, 0.75, 0.875, 1.0]}, # [0.25,0.50,0.75]\n",
    "#         \"v_reset\": {\"values\": [0.0, 10000.0]},  # [0.0, 10000.0]\n",
    "#         \"BPTT_on\": {\"values\": [True, False]},  # [True, False]\n",
    "\n",
    "#         \"SAE_hidden_nomean\": {\"values\": [True]}, # [True, False]\n",
    "\n",
    "#         # \"current_time\": {\"values\": [current_time]} #밑에서 직접설정됨.\n",
    "\n",
    "#         \"optimizer\": {\"values\": ['Adam', 'SGD']}, # ['Adam', 'SGD']\n",
    "\n",
    "#         \"coarse_com_mode\": {\"values\": [False]}, # [True, False]\n",
    "#         \"coarse_com_config\": {\"values\": [(2.0, -2.0)]}, # ['Adam', 'SGD']\n",
    "\n",
    "#         \"sae_l2_norm_bridge\": {\"values\": [True]}, # [True, False]\n",
    "#         \"sae_lif_bridge\": {\"values\": [True]}, # [False, True]\n",
    "        \n",
    "#         \"accuracy_check_epoch_term\": {\"values\": [1]}, \n",
    "\n",
    "#         \"lif_add_at_last\": {\"values\": [False]},# [True, False]\n",
    "\n",
    "#         \"two_channel_input\": {\"values\": [False]},# [True, False]\n",
    "\n",
    "#         \"lateral_feature_num\": {\"values\": [4]},# [True, False]\n",
    "\n",
    "#         \"lc_adc_on\": {\"values\": [False]},# [True, False]\n",
    "        \n",
    "#         \"converted_net_forward\": {\"values\": [True]},# [True, False]\n",
    "\n",
    "#         \"pretrained_net\": {\"values\": ['/home/bhkim003/github_folder/ByeonghyeonKim/my_snn/net_save/save_now_net_중요_20250110_203117_390.pth']},# [None]\n",
    "\n",
    "#         \"vth_mul_on\": {\"values\": [True]},# [True, False]\n",
    "#         \"batch_norm_on\": {\"values\": [True]},# [True, False]\n",
    "\n",
    "#         \"l2_norm_loss_weight\": {\"values\": [0.1]},\n",
    "\n",
    "#         \"QCFS_neuron_on\": {\"values\": [True]},   # [True, False]\n",
    "\n",
    "#         \"quantize_level_num\": {\"values\": [0]}, \n",
    "\n",
    "#         \"fusion_net\": {\"values\": [False]}, \n",
    "#         \"repeat_coding\": {\"values\": [False]}, \n",
    "\n",
    "#         \"sae_relu_on\": {\"values\": [False]}, \n",
    "\n",
    "#         \"conv1d_scaling\": {\"values\": [False]}, \n",
    "\n",
    "#         \"norm01\": {\"values\": [True]}, \n",
    "#      }\n",
    "# }\n",
    "\n",
    "\n",
    "# def hyper_iter():\n",
    "#     ### my_snn control board ########################\n",
    "#     wandb.init(save_code = False)\n",
    "#     gpu  =  '2'\n",
    "#     Conv_net  =  wandb.config.Conv_net\n",
    "#     SAE_net  =  wandb.config.SAE_net\n",
    "\n",
    "#     dataset_num  =  wandb.config.dataset_num\n",
    "#     spike_length  =  wandb.config.spike_length\n",
    "#     num_cluster  =  wandb.config.num_cluster\n",
    "#     training_cycle  =  wandb.config.training_cycle\n",
    "\n",
    "#     batch_size  =  wandb.config.batch_size\n",
    "#     max_epoch  =  wandb.config.max_epoch\n",
    "#     learning_rate  =  wandb.config.learning_rate\n",
    "#     normalize_on  =  wandb.config.normalize_on\n",
    "#     need_bias  =  wandb.config.need_bias\n",
    "\n",
    "#     lif_add_at_first  =  wandb.config.lif_add_at_first\n",
    "#     my_seed  =  wandb.config.my_seed\n",
    "\n",
    "\n",
    "#     TIME  =  wandb.config.TIME\n",
    "#     v_decay  =  wandb.config.v_decay\n",
    "#     v_threshold  =  wandb.config.v_threshold\n",
    "#     v_reset  =  wandb.config.v_reset\n",
    "#     BPTT_on  =  wandb.config.BPTT_on\n",
    "\n",
    "#     SAE_hidden_nomean  =  wandb.config.SAE_hidden_nomean\n",
    "    \n",
    "#     current_time =  datetime.datetime.now().strftime(\"%Y%m%d_%H%M%S\") + f\"_{str(int(datetime.datetime.now().microsecond / 1000)).zfill(3)}\"\n",
    "\n",
    "#     optimizer  =  wandb.config.optimizer\n",
    "\n",
    "#     coarse_com_mode = wandb.config.coarse_com_mode\n",
    "#     coarse_com_config = wandb.config.coarse_com_config # (max, min)\n",
    "\n",
    "#     sae_l2_norm_bridge = wandb.config.sae_l2_norm_bridge\n",
    "#     sae_lif_bridge = wandb.config.sae_lif_bridge\n",
    "\n",
    "#     accuracy_check_epoch_term = wandb.config.accuracy_check_epoch_term\n",
    "\n",
    "#     lif_add_at_last = wandb.config.lif_add_at_last\n",
    "\n",
    "#     two_channel_input = wandb.config.two_channel_input\n",
    "\n",
    "#     lateral_feature_num = wandb.config.lateral_feature_num\n",
    "\n",
    "#     lc_adc_on = wandb.config.lc_adc_on\n",
    "\n",
    "#     converted_net_forward = wandb.config.converted_net_forward\n",
    "\n",
    "#     pretrained_net = wandb.config.pretrained_net\n",
    "\n",
    "#     vth_mul_on = wandb.config.vth_mul_on\n",
    "#     batch_norm_on = wandb.config.batch_norm_on\n",
    "\n",
    "#     l2_norm_loss_weight = wandb.config.l2_norm_loss_weight\n",
    "\n",
    "#     QCFS_neuron_on = wandb.config.QCFS_neuron_on\n",
    "\n",
    "#     quantize_level_num = wandb.config.quantize_level_num\n",
    "\n",
    "#     fusion_net = wandb.config.fusion_net\n",
    "#     repeat_coding = wandb.config.repeat_coding\n",
    "\n",
    "#     sae_relu_on = wandb.config.sae_relu_on\n",
    "\n",
    "#     conv1d_scaling = wandb.config.conv1d_scaling\n",
    "\n",
    "#     norm01 = wandb.config.norm01\n",
    "\n",
    "#     cluster_train_system( \n",
    "#         gpu = gpu,\n",
    "#         Conv_net = Conv_net,\n",
    "#         SAE_net = SAE_net,\n",
    "\n",
    "#         # hyperparameter\n",
    "#         dataset_num = dataset_num,\n",
    "#         spike_length = spike_length,\n",
    "#         num_cluster = num_cluster,  # 클러스터 수 설정 # 논문엔 4개라는데 여기서는 3개로 했네\n",
    "#         training_cycle = training_cycle, # 그 초기 몇개까지만 cluster update할지\n",
    "\n",
    "\n",
    "#         batch_size = batch_size,\n",
    "#         max_epoch = max_epoch,\n",
    "#         learning_rate = learning_rate,\n",
    "#         normalize_on = normalize_on, # True or False #이거 안 씀 # 이거 별로 안 좋은 normalize같음 # 쓸 거면 다른 거 써라.\n",
    "#         need_bias = need_bias,\n",
    "#         # first_layer_no_train = False\n",
    "#         lif_add_at_first = lif_add_at_first,\n",
    "#         my_seed = my_seed,\n",
    "\n",
    "#         TIME = TIME, # SAE일 때만 유효\n",
    "#         v_decay = v_decay,\n",
    "#         v_threshold = v_threshold,\n",
    "#         v_reset = v_reset, # 10000이상 일 시 hard reset\n",
    "#         BPTT_on = BPTT_on,\n",
    "\n",
    "#         SAE_hidden_nomean = SAE_hidden_nomean,\n",
    "\n",
    "#         current_time = current_time,\n",
    "\n",
    "#         optimizer = optimizer, #'Adam', 'SGD'\n",
    "\n",
    "#         coarse_com_mode = coarse_com_mode,\n",
    "#         coarse_com_config = coarse_com_config, # (max, min)\n",
    "        \n",
    "#         sae_l2_norm_bridge = sae_l2_norm_bridge,\n",
    "#         sae_lif_bridge = sae_lif_bridge,\n",
    "\n",
    "#         accuracy_check_epoch_term = accuracy_check_epoch_term,\n",
    "\n",
    "#         lif_add_at_last = lif_add_at_last,\n",
    "        \n",
    "#         two_channel_input = two_channel_input,\n",
    "        \n",
    "#         lateral_feature_num = lateral_feature_num,\n",
    "\n",
    "#         lc_adc_on = lc_adc_on,\n",
    "\n",
    "#         converted_net_forward = converted_net_forward,\n",
    "\n",
    "#         pretrained_net = pretrained_net,\n",
    "\n",
    "#         vth_mul_on = vth_mul_on,\n",
    "#         batch_norm_on = batch_norm_on,\n",
    "\n",
    "#         l2_norm_loss_weight = l2_norm_loss_weight,\n",
    "\n",
    "#         QCFS_neuron_on = QCFS_neuron_on,\n",
    "\n",
    "#         quantize_level_num = quantize_level_num,\n",
    "\n",
    "#         fusion_net = fusion_net, \n",
    "#         repeat_coding = repeat_coding, \n",
    "\n",
    "#         sae_relu_on = sae_relu_on,\n",
    "\n",
    "#         conv1d_scaling = conv1d_scaling,\n",
    "\n",
    "#         norm01 = norm01,\n",
    "#         )\n",
    "    \n",
    "# # sweep_id = 'ygoj9jt4'\n",
    "# sweep_id = wandb.sweep(sweep=sweep_configuration, project=f'spike_sorting {unique_name_hyper}')\n",
    "# wandb.agent(sweep_id, function=hyper_iter, count=100000, project=f'spike_sorting {unique_name_hyper}')\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m커널을 시작하지 못했습니다. \n",
      "\u001b[1;31m포트 사용 대기 시간 초과로 인해 'aedat2 (Python 3.8.18)' 커널을 시작할 수 없습니다. \n",
      "\u001b[1;31m자세한 내용은 Jupyter <a href='command:jupyter.viewOutput'>로그</a>를 참조하세요."
     ]
    }
   ],
   "source": [
    "wandb.finish() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m커널을 시작하지 못했습니다. \n",
      "\u001b[1;31m포트 사용 대기 시간 초과로 인해 'aedat2 (Python 3.8.18)' 커널을 시작할 수 없습니다. \n",
      "\u001b[1;31m자세한 내용은 Jupyter <a href='command:jupyter.viewOutput'>로그</a>를 참조하세요."
     ]
    }
   ],
   "source": [
    "# import matplotlib.pyplot as plt\n",
    "# from matplotlib.ticker import MaxNLocator\n",
    "# import pickle\n",
    "# import json\n",
    "\n",
    "# # current_time = '20250102_225243_972'\n",
    "\n",
    "# with open(f\"result_save/cluster_accuracy_history_{current_time}.pkl\", \"rb\") as f:\n",
    "#     data = pickle.load(f)\n",
    "\n",
    "\n",
    "# # JSON으로 저장\n",
    "# with open(f\"result_save/cluster_accuracy_history_{current_time}.json\", 'r') as f:\n",
    "#     loaded_hyperparameters = json.load(f)\n",
    "\n",
    "# loss_history = data['loss_history']\n",
    "# mean_cluster_accuracy_during_training_cycle_all_dataset_history = data['mean_cluster_accuracy_during_training_cycle_all_dataset_history']\n",
    "# mean_cluster_accuracy_post_training_cycle_all_dataset_history = data['mean_cluster_accuracy_post_training_cycle_all_dataset_history']\n",
    "# mean_cluster_accuracy_total_all_dataset_history = data['mean_cluster_accuracy_total_all_dataset_history']\n",
    "# print(data)\n",
    "# max_acc = 0\n",
    "# for i in mean_cluster_accuracy_post_training_cycle_all_dataset_history:\n",
    "#     if i[1] > max_acc:\n",
    "#         max_acc = i[1]\n",
    "\n",
    "# # 설정 정보 제목 작성\n",
    "# title = (\n",
    "#     f\"Dataset Num: {loaded_hyperparameters['dataset_num']}, Conv {loaded_hyperparameters['Conv_net']}, SAE {loaded_hyperparameters['SAE_net']}, Current time {loaded_hyperparameters['current_time']}, Spike Length: {loaded_hyperparameters['spike_length']}, Num Cluster: {loaded_hyperparameters['num_cluster']}, \"\n",
    "#     f\"Training Cycle: {loaded_hyperparameters['training_cycle']}, Batch Size: {loaded_hyperparameters['batch_size']}, Max Epoch: {loaded_hyperparameters['max_epoch']}, \\n\"\n",
    "#     f\"Learning Rate: {loaded_hyperparameters['learning_rate']}, Input Normalize: {loaded_hyperparameters['normalize_on']}, Need Bias: {loaded_hyperparameters['need_bias']}, \"\n",
    "#     f\"LIF Add at First: {loaded_hyperparameters['lif_add_at_first']}, TIME: {loaded_hyperparameters['TIME']}, Seed: {loaded_hyperparameters['my_seed']}, Best ACC: {max_acc:.2f}%\"\n",
    "# )\n",
    "\n",
    "# # 데이터 리스트와 라벨 설정 (Loss 제외)\n",
    "# data_list = [\n",
    "#     (\"Mean Cluster Accuracy (During Training Cycle)\", mean_cluster_accuracy_during_training_cycle_all_dataset_history),\n",
    "#     (\"Mean Cluster Accuracy (Post Training Cycle)\", mean_cluster_accuracy_post_training_cycle_all_dataset_history),\n",
    "#     (\"Mean Cluster Accuracy (Total)\", mean_cluster_accuracy_total_all_dataset_history),\n",
    "# ]\n",
    "\n",
    "# # 플롯 생성\n",
    "# fig, ax1 = plt.subplots(figsize=(12, 8))\n",
    "\n",
    "# # 첫 번째 y축: Accuracy 관련 데이터\n",
    "# for label, data in data_list:\n",
    "#     epochs, values = zip(*data)  # epoch, value 분리\n",
    "#     ax1.plot(epochs, values, label=label)\n",
    "\n",
    "# ax1.set_xlabel(\"Epoch\")\n",
    "# ax1.set_ylabel(\"Clurstering Accuracy [%]\", color=\"blue\")\n",
    "# ax1.tick_params(axis=\"y\", labelcolor=\"blue\")\n",
    "# ax1.legend(loc=\"center right\")\n",
    "# ax1.grid(True)\n",
    "\n",
    "# # x축을 정수만 표시하도록 설정\n",
    "# ax1.xaxis.set_major_locator(MaxNLocator(integer=True))\n",
    "\n",
    "# # 두 번째 y축: Loss History\n",
    "# ax2 = ax1.twinx()\n",
    "# epochs, values = zip(*loss_history)\n",
    "# ax2.plot(epochs, values, label=\"AE Loss History\", color=\"red\", linestyle=\"--\")\n",
    "# ax2.set_ylabel(\"Loss\", color=\"red\")\n",
    "# ax2.tick_params(axis=\"y\", labelcolor=\"red\")\n",
    "# ax2.legend(loc=\"center left\")\n",
    "\n",
    "# # 제목 추가\n",
    "# plt.title(title, fontsize=10)\n",
    "# plt.tight_layout()\n",
    "# plt.savefig(f'net_save/{current_time}', dpi=300, bbox_inches=\"tight\")  # dpi=300은 고해상도로 저장, bbox_inches=\"tight\"는 여백 최소화\n",
    "# plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m커널을 시작하지 못했습니다. \n",
      "\u001b[1;31m포트 사용 대기 시간 초과로 인해 'aedat2 (Python 3.8.18)' 커널을 시작할 수 없습니다. \n",
      "\u001b[1;31m자세한 내용은 Jupyter <a href='command:jupyter.viewOutput'>로그</a>를 참조하세요."
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# 데이터셋\n",
    "filename_for_plot = [\n",
    "    \"Easy1_noise05\", \"Easy1_noise10\", \"Easy1_noise15\", \"Easy1_noise20\",\n",
    "    \"Easy2_noise05\", \"Easy2_noise10\", \"Easy2_noise15\", \"Easy2_noise20\",\n",
    "    \"Difficult1_noise05\", \"Difficult1_noise10\", \"Difficult1_noise15\", \"Difficult1_noise20\",\n",
    "    \"Difficult2_noise05\", \"Difficult2_noise10\", \"Difficult2_noise15\", \"Difficult2_noise20\"\n",
    "]\n",
    "\n",
    "# Accuracy 데이터\n",
    "ANN_conv_accracy_set= [0.97935368, 0.97682709, 0.97028784, 0.96461825, 0.97524752, 0.95803571\n",
    ", 0.95746785, 0.92628774, 0.965412,  0.97805344, 0.94869403, 0.92110454\n",
    ", 0.96784232, 0.97551789, 0.91538462, 0.84446478]\n",
    "SNN_fc_accuracy_set = [0.97114475, 0.97643732, 0.84400578, 0.78977821, 0.96616915, 0.92830189\n",
    ", 0.86176032, 0.31984948, 0.80635401, 0.88769531, 0.61003861, 0.60377358\n",
    ", 0.9592668,  0.92870999, 0.78333333, 0.67271859]\n",
    "SNN_conv_accuracy_set = [0.97445601, 0.97737983, 0.97063072, 0.95998071, 0.96268657, 0.90566038\n",
    ", 0.82545997, 0.68391345, 0.96116994, 0.92138672, 0.80694981, 0.49602781\n",
    ", 0.83604888, 0.70611057, 0.69313725, 0.5819398 ]\n",
    "\n",
    "# 평균 계산\n",
    "average_ANN_conv = np.mean(ANN_conv_accracy_set)\n",
    "average_SNN_fc = np.mean(SNN_fc_accuracy_set)\n",
    "average_SNN_conv = np.mean(SNN_conv_accuracy_set)\n",
    "\n",
    "# 데이터 준비\n",
    "accuracies = np.array([ANN_conv_accracy_set, SNN_fc_accuracy_set, SNN_conv_accuracy_set])\n",
    "averages = np.array([average_ANN_conv, average_SNN_fc, average_SNN_conv])\n",
    "\n",
    "# 시각화\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "\n",
    "# 각 모델의 정확도 플롯\n",
    "ax.plot(accuracies[0], label='ANN Conv', marker='o', linestyle='-', color='blue')\n",
    "ax.plot(accuracies[1], label='SNN FC', marker='o', linestyle='-', color='green')\n",
    "ax.plot(accuracies[2], label='SNN Conv', marker='o', linestyle='-', color='red')\n",
    "\n",
    "# 평균값 플롯\n",
    "ax.axhline(y=average_ANN_conv, color='blue', linestyle='--', label=f'Average ANN Conv: {average_ANN_conv:.3f}')\n",
    "ax.axhline(y=average_SNN_fc, color='green', linestyle='--', label=f'Average SNN FC: {average_SNN_fc:.3f}')\n",
    "ax.axhline(y=average_SNN_conv, color='red', linestyle='--', label=f'Average SNN Conv: {average_SNN_conv:.3f}')\n",
    "\n",
    "# 레이블 추가\n",
    "ax.set_xticks(np.arange(len(filename_for_plot)))\n",
    "ax.set_xticklabels(filename_for_plot, rotation=45, ha='right')\n",
    "ax.set_ylabel('Accuracy')\n",
    "ax.set_title('Accuracy Comparison of Models on Datasets')\n",
    "ax.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m커널을 시작하지 못했습니다. \n",
      "\u001b[1;31m포트 사용 대기 시간 초과로 인해 'aedat2 (Python 3.8.18)' 커널을 시작할 수 없습니다. \n",
      "\u001b[1;31m자세한 내용은 Jupyter <a href='command:jupyter.viewOutput'>로그</a>를 참조하세요."
     ]
    }
   ],
   "source": [
    "import csv\n",
    "import matplotlib.pyplot as plt\n",
    "import os  # 파일 경로 처리를 위한 모듈\n",
    "\n",
    "# CSV 파일 경로\n",
    "# csv_file_path = \"/home/bhkim003/github_folder/ByeonghyeonKim/my_snn/ae_test_deprecated/250115/sweep0_vth_mul.csv\" # vth_mul해서 sweep 돌린거\n",
    "csv_file_path = \"/home/bhkim003/github_folder/ByeonghyeonKim/my_snn/ae_test_deprecated/250115/sweep1.csv\"  #vth_mul안한거\n",
    "\n",
    "# 결과를 저장할 리스트\n",
    "tuple_list = []\n",
    "\n",
    "# CSV 파일 읽기\n",
    "with open(csv_file_path, 'r') as file:\n",
    "    reader = csv.DictReader(file)\n",
    "    for row in reader:\n",
    "        try:\n",
    "            # v_threshold, TIME, v_reset, converted_k_means_acc 값을 가져와 튜플로 변환\n",
    "            v_threshold = float(row[\"v_threshold\"])\n",
    "            time = int(row[\"TIME\"])\n",
    "            v_reset = int(row[\"v_reset\"])\n",
    "            converted_k_means_acc = float(row[\"converted_k_means_acc\"]) if row[\"converted_k_means_acc\"] else None\n",
    "\n",
    "            # 튜플 형태로 추가 (값이 None일 경우 처리할 수도 있음)\n",
    "            tuple_list.append((v_threshold, time, v_reset, converted_k_means_acc))\n",
    "        except ValueError as e:\n",
    "            print(f\"Error processing row {row}: {e}\")\n",
    "\n",
    "# 데이터를 TIME 기준으로 정렬\n",
    "tuple_list.sort(key=lambda x: x[1])  # TIME을 기준으로 오름차순 정렬\n",
    "\n",
    "# reset 방식에 따라 데이터를 나누기\n",
    "soft_reset = [t for t in tuple_list if t[2] == 0]\n",
    "hard_reset = [t for t in tuple_list if t[2] == 10000]\n",
    "\n",
    "# reset 방식과 v_threshold에 따라 색상 설정\n",
    "def plot_data(data, label_prefix, marker):\n",
    "    for v_threshold in [1.0]:  # v_threshold 기준으로 제한\n",
    "        filtered_data = [(t[1], t[3]) for t in data if t[0] == v_threshold]\n",
    "        if filtered_data:  # 해당 v_threshold 데이터가 있을 경우만 플롯\n",
    "            times, accuracies = zip(*filtered_data)  # x축(TIME), y축(converted_k_means_acc)\n",
    "            \n",
    "            plt.plot(\n",
    "                times,\n",
    "                accuracies,\n",
    "                marker,\n",
    "                label=f\"{label_prefix}, v_threshold={v_threshold}\",\n",
    "                linestyle=\"--\",\n",
    "            )\n",
    "            # 각 점에 accuracy 표시\n",
    "            for time, acc in filtered_data:\n",
    "                if acc == None:\n",
    "                    continue\n",
    "                plt.text(time, acc, f\"{acc:.2f}\", fontsize=8, ha=\"right\")\n",
    "\n",
    "# 그래프 초기화\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "# soft_reset (v_reset=0) 데이터 플롯\n",
    "plot_data(soft_reset, \"Soft Reset\", \"o\")\n",
    "\n",
    "# hard_reset (v_reset=10000) 데이터 플롯\n",
    "plot_data(hard_reset, \"Hard Reset\", \"x\")\n",
    "\n",
    "# baseline accuracy 가로선 추가\n",
    "baseline_accuracy = 94.43\n",
    "plt.axhline(y=baseline_accuracy, color=\"red\", linestyle=\"-\", label=f\"Baseline Accuracy ({baseline_accuracy}%)\")\n",
    "# baseline 텍스트 추가\n",
    "plt.text(\n",
    "    2000,  # x축 위치 (그래프 오른쪽 끝)\n",
    "    baseline_accuracy + 0.4,  # y축 위치 (baseline 위 약간)\n",
    "    f\"ANN Baseline ({baseline_accuracy}%)\",\n",
    "    color=\"red\",\n",
    "    fontsize=10,\n",
    "    ha=\"center\",\n",
    ")\n",
    "\n",
    "# CSV 파일 이름 가져오기\n",
    "csv_file_name = os.path.basename(csv_file_path)\n",
    "\n",
    "# 그래프 세부 설정\n",
    "plt.title(f\"Converted SNN K-Means Accuracy vs TIME STEP - {csv_file_name}\")\n",
    "plt.xlabel(\"TIME STEP\")\n",
    "plt.ylabel(\"Converted K-Means Accuracy [%]\")\n",
    "plt.legend(loc=\"lower right\")  # 범례를 오른쪽 아래로 이동\n",
    "plt.grid(True)\n",
    "\n",
    "# 그래프 출력\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aedat2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
