{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copyright (c) 2024 Byeonghyeon Kim \n",
    "# github site: https://github.com/bhkim003/ByeonghyeonKim\n",
    "# email: bhkim003@snu.ac.kr\n",
    " \n",
    "# Permission is hereby granted, free of charge, to any person obtaining a copy of\n",
    "# this software and associated documentation files (the \"Software\"), to deal in\n",
    "# the Software without restriction, including without limitation the rights to\n",
    "# use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of\n",
    "# the Software, and to permit persons to whom the Software is furnished to do so,\n",
    "# subject to the following conditions:\n",
    " \n",
    "# The above copyright notice and this permission notice shall be included in all\n",
    "# copies or substantial portions of the Software.\n",
    " \n",
    "# THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\n",
    "# IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS\n",
    "# FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR\n",
    "# COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER\n",
    "# IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN\n",
    "# CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_108456/2361114005.py:45: DeprecationWarning: The module snntorch.spikevision is deprecated. For loading neuromorphic datasets, we recommend using the Tonic project: https://github.com/neuromorphs/tonic\n",
      "  from snntorch.spikevision import spikedata\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.optim as optim\n",
    "import torch.optim.lr_scheduler as lr_scheduler\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "import torchvision\n",
    "import torchvision.datasets\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import time\n",
    "\n",
    "from snntorch import spikegen\n",
    "import matplotlib.pyplot as plt\n",
    "import snntorch.spikeplot as splt\n",
    "from IPython.display import HTML\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "from apex.parallel import DistributedDataParallel as DDP\n",
    "\n",
    "import random\n",
    "import datetime\n",
    "\n",
    "import json\n",
    "\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "''' 레퍼런스\n",
    "https://spikingjelly.readthedocs.io/zh-cn/0.0.0.0.4/spikingjelly.datasets.html#module-spikingjelly.datasets\n",
    "https://github.com/GorkaAbad/Sneaky-Spikes/blob/main/datasets.py\n",
    "https://github.com/GorkaAbad/Sneaky-Spikes/blob/main/how_to.md\n",
    "https://github.com/nmi-lab/torchneuromorphic\n",
    "https://snntorch.readthedocs.io/en/latest/snntorch.spikevision.spikedata.html#shd\n",
    "'''\n",
    "\n",
    "import snntorch\n",
    "from snntorch.spikevision import spikedata\n",
    "\n",
    "from spikingjelly.datasets.dvs128_gesture import DVS128Gesture\n",
    "from spikingjelly.datasets.cifar10_dvs import CIFAR10DVS\n",
    "from spikingjelly.datasets.n_mnist import NMNIST\n",
    "# from spikingjelly.datasets.es_imagenet import ESImageNet\n",
    "from spikingjelly.datasets import split_to_train_test_set\n",
    "from spikingjelly.datasets.n_caltech101 import NCaltech101\n",
    "from spikingjelly.datasets import pad_sequence_collate, padded_sequence_mask\n",
    "\n",
    "import torchneuromorphic\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bhkim003/anaconda3/envs/aedat2/lib/python3.8/site-packages/torchneuromorphic-0.3.7-py3.8.egg/torchneuromorphic/ntidigits/ntidigits_dataloaders.py:79: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
      "/home/bhkim003/anaconda3/envs/aedat2/lib/python3.8/site-packages/torchneuromorphic-0.3.7-py3.8.egg/torchneuromorphic/ntidigits/ntidigits_dataloaders.py:81: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
      "/home/bhkim003/anaconda3/envs/aedat2/lib/python3.8/site-packages/torchneuromorphic-0.3.7-py3.8.egg/torchneuromorphic/ntidigits/ntidigits_dataloaders.py:99: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
      "/home/bhkim003/anaconda3/envs/aedat2/lib/python3.8/site-packages/torchneuromorphic-0.3.7-py3.8.egg/torchneuromorphic/ntidigits/ntidigits_dataloaders.py:101: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
      "/home/bhkim003/anaconda3/envs/aedat2/lib/python3.8/site-packages/torchneuromorphic-0.3.7-py3.8.egg/torchneuromorphic/ntidigits/ntidigits_dataloaders.py:79: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
      "/home/bhkim003/anaconda3/envs/aedat2/lib/python3.8/site-packages/torchneuromorphic-0.3.7-py3.8.egg/torchneuromorphic/ntidigits/ntidigits_dataloaders.py:81: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
      "/home/bhkim003/anaconda3/envs/aedat2/lib/python3.8/site-packages/torchneuromorphic-0.3.7-py3.8.egg/torchneuromorphic/ntidigits/ntidigits_dataloaders.py:99: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
      "/home/bhkim003/anaconda3/envs/aedat2/lib/python3.8/site-packages/torchneuromorphic-0.3.7-py3.8.egg/torchneuromorphic/ntidigits/ntidigits_dataloaders.py:101: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x600 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# my module import\n",
    "from modules import *\n",
    "\n",
    "# modules 폴더에 새모듈.py 만들면\n",
    "# modules/__init__py 파일에 form .새모듈 import * 하셈\n",
    "# 그리고 새모듈.py에서 from modules.새모듈 import * 하셈\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    " # dvs 데이터 시각화 코드\n",
    " ##############################################################################################\n",
    "            # mapping = {\n",
    "            #     0: 'Hand Clapping',\n",
    "            #     1: 'Right Hand Wave',\n",
    "            #     2: 'Left Hand Wave',\n",
    "            #     3: 'Right Arm CW',\n",
    "            #     4: 'Right Arm CCW',\n",
    "            #     5: 'Left Arm CW',\n",
    "            #     6: 'Left Arm CCW',\n",
    "            #     7: 'Arm Roll',\n",
    "            #     8: 'Air Drums',\n",
    "            #     9: 'Air Guitar',\n",
    "            #     10: 'Other'\n",
    "            # }\n",
    "def dvs_visualization(inputs, labels, TIME, BATCH):\n",
    "            \n",
    "    what_input = random.randint(0, BATCH - 1)\n",
    "    inputs_for_view = inputs.permute(1, 0, 2, 3, 4)\n",
    "    for i in range(TIME):\n",
    "        # 예시 데이터 생성\n",
    "        data1 = inputs_for_view[what_input][i][0].numpy()  # torch tensor를 numpy 배열로 변환\n",
    "        data2 = inputs_for_view[what_input][i][1].numpy()  # torch tensor를 numpy 배열로 변환\n",
    "\n",
    "        # 데이터 플로팅\n",
    "        fig, axs = plt.subplots(1, 2, figsize=(12, 6))  # 1행 2열의 subplot 생성\n",
    "\n",
    "        # 첫 번째 subplot에 데이터1 플로팅\n",
    "        im1 = axs[0].imshow(data1, cmap='viridis', interpolation='nearest')\n",
    "        axs[0].set_title(f'Channel 0\\nLabel: {labels[what_input]}  Time: {i}')  # 라벨값 맵핑하여 제목에 추가\n",
    "        axs[0].set_xlabel('X axis')\n",
    "        axs[0].set_ylabel('Y axis')\n",
    "        axs[0].grid(False)\n",
    "        fig.colorbar(im1, ax=axs[0])  # Color bar 추가\n",
    "\n",
    "        # 두 번째 subplot에 데이터2 플로팅\n",
    "        im2 = axs[1].imshow(data2, cmap='viridis', interpolation='nearest')\n",
    "        axs[1].set_title(f'Channel 1\\nLabel: {labels[what_input]}  Time: {i}')  # 라벨값 맵핑하여 제목에 추가\n",
    "        axs[1].set_xlabel('X axis')\n",
    "        axs[1].set_ylabel('Y axis')\n",
    "        axs[1].grid(False)\n",
    "        fig.colorbar(im2, ax=axs[1])  # Color bar 추가\n",
    "\n",
    "        plt.tight_layout()  # subplot 간 간격 조정\n",
    "        plt.show()\n",
    "    sys.exit(\"종료\")\n",
    "\n",
    "######################################################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_snn_system(devices = \"0,1,2,3\",\n",
    "                    unique_name = 'main',\n",
    "                    my_seed = 42,\n",
    "                    TIME = 10,\n",
    "                    BATCH = 256,\n",
    "                    IMAGE_SIZE = 32,\n",
    "                    which_data = 'CIFAR10',\n",
    "                    # CLASS_NUM = 10,\n",
    "                    data_path = '/data2',\n",
    "                    rate_coding = True,\n",
    "    \n",
    "                    lif_layer_v_init = 0.0,\n",
    "                    lif_layer_v_decay = 0.6,\n",
    "                    lif_layer_v_threshold = 1.2,\n",
    "                    lif_layer_v_reset = 0.0,\n",
    "                    lif_layer_sg_width = 1,\n",
    "\n",
    "                    # synapse_conv_in_channels = IMAGE_PIXEL_CHANNEL,\n",
    "                    synapse_conv_kernel_size = 3,\n",
    "                    synapse_conv_stride = 1,\n",
    "                    synapse_conv_padding = 1,\n",
    "                    synapse_conv_trace_const1 = 1,\n",
    "                    synapse_conv_trace_const2 = 0.6,\n",
    "\n",
    "                    # synapse_fc_out_features = CLASS_NUM,\n",
    "                    synapse_fc_trace_const1 = 1,\n",
    "                    synapse_fc_trace_const2 = 0.6,\n",
    "\n",
    "                    pre_trained = False,\n",
    "                    convTrue_fcFalse = True,\n",
    "                    cfg = [64, 64],\n",
    "                    net_print = False, # True # False\n",
    "                    weight_count_print = False, # True # False\n",
    "                    pre_trained_path = \"net_save/save_now_net.pth\",\n",
    "                    learning_rate = 0.0001,\n",
    "                    epoch_num = 200,\n",
    "                    verbose_interval = 100, #숫자 크게 하면 꺼짐\n",
    "                    validation_interval = 10, #숫자 크게 하면 꺼짐\n",
    "                    tdBN_on = False,\n",
    "                    BN_on = False,\n",
    "\n",
    "                    surrogate = 'sigmoid',\n",
    "\n",
    "                    gradient_verbose = False,\n",
    "\n",
    "                    BPTT_on = False,\n",
    "\n",
    "                    optimizer_what = 'SGD', # 'SGD' 'Adam', 'RMSprop'\n",
    "                    scheduler_name = 'no',\n",
    "                    \n",
    "                    ddp_on = True,\n",
    "\n",
    "                    nda_net = False,\n",
    "                    \n",
    "                    domain_il_epoch = 0, # over 0, then domain il mode on\n",
    "\n",
    "                    dvs_clipping = True, \n",
    "                    dvs_duration = 1000000,\n",
    "\n",
    "                    OTTT_sWS_on = True, # True # False\n",
    "                  ):\n",
    "    \n",
    "    if OTTT_sWS_on == True:\n",
    "        assert BPTT_on == False and tdBN_on == False and convTrue_fcFalse == True\n",
    "\n",
    "    # 함수 내 모든 로컬 변수 저장\n",
    "    hyperparameters = locals()\n",
    "    hyperparameters['current epoch'] = 0\n",
    "\n",
    "\n",
    "    ## gpu setting ##################################################################################################################\n",
    "    os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\" \n",
    "    os.environ[\"CUDA_VISIBLE_DEVICES\"]= devices\n",
    "    ###################################################################################################################################\n",
    "\n",
    "\n",
    "    ## seed setting ##################################################################################################################\n",
    "    torch.manual_seed(my_seed)\n",
    "    ###################################################################################################################################\n",
    "\n",
    "\n",
    "    ## data_loader 가져오기 ##################################################################################################################\n",
    "    # data loader, pixel channel, class num\n",
    "    train_loader, test_loader, synapse_conv_in_channels, CLASS_NUM = data_loader(\n",
    "            which_data,\n",
    "            data_path, \n",
    "            rate_coding, \n",
    "            BATCH, \n",
    "            IMAGE_SIZE,\n",
    "            ddp_on,\n",
    "            TIME,\n",
    "            dvs_clipping,\n",
    "            dvs_duration)\n",
    "    synapse_fc_out_features = CLASS_NUM\n",
    "    ###########################################################################################################################################\n",
    "\n",
    "    \n",
    "    ## parameter number calculator (안 중요함) ##################################################################################################################\n",
    "    params_num = 0\n",
    "    img_size = IMAGE_SIZE \n",
    "    bias_param = 1 # 1 or 0\n",
    "    classifier_making = False\n",
    "    if (convTrue_fcFalse == True):\n",
    "        past_kernel = synapse_conv_in_channels\n",
    "        for kernel in cfg:\n",
    "            if (classifier_making == False):\n",
    "                if (type(kernel) == list):\n",
    "                    for residual_kernel in kernel:\n",
    "                        if (residual_kernel >= 10000 and residual_kernel < 20000): # separable\n",
    "                            residual_kernel -= 10000\n",
    "                            params_num += (synapse_conv_kernel_size**2 + bias_param) * past_kernel\n",
    "                            params_num += (1**2 * past_kernel + bias_param) * residual_kernel\n",
    "                            past_kernel = residual_kernel  \n",
    "                        elif (residual_kernel >= 20000 and residual_kernel < 30000): # depthwise\n",
    "                            residual_kernel -= 20000\n",
    "                            # 'past_kernel' should be same with 'kernel'\n",
    "                            params_num += (synapse_conv_kernel_size**2 + bias_param) * past_kernel\n",
    "                            past_kernel = residual_kernel  \n",
    "                        else:\n",
    "                            params_num += residual_kernel * ((synapse_conv_kernel_size**2) * past_kernel + bias_param)\n",
    "                            past_kernel = residual_kernel\n",
    "                elif (kernel == 'P' or kernel == 'M'):\n",
    "                    img_size = img_size // 2\n",
    "                elif (kernel == 'D'):\n",
    "                    img_size = 1\n",
    "                elif (kernel == 'L'):\n",
    "                    classifier_making = True\n",
    "                    past_kernel = past_kernel * (img_size**2)\n",
    "                else:\n",
    "                    if (kernel >= 10000 and kernel < 20000): # separable\n",
    "                        kernel -= 10000\n",
    "                        params_num += (synapse_conv_kernel_size**2 + bias_param) * past_kernel\n",
    "                        params_num += (1**2 * past_kernel + bias_param) * kernel\n",
    "                        past_kernel = kernel  \n",
    "                    elif (kernel >= 20000 and kernel < 30000): # depthwise\n",
    "                        kernel -= 20000\n",
    "                        # 'past_kernel' should be same with 'kernel'\n",
    "                        params_num += (synapse_conv_kernel_size**2 + bias_param) * past_kernel\n",
    "                        past_kernel = kernel  \n",
    "                    else:\n",
    "                        params_num += kernel * (synapse_conv_kernel_size**2 * past_kernel + bias_param)\n",
    "                        past_kernel = kernel    \n",
    "            else: # classifier making\n",
    "                params_num += (past_kernel + bias_param) * kernel\n",
    "                past_kernel = kernel\n",
    "        \n",
    "        \n",
    "        if classifier_making == False:\n",
    "            past_kernel = past_kernel*img_size*img_size\n",
    "\n",
    "        params_num += (past_kernel + bias_param) * synapse_fc_out_features\n",
    "    else:\n",
    "        past_in_channel = synapse_conv_in_channels*img_size*img_size\n",
    "        for in_channel in cfg:\n",
    "            if (type(in_channel) == list):\n",
    "                for residual_in_channel in in_channel:\n",
    "                    params_num += (past_in_channel + bias_param) * residual_in_channel\n",
    "                    past_in_channel = residual_in_channel\n",
    "            # elif (in_channel == 'M'): #it's a holy FC layer!\n",
    "            #     img_size = img_size // 2\n",
    "            else:\n",
    "                print('past_in_channel', past_in_channel)\n",
    "                print('bias_param', bias_param)\n",
    "                print('in_channel', in_channel)\n",
    "                params_num += (past_in_channel + bias_param) * in_channel\n",
    "                past_in_channel = in_channel\n",
    "        params_num += (past_in_channel + bias_param) * synapse_fc_out_features\n",
    "    ###########################################################################################################################################\n",
    "\n",
    "\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "    ### network setting #######################################################################################################################\n",
    "    if pre_trained == False:\n",
    "        if (convTrue_fcFalse == False):\n",
    "            net = MY_SNN_FC(cfg, synapse_conv_in_channels, IMAGE_SIZE, synapse_fc_out_features,\n",
    "                     synapse_fc_trace_const1, synapse_fc_trace_const2, \n",
    "                     lif_layer_v_init, lif_layer_v_decay, \n",
    "                     lif_layer_v_threshold, lif_layer_v_reset,\n",
    "                     lif_layer_sg_width,\n",
    "                     tdBN_on,\n",
    "                     BN_on, TIME,\n",
    "                     surrogate,\n",
    "                     BPTT_on).to(device)\n",
    "        else:\n",
    "            net = MY_SNN_CONV(cfg, synapse_conv_in_channels, IMAGE_SIZE,\n",
    "                     synapse_conv_kernel_size, synapse_conv_stride, \n",
    "                     synapse_conv_padding, synapse_conv_trace_const1, \n",
    "                     synapse_conv_trace_const2, \n",
    "                     lif_layer_v_init, lif_layer_v_decay, \n",
    "                     lif_layer_v_threshold, lif_layer_v_reset,\n",
    "                     lif_layer_sg_width,\n",
    "                     synapse_fc_out_features, synapse_fc_trace_const1, synapse_fc_trace_const2,\n",
    "                     tdBN_on,\n",
    "                     BN_on, TIME,\n",
    "                     surrogate,\n",
    "                     BPTT_on,\n",
    "                     OTTT_sWS_on).to(device)\n",
    "        \n",
    "        if (nda_net == True):\n",
    "            net = VGG(cfg = cfg, num_classes=10, batch_norm = tdBN_on, in_c = synapse_conv_in_channels, \n",
    "                      lif_layer_v_threshold=lif_layer_v_threshold, lif_layer_v_decay=lif_layer_v_decay, lif_layer_sg_width=lif_layer_sg_width)\n",
    "            net.T = TIME\n",
    "        net = torch.nn.DataParallel(net)\n",
    "    else:\n",
    "        net = torch.load(pre_trained_path)\n",
    "\n",
    "    net = net.to(device)\n",
    "    if (net_print == True):\n",
    "        print(net)        \n",
    "    ####################################################################################################################################\n",
    "    \n",
    "\n",
    "    ## param num and memory estimation except BN with MY own calculation some lines above ##########################################\n",
    "    real_param_num = sum(p.numel() for p in net.parameters() if p.requires_grad)\n",
    "    if (weight_count_print == True):\n",
    "        for name, param in net.named_parameters():\n",
    "            if param.requires_grad:\n",
    "                print(f'Layer: {name} | Number of parameters: {param.numel()}')\n",
    "    # Batch norm 있으면 아래 두 개 서로 다를 수 있음.\n",
    "    # assert real_param_num == params_num, f'parameter number is not same. real_param_num: {real_param_num}, params_num: {params_num}'    \n",
    "    print('='*50)\n",
    "    print(f\"My Num of PARAMS: {params_num:,}, system's param_num : {real_param_num:,}\")\n",
    "    memory = params_num / 8 / 1024 / 1024 # MB\n",
    "    precision = 32\n",
    "    memory = memory * precision \n",
    "    print(f\"Memory: {memory:.2f}MiB at {precision}-bit\")\n",
    "    print('='*50)\n",
    "    ##############################################################################################################################\n",
    "\n",
    "\n",
    "\n",
    "    ## criterion ########################################## # loss 구해주는 친구\n",
    "    criterion = nn.CrossEntropyLoss().to(device)\n",
    "    # criterion = lambda y_t, target_t: ((1 - 0.05) * F.cross_entropy(y_t, target_t) + 0.05 * F.mse_loss(y_t, F.one_hot(target_t, CLASS_NUM).float())) / TIME \n",
    "    ####################################################\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "    ## optimizer, scheduler ########################################################################\n",
    "    if(optimizer_what == 'SGD'):\n",
    "        # optimizer = optim.SGD(net.parameters(), lr=learning_rate, momentum=0.9)\n",
    "        optimizer = optim.SGD(net.parameters(), lr=learning_rate, momentum=0.9, weight_decay=0)\n",
    "    elif(optimizer_what == 'Adam'):\n",
    "        # optimizer = torch.optim.Adam(net.parameters(), lr=0.00001)\n",
    "        optimizer = torch.optim.Adam(net.parameters(), lr=learning_rate/256 * BATCH, weight_decay=1e-4)\n",
    "        # optimizer = optim.Adam(net.parameters(), lr=learning_rate, weight_decay=0, betas=(0.9, 0.999))\n",
    "    elif(optimizer_what == 'RMSprop'):\n",
    "        pass\n",
    "\n",
    "\n",
    "    if (scheduler_name == 'StepLR'):\n",
    "        scheduler = lr_scheduler.StepLR(optimizer, step_size=10, gamma=0.1)\n",
    "    elif (scheduler_name == 'ExponentialLR'):\n",
    "        scheduler = lr_scheduler.ExponentialLR(optimizer, gamma=0.95)\n",
    "    elif (scheduler_name == 'ReduceLROnPlateau'):\n",
    "        scheduler = lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.1, patience=10)\n",
    "    elif (scheduler_name == 'CosineAnnealingLR'):\n",
    "        # scheduler = lr_scheduler.CosineAnnealingLR(optimizer, eta_min=0, T_max=50)\n",
    "        scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, eta_min=0, T_max=epoch_num)\n",
    "    elif (scheduler_name == 'OneCycleLR'):\n",
    "        scheduler = lr_scheduler.OneCycleLR(optimizer, max_lr=0.1, steps_per_epoch=len(train_loader), epochs=100)\n",
    "    else:\n",
    "        pass # 'no' scheduler\n",
    "    ## optimizer, scheduler ########################################################################\n",
    "\n",
    "\n",
    "    tr_acc = 0\n",
    "    tr_correct = 0\n",
    "    tr_total = 0\n",
    "    val_acc = 0\n",
    "    val_acc_now = 0\n",
    "    elapsed_time_val = 0\n",
    "    iter_acc_array = np.array([])\n",
    "    tr_acc_array = np.array([])\n",
    "    val_acc_now_array = np.array([])\n",
    "    current_time = datetime.datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "    #======== EPOCH START ==========================================================================================\n",
    "    for epoch in range(epoch_num):\n",
    "        print('EPOCH', epoch)\n",
    "        epoch_start_time = time.time()\n",
    "        running_loss = 0.0\n",
    "\n",
    "        # if (domain_il_epoch>0 and which_data == 'PMNIST'):\n",
    "        #     k = epoch // domain_il_epoch\n",
    "        #     xtrain=data[k]['train']['x']\n",
    "        #     ytrain=data[k]['train']['y']\n",
    "        #     xtest =data[k]['test']['x']\n",
    "        #     ytest =data[k]['test']['y']\n",
    "\n",
    "        \n",
    "        ####### iterator : input_loading & tqdm을 통한 progress_bar 생성###################\n",
    "        iterator = enumerate(train_loader, 0)\n",
    "        if (ddp_on == True):\n",
    "            if torch.distributed.get_rank() == 0:   \n",
    "                iterator = tqdm(iterator, total=len(train_loader), desc='train', dynamic_ncols=True, position=0, leave=True)\n",
    "        else:\n",
    "            iterator = tqdm(iterator, total=len(train_loader), desc='train', dynamic_ncols=True, position=0, leave=True)\n",
    "        ##################################################################################   \n",
    "        \n",
    "        #### validation_interval이 batch size보다 작을 시 validation_interval을 batch size로 맞춰줌#############\n",
    "        validation_interval2 = validation_interval\n",
    "        if (validation_interval > len(iterator)):\n",
    "            validation_interval2 = len(iterator)\n",
    "        ##################################################################################################\n",
    "\n",
    "\n",
    "\n",
    "        ###### ITERATION START ##########################################################################################################\n",
    "        for i, data in iterator:\n",
    "            iter_one_train_time_start = time.time()\n",
    "            net.train() # train 모드로 바꿔줘야함\n",
    "\n",
    "            ### data loading & semi-pre-processing ################################################################################\n",
    "            if len(data) == 2:\n",
    "                inputs, labels = data\n",
    "                # 처리 로직 작성\n",
    "            elif len(data) == 3:\n",
    "                inputs, labels, x_len = data\n",
    "                # print('x_len',x_len)\n",
    "                # mask = padded_sequence_mask(x_len)\n",
    "                # max_time_step = x_len.max()\n",
    "                # min_time_step = x_len.min()\n",
    "            # print('inputs',inputs.size(),'\\nlabels',labels.size())\n",
    "                    \n",
    "            if (which_data == 'n_tidigits'):\n",
    "                inputs = inputs.permute(0, 1, 3, 2, 4)\n",
    "                labels = labels[:, 0, :]\n",
    "                labels = torch.argmax(labels, dim=1)\n",
    "            elif (which_data == 'heidelberg'):\n",
    "                inputs = inputs.view(5, 1000, 1, 700, 1)\n",
    "                print(\"\\n\\n\\n경고!!!! heidelberg 이거 타임스텝이랑 채널 잘 바꿔줘라!!!\\n\\n\\n\\n\")\n",
    "            # print('inputs',inputs.size(),'\\nlabels',labels.size())\n",
    "            # print(labels)\n",
    "                \n",
    "            if (which_data == 'DVS_CIFAR10' or which_data == 'DVS_GESTURE' or which_data == 'DVS_CIFAR10_2' or which_data == 'NMNIST' or which_data == 'N_CALTECH101' or which_data == 'n_tidigits' or which_data == 'heidelberg'):\n",
    "                inputs = inputs.permute(1, 0, 2, 3, 4)\n",
    "            elif rate_coding == True :\n",
    "                inputs = spikegen.rate(inputs, num_steps=TIME)\n",
    "            else :\n",
    "                inputs = inputs.repeat(TIME, 1, 1, 1, 1)\n",
    "            # inputs: [Time, Batch, Channel, Height, Width]  \n",
    "                \n",
    "            # # DVS에서 time duration으로 잘랐을 때는 timestep 맞춰주자 --> data 가져올 때, 그 함수 안에서 처리함.\n",
    "            # if (dvs_duration > 0): \n",
    "            #     # inputs.size(1)를 TIME으로 맞추기\n",
    "            #     T, *spatial_dims = inputs.shape\n",
    "            #     if T > TIME:\n",
    "            #         inputs = inputs[:TIME]\n",
    "            #     else:\n",
    "            #         inputs = torch.cat([inputs, torch.zeros(TIME - T, *spatial_dims)], dim=0)\n",
    "            # print('inputs',inputs.size(),'\\nlabels',labels.size())\n",
    "            ####################################################################################################################### \n",
    "                \n",
    "\n",
    "                \n",
    "            # # dvs 데이터 시각화 코드 (확인 필요할 시 써라)\n",
    "            # ##############################################################################################\n",
    "            # dvs_visualization(inputs, labels, TIME, BATCH)\n",
    "            # ######################################################################################################\n",
    "\n",
    "\n",
    "            ## device로 보내주기 ######################################\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "            ###########################################################\n",
    "\n",
    "\n",
    "            ## gradient 초기화 #######################################\n",
    "            optimizer.zero_grad()\n",
    "            ###########################################################\n",
    "\n",
    "\n",
    "            # net에 넣어줄때는 batch가 젤 앞 차원으로 와야함. # dataparallel때매##############################\n",
    "            # inputs: [Time, Batch, Channel, Height, Width]   \n",
    "            inputs = inputs.permute(1, 0, 2, 3, 4) # net에 넣어줄때는 batch가 젤 앞 차원으로 와야함. # dataparallel때매\n",
    "            # inputs: [Batch, Time, Channel, Height, Width] \n",
    "            #################################################################################################\n",
    "\n",
    "\n",
    "            ### input --> net --> output #####################################################\n",
    "            outputs = net(inputs)\n",
    "            ##################################################################################\n",
    "\n",
    "\n",
    "            #### batch 어긋남 방지 ###############################################\n",
    "            batch = BATCH \n",
    "            if labels.size(0) != BATCH: \n",
    "                batch = labels.size(0)\n",
    "            #######################################################################\n",
    "            \n",
    "\n",
    "\n",
    "            ####### training accruacy save for print ###############################\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total = labels.size(0)\n",
    "            correct = (predicted[0:batch] == labels).sum().item()\n",
    "            tr_total += total\n",
    "            tr_correct += correct\n",
    "            iter_acc = correct / total\n",
    "            if i % verbose_interval == verbose_interval-1:\n",
    "                print(f'{epoch}-{i} training acc: {100 * iter_acc:.2f}%, lr={[f\"{lr}\" for lr in (param_group[\"lr\"] for param_group in optimizer.param_groups)]}, val_acc: {100 * val_acc_now:.2f}%')\n",
    "            iter_acc_string = f'{epoch}-{i}/{len(train_loader)} iter_acc: {100 * iter_acc:.2f}%, lr={[f\"{lr}\" for lr in (param_group[\"lr\"] for param_group in optimizer.param_groups)]}'\n",
    "            ################################################################\n",
    "            \n",
    "\n",
    "            ## loss, backward ##########################################\n",
    "            loss = criterion(outputs[0:batch,:], labels)\n",
    "            loss.backward()\n",
    "            ############################################################\n",
    "\n",
    "\n",
    "            ### gradinet verbose ##########################################\n",
    "            if (gradient_verbose == True):\n",
    "                if (i % verbose_interval == verbose_interval-1):\n",
    "                    print('\\n\\nepoch', epoch, 'iter', i)\n",
    "                    for name, param in net.named_parameters():\n",
    "                        if param.requires_grad:\n",
    "                            print('\\n\\n\\n\\n' , name, param.grad)\n",
    "            ################################################################\n",
    "            \n",
    "\n",
    "            ## weight 업데이트!! ##################################\n",
    "            optimizer.step()\n",
    "            ################################################################\n",
    "\n",
    "\n",
    "            running_loss += loss.item()\n",
    "            # print(\"Epoch: {}, Iter: {}, Loss: {}\".format(epoch + 1, i + 1, running_loss / 100))\n",
    "\n",
    "            iter_one_train_time_end = time.time()\n",
    "            elapsed_time = iter_one_train_time_end - iter_one_train_time_start  # 실행 시간 계산\n",
    "\n",
    "            if (i % verbose_interval == verbose_interval-1):\n",
    "                print(f\"iter_one_train_time: {elapsed_time} seconds, last one_val_time: {elapsed_time_val} seconds\\n\")\n",
    "\n",
    "            ##### validation ##################################################################################################################################\n",
    "            if i % validation_interval2 == validation_interval2-1:\n",
    "                iter_one_val_time_start = time.time()\n",
    "                tr_acc = tr_correct/tr_total\n",
    "                tr_correct = 0\n",
    "                tr_total = 0\n",
    "                correct = 0\n",
    "                total = 0\n",
    "                with torch.no_grad():\n",
    "                    net.eval() # eval 모드로 바꿔줘야함 \n",
    "                    for data in test_loader:\n",
    "                        ## data loading & semi-pre-processing ##########################################################\n",
    "                        if len(data) == 2:\n",
    "                            inputs, labels = data\n",
    "                            # 처리 로직 작성\n",
    "                        elif len(data) == 3:\n",
    "                            inputs, labels, x_len = data\n",
    "                            # print('x_len',x_len)\n",
    "                            # mask = padded_sequence_mask(x_len)\n",
    "                            # max_time_step = x_len.max()\n",
    "                            # min_time_step = x_len.min()\n",
    "                            # B, T, *spatial_dims = inputs.shape\n",
    "\n",
    "                        if (which_data == 'DVS_CIFAR10' or which_data == 'DVS_GESTURE' or which_data == 'DVS_CIFAR10_2' or which_data == 'NMNIST' or which_data == 'N_CALTECH101' or which_data == 'n_tidigits' or which_data == 'heidelberg'):\n",
    "                            inputs = inputs.permute(1, 0, 2, 3, 4)\n",
    "                        elif rate_coding == True :\n",
    "                            inputs = spikegen.rate(inputs, num_steps=TIME)\n",
    "                        else :\n",
    "                            inputs = inputs.repeat(TIME, 1, 1, 1, 1)\n",
    "                        # inputs: [Time, Batch, Channel, Height, Width]  \n",
    "                        ###################################################################################################\n",
    "\n",
    "                        inputs = inputs.to(device)\n",
    "                        labels = labels.to(device)\n",
    "                        outputs = net(inputs.permute(1, 0, 2, 3, 4))\n",
    "                        _, predicted = torch.max(outputs.data, 1)\n",
    "                        total += labels.size(0)\n",
    "                        batch = BATCH \n",
    "                        if labels.size(0) != BATCH: \n",
    "                            batch = labels.size(0)\n",
    "                        correct += (predicted[0:batch] == labels).sum().item()\n",
    "                        val_loss = criterion(outputs[0:batch,:], labels)\n",
    "\n",
    "                    val_acc_now = correct / total\n",
    "                    # print(f'{epoch}-{i} validation acc: {100 * val_acc_now:.2f}%, lr={[f\"{lr:.10f}\" for lr in (param_group[\"lr\"] for param_group in optimizer.param_groups)]}')\n",
    "\n",
    "                iter_one_val_time_end = time.time()\n",
    "                elapsed_time_val = iter_one_val_time_end - iter_one_val_time_start  # 실행 시간 계산\n",
    "                # print(f\"iter_one_val_time: {elapsed_time_val} seconds\")\n",
    "\n",
    "                # network save\n",
    "                if val_acc < val_acc_now:\n",
    "                    val_acc = val_acc_now\n",
    "                    torch.save(net.state_dict(), f\"net_save/save_now_net_weights_{unique_name}.pth\")\n",
    "                    torch.save(net, f\"net_save/save_now_net_{unique_name}.pth\")\n",
    "                    torch.save(net.module.state_dict(), f\"net_save/save_now_net_weights2_{unique_name}.pth\")\n",
    "                    torch.save(net.module, f\"net_save/save_now_net2_{unique_name}.pth\")\n",
    "            ####################################################################################################################################################\n",
    "            iterator.set_description(f\"iter_acc: {iter_acc_string}, iter_loss: {loss}, val_acc: {100 * val_acc_now:.2f}%\")  \n",
    "\n",
    "            iter_acc_array = np.append(iter_acc_array, iter_acc)\n",
    "            tr_acc_array = np.append(tr_acc_array, tr_acc)\n",
    "            val_acc_now_array = np.append(val_acc_now_array, val_acc_now)\n",
    "            base_name = f'{current_time}'\n",
    "            iter_acc_file_name = f'result_save/{base_name}_iter_acc_array_{unique_name}.npy'\n",
    "            tr_acc_file_name = f'result_save/{base_name}_tr_acc_array_{unique_name}.npy'\n",
    "            val_acc_file_name = f'result_save/{base_name}_val_acc_now_array_{unique_name}.npy'\n",
    "            hyperparameters_file_name = f'result_save/{base_name}_hyperparameters.json_{unique_name}'\n",
    "\n",
    "            hyperparameters['current epoch'] = epoch\n",
    "\n",
    "            # 덮어쓰기 하기 싫으면 주석 풀어서 사용 (시간마다 새로 쓰기)\n",
    "            # np.save(iter_acc_file_name, iter_acc_array)\n",
    "            # np.save(val_acc_file_name, val_acc_now_array)\n",
    "            # with open(hyperparameters_file_name, 'w') as f:\n",
    "            #     json.dump(hyperparameters, f, indent=4)\n",
    "\n",
    "            np.save(f'result_save/iter_acc_array_{unique_name}.npy', iter_acc_array)\n",
    "            np.save(f'result_save/tr_acc_array_{unique_name}.npy', tr_acc_array)\n",
    "            np.save(f'result_save/val_acc_now_array_{unique_name}.npy', val_acc_now_array)\n",
    "            with open(f'result_save/hyperparameters.json_{unique_name}', 'w') as f:\n",
    "                json.dump(hyperparameters, f, indent=4)\n",
    "        ###### ITERATION END ##########################################################################################################\n",
    "                \n",
    "\n",
    "        ## scheduler update #############################################################################\n",
    "        if (scheduler_name != 'no'):\n",
    "            if (scheduler_name == 'ReduceLROnPlateau'):\n",
    "                scheduler.step(val_loss)\n",
    "            else:\n",
    "                scheduler.step()\n",
    "        #################################################################################################\n",
    "        \n",
    "        # 실행 시간 계산\n",
    "        epoch_time_end = time.time()\n",
    "        print(f\"epoch_time: {epoch_time_end - epoch_start_time} seconds\\n\") \n",
    "        \n",
    "    #======== EPOCH END ==========================================================================================\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "DataParallel(\n",
      "  (module): MY_SNN_CONV(\n",
      "    (layers): Sequential(\n",
      "      (0): WSConv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), step_mode=m)\n",
      "      (1): LIF_layer()\n",
      "      (2): Scale()\n",
      "      (3): WSConv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), step_mode=m)\n",
      "      (4): LIF_layer()\n",
      "      (5): Scale()\n",
      "      (6): DimChanger_for_pooling(\n",
      "        (ann_module): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
      "      )\n",
      "      (7): WSConv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), step_mode=m)\n",
      "      (8): LIF_layer()\n",
      "      (9): Scale()\n",
      "      (10): WSConv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), step_mode=m)\n",
      "      (11): LIF_layer()\n",
      "      (12): Scale()\n",
      "      (13): DimChanger_for_pooling(\n",
      "        (ann_module): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
      "      )\n",
      "      (14): WSConv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), step_mode=m)\n",
      "      (15): LIF_layer()\n",
      "      (16): Scale()\n",
      "      (17): WSConv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), step_mode=m)\n",
      "      (18): LIF_layer()\n",
      "      (19): Scale()\n",
      "      (20): DimChanger_for_pooling(\n",
      "        (ann_module): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
      "      )\n",
      "      (21): WSConv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), step_mode=m)\n",
      "      (22): LIF_layer()\n",
      "      (23): Scale()\n",
      "      (24): WSConv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), step_mode=m)\n",
      "      (25): LIF_layer()\n",
      "      (26): Scale()\n",
      "      (27): DimChanger_for_FC()\n",
      "      (28): SYNAPSE_FC()\n",
      "    )\n",
      "  )\n",
      ")\n",
      "==================================================\n",
      "My Num of PARAMS: 9,302,410, system's param_num : 9,305,162\n",
      "Memory: 35.49MiB at 32-bit\n",
      "==================================================\n",
      "EPOCH 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "iter_acc: 0-390/391 iter_acc: 47.50%, lr=['0.0001'], iter_loss: 1.4017674922943115, val_acc: 46.89%: 100%|██████████| 391/391 [05:26<00:00,  1.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch_time: 326.67909359931946 seconds\n",
      "\n",
      "EPOCH 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "iter_acc: 1-390/391 iter_acc: 45.00%, lr=['9.999725846827562e-05'], iter_loss: 1.4977728128433228, val_acc: 56.32%: 100%|██████████| 391/391 [05:23<00:00,  1.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch_time: 323.45860838890076 seconds\n",
      "\n",
      "EPOCH 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "iter_acc: 2-390/391 iter_acc: 62.50%, lr=['9.998903417374228e-05'], iter_loss: 1.0750797986984253, val_acc: 59.81%: 100%|██████████| 391/391 [05:24<00:00,  1.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch_time: 324.8094091415405 seconds\n",
      "\n",
      "EPOCH 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "iter_acc: 3-390/391 iter_acc: 63.75%, lr=['9.997532801828658e-05'], iter_loss: 1.0829451084136963, val_acc: 65.52%: 100%|██████████| 391/391 [06:02<00:00,  1.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch_time: 362.96807312965393 seconds\n",
      "\n",
      "EPOCH 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "iter_acc: 4-390/391 iter_acc: 57.50%, lr=['9.995614150494293e-05'], iter_loss: 1.1989320516586304, val_acc: 69.36%: 100%|██████████| 391/391 [05:50<00:00,  1.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch_time: 351.06149792671204 seconds\n",
      "\n",
      "EPOCH 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "iter_acc: 5-390/391 iter_acc: 65.00%, lr=['9.99314767377287e-05'], iter_loss: 1.045722246170044, val_acc: 71.41%: 100%|██████████| 391/391 [05:27<00:00,  1.19it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch_time: 328.05999064445496 seconds\n",
      "\n",
      "EPOCH 6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "iter_acc: 6-390/391 iter_acc: 58.75%, lr=['9.990133642141359e-05'], iter_loss: 0.965335488319397, val_acc: 71.26%: 100%|██████████| 391/391 [05:40<00:00,  1.15it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch_time: 340.899888753891 seconds\n",
      "\n",
      "EPOCH 7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "iter_acc: 7-390/391 iter_acc: 66.25%, lr=['9.986572386122291e-05'], iter_loss: 1.0075533390045166, val_acc: 74.49%: 100%|██████████| 391/391 [06:30<00:00,  1.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch_time: 390.68322920799255 seconds\n",
      "\n",
      "EPOCH 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "iter_acc: 8-390/391 iter_acc: 67.50%, lr=['9.982464296247522e-05'], iter_loss: 0.9709141850471497, val_acc: 74.94%: 100%|██████████| 391/391 [05:52<00:00,  1.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch_time: 352.3251402378082 seconds\n",
      "\n",
      "EPOCH 9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "iter_acc: 9-390/391 iter_acc: 68.75%, lr=['9.9778098230154e-05'], iter_loss: 0.9334923624992371, val_acc: 75.96%: 100%|██████████| 391/391 [05:29<00:00,  1.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch_time: 330.1758978366852 seconds\n",
      "\n",
      "EPOCH 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "iter_acc: 10-390/391 iter_acc: 70.00%, lr=['9.972609476841367e-05'], iter_loss: 0.9027312994003296, val_acc: 77.47%: 100%|██████████| 391/391 [05:25<00:00,  1.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch_time: 325.4601173400879 seconds\n",
      "\n",
      "EPOCH 11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "iter_acc: 11-390/391 iter_acc: 75.00%, lr=['9.966863828001983e-05'], iter_loss: 0.6526696681976318, val_acc: 77.97%: 100%|██████████| 391/391 [05:28<00:00,  1.19it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch_time: 328.17354226112366 seconds\n",
      "\n",
      "EPOCH 12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "iter_acc: 12-390/391 iter_acc: 72.50%, lr=['9.960573506572391e-05'], iter_loss: 0.7605578899383545, val_acc: 78.79%: 100%|██████████| 391/391 [05:35<00:00,  1.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch_time: 335.9755828380585 seconds\n",
      "\n",
      "EPOCH 13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "iter_acc: 13-390/391 iter_acc: 75.00%, lr=['9.95373920235722e-05'], iter_loss: 0.7392961382865906, val_acc: 79.41%: 100%|██████████| 391/391 [05:43<00:00,  1.14it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch_time: 343.9854049682617 seconds\n",
      "\n",
      "EPOCH 14\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "iter_acc: 14-390/391 iter_acc: 78.75%, lr=['9.946361664814943e-05'], iter_loss: 0.6895350813865662, val_acc: 79.43%: 100%|██████████| 391/391 [06:06<00:00,  1.07it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch_time: 366.78809571266174 seconds\n",
      "\n",
      "EPOCH 15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "iter_acc: 15-390/391 iter_acc: 75.00%, lr=['9.93844170297569e-05'], iter_loss: 0.7388668060302734, val_acc: 80.68%: 100%|██████████| 391/391 [06:33<00:00,  1.01s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch_time: 393.40937089920044 seconds\n",
      "\n",
      "EPOCH 16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "iter_acc: 16-390/391 iter_acc: 72.50%, lr=['9.929980185352526e-05'], iter_loss: 0.6179052591323853, val_acc: 81.02%: 100%|██████████| 391/391 [06:00<00:00,  1.08it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch_time: 361.03584003448486 seconds\n",
      "\n",
      "EPOCH 17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "iter_acc: 17-390/391 iter_acc: 83.75%, lr=['9.920978039846208e-05'], iter_loss: 0.4365234971046448, val_acc: 80.16%: 100%|██████████| 391/391 [05:49<00:00,  1.12it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch_time: 349.63509368896484 seconds\n",
      "\n",
      "EPOCH 18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "iter_acc: 18-390/391 iter_acc: 82.50%, lr=['9.911436253643444e-05'], iter_loss: 0.6781880855560303, val_acc: 81.82%: 100%|██████████| 391/391 [05:53<00:00,  1.11it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch_time: 353.80823969841003 seconds\n",
      "\n",
      "EPOCH 19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "iter_acc: 19-390/391 iter_acc: 78.75%, lr=['9.901355873108609e-05'], iter_loss: 0.4251159131526947, val_acc: 82.06%: 100%|██████████| 391/391 [05:38<00:00,  1.16it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch_time: 338.1709837913513 seconds\n",
      "\n",
      "EPOCH 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "iter_acc: 20-390/391 iter_acc: 76.25%, lr=['9.890738003669028e-05'], iter_loss: 0.6073295474052429, val_acc: 81.78%: 100%|██████████| 391/391 [05:31<00:00,  1.18it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch_time: 331.1660842895508 seconds\n",
      "\n",
      "EPOCH 21\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "iter_acc: 21-390/391 iter_acc: 82.50%, lr=['9.879583809693736e-05'], iter_loss: 0.4640195965766907, val_acc: 83.11%: 100%|██████████| 391/391 [05:31<00:00,  1.18it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch_time: 331.32392954826355 seconds\n",
      "\n",
      "EPOCH 22\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "iter_acc: 22-390/391 iter_acc: 83.75%, lr=['9.8678945143658e-05'], iter_loss: 0.5206823348999023, val_acc: 83.53%: 100%|██████████| 391/391 [05:31<00:00,  1.18it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch_time: 331.64914059638977 seconds\n",
      "\n",
      "EPOCH 23\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "iter_acc: 23-390/391 iter_acc: 76.25%, lr=['9.85567139954818e-05'], iter_loss: 0.6114174127578735, val_acc: 83.04%: 100%|██████████| 391/391 [06:07<00:00,  1.06it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch_time: 367.98139333724976 seconds\n",
      "\n",
      "EPOCH 24\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "iter_acc: 24-390/391 iter_acc: 80.00%, lr=['9.842915805643154e-05'], iter_loss: 0.5217031240463257, val_acc: 83.69%: 100%|██████████| 391/391 [06:08<00:00,  1.06it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch_time: 368.84243512153625 seconds\n",
      "\n",
      "EPOCH 25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "iter_acc: 25-310/391 iter_acc: 82.81%, lr=['9.829629131445339e-05'], iter_loss: 0.4359918534755707, val_acc: 83.69%:  80%|███████▉  | 311/391 [04:22<01:02,  1.27it/s] "
     ]
    }
   ],
   "source": [
    "### my_snn control board ########################\n",
    "decay = 0.5 # 0.875 0.25 0.125 0.75 0.5\n",
    "# nda 0.25 # ottt 0.5\n",
    "\n",
    "unique_name = 'mainotttcifar10'\n",
    "\n",
    "my_snn_system(  devices = \"4,5\",\n",
    "                unique_name = unique_name,\n",
    "                my_seed = 42,\n",
    "                TIME = 6 , # dvscifar 10 # ottt 6 or 10 # nda 10  # 제작하는 dvs에서 TIME넘거나 적으면 자르거나 PADDING함\n",
    "                BATCH = 128, # batch norm 할거면 2이상으로 해야함   # nda 256   #  ottt 128\n",
    "                IMAGE_SIZE = 32, # dvscifar 48 # MNIST 28 # CIFAR10 32 # PMNIST 28\n",
    "                # dvsgesture 128, dvs_cifar2 128, nmnist 34, n_caltech101 180,240, n_tidigits 64, heidelberg 700, \n",
    "                #pmnist는 28로 해야 됨. 나머지는 바꿔도 돌아는 감.\n",
    "\n",
    "                # DVS_CIFAR10 할거면 time 10으로 해라\n",
    "                which_data = 'CIFAR10',\n",
    "# 'CIFAR100' 'CIFAR10' 'MNIST' 'FASHION_MNIST' 'DVS_CIFAR10' 'PMNIST'아직\n",
    "# 'DVS_GESTURE','DVS_CIFAR10_2','NMNIST','N_CALTECH101','n_tidigits','heidelberg'\n",
    "                # CLASS_NUM = 10,\n",
    "                data_path = '/data2', # YOU NEED TO CHANGE THIS\n",
    "                rate_coding = False, # True # False\n",
    "\n",
    "                lif_layer_v_init = 0.0,\n",
    "                lif_layer_v_decay = decay,\n",
    "                lif_layer_v_threshold = 1.0,  # 10000이상으로 하면 NDA LIF 씀. #nda 0.5  #ottt 1.0\n",
    "                lif_layer_v_reset = 0, # 10000이상은 hardreset (내 LIF쓰기는 함 ㅇㅇ)\n",
    "                lif_layer_sg_width = 1.0, # # surrogate sigmoid 쓸 때는 의미없음\n",
    "\n",
    "                # synapse_conv_in_channels = IMAGE_PIXEL_CHANNEL,\n",
    "                synapse_conv_kernel_size = 3,\n",
    "                synapse_conv_stride = 1,\n",
    "                synapse_conv_padding = 1,\n",
    "                synapse_conv_trace_const1 = 1,\n",
    "                synapse_conv_trace_const2 = decay, # lif_layer_v_decay\n",
    "\n",
    "                # synapse_fc_out_features = CLASS_NUM,\n",
    "                synapse_fc_trace_const1 = 1,\n",
    "                synapse_fc_trace_const2 = decay, # lif_layer_v_decay\n",
    "\n",
    "                pre_trained = False, # True # False\n",
    "                convTrue_fcFalse = True, # True # False\n",
    "\n",
    "                # 'P' for average pooling, 'D' for (1,1) aver pooling, 'M' for maxpooling, 'L' for linear classifier, [  ] for residual block\n",
    "                # conv에서 10000 이상은 depth-wise separable (BPTT만 지원), 20000이상은 depth-wise (BPTT만 지원)\n",
    "                # cfg = [64],\n",
    "                # cfg = [64,[64,64],64], # 끝에 linear classifier 하나 자동으로 붙습니다\n",
    "                cfg = [64, 128, 'P', 256, 256, 'P', 512, 512, 'P', 512, 512], #ottt\n",
    "                # cfg = [64, 128, 'M', 256, 256, 'M', 512, 512, 'M', 512, 512], # ottt \n",
    "                # cfg = [64, 'P', 128, 'P', 256, 256, 'P', 512, 512, 512, 512, 'D'], # nda\n",
    "                # cfg = [64, 'P', 128, 'P', 256, 256, 'P', 512, 512, 512, 512], # nda 128pixel\n",
    "                # cfg = [64, 'P', 128, 'P', 256, 256, 'P', 512, 512, 512, 512, 'L', 4096, 4096],\n",
    "                # cfg = [20001,10001], # depthwise, separable\n",
    "                # cfg = [64,20064,10001], # vanilla conv, depthwise, separable\n",
    "                # cfg = [8, 'P', 8, 'P', 8, 'P', 8,'P', 8, 'P'],\n",
    "                # cfg = [], \n",
    "                \n",
    "                net_print = False, # True # False\n",
    "                weight_count_print = False, # True # False\n",
    "                pre_trained_path = f\"net_save/save_now_net_{unique_name}.pth\",\n",
    "                learning_rate = 0.0001, # default 0.001  # ottt 0.1 0.00001 # nda 0.001 \n",
    "                epoch_num = 300,\n",
    "                verbose_interval = 999999999, #숫자 크게 하면 꺼짐 #걍 중간중간 iter에서 끊어서 출력\n",
    "                validation_interval = 999999999, #숫자 크게 하면 에포크 마지막 iter 때 val 함\n",
    "\n",
    "                tdBN_on = False,  # True # False\n",
    "                BN_on = False,  # True # False\n",
    "                \n",
    "                surrogate = 'sigmoid', # 'rectangle' 'sigmoid' 'rough_rectangle'\n",
    "                \n",
    "                gradient_verbose = False,  # True # False  # weight gradient 각 layer마다 띄워줌\n",
    "\n",
    "                BPTT_on = False,  # True # False # True이면 BPTT, False이면 OTTT  # depthwise, separable은 BPTT만 가능\n",
    "                optimizer_what = 'SGD', # 'SGD' 'Adam', 'RMSprop'\n",
    "                scheduler_name = 'CosineAnnealingLR', # 'no' 'StepLR' 'ExponentialLR' 'ReduceLROnPlateau' 'CosineAnnealingLR' 'OneCycleLR'\n",
    "                \n",
    "                ddp_on = False,   # True # False\n",
    "\n",
    "                nda_net = False,   # True # False\n",
    "\n",
    "                domain_il_epoch = 0, # over 0, then domain il mode on # pmnist 쓸거면 HLOP 코드보고 더 디벨롭하셈. 지금 개발 hold함.\n",
    "                \n",
    "                dvs_clipping = True, # dvs zero&one  # gesture, cifar-dvs2, nmnist, ncaltech101\n",
    "                dvs_duration = 1000000, # 0 아니면 time sampling # dvs number sampling OR time sampling # gesture, cifar-dvs2, nmnist, ncaltech101\n",
    "                #있는 데이터들 #gesture 1000000 #nmnist 10000\n",
    "\n",
    "                OTTT_sWS_on = True, # True # False # BPTT끄고, CONV에만 적용됨.\n",
    "                ) \n",
    "# sigmoid와 BN이 있어야 잘된다.\n",
    "# average pooling이 낫다. \n",
    "\n",
    "# nda에서는 decay = 0.25, threshold = 0.5, width =1, surrogate = rectangle, batch = 256, tdBN = True\n",
    "## OTTT 에서는 decay = 0.5, threshold = 1.0, surrogate = sigmoid, batch = 128, BN = True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "\n",
    "def pad_array_to_match_length(array1, array2):\n",
    "    if len(array1) > len(array2):\n",
    "        padded_array2 = np.pad(array2, (0, len(array1) - len(array2)), 'constant')\n",
    "        return array1, padded_array2\n",
    "    elif len(array2) > len(array1):\n",
    "        padded_array1 = np.pad(array1, (0, len(array2) - len(array1)), 'constant')\n",
    "        return padded_array1, array2\n",
    "    else:\n",
    "        return array1, array2\n",
    "def load_hyperparameters(filename='hyperparameters.json'):\n",
    "    with open(filename, 'r') as f:\n",
    "        return json.load(f)\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "current_time = '20240628_110116'\n",
    "base_name = f'{current_time}'\n",
    "iter_acc_file_name = f'result_save/{base_name}_iter_acc_array_{unique_name}.npy'\n",
    "val_acc_file_name = f'result_save/{base_name}_val_acc_now_array_{unique_name}.npy'\n",
    "hyperparameters_file_name = f'result_save/{base_name}_hyperparameters_{unique_name}.json'\n",
    "\n",
    "### if you want to just see most recent train and val acc###########################\n",
    "iter_acc_file_name = f'result_save/iter_acc_array_{unique_name}.npy'\n",
    "tr_acc_file_name = f'result_save/tr_acc_array_{unique_name}.npy'\n",
    "val_acc_file_name = f'result_save/val_acc_now_array_{unique_name}.npy'\n",
    "hyperparameters_file_name = f'result_save/hyperparameters_{unique_name}.json'\n",
    "\n",
    "loaded_iter_acc_array = np.load(iter_acc_file_name)*100\n",
    "loaded_tr_acc_array = np.load(tr_acc_file_name)*100\n",
    "loaded_val_acc_array = np.load(val_acc_file_name)*100\n",
    "hyperparameters = load_hyperparameters(hyperparameters_file_name)\n",
    "\n",
    "loaded_iter_acc_array, loaded_val_acc_array = pad_array_to_match_length(loaded_iter_acc_array, loaded_val_acc_array)\n",
    "loaded_iter_acc_array, loaded_tr_acc_array = pad_array_to_match_length(loaded_iter_acc_array, loaded_tr_acc_array)\n",
    "loaded_val_acc_array, loaded_tr_acc_array = pad_array_to_match_length(loaded_val_acc_array, loaded_tr_acc_array)\n",
    "\n",
    "top_iter_acc = np.max(loaded_iter_acc_array)\n",
    "top_tr_acc = np.max(loaded_tr_acc_array)\n",
    "top_val_acc = np.max(loaded_val_acc_array)\n",
    "\n",
    "which_data = hyperparameters['which_data']\n",
    "BPTT_on = hyperparameters['BPTT_on']\n",
    "current_epoch = hyperparameters['current epoch']\n",
    "surrogate = hyperparameters['surrogate']\n",
    "cfg = hyperparameters['cfg']\n",
    "tdBN_on = hyperparameters['tdBN_on']\n",
    "BN_on = hyperparameters['BN_on']\n",
    "\n",
    "\n",
    "iterations = np.arange(len(loaded_iter_acc_array))\n",
    "\n",
    "# 그래프 그리기\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(iterations, loaded_iter_acc_array, label='Iter Accuracy', color='g', alpha=0.2)\n",
    "plt.plot(iterations, loaded_tr_acc_array, label='Training Accuracy', color='b')\n",
    "plt.plot(iterations, loaded_val_acc_array, label='Validation Accuracy', color='r')\n",
    "\n",
    "# # 텍스트 추가\n",
    "# plt.text(0.05, 0.95, f'Top Training Accuracy: {100*top_iter_acc:.2f}%', transform=plt.gca().transAxes, fontsize=12, verticalalignment='top', horizontalalignment='left', color='blue')\n",
    "# plt.text(0.05, 0.90, f'Top Validation Accuracy: {100*top_val_acc:.2f}%', transform=plt.gca().transAxes, fontsize=12, verticalalignment='top', horizontalalignment='left', color='red')\n",
    "# 텍스트 추가\n",
    "plt.text(0.5, 0.10, f'Top Training Accuracy: {top_tr_acc:.2f}%', transform=plt.gca().transAxes, fontsize=12, verticalalignment='top', horizontalalignment='center', color='blue')\n",
    "plt.text(0.5, 0.05, f'Top Validation Accuracy: {top_val_acc:.2f}%', transform=plt.gca().transAxes, fontsize=12, verticalalignment='top', horizontalalignment='center', color='red')\n",
    "\n",
    "plt.xlabel('Iterations')\n",
    "plt.ylabel('Accuracy [%]')\n",
    "\n",
    "# 그래프 제목에 하이퍼파라미터 정보 추가\n",
    "title = f'Training and Validation Accuracy over Iterations\\n\\nData: {which_data}, BPTT: {\"On\" if BPTT_on else \"Off\"}, Current Epoch: {current_epoch}, Surrogate: {surrogate},\\nCFG: {cfg}, tdBN: {\"On\" if tdBN_on else \"Off\"}, BN: {\"On\" if BN_on else \"Off\"}'\n",
    "\n",
    "plt.title(title)\n",
    "\n",
    "plt.legend(loc='lower right')\n",
    "plt.xlim(0)  # x축을 0부터 시작\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import snntorch as snn\n",
    "from snntorch.spikevision import spikedata\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "\n",
    "# root, train=True, transform=None, target_transform=None, download_and_create=True, num_steps=1000, ds=1, dt=1000)\n",
    "train_ds = spikedata.SHD(\"/data2/Heidelberg\", train=True)\n",
    "test_ds = spikedata.SHD(\"/data2/Heidelberg\", train=False)\n",
    "\n",
    "# create dataloaders\n",
    "train_dl = DataLoader(train_ds, shuffle=True, batch_size=64) # 8156x2x1000x700\n",
    "test_dl = DataLoader(test_ds, shuffle=False, batch_size=64) # 2264x2x1000x700\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import snntorch.spikeplot as splt\n",
    "\n",
    "# choose a random sample\n",
    "n = 6295\n",
    "\n",
    "# initialize figure and axes\n",
    "fig = plt.figure(facecolor=\"w\", figsize=(10, 5))\n",
    "ax = fig.add_subplot(111)\n",
    "\n",
    "# use spikeplot to generate a raster\n",
    "splt.raster(train_dl.dataset[n][0], ax, s=1.5, c=\"black\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nfs",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
