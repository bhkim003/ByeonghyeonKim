{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ssp.train.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x600 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import torch   \n",
    "import torch.nn as nn \n",
    "import torch.nn.functional as F   \n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import torch.optim as optim\n",
    "from scipy import io\n",
    "import itertools\n",
    "import math\n",
    "import datetime\n",
    "import wandb\n",
    "import pickle\n",
    "import json\n",
    "import time\n",
    "\n",
    "# my module import\n",
    "from modules import *\n",
    "\n",
    "# modules 폴더에 새모듈.py 만들면\n",
    "# modules/__init__py 파일에 form .새모듈 import * 하셈\n",
    "# 그리고 새모듈.py에서 from modules.새모듈 import * 하셈"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cluster_train_system( \n",
    "    gpu = 3,\n",
    "    Conv_net = True,\n",
    "    SAE_net = True,\n",
    "\n",
    "    # hyperparameter\n",
    "    dataset_num = 16,\n",
    "    spike_length = 50,\n",
    "    num_cluster = 4,  # 클러스터 수 설정 # 논문엔 4개라는데 여기서는 3개로 했네\n",
    "    training_cycle = 2400, # 그 초기 몇개까지만 cluster update할지\n",
    "\n",
    "\n",
    "    batch_size = 32,\n",
    "    max_epoch = 7000,\n",
    "    learning_rate = 0.001,\n",
    "    normalize_on = False, # True or False #이거 안 씀 # 이거 별로 안 좋은 normalize같음 # 쓸 거면 다른 거 써라.\n",
    "    need_bias = False,\n",
    "    # first_layer_no_train = False\n",
    "    lif_add_at_first = False,\n",
    "    my_seed = 42,\n",
    "\n",
    "    TIME = 10, # SAE일 때만 유효\n",
    "    v_decay = 0.5,\n",
    "    v_threshold = 0.5,\n",
    "    v_reset = 10000.0, # 10000이상 일 시 hard reset\n",
    "    BPTT_on = True,\n",
    "\n",
    "    SAE_hidden_nomean = True,\n",
    "    current_time = '20250101_210938_786',\n",
    "\n",
    "    optimizer = 'Adam',\n",
    "    ):\n",
    "    seed_assign(my_seed)\n",
    "    \n",
    "    ## 함수 내 모든 로컬 변수 저장 ########################################################\n",
    "    hyperparameters = locals()\n",
    "    print(hyperparameters)\n",
    "    # JSON으로 저장\n",
    "    with open(f\"result_save/cluster_accuracy_history_{current_time}.json\", 'w') as f:\n",
    "        json.dump(hyperparameters, f, indent=4)\n",
    "\n",
    "    ######################################################################################\n",
    "\n",
    "    \n",
    "    wandb.config.update(hyperparameters)\n",
    "    wandb.run.name = f'{current_time}_SAE_net_{SAE_net}_v_threshold_{v_threshold}'\n",
    "    wandb.define_metric(\"best_mean_cluster_accuracy_post_training_cycle_all_dataset\", summary=\"max\")\n",
    "\n",
    "    my_path_ground_BH = '/data2/spike_sorting/quiroga/BH/'\n",
    "\n",
    "\n",
    "    filename = [\"C_Easy1_noise005.mat\", \"C_Easy1_noise01.mat\", \"C_Easy1_noise015.mat\", \"C_Easy1_noise02.mat\",\n",
    "                \"C_Easy2_noise005.mat\", \"C_Easy2_noise01.mat\", \"C_Easy2_noise015.mat\", \"C_Easy2_noise02.mat\",\n",
    "                \"C_Difficult1_noise005.mat\", \"C_Difficult1_noise01.mat\", \"C_Difficult1_noise015.mat\", \"C_Difficult1_noise02.mat\",\n",
    "                \"C_Difficult2_noise005.mat\", \"C_Difficult2_noise01.mat\", \"C_Difficult2_noise015.mat\", \"C_Difficult2_noise02.mat\"]\n",
    "\n",
    "\n",
    "    spike_tot = [\"BH_Spike_e1n005.npy\", \"BH_Spike_e1n010.npy\", \"BH_Spike_e1n015.npy\", \"BH_Spike_e1n020.npy\",\n",
    "                \"BH_Spike_e2n005.npy\", \"BH_Spike_e2n010.npy\", \"BH_Spike_e2n015.npy\", \"BH_Spike_e2n020.npy\",\n",
    "                \"BH_Spike_d1n005.npy\", \"BH_Spike_d1n010.npy\", \"BH_Spike_d1n015.npy\", \"BH_Spike_d1n020.npy\",\n",
    "                \"BH_Spike_d2n005.npy\", \"BH_Spike_d2n010.npy\", \"BH_Spike_d2n015.npy\", \"BH_Spike_d2n020.npy\"]\n",
    "\n",
    "    label_tot = [\"BH_Label_e1n005.npy\", \"BH_Label_e1n010.npy\", \"BH_Label_e1n015.npy\", \"BH_Label_e1n020.npy\",\n",
    "                \"BH_Label_e2n005.npy\", \"BH_Label_e2n010.npy\", \"BH_Label_e2n015.npy\", \"BH_Label_e2n020.npy\",\n",
    "                \"BH_Label_d1n005.npy\", \"BH_Label_d1n010.npy\", \"BH_Label_d1n015.npy\", \"BH_Label_d1n020.npy\",\n",
    "                \"BH_Label_d2n005.npy\", \"BH_Label_d2n010.npy\", \"BH_Label_d2n015.npy\", \"BH_Label_d2n020.npy\"]\n",
    "\n",
    "    template =  [\"BH_Spike_TEMPLATE_e1n005.npy\", \"BH_Spike_TEMPLATE_e1n010.npy\", \"BH_Spike_TEMPLATE_e1n015.npy\", \"BH_Spike_TEMPLATE_e1n020.npy\",\n",
    "                \"BH_Spike_TEMPLATE_e2n005.npy\", \"BH_Spike_TEMPLATE_e2n010.npy\", \"BH_Spike_TEMPLATE_e2n015.npy\", \"BH_Spike_TEMPLATE_e2n020.npy\",\n",
    "                \"BH_Spike_TEMPLATE_d1n005.npy\", \"BH_Spike_TEMPLATE_d1n010.npy\", \"BH_Spike_TEMPLATE_d1n015.npy\", \"BH_Spike_TEMPLATE_d1n020.npy\",\n",
    "                \"BH_Spike_TEMPLATE_d2n005.npy\", \"BH_Spike_TEMPLATE_d2n010.npy\", \"BH_Spike_TEMPLATE_d2n015.npy\", \"BH_Spike_TEMPLATE_d2n020.npy\"]\n",
    "\n",
    "    AE_train_path_gt_detect = 'BH_quiroga_training_dataset_gt_detect.pt' \n",
    "    AE_test_path_gt_detect = 'BH_quiroga_test_dataset_gt_detect.pt'\n",
    "\n",
    "    AE_train_path_real_detect = 'BH_quiroga_training_dataset_real_detect.pt'\n",
    "    AE_test_path_real_detect = 'BH_quiroga_test_dataset_real_detect.pt'\n",
    "\n",
    "    AE_train_data = AE_train_path_real_detect #AE_train_path_gt_detect #AE_train_path_real_detect\n",
    "    AE_test_data = AE_test_path_real_detect #AE_test_path_gt_detect  #AE_test_path_real_detect\n",
    "\n",
    "    # thr_tot = np.array([0.5, 0.5, 0.55, 0.7, 0.5, 0.5, 0.55, 0.7, 0.5, 0.5, 0.55, 0.7, 0.5, 0.5, 0.55, 0.7])\n",
    "    cos_thr = np.array([0.95, 0.95, 0.95, 0.95, 0.95, 0.95, 0.95, 0.85, 0.95, 0.9, 0.8, 0.95, 0.95, 0.95, 0.95, 0.8])\n",
    "\n",
    "\n",
    "    os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\" \n",
    "    os.environ[\"CUDA_VISIBLE_DEVICES\"]= f'{gpu}'\n",
    "\n",
    "    n_sample = spike_length\n",
    "\n",
    "\n",
    "    class spikedataset(Dataset):\n",
    "        def __init__(self, path, transform = None):    \n",
    "            self.transform = transform\n",
    "            self.spike = torch.load(path)\n",
    "            \n",
    "        def __getitem__(self, index):\n",
    "            spike = self.spike[index]            \n",
    "            if self.transform is not None:\n",
    "                spike = self.transform(spike)\n",
    "            return spike\n",
    "        \n",
    "        def __len__(self):\n",
    "            return len(self.spike)\n",
    "\n",
    "    train_dataset = spikedataset(my_path_ground_BH + AE_train_data)\n",
    "    train_loader = DataLoader(dataset = train_dataset, batch_size = batch_size, shuffle = True)\n",
    "\n",
    "    test_dataset = spikedataset(my_path_ground_BH + AE_test_data)\n",
    "    test_loader = DataLoader(dataset = test_dataset, batch_size = batch_size, shuffle = False)\n",
    "\n",
    "\n",
    "\n",
    "    # 모델 초기화\n",
    "    if SAE_net == False:\n",
    "        if Conv_net == True:\n",
    "            net = Autoencoder_conv1(input_channels=1, input_length=n_sample, encoder_ch = [32, 64, 96], fc_dim = 4, padding = 0, stride = 2, kernel_size = 3, need_bias=need_bias)\n",
    "            net = torch.nn.DataParallel(net)\n",
    "        else:\n",
    "            net = Autoencoder_only_FC(encoder_ch=[96, 64, 32, 4], decoder_ch=[32,64,96,n_sample], n_sample=n_sample, need_bias=need_bias)\n",
    "            net = torch.nn.DataParallel(net)\n",
    "    else:\n",
    "        if Conv_net == True: \n",
    "            net = SAE_conv1(input_channels=1, input_length=n_sample, encoder_ch = [32, 64, 96], fc_dim = 4, padding = 0, stride = 2, kernel_size = 3, \n",
    "                                synapse_fc_trace_const1=1, \n",
    "                                synapse_fc_trace_const2=v_decay, #안씀 \n",
    "                                TIME=TIME, v_init=0.0, v_decay=v_decay, v_threshold=v_threshold, v_reset=v_reset, \n",
    "                                sg_width=4.0, surrogate='sigmoid', BPTT_on=BPTT_on, need_bias=need_bias, lif_add_at_first=lif_add_at_first)\n",
    "            net = torch.nn.DataParallel(net)\n",
    "        else:\n",
    "            net = SAE_fc_only(encoder_ch=[96, 64, 32, 4], \n",
    "                                decoder_ch=[32,64,96,n_sample], \n",
    "                                in_channels=n_sample, # in_channel 이 여기선 걍 lenght.\n",
    "                                synapse_fc_trace_const1=1,\n",
    "                                synapse_fc_trace_const2=v_decay,  #안씀 \n",
    "                                TIME=TIME, v_init=0.0, v_decay=v_decay, v_threshold=v_threshold, v_reset=v_reset, \n",
    "                                sg_width=4.0, surrogate='sigmoid', BPTT_on=BPTT_on, need_bias=need_bias, lif_add_at_first=lif_add_at_first)\n",
    "            net = torch.nn.DataParallel(net)\n",
    "\n",
    "    # net = torch.load('/home/bhkim003/github_folder/ByeonghyeonKim/my_snn/net_save/save_now_net_AE_re_e7000.pth')\n",
    "    # net = torch.load('/home/bhkim003/github_folder/ByeonghyeonKim/my_snn/net_save/save_now_net_20250101_210938_786.pth')\n",
    "    # load했으면 torch.nn.DataParallel 하지마\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    wandb.watch(net, log=\"all\", log_freq = 10)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    if SAE_net == True:\n",
    "        assert 'SAE' in net.module.__class__.__name__\n",
    "\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "\n",
    "    net = net.to(device)\n",
    "    print(net)\n",
    "    print('Device:',device)\n",
    "\n",
    "    criterion = nn.MSELoss()\n",
    "    \n",
    "    if optimizer == 'Adam':\n",
    "        optimizer = optim.Adam(net.parameters(), lr=learning_rate)\n",
    "    elif optimizer == 'SGD':\n",
    "        optimizer = optim.SGD(net.parameters(), lr = learning_rate, momentum = 0.9)\n",
    "    else:\n",
    "        assert False, 'optimizer를 잘못 입력했습니다.'\n",
    "        \n",
    "    loss_history = []\n",
    "    mean_cluster_accuracy_during_training_cycle_all_dataset_history = []\n",
    "    mean_cluster_accuracy_post_training_cycle_all_dataset_history = []\n",
    "    mean_cluster_accuracy_total_all_dataset_history = []\n",
    "\n",
    "    tau = np.zeros(num_cluster)\n",
    "\n",
    "    print(f\"\\nStart Training, current_time = {current_time}\")\n",
    "    mean_cluster_accuracy_post_training_cycle_all_dataset = 0\n",
    "    best_mean_cluster_accuracy_post_training_cycle_all_dataset = 0\n",
    "\n",
    "\n",
    "    for epoch in range(max_epoch):\n",
    "\n",
    "        ae_train_start_time = time.time()\n",
    "        running_loss = 0.0\n",
    "        net.train()\n",
    "        for data in train_loader:\n",
    "            optimizer.zero_grad()\n",
    "            spike = data\n",
    "            spike = spike.to(device)\n",
    "            if 'SAE' in net.module.__class__.__name__:\n",
    "                spike = spike.unsqueeze(-1).repeat(1, 1, TIME).permute(0,2,1) # (batch, time, feature)로 변환\n",
    "            spike_class = net(spike)\n",
    "\n",
    "            # if 'SAE' in net.module.__class__.__name__:\n",
    "            #     spike = spike.mean(dim=1)# Time 방향으로 평균\n",
    "            #     spike_class = spike_class.mean(dim=1)# Time 방향으로 평균\n",
    "\n",
    "            if 'SAE' in net.module.__class__.__name__:\n",
    "                loss1 = criterion(spike_class[:, :, 5:25], spike[:, :, 5:25])\n",
    "                loss2 = criterion(spike_class[:, :, 0:5], spike[:, :, 0:5])\n",
    "                loss3 = criterion(spike_class[:, :, 25:spike_length], spike[:, :, 25:spike_length])\n",
    "            else:\n",
    "                loss1 = criterion(spike_class[:, 5:25], spike[:, 5:25])\n",
    "                loss2 = criterion(spike_class[:, 0:5], spike[:, 0:5])\n",
    "                loss3 = criterion(spike_class[:, 25:spike_length], spike[:, 25:spike_length])\n",
    "\n",
    "            loss = loss1 * 2.125 + (loss2 + loss3)/4\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_loss += loss.item()\n",
    "            # print(f'\\nepoch-{epoch} running_loss : {running_loss:.5f}')\n",
    "        avg_loss = running_loss / len(train_loader)\n",
    "        loss_history.append((epoch, avg_loss))\n",
    "        print(f'\\nepoch-{epoch} loss : {avg_loss:.5f}')\n",
    "        print(f\"ae train 실행 시간: {time.time()-ae_train_start_time:.3f}초\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        cluster_accuracy_during_training_cycle_all_dataset = np.zeros(dataset_num)\n",
    "        cluster_accuracy_post_training_cycle_all_dataset = np.zeros(dataset_num)\n",
    "        cluster_accuracy_total_all_dataset = np.zeros(dataset_num)    \n",
    "\n",
    "        if(epoch %5 ==0 or epoch == 1): \n",
    "            accuracy_check_start_time = time.time()\n",
    "            print(f'\\nepoch-{epoch} accuracy check')\n",
    "            for ds in range(dataset_num):\n",
    "                # print('\\n', spike_tot[ds])\n",
    "\n",
    "                spike_template = np.load(my_path_ground_BH + template[ds])\n",
    "                spike = np.load(my_path_ground_BH + spike_tot[ds])\n",
    "                label = np.load(my_path_ground_BH + label_tot[ds])\n",
    "                \n",
    "                hidden_size = 4*TIME if 'SAE' in net.module.__class__.__name__ and SAE_hidden_nomean == True else 4\n",
    "\n",
    "                Cluster = np.zeros((num_cluster, hidden_size))\n",
    "                assert Cluster.shape[-1] == hidden_size, '이거 hidden dim 4 아니게 할 거면 잘 바꿔라'\n",
    "                \n",
    "                net.eval()\n",
    "                with torch.no_grad():\n",
    "                    spike_torch = torch.from_numpy(spike_template)\n",
    "                    spike_torch = spike_torch.float().to(device)\n",
    "                    if 'SAE' in net.module.__class__.__name__:\n",
    "                        spike_torch = spike_torch.unsqueeze(1).repeat(1, TIME, 1) # (batch, time, feature)로 변환\n",
    "                    inner_inf = net.module.encoder(spike_torch)\n",
    "                    # if 'SAE' in net.module.__class__.__name__:\n",
    "                    #     tensors = [inner_inf[0][i] for i in range(TIME)] \n",
    "                    #     all_equal = all(torch.equal(tensors[0], t) for t in tensors)\n",
    "                    #     print(all_equal, inner_inf)\n",
    "\n",
    "                    if 'SAE' in net.module.__class__.__name__:\n",
    "                        if SAE_hidden_nomean == True:\n",
    "                            inner_inf = inner_inf.reshape(spike_template.shape[0],-1)# time*feature 펼치기\n",
    "                        else:\n",
    "                            inner_inf = inner_inf.mean(dim=1)# Time 방향으로 평균\n",
    "                    Cluster = inner_inf.cpu().detach().numpy()\n",
    "\n",
    "                encoder_batch = 128\n",
    "                spike_hidden = np.zeros((len(spike), hidden_size))\n",
    "                net.eval()\n",
    "                with torch.no_grad():\n",
    "                    now_index = 0\n",
    "                    while (1):\n",
    "                        now_end_index = now_index+encoder_batch if now_index+encoder_batch < len(spike) else len(spike)\n",
    "                        spike_batch = spike[now_index:now_end_index] \n",
    "                        spike_torch = torch.from_numpy(spike_batch)\n",
    "                        spike_torch = spike_torch.float().to(device)\n",
    "                        if 'SAE' in net.module.__class__.__name__:\n",
    "                            spike_torch = spike_torch.unsqueeze(1).repeat(1, TIME, 1) # (batch, time, feature)로 변환\n",
    "                        inner_inf = net.module.encoder(spike_torch)\n",
    "                        if 'SAE' in net.module.__class__.__name__:\n",
    "                            if SAE_hidden_nomean == True:\n",
    "                                inner_inf = inner_inf.reshape(spike_batch.shape[0],-1)# 펼치기\n",
    "                            else:\n",
    "                                inner_inf = inner_inf.mean(dim=1)# Time 방향으로 평균\n",
    "                        spike_hidden[now_index:now_end_index] = inner_inf.cpu().detach().numpy()\n",
    "                        now_index += encoder_batch\n",
    "                        if (now_index >= len(spike)):\n",
    "                            break\n",
    "                    \n",
    "                spike_id = np.zeros(len(spike))\n",
    "                distance_sm = np.zeros(num_cluster)\n",
    "                tau = np.zeros(num_cluster)\n",
    "                \n",
    "                for spike_index in range(len(spike)): \n",
    "                    for q in range(num_cluster):\n",
    "                        tau[q] = np.dot(spike_hidden[spike_index, :], Cluster[q, :]) # 이거 l2norm 거쳐서 나온 거니까 분모 1임.\n",
    "                        if 'SAE' in net.module.__class__.__name__: # AE 때는 l2norm거쳐서 나와서 괜찮음\n",
    "                            denominator =  np.linalg.norm(spike_hidden[spike_index, :])*np.linalg.norm(Cluster[q, :]) + 1e-12\n",
    "                            tau[q] = tau[q] / denominator\n",
    "\n",
    "                    # for i in range(num_cluster): # l2 distance\n",
    "                    #     distance_sm[i] = np.sum(np.power(np.abs(Cluster[i] - spike_hidden[spike_index, :]), 2))\n",
    "                    distance_sm = np.sum(np.power(np.abs(Cluster - spike_hidden[spike_index, :]), 2), axis=1)\n",
    "\n",
    "                    m = np.argmin(distance_sm)\n",
    "                    spike_id[spike_index] = m + 1\n",
    "                    # print(spike_tot[ds], spike_index,np.max(tau))\n",
    "                    if(np.max(tau) >= cos_thr[ds] and spike_index < training_cycle): # 원래 1400 아니냐?\n",
    "                        Cluster[m] = (Cluster[m] * 15 + spike_hidden[spike_index, :])/16\n",
    "                \n",
    "                # print('Cluster',Cluster)\n",
    "                # print('spike_id', spike_id)\n",
    "\n",
    "                # spike id 분포 확인하기\n",
    "                # unique_elements, counts = np.unique(spike_id, return_counts=True)\n",
    "                # print(\"Unique elements:\", unique_elements)\n",
    "                # print(\"Counts:\", counts)\n",
    "\n",
    "                cluster_accuracy_during_training_cycle = np.zeros(math.factorial(num_cluster))\n",
    "                cluster_accuracy_post_training_cycle = np.zeros(math.factorial(num_cluster))\n",
    "                cluster_accuracy_total = np.zeros(math.factorial(num_cluster))\n",
    "                \n",
    "                label_converter_ground = list(range(1, num_cluster + 1)) # [1, 2, 3, 4] 생성\n",
    "                label_converter_permutations = list(itertools.permutations(label_converter_ground)) # 모든 순열 구하기\n",
    "                perm_i = 0\n",
    "                perm_start_time = time.time()\n",
    "                for perm in label_converter_permutations:\n",
    "                    label_converter = list(perm)\n",
    "                    # print(label_converter)\n",
    "                    correct_during_training_cycle = 0\n",
    "                    correct_post_training_cycle = 0\n",
    "\n",
    "                    assert len(spike_id) == len(label), 'spike_id랑 label 길이 같아야 됨.'\n",
    "                    for i in range(len(spike_id)):\n",
    "                        if(label_converter[int(spike_id[i]-1)] == label[i]):\n",
    "                            if i < training_cycle:\n",
    "                                correct_during_training_cycle += 1\n",
    "                            else:\n",
    "                                correct_post_training_cycle += 1\n",
    "\n",
    "                    cluster_accuracy_during_training_cycle[perm_i] = correct_during_training_cycle/training_cycle\n",
    "                    cluster_accuracy_post_training_cycle[perm_i] = correct_post_training_cycle/(len(spike_id)-training_cycle)\n",
    "                    cluster_accuracy_total[perm_i] = (correct_during_training_cycle+correct_post_training_cycle)/(len(spike_id))\n",
    "                    perm_i += 1\n",
    "                # print(f\"perm 실행 시간: {time.time()-perm_start_time:.3f}초\")\n",
    "                \n",
    "                cluster_accuracy_during_training_cycle_all_dataset[ds] = np.max(cluster_accuracy_during_training_cycle)\n",
    "                cluster_accuracy_post_training_cycle_all_dataset[ds] = cluster_accuracy_post_training_cycle[np.argmax(cluster_accuracy_during_training_cycle)]\n",
    "                cluster_accuracy_total_all_dataset[ds] = cluster_accuracy_total[np.argmax(cluster_accuracy_during_training_cycle)]\n",
    "\n",
    "            print('cluster_accuracy_post_training_cycle_all_dataset', cluster_accuracy_post_training_cycle_all_dataset)\n",
    "\n",
    "            mean_cluster_accuracy_during_training_cycle_all_dataset = np.mean(cluster_accuracy_during_training_cycle_all_dataset)\n",
    "            mean_cluster_accuracy_post_training_cycle_all_dataset = np.mean(cluster_accuracy_post_training_cycle_all_dataset)\n",
    "            mean_cluster_accuracy_total_all_dataset = np.mean(cluster_accuracy_total_all_dataset)\n",
    "            \n",
    "            mean_cluster_accuracy_during_training_cycle_all_dataset_history.append((epoch, mean_cluster_accuracy_during_training_cycle_all_dataset*100))\n",
    "            mean_cluster_accuracy_post_training_cycle_all_dataset_history.append((epoch, mean_cluster_accuracy_post_training_cycle_all_dataset*100))\n",
    "            mean_cluster_accuracy_total_all_dataset_history.append((epoch, mean_cluster_accuracy_total_all_dataset*100))\n",
    "            print(f\"mean_cluster_accuracy_during_training_cycle : {mean_cluster_accuracy_during_training_cycle_all_dataset*100:.2f}%, post_traincycle_acc : {mean_cluster_accuracy_post_training_cycle_all_dataset*100:.2f}%, total_acc : {mean_cluster_accuracy_total_all_dataset*100:.2f}%\")\n",
    "\n",
    "            if mean_cluster_accuracy_post_training_cycle_all_dataset > best_mean_cluster_accuracy_post_training_cycle_all_dataset:\n",
    "                # torch.save(net, f\"net_save/save_now_net_{current_time}.pth\")\n",
    "                # print('save model')\n",
    "                best_mean_cluster_accuracy_post_training_cycle_all_dataset = mean_cluster_accuracy_post_training_cycle_all_dataset\n",
    "            print(f\"best_mean_cluster_accuracy_post_training_cycle_all_dataset : {best_mean_cluster_accuracy_post_training_cycle_all_dataset*100:.2f}%\")\n",
    "            print(f\"accuracy_check 실행 시간: {time.time()-accuracy_check_start_time:.3f}초\")\n",
    "\n",
    "        wandb.log({\"avg_loss\": avg_loss})\n",
    "        wandb.log({\"mean_cluster_accuracy_post_training_cycle_all_dataset\": mean_cluster_accuracy_post_training_cycle_all_dataset})\n",
    "        wandb.log({\"best_mean_cluster_accuracy_post_training_cycle_all_dataset\": best_mean_cluster_accuracy_post_training_cycle_all_dataset})\n",
    "\n",
    "\n",
    "        # 저장\n",
    "        with open(f\"result_save/cluster_accuracy_history_{current_time}.pkl\", \"wb\") as f:\n",
    "            pickle.dump({\n",
    "                \"loss_history\": loss_history,\n",
    "                \"mean_cluster_accuracy_during_training_cycle_all_dataset_history\": mean_cluster_accuracy_during_training_cycle_all_dataset_history,\n",
    "                \"mean_cluster_accuracy_post_training_cycle_all_dataset_history\": mean_cluster_accuracy_post_training_cycle_all_dataset_history,\n",
    "                \"mean_cluster_accuracy_total_all_dataset_history\": mean_cluster_accuracy_total_all_dataset_history,\n",
    "            }, f)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# gpu = 5\n",
    "# Conv_net = True\n",
    "# SAE_net = True\n",
    "\n",
    "# # hyperparameter\n",
    "# dataset_num = 16\n",
    "# spike_length = 50\n",
    "# num_cluster = 4  # 클러스터 수 설정 # 논문엔 4개라는데 여기서는 3개로 했네\n",
    "# training_cycle = 1400 #1400 2400 # 그 초기 몇개까지만 cluster update할지\n",
    "\n",
    "\n",
    "# batch_size = 16\n",
    "# max_epoch = 7000\n",
    "# learning_rate = 0.001\n",
    "# normalize_on = False # True or False #이거 안 씀 # 이거 별로 안 좋은 normalize같음 # 쓸 거면 다른 거 써라.\n",
    "# need_bias = False\n",
    "# # first_layer_no_train = False\n",
    "# lif_add_at_first = False\n",
    "# my_seed = 42\n",
    "\n",
    "# TIME = 8 # SAE일 때만 유효\n",
    "# v_decay = 0.5 # -cor\n",
    "# v_threshold = 0.25 # -cor\n",
    "# v_reset = 10000.0 # -cor # 10000이상 일 시 hard reset\n",
    "# BPTT_on = True # +cor\n",
    "\n",
    "# SAE_hidden_nomean = False # False가 나았다 이상하게.\n",
    "\n",
    "# current_time = datetime.datetime.now().strftime(\"%Y%m%d_%H%M%S\") + f\"_{str(int(datetime.datetime.now().microsecond / 1000)).zfill(3)}\"\n",
    "\n",
    "# optimizer = 'Adam' #'Adam', 'SGD' # 둘다 준수함. loss 줄이는 거는 adam이 좋긴한데, cluster accuracy는 비슷함.\n",
    "\n",
    "# wandb.init(project= f'spike_sorting just run',save_code=False)\n",
    "\n",
    "# cluster_train_system( \n",
    "#     gpu = gpu,\n",
    "#     Conv_net = Conv_net,\n",
    "#     SAE_net = SAE_net,\n",
    "\n",
    "#     # hyperparameter\n",
    "#     dataset_num = dataset_num,\n",
    "#     spike_length = spike_length,\n",
    "#     num_cluster = num_cluster,  # 클러스터 수 설정 # 논문엔 4개라는데 여기서는 3개로 했네\n",
    "#     training_cycle = training_cycle, # 그 초기 몇개까지만 cluster update할지\n",
    "\n",
    "\n",
    "#     batch_size = batch_size,\n",
    "#     max_epoch = max_epoch,\n",
    "#     learning_rate = learning_rate,\n",
    "#     normalize_on = normalize_on, # True or False #이거 안 씀 # 이거 별로 안 좋은 normalize같음 # 쓸 거면 다른 거 써라.\n",
    "#     need_bias = need_bias,\n",
    "#     # first_layer_no_train = False\n",
    "#     lif_add_at_first = lif_add_at_first,\n",
    "#     my_seed = my_seed,\n",
    "\n",
    "#     TIME = TIME, # SAE일 때만 유효\n",
    "#     v_decay = v_decay,\n",
    "#     v_threshold = v_threshold,\n",
    "#     v_reset = v_reset, # 10000이상 일 시 hard reset\n",
    "#     BPTT_on = BPTT_on,\n",
    "\n",
    "#     SAE_hidden_nomean = SAE_hidden_nomean,\n",
    "#     current_time = current_time,\n",
    "#     optimizer = optimizer, #'Adam', 'SGD'\n",
    "#     )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: n5qgxnv1 with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBPTT_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tConv_net: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tSAE_hidden_nomean: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tSAE_net: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tTIME: 6\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 16\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdataset_num: 16\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.001\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_add_at_first: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmax_epoch: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmy_seed: 42\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tneed_bias: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnormalize_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_cluster: 4\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: SGD\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tspike_length: 50\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \ttraining_cycle: 1400\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tv_decay: 0.75\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tv_reset: 10000\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tv_threshold: 0.25\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mbhkim003\u001b[0m (\u001b[33mbhkim003-seoul-national-university\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.19.1 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.17.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/nfs/home/bhkim003/github_folder/ByeonghyeonKim/my_snn/wandb/run-20250102_235215-n5qgxnv1</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/bhkim003-seoul-national-university/spike_sorting%20cluster_train_system/runs/n5qgxnv1' target=\"_blank\">fresh-sweep-2</a></strong> to <a href='https://wandb.ai/bhkim003-seoul-national-university/spike_sorting%20cluster_train_system' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/bhkim003-seoul-national-university/spike_sorting%20cluster_train_system/sweeps/6xax2jii' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/spike_sorting%20cluster_train_system/sweeps/6xax2jii</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/bhkim003-seoul-national-university/spike_sorting%20cluster_train_system' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/spike_sorting%20cluster_train_system</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/bhkim003-seoul-national-university/spike_sorting%20cluster_train_system/sweeps/6xax2jii' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/spike_sorting%20cluster_train_system/sweeps/6xax2jii</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/bhkim003-seoul-national-university/spike_sorting%20cluster_train_system/runs/n5qgxnv1' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/spike_sorting%20cluster_train_system/runs/n5qgxnv1</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'Conv_net' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'SAE_net' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'dataset_num' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'spike_length' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'num_cluster' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'training_cycle' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'batch_size' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'max_epoch' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'learning_rate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'normalize_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'need_bias' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_add_at_first' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'my_seed' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'TIME' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'v_decay' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'v_threshold' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'v_reset' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BPTT_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'SAE_hidden_nomean' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'optimizer' was locked by 'sweep' (ignored update).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'gpu': 2, 'Conv_net': True, 'SAE_net': True, 'dataset_num': 16, 'spike_length': 50, 'num_cluster': 4, 'training_cycle': 1400, 'batch_size': 16, 'max_epoch': 10, 'learning_rate': 0.001, 'normalize_on': False, 'need_bias': False, 'lif_add_at_first': True, 'my_seed': 42, 'TIME': 6, 'v_decay': 0.75, 'v_threshold': 0.25, 'v_reset': 10000, 'BPTT_on': False, 'SAE_hidden_nomean': False, 'current_time': '20250102_235221_299', 'optimizer': 'SGD'}\n",
      "DataParallel(\n",
      "  (module): SAE_conv1(\n",
      "    (encoder): Sequential(\n",
      "      (0): SSBH_DimChanger_one_two()\n",
      "      (1): SSBH_DimChanger_for_unsuqeeze()\n",
      "      (2): LIF_layer()\n",
      "      (3): SSBH_DimChanger_for_one_two_coupling()\n",
      "      (4): Conv1d(1, 32, kernel_size=(3,), stride=(2,), bias=False)\n",
      "      (5): SSBH_DimChanger_for_one_two_decoupling()\n",
      "      (6): LIF_layer()\n",
      "      (7): SSBH_DimChanger_for_one_two_coupling()\n",
      "      (8): Conv1d(32, 64, kernel_size=(3,), stride=(2,), bias=False)\n",
      "      (9): SSBH_DimChanger_for_one_two_decoupling()\n",
      "      (10): LIF_layer()\n",
      "      (11): SSBH_DimChanger_for_one_two_coupling()\n",
      "      (12): Conv1d(64, 96, kernel_size=(3,), stride=(2,), bias=False)\n",
      "      (13): SSBH_DimChanger_for_one_two_decoupling()\n",
      "      (14): LIF_layer()\n",
      "      (15): SSBH_DimChanger_for_one_two_coupling()\n",
      "      (16): SSBH_DimChanger_for_fc()\n",
      "      (17): Linear(in_features=480, out_features=4, bias=False)\n",
      "      (18): SSBH_L2NormLayer()\n",
      "      (19): SSBH_DimChanger_for_one_two_decoupling()\n",
      "      (20): SSBH_DimChanger_one_two()\n",
      "    )\n",
      "    (decoder): Sequential(\n",
      "      (0): SSBH_DimChanger_one_two()\n",
      "      (1): SSBH_DimChanger_for_one_two_coupling()\n",
      "      (2): Linear(in_features=4, out_features=480, bias=False)\n",
      "      (3): SSBH_DimChanger_for_one_two_decoupling()\n",
      "      (4): LIF_layer()\n",
      "      (5): SSBH_DimChanger_for_one_two_coupling()\n",
      "      (6): SSBH_DimChanger_for_conv1()\n",
      "      (7): SSBH_DimChanger_for_one_two_decoupling()\n",
      "      (8): SSBH_DimChanger_for_one_two_coupling()\n",
      "      (9): ConvTranspose1d(96, 64, kernel_size=(3,), stride=(2,), bias=False)\n",
      "      (10): SSBH_DimChanger_for_one_two_decoupling()\n",
      "      (11): LIF_layer()\n",
      "      (12): SSBH_DimChanger_for_one_two_coupling()\n",
      "      (13): ConvTranspose1d(64, 32, kernel_size=(3,), stride=(2,), output_padding=(1,), bias=False)\n",
      "      (14): SSBH_DimChanger_for_one_two_decoupling()\n",
      "      (15): LIF_layer()\n",
      "      (16): SSBH_DimChanger_for_one_two_coupling()\n",
      "      (17): ConvTranspose1d(32, 1, kernel_size=(3,), stride=(2,), output_padding=(1,), bias=False)\n",
      "      (18): SSBH_DimChanger_for_one_two_decoupling()\n",
      "      (19): SSBH_DimChanger_for_suqeeze()\n",
      "      (20): SSBH_DimChanger_one_two()\n",
      "    )\n",
      "  )\n",
      ")\n",
      "Device: cuda\n",
      "\n",
      "Start Training, current_time = 20250102_235221_299\n"
     ]
    }
   ],
   "source": [
    "# Sweep code\n",
    "\n",
    "\n",
    "unique_name_hyper = 'cluster_train_system'\n",
    "# run_name = 'spike_sorting'\n",
    "sweep_start_time =  datetime.datetime.now().strftime(\"%Y%m%d_%H%M%S\") + f\"_{str(int(datetime.datetime.now().microsecond / 1000)).zfill(3)}\"\n",
    "sweep_configuration = {\n",
    "    'method': 'bayes', # 'random', 'bayes'\n",
    "    'name': f'spike_sorting_{sweep_start_time}',\n",
    "    'metric': {'goal': 'maximize', 'name': 'best_mean_cluster_accuracy_post_training_cycle_all_dataset'},\n",
    "    'parameters': \n",
    "    {\n",
    "        # \"gpu\": {\"values\": [1]},  # 이건 sweep parameter아님. hyper_iter에서 직접 설정\n",
    "        \"Conv_net\": {\"values\": [True]}, \n",
    "        \"SAE_net\": {\"values\": [True]}, \n",
    "\n",
    "        \"dataset_num\": {\"values\": [16]}, \n",
    "        \"spike_length\": {\"values\": [50]},  \n",
    "        \"num_cluster\": {\"values\": [4]}, \n",
    "        \"training_cycle\": {\"values\": [1400, 2400]}, # [1400, 2400]\n",
    "\n",
    "        \"batch_size\": {\"values\": [16, 32]}, #[16, 32]\n",
    "        \"max_epoch\": {\"values\": [10]}, \n",
    "        \"learning_rate\": {\"values\": [0.001]},\n",
    "        \"normalize_on\": {\"values\": [False]},\n",
    "        \"need_bias\": {\"values\": [False]}, \n",
    "\n",
    "        \"lif_add_at_first\": {\"values\": [True]}, # [True, False]\n",
    "        \"my_seed\": {\"values\": [42]}, \n",
    "\n",
    "        \"TIME\": {\"values\": [2,4,6,8,10]}, #  [4,6,8,10]\n",
    "        \"v_decay\": {\"values\": [0.25,0.50,0.75]}, # [0.25,0.50,0.75]\n",
    "        \"v_threshold\": {\"values\": [0.25,0.50,0.75]}, # [0.25,0.50,0.75]\n",
    "        \"v_reset\": {\"values\": [0.0, 10000.0]},  # [0.0, 10000.0]\n",
    "        \"BPTT_on\": {\"values\": [True, False]},  # [True, False]\n",
    "\n",
    "        \"SAE_hidden_nomean\": {\"values\": [True, False]}, # [True, False]\n",
    "\n",
    "        # \"current_time\": {\"values\": [current_time]}, \n",
    "\n",
    "        \"optimizer\": {\"values\": ['Adam', 'SGD']}, # ['Adam', 'SGD']\n",
    "     }\n",
    "}\n",
    "\n",
    "\n",
    "def hyper_iter():\n",
    "    ### my_snn control board ########################\n",
    "    wandb.init(save_code = False)\n",
    "    gpu  =  2\n",
    "    Conv_net  =  wandb.config.Conv_net\n",
    "    SAE_net  =  wandb.config.SAE_net\n",
    "\n",
    "    dataset_num  =  wandb.config.dataset_num\n",
    "    spike_length  =  wandb.config.spike_length\n",
    "    num_cluster  =  wandb.config.num_cluster\n",
    "    training_cycle  =  wandb.config.training_cycle\n",
    "\n",
    "    batch_size  =  wandb.config.batch_size\n",
    "    max_epoch  =  wandb.config.max_epoch\n",
    "    learning_rate  =  wandb.config.learning_rate\n",
    "    normalize_on  =  wandb.config.normalize_on\n",
    "    need_bias  =  wandb.config.need_bias\n",
    "\n",
    "    lif_add_at_first  =  wandb.config.lif_add_at_first\n",
    "    my_seed  =  wandb.config.my_seed\n",
    "\n",
    "\n",
    "    TIME  =  wandb.config.TIME\n",
    "    v_decay  =  wandb.config.v_decay\n",
    "    v_threshold  =  wandb.config.v_threshold\n",
    "    v_reset  =  wandb.config.v_reset\n",
    "    BPTT_on  =  wandb.config.BPTT_on\n",
    "\n",
    "    SAE_hidden_nomean  =  wandb.config.SAE_hidden_nomean\n",
    "    \n",
    "    current_time =  datetime.datetime.now().strftime(\"%Y%m%d_%H%M%S\") + f\"_{str(int(datetime.datetime.now().microsecond / 1000)).zfill(3)}\"\n",
    "\n",
    "    optimizer  =  wandb.config.optimizer\n",
    "\n",
    "\n",
    "    cluster_train_system( \n",
    "        gpu = gpu,\n",
    "        Conv_net = Conv_net,\n",
    "        SAE_net = SAE_net,\n",
    "\n",
    "        # hyperparameter\n",
    "        dataset_num = dataset_num,\n",
    "        spike_length = spike_length,\n",
    "        num_cluster = num_cluster,  # 클러스터 수 설정 # 논문엔 4개라는데 여기서는 3개로 했네\n",
    "        training_cycle = training_cycle, # 그 초기 몇개까지만 cluster update할지\n",
    "\n",
    "\n",
    "        batch_size = batch_size,\n",
    "        max_epoch = max_epoch,\n",
    "        learning_rate = learning_rate,\n",
    "        normalize_on = normalize_on, # True or False #이거 안 씀 # 이거 별로 안 좋은 normalize같음 # 쓸 거면 다른 거 써라.\n",
    "        need_bias = need_bias,\n",
    "        # first_layer_no_train = False\n",
    "        lif_add_at_first = lif_add_at_first,\n",
    "        my_seed = my_seed,\n",
    "\n",
    "        TIME = TIME, # SAE일 때만 유효\n",
    "        v_decay = v_decay,\n",
    "        v_threshold = v_threshold,\n",
    "        v_reset = v_reset, # 10000이상 일 시 hard reset\n",
    "        BPTT_on = BPTT_on,\n",
    "\n",
    "        SAE_hidden_nomean = SAE_hidden_nomean,\n",
    "\n",
    "        current_time = current_time,\n",
    "\n",
    "        optimizer = optimizer, #'Adam', 'SGD'\n",
    "        )\n",
    "    \n",
    "# sweep_id = wandb.sweep(sweep=sweep_configuration, project=f'spike_sorting {unique_name_hyper}')\n",
    "sweep_id = '6xax2jii'\n",
    "wandb.agent(sweep_id, function=hyper_iter, count=100000, project=f'spike_sorting {unique_name_hyper}')\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wandb.finish() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import matplotlib.pyplot as plt\n",
    "# from matplotlib.ticker import MaxNLocator\n",
    "# import pickle\n",
    "# import json\n",
    "\n",
    "# # current_time = '20250102_174013_409'\n",
    "\n",
    "# with open(f\"result_save/cluster_accuracy_history_{current_time}.pkl\", \"rb\") as f:\n",
    "#     data = pickle.load(f)\n",
    "\n",
    "\n",
    "# # JSON으로 저장\n",
    "# with open(f\"result_save/cluster_accuracy_history_{current_time}.json\", 'r') as f:\n",
    "#     loaded_hyperparameters = json.load(f)\n",
    "\n",
    "# loss_history = data['loss_history']\n",
    "# mean_cluster_accuracy_during_training_cycle_all_dataset_history = data['mean_cluster_accuracy_during_training_cycle_all_dataset_history']\n",
    "# mean_cluster_accuracy_post_training_cycle_all_dataset_history = data['mean_cluster_accuracy_post_training_cycle_all_dataset_history']\n",
    "# mean_cluster_accuracy_total_all_dataset_history = data['mean_cluster_accuracy_total_all_dataset_history']\n",
    "# print(data)\n",
    "# max_acc = 0\n",
    "# for i in mean_cluster_accuracy_post_training_cycle_all_dataset_history:\n",
    "#     if i[1] > max_acc:\n",
    "#         max_acc = i[1]\n",
    "\n",
    "# # 설정 정보 제목 작성\n",
    "# title = (\n",
    "#     f\"Dataset Num: {loaded_hyperparameters['dataset_num']}, Conv {loaded_hyperparameters['Conv_net']}, SAE {loaded_hyperparameters['SAE_net']}, Current time {loaded_hyperparameters['current_time']}, Spike Length: {loaded_hyperparameters['spike_length']}, Num Cluster: {loaded_hyperparameters['num_cluster']}, \"\n",
    "#     f\"Training Cycle: {loaded_hyperparameters['training_cycle']}, Batch Size: {loaded_hyperparameters['batch_size']}, Max Epoch: {loaded_hyperparameters['max_epoch']}, \\n\"\n",
    "#     f\"Learning Rate: {loaded_hyperparameters['learning_rate']}, Input Normalize: {loaded_hyperparameters['normalize_on']}, Need Bias: {loaded_hyperparameters['need_bias']}, \"\n",
    "#     f\"LIF Add at First: {loaded_hyperparameters['lif_add_at_first']}, TIME: {loaded_hyperparameters['TIME']}, Seed: {loaded_hyperparameters['my_seed']}, Best ACC: {max_acc:.2f}%\"\n",
    "# )\n",
    "\n",
    "# # 데이터 리스트와 라벨 설정 (Loss 제외)\n",
    "# data_list = [\n",
    "#     (\"Mean Cluster Accuracy (During Training Cycle)\", mean_cluster_accuracy_during_training_cycle_all_dataset_history),\n",
    "#     (\"Mean Cluster Accuracy (Post Training Cycle)\", mean_cluster_accuracy_post_training_cycle_all_dataset_history),\n",
    "#     (\"Mean Cluster Accuracy (Total)\", mean_cluster_accuracy_total_all_dataset_history),\n",
    "# ]\n",
    "\n",
    "# # 플롯 생성\n",
    "# fig, ax1 = plt.subplots(figsize=(12, 8))\n",
    "\n",
    "# # 첫 번째 y축: Accuracy 관련 데이터\n",
    "# for label, data in data_list:\n",
    "#     epochs, values = zip(*data)  # epoch, value 분리\n",
    "#     ax1.plot(epochs, values, label=label)\n",
    "\n",
    "# ax1.set_xlabel(\"Epoch\")\n",
    "# ax1.set_ylabel(\"Clurstering Accuracy [%]\", color=\"blue\")\n",
    "# ax1.tick_params(axis=\"y\", labelcolor=\"blue\")\n",
    "# ax1.legend(loc=\"center right\")\n",
    "# ax1.grid(True)\n",
    "\n",
    "# # x축을 정수만 표시하도록 설정\n",
    "# ax1.xaxis.set_major_locator(MaxNLocator(integer=True))\n",
    "\n",
    "# # 두 번째 y축: Loss History\n",
    "# ax2 = ax1.twinx()\n",
    "# epochs, values = zip(*loss_history)\n",
    "# ax2.plot(epochs, values, label=\"AE Loss History\", color=\"red\", linestyle=\"--\")\n",
    "# ax2.set_ylabel(\"Loss\", color=\"red\")\n",
    "# ax2.tick_params(axis=\"y\", labelcolor=\"red\")\n",
    "# ax2.legend(loc=\"center left\")\n",
    "\n",
    "# # 제목 추가\n",
    "# plt.title(title, fontsize=10)\n",
    "# plt.tight_layout()\n",
    "# plt.savefig(f'net_save/{current_time}', dpi=300, bbox_inches=\"tight\")  # dpi=300은 고해상도로 저장, bbox_inches=\"tight\"는 여백 최소화\n",
    "# plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aedat2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
