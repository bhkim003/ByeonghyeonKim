{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ssp.train.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x600 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import torch   \n",
    "import torch.nn as nn \n",
    "import torch.nn.functional as F   \n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import torch.optim as optim\n",
    "from scipy import io\n",
    "import itertools\n",
    "import math\n",
    "import datetime\n",
    "import wandb\n",
    "import pickle\n",
    "import json\n",
    "import time\n",
    "import sys\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import accuracy_score\n",
    "from scipy.optimize import linear_sum_assignment\n",
    "from snntorch import spikegen\n",
    "\n",
    "\n",
    "# my module import\n",
    "from modules import *\n",
    "\n",
    "# modules 폴더에 새모듈.py 만들면\n",
    "# modules/__init__py 파일에 form .새모듈 import * 하셈\n",
    "# 그리고 새모듈.py에서 from modules.새모듈 import * 하셈"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cluster_train_system( \n",
    "    gpu = '4',\n",
    "    Conv_net = True,\n",
    "    SAE_net = True,\n",
    "\n",
    "    # hyperparameter\n",
    "    dataset_num = 16,\n",
    "    spike_length = 50,\n",
    "    num_cluster = 4,  # 클러스터 수 설정 # 논문엔 4개라는데 여기서는 3개로 했네\n",
    "    training_cycle = 2400, # 그 초기 몇개까지만 cluster update할지\n",
    "\n",
    "\n",
    "    batch_size = 32,\n",
    "    max_epoch = 7000,\n",
    "    learning_rate = 0.001,\n",
    "    normalize_on = False, # True or False #이거 안 씀 # 이거 별로 안 좋은 normalize같음 # 쓸 거면 다른 거 써라.\n",
    "    need_bias = False,\n",
    "    # first_layer_no_train = False\n",
    "    lif_add_at_first = False,\n",
    "    my_seed = 42,\n",
    "\n",
    "    TIME = 10, # SAE일 때만 유효\n",
    "    v_decay = 0.5,\n",
    "    v_threshold = 0.5,\n",
    "    v_reset = 10000.0, # 10000이상 일 시 hard reset\n",
    "    BPTT_on = True,\n",
    "\n",
    "    SAE_hidden_nomean = True,\n",
    "    current_time = '20250101_210938_786',\n",
    "\n",
    "    optimizer = 'Adam',\n",
    "    coarse_com_mode = True,\n",
    "    coarse_com_config = (2.0, -2.0), # (max, min)\n",
    "\n",
    "    sae_l2_norm_bridge = True,\n",
    "    sae_lif_bridge = False,\n",
    "\n",
    "    accuracy_check_epoch_term = 5,\n",
    "    \n",
    "    lif_add_at_last = False,\n",
    "\n",
    "    two_channel_input = False,\n",
    "\n",
    "    lateral_feature_num = 4,\n",
    "\n",
    "    lc_adc_on = False, \n",
    "\n",
    "    converted_net_forward = False,\n",
    "\n",
    "    pretrained_net = None, \n",
    "\n",
    "    vth_mul_on = False,\n",
    "    batch_norm_on = False,\n",
    "\n",
    "    l2_norm_loss_weight = 0.0,\n",
    "\n",
    "    QCFS_neuron_on = False,\n",
    "\n",
    "    quantize_level_num = 0,\n",
    "\n",
    "    fusion_net = False, # True False\n",
    "    repeat_coding = False,\n",
    "    \n",
    "    sae_relu_on = False,\n",
    "\n",
    "    conv1d_scaling = False,\n",
    "\n",
    "    norm01 = True,\n",
    "    ):\n",
    "    if coarse_com_mode == True:\n",
    "        assert coarse_com_config[0] > coarse_com_config[1], 'coarse_com_config[0] > coarse_com_config[1]이어야 함'\n",
    "        assert converted_net_forward == False\n",
    "        # assert SAE_net == True, 'coarse_com_mode는 SAE_net이 True일 때만 가능'\n",
    "    if two_channel_input == True:\n",
    "        assert Conv_net and coarse_com_mode, 'two_channel_input는 Conv_net이 True일 때만 가능'\n",
    "    if lc_adc_on == True:\n",
    "        assert coarse_com_mode and SAE_net, 'lc_adc_on은 coarse_com_mode와 SAE_net이 True일 때만 가능'\n",
    "    if converted_net_forward == True:\n",
    "        assert SAE_net == False, 'converted_net_forward는 SAE_net이 False일 때만 가능'\n",
    "    if conv1d_scaling:\n",
    "        assert Conv_net and coarse_com_mode and normalize_on\n",
    "    seed_assign(my_seed)\n",
    "    ## 함수 내 모든 로컬 변수 저장 ########################################################\n",
    "    hyperparameters = locals()\n",
    "    print(hyperparameters)\n",
    "    # JSON으로 저장\n",
    "    with open(f\"result_save/cluster_accuracy_history_{current_time}.json\", 'w') as f:\n",
    "        json.dump(hyperparameters, f, indent=4)\n",
    "    ######################################################################################\n",
    "\n",
    "    \n",
    "    wandb.config.update(hyperparameters)\n",
    "    wandb.run.name = f'{current_time}_SAE_net_{SAE_net}_v_threshold_{v_threshold}'\n",
    "    wandb.define_metric(\"best_mean_cluster_accuracy_post_training_cycle_all_dataset2\", summary=\"max\")\n",
    "\n",
    "\n",
    "    my_path_ground_BH = '/data2/spike_sorting/quiroga/BH/'\n",
    "\n",
    "\n",
    "    filename = [\"C_Easy1_noise005.mat\", \"C_Easy1_noise01.mat\", \"C_Easy1_noise015.mat\", \"C_Easy1_noise02.mat\",\n",
    "                \"C_Easy2_noise005.mat\", \"C_Easy2_noise01.mat\", \"C_Easy2_noise015.mat\", \"C_Easy2_noise02.mat\",\n",
    "                \"C_Difficult1_noise005.mat\", \"C_Difficult1_noise01.mat\", \"C_Difficult1_noise015.mat\", \"C_Difficult1_noise02.mat\",\n",
    "                \"C_Difficult2_noise005.mat\", \"C_Difficult2_noise01.mat\", \"C_Difficult2_noise015.mat\", \"C_Difficult2_noise02.mat\"]\n",
    "\n",
    "\n",
    "    spike_tot = [\"BH_Spike_e1n005.npy\", \"BH_Spike_e1n010.npy\", \"BH_Spike_e1n015.npy\", \"BH_Spike_e1n020.npy\",\n",
    "                \"BH_Spike_e2n005.npy\", \"BH_Spike_e2n010.npy\", \"BH_Spike_e2n015.npy\", \"BH_Spike_e2n020.npy\",\n",
    "                \"BH_Spike_d1n005.npy\", \"BH_Spike_d1n010.npy\", \"BH_Spike_d1n015.npy\", \"BH_Spike_d1n020.npy\",\n",
    "                \"BH_Spike_d2n005.npy\", \"BH_Spike_d2n010.npy\", \"BH_Spike_d2n015.npy\", \"BH_Spike_d2n020.npy\"]\n",
    "\n",
    "    label_tot = [\"BH_Label_e1n005.npy\", \"BH_Label_e1n010.npy\", \"BH_Label_e1n015.npy\", \"BH_Label_e1n020.npy\",\n",
    "                \"BH_Label_e2n005.npy\", \"BH_Label_e2n010.npy\", \"BH_Label_e2n015.npy\", \"BH_Label_e2n020.npy\",\n",
    "                \"BH_Label_d1n005.npy\", \"BH_Label_d1n010.npy\", \"BH_Label_d1n015.npy\", \"BH_Label_d1n020.npy\",\n",
    "                \"BH_Label_d2n005.npy\", \"BH_Label_d2n010.npy\", \"BH_Label_d2n015.npy\", \"BH_Label_d2n020.npy\"]\n",
    "\n",
    "    template =  [\"BH_Spike_TEMPLATE_e1n005.npy\", \"BH_Spike_TEMPLATE_e1n010.npy\", \"BH_Spike_TEMPLATE_e1n015.npy\", \"BH_Spike_TEMPLATE_e1n020.npy\",\n",
    "                \"BH_Spike_TEMPLATE_e2n005.npy\", \"BH_Spike_TEMPLATE_e2n010.npy\", \"BH_Spike_TEMPLATE_e2n015.npy\", \"BH_Spike_TEMPLATE_e2n020.npy\",\n",
    "                \"BH_Spike_TEMPLATE_d1n005.npy\", \"BH_Spike_TEMPLATE_d1n010.npy\", \"BH_Spike_TEMPLATE_d1n015.npy\", \"BH_Spike_TEMPLATE_d1n020.npy\",\n",
    "                \"BH_Spike_TEMPLATE_d2n005.npy\", \"BH_Spike_TEMPLATE_d2n010.npy\", \"BH_Spike_TEMPLATE_d2n015.npy\", \"BH_Spike_TEMPLATE_d2n020.npy\"]\n",
    "\n",
    "    AE_train_path_gt_detect = 'BH_quiroga_training_dataset_gt_detect.pt' \n",
    "    AE_test_path_gt_detect = 'BH_quiroga_test_dataset_gt_detect.pt'\n",
    "\n",
    "    AE_train_path_real_detect = 'BH_quiroga_training_dataset_real_detect.pt'\n",
    "    AE_test_path_real_detect = 'BH_quiroga_test_dataset_real_detect.pt'\n",
    "\n",
    "    AE_train_data = AE_train_path_real_detect #AE_train_path_gt_detect #AE_train_path_real_detect\n",
    "    AE_test_data = AE_test_path_real_detect #AE_test_path_gt_detect  #AE_test_path_real_detect\n",
    "\n",
    "    # thr_tot = np.array([0.5, 0.5, 0.55, 0.7, 0.5, 0.5, 0.55, 0.7, 0.5, 0.5, 0.55, 0.7, 0.5, 0.5, 0.55, 0.7])\n",
    "    cos_thr = np.array([0.95, 0.95, 0.95, 0.95, 0.95, 0.95, 0.95, 0.85, 0.95, 0.9, 0.8, 0.95, 0.95, 0.95, 0.95, 0.8])\n",
    "    # tem=10\n",
    "    # cos_thr = np.array([tem, tem, tem, tem, tem, tem, tem, tem, tem, tem, tem, tem, tem, tem, tem, tem, ])\n",
    "\n",
    "    print('cos_thr', cos_thr)\n",
    "    \n",
    "    os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\" \n",
    "    os.environ[\"CUDA_VISIBLE_DEVICES\"]= gpu\n",
    "\n",
    "\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "\n",
    "    if coarse_com_mode == True:\n",
    "        level_num = TIME\n",
    "        TIME = spike_length\n",
    "        spike_length = level_num\n",
    "        level_interval = (coarse_com_config[0] - coarse_com_config[1]) / (level_num-1)  # max - min\n",
    "        levels = [coarse_com_config[1] + level_interval * i for i in range(level_num)]\n",
    "        levels = torch.tensor(levels).to(torch.float).to(device)\n",
    "        levels = levels.repeat(TIME,1) \n",
    "        # print('levels', levels, levels.shape) # TIME, level_num\n",
    "\n",
    "    n_sample = spike_length\n",
    "\n",
    "    class spikedataset(Dataset):\n",
    "        def __init__(self, path, transform = None):    \n",
    "            self.transform = transform\n",
    "            self.spike = torch.load(path)\n",
    "            \n",
    "        def __getitem__(self, index):\n",
    "            spike = self.spike[index]            \n",
    "            if self.transform is not None:\n",
    "                spike = self.transform(spike)\n",
    "            return spike\n",
    "        \n",
    "        def __len__(self):\n",
    "            return len(self.spike)\n",
    "\n",
    "    train_dataset = spikedataset(my_path_ground_BH + AE_train_data)\n",
    "    train_loader = DataLoader(dataset = train_dataset, batch_size = batch_size, shuffle = True)\n",
    "\n",
    "    test_dataset = spikedataset(my_path_ground_BH + AE_test_data)\n",
    "    test_loader = DataLoader(dataset = test_dataset, batch_size = batch_size, shuffle = False)\n",
    "\n",
    "\n",
    "    # vth_mul_on = True # True False\n",
    "    # batch_norm_on = True # True False\n",
    "\n",
    "\n",
    "    # 모델 초기화\n",
    "    if SAE_net == False: # 여기서는 l2norm, lif bridge 둘 다 true면 l2norm먼저\n",
    "        assert two_channel_input == False\n",
    "\n",
    "        if Conv_net == True:\n",
    "            # input_channels = 2 if two_channel_input else 1\n",
    "            input_channels = TIME if coarse_com_mode else 1\n",
    "            if fusion_net == True:\n",
    "                assert False, '이거 맞음? 다시 확인'\n",
    "                net = FUSION_net_conv1(input_channels=input_channels, input_length=n_sample, encoder_ch = [32, 64, 96], fc_dim = lateral_feature_num, padding = 0, stride = 2, kernel_size = 3, \n",
    "                                    synapse_fc_trace_const1=1, \n",
    "                                    synapse_fc_trace_const2=v_decay, #안씀 \n",
    "                                    TIME=TIME, v_init=0.0, v_decay=v_decay, v_threshold=v_threshold, v_reset=v_reset, \n",
    "                                    sg_width=4.0, surrogate='sigmoid', BPTT_on=BPTT_on, need_bias=need_bias, lif_add_at_first=lif_add_at_first,\n",
    "                                    sae_l2_norm_bridge = sae_l2_norm_bridge, sae_lif_bridge = sae_lif_bridge, lif_add_at_last=lif_add_at_last, repeat_coding=repeat_coding).to(device)\n",
    "            else: \n",
    "                net = Autoencoder_conv1(input_channels=input_channels, input_length=n_sample, encoder_ch = [32, 64, 96], fc_dim = lateral_feature_num, padding = 0, stride = 2, kernel_size = 3, need_bias=need_bias, l2norm_bridge=sae_l2_norm_bridge, relu_bridge=sae_lif_bridge, activation_collector_on=False,\n",
    "                                        batch_norm_on=batch_norm_on, QCFS_neuron_on=QCFS_neuron_on).to(device)\n",
    "            net = torch.nn.DataParallel(net)\n",
    "            if converted_net_forward:\n",
    "                converted_net = SAE_converted_conv1(input_channels=input_channels, input_length=n_sample, encoder_ch = [32, 64, 96], fc_dim = lateral_feature_num, padding = 0, stride = 2, kernel_size = 3, \n",
    "                                    synapse_fc_trace_const1=1, \n",
    "                                    synapse_fc_trace_const2=v_decay, #안씀 \n",
    "                                    TIME=TIME, v_init=0.0, v_decay=v_decay, v_threshold=v_threshold, v_reset=v_reset, \n",
    "                                    sg_width=4.0, surrogate='sigmoid', BPTT_on=BPTT_on, need_bias=need_bias, lif_add_at_first=lif_add_at_first,\n",
    "                                    sae_l2_norm_bridge = sae_l2_norm_bridge, sae_lif_bridge = sae_lif_bridge, lif_add_at_last=lif_add_at_last,\n",
    "                                    vth_mul_on=vth_mul_on, batch_norm_on=batch_norm_on).to(device) # lif bridge는 무조건 들어가게 해놨음.\n",
    "                converted_net = torch.nn.DataParallel(converted_net)\n",
    "                print('converted_net', converted_net)\n",
    "        else:\n",
    "            n_sample = n_sample * TIME if coarse_com_mode else n_sample\n",
    "            net = Autoencoder_only_FC(encoder_ch=[400, lateral_feature_num], decoder_ch=[400,n_sample], n_sample=n_sample, need_bias=need_bias, l2norm_bridge=sae_l2_norm_bridge, relu_bridge=sae_lif_bridge, activation_collector_on=False,\n",
    "                                    batch_norm_on=batch_norm_on, QCFS_neuron_on=QCFS_neuron_on).to(device)\n",
    "            net = torch.nn.DataParallel(net)\n",
    "            if converted_net_forward:\n",
    "                converted_net = SAE_converted_fc(encoder_ch=[400, lateral_feature_num], \n",
    "                                    decoder_ch=[400, n_sample], \n",
    "                                    in_channels=n_sample, # in_channel 이 여기선 걍 lenght.\n",
    "                                    synapse_fc_trace_const1=1,\n",
    "                                    synapse_fc_trace_const2=v_decay,  #안씀 \n",
    "                                    TIME=TIME, v_init=0.0, v_decay=v_decay, v_threshold=v_threshold, v_reset=v_reset, \n",
    "                                    sg_width=4.0, surrogate='sigmoid', BPTT_on=BPTT_on, need_bias=need_bias, lif_add_at_first=lif_add_at_first,\n",
    "                                    sae_l2_norm_bridge = sae_l2_norm_bridge, sae_lif_bridge = sae_lif_bridge, lif_add_at_last=lif_add_at_last,\n",
    "                                    vth_mul_on=vth_mul_on, batch_norm_on=batch_norm_on).to(device) # lif bridge는 무조건 들어가게 해놨음.\n",
    "                converted_net = torch.nn.DataParallel(converted_net)\n",
    "                # print('converted_net', converted_net)\n",
    "    else:\n",
    "        if Conv_net == True: \n",
    "            input_channels = 1\n",
    "            input_channels = 2 if two_channel_input else 1\n",
    "            if fusion_net == True:  \n",
    "                assert coarse_com_mode == True\n",
    "                # net = SAE_FUSION2_net_conv1(input_channels=input_channels, input_length=n_sample, encoder_ch = [32, 64, 96], fc_dim = lateral_feature_num, padding = 0, stride = 2, kernel_size = 3, \n",
    "                #                     synapse_fc_trace_const1=1, \n",
    "                #                     synapse_fc_trace_const2=v_decay, #안씀 \n",
    "                #                     TIME=TIME, v_init=0.0, v_decay=v_decay, v_threshold=v_threshold, v_reset=v_reset, \n",
    "                #                     sg_width=4.0, surrogate='sigmoid', BPTT_on=BPTT_on, need_bias=need_bias, lif_add_at_first=lif_add_at_first,\n",
    "                #                     sae_l2_norm_bridge = sae_l2_norm_bridge, sae_lif_bridge = sae_lif_bridge, lif_add_at_last=lif_add_at_last, batch_norm_on=batch_norm_on, sae_relu_on=sae_relu_on).to(device)\n",
    "                # net = SAE_FUSION3_net_conv1(input_channels=input_channels, input_length=n_sample, encoder_ch = [32, 64, 96], fc_dim = lateral_feature_num, padding = 0, stride = 2, kernel_size = 3, \n",
    "                #                     synapse_fc_trace_const1=1, \n",
    "                #                     synapse_fc_trace_const2=v_decay, #안씀 \n",
    "                #                     TIME=TIME, v_init=0.0, v_decay=v_decay, v_threshold=v_threshold, v_reset=v_reset, \n",
    "                #                     sg_width=4.0, surrogate='sigmoid', BPTT_on=BPTT_on, need_bias=need_bias, lif_add_at_first=lif_add_at_first,\n",
    "                #                     sae_l2_norm_bridge = sae_l2_norm_bridge, sae_lif_bridge = sae_lif_bridge, lif_add_at_last=lif_add_at_last, batch_norm_on=batch_norm_on, sae_relu_on=sae_relu_on).to(device)\n",
    "                # net = SAE_FUSION4_net_conv1(input_channels=input_channels, input_length=n_sample, encoder_ch = [32, 64, 96], fc_dim = lateral_feature_num, padding = 0, stride = 2, kernel_size = 3, \n",
    "                #                     synapse_fc_trace_const1=1, \n",
    "                #                     synapse_fc_trace_const2=v_decay, #안씀 \n",
    "                #                     TIME=TIME, v_init=0.0, v_decay=v_decay, v_threshold=v_threshold, v_reset=v_reset, \n",
    "                #                     sg_width=4.0, surrogate='sigmoid', BPTT_on=BPTT_on, need_bias=need_bias, lif_add_at_first=lif_add_at_first,\n",
    "                #                     sae_l2_norm_bridge = sae_l2_norm_bridge, sae_lif_bridge = sae_lif_bridge, lif_add_at_last=lif_add_at_last, batch_norm_on=batch_norm_on, sae_relu_on=sae_relu_on).to(device)\n",
    "                # net = SAE_FUSION5_net_conv1(input_channels=input_channels, input_length=n_sample, encoder_ch = [32, 64, 96], fc_dim = lateral_feature_num, padding = 0, stride = 2, kernel_size = 3, \n",
    "                #                     synapse_fc_trace_const1=1, \n",
    "                #                     synapse_fc_trace_const2=v_decay, #안씀 \n",
    "                #                     TIME=TIME, v_init=0.0, v_decay=v_decay, v_threshold=v_threshold, v_reset=v_reset, \n",
    "                #                     sg_width=4.0, surrogate='sigmoid', BPTT_on=BPTT_on, need_bias=need_bias, lif_add_at_first=lif_add_at_first,\n",
    "                #                     sae_l2_norm_bridge = sae_l2_norm_bridge, sae_lif_bridge = sae_lif_bridge, lif_add_at_last=lif_add_at_last, batch_norm_on=batch_norm_on, sae_relu_on=sae_relu_on).to(device)\n",
    "                # net = SAE_FUSION6_net_conv1(input_channels=input_channels, input_length=n_sample, encoder_ch = [32, 64, 96], fc_dim = lateral_feature_num, padding = 0, stride = 2, kernel_size = 3, \n",
    "                #                     synapse_fc_trace_const1=1, \n",
    "                #                     synapse_fc_trace_const2=v_decay, #안씀 \n",
    "                #                     TIME=TIME, v_init=0.0, v_decay=v_decay, v_threshold=v_threshold, v_reset=v_reset, \n",
    "                #                     sg_width=4.0, surrogate='sigmoid', BPTT_on=BPTT_on, need_bias=need_bias, lif_add_at_first=lif_add_at_first,\n",
    "                #                     sae_l2_norm_bridge = sae_l2_norm_bridge, sae_lif_bridge = sae_lif_bridge, lif_add_at_last=lif_add_at_last, batch_norm_on=batch_norm_on, sae_relu_on=sae_relu_on).to(device)\n",
    "                net = SAE_FUSION7_net_conv1(input_channels=input_channels, input_length=n_sample, encoder_ch = [32, 64, 96], fc_dim = lateral_feature_num, padding = 0, stride = 2, kernel_size = 3, \n",
    "                                    synapse_fc_trace_const1=1, \n",
    "                                    synapse_fc_trace_const2=v_decay, #안씀 \n",
    "                                    TIME=TIME, v_init=0.0, v_decay=v_decay, v_threshold=v_threshold, v_reset=v_reset, \n",
    "                                    sg_width=4.0, surrogate='sigmoid', BPTT_on=BPTT_on, need_bias=need_bias, lif_add_at_first=lif_add_at_first,\n",
    "                                    sae_l2_norm_bridge = sae_l2_norm_bridge, sae_lif_bridge = sae_lif_bridge, lif_add_at_last=lif_add_at_last, batch_norm_on=batch_norm_on, sae_relu_on=sae_relu_on).to(device)\n",
    "            else:\n",
    "                net = SAE_conv1(input_channels=input_channels, input_length=n_sample, encoder_ch = [32, 64, 96], fc_dim = lateral_feature_num, padding = 0, stride = 2, kernel_size = 3, \n",
    "                                    synapse_fc_trace_const1=1, \n",
    "                                    synapse_fc_trace_const2=v_decay, #안씀 \n",
    "                                    TIME=TIME, v_init=0.0, v_decay=v_decay, v_threshold=v_threshold, v_reset=v_reset, \n",
    "                                    sg_width=4.0, surrogate='sigmoid', BPTT_on=BPTT_on, need_bias=need_bias, lif_add_at_first=lif_add_at_first,\n",
    "                                    sae_l2_norm_bridge = sae_l2_norm_bridge, sae_lif_bridge = sae_lif_bridge, lif_add_at_last=lif_add_at_last, batch_norm_on=batch_norm_on, sae_relu_on=sae_relu_on).to(device)\n",
    "            # net = SAE_conv1_DR(input_channels=input_channels, input_length=n_sample, encoder_ch = [32, 64, 96], fc_dim = lateral_feature_num, padding = 0, stride = 2, kernel_size = 3, \n",
    "            #                     synapse_fc_trace_const1=1, \n",
    "            #                     synapse_fc_trace_const2=v_decay, #안씀 \n",
    "            #                     TIME=TIME, v_init=0.0, v_decay=v_decay, v_threshold=v_threshold, v_reset=v_reset, \n",
    "            #                     sg_width=4.0, surrogate='sigmoid', BPTT_on=BPTT_on, need_bias=need_bias, lif_add_at_first=lif_add_at_first,\n",
    "            #                     sae_l2_norm_bridge = sae_l2_norm_bridge, sae_lif_bridge = sae_lif_bridge, lif_add_at_last=lif_add_at_last, batch_norm_on=batch_norm_on).to(device)\n",
    "            net = torch.nn.DataParallel(net)\n",
    "        else:\n",
    "            net = SAE_fc_only(encoder_ch=[400, lateral_feature_num], \n",
    "                                decoder_ch=[400, n_sample], \n",
    "                                in_channels=n_sample, # in_channel 이 여기선 걍 lenght.\n",
    "                                synapse_fc_trace_const1=1,\n",
    "                                synapse_fc_trace_const2=v_decay,  #안씀 \n",
    "                                TIME=TIME, v_init=0.0, v_decay=v_decay, v_threshold=v_threshold, v_reset=v_reset, \n",
    "                                sg_width=4.0, surrogate='sigmoid', BPTT_on=BPTT_on, need_bias=need_bias, lif_add_at_first=lif_add_at_first,\n",
    "                                sae_l2_norm_bridge = sae_l2_norm_bridge, sae_lif_bridge = sae_lif_bridge, lif_add_at_last=lif_add_at_last, batch_norm_on=batch_norm_on, sae_relu_on=sae_relu_on).to(device)\n",
    "            net = torch.nn.DataParallel(net)\n",
    "\n",
    "    # net = torch.load('/home/bhkim003/github_folder/ByeonghyeonKim/my_snn/net_save/save_now_net_AE_re_e7000.pth')\n",
    "    # net = torch.load('/home/bhkim003/github_folder/ByeonghyeonKim/my_snn/net_save/save_now_net_20250101_210938_786.pth')\n",
    "    # load했으면 torch.nn.DataParallel 하지마\n",
    "    # net.module.load_state_dict(torch.load('/home/bhkim003/github_folder/ByeonghyeonKim/my_snn/net_save/save_now_net_annbase_20250108_210641_941.pth'))\n",
    "    if pretrained_net != None:\n",
    "        ######################## 모델이 달라서 dict로 weight만 넣고싶을 때\n",
    "        # # 저장된 가중치 로드\n",
    "        saved_state_dict = torch.load(pretrained_net)\n",
    "        current_state_dict = net.module.state_dict()\n",
    "\n",
    "        # 함수 호출로 가중치 매핑\n",
    "        updated_state_dict = map_and_load_weights(saved_state_dict, current_state_dict)\n",
    "\n",
    "        # 업데이트된 state_dict를 네트워크에 로드\n",
    "        net.module.load_state_dict(updated_state_dict)\n",
    "        ######################## 모델이 달라서 dict로 weight만 넣고싶을 때\n",
    "\n",
    "        ############## 일반적일 때\n",
    "        # net.module.load_state_dict(torch.load(pretrained_net))\n",
    "        ############## 일반적일 때\n",
    "    \n",
    "        # pre_net = Autoencoder_conv1(input_channels=input_channels, input_length=n_sample, encoder_ch = [32, 64, 96], fc_dim = lateral_feature_num, padding = 0, stride = 2, kernel_size = 3, need_bias=need_bias, l2norm_bridge=sae_l2_norm_bridge, relu_bridge=sae_lif_bridge, activation_collector_on=False,\n",
    "        #                         batch_norm_on=batch_norm_on, QCFS_neuron_on=False).to(device)\n",
    "        # pre_net = torch.nn.DataParallel(net)\n",
    "        # pre_net.module.load_state_dict(torch.load(pretrained_net))\n",
    "        # copy_weights(pre_net.module.encoder , net.module.encoder )\n",
    "        # copy_weights(pre_net.module.decoder , net.module.decoder  )\n",
    "\n",
    "        \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    wandb.watch(net, log=\"all\", log_freq = 10)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    if SAE_net == True:\n",
    "        assert 'SAE' in net.module.__class__.__name__\n",
    "\n",
    "\n",
    "\n",
    "    net = net.to(device)\n",
    "    print(f\"Total number of encoder parameters: {sum(p.numel() for p in net.module.encoder.parameters())}\")\n",
    "    print(net)\n",
    "    print('Device:',device)\n",
    "\n",
    "    \n",
    "    if optimizer == 'Adam':\n",
    "        optimizer = optim.Adam(net.parameters(), lr=learning_rate)\n",
    "    elif optimizer == 'SGD':\n",
    "        optimizer = optim.SGD(net.parameters(), lr = learning_rate, momentum = 0.9)\n",
    "    else:\n",
    "        assert False, 'optimizer를 잘못 입력했습니다.'\n",
    "        \n",
    "    loss_history = []\n",
    "    mean_cluster_accuracy_during_training_cycle_all_dataset_history = []\n",
    "    mean_cluster_accuracy_post_training_cycle_all_dataset_history = []\n",
    "    mean_cluster_accuracy_total_all_dataset_history = []\n",
    "\n",
    "    tau = np.zeros(num_cluster)\n",
    "\n",
    "    print(f\"\\nStart Training, current_time = {current_time}\")\n",
    "    mean_cluster_accuracy_post_training_cycle_all_dataset = 0\n",
    "    best_mean_cluster_accuracy_post_training_cycle_all_dataset = 0\n",
    "\n",
    "    if SAE_net == True:\n",
    "        assert 'SAE' in net.module.__class__.__name__\n",
    "        \n",
    "    k_means_acc_best = 0\n",
    "    min_loss = 9999999\n",
    "    min_loss_normal = 9999999\n",
    "    min_loss_coarse = 9999999\n",
    "    for epoch in range(max_epoch):\n",
    "        print()\n",
    "        l2_loss_bin= 0\n",
    "        ae_train_start_time = time.time()\n",
    "        running_loss = 0.0\n",
    "        running_loss_normal = 0.0\n",
    "        running_loss_coarse = 0.0\n",
    "        iter = 0\n",
    "        net.train()\n",
    "        # if True or max_epoch != 1:\n",
    "        wrong_element_sum = 0\n",
    "        same_data_num = 0\n",
    "        total_data_num = 0\n",
    "        if max_epoch != 1:\n",
    "            for data in train_loader:\n",
    "                optimizer.zero_grad()\n",
    "                total_data_num += len(data)\n",
    "                data = data.to(device)\n",
    "                scaling = (level_num-3)/level_num if conv1d_scaling else 1.0\n",
    "                data = zero_to_one_normalize_features(data, level_num=quantize_level_num, coarse_com_config=coarse_com_config, scaling=scaling, norm01=norm01) if normalize_on else data\n",
    "                # plot_origin_spike(data[0].cpu().detach().numpy(), min_max_y_on = True)\n",
    "                # plot_origin_spike(data[1].cpu().detach().numpy(), min_max_y_on = True)\n",
    "                spike_backup = data\n",
    "                spike = data\n",
    "                spike = spike.to(device) # batch, feature\n",
    "                spike_for_fusion2_net = spike\n",
    "                if coarse_com_mode == True and 'SAE' in net.module.__class__.__name__:\n",
    "                    # print(spike[0])\n",
    "                    spike = spike.unsqueeze(2).repeat(1, 1, level_num) # spike_length == level_num # (batch, time, feature)로 변환 \n",
    "                    spike = (spike > levels).to(torch.float) \n",
    "\n",
    "                    spike = (spike == 0).cumsum(dim=-1).eq(1).to(torch.float) if lc_adc_on == True else spike\n",
    "\n",
    "                    # spike: batch, time, level_num\n",
    "                    # levels: time, level_num\n",
    "                    if Conv_net == True:\n",
    "                        spike = spike.unsqueeze(-2) # batch, time, in_channel, feature or batch in_channel,feature\n",
    "                        if two_channel_input == True:\n",
    "                            spike_backup = spike_backup.to(device)\n",
    "                            spike_backup = spike_backup.unsqueeze(2).repeat(1, 1, level_num) # spike_length == level_num # (batch, time, feature)로 변환 \n",
    "                            spike_backup = (spike_backup <= levels).to(torch.float) \n",
    "                            spike_backup = (spike_backup == 1).cumsum(dim=-1).eq(1).to(torch.float) if lc_adc_on == True else spike_backup\n",
    "                            spike_backup = spike_backup.unsqueeze(-2)\n",
    "                            spike = torch.cat((spike, spike_backup), dim=-2)\n",
    "                    assert spike.shape[0] == batch_size and spike.shape[1] == TIME\n",
    "                elif 'SAE' in net.module.__class__.__name__:\n",
    "                    spike = spike.unsqueeze(-1).repeat(1, 1, TIME).permute(0,2,1) # (batch, time, feature)로 변환\n",
    "                    if Conv_net == True:\n",
    "                        spike = spike.unsqueeze(-2) # batch, time, in_channel, feature or batch in_channel,feature\n",
    "                else:\n",
    "                    if Conv_net == True:\n",
    "                        if coarse_com_mode == False:\n",
    "                            spike = spike.unsqueeze(-2) #batch in_channel,feature\n",
    "                        else:\n",
    "                            spike = spike.unsqueeze(2).repeat(1, 1, level_num) # spike_length == level_num # (batch, time, feature)로 변환 \n",
    "                            spike = (spike > levels).to(torch.float) \n",
    "\n",
    "                            spike = (spike == 0).cumsum(dim=-1).eq(1).to(torch.float) if lc_adc_on == True else spike\n",
    "\n",
    "                    else:\n",
    "                        if coarse_com_mode == False:\n",
    "                            pass\n",
    "                        else:\n",
    "                            spike = spike.unsqueeze(2).repeat(1, 1, level_num) # spike_length == level_num # (batch, time, feature)로 변환 \n",
    "                            spike = (spike > levels).to(torch.float) \n",
    "\n",
    "                            spike = (spike == 0).cumsum(dim=-1).eq(1).to(torch.float) if lc_adc_on == True else spike\n",
    "\n",
    "                            # spike: batch, time, feature\n",
    "                            spike = spike.reshape(spike.shape[0], -1)\n",
    "\n",
    "                    \n",
    "\n",
    "\n",
    "                    # if fusion_net == True:\n",
    "                    #     spike = spikegen.rate(spike, num_steps=TIME).transpose(0, 1)\n",
    "\n",
    "                # spike_class = net(spike) # batch, time, feature\n",
    "                encoded_spike = net.module.encoder(spike)\n",
    "                spike_class = net.module.decoder(encoded_spike)\n",
    "\n",
    "                # for i in range (2):\n",
    "                #     plot_spike(spike[i,:,0,:].cpu().numpy())\n",
    "                #     # plot_spike(spike[i,:,1,:].cpu().numpy())\n",
    "                #     plot_origin_spike(spike_class.squeeze()[i].cpu().detach().numpy(), min_max_y_on = True)\n",
    "                # assert False\n",
    "                        \n",
    "\n",
    "                loss = 0\n",
    "                loss_normal = torch.tensor(0.0)\n",
    "                loss_coarse = torch.tensor(0.0)\n",
    "                if coarse_com_mode == True and 'SAE' in net.module.__class__.__name__:\n",
    "                    criterion = nn.MSELoss().to(device)\n",
    "                    # loss1 = nn.MSELoss()(spike_class[..., 5:25], spike[..., 5:25])\n",
    "                    # loss2 = nn.MSELoss()(spike_class[..., 0:5], spike[..., 0:5])\n",
    "                    # loss3 = nn.MSELoss()(spike_class[..., 25:spike_length], spike[..., 25:spike_length])\n",
    "                    # loss = loss1 * 2.125 + (loss2 + loss3)/4\n",
    "\n",
    "                    # loss1 = nn.MSELoss()(spike_class[..., 5:25, :], spike[..., 5:25, :])\n",
    "                    # loss2 = nn.MSELoss()(spike_class[..., 0:5, :], spike[..., 0:5, :])\n",
    "                    # loss3 = nn.MSELoss()(spike_class[..., 25:spike_length, :], spike[..., 25:spike_length, :])\n",
    "                    # loss = loss1 * 2.125 + (loss2 + loss3)/4\n",
    "                    if fusion_net:\n",
    "                        # print('1', spike.shape) # batch, time, in_channel, feature [32, 50, 1, 50]\n",
    "                        \n",
    "                        # ### coarse에서 ann loss 만들기 ######\n",
    "                        # spike = spike.squeeze()\n",
    "                        # assert two_channel_input == False\n",
    "                        # zero_mask = (spike == 0)  # 0이 있는 위치\n",
    "                        # first_zero_idx = torch.where(zero_mask, torch.arange(spike.shape[-1]).to(device), spike.shape[-1]-1).min(dim=-1).values\n",
    "                        # spike = levels[0][first_zero_idx]\n",
    "                        # # plot_origin_spike(spike[0].cpu().detach().numpy())\n",
    "                        # ### coarse에서 ann loss 만들기 ######\n",
    "\n",
    "                        ### 그냥 원래 스파이크로 ann loss 만들기 ######\n",
    "                        spike = spike_for_fusion2_net\n",
    "                        ### 그냥 원래 스파이크로 ann loss 만들기 ######\n",
    "\n",
    "                        spike = spike.squeeze()\n",
    "                        spike_class = spike_class.squeeze()\n",
    "                        \n",
    "                        ### normal loss################\n",
    "                        # loss = criterion(spike_class, spike)\n",
    "                        ### normal loss################\n",
    "                        \n",
    "                        ### chan loss################\n",
    "                        loss1 = criterion(spike_class[..., 5:25], spike[..., 5:25])\n",
    "                        loss2 = criterion(spike_class[..., 0:5], spike[..., 0:5])\n",
    "                        loss3 = criterion(spike_class[..., 25:], spike[..., 25:])\n",
    "                        loss = loss1 * 2.125 + (loss2 + loss3)/4\n",
    "                        ### chan loss################\n",
    "\n",
    "\n",
    "                        # #########################################\n",
    "                        # # 손실 함수 정의 (예: MSELoss 사용)\n",
    "                        # criterion_joke = torch.nn.MSELoss(reduction='none')  # 개별 요소별 손실을 유지\n",
    "\n",
    "                        # # 손실 계산\n",
    "                        # loss1_joke = criterion_joke(spike_class[..., 5:25], spike[..., 5:25]).mean(dim=-1)  # (batch,)\n",
    "                        # loss2_joke = criterion_joke(spike_class[..., 0:5], spike[..., 0:5]).mean(dim=-1)    # (batch,)\n",
    "                        # loss3_joke = criterion_joke(spike_class[..., 25:], spike[..., 25:]).mean(dim=-1)    # (batch,)\n",
    "\n",
    "                        # # 주어진 가중치를 적용한 최종 손실\n",
    "                        # loss_joke = loss1_joke * 2.125 + (loss2_joke + loss3_joke) / 4  # (batch,)\n",
    "\n",
    "                        # # 가장 큰 손실을 갖는 샘플의 인덱스 찾기\n",
    "                        # max_loss_idx_joke = torch.argmax(loss_joke)\n",
    "\n",
    "                        # # 해당 샘플 선택\n",
    "                        # selected_sample_class = spike_class[max_loss_idx_joke]\n",
    "                        # selected_sample_spike = spike[max_loss_idx_joke]\n",
    "\n",
    "                        # # 선택한 샘플의 손실 값 출력\n",
    "                        # print(\"Index of max loss sample:\", max_loss_idx_joke.item())\n",
    "                        # print(\"Max loss value:\", loss_joke[max_loss_idx_joke].item())\n",
    "                        # mean_loss_joke = loss_joke.mean().item()\n",
    "                        # print(\"Mean loss across the batch:\", mean_loss_joke)\n",
    "\n",
    "                        # # 선택한 샘플을 시각화\n",
    "                        # plot_origin_spike(selected_sample_class.cpu().detach().numpy())\n",
    "                        # plot_origin_spike(selected_sample_spike.cpu().detach().numpy())\n",
    "                        # #########################################\n",
    "\n",
    "                        # coarse loss ######################################################\n",
    "                        loss_normal = criterion(spike_class, spike)\n",
    "                        level_num_in_loss = spike_length\n",
    "                        level_interval = (coarse_com_config[0] - coarse_com_config[1]) / (level_num_in_loss-1)  # max - min\n",
    "                        levels = [coarse_com_config[1] + level_interval * i for i in range(level_num_in_loss)]\n",
    "                        levels = torch.tensor(levels).to(torch.float).to(device)\n",
    "                        # print('coarse leves', levels)\n",
    "                        levels = levels.repeat(spike_length,1) \n",
    "\n",
    "                        spike = spike.squeeze()\n",
    "                        spike_class = spike_class.squeeze()\n",
    "                        # plot_origin_spike(spike_class[0].cpu().detach().numpy())\n",
    "                        spike = spike.unsqueeze(2).repeat(1, 1, level_num_in_loss) \n",
    "                        spike = (spike > levels).to(torch.float) \n",
    "                        spike_class = spike_class.unsqueeze(2).repeat(1, 1, level_num_in_loss) \n",
    "                        spike_class = (spike_class > levels).to(torch.float) \n",
    "                        # spike = spike[..., 0:-3, :]\n",
    "                        # spike_class = spike_class[..., 0:-3, :]\n",
    "                        loss_coarse = criterion(spike_class, spike)\n",
    "                        wrong_element_sum += torch.sum(torch.abs(spike - spike_class)).item() \n",
    "\n",
    "                        # plot_spike(spike_class[0].cpu().detach().numpy())\n",
    "                        # assert False\n",
    "                        # coarse loss ######################################################\n",
    "                    else:\n",
    "                        spike = spike.squeeze()\n",
    "                        spike_class = spike_class.squeeze()\n",
    "                        loss = criterion(spike_class, spike)\n",
    "\n",
    "                    for iii in range(spike.shape[0]):\n",
    "                        same_data_num = same_data_num + 1 if torch.eq(spike[iii], spike_class[iii]).all() else same_data_num\n",
    "                    wrong_element_sum += torch.sum(torch.abs(spike - spike_class)).item() \n",
    "\n",
    "                    # spike = spike.squeeze()\n",
    "                    # spike_class = spike_class.squeeze()\n",
    "                    # plot_spike(spike[0].cpu().detach().numpy())\n",
    "                    # plot_spike(spike_class[0].cpu().detach().numpy())\n",
    "                    # print('손실 절대값 합',np.sum(np.abs(spike[0].cpu().detach().numpy() - spike_class[0].cpu().detach().numpy())))\n",
    "                    # # assert False\n",
    "                elif 'SAE' in net.module.__class__.__name__:\n",
    "                    criterion = nn.MSELoss().to(device)\n",
    "                    loss1 = criterion(spike_class[..., 5:25], spike[..., 5:25])\n",
    "                    loss2 = criterion(spike_class[..., 0:5], spike[..., 0:5])\n",
    "                    loss3 = criterion(spike_class[..., 25:spike_length], spike[..., 25:spike_length])\n",
    "                    loss = loss1 * 2.125 + (loss2 + loss3)/4\n",
    "                    assert spike_length > 25, 'spike_length가 25보다 작음'\n",
    "                    # wrong_element_sum += torch.sum(torch.abs(spike - spike_class)).item() \n",
    "                else:\n",
    "                    criterion = nn.MSELoss().to(device)\n",
    "                    loss1 = criterion(spike_class[..., 5:25], spike[..., 5:25])\n",
    "                    loss2 = criterion(spike_class[..., 0:5], spike[..., 0:5])\n",
    "                    loss3 = criterion(spike_class[..., 25:spike_length], spike[..., 25:spike_length])\n",
    "                    loss = loss1 * 2.125 + (loss2 + loss3)/4\n",
    "                    assert spike_length > 25, 'spike_length가 25보다 작음'\n",
    "                    # wrong_element_sum += torch.sum(torch.abs(spike - spike_class)).item() \n",
    "\n",
    "\n",
    "                    if l2_norm_loss_weight > 0:\n",
    "                        assert len(encoded_spike.shape) == 2, 'time 성분 없는 걸로'\n",
    "                        l2_loss = l2_norm_loss(encoded_spike, target_norm=1.0)  # L2Norm Loss 계산, l2 1.0되게.\n",
    "                        loss = loss + l2_loss*l2_norm_loss_weight\n",
    "                        l2_loss_bin += l2_loss.item()\n",
    "\n",
    "                    # coarse loss ######################################################\n",
    "                    loss_normal = criterion(spike_class, spike)\n",
    "                    level_num_in_loss = quantize_level_num\n",
    "                    level_interval = (coarse_com_config[0] - coarse_com_config[1]) / (level_num_in_loss-1)  # max - min\n",
    "                    levels = [coarse_com_config[1] + level_interval * i for i in range(level_num_in_loss)]\n",
    "                    levels = torch.tensor(levels).to(torch.float).to(device)\n",
    "                    levels = levels.repeat(spike_length,1) \n",
    "\n",
    "                    spike = spike.squeeze()\n",
    "                    spike_class = spike_class.squeeze()\n",
    "                    # plot_origin_spike(spike_class[0].cpu().detach().numpy())\n",
    "                    spike = spike.unsqueeze(2).repeat(1, 1, level_num_in_loss) \n",
    "                    spike = (spike > levels).to(torch.float) \n",
    "                    spike_class = spike_class.unsqueeze(2).repeat(1, 1, level_num_in_loss) \n",
    "                    spike_class = (spike_class > levels).to(torch.float) \n",
    "                    # spike = spike[..., 0:-3, :]\n",
    "                    # spike_class = spike_class[..., 0:-3, :]\n",
    "                    loss_coarse = criterion(spike_class, spike)\n",
    "                    wrong_element_sum += torch.sum(torch.abs(spike - spike_class)).item() \n",
    "\n",
    "                    # plot_spike(spike_class[0].cpu().detach().numpy())\n",
    "                    # assert False\n",
    "                    # coarse loss ######################################################\n",
    "\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                running_loss += loss.item()\n",
    "                running_loss_normal += loss_normal.item()\n",
    "                running_loss_coarse += loss_coarse.item()\n",
    "                # print(f'\\nepoch-{epoch}, running_loss : {running_loss:.5f}, iter percent {iter/len(train_loader)*100:.2f}%')\n",
    "                iter += 1\n",
    "        else:\n",
    "            print('\\n\\n\\n max_epoch 1이면 Train 안함!!!!!!!!!!!!!!!!!!!!!')\n",
    "        if l2_norm_loss_weight > 0:\n",
    "            print('l2_loss_bin', l2_loss_bin/len(train_loader))\n",
    "        avg_loss = running_loss / len(train_loader)\n",
    "        assert not np.isnan(avg_loss), f\"Error: avg_loss is NaN! Running loss: {running_loss}, Length of train_loader: {len(train_loader)}\"\n",
    "        loss_history.append((epoch, avg_loss))\n",
    "        min_loss = min(min_loss, avg_loss)\n",
    "        min_loss_normal = min(min_loss_normal, running_loss_normal/len(train_loader))\n",
    "        min_loss_coarse = min(min_loss_coarse, running_loss_coarse/len(train_loader))\n",
    "        print(f'\\nepoch-{epoch} loss : {avg_loss:.8f}, loss_normal : {running_loss_normal/len(train_loader):.8f}, loss_coarse : {running_loss_coarse/len(train_loader):.8f}, min_loss : {min_loss:.8f}, min_loss_normal : {min_loss_normal:.8f}, min_loss_coarse : {min_loss_coarse:.8f}, wrong_element_sum : {wrong_element_sum:.8f}, same_data : {100*same_data_num/(total_data_num+1e-12):.2f}%')\n",
    "        print(f\"ae train 실행 시간: {time.time()-ae_train_start_time:.3f}초, 전체 시작 시간 {current_time}\")\n",
    "\n",
    "        # plot_activation_distribution(net)\n",
    "\n",
    "        if SAE_net == False and converted_net_forward == True:\n",
    "            source_encoder = net.module.encoder \n",
    "            target_encoder = converted_net.module.encoder  \n",
    "            copy_weights(source_encoder, target_encoder)\n",
    "\n",
    "        cluster_accuracy_during_training_cycle_all_dataset = np.zeros(dataset_num)\n",
    "        cluster_accuracy_post_training_cycle_all_dataset = np.zeros(dataset_num)\n",
    "        cluster_accuracy_total_all_dataset = np.zeros(dataset_num)    \n",
    "\n",
    "        k_means_acc = 0\n",
    "        converted_k_means_acc = 0\n",
    "        if(epoch % accuracy_check_epoch_term == 0 or epoch == 1 or epoch == max_epoch-1): \n",
    "            accuracy_check_start_time = time.time()\n",
    "            print(f'\\nepoch-{epoch} accuracy check')\n",
    "            k_means_bin_origin_feature = []\n",
    "            k_means_bin = []\n",
    "            converted_k_means_bin = []\n",
    "            for ds in range(dataset_num):\n",
    "                # print('\\n', spike_tot[ds])\n",
    "\n",
    "                spike_template = np.load(my_path_ground_BH + template[ds])\n",
    "                spike = np.load(my_path_ground_BH + spike_tot[ds])\n",
    "                label = np.load(my_path_ground_BH + label_tot[ds])\n",
    "                spike_template = torch.from_numpy(spike_template).to(device)\n",
    "                spike = torch.from_numpy(spike).to(device)\n",
    "                scaling = (level_num-3)/level_num if conv1d_scaling else 1.0\n",
    "                spike_template = zero_to_one_normalize_features(spike_template, level_num=quantize_level_num, coarse_com_config=coarse_com_config, scaling=scaling, norm01=norm01) if normalize_on else spike_template\n",
    "                spike = zero_to_one_normalize_features(spike, level_num=quantize_level_num, coarse_com_config=coarse_com_config, scaling=scaling, norm01=norm01) if normalize_on else spike\n",
    "                \n",
    "                hidden_size = lateral_feature_num*TIME if 'SAE' in net.module.__class__.__name__ and SAE_hidden_nomean == True and fusion_net == False or 'SAE_FUSION5' in net.module.__class__.__name__ else lateral_feature_num\n",
    "                hidden_size = lateral_feature_num if '_DR' in net.module.__class__.__name__  else hidden_size\n",
    "\n",
    "                Cluster = np.zeros((num_cluster, hidden_size))\n",
    "                assert Cluster.shape[-1] == hidden_size, '이거 hidden dim 4 아니게 할 거면 잘 바꿔라'\n",
    "                \n",
    "\n",
    "\n",
    "                net.eval()\n",
    "                with torch.no_grad():\n",
    "                    spike_torch = spike_template.float()\n",
    "                    spike_torch = spike_torch[:num_cluster]\n",
    "                    spike_backup = spike_torch\n",
    "                    spike_torch = spike_torch.to(device)\n",
    "                    if coarse_com_mode == True and 'SAE' in net.module.__class__.__name__:\n",
    "                        spike_torch = spike_torch.unsqueeze(2).repeat(1, 1, level_num) # spike_length == level_num # (batch, time, feature)로 변환 \n",
    "                        spike_torch = (spike_torch > levels).to(torch.float) \n",
    "                        spike_torch = (spike_torch == 0).cumsum(dim=-1).eq(1).to(torch.float) if lc_adc_on == True else spike_torch\n",
    "                        if Conv_net == True:\n",
    "                            spike_torch = spike_torch.unsqueeze(-2) # batch, time, in_channel, feature or batch in_channel,feature\n",
    "                            if two_channel_input == True:\n",
    "                                spike_backup = spike_backup.to(device)\n",
    "                                spike_backup = spike_backup.unsqueeze(2).repeat(1, 1, level_num) # spike_length == level_num # (batch, time, feature)로 변환 \n",
    "                                spike_backup = (spike_backup <= levels).to(torch.float) \n",
    "                                spike_backup = (spike_backup == 1).cumsum(dim=-1).eq(1).to(torch.float) if lc_adc_on == True else spike_backup\n",
    "                                spike_backup = spike_backup.unsqueeze(-2) # batch, time, in_channel, feature\n",
    "                                spike_torch = torch.cat((spike_torch, spike_backup), dim=-2)\n",
    "                    elif 'SAE' in net.module.__class__.__name__:\n",
    "                        spike_torch = spike_torch.unsqueeze(1).repeat(1, TIME, 1) # (batch, time, feature)로 변환\n",
    "                        if Conv_net == True:\n",
    "                            spike_torch = spike_torch.unsqueeze(-2) # batch, time, in_channel, feature or batch in_channel,feature\n",
    "                    else:\n",
    "                        # if Conv_net == True:\n",
    "                        #     spike_torch = spike_torch.unsqueeze(-2) #batch in_channel,feature\n",
    "                        if Conv_net == True:\n",
    "                            if coarse_com_mode == False:\n",
    "                                spike_torch = spike_torch.unsqueeze(-2) #batch in_channel,feature\n",
    "                            else:\n",
    "                                spike_torch = spike_torch.unsqueeze(2).repeat(1, 1, level_num) # spike_length == level_num # (batch, time, feature)로 변환 \n",
    "                                spike_torch = (spike_torch > levels).to(torch.float) \n",
    "\n",
    "                                spike_torch = (spike_torch == 0).cumsum(dim=-1).eq(1).to(torch.float) if lc_adc_on == True else spike_torch\n",
    "\n",
    "                        else:\n",
    "                            if coarse_com_mode == False:\n",
    "                                pass\n",
    "                            else:\n",
    "                                spike_torch = spike_torch.unsqueeze(2).repeat(1, 1, level_num) # spike_length == level_num # (batch, time, feature)로 변환 \n",
    "                                spike_torch = (spike_torch > levels).to(torch.float) \n",
    "\n",
    "                                spike_torch = (spike_torch == 0).cumsum(dim=-1).eq(1).to(torch.float) if lc_adc_on == True else spike_torch\n",
    "\n",
    "                                # spike: batch, time, feature\n",
    "                                spike_torch = spike_torch.reshape(spike_torch.shape[0], -1)\n",
    "\n",
    "                        if converted_net_forward == True:\n",
    "                            spike_torch_spikegen = spikegen.rate(spike_torch, num_steps=TIME).transpose(0, 1)\n",
    "                        # if fusion_net == True:\n",
    "                        #     spike_torch = spikegen.rate(spike_torch, num_steps=TIME).transpose(0, 1)\n",
    "                    ### forward #######################################################\n",
    "                    inner_inf = net.module.encoder(spike_torch)\n",
    "                    if SAE_net == False and converted_net_forward == True:\n",
    "                        converted_inner_inf = converted_net.module.encoder(spike_torch_spikegen)\n",
    "                    ### forward #######################################################\n",
    "\n",
    "                    # if ds % 4 == 0:\n",
    "                    #     for i in range(4):\n",
    "                    #         decoded = net.module.decoder(inner_inf).squeeze()\n",
    "                    #         plot_spike(spike_torch[i,:,:].cpu().numpy())\n",
    "                    #         plot_spike(inner_inf[i,:].cpu().numpy())\n",
    "                    #         # plot_origin_spike(net.module.decoder(inner_inf)[i,:].cpu().numpy())\n",
    "                    #         plot_origin_spike(decoded[i].cpu().numpy(), min_max_y_on = True)\n",
    "                        \n",
    "                    # if 'SAE' in net.module.__class__.__name__:\n",
    "                    #     tensors = [inner_inf[0][i] for i in range(TIME)] \n",
    "                    #     all_equal = all(torch.equal(tensors[0], t) for t in tensors)\n",
    "                    #     print(all_equal, inner_inf)\n",
    "\n",
    "                    if 'SAE' in net.module.__class__.__name__:\n",
    "                        if SAE_hidden_nomean == True:\n",
    "                            inner_inf = inner_inf.reshape(inner_inf.shape[0],-1)# time*feature 펼치기\n",
    "                        else:\n",
    "                            inner_inf = inner_inf.mean(dim=1)# Time 방향으로 평균\n",
    "                        # inner_inf = F.normalize(inner_inf, p=2, dim=1)\n",
    "                    Cluster = inner_inf.cpu().detach().numpy()\n",
    "\n",
    "                encoder_batch = 128\n",
    "                spike_hidden = np.zeros((len(spike), hidden_size))\n",
    "                converted_spike_hidden = np.zeros((len(spike), hidden_size))\n",
    "                net.eval()\n",
    "                with torch.no_grad():\n",
    "                    now_index = 0\n",
    "                    while (1):\n",
    "                        now_end_index = now_index+encoder_batch if now_index+encoder_batch < len(spike) else len(spike)\n",
    "                        spike_batch = spike[now_index:now_end_index] \n",
    "                        spike_torch = spike_batch\n",
    "                        spike_torch = spike_torch.float()\n",
    "                        spike_backup = spike_torch\n",
    "                        spike_torch = spike_torch.to(device)\n",
    "                        if coarse_com_mode == True and 'SAE' in net.module.__class__.__name__:\n",
    "                            spike_torch = spike_torch.unsqueeze(2).repeat(1, 1, level_num) # spike_length == level_num # (batch, time, feature)로 변환 \n",
    "                            spike_torch = (spike_torch > levels).to(torch.float) \n",
    "                            spike_torch = (spike_torch == 0).cumsum(dim=-1).eq(1).to(torch.float) if lc_adc_on == True else spike_torch\n",
    "                            if Conv_net == True:\n",
    "                                spike_torch = spike_torch.unsqueeze(-2) # batch, time, in_channel, feature or batch in_channel,feature\n",
    "                                if two_channel_input == True:\n",
    "                                    spike_backup = spike_backup.to(device)\n",
    "                                    spike_backup = spike_backup.unsqueeze(2).repeat(1, 1, level_num) # spike_length == level_num # (batch, time, feature)로 변환 \n",
    "                                    spike_backup = (spike_backup <= levels).to(torch.float) \n",
    "                                    spike_backup = (spike_backup == 1).cumsum(dim=-1).eq(1).to(torch.float) if lc_adc_on == True else spike_backup\n",
    "                                    spike_backup = spike_backup.unsqueeze(-2)\n",
    "                                    spike_torch = torch.cat((spike_torch, spike_backup), dim=-2)\n",
    "                        elif 'SAE' in net.module.__class__.__name__:\n",
    "                            spike_torch = spike_torch.unsqueeze(1).repeat(1, TIME, 1) # (batch, time, feature)로 변환\n",
    "                            if Conv_net == True:\n",
    "                                spike_torch = spike_torch.unsqueeze(-2) # batch, time, in_channel, feature or batch in_channel,feature\n",
    "                        else:\n",
    "                            # if Conv_net == True:\n",
    "                            #     spike_torch = spike_torch.unsqueeze(-2) #batch in_channel,feature\n",
    "                            if Conv_net == True:\n",
    "                                if coarse_com_mode == False:\n",
    "                                    spike_torch = spike_torch.unsqueeze(-2) #batch in_channel,feature\n",
    "                                else:\n",
    "                                    spike_torch = spike_torch.unsqueeze(2).repeat(1, 1, level_num) # spike_length == level_num # (batch, time, feature)로 변환 \n",
    "                                    spike_torch = (spike_torch > levels).to(torch.float) \n",
    "\n",
    "                                    spike_torch = (spike_torch == 0).cumsum(dim=-1).eq(1).to(torch.float) if lc_adc_on == True else spike_torch\n",
    "\n",
    "                            else:\n",
    "                                if coarse_com_mode == False:\n",
    "                                    pass\n",
    "                                else:\n",
    "                                    spike_torch = spike_torch.unsqueeze(2).repeat(1, 1, level_num) # spike_length == level_num # (batch, time, feature)로 변환 \n",
    "                                    spike_torch = (spike_torch > levels).to(torch.float) \n",
    "\n",
    "                                    spike_torch = (spike_torch == 0).cumsum(dim=-1).eq(1).to(torch.float) if lc_adc_on == True else spike_torch\n",
    "\n",
    "                                    # spike: batch, time, feature\n",
    "                                    spike_torch = spike_torch.reshape(spike_torch.shape[0], -1)\n",
    "                            if converted_net_forward == True:\n",
    "                                spike_torch_spikegen = spikegen.rate(spike_torch, num_steps=TIME).transpose(0, 1)\n",
    "                            # if fusion_net == True:\n",
    "                            #     spike_torch = spikegen.rate(spike_torch, num_steps=TIME).transpose(0, 1)\n",
    "                        ### forward #######################################################\n",
    "                        inner_inf = net.module.encoder(spike_torch)\n",
    "                        if SAE_net == False and converted_net_forward == True:\n",
    "                            converted_inner_inf = converted_net.module.encoder(spike_torch_spikegen)\n",
    "                        ### forward #######################################################\n",
    "                            \n",
    "                        if 'SAE' in net.module.__class__.__name__:\n",
    "                            if SAE_hidden_nomean == True:\n",
    "                                inner_inf = inner_inf.reshape(spike_batch.shape[0],-1)# 펼치기\n",
    "                            else:\n",
    "                                inner_inf = inner_inf.mean(dim=1)# Time 방향으로 평균\n",
    "                            # inner_inf = F.normalize(inner_inf, p=2, dim=1)\n",
    "                        spike_hidden[now_index:now_end_index] = inner_inf.cpu().detach().numpy()\n",
    "                        if SAE_net == False and converted_net_forward == True:\n",
    "                            converted_spike_hidden[now_index:now_end_index] = converted_inner_inf.cpu().detach().numpy()\n",
    "                        now_index += encoder_batch\n",
    "                        if (now_index >= len(spike)):\n",
    "                            break\n",
    "                    \n",
    "                spike_id = np.zeros(len(spike))\n",
    "                distance_sm = np.zeros(num_cluster)\n",
    "                tau = np.zeros(num_cluster)\n",
    "                \n",
    "                plot_tau = []\n",
    "                plot_denominator = []\n",
    "                plot_m = []\n",
    "                plot_max_tau = []\n",
    "                for spike_index in range(len(spike)): \n",
    "                    for q in range(num_cluster):\n",
    "                        tau[q] = np.dot(spike_hidden[spike_index, :], Cluster[q, :]) # 이거 l2norm 거쳐서 나온 거니까 분모 1임.\n",
    "                        denominator =  np.linalg.norm(spike_hidden[spike_index, :])*np.linalg.norm(Cluster[q, :]) + 1e-12\n",
    "                        plot_denominator.append(denominator)\n",
    "                        if 'SAE' in net.module.__class__.__name__: # AE 때는 l2norm거쳐서 나와서 괜찮음\n",
    "                            tau[q] = tau[q] / denominator\n",
    "\n",
    "                        plot_tau.append(tau[q])\n",
    "\n",
    "                    # for i in range(num_cluster): # l2 distance\n",
    "                    #     distance_sm[i] = np.sum(np.power(np.abs(Cluster[i] - spike_hidden[spike_index, :]), 2))\n",
    "                    distance_sm = np.sum(np.power(np.abs(Cluster - spike_hidden[spike_index, :]), 2), axis=1)\n",
    "\n",
    "                    m = np.argmin(distance_sm)\n",
    "                    plot_m.append(m)\n",
    "                    spike_id[spike_index] = m + 1\n",
    "                    # print(spike_tot[ds], spike_index,np.max(tau))\n",
    "                    plot_max_tau.append(np.max(tau))\n",
    "                    if(np.max(tau) >= cos_thr[ds] and spike_index < training_cycle): # 원래 1400 아니냐?\n",
    "                        Cluster[m] = (Cluster[m] * 15 + spike_hidden[spike_index, :])/16\n",
    "\n",
    "\n",
    "                \n",
    "                origin_kmeans_accuracy = cluster_spikes_with_accuracy_torch(features= spike, true_labels=label-1, n_clusters=3, init_point=None)\n",
    "                kmeans_accuracy = cluster_spikes_with_accuracy_torch(features= torch.tensor(spike_hidden).to(device), true_labels=label-1, n_clusters=3, init_point=None)\n",
    "                \n",
    "                # print('temporoal k')\n",
    "                # result = evaluate_clustering_accuracy(spike_hidden.reshape(spike_hidden.shape[0], TIME, -1), label-1, n_clusters=3)\n",
    "                # print('원래', kmeans_accuracy)\n",
    "                # print(result)\n",
    "\n",
    "                k_means_bin_origin_feature.append(origin_kmeans_accuracy)\n",
    "                k_means_bin.append(kmeans_accuracy)\n",
    "                if SAE_net == False and converted_net_forward == True:\n",
    "                    converted_kmeans_accuracy = cluster_spikes_with_accuracy_torch(features= torch.tensor(converted_spike_hidden).to(device), true_labels=label-1, n_clusters=3, init_point=None)\n",
    "                    converted_k_means_bin.append(converted_kmeans_accuracy)\n",
    "                # sklearn kmeans인데 cpu많이먹어서 버림.\n",
    "                # origin_kmeans_accuracy = cluster_spikes_with_accuracy(features= spike.cpu().detach().numpy(), true_labels=label-1, n_clusters=3, init_point=None)\n",
    "                # kmeans_accuracy = cluster_spikes_with_accuracy(features= spike_hidden, true_labels=label-1, n_clusters=3, init_point=None)\n",
    "                # k_means_bin_origin_feature.append(origin_kmeans_accuracy)\n",
    "                # k_means_bin.append(kmeans_accuracy)\n",
    "                # if SAE_net == False and converted_net_forward == True:\n",
    "                #     converted_kmeans_accuracy = cluster_spikes_with_accuracy(features= converted_spike_hidden, true_labels=label-1, n_clusters=3, init_point=None)\n",
    "                #     converted_k_means_bin.append(converted_kmeans_accuracy)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "                # print('Cluster',Cluster)\n",
    "                # print('spike_id', spike_id)\n",
    "\n",
    "                # spike id 분포 확인하기\n",
    "                # unique_elements, counts = np.unique(spike_id, return_counts=True)\n",
    "                # print(\"Unique elements:\", unique_elements)\n",
    "                # print(\"Counts:\", counts)\n",
    "\n",
    "                cluster_accuracy_during_training_cycle = np.zeros(math.factorial(num_cluster))\n",
    "                cluster_accuracy_post_training_cycle = np.zeros(math.factorial(num_cluster))\n",
    "                cluster_accuracy_total = np.zeros(math.factorial(num_cluster))\n",
    "                \n",
    "                label_converter_ground = list(range(1, num_cluster + 1)) # [1, 2, 3, 4] 생성\n",
    "                label_converter_permutations = list(itertools.permutations(label_converter_ground)) # 모든 순열 구하기\n",
    "                perm_i = 0\n",
    "                perm_start_time = time.time() \n",
    "                for perm in label_converter_permutations:\n",
    "                    label_converter = list(perm)\n",
    "                    # print(label_converter)\n",
    "                    correct_during_training_cycle = 0\n",
    "                    correct_post_training_cycle = 0\n",
    "\n",
    "                    assert len(spike_id) == len(label), 'spike_id랑 label 길이 같아야 됨.'\n",
    "                    for i in range(len(spike_id)):\n",
    "                        if(label_converter[int(spike_id[i]-1)] == label[i]):\n",
    "                            if i < training_cycle:\n",
    "                                correct_during_training_cycle += 1\n",
    "                            else:\n",
    "                                correct_post_training_cycle += 1\n",
    "\n",
    "                    cluster_accuracy_during_training_cycle[perm_i] = correct_during_training_cycle/training_cycle\n",
    "                    cluster_accuracy_post_training_cycle[perm_i] = correct_post_training_cycle/(len(spike_id)-training_cycle)\n",
    "                    cluster_accuracy_total[perm_i] = (correct_during_training_cycle+correct_post_training_cycle)/(len(spike_id))\n",
    "                    perm_i += 1\n",
    "                # print(f\"perm 실행 시간: {time.time()-perm_start_time:.3f}초\")\n",
    "                \n",
    "                cluster_accuracy_during_training_cycle_all_dataset[ds] = np.max(cluster_accuracy_during_training_cycle)\n",
    "                cluster_accuracy_post_training_cycle_all_dataset[ds] = cluster_accuracy_post_training_cycle[np.argmax(cluster_accuracy_during_training_cycle)]\n",
    "                cluster_accuracy_total_all_dataset[ds] = cluster_accuracy_total[np.argmax(cluster_accuracy_during_training_cycle)]\n",
    "                # plot_distributions(ds, plot_tau, plot_denominator, plot_m, plot_max_tau, cos_thr[ds],\n",
    "                #                    cluster_accuracy_during_training_cycle_all_dataset[ds], cluster_accuracy_post_training_cycle_all_dataset[ds], cluster_accuracy_total_all_dataset[ds])\n",
    "            print(f'k_means origin feature average accuracy : {100*sum(k_means_bin_origin_feature)/(len(k_means_bin_origin_feature)+1e-12):.8f}%, total {k_means_bin_origin_feature}')\n",
    "            \n",
    "            mean_cluster_accuracy_during_training_cycle_all_dataset = np.mean(cluster_accuracy_during_training_cycle_all_dataset)\n",
    "            mean_cluster_accuracy_post_training_cycle_all_dataset = np.mean(cluster_accuracy_post_training_cycle_all_dataset)\n",
    "            mean_cluster_accuracy_total_all_dataset = np.mean(cluster_accuracy_total_all_dataset)\n",
    "            \n",
    "            if SAE_net == False and converted_net_forward == True:\n",
    "                converted_k_means_acc = 100*sum(converted_k_means_bin)/len(converted_k_means_bin)\n",
    "                print(f'converted_kmeans average accuracy : {converted_k_means_acc:.8f}%, total {converted_k_means_bin}')\n",
    "            k_means_acc = 100*sum(k_means_bin)/len(k_means_bin)\n",
    "            if k_means_acc > k_means_acc_best:\n",
    "                # torch.save(net, f\"net_save/save_now_net_{current_time}.pth\")\n",
    "                torch.save(net.module.state_dict(), f\"net_save/save_now_net_{current_time}.pth\")\n",
    "                print('save model')\n",
    "                best_mean_cluster_accuracy_post_training_cycle_all_dataset = mean_cluster_accuracy_post_training_cycle_all_dataset\n",
    "            \n",
    "            k_means_acc_best = max(k_means_acc_best, k_means_acc)\n",
    "            print(f'kmeans average accuracy best : {k_means_acc_best:.2f}%, kmeans average accuracy : {k_means_acc:.8f}%, total {k_means_bin}')\n",
    "            print(f'cluster_accuracy_post_training_cycle_all_dataset : {cluster_accuracy_post_training_cycle_all_dataset}')\n",
    "\n",
    "            \n",
    "            mean_cluster_accuracy_during_training_cycle_all_dataset_history.append((epoch, mean_cluster_accuracy_during_training_cycle_all_dataset*100))\n",
    "            mean_cluster_accuracy_post_training_cycle_all_dataset_history.append((epoch, mean_cluster_accuracy_post_training_cycle_all_dataset*100))\n",
    "            mean_cluster_accuracy_total_all_dataset_history.append((epoch, mean_cluster_accuracy_total_all_dataset*100))\n",
    "            print(f\"mean_cluster_accuracy_during_training_cycle : {mean_cluster_accuracy_during_training_cycle_all_dataset*100:.2f}%, post_traincycle_acc : {mean_cluster_accuracy_post_training_cycle_all_dataset*100:.2f}%, total_acc : {mean_cluster_accuracy_total_all_dataset*100:.8f}%\")\n",
    "\n",
    "            # kmeans accuracy기준으로 좋은 거 저장할 거임\n",
    "            # if mean_cluster_accuracy_post_training_cycle_all_dataset > best_mean_cluster_accuracy_post_training_cycle_all_dataset:\n",
    "            #     # torch.save(net, f\"net_save/save_now_net_{current_time}.pth\")\n",
    "            #     torch.save(net.module.state_dict(), f\"net_save/save_now_net_{current_time}.pth\")\n",
    "            #     print('save model')\n",
    "            #     best_mean_cluster_accuracy_post_training_cycle_all_dataset = mean_cluster_accuracy_post_training_cycle_all_dataset\n",
    "            print(f\"best_mean_cluster_accuracy_post_training_cycle_all_dataset : {best_mean_cluster_accuracy_post_training_cycle_all_dataset*100:.2f}%\")\n",
    "            print(f\"accuracy_check 실행 시간: {time.time()-accuracy_check_start_time:.3f}초\")\n",
    "\n",
    "        wandb.log({\"avg_loss\": avg_loss})\n",
    "        wandb.log({\"mean_cluster_accuracy_post_training_cycle_all_dataset\": mean_cluster_accuracy_post_training_cycle_all_dataset})\n",
    "        wandb.log({\"best_mean_cluster_accuracy_post_training_cycle_all_dataset\": best_mean_cluster_accuracy_post_training_cycle_all_dataset})\n",
    "        wandb.log({\"best_mean_cluster_accuracy_post_training_cycle_all_dataset2\": best_mean_cluster_accuracy_post_training_cycle_all_dataset})\n",
    "        wandb.log({\"k_means_acc\": k_means_acc})\n",
    "        wandb.log({\"k_means_acc_best\": k_means_acc_best})\n",
    "        wandb.log({\"converted_k_means_acc\": converted_k_means_acc})\n",
    "\n",
    "\n",
    "        # 저장\n",
    "        with open(f\"result_save/cluster_accuracy_history_{current_time}.pkl\", \"wb\") as f:\n",
    "            pickle.dump({\n",
    "                \"loss_history\": loss_history,\n",
    "                \"mean_cluster_accuracy_during_training_cycle_all_dataset_history\": mean_cluster_accuracy_during_training_cycle_all_dataset_history,\n",
    "                \"mean_cluster_accuracy_post_training_cycle_all_dataset_history\": mean_cluster_accuracy_post_training_cycle_all_dataset_history,\n",
    "                \"mean_cluster_accuracy_total_all_dataset_history\": mean_cluster_accuracy_total_all_dataset_history,\n",
    "            }, f)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mbhkim003\u001b[0m (\u001b[33mbhkim003-seoul-national-university\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.19.8 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.17.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/nfs/home/bhkim003/github_folder/ByeonghyeonKim/my_snn/wandb/run-20250314_000159-y6th3hd3</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/bhkim003-seoul-national-university/spike_sorting%20just%20run/runs/y6th3hd3' target=\"_blank\">fearless-haze-1481</a></strong> to <a href='https://wandb.ai/bhkim003-seoul-national-university/spike_sorting%20just%20run' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/bhkim003-seoul-national-university/spike_sorting%20just%20run' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/spike_sorting%20just%20run</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/bhkim003-seoul-national-university/spike_sorting%20just%20run/runs/y6th3hd3' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/spike_sorting%20just%20run/runs/y6th3hd3</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'gpu': '0', 'Conv_net': True, 'SAE_net': True, 'dataset_num': 16, 'spike_length': 50, 'num_cluster': 4, 'training_cycle': 1400, 'batch_size': 32, 'max_epoch': 10000, 'learning_rate': 0.001, 'normalize_on': True, 'need_bias': False, 'lif_add_at_first': False, 'my_seed': 42, 'TIME': 50, 'v_decay': 0.5, 'v_threshold': 0.25, 'v_reset': 0.0, 'BPTT_on': True, 'SAE_hidden_nomean': True, 'current_time': '20250314_000157_781', 'optimizer': 'Adam', 'coarse_com_mode': True, 'sae_l2_norm_bridge': True, 'sae_lif_bridge': False, 'accuracy_check_epoch_term': 1, 'lif_add_at_last': False, 'two_channel_input': False, 'lateral_feature_num': 3, 'lc_adc_on': False, 'converted_net_forward': False, 'pretrained_net': None, 'vth_mul_on': False, 'batch_norm_on': False, 'l2_norm_loss_weight': 0, 'QCFS_neuron_on': False, 'quantize_level_num': 0, 'fusion_net': True, 'repeat_coding': False, 'sae_relu_on': False, 'conv1d_scaling': False, 'norm01': True, 'coarse_com_config': (0.999, -0.0)}\n",
      "cos_thr [0.95 0.95 0.95 0.95 0.95 0.95 0.95 0.85 0.95 0.9  0.8  0.95 0.95 0.95\n",
      " 0.95 0.8 ]\n",
      "conv length [50, 24, 11, 5]\n",
      "Total number of encoder parameters: 26562\n",
      "DataParallel(\n",
      "  (module): SAE_FUSION7_net_conv1(\n",
      "    (activation_function): LIF_layer()\n",
      "    (encoder): Sequential(\n",
      "      (0): SSBH_DimChanger_one_two()\n",
      "      (1): SSBH_DimChanger_for_one_two_coupling()\n",
      "      (2): Conv1d(1, 32, kernel_size=(3,), stride=(2,), bias=False)\n",
      "      (3): SSBH_DimChanger_for_one_two_decoupling()\n",
      "      (4): LIF_layer()\n",
      "      (5): SSBH_DimChanger_for_one_two_coupling()\n",
      "      (6): Conv1d(32, 64, kernel_size=(3,), stride=(2,), bias=False)\n",
      "      (7): SSBH_DimChanger_for_one_two_decoupling()\n",
      "      (8): LIF_layer()\n",
      "      (9): SSBH_DimChanger_for_one_two_coupling()\n",
      "      (10): Conv1d(64, 96, kernel_size=(3,), stride=(2,), bias=False)\n",
      "      (11): SSBH_DimChanger_for_one_two_decoupling()\n",
      "      (12): LIF_layer()\n",
      "      (13): SSBH_DimChanger_for_one_two_coupling()\n",
      "      (14): SSBH_DimChanger_for_fc()\n",
      "      (15): Linear(in_features=480, out_features=3, bias=False)\n",
      "      (16): SSBH_DimChanger_for_one_two_decoupling()\n",
      "      (17): LIF_layer()\n",
      "      (18): SSBH_DimChanger_one_two()\n",
      "      (19): SSBH_DimChanger_for_two_three_coupling()\n",
      "      (20): Linear(in_features=150, out_features=3, bias=False)\n",
      "      (21): SSBH_L2NormLayer()\n",
      "    )\n",
      "    (decoder): Sequential(\n",
      "      (0): Linear(in_features=3, out_features=480, bias=False)\n",
      "      (1): ReLU()\n",
      "      (2): SSBH_DimChanger_for_conv1()\n",
      "      (3): ConvTranspose1d(96, 64, kernel_size=(3,), stride=(2,), bias=False)\n",
      "      (4): ReLU()\n",
      "      (5): ConvTranspose1d(64, 32, kernel_size=(3,), stride=(2,), output_padding=(1,), bias=False)\n",
      "      (6): ReLU()\n",
      "      (7): ConvTranspose1d(32, 1, kernel_size=(3,), stride=(2,), output_padding=(1,), bias=False)\n",
      "    )\n",
      "  )\n",
      ")\n",
      "Device: cuda\n",
      "\n",
      "Start Training, current_time = 20250314_000157_781\n",
      "\n",
      "\n",
      "epoch-0 loss : 0.03923685, loss_normal : 0.02264272, loss_coarse : 0.09838771, min_loss : 0.03923685, min_loss_normal : 0.02264272, min_loss_coarse : 0.09838771, wrong_element_sum : 18890440.00000000, same_data : 0.00%\n",
      "ae train 실행 시간: 116.298초, 전체 시작 시간 20250314_000157_781\n",
      "\n",
      "epoch-0 accuracy check\n",
      "k_means origin feature average accuracy : 82.25133127%, total [0.9746727376209448, 0.9733106189664963, 0.9700891573195284, 0.9530800230282096, 0.943108504398827, 0.915340909090909, 0.801817648783348, 0.6625070901871809, 0.9488619568430388, 0.8216357308584686, 0.5872695852534562, 0.5005858230814294, 0.9429250891795482, 0.8922588099364529, 0.6738372093023256, 0.598912109934154]\n",
      "save model\n",
      "kmeans average accuracy best : 84.08%, kmeans average accuracy : 84.08108931%, total [0.9746727376209448, 0.9770017035775128, 0.9721023871153293, 0.9620034542314335, 0.9519061583577713, 0.9241477272727273, 0.8434476693051891, 0.7260351673284174, 0.9216671593260419, 0.8404872389791184, 0.7488479262672811, 0.6769185705916813, 0.9090368608799049, 0.7660311958405546, 0.6703488372093023, 0.5883194961351274]\n",
      "cluster_accuracy_post_training_cycle_all_dataset : [0.97682119 0.97690858 0.97207511 0.96094503 0.95522388 0.91556604\n",
      " 0.8463451  0.68814675 0.88048411 0.859375   0.72490347 0.64399206\n",
      " 0.91191446 0.82347236 0.70686275 0.59053989]\n",
      "mean_cluster_accuracy_during_training_cycle : 84.08%, post_traincycle_acc : 83.96%, total_acc : 84.00430071%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 83.96%\n",
      "accuracy_check 실행 시간: 24.279초\n",
      "\n",
      "\n",
      "epoch-1 loss : 0.01879916, loss_normal : 0.01690952, loss_coarse : 0.08001047, min_loss : 0.01879916, min_loss_normal : 0.01690952, min_loss_coarse : 0.08001047, wrong_element_sum : 15362010.00000000, same_data : 0.00%\n",
      "ae train 실행 시간: 115.069초, 전체 시작 시간 20250314_000157_781\n",
      "\n",
      "epoch-1 accuracy check\n",
      "k_means origin feature average accuracy : 82.25497872%, total [0.9746727376209448, 0.9733106189664963, 0.9700891573195284, 0.9530800230282096, 0.943108504398827, 0.9150568181818182, 0.801817648783348, 0.6625070901871809, 0.9488619568430388, 0.8216357308584686, 0.5872695852534562, 0.5005858230814294, 0.9429250891795482, 0.8922588099364529, 0.6744186046511628, 0.5991983967935872]\n",
      "save model\n",
      "kmeans average accuracy best : 87.04%, kmeans average accuracy : 87.03740418%, total [0.9760956175298805, 0.9764338444065872, 0.9721023871153293, 0.9654576856649395, 0.9633431085043989, 0.9431818181818182, 0.8645558487247141, 0.7705615428247305, 0.9420632574637895, 0.8639791183294664, 0.7811059907834101, 0.7287639132981839, 0.9274673008323424, 0.839110340843443, 0.7412790697674418, 0.6704838247924421]\n",
      "cluster_accuracy_post_training_cycle_all_dataset : [0.97634816 0.97549482 0.97159364 0.96432015 0.96268657 0.94575472\n",
      " 0.87419194 0.76952023 0.9404942  0.86181641 0.76206564 0.72989076\n",
      " 0.92413442 0.85063046 0.75490196 0.66555184]\n",
      "mean_cluster_accuracy_during_training_cycle : 86.88%, post_traincycle_acc : 87.06%, total_acc : 86.98620867%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 87.06%\n",
      "accuracy_check 실행 시간: 23.769초\n",
      "\n",
      "\n",
      "epoch-2 loss : 0.01774683, loss_normal : 0.01664889, loss_coarse : 0.07850035, min_loss : 0.01774683, min_loss_normal : 0.01664889, min_loss_coarse : 0.07850035, wrong_element_sum : 15072068.00000000, same_data : 0.00%\n",
      "ae train 실행 시간: 117.259초, 전체 시작 시간 20250314_000157_781\n",
      "\n",
      "epoch-2 accuracy check\n",
      "k_means origin feature average accuracy : 82.25128855%, total [0.9746727376209448, 0.9733106189664963, 0.9700891573195284, 0.9530800230282096, 0.943108504398827, 0.9150568181818182, 0.8015244796247435, 0.6622234826999432, 0.9488619568430388, 0.822215777262181, 0.5866935483870968, 0.5, 0.9429250891795482, 0.8922588099364529, 0.6741279069767442, 0.6000572573718866]\n",
      "save model\n",
      "kmeans average accuracy best : 88.24%, kmeans average accuracy : 88.23872587%, total [0.9755264655663062, 0.9772856331629756, 0.9729651998849583, 0.9643062751871042, 0.9618768328445748, 0.9443181818181818, 0.8774552917033128, 0.7898468519568916, 0.9512267218445167, 0.9051624129930395, 0.8168202764976958, 0.7551259519625073, 0.9271700356718192, 0.8578856152512998, 0.7584302325581396, 0.6827941597480676]\n",
      "cluster_accuracy_post_training_cycle_all_dataset : [0.97634816 0.97690858 0.97159364 0.96383799 0.96368159 0.94292453\n",
      " 0.88115365 0.7911571  0.93444276 0.8984375  0.8030888  0.75521351\n",
      " 0.9302444  0.87827352 0.77009804 0.68752986]\n",
      "mean_cluster_accuracy_during_training_cycle : 87.76%, post_traincycle_acc : 88.28%, total_acc : 88.06729768%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 88.28%\n",
      "accuracy_check 실행 시간: 23.760초\n",
      "\n",
      "\n",
      "epoch-3 loss : 0.01715505, loss_normal : 0.01648719, loss_coarse : 0.07754206, min_loss : 0.01715505, min_loss_normal : 0.01648719, min_loss_coarse : 0.07754206, wrong_element_sum : 14888076.00000000, same_data : 0.00%\n",
      "ae train 실행 시간: 116.937초, 전체 시작 시간 20250314_000157_781\n",
      "\n",
      "epoch-3 accuracy check\n",
      "k_means origin feature average accuracy : 82.26578875%, total [0.9746727376209448, 0.9733106189664963, 0.9700891573195284, 0.9530800230282096, 0.943108504398827, 0.9150568181818182, 0.801817648783348, 0.6625070901871809, 0.9488619568430388, 0.822215777262181, 0.5872695852534562, 0.5005858230814294, 0.9429250891795482, 0.8922588099364529, 0.6747093023255814, 0.6000572573718866]\n",
      "kmeans average accuracy best : 88.24%, kmeans average accuracy : 87.45257693%, total [0.9758110415480934, 0.9772856331629756, 0.9726775956284153, 0.9668969487622338, 0.963049853372434, 0.9426136363636364, 0.8856640281442393, 0.7702779353374929, 0.9538870824711795, 0.87877030162413, 0.7862903225806451, 0.7463386057410663, 0.89179548156956, 0.8541305603697285, 0.7593023255813953, 0.6676209561981105]\n",
      "cluster_accuracy_post_training_cycle_all_dataset : [0.97492904 0.97596607 0.96918633 0.96624879 0.96318408 0.94339623\n",
      " 0.89259075 0.73941675 0.93898134 0.88183594 0.77944015 0.71400199\n",
      " 0.89002037 0.86323957 0.77009804 0.65551839]\n",
      "mean_cluster_accuracy_during_training_cycle : 87.29%, post_traincycle_acc : 86.99%, total_acc : 87.10842864%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 88.28%\n",
      "accuracy_check 실행 시간: 23.740초\n",
      "\n",
      "\n",
      "epoch-4 loss : 0.01709694, loss_normal : 0.01647714, loss_coarse : 0.07752013, min_loss : 0.01709694, min_loss_normal : 0.01647714, min_loss_coarse : 0.07752013, wrong_element_sum : 14883866.00000000, same_data : 0.00%\n",
      "ae train 실행 시간: 115.621초, 전체 시작 시간 20250314_000157_781\n",
      "\n",
      "epoch-4 accuracy check\n",
      "k_means origin feature average accuracy : 82.25496539%, total [0.9746727376209448, 0.9733106189664963, 0.9700891573195284, 0.9530800230282096, 0.943108504398827, 0.9150568181818182, 0.801817648783348, 0.6622234826999432, 0.9488619568430388, 0.822215777262181, 0.5866935483870968, 0.5005858230814294, 0.9429250891795482, 0.8922588099364529, 0.6738372093023256, 0.6000572573718866]\n",
      "save model\n",
      "kmeans average accuracy best : 88.59%, kmeans average accuracy : 88.58883769%, total [0.9766647694934547, 0.9775695627484384, 0.9732528041415013, 0.9691997697179044, 0.9648093841642229, 0.9502840909090909, 0.8812664907651715, 0.7742484401588202, 0.9595033993496896, 0.9011020881670534, 0.8087557603686636, 0.7454598711189221, 0.9444114149821641, 0.8821490467937608, 0.7758720930232558, 0.6896650443744632]\n",
      "cluster_accuracy_post_training_cycle_all_dataset : [0.97445601 0.97596607 0.97159364 0.96624879 0.96517413 0.9495283\n",
      " 0.89109896 0.7798683  0.95057993 0.90234375 0.79295367 0.71896723\n",
      " 0.9404277  0.89767216 0.78186275 0.68944099]\n",
      "mean_cluster_accuracy_during_training_cycle : 88.31%, post_traincycle_acc : 88.43%, total_acc : 88.37597140%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 88.43%\n",
      "accuracy_check 실행 시간: 23.157초\n",
      "\n",
      "\n",
      "epoch-5 loss : 0.01681278, loss_normal : 0.01640900, loss_coarse : 0.07706626, min_loss : 0.01681278, min_loss_normal : 0.01640900, min_loss_coarse : 0.07706626, wrong_element_sum : 14796722.00000000, same_data : 0.00%\n",
      "ae train 실행 시간: 110.242초, 전체 시작 시간 20250314_000157_781\n",
      "\n",
      "epoch-5 accuracy check\n",
      "k_means origin feature average accuracy : 82.25504809%, total [0.9746727376209448, 0.9733106189664963, 0.9700891573195284, 0.9530800230282096, 0.943108504398827, 0.9150568181818182, 0.801817648783348, 0.6622234826999432, 0.9488619568430388, 0.822215777262181, 0.5866935483870968, 0.5005858230814294, 0.9429250891795482, 0.8922588099364529, 0.6747093023255814, 0.5991983967935872]\n",
      "kmeans average accuracy best : 88.59%, kmeans average accuracy : 87.89603307%, total [0.9758110415480934, 0.9775695627484384, 0.9729651998849583, 0.9671848013816926, 0.963049853372434, 0.9443181818181818, 0.8765757842274993, 0.7736812251843449, 0.9565474430978421, 0.8842807424593968, 0.7943548387096774, 0.7325717633274751, 0.9244946492271106, 0.866262276140959, 0.7691860465116279, 0.6845118809046665]\n",
      "cluster_accuracy_post_training_cycle_all_dataset : [0.97540208 0.97549482 0.97014925 0.96528447 0.96467662 0.94858491\n",
      " 0.89656887 0.75870179 0.94200706 0.84912109 0.77799228 0.72790467\n",
      " 0.92515275 0.87875849 0.77401961 0.63258481]\n",
      "mean_cluster_accuracy_during_training_cycle : 87.07%, post_traincycle_acc : 87.27%, total_acc : 87.17882658%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 88.43%\n",
      "accuracy_check 실행 시간: 24.109초\n",
      "\n",
      "\n",
      "epoch-6 loss : 0.01673841, loss_normal : 0.01637619, loss_coarse : 0.07689762, min_loss : 0.01673841, min_loss_normal : 0.01637619, min_loss_coarse : 0.07689762, wrong_element_sum : 14764344.00000000, same_data : 0.00%\n",
      "ae train 실행 시간: 112.997초, 전체 시작 시간 20250314_000157_781\n",
      "\n",
      "epoch-6 accuracy check\n",
      "k_means origin feature average accuracy : 82.26395946%, total [0.9746727376209448, 0.9733106189664963, 0.9700891573195284, 0.9530800230282096, 0.943108504398827, 0.915340909090909, 0.8015244796247435, 0.6622234826999432, 0.9488619568430388, 0.822215777262181, 0.5872695852534562, 0.5005858230814294, 0.9429250891795482, 0.8922588099364529, 0.6747093023255814, 0.6000572573718866]\n",
      "kmeans average accuracy best : 88.59%, kmeans average accuracy : 87.40085933%, total [0.9752418895845191, 0.9775695627484384, 0.9726775956284153, 0.9671848013816926, 0.963049853372434, 0.9326704545454545, 0.8674875403107593, 0.7509926262053318, 0.9491575524682234, 0.8938515081206496, 0.8038594470046083, 0.7428236672524897, 0.915576694411415, 0.8596187175043327, 0.7627906976744186, 0.649584884053822]\n",
      "cluster_accuracy_post_training_cycle_all_dataset : [0.97445601 0.97408106 0.97063072 0.96239151 0.96368159 0.93443396\n",
      " 0.87817006 0.74317968 0.94150277 0.87841797 0.79874517 0.74826216\n",
      " 0.91700611 0.86760427 0.77058824 0.65121835]\n",
      "mean_cluster_accuracy_during_training_cycle : 87.07%, post_traincycle_acc : 87.34%, total_acc : 87.22477116%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 88.43%\n",
      "accuracy_check 실행 시간: 23.337초\n",
      "\n",
      "\n",
      "epoch-7 loss : 0.01644626, loss_normal : 0.01631982, loss_coarse : 0.07643148, min_loss : 0.01644626, min_loss_normal : 0.01631982, min_loss_coarse : 0.07643148, wrong_element_sum : 14674844.00000000, same_data : 0.00%\n",
      "ae train 실행 시간: 85.684초, 전체 시작 시간 20250314_000157_781\n",
      "\n",
      "epoch-7 accuracy check\n",
      "k_means origin feature average accuracy : 82.26218852%, total [0.9746727376209448, 0.9733106189664963, 0.9700891573195284, 0.9530800230282096, 0.943108504398827, 0.9150568181818182, 0.801817648783348, 0.6625070901871809, 0.9488619568430388, 0.822215777262181, 0.5866935483870968, 0.5005858230814294, 0.9429250891795482, 0.8922588099364529, 0.6747093023255814, 0.6000572573718866]\n",
      "save model\n",
      "kmeans average accuracy best : 88.63%, kmeans average accuracy : 88.63089309%, total [0.9755264655663062, 0.9772856331629756, 0.9729651998849583, 0.9668969487622338, 0.9656891495601173, 0.9471590909090909, 0.8897683963647024, 0.7816222348269994, 0.9722140112326337, 0.9202436194895591, 0.8220046082949308, 0.7510251903925015, 0.9369797859690844, 0.8642403235124205, 0.765406976744186, 0.6719152590896078]\n",
      "cluster_accuracy_post_training_cycle_all_dataset : [0.97587512 0.97643732 0.97063072 0.96432015 0.96915423 0.94716981\n",
      " 0.90104426 0.75870179 0.96520424 0.921875   0.80405405 0.68917577\n",
      " 0.94246436 0.87051406 0.76617647 0.52747253]\n",
      "mean_cluster_accuracy_during_training_cycle : 87.32%, post_traincycle_acc : 87.19%, total_acc : 87.23391136%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 87.19%\n",
      "accuracy_check 실행 시간: 24.439초\n",
      "\n",
      "\n",
      "epoch-8 loss : 0.01649547, loss_normal : 0.01631237, loss_coarse : 0.07643878, min_loss : 0.01644626, min_loss_normal : 0.01631237, min_loss_coarse : 0.07643148, wrong_element_sum : 14676246.00000000, same_data : 0.00%\n",
      "ae train 실행 시간: 89.251초, 전체 시작 시간 20250314_000157_781\n",
      "\n",
      "epoch-8 accuracy check\n",
      "k_means origin feature average accuracy : 82.24056372%, total [0.9746727376209448, 0.9733106189664963, 0.9700891573195284, 0.9530800230282096, 0.943108504398827, 0.9150568181818182, 0.8015244796247435, 0.6625070901871809, 0.9488619568430388, 0.822215777262181, 0.5866935483870968, 0.5005858230814294, 0.9429250891795482, 0.8922588099364529, 0.673546511627907, 0.5980532493558546]\n",
      "kmeans average accuracy best : 88.63%, kmeans average accuracy : 88.55623560%, total [0.9760956175298805, 0.9770017035775128, 0.9732528041415013, 0.9677605066206102, 0.9659824046920821, 0.9536931818181819, 0.9053063617707418, 0.7975042541123085, 0.9515223174697014, 0.8924013921113689, 0.7966589861751152, 0.7255418863503222, 0.9224137931034483, 0.877527440785673, 0.7880813953488373, 0.6982536501574578]\n",
      "cluster_accuracy_post_training_cycle_all_dataset : [0.97587512 0.97549482 0.97014925 0.96432015 0.96766169 0.95235849\n",
      " 0.91248135 0.76904986 0.94301563 0.90332031 0.77557915 0.64796425\n",
      " 0.92973523 0.89767216 0.78676471 0.69851887]\n",
      "mean_cluster_accuracy_during_training_cycle : 86.96%, post_traincycle_acc : 87.94%, total_acc : 87.53662985%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 87.19%\n",
      "accuracy_check 실행 시간: 23.561초\n",
      "\n",
      "\n",
      "epoch-9 loss : 0.01639670, loss_normal : 0.01627376, loss_coarse : 0.07626649, min_loss : 0.01639670, min_loss_normal : 0.01627376, min_loss_coarse : 0.07626649, wrong_element_sum : 14643166.00000000, same_data : 0.00%\n",
      "ae train 실행 시간: 119.439초, 전체 시작 시간 20250314_000157_781\n",
      "\n",
      "epoch-9 accuracy check\n",
      "k_means origin feature average accuracy : 82.23879117%, total [0.9746727376209448, 0.9733106189664963, 0.9700891573195284, 0.9530800230282096, 0.943108504398827, 0.9150568181818182, 0.8015244796247435, 0.6622234826999432, 0.9488619568430388, 0.822215777262181, 0.5866935483870968, 0.5005858230814294, 0.9429250891795482, 0.8922588099364529, 0.673546511627907, 0.5980532493558546]\n",
      "kmeans average accuracy best : 88.63%, kmeans average accuracy : 88.20665588%, total [0.9760956175298805, 0.9775695627484384, 0.9729651998849583, 0.966321243523316, 0.9627565982404692, 0.9352272727272727, 0.8663148636763413, 0.7600680657969371, 0.9692580549807863, 0.912122969837587, 0.8142281105990783, 0.7363796133567663, 0.9402497027348394, 0.8679953783939919, 0.7755813953488372, 0.6799312911537361]\n",
      "cluster_accuracy_post_training_cycle_all_dataset : [0.97445601 0.97502356 0.96966779 0.96046287 0.96716418 0.94716981\n",
      " 0.8876181  0.76105362 0.96016137 0.92089844 0.79488417 0.51340616\n",
      " 0.94857434 0.88748788 0.78186275 0.68752986]\n",
      "mean_cluster_accuracy_during_training_cycle : 86.53%, post_traincycle_acc : 87.11%, total_acc : 86.87233139%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 87.19%\n",
      "accuracy_check 실행 시간: 23.162초\n",
      "\n",
      "\n",
      "epoch-10 loss : 0.01624656, loss_normal : 0.01621347, loss_coarse : 0.07592118, min_loss : 0.01624656, min_loss_normal : 0.01621347, min_loss_coarse : 0.07592118, wrong_element_sum : 14576866.00000000, same_data : 0.00%\n",
      "ae train 실행 시간: 91.231초, 전체 시작 시간 20250314_000157_781\n",
      "\n",
      "epoch-10 accuracy check\n",
      "k_means origin feature average accuracy : 82.25135633%, total [0.9746727376209448, 0.9733106189664963, 0.9700891573195284, 0.9530800230282096, 0.943108504398827, 0.915340909090909, 0.801817648783348, 0.6625070901871809, 0.9488619568430388, 0.822215777262181, 0.5866935483870968, 0.5005858230814294, 0.9429250891795482, 0.8922588099364529, 0.6738372093023256, 0.598912109934154]\n",
      "kmeans average accuracy best : 88.63%, kmeans average accuracy : 87.48254718%, total [0.9763801935116676, 0.9775695627484384, 0.9726775956284153, 0.968048359240069, 0.9656891495601173, 0.9403409090909091, 0.8798006449721489, 0.7577992058990357, 0.9621637599763524, 0.8410672853828306, 0.8015552995391705, 0.7319859402460457, 0.91884661117717, 0.8700173310225303, 0.7622093023255814, 0.6710563985113084]\n",
      "cluster_accuracy_post_training_cycle_all_dataset : [0.97682119 0.97643732 0.97014925 0.96480231 0.96616915 0.94764151\n",
      " 0.88562904 0.74976482 0.9626828  0.88232422 0.74034749 0.69811321\n",
      " 0.91598778 0.88457808 0.76960784 0.66555184]\n",
      "mean_cluster_accuracy_during_training_cycle : 87.02%, post_traincycle_acc : 87.23%, total_acc : 87.14180439%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 87.19%\n",
      "accuracy_check 실행 시간: 23.968초\n",
      "\n",
      "\n",
      "epoch-11 loss : 0.01619856, loss_normal : 0.01617481, loss_coarse : 0.07578679, min_loss : 0.01619856, min_loss_normal : 0.01617481, min_loss_coarse : 0.07578679, wrong_element_sum : 14551064.00000000, same_data : 0.00%\n",
      "ae train 실행 시간: 114.762초, 전체 시작 시간 20250314_000157_781\n",
      "\n",
      "epoch-11 accuracy check\n",
      "k_means origin feature average accuracy : 82.24778065%, total [0.9746727376209448, 0.9733106189664963, 0.9700891573195284, 0.9530800230282096, 0.943108504398827, 0.9150568181818182, 0.801817648783348, 0.6622234826999432, 0.9488619568430388, 0.822215777262181, 0.5866935483870968, 0.5005858230814294, 0.9429250891795482, 0.8922588099364529, 0.673546511627907, 0.5991983967935872]\n",
      "kmeans average accuracy best : 88.63%, kmeans average accuracy : 86.80677231%, total [0.9766647694934547, 0.9770017035775128, 0.9735404083980443, 0.9694876223373633, 0.9651026392961877, 0.9420454545454545, 0.8666080328349458, 0.738230289279637, 0.9600945906000591, 0.851508120649652, 0.7076612903225806, 0.6942003514938488, 0.9420332936979786, 0.877527440785673, 0.7677325581395349, 0.6796450042943029]\n",
      "cluster_accuracy_post_training_cycle_all_dataset : [0.97445601 0.97502356 0.97159364 0.96432015 0.96616915 0.94811321\n",
      " 0.89358528 0.75070555 0.93948563 0.8984375  0.72683398 0.65342602\n",
      " 0.94195519 0.88748788 0.775      0.65074056]\n",
      "mean_cluster_accuracy_during_training_cycle : 86.33%, post_traincycle_acc : 86.98%, total_acc : 86.71583491%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 87.19%\n",
      "accuracy_check 실행 시간: 24.128초\n",
      "\n",
      "\n",
      "epoch-12 loss : 0.01625274, loss_normal : 0.01622294, loss_coarse : 0.07595515, min_loss : 0.01619856, min_loss_normal : 0.01617481, min_loss_coarse : 0.07578679, wrong_element_sum : 14583390.00000000, same_data : 0.00%\n",
      "ae train 실행 시간: 114.476초, 전체 시작 시간 20250314_000157_781\n",
      "\n",
      "epoch-12 accuracy check\n",
      "k_means origin feature average accuracy : 82.26037166%, total [0.9746727376209448, 0.9733106189664963, 0.9700891573195284, 0.9530800230282096, 0.943108504398827, 0.9150568181818182, 0.801817648783348, 0.6625070901871809, 0.9488619568430388, 0.822215777262181, 0.5866935483870968, 0.5005858230814294, 0.9429250891795482, 0.8922588099364529, 0.6744186046511628, 0.6000572573718866]\n",
      "kmeans average accuracy best : 88.63%, kmeans average accuracy : 86.55681024%, total [0.9758110415480934, 0.9772856331629756, 0.9735404083980443, 0.9677605066206102, 0.9615835777126099, 0.9292613636363637, 0.8528290823805336, 0.7056154282473057, 0.9674844812296778, 0.9208236658932715, 0.8338133640552995, 0.7606912712360867, 0.9259809750297265, 0.8341998844598498, 0.7281976744186046, 0.5342112797022617]\n",
      "cluster_accuracy_post_training_cycle_all_dataset : [0.97256386 0.97455231 0.96966779 0.96432015 0.96368159 0.92877358\n",
      " 0.85877673 0.69990593 0.96116994 0.9140625  0.79584942 0.49453823\n",
      " 0.93329939 0.83705141 0.74754902 0.61490683]\n",
      "mean_cluster_accuracy_during_training_cycle : 85.70%, post_traincycle_acc : 85.19%, total_acc : 85.39515468%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 87.19%\n",
      "accuracy_check 실행 시간: 24.100초\n",
      "\n",
      "\n",
      "epoch-13 loss : 0.01610593, loss_normal : 0.01618504, loss_coarse : 0.07565789, min_loss : 0.01610593, min_loss_normal : 0.01617481, min_loss_coarse : 0.07565789, wrong_element_sum : 14526316.00000000, same_data : 0.00%\n",
      "ae train 실행 시간: 110.999초, 전체 시작 시간 20250314_000157_781\n",
      "\n",
      "epoch-13 accuracy check\n",
      "k_means origin feature average accuracy : 82.25678715%, total [0.9746727376209448, 0.9733106189664963, 0.9700891573195284, 0.9530800230282096, 0.943108504398827, 0.9150568181818182, 0.801817648783348, 0.6625070901871809, 0.9488619568430388, 0.822215777262181, 0.5872695852534562, 0.5005858230814294, 0.9429250891795482, 0.8922588099364529, 0.6741279069767442, 0.5991983967935872]\n",
      "kmeans average accuracy best : 88.63%, kmeans average accuracy : 87.87845074%, total [0.9766647694934547, 0.9772856331629756, 0.9741156169111302, 0.9689119170984456, 0.9659824046920821, 0.9485795454545455, 0.8736440926414542, 0.7733976176971072, 0.966006503103754, 0.8657192575406032, 0.763536866359447, 0.7252489748096075, 0.9530321046373365, 0.8778162911611785, 0.7732558139534884, 0.6773547094188377]\n",
      "cluster_accuracy_post_training_cycle_all_dataset : [0.97492904 0.97455231 0.97159364 0.96335583 0.96616915 0.95\n",
      " 0.90601691 0.77281279 0.96217852 0.89160156 0.74420849 0.70456802\n",
      " 0.95366599 0.8986421  0.75490196 0.64261825]\n",
      "mean_cluster_accuracy_during_training_cycle : 87.35%, post_traincycle_acc : 87.70%, total_acc : 87.55484756%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 87.19%\n",
      "accuracy_check 실행 시간: 23.787초\n",
      "\n",
      "\n",
      "epoch-14 loss : 0.01606755, loss_normal : 0.01616859, loss_coarse : 0.07557325, min_loss : 0.01606755, min_loss_normal : 0.01616859, min_loss_coarse : 0.07557325, wrong_element_sum : 14510064.00000000, same_data : 0.00%\n",
      "ae train 실행 시간: 117.798초, 전체 시작 시간 20250314_000157_781\n",
      "\n",
      "epoch-14 accuracy check\n",
      "k_means origin feature average accuracy : 82.26571524%, total [0.9746727376209448, 0.9733106189664963, 0.9700891573195284, 0.9530800230282096, 0.943108504398827, 0.9150568181818182, 0.801817648783348, 0.6622234826999432, 0.9488619568430388, 0.822215777262181, 0.5866935483870968, 0.5005858230814294, 0.942627824019025, 0.8922588099364529, 0.6747093023255814, 0.6012024048096193]\n",
      "kmeans average accuracy best : 88.63%, kmeans average accuracy : 88.00094629%, total [0.9766647694934547, 0.9770017035775128, 0.9738280126545873, 0.9697754749568221, 0.9651026392961877, 0.9451704545454546, 0.883318674875403, 0.7543959160521838, 0.9562518474726575, 0.8973317865429234, 0.7934907834101382, 0.7422378441710603, 0.9348989298454221, 0.8755054881571346, 0.7561046511627907, 0.6790724305754365]\n",
      "cluster_accuracy_post_training_cycle_all_dataset : [0.97492904 0.97502356 0.97063072 0.96624879 0.96716418 0.94716981\n",
      " 0.89855793 0.74317968 0.95461422 0.90234375 0.76254826 0.60228401\n",
      " 0.93686354 0.88845781 0.76568627 0.67128524]\n",
      "mean_cluster_accuracy_during_training_cycle : 86.75%, post_traincycle_acc : 87.04%, total_acc : 86.92133732%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 87.19%\n",
      "accuracy_check 실행 시간: 23.160초\n",
      "\n",
      "\n",
      "epoch-15 loss : 0.01602514, loss_normal : 0.01616146, loss_coarse : 0.07553723, min_loss : 0.01602514, min_loss_normal : 0.01616146, min_loss_coarse : 0.07553723, wrong_element_sum : 14503148.00000000, same_data : 0.00%\n",
      "ae train 실행 시간: 117.066초, 전체 시작 시간 20250314_000157_781\n",
      "\n",
      "epoch-15 accuracy check\n",
      "k_means origin feature average accuracy : 82.26041597%, total [0.9746727376209448, 0.9733106189664963, 0.9700891573195284, 0.9530800230282096, 0.943108504398827, 0.9150568181818182, 0.801817648783348, 0.6622234826999432, 0.9488619568430388, 0.822215777262181, 0.5866935483870968, 0.5005858230814294, 0.9429250891795482, 0.8922588099364529, 0.6747093023255814, 0.6000572573718866]\n",
      "save model\n",
      "kmeans average accuracy best : 89.23%, kmeans average accuracy : 89.22565244%, total [0.9763801935116676, 0.9772856331629756, 0.9735404083980443, 0.9689119170984456, 0.9668621700879766, 0.9576704545454545, 0.909410729991205, 0.7918321043675554, 0.9609813774756134, 0.9089327146171694, 0.806163594470046, 0.7568834212067955, 0.9548156956004756, 0.8983246678220682, 0.7755813953488372, 0.6925279129687947]\n",
      "cluster_accuracy_post_training_cycle_all_dataset : [0.97540208 0.97455231 0.97063072 0.96335583 0.9681592  0.95518868\n",
      " 0.91596221 0.79209784 0.96369138 0.90283203 0.81274131 0.72343595\n",
      " 0.95264766 0.90785645 0.78578431 0.68036312]\n",
      "mean_cluster_accuracy_during_training_cycle : 88.53%, post_traincycle_acc : 89.03%, total_acc : 88.82369497%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 89.03%\n",
      "accuracy_check 실행 시간: 23.456초\n",
      "\n",
      "\n",
      "epoch-16 loss : 0.01591056, loss_normal : 0.01611229, loss_coarse : 0.07524121, min_loss : 0.01591056, min_loss_normal : 0.01611229, min_loss_coarse : 0.07524121, wrong_element_sum : 14446312.00000000, same_data : 0.00%\n",
      "ae train 실행 시간: 116.654초, 전체 시작 시간 20250314_000157_781\n",
      "\n",
      "epoch-16 accuracy check\n",
      "k_means origin feature average accuracy : 82.26222691%, total [0.9746727376209448, 0.9733106189664963, 0.9700891573195284, 0.9530800230282096, 0.943108504398827, 0.9150568181818182, 0.801817648783348, 0.6622234826999432, 0.9488619568430388, 0.822215777262181, 0.5872695852534562, 0.5005858230814294, 0.9429250891795482, 0.8922588099364529, 0.6747093023255814, 0.5997709705124534]\n",
      "kmeans average accuracy best : 89.23%, kmeans average accuracy : 88.40498068%, total [0.9766647694934547, 0.9770017035775128, 0.9735404083980443, 0.9686240644789867, 0.9648093841642229, 0.9505681818181818, 0.8991498094400469, 0.7980714690867838, 0.9633461424770914, 0.9031322505800464, 0.7969470046082949, 0.7355008787346221, 0.9408442330558858, 0.8590410167533218, 0.7619186046511628, 0.6756369882622387]\n",
      "cluster_accuracy_post_training_cycle_all_dataset : [0.97587512 0.97502356 0.97063072 0.96287367 0.96567164 0.95188679\n",
      " 0.90104426 0.81655691 0.95713565 0.89160156 0.77702703 0.55958292\n",
      " 0.94195519 0.88166828 0.77156863 0.67128524]\n",
      "mean_cluster_accuracy_during_training_cycle : 86.89%, post_traincycle_acc : 87.32%, total_acc : 87.14596014%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 89.03%\n",
      "accuracy_check 실행 시간: 23.466초\n",
      "\n",
      "\n",
      "epoch-17 loss : 0.01608383, loss_normal : 0.01617896, loss_coarse : 0.07561898, min_loss : 0.01591056, min_loss_normal : 0.01611229, min_loss_coarse : 0.07524121, wrong_element_sum : 14518844.00000000, same_data : 0.00%\n",
      "ae train 실행 시간: 115.513초, 전체 시작 시간 20250314_000157_781\n",
      "\n",
      "epoch-17 accuracy check\n",
      "k_means origin feature average accuracy : 82.25504809%, total [0.9746727376209448, 0.9733106189664963, 0.9700891573195284, 0.9530800230282096, 0.943108504398827, 0.9150568181818182, 0.801817648783348, 0.6622234826999432, 0.9488619568430388, 0.822215777262181, 0.5866935483870968, 0.5005858230814294, 0.9429250891795482, 0.8922588099364529, 0.6747093023255814, 0.5991983967935872]\n",
      "kmeans average accuracy best : 89.23%, kmeans average accuracy : 87.47500991%, total [0.9763801935116676, 0.9775695627484384, 0.9732528041415013, 0.9691997697179044, 0.9668621700879766, 0.9508522727272727, 0.8812664907651715, 0.7685762904140669, 0.9689624593556015, 0.9031322505800464, 0.7600806451612904, 0.7024018746338606, 0.925089179548157, 0.8743500866551126, 0.7415697674418604, 0.6564557686802176]\n",
      "cluster_accuracy_post_training_cycle_all_dataset : [0.97445601 0.97502356 0.97159364 0.96480231 0.96766169 0.9504717\n",
      " 0.89557434 0.7939793  0.96167423 0.90478516 0.78667954 0.61271102\n",
      " 0.9200611  0.87051406 0.73627451 0.63258481]\n",
      "mean_cluster_accuracy_during_training_cycle : 86.81%, post_traincycle_acc : 86.99%, total_acc : 86.91998807%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 89.03%\n",
      "accuracy_check 실행 시간: 23.819초\n",
      "\n",
      "\n",
      "epoch-18 loss : 0.01595523, loss_normal : 0.01613587, loss_coarse : 0.07539674, min_loss : 0.01591056, min_loss_normal : 0.01611229, min_loss_coarse : 0.07524121, wrong_element_sum : 14476174.00000000, same_data : 0.00%\n",
      "ae train 실행 시간: 114.543초, 전체 시작 시간 20250314_000157_781\n",
      "\n",
      "epoch-18 accuracy check\n",
      "k_means origin feature average accuracy : 82.25673504%, total [0.9746727376209448, 0.9733106189664963, 0.9700891573195284, 0.9530800230282096, 0.943108504398827, 0.915340909090909, 0.801817648783348, 0.6622234826999432, 0.9488619568430388, 0.822215777262181, 0.5872695852534562, 0.5005858230814294, 0.9429250891795482, 0.8922588099364529, 0.673546511627907, 0.5997709705124534]\n",
      "kmeans average accuracy best : 89.23%, kmeans average accuracy : 87.81720259%, total [0.9766647694934547, 0.9772856331629756, 0.9744032211676733, 0.971790443293034, 0.9671554252199414, 0.9553977272727273, 0.9014951627088831, 0.7850255246738513, 0.9642329293526456, 0.898491879350348, 0.7439516129032258, 0.7003514938488576, 0.9259809750297265, 0.878105141536684, 0.7633720930232558, 0.6670483824792443]\n",
      "cluster_accuracy_post_training_cycle_all_dataset : [0.97540208 0.97549482 0.97207511 0.96769527 0.96865672 0.95613208\n",
      " 0.91695674 0.79774224 0.9591528  0.90820312 0.76351351 0.58788481\n",
      " 0.92107943 0.87487876 0.77058824 0.64309603]\n",
      "mean_cluster_accuracy_during_training_cycle : 87.23%, post_traincycle_acc : 87.24%, total_acc : 87.23481756%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 89.03%\n",
      "accuracy_check 실행 시간: 23.918초\n",
      "\n",
      "\n",
      "epoch-19 loss : 0.01597581, loss_normal : 0.01613915, loss_coarse : 0.07543691, min_loss : 0.01591056, min_loss_normal : 0.01611229, min_loss_coarse : 0.07524121, wrong_element_sum : 14483888.00000000, same_data : 0.00%\n",
      "ae train 실행 시간: 113.168초, 전체 시작 시간 20250314_000157_781\n",
      "\n",
      "epoch-19 accuracy check\n",
      "k_means origin feature average accuracy : 82.81326524%, total [0.9746727376209448, 0.9733106189664963, 0.9700891573195284, 0.9530800230282096, 0.943108504398827, 0.9150568181818182, 0.8015244796247435, 0.6622234826999432, 0.9488619568430388, 0.822215777262181, 0.5872695852534562, 0.5896309314586995, 0.9429250891795482, 0.8922588099364529, 0.6738372093023256, 0.6000572573718866]\n",
      "kmeans average accuracy best : 89.23%, kmeans average accuracy : 88.05415800%, total [0.9769493454752419, 0.9775695627484384, 0.9741156169111302, 0.9703511801957397, 0.9665689149560117, 0.9528409090909091, 0.8929932571093521, 0.783607487237663, 0.9394028968371269, 0.8796403712296984, 0.7716013824884793, 0.7363796133567663, 0.9423305588585018, 0.8734835355285961, 0.7688953488372093, 0.6819352991697681]\n",
      "cluster_accuracy_post_training_cycle_all_dataset : [0.97492904 0.97596607 0.97111218 0.96480231 0.96766169 0.95283019\n",
      " 0.90303332 0.78739417 0.95360565 0.90576172 0.79198842 0.50148957\n",
      " 0.92718941 0.88748788 0.7745098  0.66220736]\n",
      "mean_cluster_accuracy_during_training_cycle : 86.39%, post_traincycle_acc : 86.89%, total_acc : 86.68232198%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 89.03%\n",
      "accuracy_check 실행 시간: 23.977초\n",
      "\n",
      "\n",
      "epoch-20 loss : 0.01583941, loss_normal : 0.01607039, loss_coarse : 0.07510090, min_loss : 0.01583941, min_loss_normal : 0.01607039, min_loss_coarse : 0.07510090, wrong_element_sum : 14419374.00000000, same_data : 0.00%\n",
      "ae train 실행 시간: 112.706초, 전체 시작 시간 20250314_000157_781\n",
      "\n",
      "epoch-20 accuracy check\n",
      "k_means origin feature average accuracy : 82.25326370%, total [0.9746727376209448, 0.9733106189664963, 0.9700891573195284, 0.9530800230282096, 0.943108504398827, 0.9150568181818182, 0.801817648783348, 0.6625070901871809, 0.9488619568430388, 0.822215777262181, 0.5872695852534562, 0.5005858230814294, 0.9429250891795482, 0.8922588099364529, 0.6747093023255814, 0.5980532493558546]\n",
      "kmeans average accuracy best : 89.23%, kmeans average accuracy : 88.02877604%, total [0.9766647694934547, 0.9775695627484384, 0.9738280126545873, 0.9689119170984456, 0.9665689149560117, 0.9443181818181818, 0.8745236001172677, 0.762620533182076, 0.968371268105232, 0.9051624129930395, 0.7888824884792627, 0.7407732864674869, 0.9313317479191439, 0.8731946851530907, 0.765406976744186, 0.6664758087603779]\n",
      "cluster_accuracy_post_training_cycle_all_dataset : [0.97445601 0.97690858 0.97207511 0.96673095 0.96865672 0.95\n",
      " 0.89060169 0.74882408 0.96419566 0.91015625 0.82915058 0.60278054\n",
      " 0.92769857 0.88797284 0.75588235 0.66125179]\n",
      "mean_cluster_accuracy_during_training_cycle : 86.69%, post_traincycle_acc : 87.42%, total_acc : 87.12283559%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 89.03%\n",
      "accuracy_check 실행 시간: 23.712초\n",
      "\n",
      "\n",
      "epoch-21 loss : 0.01602793, loss_normal : 0.01614051, loss_coarse : 0.07547384, min_loss : 0.01583941, min_loss_normal : 0.01607039, min_loss_coarse : 0.07510090, wrong_element_sum : 14490978.00000000, same_data : 0.00%\n",
      "ae train 실행 시간: 85.949초, 전체 시작 시간 20250314_000157_781\n",
      "\n",
      "epoch-21 accuracy check\n",
      "k_means origin feature average accuracy : 82.25492108%, total [0.9746727376209448, 0.9733106189664963, 0.9700891573195284, 0.9530800230282096, 0.943108504398827, 0.9150568181818182, 0.801817648783348, 0.6625070901871809, 0.9488619568430388, 0.822215777262181, 0.5866935483870968, 0.5005858230814294, 0.9429250891795482, 0.8922588099364529, 0.673546511627907, 0.6000572573718866]\n",
      "kmeans average accuracy best : 89.23%, kmeans average accuracy : 86.72911844%, total [0.9769493454752419, 0.9772856331629756, 0.9741156169111302, 0.9697754749568221, 0.9653958944281525, 0.9457386363636363, 0.8258575197889182, 0.7266023823028928, 0.9663020987289388, 0.9144431554524362, 0.7534562211981567, 0.6991798476859988, 0.9256837098692033, 0.8541305603697285, 0.7412790697674418, 0.6604637847122817]\n",
      "cluster_accuracy_post_training_cycle_all_dataset : [0.97445601 0.97643732 0.97159364 0.96335583 0.96666667 0.94528302\n",
      " 0.87220288 0.71072437 0.9626828  0.91210938 0.76833977 0.60079444\n",
      " 0.91751527 0.85596508 0.72254902 0.6411849 ]\n",
      "mean_cluster_accuracy_during_training_cycle : 85.58%, post_traincycle_acc : 86.01%, total_acc : 85.83063423%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 89.03%\n",
      "accuracy_check 실행 시간: 24.101초\n",
      "\n",
      "\n",
      "epoch-22 loss : 0.01587652, loss_normal : 0.01606460, loss_coarse : 0.07512738, min_loss : 0.01583941, min_loss_normal : 0.01606460, min_loss_coarse : 0.07510090, wrong_element_sum : 14424458.00000000, same_data : 0.00%\n",
      "ae train 실행 시간: 116.094초, 전체 시작 시간 20250314_000157_781\n",
      "\n",
      "epoch-22 accuracy check\n",
      "k_means origin feature average accuracy : 82.25318692%, total [0.9746727376209448, 0.9733106189664963, 0.9700891573195284, 0.9530800230282096, 0.943108504398827, 0.9150568181818182, 0.801817648783348, 0.6625070901871809, 0.9488619568430388, 0.822215777262181, 0.5866935483870968, 0.5005858230814294, 0.9429250891795482, 0.8922588099364529, 0.6741279069767442, 0.5991983967935872]\n",
      "kmeans average accuracy best : 89.23%, kmeans average accuracy : 85.90437298%, total [0.9766647694934547, 0.9775695627484384, 0.9744032211676733, 0.9694876223373633, 0.9624633431085043, 0.9295454545454546, 0.8340662562298446, 0.7478729438457176, 0.9692580549807863, 0.8225058004640371, 0.7404953917050692, 0.7047451669595782, 0.9221165279429251, 0.8405545927209706, 0.7305232558139535, 0.6424277125679931]\n",
      "cluster_accuracy_post_training_cycle_all_dataset : [0.97445601 0.97596607 0.97063072 0.96190935 0.9641791  0.94056604\n",
      " 0.87966186 0.73236124 0.96167423 0.89501953 0.81563707 0.60427011\n",
      " 0.90835031 0.83414161 0.71764706 0.61968466]\n",
      "mean_cluster_accuracy_during_training_cycle : 85.70%, post_traincycle_acc : 85.98%, total_acc : 85.86186923%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 89.03%\n",
      "accuracy_check 실행 시간: 23.398초\n",
      "\n",
      "\n",
      "epoch-23 loss : 0.01586728, loss_normal : 0.01609577, loss_coarse : 0.07525794, min_loss : 0.01583941, min_loss_normal : 0.01606460, min_loss_coarse : 0.07510090, wrong_element_sum : 14449524.00000000, same_data : 0.00%\n",
      "ae train 실행 시간: 117.472초, 전체 시작 시간 20250314_000157_781\n",
      "\n",
      "epoch-23 accuracy check\n",
      "k_means origin feature average accuracy : 82.25858366%, total [0.9746727376209448, 0.9733106189664963, 0.9700891573195284, 0.9530800230282096, 0.943108504398827, 0.9150568181818182, 0.8015244796247435, 0.6622234826999432, 0.9488619568430388, 0.822215777262181, 0.5866935483870968, 0.5005858230814294, 0.9429250891795482, 0.8922588099364529, 0.6747093023255814, 0.6000572573718866]\n",
      "kmeans average accuracy best : 89.23%, kmeans average accuracy : 87.52503445%, total [0.9769493454752419, 0.9775695627484384, 0.9741156169111302, 0.9703511801957397, 0.9656891495601173, 0.9505681818181818, 0.8698328935795955, 0.7433352240499149, 0.9518179130948862, 0.9051624129930395, 0.7808179723502304, 0.7314001171646163, 0.93935790725327, 0.8714615829000578, 0.7311046511627907, 0.6644718007443459]\n",
      "cluster_accuracy_post_training_cycle_all_dataset : [0.97540208 0.97596607 0.97207511 0.96817743 0.96716418 0.95330189\n",
      " 0.89855793 0.74176858 0.94856278 0.89697266 0.79391892 0.60575968\n",
      " 0.93839104 0.83705141 0.72794118 0.65981844]\n",
      "mean_cluster_accuracy_during_training_cycle : 86.20%, post_traincycle_acc : 86.63%, total_acc : 86.45012178%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 89.03%\n",
      "accuracy_check 실행 시간: 23.914초\n",
      "\n",
      "\n",
      "epoch-24 loss : 0.01612986, loss_normal : 0.01615529, loss_coarse : 0.07561326, min_loss : 0.01583941, min_loss_normal : 0.01606460, min_loss_coarse : 0.07510090, wrong_element_sum : 14517746.00000000, same_data : 0.00%\n",
      "ae train 실행 시간: 112.735초, 전체 시작 시간 20250314_000157_781\n",
      "\n",
      "epoch-24 accuracy check\n",
      "k_means origin feature average accuracy : 82.25136465%, total [0.9746727376209448, 0.9733106189664963, 0.9700891573195284, 0.9530800230282096, 0.943108504398827, 0.9150568181818182, 0.801817648783348, 0.6625070901871809, 0.9488619568430388, 0.8216357308584686, 0.5866935483870968, 0.5002929115407148, 0.9429250891795482, 0.8922588099364529, 0.6747093023255814, 0.5991983967935872]\n",
      "kmeans average accuracy best : 89.23%, kmeans average accuracy : 87.53871550%, total [0.9760956175298805, 0.9772856331629756, 0.9732528041415013, 0.9677605066206102, 0.966275659824047, 0.9477272727272728, 0.8557607739665787, 0.737379466817924, 0.9698492462311558, 0.929814385150812, 0.8159562211981567, 0.7510251903925015, 0.9313317479191439, 0.8258232235701907, 0.7232558139534884, 0.6576009161179502]\n",
      "cluster_accuracy_post_training_cycle_all_dataset : [0.97492904 0.97455231 0.97111218 0.96046287 0.96666667 0.94433962\n",
      " 0.88413725 0.77610536 0.95864851 0.93017578 0.82866795 0.55610725\n",
      " 0.9302444  0.83511154 0.72990196 0.63258481]\n",
      "mean_cluster_accuracy_during_training_cycle : 86.52%, post_traincycle_acc : 86.59%, total_acc : 86.55681875%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 89.03%\n",
      "accuracy_check 실행 시간: 24.068초\n",
      "\n",
      "\n",
      "epoch-25 loss : 0.01588018, loss_normal : 0.01606734, loss_coarse : 0.07511126, min_loss : 0.01583941, min_loss_normal : 0.01606460, min_loss_coarse : 0.07510090, wrong_element_sum : 14421362.00000000, same_data : 0.00%\n",
      "ae train 실행 시간: 113.819초, 전체 시작 시간 20250314_000157_781\n",
      "\n",
      "epoch-25 accuracy check\n",
      "k_means origin feature average accuracy : 82.25496539%, total [0.9746727376209448, 0.9733106189664963, 0.9700891573195284, 0.9530800230282096, 0.943108504398827, 0.9150568181818182, 0.801817648783348, 0.6622234826999432, 0.9488619568430388, 0.822215777262181, 0.5866935483870968, 0.5005858230814294, 0.9429250891795482, 0.8922588099364529, 0.6738372093023256, 0.6000572573718866]\n",
      "kmeans average accuracy best : 89.23%, kmeans average accuracy : 87.47143700%, total [0.9766647694934547, 0.9772856331629756, 0.9746908254242163, 0.9689119170984456, 0.9639296187683285, 0.946590909090909, 0.8715919085312225, 0.759217243335224, 0.9512267218445167, 0.9083526682134571, 0.7779377880184332, 0.7252489748096075, 0.9343043995243757, 0.8630849220103987, 0.747093023255814, 0.6492985971943888]\n",
      "cluster_accuracy_post_training_cycle_all_dataset : [0.97540208 0.97643732 0.97255657 0.96335583 0.96616915 0.95235849\n",
      " 0.89955246 0.77281279 0.95562279 0.90429688 0.78619691 0.58192651\n",
      " 0.93329939 0.86226964 0.7254902  0.62637363]\n",
      "mean_cluster_accuracy_during_training_cycle : 84.92%, post_traincycle_acc : 86.59%, total_acc : 85.90933281%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 89.03%\n",
      "accuracy_check 실행 시간: 23.659초\n",
      "\n",
      "\n",
      "epoch-26 loss : 0.01593695, loss_normal : 0.01608837, loss_coarse : 0.07523938, min_loss : 0.01583941, min_loss_normal : 0.01606460, min_loss_coarse : 0.07510090, wrong_element_sum : 14445962.00000000, same_data : 0.00%\n",
      "ae train 실행 시간: 107.952초, 전체 시작 시간 20250314_000157_781\n",
      "\n",
      "epoch-26 accuracy check\n",
      "k_means origin feature average accuracy : 82.26041597%, total [0.9746727376209448, 0.9733106189664963, 0.9700891573195284, 0.9530800230282096, 0.943108504398827, 0.9150568181818182, 0.801817648783348, 0.6622234826999432, 0.9488619568430388, 0.822215777262181, 0.5866935483870968, 0.5005858230814294, 0.9429250891795482, 0.8922588099364529, 0.6747093023255814, 0.6000572573718866]\n",
      "kmeans average accuracy best : 89.23%, kmeans average accuracy : 87.67089139%, total [0.9758110415480934, 0.9772856331629756, 0.9735404083980443, 0.9689119170984456, 0.9615835777126099, 0.9383522727272727, 0.832014072119613, 0.7342597844583097, 0.9639373337274608, 0.9222737819025522, 0.8076036866359447, 0.7340363210310487, 0.9340071343638525, 0.8648180242634316, 0.7566860465116279, 0.6822215860292012]\n",
      "cluster_accuracy_post_training_cycle_all_dataset : [0.97492904 0.97549482 0.97111218 0.96576663 0.96169154 0.94292453\n",
      " 0.87170562 0.71683913 0.95864851 0.91015625 0.79874517 0.6102284\n",
      " 0.92922607 0.86372454 0.7377451  0.67367415]\n",
      "mean_cluster_accuracy_during_training_cycle : 86.11%, post_traincycle_acc : 86.64%, total_acc : 86.42151269%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 89.03%\n",
      "accuracy_check 실행 시간: 24.005초\n",
      "\n",
      "\n",
      "epoch-27 loss : 0.01584882, loss_normal : 0.01606137, loss_coarse : 0.07508946, min_loss : 0.01583941, min_loss_normal : 0.01606137, min_loss_coarse : 0.07508946, wrong_element_sum : 14417176.00000000, same_data : 0.00%\n",
      "ae train 실행 시간: 114.598초, 전체 시작 시간 20250314_000157_781\n",
      "\n",
      "epoch-27 accuracy check\n",
      "k_means origin feature average accuracy : 82.25855782%, total [0.9746727376209448, 0.9733106189664963, 0.9700891573195284, 0.9530800230282096, 0.943108504398827, 0.915340909090909, 0.801817648783348, 0.6622234826999432, 0.9488619568430388, 0.822215777262181, 0.5866935483870968, 0.5005858230814294, 0.9429250891795482, 0.8922588099364529, 0.6741279069767442, 0.6000572573718866]\n",
      "kmeans average accuracy best : 89.23%, kmeans average accuracy : 87.38751635%, total [0.9758110415480934, 0.9772856331629756, 0.9735404083980443, 0.9686240644789867, 0.9665689149560117, 0.9525568181818181, 0.8880093814130754, 0.7651730005672149, 0.9639373337274608, 0.9269141531322506, 0.793778801843318, 0.7633274751025191, 0.8962544589774079, 0.816002310803004, 0.7223837209302325, 0.6318350987689665]\n",
      "cluster_accuracy_post_training_cycle_all_dataset : [0.97445601 0.97502356 0.96966779 0.96190935 0.96716418 0.95141509\n",
      " 0.89607161 0.80197554 0.96116994 0.92626953 0.78764479 0.6102284\n",
      " 0.89460285 0.82589719 0.73088235 0.63975155]\n",
      "mean_cluster_accuracy_during_training_cycle : 86.09%, post_traincycle_acc : 86.71%, total_acc : 86.45555793%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 89.03%\n",
      "accuracy_check 실행 시간: 24.130초\n",
      "\n",
      "\n",
      "epoch-28 loss : 0.01585700, loss_normal : 0.01604865, loss_coarse : 0.07505085, min_loss : 0.01583941, min_loss_normal : 0.01604865, min_loss_coarse : 0.07505085, wrong_element_sum : 14409764.00000000, same_data : 0.00%\n",
      "ae train 실행 시간: 112.360초, 전체 시작 시간 20250314_000157_781\n",
      "\n",
      "epoch-28 accuracy check\n",
      "k_means origin feature average accuracy : 82.24239140%, total [0.9746727376209448, 0.9733106189664963, 0.9700891573195284, 0.9530800230282096, 0.943108504398827, 0.9150568181818182, 0.8015244796247435, 0.6622234826999432, 0.9488619568430388, 0.822215777262181, 0.5872695852534562, 0.5005858230814294, 0.9429250891795482, 0.8922588099364529, 0.673546511627907, 0.5980532493558546]\n",
      "kmeans average accuracy best : 89.23%, kmeans average accuracy : 85.23528079%, total [0.9766647694934547, 0.9772856331629756, 0.9741156169111302, 0.9686240644789867, 0.966275659824047, 0.9602272727272727, 0.9029610085019056, 0.6551332955190017, 0.945019213715637, 0.8584686774941995, 0.631336405529954, 0.7026947861745753, 0.89179548156956, 0.82842287694974, 0.7430232558139535, 0.6555969081019182]\n",
      "cluster_accuracy_post_training_cycle_all_dataset : [0.97587512 0.97596607 0.97063072 0.96190935 0.96865672 0.95613208\n",
      " 0.91198409 0.73189087 0.92687847 0.74804688 0.54488417 0.59235353\n",
      " 0.89052953 0.83802134 0.74215686 0.63449594]\n",
      "mean_cluster_accuracy_during_training_cycle : 83.77%, post_traincycle_acc : 83.57%, total_acc : 83.64816311%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 89.03%\n",
      "accuracy_check 실행 시간: 23.402초\n",
      "\n",
      "\n",
      "epoch-29 loss : 0.01609427, loss_normal : 0.01615464, loss_coarse : 0.07556630, min_loss : 0.01583941, min_loss_normal : 0.01604865, min_loss_coarse : 0.07505085, wrong_element_sum : 14508730.00000000, same_data : 0.00%\n",
      "ae train 실행 시간: 116.783초, 전체 시작 시간 20250314_000157_781\n",
      "\n",
      "epoch-29 accuracy check\n",
      "k_means origin feature average accuracy : 82.26036413%, total [0.9746727376209448, 0.9733106189664963, 0.9700891573195284, 0.9530800230282096, 0.943108504398827, 0.915340909090909, 0.8015244796247435, 0.6625070901871809, 0.9488619568430388, 0.822215777262181, 0.5872695852534562, 0.5005858230814294, 0.9429250891795482, 0.8922588099364529, 0.6747093023255814, 0.5991983967935872]\n",
      "kmeans average accuracy best : 89.23%, kmeans average accuracy : 86.60556092%, total [0.9763801935116676, 0.9775695627484384, 0.9729651998849583, 0.9691997697179044, 0.9633431085043989, 0.9522727272727273, 0.8642626795661097, 0.6786727169597278, 0.9530002955956252, 0.9118329466357309, 0.8001152073732719, 0.7314001171646163, 0.9054696789536266, 0.8255343731946851, 0.725, 0.6498711709132551]\n",
      "cluster_accuracy_post_training_cycle_all_dataset : [0.97492904 0.97643732 0.97255657 0.96335583 0.96169154 0.95283019\n",
      " 0.90551964 0.73612418 0.95057993 0.91113281 0.69015444 0.5551142\n",
      " 0.89867617 0.82832202 0.71421569 0.63067367]\n",
      "mean_cluster_accuracy_during_training_cycle : 85.25%, post_traincycle_acc : 85.14%, total_acc : 85.17878966%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 89.03%\n",
      "accuracy_check 실행 시간: 23.708초\n",
      "\n",
      "\n",
      "epoch-30 loss : 0.01582687, loss_normal : 0.01605390, loss_coarse : 0.07499509, min_loss : 0.01582687, min_loss_normal : 0.01604865, min_loss_coarse : 0.07499509, wrong_element_sum : 14399058.00000000, same_data : 0.00%\n",
      "ae train 실행 시간: 113.729초, 전체 시작 시간 20250314_000157_781\n",
      "\n",
      "epoch-30 accuracy check\n",
      "k_means origin feature average accuracy : 82.25682064%, total [0.9746727376209448, 0.9733106189664963, 0.9700891573195284, 0.9530800230282096, 0.943108504398827, 0.9150568181818182, 0.801817648783348, 0.6625070901871809, 0.9488619568430388, 0.822215777262181, 0.5866935483870968, 0.5005858230814294, 0.9429250891795482, 0.8922588099364529, 0.6747093023255814, 0.5991983967935872]\n",
      "kmeans average accuracy best : 89.23%, kmeans average accuracy : 86.79330003%, total [0.9769493454752419, 0.9772856331629756, 0.9741156169111302, 0.9691997697179044, 0.9651026392961877, 0.9463068181818182, 0.8589856347112284, 0.7220646625070902, 0.9550694649719185, 0.898491879350348, 0.7808179723502304, 0.7018160515524312, 0.9134958382877527, 0.8445984979780474, 0.7430232558139535, 0.6596049241339822]\n",
      "cluster_accuracy_post_training_cycle_all_dataset : [0.97492904 0.97502356 0.97303804 0.96287367 0.96517413 0.95188679\n",
      " 0.90253605 0.71542803 0.95612708 0.89355469 0.80694981 0.54568024\n",
      " 0.91344196 0.84626576 0.72941176 0.65121835]\n",
      "mean_cluster_accuracy_during_training_cycle : 85.74%, post_traincycle_acc : 86.02%, total_acc : 85.90589922%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 89.03%\n",
      "accuracy_check 실행 시간: 23.965초\n",
      "\n",
      "\n",
      "epoch-31 loss : 0.01604864, loss_normal : 0.01615308, loss_coarse : 0.07556231, min_loss : 0.01582687, min_loss_normal : 0.01604865, min_loss_coarse : 0.07499509, wrong_element_sum : 14507964.00000000, same_data : 0.00%\n",
      "ae train 실행 시간: 104.775초, 전체 시작 시간 20250314_000157_781\n",
      "\n",
      "epoch-31 accuracy check\n",
      "k_means origin feature average accuracy : 82.26218852%, total [0.9746727376209448, 0.9733106189664963, 0.9700891573195284, 0.9530800230282096, 0.943108504398827, 0.9150568181818182, 0.801817648783348, 0.6625070901871809, 0.9488619568430388, 0.822215777262181, 0.5866935483870968, 0.5005858230814294, 0.9429250891795482, 0.8922588099364529, 0.6747093023255814, 0.6000572573718866]\n",
      "kmeans average accuracy best : 89.23%, kmeans average accuracy : 88.05647472%, total [0.9760956175298805, 0.9775695627484384, 0.9746908254242163, 0.966321243523316, 0.9642228739002933, 0.9514204545454545, 0.8751099384344767, 0.759217243335224, 0.967188885604493, 0.927784222737819, 0.836405529953917, 0.7478031634446397, 0.9143876337693222, 0.8428653957250144, 0.7543604651162791, 0.6535929000858861]\n",
      "cluster_accuracy_post_training_cycle_all_dataset : [0.97492904 0.97549482 0.97063072 0.96046287 0.96517413 0.9509434\n",
      " 0.89308802 0.76999059 0.95864851 0.92724609 0.81177606 0.52482622\n",
      " 0.90631365 0.84917556 0.74166667 0.65360726]\n",
      "mean_cluster_accuracy_during_training_cycle : 86.53%, post_traincycle_acc : 86.46%, total_acc : 86.48994237%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 89.03%\n",
      "accuracy_check 실행 시간: 24.084초\n",
      "\n",
      "\n",
      "epoch-32 loss : 0.01576550, loss_normal : 0.01605493, loss_coarse : 0.07497690, min_loss : 0.01576550, min_loss_normal : 0.01604865, min_loss_coarse : 0.07497690, wrong_element_sum : 14395566.00000000, same_data : 0.00%\n",
      "ae train 실행 시간: 113.412초, 전체 시작 시간 20250314_000157_781\n",
      "\n",
      "epoch-32 accuracy check\n",
      "k_means origin feature average accuracy : 82.26569522%, total [0.9746727376209448, 0.9733106189664963, 0.9700891573195284, 0.9530800230282096, 0.943108504398827, 0.9150568181818182, 0.801817648783348, 0.6622234826999432, 0.9488619568430388, 0.822215777262181, 0.5872695852534562, 0.5005858230814294, 0.9429250891795482, 0.8922588099364529, 0.673546511627907, 0.6014886916690524]\n",
      "kmeans average accuracy best : 89.23%, kmeans average accuracy : 87.17902220%, total [0.9766647694934547, 0.9778534923339012, 0.9746908254242163, 0.9677605066206102, 0.9639296187683285, 0.9411931818181818, 0.8440340076223981, 0.7257515598411798, 0.966006503103754, 0.9225638051044084, 0.8148041474654378, 0.7229056824838899, 0.9152794292508918, 0.8419988445984979, 0.7447674418604651, 0.6484397366160893]\n",
      "cluster_accuracy_post_training_cycle_all_dataset : [0.97445601 0.97455231 0.97111218 0.96094503 0.9641791  0.94669811\n",
      " 0.87568374 0.73518344 0.9591528  0.91113281 0.82818533 0.56057597\n",
      " 0.90478615 0.84869059 0.73872549 0.64596273]\n",
      "mean_cluster_accuracy_during_training_cycle : 85.41%, post_traincycle_acc : 86.25%, total_acc : 85.90837279%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 89.03%\n",
      "accuracy_check 실행 시간: 24.275초\n",
      "\n",
      "\n",
      "epoch-33 loss : 0.01591254, loss_normal : 0.01608755, loss_coarse : 0.07519268, min_loss : 0.01576550, min_loss_normal : 0.01604865, min_loss_coarse : 0.07497690, wrong_element_sum : 14436994.00000000, same_data : 0.00%\n",
      "ae train 실행 시간: 113.383초, 전체 시작 시간 20250314_000157_781\n",
      "\n",
      "epoch-33 accuracy check\n",
      "k_means origin feature average accuracy : 82.61111737%, total [0.9746727376209448, 0.9733106189664963, 0.9700891573195284, 0.9530800230282096, 0.943108504398827, 0.9150568181818182, 0.801817648783348, 0.6622234826999432, 0.9488619568430388, 0.822215777262181, 0.5866935483870968, 0.5005858230814294, 0.9429250891795482, 0.8922588099364529, 0.6747093023255814, 0.6561694818207844]\n",
      "kmeans average accuracy best : 89.23%, kmeans average accuracy : 87.53426911%, total [0.9766647694934547, 0.9772856331629756, 0.9746908254242163, 0.9694876223373633, 0.9642228739002933, 0.9488636363636364, 0.8613309879800645, 0.7376630743051616, 0.9692580549807863, 0.9222737819025522, 0.8038594470046083, 0.7372583479789103, 0.8971462544589774, 0.8454650491045639, 0.7566860465116279, 0.6633266533066132]\n",
      "cluster_accuracy_post_training_cycle_all_dataset : [0.97540208 0.97502356 0.97159364 0.95949855 0.96467662 0.95\n",
      " 0.90253605 0.74129821 0.95461422 0.91552734 0.81225869 0.54865938\n",
      " 0.89562118 0.85402522 0.75833333 0.64166269]\n",
      "mean_cluster_accuracy_during_training_cycle : 85.76%, post_traincycle_acc : 86.38%, total_acc : 86.12620526%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 89.03%\n",
      "accuracy_check 실행 시간: 23.828초\n",
      "\n",
      "\n",
      "epoch-34 loss : 0.01588076, loss_normal : 0.01606248, loss_coarse : 0.07513703, min_loss : 0.01576550, min_loss_normal : 0.01604865, min_loss_coarse : 0.07497690, wrong_element_sum : 14426310.00000000, same_data : 0.00%\n",
      "ae train 실행 시간: 116.988초, 전체 시작 시간 20250314_000157_781\n",
      "\n",
      "epoch-34 accuracy check\n",
      "k_means origin feature average accuracy : 82.25326962%, total [0.9746727376209448, 0.9733106189664963, 0.9700891573195284, 0.9530800230282096, 0.943108504398827, 0.9150568181818182, 0.801817648783348, 0.6625070901871809, 0.9488619568430388, 0.822215777262181, 0.5866935483870968, 0.5005858230814294, 0.9429250891795482, 0.8922588099364529, 0.675, 0.5983395362152877]\n",
      "kmeans average accuracy best : 89.23%, kmeans average accuracy : 87.02562528%, total [0.9766647694934547, 0.9772856331629756, 0.9746908254242163, 0.9689119170984456, 0.9659824046920821, 0.9451704545454546, 0.8390501319261213, 0.7260351673284174, 0.966006503103754, 0.9286542923433875, 0.8228686635944701, 0.7328646748681898, 0.9063614744351962, 0.8226458694396303, 0.727906976744186, 0.6430002862868595]\n",
      "cluster_accuracy_post_training_cycle_all_dataset : [0.97445601 0.97596607 0.97207511 0.96046287 0.96766169 0.9495283\n",
      " 0.89209349 0.71636877 0.95663137 0.62011719 0.68339768 0.60526316\n",
      " 0.89714868 0.82929195 0.7254902  0.6215958 ]\n",
      "mean_cluster_accuracy_during_training_cycle : 84.07%, post_traincycle_acc : 83.42%, total_acc : 83.68103570%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 89.03%\n",
      "accuracy_check 실행 시간: 23.975초\n",
      "\n",
      "\n",
      "epoch-35 loss : 0.01580723, loss_normal : 0.01605018, loss_coarse : 0.07505548, min_loss : 0.01576550, min_loss_normal : 0.01604865, min_loss_coarse : 0.07497690, wrong_element_sum : 14410652.00000000, same_data : 0.00%\n",
      "ae train 실행 시간: 112.116초, 전체 시작 시간 20250314_000157_781\n",
      "\n",
      "epoch-35 accuracy check\n",
      "k_means origin feature average accuracy : 82.26578875%, total [0.9746727376209448, 0.9733106189664963, 0.9700891573195284, 0.9530800230282096, 0.943108504398827, 0.9150568181818182, 0.801817648783348, 0.6625070901871809, 0.9488619568430388, 0.822215777262181, 0.5872695852534562, 0.5005858230814294, 0.9429250891795482, 0.8922588099364529, 0.6747093023255814, 0.6000572573718866]\n",
      "kmeans average accuracy best : 89.23%, kmeans average accuracy : 87.99834602%, total [0.9769493454752419, 0.9772856331629756, 0.9746908254242163, 0.970063327576281, 0.9651026392961877, 0.9497159090909091, 0.8742304309586632, 0.735677821894498, 0.9692580549807863, 0.9205336426914154, 0.8153801843317973, 0.7381370826010545, 0.9036860879904876, 0.8648180242634316, 0.7662790697674419, 0.677927283137704]\n",
      "cluster_accuracy_post_training_cycle_all_dataset : [0.97492904 0.97549482 0.97111218 0.96190935 0.96517413 0.95188679\n",
      " 0.90104426 0.7074318  0.96066566 0.92333984 0.80405405 0.54419067\n",
      " 0.89154786 0.87099903 0.76323529 0.63640707]\n",
      "mean_cluster_accuracy_during_training_cycle : 85.98%, post_traincycle_acc : 86.27%, total_acc : 86.15056456%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 89.03%\n",
      "accuracy_check 실행 시간: 23.351초\n",
      "\n",
      "\n",
      "epoch-36 loss : 0.01580007, loss_normal : 0.01609232, loss_coarse : 0.07519145, min_loss : 0.01576550, min_loss_normal : 0.01604865, min_loss_coarse : 0.07497690, wrong_element_sum : 14436758.00000000, same_data : 0.00%\n",
      "ae train 실행 시간: 116.461초, 전체 시작 시간 20250314_000157_781\n",
      "\n",
      "epoch-36 accuracy check\n",
      "k_means origin feature average accuracy : 82.25131622%, total [0.9746727376209448, 0.9733106189664963, 0.9700891573195284, 0.9530800230282096, 0.943108504398827, 0.9150568181818182, 0.8015244796247435, 0.6622234826999432, 0.9488619568430388, 0.822215777262181, 0.5866935483870968, 0.5005858230814294, 0.9429250891795482, 0.8922588099364529, 0.673546511627907, 0.6000572573718866]\n",
      "kmeans average accuracy best : 89.23%, kmeans average accuracy : 86.99521267%, total [0.9769493454752419, 0.9775695627484384, 0.9738280126545873, 0.9689119170984456, 0.9651026392961877, 0.9471590909090909, 0.8774552917033128, 0.7231990924560409, 0.9476795743422998, 0.9060324825986079, 0.807315668202765, 0.7410661980082015, 0.9001189060642093, 0.8212016175621029, 0.7369186046511628, 0.6487260234755224]\n",
      "cluster_accuracy_post_training_cycle_all_dataset : [0.97587512 0.97643732 0.97014925 0.96142719 0.96666667 0.9504717\n",
      " 0.8975634  0.75211665 0.96167423 0.90039062 0.80839768 0.5734856\n",
      " 0.89663951 0.83123181 0.73431373 0.64070712]\n",
      "mean_cluster_accuracy_during_training_cycle : 86.04%, post_traincycle_acc : 86.23%, total_acc : 86.15293437%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 89.03%\n",
      "accuracy_check 실행 시간: 23.685초\n",
      "\n",
      "\n",
      "epoch-37 loss : 0.01582498, loss_normal : 0.01609209, loss_coarse : 0.07520891, min_loss : 0.01576550, min_loss_normal : 0.01604865, min_loss_coarse : 0.07497690, wrong_element_sum : 14440112.00000000, same_data : 0.00%\n",
      "ae train 실행 시간: 118.060초, 전체 시작 시간 20250314_000157_781\n",
      "\n",
      "epoch-37 accuracy check\n",
      "k_means origin feature average accuracy : 82.26042087%, total [0.9746727376209448, 0.9733106189664963, 0.9700891573195284, 0.9530800230282096, 0.943108504398827, 0.9150568181818182, 0.801817648783348, 0.6625070901871809, 0.9488619568430388, 0.822215777262181, 0.5872695852534562, 0.5005858230814294, 0.9429250891795482, 0.8922588099364529, 0.6747093023255814, 0.5991983967935872]\n",
      "kmeans average accuracy best : 89.23%, kmeans average accuracy : 87.22945511%, total [0.9763801935116676, 0.9775695627484384, 0.9735404083980443, 0.9671848013816926, 0.9656891495601173, 0.9502840909090909, 0.8865435356200527, 0.7033465683494045, 0.9615725687259828, 0.9135730858468677, 0.8055875576036866, 0.7384299941417691, 0.8793103448275862, 0.8341998844598498, 0.7601744186046512, 0.6633266533066132]\n",
      "cluster_accuracy_post_training_cycle_all_dataset : [0.97540208 0.97549482 0.97159364 0.96239151 0.96517413 0.95188679\n",
      " 0.89706614 0.76857949 0.94351992 0.89746094 0.73069498 0.56802383\n",
      " 0.87780041 0.84238603 0.75588235 0.65742953]\n",
      "mean_cluster_accuracy_during_training_cycle : 85.22%, post_traincycle_acc : 85.88%, total_acc : 85.61145939%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 89.03%\n",
      "accuracy_check 실행 시간: 23.150초\n",
      "\n",
      "\n",
      "epoch-38 loss : 0.01587031, loss_normal : 0.01609548, loss_coarse : 0.07523327, min_loss : 0.01576550, min_loss_normal : 0.01604865, min_loss_coarse : 0.07497690, wrong_element_sum : 14444788.00000000, same_data : 0.00%\n",
      "ae train 실행 시간: 114.328초, 전체 시작 시간 20250314_000157_781\n",
      "\n",
      "epoch-38 accuracy check\n",
      "k_means origin feature average accuracy : 82.26223283%, total [0.9746727376209448, 0.9733106189664963, 0.9700891573195284, 0.9530800230282096, 0.943108504398827, 0.9150568181818182, 0.801817648783348, 0.6622234826999432, 0.9488619568430388, 0.822215777262181, 0.5866935483870968, 0.5005858230814294, 0.9429250891795482, 0.8922588099364529, 0.675, 0.6000572573718866]\n",
      "kmeans average accuracy best : 89.23%, kmeans average accuracy : 87.79684213%, total [0.9769493454752419, 0.9775695627484384, 0.9746908254242163, 0.968048359240069, 0.9659824046920821, 0.9525568181818181, 0.8780416300205218, 0.7390811117413499, 0.9716228199822643, 0.9321345707656613, 0.8254608294930875, 0.7437024018746339, 0.8909036860879905, 0.8321779318313114, 0.7561046511627907, 0.6624677927283138]\n",
      "cluster_accuracy_post_training_cycle_all_dataset : [0.97587512 0.97549482 0.97207511 0.96287367 0.96915423 0.95518868\n",
      " 0.88960716 0.71119473 0.96066566 0.92578125 0.73600386 0.52184707\n",
      " 0.88849287 0.83511154 0.75392157 0.65599618]\n",
      "mean_cluster_accuracy_during_training_cycle : 85.55%, post_traincycle_acc : 85.56%, total_acc : 85.55032479%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 89.03%\n",
      "accuracy_check 실행 시간: 23.159초\n",
      "\n",
      "\n",
      "epoch-39 loss : 0.01584206, loss_normal : 0.01607561, loss_coarse : 0.07517390, min_loss : 0.01576550, min_loss_normal : 0.01604865, min_loss_coarse : 0.07497690, wrong_element_sum : 14433390.00000000, same_data : 0.00%\n",
      "ae train 실행 시간: 118.783초, 전체 시작 시간 20250314_000157_781\n",
      "\n",
      "epoch-39 accuracy check\n",
      "k_means origin feature average accuracy : 82.24242489%, total [0.9746727376209448, 0.9733106189664963, 0.9700891573195284, 0.9530800230282096, 0.943108504398827, 0.9150568181818182, 0.8015244796247435, 0.6622234826999432, 0.9488619568430388, 0.822215777262181, 0.5866935483870968, 0.5005858230814294, 0.9429250891795482, 0.8922588099364529, 0.6741279069767442, 0.5980532493558546]\n",
      "kmeans average accuracy best : 89.23%, kmeans average accuracy : 87.35727643%, total [0.9766647694934547, 0.9772856331629756, 0.9741156169111302, 0.9683362118595279, 0.9656891495601173, 0.9426136363636364, 0.8545880973321607, 0.7288712422007941, 0.9633461424770914, 0.9138631090487239, 0.7957949308755761, 0.7369654364381957, 0.9164684898929846, 0.8399768919699596, 0.7563953488372093, 0.6661895219009447]\n",
      "cluster_accuracy_post_training_cycle_all_dataset : [0.97587512 0.97549482 0.97111218 0.96046287 0.96616915 0.9509434\n",
      " 0.88662357 0.7173095  0.95965709 0.90087891 0.78571429 0.5531281\n",
      " 0.91089613 0.85111542 0.74607843 0.65790731]\n",
      "mean_cluster_accuracy_during_training_cycle : 86.02%, post_traincycle_acc : 86.06%, total_acc : 86.04298287%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 89.03%\n",
      "accuracy_check 실행 시간: 23.515초\n",
      "\n",
      "\n",
      "epoch-40 loss : 0.01587280, loss_normal : 0.01609079, loss_coarse : 0.07527413, min_loss : 0.01576550, min_loss_normal : 0.01604865, min_loss_coarse : 0.07497690, wrong_element_sum : 14452634.00000000, same_data : 0.00%\n",
      "ae train 실행 시간: 116.313초, 전체 시작 시간 20250314_000157_781\n",
      "\n",
      "epoch-40 accuracy check\n",
      "k_means origin feature average accuracy : 82.25492108%, total [0.9746727376209448, 0.9733106189664963, 0.9700891573195284, 0.9530800230282096, 0.943108504398827, 0.9150568181818182, 0.801817648783348, 0.6625070901871809, 0.9488619568430388, 0.822215777262181, 0.5866935483870968, 0.5005858230814294, 0.9429250891795482, 0.8922588099364529, 0.673546511627907, 0.6000572573718866]\n",
      "kmeans average accuracy best : 89.23%, kmeans average accuracy : 86.25568230%, total [0.9766647694934547, 0.9772856331629756, 0.9744032211676733, 0.9671848013816926, 0.9651026392961877, 0.9480113636363636, 0.8466725300498388, 0.6871809415768576, 0.9651197162281998, 0.9196635730858469, 0.8006912442396313, 0.7123608670181605, 0.8715814506539834, 0.8142692085499711, 0.7337209302325581, 0.6409962782708274]\n",
      "cluster_accuracy_post_training_cycle_all_dataset : [0.97398297 0.97502356 0.97111218 0.96190935 0.96567164 0.94764151\n",
      " 0.88513178 0.69332079 0.94957136 0.90332031 0.75434363 0.51936445\n",
      " 0.86507128 0.82201746 0.73284314 0.64548495]\n",
      "mean_cluster_accuracy_during_training_cycle : 83.89%, post_traincycle_acc : 84.79%, total_acc : 84.42166603%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 89.03%\n",
      "accuracy_check 실행 시간: 23.989초\n",
      "\n",
      "\n",
      "epoch-41 loss : 0.01574277, loss_normal : 0.01607397, loss_coarse : 0.07514382, min_loss : 0.01574277, min_loss_normal : 0.01604865, min_loss_coarse : 0.07497690, wrong_element_sum : 14427614.00000000, same_data : 0.00%\n",
      "ae train 실행 시간: 113.215초, 전체 시작 시간 20250314_000157_781\n",
      "\n",
      "epoch-41 accuracy check\n",
      "k_means origin feature average accuracy : 82.23699797%, total [0.9746727376209448, 0.9733106189664963, 0.9700891573195284, 0.9530800230282096, 0.943108504398827, 0.9150568181818182, 0.801817648783348, 0.6622234826999432, 0.9488619568430388, 0.822215777262181, 0.5872695852534562, 0.5005858230814294, 0.9429250891795482, 0.89052570768342, 0.6738372093023256, 0.5983395362152877]\n",
      "kmeans average accuracy best : 89.23%, kmeans average accuracy : 86.28369804%, total [0.9760956175298805, 0.9775695627484384, 0.9738280126545873, 0.9651698330454808, 0.9621700879765396, 0.9286931818181818, 0.8220463207270595, 0.6690300623936472, 0.967188885604493, 0.9266241299303944, 0.8067396313364056, 0.7343292325717633, 0.8867419738406659, 0.8229347198151358, 0.7377906976744186, 0.6484397366160893]\n",
      "cluster_accuracy_post_training_cycle_all_dataset : [0.97492904 0.97502356 0.97014925 0.95998071 0.96467662 0.93301887\n",
      " 0.85877673 0.67779868 0.95814423 0.90673828 0.80598456 0.54468719\n",
      " 0.88187373 0.82929195 0.73529412 0.63592929]\n",
      "mean_cluster_accuracy_during_training_cycle : 85.16%, post_traincycle_acc : 85.08%, total_acc : 85.10944217%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 89.03%\n",
      "accuracy_check 실행 시간: 23.726초\n",
      "\n",
      "\n",
      "epoch-42 loss : 0.01580443, loss_normal : 0.01609842, loss_coarse : 0.07533088, min_loss : 0.01574277, min_loss_normal : 0.01604865, min_loss_coarse : 0.07497690, wrong_element_sum : 14463530.00000000, same_data : 0.00%\n",
      "ae train 실행 시간: 117.041초, 전체 시작 시간 20250314_000157_781\n",
      "\n",
      "epoch-42 accuracy check\n",
      "k_means origin feature average accuracy : 82.51339778%, total [0.9746727376209448, 0.9733106189664963, 0.9700891573195284, 0.9530800230282096, 0.943108504398827, 0.9150568181818182, 0.8015244796247435, 0.6622234826999432, 0.9488619568430388, 0.822215777262181, 0.5872695852534562, 0.4935559461042765, 0.9429250891795482, 0.8922588099364529, 0.6738372093023256, 0.6481534497566561]\n",
      "kmeans average accuracy best : 89.23%, kmeans average accuracy : 86.31301214%, total [0.9760956175298805, 0.9770017035775128, 0.9744032211676733, 0.9666090961427749, 0.9659824046920821, 0.944034090909091, 0.85194957490472, 0.7019285309132162, 0.9391073012119421, 0.882830626450116, 0.7805299539170507, 0.7199765670767428, 0.896551724137931, 0.82842287694974, 0.7447674418604651, 0.6598912109934154]\n",
      "cluster_accuracy_post_training_cycle_all_dataset : [0.97540208 0.97549482 0.97159364 0.96383799 0.96766169 0.94764151\n",
      " 0.87717553 0.7116651  0.95259708 0.88769531 0.70801158 0.57398213\n",
      " 0.94450102 0.842871   0.73480392 0.64787387]\n",
      "mean_cluster_accuracy_during_training_cycle : 85.39%, post_traincycle_acc : 85.52%, total_acc : 85.46071245%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 89.03%\n",
      "accuracy_check 실행 시간: 23.761초\n",
      "\n",
      "\n",
      "epoch-43 loss : 0.01581385, loss_normal : 0.01609213, loss_coarse : 0.07527443, min_loss : 0.01574277, min_loss_normal : 0.01604865, min_loss_coarse : 0.07497690, wrong_element_sum : 14452690.00000000, same_data : 0.00%\n",
      "ae train 실행 시간: 112.279초, 전체 시작 시간 20250314_000157_781\n",
      "\n",
      "epoch-43 accuracy check\n",
      "k_means origin feature average accuracy : 82.25504809%, total [0.9746727376209448, 0.9733106189664963, 0.9700891573195284, 0.9530800230282096, 0.943108504398827, 0.9150568181818182, 0.801817648783348, 0.6622234826999432, 0.9488619568430388, 0.822215777262181, 0.5866935483870968, 0.5005858230814294, 0.9429250891795482, 0.8922588099364529, 0.6747093023255814, 0.5991983967935872]\n",
      "kmeans average accuracy best : 89.23%, kmeans average accuracy : 87.77653769%, total [0.9763801935116676, 0.9770017035775128, 0.9735404083980443, 0.9677605066206102, 0.9671554252199414, 0.9534090909090909, 0.883318674875403, 0.7674418604651163, 0.9689624593556015, 0.9248839907192575, 0.8084677419354839, 0.7234915055653193, 0.8956599286563615, 0.8367995378393992, 0.7540697674418605, 0.6659032350415116]\n",
      "cluster_accuracy_post_training_cycle_all_dataset : [0.97492904 0.97408106 0.97014925 0.96142719 0.96766169 0.95660377\n",
      " 0.89955246 0.73518344 0.96167423 0.92382812 0.82432432 0.53972195\n",
      " 0.89460285 0.8399612  0.74754902 0.64500717]\n",
      "mean_cluster_accuracy_during_training_cycle : 86.49%, post_traincycle_acc : 86.35%, total_acc : 86.40489584%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 89.03%\n",
      "accuracy_check 실행 시간: 23.543초\n",
      "\n",
      "\n",
      "epoch-44 loss : 0.01583726, loss_normal : 0.01612928, loss_coarse : 0.07539883, min_loss : 0.01574277, min_loss_normal : 0.01604865, min_loss_coarse : 0.07497690, wrong_element_sum : 14476576.00000000, same_data : 0.00%\n",
      "ae train 실행 시간: 114.851초, 전체 시작 시간 20250314_000157_781\n",
      "\n",
      "epoch-44 accuracy check\n",
      "k_means origin feature average accuracy : 82.24958206%, total [0.9746727376209448, 0.9733106189664963, 0.9700891573195284, 0.9530800230282096, 0.943108504398827, 0.9150568181818182, 0.8015244796247435, 0.6622234826999432, 0.9488619568430388, 0.822215777262181, 0.5866935483870968, 0.5005858230814294, 0.9429250891795482, 0.8922588099364529, 0.6741279069767442, 0.5991983967935872]\n",
      "kmeans average accuracy best : 89.23%, kmeans average accuracy : 86.95142241%, total [0.9758110415480934, 0.9775695627484384, 0.9741156169111302, 0.9651698330454808, 0.9656891495601173, 0.9463068181818182, 0.8636763412489006, 0.7098695405558707, 0.9624593556015371, 0.9112529002320185, 0.7868663594470046, 0.7331575864089045, 0.8825802615933412, 0.8324667822068169, 0.7613372093023256, 0.6638992270254795]\n",
      "cluster_accuracy_post_training_cycle_all_dataset : [0.97587512 0.97643732 0.97111218 0.95756991 0.96616915 0.9504717\n",
      " 0.89060169 0.69332079 0.93494705 0.91503906 0.73359073 0.56653426\n",
      " 0.8808554  0.85402522 0.75980392 0.66220736]\n",
      "mean_cluster_accuracy_during_training_cycle : 85.32%, post_traincycle_acc : 85.55%, total_acc : 85.45531070%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 89.03%\n",
      "accuracy_check 실행 시간: 23.658초\n",
      "\n",
      "\n",
      "epoch-45 loss : 0.01586365, loss_normal : 0.01613464, loss_coarse : 0.07550612, min_loss : 0.01574277, min_loss_normal : 0.01604865, min_loss_coarse : 0.07497690, wrong_element_sum : 14497176.00000000, same_data : 0.00%\n",
      "ae train 실행 시간: 92.442초, 전체 시작 시간 20250314_000157_781\n",
      "\n",
      "epoch-45 accuracy check\n",
      "k_means origin feature average accuracy : 82.25492108%, total [0.9746727376209448, 0.9733106189664963, 0.9700891573195284, 0.9530800230282096, 0.943108504398827, 0.9150568181818182, 0.801817648783348, 0.6625070901871809, 0.9488619568430388, 0.822215777262181, 0.5866935483870968, 0.5005858230814294, 0.9429250891795482, 0.8922588099364529, 0.673546511627907, 0.6000572573718866]\n",
      "kmeans average accuracy best : 89.23%, kmeans average accuracy : 86.54661442%, total [0.9766647694934547, 0.9775695627484384, 0.9735404083980443, 0.9648819804260219, 0.9668621700879766, 0.9369318181818181, 0.8343594253884491, 0.6710153148043109, 0.9710316287318947, 0.9289443155452436, 0.7969470046082949, 0.7255418863503222, 0.9069560047562426, 0.8367995378393992, 0.7412790697674418, 0.6381334096764959]\n",
      "cluster_accuracy_post_training_cycle_all_dataset : [0.97587512 0.97643732 0.97111218 0.96142719 0.96766169 0.94764151\n",
      " 0.8662357  0.69990593 0.96469995 0.92285156 0.80501931 0.59731877\n",
      " 0.90733198 0.84529583 0.74166667 0.64166269]\n",
      "mean_cluster_accuracy_during_training_cycle : 85.29%, post_traincycle_acc : 86.20%, total_acc : 85.83076472%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 89.03%\n",
      "accuracy_check 실행 시간: 23.939초\n",
      "\n",
      "\n",
      "epoch-46 loss : 0.01587820, loss_normal : 0.01615146, loss_coarse : 0.07552697, min_loss : 0.01574277, min_loss_normal : 0.01604865, min_loss_coarse : 0.07497690, wrong_element_sum : 14501178.00000000, same_data : 0.00%\n",
      "ae train 실행 시간: 97.590초, 전체 시작 시간 20250314_000157_781\n",
      "\n",
      "epoch-46 accuracy check\n",
      "k_means origin feature average accuracy : 82.24597461%, total [0.9746727376209448, 0.9733106189664963, 0.9700891573195284, 0.9530800230282096, 0.943108504398827, 0.9150568181818182, 0.801817648783348, 0.6625070901871809, 0.9488619568430388, 0.822215777262181, 0.5866935483870968, 0.5005858230814294, 0.9429250891795482, 0.8922588099364529, 0.673546511627907, 0.5986258230747209]\n",
      "kmeans average accuracy best : 89.23%, kmeans average accuracy : 86.84144619%, total [0.970973249857712, 0.9747302668938104, 0.9706643658326143, 0.9617156016119747, 0.9651026392961877, 0.9363636363636364, 0.8496042216358839, 0.7180941576857629, 0.9728052024830033, 0.939385150812065, 0.8303571428571429, 0.7480960749853545, 0.8816884661117717, 0.8058925476603119, 0.7258720930232558, 0.6432865731462926]\n",
      "cluster_accuracy_post_training_cycle_all_dataset : [0.96972564 0.97219604 0.96870486 0.94599807 0.96517413 0.94245283\n",
      " 0.87021382 0.72107244 0.94402421 0.93017578 0.82094595 0.60724926\n",
      " 0.87729124 0.82007759 0.72941176 0.64261825]\n",
      "mean_cluster_accuracy_during_training_cycle : 85.77%, post_traincycle_acc : 85.80%, total_acc : 85.78256437%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 89.03%\n",
      "accuracy_check 실행 시간: 23.420초\n",
      "\n",
      "\n",
      "epoch-47 loss : 0.01574351, loss_normal : 0.01612332, loss_coarse : 0.07538497, min_loss : 0.01574277, min_loss_normal : 0.01604865, min_loss_coarse : 0.07497690, wrong_element_sum : 14473914.00000000, same_data : 0.00%\n",
      "ae train 실행 시간: 117.660초, 전체 시작 시간 20250314_000157_781\n",
      "\n",
      "epoch-47 accuracy check\n",
      "k_means origin feature average accuracy : 82.25137006%, total [0.9746727376209448, 0.9733106189664963, 0.9700891573195284, 0.9530800230282096, 0.943108504398827, 0.9150568181818182, 0.801817648783348, 0.6625070901871809, 0.9488619568430388, 0.822215777262181, 0.5866935483870968, 0.5005858230814294, 0.9429250891795482, 0.8922588099364529, 0.6738372093023256, 0.5991983967935872]\n",
      "kmeans average accuracy best : 89.23%, kmeans average accuracy : 87.03176432%, total [0.9760956175298805, 0.9775695627484384, 0.9735404083980443, 0.9645941278065631, 0.9651026392961877, 0.9428977272727272, 0.8399296394019349, 0.6996596710153148, 0.9645285249778304, 0.9266241299303944, 0.8266129032258065, 0.7583479789103691, 0.8903091557669441, 0.8310225303292894, 0.7386627906976744, 0.649584884053822]\n",
      "cluster_accuracy_post_training_cycle_all_dataset : [0.97682119 0.97596607 0.97063072 0.95853423 0.96517413 0.94764151\n",
      " 0.86971656 0.71354657 0.95612708 0.91943359 0.79874517 0.56355511\n",
      " 0.89052953 0.8385063  0.74656863 0.6440516 ]\n",
      "mean_cluster_accuracy_during_training_cycle : 85.75%, post_traincycle_acc : 85.85%, total_acc : 85.80360382%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 89.03%\n",
      "accuracy_check 실행 시간: 23.259초\n",
      "\n",
      "\n",
      "epoch-48 loss : 0.01588152, loss_normal : 0.01615220, loss_coarse : 0.07554720, min_loss : 0.01574277, min_loss_normal : 0.01604865, min_loss_coarse : 0.07497690, wrong_element_sum : 14505062.00000000, same_data : 0.00%\n",
      "ae train 실행 시간: 113.854초, 전체 시작 시간 20250314_000157_781\n",
      "\n",
      "epoch-48 accuracy check\n",
      "k_means origin feature average accuracy : 82.24421289%, total [0.9746727376209448, 0.9733106189664963, 0.9700891573195284, 0.9530800230282096, 0.943108504398827, 0.9150568181818182, 0.801817648783348, 0.6625070901871809, 0.9488619568430388, 0.822215777262181, 0.5866935483870968, 0.5005858230814294, 0.9429250891795482, 0.8922588099364529, 0.6738372093023256, 0.5980532493558546]\n",
      "kmeans average accuracy best : 89.23%, kmeans average accuracy : 86.30497673%, total [0.9763801935116676, 0.9770017035775128, 0.9735404083980443, 0.9637305699481865, 0.964516129032258, 0.925, 0.8155965992377602, 0.7135564378899603, 0.967188885604493, 0.9327146171693735, 0.8237327188940092, 0.7255418863503222, 0.8935790725326992, 0.8070479491623339, 0.7244186046511628, 0.625250501002004]\n",
      "cluster_accuracy_post_training_cycle_all_dataset : [0.97540208 0.97643732 0.97111218 0.95612343 0.96716418 0.94103774\n",
      " 0.86822476 0.70790216 0.96116994 0.93261719 0.83059846 0.54021847\n",
      " 0.88696538 0.8128031  0.71862745 0.62924032]\n",
      "mean_cluster_accuracy_during_training_cycle : 85.06%, post_traincycle_acc : 85.47%, total_acc : 85.30390268%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 89.03%\n",
      "accuracy_check 실행 시간: 23.025초\n",
      "\n",
      "\n",
      "epoch-49 loss : 0.01586058, loss_normal : 0.01613827, loss_coarse : 0.07555293, min_loss : 0.01574277, min_loss_normal : 0.01604865, min_loss_coarse : 0.07497690, wrong_element_sum : 14506162.00000000, same_data : 0.00%\n",
      "ae train 실행 시간: 106.910초, 전체 시작 시간 20250314_000157_781\n",
      "\n",
      "epoch-49 accuracy check\n",
      "k_means origin feature average accuracy : 82.25497029%, total [0.9746727376209448, 0.9733106189664963, 0.9700891573195284, 0.9530800230282096, 0.943108504398827, 0.9150568181818182, 0.801817648783348, 0.6625070901871809, 0.9488619568430388, 0.822215777262181, 0.5872695852534562, 0.5005858230814294, 0.9429250891795482, 0.8922588099364529, 0.6738372093023256, 0.5991983967935872]\n",
      "kmeans average accuracy best : 89.23%, kmeans average accuracy : 87.78726305%, total [0.9760956175298805, 0.9772856331629756, 0.9735404083980443, 0.9637305699481865, 0.9656891495601173, 0.9448863636363637, 0.8669012019935503, 0.7512762336925695, 0.9606857818504286, 0.921983758700696, 0.824020737327189, 0.7551259519625073, 0.9123067776456599, 0.8437319468515309, 0.747093023255814, 0.6616089321500143]\n",
      "cluster_accuracy_post_training_cycle_all_dataset : [0.97540208 0.97596607 0.97255657 0.95949855 0.96616915 0.94764151\n",
      " 0.87170562 0.73847601 0.96016137 0.92724609 0.81032819 0.64250248\n",
      " 0.91293279 0.86032978 0.74068627 0.6469183 ]\n",
      "mean_cluster_accuracy_during_training_cycle : 86.69%, post_traincycle_acc : 86.93%, total_acc : 86.82609181%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 89.03%\n",
      "accuracy_check 실행 시간: 23.451초\n",
      "\n",
      "\n",
      "epoch-50 loss : 0.01588299, loss_normal : 0.01616068, loss_coarse : 0.07556685, min_loss : 0.01574277, min_loss_normal : 0.01604865, min_loss_coarse : 0.07497690, wrong_element_sum : 14508836.00000000, same_data : 0.00%\n",
      "ae train 실행 시간: 85.571초, 전체 시작 시간 20250314_000157_781\n",
      "\n",
      "epoch-50 accuracy check\n",
      "k_means origin feature average accuracy : 82.26045436%, total [0.9746727376209448, 0.9733106189664963, 0.9700891573195284, 0.9530800230282096, 0.943108504398827, 0.9150568181818182, 0.801817648783348, 0.6625070901871809, 0.9488619568430388, 0.822215777262181, 0.5866935483870968, 0.5005858230814294, 0.9429250891795482, 0.8922588099364529, 0.6752906976744186, 0.5991983967935872]\n",
      "kmeans average accuracy best : 89.23%, kmeans average accuracy : 87.59647324%, total [0.9758110415480934, 0.9772856331629756, 0.9729651998849583, 0.9625791594703512, 0.966275659824047, 0.9528409090909091, 0.8800938141307535, 0.7498581962563812, 0.9642329293526456, 0.9176334106728539, 0.8266129032258065, 0.7404803749267721, 0.8855529131985731, 0.8316002310803005, 0.7502906976744186, 0.6613226452905812]\n",
      "cluster_accuracy_post_training_cycle_all_dataset : [0.97540208 0.97502356 0.96870486 0.95805207 0.9681592  0.95330189\n",
      " 0.89308802 0.73753528 0.91427131 0.91650391 0.80212355 0.59682224\n",
      " 0.87983707 0.83608147 0.75       0.65217391]\n",
      "mean_cluster_accuracy_during_training_cycle : 86.30%, post_traincycle_acc : 86.11%, total_acc : 86.18342143%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 89.03%\n",
      "accuracy_check 실행 시간: 24.031초\n",
      "\n",
      "\n",
      "epoch-51 loss : 0.01573013, loss_normal : 0.01610037, loss_coarse : 0.07526526, min_loss : 0.01573013, min_loss_normal : 0.01604865, min_loss_coarse : 0.07497690, wrong_element_sum : 14450930.00000000, same_data : 0.00%\n",
      "ae train 실행 시간: 115.227초, 전체 시작 시간 20250314_000157_781\n",
      "\n",
      "epoch-51 accuracy check\n",
      "k_means origin feature average accuracy : 82.25671339%, total [0.9746727376209448, 0.9733106189664963, 0.9700891573195284, 0.9530800230282096, 0.943108504398827, 0.915340909090909, 0.801817648783348, 0.6622234826999432, 0.9488619568430388, 0.822215777262181, 0.5866935483870968, 0.5005858230814294, 0.9429250891795482, 0.8922588099364529, 0.673546511627907, 0.6003435442313197]\n",
      "kmeans average accuracy best : 89.23%, kmeans average accuracy : 87.29449819%, total [0.9763801935116676, 0.9772856331629756, 0.9741156169111302, 0.9625791594703512, 0.9653958944281525, 0.9491477272727272, 0.8715919085312225, 0.7271695972773681, 0.9571386343482117, 0.91792343387471, 0.8104838709677419, 0.7466315172817809, 0.9010107015457788, 0.8362218370883883, 0.7433139534883721, 0.6507300314915545]\n",
      "cluster_accuracy_post_training_cycle_all_dataset : [0.97587512 0.97596607 0.97207511 0.95949855 0.96616915 0.9490566\n",
      " 0.88562904 0.73189087 0.95612708 0.91162109 0.79343629 0.53177756\n",
      " 0.89613035 0.83511154 0.73676471 0.64882943]\n",
      "mean_cluster_accuracy_during_training_cycle : 85.49%, post_traincycle_acc : 85.79%, total_acc : 85.66307266%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 89.03%\n",
      "accuracy_check 실행 시간: 24.108초\n",
      "\n",
      "\n",
      "epoch-52 loss : 0.01577324, loss_normal : 0.01610981, loss_coarse : 0.07536612, min_loss : 0.01573013, min_loss_normal : 0.01604865, min_loss_coarse : 0.07497690, wrong_element_sum : 14470296.00000000, same_data : 0.00%\n",
      "ae train 실행 시간: 117.254초, 전체 시작 시간 20250314_000157_781\n",
      "\n",
      "epoch-52 accuracy check\n",
      "k_means origin feature average accuracy : 82.25313007%, total [0.9746727376209448, 0.9733106189664963, 0.9700891573195284, 0.9530800230282096, 0.943108504398827, 0.9150568181818182, 0.8015244796247435, 0.6625070901871809, 0.9488619568430388, 0.822215777262181, 0.5866935483870968, 0.5002929115407148, 0.9429250891795482, 0.8922588099364529, 0.6744186046511628, 0.5994846836530203]\n",
      "kmeans average accuracy best : 89.23%, kmeans average accuracy : 87.46848216%, total [0.9760956175298805, 0.9775695627484384, 0.9732528041415013, 0.9668969487622338, 0.9656891495601173, 0.944034090909091, 0.8777484608619174, 0.7521270561542824, 0.9609813774756134, 0.9185034802784223, 0.8179723502304147, 0.7463386057410663, 0.8724732461355529, 0.8365106874638937, 0.7511627906976744, 0.6576009161179502]\n",
      "cluster_accuracy_post_training_cycle_all_dataset : [0.97682119 0.97737983 0.96966779 0.96142719 0.96716418 0.95\n",
      " 0.88264545 0.74365005 0.95814423 0.91455078 0.82335907 0.50993049\n",
      " 0.86965377 0.84044617 0.75343137 0.65456283]\n",
      "mean_cluster_accuracy_during_training_cycle : 86.25%, post_traincycle_acc : 85.96%, total_acc : 86.07467940%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 89.03%\n",
      "accuracy_check 실행 시간: 24.173초\n",
      "\n",
      "\n",
      "epoch-53 loss : 0.01584514, loss_normal : 0.01615204, loss_coarse : 0.07553039, min_loss : 0.01573013, min_loss_normal : 0.01604865, min_loss_coarse : 0.07497690, wrong_element_sum : 14501836.00000000, same_data : 0.00%\n",
      "ae train 실행 시간: 114.527초, 전체 시작 시간 20250314_000157_781\n",
      "\n",
      "epoch-53 accuracy check\n",
      "k_means origin feature average accuracy : 82.25330801%, total [0.9746727376209448, 0.9733106189664963, 0.9700891573195284, 0.9530800230282096, 0.943108504398827, 0.9150568181818182, 0.801817648783348, 0.6622234826999432, 0.9488619568430388, 0.822215777262181, 0.5872695852534562, 0.5005858230814294, 0.9429250891795482, 0.8922588099364529, 0.675, 0.5980532493558546]\n",
      "kmeans average accuracy best : 89.23%, kmeans average accuracy : 85.50376491%, total [0.9763801935116676, 0.9772856331629756, 0.9741156169111302, 0.9683362118595279, 0.964516129032258, 0.9329545454545455, 0.7543242450894166, 0.6678956324446965, 0.9494531480934082, 0.8955916473317865, 0.777073732718894, 0.7117750439367311, 0.9244946492271106, 0.8336221837088388, 0.7383720930232558, 0.6344116805038649]\n",
      "cluster_accuracy_post_training_cycle_all_dataset : [0.97634816 0.97643732 0.97255657 0.96142719 0.96467662 0.94292453\n",
      " 0.87369468 0.64675447 0.89762985 0.88964844 0.64333977 0.55461768\n",
      " 0.91649695 0.8443259  0.70833333 0.63258481]\n",
      "mean_cluster_accuracy_during_training_cycle : 83.73%, post_traincycle_acc : 83.76%, total_acc : 83.74884085%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 89.03%\n",
      "accuracy_check 실행 시간: 24.054초\n",
      "\n",
      "\n",
      "epoch-54 loss : 0.01585120, loss_normal : 0.01613052, loss_coarse : 0.07553435, min_loss : 0.01573013, min_loss_normal : 0.01604865, min_loss_coarse : 0.07497690, wrong_element_sum : 14502596.00000000, same_data : 0.00%\n",
      "ae train 실행 시간: 108.766초, 전체 시작 시간 20250314_000157_781\n",
      "\n",
      "epoch-54 accuracy check\n",
      "k_means origin feature average accuracy : 82.25852131%, total [0.9746727376209448, 0.9733106189664963, 0.9700891573195284, 0.9530800230282096, 0.943108504398827, 0.9150568181818182, 0.801817648783348, 0.6625070901871809, 0.9488619568430388, 0.822215777262181, 0.5872695852534562, 0.5005858230814294, 0.9429250891795482, 0.8922588099364529, 0.673546511627907, 0.6000572573718866]\n",
      "kmeans average accuracy best : 89.23%, kmeans average accuracy : 88.32018032%, total [0.9758110415480934, 0.9772856331629756, 0.9735404083980443, 0.9657455382843984, 0.9648093841642229, 0.94375, 0.8683670477865728, 0.7186613726602382, 0.9654153118533846, 0.925754060324826, 0.8191244239631337, 0.7434094903339191, 0.9402497027348394, 0.8824378971692663, 0.7880813953488373, 0.6787861437160034]\n",
      "cluster_accuracy_post_training_cycle_all_dataset : [0.97587512 0.97596607 0.97255657 0.96190935 0.96766169 0.94575472\n",
      " 0.88314272 0.75070555 0.95108422 0.92089844 0.79150579 0.5774578\n",
      " 0.93991853 0.88554801 0.77843137 0.66602962]\n",
      "mean_cluster_accuracy_during_training_cycle : 86.72%, post_traincycle_acc : 87.15%, total_acc : 86.97462084%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 89.03%\n",
      "accuracy_check 실행 시간: 23.044초\n",
      "\n",
      "\n",
      "epoch-55 loss : 0.01587971, loss_normal : 0.01612655, loss_coarse : 0.07548200, min_loss : 0.01573013, min_loss_normal : 0.01604865, min_loss_coarse : 0.07497690, wrong_element_sum : 14492544.00000000, same_data : 0.00%\n",
      "ae train 실행 시간: 112.427초, 전체 시작 시간 20250314_000157_781\n",
      "\n",
      "epoch-55 accuracy check\n",
      "k_means origin feature average accuracy : 82.25137006%, total [0.9746727376209448, 0.9733106189664963, 0.9700891573195284, 0.9530800230282096, 0.943108504398827, 0.9150568181818182, 0.801817648783348, 0.6625070901871809, 0.9488619568430388, 0.822215777262181, 0.5866935483870968, 0.5005858230814294, 0.9429250891795482, 0.8922588099364529, 0.6738372093023256, 0.5991983967935872]\n",
      "kmeans average accuracy best : 89.23%, kmeans average accuracy : 87.83883886%, total [0.9758110415480934, 0.9772856331629756, 0.9729651998849583, 0.9643062751871042, 0.966275659824047, 0.940625, 0.8595719730284375, 0.7271695972773681, 0.9571386343482117, 0.9147331786542924, 0.804147465437788, 0.7375512595196251, 0.9152794292508918, 0.8653957250144425, 0.7834302325581395, 0.6925279129687947]\n",
      "cluster_accuracy_post_training_cycle_all_dataset : [0.97587512 0.97455231 0.97014925 0.96094503 0.96616915 0.94716981\n",
      " 0.89010443 0.72859831 0.94906707 0.90527344 0.76930502 0.64399206\n",
      " 0.9185336  0.88263822 0.77794118 0.65838509]\n",
      "mean_cluster_accuracy_during_training_cycle : 87.03%, post_traincycle_acc : 86.99%, total_acc : 87.00596293%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 89.03%\n",
      "accuracy_check 실행 시간: 24.880초\n",
      "\n",
      "\n",
      "epoch-56 loss : 0.01611299, loss_normal : 0.01621892, loss_coarse : 0.07589915, min_loss : 0.01573013, min_loss_normal : 0.01604865, min_loss_coarse : 0.07497690, wrong_element_sum : 14572638.00000000, same_data : 0.00%\n",
      "ae train 실행 시간: 117.619초, 전체 시작 시간 20250314_000157_781\n",
      "\n",
      "epoch-56 accuracy check\n",
      "k_means origin feature average accuracy : 82.25313798%, total [0.9746727376209448, 0.9733106189664963, 0.9700891573195284, 0.9530800230282096, 0.943108504398827, 0.9150568181818182, 0.8015244796247435, 0.6625070901871809, 0.9488619568430388, 0.822215777262181, 0.5872695852534562, 0.5005858230814294, 0.9429250891795482, 0.8922588099364529, 0.6738372093023256, 0.5991983967935872]\n",
      "kmeans average accuracy best : 89.23%, kmeans average accuracy : 88.17639640%, total [0.9755264655663062, 0.97671777399205, 0.9729651998849583, 0.9657455382843984, 0.9659824046920821, 0.9485795454545455, 0.8586924655526239, 0.7492909812819059, 0.9674844812296778, 0.9286542923433875, 0.8248847926267281, 0.7539543057996485, 0.9259809750297265, 0.8604852686308492, 0.7630813953488372, 0.6701975379330088]\n",
      "cluster_accuracy_post_training_cycle_all_dataset : [0.97445601 0.97549482 0.97063072 0.96142719 0.96666667 0.95188679\n",
      " 0.90303332 0.74600188 0.95562279 0.92285156 0.79295367 0.66137041\n",
      " 0.92413442 0.87245393 0.75539216 0.62828476]\n",
      "mean_cluster_accuracy_during_training_cycle : 87.10%, post_traincycle_acc : 87.27%, total_acc : 87.19628538%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 89.03%\n",
      "accuracy_check 실행 시간: 23.494초\n",
      "\n",
      "\n",
      "epoch-57 loss : 0.01573604, loss_normal : 0.01609416, loss_coarse : 0.07528658, min_loss : 0.01573013, min_loss_normal : 0.01604865, min_loss_coarse : 0.07497690, wrong_element_sum : 14455024.00000000, same_data : 0.00%\n",
      "ae train 실행 시간: 114.122초, 전체 시작 시간 20250314_000157_781\n",
      "\n",
      "epoch-57 accuracy check\n",
      "k_means origin feature average accuracy : 82.25132112%, total [0.9746727376209448, 0.9733106189664963, 0.9700891573195284, 0.9530800230282096, 0.943108504398827, 0.9150568181818182, 0.8015244796247435, 0.6625070901871809, 0.9488619568430388, 0.822215777262181, 0.5872695852534562, 0.5005858230814294, 0.9429250891795482, 0.8922588099364529, 0.673546511627907, 0.5991983967935872]\n",
      "kmeans average accuracy best : 89.23%, kmeans average accuracy : 87.18636127%, total [0.9732498577120091, 0.975298126064736, 0.9700891573195284, 0.9608520437535981, 0.9648093841642229, 0.9519886363636364, 0.8698328935795955, 0.7195121951219512, 0.9663020987289388, 0.9301044083526682, 0.8171082949308756, 0.7565905096660809, 0.9126040428061831, 0.8226458694396303, 0.7244186046511628, 0.6344116805038649]\n",
      "cluster_accuracy_post_training_cycle_all_dataset : [0.97114475 0.97408106 0.9682234  0.96046287 0.96716418 0.95188679\n",
      " 0.89806067 0.71260583 0.9404942  0.92773438 0.78909266 0.60675273\n",
      " 0.90325866 0.82783705 0.7254902  0.62111801]\n",
      "mean_cluster_accuracy_during_training_cycle : 86.09%, post_traincycle_acc : 85.91%, total_acc : 85.97768302%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 89.03%\n",
      "accuracy_check 실행 시간: 24.032초\n",
      "\n",
      "\n",
      "epoch-58 loss : 0.01574888, loss_normal : 0.01610799, loss_coarse : 0.07534213, min_loss : 0.01573013, min_loss_normal : 0.01604865, min_loss_coarse : 0.07497690, wrong_element_sum : 14465690.00000000, same_data : 0.00%\n",
      "ae train 실행 시간: 119.711초, 전체 시작 시간 20250314_000157_781\n",
      "\n",
      "epoch-58 accuracy check\n",
      "k_means origin feature average accuracy : 82.26934569%, total [0.9746727376209448, 0.9733106189664963, 0.9700891573195284, 0.9530800230282096, 0.943108504398827, 0.9150568181818182, 0.801817648783348, 0.6625070901871809, 0.9488619568430388, 0.822215777262181, 0.5866935483870968, 0.5005858230814294, 0.9429250891795482, 0.8922588099364529, 0.6747093023255814, 0.6012024048096193]\n",
      "kmeans average accuracy best : 89.23%, kmeans average accuracy : 87.68602041%, total [0.9760956175298805, 0.9772856331629756, 0.9735404083980443, 0.9654576856649395, 0.966275659824047, 0.9477272727272728, 0.8619173262972736, 0.7410663641520137, 0.9663020987289388, 0.9269141531322506, 0.8006912442396313, 0.7255418863503222, 0.9271700356718192, 0.8561525129982669, 0.7502906976744186, 0.6673346693386774]\n",
      "cluster_accuracy_post_training_cycle_all_dataset : [0.97682119 0.97690858 0.97159364 0.96239151 0.96766169 0.95141509\n",
      " 0.89010443 0.72483537 0.9591528  0.92431641 0.81853282 0.7388282\n",
      " 0.92413442 0.86469447 0.75343137 0.64835165]\n",
      "mean_cluster_accuracy_during_training_cycle : 87.38%, post_traincycle_acc : 87.83%, total_acc : 87.64710987%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 89.03%\n",
      "accuracy_check 실행 시간: 24.020초\n",
      "\n",
      "\n",
      "epoch-59 loss : 0.01572814, loss_normal : 0.01609742, loss_coarse : 0.07526737, min_loss : 0.01572814, min_loss_normal : 0.01604865, min_loss_coarse : 0.07497690, wrong_element_sum : 14451336.00000000, same_data : 0.00%\n",
      "ae train 실행 시간: 113.212초, 전체 시작 시간 20250314_000157_781\n",
      "\n",
      "epoch-59 accuracy check\n",
      "k_means origin feature average accuracy : 82.26223283%, total [0.9746727376209448, 0.9733106189664963, 0.9700891573195284, 0.9530800230282096, 0.943108504398827, 0.9150568181818182, 0.801817648783348, 0.6622234826999432, 0.9488619568430388, 0.822215777262181, 0.5866935483870968, 0.5005858230814294, 0.9429250891795482, 0.8922588099364529, 0.675, 0.6000572573718866]\n",
      "kmeans average accuracy best : 89.23%, kmeans average accuracy : 87.72309530%, total [0.9766647694934547, 0.9772856331629756, 0.9741156169111302, 0.966321243523316, 0.9665689149560117, 0.9511363636363637, 0.8715919085312225, 0.7189449801474759, 0.9639373337274608, 0.9185034802784223, 0.8081797235023042, 0.7328646748681898, 0.9247919143876338, 0.8575967648757944, 0.7581395348837209, 0.6690523904952763]\n",
      "cluster_accuracy_post_training_cycle_all_dataset : [0.97492904 0.97596607 0.97303804 0.95564127 0.96666667 0.95\n",
      " 0.90203879 0.69567262 0.95562279 0.91650391 0.82094595 0.58738828\n",
      " 0.92464358 0.86372454 0.73970588 0.62876254]\n",
      "mean_cluster_accuracy_during_training_cycle : 86.51%, post_traincycle_acc : 86.45%, total_acc : 86.46763001%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 89.03%\n",
      "accuracy_check 실행 시간: 23.556초\n",
      "\n",
      "\n",
      "epoch-60 loss : 0.01572310, loss_normal : 0.01608901, loss_coarse : 0.07522814, min_loss : 0.01572310, min_loss_normal : 0.01604865, min_loss_coarse : 0.07497690, wrong_element_sum : 14443804.00000000, same_data : 0.00%\n",
      "ae train 실행 시간: 108.590초, 전체 시작 시간 20250314_000157_781\n",
      "\n",
      "epoch-60 accuracy check\n",
      "k_means origin feature average accuracy : 82.25852131%, total [0.9746727376209448, 0.9733106189664963, 0.9700891573195284, 0.9530800230282096, 0.943108504398827, 0.9150568181818182, 0.801817648783348, 0.6625070901871809, 0.9488619568430388, 0.822215777262181, 0.5872695852534562, 0.5005858230814294, 0.9429250891795482, 0.8922588099364529, 0.673546511627907, 0.6000572573718866]\n",
      "kmeans average accuracy best : 89.23%, kmeans average accuracy : 86.56259856%, total [0.9746727376209448, 0.9764338444065872, 0.9726775956284153, 0.9614277489925158, 0.9665689149560117, 0.9494318181818182, 0.8888888888888888, 0.7076006806579693, 0.9606857818504286, 0.9170533642691415, 0.7249423963133641, 0.685120093731693, 0.8745541022592153, 0.8419988445984979, 0.7683139534883721, 0.6796450042943029]\n",
      "cluster_accuracy_post_training_cycle_all_dataset : [0.97350993 0.97502356 0.97063072 0.96046287 0.96766169 0.9490566\n",
      " 0.89308802 0.7144873  0.90065557 0.90966797 0.80888031 0.51241311\n",
      " 0.87678208 0.85741998 0.76862745 0.67128524]\n",
      "mean_cluster_accuracy_during_training_cycle : 85.95%, post_traincycle_acc : 85.69%, total_acc : 85.79269905%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 89.03%\n",
      "accuracy_check 실행 시간: 23.712초\n",
      "\n",
      "\n",
      "epoch-61 loss : 0.01570082, loss_normal : 0.01607049, loss_coarse : 0.07508638, min_loss : 0.01570082, min_loss_normal : 0.01604865, min_loss_coarse : 0.07497690, wrong_element_sum : 14416586.00000000, same_data : 0.00%\n",
      "ae train 실행 시간: 116.841초, 전체 시작 시간 20250314_000157_781\n",
      "\n",
      "epoch-61 accuracy check\n",
      "k_means origin feature average accuracy : 82.24419311%, total [0.9746727376209448, 0.9733106189664963, 0.9700891573195284, 0.9530800230282096, 0.943108504398827, 0.9150568181818182, 0.801817648783348, 0.6622234826999432, 0.9488619568430388, 0.822215777262181, 0.5866935483870968, 0.5005858230814294, 0.9429250891795482, 0.8911034084344309, 0.6741279069767442, 0.5991983967935872]\n",
      "kmeans average accuracy best : 89.23%, kmeans average accuracy : 86.94281764%, total [0.9760956175298805, 0.9772856331629756, 0.9732528041415013, 0.9674726540011515, 0.9651026392961877, 0.9389204545454546, 0.8311345646437994, 0.7087351106069201, 0.964824120603015, 0.9306844547563805, 0.8133640552995391, 0.7463386057410663, 0.9360879904875149, 0.839110340843443, 0.7386627906976744, 0.6037789865445176]\n",
      "cluster_accuracy_post_training_cycle_all_dataset : [0.97540208 0.97643732 0.97207511 0.96287367 0.9641791  0.94292453\n",
      " 0.88562904 0.68861712 0.95814423 0.92675781 0.80888031 0.53972195\n",
      " 0.92464358 0.83123181 0.74215686 0.61634018]\n",
      "mean_cluster_accuracy_during_training_cycle : 86.10%, post_traincycle_acc : 85.73%, total_acc : 85.87313826%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 89.03%\n",
      "accuracy_check 실행 시간: 24.292초\n",
      "\n",
      "\n",
      "epoch-62 loss : 0.01569029, loss_normal : 0.01609174, loss_coarse : 0.07521097, min_loss : 0.01569029, min_loss_normal : 0.01604865, min_loss_coarse : 0.07497690, wrong_element_sum : 14440506.00000000, same_data : 0.00%\n",
      "ae train 실행 시간: 119.567초, 전체 시작 시간 20250314_000157_781\n",
      "\n",
      "epoch-62 accuracy check\n",
      "k_means origin feature average accuracy : 82.24241277%, total [0.9746727376209448, 0.9733106189664963, 0.9700891573195284, 0.9530800230282096, 0.943108504398827, 0.9150568181818182, 0.801817648783348, 0.6622234826999432, 0.9488619568430388, 0.822215777262181, 0.5866935483870968, 0.5005858230814294, 0.9429250891795482, 0.8922588099364529, 0.673546511627907, 0.5983395362152877]\n",
      "kmeans average accuracy best : 89.23%, kmeans average accuracy : 86.93308167%, total [0.9760956175298805, 0.9764338444065872, 0.9729651998849583, 0.966321243523316, 0.9671554252199414, 0.946590909090909, 0.8317209029610085, 0.6917186613726602, 0.9677800768548626, 0.9318445475638051, 0.8231566820276498, 0.7422378441710603, 0.9259809750297265, 0.8238012709416522, 0.729360465116279, 0.6361294016604638]\n",
      "cluster_accuracy_post_training_cycle_all_dataset : [0.97492904 0.97549482 0.97159364 0.94985535 0.9681592  0.9504717\n",
      " 0.87021382 0.61712135 0.95763994 0.92626953 0.83156371 0.6449851\n",
      " 0.92820774 0.83268671 0.72696078 0.64787387]\n",
      "mean_cluster_accuracy_during_training_cycle : 86.01%, post_traincycle_acc : 86.09%, total_acc : 86.04972296%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 89.03%\n",
      "accuracy_check 실행 시간: 24.137초\n",
      "\n",
      "\n",
      "epoch-63 loss : 0.01569616, loss_normal : 0.01608558, loss_coarse : 0.07514875, min_loss : 0.01569029, min_loss_normal : 0.01604865, min_loss_coarse : 0.07497690, wrong_element_sum : 14428560.00000000, same_data : 0.00%\n",
      "ae train 실행 시간: 118.454초, 전체 시작 시간 20250314_000157_781\n",
      "\n",
      "epoch-63 accuracy check\n",
      "k_means origin feature average accuracy : 82.26218852%, total [0.9746727376209448, 0.9733106189664963, 0.9700891573195284, 0.9530800230282096, 0.943108504398827, 0.9150568181818182, 0.801817648783348, 0.6625070901871809, 0.9488619568430388, 0.822215777262181, 0.5866935483870968, 0.5005858230814294, 0.9429250891795482, 0.8922588099364529, 0.6747093023255814, 0.6000572573718866]\n",
      "kmeans average accuracy best : 89.23%, kmeans average accuracy : 86.61028015%, total [0.9766647694934547, 0.9775695627484384, 0.9735404083980443, 0.9651698330454808, 0.9668621700879766, 0.9446022727272727, 0.8323072412782175, 0.6698808848553602, 0.9618681643511676, 0.9208236658932715, 0.8035714285714286, 0.7419449326303457, 0.9289536266349584, 0.8298671288272674, 0.7267441860465116, 0.6372745490981964]\n",
      "cluster_accuracy_post_training_cycle_all_dataset : [0.97729423 0.97596607 0.97159364 0.96335583 0.96766169 0.95235849\n",
      " 0.87419194 0.67356538 0.95259708 0.91650391 0.80357143 0.55809335\n",
      " 0.92413442 0.83511154 0.73088235 0.63162924]\n",
      "mean_cluster_accuracy_during_training_cycle : 85.81%, post_traincycle_acc : 85.68%, total_acc : 85.73261717%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 89.03%\n",
      "accuracy_check 실행 시간: 23.856초\n",
      "\n",
      "\n",
      "epoch-64 loss : 0.01562056, loss_normal : 0.01609144, loss_coarse : 0.07508925, min_loss : 0.01562056, min_loss_normal : 0.01604865, min_loss_coarse : 0.07497690, wrong_element_sum : 14417136.00000000, same_data : 0.00%\n",
      "ae train 실행 시간: 112.142초, 전체 시작 시간 20250314_000157_781\n",
      "\n",
      "epoch-64 accuracy check\n",
      "k_means origin feature average accuracy : 82.25682064%, total [0.9746727376209448, 0.9733106189664963, 0.9700891573195284, 0.9530800230282096, 0.943108504398827, 0.9150568181818182, 0.801817648783348, 0.6625070901871809, 0.9488619568430388, 0.822215777262181, 0.5866935483870968, 0.5005858230814294, 0.9429250891795482, 0.8922588099364529, 0.6747093023255814, 0.5991983967935872]\n",
      "kmeans average accuracy best : 89.23%, kmeans average accuracy : 86.98667183%, total [0.9769493454752419, 0.9772856331629756, 0.9744032211676733, 0.9689119170984456, 0.9665689149560117, 0.946590909090909, 0.8375842861330988, 0.6905842314237096, 0.9630505468519066, 0.9164733178654292, 0.7998271889400922, 0.7193907439953134, 0.9372770511296076, 0.8573079145002889, 0.7380813953488372, 0.6475808760377899]\n",
      "cluster_accuracy_post_training_cycle_all_dataset : [0.97634816 0.97596607 0.9735195  0.96046287 0.9681592  0.95613208\n",
      " 0.90104426 0.65945437 0.9515885  0.87792969 0.58349421 0.52929494\n",
      " 0.93635438 0.84869059 0.72598039 0.61681796]\n",
      "mean_cluster_accuracy_during_training_cycle : 84.60%, post_traincycle_acc : 84.01%, total_acc : 84.24600618%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 89.03%\n",
      "accuracy_check 실행 시간: 24.966초\n",
      "\n",
      "\n",
      "epoch-65 loss : 0.01558836, loss_normal : 0.01604149, loss_coarse : 0.07491005, min_loss : 0.01558836, min_loss_normal : 0.01604149, min_loss_coarse : 0.07491005, wrong_element_sum : 14382730.00000000, same_data : 0.00%\n",
      "ae train 실행 시간: 114.476초, 전체 시작 시간 20250314_000157_781\n",
      "\n",
      "epoch-65 accuracy check\n",
      "k_means origin feature average accuracy : 82.23701572%, total [0.9746727376209448, 0.9733106189664963, 0.9700891573195284, 0.9530800230282096, 0.943108504398827, 0.915340909090909, 0.8015244796247435, 0.6622234826999432, 0.9488619568430388, 0.822215777262181, 0.5866935483870968, 0.5005858230814294, 0.9429250891795482, 0.8922588099364529, 0.6738372093023256, 0.5971943887775552]\n",
      "kmeans average accuracy best : 89.23%, kmeans average accuracy : 87.21090526%, total [0.9760956175298805, 0.9772856331629756, 0.9729651998849583, 0.9645941278065631, 0.9671554252199414, 0.9525568181818181, 0.8780416300205218, 0.7345433919455474, 0.9550694649719185, 0.910092807424594, 0.7819700460829493, 0.7281780902167545, 0.9108204518430439, 0.8385326400924321, 0.7473837209302325, 0.6584597766962497]\n",
      "cluster_accuracy_post_training_cycle_all_dataset : [0.97540208 0.97643732 0.97111218 0.96046287 0.96965174 0.95518868\n",
      " 0.9090005  0.69802446 0.93545134 0.91259766 0.8257722  0.6509434\n",
      " 0.9098778  0.84626576 0.74264706 0.65790731]\n",
      "mean_cluster_accuracy_during_training_cycle : 86.78%, post_traincycle_acc : 86.85%, total_acc : 86.82014359%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 89.03%\n",
      "accuracy_check 실행 시간: 25.036초\n",
      "\n",
      "\n",
      "epoch-66 loss : 0.01579031, loss_normal : 0.01605533, loss_coarse : 0.07512314, min_loss : 0.01558836, min_loss_normal : 0.01604149, min_loss_coarse : 0.07491005, wrong_element_sum : 14423644.00000000, same_data : 0.00%\n",
      "ae train 실행 시간: 117.874초, 전체 시작 시간 20250314_000157_781\n",
      "\n",
      "epoch-66 accuracy check\n",
      "k_means origin feature average accuracy : 82.25859911%, total [0.9746727376209448, 0.9733106189664963, 0.9700891573195284, 0.9530800230282096, 0.943108504398827, 0.9150568181818182, 0.801817648783348, 0.6622234826999432, 0.9488619568430388, 0.822215777262181, 0.5866935483870968, 0.5005858230814294, 0.9429250891795482, 0.8922588099364529, 0.6744186046511628, 0.6000572573718866]\n",
      "kmeans average accuracy best : 89.23%, kmeans average accuracy : 87.59125457%, total [0.9763801935116676, 0.9775695627484384, 0.9735404083980443, 0.9654576856649395, 0.966275659824047, 0.9497159090909091, 0.8686602169451774, 0.7240499149177538, 0.9657109074785694, 0.9254640371229699, 0.8052995391705069, 0.7021089630931459, 0.9328180737217598, 0.8633737723859041, 0.7488372093023256, 0.6693386773547094]\n",
      "cluster_accuracy_post_training_cycle_all_dataset : [0.97587512 0.97596607 0.97159364 0.95949855 0.9681592  0.9495283\n",
      " 0.89159622 0.74647225 0.95763994 0.92138672 0.80791506 0.63306852\n",
      " 0.93329939 0.86954413 0.7504902  0.66841854]\n",
      "mean_cluster_accuracy_during_training_cycle : 87.17%, post_traincycle_acc : 87.38%, total_acc : 87.28965240%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 89.03%\n",
      "accuracy_check 실행 시간: 24.739초\n",
      "\n",
      "\n",
      "epoch-67 loss : 0.01551802, loss_normal : 0.01603537, loss_coarse : 0.07487127, min_loss : 0.01551802, min_loss_normal : 0.01603537, min_loss_coarse : 0.07487127, wrong_element_sum : 14375284.00000000, same_data : 0.00%\n",
      "ae train 실행 시간: 120.297초, 전체 시작 시간 20250314_000157_781\n",
      "\n",
      "epoch-67 accuracy check\n",
      "k_means origin feature average accuracy : 82.26390593%, total [0.9746727376209448, 0.9733106189664963, 0.9700891573195284, 0.9530800230282096, 0.943108504398827, 0.9150568181818182, 0.801817648783348, 0.6622234826999432, 0.9488619568430388, 0.822215777262181, 0.5872695852534562, 0.5005858230814294, 0.9429250891795482, 0.8922588099364529, 0.673546511627907, 0.6012024048096193]\n",
      "kmeans average accuracy best : 89.23%, kmeans average accuracy : 88.62985723%, total [0.9760956175298805, 0.9770017035775128, 0.9729651998849583, 0.9637305699481865, 0.9659824046920821, 0.9528409090909091, 0.8891820580474934, 0.7733976176971072, 0.9686668637304168, 0.9228538283062645, 0.807315668202765, 0.7229056824838899, 0.9357907253269917, 0.876372039283651, 0.7837209302325582, 0.6919553392499285]\n",
      "cluster_accuracy_post_training_cycle_all_dataset : [0.97540208 0.97549482 0.97159364 0.96190935 0.96716418 0.95141509\n",
      " 0.8990552  0.76952023 0.95965709 0.92041016 0.8238417  0.69116187\n",
      " 0.93839104 0.88991271 0.78088235 0.67271859]\n",
      "mean_cluster_accuracy_during_training_cycle : 88.09%, post_traincycle_acc : 88.43%, total_acc : 88.28838996%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 89.03%\n",
      "accuracy_check 실행 시간: 26.121초\n",
      "\n",
      "\n",
      "epoch-68 loss : 0.01615676, loss_normal : 0.01621373, loss_coarse : 0.07586203, min_loss : 0.01551802, min_loss_normal : 0.01603537, min_loss_coarse : 0.07487127, wrong_element_sum : 14565510.00000000, same_data : 0.00%\n",
      "ae train 실행 시간: 117.199초, 전체 시작 시간 20250314_000157_781\n",
      "\n",
      "epoch-68 accuracy check\n",
      "k_means origin feature average accuracy : 82.25318692%, total [0.9746727376209448, 0.9733106189664963, 0.9700891573195284, 0.9530800230282096, 0.943108504398827, 0.9150568181818182, 0.801817648783348, 0.6625070901871809, 0.9488619568430388, 0.822215777262181, 0.5866935483870968, 0.5005858230814294, 0.9429250891795482, 0.8922588099364529, 0.6741279069767442, 0.5991983967935872]\n",
      "kmeans average accuracy best : 89.23%, kmeans average accuracy : 87.38054295%, total [0.9760956175298805, 0.9775695627484384, 0.9723899913718723, 0.966321243523316, 0.9665689149560117, 0.9457386363636363, 0.8475520375256523, 0.7277368122518435, 0.9689624593556015, 0.9234338747099768, 0.8294930875576036, 0.7495606326889279, 0.9185493460166468, 0.829000577700751, 0.7363372093023256, 0.6455768680217578]\n",
      "cluster_accuracy_post_training_cycle_all_dataset : [0.97587512 0.97643732 0.97111218 0.96287367 0.96666667 0.95188679\n",
      " 0.89656887 0.70555033 0.95310136 0.92382812 0.82480695 0.66832175\n",
      " 0.91700611 0.83656644 0.72941176 0.64882943]\n",
      "mean_cluster_accuracy_during_training_cycle : 86.17%, post_traincycle_acc : 86.93%, total_acc : 86.61656783%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 89.03%\n",
      "accuracy_check 실행 시간: 27.410초\n",
      "\n",
      "\n",
      "epoch-69 loss : 0.01559116, loss_normal : 0.01605179, loss_coarse : 0.07489648, min_loss : 0.01551802, min_loss_normal : 0.01603537, min_loss_coarse : 0.07487127, wrong_element_sum : 14380124.00000000, same_data : 0.00%\n",
      "ae train 실행 시간: 117.823초, 전체 시작 시간 20250314_000157_781\n",
      "\n",
      "epoch-69 accuracy check\n",
      "k_means origin feature average accuracy : 82.25863750%, total [0.9746727376209448, 0.9733106189664963, 0.9700891573195284, 0.9530800230282096, 0.943108504398827, 0.9150568181818182, 0.801817648783348, 0.6625070901871809, 0.9488619568430388, 0.822215777262181, 0.5866935483870968, 0.5005858230814294, 0.9429250891795482, 0.8922588099364529, 0.675, 0.5991983967935872]\n",
      "kmeans average accuracy best : 89.23%, kmeans average accuracy : 87.01643924%, total [0.9758110415480934, 0.9775695627484384, 0.9729651998849583, 0.9620034542314335, 0.9648093841642229, 0.9360795454545454, 0.8545880973321607, 0.7195121951219512, 0.9692580549807863, 0.9303944315545244, 0.7609447004608295, 0.7073813708260105, 0.9230083234244947, 0.8469093009820913, 0.7534883720930232, 0.6679072430575437]\n",
      "cluster_accuracy_post_training_cycle_all_dataset : [0.97634816 0.97690858 0.97111218 0.96046287 0.96567164 0.93867925\n",
      " 0.88363998 0.70555033 0.9515885  0.9296875  0.82432432 0.53277061\n",
      " 0.92566191 0.85693501 0.74019608 0.62637363]\n",
      "mean_cluster_accuracy_during_training_cycle : 86.00%, post_traincycle_acc : 86.04%, total_acc : 86.02103579%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 89.03%\n",
      "accuracy_check 실행 시간: 26.429초\n",
      "\n",
      "\n",
      "epoch-70 loss : 0.01558604, loss_normal : 0.01605726, loss_coarse : 0.07497381, min_loss : 0.01551802, min_loss_normal : 0.01603537, min_loss_coarse : 0.07487127, wrong_element_sum : 14394972.00000000, same_data : 0.00%\n",
      "ae train 실행 시간: 122.601초, 전체 시작 시간 20250314_000157_781\n",
      "\n",
      "epoch-70 accuracy check\n",
      "k_means origin feature average accuracy : 82.25501460%, total [0.9746727376209448, 0.9733106189664963, 0.9700891573195284, 0.9530800230282096, 0.943108504398827, 0.9150568181818182, 0.801817648783348, 0.6622234826999432, 0.9488619568430388, 0.822215777262181, 0.5872695852534562, 0.5005858230814294, 0.9429250891795482, 0.8922588099364529, 0.6741279069767442, 0.5991983967935872]\n",
      "kmeans average accuracy best : 89.23%, kmeans average accuracy : 86.72855998%, total [0.9760956175298805, 0.9772856331629756, 0.9738280126545873, 0.9677605066206102, 0.9656891495601173, 0.9383522727272727, 0.7695690413368513, 0.6891661939875213, 0.9639373337274608, 0.9234338747099768, 0.8110599078341014, 0.7431165787932045, 0.9337098692033293, 0.86683997689197, 0.7340116279069767, 0.6427139994274262]\n",
      "cluster_accuracy_post_training_cycle_all_dataset : [0.97587512 0.97690858 0.97159364 0.95564127 0.96666667 0.94716981\n",
      " 0.87120835 0.68814675 0.95360565 0.90771484 0.81563707 0.65243297\n",
      " 0.93075356 0.87584869 0.71421569 0.62924032]\n",
      "mean_cluster_accuracy_during_training_cycle : 86.08%, post_traincycle_acc : 86.45%, total_acc : 86.29787116%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 89.03%\n",
      "accuracy_check 실행 시간: 26.694초\n",
      "\n",
      "\n",
      "epoch-71 loss : 0.01555753, loss_normal : 0.01605144, loss_coarse : 0.07486698, min_loss : 0.01551802, min_loss_normal : 0.01603537, min_loss_coarse : 0.07486698, wrong_element_sum : 14374460.00000000, same_data : 0.00%\n",
      "ae train 실행 시간: 120.547초, 전체 시작 시간 20250314_000157_781\n",
      "\n",
      "epoch-71 accuracy check\n",
      "k_means origin feature average accuracy : 82.24781442%, total [0.9746727376209448, 0.9733106189664963, 0.9700891573195284, 0.9530800230282096, 0.943108504398827, 0.9150568181818182, 0.8015244796247435, 0.6622234826999432, 0.9488619568430388, 0.822215777262181, 0.5872695852534562, 0.5005858230814294, 0.9429250891795482, 0.8922588099364529, 0.6741279069767442, 0.5983395362152877]\n",
      "kmeans average accuracy best : 89.23%, kmeans average accuracy : 87.07314170%, total [0.974957313602732, 0.97671777399205, 0.9718147828587863, 0.9634427173287277, 0.9659824046920821, 0.9411931818181818, 0.8501905599530929, 0.7149744753261487, 0.9592078037245049, 0.9245939675174014, 0.8116359447004609, 0.7155828939660223, 0.9158739595719382, 0.8495089543616406, 0.7418604651162791, 0.6541654738047523]\n",
      "cluster_accuracy_post_training_cycle_all_dataset : [0.97492904 0.97643732 0.96918633 0.95853423 0.96865672 0.94481132\n",
      " 0.88165092 0.69473189 0.95057993 0.92529297 0.81611969 0.43992056\n",
      " 0.91649695 0.84723569 0.74068627 0.65551839]\n",
      "mean_cluster_accuracy_during_training_cycle : 85.73%, post_traincycle_acc : 85.38%, total_acc : 85.52183593%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 89.03%\n",
      "accuracy_check 실행 시간: 26.406초\n",
      "\n",
      "\n",
      "epoch-72 loss : 0.01549095, loss_normal : 0.01604276, loss_coarse : 0.07478200, min_loss : 0.01549095, min_loss_normal : 0.01603537, min_loss_coarse : 0.07478200, wrong_element_sum : 14358144.00000000, same_data : 0.00%\n",
      "ae train 실행 시간: 117.628초, 전체 시작 시간 20250314_000157_781\n",
      "\n",
      "epoch-72 accuracy check\n",
      "k_means origin feature average accuracy : 82.24608488%, total [0.9746727376209448, 0.9733106189664963, 0.9700891573195284, 0.9530800230282096, 0.943108504398827, 0.9150568181818182, 0.801817648783348, 0.6625070901871809, 0.9488619568430388, 0.822215777262181, 0.5866935483870968, 0.5005858230814294, 0.9429250891795482, 0.8922588099364529, 0.6747093023255814, 0.5974806756369883]\n",
      "kmeans average accuracy best : 89.23%, kmeans average accuracy : 87.28385064%, total [0.9763801935116676, 0.9775695627484384, 0.9732528041415013, 0.9637305699481865, 0.9665689149560117, 0.946875, 0.8692465552623864, 0.7237663074305162, 0.9633461424770914, 0.9222737819025522, 0.7577764976958525, 0.7065026362038664, 0.9233055885850179, 0.8590410167533218, 0.7581395348837209, 0.6776409962782708]\n",
      "cluster_accuracy_post_training_cycle_all_dataset : [0.97398297 0.97690858 0.97159364 0.95949855 0.96766169 0.95\n",
      " 0.89457981 0.70272813 0.94957136 0.92041016 0.81467181 0.57994042\n",
      " 0.9200611  0.85984481 0.75245098 0.64070712]\n",
      "mean_cluster_accuracy_during_training_cycle : 86.55%, post_traincycle_acc : 86.47%, total_acc : 86.49585422%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 89.03%\n",
      "accuracy_check 실행 시간: 27.562초\n",
      "\n",
      "\n",
      "epoch-73 loss : 0.01544941, loss_normal : 0.01602218, loss_coarse : 0.07479841, min_loss : 0.01544941, min_loss_normal : 0.01602218, min_loss_coarse : 0.07478200, wrong_element_sum : 14361296.00000000, same_data : 0.00%\n",
      "ae train 실행 시간: 122.183초, 전체 시작 시간 20250314_000157_781\n",
      "\n",
      "epoch-73 accuracy check\n",
      "k_means origin feature average accuracy : 82.26756432%, total [0.9746727376209448, 0.9733106189664963, 0.9700891573195284, 0.9530800230282096, 0.943108504398827, 0.915340909090909, 0.801817648783348, 0.6625070901871809, 0.9488619568430388, 0.822215777262181, 0.5872695852534562, 0.5005858230814294, 0.9429250891795482, 0.8922588099364529, 0.6747093023255814, 0.6000572573718866]\n",
      "kmeans average accuracy best : 89.23%, kmeans average accuracy : 87.06667618%, total [0.9758110415480934, 0.9772856331629756, 0.9735404083980443, 0.9631548647092688, 0.9651026392961877, 0.9426136363636364, 0.8551744356493697, 0.7402155416903006, 0.9571386343482117, 0.8955916473317865, 0.7399193548387096, 0.6906854130052724, 0.9304399524375743, 0.8682842287694974, 0.7697674418604651, 0.6859433152018323]\n",
      "cluster_accuracy_post_training_cycle_all_dataset : [0.97682119 0.97643732 0.97255657 0.96094503 0.96716418 0.94716981\n",
      " 0.88612631 0.75305738 0.95713565 0.91796875 0.82239382 0.68123138\n",
      " 0.93228106 0.87778855 0.76421569 0.66889632]\n",
      "mean_cluster_accuracy_during_training_cycle : 87.18%, post_traincycle_acc : 87.89%, total_acc : 87.59957418%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 89.03%\n",
      "accuracy_check 실행 시간: 28.203초\n",
      "\n",
      "\n",
      "epoch-74 loss : 0.01555076, loss_normal : 0.01608493, loss_coarse : 0.07495216, min_loss : 0.01544941, min_loss_normal : 0.01602218, min_loss_coarse : 0.07478200, wrong_element_sum : 14390816.00000000, same_data : 0.00%\n",
      "ae train 실행 시간: 118.784초, 전체 시작 시간 20250314_000157_781\n",
      "\n",
      "epoch-74 accuracy check\n",
      "k_means origin feature average accuracy : 82.25496539%, total [0.9746727376209448, 0.9733106189664963, 0.9700891573195284, 0.9530800230282096, 0.943108504398827, 0.9150568181818182, 0.801817648783348, 0.6622234826999432, 0.9488619568430388, 0.822215777262181, 0.5866935483870968, 0.5005858230814294, 0.9429250891795482, 0.8922588099364529, 0.6738372093023256, 0.6000572573718866]\n",
      "kmeans average accuracy best : 89.23%, kmeans average accuracy : 87.26578629%, total [0.9758110415480934, 0.9772856331629756, 0.9732528041415013, 0.9625791594703512, 0.9659824046920821, 0.9411931818181818, 0.8598651421870419, 0.7436188315371526, 0.9621637599763524, 0.933584686774942, 0.818836405529954, 0.700937316930287, 0.9129013079667063, 0.8489312536106297, 0.7328488372093023, 0.6527340395075866]\n",
      "cluster_accuracy_post_training_cycle_all_dataset : [0.97682119 0.97737983 0.97255657 0.95949855 0.9681592  0.94811321\n",
      " 0.88214818 0.72624647 0.95259708 0.93310547 0.81708494 0.44538232\n",
      " 0.90885947 0.84820563 0.73823529 0.66172957]\n",
      "mean_cluster_accuracy_during_training_cycle : 85.88%, post_traincycle_acc : 85.73%, total_acc : 85.78928806%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 89.03%\n",
      "accuracy_check 실행 시간: 27.825초\n",
      "\n",
      "\n",
      "epoch-75 loss : 0.01548873, loss_normal : 0.01602861, loss_coarse : 0.07473829, min_loss : 0.01544941, min_loss_normal : 0.01602218, min_loss_coarse : 0.07473829, wrong_element_sum : 14349752.00000000, same_data : 0.00%\n",
      "ae train 실행 시간: 116.124초, 전체 시작 시간 20250314_000157_781\n",
      "\n",
      "epoch-75 accuracy check\n",
      "k_means origin feature average accuracy : 82.25845862%, total [0.9746727376209448, 0.9733106189664963, 0.9700891573195284, 0.9530800230282096, 0.943108504398827, 0.9150568181818182, 0.801817648783348, 0.6625070901871809, 0.9488619568430388, 0.822215777262181, 0.5866935483870968, 0.5005858230814294, 0.942627824019025, 0.8922588099364529, 0.6738372093023256, 0.600629831090753]\n",
      "kmeans average accuracy best : 89.23%, kmeans average accuracy : 87.80185682%, total [0.9760956175298805, 0.9772856331629756, 0.9729651998849583, 0.9625791594703512, 0.9668621700879766, 0.9497159090909091, 0.8806801524479625, 0.7612024957458877, 0.9592078037245049, 0.9248839907192575, 0.8107718894009217, 0.7097246631517282, 0.9164684898929846, 0.854419410745234, 0.7555232558139535, 0.6699112510735757]\n",
      "cluster_accuracy_post_training_cycle_all_dataset : [0.97634816 0.97643732 0.97207511 0.95998071 0.96766169 0.95\n",
      " 0.90203879 0.74553151 0.95864851 0.92236328 0.83011583 0.43147964\n",
      " 0.91496945 0.87051406 0.74362745 0.63640707]\n",
      "mean_cluster_accuracy_during_training_cycle : 86.17%, post_traincycle_acc : 85.99%, total_acc : 86.06217316%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 89.03%\n",
      "accuracy_check 실행 시간: 27.595초\n",
      "\n",
      "\n",
      "epoch-76 loss : 0.01547504, loss_normal : 0.01602432, loss_coarse : 0.07476432, min_loss : 0.01544941, min_loss_normal : 0.01602218, min_loss_coarse : 0.07473829, wrong_element_sum : 14354750.00000000, same_data : 0.00%\n",
      "ae train 실행 시간: 123.313초, 전체 시작 시간 20250314_000157_781\n",
      "\n",
      "epoch-76 accuracy check\n",
      "k_means origin feature average accuracy : 82.25505299%, total [0.9746727376209448, 0.9733106189664963, 0.9700891573195284, 0.9530800230282096, 0.943108504398827, 0.9150568181818182, 0.801817648783348, 0.6625070901871809, 0.9488619568430388, 0.822215777262181, 0.5872695852534562, 0.5005858230814294, 0.9429250891795482, 0.8922588099364529, 0.6747093023255814, 0.5983395362152877]\n",
      "kmeans average accuracy best : 89.23%, kmeans average accuracy : 86.83838221%, total [0.9758110415480934, 0.9772856331629756, 0.9726775956284153, 0.9645941278065631, 0.9668621700879766, 0.9377840909090909, 0.8540017590149517, 0.6863301191151446, 0.9627549512267218, 0.9129930394431555, 0.7952188940092166, 0.6939074399531342, 0.9048751486325802, 0.8573079145002889, 0.7558139534883721, 0.6759232751216719]\n",
      "cluster_accuracy_post_training_cycle_all_dataset : [0.97587512 0.97737983 0.97111218 0.96142719 0.96666667 0.94198113\n",
      " 0.87916459 0.69802446 0.94704992 0.90673828 0.77557915 0.58242304\n",
      " 0.90173116 0.86081474 0.74509804 0.64309603]\n",
      "mean_cluster_accuracy_during_training_cycle : 85.44%, post_traincycle_acc : 85.84%, total_acc : 85.67338806%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 89.03%\n",
      "accuracy_check 실행 시간: 28.376초\n",
      "\n",
      "\n",
      "epoch-77 loss : 0.01591675, loss_normal : 0.01608349, loss_coarse : 0.07517645, min_loss : 0.01544941, min_loss_normal : 0.01602218, min_loss_coarse : 0.07473829, wrong_element_sum : 14433878.00000000, same_data : 0.00%\n",
      "ae train 실행 시간: 119.267초, 전체 시작 시간 20250314_000157_781\n",
      "\n",
      "epoch-77 accuracy check\n",
      "k_means origin feature average accuracy : 82.25678225%, total [0.9746727376209448, 0.9733106189664963, 0.9700891573195284, 0.9530800230282096, 0.943108504398827, 0.9150568181818182, 0.801817648783348, 0.6622234826999432, 0.9488619568430388, 0.822215777262181, 0.5866935483870968, 0.5005858230814294, 0.9429250891795482, 0.8922588099364529, 0.6741279069767442, 0.6000572573718866]\n",
      "kmeans average accuracy best : 89.23%, kmeans average accuracy : 86.65446005%, total [0.9758110415480934, 0.9772856331629756, 0.9741156169111302, 0.9671848013816926, 0.9659824046920821, 0.9451704545454546, 0.8569334506009968, 0.7234826999432785, 0.9645285249778304, 0.912122969837587, 0.6854838709677419, 0.663444639718805, 0.9435196195005945, 0.8809936452917388, 0.7601744186046512, 0.66847981677641]\n",
      "cluster_accuracy_post_training_cycle_all_dataset : [0.97540208 0.97596607 0.97207511 0.96190935 0.96567164 0.95\n",
      " 0.89060169 0.69143932 0.95511851 0.91552734 0.77027027 0.61519364\n",
      " 0.9404277  0.88748788 0.75196078 0.67701863]\n",
      "mean_cluster_accuracy_during_training_cycle : 86.31%, post_traincycle_acc : 86.85%, total_acc : 86.62745623%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 89.03%\n",
      "accuracy_check 실행 시간: 27.293초\n",
      "\n",
      "\n",
      "epoch-78 loss : 0.01549445, loss_normal : 0.01602653, loss_coarse : 0.07478157, min_loss : 0.01544941, min_loss_normal : 0.01602218, min_loss_coarse : 0.07473829, wrong_element_sum : 14358062.00000000, same_data : 0.00%\n",
      "ae train 실행 시간: 121.946초, 전체 시작 시간 20250314_000157_781\n",
      "\n",
      "epoch-78 accuracy check\n",
      "k_means origin feature average accuracy : 82.25499005%, total [0.9746727376209448, 0.9733106189664963, 0.9700891573195284, 0.9530800230282096, 0.943108504398827, 0.915340909090909, 0.801817648783348, 0.6625070901871809, 0.9488619568430388, 0.822215777262181, 0.5866935483870968, 0.5005858230814294, 0.9429250891795482, 0.8922588099364529, 0.6744186046511628, 0.598912109934154]\n",
      "kmeans average accuracy best : 89.23%, kmeans average accuracy : 87.84186728%, total [0.9760956175298805, 0.9772856331629756, 0.9732528041415013, 0.9671848013816926, 0.9665689149560117, 0.9545454545454546, 0.883318674875403, 0.7422007941009643, 0.9654153118533846, 0.9243039443155452, 0.7972350230414746, 0.6959578207381371, 0.9167657550535078, 0.8760831889081456, 0.7665697674418605, 0.6719152590896078]\n",
      "cluster_accuracy_post_training_cycle_all_dataset : [0.97587512 0.97643732 0.97159364 0.96287367 0.96666667 0.95566038\n",
      " 0.90253605 0.73894638 0.9369642  0.92529297 0.80501931 0.59682224\n",
      " 0.91496945 0.88894277 0.7622549  0.65504061]\n",
      "mean_cluster_accuracy_during_training_cycle : 86.94%, post_traincycle_acc : 87.10%, total_acc : 87.03386862%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 89.03%\n",
      "accuracy_check 실행 시간: 27.589초\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "gpu = '0'\n",
    "Conv_net = True # True False\n",
    "SAE_net = True # True False\n",
    "\n",
    "# hyperparameter\n",
    "dataset_num = 16\n",
    "spike_length = 50 # coarse_com_mode일 때는 time step이 됨.\n",
    "num_cluster = 4  # 클러스터 수 설정 # 논문엔 4개라는데 여기서는 3개로 했네\n",
    "training_cycle = 1400 #1400 2400 # 그 초기 몇개까지만 cluster update할지\n",
    "\n",
    "\n",
    "batch_size = 32\n",
    "max_epoch = 10000\n",
    "learning_rate = 0.001\n",
    "normalize_on = True # True or False # 0부터1까지 normalize\n",
    "need_bias = False\n",
    "# first_layer_no_train = False\n",
    "lif_add_at_first = False\n",
    "my_seed = 42\n",
    "\n",
    "TIME = 50 # SAE일 때만 유효. coarse_com_mode일 때는 level_num이 됨. 즉 feature 개수.\n",
    "v_decay = 0.5 # -cor\n",
    "v_threshold = 0.25 # -cor\n",
    "v_reset = 0.0 # -cor # 10000이상 일 시 hard reset\n",
    "BPTT_on = True # +cor # True False\n",
    "\n",
    "SAE_hidden_nomean = True # True False\n",
    "\n",
    "current_time = datetime.datetime.now().strftime(\"%Y%m%d_%H%M%S\") + f\"_{str(int(datetime.datetime.now().microsecond / 1000)).zfill(3)}\"\n",
    "\n",
    "optimizer = 'Adam' #'Adam', 'SGD' # 둘다 준수함. loss 줄이는 거는 adam이 좋긴한데, cluster accuracy는 비슷함.\n",
    "\n",
    "coarse_com_mode = True # True False\n",
    "coarse_com_config = (0.999, -0.0) # (max, min) (0.999, -0.0) (1.0, -0.0) (2.0, -2.0) (3.0, -3.0)\n",
    "\n",
    "sae_l2_norm_bridge = True # True False\n",
    "sae_lif_bridge = False # True False\n",
    "\n",
    "accuracy_check_epoch_term = 1\n",
    "\n",
    "lif_add_at_last = False # True False\n",
    "\n",
    "two_channel_input = False # True False\n",
    "\n",
    "lateral_feature_num = 3\n",
    "\n",
    "lc_adc_on = False # True False\n",
    "\n",
    "converted_net_forward = False # True False\n",
    "\n",
    "pretrained_net = None\n",
    "# pretrained_net = '/home/bhkim003/github_folder/ByeonghyeonKim/my_snn/net_save/save_now_net_중요_20250110_203117_390.pth'\n",
    "# pretrained_net = '/home/bhkim003/github_folder/ByeonghyeonKim/my_snn/net_save/save_now_net_중요_20250113_134126_881_이거_94나오는거.pth'\n",
    "# pretrained_net =  '/home/bhkim003/github_folder/ByeonghyeonKim/my_snn/net_save/save_now_net_20250205_184901_132.pth'\n",
    "# pretrained_net =  '/home/bhkim003/github_folder/ByeonghyeonKim/my_snn/net_save/save_now_net_20250306_134219_133.pth'\n",
    "\n",
    "vth_mul_on = False # True False\n",
    "batch_norm_on = False # True False\n",
    "\n",
    "l2_norm_loss_weight = 0 #0.0001 #0.1 #  0 # 0초과면 작동\n",
    "\n",
    "QCFS_neuron_on = False # True False\n",
    "\n",
    "quantize_level_num = 0 # 0이면 quantize 안함. 1이상이면 그 수만큼 quantize함. # normalize_on 켜져야됨. 음수면 0~1norm안하고 quant함\n",
    "\n",
    "fusion_net = True # True False # SAE_net False, Conv_net True로 해라. TIME 적절하게 설정해주고.\n",
    "repeat_coding = False # True False #fusion_net에서 쓰이는 거임 # True면 repeat, False면 rate coding.\n",
    "\n",
    "sae_relu_on = False # True False\n",
    "\n",
    "conv1d_scaling = False # True False # conv1d때매 norm하고 (level_num-3)/level_num 곱해줌 # Conv_net and coarse_com_mode and normalize_on\n",
    "\n",
    "norm01 = True # True False # normalize_on = True일 때 01norm하는지 아님 걍 quant만 하는지.\n",
    "\n",
    "wandb.init(project= f'spike_sorting just run',save_code=False)\n",
    "\n",
    "\n",
    "cluster_train_system( \n",
    "    gpu = gpu,\n",
    "    Conv_net = Conv_net,\n",
    "    SAE_net = SAE_net,\n",
    "\n",
    "    # hyperparameter\n",
    "    dataset_num = dataset_num,\n",
    "    spike_length = spike_length,\n",
    "    num_cluster = num_cluster,  # 클러스터 수 설정 # 논문엔 4개라는데 여기서는 3개로 했네\n",
    "    training_cycle = training_cycle, # 그 초기 몇개까지만 cluster update할지\n",
    "\n",
    "\n",
    "    batch_size = batch_size,\n",
    "    max_epoch = max_epoch,\n",
    "    learning_rate = learning_rate,\n",
    "    normalize_on = normalize_on, # True or False #이거 안 씀 # 이거 별로 안 좋은 normalize같음 # 쓸 거면 다른 거 써라.\n",
    "    need_bias = need_bias,\n",
    "    # first_layer_no_train = False\n",
    "    lif_add_at_first = lif_add_at_first,\n",
    "    my_seed = my_seed,\n",
    "\n",
    "    TIME = TIME, # SAE일 때만 유효\n",
    "    v_decay = v_decay,\n",
    "    v_threshold = v_threshold,\n",
    "    v_reset = v_reset, # 10000이상 일 시 hard reset\n",
    "    BPTT_on = BPTT_on,\n",
    "\n",
    "    SAE_hidden_nomean = SAE_hidden_nomean,\n",
    "    \n",
    "    current_time = current_time,\n",
    "\n",
    "    optimizer = optimizer, #'Adam', 'SGD'\n",
    "\n",
    "    coarse_com_mode = coarse_com_mode,\n",
    "    coarse_com_config = coarse_com_config, # (max, min)\n",
    "\n",
    "    \n",
    "    sae_l2_norm_bridge = sae_l2_norm_bridge,\n",
    "    sae_lif_bridge = sae_lif_bridge,\n",
    "\n",
    "    accuracy_check_epoch_term = accuracy_check_epoch_term,\n",
    "    \n",
    "    lif_add_at_last = lif_add_at_last,\n",
    "\n",
    "    two_channel_input = two_channel_input,\n",
    "\n",
    "    lateral_feature_num = lateral_feature_num,\n",
    "\n",
    "    lc_adc_on = lc_adc_on, \n",
    "\n",
    "    converted_net_forward = converted_net_forward,\n",
    "\n",
    "    pretrained_net = pretrained_net,\n",
    "\n",
    "    vth_mul_on = vth_mul_on,\n",
    "    batch_norm_on = batch_norm_on,\n",
    "\n",
    "    l2_norm_loss_weight = l2_norm_loss_weight,\n",
    "    \n",
    "    QCFS_neuron_on = QCFS_neuron_on, # True False\n",
    "\n",
    "    quantize_level_num = quantize_level_num,\n",
    "\n",
    "    fusion_net = fusion_net, # True False\n",
    "    repeat_coding = repeat_coding,\n",
    "\n",
    "    sae_relu_on = sae_relu_on,\n",
    "\n",
    "    conv1d_scaling = conv1d_scaling,\n",
    "\n",
    "    norm01 = norm01,\n",
    "\n",
    "    )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Sweep code\n",
    "\n",
    "\n",
    "# from unittest import TextTestRunner\n",
    "\n",
    "\n",
    "# unique_name_hyper = 'cluster_train_system'\n",
    "# # run_name = 'spike_sorting'\n",
    "# sweep_start_time =  datetime.datetime.now().strftime(\"%Y%m%d_%H%M%S\") + f\"_{str(int(datetime.datetime.now().microsecond / 1000)).zfill(3)}\"\n",
    "# sweep_configuration = {\n",
    "#     'method': 'bayes', # 'random', 'bayes'\n",
    "#     'name': f'spike_sorting_{sweep_start_time}',\n",
    "#     'metric': {'goal': 'maximize', 'name': 'k_means_acc_best'},\n",
    "#     'parameters': \n",
    "#     {\n",
    "#         # \"gpu\": {\"values\": ['1']},  # 이건 sweep parameter아님. hyper_iter에서 직접 설정\n",
    "#         \"Conv_net\": {\"values\": [True]}, \n",
    "#         \"SAE_net\": {\"values\": [True]}, \n",
    "\n",
    "#         \"dataset_num\": {\"values\": [16]}, \n",
    "#         \"spike_length\": {\"values\": [50]},  \n",
    "#         \"num_cluster\": {\"values\": [4]}, \n",
    "#         \"training_cycle\": {\"values\": [1400]}, # [1400, 2400]\n",
    "\n",
    "#         \"batch_size\": {\"values\": [32]}, \n",
    "#         \"max_epoch\": {\"values\": [20]}, \n",
    "#         \"learning_rate\": {\"values\": [0.001, 0.0001]},\n",
    "#         \"normalize_on\": {\"values\": [True]},\n",
    "#         \"need_bias\": {\"values\": [False]}, # [True, False]\n",
    "\n",
    "#         \"lif_add_at_first\": {\"values\": [False]}, # [True, False]\n",
    "#         \"my_seed\": {\"values\": [42]}, \n",
    "\n",
    "#         \"TIME\": {\"values\": [50]}, #  [4,6,8,10]\n",
    "#         \"v_decay\": {\"values\": [0.125, 0.25,0.50,0.75,1.0]}, # [0.25,0.50,0.75]\n",
    "#         \"v_threshold\": {\"values\": [0.125, 0.25, 0.50, 0.75, 0.875, 1.0]}, # [0.25,0.50,0.75]\n",
    "#         \"v_reset\": {\"values\": [0.0, 10000.0]},  # [0.0, 10000.0]\n",
    "#         \"BPTT_on\": {\"values\": [True, False]},  # [True, False]\n",
    "\n",
    "#         \"SAE_hidden_nomean\": {\"values\": [True]}, # [True, False]\n",
    "\n",
    "#         # \"current_time\": {\"values\": [current_time]} #밑에서 직접설정됨.\n",
    "\n",
    "#         \"optimizer\": {\"values\": ['Adam', 'SGD']}, # ['Adam', 'SGD']\n",
    "\n",
    "#         \"coarse_com_mode\": {\"values\": [True]}, # [True, False]\n",
    "#         \"coarse_com_config\": {\"values\": [(0.999, -0.0)]}, # ['Adam', 'SGD']\n",
    "\n",
    "#         \"sae_l2_norm_bridge\": {\"values\": [True]}, # [True, False]\n",
    "#         \"sae_lif_bridge\": {\"values\": [False]}, # [False, True]\n",
    "        \n",
    "#         \"accuracy_check_epoch_term\": {\"values\": [1]}, \n",
    "\n",
    "#         \"lif_add_at_last\": {\"values\": [False]},# [True, False]\n",
    "\n",
    "#         \"two_channel_input\": {\"values\": [False]},# [True, False]\n",
    "\n",
    "#         \"lateral_feature_num\": {\"values\": [4]},# [True, False]\n",
    "\n",
    "#         \"lc_adc_on\": {\"values\": [False]},# [True, False]\n",
    "        \n",
    "#         \"converted_net_forward\": {\"values\": [False]},# [True, False]\n",
    "\n",
    "#         \"pretrained_net\": {\"values\": [None]},# [None]\n",
    "\n",
    "#         \"vth_mul_on\": {\"values\": [False]},# [True, False]\n",
    "#         \"batch_norm_on\": {\"values\": [False]},# [True, False]\n",
    "\n",
    "#         \"l2_norm_loss_weight\": {\"values\": [0]},\n",
    "\n",
    "#         \"QCFS_neuron_on\": {\"values\": [False]},   # [True, False]\n",
    "\n",
    "#         \"quantize_level_num\": {\"values\": [0]}, \n",
    "\n",
    "#         \"fusion_net\": {\"values\": [True]}, \n",
    "#         \"repeat_coding\": {\"values\": [False]}, \n",
    "\n",
    "#         \"sae_relu_on\": {\"values\": [False]}, \n",
    "\n",
    "#         \"conv1d_scaling\": {\"values\": [False]}, \n",
    "\n",
    "#         \"norm01\": {\"values\": [True]}, \n",
    "#      }\n",
    "# }\n",
    "\n",
    "\n",
    "# def hyper_iter():\n",
    "#     ### my_snn control board ########################\n",
    "#     wandb.init(save_code = False)\n",
    "#     gpu  =  '2'\n",
    "#     Conv_net  =  wandb.config.Conv_net\n",
    "#     SAE_net  =  wandb.config.SAE_net\n",
    "\n",
    "#     dataset_num  =  wandb.config.dataset_num\n",
    "#     spike_length  =  wandb.config.spike_length\n",
    "#     num_cluster  =  wandb.config.num_cluster\n",
    "#     training_cycle  =  wandb.config.training_cycle\n",
    "\n",
    "#     batch_size  =  wandb.config.batch_size\n",
    "#     max_epoch  =  wandb.config.max_epoch\n",
    "#     learning_rate  =  wandb.config.learning_rate\n",
    "#     normalize_on  =  wandb.config.normalize_on\n",
    "#     need_bias  =  wandb.config.need_bias\n",
    "\n",
    "#     lif_add_at_first  =  wandb.config.lif_add_at_first\n",
    "#     my_seed  =  wandb.config.my_seed\n",
    "\n",
    "\n",
    "#     TIME  =  wandb.config.TIME\n",
    "#     v_decay  =  wandb.config.v_decay\n",
    "#     v_threshold  =  wandb.config.v_threshold\n",
    "#     v_reset  =  wandb.config.v_reset\n",
    "#     BPTT_on  =  wandb.config.BPTT_on\n",
    "\n",
    "#     SAE_hidden_nomean  =  wandb.config.SAE_hidden_nomean\n",
    "    \n",
    "#     current_time =  datetime.datetime.now().strftime(\"%Y%m%d_%H%M%S\") + f\"_{str(int(datetime.datetime.now().microsecond / 1000)).zfill(3)}\"\n",
    "\n",
    "#     optimizer  =  wandb.config.optimizer\n",
    "\n",
    "#     coarse_com_mode = wandb.config.coarse_com_mode\n",
    "#     coarse_com_config = wandb.config.coarse_com_config # (max, min)\n",
    "\n",
    "#     sae_l2_norm_bridge = wandb.config.sae_l2_norm_bridge\n",
    "#     sae_lif_bridge = wandb.config.sae_lif_bridge\n",
    "\n",
    "#     accuracy_check_epoch_term = wandb.config.accuracy_check_epoch_term\n",
    "\n",
    "#     lif_add_at_last = wandb.config.lif_add_at_last\n",
    "\n",
    "#     two_channel_input = wandb.config.two_channel_input\n",
    "\n",
    "#     lateral_feature_num = wandb.config.lateral_feature_num\n",
    "\n",
    "#     lc_adc_on = wandb.config.lc_adc_on\n",
    "\n",
    "#     converted_net_forward = wandb.config.converted_net_forward\n",
    "\n",
    "#     pretrained_net = wandb.config.pretrained_net\n",
    "\n",
    "#     vth_mul_on = wandb.config.vth_mul_on\n",
    "#     batch_norm_on = wandb.config.batch_norm_on\n",
    "\n",
    "#     l2_norm_loss_weight = wandb.config.l2_norm_loss_weight\n",
    "\n",
    "#     QCFS_neuron_on = wandb.config.QCFS_neuron_on\n",
    "\n",
    "#     quantize_level_num = wandb.config.quantize_level_num\n",
    "\n",
    "#     fusion_net = wandb.config.fusion_net\n",
    "#     repeat_coding = wandb.config.repeat_coding\n",
    "\n",
    "#     sae_relu_on = wandb.config.sae_relu_on\n",
    "\n",
    "#     conv1d_scaling = wandb.config.conv1d_scaling\n",
    "\n",
    "#     norm01 = wandb.config.norm01\n",
    "\n",
    "#     cluster_train_system( \n",
    "#         gpu = gpu,\n",
    "#         Conv_net = Conv_net,\n",
    "#         SAE_net = SAE_net,\n",
    "\n",
    "#         # hyperparameter\n",
    "#         dataset_num = dataset_num,\n",
    "#         spike_length = spike_length,\n",
    "#         num_cluster = num_cluster,  # 클러스터 수 설정 # 논문엔 4개라는데 여기서는 3개로 했네\n",
    "#         training_cycle = training_cycle, # 그 초기 몇개까지만 cluster update할지\n",
    "\n",
    "\n",
    "#         batch_size = batch_size,\n",
    "#         max_epoch = max_epoch,\n",
    "#         learning_rate = learning_rate,\n",
    "#         normalize_on = normalize_on, # True or False #이거 안 씀 # 이거 별로 안 좋은 normalize같음 # 쓸 거면 다른 거 써라.\n",
    "#         need_bias = need_bias,\n",
    "#         # first_layer_no_train = False\n",
    "#         lif_add_at_first = lif_add_at_first,\n",
    "#         my_seed = my_seed,\n",
    "\n",
    "#         TIME = TIME, # SAE일 때만 유효\n",
    "#         v_decay = v_decay,\n",
    "#         v_threshold = v_threshold,\n",
    "#         v_reset = v_reset, # 10000이상 일 시 hard reset\n",
    "#         BPTT_on = BPTT_on,\n",
    "\n",
    "#         SAE_hidden_nomean = SAE_hidden_nomean,\n",
    "\n",
    "#         current_time = current_time,\n",
    "\n",
    "#         optimizer = optimizer, #'Adam', 'SGD'\n",
    "\n",
    "#         coarse_com_mode = coarse_com_mode,\n",
    "#         coarse_com_config = coarse_com_config, # (max, min)\n",
    "        \n",
    "#         sae_l2_norm_bridge = sae_l2_norm_bridge,\n",
    "#         sae_lif_bridge = sae_lif_bridge,\n",
    "\n",
    "#         accuracy_check_epoch_term = accuracy_check_epoch_term,\n",
    "\n",
    "#         lif_add_at_last = lif_add_at_last,\n",
    "        \n",
    "#         two_channel_input = two_channel_input,\n",
    "        \n",
    "#         lateral_feature_num = lateral_feature_num,\n",
    "\n",
    "#         lc_adc_on = lc_adc_on,\n",
    "\n",
    "#         converted_net_forward = converted_net_forward,\n",
    "\n",
    "#         pretrained_net = pretrained_net,\n",
    "\n",
    "#         vth_mul_on = vth_mul_on,\n",
    "#         batch_norm_on = batch_norm_on,\n",
    "\n",
    "#         l2_norm_loss_weight = l2_norm_loss_weight,\n",
    "\n",
    "#         QCFS_neuron_on = QCFS_neuron_on,\n",
    "\n",
    "#         quantize_level_num = quantize_level_num,\n",
    "\n",
    "#         fusion_net = fusion_net, \n",
    "#         repeat_coding = repeat_coding, \n",
    "\n",
    "#         sae_relu_on = sae_relu_on,\n",
    "\n",
    "#         conv1d_scaling = conv1d_scaling,\n",
    "\n",
    "#         norm01 = norm01,\n",
    "#         )\n",
    "    \n",
    "# # sweep_id = 'ygoj9jt4'\n",
    "# sweep_id = wandb.sweep(sweep=sweep_configuration, project=f'spike_sorting {unique_name_hyper}')\n",
    "# wandb.agent(sweep_id, function=hyper_iter, count=100000, project=f'spike_sorting {unique_name_hyper}')\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wandb.finish() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import matplotlib.pyplot as plt\n",
    "# from matplotlib.ticker import MaxNLocator\n",
    "# import pickle\n",
    "# import json\n",
    "\n",
    "# # current_time = '20250102_225243_972'\n",
    "\n",
    "# with open(f\"result_save/cluster_accuracy_history_{current_time}.pkl\", \"rb\") as f:\n",
    "#     data = pickle.load(f)\n",
    "\n",
    "\n",
    "# # JSON으로 저장\n",
    "# with open(f\"result_save/cluster_accuracy_history_{current_time}.json\", 'r') as f:\n",
    "#     loaded_hyperparameters = json.load(f)\n",
    "\n",
    "# loss_history = data['loss_history']\n",
    "# mean_cluster_accuracy_during_training_cycle_all_dataset_history = data['mean_cluster_accuracy_during_training_cycle_all_dataset_history']\n",
    "# mean_cluster_accuracy_post_training_cycle_all_dataset_history = data['mean_cluster_accuracy_post_training_cycle_all_dataset_history']\n",
    "# mean_cluster_accuracy_total_all_dataset_history = data['mean_cluster_accuracy_total_all_dataset_history']\n",
    "# print(data)\n",
    "# max_acc = 0\n",
    "# for i in mean_cluster_accuracy_post_training_cycle_all_dataset_history:\n",
    "#     if i[1] > max_acc:\n",
    "#         max_acc = i[1]\n",
    "\n",
    "# # 설정 정보 제목 작성\n",
    "# title = (\n",
    "#     f\"Dataset Num: {loaded_hyperparameters['dataset_num']}, Conv {loaded_hyperparameters['Conv_net']}, SAE {loaded_hyperparameters['SAE_net']}, Current time {loaded_hyperparameters['current_time']}, Spike Length: {loaded_hyperparameters['spike_length']}, Num Cluster: {loaded_hyperparameters['num_cluster']}, \"\n",
    "#     f\"Training Cycle: {loaded_hyperparameters['training_cycle']}, Batch Size: {loaded_hyperparameters['batch_size']}, Max Epoch: {loaded_hyperparameters['max_epoch']}, \\n\"\n",
    "#     f\"Learning Rate: {loaded_hyperparameters['learning_rate']}, Input Normalize: {loaded_hyperparameters['normalize_on']}, Need Bias: {loaded_hyperparameters['need_bias']}, \"\n",
    "#     f\"LIF Add at First: {loaded_hyperparameters['lif_add_at_first']}, TIME: {loaded_hyperparameters['TIME']}, Seed: {loaded_hyperparameters['my_seed']}, Best ACC: {max_acc:.2f}%\"\n",
    "# )\n",
    "\n",
    "# # 데이터 리스트와 라벨 설정 (Loss 제외)\n",
    "# data_list = [\n",
    "#     (\"Mean Cluster Accuracy (During Training Cycle)\", mean_cluster_accuracy_during_training_cycle_all_dataset_history),\n",
    "#     (\"Mean Cluster Accuracy (Post Training Cycle)\", mean_cluster_accuracy_post_training_cycle_all_dataset_history),\n",
    "#     (\"Mean Cluster Accuracy (Total)\", mean_cluster_accuracy_total_all_dataset_history),\n",
    "# ]\n",
    "\n",
    "# # 플롯 생성\n",
    "# fig, ax1 = plt.subplots(figsize=(12, 8))\n",
    "\n",
    "# # 첫 번째 y축: Accuracy 관련 데이터\n",
    "# for label, data in data_list:\n",
    "#     epochs, values = zip(*data)  # epoch, value 분리\n",
    "#     ax1.plot(epochs, values, label=label)\n",
    "\n",
    "# ax1.set_xlabel(\"Epoch\")\n",
    "# ax1.set_ylabel(\"Clurstering Accuracy [%]\", color=\"blue\")\n",
    "# ax1.tick_params(axis=\"y\", labelcolor=\"blue\")\n",
    "# ax1.legend(loc=\"center right\")\n",
    "# ax1.grid(True)\n",
    "\n",
    "# # x축을 정수만 표시하도록 설정\n",
    "# ax1.xaxis.set_major_locator(MaxNLocator(integer=True))\n",
    "\n",
    "# # 두 번째 y축: Loss History\n",
    "# ax2 = ax1.twinx()\n",
    "# epochs, values = zip(*loss_history)\n",
    "# ax2.plot(epochs, values, label=\"AE Loss History\", color=\"red\", linestyle=\"--\")\n",
    "# ax2.set_ylabel(\"Loss\", color=\"red\")\n",
    "# ax2.tick_params(axis=\"y\", labelcolor=\"red\")\n",
    "# ax2.legend(loc=\"center left\")\n",
    "\n",
    "# # 제목 추가\n",
    "# plt.title(title, fontsize=10)\n",
    "# plt.tight_layout()\n",
    "# plt.savefig(f'net_save/{current_time}', dpi=300, bbox_inches=\"tight\")  # dpi=300은 고해상도로 저장, bbox_inches=\"tight\"는 여백 최소화\n",
    "# plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# 데이터셋\n",
    "filename_for_plot = [\n",
    "    \"Easy1_noise05\", \"Easy1_noise10\", \"Easy1_noise15\", \"Easy1_noise20\",\n",
    "    \"Easy2_noise05\", \"Easy2_noise10\", \"Easy2_noise15\", \"Easy2_noise20\",\n",
    "    \"Difficult1_noise05\", \"Difficult1_noise10\", \"Difficult1_noise15\", \"Difficult1_noise20\",\n",
    "    \"Difficult2_noise05\", \"Difficult2_noise10\", \"Difficult2_noise15\", \"Difficult2_noise20\"\n",
    "]\n",
    "\n",
    "# Accuracy 데이터\n",
    "ANN_conv_accracy_set= [0.97935368, 0.97682709, 0.97028784, 0.96461825, 0.97524752, 0.95803571\n",
    ", 0.95746785, 0.92628774, 0.965412,  0.97805344, 0.94869403, 0.92110454\n",
    ", 0.96784232, 0.97551789, 0.91538462, 0.84446478]\n",
    "SNN_fc_accuracy_set = [0.97114475, 0.97643732, 0.84400578, 0.78977821, 0.96616915, 0.92830189\n",
    ", 0.86176032, 0.31984948, 0.80635401, 0.88769531, 0.61003861, 0.60377358\n",
    ", 0.9592668,  0.92870999, 0.78333333, 0.67271859]\n",
    "SNN_conv_accuracy_set = [0.97445601, 0.97737983, 0.97063072, 0.95998071, 0.96268657, 0.90566038\n",
    ", 0.82545997, 0.68391345, 0.96116994, 0.92138672, 0.80694981, 0.49602781\n",
    ", 0.83604888, 0.70611057, 0.69313725, 0.5819398 ]\n",
    "\n",
    "# 평균 계산\n",
    "average_ANN_conv = np.mean(ANN_conv_accracy_set)\n",
    "average_SNN_fc = np.mean(SNN_fc_accuracy_set)\n",
    "average_SNN_conv = np.mean(SNN_conv_accuracy_set)\n",
    "\n",
    "# 데이터 준비\n",
    "accuracies = np.array([ANN_conv_accracy_set, SNN_fc_accuracy_set, SNN_conv_accuracy_set])\n",
    "averages = np.array([average_ANN_conv, average_SNN_fc, average_SNN_conv])\n",
    "\n",
    "# 시각화\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "\n",
    "# 각 모델의 정확도 플롯\n",
    "ax.plot(accuracies[0], label='ANN Conv', marker='o', linestyle='-', color='blue')\n",
    "ax.plot(accuracies[1], label='SNN FC', marker='o', linestyle='-', color='green')\n",
    "ax.plot(accuracies[2], label='SNN Conv', marker='o', linestyle='-', color='red')\n",
    "\n",
    "# 평균값 플롯\n",
    "ax.axhline(y=average_ANN_conv, color='blue', linestyle='--', label=f'Average ANN Conv: {average_ANN_conv:.3f}')\n",
    "ax.axhline(y=average_SNN_fc, color='green', linestyle='--', label=f'Average SNN FC: {average_SNN_fc:.3f}')\n",
    "ax.axhline(y=average_SNN_conv, color='red', linestyle='--', label=f'Average SNN Conv: {average_SNN_conv:.3f}')\n",
    "\n",
    "# 레이블 추가\n",
    "ax.set_xticks(np.arange(len(filename_for_plot)))\n",
    "ax.set_xticklabels(filename_for_plot, rotation=45, ha='right')\n",
    "ax.set_ylabel('Accuracy')\n",
    "ax.set_title('Accuracy Comparison of Models on Datasets')\n",
    "ax.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import matplotlib.pyplot as plt\n",
    "import os  # 파일 경로 처리를 위한 모듈\n",
    "\n",
    "# CSV 파일 경로\n",
    "# csv_file_path = \"/home/bhkim003/github_folder/ByeonghyeonKim/my_snn/ae_test_deprecated/250115/sweep0_vth_mul.csv\" # vth_mul해서 sweep 돌린거\n",
    "csv_file_path = \"/home/bhkim003/github_folder/ByeonghyeonKim/my_snn/ae_test_deprecated/250115/sweep1.csv\"  #vth_mul안한거\n",
    "\n",
    "# 결과를 저장할 리스트\n",
    "tuple_list = []\n",
    "\n",
    "# CSV 파일 읽기\n",
    "with open(csv_file_path, 'r') as file:\n",
    "    reader = csv.DictReader(file)\n",
    "    for row in reader:\n",
    "        try:\n",
    "            # v_threshold, TIME, v_reset, converted_k_means_acc 값을 가져와 튜플로 변환\n",
    "            v_threshold = float(row[\"v_threshold\"])\n",
    "            time = int(row[\"TIME\"])\n",
    "            v_reset = int(row[\"v_reset\"])\n",
    "            converted_k_means_acc = float(row[\"converted_k_means_acc\"]) if row[\"converted_k_means_acc\"] else None\n",
    "\n",
    "            # 튜플 형태로 추가 (값이 None일 경우 처리할 수도 있음)\n",
    "            tuple_list.append((v_threshold, time, v_reset, converted_k_means_acc))\n",
    "        except ValueError as e:\n",
    "            print(f\"Error processing row {row}: {e}\")\n",
    "\n",
    "# 데이터를 TIME 기준으로 정렬\n",
    "tuple_list.sort(key=lambda x: x[1])  # TIME을 기준으로 오름차순 정렬\n",
    "\n",
    "# reset 방식에 따라 데이터를 나누기\n",
    "soft_reset = [t for t in tuple_list if t[2] == 0]\n",
    "hard_reset = [t for t in tuple_list if t[2] == 10000]\n",
    "\n",
    "# reset 방식과 v_threshold에 따라 색상 설정\n",
    "def plot_data(data, label_prefix, marker):\n",
    "    for v_threshold in [1.0]:  # v_threshold 기준으로 제한\n",
    "        filtered_data = [(t[1], t[3]) for t in data if t[0] == v_threshold]\n",
    "        if filtered_data:  # 해당 v_threshold 데이터가 있을 경우만 플롯\n",
    "            times, accuracies = zip(*filtered_data)  # x축(TIME), y축(converted_k_means_acc)\n",
    "            \n",
    "            plt.plot(\n",
    "                times,\n",
    "                accuracies,\n",
    "                marker,\n",
    "                label=f\"{label_prefix}, v_threshold={v_threshold}\",\n",
    "                linestyle=\"--\",\n",
    "            )\n",
    "            # 각 점에 accuracy 표시\n",
    "            for time, acc in filtered_data:\n",
    "                if acc == None:\n",
    "                    continue\n",
    "                plt.text(time, acc, f\"{acc:.2f}\", fontsize=8, ha=\"right\")\n",
    "\n",
    "# 그래프 초기화\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "# soft_reset (v_reset=0) 데이터 플롯\n",
    "plot_data(soft_reset, \"Soft Reset\", \"o\")\n",
    "\n",
    "# hard_reset (v_reset=10000) 데이터 플롯\n",
    "plot_data(hard_reset, \"Hard Reset\", \"x\")\n",
    "\n",
    "# baseline accuracy 가로선 추가\n",
    "baseline_accuracy = 94.43\n",
    "plt.axhline(y=baseline_accuracy, color=\"red\", linestyle=\"-\", label=f\"Baseline Accuracy ({baseline_accuracy}%)\")\n",
    "# baseline 텍스트 추가\n",
    "plt.text(\n",
    "    2000,  # x축 위치 (그래프 오른쪽 끝)\n",
    "    baseline_accuracy + 0.4,  # y축 위치 (baseline 위 약간)\n",
    "    f\"ANN Baseline ({baseline_accuracy}%)\",\n",
    "    color=\"red\",\n",
    "    fontsize=10,\n",
    "    ha=\"center\",\n",
    ")\n",
    "\n",
    "# CSV 파일 이름 가져오기\n",
    "csv_file_name = os.path.basename(csv_file_path)\n",
    "\n",
    "# 그래프 세부 설정\n",
    "plt.title(f\"Converted SNN K-Means Accuracy vs TIME STEP - {csv_file_name}\")\n",
    "plt.xlabel(\"TIME STEP\")\n",
    "plt.ylabel(\"Converted K-Means Accuracy [%]\")\n",
    "plt.legend(loc=\"lower right\")  # 범례를 오른쪽 아래로 이동\n",
    "plt.grid(True)\n",
    "\n",
    "# 그래프 출력\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aedat2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
