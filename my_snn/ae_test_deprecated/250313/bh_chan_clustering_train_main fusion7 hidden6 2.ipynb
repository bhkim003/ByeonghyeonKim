{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ssp.train.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x600 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import torch   \n",
    "import torch.nn as nn \n",
    "import torch.nn.functional as F   \n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import torch.optim as optim\n",
    "from scipy import io\n",
    "import itertools\n",
    "import math\n",
    "import datetime\n",
    "import wandb\n",
    "import pickle\n",
    "import json\n",
    "import time\n",
    "import sys\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import accuracy_score\n",
    "from scipy.optimize import linear_sum_assignment\n",
    "from snntorch import spikegen\n",
    "\n",
    "\n",
    "# my module import\n",
    "from modules import *\n",
    "\n",
    "# modules 폴더에 새모듈.py 만들면\n",
    "# modules/__init__py 파일에 form .새모듈 import * 하셈\n",
    "# 그리고 새모듈.py에서 from modules.새모듈 import * 하셈"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cluster_train_system( \n",
    "    gpu = '4',\n",
    "    Conv_net = True,\n",
    "    SAE_net = True,\n",
    "\n",
    "    # hyperparameter\n",
    "    dataset_num = 16,\n",
    "    spike_length = 50,\n",
    "    num_cluster = 4,  # 클러스터 수 설정 # 논문엔 4개라는데 여기서는 3개로 했네\n",
    "    training_cycle = 2400, # 그 초기 몇개까지만 cluster update할지\n",
    "\n",
    "\n",
    "    batch_size = 32,\n",
    "    max_epoch = 7000,\n",
    "    learning_rate = 0.001,\n",
    "    normalize_on = False, # True or False #이거 안 씀 # 이거 별로 안 좋은 normalize같음 # 쓸 거면 다른 거 써라.\n",
    "    need_bias = False,\n",
    "    # first_layer_no_train = False\n",
    "    lif_add_at_first = False,\n",
    "    my_seed = 42,\n",
    "\n",
    "    TIME = 10, # SAE일 때만 유효\n",
    "    v_decay = 0.5,\n",
    "    v_threshold = 0.5,\n",
    "    v_reset = 10000.0, # 10000이상 일 시 hard reset\n",
    "    BPTT_on = True,\n",
    "\n",
    "    SAE_hidden_nomean = True,\n",
    "    current_time = '20250101_210938_786',\n",
    "\n",
    "    optimizer = 'Adam',\n",
    "    coarse_com_mode = True,\n",
    "    coarse_com_config = (2.0, -2.0), # (max, min)\n",
    "\n",
    "    sae_l2_norm_bridge = True,\n",
    "    sae_lif_bridge = False,\n",
    "\n",
    "    accuracy_check_epoch_term = 5,\n",
    "    \n",
    "    lif_add_at_last = False,\n",
    "\n",
    "    two_channel_input = False,\n",
    "\n",
    "    lateral_feature_num = 4,\n",
    "\n",
    "    lc_adc_on = False, \n",
    "\n",
    "    converted_net_forward = False,\n",
    "\n",
    "    pretrained_net = None, \n",
    "\n",
    "    vth_mul_on = False,\n",
    "    batch_norm_on = False,\n",
    "\n",
    "    l2_norm_loss_weight = 0.0,\n",
    "\n",
    "    QCFS_neuron_on = False,\n",
    "\n",
    "    quantize_level_num = 0,\n",
    "\n",
    "    fusion_net = False, # True False\n",
    "    repeat_coding = False,\n",
    "    \n",
    "    sae_relu_on = False,\n",
    "\n",
    "    conv1d_scaling = False,\n",
    "\n",
    "    norm01 = True,\n",
    "    ):\n",
    "    if coarse_com_mode == True:\n",
    "        assert coarse_com_config[0] > coarse_com_config[1], 'coarse_com_config[0] > coarse_com_config[1]이어야 함'\n",
    "        assert converted_net_forward == False\n",
    "        # assert SAE_net == True, 'coarse_com_mode는 SAE_net이 True일 때만 가능'\n",
    "    if two_channel_input == True:\n",
    "        assert Conv_net and coarse_com_mode, 'two_channel_input는 Conv_net이 True일 때만 가능'\n",
    "    if lc_adc_on == True:\n",
    "        assert coarse_com_mode and SAE_net, 'lc_adc_on은 coarse_com_mode와 SAE_net이 True일 때만 가능'\n",
    "    if converted_net_forward == True:\n",
    "        assert SAE_net == False, 'converted_net_forward는 SAE_net이 False일 때만 가능'\n",
    "    if conv1d_scaling:\n",
    "        assert Conv_net and coarse_com_mode and normalize_on\n",
    "    seed_assign(my_seed)\n",
    "    ## 함수 내 모든 로컬 변수 저장 ########################################################\n",
    "    hyperparameters = locals()\n",
    "    print(hyperparameters)\n",
    "    # JSON으로 저장\n",
    "    with open(f\"result_save/cluster_accuracy_history_{current_time}.json\", 'w') as f:\n",
    "        json.dump(hyperparameters, f, indent=4)\n",
    "    ######################################################################################\n",
    "\n",
    "    \n",
    "    wandb.config.update(hyperparameters)\n",
    "    wandb.run.name = f'{current_time}_SAE_net_{SAE_net}_v_threshold_{v_threshold}'\n",
    "    wandb.define_metric(\"best_mean_cluster_accuracy_post_training_cycle_all_dataset2\", summary=\"max\")\n",
    "\n",
    "\n",
    "    my_path_ground_BH = '/data2/spike_sorting/quiroga/BH/'\n",
    "\n",
    "\n",
    "    filename = [\"C_Easy1_noise005.mat\", \"C_Easy1_noise01.mat\", \"C_Easy1_noise015.mat\", \"C_Easy1_noise02.mat\",\n",
    "                \"C_Easy2_noise005.mat\", \"C_Easy2_noise01.mat\", \"C_Easy2_noise015.mat\", \"C_Easy2_noise02.mat\",\n",
    "                \"C_Difficult1_noise005.mat\", \"C_Difficult1_noise01.mat\", \"C_Difficult1_noise015.mat\", \"C_Difficult1_noise02.mat\",\n",
    "                \"C_Difficult2_noise005.mat\", \"C_Difficult2_noise01.mat\", \"C_Difficult2_noise015.mat\", \"C_Difficult2_noise02.mat\"]\n",
    "\n",
    "\n",
    "    spike_tot = [\"BH_Spike_e1n005.npy\", \"BH_Spike_e1n010.npy\", \"BH_Spike_e1n015.npy\", \"BH_Spike_e1n020.npy\",\n",
    "                \"BH_Spike_e2n005.npy\", \"BH_Spike_e2n010.npy\", \"BH_Spike_e2n015.npy\", \"BH_Spike_e2n020.npy\",\n",
    "                \"BH_Spike_d1n005.npy\", \"BH_Spike_d1n010.npy\", \"BH_Spike_d1n015.npy\", \"BH_Spike_d1n020.npy\",\n",
    "                \"BH_Spike_d2n005.npy\", \"BH_Spike_d2n010.npy\", \"BH_Spike_d2n015.npy\", \"BH_Spike_d2n020.npy\"]\n",
    "\n",
    "    label_tot = [\"BH_Label_e1n005.npy\", \"BH_Label_e1n010.npy\", \"BH_Label_e1n015.npy\", \"BH_Label_e1n020.npy\",\n",
    "                \"BH_Label_e2n005.npy\", \"BH_Label_e2n010.npy\", \"BH_Label_e2n015.npy\", \"BH_Label_e2n020.npy\",\n",
    "                \"BH_Label_d1n005.npy\", \"BH_Label_d1n010.npy\", \"BH_Label_d1n015.npy\", \"BH_Label_d1n020.npy\",\n",
    "                \"BH_Label_d2n005.npy\", \"BH_Label_d2n010.npy\", \"BH_Label_d2n015.npy\", \"BH_Label_d2n020.npy\"]\n",
    "\n",
    "    template =  [\"BH_Spike_TEMPLATE_e1n005.npy\", \"BH_Spike_TEMPLATE_e1n010.npy\", \"BH_Spike_TEMPLATE_e1n015.npy\", \"BH_Spike_TEMPLATE_e1n020.npy\",\n",
    "                \"BH_Spike_TEMPLATE_e2n005.npy\", \"BH_Spike_TEMPLATE_e2n010.npy\", \"BH_Spike_TEMPLATE_e2n015.npy\", \"BH_Spike_TEMPLATE_e2n020.npy\",\n",
    "                \"BH_Spike_TEMPLATE_d1n005.npy\", \"BH_Spike_TEMPLATE_d1n010.npy\", \"BH_Spike_TEMPLATE_d1n015.npy\", \"BH_Spike_TEMPLATE_d1n020.npy\",\n",
    "                \"BH_Spike_TEMPLATE_d2n005.npy\", \"BH_Spike_TEMPLATE_d2n010.npy\", \"BH_Spike_TEMPLATE_d2n015.npy\", \"BH_Spike_TEMPLATE_d2n020.npy\"]\n",
    "\n",
    "    AE_train_path_gt_detect = 'BH_quiroga_training_dataset_gt_detect.pt' \n",
    "    AE_test_path_gt_detect = 'BH_quiroga_test_dataset_gt_detect.pt'\n",
    "\n",
    "    AE_train_path_real_detect = 'BH_quiroga_training_dataset_real_detect.pt'\n",
    "    AE_test_path_real_detect = 'BH_quiroga_test_dataset_real_detect.pt'\n",
    "\n",
    "    AE_train_data = AE_train_path_real_detect #AE_train_path_gt_detect #AE_train_path_real_detect\n",
    "    AE_test_data = AE_test_path_real_detect #AE_test_path_gt_detect  #AE_test_path_real_detect\n",
    "\n",
    "    # thr_tot = np.array([0.5, 0.5, 0.55, 0.7, 0.5, 0.5, 0.55, 0.7, 0.5, 0.5, 0.55, 0.7, 0.5, 0.5, 0.55, 0.7])\n",
    "    cos_thr = np.array([0.95, 0.95, 0.95, 0.95, 0.95, 0.95, 0.95, 0.85, 0.95, 0.9, 0.8, 0.95, 0.95, 0.95, 0.95, 0.8])\n",
    "    # tem=10\n",
    "    # cos_thr = np.array([tem, tem, tem, tem, tem, tem, tem, tem, tem, tem, tem, tem, tem, tem, tem, tem, ])\n",
    "\n",
    "    print('cos_thr', cos_thr)\n",
    "    \n",
    "    os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\" \n",
    "    os.environ[\"CUDA_VISIBLE_DEVICES\"]= gpu\n",
    "\n",
    "\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "\n",
    "    if coarse_com_mode == True:\n",
    "        level_num = TIME\n",
    "        TIME = spike_length\n",
    "        spike_length = level_num\n",
    "        level_interval = (coarse_com_config[0] - coarse_com_config[1]) / (level_num-1)  # max - min\n",
    "        levels = [coarse_com_config[1] + level_interval * i for i in range(level_num)]\n",
    "        levels = torch.tensor(levels).to(torch.float).to(device)\n",
    "        levels = levels.repeat(TIME,1) \n",
    "        # print('levels', levels, levels.shape) # TIME, level_num\n",
    "\n",
    "    n_sample = spike_length\n",
    "\n",
    "    class spikedataset(Dataset):\n",
    "        def __init__(self, path, transform = None):    \n",
    "            self.transform = transform\n",
    "            self.spike = torch.load(path)\n",
    "            \n",
    "        def __getitem__(self, index):\n",
    "            spike = self.spike[index]            \n",
    "            if self.transform is not None:\n",
    "                spike = self.transform(spike)\n",
    "            return spike\n",
    "        \n",
    "        def __len__(self):\n",
    "            return len(self.spike)\n",
    "\n",
    "    train_dataset = spikedataset(my_path_ground_BH + AE_train_data)\n",
    "    train_loader = DataLoader(dataset = train_dataset, batch_size = batch_size, shuffle = True)\n",
    "\n",
    "    test_dataset = spikedataset(my_path_ground_BH + AE_test_data)\n",
    "    test_loader = DataLoader(dataset = test_dataset, batch_size = batch_size, shuffle = False)\n",
    "\n",
    "\n",
    "    # vth_mul_on = True # True False\n",
    "    # batch_norm_on = True # True False\n",
    "\n",
    "\n",
    "    # 모델 초기화\n",
    "    if SAE_net == False: # 여기서는 l2norm, lif bridge 둘 다 true면 l2norm먼저\n",
    "        assert two_channel_input == False\n",
    "\n",
    "        if Conv_net == True:\n",
    "            # input_channels = 2 if two_channel_input else 1\n",
    "            input_channels = TIME if coarse_com_mode else 1\n",
    "            if fusion_net == True:\n",
    "                assert False, '이거 맞음? 다시 확인'\n",
    "                net = FUSION_net_conv1(input_channels=input_channels, input_length=n_sample, encoder_ch = [32, 64, 96], fc_dim = lateral_feature_num, padding = 0, stride = 2, kernel_size = 3, \n",
    "                                    synapse_fc_trace_const1=1, \n",
    "                                    synapse_fc_trace_const2=v_decay, #안씀 \n",
    "                                    TIME=TIME, v_init=0.0, v_decay=v_decay, v_threshold=v_threshold, v_reset=v_reset, \n",
    "                                    sg_width=4.0, surrogate='sigmoid', BPTT_on=BPTT_on, need_bias=need_bias, lif_add_at_first=lif_add_at_first,\n",
    "                                    sae_l2_norm_bridge = sae_l2_norm_bridge, sae_lif_bridge = sae_lif_bridge, lif_add_at_last=lif_add_at_last, repeat_coding=repeat_coding).to(device)\n",
    "            else: \n",
    "                net = Autoencoder_conv1(input_channels=input_channels, input_length=n_sample, encoder_ch = [32, 64, 96], fc_dim = lateral_feature_num, padding = 0, stride = 2, kernel_size = 3, need_bias=need_bias, l2norm_bridge=sae_l2_norm_bridge, relu_bridge=sae_lif_bridge, activation_collector_on=False,\n",
    "                                        batch_norm_on=batch_norm_on, QCFS_neuron_on=QCFS_neuron_on).to(device)\n",
    "            net = torch.nn.DataParallel(net)\n",
    "            if converted_net_forward:\n",
    "                converted_net = SAE_converted_conv1(input_channels=input_channels, input_length=n_sample, encoder_ch = [32, 64, 96], fc_dim = lateral_feature_num, padding = 0, stride = 2, kernel_size = 3, \n",
    "                                    synapse_fc_trace_const1=1, \n",
    "                                    synapse_fc_trace_const2=v_decay, #안씀 \n",
    "                                    TIME=TIME, v_init=0.0, v_decay=v_decay, v_threshold=v_threshold, v_reset=v_reset, \n",
    "                                    sg_width=4.0, surrogate='sigmoid', BPTT_on=BPTT_on, need_bias=need_bias, lif_add_at_first=lif_add_at_first,\n",
    "                                    sae_l2_norm_bridge = sae_l2_norm_bridge, sae_lif_bridge = sae_lif_bridge, lif_add_at_last=lif_add_at_last,\n",
    "                                    vth_mul_on=vth_mul_on, batch_norm_on=batch_norm_on).to(device) # lif bridge는 무조건 들어가게 해놨음.\n",
    "                converted_net = torch.nn.DataParallel(converted_net)\n",
    "                print('converted_net', converted_net)\n",
    "        else:\n",
    "            n_sample = n_sample * TIME if coarse_com_mode else n_sample\n",
    "            net = Autoencoder_only_FC(encoder_ch=[400, lateral_feature_num], decoder_ch=[400,n_sample], n_sample=n_sample, need_bias=need_bias, l2norm_bridge=sae_l2_norm_bridge, relu_bridge=sae_lif_bridge, activation_collector_on=False,\n",
    "                                    batch_norm_on=batch_norm_on, QCFS_neuron_on=QCFS_neuron_on).to(device)\n",
    "            net = torch.nn.DataParallel(net)\n",
    "            if converted_net_forward:\n",
    "                converted_net = SAE_converted_fc(encoder_ch=[400, lateral_feature_num], \n",
    "                                    decoder_ch=[400, n_sample], \n",
    "                                    in_channels=n_sample, # in_channel 이 여기선 걍 lenght.\n",
    "                                    synapse_fc_trace_const1=1,\n",
    "                                    synapse_fc_trace_const2=v_decay,  #안씀 \n",
    "                                    TIME=TIME, v_init=0.0, v_decay=v_decay, v_threshold=v_threshold, v_reset=v_reset, \n",
    "                                    sg_width=4.0, surrogate='sigmoid', BPTT_on=BPTT_on, need_bias=need_bias, lif_add_at_first=lif_add_at_first,\n",
    "                                    sae_l2_norm_bridge = sae_l2_norm_bridge, sae_lif_bridge = sae_lif_bridge, lif_add_at_last=lif_add_at_last,\n",
    "                                    vth_mul_on=vth_mul_on, batch_norm_on=batch_norm_on).to(device) # lif bridge는 무조건 들어가게 해놨음.\n",
    "                converted_net = torch.nn.DataParallel(converted_net)\n",
    "                # print('converted_net', converted_net)\n",
    "    else:\n",
    "        if Conv_net == True: \n",
    "            input_channels = 1\n",
    "            input_channels = 2 if two_channel_input else 1\n",
    "            if fusion_net == True:  \n",
    "                assert coarse_com_mode == True\n",
    "                # net = SAE_FUSION2_net_conv1(input_channels=input_channels, input_length=n_sample, encoder_ch = [32, 64, 96], fc_dim = lateral_feature_num, padding = 0, stride = 2, kernel_size = 3, \n",
    "                #                     synapse_fc_trace_const1=1, \n",
    "                #                     synapse_fc_trace_const2=v_decay, #안씀 \n",
    "                #                     TIME=TIME, v_init=0.0, v_decay=v_decay, v_threshold=v_threshold, v_reset=v_reset, \n",
    "                #                     sg_width=4.0, surrogate='sigmoid', BPTT_on=BPTT_on, need_bias=need_bias, lif_add_at_first=lif_add_at_first,\n",
    "                #                     sae_l2_norm_bridge = sae_l2_norm_bridge, sae_lif_bridge = sae_lif_bridge, lif_add_at_last=lif_add_at_last, batch_norm_on=batch_norm_on, sae_relu_on=sae_relu_on).to(device)\n",
    "                # net = SAE_FUSION3_net_conv1(input_channels=input_channels, input_length=n_sample, encoder_ch = [32, 64, 96], fc_dim = lateral_feature_num, padding = 0, stride = 2, kernel_size = 3, \n",
    "                #                     synapse_fc_trace_const1=1, \n",
    "                #                     synapse_fc_trace_const2=v_decay, #안씀 \n",
    "                #                     TIME=TIME, v_init=0.0, v_decay=v_decay, v_threshold=v_threshold, v_reset=v_reset, \n",
    "                #                     sg_width=4.0, surrogate='sigmoid', BPTT_on=BPTT_on, need_bias=need_bias, lif_add_at_first=lif_add_at_first,\n",
    "                #                     sae_l2_norm_bridge = sae_l2_norm_bridge, sae_lif_bridge = sae_lif_bridge, lif_add_at_last=lif_add_at_last, batch_norm_on=batch_norm_on, sae_relu_on=sae_relu_on).to(device)\n",
    "                # net = SAE_FUSION4_net_conv1(input_channels=input_channels, input_length=n_sample, encoder_ch = [32, 64, 96], fc_dim = lateral_feature_num, padding = 0, stride = 2, kernel_size = 3, \n",
    "                #                     synapse_fc_trace_const1=1, \n",
    "                #                     synapse_fc_trace_const2=v_decay, #안씀 \n",
    "                #                     TIME=TIME, v_init=0.0, v_decay=v_decay, v_threshold=v_threshold, v_reset=v_reset, \n",
    "                #                     sg_width=4.0, surrogate='sigmoid', BPTT_on=BPTT_on, need_bias=need_bias, lif_add_at_first=lif_add_at_first,\n",
    "                #                     sae_l2_norm_bridge = sae_l2_norm_bridge, sae_lif_bridge = sae_lif_bridge, lif_add_at_last=lif_add_at_last, batch_norm_on=batch_norm_on, sae_relu_on=sae_relu_on).to(device)\n",
    "                # net = SAE_FUSION5_net_conv1(input_channels=input_channels, input_length=n_sample, encoder_ch = [32, 64, 96], fc_dim = lateral_feature_num, padding = 0, stride = 2, kernel_size = 3, \n",
    "                #                     synapse_fc_trace_const1=1, \n",
    "                #                     synapse_fc_trace_const2=v_decay, #안씀 \n",
    "                #                     TIME=TIME, v_init=0.0, v_decay=v_decay, v_threshold=v_threshold, v_reset=v_reset, \n",
    "                #                     sg_width=4.0, surrogate='sigmoid', BPTT_on=BPTT_on, need_bias=need_bias, lif_add_at_first=lif_add_at_first,\n",
    "                #                     sae_l2_norm_bridge = sae_l2_norm_bridge, sae_lif_bridge = sae_lif_bridge, lif_add_at_last=lif_add_at_last, batch_norm_on=batch_norm_on, sae_relu_on=sae_relu_on).to(device)\n",
    "                # net = SAE_FUSION6_net_conv1(input_channels=input_channels, input_length=n_sample, encoder_ch = [32, 64, 96], fc_dim = lateral_feature_num, padding = 0, stride = 2, kernel_size = 3, \n",
    "                #                     synapse_fc_trace_const1=1, \n",
    "                #                     synapse_fc_trace_const2=v_decay, #안씀 \n",
    "                #                     TIME=TIME, v_init=0.0, v_decay=v_decay, v_threshold=v_threshold, v_reset=v_reset, \n",
    "                #                     sg_width=4.0, surrogate='sigmoid', BPTT_on=BPTT_on, need_bias=need_bias, lif_add_at_first=lif_add_at_first,\n",
    "                #                     sae_l2_norm_bridge = sae_l2_norm_bridge, sae_lif_bridge = sae_lif_bridge, lif_add_at_last=lif_add_at_last, batch_norm_on=batch_norm_on, sae_relu_on=sae_relu_on).to(device)\n",
    "                net = SAE_FUSION7_net_conv1(input_channels=input_channels, input_length=n_sample, encoder_ch = [32, 64, 96], fc_dim = lateral_feature_num, padding = 0, stride = 2, kernel_size = 3, \n",
    "                                    synapse_fc_trace_const1=1, \n",
    "                                    synapse_fc_trace_const2=v_decay, #안씀 \n",
    "                                    TIME=TIME, v_init=0.0, v_decay=v_decay, v_threshold=v_threshold, v_reset=v_reset, \n",
    "                                    sg_width=4.0, surrogate='sigmoid', BPTT_on=BPTT_on, need_bias=need_bias, lif_add_at_first=lif_add_at_first,\n",
    "                                    sae_l2_norm_bridge = sae_l2_norm_bridge, sae_lif_bridge = sae_lif_bridge, lif_add_at_last=lif_add_at_last, batch_norm_on=batch_norm_on, sae_relu_on=sae_relu_on).to(device)\n",
    "            else:\n",
    "                net = SAE_conv1(input_channels=input_channels, input_length=n_sample, encoder_ch = [32, 64, 96], fc_dim = lateral_feature_num, padding = 0, stride = 2, kernel_size = 3, \n",
    "                                    synapse_fc_trace_const1=1, \n",
    "                                    synapse_fc_trace_const2=v_decay, #안씀 \n",
    "                                    TIME=TIME, v_init=0.0, v_decay=v_decay, v_threshold=v_threshold, v_reset=v_reset, \n",
    "                                    sg_width=4.0, surrogate='sigmoid', BPTT_on=BPTT_on, need_bias=need_bias, lif_add_at_first=lif_add_at_first,\n",
    "                                    sae_l2_norm_bridge = sae_l2_norm_bridge, sae_lif_bridge = sae_lif_bridge, lif_add_at_last=lif_add_at_last, batch_norm_on=batch_norm_on, sae_relu_on=sae_relu_on).to(device)\n",
    "            # net = SAE_conv1_DR(input_channels=input_channels, input_length=n_sample, encoder_ch = [32, 64, 96], fc_dim = lateral_feature_num, padding = 0, stride = 2, kernel_size = 3, \n",
    "            #                     synapse_fc_trace_const1=1, \n",
    "            #                     synapse_fc_trace_const2=v_decay, #안씀 \n",
    "            #                     TIME=TIME, v_init=0.0, v_decay=v_decay, v_threshold=v_threshold, v_reset=v_reset, \n",
    "            #                     sg_width=4.0, surrogate='sigmoid', BPTT_on=BPTT_on, need_bias=need_bias, lif_add_at_first=lif_add_at_first,\n",
    "            #                     sae_l2_norm_bridge = sae_l2_norm_bridge, sae_lif_bridge = sae_lif_bridge, lif_add_at_last=lif_add_at_last, batch_norm_on=batch_norm_on).to(device)\n",
    "            net = torch.nn.DataParallel(net)\n",
    "        else:\n",
    "            net = SAE_fc_only(encoder_ch=[400, lateral_feature_num], \n",
    "                                decoder_ch=[400, n_sample], \n",
    "                                in_channels=n_sample, # in_channel 이 여기선 걍 lenght.\n",
    "                                synapse_fc_trace_const1=1,\n",
    "                                synapse_fc_trace_const2=v_decay,  #안씀 \n",
    "                                TIME=TIME, v_init=0.0, v_decay=v_decay, v_threshold=v_threshold, v_reset=v_reset, \n",
    "                                sg_width=4.0, surrogate='sigmoid', BPTT_on=BPTT_on, need_bias=need_bias, lif_add_at_first=lif_add_at_first,\n",
    "                                sae_l2_norm_bridge = sae_l2_norm_bridge, sae_lif_bridge = sae_lif_bridge, lif_add_at_last=lif_add_at_last, batch_norm_on=batch_norm_on, sae_relu_on=sae_relu_on).to(device)\n",
    "            net = torch.nn.DataParallel(net)\n",
    "\n",
    "    # net = torch.load('/home/bhkim003/github_folder/ByeonghyeonKim/my_snn/net_save/save_now_net_AE_re_e7000.pth')\n",
    "    # net = torch.load('/home/bhkim003/github_folder/ByeonghyeonKim/my_snn/net_save/save_now_net_20250101_210938_786.pth')\n",
    "    # load했으면 torch.nn.DataParallel 하지마\n",
    "    # net.module.load_state_dict(torch.load('/home/bhkim003/github_folder/ByeonghyeonKim/my_snn/net_save/save_now_net_annbase_20250108_210641_941.pth'))\n",
    "    if pretrained_net != None:\n",
    "        ######################## 모델이 달라서 dict로 weight만 넣고싶을 때\n",
    "        # # 저장된 가중치 로드\n",
    "        saved_state_dict = torch.load(pretrained_net)\n",
    "        current_state_dict = net.module.state_dict()\n",
    "\n",
    "        # 함수 호출로 가중치 매핑\n",
    "        updated_state_dict = map_and_load_weights(saved_state_dict, current_state_dict)\n",
    "\n",
    "        # 업데이트된 state_dict를 네트워크에 로드\n",
    "        net.module.load_state_dict(updated_state_dict)\n",
    "        ######################## 모델이 달라서 dict로 weight만 넣고싶을 때\n",
    "\n",
    "        ############## 일반적일 때\n",
    "        # net.module.load_state_dict(torch.load(pretrained_net))\n",
    "        ############## 일반적일 때\n",
    "    \n",
    "        # pre_net = Autoencoder_conv1(input_channels=input_channels, input_length=n_sample, encoder_ch = [32, 64, 96], fc_dim = lateral_feature_num, padding = 0, stride = 2, kernel_size = 3, need_bias=need_bias, l2norm_bridge=sae_l2_norm_bridge, relu_bridge=sae_lif_bridge, activation_collector_on=False,\n",
    "        #                         batch_norm_on=batch_norm_on, QCFS_neuron_on=False).to(device)\n",
    "        # pre_net = torch.nn.DataParallel(net)\n",
    "        # pre_net.module.load_state_dict(torch.load(pretrained_net))\n",
    "        # copy_weights(pre_net.module.encoder , net.module.encoder )\n",
    "        # copy_weights(pre_net.module.decoder , net.module.decoder  )\n",
    "\n",
    "        \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    wandb.watch(net, log=\"all\", log_freq = 10)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    if SAE_net == True:\n",
    "        assert 'SAE' in net.module.__class__.__name__\n",
    "\n",
    "\n",
    "\n",
    "    net = net.to(device)\n",
    "    print(f\"Total number of encoder parameters: {sum(p.numel() for p in net.module.encoder.parameters())}\")\n",
    "    print(net)\n",
    "    print('Device:',device)\n",
    "\n",
    "    \n",
    "    if optimizer == 'Adam':\n",
    "        optimizer = optim.Adam(net.parameters(), lr=learning_rate)\n",
    "    elif optimizer == 'SGD':\n",
    "        optimizer = optim.SGD(net.parameters(), lr = learning_rate, momentum = 0.9)\n",
    "    else:\n",
    "        assert False, 'optimizer를 잘못 입력했습니다.'\n",
    "        \n",
    "    loss_history = []\n",
    "    mean_cluster_accuracy_during_training_cycle_all_dataset_history = []\n",
    "    mean_cluster_accuracy_post_training_cycle_all_dataset_history = []\n",
    "    mean_cluster_accuracy_total_all_dataset_history = []\n",
    "\n",
    "    tau = np.zeros(num_cluster)\n",
    "\n",
    "    print(f\"\\nStart Training, current_time = {current_time}\")\n",
    "    mean_cluster_accuracy_post_training_cycle_all_dataset = 0\n",
    "    best_mean_cluster_accuracy_post_training_cycle_all_dataset = 0\n",
    "\n",
    "    if SAE_net == True:\n",
    "        assert 'SAE' in net.module.__class__.__name__\n",
    "        \n",
    "    k_means_acc_best = 0\n",
    "    min_loss = 9999999\n",
    "    min_loss_normal = 9999999\n",
    "    min_loss_coarse = 9999999\n",
    "    for epoch in range(max_epoch):\n",
    "        print()\n",
    "        l2_loss_bin= 0\n",
    "        ae_train_start_time = time.time()\n",
    "        running_loss = 0.0\n",
    "        running_loss_normal = 0.0\n",
    "        running_loss_coarse = 0.0\n",
    "        iter = 0\n",
    "        net.train()\n",
    "        # if True or max_epoch != 1:\n",
    "        wrong_element_sum = 0\n",
    "        same_data_num = 0\n",
    "        total_data_num = 0\n",
    "        if max_epoch != 1:\n",
    "            for data in train_loader:\n",
    "                optimizer.zero_grad()\n",
    "                total_data_num += len(data)\n",
    "                data = data.to(device)\n",
    "                scaling = (level_num-3)/level_num if conv1d_scaling else 1.0\n",
    "                data = zero_to_one_normalize_features(data, level_num=quantize_level_num, coarse_com_config=coarse_com_config, scaling=scaling, norm01=norm01) if normalize_on else data\n",
    "                # plot_origin_spike(data[0].cpu().detach().numpy(), min_max_y_on = True)\n",
    "                # plot_origin_spike(data[1].cpu().detach().numpy(), min_max_y_on = True)\n",
    "                spike_backup = data\n",
    "                spike = data\n",
    "                spike = spike.to(device) # batch, feature\n",
    "                spike_for_fusion2_net = spike\n",
    "                if coarse_com_mode == True and 'SAE' in net.module.__class__.__name__:\n",
    "                    # print(spike[0])\n",
    "                    spike = spike.unsqueeze(2).repeat(1, 1, level_num) # spike_length == level_num # (batch, time, feature)로 변환 \n",
    "                    spike = (spike > levels).to(torch.float) \n",
    "\n",
    "                    spike = (spike == 0).cumsum(dim=-1).eq(1).to(torch.float) if lc_adc_on == True else spike\n",
    "\n",
    "                    # spike: batch, time, level_num\n",
    "                    # levels: time, level_num\n",
    "                    if Conv_net == True:\n",
    "                        spike = spike.unsqueeze(-2) # batch, time, in_channel, feature or batch in_channel,feature\n",
    "                        if two_channel_input == True:\n",
    "                            spike_backup = spike_backup.to(device)\n",
    "                            spike_backup = spike_backup.unsqueeze(2).repeat(1, 1, level_num) # spike_length == level_num # (batch, time, feature)로 변환 \n",
    "                            spike_backup = (spike_backup <= levels).to(torch.float) \n",
    "                            spike_backup = (spike_backup == 1).cumsum(dim=-1).eq(1).to(torch.float) if lc_adc_on == True else spike_backup\n",
    "                            spike_backup = spike_backup.unsqueeze(-2)\n",
    "                            spike = torch.cat((spike, spike_backup), dim=-2)\n",
    "                    assert spike.shape[0] == batch_size and spike.shape[1] == TIME\n",
    "                elif 'SAE' in net.module.__class__.__name__:\n",
    "                    spike = spike.unsqueeze(-1).repeat(1, 1, TIME).permute(0,2,1) # (batch, time, feature)로 변환\n",
    "                    if Conv_net == True:\n",
    "                        spike = spike.unsqueeze(-2) # batch, time, in_channel, feature or batch in_channel,feature\n",
    "                else:\n",
    "                    if Conv_net == True:\n",
    "                        if coarse_com_mode == False:\n",
    "                            spike = spike.unsqueeze(-2) #batch in_channel,feature\n",
    "                        else:\n",
    "                            spike = spike.unsqueeze(2).repeat(1, 1, level_num) # spike_length == level_num # (batch, time, feature)로 변환 \n",
    "                            spike = (spike > levels).to(torch.float) \n",
    "\n",
    "                            spike = (spike == 0).cumsum(dim=-1).eq(1).to(torch.float) if lc_adc_on == True else spike\n",
    "\n",
    "                    else:\n",
    "                        if coarse_com_mode == False:\n",
    "                            pass\n",
    "                        else:\n",
    "                            spike = spike.unsqueeze(2).repeat(1, 1, level_num) # spike_length == level_num # (batch, time, feature)로 변환 \n",
    "                            spike = (spike > levels).to(torch.float) \n",
    "\n",
    "                            spike = (spike == 0).cumsum(dim=-1).eq(1).to(torch.float) if lc_adc_on == True else spike\n",
    "\n",
    "                            # spike: batch, time, feature\n",
    "                            spike = spike.reshape(spike.shape[0], -1)\n",
    "\n",
    "                    \n",
    "\n",
    "\n",
    "                    # if fusion_net == True:\n",
    "                    #     spike = spikegen.rate(spike, num_steps=TIME).transpose(0, 1)\n",
    "\n",
    "                # spike_class = net(spike) # batch, time, feature\n",
    "                encoded_spike = net.module.encoder(spike)\n",
    "                spike_class = net.module.decoder(encoded_spike)\n",
    "\n",
    "                # for i in range (2):\n",
    "                #     plot_spike(spike[i,:,0,:].cpu().numpy())\n",
    "                #     # plot_spike(spike[i,:,1,:].cpu().numpy())\n",
    "                #     plot_origin_spike(spike_class.squeeze()[i].cpu().detach().numpy(), min_max_y_on = True)\n",
    "                # assert False\n",
    "                        \n",
    "\n",
    "                loss = 0\n",
    "                loss_normal = torch.tensor(0.0)\n",
    "                loss_coarse = torch.tensor(0.0)\n",
    "                if coarse_com_mode == True and 'SAE' in net.module.__class__.__name__:\n",
    "                    criterion = nn.MSELoss().to(device)\n",
    "                    # loss1 = nn.MSELoss()(spike_class[..., 5:25], spike[..., 5:25])\n",
    "                    # loss2 = nn.MSELoss()(spike_class[..., 0:5], spike[..., 0:5])\n",
    "                    # loss3 = nn.MSELoss()(spike_class[..., 25:spike_length], spike[..., 25:spike_length])\n",
    "                    # loss = loss1 * 2.125 + (loss2 + loss3)/4\n",
    "\n",
    "                    # loss1 = nn.MSELoss()(spike_class[..., 5:25, :], spike[..., 5:25, :])\n",
    "                    # loss2 = nn.MSELoss()(spike_class[..., 0:5, :], spike[..., 0:5, :])\n",
    "                    # loss3 = nn.MSELoss()(spike_class[..., 25:spike_length, :], spike[..., 25:spike_length, :])\n",
    "                    # loss = loss1 * 2.125 + (loss2 + loss3)/4\n",
    "                    if fusion_net:\n",
    "                        # print('1', spike.shape) # batch, time, in_channel, feature [32, 50, 1, 50]\n",
    "                        \n",
    "                        # ### coarse에서 ann loss 만들기 ######\n",
    "                        # spike = spike.squeeze()\n",
    "                        # assert two_channel_input == False\n",
    "                        # zero_mask = (spike == 0)  # 0이 있는 위치\n",
    "                        # first_zero_idx = torch.where(zero_mask, torch.arange(spike.shape[-1]).to(device), spike.shape[-1]-1).min(dim=-1).values\n",
    "                        # spike = levels[0][first_zero_idx]\n",
    "                        # # plot_origin_spike(spike[0].cpu().detach().numpy())\n",
    "                        # ### coarse에서 ann loss 만들기 ######\n",
    "\n",
    "                        ### 그냥 원래 스파이크로 ann loss 만들기 ######\n",
    "                        spike = spike_for_fusion2_net\n",
    "                        ### 그냥 원래 스파이크로 ann loss 만들기 ######\n",
    "\n",
    "                        spike = spike.squeeze()\n",
    "                        spike_class = spike_class.squeeze()\n",
    "                        \n",
    "                        ### normal loss################\n",
    "                        # loss = criterion(spike_class, spike)\n",
    "                        ### normal loss################\n",
    "                        \n",
    "                        ### chan loss################\n",
    "                        loss1 = criterion(spike_class[..., 5:25], spike[..., 5:25])\n",
    "                        loss2 = criterion(spike_class[..., 0:5], spike[..., 0:5])\n",
    "                        loss3 = criterion(spike_class[..., 25:], spike[..., 25:])\n",
    "                        loss = loss1 * 2.125 + (loss2 + loss3)/4\n",
    "                        ### chan loss################\n",
    "\n",
    "\n",
    "                        # #########################################\n",
    "                        # # 손실 함수 정의 (예: MSELoss 사용)\n",
    "                        # criterion_joke = torch.nn.MSELoss(reduction='none')  # 개별 요소별 손실을 유지\n",
    "\n",
    "                        # # 손실 계산\n",
    "                        # loss1_joke = criterion_joke(spike_class[..., 5:25], spike[..., 5:25]).mean(dim=-1)  # (batch,)\n",
    "                        # loss2_joke = criterion_joke(spike_class[..., 0:5], spike[..., 0:5]).mean(dim=-1)    # (batch,)\n",
    "                        # loss3_joke = criterion_joke(spike_class[..., 25:], spike[..., 25:]).mean(dim=-1)    # (batch,)\n",
    "\n",
    "                        # # 주어진 가중치를 적용한 최종 손실\n",
    "                        # loss_joke = loss1_joke * 2.125 + (loss2_joke + loss3_joke) / 4  # (batch,)\n",
    "\n",
    "                        # # 가장 큰 손실을 갖는 샘플의 인덱스 찾기\n",
    "                        # max_loss_idx_joke = torch.argmax(loss_joke)\n",
    "\n",
    "                        # # 해당 샘플 선택\n",
    "                        # selected_sample_class = spike_class[max_loss_idx_joke]\n",
    "                        # selected_sample_spike = spike[max_loss_idx_joke]\n",
    "\n",
    "                        # # 선택한 샘플의 손실 값 출력\n",
    "                        # print(\"Index of max loss sample:\", max_loss_idx_joke.item())\n",
    "                        # print(\"Max loss value:\", loss_joke[max_loss_idx_joke].item())\n",
    "                        # mean_loss_joke = loss_joke.mean().item()\n",
    "                        # print(\"Mean loss across the batch:\", mean_loss_joke)\n",
    "\n",
    "                        # # 선택한 샘플을 시각화\n",
    "                        # plot_origin_spike(selected_sample_class.cpu().detach().numpy())\n",
    "                        # plot_origin_spike(selected_sample_spike.cpu().detach().numpy())\n",
    "                        # #########################################\n",
    "\n",
    "                        # coarse loss ######################################################\n",
    "                        loss_normal = criterion(spike_class, spike)\n",
    "                        level_num_in_loss = spike_length\n",
    "                        level_interval = (coarse_com_config[0] - coarse_com_config[1]) / (level_num_in_loss-1)  # max - min\n",
    "                        levels = [coarse_com_config[1] + level_interval * i for i in range(level_num_in_loss)]\n",
    "                        levels = torch.tensor(levels).to(torch.float).to(device)\n",
    "                        # print('coarse leves', levels)\n",
    "                        levels = levels.repeat(spike_length,1) \n",
    "\n",
    "                        spike = spike.squeeze()\n",
    "                        spike_class = spike_class.squeeze()\n",
    "                        # plot_origin_spike(spike_class[0].cpu().detach().numpy())\n",
    "                        spike = spike.unsqueeze(2).repeat(1, 1, level_num_in_loss) \n",
    "                        spike = (spike > levels).to(torch.float) \n",
    "                        spike_class = spike_class.unsqueeze(2).repeat(1, 1, level_num_in_loss) \n",
    "                        spike_class = (spike_class > levels).to(torch.float) \n",
    "                        # spike = spike[..., 0:-3, :]\n",
    "                        # spike_class = spike_class[..., 0:-3, :]\n",
    "                        loss_coarse = criterion(spike_class, spike)\n",
    "                        wrong_element_sum += torch.sum(torch.abs(spike - spike_class)).item() \n",
    "\n",
    "                        # plot_spike(spike_class[0].cpu().detach().numpy())\n",
    "                        # assert False\n",
    "                        # coarse loss ######################################################\n",
    "                    else:\n",
    "                        spike = spike.squeeze()\n",
    "                        spike_class = spike_class.squeeze()\n",
    "                        loss = criterion(spike_class, spike)\n",
    "\n",
    "                    for iii in range(spike.shape[0]):\n",
    "                        same_data_num = same_data_num + 1 if torch.eq(spike[iii], spike_class[iii]).all() else same_data_num\n",
    "                    wrong_element_sum += torch.sum(torch.abs(spike - spike_class)).item() \n",
    "\n",
    "                    # spike = spike.squeeze()\n",
    "                    # spike_class = spike_class.squeeze()\n",
    "                    # plot_spike(spike[0].cpu().detach().numpy())\n",
    "                    # plot_spike(spike_class[0].cpu().detach().numpy())\n",
    "                    # print('손실 절대값 합',np.sum(np.abs(spike[0].cpu().detach().numpy() - spike_class[0].cpu().detach().numpy())))\n",
    "                    # # assert False\n",
    "                elif 'SAE' in net.module.__class__.__name__:\n",
    "                    criterion = nn.MSELoss().to(device)\n",
    "                    loss1 = criterion(spike_class[..., 5:25], spike[..., 5:25])\n",
    "                    loss2 = criterion(spike_class[..., 0:5], spike[..., 0:5])\n",
    "                    loss3 = criterion(spike_class[..., 25:spike_length], spike[..., 25:spike_length])\n",
    "                    loss = loss1 * 2.125 + (loss2 + loss3)/4\n",
    "                    assert spike_length > 25, 'spike_length가 25보다 작음'\n",
    "                    # wrong_element_sum += torch.sum(torch.abs(spike - spike_class)).item() \n",
    "                else:\n",
    "                    criterion = nn.MSELoss().to(device)\n",
    "                    loss1 = criterion(spike_class[..., 5:25], spike[..., 5:25])\n",
    "                    loss2 = criterion(spike_class[..., 0:5], spike[..., 0:5])\n",
    "                    loss3 = criterion(spike_class[..., 25:spike_length], spike[..., 25:spike_length])\n",
    "                    loss = loss1 * 2.125 + (loss2 + loss3)/4\n",
    "                    assert spike_length > 25, 'spike_length가 25보다 작음'\n",
    "                    # wrong_element_sum += torch.sum(torch.abs(spike - spike_class)).item() \n",
    "\n",
    "\n",
    "                    if l2_norm_loss_weight > 0:\n",
    "                        assert len(encoded_spike.shape) == 2, 'time 성분 없는 걸로'\n",
    "                        l2_loss = l2_norm_loss(encoded_spike, target_norm=1.0)  # L2Norm Loss 계산, l2 1.0되게.\n",
    "                        loss = loss + l2_loss*l2_norm_loss_weight\n",
    "                        l2_loss_bin += l2_loss.item()\n",
    "\n",
    "                    # coarse loss ######################################################\n",
    "                    loss_normal = criterion(spike_class, spike)\n",
    "                    level_num_in_loss = quantize_level_num\n",
    "                    level_interval = (coarse_com_config[0] - coarse_com_config[1]) / (level_num_in_loss-1)  # max - min\n",
    "                    levels = [coarse_com_config[1] + level_interval * i for i in range(level_num_in_loss)]\n",
    "                    levels = torch.tensor(levels).to(torch.float).to(device)\n",
    "                    levels = levels.repeat(spike_length,1) \n",
    "\n",
    "                    spike = spike.squeeze()\n",
    "                    spike_class = spike_class.squeeze()\n",
    "                    # plot_origin_spike(spike_class[0].cpu().detach().numpy())\n",
    "                    spike = spike.unsqueeze(2).repeat(1, 1, level_num_in_loss) \n",
    "                    spike = (spike > levels).to(torch.float) \n",
    "                    spike_class = spike_class.unsqueeze(2).repeat(1, 1, level_num_in_loss) \n",
    "                    spike_class = (spike_class > levels).to(torch.float) \n",
    "                    # spike = spike[..., 0:-3, :]\n",
    "                    # spike_class = spike_class[..., 0:-3, :]\n",
    "                    loss_coarse = criterion(spike_class, spike)\n",
    "                    wrong_element_sum += torch.sum(torch.abs(spike - spike_class)).item() \n",
    "\n",
    "                    # plot_spike(spike_class[0].cpu().detach().numpy())\n",
    "                    # assert False\n",
    "                    # coarse loss ######################################################\n",
    "\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                running_loss += loss.item()\n",
    "                running_loss_normal += loss_normal.item()\n",
    "                running_loss_coarse += loss_coarse.item()\n",
    "                # print(f'\\nepoch-{epoch}, running_loss : {running_loss:.5f}, iter percent {iter/len(train_loader)*100:.2f}%')\n",
    "                iter += 1\n",
    "        else:\n",
    "            print('\\n\\n\\n max_epoch 1이면 Train 안함!!!!!!!!!!!!!!!!!!!!!')\n",
    "        if l2_norm_loss_weight > 0:\n",
    "            print('l2_loss_bin', l2_loss_bin/len(train_loader))\n",
    "        avg_loss = running_loss / len(train_loader)\n",
    "        assert not np.isnan(avg_loss), f\"Error: avg_loss is NaN! Running loss: {running_loss}, Length of train_loader: {len(train_loader)}\"\n",
    "        loss_history.append((epoch, avg_loss))\n",
    "        min_loss = min(min_loss, avg_loss)\n",
    "        min_loss_normal = min(min_loss_normal, running_loss_normal/len(train_loader))\n",
    "        min_loss_coarse = min(min_loss_coarse, running_loss_coarse/len(train_loader))\n",
    "        print(f'\\nepoch-{epoch} loss : {avg_loss:.8f}, loss_normal : {running_loss_normal/len(train_loader):.8f}, loss_coarse : {running_loss_coarse/len(train_loader):.8f}, min_loss : {min_loss:.8f}, min_loss_normal : {min_loss_normal:.8f}, min_loss_coarse : {min_loss_coarse:.8f}, wrong_element_sum : {wrong_element_sum:.8f}, same_data : {100*same_data_num/(total_data_num+1e-12):.2f}%')\n",
    "        print(f\"ae train 실행 시간: {time.time()-ae_train_start_time:.3f}초, 전체 시작 시간 {current_time}\")\n",
    "\n",
    "        # plot_activation_distribution(net)\n",
    "\n",
    "        if SAE_net == False and converted_net_forward == True:\n",
    "            source_encoder = net.module.encoder \n",
    "            target_encoder = converted_net.module.encoder  \n",
    "            copy_weights(source_encoder, target_encoder)\n",
    "\n",
    "        cluster_accuracy_during_training_cycle_all_dataset = np.zeros(dataset_num)\n",
    "        cluster_accuracy_post_training_cycle_all_dataset = np.zeros(dataset_num)\n",
    "        cluster_accuracy_total_all_dataset = np.zeros(dataset_num)    \n",
    "\n",
    "        k_means_acc = 0\n",
    "        converted_k_means_acc = 0\n",
    "        if(epoch % accuracy_check_epoch_term == 0 or epoch == 1 or epoch == max_epoch-1): \n",
    "            accuracy_check_start_time = time.time()\n",
    "            print(f'\\nepoch-{epoch} accuracy check')\n",
    "            k_means_bin_origin_feature = []\n",
    "            k_means_bin = []\n",
    "            converted_k_means_bin = []\n",
    "            for ds in range(dataset_num):\n",
    "                # print('\\n', spike_tot[ds])\n",
    "\n",
    "                spike_template = np.load(my_path_ground_BH + template[ds])\n",
    "                spike = np.load(my_path_ground_BH + spike_tot[ds])\n",
    "                label = np.load(my_path_ground_BH + label_tot[ds])\n",
    "                spike_template = torch.from_numpy(spike_template).to(device)\n",
    "                spike = torch.from_numpy(spike).to(device)\n",
    "                scaling = (level_num-3)/level_num if conv1d_scaling else 1.0\n",
    "                spike_template = zero_to_one_normalize_features(spike_template, level_num=quantize_level_num, coarse_com_config=coarse_com_config, scaling=scaling, norm01=norm01) if normalize_on else spike_template\n",
    "                spike = zero_to_one_normalize_features(spike, level_num=quantize_level_num, coarse_com_config=coarse_com_config, scaling=scaling, norm01=norm01) if normalize_on else spike\n",
    "                \n",
    "                hidden_size = lateral_feature_num*TIME if 'SAE' in net.module.__class__.__name__ and SAE_hidden_nomean == True and fusion_net == False or 'SAE_FUSION5' in net.module.__class__.__name__ else lateral_feature_num\n",
    "                hidden_size = lateral_feature_num if '_DR' in net.module.__class__.__name__  else hidden_size\n",
    "\n",
    "                Cluster = np.zeros((num_cluster, hidden_size))\n",
    "                assert Cluster.shape[-1] == hidden_size, '이거 hidden dim 4 아니게 할 거면 잘 바꿔라'\n",
    "                \n",
    "\n",
    "\n",
    "                net.eval()\n",
    "                with torch.no_grad():\n",
    "                    spike_torch = spike_template.float()\n",
    "                    spike_torch = spike_torch[:num_cluster]\n",
    "                    spike_backup = spike_torch\n",
    "                    spike_torch = spike_torch.to(device)\n",
    "                    if coarse_com_mode == True and 'SAE' in net.module.__class__.__name__:\n",
    "                        spike_torch = spike_torch.unsqueeze(2).repeat(1, 1, level_num) # spike_length == level_num # (batch, time, feature)로 변환 \n",
    "                        spike_torch = (spike_torch > levels).to(torch.float) \n",
    "                        spike_torch = (spike_torch == 0).cumsum(dim=-1).eq(1).to(torch.float) if lc_adc_on == True else spike_torch\n",
    "                        if Conv_net == True:\n",
    "                            spike_torch = spike_torch.unsqueeze(-2) # batch, time, in_channel, feature or batch in_channel,feature\n",
    "                            if two_channel_input == True:\n",
    "                                spike_backup = spike_backup.to(device)\n",
    "                                spike_backup = spike_backup.unsqueeze(2).repeat(1, 1, level_num) # spike_length == level_num # (batch, time, feature)로 변환 \n",
    "                                spike_backup = (spike_backup <= levels).to(torch.float) \n",
    "                                spike_backup = (spike_backup == 1).cumsum(dim=-1).eq(1).to(torch.float) if lc_adc_on == True else spike_backup\n",
    "                                spike_backup = spike_backup.unsqueeze(-2) # batch, time, in_channel, feature\n",
    "                                spike_torch = torch.cat((spike_torch, spike_backup), dim=-2)\n",
    "                    elif 'SAE' in net.module.__class__.__name__:\n",
    "                        spike_torch = spike_torch.unsqueeze(1).repeat(1, TIME, 1) # (batch, time, feature)로 변환\n",
    "                        if Conv_net == True:\n",
    "                            spike_torch = spike_torch.unsqueeze(-2) # batch, time, in_channel, feature or batch in_channel,feature\n",
    "                    else:\n",
    "                        # if Conv_net == True:\n",
    "                        #     spike_torch = spike_torch.unsqueeze(-2) #batch in_channel,feature\n",
    "                        if Conv_net == True:\n",
    "                            if coarse_com_mode == False:\n",
    "                                spike_torch = spike_torch.unsqueeze(-2) #batch in_channel,feature\n",
    "                            else:\n",
    "                                spike_torch = spike_torch.unsqueeze(2).repeat(1, 1, level_num) # spike_length == level_num # (batch, time, feature)로 변환 \n",
    "                                spike_torch = (spike_torch > levels).to(torch.float) \n",
    "\n",
    "                                spike_torch = (spike_torch == 0).cumsum(dim=-1).eq(1).to(torch.float) if lc_adc_on == True else spike_torch\n",
    "\n",
    "                        else:\n",
    "                            if coarse_com_mode == False:\n",
    "                                pass\n",
    "                            else:\n",
    "                                spike_torch = spike_torch.unsqueeze(2).repeat(1, 1, level_num) # spike_length == level_num # (batch, time, feature)로 변환 \n",
    "                                spike_torch = (spike_torch > levels).to(torch.float) \n",
    "\n",
    "                                spike_torch = (spike_torch == 0).cumsum(dim=-1).eq(1).to(torch.float) if lc_adc_on == True else spike_torch\n",
    "\n",
    "                                # spike: batch, time, feature\n",
    "                                spike_torch = spike_torch.reshape(spike_torch.shape[0], -1)\n",
    "\n",
    "                        if converted_net_forward == True:\n",
    "                            spike_torch_spikegen = spikegen.rate(spike_torch, num_steps=TIME).transpose(0, 1)\n",
    "                        # if fusion_net == True:\n",
    "                        #     spike_torch = spikegen.rate(spike_torch, num_steps=TIME).transpose(0, 1)\n",
    "                    ### forward #######################################################\n",
    "                    inner_inf = net.module.encoder(spike_torch)\n",
    "                    if SAE_net == False and converted_net_forward == True:\n",
    "                        converted_inner_inf = converted_net.module.encoder(spike_torch_spikegen)\n",
    "                    ### forward #######################################################\n",
    "\n",
    "                    # if ds % 4 == 0:\n",
    "                    #     for i in range(4):\n",
    "                    #         decoded = net.module.decoder(inner_inf).squeeze()\n",
    "                    #         plot_spike(spike_torch[i,:,:].cpu().numpy())\n",
    "                    #         plot_spike(inner_inf[i,:].cpu().numpy())\n",
    "                    #         # plot_origin_spike(net.module.decoder(inner_inf)[i,:].cpu().numpy())\n",
    "                    #         plot_origin_spike(decoded[i].cpu().numpy(), min_max_y_on = True)\n",
    "                        \n",
    "                    # if 'SAE' in net.module.__class__.__name__:\n",
    "                    #     tensors = [inner_inf[0][i] for i in range(TIME)] \n",
    "                    #     all_equal = all(torch.equal(tensors[0], t) for t in tensors)\n",
    "                    #     print(all_equal, inner_inf)\n",
    "\n",
    "                    if 'SAE' in net.module.__class__.__name__:\n",
    "                        if SAE_hidden_nomean == True:\n",
    "                            inner_inf = inner_inf.reshape(inner_inf.shape[0],-1)# time*feature 펼치기\n",
    "                        else:\n",
    "                            inner_inf = inner_inf.mean(dim=1)# Time 방향으로 평균\n",
    "                        # inner_inf = F.normalize(inner_inf, p=2, dim=1)\n",
    "                    Cluster = inner_inf.cpu().detach().numpy()\n",
    "\n",
    "                encoder_batch = 128\n",
    "                spike_hidden = np.zeros((len(spike), hidden_size))\n",
    "                converted_spike_hidden = np.zeros((len(spike), hidden_size))\n",
    "                net.eval()\n",
    "                with torch.no_grad():\n",
    "                    now_index = 0\n",
    "                    while (1):\n",
    "                        now_end_index = now_index+encoder_batch if now_index+encoder_batch < len(spike) else len(spike)\n",
    "                        spike_batch = spike[now_index:now_end_index] \n",
    "                        spike_torch = spike_batch\n",
    "                        spike_torch = spike_torch.float()\n",
    "                        spike_backup = spike_torch\n",
    "                        spike_torch = spike_torch.to(device)\n",
    "                        if coarse_com_mode == True and 'SAE' in net.module.__class__.__name__:\n",
    "                            spike_torch = spike_torch.unsqueeze(2).repeat(1, 1, level_num) # spike_length == level_num # (batch, time, feature)로 변환 \n",
    "                            spike_torch = (spike_torch > levels).to(torch.float) \n",
    "                            spike_torch = (spike_torch == 0).cumsum(dim=-1).eq(1).to(torch.float) if lc_adc_on == True else spike_torch\n",
    "                            if Conv_net == True:\n",
    "                                spike_torch = spike_torch.unsqueeze(-2) # batch, time, in_channel, feature or batch in_channel,feature\n",
    "                                if two_channel_input == True:\n",
    "                                    spike_backup = spike_backup.to(device)\n",
    "                                    spike_backup = spike_backup.unsqueeze(2).repeat(1, 1, level_num) # spike_length == level_num # (batch, time, feature)로 변환 \n",
    "                                    spike_backup = (spike_backup <= levels).to(torch.float) \n",
    "                                    spike_backup = (spike_backup == 1).cumsum(dim=-1).eq(1).to(torch.float) if lc_adc_on == True else spike_backup\n",
    "                                    spike_backup = spike_backup.unsqueeze(-2)\n",
    "                                    spike_torch = torch.cat((spike_torch, spike_backup), dim=-2)\n",
    "                        elif 'SAE' in net.module.__class__.__name__:\n",
    "                            spike_torch = spike_torch.unsqueeze(1).repeat(1, TIME, 1) # (batch, time, feature)로 변환\n",
    "                            if Conv_net == True:\n",
    "                                spike_torch = spike_torch.unsqueeze(-2) # batch, time, in_channel, feature or batch in_channel,feature\n",
    "                        else:\n",
    "                            # if Conv_net == True:\n",
    "                            #     spike_torch = spike_torch.unsqueeze(-2) #batch in_channel,feature\n",
    "                            if Conv_net == True:\n",
    "                                if coarse_com_mode == False:\n",
    "                                    spike_torch = spike_torch.unsqueeze(-2) #batch in_channel,feature\n",
    "                                else:\n",
    "                                    spike_torch = spike_torch.unsqueeze(2).repeat(1, 1, level_num) # spike_length == level_num # (batch, time, feature)로 변환 \n",
    "                                    spike_torch = (spike_torch > levels).to(torch.float) \n",
    "\n",
    "                                    spike_torch = (spike_torch == 0).cumsum(dim=-1).eq(1).to(torch.float) if lc_adc_on == True else spike_torch\n",
    "\n",
    "                            else:\n",
    "                                if coarse_com_mode == False:\n",
    "                                    pass\n",
    "                                else:\n",
    "                                    spike_torch = spike_torch.unsqueeze(2).repeat(1, 1, level_num) # spike_length == level_num # (batch, time, feature)로 변환 \n",
    "                                    spike_torch = (spike_torch > levels).to(torch.float) \n",
    "\n",
    "                                    spike_torch = (spike_torch == 0).cumsum(dim=-1).eq(1).to(torch.float) if lc_adc_on == True else spike_torch\n",
    "\n",
    "                                    # spike: batch, time, feature\n",
    "                                    spike_torch = spike_torch.reshape(spike_torch.shape[0], -1)\n",
    "                            if converted_net_forward == True:\n",
    "                                spike_torch_spikegen = spikegen.rate(spike_torch, num_steps=TIME).transpose(0, 1)\n",
    "                            # if fusion_net == True:\n",
    "                            #     spike_torch = spikegen.rate(spike_torch, num_steps=TIME).transpose(0, 1)\n",
    "                        ### forward #######################################################\n",
    "                        inner_inf = net.module.encoder(spike_torch)\n",
    "                        if SAE_net == False and converted_net_forward == True:\n",
    "                            converted_inner_inf = converted_net.module.encoder(spike_torch_spikegen)\n",
    "                        ### forward #######################################################\n",
    "                            \n",
    "                        if 'SAE' in net.module.__class__.__name__:\n",
    "                            if SAE_hidden_nomean == True:\n",
    "                                inner_inf = inner_inf.reshape(spike_batch.shape[0],-1)# 펼치기\n",
    "                            else:\n",
    "                                inner_inf = inner_inf.mean(dim=1)# Time 방향으로 평균\n",
    "                            # inner_inf = F.normalize(inner_inf, p=2, dim=1)\n",
    "                        spike_hidden[now_index:now_end_index] = inner_inf.cpu().detach().numpy()\n",
    "                        if SAE_net == False and converted_net_forward == True:\n",
    "                            converted_spike_hidden[now_index:now_end_index] = converted_inner_inf.cpu().detach().numpy()\n",
    "                        now_index += encoder_batch\n",
    "                        if (now_index >= len(spike)):\n",
    "                            break\n",
    "                    \n",
    "                spike_id = np.zeros(len(spike))\n",
    "                distance_sm = np.zeros(num_cluster)\n",
    "                tau = np.zeros(num_cluster)\n",
    "                \n",
    "                plot_tau = []\n",
    "                plot_denominator = []\n",
    "                plot_m = []\n",
    "                plot_max_tau = []\n",
    "                for spike_index in range(len(spike)): \n",
    "                    for q in range(num_cluster):\n",
    "                        tau[q] = np.dot(spike_hidden[spike_index, :], Cluster[q, :]) # 이거 l2norm 거쳐서 나온 거니까 분모 1임.\n",
    "                        denominator =  np.linalg.norm(spike_hidden[spike_index, :])*np.linalg.norm(Cluster[q, :]) + 1e-12\n",
    "                        plot_denominator.append(denominator)\n",
    "                        if 'SAE' in net.module.__class__.__name__: # AE 때는 l2norm거쳐서 나와서 괜찮음\n",
    "                            tau[q] = tau[q] / denominator\n",
    "\n",
    "                        plot_tau.append(tau[q])\n",
    "\n",
    "                    # for i in range(num_cluster): # l2 distance\n",
    "                    #     distance_sm[i] = np.sum(np.power(np.abs(Cluster[i] - spike_hidden[spike_index, :]), 2))\n",
    "                    distance_sm = np.sum(np.power(np.abs(Cluster - spike_hidden[spike_index, :]), 2), axis=1)\n",
    "\n",
    "                    m = np.argmin(distance_sm)\n",
    "                    plot_m.append(m)\n",
    "                    spike_id[spike_index] = m + 1\n",
    "                    # print(spike_tot[ds], spike_index,np.max(tau))\n",
    "                    plot_max_tau.append(np.max(tau))\n",
    "                    if(np.max(tau) >= cos_thr[ds] and spike_index < training_cycle): # 원래 1400 아니냐?\n",
    "                        Cluster[m] = (Cluster[m] * 15 + spike_hidden[spike_index, :])/16\n",
    "\n",
    "\n",
    "                \n",
    "                origin_kmeans_accuracy = cluster_spikes_with_accuracy_torch(features= spike, true_labels=label-1, n_clusters=3, init_point=None)\n",
    "                kmeans_accuracy = cluster_spikes_with_accuracy_torch(features= torch.tensor(spike_hidden).to(device), true_labels=label-1, n_clusters=3, init_point=None)\n",
    "                \n",
    "                # print('temporoal k')\n",
    "                # result = evaluate_clustering_accuracy(spike_hidden.reshape(spike_hidden.shape[0], TIME, -1), label-1, n_clusters=3)\n",
    "                # print('원래', kmeans_accuracy)\n",
    "                # print(result)\n",
    "\n",
    "                k_means_bin_origin_feature.append(origin_kmeans_accuracy)\n",
    "                k_means_bin.append(kmeans_accuracy)\n",
    "                if SAE_net == False and converted_net_forward == True:\n",
    "                    converted_kmeans_accuracy = cluster_spikes_with_accuracy_torch(features= torch.tensor(converted_spike_hidden).to(device), true_labels=label-1, n_clusters=3, init_point=None)\n",
    "                    converted_k_means_bin.append(converted_kmeans_accuracy)\n",
    "                # sklearn kmeans인데 cpu많이먹어서 버림.\n",
    "                # origin_kmeans_accuracy = cluster_spikes_with_accuracy(features= spike.cpu().detach().numpy(), true_labels=label-1, n_clusters=3, init_point=None)\n",
    "                # kmeans_accuracy = cluster_spikes_with_accuracy(features= spike_hidden, true_labels=label-1, n_clusters=3, init_point=None)\n",
    "                # k_means_bin_origin_feature.append(origin_kmeans_accuracy)\n",
    "                # k_means_bin.append(kmeans_accuracy)\n",
    "                # if SAE_net == False and converted_net_forward == True:\n",
    "                #     converted_kmeans_accuracy = cluster_spikes_with_accuracy(features= converted_spike_hidden, true_labels=label-1, n_clusters=3, init_point=None)\n",
    "                #     converted_k_means_bin.append(converted_kmeans_accuracy)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "                # print('Cluster',Cluster)\n",
    "                # print('spike_id', spike_id)\n",
    "\n",
    "                # spike id 분포 확인하기\n",
    "                # unique_elements, counts = np.unique(spike_id, return_counts=True)\n",
    "                # print(\"Unique elements:\", unique_elements)\n",
    "                # print(\"Counts:\", counts)\n",
    "\n",
    "                cluster_accuracy_during_training_cycle = np.zeros(math.factorial(num_cluster))\n",
    "                cluster_accuracy_post_training_cycle = np.zeros(math.factorial(num_cluster))\n",
    "                cluster_accuracy_total = np.zeros(math.factorial(num_cluster))\n",
    "                \n",
    "                label_converter_ground = list(range(1, num_cluster + 1)) # [1, 2, 3, 4] 생성\n",
    "                label_converter_permutations = list(itertools.permutations(label_converter_ground)) # 모든 순열 구하기\n",
    "                perm_i = 0\n",
    "                perm_start_time = time.time() \n",
    "                for perm in label_converter_permutations:\n",
    "                    label_converter = list(perm)\n",
    "                    # print(label_converter)\n",
    "                    correct_during_training_cycle = 0\n",
    "                    correct_post_training_cycle = 0\n",
    "\n",
    "                    assert len(spike_id) == len(label), 'spike_id랑 label 길이 같아야 됨.'\n",
    "                    for i in range(len(spike_id)):\n",
    "                        if(label_converter[int(spike_id[i]-1)] == label[i]):\n",
    "                            if i < training_cycle:\n",
    "                                correct_during_training_cycle += 1\n",
    "                            else:\n",
    "                                correct_post_training_cycle += 1\n",
    "\n",
    "                    cluster_accuracy_during_training_cycle[perm_i] = correct_during_training_cycle/training_cycle\n",
    "                    cluster_accuracy_post_training_cycle[perm_i] = correct_post_training_cycle/(len(spike_id)-training_cycle)\n",
    "                    cluster_accuracy_total[perm_i] = (correct_during_training_cycle+correct_post_training_cycle)/(len(spike_id))\n",
    "                    perm_i += 1\n",
    "                # print(f\"perm 실행 시간: {time.time()-perm_start_time:.3f}초\")\n",
    "                \n",
    "                cluster_accuracy_during_training_cycle_all_dataset[ds] = np.max(cluster_accuracy_during_training_cycle)\n",
    "                cluster_accuracy_post_training_cycle_all_dataset[ds] = cluster_accuracy_post_training_cycle[np.argmax(cluster_accuracy_during_training_cycle)]\n",
    "                cluster_accuracy_total_all_dataset[ds] = cluster_accuracy_total[np.argmax(cluster_accuracy_during_training_cycle)]\n",
    "                # plot_distributions(ds, plot_tau, plot_denominator, plot_m, plot_max_tau, cos_thr[ds],\n",
    "                #                    cluster_accuracy_during_training_cycle_all_dataset[ds], cluster_accuracy_post_training_cycle_all_dataset[ds], cluster_accuracy_total_all_dataset[ds])\n",
    "            print(f'k_means origin feature average accuracy : {100*sum(k_means_bin_origin_feature)/(len(k_means_bin_origin_feature)+1e-12):.8f}%, total {k_means_bin_origin_feature}')\n",
    "            \n",
    "            mean_cluster_accuracy_during_training_cycle_all_dataset = np.mean(cluster_accuracy_during_training_cycle_all_dataset)\n",
    "            mean_cluster_accuracy_post_training_cycle_all_dataset = np.mean(cluster_accuracy_post_training_cycle_all_dataset)\n",
    "            mean_cluster_accuracy_total_all_dataset = np.mean(cluster_accuracy_total_all_dataset)\n",
    "            \n",
    "            if SAE_net == False and converted_net_forward == True:\n",
    "                converted_k_means_acc = 100*sum(converted_k_means_bin)/len(converted_k_means_bin)\n",
    "                print(f'converted_kmeans average accuracy : {converted_k_means_acc:.8f}%, total {converted_k_means_bin}')\n",
    "            k_means_acc = 100*sum(k_means_bin)/len(k_means_bin)\n",
    "            if k_means_acc > k_means_acc_best:\n",
    "                # torch.save(net, f\"net_save/save_now_net_{current_time}.pth\")\n",
    "                torch.save(net.module.state_dict(), f\"net_save/save_now_net_{current_time}.pth\")\n",
    "                print('save model')\n",
    "                best_mean_cluster_accuracy_post_training_cycle_all_dataset = mean_cluster_accuracy_post_training_cycle_all_dataset\n",
    "            \n",
    "            k_means_acc_best = max(k_means_acc_best, k_means_acc)\n",
    "            print(f'kmeans average accuracy best : {k_means_acc_best:.2f}%, kmeans average accuracy : {k_means_acc:.8f}%, total {k_means_bin}')\n",
    "            print(f'cluster_accuracy_post_training_cycle_all_dataset : {cluster_accuracy_post_training_cycle_all_dataset}')\n",
    "\n",
    "            \n",
    "            mean_cluster_accuracy_during_training_cycle_all_dataset_history.append((epoch, mean_cluster_accuracy_during_training_cycle_all_dataset*100))\n",
    "            mean_cluster_accuracy_post_training_cycle_all_dataset_history.append((epoch, mean_cluster_accuracy_post_training_cycle_all_dataset*100))\n",
    "            mean_cluster_accuracy_total_all_dataset_history.append((epoch, mean_cluster_accuracy_total_all_dataset*100))\n",
    "            print(f\"mean_cluster_accuracy_during_training_cycle : {mean_cluster_accuracy_during_training_cycle_all_dataset*100:.2f}%, post_traincycle_acc : {mean_cluster_accuracy_post_training_cycle_all_dataset*100:.2f}%, total_acc : {mean_cluster_accuracy_total_all_dataset*100:.8f}%\")\n",
    "\n",
    "            # kmeans accuracy기준으로 좋은 거 저장할 거임\n",
    "            # if mean_cluster_accuracy_post_training_cycle_all_dataset > best_mean_cluster_accuracy_post_training_cycle_all_dataset:\n",
    "            #     # torch.save(net, f\"net_save/save_now_net_{current_time}.pth\")\n",
    "            #     torch.save(net.module.state_dict(), f\"net_save/save_now_net_{current_time}.pth\")\n",
    "            #     print('save model')\n",
    "            #     best_mean_cluster_accuracy_post_training_cycle_all_dataset = mean_cluster_accuracy_post_training_cycle_all_dataset\n",
    "            print(f\"best_mean_cluster_accuracy_post_training_cycle_all_dataset : {best_mean_cluster_accuracy_post_training_cycle_all_dataset*100:.2f}%\")\n",
    "            print(f\"accuracy_check 실행 시간: {time.time()-accuracy_check_start_time:.3f}초\")\n",
    "\n",
    "        wandb.log({\"avg_loss\": avg_loss})\n",
    "        wandb.log({\"mean_cluster_accuracy_post_training_cycle_all_dataset\": mean_cluster_accuracy_post_training_cycle_all_dataset})\n",
    "        wandb.log({\"best_mean_cluster_accuracy_post_training_cycle_all_dataset\": best_mean_cluster_accuracy_post_training_cycle_all_dataset})\n",
    "        wandb.log({\"best_mean_cluster_accuracy_post_training_cycle_all_dataset2\": best_mean_cluster_accuracy_post_training_cycle_all_dataset})\n",
    "        wandb.log({\"k_means_acc\": k_means_acc})\n",
    "        wandb.log({\"k_means_acc_best\": k_means_acc_best})\n",
    "        wandb.log({\"converted_k_means_acc\": converted_k_means_acc})\n",
    "\n",
    "\n",
    "        # 저장\n",
    "        with open(f\"result_save/cluster_accuracy_history_{current_time}.pkl\", \"wb\") as f:\n",
    "            pickle.dump({\n",
    "                \"loss_history\": loss_history,\n",
    "                \"mean_cluster_accuracy_during_training_cycle_all_dataset_history\": mean_cluster_accuracy_during_training_cycle_all_dataset_history,\n",
    "                \"mean_cluster_accuracy_post_training_cycle_all_dataset_history\": mean_cluster_accuracy_post_training_cycle_all_dataset_history,\n",
    "                \"mean_cluster_accuracy_total_all_dataset_history\": mean_cluster_accuracy_total_all_dataset_history,\n",
    "            }, f)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mbhkim003\u001b[0m (\u001b[33mbhkim003-seoul-national-university\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.19.8 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.17.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/nfs/home/bhkim003/github_folder/ByeonghyeonKim/my_snn/wandb/run-20250314_000239-d384eixp</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/bhkim003-seoul-national-university/spike_sorting%20just%20run/runs/d384eixp' target=\"_blank\">avid-plasma-1483</a></strong> to <a href='https://wandb.ai/bhkim003-seoul-national-university/spike_sorting%20just%20run' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/bhkim003-seoul-national-university/spike_sorting%20just%20run' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/spike_sorting%20just%20run</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/bhkim003-seoul-national-university/spike_sorting%20just%20run/runs/d384eixp' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/spike_sorting%20just%20run/runs/d384eixp</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'gpu': '2', 'Conv_net': True, 'SAE_net': True, 'dataset_num': 16, 'spike_length': 50, 'num_cluster': 4, 'training_cycle': 1400, 'batch_size': 32, 'max_epoch': 10000, 'learning_rate': 0.001, 'normalize_on': True, 'need_bias': False, 'lif_add_at_first': False, 'my_seed': 42, 'TIME': 50, 'v_decay': 0.5, 'v_threshold': 0.25, 'v_reset': 0.0, 'BPTT_on': True, 'SAE_hidden_nomean': True, 'current_time': '20250314_000238_046', 'optimizer': 'Adam', 'coarse_com_mode': True, 'sae_l2_norm_bridge': True, 'sae_lif_bridge': False, 'accuracy_check_epoch_term': 1, 'lif_add_at_last': False, 'two_channel_input': False, 'lateral_feature_num': 6, 'lc_adc_on': False, 'converted_net_forward': False, 'pretrained_net': None, 'vth_mul_on': False, 'batch_norm_on': False, 'l2_norm_loss_weight': 0, 'QCFS_neuron_on': False, 'quantize_level_num': 0, 'fusion_net': True, 'repeat_coding': False, 'sae_relu_on': False, 'conv1d_scaling': False, 'norm01': True, 'coarse_com_config': (0.999, -0.0)}\n",
      "cos_thr [0.95 0.95 0.95 0.95 0.95 0.95 0.95 0.85 0.95 0.9  0.8  0.95 0.95 0.95\n",
      " 0.95 0.8 ]\n",
      "conv length [50, 24, 11, 5]\n",
      "Total number of encoder parameters: 29352\n",
      "DataParallel(\n",
      "  (module): SAE_FUSION7_net_conv1(\n",
      "    (activation_function): LIF_layer()\n",
      "    (encoder): Sequential(\n",
      "      (0): SSBH_DimChanger_one_two()\n",
      "      (1): SSBH_DimChanger_for_one_two_coupling()\n",
      "      (2): Conv1d(1, 32, kernel_size=(3,), stride=(2,), bias=False)\n",
      "      (3): SSBH_DimChanger_for_one_two_decoupling()\n",
      "      (4): LIF_layer()\n",
      "      (5): SSBH_DimChanger_for_one_two_coupling()\n",
      "      (6): Conv1d(32, 64, kernel_size=(3,), stride=(2,), bias=False)\n",
      "      (7): SSBH_DimChanger_for_one_two_decoupling()\n",
      "      (8): LIF_layer()\n",
      "      (9): SSBH_DimChanger_for_one_two_coupling()\n",
      "      (10): Conv1d(64, 96, kernel_size=(3,), stride=(2,), bias=False)\n",
      "      (11): SSBH_DimChanger_for_one_two_decoupling()\n",
      "      (12): LIF_layer()\n",
      "      (13): SSBH_DimChanger_for_one_two_coupling()\n",
      "      (14): SSBH_DimChanger_for_fc()\n",
      "      (15): Linear(in_features=480, out_features=6, bias=False)\n",
      "      (16): SSBH_DimChanger_for_one_two_decoupling()\n",
      "      (17): LIF_layer()\n",
      "      (18): SSBH_DimChanger_one_two()\n",
      "      (19): SSBH_DimChanger_for_two_three_coupling()\n",
      "      (20): Linear(in_features=300, out_features=6, bias=False)\n",
      "      (21): SSBH_L2NormLayer()\n",
      "    )\n",
      "    (decoder): Sequential(\n",
      "      (0): Linear(in_features=6, out_features=480, bias=False)\n",
      "      (1): ReLU()\n",
      "      (2): SSBH_DimChanger_for_conv1()\n",
      "      (3): ConvTranspose1d(96, 64, kernel_size=(3,), stride=(2,), bias=False)\n",
      "      (4): ReLU()\n",
      "      (5): ConvTranspose1d(64, 32, kernel_size=(3,), stride=(2,), output_padding=(1,), bias=False)\n",
      "      (6): ReLU()\n",
      "      (7): ConvTranspose1d(32, 1, kernel_size=(3,), stride=(2,), output_padding=(1,), bias=False)\n",
      "    )\n",
      "  )\n",
      ")\n",
      "Device: cuda\n",
      "\n",
      "Start Training, current_time = 20250314_000238_046\n",
      "\n",
      "\n",
      "epoch-0 loss : 0.02371674, loss_normal : 0.01670551, loss_coarse : 0.07351915, min_loss : 0.02371674, min_loss_normal : 0.01670551, min_loss_coarse : 0.07351915, wrong_element_sum : 14115678.00000000, same_data : 0.00%\n",
      "ae train 실행 시간: 126.185초, 전체 시작 시간 20250314_000238_046\n",
      "\n",
      "epoch-0 accuracy check\n",
      "k_means origin feature average accuracy : 82.25137136%, total [0.9746727376209448, 0.9733106189664963, 0.9700891573195284, 0.9530800230282096, 0.943108504398827, 0.9150568181818182, 0.8015244796247435, 0.6622234826999432, 0.9488619568430388, 0.822215777262181, 0.5866935483870968, 0.5005858230814294, 0.9429250891795482, 0.8922588099364529, 0.6741279069767442, 0.5994846836530203]\n",
      "save model\n",
      "kmeans average accuracy best : 89.05%, kmeans average accuracy : 89.05068064%, total [0.9758110415480934, 0.9758659852356616, 0.9738280126545873, 0.9625791594703512, 0.9580645161290322, 0.9409090909090909, 0.8941659337437702, 0.789563244469654, 0.9482707655926692, 0.8842807424593968, 0.7828341013824884, 0.7103104862331576, 0.952140309155767, 0.9208549971114962, 0.833139534883721, 0.7454909819639278]\n",
      "cluster_accuracy_post_training_cycle_all_dataset : [0.97776727 0.97643732 0.97544535 0.96576663 0.960199   0.93915094\n",
      " 0.89806067 0.79586077 0.93847705 0.89355469 0.76640927 0.71201589\n",
      " 0.95213849 0.92531523 0.83039216 0.7429527 ]\n",
      "mean_cluster_accuracy_during_training_cycle : 88.37%, post_traincycle_acc : 89.06%, total_acc : 88.77971182%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 89.06%\n",
      "accuracy_check 실행 시간: 24.417초\n",
      "\n",
      "\n",
      "epoch-1 loss : 0.00943336, loss_normal : 0.01202302, loss_coarse : 0.05668239, min_loss : 0.00943336, min_loss_normal : 0.01202302, min_loss_coarse : 0.05668239, wrong_element_sum : 10883020.00000000, same_data : 0.00%\n",
      "ae train 실행 시간: 124.168초, 전체 시작 시간 20250314_000238_046\n",
      "\n",
      "epoch-1 accuracy check\n",
      "k_means origin feature average accuracy : 82.25314853%, total [0.9746727376209448, 0.9733106189664963, 0.9700891573195284, 0.9530800230282096, 0.943108504398827, 0.9150568181818182, 0.801817648783348, 0.6622234826999432, 0.9488619568430388, 0.822215777262181, 0.5866935483870968, 0.5005858230814294, 0.9429250891795482, 0.8922588099364529, 0.673546511627907, 0.6000572573718866]\n",
      "save model\n",
      "kmeans average accuracy best : 90.32%, kmeans average accuracy : 90.32182472%, total [0.9755264655663062, 0.9775695627484384, 0.9741156169111302, 0.9622913068508924, 0.9589442815249267, 0.9485795454545455, 0.9091175608326004, 0.8230289279636982, 0.9562518474726575, 0.8982018561484919, 0.8159562211981567, 0.7439953134153485, 0.9545184304399524, 0.9306759098786829, 0.8520348837209303, 0.7706842255940453]\n",
      "cluster_accuracy_post_training_cycle_all_dataset : [0.97776727 0.97879359 0.97544535 0.96624879 0.96218905 0.94339623\n",
      " 0.91447041 0.82361242 0.94906707 0.90771484 0.7953668  0.70903674\n",
      " 0.95773931 0.92386033 0.84509804 0.78356426]\n",
      "mean_cluster_accuracy_during_training_cycle : 88.89%, post_traincycle_acc : 90.08%, total_acc : 89.59425368%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 90.08%\n",
      "accuracy_check 실행 시간: 23.610초\n",
      "\n",
      "\n",
      "epoch-2 loss : 0.00903311, loss_normal : 0.01187578, loss_coarse : 0.05550786, min_loss : 0.00903311, min_loss_normal : 0.01187578, min_loss_coarse : 0.05550786, wrong_element_sum : 10657510.00000000, same_data : 0.00%\n",
      "ae train 실행 시간: 129.046초, 전체 시작 시간 20250314_000238_046\n",
      "\n",
      "epoch-2 accuracy check\n",
      "k_means origin feature average accuracy : 82.25487967%, total [0.9746727376209448, 0.9733106189664963, 0.9700891573195284, 0.9530800230282096, 0.943108504398827, 0.9150568181818182, 0.801817648783348, 0.6625070901871809, 0.9488619568430388, 0.822215777262181, 0.5866935483870968, 0.5002929115407148, 0.9429250891795482, 0.8922588099364529, 0.673546511627907, 0.6003435442313197]\n",
      "save model\n",
      "kmeans average accuracy best : 91.13%, kmeans average accuracy : 91.12997127%, total [0.9758110415480934, 0.9772856331629756, 0.9744032211676733, 0.9628670120898101, 0.9609970674486803, 0.9474431818181818, 0.9114629141014365, 0.8383437322745321, 0.9651197162281998, 0.9185034802784223, 0.8487903225806451, 0.7753368482718219, 0.9560047562425684, 0.9280762564991335, 0.8630813953488372, 0.7772688233610078]\n",
      "cluster_accuracy_post_training_cycle_all_dataset : [0.97871334 0.97785108 0.97496389 0.96576663 0.96268657 0.94056604\n",
      " 0.90949776 0.81984948 0.95663137 0.9296875  0.83108108 0.77358491\n",
      " 0.94704684 0.92337536 0.86323529 0.79264214]\n",
      "mean_cluster_accuracy_during_training_cycle : 90.04%, post_traincycle_acc : 90.92%, total_acc : 90.55962740%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 90.92%\n",
      "accuracy_check 실행 시간: 24.677초\n",
      "\n",
      "\n",
      "epoch-3 loss : 0.00883611, loss_normal : 0.01180974, loss_coarse : 0.05494185, min_loss : 0.00883611, min_loss_normal : 0.01180974, min_loss_coarse : 0.05494185, wrong_element_sum : 10548836.00000000, same_data : 0.00%\n",
      "ae train 실행 시간: 126.284초, 전체 시작 시간 20250314_000238_046\n",
      "\n",
      "epoch-3 accuracy check\n",
      "k_means origin feature average accuracy : 82.26214723%, total [0.9746727376209448, 0.9733106189664963, 0.9700891573195284, 0.9530800230282096, 0.943108504398827, 0.915340909090909, 0.801817648783348, 0.6625070901871809, 0.9488619568430388, 0.822215777262181, 0.5866935483870968, 0.5005858230814294, 0.9429250891795482, 0.8922588099364529, 0.6744186046511628, 0.6000572573718866]\n",
      "kmeans average accuracy best : 91.13%, kmeans average accuracy : 90.95541293%, total [0.9763801935116676, 0.9775695627484384, 0.9746908254242163, 0.9660333909038572, 0.9615835777126099, 0.9522727272727273, 0.9217238346525946, 0.8477027793533749, 0.9550694649719185, 0.9106728538283063, 0.826036866359447, 0.7592267135325131, 0.9568965517241379, 0.9303870595031773, 0.8625, 0.7741196679072431]\n",
      "cluster_accuracy_post_training_cycle_all_dataset : [0.97918638 0.97832234 0.97544535 0.96817743 0.96218905 0.94716981\n",
      " 0.92391845 0.82314205 0.93645991 0.91748047 0.79826255 0.77457795\n",
      " 0.96130346 0.92677013 0.8627451  0.77496417]\n",
      "mean_cluster_accuracy_during_training_cycle : 90.48%, post_traincycle_acc : 90.69%, total_acc : 90.60165402%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 90.92%\n",
      "accuracy_check 실행 시간: 24.203초\n",
      "\n",
      "\n",
      "epoch-4 loss : 0.00863853, loss_normal : 0.01175622, loss_coarse : 0.05442805, min_loss : 0.00863853, min_loss_normal : 0.01175622, min_loss_coarse : 0.05442805, wrong_element_sum : 10450186.00000000, same_data : 0.00%\n",
      "ae train 실행 시간: 126.872초, 전체 시작 시간 20250314_000238_046\n",
      "\n",
      "epoch-4 accuracy check\n",
      "k_means origin feature average accuracy : 82.25674876%, total [0.9746727376209448, 0.9733106189664963, 0.9700891573195284, 0.9530800230282096, 0.943108504398827, 0.9150568181818182, 0.801817648783348, 0.6622234826999432, 0.9488619568430388, 0.822215777262181, 0.5872695852534562, 0.5005858230814294, 0.9429250891795482, 0.8922588099364529, 0.673546511627907, 0.6000572573718866]\n",
      "save model\n",
      "kmeans average accuracy best : 91.21%, kmeans average accuracy : 91.21125011%, total [0.9763801935116676, 0.9775695627484384, 0.9746908254242163, 0.9648819804260219, 0.9615835777126099, 0.9525568181818181, 0.9211374963353856, 0.8513896766874646, 0.968371268105232, 0.9303944315545244, 0.8418778801843319, 0.7630345635618043, 0.9586801426872771, 0.9352975158867707, 0.8590116279069767, 0.7569424563412539]\n",
      "cluster_accuracy_post_training_cycle_all_dataset : [0.97918638 0.97785108 0.97496389 0.96721311 0.96218905 0.94575472\n",
      " 0.92640477 0.84148636 0.9667171  0.93896484 0.81805019 0.75769613\n",
      " 0.95824847 0.93452958 0.86078431 0.77878643]\n",
      "mean_cluster_accuracy_during_training_cycle : 90.22%, post_traincycle_acc : 91.18%, total_acc : 90.78801605%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 91.18%\n",
      "accuracy_check 실행 시간: 24.336초\n",
      "\n",
      "\n",
      "epoch-5 loss : 0.00860933, loss_normal : 0.01174723, loss_coarse : 0.05437924, min_loss : 0.00860933, min_loss_normal : 0.01174723, min_loss_coarse : 0.05437924, wrong_element_sum : 10440814.00000000, same_data : 0.00%\n",
      "ae train 실행 시간: 115.719초, 전체 시작 시간 20250314_000238_046\n",
      "\n",
      "epoch-5 accuracy check\n",
      "k_means origin feature average accuracy : 82.26029186%, total [0.9746727376209448, 0.9733106189664963, 0.9700891573195284, 0.9530800230282096, 0.943108504398827, 0.9150568181818182, 0.801817648783348, 0.6622234826999432, 0.9488619568430388, 0.822215777262181, 0.5866935483870968, 0.5002929115407148, 0.9429250891795482, 0.8922588099364529, 0.6738372093023256, 0.6012024048096193]\n",
      "kmeans average accuracy best : 91.21%, kmeans average accuracy : 91.17075012%, total [0.9766647694934547, 0.9775695627484384, 0.9741156169111302, 0.9643062751871042, 0.9618768328445748, 0.9545454545454546, 0.9228965112870126, 0.8457175269427113, 0.9701448418563405, 0.9208236658932715, 0.8461981566820277, 0.7785588752196837, 0.955410225921522, 0.9263431542461005, 0.8534883720930233, 0.7586601774978529]\n",
      "cluster_accuracy_post_training_cycle_all_dataset : [0.97918638 0.97832234 0.97496389 0.96769527 0.96218905 0.9490566\n",
      " 0.92391845 0.83772342 0.95663137 0.93261719 0.81081081 0.65491559\n",
      " 0.95723014 0.93113482 0.85245098 0.77878643]\n",
      "mean_cluster_accuracy_during_training_cycle : 89.61%, post_traincycle_acc : 90.30%, total_acc : 90.01626319%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 91.18%\n",
      "accuracy_check 실행 시간: 24.486초\n",
      "\n",
      "\n",
      "epoch-6 loss : 0.00850502, loss_normal : 0.01171967, loss_coarse : 0.05410636, min_loss : 0.00850502, min_loss_normal : 0.01171967, min_loss_coarse : 0.05410636, wrong_element_sum : 10388422.00000000, same_data : 0.00%\n",
      "ae train 실행 시간: 121.509초, 전체 시작 시간 20250314_000238_046\n",
      "\n",
      "epoch-6 accuracy check\n",
      "k_means origin feature average accuracy : 82.26223773%, total [0.9746727376209448, 0.9733106189664963, 0.9700891573195284, 0.9530800230282096, 0.943108504398827, 0.9150568181818182, 0.801817648783348, 0.6625070901871809, 0.9488619568430388, 0.822215777262181, 0.5872695852534562, 0.5005858230814294, 0.9429250891795482, 0.8922588099364529, 0.675, 0.5991983967935872]\n",
      "save model\n",
      "kmeans average accuracy best : 91.57%, kmeans average accuracy : 91.56806333%, total [0.9763801935116676, 0.9778534923339012, 0.9741156169111302, 0.9645941278065631, 0.9609970674486803, 0.953125, 0.9187921430665494, 0.8499716392512763, 0.969553650605971, 0.925754060324826, 0.8525345622119815, 0.7888107791446983, 0.9577883472057075, 0.9326978625072213, 0.8715116279069768, 0.7764099627827082]\n",
      "cluster_accuracy_post_training_cycle_all_dataset : [0.97965941 0.97785108 0.97496389 0.96673095 0.96218905 0.94669811\n",
      " 0.92143212 0.84336783 0.95663137 0.93359375 0.81998069 0.58291956\n",
      " 0.95977597 0.93161979 0.87794118 0.79168657]\n",
      "mean_cluster_accuracy_during_training_cycle : 90.01%, post_traincycle_acc : 90.17%, total_acc : 90.10588553%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 90.17%\n",
      "accuracy_check 실행 시간: 24.210초\n",
      "\n",
      "\n",
      "epoch-7 loss : 0.00843333, loss_normal : 0.01169509, loss_coarse : 0.05391355, min_loss : 0.00843333, min_loss_normal : 0.01169509, min_loss_coarse : 0.05391355, wrong_element_sum : 10351402.00000000, same_data : 0.00%\n",
      "ae train 실행 시간: 115.002초, 전체 시작 시간 20250314_000238_046\n",
      "\n",
      "epoch-7 accuracy check\n",
      "k_means origin feature average accuracy : 82.26223283%, total [0.9746727376209448, 0.9733106189664963, 0.9700891573195284, 0.9530800230282096, 0.943108504398827, 0.9150568181818182, 0.801817648783348, 0.6622234826999432, 0.9488619568430388, 0.822215777262181, 0.5866935483870968, 0.5005858230814294, 0.9429250891795482, 0.8922588099364529, 0.675, 0.6000572573718866]\n",
      "save model\n",
      "kmeans average accuracy best : 91.92%, kmeans average accuracy : 91.92175206%, total [0.9766647694934547, 0.9778534923339012, 0.9746908254242163, 0.9637305699481865, 0.964516129032258, 0.9582386363636364, 0.9293462327763119, 0.8613159387407827, 0.966006503103754, 0.9243039443155452, 0.8516705069124424, 0.7923257176332748, 0.9586801426872771, 0.9404968226458694, 0.8691860465116279, 0.798454050959061]\n",
      "cluster_accuracy_post_training_cycle_all_dataset : [0.98060549 0.97832234 0.97544535 0.96624879 0.96567164 0.95471698\n",
      " 0.9288911  0.84854186 0.95259708 0.92919922 0.8277027  0.79841112\n",
      " 0.95977597 0.93016489 0.8754902  0.80458672]\n",
      "mean_cluster_accuracy_during_training_cycle : 90.98%, post_traincycle_acc : 91.73%, total_acc : 91.41928437%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 91.73%\n",
      "accuracy_check 실행 시간: 24.123초\n",
      "\n",
      "\n",
      "epoch-8 loss : 0.00847306, loss_normal : 0.01169892, loss_coarse : 0.05402654, min_loss : 0.00843333, min_loss_normal : 0.01169509, min_loss_coarse : 0.05391355, wrong_element_sum : 10373096.00000000, same_data : 0.00%\n",
      "ae train 실행 시간: 120.702초, 전체 시작 시간 20250314_000238_046\n",
      "\n",
      "epoch-8 accuracy check\n",
      "k_means origin feature average accuracy : 82.25852131%, total [0.9746727376209448, 0.9733106189664963, 0.9700891573195284, 0.9530800230282096, 0.943108504398827, 0.9150568181818182, 0.801817648783348, 0.6625070901871809, 0.9488619568430388, 0.822215777262181, 0.5872695852534562, 0.5005858230814294, 0.9429250891795482, 0.8922588099364529, 0.673546511627907, 0.6000572573718866]\n",
      "kmeans average accuracy best : 91.92%, kmeans average accuracy : 91.63126665%, total [0.9766647694934547, 0.9775695627484384, 0.9746908254242163, 0.9654576856649395, 0.9627565982404692, 0.9551136363636363, 0.920844327176781, 0.8556437889960294, 0.9713272243570795, 0.9338747099767981, 0.8617511520737328, 0.7864674868189807, 0.9583828775267539, 0.9344309647602542, 0.8625, 0.7635270541082164]\n",
      "cluster_accuracy_post_training_cycle_all_dataset : [0.97965941 0.97785108 0.97544535 0.96673095 0.9641791  0.94811321\n",
      " 0.92143212 0.84713076 0.96822995 0.94091797 0.84073359 0.78947368\n",
      " 0.9592668  0.93549952 0.85539216 0.77735308]\n",
      "mean_cluster_accuracy_during_training_cycle : 90.91%, post_traincycle_acc : 91.55%, total_acc : 91.28583926%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 91.73%\n",
      "accuracy_check 실행 시간: 24.410초\n",
      "\n",
      "\n",
      "epoch-9 loss : 0.00840508, loss_normal : 0.01167893, loss_coarse : 0.05381024, min_loss : 0.00840508, min_loss_normal : 0.01167893, min_loss_coarse : 0.05381024, wrong_element_sum : 10331566.00000000, same_data : 0.00%\n",
      "ae train 실행 시간: 117.584초, 전체 시작 시간 20250314_000238_046\n",
      "\n",
      "epoch-9 accuracy check\n",
      "k_means origin feature average accuracy : 82.24772089%, total [0.9746727376209448, 0.9733106189664963, 0.9700891573195284, 0.9530800230282096, 0.943108504398827, 0.9150568181818182, 0.8015244796247435, 0.6625070901871809, 0.9488619568430388, 0.822215777262181, 0.5866935483870968, 0.5005858230814294, 0.9429250891795482, 0.8922588099364529, 0.673546511627907, 0.5991983967935872]\n",
      "kmeans average accuracy best : 91.92%, kmeans average accuracy : 91.69192964%, total [0.9769493454752419, 0.9778534923339012, 0.9746908254242163, 0.9648819804260219, 0.964516129032258, 0.9534090909090909, 0.920257988859572, 0.8519568916619399, 0.9686668637304168, 0.9289443155452436, 0.8591589861751152, 0.7964264792032806, 0.9589774078478003, 0.9358752166377816, 0.8686046511627907, 0.7695390781563126]\n",
      "cluster_accuracy_post_training_cycle_all_dataset : [0.97965941 0.97785108 0.97544535 0.96769527 0.96467662 0.9490566\n",
      " 0.92342118 0.84148636 0.94452849 0.93701172 0.81998069 0.80089374\n",
      " 0.95977597 0.93598448 0.86715686 0.77783086]\n",
      "mean_cluster_accuracy_during_training_cycle : 90.70%, post_traincycle_acc : 91.39%, total_acc : 91.10735061%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 91.73%\n",
      "accuracy_check 실행 시간: 24.492초\n",
      "\n",
      "\n",
      "epoch-10 loss : 0.00832328, loss_normal : 0.01164536, loss_coarse : 0.05355025, min_loss : 0.00832328, min_loss_normal : 0.01164536, min_loss_coarse : 0.05355025, wrong_element_sum : 10281648.00000000, same_data : 0.00%\n",
      "ae train 실행 시간: 121.685초, 전체 시작 시간 20250314_000238_046\n",
      "\n",
      "epoch-10 accuracy check\n",
      "k_means origin feature average accuracy : 82.25675468%, total [0.9746727376209448, 0.9733106189664963, 0.9700891573195284, 0.9530800230282096, 0.943108504398827, 0.9150568181818182, 0.801817648783348, 0.6622234826999432, 0.9488619568430388, 0.822215777262181, 0.5866935483870968, 0.5005858230814294, 0.9429250891795482, 0.8922588099364529, 0.6738372093023256, 0.6003435442313197]\n",
      "kmeans average accuracy best : 91.92%, kmeans average accuracy : 91.53863888%, total [0.9769493454752419, 0.9778534923339012, 0.9746908254242163, 0.9643062751871042, 0.9636363636363636, 0.9565340909090909, 0.9217238346525946, 0.8556437889960294, 0.9689624593556015, 0.9303944315545244, 0.8392857142857143, 0.7867603983596954, 0.9583828775267539, 0.9352975158867707, 0.8625, 0.7732608073289436]\n",
      "cluster_accuracy_post_training_cycle_all_dataset : [0.97918638 0.97785108 0.97448243 0.96673095 0.96517413 0.9509434\n",
      " 0.92441571 0.84571966 0.95310136 0.93554688 0.82625483 0.77805362\n",
      " 0.9607943  0.93258972 0.85931373 0.78690874]\n",
      "mean_cluster_accuracy_during_training_cycle : 90.97%, post_traincycle_acc : 91.36%, total_acc : 91.19747484%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 91.73%\n",
      "accuracy_check 실행 시간: 24.629초\n",
      "\n",
      "\n",
      "epoch-11 loss : 0.00826428, loss_normal : 0.01163131, loss_coarse : 0.05342106, min_loss : 0.00826428, min_loss_normal : 0.01163131, min_loss_coarse : 0.05342106, wrong_element_sum : 10256844.00000000, same_data : 0.00%\n",
      "ae train 실행 시간: 118.002초, 전체 시작 시간 20250314_000238_046\n",
      "\n",
      "epoch-11 accuracy check\n",
      "k_means origin feature average accuracy : 82.25492108%, total [0.9746727376209448, 0.9733106189664963, 0.9700891573195284, 0.9530800230282096, 0.943108504398827, 0.9150568181818182, 0.801817648783348, 0.6625070901871809, 0.9488619568430388, 0.822215777262181, 0.5866935483870968, 0.5005858230814294, 0.9429250891795482, 0.8922588099364529, 0.673546511627907, 0.6000572573718866]\n",
      "kmeans average accuracy best : 91.92%, kmeans average accuracy : 91.81436598%, total [0.9766647694934547, 0.9778534923339012, 0.9746908254242163, 0.9648819804260219, 0.9642228739002933, 0.9579545454545455, 0.9325710935209616, 0.8667044809982983, 0.9663020987289388, 0.9225638051044084, 0.8352534562211982, 0.7823667252489748, 0.9589774078478003, 0.9370306181398036, 0.8718023255813954, 0.800458058975093]\n",
      "cluster_accuracy_post_training_cycle_all_dataset : [0.9782403  0.97832234 0.97496389 0.96721311 0.96716418 0.95377358\n",
      " 0.93286922 0.85418627 0.95663137 0.93261719 0.81611969 0.7795432\n",
      " 0.9592668  0.93404462 0.86127451 0.81557573]\n",
      "mean_cluster_accuracy_during_training_cycle : 91.29%, post_traincycle_acc : 91.64%, total_acc : 91.49282382%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 91.73%\n",
      "accuracy_check 실행 시간: 24.470초\n",
      "\n",
      "\n",
      "epoch-12 loss : 0.00821535, loss_normal : 0.01162301, loss_coarse : 0.05329572, min_loss : 0.00821535, min_loss_normal : 0.01162301, min_loss_coarse : 0.05329572, wrong_element_sum : 10232778.00000000, same_data : 0.00%\n",
      "ae train 실행 시간: 120.176초, 전체 시작 시간 20250314_000238_046\n",
      "\n",
      "epoch-12 accuracy check\n",
      "k_means origin feature average accuracy : 82.24955320%, total [0.9746727376209448, 0.9733106189664963, 0.9700891573195284, 0.9530800230282096, 0.943108504398827, 0.9150568181818182, 0.801817648783348, 0.6625070901871809, 0.9488619568430388, 0.822215777262181, 0.5866935483870968, 0.5005858230814294, 0.9429250891795482, 0.8922588099364529, 0.673546511627907, 0.5991983967935872]\n",
      "kmeans average accuracy best : 91.92%, kmeans average accuracy : 91.85285275%, total [0.9766647694934547, 0.9778534923339012, 0.9744032211676733, 0.9643062751871042, 0.9633431085043989, 0.9588068181818182, 0.9293462327763119, 0.8635847986386841, 0.969553650605971, 0.9350348027842227, 0.8404377880184332, 0.7776801405975395, 0.9598692033293698, 0.9393414211438474, 0.8706395348837209, 0.7955911823647295]\n",
      "cluster_accuracy_post_training_cycle_all_dataset : [0.97918638 0.97832234 0.97496389 0.96769527 0.9641791  0.9509434\n",
      " 0.93585281 0.85700847 0.96066566 0.94189453 0.82287645 0.78202582\n",
      " 0.96130346 0.93501455 0.86568627 0.79980889]\n",
      "mean_cluster_accuracy_during_training_cycle : 91.26%, post_traincycle_acc : 91.73%, total_acc : 91.54097636%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 91.73%\n",
      "accuracy_check 실행 시간: 24.392초\n",
      "\n",
      "\n",
      "epoch-13 loss : 0.00818037, loss_normal : 0.01160079, loss_coarse : 0.05314082, min_loss : 0.00818037, min_loss_normal : 0.01160079, min_loss_coarse : 0.05314082, wrong_element_sum : 10203038.00000000, same_data : 0.00%\n",
      "ae train 실행 시간: 119.505초, 전체 시작 시간 20250314_000238_046\n",
      "\n",
      "epoch-13 accuracy check\n",
      "k_means origin feature average accuracy : 82.25315343%, total [0.9746727376209448, 0.9733106189664963, 0.9700891573195284, 0.9530800230282096, 0.943108504398827, 0.9150568181818182, 0.801817648783348, 0.6625070901871809, 0.9488619568430388, 0.822215777262181, 0.5872695852534562, 0.5005858230814294, 0.9429250891795482, 0.8922588099364529, 0.673546511627907, 0.5991983967935872]\n",
      "kmeans average accuracy best : 91.92%, kmeans average accuracy : 91.68657617%, total [0.9766647694934547, 0.9778534923339012, 0.9744032211676733, 0.9634427173287277, 0.9633431085043989, 0.9579545454545455, 0.9293462327763119, 0.8581962563811685, 0.969553650605971, 0.9295243619489559, 0.8433179723502304, 0.7814879906268307, 0.9607609988109393, 0.9387637203928365, 0.8645348837209302, 0.7807042656742056]\n",
      "cluster_accuracy_post_training_cycle_all_dataset : [0.97918638 0.97832234 0.97544535 0.96673095 0.9641791  0.9504717\n",
      " 0.93485828 0.84571966 0.96419566 0.94091797 0.81225869 0.7959285\n",
      " 0.96232179 0.93161979 0.85980392 0.79216436]\n",
      "mean_cluster_accuracy_during_training_cycle : 91.03%, post_traincycle_acc : 91.59%, total_acc : 91.35640865%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 91.73%\n",
      "accuracy_check 실행 시간: 23.976초\n",
      "\n",
      "\n",
      "epoch-14 loss : 0.00817168, loss_normal : 0.01160331, loss_coarse : 0.05313769, min_loss : 0.00817168, min_loss_normal : 0.01160079, min_loss_coarse : 0.05313769, wrong_element_sum : 10202436.00000000, same_data : 0.00%\n",
      "ae train 실행 시간: 118.421초, 전체 시작 시간 20250314_000238_046\n",
      "\n",
      "epoch-14 accuracy check\n",
      "k_means origin feature average accuracy : 82.26215503%, total [0.9746727376209448, 0.9733106189664963, 0.9700891573195284, 0.9530800230282096, 0.943108504398827, 0.9150568181818182, 0.801817648783348, 0.6625070901871809, 0.9488619568430388, 0.822215777262181, 0.5872695852534562, 0.5005858230814294, 0.9429250891795482, 0.8922588099364529, 0.6741279069767442, 0.6000572573718866]\n",
      "kmeans average accuracy best : 91.92%, kmeans average accuracy : 91.46596128%, total [0.9763801935116676, 0.9775695627484384, 0.9744032211676733, 0.9648819804260219, 0.9656891495601173, 0.9559659090909091, 0.9278803869832893, 0.8556437889960294, 0.9654153118533846, 0.9274941995359629, 0.8519585253456221, 0.7858816637375513, 0.9545184304399524, 0.9272097053726169, 0.8575581395348837, 0.7661036358431148]\n",
      "cluster_accuracy_post_training_cycle_all_dataset : [0.97918638 0.97785108 0.97496389 0.96769527 0.96517413 0.95188679\n",
      " 0.92938836 0.84571966 0.95461422 0.93994141 0.81805019 0.78351539\n",
      " 0.95621181 0.92725509 0.85735294 0.79550884]\n",
      "mean_cluster_accuracy_during_training_cycle : 90.82%, post_traincycle_acc : 91.40%, total_acc : 91.16224691%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 91.73%\n",
      "accuracy_check 실행 시간: 24.401초\n",
      "\n",
      "\n",
      "epoch-15 loss : 0.00815003, loss_normal : 0.01159183, loss_coarse : 0.05308628, min_loss : 0.00815003, min_loss_normal : 0.01159183, min_loss_coarse : 0.05308628, wrong_element_sum : 10192566.00000000, same_data : 0.00%\n",
      "ae train 실행 시간: 119.896초, 전체 시작 시간 20250314_000238_046\n",
      "\n",
      "epoch-15 accuracy check\n",
      "k_means origin feature average accuracy : 82.26035923%, total [0.9746727376209448, 0.9733106189664963, 0.9700891573195284, 0.9530800230282096, 0.943108504398827, 0.915340909090909, 0.8015244796247435, 0.6622234826999432, 0.9488619568430388, 0.822215777262181, 0.5866935483870968, 0.5005858230814294, 0.9429250891795482, 0.8922588099364529, 0.6747093023255814, 0.6000572573718866]\n",
      "kmeans average accuracy best : 91.92%, kmeans average accuracy : 91.74149546%, total [0.9766647694934547, 0.9778534923339012, 0.9744032211676733, 0.9637305699481865, 0.9639296187683285, 0.9571022727272728, 0.9278803869832893, 0.8627339761769711, 0.9627549512267218, 0.9312645011600929, 0.8505184331797235, 0.7893966022261277, 0.9586801426872771, 0.9338532640092432, 0.8683139534883721, 0.779559118236473]\n",
      "cluster_accuracy_post_training_cycle_all_dataset : [0.97918638 0.97832234 0.97544535 0.96576663 0.96467662 0.95235849\n",
      " 0.93038289 0.85606773 0.94856278 0.93847656 0.82094595 0.78947368\n",
      " 0.9592668  0.93452958 0.87107843 0.79407549]\n",
      "mean_cluster_accuracy_during_training_cycle : 90.89%, post_traincycle_acc : 91.62%, total_acc : 91.32063710%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 91.73%\n",
      "accuracy_check 실행 시간: 23.992초\n",
      "\n",
      "\n",
      "epoch-16 loss : 0.00811344, loss_normal : 0.01158797, loss_coarse : 0.05304335, min_loss : 0.00811344, min_loss_normal : 0.01158797, min_loss_coarse : 0.05304335, wrong_element_sum : 10184324.00000000, same_data : 0.00%\n",
      "ae train 실행 시간: 107.880초, 전체 시작 시간 20250314_000238_046\n",
      "\n",
      "epoch-16 accuracy check\n",
      "k_means origin feature average accuracy : 82.24954197%, total [0.9746727376209448, 0.9733106189664963, 0.9700891573195284, 0.9530800230282096, 0.943108504398827, 0.9150568181818182, 0.8015244796247435, 0.6625070901871809, 0.9488619568430388, 0.8219257540603249, 0.5866935483870968, 0.5005858230814294, 0.9429250891795482, 0.8922588099364529, 0.6741279069767442, 0.5991983967935872]\n",
      "kmeans average accuracy best : 91.92%, kmeans average accuracy : 91.90582860%, total [0.9766647694934547, 0.978137421919364, 0.9746908254242163, 0.9654576856649395, 0.9653958944281525, 0.9576704545454545, 0.9290530636177075, 0.8672716959727736, 0.9680756724800473, 0.9289443155452436, 0.8516705069124424, 0.794083186877563, 0.9565992865636147, 0.9373194685153091, 0.8691860465116279, 0.7847122817062697]\n",
      "cluster_accuracy_post_training_cycle_all_dataset : [0.97918638 0.97785108 0.97544535 0.96721311 0.96666667 0.95566038\n",
      " 0.93286922 0.85983067 0.95007564 0.93505859 0.82287645 0.79344588\n",
      " 0.96028513 0.93549952 0.86421569 0.79503106]\n",
      "mean_cluster_accuracy_during_training_cycle : 90.76%, post_traincycle_acc : 91.70%, total_acc : 91.31186654%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 91.73%\n",
      "accuracy_check 실행 시간: 24.159초\n",
      "\n",
      "\n",
      "epoch-17 loss : 0.00809047, loss_normal : 0.01156780, loss_coarse : 0.05291121, min_loss : 0.00809047, min_loss_normal : 0.01156780, min_loss_coarse : 0.05291121, wrong_element_sum : 10158952.00000000, same_data : 0.00%\n",
      "ae train 실행 시간: 120.467초, 전체 시작 시간 20250314_000238_046\n",
      "\n",
      "epoch-17 accuracy check\n",
      "k_means origin feature average accuracy : 82.25329719%, total [0.9746727376209448, 0.9733106189664963, 0.9700891573195284, 0.9530800230282096, 0.943108504398827, 0.9150568181818182, 0.801817648783348, 0.6625070901871809, 0.9488619568430388, 0.822215777262181, 0.5866935483870968, 0.5005858230814294, 0.9429250891795482, 0.8922588099364529, 0.6752906976744186, 0.5980532493558546]\n",
      "kmeans average accuracy best : 91.92%, kmeans average accuracy : 91.84936217%, total [0.9766647694934547, 0.9775695627484384, 0.9746908254242163, 0.9651698330454808, 0.9653958944281525, 0.9582386363636364, 0.931691586045148, 0.8641520136131594, 0.967188885604493, 0.9182134570765661, 0.841589861751152, 0.7820738137082601, 0.9625445897740785, 0.9410745233968805, 0.8688953488372093, 0.8007443458345262]\n",
      "cluster_accuracy_post_training_cycle_all_dataset : [0.97918638 0.97785108 0.97544535 0.96721311 0.96616915 0.95283019\n",
      " 0.93535554 0.8607714  0.94301563 0.921875   0.81563707 0.77308838\n",
      " 0.96283096 0.94180407 0.87205882 0.80028667]\n",
      "mean_cluster_accuracy_during_training_cycle : 91.24%, post_traincycle_acc : 91.53%, total_acc : 91.41465817%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 91.73%\n",
      "accuracy_check 실행 시간: 24.213초\n",
      "\n",
      "\n",
      "epoch-18 loss : 0.00806238, loss_normal : 0.01155940, loss_coarse : 0.05282569, min_loss : 0.00806238, min_loss_normal : 0.01155940, min_loss_coarse : 0.05282569, wrong_element_sum : 10142532.00000000, same_data : 0.00%\n",
      "ae train 실행 시간: 118.832초, 전체 시작 시간 20250314_000238_046\n",
      "\n",
      "epoch-18 accuracy check\n",
      "k_means origin feature average accuracy : 82.25318692%, total [0.9746727376209448, 0.9733106189664963, 0.9700891573195284, 0.9530800230282096, 0.943108504398827, 0.9150568181818182, 0.801817648783348, 0.6625070901871809, 0.9488619568430388, 0.822215777262181, 0.5866935483870968, 0.5005858230814294, 0.9429250891795482, 0.8922588099364529, 0.6741279069767442, 0.5991983967935872]\n",
      "save model\n",
      "kmeans average accuracy best : 92.02%, kmeans average accuracy : 92.02310901%, total [0.9763801935116676, 0.9775695627484384, 0.9744032211676733, 0.9645941278065631, 0.9639296187683285, 0.9590909090909091, 0.9290530636177075, 0.8658536585365854, 0.9701448418563405, 0.9286542923433875, 0.8600230414746544, 0.7908611599297012, 0.9589774078478003, 0.940785673021375, 0.8712209302325581, 0.7921557400515317]\n",
      "cluster_accuracy_post_training_cycle_all_dataset : [0.97918638 0.97785108 0.97544535 0.96673095 0.96517413 0.95424528\n",
      " 0.9288911  0.85700847 0.95965709 0.93798828 0.84121622 0.79344588\n",
      " 0.9607943  0.94180407 0.87941176 0.80649785]\n",
      "mean_cluster_accuracy_during_training_cycle : 91.10%, post_traincycle_acc : 92.03%, total_acc : 91.65229764%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 92.03%\n",
      "accuracy_check 실행 시간: 24.000초\n",
      "\n",
      "\n",
      "epoch-19 loss : 0.00804587, loss_normal : 0.01156026, loss_coarse : 0.05285760, min_loss : 0.00804587, min_loss_normal : 0.01155940, min_loss_coarse : 0.05282569, wrong_element_sum : 10148660.00000000, same_data : 0.00%\n",
      "ae train 실행 시간: 119.137초, 전체 시작 시간 20250314_000238_046\n",
      "\n",
      "epoch-19 accuracy check\n",
      "k_means origin feature average accuracy : 82.26041597%, total [0.9746727376209448, 0.9733106189664963, 0.9700891573195284, 0.9530800230282096, 0.943108504398827, 0.9150568181818182, 0.801817648783348, 0.6622234826999432, 0.9488619568430388, 0.822215777262181, 0.5866935483870968, 0.5005858230814294, 0.9429250891795482, 0.8922588099364529, 0.6747093023255814, 0.6000572573718866]\n",
      "save model\n",
      "kmeans average accuracy best : 92.23%, kmeans average accuracy : 92.23030116%, total [0.9766647694934547, 0.9775695627484384, 0.9746908254242163, 0.9640184225676454, 0.9636363636363636, 0.9565340909090909, 0.9281735561418939, 0.86528644356211, 0.97073603310671, 0.9390951276102089, 0.8646313364055299, 0.8005272407732865, 0.9580856123662307, 0.9436741767764298, 0.8796511627906977, 0.7938734612081305]\n",
      "cluster_accuracy_post_training_cycle_all_dataset : [0.97918638 0.97785108 0.97496389 0.96576663 0.96567164 0.9509434\n",
      " 0.93336648 0.8565381  0.96570852 0.95117188 0.83928571 0.78798411\n",
      " 0.95875764 0.94277401 0.87647059 0.81127568]\n",
      "mean_cluster_accuracy_during_training_cycle : 91.29%, post_traincycle_acc : 92.11%, total_acc : 91.77557095%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 92.11%\n",
      "accuracy_check 실행 시간: 24.597초\n",
      "\n",
      "\n",
      "epoch-20 loss : 0.00800893, loss_normal : 0.01153961, loss_coarse : 0.05270349, min_loss : 0.00800893, min_loss_normal : 0.01153961, min_loss_coarse : 0.05270349, wrong_element_sum : 10119070.00000000, same_data : 0.00%\n",
      "ae train 실행 시간: 118.187초, 전체 시작 시간 20250314_000238_046\n",
      "\n",
      "epoch-20 accuracy check\n",
      "k_means origin feature average accuracy : 82.26035782%, total [0.9746727376209448, 0.9733106189664963, 0.9700891573195284, 0.9530800230282096, 0.943108504398827, 0.9150568181818182, 0.801817648783348, 0.6625070901871809, 0.9488619568430388, 0.822215777262181, 0.5866935483870968, 0.5002929115407148, 0.9429250891795482, 0.8922588099364529, 0.6747093023255814, 0.6000572573718866]\n",
      "save model\n",
      "kmeans average accuracy best : 92.30%, kmeans average accuracy : 92.30082883%, total [0.9766647694934547, 0.9778534923339012, 0.9746908254242163, 0.9645941278065631, 0.9668621700879766, 0.9605113636363637, 0.9290530636177075, 0.8746454906409529, 0.9698492462311558, 0.9390951276102089, 0.8657834101382489, 0.804920913884007, 0.9560047562425684, 0.9350086655112652, 0.875, 0.7975951903807615]\n",
      "cluster_accuracy_post_training_cycle_all_dataset : [0.97965941 0.97785108 0.97544535 0.96673095 0.9681592  0.95424528\n",
      " 0.93038289 0.86829727 0.96066566 0.94775391 0.83349421 0.80089374\n",
      " 0.95672098 0.93598448 0.87598039 0.81318681]\n",
      "mean_cluster_accuracy_during_training_cycle : 91.36%, post_traincycle_acc : 92.16%, total_acc : 91.83344606%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 92.16%\n",
      "accuracy_check 실행 시간: 23.861초\n",
      "\n",
      "\n",
      "epoch-21 loss : 0.00799348, loss_normal : 0.01153266, loss_coarse : 0.05267178, min_loss : 0.00799348, min_loss_normal : 0.01153266, min_loss_coarse : 0.05267178, wrong_element_sum : 10112982.00000000, same_data : 0.00%\n",
      "ae train 실행 시간: 120.195초, 전체 시작 시간 20250314_000238_046\n",
      "\n",
      "epoch-21 accuracy check\n",
      "k_means origin feature average accuracy : 82.24422371%, total [0.9746727376209448, 0.9733106189664963, 0.9700891573195284, 0.9530800230282096, 0.943108504398827, 0.9150568181818182, 0.801817648783348, 0.6622234826999432, 0.9488619568430388, 0.822215777262181, 0.5872695852534562, 0.5005858230814294, 0.9429250891795482, 0.8922588099364529, 0.673546511627907, 0.5980532493558546]\n",
      "kmeans average accuracy best : 92.30%, kmeans average accuracy : 92.21507321%, total [0.9763801935116676, 0.9772856331629756, 0.9744032211676733, 0.9648819804260219, 0.9659824046920821, 0.9579545454545455, 0.9287598944591029, 0.8564946114577425, 0.9704404374815253, 0.9332946635730859, 0.8683755760368663, 0.8008201523140012, 0.9586801426872771, 0.9399191218948585, 0.8834302325581396, 0.7973089035213283]\n",
      "cluster_accuracy_post_training_cycle_all_dataset : [0.97871334 0.97785108 0.97496389 0.96673095 0.96865672 0.95377358\n",
      " 0.93436101 0.8565381  0.9626828  0.94091797 0.83397683 0.80287984\n",
      " 0.9592668  0.93840931 0.87941176 0.80602007]\n",
      "mean_cluster_accuracy_during_training_cycle : 90.97%, post_traincycle_acc : 92.09%, total_acc : 91.63519478%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 92.16%\n",
      "accuracy_check 실행 시간: 24.287초\n",
      "\n",
      "\n",
      "epoch-22 loss : 0.00800841, loss_normal : 0.01154267, loss_coarse : 0.05278510, min_loss : 0.00799348, min_loss_normal : 0.01153266, min_loss_coarse : 0.05267178, wrong_element_sum : 10134740.00000000, same_data : 0.00%\n",
      "ae train 실행 시간: 116.779초, 전체 시작 시간 20250314_000238_046\n",
      "\n",
      "epoch-22 accuracy check\n",
      "k_means origin feature average accuracy : 82.25502672%, total [0.9746727376209448, 0.9733106189664963, 0.9700891573195284, 0.9530800230282096, 0.943108504398827, 0.9150568181818182, 0.8015244796247435, 0.6622234826999432, 0.9488619568430388, 0.822215777262181, 0.5872695852534562, 0.5005858230814294, 0.9429250891795482, 0.8922588099364529, 0.6747093023255814, 0.598912109934154]\n",
      "kmeans average accuracy best : 92.30%, kmeans average accuracy : 91.80017018%, total [0.9763801935116676, 0.9778534923339012, 0.9746908254242163, 0.9660333909038572, 0.9659824046920821, 0.9571022727272728, 0.9331574318381706, 0.8630175836642088, 0.9651197162281998, 0.9190835266821346, 0.8493663594470046, 0.7961335676625659, 0.9589774078478003, 0.9341421143847487, 0.8659883720930233, 0.7849985685657028]\n",
      "cluster_accuracy_post_training_cycle_all_dataset : [0.97871334 0.97785108 0.97496389 0.96865959 0.96666667 0.9509434\n",
      " 0.93436101 0.85324553 0.94553707 0.93261719 0.80598456 0.78947368\n",
      " 0.96181263 0.93937924 0.87254902 0.79885332]\n",
      "mean_cluster_accuracy_during_training_cycle : 90.55%, post_traincycle_acc : 91.57%, total_acc : 91.15287023%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 92.16%\n",
      "accuracy_check 실행 시간: 24.860초\n",
      "\n",
      "\n",
      "epoch-23 loss : 0.00798020, loss_normal : 0.01153086, loss_coarse : 0.05267151, min_loss : 0.00798020, min_loss_normal : 0.01153086, min_loss_coarse : 0.05267151, wrong_element_sum : 10112930.00000000, same_data : 0.00%\n",
      "ae train 실행 시간: 120.793초, 전체 시작 시간 20250314_000238_046\n",
      "\n",
      "epoch-23 accuracy check\n",
      "k_means origin feature average accuracy : 82.25685903%, total [0.9746727376209448, 0.9733106189664963, 0.9700891573195284, 0.9530800230282096, 0.943108504398827, 0.9150568181818182, 0.801817648783348, 0.6622234826999432, 0.9488619568430388, 0.822215777262181, 0.5872695852534562, 0.5005858230814294, 0.9429250891795482, 0.8922588099364529, 0.6747093023255814, 0.598912109934154]\n",
      "save model\n",
      "kmeans average accuracy best : 92.31%, kmeans average accuracy : 92.30610532%, total [0.9763801935116676, 0.9778534923339012, 0.9744032211676733, 0.9640184225676454, 0.9651026392961877, 0.9573863636363636, 0.9296394019349165, 0.8633011911514464, 0.9689624593556015, 0.9367749419953596, 0.8709677419354839, 0.819859402460457, 0.960166468489893, 0.939630271519353, 0.8718023255813954, 0.792728313770398]\n",
      "cluster_accuracy_post_training_cycle_all_dataset : [0.97871334 0.97785108 0.97544535 0.96673095 0.9681592  0.95471698\n",
      " 0.93187469 0.8537159  0.95461422 0.94335938 0.84266409 0.61866931\n",
      " 0.96130346 0.93598448 0.86911765 0.79885332]\n",
      "mean_cluster_accuracy_during_training_cycle : 89.94%, post_traincycle_acc : 90.82%, total_acc : 90.46093546%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 90.82%\n",
      "accuracy_check 실행 시간: 24.022초\n",
      "\n",
      "\n",
      "epoch-24 loss : 0.00797991, loss_normal : 0.01152356, loss_coarse : 0.05265012, min_loss : 0.00797991, min_loss_normal : 0.01152356, min_loss_coarse : 0.05265012, wrong_element_sum : 10108824.00000000, same_data : 0.00%\n",
      "ae train 실행 시간: 113.891초, 전체 시작 시간 20250314_000238_046\n",
      "\n",
      "epoch-24 accuracy check\n",
      "k_means origin feature average accuracy : 82.25318692%, total [0.9746727376209448, 0.9733106189664963, 0.9700891573195284, 0.9530800230282096, 0.943108504398827, 0.9150568181818182, 0.801817648783348, 0.6625070901871809, 0.9488619568430388, 0.822215777262181, 0.5866935483870968, 0.5005858230814294, 0.9429250891795482, 0.8922588099364529, 0.6741279069767442, 0.5991983967935872]\n",
      "kmeans average accuracy best : 92.31%, kmeans average accuracy : 92.24539630%, total [0.9763801935116676, 0.9778534923339012, 0.9746908254242163, 0.9654576856649395, 0.9671554252199414, 0.9602272727272727, 0.9313984168865436, 0.8740782756664776, 0.963641738102276, 0.9245939675174014, 0.8623271889400922, 0.8163444639718805, 0.960166468489893, 0.9315424610051993, 0.8718023255813954, 0.8016032064128257]\n",
      "cluster_accuracy_post_training_cycle_all_dataset : [0.97965941 0.97785108 0.97496389 0.96673095 0.9681592  0.95707547\n",
      " 0.92988563 0.86453434 0.94351992 0.93701172 0.82915058 0.80238332\n",
      " 0.96181263 0.93307468 0.88039216 0.81509795]\n",
      "mean_cluster_accuracy_during_training_cycle : 91.16%, post_traincycle_acc : 92.01%, total_acc : 91.65957102%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 90.82%\n",
      "accuracy_check 실행 시간: 24.491초\n",
      "\n",
      "\n",
      "epoch-25 loss : 0.00796491, loss_normal : 0.01151165, loss_coarse : 0.05256406, min_loss : 0.00796491, min_loss_normal : 0.01151165, min_loss_coarse : 0.05256406, wrong_element_sum : 10092300.00000000, same_data : 0.00%\n",
      "ae train 실행 시간: 115.461초, 전체 시작 시간 20250314_000238_046\n",
      "\n",
      "epoch-25 accuracy check\n",
      "k_means origin feature average accuracy : 82.24776520%, total [0.9746727376209448, 0.9733106189664963, 0.9700891573195284, 0.9530800230282096, 0.943108504398827, 0.9150568181818182, 0.8015244796247435, 0.6622234826999432, 0.9488619568430388, 0.822215777262181, 0.5866935483870968, 0.5005858230814294, 0.9429250891795482, 0.8922588099364529, 0.6738372093023256, 0.5991983967935872]\n",
      "kmeans average accuracy best : 92.31%, kmeans average accuracy : 92.18184397%, total [0.9760956175298805, 0.9775695627484384, 0.9746908254242163, 0.9640184225676454, 0.9642228739002933, 0.9599431818181818, 0.9275872178246849, 0.8635847986386841, 0.967188885604493, 0.9364849187935035, 0.8672235023041475, 0.8204452255418864, 0.9563020214030915, 0.9309647602541883, 0.8691860465116279, 0.7935871743486974]\n",
      "cluster_accuracy_post_training_cycle_all_dataset : [0.97871334 0.97832234 0.97496389 0.96673095 0.96567164 0.95424528\n",
      " 0.93137742 0.85136406 0.95461422 0.94482422 0.83445946 0.81578947\n",
      " 0.9607943  0.93016489 0.86715686 0.80554228]\n",
      "mean_cluster_accuracy_during_training_cycle : 91.50%, post_traincycle_acc : 91.97%, total_acc : 91.77673633%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 90.82%\n",
      "accuracy_check 실행 시간: 24.493초\n",
      "\n",
      "\n",
      "epoch-26 loss : 0.00794786, loss_normal : 0.01150586, loss_coarse : 0.05254046, min_loss : 0.00794786, min_loss_normal : 0.01150586, min_loss_coarse : 0.05254046, wrong_element_sum : 10087768.00000000, same_data : 0.00%\n",
      "ae train 실행 시간: 118.446초, 전체 시작 시간 20250314_000238_046\n",
      "\n",
      "epoch-26 accuracy check\n",
      "k_means origin feature average accuracy : 82.24239603%, total [0.9746727376209448, 0.9733106189664963, 0.9700891573195284, 0.9530800230282096, 0.943108504398827, 0.9150568181818182, 0.801817648783348, 0.6625070901871809, 0.9488619568430388, 0.822215777262181, 0.5866935483870968, 0.5005858230814294, 0.9429250891795482, 0.8922588099364529, 0.673546511627907, 0.5980532493558546]\n",
      "save model\n",
      "kmeans average accuracy best : 92.32%, kmeans average accuracy : 92.31566206%, total [0.9760956175298805, 0.9772856331629756, 0.9744032211676733, 0.9637305699481865, 0.9656891495601173, 0.959659090909091, 0.9278803869832893, 0.86528644356211, 0.9686668637304168, 0.9422853828306265, 0.8729838709677419, 0.8242530755711776, 0.9613555291319857, 0.9387637203928365, 0.8683139534883721, 0.7838534211279702]\n",
      "cluster_accuracy_post_training_cycle_all_dataset : [0.9782403  0.97785108 0.97448243 0.96673095 0.96567164 0.95471698\n",
      " 0.93336648 0.86735654 0.9591528  0.94335938 0.84121622 0.8123138\n",
      " 0.96181263 0.93404462 0.8745098  0.80745342]\n",
      "mean_cluster_accuracy_during_training_cycle : 91.17%, post_traincycle_acc : 92.20%, total_acc : 91.77718929%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 92.20%\n",
      "accuracy_check 실행 시간: 24.363초\n",
      "\n",
      "\n",
      "epoch-27 loss : 0.00794334, loss_normal : 0.01150621, loss_coarse : 0.05254749, min_loss : 0.00794334, min_loss_normal : 0.01150586, min_loss_coarse : 0.05254046, wrong_element_sum : 10089118.00000000, same_data : 0.00%\n",
      "ae train 실행 시간: 116.877초, 전체 시작 시간 20250314_000238_046\n",
      "\n",
      "epoch-27 accuracy check\n",
      "k_means origin feature average accuracy : 82.24422792%, total [0.9746727376209448, 0.9733106189664963, 0.9700891573195284, 0.9530800230282096, 0.943108504398827, 0.9150568181818182, 0.8015244796247435, 0.6622234826999432, 0.9488619568430388, 0.822215777262181, 0.5866935483870968, 0.5002929115407148, 0.9429250891795482, 0.8922588099364529, 0.6747093023255814, 0.5980532493558546]\n",
      "save model\n",
      "kmeans average accuracy best : 92.48%, kmeans average accuracy : 92.47644573%, total [0.9763801935116676, 0.9775695627484384, 0.9746908254242163, 0.9640184225676454, 0.9668621700879766, 0.9605113636363637, 0.931105247727939, 0.869540555870675, 0.9689624593556015, 0.9477958236658933, 0.8862327188940092, 0.8280609256004686, 0.9557074910820452, 0.9306759098786829, 0.8642441860465117, 0.7938734612081305]\n",
      "cluster_accuracy_post_training_cycle_all_dataset : [0.9782403  0.97785108 0.97496389 0.96721311 0.9681592  0.95660377\n",
      " 0.93187469 0.86594544 0.96066566 0.95263672 0.8484556  0.8346574\n",
      " 0.95723014 0.93016489 0.86617647 0.80267559]\n",
      "mean_cluster_accuracy_during_training_cycle : 90.99%, post_traincycle_acc : 92.33%, total_acc : 91.78239377%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 92.33%\n",
      "accuracy_check 실행 시간: 24.497초\n",
      "\n",
      "\n",
      "epoch-28 loss : 0.00793808, loss_normal : 0.01149767, loss_coarse : 0.05251429, min_loss : 0.00793808, min_loss_normal : 0.01149767, min_loss_coarse : 0.05251429, wrong_element_sum : 10082744.00000000, same_data : 0.00%\n",
      "ae train 실행 시간: 120.034초, 전체 시작 시간 20250314_000238_046\n",
      "\n",
      "epoch-28 accuracy check\n",
      "k_means origin feature average accuracy : 82.24239603%, total [0.9746727376209448, 0.9733106189664963, 0.9700891573195284, 0.9530800230282096, 0.943108504398827, 0.9150568181818182, 0.801817648783348, 0.6625070901871809, 0.9488619568430388, 0.822215777262181, 0.5866935483870968, 0.5005858230814294, 0.9429250891795482, 0.8922588099364529, 0.673546511627907, 0.5980532493558546]\n",
      "kmeans average accuracy best : 92.48%, kmeans average accuracy : 92.33674940%, total [0.9763801935116676, 0.9772856331629756, 0.9746908254242163, 0.9651698330454808, 0.9665689149560117, 0.9616477272727273, 0.9308120785693345, 0.8647192285876347, 0.968371268105232, 0.941415313225058, 0.8663594470046083, 0.8245459871118922, 0.9580856123662307, 0.9347198151357596, 0.8723837209302325, 0.7907243057543659]\n",
      "cluster_accuracy_post_training_cycle_all_dataset : [0.9782403  0.97785108 0.97496389 0.96769527 0.96865672 0.95660377\n",
      " 0.93436101 0.86171214 0.9515885  0.94921875 0.83783784 0.82373386\n",
      " 0.95977597 0.93307468 0.87892157 0.81175346]\n",
      "mean_cluster_accuracy_during_training_cycle : 91.42%, post_traincycle_acc : 92.29%, total_acc : 91.93252377%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 92.33%\n",
      "accuracy_check 실행 시간: 24.048초\n",
      "\n",
      "\n",
      "epoch-29 loss : 0.00793220, loss_normal : 0.01150128, loss_coarse : 0.05252046, min_loss : 0.00793220, min_loss_normal : 0.01149767, min_loss_coarse : 0.05251429, wrong_element_sum : 10083928.00000000, same_data : 0.00%\n",
      "ae train 실행 시간: 121.019초, 전체 시작 시간 20250314_000238_046\n",
      "\n",
      "epoch-29 accuracy check\n",
      "k_means origin feature average accuracy : 82.25678225%, total [0.9746727376209448, 0.9733106189664963, 0.9700891573195284, 0.9530800230282096, 0.943108504398827, 0.9150568181818182, 0.801817648783348, 0.6622234826999432, 0.9488619568430388, 0.822215777262181, 0.5866935483870968, 0.5005858230814294, 0.9429250891795482, 0.8922588099364529, 0.6741279069767442, 0.6000572573718866]\n",
      "kmeans average accuracy best : 92.48%, kmeans average accuracy : 92.46803195%, total [0.9766647694934547, 0.9772856331629756, 0.9744032211676733, 0.9634427173287277, 0.9656891495601173, 0.9605113636363637, 0.9284667253004983, 0.8735110606920022, 0.967188885604493, 0.9411252900232019, 0.8824884792626728, 0.8265963678968952, 0.9568965517241379, 0.9376083188908145, 0.8656976744186047, 0.7973089035213283]\n",
      "cluster_accuracy_post_training_cycle_all_dataset : [0.97918638 0.97785108 0.97448243 0.96673095 0.96666667 0.95518868\n",
      " 0.93088016 0.85606773 0.95663137 0.94970703 0.8484556  0.81578947\n",
      " 0.95824847 0.93986421 0.86764706 0.80315337]\n",
      "mean_cluster_accuracy_during_training_cycle : 90.55%, post_traincycle_acc : 92.17%, total_acc : 91.50262623%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 92.33%\n",
      "accuracy_check 실행 시간: 24.461초\n",
      "\n",
      "\n",
      "epoch-30 loss : 0.00790870, loss_normal : 0.01148772, loss_coarse : 0.05241954, min_loss : 0.00790870, min_loss_normal : 0.01148772, min_loss_coarse : 0.05241954, wrong_element_sum : 10064552.00000000, same_data : 0.00%\n",
      "ae train 실행 시간: 115.428초, 전체 시작 시간 20250314_000238_046\n",
      "\n",
      "epoch-30 accuracy check\n",
      "k_means origin feature average accuracy : 82.26038248%, total [0.9746727376209448, 0.9733106189664963, 0.9700891573195284, 0.9530800230282096, 0.943108504398827, 0.9150568181818182, 0.801817648783348, 0.6622234826999432, 0.9488619568430388, 0.822215777262181, 0.5872695852534562, 0.5005858230814294, 0.9429250891795482, 0.8922588099364529, 0.6741279069767442, 0.6000572573718866]\n",
      "kmeans average accuracy best : 92.48%, kmeans average accuracy : 92.13921065%, total [0.9763801935116676, 0.9775695627484384, 0.9744032211676733, 0.9648819804260219, 0.9668621700879766, 0.9610795454545454, 0.9287598944591029, 0.8635847986386841, 0.964824120603015, 0.9382250580046404, 0.8744239631336406, 0.8145869947275922, 0.953923900118906, 0.9306759098786829, 0.8633720930232558, 0.7887202977383339]\n",
      "cluster_accuracy_post_training_cycle_all_dataset : [0.97871334 0.97832234 0.97496389 0.96769527 0.96915423 0.95330189\n",
      " 0.93088016 0.8508937  0.95763994 0.9453125  0.83156371 0.81578947\n",
      " 0.95621181 0.93210475 0.87058824 0.78786431]\n",
      "mean_cluster_accuracy_during_training_cycle : 91.12%, post_traincycle_acc : 91.88%, total_acc : 91.56758325%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 92.33%\n",
      "accuracy_check 실행 시간: 24.329초\n",
      "\n",
      "\n",
      "epoch-31 loss : 0.00789400, loss_normal : 0.01147433, loss_coarse : 0.05234312, min_loss : 0.00789400, min_loss_normal : 0.01147433, min_loss_coarse : 0.05234312, wrong_element_sum : 10049880.00000000, same_data : 0.00%\n",
      "ae train 실행 시간: 94.239초, 전체 시작 시간 20250314_000238_046\n",
      "\n",
      "epoch-31 accuracy check\n",
      "k_means origin feature average accuracy : 82.25141437%, total [0.9746727376209448, 0.9733106189664963, 0.9700891573195284, 0.9530800230282096, 0.943108504398827, 0.9150568181818182, 0.801817648783348, 0.6622234826999432, 0.9488619568430388, 0.822215777262181, 0.5866935483870968, 0.5005858230814294, 0.9429250891795482, 0.8922588099364529, 0.6741279069767442, 0.5991983967935872]\n",
      "kmeans average accuracy best : 92.48%, kmeans average accuracy : 92.43729289%, total [0.9760956175298805, 0.9775695627484384, 0.9744032211676733, 0.9645941278065631, 0.9659824046920821, 0.9607954545454546, 0.9293462327763119, 0.868689733408962, 0.9701448418563405, 0.9463457076566125, 0.880184331797235, 0.8239601640304628, 0.9571938168846611, 0.9387637203928365, 0.8688953488372093, 0.7870025765817349]\n",
      "cluster_accuracy_post_training_cycle_all_dataset : [0.9782403  0.97832234 0.97496389 0.96721311 0.96616915 0.95754717\n",
      " 0.93286922 0.85747883 0.95864851 0.95996094 0.83687259 0.59086395\n",
      " 0.9592668  0.93646945 0.86764706 0.80363115]\n",
      "mean_cluster_accuracy_during_training_cycle : 90.12%, post_traincycle_acc : 90.79%, total_acc : 90.51684263%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 92.33%\n",
      "accuracy_check 실행 시간: 24.109초\n",
      "\n",
      "\n",
      "epoch-32 loss : 0.00787789, loss_normal : 0.01147172, loss_coarse : 0.05232244, min_loss : 0.00787789, min_loss_normal : 0.01147172, min_loss_coarse : 0.05232244, wrong_element_sum : 10045908.00000000, same_data : 0.00%\n",
      "ae train 실행 시간: 112.320초, 전체 시작 시간 20250314_000238_046\n",
      "\n",
      "epoch-32 accuracy check\n",
      "k_means origin feature average accuracy : 82.25861244%, total [0.9746727376209448, 0.9733106189664963, 0.9700891573195284, 0.9530800230282096, 0.943108504398827, 0.9150568181818182, 0.801817648783348, 0.6625070901871809, 0.9488619568430388, 0.8216357308584686, 0.5872695852534562, 0.5005858230814294, 0.9429250891795482, 0.8922588099364529, 0.675, 0.5991983967935872]\n",
      "save model\n",
      "kmeans average accuracy best : 92.55%, kmeans average accuracy : 92.55354514%, total [0.9763801935116676, 0.9775695627484384, 0.9744032211676733, 0.9637305699481865, 0.9671554252199414, 0.9616477272727273, 0.931105247727939, 0.8757799205899036, 0.9716228199822643, 0.9396751740139211, 0.8706797235023042, 0.820738137082601, 0.9580856123662307, 0.9370306181398036, 0.8790697674418605, 0.8038935012882908]\n",
      "cluster_accuracy_post_training_cycle_all_dataset : [0.97871334 0.97785108 0.97448243 0.96576663 0.9681592  0.95660377\n",
      " 0.93336648 0.86453434 0.95864851 0.95117188 0.83494208 0.80139027\n",
      " 0.9592668  0.93016489 0.8754902  0.81318681]\n",
      "mean_cluster_accuracy_during_training_cycle : 90.62%, post_traincycle_acc : 92.15%, total_acc : 91.51917665%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 92.15%\n",
      "accuracy_check 실행 시간: 24.542초\n",
      "\n",
      "\n",
      "epoch-33 loss : 0.00787840, loss_normal : 0.01147273, loss_coarse : 0.05234375, min_loss : 0.00787789, min_loss_normal : 0.01147172, min_loss_coarse : 0.05232244, wrong_element_sum : 10050000.00000000, same_data : 0.00%\n",
      "ae train 실행 시간: 114.593초, 전체 시작 시간 20250314_000238_046\n",
      "\n",
      "epoch-33 accuracy check\n",
      "k_means origin feature average accuracy : 82.26215503%, total [0.9746727376209448, 0.9733106189664963, 0.9700891573195284, 0.9530800230282096, 0.943108504398827, 0.9150568181818182, 0.801817648783348, 0.6625070901871809, 0.9488619568430388, 0.822215777262181, 0.5872695852534562, 0.5005858230814294, 0.9429250891795482, 0.8922588099364529, 0.6741279069767442, 0.6000572573718866]\n",
      "kmeans average accuracy best : 92.55%, kmeans average accuracy : 92.34866487%, total [0.9766647694934547, 0.9775695627484384, 0.9741156169111302, 0.9645941278065631, 0.967741935483871, 0.9616477272727273, 0.9313984168865436, 0.8667044809982983, 0.9698492462311558, 0.943445475638051, 0.880184331797235, 0.8210310486233158, 0.9571938168846611, 0.9332755632582322, 0.8630813953488372, 0.787288863441168]\n",
      "cluster_accuracy_post_training_cycle_all_dataset : [0.97871334 0.97785108 0.97496389 0.96721311 0.96865672 0.95849057\n",
      " 0.9288911  0.8607714  0.95360565 0.94726562 0.8296332  0.81529295\n",
      " 0.95824847 0.93452958 0.8495098  0.80124224]\n",
      "mean_cluster_accuracy_during_training_cycle : 91.84%, post_traincycle_acc : 91.91%, total_acc : 91.88006649%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 92.15%\n",
      "accuracy_check 실행 시간: 24.257초\n",
      "\n",
      "\n",
      "epoch-34 loss : 0.00786492, loss_normal : 0.01146166, loss_coarse : 0.05229243, min_loss : 0.00786492, min_loss_normal : 0.01146166, min_loss_coarse : 0.05229243, wrong_element_sum : 10040146.00000000, same_data : 0.00%\n",
      "ae train 실행 시간: 118.704초, 전체 시작 시간 20250314_000238_046\n",
      "\n",
      "epoch-34 accuracy check\n",
      "k_means origin feature average accuracy : 82.24242650%, total [0.9746727376209448, 0.9733106189664963, 0.9700891573195284, 0.9530800230282096, 0.943108504398827, 0.9150568181818182, 0.801817648783348, 0.6622234826999432, 0.9488619568430388, 0.822215777262181, 0.5866935483870968, 0.5002929115407148, 0.9429250891795482, 0.8922588099364529, 0.6741279069767442, 0.5980532493558546]\n",
      "kmeans average accuracy best : 92.55%, kmeans average accuracy : 92.38641022%, total [0.9766647694934547, 0.9778534923339012, 0.9746908254242163, 0.9643062751871042, 0.9671554252199414, 0.9610795454545454, 0.9328642626795661, 0.8684061259217243, 0.967188885604493, 0.9402552204176334, 0.8721198156682027, 0.8222026947861746, 0.9586801426872771, 0.9344309647602542, 0.8697674418604651, 0.7941597480675637]\n",
      "cluster_accuracy_post_training_cycle_all_dataset : [0.97918638 0.97832234 0.97544535 0.96673095 0.9681592  0.95613208\n",
      " 0.93684734 0.86030103 0.95713565 0.94775391 0.84700772 0.8142999\n",
      " 0.9592668  0.93452958 0.87156863 0.80458672]\n",
      "mean_cluster_accuracy_during_training_cycle : 91.23%, post_traincycle_acc : 92.23%, total_acc : 91.82160196%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 92.15%\n",
      "accuracy_check 실행 시간: 23.670초\n",
      "\n",
      "\n",
      "epoch-35 loss : 0.00785393, loss_normal : 0.01146049, loss_coarse : 0.05227628, min_loss : 0.00785393, min_loss_normal : 0.01146049, min_loss_coarse : 0.05227628, wrong_element_sum : 10037046.00000000, same_data : 0.00%\n",
      "ae train 실행 시간: 113.220초, 전체 시작 시간 20250314_000238_046\n",
      "\n",
      "epoch-35 accuracy check\n",
      "k_means origin feature average accuracy : 82.26218852%, total [0.9746727376209448, 0.9733106189664963, 0.9700891573195284, 0.9530800230282096, 0.943108504398827, 0.9150568181818182, 0.801817648783348, 0.6625070901871809, 0.9488619568430388, 0.822215777262181, 0.5866935483870968, 0.5005858230814294, 0.9429250891795482, 0.8922588099364529, 0.6747093023255814, 0.6000572573718866]\n",
      "kmeans average accuracy best : 92.55%, kmeans average accuracy : 92.33352118%, total [0.9760956175298805, 0.9772856331629756, 0.9746908254242163, 0.9645941278065631, 0.9668621700879766, 0.9590909090909091, 0.9363822925828202, 0.8757799205899036, 0.9692580549807863, 0.9411252900232019, 0.8798963133640553, 0.8142940831868776, 0.9563020214030915, 0.9335644136337378, 0.8671511627906977, 0.7809905525336387]\n",
      "cluster_accuracy_post_training_cycle_all_dataset : [0.97776727 0.97785108 0.97496389 0.96673095 0.96766169 0.95613208\n",
      " 0.9373446  0.85606773 0.96318709 0.95214844 0.83204633 0.81132075\n",
      " 0.95773931 0.93016489 0.87058824 0.80697563]\n",
      "mean_cluster_accuracy_during_training_cycle : 91.55%, post_traincycle_acc : 92.12%, total_acc : 91.88365636%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 92.15%\n",
      "accuracy_check 실행 시간: 24.197초\n",
      "\n",
      "\n",
      "epoch-36 loss : 0.00782360, loss_normal : 0.01143782, loss_coarse : 0.05212731, min_loss : 0.00782360, min_loss_normal : 0.01143782, min_loss_coarse : 0.05212731, wrong_element_sum : 10008444.00000000, same_data : 0.00%\n",
      "ae train 실행 시간: 88.903초, 전체 시작 시간 20250314_000238_046\n",
      "\n",
      "epoch-36 accuracy check\n",
      "k_means origin feature average accuracy : 82.25855901%, total [0.9746727376209448, 0.9733106189664963, 0.9700891573195284, 0.9530800230282096, 0.943108504398827, 0.9150568181818182, 0.801817648783348, 0.6625070901871809, 0.9488619568430388, 0.8219257540603249, 0.5866935483870968, 0.5005858230814294, 0.9429250891795482, 0.8922588099364529, 0.6744186046511628, 0.6000572573718866]\n",
      "kmeans average accuracy best : 92.55%, kmeans average accuracy : 92.42579566%, total [0.9766647694934547, 0.9778534923339012, 0.9746908254242163, 0.9668969487622338, 0.9671554252199414, 0.9633522727272728, 0.9363822925828202, 0.8780487804878049, 0.9654153118533846, 0.9428654292343387, 0.8701036866359447, 0.8189806678383128, 0.9560047562425684, 0.9300982091276718, 0.8680232558139535, 0.7955911823647295]\n",
      "cluster_accuracy_post_training_cycle_all_dataset : [0.97918638 0.97785108 0.97544535 0.96817743 0.96766169 0.95754717\n",
      " 0.93585281 0.86829727 0.95007564 0.95263672 0.84700772 0.81181728\n",
      " 0.95010183 0.93064985 0.88676471 0.79550884]\n",
      "mean_cluster_accuracy_during_training_cycle : 91.18%, post_traincycle_acc : 92.22%, total_acc : 91.79183319%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 92.15%\n",
      "accuracy_check 실행 시간: 24.015초\n",
      "\n",
      "\n",
      "epoch-37 loss : 0.00784176, loss_normal : 0.01144289, loss_coarse : 0.05217243, min_loss : 0.00782360, min_loss_normal : 0.01143782, min_loss_coarse : 0.05212731, wrong_element_sum : 10017106.00000000, same_data : 0.00%\n",
      "ae train 실행 시간: 116.017초, 전체 시작 시간 20250314_000238_046\n",
      "\n",
      "epoch-37 accuracy check\n",
      "k_means origin feature average accuracy : 82.25137006%, total [0.9746727376209448, 0.9733106189664963, 0.9700891573195284, 0.9530800230282096, 0.943108504398827, 0.9150568181818182, 0.801817648783348, 0.6625070901871809, 0.9488619568430388, 0.822215777262181, 0.5866935483870968, 0.5005858230814294, 0.9429250891795482, 0.8922588099364529, 0.6738372093023256, 0.5991983967935872]\n",
      "save model\n",
      "kmeans average accuracy best : 92.61%, kmeans average accuracy : 92.60974743%, total [0.9760956175298805, 0.9775695627484384, 0.9744032211676733, 0.9654576856649395, 0.967741935483871, 0.9619318181818182, 0.9287598944591029, 0.871242200794101, 0.9701448418563405, 0.9457656612529002, 0.8793202764976958, 0.8201523140011716, 0.9583828775267539, 0.9413633737723859, 0.8781976744186046, 0.8010306326939594]\n",
      "cluster_accuracy_post_training_cycle_all_dataset : [0.9782403  0.97832234 0.97496389 0.96769527 0.97064677 0.95330189\n",
      " 0.93187469 0.87158984 0.96217852 0.95214844 0.84411197 0.82969215\n",
      " 0.95977597 0.94374394 0.87107843 0.8136646 ]\n",
      "mean_cluster_accuracy_during_training_cycle : 91.68%, post_traincycle_acc : 92.52%, total_acc : 92.17720661%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 92.52%\n",
      "accuracy_check 실행 시간: 23.935초\n",
      "\n",
      "\n",
      "epoch-38 loss : 0.00781707, loss_normal : 0.01143158, loss_coarse : 0.05207098, min_loss : 0.00781707, min_loss_normal : 0.01143158, min_loss_coarse : 0.05207098, wrong_element_sum : 9997628.00000000, same_data : 0.00%\n",
      "ae train 실행 시간: 117.955초, 전체 시작 시간 20250314_000238_046\n",
      "\n",
      "epoch-38 accuracy check\n",
      "k_means origin feature average accuracy : 82.25683739%, total [0.9746727376209448, 0.9733106189664963, 0.9700891573195284, 0.9530800230282096, 0.943108504398827, 0.9150568181818182, 0.801817648783348, 0.6622234826999432, 0.9488619568430388, 0.822215777262181, 0.5866935483870968, 0.5005858230814294, 0.9429250891795482, 0.8922588099364529, 0.6747093023255814, 0.5994846836530203]\n",
      "kmeans average accuracy best : 92.61%, kmeans average accuracy : 92.25602894%, total [0.9766647694934547, 0.9772856331629756, 0.9738280126545873, 0.9640184225676454, 0.9680351906158358, 0.9627840909090909, 0.9343301084725887, 0.8743618831537152, 0.966006503103754, 0.9396751740139211, 0.8657834101382489, 0.8090216754540129, 0.9563020214030915, 0.9306759098786829, 0.8686046511627907, 0.7935871743486974]\n",
      "cluster_accuracy_post_training_cycle_all_dataset : [0.97776727 0.97737983 0.97448243 0.96673095 0.96865672 0.95943396\n",
      " 0.93635007 0.87064911 0.9480585  0.95117188 0.82818533 0.79294935\n",
      " 0.95875764 0.93113482 0.87156863 0.81223125]\n",
      "mean_cluster_accuracy_during_training_cycle : 90.92%, post_traincycle_acc : 92.03%, total_acc : 91.57840810%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 92.52%\n",
      "accuracy_check 실행 시간: 23.872초\n",
      "\n",
      "\n",
      "epoch-39 loss : 0.00781847, loss_normal : 0.01143728, loss_coarse : 0.05214755, min_loss : 0.00781707, min_loss_normal : 0.01143158, min_loss_coarse : 0.05207098, wrong_element_sum : 10012330.00000000, same_data : 0.00%\n",
      "ae train 실행 시간: 121.659초, 전체 시작 시간 20250314_000238_046\n",
      "\n",
      "epoch-39 accuracy check\n",
      "k_means origin feature average accuracy : 82.24966347%, total [0.9746727376209448, 0.9733106189664963, 0.9700891573195284, 0.9530800230282096, 0.943108504398827, 0.9150568181818182, 0.801817648783348, 0.6625070901871809, 0.9488619568430388, 0.822215777262181, 0.5866935483870968, 0.5005858230814294, 0.9429250891795482, 0.8922588099364529, 0.6747093023255814, 0.5980532493558546]\n",
      "save model\n",
      "kmeans average accuracy best : 92.63%, kmeans average accuracy : 92.62835835%, total [0.9760956175298805, 0.9772856331629756, 0.9744032211676733, 0.9651698330454808, 0.9683284457478006, 0.9616477272727273, 0.93051890941073, 0.8675553034600113, 0.971918415607449, 0.947215777262181, 0.8870967741935484, 0.8242530755711776, 0.9607609988109393, 0.9410745233968805, 0.8787790697674419, 0.7884340108789006]\n",
      "cluster_accuracy_post_training_cycle_all_dataset : [0.97871334 0.97737983 0.97448243 0.96817743 0.96915423 0.95754717\n",
      " 0.93535554 0.85747883 0.96621281 0.95117188 0.84073359 0.82125124\n",
      " 0.96130346 0.93937924 0.86764706 0.79694219]\n",
      "mean_cluster_accuracy_during_training_cycle : 91.77%, post_traincycle_acc : 92.27%, total_acc : 92.06358387%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 92.27%\n",
      "accuracy_check 실행 시간: 24.176초\n",
      "\n",
      "\n",
      "epoch-40 loss : 0.00781975, loss_normal : 0.01143015, loss_coarse : 0.05212082, min_loss : 0.00781707, min_loss_normal : 0.01143015, min_loss_coarse : 0.05207098, wrong_element_sum : 10007198.00000000, same_data : 0.00%\n",
      "ae train 실행 시간: 116.290초, 전체 시작 시간 20250314_000238_046\n",
      "\n",
      "epoch-40 accuracy check\n",
      "k_means origin feature average accuracy : 82.25669664%, total [0.9746727376209448, 0.9733106189664963, 0.9700891573195284, 0.9530800230282096, 0.943108504398827, 0.915340909090909, 0.801817648783348, 0.6625070901871809, 0.9488619568430388, 0.822215777262181, 0.5866935483870968, 0.5005858230814294, 0.9429250891795482, 0.8922588099364529, 0.673546511627907, 0.6000572573718866]\n",
      "kmeans average accuracy best : 92.63%, kmeans average accuracy : 92.55248795%, total [0.9760956175298805, 0.9775695627484384, 0.9744032211676733, 0.9651698330454808, 0.967741935483871, 0.9602272727272727, 0.9340369393139841, 0.8672716959727736, 0.9713272243570795, 0.9480858468677494, 0.8761520737327189, 0.8213239601640304, 0.9595719381688466, 0.9422299248989023, 0.8773255813953489, 0.7898654451760664]\n",
      "cluster_accuracy_post_training_cycle_all_dataset : [0.97871334 0.97832234 0.97448243 0.96817743 0.96766169 0.95849057\n",
      " 0.93535554 0.8621825  0.96116994 0.95507812 0.84893822 0.83217478\n",
      " 0.96028513 0.94471387 0.87303922 0.79455327]\n",
      "mean_cluster_accuracy_during_training_cycle : 91.60%, post_traincycle_acc : 92.46%, total_acc : 92.10850713%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 92.27%\n",
      "accuracy_check 실행 시간: 25.612초\n",
      "\n",
      "\n",
      "epoch-41 loss : 0.00780910, loss_normal : 0.01142871, loss_coarse : 0.05208104, min_loss : 0.00780910, min_loss_normal : 0.01142871, min_loss_coarse : 0.05207098, wrong_element_sum : 9999560.00000000, same_data : 0.00%\n",
      "ae train 실행 시간: 113.448초, 전체 시작 시간 20250314_000238_046\n",
      "\n",
      "epoch-41 accuracy check\n",
      "k_means origin feature average accuracy : 82.26040052%, total [0.9746727376209448, 0.9733106189664963, 0.9700891573195284, 0.9530800230282096, 0.943108504398827, 0.9150568181818182, 0.8015244796247435, 0.6622234826999432, 0.9488619568430388, 0.822215777262181, 0.5866935483870968, 0.5005858230814294, 0.9429250891795482, 0.8922588099364529, 0.675, 0.6000572573718866]\n",
      "kmeans average accuracy best : 92.63%, kmeans average accuracy : 92.48300462%, total [0.9763801935116676, 0.9775695627484384, 0.9744032211676733, 0.9640184225676454, 0.9659824046920821, 0.9599431818181818, 0.9337437701553797, 0.8698241633579127, 0.971918415607449, 0.9469257540603249, 0.8741359447004609, 0.8222026947861746, 0.9592746730083235, 0.9321201617562103, 0.8726744186046511, 0.7961637560835958]\n",
      "cluster_accuracy_post_training_cycle_all_dataset : [0.97871334 0.97832234 0.97448243 0.96673095 0.96766169 0.95424528\n",
      " 0.93485828 0.85606773 0.96772567 0.94677734 0.84169884 0.81876862\n",
      " 0.96028513 0.93549952 0.87892157 0.81748686]\n",
      "mean_cluster_accuracy_during_training_cycle : 91.37%, post_traincycle_acc : 92.36%, total_acc : 91.95628959%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 92.27%\n",
      "accuracy_check 실행 시간: 24.435초\n",
      "\n",
      "\n",
      "epoch-42 loss : 0.00783353, loss_normal : 0.01143974, loss_coarse : 0.05219057, min_loss : 0.00780910, min_loss_normal : 0.01142871, min_loss_coarse : 0.05207098, wrong_element_sum : 10020590.00000000, same_data : 0.00%\n",
      "ae train 실행 시간: 117.744초, 전체 시작 시간 20250314_000238_046\n",
      "\n",
      "epoch-42 accuracy check\n",
      "k_means origin feature average accuracy : 82.24244034%, total [0.9746727376209448, 0.9733106189664963, 0.9700891573195284, 0.9530800230282096, 0.943108504398827, 0.9150568181818182, 0.801817648783348, 0.6622234826999432, 0.9488619568430388, 0.822215777262181, 0.5866935483870968, 0.5005858230814294, 0.9429250891795482, 0.8922588099364529, 0.6738372093023256, 0.5980532493558546]\n",
      "save model\n",
      "kmeans average accuracy best : 92.69%, kmeans average accuracy : 92.69402536%, total [0.9760956175298805, 0.9775695627484384, 0.9741156169111302, 0.9645941278065631, 0.967741935483871, 0.9625, 0.9352096159484022, 0.8817356778218945, 0.9692580549807863, 0.9385150812064965, 0.8657834101382489, 0.8134153485647334, 0.9616527942925089, 0.9474292316580012, 0.8892441860465117, 0.8061837961637561]\n",
      "cluster_accuracy_post_training_cycle_all_dataset : [0.9782403  0.97832234 0.97496389 0.96769527 0.96766169 0.95754717\n",
      " 0.93833913 0.87206021 0.94906707 0.95068359 0.82818533 0.58093347\n",
      " 0.96130346 0.94325897 0.88284314 0.81748686]\n",
      "mean_cluster_accuracy_during_training_cycle : 90.33%, post_traincycle_acc : 90.93%, total_acc : 90.68208967%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 90.93%\n",
      "accuracy_check 실행 시간: 23.994초\n",
      "\n",
      "\n",
      "epoch-43 loss : 0.00780900, loss_normal : 0.01143271, loss_coarse : 0.05211283, min_loss : 0.00780900, min_loss_normal : 0.01142871, min_loss_coarse : 0.05207098, wrong_element_sum : 10005664.00000000, same_data : 0.00%\n",
      "ae train 실행 시간: 117.451초, 전체 시작 시간 20250314_000238_046\n",
      "\n",
      "epoch-43 accuracy check\n",
      "k_means origin feature average accuracy : 82.27298620%, total [0.9746727376209448, 0.9733106189664963, 0.9700891573195284, 0.9530800230282096, 0.943108504398827, 0.9150568181818182, 0.801817648783348, 0.6622234826999432, 0.9488619568430388, 0.822215777262181, 0.5889976958525346, 0.5002929115407148, 0.9429250891795482, 0.8922588099364529, 0.6747093023255814, 0.6000572573718866]\n",
      "kmeans average accuracy best : 92.69%, kmeans average accuracy : 92.29470321%, total [0.9760956175298805, 0.9775695627484384, 0.9744032211676733, 0.9640184225676454, 0.9671554252199414, 0.9630681818181818, 0.9337437701553797, 0.8689733408961997, 0.9633461424770914, 0.9367749419953596, 0.8738479262672811, 0.81195079086116, 0.9580856123662307, 0.9373194685153091, 0.8712209302325581, 0.7895791583166333]\n",
      "cluster_accuracy_post_training_cycle_all_dataset : [0.9782403  0.97832234 0.97448243 0.96721311 0.96716418 0.95566038\n",
      " 0.93535554 0.87017874 0.95057993 0.94042969 0.84073359 0.82869911\n",
      " 0.95977597 0.93937924 0.88235294 0.80554228]\n",
      "mean_cluster_accuracy_during_training_cycle : 91.23%, post_traincycle_acc : 92.34%, total_acc : 91.88328135%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 90.93%\n",
      "accuracy_check 실행 시간: 24.170초\n",
      "\n",
      "\n",
      "epoch-44 loss : 0.00778811, loss_normal : 0.01141560, loss_coarse : 0.05201730, min_loss : 0.00778811, min_loss_normal : 0.01141560, min_loss_coarse : 0.05201730, wrong_element_sum : 9987322.00000000, same_data : 0.00%\n",
      "ae train 실행 시간: 119.276초, 전체 시작 시간 20250314_000238_046\n",
      "\n",
      "epoch-44 accuracy check\n",
      "k_means origin feature average accuracy : 82.24590403%, total [0.9746727376209448, 0.9733106189664963, 0.9700891573195284, 0.9530800230282096, 0.943108504398827, 0.9150568181818182, 0.8015244796247435, 0.6625070901871809, 0.9488619568430388, 0.822215777262181, 0.5866935483870968, 0.5005858230814294, 0.9429250891795482, 0.8922588099364529, 0.6732558139534883, 0.5991983967935872]\n",
      "kmeans average accuracy best : 92.69%, kmeans average accuracy : 92.56894198%, total [0.9763801935116676, 0.9775695627484384, 0.9744032211676733, 0.9654576856649395, 0.9674486803519061, 0.9607954545454546, 0.9308120785693345, 0.8672716959727736, 0.9686668637304168, 0.9480858468677494, 0.8859447004608295, 0.8201523140011716, 0.9580856123662307, 0.9410745233968805, 0.8755813953488372, 0.7933008874892642]\n",
      "cluster_accuracy_post_training_cycle_all_dataset : [0.9782403  0.97832234 0.97448243 0.96769527 0.96716418 0.9509434\n",
      " 0.93286922 0.8621825  0.96217852 0.95263672 0.84555985 0.82075472\n",
      " 0.9607943  0.94034918 0.87254902 0.81700908]\n",
      "mean_cluster_accuracy_during_training_cycle : 91.40%, post_traincycle_acc : 92.40%, total_acc : 91.98766111%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 90.93%\n",
      "accuracy_check 실행 시간: 24.135초\n",
      "\n",
      "\n",
      "epoch-45 loss : 0.00782377, loss_normal : 0.01142767, loss_coarse : 0.05216895, min_loss : 0.00778811, min_loss_normal : 0.01141560, min_loss_coarse : 0.05201730, wrong_element_sum : 10016438.00000000, same_data : 0.00%\n",
      "ae train 실행 시간: 118.256초, 전체 시작 시간 20250314_000238_046\n",
      "\n",
      "epoch-45 accuracy check\n",
      "k_means origin feature average accuracy : 82.24599136%, total [0.9746727376209448, 0.9733106189664963, 0.9700891573195284, 0.9530800230282096, 0.943108504398827, 0.9150568181818182, 0.801817648783348, 0.6622234826999432, 0.9488619568430388, 0.822215777262181, 0.5866935483870968, 0.5005858230814294, 0.9429250891795482, 0.8922588099364529, 0.673546511627907, 0.598912109934154]\n",
      "kmeans average accuracy best : 92.69%, kmeans average accuracy : 92.50470673%, total [0.9763801935116676, 0.9772856331629756, 0.9744032211676733, 0.9654576856649395, 0.9683284457478006, 0.9627840909090909, 0.9378481383758429, 0.8786159954622802, 0.9677800768548626, 0.941415313225058, 0.8747119815668203, 0.8224956063268892, 0.9565992865636147, 0.9347198151357596, 0.8700581395348838, 0.7918694531920984]\n",
      "cluster_accuracy_post_training_cycle_all_dataset : [0.9782403  0.97785108 0.97448243 0.96769527 0.96766169 0.95613208\n",
      " 0.94032819 0.87253057 0.96116994 0.94970703 0.83349421 0.82671301\n",
      " 0.95875764 0.93743938 0.87254902 0.81127568]\n",
      "mean_cluster_accuracy_during_training_cycle : 91.62%, post_traincycle_acc : 92.41%, total_acc : 92.08985293%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 90.93%\n",
      "accuracy_check 실행 시간: 23.998초\n",
      "\n",
      "\n",
      "epoch-46 loss : 0.00779156, loss_normal : 0.01141532, loss_coarse : 0.05205628, min_loss : 0.00778811, min_loss_normal : 0.01141532, min_loss_coarse : 0.05201730, wrong_element_sum : 9994806.00000000, same_data : 0.00%\n",
      "ae train 실행 시간: 91.831초, 전체 시작 시간 20250314_000238_046\n",
      "\n",
      "epoch-46 accuracy check\n",
      "k_means origin feature average accuracy : 82.26583306%, total [0.9746727376209448, 0.9733106189664963, 0.9700891573195284, 0.9530800230282096, 0.943108504398827, 0.9150568181818182, 0.801817648783348, 0.6622234826999432, 0.9488619568430388, 0.822215777262181, 0.5872695852534562, 0.5005858230814294, 0.9429250891795482, 0.8922588099364529, 0.675, 0.6000572573718866]\n",
      "kmeans average accuracy best : 92.69%, kmeans average accuracy : 92.37778561%, total [0.9763801935116676, 0.9775695627484384, 0.9744032211676733, 0.9648819804260219, 0.9665689149560117, 0.9571022727272728, 0.9334506009967751, 0.8743618831537152, 0.9692580549807863, 0.9446055684454756, 0.8761520737327189, 0.8213239601640304, 0.9580856123662307, 0.9332755632582322, 0.8683139534883721, 0.7847122817062697]\n",
      "cluster_accuracy_post_training_cycle_all_dataset : [0.97776727 0.97785108 0.97496389 0.96576663 0.9681592  0.95188679\n",
      " 0.93535554 0.86453434 0.95360565 0.95214844 0.8277027  0.816286\n",
      " 0.9592668  0.93452958 0.86666667 0.80315337]\n",
      "mean_cluster_accuracy_during_training_cycle : 91.55%, post_traincycle_acc : 92.06%, total_acc : 91.84984743%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 90.93%\n",
      "accuracy_check 실행 시간: 23.795초\n",
      "\n",
      "\n",
      "epoch-47 loss : 0.00777694, loss_normal : 0.01141270, loss_coarse : 0.05200894, min_loss : 0.00777694, min_loss_normal : 0.01141270, min_loss_coarse : 0.05200894, wrong_element_sum : 9985716.00000000, same_data : 0.00%\n",
      "ae train 실행 시간: 88.954초, 전체 시작 시간 20250314_000238_046\n",
      "\n",
      "epoch-47 accuracy check\n",
      "k_means origin feature average accuracy : 82.23663270%, total [0.9746727376209448, 0.9733106189664963, 0.9700891573195284, 0.9530800230282096, 0.943108504398827, 0.9150568181818182, 0.7991791263559074, 0.6622234826999432, 0.9488619568430388, 0.8216357308584686, 0.5872695852534562, 0.5005858230814294, 0.9429250891795482, 0.8922588099364529, 0.673546511627907, 0.6000572573718866]\n",
      "kmeans average accuracy best : 92.69%, kmeans average accuracy : 92.27916861%, total [0.9760956175298805, 0.9775695627484384, 0.9741156169111302, 0.9648819804260219, 0.9665689149560117, 0.9588068181818182, 0.9270008795074758, 0.8604651162790697, 0.9701448418563405, 0.9373549883990719, 0.8729838709677419, 0.8131224370240188, 0.960166468489893, 0.939630271519353, 0.8773255813953489, 0.7884340108789006]\n",
      "cluster_accuracy_post_training_cycle_all_dataset : [0.9782403  0.97832234 0.97400096 0.96673095 0.96666667 0.95141509\n",
      " 0.9273993  0.86030103 0.95410993 0.94482422 0.82335907 0.8182721\n",
      " 0.96232179 0.94180407 0.87107843 0.8107979 ]\n",
      "mean_cluster_accuracy_during_training_cycle : 91.28%, post_traincycle_acc : 92.06%, total_acc : 91.73870981%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 90.93%\n",
      "accuracy_check 실행 시간: 24.205초\n",
      "\n",
      "\n",
      "epoch-48 loss : 0.00776519, loss_normal : 0.01140871, loss_coarse : 0.05197348, min_loss : 0.00776519, min_loss_normal : 0.01140871, min_loss_coarse : 0.05197348, wrong_element_sum : 9978908.00000000, same_data : 0.00%\n",
      "ae train 실행 시간: 112.213초, 전체 시작 시간 20250314_000238_046\n",
      "\n",
      "epoch-48 accuracy check\n",
      "k_means origin feature average accuracy : 82.26748452%, total [0.9746727376209448, 0.9733106189664963, 0.9700891573195284, 0.9530800230282096, 0.943108504398827, 0.9150568181818182, 0.801817648783348, 0.6625070901871809, 0.9488619568430388, 0.822215777262181, 0.5869815668202765, 0.5005858230814294, 0.9429250891795482, 0.8922588099364529, 0.6738372093023256, 0.6014886916690524]\n",
      "kmeans average accuracy best : 92.69%, kmeans average accuracy : 92.38957574%, total [0.9758110415480934, 0.9772856331629756, 0.9741156169111302, 0.9643062751871042, 0.9668621700879766, 0.9619318181818182, 0.9328642626795661, 0.8735110606920022, 0.9704404374815253, 0.9382250580046404, 0.8738479262672811, 0.8163444639718805, 0.9586801426872771, 0.940785673021375, 0.8683139534883721, 0.789006584597767]\n",
      "cluster_accuracy_post_training_cycle_all_dataset : [0.9782403  0.97785108 0.97448243 0.96673095 0.9681592  0.95754717\n",
      " 0.93535554 0.86030103 0.95410993 0.94824219 0.83445946 0.81281033\n",
      " 0.95977597 0.94083414 0.87401961 0.81414238]\n",
      "mean_cluster_accuracy_during_training_cycle : 91.17%, post_traincycle_acc : 92.23%, total_acc : 91.79890099%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 90.93%\n",
      "accuracy_check 실행 시간: 24.455초\n",
      "\n",
      "\n",
      "epoch-49 loss : 0.00776934, loss_normal : 0.01140547, loss_coarse : 0.05198683, min_loss : 0.00776519, min_loss_normal : 0.01140547, min_loss_coarse : 0.05197348, wrong_element_sum : 9981472.00000000, same_data : 0.00%\n",
      "ae train 실행 시간: 119.032초, 전체 시작 시간 20250314_000238_046\n",
      "\n",
      "epoch-49 accuracy check\n",
      "k_means origin feature average accuracy : 82.20909852%, total [0.9746727376209448, 0.9733106189664963, 0.9700891573195284, 0.9530800230282096, 0.943108504398827, 0.915340909090909, 0.801817648783348, 0.6625070901871809, 0.9488619568430388, 0.822215777262181, 0.5866935483870968, 0.4929701230228471, 0.9429250891795482, 0.8922588099364529, 0.673546511627907, 0.6000572573718866]\n",
      "kmeans average accuracy best : 92.69%, kmeans average accuracy : 92.41645488%, total [0.9760956175298805, 0.9772856331629756, 0.9744032211676733, 0.9648819804260219, 0.966275659824047, 0.9613636363636363, 0.9313984168865436, 0.867838910947249, 0.9668932899793083, 0.941415313225058, 0.8724078341013825, 0.8113649677797306, 0.9607609988109393, 0.9451184286539572, 0.8729651162790698, 0.7961637560835958]\n",
      "cluster_accuracy_post_training_cycle_all_dataset : [0.9782403  0.97785108 0.9735195  0.96624879 0.96716418 0.95613208\n",
      " 0.93237195 0.86453434 0.95612708 0.94775391 0.83204633 0.81926514\n",
      " 0.96232179 0.94471387 0.87107843 0.80172002]\n",
      "mean_cluster_accuracy_during_training_cycle : 91.23%, post_traincycle_acc : 92.19%, total_acc : 91.79959921%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 90.93%\n",
      "accuracy_check 실행 시간: 24.973초\n",
      "\n",
      "\n",
      "epoch-50 loss : 0.00776334, loss_normal : 0.01140248, loss_coarse : 0.05198290, min_loss : 0.00776334, min_loss_normal : 0.01140248, min_loss_coarse : 0.05197348, wrong_element_sum : 9980718.00000000, same_data : 0.00%\n",
      "ae train 실행 시간: 121.531초, 전체 시작 시간 20250314_000238_046\n",
      "\n",
      "epoch-50 accuracy check\n",
      "k_means origin feature average accuracy : 82.27113498%, total [0.9746727376209448, 0.9733106189664963, 0.9700891573195284, 0.9530800230282096, 0.943108504398827, 0.9150568181818182, 0.801817648783348, 0.6625070901871809, 0.9488619568430388, 0.822215777262181, 0.5866935483870968, 0.5005858230814294, 0.9429250891795482, 0.8922588099364529, 0.6747093023255814, 0.6014886916690524]\n",
      "kmeans average accuracy best : 92.69%, kmeans average accuracy : 92.59803829%, total [0.9760956175298805, 0.9775695627484384, 0.9744032211676733, 0.9643062751871042, 0.9665689149560117, 0.9630681818181818, 0.9360891234242158, 0.8752127056154283, 0.9692580549807863, 0.941415313225058, 0.8879608294930875, 0.8233743409490334, 0.9610582639714625, 0.9419410745233969, 0.8712209302325581, 0.7861437160034355]\n",
      "cluster_accuracy_post_training_cycle_all_dataset : [0.9782403  0.97832234 0.97448243 0.96624879 0.96666667 0.95754717\n",
      " 0.94032819 0.87629351 0.95209279 0.94238281 0.83638996 0.80983118\n",
      " 0.96283096 0.93937924 0.87696078 0.79980889]\n",
      "mean_cluster_accuracy_during_training_cycle : 91.70%, post_traincycle_acc : 92.24%, total_acc : 92.01568626%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 90.93%\n",
      "accuracy_check 실행 시간: 24.655초\n",
      "\n",
      "\n",
      "epoch-51 loss : 0.00773552, loss_normal : 0.01138715, loss_coarse : 0.05188089, min_loss : 0.00773552, min_loss_normal : 0.01138715, min_loss_coarse : 0.05188089, wrong_element_sum : 9961132.00000000, same_data : 0.00%\n",
      "ae train 실행 시간: 118.184초, 전체 시작 시간 20250314_000238_046\n",
      "\n",
      "epoch-51 accuracy check\n",
      "k_means origin feature average accuracy : 82.26218852%, total [0.9746727376209448, 0.9733106189664963, 0.9700891573195284, 0.9530800230282096, 0.943108504398827, 0.9150568181818182, 0.801817648783348, 0.6625070901871809, 0.9488619568430388, 0.822215777262181, 0.5866935483870968, 0.5005858230814294, 0.9429250891795482, 0.8922588099364529, 0.6747093023255814, 0.6000572573718866]\n",
      "kmeans average accuracy best : 92.69%, kmeans average accuracy : 92.56481446%, total [0.9760956175298805, 0.9772856331629756, 0.9744032211676733, 0.9645941278065631, 0.9671554252199414, 0.9602272727272727, 0.9340369393139841, 0.866988088485536, 0.969553650605971, 0.9457656612529002, 0.8853686635944701, 0.8239601640304628, 0.9589774078478003, 0.9381860196418256, 0.877906976744186, 0.7898654451760664]\n",
      "cluster_accuracy_post_training_cycle_all_dataset : [0.9782403  0.97785108 0.97448243 0.96769527 0.96666667 0.95707547\n",
      " 0.93833913 0.86406397 0.96520424 0.95019531 0.83783784 0.82323734\n",
      " 0.96130346 0.93355965 0.87696078 0.80267559]\n",
      "mean_cluster_accuracy_during_training_cycle : 91.70%, post_traincycle_acc : 92.35%, total_acc : 92.07926901%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 90.93%\n",
      "accuracy_check 실행 시간: 24.211초\n",
      "\n",
      "\n",
      "epoch-52 loss : 0.00774089, loss_normal : 0.01139428, loss_coarse : 0.05191295, min_loss : 0.00773552, min_loss_normal : 0.01138715, min_loss_coarse : 0.05188089, wrong_element_sum : 9967286.00000000, same_data : 0.00%\n",
      "ae train 실행 시간: 119.887초, 전체 시작 시간 20250314_000238_046\n",
      "\n",
      "epoch-52 accuracy check\n",
      "k_means origin feature average accuracy : 82.25856562%, total [0.9746727376209448, 0.9733106189664963, 0.9700891573195284, 0.9530800230282096, 0.943108504398827, 0.9150568181818182, 0.801817648783348, 0.6622234826999432, 0.9488619568430388, 0.822215777262181, 0.5872695852534562, 0.5005858230814294, 0.9429250891795482, 0.8922588099364529, 0.6738372093023256, 0.6000572573718866]\n",
      "save model\n",
      "kmeans average accuracy best : 92.83%, kmeans average accuracy : 92.82664209%, total [0.9760956175298805, 0.9772856331629756, 0.9744032211676733, 0.9657455382843984, 0.9671554252199414, 0.9616477272727273, 0.9357959542656112, 0.8766307430516166, 0.971918415607449, 0.9480858468677494, 0.8873847926267281, 0.8388986526069128, 0.9577883472057075, 0.9404968226458694, 0.8781976744186046, 0.79473232178643]\n",
      "cluster_accuracy_post_training_cycle_all_dataset : [0.97871334 0.97785108 0.97496389 0.96817743 0.96766169 0.95660377\n",
      " 0.93933366 0.87206021 0.96419566 0.94970703 0.84893822 0.84061569\n",
      " 0.95977597 0.94180407 0.87696078 0.81223125]\n",
      "mean_cluster_accuracy_during_training_cycle : 91.56%, post_traincycle_acc : 92.68%, total_acc : 92.22501488%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 92.68%\n",
      "accuracy_check 실행 시간: 24.204초\n",
      "\n",
      "\n",
      "epoch-53 loss : 0.00772194, loss_normal : 0.01138961, loss_coarse : 0.05187618, min_loss : 0.00772194, min_loss_normal : 0.01138715, min_loss_coarse : 0.05187618, wrong_element_sum : 9960226.00000000, same_data : 0.00%\n",
      "ae train 실행 시간: 119.442초, 전체 시작 시간 20250314_000238_046\n",
      "\n",
      "epoch-53 accuracy check\n",
      "k_means origin feature average accuracy : 82.26033817%, total [0.9746727376209448, 0.9733106189664963, 0.9700891573195284, 0.9530800230282096, 0.943108504398827, 0.9150568181818182, 0.801817648783348, 0.6625070901871809, 0.9488619568430388, 0.822215777262181, 0.5872695852534562, 0.5005858230814294, 0.9429250891795482, 0.8922588099364529, 0.6738372093023256, 0.6000572573718866]\n",
      "kmeans average accuracy best : 92.83%, kmeans average accuracy : 92.40208140%, total [0.9760956175298805, 0.9772856331629756, 0.9738280126545873, 0.9643062751871042, 0.966275659824047, 0.9599431818181818, 0.93051890941073, 0.8641520136131594, 0.9704404374815253, 0.9408352668213457, 0.8747119815668203, 0.8210310486233158, 0.9610582639714625, 0.9399191218948585, 0.8700581395348838, 0.7938734612081305]\n",
      "cluster_accuracy_post_training_cycle_all_dataset : [0.9782403  0.97785108 0.97400096 0.96721311 0.96766169 0.95471698\n",
      " 0.92938836 0.86171214 0.95259708 0.94970703 0.83108108 0.82472691\n",
      " 0.9592668  0.93937924 0.87745098 0.81653129]\n",
      "mean_cluster_accuracy_during_training_cycle : 91.55%, post_traincycle_acc : 92.26%, total_acc : 91.97128915%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 92.68%\n",
      "accuracy_check 실행 시간: 24.505초\n",
      "\n",
      "\n",
      "epoch-54 loss : 0.00771509, loss_normal : 0.01138120, loss_coarse : 0.05185157, min_loss : 0.00771509, min_loss_normal : 0.01138120, min_loss_coarse : 0.05185157, wrong_element_sum : 9955502.00000000, same_data : 0.00%\n",
      "ae train 실행 시간: 118.276초, 전체 시작 시간 20250314_000238_046\n",
      "\n",
      "epoch-54 accuracy check\n",
      "k_means origin feature average accuracy : 82.25501460%, total [0.9746727376209448, 0.9733106189664963, 0.9700891573195284, 0.9530800230282096, 0.943108504398827, 0.9150568181818182, 0.801817648783348, 0.6622234826999432, 0.9488619568430388, 0.822215777262181, 0.5872695852534562, 0.5005858230814294, 0.9429250891795482, 0.8922588099364529, 0.6741279069767442, 0.5991983967935872]\n",
      "kmeans average accuracy best : 92.83%, kmeans average accuracy : 92.62055926%, total [0.9760956175298805, 0.9775695627484384, 0.9746908254242163, 0.966321243523316, 0.9668621700879766, 0.9610795454545454, 0.9352096159484022, 0.8672716959727736, 0.9692580549807863, 0.9411252900232019, 0.8827764976958525, 0.8222026947861746, 0.9613555291319857, 0.9430964760254188, 0.8790697674418605, 0.7953048955052963]\n",
      "cluster_accuracy_post_training_cycle_all_dataset : [0.9782403  0.97785108 0.97400096 0.96817743 0.96716418 0.95754717\n",
      " 0.93833913 0.8607714  0.95511851 0.94580078 0.82722008 0.62611718\n",
      " 0.96232179 0.94519884 0.87892157 0.81175346]\n",
      "mean_cluster_accuracy_during_training_cycle : 90.15%, post_traincycle_acc : 91.09%, total_acc : 90.70392403%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 92.68%\n",
      "accuracy_check 실행 시간: 24.221초\n",
      "\n",
      "\n",
      "epoch-55 loss : 0.00770949, loss_normal : 0.01137528, loss_coarse : 0.05181331, min_loss : 0.00770949, min_loss_normal : 0.01137528, min_loss_coarse : 0.05181331, wrong_element_sum : 9948156.00000000, same_data : 0.00%\n",
      "ae train 실행 시간: 120.560초, 전체 시작 시간 20250314_000238_046\n",
      "\n",
      "epoch-55 accuracy check\n",
      "k_means origin feature average accuracy : 82.25674876%, total [0.9746727376209448, 0.9733106189664963, 0.9700891573195284, 0.9530800230282096, 0.943108504398827, 0.9150568181818182, 0.801817648783348, 0.6622234826999432, 0.9488619568430388, 0.822215777262181, 0.5872695852534562, 0.5005858230814294, 0.9429250891795482, 0.8922588099364529, 0.673546511627907, 0.6000572573718866]\n",
      "kmeans average accuracy best : 92.83%, kmeans average accuracy : 92.76215703%, total [0.9760956175298805, 0.9772856331629756, 0.9741156169111302, 0.9640184225676454, 0.9671554252199414, 0.9605113636363637, 0.9325710935209616, 0.8706749858196257, 0.97073603310671, 0.947215777262181, 0.8891129032258065, 0.8409490333919156, 0.9604637336504162, 0.9404968226458694, 0.8718023255813954, 0.7987403378184942]\n",
      "cluster_accuracy_post_training_cycle_all_dataset : [0.9782403  0.97785108 0.97448243 0.96721311 0.96915423 0.95801887\n",
      " 0.93635007 0.86735654 0.95310136 0.95556641 0.84266409 0.84309831\n",
      " 0.96181263 0.93210475 0.88382353 0.8136646 ]\n",
      "mean_cluster_accuracy_during_training_cycle : 91.88%, post_traincycle_acc : 92.59%, total_acc : 92.29716696%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 92.68%\n",
      "accuracy_check 실행 시간: 24.145초\n",
      "\n",
      "\n",
      "epoch-56 loss : 0.00771962, loss_normal : 0.01138548, loss_coarse : 0.05188218, min_loss : 0.00770949, min_loss_normal : 0.01137528, min_loss_coarse : 0.05181331, wrong_element_sum : 9961378.00000000, same_data : 0.00%\n",
      "ae train 실행 시간: 116.568초, 전체 시작 시간 20250314_000238_046\n",
      "\n",
      "epoch-56 accuracy check\n",
      "k_means origin feature average accuracy : 82.23144795%, total [0.9746727376209448, 0.9733106189664963, 0.9700891573195284, 0.9530800230282096, 0.943108504398827, 0.9150568181818182, 0.801817648783348, 0.6625070901871809, 0.9488619568430388, 0.8216357308584686, 0.5866935483870968, 0.4994141769185706, 0.9429250891795482, 0.8922588099364529, 0.673546511627907, 0.5980532493558546]\n",
      "kmeans average accuracy best : 92.83%, kmeans average accuracy : 92.71012776%, total [0.9760956175298805, 0.978137421919364, 0.9741156169111302, 0.9645941278065631, 0.9671554252199414, 0.9613636363636363, 0.9352096159484022, 0.868689733408962, 0.971918415607449, 0.9475058004640371, 0.8824884792626728, 0.8312829525483304, 0.9619500594530321, 0.9454072790294628, 0.873546511627907, 0.7941597480675637]\n",
      "cluster_accuracy_post_training_cycle_all_dataset : [0.9782403  0.97832234 0.97448243 0.96721311 0.96766169 0.95566038\n",
      " 0.93535554 0.86171214 0.96822995 0.95263672 0.83397683 0.64647468\n",
      " 0.96130346 0.94519884 0.87696078 0.81270903]\n",
      "mean_cluster_accuracy_during_training_cycle : 90.59%, post_traincycle_acc : 91.35%, total_acc : 91.03942753%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 92.68%\n",
      "accuracy_check 실행 시간: 24.951초\n",
      "\n",
      "\n",
      "epoch-57 loss : 0.00768093, loss_normal : 0.01136772, loss_coarse : 0.05168247, min_loss : 0.00768093, min_loss_normal : 0.01136772, min_loss_coarse : 0.05168247, wrong_element_sum : 9923034.00000000, same_data : 0.00%\n",
      "ae train 실행 시간: 117.382초, 전체 시작 시간 20250314_000238_046\n",
      "\n",
      "epoch-57 accuracy check\n",
      "k_means origin feature average accuracy : 82.25856323%, total [0.9746727376209448, 0.9733106189664963, 0.9700891573195284, 0.9530800230282096, 0.943108504398827, 0.9150568181818182, 0.801817648783348, 0.6625070901871809, 0.9488619568430388, 0.8216357308584686, 0.5866935483870968, 0.5005858230814294, 0.9429250891795482, 0.8922588099364529, 0.6747093023255814, 0.6000572573718866]\n",
      "kmeans average accuracy best : 92.83%, kmeans average accuracy : 92.77379486%, total [0.9760956175298805, 0.9775695627484384, 0.9744032211676733, 0.9654576856649395, 0.9674486803519061, 0.9616477272727273, 0.9346232776311932, 0.8644356211003971, 0.9725096068578185, 0.9515661252900232, 0.8862327188940092, 0.8330404217926186, 0.960166468489893, 0.9419410745233969, 0.8793604651162791, 0.7973089035213283]\n",
      "cluster_accuracy_post_training_cycle_all_dataset : [0.9782403  0.97785108 0.97400096 0.96673095 0.96666667 0.95518868\n",
      " 0.93635007 0.86030103 0.96520424 0.95703125 0.84073359 0.83763654\n",
      " 0.96181263 0.94131911 0.88382353 0.81700908]\n",
      "mean_cluster_accuracy_during_training_cycle : 91.29%, post_traincycle_acc : 92.62%, total_acc : 92.07920132%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 92.68%\n",
      "accuracy_check 실행 시간: 23.826초\n",
      "\n",
      "\n",
      "epoch-58 loss : 0.00767092, loss_normal : 0.01136032, loss_coarse : 0.05165623, min_loss : 0.00767092, min_loss_normal : 0.01136032, min_loss_coarse : 0.05165623, wrong_element_sum : 9917996.00000000, same_data : 0.00%\n",
      "ae train 실행 시간: 121.945초, 전체 시작 시간 20250314_000238_046\n",
      "\n",
      "epoch-58 accuracy check\n",
      "k_means origin feature average accuracy : 82.24946348%, total [0.9746727376209448, 0.9733106189664963, 0.9700891573195284, 0.9530800230282096, 0.943108504398827, 0.9150568181818182, 0.8015244796247435, 0.6625070901871809, 0.9488619568430388, 0.8216357308584686, 0.5866935483870968, 0.5005858230814294, 0.9429250891795482, 0.8922588099364529, 0.673546511627907, 0.6000572573718866]\n",
      "kmeans average accuracy best : 92.83%, kmeans average accuracy : 92.45293993%, total [0.9763801935116676, 0.9775695627484384, 0.9744032211676733, 0.9643062751871042, 0.9659824046920821, 0.9619318181818182, 0.9340369393139841, 0.8729438457175269, 0.9677800768548626, 0.9388051044083526, 0.8715437788018433, 0.8219097832454598, 0.9592746730083235, 0.9373194685153091, 0.8738372093023256, 0.7944460349269968]\n",
      "cluster_accuracy_post_training_cycle_all_dataset : [0.9782403  0.97737983 0.97448243 0.96673095 0.96616915 0.95754717\n",
      " 0.93336648 0.85136406 0.9480585  0.9453125  0.81805019 0.81777557\n",
      " 0.9607943  0.94228904 0.88235294 0.81605351]\n",
      "mean_cluster_accuracy_during_training_cycle : 91.17%, post_traincycle_acc : 92.10%, total_acc : 91.72170426%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 92.68%\n",
      "accuracy_check 실행 시간: 23.839초\n",
      "\n",
      "\n",
      "epoch-59 loss : 0.00768478, loss_normal : 0.01136554, loss_coarse : 0.05172203, min_loss : 0.00767092, min_loss_normal : 0.01136032, min_loss_coarse : 0.05165623, wrong_element_sum : 9930630.00000000, same_data : 0.00%\n",
      "ae train 실행 시간: 121.649초, 전체 시작 시간 20250314_000238_046\n",
      "\n",
      "epoch-59 accuracy check\n",
      "k_means origin feature average accuracy : 82.26934569%, total [0.9746727376209448, 0.9733106189664963, 0.9700891573195284, 0.9530800230282096, 0.943108504398827, 0.9150568181818182, 0.801817648783348, 0.6625070901871809, 0.9488619568430388, 0.822215777262181, 0.5866935483870968, 0.5005858230814294, 0.9429250891795482, 0.8922588099364529, 0.6747093023255814, 0.6012024048096193]\n",
      "kmeans average accuracy best : 92.83%, kmeans average accuracy : 92.48039167%, total [0.9760956175298805, 0.9775695627484384, 0.9746908254242163, 0.9660333909038572, 0.9668621700879766, 0.9607954545454546, 0.9357959542656112, 0.869540555870675, 0.9713272243570795, 0.945185614849188, 0.8836405529953917, 0.8274751025190392, 0.9595719381688466, 0.9335644136337378, 0.8671511627906977, 0.781563126252505]\n",
      "cluster_accuracy_post_training_cycle_all_dataset : [0.9782403  0.97785108 0.97496389 0.96769527 0.96766169 0.95424528\n",
      " 0.93933366 0.85983067 0.96217852 0.95019531 0.83735521 0.83167825\n",
      " 0.96028513 0.93452958 0.86176471 0.80745342]\n",
      "mean_cluster_accuracy_during_training_cycle : 91.32%, post_traincycle_acc : 92.28%, total_acc : 91.88959138%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 92.68%\n",
      "accuracy_check 실행 시간: 25.022초\n",
      "\n",
      "\n",
      "epoch-60 loss : 0.00769176, loss_normal : 0.01137072, loss_coarse : 0.05178337, min_loss : 0.00767092, min_loss_normal : 0.01136032, min_loss_coarse : 0.05165623, wrong_element_sum : 9942408.00000000, same_data : 0.00%\n",
      "ae train 실행 시간: 118.302초, 전체 시작 시간 20250314_000238_046\n",
      "\n",
      "epoch-60 accuracy check\n",
      "k_means origin feature average accuracy : 82.25490563%, total [0.9746727376209448, 0.9733106189664963, 0.9700891573195284, 0.9530800230282096, 0.943108504398827, 0.9150568181818182, 0.8015244796247435, 0.6625070901871809, 0.9488619568430388, 0.822215777262181, 0.5866935483870968, 0.5005858230814294, 0.9429250891795482, 0.8922588099364529, 0.6738372093023256, 0.6000572573718866]\n",
      "kmeans average accuracy best : 92.83%, kmeans average accuracy : 92.77171015%, total [0.9760956175298805, 0.9772856331629756, 0.9741156169111302, 0.9648819804260219, 0.9680351906158358, 0.9627840909090909, 0.9381413075344474, 0.8788996029495179, 0.973100798108188, 0.943445475638051, 0.8761520737327189, 0.8298183948447568, 0.9598692033293698, 0.939052570768342, 0.8776162790697675, 0.8041797881477241]\n",
      "cluster_accuracy_post_training_cycle_all_dataset : [0.9782403  0.97785108 0.97496389 0.96721311 0.9681592  0.95943396\n",
      " 0.93585281 0.86970837 0.96116994 0.95410156 0.83204633 0.83018868\n",
      " 0.9607943  0.94083414 0.88382353 0.81318681]\n",
      "mean_cluster_accuracy_during_training_cycle : 91.79%, post_traincycle_acc : 92.55%, total_acc : 92.23977972%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 92.68%\n",
      "accuracy_check 실행 시간: 25.606초\n",
      "\n",
      "\n",
      "epoch-61 loss : 0.00767850, loss_normal : 0.01136209, loss_coarse : 0.05173284, min_loss : 0.00767092, min_loss_normal : 0.01136032, min_loss_coarse : 0.05165623, wrong_element_sum : 9932706.00000000, same_data : 0.00%\n",
      "ae train 실행 시간: 119.473초, 전체 시작 시간 20250314_000238_046\n",
      "\n",
      "epoch-61 accuracy check\n",
      "k_means origin feature average accuracy : 82.24772089%, total [0.9746727376209448, 0.9733106189664963, 0.9700891573195284, 0.9530800230282096, 0.943108504398827, 0.9150568181818182, 0.8015244796247435, 0.6625070901871809, 0.9488619568430388, 0.822215777262181, 0.5866935483870968, 0.5005858230814294, 0.9429250891795482, 0.8922588099364529, 0.673546511627907, 0.5991983967935872]\n",
      "kmeans average accuracy best : 92.83%, kmeans average accuracy : 92.33180239%, total [0.9760956175298805, 0.9772856331629756, 0.9741156169111302, 0.9657455382843984, 0.9656891495601173, 0.959659090909091, 0.931105247727939, 0.8621667612024957, 0.967188885604493, 0.9361948955916474, 0.8692396313364056, 0.824838898652607, 0.9592746730083235, 0.9393414211438474, 0.8747093023255814, 0.7904380188949327]\n",
      "cluster_accuracy_post_training_cycle_all_dataset : [0.9782403  0.97785108 0.97400096 0.96769527 0.96616915 0.95424528\n",
      " 0.93286922 0.86030103 0.95511851 0.94726562 0.82528958 0.81976167\n",
      " 0.96130346 0.94180407 0.87009804 0.8079312 ]\n",
      "mean_cluster_accuracy_during_training_cycle : 91.67%, post_traincycle_acc : 92.12%, total_acc : 91.93915025%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 92.68%\n",
      "accuracy_check 실행 시간: 24.910초\n",
      "\n",
      "\n",
      "epoch-62 loss : 0.00769259, loss_normal : 0.01136784, loss_coarse : 0.05179165, min_loss : 0.00767092, min_loss_normal : 0.01136032, min_loss_coarse : 0.05165623, wrong_element_sum : 9943998.00000000, same_data : 0.00%\n",
      "ae train 실행 시간: 120.445초, 전체 시작 시간 20250314_000238_046\n",
      "\n",
      "epoch-62 accuracy check\n",
      "k_means origin feature average accuracy : 82.25855480%, total [0.9746727376209448, 0.9733106189664963, 0.9700891573195284, 0.9530800230282096, 0.943108504398827, 0.9150568181818182, 0.801817648783348, 0.6625070901871809, 0.9488619568430388, 0.822215777262181, 0.5866935483870968, 0.5005858230814294, 0.9429250891795482, 0.8922588099364529, 0.6741279069767442, 0.6000572573718866]\n",
      "kmeans average accuracy best : 92.83%, kmeans average accuracy : 92.69548528%, total [0.9758110415480934, 0.9775695627484384, 0.9744032211676733, 0.9645941278065631, 0.9674486803519061, 0.9619318181818182, 0.9366754617414248, 0.872093023255814, 0.9725096068578185, 0.9480858468677494, 0.8919930875576036, 0.8374340949033392, 0.9571938168846611, 0.9352975158867707, 0.872093023255814, 0.7861437160034355]\n",
      "cluster_accuracy_post_training_cycle_all_dataset : [0.9782403  0.97832234 0.97400096 0.96769527 0.96915423 0.95613208\n",
      " 0.93585281 0.86265287 0.96873424 0.95751953 0.84700772 0.82125124\n",
      " 0.9592668  0.93549952 0.87745098 0.80984233]\n",
      "mean_cluster_accuracy_during_training_cycle : 91.62%, post_traincycle_acc : 92.49%, total_acc : 92.13349841%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 92.68%\n",
      "accuracy_check 실행 시간: 24.800초\n",
      "\n",
      "\n",
      "epoch-63 loss : 0.00768544, loss_normal : 0.01135351, loss_coarse : 0.05173806, min_loss : 0.00767092, min_loss_normal : 0.01135351, min_loss_coarse : 0.05165623, wrong_element_sum : 9933708.00000000, same_data : 0.00%\n",
      "ae train 실행 시간: 122.025초, 전체 시작 시간 20250314_000238_046\n",
      "\n",
      "epoch-63 accuracy check\n",
      "k_means origin feature average accuracy : 82.25137332%, total [0.9746727376209448, 0.9733106189664963, 0.9700891573195284, 0.9530800230282096, 0.943108504398827, 0.9150568181818182, 0.801817648783348, 0.6622234826999432, 0.9488619568430388, 0.822215777262181, 0.5866935483870968, 0.5005858230814294, 0.942627824019025, 0.8922588099364529, 0.6744186046511628, 0.5991983967935872]\n",
      "save model\n",
      "kmeans average accuracy best : 92.85%, kmeans average accuracy : 92.84992730%, total [0.9760956175298805, 0.9775695627484384, 0.9738280126545873, 0.9634427173287277, 0.9680351906158358, 0.9607954545454546, 0.9381413075344474, 0.8729438457175269, 0.9701448418563405, 0.9457656612529002, 0.8902649769585254, 0.843585237258348, 0.9607609988109393, 0.9413633737723859, 0.8805232558139535, 0.792728313770398]\n",
      "cluster_accuracy_post_training_cycle_all_dataset : [0.97776727 0.97832234 0.97448243 0.96673095 0.96965174 0.95801887\n",
      " 0.94082546 0.87441204 0.9515885  0.95410156 0.83252896 0.5734856\n",
      " 0.96384929 0.94083414 0.88039216 0.81939799]\n",
      "mean_cluster_accuracy_during_training_cycle : 90.88%, post_traincycle_acc : 90.98%, total_acc : 90.93647868%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 90.98%\n",
      "accuracy_check 실행 시간: 24.780초\n",
      "\n",
      "\n",
      "epoch-64 loss : 0.00766186, loss_normal : 0.01135002, loss_coarse : 0.05166780, min_loss : 0.00766186, min_loss_normal : 0.01135002, min_loss_coarse : 0.05165623, wrong_element_sum : 9920218.00000000, same_data : 0.00%\n",
      "ae train 실행 시간: 124.540초, 전체 시작 시간 20250314_000238_046\n",
      "\n",
      "epoch-64 accuracy check\n",
      "k_means origin feature average accuracy : 82.24949646%, total [0.9746727376209448, 0.9733106189664963, 0.9700891573195284, 0.9530800230282096, 0.943108504398827, 0.915340909090909, 0.8015244796247435, 0.6625070901871809, 0.9488619568430388, 0.822215777262181, 0.5866935483870968, 0.5005858230814294, 0.9429250891795482, 0.8922588099364529, 0.673546511627907, 0.5991983967935872]\n",
      "kmeans average accuracy best : 92.85%, kmeans average accuracy : 92.82384129%, total [0.9760956175298805, 0.9775695627484384, 0.9746908254242163, 0.966321243523316, 0.9674486803519061, 0.9590909090909091, 0.9334506009967751, 0.8633011911514464, 0.9742831806089269, 0.9483758700696056, 0.8911290322580645, 0.8394844756883422, 0.9613555291319857, 0.9433853264009243, 0.8808139534883721, 0.7950186086458632]\n",
      "cluster_accuracy_post_training_cycle_all_dataset : [0.9782403  0.97785108 0.97400096 0.96721311 0.96766169 0.95566038\n",
      " 0.93635007 0.8650047  0.96822995 0.95654297 0.83445946 0.84458788\n",
      " 0.96334012 0.94519884 0.88137255 0.80554228]\n",
      "mean_cluster_accuracy_during_training_cycle : 91.76%, post_traincycle_acc : 92.63%, total_acc : 92.27480672%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 90.98%\n",
      "accuracy_check 실행 시간: 26.137초\n",
      "\n",
      "\n",
      "epoch-65 loss : 0.00766799, loss_normal : 0.01134838, loss_coarse : 0.05170434, min_loss : 0.00766186, min_loss_normal : 0.01134838, min_loss_coarse : 0.05165623, wrong_element_sum : 9927234.00000000, same_data : 0.00%\n",
      "ae train 실행 시간: 121.410초, 전체 시작 시간 20250314_000238_046\n",
      "\n",
      "epoch-65 accuracy check\n",
      "k_means origin feature average accuracy : 82.25672249%, total [0.9746727376209448, 0.9733106189664963, 0.9700891573195284, 0.9530800230282096, 0.943108504398827, 0.9150568181818182, 0.8015244796247435, 0.6625070901871809, 0.9488619568430388, 0.822215777262181, 0.5866935483870968, 0.5005858230814294, 0.9429250891795482, 0.8922588099364529, 0.6741279069767442, 0.6000572573718866]\n",
      "kmeans average accuracy best : 92.85%, kmeans average accuracy : 92.67434408%, total [0.9760956175298805, 0.9772856331629756, 0.9741156169111302, 0.9648819804260219, 0.9671554252199414, 0.9613636363636363, 0.9325710935209616, 0.86528644356211, 0.9686668637304168, 0.9390951276102089, 0.8899769585253456, 0.8353837141183362, 0.9637336504161712, 0.9471403812824957, 0.8744186046511628, 0.7907243057543659]\n",
      "cluster_accuracy_post_training_cycle_all_dataset : [0.97682119 0.97690858 0.97448243 0.96624879 0.96716418 0.95613208\n",
      " 0.93336648 0.85324553 0.95864851 0.94970703 0.84314672 0.84061569\n",
      " 0.96334012 0.9456838  0.87696078 0.80554228]\n",
      "mean_cluster_accuracy_during_training_cycle : 91.72%, post_traincycle_acc : 92.43%, total_acc : 92.13412630%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 90.98%\n",
      "accuracy_check 실행 시간: 27.049초\n",
      "\n",
      "\n",
      "epoch-66 loss : 0.00764662, loss_normal : 0.01133875, loss_coarse : 0.05160420, min_loss : 0.00764662, min_loss_normal : 0.01133875, min_loss_coarse : 0.05160420, wrong_element_sum : 9908006.00000000, same_data : 0.00%\n",
      "ae train 실행 시간: 119.750초, 전체 시작 시간 20250314_000238_046\n",
      "\n",
      "epoch-66 accuracy check\n",
      "k_means origin feature average accuracy : 82.25494272%, total [0.9746727376209448, 0.9733106189664963, 0.9700891573195284, 0.9530800230282096, 0.943108504398827, 0.9150568181818182, 0.801817648783348, 0.6625070901871809, 0.9488619568430388, 0.822215777262181, 0.5872695852534562, 0.5005858230814294, 0.9429250891795482, 0.8922588099364529, 0.673546511627907, 0.5994846836530203]\n",
      "kmeans average accuracy best : 92.85%, kmeans average accuracy : 92.54530066%, total [0.9763801935116676, 0.9778534923339012, 0.9744032211676733, 0.9640184225676454, 0.967741935483871, 0.9647727272727272, 0.9390208150102609, 0.8746454906409529, 0.9689624593556015, 0.9411252900232019, 0.8764400921658986, 0.8163444639718805, 0.9595719381688466, 0.9402079722703639, 0.8773255813953489, 0.7884340108789006]\n",
      "cluster_accuracy_post_training_cycle_all_dataset : [0.9782403  0.97832234 0.97400096 0.96624879 0.96865672 0.95990566\n",
      " 0.94132273 0.87441204 0.95562279 0.94921875 0.83349421 0.82224429\n",
      " 0.9592668  0.94180407 0.88039216 0.78213091]\n",
      "mean_cluster_accuracy_during_training_cycle : 91.58%, post_traincycle_acc : 92.28%, total_acc : 91.99468982%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 90.98%\n",
      "accuracy_check 실행 시간: 27.329초\n",
      "\n",
      "\n",
      "epoch-67 loss : 0.00765432, loss_normal : 0.01134609, loss_coarse : 0.05168302, min_loss : 0.00764662, min_loss_normal : 0.01133875, min_loss_coarse : 0.05160420, wrong_element_sum : 9923140.00000000, same_data : 0.00%\n",
      "ae train 실행 시간: 125.287초, 전체 시작 시간 20250314_000238_046\n",
      "\n",
      "epoch-67 accuracy check\n",
      "k_means origin feature average accuracy : 82.23879117%, total [0.9746727376209448, 0.9733106189664963, 0.9700891573195284, 0.9530800230282096, 0.943108504398827, 0.9150568181818182, 0.8015244796247435, 0.6622234826999432, 0.9488619568430388, 0.822215777262181, 0.5866935483870968, 0.5005858230814294, 0.9429250891795482, 0.8922588099364529, 0.673546511627907, 0.5980532493558546]\n",
      "save model\n",
      "kmeans average accuracy best : 92.99%, kmeans average accuracy : 92.99004397%, total [0.9760956175298805, 0.9772856331629756, 0.9744032211676733, 0.9660333909038572, 0.9674486803519061, 0.9639204545454545, 0.9390208150102609, 0.8774815655133296, 0.9733963937333727, 0.951276102088167, 0.8873847926267281, 0.840656121851201, 0.9622473246135553, 0.9451184286539572, 0.8773255813953489, 0.7993129115373604]\n",
      "cluster_accuracy_post_training_cycle_all_dataset : [0.9782403  0.97785108 0.97496389 0.96769527 0.96915423 0.95801887\n",
      " 0.93933366 0.86594544 0.96419566 0.94970703 0.83976834 0.84210526\n",
      " 0.96130346 0.94519884 0.87401961 0.82417582]\n",
      "mean_cluster_accuracy_during_training_cycle : 91.90%, post_traincycle_acc : 92.70%, total_acc : 92.36979803%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 92.70%\n",
      "accuracy_check 실행 시간: 28.186초\n",
      "\n",
      "\n",
      "epoch-68 loss : 0.00762586, loss_normal : 0.01133067, loss_coarse : 0.05150509, min_loss : 0.00762586, min_loss_normal : 0.01133067, min_loss_coarse : 0.05150509, wrong_element_sum : 9888978.00000000, same_data : 0.00%\n",
      "ae train 실행 시간: 122.320초, 전체 시작 시간 20250314_000238_046\n",
      "\n",
      "epoch-68 accuracy check\n",
      "k_means origin feature average accuracy : 82.25671288%, total [0.9746727376209448, 0.9733106189664963, 0.9700891573195284, 0.9530800230282096, 0.943108504398827, 0.9150568181818182, 0.801817648783348, 0.6625070901871809, 0.9488619568430388, 0.8216357308584686, 0.5872695852534562, 0.5005858230814294, 0.9429250891795482, 0.8922588099364529, 0.6738372093023256, 0.6000572573718866]\n",
      "kmeans average accuracy best : 92.99%, kmeans average accuracy : 92.68505562%, total [0.9760956175298805, 0.9775695627484384, 0.9741156169111302, 0.9645941278065631, 0.9680351906158358, 0.9616477272727273, 0.9346232776311932, 0.8797504254112308, 0.97073603310671, 0.9466357308584686, 0.8859447004608295, 0.8321616871704746, 0.960166468489893, 0.9347198151357596, 0.8718023255813954, 0.791010592613799]\n",
      "cluster_accuracy_post_training_cycle_all_dataset : [0.9782403  0.97832234 0.97448243 0.96769527 0.96865672 0.95660377\n",
      " 0.93635007 0.86688617 0.96167423 0.95019531 0.84749035 0.83813307\n",
      " 0.95977597 0.93598448 0.88627451 0.80028667]\n",
      "mean_cluster_accuracy_during_training_cycle : 91.76%, post_traincycle_acc : 92.54%, total_acc : 92.22162366%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 92.70%\n",
      "accuracy_check 실행 시간: 28.325초\n",
      "\n",
      "\n",
      "epoch-69 loss : 0.00762599, loss_normal : 0.01133202, loss_coarse : 0.05156858, min_loss : 0.00762586, min_loss_normal : 0.01133067, min_loss_coarse : 0.05150509, wrong_element_sum : 9901168.00000000, same_data : 0.00%\n",
      "ae train 실행 시간: 120.792초, 전체 시작 시간 20250314_000238_046\n",
      "\n",
      "epoch-69 accuracy check\n",
      "k_means origin feature average accuracy : 82.25137006%, total [0.9746727376209448, 0.9733106189664963, 0.9700891573195284, 0.9530800230282096, 0.943108504398827, 0.9150568181818182, 0.801817648783348, 0.6625070901871809, 0.9488619568430388, 0.822215777262181, 0.5866935483870968, 0.5005858230814294, 0.9429250891795482, 0.8922588099364529, 0.6738372093023256, 0.5991983967935872]\n",
      "kmeans average accuracy best : 92.99%, kmeans average accuracy : 92.73811365%, total [0.9760956175298805, 0.9775695627484384, 0.9744032211676733, 0.9654576856649395, 0.9680351906158358, 0.9633522727272728, 0.9410729991204925, 0.8769143505388542, 0.9716228199822643, 0.9501160092807425, 0.8859447004608295, 0.828646748681898, 0.9586801426872771, 0.9350086655112652, 0.8767441860465116, 0.7884340108789006]\n",
      "cluster_accuracy_post_training_cycle_all_dataset : [0.9782403  0.97832234 0.97544535 0.96721311 0.9681592  0.95896226\n",
      " 0.93983093 0.87441204 0.96419566 0.95703125 0.84700772 0.78848064\n",
      " 0.95977597 0.93695441 0.87941176 0.80124224]\n",
      "mean_cluster_accuracy_during_training_cycle : 91.30%, post_traincycle_acc : 92.34%, total_acc : 91.91562144%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 92.70%\n",
      "accuracy_check 실행 시간: 27.803초\n",
      "\n",
      "\n",
      "epoch-70 loss : 0.00761581, loss_normal : 0.01132836, loss_coarse : 0.05157272, min_loss : 0.00761581, min_loss_normal : 0.01132836, min_loss_coarse : 0.05150509, wrong_element_sum : 9901962.00000000, same_data : 0.00%\n",
      "ae train 실행 시간: 126.122초, 전체 시작 시간 20250314_000238_046\n",
      "\n",
      "epoch-70 accuracy check\n",
      "k_means origin feature average accuracy : 82.25305169%, total [0.9746727376209448, 0.9733106189664963, 0.9700891573195284, 0.9530800230282096, 0.943108504398827, 0.915340909090909, 0.8015244796247435, 0.6625070901871809, 0.9488619568430388, 0.8219257540603249, 0.5866935483870968, 0.5005858230814294, 0.9429250891795482, 0.8922588099364529, 0.673546511627907, 0.6000572573718866]\n",
      "kmeans average accuracy best : 92.99%, kmeans average accuracy : 92.85517578%, total [0.9760956175298805, 0.9775695627484384, 0.9744032211676733, 0.9651698330454808, 0.9680351906158358, 0.9642045454545455, 0.9363822925828202, 0.8806012478729438, 0.9722140112326337, 0.9446055684454756, 0.8879608294930875, 0.8347978910369068, 0.9631391200951248, 0.9402079722703639, 0.8744186046511628, 0.7970226166618952]\n",
      "cluster_accuracy_post_training_cycle_all_dataset : [0.97871334 0.97785108 0.97448243 0.96769527 0.96965174 0.95801887\n",
      " 0.94082546 0.87535278 0.95562279 0.95410156 0.83445946 0.54816286\n",
      " 0.96486762 0.93840931 0.89264706 0.81796464]\n",
      "mean_cluster_accuracy_during_training_cycle : 91.13%, post_traincycle_acc : 90.93%, total_acc : 91.01251424%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 92.70%\n",
      "accuracy_check 실행 시간: 26.954초\n",
      "\n",
      "\n",
      "epoch-71 loss : 0.00762144, loss_normal : 0.01132327, loss_coarse : 0.05151978, min_loss : 0.00761581, min_loss_normal : 0.01132327, min_loss_coarse : 0.05150509, wrong_element_sum : 9891798.00000000, same_data : 0.00%\n",
      "ae train 실행 시간: 122.173초, 전체 시작 시간 20250314_000238_046\n",
      "\n",
      "epoch-71 accuracy check\n",
      "k_means origin feature average accuracy : 82.23877734%, total [0.9746727376209448, 0.9733106189664963, 0.9700891573195284, 0.9530800230282096, 0.943108504398827, 0.9150568181818182, 0.8015244796247435, 0.6622234826999432, 0.9488619568430388, 0.822215777262181, 0.5866935483870968, 0.5002929115407148, 0.9429250891795482, 0.8922588099364529, 0.6738372093023256, 0.5980532493558546]\n",
      "kmeans average accuracy best : 92.99%, kmeans average accuracy : 92.78245438%, total [0.9760956175298805, 0.9770017035775128, 0.9741156169111302, 0.9648819804260219, 0.9659824046920821, 0.9607954545454546, 0.9381413075344474, 0.866988088485536, 0.9722140112326337, 0.9538863109048724, 0.8894009216589862, 0.8304042179261862, 0.9613555291319857, 0.9410745233968805, 0.8732558139534884, 0.7995991983967936]\n",
      "cluster_accuracy_post_training_cycle_all_dataset : [0.9782403  0.97737983 0.97448243 0.96817743 0.96666667 0.95330189\n",
      " 0.9388364  0.85747883 0.96520424 0.95507812 0.8503861  0.83565045\n",
      " 0.96130346 0.93889428 0.88235294 0.81175346]\n",
      "mean_cluster_accuracy_during_training_cycle : 91.76%, post_traincycle_acc : 92.59%, total_acc : 92.25351350%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 92.70%\n",
      "accuracy_check 실행 시간: 28.469초\n",
      "\n",
      "\n",
      "epoch-72 loss : 0.00761925, loss_normal : 0.01132518, loss_coarse : 0.05155084, min_loss : 0.00761581, min_loss_normal : 0.01132327, min_loss_coarse : 0.05150509, wrong_element_sum : 9897762.00000000, same_data : 0.00%\n",
      "ae train 실행 시간: 120.455초, 전체 시작 시간 20250314_000238_046\n",
      "\n",
      "epoch-72 accuracy check\n",
      "k_means origin feature average accuracy : 82.25672962%, total [0.9746727376209448, 0.9733106189664963, 0.9700891573195284, 0.9530800230282096, 0.943108504398827, 0.9150568181818182, 0.801817648783348, 0.6622234826999432, 0.9488619568430388, 0.8216357308584686, 0.5872695852534562, 0.5005858230814294, 0.9429250891795482, 0.8922588099364529, 0.6738372093023256, 0.6003435442313197]\n",
      "kmeans average accuracy best : 92.99%, kmeans average accuracy : 92.87151764%, total [0.9760956175298805, 0.9772856331629756, 0.9744032211676733, 0.9654576856649395, 0.967741935483871, 0.9627840909090909, 0.9393139841688655, 0.8749290981281905, 0.9742831806089269, 0.949245939675174, 0.8870967741935484, 0.8441710603397774, 0.960166468489893, 0.939052570768342, 0.8732558139534884, 0.7941597480675637]\n",
      "cluster_accuracy_post_training_cycle_all_dataset : [0.97776727 0.97785108 0.97400096 0.96817743 0.96965174 0.95754717\n",
      " 0.94082546 0.8621825  0.95763994 0.95507812 0.85086873 0.71201589\n",
      " 0.9607943  0.94325897 0.87352941 0.80602007]\n",
      "mean_cluster_accuracy_during_training_cycle : 90.46%, post_traincycle_acc : 91.80%, total_acc : 91.24895216%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 92.70%\n",
      "accuracy_check 실행 시간: 27.403초\n",
      "\n",
      "\n",
      "epoch-73 loss : 0.00759815, loss_normal : 0.01131970, loss_coarse : 0.05149277, min_loss : 0.00759815, min_loss_normal : 0.01131970, min_loss_coarse : 0.05149277, wrong_element_sum : 9886612.00000000, same_data : 0.00%\n",
      "ae train 실행 시간: 124.488초, 전체 시작 시간 20250314_000238_046\n",
      "\n",
      "epoch-73 accuracy check\n",
      "k_means origin feature average accuracy : 82.25145578%, total [0.9746727376209448, 0.9733106189664963, 0.9700891573195284, 0.9530800230282096, 0.943108504398827, 0.915340909090909, 0.801817648783348, 0.6622234826999432, 0.9488619568430388, 0.822215777262181, 0.5866935483870968, 0.5005858230814294, 0.9429250891795482, 0.8922588099364529, 0.6747093023255814, 0.5983395362152877]\n",
      "kmeans average accuracy best : 92.99%, kmeans average accuracy : 92.77870088%, total [0.9760956175298805, 0.9772856331629756, 0.9738280126545873, 0.9660333909038572, 0.9674486803519061, 0.9625, 0.9363822925828202, 0.8797504254112308, 0.9728052024830033, 0.951276102088167, 0.8845046082949308, 0.8350908025776216, 0.9574910820451843, 0.9387637203928365, 0.8683139534883721, 0.7970226166618952]\n",
      "cluster_accuracy_post_training_cycle_all_dataset : [0.9782403  0.97785108 0.97448243 0.96721311 0.96865672 0.95896226\n",
      " 0.93684734 0.86406397 0.95360565 0.95507812 0.83687259 0.84756703\n",
      " 0.95875764 0.93646945 0.88284314 0.82130913]\n",
      "mean_cluster_accuracy_during_training_cycle : 91.88%, post_traincycle_acc : 92.62%, total_acc : 92.31457973%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 92.70%\n",
      "accuracy_check 실행 시간: 27.296초\n",
      "\n",
      "\n",
      "epoch-74 loss : 0.00759993, loss_normal : 0.01131891, loss_coarse : 0.05151562, min_loss : 0.00759815, min_loss_normal : 0.01131891, min_loss_coarse : 0.05149277, wrong_element_sum : 9891000.00000000, same_data : 0.00%\n",
      "ae train 실행 시간: 123.247초, 전체 시작 시간 20250314_000238_046\n",
      "\n",
      "epoch-74 accuracy check\n",
      "k_means origin feature average accuracy : 82.25495786%, total [0.9746727376209448, 0.9733106189664963, 0.9700891573195284, 0.9530800230282096, 0.943108504398827, 0.915340909090909, 0.8015244796247435, 0.6622234826999432, 0.9488619568430388, 0.822215777262181, 0.5872695852534562, 0.5005858230814294, 0.9429250891795482, 0.8922588099364529, 0.6741279069767442, 0.5991983967935872]\n",
      "kmeans average accuracy best : 92.99%, kmeans average accuracy : 92.64397113%, total [0.9758110415480934, 0.9775695627484384, 0.9744032211676733, 0.9660333909038572, 0.9680351906158358, 0.9602272727272727, 0.9313984168865436, 0.8664208735110607, 0.9701448418563405, 0.9463457076566125, 0.8842165898617511, 0.8359695371997656, 0.9637336504161712, 0.9422299248989023, 0.8700581395348838, 0.7904380188949327]\n",
      "cluster_accuracy_post_training_cycle_all_dataset : [0.97776727 0.97785108 0.97448243 0.96865959 0.96865672 0.95707547\n",
      " 0.93286922 0.8607714  0.96016137 0.95605469 0.83687259 0.66385303\n",
      " 0.96334012 0.9471387  0.87598039 0.81653129]\n",
      "mean_cluster_accuracy_during_training_cycle : 90.50%, post_traincycle_acc : 91.49%, total_acc : 91.08382370%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 92.70%\n",
      "accuracy_check 실행 시간: 27.822초\n",
      "\n",
      "\n",
      "epoch-75 loss : 0.00760910, loss_normal : 0.01131637, loss_coarse : 0.05151531, min_loss : 0.00759815, min_loss_normal : 0.01131637, min_loss_coarse : 0.05149277, wrong_element_sum : 9890940.00000000, same_data : 0.00%\n",
      "ae train 실행 시간: 124.293초, 전체 시작 시간 20250314_000238_046\n",
      "\n",
      "epoch-75 accuracy check\n",
      "k_means origin feature average accuracy : 82.24959751%, total [0.9746727376209448, 0.9733106189664963, 0.9700891573195284, 0.9530800230282096, 0.943108504398827, 0.9150568181818182, 0.801817648783348, 0.6622234826999432, 0.9488619568430388, 0.822215777262181, 0.5866935483870968, 0.5005858230814294, 0.9429250891795482, 0.8922588099364529, 0.6738372093023256, 0.5991983967935872]\n",
      "kmeans average accuracy best : 92.99%, kmeans average accuracy : 92.98851596%, total [0.9763801935116676, 0.9775695627484384, 0.9741156169111302, 0.9654576856649395, 0.9671554252199414, 0.9619318181818182, 0.9372618000586338, 0.8774815655133296, 0.9742831806089269, 0.951276102088167, 0.8951612903225806, 0.8391915641476274, 0.9622473246135553, 0.9413633737723859, 0.8822674418604651, 0.7950186086458632]\n",
      "cluster_accuracy_post_training_cycle_all_dataset : [0.97776727 0.97832234 0.97448243 0.96769527 0.96766169 0.95754717\n",
      " 0.93983093 0.8664158  0.96570852 0.95556641 0.85135135 0.83416087\n",
      " 0.96283096 0.9471387  0.88480392 0.8107979 ]\n",
      "mean_cluster_accuracy_during_training_cycle : 92.17%, post_traincycle_acc : 92.76%, total_acc : 92.52184283%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 92.70%\n",
      "accuracy_check 실행 시간: 29.527초\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "gpu = '2'\n",
    "Conv_net = True # True False\n",
    "SAE_net = True # True False\n",
    "\n",
    "# hyperparameter\n",
    "dataset_num = 16\n",
    "spike_length = 50 # coarse_com_mode일 때는 time step이 됨.\n",
    "num_cluster = 4  # 클러스터 수 설정 # 논문엔 4개라는데 여기서는 3개로 했네\n",
    "training_cycle = 1400 #1400 2400 # 그 초기 몇개까지만 cluster update할지\n",
    "\n",
    "\n",
    "batch_size = 32\n",
    "max_epoch = 10000\n",
    "learning_rate = 0.001\n",
    "normalize_on = True # True or False # 0부터1까지 normalize\n",
    "need_bias = False\n",
    "# first_layer_no_train = False\n",
    "lif_add_at_first = False\n",
    "my_seed = 42\n",
    "\n",
    "TIME = 50 # SAE일 때만 유효. coarse_com_mode일 때는 level_num이 됨. 즉 feature 개수.\n",
    "v_decay = 0.5 # -cor\n",
    "v_threshold = 0.25 # -cor\n",
    "v_reset = 0.0 # -cor # 10000이상 일 시 hard reset\n",
    "BPTT_on = True # +cor # True False\n",
    "\n",
    "SAE_hidden_nomean = True # True False\n",
    "\n",
    "current_time = datetime.datetime.now().strftime(\"%Y%m%d_%H%M%S\") + f\"_{str(int(datetime.datetime.now().microsecond / 1000)).zfill(3)}\"\n",
    "\n",
    "optimizer = 'Adam' #'Adam', 'SGD' # 둘다 준수함. loss 줄이는 거는 adam이 좋긴한데, cluster accuracy는 비슷함.\n",
    "\n",
    "coarse_com_mode = True # True False\n",
    "coarse_com_config = (0.999, -0.0) # (max, min) (0.999, -0.0) (1.0, -0.0) (2.0, -2.0) (3.0, -3.0)\n",
    "\n",
    "sae_l2_norm_bridge = True # True False\n",
    "sae_lif_bridge = False # True False\n",
    "\n",
    "accuracy_check_epoch_term = 1\n",
    "\n",
    "lif_add_at_last = False # True False\n",
    "\n",
    "two_channel_input = False # True False\n",
    "\n",
    "lateral_feature_num = 6\n",
    "\n",
    "lc_adc_on = False # True False\n",
    "\n",
    "converted_net_forward = False # True False\n",
    "\n",
    "pretrained_net = None\n",
    "# pretrained_net = '/home/bhkim003/github_folder/ByeonghyeonKim/my_snn/net_save/save_now_net_중요_20250110_203117_390.pth'\n",
    "# pretrained_net = '/home/bhkim003/github_folder/ByeonghyeonKim/my_snn/net_save/save_now_net_중요_20250113_134126_881_이거_94나오는거.pth'\n",
    "# pretrained_net =  '/home/bhkim003/github_folder/ByeonghyeonKim/my_snn/net_save/save_now_net_20250205_184901_132.pth'\n",
    "# pretrained_net =  '/home/bhkim003/github_folder/ByeonghyeonKim/my_snn/net_save/save_now_net_20250306_134219_133.pth'\n",
    "\n",
    "vth_mul_on = False # True False\n",
    "batch_norm_on = False # True False\n",
    "\n",
    "l2_norm_loss_weight = 0 #0.0001 #0.1 #  0 # 0초과면 작동\n",
    "\n",
    "QCFS_neuron_on = False # True False\n",
    "\n",
    "quantize_level_num = 0 # 0이면 quantize 안함. 1이상이면 그 수만큼 quantize함. # normalize_on 켜져야됨. 음수면 0~1norm안하고 quant함\n",
    "\n",
    "fusion_net = True # True False # SAE_net False, Conv_net True로 해라. TIME 적절하게 설정해주고.\n",
    "repeat_coding = False # True False #fusion_net에서 쓰이는 거임 # True면 repeat, False면 rate coding.\n",
    "\n",
    "sae_relu_on = False # True False\n",
    "\n",
    "conv1d_scaling = False # True False # conv1d때매 norm하고 (level_num-3)/level_num 곱해줌 # Conv_net and coarse_com_mode and normalize_on\n",
    "\n",
    "norm01 = True # True False # normalize_on = True일 때 01norm하는지 아님 걍 quant만 하는지.\n",
    "\n",
    "wandb.init(project= f'spike_sorting just run',save_code=False)\n",
    "\n",
    "\n",
    "cluster_train_system( \n",
    "    gpu = gpu,\n",
    "    Conv_net = Conv_net,\n",
    "    SAE_net = SAE_net,\n",
    "\n",
    "    # hyperparameter\n",
    "    dataset_num = dataset_num,\n",
    "    spike_length = spike_length,\n",
    "    num_cluster = num_cluster,  # 클러스터 수 설정 # 논문엔 4개라는데 여기서는 3개로 했네\n",
    "    training_cycle = training_cycle, # 그 초기 몇개까지만 cluster update할지\n",
    "\n",
    "\n",
    "    batch_size = batch_size,\n",
    "    max_epoch = max_epoch,\n",
    "    learning_rate = learning_rate,\n",
    "    normalize_on = normalize_on, # True or False #이거 안 씀 # 이거 별로 안 좋은 normalize같음 # 쓸 거면 다른 거 써라.\n",
    "    need_bias = need_bias,\n",
    "    # first_layer_no_train = False\n",
    "    lif_add_at_first = lif_add_at_first,\n",
    "    my_seed = my_seed,\n",
    "\n",
    "    TIME = TIME, # SAE일 때만 유효\n",
    "    v_decay = v_decay,\n",
    "    v_threshold = v_threshold,\n",
    "    v_reset = v_reset, # 10000이상 일 시 hard reset\n",
    "    BPTT_on = BPTT_on,\n",
    "\n",
    "    SAE_hidden_nomean = SAE_hidden_nomean,\n",
    "    \n",
    "    current_time = current_time,\n",
    "\n",
    "    optimizer = optimizer, #'Adam', 'SGD'\n",
    "\n",
    "    coarse_com_mode = coarse_com_mode,\n",
    "    coarse_com_config = coarse_com_config, # (max, min)\n",
    "\n",
    "    \n",
    "    sae_l2_norm_bridge = sae_l2_norm_bridge,\n",
    "    sae_lif_bridge = sae_lif_bridge,\n",
    "\n",
    "    accuracy_check_epoch_term = accuracy_check_epoch_term,\n",
    "    \n",
    "    lif_add_at_last = lif_add_at_last,\n",
    "\n",
    "    two_channel_input = two_channel_input,\n",
    "\n",
    "    lateral_feature_num = lateral_feature_num,\n",
    "\n",
    "    lc_adc_on = lc_adc_on, \n",
    "\n",
    "    converted_net_forward = converted_net_forward,\n",
    "\n",
    "    pretrained_net = pretrained_net,\n",
    "\n",
    "    vth_mul_on = vth_mul_on,\n",
    "    batch_norm_on = batch_norm_on,\n",
    "\n",
    "    l2_norm_loss_weight = l2_norm_loss_weight,\n",
    "    \n",
    "    QCFS_neuron_on = QCFS_neuron_on, # True False\n",
    "\n",
    "    quantize_level_num = quantize_level_num,\n",
    "\n",
    "    fusion_net = fusion_net, # True False\n",
    "    repeat_coding = repeat_coding,\n",
    "\n",
    "    sae_relu_on = sae_relu_on,\n",
    "\n",
    "    conv1d_scaling = conv1d_scaling,\n",
    "\n",
    "    norm01 = norm01,\n",
    "\n",
    "    )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Sweep code\n",
    "\n",
    "\n",
    "# from unittest import TextTestRunner\n",
    "\n",
    "\n",
    "# unique_name_hyper = 'cluster_train_system'\n",
    "# # run_name = 'spike_sorting'\n",
    "# sweep_start_time =  datetime.datetime.now().strftime(\"%Y%m%d_%H%M%S\") + f\"_{str(int(datetime.datetime.now().microsecond / 1000)).zfill(3)}\"\n",
    "# sweep_configuration = {\n",
    "#     'method': 'bayes', # 'random', 'bayes'\n",
    "#     'name': f'spike_sorting_{sweep_start_time}',\n",
    "#     'metric': {'goal': 'maximize', 'name': 'k_means_acc_best'},\n",
    "#     'parameters': \n",
    "#     {\n",
    "#         # \"gpu\": {\"values\": ['1']},  # 이건 sweep parameter아님. hyper_iter에서 직접 설정\n",
    "#         \"Conv_net\": {\"values\": [True]}, \n",
    "#         \"SAE_net\": {\"values\": [True]}, \n",
    "\n",
    "#         \"dataset_num\": {\"values\": [16]}, \n",
    "#         \"spike_length\": {\"values\": [50]},  \n",
    "#         \"num_cluster\": {\"values\": [4]}, \n",
    "#         \"training_cycle\": {\"values\": [1400]}, # [1400, 2400]\n",
    "\n",
    "#         \"batch_size\": {\"values\": [32]}, \n",
    "#         \"max_epoch\": {\"values\": [20]}, \n",
    "#         \"learning_rate\": {\"values\": [0.001, 0.0001]},\n",
    "#         \"normalize_on\": {\"values\": [True]},\n",
    "#         \"need_bias\": {\"values\": [False]}, # [True, False]\n",
    "\n",
    "#         \"lif_add_at_first\": {\"values\": [False]}, # [True, False]\n",
    "#         \"my_seed\": {\"values\": [42]}, \n",
    "\n",
    "#         \"TIME\": {\"values\": [50]}, #  [4,6,8,10]\n",
    "#         \"v_decay\": {\"values\": [0.125, 0.25,0.50,0.75,1.0]}, # [0.25,0.50,0.75]\n",
    "#         \"v_threshold\": {\"values\": [0.125, 0.25, 0.50, 0.75, 0.875, 1.0]}, # [0.25,0.50,0.75]\n",
    "#         \"v_reset\": {\"values\": [0.0, 10000.0]},  # [0.0, 10000.0]\n",
    "#         \"BPTT_on\": {\"values\": [True, False]},  # [True, False]\n",
    "\n",
    "#         \"SAE_hidden_nomean\": {\"values\": [True]}, # [True, False]\n",
    "\n",
    "#         # \"current_time\": {\"values\": [current_time]} #밑에서 직접설정됨.\n",
    "\n",
    "#         \"optimizer\": {\"values\": ['Adam', 'SGD']}, # ['Adam', 'SGD']\n",
    "\n",
    "#         \"coarse_com_mode\": {\"values\": [True]}, # [True, False]\n",
    "#         \"coarse_com_config\": {\"values\": [(0.999, -0.0)]}, # ['Adam', 'SGD']\n",
    "\n",
    "#         \"sae_l2_norm_bridge\": {\"values\": [True]}, # [True, False]\n",
    "#         \"sae_lif_bridge\": {\"values\": [False]}, # [False, True]\n",
    "        \n",
    "#         \"accuracy_check_epoch_term\": {\"values\": [1]}, \n",
    "\n",
    "#         \"lif_add_at_last\": {\"values\": [False]},# [True, False]\n",
    "\n",
    "#         \"two_channel_input\": {\"values\": [False]},# [True, False]\n",
    "\n",
    "#         \"lateral_feature_num\": {\"values\": [4]},# [True, False]\n",
    "\n",
    "#         \"lc_adc_on\": {\"values\": [False]},# [True, False]\n",
    "        \n",
    "#         \"converted_net_forward\": {\"values\": [False]},# [True, False]\n",
    "\n",
    "#         \"pretrained_net\": {\"values\": [None]},# [None]\n",
    "\n",
    "#         \"vth_mul_on\": {\"values\": [False]},# [True, False]\n",
    "#         \"batch_norm_on\": {\"values\": [False]},# [True, False]\n",
    "\n",
    "#         \"l2_norm_loss_weight\": {\"values\": [0]},\n",
    "\n",
    "#         \"QCFS_neuron_on\": {\"values\": [False]},   # [True, False]\n",
    "\n",
    "#         \"quantize_level_num\": {\"values\": [0]}, \n",
    "\n",
    "#         \"fusion_net\": {\"values\": [True]}, \n",
    "#         \"repeat_coding\": {\"values\": [False]}, \n",
    "\n",
    "#         \"sae_relu_on\": {\"values\": [False]}, \n",
    "\n",
    "#         \"conv1d_scaling\": {\"values\": [False]}, \n",
    "\n",
    "#         \"norm01\": {\"values\": [True]}, \n",
    "#      }\n",
    "# }\n",
    "\n",
    "\n",
    "# def hyper_iter():\n",
    "#     ### my_snn control board ########################\n",
    "#     wandb.init(save_code = False)\n",
    "#     gpu  =  '2'\n",
    "#     Conv_net  =  wandb.config.Conv_net\n",
    "#     SAE_net  =  wandb.config.SAE_net\n",
    "\n",
    "#     dataset_num  =  wandb.config.dataset_num\n",
    "#     spike_length  =  wandb.config.spike_length\n",
    "#     num_cluster  =  wandb.config.num_cluster\n",
    "#     training_cycle  =  wandb.config.training_cycle\n",
    "\n",
    "#     batch_size  =  wandb.config.batch_size\n",
    "#     max_epoch  =  wandb.config.max_epoch\n",
    "#     learning_rate  =  wandb.config.learning_rate\n",
    "#     normalize_on  =  wandb.config.normalize_on\n",
    "#     need_bias  =  wandb.config.need_bias\n",
    "\n",
    "#     lif_add_at_first  =  wandb.config.lif_add_at_first\n",
    "#     my_seed  =  wandb.config.my_seed\n",
    "\n",
    "\n",
    "#     TIME  =  wandb.config.TIME\n",
    "#     v_decay  =  wandb.config.v_decay\n",
    "#     v_threshold  =  wandb.config.v_threshold\n",
    "#     v_reset  =  wandb.config.v_reset\n",
    "#     BPTT_on  =  wandb.config.BPTT_on\n",
    "\n",
    "#     SAE_hidden_nomean  =  wandb.config.SAE_hidden_nomean\n",
    "    \n",
    "#     current_time =  datetime.datetime.now().strftime(\"%Y%m%d_%H%M%S\") + f\"_{str(int(datetime.datetime.now().microsecond / 1000)).zfill(3)}\"\n",
    "\n",
    "#     optimizer  =  wandb.config.optimizer\n",
    "\n",
    "#     coarse_com_mode = wandb.config.coarse_com_mode\n",
    "#     coarse_com_config = wandb.config.coarse_com_config # (max, min)\n",
    "\n",
    "#     sae_l2_norm_bridge = wandb.config.sae_l2_norm_bridge\n",
    "#     sae_lif_bridge = wandb.config.sae_lif_bridge\n",
    "\n",
    "#     accuracy_check_epoch_term = wandb.config.accuracy_check_epoch_term\n",
    "\n",
    "#     lif_add_at_last = wandb.config.lif_add_at_last\n",
    "\n",
    "#     two_channel_input = wandb.config.two_channel_input\n",
    "\n",
    "#     lateral_feature_num = wandb.config.lateral_feature_num\n",
    "\n",
    "#     lc_adc_on = wandb.config.lc_adc_on\n",
    "\n",
    "#     converted_net_forward = wandb.config.converted_net_forward\n",
    "\n",
    "#     pretrained_net = wandb.config.pretrained_net\n",
    "\n",
    "#     vth_mul_on = wandb.config.vth_mul_on\n",
    "#     batch_norm_on = wandb.config.batch_norm_on\n",
    "\n",
    "#     l2_norm_loss_weight = wandb.config.l2_norm_loss_weight\n",
    "\n",
    "#     QCFS_neuron_on = wandb.config.QCFS_neuron_on\n",
    "\n",
    "#     quantize_level_num = wandb.config.quantize_level_num\n",
    "\n",
    "#     fusion_net = wandb.config.fusion_net\n",
    "#     repeat_coding = wandb.config.repeat_coding\n",
    "\n",
    "#     sae_relu_on = wandb.config.sae_relu_on\n",
    "\n",
    "#     conv1d_scaling = wandb.config.conv1d_scaling\n",
    "\n",
    "#     norm01 = wandb.config.norm01\n",
    "\n",
    "#     cluster_train_system( \n",
    "#         gpu = gpu,\n",
    "#         Conv_net = Conv_net,\n",
    "#         SAE_net = SAE_net,\n",
    "\n",
    "#         # hyperparameter\n",
    "#         dataset_num = dataset_num,\n",
    "#         spike_length = spike_length,\n",
    "#         num_cluster = num_cluster,  # 클러스터 수 설정 # 논문엔 4개라는데 여기서는 3개로 했네\n",
    "#         training_cycle = training_cycle, # 그 초기 몇개까지만 cluster update할지\n",
    "\n",
    "\n",
    "#         batch_size = batch_size,\n",
    "#         max_epoch = max_epoch,\n",
    "#         learning_rate = learning_rate,\n",
    "#         normalize_on = normalize_on, # True or False #이거 안 씀 # 이거 별로 안 좋은 normalize같음 # 쓸 거면 다른 거 써라.\n",
    "#         need_bias = need_bias,\n",
    "#         # first_layer_no_train = False\n",
    "#         lif_add_at_first = lif_add_at_first,\n",
    "#         my_seed = my_seed,\n",
    "\n",
    "#         TIME = TIME, # SAE일 때만 유효\n",
    "#         v_decay = v_decay,\n",
    "#         v_threshold = v_threshold,\n",
    "#         v_reset = v_reset, # 10000이상 일 시 hard reset\n",
    "#         BPTT_on = BPTT_on,\n",
    "\n",
    "#         SAE_hidden_nomean = SAE_hidden_nomean,\n",
    "\n",
    "#         current_time = current_time,\n",
    "\n",
    "#         optimizer = optimizer, #'Adam', 'SGD'\n",
    "\n",
    "#         coarse_com_mode = coarse_com_mode,\n",
    "#         coarse_com_config = coarse_com_config, # (max, min)\n",
    "        \n",
    "#         sae_l2_norm_bridge = sae_l2_norm_bridge,\n",
    "#         sae_lif_bridge = sae_lif_bridge,\n",
    "\n",
    "#         accuracy_check_epoch_term = accuracy_check_epoch_term,\n",
    "\n",
    "#         lif_add_at_last = lif_add_at_last,\n",
    "        \n",
    "#         two_channel_input = two_channel_input,\n",
    "        \n",
    "#         lateral_feature_num = lateral_feature_num,\n",
    "\n",
    "#         lc_adc_on = lc_adc_on,\n",
    "\n",
    "#         converted_net_forward = converted_net_forward,\n",
    "\n",
    "#         pretrained_net = pretrained_net,\n",
    "\n",
    "#         vth_mul_on = vth_mul_on,\n",
    "#         batch_norm_on = batch_norm_on,\n",
    "\n",
    "#         l2_norm_loss_weight = l2_norm_loss_weight,\n",
    "\n",
    "#         QCFS_neuron_on = QCFS_neuron_on,\n",
    "\n",
    "#         quantize_level_num = quantize_level_num,\n",
    "\n",
    "#         fusion_net = fusion_net, \n",
    "#         repeat_coding = repeat_coding, \n",
    "\n",
    "#         sae_relu_on = sae_relu_on,\n",
    "\n",
    "#         conv1d_scaling = conv1d_scaling,\n",
    "\n",
    "#         norm01 = norm01,\n",
    "#         )\n",
    "    \n",
    "# # sweep_id = 'ygoj9jt4'\n",
    "# sweep_id = wandb.sweep(sweep=sweep_configuration, project=f'spike_sorting {unique_name_hyper}')\n",
    "# wandb.agent(sweep_id, function=hyper_iter, count=100000, project=f'spike_sorting {unique_name_hyper}')\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wandb.finish() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import matplotlib.pyplot as plt\n",
    "# from matplotlib.ticker import MaxNLocator\n",
    "# import pickle\n",
    "# import json\n",
    "\n",
    "# # current_time = '20250102_225243_972'\n",
    "\n",
    "# with open(f\"result_save/cluster_accuracy_history_{current_time}.pkl\", \"rb\") as f:\n",
    "#     data = pickle.load(f)\n",
    "\n",
    "\n",
    "# # JSON으로 저장\n",
    "# with open(f\"result_save/cluster_accuracy_history_{current_time}.json\", 'r') as f:\n",
    "#     loaded_hyperparameters = json.load(f)\n",
    "\n",
    "# loss_history = data['loss_history']\n",
    "# mean_cluster_accuracy_during_training_cycle_all_dataset_history = data['mean_cluster_accuracy_during_training_cycle_all_dataset_history']\n",
    "# mean_cluster_accuracy_post_training_cycle_all_dataset_history = data['mean_cluster_accuracy_post_training_cycle_all_dataset_history']\n",
    "# mean_cluster_accuracy_total_all_dataset_history = data['mean_cluster_accuracy_total_all_dataset_history']\n",
    "# print(data)\n",
    "# max_acc = 0\n",
    "# for i in mean_cluster_accuracy_post_training_cycle_all_dataset_history:\n",
    "#     if i[1] > max_acc:\n",
    "#         max_acc = i[1]\n",
    "\n",
    "# # 설정 정보 제목 작성\n",
    "# title = (\n",
    "#     f\"Dataset Num: {loaded_hyperparameters['dataset_num']}, Conv {loaded_hyperparameters['Conv_net']}, SAE {loaded_hyperparameters['SAE_net']}, Current time {loaded_hyperparameters['current_time']}, Spike Length: {loaded_hyperparameters['spike_length']}, Num Cluster: {loaded_hyperparameters['num_cluster']}, \"\n",
    "#     f\"Training Cycle: {loaded_hyperparameters['training_cycle']}, Batch Size: {loaded_hyperparameters['batch_size']}, Max Epoch: {loaded_hyperparameters['max_epoch']}, \\n\"\n",
    "#     f\"Learning Rate: {loaded_hyperparameters['learning_rate']}, Input Normalize: {loaded_hyperparameters['normalize_on']}, Need Bias: {loaded_hyperparameters['need_bias']}, \"\n",
    "#     f\"LIF Add at First: {loaded_hyperparameters['lif_add_at_first']}, TIME: {loaded_hyperparameters['TIME']}, Seed: {loaded_hyperparameters['my_seed']}, Best ACC: {max_acc:.2f}%\"\n",
    "# )\n",
    "\n",
    "# # 데이터 리스트와 라벨 설정 (Loss 제외)\n",
    "# data_list = [\n",
    "#     (\"Mean Cluster Accuracy (During Training Cycle)\", mean_cluster_accuracy_during_training_cycle_all_dataset_history),\n",
    "#     (\"Mean Cluster Accuracy (Post Training Cycle)\", mean_cluster_accuracy_post_training_cycle_all_dataset_history),\n",
    "#     (\"Mean Cluster Accuracy (Total)\", mean_cluster_accuracy_total_all_dataset_history),\n",
    "# ]\n",
    "\n",
    "# # 플롯 생성\n",
    "# fig, ax1 = plt.subplots(figsize=(12, 8))\n",
    "\n",
    "# # 첫 번째 y축: Accuracy 관련 데이터\n",
    "# for label, data in data_list:\n",
    "#     epochs, values = zip(*data)  # epoch, value 분리\n",
    "#     ax1.plot(epochs, values, label=label)\n",
    "\n",
    "# ax1.set_xlabel(\"Epoch\")\n",
    "# ax1.set_ylabel(\"Clurstering Accuracy [%]\", color=\"blue\")\n",
    "# ax1.tick_params(axis=\"y\", labelcolor=\"blue\")\n",
    "# ax1.legend(loc=\"center right\")\n",
    "# ax1.grid(True)\n",
    "\n",
    "# # x축을 정수만 표시하도록 설정\n",
    "# ax1.xaxis.set_major_locator(MaxNLocator(integer=True))\n",
    "\n",
    "# # 두 번째 y축: Loss History\n",
    "# ax2 = ax1.twinx()\n",
    "# epochs, values = zip(*loss_history)\n",
    "# ax2.plot(epochs, values, label=\"AE Loss History\", color=\"red\", linestyle=\"--\")\n",
    "# ax2.set_ylabel(\"Loss\", color=\"red\")\n",
    "# ax2.tick_params(axis=\"y\", labelcolor=\"red\")\n",
    "# ax2.legend(loc=\"center left\")\n",
    "\n",
    "# # 제목 추가\n",
    "# plt.title(title, fontsize=10)\n",
    "# plt.tight_layout()\n",
    "# plt.savefig(f'net_save/{current_time}', dpi=300, bbox_inches=\"tight\")  # dpi=300은 고해상도로 저장, bbox_inches=\"tight\"는 여백 최소화\n",
    "# plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# 데이터셋\n",
    "filename_for_plot = [\n",
    "    \"Easy1_noise05\", \"Easy1_noise10\", \"Easy1_noise15\", \"Easy1_noise20\",\n",
    "    \"Easy2_noise05\", \"Easy2_noise10\", \"Easy2_noise15\", \"Easy2_noise20\",\n",
    "    \"Difficult1_noise05\", \"Difficult1_noise10\", \"Difficult1_noise15\", \"Difficult1_noise20\",\n",
    "    \"Difficult2_noise05\", \"Difficult2_noise10\", \"Difficult2_noise15\", \"Difficult2_noise20\"\n",
    "]\n",
    "\n",
    "# Accuracy 데이터\n",
    "ANN_conv_accracy_set= [0.97935368, 0.97682709, 0.97028784, 0.96461825, 0.97524752, 0.95803571\n",
    ", 0.95746785, 0.92628774, 0.965412,  0.97805344, 0.94869403, 0.92110454\n",
    ", 0.96784232, 0.97551789, 0.91538462, 0.84446478]\n",
    "SNN_fc_accuracy_set = [0.97114475, 0.97643732, 0.84400578, 0.78977821, 0.96616915, 0.92830189\n",
    ", 0.86176032, 0.31984948, 0.80635401, 0.88769531, 0.61003861, 0.60377358\n",
    ", 0.9592668,  0.92870999, 0.78333333, 0.67271859]\n",
    "SNN_conv_accuracy_set = [0.97445601, 0.97737983, 0.97063072, 0.95998071, 0.96268657, 0.90566038\n",
    ", 0.82545997, 0.68391345, 0.96116994, 0.92138672, 0.80694981, 0.49602781\n",
    ", 0.83604888, 0.70611057, 0.69313725, 0.5819398 ]\n",
    "\n",
    "# 평균 계산\n",
    "average_ANN_conv = np.mean(ANN_conv_accracy_set)\n",
    "average_SNN_fc = np.mean(SNN_fc_accuracy_set)\n",
    "average_SNN_conv = np.mean(SNN_conv_accuracy_set)\n",
    "\n",
    "# 데이터 준비\n",
    "accuracies = np.array([ANN_conv_accracy_set, SNN_fc_accuracy_set, SNN_conv_accuracy_set])\n",
    "averages = np.array([average_ANN_conv, average_SNN_fc, average_SNN_conv])\n",
    "\n",
    "# 시각화\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "\n",
    "# 각 모델의 정확도 플롯\n",
    "ax.plot(accuracies[0], label='ANN Conv', marker='o', linestyle='-', color='blue')\n",
    "ax.plot(accuracies[1], label='SNN FC', marker='o', linestyle='-', color='green')\n",
    "ax.plot(accuracies[2], label='SNN Conv', marker='o', linestyle='-', color='red')\n",
    "\n",
    "# 평균값 플롯\n",
    "ax.axhline(y=average_ANN_conv, color='blue', linestyle='--', label=f'Average ANN Conv: {average_ANN_conv:.3f}')\n",
    "ax.axhline(y=average_SNN_fc, color='green', linestyle='--', label=f'Average SNN FC: {average_SNN_fc:.3f}')\n",
    "ax.axhline(y=average_SNN_conv, color='red', linestyle='--', label=f'Average SNN Conv: {average_SNN_conv:.3f}')\n",
    "\n",
    "# 레이블 추가\n",
    "ax.set_xticks(np.arange(len(filename_for_plot)))\n",
    "ax.set_xticklabels(filename_for_plot, rotation=45, ha='right')\n",
    "ax.set_ylabel('Accuracy')\n",
    "ax.set_title('Accuracy Comparison of Models on Datasets')\n",
    "ax.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import matplotlib.pyplot as plt\n",
    "import os  # 파일 경로 처리를 위한 모듈\n",
    "\n",
    "# CSV 파일 경로\n",
    "# csv_file_path = \"/home/bhkim003/github_folder/ByeonghyeonKim/my_snn/ae_test_deprecated/250115/sweep0_vth_mul.csv\" # vth_mul해서 sweep 돌린거\n",
    "csv_file_path = \"/home/bhkim003/github_folder/ByeonghyeonKim/my_snn/ae_test_deprecated/250115/sweep1.csv\"  #vth_mul안한거\n",
    "\n",
    "# 결과를 저장할 리스트\n",
    "tuple_list = []\n",
    "\n",
    "# CSV 파일 읽기\n",
    "with open(csv_file_path, 'r') as file:\n",
    "    reader = csv.DictReader(file)\n",
    "    for row in reader:\n",
    "        try:\n",
    "            # v_threshold, TIME, v_reset, converted_k_means_acc 값을 가져와 튜플로 변환\n",
    "            v_threshold = float(row[\"v_threshold\"])\n",
    "            time = int(row[\"TIME\"])\n",
    "            v_reset = int(row[\"v_reset\"])\n",
    "            converted_k_means_acc = float(row[\"converted_k_means_acc\"]) if row[\"converted_k_means_acc\"] else None\n",
    "\n",
    "            # 튜플 형태로 추가 (값이 None일 경우 처리할 수도 있음)\n",
    "            tuple_list.append((v_threshold, time, v_reset, converted_k_means_acc))\n",
    "        except ValueError as e:\n",
    "            print(f\"Error processing row {row}: {e}\")\n",
    "\n",
    "# 데이터를 TIME 기준으로 정렬\n",
    "tuple_list.sort(key=lambda x: x[1])  # TIME을 기준으로 오름차순 정렬\n",
    "\n",
    "# reset 방식에 따라 데이터를 나누기\n",
    "soft_reset = [t for t in tuple_list if t[2] == 0]\n",
    "hard_reset = [t for t in tuple_list if t[2] == 10000]\n",
    "\n",
    "# reset 방식과 v_threshold에 따라 색상 설정\n",
    "def plot_data(data, label_prefix, marker):\n",
    "    for v_threshold in [1.0]:  # v_threshold 기준으로 제한\n",
    "        filtered_data = [(t[1], t[3]) for t in data if t[0] == v_threshold]\n",
    "        if filtered_data:  # 해당 v_threshold 데이터가 있을 경우만 플롯\n",
    "            times, accuracies = zip(*filtered_data)  # x축(TIME), y축(converted_k_means_acc)\n",
    "            \n",
    "            plt.plot(\n",
    "                times,\n",
    "                accuracies,\n",
    "                marker,\n",
    "                label=f\"{label_prefix}, v_threshold={v_threshold}\",\n",
    "                linestyle=\"--\",\n",
    "            )\n",
    "            # 각 점에 accuracy 표시\n",
    "            for time, acc in filtered_data:\n",
    "                if acc == None:\n",
    "                    continue\n",
    "                plt.text(time, acc, f\"{acc:.2f}\", fontsize=8, ha=\"right\")\n",
    "\n",
    "# 그래프 초기화\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "# soft_reset (v_reset=0) 데이터 플롯\n",
    "plot_data(soft_reset, \"Soft Reset\", \"o\")\n",
    "\n",
    "# hard_reset (v_reset=10000) 데이터 플롯\n",
    "plot_data(hard_reset, \"Hard Reset\", \"x\")\n",
    "\n",
    "# baseline accuracy 가로선 추가\n",
    "baseline_accuracy = 94.43\n",
    "plt.axhline(y=baseline_accuracy, color=\"red\", linestyle=\"-\", label=f\"Baseline Accuracy ({baseline_accuracy}%)\")\n",
    "# baseline 텍스트 추가\n",
    "plt.text(\n",
    "    2000,  # x축 위치 (그래프 오른쪽 끝)\n",
    "    baseline_accuracy + 0.4,  # y축 위치 (baseline 위 약간)\n",
    "    f\"ANN Baseline ({baseline_accuracy}%)\",\n",
    "    color=\"red\",\n",
    "    fontsize=10,\n",
    "    ha=\"center\",\n",
    ")\n",
    "\n",
    "# CSV 파일 이름 가져오기\n",
    "csv_file_name = os.path.basename(csv_file_path)\n",
    "\n",
    "# 그래프 세부 설정\n",
    "plt.title(f\"Converted SNN K-Means Accuracy vs TIME STEP - {csv_file_name}\")\n",
    "plt.xlabel(\"TIME STEP\")\n",
    "plt.ylabel(\"Converted K-Means Accuracy [%]\")\n",
    "plt.legend(loc=\"lower right\")  # 범례를 오른쪽 아래로 이동\n",
    "plt.grid(True)\n",
    "\n",
    "# 그래프 출력\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aedat2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
