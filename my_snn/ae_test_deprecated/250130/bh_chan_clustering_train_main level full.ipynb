{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ssp.train.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x600 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import torch   \n",
    "import torch.nn as nn \n",
    "import torch.nn.functional as F   \n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import torch.optim as optim\n",
    "from scipy import io\n",
    "import itertools\n",
    "import math\n",
    "import datetime\n",
    "import wandb\n",
    "import pickle\n",
    "import json\n",
    "import time\n",
    "import sys\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import accuracy_score\n",
    "from scipy.optimize import linear_sum_assignment\n",
    "from snntorch import spikegen\n",
    "\n",
    "\n",
    "# my module import\n",
    "from modules import *\n",
    "\n",
    "# modules 폴더에 새모듈.py 만들면\n",
    "# modules/__init__py 파일에 form .새모듈 import * 하셈\n",
    "# 그리고 새모듈.py에서 from modules.새모듈 import * 하셈"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cluster_train_system( \n",
    "    gpu = '4',\n",
    "    Conv_net = True,\n",
    "    SAE_net = True,\n",
    "\n",
    "    # hyperparameter\n",
    "    dataset_num = 16,\n",
    "    spike_length = 50,\n",
    "    num_cluster = 4,  # 클러스터 수 설정 # 논문엔 4개라는데 여기서는 3개로 했네\n",
    "    training_cycle = 2400, # 그 초기 몇개까지만 cluster update할지\n",
    "\n",
    "\n",
    "    batch_size = 32,\n",
    "    max_epoch = 7000,\n",
    "    learning_rate = 0.001,\n",
    "    normalize_on = False, # True or False #이거 안 씀 # 이거 별로 안 좋은 normalize같음 # 쓸 거면 다른 거 써라.\n",
    "    need_bias = False,\n",
    "    # first_layer_no_train = False\n",
    "    lif_add_at_first = False,\n",
    "    my_seed = 42,\n",
    "\n",
    "    TIME = 10, # SAE일 때만 유효\n",
    "    v_decay = 0.5,\n",
    "    v_threshold = 0.5,\n",
    "    v_reset = 10000.0, # 10000이상 일 시 hard reset\n",
    "    BPTT_on = True,\n",
    "\n",
    "    SAE_hidden_nomean = True,\n",
    "    current_time = '20250101_210938_786',\n",
    "\n",
    "    optimizer = 'Adam',\n",
    "    coarse_com_mode = True,\n",
    "    coarse_com_config = (2.0, -2.0), # (max, min)\n",
    "\n",
    "    sae_l2_norm_bridge = True,\n",
    "    sae_lif_bridge = False,\n",
    "\n",
    "    accuracy_check_epoch_term = 5,\n",
    "    \n",
    "    lif_add_at_last = False,\n",
    "\n",
    "    two_channel_input = False,\n",
    "\n",
    "    lateral_feature_num = 4,\n",
    "\n",
    "    lc_adc_on = False, \n",
    "\n",
    "    converted_net_forward = False,\n",
    "\n",
    "    pretrained_net = None, \n",
    "\n",
    "    vth_mul_on = False,\n",
    "    batch_norm_on = False,\n",
    "\n",
    "    l2_norm_loss_weight = 0.0,\n",
    "\n",
    "    QCFS_neuron_on = False,\n",
    "\n",
    "    quantize_level_num = 0,\n",
    "    ):\n",
    "    if coarse_com_mode == True:\n",
    "        assert coarse_com_config[0] > coarse_com_config[1], 'coarse_com_config[0] > coarse_com_config[1]이어야 함'\n",
    "        assert SAE_net == True, 'coarse_com_mode는 SAE_net이 True일 때만 가능'\n",
    "    if two_channel_input == True:\n",
    "        assert Conv_net and coarse_com_mode, 'two_channel_input는 Conv_net이 True일 때만 가능'\n",
    "    if lc_adc_on == True:\n",
    "        assert coarse_com_mode and SAE_net, 'lc_adc_on은 coarse_com_mode와 SAE_net이 True일 때만 가능'\n",
    "    if converted_net_forward == True:\n",
    "        assert SAE_net == False, 'converted_net_forward는 SAE_net이 False일 때만 가능'\n",
    "    seed_assign(my_seed)\n",
    "    ## 함수 내 모든 로컬 변수 저장 ########################################################\n",
    "    hyperparameters = locals()\n",
    "    print(hyperparameters)\n",
    "    # JSON으로 저장\n",
    "    with open(f\"result_save/cluster_accuracy_history_{current_time}.json\", 'w') as f:\n",
    "        json.dump(hyperparameters, f, indent=4)\n",
    "    ######################################################################################\n",
    "\n",
    "    \n",
    "    wandb.config.update(hyperparameters)\n",
    "    wandb.run.name = f'{current_time}_SAE_net_{SAE_net}_v_threshold_{v_threshold}'\n",
    "    wandb.define_metric(\"best_mean_cluster_accuracy_post_training_cycle_all_dataset2\", summary=\"max\")\n",
    "\n",
    "\n",
    "    my_path_ground_BH = '/data2/spike_sorting/quiroga/BH/'\n",
    "\n",
    "\n",
    "    filename = [\"C_Easy1_noise005.mat\", \"C_Easy1_noise01.mat\", \"C_Easy1_noise015.mat\", \"C_Easy1_noise02.mat\",\n",
    "                \"C_Easy2_noise005.mat\", \"C_Easy2_noise01.mat\", \"C_Easy2_noise015.mat\", \"C_Easy2_noise02.mat\",\n",
    "                \"C_Difficult1_noise005.mat\", \"C_Difficult1_noise01.mat\", \"C_Difficult1_noise015.mat\", \"C_Difficult1_noise02.mat\",\n",
    "                \"C_Difficult2_noise005.mat\", \"C_Difficult2_noise01.mat\", \"C_Difficult2_noise015.mat\", \"C_Difficult2_noise02.mat\"]\n",
    "\n",
    "\n",
    "    spike_tot = [\"BH_Spike_e1n005.npy\", \"BH_Spike_e1n010.npy\", \"BH_Spike_e1n015.npy\", \"BH_Spike_e1n020.npy\",\n",
    "                \"BH_Spike_e2n005.npy\", \"BH_Spike_e2n010.npy\", \"BH_Spike_e2n015.npy\", \"BH_Spike_e2n020.npy\",\n",
    "                \"BH_Spike_d1n005.npy\", \"BH_Spike_d1n010.npy\", \"BH_Spike_d1n015.npy\", \"BH_Spike_d1n020.npy\",\n",
    "                \"BH_Spike_d2n005.npy\", \"BH_Spike_d2n010.npy\", \"BH_Spike_d2n015.npy\", \"BH_Spike_d2n020.npy\"]\n",
    "\n",
    "    label_tot = [\"BH_Label_e1n005.npy\", \"BH_Label_e1n010.npy\", \"BH_Label_e1n015.npy\", \"BH_Label_e1n020.npy\",\n",
    "                \"BH_Label_e2n005.npy\", \"BH_Label_e2n010.npy\", \"BH_Label_e2n015.npy\", \"BH_Label_e2n020.npy\",\n",
    "                \"BH_Label_d1n005.npy\", \"BH_Label_d1n010.npy\", \"BH_Label_d1n015.npy\", \"BH_Label_d1n020.npy\",\n",
    "                \"BH_Label_d2n005.npy\", \"BH_Label_d2n010.npy\", \"BH_Label_d2n015.npy\", \"BH_Label_d2n020.npy\"]\n",
    "\n",
    "    template =  [\"BH_Spike_TEMPLATE_e1n005.npy\", \"BH_Spike_TEMPLATE_e1n010.npy\", \"BH_Spike_TEMPLATE_e1n015.npy\", \"BH_Spike_TEMPLATE_e1n020.npy\",\n",
    "                \"BH_Spike_TEMPLATE_e2n005.npy\", \"BH_Spike_TEMPLATE_e2n010.npy\", \"BH_Spike_TEMPLATE_e2n015.npy\", \"BH_Spike_TEMPLATE_e2n020.npy\",\n",
    "                \"BH_Spike_TEMPLATE_d1n005.npy\", \"BH_Spike_TEMPLATE_d1n010.npy\", \"BH_Spike_TEMPLATE_d1n015.npy\", \"BH_Spike_TEMPLATE_d1n020.npy\",\n",
    "                \"BH_Spike_TEMPLATE_d2n005.npy\", \"BH_Spike_TEMPLATE_d2n010.npy\", \"BH_Spike_TEMPLATE_d2n015.npy\", \"BH_Spike_TEMPLATE_d2n020.npy\"]\n",
    "\n",
    "    AE_train_path_gt_detect = 'BH_quiroga_training_dataset_gt_detect.pt' \n",
    "    AE_test_path_gt_detect = 'BH_quiroga_test_dataset_gt_detect.pt'\n",
    "\n",
    "    AE_train_path_real_detect = 'BH_quiroga_training_dataset_real_detect.pt'\n",
    "    AE_test_path_real_detect = 'BH_quiroga_test_dataset_real_detect.pt'\n",
    "\n",
    "    AE_train_data = AE_train_path_real_detect #AE_train_path_gt_detect #AE_train_path_real_detect\n",
    "    AE_test_data = AE_test_path_real_detect #AE_test_path_gt_detect  #AE_test_path_real_detect\n",
    "\n",
    "    # thr_tot = np.array([0.5, 0.5, 0.55, 0.7, 0.5, 0.5, 0.55, 0.7, 0.5, 0.5, 0.55, 0.7, 0.5, 0.5, 0.55, 0.7])\n",
    "    cos_thr = np.array([0.95, 0.95, 0.95, 0.95, 0.95, 0.95, 0.95, 0.85, 0.95, 0.9, 0.8, 0.95, 0.95, 0.95, 0.95, 0.8])\n",
    "    # tem=10\n",
    "    # cos_thr = np.array([tem, tem, tem, tem, tem, tem, tem, tem, tem, tem, tem, tem, tem, tem, tem, tem, ])\n",
    "\n",
    "    print('cos_thr', cos_thr)\n",
    "    \n",
    "    os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\" \n",
    "    os.environ[\"CUDA_VISIBLE_DEVICES\"]= gpu\n",
    "\n",
    "\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "\n",
    "    if coarse_com_mode == True:\n",
    "        level_num = TIME\n",
    "        TIME = spike_length\n",
    "        spike_length = level_num\n",
    "        level_interval = (coarse_com_config[0] - coarse_com_config[1]) / (level_num-1)  # max - min\n",
    "        levels = [coarse_com_config[1] + level_interval * i for i in range(level_num)]\n",
    "        levels = torch.tensor(levels).to(torch.float).to(device)\n",
    "        levels = levels.repeat(TIME,1) \n",
    "        # print('levels', levels, levels.shape) # TIME, level_num\n",
    "\n",
    "    n_sample = spike_length\n",
    "\n",
    "    class spikedataset(Dataset):\n",
    "        def __init__(self, path, transform = None):    \n",
    "            self.transform = transform\n",
    "            self.spike = torch.load(path)\n",
    "            \n",
    "        def __getitem__(self, index):\n",
    "            spike = self.spike[index]            \n",
    "            if self.transform is not None:\n",
    "                spike = self.transform(spike)\n",
    "            return spike\n",
    "        \n",
    "        def __len__(self):\n",
    "            return len(self.spike)\n",
    "\n",
    "    train_dataset = spikedataset(my_path_ground_BH + AE_train_data)\n",
    "    train_loader = DataLoader(dataset = train_dataset, batch_size = batch_size, shuffle = True)\n",
    "\n",
    "    test_dataset = spikedataset(my_path_ground_BH + AE_test_data)\n",
    "    test_loader = DataLoader(dataset = test_dataset, batch_size = batch_size, shuffle = False)\n",
    "\n",
    "\n",
    "    # vth_mul_on = True # True False\n",
    "    # batch_norm_on = True # True False\n",
    "\n",
    "\n",
    "    # 모델 초기화\n",
    "    if SAE_net == False: # 여기서는 l2norm, lif bridge 둘 다 true면 l2norm먼저\n",
    "        if Conv_net == True:\n",
    "            input_channels = 2 if two_channel_input else 1\n",
    "            net = Autoencoder_conv1(input_channels=input_channels, input_length=n_sample, encoder_ch = [32, 64, 96], fc_dim = lateral_feature_num, padding = 0, stride = 2, kernel_size = 3, need_bias=need_bias, l2norm_bridge=sae_l2_norm_bridge, relu_bridge=sae_lif_bridge, activation_collector_on=False,\n",
    "                                    batch_norm_on=batch_norm_on, QCFS_neuron_on=QCFS_neuron_on).to(device)\n",
    "            net = torch.nn.DataParallel(net)\n",
    "            if converted_net_forward:\n",
    "                converted_net = SAE_converted_conv1(input_channels=input_channels, input_length=n_sample, encoder_ch = [32, 64, 96], fc_dim = lateral_feature_num, padding = 0, stride = 2, kernel_size = 3, \n",
    "                                    synapse_fc_trace_const1=1, \n",
    "                                    synapse_fc_trace_const2=v_decay, #안씀 \n",
    "                                    TIME=TIME, v_init=0.0, v_decay=v_decay, v_threshold=v_threshold, v_reset=v_reset, \n",
    "                                    sg_width=4.0, surrogate='sigmoid', BPTT_on=BPTT_on, need_bias=need_bias, lif_add_at_first=lif_add_at_first,\n",
    "                                    sae_l2_norm_bridge = sae_l2_norm_bridge, sae_lif_bridge = sae_lif_bridge, lif_add_at_last=lif_add_at_last,\n",
    "                                    vth_mul_on=vth_mul_on, batch_norm_on=batch_norm_on).to(device) # lif bridge는 무조건 들어가게 해놨음.\n",
    "                converted_net = torch.nn.DataParallel(converted_net)\n",
    "                print('converted_net', converted_net)\n",
    "        else:\n",
    "            net = Autoencoder_only_FC(encoder_ch=[400, lateral_feature_num], decoder_ch=[400,n_sample], n_sample=n_sample, need_bias=need_bias, l2norm_bridge=sae_l2_norm_bridge, relu_bridge=sae_lif_bridge, activation_collector_on=False,\n",
    "                                    batch_norm_on=batch_norm_on, QCFS_neuron_on=QCFS_neuron_on).to(device)\n",
    "            net = torch.nn.DataParallel(net)\n",
    "            if converted_net_forward:\n",
    "                converted_net = SAE_converted_fc(encoder_ch=[400, lateral_feature_num], \n",
    "                                    decoder_ch=[400, n_sample], \n",
    "                                    in_channels=n_sample, # in_channel 이 여기선 걍 lenght.\n",
    "                                    synapse_fc_trace_const1=1,\n",
    "                                    synapse_fc_trace_const2=v_decay,  #안씀 \n",
    "                                    TIME=TIME, v_init=0.0, v_decay=v_decay, v_threshold=v_threshold, v_reset=v_reset, \n",
    "                                    sg_width=4.0, surrogate='sigmoid', BPTT_on=BPTT_on, need_bias=need_bias, lif_add_at_first=lif_add_at_first,\n",
    "                                    sae_l2_norm_bridge = sae_l2_norm_bridge, sae_lif_bridge = sae_lif_bridge, lif_add_at_last=lif_add_at_last,\n",
    "                                    vth_mul_on=vth_mul_on, batch_norm_on=batch_norm_on).to(device) # lif bridge는 무조건 들어가게 해놨음.\n",
    "                converted_net = torch.nn.DataParallel(converted_net)\n",
    "                # print('converted_net', converted_net)\n",
    "    else: # 여기서는 l2norm, lif bridge 둘 다 true면 lif또는 relu먼저\n",
    "        if Conv_net == True: \n",
    "            input_channels = 2 if two_channel_input else 1\n",
    "            net = SAE_conv1(input_channels=input_channels, input_length=n_sample, encoder_ch = [32, 64, 96], fc_dim = lateral_feature_num, padding = 0, stride = 2, kernel_size = 3, \n",
    "                                synapse_fc_trace_const1=1, \n",
    "                                synapse_fc_trace_const2=v_decay, #안씀 \n",
    "                                TIME=TIME, v_init=0.0, v_decay=v_decay, v_threshold=v_threshold, v_reset=v_reset, \n",
    "                                sg_width=4.0, surrogate='sigmoid', BPTT_on=BPTT_on, need_bias=need_bias, lif_add_at_first=lif_add_at_first,\n",
    "                                sae_l2_norm_bridge = sae_l2_norm_bridge, sae_lif_bridge = sae_lif_bridge, lif_add_at_last=lif_add_at_last).to(device)\n",
    "            net = torch.nn.DataParallel(net)\n",
    "        else:\n",
    "            net = SAE_fc_only(encoder_ch=[400, lateral_feature_num], \n",
    "                                decoder_ch=[400, n_sample], \n",
    "                                in_channels=n_sample, # in_channel 이 여기선 걍 lenght.\n",
    "                                synapse_fc_trace_const1=1,\n",
    "                                synapse_fc_trace_const2=v_decay,  #안씀 \n",
    "                                TIME=TIME, v_init=0.0, v_decay=v_decay, v_threshold=v_threshold, v_reset=v_reset, \n",
    "                                sg_width=4.0, surrogate='sigmoid', BPTT_on=BPTT_on, need_bias=need_bias, lif_add_at_first=lif_add_at_first,\n",
    "                                sae_l2_norm_bridge = sae_l2_norm_bridge, sae_lif_bridge = sae_lif_bridge, lif_add_at_last=lif_add_at_last).to(device)\n",
    "            net = torch.nn.DataParallel(net)\n",
    "\n",
    "    # net = torch.load('/home/bhkim003/github_folder/ByeonghyeonKim/my_snn/net_save/save_now_net_AE_re_e7000.pth')\n",
    "    # net = torch.load('/home/bhkim003/github_folder/ByeonghyeonKim/my_snn/net_save/save_now_net_20250101_210938_786.pth')\n",
    "    # load했으면 torch.nn.DataParallel 하지마\n",
    "    # net.module.load_state_dict(torch.load('/home/bhkim003/github_folder/ByeonghyeonKim/my_snn/net_save/save_now_net_annbase_20250108_210641_941.pth'))\n",
    "    if pretrained_net != None:\n",
    "        ######################## 모델이 달라서 dict로 weight만 넣고싶을 때\n",
    "        # # 저장된 가중치 로드\n",
    "        saved_state_dict = torch.load(pretrained_net)\n",
    "        current_state_dict = net.module.state_dict()\n",
    "\n",
    "        # 함수 호출로 가중치 매핑\n",
    "        updated_state_dict = map_and_load_weights(saved_state_dict, current_state_dict)\n",
    "\n",
    "        # 업데이트된 state_dict를 네트워크에 로드\n",
    "        net.module.load_state_dict(updated_state_dict)\n",
    "        ######################## 모델이 달라서 dict로 weight만 넣고싶을 때\n",
    "\n",
    "        ############## 일반적일 때\n",
    "        # net.module.load_state_dict(torch.load(pretrained_net))\n",
    "        ############## 일반적일 때\n",
    "    \n",
    "        # pre_net = Autoencoder_conv1(input_channels=input_channels, input_length=n_sample, encoder_ch = [32, 64, 96], fc_dim = lateral_feature_num, padding = 0, stride = 2, kernel_size = 3, need_bias=need_bias, l2norm_bridge=sae_l2_norm_bridge, relu_bridge=sae_lif_bridge, activation_collector_on=False,\n",
    "        #                         batch_norm_on=batch_norm_on, QCFS_neuron_on=False).to(device)\n",
    "        # pre_net = torch.nn.DataParallel(net)\n",
    "        # pre_net.module.load_state_dict(torch.load(pretrained_net))\n",
    "        # copy_weights(pre_net.module.encoder , net.module.encoder )\n",
    "        # copy_weights(pre_net.module.decoder , net.module.decoder  )\n",
    "\n",
    "        \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    wandb.watch(net, log=\"all\", log_freq = 10)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    if SAE_net == True:\n",
    "        assert 'SAE' in net.module.__class__.__name__\n",
    "\n",
    "\n",
    "\n",
    "    net = net.to(device)\n",
    "    print(f\"Total number of encoder parameters: {sum(p.numel() for p in net.module.encoder.parameters())}\")\n",
    "    print(net)\n",
    "    print('Device:',device)\n",
    "\n",
    "    \n",
    "    if optimizer == 'Adam':\n",
    "        optimizer = optim.Adam(net.parameters(), lr=learning_rate)\n",
    "    elif optimizer == 'SGD':\n",
    "        optimizer = optim.SGD(net.parameters(), lr = learning_rate, momentum = 0.9)\n",
    "    else:\n",
    "        assert False, 'optimizer를 잘못 입력했습니다.'\n",
    "        \n",
    "    loss_history = []\n",
    "    mean_cluster_accuracy_during_training_cycle_all_dataset_history = []\n",
    "    mean_cluster_accuracy_post_training_cycle_all_dataset_history = []\n",
    "    mean_cluster_accuracy_total_all_dataset_history = []\n",
    "\n",
    "    tau = np.zeros(num_cluster)\n",
    "\n",
    "    print(f\"\\nStart Training, current_time = {current_time}\")\n",
    "    mean_cluster_accuracy_post_training_cycle_all_dataset = 0\n",
    "    best_mean_cluster_accuracy_post_training_cycle_all_dataset = 0\n",
    "\n",
    "    if SAE_net == True:\n",
    "        assert 'SAE' in net.module.__class__.__name__\n",
    "        \n",
    "    k_means_acc_best = 0\n",
    "    for epoch in range(max_epoch):\n",
    "        print()\n",
    "        l2_loss_bin= 0\n",
    "        ae_train_start_time = time.time()\n",
    "        running_loss = 0.0\n",
    "        iter = 0\n",
    "        net.train()\n",
    "        # if True or max_epoch != 1:\n",
    "        if max_epoch != 1:\n",
    "            for data in train_loader:\n",
    "                optimizer.zero_grad()\n",
    "                data = data.to(device)\n",
    "                data = zero_to_one_normalize_features(data, level_num=quantize_level_num) if normalize_on else data\n",
    "                spike_backup = data\n",
    "                spike = data\n",
    "                spike = spike.to(device) # batch, feature\n",
    "                if coarse_com_mode == True and 'SAE' in net.module.__class__.__name__:\n",
    "                    spike = spike.unsqueeze(2).repeat(1, 1, level_num) # spike_length == level_num # (batch, time, feature)로 변환 \n",
    "                    spike = (spike > levels).to(torch.float) \n",
    "\n",
    "                    spike = (spike == 0).cumsum(dim=-1).eq(1).to(torch.float) if lc_adc_on == True else spike\n",
    "\n",
    "                    # spike: batch, time, level_num\n",
    "                    # levels: time, level_num\n",
    "                    if Conv_net == True:\n",
    "                        spike = spike.unsqueeze(-2) # batch, time, in_channel, feature or batch in_channel,feature\n",
    "                        if two_channel_input == True:\n",
    "                            spike_backup = spike_backup.to(device)\n",
    "                            spike_backup = spike_backup.unsqueeze(2).repeat(1, 1, level_num) # spike_length == level_num # (batch, time, feature)로 변환 \n",
    "                            spike_backup = (spike_backup <= levels).to(torch.float) \n",
    "                            spike_backup = (spike_backup == 1).cumsum(dim=-1).eq(1).to(torch.float) if lc_adc_on == True else spike_backup\n",
    "                            spike_backup = spike_backup.unsqueeze(-2)\n",
    "                            spike = torch.cat((spike, spike_backup), dim=-2)\n",
    "                    assert spike.shape[0] == batch_size and spike.shape[1] == TIME\n",
    "                elif 'SAE' in net.module.__class__.__name__:\n",
    "                    spike = spike.unsqueeze(-1).repeat(1, 1, TIME).permute(0,2,1) # (batch, time, feature)로 변환\n",
    "                    if Conv_net == True:\n",
    "                        spike = spike.unsqueeze(-2) # batch, time, in_channel, feature or batch in_channel,feature\n",
    "                else:\n",
    "                    if Conv_net == True:\n",
    "                        spike = spike.unsqueeze(-2) #batch in_channel,feature\n",
    "\n",
    "                # for i in range (3):\n",
    "                #     plot_spike(spike[i,:,0,:].cpu().numpy())\n",
    "                #     plot_spike(spike[i,:,1,:].cpu().numpy())\n",
    "                # assert False\n",
    "                        \n",
    "                # spike_class = net(spike) # batch, time, feature\n",
    "                encoded_spike = net.module.encoder(spike)\n",
    "                spike_class = net.module.decoder(encoded_spike)\n",
    "\n",
    "                if coarse_com_mode == True and 'SAE' in net.module.__class__.__name__:\n",
    "                    criterion = nn.MSELoss().to(device)\n",
    "                    # loss1 = nn.MSELoss()(spike_class[..., 5:25], spike[..., 5:25])\n",
    "                    # loss2 = nn.MSELoss()(spike_class[..., 0:5], spike[..., 0:5])\n",
    "                    # loss3 = nn.MSELoss()(spike_class[..., 25:spike_length], spike[..., 25:spike_length])\n",
    "                    # loss = loss1 * 2.125 + (loss2 + loss3)/4\n",
    "\n",
    "                    # loss1 = nn.MSELoss()(spike_class[..., 5:25, :], spike[..., 5:25, :])\n",
    "                    # loss2 = nn.MSELoss()(spike_class[..., 0:5, :], spike[..., 0:5, :])\n",
    "                    # loss3 = nn.MSELoss()(spike_class[..., 25:spike_length, :], spike[..., 25:spike_length, :])\n",
    "                    # loss = loss1 * 2.125 + (loss2 + loss3)/4\n",
    "\n",
    "                    loss = criterion(spike_class, spike)\n",
    "                elif 'SAE' in net.module.__class__.__name__:\n",
    "                    criterion = nn.MSELoss().to(device)\n",
    "                    loss1 = criterion(spike_class[..., 5:25], spike[..., 5:25])\n",
    "                    loss2 = criterion(spike_class[..., 0:5], spike[..., 0:5])\n",
    "                    loss3 = criterion(spike_class[..., 25:spike_length], spike[..., 25:spike_length])\n",
    "                    loss = loss1 * 2.125 + (loss2 + loss3)/4\n",
    "                    assert spike_length > 25, 'spike_length가 25보다 작음'\n",
    "                else:\n",
    "\n",
    "                    criterion = nn.MSELoss().to(device)\n",
    "                    loss1 = criterion(spike_class[..., 5:25], spike[..., 5:25])\n",
    "                    loss2 = criterion(spike_class[..., 0:5], spike[..., 0:5])\n",
    "                    loss3 = criterion(spike_class[..., 25:spike_length], spike[..., 25:spike_length])\n",
    "                    loss = loss1 * 2.125 + (loss2 + loss3)/4\n",
    "                    assert spike_length > 25, 'spike_length가 25보다 작음'\n",
    "\n",
    "                    if l2_norm_loss_weight > 0:\n",
    "                        assert len(encoded_spike.shape) == 2, 'time 성분 없는 걸로'\n",
    "                        l2_loss = l2_norm_loss(encoded_spike, target_norm=1.0)  # L2Norm Loss 계산, l2 1.0되게.\n",
    "                        loss = loss + l2_loss*l2_norm_loss_weight\n",
    "                        l2_loss_bin += l2_loss.item()\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                running_loss += loss.item()\n",
    "                # print(f'\\nepoch-{epoch}, running_loss : {running_loss:.5f}, iter percent {iter/len(train_loader)*100:.2f}%')\n",
    "                iter += 1\n",
    "        else:\n",
    "            print('\\n\\n\\n max_epoch 1이면 Train 안함!!!!!!!!!!!!!!!!!!!!!')\n",
    "        if l2_norm_loss_weight > 0:\n",
    "            print('l2_loss_bin', l2_loss_bin/len(train_loader))\n",
    "        avg_loss = running_loss / len(train_loader)\n",
    "        assert not np.isnan(avg_loss), f\"Error: avg_loss is NaN! Running loss: {running_loss}, Length of train_loader: {len(train_loader)}\"\n",
    "        loss_history.append((epoch, avg_loss))\n",
    "        print(f'\\nepoch-{epoch} loss : {avg_loss:.5f}')\n",
    "        print(f\"ae train 실행 시간: {time.time()-ae_train_start_time:.3f}초, 전체 시작 시간 {current_time}\")\n",
    "\n",
    "        # plot_activation_distribution(net)\n",
    "\n",
    "        if SAE_net == False and converted_net_forward == True:\n",
    "            source_encoder = net.module.encoder \n",
    "            target_encoder = converted_net.module.encoder  \n",
    "            copy_weights(source_encoder, target_encoder)\n",
    "\n",
    "        cluster_accuracy_during_training_cycle_all_dataset = np.zeros(dataset_num)\n",
    "        cluster_accuracy_post_training_cycle_all_dataset = np.zeros(dataset_num)\n",
    "        cluster_accuracy_total_all_dataset = np.zeros(dataset_num)    \n",
    "\n",
    "        k_means_acc = 0\n",
    "        converted_k_means_acc = 0\n",
    "        if(epoch % accuracy_check_epoch_term == 0 or epoch == 1 or epoch == max_epoch-1): \n",
    "            accuracy_check_start_time = time.time()\n",
    "            print(f'\\nepoch-{epoch} accuracy check')\n",
    "            k_means_bin_origin_feature = []\n",
    "            k_means_bin = []\n",
    "            converted_k_means_bin = []\n",
    "            for ds in range(dataset_num):\n",
    "                # print('\\n', spike_tot[ds])\n",
    "\n",
    "                spike_template = np.load(my_path_ground_BH + template[ds])\n",
    "                spike = np.load(my_path_ground_BH + spike_tot[ds])\n",
    "                label = np.load(my_path_ground_BH + label_tot[ds])\n",
    "                spike_template = torch.from_numpy(spike_template).to(device)\n",
    "                spike = torch.from_numpy(spike).to(device)\n",
    "                spike_template = zero_to_one_normalize_features(spike_template, level_num=quantize_level_num) if normalize_on else spike_template\n",
    "                spike = zero_to_one_normalize_features(spike, level_num=quantize_level_num) if normalize_on else spike\n",
    "                \n",
    "                hidden_size = lateral_feature_num*TIME if 'SAE' in net.module.__class__.__name__ and SAE_hidden_nomean == True else lateral_feature_num\n",
    "\n",
    "                Cluster = np.zeros((num_cluster, hidden_size))\n",
    "                assert Cluster.shape[-1] == hidden_size, '이거 hidden dim 4 아니게 할 거면 잘 바꿔라'\n",
    "                \n",
    "\n",
    "\n",
    "                net.eval()\n",
    "                with torch.no_grad():\n",
    "                    spike_torch = spike_template.float()\n",
    "                    spike_torch = spike_torch[:num_cluster]\n",
    "                    spike_backup = spike_torch\n",
    "                    spike_torch = spike_torch.to(device)\n",
    "                    if coarse_com_mode == True and 'SAE' in net.module.__class__.__name__:\n",
    "                        spike_torch = spike_torch.unsqueeze(2).repeat(1, 1, level_num) # spike_length == level_num # (batch, time, feature)로 변환 \n",
    "                        spike_torch = (spike_torch > levels).to(torch.float) \n",
    "                        spike_torch = (spike_torch == 0).cumsum(dim=-1).eq(1).to(torch.float) if lc_adc_on == True else spike_torch\n",
    "                        if Conv_net == True:\n",
    "                            spike_torch = spike_torch.unsqueeze(-2) # batch, time, in_channel, feature or batch in_channel,feature\n",
    "                            if two_channel_input == True:\n",
    "                                spike_backup = spike_backup.to(device)\n",
    "                                spike_backup = spike_backup.unsqueeze(2).repeat(1, 1, level_num) # spike_length == level_num # (batch, time, feature)로 변환 \n",
    "                                spike_backup = (spike_backup <= levels).to(torch.float) \n",
    "                                spike_backup = (spike_backup == 1).cumsum(dim=-1).eq(1).to(torch.float) if lc_adc_on == True else spike_backup\n",
    "                                spike_backup = spike_backup.unsqueeze(-2) # batch, time, in_channel, feature\n",
    "                                spike_torch = torch.cat((spike_torch, spike_backup), dim=-2)\n",
    "                    elif 'SAE' in net.module.__class__.__name__:\n",
    "                        spike_torch = spike_torch.unsqueeze(1).repeat(1, TIME, 1) # (batch, time, feature)로 변환\n",
    "                        if Conv_net == True:\n",
    "                            spike_torch = spike_torch.unsqueeze(-2) # batch, time, in_channel, feature or batch in_channel,feature\n",
    "                    else:\n",
    "                        if Conv_net == True:\n",
    "                            spike_torch = spike_torch.unsqueeze(-2) #batch in_channel,feature\n",
    "                        if converted_net_forward == True:\n",
    "                            spike_torch_spikegen = spikegen.rate(spike_torch, num_steps=TIME).transpose(0, 1)\n",
    "                    ### forward #######################################################\n",
    "                    inner_inf = net.module.encoder(spike_torch)\n",
    "                    if SAE_net == False and converted_net_forward == True:\n",
    "                        converted_inner_inf = converted_net.module.encoder(spike_torch_spikegen)\n",
    "                    ### forward #######################################################\n",
    "\n",
    "                    # for i in range(3):\n",
    "                    #     plot_spike(spike_torch[i,:,:].cpu().numpy())\n",
    "                    #     plot_spike(inner_inf[i,:].cpu().numpy())\n",
    "                    #     plot_spike(net.module.decoder(inner_inf)[i,:,:].cpu().numpy())\n",
    "                        \n",
    "                    # if 'SAE' in net.module.__class__.__name__:\n",
    "                    #     tensors = [inner_inf[0][i] for i in range(TIME)] \n",
    "                    #     all_equal = all(torch.equal(tensors[0], t) for t in tensors)\n",
    "                    #     print(all_equal, inner_inf)\n",
    "\n",
    "                    if 'SAE' in net.module.__class__.__name__:\n",
    "                        if SAE_hidden_nomean == True:\n",
    "                            inner_inf = inner_inf.reshape(inner_inf.shape[0],-1)# time*feature 펼치기\n",
    "                        else:\n",
    "                            inner_inf = inner_inf.mean(dim=1)# Time 방향으로 평균\n",
    "\n",
    "                    Cluster = inner_inf.cpu().detach().numpy()\n",
    "\n",
    "                encoder_batch = 128\n",
    "                spike_hidden = np.zeros((len(spike), hidden_size))\n",
    "                converted_spike_hidden = np.zeros((len(spike), hidden_size))\n",
    "                net.eval()\n",
    "                with torch.no_grad():\n",
    "                    now_index = 0\n",
    "                    while (1):\n",
    "                        now_end_index = now_index+encoder_batch if now_index+encoder_batch < len(spike) else len(spike)\n",
    "                        spike_batch = spike[now_index:now_end_index] \n",
    "                        spike_torch = spike_batch\n",
    "                        spike_torch = spike_torch.float()\n",
    "                        spike_backup = spike_torch\n",
    "                        spike_torch = spike_torch.to(device)\n",
    "                        if coarse_com_mode == True and 'SAE' in net.module.__class__.__name__:\n",
    "                            spike_torch = spike_torch.unsqueeze(2).repeat(1, 1, level_num) # spike_length == level_num # (batch, time, feature)로 변환 \n",
    "                            spike_torch = (spike_torch > levels).to(torch.float) \n",
    "                            spike_torch = (spike_torch == 0).cumsum(dim=-1).eq(1).to(torch.float) if lc_adc_on == True else spike_torch\n",
    "                            if Conv_net == True:\n",
    "                                spike_torch = spike_torch.unsqueeze(-2) # batch, time, in_channel, feature or batch in_channel,feature\n",
    "                                if two_channel_input == True:\n",
    "                                    spike_backup = spike_backup.to(device)\n",
    "                                    spike_backup = spike_backup.unsqueeze(2).repeat(1, 1, level_num) # spike_length == level_num # (batch, time, feature)로 변환 \n",
    "                                    spike_backup = (spike_backup <= levels).to(torch.float) \n",
    "                                    spike_backup = (spike_backup == 1).cumsum(dim=-1).eq(1).to(torch.float) if lc_adc_on == True else spike_backup\n",
    "                                    spike_backup = spike_backup.unsqueeze(-2)\n",
    "                                    spike_torch = torch.cat((spike_torch, spike_backup), dim=-2)\n",
    "                        elif 'SAE' in net.module.__class__.__name__:\n",
    "                            spike_torch = spike_torch.unsqueeze(1).repeat(1, TIME, 1) # (batch, time, feature)로 변환\n",
    "                            if Conv_net == True:\n",
    "                                spike_torch = spike_torch.unsqueeze(-2) # batch, time, in_channel, feature or batch in_channel,feature\n",
    "                        else:\n",
    "                            if Conv_net == True:\n",
    "                                spike_torch = spike_torch.unsqueeze(-2) #batch in_channel,feature\n",
    "                            if converted_net_forward == True:\n",
    "                                spike_torch_spikegen = spikegen.rate(spike_torch, num_steps=TIME).transpose(0, 1)\n",
    "                                \n",
    "                        ### forward #######################################################\n",
    "                        inner_inf = net.module.encoder(spike_torch)\n",
    "                        if SAE_net == False and converted_net_forward == True:\n",
    "                            converted_inner_inf = converted_net.module.encoder(spike_torch_spikegen)\n",
    "                        ### forward #######################################################\n",
    "                            \n",
    "                        if 'SAE' in net.module.__class__.__name__:\n",
    "                            if SAE_hidden_nomean == True:\n",
    "                                inner_inf = inner_inf.reshape(spike_batch.shape[0],-1)# 펼치기\n",
    "                            else:\n",
    "                                inner_inf = inner_inf.mean(dim=1)# Time 방향으로 평균\n",
    "                        spike_hidden[now_index:now_end_index] = inner_inf.cpu().detach().numpy()\n",
    "                        if SAE_net == False and converted_net_forward == True:\n",
    "                            converted_spike_hidden[now_index:now_end_index] = converted_inner_inf.cpu().detach().numpy()\n",
    "                        now_index += encoder_batch\n",
    "                        if (now_index >= len(spike)):\n",
    "                            break\n",
    "                    \n",
    "                spike_id = np.zeros(len(spike))\n",
    "                distance_sm = np.zeros(num_cluster)\n",
    "                tau = np.zeros(num_cluster)\n",
    "                \n",
    "                plot_tau = []\n",
    "                plot_denominator = []\n",
    "                plot_m = []\n",
    "                plot_max_tau = []\n",
    "                for spike_index in range(len(spike)): \n",
    "                    for q in range(num_cluster):\n",
    "                        tau[q] = np.dot(spike_hidden[spike_index, :], Cluster[q, :]) # 이거 l2norm 거쳐서 나온 거니까 분모 1임.\n",
    "                        denominator =  np.linalg.norm(spike_hidden[spike_index, :])*np.linalg.norm(Cluster[q, :]) + 1e-12\n",
    "                        plot_denominator.append(denominator)\n",
    "                        if 'SAE' in net.module.__class__.__name__: # AE 때는 l2norm거쳐서 나와서 괜찮음\n",
    "                            tau[q] = tau[q] / denominator\n",
    "\n",
    "                        plot_tau.append(tau[q])\n",
    "\n",
    "                    # for i in range(num_cluster): # l2 distance\n",
    "                    #     distance_sm[i] = np.sum(np.power(np.abs(Cluster[i] - spike_hidden[spike_index, :]), 2))\n",
    "                    distance_sm = np.sum(np.power(np.abs(Cluster - spike_hidden[spike_index, :]), 2), axis=1)\n",
    "\n",
    "                    m = np.argmin(distance_sm)\n",
    "                    plot_m.append(m)\n",
    "                    spike_id[spike_index] = m + 1\n",
    "                    # print(spike_tot[ds], spike_index,np.max(tau))\n",
    "                    plot_max_tau.append(np.max(tau))\n",
    "                    if(np.max(tau) >= cos_thr[ds] and spike_index < training_cycle): # 원래 1400 아니냐?\n",
    "                        Cluster[m] = (Cluster[m] * 15 + spike_hidden[spike_index, :])/16\n",
    "\n",
    "\n",
    "                \n",
    "                origin_kmeans_accuracy = cluster_spikes_with_accuracy_torch(features= spike, true_labels=label-1, n_clusters=3, init_point=None)\n",
    "                kmeans_accuracy = cluster_spikes_with_accuracy_torch(features= torch.tensor(spike_hidden).to(device), true_labels=label-1, n_clusters=3, init_point=None)\n",
    "                k_means_bin_origin_feature.append(origin_kmeans_accuracy)\n",
    "                k_means_bin.append(kmeans_accuracy)\n",
    "                if SAE_net == False and converted_net_forward == True:\n",
    "                    converted_kmeans_accuracy = cluster_spikes_with_accuracy_torch(features= torch.tensor(converted_spike_hidden).to(device), true_labels=label-1, n_clusters=3, init_point=None)\n",
    "                    converted_k_means_bin.append(converted_kmeans_accuracy)\n",
    "                # sklearn kmeans인데 cpu많이먹어서 버림.\n",
    "                # origin_kmeans_accuracy = cluster_spikes_with_accuracy(features= spike.cpu().detach().numpy(), true_labels=label-1, n_clusters=3, init_point=None)\n",
    "                # kmeans_accuracy = cluster_spikes_with_accuracy(features= spike_hidden, true_labels=label-1, n_clusters=3, init_point=None)\n",
    "                # k_means_bin_origin_feature.append(origin_kmeans_accuracy)\n",
    "                # k_means_bin.append(kmeans_accuracy)\n",
    "                # if SAE_net == False and converted_net_forward == True:\n",
    "                #     converted_kmeans_accuracy = cluster_spikes_with_accuracy(features= converted_spike_hidden, true_labels=label-1, n_clusters=3, init_point=None)\n",
    "                #     converted_k_means_bin.append(converted_kmeans_accuracy)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "                # print('Cluster',Cluster)\n",
    "                # print('spike_id', spike_id)\n",
    "\n",
    "                # spike id 분포 확인하기\n",
    "                # unique_elements, counts = np.unique(spike_id, return_counts=True)\n",
    "                # print(\"Unique elements:\", unique_elements)\n",
    "                # print(\"Counts:\", counts)\n",
    "\n",
    "                cluster_accuracy_during_training_cycle = np.zeros(math.factorial(num_cluster))\n",
    "                cluster_accuracy_post_training_cycle = np.zeros(math.factorial(num_cluster))\n",
    "                cluster_accuracy_total = np.zeros(math.factorial(num_cluster))\n",
    "                \n",
    "                label_converter_ground = list(range(1, num_cluster + 1)) # [1, 2, 3, 4] 생성\n",
    "                label_converter_permutations = list(itertools.permutations(label_converter_ground)) # 모든 순열 구하기\n",
    "                perm_i = 0\n",
    "                perm_start_time = time.time() \n",
    "                for perm in label_converter_permutations:\n",
    "                    label_converter = list(perm)\n",
    "                    # print(label_converter)\n",
    "                    correct_during_training_cycle = 0\n",
    "                    correct_post_training_cycle = 0\n",
    "\n",
    "                    assert len(spike_id) == len(label), 'spike_id랑 label 길이 같아야 됨.'\n",
    "                    for i in range(len(spike_id)):\n",
    "                        if(label_converter[int(spike_id[i]-1)] == label[i]):\n",
    "                            if i < training_cycle:\n",
    "                                correct_during_training_cycle += 1\n",
    "                            else:\n",
    "                                correct_post_training_cycle += 1\n",
    "\n",
    "                    cluster_accuracy_during_training_cycle[perm_i] = correct_during_training_cycle/training_cycle\n",
    "                    cluster_accuracy_post_training_cycle[perm_i] = correct_post_training_cycle/(len(spike_id)-training_cycle)\n",
    "                    cluster_accuracy_total[perm_i] = (correct_during_training_cycle+correct_post_training_cycle)/(len(spike_id))\n",
    "                    perm_i += 1\n",
    "                # print(f\"perm 실행 시간: {time.time()-perm_start_time:.3f}초\")\n",
    "                \n",
    "                cluster_accuracy_during_training_cycle_all_dataset[ds] = np.max(cluster_accuracy_during_training_cycle)\n",
    "                cluster_accuracy_post_training_cycle_all_dataset[ds] = cluster_accuracy_post_training_cycle[np.argmax(cluster_accuracy_during_training_cycle)]\n",
    "                cluster_accuracy_total_all_dataset[ds] = cluster_accuracy_total[np.argmax(cluster_accuracy_during_training_cycle)]\n",
    "                # plot_distributions(ds, plot_tau, plot_denominator, plot_m, plot_max_tau, cos_thr[ds],\n",
    "                #                    cluster_accuracy_during_training_cycle_all_dataset[ds], cluster_accuracy_post_training_cycle_all_dataset[ds], cluster_accuracy_total_all_dataset[ds])\n",
    "            print(f'k_means origin feature average accuracy : {100*sum(k_means_bin_origin_feature)/(len(k_means_bin_origin_feature)+1e-12):.8f}%, total {k_means_bin_origin_feature}')\n",
    "            \n",
    "            mean_cluster_accuracy_during_training_cycle_all_dataset = np.mean(cluster_accuracy_during_training_cycle_all_dataset)\n",
    "            mean_cluster_accuracy_post_training_cycle_all_dataset = np.mean(cluster_accuracy_post_training_cycle_all_dataset)\n",
    "            mean_cluster_accuracy_total_all_dataset = np.mean(cluster_accuracy_total_all_dataset)\n",
    "            \n",
    "            if SAE_net == False and converted_net_forward == True:\n",
    "                converted_k_means_acc = 100*sum(converted_k_means_bin)/len(converted_k_means_bin)\n",
    "                print(f'converted_kmeans average accuracy : {converted_k_means_acc:.8f}%, total {converted_k_means_bin}')\n",
    "            k_means_acc = 100*sum(k_means_bin)/len(k_means_bin)\n",
    "            if k_means_acc > k_means_acc_best:\n",
    "                # torch.save(net, f\"net_save/save_now_net_{current_time}.pth\")\n",
    "                torch.save(net.module.state_dict(), f\"net_save/save_now_net_{current_time}.pth\")\n",
    "                print('save model')\n",
    "                best_mean_cluster_accuracy_post_training_cycle_all_dataset = mean_cluster_accuracy_post_training_cycle_all_dataset\n",
    "            \n",
    "            k_means_acc_best = max(k_means_acc_best, k_means_acc)\n",
    "            print(f'kmeans average accuracy best : {k_means_acc_best:.2f}%, kmeans average accuracy : {k_means_acc:.8f}%, total {k_means_bin}')\n",
    "            print(f'cluster_accuracy_post_training_cycle_all_dataset : {cluster_accuracy_post_training_cycle_all_dataset}')\n",
    "\n",
    "            \n",
    "            mean_cluster_accuracy_during_training_cycle_all_dataset_history.append((epoch, mean_cluster_accuracy_during_training_cycle_all_dataset*100))\n",
    "            mean_cluster_accuracy_post_training_cycle_all_dataset_history.append((epoch, mean_cluster_accuracy_post_training_cycle_all_dataset*100))\n",
    "            mean_cluster_accuracy_total_all_dataset_history.append((epoch, mean_cluster_accuracy_total_all_dataset*100))\n",
    "            print(f\"mean_cluster_accuracy_during_training_cycle : {mean_cluster_accuracy_during_training_cycle_all_dataset*100:.2f}%, post_traincycle_acc : {mean_cluster_accuracy_post_training_cycle_all_dataset*100:.2f}%, total_acc : {mean_cluster_accuracy_total_all_dataset*100:.8f}%\")\n",
    "\n",
    "            # kmeans accuracy기준으로 좋은 거 저장할 거임\n",
    "            # if mean_cluster_accuracy_post_training_cycle_all_dataset > best_mean_cluster_accuracy_post_training_cycle_all_dataset:\n",
    "            #     # torch.save(net, f\"net_save/save_now_net_{current_time}.pth\")\n",
    "            #     torch.save(net.module.state_dict(), f\"net_save/save_now_net_{current_time}.pth\")\n",
    "            #     print('save model')\n",
    "            #     best_mean_cluster_accuracy_post_training_cycle_all_dataset = mean_cluster_accuracy_post_training_cycle_all_dataset\n",
    "            print(f\"best_mean_cluster_accuracy_post_training_cycle_all_dataset : {best_mean_cluster_accuracy_post_training_cycle_all_dataset*100:.2f}%\")\n",
    "            print(f\"accuracy_check 실행 시간: {time.time()-accuracy_check_start_time:.3f}초\")\n",
    "\n",
    "        wandb.log({\"avg_loss\": avg_loss})\n",
    "        wandb.log({\"mean_cluster_accuracy_post_training_cycle_all_dataset\": mean_cluster_accuracy_post_training_cycle_all_dataset})\n",
    "        wandb.log({\"best_mean_cluster_accuracy_post_training_cycle_all_dataset\": best_mean_cluster_accuracy_post_training_cycle_all_dataset})\n",
    "        wandb.log({\"best_mean_cluster_accuracy_post_training_cycle_all_dataset2\": best_mean_cluster_accuracy_post_training_cycle_all_dataset})\n",
    "        wandb.log({\"k_means_acc\": k_means_acc})\n",
    "        wandb.log({\"k_means_acc_best\": k_means_acc_best})\n",
    "        wandb.log({\"converted_k_means_acc\": converted_k_means_acc})\n",
    "\n",
    "\n",
    "        # 저장\n",
    "        with open(f\"result_save/cluster_accuracy_history_{current_time}.pkl\", \"wb\") as f:\n",
    "            pickle.dump({\n",
    "                \"loss_history\": loss_history,\n",
    "                \"mean_cluster_accuracy_during_training_cycle_all_dataset_history\": mean_cluster_accuracy_during_training_cycle_all_dataset_history,\n",
    "                \"mean_cluster_accuracy_post_training_cycle_all_dataset_history\": mean_cluster_accuracy_post_training_cycle_all_dataset_history,\n",
    "                \"mean_cluster_accuracy_total_all_dataset_history\": mean_cluster_accuracy_total_all_dataset_history,\n",
    "            }, f)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mbhkim003\u001b[0m (\u001b[33mbhkim003-seoul-national-university\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.19.5 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.17.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/nfs/home/bhkim003/github_folder/ByeonghyeonKim/my_snn/wandb/run-20250130_232243-dc7suyfm</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/bhkim003-seoul-national-university/spike_sorting%20just%20run/runs/dc7suyfm' target=\"_blank\">rich-snowflake-827</a></strong> to <a href='https://wandb.ai/bhkim003-seoul-national-university/spike_sorting%20just%20run' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/bhkim003-seoul-national-university/spike_sorting%20just%20run' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/spike_sorting%20just%20run</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/bhkim003-seoul-national-university/spike_sorting%20just%20run/runs/dc7suyfm' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/spike_sorting%20just%20run/runs/dc7suyfm</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'gpu': '0', 'Conv_net': True, 'SAE_net': False, 'dataset_num': 16, 'spike_length': 50, 'num_cluster': 4, 'training_cycle': 2400, 'batch_size': 32, 'max_epoch': 7000, 'learning_rate': 0.001, 'normalize_on': True, 'need_bias': False, 'lif_add_at_first': False, 'my_seed': 42, 'TIME': 1000, 'v_decay': 0.25, 'v_threshold': 0.5, 'v_reset': 10000.0, 'BPTT_on': False, 'SAE_hidden_nomean': True, 'current_time': '20250130_232241_674', 'optimizer': 'SGD', 'coarse_com_mode': False, 'sae_l2_norm_bridge': True, 'sae_lif_bridge': True, 'accuracy_check_epoch_term': 1, 'lif_add_at_last': False, 'two_channel_input': False, 'lateral_feature_num': 4, 'lc_adc_on': False, 'converted_net_forward': False, 'pretrained_net': None, 'vth_mul_on': False, 'batch_norm_on': False, 'l2_norm_loss_weight': 0, 'QCFS_neuron_on': False, 'quantize_level_num': 0, 'coarse_com_config': (1.0, -0.0)}\n",
      "cos_thr [0.95 0.95 0.95 0.95 0.95 0.95 0.95 0.85 0.95 0.9  0.8  0.95 0.95 0.95\n",
      " 0.95 0.8 ]\n",
      "ae conv lenght [50, 24, 11, 5]\n",
      "Total number of encoder parameters: 26592\n",
      "DataParallel(\n",
      "  (module): Autoencoder_conv1(\n",
      "    (activation_function): ReLU()\n",
      "    (encoder): Sequential(\n",
      "      (0): Conv1d(1, 32, kernel_size=(3,), stride=(2,), bias=False)\n",
      "      (1): ReLU()\n",
      "      (2): Conv1d(32, 64, kernel_size=(3,), stride=(2,), bias=False)\n",
      "      (3): ReLU()\n",
      "      (4): Conv1d(64, 96, kernel_size=(3,), stride=(2,), bias=False)\n",
      "      (5): ReLU()\n",
      "      (6): SSBH_DimChanger_for_fc()\n",
      "      (7): Linear(in_features=480, out_features=4, bias=False)\n",
      "      (8): ReLU()\n",
      "      (9): SSBH_L2NormLayer()\n",
      "    )\n",
      "    (decoder): Sequential(\n",
      "      (0): Linear(in_features=4, out_features=480, bias=False)\n",
      "      (1): ReLU()\n",
      "      (2): SSBH_DimChanger_for_conv1()\n",
      "      (3): ConvTranspose1d(96, 64, kernel_size=(3,), stride=(2,), bias=False)\n",
      "      (4): ReLU()\n",
      "      (5): ConvTranspose1d(64, 32, kernel_size=(3,), stride=(2,), output_padding=(1,), bias=False)\n",
      "      (6): ReLU()\n",
      "      (7): ConvTranspose1d(32, 1, kernel_size=(3,), stride=(2,), output_padding=(1,), bias=False)\n",
      "    )\n",
      "  )\n",
      ")\n",
      "Device: cuda\n",
      "\n",
      "Start Training, current_time = 20250130_232241_674\n",
      "\n",
      "\n",
      "epoch-0 loss : 0.08990\n",
      "ae train 실행 시간: 8.944초, 전체 시작 시간 20250130_232241_674\n",
      "\n",
      "epoch-0 accuracy check\n",
      "k_means origin feature average accuracy : 82.25492108%, total [0.9746727376209448, 0.9733106189664963, 0.9700891573195284, 0.9530800230282096, 0.943108504398827, 0.9150568181818182, 0.801817648783348, 0.6625070901871809, 0.9488619568430388, 0.822215777262181, 0.5866935483870968, 0.5005858230814294, 0.9429250891795482, 0.8922588099364529, 0.673546511627907, 0.6000572573718866]\n",
      "save model\n",
      "kmeans average accuracy best : 82.18%, kmeans average accuracy : 82.17770609%, total [0.9723961297666477, 0.9741624077228848, 0.9700891573195284, 0.9562464018422567, 0.9530791788856305, 0.8926136363636363, 0.830255057167986, 0.7773681225184345, 0.8468814661543009, 0.6313805104408353, 0.5288018433179723, 0.5090802577621558, 0.9548156956004756, 0.9069901790872328, 0.7895348837209303, 0.6547380475236186]\n",
      "cluster_accuracy_post_training_cycle_all_dataset : [0.97576302 0.97237077 0.96750232 0.96089385 0.96039604 0.89107143\n",
      " 0.82888229 0.76642984 0.78433367 0.63645038 0.49347015 0.50591716\n",
      " 0.95850622 0.90301318 0.78557692 0.51692589]\n",
      "mean_cluster_accuracy_during_training_cycle : 81.30%, post_traincycle_acc : 80.67%, total_acc : 81.11104947%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 80.67%\n",
      "accuracy_check 실행 시간: 12.745초\n",
      "\n",
      "\n",
      "epoch-1 loss : 0.03742\n",
      "ae train 실행 시간: 8.204초, 전체 시작 시간 20250130_232241_674\n",
      "\n",
      "epoch-1 accuracy check\n",
      "k_means origin feature average accuracy : 82.25860333%, total [0.9746727376209448, 0.9733106189664963, 0.9700891573195284, 0.9530800230282096, 0.943108504398827, 0.9150568181818182, 0.801817648783348, 0.6622234826999432, 0.9488619568430388, 0.8219257540603249, 0.5866935483870968, 0.5005858230814294, 0.9429250891795482, 0.8922588099364529, 0.6747093023255814, 0.6000572573718866]\n",
      "save model\n",
      "kmeans average accuracy best : 89.89%, kmeans average accuracy : 89.89453246%, total [0.9738190096755834, 0.9758659852356616, 0.9715271786022434, 0.9628670120898101, 0.9674486803519061, 0.9627840909090909, 0.9287598944591029, 0.8343732274532047, 0.9586166124741354, 0.8941415313225058, 0.7880184331797235, 0.7123608670181605, 0.9565992865636147, 0.9251877527440786, 0.8424418604651163, 0.7283137703979388]\n",
      "cluster_accuracy_post_training_cycle_all_dataset : [0.97666068 0.97504456 0.96935933 0.96834264 0.97623762 0.95446429\n",
      " 0.93175074 0.82060391 0.95320448 0.89980916 0.77798507 0.71301775\n",
      " 0.94917012 0.92843691 0.85576923 0.70539799]\n",
      "mean_cluster_accuracy_during_training_cycle : 89.62%, post_traincycle_acc : 89.72%, total_acc : 89.65019030%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 89.72%\n",
      "accuracy_check 실행 시간: 12.078초\n",
      "\n",
      "\n",
      "epoch-2 loss : 0.02758\n",
      "ae train 실행 시간: 8.090초, 전체 시작 시간 20250130_232241_674\n",
      "\n",
      "epoch-2 accuracy check\n",
      "k_means origin feature average accuracy : 82.25855480%, total [0.9746727376209448, 0.9733106189664963, 0.9700891573195284, 0.9530800230282096, 0.943108504398827, 0.9150568181818182, 0.801817648783348, 0.6625070901871809, 0.9488619568430388, 0.822215777262181, 0.5866935483870968, 0.5005858230814294, 0.9429250891795482, 0.8922588099364529, 0.6741279069767442, 0.6000572573718866]\n",
      "save model\n",
      "kmeans average accuracy best : 90.40%, kmeans average accuracy : 90.39728233%, total [0.9738190096755834, 0.975298126064736, 0.9712395743457003, 0.9643062751871042, 0.967741935483871, 0.965625, 0.9346232776311932, 0.8732274532047646, 0.9589122080993201, 0.8889211136890951, 0.7865783410138248, 0.7249560632688928, 0.9557074910820452, 0.9228769497400346, 0.8465116279069768, 0.753220727168623]\n",
      "cluster_accuracy_post_training_cycle_all_dataset : [0.97666068 0.97326203 0.96935933 0.97020484 0.97524752 0.95803571\n",
      " 0.93175074 0.86767318 0.95218718 0.88454198 0.79664179 0.72386588\n",
      " 0.95124481 0.92843691 0.85384615 0.75022873]\n",
      "mean_cluster_accuracy_during_training_cycle : 89.98%, post_traincycle_acc : 90.39%, total_acc : 90.10406347%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 90.39%\n",
      "accuracy_check 실행 시간: 12.148초\n",
      "\n",
      "\n",
      "epoch-3 loss : 0.02351\n",
      "ae train 실행 시간: 8.122초, 전체 시작 시간 20250130_232241_674\n",
      "\n",
      "epoch-3 accuracy check\n",
      "k_means origin feature average accuracy : 82.26764992%, total [0.9746727376209448, 0.9733106189664963, 0.9700891573195284, 0.9530800230282096, 0.943108504398827, 0.9150568181818182, 0.801817648783348, 0.6622234826999432, 0.9488619568430388, 0.822215777262181, 0.5872695852534562, 0.5005858230814294, 0.9429250891795482, 0.8922588099364529, 0.6752906976744186, 0.6000572573718866]\n",
      "save model\n",
      "kmeans average accuracy best : 90.42%, kmeans average accuracy : 90.42465764%, total [0.972965281730222, 0.975298126064736, 0.9709519700891573, 0.9637305699481865, 0.967741935483871, 0.9667613636363637, 0.9378481383758429, 0.8729438457175269, 0.9571386343482117, 0.884860788863109, 0.7733294930875576, 0.7132396016403046, 0.9571938168846611, 0.9257654534950895, 0.8531976744186046, 0.7749785284855425]\n",
      "cluster_accuracy_post_training_cycle_all_dataset : [0.97576302 0.97326203 0.96750232 0.97020484 0.97524752 0.95714286\n",
      " 0.92779426 0.87033748 0.95320448 0.8769084  0.77985075 0.71104536\n",
      " 0.9533195  0.93502825 0.8625     0.77676121]\n",
      "mean_cluster_accuracy_during_training_cycle : 90.12%, post_traincycle_acc : 90.41%, total_acc : 90.20950904%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 90.41%\n",
      "accuracy_check 실행 시간: 13.062초\n",
      "\n",
      "\n",
      "epoch-4 loss : 0.02119\n",
      "ae train 실행 시간: 7.808초, 전체 시작 시간 20250130_232241_674\n",
      "\n",
      "epoch-4 accuracy check\n",
      "k_means origin feature average accuracy : 82.25498833%, total [0.9746727376209448, 0.9733106189664963, 0.9700891573195284, 0.9530800230282096, 0.943108504398827, 0.9150568181818182, 0.8015244796247435, 0.6625070901871809, 0.9488619568430388, 0.822215777262181, 0.5866935483870968, 0.5005858230814294, 0.9429250891795482, 0.8922588099364529, 0.6747093023255814, 0.5991983967935872]\n",
      "save model\n",
      "kmeans average accuracy best : 90.44%, kmeans average accuracy : 90.44214806%, total [0.9726807057484348, 0.975298126064736, 0.9709519700891573, 0.9643062751871042, 0.9674486803519061, 0.9667613636363637, 0.9331574318381706, 0.8709585933068633, 0.9577298255985811, 0.8842807424593968, 0.7788018433179723, 0.7123608670181605, 0.9563020214030915, 0.9260543038705951, 0.8555232558139535, 0.7781276839393072]\n",
      "cluster_accuracy_post_training_cycle_all_dataset : [0.97576302 0.97326203 0.96843083 0.97020484 0.97524752 0.95625\n",
      " 0.92581602 0.86412078 0.95320448 0.88167939 0.77518657 0.71104536\n",
      " 0.9533195  0.93314501 0.84615385 0.78865508]\n",
      "mean_cluster_accuracy_during_training_cycle : 90.01%, post_traincycle_acc : 90.32%, total_acc : 90.10290088%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 90.32%\n",
      "accuracy_check 실행 시간: 12.779초\n",
      "\n",
      "\n",
      "epoch-5 loss : 0.01972\n",
      "ae train 실행 시간: 7.937초, 전체 시작 시간 20250130_232241_674\n",
      "\n",
      "epoch-5 accuracy check\n",
      "k_means origin feature average accuracy : 82.24959751%, total [0.9746727376209448, 0.9733106189664963, 0.9700891573195284, 0.9530800230282096, 0.943108504398827, 0.9150568181818182, 0.801817648783348, 0.6622234826999432, 0.9488619568430388, 0.822215777262181, 0.5866935483870968, 0.5005858230814294, 0.9429250891795482, 0.8922588099364529, 0.6738372093023256, 0.5991983967935872]\n",
      "save model\n",
      "kmeans average accuracy best : 90.47%, kmeans average accuracy : 90.47297772%, total [0.9726807057484348, 0.975298126064736, 0.9712395743457003, 0.9654576856649395, 0.967741935483871, 0.9667613636363637, 0.9346232776311932, 0.8706749858196257, 0.9595033993496896, 0.8871809744779582, 0.779089861751152, 0.7073813708260105, 0.9565992865636147, 0.9269208549971115, 0.8563953488372092, 0.7781276839393072]\n",
      "cluster_accuracy_post_training_cycle_all_dataset : [0.97576302 0.97326203 0.96750232 0.97020484 0.97524752 0.95714286\n",
      " 0.92680514 0.86056838 0.95422177 0.88263359 0.79011194 0.71104536\n",
      " 0.9533195  0.93879473 0.84519231 0.78774016]\n",
      "mean_cluster_accuracy_during_training_cycle : 90.04%, post_traincycle_acc : 90.43%, total_acc : 90.16215937%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 90.43%\n",
      "accuracy_check 실행 시간: 12.992초\n",
      "\n",
      "\n",
      "epoch-6 loss : 0.01871\n",
      "ae train 실행 시간: 7.960초, 전체 시작 시간 20250130_232241_674\n",
      "\n",
      "epoch-6 accuracy check\n",
      "k_means origin feature average accuracy : 82.25504809%, total [0.9746727376209448, 0.9733106189664963, 0.9700891573195284, 0.9530800230282096, 0.943108504398827, 0.9150568181818182, 0.801817648783348, 0.6622234826999432, 0.9488619568430388, 0.822215777262181, 0.5866935483870968, 0.5005858230814294, 0.9429250891795482, 0.8922588099364529, 0.6747093023255814, 0.5991983967935872]\n",
      "kmeans average accuracy best : 90.47%, kmeans average accuracy : 90.27333421%, total [0.9726807057484348, 0.9744463373083475, 0.9709519700891573, 0.9643062751871042, 0.9671554252199414, 0.9650568181818182, 0.9272940486660803, 0.8581962563811685, 0.9580254212237659, 0.882830626450116, 0.7808179723502304, 0.7111892208553017, 0.9548156956004756, 0.9231658001155402, 0.8561046511627907, 0.7766962496421415]\n",
      "cluster_accuracy_post_training_cycle_all_dataset : [0.97486535 0.9714795  0.96935933 0.97113594 0.97524752 0.95714286\n",
      " 0.92284866 0.85701599 0.95218718 0.87881679 0.78451493 0.71794872\n",
      " 0.95020747 0.93408663 0.85384615 0.7831656 ]\n",
      "mean_cluster_accuracy_during_training_cycle : 89.79%, post_traincycle_acc : 90.34%, total_acc : 89.95510866%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 90.43%\n",
      "accuracy_check 실행 시간: 12.756초\n",
      "\n",
      "\n",
      "epoch-7 loss : 0.01798\n",
      "ae train 실행 시간: 8.032초, 전체 시작 시간 20250130_232241_674\n",
      "\n",
      "epoch-7 accuracy check\n",
      "k_means origin feature average accuracy : 82.25149115%, total [0.9746727376209448, 0.9733106189664963, 0.9700891573195284, 0.9530800230282096, 0.943108504398827, 0.9150568181818182, 0.801817648783348, 0.6622234826999432, 0.9488619568430388, 0.822215777262181, 0.5872695852534562, 0.5005858230814294, 0.9429250891795482, 0.8922588099364529, 0.6747093023255814, 0.5980532493558546]\n",
      "kmeans average accuracy best : 90.47%, kmeans average accuracy : 90.26914091%, total [0.9732498577120091, 0.9747302668938104, 0.9715271786022434, 0.9645941278065631, 0.966275659824047, 0.9630681818181818, 0.9267077103488713, 0.8508224617129893, 0.9600945906000591, 0.8874709976798144, 0.7836981566820277, 0.7135325131810193, 0.9542211652794292, 0.9222992489890237, 0.854360465116279, 0.7764099627827082]\n",
      "cluster_accuracy_post_training_cycle_all_dataset : [0.97486535 0.97237077 0.97028784 0.97020484 0.97524752 0.95357143\n",
      " 0.91592483 0.84635879 0.95320448 0.88454198 0.77985075 0.71400394\n",
      " 0.95020747 0.93126177 0.85288462 0.77676121]\n",
      "mean_cluster_accuracy_during_training_cycle : 89.76%, post_traincycle_acc : 90.13%, total_acc : 89.86960181%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 90.43%\n",
      "accuracy_check 실행 시간: 12.133초\n",
      "\n",
      "\n",
      "epoch-8 loss : 0.01742\n",
      "ae train 실행 시간: 8.072초, 전체 시작 시간 20250130_232241_674\n",
      "\n",
      "epoch-8 accuracy check\n",
      "k_means origin feature average accuracy : 82.25851350%, total [0.9746727376209448, 0.9733106189664963, 0.9700891573195284, 0.9530800230282096, 0.943108504398827, 0.915340909090909, 0.801817648783348, 0.6625070901871809, 0.9488619568430388, 0.822215777262181, 0.5866935483870968, 0.5005858230814294, 0.9429250891795482, 0.8922588099364529, 0.6738372093023256, 0.6000572573718866]\n",
      "kmeans average accuracy best : 90.47%, kmeans average accuracy : 90.38332772%, total [0.9732498577120091, 0.9741624077228848, 0.9712395743457003, 0.9651698330454808, 0.9659824046920821, 0.9627840909090909, 0.9281735561418939, 0.845150311968236, 0.9595033993496896, 0.8895011600928074, 0.7995391705069125, 0.7193907439953134, 0.9524375743162902, 0.9214326978625073, 0.8531976744186046, 0.7804179788147724]\n",
      "cluster_accuracy_post_training_cycle_all_dataset : [0.97486535 0.97058824 0.97028784 0.97113594 0.97524752 0.95446429\n",
      " 0.91691395 0.84635879 0.95523906 0.88549618 0.78731343 0.71597633\n",
      " 0.95020747 0.93220339 0.85576923 0.77584629]\n",
      "mean_cluster_accuracy_during_training_cycle : 89.73%, post_traincycle_acc : 90.24%, total_acc : 89.88528963%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 90.43%\n",
      "accuracy_check 실행 시간: 11.983초\n",
      "\n",
      "\n",
      "epoch-9 loss : 0.01698\n",
      "ae train 실행 시간: 8.690초, 전체 시작 시간 20250130_232241_674\n",
      "\n",
      "epoch-9 accuracy check\n",
      "k_means origin feature average accuracy : 82.25495484%, total [0.9746727376209448, 0.9733106189664963, 0.9700891573195284, 0.9530800230282096, 0.943108504398827, 0.9150568181818182, 0.8015244796247435, 0.6625070901871809, 0.9488619568430388, 0.822215777262181, 0.5872695852534562, 0.5005858230814294, 0.9429250891795482, 0.8922588099364529, 0.6741279069767442, 0.5991983967935872]\n",
      "kmeans average accuracy best : 90.47%, kmeans average accuracy : 90.46585758%, total [0.9732498577120091, 0.9738784781374219, 0.9712395743457003, 0.9654576856649395, 0.9665689149560117, 0.9625, 0.9261213720316622, 0.8479863868406126, 0.9595033993496896, 0.886600928074246, 0.7966589861751152, 0.7185120093731693, 0.953923900118906, 0.9248989023685731, 0.8584302325581395, 0.789006584597767]\n",
      "cluster_accuracy_post_training_cycle_all_dataset : [0.97486535 0.97058824 0.96935933 0.97113594 0.97524752 0.95535714\n",
      " 0.91889219 0.84369449 0.95320448 0.88358779 0.79104478 0.71499014\n",
      " 0.95020747 0.93408663 0.8625     0.77767612]\n",
      "mean_cluster_accuracy_during_training_cycle : 89.73%, post_traincycle_acc : 90.29%, total_acc : 89.89665105%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 90.43%\n",
      "accuracy_check 실행 시간: 12.033초\n",
      "\n",
      "\n",
      "epoch-10 loss : 0.01664\n",
      "ae train 실행 시간: 7.937초, 전체 시작 시간 20250130_232241_674\n",
      "\n",
      "epoch-10 accuracy check\n",
      "k_means origin feature average accuracy : 82.24225975%, total [0.9746727376209448, 0.9733106189664963, 0.9700891573195284, 0.9530800230282096, 0.943108504398827, 0.9150568181818182, 0.8006449721489299, 0.6625070901871809, 0.9488619568430388, 0.822215777262181, 0.5872695852534562, 0.5005858230814294, 0.9429250891795482, 0.89052570768342, 0.6747093023255814, 0.5991983967935872]\n",
      "save model\n",
      "kmeans average accuracy best : 90.56%, kmeans average accuracy : 90.56255531%, total [0.9735344336937962, 0.9741624077228848, 0.9721023871153293, 0.9654576856649395, 0.9668621700879766, 0.962215909090909, 0.9226033421284081, 0.8423142370958593, 0.9609813774756134, 0.892691415313225, 0.8050115207373272, 0.7243702401874634, 0.953923900118906, 0.9246100519930676, 0.8593023255813953, 0.7898654451760664]\n",
      "cluster_accuracy_post_training_cycle_all_dataset : [0.97576302 0.97058824 0.97028784 0.97113594 0.97425743 0.95535714\n",
      " 0.91394659 0.8348135  0.95523906 0.89026718 0.79197761 0.71696252\n",
      " 0.95228216 0.93502825 0.86538462 0.78591034]\n",
      "mean_cluster_accuracy_during_training_cycle : 89.83%, post_traincycle_acc : 90.37%, total_acc : 89.99507813%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 90.37%\n",
      "accuracy_check 실행 시간: 10.926초\n",
      "\n",
      "\n",
      "epoch-11 loss : 0.01638\n",
      "ae train 실행 시간: 7.686초, 전체 시작 시간 20250130_232241_674\n",
      "\n",
      "epoch-11 accuracy check\n",
      "k_means origin feature average accuracy : 82.26578875%, total [0.9746727376209448, 0.9733106189664963, 0.9700891573195284, 0.9530800230282096, 0.943108504398827, 0.9150568181818182, 0.801817648783348, 0.6625070901871809, 0.9488619568430388, 0.822215777262181, 0.5872695852534562, 0.5005858230814294, 0.9429250891795482, 0.8922588099364529, 0.6747093023255814, 0.6000572573718866]\n",
      "save model\n",
      "kmeans average accuracy best : 90.64%, kmeans average accuracy : 90.64216658%, total [0.9735344336937962, 0.9741624077228848, 0.9718147828587863, 0.9660333909038572, 0.966275659824047, 0.9627840909090909, 0.9261213720316622, 0.8437322745320477, 0.9627549512267218, 0.8915313225058005, 0.8052995391705069, 0.7249560632688928, 0.9542211652794292, 0.9260543038705951, 0.8598837209302326, 0.7935871743486974]\n",
      "cluster_accuracy_post_training_cycle_all_dataset : [0.97576302 0.97058824 0.96935933 0.97299814 0.97425743 0.95535714\n",
      " 0.91097923 0.8339254  0.95523906 0.89217557 0.79384328 0.70118343\n",
      " 0.95124481 0.93785311 0.86634615 0.79414456]\n",
      "mean_cluster_accuracy_during_training_cycle : 89.79%, post_traincycle_acc : 90.35%, total_acc : 89.96151323%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 90.35%\n",
      "accuracy_check 실행 시간: 10.836초\n",
      "\n",
      "\n",
      "epoch-12 loss : 0.01611\n",
      "ae train 실행 시간: 7.704초, 전체 시작 시간 20250130_232241_674\n",
      "\n",
      "epoch-12 accuracy check\n",
      "k_means origin feature average accuracy : 82.24955320%, total [0.9746727376209448, 0.9733106189664963, 0.9700891573195284, 0.9530800230282096, 0.943108504398827, 0.9150568181818182, 0.801817648783348, 0.6625070901871809, 0.9488619568430388, 0.822215777262181, 0.5866935483870968, 0.5005858230814294, 0.9429250891795482, 0.8922588099364529, 0.673546511627907, 0.5991983967935872]\n",
      "save model\n",
      "kmeans average accuracy best : 90.64%, kmeans average accuracy : 90.64406253%, total [0.9735344336937962, 0.9741624077228848, 0.9718147828587863, 0.9660333909038572, 0.966275659824047, 0.9607954545454546, 0.9226033421284081, 0.8420306296086216, 0.9589122080993201, 0.8915313225058005, 0.8050115207373272, 0.7322788517867604, 0.9542211652794292, 0.9269208549971115, 0.861046511627907, 0.7958774692241626]\n",
      "cluster_accuracy_post_training_cycle_all_dataset : [0.97576302 0.97058824 0.96935933 0.97299814 0.97425743 0.95446429\n",
      " 0.91196835 0.8312611  0.95523906 0.89503817 0.79291045 0.72287968\n",
      " 0.9533195  0.93879473 0.86730769 0.78499543]\n",
      "mean_cluster_accuracy_during_training_cycle : 89.85%, post_traincycle_acc : 90.44%, total_acc : 90.02581424%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 90.44%\n",
      "accuracy_check 실행 시간: 11.138초\n",
      "\n",
      "\n",
      "epoch-13 loss : 0.01591\n",
      "ae train 실행 시간: 7.733초, 전체 시작 시간 20250130_232241_674\n",
      "\n",
      "epoch-13 accuracy check\n",
      "k_means origin feature average accuracy : 82.25856323%, total [0.9746727376209448, 0.9733106189664963, 0.9700891573195284, 0.9530800230282096, 0.943108504398827, 0.9150568181818182, 0.801817648783348, 0.6625070901871809, 0.9488619568430388, 0.8216357308584686, 0.5866935483870968, 0.5005858230814294, 0.9429250891795482, 0.8922588099364529, 0.6747093023255814, 0.6000572573718866]\n",
      "save model\n",
      "kmeans average accuracy best : 90.89%, kmeans average accuracy : 90.88557303%, total [0.9735344336937962, 0.9741624077228848, 0.9721023871153293, 0.9666090961427749, 0.9668621700879766, 0.9625, 0.9272940486660803, 0.8423142370958593, 0.9592078037245049, 0.8932714617169374, 0.8078917050691244, 0.7422378441710603, 0.9563020214030915, 0.92894280762565, 0.8665697674418604, 0.8018894932722588]\n",
      "cluster_accuracy_post_training_cycle_all_dataset : [0.97576302 0.97058824 0.96935933 0.97392924 0.97524752 0.95714286\n",
      " 0.91097923 0.84458259 0.95422177 0.89503817 0.80130597 0.74260355\n",
      " 0.9533195  0.93973635 0.86826923 0.79231473]\n",
      "mean_cluster_accuracy_during_training_cycle : 89.96%, post_traincycle_acc : 90.78%, total_acc : 90.20850646%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 90.78%\n",
      "accuracy_check 실행 시간: 11.675초\n",
      "\n",
      "\n",
      "epoch-14 loss : 0.01573\n",
      "ae train 실행 시간: 7.794초, 전체 시작 시간 20250130_232241_674\n",
      "\n",
      "epoch-14 accuracy check\n",
      "k_means origin feature average accuracy : 82.26401620%, total [0.9746727376209448, 0.9733106189664963, 0.9700891573195284, 0.9530800230282096, 0.943108504398827, 0.9150568181818182, 0.801817648783348, 0.6622234826999432, 0.9488619568430388, 0.822215777262181, 0.5872695852534562, 0.5005858230814294, 0.9429250891795482, 0.8922588099364529, 0.6747093023255814, 0.6000572573718866]\n",
      "kmeans average accuracy best : 90.89%, kmeans average accuracy : 90.72944858%, total [0.9735344336937962, 0.9738784781374219, 0.9718147828587863, 0.9651698330454808, 0.966275659824047, 0.9619318181818182, 0.9234828496042217, 0.8394781622234827, 0.9538870824711795, 0.8874709976798144, 0.8052995391705069, 0.7422378441710603, 0.9560047562425684, 0.9286539572501444, 0.8659883720930233, 0.8016032064128257]\n",
      "cluster_accuracy_post_training_cycle_all_dataset : [0.97576302 0.97058824 0.96935933 0.97392924 0.97524752 0.95535714\n",
      " 0.91196835 0.8383659  0.95015259 0.88835878 0.78451493 0.73767258\n",
      " 0.95435685 0.93973635 0.86634615 0.78133577]\n",
      "mean_cluster_accuracy_during_training_cycle : 89.89%, post_traincycle_acc : 90.46%, total_acc : 90.05595524%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 90.78%\n",
      "accuracy_check 실행 시간: 11.163초\n",
      "\n",
      "\n",
      "epoch-15 loss : 0.01555\n",
      "ae train 실행 시간: 7.683초, 전체 시작 시간 20250130_232241_674\n",
      "\n",
      "epoch-15 accuracy check\n",
      "k_means origin feature average accuracy : 82.24594995%, total [0.9746727376209448, 0.9733106189664963, 0.9700891573195284, 0.9530800230282096, 0.943108504398827, 0.9150568181818182, 0.801817648783348, 0.6622234826999432, 0.9488619568430388, 0.822215777262181, 0.5866935483870968, 0.5002929115407148, 0.9429250891795482, 0.8922588099364529, 0.673546511627907, 0.5991983967935872]\n",
      "kmeans average accuracy best : 90.89%, kmeans average accuracy : 90.87488032%, total [0.9735344336937962, 0.9741624077228848, 0.9721023871153293, 0.9657455382843984, 0.966275659824047, 0.9613636363636363, 0.9240691879214307, 0.8374929098128191, 0.9562518474726575, 0.8921113689095128, 0.8047235023041475, 0.7478031634446397, 0.9563020214030915, 0.9303870595031773, 0.8688953488372093, 0.8087603778986544]\n",
      "cluster_accuracy_post_training_cycle_all_dataset : [0.97576302 0.97058824 0.96935933 0.97486034 0.97524752 0.95625\n",
      " 0.91097923 0.84547069 0.95218718 0.88931298 0.78544776 0.74654832\n",
      " 0.95539419 0.94350282 0.87211538 0.79414456]\n",
      "mean_cluster_accuracy_during_training_cycle : 90.07%, post_traincycle_acc : 90.73%, total_acc : 90.26722245%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 90.78%\n",
      "accuracy_check 실행 시간: 10.890초\n",
      "\n",
      "\n",
      "epoch-16 loss : 0.01547\n",
      "ae train 실행 시간: 7.708초, 전체 시작 시간 20250130_232241_674\n",
      "\n",
      "epoch-16 accuracy check\n",
      "k_means origin feature average accuracy : 82.26218852%, total [0.9746727376209448, 0.9733106189664963, 0.9700891573195284, 0.9530800230282096, 0.943108504398827, 0.9150568181818182, 0.801817648783348, 0.6625070901871809, 0.9488619568430388, 0.822215777262181, 0.5866935483870968, 0.5005858230814294, 0.9429250891795482, 0.8922588099364529, 0.6747093023255814, 0.6000572573718866]\n",
      "save model\n",
      "kmeans average accuracy best : 91.06%, kmeans average accuracy : 91.05943040%, total [0.9735344336937962, 0.9738784781374219, 0.9718147828587863, 0.9654576856649395, 0.9674486803519061, 0.9625, 0.9240691879214307, 0.8448667044809983, 0.9592078037245049, 0.8938515081206496, 0.804147465437788, 0.7524897480960749, 0.9580856123662307, 0.9350086655112652, 0.8723837209302325, 0.8107643859146865]\n",
      "cluster_accuracy_post_training_cycle_all_dataset : [0.97576302 0.97058824 0.96935933 0.97392924 0.97524752 0.95625\n",
      " 0.91295747 0.839254   0.95625636 0.89026718 0.79384328 0.74556213\n",
      " 0.95746888 0.94821092 0.87596154 0.79231473]\n",
      "mean_cluster_accuracy_during_training_cycle : 90.24%, post_traincycle_acc : 90.83%, total_acc : 90.41448219%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 90.83%\n",
      "accuracy_check 실행 시간: 10.902초\n",
      "\n",
      "\n",
      "epoch-17 loss : 0.01529\n",
      "ae train 실행 시간: 7.711초, 전체 시작 시간 20250130_232241_674\n",
      "\n",
      "epoch-17 accuracy check\n",
      "k_means origin feature average accuracy : 82.26582224%, total [0.9746727376209448, 0.9733106189664963, 0.9700891573195284, 0.9530800230282096, 0.943108504398827, 0.9150568181818182, 0.801817648783348, 0.6625070901871809, 0.9488619568430388, 0.822215777262181, 0.5866935483870968, 0.5005858230814294, 0.9429250891795482, 0.8922588099364529, 0.6752906976744186, 0.6000572573718866]\n",
      "kmeans average accuracy best : 91.06%, kmeans average accuracy : 91.01496458%, total [0.9735344336937962, 0.9738784781374219, 0.9715271786022434, 0.9651698330454808, 0.9659824046920821, 0.9613636363636363, 0.9228965112870126, 0.839194554736245, 0.9577298255985811, 0.8935614849187935, 0.8058755760368663, 0.7568834212067955, 0.9577883472057075, 0.9361640670132871, 0.8715116279069768, 0.8093329516175207]\n",
      "cluster_accuracy_post_training_cycle_all_dataset : [0.97576302 0.97058824 0.96935933 0.97392924 0.97524752 0.95357143\n",
      " 0.90999011 0.8312611  0.95422177 0.89026718 0.7863806  0.75838264\n",
      " 0.95954357 0.94915254 0.87596154 0.79231473]\n",
      "mean_cluster_accuracy_during_training_cycle : 90.21%, post_traincycle_acc : 90.79%, total_acc : 90.38263648%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 90.83%\n",
      "accuracy_check 실행 시간: 10.729초\n",
      "\n",
      "\n",
      "epoch-18 loss : 0.01517\n",
      "ae train 실행 시간: 7.744초, 전체 시작 시간 20250130_232241_674\n",
      "\n",
      "epoch-18 accuracy check\n",
      "k_means origin feature average accuracy : 82.25315343%, total [0.9746727376209448, 0.9733106189664963, 0.9700891573195284, 0.9530800230282096, 0.943108504398827, 0.9150568181818182, 0.801817648783348, 0.6625070901871809, 0.9488619568430388, 0.822215777262181, 0.5872695852534562, 0.5005858230814294, 0.9429250891795482, 0.8922588099364529, 0.673546511627907, 0.5991983967935872]\n",
      "kmeans average accuracy best : 91.06%, kmeans average accuracy : 90.98431548%, total [0.9735344336937962, 0.9741624077228848, 0.9718147828587863, 0.9657455382843984, 0.9659824046920821, 0.9605113636363637, 0.9220170038111991, 0.8369256948383438, 0.9571386343482117, 0.8953016241299304, 0.8087557603686636, 0.7560046865846515, 0.9577883472057075, 0.9332755632582322, 0.8700581395348838, 0.8084740910392213]\n",
      "cluster_accuracy_post_training_cycle_all_dataset : [0.97666068 0.97058824 0.96935933 0.97392924 0.97425743 0.95357143\n",
      " 0.90900099 0.8374778  0.95523906 0.89790076 0.7863806  0.765286\n",
      " 0.95850622 0.94632768 0.87307692 0.78956999]\n",
      "mean_cluster_accuracy_during_training_cycle : 90.19%, post_traincycle_acc : 90.86%, total_acc : 90.38638062%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 90.83%\n",
      "accuracy_check 실행 시간: 11.110초\n",
      "\n",
      "\n",
      "epoch-19 loss : 0.01507\n",
      "ae train 실행 시간: 7.751초, 전체 시작 시간 20250130_232241_674\n",
      "\n",
      "epoch-19 accuracy check\n",
      "k_means origin feature average accuracy : 82.26034409%, total [0.9746727376209448, 0.9733106189664963, 0.9700891573195284, 0.9530800230282096, 0.943108504398827, 0.9150568181818182, 0.801817648783348, 0.6625070901871809, 0.9488619568430388, 0.822215777262181, 0.5866935483870968, 0.5005858230814294, 0.9429250891795482, 0.8922588099364529, 0.6741279069767442, 0.6003435442313197]\n",
      "save model\n",
      "kmeans average accuracy best : 91.07%, kmeans average accuracy : 91.06820060%, total [0.9735344336937962, 0.9741624077228848, 0.9723899913718723, 0.9660333909038572, 0.966275659824047, 0.959659090909091, 0.92143066549399, 0.8425978445830969, 0.9538870824711795, 0.8932714617169374, 0.8101958525345622, 0.7601054481546573, 0.9583828775267539, 0.9341421143847487, 0.8709302325581395, 0.8139135413684512]\n",
      "cluster_accuracy_post_training_cycle_all_dataset : [0.97576302 0.97058824 0.96935933 0.97486034 0.97425743 0.95446429\n",
      " 0.91196835 0.8294849  0.95320448 0.89694656 0.78544776 0.76134122\n",
      " 0.95954357 0.95009416 0.87692308 0.81610247]\n",
      "mean_cluster_accuracy_during_training_cycle : 90.38%, post_traincycle_acc : 91.00%, total_acc : 90.56759320%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 91.00%\n",
      "accuracy_check 실행 시간: 10.915초\n",
      "\n",
      "\n",
      "epoch-20 loss : 0.01496\n",
      "ae train 실행 시간: 7.689초, 전체 시작 시간 20250130_232241_674\n",
      "\n",
      "epoch-20 accuracy check\n",
      "k_means origin feature average accuracy : 82.24958206%, total [0.9746727376209448, 0.9733106189664963, 0.9700891573195284, 0.9530800230282096, 0.943108504398827, 0.9150568181818182, 0.8015244796247435, 0.6622234826999432, 0.9488619568430388, 0.822215777262181, 0.5866935483870968, 0.5005858230814294, 0.9429250891795482, 0.8922588099364529, 0.6741279069767442, 0.5991983967935872]\n",
      "kmeans average accuracy best : 91.07%, kmeans average accuracy : 90.98393535%, total [0.9735344336937962, 0.9741624077228848, 0.9723899913718723, 0.9657455382843984, 0.9659824046920821, 0.9605113636363637, 0.9226033421284081, 0.8363584798638684, 0.9541826780963641, 0.8932714617169374, 0.8101958525345622, 0.7580550673696543, 0.9574910820451843, 0.9344309647602542, 0.8688953488372093, 0.8096192384769539]\n",
      "cluster_accuracy_post_training_cycle_all_dataset : [0.97576302 0.97058824 0.96935933 0.97392924 0.97425743 0.95357143\n",
      " 0.91097923 0.8277087  0.95320448 0.89599237 0.78544776 0.76232742\n",
      " 0.95850622 0.94256121 0.87211538 0.81518756]\n",
      "mean_cluster_accuracy_during_training_cycle : 90.29%, post_traincycle_acc : 90.88%, total_acc : 90.46613775%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 91.00%\n",
      "accuracy_check 실행 시간: 11.228초\n",
      "\n",
      "\n",
      "epoch-21 loss : 0.01487\n",
      "ae train 실행 시간: 7.684초, 전체 시작 시간 20250130_232241_674\n",
      "\n",
      "epoch-21 accuracy check\n",
      "k_means origin feature average accuracy : 82.25141437%, total [0.9746727376209448, 0.9733106189664963, 0.9700891573195284, 0.9530800230282096, 0.943108504398827, 0.9150568181818182, 0.801817648783348, 0.6622234826999432, 0.9488619568430388, 0.822215777262181, 0.5866935483870968, 0.5005858230814294, 0.9429250891795482, 0.8922588099364529, 0.6741279069767442, 0.5991983967935872]\n",
      "kmeans average accuracy best : 91.07%, kmeans average accuracy : 91.03221574%, total [0.9741035856573705, 0.9747302668938104, 0.9726775956284153, 0.9660333909038572, 0.9659824046920821, 0.9602272727272727, 0.9223101729698036, 0.835791264889393, 0.9515223174697014, 0.892691415313225, 0.8104838709677419, 0.7589338019917985, 0.9580856123662307, 0.9352975158867707, 0.8715116279069768, 0.8147724019467506]\n",
      "cluster_accuracy_post_training_cycle_all_dataset : [0.97666068 0.97058824 0.96935933 0.97392924 0.97425743 0.95267857\n",
      " 0.90999011 0.84280639 0.95422177 0.89503817 0.7863806  0.76134122\n",
      " 0.96058091 0.94350282 0.87211538 0.81701738]\n",
      "mean_cluster_accuracy_during_training_cycle : 90.17%, post_traincycle_acc : 91.00%, total_acc : 90.41710854%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 91.00%\n",
      "accuracy_check 실행 시간: 10.875초\n",
      "\n",
      "\n",
      "epoch-22 loss : 0.01477\n",
      "ae train 실행 시간: 7.723초, 전체 시작 시간 20250130_232241_674\n",
      "\n",
      "epoch-22 accuracy check\n",
      "k_means origin feature average accuracy : 82.24602975%, total [0.9746727376209448, 0.9733106189664963, 0.9700891573195284, 0.9530800230282096, 0.943108504398827, 0.9150568181818182, 0.801817648783348, 0.6625070901871809, 0.9488619568430388, 0.822215777262181, 0.5866935483870968, 0.5005858230814294, 0.9429250891795482, 0.8922588099364529, 0.6741279069767442, 0.5980532493558546]\n",
      "save model\n",
      "kmeans average accuracy best : 91.08%, kmeans average accuracy : 91.07564759%, total [0.9735344336937962, 0.9741624077228848, 0.9718147828587863, 0.9666090961427749, 0.966275659824047, 0.9607954545454546, 0.9220170038111991, 0.8389109472490074, 0.9527046999704404, 0.8921113689095128, 0.8104838709677419, 0.7601054481546573, 0.9583828775267539, 0.9370306181398036, 0.8729651162790698, 0.8141998282278844]\n",
      "cluster_accuracy_post_training_cycle_all_dataset : [0.97576302 0.97058824 0.96935933 0.97392924 0.97425743 0.95535714\n",
      " 0.90900099 0.84547069 0.95422177 0.89503817 0.78824627 0.76232742\n",
      " 0.96161826 0.94256121 0.87019231 0.8179323 ]\n",
      "mean_cluster_accuracy_during_training_cycle : 90.20%, post_traincycle_acc : 91.04%, total_acc : 90.44734171%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 91.04%\n",
      "accuracy_check 실행 시간: 10.953초\n",
      "\n",
      "\n",
      "epoch-23 loss : 0.01471\n",
      "ae train 실행 시간: 7.677초, 전체 시작 시간 20250130_232241_674\n",
      "\n",
      "epoch-23 accuracy check\n",
      "k_means origin feature average accuracy : 82.25134249%, total [0.9746727376209448, 0.9733106189664963, 0.9700891573195284, 0.9530800230282096, 0.943108504398827, 0.9150568181818182, 0.801817648783348, 0.6625070901871809, 0.9488619568430388, 0.822215777262181, 0.5866935483870968, 0.5005858230814294, 0.9429250891795482, 0.8922588099364529, 0.673546511627907, 0.5994846836530203]\n",
      "save model\n",
      "kmeans average accuracy best : 91.25%, kmeans average accuracy : 91.24891309%, total [0.9738190096755834, 0.9741624077228848, 0.9718147828587863, 0.9660333909038572, 0.9668621700879766, 0.9599431818181818, 0.9243623570800352, 0.844299489506523, 0.9524091043452557, 0.8932714617169374, 0.8142281105990783, 0.7624487404803749, 0.9592746730083235, 0.9399191218948585, 0.8781976744186046, 0.8187804179788147]\n",
      "cluster_accuracy_post_training_cycle_all_dataset : [0.97666068 0.97058824 0.96935933 0.97392924 0.97524752 0.95357143\n",
      " 0.90999011 0.8383659  0.95320448 0.89790076 0.78824627 0.76331361\n",
      " 0.96161826 0.95480226 0.87692308 0.81976212]\n",
      "mean_cluster_accuracy_during_training_cycle : 90.31%, post_traincycle_acc : 91.15%, total_acc : 90.55890242%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 91.15%\n",
      "accuracy_check 실행 시간: 11.213초\n",
      "\n",
      "\n",
      "epoch-24 loss : 0.01462\n",
      "ae train 실행 시간: 7.773초, 전체 시작 시간 20250130_232241_674\n",
      "\n",
      "epoch-24 accuracy check\n",
      "k_means origin feature average accuracy : 82.25853805%, total [0.9746727376209448, 0.9733106189664963, 0.9700891573195284, 0.9530800230282096, 0.943108504398827, 0.9150568181818182, 0.801817648783348, 0.6622234826999432, 0.9488619568430388, 0.822215777262181, 0.5872695852534562, 0.5005858230814294, 0.9429250891795482, 0.8922588099364529, 0.673546511627907, 0.6003435442313197]\n",
      "kmeans average accuracy best : 91.25%, kmeans average accuracy : 91.18892926%, total [0.9738190096755834, 0.9741624077228848, 0.9721023871153293, 0.966321243523316, 0.9659824046920821, 0.9599431818181818, 0.9234828496042217, 0.8457175269427113, 0.952113508720071, 0.8929814385150812, 0.8107718894009217, 0.7606912712360867, 0.9595719381688466, 0.9399191218948585, 0.8758720930232559, 0.8167764099627827]\n",
      "cluster_accuracy_post_training_cycle_all_dataset : [0.97666068 0.97058824 0.96935933 0.97392924 0.97425743 0.95446429\n",
      " 0.91295747 0.8365897  0.95218718 0.89599237 0.7891791  0.76923077\n",
      " 0.96369295 0.95009416 0.87403846 0.82159195]\n",
      "mean_cluster_accuracy_during_training_cycle : 90.37%, post_traincycle_acc : 91.16%, total_acc : 90.60336070%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 91.15%\n",
      "accuracy_check 실행 시간: 11.217초\n",
      "\n",
      "\n",
      "epoch-25 loss : 0.01454\n",
      "ae train 실행 시간: 7.738초, 전체 시작 시간 20250130_232241_674\n",
      "\n",
      "epoch-25 accuracy check\n",
      "k_means origin feature average accuracy : 82.25313308%, total [0.9746727376209448, 0.9733106189664963, 0.9700891573195284, 0.9530800230282096, 0.943108504398827, 0.9150568181818182, 0.8015244796247435, 0.6622234826999432, 0.9488619568430388, 0.822215777262181, 0.5866935483870968, 0.5005858230814294, 0.9429250891795482, 0.8922588099364529, 0.6738372093023256, 0.6000572573718866]\n",
      "kmeans average accuracy best : 91.25%, kmeans average accuracy : 91.16659468%, total [0.9738190096755834, 0.9741624077228848, 0.9726775956284153, 0.966321243523316, 0.9659824046920821, 0.959375, 0.9231896804456171, 0.844299489506523, 0.9470883830919302, 0.8915313225058005, 0.8125, 0.7618629173989455, 0.9589774078478003, 0.9376083188908145, 0.877906976744186, 0.819352991697681]\n",
      "cluster_accuracy_post_training_cycle_all_dataset : [0.97576302 0.97058824 0.96935933 0.97392924 0.97425743 0.95357143\n",
      " 0.90999011 0.8401421  0.95218718 0.88645038 0.78264925 0.76134122\n",
      " 0.96369295 0.95009416 0.87596154 0.82891125]\n",
      "mean_cluster_accuracy_during_training_cycle : 90.33%, post_traincycle_acc : 91.06%, total_acc : 90.54291479%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 91.15%\n",
      "accuracy_check 실행 시간: 11.204초\n",
      "\n",
      "\n",
      "epoch-26 loss : 0.01449\n",
      "ae train 실행 시간: 7.700초, 전체 시작 시간 20250130_232241_674\n",
      "\n",
      "epoch-26 accuracy check\n",
      "k_means origin feature average accuracy : 82.25678225%, total [0.9746727376209448, 0.9733106189664963, 0.9700891573195284, 0.9530800230282096, 0.943108504398827, 0.9150568181818182, 0.801817648783348, 0.6622234826999432, 0.9488619568430388, 0.822215777262181, 0.5866935483870968, 0.5005858230814294, 0.9429250891795482, 0.8922588099364529, 0.6741279069767442, 0.6000572573718866]\n",
      "kmeans average accuracy best : 91.25%, kmeans average accuracy : 91.12741418%, total [0.9738190096755834, 0.9741624077228848, 0.9726775956284153, 0.9660333909038572, 0.9659824046920821, 0.9602272727272727, 0.9231896804456171, 0.8431650595575724, 0.9503399349689624, 0.8921113689095128, 0.8076036866359447, 0.7612770943175161, 0.9583828775267539, 0.9370306181398036, 0.8770348837209302, 0.817348983681649]\n",
      "cluster_accuracy_post_training_cycle_all_dataset : [0.97576302 0.97058824 0.96935933 0.97392924 0.97425743 0.95535714\n",
      " 0.90999011 0.8374778  0.95320448 0.88645038 0.78358209 0.76134122\n",
      " 0.96161826 0.94350282 0.875      0.82708143]\n",
      "mean_cluster_accuracy_during_training_cycle : 90.26%, post_traincycle_acc : 90.99%, total_acc : 90.47769060%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 91.15%\n",
      "accuracy_check 실행 시간: 11.259초\n",
      "\n",
      "\n",
      "epoch-27 loss : 0.01442\n",
      "ae train 실행 시간: 7.650초, 전체 시작 시간 20250130_232241_674\n",
      "\n",
      "epoch-27 accuracy check\n",
      "k_means origin feature average accuracy : 82.24964802%, total [0.9746727376209448, 0.9733106189664963, 0.9700891573195284, 0.9530800230282096, 0.943108504398827, 0.9150568181818182, 0.8015244796247435, 0.6625070901871809, 0.9488619568430388, 0.822215777262181, 0.5866935483870968, 0.5005858230814294, 0.9429250891795482, 0.8922588099364529, 0.675, 0.5980532493558546]\n",
      "kmeans average accuracy best : 91.25%, kmeans average accuracy : 91.18666599%, total [0.9738190096755834, 0.9741624077228848, 0.9718147828587863, 0.9660333909038572, 0.9659824046920821, 0.959659090909091, 0.9240691879214307, 0.8454339194554736, 0.9464971918415608, 0.890661252900232, 0.8133640552995391, 0.7630345635618043, 0.9604637336504162, 0.938474870017331, 0.8776162790697675, 0.8187804179788147]\n",
      "cluster_accuracy_post_training_cycle_all_dataset : [0.97576302 0.97058824 0.96935933 0.97392924 0.97425743 0.95267857\n",
      " 0.91196835 0.8365897  0.95320448 0.89122137 0.78358209 0.765286\n",
      " 0.96369295 0.95574388 0.87596154 0.83074108]\n",
      "mean_cluster_accuracy_during_training_cycle : 90.36%, post_traincycle_acc : 91.15%, total_acc : 90.59723270%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 91.15%\n",
      "accuracy_check 실행 시간: 11.075초\n",
      "\n",
      "\n",
      "epoch-28 loss : 0.01434\n",
      "ae train 실행 시간: 7.667초, 전체 시작 시간 20250130_232241_674\n",
      "\n",
      "epoch-28 accuracy check\n",
      "k_means origin feature average accuracy : 82.24959580%, total [0.9746727376209448, 0.9733106189664963, 0.9700891573195284, 0.9530800230282096, 0.943108504398827, 0.9150568181818182, 0.8015244796247435, 0.6622234826999432, 0.9488619568430388, 0.822215777262181, 0.5866935483870968, 0.5002929115407148, 0.9429250891795482, 0.8922588099364529, 0.6747093023255814, 0.598912109934154]\n",
      "kmeans average accuracy best : 91.25%, kmeans average accuracy : 91.10875258%, total [0.9738190096755834, 0.9741624077228848, 0.9721023871153293, 0.966321243523316, 0.9656891495601173, 0.9588068181818182, 0.9231896804456171, 0.8440158820192853, 0.9441324268400828, 0.8889211136890951, 0.8119239631336406, 0.7621558289396603, 0.960166468489893, 0.9373194685153091, 0.8773255813953489, 0.817348983681649]\n",
      "cluster_accuracy_post_training_cycle_all_dataset : [0.97576302 0.97058824 0.96935933 0.97392924 0.97425743 0.95357143\n",
      " 0.91097923 0.8365897  0.94710071 0.89026718 0.78358209 0.77021696\n",
      " 0.96369295 0.95574388 0.87788462 0.82982617]\n",
      "mean_cluster_accuracy_during_training_cycle : 90.27%, post_traincycle_acc : 91.15%, total_acc : 90.52906884%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 91.15%\n",
      "accuracy_check 실행 시간: 11.255초\n",
      "\n",
      "\n",
      "epoch-29 loss : 0.01428\n",
      "ae train 실행 시간: 7.630초, 전체 시작 시간 20250130_232241_674\n",
      "\n",
      "epoch-29 accuracy check\n",
      "k_means origin feature average accuracy : 82.25859319%, total [0.9746727376209448, 0.9733106189664963, 0.9700891573195284, 0.9530800230282096, 0.943108504398827, 0.9150568181818182, 0.801817648783348, 0.6622234826999432, 0.9488619568430388, 0.822215777262181, 0.5872695852534562, 0.5005858230814294, 0.9429250891795482, 0.8922588099364529, 0.6741279069767442, 0.5997709705124534]\n",
      "kmeans average accuracy best : 91.25%, kmeans average accuracy : 91.19858919%, total [0.9738190096755834, 0.9741624077228848, 0.9721023871153293, 0.966321243523316, 0.9659824046920821, 0.9599431818181818, 0.9240691879214307, 0.849404424276801, 0.9453148093408218, 0.8900812064965197, 0.8127880184331797, 0.7665495020503807, 0.9583828775267539, 0.93789716926632, 0.8770348837209302, 0.8179215574005153]\n",
      "cluster_accuracy_post_training_cycle_all_dataset : [0.97576302 0.97058824 0.96935933 0.97392924 0.97425743 0.95535714\n",
      " 0.91295747 0.839254   0.94404883 0.89122137 0.78544776 0.76331361\n",
      " 0.9626556  0.9519774  0.875      0.82799634]\n",
      "mean_cluster_accuracy_during_training_cycle : 90.39%, post_traincycle_acc : 91.08%, total_acc : 90.59276002%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 91.15%\n",
      "accuracy_check 실행 시간: 10.913초\n",
      "\n",
      "\n",
      "epoch-30 loss : 0.01422\n",
      "ae train 실행 시간: 7.711초, 전체 시작 시간 20250130_232241_674\n",
      "\n",
      "epoch-30 accuracy check\n",
      "k_means origin feature average accuracy : 82.26218389%, total [0.9746727376209448, 0.9733106189664963, 0.9700891573195284, 0.9530800230282096, 0.943108504398827, 0.9150568181818182, 0.8015244796247435, 0.6622234826999432, 0.9488619568430388, 0.822215777262181, 0.5872695852534562, 0.5005858230814294, 0.9429250891795482, 0.8922588099364529, 0.6747093023255814, 0.6000572573718866]\n",
      "kmeans average accuracy best : 91.25%, kmeans average accuracy : 91.18481882%, total [0.9738190096755834, 0.9741624077228848, 0.9721023871153293, 0.966321243523316, 0.9665689149560117, 0.9602272727272727, 0.9252418645558487, 0.8533749290981282, 0.9391073012119421, 0.8880510440835266, 0.8125, 0.7624487404803749, 0.960166468489893, 0.938474870017331, 0.8799418604651162, 0.8170626968222159]\n",
      "cluster_accuracy_post_training_cycle_all_dataset : [0.97576302 0.97058824 0.96935933 0.97392924 0.97425743 0.95357143\n",
      " 0.91394659 0.8410302  0.94404883 0.89217557 0.79011194 0.77613412\n",
      " 0.96473029 0.95574388 0.87307692 0.82891125]\n",
      "mean_cluster_accuracy_during_training_cycle : 90.36%, post_traincycle_acc : 91.23%, total_acc : 90.61879191%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 91.15%\n",
      "accuracy_check 실행 시간: 11.149초\n",
      "\n",
      "\n",
      "epoch-31 loss : 0.01416\n",
      "ae train 실행 시간: 7.736초, 전체 시작 시간 20250130_232241_674\n",
      "\n",
      "epoch-31 accuracy check\n",
      "k_means origin feature average accuracy : 82.26219154%, total [0.9746727376209448, 0.9733106189664963, 0.9700891573195284, 0.9530800230282096, 0.943108504398827, 0.915340909090909, 0.801817648783348, 0.6622234826999432, 0.9488619568430388, 0.822215777262181, 0.5866935483870968, 0.5005858230814294, 0.9429250891795482, 0.8922588099364529, 0.6747093023255814, 0.6000572573718866]\n",
      "save model\n",
      "kmeans average accuracy best : 91.26%, kmeans average accuracy : 91.25586759%, total [0.9738190096755834, 0.9747302668938104, 0.9723899913718723, 0.9666090961427749, 0.9668621700879766, 0.9602272727272727, 0.9258282028730578, 0.8519568916619399, 0.9402896837126811, 0.8889211136890951, 0.8136520737327189, 0.768306971294669, 0.9595719381688466, 0.938474870017331, 0.8802325581395349, 0.819066704838248]\n",
      "cluster_accuracy_post_training_cycle_all_dataset : [0.97576302 0.97058824 0.96935933 0.97392924 0.97425743 0.95357143\n",
      " 0.91493571 0.84547069 0.94404883 0.88931298 0.78544776 0.76627219\n",
      " 0.9626556  0.95480226 0.875      0.82982617]\n",
      "mean_cluster_accuracy_during_training_cycle : 90.37%, post_traincycle_acc : 91.16%, total_acc : 90.60683875%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 91.16%\n",
      "accuracy_check 실행 시간: 11.044초\n",
      "\n",
      "\n",
      "epoch-32 loss : 0.01414\n",
      "ae train 실행 시간: 7.742초, 전체 시작 시간 20250130_232241_674\n",
      "\n",
      "epoch-32 accuracy check\n",
      "k_means origin feature average accuracy : 82.25857997%, total [0.9746727376209448, 0.9733106189664963, 0.9700891573195284, 0.9530800230282096, 0.943108504398827, 0.9150568181818182, 0.801817648783348, 0.6622234826999432, 0.9488619568430388, 0.8216357308584686, 0.5866935483870968, 0.5005858230814294, 0.9429250891795482, 0.8922588099364529, 0.6747093023255814, 0.6003435442313197]\n",
      "kmeans average accuracy best : 91.26%, kmeans average accuracy : 91.12238552%, total [0.9738190096755834, 0.9741624077228848, 0.9726775956284153, 0.9666090961427749, 0.9668621700879766, 0.9605113636363637, 0.9261213720316622, 0.8530913216108905, 0.9337865799586166, 0.8822505800464037, 0.8099078341013825, 0.7627416520210897, 0.9592746730083235, 0.939052570768342, 0.8793604651162791, 0.819352991697681]\n",
      "cluster_accuracy_post_training_cycle_all_dataset : [0.97576302 0.97058824 0.96935933 0.97392924 0.97425743 0.95357143\n",
      " 0.91691395 0.84991119 0.94201424 0.89122137 0.77705224 0.77021696\n",
      " 0.9626556  0.95574388 0.86730769 0.82799634]\n",
      "mean_cluster_accuracy_during_training_cycle : 90.45%, post_traincycle_acc : 91.12%, total_acc : 90.64460113%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 91.16%\n",
      "accuracy_check 실행 시간: 11.326초\n",
      "\n",
      "\n",
      "epoch-33 loss : 0.01407\n",
      "ae train 실행 시간: 7.711초, 전체 시작 시간 20250130_232241_674\n",
      "\n",
      "epoch-33 accuracy check\n",
      "k_means origin feature average accuracy : 82.24778065%, total [0.9746727376209448, 0.9733106189664963, 0.9700891573195284, 0.9530800230282096, 0.943108504398827, 0.9150568181818182, 0.801817648783348, 0.6622234826999432, 0.9488619568430388, 0.822215777262181, 0.5866935483870968, 0.5005858230814294, 0.9429250891795482, 0.8922588099364529, 0.673546511627907, 0.5991983967935872]\n",
      "kmeans average accuracy best : 91.26%, kmeans average accuracy : 91.20640546%, total [0.9738190096755834, 0.9744463373083475, 0.9723899913718723, 0.9666090961427749, 0.9659824046920821, 0.9610795454545454, 0.9270008795074758, 0.8525241066364152, 0.9376293230860183, 0.8868909512761021, 0.8133640552995391, 0.7656707674282367, 0.9598692033293698, 0.9376083188908145, 0.8793604651162791, 0.8187804179788147]\n",
      "cluster_accuracy_post_training_cycle_all_dataset : [0.97576302 0.97058824 0.96935933 0.97392924 0.97425743 0.95267857\n",
      " 0.91493571 0.84724689 0.94303154 0.89122137 0.78824627 0.765286\n",
      " 0.96369295 0.9566855  0.86923077 0.82708143]\n",
      "mean_cluster_accuracy_during_training_cycle : 90.36%, post_traincycle_acc : 91.15%, total_acc : 90.59242094%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 91.16%\n",
      "accuracy_check 실행 시간: 11.032초\n",
      "\n",
      "\n",
      "epoch-34 loss : 0.01401\n",
      "ae train 실행 시간: 7.708초, 전체 시작 시간 20250130_232241_674\n",
      "\n",
      "epoch-34 accuracy check\n",
      "k_means origin feature average accuracy : 82.24599626%, total [0.9746727376209448, 0.9733106189664963, 0.9700891573195284, 0.9530800230282096, 0.943108504398827, 0.9150568181818182, 0.801817648783348, 0.6625070901871809, 0.9488619568430388, 0.822215777262181, 0.5872695852534562, 0.5005858230814294, 0.9429250891795482, 0.8922588099364529, 0.673546511627907, 0.5980532493558546]\n",
      "kmeans average accuracy best : 91.26%, kmeans average accuracy : 91.14119548%, total [0.9738190096755834, 0.9741624077228848, 0.9726775956284153, 0.9666090961427749, 0.9668621700879766, 0.959375, 0.9249486953972442, 0.8519568916619399, 0.9385161099615725, 0.8868909512761021, 0.8119239631336406, 0.7615700058582309, 0.9589774078478003, 0.9373194685153091, 0.8784883720930232, 0.8184941311193816]\n",
      "cluster_accuracy_post_training_cycle_all_dataset : [0.97576302 0.97058824 0.96935933 0.97392924 0.97425743 0.95267857\n",
      " 0.91493571 0.84458259 0.94404883 0.89026718 0.78544776 0.77514793\n",
      " 0.96369295 0.95386064 0.87115385 0.82891125]\n",
      "mean_cluster_accuracy_during_training_cycle : 90.54%, post_traincycle_acc : 91.18%, total_acc : 90.72729971%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 91.16%\n",
      "accuracy_check 실행 시간: 10.945초\n",
      "\n",
      "\n",
      "epoch-35 loss : 0.01398\n",
      "ae train 실행 시간: 7.679초, 전체 시작 시간 20250130_232241_674\n",
      "\n",
      "epoch-35 accuracy check\n",
      "k_means origin feature average accuracy : 82.24237097%, total [0.9746727376209448, 0.9733106189664963, 0.9700891573195284, 0.9530800230282096, 0.943108504398827, 0.9150568181818182, 0.801817648783348, 0.6625070901871809, 0.9488619568430388, 0.8216357308584686, 0.5872695852534562, 0.5005858230814294, 0.9429250891795482, 0.8922588099364529, 0.673546511627907, 0.5980532493558546]\n",
      "save model\n",
      "kmeans average accuracy best : 91.32%, kmeans average accuracy : 91.32046149%, total [0.9738190096755834, 0.9744463373083475, 0.9726775956284153, 0.9666090961427749, 0.9671554252199414, 0.9605113636363637, 0.9252418645558487, 0.8545093590470788, 0.9414720662134201, 0.894431554524362, 0.8171082949308756, 0.7668424135910955, 0.9589774078478003, 0.9381860196418256, 0.8793604651162791, 0.8199255654165474]\n",
      "cluster_accuracy_post_training_cycle_all_dataset : [0.97576302 0.9714795  0.96935933 0.97392924 0.97425743 0.95446429\n",
      " 0.91592483 0.84813499 0.94404883 0.89026718 0.78544776 0.7642998\n",
      " 0.9626556  0.9566855  0.86826923 0.82891125]\n",
      "mean_cluster_accuracy_during_training_cycle : 90.45%, post_traincycle_acc : 91.15%, total_acc : 90.65851241%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 91.15%\n",
      "accuracy_check 실행 시간: 10.928초\n",
      "\n",
      "\n",
      "epoch-36 loss : 0.01392\n",
      "ae train 실행 시간: 7.645초, 전체 시작 시간 20250130_232241_674\n",
      "\n",
      "epoch-36 accuracy check\n",
      "k_means origin feature average accuracy : 82.24947330%, total [0.9746727376209448, 0.9733106189664963, 0.9700891573195284, 0.9530800230282096, 0.943108504398827, 0.9150568181818182, 0.801817648783348, 0.6622234826999432, 0.9488619568430388, 0.822215777262181, 0.5866935483870968, 0.4997070884592853, 0.9429250891795482, 0.8922588099364529, 0.6738372093023256, 0.6000572573718866]\n",
      "kmeans average accuracy best : 91.32%, kmeans average accuracy : 91.26050355%, total [0.9738190096755834, 0.9741624077228848, 0.9723899913718723, 0.9668969487622338, 0.9665689149560117, 0.9605113636363637, 0.9255350337144532, 0.8553601815087918, 0.9411764705882353, 0.8880510440835266, 0.8136520737327189, 0.7647920328060925, 0.9592746730083235, 0.9373194685153091, 0.8808139534883721, 0.8213569997137131]\n",
      "cluster_accuracy_post_training_cycle_all_dataset : [0.97576302 0.97058824 0.96935933 0.97392924 0.97425743 0.95267857\n",
      " 0.91493571 0.84547069 0.94404883 0.89122137 0.78264925 0.77317554\n",
      " 0.9626556  0.95762712 0.86826923 0.82982617]\n",
      "mean_cluster_accuracy_during_training_cycle : 90.84%, post_traincycle_acc : 91.17%, total_acc : 90.93798101%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 91.15%\n",
      "accuracy_check 실행 시간: 11.101초\n",
      "\n",
      "\n",
      "epoch-37 loss : 0.01387\n",
      "ae train 실행 시간: 7.701초, 전체 시작 시간 20250130_232241_674\n",
      "\n",
      "epoch-37 accuracy check\n",
      "k_means origin feature average accuracy : 82.26398401%, total [0.9746727376209448, 0.9733106189664963, 0.9700891573195284, 0.9530800230282096, 0.943108504398827, 0.9150568181818182, 0.8015244796247435, 0.6625070901871809, 0.9488619568430388, 0.822215777262181, 0.5872695852534562, 0.5005858230814294, 0.9429250891795482, 0.8922588099364529, 0.675, 0.5997709705124534]\n",
      "save model\n",
      "kmeans average accuracy best : 91.33%, kmeans average accuracy : 91.32907103%, total [0.9738190096755834, 0.9750141964792731, 0.9726775956284153, 0.9666090961427749, 0.9665689149560117, 0.9607954545454546, 0.9284667253004983, 0.8579126488939308, 0.9411764705882353, 0.8912412993039444, 0.8133640552995391, 0.7668424135910955, 0.9589774078478003, 0.9387637203928365, 0.8787790697674419, 0.8216432865731463]\n",
      "cluster_accuracy_post_training_cycle_all_dataset : [0.97576302 0.9714795  0.96935933 0.97392924 0.97425743 0.95357143\n",
      " 0.91691395 0.84991119 0.94404883 0.89122137 0.7863806  0.77712032\n",
      " 0.96369295 0.95574388 0.87019231 0.83074108]\n",
      "mean_cluster_accuracy_during_training_cycle : 90.91%, post_traincycle_acc : 91.28%, total_acc : 91.01838102%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 91.28%\n",
      "accuracy_check 실행 시간: 10.899초\n",
      "\n",
      "\n",
      "epoch-38 loss : 0.01384\n",
      "ae train 실행 시간: 7.739초, 전체 시작 시간 20250130_232241_674\n",
      "\n",
      "epoch-38 accuracy check\n",
      "k_means origin feature average accuracy : 82.24966347%, total [0.9746727376209448, 0.9733106189664963, 0.9700891573195284, 0.9530800230282096, 0.943108504398827, 0.9150568181818182, 0.801817648783348, 0.6625070901871809, 0.9488619568430388, 0.822215777262181, 0.5866935483870968, 0.5005858230814294, 0.9429250891795482, 0.8922588099364529, 0.6747093023255814, 0.5980532493558546]\n",
      "kmeans average accuracy best : 91.33%, kmeans average accuracy : 91.32215327%, total [0.9738190096755834, 0.9741624077228848, 0.9723899913718723, 0.9671848013816926, 0.9668621700879766, 0.9610795454545454, 0.9281735561418939, 0.8581962563811685, 0.9423588530889743, 0.8929814385150812, 0.8142281105990783, 0.7680140597539543, 0.9580856123662307, 0.9370306181398036, 0.8781976744186046, 0.8187804179788147]\n",
      "cluster_accuracy_post_training_cycle_all_dataset : [0.97576302 0.97058824 0.96935933 0.97392924 0.97425743 0.95357143\n",
      " 0.91493571 0.85168739 0.94506612 0.89026718 0.78264925 0.76035503\n",
      " 0.96369295 0.95386064 0.87115385 0.8252516 ]\n",
      "mean_cluster_accuracy_during_training_cycle : 90.94%, post_traincycle_acc : 91.10%, total_acc : 90.98817957%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 91.28%\n",
      "accuracy_check 실행 시간: 11.197초\n",
      "\n",
      "\n",
      "epoch-39 loss : 0.01380\n",
      "ae train 실행 시간: 7.674초, 전체 시작 시간 20250130_232241_674\n",
      "\n",
      "epoch-39 accuracy check\n",
      "k_means origin feature average accuracy : 82.24960241%, total [0.9746727376209448, 0.9733106189664963, 0.9700891573195284, 0.9530800230282096, 0.943108504398827, 0.9150568181818182, 0.801817648783348, 0.6625070901871809, 0.9488619568430388, 0.822215777262181, 0.5872695852534562, 0.5005858230814294, 0.9429250891795482, 0.8922588099364529, 0.6738372093023256, 0.5983395362152877]\n",
      "save model\n",
      "kmeans average accuracy best : 91.34%, kmeans average accuracy : 91.33637225%, total [0.9738190096755834, 0.9744463373083475, 0.9726775956284153, 0.9668969487622338, 0.9671554252199414, 0.9616477272727273, 0.9278803869832893, 0.8579126488939308, 0.9417676618386048, 0.8941415313225058, 0.8148041474654378, 0.7662565905096661, 0.9586801426872771, 0.9373194685153091, 0.8784883720930232, 0.8199255654165474]\n",
      "cluster_accuracy_post_training_cycle_all_dataset : [0.97576302 0.9714795  0.96935933 0.97392924 0.97425743 0.95178571\n",
      " 0.91790307 0.85079929 0.94404883 0.88931298 0.78171642 0.76232742\n",
      " 0.96369295 0.95291902 0.87211538 0.82891125]\n",
      "mean_cluster_accuracy_during_training_cycle : 90.93%, post_traincycle_acc : 91.13%, total_acc : 90.99180266%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 91.13%\n",
      "accuracy_check 실행 시간: 11.048초\n",
      "\n",
      "\n",
      "epoch-40 loss : 0.01376\n",
      "ae train 실행 시간: 7.690초, 전체 시작 시간 20250130_232241_674\n",
      "\n",
      "epoch-40 accuracy check\n",
      "k_means origin feature average accuracy : 82.25854398%, total [0.9746727376209448, 0.9733106189664963, 0.9700891573195284, 0.9530800230282096, 0.943108504398827, 0.9150568181818182, 0.801817648783348, 0.6622234826999432, 0.9488619568430388, 0.822215777262181, 0.5866935483870968, 0.5005858230814294, 0.9429250891795482, 0.8922588099364529, 0.6738372093023256, 0.600629831090753]\n",
      "save model\n",
      "kmeans average accuracy best : 91.35%, kmeans average accuracy : 91.34879923%, total [0.9738190096755834, 0.9741624077228848, 0.9726775956284153, 0.9666090961427749, 0.9671554252199414, 0.9613636363636363, 0.929932571093521, 0.8587634713556438, 0.9402896837126811, 0.8915313225058005, 0.8136520737327189, 0.7671353251318102, 0.9586801426872771, 0.9387637203928365, 0.8781976744186046, 0.8230747208703121]\n",
      "cluster_accuracy_post_training_cycle_all_dataset : [0.97576302 0.97058824 0.96935933 0.97392924 0.97425743 0.95267857\n",
      " 0.91691395 0.85079929 0.94303154 0.89217557 0.77985075 0.76627219\n",
      " 0.96369295 0.95291902 0.87211538 0.82891125]\n",
      "mean_cluster_accuracy_during_training_cycle : 90.91%, post_traincycle_acc : 91.15%, total_acc : 90.97808307%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 91.15%\n",
      "accuracy_check 실행 시간: 11.052초\n",
      "\n",
      "\n",
      "epoch-41 loss : 0.01372\n",
      "ae train 실행 시간: 7.771초, 전체 시작 시간 20250130_232241_674\n",
      "\n",
      "epoch-41 accuracy check\n",
      "k_means origin feature average accuracy : 82.26402702%, total [0.9746727376209448, 0.9733106189664963, 0.9700891573195284, 0.9530800230282096, 0.943108504398827, 0.9150568181818182, 0.801817648783348, 0.6625070901871809, 0.9488619568430388, 0.822215777262181, 0.5872695852534562, 0.5005858230814294, 0.9429250891795482, 0.8922588099364529, 0.675, 0.5994846836530203]\n",
      "kmeans average accuracy best : 91.35%, kmeans average accuracy : 91.33538909%, total [0.9741035856573705, 0.9747302668938104, 0.9726775956284153, 0.9668969487622338, 0.9668621700879766, 0.9616477272727273, 0.9302257402521255, 0.8607487237663074, 0.9385161099615725, 0.8851508120649652, 0.8113479262672811, 0.7644991212653779, 0.9592746730083235, 0.939630271519353, 0.8825581395348837, 0.8247924420269109]\n",
      "cluster_accuracy_post_training_cycle_all_dataset : [0.97576302 0.9714795  0.96935933 0.97392924 0.97425743 0.95357143\n",
      " 0.92087043 0.85168739 0.94201424 0.88740458 0.77798507 0.76627219\n",
      " 0.96369295 0.95951036 0.87403846 0.83257091]\n",
      "mean_cluster_accuracy_during_training_cycle : 90.99%, post_traincycle_acc : 91.22%, total_acc : 91.05440306%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 91.15%\n",
      "accuracy_check 실행 시간: 11.066초\n",
      "\n",
      "\n",
      "epoch-42 loss : 0.01368\n",
      "ae train 실행 시간: 7.679초, 전체 시작 시간 20250130_232241_674\n",
      "\n",
      "epoch-42 accuracy check\n",
      "k_means origin feature average accuracy : 82.25855480%, total [0.9746727376209448, 0.9733106189664963, 0.9700891573195284, 0.9530800230282096, 0.943108504398827, 0.9150568181818182, 0.801817648783348, 0.6625070901871809, 0.9488619568430388, 0.822215777262181, 0.5866935483870968, 0.5005858230814294, 0.9429250891795482, 0.8922588099364529, 0.6741279069767442, 0.6000572573718866]\n",
      "save model\n",
      "kmeans average accuracy best : 91.35%, kmeans average accuracy : 91.35279658%, total [0.9738190096755834, 0.9747302668938104, 0.9726775956284153, 0.9668969487622338, 0.9665689149560117, 0.9610795454545454, 0.9287598944591029, 0.8573454339194555, 0.942654448714159, 0.8929814385150812, 0.8150921658986175, 0.7674282366725249, 0.9583828775267539, 0.9376083188908145, 0.8787790697674419, 0.8216432865731463]\n",
      "cluster_accuracy_post_training_cycle_all_dataset : [0.97576302 0.9714795  0.96935933 0.97392924 0.97425743 0.95446429\n",
      " 0.91988131 0.84902309 0.94201424 0.89026718 0.77891791 0.7642998\n",
      " 0.96369295 0.95480226 0.87403846 0.82982617]\n",
      "mean_cluster_accuracy_during_training_cycle : 90.92%, post_traincycle_acc : 91.16%, total_acc : 90.99089006%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 91.16%\n",
      "accuracy_check 실행 시간: 11.319초\n",
      "\n",
      "\n",
      "epoch-43 loss : 0.01401\n",
      "ae train 실행 시간: 7.699초, 전체 시작 시간 20250130_232241_674\n",
      "\n",
      "epoch-43 accuracy check\n",
      "k_means origin feature average accuracy : 82.26211374%, total [0.9746727376209448, 0.9733106189664963, 0.9700891573195284, 0.9530800230282096, 0.943108504398827, 0.915340909090909, 0.801817648783348, 0.6625070901871809, 0.9488619568430388, 0.822215777262181, 0.5872695852534562, 0.5005858230814294, 0.9429250891795482, 0.8922588099364529, 0.6738372093023256, 0.6000572573718866]\n",
      "save model\n",
      "kmeans average accuracy best : 91.56%, kmeans average accuracy : 91.55781307%, total [0.9735344336937962, 0.9741624077228848, 0.9723899913718723, 0.9660333909038572, 0.9674486803519061, 0.9619318181818182, 0.9290530636177075, 0.8593306863301191, 0.9603901862252439, 0.8967517401392111, 0.8225806451612904, 0.7671353251318102, 0.9592746730083235, 0.9410745233968805, 0.8805232558139535, 0.8176352705410822]\n",
      "cluster_accuracy_post_training_cycle_all_dataset : [0.97576302 0.97058824 0.96935933 0.97392924 0.97524752 0.95446429\n",
      " 0.91889219 0.85079929 0.95523906 0.89790076 0.79477612 0.76232742\n",
      " 0.96473029 0.95574388 0.87115385 0.82159195]\n",
      "mean_cluster_accuracy_during_training_cycle : 90.90%, post_traincycle_acc : 91.33%, total_acc : 91.02983258%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 91.33%\n",
      "accuracy_check 실행 시간: 10.850초\n",
      "\n",
      "\n",
      "epoch-44 loss : 0.01366\n",
      "ae train 실행 시간: 7.650초, 전체 시작 시간 20250130_232241_674\n",
      "\n",
      "epoch-44 accuracy check\n",
      "k_means origin feature average accuracy : 82.26041597%, total [0.9746727376209448, 0.9733106189664963, 0.9700891573195284, 0.9530800230282096, 0.943108504398827, 0.9150568181818182, 0.801817648783348, 0.6622234826999432, 0.9488619568430388, 0.822215777262181, 0.5866935483870968, 0.5005858230814294, 0.9429250891795482, 0.8922588099364529, 0.6747093023255814, 0.6000572573718866]\n",
      "kmeans average accuracy best : 91.56%, kmeans average accuracy : 91.53671550%, total [0.9738190096755834, 0.9747302668938104, 0.9726775956284153, 0.9666090961427749, 0.9668621700879766, 0.9619318181818182, 0.9319847552037526, 0.8624503686897335, 0.9530002955956252, 0.8938515081206496, 0.8159562211981567, 0.7727006444053895, 0.9580856123662307, 0.9376083188908145, 0.8811046511627907, 0.8225021471514458]\n",
      "cluster_accuracy_post_training_cycle_all_dataset : [0.97576302 0.97058824 0.96935933 0.97392924 0.97425743 0.95446429\n",
      " 0.92581602 0.85435169 0.9491353  0.89312977 0.78824627 0.77021696\n",
      " 0.96369295 0.9566855  0.86442308 0.82708143]\n",
      "mean_cluster_accuracy_during_training_cycle : 90.87%, post_traincycle_acc : 91.32%, total_acc : 91.00455708%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 91.33%\n",
      "accuracy_check 실행 시간: 11.212초\n",
      "\n",
      "\n",
      "epoch-45 loss : 0.01359\n",
      "ae train 실행 시간: 7.780초, 전체 시작 시간 20250130_232241_674\n",
      "\n",
      "epoch-45 accuracy check\n",
      "k_means origin feature average accuracy : 82.25318692%, total [0.9746727376209448, 0.9733106189664963, 0.9700891573195284, 0.9530800230282096, 0.943108504398827, 0.9150568181818182, 0.801817648783348, 0.6625070901871809, 0.9488619568430388, 0.822215777262181, 0.5866935483870968, 0.5005858230814294, 0.9429250891795482, 0.8922588099364529, 0.6741279069767442, 0.5991983967935872]\n",
      "kmeans average accuracy best : 91.56%, kmeans average accuracy : 91.43344714%, total [0.9738190096755834, 0.9744463373083475, 0.9726775956284153, 0.9666090961427749, 0.966275659824047, 0.9619318181818182, 0.9293462327763119, 0.8590470788428815, 0.9524091043452557, 0.8918213457076566, 0.8136520737327189, 0.768306971294669, 0.9586801426872771, 0.9370306181398036, 0.8796511627906977, 0.8236472945891784]\n",
      "cluster_accuracy_post_training_cycle_all_dataset : [0.97576302 0.97058824 0.96935933 0.97392924 0.97425743 0.95357143\n",
      " 0.92185955 0.85168739 0.94710071 0.89217557 0.78544776 0.76331361\n",
      " 0.96369295 0.95574388 0.86826923 0.82982617]\n",
      "mean_cluster_accuracy_during_training_cycle : 90.85%, post_traincycle_acc : 91.23%, total_acc : 90.96097231%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 91.33%\n",
      "accuracy_check 실행 시간: 10.867초\n",
      "\n",
      "\n",
      "epoch-46 loss : 0.01355\n",
      "ae train 실행 시간: 7.691초, 전체 시작 시간 20250130_232241_674\n",
      "\n",
      "epoch-46 accuracy check\n",
      "k_means origin feature average accuracy : 82.24590825%, total [0.9746727376209448, 0.9733106189664963, 0.9700891573195284, 0.9530800230282096, 0.943108504398827, 0.9150568181818182, 0.8015244796247435, 0.6625070901871809, 0.9488619568430388, 0.8219257540603249, 0.5866935483870968, 0.5005858230814294, 0.9429250891795482, 0.8922588099364529, 0.673546511627907, 0.5991983967935872]\n",
      "kmeans average accuracy best : 91.56%, kmeans average accuracy : 91.39361928%, total [0.9741035856573705, 0.9750141964792731, 0.9726775956284153, 0.9668969487622338, 0.9671554252199414, 0.962215909090909, 0.931691586045148, 0.8610323312535451, 0.9370381318356489, 0.8834106728538283, 0.8110599078341014, 0.7721148213239601, 0.9586801426872771, 0.939630271519353, 0.8854651162790698, 0.8247924420269109]\n",
      "cluster_accuracy_post_training_cycle_all_dataset : [0.97576302 0.9714795  0.96935933 0.97392924 0.97425743 0.95446429\n",
      " 0.91790307 0.85168739 0.94201424 0.89122137 0.78171642 0.76725838\n",
      " 0.96369295 0.95762712 0.86923077 0.82891125]\n",
      "mean_cluster_accuracy_during_training_cycle : 90.96%, post_traincycle_acc : 91.19%, total_acc : 91.02987252%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 91.33%\n",
      "accuracy_check 실행 시간: 10.923초\n",
      "\n",
      "\n",
      "epoch-47 loss : 0.01352\n",
      "ae train 실행 시간: 7.711초, 전체 시작 시간 20250130_232241_674\n",
      "\n",
      "epoch-47 accuracy check\n",
      "k_means origin feature average accuracy : 82.26042087%, total [0.9746727376209448, 0.9733106189664963, 0.9700891573195284, 0.9530800230282096, 0.943108504398827, 0.9150568181818182, 0.801817648783348, 0.6625070901871809, 0.9488619568430388, 0.822215777262181, 0.5872695852534562, 0.5005858230814294, 0.9429250891795482, 0.8922588099364529, 0.6747093023255814, 0.5991983967935872]\n",
      "kmeans average accuracy best : 91.56%, kmeans average accuracy : 91.51501498%, total [0.9735344336937962, 0.9750141964792731, 0.9723899913718723, 0.9671848013816926, 0.9665689149560117, 0.9619318181818182, 0.93051890941073, 0.8604651162790697, 0.9527046999704404, 0.8918213457076566, 0.8113479262672811, 0.7665495020503807, 0.9595719381688466, 0.9410745233968805, 0.8877906976744186, 0.8239335814486115]\n",
      "cluster_accuracy_post_training_cycle_all_dataset : [0.97576302 0.9714795  0.96935933 0.97392924 0.97425743 0.95446429\n",
      " 0.92185955 0.85079929 0.94404883 0.89122137 0.77985075 0.76331361\n",
      " 0.96473029 0.95762712 0.87403846 0.83074108]\n",
      "mean_cluster_accuracy_during_training_cycle : 90.98%, post_traincycle_acc : 91.23%, total_acc : 91.05658130%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 91.33%\n",
      "accuracy_check 실행 시간: 11.053초\n",
      "\n",
      "\n",
      "epoch-48 loss : 0.01350\n",
      "ae train 실행 시간: 7.668초, 전체 시작 시간 20250130_232241_674\n",
      "\n",
      "epoch-48 accuracy check\n",
      "k_means origin feature average accuracy : 82.24777182%, total [0.9746727376209448, 0.9733106189664963, 0.9700891573195284, 0.9530800230282096, 0.943108504398827, 0.915340909090909, 0.801817648783348, 0.6625070901871809, 0.9488619568430388, 0.822215777262181, 0.5872695852534562, 0.5005858230814294, 0.9429250891795482, 0.8922588099364529, 0.673546511627907, 0.5980532493558546]\n",
      "save model\n",
      "kmeans average accuracy best : 91.57%, kmeans average accuracy : 91.56756297%, total [0.9738190096755834, 0.9747302668938104, 0.9726775956284153, 0.9668969487622338, 0.9665689149560117, 0.9627840909090909, 0.9322779243623571, 0.8633011911514464, 0.9417676618386048, 0.8900812064965197, 0.8133640552995391, 0.7712360867018161, 0.9595719381688466, 0.9428076256499134, 0.8906976744186047, 0.8282278843401087]\n",
      "cluster_accuracy_post_training_cycle_all_dataset : [0.97576302 0.97058824 0.96935933 0.97392924 0.97425743 0.95446429\n",
      " 0.92680514 0.85523979 0.94303154 0.88931298 0.77705224 0.76331361\n",
      " 0.96473029 0.95856874 0.87115385 0.83531565]\n",
      "mean_cluster_accuracy_during_training_cycle : 91.10%, post_traincycle_acc : 91.27%, total_acc : 91.15210349%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 91.27%\n",
      "accuracy_check 실행 시간: 11.354초\n",
      "\n",
      "\n",
      "epoch-49 loss : 0.01346\n",
      "ae train 실행 시간: 7.695초, 전체 시작 시간 20250130_232241_674\n",
      "\n",
      "epoch-49 accuracy check\n",
      "k_means origin feature average accuracy : 82.26218852%, total [0.9746727376209448, 0.9733106189664963, 0.9700891573195284, 0.9530800230282096, 0.943108504398827, 0.9150568181818182, 0.801817648783348, 0.6625070901871809, 0.9488619568430388, 0.822215777262181, 0.5866935483870968, 0.5005858230814294, 0.9429250891795482, 0.8922588099364529, 0.6747093023255814, 0.6000572573718866]\n",
      "save model\n",
      "kmeans average accuracy best : 91.64%, kmeans average accuracy : 91.63783982%, total [0.9738190096755834, 0.9747302668938104, 0.9726775956284153, 0.9671848013816926, 0.9659824046920821, 0.9625, 0.9322779243623571, 0.8633011911514464, 0.9532958912208099, 0.8953016241299304, 0.8153801843317973, 0.7703573520796719, 0.9595719381688466, 0.9404968226458694, 0.888953488372093, 0.8262238763240767]\n",
      "cluster_accuracy_post_training_cycle_all_dataset : [0.97576302 0.97058824 0.96935933 0.97392924 0.97425743 0.95357143\n",
      " 0.9248269  0.85257549 0.94608342 0.89503817 0.78078358 0.765286\n",
      " 0.96473029 0.95762712 0.87019231 0.83531565]\n",
      "mean_cluster_accuracy_during_training_cycle : 91.12%, post_traincycle_acc : 91.31%, total_acc : 91.17590423%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 91.31%\n",
      "accuracy_check 실행 시간: 10.922초\n",
      "\n",
      "\n",
      "epoch-50 loss : 0.01344\n",
      "ae train 실행 시간: 7.720초, 전체 시작 시간 20250130_232241_674\n",
      "\n",
      "epoch-50 accuracy check\n",
      "k_means origin feature average accuracy : 82.24421289%, total [0.9746727376209448, 0.9733106189664963, 0.9700891573195284, 0.9530800230282096, 0.943108504398827, 0.9150568181818182, 0.801817648783348, 0.6625070901871809, 0.9488619568430388, 0.822215777262181, 0.5866935483870968, 0.5005858230814294, 0.9429250891795482, 0.8922588099364529, 0.6738372093023256, 0.5980532493558546]\n",
      "kmeans average accuracy best : 91.64%, kmeans average accuracy : 91.60728550%, total [0.9738190096755834, 0.9744463373083475, 0.9723899913718723, 0.9668969487622338, 0.9659824046920821, 0.9619318181818182, 0.9313984168865436, 0.8613159387407827, 0.9532958912208099, 0.8935614849187935, 0.8119239631336406, 0.7694786174575279, 0.9595719381688466, 0.9419410745233969, 0.8906976744186047, 0.828514171199542]\n",
      "cluster_accuracy_post_training_cycle_all_dataset : [0.97576302 0.97058824 0.96935933 0.97392924 0.97425743 0.95446429\n",
      " 0.9248269  0.84991119 0.94710071 0.89408397 0.77891791 0.765286\n",
      " 0.96473029 0.95951036 0.87307692 0.83440073]\n",
      "mean_cluster_accuracy_during_training_cycle : 91.02%, post_traincycle_acc : 91.31%, total_acc : 91.10701895%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 91.31%\n",
      "accuracy_check 실행 시간: 11.377초\n",
      "\n",
      "\n",
      "epoch-51 loss : 0.01341\n",
      "ae train 실행 시간: 7.748초, 전체 시작 시간 20250130_232241_674\n",
      "\n",
      "epoch-51 accuracy check\n",
      "k_means origin feature average accuracy : 82.26207825%, total [0.9746727376209448, 0.9733106189664963, 0.9700891573195284, 0.9530800230282096, 0.943108504398827, 0.9150568181818182, 0.801817648783348, 0.6625070901871809, 0.9488619568430388, 0.822215777262181, 0.5866935483870968, 0.5005858230814294, 0.9429250891795482, 0.8922588099364529, 0.673546511627907, 0.6012024048096193]\n",
      "kmeans average accuracy best : 91.64%, kmeans average accuracy : 91.56104845%, total [0.9738190096755834, 0.9747302668938104, 0.9726775956284153, 0.9668969487622338, 0.966275659824047, 0.9619318181818182, 0.9319847552037526, 0.8624503686897335, 0.9464971918415608, 0.8924013921113689, 0.8139400921658986, 0.7680140597539543, 0.960166468489893, 0.9404968226458694, 0.8901162790697674, 0.8273690237618093]\n",
      "cluster_accuracy_post_training_cycle_all_dataset : [0.97576302 0.97058824 0.96935933 0.97392924 0.97425743 0.95535714\n",
      " 0.92581602 0.85346359 0.94506612 0.89122137 0.77891791 0.76923077\n",
      " 0.96473029 0.95762712 0.875      0.83531565]\n",
      "mean_cluster_accuracy_during_training_cycle : 91.07%, post_traincycle_acc : 91.35%, total_acc : 91.15013032%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 91.31%\n",
      "accuracy_check 실행 시간: 11.178초\n",
      "\n",
      "\n",
      "epoch-52 loss : 0.01338\n",
      "ae train 실행 시간: 7.755초, 전체 시작 시간 20250130_232241_674\n",
      "\n",
      "epoch-52 accuracy check\n",
      "k_means origin feature average accuracy : 82.25137006%, total [0.9746727376209448, 0.9733106189664963, 0.9700891573195284, 0.9530800230282096, 0.943108504398827, 0.9150568181818182, 0.801817648783348, 0.6625070901871809, 0.9488619568430388, 0.822215777262181, 0.5866935483870968, 0.5005858230814294, 0.9429250891795482, 0.8922588099364529, 0.6738372093023256, 0.5991983967935872]\n",
      "save model\n",
      "kmeans average accuracy best : 91.73%, kmeans average accuracy : 91.72608877%, total [0.9738190096755834, 0.9747302668938104, 0.9726775956284153, 0.9660333909038572, 0.9665689149560117, 0.9625, 0.9349164467897977, 0.8667044809982983, 0.9530002955956252, 0.8947215777262181, 0.8159562211981567, 0.7680140597539543, 0.9607609988109393, 0.9436741767764298, 0.8921511627906977, 0.8299456054967077]\n",
      "cluster_accuracy_post_training_cycle_all_dataset : [0.97576302 0.97058824 0.96935933 0.97392924 0.97425743 0.95535714\n",
      " 0.92087043 0.85346359 0.94608342 0.89312977 0.77985075 0.765286\n",
      " 0.96473029 0.96045198 0.87596154 0.83165599]\n",
      "mean_cluster_accuracy_during_training_cycle : 91.25%, post_traincycle_acc : 91.32%, total_acc : 91.26643211%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 91.32%\n",
      "accuracy_check 실행 시간: 11.012초\n",
      "\n",
      "\n",
      "epoch-53 loss : 0.01336\n",
      "ae train 실행 시간: 7.763초, 전체 시작 시간 20250130_232241_674\n",
      "\n",
      "epoch-53 accuracy check\n",
      "k_means origin feature average accuracy : 82.25149115%, total [0.9746727376209448, 0.9733106189664963, 0.9700891573195284, 0.9530800230282096, 0.943108504398827, 0.9150568181818182, 0.801817648783348, 0.6622234826999432, 0.9488619568430388, 0.822215777262181, 0.5872695852534562, 0.5005858230814294, 0.9429250891795482, 0.8922588099364529, 0.6747093023255814, 0.5980532493558546]\n",
      "save model\n",
      "kmeans average accuracy best : 91.73%, kmeans average accuracy : 91.73187982%, total [0.9741035856573705, 0.9747302668938104, 0.9726775956284153, 0.9668969487622338, 0.9659824046920821, 0.9625, 0.9325710935209616, 0.8638684061259218, 0.9553650605971031, 0.8979118329466357, 0.815668202764977, 0.768306971294669, 0.9604637336504162, 0.9433853264009243, 0.8921511627906977, 0.830518179215574]\n",
      "cluster_accuracy_post_training_cycle_all_dataset : [0.97576302 0.97058824 0.96935933 0.97392924 0.97425743 0.95357143\n",
      " 0.92680514 0.85257549 0.94608342 0.89408397 0.77985075 0.76232742\n",
      " 0.96473029 0.95951036 0.87403846 0.83531565]\n",
      "mean_cluster_accuracy_during_training_cycle : 91.28%, post_traincycle_acc : 91.33%, total_acc : 91.29341349%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 91.33%\n",
      "accuracy_check 실행 시간: 11.021초\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "gpu = '0'\n",
    "Conv_net = True # True False\n",
    "SAE_net = False # True False\n",
    "\n",
    "# hyperparameter\n",
    "dataset_num = 16\n",
    "spike_length = 50 # coarse_com_mode일 때는 time step이 됨.\n",
    "num_cluster = 4  # 클러스터 수 설정 # 논문엔 4개라는데 여기서는 3개로 했네\n",
    "training_cycle = 2400 #1400 2400 # 그 초기 몇개까지만 cluster update할지\n",
    "\n",
    "\n",
    "batch_size = 32\n",
    "max_epoch = 7000\n",
    "learning_rate = 0.001\n",
    "normalize_on = True # True or False # 0부터1까지 normalize\n",
    "need_bias = False\n",
    "# first_layer_no_train = False\n",
    "lif_add_at_first = False\n",
    "my_seed = 42\n",
    "\n",
    "TIME = 1000 # SAE일 때만 유효. coarse_com_mode일 때는 level_num이 됨. 즉 feature 개수.\n",
    "v_decay = 0.25 # -cor\n",
    "v_threshold = 0.5 # -cor\n",
    "v_reset = 10000.0 # -cor # 10000이상 일 시 hard reset\n",
    "BPTT_on = False # +cor # True False\n",
    "\n",
    "SAE_hidden_nomean = True # True False\n",
    "\n",
    "current_time = datetime.datetime.now().strftime(\"%Y%m%d_%H%M%S\") + f\"_{str(int(datetime.datetime.now().microsecond / 1000)).zfill(3)}\"\n",
    "\n",
    "optimizer = 'SGD' #'Adam', 'SGD' # 둘다 준수함. loss 줄이는 거는 adam이 좋긴한데, cluster accuracy는 비슷함.\n",
    "\n",
    "coarse_com_mode = False # True False\n",
    "coarse_com_config = (1.0, -0.0) # (max, min) (2.0, -2.0) (3.0, -3.0)\n",
    "\n",
    "sae_l2_norm_bridge = True # True False\n",
    "sae_lif_bridge = True # False True\n",
    "\n",
    "accuracy_check_epoch_term = 1\n",
    "\n",
    "lif_add_at_last = False # True False\n",
    "\n",
    "two_channel_input = False # True False\n",
    "\n",
    "lateral_feature_num = 4\n",
    "\n",
    "lc_adc_on = False # True False\n",
    "\n",
    "converted_net_forward = False # True False\n",
    "\n",
    "pretrained_net = None\n",
    "# pretrained_net = '/home/bhkim003/github_folder/ByeonghyeonKim/my_snn/net_save/save_now_net_중요_20250110_203117_390.pth'\n",
    "# pretrained_net = '/home/bhkim003/github_folder/ByeonghyeonKim/my_snn/net_save/save_now_net_중요_20250113_134126_881_이거_94나오는거.pth'\n",
    "# pretrained_net = '/home/bhkim003/github_folder/ByeonghyeonKim/my_snn/net_save/save_now_net_중요_20250115_200335_029_무한열차95.12.pth'\n",
    "# pretrained_net = '/home/bhkim003/github_folder/ByeonghyeonKim/my_snn/net_save/save_now_net_중요_20250115_200335_029_무한열차95.23.pth'\n",
    "\n",
    "vth_mul_on = False # True False\n",
    "batch_norm_on = False # True False\n",
    "\n",
    "l2_norm_loss_weight = 0 #0.0001 #0.1 #  0 # 0초과면 작동\n",
    "\n",
    "QCFS_neuron_on = False # True False\n",
    "\n",
    "quantize_level_num = 0 # 0이면 quantize 안함. 1이상이면 그 수만큼 quantize함.\n",
    "\n",
    "wandb.init(project= f'spike_sorting just run',save_code=False)\n",
    "\n",
    "\n",
    "cluster_train_system( \n",
    "    gpu = gpu,\n",
    "    Conv_net = Conv_net,\n",
    "    SAE_net = SAE_net,\n",
    "\n",
    "    # hyperparameter\n",
    "    dataset_num = dataset_num,\n",
    "    spike_length = spike_length,\n",
    "    num_cluster = num_cluster,  # 클러스터 수 설정 # 논문엔 4개라는데 여기서는 3개로 했네\n",
    "    training_cycle = training_cycle, # 그 초기 몇개까지만 cluster update할지\n",
    "\n",
    "\n",
    "    batch_size = batch_size,\n",
    "    max_epoch = max_epoch,\n",
    "    learning_rate = learning_rate,\n",
    "    normalize_on = normalize_on, # True or False #이거 안 씀 # 이거 별로 안 좋은 normalize같음 # 쓸 거면 다른 거 써라.\n",
    "    need_bias = need_bias,\n",
    "    # first_layer_no_train = False\n",
    "    lif_add_at_first = lif_add_at_first,\n",
    "    my_seed = my_seed,\n",
    "\n",
    "    TIME = TIME, # SAE일 때만 유효\n",
    "    v_decay = v_decay,\n",
    "    v_threshold = v_threshold,\n",
    "    v_reset = v_reset, # 10000이상 일 시 hard reset\n",
    "    BPTT_on = BPTT_on,\n",
    "\n",
    "    SAE_hidden_nomean = SAE_hidden_nomean,\n",
    "    \n",
    "    current_time = current_time,\n",
    "\n",
    "    optimizer = optimizer, #'Adam', 'SGD'\n",
    "\n",
    "    coarse_com_mode = coarse_com_mode,\n",
    "    coarse_com_config = coarse_com_config, # (max, min)\n",
    "\n",
    "    \n",
    "    sae_l2_norm_bridge = sae_l2_norm_bridge,\n",
    "    sae_lif_bridge = sae_lif_bridge,\n",
    "\n",
    "    accuracy_check_epoch_term = accuracy_check_epoch_term,\n",
    "    \n",
    "    lif_add_at_last = lif_add_at_last,\n",
    "\n",
    "    two_channel_input = two_channel_input,\n",
    "\n",
    "    lateral_feature_num = lateral_feature_num,\n",
    "\n",
    "    lc_adc_on = lc_adc_on, \n",
    "\n",
    "    converted_net_forward = converted_net_forward,\n",
    "\n",
    "    pretrained_net = pretrained_net,\n",
    "\n",
    "    vth_mul_on = vth_mul_on,\n",
    "    batch_norm_on = batch_norm_on,\n",
    "\n",
    "    l2_norm_loss_weight = l2_norm_loss_weight,\n",
    "    \n",
    "    QCFS_neuron_on = QCFS_neuron_on, # True False\n",
    "\n",
    "    quantize_level_num = quantize_level_num,\n",
    "\n",
    "    )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Sweep code\n",
    "\n",
    "\n",
    "# from unittest import TextTestRunner\n",
    "\n",
    "\n",
    "# unique_name_hyper = 'cluster_train_system'\n",
    "# # run_name = 'spike_sorting'\n",
    "# sweep_start_time =  datetime.datetime.now().strftime(\"%Y%m%d_%H%M%S\") + f\"_{str(int(datetime.datetime.now().microsecond / 1000)).zfill(3)}\"\n",
    "# sweep_configuration = {\n",
    "#     'method': 'bayes', # 'random', 'bayes'\n",
    "#     'name': f'spike_sorting_{sweep_start_time}',\n",
    "#     'metric': {'goal': 'maximize', 'name': 'k_means_acc_best'},\n",
    "#     'parameters': \n",
    "#     {\n",
    "#         # \"gpu\": {\"values\": ['1']},  # 이건 sweep parameter아님. hyper_iter에서 직접 설정\n",
    "#         \"Conv_net\": {\"values\": [True]}, \n",
    "#         \"SAE_net\": {\"values\": [False]}, \n",
    "\n",
    "#         \"dataset_num\": {\"values\": [16]}, \n",
    "#         \"spike_length\": {\"values\": [50]},  \n",
    "#         \"num_cluster\": {\"values\": [4]}, \n",
    "#         \"training_cycle\": {\"values\": [2400]}, # [1400, 2400]\n",
    "\n",
    "#         \"batch_size\": {\"values\": [32]}, \n",
    "#         \"max_epoch\": {\"values\": [1]}, \n",
    "#         \"learning_rate\": {\"values\": [0.001, 0.0001]},\n",
    "#         \"normalize_on\": {\"values\": [True]},\n",
    "#         \"need_bias\": {\"values\": [False]}, # [True, False]\n",
    "\n",
    "#         \"lif_add_at_first\": {\"values\": [False]}, # [True, False]\n",
    "#         \"my_seed\": {\"values\": [42]}, \n",
    "\n",
    "#         \"TIME\": {\"values\": [10, 50, 100, 250, 500, 750, 1000, 1500, 2000, 2500]}, #  [4,6,8,10]\n",
    "#         \"v_decay\": {\"values\": [1.0]}, # [0.25,0.50,0.75]\n",
    "#         \"v_threshold\": {\"values\": [0.125, 0.25, 0.50, 0.75, 0.875, 1.0]}, # [0.25,0.50,0.75]\n",
    "#         \"v_reset\": {\"values\": [0.0, 10000.0]},  # [0.0, 10000.0]\n",
    "#         \"BPTT_on\": {\"values\": [True, False]},  # [True, False]\n",
    "\n",
    "#         \"SAE_hidden_nomean\": {\"values\": [True]}, # [True, False]\n",
    "\n",
    "#         # \"current_time\": {\"values\": [current_time]} #밑에서 직접설정됨.\n",
    "\n",
    "#         \"optimizer\": {\"values\": ['Adam', 'SGD']}, # ['Adam', 'SGD']\n",
    "\n",
    "#         \"coarse_com_mode\": {\"values\": [False]}, # [True, False]\n",
    "#         \"coarse_com_config\": {\"values\": [(2.0, -2.0)]}, # ['Adam', 'SGD']\n",
    "\n",
    "#         \"sae_l2_norm_bridge\": {\"values\": [True]}, # [True, False]\n",
    "#         \"sae_lif_bridge\": {\"values\": [True]}, # [False, True]\n",
    "        \n",
    "#         \"accuracy_check_epoch_term\": {\"values\": [1]}, \n",
    "\n",
    "#         \"lif_add_at_last\": {\"values\": [False]},# [True, False]\n",
    "\n",
    "#         \"two_channel_input\": {\"values\": [False]},# [True, False]\n",
    "\n",
    "#         \"lateral_feature_num\": {\"values\": [4]},# [True, False]\n",
    "\n",
    "#         \"lc_adc_on\": {\"values\": [False]},# [True, False]\n",
    "        \n",
    "#         \"converted_net_forward\": {\"values\": [True]},# [True, False]\n",
    "\n",
    "#         \"pretrained_net\": {\"values\": ['/home/bhkim003/github_folder/ByeonghyeonKim/my_snn/net_save/save_now_net_중요_20250110_203117_390.pth']},# [None]\n",
    "\n",
    "#         \"vth_mul_on\": {\"values\": [True]},# [True, False]\n",
    "#         \"batch_norm_on\": {\"values\": [True]},# [True, False]\n",
    "\n",
    "#         \"l2_norm_loss_weight\": {\"values\": [0.1]},\n",
    "\n",
    "#         \"QCFS_neuron_on\": {\"values\": [True]},   # [True, False]\n",
    "\n",
    "#         \"quantize_level_num\": {\"values\": [0]}, \n",
    "\n",
    "\n",
    "#      }\n",
    "# }\n",
    "\n",
    "\n",
    "# def hyper_iter():\n",
    "#     ### my_snn control board ########################\n",
    "#     wandb.init(save_code = False)\n",
    "#     gpu  =  '2'\n",
    "#     Conv_net  =  wandb.config.Conv_net\n",
    "#     SAE_net  =  wandb.config.SAE_net\n",
    "\n",
    "#     dataset_num  =  wandb.config.dataset_num\n",
    "#     spike_length  =  wandb.config.spike_length\n",
    "#     num_cluster  =  wandb.config.num_cluster\n",
    "#     training_cycle  =  wandb.config.training_cycle\n",
    "\n",
    "#     batch_size  =  wandb.config.batch_size\n",
    "#     max_epoch  =  wandb.config.max_epoch\n",
    "#     learning_rate  =  wandb.config.learning_rate\n",
    "#     normalize_on  =  wandb.config.normalize_on\n",
    "#     need_bias  =  wandb.config.need_bias\n",
    "\n",
    "#     lif_add_at_first  =  wandb.config.lif_add_at_first\n",
    "#     my_seed  =  wandb.config.my_seed\n",
    "\n",
    "\n",
    "#     TIME  =  wandb.config.TIME\n",
    "#     v_decay  =  wandb.config.v_decay\n",
    "#     v_threshold  =  wandb.config.v_threshold\n",
    "#     v_reset  =  wandb.config.v_reset\n",
    "#     BPTT_on  =  wandb.config.BPTT_on\n",
    "\n",
    "#     SAE_hidden_nomean  =  wandb.config.SAE_hidden_nomean\n",
    "    \n",
    "#     current_time =  datetime.datetime.now().strftime(\"%Y%m%d_%H%M%S\") + f\"_{str(int(datetime.datetime.now().microsecond / 1000)).zfill(3)}\"\n",
    "\n",
    "#     optimizer  =  wandb.config.optimizer\n",
    "\n",
    "#     coarse_com_mode = wandb.config.coarse_com_mode\n",
    "#     coarse_com_config = wandb.config.coarse_com_config # (max, min)\n",
    "\n",
    "#     sae_l2_norm_bridge = wandb.config.sae_l2_norm_bridge\n",
    "#     sae_lif_bridge = wandb.config.sae_lif_bridge\n",
    "\n",
    "#     accuracy_check_epoch_term = wandb.config.accuracy_check_epoch_term\n",
    "\n",
    "#     lif_add_at_last = wandb.config.lif_add_at_last\n",
    "\n",
    "#     two_channel_input = wandb.config.two_channel_input\n",
    "\n",
    "#     lateral_feature_num = wandb.config.lateral_feature_num\n",
    "\n",
    "#     lc_adc_on = wandb.config.lc_adc_on\n",
    "\n",
    "#     converted_net_forward = wandb.config.converted_net_forward\n",
    "\n",
    "#     pretrained_net = wandb.config.pretrained_net\n",
    "\n",
    "#     vth_mul_on = wandb.config.vth_mul_on\n",
    "#     batch_norm_on = wandb.config.batch_norm_on\n",
    "\n",
    "#     l2_norm_loss_weight = wandb.config.l2_norm_loss_weight\n",
    "\n",
    "#     QCFS_neuron_on = wandb.config.QCFS_neuron_on\n",
    "\n",
    "#     quantize_level_num = wandb.config.quantize_level_num\n",
    "\n",
    "    \n",
    "\n",
    "#     cluster_train_system( \n",
    "#         gpu = gpu,\n",
    "#         Conv_net = Conv_net,\n",
    "#         SAE_net = SAE_net,\n",
    "\n",
    "#         # hyperparameter\n",
    "#         dataset_num = dataset_num,\n",
    "#         spike_length = spike_length,\n",
    "#         num_cluster = num_cluster,  # 클러스터 수 설정 # 논문엔 4개라는데 여기서는 3개로 했네\n",
    "#         training_cycle = training_cycle, # 그 초기 몇개까지만 cluster update할지\n",
    "\n",
    "\n",
    "#         batch_size = batch_size,\n",
    "#         max_epoch = max_epoch,\n",
    "#         learning_rate = learning_rate,\n",
    "#         normalize_on = normalize_on, # True or False #이거 안 씀 # 이거 별로 안 좋은 normalize같음 # 쓸 거면 다른 거 써라.\n",
    "#         need_bias = need_bias,\n",
    "#         # first_layer_no_train = False\n",
    "#         lif_add_at_first = lif_add_at_first,\n",
    "#         my_seed = my_seed,\n",
    "\n",
    "#         TIME = TIME, # SAE일 때만 유효\n",
    "#         v_decay = v_decay,\n",
    "#         v_threshold = v_threshold,\n",
    "#         v_reset = v_reset, # 10000이상 일 시 hard reset\n",
    "#         BPTT_on = BPTT_on,\n",
    "\n",
    "#         SAE_hidden_nomean = SAE_hidden_nomean,\n",
    "\n",
    "#         current_time = current_time,\n",
    "\n",
    "#         optimizer = optimizer, #'Adam', 'SGD'\n",
    "\n",
    "#         coarse_com_mode = coarse_com_mode,\n",
    "#         coarse_com_config = coarse_com_config, # (max, min)\n",
    "        \n",
    "#         sae_l2_norm_bridge = sae_l2_norm_bridge,\n",
    "#         sae_lif_bridge = sae_lif_bridge,\n",
    "\n",
    "#         accuracy_check_epoch_term = accuracy_check_epoch_term,\n",
    "\n",
    "#         lif_add_at_last = lif_add_at_last,\n",
    "        \n",
    "#         two_channel_input = two_channel_input,\n",
    "        \n",
    "#         lateral_feature_num = lateral_feature_num,\n",
    "\n",
    "#         lc_adc_on = lc_adc_on,\n",
    "\n",
    "#         converted_net_forward = converted_net_forward,\n",
    "\n",
    "#         pretrained_net = pretrained_net,\n",
    "\n",
    "#         vth_mul_on = vth_mul_on,\n",
    "#         batch_norm_on = batch_norm_on,\n",
    "\n",
    "#         l2_norm_loss_weight = l2_norm_loss_weight,\n",
    "\n",
    "#         QCFS_neuron_on = QCFS_neuron_on,\n",
    "\n",
    "#         quantize_level_num = quantize_level_num,\n",
    "\n",
    "#         )\n",
    "    \n",
    "# # sweep_id = 'ygoj9jt4'\n",
    "# sweep_id = wandb.sweep(sweep=sweep_configuration, project=f'spike_sorting {unique_name_hyper}')\n",
    "# wandb.agent(sweep_id, function=hyper_iter, count=100000, project=f'spike_sorting {unique_name_hyper}')\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wandb.finish() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import matplotlib.pyplot as plt\n",
    "# from matplotlib.ticker import MaxNLocator\n",
    "# import pickle\n",
    "# import json\n",
    "\n",
    "# # current_time = '20250102_225243_972'\n",
    "\n",
    "# with open(f\"result_save/cluster_accuracy_history_{current_time}.pkl\", \"rb\") as f:\n",
    "#     data = pickle.load(f)\n",
    "\n",
    "\n",
    "# # JSON으로 저장\n",
    "# with open(f\"result_save/cluster_accuracy_history_{current_time}.json\", 'r') as f:\n",
    "#     loaded_hyperparameters = json.load(f)\n",
    "\n",
    "# loss_history = data['loss_history']\n",
    "# mean_cluster_accuracy_during_training_cycle_all_dataset_history = data['mean_cluster_accuracy_during_training_cycle_all_dataset_history']\n",
    "# mean_cluster_accuracy_post_training_cycle_all_dataset_history = data['mean_cluster_accuracy_post_training_cycle_all_dataset_history']\n",
    "# mean_cluster_accuracy_total_all_dataset_history = data['mean_cluster_accuracy_total_all_dataset_history']\n",
    "# print(data)\n",
    "# max_acc = 0\n",
    "# for i in mean_cluster_accuracy_post_training_cycle_all_dataset_history:\n",
    "#     if i[1] > max_acc:\n",
    "#         max_acc = i[1]\n",
    "\n",
    "# # 설정 정보 제목 작성\n",
    "# title = (\n",
    "#     f\"Dataset Num: {loaded_hyperparameters['dataset_num']}, Conv {loaded_hyperparameters['Conv_net']}, SAE {loaded_hyperparameters['SAE_net']}, Current time {loaded_hyperparameters['current_time']}, Spike Length: {loaded_hyperparameters['spike_length']}, Num Cluster: {loaded_hyperparameters['num_cluster']}, \"\n",
    "#     f\"Training Cycle: {loaded_hyperparameters['training_cycle']}, Batch Size: {loaded_hyperparameters['batch_size']}, Max Epoch: {loaded_hyperparameters['max_epoch']}, \\n\"\n",
    "#     f\"Learning Rate: {loaded_hyperparameters['learning_rate']}, Input Normalize: {loaded_hyperparameters['normalize_on']}, Need Bias: {loaded_hyperparameters['need_bias']}, \"\n",
    "#     f\"LIF Add at First: {loaded_hyperparameters['lif_add_at_first']}, TIME: {loaded_hyperparameters['TIME']}, Seed: {loaded_hyperparameters['my_seed']}, Best ACC: {max_acc:.2f}%\"\n",
    "# )\n",
    "\n",
    "# # 데이터 리스트와 라벨 설정 (Loss 제외)\n",
    "# data_list = [\n",
    "#     (\"Mean Cluster Accuracy (During Training Cycle)\", mean_cluster_accuracy_during_training_cycle_all_dataset_history),\n",
    "#     (\"Mean Cluster Accuracy (Post Training Cycle)\", mean_cluster_accuracy_post_training_cycle_all_dataset_history),\n",
    "#     (\"Mean Cluster Accuracy (Total)\", mean_cluster_accuracy_total_all_dataset_history),\n",
    "# ]\n",
    "\n",
    "# # 플롯 생성\n",
    "# fig, ax1 = plt.subplots(figsize=(12, 8))\n",
    "\n",
    "# # 첫 번째 y축: Accuracy 관련 데이터\n",
    "# for label, data in data_list:\n",
    "#     epochs, values = zip(*data)  # epoch, value 분리\n",
    "#     ax1.plot(epochs, values, label=label)\n",
    "\n",
    "# ax1.set_xlabel(\"Epoch\")\n",
    "# ax1.set_ylabel(\"Clurstering Accuracy [%]\", color=\"blue\")\n",
    "# ax1.tick_params(axis=\"y\", labelcolor=\"blue\")\n",
    "# ax1.legend(loc=\"center right\")\n",
    "# ax1.grid(True)\n",
    "\n",
    "# # x축을 정수만 표시하도록 설정\n",
    "# ax1.xaxis.set_major_locator(MaxNLocator(integer=True))\n",
    "\n",
    "# # 두 번째 y축: Loss History\n",
    "# ax2 = ax1.twinx()\n",
    "# epochs, values = zip(*loss_history)\n",
    "# ax2.plot(epochs, values, label=\"AE Loss History\", color=\"red\", linestyle=\"--\")\n",
    "# ax2.set_ylabel(\"Loss\", color=\"red\")\n",
    "# ax2.tick_params(axis=\"y\", labelcolor=\"red\")\n",
    "# ax2.legend(loc=\"center left\")\n",
    "\n",
    "# # 제목 추가\n",
    "# plt.title(title, fontsize=10)\n",
    "# plt.tight_layout()\n",
    "# plt.savefig(f'net_save/{current_time}', dpi=300, bbox_inches=\"tight\")  # dpi=300은 고해상도로 저장, bbox_inches=\"tight\"는 여백 최소화\n",
    "# plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# 데이터셋\n",
    "filename_for_plot = [\n",
    "    \"Easy1_noise05\", \"Easy1_noise10\", \"Easy1_noise15\", \"Easy1_noise20\",\n",
    "    \"Easy2_noise05\", \"Easy2_noise10\", \"Easy2_noise15\", \"Easy2_noise20\",\n",
    "    \"Difficult1_noise05\", \"Difficult1_noise10\", \"Difficult1_noise15\", \"Difficult1_noise20\",\n",
    "    \"Difficult2_noise05\", \"Difficult2_noise10\", \"Difficult2_noise15\", \"Difficult2_noise20\"\n",
    "]\n",
    "\n",
    "# Accuracy 데이터\n",
    "ANN_conv_accracy_set= [0.97935368, 0.97682709, 0.97028784, 0.96461825, 0.97524752, 0.95803571\n",
    ", 0.95746785, 0.92628774, 0.965412,  0.97805344, 0.94869403, 0.92110454\n",
    ", 0.96784232, 0.97551789, 0.91538462, 0.84446478]\n",
    "SNN_fc_accuracy_set = [0.97114475, 0.97643732, 0.84400578, 0.78977821, 0.96616915, 0.92830189\n",
    ", 0.86176032, 0.31984948, 0.80635401, 0.88769531, 0.61003861, 0.60377358\n",
    ", 0.9592668,  0.92870999, 0.78333333, 0.67271859]\n",
    "SNN_conv_accuracy_set = [0.97445601, 0.97737983, 0.97063072, 0.95998071, 0.96268657, 0.90566038\n",
    ", 0.82545997, 0.68391345, 0.96116994, 0.92138672, 0.80694981, 0.49602781\n",
    ", 0.83604888, 0.70611057, 0.69313725, 0.5819398 ]\n",
    "\n",
    "# 평균 계산\n",
    "average_ANN_conv = np.mean(ANN_conv_accracy_set)\n",
    "average_SNN_fc = np.mean(SNN_fc_accuracy_set)\n",
    "average_SNN_conv = np.mean(SNN_conv_accuracy_set)\n",
    "\n",
    "# 데이터 준비\n",
    "accuracies = np.array([ANN_conv_accracy_set, SNN_fc_accuracy_set, SNN_conv_accuracy_set])\n",
    "averages = np.array([average_ANN_conv, average_SNN_fc, average_SNN_conv])\n",
    "\n",
    "# 시각화\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "\n",
    "# 각 모델의 정확도 플롯\n",
    "ax.plot(accuracies[0], label='ANN Conv', marker='o', linestyle='-', color='blue')\n",
    "ax.plot(accuracies[1], label='SNN FC', marker='o', linestyle='-', color='green')\n",
    "ax.plot(accuracies[2], label='SNN Conv', marker='o', linestyle='-', color='red')\n",
    "\n",
    "# 평균값 플롯\n",
    "ax.axhline(y=average_ANN_conv, color='blue', linestyle='--', label=f'Average ANN Conv: {average_ANN_conv:.3f}')\n",
    "ax.axhline(y=average_SNN_fc, color='green', linestyle='--', label=f'Average SNN FC: {average_SNN_fc:.3f}')\n",
    "ax.axhline(y=average_SNN_conv, color='red', linestyle='--', label=f'Average SNN Conv: {average_SNN_conv:.3f}')\n",
    "\n",
    "# 레이블 추가\n",
    "ax.set_xticks(np.arange(len(filename_for_plot)))\n",
    "ax.set_xticklabels(filename_for_plot, rotation=45, ha='right')\n",
    "ax.set_ylabel('Accuracy')\n",
    "ax.set_title('Accuracy Comparison of Models on Datasets')\n",
    "ax.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import matplotlib.pyplot as plt\n",
    "import os  # 파일 경로 처리를 위한 모듈\n",
    "\n",
    "# CSV 파일 경로\n",
    "# csv_file_path = \"/home/bhkim003/github_folder/ByeonghyeonKim/my_snn/ae_test_deprecated/250115/sweep0_vth_mul.csv\" # vth_mul해서 sweep 돌린거\n",
    "csv_file_path = \"/home/bhkim003/github_folder/ByeonghyeonKim/my_snn/ae_test_deprecated/250115/sweep1.csv\"  #vth_mul안한거\n",
    "\n",
    "# 결과를 저장할 리스트\n",
    "tuple_list = []\n",
    "\n",
    "# CSV 파일 읽기\n",
    "with open(csv_file_path, 'r') as file:\n",
    "    reader = csv.DictReader(file)\n",
    "    for row in reader:\n",
    "        try:\n",
    "            # v_threshold, TIME, v_reset, converted_k_means_acc 값을 가져와 튜플로 변환\n",
    "            v_threshold = float(row[\"v_threshold\"])\n",
    "            time = int(row[\"TIME\"])\n",
    "            v_reset = int(row[\"v_reset\"])\n",
    "            converted_k_means_acc = float(row[\"converted_k_means_acc\"]) if row[\"converted_k_means_acc\"] else None\n",
    "\n",
    "            # 튜플 형태로 추가 (값이 None일 경우 처리할 수도 있음)\n",
    "            tuple_list.append((v_threshold, time, v_reset, converted_k_means_acc))\n",
    "        except ValueError as e:\n",
    "            print(f\"Error processing row {row}: {e}\")\n",
    "\n",
    "# 데이터를 TIME 기준으로 정렬\n",
    "tuple_list.sort(key=lambda x: x[1])  # TIME을 기준으로 오름차순 정렬\n",
    "\n",
    "# reset 방식에 따라 데이터를 나누기\n",
    "soft_reset = [t for t in tuple_list if t[2] == 0]\n",
    "hard_reset = [t for t in tuple_list if t[2] == 10000]\n",
    "\n",
    "# reset 방식과 v_threshold에 따라 색상 설정\n",
    "def plot_data(data, label_prefix, marker):\n",
    "    for v_threshold in [1.0]:  # v_threshold 기준으로 제한\n",
    "        filtered_data = [(t[1], t[3]) for t in data if t[0] == v_threshold]\n",
    "        if filtered_data:  # 해당 v_threshold 데이터가 있을 경우만 플롯\n",
    "            times, accuracies = zip(*filtered_data)  # x축(TIME), y축(converted_k_means_acc)\n",
    "            \n",
    "            plt.plot(\n",
    "                times,\n",
    "                accuracies,\n",
    "                marker,\n",
    "                label=f\"{label_prefix}, v_threshold={v_threshold}\",\n",
    "                linestyle=\"--\",\n",
    "            )\n",
    "            # 각 점에 accuracy 표시\n",
    "            for time, acc in filtered_data:\n",
    "                if acc == None:\n",
    "                    continue\n",
    "                plt.text(time, acc, f\"{acc:.2f}\", fontsize=8, ha=\"right\")\n",
    "\n",
    "# 그래프 초기화\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "# soft_reset (v_reset=0) 데이터 플롯\n",
    "plot_data(soft_reset, \"Soft Reset\", \"o\")\n",
    "\n",
    "# hard_reset (v_reset=10000) 데이터 플롯\n",
    "plot_data(hard_reset, \"Hard Reset\", \"x\")\n",
    "\n",
    "# baseline accuracy 가로선 추가\n",
    "baseline_accuracy = 94.43\n",
    "plt.axhline(y=baseline_accuracy, color=\"red\", linestyle=\"-\", label=f\"Baseline Accuracy ({baseline_accuracy}%)\")\n",
    "# baseline 텍스트 추가\n",
    "plt.text(\n",
    "    2000,  # x축 위치 (그래프 오른쪽 끝)\n",
    "    baseline_accuracy + 0.4,  # y축 위치 (baseline 위 약간)\n",
    "    f\"ANN Baseline ({baseline_accuracy}%)\",\n",
    "    color=\"red\",\n",
    "    fontsize=10,\n",
    "    ha=\"center\",\n",
    ")\n",
    "\n",
    "# CSV 파일 이름 가져오기\n",
    "csv_file_name = os.path.basename(csv_file_path)\n",
    "\n",
    "# 그래프 세부 설정\n",
    "plt.title(f\"Converted SNN K-Means Accuracy vs TIME STEP - {csv_file_name}\")\n",
    "plt.xlabel(\"TIME STEP\")\n",
    "plt.ylabel(\"Converted K-Means Accuracy [%]\")\n",
    "plt.legend(loc=\"lower right\")  # 범례를 오른쪽 아래로 이동\n",
    "plt.grid(True)\n",
    "\n",
    "# 그래프 출력\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aedat2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
