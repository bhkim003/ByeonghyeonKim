{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ssp.train.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x600 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import torch   \n",
    "import torch.nn as nn \n",
    "import torch.nn.functional as F   \n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import torch.optim as optim\n",
    "from scipy import io\n",
    "import itertools\n",
    "import math\n",
    "import datetime\n",
    "import wandb\n",
    "import pickle\n",
    "import json\n",
    "import time\n",
    "import sys\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import accuracy_score\n",
    "from scipy.optimize import linear_sum_assignment\n",
    "from snntorch import spikegen\n",
    "\n",
    "\n",
    "# my module import\n",
    "from modules import *\n",
    "\n",
    "# modules 폴더에 새모듈.py 만들면\n",
    "# modules/__init__py 파일에 form .새모듈 import * 하셈\n",
    "# 그리고 새모듈.py에서 from modules.새모듈 import * 하셈"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cluster_train_system( \n",
    "    gpu = '4',\n",
    "    Conv_net = True,\n",
    "    SAE_net = True,\n",
    "\n",
    "    # hyperparameter\n",
    "    dataset_num = 16,\n",
    "    spike_length = 50,\n",
    "    num_cluster = 4,  # 클러스터 수 설정 # 논문엔 4개라는데 여기서는 3개로 했네\n",
    "    training_cycle = 2400, # 그 초기 몇개까지만 cluster update할지\n",
    "\n",
    "\n",
    "    batch_size = 32,\n",
    "    max_epoch = 7000,\n",
    "    learning_rate = 0.001,\n",
    "    normalize_on = False, # True or False #이거 안 씀 # 이거 별로 안 좋은 normalize같음 # 쓸 거면 다른 거 써라.\n",
    "    need_bias = False,\n",
    "    # first_layer_no_train = False\n",
    "    lif_add_at_first = False,\n",
    "    my_seed = 42,\n",
    "\n",
    "    TIME = 10, # SAE일 때만 유효\n",
    "    v_decay = 0.5,\n",
    "    v_threshold = 0.5,\n",
    "    v_reset = 10000.0, # 10000이상 일 시 hard reset\n",
    "    BPTT_on = True,\n",
    "\n",
    "    SAE_hidden_nomean = True,\n",
    "    current_time = '20250101_210938_786',\n",
    "\n",
    "    optimizer = 'Adam',\n",
    "    coarse_com_mode = True,\n",
    "    coarse_com_config = (2.0, -2.0), # (max, min)\n",
    "\n",
    "    sae_l2_norm_bridge = True,\n",
    "    sae_lif_bridge = False,\n",
    "\n",
    "    accuracy_check_epoch_term = 5,\n",
    "    \n",
    "    lif_add_at_last = False,\n",
    "\n",
    "    two_channel_input = False,\n",
    "\n",
    "    lateral_feature_num = 4,\n",
    "\n",
    "    lc_adc_on = False, \n",
    "\n",
    "    converted_net_forward = False,\n",
    "\n",
    "    pretrained_net = None, \n",
    "\n",
    "    vth_mul_on = False,\n",
    "    batch_norm_on = False,\n",
    "\n",
    "    l2_norm_loss_weight = 0.0,\n",
    "\n",
    "    QCFS_neuron_on = False,\n",
    "\n",
    "    quantize_level_num = 0,\n",
    "\n",
    "    fusion_net = False, # True False\n",
    "    repeat_coding = False,\n",
    "    \n",
    "    sae_relu_on = False,\n",
    "\n",
    "    conv1d_scaling = False,\n",
    "\n",
    "    norm01 = True,\n",
    "    ):\n",
    "    if coarse_com_mode == True:\n",
    "        assert coarse_com_config[0] > coarse_com_config[1], 'coarse_com_config[0] > coarse_com_config[1]이어야 함'\n",
    "        assert converted_net_forward == False\n",
    "        # assert SAE_net == True, 'coarse_com_mode는 SAE_net이 True일 때만 가능'\n",
    "    if two_channel_input == True:\n",
    "        assert Conv_net and coarse_com_mode, 'two_channel_input는 Conv_net이 True일 때만 가능'\n",
    "    if lc_adc_on == True:\n",
    "        assert coarse_com_mode and SAE_net, 'lc_adc_on은 coarse_com_mode와 SAE_net이 True일 때만 가능'\n",
    "    if converted_net_forward == True:\n",
    "        assert SAE_net == False, 'converted_net_forward는 SAE_net이 False일 때만 가능'\n",
    "    if conv1d_scaling:\n",
    "        assert Conv_net and coarse_com_mode and normalize_on\n",
    "    seed_assign(my_seed)\n",
    "    ## 함수 내 모든 로컬 변수 저장 ########################################################\n",
    "    hyperparameters = locals()\n",
    "    print(hyperparameters)\n",
    "    # JSON으로 저장\n",
    "    with open(f\"result_save/cluster_accuracy_history_{current_time}.json\", 'w') as f:\n",
    "        json.dump(hyperparameters, f, indent=4)\n",
    "    ######################################################################################\n",
    "\n",
    "    \n",
    "    wandb.config.update(hyperparameters)\n",
    "    wandb.run.name = f'{current_time}_SAE_net_{SAE_net}_v_threshold_{v_threshold}'\n",
    "    wandb.define_metric(\"best_mean_cluster_accuracy_post_training_cycle_all_dataset2\", summary=\"max\")\n",
    "\n",
    "\n",
    "    my_path_ground_BH = '/data2/spike_sorting/quiroga/BH/'\n",
    "\n",
    "\n",
    "    filename = [\"C_Easy1_noise005.mat\", \"C_Easy1_noise01.mat\", \"C_Easy1_noise015.mat\", \"C_Easy1_noise02.mat\",\n",
    "                \"C_Easy2_noise005.mat\", \"C_Easy2_noise01.mat\", \"C_Easy2_noise015.mat\", \"C_Easy2_noise02.mat\",\n",
    "                \"C_Difficult1_noise005.mat\", \"C_Difficult1_noise01.mat\", \"C_Difficult1_noise015.mat\", \"C_Difficult1_noise02.mat\",\n",
    "                \"C_Difficult2_noise005.mat\", \"C_Difficult2_noise01.mat\", \"C_Difficult2_noise015.mat\", \"C_Difficult2_noise02.mat\"]\n",
    "\n",
    "\n",
    "    spike_tot = [\"BH_Spike_e1n005.npy\", \"BH_Spike_e1n010.npy\", \"BH_Spike_e1n015.npy\", \"BH_Spike_e1n020.npy\",\n",
    "                \"BH_Spike_e2n005.npy\", \"BH_Spike_e2n010.npy\", \"BH_Spike_e2n015.npy\", \"BH_Spike_e2n020.npy\",\n",
    "                \"BH_Spike_d1n005.npy\", \"BH_Spike_d1n010.npy\", \"BH_Spike_d1n015.npy\", \"BH_Spike_d1n020.npy\",\n",
    "                \"BH_Spike_d2n005.npy\", \"BH_Spike_d2n010.npy\", \"BH_Spike_d2n015.npy\", \"BH_Spike_d2n020.npy\"]\n",
    "\n",
    "    label_tot = [\"BH_Label_e1n005.npy\", \"BH_Label_e1n010.npy\", \"BH_Label_e1n015.npy\", \"BH_Label_e1n020.npy\",\n",
    "                \"BH_Label_e2n005.npy\", \"BH_Label_e2n010.npy\", \"BH_Label_e2n015.npy\", \"BH_Label_e2n020.npy\",\n",
    "                \"BH_Label_d1n005.npy\", \"BH_Label_d1n010.npy\", \"BH_Label_d1n015.npy\", \"BH_Label_d1n020.npy\",\n",
    "                \"BH_Label_d2n005.npy\", \"BH_Label_d2n010.npy\", \"BH_Label_d2n015.npy\", \"BH_Label_d2n020.npy\"]\n",
    "\n",
    "    template =  [\"BH_Spike_TEMPLATE_e1n005.npy\", \"BH_Spike_TEMPLATE_e1n010.npy\", \"BH_Spike_TEMPLATE_e1n015.npy\", \"BH_Spike_TEMPLATE_e1n020.npy\",\n",
    "                \"BH_Spike_TEMPLATE_e2n005.npy\", \"BH_Spike_TEMPLATE_e2n010.npy\", \"BH_Spike_TEMPLATE_e2n015.npy\", \"BH_Spike_TEMPLATE_e2n020.npy\",\n",
    "                \"BH_Spike_TEMPLATE_d1n005.npy\", \"BH_Spike_TEMPLATE_d1n010.npy\", \"BH_Spike_TEMPLATE_d1n015.npy\", \"BH_Spike_TEMPLATE_d1n020.npy\",\n",
    "                \"BH_Spike_TEMPLATE_d2n005.npy\", \"BH_Spike_TEMPLATE_d2n010.npy\", \"BH_Spike_TEMPLATE_d2n015.npy\", \"BH_Spike_TEMPLATE_d2n020.npy\"]\n",
    "\n",
    "    AE_train_path_gt_detect = 'BH_quiroga_training_dataset_gt_detect.pt' \n",
    "    AE_test_path_gt_detect = 'BH_quiroga_test_dataset_gt_detect.pt'\n",
    "\n",
    "    AE_train_path_real_detect = 'BH_quiroga_training_dataset_real_detect.pt'\n",
    "    AE_test_path_real_detect = 'BH_quiroga_test_dataset_real_detect.pt'\n",
    "\n",
    "    AE_train_data = AE_train_path_real_detect #AE_train_path_gt_detect #AE_train_path_real_detect\n",
    "    AE_test_data = AE_test_path_real_detect #AE_test_path_gt_detect  #AE_test_path_real_detect\n",
    "\n",
    "    # thr_tot = np.array([0.5, 0.5, 0.55, 0.7, 0.5, 0.5, 0.55, 0.7, 0.5, 0.5, 0.55, 0.7, 0.5, 0.5, 0.55, 0.7])\n",
    "    cos_thr = np.array([0.95, 0.95, 0.95, 0.95, 0.95, 0.95, 0.95, 0.85, 0.95, 0.9, 0.8, 0.95, 0.95, 0.95, 0.95, 0.8])\n",
    "    # tem=10\n",
    "    # cos_thr = np.array([tem, tem, tem, tem, tem, tem, tem, tem, tem, tem, tem, tem, tem, tem, tem, tem, ])\n",
    "\n",
    "    print('cos_thr', cos_thr)\n",
    "    \n",
    "    os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\" \n",
    "    os.environ[\"CUDA_VISIBLE_DEVICES\"]= gpu\n",
    "\n",
    "\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "\n",
    "    if coarse_com_mode == True:\n",
    "        level_num = TIME\n",
    "        TIME = spike_length\n",
    "        spike_length = level_num\n",
    "        level_interval = (coarse_com_config[0] - coarse_com_config[1]) / (level_num-1)  # max - min\n",
    "        levels = [coarse_com_config[1] + level_interval * i for i in range(level_num)]\n",
    "        levels = torch.tensor(levels).to(torch.float).to(device)\n",
    "        levels = levels.repeat(TIME,1) \n",
    "        # print('levels', levels, levels.shape) # TIME, level_num\n",
    "\n",
    "    n_sample = spike_length\n",
    "\n",
    "    class spikedataset(Dataset):\n",
    "        def __init__(self, path, transform = None):    \n",
    "            self.transform = transform\n",
    "            self.spike = torch.load(path)\n",
    "            \n",
    "        def __getitem__(self, index):\n",
    "            spike = self.spike[index]            \n",
    "            if self.transform is not None:\n",
    "                spike = self.transform(spike)\n",
    "            return spike\n",
    "        \n",
    "        def __len__(self):\n",
    "            return len(self.spike)\n",
    "\n",
    "    train_dataset = spikedataset(my_path_ground_BH + AE_train_data)\n",
    "    train_loader = DataLoader(dataset = train_dataset, batch_size = batch_size, shuffle = True)\n",
    "\n",
    "    test_dataset = spikedataset(my_path_ground_BH + AE_test_data)\n",
    "    test_loader = DataLoader(dataset = test_dataset, batch_size = batch_size, shuffle = False)\n",
    "\n",
    "\n",
    "    # vth_mul_on = True # True False\n",
    "    # batch_norm_on = True # True False\n",
    "\n",
    "\n",
    "    # 모델 초기화\n",
    "    if SAE_net == False: # 여기서는 l2norm, lif bridge 둘 다 true면 l2norm먼저\n",
    "        assert two_channel_input == False\n",
    "\n",
    "        if Conv_net == True:\n",
    "            # input_channels = 2 if two_channel_input else 1\n",
    "            input_channels = TIME if coarse_com_mode else 1\n",
    "            if fusion_net == True:\n",
    "                assert False, '이거 맞음? 다시 확인'\n",
    "                net = FUSION_net_conv1(input_channels=input_channels, input_length=n_sample, encoder_ch = [32, 64, 96], fc_dim = lateral_feature_num, padding = 0, stride = 2, kernel_size = 3, \n",
    "                                    synapse_fc_trace_const1=1, \n",
    "                                    synapse_fc_trace_const2=v_decay, #안씀 \n",
    "                                    TIME=TIME, v_init=0.0, v_decay=v_decay, v_threshold=v_threshold, v_reset=v_reset, \n",
    "                                    sg_width=4.0, surrogate='sigmoid', BPTT_on=BPTT_on, need_bias=need_bias, lif_add_at_first=lif_add_at_first,\n",
    "                                    sae_l2_norm_bridge = sae_l2_norm_bridge, sae_lif_bridge = sae_lif_bridge, lif_add_at_last=lif_add_at_last, repeat_coding=repeat_coding).to(device)\n",
    "            else: \n",
    "                net = Autoencoder_conv1(input_channels=input_channels, input_length=n_sample, encoder_ch = [32, 64, 96], fc_dim = lateral_feature_num, padding = 0, stride = 2, kernel_size = 3, need_bias=need_bias, l2norm_bridge=sae_l2_norm_bridge, relu_bridge=sae_lif_bridge, activation_collector_on=False,\n",
    "                                        batch_norm_on=batch_norm_on, QCFS_neuron_on=QCFS_neuron_on).to(device)\n",
    "            net = torch.nn.DataParallel(net)\n",
    "            if converted_net_forward:\n",
    "                converted_net = SAE_converted_conv1(input_channels=input_channels, input_length=n_sample, encoder_ch = [32, 64, 96], fc_dim = lateral_feature_num, padding = 0, stride = 2, kernel_size = 3, \n",
    "                                    synapse_fc_trace_const1=1, \n",
    "                                    synapse_fc_trace_const2=v_decay, #안씀 \n",
    "                                    TIME=TIME, v_init=0.0, v_decay=v_decay, v_threshold=v_threshold, v_reset=v_reset, \n",
    "                                    sg_width=4.0, surrogate='sigmoid', BPTT_on=BPTT_on, need_bias=need_bias, lif_add_at_first=lif_add_at_first,\n",
    "                                    sae_l2_norm_bridge = sae_l2_norm_bridge, sae_lif_bridge = sae_lif_bridge, lif_add_at_last=lif_add_at_last,\n",
    "                                    vth_mul_on=vth_mul_on, batch_norm_on=batch_norm_on).to(device) # lif bridge는 무조건 들어가게 해놨음.\n",
    "                converted_net = torch.nn.DataParallel(converted_net)\n",
    "                print('converted_net', converted_net)\n",
    "        else:\n",
    "            n_sample = n_sample * TIME if coarse_com_mode else n_sample\n",
    "            net = Autoencoder_only_FC(encoder_ch=[400, lateral_feature_num], decoder_ch=[400,n_sample], n_sample=n_sample, need_bias=need_bias, l2norm_bridge=sae_l2_norm_bridge, relu_bridge=sae_lif_bridge, activation_collector_on=False,\n",
    "                                    batch_norm_on=batch_norm_on, QCFS_neuron_on=QCFS_neuron_on).to(device)\n",
    "            net = torch.nn.DataParallel(net)\n",
    "            if converted_net_forward:\n",
    "                converted_net = SAE_converted_fc(encoder_ch=[400, lateral_feature_num], \n",
    "                                    decoder_ch=[400, n_sample], \n",
    "                                    in_channels=n_sample, # in_channel 이 여기선 걍 lenght.\n",
    "                                    synapse_fc_trace_const1=1,\n",
    "                                    synapse_fc_trace_const2=v_decay,  #안씀 \n",
    "                                    TIME=TIME, v_init=0.0, v_decay=v_decay, v_threshold=v_threshold, v_reset=v_reset, \n",
    "                                    sg_width=4.0, surrogate='sigmoid', BPTT_on=BPTT_on, need_bias=need_bias, lif_add_at_first=lif_add_at_first,\n",
    "                                    sae_l2_norm_bridge = sae_l2_norm_bridge, sae_lif_bridge = sae_lif_bridge, lif_add_at_last=lif_add_at_last,\n",
    "                                    vth_mul_on=vth_mul_on, batch_norm_on=batch_norm_on).to(device) # lif bridge는 무조건 들어가게 해놨음.\n",
    "                converted_net = torch.nn.DataParallel(converted_net)\n",
    "                # print('converted_net', converted_net)\n",
    "    else:\n",
    "        if Conv_net == True: \n",
    "            input_channels = 1\n",
    "            input_channels = 2 if two_channel_input else 1\n",
    "            if fusion_net == True:  \n",
    "                assert coarse_com_mode == True\n",
    "                # net = SAE_FUSION2_net_conv1(input_channels=input_channels, input_length=n_sample, encoder_ch = [32, 64, 96], fc_dim = lateral_feature_num, padding = 0, stride = 2, kernel_size = 3, \n",
    "                #                     synapse_fc_trace_const1=1, \n",
    "                #                     synapse_fc_trace_const2=v_decay, #안씀 \n",
    "                #                     TIME=TIME, v_init=0.0, v_decay=v_decay, v_threshold=v_threshold, v_reset=v_reset, \n",
    "                #                     sg_width=4.0, surrogate='sigmoid', BPTT_on=BPTT_on, need_bias=need_bias, lif_add_at_first=lif_add_at_first,\n",
    "                #                     sae_l2_norm_bridge = sae_l2_norm_bridge, sae_lif_bridge = sae_lif_bridge, lif_add_at_last=lif_add_at_last, batch_norm_on=batch_norm_on, sae_relu_on=sae_relu_on).to(device)\n",
    "                # net = SAE_FUSION3_net_conv1(input_channels=input_channels, input_length=n_sample, encoder_ch = [32, 64, 96], fc_dim = lateral_feature_num, padding = 0, stride = 2, kernel_size = 3, \n",
    "                #                     synapse_fc_trace_const1=1, \n",
    "                #                     synapse_fc_trace_const2=v_decay, #안씀 \n",
    "                #                     TIME=TIME, v_init=0.0, v_decay=v_decay, v_threshold=v_threshold, v_reset=v_reset, \n",
    "                #                     sg_width=4.0, surrogate='sigmoid', BPTT_on=BPTT_on, need_bias=need_bias, lif_add_at_first=lif_add_at_first,\n",
    "                #                     sae_l2_norm_bridge = sae_l2_norm_bridge, sae_lif_bridge = sae_lif_bridge, lif_add_at_last=lif_add_at_last, batch_norm_on=batch_norm_on, sae_relu_on=sae_relu_on).to(device)\n",
    "                # net = SAE_FUSION4_net_conv1(input_channels=input_channels, input_length=n_sample, encoder_ch = [32, 64, 96], fc_dim = lateral_feature_num, padding = 0, stride = 2, kernel_size = 3, \n",
    "                #                     synapse_fc_trace_const1=1, \n",
    "                #                     synapse_fc_trace_const2=v_decay, #안씀 \n",
    "                #                     TIME=TIME, v_init=0.0, v_decay=v_decay, v_threshold=v_threshold, v_reset=v_reset, \n",
    "                #                     sg_width=4.0, surrogate='sigmoid', BPTT_on=BPTT_on, need_bias=need_bias, lif_add_at_first=lif_add_at_first,\n",
    "                #                     sae_l2_norm_bridge = sae_l2_norm_bridge, sae_lif_bridge = sae_lif_bridge, lif_add_at_last=lif_add_at_last, batch_norm_on=batch_norm_on, sae_relu_on=sae_relu_on).to(device)\n",
    "                # net = SAE_FUSION5_net_conv1(input_channels=input_channels, input_length=n_sample, encoder_ch = [32, 64, 96], fc_dim = lateral_feature_num, padding = 0, stride = 2, kernel_size = 3, \n",
    "                #                     synapse_fc_trace_const1=1, \n",
    "                #                     synapse_fc_trace_const2=v_decay, #안씀 \n",
    "                #                     TIME=TIME, v_init=0.0, v_decay=v_decay, v_threshold=v_threshold, v_reset=v_reset, \n",
    "                #                     sg_width=4.0, surrogate='sigmoid', BPTT_on=BPTT_on, need_bias=need_bias, lif_add_at_first=lif_add_at_first,\n",
    "                #                     sae_l2_norm_bridge = sae_l2_norm_bridge, sae_lif_bridge = sae_lif_bridge, lif_add_at_last=lif_add_at_last, batch_norm_on=batch_norm_on, sae_relu_on=sae_relu_on).to(device)\n",
    "                net = SAE_FUSION6_net_conv1(input_channels=input_channels, input_length=n_sample, encoder_ch = [32, 64, 96], fc_dim = lateral_feature_num, padding = 0, stride = 2, kernel_size = 3, \n",
    "                                    synapse_fc_trace_const1=1, \n",
    "                                    synapse_fc_trace_const2=v_decay, #안씀 \n",
    "                                    TIME=TIME, v_init=0.0, v_decay=v_decay, v_threshold=v_threshold, v_reset=v_reset, \n",
    "                                    sg_width=4.0, surrogate='sigmoid', BPTT_on=BPTT_on, need_bias=need_bias, lif_add_at_first=lif_add_at_first,\n",
    "                                    sae_l2_norm_bridge = sae_l2_norm_bridge, sae_lif_bridge = sae_lif_bridge, lif_add_at_last=lif_add_at_last, batch_norm_on=batch_norm_on, sae_relu_on=sae_relu_on).to(device)\n",
    "            else:\n",
    "                net = SAE_conv1(input_channels=input_channels, input_length=n_sample, encoder_ch = [32, 64, 96], fc_dim = lateral_feature_num, padding = 0, stride = 2, kernel_size = 3, \n",
    "                                    synapse_fc_trace_const1=1, \n",
    "                                    synapse_fc_trace_const2=v_decay, #안씀 \n",
    "                                    TIME=TIME, v_init=0.0, v_decay=v_decay, v_threshold=v_threshold, v_reset=v_reset, \n",
    "                                    sg_width=4.0, surrogate='sigmoid', BPTT_on=BPTT_on, need_bias=need_bias, lif_add_at_first=lif_add_at_first,\n",
    "                                    sae_l2_norm_bridge = sae_l2_norm_bridge, sae_lif_bridge = sae_lif_bridge, lif_add_at_last=lif_add_at_last, batch_norm_on=batch_norm_on, sae_relu_on=sae_relu_on).to(device)\n",
    "            # net = SAE_conv1_DR(input_channels=input_channels, input_length=n_sample, encoder_ch = [32, 64, 96], fc_dim = lateral_feature_num, padding = 0, stride = 2, kernel_size = 3, \n",
    "            #                     synapse_fc_trace_const1=1, \n",
    "            #                     synapse_fc_trace_const2=v_decay, #안씀 \n",
    "            #                     TIME=TIME, v_init=0.0, v_decay=v_decay, v_threshold=v_threshold, v_reset=v_reset, \n",
    "            #                     sg_width=4.0, surrogate='sigmoid', BPTT_on=BPTT_on, need_bias=need_bias, lif_add_at_first=lif_add_at_first,\n",
    "            #                     sae_l2_norm_bridge = sae_l2_norm_bridge, sae_lif_bridge = sae_lif_bridge, lif_add_at_last=lif_add_at_last, batch_norm_on=batch_norm_on).to(device)\n",
    "            net = torch.nn.DataParallel(net)\n",
    "        else:\n",
    "            net = SAE_fc_only(encoder_ch=[400, lateral_feature_num], \n",
    "                                decoder_ch=[400, n_sample], \n",
    "                                in_channels=n_sample, # in_channel 이 여기선 걍 lenght.\n",
    "                                synapse_fc_trace_const1=1,\n",
    "                                synapse_fc_trace_const2=v_decay,  #안씀 \n",
    "                                TIME=TIME, v_init=0.0, v_decay=v_decay, v_threshold=v_threshold, v_reset=v_reset, \n",
    "                                sg_width=4.0, surrogate='sigmoid', BPTT_on=BPTT_on, need_bias=need_bias, lif_add_at_first=lif_add_at_first,\n",
    "                                sae_l2_norm_bridge = sae_l2_norm_bridge, sae_lif_bridge = sae_lif_bridge, lif_add_at_last=lif_add_at_last, batch_norm_on=batch_norm_on, sae_relu_on=sae_relu_on).to(device)\n",
    "            net = torch.nn.DataParallel(net)\n",
    "\n",
    "    # net = torch.load('/home/bhkim003/github_folder/ByeonghyeonKim/my_snn/net_save/save_now_net_AE_re_e7000.pth')\n",
    "    # net = torch.load('/home/bhkim003/github_folder/ByeonghyeonKim/my_snn/net_save/save_now_net_20250101_210938_786.pth')\n",
    "    # load했으면 torch.nn.DataParallel 하지마\n",
    "    # net.module.load_state_dict(torch.load('/home/bhkim003/github_folder/ByeonghyeonKim/my_snn/net_save/save_now_net_annbase_20250108_210641_941.pth'))\n",
    "    if pretrained_net != None:\n",
    "        ######################## 모델이 달라서 dict로 weight만 넣고싶을 때\n",
    "        # # 저장된 가중치 로드\n",
    "        saved_state_dict = torch.load(pretrained_net)\n",
    "        current_state_dict = net.module.state_dict()\n",
    "\n",
    "        # 함수 호출로 가중치 매핑\n",
    "        updated_state_dict = map_and_load_weights(saved_state_dict, current_state_dict)\n",
    "\n",
    "        # 업데이트된 state_dict를 네트워크에 로드\n",
    "        net.module.load_state_dict(updated_state_dict)\n",
    "        ######################## 모델이 달라서 dict로 weight만 넣고싶을 때\n",
    "\n",
    "        ############## 일반적일 때\n",
    "        # net.module.load_state_dict(torch.load(pretrained_net))\n",
    "        ############## 일반적일 때\n",
    "    \n",
    "        # pre_net = Autoencoder_conv1(input_channels=input_channels, input_length=n_sample, encoder_ch = [32, 64, 96], fc_dim = lateral_feature_num, padding = 0, stride = 2, kernel_size = 3, need_bias=need_bias, l2norm_bridge=sae_l2_norm_bridge, relu_bridge=sae_lif_bridge, activation_collector_on=False,\n",
    "        #                         batch_norm_on=batch_norm_on, QCFS_neuron_on=False).to(device)\n",
    "        # pre_net = torch.nn.DataParallel(net)\n",
    "        # pre_net.module.load_state_dict(torch.load(pretrained_net))\n",
    "        # copy_weights(pre_net.module.encoder , net.module.encoder )\n",
    "        # copy_weights(pre_net.module.decoder , net.module.decoder  )\n",
    "\n",
    "        \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    wandb.watch(net, log=\"all\", log_freq = 10)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    if SAE_net == True:\n",
    "        assert 'SAE' in net.module.__class__.__name__\n",
    "\n",
    "\n",
    "\n",
    "    net = net.to(device)\n",
    "    print(f\"Total number of encoder parameters: {sum(p.numel() for p in net.module.encoder.parameters())}\")\n",
    "    print(net)\n",
    "    print('Device:',device)\n",
    "\n",
    "    \n",
    "    if optimizer == 'Adam':\n",
    "        optimizer = optim.Adam(net.parameters(), lr=learning_rate)\n",
    "    elif optimizer == 'SGD':\n",
    "        optimizer = optim.SGD(net.parameters(), lr = learning_rate, momentum = 0.9)\n",
    "    else:\n",
    "        assert False, 'optimizer를 잘못 입력했습니다.'\n",
    "        \n",
    "    loss_history = []\n",
    "    mean_cluster_accuracy_during_training_cycle_all_dataset_history = []\n",
    "    mean_cluster_accuracy_post_training_cycle_all_dataset_history = []\n",
    "    mean_cluster_accuracy_total_all_dataset_history = []\n",
    "\n",
    "    tau = np.zeros(num_cluster)\n",
    "\n",
    "    print(f\"\\nStart Training, current_time = {current_time}\")\n",
    "    mean_cluster_accuracy_post_training_cycle_all_dataset = 0\n",
    "    best_mean_cluster_accuracy_post_training_cycle_all_dataset = 0\n",
    "\n",
    "    if SAE_net == True:\n",
    "        assert 'SAE' in net.module.__class__.__name__\n",
    "        \n",
    "    k_means_acc_best = 0\n",
    "    min_loss = 9999999\n",
    "    min_loss_normal = 9999999\n",
    "    min_loss_coarse = 9999999\n",
    "    for epoch in range(max_epoch):\n",
    "        print()\n",
    "        l2_loss_bin= 0\n",
    "        ae_train_start_time = time.time()\n",
    "        running_loss = 0.0\n",
    "        running_loss_normal = 0.0\n",
    "        running_loss_coarse = 0.0\n",
    "        iter = 0\n",
    "        net.train()\n",
    "        # if True or max_epoch != 1:\n",
    "        wrong_element_sum = 0\n",
    "        same_data_num = 0\n",
    "        total_data_num = 0\n",
    "        if max_epoch != 1:\n",
    "            for data in train_loader:\n",
    "                optimizer.zero_grad()\n",
    "                total_data_num += len(data)\n",
    "                data = data.to(device)\n",
    "                scaling = (level_num-3)/level_num if conv1d_scaling else 1.0\n",
    "                data = zero_to_one_normalize_features(data, level_num=quantize_level_num, coarse_com_config=coarse_com_config, scaling=scaling, norm01=norm01) if normalize_on else data\n",
    "                # plot_origin_spike(data[0].cpu().detach().numpy(), min_max_y_on = True)\n",
    "                # plot_origin_spike(data[1].cpu().detach().numpy(), min_max_y_on = True)\n",
    "                spike_backup = data\n",
    "                spike = data\n",
    "                spike = spike.to(device) # batch, feature\n",
    "                spike_for_fusion2_net = spike\n",
    "                if coarse_com_mode == True and 'SAE' in net.module.__class__.__name__:\n",
    "                    # print(spike[0])\n",
    "                    spike = spike.unsqueeze(2).repeat(1, 1, level_num) # spike_length == level_num # (batch, time, feature)로 변환 \n",
    "                    spike = (spike > levels).to(torch.float) \n",
    "\n",
    "                    spike = (spike == 0).cumsum(dim=-1).eq(1).to(torch.float) if lc_adc_on == True else spike\n",
    "\n",
    "                    # spike: batch, time, level_num\n",
    "                    # levels: time, level_num\n",
    "                    if Conv_net == True:\n",
    "                        spike = spike.unsqueeze(-2) # batch, time, in_channel, feature or batch in_channel,feature\n",
    "                        if two_channel_input == True:\n",
    "                            spike_backup = spike_backup.to(device)\n",
    "                            spike_backup = spike_backup.unsqueeze(2).repeat(1, 1, level_num) # spike_length == level_num # (batch, time, feature)로 변환 \n",
    "                            spike_backup = (spike_backup <= levels).to(torch.float) \n",
    "                            spike_backup = (spike_backup == 1).cumsum(dim=-1).eq(1).to(torch.float) if lc_adc_on == True else spike_backup\n",
    "                            spike_backup = spike_backup.unsqueeze(-2)\n",
    "                            spike = torch.cat((spike, spike_backup), dim=-2)\n",
    "                    assert spike.shape[0] == batch_size and spike.shape[1] == TIME\n",
    "                elif 'SAE' in net.module.__class__.__name__:\n",
    "                    spike = spike.unsqueeze(-1).repeat(1, 1, TIME).permute(0,2,1) # (batch, time, feature)로 변환\n",
    "                    if Conv_net == True:\n",
    "                        spike = spike.unsqueeze(-2) # batch, time, in_channel, feature or batch in_channel,feature\n",
    "                else:\n",
    "                    if Conv_net == True:\n",
    "                        if coarse_com_mode == False:\n",
    "                            spike = spike.unsqueeze(-2) #batch in_channel,feature\n",
    "                        else:\n",
    "                            spike = spike.unsqueeze(2).repeat(1, 1, level_num) # spike_length == level_num # (batch, time, feature)로 변환 \n",
    "                            spike = (spike > levels).to(torch.float) \n",
    "\n",
    "                            spike = (spike == 0).cumsum(dim=-1).eq(1).to(torch.float) if lc_adc_on == True else spike\n",
    "\n",
    "                    else:\n",
    "                        if coarse_com_mode == False:\n",
    "                            pass\n",
    "                        else:\n",
    "                            spike = spike.unsqueeze(2).repeat(1, 1, level_num) # spike_length == level_num # (batch, time, feature)로 변환 \n",
    "                            spike = (spike > levels).to(torch.float) \n",
    "\n",
    "                            spike = (spike == 0).cumsum(dim=-1).eq(1).to(torch.float) if lc_adc_on == True else spike\n",
    "\n",
    "                            # spike: batch, time, feature\n",
    "                            spike = spike.reshape(spike.shape[0], -1)\n",
    "\n",
    "                    \n",
    "\n",
    "\n",
    "                    # if fusion_net == True:\n",
    "                    #     spike = spikegen.rate(spike, num_steps=TIME).transpose(0, 1)\n",
    "\n",
    "                # spike_class = net(spike) # batch, time, feature\n",
    "                encoded_spike = net.module.encoder(spike)\n",
    "                spike_class = net.module.decoder(encoded_spike)\n",
    "\n",
    "                # for i in range (2):\n",
    "                #     plot_spike(spike[i,:,0,:].cpu().numpy())\n",
    "                #     # plot_spike(spike[i,:,1,:].cpu().numpy())\n",
    "                #     plot_origin_spike(spike_class.squeeze()[i].cpu().detach().numpy(), min_max_y_on = True)\n",
    "                # assert False\n",
    "                        \n",
    "\n",
    "                loss = 0\n",
    "                loss_normal = torch.tensor(0.0)\n",
    "                loss_coarse = torch.tensor(0.0)\n",
    "                if coarse_com_mode == True and 'SAE' in net.module.__class__.__name__:\n",
    "                    criterion = nn.MSELoss().to(device)\n",
    "                    # loss1 = nn.MSELoss()(spike_class[..., 5:25], spike[..., 5:25])\n",
    "                    # loss2 = nn.MSELoss()(spike_class[..., 0:5], spike[..., 0:5])\n",
    "                    # loss3 = nn.MSELoss()(spike_class[..., 25:spike_length], spike[..., 25:spike_length])\n",
    "                    # loss = loss1 * 2.125 + (loss2 + loss3)/4\n",
    "\n",
    "                    # loss1 = nn.MSELoss()(spike_class[..., 5:25, :], spike[..., 5:25, :])\n",
    "                    # loss2 = nn.MSELoss()(spike_class[..., 0:5, :], spike[..., 0:5, :])\n",
    "                    # loss3 = nn.MSELoss()(spike_class[..., 25:spike_length, :], spike[..., 25:spike_length, :])\n",
    "                    # loss = loss1 * 2.125 + (loss2 + loss3)/4\n",
    "                    if fusion_net:\n",
    "                        # print('1', spike.shape) # batch, time, in_channel, feature [32, 50, 1, 50]\n",
    "                        \n",
    "                        # ### coarse에서 ann loss 만들기 ######\n",
    "                        # spike = spike.squeeze()\n",
    "                        # assert two_channel_input == False\n",
    "                        # zero_mask = (spike == 0)  # 0이 있는 위치\n",
    "                        # first_zero_idx = torch.where(zero_mask, torch.arange(spike.shape[-1]).to(device), spike.shape[-1]-1).min(dim=-1).values\n",
    "                        # spike = levels[0][first_zero_idx]\n",
    "                        # # plot_origin_spike(spike[0].cpu().detach().numpy())\n",
    "                        # ### coarse에서 ann loss 만들기 ######\n",
    "\n",
    "                        ### 그냥 원래 스파이크로 ann loss 만들기 ######\n",
    "                        spike = spike_for_fusion2_net\n",
    "                        ### 그냥 원래 스파이크로 ann loss 만들기 ######\n",
    "\n",
    "                        spike = spike.squeeze()\n",
    "                        spike_class = spike_class.squeeze()\n",
    "                        \n",
    "                        ### normal loss################\n",
    "                        # loss = criterion(spike_class, spike)\n",
    "                        ### normal loss################\n",
    "                        \n",
    "                        ### chan loss################\n",
    "                        loss1 = criterion(spike_class[..., 5:25], spike[..., 5:25])\n",
    "                        loss2 = criterion(spike_class[..., 0:5], spike[..., 0:5])\n",
    "                        loss3 = criterion(spike_class[..., 25:], spike[..., 25:])\n",
    "                        loss = loss1 * 2.125 + (loss2 + loss3)/4\n",
    "                        ### chan loss################\n",
    "\n",
    "\n",
    "                        # #########################################\n",
    "                        # # 손실 함수 정의 (예: MSELoss 사용)\n",
    "                        # criterion_joke = torch.nn.MSELoss(reduction='none')  # 개별 요소별 손실을 유지\n",
    "\n",
    "                        # # 손실 계산\n",
    "                        # loss1_joke = criterion_joke(spike_class[..., 5:25], spike[..., 5:25]).mean(dim=-1)  # (batch,)\n",
    "                        # loss2_joke = criterion_joke(spike_class[..., 0:5], spike[..., 0:5]).mean(dim=-1)    # (batch,)\n",
    "                        # loss3_joke = criterion_joke(spike_class[..., 25:], spike[..., 25:]).mean(dim=-1)    # (batch,)\n",
    "\n",
    "                        # # 주어진 가중치를 적용한 최종 손실\n",
    "                        # loss_joke = loss1_joke * 2.125 + (loss2_joke + loss3_joke) / 4  # (batch,)\n",
    "\n",
    "                        # # 가장 큰 손실을 갖는 샘플의 인덱스 찾기\n",
    "                        # max_loss_idx_joke = torch.argmax(loss_joke)\n",
    "\n",
    "                        # # 해당 샘플 선택\n",
    "                        # selected_sample_class = spike_class[max_loss_idx_joke]\n",
    "                        # selected_sample_spike = spike[max_loss_idx_joke]\n",
    "\n",
    "                        # # 선택한 샘플의 손실 값 출력\n",
    "                        # print(\"Index of max loss sample:\", max_loss_idx_joke.item())\n",
    "                        # print(\"Max loss value:\", loss_joke[max_loss_idx_joke].item())\n",
    "                        # mean_loss_joke = loss_joke.mean().item()\n",
    "                        # print(\"Mean loss across the batch:\", mean_loss_joke)\n",
    "\n",
    "                        # # 선택한 샘플을 시각화\n",
    "                        # plot_origin_spike(selected_sample_class.cpu().detach().numpy())\n",
    "                        # plot_origin_spike(selected_sample_spike.cpu().detach().numpy())\n",
    "                        # #########################################\n",
    "\n",
    "                        # coarse loss ######################################################\n",
    "                        loss_normal = criterion(spike_class, spike)\n",
    "                        level_num_in_loss = spike_length\n",
    "                        level_interval = (coarse_com_config[0] - coarse_com_config[1]) / (level_num_in_loss-1)  # max - min\n",
    "                        levels = [coarse_com_config[1] + level_interval * i for i in range(level_num_in_loss)]\n",
    "                        levels = torch.tensor(levels).to(torch.float).to(device)\n",
    "                        # print('coarse leves', levels)\n",
    "                        levels = levels.repeat(spike_length,1) \n",
    "\n",
    "                        spike = spike.squeeze()\n",
    "                        spike_class = spike_class.squeeze()\n",
    "                        # plot_origin_spike(spike_class[0].cpu().detach().numpy())\n",
    "                        spike = spike.unsqueeze(2).repeat(1, 1, level_num_in_loss) \n",
    "                        spike = (spike > levels).to(torch.float) \n",
    "                        spike_class = spike_class.unsqueeze(2).repeat(1, 1, level_num_in_loss) \n",
    "                        spike_class = (spike_class > levels).to(torch.float) \n",
    "                        # spike = spike[..., 0:-3, :]\n",
    "                        # spike_class = spike_class[..., 0:-3, :]\n",
    "                        loss_coarse = criterion(spike_class, spike)\n",
    "                        wrong_element_sum += torch.sum(torch.abs(spike - spike_class)).item() \n",
    "\n",
    "                        # plot_spike(spike_class[0].cpu().detach().numpy())\n",
    "                        # assert False\n",
    "                        # coarse loss ######################################################\n",
    "                    else:\n",
    "                        spike = spike.squeeze()\n",
    "                        spike_class = spike_class.squeeze()\n",
    "                        loss = criterion(spike_class, spike)\n",
    "\n",
    "                    for iii in range(spike.shape[0]):\n",
    "                        same_data_num = same_data_num + 1 if torch.eq(spike[iii], spike_class[iii]).all() else same_data_num\n",
    "                    wrong_element_sum += torch.sum(torch.abs(spike - spike_class)).item() \n",
    "\n",
    "                    # spike = spike.squeeze()\n",
    "                    # spike_class = spike_class.squeeze()\n",
    "                    # plot_spike(spike[0].cpu().detach().numpy())\n",
    "                    # plot_spike(spike_class[0].cpu().detach().numpy())\n",
    "                    # print('손실 절대값 합',np.sum(np.abs(spike[0].cpu().detach().numpy() - spike_class[0].cpu().detach().numpy())))\n",
    "                    # # assert False\n",
    "                elif 'SAE' in net.module.__class__.__name__:\n",
    "                    criterion = nn.MSELoss().to(device)\n",
    "                    loss1 = criterion(spike_class[..., 5:25], spike[..., 5:25])\n",
    "                    loss2 = criterion(spike_class[..., 0:5], spike[..., 0:5])\n",
    "                    loss3 = criterion(spike_class[..., 25:spike_length], spike[..., 25:spike_length])\n",
    "                    loss = loss1 * 2.125 + (loss2 + loss3)/4\n",
    "                    assert spike_length > 25, 'spike_length가 25보다 작음'\n",
    "                    # wrong_element_sum += torch.sum(torch.abs(spike - spike_class)).item() \n",
    "                else:\n",
    "                    criterion = nn.MSELoss().to(device)\n",
    "                    loss1 = criterion(spike_class[..., 5:25], spike[..., 5:25])\n",
    "                    loss2 = criterion(spike_class[..., 0:5], spike[..., 0:5])\n",
    "                    loss3 = criterion(spike_class[..., 25:spike_length], spike[..., 25:spike_length])\n",
    "                    loss = loss1 * 2.125 + (loss2 + loss3)/4\n",
    "                    assert spike_length > 25, 'spike_length가 25보다 작음'\n",
    "                    # wrong_element_sum += torch.sum(torch.abs(spike - spike_class)).item() \n",
    "\n",
    "\n",
    "                    if l2_norm_loss_weight > 0:\n",
    "                        assert len(encoded_spike.shape) == 2, 'time 성분 없는 걸로'\n",
    "                        l2_loss = l2_norm_loss(encoded_spike, target_norm=1.0)  # L2Norm Loss 계산, l2 1.0되게.\n",
    "                        loss = loss + l2_loss*l2_norm_loss_weight\n",
    "                        l2_loss_bin += l2_loss.item()\n",
    "\n",
    "                    # coarse loss ######################################################\n",
    "                    loss_normal = criterion(spike_class, spike)\n",
    "                    level_num_in_loss = quantize_level_num\n",
    "                    level_interval = (coarse_com_config[0] - coarse_com_config[1]) / (level_num_in_loss-1)  # max - min\n",
    "                    levels = [coarse_com_config[1] + level_interval * i for i in range(level_num_in_loss)]\n",
    "                    levels = torch.tensor(levels).to(torch.float).to(device)\n",
    "                    levels = levels.repeat(spike_length,1) \n",
    "\n",
    "                    spike = spike.squeeze()\n",
    "                    spike_class = spike_class.squeeze()\n",
    "                    # plot_origin_spike(spike_class[0].cpu().detach().numpy())\n",
    "                    spike = spike.unsqueeze(2).repeat(1, 1, level_num_in_loss) \n",
    "                    spike = (spike > levels).to(torch.float) \n",
    "                    spike_class = spike_class.unsqueeze(2).repeat(1, 1, level_num_in_loss) \n",
    "                    spike_class = (spike_class > levels).to(torch.float) \n",
    "                    # spike = spike[..., 0:-3, :]\n",
    "                    # spike_class = spike_class[..., 0:-3, :]\n",
    "                    loss_coarse = criterion(spike_class, spike)\n",
    "                    wrong_element_sum += torch.sum(torch.abs(spike - spike_class)).item() \n",
    "\n",
    "                    # plot_spike(spike_class[0].cpu().detach().numpy())\n",
    "                    # assert False\n",
    "                    # coarse loss ######################################################\n",
    "\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                running_loss += loss.item()\n",
    "                running_loss_normal += loss_normal.item()\n",
    "                running_loss_coarse += loss_coarse.item()\n",
    "                # print(f'\\nepoch-{epoch}, running_loss : {running_loss:.5f}, iter percent {iter/len(train_loader)*100:.2f}%')\n",
    "                iter += 1\n",
    "        else:\n",
    "            print('\\n\\n\\n max_epoch 1이면 Train 안함!!!!!!!!!!!!!!!!!!!!!')\n",
    "        if l2_norm_loss_weight > 0:\n",
    "            print('l2_loss_bin', l2_loss_bin/len(train_loader))\n",
    "        avg_loss = running_loss / len(train_loader)\n",
    "        assert not np.isnan(avg_loss), f\"Error: avg_loss is NaN! Running loss: {running_loss}, Length of train_loader: {len(train_loader)}\"\n",
    "        loss_history.append((epoch, avg_loss))\n",
    "        min_loss = min(min_loss, avg_loss)\n",
    "        min_loss_normal = min(min_loss_normal, running_loss_normal/len(train_loader))\n",
    "        min_loss_coarse = min(min_loss_coarse, running_loss_coarse/len(train_loader))\n",
    "        print(f'\\nepoch-{epoch} loss : {avg_loss:.8f}, loss_normal : {running_loss_normal/len(train_loader):.8f}, loss_coarse : {running_loss_coarse/len(train_loader):.8f}, min_loss : {min_loss:.8f}, min_loss_normal : {min_loss_normal:.8f}, min_loss_coarse : {min_loss_coarse:.8f}, wrong_element_sum : {wrong_element_sum:.8f}, same_data : {100*same_data_num/(total_data_num+1e-12):.2f}%')\n",
    "        print(f\"ae train 실행 시간: {time.time()-ae_train_start_time:.3f}초, 전체 시작 시간 {current_time}\")\n",
    "\n",
    "        # plot_activation_distribution(net)\n",
    "\n",
    "        if SAE_net == False and converted_net_forward == True:\n",
    "            source_encoder = net.module.encoder \n",
    "            target_encoder = converted_net.module.encoder  \n",
    "            copy_weights(source_encoder, target_encoder)\n",
    "\n",
    "        cluster_accuracy_during_training_cycle_all_dataset = np.zeros(dataset_num)\n",
    "        cluster_accuracy_post_training_cycle_all_dataset = np.zeros(dataset_num)\n",
    "        cluster_accuracy_total_all_dataset = np.zeros(dataset_num)    \n",
    "\n",
    "        k_means_acc = 0\n",
    "        converted_k_means_acc = 0\n",
    "        if(epoch % accuracy_check_epoch_term == 0 or epoch == 1 or epoch == max_epoch-1): \n",
    "            accuracy_check_start_time = time.time()\n",
    "            print(f'\\nepoch-{epoch} accuracy check')\n",
    "            k_means_bin_origin_feature = []\n",
    "            k_means_bin = []\n",
    "            converted_k_means_bin = []\n",
    "            for ds in range(dataset_num):\n",
    "                # print('\\n', spike_tot[ds])\n",
    "\n",
    "                spike_template = np.load(my_path_ground_BH + template[ds])\n",
    "                spike = np.load(my_path_ground_BH + spike_tot[ds])\n",
    "                label = np.load(my_path_ground_BH + label_tot[ds])\n",
    "                spike_template = torch.from_numpy(spike_template).to(device)\n",
    "                spike = torch.from_numpy(spike).to(device)\n",
    "                scaling = (level_num-3)/level_num if conv1d_scaling else 1.0\n",
    "                spike_template = zero_to_one_normalize_features(spike_template, level_num=quantize_level_num, coarse_com_config=coarse_com_config, scaling=scaling, norm01=norm01) if normalize_on else spike_template\n",
    "                spike = zero_to_one_normalize_features(spike, level_num=quantize_level_num, coarse_com_config=coarse_com_config, scaling=scaling, norm01=norm01) if normalize_on else spike\n",
    "                \n",
    "                hidden_size = lateral_feature_num*TIME if 'SAE' in net.module.__class__.__name__ and SAE_hidden_nomean == True and fusion_net == False or 'SAE_FUSION5' in net.module.__class__.__name__ else lateral_feature_num\n",
    "                hidden_size = lateral_feature_num if '_DR' in net.module.__class__.__name__  else hidden_size\n",
    "\n",
    "                Cluster = np.zeros((num_cluster, hidden_size))\n",
    "                assert Cluster.shape[-1] == hidden_size, '이거 hidden dim 4 아니게 할 거면 잘 바꿔라'\n",
    "                \n",
    "\n",
    "\n",
    "                net.eval()\n",
    "                with torch.no_grad():\n",
    "                    spike_torch = spike_template.float()\n",
    "                    spike_torch = spike_torch[:num_cluster]\n",
    "                    spike_backup = spike_torch\n",
    "                    spike_torch = spike_torch.to(device)\n",
    "                    if coarse_com_mode == True and 'SAE' in net.module.__class__.__name__:\n",
    "                        spike_torch = spike_torch.unsqueeze(2).repeat(1, 1, level_num) # spike_length == level_num # (batch, time, feature)로 변환 \n",
    "                        spike_torch = (spike_torch > levels).to(torch.float) \n",
    "                        spike_torch = (spike_torch == 0).cumsum(dim=-1).eq(1).to(torch.float) if lc_adc_on == True else spike_torch\n",
    "                        if Conv_net == True:\n",
    "                            spike_torch = spike_torch.unsqueeze(-2) # batch, time, in_channel, feature or batch in_channel,feature\n",
    "                            if two_channel_input == True:\n",
    "                                spike_backup = spike_backup.to(device)\n",
    "                                spike_backup = spike_backup.unsqueeze(2).repeat(1, 1, level_num) # spike_length == level_num # (batch, time, feature)로 변환 \n",
    "                                spike_backup = (spike_backup <= levels).to(torch.float) \n",
    "                                spike_backup = (spike_backup == 1).cumsum(dim=-1).eq(1).to(torch.float) if lc_adc_on == True else spike_backup\n",
    "                                spike_backup = spike_backup.unsqueeze(-2) # batch, time, in_channel, feature\n",
    "                                spike_torch = torch.cat((spike_torch, spike_backup), dim=-2)\n",
    "                    elif 'SAE' in net.module.__class__.__name__:\n",
    "                        spike_torch = spike_torch.unsqueeze(1).repeat(1, TIME, 1) # (batch, time, feature)로 변환\n",
    "                        if Conv_net == True:\n",
    "                            spike_torch = spike_torch.unsqueeze(-2) # batch, time, in_channel, feature or batch in_channel,feature\n",
    "                    else:\n",
    "                        # if Conv_net == True:\n",
    "                        #     spike_torch = spike_torch.unsqueeze(-2) #batch in_channel,feature\n",
    "                        if Conv_net == True:\n",
    "                            if coarse_com_mode == False:\n",
    "                                spike_torch = spike_torch.unsqueeze(-2) #batch in_channel,feature\n",
    "                            else:\n",
    "                                spike_torch = spike_torch.unsqueeze(2).repeat(1, 1, level_num) # spike_length == level_num # (batch, time, feature)로 변환 \n",
    "                                spike_torch = (spike_torch > levels).to(torch.float) \n",
    "\n",
    "                                spike_torch = (spike_torch == 0).cumsum(dim=-1).eq(1).to(torch.float) if lc_adc_on == True else spike_torch\n",
    "\n",
    "                        else:\n",
    "                            if coarse_com_mode == False:\n",
    "                                pass\n",
    "                            else:\n",
    "                                spike_torch = spike_torch.unsqueeze(2).repeat(1, 1, level_num) # spike_length == level_num # (batch, time, feature)로 변환 \n",
    "                                spike_torch = (spike_torch > levels).to(torch.float) \n",
    "\n",
    "                                spike_torch = (spike_torch == 0).cumsum(dim=-1).eq(1).to(torch.float) if lc_adc_on == True else spike_torch\n",
    "\n",
    "                                # spike: batch, time, feature\n",
    "                                spike_torch = spike_torch.reshape(spike_torch.shape[0], -1)\n",
    "\n",
    "                        if converted_net_forward == True:\n",
    "                            spike_torch_spikegen = spikegen.rate(spike_torch, num_steps=TIME).transpose(0, 1)\n",
    "                        # if fusion_net == True:\n",
    "                        #     spike_torch = spikegen.rate(spike_torch, num_steps=TIME).transpose(0, 1)\n",
    "                    ### forward #######################################################\n",
    "                    inner_inf = net.module.encoder(spike_torch)\n",
    "                    if SAE_net == False and converted_net_forward == True:\n",
    "                        converted_inner_inf = converted_net.module.encoder(spike_torch_spikegen)\n",
    "                    ### forward #######################################################\n",
    "\n",
    "                    # if ds % 4 == 0:\n",
    "                    #     for i in range(4):\n",
    "                    #         decoded = net.module.decoder(inner_inf).squeeze()\n",
    "                    #         plot_spike(spike_torch[i,:,:].cpu().numpy())\n",
    "                    #         plot_spike(inner_inf[i,:].cpu().numpy())\n",
    "                    #         # plot_origin_spike(net.module.decoder(inner_inf)[i,:].cpu().numpy())\n",
    "                    #         plot_origin_spike(decoded[i].cpu().numpy(), min_max_y_on = True)\n",
    "                        \n",
    "                    # if 'SAE' in net.module.__class__.__name__:\n",
    "                    #     tensors = [inner_inf[0][i] for i in range(TIME)] \n",
    "                    #     all_equal = all(torch.equal(tensors[0], t) for t in tensors)\n",
    "                    #     print(all_equal, inner_inf)\n",
    "\n",
    "                    if 'SAE' in net.module.__class__.__name__:\n",
    "                        if SAE_hidden_nomean == True:\n",
    "                            inner_inf = inner_inf.reshape(inner_inf.shape[0],-1)# time*feature 펼치기\n",
    "                        else:\n",
    "                            inner_inf = inner_inf.mean(dim=1)# Time 방향으로 평균\n",
    "                        # inner_inf = F.normalize(inner_inf, p=2, dim=1)\n",
    "                    Cluster = inner_inf.cpu().detach().numpy()\n",
    "\n",
    "                encoder_batch = 128\n",
    "                spike_hidden = np.zeros((len(spike), hidden_size))\n",
    "                converted_spike_hidden = np.zeros((len(spike), hidden_size))\n",
    "                net.eval()\n",
    "                with torch.no_grad():\n",
    "                    now_index = 0\n",
    "                    while (1):\n",
    "                        now_end_index = now_index+encoder_batch if now_index+encoder_batch < len(spike) else len(spike)\n",
    "                        spike_batch = spike[now_index:now_end_index] \n",
    "                        spike_torch = spike_batch\n",
    "                        spike_torch = spike_torch.float()\n",
    "                        spike_backup = spike_torch\n",
    "                        spike_torch = spike_torch.to(device)\n",
    "                        if coarse_com_mode == True and 'SAE' in net.module.__class__.__name__:\n",
    "                            spike_torch = spike_torch.unsqueeze(2).repeat(1, 1, level_num) # spike_length == level_num # (batch, time, feature)로 변환 \n",
    "                            spike_torch = (spike_torch > levels).to(torch.float) \n",
    "                            spike_torch = (spike_torch == 0).cumsum(dim=-1).eq(1).to(torch.float) if lc_adc_on == True else spike_torch\n",
    "                            if Conv_net == True:\n",
    "                                spike_torch = spike_torch.unsqueeze(-2) # batch, time, in_channel, feature or batch in_channel,feature\n",
    "                                if two_channel_input == True:\n",
    "                                    spike_backup = spike_backup.to(device)\n",
    "                                    spike_backup = spike_backup.unsqueeze(2).repeat(1, 1, level_num) # spike_length == level_num # (batch, time, feature)로 변환 \n",
    "                                    spike_backup = (spike_backup <= levels).to(torch.float) \n",
    "                                    spike_backup = (spike_backup == 1).cumsum(dim=-1).eq(1).to(torch.float) if lc_adc_on == True else spike_backup\n",
    "                                    spike_backup = spike_backup.unsqueeze(-2)\n",
    "                                    spike_torch = torch.cat((spike_torch, spike_backup), dim=-2)\n",
    "                        elif 'SAE' in net.module.__class__.__name__:\n",
    "                            spike_torch = spike_torch.unsqueeze(1).repeat(1, TIME, 1) # (batch, time, feature)로 변환\n",
    "                            if Conv_net == True:\n",
    "                                spike_torch = spike_torch.unsqueeze(-2) # batch, time, in_channel, feature or batch in_channel,feature\n",
    "                        else:\n",
    "                            # if Conv_net == True:\n",
    "                            #     spike_torch = spike_torch.unsqueeze(-2) #batch in_channel,feature\n",
    "                            if Conv_net == True:\n",
    "                                if coarse_com_mode == False:\n",
    "                                    spike_torch = spike_torch.unsqueeze(-2) #batch in_channel,feature\n",
    "                                else:\n",
    "                                    spike_torch = spike_torch.unsqueeze(2).repeat(1, 1, level_num) # spike_length == level_num # (batch, time, feature)로 변환 \n",
    "                                    spike_torch = (spike_torch > levels).to(torch.float) \n",
    "\n",
    "                                    spike_torch = (spike_torch == 0).cumsum(dim=-1).eq(1).to(torch.float) if lc_adc_on == True else spike_torch\n",
    "\n",
    "                            else:\n",
    "                                if coarse_com_mode == False:\n",
    "                                    pass\n",
    "                                else:\n",
    "                                    spike_torch = spike_torch.unsqueeze(2).repeat(1, 1, level_num) # spike_length == level_num # (batch, time, feature)로 변환 \n",
    "                                    spike_torch = (spike_torch > levels).to(torch.float) \n",
    "\n",
    "                                    spike_torch = (spike_torch == 0).cumsum(dim=-1).eq(1).to(torch.float) if lc_adc_on == True else spike_torch\n",
    "\n",
    "                                    # spike: batch, time, feature\n",
    "                                    spike_torch = spike_torch.reshape(spike_torch.shape[0], -1)\n",
    "                            if converted_net_forward == True:\n",
    "                                spike_torch_spikegen = spikegen.rate(spike_torch, num_steps=TIME).transpose(0, 1)\n",
    "                            # if fusion_net == True:\n",
    "                            #     spike_torch = spikegen.rate(spike_torch, num_steps=TIME).transpose(0, 1)\n",
    "                        ### forward #######################################################\n",
    "                        inner_inf = net.module.encoder(spike_torch)\n",
    "                        if SAE_net == False and converted_net_forward == True:\n",
    "                            converted_inner_inf = converted_net.module.encoder(spike_torch_spikegen)\n",
    "                        ### forward #######################################################\n",
    "                            \n",
    "                        if 'SAE' in net.module.__class__.__name__:\n",
    "                            if SAE_hidden_nomean == True:\n",
    "                                inner_inf = inner_inf.reshape(spike_batch.shape[0],-1)# 펼치기\n",
    "                            else:\n",
    "                                inner_inf = inner_inf.mean(dim=1)# Time 방향으로 평균\n",
    "                            # inner_inf = F.normalize(inner_inf, p=2, dim=1)\n",
    "                        spike_hidden[now_index:now_end_index] = inner_inf.cpu().detach().numpy()\n",
    "                        if SAE_net == False and converted_net_forward == True:\n",
    "                            converted_spike_hidden[now_index:now_end_index] = converted_inner_inf.cpu().detach().numpy()\n",
    "                        now_index += encoder_batch\n",
    "                        if (now_index >= len(spike)):\n",
    "                            break\n",
    "                    \n",
    "                spike_id = np.zeros(len(spike))\n",
    "                distance_sm = np.zeros(num_cluster)\n",
    "                tau = np.zeros(num_cluster)\n",
    "                \n",
    "                plot_tau = []\n",
    "                plot_denominator = []\n",
    "                plot_m = []\n",
    "                plot_max_tau = []\n",
    "                for spike_index in range(len(spike)): \n",
    "                    for q in range(num_cluster):\n",
    "                        tau[q] = np.dot(spike_hidden[spike_index, :], Cluster[q, :]) # 이거 l2norm 거쳐서 나온 거니까 분모 1임.\n",
    "                        denominator =  np.linalg.norm(spike_hidden[spike_index, :])*np.linalg.norm(Cluster[q, :]) + 1e-12\n",
    "                        plot_denominator.append(denominator)\n",
    "                        if 'SAE' in net.module.__class__.__name__: # AE 때는 l2norm거쳐서 나와서 괜찮음\n",
    "                            tau[q] = tau[q] / denominator\n",
    "\n",
    "                        plot_tau.append(tau[q])\n",
    "\n",
    "                    # for i in range(num_cluster): # l2 distance\n",
    "                    #     distance_sm[i] = np.sum(np.power(np.abs(Cluster[i] - spike_hidden[spike_index, :]), 2))\n",
    "                    distance_sm = np.sum(np.power(np.abs(Cluster - spike_hidden[spike_index, :]), 2), axis=1)\n",
    "\n",
    "                    m = np.argmin(distance_sm)\n",
    "                    plot_m.append(m)\n",
    "                    spike_id[spike_index] = m + 1\n",
    "                    # print(spike_tot[ds], spike_index,np.max(tau))\n",
    "                    plot_max_tau.append(np.max(tau))\n",
    "                    if(np.max(tau) >= cos_thr[ds] and spike_index < training_cycle): # 원래 1400 아니냐?\n",
    "                        Cluster[m] = (Cluster[m] * 15 + spike_hidden[spike_index, :])/16\n",
    "\n",
    "\n",
    "                \n",
    "                origin_kmeans_accuracy = cluster_spikes_with_accuracy_torch(features= spike, true_labels=label-1, n_clusters=3, init_point=None)\n",
    "                kmeans_accuracy = cluster_spikes_with_accuracy_torch(features= torch.tensor(spike_hidden).to(device), true_labels=label-1, n_clusters=3, init_point=None)\n",
    "                \n",
    "                # print('temporoal k')\n",
    "                # result = evaluate_clustering_accuracy(spike_hidden.reshape(spike_hidden.shape[0], TIME, -1), label-1, n_clusters=3)\n",
    "                # print('원래', kmeans_accuracy)\n",
    "                # print(result)\n",
    "\n",
    "                k_means_bin_origin_feature.append(origin_kmeans_accuracy)\n",
    "                k_means_bin.append(kmeans_accuracy)\n",
    "                if SAE_net == False and converted_net_forward == True:\n",
    "                    converted_kmeans_accuracy = cluster_spikes_with_accuracy_torch(features= torch.tensor(converted_spike_hidden).to(device), true_labels=label-1, n_clusters=3, init_point=None)\n",
    "                    converted_k_means_bin.append(converted_kmeans_accuracy)\n",
    "                # sklearn kmeans인데 cpu많이먹어서 버림.\n",
    "                # origin_kmeans_accuracy = cluster_spikes_with_accuracy(features= spike.cpu().detach().numpy(), true_labels=label-1, n_clusters=3, init_point=None)\n",
    "                # kmeans_accuracy = cluster_spikes_with_accuracy(features= spike_hidden, true_labels=label-1, n_clusters=3, init_point=None)\n",
    "                # k_means_bin_origin_feature.append(origin_kmeans_accuracy)\n",
    "                # k_means_bin.append(kmeans_accuracy)\n",
    "                # if SAE_net == False and converted_net_forward == True:\n",
    "                #     converted_kmeans_accuracy = cluster_spikes_with_accuracy(features= converted_spike_hidden, true_labels=label-1, n_clusters=3, init_point=None)\n",
    "                #     converted_k_means_bin.append(converted_kmeans_accuracy)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "                # print('Cluster',Cluster)\n",
    "                # print('spike_id', spike_id)\n",
    "\n",
    "                # spike id 분포 확인하기\n",
    "                # unique_elements, counts = np.unique(spike_id, return_counts=True)\n",
    "                # print(\"Unique elements:\", unique_elements)\n",
    "                # print(\"Counts:\", counts)\n",
    "\n",
    "                cluster_accuracy_during_training_cycle = np.zeros(math.factorial(num_cluster))\n",
    "                cluster_accuracy_post_training_cycle = np.zeros(math.factorial(num_cluster))\n",
    "                cluster_accuracy_total = np.zeros(math.factorial(num_cluster))\n",
    "                \n",
    "                label_converter_ground = list(range(1, num_cluster + 1)) # [1, 2, 3, 4] 생성\n",
    "                label_converter_permutations = list(itertools.permutations(label_converter_ground)) # 모든 순열 구하기\n",
    "                perm_i = 0\n",
    "                perm_start_time = time.time() \n",
    "                for perm in label_converter_permutations:\n",
    "                    label_converter = list(perm)\n",
    "                    # print(label_converter)\n",
    "                    correct_during_training_cycle = 0\n",
    "                    correct_post_training_cycle = 0\n",
    "\n",
    "                    assert len(spike_id) == len(label), 'spike_id랑 label 길이 같아야 됨.'\n",
    "                    for i in range(len(spike_id)):\n",
    "                        if(label_converter[int(spike_id[i]-1)] == label[i]):\n",
    "                            if i < training_cycle:\n",
    "                                correct_during_training_cycle += 1\n",
    "                            else:\n",
    "                                correct_post_training_cycle += 1\n",
    "\n",
    "                    cluster_accuracy_during_training_cycle[perm_i] = correct_during_training_cycle/training_cycle\n",
    "                    cluster_accuracy_post_training_cycle[perm_i] = correct_post_training_cycle/(len(spike_id)-training_cycle)\n",
    "                    cluster_accuracy_total[perm_i] = (correct_during_training_cycle+correct_post_training_cycle)/(len(spike_id))\n",
    "                    perm_i += 1\n",
    "                # print(f\"perm 실행 시간: {time.time()-perm_start_time:.3f}초\")\n",
    "                \n",
    "                cluster_accuracy_during_training_cycle_all_dataset[ds] = np.max(cluster_accuracy_during_training_cycle)\n",
    "                cluster_accuracy_post_training_cycle_all_dataset[ds] = cluster_accuracy_post_training_cycle[np.argmax(cluster_accuracy_during_training_cycle)]\n",
    "                cluster_accuracy_total_all_dataset[ds] = cluster_accuracy_total[np.argmax(cluster_accuracy_during_training_cycle)]\n",
    "                # plot_distributions(ds, plot_tau, plot_denominator, plot_m, plot_max_tau, cos_thr[ds],\n",
    "                #                    cluster_accuracy_during_training_cycle_all_dataset[ds], cluster_accuracy_post_training_cycle_all_dataset[ds], cluster_accuracy_total_all_dataset[ds])\n",
    "            print(f'k_means origin feature average accuracy : {100*sum(k_means_bin_origin_feature)/(len(k_means_bin_origin_feature)+1e-12):.8f}%, total {k_means_bin_origin_feature}')\n",
    "            \n",
    "            mean_cluster_accuracy_during_training_cycle_all_dataset = np.mean(cluster_accuracy_during_training_cycle_all_dataset)\n",
    "            mean_cluster_accuracy_post_training_cycle_all_dataset = np.mean(cluster_accuracy_post_training_cycle_all_dataset)\n",
    "            mean_cluster_accuracy_total_all_dataset = np.mean(cluster_accuracy_total_all_dataset)\n",
    "            \n",
    "            if SAE_net == False and converted_net_forward == True:\n",
    "                converted_k_means_acc = 100*sum(converted_k_means_bin)/len(converted_k_means_bin)\n",
    "                print(f'converted_kmeans average accuracy : {converted_k_means_acc:.8f}%, total {converted_k_means_bin}')\n",
    "            k_means_acc = 100*sum(k_means_bin)/len(k_means_bin)\n",
    "            if k_means_acc > k_means_acc_best:\n",
    "                # torch.save(net, f\"net_save/save_now_net_{current_time}.pth\")\n",
    "                torch.save(net.module.state_dict(), f\"net_save/save_now_net_{current_time}.pth\")\n",
    "                print('save model')\n",
    "                best_mean_cluster_accuracy_post_training_cycle_all_dataset = mean_cluster_accuracy_post_training_cycle_all_dataset\n",
    "            \n",
    "            k_means_acc_best = max(k_means_acc_best, k_means_acc)\n",
    "            print(f'kmeans average accuracy best : {k_means_acc_best:.2f}%, kmeans average accuracy : {k_means_acc:.8f}%, total {k_means_bin}')\n",
    "            print(f'cluster_accuracy_post_training_cycle_all_dataset : {cluster_accuracy_post_training_cycle_all_dataset}')\n",
    "\n",
    "            \n",
    "            mean_cluster_accuracy_during_training_cycle_all_dataset_history.append((epoch, mean_cluster_accuracy_during_training_cycle_all_dataset*100))\n",
    "            mean_cluster_accuracy_post_training_cycle_all_dataset_history.append((epoch, mean_cluster_accuracy_post_training_cycle_all_dataset*100))\n",
    "            mean_cluster_accuracy_total_all_dataset_history.append((epoch, mean_cluster_accuracy_total_all_dataset*100))\n",
    "            print(f\"mean_cluster_accuracy_during_training_cycle : {mean_cluster_accuracy_during_training_cycle_all_dataset*100:.2f}%, post_traincycle_acc : {mean_cluster_accuracy_post_training_cycle_all_dataset*100:.2f}%, total_acc : {mean_cluster_accuracy_total_all_dataset*100:.8f}%\")\n",
    "\n",
    "            # kmeans accuracy기준으로 좋은 거 저장할 거임\n",
    "            # if mean_cluster_accuracy_post_training_cycle_all_dataset > best_mean_cluster_accuracy_post_training_cycle_all_dataset:\n",
    "            #     # torch.save(net, f\"net_save/save_now_net_{current_time}.pth\")\n",
    "            #     torch.save(net.module.state_dict(), f\"net_save/save_now_net_{current_time}.pth\")\n",
    "            #     print('save model')\n",
    "            #     best_mean_cluster_accuracy_post_training_cycle_all_dataset = mean_cluster_accuracy_post_training_cycle_all_dataset\n",
    "            print(f\"best_mean_cluster_accuracy_post_training_cycle_all_dataset : {best_mean_cluster_accuracy_post_training_cycle_all_dataset*100:.2f}%\")\n",
    "            print(f\"accuracy_check 실행 시간: {time.time()-accuracy_check_start_time:.3f}초\")\n",
    "\n",
    "        wandb.log({\"avg_loss\": avg_loss})\n",
    "        wandb.log({\"mean_cluster_accuracy_post_training_cycle_all_dataset\": mean_cluster_accuracy_post_training_cycle_all_dataset})\n",
    "        wandb.log({\"best_mean_cluster_accuracy_post_training_cycle_all_dataset\": best_mean_cluster_accuracy_post_training_cycle_all_dataset})\n",
    "        wandb.log({\"best_mean_cluster_accuracy_post_training_cycle_all_dataset2\": best_mean_cluster_accuracy_post_training_cycle_all_dataset})\n",
    "        wandb.log({\"k_means_acc\": k_means_acc})\n",
    "        wandb.log({\"k_means_acc_best\": k_means_acc_best})\n",
    "        wandb.log({\"converted_k_means_acc\": converted_k_means_acc})\n",
    "\n",
    "\n",
    "        # 저장\n",
    "        with open(f\"result_save/cluster_accuracy_history_{current_time}.pkl\", \"wb\") as f:\n",
    "            pickle.dump({\n",
    "                \"loss_history\": loss_history,\n",
    "                \"mean_cluster_accuracy_during_training_cycle_all_dataset_history\": mean_cluster_accuracy_during_training_cycle_all_dataset_history,\n",
    "                \"mean_cluster_accuracy_post_training_cycle_all_dataset_history\": mean_cluster_accuracy_post_training_cycle_all_dataset_history,\n",
    "                \"mean_cluster_accuracy_total_all_dataset_history\": mean_cluster_accuracy_total_all_dataset_history,\n",
    "            }, f)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mbhkim003\u001b[0m (\u001b[33mbhkim003-seoul-national-university\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.19.8 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.17.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/nfs/home/bhkim003/github_folder/ByeonghyeonKim/my_snn/wandb/run-20250312_164921-qks2fe9c</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/bhkim003-seoul-national-university/spike_sorting%20just%20run/runs/qks2fe9c' target=\"_blank\">leafy-durian-1434</a></strong> to <a href='https://wandb.ai/bhkim003-seoul-national-university/spike_sorting%20just%20run' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/bhkim003-seoul-national-university/spike_sorting%20just%20run' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/spike_sorting%20just%20run</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/bhkim003-seoul-national-university/spike_sorting%20just%20run/runs/qks2fe9c' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/spike_sorting%20just%20run/runs/qks2fe9c</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'gpu': '3', 'Conv_net': True, 'SAE_net': True, 'dataset_num': 16, 'spike_length': 50, 'num_cluster': 4, 'training_cycle': 1400, 'batch_size': 32, 'max_epoch': 10000, 'learning_rate': 0.001, 'normalize_on': True, 'need_bias': False, 'lif_add_at_first': False, 'my_seed': 42, 'TIME': 50, 'v_decay': 0.5, 'v_threshold': 0.25, 'v_reset': 0.0, 'BPTT_on': True, 'SAE_hidden_nomean': True, 'current_time': '20250312_164918_659', 'optimizer': 'Adam', 'coarse_com_mode': True, 'sae_l2_norm_bridge': True, 'sae_lif_bridge': False, 'accuracy_check_epoch_term': 1, 'lif_add_at_last': False, 'two_channel_input': False, 'lateral_feature_num': 4, 'lc_adc_on': False, 'converted_net_forward': False, 'pretrained_net': None, 'vth_mul_on': False, 'batch_norm_on': False, 'l2_norm_loss_weight': 0, 'QCFS_neuron_on': False, 'quantize_level_num': 0, 'fusion_net': True, 'repeat_coding': False, 'sae_relu_on': False, 'conv1d_scaling': False, 'norm01': True, 'coarse_com_config': (0.999, -0.0)}\n",
      "cos_thr [0.95 0.95 0.95 0.95 0.95 0.95 0.95 0.85 0.95 0.9  0.8  0.95 0.95 0.95\n",
      " 0.95 0.8 ]\n",
      "conv length [50, 24, 11, 5]\n",
      "Total number of encoder parameters: 26792\n",
      "DataParallel(\n",
      "  (module): SAE_FUSION6_net_conv1(\n",
      "    (activation_function): LIF_layer()\n",
      "    (encoder): Sequential(\n",
      "      (0): SSBH_DimChanger_one_two()\n",
      "      (1): SSBH_DimChanger_for_one_two_coupling()\n",
      "      (2): Conv1d(1, 32, kernel_size=(3,), stride=(2,), bias=False)\n",
      "      (3): SSBH_DimChanger_for_one_two_decoupling()\n",
      "      (4): LIF_layer()\n",
      "      (5): SSBH_DimChanger_for_one_two_coupling()\n",
      "      (6): Conv1d(32, 64, kernel_size=(3,), stride=(2,), bias=False)\n",
      "      (7): SSBH_DimChanger_for_one_two_decoupling()\n",
      "      (8): LIF_layer()\n",
      "      (9): SSBH_DimChanger_for_one_two_coupling()\n",
      "      (10): Conv1d(64, 96, kernel_size=(3,), stride=(2,), bias=False)\n",
      "      (11): SSBH_DimChanger_for_one_two_decoupling()\n",
      "      (12): LIF_layer()\n",
      "      (13): SSBH_DimChanger_for_one_two_coupling()\n",
      "      (14): SSBH_DimChanger_for_fc()\n",
      "      (15): Linear(in_features=480, out_features=4, bias=False)\n",
      "      (16): SSBH_DimChanger_for_one_two_decoupling()\n",
      "      (17): LIF_layer()\n",
      "      (18): SSBH_DimChanger_one_two()\n",
      "      (19): SSBH_MultiLinearLayer(\n",
      "        (linears): ModuleList(\n",
      "          (0): Linear(in_features=50, out_features=1, bias=False)\n",
      "          (1): Linear(in_features=50, out_features=1, bias=False)\n",
      "          (2): Linear(in_features=50, out_features=1, bias=False)\n",
      "          (3): Linear(in_features=50, out_features=1, bias=False)\n",
      "        )\n",
      "      )\n",
      "      (20): SSBH_L2NormLayer()\n",
      "    )\n",
      "    (decoder): Sequential(\n",
      "      (0): Linear(in_features=4, out_features=480, bias=False)\n",
      "      (1): ReLU()\n",
      "      (2): SSBH_DimChanger_for_conv1()\n",
      "      (3): ConvTranspose1d(96, 64, kernel_size=(3,), stride=(2,), bias=False)\n",
      "      (4): ReLU()\n",
      "      (5): ConvTranspose1d(64, 32, kernel_size=(3,), stride=(2,), output_padding=(1,), bias=False)\n",
      "      (6): ReLU()\n",
      "      (7): ConvTranspose1d(32, 1, kernel_size=(3,), stride=(2,), output_padding=(1,), bias=False)\n",
      "    )\n",
      "  )\n",
      ")\n",
      "Device: cuda\n",
      "\n",
      "Start Training, current_time = 20250312_164918_659\n",
      "\n",
      "\n",
      "epoch-0 loss : 0.03193169, loss_normal : 0.02073189, loss_coarse : 0.09252258, min_loss : 0.03193169, min_loss_normal : 0.02073189, min_loss_coarse : 0.09252258, wrong_element_sum : 17764336.00000000, same_data : 0.00%\n",
      "ae train 실행 시간: 116.034초, 전체 시작 시간 20250312_164918_659\n",
      "\n",
      "epoch-0 accuracy check\n",
      "k_means origin feature average accuracy : 82.25314853%, total [0.9746727376209448, 0.9733106189664963, 0.9700891573195284, 0.9530800230282096, 0.943108504398827, 0.9150568181818182, 0.801817648783348, 0.6622234826999432, 0.9488619568430388, 0.822215777262181, 0.5866935483870968, 0.5005858230814294, 0.9429250891795482, 0.8922588099364529, 0.673546511627907, 0.6000572573718866]\n",
      "save model\n",
      "kmeans average accuracy best : 86.90%, kmeans average accuracy : 86.89504900%, total [0.9746727376209448, 0.9758659852356616, 0.9726775956284153, 0.9634427173287277, 0.9653958944281525, 0.9431818181818182, 0.8885957197302844, 0.8122518434486671, 0.9583210168489507, 0.892691415313225, 0.7992511520737328, 0.7305213825424721, 0.8870392390011891, 0.7998266897746967, 0.7127906976744186, 0.6266819352991698]\n",
      "cluster_accuracy_post_training_cycle_all_dataset : [0.97729423 0.97643732 0.9735195  0.96528447 0.96716418 0.93490566\n",
      " 0.89010443 0.81091251 0.93746848 0.88964844 0.80164093 0.71499503\n",
      " 0.88696538 0.814258   0.69509804 0.61442905]\n",
      "mean_cluster_accuracy_during_training_cycle : 86.28%, post_traincycle_acc : 86.56%, total_acc : 86.44737038%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 86.56%\n",
      "accuracy_check 실행 시간: 25.933초\n",
      "\n",
      "\n",
      "epoch-1 loss : 0.01706973, loss_normal : 0.01616167, loss_coarse : 0.07749230, min_loss : 0.01706973, min_loss_normal : 0.01616167, min_loss_coarse : 0.07749230, wrong_element_sum : 14878522.00000000, same_data : 0.00%\n",
      "ae train 실행 시간: 114.629초, 전체 시작 시간 20250312_164918_659\n",
      "\n",
      "epoch-1 accuracy check\n",
      "k_means origin feature average accuracy : 82.25849966%, total [0.9746727376209448, 0.9733106189664963, 0.9700891573195284, 0.9530800230282096, 0.943108504398827, 0.9150568181818182, 0.801817648783348, 0.6625070901871809, 0.9488619568430388, 0.822215777262181, 0.5866935483870968, 0.5005858230814294, 0.9429250891795482, 0.8922588099364529, 0.673546511627907, 0.600629831090753]\n",
      "save model\n",
      "kmeans average accuracy best : 88.17%, kmeans average accuracy : 88.16698348%, total [0.9735344336937962, 0.9750141964792731, 0.9706643658326143, 0.9597006332757628, 0.9653958944281525, 0.9522727272727273, 0.9055995309293462, 0.8295519001701644, 0.9323086018326929, 0.8889211136890951, 0.8119239631336406, 0.7615700058582309, 0.9348989298454221, 0.8726169844020797, 0.7357558139534883, 0.6369882622387633]\n",
      "cluster_accuracy_post_training_cycle_all_dataset : [0.97587512 0.97502356 0.97255657 0.96094503 0.96616915 0.9490566\n",
      " 0.90651417 0.81044214 0.91679274 0.88134766 0.80019305 0.69414101\n",
      " 0.93482688 0.89039767 0.79607843 0.59913999]\n",
      "mean_cluster_accuracy_during_training_cycle : 86.98%, post_traincycle_acc : 87.68%, total_acc : 87.39710766%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 87.68%\n",
      "accuracy_check 실행 시간: 28.521초\n",
      "\n",
      "\n",
      "epoch-2 loss : 0.01602240, loss_normal : 0.01593128, loss_coarse : 0.07586996, min_loss : 0.01602240, min_loss_normal : 0.01593128, min_loss_coarse : 0.07586996, wrong_element_sum : 14567032.00000000, same_data : 0.00%\n",
      "ae train 실행 시간: 120.258초, 전체 시작 시간 20250312_164918_659\n",
      "\n",
      "epoch-2 accuracy check\n",
      "k_means origin feature average accuracy : 82.26218852%, total [0.9746727376209448, 0.9733106189664963, 0.9700891573195284, 0.9530800230282096, 0.943108504398827, 0.9150568181818182, 0.801817648783348, 0.6625070901871809, 0.9488619568430388, 0.822215777262181, 0.5866935483870968, 0.5005858230814294, 0.9429250891795482, 0.8922588099364529, 0.6747093023255814, 0.6000572573718866]\n",
      "kmeans average accuracy best : 88.17%, kmeans average accuracy : 87.43729210%, total [0.9746727376209448, 0.9770017035775128, 0.9712395743457003, 0.9614277489925158, 0.9589442815249267, 0.9474431818181818, 0.8903547346819115, 0.8048780487804879, 0.9184156074490097, 0.8645591647331786, 0.7960829493087558, 0.7369654364381957, 0.9239001189060642, 0.8613518197573656, 0.7497093023255814, 0.6530203263670198]\n",
      "cluster_accuracy_post_training_cycle_all_dataset : [0.97634816 0.97690858 0.97303804 0.96287367 0.95820896 0.93726415\n",
      " 0.88811537 0.77892756 0.89309128 0.84423828 0.78957529 0.72790467\n",
      " 0.9185336  0.87293889 0.79166667 0.65312948]\n",
      "mean_cluster_accuracy_during_training_cycle : 86.18%, post_traincycle_acc : 87.14%, total_acc : 86.75248406%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 87.68%\n",
      "accuracy_check 실행 시간: 31.993초\n",
      "\n",
      "\n",
      "epoch-3 loss : 0.01567658, loss_normal : 0.01586201, loss_coarse : 0.07525808, min_loss : 0.01567658, min_loss_normal : 0.01586201, min_loss_coarse : 0.07525808, wrong_element_sum : 14449552.00000000, same_data : 0.00%\n",
      "ae train 실행 시간: 116.466초, 전체 시작 시간 20250312_164918_659\n",
      "\n",
      "epoch-3 accuracy check\n",
      "k_means origin feature average accuracy : 82.26936244%, total [0.9746727376209448, 0.9733106189664963, 0.9700891573195284, 0.9530800230282096, 0.943108504398827, 0.9150568181818182, 0.801817648783348, 0.6622234826999432, 0.9488619568430388, 0.822215777262181, 0.5866935483870968, 0.5005858230814294, 0.9429250891795482, 0.8922588099364529, 0.6747093023255814, 0.6014886916690524]\n",
      "kmeans average accuracy best : 88.17%, kmeans average accuracy : 87.09710558%, total [0.9758110415480934, 0.97671777399205, 0.9732528041415013, 0.966321243523316, 0.9648093841642229, 0.9599431818181818, 0.920257988859572, 0.810550198525241, 0.9621637599763524, 0.8628190255220418, 0.7304147465437788, 0.6631517281780902, 0.9206302021403091, 0.8431542461005199, 0.7462209302325581, 0.6593186372745491]\n",
      "cluster_accuracy_post_training_cycle_all_dataset : [0.97871334 0.97690858 0.97303804 0.96673095 0.96567164 0.95518868\n",
      " 0.91596221 0.7869238  0.95410993 0.82714844 0.76689189 0.67626614\n",
      " 0.9185336  0.85160039 0.77254902 0.66316292]\n",
      "mean_cluster_accuracy_during_training_cycle : 86.65%, post_traincycle_acc : 87.18%, total_acc : 86.96576646%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 87.68%\n",
      "accuracy_check 실행 시간: 22.948초\n",
      "\n",
      "\n",
      "epoch-4 loss : 0.01547735, loss_normal : 0.01581255, loss_coarse : 0.07487010, min_loss : 0.01547735, min_loss_normal : 0.01581255, min_loss_coarse : 0.07487010, wrong_element_sum : 14375060.00000000, same_data : 0.00%\n",
      "ae train 실행 시간: 113.981초, 전체 시작 시간 20250312_164918_659\n",
      "\n",
      "epoch-4 accuracy check\n",
      "k_means origin feature average accuracy : 82.24237148%, total [0.9746727376209448, 0.9733106189664963, 0.9700891573195284, 0.9530800230282096, 0.943108504398827, 0.915340909090909, 0.801817648783348, 0.6625070901871809, 0.9488619568430388, 0.822215777262181, 0.586405529953917, 0.5005858230814294, 0.9429250891795482, 0.8922588099364529, 0.673546511627907, 0.5980532493558546]\n",
      "save model\n",
      "kmeans average accuracy best : 89.05%, kmeans average accuracy : 89.05186796%, total [0.972965281730222, 0.9747302668938104, 0.9718147828587863, 0.9620034542314335, 0.9609970674486803, 0.9480113636363636, 0.8988566402814424, 0.8150879183210437, 0.9689624593556015, 0.9054524361948956, 0.8142281105990783, 0.7437024018746339, 0.9286563614744352, 0.8847487001733102, 0.7886627906976744, 0.7094188376753507]\n",
      "cluster_accuracy_post_training_cycle_all_dataset : [0.97587512 0.97502356 0.97255657 0.96383799 0.960199   0.93962264\n",
      " 0.8975634  0.79962371 0.96016137 0.9140625  0.79198842 0.75769613\n",
      " 0.92617108 0.88651794 0.80882353 0.72097468]\n",
      "mean_cluster_accuracy_during_training_cycle : 88.79%, post_traincycle_acc : 89.07%, total_acc : 88.95152352%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 89.07%\n",
      "accuracy_check 실행 시간: 31.369초\n",
      "\n",
      "\n",
      "epoch-5 loss : 0.01536354, loss_normal : 0.01579953, loss_coarse : 0.07471363, min_loss : 0.01536354, min_loss_normal : 0.01579953, min_loss_coarse : 0.07471363, wrong_element_sum : 14345018.00000000, same_data : 0.00%\n",
      "ae train 실행 시간: 119.514초, 전체 시작 시간 20250312_164918_659\n",
      "\n",
      "epoch-5 accuracy check\n",
      "k_means origin feature average accuracy : 82.25497029%, total [0.9746727376209448, 0.9733106189664963, 0.9700891573195284, 0.9530800230282096, 0.943108504398827, 0.9150568181818182, 0.801817648783348, 0.6625070901871809, 0.9488619568430388, 0.822215777262181, 0.5872695852534562, 0.5005858230814294, 0.9429250891795482, 0.8922588099364529, 0.6738372093023256, 0.5991983967935872]\n",
      "kmeans average accuracy best : 89.05%, kmeans average accuracy : 89.04557549%, total [0.9735344336937962, 0.9755820556501987, 0.9706643658326143, 0.9637305699481865, 0.967741935483871, 0.9613636363636363, 0.919671650542363, 0.8511060692002269, 0.9663020987289388, 0.9170533642691415, 0.8220046082949308, 0.7340363210310487, 0.925089179548157, 0.8561525129982669, 0.7604651162790698, 0.6827941597480676]\n",
      "cluster_accuracy_post_training_cycle_all_dataset : [0.97634816 0.97549482 0.97207511 0.96480231 0.9681592  0.95660377\n",
      " 0.92491298 0.84619003 0.95864851 0.91943359 0.80888031 0.74478649\n",
      " 0.92668024 0.85548012 0.77892157 0.49641663]\n",
      "mean_cluster_accuracy_during_training_cycle : 87.83%, post_traincycle_acc : 87.96%, total_acc : 87.90623627%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 89.07%\n",
      "accuracy_check 실행 시간: 31.167초\n",
      "\n",
      "\n",
      "epoch-6 loss : 0.01531374, loss_normal : 0.01576526, loss_coarse : 0.07450909, min_loss : 0.01531374, min_loss_normal : 0.01576526, min_loss_coarse : 0.07450909, wrong_element_sum : 14305746.00000000, same_data : 0.00%\n",
      "ae train 실행 시간: 119.061초, 전체 시작 시간 20250312_164918_659\n",
      "\n",
      "epoch-6 accuracy check\n",
      "k_means origin feature average accuracy : 82.25864832%, total [0.9746727376209448, 0.9733106189664963, 0.9700891573195284, 0.9530800230282096, 0.943108504398827, 0.9150568181818182, 0.801817648783348, 0.6622234826999432, 0.9488619568430388, 0.822215777262181, 0.5872695852534562, 0.5005858230814294, 0.9429250891795482, 0.8922588099364529, 0.6747093023255814, 0.5991983967935872]\n",
      "kmeans average accuracy best : 89.05%, kmeans average accuracy : 88.94964601%, total [0.9723961297666477, 0.9744463373083475, 0.9703767615760713, 0.9585492227979274, 0.9636363636363636, 0.9542613636363636, 0.9067722075637643, 0.8340896199659671, 0.9639373337274608, 0.8900812064965197, 0.8130760368663594, 0.7334504979496193, 0.9435196195005945, 0.8911034084344309, 0.7854651162790698, 0.6767821356999714]\n",
      "cluster_accuracy_post_training_cycle_all_dataset : [0.97445601 0.97408106 0.97111218 0.96142719 0.96169154 0.94716981\n",
      " 0.90701144 0.81373471 0.94099849 0.88232422 0.80019305 0.73237339\n",
      " 0.9404277  0.89912706 0.81666667 0.66364071]\n",
      "mean_cluster_accuracy_during_training_cycle : 88.50%, post_traincycle_acc : 88.67%, total_acc : 88.59466459%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 89.07%\n",
      "accuracy_check 실행 시간: 30.818초\n",
      "\n",
      "\n",
      "epoch-7 loss : 0.01514100, loss_normal : 0.01575189, loss_coarse : 0.07439921, min_loss : 0.01514100, min_loss_normal : 0.01575189, min_loss_coarse : 0.07439921, wrong_element_sum : 14284648.00000000, same_data : 0.00%\n",
      "ae train 실행 시간: 118.755초, 전체 시작 시간 20250312_164918_659\n",
      "\n",
      "epoch-7 accuracy check\n",
      "k_means origin feature average accuracy : 82.25313798%, total [0.9746727376209448, 0.9733106189664963, 0.9700891573195284, 0.9530800230282096, 0.943108504398827, 0.9150568181818182, 0.8015244796247435, 0.6625070901871809, 0.9488619568430388, 0.822215777262181, 0.5872695852534562, 0.5005858230814294, 0.9429250891795482, 0.8922588099364529, 0.6738372093023256, 0.5991983967935872]\n",
      "kmeans average accuracy best : 89.05%, kmeans average accuracy : 88.65497698%, total [0.974957313602732, 0.9770017035775128, 0.9712395743457003, 0.9620034542314335, 0.9653958944281525, 0.9539772727272727, 0.9123424215772501, 0.8278502552467385, 0.967188885604493, 0.9054524361948956, 0.8191244239631337, 0.7562975981253661, 0.9268727705112961, 0.8665511265164645, 0.7566860465116279, 0.6418551388491268]\n",
      "cluster_accuracy_post_training_cycle_all_dataset : [0.97682119 0.97690858 0.97159364 0.96480231 0.96517413 0.95235849\n",
      " 0.90203879 0.81420508 0.96419566 0.91845703 0.81563707 0.75422046\n",
      " 0.91598778 0.87875849 0.80931373 0.64357382]\n",
      "mean_cluster_accuracy_during_training_cycle : 88.23%, post_traincycle_acc : 88.90%, total_acc : 88.62641781%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 89.07%\n",
      "accuracy_check 실행 시간: 24.093초\n",
      "\n",
      "\n",
      "epoch-8 loss : 0.01501565, loss_normal : 0.01575361, loss_coarse : 0.07430613, min_loss : 0.01501565, min_loss_normal : 0.01575189, min_loss_coarse : 0.07430613, wrong_element_sum : 14266778.00000000, same_data : 0.00%\n",
      "ae train 실행 시간: 119.853초, 전체 시작 시간 20250312_164918_659\n",
      "\n",
      "epoch-8 accuracy check\n",
      "k_means origin feature average accuracy : 82.25492108%, total [0.9746727376209448, 0.9733106189664963, 0.9700891573195284, 0.9530800230282096, 0.943108504398827, 0.9150568181818182, 0.801817648783348, 0.6625070901871809, 0.9488619568430388, 0.822215777262181, 0.5866935483870968, 0.5005858230814294, 0.9429250891795482, 0.8922588099364529, 0.673546511627907, 0.6000572573718866]\n",
      "kmeans average accuracy best : 89.05%, kmeans average accuracy : 89.04558213%, total [0.9743881616391576, 0.9750141964792731, 0.9709519700891573, 0.9643062751871042, 0.9627565982404692, 0.9534090909090909, 0.9132219290530637, 0.7941009642654566, 0.9612769731007981, 0.8953016241299304, 0.8090437788018433, 0.7167545401288811, 0.9476813317479191, 0.8971692663200462, 0.8136627906976744, 0.6982536501574578]\n",
      "cluster_accuracy_post_training_cycle_all_dataset : [0.97634816 0.97408106 0.97014925 0.96528447 0.96119403 0.94528302\n",
      " 0.91098956 0.80056444 0.9591528  0.89794922 0.80550193 0.73485601\n",
      " 0.93940937 0.90591659 0.82303922 0.70998567]\n",
      "mean_cluster_accuracy_during_training_cycle : 88.71%, post_traincycle_acc : 89.25%, total_acc : 89.02754878%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 89.07%\n",
      "accuracy_check 실행 시간: 30.367초\n",
      "\n",
      "\n",
      "epoch-9 loss : 0.01490476, loss_normal : 0.01567066, loss_coarse : 0.07397123, min_loss : 0.01490476, min_loss_normal : 0.01567066, min_loss_coarse : 0.07397123, wrong_element_sum : 14202476.00000000, same_data : 0.00%\n",
      "ae train 실행 시간: 121.360초, 전체 시작 시간 20250312_164918_659\n",
      "\n",
      "epoch-9 accuracy check\n",
      "k_means origin feature average accuracy : 82.26041597%, total [0.9746727376209448, 0.9733106189664963, 0.9700891573195284, 0.9530800230282096, 0.943108504398827, 0.9150568181818182, 0.801817648783348, 0.6622234826999432, 0.9488619568430388, 0.822215777262181, 0.5866935483870968, 0.5005858230814294, 0.9429250891795482, 0.8922588099364529, 0.6747093023255814, 0.6000572573718866]\n",
      "save model\n",
      "kmeans average accuracy best : 89.20%, kmeans average accuracy : 89.19702855%, total [0.9746727376209448, 0.97671777399205, 0.9729651998849583, 0.9645941278065631, 0.9659824046920821, 0.9525568181818181, 0.8994429785986514, 0.8077141236528644, 0.9515223174697014, 0.8839907192575406, 0.8015552995391705, 0.7527826596367897, 0.9247919143876338, 0.8954361640670133, 0.8107558139534884, 0.7360435156026338]\n",
      "cluster_accuracy_post_training_cycle_all_dataset : [0.97682119 0.97737983 0.97255657 0.96624879 0.96467662 0.9504717\n",
      " 0.89855793 0.78033866 0.90065557 0.90527344 0.78812741 0.74826216\n",
      " 0.92769857 0.90688652 0.8127451  0.73913043]\n",
      "mean_cluster_accuracy_during_training_cycle : 87.93%, post_traincycle_acc : 88.85%, total_acc : 88.47209510%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 88.85%\n",
      "accuracy_check 실행 시간: 30.910초\n",
      "\n",
      "\n",
      "epoch-10 loss : 0.01474284, loss_normal : 0.01561545, loss_coarse : 0.07368156, min_loss : 0.01474284, min_loss_normal : 0.01561545, min_loss_coarse : 0.07368156, wrong_element_sum : 14146860.00000000, same_data : 0.00%\n",
      "ae train 실행 시간: 120.746초, 전체 시작 시간 20250312_164918_659\n",
      "\n",
      "epoch-10 accuracy check\n",
      "k_means origin feature average accuracy : 82.25682064%, total [0.9746727376209448, 0.9733106189664963, 0.9700891573195284, 0.9530800230282096, 0.943108504398827, 0.9150568181818182, 0.801817648783348, 0.6625070901871809, 0.9488619568430388, 0.822215777262181, 0.5866935483870968, 0.5005858230814294, 0.9429250891795482, 0.8922588099364529, 0.6747093023255814, 0.5991983967935872]\n",
      "kmeans average accuracy best : 89.20%, kmeans average accuracy : 88.78290336%, total [0.9738190096755834, 0.9755820556501987, 0.9718147828587863, 0.9643062751871042, 0.9621700879765396, 0.9517045454545454, 0.9082380533567869, 0.7773681225184345, 0.9512267218445167, 0.8744199535962877, 0.798963133640553, 0.7352079671939075, 0.9461950059453033, 0.8948584633160023, 0.7968023255813953, 0.7225880332092757]\n",
      "cluster_accuracy_post_training_cycle_all_dataset : [0.97587512 0.97502356 0.97303804 0.96576663 0.96169154 0.9490566\n",
      " 0.9075087  0.72718721 0.93595562 0.87158203 0.77992278 0.73237339\n",
      " 0.95010183 0.89524733 0.82598039 0.72861921]\n",
      "mean_cluster_accuracy_during_training_cycle : 88.42%, post_traincycle_acc : 88.47%, total_acc : 88.44059671%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 88.85%\n",
      "accuracy_check 실행 시간: 31.311초\n",
      "\n",
      "\n",
      "epoch-11 loss : 0.01471150, loss_normal : 0.01564459, loss_coarse : 0.07368745, min_loss : 0.01471150, min_loss_normal : 0.01561545, min_loss_coarse : 0.07368156, wrong_element_sum : 14147990.00000000, same_data : 0.00%\n",
      "ae train 실행 시간: 120.452초, 전체 시작 시간 20250312_164918_659\n",
      "\n",
      "epoch-11 accuracy check\n",
      "k_means origin feature average accuracy : 82.25131332%, total [0.9746727376209448, 0.9733106189664963, 0.9700891573195284, 0.9530800230282096, 0.943108504398827, 0.915340909090909, 0.8015244796247435, 0.6625070901871809, 0.9488619568430388, 0.822215777262181, 0.5866935483870968, 0.5005858230814294, 0.9429250891795482, 0.8922588099364529, 0.6738372093023256, 0.5991983967935872]\n",
      "save model\n",
      "kmeans average accuracy best : 89.27%, kmeans average accuracy : 89.27258886%, total [0.9743881616391576, 0.9750141964792731, 0.9709519700891573, 0.9631548647092688, 0.9653958944281525, 0.95625, 0.9070653767223688, 0.7946681792399319, 0.9524091043452557, 0.896461716937355, 0.8214285714285714, 0.7217340363210311, 0.9461950059453033, 0.8980358174465627, 0.8081395348837209, 0.7323217864300029]\n",
      "cluster_accuracy_post_training_cycle_all_dataset : [0.97587512 0.97455231 0.97063072 0.96432015 0.96616915 0.95330189\n",
      " 0.91546494 0.80291627 0.93343419 0.91210938 0.80791506 0.74528302\n",
      " 0.94450102 0.89524733 0.82352941 0.72718586]\n",
      "mean_cluster_accuracy_during_training_cycle : 89.28%, post_traincycle_acc : 89.45%, total_acc : 89.38056756%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 89.45%\n",
      "accuracy_check 실행 시간: 25.267초\n",
      "\n",
      "\n",
      "epoch-12 loss : 0.01495846, loss_normal : 0.01569541, loss_coarse : 0.07403200, min_loss : 0.01471150, min_loss_normal : 0.01561545, min_loss_coarse : 0.07368156, wrong_element_sum : 14214144.00000000, same_data : 0.00%\n",
      "ae train 실행 시간: 112.963초, 전체 시작 시간 20250312_164918_659\n",
      "\n",
      "epoch-12 accuracy check\n",
      "k_means origin feature average accuracy : 82.25849966%, total [0.9746727376209448, 0.9733106189664963, 0.9700891573195284, 0.9530800230282096, 0.943108504398827, 0.9150568181818182, 0.801817648783348, 0.6625070901871809, 0.9488619568430388, 0.822215777262181, 0.5866935483870968, 0.5005858230814294, 0.9429250891795482, 0.8922588099364529, 0.673546511627907, 0.600629831090753]\n",
      "kmeans average accuracy best : 89.27%, kmeans average accuracy : 87.85277820%, total [0.9732498577120091, 0.9741624077228848, 0.9692263445498993, 0.9628670120898101, 0.9612903225806452, 0.9534090909090909, 0.8938727645851656, 0.7456040839478162, 0.9355601537097251, 0.8924013921113689, 0.815668202764977, 0.6933216168717048, 0.9381688466111772, 0.8717504332755632, 0.7790697674418605, 0.696822215860292]\n",
      "cluster_accuracy_post_training_cycle_all_dataset : [0.97445601 0.9736098  0.96966779 0.96335583 0.96169154 0.94811321\n",
      " 0.89955246 0.71542803 0.91477559 0.89941406 0.78426641 0.7408143\n",
      " 0.93380855 0.88312318 0.80588235 0.72814142]\n",
      "mean_cluster_accuracy_during_training_cycle : 88.04%, post_traincycle_acc : 88.10%, total_acc : 88.07302211%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 89.45%\n",
      "accuracy_check 실행 시간: 29.610초\n",
      "\n",
      "\n",
      "epoch-13 loss : 0.01445147, loss_normal : 0.01556124, loss_coarse : 0.07315303, min_loss : 0.01445147, min_loss_normal : 0.01556124, min_loss_coarse : 0.07315303, wrong_element_sum : 14045382.00000000, same_data : 0.00%\n",
      "ae train 실행 시간: 117.486초, 전체 시작 시간 20250312_164918_659\n",
      "\n",
      "epoch-13 accuracy check\n",
      "k_means origin feature average accuracy : 82.26209829%, total [0.9746727376209448, 0.9733106189664963, 0.9700891573195284, 0.9530800230282096, 0.943108504398827, 0.915340909090909, 0.8015244796247435, 0.6625070901871809, 0.9488619568430388, 0.822215777262181, 0.5872695852534562, 0.5005858230814294, 0.9429250891795482, 0.8922588099364529, 0.6741279069767442, 0.6000572573718866]\n",
      "kmeans average accuracy best : 89.27%, kmeans average accuracy : 89.09365034%, total [0.9755264655663062, 0.9755820556501987, 0.9709519700891573, 0.9605641911341393, 0.9624633431085043, 0.9505681818181818, 0.8947522720609792, 0.7841747022121384, 0.8965415311853384, 0.880800464037123, 0.8222926267281107, 0.7601054481546573, 0.9503567181926278, 0.9087232813402657, 0.8226744186046512, 0.7389063841969653]\n",
      "cluster_accuracy_post_training_cycle_all_dataset : [0.9782403  0.97549482 0.97111218 0.96335583 0.96218905 0.94292453\n",
      " 0.90303332 0.74035748 0.87392839 0.85986328 0.79391892 0.76812314\n",
      " 0.9490835  0.90446169 0.82941176 0.75967511]\n",
      "mean_cluster_accuracy_during_training_cycle : 87.93%, post_traincycle_acc : 88.59%, total_acc : 88.32097595%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 89.45%\n",
      "accuracy_check 실행 시간: 28.785초\n",
      "\n",
      "\n",
      "epoch-14 loss : 0.01433786, loss_normal : 0.01551242, loss_coarse : 0.07296557, min_loss : 0.01433786, min_loss_normal : 0.01551242, min_loss_coarse : 0.07296557, wrong_element_sum : 14009390.00000000, same_data : 0.00%\n",
      "ae train 실행 시간: 117.734초, 전체 시작 시간 20250312_164918_659\n",
      "\n",
      "epoch-14 accuracy check\n",
      "k_means origin feature average accuracy : 82.25674876%, total [0.9746727376209448, 0.9733106189664963, 0.9700891573195284, 0.9530800230282096, 0.943108504398827, 0.9150568181818182, 0.801817648783348, 0.6622234826999432, 0.9488619568430388, 0.822215777262181, 0.5872695852534562, 0.5005858230814294, 0.9429250891795482, 0.8922588099364529, 0.673546511627907, 0.6000572573718866]\n",
      "save model\n",
      "kmeans average accuracy best : 89.55%, kmeans average accuracy : 89.55133635%, total [0.9723961297666477, 0.9747302668938104, 0.9698015530629853, 0.9591249280368451, 0.9653958944281525, 0.9599431818181818, 0.9141014365288772, 0.8125354509359047, 0.9284658587052912, 0.900522041763341, 0.8346774193548387, 0.7360867018160515, 0.9536266349583828, 0.901790872328134, 0.8063953488372093, 0.7386200973375322]\n",
      "cluster_accuracy_post_training_cycle_all_dataset : [0.97161779 0.97455231 0.96918633 0.96094503 0.96218905 0.95424528\n",
      " 0.91944306 0.7826905  0.9183056  0.89550781 0.82239382 0.77259186\n",
      " 0.94857434 0.90494665 0.80833333 0.75441949]\n",
      "mean_cluster_accuracy_during_training_cycle : 89.33%, post_traincycle_acc : 89.50%, total_acc : 89.42949048%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 89.50%\n",
      "accuracy_check 실행 시간: 30.037초\n",
      "\n",
      "\n",
      "epoch-15 loss : 0.01441876, loss_normal : 0.01553730, loss_coarse : 0.07316713, min_loss : 0.01433786, min_loss_normal : 0.01551242, min_loss_coarse : 0.07296557, wrong_element_sum : 14048090.00000000, same_data : 0.00%\n",
      "ae train 실행 시간: 118.869초, 전체 시작 시간 20250312_164918_659\n",
      "\n",
      "epoch-15 accuracy check\n",
      "k_means origin feature average accuracy : 82.26393350%, total [0.9746727376209448, 0.9733106189664963, 0.9700891573195284, 0.9530800230282096, 0.943108504398827, 0.9150568181818182, 0.801817648783348, 0.6622234826999432, 0.9488619568430388, 0.822215777262181, 0.5872695852534562, 0.5005858230814294, 0.9429250891795482, 0.8922588099364529, 0.6738372093023256, 0.6009161179501861]\n",
      "save model\n",
      "kmeans average accuracy best : 89.77%, kmeans average accuracy : 89.76873644%, total [0.974957313602732, 0.9764338444065872, 0.9726775956284153, 0.9640184225676454, 0.964516129032258, 0.9559659090909091, 0.9047200234535326, 0.7960862166761202, 0.9728052024830033, 0.9338747099767981, 0.8384216589861752, 0.7612770943175161, 0.9301426872770512, 0.8965915655690352, 0.813953488372093, 0.7065559690810191]\n",
      "cluster_accuracy_post_training_cycle_all_dataset : [0.97729423 0.97690858 0.97303804 0.96576663 0.96218905 0.95377358\n",
      " 0.90551964 0.74270931 0.9667171  0.93994141 0.82480695 0.76514399\n",
      " 0.93533605 0.8971872  0.82647059 0.71380793]\n",
      "mean_cluster_accuracy_during_training_cycle : 89.45%, post_traincycle_acc : 89.54%, total_acc : 89.49880391%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 89.54%\n",
      "accuracy_check 실행 시간: 31.355초\n",
      "\n",
      "\n",
      "epoch-16 loss : 0.01428796, loss_normal : 0.01552812, loss_coarse : 0.07296150, min_loss : 0.01428796, min_loss_normal : 0.01551242, min_loss_coarse : 0.07296150, wrong_element_sum : 14008608.00000000, same_data : 0.00%\n",
      "ae train 실행 시간: 113.442초, 전체 시작 시간 20250312_164918_659\n",
      "\n",
      "epoch-16 accuracy check\n",
      "k_means origin feature average accuracy : 82.24242650%, total [0.9746727376209448, 0.9733106189664963, 0.9700891573195284, 0.9530800230282096, 0.943108504398827, 0.9150568181818182, 0.801817648783348, 0.6622234826999432, 0.9488619568430388, 0.822215777262181, 0.5866935483870968, 0.5002929115407148, 0.9429250891795482, 0.8922588099364529, 0.6741279069767442, 0.5980532493558546]\n",
      "kmeans average accuracy best : 89.77%, kmeans average accuracy : 89.75431372%, total [0.974957313602732, 0.9758659852356616, 0.9718147828587863, 0.9622913068508924, 0.9642228739002933, 0.9539772727272727, 0.9108765757842275, 0.7824730572887124, 0.9665976943541236, 0.894431554524362, 0.8243087557603687, 0.7568834212067955, 0.953923900118906, 0.9061236279607163, 0.8276162790697674, 0.734325794446035]\n",
      "cluster_accuracy_post_training_cycle_all_dataset : [0.97729423 0.97596607 0.97111218 0.96383799 0.96119403 0.94858491\n",
      " 0.90850323 0.76810913 0.94654564 0.87695312 0.79874517 0.77110228\n",
      " 0.94602851 0.90543162 0.83921569 0.73005256]\n",
      "mean_cluster_accuracy_during_training_cycle : 89.29%, post_traincycle_acc : 89.30%, total_acc : 89.29609727%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 89.54%\n",
      "accuracy_check 실행 시간: 23.006초\n",
      "\n",
      "\n",
      "epoch-17 loss : 0.01420163, loss_normal : 0.01548141, loss_coarse : 0.07278274, min_loss : 0.01420163, min_loss_normal : 0.01548141, min_loss_coarse : 0.07278274, wrong_element_sum : 13974286.00000000, same_data : 0.00%\n",
      "ae train 실행 시간: 119.037초, 전체 시작 시간 20250312_164918_659\n",
      "\n",
      "epoch-17 accuracy check\n",
      "k_means origin feature average accuracy : 82.26035782%, total [0.9746727376209448, 0.9733106189664963, 0.9700891573195284, 0.9530800230282096, 0.943108504398827, 0.9150568181818182, 0.801817648783348, 0.6625070901871809, 0.9488619568430388, 0.822215777262181, 0.5866935483870968, 0.5002929115407148, 0.9429250891795482, 0.8922588099364529, 0.6747093023255814, 0.6000572573718866]\n",
      "kmeans average accuracy best : 89.77%, kmeans average accuracy : 88.86579551%, total [0.9741035856573705, 0.9747302668938104, 0.9715271786022434, 0.9640184225676454, 0.9624633431085043, 0.9522727272727273, 0.9149809440046907, 0.7821894498014748, 0.9665976943541236, 0.9069025522041764, 0.8136520737327189, 0.7442882249560633, 0.929845422116528, 0.8809936452917388, 0.7831395348837209, 0.696822215860292]\n",
      "cluster_accuracy_post_training_cycle_all_dataset : [0.97729423 0.97502356 0.97063072 0.96432015 0.96069652 0.94858491\n",
      " 0.91397315 0.73706491 0.94351992 0.90527344 0.79874517 0.7591857\n",
      " 0.92718941 0.88312318 0.80343137 0.70186335]\n",
      "mean_cluster_accuracy_during_training_cycle : 88.58%, post_traincycle_acc : 88.56%, total_acc : 88.56744258%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 89.54%\n",
      "accuracy_check 실행 시간: 30.142초\n",
      "\n",
      "\n",
      "epoch-18 loss : 0.01414327, loss_normal : 0.01545952, loss_coarse : 0.07265827, min_loss : 0.01414327, min_loss_normal : 0.01545952, min_loss_coarse : 0.07265827, wrong_element_sum : 13950388.00000000, same_data : 0.00%\n",
      "ae train 실행 시간: 120.543초, 전체 시작 시간 20250312_164918_659\n",
      "\n",
      "epoch-18 accuracy check\n",
      "k_means origin feature average accuracy : 82.24421289%, total [0.9746727376209448, 0.9733106189664963, 0.9700891573195284, 0.9530800230282096, 0.943108504398827, 0.9150568181818182, 0.801817648783348, 0.6625070901871809, 0.9488619568430388, 0.822215777262181, 0.5866935483870968, 0.5005858230814294, 0.9429250891795482, 0.8922588099364529, 0.6738372093023256, 0.5980532493558546]\n",
      "kmeans average accuracy best : 89.77%, kmeans average accuracy : 88.07664782%, total [0.9738190096755834, 0.975298126064736, 0.9706643658326143, 0.9608520437535981, 0.9586510263929618, 0.9420454545454545, 0.890647903840516, 0.7697107203630176, 0.9388117055867573, 0.87122969837587, 0.7845622119815668, 0.7299355594610427, 0.9444114149821641, 0.9026574234546505, 0.8119186046511628, 0.6670483824792443]\n",
      "cluster_accuracy_post_training_cycle_all_dataset : [0.97587512 0.97455231 0.96966779 0.96142719 0.95820896 0.93632075\n",
      " 0.88314272 0.76152399 0.90368129 0.86328125 0.77702703 0.73535253\n",
      " 0.94755601 0.92240543 0.82401961 0.72049689]\n",
      "mean_cluster_accuracy_during_training_cycle : 88.04%, post_traincycle_acc : 88.22%, total_acc : 88.14257920%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 89.54%\n",
      "accuracy_check 실행 시간: 31.593초\n",
      "\n",
      "\n",
      "epoch-19 loss : 0.01416277, loss_normal : 0.01549612, loss_coarse : 0.07282266, min_loss : 0.01414327, min_loss_normal : 0.01545952, min_loss_coarse : 0.07265827, wrong_element_sum : 13981952.00000000, same_data : 0.00%\n",
      "ae train 실행 시간: 120.461초, 전체 시작 시간 20250312_164918_659\n",
      "\n",
      "epoch-19 accuracy check\n",
      "k_means origin feature average accuracy : 82.26218852%, total [0.9746727376209448, 0.9733106189664963, 0.9700891573195284, 0.9530800230282096, 0.943108504398827, 0.9150568181818182, 0.801817648783348, 0.6625070901871809, 0.9488619568430388, 0.822215777262181, 0.5866935483870968, 0.5005858230814294, 0.9429250891795482, 0.8922588099364529, 0.6747093023255814, 0.6000572573718866]\n",
      "kmeans average accuracy best : 89.77%, kmeans average accuracy : 88.32138429%, total [0.9715424018212863, 0.9738784781374219, 0.9698015530629853, 0.9591249280368451, 0.966275659824047, 0.9542613636363636, 0.8962181178540017, 0.7606352807714124, 0.9491575524682234, 0.8950116009280742, 0.7932027649769585, 0.7325717633274751, 0.9274673008323424, 0.8879260543038706, 0.7877906976744186, 0.7065559690810191]\n",
      "cluster_accuracy_post_training_cycle_all_dataset : [0.9730369  0.97408106 0.96918633 0.96094503 0.96467662 0.9495283\n",
      " 0.91844853 0.73800564 0.91427131 0.87988281 0.78716216 0.74379345\n",
      " 0.92362525 0.8942774  0.81372549 0.70138557]\n",
      "mean_cluster_accuracy_during_training_cycle : 88.38%, post_traincycle_acc : 88.16%, total_acc : 88.24910832%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 89.54%\n",
      "accuracy_check 실행 시간: 31.417초\n",
      "\n",
      "\n",
      "epoch-20 loss : 0.01420547, loss_normal : 0.01550017, loss_coarse : 0.07275377, min_loss : 0.01414327, min_loss_normal : 0.01545952, min_loss_coarse : 0.07265827, wrong_element_sum : 13968724.00000000, same_data : 0.00%\n",
      "ae train 실행 시간: 121.486초, 전체 시작 시간 20250312_164918_659\n",
      "\n",
      "epoch-20 accuracy check\n",
      "k_means origin feature average accuracy : 82.25682064%, total [0.9746727376209448, 0.9733106189664963, 0.9700891573195284, 0.9530800230282096, 0.943108504398827, 0.9150568181818182, 0.801817648783348, 0.6625070901871809, 0.9488619568430388, 0.822215777262181, 0.5866935483870968, 0.5005858230814294, 0.9429250891795482, 0.8922588099364529, 0.6747093023255814, 0.5991983967935872]\n",
      "kmeans average accuracy best : 89.77%, kmeans average accuracy : 87.62623363%, total [0.9741035856573705, 0.9755820556501987, 0.9706643658326143, 0.9617156016119747, 0.9577712609970674, 0.9369318181818181, 0.8777484608619174, 0.7141236528644356, 0.9302394324563996, 0.8715197215777262, 0.7874423963133641, 0.7331575864089045, 0.9509512485136742, 0.9046793760831889, 0.795639534883721, 0.677927283137704]\n",
      "cluster_accuracy_post_training_cycle_all_dataset : [0.97634816 0.97502356 0.97014925 0.96190935 0.95721393 0.92358491\n",
      " 0.876181   0.76058325 0.88754413 0.86669922 0.77027027 0.72889772\n",
      " 0.94755601 0.90931135 0.82303922 0.67749642]\n",
      "mean_cluster_accuracy_during_training_cycle : 87.04%, post_traincycle_acc : 87.57%, total_acc : 87.35054317%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 89.54%\n",
      "accuracy_check 실행 시간: 23.719초\n",
      "\n",
      "\n",
      "epoch-21 loss : 0.01420316, loss_normal : 0.01549868, loss_coarse : 0.07282269, min_loss : 0.01414327, min_loss_normal : 0.01545952, min_loss_coarse : 0.07265827, wrong_element_sum : 13981956.00000000, same_data : 0.00%\n",
      "ae train 실행 시간: 117.145초, 전체 시작 시간 20250312_164918_659\n",
      "\n",
      "epoch-21 accuracy check\n",
      "k_means origin feature average accuracy : 82.25313798%, total [0.9746727376209448, 0.9733106189664963, 0.9700891573195284, 0.9530800230282096, 0.943108504398827, 0.9150568181818182, 0.8015244796247435, 0.6625070901871809, 0.9488619568430388, 0.822215777262181, 0.5872695852534562, 0.5005858230814294, 0.9429250891795482, 0.8922588099364529, 0.6738372093023256, 0.5991983967935872]\n",
      "kmeans average accuracy best : 89.77%, kmeans average accuracy : 87.91792757%, total [0.9743881616391576, 0.9755820556501987, 0.9706643658326143, 0.9605641911341393, 0.9577712609970674, 0.9400568181818182, 0.8745236001172677, 0.7376630743051616, 0.9204847768253029, 0.8825406032482599, 0.8113479262672811, 0.7583479789103691, 0.9429250891795482, 0.8879260543038706, 0.7921511627906976, 0.6799312911537361]\n",
      "cluster_accuracy_post_training_cycle_all_dataset : [0.97587512 0.97502356 0.97159364 0.96239151 0.95870647 0.92688679\n",
      " 0.89060169 0.73095014 0.90166415 0.88769531 0.78378378 0.75074479\n",
      " 0.93380855 0.89233754 0.81764706 0.7147635 ]\n",
      "mean_cluster_accuracy_during_training_cycle : 87.53%, post_traincycle_acc : 87.97%, total_acc : 87.78637469%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 89.54%\n",
      "accuracy_check 실행 시간: 30.077초\n",
      "\n",
      "\n",
      "epoch-22 loss : 0.01419206, loss_normal : 0.01546573, loss_coarse : 0.07264507, min_loss : 0.01414327, min_loss_normal : 0.01545952, min_loss_coarse : 0.07264507, wrong_element_sum : 13947854.00000000, same_data : 0.00%\n",
      "ae train 실행 시간: 120.696초, 전체 시작 시간 20250312_164918_659\n",
      "\n",
      "epoch-22 accuracy check\n",
      "k_means origin feature average accuracy : 82.25492108%, total [0.9746727376209448, 0.9733106189664963, 0.9700891573195284, 0.9530800230282096, 0.943108504398827, 0.9150568181818182, 0.801817648783348, 0.6625070901871809, 0.9488619568430388, 0.822215777262181, 0.5866935483870968, 0.5005858230814294, 0.9429250891795482, 0.8922588099364529, 0.673546511627907, 0.6000572573718866]\n",
      "kmeans average accuracy best : 89.77%, kmeans average accuracy : 88.09874535%, total [0.9741035856573705, 0.9744463373083475, 0.9698015530629853, 0.9631548647092688, 0.9586510263929618, 0.9417613636363636, 0.8970976253298153, 0.7507090187180941, 0.950931126219332, 0.8921113689095128, 0.8006912442396313, 0.7314001171646163, 0.9435196195005945, 0.8844598497978048, 0.7758720930232558, 0.6870884626395648]\n",
      "cluster_accuracy_post_training_cycle_all_dataset : [0.97634816 0.97455231 0.96870486 0.96335583 0.960199   0.93301887\n",
      " 0.88015912 0.72201317 0.92233989 0.90576172 0.77316602 0.73535253\n",
      " 0.93788187 0.88942774 0.78872549 0.64022934]\n",
      "mean_cluster_accuracy_during_training_cycle : 87.88%, post_traincycle_acc : 87.32%, total_acc : 87.54259268%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 89.54%\n",
      "accuracy_check 실행 시간: 30.139초\n",
      "\n",
      "\n",
      "epoch-23 loss : 0.01395675, loss_normal : 0.01540346, loss_coarse : 0.07225949, min_loss : 0.01395675, min_loss_normal : 0.01540346, min_loss_coarse : 0.07225949, wrong_element_sum : 13873822.00000000, same_data : 0.00%\n",
      "ae train 실행 시간: 118.632초, 전체 시작 시간 20250312_164918_659\n",
      "\n",
      "epoch-23 accuracy check\n",
      "k_means origin feature average accuracy : 82.25680680%, total [0.9746727376209448, 0.9733106189664963, 0.9700891573195284, 0.9530800230282096, 0.943108504398827, 0.9150568181818182, 0.801817648783348, 0.6625070901871809, 0.9488619568430388, 0.822215777262181, 0.5866935483870968, 0.5002929115407148, 0.9429250891795482, 0.8922588099364529, 0.675, 0.5991983967935872]\n",
      "kmeans average accuracy best : 89.77%, kmeans average accuracy : 88.21547378%, total [0.9732498577120091, 0.9738784781374219, 0.9703767615760713, 0.959412780656304, 0.9583577712609971, 0.9394886363636363, 0.8666080328349458, 0.7697107203630176, 0.9311262193319539, 0.8950116009280742, 0.8113479262672811, 0.7615700058582309, 0.9441141498216409, 0.8957250144425187, 0.7828488372093023, 0.6816490123103349]\n",
      "cluster_accuracy_post_training_cycle_all_dataset : [0.97492904 0.97408106 0.96870486 0.96094503 0.95721393 0.93349057\n",
      " 0.88662357 0.75399812 0.92738275 0.88916016 0.78474903 0.76017875\n",
      " 0.94093686 0.89621726 0.8122549  0.69469661]\n",
      "mean_cluster_accuracy_during_training_cycle : 87.89%, post_traincycle_acc : 88.22%, total_acc : 88.08229365%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 89.54%\n",
      "accuracy_check 실행 시간: 29.842초\n",
      "\n",
      "\n",
      "epoch-24 loss : 0.01398217, loss_normal : 0.01542284, loss_coarse : 0.07237061, min_loss : 0.01395675, min_loss_normal : 0.01540346, min_loss_coarse : 0.07225949, wrong_element_sum : 13895158.00000000, same_data : 0.00%\n",
      "ae train 실행 시간: 117.883초, 전체 시작 시간 20250312_164918_659\n",
      "\n",
      "epoch-24 accuracy check\n",
      "k_means origin feature average accuracy : 82.26215805%, total [0.9746727376209448, 0.9733106189664963, 0.9700891573195284, 0.9530800230282096, 0.943108504398827, 0.915340909090909, 0.801817648783348, 0.6622234826999432, 0.9488619568430388, 0.822215777262181, 0.5872695852534562, 0.5005858230814294, 0.9429250891795482, 0.8922588099364529, 0.6741279069767442, 0.6000572573718866]\n",
      "kmeans average accuracy best : 89.77%, kmeans average accuracy : 88.19724336%, total [0.9746727376209448, 0.9758659852356616, 0.9721023871153293, 0.9631548647092688, 0.953958944281525, 0.930965909090909, 0.8742304309586632, 0.7827566647759501, 0.9290570499556606, 0.8813805104408353, 0.7975230414746544, 0.739601640304628, 0.9545184304399524, 0.9121894858463316, 0.797093023255814, 0.6724878328084741]\n",
      "cluster_accuracy_post_training_cycle_all_dataset : [0.97682119 0.97596607 0.97159364 0.96335583 0.95671642 0.92311321\n",
      " 0.87468921 0.69190969 0.91174987 0.86767578 0.77123552 0.73833168\n",
      " 0.95366599 0.92095053 0.81127451 0.6751075 ]\n",
      "mean_cluster_accuracy_during_training_cycle : 87.66%, post_traincycle_acc : 87.40%, total_acc : 87.49928589%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 89.54%\n",
      "accuracy_check 실행 시간: 31.203초\n",
      "\n",
      "\n",
      "epoch-25 loss : 0.01395493, loss_normal : 0.01541123, loss_coarse : 0.07229557, min_loss : 0.01395493, min_loss_normal : 0.01540346, min_loss_coarse : 0.07225949, wrong_element_sum : 13880750.00000000, same_data : 0.00%\n",
      "ae train 실행 시간: 116.105초, 전체 시작 시간 20250312_164918_659\n",
      "\n",
      "epoch-25 accuracy check\n",
      "k_means origin feature average accuracy : 82.26401620%, total [0.9746727376209448, 0.9733106189664963, 0.9700891573195284, 0.9530800230282096, 0.943108504398827, 0.9150568181818182, 0.801817648783348, 0.6622234826999432, 0.9488619568430388, 0.822215777262181, 0.5872695852534562, 0.5005858230814294, 0.9429250891795482, 0.8922588099364529, 0.6747093023255814, 0.6000572573718866]\n",
      "kmeans average accuracy best : 89.77%, kmeans average accuracy : 88.96607559%, total [0.9738190096755834, 0.9750141964792731, 0.9692263445498993, 0.959412780656304, 0.9636363636363636, 0.9517045454545454, 0.8991498094400469, 0.7759500850822462, 0.9571386343482117, 0.904292343387471, 0.8289170506912442, 0.7495606326889279, 0.9444114149821641, 0.8879260543038706, 0.7921511627906976, 0.7022616661895219]\n",
      "cluster_accuracy_post_training_cycle_all_dataset : [0.97492904 0.97408106 0.9682234  0.96046287 0.96169154 0.94764151\n",
      " 0.90452511 0.73659454 0.92990419 0.91748047 0.79584942 0.76216485\n",
      " 0.93991853 0.88797284 0.81029412 0.68705208]\n",
      "mean_cluster_accuracy_during_training_cycle : 88.61%, post_traincycle_acc : 88.49%, total_acc : 88.53838826%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 89.54%\n",
      "accuracy_check 실행 시간: 24.036초\n",
      "\n",
      "\n",
      "epoch-26 loss : 0.01382656, loss_normal : 0.01535683, loss_coarse : 0.07208975, min_loss : 0.01382656, min_loss_normal : 0.01535683, min_loss_coarse : 0.07208975, wrong_element_sum : 13841232.00000000, same_data : 0.00%\n",
      "ae train 실행 시간: 118.338초, 전체 시작 시간 20250312_164918_659\n",
      "\n",
      "epoch-26 accuracy check\n",
      "k_means origin feature average accuracy : 82.25318692%, total [0.9746727376209448, 0.9733106189664963, 0.9700891573195284, 0.9530800230282096, 0.943108504398827, 0.9150568181818182, 0.801817648783348, 0.6625070901871809, 0.9488619568430388, 0.822215777262181, 0.5866935483870968, 0.5005858230814294, 0.9429250891795482, 0.8922588099364529, 0.6741279069767442, 0.5991983967935872]\n",
      "kmeans average accuracy best : 89.77%, kmeans average accuracy : 88.49651762%, total [0.9721115537848606, 0.9730266893810335, 0.9686511360368133, 0.959412780656304, 0.9618768328445748, 0.946590909090909, 0.9032541776605101, 0.7419171866137266, 0.9320130062075082, 0.8842807424593968, 0.8064516129032258, 0.7486818980667839, 0.9536266349583828, 0.9090121317157712, 0.7997093023255814, 0.6988262238763241]\n",
      "cluster_accuracy_post_training_cycle_all_dataset : [0.97256386 0.9736098  0.96774194 0.96142719 0.95920398 0.93915094\n",
      " 0.90551964 0.74459078 0.89510842 0.85058594 0.78571429 0.75273088\n",
      " 0.95010183 0.9185257  0.81470588 0.66316292]\n",
      "mean_cluster_accuracy_during_training_cycle : 87.95%, post_traincycle_acc : 87.84%, total_acc : 87.88040495%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 89.54%\n",
      "accuracy_check 실행 시간: 29.995초\n",
      "\n",
      "\n",
      "epoch-27 loss : 0.01387421, loss_normal : 0.01538744, loss_coarse : 0.07223646, min_loss : 0.01382656, min_loss_normal : 0.01535683, min_loss_coarse : 0.07208975, wrong_element_sum : 13869400.00000000, same_data : 0.00%\n",
      "ae train 실행 시간: 117.358초, 전체 시작 시간 20250312_164918_659\n",
      "\n",
      "epoch-27 accuracy check\n",
      "k_means origin feature average accuracy : 82.25149115%, total [0.9746727376209448, 0.9733106189664963, 0.9700891573195284, 0.9530800230282096, 0.943108504398827, 0.9150568181818182, 0.801817648783348, 0.6622234826999432, 0.9488619568430388, 0.822215777262181, 0.5872695852534562, 0.5005858230814294, 0.9429250891795482, 0.8922588099364529, 0.6747093023255814, 0.5980532493558546]\n",
      "kmeans average accuracy best : 89.77%, kmeans average accuracy : 88.27308990%, total [0.9721115537848606, 0.9744463373083475, 0.9695139488064424, 0.9599884858952217, 0.9598240469208211, 0.9485795454545455, 0.8976839636470243, 0.764322178105502, 0.9562518474726575, 0.9002320185614849, 0.8055875576036866, 0.7144112478031635, 0.9512485136741974, 0.8847487001733102, 0.7802325581395348, 0.6845118809046665]\n",
      "cluster_accuracy_post_training_cycle_all_dataset : [0.9730369  0.9736098  0.9682234  0.96335583 0.95771144 0.94433962\n",
      " 0.89010443 0.73471308 0.91225416 0.90576172 0.77557915 0.75173784\n",
      " 0.9490835  0.89233754 0.78970588 0.68609651]\n",
      "mean_cluster_accuracy_during_training_cycle : 88.25%, post_traincycle_acc : 87.92%, total_acc : 88.05385883%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 89.54%\n",
      "accuracy_check 실행 시간: 32.759초\n",
      "\n",
      "\n",
      "epoch-28 loss : 0.01377074, loss_normal : 0.01536251, loss_coarse : 0.07192445, min_loss : 0.01377074, min_loss_normal : 0.01535683, min_loss_coarse : 0.07192445, wrong_element_sum : 13809494.00000000, same_data : 0.00%\n",
      "ae train 실행 시간: 118.738초, 전체 시작 시간 20250312_164918_659\n",
      "\n",
      "epoch-28 accuracy check\n",
      "k_means origin feature average accuracy : 82.25317990%, total [0.9746727376209448, 0.9733106189664963, 0.9700891573195284, 0.9530800230282096, 0.943108504398827, 0.9150568181818182, 0.8015244796247435, 0.6625070901871809, 0.9488619568430388, 0.8216357308584686, 0.5866935483870968, 0.5005858230814294, 0.9429250891795482, 0.8922588099364529, 0.675, 0.5991983967935872]\n",
      "kmeans average accuracy best : 89.77%, kmeans average accuracy : 87.81407980%, total [0.974957313602732, 0.9750141964792731, 0.9712395743457003, 0.9617156016119747, 0.9583577712609971, 0.9318181818181818, 0.8557607739665787, 0.7660238230289279, 0.9225539462015963, 0.8703596287703016, 0.8047235023041475, 0.7469244288224957, 0.9467895362663495, 0.8827267475447718, 0.7950581395348837, 0.6862296020612654]\n",
      "cluster_accuracy_post_training_cycle_all_dataset : [0.97634816 0.97455231 0.97014925 0.96383799 0.95721393 0.92971698\n",
      " 0.87468921 0.75070555 0.90569844 0.87353516 0.7784749  0.75868918\n",
      " 0.94806517 0.89233754 0.80735294 0.7032967 ]\n",
      "mean_cluster_accuracy_during_training_cycle : 87.30%, post_traincycle_acc : 87.90%, total_acc : 87.65531124%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 89.54%\n",
      "accuracy_check 실행 시간: 31.738초\n",
      "\n",
      "\n",
      "epoch-29 loss : 0.01379473, loss_normal : 0.01533458, loss_coarse : 0.07193475, min_loss : 0.01377074, min_loss_normal : 0.01533458, min_loss_coarse : 0.07192445, wrong_element_sum : 13811472.00000000, same_data : 0.00%\n",
      "ae train 실행 시간: 117.991초, 전체 시작 시간 20250312_164918_659\n",
      "\n",
      "epoch-29 accuracy check\n",
      "k_means origin feature average accuracy : 82.24959751%, total [0.9746727376209448, 0.9733106189664963, 0.9700891573195284, 0.9530800230282096, 0.943108504398827, 0.9150568181818182, 0.801817648783348, 0.6622234826999432, 0.9488619568430388, 0.822215777262181, 0.5866935483870968, 0.5005858230814294, 0.9429250891795482, 0.8922588099364529, 0.6738372093023256, 0.5991983967935872]\n",
      "kmeans average accuracy best : 89.77%, kmeans average accuracy : 88.38294962%, total [0.9743881616391576, 0.9764338444065872, 0.9718147828587863, 0.9625791594703512, 0.9609970674486803, 0.946590909090909, 0.8859571973028437, 0.7623369256948384, 0.9562518474726575, 0.8897911832946636, 0.8032834101382489, 0.7454598711189221, 0.9414387633769322, 0.8902368573079145, 0.7863372093023255, 0.687374749498998]\n",
      "cluster_accuracy_post_training_cycle_all_dataset : [0.97682119 0.97690858 0.97207511 0.96432015 0.95870647 0.94245283\n",
      " 0.88314272 0.72671684 0.96520424 0.85742188 0.7726834  0.76663357\n",
      " 0.93584521 0.89233754 0.80735294 0.70234114]\n",
      "mean_cluster_accuracy_during_training_cycle : 87.67%, post_traincycle_acc : 88.13%, total_acc : 87.94036689%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 89.54%\n",
      "accuracy_check 실행 시간: 27.793초\n",
      "\n",
      "\n",
      "epoch-30 loss : 0.01389974, loss_normal : 0.01537099, loss_coarse : 0.07209586, min_loss : 0.01377074, min_loss_normal : 0.01533458, min_loss_coarse : 0.07192445, wrong_element_sum : 13842406.00000000, same_data : 0.00%\n",
      "ae train 실행 시간: 103.614초, 전체 시작 시간 20250312_164918_659\n",
      "\n",
      "epoch-30 accuracy check\n",
      "k_means origin feature average accuracy : 82.25321579%, total [0.9746727376209448, 0.9733106189664963, 0.9700891573195284, 0.9530800230282096, 0.943108504398827, 0.9150568181818182, 0.8015244796247435, 0.6622234826999432, 0.9488619568430388, 0.822215777262181, 0.5866935483870968, 0.5005858230814294, 0.9429250891795482, 0.8922588099364529, 0.6747093023255814, 0.5991983967935872]\n",
      "kmeans average accuracy best : 89.77%, kmeans average accuracy : 88.24815917%, total [0.9752418895845191, 0.9770017035775128, 0.9721023871153293, 0.9622913068508924, 0.9642228739002933, 0.9491477272727272, 0.891234242157725, 0.7827566647759501, 0.9571386343482117, 0.8909512761020881, 0.8001152073732719, 0.7580550673696543, 0.9343043995243757, 0.8755054881571346, 0.7683139534883721, 0.6613226452905812]\n",
      "cluster_accuracy_post_training_cycle_all_dataset : [0.97729423 0.97690858 0.97111218 0.96335583 0.9641791  0.94622642\n",
      " 0.8990552  0.74929445 0.94200706 0.90966797 0.78330116 0.76564052\n",
      " 0.93584521 0.88360815 0.79264706 0.66555184]\n",
      "mean_cluster_accuracy_during_training_cycle : 87.83%, post_traincycle_acc : 88.29%, total_acc : 88.09822390%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 89.54%\n",
      "accuracy_check 실행 시간: 28.915초\n",
      "\n",
      "\n",
      "epoch-31 loss : 0.01375428, loss_normal : 0.01531931, loss_coarse : 0.07183408, min_loss : 0.01375428, min_loss_normal : 0.01531931, min_loss_coarse : 0.07183408, wrong_element_sum : 13792144.00000000, same_data : 0.00%\n",
      "ae train 실행 시간: 119.589초, 전체 시작 시간 20250312_164918_659\n",
      "\n",
      "epoch-31 accuracy check\n",
      "k_means origin feature average accuracy : 82.25314587%, total [0.9746727376209448, 0.9733106189664963, 0.9700891573195284, 0.9530800230282096, 0.943108504398827, 0.9150568181818182, 0.801817648783348, 0.6625070901871809, 0.9488619568430388, 0.822215777262181, 0.5866935483870968, 0.5005858230814294, 0.942627824019025, 0.8922588099364529, 0.6744186046511628, 0.5991983967935872]\n",
      "kmeans average accuracy best : 89.77%, kmeans average accuracy : 88.34486577%, total [0.9732498577120091, 0.9750141964792731, 0.9706643658326143, 0.9625791594703512, 0.9618768328445748, 0.944034090909091, 0.890647903840516, 0.7572319909245604, 0.9642329293526456, 0.900522041763341, 0.8101958525345622, 0.7164616285881664, 0.9515457788347206, 0.8974581166955518, 0.7906976744186046, 0.6687661036358431]\n",
      "cluster_accuracy_post_training_cycle_all_dataset : [0.97587512 0.97502356 0.97014925 0.96335583 0.95920398 0.93867925\n",
      " 0.88861263 0.76152399 0.93595562 0.91748047 0.79681467 0.76812314\n",
      " 0.95162933 0.87875849 0.80392157 0.67367415]\n",
      "mean_cluster_accuracy_during_training_cycle : 88.29%, post_traincycle_acc : 88.49%, total_acc : 88.40556910%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 89.54%\n",
      "accuracy_check 실행 시간: 30.602초\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "gpu = '3'\n",
    "Conv_net = True # True False\n",
    "SAE_net = True # True False\n",
    "\n",
    "# hyperparameter\n",
    "dataset_num = 16\n",
    "spike_length = 50 # coarse_com_mode일 때는 time step이 됨.\n",
    "num_cluster = 4  # 클러스터 수 설정 # 논문엔 4개라는데 여기서는 3개로 했네\n",
    "training_cycle = 1400 #1400 2400 # 그 초기 몇개까지만 cluster update할지\n",
    "\n",
    "\n",
    "batch_size = 32\n",
    "max_epoch = 10000\n",
    "learning_rate = 0.001\n",
    "normalize_on = True # True or False # 0부터1까지 normalize\n",
    "need_bias = False\n",
    "# first_layer_no_train = False\n",
    "lif_add_at_first = False\n",
    "my_seed = 42\n",
    "\n",
    "TIME = 50 # SAE일 때만 유효. coarse_com_mode일 때는 level_num이 됨. 즉 feature 개수.\n",
    "v_decay = 0.5 # -cor\n",
    "v_threshold = 0.25 # -cor\n",
    "v_reset = 0.0 # -cor # 10000이상 일 시 hard reset\n",
    "BPTT_on = True # +cor # True False\n",
    "\n",
    "SAE_hidden_nomean = True # True False\n",
    "\n",
    "current_time = datetime.datetime.now().strftime(\"%Y%m%d_%H%M%S\") + f\"_{str(int(datetime.datetime.now().microsecond / 1000)).zfill(3)}\"\n",
    "\n",
    "optimizer = 'Adam' #'Adam', 'SGD' # 둘다 준수함. loss 줄이는 거는 adam이 좋긴한데, cluster accuracy는 비슷함.\n",
    "\n",
    "coarse_com_mode = True # True False\n",
    "coarse_com_config = (0.999, -0.0) # (max, min) (0.999, -0.0) (1.0, -0.0) (2.0, -2.0) (3.0, -3.0)\n",
    "\n",
    "sae_l2_norm_bridge = True # True False\n",
    "sae_lif_bridge = False # True False\n",
    "\n",
    "accuracy_check_epoch_term = 1\n",
    "\n",
    "lif_add_at_last = False # True False\n",
    "\n",
    "two_channel_input = False # True False\n",
    "\n",
    "lateral_feature_num = 4\n",
    "\n",
    "lc_adc_on = False # True False\n",
    "\n",
    "converted_net_forward = False # True False\n",
    "\n",
    "pretrained_net = None\n",
    "# pretrained_net = '/home/bhkim003/github_folder/ByeonghyeonKim/my_snn/net_save/save_now_net_중요_20250110_203117_390.pth'\n",
    "# pretrained_net = '/home/bhkim003/github_folder/ByeonghyeonKim/my_snn/net_save/save_now_net_중요_20250113_134126_881_이거_94나오는거.pth'\n",
    "# pretrained_net =  '/home/bhkim003/github_folder/ByeonghyeonKim/my_snn/net_save/save_now_net_20250205_184901_132.pth'\n",
    "# pretrained_net =  '/home/bhkim003/github_folder/ByeonghyeonKim/my_snn/net_save/save_now_net_20250306_134219_133.pth'\n",
    "\n",
    "vth_mul_on = False # True False\n",
    "batch_norm_on = False # True False\n",
    "\n",
    "l2_norm_loss_weight = 0 #0.0001 #0.1 #  0 # 0초과면 작동\n",
    "\n",
    "QCFS_neuron_on = False # True False\n",
    "\n",
    "quantize_level_num = 0 # 0이면 quantize 안함. 1이상이면 그 수만큼 quantize함. # normalize_on 켜져야됨. 음수면 0~1norm안하고 quant함\n",
    "\n",
    "fusion_net = True # True False # SAE_net False, Conv_net True로 해라. TIME 적절하게 설정해주고.\n",
    "repeat_coding = False # True False #fusion_net에서 쓰이는 거임 # True면 repeat, False면 rate coding.\n",
    "\n",
    "sae_relu_on = False # True False\n",
    "\n",
    "conv1d_scaling = False # True False # conv1d때매 norm하고 (level_num-3)/level_num 곱해줌 # Conv_net and coarse_com_mode and normalize_on\n",
    "\n",
    "norm01 = True # True False # normalize_on = True일 때 01norm하는지 아님 걍 quant만 하는지.\n",
    "\n",
    "wandb.init(project= f'spike_sorting just run',save_code=False)\n",
    "\n",
    "\n",
    "cluster_train_system( \n",
    "    gpu = gpu,\n",
    "    Conv_net = Conv_net,\n",
    "    SAE_net = SAE_net,\n",
    "\n",
    "    # hyperparameter\n",
    "    dataset_num = dataset_num,\n",
    "    spike_length = spike_length,\n",
    "    num_cluster = num_cluster,  # 클러스터 수 설정 # 논문엔 4개라는데 여기서는 3개로 했네\n",
    "    training_cycle = training_cycle, # 그 초기 몇개까지만 cluster update할지\n",
    "\n",
    "\n",
    "    batch_size = batch_size,\n",
    "    max_epoch = max_epoch,\n",
    "    learning_rate = learning_rate,\n",
    "    normalize_on = normalize_on, # True or False #이거 안 씀 # 이거 별로 안 좋은 normalize같음 # 쓸 거면 다른 거 써라.\n",
    "    need_bias = need_bias,\n",
    "    # first_layer_no_train = False\n",
    "    lif_add_at_first = lif_add_at_first,\n",
    "    my_seed = my_seed,\n",
    "\n",
    "    TIME = TIME, # SAE일 때만 유효\n",
    "    v_decay = v_decay,\n",
    "    v_threshold = v_threshold,\n",
    "    v_reset = v_reset, # 10000이상 일 시 hard reset\n",
    "    BPTT_on = BPTT_on,\n",
    "\n",
    "    SAE_hidden_nomean = SAE_hidden_nomean,\n",
    "    \n",
    "    current_time = current_time,\n",
    "\n",
    "    optimizer = optimizer, #'Adam', 'SGD'\n",
    "\n",
    "    coarse_com_mode = coarse_com_mode,\n",
    "    coarse_com_config = coarse_com_config, # (max, min)\n",
    "\n",
    "    \n",
    "    sae_l2_norm_bridge = sae_l2_norm_bridge,\n",
    "    sae_lif_bridge = sae_lif_bridge,\n",
    "\n",
    "    accuracy_check_epoch_term = accuracy_check_epoch_term,\n",
    "    \n",
    "    lif_add_at_last = lif_add_at_last,\n",
    "\n",
    "    two_channel_input = two_channel_input,\n",
    "\n",
    "    lateral_feature_num = lateral_feature_num,\n",
    "\n",
    "    lc_adc_on = lc_adc_on, \n",
    "\n",
    "    converted_net_forward = converted_net_forward,\n",
    "\n",
    "    pretrained_net = pretrained_net,\n",
    "\n",
    "    vth_mul_on = vth_mul_on,\n",
    "    batch_norm_on = batch_norm_on,\n",
    "\n",
    "    l2_norm_loss_weight = l2_norm_loss_weight,\n",
    "    \n",
    "    QCFS_neuron_on = QCFS_neuron_on, # True False\n",
    "\n",
    "    quantize_level_num = quantize_level_num,\n",
    "\n",
    "    fusion_net = fusion_net, # True False\n",
    "    repeat_coding = repeat_coding,\n",
    "\n",
    "    sae_relu_on = sae_relu_on,\n",
    "\n",
    "    conv1d_scaling = conv1d_scaling,\n",
    "\n",
    "    norm01 = norm01,\n",
    "\n",
    "    )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Sweep code\n",
    "\n",
    "\n",
    "# from unittest import TextTestRunner\n",
    "\n",
    "\n",
    "# unique_name_hyper = 'cluster_train_system'\n",
    "# # run_name = 'spike_sorting'\n",
    "# sweep_start_time =  datetime.datetime.now().strftime(\"%Y%m%d_%H%M%S\") + f\"_{str(int(datetime.datetime.now().microsecond / 1000)).zfill(3)}\"\n",
    "# sweep_configuration = {\n",
    "#     'method': 'bayes', # 'random', 'bayes'\n",
    "#     'name': f'spike_sorting_{sweep_start_time}',\n",
    "#     'metric': {'goal': 'maximize', 'name': 'k_means_acc_best'},\n",
    "#     'parameters': \n",
    "#     {\n",
    "#         # \"gpu\": {\"values\": ['1']},  # 이건 sweep parameter아님. hyper_iter에서 직접 설정\n",
    "#         \"Conv_net\": {\"values\": [True]}, \n",
    "#         \"SAE_net\": {\"values\": [True]}, \n",
    "\n",
    "#         \"dataset_num\": {\"values\": [16]}, \n",
    "#         \"spike_length\": {\"values\": [50]},  \n",
    "#         \"num_cluster\": {\"values\": [4]}, \n",
    "#         \"training_cycle\": {\"values\": [1400]}, # [1400, 2400]\n",
    "\n",
    "#         \"batch_size\": {\"values\": [32]}, \n",
    "#         \"max_epoch\": {\"values\": [20]}, \n",
    "#         \"learning_rate\": {\"values\": [0.001, 0.0001]},\n",
    "#         \"normalize_on\": {\"values\": [True]},\n",
    "#         \"need_bias\": {\"values\": [False]}, # [True, False]\n",
    "\n",
    "#         \"lif_add_at_first\": {\"values\": [False]}, # [True, False]\n",
    "#         \"my_seed\": {\"values\": [42]}, \n",
    "\n",
    "#         \"TIME\": {\"values\": [50]}, #  [4,6,8,10]\n",
    "#         \"v_decay\": {\"values\": [0.125, 0.25,0.50,0.75,1.0]}, # [0.25,0.50,0.75]\n",
    "#         \"v_threshold\": {\"values\": [0.125, 0.25, 0.50, 0.75, 0.875, 1.0]}, # [0.25,0.50,0.75]\n",
    "#         \"v_reset\": {\"values\": [0.0, 10000.0]},  # [0.0, 10000.0]\n",
    "#         \"BPTT_on\": {\"values\": [True, False]},  # [True, False]\n",
    "\n",
    "#         \"SAE_hidden_nomean\": {\"values\": [True]}, # [True, False]\n",
    "\n",
    "#         # \"current_time\": {\"values\": [current_time]} #밑에서 직접설정됨.\n",
    "\n",
    "#         \"optimizer\": {\"values\": ['Adam', 'SGD']}, # ['Adam', 'SGD']\n",
    "\n",
    "#         \"coarse_com_mode\": {\"values\": [True]}, # [True, False]\n",
    "#         \"coarse_com_config\": {\"values\": [(0.999, -0.0)]}, # ['Adam', 'SGD']\n",
    "\n",
    "#         \"sae_l2_norm_bridge\": {\"values\": [True]}, # [True, False]\n",
    "#         \"sae_lif_bridge\": {\"values\": [False]}, # [False, True]\n",
    "        \n",
    "#         \"accuracy_check_epoch_term\": {\"values\": [1]}, \n",
    "\n",
    "#         \"lif_add_at_last\": {\"values\": [False]},# [True, False]\n",
    "\n",
    "#         \"two_channel_input\": {\"values\": [False]},# [True, False]\n",
    "\n",
    "#         \"lateral_feature_num\": {\"values\": [4]},# [True, False]\n",
    "\n",
    "#         \"lc_adc_on\": {\"values\": [False]},# [True, False]\n",
    "        \n",
    "#         \"converted_net_forward\": {\"values\": [False]},# [True, False]\n",
    "\n",
    "#         \"pretrained_net\": {\"values\": [None]},# [None]\n",
    "\n",
    "#         \"vth_mul_on\": {\"values\": [False]},# [True, False]\n",
    "#         \"batch_norm_on\": {\"values\": [False]},# [True, False]\n",
    "\n",
    "#         \"l2_norm_loss_weight\": {\"values\": [0]},\n",
    "\n",
    "#         \"QCFS_neuron_on\": {\"values\": [False]},   # [True, False]\n",
    "\n",
    "#         \"quantize_level_num\": {\"values\": [0]}, \n",
    "\n",
    "#         \"fusion_net\": {\"values\": [True]}, \n",
    "#         \"repeat_coding\": {\"values\": [False]}, \n",
    "\n",
    "#         \"sae_relu_on\": {\"values\": [False]}, \n",
    "\n",
    "#         \"conv1d_scaling\": {\"values\": [False]}, \n",
    "\n",
    "#         \"norm01\": {\"values\": [True]}, \n",
    "#      }\n",
    "# }\n",
    "\n",
    "\n",
    "# def hyper_iter():\n",
    "#     ### my_snn control board ########################\n",
    "#     wandb.init(save_code = False)\n",
    "#     gpu  =  '2'\n",
    "#     Conv_net  =  wandb.config.Conv_net\n",
    "#     SAE_net  =  wandb.config.SAE_net\n",
    "\n",
    "#     dataset_num  =  wandb.config.dataset_num\n",
    "#     spike_length  =  wandb.config.spike_length\n",
    "#     num_cluster  =  wandb.config.num_cluster\n",
    "#     training_cycle  =  wandb.config.training_cycle\n",
    "\n",
    "#     batch_size  =  wandb.config.batch_size\n",
    "#     max_epoch  =  wandb.config.max_epoch\n",
    "#     learning_rate  =  wandb.config.learning_rate\n",
    "#     normalize_on  =  wandb.config.normalize_on\n",
    "#     need_bias  =  wandb.config.need_bias\n",
    "\n",
    "#     lif_add_at_first  =  wandb.config.lif_add_at_first\n",
    "#     my_seed  =  wandb.config.my_seed\n",
    "\n",
    "\n",
    "#     TIME  =  wandb.config.TIME\n",
    "#     v_decay  =  wandb.config.v_decay\n",
    "#     v_threshold  =  wandb.config.v_threshold\n",
    "#     v_reset  =  wandb.config.v_reset\n",
    "#     BPTT_on  =  wandb.config.BPTT_on\n",
    "\n",
    "#     SAE_hidden_nomean  =  wandb.config.SAE_hidden_nomean\n",
    "    \n",
    "#     current_time =  datetime.datetime.now().strftime(\"%Y%m%d_%H%M%S\") + f\"_{str(int(datetime.datetime.now().microsecond / 1000)).zfill(3)}\"\n",
    "\n",
    "#     optimizer  =  wandb.config.optimizer\n",
    "\n",
    "#     coarse_com_mode = wandb.config.coarse_com_mode\n",
    "#     coarse_com_config = wandb.config.coarse_com_config # (max, min)\n",
    "\n",
    "#     sae_l2_norm_bridge = wandb.config.sae_l2_norm_bridge\n",
    "#     sae_lif_bridge = wandb.config.sae_lif_bridge\n",
    "\n",
    "#     accuracy_check_epoch_term = wandb.config.accuracy_check_epoch_term\n",
    "\n",
    "#     lif_add_at_last = wandb.config.lif_add_at_last\n",
    "\n",
    "#     two_channel_input = wandb.config.two_channel_input\n",
    "\n",
    "#     lateral_feature_num = wandb.config.lateral_feature_num\n",
    "\n",
    "#     lc_adc_on = wandb.config.lc_adc_on\n",
    "\n",
    "#     converted_net_forward = wandb.config.converted_net_forward\n",
    "\n",
    "#     pretrained_net = wandb.config.pretrained_net\n",
    "\n",
    "#     vth_mul_on = wandb.config.vth_mul_on\n",
    "#     batch_norm_on = wandb.config.batch_norm_on\n",
    "\n",
    "#     l2_norm_loss_weight = wandb.config.l2_norm_loss_weight\n",
    "\n",
    "#     QCFS_neuron_on = wandb.config.QCFS_neuron_on\n",
    "\n",
    "#     quantize_level_num = wandb.config.quantize_level_num\n",
    "\n",
    "#     fusion_net = wandb.config.fusion_net\n",
    "#     repeat_coding = wandb.config.repeat_coding\n",
    "\n",
    "#     sae_relu_on = wandb.config.sae_relu_on\n",
    "\n",
    "#     conv1d_scaling = wandb.config.conv1d_scaling\n",
    "\n",
    "#     norm01 = wandb.config.norm01\n",
    "\n",
    "#     cluster_train_system( \n",
    "#         gpu = gpu,\n",
    "#         Conv_net = Conv_net,\n",
    "#         SAE_net = SAE_net,\n",
    "\n",
    "#         # hyperparameter\n",
    "#         dataset_num = dataset_num,\n",
    "#         spike_length = spike_length,\n",
    "#         num_cluster = num_cluster,  # 클러스터 수 설정 # 논문엔 4개라는데 여기서는 3개로 했네\n",
    "#         training_cycle = training_cycle, # 그 초기 몇개까지만 cluster update할지\n",
    "\n",
    "\n",
    "#         batch_size = batch_size,\n",
    "#         max_epoch = max_epoch,\n",
    "#         learning_rate = learning_rate,\n",
    "#         normalize_on = normalize_on, # True or False #이거 안 씀 # 이거 별로 안 좋은 normalize같음 # 쓸 거면 다른 거 써라.\n",
    "#         need_bias = need_bias,\n",
    "#         # first_layer_no_train = False\n",
    "#         lif_add_at_first = lif_add_at_first,\n",
    "#         my_seed = my_seed,\n",
    "\n",
    "#         TIME = TIME, # SAE일 때만 유효\n",
    "#         v_decay = v_decay,\n",
    "#         v_threshold = v_threshold,\n",
    "#         v_reset = v_reset, # 10000이상 일 시 hard reset\n",
    "#         BPTT_on = BPTT_on,\n",
    "\n",
    "#         SAE_hidden_nomean = SAE_hidden_nomean,\n",
    "\n",
    "#         current_time = current_time,\n",
    "\n",
    "#         optimizer = optimizer, #'Adam', 'SGD'\n",
    "\n",
    "#         coarse_com_mode = coarse_com_mode,\n",
    "#         coarse_com_config = coarse_com_config, # (max, min)\n",
    "        \n",
    "#         sae_l2_norm_bridge = sae_l2_norm_bridge,\n",
    "#         sae_lif_bridge = sae_lif_bridge,\n",
    "\n",
    "#         accuracy_check_epoch_term = accuracy_check_epoch_term,\n",
    "\n",
    "#         lif_add_at_last = lif_add_at_last,\n",
    "        \n",
    "#         two_channel_input = two_channel_input,\n",
    "        \n",
    "#         lateral_feature_num = lateral_feature_num,\n",
    "\n",
    "#         lc_adc_on = lc_adc_on,\n",
    "\n",
    "#         converted_net_forward = converted_net_forward,\n",
    "\n",
    "#         pretrained_net = pretrained_net,\n",
    "\n",
    "#         vth_mul_on = vth_mul_on,\n",
    "#         batch_norm_on = batch_norm_on,\n",
    "\n",
    "#         l2_norm_loss_weight = l2_norm_loss_weight,\n",
    "\n",
    "#         QCFS_neuron_on = QCFS_neuron_on,\n",
    "\n",
    "#         quantize_level_num = quantize_level_num,\n",
    "\n",
    "#         fusion_net = fusion_net, \n",
    "#         repeat_coding = repeat_coding, \n",
    "\n",
    "#         sae_relu_on = sae_relu_on,\n",
    "\n",
    "#         conv1d_scaling = conv1d_scaling,\n",
    "\n",
    "#         norm01 = norm01,\n",
    "#         )\n",
    "    \n",
    "# # sweep_id = 'ygoj9jt4'\n",
    "# sweep_id = wandb.sweep(sweep=sweep_configuration, project=f'spike_sorting {unique_name_hyper}')\n",
    "# wandb.agent(sweep_id, function=hyper_iter, count=100000, project=f'spike_sorting {unique_name_hyper}')\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wandb.finish() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import matplotlib.pyplot as plt\n",
    "# from matplotlib.ticker import MaxNLocator\n",
    "# import pickle\n",
    "# import json\n",
    "\n",
    "# # current_time = '20250102_225243_972'\n",
    "\n",
    "# with open(f\"result_save/cluster_accuracy_history_{current_time}.pkl\", \"rb\") as f:\n",
    "#     data = pickle.load(f)\n",
    "\n",
    "\n",
    "# # JSON으로 저장\n",
    "# with open(f\"result_save/cluster_accuracy_history_{current_time}.json\", 'r') as f:\n",
    "#     loaded_hyperparameters = json.load(f)\n",
    "\n",
    "# loss_history = data['loss_history']\n",
    "# mean_cluster_accuracy_during_training_cycle_all_dataset_history = data['mean_cluster_accuracy_during_training_cycle_all_dataset_history']\n",
    "# mean_cluster_accuracy_post_training_cycle_all_dataset_history = data['mean_cluster_accuracy_post_training_cycle_all_dataset_history']\n",
    "# mean_cluster_accuracy_total_all_dataset_history = data['mean_cluster_accuracy_total_all_dataset_history']\n",
    "# print(data)\n",
    "# max_acc = 0\n",
    "# for i in mean_cluster_accuracy_post_training_cycle_all_dataset_history:\n",
    "#     if i[1] > max_acc:\n",
    "#         max_acc = i[1]\n",
    "\n",
    "# # 설정 정보 제목 작성\n",
    "# title = (\n",
    "#     f\"Dataset Num: {loaded_hyperparameters['dataset_num']}, Conv {loaded_hyperparameters['Conv_net']}, SAE {loaded_hyperparameters['SAE_net']}, Current time {loaded_hyperparameters['current_time']}, Spike Length: {loaded_hyperparameters['spike_length']}, Num Cluster: {loaded_hyperparameters['num_cluster']}, \"\n",
    "#     f\"Training Cycle: {loaded_hyperparameters['training_cycle']}, Batch Size: {loaded_hyperparameters['batch_size']}, Max Epoch: {loaded_hyperparameters['max_epoch']}, \\n\"\n",
    "#     f\"Learning Rate: {loaded_hyperparameters['learning_rate']}, Input Normalize: {loaded_hyperparameters['normalize_on']}, Need Bias: {loaded_hyperparameters['need_bias']}, \"\n",
    "#     f\"LIF Add at First: {loaded_hyperparameters['lif_add_at_first']}, TIME: {loaded_hyperparameters['TIME']}, Seed: {loaded_hyperparameters['my_seed']}, Best ACC: {max_acc:.2f}%\"\n",
    "# )\n",
    "\n",
    "# # 데이터 리스트와 라벨 설정 (Loss 제외)\n",
    "# data_list = [\n",
    "#     (\"Mean Cluster Accuracy (During Training Cycle)\", mean_cluster_accuracy_during_training_cycle_all_dataset_history),\n",
    "#     (\"Mean Cluster Accuracy (Post Training Cycle)\", mean_cluster_accuracy_post_training_cycle_all_dataset_history),\n",
    "#     (\"Mean Cluster Accuracy (Total)\", mean_cluster_accuracy_total_all_dataset_history),\n",
    "# ]\n",
    "\n",
    "# # 플롯 생성\n",
    "# fig, ax1 = plt.subplots(figsize=(12, 8))\n",
    "\n",
    "# # 첫 번째 y축: Accuracy 관련 데이터\n",
    "# for label, data in data_list:\n",
    "#     epochs, values = zip(*data)  # epoch, value 분리\n",
    "#     ax1.plot(epochs, values, label=label)\n",
    "\n",
    "# ax1.set_xlabel(\"Epoch\")\n",
    "# ax1.set_ylabel(\"Clurstering Accuracy [%]\", color=\"blue\")\n",
    "# ax1.tick_params(axis=\"y\", labelcolor=\"blue\")\n",
    "# ax1.legend(loc=\"center right\")\n",
    "# ax1.grid(True)\n",
    "\n",
    "# # x축을 정수만 표시하도록 설정\n",
    "# ax1.xaxis.set_major_locator(MaxNLocator(integer=True))\n",
    "\n",
    "# # 두 번째 y축: Loss History\n",
    "# ax2 = ax1.twinx()\n",
    "# epochs, values = zip(*loss_history)\n",
    "# ax2.plot(epochs, values, label=\"AE Loss History\", color=\"red\", linestyle=\"--\")\n",
    "# ax2.set_ylabel(\"Loss\", color=\"red\")\n",
    "# ax2.tick_params(axis=\"y\", labelcolor=\"red\")\n",
    "# ax2.legend(loc=\"center left\")\n",
    "\n",
    "# # 제목 추가\n",
    "# plt.title(title, fontsize=10)\n",
    "# plt.tight_layout()\n",
    "# plt.savefig(f'net_save/{current_time}', dpi=300, bbox_inches=\"tight\")  # dpi=300은 고해상도로 저장, bbox_inches=\"tight\"는 여백 최소화\n",
    "# plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# 데이터셋\n",
    "filename_for_plot = [\n",
    "    \"Easy1_noise05\", \"Easy1_noise10\", \"Easy1_noise15\", \"Easy1_noise20\",\n",
    "    \"Easy2_noise05\", \"Easy2_noise10\", \"Easy2_noise15\", \"Easy2_noise20\",\n",
    "    \"Difficult1_noise05\", \"Difficult1_noise10\", \"Difficult1_noise15\", \"Difficult1_noise20\",\n",
    "    \"Difficult2_noise05\", \"Difficult2_noise10\", \"Difficult2_noise15\", \"Difficult2_noise20\"\n",
    "]\n",
    "\n",
    "# Accuracy 데이터\n",
    "ANN_conv_accracy_set= [0.97935368, 0.97682709, 0.97028784, 0.96461825, 0.97524752, 0.95803571\n",
    ", 0.95746785, 0.92628774, 0.965412,  0.97805344, 0.94869403, 0.92110454\n",
    ", 0.96784232, 0.97551789, 0.91538462, 0.84446478]\n",
    "SNN_fc_accuracy_set = [0.97114475, 0.97643732, 0.84400578, 0.78977821, 0.96616915, 0.92830189\n",
    ", 0.86176032, 0.31984948, 0.80635401, 0.88769531, 0.61003861, 0.60377358\n",
    ", 0.9592668,  0.92870999, 0.78333333, 0.67271859]\n",
    "SNN_conv_accuracy_set = [0.97445601, 0.97737983, 0.97063072, 0.95998071, 0.96268657, 0.90566038\n",
    ", 0.82545997, 0.68391345, 0.96116994, 0.92138672, 0.80694981, 0.49602781\n",
    ", 0.83604888, 0.70611057, 0.69313725, 0.5819398 ]\n",
    "\n",
    "# 평균 계산\n",
    "average_ANN_conv = np.mean(ANN_conv_accracy_set)\n",
    "average_SNN_fc = np.mean(SNN_fc_accuracy_set)\n",
    "average_SNN_conv = np.mean(SNN_conv_accuracy_set)\n",
    "\n",
    "# 데이터 준비\n",
    "accuracies = np.array([ANN_conv_accracy_set, SNN_fc_accuracy_set, SNN_conv_accuracy_set])\n",
    "averages = np.array([average_ANN_conv, average_SNN_fc, average_SNN_conv])\n",
    "\n",
    "# 시각화\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "\n",
    "# 각 모델의 정확도 플롯\n",
    "ax.plot(accuracies[0], label='ANN Conv', marker='o', linestyle='-', color='blue')\n",
    "ax.plot(accuracies[1], label='SNN FC', marker='o', linestyle='-', color='green')\n",
    "ax.plot(accuracies[2], label='SNN Conv', marker='o', linestyle='-', color='red')\n",
    "\n",
    "# 평균값 플롯\n",
    "ax.axhline(y=average_ANN_conv, color='blue', linestyle='--', label=f'Average ANN Conv: {average_ANN_conv:.3f}')\n",
    "ax.axhline(y=average_SNN_fc, color='green', linestyle='--', label=f'Average SNN FC: {average_SNN_fc:.3f}')\n",
    "ax.axhline(y=average_SNN_conv, color='red', linestyle='--', label=f'Average SNN Conv: {average_SNN_conv:.3f}')\n",
    "\n",
    "# 레이블 추가\n",
    "ax.set_xticks(np.arange(len(filename_for_plot)))\n",
    "ax.set_xticklabels(filename_for_plot, rotation=45, ha='right')\n",
    "ax.set_ylabel('Accuracy')\n",
    "ax.set_title('Accuracy Comparison of Models on Datasets')\n",
    "ax.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import matplotlib.pyplot as plt\n",
    "import os  # 파일 경로 처리를 위한 모듈\n",
    "\n",
    "# CSV 파일 경로\n",
    "# csv_file_path = \"/home/bhkim003/github_folder/ByeonghyeonKim/my_snn/ae_test_deprecated/250115/sweep0_vth_mul.csv\" # vth_mul해서 sweep 돌린거\n",
    "csv_file_path = \"/home/bhkim003/github_folder/ByeonghyeonKim/my_snn/ae_test_deprecated/250115/sweep1.csv\"  #vth_mul안한거\n",
    "\n",
    "# 결과를 저장할 리스트\n",
    "tuple_list = []\n",
    "\n",
    "# CSV 파일 읽기\n",
    "with open(csv_file_path, 'r') as file:\n",
    "    reader = csv.DictReader(file)\n",
    "    for row in reader:\n",
    "        try:\n",
    "            # v_threshold, TIME, v_reset, converted_k_means_acc 값을 가져와 튜플로 변환\n",
    "            v_threshold = float(row[\"v_threshold\"])\n",
    "            time = int(row[\"TIME\"])\n",
    "            v_reset = int(row[\"v_reset\"])\n",
    "            converted_k_means_acc = float(row[\"converted_k_means_acc\"]) if row[\"converted_k_means_acc\"] else None\n",
    "\n",
    "            # 튜플 형태로 추가 (값이 None일 경우 처리할 수도 있음)\n",
    "            tuple_list.append((v_threshold, time, v_reset, converted_k_means_acc))\n",
    "        except ValueError as e:\n",
    "            print(f\"Error processing row {row}: {e}\")\n",
    "\n",
    "# 데이터를 TIME 기준으로 정렬\n",
    "tuple_list.sort(key=lambda x: x[1])  # TIME을 기준으로 오름차순 정렬\n",
    "\n",
    "# reset 방식에 따라 데이터를 나누기\n",
    "soft_reset = [t for t in tuple_list if t[2] == 0]\n",
    "hard_reset = [t for t in tuple_list if t[2] == 10000]\n",
    "\n",
    "# reset 방식과 v_threshold에 따라 색상 설정\n",
    "def plot_data(data, label_prefix, marker):\n",
    "    for v_threshold in [1.0]:  # v_threshold 기준으로 제한\n",
    "        filtered_data = [(t[1], t[3]) for t in data if t[0] == v_threshold]\n",
    "        if filtered_data:  # 해당 v_threshold 데이터가 있을 경우만 플롯\n",
    "            times, accuracies = zip(*filtered_data)  # x축(TIME), y축(converted_k_means_acc)\n",
    "            \n",
    "            plt.plot(\n",
    "                times,\n",
    "                accuracies,\n",
    "                marker,\n",
    "                label=f\"{label_prefix}, v_threshold={v_threshold}\",\n",
    "                linestyle=\"--\",\n",
    "            )\n",
    "            # 각 점에 accuracy 표시\n",
    "            for time, acc in filtered_data:\n",
    "                if acc == None:\n",
    "                    continue\n",
    "                plt.text(time, acc, f\"{acc:.2f}\", fontsize=8, ha=\"right\")\n",
    "\n",
    "# 그래프 초기화\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "# soft_reset (v_reset=0) 데이터 플롯\n",
    "plot_data(soft_reset, \"Soft Reset\", \"o\")\n",
    "\n",
    "# hard_reset (v_reset=10000) 데이터 플롯\n",
    "plot_data(hard_reset, \"Hard Reset\", \"x\")\n",
    "\n",
    "# baseline accuracy 가로선 추가\n",
    "baseline_accuracy = 94.43\n",
    "plt.axhline(y=baseline_accuracy, color=\"red\", linestyle=\"-\", label=f\"Baseline Accuracy ({baseline_accuracy}%)\")\n",
    "# baseline 텍스트 추가\n",
    "plt.text(\n",
    "    2000,  # x축 위치 (그래프 오른쪽 끝)\n",
    "    baseline_accuracy + 0.4,  # y축 위치 (baseline 위 약간)\n",
    "    f\"ANN Baseline ({baseline_accuracy}%)\",\n",
    "    color=\"red\",\n",
    "    fontsize=10,\n",
    "    ha=\"center\",\n",
    ")\n",
    "\n",
    "# CSV 파일 이름 가져오기\n",
    "csv_file_name = os.path.basename(csv_file_path)\n",
    "\n",
    "# 그래프 세부 설정\n",
    "plt.title(f\"Converted SNN K-Means Accuracy vs TIME STEP - {csv_file_name}\")\n",
    "plt.xlabel(\"TIME STEP\")\n",
    "plt.ylabel(\"Converted K-Means Accuracy [%]\")\n",
    "plt.legend(loc=\"lower right\")  # 범례를 오른쪽 아래로 이동\n",
    "plt.grid(True)\n",
    "\n",
    "# 그래프 출력\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aedat2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
