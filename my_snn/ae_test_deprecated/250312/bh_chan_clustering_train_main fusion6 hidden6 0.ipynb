{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ssp.train.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x600 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import torch   \n",
    "import torch.nn as nn \n",
    "import torch.nn.functional as F   \n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import torch.optim as optim\n",
    "from scipy import io\n",
    "import itertools\n",
    "import math\n",
    "import datetime\n",
    "import wandb\n",
    "import pickle\n",
    "import json\n",
    "import time\n",
    "import sys\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import accuracy_score\n",
    "from scipy.optimize import linear_sum_assignment\n",
    "from snntorch import spikegen\n",
    "\n",
    "\n",
    "# my module import\n",
    "from modules import *\n",
    "\n",
    "# modules 폴더에 새모듈.py 만들면\n",
    "# modules/__init__py 파일에 form .새모듈 import * 하셈\n",
    "# 그리고 새모듈.py에서 from modules.새모듈 import * 하셈"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cluster_train_system( \n",
    "    gpu = '4',\n",
    "    Conv_net = True,\n",
    "    SAE_net = True,\n",
    "\n",
    "    # hyperparameter\n",
    "    dataset_num = 16,\n",
    "    spike_length = 50,\n",
    "    num_cluster = 4,  # 클러스터 수 설정 # 논문엔 4개라는데 여기서는 3개로 했네\n",
    "    training_cycle = 2400, # 그 초기 몇개까지만 cluster update할지\n",
    "\n",
    "\n",
    "    batch_size = 32,\n",
    "    max_epoch = 7000,\n",
    "    learning_rate = 0.001,\n",
    "    normalize_on = False, # True or False #이거 안 씀 # 이거 별로 안 좋은 normalize같음 # 쓸 거면 다른 거 써라.\n",
    "    need_bias = False,\n",
    "    # first_layer_no_train = False\n",
    "    lif_add_at_first = False,\n",
    "    my_seed = 42,\n",
    "\n",
    "    TIME = 10, # SAE일 때만 유효\n",
    "    v_decay = 0.5,\n",
    "    v_threshold = 0.5,\n",
    "    v_reset = 10000.0, # 10000이상 일 시 hard reset\n",
    "    BPTT_on = True,\n",
    "\n",
    "    SAE_hidden_nomean = True,\n",
    "    current_time = '20250101_210938_786',\n",
    "\n",
    "    optimizer = 'Adam',\n",
    "    coarse_com_mode = True,\n",
    "    coarse_com_config = (2.0, -2.0), # (max, min)\n",
    "\n",
    "    sae_l2_norm_bridge = True,\n",
    "    sae_lif_bridge = False,\n",
    "\n",
    "    accuracy_check_epoch_term = 5,\n",
    "    \n",
    "    lif_add_at_last = False,\n",
    "\n",
    "    two_channel_input = False,\n",
    "\n",
    "    lateral_feature_num = 4,\n",
    "\n",
    "    lc_adc_on = False, \n",
    "\n",
    "    converted_net_forward = False,\n",
    "\n",
    "    pretrained_net = None, \n",
    "\n",
    "    vth_mul_on = False,\n",
    "    batch_norm_on = False,\n",
    "\n",
    "    l2_norm_loss_weight = 0.0,\n",
    "\n",
    "    QCFS_neuron_on = False,\n",
    "\n",
    "    quantize_level_num = 0,\n",
    "\n",
    "    fusion_net = False, # True False\n",
    "    repeat_coding = False,\n",
    "    \n",
    "    sae_relu_on = False,\n",
    "\n",
    "    conv1d_scaling = False,\n",
    "\n",
    "    norm01 = True,\n",
    "    ):\n",
    "    if coarse_com_mode == True:\n",
    "        assert coarse_com_config[0] > coarse_com_config[1], 'coarse_com_config[0] > coarse_com_config[1]이어야 함'\n",
    "        assert converted_net_forward == False\n",
    "        # assert SAE_net == True, 'coarse_com_mode는 SAE_net이 True일 때만 가능'\n",
    "    if two_channel_input == True:\n",
    "        assert Conv_net and coarse_com_mode, 'two_channel_input는 Conv_net이 True일 때만 가능'\n",
    "    if lc_adc_on == True:\n",
    "        assert coarse_com_mode and SAE_net, 'lc_adc_on은 coarse_com_mode와 SAE_net이 True일 때만 가능'\n",
    "    if converted_net_forward == True:\n",
    "        assert SAE_net == False, 'converted_net_forward는 SAE_net이 False일 때만 가능'\n",
    "    if conv1d_scaling:\n",
    "        assert Conv_net and coarse_com_mode and normalize_on\n",
    "    seed_assign(my_seed)\n",
    "    ## 함수 내 모든 로컬 변수 저장 ########################################################\n",
    "    hyperparameters = locals()\n",
    "    print(hyperparameters)\n",
    "    # JSON으로 저장\n",
    "    with open(f\"result_save/cluster_accuracy_history_{current_time}.json\", 'w') as f:\n",
    "        json.dump(hyperparameters, f, indent=4)\n",
    "    ######################################################################################\n",
    "\n",
    "    \n",
    "    wandb.config.update(hyperparameters)\n",
    "    wandb.run.name = f'{current_time}_SAE_net_{SAE_net}_v_threshold_{v_threshold}'\n",
    "    wandb.define_metric(\"best_mean_cluster_accuracy_post_training_cycle_all_dataset2\", summary=\"max\")\n",
    "\n",
    "\n",
    "    my_path_ground_BH = '/data2/spike_sorting/quiroga/BH/'\n",
    "\n",
    "\n",
    "    filename = [\"C_Easy1_noise005.mat\", \"C_Easy1_noise01.mat\", \"C_Easy1_noise015.mat\", \"C_Easy1_noise02.mat\",\n",
    "                \"C_Easy2_noise005.mat\", \"C_Easy2_noise01.mat\", \"C_Easy2_noise015.mat\", \"C_Easy2_noise02.mat\",\n",
    "                \"C_Difficult1_noise005.mat\", \"C_Difficult1_noise01.mat\", \"C_Difficult1_noise015.mat\", \"C_Difficult1_noise02.mat\",\n",
    "                \"C_Difficult2_noise005.mat\", \"C_Difficult2_noise01.mat\", \"C_Difficult2_noise015.mat\", \"C_Difficult2_noise02.mat\"]\n",
    "\n",
    "\n",
    "    spike_tot = [\"BH_Spike_e1n005.npy\", \"BH_Spike_e1n010.npy\", \"BH_Spike_e1n015.npy\", \"BH_Spike_e1n020.npy\",\n",
    "                \"BH_Spike_e2n005.npy\", \"BH_Spike_e2n010.npy\", \"BH_Spike_e2n015.npy\", \"BH_Spike_e2n020.npy\",\n",
    "                \"BH_Spike_d1n005.npy\", \"BH_Spike_d1n010.npy\", \"BH_Spike_d1n015.npy\", \"BH_Spike_d1n020.npy\",\n",
    "                \"BH_Spike_d2n005.npy\", \"BH_Spike_d2n010.npy\", \"BH_Spike_d2n015.npy\", \"BH_Spike_d2n020.npy\"]\n",
    "\n",
    "    label_tot = [\"BH_Label_e1n005.npy\", \"BH_Label_e1n010.npy\", \"BH_Label_e1n015.npy\", \"BH_Label_e1n020.npy\",\n",
    "                \"BH_Label_e2n005.npy\", \"BH_Label_e2n010.npy\", \"BH_Label_e2n015.npy\", \"BH_Label_e2n020.npy\",\n",
    "                \"BH_Label_d1n005.npy\", \"BH_Label_d1n010.npy\", \"BH_Label_d1n015.npy\", \"BH_Label_d1n020.npy\",\n",
    "                \"BH_Label_d2n005.npy\", \"BH_Label_d2n010.npy\", \"BH_Label_d2n015.npy\", \"BH_Label_d2n020.npy\"]\n",
    "\n",
    "    template =  [\"BH_Spike_TEMPLATE_e1n005.npy\", \"BH_Spike_TEMPLATE_e1n010.npy\", \"BH_Spike_TEMPLATE_e1n015.npy\", \"BH_Spike_TEMPLATE_e1n020.npy\",\n",
    "                \"BH_Spike_TEMPLATE_e2n005.npy\", \"BH_Spike_TEMPLATE_e2n010.npy\", \"BH_Spike_TEMPLATE_e2n015.npy\", \"BH_Spike_TEMPLATE_e2n020.npy\",\n",
    "                \"BH_Spike_TEMPLATE_d1n005.npy\", \"BH_Spike_TEMPLATE_d1n010.npy\", \"BH_Spike_TEMPLATE_d1n015.npy\", \"BH_Spike_TEMPLATE_d1n020.npy\",\n",
    "                \"BH_Spike_TEMPLATE_d2n005.npy\", \"BH_Spike_TEMPLATE_d2n010.npy\", \"BH_Spike_TEMPLATE_d2n015.npy\", \"BH_Spike_TEMPLATE_d2n020.npy\"]\n",
    "\n",
    "    AE_train_path_gt_detect = 'BH_quiroga_training_dataset_gt_detect.pt' \n",
    "    AE_test_path_gt_detect = 'BH_quiroga_test_dataset_gt_detect.pt'\n",
    "\n",
    "    AE_train_path_real_detect = 'BH_quiroga_training_dataset_real_detect.pt'\n",
    "    AE_test_path_real_detect = 'BH_quiroga_test_dataset_real_detect.pt'\n",
    "\n",
    "    AE_train_data = AE_train_path_real_detect #AE_train_path_gt_detect #AE_train_path_real_detect\n",
    "    AE_test_data = AE_test_path_real_detect #AE_test_path_gt_detect  #AE_test_path_real_detect\n",
    "\n",
    "    # thr_tot = np.array([0.5, 0.5, 0.55, 0.7, 0.5, 0.5, 0.55, 0.7, 0.5, 0.5, 0.55, 0.7, 0.5, 0.5, 0.55, 0.7])\n",
    "    cos_thr = np.array([0.95, 0.95, 0.95, 0.95, 0.95, 0.95, 0.95, 0.85, 0.95, 0.9, 0.8, 0.95, 0.95, 0.95, 0.95, 0.8])\n",
    "    # tem=10\n",
    "    # cos_thr = np.array([tem, tem, tem, tem, tem, tem, tem, tem, tem, tem, tem, tem, tem, tem, tem, tem, ])\n",
    "\n",
    "    print('cos_thr', cos_thr)\n",
    "    \n",
    "    os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\" \n",
    "    os.environ[\"CUDA_VISIBLE_DEVICES\"]= gpu\n",
    "\n",
    "\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "\n",
    "    if coarse_com_mode == True:\n",
    "        level_num = TIME\n",
    "        TIME = spike_length\n",
    "        spike_length = level_num\n",
    "        level_interval = (coarse_com_config[0] - coarse_com_config[1]) / (level_num-1)  # max - min\n",
    "        levels = [coarse_com_config[1] + level_interval * i for i in range(level_num)]\n",
    "        levels = torch.tensor(levels).to(torch.float).to(device)\n",
    "        levels = levels.repeat(TIME,1) \n",
    "        # print('levels', levels, levels.shape) # TIME, level_num\n",
    "\n",
    "    n_sample = spike_length\n",
    "\n",
    "    class spikedataset(Dataset):\n",
    "        def __init__(self, path, transform = None):    \n",
    "            self.transform = transform\n",
    "            self.spike = torch.load(path)\n",
    "            \n",
    "        def __getitem__(self, index):\n",
    "            spike = self.spike[index]            \n",
    "            if self.transform is not None:\n",
    "                spike = self.transform(spike)\n",
    "            return spike\n",
    "        \n",
    "        def __len__(self):\n",
    "            return len(self.spike)\n",
    "\n",
    "    train_dataset = spikedataset(my_path_ground_BH + AE_train_data)\n",
    "    train_loader = DataLoader(dataset = train_dataset, batch_size = batch_size, shuffle = True)\n",
    "\n",
    "    test_dataset = spikedataset(my_path_ground_BH + AE_test_data)\n",
    "    test_loader = DataLoader(dataset = test_dataset, batch_size = batch_size, shuffle = False)\n",
    "\n",
    "\n",
    "    # vth_mul_on = True # True False\n",
    "    # batch_norm_on = True # True False\n",
    "\n",
    "\n",
    "    # 모델 초기화\n",
    "    if SAE_net == False: # 여기서는 l2norm, lif bridge 둘 다 true면 l2norm먼저\n",
    "        assert two_channel_input == False\n",
    "\n",
    "        if Conv_net == True:\n",
    "            # input_channels = 2 if two_channel_input else 1\n",
    "            input_channels = TIME if coarse_com_mode else 1\n",
    "            if fusion_net == True:\n",
    "                assert False, '이거 맞음? 다시 확인'\n",
    "                net = FUSION_net_conv1(input_channels=input_channels, input_length=n_sample, encoder_ch = [32, 64, 96], fc_dim = lateral_feature_num, padding = 0, stride = 2, kernel_size = 3, \n",
    "                                    synapse_fc_trace_const1=1, \n",
    "                                    synapse_fc_trace_const2=v_decay, #안씀 \n",
    "                                    TIME=TIME, v_init=0.0, v_decay=v_decay, v_threshold=v_threshold, v_reset=v_reset, \n",
    "                                    sg_width=4.0, surrogate='sigmoid', BPTT_on=BPTT_on, need_bias=need_bias, lif_add_at_first=lif_add_at_first,\n",
    "                                    sae_l2_norm_bridge = sae_l2_norm_bridge, sae_lif_bridge = sae_lif_bridge, lif_add_at_last=lif_add_at_last, repeat_coding=repeat_coding).to(device)\n",
    "            else: \n",
    "                net = Autoencoder_conv1(input_channels=input_channels, input_length=n_sample, encoder_ch = [32, 64, 96], fc_dim = lateral_feature_num, padding = 0, stride = 2, kernel_size = 3, need_bias=need_bias, l2norm_bridge=sae_l2_norm_bridge, relu_bridge=sae_lif_bridge, activation_collector_on=False,\n",
    "                                        batch_norm_on=batch_norm_on, QCFS_neuron_on=QCFS_neuron_on).to(device)\n",
    "            net = torch.nn.DataParallel(net)\n",
    "            if converted_net_forward:\n",
    "                converted_net = SAE_converted_conv1(input_channels=input_channels, input_length=n_sample, encoder_ch = [32, 64, 96], fc_dim = lateral_feature_num, padding = 0, stride = 2, kernel_size = 3, \n",
    "                                    synapse_fc_trace_const1=1, \n",
    "                                    synapse_fc_trace_const2=v_decay, #안씀 \n",
    "                                    TIME=TIME, v_init=0.0, v_decay=v_decay, v_threshold=v_threshold, v_reset=v_reset, \n",
    "                                    sg_width=4.0, surrogate='sigmoid', BPTT_on=BPTT_on, need_bias=need_bias, lif_add_at_first=lif_add_at_first,\n",
    "                                    sae_l2_norm_bridge = sae_l2_norm_bridge, sae_lif_bridge = sae_lif_bridge, lif_add_at_last=lif_add_at_last,\n",
    "                                    vth_mul_on=vth_mul_on, batch_norm_on=batch_norm_on).to(device) # lif bridge는 무조건 들어가게 해놨음.\n",
    "                converted_net = torch.nn.DataParallel(converted_net)\n",
    "                print('converted_net', converted_net)\n",
    "        else:\n",
    "            n_sample = n_sample * TIME if coarse_com_mode else n_sample\n",
    "            net = Autoencoder_only_FC(encoder_ch=[400, lateral_feature_num], decoder_ch=[400,n_sample], n_sample=n_sample, need_bias=need_bias, l2norm_bridge=sae_l2_norm_bridge, relu_bridge=sae_lif_bridge, activation_collector_on=False,\n",
    "                                    batch_norm_on=batch_norm_on, QCFS_neuron_on=QCFS_neuron_on).to(device)\n",
    "            net = torch.nn.DataParallel(net)\n",
    "            if converted_net_forward:\n",
    "                converted_net = SAE_converted_fc(encoder_ch=[400, lateral_feature_num], \n",
    "                                    decoder_ch=[400, n_sample], \n",
    "                                    in_channels=n_sample, # in_channel 이 여기선 걍 lenght.\n",
    "                                    synapse_fc_trace_const1=1,\n",
    "                                    synapse_fc_trace_const2=v_decay,  #안씀 \n",
    "                                    TIME=TIME, v_init=0.0, v_decay=v_decay, v_threshold=v_threshold, v_reset=v_reset, \n",
    "                                    sg_width=4.0, surrogate='sigmoid', BPTT_on=BPTT_on, need_bias=need_bias, lif_add_at_first=lif_add_at_first,\n",
    "                                    sae_l2_norm_bridge = sae_l2_norm_bridge, sae_lif_bridge = sae_lif_bridge, lif_add_at_last=lif_add_at_last,\n",
    "                                    vth_mul_on=vth_mul_on, batch_norm_on=batch_norm_on).to(device) # lif bridge는 무조건 들어가게 해놨음.\n",
    "                converted_net = torch.nn.DataParallel(converted_net)\n",
    "                # print('converted_net', converted_net)\n",
    "    else:\n",
    "        if Conv_net == True: \n",
    "            input_channels = 1\n",
    "            input_channels = 2 if two_channel_input else 1\n",
    "            if fusion_net == True:  \n",
    "                assert coarse_com_mode == True\n",
    "                # net = SAE_FUSION2_net_conv1(input_channels=input_channels, input_length=n_sample, encoder_ch = [32, 64, 96], fc_dim = lateral_feature_num, padding = 0, stride = 2, kernel_size = 3, \n",
    "                #                     synapse_fc_trace_const1=1, \n",
    "                #                     synapse_fc_trace_const2=v_decay, #안씀 \n",
    "                #                     TIME=TIME, v_init=0.0, v_decay=v_decay, v_threshold=v_threshold, v_reset=v_reset, \n",
    "                #                     sg_width=4.0, surrogate='sigmoid', BPTT_on=BPTT_on, need_bias=need_bias, lif_add_at_first=lif_add_at_first,\n",
    "                #                     sae_l2_norm_bridge = sae_l2_norm_bridge, sae_lif_bridge = sae_lif_bridge, lif_add_at_last=lif_add_at_last, batch_norm_on=batch_norm_on, sae_relu_on=sae_relu_on).to(device)\n",
    "                # net = SAE_FUSION3_net_conv1(input_channels=input_channels, input_length=n_sample, encoder_ch = [32, 64, 96], fc_dim = lateral_feature_num, padding = 0, stride = 2, kernel_size = 3, \n",
    "                #                     synapse_fc_trace_const1=1, \n",
    "                #                     synapse_fc_trace_const2=v_decay, #안씀 \n",
    "                #                     TIME=TIME, v_init=0.0, v_decay=v_decay, v_threshold=v_threshold, v_reset=v_reset, \n",
    "                #                     sg_width=4.0, surrogate='sigmoid', BPTT_on=BPTT_on, need_bias=need_bias, lif_add_at_first=lif_add_at_first,\n",
    "                #                     sae_l2_norm_bridge = sae_l2_norm_bridge, sae_lif_bridge = sae_lif_bridge, lif_add_at_last=lif_add_at_last, batch_norm_on=batch_norm_on, sae_relu_on=sae_relu_on).to(device)\n",
    "                # net = SAE_FUSION4_net_conv1(input_channels=input_channels, input_length=n_sample, encoder_ch = [32, 64, 96], fc_dim = lateral_feature_num, padding = 0, stride = 2, kernel_size = 3, \n",
    "                #                     synapse_fc_trace_const1=1, \n",
    "                #                     synapse_fc_trace_const2=v_decay, #안씀 \n",
    "                #                     TIME=TIME, v_init=0.0, v_decay=v_decay, v_threshold=v_threshold, v_reset=v_reset, \n",
    "                #                     sg_width=4.0, surrogate='sigmoid', BPTT_on=BPTT_on, need_bias=need_bias, lif_add_at_first=lif_add_at_first,\n",
    "                #                     sae_l2_norm_bridge = sae_l2_norm_bridge, sae_lif_bridge = sae_lif_bridge, lif_add_at_last=lif_add_at_last, batch_norm_on=batch_norm_on, sae_relu_on=sae_relu_on).to(device)\n",
    "                # net = SAE_FUSION5_net_conv1(input_channels=input_channels, input_length=n_sample, encoder_ch = [32, 64, 96], fc_dim = lateral_feature_num, padding = 0, stride = 2, kernel_size = 3, \n",
    "                #                     synapse_fc_trace_const1=1, \n",
    "                #                     synapse_fc_trace_const2=v_decay, #안씀 \n",
    "                #                     TIME=TIME, v_init=0.0, v_decay=v_decay, v_threshold=v_threshold, v_reset=v_reset, \n",
    "                #                     sg_width=4.0, surrogate='sigmoid', BPTT_on=BPTT_on, need_bias=need_bias, lif_add_at_first=lif_add_at_first,\n",
    "                #                     sae_l2_norm_bridge = sae_l2_norm_bridge, sae_lif_bridge = sae_lif_bridge, lif_add_at_last=lif_add_at_last, batch_norm_on=batch_norm_on, sae_relu_on=sae_relu_on).to(device)\n",
    "                net = SAE_FUSION6_net_conv1(input_channels=input_channels, input_length=n_sample, encoder_ch = [32, 64, 96], fc_dim = lateral_feature_num, padding = 0, stride = 2, kernel_size = 3, \n",
    "                                    synapse_fc_trace_const1=1, \n",
    "                                    synapse_fc_trace_const2=v_decay, #안씀 \n",
    "                                    TIME=TIME, v_init=0.0, v_decay=v_decay, v_threshold=v_threshold, v_reset=v_reset, \n",
    "                                    sg_width=4.0, surrogate='sigmoid', BPTT_on=BPTT_on, need_bias=need_bias, lif_add_at_first=lif_add_at_first,\n",
    "                                    sae_l2_norm_bridge = sae_l2_norm_bridge, sae_lif_bridge = sae_lif_bridge, lif_add_at_last=lif_add_at_last, batch_norm_on=batch_norm_on, sae_relu_on=sae_relu_on).to(device)\n",
    "            else:\n",
    "                net = SAE_conv1(input_channels=input_channels, input_length=n_sample, encoder_ch = [32, 64, 96], fc_dim = lateral_feature_num, padding = 0, stride = 2, kernel_size = 3, \n",
    "                                    synapse_fc_trace_const1=1, \n",
    "                                    synapse_fc_trace_const2=v_decay, #안씀 \n",
    "                                    TIME=TIME, v_init=0.0, v_decay=v_decay, v_threshold=v_threshold, v_reset=v_reset, \n",
    "                                    sg_width=4.0, surrogate='sigmoid', BPTT_on=BPTT_on, need_bias=need_bias, lif_add_at_first=lif_add_at_first,\n",
    "                                    sae_l2_norm_bridge = sae_l2_norm_bridge, sae_lif_bridge = sae_lif_bridge, lif_add_at_last=lif_add_at_last, batch_norm_on=batch_norm_on, sae_relu_on=sae_relu_on).to(device)\n",
    "            # net = SAE_conv1_DR(input_channels=input_channels, input_length=n_sample, encoder_ch = [32, 64, 96], fc_dim = lateral_feature_num, padding = 0, stride = 2, kernel_size = 3, \n",
    "            #                     synapse_fc_trace_const1=1, \n",
    "            #                     synapse_fc_trace_const2=v_decay, #안씀 \n",
    "            #                     TIME=TIME, v_init=0.0, v_decay=v_decay, v_threshold=v_threshold, v_reset=v_reset, \n",
    "            #                     sg_width=4.0, surrogate='sigmoid', BPTT_on=BPTT_on, need_bias=need_bias, lif_add_at_first=lif_add_at_first,\n",
    "            #                     sae_l2_norm_bridge = sae_l2_norm_bridge, sae_lif_bridge = sae_lif_bridge, lif_add_at_last=lif_add_at_last, batch_norm_on=batch_norm_on).to(device)\n",
    "            net = torch.nn.DataParallel(net)\n",
    "        else:\n",
    "            net = SAE_fc_only(encoder_ch=[400, lateral_feature_num], \n",
    "                                decoder_ch=[400, n_sample], \n",
    "                                in_channels=n_sample, # in_channel 이 여기선 걍 lenght.\n",
    "                                synapse_fc_trace_const1=1,\n",
    "                                synapse_fc_trace_const2=v_decay,  #안씀 \n",
    "                                TIME=TIME, v_init=0.0, v_decay=v_decay, v_threshold=v_threshold, v_reset=v_reset, \n",
    "                                sg_width=4.0, surrogate='sigmoid', BPTT_on=BPTT_on, need_bias=need_bias, lif_add_at_first=lif_add_at_first,\n",
    "                                sae_l2_norm_bridge = sae_l2_norm_bridge, sae_lif_bridge = sae_lif_bridge, lif_add_at_last=lif_add_at_last, batch_norm_on=batch_norm_on, sae_relu_on=sae_relu_on).to(device)\n",
    "            net = torch.nn.DataParallel(net)\n",
    "\n",
    "    # net = torch.load('/home/bhkim003/github_folder/ByeonghyeonKim/my_snn/net_save/save_now_net_AE_re_e7000.pth')\n",
    "    # net = torch.load('/home/bhkim003/github_folder/ByeonghyeonKim/my_snn/net_save/save_now_net_20250101_210938_786.pth')\n",
    "    # load했으면 torch.nn.DataParallel 하지마\n",
    "    # net.module.load_state_dict(torch.load('/home/bhkim003/github_folder/ByeonghyeonKim/my_snn/net_save/save_now_net_annbase_20250108_210641_941.pth'))\n",
    "    if pretrained_net != None:\n",
    "        ######################## 모델이 달라서 dict로 weight만 넣고싶을 때\n",
    "        # # 저장된 가중치 로드\n",
    "        saved_state_dict = torch.load(pretrained_net)\n",
    "        current_state_dict = net.module.state_dict()\n",
    "\n",
    "        # 함수 호출로 가중치 매핑\n",
    "        updated_state_dict = map_and_load_weights(saved_state_dict, current_state_dict)\n",
    "\n",
    "        # 업데이트된 state_dict를 네트워크에 로드\n",
    "        net.module.load_state_dict(updated_state_dict)\n",
    "        ######################## 모델이 달라서 dict로 weight만 넣고싶을 때\n",
    "\n",
    "        ############## 일반적일 때\n",
    "        # net.module.load_state_dict(torch.load(pretrained_net))\n",
    "        ############## 일반적일 때\n",
    "    \n",
    "        # pre_net = Autoencoder_conv1(input_channels=input_channels, input_length=n_sample, encoder_ch = [32, 64, 96], fc_dim = lateral_feature_num, padding = 0, stride = 2, kernel_size = 3, need_bias=need_bias, l2norm_bridge=sae_l2_norm_bridge, relu_bridge=sae_lif_bridge, activation_collector_on=False,\n",
    "        #                         batch_norm_on=batch_norm_on, QCFS_neuron_on=False).to(device)\n",
    "        # pre_net = torch.nn.DataParallel(net)\n",
    "        # pre_net.module.load_state_dict(torch.load(pretrained_net))\n",
    "        # copy_weights(pre_net.module.encoder , net.module.encoder )\n",
    "        # copy_weights(pre_net.module.decoder , net.module.decoder  )\n",
    "\n",
    "        \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    wandb.watch(net, log=\"all\", log_freq = 10)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    if SAE_net == True:\n",
    "        assert 'SAE' in net.module.__class__.__name__\n",
    "\n",
    "\n",
    "\n",
    "    net = net.to(device)\n",
    "    print(f\"Total number of encoder parameters: {sum(p.numel() for p in net.module.encoder.parameters())}\")\n",
    "    print(net)\n",
    "    print('Device:',device)\n",
    "\n",
    "    \n",
    "    if optimizer == 'Adam':\n",
    "        optimizer = optim.Adam(net.parameters(), lr=learning_rate)\n",
    "    elif optimizer == 'SGD':\n",
    "        optimizer = optim.SGD(net.parameters(), lr = learning_rate, momentum = 0.9)\n",
    "    else:\n",
    "        assert False, 'optimizer를 잘못 입력했습니다.'\n",
    "        \n",
    "    loss_history = []\n",
    "    mean_cluster_accuracy_during_training_cycle_all_dataset_history = []\n",
    "    mean_cluster_accuracy_post_training_cycle_all_dataset_history = []\n",
    "    mean_cluster_accuracy_total_all_dataset_history = []\n",
    "\n",
    "    tau = np.zeros(num_cluster)\n",
    "\n",
    "    print(f\"\\nStart Training, current_time = {current_time}\")\n",
    "    mean_cluster_accuracy_post_training_cycle_all_dataset = 0\n",
    "    best_mean_cluster_accuracy_post_training_cycle_all_dataset = 0\n",
    "\n",
    "    if SAE_net == True:\n",
    "        assert 'SAE' in net.module.__class__.__name__\n",
    "        \n",
    "    k_means_acc_best = 0\n",
    "    min_loss = 9999999\n",
    "    min_loss_normal = 9999999\n",
    "    min_loss_coarse = 9999999\n",
    "    for epoch in range(max_epoch):\n",
    "        print()\n",
    "        l2_loss_bin= 0\n",
    "        ae_train_start_time = time.time()\n",
    "        running_loss = 0.0\n",
    "        running_loss_normal = 0.0\n",
    "        running_loss_coarse = 0.0\n",
    "        iter = 0\n",
    "        net.train()\n",
    "        # if True or max_epoch != 1:\n",
    "        wrong_element_sum = 0\n",
    "        same_data_num = 0\n",
    "        total_data_num = 0\n",
    "        if max_epoch != 1:\n",
    "            for data in train_loader:\n",
    "                optimizer.zero_grad()\n",
    "                total_data_num += len(data)\n",
    "                data = data.to(device)\n",
    "                scaling = (level_num-3)/level_num if conv1d_scaling else 1.0\n",
    "                data = zero_to_one_normalize_features(data, level_num=quantize_level_num, coarse_com_config=coarse_com_config, scaling=scaling, norm01=norm01) if normalize_on else data\n",
    "                # plot_origin_spike(data[0].cpu().detach().numpy(), min_max_y_on = True)\n",
    "                # plot_origin_spike(data[1].cpu().detach().numpy(), min_max_y_on = True)\n",
    "                spike_backup = data\n",
    "                spike = data\n",
    "                spike = spike.to(device) # batch, feature\n",
    "                spike_for_fusion2_net = spike\n",
    "                if coarse_com_mode == True and 'SAE' in net.module.__class__.__name__:\n",
    "                    # print(spike[0])\n",
    "                    spike = spike.unsqueeze(2).repeat(1, 1, level_num) # spike_length == level_num # (batch, time, feature)로 변환 \n",
    "                    spike = (spike > levels).to(torch.float) \n",
    "\n",
    "                    spike = (spike == 0).cumsum(dim=-1).eq(1).to(torch.float) if lc_adc_on == True else spike\n",
    "\n",
    "                    # spike: batch, time, level_num\n",
    "                    # levels: time, level_num\n",
    "                    if Conv_net == True:\n",
    "                        spike = spike.unsqueeze(-2) # batch, time, in_channel, feature or batch in_channel,feature\n",
    "                        if two_channel_input == True:\n",
    "                            spike_backup = spike_backup.to(device)\n",
    "                            spike_backup = spike_backup.unsqueeze(2).repeat(1, 1, level_num) # spike_length == level_num # (batch, time, feature)로 변환 \n",
    "                            spike_backup = (spike_backup <= levels).to(torch.float) \n",
    "                            spike_backup = (spike_backup == 1).cumsum(dim=-1).eq(1).to(torch.float) if lc_adc_on == True else spike_backup\n",
    "                            spike_backup = spike_backup.unsqueeze(-2)\n",
    "                            spike = torch.cat((spike, spike_backup), dim=-2)\n",
    "                    assert spike.shape[0] == batch_size and spike.shape[1] == TIME\n",
    "                elif 'SAE' in net.module.__class__.__name__:\n",
    "                    spike = spike.unsqueeze(-1).repeat(1, 1, TIME).permute(0,2,1) # (batch, time, feature)로 변환\n",
    "                    if Conv_net == True:\n",
    "                        spike = spike.unsqueeze(-2) # batch, time, in_channel, feature or batch in_channel,feature\n",
    "                else:\n",
    "                    if Conv_net == True:\n",
    "                        if coarse_com_mode == False:\n",
    "                            spike = spike.unsqueeze(-2) #batch in_channel,feature\n",
    "                        else:\n",
    "                            spike = spike.unsqueeze(2).repeat(1, 1, level_num) # spike_length == level_num # (batch, time, feature)로 변환 \n",
    "                            spike = (spike > levels).to(torch.float) \n",
    "\n",
    "                            spike = (spike == 0).cumsum(dim=-1).eq(1).to(torch.float) if lc_adc_on == True else spike\n",
    "\n",
    "                    else:\n",
    "                        if coarse_com_mode == False:\n",
    "                            pass\n",
    "                        else:\n",
    "                            spike = spike.unsqueeze(2).repeat(1, 1, level_num) # spike_length == level_num # (batch, time, feature)로 변환 \n",
    "                            spike = (spike > levels).to(torch.float) \n",
    "\n",
    "                            spike = (spike == 0).cumsum(dim=-1).eq(1).to(torch.float) if lc_adc_on == True else spike\n",
    "\n",
    "                            # spike: batch, time, feature\n",
    "                            spike = spike.reshape(spike.shape[0], -1)\n",
    "\n",
    "                    \n",
    "\n",
    "\n",
    "                    # if fusion_net == True:\n",
    "                    #     spike = spikegen.rate(spike, num_steps=TIME).transpose(0, 1)\n",
    "\n",
    "                # spike_class = net(spike) # batch, time, feature\n",
    "                encoded_spike = net.module.encoder(spike)\n",
    "                spike_class = net.module.decoder(encoded_spike)\n",
    "\n",
    "                # for i in range (2):\n",
    "                #     plot_spike(spike[i,:,0,:].cpu().numpy())\n",
    "                #     # plot_spike(spike[i,:,1,:].cpu().numpy())\n",
    "                #     plot_origin_spike(spike_class.squeeze()[i].cpu().detach().numpy(), min_max_y_on = True)\n",
    "                # assert False\n",
    "                        \n",
    "\n",
    "                loss = 0\n",
    "                loss_normal = torch.tensor(0.0)\n",
    "                loss_coarse = torch.tensor(0.0)\n",
    "                if coarse_com_mode == True and 'SAE' in net.module.__class__.__name__:\n",
    "                    criterion = nn.MSELoss().to(device)\n",
    "                    # loss1 = nn.MSELoss()(spike_class[..., 5:25], spike[..., 5:25])\n",
    "                    # loss2 = nn.MSELoss()(spike_class[..., 0:5], spike[..., 0:5])\n",
    "                    # loss3 = nn.MSELoss()(spike_class[..., 25:spike_length], spike[..., 25:spike_length])\n",
    "                    # loss = loss1 * 2.125 + (loss2 + loss3)/4\n",
    "\n",
    "                    # loss1 = nn.MSELoss()(spike_class[..., 5:25, :], spike[..., 5:25, :])\n",
    "                    # loss2 = nn.MSELoss()(spike_class[..., 0:5, :], spike[..., 0:5, :])\n",
    "                    # loss3 = nn.MSELoss()(spike_class[..., 25:spike_length, :], spike[..., 25:spike_length, :])\n",
    "                    # loss = loss1 * 2.125 + (loss2 + loss3)/4\n",
    "                    if fusion_net:\n",
    "                        # print('1', spike.shape) # batch, time, in_channel, feature [32, 50, 1, 50]\n",
    "                        \n",
    "                        # ### coarse에서 ann loss 만들기 ######\n",
    "                        # spike = spike.squeeze()\n",
    "                        # assert two_channel_input == False\n",
    "                        # zero_mask = (spike == 0)  # 0이 있는 위치\n",
    "                        # first_zero_idx = torch.where(zero_mask, torch.arange(spike.shape[-1]).to(device), spike.shape[-1]-1).min(dim=-1).values\n",
    "                        # spike = levels[0][first_zero_idx]\n",
    "                        # # plot_origin_spike(spike[0].cpu().detach().numpy())\n",
    "                        # ### coarse에서 ann loss 만들기 ######\n",
    "\n",
    "                        ### 그냥 원래 스파이크로 ann loss 만들기 ######\n",
    "                        spike = spike_for_fusion2_net\n",
    "                        ### 그냥 원래 스파이크로 ann loss 만들기 ######\n",
    "\n",
    "                        spike = spike.squeeze()\n",
    "                        spike_class = spike_class.squeeze()\n",
    "                        \n",
    "                        ### normal loss################\n",
    "                        # loss = criterion(spike_class, spike)\n",
    "                        ### normal loss################\n",
    "                        \n",
    "                        ### chan loss################\n",
    "                        loss1 = criterion(spike_class[..., 5:25], spike[..., 5:25])\n",
    "                        loss2 = criterion(spike_class[..., 0:5], spike[..., 0:5])\n",
    "                        loss3 = criterion(spike_class[..., 25:], spike[..., 25:])\n",
    "                        loss = loss1 * 2.125 + (loss2 + loss3)/4\n",
    "                        ### chan loss################\n",
    "\n",
    "\n",
    "                        # #########################################\n",
    "                        # # 손실 함수 정의 (예: MSELoss 사용)\n",
    "                        # criterion_joke = torch.nn.MSELoss(reduction='none')  # 개별 요소별 손실을 유지\n",
    "\n",
    "                        # # 손실 계산\n",
    "                        # loss1_joke = criterion_joke(spike_class[..., 5:25], spike[..., 5:25]).mean(dim=-1)  # (batch,)\n",
    "                        # loss2_joke = criterion_joke(spike_class[..., 0:5], spike[..., 0:5]).mean(dim=-1)    # (batch,)\n",
    "                        # loss3_joke = criterion_joke(spike_class[..., 25:], spike[..., 25:]).mean(dim=-1)    # (batch,)\n",
    "\n",
    "                        # # 주어진 가중치를 적용한 최종 손실\n",
    "                        # loss_joke = loss1_joke * 2.125 + (loss2_joke + loss3_joke) / 4  # (batch,)\n",
    "\n",
    "                        # # 가장 큰 손실을 갖는 샘플의 인덱스 찾기\n",
    "                        # max_loss_idx_joke = torch.argmax(loss_joke)\n",
    "\n",
    "                        # # 해당 샘플 선택\n",
    "                        # selected_sample_class = spike_class[max_loss_idx_joke]\n",
    "                        # selected_sample_spike = spike[max_loss_idx_joke]\n",
    "\n",
    "                        # # 선택한 샘플의 손실 값 출력\n",
    "                        # print(\"Index of max loss sample:\", max_loss_idx_joke.item())\n",
    "                        # print(\"Max loss value:\", loss_joke[max_loss_idx_joke].item())\n",
    "                        # mean_loss_joke = loss_joke.mean().item()\n",
    "                        # print(\"Mean loss across the batch:\", mean_loss_joke)\n",
    "\n",
    "                        # # 선택한 샘플을 시각화\n",
    "                        # plot_origin_spike(selected_sample_class.cpu().detach().numpy())\n",
    "                        # plot_origin_spike(selected_sample_spike.cpu().detach().numpy())\n",
    "                        # #########################################\n",
    "\n",
    "                        # coarse loss ######################################################\n",
    "                        loss_normal = criterion(spike_class, spike)\n",
    "                        level_num_in_loss = spike_length\n",
    "                        level_interval = (coarse_com_config[0] - coarse_com_config[1]) / (level_num_in_loss-1)  # max - min\n",
    "                        levels = [coarse_com_config[1] + level_interval * i for i in range(level_num_in_loss)]\n",
    "                        levels = torch.tensor(levels).to(torch.float).to(device)\n",
    "                        # print('coarse leves', levels)\n",
    "                        levels = levels.repeat(spike_length,1) \n",
    "\n",
    "                        spike = spike.squeeze()\n",
    "                        spike_class = spike_class.squeeze()\n",
    "                        # plot_origin_spike(spike_class[0].cpu().detach().numpy())\n",
    "                        spike = spike.unsqueeze(2).repeat(1, 1, level_num_in_loss) \n",
    "                        spike = (spike > levels).to(torch.float) \n",
    "                        spike_class = spike_class.unsqueeze(2).repeat(1, 1, level_num_in_loss) \n",
    "                        spike_class = (spike_class > levels).to(torch.float) \n",
    "                        # spike = spike[..., 0:-3, :]\n",
    "                        # spike_class = spike_class[..., 0:-3, :]\n",
    "                        loss_coarse = criterion(spike_class, spike)\n",
    "                        wrong_element_sum += torch.sum(torch.abs(spike - spike_class)).item() \n",
    "\n",
    "                        # plot_spike(spike_class[0].cpu().detach().numpy())\n",
    "                        # assert False\n",
    "                        # coarse loss ######################################################\n",
    "                    else:\n",
    "                        spike = spike.squeeze()\n",
    "                        spike_class = spike_class.squeeze()\n",
    "                        loss = criterion(spike_class, spike)\n",
    "\n",
    "                    for iii in range(spike.shape[0]):\n",
    "                        same_data_num = same_data_num + 1 if torch.eq(spike[iii], spike_class[iii]).all() else same_data_num\n",
    "                    wrong_element_sum += torch.sum(torch.abs(spike - spike_class)).item() \n",
    "\n",
    "                    # spike = spike.squeeze()\n",
    "                    # spike_class = spike_class.squeeze()\n",
    "                    # plot_spike(spike[0].cpu().detach().numpy())\n",
    "                    # plot_spike(spike_class[0].cpu().detach().numpy())\n",
    "                    # print('손실 절대값 합',np.sum(np.abs(spike[0].cpu().detach().numpy() - spike_class[0].cpu().detach().numpy())))\n",
    "                    # # assert False\n",
    "                elif 'SAE' in net.module.__class__.__name__:\n",
    "                    criterion = nn.MSELoss().to(device)\n",
    "                    loss1 = criterion(spike_class[..., 5:25], spike[..., 5:25])\n",
    "                    loss2 = criterion(spike_class[..., 0:5], spike[..., 0:5])\n",
    "                    loss3 = criterion(spike_class[..., 25:spike_length], spike[..., 25:spike_length])\n",
    "                    loss = loss1 * 2.125 + (loss2 + loss3)/4\n",
    "                    assert spike_length > 25, 'spike_length가 25보다 작음'\n",
    "                    # wrong_element_sum += torch.sum(torch.abs(spike - spike_class)).item() \n",
    "                else:\n",
    "                    criterion = nn.MSELoss().to(device)\n",
    "                    loss1 = criterion(spike_class[..., 5:25], spike[..., 5:25])\n",
    "                    loss2 = criterion(spike_class[..., 0:5], spike[..., 0:5])\n",
    "                    loss3 = criterion(spike_class[..., 25:spike_length], spike[..., 25:spike_length])\n",
    "                    loss = loss1 * 2.125 + (loss2 + loss3)/4\n",
    "                    assert spike_length > 25, 'spike_length가 25보다 작음'\n",
    "                    # wrong_element_sum += torch.sum(torch.abs(spike - spike_class)).item() \n",
    "\n",
    "\n",
    "                    if l2_norm_loss_weight > 0:\n",
    "                        assert len(encoded_spike.shape) == 2, 'time 성분 없는 걸로'\n",
    "                        l2_loss = l2_norm_loss(encoded_spike, target_norm=1.0)  # L2Norm Loss 계산, l2 1.0되게.\n",
    "                        loss = loss + l2_loss*l2_norm_loss_weight\n",
    "                        l2_loss_bin += l2_loss.item()\n",
    "\n",
    "                    # coarse loss ######################################################\n",
    "                    loss_normal = criterion(spike_class, spike)\n",
    "                    level_num_in_loss = quantize_level_num\n",
    "                    level_interval = (coarse_com_config[0] - coarse_com_config[1]) / (level_num_in_loss-1)  # max - min\n",
    "                    levels = [coarse_com_config[1] + level_interval * i for i in range(level_num_in_loss)]\n",
    "                    levels = torch.tensor(levels).to(torch.float).to(device)\n",
    "                    levels = levels.repeat(spike_length,1) \n",
    "\n",
    "                    spike = spike.squeeze()\n",
    "                    spike_class = spike_class.squeeze()\n",
    "                    # plot_origin_spike(spike_class[0].cpu().detach().numpy())\n",
    "                    spike = spike.unsqueeze(2).repeat(1, 1, level_num_in_loss) \n",
    "                    spike = (spike > levels).to(torch.float) \n",
    "                    spike_class = spike_class.unsqueeze(2).repeat(1, 1, level_num_in_loss) \n",
    "                    spike_class = (spike_class > levels).to(torch.float) \n",
    "                    # spike = spike[..., 0:-3, :]\n",
    "                    # spike_class = spike_class[..., 0:-3, :]\n",
    "                    loss_coarse = criterion(spike_class, spike)\n",
    "                    wrong_element_sum += torch.sum(torch.abs(spike - spike_class)).item() \n",
    "\n",
    "                    # plot_spike(spike_class[0].cpu().detach().numpy())\n",
    "                    # assert False\n",
    "                    # coarse loss ######################################################\n",
    "\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                running_loss += loss.item()\n",
    "                running_loss_normal += loss_normal.item()\n",
    "                running_loss_coarse += loss_coarse.item()\n",
    "                # print(f'\\nepoch-{epoch}, running_loss : {running_loss:.5f}, iter percent {iter/len(train_loader)*100:.2f}%')\n",
    "                iter += 1\n",
    "        else:\n",
    "            print('\\n\\n\\n max_epoch 1이면 Train 안함!!!!!!!!!!!!!!!!!!!!!')\n",
    "        if l2_norm_loss_weight > 0:\n",
    "            print('l2_loss_bin', l2_loss_bin/len(train_loader))\n",
    "        avg_loss = running_loss / len(train_loader)\n",
    "        assert not np.isnan(avg_loss), f\"Error: avg_loss is NaN! Running loss: {running_loss}, Length of train_loader: {len(train_loader)}\"\n",
    "        loss_history.append((epoch, avg_loss))\n",
    "        min_loss = min(min_loss, avg_loss)\n",
    "        min_loss_normal = min(min_loss_normal, running_loss_normal/len(train_loader))\n",
    "        min_loss_coarse = min(min_loss_coarse, running_loss_coarse/len(train_loader))\n",
    "        print(f'\\nepoch-{epoch} loss : {avg_loss:.8f}, loss_normal : {running_loss_normal/len(train_loader):.8f}, loss_coarse : {running_loss_coarse/len(train_loader):.8f}, min_loss : {min_loss:.8f}, min_loss_normal : {min_loss_normal:.8f}, min_loss_coarse : {min_loss_coarse:.8f}, wrong_element_sum : {wrong_element_sum:.8f}, same_data : {100*same_data_num/(total_data_num+1e-12):.2f}%')\n",
    "        print(f\"ae train 실행 시간: {time.time()-ae_train_start_time:.3f}초, 전체 시작 시간 {current_time}\")\n",
    "\n",
    "        # plot_activation_distribution(net)\n",
    "\n",
    "        if SAE_net == False and converted_net_forward == True:\n",
    "            source_encoder = net.module.encoder \n",
    "            target_encoder = converted_net.module.encoder  \n",
    "            copy_weights(source_encoder, target_encoder)\n",
    "\n",
    "        cluster_accuracy_during_training_cycle_all_dataset = np.zeros(dataset_num)\n",
    "        cluster_accuracy_post_training_cycle_all_dataset = np.zeros(dataset_num)\n",
    "        cluster_accuracy_total_all_dataset = np.zeros(dataset_num)    \n",
    "\n",
    "        k_means_acc = 0\n",
    "        converted_k_means_acc = 0\n",
    "        if(epoch % accuracy_check_epoch_term == 0 or epoch == 1 or epoch == max_epoch-1): \n",
    "            accuracy_check_start_time = time.time()\n",
    "            print(f'\\nepoch-{epoch} accuracy check')\n",
    "            k_means_bin_origin_feature = []\n",
    "            k_means_bin = []\n",
    "            converted_k_means_bin = []\n",
    "            for ds in range(dataset_num):\n",
    "                # print('\\n', spike_tot[ds])\n",
    "\n",
    "                spike_template = np.load(my_path_ground_BH + template[ds])\n",
    "                spike = np.load(my_path_ground_BH + spike_tot[ds])\n",
    "                label = np.load(my_path_ground_BH + label_tot[ds])\n",
    "                spike_template = torch.from_numpy(spike_template).to(device)\n",
    "                spike = torch.from_numpy(spike).to(device)\n",
    "                scaling = (level_num-3)/level_num if conv1d_scaling else 1.0\n",
    "                spike_template = zero_to_one_normalize_features(spike_template, level_num=quantize_level_num, coarse_com_config=coarse_com_config, scaling=scaling, norm01=norm01) if normalize_on else spike_template\n",
    "                spike = zero_to_one_normalize_features(spike, level_num=quantize_level_num, coarse_com_config=coarse_com_config, scaling=scaling, norm01=norm01) if normalize_on else spike\n",
    "                \n",
    "                hidden_size = lateral_feature_num*TIME if 'SAE' in net.module.__class__.__name__ and SAE_hidden_nomean == True and fusion_net == False or 'SAE_FUSION5' in net.module.__class__.__name__ else lateral_feature_num\n",
    "                hidden_size = lateral_feature_num if '_DR' in net.module.__class__.__name__  else hidden_size\n",
    "\n",
    "                Cluster = np.zeros((num_cluster, hidden_size))\n",
    "                assert Cluster.shape[-1] == hidden_size, '이거 hidden dim 4 아니게 할 거면 잘 바꿔라'\n",
    "                \n",
    "\n",
    "\n",
    "                net.eval()\n",
    "                with torch.no_grad():\n",
    "                    spike_torch = spike_template.float()\n",
    "                    spike_torch = spike_torch[:num_cluster]\n",
    "                    spike_backup = spike_torch\n",
    "                    spike_torch = spike_torch.to(device)\n",
    "                    if coarse_com_mode == True and 'SAE' in net.module.__class__.__name__:\n",
    "                        spike_torch = spike_torch.unsqueeze(2).repeat(1, 1, level_num) # spike_length == level_num # (batch, time, feature)로 변환 \n",
    "                        spike_torch = (spike_torch > levels).to(torch.float) \n",
    "                        spike_torch = (spike_torch == 0).cumsum(dim=-1).eq(1).to(torch.float) if lc_adc_on == True else spike_torch\n",
    "                        if Conv_net == True:\n",
    "                            spike_torch = spike_torch.unsqueeze(-2) # batch, time, in_channel, feature or batch in_channel,feature\n",
    "                            if two_channel_input == True:\n",
    "                                spike_backup = spike_backup.to(device)\n",
    "                                spike_backup = spike_backup.unsqueeze(2).repeat(1, 1, level_num) # spike_length == level_num # (batch, time, feature)로 변환 \n",
    "                                spike_backup = (spike_backup <= levels).to(torch.float) \n",
    "                                spike_backup = (spike_backup == 1).cumsum(dim=-1).eq(1).to(torch.float) if lc_adc_on == True else spike_backup\n",
    "                                spike_backup = spike_backup.unsqueeze(-2) # batch, time, in_channel, feature\n",
    "                                spike_torch = torch.cat((spike_torch, spike_backup), dim=-2)\n",
    "                    elif 'SAE' in net.module.__class__.__name__:\n",
    "                        spike_torch = spike_torch.unsqueeze(1).repeat(1, TIME, 1) # (batch, time, feature)로 변환\n",
    "                        if Conv_net == True:\n",
    "                            spike_torch = spike_torch.unsqueeze(-2) # batch, time, in_channel, feature or batch in_channel,feature\n",
    "                    else:\n",
    "                        # if Conv_net == True:\n",
    "                        #     spike_torch = spike_torch.unsqueeze(-2) #batch in_channel,feature\n",
    "                        if Conv_net == True:\n",
    "                            if coarse_com_mode == False:\n",
    "                                spike_torch = spike_torch.unsqueeze(-2) #batch in_channel,feature\n",
    "                            else:\n",
    "                                spike_torch = spike_torch.unsqueeze(2).repeat(1, 1, level_num) # spike_length == level_num # (batch, time, feature)로 변환 \n",
    "                                spike_torch = (spike_torch > levels).to(torch.float) \n",
    "\n",
    "                                spike_torch = (spike_torch == 0).cumsum(dim=-1).eq(1).to(torch.float) if lc_adc_on == True else spike_torch\n",
    "\n",
    "                        else:\n",
    "                            if coarse_com_mode == False:\n",
    "                                pass\n",
    "                            else:\n",
    "                                spike_torch = spike_torch.unsqueeze(2).repeat(1, 1, level_num) # spike_length == level_num # (batch, time, feature)로 변환 \n",
    "                                spike_torch = (spike_torch > levels).to(torch.float) \n",
    "\n",
    "                                spike_torch = (spike_torch == 0).cumsum(dim=-1).eq(1).to(torch.float) if lc_adc_on == True else spike_torch\n",
    "\n",
    "                                # spike: batch, time, feature\n",
    "                                spike_torch = spike_torch.reshape(spike_torch.shape[0], -1)\n",
    "\n",
    "                        if converted_net_forward == True:\n",
    "                            spike_torch_spikegen = spikegen.rate(spike_torch, num_steps=TIME).transpose(0, 1)\n",
    "                        # if fusion_net == True:\n",
    "                        #     spike_torch = spikegen.rate(spike_torch, num_steps=TIME).transpose(0, 1)\n",
    "                    ### forward #######################################################\n",
    "                    inner_inf = net.module.encoder(spike_torch)\n",
    "                    if SAE_net == False and converted_net_forward == True:\n",
    "                        converted_inner_inf = converted_net.module.encoder(spike_torch_spikegen)\n",
    "                    ### forward #######################################################\n",
    "\n",
    "                    # if ds % 4 == 0:\n",
    "                    #     for i in range(4):\n",
    "                    #         decoded = net.module.decoder(inner_inf).squeeze()\n",
    "                    #         plot_spike(spike_torch[i,:,:].cpu().numpy())\n",
    "                    #         plot_spike(inner_inf[i,:].cpu().numpy())\n",
    "                    #         # plot_origin_spike(net.module.decoder(inner_inf)[i,:].cpu().numpy())\n",
    "                    #         plot_origin_spike(decoded[i].cpu().numpy(), min_max_y_on = True)\n",
    "                        \n",
    "                    # if 'SAE' in net.module.__class__.__name__:\n",
    "                    #     tensors = [inner_inf[0][i] for i in range(TIME)] \n",
    "                    #     all_equal = all(torch.equal(tensors[0], t) for t in tensors)\n",
    "                    #     print(all_equal, inner_inf)\n",
    "\n",
    "                    if 'SAE' in net.module.__class__.__name__:\n",
    "                        if SAE_hidden_nomean == True:\n",
    "                            inner_inf = inner_inf.reshape(inner_inf.shape[0],-1)# time*feature 펼치기\n",
    "                        else:\n",
    "                            inner_inf = inner_inf.mean(dim=1)# Time 방향으로 평균\n",
    "                        # inner_inf = F.normalize(inner_inf, p=2, dim=1)\n",
    "                    Cluster = inner_inf.cpu().detach().numpy()\n",
    "\n",
    "                encoder_batch = 128\n",
    "                spike_hidden = np.zeros((len(spike), hidden_size))\n",
    "                converted_spike_hidden = np.zeros((len(spike), hidden_size))\n",
    "                net.eval()\n",
    "                with torch.no_grad():\n",
    "                    now_index = 0\n",
    "                    while (1):\n",
    "                        now_end_index = now_index+encoder_batch if now_index+encoder_batch < len(spike) else len(spike)\n",
    "                        spike_batch = spike[now_index:now_end_index] \n",
    "                        spike_torch = spike_batch\n",
    "                        spike_torch = spike_torch.float()\n",
    "                        spike_backup = spike_torch\n",
    "                        spike_torch = spike_torch.to(device)\n",
    "                        if coarse_com_mode == True and 'SAE' in net.module.__class__.__name__:\n",
    "                            spike_torch = spike_torch.unsqueeze(2).repeat(1, 1, level_num) # spike_length == level_num # (batch, time, feature)로 변환 \n",
    "                            spike_torch = (spike_torch > levels).to(torch.float) \n",
    "                            spike_torch = (spike_torch == 0).cumsum(dim=-1).eq(1).to(torch.float) if lc_adc_on == True else spike_torch\n",
    "                            if Conv_net == True:\n",
    "                                spike_torch = spike_torch.unsqueeze(-2) # batch, time, in_channel, feature or batch in_channel,feature\n",
    "                                if two_channel_input == True:\n",
    "                                    spike_backup = spike_backup.to(device)\n",
    "                                    spike_backup = spike_backup.unsqueeze(2).repeat(1, 1, level_num) # spike_length == level_num # (batch, time, feature)로 변환 \n",
    "                                    spike_backup = (spike_backup <= levels).to(torch.float) \n",
    "                                    spike_backup = (spike_backup == 1).cumsum(dim=-1).eq(1).to(torch.float) if lc_adc_on == True else spike_backup\n",
    "                                    spike_backup = spike_backup.unsqueeze(-2)\n",
    "                                    spike_torch = torch.cat((spike_torch, spike_backup), dim=-2)\n",
    "                        elif 'SAE' in net.module.__class__.__name__:\n",
    "                            spike_torch = spike_torch.unsqueeze(1).repeat(1, TIME, 1) # (batch, time, feature)로 변환\n",
    "                            if Conv_net == True:\n",
    "                                spike_torch = spike_torch.unsqueeze(-2) # batch, time, in_channel, feature or batch in_channel,feature\n",
    "                        else:\n",
    "                            # if Conv_net == True:\n",
    "                            #     spike_torch = spike_torch.unsqueeze(-2) #batch in_channel,feature\n",
    "                            if Conv_net == True:\n",
    "                                if coarse_com_mode == False:\n",
    "                                    spike_torch = spike_torch.unsqueeze(-2) #batch in_channel,feature\n",
    "                                else:\n",
    "                                    spike_torch = spike_torch.unsqueeze(2).repeat(1, 1, level_num) # spike_length == level_num # (batch, time, feature)로 변환 \n",
    "                                    spike_torch = (spike_torch > levels).to(torch.float) \n",
    "\n",
    "                                    spike_torch = (spike_torch == 0).cumsum(dim=-1).eq(1).to(torch.float) if lc_adc_on == True else spike_torch\n",
    "\n",
    "                            else:\n",
    "                                if coarse_com_mode == False:\n",
    "                                    pass\n",
    "                                else:\n",
    "                                    spike_torch = spike_torch.unsqueeze(2).repeat(1, 1, level_num) # spike_length == level_num # (batch, time, feature)로 변환 \n",
    "                                    spike_torch = (spike_torch > levels).to(torch.float) \n",
    "\n",
    "                                    spike_torch = (spike_torch == 0).cumsum(dim=-1).eq(1).to(torch.float) if lc_adc_on == True else spike_torch\n",
    "\n",
    "                                    # spike: batch, time, feature\n",
    "                                    spike_torch = spike_torch.reshape(spike_torch.shape[0], -1)\n",
    "                            if converted_net_forward == True:\n",
    "                                spike_torch_spikegen = spikegen.rate(spike_torch, num_steps=TIME).transpose(0, 1)\n",
    "                            # if fusion_net == True:\n",
    "                            #     spike_torch = spikegen.rate(spike_torch, num_steps=TIME).transpose(0, 1)\n",
    "                        ### forward #######################################################\n",
    "                        inner_inf = net.module.encoder(spike_torch)\n",
    "                        if SAE_net == False and converted_net_forward == True:\n",
    "                            converted_inner_inf = converted_net.module.encoder(spike_torch_spikegen)\n",
    "                        ### forward #######################################################\n",
    "                            \n",
    "                        if 'SAE' in net.module.__class__.__name__:\n",
    "                            if SAE_hidden_nomean == True:\n",
    "                                inner_inf = inner_inf.reshape(spike_batch.shape[0],-1)# 펼치기\n",
    "                            else:\n",
    "                                inner_inf = inner_inf.mean(dim=1)# Time 방향으로 평균\n",
    "                            # inner_inf = F.normalize(inner_inf, p=2, dim=1)\n",
    "                        spike_hidden[now_index:now_end_index] = inner_inf.cpu().detach().numpy()\n",
    "                        if SAE_net == False and converted_net_forward == True:\n",
    "                            converted_spike_hidden[now_index:now_end_index] = converted_inner_inf.cpu().detach().numpy()\n",
    "                        now_index += encoder_batch\n",
    "                        if (now_index >= len(spike)):\n",
    "                            break\n",
    "                    \n",
    "                spike_id = np.zeros(len(spike))\n",
    "                distance_sm = np.zeros(num_cluster)\n",
    "                tau = np.zeros(num_cluster)\n",
    "                \n",
    "                plot_tau = []\n",
    "                plot_denominator = []\n",
    "                plot_m = []\n",
    "                plot_max_tau = []\n",
    "                for spike_index in range(len(spike)): \n",
    "                    for q in range(num_cluster):\n",
    "                        tau[q] = np.dot(spike_hidden[spike_index, :], Cluster[q, :]) # 이거 l2norm 거쳐서 나온 거니까 분모 1임.\n",
    "                        denominator =  np.linalg.norm(spike_hidden[spike_index, :])*np.linalg.norm(Cluster[q, :]) + 1e-12\n",
    "                        plot_denominator.append(denominator)\n",
    "                        if 'SAE' in net.module.__class__.__name__: # AE 때는 l2norm거쳐서 나와서 괜찮음\n",
    "                            tau[q] = tau[q] / denominator\n",
    "\n",
    "                        plot_tau.append(tau[q])\n",
    "\n",
    "                    # for i in range(num_cluster): # l2 distance\n",
    "                    #     distance_sm[i] = np.sum(np.power(np.abs(Cluster[i] - spike_hidden[spike_index, :]), 2))\n",
    "                    distance_sm = np.sum(np.power(np.abs(Cluster - spike_hidden[spike_index, :]), 2), axis=1)\n",
    "\n",
    "                    m = np.argmin(distance_sm)\n",
    "                    plot_m.append(m)\n",
    "                    spike_id[spike_index] = m + 1\n",
    "                    # print(spike_tot[ds], spike_index,np.max(tau))\n",
    "                    plot_max_tau.append(np.max(tau))\n",
    "                    if(np.max(tau) >= cos_thr[ds] and spike_index < training_cycle): # 원래 1400 아니냐?\n",
    "                        Cluster[m] = (Cluster[m] * 15 + spike_hidden[spike_index, :])/16\n",
    "\n",
    "\n",
    "                \n",
    "                origin_kmeans_accuracy = cluster_spikes_with_accuracy_torch(features= spike, true_labels=label-1, n_clusters=3, init_point=None)\n",
    "                kmeans_accuracy = cluster_spikes_with_accuracy_torch(features= torch.tensor(spike_hidden).to(device), true_labels=label-1, n_clusters=3, init_point=None)\n",
    "                \n",
    "                # print('temporoal k')\n",
    "                # result = evaluate_clustering_accuracy(spike_hidden.reshape(spike_hidden.shape[0], TIME, -1), label-1, n_clusters=3)\n",
    "                # print('원래', kmeans_accuracy)\n",
    "                # print(result)\n",
    "\n",
    "                k_means_bin_origin_feature.append(origin_kmeans_accuracy)\n",
    "                k_means_bin.append(kmeans_accuracy)\n",
    "                if SAE_net == False and converted_net_forward == True:\n",
    "                    converted_kmeans_accuracy = cluster_spikes_with_accuracy_torch(features= torch.tensor(converted_spike_hidden).to(device), true_labels=label-1, n_clusters=3, init_point=None)\n",
    "                    converted_k_means_bin.append(converted_kmeans_accuracy)\n",
    "                # sklearn kmeans인데 cpu많이먹어서 버림.\n",
    "                # origin_kmeans_accuracy = cluster_spikes_with_accuracy(features= spike.cpu().detach().numpy(), true_labels=label-1, n_clusters=3, init_point=None)\n",
    "                # kmeans_accuracy = cluster_spikes_with_accuracy(features= spike_hidden, true_labels=label-1, n_clusters=3, init_point=None)\n",
    "                # k_means_bin_origin_feature.append(origin_kmeans_accuracy)\n",
    "                # k_means_bin.append(kmeans_accuracy)\n",
    "                # if SAE_net == False and converted_net_forward == True:\n",
    "                #     converted_kmeans_accuracy = cluster_spikes_with_accuracy(features= converted_spike_hidden, true_labels=label-1, n_clusters=3, init_point=None)\n",
    "                #     converted_k_means_bin.append(converted_kmeans_accuracy)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "                # print('Cluster',Cluster)\n",
    "                # print('spike_id', spike_id)\n",
    "\n",
    "                # spike id 분포 확인하기\n",
    "                # unique_elements, counts = np.unique(spike_id, return_counts=True)\n",
    "                # print(\"Unique elements:\", unique_elements)\n",
    "                # print(\"Counts:\", counts)\n",
    "\n",
    "                cluster_accuracy_during_training_cycle = np.zeros(math.factorial(num_cluster))\n",
    "                cluster_accuracy_post_training_cycle = np.zeros(math.factorial(num_cluster))\n",
    "                cluster_accuracy_total = np.zeros(math.factorial(num_cluster))\n",
    "                \n",
    "                label_converter_ground = list(range(1, num_cluster + 1)) # [1, 2, 3, 4] 생성\n",
    "                label_converter_permutations = list(itertools.permutations(label_converter_ground)) # 모든 순열 구하기\n",
    "                perm_i = 0\n",
    "                perm_start_time = time.time() \n",
    "                for perm in label_converter_permutations:\n",
    "                    label_converter = list(perm)\n",
    "                    # print(label_converter)\n",
    "                    correct_during_training_cycle = 0\n",
    "                    correct_post_training_cycle = 0\n",
    "\n",
    "                    assert len(spike_id) == len(label), 'spike_id랑 label 길이 같아야 됨.'\n",
    "                    for i in range(len(spike_id)):\n",
    "                        if(label_converter[int(spike_id[i]-1)] == label[i]):\n",
    "                            if i < training_cycle:\n",
    "                                correct_during_training_cycle += 1\n",
    "                            else:\n",
    "                                correct_post_training_cycle += 1\n",
    "\n",
    "                    cluster_accuracy_during_training_cycle[perm_i] = correct_during_training_cycle/training_cycle\n",
    "                    cluster_accuracy_post_training_cycle[perm_i] = correct_post_training_cycle/(len(spike_id)-training_cycle)\n",
    "                    cluster_accuracy_total[perm_i] = (correct_during_training_cycle+correct_post_training_cycle)/(len(spike_id))\n",
    "                    perm_i += 1\n",
    "                # print(f\"perm 실행 시간: {time.time()-perm_start_time:.3f}초\")\n",
    "                \n",
    "                cluster_accuracy_during_training_cycle_all_dataset[ds] = np.max(cluster_accuracy_during_training_cycle)\n",
    "                cluster_accuracy_post_training_cycle_all_dataset[ds] = cluster_accuracy_post_training_cycle[np.argmax(cluster_accuracy_during_training_cycle)]\n",
    "                cluster_accuracy_total_all_dataset[ds] = cluster_accuracy_total[np.argmax(cluster_accuracy_during_training_cycle)]\n",
    "                # plot_distributions(ds, plot_tau, plot_denominator, plot_m, plot_max_tau, cos_thr[ds],\n",
    "                #                    cluster_accuracy_during_training_cycle_all_dataset[ds], cluster_accuracy_post_training_cycle_all_dataset[ds], cluster_accuracy_total_all_dataset[ds])\n",
    "            print(f'k_means origin feature average accuracy : {100*sum(k_means_bin_origin_feature)/(len(k_means_bin_origin_feature)+1e-12):.8f}%, total {k_means_bin_origin_feature}')\n",
    "            \n",
    "            mean_cluster_accuracy_during_training_cycle_all_dataset = np.mean(cluster_accuracy_during_training_cycle_all_dataset)\n",
    "            mean_cluster_accuracy_post_training_cycle_all_dataset = np.mean(cluster_accuracy_post_training_cycle_all_dataset)\n",
    "            mean_cluster_accuracy_total_all_dataset = np.mean(cluster_accuracy_total_all_dataset)\n",
    "            \n",
    "            if SAE_net == False and converted_net_forward == True:\n",
    "                converted_k_means_acc = 100*sum(converted_k_means_bin)/len(converted_k_means_bin)\n",
    "                print(f'converted_kmeans average accuracy : {converted_k_means_acc:.8f}%, total {converted_k_means_bin}')\n",
    "            k_means_acc = 100*sum(k_means_bin)/len(k_means_bin)\n",
    "            if k_means_acc > k_means_acc_best:\n",
    "                # torch.save(net, f\"net_save/save_now_net_{current_time}.pth\")\n",
    "                torch.save(net.module.state_dict(), f\"net_save/save_now_net_{current_time}.pth\")\n",
    "                print('save model')\n",
    "                best_mean_cluster_accuracy_post_training_cycle_all_dataset = mean_cluster_accuracy_post_training_cycle_all_dataset\n",
    "            \n",
    "            k_means_acc_best = max(k_means_acc_best, k_means_acc)\n",
    "            print(f'kmeans average accuracy best : {k_means_acc_best:.2f}%, kmeans average accuracy : {k_means_acc:.8f}%, total {k_means_bin}')\n",
    "            print(f'cluster_accuracy_post_training_cycle_all_dataset : {cluster_accuracy_post_training_cycle_all_dataset}')\n",
    "\n",
    "            \n",
    "            mean_cluster_accuracy_during_training_cycle_all_dataset_history.append((epoch, mean_cluster_accuracy_during_training_cycle_all_dataset*100))\n",
    "            mean_cluster_accuracy_post_training_cycle_all_dataset_history.append((epoch, mean_cluster_accuracy_post_training_cycle_all_dataset*100))\n",
    "            mean_cluster_accuracy_total_all_dataset_history.append((epoch, mean_cluster_accuracy_total_all_dataset*100))\n",
    "            print(f\"mean_cluster_accuracy_during_training_cycle : {mean_cluster_accuracy_during_training_cycle_all_dataset*100:.2f}%, post_traincycle_acc : {mean_cluster_accuracy_post_training_cycle_all_dataset*100:.2f}%, total_acc : {mean_cluster_accuracy_total_all_dataset*100:.8f}%\")\n",
    "\n",
    "            # kmeans accuracy기준으로 좋은 거 저장할 거임\n",
    "            # if mean_cluster_accuracy_post_training_cycle_all_dataset > best_mean_cluster_accuracy_post_training_cycle_all_dataset:\n",
    "            #     # torch.save(net, f\"net_save/save_now_net_{current_time}.pth\")\n",
    "            #     torch.save(net.module.state_dict(), f\"net_save/save_now_net_{current_time}.pth\")\n",
    "            #     print('save model')\n",
    "            #     best_mean_cluster_accuracy_post_training_cycle_all_dataset = mean_cluster_accuracy_post_training_cycle_all_dataset\n",
    "            print(f\"best_mean_cluster_accuracy_post_training_cycle_all_dataset : {best_mean_cluster_accuracy_post_training_cycle_all_dataset*100:.2f}%\")\n",
    "            print(f\"accuracy_check 실행 시간: {time.time()-accuracy_check_start_time:.3f}초\")\n",
    "\n",
    "        wandb.log({\"avg_loss\": avg_loss})\n",
    "        wandb.log({\"mean_cluster_accuracy_post_training_cycle_all_dataset\": mean_cluster_accuracy_post_training_cycle_all_dataset})\n",
    "        wandb.log({\"best_mean_cluster_accuracy_post_training_cycle_all_dataset\": best_mean_cluster_accuracy_post_training_cycle_all_dataset})\n",
    "        wandb.log({\"best_mean_cluster_accuracy_post_training_cycle_all_dataset2\": best_mean_cluster_accuracy_post_training_cycle_all_dataset})\n",
    "        wandb.log({\"k_means_acc\": k_means_acc})\n",
    "        wandb.log({\"k_means_acc_best\": k_means_acc_best})\n",
    "        wandb.log({\"converted_k_means_acc\": converted_k_means_acc})\n",
    "\n",
    "\n",
    "        # 저장\n",
    "        with open(f\"result_save/cluster_accuracy_history_{current_time}.pkl\", \"wb\") as f:\n",
    "            pickle.dump({\n",
    "                \"loss_history\": loss_history,\n",
    "                \"mean_cluster_accuracy_during_training_cycle_all_dataset_history\": mean_cluster_accuracy_during_training_cycle_all_dataset_history,\n",
    "                \"mean_cluster_accuracy_post_training_cycle_all_dataset_history\": mean_cluster_accuracy_post_training_cycle_all_dataset_history,\n",
    "                \"mean_cluster_accuracy_total_all_dataset_history\": mean_cluster_accuracy_total_all_dataset_history,\n",
    "            }, f)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mbhkim003\u001b[0m (\u001b[33mbhkim003-seoul-national-university\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.19.8 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.17.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/nfs/home/bhkim003/github_folder/ByeonghyeonKim/my_snn/wandb/run-20250312_165417-lc1zpj4z</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/bhkim003-seoul-national-university/spike_sorting%20just%20run/runs/lc1zpj4z' target=\"_blank\">tough-universe-1438</a></strong> to <a href='https://wandb.ai/bhkim003-seoul-national-university/spike_sorting%20just%20run' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/bhkim003-seoul-national-university/spike_sorting%20just%20run' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/spike_sorting%20just%20run</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/bhkim003-seoul-national-university/spike_sorting%20just%20run/runs/lc1zpj4z' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/spike_sorting%20just%20run/runs/lc1zpj4z</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'gpu': '0', 'Conv_net': True, 'SAE_net': True, 'dataset_num': 16, 'spike_length': 50, 'num_cluster': 4, 'training_cycle': 1400, 'batch_size': 32, 'max_epoch': 10000, 'learning_rate': 0.001, 'normalize_on': True, 'need_bias': False, 'lif_add_at_first': False, 'my_seed': 42, 'TIME': 50, 'v_decay': 0.5, 'v_threshold': 0.25, 'v_reset': 0.0, 'BPTT_on': True, 'SAE_hidden_nomean': True, 'current_time': '20250312_165415_014', 'optimizer': 'Adam', 'coarse_com_mode': True, 'sae_l2_norm_bridge': True, 'sae_lif_bridge': False, 'accuracy_check_epoch_term': 1, 'lif_add_at_last': False, 'two_channel_input': False, 'lateral_feature_num': 6, 'lc_adc_on': False, 'converted_net_forward': False, 'pretrained_net': None, 'vth_mul_on': False, 'batch_norm_on': False, 'l2_norm_loss_weight': 0, 'QCFS_neuron_on': False, 'quantize_level_num': 0, 'fusion_net': True, 'repeat_coding': False, 'sae_relu_on': False, 'conv1d_scaling': False, 'norm01': True, 'coarse_com_config': (0.999, -0.0)}\n",
      "cos_thr [0.95 0.95 0.95 0.95 0.95 0.95 0.95 0.85 0.95 0.9  0.8  0.95 0.95 0.95\n",
      " 0.95 0.8 ]\n",
      "conv length [50, 24, 11, 5]\n",
      "Total number of encoder parameters: 27852\n",
      "DataParallel(\n",
      "  (module): SAE_FUSION6_net_conv1(\n",
      "    (activation_function): LIF_layer()\n",
      "    (encoder): Sequential(\n",
      "      (0): SSBH_DimChanger_one_two()\n",
      "      (1): SSBH_DimChanger_for_one_two_coupling()\n",
      "      (2): Conv1d(1, 32, kernel_size=(3,), stride=(2,), bias=False)\n",
      "      (3): SSBH_DimChanger_for_one_two_decoupling()\n",
      "      (4): LIF_layer()\n",
      "      (5): SSBH_DimChanger_for_one_two_coupling()\n",
      "      (6): Conv1d(32, 64, kernel_size=(3,), stride=(2,), bias=False)\n",
      "      (7): SSBH_DimChanger_for_one_two_decoupling()\n",
      "      (8): LIF_layer()\n",
      "      (9): SSBH_DimChanger_for_one_two_coupling()\n",
      "      (10): Conv1d(64, 96, kernel_size=(3,), stride=(2,), bias=False)\n",
      "      (11): SSBH_DimChanger_for_one_two_decoupling()\n",
      "      (12): LIF_layer()\n",
      "      (13): SSBH_DimChanger_for_one_two_coupling()\n",
      "      (14): SSBH_DimChanger_for_fc()\n",
      "      (15): Linear(in_features=480, out_features=6, bias=False)\n",
      "      (16): SSBH_DimChanger_for_one_two_decoupling()\n",
      "      (17): LIF_layer()\n",
      "      (18): SSBH_DimChanger_one_two()\n",
      "      (19): SSBH_MultiLinearLayer(\n",
      "        (linears): ModuleList(\n",
      "          (0): Linear(in_features=50, out_features=1, bias=False)\n",
      "          (1): Linear(in_features=50, out_features=1, bias=False)\n",
      "          (2): Linear(in_features=50, out_features=1, bias=False)\n",
      "          (3): Linear(in_features=50, out_features=1, bias=False)\n",
      "          (4): Linear(in_features=50, out_features=1, bias=False)\n",
      "          (5): Linear(in_features=50, out_features=1, bias=False)\n",
      "        )\n",
      "      )\n",
      "      (20): SSBH_L2NormLayer()\n",
      "    )\n",
      "    (decoder): Sequential(\n",
      "      (0): Linear(in_features=6, out_features=480, bias=False)\n",
      "      (1): ReLU()\n",
      "      (2): SSBH_DimChanger_for_conv1()\n",
      "      (3): ConvTranspose1d(96, 64, kernel_size=(3,), stride=(2,), bias=False)\n",
      "      (4): ReLU()\n",
      "      (5): ConvTranspose1d(64, 32, kernel_size=(3,), stride=(2,), output_padding=(1,), bias=False)\n",
      "      (6): ReLU()\n",
      "      (7): ConvTranspose1d(32, 1, kernel_size=(3,), stride=(2,), output_padding=(1,), bias=False)\n",
      "    )\n",
      "  )\n",
      ")\n",
      "Device: cuda\n",
      "\n",
      "Start Training, current_time = 20250312_165415_014\n",
      "\n",
      "\n",
      "epoch-0 loss : 0.02575046, loss_normal : 0.01814831, loss_coarse : 0.08282674, min_loss : 0.02575046, min_loss_normal : 0.01814831, min_loss_coarse : 0.08282674, wrong_element_sum : 15902734.00000000, same_data : 0.00%\n",
      "ae train 실행 시간: 124.694초, 전체 시작 시간 20250312_165415_014\n",
      "\n",
      "epoch-0 accuracy check\n",
      "k_means origin feature average accuracy : 82.24779740%, total [0.9746727376209448, 0.9733106189664963, 0.9700891573195284, 0.9530800230282096, 0.943108504398827, 0.9150568181818182, 0.801817648783348, 0.6622234826999432, 0.9488619568430388, 0.822215777262181, 0.586405529953917, 0.5005858230814294, 0.9429250891795482, 0.8922588099364529, 0.6738372093023256, 0.5991983967935872]\n",
      "save model\n",
      "kmeans average accuracy best : 86.62%, kmeans average accuracy : 86.61724647%, total [0.9760956175298805, 0.9770017035775128, 0.9735404083980443, 0.9660333909038572, 0.9592375366568915, 0.9409090909090909, 0.8774552917033128, 0.7923993193420307, 0.9405852793378658, 0.8723897911832946, 0.7690092165898618, 0.6804335090802578, 0.9280618311533888, 0.8523974581166955, 0.7125, 0.6407099914113942]\n",
      "cluster_accuracy_post_training_cycle_all_dataset : [0.97918638 0.97785108 0.97255657 0.96865959 0.960199   0.93254717\n",
      " 0.88015912 0.55973659 0.9369642  0.85400391 0.77027027 0.683714\n",
      " 0.92362525 0.85741998 0.77647059 0.67558528]\n",
      "mean_cluster_accuracy_during_training_cycle : 85.20%, post_traincycle_acc : 85.68%, total_acc : 85.48084952%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 85.68%\n",
      "accuracy_check 실행 시간: 31.681초\n",
      "\n",
      "\n",
      "epoch-1 loss : 0.01280801, loss_normal : 0.01341924, loss_coarse : 0.06561602, min_loss : 0.01280801, min_loss_normal : 0.01341924, min_loss_coarse : 0.06561602, wrong_element_sum : 12598276.00000000, same_data : 0.00%\n",
      "ae train 실행 시간: 124.850초, 전체 시작 시간 20250312_165415_014\n",
      "\n",
      "epoch-1 accuracy check\n",
      "k_means origin feature average accuracy : 82.25126650%, total [0.9746727376209448, 0.9733106189664963, 0.9700891573195284, 0.9530800230282096, 0.943108504398827, 0.9150568181818182, 0.8015244796247435, 0.6625070901871809, 0.9488619568430388, 0.8216357308584686, 0.5866935483870968, 0.5002929115407148, 0.9429250891795482, 0.8922588099364529, 0.6741279069767442, 0.6000572573718866]\n",
      "save model\n",
      "kmeans average accuracy best : 88.12%, kmeans average accuracy : 88.12183439%, total [0.9763801935116676, 0.9772856331629756, 0.9738280126545873, 0.9643062751871042, 0.9633431085043989, 0.9448863636363637, 0.8991498094400469, 0.8150879183210437, 0.9571386343482117, 0.8921113689095128, 0.7851382488479263, 0.7106033977738723, 0.9325208085612366, 0.8804159445407279, 0.7651162790697674, 0.6621815058688806]\n",
      "cluster_accuracy_post_training_cycle_all_dataset : [0.97965941 0.97785108 0.9735195  0.96480231 0.96467662 0.93867925\n",
      " 0.89607161 0.76622766 0.95259708 0.90917969 0.77992278 0.67825223\n",
      " 0.93380855 0.86469447 0.79019608 0.67845198]\n",
      "mean_cluster_accuracy_during_training_cycle : 87.53%, post_traincycle_acc : 87.80%, total_acc : 87.69071428%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 87.80%\n",
      "accuracy_check 실행 시간: 28.303초\n",
      "\n",
      "\n",
      "epoch-2 loss : 0.01197265, loss_normal : 0.01309156, loss_coarse : 0.06363465, min_loss : 0.01197265, min_loss_normal : 0.01309156, min_loss_coarse : 0.06363465, wrong_element_sum : 12217854.00000000, same_data : 0.00%\n",
      "ae train 실행 시간: 127.214초, 전체 시작 시간 20250312_165415_014\n",
      "\n",
      "epoch-2 accuracy check\n",
      "k_means origin feature average accuracy : 82.26218852%, total [0.9746727376209448, 0.9733106189664963, 0.9700891573195284, 0.9530800230282096, 0.943108504398827, 0.9150568181818182, 0.801817648783348, 0.6625070901871809, 0.9488619568430388, 0.822215777262181, 0.5866935483870968, 0.5005858230814294, 0.9429250891795482, 0.8922588099364529, 0.6747093023255814, 0.6000572573718866]\n",
      "save model\n",
      "kmeans average accuracy best : 89.21%, kmeans average accuracy : 89.20871585%, total [0.9763801935116676, 0.9772856331629756, 0.9741156169111302, 0.9666090961427749, 0.9668621700879766, 0.9542613636363636, 0.909410729991205, 0.8312535450935905, 0.9538870824711795, 0.9051624129930395, 0.8217165898617511, 0.7551259519625073, 0.9390606420927468, 0.8974581166955518, 0.7680232558139535, 0.6767821356999714]\n",
      "cluster_accuracy_post_training_cycle_all_dataset : [0.97918638 0.97832234 0.97400096 0.96962392 0.96716418 0.94622642\n",
      " 0.9090005  0.60677328 0.93746848 0.9140625  0.80501931 0.72492552\n",
      " 0.93635438 0.90397672 0.80833333 0.73674152]\n",
      "mean_cluster_accuracy_during_training_cycle : 87.48%, post_traincycle_acc : 88.11%, total_acc : 87.85358596%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 88.11%\n",
      "accuracy_check 실행 시간: 32.859초\n",
      "\n",
      "\n",
      "epoch-3 loss : 0.01150250, loss_normal : 0.01286020, loss_coarse : 0.06233456, min_loss : 0.01150250, min_loss_normal : 0.01286020, min_loss_coarse : 0.06233456, wrong_element_sum : 11968236.00000000, same_data : 0.00%\n",
      "ae train 실행 시간: 128.910초, 전체 시작 시간 20250312_165415_014\n",
      "\n",
      "epoch-3 accuracy check\n",
      "k_means origin feature average accuracy : 82.25682064%, total [0.9746727376209448, 0.9733106189664963, 0.9700891573195284, 0.9530800230282096, 0.943108504398827, 0.9150568181818182, 0.801817648783348, 0.6625070901871809, 0.9488619568430388, 0.822215777262181, 0.5866935483870968, 0.5005858230814294, 0.9429250891795482, 0.8922588099364529, 0.6747093023255814, 0.5991983967935872]\n",
      "kmeans average accuracy best : 89.21%, kmeans average accuracy : 88.85495000%, total [0.9763801935116676, 0.9775695627484384, 0.9744032211676733, 0.9674726540011515, 0.9648093841642229, 0.9599431818181818, 0.9123424215772501, 0.8389109472490074, 0.9213715637008573, 0.8831206496519721, 0.7845622119815668, 0.7337434094903339, 0.9307372175980975, 0.8913922588099364, 0.8040697674418604, 0.6959633552819926]\n",
      "cluster_accuracy_post_training_cycle_all_dataset : [0.97918638 0.97832234 0.97496389 0.96817743 0.96616915 0.95235849\n",
      " 0.91447041 0.71636877 0.90973273 0.89697266 0.76640927 0.64448858\n",
      " 0.92260692 0.8957323  0.81862745 0.66411849]\n",
      "mean_cluster_accuracy_during_training_cycle : 87.89%, post_traincycle_acc : 87.30%, total_acc : 87.53993601%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 88.11%\n",
      "accuracy_check 실행 시간: 32.573초\n",
      "\n",
      "\n",
      "epoch-4 loss : 0.01137883, loss_normal : 0.01276858, loss_coarse : 0.06178104, min_loss : 0.01137883, min_loss_normal : 0.01276858, min_loss_coarse : 0.06178104, wrong_element_sum : 11861960.00000000, same_data : 0.00%\n",
      "ae train 실행 시간: 129.074초, 전체 시작 시간 20250312_165415_014\n",
      "\n",
      "epoch-4 accuracy check\n",
      "k_means origin feature average accuracy : 82.24041923%, total [0.9746727376209448, 0.9733106189664963, 0.9700891573195284, 0.9530800230282096, 0.943108504398827, 0.9150568181818182, 0.8003518029903254, 0.6625070901871809, 0.9488619568430388, 0.822215777262181, 0.5866935483870968, 0.5005858230814294, 0.9429250891795482, 0.8922588099364529, 0.6738372093023256, 0.598912109934154]\n",
      "kmeans average accuracy best : 89.21%, kmeans average accuracy : 88.72410259%, total [0.9766647694934547, 0.9772856331629756, 0.9741156169111302, 0.9625791594703512, 0.9659824046920821, 0.9383522727272727, 0.8698328935795955, 0.7606352807714124, 0.9435412355897133, 0.9074825986078886, 0.8220046082949308, 0.7589338019917985, 0.9372770511296076, 0.89052570768342, 0.8052325581395349, 0.7054108216432866]\n",
      "cluster_accuracy_post_training_cycle_all_dataset : [0.97965941 0.97785108 0.97496389 0.96480231 0.96716418 0.93490566\n",
      " 0.8891099  0.72483537 0.92536561 0.90087891 0.81225869 0.74875869\n",
      " 0.93788187 0.88748788 0.82254902 0.7032967 ]\n",
      "mean_cluster_accuracy_during_training_cycle : 88.16%, post_traincycle_acc : 88.45%, total_acc : 88.32811785%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 88.11%\n",
      "accuracy_check 실행 시간: 34.005초\n",
      "\n",
      "\n",
      "epoch-5 loss : 0.01108024, loss_normal : 0.01267373, loss_coarse : 0.06107765, min_loss : 0.01108024, min_loss_normal : 0.01267373, min_loss_coarse : 0.06107765, wrong_element_sum : 11726910.00000000, same_data : 0.00%\n",
      "ae train 실행 시간: 125.011초, 전체 시작 시간 20250312_165415_014\n",
      "\n",
      "epoch-5 accuracy check\n",
      "k_means origin feature average accuracy : 82.26219644%, total [0.9746727376209448, 0.9733106189664963, 0.9700891573195284, 0.9530800230282096, 0.943108504398827, 0.915340909090909, 0.801817648783348, 0.6625070901871809, 0.9488619568430388, 0.822215777262181, 0.5872695852534562, 0.5005858230814294, 0.9429250891795482, 0.8922588099364529, 0.6747093023255814, 0.5991983967935872]\n",
      "save model\n",
      "kmeans average accuracy best : 89.67%, kmeans average accuracy : 89.67252235%, total [0.9763801935116676, 0.9775695627484384, 0.9744032211676733, 0.9691997697179044, 0.9642228739002933, 0.9471590909090909, 0.8965112870126063, 0.8218944980147476, 0.9657109074785694, 0.9251740139211136, 0.8493663594470046, 0.7779730521382543, 0.9476813317479191, 0.8983246678220682, 0.7909883720930233, 0.6650443744632122]\n",
      "cluster_accuracy_post_training_cycle_all_dataset : [0.97918638 0.97879359 0.97448243 0.96962392 0.96467662 0.93867925\n",
      " 0.8975634  0.59031044 0.9591528  0.93310547 0.81853282 0.78947368\n",
      " 0.95010183 0.89912706 0.81372549 0.69230769]\n",
      "mean_cluster_accuracy_during_training_cycle : 88.55%, post_traincycle_acc : 88.43%, total_acc : 88.47153516%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 88.43%\n",
      "accuracy_check 실행 시간: 31.382초\n",
      "\n",
      "\n",
      "epoch-6 loss : 0.01083050, loss_normal : 0.01257556, loss_coarse : 0.06047410, min_loss : 0.01083050, min_loss_normal : 0.01257556, min_loss_coarse : 0.06047410, wrong_element_sum : 11611028.00000000, same_data : 0.00%\n",
      "ae train 실행 시간: 128.438초, 전체 시작 시간 20250312_165415_014\n",
      "\n",
      "epoch-6 accuracy check\n",
      "k_means origin feature average accuracy : 82.60210985%, total [0.9746727376209448, 0.9733106189664963, 0.9700891573195284, 0.9530800230282096, 0.943108504398827, 0.9150568181818182, 0.801817648783348, 0.6622234826999432, 0.9488619568430388, 0.822215777262181, 0.5872695852534562, 0.5005858230814294, 0.9429250891795482, 0.8922588099364529, 0.6738372093023256, 0.6550243343830519]\n",
      "save model\n",
      "kmeans average accuracy best : 89.91%, kmeans average accuracy : 89.91243601%, total [0.9763801935116676, 0.9772856331629756, 0.9738280126545873, 0.9645941278065631, 0.9607038123167155, 0.9372159090909091, 0.890061565523307, 0.8289846851956891, 0.9618681643511676, 0.912122969837587, 0.8346774193548387, 0.7697715289982425, 0.9447086801426873, 0.9046793760831889, 0.8308139534883721, 0.7182937303177784]\n",
      "cluster_accuracy_post_training_cycle_all_dataset : [0.97918638 0.97785108 0.97400096 0.96914176 0.96119403 0.9254717\n",
      " 0.88314272 0.79444967 0.94856278 0.92089844 0.79198842 0.77308838\n",
      " 0.94399185 0.91125121 0.83186275 0.77257525]\n",
      "mean_cluster_accuracy_during_training_cycle : 88.79%, post_traincycle_acc : 89.74%, total_acc : 89.35108287%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 89.74%\n",
      "accuracy_check 실행 시간: 33.378초\n",
      "\n",
      "\n",
      "epoch-7 loss : 0.01068620, loss_normal : 0.01253657, loss_coarse : 0.06016424, min_loss : 0.01068620, min_loss_normal : 0.01253657, min_loss_coarse : 0.06016424, wrong_element_sum : 11551534.00000000, same_data : 0.00%\n",
      "ae train 실행 시간: 129.112초, 전체 시작 시간 20250312_165415_014\n",
      "\n",
      "epoch-7 accuracy check\n",
      "k_means origin feature average accuracy : 82.25679017%, total [0.9746727376209448, 0.9733106189664963, 0.9700891573195284, 0.9530800230282096, 0.943108504398827, 0.915340909090909, 0.801817648783348, 0.6622234826999432, 0.9488619568430388, 0.822215777262181, 0.5872695852534562, 0.5005858230814294, 0.9429250891795482, 0.8922588099364529, 0.6741279069767442, 0.5991983967935872]\n",
      "kmeans average accuracy best : 89.91%, kmeans average accuracy : 89.26570767%, total [0.9763801935116676, 0.9775695627484384, 0.9744032211676733, 0.9689119170984456, 0.9642228739002933, 0.944034090909091, 0.8988566402814424, 0.7663074305161657, 0.9500443393437777, 0.9040023201856149, 0.8341013824884793, 0.7656707674282367, 0.9369797859690844, 0.9043905257076834, 0.8229651162790698, 0.6936730604065273]\n",
      "cluster_accuracy_post_training_cycle_all_dataset : [0.97918638 0.97832234 0.97400096 0.96914176 0.96218905 0.94433962\n",
      " 0.89656887 0.55879586 0.93847705 0.91796875 0.80984556 0.78351539\n",
      " 0.93635438 0.91076625 0.83578431 0.6722408 ]\n",
      "mean_cluster_accuracy_during_training_cycle : 88.96%, post_traincycle_acc : 87.92%, total_acc : 88.33304123%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 89.74%\n",
      "accuracy_check 실행 시간: 33.331초\n",
      "\n",
      "\n",
      "epoch-8 loss : 0.01068263, loss_normal : 0.01252046, loss_coarse : 0.06005739, min_loss : 0.01068263, min_loss_normal : 0.01252046, min_loss_coarse : 0.06005739, wrong_element_sum : 11531020.00000000, same_data : 0.00%\n",
      "ae train 실행 시간: 129.716초, 전체 시작 시간 20250312_165415_014\n",
      "\n",
      "epoch-8 accuracy check\n",
      "k_means origin feature average accuracy : 82.25492108%, total [0.9746727376209448, 0.9733106189664963, 0.9700891573195284, 0.9530800230282096, 0.943108504398827, 0.9150568181818182, 0.801817648783348, 0.6625070901871809, 0.9488619568430388, 0.822215777262181, 0.5866935483870968, 0.5005858230814294, 0.9429250891795482, 0.8922588099364529, 0.673546511627907, 0.6000572573718866]\n",
      "kmeans average accuracy best : 89.91%, kmeans average accuracy : 88.92708731%, total [0.9763801935116676, 0.9775695627484384, 0.9744032211676733, 0.968048359240069, 0.963049853372434, 0.9392045454545455, 0.8545880973321607, 0.7640385706182643, 0.9323086018326929, 0.8979118329466357, 0.8315092165898618, 0.7653778558875219, 0.9453032104637337, 0.8983246678220682, 0.8174418604651162, 0.7228743200687089]\n",
      "cluster_accuracy_post_training_cycle_all_dataset : [0.97918638 0.97832234 0.97496389 0.96817743 0.96268657 0.94575472\n",
      " 0.87468921 0.70084666 0.94402421 0.91064453 0.81322394 0.7795432\n",
      " 0.94501018 0.91173618 0.83676471 0.73960822]\n",
      "mean_cluster_accuracy_during_training_cycle : 88.75%, post_traincycle_acc : 89.16%, total_acc : 88.99118971%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 89.74%\n",
      "accuracy_check 실행 시간: 33.213초\n",
      "\n",
      "\n",
      "epoch-9 loss : 0.01053386, loss_normal : 0.01247676, loss_coarse : 0.05973418, min_loss : 0.01053386, min_loss_normal : 0.01247676, min_loss_coarse : 0.05973418, wrong_element_sum : 11468962.00000000, same_data : 0.00%\n",
      "ae train 실행 시간: 114.366초, 전체 시작 시간 20250312_165415_014\n",
      "\n",
      "epoch-9 accuracy check\n",
      "k_means origin feature average accuracy : 82.24957484%, total [0.9746727376209448, 0.9733106189664963, 0.9700891573195284, 0.9530800230282096, 0.943108504398827, 0.9150568181818182, 0.801817648783348, 0.6625070901871809, 0.9488619568430388, 0.822215777262181, 0.5872695852534562, 0.5005858230814294, 0.9429250891795482, 0.8922588099364529, 0.673546511627907, 0.5986258230747209]\n",
      "kmeans average accuracy best : 89.91%, kmeans average accuracy : 88.32213762%, total [0.9763801935116676, 0.9775695627484384, 0.9735404083980443, 0.9654576856649395, 0.9633431085043989, 0.9377840909090909, 0.8569334506009968, 0.767725467952354, 0.943836831214898, 0.880800464037123, 0.8153801843317973, 0.7644991212653779, 0.9408442330558858, 0.8997689196995956, 0.8037790697674418, 0.6638992270254795]\n",
      "cluster_accuracy_post_training_cycle_all_dataset : [0.97918638 0.97832234 0.9735195  0.96817743 0.96368159 0.93773585\n",
      " 0.86971656 0.69190969 0.92586989 0.89306641 0.78426641 0.77209533\n",
      " 0.94297352 0.89330747 0.82941176 0.63927377]\n",
      "mean_cluster_accuracy_during_training_cycle : 88.02%, post_traincycle_acc : 87.77%, total_acc : 87.86410397%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 89.74%\n",
      "accuracy_check 실행 시간: 32.517초\n",
      "\n",
      "\n",
      "epoch-10 loss : 0.01052149, loss_normal : 0.01246843, loss_coarse : 0.05967583, min_loss : 0.01052149, min_loss_normal : 0.01246843, min_loss_coarse : 0.05967583, wrong_element_sum : 11457760.00000000, same_data : 0.00%\n",
      "ae train 실행 시간: 128.322초, 전체 시작 시간 20250312_165415_014\n",
      "\n",
      "epoch-10 accuracy check\n",
      "k_means origin feature average accuracy : 82.26035621%, total [0.9746727376209448, 0.9733106189664963, 0.9700891573195284, 0.9530800230282096, 0.943108504398827, 0.9150568181818182, 0.8015244796247435, 0.6625070901871809, 0.9488619568430388, 0.822215777262181, 0.5866935483870968, 0.5005858230814294, 0.9429250891795482, 0.8922588099364529, 0.6747093023255814, 0.6000572573718866]\n",
      "kmeans average accuracy best : 89.91%, kmeans average accuracy : 88.70763836%, total [0.9766647694934547, 0.9775695627484384, 0.9738280126545873, 0.9686240644789867, 0.9627565982404692, 0.9386363636363636, 0.8581061272354148, 0.7753828701077708, 0.9571386343482117, 0.8990719257540604, 0.8320852534562212, 0.781195079086116, 0.9408442330558858, 0.8948584633160023, 0.8002906976744186, 0.6561694818207844]\n",
      "cluster_accuracy_post_training_cycle_all_dataset : [0.97965941 0.97832234 0.97400096 0.96962392 0.9641791  0.93962264\n",
      " 0.86872203 0.71636877 0.93545134 0.90380859 0.81032819 0.79344588\n",
      " 0.94399185 0.90349176 0.82205882 0.71141902]\n",
      "mean_cluster_accuracy_during_training_cycle : 88.62%, post_traincycle_acc : 88.84%, total_acc : 88.74725452%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 89.74%\n",
      "accuracy_check 실행 시간: 32.548초\n",
      "\n",
      "\n",
      "epoch-11 loss : 0.01037506, loss_normal : 0.01241885, loss_coarse : 0.05936138, min_loss : 0.01037506, min_loss_normal : 0.01241885, min_loss_coarse : 0.05936138, wrong_element_sum : 11397386.00000000, same_data : 0.00%\n",
      "ae train 실행 시간: 125.882초, 전체 시작 시간 20250312_165415_014\n",
      "\n",
      "epoch-11 accuracy check\n",
      "k_means origin feature average accuracy : 82.26212746%, total [0.9746727376209448, 0.9733106189664963, 0.9700891573195284, 0.9530800230282096, 0.943108504398827, 0.9150568181818182, 0.801817648783348, 0.6625070901871809, 0.9488619568430388, 0.822215777262181, 0.5872695852534562, 0.5005858230814294, 0.9429250891795482, 0.8922588099364529, 0.6738372093023256, 0.6003435442313197]\n",
      "kmeans average accuracy best : 89.91%, kmeans average accuracy : 89.61273051%, total [0.9763801935116676, 0.9778534923339012, 0.9738280126545873, 0.9683362118595279, 0.9659824046920821, 0.9474431818181818, 0.8759894459102903, 0.7745320476460579, 0.9547738693467337, 0.9109628770301624, 0.8317972350230415, 0.7615700058582309, 0.9441141498216409, 0.9110340843443097, 0.8319767441860465, 0.7314629258517034]\n",
      "cluster_accuracy_post_training_cycle_all_dataset : [0.97918638 0.97832234 0.97448243 0.96914176 0.96368159 0.93537736\n",
      " 0.88264545 0.74506115 0.94200706 0.91650391 0.79488417 0.78301887\n",
      " 0.94144603 0.91949564 0.85490196 0.76015289]\n",
      "mean_cluster_accuracy_during_training_cycle : 89.01%, post_traincycle_acc : 89.63%, total_acc : 89.37610420%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 89.74%\n",
      "accuracy_check 실행 시간: 32.407초\n",
      "\n",
      "\n",
      "epoch-12 loss : 0.01033038, loss_normal : 0.01240117, loss_coarse : 0.05918272, min_loss : 0.01033038, min_loss_normal : 0.01240117, min_loss_coarse : 0.05918272, wrong_element_sum : 11363082.00000000, same_data : 0.00%\n",
      "ae train 실행 시간: 128.583초, 전체 시작 시간 20250312_165415_014\n",
      "\n",
      "epoch-12 accuracy check\n",
      "k_means origin feature average accuracy : 82.24244034%, total [0.9746727376209448, 0.9733106189664963, 0.9700891573195284, 0.9530800230282096, 0.943108504398827, 0.9150568181818182, 0.801817648783348, 0.6622234826999432, 0.9488619568430388, 0.822215777262181, 0.5866935483870968, 0.5005858230814294, 0.9429250891795482, 0.8922588099364529, 0.6738372093023256, 0.5980532493558546]\n",
      "kmeans average accuracy best : 89.91%, kmeans average accuracy : 89.22201121%, total [0.9760956175298805, 0.9775695627484384, 0.9732528041415013, 0.9657455382843984, 0.963049853372434, 0.9508522727272727, 0.9047200234535326, 0.7972206466250709, 0.9553650605971031, 0.8947215777262181, 0.8127880184331797, 0.7636203866432337, 0.9435196195005945, 0.9032351242056614, 0.8061046511627907, 0.6876610363584311]\n",
      "cluster_accuracy_post_training_cycle_all_dataset : [0.97871334 0.97785108 0.9735195  0.96817743 0.96268657 0.94575472\n",
      " 0.90402785 0.65804327 0.92637418 0.91259766 0.78861004 0.77259186\n",
      " 0.94501018 0.89185257 0.81519608 0.68848543]\n",
      "mean_cluster_accuracy_during_training_cycle : 89.09%, post_traincycle_acc : 88.18%, total_acc : 88.54144102%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 89.74%\n",
      "accuracy_check 실행 시간: 32.377초\n",
      "\n",
      "\n",
      "epoch-13 loss : 0.01039924, loss_normal : 0.01243449, loss_coarse : 0.05946049, min_loss : 0.01033038, min_loss_normal : 0.01240117, min_loss_coarse : 0.05918272, wrong_element_sum : 11416414.00000000, same_data : 0.00%\n",
      "ae train 실행 시간: 120.283초, 전체 시작 시간 20250312_165415_014\n",
      "\n",
      "epoch-13 accuracy check\n",
      "k_means origin feature average accuracy : 82.25320327%, total [0.9746727376209448, 0.9733106189664963, 0.9700891573195284, 0.9530800230282096, 0.943108504398827, 0.915340909090909, 0.801817648783348, 0.6625070901871809, 0.9488619568430388, 0.8216357308584686, 0.5872695852534562, 0.5005858230814294, 0.9429250891795482, 0.8922588099364529, 0.6747093023255814, 0.5983395362152877]\n",
      "kmeans average accuracy best : 89.91%, kmeans average accuracy : 89.77033079%, total [0.9760956175298805, 0.9775695627484384, 0.9738280126545873, 0.9689119170984456, 0.963049853372434, 0.9480113636363636, 0.9079448841981823, 0.8043108338060124, 0.9550694649719185, 0.8993619489559165, 0.8338133640552995, 0.7738722905682484, 0.9497621878715814, 0.9231658001155402, 0.8328488372093024, 0.6756369882622387]\n",
      "cluster_accuracy_post_training_cycle_all_dataset : [0.97871334 0.97832234 0.97400096 0.96962392 0.96318408 0.94433962\n",
      " 0.90999503 0.81185325 0.93393848 0.90478516 0.81177606 0.78003972\n",
      " 0.94959267 0.91125121 0.85147059 0.70664118]\n",
      "mean_cluster_accuracy_during_training_cycle : 88.83%, post_traincycle_acc : 89.87%, total_acc : 89.44487231%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 89.74%\n",
      "accuracy_check 실행 시간: 28.115초\n",
      "\n",
      "\n",
      "epoch-14 loss : 0.01029592, loss_normal : 0.01238048, loss_coarse : 0.05909846, min_loss : 0.01029592, min_loss_normal : 0.01238048, min_loss_coarse : 0.05909846, wrong_element_sum : 11346904.00000000, same_data : 0.00%\n",
      "ae train 실행 시간: 127.918초, 전체 시작 시간 20250312_165415_014\n",
      "\n",
      "epoch-14 accuracy check\n",
      "k_means origin feature average accuracy : 82.24962998%, total [0.9746727376209448, 0.9733106189664963, 0.9700891573195284, 0.9530800230282096, 0.943108504398827, 0.9150568181818182, 0.801817648783348, 0.6625070901871809, 0.9488619568430388, 0.822215777262181, 0.5872695852534562, 0.5005858230814294, 0.9429250891795482, 0.8922588099364529, 0.6741279069767442, 0.5980532493558546]\n",
      "kmeans average accuracy best : 89.91%, kmeans average accuracy : 89.29634593%, total [0.9763801935116676, 0.9775695627484384, 0.9738280126545873, 0.9683362118595279, 0.9633431085043989, 0.9508522727272727, 0.8968044561712107, 0.7983550765740216, 0.9562518474726575, 0.892691415313225, 0.8194124423963134, 0.7671353251318102, 0.9458977407847801, 0.9104563835932987, 0.8098837209302325, 0.6802175780131692]\n",
      "cluster_accuracy_post_training_cycle_all_dataset : [0.97918638 0.97832234 0.97400096 0.96914176 0.96069652 0.9504717\n",
      " 0.88662357 0.68062088 0.95057993 0.91650391 0.78957529 0.78500497\n",
      " 0.94806517 0.91319108 0.84313725 0.69469661]\n",
      "mean_cluster_accuracy_during_training_cycle : 89.06%, post_traincycle_acc : 88.87%, total_acc : 88.94208985%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 89.74%\n",
      "accuracy_check 실행 시간: 33.275초\n",
      "\n",
      "\n",
      "epoch-15 loss : 0.01029623, loss_normal : 0.01239340, loss_coarse : 0.05919173, min_loss : 0.01029592, min_loss_normal : 0.01238048, min_loss_coarse : 0.05909846, wrong_element_sum : 11364812.00000000, same_data : 0.00%\n",
      "ae train 실행 시간: 130.136초, 전체 시작 시간 20250312_165415_014\n",
      "\n",
      "epoch-15 accuracy check\n",
      "k_means origin feature average accuracy : 82.26580549%, total [0.9746727376209448, 0.9733106189664963, 0.9700891573195284, 0.9530800230282096, 0.943108504398827, 0.9150568181818182, 0.801817648783348, 0.6622234826999432, 0.9488619568430388, 0.822215777262181, 0.5872695852534562, 0.5005858230814294, 0.9429250891795482, 0.8922588099364529, 0.6747093023255814, 0.6003435442313197]\n",
      "kmeans average accuracy best : 89.91%, kmeans average accuracy : 89.41687003%, total [0.9763801935116676, 0.9775695627484384, 0.9735404083980443, 0.9666090961427749, 0.9612903225806452, 0.9414772727272728, 0.873057754324245, 0.7728304027226319, 0.9364469405852793, 0.9028422273781903, 0.8338133640552995, 0.7770943175161101, 0.9512485136741974, 0.9150779896013865, 0.8328488372093024, 0.7145720011451474]\n",
      "cluster_accuracy_post_training_cycle_all_dataset : [0.97918638 0.97832234 0.97400096 0.96865959 0.96119403 0.94103774\n",
      " 0.87817006 0.66039511 0.92990419 0.90380859 0.80067568 0.78252234\n",
      " 0.95213849 0.9214355  0.84558824 0.7118968 ]\n",
      "mean_cluster_accuracy_during_training_cycle : 88.71%, post_traincycle_acc : 88.68%, total_acc : 88.68891035%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 89.74%\n",
      "accuracy_check 실행 시간: 33.592초\n",
      "\n",
      "\n",
      "epoch-16 loss : 0.01030531, loss_normal : 0.01240411, loss_coarse : 0.05920932, min_loss : 0.01029592, min_loss_normal : 0.01238048, min_loss_coarse : 0.05909846, wrong_element_sum : 11368190.00000000, same_data : 0.00%\n",
      "ae train 실행 시간: 130.025초, 전체 시작 시간 20250312_165415_014\n",
      "\n",
      "epoch-16 accuracy check\n",
      "k_means origin feature average accuracy : 82.25314853%, total [0.9746727376209448, 0.9733106189664963, 0.9700891573195284, 0.9530800230282096, 0.943108504398827, 0.9150568181818182, 0.801817648783348, 0.6622234826999432, 0.9488619568430388, 0.822215777262181, 0.5866935483870968, 0.5005858230814294, 0.9429250891795482, 0.8922588099364529, 0.673546511627907, 0.6000572573718866]\n",
      "kmeans average accuracy best : 89.91%, kmeans average accuracy : 89.10766367%, total [0.9760956175298805, 0.9775695627484384, 0.9738280126545873, 0.9666090961427749, 0.9633431085043989, 0.9431818181818182, 0.900322486074465, 0.8043108338060124, 0.9515223174697014, 0.9167633410672854, 0.8355414746543779, 0.7864674868189807, 0.9253864447086801, 0.8743500866551126, 0.7837209302325582, 0.6782135699971371]\n",
      "cluster_accuracy_post_training_cycle_all_dataset : [0.97871334 0.97785108 0.97400096 0.96865959 0.9641791  0.93773585\n",
      " 0.89457981 0.79350894 0.9293999  0.92089844 0.79971042 0.78699106\n",
      " 0.92617108 0.88797284 0.80833333 0.649785  ]\n",
      "mean_cluster_accuracy_during_training_cycle : 88.88%, post_traincycle_acc : 88.74%, total_acc : 88.79421836%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 89.74%\n",
      "accuracy_check 실행 시간: 32.047초\n",
      "\n",
      "\n",
      "epoch-17 loss : 0.01017430, loss_normal : 0.01235447, loss_coarse : 0.05886357, min_loss : 0.01017430, min_loss_normal : 0.01235447, min_loss_coarse : 0.05886357, wrong_element_sum : 11301806.00000000, same_data : 0.00%\n",
      "ae train 실행 시간: 123.893초, 전체 시작 시간 20250312_165415_014\n",
      "\n",
      "epoch-17 accuracy check\n",
      "k_means origin feature average accuracy : 82.24778065%, total [0.9746727376209448, 0.9733106189664963, 0.9700891573195284, 0.9530800230282096, 0.943108504398827, 0.9150568181818182, 0.801817648783348, 0.6622234826999432, 0.9488619568430388, 0.822215777262181, 0.5866935483870968, 0.5005858230814294, 0.9429250891795482, 0.8922588099364529, 0.673546511627907, 0.5991983967935872]\n",
      "kmeans average accuracy best : 89.91%, kmeans average accuracy : 89.08626378%, total [0.9763801935116676, 0.9775695627484384, 0.9741156169111302, 0.9677605066206102, 0.9560117302052786, 0.9420454545454545, 0.8959249486953973, 0.784458309699376, 0.9423588530889743, 0.880800464037123, 0.8341013824884793, 0.7615700058582309, 0.9497621878715814, 0.9119006354708261, 0.8142441860465116, 0.6847981677640996]\n",
      "cluster_accuracy_post_training_cycle_all_dataset : [0.97918638 0.97832234 0.97400096 0.96865959 0.95721393 0.94056604\n",
      " 0.88165092 0.78222013 0.94503278 0.90478516 0.81515444 0.79344588\n",
      " 0.95010183 0.91367604 0.82352941 0.71046345]\n",
      "mean_cluster_accuracy_during_training_cycle : 89.20%, post_traincycle_acc : 89.49%, total_acc : 89.37105191%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 89.74%\n",
      "accuracy_check 실행 시간: 25.922초\n",
      "\n",
      "\n",
      "epoch-18 loss : 0.01007535, loss_normal : 0.01233052, loss_coarse : 0.05873071, min_loss : 0.01007535, min_loss_normal : 0.01233052, min_loss_coarse : 0.05873071, wrong_element_sum : 11276296.00000000, same_data : 0.00%\n",
      "ae train 실행 시간: 128.161초, 전체 시작 시간 20250312_165415_014\n",
      "\n",
      "epoch-18 accuracy check\n",
      "k_means origin feature average accuracy : 82.24595324%, total [0.9746727376209448, 0.9733106189664963, 0.9700891573195284, 0.9530800230282096, 0.943108504398827, 0.9150568181818182, 0.8015244796247435, 0.6625070901871809, 0.9488619568430388, 0.822215777262181, 0.5872695852534562, 0.5005858230814294, 0.9429250891795482, 0.8922588099364529, 0.673546511627907, 0.5983395362152877]\n",
      "kmeans average accuracy best : 89.91%, kmeans average accuracy : 89.53544064%, total [0.9766647694934547, 0.9775695627484384, 0.9744032211676733, 0.9683362118595279, 0.9621700879765396, 0.946875, 0.8853708589856347, 0.7833238797504254, 0.9600945906000591, 0.9164733178654292, 0.8338133640552995, 0.7776801405975395, 0.9527348394768134, 0.9095898324667822, 0.8206395348837209, 0.6799312911537361]\n",
      "cluster_accuracy_post_training_cycle_all_dataset : [0.97965941 0.97832234 0.97496389 0.96962392 0.96517413 0.94009434\n",
      " 0.89159622 0.66274694 0.95461422 0.90966797 0.80019305 0.77855015\n",
      " 0.95213849 0.91561591 0.84460784 0.72718586]\n",
      "mean_cluster_accuracy_during_training_cycle : 89.09%, post_traincycle_acc : 89.03%, total_acc : 89.04634129%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 89.74%\n",
      "accuracy_check 실행 시간: 32.363초\n",
      "\n",
      "\n",
      "epoch-19 loss : 0.01015136, loss_normal : 0.01235354, loss_coarse : 0.05886446, min_loss : 0.01007535, min_loss_normal : 0.01233052, min_loss_coarse : 0.05873071, wrong_element_sum : 11301976.00000000, same_data : 0.00%\n",
      "ae train 실행 시간: 127.852초, 전체 시작 시간 20250312_165415_014\n",
      "\n",
      "epoch-19 accuracy check\n",
      "k_means origin feature average accuracy : 82.26218389%, total [0.9746727376209448, 0.9733106189664963, 0.9700891573195284, 0.9530800230282096, 0.943108504398827, 0.9150568181818182, 0.8015244796247435, 0.6622234826999432, 0.9488619568430388, 0.822215777262181, 0.5872695852534562, 0.5005858230814294, 0.9429250891795482, 0.8922588099364529, 0.6747093023255814, 0.6000572573718866]\n",
      "kmeans average accuracy best : 89.91%, kmeans average accuracy : 89.21581404%, total [0.9763801935116676, 0.9772856331629756, 0.9741156169111302, 0.9694876223373633, 0.9583577712609971, 0.944034090909091, 0.8956317795367927, 0.7813386273397618, 0.9476795743422998, 0.9144431554524362, 0.8464861751152074, 0.7961335676625659, 0.9453032104637337, 0.8994800693240901, 0.7767441860465116, 0.6716289722301746]\n",
      "cluster_accuracy_post_training_cycle_all_dataset : [0.97965941 0.97737983 0.97448243 0.96865959 0.95970149 0.93867925\n",
      " 0.89557434 0.70555033 0.9369642  0.91943359 0.81177606 0.80933466\n",
      " 0.94551935 0.89185257 0.80098039 0.66985189]\n",
      "mean_cluster_accuracy_during_training_cycle : 88.86%, post_traincycle_acc : 88.66%, total_acc : 88.73525768%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 89.74%\n",
      "accuracy_check 실행 시간: 32.799초\n",
      "\n",
      "\n",
      "epoch-20 loss : 0.01015621, loss_normal : 0.01235449, loss_coarse : 0.05888012, min_loss : 0.01007535, min_loss_normal : 0.01233052, min_loss_coarse : 0.05873071, wrong_element_sum : 11304984.00000000, same_data : 0.00%\n",
      "ae train 실행 시간: 128.028초, 전체 시작 시간 20250312_165415_014\n",
      "\n",
      "epoch-20 accuracy check\n",
      "k_means origin feature average accuracy : 82.25673794%, total [0.9746727376209448, 0.9733106189664963, 0.9700891573195284, 0.9530800230282096, 0.943108504398827, 0.9150568181818182, 0.801817648783348, 0.6625070901871809, 0.9488619568430388, 0.822215777262181, 0.5866935483870968, 0.5005858230814294, 0.9429250891795482, 0.8922588099364529, 0.6738372093023256, 0.6000572573718866]\n",
      "kmeans average accuracy best : 89.91%, kmeans average accuracy : 88.82007294%, total [0.9763801935116676, 0.9775695627484384, 0.9735404083980443, 0.9674726540011515, 0.9598240469208211, 0.930965909090909, 0.8563471122837878, 0.7702779353374929, 0.9328997930830624, 0.8816705336426914, 0.8217165898617511, 0.7814879906268307, 0.9536266349583828, 0.9217215482380127, 0.8197674418604651, 0.6859433152018323]\n",
      "cluster_accuracy_post_training_cycle_all_dataset : [0.97918638 0.97832234 0.9735195  0.96769527 0.96169154 0.92735849\n",
      " 0.87170562 0.74647225 0.91780131 0.87890625 0.80019305 0.78003972\n",
      " 0.95773931 0.91367604 0.83284314 0.70520784]\n",
      "mean_cluster_accuracy_during_training_cycle : 88.75%, post_traincycle_acc : 88.70%, total_acc : 88.71910397%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 89.74%\n",
      "accuracy_check 실행 시간: 32.854초\n",
      "\n",
      "\n",
      "epoch-21 loss : 0.01023587, loss_normal : 0.01237146, loss_coarse : 0.05911280, min_loss : 0.01007535, min_loss_normal : 0.01233052, min_loss_coarse : 0.05873071, wrong_element_sum : 11349658.00000000, same_data : 0.00%\n",
      "ae train 실행 시간: 127.678초, 전체 시작 시간 20250312_165415_014\n",
      "\n",
      "epoch-21 accuracy check\n",
      "k_means origin feature average accuracy : 82.25674876%, total [0.9746727376209448, 0.9733106189664963, 0.9700891573195284, 0.9530800230282096, 0.943108504398827, 0.9150568181818182, 0.801817648783348, 0.6622234826999432, 0.9488619568430388, 0.822215777262181, 0.5872695852534562, 0.5005858230814294, 0.9429250891795482, 0.8922588099364529, 0.673546511627907, 0.6000572573718866]\n",
      "kmeans average accuracy best : 89.91%, kmeans average accuracy : 88.94844091%, total [0.9763801935116676, 0.9775695627484384, 0.9744032211676733, 0.9671848013816926, 0.9633431085043989, 0.9397727272727273, 0.8795074758135444, 0.7858763471355644, 0.9337865799586166, 0.8970417633410673, 0.8286290322580645, 0.7797305213825425, 0.9473840665873959, 0.91421143847487, 0.811046511627907, 0.6558831949613513]\n",
      "cluster_accuracy_post_training_cycle_all_dataset : [0.97965941 0.97832234 0.97496389 0.96865959 0.96318408 0.94433962\n",
      " 0.88214818 0.76481656 0.92788704 0.89404297 0.78667954 0.79890765\n",
      " 0.94959267 0.91707081 0.8254902  0.72575251]\n",
      "mean_cluster_accuracy_during_training_cycle : 88.98%, post_traincycle_acc : 89.26%, total_acc : 89.14472131%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 89.74%\n",
      "accuracy_check 실행 시간: 28.072초\n",
      "\n",
      "\n",
      "epoch-22 loss : 0.01006206, loss_normal : 0.01230846, loss_coarse : 0.05861409, min_loss : 0.01006206, min_loss_normal : 0.01230846, min_loss_coarse : 0.05861409, wrong_element_sum : 11253906.00000000, same_data : 0.00%\n",
      "ae train 실행 시간: 126.407초, 전체 시작 시간 20250312_165415_014\n",
      "\n",
      "epoch-22 accuracy check\n",
      "k_means origin feature average accuracy : 82.23155171%, total [0.9746727376209448, 0.9733106189664963, 0.9700891573195284, 0.9530800230282096, 0.943108504398827, 0.915340909090909, 0.8015244796247435, 0.6622234826999432, 0.9488619568430388, 0.822215777262181, 0.5866935483870968, 0.5005858230814294, 0.9429250891795482, 0.89052570768342, 0.6738372093023256, 0.5980532493558546]\n",
      "kmeans average accuracy best : 89.91%, kmeans average accuracy : 89.15257641%, total [0.9766647694934547, 0.9775695627484384, 0.9735404083980443, 0.9657455382843984, 0.9577712609970674, 0.9275568181818182, 0.8510700674289065, 0.7691435053885423, 0.9615725687259828, 0.9176334106728539, 0.8326612903225806, 0.7926186291739895, 0.9503567181926278, 0.9055459272097054, 0.8081395348837209, 0.696822215860292]\n",
      "cluster_accuracy_post_training_cycle_all_dataset : [0.97965941 0.97832234 0.9735195  0.96721311 0.96119403 0.92122642\n",
      " 0.85280955 0.7158984  0.93746848 0.92675781 0.8257722  0.78301887\n",
      " 0.95112016 0.90785645 0.81372549 0.73005256]\n",
      "mean_cluster_accuracy_during_training_cycle : 88.74%, post_traincycle_acc : 88.91%, total_acc : 88.83940015%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 89.74%\n",
      "accuracy_check 실행 시간: 31.369초\n",
      "\n",
      "\n",
      "epoch-23 loss : 0.00999663, loss_normal : 0.01228648, loss_coarse : 0.05848060, min_loss : 0.00999663, min_loss_normal : 0.01228648, min_loss_coarse : 0.05848060, wrong_element_sum : 11228276.00000000, same_data : 0.00%\n",
      "ae train 실행 시간: 127.512초, 전체 시작 시간 20250312_165415_014\n",
      "\n",
      "epoch-23 accuracy check\n",
      "k_means origin feature average accuracy : 82.25852974%, total [0.9746727376209448, 0.9733106189664963, 0.9700891573195284, 0.9530800230282096, 0.943108504398827, 0.9150568181818182, 0.801817648783348, 0.6625070901871809, 0.9488619568430388, 0.8216357308584686, 0.5872695852534562, 0.5005858230814294, 0.9429250891795482, 0.8922588099364529, 0.6741279069767442, 0.6000572573718866]\n",
      "kmeans average accuracy best : 89.91%, kmeans average accuracy : 89.74831761%, total [0.9769493454752419, 0.9778534923339012, 0.9738280126545873, 0.9697754749568221, 0.9618768328445748, 0.9414772727272728, 0.8979771328056289, 0.8045944412932502, 0.9453148093408218, 0.8958816705336426, 0.8346774193548387, 0.789103690685413, 0.9456004756242569, 0.91421143847487, 0.8380813953488372, 0.6925279129687947]\n",
      "cluster_accuracy_post_training_cycle_all_dataset : [0.98013245 0.97879359 0.97448243 0.97058824 0.96169154 0.93301887\n",
      " 0.89607161 0.7883349  0.91729702 0.88232422 0.80743243 0.78252234\n",
      " 0.94755601 0.91464597 0.85196078 0.67128524]\n",
      "mean_cluster_accuracy_during_training_cycle : 89.32%, post_traincycle_acc : 89.11%, total_acc : 89.19623692%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 89.74%\n",
      "accuracy_check 실행 시간: 35.014초\n",
      "\n",
      "\n",
      "epoch-24 loss : 0.00998150, loss_normal : 0.01227500, loss_coarse : 0.05842981, min_loss : 0.00998150, min_loss_normal : 0.01227500, min_loss_coarse : 0.05842981, wrong_element_sum : 11218524.00000000, same_data : 0.00%\n",
      "ae train 실행 시간: 128.087초, 전체 시작 시간 20250312_165415_014\n",
      "\n",
      "epoch-24 accuracy check\n",
      "k_means origin feature average accuracy : 82.25679068%, total [0.9746727376209448, 0.9733106189664963, 0.9700891573195284, 0.9530800230282096, 0.943108504398827, 0.9150568181818182, 0.801817648783348, 0.6622234826999432, 0.9488619568430388, 0.8216357308584686, 0.5866935483870968, 0.5005858230814294, 0.9429250891795482, 0.8922588099364529, 0.6747093023255814, 0.6000572573718866]\n",
      "kmeans average accuracy best : 89.91%, kmeans average accuracy : 88.90283026%, total [0.9766647694934547, 0.9778534923339012, 0.9738280126545873, 0.9671848013816926, 0.9615835777126099, 0.9423295454545455, 0.8897683963647024, 0.7958026091888826, 0.9600945906000591, 0.9080626450116009, 0.824020737327189, 0.773286467486819, 0.9429250891795482, 0.8818601964182553, 0.7738372093023256, 0.6753507014028056]\n",
      "cluster_accuracy_post_training_cycle_all_dataset : [0.97965941 0.97879359 0.97496389 0.96962392 0.9641791  0.93726415\n",
      " 0.88861263 0.69190969 0.95108422 0.91357422 0.79681467 0.76464747\n",
      " 0.94602851 0.88506305 0.80392157 0.69039656]\n",
      "mean_cluster_accuracy_during_training_cycle : 88.47%, post_traincycle_acc : 88.35%, total_acc : 88.39576384%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 89.74%\n",
      "accuracy_check 실행 시간: 31.618초\n",
      "\n",
      "\n",
      "epoch-25 loss : 0.01019240, loss_normal : 0.01236945, loss_coarse : 0.05902509, min_loss : 0.00998150, min_loss_normal : 0.01227500, min_loss_coarse : 0.05842981, wrong_element_sum : 11332818.00000000, same_data : 0.00%\n",
      "ae train 실행 시간: 128.014초, 전체 시작 시간 20250312_165415_014\n",
      "\n",
      "epoch-25 accuracy check\n",
      "k_means origin feature average accuracy : 82.25129023%, total [0.9746727376209448, 0.9733106189664963, 0.9700891573195284, 0.9530800230282096, 0.943108504398827, 0.9150568181818182, 0.8009381413075345, 0.6625070901871809, 0.9488619568430388, 0.822215777262181, 0.5872695852534562, 0.5005858230814294, 0.9429250891795482, 0.8922588099364529, 0.6741279069767442, 0.5991983967935872]\n",
      "kmeans average accuracy best : 89.91%, kmeans average accuracy : 88.78056256%, total [0.9769493454752419, 0.978137421919364, 0.9752660339373023, 0.9668969487622338, 0.9607038123167155, 0.9357954545454545, 0.8651421870419231, 0.7379466817923993, 0.9459060005911912, 0.9164733178654292, 0.8398617511520737, 0.7823667252489748, 0.952140309155767, 0.9041016753321779, 0.7912790697674419, 0.6759232751216719]\n",
      "cluster_accuracy_post_training_cycle_all_dataset : [0.98013245 0.97926484 0.97496389 0.96817743 0.96069652 0.93160377\n",
      " 0.87021382 0.70790216 0.92032274 0.91894531 0.81322394 0.78103277\n",
      " 0.95213849 0.89379243 0.80441176 0.66555184]\n",
      "mean_cluster_accuracy_during_training_cycle : 87.45%, post_traincycle_acc : 88.26%, total_acc : 87.92979702%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 89.74%\n",
      "accuracy_check 실행 시간: 28.497초\n",
      "\n",
      "\n",
      "epoch-26 loss : 0.01007284, loss_normal : 0.01231684, loss_coarse : 0.05863992, min_loss : 0.00998150, min_loss_normal : 0.01227500, min_loss_coarse : 0.05842981, wrong_element_sum : 11258864.00000000, same_data : 0.00%\n",
      "ae train 실행 시간: 130.193초, 전체 시작 시간 20250312_165415_014\n",
      "\n",
      "epoch-26 accuracy check\n",
      "k_means origin feature average accuracy : 82.25855860%, total [0.9746727376209448, 0.9733106189664963, 0.9700891573195284, 0.9530800230282096, 0.943108504398827, 0.9150568181818182, 0.8015244796247435, 0.6622234826999432, 0.9488619568430388, 0.8216357308584686, 0.5872695852534562, 0.5005858230814294, 0.9429250891795482, 0.8922588099364529, 0.6747093023255814, 0.6000572573718866]\n",
      "kmeans average accuracy best : 89.91%, kmeans average accuracy : 89.09336577%, total [0.9766647694934547, 0.9778534923339012, 0.9744032211676733, 0.9657455382843984, 0.9621700879765396, 0.9335227272727272, 0.8765757842274993, 0.7872943845717527, 0.9346733668341709, 0.8912412993039444, 0.839573732718894, 0.799941417691857, 0.9402497027348394, 0.9078567302137492, 0.8055232558139535, 0.6816490123103349]\n",
      "cluster_accuracy_post_training_cycle_all_dataset : [0.98013245 0.97785108 0.97448243 0.96721311 0.96318408 0.92924528\n",
      " 0.87866733 0.710254   0.87392839 0.90917969 0.81032819 0.79940417\n",
      " 0.9404277  0.91173618 0.83382353 0.68514095]\n",
      "mean_cluster_accuracy_during_training_cycle : 88.57%, post_traincycle_acc : 88.41%, total_acc : 88.46703745%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 89.74%\n",
      "accuracy_check 실행 시간: 32.264초\n",
      "\n",
      "\n",
      "epoch-27 loss : 0.00999909, loss_normal : 0.01229652, loss_coarse : 0.05853690, min_loss : 0.00998150, min_loss_normal : 0.01227500, min_loss_coarse : 0.05842981, wrong_element_sum : 11239086.00000000, same_data : 0.00%\n",
      "ae train 실행 시간: 129.010초, 전체 시작 시간 20250312_165415_014\n",
      "\n",
      "epoch-27 accuracy check\n",
      "k_means origin feature average accuracy : 82.24602975%, total [0.9746727376209448, 0.9733106189664963, 0.9700891573195284, 0.9530800230282096, 0.943108504398827, 0.9150568181818182, 0.801817648783348, 0.6625070901871809, 0.9488619568430388, 0.822215777262181, 0.5866935483870968, 0.5005858230814294, 0.9429250891795482, 0.8922588099364529, 0.6741279069767442, 0.5980532493558546]\n",
      "kmeans average accuracy best : 89.91%, kmeans average accuracy : 89.18115960%, total [0.9775184974388161, 0.9787052810902896, 0.9749784296807593, 0.9637305699481865, 0.9595307917888563, 0.9366477272727273, 0.8841981823512166, 0.7762336925694838, 0.9577298255985811, 0.923723897911833, 0.8421658986175116, 0.79701230228471, 0.9387633769322236, 0.8902368573079145, 0.7936046511627907, 0.674205553965073]\n",
      "cluster_accuracy_post_training_cycle_all_dataset : [0.98107852 0.97879359 0.97496389 0.96624879 0.96119403 0.93537736\n",
      " 0.88960716 0.6349953  0.89611699 0.93310547 0.7972973  0.8123138\n",
      " 0.94297352 0.89524733 0.81372549 0.66507406]\n",
      "mean_cluster_accuracy_during_training_cycle : 88.74%, post_traincycle_acc : 87.99%, total_acc : 88.28494969%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 89.74%\n",
      "accuracy_check 실행 시간: 35.122초\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "gpu = '0'\n",
    "Conv_net = True # True False\n",
    "SAE_net = True # True False\n",
    "\n",
    "# hyperparameter\n",
    "dataset_num = 16\n",
    "spike_length = 50 # coarse_com_mode일 때는 time step이 됨.\n",
    "num_cluster = 4  # 클러스터 수 설정 # 논문엔 4개라는데 여기서는 3개로 했네\n",
    "training_cycle = 1400 #1400 2400 # 그 초기 몇개까지만 cluster update할지\n",
    "\n",
    "\n",
    "batch_size = 32\n",
    "max_epoch = 10000\n",
    "learning_rate = 0.001\n",
    "normalize_on = True # True or False # 0부터1까지 normalize\n",
    "need_bias = False\n",
    "# first_layer_no_train = False\n",
    "lif_add_at_first = False\n",
    "my_seed = 42\n",
    "\n",
    "TIME = 50 # SAE일 때만 유효. coarse_com_mode일 때는 level_num이 됨. 즉 feature 개수.\n",
    "v_decay = 0.5 # -cor\n",
    "v_threshold = 0.25 # -cor\n",
    "v_reset = 0.0 # -cor # 10000이상 일 시 hard reset\n",
    "BPTT_on = True # +cor # True False\n",
    "\n",
    "SAE_hidden_nomean = True # True False\n",
    "\n",
    "current_time = datetime.datetime.now().strftime(\"%Y%m%d_%H%M%S\") + f\"_{str(int(datetime.datetime.now().microsecond / 1000)).zfill(3)}\"\n",
    "\n",
    "optimizer = 'Adam' #'Adam', 'SGD' # 둘다 준수함. loss 줄이는 거는 adam이 좋긴한데, cluster accuracy는 비슷함.\n",
    "\n",
    "coarse_com_mode = True # True False\n",
    "coarse_com_config = (0.999, -0.0) # (max, min) (0.999, -0.0) (1.0, -0.0) (2.0, -2.0) (3.0, -3.0)\n",
    "\n",
    "sae_l2_norm_bridge = True # True False\n",
    "sae_lif_bridge = False # True False\n",
    "\n",
    "accuracy_check_epoch_term = 1\n",
    "\n",
    "lif_add_at_last = False # True False\n",
    "\n",
    "two_channel_input = False # True False\n",
    "\n",
    "lateral_feature_num = 6\n",
    "\n",
    "lc_adc_on = False # True False\n",
    "\n",
    "converted_net_forward = False # True False\n",
    "\n",
    "pretrained_net = None\n",
    "# pretrained_net = '/home/bhkim003/github_folder/ByeonghyeonKim/my_snn/net_save/save_now_net_중요_20250110_203117_390.pth'\n",
    "# pretrained_net = '/home/bhkim003/github_folder/ByeonghyeonKim/my_snn/net_save/save_now_net_중요_20250113_134126_881_이거_94나오는거.pth'\n",
    "# pretrained_net =  '/home/bhkim003/github_folder/ByeonghyeonKim/my_snn/net_save/save_now_net_20250205_184901_132.pth'\n",
    "# pretrained_net =  '/home/bhkim003/github_folder/ByeonghyeonKim/my_snn/net_save/save_now_net_20250306_134219_133.pth'\n",
    "\n",
    "vth_mul_on = False # True False\n",
    "batch_norm_on = False # True False\n",
    "\n",
    "l2_norm_loss_weight = 0 #0.0001 #0.1 #  0 # 0초과면 작동\n",
    "\n",
    "QCFS_neuron_on = False # True False\n",
    "\n",
    "quantize_level_num = 0 # 0이면 quantize 안함. 1이상이면 그 수만큼 quantize함. # normalize_on 켜져야됨. 음수면 0~1norm안하고 quant함\n",
    "\n",
    "fusion_net = True # True False # SAE_net False, Conv_net True로 해라. TIME 적절하게 설정해주고.\n",
    "repeat_coding = False # True False #fusion_net에서 쓰이는 거임 # True면 repeat, False면 rate coding.\n",
    "\n",
    "sae_relu_on = False # True False\n",
    "\n",
    "conv1d_scaling = False # True False # conv1d때매 norm하고 (level_num-3)/level_num 곱해줌 # Conv_net and coarse_com_mode and normalize_on\n",
    "\n",
    "norm01 = True # True False # normalize_on = True일 때 01norm하는지 아님 걍 quant만 하는지.\n",
    "\n",
    "wandb.init(project= f'spike_sorting just run',save_code=False)\n",
    "\n",
    "\n",
    "cluster_train_system( \n",
    "    gpu = gpu,\n",
    "    Conv_net = Conv_net,\n",
    "    SAE_net = SAE_net,\n",
    "\n",
    "    # hyperparameter\n",
    "    dataset_num = dataset_num,\n",
    "    spike_length = spike_length,\n",
    "    num_cluster = num_cluster,  # 클러스터 수 설정 # 논문엔 4개라는데 여기서는 3개로 했네\n",
    "    training_cycle = training_cycle, # 그 초기 몇개까지만 cluster update할지\n",
    "\n",
    "\n",
    "    batch_size = batch_size,\n",
    "    max_epoch = max_epoch,\n",
    "    learning_rate = learning_rate,\n",
    "    normalize_on = normalize_on, # True or False #이거 안 씀 # 이거 별로 안 좋은 normalize같음 # 쓸 거면 다른 거 써라.\n",
    "    need_bias = need_bias,\n",
    "    # first_layer_no_train = False\n",
    "    lif_add_at_first = lif_add_at_first,\n",
    "    my_seed = my_seed,\n",
    "\n",
    "    TIME = TIME, # SAE일 때만 유효\n",
    "    v_decay = v_decay,\n",
    "    v_threshold = v_threshold,\n",
    "    v_reset = v_reset, # 10000이상 일 시 hard reset\n",
    "    BPTT_on = BPTT_on,\n",
    "\n",
    "    SAE_hidden_nomean = SAE_hidden_nomean,\n",
    "    \n",
    "    current_time = current_time,\n",
    "\n",
    "    optimizer = optimizer, #'Adam', 'SGD'\n",
    "\n",
    "    coarse_com_mode = coarse_com_mode,\n",
    "    coarse_com_config = coarse_com_config, # (max, min)\n",
    "\n",
    "    \n",
    "    sae_l2_norm_bridge = sae_l2_norm_bridge,\n",
    "    sae_lif_bridge = sae_lif_bridge,\n",
    "\n",
    "    accuracy_check_epoch_term = accuracy_check_epoch_term,\n",
    "    \n",
    "    lif_add_at_last = lif_add_at_last,\n",
    "\n",
    "    two_channel_input = two_channel_input,\n",
    "\n",
    "    lateral_feature_num = lateral_feature_num,\n",
    "\n",
    "    lc_adc_on = lc_adc_on, \n",
    "\n",
    "    converted_net_forward = converted_net_forward,\n",
    "\n",
    "    pretrained_net = pretrained_net,\n",
    "\n",
    "    vth_mul_on = vth_mul_on,\n",
    "    batch_norm_on = batch_norm_on,\n",
    "\n",
    "    l2_norm_loss_weight = l2_norm_loss_weight,\n",
    "    \n",
    "    QCFS_neuron_on = QCFS_neuron_on, # True False\n",
    "\n",
    "    quantize_level_num = quantize_level_num,\n",
    "\n",
    "    fusion_net = fusion_net, # True False\n",
    "    repeat_coding = repeat_coding,\n",
    "\n",
    "    sae_relu_on = sae_relu_on,\n",
    "\n",
    "    conv1d_scaling = conv1d_scaling,\n",
    "\n",
    "    norm01 = norm01,\n",
    "\n",
    "    )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Sweep code\n",
    "\n",
    "\n",
    "# from unittest import TextTestRunner\n",
    "\n",
    "\n",
    "# unique_name_hyper = 'cluster_train_system'\n",
    "# # run_name = 'spike_sorting'\n",
    "# sweep_start_time =  datetime.datetime.now().strftime(\"%Y%m%d_%H%M%S\") + f\"_{str(int(datetime.datetime.now().microsecond / 1000)).zfill(3)}\"\n",
    "# sweep_configuration = {\n",
    "#     'method': 'bayes', # 'random', 'bayes'\n",
    "#     'name': f'spike_sorting_{sweep_start_time}',\n",
    "#     'metric': {'goal': 'maximize', 'name': 'k_means_acc_best'},\n",
    "#     'parameters': \n",
    "#     {\n",
    "#         # \"gpu\": {\"values\": ['1']},  # 이건 sweep parameter아님. hyper_iter에서 직접 설정\n",
    "#         \"Conv_net\": {\"values\": [True]}, \n",
    "#         \"SAE_net\": {\"values\": [True]}, \n",
    "\n",
    "#         \"dataset_num\": {\"values\": [16]}, \n",
    "#         \"spike_length\": {\"values\": [50]},  \n",
    "#         \"num_cluster\": {\"values\": [4]}, \n",
    "#         \"training_cycle\": {\"values\": [1400]}, # [1400, 2400]\n",
    "\n",
    "#         \"batch_size\": {\"values\": [32]}, \n",
    "#         \"max_epoch\": {\"values\": [20]}, \n",
    "#         \"learning_rate\": {\"values\": [0.001, 0.0001]},\n",
    "#         \"normalize_on\": {\"values\": [True]},\n",
    "#         \"need_bias\": {\"values\": [False]}, # [True, False]\n",
    "\n",
    "#         \"lif_add_at_first\": {\"values\": [False]}, # [True, False]\n",
    "#         \"my_seed\": {\"values\": [42]}, \n",
    "\n",
    "#         \"TIME\": {\"values\": [50]}, #  [4,6,8,10]\n",
    "#         \"v_decay\": {\"values\": [0.125, 0.25,0.50,0.75,1.0]}, # [0.25,0.50,0.75]\n",
    "#         \"v_threshold\": {\"values\": [0.125, 0.25, 0.50, 0.75, 0.875, 1.0]}, # [0.25,0.50,0.75]\n",
    "#         \"v_reset\": {\"values\": [0.0, 10000.0]},  # [0.0, 10000.0]\n",
    "#         \"BPTT_on\": {\"values\": [True, False]},  # [True, False]\n",
    "\n",
    "#         \"SAE_hidden_nomean\": {\"values\": [True]}, # [True, False]\n",
    "\n",
    "#         # \"current_time\": {\"values\": [current_time]} #밑에서 직접설정됨.\n",
    "\n",
    "#         \"optimizer\": {\"values\": ['Adam', 'SGD']}, # ['Adam', 'SGD']\n",
    "\n",
    "#         \"coarse_com_mode\": {\"values\": [True]}, # [True, False]\n",
    "#         \"coarse_com_config\": {\"values\": [(0.999, -0.0)]}, # ['Adam', 'SGD']\n",
    "\n",
    "#         \"sae_l2_norm_bridge\": {\"values\": [True]}, # [True, False]\n",
    "#         \"sae_lif_bridge\": {\"values\": [False]}, # [False, True]\n",
    "        \n",
    "#         \"accuracy_check_epoch_term\": {\"values\": [1]}, \n",
    "\n",
    "#         \"lif_add_at_last\": {\"values\": [False]},# [True, False]\n",
    "\n",
    "#         \"two_channel_input\": {\"values\": [False]},# [True, False]\n",
    "\n",
    "#         \"lateral_feature_num\": {\"values\": [4]},# [True, False]\n",
    "\n",
    "#         \"lc_adc_on\": {\"values\": [False]},# [True, False]\n",
    "        \n",
    "#         \"converted_net_forward\": {\"values\": [False]},# [True, False]\n",
    "\n",
    "#         \"pretrained_net\": {\"values\": [None]},# [None]\n",
    "\n",
    "#         \"vth_mul_on\": {\"values\": [False]},# [True, False]\n",
    "#         \"batch_norm_on\": {\"values\": [False]},# [True, False]\n",
    "\n",
    "#         \"l2_norm_loss_weight\": {\"values\": [0]},\n",
    "\n",
    "#         \"QCFS_neuron_on\": {\"values\": [False]},   # [True, False]\n",
    "\n",
    "#         \"quantize_level_num\": {\"values\": [0]}, \n",
    "\n",
    "#         \"fusion_net\": {\"values\": [True]}, \n",
    "#         \"repeat_coding\": {\"values\": [False]}, \n",
    "\n",
    "#         \"sae_relu_on\": {\"values\": [False]}, \n",
    "\n",
    "#         \"conv1d_scaling\": {\"values\": [False]}, \n",
    "\n",
    "#         \"norm01\": {\"values\": [True]}, \n",
    "#      }\n",
    "# }\n",
    "\n",
    "\n",
    "# def hyper_iter():\n",
    "#     ### my_snn control board ########################\n",
    "#     wandb.init(save_code = False)\n",
    "#     gpu  =  '2'\n",
    "#     Conv_net  =  wandb.config.Conv_net\n",
    "#     SAE_net  =  wandb.config.SAE_net\n",
    "\n",
    "#     dataset_num  =  wandb.config.dataset_num\n",
    "#     spike_length  =  wandb.config.spike_length\n",
    "#     num_cluster  =  wandb.config.num_cluster\n",
    "#     training_cycle  =  wandb.config.training_cycle\n",
    "\n",
    "#     batch_size  =  wandb.config.batch_size\n",
    "#     max_epoch  =  wandb.config.max_epoch\n",
    "#     learning_rate  =  wandb.config.learning_rate\n",
    "#     normalize_on  =  wandb.config.normalize_on\n",
    "#     need_bias  =  wandb.config.need_bias\n",
    "\n",
    "#     lif_add_at_first  =  wandb.config.lif_add_at_first\n",
    "#     my_seed  =  wandb.config.my_seed\n",
    "\n",
    "\n",
    "#     TIME  =  wandb.config.TIME\n",
    "#     v_decay  =  wandb.config.v_decay\n",
    "#     v_threshold  =  wandb.config.v_threshold\n",
    "#     v_reset  =  wandb.config.v_reset\n",
    "#     BPTT_on  =  wandb.config.BPTT_on\n",
    "\n",
    "#     SAE_hidden_nomean  =  wandb.config.SAE_hidden_nomean\n",
    "    \n",
    "#     current_time =  datetime.datetime.now().strftime(\"%Y%m%d_%H%M%S\") + f\"_{str(int(datetime.datetime.now().microsecond / 1000)).zfill(3)}\"\n",
    "\n",
    "#     optimizer  =  wandb.config.optimizer\n",
    "\n",
    "#     coarse_com_mode = wandb.config.coarse_com_mode\n",
    "#     coarse_com_config = wandb.config.coarse_com_config # (max, min)\n",
    "\n",
    "#     sae_l2_norm_bridge = wandb.config.sae_l2_norm_bridge\n",
    "#     sae_lif_bridge = wandb.config.sae_lif_bridge\n",
    "\n",
    "#     accuracy_check_epoch_term = wandb.config.accuracy_check_epoch_term\n",
    "\n",
    "#     lif_add_at_last = wandb.config.lif_add_at_last\n",
    "\n",
    "#     two_channel_input = wandb.config.two_channel_input\n",
    "\n",
    "#     lateral_feature_num = wandb.config.lateral_feature_num\n",
    "\n",
    "#     lc_adc_on = wandb.config.lc_adc_on\n",
    "\n",
    "#     converted_net_forward = wandb.config.converted_net_forward\n",
    "\n",
    "#     pretrained_net = wandb.config.pretrained_net\n",
    "\n",
    "#     vth_mul_on = wandb.config.vth_mul_on\n",
    "#     batch_norm_on = wandb.config.batch_norm_on\n",
    "\n",
    "#     l2_norm_loss_weight = wandb.config.l2_norm_loss_weight\n",
    "\n",
    "#     QCFS_neuron_on = wandb.config.QCFS_neuron_on\n",
    "\n",
    "#     quantize_level_num = wandb.config.quantize_level_num\n",
    "\n",
    "#     fusion_net = wandb.config.fusion_net\n",
    "#     repeat_coding = wandb.config.repeat_coding\n",
    "\n",
    "#     sae_relu_on = wandb.config.sae_relu_on\n",
    "\n",
    "#     conv1d_scaling = wandb.config.conv1d_scaling\n",
    "\n",
    "#     norm01 = wandb.config.norm01\n",
    "\n",
    "#     cluster_train_system( \n",
    "#         gpu = gpu,\n",
    "#         Conv_net = Conv_net,\n",
    "#         SAE_net = SAE_net,\n",
    "\n",
    "#         # hyperparameter\n",
    "#         dataset_num = dataset_num,\n",
    "#         spike_length = spike_length,\n",
    "#         num_cluster = num_cluster,  # 클러스터 수 설정 # 논문엔 4개라는데 여기서는 3개로 했네\n",
    "#         training_cycle = training_cycle, # 그 초기 몇개까지만 cluster update할지\n",
    "\n",
    "\n",
    "#         batch_size = batch_size,\n",
    "#         max_epoch = max_epoch,\n",
    "#         learning_rate = learning_rate,\n",
    "#         normalize_on = normalize_on, # True or False #이거 안 씀 # 이거 별로 안 좋은 normalize같음 # 쓸 거면 다른 거 써라.\n",
    "#         need_bias = need_bias,\n",
    "#         # first_layer_no_train = False\n",
    "#         lif_add_at_first = lif_add_at_first,\n",
    "#         my_seed = my_seed,\n",
    "\n",
    "#         TIME = TIME, # SAE일 때만 유효\n",
    "#         v_decay = v_decay,\n",
    "#         v_threshold = v_threshold,\n",
    "#         v_reset = v_reset, # 10000이상 일 시 hard reset\n",
    "#         BPTT_on = BPTT_on,\n",
    "\n",
    "#         SAE_hidden_nomean = SAE_hidden_nomean,\n",
    "\n",
    "#         current_time = current_time,\n",
    "\n",
    "#         optimizer = optimizer, #'Adam', 'SGD'\n",
    "\n",
    "#         coarse_com_mode = coarse_com_mode,\n",
    "#         coarse_com_config = coarse_com_config, # (max, min)\n",
    "        \n",
    "#         sae_l2_norm_bridge = sae_l2_norm_bridge,\n",
    "#         sae_lif_bridge = sae_lif_bridge,\n",
    "\n",
    "#         accuracy_check_epoch_term = accuracy_check_epoch_term,\n",
    "\n",
    "#         lif_add_at_last = lif_add_at_last,\n",
    "        \n",
    "#         two_channel_input = two_channel_input,\n",
    "        \n",
    "#         lateral_feature_num = lateral_feature_num,\n",
    "\n",
    "#         lc_adc_on = lc_adc_on,\n",
    "\n",
    "#         converted_net_forward = converted_net_forward,\n",
    "\n",
    "#         pretrained_net = pretrained_net,\n",
    "\n",
    "#         vth_mul_on = vth_mul_on,\n",
    "#         batch_norm_on = batch_norm_on,\n",
    "\n",
    "#         l2_norm_loss_weight = l2_norm_loss_weight,\n",
    "\n",
    "#         QCFS_neuron_on = QCFS_neuron_on,\n",
    "\n",
    "#         quantize_level_num = quantize_level_num,\n",
    "\n",
    "#         fusion_net = fusion_net, \n",
    "#         repeat_coding = repeat_coding, \n",
    "\n",
    "#         sae_relu_on = sae_relu_on,\n",
    "\n",
    "#         conv1d_scaling = conv1d_scaling,\n",
    "\n",
    "#         norm01 = norm01,\n",
    "#         )\n",
    "    \n",
    "# # sweep_id = 'ygoj9jt4'\n",
    "# sweep_id = wandb.sweep(sweep=sweep_configuration, project=f'spike_sorting {unique_name_hyper}')\n",
    "# wandb.agent(sweep_id, function=hyper_iter, count=100000, project=f'spike_sorting {unique_name_hyper}')\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wandb.finish() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import matplotlib.pyplot as plt\n",
    "# from matplotlib.ticker import MaxNLocator\n",
    "# import pickle\n",
    "# import json\n",
    "\n",
    "# # current_time = '20250102_225243_972'\n",
    "\n",
    "# with open(f\"result_save/cluster_accuracy_history_{current_time}.pkl\", \"rb\") as f:\n",
    "#     data = pickle.load(f)\n",
    "\n",
    "\n",
    "# # JSON으로 저장\n",
    "# with open(f\"result_save/cluster_accuracy_history_{current_time}.json\", 'r') as f:\n",
    "#     loaded_hyperparameters = json.load(f)\n",
    "\n",
    "# loss_history = data['loss_history']\n",
    "# mean_cluster_accuracy_during_training_cycle_all_dataset_history = data['mean_cluster_accuracy_during_training_cycle_all_dataset_history']\n",
    "# mean_cluster_accuracy_post_training_cycle_all_dataset_history = data['mean_cluster_accuracy_post_training_cycle_all_dataset_history']\n",
    "# mean_cluster_accuracy_total_all_dataset_history = data['mean_cluster_accuracy_total_all_dataset_history']\n",
    "# print(data)\n",
    "# max_acc = 0\n",
    "# for i in mean_cluster_accuracy_post_training_cycle_all_dataset_history:\n",
    "#     if i[1] > max_acc:\n",
    "#         max_acc = i[1]\n",
    "\n",
    "# # 설정 정보 제목 작성\n",
    "# title = (\n",
    "#     f\"Dataset Num: {loaded_hyperparameters['dataset_num']}, Conv {loaded_hyperparameters['Conv_net']}, SAE {loaded_hyperparameters['SAE_net']}, Current time {loaded_hyperparameters['current_time']}, Spike Length: {loaded_hyperparameters['spike_length']}, Num Cluster: {loaded_hyperparameters['num_cluster']}, \"\n",
    "#     f\"Training Cycle: {loaded_hyperparameters['training_cycle']}, Batch Size: {loaded_hyperparameters['batch_size']}, Max Epoch: {loaded_hyperparameters['max_epoch']}, \\n\"\n",
    "#     f\"Learning Rate: {loaded_hyperparameters['learning_rate']}, Input Normalize: {loaded_hyperparameters['normalize_on']}, Need Bias: {loaded_hyperparameters['need_bias']}, \"\n",
    "#     f\"LIF Add at First: {loaded_hyperparameters['lif_add_at_first']}, TIME: {loaded_hyperparameters['TIME']}, Seed: {loaded_hyperparameters['my_seed']}, Best ACC: {max_acc:.2f}%\"\n",
    "# )\n",
    "\n",
    "# # 데이터 리스트와 라벨 설정 (Loss 제외)\n",
    "# data_list = [\n",
    "#     (\"Mean Cluster Accuracy (During Training Cycle)\", mean_cluster_accuracy_during_training_cycle_all_dataset_history),\n",
    "#     (\"Mean Cluster Accuracy (Post Training Cycle)\", mean_cluster_accuracy_post_training_cycle_all_dataset_history),\n",
    "#     (\"Mean Cluster Accuracy (Total)\", mean_cluster_accuracy_total_all_dataset_history),\n",
    "# ]\n",
    "\n",
    "# # 플롯 생성\n",
    "# fig, ax1 = plt.subplots(figsize=(12, 8))\n",
    "\n",
    "# # 첫 번째 y축: Accuracy 관련 데이터\n",
    "# for label, data in data_list:\n",
    "#     epochs, values = zip(*data)  # epoch, value 분리\n",
    "#     ax1.plot(epochs, values, label=label)\n",
    "\n",
    "# ax1.set_xlabel(\"Epoch\")\n",
    "# ax1.set_ylabel(\"Clurstering Accuracy [%]\", color=\"blue\")\n",
    "# ax1.tick_params(axis=\"y\", labelcolor=\"blue\")\n",
    "# ax1.legend(loc=\"center right\")\n",
    "# ax1.grid(True)\n",
    "\n",
    "# # x축을 정수만 표시하도록 설정\n",
    "# ax1.xaxis.set_major_locator(MaxNLocator(integer=True))\n",
    "\n",
    "# # 두 번째 y축: Loss History\n",
    "# ax2 = ax1.twinx()\n",
    "# epochs, values = zip(*loss_history)\n",
    "# ax2.plot(epochs, values, label=\"AE Loss History\", color=\"red\", linestyle=\"--\")\n",
    "# ax2.set_ylabel(\"Loss\", color=\"red\")\n",
    "# ax2.tick_params(axis=\"y\", labelcolor=\"red\")\n",
    "# ax2.legend(loc=\"center left\")\n",
    "\n",
    "# # 제목 추가\n",
    "# plt.title(title, fontsize=10)\n",
    "# plt.tight_layout()\n",
    "# plt.savefig(f'net_save/{current_time}', dpi=300, bbox_inches=\"tight\")  # dpi=300은 고해상도로 저장, bbox_inches=\"tight\"는 여백 최소화\n",
    "# plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# 데이터셋\n",
    "filename_for_plot = [\n",
    "    \"Easy1_noise05\", \"Easy1_noise10\", \"Easy1_noise15\", \"Easy1_noise20\",\n",
    "    \"Easy2_noise05\", \"Easy2_noise10\", \"Easy2_noise15\", \"Easy2_noise20\",\n",
    "    \"Difficult1_noise05\", \"Difficult1_noise10\", \"Difficult1_noise15\", \"Difficult1_noise20\",\n",
    "    \"Difficult2_noise05\", \"Difficult2_noise10\", \"Difficult2_noise15\", \"Difficult2_noise20\"\n",
    "]\n",
    "\n",
    "# Accuracy 데이터\n",
    "ANN_conv_accracy_set= [0.97935368, 0.97682709, 0.97028784, 0.96461825, 0.97524752, 0.95803571\n",
    ", 0.95746785, 0.92628774, 0.965412,  0.97805344, 0.94869403, 0.92110454\n",
    ", 0.96784232, 0.97551789, 0.91538462, 0.84446478]\n",
    "SNN_fc_accuracy_set = [0.97114475, 0.97643732, 0.84400578, 0.78977821, 0.96616915, 0.92830189\n",
    ", 0.86176032, 0.31984948, 0.80635401, 0.88769531, 0.61003861, 0.60377358\n",
    ", 0.9592668,  0.92870999, 0.78333333, 0.67271859]\n",
    "SNN_conv_accuracy_set = [0.97445601, 0.97737983, 0.97063072, 0.95998071, 0.96268657, 0.90566038\n",
    ", 0.82545997, 0.68391345, 0.96116994, 0.92138672, 0.80694981, 0.49602781\n",
    ", 0.83604888, 0.70611057, 0.69313725, 0.5819398 ]\n",
    "\n",
    "# 평균 계산\n",
    "average_ANN_conv = np.mean(ANN_conv_accracy_set)\n",
    "average_SNN_fc = np.mean(SNN_fc_accuracy_set)\n",
    "average_SNN_conv = np.mean(SNN_conv_accuracy_set)\n",
    "\n",
    "# 데이터 준비\n",
    "accuracies = np.array([ANN_conv_accracy_set, SNN_fc_accuracy_set, SNN_conv_accuracy_set])\n",
    "averages = np.array([average_ANN_conv, average_SNN_fc, average_SNN_conv])\n",
    "\n",
    "# 시각화\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "\n",
    "# 각 모델의 정확도 플롯\n",
    "ax.plot(accuracies[0], label='ANN Conv', marker='o', linestyle='-', color='blue')\n",
    "ax.plot(accuracies[1], label='SNN FC', marker='o', linestyle='-', color='green')\n",
    "ax.plot(accuracies[2], label='SNN Conv', marker='o', linestyle='-', color='red')\n",
    "\n",
    "# 평균값 플롯\n",
    "ax.axhline(y=average_ANN_conv, color='blue', linestyle='--', label=f'Average ANN Conv: {average_ANN_conv:.3f}')\n",
    "ax.axhline(y=average_SNN_fc, color='green', linestyle='--', label=f'Average SNN FC: {average_SNN_fc:.3f}')\n",
    "ax.axhline(y=average_SNN_conv, color='red', linestyle='--', label=f'Average SNN Conv: {average_SNN_conv:.3f}')\n",
    "\n",
    "# 레이블 추가\n",
    "ax.set_xticks(np.arange(len(filename_for_plot)))\n",
    "ax.set_xticklabels(filename_for_plot, rotation=45, ha='right')\n",
    "ax.set_ylabel('Accuracy')\n",
    "ax.set_title('Accuracy Comparison of Models on Datasets')\n",
    "ax.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import matplotlib.pyplot as plt\n",
    "import os  # 파일 경로 처리를 위한 모듈\n",
    "\n",
    "# CSV 파일 경로\n",
    "# csv_file_path = \"/home/bhkim003/github_folder/ByeonghyeonKim/my_snn/ae_test_deprecated/250115/sweep0_vth_mul.csv\" # vth_mul해서 sweep 돌린거\n",
    "csv_file_path = \"/home/bhkim003/github_folder/ByeonghyeonKim/my_snn/ae_test_deprecated/250115/sweep1.csv\"  #vth_mul안한거\n",
    "\n",
    "# 결과를 저장할 리스트\n",
    "tuple_list = []\n",
    "\n",
    "# CSV 파일 읽기\n",
    "with open(csv_file_path, 'r') as file:\n",
    "    reader = csv.DictReader(file)\n",
    "    for row in reader:\n",
    "        try:\n",
    "            # v_threshold, TIME, v_reset, converted_k_means_acc 값을 가져와 튜플로 변환\n",
    "            v_threshold = float(row[\"v_threshold\"])\n",
    "            time = int(row[\"TIME\"])\n",
    "            v_reset = int(row[\"v_reset\"])\n",
    "            converted_k_means_acc = float(row[\"converted_k_means_acc\"]) if row[\"converted_k_means_acc\"] else None\n",
    "\n",
    "            # 튜플 형태로 추가 (값이 None일 경우 처리할 수도 있음)\n",
    "            tuple_list.append((v_threshold, time, v_reset, converted_k_means_acc))\n",
    "        except ValueError as e:\n",
    "            print(f\"Error processing row {row}: {e}\")\n",
    "\n",
    "# 데이터를 TIME 기준으로 정렬\n",
    "tuple_list.sort(key=lambda x: x[1])  # TIME을 기준으로 오름차순 정렬\n",
    "\n",
    "# reset 방식에 따라 데이터를 나누기\n",
    "soft_reset = [t for t in tuple_list if t[2] == 0]\n",
    "hard_reset = [t for t in tuple_list if t[2] == 10000]\n",
    "\n",
    "# reset 방식과 v_threshold에 따라 색상 설정\n",
    "def plot_data(data, label_prefix, marker):\n",
    "    for v_threshold in [1.0]:  # v_threshold 기준으로 제한\n",
    "        filtered_data = [(t[1], t[3]) for t in data if t[0] == v_threshold]\n",
    "        if filtered_data:  # 해당 v_threshold 데이터가 있을 경우만 플롯\n",
    "            times, accuracies = zip(*filtered_data)  # x축(TIME), y축(converted_k_means_acc)\n",
    "            \n",
    "            plt.plot(\n",
    "                times,\n",
    "                accuracies,\n",
    "                marker,\n",
    "                label=f\"{label_prefix}, v_threshold={v_threshold}\",\n",
    "                linestyle=\"--\",\n",
    "            )\n",
    "            # 각 점에 accuracy 표시\n",
    "            for time, acc in filtered_data:\n",
    "                if acc == None:\n",
    "                    continue\n",
    "                plt.text(time, acc, f\"{acc:.2f}\", fontsize=8, ha=\"right\")\n",
    "\n",
    "# 그래프 초기화\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "# soft_reset (v_reset=0) 데이터 플롯\n",
    "plot_data(soft_reset, \"Soft Reset\", \"o\")\n",
    "\n",
    "# hard_reset (v_reset=10000) 데이터 플롯\n",
    "plot_data(hard_reset, \"Hard Reset\", \"x\")\n",
    "\n",
    "# baseline accuracy 가로선 추가\n",
    "baseline_accuracy = 94.43\n",
    "plt.axhline(y=baseline_accuracy, color=\"red\", linestyle=\"-\", label=f\"Baseline Accuracy ({baseline_accuracy}%)\")\n",
    "# baseline 텍스트 추가\n",
    "plt.text(\n",
    "    2000,  # x축 위치 (그래프 오른쪽 끝)\n",
    "    baseline_accuracy + 0.4,  # y축 위치 (baseline 위 약간)\n",
    "    f\"ANN Baseline ({baseline_accuracy}%)\",\n",
    "    color=\"red\",\n",
    "    fontsize=10,\n",
    "    ha=\"center\",\n",
    ")\n",
    "\n",
    "# CSV 파일 이름 가져오기\n",
    "csv_file_name = os.path.basename(csv_file_path)\n",
    "\n",
    "# 그래프 세부 설정\n",
    "plt.title(f\"Converted SNN K-Means Accuracy vs TIME STEP - {csv_file_name}\")\n",
    "plt.xlabel(\"TIME STEP\")\n",
    "plt.ylabel(\"Converted K-Means Accuracy [%]\")\n",
    "plt.legend(loc=\"lower right\")  # 범례를 오른쪽 아래로 이동\n",
    "plt.grid(True)\n",
    "\n",
    "# 그래프 출력\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aedat2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
