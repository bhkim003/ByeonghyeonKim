{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ssp.train.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x600 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import torch   \n",
    "import torch.nn as nn \n",
    "import torch.nn.functional as F   \n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import torch.optim as optim\n",
    "from scipy import io\n",
    "import itertools\n",
    "import math\n",
    "import datetime\n",
    "import wandb\n",
    "import pickle\n",
    "import json\n",
    "import time\n",
    "import sys\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import accuracy_score\n",
    "from scipy.optimize import linear_sum_assignment\n",
    "from snntorch import spikegen\n",
    "\n",
    "\n",
    "# my module import\n",
    "from modules import *\n",
    "\n",
    "# os.environ[\"CUBLAS_WORKSPACE_CONFIG\"] = \":4096:8\"\n",
    "\n",
    "# modules 폴더에 새모듈.py 만들면\n",
    "# modules/__init__py 파일에 form .새모듈 import * 하셈\n",
    "# 그리고 새모듈.py에서 from modules.새모듈 import * 하셈"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cluster_train_system( \n",
    "    gpu = '4',\n",
    "    Conv_net = True,\n",
    "    SAE_net = True,\n",
    "\n",
    "    # hyperparameter\n",
    "    dataset_num = 16,\n",
    "    spike_length = 50,\n",
    "    num_cluster = 4,  # 클러스터 수 설정 # 논문엔 4개라는데 여기서는 3개로 했네\n",
    "    training_cycle = 2400, # 그 초기 몇개까지만 cluster update할지\n",
    "\n",
    "\n",
    "    batch_size = 32,\n",
    "    max_epoch = 7000,\n",
    "    learning_rate = 0.001,\n",
    "    normalize_on = False, # True or False #이거 안 씀 # 이거 별로 안 좋은 normalize같음 # 쓸 거면 다른 거 써라.\n",
    "    need_bias = False,\n",
    "    # first_layer_no_train = False\n",
    "    lif_add_at_first = False,\n",
    "    my_seed = 42,\n",
    "\n",
    "    TIME = 10, # SAE일 때만 유효\n",
    "    v_decay = 0.5,\n",
    "    v_threshold = 0.5,\n",
    "    v_reset = 10000.0, # 10000이상 일 시 hard reset\n",
    "    BPTT_on = True,\n",
    "\n",
    "    SAE_hidden_nomean = True,\n",
    "    current_time = '20250101_210938_786',\n",
    "\n",
    "    optimizer = 'Adam',\n",
    "    coarse_com_mode = True,\n",
    "    coarse_com_config = (2.0, -2.0), # (max, min)\n",
    "\n",
    "    sae_l2_norm_bridge = True,\n",
    "    sae_lif_bridge = False,\n",
    "\n",
    "    accuracy_check_epoch_term = 5,\n",
    "    \n",
    "    lif_add_at_last = False,\n",
    "\n",
    "    two_channel_input = False,\n",
    "\n",
    "    lateral_feature_num = 4,\n",
    "\n",
    "    lc_adc_on = False, \n",
    "\n",
    "    converted_net_forward = False,\n",
    "\n",
    "    pretrained_net = None, \n",
    "\n",
    "    vth_mul_on = False,\n",
    "    batch_norm_on = False,\n",
    "\n",
    "    l2_norm_loss_weight = 0.0,\n",
    "\n",
    "    QCFS_neuron_on = False,\n",
    "\n",
    "    quantize_level_num = 0,\n",
    "\n",
    "    fusion_net = False, # True False\n",
    "    repeat_coding = False,\n",
    "    \n",
    "    sae_relu_on = False,\n",
    "\n",
    "    conv1d_scaling = False,\n",
    "\n",
    "    norm01 = True,\n",
    "\n",
    "    chan_loss_factor = 1.0,\n",
    "    ):\n",
    "    if coarse_com_mode == True:\n",
    "        assert coarse_com_config[0] > coarse_com_config[1], 'coarse_com_config[0] > coarse_com_config[1]이어야 함'\n",
    "        assert converted_net_forward == False\n",
    "        # assert SAE_net == True, 'coarse_com_mode는 SAE_net이 True일 때만 가능'\n",
    "    if two_channel_input == True:\n",
    "        assert Conv_net and coarse_com_mode, 'two_channel_input는 Conv_net이 True일 때만 가능'\n",
    "    if lc_adc_on == True:\n",
    "        assert coarse_com_mode and SAE_net, 'lc_adc_on은 coarse_com_mode와 SAE_net이 True일 때만 가능'\n",
    "    if converted_net_forward == True:\n",
    "        assert SAE_net == False, 'converted_net_forward는 SAE_net이 False일 때만 가능'\n",
    "    if conv1d_scaling:\n",
    "        assert Conv_net and coarse_com_mode and normalize_on\n",
    "    seed_assign(my_seed)\n",
    "    ## 함수 내 모든 로컬 변수 저장 ########################################################\n",
    "    hyperparameters = locals()\n",
    "    print(hyperparameters)\n",
    "    # JSON으로 저장\n",
    "    with open(f\"result_save/cluster_accuracy_history_{current_time}.json\", 'w') as f:\n",
    "        json.dump(hyperparameters, f, indent=4)\n",
    "    ######################################################################################\n",
    "\n",
    "    \n",
    "    wandb.config.update(hyperparameters)\n",
    "    wandb.run.name = f'{current_time}_SAE_net_{SAE_net}_v_threshold_{v_threshold}'\n",
    "    wandb.define_metric(\"best_mean_cluster_accuracy_post_training_cycle_all_dataset2\", summary=\"max\")\n",
    "\n",
    "\n",
    "    my_path_ground_BH = '/data2/spike_sorting/quiroga/BH/'\n",
    "\n",
    "\n",
    "    filename = [\"C_Easy1_noise005.mat\", \"C_Easy1_noise01.mat\", \"C_Easy1_noise015.mat\", \"C_Easy1_noise02.mat\",\n",
    "                \"C_Easy2_noise005.mat\", \"C_Easy2_noise01.mat\", \"C_Easy2_noise015.mat\", \"C_Easy2_noise02.mat\",\n",
    "                \"C_Difficult1_noise005.mat\", \"C_Difficult1_noise01.mat\", \"C_Difficult1_noise015.mat\", \"C_Difficult1_noise02.mat\",\n",
    "                \"C_Difficult2_noise005.mat\", \"C_Difficult2_noise01.mat\", \"C_Difficult2_noise015.mat\", \"C_Difficult2_noise02.mat\"]\n",
    "\n",
    "\n",
    "    spike_tot = [\"BH_Spike_e1n005.npy\", \"BH_Spike_e1n010.npy\", \"BH_Spike_e1n015.npy\", \"BH_Spike_e1n020.npy\",\n",
    "                \"BH_Spike_e2n005.npy\", \"BH_Spike_e2n010.npy\", \"BH_Spike_e2n015.npy\", \"BH_Spike_e2n020.npy\",\n",
    "                \"BH_Spike_d1n005.npy\", \"BH_Spike_d1n010.npy\", \"BH_Spike_d1n015.npy\", \"BH_Spike_d1n020.npy\",\n",
    "                \"BH_Spike_d2n005.npy\", \"BH_Spike_d2n010.npy\", \"BH_Spike_d2n015.npy\", \"BH_Spike_d2n020.npy\"]\n",
    "\n",
    "    label_tot = [\"BH_Label_e1n005.npy\", \"BH_Label_e1n010.npy\", \"BH_Label_e1n015.npy\", \"BH_Label_e1n020.npy\",\n",
    "                \"BH_Label_e2n005.npy\", \"BH_Label_e2n010.npy\", \"BH_Label_e2n015.npy\", \"BH_Label_e2n020.npy\",\n",
    "                \"BH_Label_d1n005.npy\", \"BH_Label_d1n010.npy\", \"BH_Label_d1n015.npy\", \"BH_Label_d1n020.npy\",\n",
    "                \"BH_Label_d2n005.npy\", \"BH_Label_d2n010.npy\", \"BH_Label_d2n015.npy\", \"BH_Label_d2n020.npy\"]\n",
    "\n",
    "    template =  [\"BH_Spike_TEMPLATE_e1n005.npy\", \"BH_Spike_TEMPLATE_e1n010.npy\", \"BH_Spike_TEMPLATE_e1n015.npy\", \"BH_Spike_TEMPLATE_e1n020.npy\",\n",
    "                \"BH_Spike_TEMPLATE_e2n005.npy\", \"BH_Spike_TEMPLATE_e2n010.npy\", \"BH_Spike_TEMPLATE_e2n015.npy\", \"BH_Spike_TEMPLATE_e2n020.npy\",\n",
    "                \"BH_Spike_TEMPLATE_d1n005.npy\", \"BH_Spike_TEMPLATE_d1n010.npy\", \"BH_Spike_TEMPLATE_d1n015.npy\", \"BH_Spike_TEMPLATE_d1n020.npy\",\n",
    "                \"BH_Spike_TEMPLATE_d2n005.npy\", \"BH_Spike_TEMPLATE_d2n010.npy\", \"BH_Spike_TEMPLATE_d2n015.npy\", \"BH_Spike_TEMPLATE_d2n020.npy\"]\n",
    "\n",
    "    AE_train_path_gt_detect = 'BH_quiroga_training_dataset_gt_detect.pt' \n",
    "    AE_test_path_gt_detect = 'BH_quiroga_test_dataset_gt_detect.pt'\n",
    "\n",
    "    AE_train_path_real_detect = 'BH_quiroga_training_dataset_real_detect.pt'\n",
    "    AE_test_path_real_detect = 'BH_quiroga_test_dataset_real_detect.pt'\n",
    "\n",
    "    AE_train_data = AE_train_path_real_detect #AE_train_path_gt_detect #AE_train_path_real_detect\n",
    "    AE_test_data = AE_test_path_real_detect #AE_test_path_gt_detect  #AE_test_path_real_detect\n",
    "\n",
    "    # thr_tot = np.array([0.5, 0.5, 0.55, 0.7, 0.5, 0.5, 0.55, 0.7, 0.5, 0.5, 0.55, 0.7, 0.5, 0.5, 0.55, 0.7])\n",
    "    cos_thr = np.array([0.95, 0.95, 0.95, 0.95, 0.95, 0.95, 0.95, 0.85, 0.95, 0.9, 0.8, 0.95, 0.95, 0.95, 0.95, 0.8])\n",
    "    # tem=10\n",
    "    # cos_thr = np.array([tem, tem, tem, tem, tem, tem, tem, tem, tem, tem, tem, tem, tem, tem, tem, tem, ])\n",
    "\n",
    "    print('cos_thr', cos_thr)\n",
    "    \n",
    "    os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\" \n",
    "    os.environ[\"CUDA_VISIBLE_DEVICES\"]= gpu\n",
    "\n",
    "\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "\n",
    "    if coarse_com_mode == True:\n",
    "        level_num = TIME\n",
    "        TIME = spike_length\n",
    "        spike_length = level_num\n",
    "        level_interval = (coarse_com_config[0] - coarse_com_config[1]) / (level_num-1)  # max - min\n",
    "        levels = [coarse_com_config[1] + level_interval * i for i in range(level_num)]\n",
    "        levels = torch.tensor(levels).to(torch.float32).to(device)\n",
    "        levels = levels.repeat(TIME,1) \n",
    "        # print('levels', levels, levels.shape) # TIME, level_num\n",
    "\n",
    "    n_sample = spike_length\n",
    "\n",
    "    class spikedataset(Dataset):\n",
    "        def __init__(self, path, transform = None):    \n",
    "            self.transform = transform\n",
    "            self.spike = torch.load(path)\n",
    "            \n",
    "        def __getitem__(self, index):\n",
    "            spike = self.spike[index]            \n",
    "            if self.transform is not None:\n",
    "                spike = self.transform(spike)\n",
    "            return spike\n",
    "        \n",
    "        def __len__(self):\n",
    "            return len(self.spike)\n",
    "\n",
    "    train_dataset = spikedataset(my_path_ground_BH + AE_train_data)\n",
    "    train_loader = DataLoader(dataset = train_dataset, batch_size = batch_size, shuffle = True)\n",
    "\n",
    "    test_dataset = spikedataset(my_path_ground_BH + AE_test_data)\n",
    "    test_loader = DataLoader(dataset = test_dataset, batch_size = batch_size, shuffle = False)\n",
    "\n",
    "\n",
    "    # vth_mul_on = True # True False\n",
    "    # batch_norm_on = True # True False\n",
    "\n",
    "\n",
    "    # 모델 초기화\n",
    "    if SAE_net == False: # 여기서는 l2norm, lif bridge 둘 다 true면 l2norm먼저\n",
    "        assert two_channel_input == False\n",
    "\n",
    "        if Conv_net == True:\n",
    "            # input_channels = 2 if two_channel_input else 1\n",
    "            input_channels = TIME if coarse_com_mode else 1\n",
    "            if fusion_net == True:\n",
    "                assert False, '이거 맞음? 다시 확인'\n",
    "                net = FUSION_net_conv1(input_channels=input_channels, input_length=n_sample, encoder_ch = [32, 64, 96], fc_dim = lateral_feature_num, padding = 0, stride = 2, kernel_size = 3, \n",
    "                                    synapse_fc_trace_const1=1, \n",
    "                                    synapse_fc_trace_const2=v_decay, #안씀 \n",
    "                                    TIME=TIME, v_init=0.0, v_decay=v_decay, v_threshold=v_threshold, v_reset=v_reset, \n",
    "                                    sg_width=4.0, surrogate='sigmoid', BPTT_on=BPTT_on, need_bias=need_bias, lif_add_at_first=lif_add_at_first,\n",
    "                                    sae_l2_norm_bridge = sae_l2_norm_bridge, sae_lif_bridge = sae_lif_bridge, lif_add_at_last=lif_add_at_last, repeat_coding=repeat_coding).to(device)\n",
    "            else: \n",
    "                net = Autoencoder_conv1(input_channels=input_channels, input_length=n_sample, encoder_ch = [32, 64, 96], fc_dim = lateral_feature_num, padding = 0, stride = 2, kernel_size = 3, need_bias=need_bias, l2norm_bridge=sae_l2_norm_bridge, relu_bridge=sae_lif_bridge, activation_collector_on=False,\n",
    "                                        batch_norm_on=batch_norm_on, QCFS_neuron_on=QCFS_neuron_on).to(device)\n",
    "            net = torch.nn.DataParallel(net)\n",
    "            if converted_net_forward:\n",
    "                converted_net = SAE_converted_conv1(input_channels=input_channels, input_length=n_sample, encoder_ch = [32, 64, 96], fc_dim = lateral_feature_num, padding = 0, stride = 2, kernel_size = 3, \n",
    "                                    synapse_fc_trace_const1=1, \n",
    "                                    synapse_fc_trace_const2=v_decay, #안씀 \n",
    "                                    TIME=TIME, v_init=0.0, v_decay=v_decay, v_threshold=v_threshold, v_reset=v_reset, \n",
    "                                    sg_width=4.0, surrogate='sigmoid', BPTT_on=BPTT_on, need_bias=need_bias, lif_add_at_first=lif_add_at_first,\n",
    "                                    sae_l2_norm_bridge = sae_l2_norm_bridge, sae_lif_bridge = sae_lif_bridge, lif_add_at_last=lif_add_at_last,\n",
    "                                    vth_mul_on=vth_mul_on, batch_norm_on=batch_norm_on).to(device) # lif bridge는 무조건 들어가게 해놨음.\n",
    "                converted_net = torch.nn.DataParallel(converted_net)\n",
    "                print('converted_net', converted_net)\n",
    "        else:\n",
    "            n_sample = n_sample * TIME if coarse_com_mode else n_sample\n",
    "            net = Autoencoder_only_FC(encoder_ch=[400, lateral_feature_num], decoder_ch=[400,n_sample], n_sample=n_sample, need_bias=need_bias, l2norm_bridge=sae_l2_norm_bridge, relu_bridge=sae_lif_bridge, activation_collector_on=False,\n",
    "                                    batch_norm_on=batch_norm_on, QCFS_neuron_on=QCFS_neuron_on).to(device)\n",
    "            net = torch.nn.DataParallel(net)\n",
    "            if converted_net_forward:\n",
    "                converted_net = SAE_converted_fc(encoder_ch=[400, lateral_feature_num], \n",
    "                                    decoder_ch=[400, n_sample], \n",
    "                                    in_channels=n_sample, # in_channel 이 여기선 걍 lenght.\n",
    "                                    synapse_fc_trace_const1=1,\n",
    "                                    synapse_fc_trace_const2=v_decay,  #안씀 \n",
    "                                    TIME=TIME, v_init=0.0, v_decay=v_decay, v_threshold=v_threshold, v_reset=v_reset, \n",
    "                                    sg_width=4.0, surrogate='sigmoid', BPTT_on=BPTT_on, need_bias=need_bias, lif_add_at_first=lif_add_at_first,\n",
    "                                    sae_l2_norm_bridge = sae_l2_norm_bridge, sae_lif_bridge = sae_lif_bridge, lif_add_at_last=lif_add_at_last,\n",
    "                                    vth_mul_on=vth_mul_on, batch_norm_on=batch_norm_on).to(device) # lif bridge는 무조건 들어가게 해놨음.\n",
    "                converted_net = torch.nn.DataParallel(converted_net)\n",
    "                # print('converted_net', converted_net)\n",
    "    else:\n",
    "        if Conv_net == True: \n",
    "            input_channels = 1\n",
    "            input_channels = 2 if two_channel_input else 1\n",
    "            if fusion_net == True:  \n",
    "                assert coarse_com_mode == True\n",
    "                # net = SAE_FUSION2_net_conv1(input_channels=input_channels, input_length=n_sample, encoder_ch = [32, 64, 96], fc_dim = lateral_feature_num, padding = 0, stride = 2, kernel_size = 3, \n",
    "                #                     synapse_fc_trace_const1=1, \n",
    "                #                     synapse_fc_trace_const2=v_decay, #안씀 \n",
    "                #                     TIME=TIME, v_init=0.0, v_decay=v_decay, v_threshold=v_threshold, v_reset=v_reset, \n",
    "                #                     sg_width=4.0, surrogate='sigmoid', BPTT_on=BPTT_on, need_bias=need_bias, lif_add_at_first=lif_add_at_first,\n",
    "                #                     sae_l2_norm_bridge = sae_l2_norm_bridge, sae_lif_bridge = sae_lif_bridge, lif_add_at_last=lif_add_at_last, batch_norm_on=batch_norm_on, sae_relu_on=sae_relu_on).to(device)\n",
    "                # net = SAE_FUSION3_net_conv1(input_channels=input_channels, input_length=n_sample, encoder_ch = [32, 64, 96], fc_dim = lateral_feature_num, padding = 0, stride = 2, kernel_size = 3, \n",
    "                #                     synapse_fc_trace_const1=1, \n",
    "                #                     synapse_fc_trace_const2=v_decay, #안씀 \n",
    "                #                     TIME=TIME, v_init=0.0, v_decay=v_decay, v_threshold=v_threshold, v_reset=v_reset, \n",
    "                #                     sg_width=4.0, surrogate='sigmoid', BPTT_on=BPTT_on, need_bias=need_bias, lif_add_at_first=lif_add_at_first,\n",
    "                #                     sae_l2_norm_bridge = sae_l2_norm_bridge, sae_lif_bridge = sae_lif_bridge, lif_add_at_last=lif_add_at_last, batch_norm_on=batch_norm_on, sae_relu_on=sae_relu_on).to(device)\n",
    "                # net = SAE_FUSION4_net_conv1(input_channels=input_channels, input_length=n_sample, encoder_ch = [32, 64, 96], fc_dim = lateral_feature_num, padding = 0, stride = 2, kernel_size = 3, \n",
    "                #                     synapse_fc_trace_const1=1, \n",
    "                #                     synapse_fc_trace_const2=v_decay, #안씀 \n",
    "                #                     TIME=TIME, v_init=0.0, v_decay=v_decay, v_threshold=v_threshold, v_reset=v_reset, \n",
    "                #                     sg_width=4.0, surrogate='sigmoid', BPTT_on=BPTT_on, need_bias=need_bias, lif_add_at_first=lif_add_at_first,\n",
    "                #                     sae_l2_norm_bridge = sae_l2_norm_bridge, sae_lif_bridge = sae_lif_bridge, lif_add_at_last=lif_add_at_last, batch_norm_on=batch_norm_on, sae_relu_on=sae_relu_on).to(device)\n",
    "                net = SAE_FUSION5_net_conv1(input_channels=input_channels, input_length=n_sample, encoder_ch = [32, 64, 96], fc_dim = lateral_feature_num, padding = 0, stride = 2, kernel_size = 3, \n",
    "                                    synapse_fc_trace_const1=1, \n",
    "                                    synapse_fc_trace_const2=v_decay, #안씀 \n",
    "                                    TIME=TIME, v_init=0.0, v_decay=v_decay, v_threshold=v_threshold, v_reset=v_reset, \n",
    "                                    sg_width=4.0, surrogate='sigmoid', BPTT_on=BPTT_on, need_bias=need_bias, lif_add_at_first=lif_add_at_first,\n",
    "                                    sae_l2_norm_bridge = sae_l2_norm_bridge, sae_lif_bridge = sae_lif_bridge, lif_add_at_last=lif_add_at_last, batch_norm_on=batch_norm_on, sae_relu_on=sae_relu_on).to(device)\n",
    "                # net = SAE_FUSION6_net_conv1(input_channels=input_channels, input_length=n_sample, encoder_ch = [32, 64, 96], fc_dim = lateral_feature_num, padding = 0, stride = 2, kernel_size = 3, \n",
    "                #                     synapse_fc_trace_const1=1, \n",
    "                #                     synapse_fc_trace_const2=v_decay, #안씀 \n",
    "                #                     TIME=TIME, v_init=0.0, v_decay=v_decay, v_threshold=v_threshold, v_reset=v_reset, \n",
    "                #                     sg_width=4.0, surrogate='sigmoid', BPTT_on=BPTT_on, need_bias=need_bias, lif_add_at_first=lif_add_at_first,\n",
    "                #                     sae_l2_norm_bridge = sae_l2_norm_bridge, sae_lif_bridge = sae_lif_bridge, lif_add_at_last=lif_add_at_last, batch_norm_on=batch_norm_on, sae_relu_on=sae_relu_on).to(device)\n",
    "                # net = SAE_FUSION7_net_conv1(input_channels=input_channels, input_length=n_sample, encoder_ch = [32, 64, 96], fc_dim = lateral_feature_num, padding = 0, stride = 2, kernel_size = 3, \n",
    "                #                     synapse_fc_trace_const1=1, \n",
    "                #                     synapse_fc_trace_const2=v_decay, #안씀 \n",
    "                #                     TIME=TIME, v_init=0.0, v_decay=v_decay, v_threshold=v_threshold, v_reset=v_reset, \n",
    "                #                     sg_width=4.0, surrogate='sigmoid', BPTT_on=BPTT_on, need_bias=need_bias, lif_add_at_first=lif_add_at_first,\n",
    "                #                     sae_l2_norm_bridge = sae_l2_norm_bridge, sae_lif_bridge = sae_lif_bridge, lif_add_at_last=lif_add_at_last, batch_norm_on=batch_norm_on, sae_relu_on=sae_relu_on).to(device)\n",
    "            else:\n",
    "                net = SAE_conv1(input_channels=input_channels, input_length=n_sample, encoder_ch = [32, 64, 96], fc_dim = lateral_feature_num, padding = 0, stride = 2, kernel_size = 3, \n",
    "                                    synapse_fc_trace_const1=1, \n",
    "                                    synapse_fc_trace_const2=v_decay, #안씀 \n",
    "                                    TIME=TIME, v_init=0.0, v_decay=v_decay, v_threshold=v_threshold, v_reset=v_reset, \n",
    "                                    sg_width=4.0, surrogate='sigmoid', BPTT_on=BPTT_on, need_bias=need_bias, lif_add_at_first=lif_add_at_first,\n",
    "                                    sae_l2_norm_bridge = sae_l2_norm_bridge, sae_lif_bridge = sae_lif_bridge, lif_add_at_last=lif_add_at_last, batch_norm_on=batch_norm_on, sae_relu_on=sae_relu_on).to(device)\n",
    "            # net = SAE_conv1_DR(input_channels=input_channels, input_length=n_sample, encoder_ch = [32, 64, 96], fc_dim = lateral_feature_num, padding = 0, stride = 2, kernel_size = 3, \n",
    "            #                     synapse_fc_trace_const1=1, \n",
    "            #                     synapse_fc_trace_const2=v_decay, #안씀 \n",
    "            #                     TIME=TIME, v_init=0.0, v_decay=v_decay, v_threshold=v_threshold, v_reset=v_reset, \n",
    "            #                     sg_width=4.0, surrogate='sigmoid', BPTT_on=BPTT_on, need_bias=need_bias, lif_add_at_first=lif_add_at_first,\n",
    "            #                     sae_l2_norm_bridge = sae_l2_norm_bridge, sae_lif_bridge = sae_lif_bridge, lif_add_at_last=lif_add_at_last, batch_norm_on=batch_norm_on).to(device)\n",
    "            net = torch.nn.DataParallel(net)\n",
    "        else:\n",
    "            net = SAE_fc_only(encoder_ch=[400, lateral_feature_num], \n",
    "                                decoder_ch=[400, n_sample], \n",
    "                                in_channels=n_sample, # in_channel 이 여기선 걍 lenght.\n",
    "                                synapse_fc_trace_const1=1,\n",
    "                                synapse_fc_trace_const2=v_decay,  #안씀 \n",
    "                                TIME=TIME, v_init=0.0, v_decay=v_decay, v_threshold=v_threshold, v_reset=v_reset, \n",
    "                                sg_width=4.0, surrogate='sigmoid', BPTT_on=BPTT_on, need_bias=need_bias, lif_add_at_first=lif_add_at_first,\n",
    "                                sae_l2_norm_bridge = sae_l2_norm_bridge, sae_lif_bridge = sae_lif_bridge, lif_add_at_last=lif_add_at_last, batch_norm_on=batch_norm_on, sae_relu_on=sae_relu_on).to(device)\n",
    "            net = torch.nn.DataParallel(net)\n",
    "\n",
    "    # net = torch.load('/home/bhkim003/github_folder/ByeonghyeonKim/my_snn/net_save/save_now_net_AE_re_e7000.pth')\n",
    "    # net = torch.load('/home/bhkim003/github_folder/ByeonghyeonKim/my_snn/net_save/save_now_net_20250101_210938_786.pth')\n",
    "    # load했으면 torch.nn.DataParallel 하지마\n",
    "    # net.module.load_state_dict(torch.load('/home/bhkim003/github_folder/ByeonghyeonKim/my_snn/net_save/save_now_net_annbase_20250108_210641_941.pth'))\n",
    "    if pretrained_net != None:\n",
    "        ######################## 모델이 달라서 dict로 weight만 넣고싶을 때\n",
    "        # # 저장된 가중치 로드\n",
    "        saved_state_dict = torch.load(pretrained_net)\n",
    "        current_state_dict = net.module.state_dict()\n",
    "\n",
    "        # 함수 호출로 가중치 매핑\n",
    "        updated_state_dict = map_and_load_weights(saved_state_dict, current_state_dict)\n",
    "\n",
    "        # 업데이트된 state_dict를 네트워크에 로드\n",
    "        net.module.load_state_dict(updated_state_dict)\n",
    "        ######################## 모델이 달라서 dict로 weight만 넣고싶을 때\n",
    "\n",
    "        ############## 일반적일 때\n",
    "        # net.module.load_state_dict(torch.load(pretrained_net))\n",
    "        ############## 일반적일 때\n",
    "    \n",
    "        # pre_net = Autoencoder_conv1(input_channels=input_channels, input_length=n_sample, encoder_ch = [32, 64, 96], fc_dim = lateral_feature_num, padding = 0, stride = 2, kernel_size = 3, need_bias=need_bias, l2norm_bridge=sae_l2_norm_bridge, relu_bridge=sae_lif_bridge, activation_collector_on=False,\n",
    "        #                         batch_norm_on=batch_norm_on, QCFS_neuron_on=False).to(device)\n",
    "        # pre_net = torch.nn.DataParallel(net)\n",
    "        # pre_net.module.load_state_dict(torch.load(pretrained_net))\n",
    "        # copy_weights(pre_net.module.encoder , net.module.encoder )\n",
    "        # copy_weights(pre_net.module.decoder , net.module.decoder  )\n",
    "\n",
    "        \n",
    "\n",
    "\n",
    "\n",
    "    wandb.watch(net, log=\"all\", log_freq = 10)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    if SAE_net == True:\n",
    "        assert 'SAE' in net.module.__class__.__name__\n",
    "\n",
    "\n",
    "\n",
    "    net = net.to(device)\n",
    "    print(f\"Total number of encoder parameters: {sum(p.numel() for p in net.module.encoder.parameters())}\")\n",
    "    print(net)\n",
    "    print('Device:',device)\n",
    "\n",
    "    \n",
    "    if optimizer == 'Adam':\n",
    "        optimizer = optim.Adam(net.parameters(), lr=learning_rate)\n",
    "    elif optimizer == 'SGD':\n",
    "        optimizer = optim.SGD(net.parameters(), lr = learning_rate, momentum = 0.9)\n",
    "    else:\n",
    "        assert False, 'optimizer를 잘못 입력했습니다.'\n",
    "        \n",
    "    loss_history = []\n",
    "    mean_cluster_accuracy_during_training_cycle_all_dataset_history = []\n",
    "    mean_cluster_accuracy_post_training_cycle_all_dataset_history = []\n",
    "    mean_cluster_accuracy_total_all_dataset_history = []\n",
    "\n",
    "    tau = np.zeros(num_cluster)\n",
    "\n",
    "    print(f\"\\nStart Training, current_time = {current_time}\")\n",
    "    mean_cluster_accuracy_post_training_cycle_all_dataset = 0\n",
    "    best_mean_cluster_accuracy_post_training_cycle_all_dataset = 0\n",
    "\n",
    "    if SAE_net == True:\n",
    "        assert 'SAE' in net.module.__class__.__name__\n",
    "        \n",
    "    k_means_acc_best = 0\n",
    "    min_loss = 9999999\n",
    "    min_loss_normal = 9999999\n",
    "    min_loss_coarse = 9999999\n",
    "    for epoch in range(max_epoch):\n",
    "        print()\n",
    "        l2_loss_bin= 0\n",
    "        ae_train_start_time = time.time()\n",
    "        running_loss = 0.0\n",
    "        running_loss_normal = 0.0\n",
    "        running_loss_coarse = 0.0\n",
    "        iter = 0\n",
    "        net.train()\n",
    "        # if True or max_epoch != 1:\n",
    "        wrong_element_sum = 0\n",
    "        same_data_num = 0\n",
    "        total_data_num = 0\n",
    "        if max_epoch != 1:\n",
    "            for data in train_loader:\n",
    "                optimizer.zero_grad()\n",
    "                total_data_num += len(data)\n",
    "                data = data.to(device)\n",
    "                scaling = (level_num-3)/level_num if conv1d_scaling else 1.0\n",
    "                data = zero_to_one_normalize_features(data, level_num=quantize_level_num, coarse_com_config=coarse_com_config, scaling=scaling, norm01=norm01) if normalize_on else data\n",
    "                # plot_origin_spike(data[0].cpu().detach().numpy(), min_max_y_on = True)\n",
    "                # plot_origin_spike(data[1].cpu().detach().numpy(), min_max_y_on = True)\n",
    "                spike_backup = data\n",
    "                spike = data\n",
    "                spike = spike.to(device) # batch, feature\n",
    "                spike_for_fusion2_net = spike\n",
    "                if coarse_com_mode == True and 'SAE' in net.module.__class__.__name__:\n",
    "                    # print(spike[0])\n",
    "                    spike = spike.unsqueeze(2).repeat(1, 1, level_num) # spike_length == level_num # (batch, time, feature)로 변환 \n",
    "                    spike = (spike > levels).to(torch.float) \n",
    "\n",
    "                    spike = (spike == 0).cumsum(dim=-1).eq(1).to(torch.float) if lc_adc_on == True else spike\n",
    "\n",
    "                    # spike: batch, time, level_num\n",
    "                    # levels: time, level_num\n",
    "                    if Conv_net == True:\n",
    "                        spike = spike.unsqueeze(-2) # batch, time, in_channel, feature or batch in_channel,feature\n",
    "                        if two_channel_input == True:\n",
    "                            spike_backup = spike_backup.to(device)\n",
    "                            spike_backup = spike_backup.unsqueeze(2).repeat(1, 1, level_num) # spike_length == level_num # (batch, time, feature)로 변환 \n",
    "                            spike_backup = (spike_backup <= levels).to(torch.float) \n",
    "                            spike_backup = (spike_backup == 1).cumsum(dim=-1).eq(1).to(torch.float) if lc_adc_on == True else spike_backup\n",
    "                            spike_backup = spike_backup.unsqueeze(-2)\n",
    "                            spike = torch.cat((spike, spike_backup), dim=-2)\n",
    "                    assert spike.shape[0] == batch_size and spike.shape[1] == TIME\n",
    "                elif 'SAE' in net.module.__class__.__name__:\n",
    "                    spike = spike.unsqueeze(-1).repeat(1, 1, TIME).permute(0,2,1) # (batch, time, feature)로 변환\n",
    "                    if Conv_net == True:\n",
    "                        spike = spike.unsqueeze(-2) # batch, time, in_channel, feature or batch in_channel,feature\n",
    "                else:\n",
    "                    if Conv_net == True:\n",
    "                        if coarse_com_mode == False:\n",
    "                            spike = spike.unsqueeze(-2) #batch in_channel,feature\n",
    "                        else:\n",
    "                            spike = spike.unsqueeze(2).repeat(1, 1, level_num) # spike_length == level_num # (batch, time, feature)로 변환 \n",
    "                            spike = (spike > levels).to(torch.float) \n",
    "\n",
    "                            spike = (spike == 0).cumsum(dim=-1).eq(1).to(torch.float) if lc_adc_on == True else spike\n",
    "\n",
    "                    else:\n",
    "                        if coarse_com_mode == False:\n",
    "                            pass\n",
    "                        else:\n",
    "                            spike = spike.unsqueeze(2).repeat(1, 1, level_num) # spike_length == level_num # (batch, time, feature)로 변환 \n",
    "                            spike = (spike > levels).to(torch.float) \n",
    "\n",
    "                            spike = (spike == 0).cumsum(dim=-1).eq(1).to(torch.float) if lc_adc_on == True else spike\n",
    "\n",
    "                            # spike: batch, time, feature\n",
    "                            spike = spike.reshape(spike.shape[0], -1)\n",
    "\n",
    "                    \n",
    "\n",
    "\n",
    "                    # if fusion_net == True:\n",
    "                    #     spike = spikegen.rate(spike, num_steps=TIME).transpose(0, 1)\n",
    "\n",
    "                # spike_class = net(spike) # batch, time, feature\n",
    "                encoded_spike = net.module.encoder(spike)\n",
    "                spike_class = net.module.decoder(encoded_spike)\n",
    "                \n",
    "                print(spike_class)\n",
    "                # # 각 레이어의 weight와 bias의 비트 수 출력\n",
    "                # print(\"\\n=== Encoder & Decoder Weight/Bias Bit Size ===\")\n",
    "                # for name, param in net.module.named_parameters():\n",
    "                #     bit_size = param.element_size() * 8  # 바이트 크기에 8을 곱하여 비트 수 계산\n",
    "                #     print(f\"{name}: {bit_size} bits ({param.dtype})\")\n",
    "\n",
    "\n",
    "                # print('encoded_spike', spike_class)\n",
    "\n",
    "                # for i in range (2):\n",
    "                #     plot_spike(spike[i,:,0,:].cpu().numpy())\n",
    "                #     # plot_spike(spike[i,:,1,:].cpu().numpy())\n",
    "                #     plot_origin_spike(spike_class.squeeze()[i].cpu().detach().numpy(), min_max_y_on = True)\n",
    "                # assert False\n",
    "                        \n",
    "\n",
    "                loss = 0\n",
    "                loss_normal = torch.tensor(0.0)\n",
    "                loss_coarse = torch.tensor(0.0)\n",
    "                if coarse_com_mode == True and 'SAE' in net.module.__class__.__name__:\n",
    "                    criterion = nn.MSELoss().to(device)\n",
    "                    # loss1 = nn.MSELoss()(spike_class[..., 5:25], spike[..., 5:25])\n",
    "                    # loss2 = nn.MSELoss()(spike_class[..., 0:5], spike[..., 0:5])\n",
    "                    # loss3 = nn.MSELoss()(spike_class[..., 25:spike_length], spike[..., 25:spike_length])\n",
    "                    # loss = loss1 * chan_loss_factor*2.125 + (loss2 + loss3) *(1/chan_loss_factor)/ 4 \n",
    "\n",
    "                    # loss1 = nn.MSELoss()(spike_class[..., 5:25, :], spike[..., 5:25, :])\n",
    "                    # loss2 = nn.MSELoss()(spike_class[..., 0:5, :], spike[..., 0:5, :])\n",
    "                    # loss3 = nn.MSELoss()(spike_class[..., 25:spike_length, :], spike[..., 25:spike_length, :])\n",
    "                    # loss = loss1 * chan_loss_factor*2.125 + (loss2 + loss3) *(1/chan_loss_factor)/ 4 \n",
    "                    if fusion_net:\n",
    "                        # print('1', spike.shape) # batch, time, in_channel, feature [32, 50, 1, 50]\n",
    "                        \n",
    "                        # ### coarse에서 ann loss 만들기 ######\n",
    "                        # spike = spike.squeeze()\n",
    "                        # assert two_channel_input == False\n",
    "                        # zero_mask = (spike == 0)  # 0이 있는 위치\n",
    "                        # first_zero_idx = torch.where(zero_mask, torch.arange(spike.shape[-1]).to(device), spike.shape[-1]-1).min(dim=-1).values\n",
    "                        # spike = levels[0][first_zero_idx]\n",
    "                        # # plot_origin_spike(spike[0].cpu().detach().numpy())\n",
    "                        # ### coarse에서 ann loss 만들기 ######\n",
    "\n",
    "                        ### 그냥 원래 스파이크로 ann loss 만들기 ######\n",
    "                        spike = spike_for_fusion2_net\n",
    "                        ### 그냥 원래 스파이크로 ann loss 만들기 ######\n",
    "\n",
    "                        spike = spike.squeeze()\n",
    "                        spike_class = spike_class.squeeze()\n",
    "                        \n",
    "                        ### normal loss################\n",
    "                        # loss = criterion(spike_class, spike)\n",
    "                        ### normal loss################\n",
    "                        \n",
    "                        ### chan loss################\n",
    "                        loss1 = criterion(spike_class[..., 5:25], spike[..., 5:25])\n",
    "                        loss2 = criterion(spike_class[..., 0:5], spike[..., 0:5])\n",
    "                        loss3 = criterion(spike_class[..., 25:], spike[..., 25:])\n",
    "                        loss = loss1 * chan_loss_factor*2.125 + (loss2 + loss3) *(1/chan_loss_factor)/ 4 \n",
    "                        ### chan loss################\n",
    "\n",
    "\n",
    "                        # #########################################\n",
    "                        # # 손실 함수 정의 (예: MSELoss 사용)\n",
    "                        # criterion_joke = torch.nn.MSELoss(reduction='none')  # 개별 요소별 손실을 유지\n",
    "\n",
    "                        # # 손실 계산\n",
    "                        # loss1_joke = criterion_joke(spike_class[..., 5:25], spike[..., 5:25]).mean(dim=-1)  # (batch,)\n",
    "                        # loss2_joke = criterion_joke(spike_class[..., 0:5], spike[..., 0:5]).mean(dim=-1)    # (batch,)\n",
    "                        # loss3_joke = criterion_joke(spike_class[..., 25:], spike[..., 25:]).mean(dim=-1)    # (batch,)\n",
    "\n",
    "                        # # 주어진 가중치를 적용한 최종 손실\n",
    "                        # loss_joke = loss1_joke * chan_loss_factor*2.125 + (loss2_joke + loss3_joke) *(1/chan_loss_factor)/ 4 \n",
    "\n",
    "                        # # 가장 큰 손실을 갖는 샘플의 인덱스 찾기\n",
    "                        # max_loss_idx_joke = torch.argmax(loss_joke)\n",
    "\n",
    "                        # # 해당 샘플 선택\n",
    "                        # selected_sample_class = spike_class[max_loss_idx_joke]\n",
    "                        # selected_sample_spike = spike[max_loss_idx_joke]\n",
    "\n",
    "                        # # 선택한 샘플의 손실 값 출력\n",
    "                        # print(\"Index of max loss sample:\", max_loss_idx_joke.item())\n",
    "                        # print(\"Max loss value:\", loss_joke[max_loss_idx_joke].item())\n",
    "                        # mean_loss_joke = loss_joke.mean().item()\n",
    "                        # print(\"Mean loss across the batch:\", mean_loss_joke)\n",
    "\n",
    "                        # # 선택한 샘플을 시각화\n",
    "                        # plot_origin_spike(selected_sample_class.cpu().detach().numpy())\n",
    "                        # plot_origin_spike(selected_sample_spike.cpu().detach().numpy())\n",
    "                        # #########################################\n",
    "\n",
    "                        # coarse loss ######################################################\n",
    "                        loss_normal = criterion(spike_class, spike)\n",
    "                        level_num_in_loss = spike_length\n",
    "                        level_interval = (coarse_com_config[0] - coarse_com_config[1]) / (level_num_in_loss-1)  # max - min\n",
    "                        levels = [coarse_com_config[1] + level_interval * i for i in range(level_num_in_loss)]\n",
    "                        levels = torch.tensor(levels).to(torch.float).to(device)\n",
    "                        # print('coarse leves', levels)\n",
    "                        levels = levels.repeat(spike_length,1) \n",
    "\n",
    "                        spike = spike.squeeze()\n",
    "                        spike_class = spike_class.squeeze()\n",
    "                        # plot_origin_spike(spike_class[0].cpu().detach().numpy())\n",
    "                        spike = spike.unsqueeze(2).repeat(1, 1, level_num_in_loss) \n",
    "                        spike = (spike > levels).to(torch.float) \n",
    "                        spike_class = spike_class.unsqueeze(2).repeat(1, 1, level_num_in_loss) \n",
    "                        spike_class = (spike_class > levels).to(torch.float) \n",
    "                        # spike = spike[..., 0:-3, :]\n",
    "                        # spike_class = spike_class[..., 0:-3, :]\n",
    "                        loss_coarse = criterion(spike_class, spike)\n",
    "                        wrong_element_sum += torch.sum(torch.abs(spike - spike_class)).item() \n",
    "\n",
    "                        # plot_spike(spike_class[0].cpu().detach().numpy())\n",
    "                        # assert False\n",
    "                        # coarse loss ######################################################\n",
    "                    else:\n",
    "                        spike = spike.squeeze()\n",
    "                        spike_class = spike_class.squeeze()\n",
    "                        loss = criterion(spike_class, spike)\n",
    "\n",
    "                    for iii in range(spike.shape[0]):\n",
    "                        same_data_num = same_data_num + 1 if torch.eq(spike[iii], spike_class[iii]).all() else same_data_num\n",
    "                    wrong_element_sum += torch.sum(torch.abs(spike - spike_class)).item() \n",
    "\n",
    "                    # spike = spike.squeeze()\n",
    "                    # spike_class = spike_class.squeeze()\n",
    "                    # plot_spike(spike[0].cpu().detach().numpy())\n",
    "                    # plot_spike(spike_class[0].cpu().detach().numpy())\n",
    "                    # print('손실 절대값 합',np.sum(np.abs(spike[0].cpu().detach().numpy() - spike_class[0].cpu().detach().numpy())))\n",
    "                    # # assert False\n",
    "                elif 'SAE' in net.module.__class__.__name__:\n",
    "                    criterion = nn.MSELoss().to(device)\n",
    "                    loss1 = criterion(spike_class[..., 5:25], spike[..., 5:25])\n",
    "                    loss2 = criterion(spike_class[..., 0:5], spike[..., 0:5])\n",
    "                    loss3 = criterion(spike_class[..., 25:spike_length], spike[..., 25:spike_length])\n",
    "                    # loss = loss1 * 2.125 + (loss2 + loss3)/4 # chan_loss_factor = 1\n",
    "                    loss = loss1 * chan_loss_factor*2.125 + (loss2 + loss3) *(1/chan_loss_factor)/ 4 \n",
    "                    assert spike_length > 25, 'spike_length가 25보다 작음'\n",
    "                    # wrong_element_sum += torch.sum(torch.abs(spike - spike_class)).item() \n",
    "                else:\n",
    "                    criterion = nn.MSELoss().to(device)\n",
    "                    loss1 = criterion(spike_class[..., 5:25], spike[..., 5:25])\n",
    "                    loss2 = criterion(spike_class[..., 0:5], spike[..., 0:5])\n",
    "                    loss3 = criterion(spike_class[..., 25:spike_length], spike[..., 25:spike_length])\n",
    "                    loss = loss1 * chan_loss_factor*2.125 + (loss2 + loss3) *(1/chan_loss_factor)/ 4 \n",
    "                    assert spike_length > 25, 'spike_length가 25보다 작음'\n",
    "                    # wrong_element_sum += torch.sum(torch.abs(spike - spike_class)).item() \n",
    "\n",
    "\n",
    "                    if l2_norm_loss_weight > 0:\n",
    "                        assert len(encoded_spike.shape) == 2, 'time 성분 없는 걸로'\n",
    "                        l2_loss = l2_norm_loss(encoded_spike, target_norm=1.0)  # L2Norm Loss 계산, l2 1.0되게.\n",
    "                        loss = loss + l2_loss*l2_norm_loss_weight\n",
    "                        l2_loss_bin += l2_loss.item()\n",
    "\n",
    "                    # coarse loss ######################################################\n",
    "                    loss_normal = criterion(spike_class, spike)\n",
    "                    level_num_in_loss = quantize_level_num\n",
    "                    level_interval = (coarse_com_config[0] - coarse_com_config[1]) / (level_num_in_loss-1)  # max - min\n",
    "                    levels = [coarse_com_config[1] + level_interval * i for i in range(level_num_in_loss)]\n",
    "                    levels = torch.tensor(levels).to(torch.float).to(device)\n",
    "                    levels = levels.repeat(spike_length,1) \n",
    "\n",
    "                    spike = spike.squeeze()\n",
    "                    spike_class = spike_class.squeeze()\n",
    "                    # plot_origin_spike(spike_class[0].cpu().detach().numpy())\n",
    "                    spike = spike.unsqueeze(2).repeat(1, 1, level_num_in_loss) \n",
    "                    spike = (spike > levels).to(torch.float) \n",
    "                    spike_class = spike_class.unsqueeze(2).repeat(1, 1, level_num_in_loss) \n",
    "                    spike_class = (spike_class > levels).to(torch.float) \n",
    "                    # spike = spike[..., 0:-3, :]\n",
    "                    # spike_class = spike_class[..., 0:-3, :]\n",
    "                    loss_coarse = criterion(spike_class, spike)\n",
    "                    wrong_element_sum += torch.sum(torch.abs(spike - spike_class)).item() \n",
    "\n",
    "                    # plot_spike(spike_class[0].cpu().detach().numpy())\n",
    "                    # assert False\n",
    "                    # coarse loss ######################################################\n",
    "\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                running_loss += loss.item()\n",
    "                running_loss_normal += loss_normal.item()\n",
    "                running_loss_coarse += loss_coarse.item()\n",
    "                # print(f'\\nepoch-{epoch}, running_loss : {running_loss:.5f}, iter percent {iter/len(train_loader)*100:.2f}%')\n",
    "                iter += 1\n",
    "        else:\n",
    "            print('\\n\\n\\n max_epoch 1이면 Train 안함!!!!!!!!!!!!!!!!!!!!!')\n",
    "        if l2_norm_loss_weight > 0:\n",
    "            print('l2_loss_bin', l2_loss_bin/len(train_loader))\n",
    "        avg_loss = running_loss / len(train_loader)\n",
    "        assert not np.isnan(avg_loss), f\"Error: avg_loss is NaN! Running loss: {running_loss}, Length of train_loader: {len(train_loader)}\"\n",
    "        loss_history.append((epoch, avg_loss))\n",
    "        min_loss = min(min_loss, avg_loss)\n",
    "        min_loss_normal = min(min_loss_normal, running_loss_normal/len(train_loader))\n",
    "        min_loss_coarse = min(min_loss_coarse, running_loss_coarse/len(train_loader))\n",
    "        print(f'\\nepoch-{epoch} loss : {avg_loss:.8f}, loss_normal : {running_loss_normal/len(train_loader):.8f}, loss_coarse : {running_loss_coarse/len(train_loader):.8f}, min_loss : {min_loss:.8f}, min_loss_normal : {min_loss_normal:.8f}, min_loss_coarse : {min_loss_coarse:.8f}, wrong_element_sum : {wrong_element_sum:.8f}, same_data : {100*same_data_num/(total_data_num+1e-12):.2f}%')\n",
    "        print(f\"ae train 실행 시간: {time.time()-ae_train_start_time:.3f}초, 전체 시작 시간 {current_time}\")\n",
    "\n",
    "        # plot_activation_distribution(net)\n",
    "\n",
    "        if SAE_net == False and converted_net_forward == True:\n",
    "            source_encoder = net.module.encoder \n",
    "            target_encoder = converted_net.module.encoder  \n",
    "            copy_weights(source_encoder, target_encoder)\n",
    "\n",
    "        cluster_accuracy_during_training_cycle_all_dataset = np.zeros(dataset_num)\n",
    "        cluster_accuracy_post_training_cycle_all_dataset = np.zeros(dataset_num)\n",
    "        cluster_accuracy_total_all_dataset = np.zeros(dataset_num)    \n",
    "\n",
    "        k_means_acc = 0\n",
    "        converted_k_means_acc = 0\n",
    "        if(epoch % accuracy_check_epoch_term == 0 or epoch == 1 or epoch == max_epoch-1): \n",
    "            accuracy_check_start_time = time.time()\n",
    "            print(f'\\nepoch-{epoch} accuracy check')\n",
    "            k_means_bin_origin_feature = []\n",
    "            k_means_bin = []\n",
    "            converted_k_means_bin = []\n",
    "            dtw_accuracy_mean = 0\n",
    "            for ds in range(dataset_num):\n",
    "                # print('\\n', spike_tot[ds])\n",
    "\n",
    "                spike_template = np.load(my_path_ground_BH + template[ds])\n",
    "                spike = np.load(my_path_ground_BH + spike_tot[ds])\n",
    "                label = np.load(my_path_ground_BH + label_tot[ds])\n",
    "                spike_template = torch.from_numpy(spike_template).to(device)\n",
    "                spike = torch.from_numpy(spike).to(device)\n",
    "                scaling = (level_num-3)/level_num if conv1d_scaling else 1.0\n",
    "                spike_template = zero_to_one_normalize_features(spike_template, level_num=quantize_level_num, coarse_com_config=coarse_com_config, scaling=scaling, norm01=norm01) if normalize_on else spike_template\n",
    "                spike = zero_to_one_normalize_features(spike, level_num=quantize_level_num, coarse_com_config=coarse_com_config, scaling=scaling, norm01=norm01) if normalize_on else spike\n",
    "                \n",
    "                hidden_size = lateral_feature_num*TIME if 'SAE' in net.module.__class__.__name__ and SAE_hidden_nomean == True and fusion_net == False or 'SAE_FUSION5' in net.module.__class__.__name__ else lateral_feature_num\n",
    "                hidden_size = lateral_feature_num if '_DR' in net.module.__class__.__name__  else hidden_size\n",
    "\n",
    "                Cluster = np.zeros((num_cluster, hidden_size))\n",
    "                assert Cluster.shape[-1] == hidden_size, '이거 hidden dim 4 아니게 할 거면 잘 바꿔라'\n",
    "                \n",
    "\n",
    "\n",
    "                net.eval()\n",
    "                with torch.no_grad():\n",
    "                    spike_torch = spike_template.float()\n",
    "                    spike_torch = spike_torch[:num_cluster]\n",
    "                    spike_backup = spike_torch\n",
    "                    spike_torch = spike_torch.to(device)\n",
    "                    if coarse_com_mode == True and 'SAE' in net.module.__class__.__name__:\n",
    "                        spike_torch = spike_torch.unsqueeze(2).repeat(1, 1, level_num) # spike_length == level_num # (batch, time, feature)로 변환 \n",
    "                        spike_torch = (spike_torch > levels).to(torch.float) \n",
    "                        spike_torch = (spike_torch == 0).cumsum(dim=-1).eq(1).to(torch.float) if lc_adc_on == True else spike_torch\n",
    "                        if Conv_net == True:\n",
    "                            spike_torch = spike_torch.unsqueeze(-2) # batch, time, in_channel, feature or batch in_channel,feature\n",
    "                            if two_channel_input == True:\n",
    "                                spike_backup = spike_backup.to(device)\n",
    "                                spike_backup = spike_backup.unsqueeze(2).repeat(1, 1, level_num) # spike_length == level_num # (batch, time, feature)로 변환 \n",
    "                                spike_backup = (spike_backup <= levels).to(torch.float) \n",
    "                                spike_backup = (spike_backup == 1).cumsum(dim=-1).eq(1).to(torch.float) if lc_adc_on == True else spike_backup\n",
    "                                spike_backup = spike_backup.unsqueeze(-2) # batch, time, in_channel, feature\n",
    "                                spike_torch = torch.cat((spike_torch, spike_backup), dim=-2)\n",
    "                    elif 'SAE' in net.module.__class__.__name__:\n",
    "                        spike_torch = spike_torch.unsqueeze(1).repeat(1, TIME, 1) # (batch, time, feature)로 변환\n",
    "                        if Conv_net == True:\n",
    "                            spike_torch = spike_torch.unsqueeze(-2) # batch, time, in_channel, feature or batch in_channel,feature\n",
    "                    else:\n",
    "                        # if Conv_net == True:\n",
    "                        #     spike_torch = spike_torch.unsqueeze(-2) #batch in_channel,feature\n",
    "                        if Conv_net == True:\n",
    "                            if coarse_com_mode == False:\n",
    "                                spike_torch = spike_torch.unsqueeze(-2) #batch in_channel,feature\n",
    "                            else:\n",
    "                                spike_torch = spike_torch.unsqueeze(2).repeat(1, 1, level_num) # spike_length == level_num # (batch, time, feature)로 변환 \n",
    "                                spike_torch = (spike_torch > levels).to(torch.float) \n",
    "\n",
    "                                spike_torch = (spike_torch == 0).cumsum(dim=-1).eq(1).to(torch.float) if lc_adc_on == True else spike_torch\n",
    "\n",
    "                        else:\n",
    "                            if coarse_com_mode == False:\n",
    "                                pass\n",
    "                            else:\n",
    "                                spike_torch = spike_torch.unsqueeze(2).repeat(1, 1, level_num) # spike_length == level_num # (batch, time, feature)로 변환 \n",
    "                                spike_torch = (spike_torch > levels).to(torch.float) \n",
    "\n",
    "                                spike_torch = (spike_torch == 0).cumsum(dim=-1).eq(1).to(torch.float) if lc_adc_on == True else spike_torch\n",
    "\n",
    "                                # spike: batch, time, feature\n",
    "                                spike_torch = spike_torch.reshape(spike_torch.shape[0], -1)\n",
    "\n",
    "                        if converted_net_forward == True:\n",
    "                            spike_torch_spikegen = spikegen.rate(spike_torch, num_steps=TIME).transpose(0, 1)\n",
    "                        # if fusion_net == True:\n",
    "                        #     spike_torch = spikegen.rate(spike_torch, num_steps=TIME).transpose(0, 1)\n",
    "                    ### forward #######################################################\n",
    "                    inner_inf = net.module.encoder(spike_torch)\n",
    "                    if SAE_net == False and converted_net_forward == True:\n",
    "                        converted_inner_inf = converted_net.module.encoder(spike_torch_spikegen)\n",
    "                    ### forward #######################################################\n",
    "\n",
    "                    # if ds % 4 == 0:\n",
    "                    #     for i in range(4):\n",
    "                    #         decoded = net.module.decoder(inner_inf).squeeze()\n",
    "                    #         plot_spike(spike_torch[i,:,:].cpu().numpy())\n",
    "                    #         plot_spike(inner_inf[i,:].cpu().numpy())\n",
    "                    #         # plot_origin_spike(net.module.decoder(inner_inf)[i,:].cpu().numpy())\n",
    "                    #         plot_origin_spike(decoded[i].cpu().numpy(), min_max_y_on = True)\n",
    "                        \n",
    "                    # if 'SAE' in net.module.__class__.__name__:\n",
    "                    #     tensors = [inner_inf[0][i] for i in range(TIME)] \n",
    "                    #     all_equal = all(torch.equal(tensors[0], t) for t in tensors)\n",
    "                    #     print(all_equal, inner_inf)\n",
    "\n",
    "                    if 'SAE' in net.module.__class__.__name__:\n",
    "                        if SAE_hidden_nomean == True:\n",
    "                            inner_inf = inner_inf.reshape(inner_inf.shape[0],-1)# time*feature 펼치기\n",
    "                        else:\n",
    "                            inner_inf = inner_inf.mean(dim=1)# Time 방향으로 평균\n",
    "                        # inner_inf = F.normalize(inner_inf, p=2, dim=1)\n",
    "                    Cluster = inner_inf.cpu().detach().numpy()\n",
    "\n",
    "                encoder_batch = 128\n",
    "                spike_hidden = np.zeros((len(spike), hidden_size))\n",
    "                converted_spike_hidden = np.zeros((len(spike), hidden_size))\n",
    "                net.eval()\n",
    "                with torch.no_grad():\n",
    "                    now_index = 0\n",
    "                    while (1):\n",
    "                        now_end_index = now_index+encoder_batch if now_index+encoder_batch < len(spike) else len(spike)\n",
    "                        spike_batch = spike[now_index:now_end_index] \n",
    "                        spike_torch = spike_batch\n",
    "                        spike_torch = spike_torch.float()\n",
    "                        spike_backup = spike_torch\n",
    "                        spike_torch = spike_torch.to(device)\n",
    "                        if coarse_com_mode == True and 'SAE' in net.module.__class__.__name__:\n",
    "                            spike_torch = spike_torch.unsqueeze(2).repeat(1, 1, level_num) # spike_length == level_num # (batch, time, feature)로 변환 \n",
    "                            spike_torch = (spike_torch > levels).to(torch.float) \n",
    "                            spike_torch = (spike_torch == 0).cumsum(dim=-1).eq(1).to(torch.float) if lc_adc_on == True else spike_torch\n",
    "                            if Conv_net == True:\n",
    "                                spike_torch = spike_torch.unsqueeze(-2) # batch, time, in_channel, feature or batch in_channel,feature\n",
    "                                if two_channel_input == True:\n",
    "                                    spike_backup = spike_backup.to(device)\n",
    "                                    spike_backup = spike_backup.unsqueeze(2).repeat(1, 1, level_num) # spike_length == level_num # (batch, time, feature)로 변환 \n",
    "                                    spike_backup = (spike_backup <= levels).to(torch.float) \n",
    "                                    spike_backup = (spike_backup == 1).cumsum(dim=-1).eq(1).to(torch.float) if lc_adc_on == True else spike_backup\n",
    "                                    spike_backup = spike_backup.unsqueeze(-2)\n",
    "                                    spike_torch = torch.cat((spike_torch, spike_backup), dim=-2)\n",
    "                        elif 'SAE' in net.module.__class__.__name__:\n",
    "                            spike_torch = spike_torch.unsqueeze(1).repeat(1, TIME, 1) # (batch, time, feature)로 변환\n",
    "                            if Conv_net == True:\n",
    "                                spike_torch = spike_torch.unsqueeze(-2) # batch, time, in_channel, feature or batch in_channel,feature\n",
    "                        else:\n",
    "                            # if Conv_net == True:\n",
    "                            #     spike_torch = spike_torch.unsqueeze(-2) #batch in_channel,feature\n",
    "                            if Conv_net == True:\n",
    "                                if coarse_com_mode == False:\n",
    "                                    spike_torch = spike_torch.unsqueeze(-2) #batch in_channel,feature\n",
    "                                else:\n",
    "                                    spike_torch = spike_torch.unsqueeze(2).repeat(1, 1, level_num) # spike_length == level_num # (batch, time, feature)로 변환 \n",
    "                                    spike_torch = (spike_torch > levels).to(torch.float) \n",
    "\n",
    "                                    spike_torch = (spike_torch == 0).cumsum(dim=-1).eq(1).to(torch.float) if lc_adc_on == True else spike_torch\n",
    "\n",
    "                            else:\n",
    "                                if coarse_com_mode == False:\n",
    "                                    pass\n",
    "                                else:\n",
    "                                    spike_torch = spike_torch.unsqueeze(2).repeat(1, 1, level_num) # spike_length == level_num # (batch, time, feature)로 변환 \n",
    "                                    spike_torch = (spike_torch > levels).to(torch.float) \n",
    "\n",
    "                                    spike_torch = (spike_torch == 0).cumsum(dim=-1).eq(1).to(torch.float) if lc_adc_on == True else spike_torch\n",
    "\n",
    "                                    # spike: batch, time, feature\n",
    "                                    spike_torch = spike_torch.reshape(spike_torch.shape[0], -1)\n",
    "                            if converted_net_forward == True:\n",
    "                                spike_torch_spikegen = spikegen.rate(spike_torch, num_steps=TIME).transpose(0, 1)\n",
    "                            # if fusion_net == True:\n",
    "                            #     spike_torch = spikegen.rate(spike_torch, num_steps=TIME).transpose(0, 1)\n",
    "                        ### forward #######################################################\n",
    "                        inner_inf = net.module.encoder(spike_torch)\n",
    "                        if SAE_net == False and converted_net_forward == True:\n",
    "                            converted_inner_inf = converted_net.module.encoder(spike_torch_spikegen)\n",
    "                        ### forward #######################################################\n",
    "                            \n",
    "                        if 'SAE' in net.module.__class__.__name__:\n",
    "                            if SAE_hidden_nomean == True:\n",
    "                                inner_inf = inner_inf.reshape(spike_batch.shape[0],-1)# 펼치기\n",
    "                            else:\n",
    "                                inner_inf = inner_inf.mean(dim=1)# Time 방향으로 평균\n",
    "                            # inner_inf = F.normalize(inner_inf, p=2, dim=1)\n",
    "                        spike_hidden[now_index:now_end_index] = inner_inf.cpu().detach().numpy()\n",
    "                        if SAE_net == False and converted_net_forward == True:\n",
    "                            converted_spike_hidden[now_index:now_end_index] = converted_inner_inf.cpu().detach().numpy()\n",
    "                        now_index += encoder_batch\n",
    "                        if (now_index >= len(spike)):\n",
    "                            break\n",
    "                    \n",
    "                spike_id = np.zeros(len(spike))\n",
    "                distance_sm = np.zeros(num_cluster)\n",
    "                tau = np.zeros(num_cluster)\n",
    "                \n",
    "                plot_tau = []\n",
    "                plot_denominator = []\n",
    "                plot_m = []\n",
    "                plot_max_tau = []\n",
    "                for spike_index in range(len(spike)): \n",
    "                    for q in range(num_cluster):\n",
    "                        tau[q] = np.dot(spike_hidden[spike_index, :], Cluster[q, :]) # 이거 l2norm 거쳐서 나온 거니까 분모 1임.\n",
    "                        denominator =  np.linalg.norm(spike_hidden[spike_index, :])*np.linalg.norm(Cluster[q, :]) + 1e-12\n",
    "                        plot_denominator.append(denominator)\n",
    "                        if 'SAE' in net.module.__class__.__name__: # AE 때는 l2norm거쳐서 나와서 괜찮음\n",
    "                            tau[q] = tau[q] / denominator\n",
    "\n",
    "                        plot_tau.append(tau[q])\n",
    "\n",
    "                    # for i in range(num_cluster): # l2 distance\n",
    "                    #     distance_sm[i] = np.sum(np.power(np.abs(Cluster[i] - spike_hidden[spike_index, :]), 2))\n",
    "                    distance_sm = np.sum(np.power(np.abs(Cluster - spike_hidden[spike_index, :]), 2), axis=1)\n",
    "\n",
    "                    m = np.argmin(distance_sm)\n",
    "                    plot_m.append(m)\n",
    "                    spike_id[spike_index] = m + 1\n",
    "                    # print(spike_tot[ds], spike_index,np.max(tau))\n",
    "                    plot_max_tau.append(np.max(tau))\n",
    "                    if(np.max(tau) >= cos_thr[ds] and spike_index < training_cycle): # 원래 1400 아니냐?\n",
    "                        Cluster[m] = (Cluster[m] * 15 + spike_hidden[spike_index, :])/16\n",
    "\n",
    "\n",
    "                \n",
    "                origin_kmeans_accuracy = cluster_spikes_with_accuracy_torch(features= spike, true_labels=label-1, n_clusters=3, init_point=None)\n",
    "                kmeans_accuracy = cluster_spikes_with_accuracy_torch(features= torch.tensor(spike_hidden).to(device), true_labels=label-1, n_clusters=3, init_point=None)\n",
    "                \n",
    "                # ## dtw accruacy #######################################################\n",
    "                # mola = spike_hidden.reshape(spike_hidden.shape[0], TIME, -1)\n",
    "                # # print(mola.shape)\n",
    "                # result = evaluate_clustering_accuracy(mola, label-1, n_clusters=3)\n",
    "                # print('그냥 kmeans', kmeans_accuracy, 'dtw', result[\"DTW Clustering Accuracy\"])\n",
    "                # dtw_accuracy_mean += result[\"DTW Clustering Accuracy\"]\n",
    "                # if ds == dataset_num-1:\n",
    "                #     print('dtw_accuracy_mean', dtw_accuracy_mean/dataset_num)\n",
    "                # ## dtw accruacy #######################################################\n",
    "\n",
    "                k_means_bin_origin_feature.append(origin_kmeans_accuracy)\n",
    "                k_means_bin.append(kmeans_accuracy)\n",
    "                if SAE_net == False and converted_net_forward == True:\n",
    "                    converted_kmeans_accuracy = cluster_spikes_with_accuracy_torch(features= torch.tensor(converted_spike_hidden).to(device), true_labels=label-1, n_clusters=3, init_point=None)\n",
    "                    converted_k_means_bin.append(converted_kmeans_accuracy)\n",
    "                # sklearn kmeans인데 cpu많이먹어서 버림.\n",
    "                # origin_kmeans_accuracy = cluster_spikes_with_accuracy(features= spike.cpu().detach().numpy(), true_labels=label-1, n_clusters=3, init_point=None)\n",
    "                # kmeans_accuracy = cluster_spikes_with_accuracy(features= spike_hidden, true_labels=label-1, n_clusters=3, init_point=None)\n",
    "                # k_means_bin_origin_feature.append(origin_kmeans_accuracy)\n",
    "                # k_means_bin.append(kmeans_accuracy)\n",
    "                # if SAE_net == False and converted_net_forward == True:\n",
    "                #     converted_kmeans_accuracy = cluster_spikes_with_accuracy(features= converted_spike_hidden, true_labels=label-1, n_clusters=3, init_point=None)\n",
    "                #     converted_k_means_bin.append(converted_kmeans_accuracy)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "                # print('Cluster',Cluster)\n",
    "                # print('spike_id', spike_id)\n",
    "\n",
    "                # spike id 분포 확인하기\n",
    "                # unique_elements, counts = np.unique(spike_id, return_counts=True)\n",
    "                # print(\"Unique elements:\", unique_elements)\n",
    "                # print(\"Counts:\", counts)\n",
    "\n",
    "                cluster_accuracy_during_training_cycle = np.zeros(math.factorial(num_cluster))\n",
    "                cluster_accuracy_post_training_cycle = np.zeros(math.factorial(num_cluster))\n",
    "                cluster_accuracy_total = np.zeros(math.factorial(num_cluster))\n",
    "                \n",
    "                label_converter_ground = list(range(1, num_cluster + 1)) # [1, 2, 3, 4] 생성\n",
    "                label_converter_permutations = list(itertools.permutations(label_converter_ground)) # 모든 순열 구하기\n",
    "                perm_i = 0\n",
    "                perm_start_time = time.time() \n",
    "                for perm in label_converter_permutations:\n",
    "                    label_converter = list(perm)\n",
    "                    # print(label_converter)\n",
    "                    correct_during_training_cycle = 0\n",
    "                    correct_post_training_cycle = 0\n",
    "\n",
    "                    assert len(spike_id) == len(label), 'spike_id랑 label 길이 같아야 됨.'\n",
    "                    for i in range(len(spike_id)):\n",
    "                        if(label_converter[int(spike_id[i]-1)] == label[i]):\n",
    "                            if i < training_cycle:\n",
    "                                correct_during_training_cycle += 1\n",
    "                            else:\n",
    "                                correct_post_training_cycle += 1\n",
    "\n",
    "                    cluster_accuracy_during_training_cycle[perm_i] = correct_during_training_cycle/training_cycle\n",
    "                    cluster_accuracy_post_training_cycle[perm_i] = correct_post_training_cycle/(len(spike_id)-training_cycle)\n",
    "                    cluster_accuracy_total[perm_i] = (correct_during_training_cycle+correct_post_training_cycle)/(len(spike_id))\n",
    "                    perm_i += 1\n",
    "                # print(f\"perm 실행 시간: {time.time()-perm_start_time:.3f}초\")\n",
    "                \n",
    "                cluster_accuracy_during_training_cycle_all_dataset[ds] = np.max(cluster_accuracy_during_training_cycle)\n",
    "                cluster_accuracy_post_training_cycle_all_dataset[ds] = cluster_accuracy_post_training_cycle[np.argmax(cluster_accuracy_during_training_cycle)]\n",
    "                cluster_accuracy_total_all_dataset[ds] = cluster_accuracy_total[np.argmax(cluster_accuracy_during_training_cycle)]\n",
    "                # plot_distributions(ds, plot_tau, plot_denominator, plot_m, plot_max_tau, cos_thr[ds],\n",
    "                #                    cluster_accuracy_during_training_cycle_all_dataset[ds], cluster_accuracy_post_training_cycle_all_dataset[ds], cluster_accuracy_total_all_dataset[ds])\n",
    "            print(f'k_means origin feature average accuracy : {100*sum(k_means_bin_origin_feature)/(len(k_means_bin_origin_feature)+1e-12):.8f}%, total {k_means_bin_origin_feature}')\n",
    "            \n",
    "            mean_cluster_accuracy_during_training_cycle_all_dataset = np.mean(cluster_accuracy_during_training_cycle_all_dataset)\n",
    "            mean_cluster_accuracy_post_training_cycle_all_dataset = np.mean(cluster_accuracy_post_training_cycle_all_dataset)\n",
    "            mean_cluster_accuracy_total_all_dataset = np.mean(cluster_accuracy_total_all_dataset)\n",
    "            \n",
    "            if SAE_net == False and converted_net_forward == True:\n",
    "                converted_k_means_acc = 100*sum(converted_k_means_bin)/len(converted_k_means_bin)\n",
    "                print(f'converted_kmeans average accuracy : {converted_k_means_acc:.8f}%, total {converted_k_means_bin}')\n",
    "            k_means_acc = 100*sum(k_means_bin)/len(k_means_bin)\n",
    "            if k_means_acc > k_means_acc_best:\n",
    "                # torch.save(net, f\"net_save/save_now_net_{current_time}.pth\")\n",
    "                torch.save(net.module.state_dict(), f\"net_save/save_now_net_{current_time}.pth\")\n",
    "                print('save model')\n",
    "                best_mean_cluster_accuracy_post_training_cycle_all_dataset = mean_cluster_accuracy_post_training_cycle_all_dataset\n",
    "            \n",
    "            k_means_acc_best = max(k_means_acc_best, k_means_acc)\n",
    "            print(f'kmeans average accuracy best : {k_means_acc_best:.2f}%, kmeans average accuracy : {k_means_acc:.8f}%, total {k_means_bin}')\n",
    "            print(f'cluster_accuracy_post_training_cycle_all_dataset : {cluster_accuracy_post_training_cycle_all_dataset}')\n",
    "\n",
    "            \n",
    "            mean_cluster_accuracy_during_training_cycle_all_dataset_history.append((epoch, mean_cluster_accuracy_during_training_cycle_all_dataset*100))\n",
    "            mean_cluster_accuracy_post_training_cycle_all_dataset_history.append((epoch, mean_cluster_accuracy_post_training_cycle_all_dataset*100))\n",
    "            mean_cluster_accuracy_total_all_dataset_history.append((epoch, mean_cluster_accuracy_total_all_dataset*100))\n",
    "            print(f\"mean_cluster_accuracy_during_training_cycle : {mean_cluster_accuracy_during_training_cycle_all_dataset*100:.2f}%, post_traincycle_acc : {mean_cluster_accuracy_post_training_cycle_all_dataset*100:.2f}%, total_acc : {mean_cluster_accuracy_total_all_dataset*100:.8f}%\")\n",
    "\n",
    "            # kmeans accuracy기준으로 좋은 거 저장할 거임\n",
    "            # if mean_cluster_accuracy_post_training_cycle_all_dataset > best_mean_cluster_accuracy_post_training_cycle_all_dataset:\n",
    "            #     # torch.save(net, f\"net_save/save_now_net_{current_time}.pth\")\n",
    "            #     torch.save(net.module.state_dict(), f\"net_save/save_now_net_{current_time}.pth\")\n",
    "            #     print('save model')\n",
    "            #     best_mean_cluster_accuracy_post_training_cycle_all_dataset = mean_cluster_accuracy_post_training_cycle_all_dataset\n",
    "            print(f\"best_mean_cluster_accuracy_post_training_cycle_all_dataset : {best_mean_cluster_accuracy_post_training_cycle_all_dataset*100:.2f}%\")\n",
    "            print(f\"accuracy_check 실행 시간: {time.time()-accuracy_check_start_time:.3f}초\")\n",
    "\n",
    "        wandb.log({\"avg_loss\": avg_loss})\n",
    "        wandb.log({\"mean_cluster_accuracy_post_training_cycle_all_dataset\": mean_cluster_accuracy_post_training_cycle_all_dataset})\n",
    "        wandb.log({\"best_mean_cluster_accuracy_post_training_cycle_all_dataset\": best_mean_cluster_accuracy_post_training_cycle_all_dataset})\n",
    "        wandb.log({\"best_mean_cluster_accuracy_post_training_cycle_all_dataset2\": best_mean_cluster_accuracy_post_training_cycle_all_dataset})\n",
    "        wandb.log({\"k_means_acc\": k_means_acc})\n",
    "        wandb.log({\"k_means_acc_best\": k_means_acc_best})\n",
    "        wandb.log({\"converted_k_means_acc\": converted_k_means_acc})\n",
    "\n",
    "\n",
    "        # 저장\n",
    "        with open(f\"result_save/cluster_accuracy_history_{current_time}.pkl\", \"wb\") as f:\n",
    "            pickle.dump({\n",
    "                \"loss_history\": loss_history,\n",
    "                \"mean_cluster_accuracy_during_training_cycle_all_dataset_history\": mean_cluster_accuracy_during_training_cycle_all_dataset_history,\n",
    "                \"mean_cluster_accuracy_post_training_cycle_all_dataset_history\": mean_cluster_accuracy_post_training_cycle_all_dataset_history,\n",
    "                \"mean_cluster_accuracy_total_all_dataset_history\": mean_cluster_accuracy_total_all_dataset_history,\n",
    "            }, f)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mbhkim003\u001b[0m (\u001b[33mbhkim003-seoul-national-university\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.19.8 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.17.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/nfs/home/bhkim003/github_folder/ByeonghyeonKim/my_snn/wandb/run-20250314_172211-hx1sgh05</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/bhkim003-seoul-national-university/spike_sorting%20just%20run/runs/hx1sgh05' target=\"_blank\">derby-square-1564</a></strong> to <a href='https://wandb.ai/bhkim003-seoul-national-university/spike_sorting%20just%20run' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/bhkim003-seoul-national-university/spike_sorting%20just%20run' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/spike_sorting%20just%20run</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/bhkim003-seoul-national-university/spike_sorting%20just%20run/runs/hx1sgh05' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/spike_sorting%20just%20run/runs/hx1sgh05</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'gpu': '5', 'Conv_net': True, 'SAE_net': True, 'dataset_num': 16, 'spike_length': 50, 'num_cluster': 4, 'training_cycle': 1400, 'batch_size': 32, 'max_epoch': 10000, 'learning_rate': 0.001, 'normalize_on': True, 'need_bias': False, 'lif_add_at_first': False, 'my_seed': 42, 'TIME': 50, 'v_decay': 0.5, 'v_threshold': 0.25, 'v_reset': 0.0, 'BPTT_on': True, 'SAE_hidden_nomean': True, 'current_time': '20250314_172209_650', 'optimizer': 'Adam', 'coarse_com_mode': True, 'sae_l2_norm_bridge': True, 'sae_lif_bridge': False, 'accuracy_check_epoch_term': 1, 'lif_add_at_last': False, 'two_channel_input': False, 'lateral_feature_num': 2, 'lc_adc_on': False, 'converted_net_forward': False, 'pretrained_net': None, 'vth_mul_on': False, 'batch_norm_on': False, 'l2_norm_loss_weight': 0, 'QCFS_neuron_on': False, 'quantize_level_num': 0, 'fusion_net': True, 'repeat_coding': False, 'sae_relu_on': False, 'conv1d_scaling': False, 'norm01': True, 'chan_loss_factor': 1, 'coarse_com_config': (0.999, -0.0)}\n",
      "cos_thr [0.95 0.95 0.95 0.95 0.95 0.95 0.95 0.85 0.95 0.9  0.8  0.95 0.95 0.95\n",
      " 0.95 0.8 ]\n",
      "conv length [50, 24, 11, 5]\n",
      "Total number of encoder parameters: 25632\n",
      "DataParallel(\n",
      "  (module): SAE_FUSION5_net_conv1(\n",
      "    (activation_function): LIF_layer()\n",
      "    (encoder): Sequential(\n",
      "      (0): SSBH_DimChanger_one_two()\n",
      "      (1): SSBH_DimChanger_for_one_two_coupling()\n",
      "      (2): Conv1d(1, 32, kernel_size=(3,), stride=(2,), bias=False)\n",
      "      (3): SSBH_DimChanger_for_one_two_decoupling()\n",
      "      (4): LIF_layer()\n",
      "      (5): SSBH_DimChanger_for_one_two_coupling()\n",
      "      (6): Conv1d(32, 64, kernel_size=(3,), stride=(2,), bias=False)\n",
      "      (7): SSBH_DimChanger_for_one_two_decoupling()\n",
      "      (8): LIF_layer()\n",
      "      (9): SSBH_DimChanger_for_one_two_coupling()\n",
      "      (10): Conv1d(64, 96, kernel_size=(3,), stride=(2,), bias=False)\n",
      "      (11): SSBH_DimChanger_for_one_two_decoupling()\n",
      "      (12): LIF_layer()\n",
      "      (13): SSBH_DimChanger_for_one_two_coupling()\n",
      "      (14): SSBH_DimChanger_for_fc()\n",
      "      (15): Linear(in_features=480, out_features=2, bias=False)\n",
      "      (16): SSBH_DimChanger_for_one_two_decoupling()\n",
      "      (17): LIF_layer()\n",
      "      (18): SSBH_DimChanger_one_two()\n",
      "    )\n",
      "    (decoder): Sequential(\n",
      "      (0): SSBH_DimChanger_for_two_three_coupling()\n",
      "      (1): Linear(in_features=100, out_features=480, bias=False)\n",
      "      (2): ReLU()\n",
      "      (3): SSBH_DimChanger_for_conv1()\n",
      "      (4): ConvTranspose1d(96, 64, kernel_size=(3,), stride=(2,), bias=False)\n",
      "      (5): ReLU()\n",
      "      (6): ConvTranspose1d(64, 32, kernel_size=(3,), stride=(2,), output_padding=(1,), bias=False)\n",
      "      (7): ReLU()\n",
      "      (8): ConvTranspose1d(32, 1, kernel_size=(3,), stride=(2,), output_padding=(1,), bias=False)\n",
      "    )\n",
      "  )\n",
      ")\n",
      "Device: cuda\n",
      "\n",
      "Start Training, current_time = 20250314_172209_650\n",
      "\n",
      "tensor([[[-0.0561,  0.0148, -0.0587,  ...,  0.0000,  0.0000,  0.0000]],\n",
      "\n",
      "        [[-0.0563,  0.0090,  0.0215,  ...,  0.0000,  0.0000,  0.0000]],\n",
      "\n",
      "        [[-0.0856,  0.0255, -0.0038,  ...,  0.0000,  0.0000,  0.0000]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.0613,  0.0252, -0.0092,  ...,  0.0000,  0.0000,  0.0000]],\n",
      "\n",
      "        [[-0.0442,  0.0075, -0.0067,  ...,  0.0000,  0.0000,  0.0000]],\n",
      "\n",
      "        [[-0.0489,  0.0210, -0.0345,  ...,  0.0000,  0.0000,  0.0000]]],\n",
      "       device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([[[-0.0207,  0.0337,  0.0593,  ...,  0.0000,  0.0000,  0.0000]],\n",
      "\n",
      "        [[-0.0430,  0.0308,  0.0309,  ...,  0.0000,  0.0000,  0.0000]],\n",
      "\n",
      "        [[-0.0393,  0.0044,  0.0631,  ...,  0.0000,  0.0000,  0.0000]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.0430,  0.0308,  0.0309,  ...,  0.0000,  0.0000,  0.0000]],\n",
      "\n",
      "        [[-0.0663,  0.0367,  0.0307,  ...,  0.0000,  0.0000,  0.0000]],\n",
      "\n",
      "        [[-0.0398,  0.0499,  0.0419,  ...,  0.0000,  0.0000,  0.0000]]],\n",
      "       device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([[[-0.0657,  0.0475,  0.0892,  ...,  0.0000,  0.0000,  0.0000]],\n",
      "\n",
      "        [[ 0.0078,  0.0431,  0.1773,  ...,  0.0000,  0.0000,  0.0000]],\n",
      "\n",
      "        [[-0.0404,  0.0647,  0.0771,  ...,  0.0000,  0.0000,  0.0000]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.0267,  0.0562,  0.0582,  ...,  0.0000,  0.0000,  0.0000]],\n",
      "\n",
      "        [[-0.0374,  0.0340,  0.0411,  ...,  0.0000,  0.0000,  0.0000]],\n",
      "\n",
      "        [[-0.0377,  0.0722,  0.0661,  ...,  0.0000,  0.0000,  0.0000]]],\n",
      "       device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([[[ 0.0069,  0.1399,  0.2116,  ...,  0.0000,  0.0000,  0.0000]],\n",
      "\n",
      "        [[-0.0093,  0.0769,  0.2449,  ...,  0.0000,  0.0000,  0.0000]],\n",
      "\n",
      "        [[-0.0172,  0.1016,  0.1588,  ...,  0.0000,  0.0000,  0.0000]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 0.0021,  0.0499,  0.1793,  ...,  0.0000,  0.0000,  0.0000]],\n",
      "\n",
      "        [[-0.0110,  0.1168,  0.1097,  ...,  0.0000,  0.0000,  0.0000]],\n",
      "\n",
      "        [[-0.0022,  0.1084,  0.2380,  ...,  0.0000,  0.0000,  0.0000]]],\n",
      "       device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([[[-0.0089,  0.1180,  0.2066,  ...,  0.0000,  0.0000,  0.0000]],\n",
      "\n",
      "        [[ 0.0184,  0.0977,  0.2105,  ...,  0.0000,  0.0000,  0.0000]],\n",
      "\n",
      "        [[ 0.0213,  0.1083,  0.2033,  ...,  0.0000,  0.0000,  0.0000]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 0.0055,  0.1057,  0.1701,  ...,  0.0000,  0.0000,  0.0000]],\n",
      "\n",
      "        [[-0.0089,  0.1409,  0.1844,  ...,  0.0000,  0.0000,  0.0000]],\n",
      "\n",
      "        [[ 0.0201,  0.1287,  0.1793,  ...,  0.0000,  0.0000,  0.0000]]],\n",
      "       device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([[[0.0681, 0.1215, 0.2941,  ..., 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0557, 0.1164, 0.2760,  ..., 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0410, 0.1479, 0.2590,  ..., 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[0.0544, 0.1605, 0.3078,  ..., 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0577, 0.1434, 0.2473,  ..., 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0686, 0.0804, 0.2715,  ..., 0.0000, 0.0000, 0.0000]]],\n",
      "       device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([[[0.0636, 0.1879, 0.2834,  ..., 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0842, 0.1492, 0.3694,  ..., 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0817, 0.1294, 0.2379,  ..., 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[0.0759, 0.1685, 0.3397,  ..., 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0465, 0.1434, 0.2563,  ..., 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0635, 0.1095, 0.2910,  ..., 0.0000, 0.0000, 0.0000]]],\n",
      "       device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([[[0.1061, 0.1558, 0.3248,  ..., 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0742, 0.1058, 0.2348,  ..., 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.1019, 0.0988, 0.3003,  ..., 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[0.0831, 0.1175, 0.2548,  ..., 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.1061, 0.1504, 0.3251,  ..., 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0775, 0.1143, 0.2625,  ..., 0.0000, 0.0000, 0.0000]]],\n",
      "       device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([[[0.1063, 0.0959, 0.2181,  ..., 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.1053, 0.1305, 0.2588,  ..., 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.1025, 0.0883, 0.2206,  ..., 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[0.1001, 0.1085, 0.2610,  ..., 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0813, 0.1075, 0.2248,  ..., 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0853, 0.1234, 0.2301,  ..., 0.0000, 0.0000, 0.0000]]],\n",
      "       device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([[[0.0908, 0.1049, 0.2209,  ..., 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0759, 0.1109, 0.1882,  ..., 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0935, 0.1080, 0.2124,  ..., 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[0.0631, 0.1428, 0.1948,  ..., 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0793, 0.1180, 0.1784,  ..., 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.1327, 0.1547, 0.3114,  ..., 0.0000, 0.0000, 0.0000]]],\n",
      "       device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([[[0.0974, 0.1096, 0.2180,  ..., 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0887, 0.1045, 0.1841,  ..., 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.1190, 0.0899, 0.2258,  ..., 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[0.1056, 0.1252, 0.2175,  ..., 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0894, 0.1256, 0.1824,  ..., 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.1363, 0.1344, 0.2609,  ..., 0.0000, 0.0000, 0.0000]]],\n",
      "       device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([[[0.0841, 0.1686, 0.2542,  ..., 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0977, 0.1108, 0.1852,  ..., 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0903, 0.1202, 0.1887,  ..., 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[0.0964, 0.1160, 0.2130,  ..., 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.1538, 0.1767, 0.2991,  ..., 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.1041, 0.1062, 0.2205,  ..., 0.0000, 0.0000, 0.0000]]],\n",
      "       device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([[[0.1508, 0.1141, 0.2848,  ..., 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.1087, 0.1212, 0.1901,  ..., 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.1130, 0.1193, 0.2188,  ..., 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[0.1518, 0.1718, 0.2936,  ..., 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.1149, 0.1340, 0.2155,  ..., 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.1182, 0.1476, 0.2182,  ..., 0.0000, 0.0000, 0.0000]]],\n",
      "       device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([[[0.1722, 0.2092, 0.2987,  ..., 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.1622, 0.1523, 0.2927,  ..., 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.1176, 0.1256, 0.2166,  ..., 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[0.1265, 0.1472, 0.2032,  ..., 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.1277, 0.1341, 0.2226,  ..., 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.1388, 0.1797, 0.2401,  ..., 0.0000, 0.0000, 0.0000]]],\n",
      "       device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([[[0.1762, 0.1830, 0.3095,  ..., 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.1631, 0.1747, 0.2530,  ..., 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.1741, 0.2238, 0.3183,  ..., 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[0.1531, 0.1842, 0.2309,  ..., 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.1441, 0.1436, 0.2383,  ..., 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.1327, 0.1389, 0.2256,  ..., 0.0000, 0.0000, 0.0000]]],\n",
      "       device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([[[0.1586, 0.1716, 0.2487,  ..., 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.1472, 0.1957, 0.2548,  ..., 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.1581, 0.1710, 0.2445,  ..., 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[0.1850, 0.1513, 0.2842,  ..., 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.1591, 0.1708, 0.2587,  ..., 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.1894, 0.1894, 0.3211,  ..., 0.0000, 0.0000, 0.0000]]],\n",
      "       device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([[[0.2349, 0.2837, 0.3778,  ..., 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.1853, 0.2115, 0.2905,  ..., 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.1714, 0.1876, 0.2565,  ..., 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[0.1713, 0.1852, 0.2727,  ..., 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.1718, 0.1882, 0.2675,  ..., 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.1961, 0.2098, 0.3226,  ..., 0.0000, 0.0000, 0.0000]]],\n",
      "       device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([[[0.1905, 0.2187, 0.2846,  ..., 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.2142, 0.2906, 0.3498,  ..., 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.2000, 0.2255, 0.3005,  ..., 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[0.1612, 0.2173, 0.2429,  ..., 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.1943, 0.2335, 0.3023,  ..., 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.2057, 0.1886, 0.3009,  ..., 0.0000, 0.0000, 0.0000]]],\n",
      "       device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([[[0.2225, 0.2719, 0.3348,  ..., 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.1929, 0.2304, 0.2704,  ..., 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.2142, 0.2207, 0.3148,  ..., 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[0.2103, 0.2473, 0.3083,  ..., 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.2773, 0.3166, 0.4264,  ..., 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.2274, 0.2614, 0.3344,  ..., 0.0000, 0.0000, 0.0000]]],\n",
      "       device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([[[0.2788, 0.3448, 0.4229,  ..., 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.2306, 0.2157, 0.3288,  ..., 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.2076, 0.2466, 0.2996,  ..., 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[0.2080, 0.2296, 0.2879,  ..., 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.2030, 0.2503, 0.2756,  ..., 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.2765, 0.3428, 0.4158,  ..., 0.0000, 0.0000, 0.0000]]],\n",
      "       device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([[[0.2256, 0.2430, 0.3091,  ..., 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.2808, 0.3550, 0.4151,  ..., 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.2225, 0.2232, 0.3265,  ..., 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[0.2392, 0.2301, 0.3345,  ..., 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.2261, 0.2457, 0.3111,  ..., 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.2419, 0.2850, 0.3412,  ..., 0.0000, 0.0000, 0.0000]]],\n",
      "       device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([[[0.2402, 0.3131, 0.3648,  ..., 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.2397, 0.2970, 0.3393,  ..., 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.2115, 0.2842, 0.3002,  ..., 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[0.2270, 0.2511, 0.3006,  ..., 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.2331, 0.2420, 0.3145,  ..., 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.2187, 0.2589, 0.2958,  ..., 0.0000, 0.0000, 0.0000]]],\n",
      "       device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([[[0.2319, 0.2649, 0.3076,  ..., 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.2730, 0.3470, 0.4082,  ..., 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.2909, 0.3619, 0.4207,  ..., 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[0.2626, 0.3049, 0.3827,  ..., 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.2493, 0.2917, 0.3646,  ..., 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.2710, 0.2635, 0.3845,  ..., 0.0000, 0.0000, 0.0000]]],\n",
      "       device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([[[0.2492, 0.2381, 0.3289,  ..., 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.2999, 0.3693, 0.4372,  ..., 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.2509, 0.2413, 0.3263,  ..., 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[0.2863, 0.3623, 0.4169,  ..., 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.2406, 0.2600, 0.3044,  ..., 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.3110, 0.3552, 0.4447,  ..., 0.0000, 0.0000, 0.0000]]],\n",
      "       device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([[[0.2714, 0.2835, 0.3277,  ..., 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.2176, 0.2326, 0.2654,  ..., 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.2773, 0.3319, 0.3901,  ..., 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[0.2512, 0.2715, 0.3171,  ..., 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.2348, 0.2567, 0.2970,  ..., 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.2864, 0.3758, 0.4256,  ..., 0.0000, 0.0000, 0.0000]]],\n",
      "       device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([[[0.2187, 0.2546, 0.2719,  ..., 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.2437, 0.2600, 0.2925,  ..., 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.2613, 0.3181, 0.3345,  ..., 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[0.2506, 0.2762, 0.3159,  ..., 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.2704, 0.2457, 0.3264,  ..., 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.3164, 0.3840, 0.4434,  ..., 0.0000, 0.0000, 0.0000]]],\n",
      "       device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([[[0.2720, 0.2617, 0.3267,  ..., 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.2997, 0.3247, 0.3759,  ..., 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.2871, 0.3464, 0.3829,  ..., 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[0.2713, 0.2728, 0.3233,  ..., 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.2975, 0.3656, 0.4118,  ..., 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.2526, 0.2671, 0.2949,  ..., 0.0000, 0.0000, 0.0000]]],\n",
      "       device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([[[0.3109, 0.4103, 0.4386,  ..., 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.2959, 0.3118, 0.3722,  ..., 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.2737, 0.3202, 0.3571,  ..., 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[0.2765, 0.2871, 0.3150,  ..., 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.3133, 0.3994, 0.4426,  ..., 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.3447, 0.4145, 0.4642,  ..., 0.0000, 0.0000, 0.0000]]],\n",
      "       device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([[[0.2904, 0.2802, 0.3427,  ..., 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.2466, 0.2547, 0.2634,  ..., 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.3544, 0.4234, 0.4656,  ..., 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[0.3659, 0.4436, 0.5058,  ..., 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.2798, 0.2686, 0.3204,  ..., 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.2129, 0.2582, 0.2738,  ..., 0.0000, 0.0000, 0.0000]]],\n",
      "       device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([[[0.2793, 0.2696, 0.2900,  ..., 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.3860, 0.4476, 0.5075,  ..., 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.3624, 0.4363, 0.4523,  ..., 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[0.3496, 0.4479, 0.4718,  ..., 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.2840, 0.2786, 0.3175,  ..., 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.2967, 0.3205, 0.3291,  ..., 0.0000, 0.0000, 0.0000]]],\n",
      "       device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([[[0.3732, 0.4194, 0.4373,  ..., 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.2827, 0.3028, 0.3132,  ..., 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.3163, 0.4197, 0.4333,  ..., 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[0.3660, 0.4605, 0.4781,  ..., 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.2973, 0.2786, 0.3085,  ..., 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.2764, 0.2855, 0.2868,  ..., 0.0000, 0.0000, 0.0000]]],\n",
      "       device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([[[0.2741, 0.2826, 0.2655,  ..., 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.2876, 0.3646, 0.3239,  ..., 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.3477, 0.3942, 0.3767,  ..., 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[0.2628, 0.2808, 0.2495,  ..., 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.2778, 0.2949, 0.2691,  ..., 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.3952, 0.4613, 0.4983,  ..., 0.0000, 0.0000, 0.0000]]],\n",
      "       device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([[[0.2731, 0.2818, 0.2477,  ..., 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.3077, 0.3115, 0.2878,  ..., 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.3539, 0.4182, 0.3928,  ..., 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[0.3257, 0.3243, 0.3442,  ..., 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.2277, 0.2831, 0.2270,  ..., 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.3064, 0.3276, 0.3047,  ..., 0.0000, 0.0000, 0.0000]]],\n",
      "       device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([[[0.2880, 0.3076, 0.2957,  ..., 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.4373, 0.4899, 0.4912,  ..., 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.2897, 0.2931, 0.2593,  ..., 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[0.3469, 0.3582, 0.3563,  ..., 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.2763, 0.2855, 0.2388,  ..., 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.2947, 0.2987, 0.2617,  ..., 0.0000, 0.0000, 0.0000]]],\n",
      "       device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([[[0.2782, 0.3005, 0.2932,  ..., 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.3118, 0.3295, 0.2895,  ..., 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.2890, 0.3022, 0.2642,  ..., 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[0.4015, 0.4789, 0.4755,  ..., 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.2593, 0.2736, 0.2383,  ..., 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.3316, 0.3146, 0.3210,  ..., 0.0000, 0.0000, 0.0000]]],\n",
      "       device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([[[0.3581, 0.4173, 0.3471,  ..., 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.3509, 0.4221, 0.3833,  ..., 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.3121, 0.3312, 0.2798,  ..., 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[0.3755, 0.4375, 0.4042,  ..., 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.3280, 0.3418, 0.2924,  ..., 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.2982, 0.3311, 0.2909,  ..., 0.0000, 0.0000, 0.0000]]],\n",
      "       device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([[[0.4227, 0.5029, 0.4969,  ..., 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.3661, 0.4370, 0.3782,  ..., 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.4323, 0.5520, 0.4867,  ..., 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[0.3449, 0.4220, 0.3455,  ..., 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.3282, 0.3155, 0.2998,  ..., 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.4356, 0.5050, 0.4929,  ..., 0.0000, 0.0000, 0.0000]]],\n",
      "       device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([[[0.3112, 0.3278, 0.3092,  ..., 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.2829, 0.2768, 0.2575,  ..., 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.2597, 0.2558, 0.2324,  ..., 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[0.3382, 0.3746, 0.3164,  ..., 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.3285, 0.3353, 0.2883,  ..., 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.2548, 0.2653, 0.2288,  ..., 0.0000, 0.0000, 0.0000]]],\n",
      "       device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([[[0.2717, 0.2768, 0.2450,  ..., 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.3708, 0.4492, 0.3918,  ..., 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.2830, 0.2695, 0.2231,  ..., 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[0.2749, 0.2773, 0.2377,  ..., 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.3558, 0.4412, 0.3819,  ..., 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.2987, 0.3551, 0.2963,  ..., 0.0000, 0.0000, 0.0000]]],\n",
      "       device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([[[0.2551, 0.2364, 0.2370,  ..., 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.3033, 0.2775, 0.2664,  ..., 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.3749, 0.4106, 0.4015,  ..., 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[0.3151, 0.3546, 0.3022,  ..., 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.3543, 0.4425, 0.3832,  ..., 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.4473, 0.5194, 0.5104,  ..., 0.0000, 0.0000, 0.0000]]],\n",
      "       device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([[[0.3971, 0.4409, 0.4261,  ..., 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.3239, 0.3371, 0.3098,  ..., 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.3131, 0.2859, 0.2794,  ..., 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[0.2755, 0.2790, 0.2253,  ..., 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.2618, 0.2814, 0.2192,  ..., 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.1840, 0.2129, 0.1684,  ..., 0.0000, 0.0000, 0.0000]]],\n",
      "       device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([[[0.3456, 0.3945, 0.3988,  ..., 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.2999, 0.3326, 0.2857,  ..., 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.4146, 0.4386, 0.4617,  ..., 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[0.4458, 0.5077, 0.4978,  ..., 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.3148, 0.3599, 0.2917,  ..., 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.3546, 0.3982, 0.3694,  ..., 0.0000, 0.0000, 0.0000]]],\n",
      "       device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([[[0.2725, 0.2488, 0.2935,  ..., 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.2679, 0.2755, 0.2306,  ..., 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.2460, 0.3091, 0.2442,  ..., 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[0.3709, 0.4150, 0.3423,  ..., 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.2626, 0.2626, 0.2197,  ..., 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.1804, 0.2026, 0.1720,  ..., 0.0000, 0.0000, 0.0000]]],\n",
      "       device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([[[0.2548, 0.2536, 0.2229,  ..., 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.3025, 0.2635, 0.2592,  ..., 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.3023, 0.3460, 0.2611,  ..., 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[0.2375, 0.2224, 0.2295,  ..., 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.2948, 0.3301, 0.2626,  ..., 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.2485, 0.2803, 0.2475,  ..., 0.0000, 0.0000, 0.0000]]],\n",
      "       device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([[[0.4599, 0.5188, 0.5159,  ..., 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.3159, 0.2793, 0.2852,  ..., 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.2409, 0.2481, 0.2161,  ..., 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[0.2522, 0.2371, 0.2171,  ..., 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.4174, 0.4629, 0.4569,  ..., 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.3784, 0.4419, 0.3984,  ..., 0.0000, 0.0000, 0.0000]]],\n",
      "       device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([[[0.3455, 0.3428, 0.3401,  ..., 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.3191, 0.2961, 0.2802,  ..., 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.2988, 0.2711, 0.2717,  ..., 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[0.2635, 0.2520, 0.2171,  ..., 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.4460, 0.4920, 0.4964,  ..., 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.2957, 0.2784, 0.2601,  ..., 0.0000, 0.0000, 0.0000]]],\n",
      "       device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([[[0.4592, 0.5243, 0.5284,  ..., 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.2527, 0.2135, 0.2442,  ..., 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.2395, 0.2499, 0.2105,  ..., 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[0.4081, 0.4239, 0.4148,  ..., 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.2639, 0.2595, 0.2502,  ..., 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.4129, 0.5440, 0.5009,  ..., 0.0000, 0.0000, 0.0000]]],\n",
      "       device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([[[0.3507, 0.3618, 0.3591,  ..., 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.3358, 0.3189, 0.3218,  ..., 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.2560, 0.2893, 0.2571,  ..., 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[0.2745, 0.3085, 0.2546,  ..., 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.2619, 0.2865, 0.2700,  ..., 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.2996, 0.2751, 0.2398,  ..., 0.0000, 0.0000, 0.0000]]],\n",
      "       device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([[[0.2748, 0.3337, 0.2773,  ..., 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.2854, 0.2435, 0.2443,  ..., 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.1768, 0.1978, 0.1514,  ..., 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[0.3885, 0.4075, 0.4034,  ..., 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.2835, 0.3129, 0.2626,  ..., 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.2486, 0.2941, 0.2557,  ..., 0.0000, 0.0000, 0.0000]]],\n",
      "       device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([[[0.4131, 0.5349, 0.4762,  ..., 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.2384, 0.2220, 0.2207,  ..., 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.4554, 0.5161, 0.5208,  ..., 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[0.2385, 0.2200, 0.2133,  ..., 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.2554, 0.2879, 0.2229,  ..., 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.2460, 0.2324, 0.2418,  ..., 0.0000, 0.0000, 0.0000]]],\n",
      "       device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([[[0.2924, 0.2730, 0.2988,  ..., 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.2570, 0.2854, 0.2715,  ..., 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.2148, 0.2102, 0.1680,  ..., 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[0.2260, 0.2490, 0.2095,  ..., 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.1994, 0.1940, 0.1691,  ..., 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.3252, 0.3129, 0.3327,  ..., 0.0000, 0.0000, 0.0000]]],\n",
      "       device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([[[0.3695, 0.4346, 0.4183,  ..., 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.2265, 0.2286, 0.2202,  ..., 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.2961, 0.3104, 0.2665,  ..., 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[0.4698, 0.5309, 0.5447,  ..., 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.4465, 0.5254, 0.5245,  ..., 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.3463, 0.3930, 0.3422,  ..., 0.0000, 0.0000, 0.0000]]],\n",
      "       device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "tensor([[[0.3046, 0.3411, 0.3354,  ..., 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.3172, 0.2731, 0.3177,  ..., 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.3143, 0.3639, 0.3031,  ..., 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[0.3412, 0.3915, 0.3698,  ..., 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.2397, 0.2535, 0.2063,  ..., 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.4641, 0.5231, 0.5507,  ..., 0.0000, 0.0000, 0.0000]]],\n",
      "       device='cuda:0', grad_fn=<SqueezeBackward1>)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "gpu = '5'\n",
    "Conv_net = True # True False\n",
    "SAE_net = True # True False\n",
    "\n",
    "# hyperparameter\n",
    "dataset_num = 16\n",
    "spike_length = 50 # coarse_com_mode일 때는 time step이 됨.\n",
    "num_cluster = 4  # 클러스터 수 설정 # 논문엔 4개라는데 여기서는 3개로 했네\n",
    "training_cycle = 1400 #1400 2400 # 그 초기 몇개까지만 cluster update할지\n",
    "\n",
    "\n",
    "batch_size = 32\n",
    "max_epoch = 10000 # 10000 # 1\n",
    "learning_rate = 0.001\n",
    "normalize_on = True # True or False # 0부터1까지 normalize\n",
    "need_bias = False\n",
    "# first_layer_no_train = False\n",
    "lif_add_at_first = False\n",
    "my_seed = 42\n",
    "\n",
    "TIME = 50 # SAE일 때만 유효. coarse_com_mode일 때는 level_num이 됨. 즉 feature 개수.\n",
    "v_decay = 0.5 # -cor\n",
    "v_threshold = 0.25 # -cor\n",
    "v_reset = 0.0 # -cor # 10000이상 일 시 hard reset\n",
    "BPTT_on = True # +cor # True False\n",
    "\n",
    "SAE_hidden_nomean = True # True False\n",
    "\n",
    "current_time = datetime.datetime.now().strftime(\"%Y%m%d_%H%M%S\") + f\"_{str(int(datetime.datetime.now().microsecond / 1000)).zfill(3)}\"\n",
    "\n",
    "optimizer = 'Adam' #'Adam', 'SGD' # 둘다 준수함. loss 줄이는 거는 adam이 좋긴한데, cluster accuracy는 비슷함.\n",
    "\n",
    "coarse_com_mode = True # True False\n",
    "coarse_com_config = (0.999, -0.0) # (max, min) (0.999, -0.0) (1.0, -0.0) (2.0, -2.0) (3.0, -3.0)\n",
    "\n",
    "sae_l2_norm_bridge = True # True False\n",
    "sae_lif_bridge = False # True False\n",
    "\n",
    "accuracy_check_epoch_term = 1\n",
    "\n",
    "lif_add_at_last = False # True False\n",
    "\n",
    "two_channel_input = False # True False\n",
    "\n",
    "lateral_feature_num = 2\n",
    "\n",
    "lc_adc_on = False # True False\n",
    "\n",
    "converted_net_forward = False # True False\n",
    "\n",
    "pretrained_net = None\n",
    "# pretrained_net = '/home/bhkim003/github_folder/ByeonghyeonKim/my_snn/net_save/save_now_net_중요_20250110_203117_390.pth'\n",
    "# pretrained_net = '/home/bhkim003/github_folder/ByeonghyeonKim/my_snn/net_save/save_now_net_중요_20250113_134126_881_이거_94나오는거.pth'\n",
    "# pretrained_net = '/home/bhkim003/github_folder/ByeonghyeonKim/my_snn/net_save/save_now_net_20250205_184901_132.pth'\n",
    "# pretrained_net = '/home/bhkim003/github_folder/ByeonghyeonKim/my_snn/net_save/save_now_net_20250306_134219_133.pth'\n",
    "\n",
    "vth_mul_on = False # True False\n",
    "batch_norm_on = False # True False\n",
    "\n",
    "l2_norm_loss_weight = 0 #0.0001 #0.1 #  0 # 0초과면 작동\n",
    "\n",
    "QCFS_neuron_on = False # True False\n",
    "\n",
    "quantize_level_num = 0 # 0이면 quantize 안함. 1이상이면 그 수만큼 quantize함. # normalize_on 켜져야됨. 음수면 0~1norm안하고 quant함\n",
    "\n",
    "fusion_net = True # True False # SAE_net False, Conv_net True로 해라. TIME 적절하게 설정해주고.\n",
    "repeat_coding = False # True False #fusion_net에서 쓰이는 거임 # True면 repeat, False면 rate coding.\n",
    "\n",
    "sae_relu_on = False # True False\n",
    "\n",
    "conv1d_scaling = False # True False # conv1d때매 norm하고 (level_num-3)/level_num 곱해줌 # Conv_net and coarse_com_mode and normalize_on\n",
    "\n",
    "norm01 = True # True False # normalize_on = True일 때 01norm하는지 아님 걍 quant만 하는지.\n",
    "\n",
    "chan_loss_factor = 1\n",
    "\n",
    "# multi_timestep_insert = (20,10) # (20,10) # None # (한번에 넣을 timestep,stride)\n",
    "\n",
    "wandb.init(project= f'spike_sorting just run',save_code=False)\n",
    "\n",
    "\n",
    "cluster_train_system( \n",
    "    gpu = gpu,\n",
    "    Conv_net = Conv_net,\n",
    "    SAE_net = SAE_net,\n",
    "\n",
    "    # hyperparameter\n",
    "    dataset_num = dataset_num,\n",
    "    spike_length = spike_length,\n",
    "    num_cluster = num_cluster,  # 클러스터 수 설정 # 논문엔 4개라는데 여기서는 3개로 했네\n",
    "    training_cycle = training_cycle, # 그 초기 몇개까지만 cluster update할지\n",
    "\n",
    "\n",
    "    batch_size = batch_size,\n",
    "    max_epoch = max_epoch,\n",
    "    learning_rate = learning_rate,\n",
    "    normalize_on = normalize_on, # True or False #이거 안 씀 # 이거 별로 안 좋은 normalize같음 # 쓸 거면 다른 거 써라.\n",
    "    need_bias = need_bias,\n",
    "    # first_layer_no_train = False\n",
    "    lif_add_at_first = lif_add_at_first,\n",
    "    my_seed = my_seed,\n",
    "\n",
    "    TIME = TIME, # SAE일 때만 유효\n",
    "    v_decay = v_decay,\n",
    "    v_threshold = v_threshold,\n",
    "    v_reset = v_reset, # 10000이상 일 시 hard reset\n",
    "    BPTT_on = BPTT_on,\n",
    "\n",
    "    SAE_hidden_nomean = SAE_hidden_nomean,\n",
    "    \n",
    "    current_time = current_time,\n",
    "\n",
    "    optimizer = optimizer, #'Adam', 'SGD'\n",
    "\n",
    "    coarse_com_mode = coarse_com_mode,\n",
    "    coarse_com_config = coarse_com_config, # (max, min)\n",
    "\n",
    "    \n",
    "    sae_l2_norm_bridge = sae_l2_norm_bridge,\n",
    "    sae_lif_bridge = sae_lif_bridge,\n",
    "\n",
    "    accuracy_check_epoch_term = accuracy_check_epoch_term,\n",
    "    \n",
    "    lif_add_at_last = lif_add_at_last,\n",
    "\n",
    "    two_channel_input = two_channel_input,\n",
    "\n",
    "    lateral_feature_num = lateral_feature_num,\n",
    "\n",
    "    lc_adc_on = lc_adc_on, \n",
    "\n",
    "    converted_net_forward = converted_net_forward,\n",
    "\n",
    "    pretrained_net = pretrained_net,\n",
    "\n",
    "    vth_mul_on = vth_mul_on,\n",
    "    batch_norm_on = batch_norm_on,\n",
    "\n",
    "    l2_norm_loss_weight = l2_norm_loss_weight,\n",
    "    \n",
    "    QCFS_neuron_on = QCFS_neuron_on, # True False\n",
    "\n",
    "    quantize_level_num = quantize_level_num,\n",
    "\n",
    "    fusion_net = fusion_net, # True False\n",
    "    repeat_coding = repeat_coding,\n",
    "\n",
    "    sae_relu_on = sae_relu_on,\n",
    "\n",
    "    conv1d_scaling = conv1d_scaling,\n",
    "\n",
    "    norm01 = norm01,\n",
    "\n",
    "    chan_loss_factor = chan_loss_factor,\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Sweep code\n",
    "\n",
    "\n",
    "# from unittest import TextTestRunner\n",
    "\n",
    "\n",
    "# unique_name_hyper = 'cluster_train_system'\n",
    "# # run_name = 'spike_sorting'\n",
    "# sweep_start_time =  datetime.datetime.now().strftime(\"%Y%m%d_%H%M%S\") + f\"_{str(int(datetime.datetime.now().microsecond / 1000)).zfill(3)}\"\n",
    "# sweep_configuration = {\n",
    "#     'method': 'grid', # 'random', 'bayes', 'grid'\n",
    "#     'name': f'spike_sorting_{sweep_start_time}',\n",
    "#     'metric': {'goal': 'maximize', 'name': 'k_means_acc_best'},\n",
    "#     'parameters': \n",
    "#     {\n",
    "#         # \"gpu\": {\"values\": ['1']},  # 이건 sweep parameter아님. hyper_iter에서 직접 설정\n",
    "#         \"Conv_net\": {\"values\": [True]}, \n",
    "#         \"SAE_net\": {\"values\": [True]}, \n",
    "\n",
    "#         \"dataset_num\": {\"values\": [16]}, \n",
    "#         \"spike_length\": {\"values\": [50]},  \n",
    "#         \"num_cluster\": {\"values\": [4]}, \n",
    "#         \"training_cycle\": {\"values\": [1400]}, # [1400, 2400]\n",
    "\n",
    "#         \"batch_size\": {\"values\": [32]}, \n",
    "#         \"max_epoch\": {\"values\": [20]}, \n",
    "#         \"learning_rate\": {\"values\": [0.001, 0.0001]},\n",
    "#         \"normalize_on\": {\"values\": [True]},\n",
    "#         \"need_bias\": {\"values\": [False]}, # [True, False]\n",
    "\n",
    "#         \"lif_add_at_first\": {\"values\": [False]}, # [True, False]\n",
    "#         \"my_seed\": {\"values\": [42]}, \n",
    "\n",
    "#         \"TIME\": {\"values\": [50]}, #  [4,6,8,10]\n",
    "#         \"v_decay\": {\"values\": [0.5]}, # [0.25,0.50,0.75]\n",
    "#         \"v_threshold\": {\"values\": [0.25]}, # [0.25,0.50,0.75]\n",
    "#         \"v_reset\": {\"values\": [0.0]},  # [0.0, 10000.0]\n",
    "#         \"BPTT_on\": {\"values\": [True]},  # [True, False]\n",
    "\n",
    "#         \"SAE_hidden_nomean\": {\"values\": [True]}, # [True, False]\n",
    "\n",
    "#         # \"current_time\": {\"values\": [current_time]} #밑에서 직접설정됨.\n",
    "\n",
    "#         \"optimizer\": {\"values\": ['Adam']}, # ['Adam', 'SGD']\n",
    "\n",
    "#         \"coarse_com_mode\": {\"values\": [True]}, # [True, False]\n",
    "#         \"coarse_com_config\": {\"values\": [(0.999, -0.0)]}, # ['Adam', 'SGD']\n",
    "\n",
    "#         \"sae_l2_norm_bridge\": {\"values\": [True]}, # [True, False]\n",
    "#         \"sae_lif_bridge\": {\"values\": [False]}, # [False, True]\n",
    "        \n",
    "#         \"accuracy_check_epoch_term\": {\"values\": [1]}, \n",
    "\n",
    "#         \"lif_add_at_last\": {\"values\": [False]},# [True, False]\n",
    "\n",
    "#         \"two_channel_input\": {\"values\": [False]},# [True, False]\n",
    "\n",
    "#         \"lateral_feature_num\": {\"values\": [2, 4]},# [True, False]\n",
    "\n",
    "#         \"lc_adc_on\": {\"values\": [False]},# [True, False]\n",
    "        \n",
    "#         \"converted_net_forward\": {\"values\": [False]},# [True, False]\n",
    "\n",
    "#         \"pretrained_net\": {\"values\": [None]},# [None]\n",
    "\n",
    "#         \"vth_mul_on\": {\"values\": [False]},# [True, False]\n",
    "#         \"batch_norm_on\": {\"values\": [False]},# [True, False]\n",
    "\n",
    "#         \"l2_norm_loss_weight\": {\"values\": [0]},\n",
    "\n",
    "#         \"QCFS_neuron_on\": {\"values\": [False]},   # [True, False]\n",
    "\n",
    "#         \"quantize_level_num\": {\"values\": [0]}, \n",
    "\n",
    "#         \"fusion_net\": {\"values\": [True]}, \n",
    "#         \"repeat_coding\": {\"values\": [False]}, \n",
    "\n",
    "#         \"sae_relu_on\": {\"values\": [False]}, \n",
    "\n",
    "#         \"conv1d_scaling\": {\"values\": [False]}, \n",
    "\n",
    "#         \"norm01\": {\"values\": [True]}, \n",
    "\n",
    "#         \"chan_loss_factor\": {\"values\": [0.25,0.5,0.75,1.0,1.25,1.5,1.75,2.0,2.5,3.0,3.5]}, \n",
    "\n",
    "        \n",
    "#      }\n",
    "# }\n",
    "\n",
    "\n",
    "# def hyper_iter():\n",
    "#     ### my_snn control board ########################\n",
    "#     wandb.init(save_code = False)\n",
    "#     gpu  =  '2'\n",
    "#     Conv_net  =  wandb.config.Conv_net\n",
    "#     SAE_net  =  wandb.config.SAE_net\n",
    "\n",
    "#     dataset_num  =  wandb.config.dataset_num\n",
    "#     spike_length  =  wandb.config.spike_length\n",
    "#     num_cluster  =  wandb.config.num_cluster\n",
    "#     training_cycle  =  wandb.config.training_cycle\n",
    "\n",
    "#     batch_size  =  wandb.config.batch_size\n",
    "#     max_epoch  =  wandb.config.max_epoch\n",
    "#     learning_rate  =  wandb.config.learning_rate\n",
    "#     normalize_on  =  wandb.config.normalize_on\n",
    "#     need_bias  =  wandb.config.need_bias\n",
    "\n",
    "#     lif_add_at_first  =  wandb.config.lif_add_at_first\n",
    "#     my_seed  =  wandb.config.my_seed\n",
    "\n",
    "\n",
    "#     TIME  =  wandb.config.TIME\n",
    "#     v_decay  =  wandb.config.v_decay\n",
    "#     v_threshold  =  wandb.config.v_threshold\n",
    "#     v_reset  =  wandb.config.v_reset\n",
    "#     BPTT_on  =  wandb.config.BPTT_on\n",
    "\n",
    "#     SAE_hidden_nomean  =  wandb.config.SAE_hidden_nomean\n",
    "    \n",
    "#     current_time =  datetime.datetime.now().strftime(\"%Y%m%d_%H%M%S\") + f\"_{str(int(datetime.datetime.now().microsecond / 1000)).zfill(3)}\"\n",
    "\n",
    "#     optimizer  =  wandb.config.optimizer\n",
    "\n",
    "#     coarse_com_mode = wandb.config.coarse_com_mode\n",
    "#     coarse_com_config = wandb.config.coarse_com_config # (max, min)\n",
    "\n",
    "#     sae_l2_norm_bridge = wandb.config.sae_l2_norm_bridge\n",
    "#     sae_lif_bridge = wandb.config.sae_lif_bridge\n",
    "\n",
    "#     accuracy_check_epoch_term = wandb.config.accuracy_check_epoch_term\n",
    "\n",
    "#     lif_add_at_last = wandb.config.lif_add_at_last\n",
    "\n",
    "#     two_channel_input = wandb.config.two_channel_input\n",
    "\n",
    "#     lateral_feature_num = wandb.config.lateral_feature_num\n",
    "\n",
    "#     lc_adc_on = wandb.config.lc_adc_on\n",
    "\n",
    "#     converted_net_forward = wandb.config.converted_net_forward\n",
    "\n",
    "#     pretrained_net = wandb.config.pretrained_net\n",
    "\n",
    "#     vth_mul_on = wandb.config.vth_mul_on\n",
    "#     batch_norm_on = wandb.config.batch_norm_on\n",
    "\n",
    "#     l2_norm_loss_weight = wandb.config.l2_norm_loss_weight\n",
    "\n",
    "#     QCFS_neuron_on = wandb.config.QCFS_neuron_on\n",
    "\n",
    "#     quantize_level_num = wandb.config.quantize_level_num\n",
    "\n",
    "#     fusion_net = wandb.config.fusion_net\n",
    "#     repeat_coding = wandb.config.repeat_coding\n",
    "\n",
    "#     sae_relu_on = wandb.config.sae_relu_on\n",
    "\n",
    "#     conv1d_scaling = wandb.config.conv1d_scaling\n",
    "\n",
    "#     norm01 = wandb.config.norm01\n",
    "\n",
    "#     chan_loss_factor = wandb.config.chan_loss_factor\n",
    "\n",
    "#     cluster_train_system( \n",
    "#         gpu = gpu,\n",
    "#         Conv_net = Conv_net,\n",
    "#         SAE_net = SAE_net,\n",
    "\n",
    "#         # hyperparameter\n",
    "#         dataset_num = dataset_num,\n",
    "#         spike_length = spike_length,\n",
    "#         num_cluster = num_cluster,  # 클러스터 수 설정 # 논문엔 4개라는데 여기서는 3개로 했네\n",
    "#         training_cycle = training_cycle, # 그 초기 몇개까지만 cluster update할지\n",
    "\n",
    "\n",
    "#         batch_size = batch_size,\n",
    "#         max_epoch = max_epoch,\n",
    "#         learning_rate = learning_rate,\n",
    "#         normalize_on = normalize_on, # True or False #이거 안 씀 # 이거 별로 안 좋은 normalize같음 # 쓸 거면 다른 거 써라.\n",
    "#         need_bias = need_bias,\n",
    "#         # first_layer_no_train = False\n",
    "#         lif_add_at_first = lif_add_at_first,\n",
    "#         my_seed = my_seed,\n",
    "\n",
    "#         TIME = TIME, # SAE일 때만 유효\n",
    "#         v_decay = v_decay,\n",
    "#         v_threshold = v_threshold,\n",
    "#         v_reset = v_reset, # 10000이상 일 시 hard reset\n",
    "#         BPTT_on = BPTT_on,\n",
    "\n",
    "#         SAE_hidden_nomean = SAE_hidden_nomean,\n",
    "\n",
    "#         current_time = current_time,\n",
    "\n",
    "#         optimizer = optimizer, #'Adam', 'SGD'\n",
    "\n",
    "#         coarse_com_mode = coarse_com_mode,\n",
    "#         coarse_com_config = coarse_com_config, # (max, min)\n",
    "        \n",
    "#         sae_l2_norm_bridge = sae_l2_norm_bridge,\n",
    "#         sae_lif_bridge = sae_lif_bridge,\n",
    "\n",
    "#         accuracy_check_epoch_term = accuracy_check_epoch_term,\n",
    "\n",
    "#         lif_add_at_last = lif_add_at_last,\n",
    "        \n",
    "#         two_channel_input = two_channel_input,\n",
    "        \n",
    "#         lateral_feature_num = lateral_feature_num,\n",
    "\n",
    "#         lc_adc_on = lc_adc_on,\n",
    "\n",
    "#         converted_net_forward = converted_net_forward,\n",
    "\n",
    "#         pretrained_net = pretrained_net,\n",
    "\n",
    "#         vth_mul_on = vth_mul_on,\n",
    "#         batch_norm_on = batch_norm_on,\n",
    "\n",
    "#         l2_norm_loss_weight = l2_norm_loss_weight,\n",
    "\n",
    "#         QCFS_neuron_on = QCFS_neuron_on,\n",
    "\n",
    "#         quantize_level_num = quantize_level_num,\n",
    "\n",
    "#         fusion_net = fusion_net, \n",
    "#         repeat_coding = repeat_coding, \n",
    "\n",
    "#         sae_relu_on = sae_relu_on,\n",
    "\n",
    "#         conv1d_scaling = conv1d_scaling,\n",
    "\n",
    "#         norm01 = norm01,\n",
    "\n",
    "#         chan_loss_factor = chan_loss_factor,\n",
    "#         )\n",
    "    \n",
    "# # sweep_id = 'ygoj9jt4'\n",
    "# sweep_id = wandb.sweep(sweep=sweep_configuration, project=f'spike_sorting {unique_name_hyper}')\n",
    "# wandb.agent(sweep_id, function=hyper_iter, count=100000, project=f'spike_sorting {unique_name_hyper}')\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wandb.finish() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import matplotlib.pyplot as plt\n",
    "# from matplotlib.ticker import MaxNLocator\n",
    "# import pickle\n",
    "# import json\n",
    "\n",
    "# # current_time = '20250102_225243_972'\n",
    "\n",
    "# with open(f\"result_save/cluster_accuracy_history_{current_time}.pkl\", \"rb\") as f:\n",
    "#     data = pickle.load(f)\n",
    "\n",
    "\n",
    "# # JSON으로 저장\n",
    "# with open(f\"result_save/cluster_accuracy_history_{current_time}.json\", 'r') as f:\n",
    "#     loaded_hyperparameters = json.load(f)\n",
    "\n",
    "# loss_history = data['loss_history']\n",
    "# mean_cluster_accuracy_during_training_cycle_all_dataset_history = data['mean_cluster_accuracy_during_training_cycle_all_dataset_history']\n",
    "# mean_cluster_accuracy_post_training_cycle_all_dataset_history = data['mean_cluster_accuracy_post_training_cycle_all_dataset_history']\n",
    "# mean_cluster_accuracy_total_all_dataset_history = data['mean_cluster_accuracy_total_all_dataset_history']\n",
    "# print(data)\n",
    "# max_acc = 0\n",
    "# for i in mean_cluster_accuracy_post_training_cycle_all_dataset_history:\n",
    "#     if i[1] > max_acc:\n",
    "#         max_acc = i[1]\n",
    "\n",
    "# # 설정 정보 제목 작성\n",
    "# title = (\n",
    "#     f\"Dataset Num: {loaded_hyperparameters['dataset_num']}, Conv {loaded_hyperparameters['Conv_net']}, SAE {loaded_hyperparameters['SAE_net']}, Current time {loaded_hyperparameters['current_time']}, Spike Length: {loaded_hyperparameters['spike_length']}, Num Cluster: {loaded_hyperparameters['num_cluster']}, \"\n",
    "#     f\"Training Cycle: {loaded_hyperparameters['training_cycle']}, Batch Size: {loaded_hyperparameters['batch_size']}, Max Epoch: {loaded_hyperparameters['max_epoch']}, \\n\"\n",
    "#     f\"Learning Rate: {loaded_hyperparameters['learning_rate']}, Input Normalize: {loaded_hyperparameters['normalize_on']}, Need Bias: {loaded_hyperparameters['need_bias']}, \"\n",
    "#     f\"LIF Add at First: {loaded_hyperparameters['lif_add_at_first']}, TIME: {loaded_hyperparameters['TIME']}, Seed: {loaded_hyperparameters['my_seed']}, Best ACC: {max_acc:.2f}%\"\n",
    "# )\n",
    "\n",
    "# # 데이터 리스트와 라벨 설정 (Loss 제외)\n",
    "# data_list = [\n",
    "#     (\"Mean Cluster Accuracy (During Training Cycle)\", mean_cluster_accuracy_during_training_cycle_all_dataset_history),\n",
    "#     (\"Mean Cluster Accuracy (Post Training Cycle)\", mean_cluster_accuracy_post_training_cycle_all_dataset_history),\n",
    "#     (\"Mean Cluster Accuracy (Total)\", mean_cluster_accuracy_total_all_dataset_history),\n",
    "# ]\n",
    "\n",
    "# # 플롯 생성\n",
    "# fig, ax1 = plt.subplots(figsize=(12, 8))\n",
    "\n",
    "# # 첫 번째 y축: Accuracy 관련 데이터\n",
    "# for label, data in data_list:\n",
    "#     epochs, values = zip(*data)  # epoch, value 분리\n",
    "#     ax1.plot(epochs, values, label=label)\n",
    "\n",
    "# ax1.set_xlabel(\"Epoch\")\n",
    "# ax1.set_ylabel(\"Clurstering Accuracy [%]\", color=\"blue\")\n",
    "# ax1.tick_params(axis=\"y\", labelcolor=\"blue\")\n",
    "# ax1.legend(loc=\"center right\")\n",
    "# ax1.grid(True)\n",
    "\n",
    "# # x축을 정수만 표시하도록 설정\n",
    "# ax1.xaxis.set_major_locator(MaxNLocator(integer=True))\n",
    "\n",
    "# # 두 번째 y축: Loss History\n",
    "# ax2 = ax1.twinx()\n",
    "# epochs, values = zip(*loss_history)\n",
    "# ax2.plot(epochs, values, label=\"AE Loss History\", color=\"red\", linestyle=\"--\")\n",
    "# ax2.set_ylabel(\"Loss\", color=\"red\")\n",
    "# ax2.tick_params(axis=\"y\", labelcolor=\"red\")\n",
    "# ax2.legend(loc=\"center left\")\n",
    "\n",
    "# # 제목 추가\n",
    "# plt.title(title, fontsize=10)\n",
    "# plt.tight_layout()\n",
    "# plt.savefig(f'net_save/{current_time}', dpi=300, bbox_inches=\"tight\")  # dpi=300은 고해상도로 저장, bbox_inches=\"tight\"는 여백 최소화\n",
    "# plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# 데이터셋\n",
    "filename_for_plot = [\n",
    "    \"Easy1_noise05\", \"Easy1_noise10\", \"Easy1_noise15\", \"Easy1_noise20\",\n",
    "    \"Easy2_noise05\", \"Easy2_noise10\", \"Easy2_noise15\", \"Easy2_noise20\",\n",
    "    \"Difficult1_noise05\", \"Difficult1_noise10\", \"Difficult1_noise15\", \"Difficult1_noise20\",\n",
    "    \"Difficult2_noise05\", \"Difficult2_noise10\", \"Difficult2_noise15\", \"Difficult2_noise20\"\n",
    "]\n",
    "\n",
    "# Accuracy 데이터\n",
    "ANN_conv_accracy_set= [0.97935368, 0.97682709, 0.97028784, 0.96461825, 0.97524752, 0.95803571\n",
    ", 0.95746785, 0.92628774, 0.965412,  0.97805344, 0.94869403, 0.92110454\n",
    ", 0.96784232, 0.97551789, 0.91538462, 0.84446478]\n",
    "SNN_fc_accuracy_set = [0.97114475, 0.97643732, 0.84400578, 0.78977821, 0.96616915, 0.92830189\n",
    ", 0.86176032, 0.31984948, 0.80635401, 0.88769531, 0.61003861, 0.60377358\n",
    ", 0.9592668,  0.92870999, 0.78333333, 0.67271859]\n",
    "SNN_conv_accuracy_set = [0.97445601, 0.97737983, 0.97063072, 0.95998071, 0.96268657, 0.90566038\n",
    ", 0.82545997, 0.68391345, 0.96116994, 0.92138672, 0.80694981, 0.49602781\n",
    ", 0.83604888, 0.70611057, 0.69313725, 0.5819398 ]\n",
    "\n",
    "# 평균 계산\n",
    "average_ANN_conv = np.mean(ANN_conv_accracy_set)\n",
    "average_SNN_fc = np.mean(SNN_fc_accuracy_set)\n",
    "average_SNN_conv = np.mean(SNN_conv_accuracy_set)\n",
    "\n",
    "# 데이터 준비\n",
    "accuracies = np.array([ANN_conv_accracy_set, SNN_fc_accuracy_set, SNN_conv_accuracy_set])\n",
    "averages = np.array([average_ANN_conv, average_SNN_fc, average_SNN_conv])\n",
    "\n",
    "# 시각화\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "\n",
    "# 각 모델의 정확도 플롯\n",
    "ax.plot(accuracies[0], label='ANN Conv', marker='o', linestyle='-', color='blue')\n",
    "ax.plot(accuracies[1], label='SNN FC', marker='o', linestyle='-', color='green')\n",
    "ax.plot(accuracies[2], label='SNN Conv', marker='o', linestyle='-', color='red')\n",
    "\n",
    "# 평균값 플롯\n",
    "ax.axhline(y=average_ANN_conv, color='blue', linestyle='--', label=f'Average ANN Conv: {average_ANN_conv:.3f}')\n",
    "ax.axhline(y=average_SNN_fc, color='green', linestyle='--', label=f'Average SNN FC: {average_SNN_fc:.3f}')\n",
    "ax.axhline(y=average_SNN_conv, color='red', linestyle='--', label=f'Average SNN Conv: {average_SNN_conv:.3f}')\n",
    "\n",
    "# 레이블 추가\n",
    "ax.set_xticks(np.arange(len(filename_for_plot)))\n",
    "ax.set_xticklabels(filename_for_plot, rotation=45, ha='right')\n",
    "ax.set_ylabel('Accuracy')\n",
    "ax.set_title('Accuracy Comparison of Models on Datasets')\n",
    "ax.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import matplotlib.pyplot as plt\n",
    "import os  # 파일 경로 처리를 위한 모듈\n",
    "\n",
    "# CSV 파일 경로\n",
    "# csv_file_path = \"/home/bhkim003/github_folder/ByeonghyeonKim/my_snn/ae_test_deprecated/250115/sweep0_vth_mul.csv\" # vth_mul해서 sweep 돌린거\n",
    "csv_file_path = \"/home/bhkim003/github_folder/ByeonghyeonKim/my_snn/ae_test_deprecated/250115/sweep1.csv\"  #vth_mul안한거\n",
    "\n",
    "# 결과를 저장할 리스트\n",
    "tuple_list = []\n",
    "\n",
    "# CSV 파일 읽기\n",
    "with open(csv_file_path, 'r') as file:\n",
    "    reader = csv.DictReader(file)\n",
    "    for row in reader:\n",
    "        try:\n",
    "            # v_threshold, TIME, v_reset, converted_k_means_acc 값을 가져와 튜플로 변환\n",
    "            v_threshold = float(row[\"v_threshold\"])\n",
    "            time = int(row[\"TIME\"])\n",
    "            v_reset = int(row[\"v_reset\"])\n",
    "            converted_k_means_acc = float(row[\"converted_k_means_acc\"]) if row[\"converted_k_means_acc\"] else None\n",
    "\n",
    "            # 튜플 형태로 추가 (값이 None일 경우 처리할 수도 있음)\n",
    "            tuple_list.append((v_threshold, time, v_reset, converted_k_means_acc))\n",
    "        except ValueError as e:\n",
    "            print(f\"Error processing row {row}: {e}\")\n",
    "\n",
    "# 데이터를 TIME 기준으로 정렬\n",
    "tuple_list.sort(key=lambda x: x[1])  # TIME을 기준으로 오름차순 정렬\n",
    "\n",
    "# reset 방식에 따라 데이터를 나누기\n",
    "soft_reset = [t for t in tuple_list if t[2] == 0]\n",
    "hard_reset = [t for t in tuple_list if t[2] == 10000]\n",
    "\n",
    "# reset 방식과 v_threshold에 따라 색상 설정\n",
    "def plot_data(data, label_prefix, marker):\n",
    "    for v_threshold in [1.0]:  # v_threshold 기준으로 제한\n",
    "        filtered_data = [(t[1], t[3]) for t in data if t[0] == v_threshold]\n",
    "        if filtered_data:  # 해당 v_threshold 데이터가 있을 경우만 플롯\n",
    "            times, accuracies = zip(*filtered_data)  # x축(TIME), y축(converted_k_means_acc)\n",
    "            \n",
    "            plt.plot(\n",
    "                times,\n",
    "                accuracies,\n",
    "                marker,\n",
    "                label=f\"{label_prefix}, v_threshold={v_threshold}\",\n",
    "                linestyle=\"--\",\n",
    "            )\n",
    "            # 각 점에 accuracy 표시\n",
    "            for time, acc in filtered_data:\n",
    "                if acc == None:\n",
    "                    continue\n",
    "                plt.text(time, acc, f\"{acc:.2f}\", fontsize=8, ha=\"right\")\n",
    "\n",
    "# 그래프 초기화\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "# soft_reset (v_reset=0) 데이터 플롯\n",
    "plot_data(soft_reset, \"Soft Reset\", \"o\")\n",
    "\n",
    "# hard_reset (v_reset=10000) 데이터 플롯\n",
    "plot_data(hard_reset, \"Hard Reset\", \"x\")\n",
    "\n",
    "# baseline accuracy 가로선 추가\n",
    "baseline_accuracy = 94.43\n",
    "plt.axhline(y=baseline_accuracy, color=\"red\", linestyle=\"-\", label=f\"Baseline Accuracy ({baseline_accuracy}%)\")\n",
    "# baseline 텍스트 추가\n",
    "plt.text(\n",
    "    2000,  # x축 위치 (그래프 오른쪽 끝)\n",
    "    baseline_accuracy + 0.4,  # y축 위치 (baseline 위 약간)\n",
    "    f\"ANN Baseline ({baseline_accuracy}%)\",\n",
    "    color=\"red\",\n",
    "    fontsize=10,\n",
    "    ha=\"center\",\n",
    ")\n",
    "\n",
    "# CSV 파일 이름 가져오기\n",
    "csv_file_name = os.path.basename(csv_file_path)\n",
    "\n",
    "# 그래프 세부 설정\n",
    "plt.title(f\"Converted SNN K-Means Accuracy vs TIME STEP - {csv_file_name}\")\n",
    "plt.xlabel(\"TIME STEP\")\n",
    "plt.ylabel(\"Converted K-Means Accuracy [%]\")\n",
    "plt.legend(loc=\"lower right\")  # 범례를 오른쪽 아래로 이동\n",
    "plt.grid(True)\n",
    "\n",
    "# 그래프 출력\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aedat2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
