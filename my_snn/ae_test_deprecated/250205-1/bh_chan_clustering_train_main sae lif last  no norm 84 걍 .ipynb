{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ssp.train.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x600 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import torch   \n",
    "import torch.nn as nn \n",
    "import torch.nn.functional as F   \n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import torch.optim as optim\n",
    "from scipy import io\n",
    "import itertools\n",
    "import math\n",
    "import datetime\n",
    "import wandb\n",
    "import pickle\n",
    "import json\n",
    "import time\n",
    "import sys\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import accuracy_score\n",
    "from scipy.optimize import linear_sum_assignment\n",
    "from snntorch import spikegen\n",
    "\n",
    "\n",
    "# my module import\n",
    "from modules import *\n",
    "\n",
    "# modules 폴더에 새모듈.py 만들면\n",
    "# modules/__init__py 파일에 form .새모듈 import * 하셈\n",
    "# 그리고 새모듈.py에서 from modules.새모듈 import * 하셈"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cluster_train_system( \n",
    "    gpu = '4',\n",
    "    Conv_net = True,\n",
    "    SAE_net = True,\n",
    "\n",
    "    # hyperparameter\n",
    "    dataset_num = 16,\n",
    "    spike_length = 50,\n",
    "    num_cluster = 4,  # 클러스터 수 설정 # 논문엔 4개라는데 여기서는 3개로 했네\n",
    "    training_cycle = 2400, # 그 초기 몇개까지만 cluster update할지\n",
    "\n",
    "\n",
    "    batch_size = 32,\n",
    "    max_epoch = 7000,\n",
    "    learning_rate = 0.001,\n",
    "    normalize_on = False, # True or False #이거 안 씀 # 이거 별로 안 좋은 normalize같음 # 쓸 거면 다른 거 써라.\n",
    "    need_bias = False,\n",
    "    # first_layer_no_train = False\n",
    "    lif_add_at_first = False,\n",
    "    my_seed = 42,\n",
    "\n",
    "    TIME = 10, # SAE일 때만 유효\n",
    "    v_decay = 0.5,\n",
    "    v_threshold = 0.5,\n",
    "    v_reset = 10000.0, # 10000이상 일 시 hard reset\n",
    "    BPTT_on = True,\n",
    "\n",
    "    SAE_hidden_nomean = True,\n",
    "    current_time = '20250101_210938_786',\n",
    "\n",
    "    optimizer = 'Adam',\n",
    "    coarse_com_mode = True,\n",
    "    coarse_com_config = (2.0, -2.0), # (max, min)\n",
    "\n",
    "    sae_l2_norm_bridge = True,\n",
    "    sae_lif_bridge = False,\n",
    "\n",
    "    accuracy_check_epoch_term = 5,\n",
    "    \n",
    "    lif_add_at_last = False,\n",
    "\n",
    "    two_channel_input = False,\n",
    "\n",
    "    lateral_feature_num = 4,\n",
    "\n",
    "    lc_adc_on = False, \n",
    "\n",
    "    converted_net_forward = False,\n",
    "\n",
    "    pretrained_net = None, \n",
    "\n",
    "    vth_mul_on = False,\n",
    "    batch_norm_on = False,\n",
    "\n",
    "    l2_norm_loss_weight = 0.0,\n",
    "\n",
    "    QCFS_neuron_on = False,\n",
    "\n",
    "    quantize_level_num = 0,\n",
    "\n",
    "    fusion_net = False, # True False\n",
    "    repeat_coding = False,\n",
    "    ):\n",
    "    if coarse_com_mode == True:\n",
    "        assert coarse_com_config[0] > coarse_com_config[1], 'coarse_com_config[0] > coarse_com_config[1]이어야 함'\n",
    "        assert SAE_net == True, 'coarse_com_mode는 SAE_net이 True일 때만 가능'\n",
    "    if two_channel_input == True:\n",
    "        assert Conv_net and coarse_com_mode, 'two_channel_input는 Conv_net이 True일 때만 가능'\n",
    "    if lc_adc_on == True:\n",
    "        assert coarse_com_mode and SAE_net, 'lc_adc_on은 coarse_com_mode와 SAE_net이 True일 때만 가능'\n",
    "    if converted_net_forward == True:\n",
    "        assert SAE_net == False, 'converted_net_forward는 SAE_net이 False일 때만 가능'\n",
    "    seed_assign(my_seed)\n",
    "    ## 함수 내 모든 로컬 변수 저장 ########################################################\n",
    "    hyperparameters = locals()\n",
    "    print(hyperparameters)\n",
    "    # JSON으로 저장\n",
    "    with open(f\"result_save/cluster_accuracy_history_{current_time}.json\", 'w') as f:\n",
    "        json.dump(hyperparameters, f, indent=4)\n",
    "    ######################################################################################\n",
    "\n",
    "    \n",
    "    wandb.config.update(hyperparameters)\n",
    "    wandb.run.name = f'{current_time}_SAE_net_{SAE_net}_v_threshold_{v_threshold}'\n",
    "    wandb.define_metric(\"best_mean_cluster_accuracy_post_training_cycle_all_dataset2\", summary=\"max\")\n",
    "\n",
    "\n",
    "    my_path_ground_BH = '/data2/spike_sorting/quiroga/BH/'\n",
    "\n",
    "\n",
    "    filename = [\"C_Easy1_noise005.mat\", \"C_Easy1_noise01.mat\", \"C_Easy1_noise015.mat\", \"C_Easy1_noise02.mat\",\n",
    "                \"C_Easy2_noise005.mat\", \"C_Easy2_noise01.mat\", \"C_Easy2_noise015.mat\", \"C_Easy2_noise02.mat\",\n",
    "                \"C_Difficult1_noise005.mat\", \"C_Difficult1_noise01.mat\", \"C_Difficult1_noise015.mat\", \"C_Difficult1_noise02.mat\",\n",
    "                \"C_Difficult2_noise005.mat\", \"C_Difficult2_noise01.mat\", \"C_Difficult2_noise015.mat\", \"C_Difficult2_noise02.mat\"]\n",
    "\n",
    "\n",
    "    spike_tot = [\"BH_Spike_e1n005.npy\", \"BH_Spike_e1n010.npy\", \"BH_Spike_e1n015.npy\", \"BH_Spike_e1n020.npy\",\n",
    "                \"BH_Spike_e2n005.npy\", \"BH_Spike_e2n010.npy\", \"BH_Spike_e2n015.npy\", \"BH_Spike_e2n020.npy\",\n",
    "                \"BH_Spike_d1n005.npy\", \"BH_Spike_d1n010.npy\", \"BH_Spike_d1n015.npy\", \"BH_Spike_d1n020.npy\",\n",
    "                \"BH_Spike_d2n005.npy\", \"BH_Spike_d2n010.npy\", \"BH_Spike_d2n015.npy\", \"BH_Spike_d2n020.npy\"]\n",
    "\n",
    "    label_tot = [\"BH_Label_e1n005.npy\", \"BH_Label_e1n010.npy\", \"BH_Label_e1n015.npy\", \"BH_Label_e1n020.npy\",\n",
    "                \"BH_Label_e2n005.npy\", \"BH_Label_e2n010.npy\", \"BH_Label_e2n015.npy\", \"BH_Label_e2n020.npy\",\n",
    "                \"BH_Label_d1n005.npy\", \"BH_Label_d1n010.npy\", \"BH_Label_d1n015.npy\", \"BH_Label_d1n020.npy\",\n",
    "                \"BH_Label_d2n005.npy\", \"BH_Label_d2n010.npy\", \"BH_Label_d2n015.npy\", \"BH_Label_d2n020.npy\"]\n",
    "\n",
    "    template =  [\"BH_Spike_TEMPLATE_e1n005.npy\", \"BH_Spike_TEMPLATE_e1n010.npy\", \"BH_Spike_TEMPLATE_e1n015.npy\", \"BH_Spike_TEMPLATE_e1n020.npy\",\n",
    "                \"BH_Spike_TEMPLATE_e2n005.npy\", \"BH_Spike_TEMPLATE_e2n010.npy\", \"BH_Spike_TEMPLATE_e2n015.npy\", \"BH_Spike_TEMPLATE_e2n020.npy\",\n",
    "                \"BH_Spike_TEMPLATE_d1n005.npy\", \"BH_Spike_TEMPLATE_d1n010.npy\", \"BH_Spike_TEMPLATE_d1n015.npy\", \"BH_Spike_TEMPLATE_d1n020.npy\",\n",
    "                \"BH_Spike_TEMPLATE_d2n005.npy\", \"BH_Spike_TEMPLATE_d2n010.npy\", \"BH_Spike_TEMPLATE_d2n015.npy\", \"BH_Spike_TEMPLATE_d2n020.npy\"]\n",
    "\n",
    "    AE_train_path_gt_detect = 'BH_quiroga_training_dataset_gt_detect.pt' \n",
    "    AE_test_path_gt_detect = 'BH_quiroga_test_dataset_gt_detect.pt'\n",
    "\n",
    "    AE_train_path_real_detect = 'BH_quiroga_training_dataset_real_detect.pt'\n",
    "    AE_test_path_real_detect = 'BH_quiroga_test_dataset_real_detect.pt'\n",
    "\n",
    "    AE_train_data = AE_train_path_real_detect #AE_train_path_gt_detect #AE_train_path_real_detect\n",
    "    AE_test_data = AE_test_path_real_detect #AE_test_path_gt_detect  #AE_test_path_real_detect\n",
    "\n",
    "    # thr_tot = np.array([0.5, 0.5, 0.55, 0.7, 0.5, 0.5, 0.55, 0.7, 0.5, 0.5, 0.55, 0.7, 0.5, 0.5, 0.55, 0.7])\n",
    "    cos_thr = np.array([0.95, 0.95, 0.95, 0.95, 0.95, 0.95, 0.95, 0.85, 0.95, 0.9, 0.8, 0.95, 0.95, 0.95, 0.95, 0.8])\n",
    "    # tem=10\n",
    "    # cos_thr = np.array([tem, tem, tem, tem, tem, tem, tem, tem, tem, tem, tem, tem, tem, tem, tem, tem, ])\n",
    "\n",
    "    print('cos_thr', cos_thr)\n",
    "    \n",
    "    os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\" \n",
    "    os.environ[\"CUDA_VISIBLE_DEVICES\"]= gpu\n",
    "\n",
    "\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "\n",
    "    if coarse_com_mode == True:\n",
    "        level_num = TIME\n",
    "        TIME = spike_length\n",
    "        spike_length = level_num\n",
    "        level_interval = (coarse_com_config[0] - coarse_com_config[1]) / (level_num-1)  # max - min\n",
    "        levels = [coarse_com_config[1] + level_interval * i for i in range(level_num)]\n",
    "        levels = torch.tensor(levels).to(torch.float).to(device)\n",
    "        levels = levels.repeat(TIME,1) \n",
    "        # print('levels', levels, levels.shape) # TIME, level_num\n",
    "\n",
    "    n_sample = spike_length\n",
    "\n",
    "    class spikedataset(Dataset):\n",
    "        def __init__(self, path, transform = None):    \n",
    "            self.transform = transform\n",
    "            self.spike = torch.load(path)\n",
    "            \n",
    "        def __getitem__(self, index):\n",
    "            spike = self.spike[index]            \n",
    "            if self.transform is not None:\n",
    "                spike = self.transform(spike)\n",
    "            return spike\n",
    "        \n",
    "        def __len__(self):\n",
    "            return len(self.spike)\n",
    "\n",
    "    train_dataset = spikedataset(my_path_ground_BH + AE_train_data)\n",
    "    train_loader = DataLoader(dataset = train_dataset, batch_size = batch_size, shuffle = True)\n",
    "\n",
    "    test_dataset = spikedataset(my_path_ground_BH + AE_test_data)\n",
    "    test_loader = DataLoader(dataset = test_dataset, batch_size = batch_size, shuffle = False)\n",
    "\n",
    "\n",
    "    # vth_mul_on = True # True False\n",
    "    # batch_norm_on = True # True False\n",
    "\n",
    "\n",
    "    # 모델 초기화\n",
    "    if SAE_net == False: # 여기서는 l2norm, lif bridge 둘 다 true면 l2norm먼저\n",
    "        if Conv_net == True:\n",
    "            input_channels = 2 if two_channel_input else 1\n",
    "            if fusion_net == True:\n",
    "                net = FUSION_net_conv1(input_channels=input_channels, input_length=n_sample, encoder_ch = [32, 64, 96], fc_dim = lateral_feature_num, padding = 0, stride = 2, kernel_size = 3, \n",
    "                                    synapse_fc_trace_const1=1, \n",
    "                                    synapse_fc_trace_const2=v_decay, #안씀 \n",
    "                                    TIME=TIME, v_init=0.0, v_decay=v_decay, v_threshold=v_threshold, v_reset=v_reset, \n",
    "                                    sg_width=4.0, surrogate='sigmoid', BPTT_on=BPTT_on, need_bias=need_bias, lif_add_at_first=lif_add_at_first,\n",
    "                                    sae_l2_norm_bridge = sae_l2_norm_bridge, sae_lif_bridge = sae_lif_bridge, lif_add_at_last=lif_add_at_last, repeat_coding=repeat_coding).to(device)\n",
    "            else: \n",
    "                net = Autoencoder_conv1(input_channels=input_channels, input_length=n_sample, encoder_ch = [32, 64, 96], fc_dim = lateral_feature_num, padding = 0, stride = 2, kernel_size = 3, need_bias=need_bias, l2norm_bridge=sae_l2_norm_bridge, relu_bridge=sae_lif_bridge, activation_collector_on=False,\n",
    "                                        batch_norm_on=batch_norm_on, QCFS_neuron_on=QCFS_neuron_on).to(device)\n",
    "            net = torch.nn.DataParallel(net)\n",
    "            if converted_net_forward:\n",
    "                converted_net = SAE_converted_conv1(input_channels=input_channels, input_length=n_sample, encoder_ch = [32, 64, 96], fc_dim = lateral_feature_num, padding = 0, stride = 2, kernel_size = 3, \n",
    "                                    synapse_fc_trace_const1=1, \n",
    "                                    synapse_fc_trace_const2=v_decay, #안씀 \n",
    "                                    TIME=TIME, v_init=0.0, v_decay=v_decay, v_threshold=v_threshold, v_reset=v_reset, \n",
    "                                    sg_width=4.0, surrogate='sigmoid', BPTT_on=BPTT_on, need_bias=need_bias, lif_add_at_first=lif_add_at_first,\n",
    "                                    sae_l2_norm_bridge = sae_l2_norm_bridge, sae_lif_bridge = sae_lif_bridge, lif_add_at_last=lif_add_at_last,\n",
    "                                    vth_mul_on=vth_mul_on, batch_norm_on=batch_norm_on).to(device) # lif bridge는 무조건 들어가게 해놨음.\n",
    "                converted_net = torch.nn.DataParallel(converted_net)\n",
    "                print('converted_net', converted_net)\n",
    "        else:\n",
    "            net = Autoencoder_only_FC(encoder_ch=[400, lateral_feature_num], decoder_ch=[400,n_sample], n_sample=n_sample, need_bias=need_bias, l2norm_bridge=sae_l2_norm_bridge, relu_bridge=sae_lif_bridge, activation_collector_on=False,\n",
    "                                    batch_norm_on=batch_norm_on, QCFS_neuron_on=QCFS_neuron_on).to(device)\n",
    "            net = torch.nn.DataParallel(net)\n",
    "            if converted_net_forward:\n",
    "                converted_net = SAE_converted_fc(encoder_ch=[400, lateral_feature_num], \n",
    "                                    decoder_ch=[400, n_sample], \n",
    "                                    in_channels=n_sample, # in_channel 이 여기선 걍 lenght.\n",
    "                                    synapse_fc_trace_const1=1,\n",
    "                                    synapse_fc_trace_const2=v_decay,  #안씀 \n",
    "                                    TIME=TIME, v_init=0.0, v_decay=v_decay, v_threshold=v_threshold, v_reset=v_reset, \n",
    "                                    sg_width=4.0, surrogate='sigmoid', BPTT_on=BPTT_on, need_bias=need_bias, lif_add_at_first=lif_add_at_first,\n",
    "                                    sae_l2_norm_bridge = sae_l2_norm_bridge, sae_lif_bridge = sae_lif_bridge, lif_add_at_last=lif_add_at_last,\n",
    "                                    vth_mul_on=vth_mul_on, batch_norm_on=batch_norm_on).to(device) # lif bridge는 무조건 들어가게 해놨음.\n",
    "                converted_net = torch.nn.DataParallel(converted_net)\n",
    "                # print('converted_net', converted_net)\n",
    "    else: # 여기서는 l2norm, lif bridge 둘 다 true면 lif또는 relu먼저\n",
    "        if Conv_net == True: \n",
    "            input_channels = 2 if two_channel_input else 1\n",
    "            net = SAE_conv1(input_channels=input_channels, input_length=n_sample, encoder_ch = [32, 64, 96], fc_dim = lateral_feature_num, padding = 0, stride = 2, kernel_size = 3, \n",
    "                                synapse_fc_trace_const1=1, \n",
    "                                synapse_fc_trace_const2=v_decay, #안씀 \n",
    "                                TIME=TIME, v_init=0.0, v_decay=v_decay, v_threshold=v_threshold, v_reset=v_reset, \n",
    "                                sg_width=4.0, surrogate='sigmoid', BPTT_on=BPTT_on, need_bias=need_bias, lif_add_at_first=lif_add_at_first,\n",
    "                                sae_l2_norm_bridge = sae_l2_norm_bridge, sae_lif_bridge = sae_lif_bridge, lif_add_at_last=lif_add_at_last, batch_norm_on=batch_norm_on).to(device)\n",
    "            net = torch.nn.DataParallel(net)\n",
    "        else:\n",
    "            net = SAE_fc_only(encoder_ch=[400, lateral_feature_num], \n",
    "                                decoder_ch=[400, n_sample], \n",
    "                                in_channels=n_sample, # in_channel 이 여기선 걍 lenght.\n",
    "                                synapse_fc_trace_const1=1,\n",
    "                                synapse_fc_trace_const2=v_decay,  #안씀 \n",
    "                                TIME=TIME, v_init=0.0, v_decay=v_decay, v_threshold=v_threshold, v_reset=v_reset, \n",
    "                                sg_width=4.0, surrogate='sigmoid', BPTT_on=BPTT_on, need_bias=need_bias, lif_add_at_first=lif_add_at_first,\n",
    "                                sae_l2_norm_bridge = sae_l2_norm_bridge, sae_lif_bridge = sae_lif_bridge, lif_add_at_last=lif_add_at_last, batch_norm_on=batch_norm_on).to(device)\n",
    "            net = torch.nn.DataParallel(net)\n",
    "\n",
    "    # net = torch.load('/home/bhkim003/github_folder/ByeonghyeonKim/my_snn/net_save/save_now_net_AE_re_e7000.pth')\n",
    "    # net = torch.load('/home/bhkim003/github_folder/ByeonghyeonKim/my_snn/net_save/save_now_net_20250101_210938_786.pth')\n",
    "    # load했으면 torch.nn.DataParallel 하지마\n",
    "    # net.module.load_state_dict(torch.load('/home/bhkim003/github_folder/ByeonghyeonKim/my_snn/net_save/save_now_net_annbase_20250108_210641_941.pth'))\n",
    "    if pretrained_net != None:\n",
    "        ######################## 모델이 달라서 dict로 weight만 넣고싶을 때\n",
    "        # # 저장된 가중치 로드\n",
    "        saved_state_dict = torch.load(pretrained_net)\n",
    "        current_state_dict = net.module.state_dict()\n",
    "\n",
    "        # 함수 호출로 가중치 매핑\n",
    "        updated_state_dict = map_and_load_weights(saved_state_dict, current_state_dict)\n",
    "\n",
    "        # 업데이트된 state_dict를 네트워크에 로드\n",
    "        net.module.load_state_dict(updated_state_dict)\n",
    "        ######################## 모델이 달라서 dict로 weight만 넣고싶을 때\n",
    "\n",
    "        ############## 일반적일 때\n",
    "        # net.module.load_state_dict(torch.load(pretrained_net))\n",
    "        ############## 일반적일 때\n",
    "    \n",
    "        # pre_net = Autoencoder_conv1(input_channels=input_channels, input_length=n_sample, encoder_ch = [32, 64, 96], fc_dim = lateral_feature_num, padding = 0, stride = 2, kernel_size = 3, need_bias=need_bias, l2norm_bridge=sae_l2_norm_bridge, relu_bridge=sae_lif_bridge, activation_collector_on=False,\n",
    "        #                         batch_norm_on=batch_norm_on, QCFS_neuron_on=False).to(device)\n",
    "        # pre_net = torch.nn.DataParallel(net)\n",
    "        # pre_net.module.load_state_dict(torch.load(pretrained_net))\n",
    "        # copy_weights(pre_net.module.encoder , net.module.encoder )\n",
    "        # copy_weights(pre_net.module.decoder , net.module.decoder  )\n",
    "\n",
    "        \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    wandb.watch(net, log=\"all\", log_freq = 10)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    if SAE_net == True:\n",
    "        assert 'SAE' in net.module.__class__.__name__\n",
    "\n",
    "\n",
    "\n",
    "    net = net.to(device)\n",
    "    print(f\"Total number of encoder parameters: {sum(p.numel() for p in net.module.encoder.parameters())}\")\n",
    "    print(net)\n",
    "    print('Device:',device)\n",
    "\n",
    "    \n",
    "    if optimizer == 'Adam':\n",
    "        optimizer = optim.Adam(net.parameters(), lr=learning_rate)\n",
    "    elif optimizer == 'SGD':\n",
    "        optimizer = optim.SGD(net.parameters(), lr = learning_rate, momentum = 0.9)\n",
    "    else:\n",
    "        assert False, 'optimizer를 잘못 입력했습니다.'\n",
    "        \n",
    "    loss_history = []\n",
    "    mean_cluster_accuracy_during_training_cycle_all_dataset_history = []\n",
    "    mean_cluster_accuracy_post_training_cycle_all_dataset_history = []\n",
    "    mean_cluster_accuracy_total_all_dataset_history = []\n",
    "\n",
    "    tau = np.zeros(num_cluster)\n",
    "\n",
    "    print(f\"\\nStart Training, current_time = {current_time}\")\n",
    "    mean_cluster_accuracy_post_training_cycle_all_dataset = 0\n",
    "    best_mean_cluster_accuracy_post_training_cycle_all_dataset = 0\n",
    "\n",
    "    if SAE_net == True:\n",
    "        assert 'SAE' in net.module.__class__.__name__\n",
    "        \n",
    "    k_means_acc_best = 0\n",
    "    for epoch in range(max_epoch):\n",
    "        print()\n",
    "        l2_loss_bin= 0\n",
    "        ae_train_start_time = time.time()\n",
    "        running_loss = 0.0\n",
    "        running_loss_normal = 0.0\n",
    "        running_loss_coarse = 0.0\n",
    "        iter = 0\n",
    "        net.train()\n",
    "        # if True or max_epoch != 1:\n",
    "        if max_epoch != 1:\n",
    "            for data in train_loader:\n",
    "                optimizer.zero_grad()\n",
    "                data = data.to(device)\n",
    "                data = zero_to_one_normalize_features(data, level_num=quantize_level_num) if normalize_on else data\n",
    "                spike_backup = data\n",
    "                spike = data\n",
    "                spike = spike.to(device) # batch, feature\n",
    "                if coarse_com_mode == True and 'SAE' in net.module.__class__.__name__:\n",
    "                    spike = spike.unsqueeze(2).repeat(1, 1, level_num) # spike_length == level_num # (batch, time, feature)로 변환 \n",
    "                    spike = (spike > levels).to(torch.float) \n",
    "\n",
    "                    spike = (spike == 0).cumsum(dim=-1).eq(1).to(torch.float) if lc_adc_on == True else spike\n",
    "\n",
    "                    # spike: batch, time, level_num\n",
    "                    # levels: time, level_num\n",
    "                    if Conv_net == True:\n",
    "                        spike = spike.unsqueeze(-2) # batch, time, in_channel, feature or batch in_channel,feature\n",
    "                        if two_channel_input == True:\n",
    "                            spike_backup = spike_backup.to(device)\n",
    "                            spike_backup = spike_backup.unsqueeze(2).repeat(1, 1, level_num) # spike_length == level_num # (batch, time, feature)로 변환 \n",
    "                            spike_backup = (spike_backup <= levels).to(torch.float) \n",
    "                            spike_backup = (spike_backup == 1).cumsum(dim=-1).eq(1).to(torch.float) if lc_adc_on == True else spike_backup\n",
    "                            spike_backup = spike_backup.unsqueeze(-2)\n",
    "                            spike = torch.cat((spike, spike_backup), dim=-2)\n",
    "                    assert spike.shape[0] == batch_size and spike.shape[1] == TIME\n",
    "                elif 'SAE' in net.module.__class__.__name__:\n",
    "                    spike = spike.unsqueeze(-1).repeat(1, 1, TIME).permute(0,2,1) # (batch, time, feature)로 변환\n",
    "                    if Conv_net == True:\n",
    "                        spike = spike.unsqueeze(-2) # batch, time, in_channel, feature or batch in_channel,feature\n",
    "                else:\n",
    "                    if Conv_net == True:\n",
    "                        spike = spike.unsqueeze(-2) #batch in_channel,feature\n",
    "                    # if fusion_net == True:\n",
    "                    #     spike = spikegen.rate(spike, num_steps=TIME).transpose(0, 1)\n",
    "\n",
    "                # for i in range (3):\n",
    "                #     plot_spike(spike[i,:,0,:].cpu().numpy())\n",
    "                #     plot_spike(spike[i,:,1,:].cpu().numpy())\n",
    "                # assert False\n",
    "                        \n",
    "                # spike_class = net(spike) # batch, time, feature\n",
    "                encoded_spike = net.module.encoder(spike)\n",
    "                spike_class = net.module.decoder(encoded_spike)\n",
    "\n",
    "                loss = 0\n",
    "                loss_normal = torch.tensor(0.0)\n",
    "                loss_coarse = torch.tensor(0.0)\n",
    "                if coarse_com_mode == True and 'SAE' in net.module.__class__.__name__:\n",
    "                    criterion = nn.MSELoss().to(device)\n",
    "                    # loss1 = nn.MSELoss()(spike_class[..., 5:25], spike[..., 5:25])\n",
    "                    # loss2 = nn.MSELoss()(spike_class[..., 0:5], spike[..., 0:5])\n",
    "                    # loss3 = nn.MSELoss()(spike_class[..., 25:spike_length], spike[..., 25:spike_length])\n",
    "                    # loss = loss1 * 2.125 + (loss2 + loss3)/4\n",
    "\n",
    "                    # loss1 = nn.MSELoss()(spike_class[..., 5:25, :], spike[..., 5:25, :])\n",
    "                    # loss2 = nn.MSELoss()(spike_class[..., 0:5, :], spike[..., 0:5, :])\n",
    "                    # loss3 = nn.MSELoss()(spike_class[..., 25:spike_length, :], spike[..., 25:spike_length, :])\n",
    "                    # loss = loss1 * 2.125 + (loss2 + loss3)/4\n",
    "\n",
    "                    loss = criterion(spike_class, spike)\n",
    "                elif 'SAE' in net.module.__class__.__name__:\n",
    "                    criterion = nn.MSELoss().to(device)\n",
    "                    loss1 = criterion(spike_class[..., 5:25], spike[..., 5:25])\n",
    "                    loss2 = criterion(spike_class[..., 0:5], spike[..., 0:5])\n",
    "                    loss3 = criterion(spike_class[..., 25:spike_length], spike[..., 25:spike_length])\n",
    "                    loss = loss1 * 2.125 + (loss2 + loss3)/4\n",
    "                    assert spike_length > 25, 'spike_length가 25보다 작음'\n",
    "                else:\n",
    "                    criterion = nn.MSELoss().to(device)\n",
    "                    loss1 = criterion(spike_class[..., 5:25], spike[..., 5:25])\n",
    "                    loss2 = criterion(spike_class[..., 0:5], spike[..., 0:5])\n",
    "                    loss3 = criterion(spike_class[..., 25:spike_length], spike[..., 25:spike_length])\n",
    "                    loss = loss1 * 2.125 + (loss2 + loss3)/4\n",
    "                    assert spike_length > 25, 'spike_length가 25보다 작음'\n",
    "\n",
    "                    if l2_norm_loss_weight > 0:\n",
    "                        assert len(encoded_spike.shape) == 2, 'time 성분 없는 걸로'\n",
    "                        l2_loss = l2_norm_loss(encoded_spike, target_norm=1.0)  # L2Norm Loss 계산, l2 1.0되게.\n",
    "                        loss = loss + l2_loss*l2_norm_loss_weight\n",
    "                        l2_loss_bin += l2_loss.item()\n",
    "\n",
    "                    # coarse loss ######################################################\n",
    "                    loss_normal = criterion(spike_class, spike)\n",
    "                    level_num_in_loss = quantize_level_num\n",
    "                    level_interval = (coarse_com_config[0] - coarse_com_config[1]) / (level_num_in_loss-1)  # max - min\n",
    "                    levels = [coarse_com_config[1] + level_interval * i for i in range(level_num_in_loss)]\n",
    "                    levels = torch.tensor(levels).to(torch.float).to(device)\n",
    "                    levels = levels.repeat(spike_length,1) \n",
    "\n",
    "                    spike = spike.squeeze()\n",
    "                    spike_class = spike_class.squeeze()\n",
    "                    # plot_origin_spike(spike_class[0].cpu().detach().numpy())\n",
    "                    spike = spike.unsqueeze(2).repeat(1, 1, level_num_in_loss) \n",
    "                    spike = (spike > levels).to(torch.float) \n",
    "                    spike_class = spike_class.unsqueeze(2).repeat(1, 1, level_num_in_loss) \n",
    "                    spike_class = (spike_class > levels).to(torch.float) \n",
    "\n",
    "                    loss_coarse = criterion(spike_class, spike)\n",
    "\n",
    "                    # plot_spike(spike_class[0].cpu().detach().numpy())\n",
    "                    # assert False\n",
    "                    # coarse loss ######################################################\n",
    "\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                running_loss += loss.item()\n",
    "                running_loss_normal += loss_normal.item()\n",
    "                running_loss_coarse += loss_coarse.item()\n",
    "                # print(f'\\nepoch-{epoch}, running_loss : {running_loss:.5f}, iter percent {iter/len(train_loader)*100:.2f}%')\n",
    "                iter += 1\n",
    "        else:\n",
    "            print('\\n\\n\\n max_epoch 1이면 Train 안함!!!!!!!!!!!!!!!!!!!!!')\n",
    "        if l2_norm_loss_weight > 0:\n",
    "            print('l2_loss_bin', l2_loss_bin/len(train_loader))\n",
    "        avg_loss = running_loss / len(train_loader)\n",
    "        assert not np.isnan(avg_loss), f\"Error: avg_loss is NaN! Running loss: {running_loss}, Length of train_loader: {len(train_loader)}\"\n",
    "        loss_history.append((epoch, avg_loss))\n",
    "        print(f'\\nepoch-{epoch} loss : {avg_loss:.5f}, loss_normal : {running_loss_normal/len(train_loader):.5f}, loss_coarse : {running_loss_coarse/len(train_loader):.5f}')\n",
    "        print(f\"ae train 실행 시간: {time.time()-ae_train_start_time:.3f}초, 전체 시작 시간 {current_time}\")\n",
    "\n",
    "        # plot_activation_distribution(net)\n",
    "\n",
    "        if SAE_net == False and converted_net_forward == True:\n",
    "            source_encoder = net.module.encoder \n",
    "            target_encoder = converted_net.module.encoder  \n",
    "            copy_weights(source_encoder, target_encoder)\n",
    "\n",
    "        cluster_accuracy_during_training_cycle_all_dataset = np.zeros(dataset_num)\n",
    "        cluster_accuracy_post_training_cycle_all_dataset = np.zeros(dataset_num)\n",
    "        cluster_accuracy_total_all_dataset = np.zeros(dataset_num)    \n",
    "\n",
    "        k_means_acc = 0\n",
    "        converted_k_means_acc = 0\n",
    "        if(epoch % accuracy_check_epoch_term == 0 or epoch == 1 or epoch == max_epoch-1): \n",
    "            accuracy_check_start_time = time.time()\n",
    "            print(f'\\nepoch-{epoch} accuracy check')\n",
    "            k_means_bin_origin_feature = []\n",
    "            k_means_bin = []\n",
    "            converted_k_means_bin = []\n",
    "            for ds in range(dataset_num):\n",
    "                # print('\\n', spike_tot[ds])\n",
    "\n",
    "                spike_template = np.load(my_path_ground_BH + template[ds])\n",
    "                spike = np.load(my_path_ground_BH + spike_tot[ds])\n",
    "                label = np.load(my_path_ground_BH + label_tot[ds])\n",
    "                spike_template = torch.from_numpy(spike_template).to(device)\n",
    "                spike = torch.from_numpy(spike).to(device)\n",
    "                spike_template = zero_to_one_normalize_features(spike_template, level_num=quantize_level_num) if normalize_on else spike_template\n",
    "                spike = zero_to_one_normalize_features(spike, level_num=quantize_level_num) if normalize_on else spike\n",
    "                \n",
    "                hidden_size = lateral_feature_num*TIME if 'SAE' in net.module.__class__.__name__ and SAE_hidden_nomean == True else lateral_feature_num\n",
    "\n",
    "                Cluster = np.zeros((num_cluster, hidden_size))\n",
    "                assert Cluster.shape[-1] == hidden_size, '이거 hidden dim 4 아니게 할 거면 잘 바꿔라'\n",
    "                \n",
    "\n",
    "\n",
    "                net.eval()\n",
    "                with torch.no_grad():\n",
    "                    spike_torch = spike_template.float()\n",
    "                    spike_torch = spike_torch[:num_cluster]\n",
    "                    spike_backup = spike_torch\n",
    "                    spike_torch = spike_torch.to(device)\n",
    "                    if coarse_com_mode == True and 'SAE' in net.module.__class__.__name__:\n",
    "                        spike_torch = spike_torch.unsqueeze(2).repeat(1, 1, level_num) # spike_length == level_num # (batch, time, feature)로 변환 \n",
    "                        spike_torch = (spike_torch > levels).to(torch.float) \n",
    "                        spike_torch = (spike_torch == 0).cumsum(dim=-1).eq(1).to(torch.float) if lc_adc_on == True else spike_torch\n",
    "                        if Conv_net == True:\n",
    "                            spike_torch = spike_torch.unsqueeze(-2) # batch, time, in_channel, feature or batch in_channel,feature\n",
    "                            if two_channel_input == True:\n",
    "                                spike_backup = spike_backup.to(device)\n",
    "                                spike_backup = spike_backup.unsqueeze(2).repeat(1, 1, level_num) # spike_length == level_num # (batch, time, feature)로 변환 \n",
    "                                spike_backup = (spike_backup <= levels).to(torch.float) \n",
    "                                spike_backup = (spike_backup == 1).cumsum(dim=-1).eq(1).to(torch.float) if lc_adc_on == True else spike_backup\n",
    "                                spike_backup = spike_backup.unsqueeze(-2) # batch, time, in_channel, feature\n",
    "                                spike_torch = torch.cat((spike_torch, spike_backup), dim=-2)\n",
    "                    elif 'SAE' in net.module.__class__.__name__:\n",
    "                        spike_torch = spike_torch.unsqueeze(1).repeat(1, TIME, 1) # (batch, time, feature)로 변환\n",
    "                        if Conv_net == True:\n",
    "                            spike_torch = spike_torch.unsqueeze(-2) # batch, time, in_channel, feature or batch in_channel,feature\n",
    "                    else:\n",
    "                        if Conv_net == True:\n",
    "                            spike_torch = spike_torch.unsqueeze(-2) #batch in_channel,feature\n",
    "                        if converted_net_forward == True:\n",
    "                            spike_torch_spikegen = spikegen.rate(spike_torch, num_steps=TIME).transpose(0, 1)\n",
    "                        # if fusion_net == True:\n",
    "                        #     spike_torch = spikegen.rate(spike_torch, num_steps=TIME).transpose(0, 1)\n",
    "                    ### forward #######################################################\n",
    "                    inner_inf = net.module.encoder(spike_torch)\n",
    "                    if SAE_net == False and converted_net_forward == True:\n",
    "                        converted_inner_inf = converted_net.module.encoder(spike_torch_spikegen)\n",
    "                    ### forward #######################################################\n",
    "\n",
    "                    # for i in range(3):\n",
    "                    #     plot_spike(spike_torch[i,:,:].cpu().numpy())\n",
    "                    #     plot_spike(inner_inf[i,:].cpu().numpy())\n",
    "                    #     plot_spike(net.module.decoder(inner_inf)[i,:,:].cpu().numpy())\n",
    "                        \n",
    "                    # if 'SAE' in net.module.__class__.__name__:\n",
    "                    #     tensors = [inner_inf[0][i] for i in range(TIME)] \n",
    "                    #     all_equal = all(torch.equal(tensors[0], t) for t in tensors)\n",
    "                    #     print(all_equal, inner_inf)\n",
    "\n",
    "                    if 'SAE' in net.module.__class__.__name__:\n",
    "                        if SAE_hidden_nomean == True:\n",
    "                            inner_inf = inner_inf.reshape(inner_inf.shape[0],-1)# time*feature 펼치기\n",
    "                        else:\n",
    "                            inner_inf = inner_inf.mean(dim=1)# Time 방향으로 평균\n",
    "\n",
    "                    Cluster = inner_inf.cpu().detach().numpy()\n",
    "\n",
    "                encoder_batch = 128\n",
    "                spike_hidden = np.zeros((len(spike), hidden_size))\n",
    "                converted_spike_hidden = np.zeros((len(spike), hidden_size))\n",
    "                net.eval()\n",
    "                with torch.no_grad():\n",
    "                    now_index = 0\n",
    "                    while (1):\n",
    "                        now_end_index = now_index+encoder_batch if now_index+encoder_batch < len(spike) else len(spike)\n",
    "                        spike_batch = spike[now_index:now_end_index] \n",
    "                        spike_torch = spike_batch\n",
    "                        spike_torch = spike_torch.float()\n",
    "                        spike_backup = spike_torch\n",
    "                        spike_torch = spike_torch.to(device)\n",
    "                        if coarse_com_mode == True and 'SAE' in net.module.__class__.__name__:\n",
    "                            spike_torch = spike_torch.unsqueeze(2).repeat(1, 1, level_num) # spike_length == level_num # (batch, time, feature)로 변환 \n",
    "                            spike_torch = (spike_torch > levels).to(torch.float) \n",
    "                            spike_torch = (spike_torch == 0).cumsum(dim=-1).eq(1).to(torch.float) if lc_adc_on == True else spike_torch\n",
    "                            if Conv_net == True:\n",
    "                                spike_torch = spike_torch.unsqueeze(-2) # batch, time, in_channel, feature or batch in_channel,feature\n",
    "                                if two_channel_input == True:\n",
    "                                    spike_backup = spike_backup.to(device)\n",
    "                                    spike_backup = spike_backup.unsqueeze(2).repeat(1, 1, level_num) # spike_length == level_num # (batch, time, feature)로 변환 \n",
    "                                    spike_backup = (spike_backup <= levels).to(torch.float) \n",
    "                                    spike_backup = (spike_backup == 1).cumsum(dim=-1).eq(1).to(torch.float) if lc_adc_on == True else spike_backup\n",
    "                                    spike_backup = spike_backup.unsqueeze(-2)\n",
    "                                    spike_torch = torch.cat((spike_torch, spike_backup), dim=-2)\n",
    "                        elif 'SAE' in net.module.__class__.__name__:\n",
    "                            spike_torch = spike_torch.unsqueeze(1).repeat(1, TIME, 1) # (batch, time, feature)로 변환\n",
    "                            if Conv_net == True:\n",
    "                                spike_torch = spike_torch.unsqueeze(-2) # batch, time, in_channel, feature or batch in_channel,feature\n",
    "                        else:\n",
    "                            if Conv_net == True:\n",
    "                                spike_torch = spike_torch.unsqueeze(-2) #batch in_channel,feature\n",
    "                            if converted_net_forward == True:\n",
    "                                spike_torch_spikegen = spikegen.rate(spike_torch, num_steps=TIME).transpose(0, 1)\n",
    "                            # if fusion_net == True:\n",
    "                            #     spike_torch = spikegen.rate(spike_torch, num_steps=TIME).transpose(0, 1)\n",
    "                        ### forward #######################################################\n",
    "                        inner_inf = net.module.encoder(spike_torch)\n",
    "                        if SAE_net == False and converted_net_forward == True:\n",
    "                            converted_inner_inf = converted_net.module.encoder(spike_torch_spikegen)\n",
    "                        ### forward #######################################################\n",
    "                            \n",
    "                        if 'SAE' in net.module.__class__.__name__:\n",
    "                            if SAE_hidden_nomean == True:\n",
    "                                inner_inf = inner_inf.reshape(spike_batch.shape[0],-1)# 펼치기\n",
    "                            else:\n",
    "                                inner_inf = inner_inf.mean(dim=1)# Time 방향으로 평균\n",
    "                        spike_hidden[now_index:now_end_index] = inner_inf.cpu().detach().numpy()\n",
    "                        if SAE_net == False and converted_net_forward == True:\n",
    "                            converted_spike_hidden[now_index:now_end_index] = converted_inner_inf.cpu().detach().numpy()\n",
    "                        now_index += encoder_batch\n",
    "                        if (now_index >= len(spike)):\n",
    "                            break\n",
    "                    \n",
    "                spike_id = np.zeros(len(spike))\n",
    "                distance_sm = np.zeros(num_cluster)\n",
    "                tau = np.zeros(num_cluster)\n",
    "                \n",
    "                plot_tau = []\n",
    "                plot_denominator = []\n",
    "                plot_m = []\n",
    "                plot_max_tau = []\n",
    "                for spike_index in range(len(spike)): \n",
    "                    for q in range(num_cluster):\n",
    "                        tau[q] = np.dot(spike_hidden[spike_index, :], Cluster[q, :]) # 이거 l2norm 거쳐서 나온 거니까 분모 1임.\n",
    "                        denominator =  np.linalg.norm(spike_hidden[spike_index, :])*np.linalg.norm(Cluster[q, :]) + 1e-12\n",
    "                        plot_denominator.append(denominator)\n",
    "                        if 'SAE' in net.module.__class__.__name__: # AE 때는 l2norm거쳐서 나와서 괜찮음\n",
    "                            tau[q] = tau[q] / denominator\n",
    "\n",
    "                        plot_tau.append(tau[q])\n",
    "\n",
    "                    # for i in range(num_cluster): # l2 distance\n",
    "                    #     distance_sm[i] = np.sum(np.power(np.abs(Cluster[i] - spike_hidden[spike_index, :]), 2))\n",
    "                    distance_sm = np.sum(np.power(np.abs(Cluster - spike_hidden[spike_index, :]), 2), axis=1)\n",
    "\n",
    "                    m = np.argmin(distance_sm)\n",
    "                    plot_m.append(m)\n",
    "                    spike_id[spike_index] = m + 1\n",
    "                    # print(spike_tot[ds], spike_index,np.max(tau))\n",
    "                    plot_max_tau.append(np.max(tau))\n",
    "                    if(np.max(tau) >= cos_thr[ds] and spike_index < training_cycle): # 원래 1400 아니냐?\n",
    "                        Cluster[m] = (Cluster[m] * 15 + spike_hidden[spike_index, :])/16\n",
    "\n",
    "\n",
    "                \n",
    "                origin_kmeans_accuracy = cluster_spikes_with_accuracy_torch(features= spike, true_labels=label-1, n_clusters=3, init_point=None)\n",
    "                kmeans_accuracy = cluster_spikes_with_accuracy_torch(features= torch.tensor(spike_hidden).to(device), true_labels=label-1, n_clusters=3, init_point=None)\n",
    "                k_means_bin_origin_feature.append(origin_kmeans_accuracy)\n",
    "                k_means_bin.append(kmeans_accuracy)\n",
    "                if SAE_net == False and converted_net_forward == True:\n",
    "                    converted_kmeans_accuracy = cluster_spikes_with_accuracy_torch(features= torch.tensor(converted_spike_hidden).to(device), true_labels=label-1, n_clusters=3, init_point=None)\n",
    "                    converted_k_means_bin.append(converted_kmeans_accuracy)\n",
    "                # sklearn kmeans인데 cpu많이먹어서 버림.\n",
    "                # origin_kmeans_accuracy = cluster_spikes_with_accuracy(features= spike.cpu().detach().numpy(), true_labels=label-1, n_clusters=3, init_point=None)\n",
    "                # kmeans_accuracy = cluster_spikes_with_accuracy(features= spike_hidden, true_labels=label-1, n_clusters=3, init_point=None)\n",
    "                # k_means_bin_origin_feature.append(origin_kmeans_accuracy)\n",
    "                # k_means_bin.append(kmeans_accuracy)\n",
    "                # if SAE_net == False and converted_net_forward == True:\n",
    "                #     converted_kmeans_accuracy = cluster_spikes_with_accuracy(features= converted_spike_hidden, true_labels=label-1, n_clusters=3, init_point=None)\n",
    "                #     converted_k_means_bin.append(converted_kmeans_accuracy)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "                # print('Cluster',Cluster)\n",
    "                # print('spike_id', spike_id)\n",
    "\n",
    "                # spike id 분포 확인하기\n",
    "                # unique_elements, counts = np.unique(spike_id, return_counts=True)\n",
    "                # print(\"Unique elements:\", unique_elements)\n",
    "                # print(\"Counts:\", counts)\n",
    "\n",
    "                cluster_accuracy_during_training_cycle = np.zeros(math.factorial(num_cluster))\n",
    "                cluster_accuracy_post_training_cycle = np.zeros(math.factorial(num_cluster))\n",
    "                cluster_accuracy_total = np.zeros(math.factorial(num_cluster))\n",
    "                \n",
    "                label_converter_ground = list(range(1, num_cluster + 1)) # [1, 2, 3, 4] 생성\n",
    "                label_converter_permutations = list(itertools.permutations(label_converter_ground)) # 모든 순열 구하기\n",
    "                perm_i = 0\n",
    "                perm_start_time = time.time() \n",
    "                for perm in label_converter_permutations:\n",
    "                    label_converter = list(perm)\n",
    "                    # print(label_converter)\n",
    "                    correct_during_training_cycle = 0\n",
    "                    correct_post_training_cycle = 0\n",
    "\n",
    "                    assert len(spike_id) == len(label), 'spike_id랑 label 길이 같아야 됨.'\n",
    "                    for i in range(len(spike_id)):\n",
    "                        if(label_converter[int(spike_id[i]-1)] == label[i]):\n",
    "                            if i < training_cycle:\n",
    "                                correct_during_training_cycle += 1\n",
    "                            else:\n",
    "                                correct_post_training_cycle += 1\n",
    "\n",
    "                    cluster_accuracy_during_training_cycle[perm_i] = correct_during_training_cycle/training_cycle\n",
    "                    cluster_accuracy_post_training_cycle[perm_i] = correct_post_training_cycle/(len(spike_id)-training_cycle)\n",
    "                    cluster_accuracy_total[perm_i] = (correct_during_training_cycle+correct_post_training_cycle)/(len(spike_id))\n",
    "                    perm_i += 1\n",
    "                # print(f\"perm 실행 시간: {time.time()-perm_start_time:.3f}초\")\n",
    "                \n",
    "                cluster_accuracy_during_training_cycle_all_dataset[ds] = np.max(cluster_accuracy_during_training_cycle)\n",
    "                cluster_accuracy_post_training_cycle_all_dataset[ds] = cluster_accuracy_post_training_cycle[np.argmax(cluster_accuracy_during_training_cycle)]\n",
    "                cluster_accuracy_total_all_dataset[ds] = cluster_accuracy_total[np.argmax(cluster_accuracy_during_training_cycle)]\n",
    "                # plot_distributions(ds, plot_tau, plot_denominator, plot_m, plot_max_tau, cos_thr[ds],\n",
    "                #                    cluster_accuracy_during_training_cycle_all_dataset[ds], cluster_accuracy_post_training_cycle_all_dataset[ds], cluster_accuracy_total_all_dataset[ds])\n",
    "            print(f'k_means origin feature average accuracy : {100*sum(k_means_bin_origin_feature)/(len(k_means_bin_origin_feature)+1e-12):.8f}%, total {k_means_bin_origin_feature}')\n",
    "            \n",
    "            mean_cluster_accuracy_during_training_cycle_all_dataset = np.mean(cluster_accuracy_during_training_cycle_all_dataset)\n",
    "            mean_cluster_accuracy_post_training_cycle_all_dataset = np.mean(cluster_accuracy_post_training_cycle_all_dataset)\n",
    "            mean_cluster_accuracy_total_all_dataset = np.mean(cluster_accuracy_total_all_dataset)\n",
    "            \n",
    "            if SAE_net == False and converted_net_forward == True:\n",
    "                converted_k_means_acc = 100*sum(converted_k_means_bin)/len(converted_k_means_bin)\n",
    "                print(f'converted_kmeans average accuracy : {converted_k_means_acc:.8f}%, total {converted_k_means_bin}')\n",
    "            k_means_acc = 100*sum(k_means_bin)/len(k_means_bin)\n",
    "            if k_means_acc > k_means_acc_best:\n",
    "                # torch.save(net, f\"net_save/save_now_net_{current_time}.pth\")\n",
    "                torch.save(net.module.state_dict(), f\"net_save/save_now_net_{current_time}.pth\")\n",
    "                print('save model')\n",
    "                best_mean_cluster_accuracy_post_training_cycle_all_dataset = mean_cluster_accuracy_post_training_cycle_all_dataset\n",
    "            \n",
    "            k_means_acc_best = max(k_means_acc_best, k_means_acc)\n",
    "            print(f'kmeans average accuracy best : {k_means_acc_best:.2f}%, kmeans average accuracy : {k_means_acc:.8f}%, total {k_means_bin}')\n",
    "            print(f'cluster_accuracy_post_training_cycle_all_dataset : {cluster_accuracy_post_training_cycle_all_dataset}')\n",
    "\n",
    "            \n",
    "            mean_cluster_accuracy_during_training_cycle_all_dataset_history.append((epoch, mean_cluster_accuracy_during_training_cycle_all_dataset*100))\n",
    "            mean_cluster_accuracy_post_training_cycle_all_dataset_history.append((epoch, mean_cluster_accuracy_post_training_cycle_all_dataset*100))\n",
    "            mean_cluster_accuracy_total_all_dataset_history.append((epoch, mean_cluster_accuracy_total_all_dataset*100))\n",
    "            print(f\"mean_cluster_accuracy_during_training_cycle : {mean_cluster_accuracy_during_training_cycle_all_dataset*100:.2f}%, post_traincycle_acc : {mean_cluster_accuracy_post_training_cycle_all_dataset*100:.2f}%, total_acc : {mean_cluster_accuracy_total_all_dataset*100:.8f}%\")\n",
    "\n",
    "            # kmeans accuracy기준으로 좋은 거 저장할 거임\n",
    "            # if mean_cluster_accuracy_post_training_cycle_all_dataset > best_mean_cluster_accuracy_post_training_cycle_all_dataset:\n",
    "            #     # torch.save(net, f\"net_save/save_now_net_{current_time}.pth\")\n",
    "            #     torch.save(net.module.state_dict(), f\"net_save/save_now_net_{current_time}.pth\")\n",
    "            #     print('save model')\n",
    "            #     best_mean_cluster_accuracy_post_training_cycle_all_dataset = mean_cluster_accuracy_post_training_cycle_all_dataset\n",
    "            print(f\"best_mean_cluster_accuracy_post_training_cycle_all_dataset : {best_mean_cluster_accuracy_post_training_cycle_all_dataset*100:.2f}%\")\n",
    "            print(f\"accuracy_check 실행 시간: {time.time()-accuracy_check_start_time:.3f}초\")\n",
    "\n",
    "        wandb.log({\"avg_loss\": avg_loss})\n",
    "        wandb.log({\"mean_cluster_accuracy_post_training_cycle_all_dataset\": mean_cluster_accuracy_post_training_cycle_all_dataset})\n",
    "        wandb.log({\"best_mean_cluster_accuracy_post_training_cycle_all_dataset\": best_mean_cluster_accuracy_post_training_cycle_all_dataset})\n",
    "        wandb.log({\"best_mean_cluster_accuracy_post_training_cycle_all_dataset2\": best_mean_cluster_accuracy_post_training_cycle_all_dataset})\n",
    "        wandb.log({\"k_means_acc\": k_means_acc})\n",
    "        wandb.log({\"k_means_acc_best\": k_means_acc_best})\n",
    "        wandb.log({\"converted_k_means_acc\": converted_k_means_acc})\n",
    "\n",
    "\n",
    "        # 저장\n",
    "        with open(f\"result_save/cluster_accuracy_history_{current_time}.pkl\", \"wb\") as f:\n",
    "            pickle.dump({\n",
    "                \"loss_history\": loss_history,\n",
    "                \"mean_cluster_accuracy_during_training_cycle_all_dataset_history\": mean_cluster_accuracy_during_training_cycle_all_dataset_history,\n",
    "                \"mean_cluster_accuracy_post_training_cycle_all_dataset_history\": mean_cluster_accuracy_post_training_cycle_all_dataset_history,\n",
    "                \"mean_cluster_accuracy_total_all_dataset_history\": mean_cluster_accuracy_total_all_dataset_history,\n",
    "            }, f)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mbhkim003\u001b[0m (\u001b[33mbhkim003-seoul-national-university\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.19.6 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.17.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/nfs/home/bhkim003/github_folder/ByeonghyeonKim/my_snn/wandb/run-20250205_133205-5ipto0s3</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/bhkim003-seoul-national-university/spike_sorting%20just%20run/runs/5ipto0s3' target=\"_blank\">smooth-silence-985</a></strong> to <a href='https://wandb.ai/bhkim003-seoul-national-university/spike_sorting%20just%20run' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/bhkim003-seoul-national-university/spike_sorting%20just%20run' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/spike_sorting%20just%20run</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/bhkim003-seoul-national-university/spike_sorting%20just%20run/runs/5ipto0s3' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/spike_sorting%20just%20run/runs/5ipto0s3</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'gpu': '1', 'Conv_net': True, 'SAE_net': True, 'dataset_num': 16, 'spike_length': 50, 'num_cluster': 4, 'training_cycle': 1400, 'batch_size': 32, 'max_epoch': 7000, 'learning_rate': 0.001, 'normalize_on': False, 'need_bias': False, 'lif_add_at_first': False, 'my_seed': 42, 'TIME': 50, 'v_decay': 0.25, 'v_threshold': 0.25, 'v_reset': 10000.0, 'BPTT_on': True, 'SAE_hidden_nomean': True, 'current_time': '20250205_133203_020', 'optimizer': 'Adam', 'coarse_com_mode': True, 'sae_l2_norm_bridge': False, 'sae_lif_bridge': True, 'accuracy_check_epoch_term': 1, 'lif_add_at_last': True, 'two_channel_input': False, 'lateral_feature_num': 4, 'lc_adc_on': False, 'converted_net_forward': False, 'pretrained_net': None, 'vth_mul_on': False, 'batch_norm_on': False, 'l2_norm_loss_weight': 0, 'QCFS_neuron_on': False, 'quantize_level_num': 0, 'fusion_net': False, 'repeat_coding': False, 'coarse_com_config': (2.0, -2.0)}\n",
      "cos_thr [0.95 0.95 0.95 0.95 0.95 0.95 0.95 0.85 0.95 0.9  0.8  0.95 0.95 0.95\n",
      " 0.95 0.8 ]\n",
      "conv length [50, 24, 11, 5]\n",
      "Total number of encoder parameters: 26592\n",
      "DataParallel(\n",
      "  (module): SAE_conv1(\n",
      "    (encoder): Sequential(\n",
      "      (0): SSBH_DimChanger_one_two()\n",
      "      (1): SSBH_DimChanger_for_one_two_coupling()\n",
      "      (2): Conv1d(1, 32, kernel_size=(3,), stride=(2,), bias=False)\n",
      "      (3): SSBH_DimChanger_for_one_two_decoupling()\n",
      "      (4): LIF_layer()\n",
      "      (5): SSBH_DimChanger_for_one_two_coupling()\n",
      "      (6): Conv1d(32, 64, kernel_size=(3,), stride=(2,), bias=False)\n",
      "      (7): SSBH_DimChanger_for_one_two_decoupling()\n",
      "      (8): LIF_layer()\n",
      "      (9): SSBH_DimChanger_for_one_two_coupling()\n",
      "      (10): Conv1d(64, 96, kernel_size=(3,), stride=(2,), bias=False)\n",
      "      (11): SSBH_DimChanger_for_one_two_decoupling()\n",
      "      (12): LIF_layer()\n",
      "      (13): SSBH_DimChanger_for_one_two_coupling()\n",
      "      (14): SSBH_DimChanger_for_fc()\n",
      "      (15): Linear(in_features=480, out_features=4, bias=False)\n",
      "      (16): SSBH_DimChanger_for_one_two_decoupling()\n",
      "      (17): LIF_layer()\n",
      "      (18): SSBH_DimChanger_one_two()\n",
      "    )\n",
      "    (decoder): Sequential(\n",
      "      (0): SSBH_DimChanger_one_two()\n",
      "      (1): SSBH_DimChanger_for_one_two_coupling()\n",
      "      (2): Linear(in_features=4, out_features=480, bias=False)\n",
      "      (3): SSBH_DimChanger_for_one_two_decoupling()\n",
      "      (4): LIF_layer()\n",
      "      (5): SSBH_DimChanger_for_one_two_coupling()\n",
      "      (6): SSBH_DimChanger_for_conv1()\n",
      "      (7): SSBH_DimChanger_for_one_two_decoupling()\n",
      "      (8): SSBH_DimChanger_for_one_two_coupling()\n",
      "      (9): ConvTranspose1d(96, 64, kernel_size=(3,), stride=(2,), bias=False)\n",
      "      (10): SSBH_DimChanger_for_one_two_decoupling()\n",
      "      (11): LIF_layer()\n",
      "      (12): SSBH_DimChanger_for_one_two_coupling()\n",
      "      (13): ConvTranspose1d(64, 32, kernel_size=(3,), stride=(2,), output_padding=(1,), bias=False)\n",
      "      (14): SSBH_DimChanger_for_one_two_decoupling()\n",
      "      (15): LIF_layer()\n",
      "      (16): SSBH_DimChanger_for_one_two_coupling()\n",
      "      (17): ConvTranspose1d(32, 1, kernel_size=(3,), stride=(2,), output_padding=(1,), bias=False)\n",
      "      (18): SSBH_DimChanger_for_one_two_decoupling()\n",
      "      (19): LIF_layer()\n",
      "      (20): SSBH_DimChanger_one_two()\n",
      "    )\n",
      "  )\n",
      ")\n",
      "Device: cuda\n",
      "\n",
      "Start Training, current_time = 20250205_133203_020\n",
      "\n",
      "\n",
      "epoch-0 loss : 0.02163, loss_normal : 0.00000, loss_coarse : 0.00000\n",
      "ae train 실행 시간: 237.080초, 전체 시작 시간 20250205_133203_020\n",
      "\n",
      "epoch-0 accuracy check\n",
      "k_means origin feature average accuracy : 87.43526775%, total [0.9766647694934547, 0.9775695627484384, 0.9746908254242163, 0.9645941278065631, 0.9607038123167155, 0.9434659090909091, 0.8560539431251832, 0.6951219512195121, 0.973100798108188, 0.9364849187935035, 0.8341013824884793, 0.6868775629759812, 0.9565992865636147, 0.9246100519930676, 0.7398255813953488, 0.5891783567134269]\n",
      "save model\n",
      "kmeans average accuracy best : 83.22%, kmeans average accuracy : 83.21677436%, total [0.9681274900398407, 0.9696195343554799, 0.9620362381363244, 0.9441565918249856, 0.9689149560117302, 0.9340909090909091, 0.8111990618586925, 0.5195689166193987, 0.9627549512267218, 0.9074825986078886, 0.628168202764977, 0.5749853544229643, 0.9607609988109393, 0.9032351242056614, 0.7630813953488372, 0.5365015745777268]\n",
      "cluster_accuracy_post_training_cycle_all_dataset : [0.9692526  0.96559849 0.94415022 0.8635487  0.96368159 0.9009434\n",
      " 0.78717056 0.56067733 0.92990419 0.89404297 0.65057915 0.48560079\n",
      " 0.95977597 0.81813773 0.57352941 0.49259436]\n",
      "mean_cluster_accuracy_during_training_cycle : 79.54%, post_traincycle_acc : 79.74%, total_acc : 79.65920181%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 79.74%\n",
      "accuracy_check 실행 시간: 28.426초\n",
      "\n",
      "\n",
      "epoch-1 loss : 0.01320, loss_normal : 0.00000, loss_coarse : 0.00000\n",
      "ae train 실행 시간: 240.384초, 전체 시작 시간 20250205_133203_020\n",
      "\n",
      "epoch-1 accuracy check\n",
      "k_means origin feature average accuracy : 87.40075895%, total [0.9766647694934547, 0.9775695627484384, 0.9746908254242163, 0.9645941278065631, 0.9607038123167155, 0.9434659090909091, 0.8560539431251832, 0.6951219512195121, 0.973100798108188, 0.9364849187935035, 0.8341013824884793, 0.6868775629759812, 0.9565992865636147, 0.9243212016175621, 0.734593023255814, 0.5891783567134269]\n",
      "kmeans average accuracy best : 83.22%, kmeans average accuracy : 81.24898878%, total [0.9684120660216278, 0.9690516751845543, 0.9603106125970664, 0.93811168681635, 0.969208211143695, 0.9204545454545454, 0.7851070067428907, 0.5876347135564379, 0.9571386343482117, 0.804814385150812, 0.5996543778801844, 0.5454012888107791, 0.9586801426872771, 0.9015020219526285, 0.609593023255814, 0.5247638133409677]\n",
      "cluster_accuracy_post_training_cycle_all_dataset : [0.96736045 0.95617342 0.94077997 0.80520733 0.96865672 0.89811321\n",
      " 0.80755843 0.51881468 0.92637418 0.86474609 0.57528958 0.47070506\n",
      " 0.95468432 0.77255092 0.525      0.4859054 ]\n",
      "mean_cluster_accuracy_during_training_cycle : 77.94%, post_traincycle_acc : 77.74%, total_acc : 77.81391871%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 79.74%\n",
      "accuracy_check 실행 시간: 27.934초\n",
      "\n",
      "\n",
      "epoch-2 loss : 0.01245, loss_normal : 0.00000, loss_coarse : 0.00000\n",
      "ae train 실행 시간: 243.214초, 전체 시작 시간 20250205_133203_020\n",
      "\n",
      "epoch-2 accuracy check\n",
      "k_means origin feature average accuracy : 87.40940132%, total [0.9766647694934547, 0.9775695627484384, 0.9746908254242163, 0.9645941278065631, 0.9607038123167155, 0.9434659090909091, 0.8560539431251832, 0.6951219512195121, 0.973100798108188, 0.9364849187935035, 0.8341013824884793, 0.682190978324546, 0.9565992865636147, 0.9243212016175621, 0.7383720930232558, 0.5914686515888921]\n",
      "kmeans average accuracy best : 83.22%, kmeans average accuracy : 81.15618439%, total [0.9686966420034149, 0.969335604770017, 0.9580097785447225, 0.9280368451352907, 0.9674486803519061, 0.9167613636363636, 0.7563764291996482, 0.5167328417470222, 0.9556606562222879, 0.8059744779582366, 0.6080069124423964, 0.5459871118922085, 0.9595719381688466, 0.8861929520508377, 0.7357558139534883, 0.506441454337246]\n",
      "cluster_accuracy_post_training_cycle_all_dataset : [0.97019868 0.95994345 0.9364468  0.82931533 0.96467662 0.89481132\n",
      " 0.76429637 0.59266228 0.94351992 0.84765625 0.63658301 0.46276068\n",
      " 0.91547862 0.76527643 0.55       0.50215002]\n",
      "mean_cluster_accuracy_during_training_cycle : 77.00%, post_traincycle_acc : 78.35%, total_acc : 77.80615951%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 79.74%\n",
      "accuracy_check 실행 시간: 28.406초\n",
      "\n",
      "\n",
      "epoch-3 loss : 0.01147, loss_normal : 0.00000, loss_coarse : 0.00000\n",
      "ae train 실행 시간: 239.772초, 전체 시작 시간 20250205_133203_020\n",
      "\n",
      "epoch-3 accuracy check\n",
      "k_means origin feature average accuracy : 87.36317234%, total [0.9766647694934547, 0.9775695627484384, 0.9746908254242163, 0.9645941278065631, 0.9607038123167155, 0.9434659090909091, 0.8560539431251832, 0.6951219512195121, 0.973100798108188, 0.9364849187935035, 0.8338133640552995, 0.6833626244874048, 0.9565992865636147, 0.9243212016175621, 0.7398255813953488, 0.5817348983681649]\n",
      "kmeans average accuracy best : 83.22%, kmeans average accuracy : 82.41805024%, total [0.9681274900398407, 0.969335604770017, 0.9608858211101524, 0.9372481289579735, 0.967741935483871, 0.9329545454545455, 0.78246848431545, 0.5155984117980714, 0.9586166124741354, 0.8784802784222738, 0.6160714285714286, 0.5670767428236673, 0.9592746730083235, 0.8902368573079145, 0.7494186046511628, 0.5333524191239623]\n",
      "cluster_accuracy_post_training_cycle_all_dataset : [0.96736045 0.95900094 0.94077997 0.83895853 0.94228856 0.86886792\n",
      " 0.78170065 0.60724365 0.94351992 0.74902344 0.63658301 0.49602781\n",
      " 0.92718941 0.76091174 0.53823529 0.35260392]\n",
      "mean_cluster_accuracy_during_training_cycle : 76.62%, post_traincycle_acc : 76.94%, total_acc : 76.80865888%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 79.74%\n",
      "accuracy_check 실행 시간: 29.030초\n",
      "\n",
      "\n",
      "epoch-4 loss : 0.01147, loss_normal : 0.00000, loss_coarse : 0.00000\n",
      "ae train 실행 시간: 239.599초, 전체 시작 시간 20250205_133203_020\n",
      "\n",
      "epoch-4 accuracy check\n",
      "k_means origin feature average accuracy : 87.43346244%, total [0.9766647694934547, 0.9775695627484384, 0.9746908254242163, 0.9645941278065631, 0.9607038123167155, 0.9434659090909091, 0.8560539431251832, 0.6951219512195121, 0.973100798108188, 0.9364849187935035, 0.8341013824884793, 0.6868775629759812, 0.9565992865636147, 0.9243212016175621, 0.7398255813953488, 0.5891783567134269]\n",
      "kmeans average accuracy best : 83.22%, kmeans average accuracy : 79.99368793%, total [0.9689812179852021, 0.9690516751845543, 0.9585849870578085, 0.9323546344271733, 0.9671554252199414, 0.9090909090909091, 0.783641160949868, 0.6409529211571185, 0.9568430387230269, 0.7972737819025522, 0.6123271889400922, 0.5577035735207967, 0.9592746730083235, 0.6733102253032929, 0.5994186046511628, 0.5130260521042084]\n",
      "cluster_accuracy_post_training_cycle_all_dataset : [0.96877956 0.96748351 0.94029851 0.8659595  0.96517413 0.8990566\n",
      " 0.79114868 0.56020696 0.91174987 0.85058594 0.63465251 0.48709037\n",
      " 0.8793279  0.76673133 0.53431373 0.46727186]\n",
      "mean_cluster_accuracy_during_training_cycle : 77.75%, post_traincycle_acc : 78.06%, total_acc : 77.93609968%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 79.74%\n",
      "accuracy_check 실행 시간: 28.165초\n",
      "\n",
      "\n",
      "epoch-5 loss : 0.01008, loss_normal : 0.00000, loss_coarse : 0.00000\n",
      "ae train 실행 시간: 243.173초, 전체 시작 시간 20250205_133203_020\n",
      "\n",
      "epoch-5 accuracy check\n",
      "k_means origin feature average accuracy : 87.32020753%, total [0.9766647694934547, 0.9775695627484384, 0.9746908254242163, 0.9645941278065631, 0.9607038123167155, 0.9434659090909091, 0.8560539431251832, 0.6951219512195121, 0.973100798108188, 0.9364849187935035, 0.8341013824884793, 0.6698886936145284, 0.9565992865636147, 0.9243212016175621, 0.7406976744186047, 0.5871743486973948]\n",
      "kmeans average accuracy best : 83.22%, kmeans average accuracy : 82.20154463%, total [0.9684120660216278, 0.969335604770017, 0.9605982168536095, 0.9421416234887737, 0.9659824046920821, 0.9059659090909091, 0.7877455291703312, 0.6228020419739081, 0.9376293230860183, 0.7700116009280742, 0.6140552995391705, 0.5474516695957821, 0.9616527942925089, 0.9058347775852109, 0.7575581395348837, 0.5350701402805611]\n",
      "cluster_accuracy_post_training_cycle_all_dataset : [0.96073794 0.9401508  0.93163216 0.8611379  0.90945274 0.85188679\n",
      " 0.73943312 0.46801505 0.903177   0.63330078 0.66505792 0.47020854\n",
      " 0.92362525 0.77740058 0.53627451 0.60344004]\n",
      "mean_cluster_accuracy_during_training_cycle : 74.83%, post_traincycle_acc : 76.09%, total_acc : 75.58224313%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 79.74%\n",
      "accuracy_check 실행 시간: 29.056초\n",
      "\n",
      "\n",
      "epoch-6 loss : 0.00917, loss_normal : 0.00000, loss_coarse : 0.00000\n",
      "ae train 실행 시간: 243.061초, 전체 시작 시간 20250205_133203_020\n",
      "\n",
      "epoch-6 accuracy check\n",
      "k_means origin feature average accuracy : 87.43619069%, total [0.9766647694934547, 0.9775695627484384, 0.9746908254242163, 0.9645941278065631, 0.9607038123167155, 0.944034090909091, 0.8560539431251832, 0.6951219512195121, 0.973100798108188, 0.9364849187935035, 0.8338133640552995, 0.6810193321616872, 0.9565992865636147, 0.9246100519930676, 0.7398255813953488, 0.5949040939020899]\n",
      "save model\n",
      "kmeans average accuracy best : 83.87%, kmeans average accuracy : 83.87455910%, total [0.9686966420034149, 0.9710391822827938, 0.9620362381363244, 0.9430051813471503, 0.9671554252199414, 0.9303977272727273, 0.8123717384931105, 0.6488939307997731, 0.9488619568430388, 0.8955916473317865, 0.6203917050691244, 0.554481546572935, 0.9622473246135553, 0.9121894858463316, 0.7686046511627908, 0.5539650730031491]\n",
      "cluster_accuracy_post_training_cycle_all_dataset : [0.95600757 0.92507069 0.94415022 0.87415622 0.94129353 0.88160377\n",
      " 0.79413227 0.42144873 0.90166415 0.64648438 0.63079151 0.47666336\n",
      " 0.91038697 0.76479146 0.51519608 0.57286192]\n",
      "mean_cluster_accuracy_during_training_cycle : 76.18%, post_traincycle_acc : 75.98%, total_acc : 76.05804094%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 75.98%\n",
      "accuracy_check 실행 시간: 28.645초\n",
      "\n",
      "\n",
      "epoch-7 loss : 0.00891, loss_normal : 0.00000, loss_coarse : 0.00000\n",
      "ae train 실행 시간: 236.292초, 전체 시작 시간 20250205_133203_020\n",
      "\n",
      "epoch-7 accuracy check\n",
      "k_means origin feature average accuracy : 87.37221691%, total [0.9766647694934547, 0.9775695627484384, 0.9746908254242163, 0.9645941278065631, 0.9607038123167155, 0.9434659090909091, 0.8560539431251832, 0.6951219512195121, 0.973100798108188, 0.9364849187935035, 0.8341013824884793, 0.6839484475688342, 0.9565992865636147, 0.9248989023685731, 0.7395348837209302, 0.582021185227598]\n",
      "save model\n",
      "kmeans average accuracy best : 84.72%, kmeans average accuracy : 84.72167078%, total [0.9686966420034149, 0.969335604770017, 0.9643370721886684, 0.9476108232584917, 0.9674486803519061, 0.9136363636363637, 0.802403987100557, 0.6744186046511628, 0.9527046999704404, 0.9074825986078886, 0.6183755760368663, 0.5553602811950791, 0.9631391200951248, 0.9113229347198152, 0.7755813953488372, 0.6636129401660463]\n",
      "cluster_accuracy_post_training_cycle_all_dataset : [0.96168401 0.95994345 0.94126143 0.89585342 0.9318408  0.86933962\n",
      " 0.7255097  0.43226717 0.9404942  0.64355469 0.54488417 0.49404171\n",
      " 0.88187373 0.79679922 0.58676471 0.51839465]\n",
      "mean_cluster_accuracy_during_training_cycle : 75.85%, post_traincycle_acc : 75.78%, total_acc : 75.80499099%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 75.78%\n",
      "accuracy_check 실행 시간: 35.745초\n",
      "\n",
      "\n",
      "epoch-8 loss : 0.00828, loss_normal : 0.00000, loss_coarse : 0.00000\n",
      "ae train 실행 시간: 241.148초, 전체 시작 시간 20250205_133203_020\n",
      "\n",
      "epoch-8 accuracy check\n",
      "k_means origin feature average accuracy : 87.26683453%, total [0.9766647694934547, 0.9775695627484384, 0.9746908254242163, 0.9645941278065631, 0.9607038123167155, 0.9434659090909091, 0.8560539431251832, 0.6951219512195121, 0.973100798108188, 0.9364849187935035, 0.8341013824884793, 0.6839484475688342, 0.9565992865636147, 0.9243212016175621, 0.7229651162790698, 0.5823074720870312]\n",
      "kmeans average accuracy best : 84.72%, kmeans average accuracy : 81.64220409%, total [0.9669891861126921, 0.9696195343554799, 0.9623238423928674, 0.9461715601611975, 0.9624633431085043, 0.8900568181818181, 0.7760187628261507, 0.4608621667612025, 0.9151640555719776, 0.761600928074246, 0.6345046082949308, 0.5565319273579379, 0.9610582639714625, 0.8986135181975736, 0.752906976744186, 0.647867162897223]\n",
      "cluster_accuracy_post_training_cycle_all_dataset : [0.96546831 0.95617342 0.92103996 0.86499518 0.93631841 0.78349057\n",
      " 0.70661363 0.61900282 0.89107413 0.66943359 0.54681467 0.46772592\n",
      " 0.90733198 0.74781765 0.54117647 0.33827043]\n",
      "mean_cluster_accuracy_during_training_cycle : 73.57%, post_traincycle_acc : 74.14%, total_acc : 73.90984199%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 75.78%\n",
      "accuracy_check 실행 시간: 28.844초\n",
      "\n",
      "\n",
      "epoch-9 loss : 0.00897, loss_normal : 0.00000, loss_coarse : 0.00000\n",
      "ae train 실행 시간: 234.097초, 전체 시작 시간 20250205_133203_020\n",
      "\n",
      "epoch-9 accuracy check\n",
      "k_means origin feature average accuracy : 87.42981717%, total [0.9766647694934547, 0.9775695627484384, 0.9746908254242163, 0.9645941278065631, 0.9607038123167155, 0.9434659090909091, 0.8560539431251832, 0.6951219512195121, 0.973100798108188, 0.9364849187935035, 0.8341013824884793, 0.6868775629759812, 0.9565992865636147, 0.9246100519930676, 0.7389534883720931, 0.5891783567134269]\n",
      "kmeans average accuracy best : 84.72%, kmeans average accuracy : 81.88979237%, total [0.9675583380762663, 0.969335604770017, 0.9605982168536095, 0.9409902130109384, 0.9633431085043989, 0.8727272727272727, 0.7578422749926708, 0.6440726035167328, 0.9089565474430978, 0.7491299303944315, 0.6033986175115207, 0.5196250732278852, 0.960166468489893, 0.8939919121894858, 0.7447674418604651, 0.645863154881191]\n",
      "cluster_accuracy_post_training_cycle_all_dataset : [0.96641438 0.95475966 0.89552239 0.86210222 0.93432836 0.80330189\n",
      " 0.68920935 0.55268109 0.89914271 0.5390625  0.52895753 0.44438928\n",
      " 0.89562118 0.73035887 0.52401961 0.34018156]\n",
      "mean_cluster_accuracy_during_training_cycle : 72.44%, post_traincycle_acc : 72.25%, total_acc : 72.32320776%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 75.78%\n",
      "accuracy_check 실행 시간: 28.669초\n",
      "\n",
      "\n",
      "epoch-10 loss : 0.00831, loss_normal : 0.00000, loss_coarse : 0.00000\n",
      "ae train 실행 시간: 235.481초, 전체 시작 시간 20250205_133203_020\n",
      "\n",
      "epoch-10 accuracy check\n",
      "k_means origin feature average accuracy : 87.32908732%, total [0.9766647694934547, 0.9775695627484384, 0.9746908254242163, 0.9645941278065631, 0.9607038123167155, 0.9434659090909091, 0.8560539431251832, 0.6951219512195121, 0.973100798108188, 0.9364849187935035, 0.8341013824884793, 0.6698886936145284, 0.9565992865636147, 0.9246100519930676, 0.7398255813953488, 0.5891783567134269]\n",
      "kmeans average accuracy best : 84.72%, kmeans average accuracy : 80.55381327%, total [0.9675583380762663, 0.9687677455990914, 0.9588725913143514, 0.9389752446747266, 0.9618768328445748, 0.8738636363636364, 0.7531515684549985, 0.46880317640385705, 0.918120011823825, 0.7386890951276102, 0.581221198156682, 0.5392501464557704, 0.9613555291319857, 0.8971692663200462, 0.7311046511627907, 0.6298310907529344]\n",
      "cluster_accuracy_post_training_cycle_all_dataset : [0.96688742 0.95051838 0.87530091 0.83847637 0.94378109 0.80660377\n",
      " 0.72352064 0.37300094 0.89561271 0.52050781 0.58397683 0.44786495\n",
      " 0.9287169  0.7400582  0.50147059 0.43956044]\n",
      "mean_cluster_accuracy_during_training_cycle : 72.25%, post_traincycle_acc : 72.10%, total_acc : 72.15286327%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 75.78%\n",
      "accuracy_check 실행 시간: 28.406초\n",
      "\n",
      "\n",
      "epoch-11 loss : 0.00980, loss_normal : 0.00000, loss_coarse : 0.00000\n",
      "ae train 실행 시간: 237.394초, 전체 시작 시간 20250205_133203_020\n",
      "\n",
      "epoch-11 accuracy check\n",
      "k_means origin feature average accuracy : 87.36071063%, total [0.9766647694934547, 0.9775695627484384, 0.9746908254242163, 0.9645941278065631, 0.9607038123167155, 0.944034090909091, 0.8560539431251832, 0.6951219512195121, 0.973100798108188, 0.9364849187935035, 0.8338133640552995, 0.6868775629759812, 0.9565992865636147, 0.9246100519930676, 0.7276162790697674, 0.5891783567134269]\n",
      "kmeans average accuracy best : 84.72%, kmeans average accuracy : 83.38700766%, total [0.9684120660216278, 0.9687677455990914, 0.9628990509059534, 0.9467472654001151, 0.9689149560117302, 0.9190340909090909, 0.8147170917619466, 0.6885989790130459, 0.9530002955956252, 0.7819025522041764, 0.606278801843318, 0.5454012888107791, 0.9586801426872771, 0.9015020219526285, 0.7590116279069767, 0.5980532493558546]\n",
      "cluster_accuracy_post_training_cycle_all_dataset : [0.96215705 0.94297832 0.93500241 0.86065574 0.94477612 0.83537736\n",
      " 0.77971159 0.55409219 0.85930408 0.69824219 0.64092664 0.459285\n",
      " 0.88391039 0.74442289 0.52205882 0.54753942]\n",
      "mean_cluster_accuracy_during_training_cycle : 74.88%, post_traincycle_acc : 76.07%, total_acc : 75.58720791%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 75.78%\n",
      "accuracy_check 실행 시간: 26.947초\n",
      "\n",
      "\n",
      "epoch-12 loss : 0.00965, loss_normal : 0.00000, loss_coarse : 0.00000\n",
      "ae train 실행 시간: 228.639초, 전체 시작 시간 20250205_133203_020\n",
      "\n",
      "epoch-12 accuracy check\n",
      "k_means origin feature average accuracy : 87.31298888%, total [0.9766647694934547, 0.9775695627484384, 0.9746908254242163, 0.9645941278065631, 0.9607038123167155, 0.9434659090909091, 0.8560539431251832, 0.6951219512195121, 0.973100798108188, 0.9364849187935035, 0.8338133640552995, 0.6698886936145284, 0.9565992865636147, 0.9248989023685731, 0.7398255813953488, 0.5866017749785285]\n",
      "kmeans average accuracy best : 84.72%, kmeans average accuracy : 82.91995427%, total [0.9684120660216278, 0.9696195343554799, 0.9628990509059534, 0.9493379389752447, 0.9689149560117302, 0.940625, 0.8504837291116975, 0.6880317640385706, 0.9571386343482117, 0.847737819025522, 0.6082949308755761, 0.5486233157586409, 0.9557074910820452, 0.902946273830156, 0.6119186046511628, 0.5365015745777268]\n",
      "cluster_accuracy_post_training_cycle_all_dataset : [0.96263009 0.96277097 0.93355802 0.88235294 0.95074627 0.89528302\n",
      " 0.79462954 0.46331138 0.85980837 0.87011719 0.64913127 0.44389275\n",
      " 0.87423625 0.77643065 0.56911765 0.3277592 ]\n",
      "mean_cluster_accuracy_during_training_cycle : 75.90%, post_traincycle_acc : 76.35%, total_acc : 76.15996692%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 75.78%\n",
      "accuracy_check 실행 시간: 27.459초\n",
      "\n",
      "\n",
      "epoch-13 loss : 0.00903, loss_normal : 0.00000, loss_coarse : 0.00000\n",
      "ae train 실행 시간: 221.318초, 전체 시작 시간 20250205_133203_020\n",
      "\n",
      "epoch-13 accuracy check\n",
      "k_means origin feature average accuracy : 87.34922783%, total [0.9766647694934547, 0.9775695627484384, 0.9746908254242163, 0.9645941278065631, 0.9607038123167155, 0.9434659090909091, 0.8560539431251832, 0.6951219512195121, 0.973100798108188, 0.9364849187935035, 0.8341013824884793, 0.6868775629759812, 0.9565992865636147, 0.9243212016175621, 0.7383720930232558, 0.5771543086172345]\n",
      "kmeans average accuracy best : 84.72%, kmeans average accuracy : 82.68450770%, total [0.9675583380762663, 0.9701873935264055, 0.9580097785447225, 0.924006908462867, 0.9712609970674487, 0.9332386363636364, 0.8100263852242744, 0.63471355643789, 0.950931126219332, 0.8303364269141531, 0.6189516129032258, 0.5448154657293497, 0.9568965517241379, 0.9026574234546505, 0.7540697674418605, 0.5018608645863155]\n",
      "cluster_accuracy_post_training_cycle_all_dataset : [0.96594134 0.96088596 0.95570534 0.89440694 0.93930348 0.88632075\n",
      " 0.76131278 0.31373471 0.89813414 0.87548828 0.62403475 0.49106256\n",
      " 0.87881874 0.77109602 0.57107843 0.44863832]\n",
      "mean_cluster_accuracy_during_training_cycle : 78.26%, post_traincycle_acc : 76.47%, total_acc : 77.18612871%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 75.78%\n",
      "accuracy_check 실행 시간: 26.768초\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "gpu = '1'\n",
    "Conv_net = True # True False\n",
    "SAE_net = True # True False\n",
    "\n",
    "# hyperparameter\n",
    "dataset_num = 16\n",
    "spike_length = 50 # coarse_com_mode일 때는 time step이 됨.\n",
    "num_cluster = 4  # 클러스터 수 설정 # 논문엔 4개라는데 여기서는 3개로 했네\n",
    "training_cycle = 1400 #1400 2400 # 그 초기 몇개까지만 cluster update할지\n",
    "\n",
    "\n",
    "batch_size = 32\n",
    "max_epoch = 7000\n",
    "learning_rate = 0.001\n",
    "normalize_on = False # True or False # 0부터1까지 normalize\n",
    "need_bias = False\n",
    "# first_layer_no_train = False\n",
    "lif_add_at_first = False\n",
    "my_seed = 42\n",
    "\n",
    "TIME = 50 # SAE일 때만 유효. coarse_com_mode일 때는 level_num이 됨. 즉 feature 개수.\n",
    "v_decay = 0.25 # -cor\n",
    "v_threshold = 0.25 # -cor\n",
    "v_reset = 10000.0 # -cor # 10000이상 일 시 hard reset\n",
    "BPTT_on = True # +cor # True False\n",
    "\n",
    "SAE_hidden_nomean = True # True False\n",
    "\n",
    "current_time = datetime.datetime.now().strftime(\"%Y%m%d_%H%M%S\") + f\"_{str(int(datetime.datetime.now().microsecond / 1000)).zfill(3)}\"\n",
    "\n",
    "optimizer = 'Adam' #'Adam', 'SGD' # 둘다 준수함. loss 줄이는 거는 adam이 좋긴한데, cluster accuracy는 비슷함.\n",
    "\n",
    "coarse_com_mode = True # True False\n",
    "coarse_com_config = (2.0, -2.0) # (max, min) (2.0, -2.0) (3.0, -3.0)\n",
    "\n",
    "sae_l2_norm_bridge = False # True False\n",
    "sae_lif_bridge = True # False True\n",
    "\n",
    "accuracy_check_epoch_term = 1\n",
    "\n",
    "lif_add_at_last = True # True False\n",
    "\n",
    "two_channel_input = False # True False\n",
    "\n",
    "lateral_feature_num = 4\n",
    "\n",
    "lc_adc_on = False # True False\n",
    "\n",
    "converted_net_forward = False # True False\n",
    "\n",
    "pretrained_net = None\n",
    "# pretrained_net = '/home/bhkim003/github_folder/ByeonghyeonKim/my_snn/net_save/save_now_net_중요_20250110_203117_390.pth'\n",
    "# pretrained_net = '/home/bhkim003/github_folder/ByeonghyeonKim/my_snn/net_save/save_now_net_중요_20250113_134126_881_이거_94나오는거.pth'\n",
    "# pretrained_net = '/home/bhkim003/github_folder/ByeonghyeonKim/my_snn/net_save/save_now_net_중요_20250115_200335_029_무한열차95.12.pth'\n",
    "# pretrained_net = '/home/bhkim003/github_folder/ByeonghyeonKim/my_snn/net_save/save_now_net_중요_20250115_200335_029_무한열차95.23.pth'\n",
    "\n",
    "vth_mul_on = False # True False\n",
    "batch_norm_on = False # True False\n",
    "\n",
    "l2_norm_loss_weight = 0 #0.0001 #0.1 #  0 # 0초과면 작동\n",
    "\n",
    "QCFS_neuron_on = False # True False\n",
    "\n",
    "quantize_level_num = 0 # 0이면 quantize 안함. 1이상이면 그 수만큼 quantize함.\n",
    "\n",
    "fusion_net = False # True False # SAE_net False, Conv_net True로 해라. TIME 적절하게 설정해주고.\n",
    "repeat_coding = False # True False # True면 repeat, False면 rate coding.\n",
    "\n",
    "wandb.init(project= f'spike_sorting just run',save_code=False)\n",
    "\n",
    "\n",
    "cluster_train_system( \n",
    "    gpu = gpu,\n",
    "    Conv_net = Conv_net,\n",
    "    SAE_net = SAE_net,\n",
    "\n",
    "    # hyperparameter\n",
    "    dataset_num = dataset_num,\n",
    "    spike_length = spike_length,\n",
    "    num_cluster = num_cluster,  # 클러스터 수 설정 # 논문엔 4개라는데 여기서는 3개로 했네\n",
    "    training_cycle = training_cycle, # 그 초기 몇개까지만 cluster update할지\n",
    "\n",
    "\n",
    "    batch_size = batch_size,\n",
    "    max_epoch = max_epoch,\n",
    "    learning_rate = learning_rate,\n",
    "    normalize_on = normalize_on, # True or False #이거 안 씀 # 이거 별로 안 좋은 normalize같음 # 쓸 거면 다른 거 써라.\n",
    "    need_bias = need_bias,\n",
    "    # first_layer_no_train = False\n",
    "    lif_add_at_first = lif_add_at_first,\n",
    "    my_seed = my_seed,\n",
    "\n",
    "    TIME = TIME, # SAE일 때만 유효\n",
    "    v_decay = v_decay,\n",
    "    v_threshold = v_threshold,\n",
    "    v_reset = v_reset, # 10000이상 일 시 hard reset\n",
    "    BPTT_on = BPTT_on,\n",
    "\n",
    "    SAE_hidden_nomean = SAE_hidden_nomean,\n",
    "    \n",
    "    current_time = current_time,\n",
    "\n",
    "    optimizer = optimizer, #'Adam', 'SGD'\n",
    "\n",
    "    coarse_com_mode = coarse_com_mode,\n",
    "    coarse_com_config = coarse_com_config, # (max, min)\n",
    "\n",
    "    \n",
    "    sae_l2_norm_bridge = sae_l2_norm_bridge,\n",
    "    sae_lif_bridge = sae_lif_bridge,\n",
    "\n",
    "    accuracy_check_epoch_term = accuracy_check_epoch_term,\n",
    "    \n",
    "    lif_add_at_last = lif_add_at_last,\n",
    "\n",
    "    two_channel_input = two_channel_input,\n",
    "\n",
    "    lateral_feature_num = lateral_feature_num,\n",
    "\n",
    "    lc_adc_on = lc_adc_on, \n",
    "\n",
    "    converted_net_forward = converted_net_forward,\n",
    "\n",
    "    pretrained_net = pretrained_net,\n",
    "\n",
    "    vth_mul_on = vth_mul_on,\n",
    "    batch_norm_on = batch_norm_on,\n",
    "\n",
    "    l2_norm_loss_weight = l2_norm_loss_weight,\n",
    "    \n",
    "    QCFS_neuron_on = QCFS_neuron_on, # True False\n",
    "\n",
    "    quantize_level_num = quantize_level_num,\n",
    "\n",
    "    fusion_net = fusion_net, # True False\n",
    "    repeat_coding = repeat_coding,\n",
    "    )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Sweep code\n",
    "\n",
    "\n",
    "# from unittest import TextTestRunner\n",
    "\n",
    "\n",
    "# unique_name_hyper = 'cluster_train_system'\n",
    "# # run_name = 'spike_sorting'\n",
    "# sweep_start_time =  datetime.datetime.now().strftime(\"%Y%m%d_%H%M%S\") + f\"_{str(int(datetime.datetime.now().microsecond / 1000)).zfill(3)}\"\n",
    "# sweep_configuration = {\n",
    "#     'method': 'bayes', # 'random', 'bayes'\n",
    "#     'name': f'spike_sorting_{sweep_start_time}',\n",
    "#     'metric': {'goal': 'maximize', 'name': 'k_means_acc_best'},\n",
    "#     'parameters': \n",
    "#     {\n",
    "#         # \"gpu\": {\"values\": ['1']},  # 이건 sweep parameter아님. hyper_iter에서 직접 설정\n",
    "#         \"Conv_net\": {\"values\": [True]}, \n",
    "#         \"SAE_net\": {\"values\": [False]}, \n",
    "\n",
    "#         \"dataset_num\": {\"values\": [16]}, \n",
    "#         \"spike_length\": {\"values\": [50]},  \n",
    "#         \"num_cluster\": {\"values\": [4]}, \n",
    "#         \"training_cycle\": {\"values\": [2400]}, # [1400, 2400]\n",
    "\n",
    "#         \"batch_size\": {\"values\": [32]}, \n",
    "#         \"max_epoch\": {\"values\": [1]}, \n",
    "#         \"learning_rate\": {\"values\": [0.001, 0.0001]},\n",
    "#         \"normalize_on\": {\"values\": [True]},\n",
    "#         \"need_bias\": {\"values\": [False]}, # [True, False]\n",
    "\n",
    "#         \"lif_add_at_first\": {\"values\": [False]}, # [True, False]\n",
    "#         \"my_seed\": {\"values\": [42]}, \n",
    "\n",
    "#         \"TIME\": {\"values\": [10, 50, 100, 250, 500, 750, 1000, 1500, 2000, 2500]}, #  [4,6,8,10]\n",
    "#         \"v_decay\": {\"values\": [1.0]}, # [0.25,0.50,0.75]\n",
    "#         \"v_threshold\": {\"values\": [0.125, 0.25, 0.50, 0.75, 0.875, 1.0]}, # [0.25,0.50,0.75]\n",
    "#         \"v_reset\": {\"values\": [0.0, 10000.0]},  # [0.0, 10000.0]\n",
    "#         \"BPTT_on\": {\"values\": [True, False]},  # [True, False]\n",
    "\n",
    "#         \"SAE_hidden_nomean\": {\"values\": [True]}, # [True, False]\n",
    "\n",
    "#         # \"current_time\": {\"values\": [current_time]} #밑에서 직접설정됨.\n",
    "\n",
    "#         \"optimizer\": {\"values\": ['Adam', 'SGD']}, # ['Adam', 'SGD']\n",
    "\n",
    "#         \"coarse_com_mode\": {\"values\": [False]}, # [True, False]\n",
    "#         \"coarse_com_config\": {\"values\": [(2.0, -2.0)]}, # ['Adam', 'SGD']\n",
    "\n",
    "#         \"sae_l2_norm_bridge\": {\"values\": [True]}, # [True, False]\n",
    "#         \"sae_lif_bridge\": {\"values\": [True]}, # [False, True]\n",
    "        \n",
    "#         \"accuracy_check_epoch_term\": {\"values\": [1]}, \n",
    "\n",
    "#         \"lif_add_at_last\": {\"values\": [False]},# [True, False]\n",
    "\n",
    "#         \"two_channel_input\": {\"values\": [False]},# [True, False]\n",
    "\n",
    "#         \"lateral_feature_num\": {\"values\": [4]},# [True, False]\n",
    "\n",
    "#         \"lc_adc_on\": {\"values\": [False]},# [True, False]\n",
    "        \n",
    "#         \"converted_net_forward\": {\"values\": [True]},# [True, False]\n",
    "\n",
    "#         \"pretrained_net\": {\"values\": ['/home/bhkim003/github_folder/ByeonghyeonKim/my_snn/net_save/save_now_net_중요_20250110_203117_390.pth']},# [None]\n",
    "\n",
    "#         \"vth_mul_on\": {\"values\": [True]},# [True, False]\n",
    "#         \"batch_norm_on\": {\"values\": [True]},# [True, False]\n",
    "\n",
    "#         \"l2_norm_loss_weight\": {\"values\": [0.1]},\n",
    "\n",
    "#         \"QCFS_neuron_on\": {\"values\": [True]},   # [True, False]\n",
    "\n",
    "#         \"quantize_level_num\": {\"values\": [0]}, \n",
    "\n",
    "#         \"fusion_net\": {\"values\": [False]}, \n",
    "#         \"repeat_coding\": {\"values\": [False]}, \n",
    "#      }\n",
    "# }\n",
    "\n",
    "\n",
    "# def hyper_iter():\n",
    "#     ### my_snn control board ########################\n",
    "#     wandb.init(save_code = False)\n",
    "#     gpu  =  '2'\n",
    "#     Conv_net  =  wandb.config.Conv_net\n",
    "#     SAE_net  =  wandb.config.SAE_net\n",
    "\n",
    "#     dataset_num  =  wandb.config.dataset_num\n",
    "#     spike_length  =  wandb.config.spike_length\n",
    "#     num_cluster  =  wandb.config.num_cluster\n",
    "#     training_cycle  =  wandb.config.training_cycle\n",
    "\n",
    "#     batch_size  =  wandb.config.batch_size\n",
    "#     max_epoch  =  wandb.config.max_epoch\n",
    "#     learning_rate  =  wandb.config.learning_rate\n",
    "#     normalize_on  =  wandb.config.normalize_on\n",
    "#     need_bias  =  wandb.config.need_bias\n",
    "\n",
    "#     lif_add_at_first  =  wandb.config.lif_add_at_first\n",
    "#     my_seed  =  wandb.config.my_seed\n",
    "\n",
    "\n",
    "#     TIME  =  wandb.config.TIME\n",
    "#     v_decay  =  wandb.config.v_decay\n",
    "#     v_threshold  =  wandb.config.v_threshold\n",
    "#     v_reset  =  wandb.config.v_reset\n",
    "#     BPTT_on  =  wandb.config.BPTT_on\n",
    "\n",
    "#     SAE_hidden_nomean  =  wandb.config.SAE_hidden_nomean\n",
    "    \n",
    "#     current_time =  datetime.datetime.now().strftime(\"%Y%m%d_%H%M%S\") + f\"_{str(int(datetime.datetime.now().microsecond / 1000)).zfill(3)}\"\n",
    "\n",
    "#     optimizer  =  wandb.config.optimizer\n",
    "\n",
    "#     coarse_com_mode = wandb.config.coarse_com_mode\n",
    "#     coarse_com_config = wandb.config.coarse_com_config # (max, min)\n",
    "\n",
    "#     sae_l2_norm_bridge = wandb.config.sae_l2_norm_bridge\n",
    "#     sae_lif_bridge = wandb.config.sae_lif_bridge\n",
    "\n",
    "#     accuracy_check_epoch_term = wandb.config.accuracy_check_epoch_term\n",
    "\n",
    "#     lif_add_at_last = wandb.config.lif_add_at_last\n",
    "\n",
    "#     two_channel_input = wandb.config.two_channel_input\n",
    "\n",
    "#     lateral_feature_num = wandb.config.lateral_feature_num\n",
    "\n",
    "#     lc_adc_on = wandb.config.lc_adc_on\n",
    "\n",
    "#     converted_net_forward = wandb.config.converted_net_forward\n",
    "\n",
    "#     pretrained_net = wandb.config.pretrained_net\n",
    "\n",
    "#     vth_mul_on = wandb.config.vth_mul_on\n",
    "#     batch_norm_on = wandb.config.batch_norm_on\n",
    "\n",
    "#     l2_norm_loss_weight = wandb.config.l2_norm_loss_weight\n",
    "\n",
    "#     QCFS_neuron_on = wandb.config.QCFS_neuron_on\n",
    "\n",
    "#     quantize_level_num = wandb.config.quantize_level_num\n",
    "\n",
    "#     fusion_net = wandb.config.fusion_net\n",
    "#     repeat_coding = wandb.config.repeat_coding\n",
    "\n",
    "#     cluster_train_system( \n",
    "#         gpu = gpu,\n",
    "#         Conv_net = Conv_net,\n",
    "#         SAE_net = SAE_net,\n",
    "\n",
    "#         # hyperparameter\n",
    "#         dataset_num = dataset_num,\n",
    "#         spike_length = spike_length,\n",
    "#         num_cluster = num_cluster,  # 클러스터 수 설정 # 논문엔 4개라는데 여기서는 3개로 했네\n",
    "#         training_cycle = training_cycle, # 그 초기 몇개까지만 cluster update할지\n",
    "\n",
    "\n",
    "#         batch_size = batch_size,\n",
    "#         max_epoch = max_epoch,\n",
    "#         learning_rate = learning_rate,\n",
    "#         normalize_on = normalize_on, # True or False #이거 안 씀 # 이거 별로 안 좋은 normalize같음 # 쓸 거면 다른 거 써라.\n",
    "#         need_bias = need_bias,\n",
    "#         # first_layer_no_train = False\n",
    "#         lif_add_at_first = lif_add_at_first,\n",
    "#         my_seed = my_seed,\n",
    "\n",
    "#         TIME = TIME, # SAE일 때만 유효\n",
    "#         v_decay = v_decay,\n",
    "#         v_threshold = v_threshold,\n",
    "#         v_reset = v_reset, # 10000이상 일 시 hard reset\n",
    "#         BPTT_on = BPTT_on,\n",
    "\n",
    "#         SAE_hidden_nomean = SAE_hidden_nomean,\n",
    "\n",
    "#         current_time = current_time,\n",
    "\n",
    "#         optimizer = optimizer, #'Adam', 'SGD'\n",
    "\n",
    "#         coarse_com_mode = coarse_com_mode,\n",
    "#         coarse_com_config = coarse_com_config, # (max, min)\n",
    "        \n",
    "#         sae_l2_norm_bridge = sae_l2_norm_bridge,\n",
    "#         sae_lif_bridge = sae_lif_bridge,\n",
    "\n",
    "#         accuracy_check_epoch_term = accuracy_check_epoch_term,\n",
    "\n",
    "#         lif_add_at_last = lif_add_at_last,\n",
    "        \n",
    "#         two_channel_input = two_channel_input,\n",
    "        \n",
    "#         lateral_feature_num = lateral_feature_num,\n",
    "\n",
    "#         lc_adc_on = lc_adc_on,\n",
    "\n",
    "#         converted_net_forward = converted_net_forward,\n",
    "\n",
    "#         pretrained_net = pretrained_net,\n",
    "\n",
    "#         vth_mul_on = vth_mul_on,\n",
    "#         batch_norm_on = batch_norm_on,\n",
    "\n",
    "#         l2_norm_loss_weight = l2_norm_loss_weight,\n",
    "\n",
    "#         QCFS_neuron_on = QCFS_neuron_on,\n",
    "\n",
    "#         quantize_level_num = quantize_level_num,\n",
    "\n",
    "#         fusion_net = fusion_net, \n",
    "#         repeat_coding = repeat_coding, \n",
    "#         )\n",
    "    \n",
    "# # sweep_id = 'ygoj9jt4'\n",
    "# sweep_id = wandb.sweep(sweep=sweep_configuration, project=f'spike_sorting {unique_name_hyper}')\n",
    "# wandb.agent(sweep_id, function=hyper_iter, count=100000, project=f'spike_sorting {unique_name_hyper}')\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wandb.finish() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import matplotlib.pyplot as plt\n",
    "# from matplotlib.ticker import MaxNLocator\n",
    "# import pickle\n",
    "# import json\n",
    "\n",
    "# # current_time = '20250102_225243_972'\n",
    "\n",
    "# with open(f\"result_save/cluster_accuracy_history_{current_time}.pkl\", \"rb\") as f:\n",
    "#     data = pickle.load(f)\n",
    "\n",
    "\n",
    "# # JSON으로 저장\n",
    "# with open(f\"result_save/cluster_accuracy_history_{current_time}.json\", 'r') as f:\n",
    "#     loaded_hyperparameters = json.load(f)\n",
    "\n",
    "# loss_history = data['loss_history']\n",
    "# mean_cluster_accuracy_during_training_cycle_all_dataset_history = data['mean_cluster_accuracy_during_training_cycle_all_dataset_history']\n",
    "# mean_cluster_accuracy_post_training_cycle_all_dataset_history = data['mean_cluster_accuracy_post_training_cycle_all_dataset_history']\n",
    "# mean_cluster_accuracy_total_all_dataset_history = data['mean_cluster_accuracy_total_all_dataset_history']\n",
    "# print(data)\n",
    "# max_acc = 0\n",
    "# for i in mean_cluster_accuracy_post_training_cycle_all_dataset_history:\n",
    "#     if i[1] > max_acc:\n",
    "#         max_acc = i[1]\n",
    "\n",
    "# # 설정 정보 제목 작성\n",
    "# title = (\n",
    "#     f\"Dataset Num: {loaded_hyperparameters['dataset_num']}, Conv {loaded_hyperparameters['Conv_net']}, SAE {loaded_hyperparameters['SAE_net']}, Current time {loaded_hyperparameters['current_time']}, Spike Length: {loaded_hyperparameters['spike_length']}, Num Cluster: {loaded_hyperparameters['num_cluster']}, \"\n",
    "#     f\"Training Cycle: {loaded_hyperparameters['training_cycle']}, Batch Size: {loaded_hyperparameters['batch_size']}, Max Epoch: {loaded_hyperparameters['max_epoch']}, \\n\"\n",
    "#     f\"Learning Rate: {loaded_hyperparameters['learning_rate']}, Input Normalize: {loaded_hyperparameters['normalize_on']}, Need Bias: {loaded_hyperparameters['need_bias']}, \"\n",
    "#     f\"LIF Add at First: {loaded_hyperparameters['lif_add_at_first']}, TIME: {loaded_hyperparameters['TIME']}, Seed: {loaded_hyperparameters['my_seed']}, Best ACC: {max_acc:.2f}%\"\n",
    "# )\n",
    "\n",
    "# # 데이터 리스트와 라벨 설정 (Loss 제외)\n",
    "# data_list = [\n",
    "#     (\"Mean Cluster Accuracy (During Training Cycle)\", mean_cluster_accuracy_during_training_cycle_all_dataset_history),\n",
    "#     (\"Mean Cluster Accuracy (Post Training Cycle)\", mean_cluster_accuracy_post_training_cycle_all_dataset_history),\n",
    "#     (\"Mean Cluster Accuracy (Total)\", mean_cluster_accuracy_total_all_dataset_history),\n",
    "# ]\n",
    "\n",
    "# # 플롯 생성\n",
    "# fig, ax1 = plt.subplots(figsize=(12, 8))\n",
    "\n",
    "# # 첫 번째 y축: Accuracy 관련 데이터\n",
    "# for label, data in data_list:\n",
    "#     epochs, values = zip(*data)  # epoch, value 분리\n",
    "#     ax1.plot(epochs, values, label=label)\n",
    "\n",
    "# ax1.set_xlabel(\"Epoch\")\n",
    "# ax1.set_ylabel(\"Clurstering Accuracy [%]\", color=\"blue\")\n",
    "# ax1.tick_params(axis=\"y\", labelcolor=\"blue\")\n",
    "# ax1.legend(loc=\"center right\")\n",
    "# ax1.grid(True)\n",
    "\n",
    "# # x축을 정수만 표시하도록 설정\n",
    "# ax1.xaxis.set_major_locator(MaxNLocator(integer=True))\n",
    "\n",
    "# # 두 번째 y축: Loss History\n",
    "# ax2 = ax1.twinx()\n",
    "# epochs, values = zip(*loss_history)\n",
    "# ax2.plot(epochs, values, label=\"AE Loss History\", color=\"red\", linestyle=\"--\")\n",
    "# ax2.set_ylabel(\"Loss\", color=\"red\")\n",
    "# ax2.tick_params(axis=\"y\", labelcolor=\"red\")\n",
    "# ax2.legend(loc=\"center left\")\n",
    "\n",
    "# # 제목 추가\n",
    "# plt.title(title, fontsize=10)\n",
    "# plt.tight_layout()\n",
    "# plt.savefig(f'net_save/{current_time}', dpi=300, bbox_inches=\"tight\")  # dpi=300은 고해상도로 저장, bbox_inches=\"tight\"는 여백 최소화\n",
    "# plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# 데이터셋\n",
    "filename_for_plot = [\n",
    "    \"Easy1_noise05\", \"Easy1_noise10\", \"Easy1_noise15\", \"Easy1_noise20\",\n",
    "    \"Easy2_noise05\", \"Easy2_noise10\", \"Easy2_noise15\", \"Easy2_noise20\",\n",
    "    \"Difficult1_noise05\", \"Difficult1_noise10\", \"Difficult1_noise15\", \"Difficult1_noise20\",\n",
    "    \"Difficult2_noise05\", \"Difficult2_noise10\", \"Difficult2_noise15\", \"Difficult2_noise20\"\n",
    "]\n",
    "\n",
    "# Accuracy 데이터\n",
    "ANN_conv_accracy_set= [0.97935368, 0.97682709, 0.97028784, 0.96461825, 0.97524752, 0.95803571\n",
    ", 0.95746785, 0.92628774, 0.965412,  0.97805344, 0.94869403, 0.92110454\n",
    ", 0.96784232, 0.97551789, 0.91538462, 0.84446478]\n",
    "SNN_fc_accuracy_set = [0.97114475, 0.97643732, 0.84400578, 0.78977821, 0.96616915, 0.92830189\n",
    ", 0.86176032, 0.31984948, 0.80635401, 0.88769531, 0.61003861, 0.60377358\n",
    ", 0.9592668,  0.92870999, 0.78333333, 0.67271859]\n",
    "SNN_conv_accuracy_set = [0.97445601, 0.97737983, 0.97063072, 0.95998071, 0.96268657, 0.90566038\n",
    ", 0.82545997, 0.68391345, 0.96116994, 0.92138672, 0.80694981, 0.49602781\n",
    ", 0.83604888, 0.70611057, 0.69313725, 0.5819398 ]\n",
    "\n",
    "# 평균 계산\n",
    "average_ANN_conv = np.mean(ANN_conv_accracy_set)\n",
    "average_SNN_fc = np.mean(SNN_fc_accuracy_set)\n",
    "average_SNN_conv = np.mean(SNN_conv_accuracy_set)\n",
    "\n",
    "# 데이터 준비\n",
    "accuracies = np.array([ANN_conv_accracy_set, SNN_fc_accuracy_set, SNN_conv_accuracy_set])\n",
    "averages = np.array([average_ANN_conv, average_SNN_fc, average_SNN_conv])\n",
    "\n",
    "# 시각화\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "\n",
    "# 각 모델의 정확도 플롯\n",
    "ax.plot(accuracies[0], label='ANN Conv', marker='o', linestyle='-', color='blue')\n",
    "ax.plot(accuracies[1], label='SNN FC', marker='o', linestyle='-', color='green')\n",
    "ax.plot(accuracies[2], label='SNN Conv', marker='o', linestyle='-', color='red')\n",
    "\n",
    "# 평균값 플롯\n",
    "ax.axhline(y=average_ANN_conv, color='blue', linestyle='--', label=f'Average ANN Conv: {average_ANN_conv:.3f}')\n",
    "ax.axhline(y=average_SNN_fc, color='green', linestyle='--', label=f'Average SNN FC: {average_SNN_fc:.3f}')\n",
    "ax.axhline(y=average_SNN_conv, color='red', linestyle='--', label=f'Average SNN Conv: {average_SNN_conv:.3f}')\n",
    "\n",
    "# 레이블 추가\n",
    "ax.set_xticks(np.arange(len(filename_for_plot)))\n",
    "ax.set_xticklabels(filename_for_plot, rotation=45, ha='right')\n",
    "ax.set_ylabel('Accuracy')\n",
    "ax.set_title('Accuracy Comparison of Models on Datasets')\n",
    "ax.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import matplotlib.pyplot as plt\n",
    "import os  # 파일 경로 처리를 위한 모듈\n",
    "\n",
    "# CSV 파일 경로\n",
    "# csv_file_path = \"/home/bhkim003/github_folder/ByeonghyeonKim/my_snn/ae_test_deprecated/250115/sweep0_vth_mul.csv\" # vth_mul해서 sweep 돌린거\n",
    "csv_file_path = \"/home/bhkim003/github_folder/ByeonghyeonKim/my_snn/ae_test_deprecated/250115/sweep1.csv\"  #vth_mul안한거\n",
    "\n",
    "# 결과를 저장할 리스트\n",
    "tuple_list = []\n",
    "\n",
    "# CSV 파일 읽기\n",
    "with open(csv_file_path, 'r') as file:\n",
    "    reader = csv.DictReader(file)\n",
    "    for row in reader:\n",
    "        try:\n",
    "            # v_threshold, TIME, v_reset, converted_k_means_acc 값을 가져와 튜플로 변환\n",
    "            v_threshold = float(row[\"v_threshold\"])\n",
    "            time = int(row[\"TIME\"])\n",
    "            v_reset = int(row[\"v_reset\"])\n",
    "            converted_k_means_acc = float(row[\"converted_k_means_acc\"]) if row[\"converted_k_means_acc\"] else None\n",
    "\n",
    "            # 튜플 형태로 추가 (값이 None일 경우 처리할 수도 있음)\n",
    "            tuple_list.append((v_threshold, time, v_reset, converted_k_means_acc))\n",
    "        except ValueError as e:\n",
    "            print(f\"Error processing row {row}: {e}\")\n",
    "\n",
    "# 데이터를 TIME 기준으로 정렬\n",
    "tuple_list.sort(key=lambda x: x[1])  # TIME을 기준으로 오름차순 정렬\n",
    "\n",
    "# reset 방식에 따라 데이터를 나누기\n",
    "soft_reset = [t for t in tuple_list if t[2] == 0]\n",
    "hard_reset = [t for t in tuple_list if t[2] == 10000]\n",
    "\n",
    "# reset 방식과 v_threshold에 따라 색상 설정\n",
    "def plot_data(data, label_prefix, marker):\n",
    "    for v_threshold in [1.0]:  # v_threshold 기준으로 제한\n",
    "        filtered_data = [(t[1], t[3]) for t in data if t[0] == v_threshold]\n",
    "        if filtered_data:  # 해당 v_threshold 데이터가 있을 경우만 플롯\n",
    "            times, accuracies = zip(*filtered_data)  # x축(TIME), y축(converted_k_means_acc)\n",
    "            \n",
    "            plt.plot(\n",
    "                times,\n",
    "                accuracies,\n",
    "                marker,\n",
    "                label=f\"{label_prefix}, v_threshold={v_threshold}\",\n",
    "                linestyle=\"--\",\n",
    "            )\n",
    "            # 각 점에 accuracy 표시\n",
    "            for time, acc in filtered_data:\n",
    "                if acc == None:\n",
    "                    continue\n",
    "                plt.text(time, acc, f\"{acc:.2f}\", fontsize=8, ha=\"right\")\n",
    "\n",
    "# 그래프 초기화\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "# soft_reset (v_reset=0) 데이터 플롯\n",
    "plot_data(soft_reset, \"Soft Reset\", \"o\")\n",
    "\n",
    "# hard_reset (v_reset=10000) 데이터 플롯\n",
    "plot_data(hard_reset, \"Hard Reset\", \"x\")\n",
    "\n",
    "# baseline accuracy 가로선 추가\n",
    "baseline_accuracy = 94.43\n",
    "plt.axhline(y=baseline_accuracy, color=\"red\", linestyle=\"-\", label=f\"Baseline Accuracy ({baseline_accuracy}%)\")\n",
    "# baseline 텍스트 추가\n",
    "plt.text(\n",
    "    2000,  # x축 위치 (그래프 오른쪽 끝)\n",
    "    baseline_accuracy + 0.4,  # y축 위치 (baseline 위 약간)\n",
    "    f\"ANN Baseline ({baseline_accuracy}%)\",\n",
    "    color=\"red\",\n",
    "    fontsize=10,\n",
    "    ha=\"center\",\n",
    ")\n",
    "\n",
    "# CSV 파일 이름 가져오기\n",
    "csv_file_name = os.path.basename(csv_file_path)\n",
    "\n",
    "# 그래프 세부 설정\n",
    "plt.title(f\"Converted SNN K-Means Accuracy vs TIME STEP - {csv_file_name}\")\n",
    "plt.xlabel(\"TIME STEP\")\n",
    "plt.ylabel(\"Converted K-Means Accuracy [%]\")\n",
    "plt.legend(loc=\"lower right\")  # 범례를 오른쪽 아래로 이동\n",
    "plt.grid(True)\n",
    "\n",
    "# 그래프 출력\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aedat2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
