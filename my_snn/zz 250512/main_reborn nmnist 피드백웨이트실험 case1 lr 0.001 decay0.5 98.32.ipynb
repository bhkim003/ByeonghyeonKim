{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_7826/3748606120.py:46: DeprecationWarning: The module snntorch.spikevision is deprecated. For loading neuromorphic datasets, we recommend using the Tonic project: https://github.com/neuromorphs/tonic\n",
      "  from snntorch.spikevision import spikedata\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x600 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "import argparse\n",
    "import torch\n",
    "import torch.nn as nn \n",
    "import torch.nn.functional as F\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.optim as optim\n",
    "import torch.optim.lr_scheduler as lr_scheduler\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "import torchvision\n",
    "import torchvision.datasets\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import time\n",
    "\n",
    "from snntorch import spikegen\n",
    "import matplotlib.pyplot as plt\n",
    "import snntorch.spikeplot as splt\n",
    "from IPython.display import HTML\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "from apex.parallel import DistributedDataParallel as DDP\n",
    "\n",
    "import random\n",
    "import datetime\n",
    "\n",
    "import json\n",
    "\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "''' 레퍼런스\n",
    "https://spikingjelly.readthedocs.io/zh-cn/0.0.0.0.4/spikingjelly.datasets.html#module-spikingjelly.datasets\n",
    "https://github.com/GorkaAbad/Sneaky-Spikes/blob/main/datasets.py\n",
    "https://github.com/GorkaAbad/Sneaky-Spikes/blob/main/how_to.md\n",
    "https://github.com/nmi-lab/torchneuromorphic\n",
    "https://snntorch.readthedocs.io/en/latest/snntorch.spikevision.spikedata.html#shd\n",
    "'''\n",
    "\n",
    "import snntorch\n",
    "from snntorch.spikevision import spikedata\n",
    "\n",
    "import modules.spikingjelly;\n",
    "from modules.spikingjelly.datasets.dvs128_gesture import DVS128Gesture\n",
    "from modules.spikingjelly.datasets.cifar10_dvs import CIFAR10DVS\n",
    "from modules.spikingjelly.datasets.n_mnist import NMNIST\n",
    "# from modules.spikingjelly.datasets.es_imagenet import ESImageNet\n",
    "from modules.spikingjelly.datasets import split_to_train_test_set\n",
    "from modules.spikingjelly.datasets.n_caltech101 import NCaltech101\n",
    "from modules.spikingjelly.datasets import pad_sequence_collate, padded_sequence_mask\n",
    "\n",
    "import modules.torchneuromorphic as torchneuromorphic\n",
    "\n",
    "import wandb\n",
    "\n",
    "from torchviz import make_dot\n",
    "import graphviz\n",
    "from turtle import shape\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# my module import\n",
    "from modules import *\n",
    "\n",
    "# modules 폴더에 새모듈.py 만들면\n",
    "# modules/__init__py 파일에 form .새모듈 import * 하셈\n",
    "# 그리고 새모듈.py에서 from modules.새모듈 import * 하셈\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def my_snn_system(devices = \"0,1,2,3\",\n",
    "                    single_step = False, # True # False\n",
    "                    unique_name = 'main',\n",
    "                    my_seed = 42,\n",
    "                    TIME = 10,\n",
    "                    BATCH = 256,\n",
    "                    IMAGE_SIZE = 32,\n",
    "                    which_data = 'CIFAR10',\n",
    "                    # CLASS_NUM = 10,\n",
    "                    data_path = '/data2',\n",
    "                    rate_coding = True,\n",
    "    \n",
    "                    lif_layer_v_init = 0.0,\n",
    "                    lif_layer_v_decay = 0.6,\n",
    "                    lif_layer_v_threshold = 1.2,\n",
    "                    lif_layer_v_reset = 0.0,\n",
    "                    lif_layer_sg_width = 1,\n",
    "\n",
    "                    # synapse_conv_in_channels = IMAGE_PIXEL_CHANNEL,\n",
    "                    synapse_conv_kernel_size = 3,\n",
    "                    synapse_conv_stride = 1,\n",
    "                    synapse_conv_padding = 1,\n",
    "\n",
    "                    synapse_trace_const1 = 1,\n",
    "                    synapse_trace_const2 = 0.6,\n",
    "\n",
    "                    # synapse_fc_out_features = CLASS_NUM,\n",
    "\n",
    "                    pre_trained = False,\n",
    "                    convTrue_fcFalse = True,\n",
    "\n",
    "                    cfg = [64, 64],\n",
    "                    net_print = False, # True # False\n",
    "                    \n",
    "                    pre_trained_path = \"net_save/save_now_net.pth\",\n",
    "                    learning_rate = 0.0001,\n",
    "                    epoch_num = 200,\n",
    "                    tdBN_on = False,\n",
    "                    BN_on = False,\n",
    "\n",
    "                    surrogate = 'sigmoid',\n",
    "\n",
    "                    BPTT_on = False,\n",
    "\n",
    "                    optimizer_what = 'SGD', # 'SGD' 'Adam', 'RMSprop'\n",
    "                    scheduler_name = 'no',\n",
    "                    \n",
    "                    ddp_on = False, # DECREPATED # fALSE\n",
    "\n",
    "                    dvs_clipping = 1, \n",
    "                    dvs_duration = 25_000,\n",
    "\n",
    "\n",
    "                    DFA_on = False, # True # False\n",
    "                    trace_on = False, \n",
    "                    OTTT_input_trace_on = False, # True # False\n",
    "                    \n",
    "                    exclude_class = True, # True # False # gesture에서 10번째 클래스 제외\n",
    "\n",
    "                    merge_polarities = False, # True # False # tonic dvs dataset 에서 polarities 합치기\n",
    "                    denoise_on = True, \n",
    "\n",
    "                    extra_train_dataset = 0, # DECREPATED # data_loader에서 train dataset을 몇개 더 쓸건지 \n",
    "\n",
    "                    num_workers = 2,\n",
    "                    chaching_on = True,\n",
    "                    pin_memory = True, # True # False\n",
    "                    \n",
    "                    UDA_on = False,  # DECREPATED # uda\n",
    "                    alpha_uda = 1.0, # DECREPATED # uda\n",
    "\n",
    "                    bias = True,\n",
    "\n",
    "                    last_lif = False,\n",
    "                        \n",
    "                    temporal_filter = 1, \n",
    "                    initial_pooling = 1,\n",
    "\n",
    "                    temporal_filter_accumulation = False,\n",
    "                    ):\n",
    "    ## 함수 내 모든 로컬 변수 저장 ########################################################\n",
    "    hyperparameters = locals()\n",
    "    print('param', hyperparameters,'\\n')\n",
    "    hyperparameters['current epoch'] = 0\n",
    "    ######################################################################################\n",
    "\n",
    "    ## hyperparameter check #############################################################\n",
    "    if single_step == True:\n",
    "        assert BPTT_on == False and tdBN_on == False \n",
    "    if tdBN_on == True:\n",
    "        assert BPTT_on == True\n",
    "    if pre_trained == True:\n",
    "        print('\\n\\n')\n",
    "        print(\"Caution! pre_trained is True\\n\\n\"*3)    \n",
    "    if DFA_on == True:\n",
    "        assert single_step == True and BPTT_on == False \n",
    "    # assert single_step == DFA_on, 'DFA랑 single_step공존하게해라'\n",
    "    if trace_on:\n",
    "        assert BPTT_on == False and single_step == True\n",
    "    if OTTT_input_trace_on == True:\n",
    "        assert BPTT_on == False and single_step == True #and trace_on == True\n",
    "    if temporal_filter > 1:\n",
    "        assert convTrue_fcFalse == False\n",
    "    ######################################################################################\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "    ## wandb 세팅 ###################################################################\n",
    "    current_time = datetime.datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "    wandb.config.update(hyperparameters)\n",
    "    wandb.run.name = f'lr_{learning_rate}_{unique_name}_{which_data}_tstep{TIME}'\n",
    "    wandb.define_metric(\"summary_val_acc\", summary=\"max\")\n",
    "    # wandb.run.log_code(\".\", \n",
    "    #                     include_fn=lambda path: path.endswith(\".py\") or path.endswith(\".ipynb\"),\n",
    "    #                     exclude_fn=lambda path: 'logs/' in path or 'net_save/' in path or 'result_save/' in path or 'trying/' in path or 'wandb/' in path or 'private/' in path or '.git/' in path or 'tonic' in path or 'torchneuromorphic' in path or 'spikingjelly' in path \n",
    "    #                     )\n",
    "    ###################################################################################\n",
    "\n",
    "\n",
    "\n",
    "    ## gpu setting ##################################################################################################################\n",
    "    os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\" \n",
    "    os.environ[\"CUDA_VISIBLE_DEVICES\"]= devices\n",
    "    ###################################################################################################################################\n",
    "\n",
    "\n",
    "    ## seed setting ##################################################################################################################\n",
    "    seed_assign(my_seed)\n",
    "    ###################################################################################################################################\n",
    "    \n",
    "\n",
    "    ## data_loader 가져오기 ##################################################################################################################\n",
    "    # data loader, pixel channel, class num\n",
    "    train_data_split_indices = []\n",
    "    train_loader, test_loader, synapse_conv_in_channels, CLASS_NUM, train_data_count = data_loader(\n",
    "            which_data,\n",
    "            data_path, \n",
    "            rate_coding, \n",
    "            BATCH, \n",
    "            IMAGE_SIZE,\n",
    "            ddp_on,\n",
    "            TIME*temporal_filter, \n",
    "            dvs_clipping,\n",
    "            dvs_duration,\n",
    "            exclude_class,\n",
    "            merge_polarities,\n",
    "            denoise_on,\n",
    "            my_seed,\n",
    "            extra_train_dataset,\n",
    "            num_workers,\n",
    "            chaching_on,\n",
    "            pin_memory,\n",
    "            train_data_split_indices,) \n",
    "    synapse_fc_out_features = CLASS_NUM\n",
    "\n",
    "    print('\\nlen(train_loader):', len(train_loader), 'BATCH:', BATCH, 'train_data_count:', train_data_count) \n",
    "    print('len(test_loader):', len(test_loader), 'BATCH:', BATCH)\n",
    "\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    print(f\"\\ndevice ==> {device}\\n\")\n",
    "    if device == \"cpu\":\n",
    "        print(\"=\"*50,\"\\n[WARNING]\\n[WARNING]\\n[WARNING]\\n: cpu mode\\n\\n\",\"=\"*50)\n",
    "\n",
    "    ### network setting #######################################################################################################################\n",
    "    if (convTrue_fcFalse == False):\n",
    "        net = REBORN_MY_SNN_FC(cfg, synapse_conv_in_channels*temporal_filter, IMAGE_SIZE//initial_pooling, synapse_fc_out_features,\n",
    "                    synapse_trace_const1, synapse_trace_const2, \n",
    "                    lif_layer_v_init, lif_layer_v_decay, \n",
    "                    lif_layer_v_threshold, lif_layer_v_reset,\n",
    "                    lif_layer_sg_width,\n",
    "                    tdBN_on,\n",
    "                    BN_on, TIME,\n",
    "                    surrogate,\n",
    "                    BPTT_on,\n",
    "                    DFA_on,\n",
    "                    bias,\n",
    "                    single_step,\n",
    "                    last_lif,\n",
    "                    trace_on).to(device)\n",
    "    else:\n",
    "        net = REBORN_MY_SNN_CONV(cfg, synapse_conv_in_channels, IMAGE_SIZE//initial_pooling,\n",
    "                    synapse_conv_kernel_size, synapse_conv_stride, \n",
    "                    synapse_conv_padding, synapse_trace_const1, \n",
    "                    synapse_trace_const2, \n",
    "                    lif_layer_v_init, lif_layer_v_decay, \n",
    "                    lif_layer_v_threshold, lif_layer_v_reset,\n",
    "                    lif_layer_sg_width,\n",
    "                    synapse_fc_out_features, \n",
    "                    tdBN_on,\n",
    "                    BN_on, TIME,\n",
    "                    surrogate,\n",
    "                    BPTT_on,\n",
    "                    DFA_on,\n",
    "                    bias,\n",
    "                    single_step,\n",
    "                    last_lif,\n",
    "                    trace_on).to(device)\n",
    "\n",
    "    net = torch.nn.DataParallel(net) \n",
    "    \n",
    "    if pre_trained == True:\n",
    "        net.load_state_dict(torch.load(pre_trained_path))\n",
    "    \n",
    "    net = net.to(device)\n",
    "    if (net_print == True):\n",
    "        print(net)    \n",
    "\n",
    "    print(f\"\\n========================================================\\nTrainable parameters: {sum(p.numel() for p in net.parameters() if p.requires_grad):,}\\n========================================================\\n\")\n",
    "    ####################################################################################################################################\n",
    "    \n",
    "\n",
    "    ## wandb logging ###########################################\n",
    "    # wandb.watch(net, log=\"all\", log_freq = 10) #gradient, parameter logging해줌\n",
    "    ############################################################\n",
    "\n",
    "    ## criterion ########################################## # loss 구해주는 친구\n",
    "    def my_cross_entropy_loss(logits, targets):\n",
    "        # logits: (batch_size, num_classes)\n",
    "        # targets: (batch_size,) -> 클래스 인덱스\n",
    "        log_probs = F.log_softmax(logits, dim=1)  # log(p_i)\n",
    "        loss = F.nll_loss(log_probs, targets)\n",
    "        # print(loss.shape)\n",
    "        return loss\n",
    "    \n",
    "    class CustomLossFunction(torch.autograd.Function):\n",
    "        @staticmethod\n",
    "        def forward(ctx, input, target):\n",
    "            # MSE를 계산\n",
    "            ctx.save_for_backward(input, target)\n",
    "            target_one_hot = torch.zeros_like(input).scatter_(1, target.unsqueeze(1), 1.0)\n",
    "            return torch.mean((input - target_one_hot) ** 2)\n",
    "\n",
    "        @staticmethod\n",
    "        def backward(ctx, grad_output):\n",
    "            # MAE 스타일의 gradient를 흉내냄\n",
    "            input, target = ctx.saved_tensors\n",
    "            input_argmax = input.argmax(dim=1)\n",
    "            input_one_hot = torch.zeros_like(input).scatter_(1, input_argmax.unsqueeze(1), 1.0)\n",
    "            target_one_hot = torch.zeros_like(input).scatter_(1, target.unsqueeze(1), 1.0)\n",
    "            # print('grad_output', grad_output) # 이거 걍 1.0임\n",
    "            return input_one_hot - target_one_hot, None  # target에는 gradient 없음\n",
    "\n",
    "    # Wrapper module\n",
    "    class CustomCriterion(torch.nn.Module):\n",
    "        def __init__(self):\n",
    "            super().__init__()\n",
    "\n",
    "        def forward(self, input, target):\n",
    "            return CustomLossFunction.apply(input, target)\n",
    "\n",
    "    criterion = nn.CrossEntropyLoss().to(device)\n",
    "    # criterion = CustomCriterion().to(device)\n",
    "    \n",
    "    # if (OTTT_sWS_on == True):\n",
    "    #     # criterion = nn.CrossEntropyLoss().to(device)\n",
    "        # criterion = lambda y_t, target_t: ((1 - 0.05) * F.cross_entropy(y_t, target_t) + 0.05 * F.mse_loss(y_t, F.one_hot(target_t, CLASS_NUM).float())) / TIME \n",
    "    #     if which_data == 'DVS_GESTURE':\n",
    "    #         criterion = lambda y_t, target_t: ((1 - 0.001) * F.cross_entropy(y_t, target_t) + 0.001 * F.mse_loss(y_t, F.one_hot(target_t, CLASS_NUM).float())) / TIME \n",
    "    \n",
    "    print('current loss function:', criterion)\n",
    "    ####################################################\n",
    "    \n",
    "    ## optimizer, scheduler ########################################################################\n",
    "    if(optimizer_what == 'SGD'):\n",
    "        optimizer = optim.SGD(net.parameters(), lr=learning_rate, momentum=0.9)\n",
    "        # optimizer = optim.SGD(net.parameters(), lr=learning_rate, momentum=0.9, weight_decay=0)\n",
    "    elif(optimizer_what == 'Adam'):\n",
    "        optimizer = torch.optim.Adam(net.parameters(), lr=learning_rate)\n",
    "        # optimizer = torch.optim.Adam(net.parameters(), lr=0.00001)\n",
    "        # optimizer = torch.optim.Adam(net.parameters(), lr=learning_rate/256 * BATCH, weight_decay=1e-4)\n",
    "        # optimizer = optim.Adam(net.parameters(), lr=learning_rate, weight_decay=0, betas=(0.9, 0.999))\n",
    "    elif(optimizer_what == 'RMSprop'):\n",
    "        pass\n",
    "\n",
    "\n",
    "    if (scheduler_name == 'StepLR'):\n",
    "        scheduler = lr_scheduler.StepLR(optimizer, step_size=10, gamma=0.1)\n",
    "    elif (scheduler_name == 'ExponentialLR'):\n",
    "        scheduler = lr_scheduler.ExponentialLR(optimizer, gamma=0.95)\n",
    "    elif (scheduler_name == 'ReduceLROnPlateau'):\n",
    "        scheduler = lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.1, patience=10)\n",
    "    elif (scheduler_name == 'CosineAnnealingLR'):\n",
    "        # scheduler = lr_scheduler.CosineAnnealingLR(optimizer, eta_min=0, T_max=50)\n",
    "        scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, eta_min=0, T_max=epoch_num)\n",
    "    elif (scheduler_name == 'OneCycleLR'):\n",
    "        scheduler = lr_scheduler.OneCycleLR(optimizer, max_lr=0.1, steps_per_epoch=len(train_loader), epochs=epoch_num)\n",
    "    else:\n",
    "        pass # 'no' scheduler\n",
    "    ## optimizer, scheduler ########################################################################\n",
    "\n",
    "\n",
    "    tr_acc = 0\n",
    "    tr_correct = 0\n",
    "    tr_total = 0\n",
    "    tr_acc_best = 0\n",
    "    tr_epoch_loss_temp = 0\n",
    "    tr_epoch_loss = 0\n",
    "    val_acc_best = 0\n",
    "    val_acc_now = 0\n",
    "    val_loss = 0\n",
    "    iter_of_val = False\n",
    "    #======== EPOCH START ==========================================================================================\n",
    "    for epoch in range(epoch_num):\n",
    "        if epoch == 1:\n",
    "            for name, module in net.named_modules():\n",
    "                if isinstance(module, Feedback_Receiver):\n",
    "                    print(f\"[{name}] weight_fb parameter count: {module.weight_fb.numel():,}\")\n",
    "        ####### iterator : input_loading & tqdm을 통한 progress_bar 생성###################\n",
    "        iterator = enumerate(train_loader, 0)\n",
    "        # iterator = tqdm(iterator, total=len(train_loader), desc='train', dynamic_ncols=True, position=0, leave=True)\n",
    "        ##################################################################################   \n",
    "\n",
    "        ###### ITERATION START ##########################################################################################################\n",
    "        for i, data in iterator:\n",
    "            net.train() # train 모드로 바꿔줘야함\n",
    "            ### data loading & semi-pre-processing ################################################################################\n",
    "            if len(data) == 2:\n",
    "                inputs, labels = data\n",
    "                # 처리 로직 작성\n",
    "            elif len(data) == 3:\n",
    "                inputs, labels, x_len = data\n",
    "            else:\n",
    "                assert False, 'data length is not 2 or 3'\n",
    "            #######################################################################################################################\n",
    "                \n",
    "            ## batch 크기 ######################################\n",
    "            real_batch = labels.size(0)\n",
    "            ###########################################################\n",
    "\n",
    "            # 차원 전처리\n",
    "            ###########################################################################################################################        \n",
    "            if (which_data == 'DVS_CIFAR10' or which_data == 'DVS_GESTURE' or which_data == 'DVS_GESTURE_TONIC' or which_data == 'DVS_CIFAR10_2' or which_data == 'NMNIST' or which_data == 'NMNIST_TONIC' or which_data == 'N_CALTECH101' or which_data == 'n_tidigits' or which_data == 'heidelberg'):\n",
    "                inputs = inputs.permute(1, 0, 2, 3, 4)\n",
    "            elif rate_coding == True :\n",
    "                inputs = spikegen.rate(inputs, num_steps=TIME)\n",
    "            else :\n",
    "                inputs = inputs.repeat(TIME, 1, 1, 1, 1)\n",
    "            # inputs: [Time, Batch, Channel, Height, Width]  \n",
    "            ####################################################################################################################### \n",
    "                \n",
    "\n",
    "\n",
    "                            \n",
    "            ## initial pooling #######################################################################\n",
    "            if (initial_pooling > 1):\n",
    "                pool = nn.MaxPool2d(kernel_size=2)\n",
    "                num_pooling_layers = int(math.log2(initial_pooling))\n",
    "                # Time, Batch, Channel 차원은 그대로 두고, Height, Width 차원에 대해서만 pooling 적용\n",
    "                shape_temp = inputs.shape\n",
    "                inputs = inputs.reshape(shape_temp[0]*shape_temp[1], shape_temp[2], shape_temp[3], shape_temp[4])\n",
    "                for _ in range(num_pooling_layers):\n",
    "                    inputs = pool(inputs)\n",
    "                inputs = inputs.reshape(shape_temp[0], shape_temp[1], shape_temp[2], shape_temp[3]//initial_pooling, shape_temp[4]//initial_pooling)\n",
    "            ## initial pooling #######################################################################\n",
    "            ## temporal filtering ####################################################################\n",
    "            shape_temp = inputs.shape\n",
    "            if (temporal_filter > 1):\n",
    "                slice_bucket = []\n",
    "                for t_temp in range(TIME):\n",
    "                    start = t_temp * temporal_filter\n",
    "                    end = start + temporal_filter\n",
    "                    slice_concat = torch.movedim(inputs[start:end], 0, 1).reshape(shape_temp[1],shape_temp[2],shape_temp[3],-1)\n",
    "                    \n",
    "                    if temporal_filter_accumulation == True:\n",
    "                        if t_temp == 0:\n",
    "                            slice_bucket.append(slice_concat)\n",
    "                        else:\n",
    "                            slice_bucket.append(slice_concat+slice_bucket[t_temp-1])\n",
    "                    else:\n",
    "                        slice_bucket.append(slice_concat)\n",
    "\n",
    "                inputs = torch.stack(slice_bucket, dim=0)\n",
    "                if temporal_filter_accumulation == True and dvs_clipping > 0:\n",
    "                    inputs = (inputs != 0.0).float()\n",
    "            ## temporal filtering ####################################################################\n",
    "            ####################################################################################################################### \n",
    "                \n",
    "\n",
    "            # # dvs 데이터 시각화 코드 (확인 필요할 시 써라)\n",
    "            # ##############################################################################################\n",
    "            # dvs_visualization(inputs, labels, TIME, BATCH, my_seed)\n",
    "            # #####################################################################################################\n",
    "\n",
    "            ## to (device) #######################################\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "            ###########################################################\n",
    "\n",
    "            ## gradient 초기화 #######################################\n",
    "            optimizer.zero_grad()\n",
    "            ###########################################################\n",
    "                            \n",
    "            if merge_polarities == True:\n",
    "                inputs = inputs[:,:,0:1,:,:]\n",
    "\n",
    "            if single_step == False:\n",
    "                # net에 넣어줄때는 batch가 젤 앞 차원으로 와야함. # dataparallel때매##############################\n",
    "                # inputs: [Time, Batch, Channel, Height, Width]   \n",
    "                inputs = inputs.permute(1, 0, 2, 3, 4) # net에 넣어줄때는 batch가 젤 앞 차원으로 와야함. # dataparallel때매\n",
    "                # inputs: [Batch, Time, Channel, Height, Width] \n",
    "                #################################################################################################\n",
    "            else:\n",
    "                labels = labels.repeat(TIME, 1)\n",
    "                ## first input도 ottt trace 적용하기 위한 코드 (validation 시에는 필요X) ##########################\n",
    "                if trace_on == True and OTTT_input_trace_on == True:\n",
    "                    spike = inputs\n",
    "                    trace = torch.full_like(spike, fill_value = 0.0, dtype = torch.float, requires_grad=False)\n",
    "                    inputs = []\n",
    "                    for t in range(TIME):\n",
    "                        trace[t] = trace[t-1]*synapse_trace_const2 + spike[t]*synapse_trace_const1\n",
    "                        inputs += [[spike[t], trace[t]]]\n",
    "                ##################################################################################################\n",
    "\n",
    "\n",
    "            if single_step == False:\n",
    "                ### input --> net --> output #####################################################\n",
    "                outputs = net(inputs)\n",
    "                ##################################################################################\n",
    "                ## loss, backward ##########################################\n",
    "                iter_loss = criterion(outputs, labels)\n",
    "                iter_loss.backward()\n",
    "                ############################################################\n",
    "                ## weight 업데이트!! ##################################\n",
    "                optimizer.step()\n",
    "                ################################################################\n",
    "            else:\n",
    "                outputs_all = []\n",
    "                iter_loss = 0.0\n",
    "                for t in range(TIME):\n",
    "                    ### input[t] --> net --> output_one_time #########################################\n",
    "                    outputs_one_time = net(inputs[t])\n",
    "                    ##################################################################################\n",
    "                    one_time_loss = criterion(outputs_one_time, labels[t].contiguous())\n",
    "                    one_time_loss.backward() # one_time backward\n",
    "                    iter_loss += one_time_loss.data\n",
    "                    outputs_all.append(outputs_one_time.detach())\n",
    "                optimizer.step() # full step time update\n",
    "                outputs_all = torch.stack(outputs_all, dim=1)\n",
    "                outputs = outputs_all.mean(1) # ottt꺼 쓸때\n",
    "                labels = labels[0]\n",
    "                iter_loss /= TIME\n",
    "\n",
    "            tr_epoch_loss_temp += iter_loss.data/len(train_loader)\n",
    "\n",
    "            ## net 그림 출력해보기 #################################################################\n",
    "            # print('시각화')\n",
    "            # make_dot(outputs, params=dict(list(net.named_parameters()))).render(\"net_torchviz\", format=\"png\")\n",
    "            # return 0\n",
    "            ##################################################################################\n",
    "\n",
    "            #### batch 어긋남 방지 ###############################################\n",
    "            assert real_batch == outputs.size(0), f'batch size is not same. real_batch: {real_batch}, outputs.size(0): {outputs.size(0)}'\n",
    "            #######################################################################\n",
    "            \n",
    "\n",
    "            ####### training accruacy save for print ###############################\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total = real_batch\n",
    "            correct = (predicted == labels).sum().item()\n",
    "            iter_acc = correct / total\n",
    "            tr_total += total\n",
    "            tr_correct += correct\n",
    "            iter_acc_string = f'epoch-{epoch:<3} iter_acc:{100 * iter_acc:7.2f}%, lr={[f\"{lr:9.7f}\" for lr in (param_group[\"lr\"] for param_group in optimizer.param_groups)]}'\n",
    "            iter_acc_string2 = f'epoch-{epoch:<3} lr={[f\"{lr:9.7f}\" for lr in (param_group[\"lr\"] for param_group in optimizer.param_groups)]}'\n",
    "            ################################################################\n",
    "            \n",
    "\n",
    "            ##### validation ##################################################################################################################################\n",
    "            if i == len(train_loader)-1 :\n",
    "                iter_of_val = True\n",
    "\n",
    "                tr_acc = tr_correct/tr_total\n",
    "                tr_correct = 0\n",
    "                tr_total = 0\n",
    "\n",
    "                val_loss = 0\n",
    "                correct_val = 0\n",
    "                total_val = 0\n",
    "\n",
    "                with torch.no_grad():\n",
    "                    net.eval() # eval 모드로 바꿔줘야함 \n",
    "                    for data_val in test_loader:\n",
    "                        ## data_val loading & semi-pre-processing ##########################################################\n",
    "                        if len(data_val) == 2:\n",
    "                            inputs_val, labels_val = data_val\n",
    "                        elif len(data_val) == 3:\n",
    "                            inputs_val, labels_val, x_len = data_val\n",
    "                        else:\n",
    "                            assert False, 'data_val length is not 2 or 3'\n",
    "\n",
    "                        if (which_data == 'DVS_CIFAR10' or which_data == 'DVS_GESTURE' or which_data == 'DVS_GESTURE_TONIC' or which_data == 'DVS_CIFAR10_2' or which_data == 'NMNIST' or which_data == 'NMNIST_TONIC' or which_data == 'N_CALTECH101' or which_data == 'n_tidigits' or which_data == 'heidelberg'):\n",
    "                            inputs_val = inputs_val.permute(1, 0, 2, 3, 4)\n",
    "                        elif rate_coding == True :\n",
    "                            inputs_val = spikegen.rate(inputs_val, num_steps=TIME)\n",
    "                        else :\n",
    "                            inputs_val = inputs_val.repeat(TIME, 1, 1, 1, 1)\n",
    "                        # inputs_val: [Time, Batch, Channel, Height, Width]  \n",
    "                        ###################################################################################################\n",
    "\n",
    "                        \n",
    "                        ## initial pooling #######################################################################\n",
    "                        if (initial_pooling > 1):\n",
    "                            pool = nn.MaxPool2d(kernel_size=2)\n",
    "                            num_pooling_layers = int(math.log2(initial_pooling))\n",
    "                            # Time, Batch, Channel 차원은 그대로 두고, Height, Width 차원에 대해서만 pooling 적용\n",
    "                            shape_temp = inputs_val.shape\n",
    "                            inputs_val = inputs_val.reshape(shape_temp[0]*shape_temp[1], shape_temp[2], shape_temp[3], shape_temp[4])\n",
    "                            for _ in range(num_pooling_layers):\n",
    "                                inputs_val = pool(inputs_val)\n",
    "                            inputs_val = inputs_val.reshape(shape_temp[0], shape_temp[1], shape_temp[2], shape_temp[3]//initial_pooling, shape_temp[4]//initial_pooling)\n",
    "                        ## initial pooling #######################################################################\n",
    "\n",
    "                        ## temporal filtering ####################################################################\n",
    "                        shape_temp = inputs_val.shape\n",
    "                        if (temporal_filter > 1):\n",
    "                            slice_bucket = []\n",
    "                            for t_temp in range(TIME):\n",
    "                                start = t_temp * temporal_filter\n",
    "                                end = start + temporal_filter\n",
    "                                slice_concat = torch.movedim(inputs_val[start:end], 0, 1).reshape(shape_temp[1],shape_temp[2],shape_temp[3],-1)\n",
    "                                \n",
    "                                if temporal_filter_accumulation == True:\n",
    "                                    if t_temp == 0:\n",
    "                                        slice_bucket.append(slice_concat)\n",
    "                                    else:\n",
    "                                        slice_bucket.append(slice_concat+slice_bucket[t_temp-1])\n",
    "                                else:\n",
    "                                    slice_bucket.append(slice_concat)\n",
    "\n",
    "                            inputs_val = torch.stack(slice_bucket, dim=0)\n",
    "                            if temporal_filter_accumulation == True and dvs_clipping > 0:\n",
    "                                inputs = (inputs != 0.0).float()\n",
    "                        ## temporal filtering ####################################################################\n",
    "                            \n",
    "                        inputs_val = inputs_val.to(device)\n",
    "                        labels_val = labels_val.to(device)\n",
    "                        real_batch = labels_val.size(0)\n",
    "                        \n",
    "                        if merge_polarities == True:\n",
    "                            inputs_val = inputs_val[:,:,0:1,:,:]\n",
    "\n",
    "                        ## network 연산 시작 ############################################################################################################\n",
    "                        if single_step == False:\n",
    "                            outputs = net(inputs_val.permute(1, 0, 2, 3, 4)) #inputs_val: [Batch, Time, Channel, Height, Width]  \n",
    "                            val_loss += criterion(outputs, labels_val)/len(test_loader)\n",
    "                        else:\n",
    "                            outputs_all = []\n",
    "                            for t in range(TIME):\n",
    "                                outputs = net(inputs_val[t])\n",
    "                                val_loss_temp = criterion(outputs, labels_val)\n",
    "                                outputs_all.append(outputs.detach())\n",
    "                                val_loss += (val_loss_temp.data/TIME)/len(test_loader)\n",
    "                            outputs_all = torch.stack(outputs_all, dim=1)\n",
    "                            outputs = outputs_all.mean(1)\n",
    "                        #################################################################################################################################\n",
    "\n",
    "                        _, predicted = torch.max(outputs.data, 1)\n",
    "                        total_val += real_batch\n",
    "                        assert real_batch == outputs.size(0), f'batch size is not same. real_batch: {real_batch}, outputs.size(0): {outputs.size(0)}'\n",
    "                        correct_val += (predicted == labels_val).sum().item()\n",
    "\n",
    "                    val_acc_now = correct_val / total_val\n",
    "\n",
    "                if val_acc_best < val_acc_now:\n",
    "                    val_acc_best = val_acc_now\n",
    "                    # wandb 키면 state_dict아닌거는 저장 안됨\n",
    "                    # network save\n",
    "                    # torch.save(net.state_dict(), f\"net_save/save_now_net_weights_{unique_name}.pth\")\n",
    "\n",
    "                if tr_acc_best < tr_acc:\n",
    "                    tr_acc_best = tr_acc\n",
    "\n",
    "                tr_epoch_loss = tr_epoch_loss_temp\n",
    "                tr_epoch_loss_temp = 0\n",
    "\n",
    "            ####################################################################################################################################################\n",
    "            \n",
    "            ## progress bar update ############################################################################################################\n",
    "            if iter_of_val == False:\n",
    "                # iterator.set_description(f\"{iter_acc_string}, iter_loss:{iter_loss:10.6f}\") \n",
    "                pass \n",
    "            else:\n",
    "                # iterator.set_description(f\"{iter_acc_string2}, tr/val_loss:{tr_epoch_loss:10.6f}/{val_loss:10.6f}, tr:{100 * tr_acc:7.2f}%, tr_best:{100 * tr_acc_best:7.2f}%, val:{100 * val_acc_now:7.2f}%, val_best:{100 * val_acc_best:7.2f}%\")  \n",
    "                print(f\"{iter_acc_string2}, tr/val_loss:{tr_epoch_loss:10.6f}/{val_loss:10.6f}, val:{100 * val_acc_now:7.2f}%, val_best:{100 * val_acc_best:7.2f}%, tr:{100 * tr_acc:7.2f}%, tr_best:{100 * tr_acc_best:7.2f}%\")\n",
    "                iter_of_val = False\n",
    "            ####################################################################################################################################\n",
    "            \n",
    "            ## wandb logging ############################################################################################################\n",
    "            wandb.log({\"iter_acc\": iter_acc})\n",
    "            wandb.log({\"tr_acc\": tr_acc})\n",
    "            wandb.log({\"val_acc_now\": val_acc_now})\n",
    "            wandb.log({\"val_acc_best\": val_acc_best})\n",
    "            wandb.log({\"summary_val_acc\": val_acc_now})\n",
    "            wandb.log({\"epoch\": epoch})\n",
    "            wandb.log({\"val_loss\": val_loss}) \n",
    "            wandb.log({\"tr_epoch_loss\": tr_epoch_loss})   \n",
    "            ####################################################################################################################################\n",
    "            \n",
    "        ###### ITERATION END ##########################################################################################################\n",
    "\n",
    "        ## scheduler update #############################################################################\n",
    "        if (scheduler_name != 'no'):\n",
    "            if (scheduler_name == 'ReduceLROnPlateau'):\n",
    "                scheduler.step(val_loss)\n",
    "            else:\n",
    "                scheduler.step()\n",
    "        #################################################################################################\n",
    "        \n",
    "    #======== EPOCH END ==========================================================================================\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# unique_name = 'main' ## 이거 설정하면 새로운 경로에 모두 save\n",
    "# wandb.init(project= f'my_snn {unique_name}',save_code=False, dir='/data2/bh_wandb', tags=[\"common\"])\n",
    "# ## wandb 과거 하이퍼파라미터 가져와서 붙여넣기 (devices unique_name은 니가 할당해라)#################################\n",
    "# param = {'devices': '3', 'single_step': True, 'unique_name': 'main', 'my_seed': 42, 'TIME': 10, 'BATCH': 16, 'IMAGE_SIZE': 128, 'which_data': 'DVS_GESTURE_TONIC', 'data_path': '/data2', 'rate_coding': False, 'lif_layer_v_init': 0, 'lif_layer_v_decay': 0.25, 'lif_layer_v_threshold': 0.75, 'lif_layer_v_reset': 0, 'lif_layer_sg_width': 4, 'synapse_conv_kernel_size': 3, 'synapse_conv_stride': 1, 'synapse_conv_padding': 1, 'synapse_trace_const1': 1, 'synapse_trace_const2': 0, 'pre_trained': False, 'convTrue_fcFalse': False, 'cfg': [200, 200], 'net_print': True, 'pre_trained_path': 'net_save/save_now_net_weights_{unique_name}.pth', 'learning_rate': 0.001, 'epoch_num': 100, 'tdBN_on': False, 'BN_on': False, 'surrogate': 'hard_sigmoid', 'BPTT_on': False, 'optimizer_what': 'SGD', 'scheduler_name': 'no', 'ddp_on': False, 'dvs_clipping': 2, 'dvs_duration': 25000, 'DFA_on': True, 'trace_on': True, 'OTTT_input_trace_on': False, 'exclude_class': True, 'merge_polarities': False, 'denoise_on': True, 'extra_train_dataset': 0, 'num_workers': 2, 'chaching_on': True, 'pin_memory': True, 'UDA_on': False, 'alpha_uda': 1, 'bias': True, 'last_lif': False, 'temporal_filter': 5, 'initial_pooling': 8}\n",
    "# my_snn_system(devices = '0',single_step = param['single_step'],unique_name = unique_name,my_seed = param['my_seed'],TIME = param['TIME'],BATCH = param['BATCH'],IMAGE_SIZE = param['IMAGE_SIZE'],which_data = param['which_data'],data_path = param['data_path'],rate_coding = param['rate_coding'],lif_layer_v_init = param['lif_layer_v_init'],lif_layer_v_decay = param['lif_layer_v_decay'],lif_layer_v_threshold = param['lif_layer_v_threshold'],lif_layer_v_reset = param['lif_layer_v_reset'],lif_layer_sg_width = param['lif_layer_sg_width'],synapse_conv_kernel_size = param['synapse_conv_kernel_size'],synapse_conv_stride = param['synapse_conv_stride'],synapse_conv_padding = param['synapse_conv_padding'],synapse_trace_const1 = param['synapse_trace_const1'],synapse_trace_const2 = param['synapse_trace_const2'],pre_trained = param['pre_trained'],convTrue_fcFalse = param['convTrue_fcFalse'],cfg = param['cfg'],net_print = param['net_print'],pre_trained_path = param['pre_trained_path'],learning_rate = param['learning_rate'],epoch_num = param['epoch_num'],tdBN_on = param['tdBN_on'],BN_on = param['BN_on'],surrogate = param['surrogate'],BPTT_on = param['BPTT_on'],optimizer_what = param['optimizer_what'],scheduler_name = param['scheduler_name'],ddp_on = param['ddp_on'],dvs_clipping = param['dvs_clipping'],dvs_duration = param['dvs_duration'],DFA_on = param['DFA_on'],trace_on = param['trace_on'],OTTT_input_trace_on = param['OTTT_input_trace_on'],exclude_class = param['exclude_class'],merge_polarities = param['merge_polarities'],denoise_on = param['denoise_on'],extra_train_dataset = param['extra_train_dataset'],num_workers = param['num_workers'],chaching_on = param['chaching_on'],pin_memory = param['pin_memory'],UDA_on = param['UDA_on'],alpha_uda = param['alpha_uda'],bias = param['bias'],last_lif = param['last_lif'],temporal_filter = param['temporal_filter'],initial_pooling = param['initial_pooling'],temporal_filter_accumulation= param['temporal_filter_accumulation'])\n",
    "# #############################################################################\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mbhkim003\u001b[0m (\u001b[33mbhkim003-seoul-national-university\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.19.11 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.17.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/data2/bh_wandb/wandb/run-20250512_125952-cpdebrwq</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/cpdebrwq' target=\"_blank\">exalted-water-8377</a></strong> to <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/cpdebrwq' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/cpdebrwq</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "param {'devices': '2', 'single_step': True, 'unique_name': 'main', 'my_seed': 42, 'TIME': 10, 'BATCH': 16, 'IMAGE_SIZE': 17, 'which_data': 'NMNIST_TONIC', 'data_path': '/data2', 'rate_coding': False, 'lif_layer_v_init': 0.0, 'lif_layer_v_decay': 0.5, 'lif_layer_v_threshold': 0.5, 'lif_layer_v_reset': 10000.0, 'lif_layer_sg_width': 4.0, 'synapse_conv_kernel_size': 3, 'synapse_conv_stride': 1, 'synapse_conv_padding': 1, 'synapse_trace_const1': 1, 'synapse_trace_const2': 0.5, 'pre_trained': False, 'convTrue_fcFalse': False, 'cfg': [200, 200], 'net_print': True, 'pre_trained_path': 'net_save/save_now_net_weights_main.pth', 'learning_rate': 0.001, 'epoch_num': 10000, 'tdBN_on': False, 'BN_on': False, 'surrogate': 'hard_sigmoid', 'BPTT_on': False, 'optimizer_what': 'SGD', 'scheduler_name': 'no', 'ddp_on': False, 'dvs_clipping': 1, 'dvs_duration': 5000, 'DFA_on': True, 'trace_on': False, 'OTTT_input_trace_on': False, 'exclude_class': True, 'merge_polarities': False, 'denoise_on': False, 'extra_train_dataset': 0, 'num_workers': 2, 'chaching_on': True, 'pin_memory': True, 'UDA_on': False, 'alpha_uda': 1.0, 'bias': True, 'last_lif': False, 'temporal_filter': 1, 'initial_pooling': 1, 'temporal_filter_accumulation': False} \n",
      "\n",
      "dataset_hash = 7b0583c2e220caca87b64bcaac63adf4\n",
      "cache path exists\n",
      "\n",
      "len(train_loader): 3750 BATCH: 16 train_data_count: 60000\n",
      "len(test_loader): 625 BATCH: 16\n",
      "\n",
      "device ==> cuda\n",
      "\n",
      "DataParallel(\n",
      "  (module): REBORN_MY_SNN_FC(\n",
      "    (layers): REBORN_MY_Sequential(\n",
      "      (0): DimChanger_for_FC()\n",
      "      (1): Shaker_for_FC()\n",
      "      (2): Sparsity_Checker()\n",
      "      (3): SYNAPSE_FC(in_features=578, out_features=200, TIME=10, bias=True, sstep=True, time_different_weight=False)\n",
      "      (4): LIF_layer(v_init=0.0, v_decay=0.5, v_threshold=0.5, v_reset=10000.0, sg_width=4.0, surrogate=hard_sigmoid, BPTT_on=False, trace_const1=1, trace_const2=0.5, TIME=10, sstep=True, trace_on=False)\n",
      "      (5): Sparsity_Checker()\n",
      "      (6): Feedback_Receiver()\n",
      "      (7): SYNAPSE_FC(in_features=200, out_features=200, TIME=10, bias=True, sstep=True, time_different_weight=False)\n",
      "      (8): LIF_layer(v_init=0.0, v_decay=0.5, v_threshold=0.5, v_reset=10000.0, sg_width=4.0, surrogate=hard_sigmoid, BPTT_on=False, trace_const1=1, trace_const2=0.5, TIME=10, sstep=True, trace_on=False)\n",
      "      (9): Sparsity_Checker()\n",
      "      (10): Feedback_Receiver()\n",
      "      (11): SYNAPSE_FC(in_features=200, out_features=10, TIME=10, bias=True, sstep=True, time_different_weight=False)\n",
      "      (DFA_top): Top_Gradient()\n",
      "    )\n",
      "  )\n",
      ")\n",
      "\n",
      "========================================================\n",
      "Trainable parameters: 158,010\n",
      "========================================================\n",
      "\n",
      "current loss function: CrossEntropyLoss()\n",
      "self.perm fc input 처음에 한번 섞기 tensor([575, 370,  61, 417, 461,  13, 521, 431, 548, 388, 477, 324, 235,  75,\n",
      "          4, 257,  81, 220, 328, 313, 274, 382, 334, 558,  35, 518, 482,  79,\n",
      "        133,  21, 171, 510, 389, 112, 159, 246, 507, 150, 437,  85, 287,  20,\n",
      "        418, 529, 394, 142, 503, 368,  32, 443, 156, 376, 110,  58, 128, 564,\n",
      "          5, 190, 309, 113, 407, 260, 547, 264,  94, 367, 141, 327, 341, 188,\n",
      "        253, 255, 364, 291,  25, 230,  89, 530, 285, 557,  82, 381, 138,  30,\n",
      "        252, 233, 353, 129, 254, 148, 210, 192, 100,  98, 321,  49, 377, 472,\n",
      "        345,  84, 225, 224, 245, 532, 490, 419, 447, 320, 372, 244, 184, 556,\n",
      "        359, 476, 214,   9, 237, 401, 467, 475, 474, 272, 132, 378, 549, 319,\n",
      "        135,  39, 436,  83, 312, 217, 271, 115, 293, 294, 373, 512, 536, 303,\n",
      "        131, 329, 535,  95, 404, 124, 123, 152, 109, 365, 533, 164, 116, 470,\n",
      "        339, 420, 178, 433, 351, 179,  40, 400, 390, 374,  72, 519, 356, 360,\n",
      "        538, 333, 411, 495,  41,  31,  69, 180, 465, 523, 207, 487, 396, 120,\n",
      "        391, 157, 173, 403, 386, 452, 511, 101, 406, 137, 182,  54, 163, 570,\n",
      "        338, 122, 145, 554, 185, 460, 405,  18, 261, 162, 302, 308, 453,   0,\n",
      "        144, 170, 198, 295, 161,  53,  73, 416,  46, 429, 169, 238, 402, 296,\n",
      "        380, 542, 540, 277, 514, 323, 301,  86, 565, 304, 577,  14, 143, 183,\n",
      "         63, 107, 212, 481, 213,  67, 573, 500, 286, 165, 290, 488,  88, 263,\n",
      "        218,  55, 493, 130, 197, 517, 205, 454,  59,   7, 392, 236, 262, 223,\n",
      "        240, 397, 119, 196, 114, 219, 318, 527, 459, 444,  93, 395, 408, 498,\n",
      "        151, 340, 464, 506, 509,  78,  70, 572, 221,  16, 562,  50, 479, 438,\n",
      "        208, 516,  36,  57, 200, 355,  91,  77, 243, 149, 485, 496, 568, 242,\n",
      "        469, 344, 106, 247, 471, 410, 413,  87, 352,   3, 393, 421, 231,  60,\n",
      "        189, 449,  38, 428, 357, 571,  19, 204, 227, 450, 520, 480, 504, 102,\n",
      "        435, 307, 335, 256, 222, 160,   1, 300, 515,  37, 288,  71, 306, 187,\n",
      "        125, 127, 531, 325, 385, 158, 379, 134,  48, 502, 166, 362,  90, 346,\n",
      "        154, 281, 473, 282, 167,  96, 349,  51, 269,  92, 422, 528, 425,  12,\n",
      "         42, 215, 267,  45, 276, 489, 491, 525, 427, 140,  26, 463, 442,  74,\n",
      "         64, 193, 441, 383, 455,   8, 458, 492, 387, 248, 409, 350, 358, 155,\n",
      "        546, 366,  97, 551, 423, 239,  52, 228, 118,  15,  47, 560, 117, 424,\n",
      "        567, 194, 168, 203,  66, 147, 172, 146, 501,  10, 279, 111, 268, 559,\n",
      "        175, 305, 211, 466,  62,  29, 299, 251, 297, 315, 311, 229, 484, 298,\n",
      "        177, 258, 539, 412, 348, 289, 426, 513, 216, 226, 555, 524, 398, 432,\n",
      "        552, 576, 434, 314, 105, 440, 574, 266,  33, 363, 316, 202, 280,  80,\n",
      "        522, 181, 278, 273, 139, 136,   6, 292, 354, 526,  17, 445, 462, 326,\n",
      "        250,  44, 486, 553, 569, 369, 561, 259, 494,  43, 439, 265, 195, 176,\n",
      "         68, 201, 284,  24, 121, 347,  65,  99, 343, 283, 241, 566, 322, 317,\n",
      "        104, 545, 103, 457,  27, 478, 199, 505, 483,  34, 234, 499, 275, 126,\n",
      "        310,  22,  56, 361, 537, 430, 249, 543, 451, 191, 534, 174, 497, 544,\n",
      "        186, 206, 508, 337, 108,   2, 541, 384, 371, 330, 375, 456, 414, 550,\n",
      "        336, 331, 232, 209, 270,  76,  11, 342, 415, 446, 332, 448,  28, 399,\n",
      "        563, 153,  23, 468], device='cuda:0')\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAnYAAAHWCAYAAAD6oMSKAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8pXeV/AAAACXBIWXMAAA9hAAAPYQGoP6dpAABL3klEQVR4nO3deXhU9d3+8XsmhGwCApGEsEYNi4AooCgoSzXBDRTbUg2bLEIFLYg+KKKPoVJUfERaFZQKAbUB3MClFYnKpsEFBFo0hqiRIBDiIBIkIQTm+/uDZn4O2WaGyczk5P26rlwXc85nzvmcb4bh5qw2Y4wRAAAA6jx7sBsAAACAfxDsAAAALIJgBwAAYBEEOwAAAIsg2AEAAFgEwQ4AAMAiCHYAAAAWQbADAACwCIIdAACARRDsgDrmtddek81m08qVKyvM6969u2w2m957770K88477zz16NHDq3Xddtttat++vU99pqWlyWazyeFw1Fg7Z84crV69usa6N998UzabTc8991yVNZmZmbLZbJo3b57HvZ7Jdp6p9u3by2azyWazyW63q0mTJurcubNGjRqltWvXVvoem82mtLQ0r9bzr3/9y+v3VLaupUuXymazacuWLV4vqyr79u1TWlqatm/fXmFe+ecIgGcIdkAdM2DAANlsNq1bt85t+k8//aT//Oc/iomJqTDvhx9+0HfffaeBAwd6ta6HHnpIq1atOuOea+JpsLv++usVHx+vJUuWVFmTnp6u8PBwjRw50o8d1q6+fftq8+bNysrK0uuvv64777xTeXl5GjRokH73u9+prKzMrX7z5s0aP368V+v417/+pVmzZnndmy/r8ta+ffs0a9asSoPd+PHjtXnz5lpdP2AlBDugjomNjVXXrl21fv16t+kbNmxQgwYNNG7cuArBrvy1t8HuvPPO08UXX3xG/fpTgwYNNGrUKH3++efauXNnhfk///yzVq1apSFDhuicc84JQoe+Ofvss3XZZZfpsssu09VXX63Jkydr06ZNevjhh/X666/rwQcfdKu/7LLL1Lp161rrxxijkpKSgKyrJq1bt9Zll10WtPUDdQ3BDqiDBg4cqJycHO3fv981bf369brkkkt03XXXaevWrTpy5IjbvLCwMF155ZWSTv3DvWDBAl100UWKiopS06ZN9bvf/U7fffed23oqO0T5888/a9y4cWrWrJnOOussXX/99fruu++qPDx44MAB3XrrrWrSpIni4uI0duxYHT582DXfZrPp6NGjWrZsmeuQ5IABA6rc9nHjxkk6tWfudMuXL9exY8c0duxYSdKzzz6rfv36qUWLFoqJiVG3bt00d+7cCnvATvf999/LZrNp6dKlFeZVtp25ublKTU1VixYtFBERoc6dO+vZZ5+tdh2eSEtLU5cuXfTMM8/o2LFjVfZQXFyse++9V4mJiYqMjFSzZs3Uq1cvLV++XNKp32N5P+VjbLPZ9P3337um3XnnnXruuefUuXNnRUREaNmyZVVuryQdOnRIY8aMUbNmzRQTE6PBgwdX+Py0b99et912W4X3DhgwwPU7Lv/cStKYMWNcvZWvs7JDsU6nU3PnzlWnTp0UERGhFi1aaNSoUfrhhx8qrKdr1676/PPPdeWVVyo6OlrnnnuuHnvsMTmdzqoHHqjDCHZAHVS+5+3Xe+3WrVun/v37q2/fvrLZbNq0aZPbvB49eqhJkyaSpIkTJ2rq1Km6+uqrtXr1ai1YsEBffvml+vTpowMHDlS5XqfTqcGDBysjI0P33XefVq1apd69e+uaa66p8j2//e1v1aFDB73++uu6//77lZGRobvvvts1f/PmzYqKitJ1112nzZs3a/PmzVqwYEGVy+vQoYOuuOIKvfzyyxUCWnp6ulq1aqVBgwZJkr799lulpqbqpZde0jvvvKNx48bpiSee0MSJE6tcvre++uorXXLJJdq5c6eefPJJvfPOO7r++uv1pz/9yadDn6cbPHiwiouLqz2nbdq0aVq4cKH+9Kc/ac2aNXrppZf0+9//XgcPHpR06pD67373O0lyjfHmzZvVsmVL1zJWr16thQsX6n//93/13nvvuf4TUJVx48bJbrcrIyND8+fP12effaYBAwbo559/9mr7evTo4QrpDz74oKu36g7/3nHHHbrvvvuUnJyst956S4888ojWrFmjPn36VDins6CgQMOHD9eIESP01ltv6dprr9WMGTP08ssve9UnUGcYAHXOTz/9ZOx2u5kwYYIxxhiHw2FsNptZs2aNMcaYSy+91Nx7773GGGPy8/ONJDN9+nRjjDGbN282ksyTTz7ptsw9e/aYqKgoV50xxowePdq0a9fO9fqf//ynkWQWLlzo9t5HH33USDIPP/ywa9rDDz9sJJm5c+e61U6aNMlERkYap9PpmhYTE2NGjx7t8fanp6cbSeaNN95wTdu5c6eRZGbOnFnpe06ePGnKysrMiy++aMLCwsxPP/1U5Xbm5eUZSSY9Pb3Cck7fzkGDBpnWrVubw4cPu9XdeeedJjIy0m09lWnXrp25/vrrq5y/cOFCI8msXLmyyh66du1qbrrppmrXM3nyZFPVV74k06RJk0p7PX1d5WM/dOhQt7qPP/7YSDKzZ89227bKfq/9+/c3/fv3d73+/PPPqxzv8s9RuezsbCPJTJo0ya3u008/NZLMAw884LYeSebTTz91q73gggvMoEGDKqwLsAL22AF1UNOmTdW9e3fXHrsNGzYoLCxMffv2lST179/fdV7d6efXvfPOO7LZbBoxYoROnDjh+omPj3dbZmU2bNggSRo2bJjb9FtvvbXK9wwZMsTt9YUXXqhjx46psLDQ8w0+zbBhw9SoUSO3iyiWLFkim82mMWPGuKZt27ZNQ4YMUfPmzRUWFqbw8HCNGjVKJ0+e1K5du3xef7ljx47pgw8+0NChQxUdHe02ntddd52OHTumTz755IzWYYypsebSSy/Vu+++q/vvv1/r1693nR/njd/85jdq2rSpx/XDhw93e92nTx+1a9euwvmd/la+/NMP8V566aXq3LmzPvjgA7fp8fHxuvTSS92mXXjhhdq9e3et9gkEC8EOqKMGDhyoXbt2ad++fVq3bp169uyps846S9KpYLdt2zYdPnxY69atU4MGDXTFFVdIOnXOmzFGcXFxCg8Pd/v55JNPqr09ycGDB9WgQQM1a9bMbXpcXFyV72nevLnb64iICEnyKXyUi46O1i233KI1a9aooKBAJ06c0Msvv6z+/fvrvPPOkyTl5+fryiuv1N69e/XXv/5VmzZt0ueff+461+xM1l/u4MGDOnHihJ5++ukKY3nddddJkke3e6lOeQBJSEiosuZvf/ub7rvvPq1evVoDBw5Us2bNdNNNNyk3N9fj9fz6sKwn4uPjK51Wfvi3tpQvv7J+ExISKqz/9M+fdOoz6I/fPxCKGgS7AQC+GThwoObNm6f169dr/fr1riAhyRXiNm7c6Do5vTz0xcbGus7BKw9Zv1bZtHLNmzfXiRMn9NNPP7mFu4KCAn9tlsfGjRunv//973rxxRfVoUMHFRYW6sknn3TNX716tY4ePao33nhD7dq1c02v7JYap4uMjJQklZaWuk0/PTQ0bdpUYWFhGjlypCZPnlzpshITEz3dpAqMMXr77bcVExOjXr16VVkXExOjWbNmadasWTpw4IBr793gwYP19ddfe7Qub+8VV9nvvKCgQOeff77rdWRkZIUxlE6F3djYWK/WV648qO3fv7/C1br79u3zebmAVbDHDqij+vXrp7CwML322mv68ssv3a4kbdKkiS666CItW7ZM33//vdttTm644QYZY7R371716tWrwk+3bt2qXGf//v0lqcLNkVesWHFG2+LLHpTevXura9euSk9PV3p6upo0aaLf/va3rvnlQeXXQdUYo7///e81LjsuLk6RkZH697//7Tb9zTffdHsdHR2tgQMHatu2bbrwwgsrHc/K9hh5atasWfrqq680ZcoUV9j0pPfbbrtNt956q3JyclRcXCzJP3tKf+0f//iH2+usrCzt3r3b7XPYvn37CmO4a9cu5eTkuE3zprff/OY3klTh4ofPP/9c2dnZuuqqqzzeBsCK2GMH1FGNGzdWjx49tHr1atntdtf5deX69++v+fPnS3K/f13fvn01YcIEjRkzRlu2bFG/fv0UExOj/fv366OPPlK3bt10xx13VLrOa665Rn379tU999yjoqIi9ezZU5s3b9aLL74oSbLbffu/Yrdu3bR+/Xq9/fbbatmypRo1aqSOHTvW+L6xY8dq2rRpysnJ0cSJExUVFeWal5ycrIYNG+rWW2/V9OnTdezYMS1cuFCHDh2qcbnl5yAuWbJE5513nrp3767PPvtMGRkZFWr/+te/6oorrtCVV16pO+64Q+3bt9eRI0f0zTff6O2339aHH35Y4/p+/vln17l4R48eVU5OjlasWKFNmzZp2LBhNV5d27t3b91www268MIL1bRpU2VnZ+ull17S5ZdfrujoaElyBfbHH39c1157rcLCwnThhReqYcOGNfZXmS1btmj8+PH6/e9/rz179mjmzJlq1aqVJk2a5KoZOXKkRowYoUmTJum3v/2tdu/erblz51a4x+B5552nqKgo/eMf/1Dnzp111llnKSEhodLDzx07dtSECRP09NNPy26369prr9X333+vhx56SG3atHG74hqol4J66QaAMzJ9+nQjyfTq1avCvNWrVxtJpmHDhubo0aMV5i9ZssT07t3bxMTEmKioKHPeeeeZUaNGmS1btrhqTr9a1JhTV+SOGTPGnH322SY6OtokJyebTz75xEgyf/3rX1115Vcz/vjjj27vL7+qMi8vzzVt+/btpm/fviY6OtpIcrtisjo//vijadiwoZFkPvvsswrz3377bdO9e3cTGRlpWrVqZf7nf/7HvPvuu0aSWbduXbXbefjwYTN+/HgTFxdnYmJizODBg833339f4SpRY05dRTt27FjTqlUrEx4ebs455xzTp08ftytEq9KuXTsjyUgyNpvNnHXWWaZjx45m5MiR5r333qv0Paf3cP/995tevXqZpk2bmoiICHPuueeau+++2zgcDldNaWmpGT9+vDnnnHOMzWZz+x1IMpMnT/ZoXeW/v7Vr15qRI0eas88+20RFRZnrrrvO5Obmur3X6XSauXPnmnPPPddERkaaXr16mQ8//LDCVbHGGLN8+XLTqVMnEx4e7rbO06+KNebUFc6PP/646dChgwkPDzexsbFmxIgRZs+ePW51/fv3N126dKmwTZX9vgGrsBnjwSVXAFCNjIwMDR8+XB9//LH69OkT7HYAoN4i2AHwyvLly7V3715169ZNdrtdn3zyiZ544gldfPHFrtuhAACCg3PsAHilUaNGWrFihWbPnq2jR4+qZcuWuu222zR79uxgtwYA9R577AAAACyC250AAABYBMEOAADAIgh2AAAAFsHFE5KcTqf27dunRo0aef1YHQAAgNpkjNGRI0eUkJBQ443gCXY69XzBNm3aBLsNAACAKu3Zs6fCM5JPR7DTqds3SKcGrHHjxkHupnJlZWVau3atUlJSFB4eHux2Qh7j5R3Gy3OMlXcYL+8wXt6pL+NVVFSkNm3auPJKdQh2+v8PC2/cuHFIB7vo6Gg1btzY0h9ef2G8vMN4eY6x8g7j5R3Gyzv1bbw8OV2MiycAAAAsgmAHAABgEQQ7AAAAiyDYAQAAWATBDgAAwCIIdgAAABZBsAMAALAIgh0AAIBFEOwAAAAsgmAHAABgEQQ7AAAAiyDYAQAAWATBDgAAwCIIdgAAABYR1GC3ceNGDR48WAkJCbLZbFq9erVrXllZme677z5169ZNMTExSkhI0KhRo7Rv3z63ZZSWluquu+5SbGysYmJiNGTIEP3www8B3hIAAIDgaxDMlR89elTdu3fXmDFj9Nvf/tZtXnFxsb744gs99NBD6t69uw4dOqSpU6dqyJAh2rJli6tu6tSpevvtt7VixQo1b95c99xzj2644QZt3bpVYWFhgd4kABZX/h/HHTt2yG6v+v/GsbGxatu2baDaAgBJQQ521157ra699tpK5zVp0kSZmZlu055++mldeumlys/PV9u2bXX48GEtXrxYL730kq6++mpJ0ssvv6w2bdro/fff16BBg2p9GwDUH/n5+ep1ySVasnix+vXrp5KSkipro6Kj9XV2NuEOQEAFNdh56/Dhw7LZbDr77LMlSVu3blVZWZlSUlJcNQkJCeratauysrIIdgD8yuFwqKS4WJI04YW3dFK2SusK83L1yoN3yOFwEOwABFSdCXbHjh3T/fffr9TUVDVu3FiSVFBQoIYNG6pp06ZutXFxcSooKKhyWaWlpSotLXW9LioqknTqvL6ysrJa6P7MlfcVqv2FGsbLO4yXZ5xOp6KioiRJrZM6yWmv/Cs0TEZRUVFyOp31fkz5bHmH8fJOfRkvb7avTgS7srIy3XLLLXI6nVqwYEGN9cYY2WyV/09akh599FHNmjWrwvS1a9cqOjr6jHqtbacfnkb1GC/vMF41W7JkiSQpad/WKms6xkgDly/X3r17tXfv3kC1FtL4bHmH8fKO1cer+L9HCjwR8sGurKxMw4YNU15enj788EPX3jpJio+P1/Hjx3Xo0CG3vXaFhYXq06dPlcucMWOGpk2b5npdVFSkNm3aKCUlxW35oaSsrEyZmZlKTk5WeHh4sNsJeYyXdxgvz+zYsUODBg3SkiVLlJvQs8o9dvtydmrR+CHauHGjunfvHuAuQwufLe8wXt6pL+NVfmTREyEd7MpDXW5urtatW6fmzZu7ze/Zs6fCw8OVmZmpYcOGSZL279+vnTt3au7cuVUuNyIiQhERERWmh4eHh/wHoy70GEoYL+8wXtWz2+2uCyac9gZVBruTsqmkpER2u53x/C8+W95hvLxj9fHyZtuCGux++eUXffPNN67XeXl52r59u5o1a6aEhAT97ne/0xdffKF33nlHJ0+edJ0316xZMzVs2FBNmjTRuHHjdM8996h58+Zq1qyZ7r33XnXr1s11lSwAAEB9EdRgt2XLFg0cOND1uvzw6OjRo5WWlqa33npLknTRRRe5vW/dunUaMGCAJOmpp55SgwYNNGzYMJWUlOiqq67S0qVLuYcdAACod4Ia7AYMGCBjTJXzq5tXLjIyUk8//bSefvppf7YGAABQ5/CsWAAAAIsg2AEAAFgEwQ4AAMAiCHYAAAAWQbADAACwCIIdAACARRDsAAAALIJgBwAAYBEEOwAAAIsg2AEAAFgEwQ4AAMAigvqsWACwsuzs7BprYmNj1bZt2wB0A6A+INgBgJ8dcRyQzW7XiBEjaqyNio7W19nZhDsAfkGwAwA/KzlSJON0atjshWqRmFRlXWFerl558A45HA6CHQC/INgBsLT8/Hw5HI4a62rjkGiLxCS16tzdr8sEgOoQ7ABYVn5+vjp17qyS4uIaazkkCsAKCHYALMvhcKikuJhDogDqDYIdAMvjkCiA+oL72AEAAFgEwQ4AAMAiCHYAAAAWQbADAACwCIIdAACARRDsAAAALIJgBwAAYBEEOwAAAIsg2AEAAFgEwQ4AAMAiCHYAAAAWQbADAACwCIIdAACARRDsAAAALIJgBwAAYBEEOwAAAIsg2AEAAFhEg2A3AKB+yM/Pl8PhqLEuNjZWbdu2DUBHAGA9BDsAtS4/P1+dOndWSXFxjbVR0dH6OjubcAcAPiDYAah1DodDJcXFGjZ7oVokJlVZV5iXq1cevEMOh4NgBwA+INgBCJgWiUlq1bl7sNsAAMvi4gkAAACLINgBAABYBIdiAeC/srOzz2g+AAQbwQ5AvXfEcUA2u10jRoyosTYqKioAHQGAbwh2AOq9kiNFMk5njVft5nz8gT5Knx+4xgDASwQ7APivmq7aLczLDWA3AOA9Lp4AAACwCIIdAACARRDsAAAALIJgBwAAYBEEOwAAAIsIarDbuHGjBg8erISEBNlsNq1evdptvjFGaWlpSkhIUFRUlAYMGKAvv/zSraa0tFR33XWXYmNjFRMToyFDhuiHH34I4FYAAACEhqAGu6NHj6p79+565plnKp0/d+5czZs3T88884w+//xzxcfHKzk5WUeOHHHVTJ06VatWrdKKFSv00Ucf6ZdfftENN9ygkydPBmozAAAAQkJQ72N37bXX6tprr610njFG8+fP18yZM3XzzTdLkpYtW6a4uDhlZGRo4sSJOnz4sBYvXqyXXnpJV199tSTp5ZdfVps2bfT+++9r0KBBAdsWAACAYAvZc+zy8vJUUFCglJQU17SIiAj1799fWVlZkqStW7eqrKzMrSYhIUFdu3Z11QAAANQXIfvkiYKCAklSXFyc2/S4uDjt3r3bVdOwYUM1bdq0Qk35+ytTWlqq0tJS1+uioiJJUllZmcrKyvzSv7+V9xWq/YUaxss7tT1eTqdTUVFRCpOR3XmiyrowGUVFRcnpdPqlF0/X28Bu86pOkl+WV7692dnZcjqd1W5L8+bN1bp162prQhF/F73DeHmnvoyXN9tnM8aYWuzFYzabTatWrdJNN90kScrKylLfvn21b98+tWzZ0lV3++23a8+ePVqzZo0yMjI0ZswYt5AmScnJyTrvvPP03HPPVbqutLQ0zZo1q8L0jIwMRUdH+2+jAAAAzlBxcbFSU1N1+PBhNW7cuNrakN1jFx8fL+nUXrlfB7vCwkLXXrz4+HgdP35chw4dcttrV1hYqD59+lS57BkzZmjatGmu10VFRWrTpo1SUlJqHLBgKSsrU2ZmppKTkxUeHh7sdkIe4+Wd2h6vHTt2qF+/fprwwltK6Ni1yrp9OTu1aPwQbdy4Ud27V/3MVn+vd8faN7Xqkbs9qlvzfw9oyZIlyk3oKae98q9Qb5a36pG7NfShp3ROu/OqrPtx97da9cjdfhuXQOLvoncYL+/Ul/EqP7LoiZANdomJiYqPj1dmZqYuvvhiSdLx48e1YcMGPf7445Kknj17Kjw8XJmZmRo2bJgkaf/+/dq5c6fmzp1b5bIjIiIUERFRYXp4eHjIfzDqQo+hhPHyTm2Nl91uV0lJiU7KVmUYkqSTsqmkpER2u90vfXi63hNO41WdJDntDaqs9XZ5zdqdr/jOVQc2f49LMPB30TuMl3esPl7ebFtQg90vv/yib775xvU6Ly9P27dvV7NmzdS2bVtNnTpVc+bMUVJSkpKSkjRnzhxFR0crNTVVktSkSRONGzdO99xzj5o3b65mzZrp3nvvVbdu3VxXyQIAANQXQQ12W7Zs0cCBA12vyw+Pjh49WkuXLtX06dNVUlKiSZMm6dChQ+rdu7fWrl2rRo0aud7z1FNPqUGDBho2bJhKSkp01VVXaenSpQoLCwv49gAAAARTUIPdgAEDVN21GzabTWlpaUpLS6uyJjIyUk8//bSefvrpWugQAACg7gjZ+9gBAADAOwQ7AAAAiyDYAQAAWATBDgAAwCIIdgAAABZBsAMAALAIgh0AAIBFEOwAAAAsgmAHAABgEQQ7AAAAiyDYAQAAWATBDgAAwCIIdgAAABZBsAMAALCIBsFuAABOl52dXWNNbGys2rZtG4BuAKDuINgBCBlHHAdks9s1YsSIGmujoqP1dXY24Q4AfoVgByBklBwpknE6NWz2QrVITKqyrjAvV688eIccDgfBDgB+hWAHIOS0SExSq87dg91GyOEQNYCaEOwAIMRxiBqApwh2ABDiOEQNwFMEOwCoIzhEDaAm3McOAADAIgh2AAAAFsGhWAB1Vk1XiXpyFSkAWAnBDkCd481VogBQnxDsANQ5nl4lmvPxB8pc8GgAOwOA4CLYAaizarpKtDAvN4DdAEDwcfEEAACARRDsAAAALIJgBwAAYBEEOwAAAIsg2AEAAFgEwQ4AAMAiCHYAAAAWQbADAACwCIIdAACARRDsAAAALIJgBwAAYBEEOwAAAIsg2AEAAFgEwQ4AAMAiCHYAAAAWQbADAACwCIIdAACARRDsAAAALIJgBwAAYBEEOwAAAItoEOwGANRd+fn5cjgcNdZlZ2cHoBsAAMEOgE/y8/PVqXNnlRQXB7sVAMB/EewA+MThcKikuFjDZi9Ui8SkamtzPv5AmQseDVBnAFB/hXSwO3HihNLS0vSPf/xDBQUFatmypW677TY9+OCDsttPnR5ojNGsWbO0aNEiHTp0SL1799azzz6rLl26BLl7oH5okZikVp27V1tTmJcboG7gKU8Po8fGxqpt27YB6AiAP4R0sHv88cf13HPPadmyZerSpYu2bNmiMWPGqEmTJpoyZYokae7cuZo3b56WLl2qDh06aPbs2UpOTlZOTo4aNWoU5C0AgNDjzWH0qOhofZ2dTbgD6oiQDnabN2/WjTfeqOuvv16S1L59ey1fvlxbtmyRdGpv3fz58zVz5kzdfPPNkqRly5YpLi5OGRkZmjhxYtB6B4BQ5elh9MK8XL3y4B1yOBwEO6COCOlgd8UVV+i5557Trl271KFDB+3YsUMfffSR5s+fL0nKy8tTQUGBUlJSXO+JiIhQ//79lZWVVWWwKy0tVWlpqet1UVGRJKmsrExlZWW1t0FnoLyvUO0v1DBe3vFlvJxOp6KiohQmI7vzRLW1Dew2j2rrSp2kkOwvTEZRUVFyOp3V/i7Lf3ctE89XQseqT1vxdHnV4e+idxgv79SX8fJm+2zGGFOLvZwRY4weeOABPf744woLC9PJkyf1l7/8RTNmzJAkZWVlqW/fvtq7d68SEhJc75swYYJ2796t9957r9LlpqWladasWRWmZ2RkKDo6unY2BgAAwAfFxcVKTU3V4cOH1bhx42prQ3qP3cqVK/Xyyy8rIyNDXbp00fbt2zV16lQlJCRo9OjRrjqbzeb2PmNMhWm/NmPGDE2bNs31uqioSG3atFFKSkqNAxYsZWVlyszMVHJyssLDw4PdTshjvLzjy3jt2LFD/fr104QX3lJCx67V1659U6seubvG2rpQt+b/HtCSJUuUm9BTTnvlX6HB6m9fzk4tGj9EGzduVPfuVV/Q4unvztPlVYe/i95hvLxTX8ar/MiiJ0I62P3P//yP7r//ft1yyy2SpG7dumn37t169NFHNXr0aMXHx0uS64rZcoWFhYqLi6tyuREREYqIiKgwPTw8POQ/GHWhx1DCeHnHm/Gy2+0qKSnRSdmqDDjlTjiNR7V1pU6SnPYGVdYGq7+TsqmkpER2u73a36OnvztPl+cJ/i56h/HyjtXHy5ttC+lHihUXF7tua1IuLCxMTqdTkpSYmKj4+HhlZma65h8/flwbNmxQnz59AtorAABAsIX0HrvBgwfrL3/5i9q2basuXbpo27ZtmjdvnsaOHSvp1CHYqVOnas6cOUpKSlJSUpLmzJmj6OhopaamBrl7AACAwArpYPf000/roYce0qRJk1RYWKiEhARNnDhR//u//+uqmT59ukpKSjRp0iTXDYrXrl3LPewAAEC9E9LBrlGjRpo/f77r9iaVsdlsSktLU1paWsD6AgAACEUhfY4dAAAAPEewAwAAsIiQPhQLIDg8eUB8dnZ2gLoBAHiKYAfAjTcPiAcAhBaCHQA3nj4gPufjD5S54NEAdgYAqAnBDkClWiQmqVXnqh8jVZiXG8BuAACe4OIJAAAAiyDYAQAAWATBDgAAwCIIdgAAABbhU7DLy8vzdx8AAAA4Qz4Fu/PPP18DBw7Uyy+/rGPHjvm7JwAAAPjAp2C3Y8cOXXzxxbrnnnsUHx+viRMn6rPPPvN3bwAAAPCCT8Gua9eumjdvnvbu3av09HQVFBToiiuuUJcuXTRv3jz9+OOP/u4TAAAANTijiycaNGigoUOH6pVXXtHjjz+ub7/9Vvfee69at26tUaNGaf/+/f7qEwAAADU4o2C3ZcsWTZo0SS1bttS8efN077336ttvv9WHH36ovXv36sYbb/RXnwAAAKiBT48UmzdvntLT05WTk6PrrrtOL774oq677jrZ7adyYmJiop5//nl16tTJr80CAACgaj4Fu4ULF2rs2LEaM2aM4uPjK61p27atFi9efEbNAQAAwHM+Bbvc3Jof/t2wYUONHj3al8UDAADABz6dY5eenq5XX321wvRXX31Vy5YtO+OmAAAA4D2fgt1jjz2m2NjYCtNbtGihOXPmnHFTAAAA8J5PwW737t1KTEysML1du3bKz88/46YAAADgPZ+CXYsWLfTvf/+7wvQdO3aoefPmZ9wUAAAAvOfTxRO33HKL/vSnP6lRo0bq16+fJGnDhg2aMmWKbrnlFr82CMB/8vPz5XA4Kkx3Op2STv3nLCcnJ9Btwc+ys7PPaD6AusunYDd79mzt3r1bV111lRo0OLUIp9OpUaNGcY4dEKLy8/PVqXNnlRQXV5gXFRWl5cuXq1+/fiopKQlCd/CHI44DstntGjFiRLBbARAkPgW7hg0bauXKlXrkkUe0Y8cORUVFqVu3bmrXrp2/+wPgJw6HQyXFxRo2e6FaJCa5zQuTkXRUE154S199/KEyFzwanCZxRkqOFMk4nZX+jn8t5+MP+B0DFuVTsCvXoUMHdejQwV+9AAiAFolJatW5u9s0u/OE9MOnSujYVfvzvglSZ/CXyn7Hv1aYV/O9SL3lyWF+u92u0tJSRUREeLTM2NhYtW3b1q99AlbnU7A7efKkli5dqg8++ECFhYWuv7jlPvzwQ780BwAIfd4c5rfZ7TKn/ZtRlajoaH2dnU24A7zgU7CbMmWKli5dquuvv15du3aVzWbzd18AgDrC28P8NR0qlk7tVXzlwTvkcDgIdoAXfAp2K1as0CuvvKLrrrvO3/0AAOooTw/z13SoGIDvfLqPXcOGDXX++ef7uxcAAACcAZ+C3T333KO//vWvMsb4ux8AAAD4yKdDsR999JHWrVund999V126dFF4eLjb/DfeeMMvzQEAAMBzPgW7s88+W0OHDvV3LwAAADgDPgW79PR0f/cBAACAM+TTOXaSdOLECb3//vt6/vnndeTIEUnSvn379Msvv/itOQAAAHjOpz12u3fv1jXXXKP8/HyVlpYqOTlZjRo10ty5c3Xs2DE999xz/u4TAAAANfBpj92UKVPUq1cvHTp0SFFRUa7pQ4cO1QcffOC35gAAAOA5n6+K/fjjj9WwYUO36e3atdPevXv90hgAAAC849MeO6fTqZMnT1aY/sMPP6hRo0Zn3BQAAAC851OwS05O1vz5812vbTabfvnlFz388MM8ZgwAACBIfDoU+9RTT2ngwIG64IILdOzYMaWmpio3N1exsbFavny5v3sEAACAB3wKdgkJCdq+fbuWL1+uL774Qk6nU+PGjdPw4cPdLqYAAABA4PgU7CQpKipKY8eO1dixY/3ZDwAAAHzkU7B78cUXq50/atQon5oBAACA73wKdlOmTHF7XVZWpuLiYjVs2FDR0dEEOwAAgCDw6arYQ4cOuf388ssvysnJ0RVXXMHFEwAAAEHi87NiT5eUlKTHHnuswt48AAAABIbfgp0khYWFad++ff5cJAAAADzk0zl2b731lttrY4z279+vZ555Rn379vVLYwAAAPCOT8Hupptucntts9l0zjnn6De/+Y2efPJJf/TlsnfvXt1333169913VVJSog4dOmjx4sXq2bOnpFOhctasWVq0aJEOHTqk3r1769lnn1WXLl382gcAAECo8ynYOZ1Of/dRqUOHDqlv374aOHCg3n33XbVo0ULffvutzj77bFfN3LlzNW/ePC1dulQdOnTQ7NmzlZycrJycHJ5bCwAA6hWfb1AcCI8//rjatGmj9PR017T27du7/myM0fz58zVz5kzdfPPNkqRly5YpLi5OGRkZmjhxYqBbBgAACBqfgt20adM8rp03b54vq5B06ly+QYMG6fe//702bNigVq1aadKkSbr99tslSXl5eSooKFBKSorrPREREerfv7+ysrKqDHalpaUqLS11vS4qKpJ06n58ZWVlPvdbm8r7CtX+Qg3jVZHT6VRUVJTCZGR3nnCbV/7a7jyhBnZblXW/5mmdN7V1pU5SSPfnr7owGUVFRcnpdFb7d8nfny1v1m01fHd5p76MlzfbZzPGGG9XMHDgQH3xxRc6ceKEOnbsKEnatWuXwsLC1KNHj/+/cJtNH374obeLd4mMjJR0Kkj+/ve/12effaapU6fq+eef16hRo5SVlaW+fftq7969SkhIcL1vwoQJ2r17t957771Kl5uWlqZZs2ZVmJ6RkaHo6Gif+wUAAPC34uJipaam6vDhw2rcuHG1tT7tsRs8eLAaNWqkZcuWqWnTppJOnQ83ZswYXXnllbrnnnt8WWwFTqdTvXr10pw5cyRJF198sb788kstXLjQ7ekWNpvN7X3GmArTfm3GjBluex2LiorUpk0bpaSk1DhgwVJWVqbMzEwlJycrPDw82O2EPMaroh07dqhfv36a8MJbSujY1W2e3XlCSfu2Kjehp7a9/0+teuTuSuvclrf2TY/qvKmtC3Vr/u8BLVmyRLkJPeW0V/4VWhe2w5O6fTk7tWj8EG3cuFHdu3evenl+/mx5s26r4bvLO/VlvMqPLHrCp2D35JNPau3ata5QJ0lNmzbV7NmzlZKS4rdg17JlS11wwQVu0zp37qzXX39dkhQfHy9JKigoUMuWLV01hYWFiouLq3K5ERERioiIqDA9PDw85D8YdaHHUMJ4/X92u10lJSU6KVuVgcRpb6ATTlNjnSSP67yprSt10qmxqqo22P35q+6kbCopKZHdbq/275G/P1verNuq+O7yjtXHy5tt8+kGxUVFRTpw4ECF6YWFhTpy5Igvi6xU3759lZOT4zZt165dateunSQpMTFR8fHxyszMdM0/fvy4NmzYoD59+vitDwAAgLrAp2A3dOhQjRkzRq+99pp++OEH/fDDD3rttdc0btw419Wp/nD33Xfrk08+0Zw5c/TNN98oIyNDixYt0uTJkyWdOgQ7depUzZkzR6tWrdLOnTt12223KTo6WqmpqX7rAwAAoC7w6VDsc889p3vvvVcjRoxwXanRoEEDjRs3Tk888YTfmrvkkku0atUqzZgxQ3/+85+VmJio+fPna/jw4a6a6dOnq6SkRJMmTXLdoHjt2rXcww4A/CQ7O/uM5gMIHJ+CXXR0tBYsWKAnnnhC3377rYwxOv/88xUTE+Pv/nTDDTfohhtuqHK+zWZTWlqa0tLS/L5uAKjPjjgOyGa3a8SIEcFuBYCHzugGxfv379f+/fvVr18/RUVF1Xg1KgCg7ig5UiTjdGrY7IVqkZhUZV3Oxx8oc8GjAewMQFV8CnYHDx7UsGHDtG7dOtlsNuXm5urcc8/V+PHjdfbZZ/v9ebEAgOBpkZikVp2rvuVIYV5uALsBUB2fLp64++67FR4ervz8fLcb+v7hD3/QmjVr/NYcAAAAPOfTHru1a9fqvffeU+vWrd2mJyUlaffu3X5pDAAAAN7xaY/d0aNHK330lsPhqPTGvwAAAKh9PgW7fv366cUXX3S9ttlscjqdeuKJJzRw4EC/NQcAAADP+XQo9oknntCAAQO0ZcsWHT9+XNOnT9eXX36pn376SR9//LG/ewQAAIAHfNpjd8EFF+jf//63Lr30UiUnJ+vo0aO6+eabtW3bNp133nn+7hEAAAAe8HqPXVlZmVJSUvT8889r1qxZtdETAAAAfOD1Hrvw8HDt3LmTGxEDAACEGJ8OxY4aNUqLFy/2dy8AAAA4Az5dPHH8+HG98MILyszMVK9evSo8I3bevHl+aQ4AAACe8yrYfffdd2rfvr127typHj16SJJ27drlVsMhWgAAgODwKtglJSVp//79WrdunaRTjxD729/+pri4uFppDgAAAJ7z6hw7Y4zb63fffVdHjx71a0MAAADwjU8XT5Q7PegBAAAgeLwKdjabrcI5dJxTBwAAEBq8OsfOGKPbbrtNERERkqRjx47pj3/8Y4WrYt944w3/dQgAAACPeBXsRo8e7fZ6xIgRfm0GAAAAvvMq2KWnp9dWHwAAADhDPt2gGACAQMjOzq6xJjY2Vm3btg1AN0DoI9gBAELOEccB2ex2j075iYqO1tfZ2YQ7QAQ7AEAIKjlSJON0atjshWqRmFRlXWFerl558A45HA6CHSCCHQAghLVITFKrzt2D3QZQZ5zRDYoBAAAQOgh2AAAAFkGwAwAAsAiCHQAAgEUQ7AAAACyCq2IBC8jPz5fD4ai2xpMbvQIA6jaCHVDH5efnq1PnziopLg52KwCAICPYAXWcw+FQSXFxjTdyzfn4A2UueDSAnQEAAo1gB1hETTdyLczLDWA3QGDxTFngFIIdAKDO4pmygDuCHQCgzuKZsoA7gh0AoM7jmbLAKdzHDgAAwCIIdgAAABbBoVgAQL3B1bOwOoIdAMDyuHoW9QXBDgBgeVw9i/qCYAcAqDe4ehZWx8UTAAAAFkGwAwAAsAiCHQAAgEUQ7AAAACyCYAcAAGARBDsAAACLINgBAABYBMEOAADAIupUsHv00Udls9k0depU1zRjjNLS0pSQkKCoqCgNGDBAX375ZfCaBAAACJI6E+w+//xzLVq0SBdeeKHb9Llz52revHl65pln9Pnnnys+Pl7Jyck6cuRIkDoFAAAIjjoR7H755RcNHz5cf//739W0aVPXdGOM5s+fr5kzZ+rmm29W165dtWzZMhUXFysjIyOIHQMAAARenXhW7OTJk3X99dfr6quv1uzZs13T8/LyVFBQoJSUFNe0iIgI9e/fX1lZWZo4cWKlyystLVVpaanrdVFRkSSprKxMZWVltbQVZ6a8r1DtL9TUp/FyOp2KiopSmIzszhNV1jWw26qsK39td56ots7T5flaW1fqJIV0f6FU58tnK5jbEiajqKgoOZ3OoHx/1KfvLn+oL+PlzfbZjDGmFns5YytWrNBf/vIXff7554qMjNSAAQN00UUXaf78+crKylLfvn21d+9eJSQkuN4zYcIE7d69W++9916ly0xLS9OsWbMqTM/IyFB0dHStbQsAAIC3iouLlZqaqsOHD6tx48bV1ob0Hrs9e/ZoypQpWrt2rSIjI6uss9lsbq+NMRWm/dqMGTM0bdo01+uioiK1adNGKSkpNQ5YsJSVlSkzM1PJyckKDw8Pdjshrz6N144dO9SvXz9NeOEtJXTsWnXd2je16pG7K62zO08oad9W5Sb01Lb3/1llnafL87W2LtSt+b8HtGTJEuUm9JTTXvlXaF3YjkDV+fLZCua27MvZqUXjh2jjxo3q3r17tT3Whvr03eUP9WW8yo8seiKkg93WrVtVWFionj17uqadPHlSGzdu1DPPPKOcnBxJUkFBgVq2bOmqKSwsVFxcXJXLjYiIUERERIXp4eHhIf/BqAs9hpL6MF52u10lJSU6KVuVQUOSTjhNjXVOewOP6jxdnre1daVOOjVWVdUGu79QrPPmsxXMbTkpm0pKSmS324P63VEfvrv8yerj5c22hfTFE1dddZX+85//aPv27a6fXr16afjw4dq+fbvOPfdcxcfHKzMz0/We48ePa8OGDerTp08QOwcAAAi8kN5j16hRI3Xt6r7LPCYmRs2bN3dNnzp1qubMmaOkpCQlJSVpzpw5io6OVmpqajBaBgAACJqQDnaemD59ukpKSjRp0iQdOnRIvXv31tq1a9WoUaNgtwYAABBQdS7YrV+/3u21zWZTWlqa0tLSgtIPAABAqAjpc+wAAADgOYIdAACARRDsAAAALIJgBwAAYBEEOwAAAIsg2AEAAFgEwQ4AAMAi6tx97IBQlp+fL4fDUWNdbGys2rZtG4COAAD1CcEO8JP8/Hx16txZJcXFNdZGRUfr6+xswh0AwK8IdoCfOBwOlRQXa9jshWqRmFRlXWFerl558A45HA6CHQDArwh2gJ+1SExSq87da6zLzs6usYZDtgAAbxDsgAA74jggm92uESNG1FjLIVsAgDcIdkCAlRwpknE6OWQLAPA7gh0QJP46ZOvJIV0AQP1AsANClDeHbAEAkAh2QMjy9JBtzscfKHPBowHsDAAQqgh2QIir6ZBtYV5uALsBAIQyHikGAABgEQQ7AAAAiyDYAQAAWATBDgAAwCIIdgAAABZBsAMAALAIgh0AAIBFEOwAAAAsgmAHAABgEQQ7AAAAiyDYAQAAWATBDgAAwCIIdgAAABZBsAMAALAIgh0AAIBFEOwAAAAsgmAHAABgEQQ7AAAAiyDYAQAAWATBDgAAwCIIdgAAABZBsAMAALAIgh0AAIBFEOwAAAAsgmAHAABgEQQ7AAAAiyDYAQAAWATBDgAAwCIIdgAAABZBsAMAALCIBsFuAACAUJOdnV1jTWxsrNq2bRuAbgDPEewAAPivI44DstntGjFiRI21UdHR+jo7m3CHkBLSwe7RRx/VG2+8oa+//lpRUVHq06ePHn/8cXXs2NFVY4zRrFmztGjRIh06dEi9e/fWs88+qy5dugSxcwBAXVRypEjG6dSw2QvVIjGpyrrCvFy98uAdcjgcBDuElJAOdhs2bNDkyZN1ySWX6MSJE5o5c6ZSUlL01VdfKSYmRpI0d+5czZs3T0uXLlWHDh00e/ZsJScnKycnR40aNQryFsAq8vPz5XA4qq3x5NANgLqhRWKSWnXuHuw2AK+FdLBbs2aN2+v09HS1aNFCW7duVb9+/WSM0fz58zVz5kzdfPPNkqRly5YpLi5OGRkZmjhxYjDahsXk5+erU+fOKikuDnYrAABUK6SD3ekOHz4sSWrWrJkkKS8vTwUFBUpJSXHVREREqH///srKyiLYwS8cDodKiotrPDST8/EHylzwaAA7AwDAXZ0JdsYYTZs2TVdccYW6du0qSSooKJAkxcXFudXGxcVp9+7dVS6rtLRUpaWlrtdFRUWSpLKyMpWVlfm7db8o7ytU+ws1/hwvp9OpqKgotUw8Xwkdqz5386fd3ygqKkphMrI7T1RZ18BuC7m68td25wm/rzfQ2xKIOkkh3V8o1fny2QrVbfm1MBlFRUXJ6XT69XuZ73rv1Jfx8mb7bMYYU4u9+M3kyZP1z3/+Ux999JFat24tScrKylLfvn21b98+tWzZ0lV7++23a8+ePRUO5ZZLS0vTrFmzKkzPyMhQdHR07WwAAACAD4qLi5WamqrDhw+rcePG1dbWiT12d911l9566y1t3LjRFeokKT4+XtKpPXe/DnaFhYUV9uL92owZMzRt2jTX66KiIrVp00YpKSk1DliwlJWVKTMzU8nJyQoPDw92OyHPn+O1Y8cO9evXTxNeeEsJHbtWXbf2Ta165O46WWd3nlDSvq3KTeipbe//06/rDfS21Hbdmv97QEuWLFFuQk857ZV/hdaF7Qjlz1aobsuv7cvZqUXjh2jjxo3q3t1/F1nwXe+d+jJe5UcWPRHSwc4Yo7vuukurVq3S+vXrlZiY6DY/MTFR8fHxyszM1MUXXyxJOn78uDZs2KDHH3+8yuVGREQoIiKiwvTw8PCQ/2DUhR5DiT/Gy263q6SkRCdlq/Ifckk64TR1vs5pb+D39QZrW2qzTjo1VlXVBru/UKzz5rMV6tsiSSdlU0lJiex2e618J/Nd7x2rj5c32xbSwW7y5MnKyMjQm2++qUaNGrnOqWvSpImioqJks9k0depUzZkzR0lJSUpKStKcOXMUHR2t1NTUIHcPAAAQWCEd7BYuXChJGjBggNv09PR03XbbbZKk6dOnq6SkRJMmTXLdoHjt2rXcww4AANQ7IR3sPLmuw2azKS0tTWlpabXfEAAAQAizB7sBAAAA+AfBDgAAwCJC+lAsUNt4BiyAM+HJ90NsbKzatm0bgG4Agh3qMZ4BC8BXRxwHZLPbNWLEiBpro6Kj9XV2NuEOAUGwQ73FM2AB+KrkSJGM01nj90dhXq5eefAOORwOgh0CgmCHeq9FYpJada76zvGFebkB7AZAXVLT9wcQaFw8AQAAYBEEOwAAAIsg2AEAAFgEwQ4AAMAiCHYAAAAWQbADAACwCIIdAACARRDsAAAALIIbFAMAUMs8faZsy5YtA9ANrIxgBwBALfH2mbJf7twZgK5gZQQ7AABqibfPlD148GAAu4MVEexQp+Tn58vhcNRY17Rp0wB0AwCe8fSZsjk5OTrrrLO0Y8cO2e2VnwYfGxurtm3b+rtFWATBDnVGfn6+OnXurJLi4hprmzVvriWLFwegKwA4c+WHbG+//XYtX75c/fr1U0lJSaW1UdHR+jo7m3CHShHsUGc4HA6VFBd7dEjj7b9MC2BnAHBmyg/ZDn3oKUnShBfe0knZKtSVH7J1OBwEO1SKYIeQ4Mkh1vKryjw9pAEAdc057c6TdFQJHbvKaeefaHiPTw2CzptDrAAAoGoEOwSdp4dYcz7+QJkLHg1gZwAA1C0EO4SMmg6xFubler3M6q4s8+SGoQAA1CUEO1hO+dVlkqq9sgwAAKsh2MFyyq8uk6q+skzi0C4AwHoIdvCapzcJloJ/I83qrizz5dAuAAChjGAHr3h7BSs30gQAIHAIdvCKp1ewStxIEwCAQCPYwYWbBAMAULcR7CCJmwQDAGAFBDtI4ibBAABYAcEObmrjJsEAgLrP0zsiBPtuCPUdwQ4AAFTLm9N1uBtCcBHsAABAtTw9XYe7IQQfwQ4AAAvy9NBpaWmpIiIiqq3hjgh1B8EOAACL8ebQqc1udz2GEXUfwQ4AAIvx9k4H3BHBOgh2AABYlKd3OuCOCNZBsAMAoI4pP+fN1/m1zZP1c1uU2kGwAwCgjjjiOCCb3a4RI0YEu5VKedMft0WpHQQ7AADqiJIjRTJOZ8ieE+dpf9wWpfYQ7FDrQv2QAQDUNaF+Thy3RQkegh1qTagfMgAAwGoIdqg1oX7IAAAAqyHY1QOe3H28Ng+HhvohAwBAcHj6bw9X0HqOYGdx3tx9HACAQPD2VB2uoPUcwc7ivL37OAAAtc3TU3UkrqD1FsGunuBwKAAg1ATr6llPTlGS6uYhYIIdAACoN7w5RakuHgK2TLBbsGCBnnjiCe3fv19dunTR/PnzdeWVVwa7LQAAEEI8PUWprh4CtkSwW7lypaZOnaoFCxaob9++ev7553Xttdfqq6++Cqlfhqe7fktLSxUREeE2zel0SpJ27Nghu91eZd3puPkvAKC+8OYuEJ4eBq5rz721RLCbN2+exo0bp/Hjx0uS5s+fr/fee08LFy7Uo4+GxgUB3uz6tdntMv8NcuWioqK0fPly9evXTyUlJVXWAQBQH/n7LhB19bm3dT7YHT9+XFu3btX999/vNj0lJUVZWVlB6qoib69OPb0uTEbSUU144S2dlK3KuqqWBwCAlfn7LhB19bm3dT7YORwOnTx5UnFxcW7T4+LiVFBQUOl7SktLVVpa6np9+PBhSdJPP/2ksrKyWumzqKhIkZGRMseP6UTxL1UXnjxRaZ2RUbGtRCeKjU7KVmVdVcs7kPOfausO7fnOr3W1sUxv64qLi5W/7ZNT4xWC/YVSXZiM2sSUKH/bJ5b8LPDZCl6dL5+tUN2WgNTlfqniDi2q/HwFvb8g/FtycE+eIiMjtXXrVhUVFbnNczqdKi4u1qZNm/Ttt9/Wyr+LNS3PHD+myMhIFRUV6eDBg9Vui6+OHDlyal3G1Fxs6ri9e/caSSYrK8tt+uzZs03Hjh0rfc/DDz9sJPHDDz/88MMPP/zUmZ89e/bUmIvq/B672NhYhYWFVdg7V1hYWGEvXrkZM2Zo2rRprtdOp1M//fSTmjdvLput8v+BB1tRUZHatGmjPXv2qHHjxsFuJ+QxXt5hvDzHWHmH8fIO4+Wd+jJexhgdOXJECQkJNdbW+WDXsGFD9ezZU5mZmRo6dKhremZmpm688cZK3xMREVHhatKzzz67Ntv0m8aNG1v6w+tvjJd3GC/PMVbeYby8w3h5pz6MV5MmTTyqq/PBTpKmTZumkSNHqlevXrr88su1aNEi5efn649//GOwWwMAAAgYSwS7P/zhDzp48KD+/Oc/a//+/eratav+9a9/qV27dsFuDQAAIGAsEewkadKkSZo0aVKw26g1ERERevjhh2u8ITFOYby8w3h5jrHyDuPlHcbLO4xXRTZjPLl2FgAAAKHOHuwGAAAA4B8EOwAAAIsg2AEAAFgEwS5EHTp0SCNHjlSTJk3UpEkTjRw5Uj///HO170lLS1OnTp0UExOjpk2b6uqrr9ann34amIaDzNvxKisr03333adu3bopJiZGCQkJGjVqlPbt2xe4poPIl8/XG2+8oUGDBik2NlY2m03bt28PSK/BsGDBAiUmJioyMlI9e/bUpk2bqq3fsGGDevbsqcjISJ177rl67rnnAtRpaPBmvPbv36/U1FR17NhRdrtdU6dODVyjIcKb8XrjjTeUnJysc845R40bN9bll1+u9957L4DdBp834/XRRx+pb9++at68uaKiotSpUyc99dRTAew2+Ah2ISo1NVXbt2/XmjVrtGbNGm3fvl0jR46s9j0dOnTQM888o//85z/66KOP1L59e6WkpOjHH38MUNfB4+14FRcX64svvtBDDz2kL774Qm+88YZ27dqlIUOGBLDr4PHl83X06FH17dtXjz32WIC6DI6VK1dq6tSpmjlzprZt26Yrr7xS1157rfLz8yutz8vL03XXXacrr7xS27Zt0wMPPKA//elPev311wPceXB4O16lpaU655xzNHPmTHXv3j3A3Qaft+O1ceNGJScn61//+pe2bt2qgQMHavDgwdq2bVuAOw8Ob8crJiZGd955pzZu3Kjs7Gw9+OCDevDBB7Vo0aIAdx5EZ/60VvjbV199ZSSZTz75xDVt8+bNRpL5+uuvPV7O4cOHjSTz/vvv10abIcNf4/XZZ58ZSWb37t210WbIONPxysvLM5LMtm3barHL4Ln00kvNH//4R7dpnTp1Mvfff3+l9dOnTzedOnVymzZx4kRz2WWX1VqPocTb8fq1/v37mylTptRSZ6HpTMar3AUXXGBmzZrl79ZCkj/Ga+jQoWbEiBH+bi1ksccuBG3evFlNmjRR7969XdMuu+wyNWnSRFlZWR4t4/jx41q0aJGaNGli+f8V+2O8JOnw4cOy2Wx15vFyvvLXeFnR8ePHtXXrVqWkpLhNT0lJqXJsNm/eXKF+0KBB2rJli8rKymqt11Dgy3jVZ/4YL6fTqSNHjqhZs2a10WJI8cd4bdu2TVlZWerfv39ttBiSCHYhqKCgQC1atKgwvUWLFiooKKj2ve+8847OOussRUZG6qmnnlJmZqZiY2Nrq9WQcCbjVe7YsWO6//77lZqaavnnDfpjvKzK4XDo5MmTiouLc5seFxdX5dgUFBRUWn/ixAk5HI5a6zUU+DJe9Zk/xuvJJ5/U0aNHNWzYsNpoMaScyXi1bt1aERER6tWrlyZPnqzx48fXZqshhWAXQGlpabLZbNX+bNmyRZJks9kqvN8YU+n0Xxs4cKC2b9+urKwsXXPNNRo2bJgKCwtrZXtqWyDGSzp1IcUtt9wip9OpBQsW+H07AiVQ41UfnD4ONY1NZfWVTbcqb8ervvN1vJYvX660tDStXLmy0v+cWZUv47Vp0yZt2bJFzz33nObPn6/ly5fXZoshxTKPFKsL7rzzTt1yyy3V1rRv317//ve/deDAgQrzfvzxxwr/czldTEyMzj//fJ1//vm67LLLlJSUpMWLF2vGjBln1HswBGK8ysrKNGzYMOXl5enDDz+s03vrAjFeVhcbG6uwsLAKewMKCwurHJv4+PhK6xs0aKDmzZvXWq+hwJfxqs/OZLxWrlypcePG6dVXX9XVV19dm22GjDMZr8TERElSt27ddODAAaWlpenWW2+ttV5DCcEugGJjYz06LHr55Zfr8OHD+uyzz3TppZdKkj799FMdPnxYffr08WqdxhiVlpb61G+w1fZ4lYe63NxcrVu3rs7/IxyMz5fVNGzYUD179lRmZqaGDh3qmp6Zmakbb7yx0vdcfvnlevvtt92mrV27Vr169VJ4eHit9htsvoxXfebreC1fvlxjx47V8uXLdf311wei1ZDgr89XXf530CfBumoD1bvmmmvMhRdeaDZv3mw2b95sunXrZm644Qa3mo4dO5o33njDGGPML7/8YmbMmGE2b95svv/+e7N161Yzbtw4ExERYXbu3BmMTQgob8errKzMDBkyxLRu3dps377d7N+/3/VTWloajE0IKG/HyxhjDh48aLZt22b++c9/GklmxYoVZtu2bWb//v2Bbr9WrVixwoSHh5vFixebr776ykydOtXExMSY77//3hhjzP33329Gjhzpqv/uu+9MdHS0ufvuu81XX31lFi9ebMLDw81rr70WrE0IKG/Hyxhjtm3bZrZt22Z69uxpUlNTzbZt28yXX34ZjPYDztvxysjIMA0aNDDPPvus2/fUzz//HKxNCChvx+uZZ54xb731ltm1a5fZtWuXWbJkiWncuLGZOXNmsDYh4Ah2IergwYNm+PDhplGjRqZRo0Zm+PDh5tChQ241kkx6eroxxpiSkhIzdOhQk5CQYBo2bGhatmxphgwZYj777LPANx8E3o5X+S07KvtZt25dwPsPNG/Hyxhj0tPTKx2vhx9+OKC9B8Kzzz5r2rVrZxo2bGh69OhhNmzY4Jo3evRo079/f7f69evXm4svvtg0bNjQtG/f3ixcuDDAHQeXt+NV2eeoXbt2gW06iLwZr/79+1c6XqNHjw5840HizXj97W9/M126dDHR0dGmcePG5uKLLzYLFiwwJ0+eDELnwWEz5r9n+QIAAKBO46pYAAAAiyDYAQAAWATBDgAAwCIIdgAAABZBsAMAALAIgh0AAIBFEOwAAAAsgmAHAABgEQQ7APCjAQMGaOrUqcFuA0A9RbADgP8aPHiwrr766krnbd68WTabTV988UWAuwIAzxHsAOC/xo0bpw8//FC7d++uMG/JkiW66KKL1KNHjyB0BgCeIdgBwH/dcMMNatGihZYuXeo2vbi4WCtXrtRNN92kW2+9Va1bt1Z0dLS6deum5cuXV7tMm82m1atXu007++yz3daxd+9e/eEPf1DTpk3VvHlz3Xjjjfr+++/9s1EA6hWCHQD8V4MGDTRq1CgtXbpUxhjX9FdffVXHjx/X+PHj1bNnT73zzjvauXOnJkyYoJEjR+rTTz/1eZ3FxcUaOHCgzjrrLG3cuFEfffSRzjrrLF1zzTU6fvy4PzYLQD1CsAOAXxk7dqy+//57rV+/3jVtyZIluvnmm9WqVSvde++9uuiii3Tuuefqrrvu0qBBg/Tqq6/6vL4VK1bIbrfrhRdeULdu3dS5c2elp6crPz/frQcA8ESDYDcAAKGkU6dO6tOnj5YsWaKBAwfq22+/1aZNm7R27VqdPHlSjz32mFauXKm9e/eqtLRUpaWliomJ8Xl9W7du1TfffKNGjRq5TT927Ji+/fbbM90cAPUMwQ4ATjNu3DjdeeedevbZZ5Wenq527drpqquu0hNPPKGnnnpK8+fPV7du3RQTE6OpU6dWe8jUZrO5HdaVpLKyMtefnU6nevbsqX/84x8V3nvOOef4b6MA1AsEOwA4zbBhwzRlyhRlZGRo2bJluv3222Wz2bRp0ybdeOONGjFihKRToSw3N1edO3euclnnnHOO9u/f73qdm5ur4uJi1+sePXpo5cqVatGihRo3blx7GwWgXuAcOwA4zVlnnaU//OEPeuCBB7Rv3z7ddtttkqTzzz9fmZmZysrKUnZ2tiZOnKiCgoJql/Wb3/xGzzzzjL744gtt2bJFf/zjHxUeHu6aP3z4cMXGxurGG2/Upk2blJeXpw0bNmjKlCn64YcfanMzAVgQwQ4AKjFu3DgdOnRIV199tdq2bStJeuihh9SjRw8NGjRIAwYMUHx8vG666aZql/Pkk0+qTZs26tevn1JTU3XvvfcqOjraNT86OlobN25U27ZtdfPNN6tz584aO3asSkpK2IMHwGs2c/rJHwAAAKiT2GMHAABgEQQ7AAAAiyDYAQAAWATBDgAAwCIIdgAAABZBsAMAALAIgh0AAIBFEOwAAAAsgmAHAABgEQQ7AAAAiyDYAQAAWATBDgAAwCL+Hyyu8sG4TtGPAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch-0   lr=['0.0010000'], tr/val_loss:  0.658626/  0.411012, val:  94.75%, val_best:  94.75%, tr:  88.43%, tr_best:  88.43%\n",
      "[module.layers.6] weight_fb parameter count: 2,000\n",
      "[module.layers.10] weight_fb parameter count: 2,000\n",
      "epoch-1   lr=['0.0010000'], tr/val_loss:  0.393684/  0.348241, val:  95.42%, val_best:  95.42%, tr:  94.68%, tr_best:  94.68%\n",
      "epoch-2   lr=['0.0010000'], tr/val_loss:  0.334627/  0.298724, val:  96.42%, val_best:  96.42%, tr:  95.65%, tr_best:  95.65%\n",
      "epoch-3   lr=['0.0010000'], tr/val_loss:  0.300974/  0.292585, val:  96.32%, val_best:  96.42%, tr:  96.13%, tr_best:  96.13%\n",
      "epoch-4   lr=['0.0010000'], tr/val_loss:  0.280164/  0.265609, val:  96.61%, val_best:  96.61%, tr:  96.51%, tr_best:  96.51%\n",
      "epoch-5   lr=['0.0010000'], tr/val_loss:  0.263757/  0.253974, val:  96.61%, val_best:  96.61%, tr:  96.80%, tr_best:  96.80%\n",
      "epoch-6   lr=['0.0010000'], tr/val_loss:  0.251417/  0.255099, val:  96.68%, val_best:  96.68%, tr:  96.99%, tr_best:  96.99%\n",
      "epoch-7   lr=['0.0010000'], tr/val_loss:  0.241970/  0.245524, val:  97.15%, val_best:  97.15%, tr:  97.15%, tr_best:  97.15%\n",
      "epoch-8   lr=['0.0010000'], tr/val_loss:  0.233522/  0.226739, val:  97.24%, val_best:  97.24%, tr:  97.27%, tr_best:  97.27%\n",
      "epoch-9   lr=['0.0010000'], tr/val_loss:  0.225135/  0.223424, val:  97.27%, val_best:  97.27%, tr:  97.40%, tr_best:  97.40%\n",
      "epoch-10  lr=['0.0010000'], tr/val_loss:  0.217813/  0.223370, val:  97.29%, val_best:  97.29%, tr:  97.54%, tr_best:  97.54%\n",
      "epoch-11  lr=['0.0010000'], tr/val_loss:  0.213075/  0.237017, val:  96.94%, val_best:  97.29%, tr:  97.63%, tr_best:  97.63%\n",
      "epoch-12  lr=['0.0010000'], tr/val_loss:  0.207301/  0.219299, val:  97.29%, val_best:  97.29%, tr:  97.70%, tr_best:  97.70%\n",
      "epoch-13  lr=['0.0010000'], tr/val_loss:  0.202864/  0.208524, val:  97.60%, val_best:  97.60%, tr:  97.77%, tr_best:  97.77%\n",
      "epoch-14  lr=['0.0010000'], tr/val_loss:  0.198581/  0.220841, val:  97.50%, val_best:  97.60%, tr:  97.83%, tr_best:  97.83%\n",
      "epoch-15  lr=['0.0010000'], tr/val_loss:  0.194228/  0.215062, val:  97.47%, val_best:  97.60%, tr:  97.97%, tr_best:  97.97%\n",
      "epoch-16  lr=['0.0010000'], tr/val_loss:  0.192122/  0.215511, val:  97.66%, val_best:  97.66%, tr:  97.96%, tr_best:  97.97%\n",
      "epoch-17  lr=['0.0010000'], tr/val_loss:  0.187972/  0.222491, val:  97.27%, val_best:  97.66%, tr:  98.08%, tr_best:  98.08%\n",
      "epoch-18  lr=['0.0010000'], tr/val_loss:  0.185237/  0.205384, val:  97.82%, val_best:  97.82%, tr:  98.06%, tr_best:  98.08%\n",
      "epoch-19  lr=['0.0010000'], tr/val_loss:  0.181420/  0.213889, val:  97.37%, val_best:  97.82%, tr:  98.14%, tr_best:  98.14%\n",
      "epoch-20  lr=['0.0010000'], tr/val_loss:  0.178747/  0.208343, val:  97.68%, val_best:  97.82%, tr:  98.19%, tr_best:  98.19%\n",
      "epoch-21  lr=['0.0010000'], tr/val_loss:  0.176583/  0.208618, val:  97.46%, val_best:  97.82%, tr:  98.22%, tr_best:  98.22%\n",
      "epoch-22  lr=['0.0010000'], tr/val_loss:  0.173744/  0.206496, val:  97.40%, val_best:  97.82%, tr:  98.31%, tr_best:  98.31%\n",
      "epoch-23  lr=['0.0010000'], tr/val_loss:  0.171956/  0.202983, val:  97.72%, val_best:  97.82%, tr:  98.25%, tr_best:  98.31%\n",
      "epoch-24  lr=['0.0010000'], tr/val_loss:  0.170132/  0.195720, val:  97.83%, val_best:  97.83%, tr:  98.35%, tr_best:  98.35%\n",
      "epoch-25  lr=['0.0010000'], tr/val_loss:  0.167709/  0.209007, val:  97.57%, val_best:  97.83%, tr:  98.37%, tr_best:  98.37%\n",
      "epoch-26  lr=['0.0010000'], tr/val_loss:  0.166312/  0.194117, val:  97.88%, val_best:  97.88%, tr:  98.44%, tr_best:  98.44%\n",
      "epoch-27  lr=['0.0010000'], tr/val_loss:  0.164940/  0.192319, val:  97.91%, val_best:  97.91%, tr:  98.43%, tr_best:  98.44%\n",
      "epoch-28  lr=['0.0010000'], tr/val_loss:  0.162550/  0.204530, val:  97.61%, val_best:  97.91%, tr:  98.49%, tr_best:  98.49%\n",
      "epoch-29  lr=['0.0010000'], tr/val_loss:  0.160427/  0.200646, val:  97.88%, val_best:  97.91%, tr:  98.52%, tr_best:  98.52%\n",
      "epoch-30  lr=['0.0010000'], tr/val_loss:  0.159003/  0.192758, val:  98.10%, val_best:  98.10%, tr:  98.50%, tr_best:  98.52%\n",
      "epoch-31  lr=['0.0010000'], tr/val_loss:  0.156797/  0.192039, val:  97.89%, val_best:  98.10%, tr:  98.58%, tr_best:  98.58%\n",
      "epoch-32  lr=['0.0010000'], tr/val_loss:  0.155683/  0.196062, val:  97.90%, val_best:  98.10%, tr:  98.58%, tr_best:  98.58%\n",
      "epoch-33  lr=['0.0010000'], tr/val_loss:  0.153844/  0.193545, val:  98.02%, val_best:  98.10%, tr:  98.62%, tr_best:  98.62%\n",
      "epoch-34  lr=['0.0010000'], tr/val_loss:  0.152420/  0.199208, val:  97.70%, val_best:  98.10%, tr:  98.64%, tr_best:  98.64%\n",
      "epoch-35  lr=['0.0010000'], tr/val_loss:  0.151331/  0.190625, val:  97.98%, val_best:  98.10%, tr:  98.68%, tr_best:  98.68%\n",
      "epoch-36  lr=['0.0010000'], tr/val_loss:  0.149941/  0.196214, val:  97.74%, val_best:  98.10%, tr:  98.73%, tr_best:  98.73%\n",
      "epoch-37  lr=['0.0010000'], tr/val_loss:  0.149156/  0.189535, val:  97.99%, val_best:  98.10%, tr:  98.70%, tr_best:  98.73%\n",
      "epoch-38  lr=['0.0010000'], tr/val_loss:  0.147194/  0.191988, val:  97.98%, val_best:  98.10%, tr:  98.72%, tr_best:  98.73%\n",
      "epoch-39  lr=['0.0010000'], tr/val_loss:  0.145362/  0.195373, val:  97.86%, val_best:  98.10%, tr:  98.80%, tr_best:  98.80%\n",
      "epoch-40  lr=['0.0010000'], tr/val_loss:  0.144284/  0.198401, val:  97.84%, val_best:  98.10%, tr:  98.81%, tr_best:  98.81%\n",
      "epoch-41  lr=['0.0010000'], tr/val_loss:  0.144847/  0.194388, val:  98.09%, val_best:  98.10%, tr:  98.73%, tr_best:  98.81%\n",
      "epoch-42  lr=['0.0010000'], tr/val_loss:  0.143185/  0.191301, val:  98.07%, val_best:  98.10%, tr:  98.80%, tr_best:  98.81%\n",
      "epoch-43  lr=['0.0010000'], tr/val_loss:  0.142278/  0.186291, val:  98.15%, val_best:  98.15%, tr:  98.79%, tr_best:  98.81%\n",
      "epoch-44  lr=['0.0010000'], tr/val_loss:  0.141522/  0.196074, val:  97.85%, val_best:  98.15%, tr:  98.79%, tr_best:  98.81%\n",
      "epoch-45  lr=['0.0010000'], tr/val_loss:  0.140347/  0.194112, val:  97.99%, val_best:  98.15%, tr:  98.78%, tr_best:  98.81%\n",
      "epoch-46  lr=['0.0010000'], tr/val_loss:  0.138930/  0.188107, val:  98.04%, val_best:  98.15%, tr:  98.86%, tr_best:  98.86%\n",
      "epoch-47  lr=['0.0010000'], tr/val_loss:  0.138135/  0.192665, val:  98.03%, val_best:  98.15%, tr:  98.88%, tr_best:  98.88%\n",
      "epoch-48  lr=['0.0010000'], tr/val_loss:  0.138432/  0.191866, val:  97.98%, val_best:  98.15%, tr:  98.85%, tr_best:  98.88%\n",
      "epoch-49  lr=['0.0010000'], tr/val_loss:  0.136510/  0.189719, val:  98.09%, val_best:  98.15%, tr:  98.93%, tr_best:  98.93%\n",
      "epoch-50  lr=['0.0010000'], tr/val_loss:  0.136372/  0.188694, val:  98.11%, val_best:  98.15%, tr:  98.90%, tr_best:  98.93%\n",
      "epoch-51  lr=['0.0010000'], tr/val_loss:  0.135317/  0.192553, val:  98.09%, val_best:  98.15%, tr:  98.94%, tr_best:  98.94%\n",
      "epoch-52  lr=['0.0010000'], tr/val_loss:  0.134673/  0.190258, val:  98.13%, val_best:  98.15%, tr:  98.91%, tr_best:  98.94%\n",
      "epoch-53  lr=['0.0010000'], tr/val_loss:  0.133887/  0.194958, val:  97.90%, val_best:  98.15%, tr:  98.93%, tr_best:  98.94%\n",
      "epoch-54  lr=['0.0010000'], tr/val_loss:  0.133089/  0.200852, val:  98.04%, val_best:  98.15%, tr:  98.94%, tr_best:  98.94%\n",
      "epoch-55  lr=['0.0010000'], tr/val_loss:  0.131665/  0.195013, val:  97.96%, val_best:  98.15%, tr:  98.98%, tr_best:  98.98%\n",
      "epoch-56  lr=['0.0010000'], tr/val_loss:  0.130637/  0.193973, val:  97.89%, val_best:  98.15%, tr:  98.99%, tr_best:  98.99%\n",
      "epoch-57  lr=['0.0010000'], tr/val_loss:  0.130547/  0.190080, val:  98.15%, val_best:  98.15%, tr:  98.99%, tr_best:  98.99%\n",
      "epoch-58  lr=['0.0010000'], tr/val_loss:  0.129738/  0.192954, val:  98.07%, val_best:  98.15%, tr:  98.96%, tr_best:  98.99%\n",
      "epoch-59  lr=['0.0010000'], tr/val_loss:  0.128842/  0.193048, val:  98.05%, val_best:  98.15%, tr:  99.04%, tr_best:  99.04%\n",
      "epoch-60  lr=['0.0010000'], tr/val_loss:  0.128689/  0.193534, val:  98.01%, val_best:  98.15%, tr:  99.04%, tr_best:  99.04%\n",
      "epoch-61  lr=['0.0010000'], tr/val_loss:  0.127167/  0.192151, val:  98.07%, val_best:  98.15%, tr:  99.02%, tr_best:  99.04%\n",
      "epoch-62  lr=['0.0010000'], tr/val_loss:  0.126719/  0.195500, val:  98.10%, val_best:  98.15%, tr:  99.06%, tr_best:  99.06%\n",
      "epoch-63  lr=['0.0010000'], tr/val_loss:  0.126286/  0.200999, val:  97.99%, val_best:  98.15%, tr:  99.11%, tr_best:  99.11%\n",
      "epoch-64  lr=['0.0010000'], tr/val_loss:  0.125734/  0.197328, val:  98.08%, val_best:  98.15%, tr:  99.05%, tr_best:  99.11%\n",
      "epoch-65  lr=['0.0010000'], tr/val_loss:  0.124497/  0.193097, val:  98.16%, val_best:  98.16%, tr:  99.10%, tr_best:  99.11%\n",
      "epoch-66  lr=['0.0010000'], tr/val_loss:  0.124325/  0.189986, val:  98.27%, val_best:  98.27%, tr:  99.05%, tr_best:  99.11%\n",
      "epoch-67  lr=['0.0010000'], tr/val_loss:  0.123176/  0.193151, val:  98.23%, val_best:  98.27%, tr:  99.11%, tr_best:  99.11%\n",
      "epoch-68  lr=['0.0010000'], tr/val_loss:  0.122485/  0.194517, val:  98.02%, val_best:  98.27%, tr:  99.17%, tr_best:  99.17%\n",
      "epoch-69  lr=['0.0010000'], tr/val_loss:  0.121656/  0.200788, val:  98.08%, val_best:  98.27%, tr:  99.13%, tr_best:  99.17%\n",
      "epoch-70  lr=['0.0010000'], tr/val_loss:  0.121128/  0.189983, val:  98.09%, val_best:  98.27%, tr:  99.17%, tr_best:  99.17%\n",
      "epoch-71  lr=['0.0010000'], tr/val_loss:  0.120878/  0.195341, val:  98.13%, val_best:  98.27%, tr:  99.15%, tr_best:  99.17%\n",
      "epoch-72  lr=['0.0010000'], tr/val_loss:  0.119878/  0.198511, val:  98.07%, val_best:  98.27%, tr:  99.14%, tr_best:  99.17%\n",
      "epoch-73  lr=['0.0010000'], tr/val_loss:  0.119021/  0.197565, val:  98.09%, val_best:  98.27%, tr:  99.16%, tr_best:  99.17%\n",
      "epoch-74  lr=['0.0010000'], tr/val_loss:  0.119089/  0.196465, val:  98.02%, val_best:  98.27%, tr:  99.17%, tr_best:  99.17%\n",
      "epoch-75  lr=['0.0010000'], tr/val_loss:  0.118793/  0.192442, val:  98.07%, val_best:  98.27%, tr:  99.16%, tr_best:  99.17%\n",
      "epoch-76  lr=['0.0010000'], tr/val_loss:  0.116994/  0.189622, val:  98.18%, val_best:  98.27%, tr:  99.24%, tr_best:  99.24%\n",
      "epoch-77  lr=['0.0010000'], tr/val_loss:  0.116629/  0.193696, val:  98.13%, val_best:  98.27%, tr:  99.26%, tr_best:  99.26%\n",
      "epoch-78  lr=['0.0010000'], tr/val_loss:  0.116633/  0.190155, val:  98.26%, val_best:  98.27%, tr:  99.20%, tr_best:  99.26%\n",
      "epoch-79  lr=['0.0010000'], tr/val_loss:  0.116659/  0.198079, val:  97.94%, val_best:  98.27%, tr:  99.21%, tr_best:  99.26%\n",
      "epoch-80  lr=['0.0010000'], tr/val_loss:  0.115499/  0.197362, val:  98.21%, val_best:  98.27%, tr:  99.26%, tr_best:  99.26%\n",
      "epoch-81  lr=['0.0010000'], tr/val_loss:  0.115812/  0.195029, val:  98.09%, val_best:  98.27%, tr:  99.24%, tr_best:  99.26%\n",
      "epoch-82  lr=['0.0010000'], tr/val_loss:  0.114942/  0.193076, val:  98.11%, val_best:  98.27%, tr:  99.23%, tr_best:  99.26%\n",
      "epoch-83  lr=['0.0010000'], tr/val_loss:  0.114290/  0.194785, val:  98.08%, val_best:  98.27%, tr:  99.29%, tr_best:  99.29%\n",
      "epoch-84  lr=['0.0010000'], tr/val_loss:  0.114131/  0.191889, val:  98.32%, val_best:  98.32%, tr:  99.28%, tr_best:  99.29%\n",
      "epoch-85  lr=['0.0010000'], tr/val_loss:  0.113879/  0.192440, val:  98.17%, val_best:  98.32%, tr:  99.24%, tr_best:  99.29%\n",
      "epoch-86  lr=['0.0010000'], tr/val_loss:  0.113416/  0.191829, val:  98.19%, val_best:  98.32%, tr:  99.28%, tr_best:  99.29%\n",
      "epoch-87  lr=['0.0010000'], tr/val_loss:  0.112487/  0.195579, val:  98.25%, val_best:  98.32%, tr:  99.29%, tr_best:  99.29%\n",
      "epoch-88  lr=['0.0010000'], tr/val_loss:  0.111841/  0.199025, val:  98.22%, val_best:  98.32%, tr:  99.30%, tr_best:  99.30%\n",
      "epoch-89  lr=['0.0010000'], tr/val_loss:  0.111968/  0.193367, val:  98.20%, val_best:  98.32%, tr:  99.30%, tr_best:  99.30%\n",
      "epoch-90  lr=['0.0010000'], tr/val_loss:  0.111440/  0.199512, val:  98.18%, val_best:  98.32%, tr:  99.28%, tr_best:  99.30%\n",
      "epoch-91  lr=['0.0010000'], tr/val_loss:  0.110832/  0.200734, val:  98.13%, val_best:  98.32%, tr:  99.30%, tr_best:  99.30%\n",
      "epoch-92  lr=['0.0010000'], tr/val_loss:  0.109530/  0.196300, val:  98.22%, val_best:  98.32%, tr:  99.35%, tr_best:  99.35%\n",
      "epoch-93  lr=['0.0010000'], tr/val_loss:  0.110385/  0.199560, val:  98.20%, val_best:  98.32%, tr:  99.31%, tr_best:  99.35%\n",
      "epoch-94  lr=['0.0010000'], tr/val_loss:  0.109165/  0.196401, val:  98.26%, val_best:  98.32%, tr:  99.34%, tr_best:  99.35%\n",
      "epoch-95  lr=['0.0010000'], tr/val_loss:  0.108989/  0.197305, val:  98.17%, val_best:  98.32%, tr:  99.36%, tr_best:  99.36%\n",
      "epoch-96  lr=['0.0010000'], tr/val_loss:  0.108385/  0.197417, val:  98.17%, val_best:  98.32%, tr:  99.34%, tr_best:  99.36%\n",
      "epoch-97  lr=['0.0010000'], tr/val_loss:  0.107450/  0.195612, val:  98.29%, val_best:  98.32%, tr:  99.38%, tr_best:  99.38%\n",
      "epoch-98  lr=['0.0010000'], tr/val_loss:  0.108110/  0.194793, val:  98.23%, val_best:  98.32%, tr:  99.35%, tr_best:  99.38%\n",
      "epoch-99  lr=['0.0010000'], tr/val_loss:  0.107160/  0.201272, val:  98.30%, val_best:  98.32%, tr:  99.36%, tr_best:  99.38%\n",
      "epoch-100 lr=['0.0010000'], tr/val_loss:  0.106830/  0.196382, val:  98.17%, val_best:  98.32%, tr:  99.41%, tr_best:  99.41%\n",
      "epoch-101 lr=['0.0010000'], tr/val_loss:  0.107327/  0.196994, val:  98.20%, val_best:  98.32%, tr:  99.41%, tr_best:  99.41%\n",
      "epoch-102 lr=['0.0010000'], tr/val_loss:  0.106325/  0.199695, val:  98.16%, val_best:  98.32%, tr:  99.38%, tr_best:  99.41%\n",
      "epoch-103 lr=['0.0010000'], tr/val_loss:  0.106148/  0.195787, val:  98.24%, val_best:  98.32%, tr:  99.38%, tr_best:  99.41%\n",
      "epoch-104 lr=['0.0010000'], tr/val_loss:  0.105525/  0.203985, val:  98.10%, val_best:  98.32%, tr:  99.38%, tr_best:  99.41%\n",
      "epoch-105 lr=['0.0010000'], tr/val_loss:  0.105734/  0.196308, val:  98.33%, val_best:  98.33%, tr:  99.38%, tr_best:  99.41%\n",
      "epoch-106 lr=['0.0010000'], tr/val_loss:  0.105024/  0.195019, val:  98.34%, val_best:  98.34%, tr:  99.44%, tr_best:  99.44%\n",
      "epoch-107 lr=['0.0010000'], tr/val_loss:  0.103953/  0.203904, val:  98.15%, val_best:  98.34%, tr:  99.41%, tr_best:  99.44%\n",
      "epoch-108 lr=['0.0010000'], tr/val_loss:  0.104012/  0.198049, val:  98.27%, val_best:  98.34%, tr:  99.41%, tr_best:  99.44%\n",
      "epoch-109 lr=['0.0010000'], tr/val_loss:  0.103856/  0.198030, val:  98.34%, val_best:  98.34%, tr:  99.41%, tr_best:  99.44%\n",
      "epoch-110 lr=['0.0010000'], tr/val_loss:  0.103896/  0.198509, val:  98.25%, val_best:  98.34%, tr:  99.44%, tr_best:  99.44%\n",
      "epoch-111 lr=['0.0010000'], tr/val_loss:  0.103088/  0.200270, val:  98.28%, val_best:  98.34%, tr:  99.44%, tr_best:  99.44%\n",
      "epoch-112 lr=['0.0010000'], tr/val_loss:  0.102401/  0.196858, val:  98.28%, val_best:  98.34%, tr:  99.40%, tr_best:  99.44%\n",
      "epoch-113 lr=['0.0010000'], tr/val_loss:  0.102295/  0.203723, val:  98.10%, val_best:  98.34%, tr:  99.44%, tr_best:  99.44%\n",
      "epoch-114 lr=['0.0010000'], tr/val_loss:  0.102502/  0.203926, val:  98.19%, val_best:  98.34%, tr:  99.44%, tr_best:  99.44%\n",
      "epoch-115 lr=['0.0010000'], tr/val_loss:  0.102102/  0.203776, val:  98.10%, val_best:  98.34%, tr:  99.44%, tr_best:  99.44%\n",
      "epoch-116 lr=['0.0010000'], tr/val_loss:  0.101902/  0.198536, val:  98.21%, val_best:  98.34%, tr:  99.42%, tr_best:  99.44%\n",
      "epoch-117 lr=['0.0010000'], tr/val_loss:  0.100860/  0.206006, val:  98.07%, val_best:  98.34%, tr:  99.48%, tr_best:  99.48%\n",
      "epoch-118 lr=['0.0010000'], tr/val_loss:  0.101110/  0.200384, val:  98.21%, val_best:  98.34%, tr:  99.48%, tr_best:  99.48%\n",
      "epoch-119 lr=['0.0010000'], tr/val_loss:  0.101136/  0.201319, val:  98.18%, val_best:  98.34%, tr:  99.47%, tr_best:  99.48%\n",
      "epoch-120 lr=['0.0010000'], tr/val_loss:  0.100413/  0.209811, val:  98.12%, val_best:  98.34%, tr:  99.47%, tr_best:  99.48%\n",
      "epoch-121 lr=['0.0010000'], tr/val_loss:  0.099980/  0.204530, val:  98.27%, val_best:  98.34%, tr:  99.52%, tr_best:  99.52%\n",
      "epoch-122 lr=['0.0010000'], tr/val_loss:  0.100260/  0.202798, val:  98.21%, val_best:  98.34%, tr:  99.51%, tr_best:  99.52%\n",
      "epoch-123 lr=['0.0010000'], tr/val_loss:  0.099500/  0.205063, val:  98.16%, val_best:  98.34%, tr:  99.46%, tr_best:  99.52%\n",
      "epoch-124 lr=['0.0010000'], tr/val_loss:  0.099435/  0.201572, val:  98.30%, val_best:  98.34%, tr:  99.47%, tr_best:  99.52%\n",
      "epoch-125 lr=['0.0010000'], tr/val_loss:  0.098722/  0.207172, val:  98.16%, val_best:  98.34%, tr:  99.49%, tr_best:  99.52%\n",
      "epoch-126 lr=['0.0010000'], tr/val_loss:  0.098685/  0.200621, val:  98.27%, val_best:  98.34%, tr:  99.48%, tr_best:  99.52%\n",
      "epoch-127 lr=['0.0010000'], tr/val_loss:  0.098277/  0.203879, val:  98.12%, val_best:  98.34%, tr:  99.49%, tr_best:  99.52%\n",
      "epoch-128 lr=['0.0010000'], tr/val_loss:  0.098280/  0.204354, val:  98.26%, val_best:  98.34%, tr:  99.49%, tr_best:  99.52%\n",
      "epoch-129 lr=['0.0010000'], tr/val_loss:  0.097598/  0.199049, val:  98.36%, val_best:  98.36%, tr:  99.50%, tr_best:  99.52%\n",
      "epoch-130 lr=['0.0010000'], tr/val_loss:  0.097046/  0.204870, val:  98.22%, val_best:  98.36%, tr:  99.52%, tr_best:  99.52%\n",
      "epoch-131 lr=['0.0010000'], tr/val_loss:  0.097278/  0.202341, val:  98.18%, val_best:  98.36%, tr:  99.54%, tr_best:  99.54%\n",
      "epoch-132 lr=['0.0010000'], tr/val_loss:  0.097423/  0.207095, val:  98.18%, val_best:  98.36%, tr:  99.53%, tr_best:  99.54%\n",
      "epoch-133 lr=['0.0010000'], tr/val_loss:  0.096520/  0.209726, val:  98.24%, val_best:  98.36%, tr:  99.52%, tr_best:  99.54%\n",
      "epoch-134 lr=['0.0010000'], tr/val_loss:  0.097053/  0.204712, val:  98.32%, val_best:  98.36%, tr:  99.52%, tr_best:  99.54%\n",
      "epoch-135 lr=['0.0010000'], tr/val_loss:  0.096997/  0.200229, val:  98.24%, val_best:  98.36%, tr:  99.53%, tr_best:  99.54%\n",
      "epoch-136 lr=['0.0010000'], tr/val_loss:  0.096237/  0.203303, val:  98.25%, val_best:  98.36%, tr:  99.54%, tr_best:  99.54%\n",
      "epoch-137 lr=['0.0010000'], tr/val_loss:  0.095841/  0.200928, val:  98.28%, val_best:  98.36%, tr:  99.51%, tr_best:  99.54%\n",
      "epoch-138 lr=['0.0010000'], tr/val_loss:  0.095151/  0.205774, val:  98.28%, val_best:  98.36%, tr:  99.54%, tr_best:  99.54%\n",
      "epoch-139 lr=['0.0010000'], tr/val_loss:  0.094986/  0.208300, val:  98.17%, val_best:  98.36%, tr:  99.55%, tr_best:  99.55%\n",
      "epoch-140 lr=['0.0010000'], tr/val_loss:  0.094622/  0.206265, val:  98.25%, val_best:  98.36%, tr:  99.56%, tr_best:  99.56%\n",
      "epoch-141 lr=['0.0010000'], tr/val_loss:  0.094427/  0.212118, val:  98.14%, val_best:  98.36%, tr:  99.55%, tr_best:  99.56%\n",
      "epoch-142 lr=['0.0010000'], tr/val_loss:  0.094071/  0.204807, val:  98.22%, val_best:  98.36%, tr:  99.57%, tr_best:  99.57%\n",
      "epoch-143 lr=['0.0010000'], tr/val_loss:  0.094002/  0.206491, val:  98.25%, val_best:  98.36%, tr:  99.56%, tr_best:  99.57%\n",
      "epoch-144 lr=['0.0010000'], tr/val_loss:  0.094381/  0.206811, val:  98.17%, val_best:  98.36%, tr:  99.57%, tr_best:  99.57%\n",
      "epoch-145 lr=['0.0010000'], tr/val_loss:  0.093289/  0.203566, val:  98.31%, val_best:  98.36%, tr:  99.59%, tr_best:  99.59%\n",
      "epoch-146 lr=['0.0010000'], tr/val_loss:  0.092781/  0.210196, val:  98.24%, val_best:  98.36%, tr:  99.56%, tr_best:  99.59%\n",
      "epoch-147 lr=['0.0010000'], tr/val_loss:  0.093149/  0.204978, val:  98.32%, val_best:  98.36%, tr:  99.58%, tr_best:  99.59%\n",
      "epoch-148 lr=['0.0010000'], tr/val_loss:  0.092836/  0.210645, val:  98.32%, val_best:  98.36%, tr:  99.57%, tr_best:  99.59%\n",
      "epoch-149 lr=['0.0010000'], tr/val_loss:  0.091968/  0.208029, val:  98.27%, val_best:  98.36%, tr:  99.60%, tr_best:  99.60%\n",
      "epoch-150 lr=['0.0010000'], tr/val_loss:  0.092772/  0.210061, val:  98.18%, val_best:  98.36%, tr:  99.55%, tr_best:  99.60%\n",
      "epoch-151 lr=['0.0010000'], tr/val_loss:  0.092146/  0.206416, val:  98.24%, val_best:  98.36%, tr:  99.56%, tr_best:  99.60%\n",
      "epoch-152 lr=['0.0010000'], tr/val_loss:  0.092280/  0.206144, val:  98.39%, val_best:  98.39%, tr:  99.61%, tr_best:  99.61%\n",
      "epoch-153 lr=['0.0010000'], tr/val_loss:  0.091893/  0.207635, val:  98.29%, val_best:  98.39%, tr:  99.60%, tr_best:  99.61%\n",
      "epoch-154 lr=['0.0010000'], tr/val_loss:  0.091441/  0.207819, val:  98.22%, val_best:  98.39%, tr:  99.61%, tr_best:  99.61%\n",
      "epoch-155 lr=['0.0010000'], tr/val_loss:  0.091204/  0.211989, val:  98.18%, val_best:  98.39%, tr:  99.57%, tr_best:  99.61%\n",
      "epoch-156 lr=['0.0010000'], tr/val_loss:  0.091313/  0.210907, val:  98.24%, val_best:  98.39%, tr:  99.58%, tr_best:  99.61%\n",
      "epoch-157 lr=['0.0010000'], tr/val_loss:  0.090412/  0.213326, val:  98.18%, val_best:  98.39%, tr:  99.62%, tr_best:  99.62%\n",
      "epoch-158 lr=['0.0010000'], tr/val_loss:  0.090003/  0.219730, val:  98.15%, val_best:  98.39%, tr:  99.59%, tr_best:  99.62%\n",
      "epoch-159 lr=['0.0010000'], tr/val_loss:  0.090629/  0.216344, val:  98.11%, val_best:  98.39%, tr:  99.61%, tr_best:  99.62%\n",
      "epoch-160 lr=['0.0010000'], tr/val_loss:  0.089579/  0.211146, val:  98.19%, val_best:  98.39%, tr:  99.63%, tr_best:  99.63%\n",
      "epoch-161 lr=['0.0010000'], tr/val_loss:  0.089611/  0.216942, val:  98.14%, val_best:  98.39%, tr:  99.61%, tr_best:  99.63%\n",
      "epoch-162 lr=['0.0010000'], tr/val_loss:  0.089449/  0.209767, val:  98.32%, val_best:  98.39%, tr:  99.61%, tr_best:  99.63%\n",
      "epoch-163 lr=['0.0010000'], tr/val_loss:  0.089268/  0.210133, val:  98.24%, val_best:  98.39%, tr:  99.62%, tr_best:  99.63%\n",
      "epoch-164 lr=['0.0010000'], tr/val_loss:  0.088861/  0.209214, val:  98.27%, val_best:  98.39%, tr:  99.62%, tr_best:  99.63%\n",
      "epoch-165 lr=['0.0010000'], tr/val_loss:  0.088664/  0.215000, val:  98.19%, val_best:  98.39%, tr:  99.61%, tr_best:  99.63%\n",
      "epoch-166 lr=['0.0010000'], tr/val_loss:  0.088602/  0.208811, val:  98.32%, val_best:  98.39%, tr:  99.62%, tr_best:  99.63%\n",
      "epoch-167 lr=['0.0010000'], tr/val_loss:  0.088563/  0.217302, val:  98.10%, val_best:  98.39%, tr:  99.62%, tr_best:  99.63%\n",
      "epoch-168 lr=['0.0010000'], tr/val_loss:  0.088219/  0.213799, val:  98.25%, val_best:  98.39%, tr:  99.61%, tr_best:  99.63%\n",
      "epoch-169 lr=['0.0010000'], tr/val_loss:  0.087724/  0.213661, val:  98.26%, val_best:  98.39%, tr:  99.66%, tr_best:  99.66%\n",
      "epoch-170 lr=['0.0010000'], tr/val_loss:  0.087561/  0.219352, val:  98.11%, val_best:  98.39%, tr:  99.60%, tr_best:  99.66%\n",
      "epoch-171 lr=['0.0010000'], tr/val_loss:  0.086751/  0.213965, val:  98.23%, val_best:  98.39%, tr:  99.64%, tr_best:  99.66%\n",
      "epoch-172 lr=['0.0010000'], tr/val_loss:  0.087363/  0.210859, val:  98.29%, val_best:  98.39%, tr:  99.63%, tr_best:  99.66%\n",
      "epoch-173 lr=['0.0010000'], tr/val_loss:  0.087216/  0.222939, val:  98.12%, val_best:  98.39%, tr:  99.64%, tr_best:  99.66%\n",
      "epoch-174 lr=['0.0010000'], tr/val_loss:  0.087078/  0.213177, val:  98.11%, val_best:  98.39%, tr:  99.64%, tr_best:  99.66%\n",
      "epoch-175 lr=['0.0010000'], tr/val_loss:  0.086588/  0.213278, val:  98.40%, val_best:  98.40%, tr:  99.65%, tr_best:  99.66%\n",
      "epoch-176 lr=['0.0010000'], tr/val_loss:  0.086510/  0.211234, val:  98.31%, val_best:  98.40%, tr:  99.63%, tr_best:  99.66%\n",
      "epoch-177 lr=['0.0010000'], tr/val_loss:  0.086065/  0.219174, val:  98.22%, val_best:  98.40%, tr:  99.65%, tr_best:  99.66%\n",
      "epoch-178 lr=['0.0010000'], tr/val_loss:  0.086113/  0.214892, val:  98.28%, val_best:  98.40%, tr:  99.67%, tr_best:  99.67%\n",
      "epoch-179 lr=['0.0010000'], tr/val_loss:  0.085602/  0.213774, val:  98.33%, val_best:  98.40%, tr:  99.67%, tr_best:  99.67%\n",
      "epoch-180 lr=['0.0010000'], tr/val_loss:  0.085412/  0.212812, val:  98.36%, val_best:  98.40%, tr:  99.67%, tr_best:  99.67%\n",
      "epoch-181 lr=['0.0010000'], tr/val_loss:  0.085171/  0.212005, val:  98.25%, val_best:  98.40%, tr:  99.67%, tr_best:  99.67%\n",
      "epoch-182 lr=['0.0010000'], tr/val_loss:  0.085322/  0.215293, val:  98.35%, val_best:  98.40%, tr:  99.67%, tr_best:  99.67%\n",
      "epoch-183 lr=['0.0010000'], tr/val_loss:  0.084915/  0.214349, val:  98.22%, val_best:  98.40%, tr:  99.68%, tr_best:  99.68%\n",
      "epoch-184 lr=['0.0010000'], tr/val_loss:  0.085091/  0.217885, val:  98.24%, val_best:  98.40%, tr:  99.66%, tr_best:  99.68%\n",
      "epoch-185 lr=['0.0010000'], tr/val_loss:  0.084687/  0.215571, val:  98.27%, val_best:  98.40%, tr:  99.68%, tr_best:  99.68%\n",
      "epoch-186 lr=['0.0010000'], tr/val_loss:  0.084452/  0.217078, val:  98.37%, val_best:  98.40%, tr:  99.68%, tr_best:  99.68%\n",
      "epoch-187 lr=['0.0010000'], tr/val_loss:  0.085020/  0.218513, val:  98.24%, val_best:  98.40%, tr:  99.66%, tr_best:  99.68%\n",
      "epoch-188 lr=['0.0010000'], tr/val_loss:  0.084127/  0.220397, val:  98.18%, val_best:  98.40%, tr:  99.69%, tr_best:  99.69%\n",
      "epoch-189 lr=['0.0010000'], tr/val_loss:  0.084437/  0.214854, val:  98.26%, val_best:  98.40%, tr:  99.70%, tr_best:  99.70%\n",
      "epoch-190 lr=['0.0010000'], tr/val_loss:  0.084010/  0.215077, val:  98.29%, val_best:  98.40%, tr:  99.66%, tr_best:  99.70%\n",
      "epoch-191 lr=['0.0010000'], tr/val_loss:  0.083419/  0.220225, val:  98.17%, val_best:  98.40%, tr:  99.67%, tr_best:  99.70%\n",
      "epoch-192 lr=['0.0010000'], tr/val_loss:  0.083724/  0.215364, val:  98.31%, val_best:  98.40%, tr:  99.70%, tr_best:  99.70%\n",
      "epoch-193 lr=['0.0010000'], tr/val_loss:  0.083399/  0.219904, val:  98.16%, val_best:  98.40%, tr:  99.67%, tr_best:  99.70%\n",
      "epoch-194 lr=['0.0010000'], tr/val_loss:  0.083728/  0.221593, val:  98.21%, val_best:  98.40%, tr:  99.65%, tr_best:  99.70%\n",
      "epoch-195 lr=['0.0010000'], tr/val_loss:  0.082921/  0.217804, val:  98.27%, val_best:  98.40%, tr:  99.68%, tr_best:  99.70%\n"
     ]
    }
   ],
   "source": [
    "### my_snn control board (Gesture) ########################\n",
    "decay = 0.5 # 0.0 # 0.875 0.25 0.125 0.75 0.5\n",
    "# nda 0.25 # ottt 0.5\n",
    "\n",
    "unique_name = 'main' ## 이거 설정하면 새로운 경로에 모두 save\n",
    "run_name = 'main' ## 이거 설정하면 새로운 경로에 모두 save\n",
    "\n",
    "\n",
    "\n",
    "wandb.init(project= f'my_snn {unique_name}',save_code=False, dir='/data2/bh_wandb', tags=[\"common\"])\n",
    "\n",
    "my_snn_system(  devices = \"2\",\n",
    "                single_step = True, # True # False # DFA_on이랑 같이 가라\n",
    "                unique_name = run_name,\n",
    "                my_seed = 42,\n",
    "                TIME = 10, # dvscifar 10 # ottt 6 or 10 # nda 10  # 제작하는 dvs에서 TIME넘거나 적으면 자르거나 PADDING함\n",
    "                BATCH = 16, # batch norm 할거면 2이상으로 해야함   # nda 256   #  ottt 128\n",
    "                IMAGE_SIZE = 17, # dvscifar 48 # MNIST 28 # CIFAR10 32 # PMNIST 28 #NMNIST 34 # GESTURE 128\n",
    "                # dvsgesture 128, dvs_cifar2 128, nmnist 34, n_caltech101 180,240, n_tidigits 64, heidelberg 700, \n",
    "\n",
    "                # DVS_CIFAR10 할거면 time 10으로 해라\n",
    "                which_data = 'NMNIST_TONIC',\n",
    "# 'CIFAR100' 'CIFAR10' 'MNIST' 'FASHION_MNIST' 'DVS_CIFAR10' 'PMNIST'아직\n",
    "# 'DVS_GESTURE', 'DVS_GESTURE_TONIC','DVS_CIFAR10_2','NMNIST','NMNIST_TONIC','CIFAR10','N_CALTECH101','n_tidigits','heidelberg'\n",
    "                # CLASS_NUM = 10,\n",
    "                data_path = '/data2', # YOU NEED TO CHANGE THIS\n",
    "                rate_coding = False, # True # False\n",
    "\n",
    "                lif_layer_v_init = 0.0,\n",
    "                lif_layer_v_decay = decay,\n",
    "                lif_layer_v_threshold = 0.5,   #nda 0.5  #ottt 1.0\n",
    "                lif_layer_v_reset = 10000.0, # 10000이상은 hardreset (내 LIF쓰기는 함 ㅇㅇ)\n",
    "                lif_layer_sg_width = 4.0, # 2.570969004857107 # sigmoid류에서는 alpha값 4.0, rectangle류에서는 width값 0.5\n",
    "\n",
    "                # synapse_conv_in_channels = IMAGE_PIXEL_CHANNEL,\n",
    "                synapse_conv_kernel_size = 3,\n",
    "                synapse_conv_stride = 1,\n",
    "                synapse_conv_padding = 1,\n",
    "\n",
    "                synapse_trace_const1 = 1, # 현재 trace구할 때 현재 spike에 곱해지는 상수. 걍 1로 두셈.\n",
    "                synapse_trace_const2 = decay, # 현재 trace구할 때 직전 trace에 곱해지는 상수. lif_layer_v_decay와 같게 할 것을 추천\n",
    "\n",
    "                # synapse_fc_out_features = CLASS_NUM,\n",
    "\n",
    "                pre_trained = False, # True # False\n",
    "                convTrue_fcFalse = False, # True # False\n",
    "\n",
    "                # 'P' for average pooling, 'D' for (1,1) aver pooling, 'M' for maxpooling, 'L' for linear classifier, [  ] for residual block\n",
    "                # conv에서 10000 이상은 depth-wise separable (BPTT만 지원), 20000이상은 depth-wise (BPTT만 지원)\n",
    "                # cfg = ['M', 'M', 32, 'P', 32, 'P', 32, 'P'], \n",
    "                # cfg = ['M', 'M', 64, 'P', 64, 'P', 64, 'P'], \n",
    "                # cfg = ['M', 'M', 64, 'M', 96, 'M', 128, 'M'], \n",
    "                cfg = [200, 200], \n",
    "                # cfg = ['M', 'M', 64, 'M', 96], \n",
    "                # cfg = ['M', 'M', 64, 'M', 96, 'L', 512, 512], \n",
    "                # cfg = ['M', 'M', 64], \n",
    "                # cfg = [64, 124, 64, 124],\n",
    "                # cfg = ['M','M',512], \n",
    "                # cfg = [512], \n",
    "                # cfg = ['M', 'M', 64, 128, 'P', 128, 'P'], \n",
    "                # cfg = ['M','M',512],\n",
    "                # cfg = ['M',200],\n",
    "                # cfg = [200,200],\n",
    "                # cfg = ['M','M',200,200],\n",
    "                # cfg = ([200],[200],[200],[2]), # (feature extractor, classifier, domain adapter, # of domain)\n",
    "                # cfg = (['M','M',200],[200],[200],[2]), # (feature extractor, classifier, domain adapter, # of domain)\n",
    "                # cfg = ['M',200,200],\n",
    "                # cfg = ['M','M',1024,512,256,128,64],\n",
    "                # cfg = [200,200],\n",
    "                # cfg = [12], #fc\n",
    "                # cfg = [12, 'M', 48, 'M', 12], \n",
    "                # cfg = [64,[64,64],64], # 끝에 linear classifier 하나 자동으로 붙습니다\n",
    "                # cfg = [64, 128, 'P', 256, 256, 'P', 512, 512, 'P', 512, 512, 'D'], #ottt\n",
    "                # cfg = [64, 128, 'P', 256, 256, 'P', 512, 512, 'P', 512, 512], \n",
    "                # cfg = [64, 128, 'M', 256, 256, 'M', 512, 512, 'M', 512, 512], \n",
    "                # cfg = [64, 'P', 128, 'P', 256, 256, 'P', 512, 512, 512, 512, 'D'], # nda\n",
    "                # cfg = [64, 'P', 128, 'P', 256, 256, 'P', 512, 512, 512, 512], # nda 128pixel\n",
    "                # cfg = [64, 'P', 128, 'P', 256, 256, 'P', 512, 512, 512, 512, 'L', 4096, 4096],\n",
    "                # cfg = [20001,10001], # depthwise, separable\n",
    "                # cfg = [64,20064,10001], # vanilla conv, depthwise, separable\n",
    "                # cfg = [8, 'P', 8, 'P', 8, 'P', 8,'P', 8, 'P'],\n",
    "                # cfg = [],        \n",
    "                \n",
    "                net_print = True, # True # False # True로 하길 추천\n",
    "                \n",
    "                pre_trained_path = f\"net_save/save_now_net_weights_{unique_name}.pth\",\n",
    "                learning_rate = 0.001, #0.1 bptt, #0.01 ottt, # default 0.001  # ottt 0.1 # nda 0.001 # 0.00936191669529645\n",
    "                epoch_num = 10000,\n",
    "                tdBN_on = False,  # True # False\n",
    "                BN_on = False,  # True # False\n",
    "                \n",
    "                surrogate = 'hard_sigmoid', # 'sigmoid' 'rectangle' 'rough_rectangle' 'hard_sigmoid'\n",
    "                \n",
    "                BPTT_on = False,  # True # False # True이면 BPTT, False이면 OTTT  # depthwise, separable은 BPTT만 가능\n",
    "                \n",
    "                optimizer_what = 'SGD', # 'SGD' 'Adam', 'RMSprop'\n",
    "                scheduler_name = 'no', # 'no' 'StepLR' 'ExponentialLR' 'ReduceLROnPlateau' 'CosineAnnealingLR' 'OneCycleLR'\n",
    "                \n",
    "                ddp_on = False, # DECREPATED # fALSE\n",
    "\n",
    "                dvs_clipping = 1, #일반적으로 1 또는 2 # 100ms때는 5 # 숫자만큼 크면 spike 아니면 걍 0\n",
    "                # gesture, cifar-dvs2, nmnist, ncaltech101\n",
    "                # gesture: 100_000c1-5, 25_000c5, 10_000c5, 1_000c5, 1_000_000c5\n",
    "\n",
    "                dvs_duration = 5_000, # 10_000 # 25_000, # 0 아니면 time sampling # dvs number sampling OR time sampling # gesture, cifar-dvs2, nmnist, ncaltech101\n",
    "                # 있는 데이터들 #gesture 100_000 25_000 10_000 1_000 1_000_000 #nmnist 10000 #nmnist_tonic 10_000 25_000\n",
    "                # 한 숫자가 1us인듯 (spikingjelly코드에서)\n",
    "                # 한 장에 50 timestep만 생산함. 싫으면 my_snn/trying/spikingjelly_dvsgesture의__init__.py 를 참고해봐\n",
    "                # nmnist 5_000us, gesture는 100_000us, 25_000us\n",
    "\n",
    "                DFA_on = True, # True # False # single_step이랑 같이 켜야 됨.\n",
    "\n",
    "                trace_on = False,   # True # False\n",
    "                OTTT_input_trace_on = False, # True # False # 맨 처음 input에 trace 적용 # trace_on False면 의미없음.\n",
    "\n",
    "                exclude_class = True, # True # False # gesture에서 10번째 클래스 제외\n",
    "\n",
    "                merge_polarities = False, # True # False # tonic dvs dataset 에서 polarities 합치기\n",
    "                denoise_on = False, # True # False # &&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&\n",
    "\n",
    "                extra_train_dataset = 0, \n",
    "\n",
    "                num_workers = 2, # local wsl에서는 2가 맞고, 서버에서는 4가 좋더라.\n",
    "                chaching_on = True, # True # False # only for certain datasets (gesture_tonic, nmnist_tonic)\n",
    "                pin_memory = True, # True # False \n",
    "\n",
    "                UDA_on = False,  # DECREPATED # uda\n",
    "                alpha_uda = 1.0, # DECREPATED # uda\n",
    "\n",
    "                bias = True, # True # False \n",
    "\n",
    "                last_lif = False, # True # False \n",
    "\n",
    "                temporal_filter = 1, \n",
    "                initial_pooling = 1,\n",
    "\n",
    "                temporal_filter_accumulation = False, # True # False \n",
    "                ) \n",
    "\n",
    "# num_workers = 4 * num_GPU (or 8, 16, 2 * num_GPU)\n",
    "# entry * batch_size * num_worker = num_GPU * GPU_throughtput\n",
    "# num_workers = batch_size / num_GPU\n",
    "# num_workers = batch_size / num_CPU\n",
    "\n",
    "# sigmoid와 BN이 있어야 잘된다.\n",
    "# average pooling  \n",
    "# 이 낫다. \n",
    "\n",
    "# nda에서는 decay = 0.25, threshold = 0.5, width =1, surrogate = rectangle, batch = 256, tdBN = True\n",
    "## OTTT 에서는 decay = 0.5, threshold = 1.0, surrogate = sigmoid, batch = 128, BN = True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # sweep 하는 코드, 위 셀 주석처리 해야 됨.\n",
    "\n",
    "# # 이런 워닝 뜨는 거는 걍 너가 main 안에서  wandb.config.update(hyperparameters)할 때 물려서임. 어차피 근데 sweep에서 지정한 걸로 덮어짐 \n",
    "# # wandb: WARNING Config item 'BATCH' was locked by 'sweep' (ignored update).\n",
    "\n",
    "# unique_name_hyper = 'main'\n",
    "# sweep_configuration = {\n",
    "#     'method': 'bayes', # 'random', 'bayes'\n",
    "#     'name': f'my_snn_sweep{datetime.datetime.now().strftime(\"%Y%m%d_%H%M%S\")}',\n",
    "#     'metric': {'goal': 'maximize', 'name': 'val_acc_best'},\n",
    "#     'parameters': \n",
    "#     {\n",
    "#         # \"devices\": {\"values\": [\"1\"]},\n",
    "#         \"single_step\": {\"values\": [True]},\n",
    "#         # \"unique_name\": {\"values\": [unique_name_hyper]},\n",
    "#         \"my_seed\": {\"values\": [42]},\n",
    "#         \"TIME\": {\"values\": [10]},\n",
    "#         \"BATCH\": {\"values\": [16]},\n",
    "#         \"IMAGE_SIZE\": {\"values\": [128]},\n",
    "#         \"which_data\": {\"values\": ['DVS_GESTURE_TONIC']},\n",
    "#         \"data_path\": {\"values\": ['/data2']},\n",
    "#         \"rate_coding\": {\"values\": [False]},\n",
    "#         \"lif_layer_v_init\": {\"values\": [0.0]},\n",
    "#         \"lif_layer_v_decay\": {\"values\": [0.5]},\n",
    "#         \"lif_layer_v_threshold\": {\"values\": [0.25, 0.5, 0.75, 1.0]},\n",
    "#         \"lif_layer_v_reset\": {\"values\": [10000.0, 0.0]},\n",
    "#         \"lif_layer_sg_width\": {\"values\": [1.0,2.0,3.0,4.0,5.0]},\n",
    "\n",
    "#         \"synapse_conv_kernel_size\": {\"values\": [3]},\n",
    "#         \"synapse_conv_stride\": {\"values\": [1]},\n",
    "#         \"synapse_conv_padding\": {\"values\": [1]},\n",
    "\n",
    "#         \"synapse_trace_const1\": {\"values\": [1]},\n",
    "#         \"synapse_trace_const2\": {\"values\": [0, 0.5]},\n",
    "\n",
    "#         \"pre_trained\": {\"values\": [False]},\n",
    "#         \"convTrue_fcFalse\": {\"values\": [False]},\n",
    "\n",
    "#         \"cfg\": {\"values\": [['M','M',200,200]]},\n",
    "\n",
    "#         \"net_print\": {\"values\": [True]},\n",
    "\n",
    "#         \"pre_trained_path\": {\"values\": [\"net_save/save_now_net_weights_{unique_name}.pth\"]},\n",
    "#         \"learning_rate\": {\"values\": [0.001,0.01,0.1,0.0001]}, \n",
    "#         \"epoch_num\": {\"values\": [100]}, \n",
    "#         \"tdBN_on\": {\"values\": [False]},\n",
    "#         \"BN_on\": {\"values\": [False]},\n",
    "\n",
    "#         \"surrogate\": {\"values\": ['hard_sigmoid']},\n",
    "\n",
    "#         \"BPTT_on\": {\"values\": [False]},\n",
    "\n",
    "#         \"optimizer_what\": {\"values\": ['SGD']},\n",
    "#         \"scheduler_name\": {\"values\": ['no']},\n",
    "\n",
    "#         \"ddp_on\": {\"values\": [False]},\n",
    "\n",
    "#         \"dvs_clipping\": {\"values\": [5]}, \n",
    "\n",
    "#         \"dvs_duration\": {\"values\": [100_000]}, \n",
    "\n",
    "#         \"DFA_on\": {\"values\": [True, False]},\n",
    "\n",
    "#         \"trace_on\": {\"values\": [True]},\n",
    "#         \"OTTT_input_trace_on\": {\"values\": [False]},\n",
    "\n",
    "#         \"exclude_class\": {\"values\": [True]},\n",
    "\n",
    "#         \"merge_polarities\": {\"values\": [False]},\n",
    "#         \"denoise_on\": {\"values\": [True, False]},\n",
    "\n",
    "#         \"extra_train_dataset\": {\"values\": [0]},\n",
    "\n",
    "#         \"num_workers\": {\"values\": [2]},\n",
    "#         \"chaching_on\": {\"values\": [True]},\n",
    "#         \"pin_memory\": {\"values\": [True]},\n",
    "\n",
    "#         \"UDA_on\": {\"values\": [False]},\n",
    "#         \"alpha_uda\": {\"values\": [1.0]},\n",
    "\n",
    "#         \"bias\": {\"values\": [True]},\n",
    "\n",
    "#         \"last_lif\": {\"values\": [False]},\n",
    "\n",
    "#         \"temporal_filter\": {\"values\": [1]},\n",
    "#         \"initial_pooling\": {\"values\": [1]},\n",
    "\n",
    "#         \"temporal_filter_accumulation\": {\"values\": [False]},\n",
    "#      }\n",
    "# }\n",
    "\n",
    "# def hyper_iter():\n",
    "#     ### my_snn control board ########################\n",
    "#     wandb.init(save_code=False, dir='/data2/bh_wandb', tags=[\"sweep\"])\n",
    "\n",
    "#     my_snn_system(  \n",
    "#         devices  =  \"0\",\n",
    "#         single_step  =  wandb.config.single_step,\n",
    "#         unique_name  =  unique_name_hyper,\n",
    "#         my_seed  =  wandb.config.my_seed,\n",
    "#         TIME  =  wandb.config.TIME,\n",
    "#         BATCH  =  wandb.config.BATCH,\n",
    "#         IMAGE_SIZE  =  wandb.config.IMAGE_SIZE,\n",
    "#         which_data  =  wandb.config.which_data,\n",
    "#         data_path  =  wandb.config.data_path,\n",
    "#         rate_coding  =  wandb.config.rate_coding,\n",
    "#         lif_layer_v_init  =  wandb.config.lif_layer_v_init,\n",
    "#         lif_layer_v_decay  =  wandb.config.lif_layer_v_decay,\n",
    "#         lif_layer_v_threshold  =  wandb.config.lif_layer_v_threshold,\n",
    "#         lif_layer_v_reset  =  wandb.config.lif_layer_v_reset,\n",
    "#         lif_layer_sg_width  =  wandb.config.lif_layer_sg_width,\n",
    "#         synapse_conv_kernel_size  =  wandb.config.synapse_conv_kernel_size,\n",
    "#         synapse_conv_stride  =  wandb.config.synapse_conv_stride,\n",
    "#         synapse_conv_padding  =  wandb.config.synapse_conv_padding,\n",
    "#         synapse_trace_const1  =  wandb.config.synapse_trace_const1,\n",
    "#         synapse_trace_const2  =  wandb.config.synapse_trace_const2,\n",
    "#         pre_trained  =  wandb.config.pre_trained,\n",
    "#         convTrue_fcFalse  =  wandb.config.convTrue_fcFalse,\n",
    "#         cfg  =  wandb.config.cfg,\n",
    "#         net_print  =  wandb.config.net_print,\n",
    "#         pre_trained_path  =  wandb.config.pre_trained_path,\n",
    "#         learning_rate  =  wandb.config.learning_rate,\n",
    "#         epoch_num  =  wandb.config.epoch_num,\n",
    "#         tdBN_on  =  wandb.config.tdBN_on,\n",
    "#         BN_on  =  wandb.config.BN_on,\n",
    "#         surrogate  =  wandb.config.surrogate,\n",
    "#         BPTT_on  =  wandb.config.BPTT_on,\n",
    "#         optimizer_what  =  wandb.config.optimizer_what,\n",
    "#         scheduler_name  =  wandb.config.scheduler_name,\n",
    "#         ddp_on  =  wandb.config.ddp_on,\n",
    "#         dvs_clipping  =  wandb.config.dvs_clipping,\n",
    "#         dvs_duration  =  wandb.config.dvs_duration,\n",
    "#         DFA_on  =  wandb.config.DFA_on,\n",
    "#         trace_on  =  wandb.config.trace_on,\n",
    "#         OTTT_input_trace_on  =  wandb.config.OTTT_input_trace_on,\n",
    "#         exclude_class  =  wandb.config.exclude_class,\n",
    "#         merge_polarities  =  wandb.config.merge_polarities,\n",
    "#         denoise_on  =  wandb.config.denoise_on,\n",
    "#         extra_train_dataset  =  wandb.config.extra_train_dataset,\n",
    "#         num_workers  =  wandb.config.num_workers,\n",
    "#         chaching_on  =  wandb.config.chaching_on,\n",
    "#         pin_memory  =  wandb.config.pin_memory,\n",
    "#         UDA_on  =  wandb.config.UDA_on,\n",
    "#         alpha_uda  =  wandb.config.alpha_uda,\n",
    "#         bias  =  wandb.config.bias,\n",
    "#         last_lif  =  wandb.config.last_lif,\n",
    "#         temporal_filter  =  wandb.config.temporal_filter,\n",
    "#         initial_pooling  =  wandb.config.initial_pooling,\n",
    "#         temporal_filter_accumulation  =  wandb.config.temporal_filter_accumulation,\n",
    "#                         ) \n",
    "#     # sigmoid와 BN이 있어야 잘된다.\n",
    "#     # average pooling\n",
    "#     # 이 낫다. \n",
    "    \n",
    "#     # nda에서는 decay = 0.25, threshold = 0.5, width =1, surrogate = rectangle, batch = 256, tdBN = True\n",
    "#     ## OTTT 에서는 decay = 0.5, threshold = 1.0, surrogate = sigmoid, batch = 128, BN = True\n",
    "\n",
    "# # sweep_id = '6pj3lh8j'\n",
    "# sweep_id = wandb.sweep(sweep=sweep_configuration, project=f'my_snn {unique_name_hyper}')\n",
    "# wandb.agent(sweep_id, function=hyper_iter, count=10000, project=f'my_snn {unique_name_hyper}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wandb.finish() "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aedat2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
