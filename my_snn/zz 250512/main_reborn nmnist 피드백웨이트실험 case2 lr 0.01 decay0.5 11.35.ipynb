{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_19185/3748606120.py:46: DeprecationWarning: The module snntorch.spikevision is deprecated. For loading neuromorphic datasets, we recommend using the Tonic project: https://github.com/neuromorphs/tonic\n",
      "  from snntorch.spikevision import spikedata\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x600 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "import argparse\n",
    "import torch\n",
    "import torch.nn as nn \n",
    "import torch.nn.functional as F\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.optim as optim\n",
    "import torch.optim.lr_scheduler as lr_scheduler\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "import torchvision\n",
    "import torchvision.datasets\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import time\n",
    "\n",
    "from snntorch import spikegen\n",
    "import matplotlib.pyplot as plt\n",
    "import snntorch.spikeplot as splt\n",
    "from IPython.display import HTML\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "from apex.parallel import DistributedDataParallel as DDP\n",
    "\n",
    "import random\n",
    "import datetime\n",
    "\n",
    "import json\n",
    "\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "''' 레퍼런스\n",
    "https://spikingjelly.readthedocs.io/zh-cn/0.0.0.0.4/spikingjelly.datasets.html#module-spikingjelly.datasets\n",
    "https://github.com/GorkaAbad/Sneaky-Spikes/blob/main/datasets.py\n",
    "https://github.com/GorkaAbad/Sneaky-Spikes/blob/main/how_to.md\n",
    "https://github.com/nmi-lab/torchneuromorphic\n",
    "https://snntorch.readthedocs.io/en/latest/snntorch.spikevision.spikedata.html#shd\n",
    "'''\n",
    "\n",
    "import snntorch\n",
    "from snntorch.spikevision import spikedata\n",
    "\n",
    "import modules.spikingjelly;\n",
    "from modules.spikingjelly.datasets.dvs128_gesture import DVS128Gesture\n",
    "from modules.spikingjelly.datasets.cifar10_dvs import CIFAR10DVS\n",
    "from modules.spikingjelly.datasets.n_mnist import NMNIST\n",
    "# from modules.spikingjelly.datasets.es_imagenet import ESImageNet\n",
    "from modules.spikingjelly.datasets import split_to_train_test_set\n",
    "from modules.spikingjelly.datasets.n_caltech101 import NCaltech101\n",
    "from modules.spikingjelly.datasets import pad_sequence_collate, padded_sequence_mask\n",
    "\n",
    "import modules.torchneuromorphic as torchneuromorphic\n",
    "\n",
    "import wandb\n",
    "\n",
    "from torchviz import make_dot\n",
    "import graphviz\n",
    "from turtle import shape\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# my module import\n",
    "from modules import *\n",
    "\n",
    "# modules 폴더에 새모듈.py 만들면\n",
    "# modules/__init__py 파일에 form .새모듈 import * 하셈\n",
    "# 그리고 새모듈.py에서 from modules.새모듈 import * 하셈\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def my_snn_system(devices = \"0,1,2,3\",\n",
    "                    single_step = False, # True # False\n",
    "                    unique_name = 'main',\n",
    "                    my_seed = 42,\n",
    "                    TIME = 10,\n",
    "                    BATCH = 256,\n",
    "                    IMAGE_SIZE = 32,\n",
    "                    which_data = 'CIFAR10',\n",
    "                    # CLASS_NUM = 10,\n",
    "                    data_path = '/data2',\n",
    "                    rate_coding = True,\n",
    "    \n",
    "                    lif_layer_v_init = 0.0,\n",
    "                    lif_layer_v_decay = 0.6,\n",
    "                    lif_layer_v_threshold = 1.2,\n",
    "                    lif_layer_v_reset = 0.0,\n",
    "                    lif_layer_sg_width = 1,\n",
    "\n",
    "                    # synapse_conv_in_channels = IMAGE_PIXEL_CHANNEL,\n",
    "                    synapse_conv_kernel_size = 3,\n",
    "                    synapse_conv_stride = 1,\n",
    "                    synapse_conv_padding = 1,\n",
    "\n",
    "                    synapse_trace_const1 = 1,\n",
    "                    synapse_trace_const2 = 0.6,\n",
    "\n",
    "                    # synapse_fc_out_features = CLASS_NUM,\n",
    "\n",
    "                    pre_trained = False,\n",
    "                    convTrue_fcFalse = True,\n",
    "\n",
    "                    cfg = [64, 64],\n",
    "                    net_print = False, # True # False\n",
    "                    \n",
    "                    pre_trained_path = \"net_save/save_now_net.pth\",\n",
    "                    learning_rate = 0.0001,\n",
    "                    epoch_num = 200,\n",
    "                    tdBN_on = False,\n",
    "                    BN_on = False,\n",
    "\n",
    "                    surrogate = 'sigmoid',\n",
    "\n",
    "                    BPTT_on = False,\n",
    "\n",
    "                    optimizer_what = 'SGD', # 'SGD' 'Adam', 'RMSprop'\n",
    "                    scheduler_name = 'no',\n",
    "                    \n",
    "                    ddp_on = False, # DECREPATED # fALSE\n",
    "\n",
    "                    dvs_clipping = 1, \n",
    "                    dvs_duration = 25_000,\n",
    "\n",
    "\n",
    "                    DFA_on = False, # True # False\n",
    "                    trace_on = False, \n",
    "                    OTTT_input_trace_on = False, # True # False\n",
    "                    \n",
    "                    exclude_class = True, # True # False # gesture에서 10번째 클래스 제외\n",
    "\n",
    "                    merge_polarities = False, # True # False # tonic dvs dataset 에서 polarities 합치기\n",
    "                    denoise_on = True, \n",
    "\n",
    "                    extra_train_dataset = 0, # DECREPATED # data_loader에서 train dataset을 몇개 더 쓸건지 \n",
    "\n",
    "                    num_workers = 2,\n",
    "                    chaching_on = True,\n",
    "                    pin_memory = True, # True # False\n",
    "                    \n",
    "                    UDA_on = False,  # DECREPATED # uda\n",
    "                    alpha_uda = 1.0, # DECREPATED # uda\n",
    "\n",
    "                    bias = True,\n",
    "\n",
    "                    last_lif = False,\n",
    "                        \n",
    "                    temporal_filter = 1, \n",
    "                    initial_pooling = 1,\n",
    "\n",
    "                    temporal_filter_accumulation = False,\n",
    "                    ):\n",
    "    ## 함수 내 모든 로컬 변수 저장 ########################################################\n",
    "    hyperparameters = locals()\n",
    "    print('param', hyperparameters,'\\n')\n",
    "    hyperparameters['current epoch'] = 0\n",
    "    ######################################################################################\n",
    "\n",
    "    ## hyperparameter check #############################################################\n",
    "    if single_step == True:\n",
    "        assert BPTT_on == False and tdBN_on == False \n",
    "    if tdBN_on == True:\n",
    "        assert BPTT_on == True\n",
    "    if pre_trained == True:\n",
    "        print('\\n\\n')\n",
    "        print(\"Caution! pre_trained is True\\n\\n\"*3)    \n",
    "    if DFA_on == True:\n",
    "        assert single_step == True and BPTT_on == False \n",
    "    # assert single_step == DFA_on, 'DFA랑 single_step공존하게해라'\n",
    "    if trace_on:\n",
    "        assert BPTT_on == False and single_step == True\n",
    "    if OTTT_input_trace_on == True:\n",
    "        assert BPTT_on == False and single_step == True #and trace_on == True\n",
    "    if temporal_filter > 1:\n",
    "        assert convTrue_fcFalse == False\n",
    "    ######################################################################################\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "    ## wandb 세팅 ###################################################################\n",
    "    current_time = datetime.datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "    wandb.config.update(hyperparameters)\n",
    "    wandb.run.name = f'lr_{learning_rate}_{unique_name}_{which_data}_tstep{TIME}'\n",
    "    wandb.define_metric(\"summary_val_acc\", summary=\"max\")\n",
    "    # wandb.run.log_code(\".\", \n",
    "    #                     include_fn=lambda path: path.endswith(\".py\") or path.endswith(\".ipynb\"),\n",
    "    #                     exclude_fn=lambda path: 'logs/' in path or 'net_save/' in path or 'result_save/' in path or 'trying/' in path or 'wandb/' in path or 'private/' in path or '.git/' in path or 'tonic' in path or 'torchneuromorphic' in path or 'spikingjelly' in path \n",
    "    #                     )\n",
    "    ###################################################################################\n",
    "\n",
    "\n",
    "\n",
    "    ## gpu setting ##################################################################################################################\n",
    "    os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\" \n",
    "    os.environ[\"CUDA_VISIBLE_DEVICES\"]= devices\n",
    "    ###################################################################################################################################\n",
    "\n",
    "\n",
    "    ## seed setting ##################################################################################################################\n",
    "    seed_assign(my_seed)\n",
    "    ###################################################################################################################################\n",
    "    \n",
    "\n",
    "    ## data_loader 가져오기 ##################################################################################################################\n",
    "    # data loader, pixel channel, class num\n",
    "    train_data_split_indices = []\n",
    "    train_loader, test_loader, synapse_conv_in_channels, CLASS_NUM, train_data_count = data_loader(\n",
    "            which_data,\n",
    "            data_path, \n",
    "            rate_coding, \n",
    "            BATCH, \n",
    "            IMAGE_SIZE,\n",
    "            ddp_on,\n",
    "            TIME*temporal_filter, \n",
    "            dvs_clipping,\n",
    "            dvs_duration,\n",
    "            exclude_class,\n",
    "            merge_polarities,\n",
    "            denoise_on,\n",
    "            my_seed,\n",
    "            extra_train_dataset,\n",
    "            num_workers,\n",
    "            chaching_on,\n",
    "            pin_memory,\n",
    "            train_data_split_indices,) \n",
    "    synapse_fc_out_features = CLASS_NUM\n",
    "\n",
    "    print('\\nlen(train_loader):', len(train_loader), 'BATCH:', BATCH, 'train_data_count:', train_data_count) \n",
    "    print('len(test_loader):', len(test_loader), 'BATCH:', BATCH)\n",
    "\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    print(f\"\\ndevice ==> {device}\\n\")\n",
    "    if device == \"cpu\":\n",
    "        print(\"=\"*50,\"\\n[WARNING]\\n[WARNING]\\n[WARNING]\\n: cpu mode\\n\\n\",\"=\"*50)\n",
    "\n",
    "    ### network setting #######################################################################################################################\n",
    "    if (convTrue_fcFalse == False):\n",
    "        net = REBORN_MY_SNN_FC(cfg, synapse_conv_in_channels*temporal_filter, IMAGE_SIZE//initial_pooling, synapse_fc_out_features,\n",
    "                    synapse_trace_const1, synapse_trace_const2, \n",
    "                    lif_layer_v_init, lif_layer_v_decay, \n",
    "                    lif_layer_v_threshold, lif_layer_v_reset,\n",
    "                    lif_layer_sg_width,\n",
    "                    tdBN_on,\n",
    "                    BN_on, TIME,\n",
    "                    surrogate,\n",
    "                    BPTT_on,\n",
    "                    DFA_on,\n",
    "                    bias,\n",
    "                    single_step,\n",
    "                    last_lif,\n",
    "                    trace_on).to(device)\n",
    "    else:\n",
    "        net = REBORN_MY_SNN_CONV(cfg, synapse_conv_in_channels, IMAGE_SIZE//initial_pooling,\n",
    "                    synapse_conv_kernel_size, synapse_conv_stride, \n",
    "                    synapse_conv_padding, synapse_trace_const1, \n",
    "                    synapse_trace_const2, \n",
    "                    lif_layer_v_init, lif_layer_v_decay, \n",
    "                    lif_layer_v_threshold, lif_layer_v_reset,\n",
    "                    lif_layer_sg_width,\n",
    "                    synapse_fc_out_features, \n",
    "                    tdBN_on,\n",
    "                    BN_on, TIME,\n",
    "                    surrogate,\n",
    "                    BPTT_on,\n",
    "                    DFA_on,\n",
    "                    bias,\n",
    "                    single_step,\n",
    "                    last_lif,\n",
    "                    trace_on).to(device)\n",
    "\n",
    "    net = torch.nn.DataParallel(net) \n",
    "    \n",
    "    if pre_trained == True:\n",
    "        net.load_state_dict(torch.load(pre_trained_path))\n",
    "    \n",
    "    net = net.to(device)\n",
    "    if (net_print == True):\n",
    "        print(net)    \n",
    "\n",
    "    print(f\"\\n========================================================\\nTrainable parameters: {sum(p.numel() for p in net.parameters() if p.requires_grad):,}\\n========================================================\\n\")\n",
    "    ####################################################################################################################################\n",
    "    \n",
    "\n",
    "    ## wandb logging ###########################################\n",
    "    # wandb.watch(net, log=\"all\", log_freq = 10) #gradient, parameter logging해줌\n",
    "    ############################################################\n",
    "\n",
    "    ## criterion ########################################## # loss 구해주는 친구\n",
    "    def my_cross_entropy_loss(logits, targets):\n",
    "        # logits: (batch_size, num_classes)\n",
    "        # targets: (batch_size,) -> 클래스 인덱스\n",
    "        log_probs = F.log_softmax(logits, dim=1)  # log(p_i)\n",
    "        loss = F.nll_loss(log_probs, targets)\n",
    "        # print(loss.shape)\n",
    "        return loss\n",
    "    \n",
    "    class CustomLossFunction(torch.autograd.Function):\n",
    "        @staticmethod\n",
    "        def forward(ctx, input, target):\n",
    "            # MSE를 계산\n",
    "            ctx.save_for_backward(input, target)\n",
    "            target_one_hot = torch.zeros_like(input).scatter_(1, target.unsqueeze(1), 1.0)\n",
    "            return torch.mean((input - target_one_hot) ** 2)\n",
    "\n",
    "        @staticmethod\n",
    "        def backward(ctx, grad_output):\n",
    "            # MAE 스타일의 gradient를 흉내냄\n",
    "            input, target = ctx.saved_tensors\n",
    "            input_argmax = input.argmax(dim=1)\n",
    "            input_one_hot = torch.zeros_like(input).scatter_(1, input_argmax.unsqueeze(1), 1.0)\n",
    "            target_one_hot = torch.zeros_like(input).scatter_(1, target.unsqueeze(1), 1.0)\n",
    "            # print('grad_output', grad_output) # 이거 걍 1.0임\n",
    "            return input_one_hot - target_one_hot, None  # target에는 gradient 없음\n",
    "\n",
    "    # Wrapper module\n",
    "    class CustomCriterion(torch.nn.Module):\n",
    "        def __init__(self):\n",
    "            super().__init__()\n",
    "\n",
    "        def forward(self, input, target):\n",
    "            return CustomLossFunction.apply(input, target)\n",
    "\n",
    "    # criterion = nn.CrossEntropyLoss().to(device)\n",
    "    criterion = CustomCriterion().to(device)\n",
    "    \n",
    "    # if (OTTT_sWS_on == True):\n",
    "    #     # criterion = nn.CrossEntropyLoss().to(device)\n",
    "        # criterion = lambda y_t, target_t: ((1 - 0.05) * F.cross_entropy(y_t, target_t) + 0.05 * F.mse_loss(y_t, F.one_hot(target_t, CLASS_NUM).float())) / TIME \n",
    "    #     if which_data == 'DVS_GESTURE':\n",
    "    #         criterion = lambda y_t, target_t: ((1 - 0.001) * F.cross_entropy(y_t, target_t) + 0.001 * F.mse_loss(y_t, F.one_hot(target_t, CLASS_NUM).float())) / TIME \n",
    "    \n",
    "    print('current loss function:', criterion)\n",
    "    ####################################################\n",
    "    \n",
    "    ## optimizer, scheduler ########################################################################\n",
    "    if(optimizer_what == 'SGD'):\n",
    "        optimizer = optim.SGD(net.parameters(), lr=learning_rate, momentum=0.9)\n",
    "        # optimizer = optim.SGD(net.parameters(), lr=learning_rate, momentum=0.9, weight_decay=0)\n",
    "    elif(optimizer_what == 'Adam'):\n",
    "        optimizer = torch.optim.Adam(net.parameters(), lr=learning_rate)\n",
    "        # optimizer = torch.optim.Adam(net.parameters(), lr=0.00001)\n",
    "        # optimizer = torch.optim.Adam(net.parameters(), lr=learning_rate/256 * BATCH, weight_decay=1e-4)\n",
    "        # optimizer = optim.Adam(net.parameters(), lr=learning_rate, weight_decay=0, betas=(0.9, 0.999))\n",
    "    elif(optimizer_what == 'RMSprop'):\n",
    "        pass\n",
    "\n",
    "\n",
    "    if (scheduler_name == 'StepLR'):\n",
    "        scheduler = lr_scheduler.StepLR(optimizer, step_size=10, gamma=0.1)\n",
    "    elif (scheduler_name == 'ExponentialLR'):\n",
    "        scheduler = lr_scheduler.ExponentialLR(optimizer, gamma=0.95)\n",
    "    elif (scheduler_name == 'ReduceLROnPlateau'):\n",
    "        scheduler = lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.1, patience=10)\n",
    "    elif (scheduler_name == 'CosineAnnealingLR'):\n",
    "        # scheduler = lr_scheduler.CosineAnnealingLR(optimizer, eta_min=0, T_max=50)\n",
    "        scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, eta_min=0, T_max=epoch_num)\n",
    "    elif (scheduler_name == 'OneCycleLR'):\n",
    "        scheduler = lr_scheduler.OneCycleLR(optimizer, max_lr=0.1, steps_per_epoch=len(train_loader), epochs=epoch_num)\n",
    "    else:\n",
    "        pass # 'no' scheduler\n",
    "    ## optimizer, scheduler ########################################################################\n",
    "\n",
    "\n",
    "    tr_acc = 0\n",
    "    tr_correct = 0\n",
    "    tr_total = 0\n",
    "    tr_acc_best = 0\n",
    "    tr_epoch_loss_temp = 0\n",
    "    tr_epoch_loss = 0\n",
    "    val_acc_best = 0\n",
    "    val_acc_now = 0\n",
    "    val_loss = 0\n",
    "    iter_of_val = False\n",
    "    #======== EPOCH START ==========================================================================================\n",
    "    for epoch in range(epoch_num):\n",
    "        if epoch == 1:\n",
    "            for name, module in net.named_modules():\n",
    "                if isinstance(module, Feedback_Receiver):\n",
    "                    print(f\"[{name}] weight_fb parameter count: {module.weight_fb.numel():,}\")\n",
    "        ####### iterator : input_loading & tqdm을 통한 progress_bar 생성###################\n",
    "        iterator = enumerate(train_loader, 0)\n",
    "        # iterator = tqdm(iterator, total=len(train_loader), desc='train', dynamic_ncols=True, position=0, leave=True)\n",
    "        ##################################################################################   \n",
    "\n",
    "        ###### ITERATION START ##########################################################################################################\n",
    "        for i, data in iterator:\n",
    "            net.train() # train 모드로 바꿔줘야함\n",
    "            ### data loading & semi-pre-processing ################################################################################\n",
    "            if len(data) == 2:\n",
    "                inputs, labels = data\n",
    "                # 처리 로직 작성\n",
    "            elif len(data) == 3:\n",
    "                inputs, labels, x_len = data\n",
    "            else:\n",
    "                assert False, 'data length is not 2 or 3'\n",
    "            #######################################################################################################################\n",
    "                \n",
    "            ## batch 크기 ######################################\n",
    "            real_batch = labels.size(0)\n",
    "            ###########################################################\n",
    "\n",
    "            # 차원 전처리\n",
    "            ###########################################################################################################################        \n",
    "            if (which_data == 'DVS_CIFAR10' or which_data == 'DVS_GESTURE' or which_data == 'DVS_GESTURE_TONIC' or which_data == 'DVS_CIFAR10_2' or which_data == 'NMNIST' or which_data == 'NMNIST_TONIC' or which_data == 'N_CALTECH101' or which_data == 'n_tidigits' or which_data == 'heidelberg'):\n",
    "                inputs = inputs.permute(1, 0, 2, 3, 4)\n",
    "            elif rate_coding == True :\n",
    "                inputs = spikegen.rate(inputs, num_steps=TIME)\n",
    "            else :\n",
    "                inputs = inputs.repeat(TIME, 1, 1, 1, 1)\n",
    "            # inputs: [Time, Batch, Channel, Height, Width]  \n",
    "            ####################################################################################################################### \n",
    "                \n",
    "\n",
    "\n",
    "                            \n",
    "            ## initial pooling #######################################################################\n",
    "            if (initial_pooling > 1):\n",
    "                pool = nn.MaxPool2d(kernel_size=2)\n",
    "                num_pooling_layers = int(math.log2(initial_pooling))\n",
    "                # Time, Batch, Channel 차원은 그대로 두고, Height, Width 차원에 대해서만 pooling 적용\n",
    "                shape_temp = inputs.shape\n",
    "                inputs = inputs.reshape(shape_temp[0]*shape_temp[1], shape_temp[2], shape_temp[3], shape_temp[4])\n",
    "                for _ in range(num_pooling_layers):\n",
    "                    inputs = pool(inputs)\n",
    "                inputs = inputs.reshape(shape_temp[0], shape_temp[1], shape_temp[2], shape_temp[3]//initial_pooling, shape_temp[4]//initial_pooling)\n",
    "            ## initial pooling #######################################################################\n",
    "            ## temporal filtering ####################################################################\n",
    "            shape_temp = inputs.shape\n",
    "            if (temporal_filter > 1):\n",
    "                slice_bucket = []\n",
    "                for t_temp in range(TIME):\n",
    "                    start = t_temp * temporal_filter\n",
    "                    end = start + temporal_filter\n",
    "                    slice_concat = torch.movedim(inputs[start:end], 0, 1).reshape(shape_temp[1],shape_temp[2],shape_temp[3],-1)\n",
    "                    \n",
    "                    if temporal_filter_accumulation == True:\n",
    "                        if t_temp == 0:\n",
    "                            slice_bucket.append(slice_concat)\n",
    "                        else:\n",
    "                            slice_bucket.append(slice_concat+slice_bucket[t_temp-1])\n",
    "                    else:\n",
    "                        slice_bucket.append(slice_concat)\n",
    "\n",
    "                inputs = torch.stack(slice_bucket, dim=0)\n",
    "                if temporal_filter_accumulation == True and dvs_clipping > 0:\n",
    "                    inputs = (inputs != 0.0).float()\n",
    "            ## temporal filtering ####################################################################\n",
    "            ####################################################################################################################### \n",
    "                \n",
    "\n",
    "            # # dvs 데이터 시각화 코드 (확인 필요할 시 써라)\n",
    "            # ##############################################################################################\n",
    "            # dvs_visualization(inputs, labels, TIME, BATCH, my_seed)\n",
    "            # #####################################################################################################\n",
    "\n",
    "            ## to (device) #######################################\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "            ###########################################################\n",
    "\n",
    "            ## gradient 초기화 #######################################\n",
    "            optimizer.zero_grad()\n",
    "            ###########################################################\n",
    "                            \n",
    "            if merge_polarities == True:\n",
    "                inputs = inputs[:,:,0:1,:,:]\n",
    "\n",
    "            if single_step == False:\n",
    "                # net에 넣어줄때는 batch가 젤 앞 차원으로 와야함. # dataparallel때매##############################\n",
    "                # inputs: [Time, Batch, Channel, Height, Width]   \n",
    "                inputs = inputs.permute(1, 0, 2, 3, 4) # net에 넣어줄때는 batch가 젤 앞 차원으로 와야함. # dataparallel때매\n",
    "                # inputs: [Batch, Time, Channel, Height, Width] \n",
    "                #################################################################################################\n",
    "            else:\n",
    "                labels = labels.repeat(TIME, 1)\n",
    "                ## first input도 ottt trace 적용하기 위한 코드 (validation 시에는 필요X) ##########################\n",
    "                if trace_on == True and OTTT_input_trace_on == True:\n",
    "                    spike = inputs\n",
    "                    trace = torch.full_like(spike, fill_value = 0.0, dtype = torch.float, requires_grad=False)\n",
    "                    inputs = []\n",
    "                    for t in range(TIME):\n",
    "                        trace[t] = trace[t-1]*synapse_trace_const2 + spike[t]*synapse_trace_const1\n",
    "                        inputs += [[spike[t], trace[t]]]\n",
    "                ##################################################################################################\n",
    "\n",
    "\n",
    "            if single_step == False:\n",
    "                ### input --> net --> output #####################################################\n",
    "                outputs = net(inputs)\n",
    "                ##################################################################################\n",
    "                ## loss, backward ##########################################\n",
    "                iter_loss = criterion(outputs, labels)\n",
    "                iter_loss.backward()\n",
    "                ############################################################\n",
    "                ## weight 업데이트!! ##################################\n",
    "                optimizer.step()\n",
    "                ################################################################\n",
    "            else:\n",
    "                outputs_all = []\n",
    "                iter_loss = 0.0\n",
    "                for t in range(TIME):\n",
    "                    ### input[t] --> net --> output_one_time #########################################\n",
    "                    outputs_one_time = net(inputs[t])\n",
    "                    ##################################################################################\n",
    "                    one_time_loss = criterion(outputs_one_time, labels[t].contiguous())\n",
    "                    one_time_loss.backward() # one_time backward\n",
    "                    iter_loss += one_time_loss.data\n",
    "                    outputs_all.append(outputs_one_time.detach())\n",
    "                optimizer.step() # full step time update\n",
    "                outputs_all = torch.stack(outputs_all, dim=1)\n",
    "                outputs = outputs_all.mean(1) # ottt꺼 쓸때\n",
    "                labels = labels[0]\n",
    "                iter_loss /= TIME\n",
    "\n",
    "            tr_epoch_loss_temp += iter_loss.data/len(train_loader)\n",
    "\n",
    "            ## net 그림 출력해보기 #################################################################\n",
    "            # print('시각화')\n",
    "            # make_dot(outputs, params=dict(list(net.named_parameters()))).render(\"net_torchviz\", format=\"png\")\n",
    "            # return 0\n",
    "            ##################################################################################\n",
    "\n",
    "            #### batch 어긋남 방지 ###############################################\n",
    "            assert real_batch == outputs.size(0), f'batch size is not same. real_batch: {real_batch}, outputs.size(0): {outputs.size(0)}'\n",
    "            #######################################################################\n",
    "            \n",
    "\n",
    "            ####### training accruacy save for print ###############################\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total = real_batch\n",
    "            correct = (predicted == labels).sum().item()\n",
    "            iter_acc = correct / total\n",
    "            tr_total += total\n",
    "            tr_correct += correct\n",
    "            iter_acc_string = f'epoch-{epoch:<3} iter_acc:{100 * iter_acc:7.2f}%, lr={[f\"{lr:9.7f}\" for lr in (param_group[\"lr\"] for param_group in optimizer.param_groups)]}'\n",
    "            iter_acc_string2 = f'epoch-{epoch:<3} lr={[f\"{lr:9.7f}\" for lr in (param_group[\"lr\"] for param_group in optimizer.param_groups)]}'\n",
    "            ################################################################\n",
    "            \n",
    "\n",
    "            ##### validation ##################################################################################################################################\n",
    "            if i == len(train_loader)-1 :\n",
    "                iter_of_val = True\n",
    "\n",
    "                tr_acc = tr_correct/tr_total\n",
    "                tr_correct = 0\n",
    "                tr_total = 0\n",
    "\n",
    "                val_loss = 0\n",
    "                correct_val = 0\n",
    "                total_val = 0\n",
    "\n",
    "                with torch.no_grad():\n",
    "                    net.eval() # eval 모드로 바꿔줘야함 \n",
    "                    for data_val in test_loader:\n",
    "                        ## data_val loading & semi-pre-processing ##########################################################\n",
    "                        if len(data_val) == 2:\n",
    "                            inputs_val, labels_val = data_val\n",
    "                        elif len(data_val) == 3:\n",
    "                            inputs_val, labels_val, x_len = data_val\n",
    "                        else:\n",
    "                            assert False, 'data_val length is not 2 or 3'\n",
    "\n",
    "                        if (which_data == 'DVS_CIFAR10' or which_data == 'DVS_GESTURE' or which_data == 'DVS_GESTURE_TONIC' or which_data == 'DVS_CIFAR10_2' or which_data == 'NMNIST' or which_data == 'NMNIST_TONIC' or which_data == 'N_CALTECH101' or which_data == 'n_tidigits' or which_data == 'heidelberg'):\n",
    "                            inputs_val = inputs_val.permute(1, 0, 2, 3, 4)\n",
    "                        elif rate_coding == True :\n",
    "                            inputs_val = spikegen.rate(inputs_val, num_steps=TIME)\n",
    "                        else :\n",
    "                            inputs_val = inputs_val.repeat(TIME, 1, 1, 1, 1)\n",
    "                        # inputs_val: [Time, Batch, Channel, Height, Width]  \n",
    "                        ###################################################################################################\n",
    "\n",
    "                        \n",
    "                        ## initial pooling #######################################################################\n",
    "                        if (initial_pooling > 1):\n",
    "                            pool = nn.MaxPool2d(kernel_size=2)\n",
    "                            num_pooling_layers = int(math.log2(initial_pooling))\n",
    "                            # Time, Batch, Channel 차원은 그대로 두고, Height, Width 차원에 대해서만 pooling 적용\n",
    "                            shape_temp = inputs_val.shape\n",
    "                            inputs_val = inputs_val.reshape(shape_temp[0]*shape_temp[1], shape_temp[2], shape_temp[3], shape_temp[4])\n",
    "                            for _ in range(num_pooling_layers):\n",
    "                                inputs_val = pool(inputs_val)\n",
    "                            inputs_val = inputs_val.reshape(shape_temp[0], shape_temp[1], shape_temp[2], shape_temp[3]//initial_pooling, shape_temp[4]//initial_pooling)\n",
    "                        ## initial pooling #######################################################################\n",
    "\n",
    "                        ## temporal filtering ####################################################################\n",
    "                        shape_temp = inputs_val.shape\n",
    "                        if (temporal_filter > 1):\n",
    "                            slice_bucket = []\n",
    "                            for t_temp in range(TIME):\n",
    "                                start = t_temp * temporal_filter\n",
    "                                end = start + temporal_filter\n",
    "                                slice_concat = torch.movedim(inputs_val[start:end], 0, 1).reshape(shape_temp[1],shape_temp[2],shape_temp[3],-1)\n",
    "                                \n",
    "                                if temporal_filter_accumulation == True:\n",
    "                                    if t_temp == 0:\n",
    "                                        slice_bucket.append(slice_concat)\n",
    "                                    else:\n",
    "                                        slice_bucket.append(slice_concat+slice_bucket[t_temp-1])\n",
    "                                else:\n",
    "                                    slice_bucket.append(slice_concat)\n",
    "\n",
    "                            inputs_val = torch.stack(slice_bucket, dim=0)\n",
    "                            if temporal_filter_accumulation == True and dvs_clipping > 0:\n",
    "                                inputs = (inputs != 0.0).float()\n",
    "                        ## temporal filtering ####################################################################\n",
    "                            \n",
    "                        inputs_val = inputs_val.to(device)\n",
    "                        labels_val = labels_val.to(device)\n",
    "                        real_batch = labels_val.size(0)\n",
    "                        \n",
    "                        if merge_polarities == True:\n",
    "                            inputs_val = inputs_val[:,:,0:1,:,:]\n",
    "\n",
    "                        ## network 연산 시작 ############################################################################################################\n",
    "                        if single_step == False:\n",
    "                            outputs = net(inputs_val.permute(1, 0, 2, 3, 4)) #inputs_val: [Batch, Time, Channel, Height, Width]  \n",
    "                            val_loss += criterion(outputs, labels_val)/len(test_loader)\n",
    "                        else:\n",
    "                            outputs_all = []\n",
    "                            for t in range(TIME):\n",
    "                                outputs = net(inputs_val[t])\n",
    "                                val_loss_temp = criterion(outputs, labels_val)\n",
    "                                outputs_all.append(outputs.detach())\n",
    "                                val_loss += (val_loss_temp.data/TIME)/len(test_loader)\n",
    "                            outputs_all = torch.stack(outputs_all, dim=1)\n",
    "                            outputs = outputs_all.mean(1)\n",
    "                        #################################################################################################################################\n",
    "\n",
    "                        _, predicted = torch.max(outputs.data, 1)\n",
    "                        total_val += real_batch\n",
    "                        assert real_batch == outputs.size(0), f'batch size is not same. real_batch: {real_batch}, outputs.size(0): {outputs.size(0)}'\n",
    "                        correct_val += (predicted == labels_val).sum().item()\n",
    "\n",
    "                    val_acc_now = correct_val / total_val\n",
    "\n",
    "                if val_acc_best < val_acc_now:\n",
    "                    val_acc_best = val_acc_now\n",
    "                    # wandb 키면 state_dict아닌거는 저장 안됨\n",
    "                    # network save\n",
    "                    # torch.save(net.state_dict(), f\"net_save/save_now_net_weights_{unique_name}.pth\")\n",
    "\n",
    "                if tr_acc_best < tr_acc:\n",
    "                    tr_acc_best = tr_acc\n",
    "\n",
    "                tr_epoch_loss = tr_epoch_loss_temp\n",
    "                tr_epoch_loss_temp = 0\n",
    "\n",
    "            ####################################################################################################################################################\n",
    "            \n",
    "            ## progress bar update ############################################################################################################\n",
    "            if iter_of_val == False:\n",
    "                # iterator.set_description(f\"{iter_acc_string}, iter_loss:{iter_loss:10.6f}\") \n",
    "                pass \n",
    "            else:\n",
    "                # iterator.set_description(f\"{iter_acc_string2}, tr/val_loss:{tr_epoch_loss:10.6f}/{val_loss:10.6f}, tr:{100 * tr_acc:7.2f}%, tr_best:{100 * tr_acc_best:7.2f}%, val:{100 * val_acc_now:7.2f}%, val_best:{100 * val_acc_best:7.2f}%\")  \n",
    "                print(f\"{iter_acc_string2}, tr/val_loss:{tr_epoch_loss:10.6f}/{val_loss:10.6f}, val:{100 * val_acc_now:7.2f}%, val_best:{100 * val_acc_best:7.2f}%, tr:{100 * tr_acc:7.2f}%, tr_best:{100 * tr_acc_best:7.2f}%\")\n",
    "                iter_of_val = False\n",
    "            ####################################################################################################################################\n",
    "            \n",
    "            ## wandb logging ############################################################################################################\n",
    "            wandb.log({\"iter_acc\": iter_acc})\n",
    "            wandb.log({\"tr_acc\": tr_acc})\n",
    "            wandb.log({\"val_acc_now\": val_acc_now})\n",
    "            wandb.log({\"val_acc_best\": val_acc_best})\n",
    "            wandb.log({\"summary_val_acc\": val_acc_now})\n",
    "            wandb.log({\"epoch\": epoch})\n",
    "            wandb.log({\"val_loss\": val_loss}) \n",
    "            wandb.log({\"tr_epoch_loss\": tr_epoch_loss})   \n",
    "            ####################################################################################################################################\n",
    "            \n",
    "        ###### ITERATION END ##########################################################################################################\n",
    "\n",
    "        ## scheduler update #############################################################################\n",
    "        if (scheduler_name != 'no'):\n",
    "            if (scheduler_name == 'ReduceLROnPlateau'):\n",
    "                scheduler.step(val_loss)\n",
    "            else:\n",
    "                scheduler.step()\n",
    "        #################################################################################################\n",
    "        \n",
    "    #======== EPOCH END ==========================================================================================\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# unique_name = 'main' ## 이거 설정하면 새로운 경로에 모두 save\n",
    "# wandb.init(project= f'my_snn {unique_name}',save_code=False, dir='/data2/bh_wandb', tags=[\"common\"])\n",
    "# ## wandb 과거 하이퍼파라미터 가져와서 붙여넣기 (devices unique_name은 니가 할당해라)#################################\n",
    "# param = {'devices': '3', 'single_step': True, 'unique_name': 'main', 'my_seed': 42, 'TIME': 10, 'BATCH': 16, 'IMAGE_SIZE': 128, 'which_data': 'DVS_GESTURE_TONIC', 'data_path': '/data2', 'rate_coding': False, 'lif_layer_v_init': 0, 'lif_layer_v_decay': 0.25, 'lif_layer_v_threshold': 0.75, 'lif_layer_v_reset': 0, 'lif_layer_sg_width': 4, 'synapse_conv_kernel_size': 3, 'synapse_conv_stride': 1, 'synapse_conv_padding': 1, 'synapse_trace_const1': 1, 'synapse_trace_const2': 0, 'pre_trained': False, 'convTrue_fcFalse': False, 'cfg': [200, 200], 'net_print': True, 'pre_trained_path': 'net_save/save_now_net_weights_{unique_name}.pth', 'learning_rate': 0.001, 'epoch_num': 100, 'tdBN_on': False, 'BN_on': False, 'surrogate': 'hard_sigmoid', 'BPTT_on': False, 'optimizer_what': 'SGD', 'scheduler_name': 'no', 'ddp_on': False, 'dvs_clipping': 2, 'dvs_duration': 25000, 'DFA_on': True, 'trace_on': True, 'OTTT_input_trace_on': False, 'exclude_class': True, 'merge_polarities': False, 'denoise_on': True, 'extra_train_dataset': 0, 'num_workers': 2, 'chaching_on': True, 'pin_memory': True, 'UDA_on': False, 'alpha_uda': 1, 'bias': True, 'last_lif': False, 'temporal_filter': 5, 'initial_pooling': 8}\n",
    "# my_snn_system(devices = '0',single_step = param['single_step'],unique_name = unique_name,my_seed = param['my_seed'],TIME = param['TIME'],BATCH = param['BATCH'],IMAGE_SIZE = param['IMAGE_SIZE'],which_data = param['which_data'],data_path = param['data_path'],rate_coding = param['rate_coding'],lif_layer_v_init = param['lif_layer_v_init'],lif_layer_v_decay = param['lif_layer_v_decay'],lif_layer_v_threshold = param['lif_layer_v_threshold'],lif_layer_v_reset = param['lif_layer_v_reset'],lif_layer_sg_width = param['lif_layer_sg_width'],synapse_conv_kernel_size = param['synapse_conv_kernel_size'],synapse_conv_stride = param['synapse_conv_stride'],synapse_conv_padding = param['synapse_conv_padding'],synapse_trace_const1 = param['synapse_trace_const1'],synapse_trace_const2 = param['synapse_trace_const2'],pre_trained = param['pre_trained'],convTrue_fcFalse = param['convTrue_fcFalse'],cfg = param['cfg'],net_print = param['net_print'],pre_trained_path = param['pre_trained_path'],learning_rate = param['learning_rate'],epoch_num = param['epoch_num'],tdBN_on = param['tdBN_on'],BN_on = param['BN_on'],surrogate = param['surrogate'],BPTT_on = param['BPTT_on'],optimizer_what = param['optimizer_what'],scheduler_name = param['scheduler_name'],ddp_on = param['ddp_on'],dvs_clipping = param['dvs_clipping'],dvs_duration = param['dvs_duration'],DFA_on = param['DFA_on'],trace_on = param['trace_on'],OTTT_input_trace_on = param['OTTT_input_trace_on'],exclude_class = param['exclude_class'],merge_polarities = param['merge_polarities'],denoise_on = param['denoise_on'],extra_train_dataset = param['extra_train_dataset'],num_workers = param['num_workers'],chaching_on = param['chaching_on'],pin_memory = param['pin_memory'],UDA_on = param['UDA_on'],alpha_uda = param['alpha_uda'],bias = param['bias'],last_lif = param['last_lif'],temporal_filter = param['temporal_filter'],initial_pooling = param['initial_pooling'],temporal_filter_accumulation= param['temporal_filter_accumulation'])\n",
    "# #############################################################################\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mbhkim003\u001b[0m (\u001b[33mbhkim003-seoul-national-university\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.19.11 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.17.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/data2/bh_wandb/wandb/run-20250512_222000-lyqx484g</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/lyqx484g' target=\"_blank\">super-glitter-8391</a></strong> to <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/lyqx484g' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/lyqx484g</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "param {'devices': '2', 'single_step': True, 'unique_name': 'main', 'my_seed': 42, 'TIME': 10, 'BATCH': 16, 'IMAGE_SIZE': 17, 'which_data': 'NMNIST_TONIC', 'data_path': '/data2', 'rate_coding': False, 'lif_layer_v_init': 0.0, 'lif_layer_v_decay': 0.5, 'lif_layer_v_threshold': 0.5, 'lif_layer_v_reset': 10000.0, 'lif_layer_sg_width': 4.0, 'synapse_conv_kernel_size': 3, 'synapse_conv_stride': 1, 'synapse_conv_padding': 1, 'synapse_trace_const1': 1, 'synapse_trace_const2': 0.5, 'pre_trained': False, 'convTrue_fcFalse': False, 'cfg': [200, 200], 'net_print': True, 'pre_trained_path': 'net_save/save_now_net_weights_main.pth', 'learning_rate': 0.01, 'epoch_num': 10000, 'tdBN_on': False, 'BN_on': False, 'surrogate': 'hard_sigmoid', 'BPTT_on': False, 'optimizer_what': 'SGD', 'scheduler_name': 'no', 'ddp_on': False, 'dvs_clipping': 1, 'dvs_duration': 5000, 'DFA_on': True, 'trace_on': False, 'OTTT_input_trace_on': False, 'exclude_class': True, 'merge_polarities': False, 'denoise_on': False, 'extra_train_dataset': 0, 'num_workers': 2, 'chaching_on': True, 'pin_memory': True, 'UDA_on': False, 'alpha_uda': 1.0, 'bias': True, 'last_lif': False, 'temporal_filter': 1, 'initial_pooling': 1, 'temporal_filter_accumulation': False} \n",
      "\n",
      "dataset_hash = 7b0583c2e220caca87b64bcaac63adf4\n",
      "cache path exists\n",
      "\n",
      "len(train_loader): 3750 BATCH: 16 train_data_count: 60000\n",
      "len(test_loader): 625 BATCH: 16\n",
      "\n",
      "device ==> cuda\n",
      "\n",
      "DataParallel(\n",
      "  (module): REBORN_MY_SNN_FC(\n",
      "    (layers): REBORN_MY_Sequential(\n",
      "      (0): DimChanger_for_FC()\n",
      "      (1): Shaker_for_FC()\n",
      "      (2): Sparsity_Checker()\n",
      "      (3): SYNAPSE_FC(in_features=578, out_features=200, TIME=10, bias=True, sstep=True, time_different_weight=False)\n",
      "      (4): LIF_layer(v_init=0.0, v_decay=0.5, v_threshold=0.5, v_reset=10000.0, sg_width=4.0, surrogate=hard_sigmoid, BPTT_on=False, trace_const1=1, trace_const2=0.5, TIME=10, sstep=True, trace_on=False)\n",
      "      (5): Sparsity_Checker()\n",
      "      (6): Feedback_Receiver()\n",
      "      (7): SYNAPSE_FC(in_features=200, out_features=200, TIME=10, bias=True, sstep=True, time_different_weight=False)\n",
      "      (8): LIF_layer(v_init=0.0, v_decay=0.5, v_threshold=0.5, v_reset=10000.0, sg_width=4.0, surrogate=hard_sigmoid, BPTT_on=False, trace_const1=1, trace_const2=0.5, TIME=10, sstep=True, trace_on=False)\n",
      "      (9): Sparsity_Checker()\n",
      "      (10): Feedback_Receiver()\n",
      "      (11): SYNAPSE_FC(in_features=200, out_features=10, TIME=10, bias=True, sstep=True, time_different_weight=False)\n",
      "      (DFA_top): Top_Gradient()\n",
      "    )\n",
      "  )\n",
      ")\n",
      "\n",
      "========================================================\n",
      "Trainable parameters: 158,010\n",
      "========================================================\n",
      "\n",
      "current loss function: CustomCriterion()\n",
      "self.perm fc input 처음에 한번 섞기 tensor([575, 370,  61, 417, 461,  13, 521, 431, 548, 388, 477, 324, 235,  75,\n",
      "          4, 257,  81, 220, 328, 313, 274, 382, 334, 558,  35, 518, 482,  79,\n",
      "        133,  21, 171, 510, 389, 112, 159, 246, 507, 150, 437,  85, 287,  20,\n",
      "        418, 529, 394, 142, 503, 368,  32, 443, 156, 376, 110,  58, 128, 564,\n",
      "          5, 190, 309, 113, 407, 260, 547, 264,  94, 367, 141, 327, 341, 188,\n",
      "        253, 255, 364, 291,  25, 230,  89, 530, 285, 557,  82, 381, 138,  30,\n",
      "        252, 233, 353, 129, 254, 148, 210, 192, 100,  98, 321,  49, 377, 472,\n",
      "        345,  84, 225, 224, 245, 532, 490, 419, 447, 320, 372, 244, 184, 556,\n",
      "        359, 476, 214,   9, 237, 401, 467, 475, 474, 272, 132, 378, 549, 319,\n",
      "        135,  39, 436,  83, 312, 217, 271, 115, 293, 294, 373, 512, 536, 303,\n",
      "        131, 329, 535,  95, 404, 124, 123, 152, 109, 365, 533, 164, 116, 470,\n",
      "        339, 420, 178, 433, 351, 179,  40, 400, 390, 374,  72, 519, 356, 360,\n",
      "        538, 333, 411, 495,  41,  31,  69, 180, 465, 523, 207, 487, 396, 120,\n",
      "        391, 157, 173, 403, 386, 452, 511, 101, 406, 137, 182,  54, 163, 570,\n",
      "        338, 122, 145, 554, 185, 460, 405,  18, 261, 162, 302, 308, 453,   0,\n",
      "        144, 170, 198, 295, 161,  53,  73, 416,  46, 429, 169, 238, 402, 296,\n",
      "        380, 542, 540, 277, 514, 323, 301,  86, 565, 304, 577,  14, 143, 183,\n",
      "         63, 107, 212, 481, 213,  67, 573, 500, 286, 165, 290, 488,  88, 263,\n",
      "        218,  55, 493, 130, 197, 517, 205, 454,  59,   7, 392, 236, 262, 223,\n",
      "        240, 397, 119, 196, 114, 219, 318, 527, 459, 444,  93, 395, 408, 498,\n",
      "        151, 340, 464, 506, 509,  78,  70, 572, 221,  16, 562,  50, 479, 438,\n",
      "        208, 516,  36,  57, 200, 355,  91,  77, 243, 149, 485, 496, 568, 242,\n",
      "        469, 344, 106, 247, 471, 410, 413,  87, 352,   3, 393, 421, 231,  60,\n",
      "        189, 449,  38, 428, 357, 571,  19, 204, 227, 450, 520, 480, 504, 102,\n",
      "        435, 307, 335, 256, 222, 160,   1, 300, 515,  37, 288,  71, 306, 187,\n",
      "        125, 127, 531, 325, 385, 158, 379, 134,  48, 502, 166, 362,  90, 346,\n",
      "        154, 281, 473, 282, 167,  96, 349,  51, 269,  92, 422, 528, 425,  12,\n",
      "         42, 215, 267,  45, 276, 489, 491, 525, 427, 140,  26, 463, 442,  74,\n",
      "         64, 193, 441, 383, 455,   8, 458, 492, 387, 248, 409, 350, 358, 155,\n",
      "        546, 366,  97, 551, 423, 239,  52, 228, 118,  15,  47, 560, 117, 424,\n",
      "        567, 194, 168, 203,  66, 147, 172, 146, 501,  10, 279, 111, 268, 559,\n",
      "        175, 305, 211, 466,  62,  29, 299, 251, 297, 315, 311, 229, 484, 298,\n",
      "        177, 258, 539, 412, 348, 289, 426, 513, 216, 226, 555, 524, 398, 432,\n",
      "        552, 576, 434, 314, 105, 440, 574, 266,  33, 363, 316, 202, 280,  80,\n",
      "        522, 181, 278, 273, 139, 136,   6, 292, 354, 526,  17, 445, 462, 326,\n",
      "        250,  44, 486, 553, 569, 369, 561, 259, 494,  43, 439, 265, 195, 176,\n",
      "         68, 201, 284,  24, 121, 347,  65,  99, 343, 283, 241, 566, 322, 317,\n",
      "        104, 545, 103, 457,  27, 478, 199, 505, 483,  34, 234, 499, 275, 126,\n",
      "        310,  22,  56, 361, 537, 430, 249, 543, 451, 191, 534, 174, 497, 544,\n",
      "        186, 206, 508, 337, 108,   2, 541, 384, 371, 330, 375, 456, 414, 550,\n",
      "        336, 331, 232, 209, 270,  76,  11, 342, 415, 446, 332, 448,  28, 399,\n",
      "        563, 153,  23, 468], device='cuda:0')\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch-0   lr=['0.0100000'], tr/val_loss:24519.072266/35222.550781, val:  10.32%, val_best:  10.32%, tr:   9.99%, tr_best:   9.99%\n",
      "[module.layers.6] weight_fb parameter count: 2,000\n",
      "[module.layers.10] weight_fb parameter count: 2,000\n",
      "epoch-1   lr=['0.0100000'], tr/val_loss:24198.472656/50580.316406, val:   8.92%, val_best:  10.32%, tr:   9.97%, tr_best:   9.99%\n",
      "epoch-2   lr=['0.0100000'], tr/val_loss:24738.369141/20201.619141, val:   8.92%, val_best:  10.32%, tr:  10.21%, tr_best:  10.21%\n",
      "epoch-3   lr=['0.0100000'], tr/val_loss:25466.283203/37108.269531, val:  10.10%, val_best:  10.32%, tr:   9.99%, tr_best:  10.21%\n",
      "epoch-4   lr=['0.0100000'], tr/val_loss:25455.416016/56293.722656, val:   9.80%, val_best:  10.32%, tr:  10.17%, tr_best:  10.21%\n",
      "epoch-5   lr=['0.0100000'], tr/val_loss:24112.496094/44865.074219, val:  10.32%, val_best:  10.32%, tr:  10.08%, tr_best:  10.21%\n",
      "epoch-6   lr=['0.0100000'], tr/val_loss:23246.058594/6044.358887, val:  10.28%, val_best:  10.32%, tr:  10.29%, tr_best:  10.29%\n",
      "epoch-7   lr=['0.0100000'], tr/val_loss:24418.474609/9867.490234, val:   9.80%, val_best:  10.32%, tr:   9.79%, tr_best:  10.29%\n",
      "epoch-8   lr=['0.0100000'], tr/val_loss:25374.378906/50280.980469, val:  10.28%, val_best:  10.32%, tr:   9.80%, tr_best:  10.29%\n",
      "epoch-9   lr=['0.0100000'], tr/val_loss:24407.298828/39013.644531, val:   9.80%, val_best:  10.32%, tr:  10.32%, tr_best:  10.32%\n",
      "epoch-10  lr=['0.0100000'], tr/val_loss:24497.871094/26228.814453, val:  10.28%, val_best:  10.32%, tr:   9.79%, tr_best:  10.32%\n",
      "epoch-11  lr=['0.0100000'], tr/val_loss:23837.599609/3663.239258, val:  10.28%, val_best:  10.32%, tr:   9.96%, tr_best:  10.32%\n",
      "epoch-12  lr=['0.0100000'], tr/val_loss:24808.494141/15361.116211, val:   9.58%, val_best:  10.32%, tr:   9.70%, tr_best:  10.32%\n",
      "epoch-13  lr=['0.0100000'], tr/val_loss:25040.386719/26238.990234, val:  10.32%, val_best:  10.32%, tr:   9.92%, tr_best:  10.32%\n",
      "epoch-14  lr=['0.0100000'], tr/val_loss:25254.611328/36013.558594, val:   9.82%, val_best:  10.32%, tr:   9.96%, tr_best:  10.32%\n",
      "epoch-15  lr=['0.0100000'], tr/val_loss:24683.763672/36561.222656, val:   8.92%, val_best:  10.32%, tr:   9.91%, tr_best:  10.32%\n",
      "epoch-16  lr=['0.0100000'], tr/val_loss:24168.783203/19482.640625, val:  10.32%, val_best:  10.32%, tr:   9.85%, tr_best:  10.32%\n",
      "epoch-17  lr=['0.0100000'], tr/val_loss:26782.259766/24894.173828, val:   8.92%, val_best:  10.32%, tr:  10.04%, tr_best:  10.32%\n",
      "epoch-18  lr=['0.0100000'], tr/val_loss:25073.652344/10754.132812, val:  10.09%, val_best:  10.32%, tr:  10.14%, tr_best:  10.32%\n",
      "epoch-19  lr=['0.0100000'], tr/val_loss:26646.410156/5175.141113, val:   8.92%, val_best:  10.32%, tr:   9.96%, tr_best:  10.32%\n",
      "epoch-20  lr=['0.0100000'], tr/val_loss:23884.228516/7452.319824, val:  10.09%, val_best:  10.32%, tr:  10.03%, tr_best:  10.32%\n",
      "epoch-21  lr=['0.0100000'], tr/val_loss:23563.109375/37403.851562, val:   8.92%, val_best:  10.32%, tr:  10.23%, tr_best:  10.32%\n",
      "epoch-22  lr=['0.0100000'], tr/val_loss:26018.667969/21085.781250, val:  10.10%, val_best:  10.32%, tr:  10.00%, tr_best:  10.32%\n",
      "epoch-23  lr=['0.0100000'], tr/val_loss:26714.310547/27653.513672, val:  10.09%, val_best:  10.32%, tr:   9.78%, tr_best:  10.32%\n",
      "epoch-24  lr=['0.0100000'], tr/val_loss:25899.457031/20829.701172, val:  10.32%, val_best:  10.32%, tr:  10.22%, tr_best:  10.32%\n",
      "epoch-25  lr=['0.0100000'], tr/val_loss:26006.833984/38994.832031, val:   8.92%, val_best:  10.32%, tr:   9.99%, tr_best:  10.32%\n",
      "epoch-26  lr=['0.0100000'], tr/val_loss:24000.521484/25775.429688, val:   9.80%, val_best:  10.32%, tr:   9.95%, tr_best:  10.32%\n",
      "epoch-27  lr=['0.0100000'], tr/val_loss:25528.843750/15145.009766, val:  10.09%, val_best:  10.32%, tr:   9.94%, tr_best:  10.32%\n",
      "epoch-28  lr=['0.0100000'], tr/val_loss:26025.972656/38089.218750, val:   9.74%, val_best:  10.32%, tr:  10.15%, tr_best:  10.32%\n",
      "epoch-29  lr=['0.0100000'], tr/val_loss:24272.191406/30364.933594, val:  10.28%, val_best:  10.32%, tr:   9.93%, tr_best:  10.32%\n",
      "epoch-30  lr=['0.0100000'], tr/val_loss:24829.982422/28950.302734, val:  10.10%, val_best:  10.32%, tr:  10.13%, tr_best:  10.32%\n",
      "epoch-31  lr=['0.0100000'], tr/val_loss:25200.814453/13849.488281, val:  10.32%, val_best:  10.32%, tr:  10.13%, tr_best:  10.32%\n",
      "epoch-32  lr=['0.0100000'], tr/val_loss:24832.253906/32675.675781, val:  10.09%, val_best:  10.32%, tr:  10.13%, tr_best:  10.32%\n",
      "epoch-33  lr=['0.0100000'], tr/val_loss:24744.130859/26802.859375, val:   9.74%, val_best:  10.32%, tr:  10.16%, tr_best:  10.32%\n",
      "epoch-34  lr=['0.0100000'], tr/val_loss:26316.589844/17804.708984, val:  11.35%, val_best:  11.35%, tr:  10.00%, tr_best:  10.32%\n",
      "epoch-35  lr=['0.0100000'], tr/val_loss:23427.576172/37105.382812, val:   9.74%, val_best:  11.35%, tr:  10.18%, tr_best:  10.32%\n",
      "epoch-36  lr=['0.0100000'], tr/val_loss:25251.322266/62437.792969, val:  10.10%, val_best:  11.35%, tr:  10.04%, tr_best:  10.32%\n",
      "epoch-37  lr=['0.0100000'], tr/val_loss:26346.222656/9756.386719, val:  10.09%, val_best:  11.35%, tr:  10.20%, tr_best:  10.32%\n",
      "epoch-38  lr=['0.0100000'], tr/val_loss:25431.318359/26133.568359, val:   9.58%, val_best:  11.35%, tr:   9.72%, tr_best:  10.32%\n",
      "epoch-39  lr=['0.0100000'], tr/val_loss:25531.794922/46073.191406, val:   9.82%, val_best:  11.35%, tr:  10.17%, tr_best:  10.32%\n",
      "epoch-40  lr=['0.0100000'], tr/val_loss:28090.328125/22160.964844, val:  10.09%, val_best:  11.35%, tr:   9.85%, tr_best:  10.32%\n",
      "epoch-41  lr=['0.0100000'], tr/val_loss:25556.494141/43294.894531, val:  10.32%, val_best:  11.35%, tr:   9.71%, tr_best:  10.32%\n",
      "epoch-42  lr=['0.0100000'], tr/val_loss:26025.832031/13174.016602, val:  10.09%, val_best:  11.35%, tr:  10.05%, tr_best:  10.32%\n",
      "epoch-43  lr=['0.0100000'], tr/val_loss:26631.263672/15149.104492, val:  10.28%, val_best:  11.35%, tr:  10.03%, tr_best:  10.32%\n",
      "epoch-44  lr=['0.0100000'], tr/val_loss:24518.476562/15442.666016, val:   8.92%, val_best:  11.35%, tr:  10.16%, tr_best:  10.32%\n",
      "epoch-45  lr=['0.0100000'], tr/val_loss:24456.212891/20884.126953, val:  10.10%, val_best:  11.35%, tr:  10.05%, tr_best:  10.32%\n",
      "epoch-46  lr=['0.0100000'], tr/val_loss:25448.105469/20629.458984, val:   9.58%, val_best:  11.35%, tr:  10.18%, tr_best:  10.32%\n",
      "epoch-47  lr=['0.0100000'], tr/val_loss:27079.150391/16523.859375, val:   9.74%, val_best:  11.35%, tr:  10.08%, tr_best:  10.32%\n",
      "epoch-48  lr=['0.0100000'], tr/val_loss:26231.095703/11356.699219, val:  10.09%, val_best:  11.35%, tr:   9.90%, tr_best:  10.32%\n",
      "epoch-49  lr=['0.0100000'], tr/val_loss:24623.931641/50858.449219, val:  10.09%, val_best:  11.35%, tr:   9.89%, tr_best:  10.32%\n",
      "epoch-50  lr=['0.0100000'], tr/val_loss:25880.642578/77938.382812, val:   9.58%, val_best:  11.35%, tr:  10.14%, tr_best:  10.32%\n",
      "epoch-51  lr=['0.0100000'], tr/val_loss:25332.279297/15820.536133, val:   9.82%, val_best:  11.35%, tr:   9.85%, tr_best:  10.32%\n",
      "epoch-52  lr=['0.0100000'], tr/val_loss:25514.767578/28513.126953, val:   9.80%, val_best:  11.35%, tr:  10.02%, tr_best:  10.32%\n",
      "epoch-53  lr=['0.0100000'], tr/val_loss:27213.132812/16971.527344, val:  10.09%, val_best:  11.35%, tr:   9.98%, tr_best:  10.32%\n",
      "epoch-54  lr=['0.0100000'], tr/val_loss:25255.970703/34504.910156, val:   9.74%, val_best:  11.35%, tr:  10.13%, tr_best:  10.32%\n",
      "epoch-55  lr=['0.0100000'], tr/val_loss:28490.601562/23816.517578, val:   9.80%, val_best:  11.35%, tr:   9.88%, tr_best:  10.32%\n",
      "epoch-56  lr=['0.0100000'], tr/val_loss:26928.365234/31617.164062, val:   9.82%, val_best:  11.35%, tr:  10.15%, tr_best:  10.32%\n",
      "epoch-57  lr=['0.0100000'], tr/val_loss:25537.091797/21876.628906, val:  10.32%, val_best:  11.35%, tr:  10.08%, tr_best:  10.32%\n",
      "epoch-58  lr=['0.0100000'], tr/val_loss:24414.857422/52371.480469, val:  10.28%, val_best:  11.35%, tr:   9.80%, tr_best:  10.32%\n",
      "epoch-59  lr=['0.0100000'], tr/val_loss:26958.650391/46171.957031, val:   8.92%, val_best:  11.35%, tr:  10.09%, tr_best:  10.32%\n",
      "epoch-60  lr=['0.0100000'], tr/val_loss:25823.140625/25312.175781, val:   9.74%, val_best:  11.35%, tr:  10.02%, tr_best:  10.32%\n",
      "epoch-61  lr=['0.0100000'], tr/val_loss:27306.839844/28025.947266, val:  11.35%, val_best:  11.35%, tr:  10.11%, tr_best:  10.32%\n",
      "epoch-62  lr=['0.0100000'], tr/val_loss:25084.226562/20302.865234, val:   9.80%, val_best:  11.35%, tr:  10.07%, tr_best:  10.32%\n",
      "epoch-63  lr=['0.0100000'], tr/val_loss:24715.482422/8868.375977, val:  10.32%, val_best:  11.35%, tr:   9.80%, tr_best:  10.32%\n",
      "epoch-64  lr=['0.0100000'], tr/val_loss:27161.060547/11439.497070, val:  10.28%, val_best:  11.35%, tr:  10.01%, tr_best:  10.32%\n",
      "epoch-65  lr=['0.0100000'], tr/val_loss:27592.390625/14280.418945, val:   9.74%, val_best:  11.35%, tr:  10.05%, tr_best:  10.32%\n",
      "epoch-66  lr=['0.0100000'], tr/val_loss:25330.880859/28796.492188, val:  10.10%, val_best:  11.35%, tr:   9.80%, tr_best:  10.32%\n",
      "epoch-67  lr=['0.0100000'], tr/val_loss:26308.978516/6590.833496, val:  10.10%, val_best:  11.35%, tr:   9.83%, tr_best:  10.32%\n",
      "epoch-68  lr=['0.0100000'], tr/val_loss:25495.523438/24439.044922, val:   9.82%, val_best:  11.35%, tr:  10.01%, tr_best:  10.32%\n",
      "epoch-69  lr=['0.0100000'], tr/val_loss:24860.250000/24831.673828, val:   9.74%, val_best:  11.35%, tr:   9.90%, tr_best:  10.32%\n",
      "epoch-70  lr=['0.0100000'], tr/val_loss:23828.664062/30752.628906, val:  10.28%, val_best:  11.35%, tr:   9.94%, tr_best:  10.32%\n",
      "epoch-71  lr=['0.0100000'], tr/val_loss:26313.103516/11552.465820, val:   9.82%, val_best:  11.35%, tr:  10.02%, tr_best:  10.32%\n",
      "epoch-72  lr=['0.0100000'], tr/val_loss:26100.263672/8762.499023, val:   9.80%, val_best:  11.35%, tr:  10.03%, tr_best:  10.32%\n",
      "epoch-73  lr=['0.0100000'], tr/val_loss:24307.902344/44846.621094, val:  10.09%, val_best:  11.35%, tr:   9.99%, tr_best:  10.32%\n",
      "epoch-74  lr=['0.0100000'], tr/val_loss:24964.658203/36544.769531, val:  11.35%, val_best:  11.35%, tr:   9.92%, tr_best:  10.32%\n",
      "epoch-75  lr=['0.0100000'], tr/val_loss:25503.673828/26648.365234, val:   9.74%, val_best:  11.35%, tr:   9.95%, tr_best:  10.32%\n",
      "epoch-76  lr=['0.0100000'], tr/val_loss:25782.845703/14784.967773, val:   9.82%, val_best:  11.35%, tr:  10.06%, tr_best:  10.32%\n",
      "epoch-77  lr=['0.0100000'], tr/val_loss:25132.857422/18683.896484, val:  10.32%, val_best:  11.35%, tr:   9.73%, tr_best:  10.32%\n",
      "epoch-78  lr=['0.0100000'], tr/val_loss:26180.832031/9858.696289, val:  10.09%, val_best:  11.35%, tr:   9.95%, tr_best:  10.32%\n",
      "epoch-79  lr=['0.0100000'], tr/val_loss:25091.220703/21586.091797, val:   9.82%, val_best:  11.35%, tr:   9.79%, tr_best:  10.32%\n",
      "epoch-80  lr=['0.0100000'], tr/val_loss:24379.294922/14760.328125, val:   9.82%, val_best:  11.35%, tr:  10.12%, tr_best:  10.32%\n",
      "epoch-81  lr=['0.0100000'], tr/val_loss:26311.830078/14661.611328, val:   9.82%, val_best:  11.35%, tr:   9.91%, tr_best:  10.32%\n",
      "epoch-82  lr=['0.0100000'], tr/val_loss:24587.238281/24068.837891, val:  10.28%, val_best:  11.35%, tr:   9.94%, tr_best:  10.32%\n",
      "epoch-83  lr=['0.0100000'], tr/val_loss:25677.968750/6761.328613, val:  10.09%, val_best:  11.35%, tr:  10.04%, tr_best:  10.32%\n",
      "epoch-84  lr=['0.0100000'], tr/val_loss:26049.199219/15400.918945, val:  10.28%, val_best:  11.35%, tr:  10.22%, tr_best:  10.32%\n",
      "epoch-85  lr=['0.0100000'], tr/val_loss:25633.019531/13660.449219, val:   9.82%, val_best:  11.35%, tr:  10.10%, tr_best:  10.32%\n",
      "epoch-86  lr=['0.0100000'], tr/val_loss:25991.691406/15936.916016, val:   9.58%, val_best:  11.35%, tr:   9.89%, tr_best:  10.32%\n",
      "epoch-87  lr=['0.0100000'], tr/val_loss:26191.353516/45309.523438, val:   8.92%, val_best:  11.35%, tr:  10.03%, tr_best:  10.32%\n",
      "epoch-88  lr=['0.0100000'], tr/val_loss:27726.683594/9124.864258, val:   8.92%, val_best:  11.35%, tr:  10.14%, tr_best:  10.32%\n",
      "epoch-89  lr=['0.0100000'], tr/val_loss:26021.173828/21557.544922, val:   9.74%, val_best:  11.35%, tr:  10.11%, tr_best:  10.32%\n",
      "epoch-90  lr=['0.0100000'], tr/val_loss:26628.511719/11203.426758, val:  10.32%, val_best:  11.35%, tr:  10.17%, tr_best:  10.32%\n",
      "epoch-91  lr=['0.0100000'], tr/val_loss:25424.914062/4941.950195, val:   9.74%, val_best:  11.35%, tr:   9.99%, tr_best:  10.32%\n",
      "epoch-92  lr=['0.0100000'], tr/val_loss:26168.390625/18793.210938, val:   9.58%, val_best:  11.35%, tr:  10.05%, tr_best:  10.32%\n",
      "epoch-93  lr=['0.0100000'], tr/val_loss:25542.664062/20908.785156, val:  11.35%, val_best:  11.35%, tr:  10.17%, tr_best:  10.32%\n",
      "epoch-94  lr=['0.0100000'], tr/val_loss:26585.978516/39931.625000, val:   9.58%, val_best:  11.35%, tr:  10.08%, tr_best:  10.32%\n",
      "epoch-95  lr=['0.0100000'], tr/val_loss:25739.181641/17231.472656, val:   9.82%, val_best:  11.35%, tr:   9.89%, tr_best:  10.32%\n",
      "epoch-96  lr=['0.0100000'], tr/val_loss:25518.009766/26020.548828, val:   9.58%, val_best:  11.35%, tr:   9.96%, tr_best:  10.32%\n",
      "epoch-97  lr=['0.0100000'], tr/val_loss:25989.326172/5705.920410, val:  10.32%, val_best:  11.35%, tr:   9.80%, tr_best:  10.32%\n",
      "epoch-98  lr=['0.0100000'], tr/val_loss:26014.826172/32108.882812, val:  10.10%, val_best:  11.35%, tr:   9.93%, tr_best:  10.32%\n",
      "epoch-99  lr=['0.0100000'], tr/val_loss:27738.851562/69568.601562, val:  10.09%, val_best:  11.35%, tr:  10.05%, tr_best:  10.32%\n",
      "epoch-100 lr=['0.0100000'], tr/val_loss:25752.802734/38096.429688, val:   9.80%, val_best:  11.35%, tr:   9.88%, tr_best:  10.32%\n",
      "epoch-101 lr=['0.0100000'], tr/val_loss:25013.099609/13687.500977, val:   8.92%, val_best:  11.35%, tr:  10.05%, tr_best:  10.32%\n",
      "epoch-102 lr=['0.0100000'], tr/val_loss:25300.130859/18254.785156, val:   9.82%, val_best:  11.35%, tr:  10.08%, tr_best:  10.32%\n",
      "epoch-103 lr=['0.0100000'], tr/val_loss:24876.972656/11421.536133, val:   9.82%, val_best:  11.35%, tr:   9.83%, tr_best:  10.32%\n",
      "epoch-104 lr=['0.0100000'], tr/val_loss:25525.777344/28396.875000, val:   9.80%, val_best:  11.35%, tr:  10.10%, tr_best:  10.32%\n",
      "epoch-105 lr=['0.0100000'], tr/val_loss:25521.154297/36532.113281, val:  10.28%, val_best:  11.35%, tr:   9.89%, tr_best:  10.32%\n",
      "epoch-106 lr=['0.0100000'], tr/val_loss:27252.781250/34109.296875, val:  10.10%, val_best:  11.35%, tr:  10.12%, tr_best:  10.32%\n",
      "epoch-107 lr=['0.0100000'], tr/val_loss:25284.167969/23119.992188, val:   8.92%, val_best:  11.35%, tr:   9.80%, tr_best:  10.32%\n",
      "epoch-108 lr=['0.0100000'], tr/val_loss:25881.240234/59858.824219, val:  11.35%, val_best:  11.35%, tr:   9.92%, tr_best:  10.32%\n",
      "epoch-109 lr=['0.0100000'], tr/val_loss:26211.726562/24363.548828, val:  10.28%, val_best:  11.35%, tr:   9.88%, tr_best:  10.32%\n",
      "epoch-110 lr=['0.0100000'], tr/val_loss:26868.353516/53807.738281, val:   9.80%, val_best:  11.35%, tr:   9.86%, tr_best:  10.32%\n",
      "epoch-111 lr=['0.0100000'], tr/val_loss:26339.111328/10517.633789, val:   9.74%, val_best:  11.35%, tr:  10.14%, tr_best:  10.32%\n",
      "epoch-112 lr=['0.0100000'], tr/val_loss:26550.386719/32864.101562, val:  10.32%, val_best:  11.35%, tr:   9.93%, tr_best:  10.32%\n",
      "epoch-113 lr=['0.0100000'], tr/val_loss:26363.400391/28513.683594, val:  10.28%, val_best:  11.35%, tr:   9.73%, tr_best:  10.32%\n",
      "epoch-114 lr=['0.0100000'], tr/val_loss:24581.759766/46405.238281, val:   9.58%, val_best:  11.35%, tr:  10.01%, tr_best:  10.32%\n",
      "epoch-115 lr=['0.0100000'], tr/val_loss:25974.117188/74944.742188, val:  10.09%, val_best:  11.35%, tr:   9.86%, tr_best:  10.32%\n",
      "epoch-116 lr=['0.0100000'], tr/val_loss:25813.261719/20323.812500, val:  10.32%, val_best:  11.35%, tr:  10.03%, tr_best:  10.32%\n",
      "epoch-117 lr=['0.0100000'], tr/val_loss:26589.582031/11332.258789, val:  10.32%, val_best:  11.35%, tr:  10.19%, tr_best:  10.32%\n",
      "epoch-118 lr=['0.0100000'], tr/val_loss:25369.050781/35195.488281, val:   9.82%, val_best:  11.35%, tr:  10.14%, tr_best:  10.32%\n",
      "epoch-119 lr=['0.0100000'], tr/val_loss:26166.205078/24159.736328, val:  10.10%, val_best:  11.35%, tr:   9.82%, tr_best:  10.32%\n",
      "epoch-120 lr=['0.0100000'], tr/val_loss:26568.820312/40146.917969, val:   9.82%, val_best:  11.35%, tr:  10.01%, tr_best:  10.32%\n",
      "epoch-121 lr=['0.0100000'], tr/val_loss:26855.271484/30618.187500, val:  10.32%, val_best:  11.35%, tr:   9.79%, tr_best:  10.32%\n",
      "epoch-122 lr=['0.0100000'], tr/val_loss:25776.501953/25392.628906, val:  10.10%, val_best:  11.35%, tr:  10.20%, tr_best:  10.32%\n",
      "epoch-123 lr=['0.0100000'], tr/val_loss:27442.822266/34460.523438, val:   9.58%, val_best:  11.35%, tr:  10.26%, tr_best:  10.32%\n",
      "epoch-124 lr=['0.0100000'], tr/val_loss:25220.128906/6269.153809, val:   9.80%, val_best:  11.35%, tr:  10.10%, tr_best:  10.32%\n",
      "epoch-125 lr=['0.0100000'], tr/val_loss:25817.902344/19102.880859, val:   9.58%, val_best:  11.35%, tr:   9.77%, tr_best:  10.32%\n",
      "epoch-126 lr=['0.0100000'], tr/val_loss:26222.685547/10852.424805, val:   9.82%, val_best:  11.35%, tr:  10.14%, tr_best:  10.32%\n",
      "epoch-127 lr=['0.0100000'], tr/val_loss:26044.455078/38888.312500, val:  11.35%, val_best:  11.35%, tr:  10.06%, tr_best:  10.32%\n",
      "epoch-128 lr=['0.0100000'], tr/val_loss:26921.853516/33067.808594, val:  10.09%, val_best:  11.35%, tr:  10.03%, tr_best:  10.32%\n",
      "epoch-129 lr=['0.0100000'], tr/val_loss:25994.083984/13658.178711, val:  11.35%, val_best:  11.35%, tr:  10.18%, tr_best:  10.32%\n",
      "epoch-130 lr=['0.0100000'], tr/val_loss:26114.720703/6818.830566, val:   9.80%, val_best:  11.35%, tr:   9.85%, tr_best:  10.32%\n",
      "epoch-131 lr=['0.0100000'], tr/val_loss:25800.785156/27252.742188, val:  10.09%, val_best:  11.35%, tr:  10.11%, tr_best:  10.32%\n",
      "epoch-132 lr=['0.0100000'], tr/val_loss:25877.103516/19123.089844, val:  10.32%, val_best:  11.35%, tr:  10.15%, tr_best:  10.32%\n",
      "epoch-133 lr=['0.0100000'], tr/val_loss:25960.390625/14007.279297, val:  10.09%, val_best:  11.35%, tr:  10.06%, tr_best:  10.32%\n",
      "epoch-134 lr=['0.0100000'], tr/val_loss:26328.066406/35434.667969, val:  11.35%, val_best:  11.35%, tr:  10.11%, tr_best:  10.32%\n",
      "epoch-135 lr=['0.0100000'], tr/val_loss:26578.648438/87618.070312, val:   9.58%, val_best:  11.35%, tr:  10.23%, tr_best:  10.32%\n",
      "epoch-136 lr=['0.0100000'], tr/val_loss:28174.078125/43484.433594, val:  10.10%, val_best:  11.35%, tr:   9.87%, tr_best:  10.32%\n",
      "epoch-137 lr=['0.0100000'], tr/val_loss:27111.734375/27096.802734, val:  10.10%, val_best:  11.35%, tr:   9.76%, tr_best:  10.32%\n",
      "epoch-138 lr=['0.0100000'], tr/val_loss:26422.619141/34940.503906, val:   9.58%, val_best:  11.35%, tr:   9.86%, tr_best:  10.32%\n",
      "epoch-139 lr=['0.0100000'], tr/val_loss:25462.816406/19211.814453, val:  10.28%, val_best:  11.35%, tr:   9.79%, tr_best:  10.32%\n",
      "epoch-140 lr=['0.0100000'], tr/val_loss:26236.923828/52767.906250, val:  10.10%, val_best:  11.35%, tr:  10.22%, tr_best:  10.32%\n",
      "epoch-141 lr=['0.0100000'], tr/val_loss:27338.539062/107909.335938, val:  10.28%, val_best:  11.35%, tr:   9.92%, tr_best:  10.32%\n",
      "epoch-142 lr=['0.0100000'], tr/val_loss:27200.494141/16544.244141, val:  10.10%, val_best:  11.35%, tr:   9.97%, tr_best:  10.32%\n",
      "epoch-143 lr=['0.0100000'], tr/val_loss:26433.279297/30938.099609, val:  10.09%, val_best:  11.35%, tr:   9.99%, tr_best:  10.32%\n",
      "epoch-144 lr=['0.0100000'], tr/val_loss:28676.386719/5499.747070, val:  10.09%, val_best:  11.35%, tr:  10.08%, tr_best:  10.32%\n",
      "epoch-145 lr=['0.0100000'], tr/val_loss:26716.814453/9249.994141, val:  10.32%, val_best:  11.35%, tr:  10.08%, tr_best:  10.32%\n",
      "epoch-146 lr=['0.0100000'], tr/val_loss:25852.177734/26359.105469, val:  11.35%, val_best:  11.35%, tr:  10.16%, tr_best:  10.32%\n",
      "epoch-147 lr=['0.0100000'], tr/val_loss:25714.183594/16743.609375, val:  11.35%, val_best:  11.35%, tr:   9.77%, tr_best:  10.32%\n",
      "epoch-148 lr=['0.0100000'], tr/val_loss:26018.900391/18981.484375, val:   9.58%, val_best:  11.35%, tr:   9.85%, tr_best:  10.32%\n",
      "epoch-149 lr=['0.0100000'], tr/val_loss:24743.285156/52598.792969, val:   9.74%, val_best:  11.35%, tr:  10.06%, tr_best:  10.32%\n",
      "epoch-150 lr=['0.0100000'], tr/val_loss:24206.402344/46353.066406, val:   8.92%, val_best:  11.35%, tr:  10.01%, tr_best:  10.32%\n",
      "epoch-151 lr=['0.0100000'], tr/val_loss:25555.980469/27540.859375, val:   9.80%, val_best:  11.35%, tr:   9.98%, tr_best:  10.32%\n",
      "epoch-152 lr=['0.0100000'], tr/val_loss:25800.843750/46756.187500, val:   9.82%, val_best:  11.35%, tr:   9.95%, tr_best:  10.32%\n",
      "epoch-153 lr=['0.0100000'], tr/val_loss:26050.248047/17704.582031, val:   8.92%, val_best:  11.35%, tr:  10.13%, tr_best:  10.32%\n",
      "epoch-154 lr=['0.0100000'], tr/val_loss:27404.484375/34707.195312, val:  10.09%, val_best:  11.35%, tr:   9.89%, tr_best:  10.32%\n",
      "epoch-155 lr=['0.0100000'], tr/val_loss:26924.849609/13171.175781, val:   9.74%, val_best:  11.35%, tr:   9.93%, tr_best:  10.32%\n",
      "epoch-156 lr=['0.0100000'], tr/val_loss:25559.544922/18189.144531, val:  10.09%, val_best:  11.35%, tr:  10.11%, tr_best:  10.32%\n",
      "epoch-157 lr=['0.0100000'], tr/val_loss:26130.197266/9350.242188, val:  10.32%, val_best:  11.35%, tr:   9.99%, tr_best:  10.32%\n",
      "epoch-158 lr=['0.0100000'], tr/val_loss:26217.607422/32894.804688, val:  10.28%, val_best:  11.35%, tr:   9.85%, tr_best:  10.32%\n",
      "epoch-159 lr=['0.0100000'], tr/val_loss:25227.320312/23653.644531, val:   9.58%, val_best:  11.35%, tr:  10.09%, tr_best:  10.32%\n",
      "epoch-160 lr=['0.0100000'], tr/val_loss:27563.119141/36833.894531, val:   9.82%, val_best:  11.35%, tr:  10.06%, tr_best:  10.32%\n",
      "epoch-161 lr=['0.0100000'], tr/val_loss:26163.203125/40292.250000, val:   9.58%, val_best:  11.35%, tr:   9.97%, tr_best:  10.32%\n",
      "epoch-162 lr=['0.0100000'], tr/val_loss:25833.658203/20990.003906, val:   9.80%, val_best:  11.35%, tr:  10.05%, tr_best:  10.32%\n",
      "epoch-163 lr=['0.0100000'], tr/val_loss:26216.687500/32919.781250, val:   9.74%, val_best:  11.35%, tr:  10.35%, tr_best:  10.35%\n",
      "epoch-164 lr=['0.0100000'], tr/val_loss:26324.937500/28345.380859, val:  10.09%, val_best:  11.35%, tr:   9.99%, tr_best:  10.35%\n",
      "epoch-165 lr=['0.0100000'], tr/val_loss:26218.615234/21120.050781, val:  10.09%, val_best:  11.35%, tr:  10.02%, tr_best:  10.35%\n",
      "epoch-166 lr=['0.0100000'], tr/val_loss:27033.255859/51116.570312, val:  10.09%, val_best:  11.35%, tr:   9.97%, tr_best:  10.35%\n",
      "epoch-167 lr=['0.0100000'], tr/val_loss:24897.457031/47539.917969, val:   9.82%, val_best:  11.35%, tr:  10.04%, tr_best:  10.35%\n",
      "epoch-168 lr=['0.0100000'], tr/val_loss:27716.728516/46785.703125, val:   9.82%, val_best:  11.35%, tr:  10.11%, tr_best:  10.35%\n",
      "epoch-169 lr=['0.0100000'], tr/val_loss:25062.271484/16897.724609, val:  10.32%, val_best:  11.35%, tr:  10.06%, tr_best:  10.35%\n",
      "epoch-170 lr=['0.0100000'], tr/val_loss:26956.466797/28865.544922, val:  10.32%, val_best:  11.35%, tr:   9.90%, tr_best:  10.35%\n",
      "epoch-171 lr=['0.0100000'], tr/val_loss:24713.019531/29170.326172, val:   8.92%, val_best:  11.35%, tr:  10.11%, tr_best:  10.35%\n",
      "epoch-172 lr=['0.0100000'], tr/val_loss:26349.376953/54057.847656, val:   8.92%, val_best:  11.35%, tr:   9.98%, tr_best:  10.35%\n",
      "epoch-173 lr=['0.0100000'], tr/val_loss:25441.958984/7112.063477, val:  10.09%, val_best:  11.35%, tr:   9.86%, tr_best:  10.35%\n",
      "epoch-174 lr=['0.0100000'], tr/val_loss:26178.896484/35260.562500, val:   9.74%, val_best:  11.35%, tr:  10.21%, tr_best:  10.35%\n",
      "epoch-175 lr=['0.0100000'], tr/val_loss:25430.757812/30041.519531, val:   8.92%, val_best:  11.35%, tr:  10.08%, tr_best:  10.35%\n",
      "epoch-176 lr=['0.0100000'], tr/val_loss:26239.488281/22082.574219, val:  11.35%, val_best:  11.35%, tr:  10.00%, tr_best:  10.35%\n",
      "epoch-177 lr=['0.0100000'], tr/val_loss:26629.429688/12338.101562, val:  11.35%, val_best:  11.35%, tr:  10.17%, tr_best:  10.35%\n",
      "epoch-178 lr=['0.0100000'], tr/val_loss:27439.703125/15471.900391, val:   9.80%, val_best:  11.35%, tr:   9.88%, tr_best:  10.35%\n",
      "epoch-179 lr=['0.0100000'], tr/val_loss:26396.943359/4213.572266, val:  10.10%, val_best:  11.35%, tr:  10.18%, tr_best:  10.35%\n",
      "epoch-180 lr=['0.0100000'], tr/val_loss:26862.187500/41054.050781, val:   9.80%, val_best:  11.35%, tr:  10.10%, tr_best:  10.35%\n",
      "epoch-181 lr=['0.0100000'], tr/val_loss:26067.111328/22296.128906, val:   9.82%, val_best:  11.35%, tr:   9.98%, tr_best:  10.35%\n",
      "epoch-182 lr=['0.0100000'], tr/val_loss:25854.429688/17288.636719, val:  10.10%, val_best:  11.35%, tr:  10.11%, tr_best:  10.35%\n",
      "epoch-183 lr=['0.0100000'], tr/val_loss:26008.990234/26236.125000, val:  10.10%, val_best:  11.35%, tr:  10.10%, tr_best:  10.35%\n",
      "epoch-184 lr=['0.0100000'], tr/val_loss:24825.246094/40333.046875, val:  10.28%, val_best:  11.35%, tr:   9.93%, tr_best:  10.35%\n",
      "epoch-185 lr=['0.0100000'], tr/val_loss:25710.185547/30333.689453, val:   9.80%, val_best:  11.35%, tr:  10.17%, tr_best:  10.35%\n",
      "epoch-186 lr=['0.0100000'], tr/val_loss:25445.537109/8818.075195, val:  10.10%, val_best:  11.35%, tr:   9.91%, tr_best:  10.35%\n",
      "epoch-187 lr=['0.0100000'], tr/val_loss:26840.416016/35257.023438, val:  10.32%, val_best:  11.35%, tr:  10.15%, tr_best:  10.35%\n",
      "epoch-188 lr=['0.0100000'], tr/val_loss:25092.667969/45964.386719, val:   8.92%, val_best:  11.35%, tr:  10.10%, tr_best:  10.35%\n",
      "epoch-189 lr=['0.0100000'], tr/val_loss:25221.082031/34516.992188, val:   9.58%, val_best:  11.35%, tr:   9.82%, tr_best:  10.35%\n",
      "epoch-190 lr=['0.0100000'], tr/val_loss:25958.708984/13221.322266, val:  10.32%, val_best:  11.35%, tr:  10.12%, tr_best:  10.35%\n",
      "epoch-191 lr=['0.0100000'], tr/val_loss:26369.939453/14728.629883, val:   9.58%, val_best:  11.35%, tr:   9.89%, tr_best:  10.35%\n",
      "epoch-192 lr=['0.0100000'], tr/val_loss:25362.548828/8496.967773, val:   9.82%, val_best:  11.35%, tr:  10.20%, tr_best:  10.35%\n",
      "epoch-193 lr=['0.0100000'], tr/val_loss:25857.050781/22065.218750, val:  10.28%, val_best:  11.35%, tr:  10.00%, tr_best:  10.35%\n",
      "epoch-194 lr=['0.0100000'], tr/val_loss:27082.093750/24469.947266, val:   9.82%, val_best:  11.35%, tr:   9.98%, tr_best:  10.35%\n",
      "epoch-195 lr=['0.0100000'], tr/val_loss:27186.966797/21588.210938, val:  11.35%, val_best:  11.35%, tr:  10.11%, tr_best:  10.35%\n",
      "epoch-196 lr=['0.0100000'], tr/val_loss:25978.453125/12158.049805, val:  11.35%, val_best:  11.35%, tr:  10.10%, tr_best:  10.35%\n",
      "epoch-197 lr=['0.0100000'], tr/val_loss:26375.431641/9497.479492, val:  11.35%, val_best:  11.35%, tr:   9.94%, tr_best:  10.35%\n",
      "epoch-198 lr=['0.0100000'], tr/val_loss:25669.294922/38120.093750, val:   9.80%, val_best:  11.35%, tr:  10.05%, tr_best:  10.35%\n",
      "epoch-199 lr=['0.0100000'], tr/val_loss:25702.228516/22822.169922, val:  10.28%, val_best:  11.35%, tr:   9.93%, tr_best:  10.35%\n",
      "epoch-200 lr=['0.0100000'], tr/val_loss:25576.505859/18986.783203, val:   8.92%, val_best:  11.35%, tr:  10.02%, tr_best:  10.35%\n",
      "epoch-201 lr=['0.0100000'], tr/val_loss:26560.576172/26190.533203, val:  10.32%, val_best:  11.35%, tr:  10.24%, tr_best:  10.35%\n",
      "epoch-202 lr=['0.0100000'], tr/val_loss:26479.951172/26768.039062, val:  10.09%, val_best:  11.35%, tr:  10.20%, tr_best:  10.35%\n",
      "epoch-203 lr=['0.0100000'], tr/val_loss:26273.634766/4734.397949, val:  10.09%, val_best:  11.35%, tr:   9.90%, tr_best:  10.35%\n",
      "epoch-204 lr=['0.0100000'], tr/val_loss:25658.062500/22724.541016, val:   8.92%, val_best:  11.35%, tr:  10.25%, tr_best:  10.35%\n",
      "epoch-205 lr=['0.0100000'], tr/val_loss:26069.937500/13693.563477, val:   9.82%, val_best:  11.35%, tr:   9.99%, tr_best:  10.35%\n",
      "epoch-206 lr=['0.0100000'], tr/val_loss:25032.125000/6854.347656, val:   9.82%, val_best:  11.35%, tr:   9.88%, tr_best:  10.35%\n",
      "epoch-207 lr=['0.0100000'], tr/val_loss:25944.578125/21564.029297, val:  10.32%, val_best:  11.35%, tr:  10.03%, tr_best:  10.35%\n",
      "epoch-208 lr=['0.0100000'], tr/val_loss:26373.144531/24456.154297, val:   9.58%, val_best:  11.35%, tr:  10.14%, tr_best:  10.35%\n",
      "epoch-209 lr=['0.0100000'], tr/val_loss:28116.023438/15748.991211, val:  11.35%, val_best:  11.35%, tr:   9.98%, tr_best:  10.35%\n",
      "epoch-210 lr=['0.0100000'], tr/val_loss:27025.046875/22241.515625, val:   9.74%, val_best:  11.35%, tr:  10.03%, tr_best:  10.35%\n",
      "epoch-211 lr=['0.0100000'], tr/val_loss:26870.478516/28698.083984, val:   9.82%, val_best:  11.35%, tr:   9.98%, tr_best:  10.35%\n",
      "epoch-212 lr=['0.0100000'], tr/val_loss:26420.017578/29145.816406, val:   9.74%, val_best:  11.35%, tr:   9.98%, tr_best:  10.35%\n",
      "epoch-213 lr=['0.0100000'], tr/val_loss:25120.556641/29883.273438, val:  10.10%, val_best:  11.35%, tr:  10.05%, tr_best:  10.35%\n",
      "epoch-214 lr=['0.0100000'], tr/val_loss:25272.402344/34430.527344, val:   9.58%, val_best:  11.35%, tr:  10.14%, tr_best:  10.35%\n",
      "epoch-215 lr=['0.0100000'], tr/val_loss:26697.382812/19902.935547, val:  10.32%, val_best:  11.35%, tr:   9.89%, tr_best:  10.35%\n",
      "epoch-216 lr=['0.0100000'], tr/val_loss:24734.845703/5245.709473, val:  10.10%, val_best:  11.35%, tr:  10.18%, tr_best:  10.35%\n",
      "epoch-217 lr=['0.0100000'], tr/val_loss:25339.992188/12505.889648, val:   9.58%, val_best:  11.35%, tr:  10.12%, tr_best:  10.35%\n",
      "epoch-218 lr=['0.0100000'], tr/val_loss:25677.140625/20531.015625, val:   9.80%, val_best:  11.35%, tr:  10.10%, tr_best:  10.35%\n",
      "epoch-219 lr=['0.0100000'], tr/val_loss:24205.453125/14609.951172, val:  10.09%, val_best:  11.35%, tr:   9.98%, tr_best:  10.35%\n",
      "epoch-220 lr=['0.0100000'], tr/val_loss:24848.402344/19438.410156, val:  10.32%, val_best:  11.35%, tr:  10.13%, tr_best:  10.35%\n",
      "epoch-221 lr=['0.0100000'], tr/val_loss:26478.910156/23172.953125, val:  10.32%, val_best:  11.35%, tr:  10.08%, tr_best:  10.35%\n",
      "epoch-222 lr=['0.0100000'], tr/val_loss:25537.480469/28088.060547, val:   9.80%, val_best:  11.35%, tr:   9.95%, tr_best:  10.35%\n",
      "epoch-223 lr=['0.0100000'], tr/val_loss:27060.566406/51556.109375, val:  10.28%, val_best:  11.35%, tr:   9.87%, tr_best:  10.35%\n",
      "epoch-224 lr=['0.0100000'], tr/val_loss:25496.539062/35251.757812, val:   9.80%, val_best:  11.35%, tr:  10.02%, tr_best:  10.35%\n",
      "epoch-225 lr=['0.0100000'], tr/val_loss:27512.398438/12180.081055, val:   9.80%, val_best:  11.35%, tr:  10.34%, tr_best:  10.35%\n",
      "epoch-226 lr=['0.0100000'], tr/val_loss:26177.056641/10172.086914, val:  10.10%, val_best:  11.35%, tr:  10.24%, tr_best:  10.35%\n",
      "epoch-227 lr=['0.0100000'], tr/val_loss:27070.472656/26708.406250, val:  10.09%, val_best:  11.35%, tr:  10.00%, tr_best:  10.35%\n",
      "epoch-228 lr=['0.0100000'], tr/val_loss:26828.056641/35856.441406, val:   9.74%, val_best:  11.35%, tr:   9.91%, tr_best:  10.35%\n",
      "epoch-229 lr=['0.0100000'], tr/val_loss:26116.681641/17704.052734, val:   9.58%, val_best:  11.35%, tr:   9.76%, tr_best:  10.35%\n",
      "epoch-230 lr=['0.0100000'], tr/val_loss:26972.964844/13036.068359, val:   9.58%, val_best:  11.35%, tr:   9.91%, tr_best:  10.35%\n",
      "epoch-231 lr=['0.0100000'], tr/val_loss:26071.988281/25801.777344, val:  10.32%, val_best:  11.35%, tr:   9.98%, tr_best:  10.35%\n",
      "epoch-232 lr=['0.0100000'], tr/val_loss:26972.406250/24269.980469, val:  10.28%, val_best:  11.35%, tr:   9.86%, tr_best:  10.35%\n",
      "epoch-233 lr=['0.0100000'], tr/val_loss:25917.722656/38172.738281, val:  10.09%, val_best:  11.35%, tr:  10.12%, tr_best:  10.35%\n",
      "epoch-234 lr=['0.0100000'], tr/val_loss:25907.230469/13229.784180, val:   9.80%, val_best:  11.35%, tr:   9.90%, tr_best:  10.35%\n",
      "epoch-235 lr=['0.0100000'], tr/val_loss:24892.402344/59070.507812, val:   9.80%, val_best:  11.35%, tr:  10.01%, tr_best:  10.35%\n",
      "epoch-236 lr=['0.0100000'], tr/val_loss:26187.697266/12644.508789, val:  11.35%, val_best:  11.35%, tr:   9.96%, tr_best:  10.35%\n",
      "epoch-237 lr=['0.0100000'], tr/val_loss:25083.664062/23595.298828, val:   9.58%, val_best:  11.35%, tr:  10.13%, tr_best:  10.35%\n",
      "epoch-238 lr=['0.0100000'], tr/val_loss:25324.064453/12589.129883, val:   9.58%, val_best:  11.35%, tr:   9.93%, tr_best:  10.35%\n",
      "epoch-239 lr=['0.0100000'], tr/val_loss:24226.078125/29524.148438, val:   9.82%, val_best:  11.35%, tr:   9.90%, tr_best:  10.35%\n",
      "epoch-240 lr=['0.0100000'], tr/val_loss:25518.531250/18232.181641, val:  10.28%, val_best:  11.35%, tr:  10.07%, tr_best:  10.35%\n",
      "epoch-241 lr=['0.0100000'], tr/val_loss:25739.169922/9313.361328, val:   8.92%, val_best:  11.35%, tr:  10.14%, tr_best:  10.35%\n",
      "epoch-242 lr=['0.0100000'], tr/val_loss:24946.898438/6522.754395, val:  10.10%, val_best:  11.35%, tr:   9.90%, tr_best:  10.35%\n",
      "epoch-243 lr=['0.0100000'], tr/val_loss:26178.562500/52648.960938, val:  10.32%, val_best:  11.35%, tr:  10.12%, tr_best:  10.35%\n",
      "epoch-244 lr=['0.0100000'], tr/val_loss:26913.617188/24242.220703, val:  10.09%, val_best:  11.35%, tr:  10.05%, tr_best:  10.35%\n",
      "epoch-245 lr=['0.0100000'], tr/val_loss:26274.062500/24548.328125, val:   9.82%, val_best:  11.35%, tr:  10.24%, tr_best:  10.35%\n",
      "epoch-246 lr=['0.0100000'], tr/val_loss:25255.283203/28667.849609, val:  10.28%, val_best:  11.35%, tr:  10.11%, tr_best:  10.35%\n",
      "epoch-247 lr=['0.0100000'], tr/val_loss:26304.806641/28685.900391, val:   9.58%, val_best:  11.35%, tr:   9.96%, tr_best:  10.35%\n",
      "epoch-248 lr=['0.0100000'], tr/val_loss:26436.947266/14294.958008, val:   9.58%, val_best:  11.35%, tr:  10.10%, tr_best:  10.35%\n",
      "epoch-249 lr=['0.0100000'], tr/val_loss:25675.486328/24115.902344, val:   9.80%, val_best:  11.35%, tr:  10.19%, tr_best:  10.35%\n",
      "epoch-250 lr=['0.0100000'], tr/val_loss:24512.884766/43456.542969, val:  10.09%, val_best:  11.35%, tr:   9.93%, tr_best:  10.35%\n",
      "epoch-251 lr=['0.0100000'], tr/val_loss:24135.695312/13079.703125, val:   9.82%, val_best:  11.35%, tr:   9.80%, tr_best:  10.35%\n",
      "epoch-252 lr=['0.0100000'], tr/val_loss:26561.859375/12570.970703, val:   9.82%, val_best:  11.35%, tr:  10.06%, tr_best:  10.35%\n",
      "epoch-253 lr=['0.0100000'], tr/val_loss:27230.236328/12248.626953, val:   8.92%, val_best:  11.35%, tr:  10.10%, tr_best:  10.35%\n",
      "epoch-254 lr=['0.0100000'], tr/val_loss:27240.693359/26798.382812, val:  10.10%, val_best:  11.35%, tr:  10.09%, tr_best:  10.35%\n",
      "epoch-255 lr=['0.0100000'], tr/val_loss:25523.027344/31996.048828, val:   9.74%, val_best:  11.35%, tr:  10.18%, tr_best:  10.35%\n",
      "epoch-256 lr=['0.0100000'], tr/val_loss:25472.371094/27655.255859, val:  11.35%, val_best:  11.35%, tr:  10.16%, tr_best:  10.35%\n",
      "epoch-257 lr=['0.0100000'], tr/val_loss:25271.160156/19687.695312, val:  10.28%, val_best:  11.35%, tr:  10.22%, tr_best:  10.35%\n",
      "epoch-258 lr=['0.0100000'], tr/val_loss:26063.906250/6322.058105, val:   8.92%, val_best:  11.35%, tr:   9.97%, tr_best:  10.35%\n",
      "epoch-259 lr=['0.0100000'], tr/val_loss:27489.410156/31136.664062, val:   8.92%, val_best:  11.35%, tr:  10.00%, tr_best:  10.35%\n",
      "epoch-260 lr=['0.0100000'], tr/val_loss:25933.462891/20342.773438, val:  10.32%, val_best:  11.35%, tr:  10.15%, tr_best:  10.35%\n",
      "epoch-261 lr=['0.0100000'], tr/val_loss:28169.632812/47988.980469, val:   9.74%, val_best:  11.35%, tr:   9.93%, tr_best:  10.35%\n",
      "epoch-262 lr=['0.0100000'], tr/val_loss:25444.884766/45113.003906, val:   9.58%, val_best:  11.35%, tr:   9.74%, tr_best:  10.35%\n",
      "epoch-263 lr=['0.0100000'], tr/val_loss:26833.701172/10346.409180, val:   9.58%, val_best:  11.35%, tr:   9.86%, tr_best:  10.35%\n",
      "epoch-264 lr=['0.0100000'], tr/val_loss:25928.890625/11167.228516, val:   9.58%, val_best:  11.35%, tr:   9.93%, tr_best:  10.35%\n",
      "epoch-265 lr=['0.0100000'], tr/val_loss:26212.433594/34277.667969, val:  11.35%, val_best:  11.35%, tr:  10.04%, tr_best:  10.35%\n",
      "epoch-266 lr=['0.0100000'], tr/val_loss:27082.564453/14217.519531, val:   8.92%, val_best:  11.35%, tr:   9.76%, tr_best:  10.35%\n",
      "epoch-267 lr=['0.0100000'], tr/val_loss:26561.316406/12846.686523, val:   8.92%, val_best:  11.35%, tr:   9.92%, tr_best:  10.35%\n",
      "epoch-268 lr=['0.0100000'], tr/val_loss:26332.449219/56491.320312, val:   9.82%, val_best:  11.35%, tr:  10.07%, tr_best:  10.35%\n",
      "epoch-269 lr=['0.0100000'], tr/val_loss:26574.748047/63230.414062, val:  11.35%, val_best:  11.35%, tr:   9.95%, tr_best:  10.35%\n"
     ]
    }
   ],
   "source": [
    "### my_snn control board (Gesture) ########################\n",
    "decay = 0.5 # 0.0 # 0.875 0.25 0.125 0.75 0.5\n",
    "# nda 0.25 # ottt 0.5\n",
    "\n",
    "unique_name = 'main' ## 이거 설정하면 새로운 경로에 모두 save\n",
    "run_name = 'main' ## 이거 설정하면 새로운 경로에 모두 save\n",
    "\n",
    "\n",
    "\n",
    "wandb.init(project= f'my_snn {unique_name}',save_code=False, dir='/data2/bh_wandb', tags=[\"common\"])\n",
    "\n",
    "my_snn_system(  devices = \"2\",\n",
    "                single_step = True, # True # False # DFA_on이랑 같이 가라\n",
    "                unique_name = run_name,\n",
    "                my_seed = 42,\n",
    "                TIME = 10, # dvscifar 10 # ottt 6 or 10 # nda 10  # 제작하는 dvs에서 TIME넘거나 적으면 자르거나 PADDING함\n",
    "                BATCH = 16, # batch norm 할거면 2이상으로 해야함   # nda 256   #  ottt 128\n",
    "                IMAGE_SIZE = 17, # dvscifar 48 # MNIST 28 # CIFAR10 32 # PMNIST 28 #NMNIST 34 # GESTURE 128\n",
    "                # dvsgesture 128, dvs_cifar2 128, nmnist 34, n_caltech101 180,240, n_tidigits 64, heidelberg 700, \n",
    "\n",
    "                # DVS_CIFAR10 할거면 time 10으로 해라\n",
    "                which_data = 'NMNIST_TONIC',\n",
    "# 'CIFAR100' 'CIFAR10' 'MNIST' 'FASHION_MNIST' 'DVS_CIFAR10' 'PMNIST'아직\n",
    "# 'DVS_GESTURE', 'DVS_GESTURE_TONIC','DVS_CIFAR10_2','NMNIST','NMNIST_TONIC','CIFAR10','N_CALTECH101','n_tidigits','heidelberg'\n",
    "                # CLASS_NUM = 10,\n",
    "                data_path = '/data2', # YOU NEED TO CHANGE THIS\n",
    "                rate_coding = False, # True # False\n",
    "\n",
    "                lif_layer_v_init = 0.0,\n",
    "                lif_layer_v_decay = decay,\n",
    "                lif_layer_v_threshold = 0.5,   #nda 0.5  #ottt 1.0\n",
    "                lif_layer_v_reset = 10000.0, # 10000이상은 hardreset (내 LIF쓰기는 함 ㅇㅇ)\n",
    "                lif_layer_sg_width = 4.0, # 2.570969004857107 # sigmoid류에서는 alpha값 4.0, rectangle류에서는 width값 0.5\n",
    "\n",
    "                # synapse_conv_in_channels = IMAGE_PIXEL_CHANNEL,\n",
    "                synapse_conv_kernel_size = 3,\n",
    "                synapse_conv_stride = 1,\n",
    "                synapse_conv_padding = 1,\n",
    "\n",
    "                synapse_trace_const1 = 1, # 현재 trace구할 때 현재 spike에 곱해지는 상수. 걍 1로 두셈.\n",
    "                synapse_trace_const2 = decay, # 현재 trace구할 때 직전 trace에 곱해지는 상수. lif_layer_v_decay와 같게 할 것을 추천\n",
    "\n",
    "                # synapse_fc_out_features = CLASS_NUM,\n",
    "\n",
    "                pre_trained = False, # True # False\n",
    "                convTrue_fcFalse = False, # True # False\n",
    "\n",
    "                # 'P' for average pooling, 'D' for (1,1) aver pooling, 'M' for maxpooling, 'L' for linear classifier, [  ] for residual block\n",
    "                # conv에서 10000 이상은 depth-wise separable (BPTT만 지원), 20000이상은 depth-wise (BPTT만 지원)\n",
    "                # cfg = ['M', 'M', 32, 'P', 32, 'P', 32, 'P'], \n",
    "                # cfg = ['M', 'M', 64, 'P', 64, 'P', 64, 'P'], \n",
    "                # cfg = ['M', 'M', 64, 'M', 96, 'M', 128, 'M'], \n",
    "                cfg = [200, 200], \n",
    "                # cfg = ['M', 'M', 64, 'M', 96], \n",
    "                # cfg = ['M', 'M', 64, 'M', 96, 'L', 512, 512], \n",
    "                # cfg = ['M', 'M', 64], \n",
    "                # cfg = [64, 124, 64, 124],\n",
    "                # cfg = ['M','M',512], \n",
    "                # cfg = [512], \n",
    "                # cfg = ['M', 'M', 64, 128, 'P', 128, 'P'], \n",
    "                # cfg = ['M','M',512],\n",
    "                # cfg = ['M',200],\n",
    "                # cfg = [200,200],\n",
    "                # cfg = ['M','M',200,200],\n",
    "                # cfg = ([200],[200],[200],[2]), # (feature extractor, classifier, domain adapter, # of domain)\n",
    "                # cfg = (['M','M',200],[200],[200],[2]), # (feature extractor, classifier, domain adapter, # of domain)\n",
    "                # cfg = ['M',200,200],\n",
    "                # cfg = ['M','M',1024,512,256,128,64],\n",
    "                # cfg = [200,200],\n",
    "                # cfg = [12], #fc\n",
    "                # cfg = [12, 'M', 48, 'M', 12], \n",
    "                # cfg = [64,[64,64],64], # 끝에 linear classifier 하나 자동으로 붙습니다\n",
    "                # cfg = [64, 128, 'P', 256, 256, 'P', 512, 512, 'P', 512, 512, 'D'], #ottt\n",
    "                # cfg = [64, 128, 'P', 256, 256, 'P', 512, 512, 'P', 512, 512], \n",
    "                # cfg = [64, 128, 'M', 256, 256, 'M', 512, 512, 'M', 512, 512], \n",
    "                # cfg = [64, 'P', 128, 'P', 256, 256, 'P', 512, 512, 512, 512, 'D'], # nda\n",
    "                # cfg = [64, 'P', 128, 'P', 256, 256, 'P', 512, 512, 512, 512], # nda 128pixel\n",
    "                # cfg = [64, 'P', 128, 'P', 256, 256, 'P', 512, 512, 512, 512, 'L', 4096, 4096],\n",
    "                # cfg = [20001,10001], # depthwise, separable\n",
    "                # cfg = [64,20064,10001], # vanilla conv, depthwise, separable\n",
    "                # cfg = [8, 'P', 8, 'P', 8, 'P', 8,'P', 8, 'P'],\n",
    "                # cfg = [],        \n",
    "                \n",
    "                net_print = True, # True # False # True로 하길 추천\n",
    "                \n",
    "                pre_trained_path = f\"net_save/save_now_net_weights_{unique_name}.pth\",\n",
    "                learning_rate = 0.01, #0.1 bptt, #0.01 ottt, # default 0.001  # ottt 0.1 # nda 0.001 # 0.00936191669529645\n",
    "                epoch_num = 10000,\n",
    "                tdBN_on = False,  # True # False\n",
    "                BN_on = False,  # True # False\n",
    "                \n",
    "                surrogate = 'hard_sigmoid', # 'sigmoid' 'rectangle' 'rough_rectangle' 'hard_sigmoid'\n",
    "                \n",
    "                BPTT_on = False,  # True # False # True이면 BPTT, False이면 OTTT  # depthwise, separable은 BPTT만 가능\n",
    "                \n",
    "                optimizer_what = 'SGD', # 'SGD' 'Adam', 'RMSprop'\n",
    "                scheduler_name = 'no', # 'no' 'StepLR' 'ExponentialLR' 'ReduceLROnPlateau' 'CosineAnnealingLR' 'OneCycleLR'\n",
    "                \n",
    "                ddp_on = False, # DECREPATED # fALSE\n",
    "\n",
    "                dvs_clipping = 1, #일반적으로 1 또는 2 # 100ms때는 5 # 숫자만큼 크면 spike 아니면 걍 0\n",
    "                # gesture, cifar-dvs2, nmnist, ncaltech101\n",
    "                # gesture: 100_000c1-5, 25_000c5, 10_000c5, 1_000c5, 1_000_000c5\n",
    "\n",
    "                dvs_duration = 5_000, # 10_000 # 25_000, # 0 아니면 time sampling # dvs number sampling OR time sampling # gesture, cifar-dvs2, nmnist, ncaltech101\n",
    "                # 있는 데이터들 #gesture 100_000 25_000 10_000 1_000 1_000_000 #nmnist 10000 #nmnist_tonic 10_000 25_000\n",
    "                # 한 숫자가 1us인듯 (spikingjelly코드에서)\n",
    "                # 한 장에 50 timestep만 생산함. 싫으면 my_snn/trying/spikingjelly_dvsgesture의__init__.py 를 참고해봐\n",
    "                # nmnist 5_000us, gesture는 100_000us, 25_000us\n",
    "\n",
    "                DFA_on = True, # True # False # single_step이랑 같이 켜야 됨.\n",
    "\n",
    "                trace_on = False,   # True # False\n",
    "                OTTT_input_trace_on = False, # True # False # 맨 처음 input에 trace 적용 # trace_on False면 의미없음.\n",
    "\n",
    "                exclude_class = True, # True # False # gesture에서 10번째 클래스 제외\n",
    "\n",
    "                merge_polarities = False, # True # False # tonic dvs dataset 에서 polarities 합치기\n",
    "                denoise_on = False, # True # False # &&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&\n",
    "\n",
    "                extra_train_dataset = 0, \n",
    "\n",
    "                num_workers = 2, # local wsl에서는 2가 맞고, 서버에서는 4가 좋더라.\n",
    "                chaching_on = True, # True # False # only for certain datasets (gesture_tonic, nmnist_tonic)\n",
    "                pin_memory = True, # True # False \n",
    "\n",
    "                UDA_on = False,  # DECREPATED # uda\n",
    "                alpha_uda = 1.0, # DECREPATED # uda\n",
    "\n",
    "                bias = True, # True # False \n",
    "\n",
    "                last_lif = False, # True # False \n",
    "\n",
    "                temporal_filter = 1, \n",
    "                initial_pooling = 1,\n",
    "\n",
    "                temporal_filter_accumulation = False, # True # False \n",
    "                ) \n",
    "\n",
    "# num_workers = 4 * num_GPU (or 8, 16, 2 * num_GPU)\n",
    "# entry * batch_size * num_worker = num_GPU * GPU_throughtput\n",
    "# num_workers = batch_size / num_GPU\n",
    "# num_workers = batch_size / num_CPU\n",
    "\n",
    "# sigmoid와 BN이 있어야 잘된다.\n",
    "# average pooling  \n",
    "# 이 낫다. \n",
    "\n",
    "# nda에서는 decay = 0.25, threshold = 0.5, width =1, surrogate = rectangle, batch = 256, tdBN = True\n",
    "## OTTT 에서는 decay = 0.5, threshold = 1.0, surrogate = sigmoid, batch = 128, BN = True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # sweep 하는 코드, 위 셀 주석처리 해야 됨.\n",
    "\n",
    "# # 이런 워닝 뜨는 거는 걍 너가 main 안에서  wandb.config.update(hyperparameters)할 때 물려서임. 어차피 근데 sweep에서 지정한 걸로 덮어짐 \n",
    "# # wandb: WARNING Config item 'BATCH' was locked by 'sweep' (ignored update).\n",
    "\n",
    "# unique_name_hyper = 'main'\n",
    "# sweep_configuration = {\n",
    "#     'method': 'bayes', # 'random', 'bayes'\n",
    "#     'name': f'my_snn_sweep{datetime.datetime.now().strftime(\"%Y%m%d_%H%M%S\")}',\n",
    "#     'metric': {'goal': 'maximize', 'name': 'val_acc_best'},\n",
    "#     'parameters': \n",
    "#     {\n",
    "#         # \"devices\": {\"values\": [\"1\"]},\n",
    "#         \"single_step\": {\"values\": [True]},\n",
    "#         # \"unique_name\": {\"values\": [unique_name_hyper]},\n",
    "#         \"my_seed\": {\"values\": [42]},\n",
    "#         \"TIME\": {\"values\": [10]},\n",
    "#         \"BATCH\": {\"values\": [16]},\n",
    "#         \"IMAGE_SIZE\": {\"values\": [128]},\n",
    "#         \"which_data\": {\"values\": ['DVS_GESTURE_TONIC']},\n",
    "#         \"data_path\": {\"values\": ['/data2']},\n",
    "#         \"rate_coding\": {\"values\": [False]},\n",
    "#         \"lif_layer_v_init\": {\"values\": [0.0]},\n",
    "#         \"lif_layer_v_decay\": {\"values\": [0.5]},\n",
    "#         \"lif_layer_v_threshold\": {\"values\": [0.25, 0.5, 0.75, 1.0]},\n",
    "#         \"lif_layer_v_reset\": {\"values\": [10000.0, 0.0]},\n",
    "#         \"lif_layer_sg_width\": {\"values\": [1.0,2.0,3.0,4.0,5.0]},\n",
    "\n",
    "#         \"synapse_conv_kernel_size\": {\"values\": [3]},\n",
    "#         \"synapse_conv_stride\": {\"values\": [1]},\n",
    "#         \"synapse_conv_padding\": {\"values\": [1]},\n",
    "\n",
    "#         \"synapse_trace_const1\": {\"values\": [1]},\n",
    "#         \"synapse_trace_const2\": {\"values\": [0, 0.5]},\n",
    "\n",
    "#         \"pre_trained\": {\"values\": [False]},\n",
    "#         \"convTrue_fcFalse\": {\"values\": [False]},\n",
    "\n",
    "#         \"cfg\": {\"values\": [['M','M',200,200]]},\n",
    "\n",
    "#         \"net_print\": {\"values\": [True]},\n",
    "\n",
    "#         \"pre_trained_path\": {\"values\": [\"net_save/save_now_net_weights_{unique_name}.pth\"]},\n",
    "#         \"learning_rate\": {\"values\": [0.001,0.01,0.1,0.0001]}, \n",
    "#         \"epoch_num\": {\"values\": [100]}, \n",
    "#         \"tdBN_on\": {\"values\": [False]},\n",
    "#         \"BN_on\": {\"values\": [False]},\n",
    "\n",
    "#         \"surrogate\": {\"values\": ['hard_sigmoid']},\n",
    "\n",
    "#         \"BPTT_on\": {\"values\": [False]},\n",
    "\n",
    "#         \"optimizer_what\": {\"values\": ['SGD']},\n",
    "#         \"scheduler_name\": {\"values\": ['no']},\n",
    "\n",
    "#         \"ddp_on\": {\"values\": [False]},\n",
    "\n",
    "#         \"dvs_clipping\": {\"values\": [5]}, \n",
    "\n",
    "#         \"dvs_duration\": {\"values\": [100_000]}, \n",
    "\n",
    "#         \"DFA_on\": {\"values\": [True, False]},\n",
    "\n",
    "#         \"trace_on\": {\"values\": [True]},\n",
    "#         \"OTTT_input_trace_on\": {\"values\": [False]},\n",
    "\n",
    "#         \"exclude_class\": {\"values\": [True]},\n",
    "\n",
    "#         \"merge_polarities\": {\"values\": [False]},\n",
    "#         \"denoise_on\": {\"values\": [True, False]},\n",
    "\n",
    "#         \"extra_train_dataset\": {\"values\": [0]},\n",
    "\n",
    "#         \"num_workers\": {\"values\": [2]},\n",
    "#         \"chaching_on\": {\"values\": [True]},\n",
    "#         \"pin_memory\": {\"values\": [True]},\n",
    "\n",
    "#         \"UDA_on\": {\"values\": [False]},\n",
    "#         \"alpha_uda\": {\"values\": [1.0]},\n",
    "\n",
    "#         \"bias\": {\"values\": [True]},\n",
    "\n",
    "#         \"last_lif\": {\"values\": [False]},\n",
    "\n",
    "#         \"temporal_filter\": {\"values\": [1]},\n",
    "#         \"initial_pooling\": {\"values\": [1]},\n",
    "\n",
    "#         \"temporal_filter_accumulation\": {\"values\": [False]},\n",
    "#      }\n",
    "# }\n",
    "\n",
    "# def hyper_iter():\n",
    "#     ### my_snn control board ########################\n",
    "#     wandb.init(save_code=False, dir='/data2/bh_wandb', tags=[\"sweep\"])\n",
    "\n",
    "#     my_snn_system(  \n",
    "#         devices  =  \"0\",\n",
    "#         single_step  =  wandb.config.single_step,\n",
    "#         unique_name  =  unique_name_hyper,\n",
    "#         my_seed  =  wandb.config.my_seed,\n",
    "#         TIME  =  wandb.config.TIME,\n",
    "#         BATCH  =  wandb.config.BATCH,\n",
    "#         IMAGE_SIZE  =  wandb.config.IMAGE_SIZE,\n",
    "#         which_data  =  wandb.config.which_data,\n",
    "#         data_path  =  wandb.config.data_path,\n",
    "#         rate_coding  =  wandb.config.rate_coding,\n",
    "#         lif_layer_v_init  =  wandb.config.lif_layer_v_init,\n",
    "#         lif_layer_v_decay  =  wandb.config.lif_layer_v_decay,\n",
    "#         lif_layer_v_threshold  =  wandb.config.lif_layer_v_threshold,\n",
    "#         lif_layer_v_reset  =  wandb.config.lif_layer_v_reset,\n",
    "#         lif_layer_sg_width  =  wandb.config.lif_layer_sg_width,\n",
    "#         synapse_conv_kernel_size  =  wandb.config.synapse_conv_kernel_size,\n",
    "#         synapse_conv_stride  =  wandb.config.synapse_conv_stride,\n",
    "#         synapse_conv_padding  =  wandb.config.synapse_conv_padding,\n",
    "#         synapse_trace_const1  =  wandb.config.synapse_trace_const1,\n",
    "#         synapse_trace_const2  =  wandb.config.synapse_trace_const2,\n",
    "#         pre_trained  =  wandb.config.pre_trained,\n",
    "#         convTrue_fcFalse  =  wandb.config.convTrue_fcFalse,\n",
    "#         cfg  =  wandb.config.cfg,\n",
    "#         net_print  =  wandb.config.net_print,\n",
    "#         pre_trained_path  =  wandb.config.pre_trained_path,\n",
    "#         learning_rate  =  wandb.config.learning_rate,\n",
    "#         epoch_num  =  wandb.config.epoch_num,\n",
    "#         tdBN_on  =  wandb.config.tdBN_on,\n",
    "#         BN_on  =  wandb.config.BN_on,\n",
    "#         surrogate  =  wandb.config.surrogate,\n",
    "#         BPTT_on  =  wandb.config.BPTT_on,\n",
    "#         optimizer_what  =  wandb.config.optimizer_what,\n",
    "#         scheduler_name  =  wandb.config.scheduler_name,\n",
    "#         ddp_on  =  wandb.config.ddp_on,\n",
    "#         dvs_clipping  =  wandb.config.dvs_clipping,\n",
    "#         dvs_duration  =  wandb.config.dvs_duration,\n",
    "#         DFA_on  =  wandb.config.DFA_on,\n",
    "#         trace_on  =  wandb.config.trace_on,\n",
    "#         OTTT_input_trace_on  =  wandb.config.OTTT_input_trace_on,\n",
    "#         exclude_class  =  wandb.config.exclude_class,\n",
    "#         merge_polarities  =  wandb.config.merge_polarities,\n",
    "#         denoise_on  =  wandb.config.denoise_on,\n",
    "#         extra_train_dataset  =  wandb.config.extra_train_dataset,\n",
    "#         num_workers  =  wandb.config.num_workers,\n",
    "#         chaching_on  =  wandb.config.chaching_on,\n",
    "#         pin_memory  =  wandb.config.pin_memory,\n",
    "#         UDA_on  =  wandb.config.UDA_on,\n",
    "#         alpha_uda  =  wandb.config.alpha_uda,\n",
    "#         bias  =  wandb.config.bias,\n",
    "#         last_lif  =  wandb.config.last_lif,\n",
    "#         temporal_filter  =  wandb.config.temporal_filter,\n",
    "#         initial_pooling  =  wandb.config.initial_pooling,\n",
    "#         temporal_filter_accumulation  =  wandb.config.temporal_filter_accumulation,\n",
    "#                         ) \n",
    "#     # sigmoid와 BN이 있어야 잘된다.\n",
    "#     # average pooling\n",
    "#     # 이 낫다. \n",
    "    \n",
    "#     # nda에서는 decay = 0.25, threshold = 0.5, width =1, surrogate = rectangle, batch = 256, tdBN = True\n",
    "#     ## OTTT 에서는 decay = 0.5, threshold = 1.0, surrogate = sigmoid, batch = 128, BN = True\n",
    "\n",
    "# # sweep_id = '6pj3lh8j'\n",
    "# sweep_id = wandb.sweep(sweep=sweep_configuration, project=f'my_snn {unique_name_hyper}')\n",
    "# wandb.agent(sweep_id, function=hyper_iter, count=10000, project=f'my_snn {unique_name_hyper}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wandb.finish() "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aedat2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
