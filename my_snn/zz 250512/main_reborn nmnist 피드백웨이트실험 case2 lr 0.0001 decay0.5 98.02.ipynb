{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_36325/3748606120.py:46: DeprecationWarning: The module snntorch.spikevision is deprecated. For loading neuromorphic datasets, we recommend using the Tonic project: https://github.com/neuromorphs/tonic\n",
      "  from snntorch.spikevision import spikedata\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAl4AAAIhCAYAAACfVbSSAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8pXeV/AAAACXBIWXMAAA9hAAAPYQGoP6dpAAA8D0lEQVR4nO3de1yUdf7//+cAMngAPIKYiHTYjbTCwMpTPzvIrqtm20HXykNqq3nKw5aytllaklbmbqZlnjIPkalp5VpsbmmlG5Fp28lKEyyJNANTAZm5fn+48v2MoDHTzPtyhsf9drtut7i45n29ZhJ5+bze1/tyWJZlCQAAAAEXZncBAAAAtQWNFwAAgCE0XgAAAIbQeAEAABhC4wUAAGAIjRcAAIAhNF4AAACG0HgBAAAYQuMFAABgCI0X4IMlS5bI4XBUbhEREUpISNCf/vQnffnll7bV9cADD8jhcNh2/lPl5eVp5MiRuvjiixUdHa34+Hhdd9112rRpU5VjBw0a5PGZ1q9fX61bt9b111+vxYsXq6yszOvzjx8/Xg6HQz179vTH2wGAX43GC/gVFi9erK1bt+pf//qXRo0apfXr16tz5846dOiQ3aWdFVauXKn3339fgwcP1rp167RgwQI5nU5de+21Wrp0aZXj69atq61bt2rr1q169dVXNXXqVNWvX1933nmn0tLStG/fvhqf+/jx41q2bJkkaePGjfr222/99r4AwGcWAK8tXrzYkmTl5uZ67H/wwQctSdaiRYtsqWvKlCnW2fRj/f3331fZV1FRYV1yySXWeeed57F/4MCBVv369asd5/XXX7fq1KljXXHFFTU+96pVqyxJVo8ePSxJ1sMPP1yj15WXl1vHjx+v9ntHjhyp8fkBoDokXoAfpaenS5K+//77yn2lpaWaMGGCUlNTFRsbq8aNG6tDhw5at25dldc7HA6NGjVKzz//vFJSUlSvXj1deumlevXVV6sc+9prryk1NVVOp1PJycl67LHHqq2ptLRUmZmZSk5OVmRkpM455xyNHDlSP/30k8dxrVu3Vs+ePfXqq6+qXbt2qlu3rlJSUirPvWTJEqWkpKh+/fq6/PLL9cEHH/zi5xEXF1dlX3h4uNLS0lRQUPCLrz8pIyNDd955p/7zn/9o8+bNNXrNwoULFRkZqcWLFysxMVGLFy+WZVkex7z11ltyOBx6/vnnNWHCBJ1zzjlyOp366quvNGjQIDVo0EAff/yxMjIyFB0drWuvvVaSlJOTo969e6tly5aKiorS+eefr2HDhunAgQOVY2/ZskUOh0MrV66sUtvSpUvlcDiUm5tb488AQGig8QL8aM+ePZKk3/zmN5X7ysrK9OOPP+ovf/mLXn75Za1cuVKdO3fWjTfeWO3lttdee01z5szR1KlTtXr1ajVu3Fh//OMftXv37spj3nzzTfXu3VvR0dF64YUX9Oijj+rFF1/U4sWLPcayLEs33HCDHnvsMfXv31+vvfaaxo8fr+eee07XXHNNlXlTO3bsUGZmpiZOnKg1a9YoNjZWN954o6ZMmaIFCxZo+vTpWr58uYqLi9WzZ08dO3bM68+ooqJCW7ZsUZs2bbx63fXXXy9JNWq89u3bpzfeeEO9e/dWs2bNNHDgQH311VenfW1mZqby8/P19NNP65VXXqlsGMvLy3X99dfrmmuu0bp16/Tggw9Kkr7++mt16NBB8+bN0xtvvKH7779f//nPf9S5c2cdP35cktSlSxe1a9dOTz31VJXzzZkzR+3bt1f79u29+gwAhAC7IzcgGJ281Lht2zbr+PHj1uHDh62NGzdazZs3t6666qrTXqqyrBOX2o4fP24NGTLEateuncf3JFnx8fFWSUlJ5b7CwkIrLCzMysrKqtx3xRVXWC1atLCOHTtWua+kpMRq3Lixx6XGjRs3WpKsmTNnepwnOzvbkmTNnz+/cl9SUpJVt25da9++fZX7PvroI0uSlZCQ4HGZ7eWXX7YkWevXr6/Jx+Vh8uTJliTr5Zdf9th/pkuNlmVZn332mSXJuuuuu37xHFOnTrUkWRs3brQsy7J2795tORwOq3///h7H/fvf/7YkWVdddVWVMQYOHFijy8Zut9s6fvy4tXfvXkuStW7dusrvnfxzsn379sp977//viXJeu65537xfQAIPSRewK9w5ZVXqk6dOoqOjtbvf/97NWrUSOvWrVNERITHcatWrVKnTp3UoEEDRUREqE6dOlq4cKE+++yzKmNeffXVio6Orvw6Pj5ecXFx2rt3ryTpyJEjys3N1Y033qioqKjK46Kjo9WrVy+PsU7ePTho0CCP/bfccovq16+vN99802N/amqqzjnnnMqvU1JSJEldu3ZVvXr1quw/WVNNLViwQA8//LAmTJig3r17e/Va65TLhGc67uTlxW7dukmSkpOT1bVrV61evVolJSVVXnPTTTeddrzqvldUVKThw4crMTGx8v9nUlKSJHn8P+3Xr5/i4uI8Uq8nn3xSzZo1U9++fWv0fgCEFhov4FdYunSpcnNztWnTJg0bNkyfffaZ+vXr53HMmjVr1KdPH51zzjlatmyZtm7dqtzcXA0ePFilpaVVxmzSpEmVfU6ns/Ky3qFDh+R2u9W8efMqx5267+DBg4qIiFCzZs089jscDjVv3lwHDx702N+4cWOPryMjI8+4v7r6T2fx4sUaNmyY/vznP+vRRx+t8etOOtnktWjR4ozHbdq0SXv27NEtt9yikpIS/fTTT/rpp5/Up08fHT16tNo5VwkJCdWOVa9ePcXExHjsc7vdysjI0Jo1a3TvvffqzTff1Pvvv69t27ZJksflV6fTqWHDhmnFihX66aef9MMPP+jFF1/U0KFD5XQ6vXr/AEJDxC8fAuB0UlJSKifUX3311XK5XFqwYIFeeukl3XzzzZKkZcuWKTk5WdnZ2R5rbPmyLpUkNWrUSA6HQ4WFhVW+d+q+Jk2aqKKiQj/88INH82VZlgoLC43NMVq8eLGGDh2qgQMH6umnn/ZprbH169dLOpG+ncnChQslSbNmzdKsWbOq/f6wYcM89p2unur2//e//9WOHTu0ZMkSDRw4sHL/V199Ve0Yd911lx555BEtWrRIpaWlqqio0PDhw8/4HgCELhIvwI9mzpypRo0a6f7775fb7ZZ04pd3ZGSkxy/xwsLCau9qrImTdxWuWbPGI3E6fPiwXnnlFY9jT96Fd3I9q5NWr16tI0eOVH4/kJYsWaKhQ4fq9ttv14IFC3xqunJycrRgwQJ17NhRnTt3Pu1xhw4d0tq1a9WpUyf9+9//rrLddtttys3N1X//+1+f38/J+k9NrJ555plqj09ISNAtt9yiuXPn6umnn1avXr3UqlUrn88PILiReAF+1KhRI2VmZuree+/VihUrdPvtt6tnz55as2aNRowYoZtvvlkFBQWaNm2aEhISfF7lftq0afr973+vbt26acKECXK5XJoxY4bq16+vH3/8sfK4bt266Xe/+50mTpyokpISderUSTt37tSUKVPUrl079e/f319vvVqrVq3SkCFDlJqaqmHDhun999/3+H67du08Ghi32115ya6srEz5+fn65z//qRdffFEpKSl68cUXz3i+5cuXq7S0VGPGjKk2GWvSpImWL1+uhQsX6oknnvDpPV144YU677zzNGnSJFmWpcaNG+uVV15RTk7OaV9z991364orrpCkKneeAqhl7J3bDwSn0y2galmWdezYMatVq1bWBRdcYFVUVFiWZVmPPPKI1bp1a8vpdFopKSnWs88+W+1ip5KskSNHVhkzKSnJGjhwoMe+9evXW5dccokVGRlptWrVynrkkUeqHfPYsWPWxIkTraSkJKtOnTpWQkKCddddd1mHDh2qco4ePXpUOXd1Ne3Zs8eSZD366KOn/Yws6//dGXi6bc+ePac9tm7dularVq2sXr16WYsWLbLKysrOeC7LsqzU1FQrLi7ujMdeeeWVVtOmTa2ysrLKuxpXrVpVbe2nu8vy008/tbp162ZFR0dbjRo1sm655RYrPz/fkmRNmTKl2te0bt3aSklJ+cX3ACC0OSyrhrcKAQB8snPnTl166aV66qmnNGLECLvLAWAjGi8ACJCvv/5ae/fu1V//+lfl5+frq6++8liWA0Dtw+R6AAiQadOmqVu3bvr555+1atUqmi4AJF4AAACmkHgBAAAYQuMFAABgCI0XAACAIUG9gKrb7dZ3332n6Ohon1bDBgCgNrEsS4cPH1aLFi0UFmY+eyktLVV5eXlAxo6MjFRUVFRAxvanoG68vvvuOyUmJtpdBgAAQaWgoEAtW7Y0es7S0lIlJzVQYZErIOM3b95ce/bsOeubr6BuvKKjoyVJl3edpIiIs/uDPlWdw8ftLsEnTy1+1u4SfDZ69412l+CTrz8x+5ejv0QnFdtdgs9+/jrW7hJ8EvV9cM4eeerOeXaX4LO7/3GX3SV4xVVeqs+fm1r5+9Ok8vJyFRa5tDevtWKi/ftnteSwW0lp36i8vJzGK5BOXl6MiIgKusYrIiLc7hJ8Eu3nHxaTIuo7f/mgs1DYWf6XyOmE1yv95YPOUkH7mTuD8+ezfhD/vRIeGZx/VuycntMg2qEG0f49v1vBM90oqBsvAAAQXFyWWy4/ryDqstz+HTCAgvefGQAAAEGGxAsAABjjliW3/Bt5+Xu8QCLxAgAAMITECwAAGOOWW/6ekeX/EQOHxAsAAMAQEi8AAGCMy7Lksvw7J8vf4wUSiRcAAIAhJF4AAMCY2n5XI40XAAAwxi1LrlrceHGpEQAAwBASLwAAYExtv9RI4gUAAGAIiRcAADCG5SQAAABgBIkXAAAwxv2/zd9jBgvbE6+5c+cqOTlZUVFRSktL05YtW+wuCQAAICBsbbyys7M1duxYTZ48Wdu3b1eXLl3UvXt35efn21kWAAAIENf/1vHy9xYsbG28Zs2apSFDhmjo0KFKSUnR7NmzlZiYqHnz5tlZFgAACBCXFZgtWNjWeJWXlysvL08ZGRke+zMyMvTee+9V+5qysjKVlJR4bAAAAMHCtsbrwIEDcrlcio+P99gfHx+vwsLCal+TlZWl2NjYyi0xMdFEqQAAwE/cAdqChe2T6x0Oh8fXlmVV2XdSZmamiouLK7eCggITJQIAAPiFbctJNG3aVOHh4VXSraKioiop2ElOp1NOp9NEeQAAIADccsil6gOWXzNmsLAt8YqMjFRaWppycnI89ufk5Khjx442VQUAABA4ti6gOn78ePXv31/p6enq0KGD5s+fr/z8fA0fPtzOsgAAQIC4rRObv8cMFrY2Xn379tXBgwc1depU7d+/X23bttWGDRuUlJRkZ1kAAAABYfsjg0aMGKERI0bYXQYAADDAFYA5Xv4eL5Bsb7wAAEDtUdsbL9uXkwAAAKgtSLwAAIAxbssht+Xn5ST8PF4gkXgBAAAYQuIFAACMYY4XAAAAjCDxAgAAxrgUJpefcx+XX0cLLBIvAAAAQ0i8AACAMVYA7mq0guiuRhovAABgDJPrAQAAYASJFwAAMMZlhcll+XlyveXX4QKKxAsAAMAQEi8AAGCMWw65/Zz7uBU8kReJFwAAgCEhkXilPbBdzgZ17C7DKx+OaWd3CT75S8H1dpfgM2tSY7tL8EnsfYfsLsEnL6cutLsEn113dKTdJfik93Uf2l2CT466nXaX4LPkP31pdwleOX6kXJ88a28N3NUIAAAAI0Ii8QIAAMEhMHc1Bs8cLxovAABgzInJ9f69NOjv8QKJS40AAACGkHgBAABj3AqTi+UkAAAAEGgkXgAAwJjaPrmexAsAAMAQEi8AAGCMW2E8MggAAACBR+IFAACMcVkOuSw/PzLIz+MFEo0XAAAwxhWA5SRcXGoEAADAqUi8AACAMW4rTG4/LyfhZjkJAAAAnIrECwAAGMMcLwAAABhB4gUAAIxxy//LP7j9OlpgkXgBAAAYQuIFAACMCcwjg4InR6LxAgAAxrisMLn8vJyEv8cLpOCpFAAAIMiReAEAAGPccsgtf0+uD55nNZJ4AQAAGELiBQAAjGGOFwAAAIwg8QIAAMYE5pFBwZMjBU+lAAAAQY7ECwAAGOO2HHL7+5FBfh4vkEi8AAAADCHxAgAAxrgDMMeLRwYBAABUw22Fye3n5R/8PV4gBU+lAAAAQY7GCwAAGOOSIyCbL+bOnavk5GRFRUUpLS1NW7ZsOePxy5cv16WXXqp69eopISFBd9xxhw4ePOjVOWm8AABArZOdna2xY8dq8uTJ2r59u7p06aLu3bsrPz+/2uPfeecdDRgwQEOGDNEnn3yiVatWKTc3V0OHDvXqvDReAADAmJNzvPy9eWvWrFkaMmSIhg4dqpSUFM2ePVuJiYmaN29etcdv27ZNrVu31pgxY5ScnKzOnTtr2LBh+uCDD7w6L40XAAAICSUlJR5bWVlZtceVl5crLy9PGRkZHvszMjL03nvvVfuajh07at++fdqwYYMsy9L333+vl156ST169PCqRhovAABgjEuBmOd1QmJiomJjYyu3rKysams4cOCAXC6X4uPjPfbHx8ersLCw2td07NhRy5cvV9++fRUZGanmzZurYcOGevLJJ716/zReAAAgJBQUFKi4uLhyy8zMPOPxDofnpHzLsqrsO+nTTz/VmDFjdP/99ysvL08bN27Unj17NHz4cK9qZB0vAABgTCDX8YqJiVFMTMwvHt+0aVOFh4dXSbeKioqqpGAnZWVlqVOnTrrnnnskSZdcconq16+vLl266KGHHlJCQkKNaiXxAgAAxrissIBs3oiMjFRaWppycnI89ufk5Khjx47Vvubo0aMKC/M8T3h4uKQTSVlN0XgBAIBaZ/z48VqwYIEWLVqkzz77TOPGjVN+fn7lpcPMzEwNGDCg8vhevXppzZo1mjdvnnbv3q13331XY8aM0eWXX64WLVrU+LxcagQAAMZYcsjt44KnZxrTW3379tXBgwc1depU7d+/X23bttWGDRuUlJQkSdq/f7/Hml6DBg3S4cOHNWfOHE2YMEENGzbUNddcoxkzZnh1XhovAABQK40YMUIjRoyo9ntLliypsm/06NEaPXr0rzonjRcAADDGlzlZNRkzWARPpQAAAEEuJBKvjS9foXBnlN1leKV02DG7S/BJ4boL7S7BZ89nP2F3CT7pu2ys3SX4pMeWe+0uwWcJn1XYXYJP2j6+z+4SfDLtzjvsLsFnzvwf7S7BKxWu6ldyN8ltOeS2/DvHy9/jBRKJFwAAgCEhkXgBAIDg4FKYXH7Offw9XiDReAEAAGO41AgAAAAjSLwAAIAxboXJ7efcx9/jBVLwVAoAABDkSLwAAIAxLsshl5/nZPl7vEAi8QIAADCExAsAABjDXY0AAAAwgsQLAAAYY1lhcvv5odZWED0km8YLAAAY45JDLvl5cr2fxwuk4GkRAQAAghyJFwAAMMZt+X8yvNvy63ABReIFAABgCIkXAAAwxh2AyfX+Hi+QgqdSAACAIEfiBQAAjHHLIbef70L093iBZGvilZWVpfbt2ys6OlpxcXG64YYb9MUXX9hZEgAAQMDY2ni9/fbbGjlypLZt26acnBxVVFQoIyNDR44csbMsAAAQICcfku3vLVjYeqlx48aNHl8vXrxYcXFxysvL01VXXWVTVQAAIFBq++T6s2qOV3FxsSSpcePG1X6/rKxMZWVllV+XlJQYqQsAAMAfzpoW0bIsjR8/Xp07d1bbtm2rPSYrK0uxsbGVW2JiouEqAQDAr+GWQ27LzxuT6703atQo7dy5UytXrjztMZmZmSouLq7cCgoKDFYIAADw65wVlxpHjx6t9evXa/PmzWrZsuVpj3M6nXI6nQYrAwAA/mQFYDkJK4gSL1sbL8uyNHr0aK1du1ZvvfWWkpOT7SwHAAAgoGxtvEaOHKkVK1Zo3bp1io6OVmFhoSQpNjZWdevWtbM0AAAQACfnZfl7zGBh6xyvefPmqbi4WF27dlVCQkLllp2dbWdZAAAAAWH7pUYAAFB7sI4XAACAIVxqBAAAgBEkXgAAwBh3AJaTYAFVAAAAVEHiBQAAjGGOFwAAAIwg8QIAAMaQeAEAAMAIEi8AAGBMbU+8aLwAAIAxtb3x4lIjAACAISReAADAGEv+X/A0mJ78TOIFAABgCIkXAAAwhjleAAAAMILECwAAGFPbE6+QaLwu/f3nqlM/0u4yvPLZcyl2l+CTf0ycY3cJPhvw5Di7S/BJnTp2V+CbOoeDabqrp9LG4XaX4JOlV6baXYJPUv+13e4SfPav56+0uwSvuMpKpbl2V1G7hUTjBQAAggOJFwAAgCG1vfFicj0AAIAhJF4AAMAYy3LI8nNC5e/xAonECwAAwBASLwAAYIxbDr8/Msjf4wUSiRcAAIAhJF4AAMAY7moEAACAESReAADAGO5qBAAAgBEkXgAAwJjaPseLxgsAABjDpUYAAAAYQeIFAACMsQJwqZHECwAAAFWQeAEAAGMsSZbl/zGDBYkXAACAISReAADAGLcccvCQbAAAAAQaiRcAADCmtq/jReMFAACMcVsOOWrxyvVcagQAADCExAsAABhjWQFYTiKI1pMg8QIAADCExAsAABhT2yfXk3gBAAAYQuIFAACMIfECAACAESReAADAmNq+jheNFwAAMIblJAAAAGAEiRcAADDmROLl78n1fh0uoEi8AAAADCHxAgAAxrCcBAAAQC00d+5cJScnKyoqSmlpadqyZcsZjy8rK9PkyZOVlJQkp9Op8847T4sWLfLqnCReAADAGOt/m7/H9FZ2drbGjh2ruXPnqlOnTnrmmWfUvXt3ffrpp2rVqlW1r+nTp4++//57LVy4UOeff76KiopUUVHh1XlpvAAAQK0za9YsDRkyREOHDpUkzZ49W6+//rrmzZunrKysKsdv3LhRb7/9tnbv3q3GjRtLklq3bu31ebnUCAAAjDk5x8vfmySVlJR4bGVlZdXWUF5erry8PGVkZHjsz8jI0HvvvVfta9avX6/09HTNnDlT55xzjn7zm9/oL3/5i44dO+bV+yfxAgAA5gTwWmNiYqLH7ilTpuiBBx6ocviBAwfkcrkUHx/vsT8+Pl6FhYXVnmL37t165513FBUVpbVr1+rAgQMaMWKEfvzxR6/medF4AQCAkFBQUKCYmJjKr51O5xmPdzg874a0LKvKvpPcbrccDoeWL1+u2NhYSScuV95888166qmnVLdu3RrVSOMFAADMCcByEvrfeDExMR6N1+k0bdpU4eHhVdKtoqKiKinYSQkJCTrnnHMqmy5JSklJkWVZ2rdvny644IIalcocLwAAUKtERkYqLS1NOTk5HvtzcnLUsWPHal/TqVMnfffdd/r5558r9+3atUthYWFq2bJljc9N4wUAAIw5+ZBsf2/eGj9+vBYsWKBFixbps88+07hx45Sfn6/hw4dLkjIzMzVgwIDK42+99VY1adJEd9xxhz799FNt3rxZ99xzjwYPHlzjy4wSlxoBAEAt1LdvXx08eFBTp07V/v371bZtW23YsEFJSUmSpP379ys/P7/y+AYNGignJ0ejR49Wenq6mjRpoj59+uihhx7y6rwOywqmR0t6KikpUWxsrK5N+Ysiws88ge5s8+3DwRk2Rj//y9fOz1bf31T9bcVnu8fbv2h3CT457K75vwDPNltLzre7BJ+0cP5kdwk++fpoM7tL8NmmDy+yuwSvuI+Vat/4+1VcXFyjuVD+dPJ3dutF9ymsXpRfx3YfLdU3gx+y5X15Kzh/+wMAAAQhLjUCAABzLEflXYh+HTNI0HgBAABjfJ0M/0tjBgsuNQIAABhC4gUAAMwJ4CODggGJFwAAgCEkXgAAwBgrAI8M8vsjiAKIxAsAAMAQEi8AAGBWEM3J8jcSLwAAAENIvAAAgDG1fY4XjRcAADCH5SQAAABgAokXAAAwyPG/zd9jBgcSLwAAAENIvAAAgDnM8QIAAIAJJF4AAMAcEi8AAACYcNY0XllZWXI4HBo7dqzdpQAAgECxHIHZgsRZcakxNzdX8+fP1yWXXGJ3KQAAIIAs68Tm7zGDhe2J188//6zbbrtNzz77rBo1amR3OQAAAAFje+M1cuRI9ejRQ9ddd90vHltWVqaSkhKPDQAABBErQFuQsPVS4wsvvKAPP/xQubm5NTo+KytLDz74YICrAgAACAzbEq+CggLdfffdWrZsmaKiomr0mszMTBUXF1duBQUFAa4SAAD4FZPr7ZGXl6eioiKlpaVV7nO5XNq8ebPmzJmjsrIyhYeHe7zG6XTK6XSaLhUAAMAvbGu8rr32Wn388cce++644w5deOGFmjhxYpWmCwAABD+HdWLz95jBwrbGKzo6Wm3btvXYV79+fTVp0qTKfgAAgFDg9Ryv5557Tq+99lrl1/fee68aNmyojh07au/evX4tDgAAhJhaflej143X9OnTVbduXUnS1q1bNWfOHM2cOVNNmzbVuHHjflUxb731lmbPnv2rxgAAAGcxJtd7p6CgQOeff74k6eWXX9bNN9+sP//5z+rUqZO6du3q7/oAAABChteJV4MGDXTw4EFJ0htvvFG58GlUVJSOHTvm3+oAAEBoqeWXGr1OvLp166ahQ4eqXbt22rVrl3r06CFJ+uSTT9S6dWt/1wcAABAyvE68nnrqKXXo0EE//PCDVq9erSZNmkg6sS5Xv379/F4gAAAIISRe3mnYsKHmzJlTZT+P8gEAADizGjVeO3fuVNu2bRUWFqadO3ee8dhLLrnEL4UBAIAQFIiEKtQSr9TUVBUWFiouLk6pqalyOByyrP/3Lk9+7XA45HK5AlYsAABAMKtR47Vnzx41a9as8r8BAAB8Eoh1t0JtHa+kpKRq//tU/zcFAwAAgCev72rs37+/fv755yr7v/nmG1111VV+KQoAAISmkw/J9vcWLLxuvD799FNdfPHFevfddyv3Pffcc7r00ksVHx/v1+IAAECIYTkJ7/znP//Rfffdp2uuuUYTJkzQl19+qY0bN+rvf/+7Bg8eHIgaAQAAQoLXjVdERIQeeeQROZ1OTZs2TREREXr77bfVoUOHQNQHAAAQMry+1Hj8+HFNmDBBM2bMUGZmpjp06KA//vGP2rBhQyDqAwAACBleJ17p6ek6evSo3nrrLV155ZWyLEszZ87UjTfeqMGDB2vu3LmBqBMAAIQAh/w/GT54FpPwsfH6xz/+ofr160s6sXjqxIkT9bvf/U6333673wusiaMtoxVRJ8qWc/sqseE+u0vwifXuj3aX4LPY/3j9x/2ssHNDK7tL8Mmyz9vbXYLP1l/xtN0l+OSoOzj/jP+5wJ7fHf5w7m8K7S7BKxVHyhScv31Ch9c/pQsXLqx2f2pqqvLy8n51QQAAIISxgKrvjh07puPHj3vsczqdv6ogAACAUOX15PojR45o1KhRiouLU4MGDdSoUSOPDQAA4LRq+TpeXjde9957rzZt2qS5c+fK6XRqwYIFevDBB9WiRQstXbo0EDUCAIBQUcsbL68vNb7yyitaunSpunbtqsGDB6tLly46//zzlZSUpOXLl+u2224LRJ0AAABBz+vE68cff1RycrIkKSYmRj/+eOIut86dO2vz5s3+rQ4AAIQUntXopXPPPVfffPONJOmiiy7Siy++KOlEEtawYUN/1gYAABBSvG687rjjDu3YsUOSlJmZWTnXa9y4cbrnnnv8XiAAAAghzPHyzrhx4yr/++qrr9bnn3+uDz74QOedd54uvfRSvxYHAAAQSn71MsetWrVSq1bBubI2AAAwLBAJVRAlXl5fagQAAIBvgvPBXgAAICgF4i7EkLyrcd8+HqsJAAB+pZPPavT3FiRq3Hi1bdtWzz//fCBrAQAACGk1brymT5+ukSNH6qabbtLBgwcDWRMAAAhVtXw5iRo3XiNGjNCOHTt06NAhtWnTRuvXrw9kXQAAACHHq8n1ycnJ2rRpk+bMmaObbrpJKSkpiojwHOLDDz/0a4EAACB01PbJ9V7f1bh3716tXr1ajRs3Vu/evas0XgAAAKieV13Ts88+qwkTJui6667Tf//7XzVr1ixQdQEAgFBUyxdQrXHj9fvf/17vv/++5syZowEDBgSyJgAAgJBU48bL5XJp586datmyZSDrAQAAoSwAc7xCMvHKyckJZB0AAKA2qOWXGnlWIwAAgCHckggAAMwh8QIAAIAJJF4AAMCY2r6AKokXAACAITReAAAAhtB4AQAAGMIcLwAAYE4tv6uRxgsAABjD5HoAAAAYQeIFAADMCqKEyt9IvAAAAAwh8QIAAObU8sn1JF4AAACGkHgBAABjuKsRAAAARtB4AQAAc6wAbT6YO3eukpOTFRUVpbS0NG3ZsqVGr3v33XcVERGh1NRUr89J4wUAAIw5eanR35u3srOzNXbsWE2ePFnbt29Xly5d1L17d+Xn55/xdcXFxRowYICuvfZan94/jRcAAKh1Zs2apSFDhmjo0KFKSUnR7NmzlZiYqHnz5p3xdcOGDdOtt96qDh06+HReGi8AAGBOAC81lpSUeGxlZWXVllBeXq68vDxlZGR47M/IyNB777132tIXL16sr7/+WlOmTPHlnUui8QIAACEiMTFRsbGxlVtWVla1xx04cEAul0vx8fEe++Pj41VYWFjta7788ktNmjRJy5cvV0SE74tCsJwEAAAwJ4ALqBYUFCgmJqZyt9PpPOPLHA6H5zCWVWWfJLlcLt1666168MEH9Zvf/OZXlUrjBQAAQkJMTIxH43U6TZs2VXh4eJV0q6ioqEoKJkmHDx/WBx98oO3bt2vUqFGSJLfbLcuyFBERoTfeeEPXXHNNjWqk8QIAAMacDQuoRkZGKi0tTTk5OfrjH/9YuT8nJ0e9e/eucnxMTIw+/vhjj31z587Vpk2b9NJLLyk5ObnG5w6Jxqu0SYTCI4PrrdQffOb482zlPvyD3SX4bNdDF9tdgk9+eijR7hJ8UnaN2+4SfPZhaUu7S/DJnMl97C7BJ3c//JLdJfhsRdf2dpfglQr3cbtLOGuMHz9e/fv3V3p6ujp06KD58+crPz9fw4cPlyRlZmbq22+/1dKlSxUWFqa2bdt6vD4uLk5RUVFV9v+S4OpWAABAcDtLHpLdt29fHTx4UFOnTtX+/fvVtm1bbdiwQUlJSZKk/fv3/+KaXr6g8QIAAOacJY2XJI0YMUIjRoyo9ntLliw542sfeOABPfDAA16fk+UkAAAADCHxAgAAxpwNk+vtROIFAABgCIkXAAAw5yya42UHEi8AAABDSLwAAIAxzPECAACAESReAADAnFo+x4vGCwAAmFPLGy8uNQIAABhC4gUAAIxx/G/z95jBgsQLAADAEBIvAABgDnO8AAAAYAKJFwAAMIYFVAEAAGCE7Y3Xt99+q9tvv11NmjRRvXr1lJqaqry8PLvLAgAAgWAFaAsStl5qPHTokDp16qSrr75a//znPxUXF6evv/5aDRs2tLMsAAAQSEHUKPmbrY3XjBkzlJiYqMWLF1fua926tX0FAQAABJCtlxrXr1+v9PR03XLLLYqLi1O7du307LPPnvb4srIylZSUeGwAACB4nJxc7+8tWNjaeO3evVvz5s3TBRdcoNdff13Dhw/XmDFjtHTp0mqPz8rKUmxsbOWWmJhouGIAAADf2dp4ud1uXXbZZZo+fbratWunYcOG6c4779S8efOqPT4zM1PFxcWVW0FBgeGKAQDAr1LLJ9fb2nglJCTooosu8tiXkpKi/Pz8ao93Op2KiYnx2AAAAIKFrZPrO3XqpC+++MJj365du5SUlGRTRQAAIJBYQNVG48aN07Zt2zR9+nR99dVXWrFihebPn6+RI0faWRYAAEBA2Np4tW/fXmvXrtXKlSvVtm1bTZs2TbNnz9Ztt91mZ1kAACBQavkcL9uf1dizZ0/17NnT7jIAAAACzvbGCwAA1B61fY4XjRcAADAnEJcGg6jxsv0h2QAAALUFiRcAADCHxAsAAAAmkHgBAABjavvkehIvAAAAQ0i8AACAOczxAgAAgAkkXgAAwBiHZclh+Tei8vd4gUTjBQAAzOFSIwAAAEwg8QIAAMawnAQAAACMIPECAADmMMcLAAAAJoRE4tXovz8pItxpdxleKeqaYHcJPsl96GW7S/BZWt45dpfgE9cHje0uwSeJG+2uwHdfdAjOn8+hD621uwSf/O2Nm+0uwWcXNjpkdwlesVxlUqG9NTDHCwAAAEaEROIFAACCRC2f40XjBQAAjOFSIwAAAIwg8QIAAObU8kuNJF4AAACGkHgBAACjgmlOlr+ReAEAABhC4gUAAMyxrBObv8cMEiReAAAAhpB4AQAAY2r7Ol40XgAAwByWkwAAAIAJJF4AAMAYh/vE5u8xgwWJFwAAgCEkXgAAwBzmeAEAAMAEEi8AAGBMbV9OgsQLAADAEBIvAABgTi1/ZBCNFwAAMIZLjQAAADCCxAsAAJjDchIAAAAwgcQLAAAYwxwvAAAAGEHiBQAAzKnly0mQeAEAABhC4gUAAIyp7XO8aLwAAIA5LCcBAAAAE0i8AACAMbX9UiOJFwAAgCEkXgAAwBy3dWLz95hBgsQLAADAEBIvAABgDnc1AgAAwAQSLwAAYIxDAbir0b/DBRSNFwAAMIdnNQIAANQ+c+fOVXJysqKiopSWlqYtW7ac9tg1a9aoW7duatasmWJiYtShQwe9/vrrXp+TxgsAABhzcgFVf2/eys7O1tixYzV58mRt375dXbp0Uffu3ZWfn1/t8Zs3b1a3bt20YcMG5eXl6eqrr1avXr20fft2r85L4wUAAGqdWbNmaciQIRo6dKhSUlI0e/ZsJSYmat68edUeP3v2bN17771q3769LrjgAk2fPl0XXHCBXnnlFa/OS+MFAADMsQK0SSopKfHYysrKqi2hvLxceXl5ysjI8NifkZGh9957r0Zvw+126/Dhw2rcuHFN37kkGi8AABAiEhMTFRsbW7llZWVVe9yBAwfkcrkUHx/vsT8+Pl6FhYU1Otfjjz+uI0eOqE+fPl7VyF2NAADAGIdlyeHnuxBPjldQUKCYmJjK/U6n88yvc3guRGFZVpV91Vm5cqUeeOABrVu3TnFxcV7VGhKN13ddGyncGWV3GV4Jpiep/1+/a5Fqdwk+G//Fm3aX4JN/hHn3r6mzxcGLgvevl0MV9ewuwSfLXr/J7hJ8YsW47C7BZ/M3LrK7BK8cPuxW24vsriJwYmJiPBqv02natKnCw8OrpFtFRUVVUrBTZWdna8iQIVq1apWuu+46r2vkUiMAADDHHaDNC5GRkUpLS1NOTo7H/pycHHXs2PG0r1u5cqUGDRqkFStWqEePHt6d9H+C95+kAAAg6ATyUqM3xo8fr/79+ys9PV0dOnTQ/PnzlZ+fr+HDh0uSMjMz9e2332rp0qWSTjRdAwYM0N///nddeeWVlWlZ3bp1FRsbW+Pz0ngBAIBap2/fvjp48KCmTp2q/fv3q23bttqwYYOSkpIkSfv37/dY0+uZZ55RRUWFRo4cqZEjR1buHzhwoJYsWVLj89J4AQAAc/7P8g9+HdMHI0aM0IgRI6r93qnN1FtvveXbSU7BHC8AAABDSLwAAIA5PCQbAAAAJpB4AQAAY3x9qPUvjRksSLwAAAAMIfECAADmMMcLAAAAJpB4AQAAYxzuE5u/xwwWNF4AAMAcLjUCAADABBIvAABgzln0yCA7kHgBAAAYQuIFAACMcViWHH6ek+Xv8QKJxAsAAMAQEi8AAGAOdzXap6KiQvfdd5+Sk5NVt25dnXvuuZo6darc7iBakAMAAKCGbE28ZsyYoaefflrPPfec2rRpow8++EB33HGHYmNjdffdd9tZGgAACARLkr/zleAJvOxtvLZu3arevXurR48ekqTWrVtr5cqV+uCDD6o9vqysTGVlZZVfl5SUGKkTAAD4B5PrbdS5c2e9+eab2rVrlyRpx44deuedd/SHP/yh2uOzsrIUGxtbuSUmJposFwAA4FexNfGaOHGiiouLdeGFFyo8PFwul0sPP/yw+vXrV+3xmZmZGj9+fOXXJSUlNF8AAAQTSwGYXO/f4QLJ1sYrOztby5Yt04oVK9SmTRt99NFHGjt2rFq0aKGBAwdWOd7pdMrpdNpQKQAAwK9na+N1zz33aNKkSfrTn/4kSbr44ou1d+9eZWVlVdt4AQCAIMdyEvY5evSowsI8SwgPD2c5CQAAEJJsTbx69eqlhx9+WK1atVKbNm20fft2zZo1S4MHD7azLAAAEChuSY4AjBkkbG28nnzySf3tb3/TiBEjVFRUpBYtWmjYsGG6//777SwLAAAgIGxtvKKjozV79mzNnj3bzjIAAIAhtX0dL57VCAAAzGFyPQAAAEwg8QIAAOaQeAEAAMAEEi8AAGAOiRcAAABMIPECAADm1PIFVEm8AAAADCHxAgAAxrCAKgAAgClMrgcAAIAJJF4AAMActyU5/JxQuUm8AAAAcAoSLwAAYA5zvAAAAGACiRcAADAoAImXgifxConGK6LUUngQTayTpKYfHbW7BJ/smne53SX4rHWdD+0uwSdNNnxhdwk+qXvleXaX4LN1F1xqdwk+iSy3uwLfOOpV2F2Cz/6/l/5idwlecZeWSrrP7jJqtZBovAAAQJCo5XO8aLwAAIA5bkt+vzQYRFe9mFwPAABgCIkXAAAwx3Kf2Pw9ZpAg8QIAADCExAsAAJhTyyfXk3gBAAAYQuIFAADM4a5GAAAAmEDiBQAAzKnlc7xovAAAgDmWAtB4+Xe4QOJSIwAAgCEkXgAAwJxafqmRxAsAAMAQEi8AAGCO2y3Jz4/4cfPIIAAAAJyCxAsAAJjDHC8AAACYQOIFAADMqeWJF40XAAAwh2c1AgAAwAQSLwAAYIxluWVZ/l3+wd/jBRKJFwAAgCEkXgAAwBzL8v+crCCaXE/iBQAAYAiJFwAAMMcKwF2NJF4AAAA4FYkXAAAwx+2WHH6+CzGI7mqk8QIAAOZwqREAAAAmkHgBAABjLLdblp8vNbKAKgAAAKog8QIAAOYwxwsAAAAmkHgBAABz3JbkIPECAABAgJF4AQAAcyxLkr8XUCXxAgAAwClIvAAAgDGW25Ll5zleVhAlXjReAADAHMst/19qZAFVAAAAnILECwAAGFPbLzWSeAEAABhC4gUAAMyp5XO8grrxOhktuspLba7EexUVwVezJLmPBU+ce6ojh4PnB/P/qnCX212CTyqOB+efcUlyHwvOPyvu0iCt+1iZ3SX4zBFkn7m79MTPpZ2X5ip03O+PaqzQcf8OGEAOK5gujJ5i3759SkxMtLsMAACCSkFBgVq2bGn0nKWlpUpOTlZhYWFAxm/evLn27NmjqKiogIzvL0HdeLndbn333XeKjo6Ww+Hw69glJSVKTExUQUGBYmJi/Do2qsdnbhaft1l83ubxmVdlWZYOHz6sFi1aKCzM/DTv0tJSlZcHJsWPjIw865suKcgvNYaFhQW8Y4+JieEH1jA+c7P4vM3i8zaPz9xTbGysbeeOiooKiuYokLirEQAAwBAaLwAAAENovE7D6XRqypQpcjqddpdSa/CZm8XnbRaft3l85jgbBfXkegAAgGBC4gUAAGAIjRcAAIAhNF4AAACG0HgBAAAYQuN1GnPnzlVycrKioqKUlpamLVu22F1SSMrKylL79u0VHR2tuLg43XDDDfriiy/sLqvWyMrKksPh0NixY+0uJaR9++23uv3229WkSRPVq1dPqampysvLs7uskFRRUaH77rtPycnJqlu3rs4991xNnTpVbndwPVMRoYvGqxrZ2dkaO3asJk+erO3bt6tLly7q3r278vPz7S4t5Lz99tsaOXKktm3bppycHFVUVCgjI0NHjhyxu7SQl5ubq/nz5+uSSy6xu5SQdujQIXXq1El16tTRP//5T3366ad6/PHH1bBhQ7tLC0kzZszQ008/rTlz5uizzz7TzJkz9eijj+rJJ5+0uzRAEstJVOuKK67QZZddpnnz5lXuS0lJ0Q033KCsrCwbKwt9P/zwg+Li4vT222/rqquusruckPXzzz/rsssu09y5c/XQQw8pNTVVs2fPtruskDRp0iS9++67pOaG9OzZU/Hx8Vq4cGHlvptuukn16tXT888/b2NlwAkkXqcoLy9XXl6eMjIyPPZnZGTovffes6mq2qO4uFiS1LhxY5srCW0jR45Ujx49dN1119ldSshbv3690tPTdcsttyguLk7t2rXTs88+a3dZIatz58568803tWvXLknSjh079M477+gPf/iDzZUBJwT1Q7ID4cCBA3K5XIqPj/fYHx8fr8LCQpuqqh0sy9L48ePVuXNntW3b1u5yQtYLL7ygDz/8ULm5uXaXUivs3r1b8+bN0/jx4/XXv/5V77//vsaMGSOn06kBAwbYXV7ImThxooqLi3XhhRcqPDxcLpdLDz/8sPr162d3aYAkGq/TcjgcHl9bllVlH/xr1KhR2rlzp9555x27SwlZBQUFuvvuu/XGG28oKirK7nJqBbfbrfT0dE2fPl2S1K5dO33yySeaN28ejVcAZGdna9myZVqxYoXatGmjjz76SGPHjlWLFi00cOBAu8sDaLxO1bRpU4WHh1dJt4qKiqqkYPCf0aNHa/369dq8ebNatmxpdzkhKy8vT0VFRUpLS6vc53K5tHnzZs2ZM0dlZWUKDw+3scLQk5CQoIsuushjX0pKilavXm1TRaHtnnvu0aRJk/SnP/1JknTxxRdr7969ysrKovHCWYE5XqeIjIxUWlqacnJyPPbn5OSoY8eONlUVuizL0qhRo7RmzRpt2rRJycnJdpcU0q699lp9/PHH+uijjyq39PR03Xbbbfroo49ougKgU6dOVZZI2bVrl5KSkmyqKLQdPXpUYWGev9rCw8NZTgJnDRKvaowfP179+/dXenq6OnTooPnz5ys/P1/Dhw+3u7SQM3LkSK1YsULr1q1TdHR0ZdIYGxurunXr2lxd6ImOjq4yf65+/fpq0qQJ8+oCZNy4cerYsaOmT5+uPn366P3339f8+fM1f/58u0sLSb169dLDDz+sVq1aqU2bNtq+fbtmzZqlwYMH210aIInlJE5r7ty5mjlzpvbv36+2bdvqiSeeYHmDADjdvLnFixdr0KBBZouppbp27cpyEgH26quvKjMzU19++aWSk5M1fvx43XnnnXaXFZIOHz6sv/3tb1q7dq2KiorUokUL9evXT/fff78iIyPtLg+g8QIAADCFOV4AAACG0HgBAAAYQuMFAABgCI0XAACAITReAAAAhtB4AQAAGELjBQAAYAiNFwAAgCE0XgBs53A49PLLL9tdBgAEHI0XALlcLnXs2FE33XSTx/7i4mIlJibqvvvuC+j59+/fr+7duwf0HABwNuCRQQAkSV9++aVSU1M1f/583XbbbZKkAQMGaMeOHcrNzeU5dwDgByReACRJF1xwgbKysjR69Gh99913WrdunV544QU999xzZ2y6li1bpvT0dEVHR6t58+a69dZbVVRUVPn9qVOnqkWLFjp48GDlvuuvv15XXXWV3G63JM9LjeXl5Ro1apQSEhIUFRWl1q1bKysrKzBvGgAMI/ECUMmyLF1zzTUKDw/Xxx9/rNGjR//iZcZFixYpISFBv/3tb1VUVKRx48apUaNG2rBhg6QTlzG7dOmi+Ph4rV27Vk8//bQmTZqkHTt2KCkpSdKJxmvt2rW64YYb9Nhjj+kf//iHli9frlatWqmgoEAFBQXq169fwN8/AAQajRcAD59//rlSUlJ08cUX68MPP1RERIRXr8/NzdXll1+uw4cPq0GDBpKk3bt3KzU1VSNGjNCTTz7pcTlT8my8xowZo08++UT/+te/5HA4/PreAMBuXGoE4GHRokWqV6+e9uzZo3379v3i8du3b1fv3r2VlJSk6Ohode3aVZKUn59fecy5556rxx57TDNmzFCvXr08mq5TDRo0SB999JF++9vfasyYMXrjjTd+9XsCgLMFjReASlu3btUTTzyhdevWqUOHDhoyZIjOFIofOXJEGRkZatCggZYtW6bc3FytXbtW0om5Wv/X5s2bFR4erm+++UYVFRWnHfOyyy7Tnj17NG3aNB07dkx9+vTRzTff7J83CAA2o/ECIEk6duyYBg4cqGHDhum6667TggULlJubq2eeeea0r/n888914MABPfLII+rSpYsuvPBCj4n1J2VnZ2vNmjV66623VFBQoGnTpp2xlpiYGPXt21fPPvussrOztXr1av3444+/+j0CgN1ovABIkiZNmiS3260ZM2ZIklq1aqXHH39c99xzj7755ptqX9OqVStFRkbqySef1O7du7V+/foqTdW+fft01113acaMGercubOWLFmirKwsbdu2rdoxn3jiCb3wwgv6/PPPtWvXLq1atUrNmzdXw4YN/fl2AcAWNF4A9Pbbb+upp57SkiVLVL9+/cr9d955pzp27HjaS47NmjXTkiVLtGrVKl100UV65JFH9Nhjj1V+37IsDRo0SJdffrlGjRolSerWrZtGjRql22+/XT///HOVMRs0aKAZM2YoPT1d7du31zfffKMNGzYoLIy/rgAEP+5qBAAAMIR/QgIAABhC4wUAAGAIjRcAAIAhNF4AAACG0HgBAAAYQuMFAABgCI0XAACAITReAAAAhtB4AQAAGELjBQAAYAiNFwAAgCH/P2+MRE5hrzKxAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 800x600 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "import argparse\n",
    "import torch\n",
    "import torch.nn as nn \n",
    "import torch.nn.functional as F\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.optim as optim\n",
    "import torch.optim.lr_scheduler as lr_scheduler\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "import torchvision\n",
    "import torchvision.datasets\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import time\n",
    "\n",
    "from snntorch import spikegen\n",
    "import matplotlib.pyplot as plt\n",
    "import snntorch.spikeplot as splt\n",
    "from IPython.display import HTML\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "from apex.parallel import DistributedDataParallel as DDP\n",
    "\n",
    "import random\n",
    "import datetime\n",
    "\n",
    "import json\n",
    "\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "''' 레퍼런스\n",
    "https://spikingjelly.readthedocs.io/zh-cn/0.0.0.0.4/spikingjelly.datasets.html#module-spikingjelly.datasets\n",
    "https://github.com/GorkaAbad/Sneaky-Spikes/blob/main/datasets.py\n",
    "https://github.com/GorkaAbad/Sneaky-Spikes/blob/main/how_to.md\n",
    "https://github.com/nmi-lab/torchneuromorphic\n",
    "https://snntorch.readthedocs.io/en/latest/snntorch.spikevision.spikedata.html#shd\n",
    "'''\n",
    "\n",
    "import snntorch\n",
    "from snntorch.spikevision import spikedata\n",
    "\n",
    "import modules.spikingjelly;\n",
    "from modules.spikingjelly.datasets.dvs128_gesture import DVS128Gesture\n",
    "from modules.spikingjelly.datasets.cifar10_dvs import CIFAR10DVS\n",
    "from modules.spikingjelly.datasets.n_mnist import NMNIST\n",
    "# from modules.spikingjelly.datasets.es_imagenet import ESImageNet\n",
    "from modules.spikingjelly.datasets import split_to_train_test_set\n",
    "from modules.spikingjelly.datasets.n_caltech101 import NCaltech101\n",
    "from modules.spikingjelly.datasets import pad_sequence_collate, padded_sequence_mask\n",
    "\n",
    "import modules.torchneuromorphic as torchneuromorphic\n",
    "\n",
    "import wandb\n",
    "\n",
    "from torchviz import make_dot\n",
    "import graphviz\n",
    "from turtle import shape\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# my module import\n",
    "from modules import *\n",
    "\n",
    "# modules 폴더에 새모듈.py 만들면\n",
    "# modules/__init__py 파일에 form .새모듈 import * 하셈\n",
    "# 그리고 새모듈.py에서 from modules.새모듈 import * 하셈\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def my_snn_system(devices = \"0,1,2,3\",\n",
    "                    single_step = False, # True # False\n",
    "                    unique_name = 'main',\n",
    "                    my_seed = 42,\n",
    "                    TIME = 10,\n",
    "                    BATCH = 256,\n",
    "                    IMAGE_SIZE = 32,\n",
    "                    which_data = 'CIFAR10',\n",
    "                    # CLASS_NUM = 10,\n",
    "                    data_path = '/data2',\n",
    "                    rate_coding = True,\n",
    "    \n",
    "                    lif_layer_v_init = 0.0,\n",
    "                    lif_layer_v_decay = 0.6,\n",
    "                    lif_layer_v_threshold = 1.2,\n",
    "                    lif_layer_v_reset = 0.0,\n",
    "                    lif_layer_sg_width = 1,\n",
    "\n",
    "                    # synapse_conv_in_channels = IMAGE_PIXEL_CHANNEL,\n",
    "                    synapse_conv_kernel_size = 3,\n",
    "                    synapse_conv_stride = 1,\n",
    "                    synapse_conv_padding = 1,\n",
    "\n",
    "                    synapse_trace_const1 = 1,\n",
    "                    synapse_trace_const2 = 0.6,\n",
    "\n",
    "                    # synapse_fc_out_features = CLASS_NUM,\n",
    "\n",
    "                    pre_trained = False,\n",
    "                    convTrue_fcFalse = True,\n",
    "\n",
    "                    cfg = [64, 64],\n",
    "                    net_print = False, # True # False\n",
    "                    \n",
    "                    pre_trained_path = \"net_save/save_now_net.pth\",\n",
    "                    learning_rate = 0.0001,\n",
    "                    epoch_num = 200,\n",
    "                    tdBN_on = False,\n",
    "                    BN_on = False,\n",
    "\n",
    "                    surrogate = 'sigmoid',\n",
    "\n",
    "                    BPTT_on = False,\n",
    "\n",
    "                    optimizer_what = 'SGD', # 'SGD' 'Adam', 'RMSprop'\n",
    "                    scheduler_name = 'no',\n",
    "                    \n",
    "                    ddp_on = False, # DECREPATED # fALSE\n",
    "\n",
    "                    dvs_clipping = 1, \n",
    "                    dvs_duration = 25_000,\n",
    "\n",
    "\n",
    "                    DFA_on = False, # True # False\n",
    "                    trace_on = False, \n",
    "                    OTTT_input_trace_on = False, # True # False\n",
    "                    \n",
    "                    exclude_class = True, # True # False # gesture에서 10번째 클래스 제외\n",
    "\n",
    "                    merge_polarities = False, # True # False # tonic dvs dataset 에서 polarities 합치기\n",
    "                    denoise_on = True, \n",
    "\n",
    "                    extra_train_dataset = 0, # DECREPATED # data_loader에서 train dataset을 몇개 더 쓸건지 \n",
    "\n",
    "                    num_workers = 2,\n",
    "                    chaching_on = True,\n",
    "                    pin_memory = True, # True # False\n",
    "                    \n",
    "                    UDA_on = False,  # DECREPATED # uda\n",
    "                    alpha_uda = 1.0, # DECREPATED # uda\n",
    "\n",
    "                    bias = True,\n",
    "\n",
    "                    last_lif = False,\n",
    "                        \n",
    "                    temporal_filter = 1, \n",
    "                    initial_pooling = 1,\n",
    "\n",
    "                    temporal_filter_accumulation = False,\n",
    "                    ):\n",
    "    ## 함수 내 모든 로컬 변수 저장 ########################################################\n",
    "    hyperparameters = locals()\n",
    "    print('param', hyperparameters,'\\n')\n",
    "    hyperparameters['current epoch'] = 0\n",
    "    ######################################################################################\n",
    "\n",
    "    ## hyperparameter check #############################################################\n",
    "    if single_step == True:\n",
    "        assert BPTT_on == False and tdBN_on == False \n",
    "    if tdBN_on == True:\n",
    "        assert BPTT_on == True\n",
    "    if pre_trained == True:\n",
    "        print('\\n\\n')\n",
    "        print(\"Caution! pre_trained is True\\n\\n\"*3)    \n",
    "    if DFA_on == True:\n",
    "        assert single_step == True and BPTT_on == False \n",
    "    # assert single_step == DFA_on, 'DFA랑 single_step공존하게해라'\n",
    "    if trace_on:\n",
    "        assert BPTT_on == False and single_step == True\n",
    "    if OTTT_input_trace_on == True:\n",
    "        assert BPTT_on == False and single_step == True #and trace_on == True\n",
    "    if temporal_filter > 1:\n",
    "        assert convTrue_fcFalse == False\n",
    "    ######################################################################################\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "    ## wandb 세팅 ###################################################################\n",
    "    current_time = datetime.datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "    wandb.config.update(hyperparameters)\n",
    "    wandb.run.name = f'lr_{learning_rate}_{unique_name}_{which_data}_tstep{TIME}'\n",
    "    wandb.define_metric(\"summary_val_acc\", summary=\"max\")\n",
    "    # wandb.run.log_code(\".\", \n",
    "    #                     include_fn=lambda path: path.endswith(\".py\") or path.endswith(\".ipynb\"),\n",
    "    #                     exclude_fn=lambda path: 'logs/' in path or 'net_save/' in path or 'result_save/' in path or 'trying/' in path or 'wandb/' in path or 'private/' in path or '.git/' in path or 'tonic' in path or 'torchneuromorphic' in path or 'spikingjelly' in path \n",
    "    #                     )\n",
    "    ###################################################################################\n",
    "\n",
    "\n",
    "\n",
    "    ## gpu setting ##################################################################################################################\n",
    "    os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\" \n",
    "    os.environ[\"CUDA_VISIBLE_DEVICES\"]= devices\n",
    "    ###################################################################################################################################\n",
    "\n",
    "\n",
    "    ## seed setting ##################################################################################################################\n",
    "    seed_assign(my_seed)\n",
    "    ###################################################################################################################################\n",
    "    \n",
    "\n",
    "    ## data_loader 가져오기 ##################################################################################################################\n",
    "    # data loader, pixel channel, class num\n",
    "    train_data_split_indices = []\n",
    "    train_loader, test_loader, synapse_conv_in_channels, CLASS_NUM, train_data_count = data_loader(\n",
    "            which_data,\n",
    "            data_path, \n",
    "            rate_coding, \n",
    "            BATCH, \n",
    "            IMAGE_SIZE,\n",
    "            ddp_on,\n",
    "            TIME*temporal_filter, \n",
    "            dvs_clipping,\n",
    "            dvs_duration,\n",
    "            exclude_class,\n",
    "            merge_polarities,\n",
    "            denoise_on,\n",
    "            my_seed,\n",
    "            extra_train_dataset,\n",
    "            num_workers,\n",
    "            chaching_on,\n",
    "            pin_memory,\n",
    "            train_data_split_indices,) \n",
    "    synapse_fc_out_features = CLASS_NUM\n",
    "\n",
    "    print('\\nlen(train_loader):', len(train_loader), 'BATCH:', BATCH, 'train_data_count:', train_data_count) \n",
    "    print('len(test_loader):', len(test_loader), 'BATCH:', BATCH)\n",
    "\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    print(f\"\\ndevice ==> {device}\\n\")\n",
    "    if device == \"cpu\":\n",
    "        print(\"=\"*50,\"\\n[WARNING]\\n[WARNING]\\n[WARNING]\\n: cpu mode\\n\\n\",\"=\"*50)\n",
    "\n",
    "    ### network setting #######################################################################################################################\n",
    "    if (convTrue_fcFalse == False):\n",
    "        net = REBORN_MY_SNN_FC(cfg, synapse_conv_in_channels*temporal_filter, IMAGE_SIZE//initial_pooling, synapse_fc_out_features,\n",
    "                    synapse_trace_const1, synapse_trace_const2, \n",
    "                    lif_layer_v_init, lif_layer_v_decay, \n",
    "                    lif_layer_v_threshold, lif_layer_v_reset,\n",
    "                    lif_layer_sg_width,\n",
    "                    tdBN_on,\n",
    "                    BN_on, TIME,\n",
    "                    surrogate,\n",
    "                    BPTT_on,\n",
    "                    DFA_on,\n",
    "                    bias,\n",
    "                    single_step,\n",
    "                    last_lif,\n",
    "                    trace_on).to(device)\n",
    "    else:\n",
    "        net = REBORN_MY_SNN_CONV(cfg, synapse_conv_in_channels, IMAGE_SIZE//initial_pooling,\n",
    "                    synapse_conv_kernel_size, synapse_conv_stride, \n",
    "                    synapse_conv_padding, synapse_trace_const1, \n",
    "                    synapse_trace_const2, \n",
    "                    lif_layer_v_init, lif_layer_v_decay, \n",
    "                    lif_layer_v_threshold, lif_layer_v_reset,\n",
    "                    lif_layer_sg_width,\n",
    "                    synapse_fc_out_features, \n",
    "                    tdBN_on,\n",
    "                    BN_on, TIME,\n",
    "                    surrogate,\n",
    "                    BPTT_on,\n",
    "                    DFA_on,\n",
    "                    bias,\n",
    "                    single_step,\n",
    "                    last_lif,\n",
    "                    trace_on).to(device)\n",
    "\n",
    "    net = torch.nn.DataParallel(net) \n",
    "    \n",
    "    if pre_trained == True:\n",
    "        net.load_state_dict(torch.load(pre_trained_path))\n",
    "    \n",
    "    net = net.to(device)\n",
    "    if (net_print == True):\n",
    "        print(net)    \n",
    "\n",
    "    print(f\"\\n========================================================\\nTrainable parameters: {sum(p.numel() for p in net.parameters() if p.requires_grad):,}\\n========================================================\\n\")\n",
    "    ####################################################################################################################################\n",
    "    \n",
    "\n",
    "    ## wandb logging ###########################################\n",
    "    # wandb.watch(net, log=\"all\", log_freq = 10) #gradient, parameter logging해줌\n",
    "    ############################################################\n",
    "\n",
    "    ## criterion ########################################## # loss 구해주는 친구\n",
    "    def my_cross_entropy_loss(logits, targets):\n",
    "        # logits: (batch_size, num_classes)\n",
    "        # targets: (batch_size,) -> 클래스 인덱스\n",
    "        log_probs = F.log_softmax(logits, dim=1)  # log(p_i)\n",
    "        loss = F.nll_loss(log_probs, targets)\n",
    "        # print(loss.shape)\n",
    "        return loss\n",
    "    \n",
    "    class CustomLossFunction(torch.autograd.Function):\n",
    "        @staticmethod\n",
    "        def forward(ctx, input, target):\n",
    "            # MSE를 계산\n",
    "            ctx.save_for_backward(input, target)\n",
    "            target_one_hot = torch.zeros_like(input).scatter_(1, target.unsqueeze(1), 1.0)\n",
    "            return torch.mean((input - target_one_hot) ** 2)\n",
    "\n",
    "        @staticmethod\n",
    "        def backward(ctx, grad_output):\n",
    "            # MAE 스타일의 gradient를 흉내냄\n",
    "            input, target = ctx.saved_tensors\n",
    "            input_argmax = input.argmax(dim=1)\n",
    "            input_one_hot = torch.zeros_like(input).scatter_(1, input_argmax.unsqueeze(1), 1.0)\n",
    "            target_one_hot = torch.zeros_like(input).scatter_(1, target.unsqueeze(1), 1.0)\n",
    "            # print('grad_output', grad_output) # 이거 걍 1.0임\n",
    "            return input_one_hot - target_one_hot, None  # target에는 gradient 없음\n",
    "\n",
    "    # Wrapper module\n",
    "    class CustomCriterion(torch.nn.Module):\n",
    "        def __init__(self):\n",
    "            super().__init__()\n",
    "\n",
    "        def forward(self, input, target):\n",
    "            return CustomLossFunction.apply(input, target)\n",
    "\n",
    "    # criterion = nn.CrossEntropyLoss().to(device)\n",
    "    criterion = CustomCriterion().to(device)\n",
    "    \n",
    "    # if (OTTT_sWS_on == True):\n",
    "    #     # criterion = nn.CrossEntropyLoss().to(device)\n",
    "        # criterion = lambda y_t, target_t: ((1 - 0.05) * F.cross_entropy(y_t, target_t) + 0.05 * F.mse_loss(y_t, F.one_hot(target_t, CLASS_NUM).float())) / TIME \n",
    "    #     if which_data == 'DVS_GESTURE':\n",
    "    #         criterion = lambda y_t, target_t: ((1 - 0.001) * F.cross_entropy(y_t, target_t) + 0.001 * F.mse_loss(y_t, F.one_hot(target_t, CLASS_NUM).float())) / TIME \n",
    "    \n",
    "    print('current loss function:', criterion)\n",
    "    ####################################################\n",
    "    \n",
    "    ## optimizer, scheduler ########################################################################\n",
    "    if(optimizer_what == 'SGD'):\n",
    "        optimizer = optim.SGD(net.parameters(), lr=learning_rate, momentum=0.9)\n",
    "        # optimizer = optim.SGD(net.parameters(), lr=learning_rate, momentum=0.9, weight_decay=0)\n",
    "    elif(optimizer_what == 'Adam'):\n",
    "        optimizer = torch.optim.Adam(net.parameters(), lr=learning_rate)\n",
    "        # optimizer = torch.optim.Adam(net.parameters(), lr=0.00001)\n",
    "        # optimizer = torch.optim.Adam(net.parameters(), lr=learning_rate/256 * BATCH, weight_decay=1e-4)\n",
    "        # optimizer = optim.Adam(net.parameters(), lr=learning_rate, weight_decay=0, betas=(0.9, 0.999))\n",
    "    elif(optimizer_what == 'RMSprop'):\n",
    "        pass\n",
    "\n",
    "\n",
    "    if (scheduler_name == 'StepLR'):\n",
    "        scheduler = lr_scheduler.StepLR(optimizer, step_size=10, gamma=0.1)\n",
    "    elif (scheduler_name == 'ExponentialLR'):\n",
    "        scheduler = lr_scheduler.ExponentialLR(optimizer, gamma=0.95)\n",
    "    elif (scheduler_name == 'ReduceLROnPlateau'):\n",
    "        scheduler = lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.1, patience=10)\n",
    "    elif (scheduler_name == 'CosineAnnealingLR'):\n",
    "        # scheduler = lr_scheduler.CosineAnnealingLR(optimizer, eta_min=0, T_max=50)\n",
    "        scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, eta_min=0, T_max=epoch_num)\n",
    "    elif (scheduler_name == 'OneCycleLR'):\n",
    "        scheduler = lr_scheduler.OneCycleLR(optimizer, max_lr=0.1, steps_per_epoch=len(train_loader), epochs=epoch_num)\n",
    "    else:\n",
    "        pass # 'no' scheduler\n",
    "    ## optimizer, scheduler ########################################################################\n",
    "\n",
    "\n",
    "    tr_acc = 0\n",
    "    tr_correct = 0\n",
    "    tr_total = 0\n",
    "    tr_acc_best = 0\n",
    "    tr_epoch_loss_temp = 0\n",
    "    tr_epoch_loss = 0\n",
    "    val_acc_best = 0\n",
    "    val_acc_now = 0\n",
    "    val_loss = 0\n",
    "    iter_of_val = False\n",
    "    #======== EPOCH START ==========================================================================================\n",
    "    for epoch in range(epoch_num):\n",
    "        if epoch == 1:\n",
    "            for name, module in net.named_modules():\n",
    "                if isinstance(module, Feedback_Receiver):\n",
    "                    print(f\"[{name}] weight_fb parameter count: {module.weight_fb.numel():,}\")\n",
    "        ####### iterator : input_loading & tqdm을 통한 progress_bar 생성###################\n",
    "        iterator = enumerate(train_loader, 0)\n",
    "        # iterator = tqdm(iterator, total=len(train_loader), desc='train', dynamic_ncols=True, position=0, leave=True)\n",
    "        ##################################################################################   \n",
    "\n",
    "        ###### ITERATION START ##########################################################################################################\n",
    "        for i, data in iterator:\n",
    "            net.train() # train 모드로 바꿔줘야함\n",
    "            ### data loading & semi-pre-processing ################################################################################\n",
    "            if len(data) == 2:\n",
    "                inputs, labels = data\n",
    "                # 처리 로직 작성\n",
    "            elif len(data) == 3:\n",
    "                inputs, labels, x_len = data\n",
    "            else:\n",
    "                assert False, 'data length is not 2 or 3'\n",
    "            #######################################################################################################################\n",
    "                \n",
    "            ## batch 크기 ######################################\n",
    "            real_batch = labels.size(0)\n",
    "            ###########################################################\n",
    "\n",
    "            # 차원 전처리\n",
    "            ###########################################################################################################################        \n",
    "            if (which_data == 'DVS_CIFAR10' or which_data == 'DVS_GESTURE' or which_data == 'DVS_GESTURE_TONIC' or which_data == 'DVS_CIFAR10_2' or which_data == 'NMNIST' or which_data == 'NMNIST_TONIC' or which_data == 'N_CALTECH101' or which_data == 'n_tidigits' or which_data == 'heidelberg'):\n",
    "                inputs = inputs.permute(1, 0, 2, 3, 4)\n",
    "            elif rate_coding == True :\n",
    "                inputs = spikegen.rate(inputs, num_steps=TIME)\n",
    "            else :\n",
    "                inputs = inputs.repeat(TIME, 1, 1, 1, 1)\n",
    "            # inputs: [Time, Batch, Channel, Height, Width]  \n",
    "            ####################################################################################################################### \n",
    "                \n",
    "\n",
    "\n",
    "                            \n",
    "            ## initial pooling #######################################################################\n",
    "            if (initial_pooling > 1):\n",
    "                pool = nn.MaxPool2d(kernel_size=2)\n",
    "                num_pooling_layers = int(math.log2(initial_pooling))\n",
    "                # Time, Batch, Channel 차원은 그대로 두고, Height, Width 차원에 대해서만 pooling 적용\n",
    "                shape_temp = inputs.shape\n",
    "                inputs = inputs.reshape(shape_temp[0]*shape_temp[1], shape_temp[2], shape_temp[3], shape_temp[4])\n",
    "                for _ in range(num_pooling_layers):\n",
    "                    inputs = pool(inputs)\n",
    "                inputs = inputs.reshape(shape_temp[0], shape_temp[1], shape_temp[2], shape_temp[3]//initial_pooling, shape_temp[4]//initial_pooling)\n",
    "            ## initial pooling #######################################################################\n",
    "            ## temporal filtering ####################################################################\n",
    "            shape_temp = inputs.shape\n",
    "            if (temporal_filter > 1):\n",
    "                slice_bucket = []\n",
    "                for t_temp in range(TIME):\n",
    "                    start = t_temp * temporal_filter\n",
    "                    end = start + temporal_filter\n",
    "                    slice_concat = torch.movedim(inputs[start:end], 0, 1).reshape(shape_temp[1],shape_temp[2],shape_temp[3],-1)\n",
    "                    \n",
    "                    if temporal_filter_accumulation == True:\n",
    "                        if t_temp == 0:\n",
    "                            slice_bucket.append(slice_concat)\n",
    "                        else:\n",
    "                            slice_bucket.append(slice_concat+slice_bucket[t_temp-1])\n",
    "                    else:\n",
    "                        slice_bucket.append(slice_concat)\n",
    "\n",
    "                inputs = torch.stack(slice_bucket, dim=0)\n",
    "                if temporal_filter_accumulation == True and dvs_clipping > 0:\n",
    "                    inputs = (inputs != 0.0).float()\n",
    "            ## temporal filtering ####################################################################\n",
    "            ####################################################################################################################### \n",
    "                \n",
    "\n",
    "            # # dvs 데이터 시각화 코드 (확인 필요할 시 써라)\n",
    "            # ##############################################################################################\n",
    "            # dvs_visualization(inputs, labels, TIME, BATCH, my_seed)\n",
    "            # #####################################################################################################\n",
    "\n",
    "            ## to (device) #######################################\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "            ###########################################################\n",
    "\n",
    "            ## gradient 초기화 #######################################\n",
    "            optimizer.zero_grad()\n",
    "            ###########################################################\n",
    "                            \n",
    "            if merge_polarities == True:\n",
    "                inputs = inputs[:,:,0:1,:,:]\n",
    "\n",
    "            if single_step == False:\n",
    "                # net에 넣어줄때는 batch가 젤 앞 차원으로 와야함. # dataparallel때매##############################\n",
    "                # inputs: [Time, Batch, Channel, Height, Width]   \n",
    "                inputs = inputs.permute(1, 0, 2, 3, 4) # net에 넣어줄때는 batch가 젤 앞 차원으로 와야함. # dataparallel때매\n",
    "                # inputs: [Batch, Time, Channel, Height, Width] \n",
    "                #################################################################################################\n",
    "            else:\n",
    "                labels = labels.repeat(TIME, 1)\n",
    "                ## first input도 ottt trace 적용하기 위한 코드 (validation 시에는 필요X) ##########################\n",
    "                if trace_on == True and OTTT_input_trace_on == True:\n",
    "                    spike = inputs\n",
    "                    trace = torch.full_like(spike, fill_value = 0.0, dtype = torch.float, requires_grad=False)\n",
    "                    inputs = []\n",
    "                    for t in range(TIME):\n",
    "                        trace[t] = trace[t-1]*synapse_trace_const2 + spike[t]*synapse_trace_const1\n",
    "                        inputs += [[spike[t], trace[t]]]\n",
    "                ##################################################################################################\n",
    "\n",
    "\n",
    "            if single_step == False:\n",
    "                ### input --> net --> output #####################################################\n",
    "                outputs = net(inputs)\n",
    "                ##################################################################################\n",
    "                ## loss, backward ##########################################\n",
    "                iter_loss = criterion(outputs, labels)\n",
    "                iter_loss.backward()\n",
    "                ############################################################\n",
    "                ## weight 업데이트!! ##################################\n",
    "                optimizer.step()\n",
    "                ################################################################\n",
    "            else:\n",
    "                outputs_all = []\n",
    "                iter_loss = 0.0\n",
    "                for t in range(TIME):\n",
    "                    ### input[t] --> net --> output_one_time #########################################\n",
    "                    outputs_one_time = net(inputs[t])\n",
    "                    ##################################################################################\n",
    "                    one_time_loss = criterion(outputs_one_time, labels[t].contiguous())\n",
    "                    one_time_loss.backward() # one_time backward\n",
    "                    iter_loss += one_time_loss.data\n",
    "                    outputs_all.append(outputs_one_time.detach())\n",
    "                optimizer.step() # full step time update\n",
    "                outputs_all = torch.stack(outputs_all, dim=1)\n",
    "                outputs = outputs_all.mean(1) # ottt꺼 쓸때\n",
    "                labels = labels[0]\n",
    "                iter_loss /= TIME\n",
    "\n",
    "            tr_epoch_loss_temp += iter_loss.data/len(train_loader)\n",
    "\n",
    "            ## net 그림 출력해보기 #################################################################\n",
    "            # print('시각화')\n",
    "            # make_dot(outputs, params=dict(list(net.named_parameters()))).render(\"net_torchviz\", format=\"png\")\n",
    "            # return 0\n",
    "            ##################################################################################\n",
    "\n",
    "            #### batch 어긋남 방지 ###############################################\n",
    "            assert real_batch == outputs.size(0), f'batch size is not same. real_batch: {real_batch}, outputs.size(0): {outputs.size(0)}'\n",
    "            #######################################################################\n",
    "            \n",
    "\n",
    "            ####### training accruacy save for print ###############################\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total = real_batch\n",
    "            correct = (predicted == labels).sum().item()\n",
    "            iter_acc = correct / total\n",
    "            tr_total += total\n",
    "            tr_correct += correct\n",
    "            iter_acc_string = f'epoch-{epoch:<3} iter_acc:{100 * iter_acc:7.2f}%, lr={[f\"{lr:9.7f}\" for lr in (param_group[\"lr\"] for param_group in optimizer.param_groups)]}'\n",
    "            iter_acc_string2 = f'epoch-{epoch:<3} lr={[f\"{lr:9.7f}\" for lr in (param_group[\"lr\"] for param_group in optimizer.param_groups)]}'\n",
    "            ################################################################\n",
    "            \n",
    "\n",
    "            ##### validation ##################################################################################################################################\n",
    "            if i == len(train_loader)-1 :\n",
    "                iter_of_val = True\n",
    "\n",
    "                tr_acc = tr_correct/tr_total\n",
    "                tr_correct = 0\n",
    "                tr_total = 0\n",
    "\n",
    "                val_loss = 0\n",
    "                correct_val = 0\n",
    "                total_val = 0\n",
    "\n",
    "                with torch.no_grad():\n",
    "                    net.eval() # eval 모드로 바꿔줘야함 \n",
    "                    for data_val in test_loader:\n",
    "                        ## data_val loading & semi-pre-processing ##########################################################\n",
    "                        if len(data_val) == 2:\n",
    "                            inputs_val, labels_val = data_val\n",
    "                        elif len(data_val) == 3:\n",
    "                            inputs_val, labels_val, x_len = data_val\n",
    "                        else:\n",
    "                            assert False, 'data_val length is not 2 or 3'\n",
    "\n",
    "                        if (which_data == 'DVS_CIFAR10' or which_data == 'DVS_GESTURE' or which_data == 'DVS_GESTURE_TONIC' or which_data == 'DVS_CIFAR10_2' or which_data == 'NMNIST' or which_data == 'NMNIST_TONIC' or which_data == 'N_CALTECH101' or which_data == 'n_tidigits' or which_data == 'heidelberg'):\n",
    "                            inputs_val = inputs_val.permute(1, 0, 2, 3, 4)\n",
    "                        elif rate_coding == True :\n",
    "                            inputs_val = spikegen.rate(inputs_val, num_steps=TIME)\n",
    "                        else :\n",
    "                            inputs_val = inputs_val.repeat(TIME, 1, 1, 1, 1)\n",
    "                        # inputs_val: [Time, Batch, Channel, Height, Width]  \n",
    "                        ###################################################################################################\n",
    "\n",
    "                        \n",
    "                        ## initial pooling #######################################################################\n",
    "                        if (initial_pooling > 1):\n",
    "                            pool = nn.MaxPool2d(kernel_size=2)\n",
    "                            num_pooling_layers = int(math.log2(initial_pooling))\n",
    "                            # Time, Batch, Channel 차원은 그대로 두고, Height, Width 차원에 대해서만 pooling 적용\n",
    "                            shape_temp = inputs_val.shape\n",
    "                            inputs_val = inputs_val.reshape(shape_temp[0]*shape_temp[1], shape_temp[2], shape_temp[3], shape_temp[4])\n",
    "                            for _ in range(num_pooling_layers):\n",
    "                                inputs_val = pool(inputs_val)\n",
    "                            inputs_val = inputs_val.reshape(shape_temp[0], shape_temp[1], shape_temp[2], shape_temp[3]//initial_pooling, shape_temp[4]//initial_pooling)\n",
    "                        ## initial pooling #######################################################################\n",
    "\n",
    "                        ## temporal filtering ####################################################################\n",
    "                        shape_temp = inputs_val.shape\n",
    "                        if (temporal_filter > 1):\n",
    "                            slice_bucket = []\n",
    "                            for t_temp in range(TIME):\n",
    "                                start = t_temp * temporal_filter\n",
    "                                end = start + temporal_filter\n",
    "                                slice_concat = torch.movedim(inputs_val[start:end], 0, 1).reshape(shape_temp[1],shape_temp[2],shape_temp[3],-1)\n",
    "                                \n",
    "                                if temporal_filter_accumulation == True:\n",
    "                                    if t_temp == 0:\n",
    "                                        slice_bucket.append(slice_concat)\n",
    "                                    else:\n",
    "                                        slice_bucket.append(slice_concat+slice_bucket[t_temp-1])\n",
    "                                else:\n",
    "                                    slice_bucket.append(slice_concat)\n",
    "\n",
    "                            inputs_val = torch.stack(slice_bucket, dim=0)\n",
    "                            if temporal_filter_accumulation == True and dvs_clipping > 0:\n",
    "                                inputs = (inputs != 0.0).float()\n",
    "                        ## temporal filtering ####################################################################\n",
    "                            \n",
    "                        inputs_val = inputs_val.to(device)\n",
    "                        labels_val = labels_val.to(device)\n",
    "                        real_batch = labels_val.size(0)\n",
    "                        \n",
    "                        if merge_polarities == True:\n",
    "                            inputs_val = inputs_val[:,:,0:1,:,:]\n",
    "\n",
    "                        ## network 연산 시작 ############################################################################################################\n",
    "                        if single_step == False:\n",
    "                            outputs = net(inputs_val.permute(1, 0, 2, 3, 4)) #inputs_val: [Batch, Time, Channel, Height, Width]  \n",
    "                            val_loss += criterion(outputs, labels_val)/len(test_loader)\n",
    "                        else:\n",
    "                            outputs_all = []\n",
    "                            for t in range(TIME):\n",
    "                                outputs = net(inputs_val[t])\n",
    "                                val_loss_temp = criterion(outputs, labels_val)\n",
    "                                outputs_all.append(outputs.detach())\n",
    "                                val_loss += (val_loss_temp.data/TIME)/len(test_loader)\n",
    "                            outputs_all = torch.stack(outputs_all, dim=1)\n",
    "                            outputs = outputs_all.mean(1)\n",
    "                        #################################################################################################################################\n",
    "\n",
    "                        _, predicted = torch.max(outputs.data, 1)\n",
    "                        total_val += real_batch\n",
    "                        assert real_batch == outputs.size(0), f'batch size is not same. real_batch: {real_batch}, outputs.size(0): {outputs.size(0)}'\n",
    "                        correct_val += (predicted == labels_val).sum().item()\n",
    "\n",
    "                    val_acc_now = correct_val / total_val\n",
    "\n",
    "                if val_acc_best < val_acc_now:\n",
    "                    val_acc_best = val_acc_now\n",
    "                    # wandb 키면 state_dict아닌거는 저장 안됨\n",
    "                    # network save\n",
    "                    # torch.save(net.state_dict(), f\"net_save/save_now_net_weights_{unique_name}.pth\")\n",
    "\n",
    "                if tr_acc_best < tr_acc:\n",
    "                    tr_acc_best = tr_acc\n",
    "\n",
    "                tr_epoch_loss = tr_epoch_loss_temp\n",
    "                tr_epoch_loss_temp = 0\n",
    "\n",
    "            ####################################################################################################################################################\n",
    "            \n",
    "            ## progress bar update ############################################################################################################\n",
    "            if iter_of_val == False:\n",
    "                # iterator.set_description(f\"{iter_acc_string}, iter_loss:{iter_loss:10.6f}\") \n",
    "                pass \n",
    "            else:\n",
    "                # iterator.set_description(f\"{iter_acc_string2}, tr/val_loss:{tr_epoch_loss:10.6f}/{val_loss:10.6f}, tr:{100 * tr_acc:7.2f}%, tr_best:{100 * tr_acc_best:7.2f}%, val:{100 * val_acc_now:7.2f}%, val_best:{100 * val_acc_best:7.2f}%\")  \n",
    "                print(f\"{iter_acc_string2}, tr/val_loss:{tr_epoch_loss:10.6f}/{val_loss:10.6f}, val:{100 * val_acc_now:7.2f}%, val_best:{100 * val_acc_best:7.2f}%, tr:{100 * tr_acc:7.2f}%, tr_best:{100 * tr_acc_best:7.2f}%\")\n",
    "                iter_of_val = False\n",
    "            ####################################################################################################################################\n",
    "            \n",
    "            ## wandb logging ############################################################################################################\n",
    "            wandb.log({\"iter_acc\": iter_acc})\n",
    "            wandb.log({\"tr_acc\": tr_acc})\n",
    "            wandb.log({\"val_acc_now\": val_acc_now})\n",
    "            wandb.log({\"val_acc_best\": val_acc_best})\n",
    "            wandb.log({\"summary_val_acc\": val_acc_now})\n",
    "            wandb.log({\"epoch\": epoch})\n",
    "            wandb.log({\"val_loss\": val_loss}) \n",
    "            wandb.log({\"tr_epoch_loss\": tr_epoch_loss})   \n",
    "            ####################################################################################################################################\n",
    "            \n",
    "        ###### ITERATION END ##########################################################################################################\n",
    "\n",
    "        ## scheduler update #############################################################################\n",
    "        if (scheduler_name != 'no'):\n",
    "            if (scheduler_name == 'ReduceLROnPlateau'):\n",
    "                scheduler.step(val_loss)\n",
    "            else:\n",
    "                scheduler.step()\n",
    "        #################################################################################################\n",
    "        \n",
    "    #======== EPOCH END ==========================================================================================\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# unique_name = 'main' ## 이거 설정하면 새로운 경로에 모두 save\n",
    "# wandb.init(project= f'my_snn {unique_name}',save_code=False, dir='/data2/bh_wandb', tags=[\"common\"])\n",
    "# ## wandb 과거 하이퍼파라미터 가져와서 붙여넣기 (devices unique_name은 니가 할당해라)#################################\n",
    "# param = {'devices': '3', 'single_step': True, 'unique_name': 'main', 'my_seed': 42, 'TIME': 10, 'BATCH': 16, 'IMAGE_SIZE': 128, 'which_data': 'DVS_GESTURE_TONIC', 'data_path': '/data2', 'rate_coding': False, 'lif_layer_v_init': 0, 'lif_layer_v_decay': 0.25, 'lif_layer_v_threshold': 0.75, 'lif_layer_v_reset': 0, 'lif_layer_sg_width': 4, 'synapse_conv_kernel_size': 3, 'synapse_conv_stride': 1, 'synapse_conv_padding': 1, 'synapse_trace_const1': 1, 'synapse_trace_const2': 0, 'pre_trained': False, 'convTrue_fcFalse': False, 'cfg': [200, 200], 'net_print': True, 'pre_trained_path': 'net_save/save_now_net_weights_{unique_name}.pth', 'learning_rate': 0.001, 'epoch_num': 100, 'tdBN_on': False, 'BN_on': False, 'surrogate': 'hard_sigmoid', 'BPTT_on': False, 'optimizer_what': 'SGD', 'scheduler_name': 'no', 'ddp_on': False, 'dvs_clipping': 2, 'dvs_duration': 25000, 'DFA_on': True, 'trace_on': True, 'OTTT_input_trace_on': False, 'exclude_class': True, 'merge_polarities': False, 'denoise_on': True, 'extra_train_dataset': 0, 'num_workers': 2, 'chaching_on': True, 'pin_memory': True, 'UDA_on': False, 'alpha_uda': 1, 'bias': True, 'last_lif': False, 'temporal_filter': 5, 'initial_pooling': 8}\n",
    "# my_snn_system(devices = '0',single_step = param['single_step'],unique_name = unique_name,my_seed = param['my_seed'],TIME = param['TIME'],BATCH = param['BATCH'],IMAGE_SIZE = param['IMAGE_SIZE'],which_data = param['which_data'],data_path = param['data_path'],rate_coding = param['rate_coding'],lif_layer_v_init = param['lif_layer_v_init'],lif_layer_v_decay = param['lif_layer_v_decay'],lif_layer_v_threshold = param['lif_layer_v_threshold'],lif_layer_v_reset = param['lif_layer_v_reset'],lif_layer_sg_width = param['lif_layer_sg_width'],synapse_conv_kernel_size = param['synapse_conv_kernel_size'],synapse_conv_stride = param['synapse_conv_stride'],synapse_conv_padding = param['synapse_conv_padding'],synapse_trace_const1 = param['synapse_trace_const1'],synapse_trace_const2 = param['synapse_trace_const2'],pre_trained = param['pre_trained'],convTrue_fcFalse = param['convTrue_fcFalse'],cfg = param['cfg'],net_print = param['net_print'],pre_trained_path = param['pre_trained_path'],learning_rate = param['learning_rate'],epoch_num = param['epoch_num'],tdBN_on = param['tdBN_on'],BN_on = param['BN_on'],surrogate = param['surrogate'],BPTT_on = param['BPTT_on'],optimizer_what = param['optimizer_what'],scheduler_name = param['scheduler_name'],ddp_on = param['ddp_on'],dvs_clipping = param['dvs_clipping'],dvs_duration = param['dvs_duration'],DFA_on = param['DFA_on'],trace_on = param['trace_on'],OTTT_input_trace_on = param['OTTT_input_trace_on'],exclude_class = param['exclude_class'],merge_polarities = param['merge_polarities'],denoise_on = param['denoise_on'],extra_train_dataset = param['extra_train_dataset'],num_workers = param['num_workers'],chaching_on = param['chaching_on'],pin_memory = param['pin_memory'],UDA_on = param['UDA_on'],alpha_uda = param['alpha_uda'],bias = param['bias'],last_lif = param['last_lif'],temporal_filter = param['temporal_filter'],initial_pooling = param['initial_pooling'],temporal_filter_accumulation= param['temporal_filter_accumulation'])\n",
    "# #############################################################################\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mbhkim003\u001b[0m (\u001b[33mbhkim003-seoul-national-university\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.19.11 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.17.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/data2/bh_wandb/wandb/run-20250512_124628-c91ivchq</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/c91ivchq' target=\"_blank\">woven-paper-8371</a></strong> to <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/c91ivchq' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/c91ivchq</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "param {'devices': '4', 'single_step': True, 'unique_name': 'main', 'my_seed': 42, 'TIME': 10, 'BATCH': 16, 'IMAGE_SIZE': 17, 'which_data': 'NMNIST_TONIC', 'data_path': '/data2', 'rate_coding': False, 'lif_layer_v_init': 0.0, 'lif_layer_v_decay': 0.5, 'lif_layer_v_threshold': 0.5, 'lif_layer_v_reset': 10000.0, 'lif_layer_sg_width': 4.0, 'synapse_conv_kernel_size': 3, 'synapse_conv_stride': 1, 'synapse_conv_padding': 1, 'synapse_trace_const1': 1, 'synapse_trace_const2': 0.5, 'pre_trained': False, 'convTrue_fcFalse': False, 'cfg': [200, 200], 'net_print': True, 'pre_trained_path': 'net_save/save_now_net_weights_main.pth', 'learning_rate': 0.0001, 'epoch_num': 10000, 'tdBN_on': False, 'BN_on': False, 'surrogate': 'hard_sigmoid', 'BPTT_on': False, 'optimizer_what': 'SGD', 'scheduler_name': 'no', 'ddp_on': False, 'dvs_clipping': 1, 'dvs_duration': 5000, 'DFA_on': True, 'trace_on': False, 'OTTT_input_trace_on': False, 'exclude_class': True, 'merge_polarities': False, 'denoise_on': False, 'extra_train_dataset': 0, 'num_workers': 2, 'chaching_on': True, 'pin_memory': True, 'UDA_on': False, 'alpha_uda': 1.0, 'bias': True, 'last_lif': False, 'temporal_filter': 1, 'initial_pooling': 1, 'temporal_filter_accumulation': False} \n",
      "\n",
      "dataset_hash = 7b0583c2e220caca87b64bcaac63adf4\n",
      "cache path exists\n",
      "\n",
      "len(train_loader): 3750 BATCH: 16 train_data_count: 60000\n",
      "len(test_loader): 625 BATCH: 16\n",
      "\n",
      "device ==> cuda\n",
      "\n",
      "DataParallel(\n",
      "  (module): REBORN_MY_SNN_FC(\n",
      "    (layers): REBORN_MY_Sequential(\n",
      "      (0): DimChanger_for_FC()\n",
      "      (1): Shaker_for_FC()\n",
      "      (2): Sparsity_Checker()\n",
      "      (3): SYNAPSE_FC(in_features=578, out_features=200, TIME=10, bias=True, sstep=True, time_different_weight=False)\n",
      "      (4): LIF_layer(v_init=0.0, v_decay=0.5, v_threshold=0.5, v_reset=10000.0, sg_width=4.0, surrogate=hard_sigmoid, BPTT_on=False, trace_const1=1, trace_const2=0.5, TIME=10, sstep=True, trace_on=False)\n",
      "      (5): Sparsity_Checker()\n",
      "      (6): Feedback_Receiver()\n",
      "      (7): SYNAPSE_FC(in_features=200, out_features=200, TIME=10, bias=True, sstep=True, time_different_weight=False)\n",
      "      (8): LIF_layer(v_init=0.0, v_decay=0.5, v_threshold=0.5, v_reset=10000.0, sg_width=4.0, surrogate=hard_sigmoid, BPTT_on=False, trace_const1=1, trace_const2=0.5, TIME=10, sstep=True, trace_on=False)\n",
      "      (9): Sparsity_Checker()\n",
      "      (10): Feedback_Receiver()\n",
      "      (11): SYNAPSE_FC(in_features=200, out_features=10, TIME=10, bias=True, sstep=True, time_different_weight=False)\n",
      "      (DFA_top): Top_Gradient()\n",
      "    )\n",
      "  )\n",
      ")\n",
      "\n",
      "========================================================\n",
      "Trainable parameters: 158,010\n",
      "========================================================\n",
      "\n",
      "current loss function: CustomCriterion()\n",
      "self.perm fc input 처음에 한번 섞기 tensor([575, 370,  61, 417, 461,  13, 521, 431, 548, 388, 477, 324, 235,  75,\n",
      "          4, 257,  81, 220, 328, 313, 274, 382, 334, 558,  35, 518, 482,  79,\n",
      "        133,  21, 171, 510, 389, 112, 159, 246, 507, 150, 437,  85, 287,  20,\n",
      "        418, 529, 394, 142, 503, 368,  32, 443, 156, 376, 110,  58, 128, 564,\n",
      "          5, 190, 309, 113, 407, 260, 547, 264,  94, 367, 141, 327, 341, 188,\n",
      "        253, 255, 364, 291,  25, 230,  89, 530, 285, 557,  82, 381, 138,  30,\n",
      "        252, 233, 353, 129, 254, 148, 210, 192, 100,  98, 321,  49, 377, 472,\n",
      "        345,  84, 225, 224, 245, 532, 490, 419, 447, 320, 372, 244, 184, 556,\n",
      "        359, 476, 214,   9, 237, 401, 467, 475, 474, 272, 132, 378, 549, 319,\n",
      "        135,  39, 436,  83, 312, 217, 271, 115, 293, 294, 373, 512, 536, 303,\n",
      "        131, 329, 535,  95, 404, 124, 123, 152, 109, 365, 533, 164, 116, 470,\n",
      "        339, 420, 178, 433, 351, 179,  40, 400, 390, 374,  72, 519, 356, 360,\n",
      "        538, 333, 411, 495,  41,  31,  69, 180, 465, 523, 207, 487, 396, 120,\n",
      "        391, 157, 173, 403, 386, 452, 511, 101, 406, 137, 182,  54, 163, 570,\n",
      "        338, 122, 145, 554, 185, 460, 405,  18, 261, 162, 302, 308, 453,   0,\n",
      "        144, 170, 198, 295, 161,  53,  73, 416,  46, 429, 169, 238, 402, 296,\n",
      "        380, 542, 540, 277, 514, 323, 301,  86, 565, 304, 577,  14, 143, 183,\n",
      "         63, 107, 212, 481, 213,  67, 573, 500, 286, 165, 290, 488,  88, 263,\n",
      "        218,  55, 493, 130, 197, 517, 205, 454,  59,   7, 392, 236, 262, 223,\n",
      "        240, 397, 119, 196, 114, 219, 318, 527, 459, 444,  93, 395, 408, 498,\n",
      "        151, 340, 464, 506, 509,  78,  70, 572, 221,  16, 562,  50, 479, 438,\n",
      "        208, 516,  36,  57, 200, 355,  91,  77, 243, 149, 485, 496, 568, 242,\n",
      "        469, 344, 106, 247, 471, 410, 413,  87, 352,   3, 393, 421, 231,  60,\n",
      "        189, 449,  38, 428, 357, 571,  19, 204, 227, 450, 520, 480, 504, 102,\n",
      "        435, 307, 335, 256, 222, 160,   1, 300, 515,  37, 288,  71, 306, 187,\n",
      "        125, 127, 531, 325, 385, 158, 379, 134,  48, 502, 166, 362,  90, 346,\n",
      "        154, 281, 473, 282, 167,  96, 349,  51, 269,  92, 422, 528, 425,  12,\n",
      "         42, 215, 267,  45, 276, 489, 491, 525, 427, 140,  26, 463, 442,  74,\n",
      "         64, 193, 441, 383, 455,   8, 458, 492, 387, 248, 409, 350, 358, 155,\n",
      "        546, 366,  97, 551, 423, 239,  52, 228, 118,  15,  47, 560, 117, 424,\n",
      "        567, 194, 168, 203,  66, 147, 172, 146, 501,  10, 279, 111, 268, 559,\n",
      "        175, 305, 211, 466,  62,  29, 299, 251, 297, 315, 311, 229, 484, 298,\n",
      "        177, 258, 539, 412, 348, 289, 426, 513, 216, 226, 555, 524, 398, 432,\n",
      "        552, 576, 434, 314, 105, 440, 574, 266,  33, 363, 316, 202, 280,  80,\n",
      "        522, 181, 278, 273, 139, 136,   6, 292, 354, 526,  17, 445, 462, 326,\n",
      "        250,  44, 486, 553, 569, 369, 561, 259, 494,  43, 439, 265, 195, 176,\n",
      "         68, 201, 284,  24, 121, 347,  65,  99, 343, 283, 241, 566, 322, 317,\n",
      "        104, 545, 103, 457,  27, 478, 199, 505, 483,  34, 234, 499, 275, 126,\n",
      "        310,  22,  56, 361, 537, 430, 249, 543, 451, 191, 534, 174, 497, 544,\n",
      "        186, 206, 508, 337, 108,   2, 541, 384, 371, 330, 375, 456, 414, 550,\n",
      "        336, 331, 232, 209, 270,  76,  11, 342, 415, 446, 332, 448,  28, 399,\n",
      "        563, 153,  23, 468], device='cuda:0')\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAnYAAAHWCAYAAAD6oMSKAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8pXeV/AAAACXBIWXMAAA9hAAAPYQGoP6dpAABL3klEQVR4nO3deXhU9d3+8XsmhGwCApGEsEYNi4AooCgoSzXBDRTbUg2bLEIFLYg+KKKPoVJUfERaFZQKAbUB3MClFYnKpsEFBFo0hqiRIBDiIBIkIQTm+/uDZn4O2WaGyczk5P26rlwXc85nzvmcb4bh5qw2Y4wRAAAA6jx7sBsAAACAfxDsAAAALIJgBwAAYBEEOwAAAIsg2AEAAFgEwQ4AAMAiCHYAAAAWQbADAACwCIIdAACARRDsgDrmtddek81m08qVKyvM6969u2w2m957770K88477zz16NHDq3Xddtttat++vU99pqWlyWazyeFw1Fg7Z84crV69usa6N998UzabTc8991yVNZmZmbLZbJo3b57HvZ7Jdp6p9u3by2azyWazyW63q0mTJurcubNGjRqltWvXVvoem82mtLQ0r9bzr3/9y+v3VLaupUuXymazacuWLV4vqyr79u1TWlqatm/fXmFe+ecIgGcIdkAdM2DAANlsNq1bt85t+k8//aT//Oc/iomJqTDvhx9+0HfffaeBAwd6ta6HHnpIq1atOuOea+JpsLv++usVHx+vJUuWVFmTnp6u8PBwjRw50o8d1q6+fftq8+bNysrK0uuvv64777xTeXl5GjRokH73u9+prKzMrX7z5s0aP368V+v417/+pVmzZnndmy/r8ta+ffs0a9asSoPd+PHjtXnz5lpdP2AlBDugjomNjVXXrl21fv16t+kbNmxQgwYNNG7cuArBrvy1t8HuvPPO08UXX3xG/fpTgwYNNGrUKH3++efauXNnhfk///yzVq1apSFDhuicc84JQoe+Ofvss3XZZZfpsssu09VXX63Jkydr06ZNevjhh/X666/rwQcfdKu/7LLL1Lp161rrxxijkpKSgKyrJq1bt9Zll10WtPUDdQ3BDqiDBg4cqJycHO3fv981bf369brkkkt03XXXaevWrTpy5IjbvLCwMF155ZWSTv3DvWDBAl100UWKiopS06ZN9bvf/U7fffed23oqO0T5888/a9y4cWrWrJnOOussXX/99fruu++qPDx44MAB3XrrrWrSpIni4uI0duxYHT582DXfZrPp6NGjWrZsmeuQ5IABA6rc9nHjxkk6tWfudMuXL9exY8c0duxYSdKzzz6rfv36qUWLFoqJiVG3bt00d+7cCnvATvf999/LZrNp6dKlFeZVtp25ublKTU1VixYtFBERoc6dO+vZZ5+tdh2eSEtLU5cuXfTMM8/o2LFjVfZQXFyse++9V4mJiYqMjFSzZs3Uq1cvLV++XNKp32N5P+VjbLPZ9P3337um3XnnnXruuefUuXNnRUREaNmyZVVuryQdOnRIY8aMUbNmzRQTE6PBgwdX+Py0b99et912W4X3DhgwwPU7Lv/cStKYMWNcvZWvs7JDsU6nU3PnzlWnTp0UERGhFi1aaNSoUfrhhx8qrKdr1676/PPPdeWVVyo6OlrnnnuuHnvsMTmdzqoHHqjDCHZAHVS+5+3Xe+3WrVun/v37q2/fvrLZbNq0aZPbvB49eqhJkyaSpIkTJ2rq1Km6+uqrtXr1ai1YsEBffvml+vTpowMHDlS5XqfTqcGDBysjI0P33XefVq1apd69e+uaa66p8j2//e1v1aFDB73++uu6//77lZGRobvvvts1f/PmzYqKitJ1112nzZs3a/PmzVqwYEGVy+vQoYOuuOIKvfzyyxUCWnp6ulq1aqVBgwZJkr799lulpqbqpZde0jvvvKNx48bpiSee0MSJE6tcvre++uorXXLJJdq5c6eefPJJvfPOO7r++uv1pz/9yadDn6cbPHiwiouLqz2nbdq0aVq4cKH+9Kc/ac2aNXrppZf0+9//XgcPHpR06pD67373O0lyjfHmzZvVsmVL1zJWr16thQsX6n//93/13nvvuf4TUJVx48bJbrcrIyND8+fP12effaYBAwbo559/9mr7evTo4QrpDz74oKu36g7/3nHHHbrvvvuUnJyst956S4888ojWrFmjPn36VDins6CgQMOHD9eIESP01ltv6dprr9WMGTP08ssve9UnUGcYAHXOTz/9ZOx2u5kwYYIxxhiHw2FsNptZs2aNMcaYSy+91Nx7773GGGPy8/ONJDN9+nRjjDGbN282ksyTTz7ptsw9e/aYqKgoV50xxowePdq0a9fO9fqf//ynkWQWLlzo9t5HH33USDIPP/ywa9rDDz9sJJm5c+e61U6aNMlERkYap9PpmhYTE2NGjx7t8fanp6cbSeaNN95wTdu5c6eRZGbOnFnpe06ePGnKysrMiy++aMLCwsxPP/1U5Xbm5eUZSSY9Pb3Cck7fzkGDBpnWrVubw4cPu9XdeeedJjIy0m09lWnXrp25/vrrq5y/cOFCI8msXLmyyh66du1qbrrppmrXM3nyZFPVV74k06RJk0p7PX1d5WM/dOhQt7qPP/7YSDKzZ89227bKfq/9+/c3/fv3d73+/PPPqxzv8s9RuezsbCPJTJo0ya3u008/NZLMAw884LYeSebTTz91q73gggvMoEGDKqwLsAL22AF1UNOmTdW9e3fXHrsNGzYoLCxMffv2lST179/fdV7d6efXvfPOO7LZbBoxYoROnDjh+omPj3dbZmU2bNggSRo2bJjb9FtvvbXK9wwZMsTt9YUXXqhjx46psLDQ8w0+zbBhw9SoUSO3iyiWLFkim82mMWPGuKZt27ZNQ4YMUfPmzRUWFqbw8HCNGjVKJ0+e1K5du3xef7ljx47pgw8+0NChQxUdHe02ntddd52OHTumTz755IzWYYypsebSSy/Vu+++q/vvv1/r1693nR/njd/85jdq2rSpx/XDhw93e92nTx+1a9euwvmd/la+/NMP8V566aXq3LmzPvjgA7fp8fHxuvTSS92mXXjhhdq9e3et9gkEC8EOqKMGDhyoXbt2ad++fVq3bp169uyps846S9KpYLdt2zYdPnxY69atU4MGDXTFFVdIOnXOmzFGcXFxCg8Pd/v55JNPqr09ycGDB9WgQQM1a9bMbXpcXFyV72nevLnb64iICEnyKXyUi46O1i233KI1a9aooKBAJ06c0Msvv6z+/fvrvPPOkyTl5+fryiuv1N69e/XXv/5VmzZt0ueff+461+xM1l/u4MGDOnHihJ5++ukKY3nddddJkke3e6lOeQBJSEiosuZvf/ub7rvvPq1evVoDBw5Us2bNdNNNNyk3N9fj9fz6sKwn4uPjK51Wfvi3tpQvv7J+ExISKqz/9M+fdOoz6I/fPxCKGgS7AQC+GThwoObNm6f169dr/fr1riAhyRXiNm7c6Do5vTz0xcbGus7BKw9Zv1bZtHLNmzfXiRMn9NNPP7mFu4KCAn9tlsfGjRunv//973rxxRfVoUMHFRYW6sknn3TNX716tY4ePao33nhD7dq1c02v7JYap4uMjJQklZaWuk0/PTQ0bdpUYWFhGjlypCZPnlzpshITEz3dpAqMMXr77bcVExOjXr16VVkXExOjWbNmadasWTpw4IBr793gwYP19ddfe7Qub+8VV9nvvKCgQOeff77rdWRkZIUxlE6F3djYWK/WV648qO3fv7/C1br79u3zebmAVbDHDqij+vXrp7CwML322mv68ssv3a4kbdKkiS666CItW7ZM33//vdttTm644QYZY7R371716tWrwk+3bt2qXGf//v0lqcLNkVesWHFG2+LLHpTevXura9euSk9PV3p6upo0aaLf/va3rvnlQeXXQdUYo7///e81LjsuLk6RkZH697//7Tb9zTffdHsdHR2tgQMHatu2bbrwwgsrHc/K9hh5atasWfrqq680ZcoUV9j0pPfbbrtNt956q3JyclRcXCzJP3tKf+0f//iH2+usrCzt3r3b7XPYvn37CmO4a9cu5eTkuE3zprff/OY3klTh4ofPP/9c2dnZuuqqqzzeBsCK2GMH1FGNGzdWjx49tHr1atntdtf5deX69++v+fPnS3K/f13fvn01YcIEjRkzRlu2bFG/fv0UExOj/fv366OPPlK3bt10xx13VLrOa665Rn379tU999yjoqIi9ezZU5s3b9aLL74oSbLbffu/Yrdu3bR+/Xq9/fbbatmypRo1aqSOHTvW+L6xY8dq2rRpysnJ0cSJExUVFeWal5ycrIYNG+rWW2/V9OnTdezYMS1cuFCHDh2qcbnl5yAuWbJE5513nrp3767PPvtMGRkZFWr/+te/6oorrtCVV16pO+64Q+3bt9eRI0f0zTff6O2339aHH35Y4/p+/vln17l4R48eVU5OjlasWKFNmzZp2LBhNV5d27t3b91www268MIL1bRpU2VnZ+ull17S5ZdfrujoaElyBfbHH39c1157rcLCwnThhReqYcOGNfZXmS1btmj8+PH6/e9/rz179mjmzJlq1aqVJk2a5KoZOXKkRowYoUmTJum3v/2tdu/erblz51a4x+B5552nqKgo/eMf/1Dnzp111llnKSEhodLDzx07dtSECRP09NNPy26369prr9X333+vhx56SG3atHG74hqol4J66QaAMzJ9+nQjyfTq1avCvNWrVxtJpmHDhubo0aMV5i9ZssT07t3bxMTEmKioKHPeeeeZUaNGmS1btrhqTr9a1JhTV+SOGTPGnH322SY6OtokJyebTz75xEgyf/3rX1115Vcz/vjjj27vL7+qMi8vzzVt+/btpm/fviY6OtpIcrtisjo//vijadiwoZFkPvvsswrz3377bdO9e3cTGRlpWrVqZf7nf/7HvPvuu0aSWbduXbXbefjwYTN+/HgTFxdnYmJizODBg833339f4SpRY05dRTt27FjTqlUrEx4ebs455xzTp08ftytEq9KuXTsjyUgyNpvNnHXWWaZjx45m5MiR5r333qv0Paf3cP/995tevXqZpk2bmoiICHPuueeau+++2zgcDldNaWmpGT9+vDnnnHOMzWZz+x1IMpMnT/ZoXeW/v7Vr15qRI0eas88+20RFRZnrrrvO5Obmur3X6XSauXPnmnPPPddERkaaXr16mQ8//LDCVbHGGLN8+XLTqVMnEx4e7rbO06+KNebUFc6PP/646dChgwkPDzexsbFmxIgRZs+ePW51/fv3N126dKmwTZX9vgGrsBnjwSVXAFCNjIwMDR8+XB9//LH69OkT7HYAoN4i2AHwyvLly7V3715169ZNdrtdn3zyiZ544gldfPHFrtuhAACCg3PsAHilUaNGWrFihWbPnq2jR4+qZcuWuu222zR79uxgtwYA9R577AAAACyC250AAABYBMEOAADAIgh2AAAAFsHFE5KcTqf27dunRo0aef1YHQAAgNpkjNGRI0eUkJBQ443gCXY69XzBNm3aBLsNAACAKu3Zs6fCM5JPR7DTqds3SKcGrHHjxkHupnJlZWVau3atUlJSFB4eHux2Qh7j5R3Gy3OMlXcYL+8wXt6pL+NVVFSkNm3auPJKdQh2+v8PC2/cuHFIB7vo6Gg1btzY0h9ef2G8vMN4eY6x8g7j5R3Gyzv1bbw8OV2MiycAAAAsgmAHAABgEQQ7AAAAiyDYAQAAWATBDgAAwCIIdgAAABZBsAMAALAIgh0AAIBFEOwAAAAsgmAHAABgEQQ7AAAAiyDYAQAAWATBDgAAwCIIdgAAABYR1GC3ceNGDR48WAkJCbLZbFq9erVrXllZme677z5169ZNMTExSkhI0KhRo7Rv3z63ZZSWluquu+5SbGysYmJiNGTIEP3www8B3hIAAIDgaxDMlR89elTdu3fXmDFj9Nvf/tZtXnFxsb744gs99NBD6t69uw4dOqSpU6dqyJAh2rJli6tu6tSpevvtt7VixQo1b95c99xzj2644QZt3bpVYWFhgd4kABZX/h/HHTt2yG6v+v/GsbGxatu2baDaAgBJQQ521157ra699tpK5zVp0kSZmZlu055++mldeumlys/PV9u2bXX48GEtXrxYL730kq6++mpJ0ssvv6w2bdro/fff16BBg2p9GwDUH/n5+ep1ySVasnix+vXrp5KSkipro6Kj9XV2NuEOQEAFNdh56/Dhw7LZbDr77LMlSVu3blVZWZlSUlJcNQkJCeratauysrIIdgD8yuFwqKS4WJI04YW3dFK2SusK83L1yoN3yOFwEOwABFSdCXbHjh3T/fffr9TUVDVu3FiSVFBQoIYNG6pp06ZutXFxcSooKKhyWaWlpSotLXW9LioqknTqvL6ysrJa6P7MlfcVqv2FGsbLO4yXZ5xOp6KioiRJrZM6yWmv/Cs0TEZRUVFyOp31fkz5bHmH8fJOfRkvb7avTgS7srIy3XLLLXI6nVqwYEGN9cYY2WyV/09akh599FHNmjWrwvS1a9cqOjr6jHqtbacfnkb1GC/vMF41W7JkiSQpad/WKms6xkgDly/X3r17tXfv3kC1FtL4bHmH8fKO1cer+L9HCjwR8sGurKxMw4YNU15enj788EPX3jpJio+P1/Hjx3Xo0CG3vXaFhYXq06dPlcucMWOGpk2b5npdVFSkNm3aKCUlxW35oaSsrEyZmZlKTk5WeHh4sNsJeYyXdxgvz+zYsUODBg3SkiVLlJvQs8o9dvtydmrR+CHauHGjunfvHuAuQwufLe8wXt6pL+NVfmTREyEd7MpDXW5urtatW6fmzZu7ze/Zs6fCw8OVmZmpYcOGSZL279+vnTt3au7cuVUuNyIiQhERERWmh4eHh/wHoy70GEoYL+8wXtWz2+2uCyac9gZVBruTsqmkpER2u53x/C8+W95hvLxj9fHyZtuCGux++eUXffPNN67XeXl52r59u5o1a6aEhAT97ne/0xdffKF33nlHJ0+edJ0316xZMzVs2FBNmjTRuHHjdM8996h58+Zq1qyZ7r33XnXr1s11lSwAAEB9EdRgt2XLFg0cOND1uvzw6OjRo5WWlqa33npLknTRRRe5vW/dunUaMGCAJOmpp55SgwYNNGzYMJWUlOiqq67S0qVLuYcdAACod4Ia7AYMGCBjTJXzq5tXLjIyUk8//bSefvppf7YGAABQ5/CsWAAAAIsg2AEAAFgEwQ4AAMAiCHYAAAAWQbADAACwCIIdAACARRDsAAAALIJgBwAAYBEEOwAAAIsg2AEAAFgEwQ4AAMAigvqsWACwsuzs7BprYmNj1bZt2wB0A6A+INgBgJ8dcRyQzW7XiBEjaqyNio7W19nZhDsAfkGwAwA/KzlSJON0atjshWqRmFRlXWFerl558A45HA6CHQC/INgBsLT8/Hw5HI4a62rjkGiLxCS16tzdr8sEgOoQ7ABYVn5+vjp17qyS4uIaazkkCsAKCHYALMvhcKikuJhDogDqDYIdAMvjkCiA+oL72AEAAFgEwQ4AAMAiCHYAAAAWQbADAACwCIIdAACARRDsAAAALIJgBwAAYBEEOwAAAIsg2AEAAFgEwQ4AAMAiCHYAAAAWQbADAACwCIIdAACARRDsAAAALIJgBwAAYBEEOwAAAIsg2AEAAFhEg2A3AKB+yM/Pl8PhqLEuNjZWbdu2DUBHAGA9BDsAtS4/P1+dOndWSXFxjbVR0dH6OjubcAcAPiDYAah1DodDJcXFGjZ7oVokJlVZV5iXq1cevEMOh4NgBwA+INgBCJgWiUlq1bl7sNsAAMvi4gkAAACLINgBAABYBIdiAeC/srOzz2g+AAQbwQ5AvXfEcUA2u10jRoyosTYqKioAHQGAbwh2AOq9kiNFMk5njVft5nz8gT5Knx+4xgDASwQ7APivmq7aLczLDWA3AOA9Lp4AAACwCIIdAACARRDsAAAALIJgBwAAYBEEOwAAAIsIarDbuHGjBg8erISEBNlsNq1evdptvjFGaWlpSkhIUFRUlAYMGKAvv/zSraa0tFR33XWXYmNjFRMToyFDhuiHH34I4FYAAACEhqAGu6NHj6p79+565plnKp0/d+5czZs3T88884w+//xzxcfHKzk5WUeOHHHVTJ06VatWrdKKFSv00Ucf6ZdfftENN9ygkydPBmozAAAAQkJQ72N37bXX6tprr610njFG8+fP18yZM3XzzTdLkpYtW6a4uDhlZGRo4sSJOnz4sBYvXqyXXnpJV199tSTp5ZdfVps2bfT+++9r0KBBAdsWAACAYAvZc+zy8vJUUFCglJQU17SIiAj1799fWVlZkqStW7eqrKzMrSYhIUFdu3Z11QAAANQXIfvkiYKCAklSXFyc2/S4uDjt3r3bVdOwYUM1bdq0Qk35+ytTWlqq0tJS1+uioiJJUllZmcrKyvzSv7+V9xWq/YUaxss7tT1eTqdTUVFRCpOR3XmiyrowGUVFRcnpdPqlF0/X28Bu86pOkl+WV7692dnZcjqd1W5L8+bN1bp162prQhF/F73DeHmnvoyXN9tnM8aYWuzFYzabTatWrdJNN90kScrKylLfvn21b98+tWzZ0lV3++23a8+ePVqzZo0yMjI0ZswYt5AmScnJyTrvvPP03HPPVbqutLQ0zZo1q8L0jIwMRUdH+2+jAAAAzlBxcbFSU1N1+PBhNW7cuNrakN1jFx8fL+nUXrlfB7vCwkLXXrz4+HgdP35chw4dcttrV1hYqD59+lS57BkzZmjatGmu10VFRWrTpo1SUlJqHLBgKSsrU2ZmppKTkxUeHh7sdkIe4+Wd2h6vHTt2qF+/fprwwltK6Ni1yrp9OTu1aPwQbdy4Ud27V/3MVn+vd8faN7Xqkbs9qlvzfw9oyZIlyk3oKae98q9Qb5a36pG7NfShp3ROu/OqrPtx97da9cjdfhuXQOLvoncYL+/Ul/EqP7LoiZANdomJiYqPj1dmZqYuvvhiSdLx48e1YcMGPf7445Kknj17Kjw8XJmZmRo2bJgkaf/+/dq5c6fmzp1b5bIjIiIUERFRYXp4eHjIfzDqQo+hhPHyTm2Nl91uV0lJiU7KVmUYkqSTsqmkpER2u90vfXi63hNO41WdJDntDaqs9XZ5zdqdr/jOVQc2f49LMPB30TuMl3esPl7ebFtQg90vv/yib775xvU6Ly9P27dvV7NmzdS2bVtNnTpVc+bMUVJSkpKSkjRnzhxFR0crNTVVktSkSRONGzdO99xzj5o3b65mzZrp3nvvVbdu3VxXyQIAANQXQQ12W7Zs0cCBA12vyw+Pjh49WkuXLtX06dNVUlKiSZMm6dChQ+rdu7fWrl2rRo0aud7z1FNPqUGDBho2bJhKSkp01VVXaenSpQoLCwv49gAAAARTUIPdgAEDVN21GzabTWlpaUpLS6uyJjIyUk8//bSefvrpWugQAACg7gjZ+9gBAADAOwQ7AAAAiyDYAQAAWATBDgAAwCIIdgAAABZBsAMAALAIgh0AAIBFEOwAAAAsgmAHAABgEQQ7AAAAiyDYAQAAWATBDgAAwCIIdgAAABZBsAMAALCIBsFuAABOl52dXWNNbGys2rZtG4BuAKDuINgBCBlHHAdks9s1YsSIGmujoqP1dXY24Q4AfoVgByBklBwpknE6NWz2QrVITKqyrjAvV688eIccDgfBDgB+hWAHIOS0SExSq87dg91GyOEQNYCaEOwAIMRxiBqApwh2ABDiOEQNwFMEOwCoIzhEDaAm3McOAADAIgh2AAAAFsGhWAB1Vk1XiXpyFSkAWAnBDkCd481VogBQnxDsANQ5nl4lmvPxB8pc8GgAOwOA4CLYAaizarpKtDAvN4DdAEDwcfEEAACARRDsAAAALIJgBwAAYBEEOwAAAIsg2AEAAFgEwQ4AAMAiCHYAAAAWQbADAACwCIIdAACARRDsAAAALIJgBwAAYBEEOwAAAIsg2AEAAFgEwQ4AAMAiCHYAAAAWQbADAACwCIIdAACARRDsAAAALIJgBwAAYBEEOwAAAItoEOwGANRd+fn5cjgcNdZlZ2cHoBsAAMEOgE/y8/PVqXNnlRQXB7sVAMB/EewA+MThcKikuFjDZi9Ui8SkamtzPv5AmQseDVBnAFB/hXSwO3HihNLS0vSPf/xDBQUFatmypW677TY9+OCDsttPnR5ojNGsWbO0aNEiHTp0SL1799azzz6rLl26BLl7oH5okZikVp27V1tTmJcboG7gKU8Po8fGxqpt27YB6AiAP4R0sHv88cf13HPPadmyZerSpYu2bNmiMWPGqEmTJpoyZYokae7cuZo3b56WLl2qDh06aPbs2UpOTlZOTo4aNWoU5C0AgNDjzWH0qOhofZ2dTbgD6oiQDnabN2/WjTfeqOuvv16S1L59ey1fvlxbtmyRdGpv3fz58zVz5kzdfPPNkqRly5YpLi5OGRkZmjhxYtB6B4BQ5elh9MK8XL3y4B1yOBwEO6COCOlgd8UVV+i5557Trl271KFDB+3YsUMfffSR5s+fL0nKy8tTQUGBUlJSXO+JiIhQ//79lZWVVWWwKy0tVWlpqet1UVGRJKmsrExlZWW1t0FnoLyvUO0v1DBe3vFlvJxOp6KiohQmI7vzRLW1Dew2j2rrSp2kkOwvTEZRUVFyOp3V/i7Lf3ctE89XQseqT1vxdHnV4e+idxgv79SX8fJm+2zGGFOLvZwRY4weeOABPf744woLC9PJkyf1l7/8RTNmzJAkZWVlqW/fvtq7d68SEhJc75swYYJ2796t9957r9LlpqWladasWRWmZ2RkKDo6unY2BgAAwAfFxcVKTU3V4cOH1bhx42prQ3qP3cqVK/Xyyy8rIyNDXbp00fbt2zV16lQlJCRo9OjRrjqbzeb2PmNMhWm/NmPGDE2bNs31uqioSG3atFFKSkqNAxYsZWVlyszMVHJyssLDw4PdTshjvLzjy3jt2LFD/fr104QX3lJCx67V1659U6seubvG2rpQt+b/HtCSJUuUm9BTTnvlX6HB6m9fzk4tGj9EGzduVPfuVV/Q4unvztPlVYe/i95hvLxTX8ar/MiiJ0I62P3P//yP7r//ft1yyy2SpG7dumn37t169NFHNXr0aMXHx0uS64rZcoWFhYqLi6tyuREREYqIiKgwPTw8POQ/GHWhx1DCeHnHm/Gy2+0qKSnRSdmqDDjlTjiNR7V1pU6SnPYGVdYGq7+TsqmkpER2u73a36OnvztPl+cJ/i56h/HyjtXHy5ttC+lHihUXF7tua1IuLCxMTqdTkpSYmKj4+HhlZma65h8/flwbNmxQnz59AtorAABAsIX0HrvBgwfrL3/5i9q2basuXbpo27ZtmjdvnsaOHSvp1CHYqVOnas6cOUpKSlJSUpLmzJmj6OhopaamBrl7AACAwArpYPf000/roYce0qRJk1RYWKiEhARNnDhR//u//+uqmT59ukpKSjRp0iTXDYrXrl3LPewAAEC9E9LBrlGjRpo/f77r9iaVsdlsSktLU1paWsD6AgAACEUhfY4dAAAAPEewAwAAsIiQPhQLIDg8eUB8dnZ2gLoBAHiKYAfAjTcPiAcAhBaCHQA3nj4gPufjD5S54NEAdgYAqAnBDkClWiQmqVXnqh8jVZiXG8BuAACe4OIJAAAAiyDYAQAAWATBDgAAwCIIdgAAABbhU7DLy8vzdx8AAAA4Qz4Fu/PPP18DBw7Uyy+/rGPHjvm7JwAAAPjAp2C3Y8cOXXzxxbrnnnsUHx+viRMn6rPPPvN3bwAAAPCCT8Gua9eumjdvnvbu3av09HQVFBToiiuuUJcuXTRv3jz9+OOP/u4TAAAANTijiycaNGigoUOH6pVXXtHjjz+ub7/9Vvfee69at26tUaNGaf/+/f7qEwAAADU4o2C3ZcsWTZo0SS1bttS8efN077336ttvv9WHH36ovXv36sYbb/RXnwAAAKiBT48UmzdvntLT05WTk6PrrrtOL774oq677jrZ7adyYmJiop5//nl16tTJr80CAACgaj4Fu4ULF2rs2LEaM2aM4uPjK61p27atFi9efEbNAQAAwHM+Bbvc3Jof/t2wYUONHj3al8UDAADABz6dY5eenq5XX321wvRXX31Vy5YtO+OmAAAA4D2fgt1jjz2m2NjYCtNbtGihOXPmnHFTAAAA8J5PwW737t1KTEysML1du3bKz88/46YAAADgPZ+CXYsWLfTvf/+7wvQdO3aoefPmZ9wUAAAAvOfTxRO33HKL/vSnP6lRo0bq16+fJGnDhg2aMmWKbrnlFr82CMB/8vPz5XA4Kkx3Op2STv3nLCcnJ9Btwc+ys7PPaD6AusunYDd79mzt3r1bV111lRo0OLUIp9OpUaNGcY4dEKLy8/PVqXNnlRQXV5gXFRWl5cuXq1+/fiopKQlCd/CHI44DstntGjFiRLBbARAkPgW7hg0bauXKlXrkkUe0Y8cORUVFqVu3bmrXrp2/+wPgJw6HQyXFxRo2e6FaJCa5zQuTkXRUE154S199/KEyFzwanCZxRkqOFMk4nZX+jn8t5+MP+B0DFuVTsCvXoUMHdejQwV+9AAiAFolJatW5u9s0u/OE9MOnSujYVfvzvglSZ/CXyn7Hv1aYV/O9SL3lyWF+u92u0tJSRUREeLTM2NhYtW3b1q99AlbnU7A7efKkli5dqg8++ECFhYWuv7jlPvzwQ780BwAIfd4c5rfZ7TKn/ZtRlajoaH2dnU24A7zgU7CbMmWKli5dquuvv15du3aVzWbzd18AgDrC28P8NR0qlk7tVXzlwTvkcDgIdoAXfAp2K1as0CuvvKLrrrvO3/0AAOooTw/z13SoGIDvfLqPXcOGDXX++ef7uxcAAACcAZ+C3T333KO//vWvMsb4ux8AAAD4yKdDsR999JHWrVund999V126dFF4eLjb/DfeeMMvzQEAAMBzPgW7s88+W0OHDvV3LwAAADgDPgW79PR0f/cBAACAM+TTOXaSdOLECb3//vt6/vnndeTIEUnSvn379Msvv/itOQAAAHjOpz12u3fv1jXXXKP8/HyVlpYqOTlZjRo10ty5c3Xs2DE999xz/u4TAAAANfBpj92UKVPUq1cvHTp0SFFRUa7pQ4cO1QcffOC35gAAAOA5n6+K/fjjj9WwYUO36e3atdPevXv90hgAAAC849MeO6fTqZMnT1aY/sMPP6hRo0Zn3BQAAAC851OwS05O1vz5812vbTabfvnlFz388MM8ZgwAACBIfDoU+9RTT2ngwIG64IILdOzYMaWmpio3N1exsbFavny5v3sEAACAB3wKdgkJCdq+fbuWL1+uL774Qk6nU+PGjdPw4cPdLqYAAABA4PgU7CQpKipKY8eO1dixY/3ZDwAAAHzkU7B78cUXq50/atQon5oBAACA73wKdlOmTHF7XVZWpuLiYjVs2FDR0dEEOwAAgCDw6arYQ4cOuf388ssvysnJ0RVXXMHFEwAAAEHi87NiT5eUlKTHHnuswt48AAAABIbfgp0khYWFad++ff5cJAAAADzk0zl2b731lttrY4z279+vZ555Rn379vVLYwAAAPCOT8Hupptucntts9l0zjnn6De/+Y2efPJJf/TlsnfvXt1333169913VVJSog4dOmjx4sXq2bOnpFOhctasWVq0aJEOHTqk3r1769lnn1WXLl382gcAAECo8ynYOZ1Of/dRqUOHDqlv374aOHCg3n33XbVo0ULffvutzj77bFfN3LlzNW/ePC1dulQdOnTQ7NmzlZycrJycHJ5bCwAA6hWfb1AcCI8//rjatGmj9PR017T27du7/myM0fz58zVz5kzdfPPNkqRly5YpLi5OGRkZmjhxYqBbBgAACBqfgt20adM8rp03b54vq5B06ly+QYMG6fe//702bNigVq1aadKkSbr99tslSXl5eSooKFBKSorrPREREerfv7+ysrKqDHalpaUqLS11vS4qKpJ06n58ZWVlPvdbm8r7CtX+Qg3jVZHT6VRUVJTCZGR3nnCbV/7a7jyhBnZblXW/5mmdN7V1pU5SSPfnr7owGUVFRcnpdFb7d8nfny1v1m01fHd5p76MlzfbZzPGGG9XMHDgQH3xxRc6ceKEOnbsKEnatWuXwsLC1KNHj/+/cJtNH374obeLd4mMjJR0Kkj+/ve/12effaapU6fq+eef16hRo5SVlaW+fftq7969SkhIcL1vwoQJ2r17t957771Kl5uWlqZZs2ZVmJ6RkaHo6Gif+wUAAPC34uJipaam6vDhw2rcuHG1tT7tsRs8eLAaNWqkZcuWqWnTppJOnQ83ZswYXXnllbrnnnt8WWwFTqdTvXr10pw5cyRJF198sb788kstXLjQ7ekWNpvN7X3GmArTfm3GjBluex2LiorUpk0bpaSk1DhgwVJWVqbMzEwlJycrPDw82O2EPMaroh07dqhfv36a8MJbSujY1W2e3XlCSfu2Kjehp7a9/0+teuTuSuvclrf2TY/qvKmtC3Vr/u8BLVmyRLkJPeW0V/4VWhe2w5O6fTk7tWj8EG3cuFHdu3evenl+/mx5s26r4bvLO/VlvMqPLHrCp2D35JNPau3ata5QJ0lNmzbV7NmzlZKS4rdg17JlS11wwQVu0zp37qzXX39dkhQfHy9JKigoUMuWLV01hYWFiouLq3K5ERERioiIqDA9PDw85D8YdaHHUMJ4/X92u10lJSU6KVuVgcRpb6ATTlNjnSSP67yprSt10qmxqqo22P35q+6kbCopKZHdbq/275G/P1verNuq+O7yjtXHy5tt8+kGxUVFRTpw4ECF6YWFhTpy5Igvi6xU3759lZOT4zZt165dateunSQpMTFR8fHxyszMdM0/fvy4NmzYoD59+vitDwAAgLrAp2A3dOhQjRkzRq+99pp++OEH/fDDD3rttdc0btw419Wp/nD33Xfrk08+0Zw5c/TNN98oIyNDixYt0uTJkyWdOgQ7depUzZkzR6tWrdLOnTt12223KTo6WqmpqX7rAwAAoC7w6VDsc889p3vvvVcjRoxwXanRoEEDjRs3Tk888YTfmrvkkku0atUqzZgxQ3/+85+VmJio+fPna/jw4a6a6dOnq6SkRJMmTXLdoHjt2rXcww4A/CQ7O/uM5gMIHJ+CXXR0tBYsWKAnnnhC3377rYwxOv/88xUTE+Pv/nTDDTfohhtuqHK+zWZTWlqa0tLS/L5uAKjPjjgOyGa3a8SIEcFuBYCHzugGxfv379f+/fvVr18/RUVF1Xg1KgCg7ig5UiTjdGrY7IVqkZhUZV3Oxx8oc8GjAewMQFV8CnYHDx7UsGHDtG7dOtlsNuXm5urcc8/V+PHjdfbZZ/v9ebEAgOBpkZikVp2rvuVIYV5uALsBUB2fLp64++67FR4ervz8fLcb+v7hD3/QmjVr/NYcAAAAPOfTHru1a9fqvffeU+vWrd2mJyUlaffu3X5pDAAAAN7xaY/d0aNHK330lsPhqPTGvwAAAKh9PgW7fv366cUXX3S9ttlscjqdeuKJJzRw4EC/NQcAAADP+XQo9oknntCAAQO0ZcsWHT9+XNOnT9eXX36pn376SR9//LG/ewQAAIAHfNpjd8EFF+jf//63Lr30UiUnJ+vo0aO6+eabtW3bNp133nn+7hEAAAAe8HqPXVlZmVJSUvT8889r1qxZtdETAAAAfOD1Hrvw8HDt3LmTGxEDAACEGJ8OxY4aNUqLFy/2dy8AAAA4Az5dPHH8+HG98MILyszMVK9evSo8I3bevHl+aQ4AAACe8yrYfffdd2rfvr127typHj16SJJ27drlVsMhWgAAgODwKtglJSVp//79WrdunaRTjxD729/+pri4uFppDgAAAJ7z6hw7Y4zb63fffVdHjx71a0MAAADwjU8XT5Q7PegBAAAgeLwKdjabrcI5dJxTBwAAEBq8OsfOGKPbbrtNERERkqRjx47pj3/8Y4WrYt944w3/dQgAAACPeBXsRo8e7fZ6xIgRfm0GAAAAvvMq2KWnp9dWHwAAADhDPt2gGACAQMjOzq6xJjY2Vm3btg1AN0DoI9gBAELOEccB2ex2j075iYqO1tfZ2YQ7QAQ7AEAIKjlSJON0atjshWqRmFRlXWFerl558A45HA6CHSCCHQAghLVITFKrzt2D3QZQZ5zRDYoBAAAQOgh2AAAAFkGwAwAAsAiCHQAAgEUQ7AAAACyCq2IBC8jPz5fD4ai2xpMbvQIA6jaCHVDH5efnq1PnziopLg52KwCAICPYAXWcw+FQSXFxjTdyzfn4A2UueDSAnQEAAo1gB1hETTdyLczLDWA3QGDxTFngFIIdAKDO4pmygDuCHQCgzuKZsoA7gh0AoM7jmbLAKdzHDgAAwCIIdgAAABbBoVgAQL3B1bOwOoIdAMDyuHoW9QXBDgBgeVw9i/qCYAcAqDe4ehZWx8UTAAAAFkGwAwAAsAiCHQAAgEUQ7AAAACyCYAcAAGARBDsAAACLINgBAABYBMEOAADAIupUsHv00Udls9k0depU1zRjjNLS0pSQkKCoqCgNGDBAX375ZfCaBAAACJI6E+w+//xzLVq0SBdeeKHb9Llz52revHl65pln9Pnnnys+Pl7Jyck6cuRIkDoFAAAIjjoR7H755RcNHz5cf//739W0aVPXdGOM5s+fr5kzZ+rmm29W165dtWzZMhUXFysjIyOIHQMAAARenXhW7OTJk3X99dfr6quv1uzZs13T8/LyVFBQoJSUFNe0iIgI9e/fX1lZWZo4cWKlyystLVVpaanrdVFRkSSprKxMZWVltbQVZ6a8r1DtL9TUp/FyOp2KiopSmIzszhNV1jWw26qsK39td56ots7T5flaW1fqJIV0f6FU58tnK5jbEiajqKgoOZ3OoHx/1KfvLn+oL+PlzfbZjDGmFns5YytWrNBf/vIXff7554qMjNSAAQN00UUXaf78+crKylLfvn21d+9eJSQkuN4zYcIE7d69W++9916ly0xLS9OsWbMqTM/IyFB0dHStbQsAAIC3iouLlZqaqsOHD6tx48bV1ob0Hrs9e/ZoypQpWrt2rSIjI6uss9lsbq+NMRWm/dqMGTM0bdo01+uioiK1adNGKSkpNQ5YsJSVlSkzM1PJyckKDw8Pdjshrz6N144dO9SvXz9NeOEtJXTsWnXd2je16pG7K62zO08oad9W5Sb01Lb3/1llnafL87W2LtSt+b8HtGTJEuUm9JTTXvlXaF3YjkDV+fLZCua27MvZqUXjh2jjxo3q3r17tT3Whvr03eUP9WW8yo8seiKkg93WrVtVWFionj17uqadPHlSGzdu1DPPPKOcnBxJUkFBgVq2bOmqKSwsVFxcXJXLjYiIUERERIXp4eHhIf/BqAs9hpL6MF52u10lJSU6KVuVQUOSTjhNjXVOewOP6jxdnre1daVOOjVWVdUGu79QrPPmsxXMbTkpm0pKSmS324P63VEfvrv8yerj5c22hfTFE1dddZX+85//aPv27a6fXr16afjw4dq+fbvOPfdcxcfHKzMz0/We48ePa8OGDerTp08QOwcAAAi8kN5j16hRI3Xt6r7LPCYmRs2bN3dNnzp1qubMmaOkpCQlJSVpzpw5io6OVmpqajBaBgAACJqQDnaemD59ukpKSjRp0iQdOnRIvXv31tq1a9WoUaNgtwYAABBQdS7YrV+/3u21zWZTWlqa0tLSgtIPAABAqAjpc+wAAADgOYIdAACARRDsAAAALIJgBwAAYBEEOwAAAIsg2AEAAFgEwQ4AAMAi6tx97IBQlp+fL4fDUWNdbGys2rZtG4COAAD1CcEO8JP8/Hx16txZJcXFNdZGRUfr6+xswh0AwK8IdoCfOBwOlRQXa9jshWqRmFRlXWFerl558A45HA6CHQDArwh2gJ+1SExSq87da6zLzs6usYZDtgAAbxDsgAA74jggm92uESNG1FjLIVsAgDcIdkCAlRwpknE6OWQLAPA7gh0QJP46ZOvJIV0AQP1AsANClDeHbAEAkAh2QMjy9JBtzscfKHPBowHsDAAQqgh2QIir6ZBtYV5uALsBAIQyHikGAABgEQQ7AAAAiyDYAQAAWATBDgAAwCIIdgAAABZBsAMAALAIgh0AAIBFEOwAAAAsgmAHAABgEQQ7AAAAiyDYAQAAWATBDgAAwCIIdgAAABZBsAMAALAIgh0AAIBFEOwAAAAsgmAHAABgEQQ7AAAAiyDYAQAAWATBDgAAwCIIdgAAABZBsAMAALAIgh0AAIBFEOwAAAAsgmAHAABgEQQ7AAAAiyDYAQAAWATBDgAAwCIIdgAAABZBsAMAALCIBsFuAACAUJOdnV1jTWxsrNq2bRuAbgDPEewAAPivI44DstntGjFiRI21UdHR+jo7m3CHkBLSwe7RRx/VG2+8oa+//lpRUVHq06ePHn/8cXXs2NFVY4zRrFmztGjRIh06dEi9e/fWs88+qy5dugSxcwBAXVRypEjG6dSw2QvVIjGpyrrCvFy98uAdcjgcBDuElJAOdhs2bNDkyZN1ySWX6MSJE5o5c6ZSUlL01VdfKSYmRpI0d+5czZs3T0uXLlWHDh00e/ZsJScnKycnR40aNQryFsAq8vPz5XA4qq3x5NANgLqhRWKSWnXuHuw2AK+FdLBbs2aN2+v09HS1aNFCW7duVb9+/WSM0fz58zVz5kzdfPPNkqRly5YpLi5OGRkZmjhxYjDahsXk5+erU+fOKikuDnYrAABUK6SD3ekOHz4sSWrWrJkkKS8vTwUFBUpJSXHVREREqH///srKyiLYwS8cDodKiotrPDST8/EHylzwaAA7AwDAXZ0JdsYYTZs2TVdccYW6du0qSSooKJAkxcXFudXGxcVp9+7dVS6rtLRUpaWlrtdFRUWSpLKyMpWVlfm7db8o7ytU+ws1/hwvp9OpqKgotUw8Xwkdqz5386fd3ygqKkphMrI7T1RZ18BuC7m68td25wm/rzfQ2xKIOkkh3V8o1fny2QrVbfm1MBlFRUXJ6XT69XuZ73rv1Jfx8mb7bMYYU4u9+M3kyZP1z3/+Ux999JFat24tScrKylLfvn21b98+tWzZ0lV7++23a8+ePRUO5ZZLS0vTrFmzKkzPyMhQdHR07WwAAACAD4qLi5WamqrDhw+rcePG1dbWiT12d911l9566y1t3LjRFeokKT4+XtKpPXe/DnaFhYUV9uL92owZMzRt2jTX66KiIrVp00YpKSk1DliwlJWVKTMzU8nJyQoPDw92OyHPn+O1Y8cO9evXTxNeeEsJHbtWXbf2Ta165O46WWd3nlDSvq3KTeipbe//06/rDfS21Hbdmv97QEuWLFFuQk857ZV/hdaF7Qjlz1aobsuv7cvZqUXjh2jjxo3q3t1/F1nwXe+d+jJe5UcWPRHSwc4Yo7vuukurVq3S+vXrlZiY6DY/MTFR8fHxyszM1MUXXyxJOn78uDZs2KDHH3+8yuVGREQoIiKiwvTw8PCQ/2DUhR5DiT/Gy263q6SkRCdlq/Ifckk64TR1vs5pb+D39QZrW2qzTjo1VlXVBru/UKzz5rMV6tsiSSdlU0lJiex2e618J/Nd7x2rj5c32xbSwW7y5MnKyMjQm2++qUaNGrnOqWvSpImioqJks9k0depUzZkzR0lJSUpKStKcOXMUHR2t1NTUIHcPAAAQWCEd7BYuXChJGjBggNv09PR03XbbbZKk6dOnq6SkRJMmTXLdoHjt2rXcww4AANQ7IR3sPLmuw2azKS0tTWlpabXfEAAAQAizB7sBAAAA+AfBDgAAwCJC+lAsUNt4BiyAM+HJ90NsbKzatm0bgG4Agh3qMZ4BC8BXRxwHZLPbNWLEiBpro6Kj9XV2NuEOAUGwQ73FM2AB+KrkSJGM01nj90dhXq5eefAOORwOgh0CgmCHeq9FYpJada76zvGFebkB7AZAXVLT9wcQaFw8AQAAYBEEOwAAAIsg2AEAAFgEwQ4AAMAiCHYAAAAWQbADAACwCIIdAACARRDsAAAALIIbFAMAUMs8faZsy5YtA9ANrIxgBwBALfH2mbJf7twZgK5gZQQ7AABqibfPlD148GAAu4MVEexQp+Tn58vhcNRY17Rp0wB0AwCe8fSZsjk5OTrrrLO0Y8cO2e2VnwYfGxurtm3b+rtFWATBDnVGfn6+OnXurJLi4hprmzVvriWLFwegKwA4c+WHbG+//XYtX75c/fr1U0lJSaW1UdHR+jo7m3CHShHsUGc4HA6VFBd7dEjj7b9MC2BnAHBmyg/ZDn3oKUnShBfe0knZKtSVH7J1OBwEO1SKYIeQ4Mkh1vKryjw9pAEAdc057c6TdFQJHbvKaeefaHiPTw2CzptDrAAAoGoEOwSdp4dYcz7+QJkLHg1gZwAA1C0EO4SMmg6xFubler3M6q4s8+SGoQAA1CUEO1hO+dVlkqq9sgwAAKsh2MFyyq8uk6q+skzi0C4AwHoIdvCapzcJloJ/I83qrizz5dAuAAChjGAHr3h7BSs30gQAIHAIdvCKp1ewStxIEwCAQCPYwYWbBAMAULcR7CCJmwQDAGAFBDtI4ibBAABYAcEObmrjJsEAgLrP0zsiBPtuCPUdwQ4AAFTLm9N1uBtCcBHsAABAtTw9XYe7IQQfwQ4AAAvy9NBpaWmpIiIiqq3hjgh1B8EOAACL8ebQqc1udz2GEXUfwQ4AAIvx9k4H3BHBOgh2AABYlKd3OuCOCNZBsAMAoI4pP+fN1/m1zZP1c1uU2kGwAwCgjjjiOCCb3a4RI0YEu5VKedMft0WpHQQ7AADqiJIjRTJOZ8ieE+dpf9wWpfYQ7FDrQv2QAQDUNaF+Thy3RQkegh1qTagfMgAAwGoIdqg1oX7IAAAAqyHY1QOe3H28Ng+HhvohAwBAcHj6bw9X0HqOYGdx3tx9HACAQPD2VB2uoPUcwc7ivL37OAAAtc3TU3UkrqD1FsGunuBwKAAg1ATr6llPTlGS6uYhYIIdAACoN7w5RakuHgK2TLBbsGCBnnjiCe3fv19dunTR/PnzdeWVVwa7LQAAEEI8PUWprh4CtkSwW7lypaZOnaoFCxaob9++ev7553Xttdfqq6++Cqlfhqe7fktLSxUREeE2zel0SpJ27Nghu91eZd3puPkvAKC+8OYuEJ4eBq5rz721RLCbN2+exo0bp/Hjx0uS5s+fr/fee08LFy7Uo4+GxgUB3uz6tdntMv8NcuWioqK0fPly9evXTyUlJVXWAQBQH/n7LhB19bm3dT7YHT9+XFu3btX999/vNj0lJUVZWVlB6qoib69OPb0uTEbSUU144S2dlK3KuqqWBwCAlfn7LhB19bm3dT7YORwOnTx5UnFxcW7T4+LiVFBQUOl7SktLVVpa6np9+PBhSdJPP/2ksrKyWumzqKhIkZGRMseP6UTxL1UXnjxRaZ2RUbGtRCeKjU7KVmVdVcs7kPOfausO7fnOr3W1sUxv64qLi5W/7ZNT4xWC/YVSXZiM2sSUKH/bJ5b8LPDZCl6dL5+tUN2WgNTlfqniDi2q/HwFvb8g/FtycE+eIiMjtXXrVhUVFbnNczqdKi4u1qZNm/Ttt9/Wyr+LNS3PHD+myMhIFRUV6eDBg9Vui6+OHDlyal3G1Fxs6ri9e/caSSYrK8tt+uzZs03Hjh0rfc/DDz9sJPHDDz/88MMPP/zUmZ89e/bUmIvq/B672NhYhYWFVdg7V1hYWGEvXrkZM2Zo2rRprtdOp1M//fSTmjdvLput8v+BB1tRUZHatGmjPXv2qHHjxsFuJ+QxXt5hvDzHWHmH8fIO4+Wd+jJexhgdOXJECQkJNdbW+WDXsGFD9ezZU5mZmRo6dKhremZmpm688cZK3xMREVHhatKzzz67Ntv0m8aNG1v6w+tvjJd3GC/PMVbeYby8w3h5pz6MV5MmTTyqq/PBTpKmTZumkSNHqlevXrr88su1aNEi5efn649//GOwWwMAAAgYSwS7P/zhDzp48KD+/Oc/a//+/eratav+9a9/qV27dsFuDQAAIGAsEewkadKkSZo0aVKw26g1ERERevjhh2u8ITFOYby8w3h5jrHyDuPlHcbLO4xXRTZjPLl2FgAAAKHOHuwGAAAA4B8EOwAAAIsg2AEAAFgEwS5EHTp0SCNHjlSTJk3UpEkTjRw5Uj///HO170lLS1OnTp0UExOjpk2b6uqrr9ann34amIaDzNvxKisr03333adu3bopJiZGCQkJGjVqlPbt2xe4poPIl8/XG2+8oUGDBik2NlY2m03bt28PSK/BsGDBAiUmJioyMlI9e/bUpk2bqq3fsGGDevbsqcjISJ177rl67rnnAtRpaPBmvPbv36/U1FR17NhRdrtdU6dODVyjIcKb8XrjjTeUnJysc845R40bN9bll1+u9957L4DdBp834/XRRx+pb9++at68uaKiotSpUyc99dRTAew2+Ah2ISo1NVXbt2/XmjVrtGbNGm3fvl0jR46s9j0dOnTQM888o//85z/66KOP1L59e6WkpOjHH38MUNfB4+14FRcX64svvtBDDz2kL774Qm+88YZ27dqlIUOGBLDr4PHl83X06FH17dtXjz32WIC6DI6VK1dq6tSpmjlzprZt26Yrr7xS1157rfLz8yutz8vL03XXXacrr7xS27Zt0wMPPKA//elPev311wPceXB4O16lpaU655xzNHPmTHXv3j3A3Qaft+O1ceNGJScn61//+pe2bt2qgQMHavDgwdq2bVuAOw8Ob8crJiZGd955pzZu3Kjs7Gw9+OCDevDBB7Vo0aIAdx5EZ/60VvjbV199ZSSZTz75xDVt8+bNRpL5+uuvPV7O4cOHjSTz/vvv10abIcNf4/XZZ58ZSWb37t210WbIONPxysvLM5LMtm3barHL4Ln00kvNH//4R7dpnTp1Mvfff3+l9dOnTzedOnVymzZx4kRz2WWX1VqPocTb8fq1/v37mylTptRSZ6HpTMar3AUXXGBmzZrl79ZCkj/Ga+jQoWbEiBH+bi1ksccuBG3evFlNmjRR7969XdMuu+wyNWnSRFlZWR4t4/jx41q0aJGaNGli+f8V+2O8JOnw4cOy2Wx15vFyvvLXeFnR8ePHtXXrVqWkpLhNT0lJqXJsNm/eXKF+0KBB2rJli8rKymqt11Dgy3jVZ/4YL6fTqSNHjqhZs2a10WJI8cd4bdu2TVlZWerfv39ttBiSCHYhqKCgQC1atKgwvUWLFiooKKj2ve+8847OOussRUZG6qmnnlJmZqZiY2Nrq9WQcCbjVe7YsWO6//77lZqaavnnDfpjvKzK4XDo5MmTiouLc5seFxdX5dgUFBRUWn/ixAk5HI5a6zUU+DJe9Zk/xuvJJ5/U0aNHNWzYsNpoMaScyXi1bt1aERER6tWrlyZPnqzx48fXZqshhWAXQGlpabLZbNX+bNmyRZJks9kqvN8YU+n0Xxs4cKC2b9+urKwsXXPNNRo2bJgKCwtrZXtqWyDGSzp1IcUtt9wip9OpBQsW+H07AiVQ41UfnD4ONY1NZfWVTbcqb8ervvN1vJYvX660tDStXLmy0v+cWZUv47Vp0yZt2bJFzz33nObPn6/ly5fXZoshxTKPFKsL7rzzTt1yyy3V1rRv317//ve/deDAgQrzfvzxxwr/czldTEyMzj//fJ1//vm67LLLlJSUpMWLF2vGjBln1HswBGK8ysrKNGzYMOXl5enDDz+s03vrAjFeVhcbG6uwsLAKewMKCwurHJv4+PhK6xs0aKDmzZvXWq+hwJfxqs/OZLxWrlypcePG6dVXX9XVV19dm22GjDMZr8TERElSt27ddODAAaWlpenWW2+ttV5DCcEugGJjYz06LHr55Zfr8OHD+uyzz3TppZdKkj799FMdPnxYffr08WqdxhiVlpb61G+w1fZ4lYe63NxcrVu3rs7/IxyMz5fVNGzYUD179lRmZqaGDh3qmp6Zmakbb7yx0vdcfvnlevvtt92mrV27Vr169VJ4eHit9htsvoxXfebreC1fvlxjx47V8uXLdf311wei1ZDgr89XXf530CfBumoD1bvmmmvMhRdeaDZv3mw2b95sunXrZm644Qa3mo4dO5o33njDGGPML7/8YmbMmGE2b95svv/+e7N161Yzbtw4ExERYXbu3BmMTQgob8errKzMDBkyxLRu3dps377d7N+/3/VTWloajE0IKG/HyxhjDh48aLZt22b++c9/GklmxYoVZtu2bWb//v2Bbr9WrVixwoSHh5vFixebr776ykydOtXExMSY77//3hhjzP33329Gjhzpqv/uu+9MdHS0ufvuu81XX31lFi9ebMLDw81rr70WrE0IKG/Hyxhjtm3bZrZt22Z69uxpUlNTzbZt28yXX34ZjPYDztvxysjIMA0aNDDPPvus2/fUzz//HKxNCChvx+uZZ54xb731ltm1a5fZtWuXWbJkiWncuLGZOXNmsDYh4Ah2IergwYNm+PDhplGjRqZRo0Zm+PDh5tChQ241kkx6eroxxpiSkhIzdOhQk5CQYBo2bGhatmxphgwZYj777LPANx8E3o5X+S07KvtZt25dwPsPNG/Hyxhj0tPTKx2vhx9+OKC9B8Kzzz5r2rVrZxo2bGh69OhhNmzY4Jo3evRo079/f7f69evXm4svvtg0bNjQtG/f3ixcuDDAHQeXt+NV2eeoXbt2gW06iLwZr/79+1c6XqNHjw5840HizXj97W9/M126dDHR0dGmcePG5uKLLzYLFiwwJ0+eDELnwWEz5r9n+QIAAKBO46pYAAAAiyDYAQAAWATBDgAAwCIIdgAAABZBsAMAALAIgh0AAIBFEOwAAAAsgmAHAABgEQQ7APCjAQMGaOrUqcFuA0A9RbADgP8aPHiwrr766krnbd68WTabTV988UWAuwIAzxHsAOC/xo0bpw8//FC7d++uMG/JkiW66KKL1KNHjyB0BgCeIdgBwH/dcMMNatGihZYuXeo2vbi4WCtXrtRNN92kW2+9Va1bt1Z0dLS6deum5cuXV7tMm82m1atXu007++yz3daxd+9e/eEPf1DTpk3VvHlz3Xjjjfr+++/9s1EA6hWCHQD8V4MGDTRq1CgtXbpUxhjX9FdffVXHjx/X+PHj1bNnT73zzjvauXOnJkyYoJEjR+rTTz/1eZ3FxcUaOHCgzjrrLG3cuFEfffSRzjrrLF1zzTU6fvy4PzYLQD1CsAOAXxk7dqy+//57rV+/3jVtyZIluvnmm9WqVSvde++9uuiii3Tuuefqrrvu0qBBg/Tqq6/6vL4VK1bIbrfrhRdeULdu3dS5c2elp6crPz/frQcA8ESDYDcAAKGkU6dO6tOnj5YsWaKBAwfq22+/1aZNm7R27VqdPHlSjz32mFauXKm9e/eqtLRUpaWliomJ8Xl9W7du1TfffKNGjRq5TT927Ji+/fbbM90cAPUMwQ4ATjNu3DjdeeedevbZZ5Wenq527drpqquu0hNPPKGnnnpK8+fPV7du3RQTE6OpU6dWe8jUZrO5HdaVpLKyMtefnU6nevbsqX/84x8V3nvOOef4b6MA1AsEOwA4zbBhwzRlyhRlZGRo2bJluv3222Wz2bRp0ybdeOONGjFihKRToSw3N1edO3euclnnnHOO9u/f73qdm5ur4uJi1+sePXpo5cqVatGihRo3blx7GwWgXuAcOwA4zVlnnaU//OEPeuCBB7Rv3z7ddtttkqTzzz9fmZmZysrKUnZ2tiZOnKiCgoJql/Wb3/xGzzzzjL744gtt2bJFf/zjHxUeHu6aP3z4cMXGxurGG2/Upk2blJeXpw0bNmjKlCn64YcfanMzAVgQwQ4AKjFu3DgdOnRIV199tdq2bStJeuihh9SjRw8NGjRIAwYMUHx8vG666aZql/Pkk0+qTZs26tevn1JTU3XvvfcqOjraNT86OlobN25U27ZtdfPNN6tz584aO3asSkpK2IMHwGs2c/rJHwAAAKiT2GMHAABgEQQ7AAAAiyDYAQAAWATBDgAAwCIIdgAAABZBsAMAALAIgh0AAIBFEOwAAAAsgmAHAABgEQQ7AAAAiyDYAQAAWATBDgAAwCL+Hyyu8sG4TtGPAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch-0   lr=['0.0001000'], tr/val_loss:  0.132776/  0.132964, val:  88.43%, val_best:  88.43%, tr:  82.85%, tr_best:  82.85%\n",
      "[module.layers.6] weight_fb parameter count: 2,000\n",
      "[module.layers.10] weight_fb parameter count: 2,000\n",
      "epoch-1   lr=['0.0001000'], tr/val_loss:  0.159144/  0.148794, val:  93.48%, val_best:  93.48%, tr:  90.86%, tr_best:  90.86%\n",
      "epoch-2   lr=['0.0001000'], tr/val_loss:  0.172903/  0.159289, val:  94.53%, val_best:  94.53%, tr:  92.68%, tr_best:  92.68%\n",
      "epoch-3   lr=['0.0001000'], tr/val_loss:  0.172867/  0.176250, val:  93.82%, val_best:  94.53%, tr:  93.27%, tr_best:  93.27%\n",
      "epoch-4   lr=['0.0001000'], tr/val_loss:  0.189127/  0.149039, val:  95.97%, val_best:  95.97%, tr:  94.09%, tr_best:  94.09%\n",
      "epoch-5   lr=['0.0001000'], tr/val_loss:  0.185438/  0.164881, val:  96.64%, val_best:  96.64%, tr:  94.59%, tr_best:  94.59%\n",
      "epoch-6   lr=['0.0001000'], tr/val_loss:  0.178228/  0.170533, val:  94.14%, val_best:  96.64%, tr:  94.99%, tr_best:  94.99%\n",
      "epoch-7   lr=['0.0001000'], tr/val_loss:  0.192231/  0.190397, val:  95.89%, val_best:  96.64%, tr:  94.92%, tr_best:  94.99%\n",
      "epoch-8   lr=['0.0001000'], tr/val_loss:  0.190989/  0.225502, val:  93.56%, val_best:  96.64%, tr:  95.30%, tr_best:  95.30%\n",
      "epoch-9   lr=['0.0001000'], tr/val_loss:  0.202861/  0.214763, val:  93.66%, val_best:  96.64%, tr:  95.55%, tr_best:  95.55%\n",
      "epoch-10  lr=['0.0001000'], tr/val_loss:  0.201975/  0.201015, val:  94.01%, val_best:  96.64%, tr:  95.70%, tr_best:  95.70%\n",
      "epoch-11  lr=['0.0001000'], tr/val_loss:  0.217419/  0.270958, val:  94.18%, val_best:  96.64%, tr:  95.80%, tr_best:  95.80%\n",
      "epoch-12  lr=['0.0001000'], tr/val_loss:  0.220348/  0.183924, val:  96.22%, val_best:  96.64%, tr:  96.03%, tr_best:  96.03%\n",
      "epoch-13  lr=['0.0001000'], tr/val_loss:  0.211637/  0.238208, val:  94.65%, val_best:  96.64%, tr:  96.19%, tr_best:  96.19%\n",
      "epoch-14  lr=['0.0001000'], tr/val_loss:  0.220911/  0.214113, val:  96.25%, val_best:  96.64%, tr:  96.28%, tr_best:  96.28%\n",
      "epoch-15  lr=['0.0001000'], tr/val_loss:  0.222430/  0.184649, val:  97.28%, val_best:  97.28%, tr:  96.28%, tr_best:  96.28%\n",
      "epoch-16  lr=['0.0001000'], tr/val_loss:  0.222640/  0.229853, val:  95.75%, val_best:  97.28%, tr:  96.55%, tr_best:  96.55%\n",
      "epoch-17  lr=['0.0001000'], tr/val_loss:  0.232353/  0.228279, val:  95.78%, val_best:  97.28%, tr:  96.51%, tr_best:  96.55%\n",
      "epoch-18  lr=['0.0001000'], tr/val_loss:  0.235777/  0.236068, val:  96.37%, val_best:  97.28%, tr:  96.50%, tr_best:  96.55%\n",
      "epoch-19  lr=['0.0001000'], tr/val_loss:  0.219768/  0.217716, val:  96.61%, val_best:  97.28%, tr:  96.76%, tr_best:  96.76%\n",
      "epoch-20  lr=['0.0001000'], tr/val_loss:  0.227832/  0.265589, val:  96.07%, val_best:  97.28%, tr:  96.92%, tr_best:  96.92%\n",
      "epoch-21  lr=['0.0001000'], tr/val_loss:  0.236355/  0.233391, val:  95.11%, val_best:  97.28%, tr:  96.76%, tr_best:  96.92%\n",
      "epoch-22  lr=['0.0001000'], tr/val_loss:  0.237192/  0.230602, val:  97.35%, val_best:  97.35%, tr:  96.94%, tr_best:  96.94%\n",
      "epoch-23  lr=['0.0001000'], tr/val_loss:  0.237090/  0.243041, val:  96.88%, val_best:  97.35%, tr:  97.01%, tr_best:  97.01%\n",
      "epoch-24  lr=['0.0001000'], tr/val_loss:  0.234227/  0.235958, val:  96.54%, val_best:  97.35%, tr:  97.07%, tr_best:  97.07%\n",
      "epoch-25  lr=['0.0001000'], tr/val_loss:  0.221646/  0.243087, val:  95.83%, val_best:  97.35%, tr:  97.13%, tr_best:  97.13%\n",
      "epoch-26  lr=['0.0001000'], tr/val_loss:  0.226396/  0.223607, val:  96.77%, val_best:  97.35%, tr:  97.30%, tr_best:  97.30%\n",
      "epoch-27  lr=['0.0001000'], tr/val_loss:  0.247859/  0.212374, val:  97.30%, val_best:  97.35%, tr:  97.15%, tr_best:  97.30%\n",
      "epoch-28  lr=['0.0001000'], tr/val_loss:  0.231860/  0.234621, val:  96.85%, val_best:  97.35%, tr:  97.30%, tr_best:  97.30%\n",
      "epoch-29  lr=['0.0001000'], tr/val_loss:  0.231351/  0.217198, val:  95.47%, val_best:  97.35%, tr:  97.42%, tr_best:  97.42%\n",
      "epoch-30  lr=['0.0001000'], tr/val_loss:  0.247203/  0.302272, val:  95.60%, val_best:  97.35%, tr:  97.30%, tr_best:  97.42%\n",
      "epoch-31  lr=['0.0001000'], tr/val_loss:  0.261889/  0.242186, val:  97.15%, val_best:  97.35%, tr:  97.47%, tr_best:  97.47%\n",
      "epoch-32  lr=['0.0001000'], tr/val_loss:  0.243626/  0.230130, val:  97.22%, val_best:  97.35%, tr:  97.50%, tr_best:  97.50%\n",
      "epoch-33  lr=['0.0001000'], tr/val_loss:  0.247127/  0.284957, val:  95.27%, val_best:  97.35%, tr:  97.43%, tr_best:  97.50%\n",
      "epoch-34  lr=['0.0001000'], tr/val_loss:  0.249230/  0.229796, val:  96.40%, val_best:  97.35%, tr:  97.56%, tr_best:  97.56%\n",
      "epoch-35  lr=['0.0001000'], tr/val_loss:  0.257738/  0.294676, val:  97.55%, val_best:  97.55%, tr:  97.61%, tr_best:  97.61%\n",
      "epoch-36  lr=['0.0001000'], tr/val_loss:  0.242589/  0.268156, val:  97.05%, val_best:  97.55%, tr:  97.68%, tr_best:  97.68%\n",
      "epoch-37  lr=['0.0001000'], tr/val_loss:  0.267048/  0.277956, val:  97.59%, val_best:  97.59%, tr:  97.64%, tr_best:  97.68%\n",
      "epoch-38  lr=['0.0001000'], tr/val_loss:  0.253512/  0.248048, val:  94.98%, val_best:  97.59%, tr:  97.79%, tr_best:  97.79%\n",
      "epoch-39  lr=['0.0001000'], tr/val_loss:  0.259100/  0.322684, val:  96.63%, val_best:  97.59%, tr:  97.69%, tr_best:  97.79%\n",
      "epoch-40  lr=['0.0001000'], tr/val_loss:  0.264317/  0.248249, val:  97.50%, val_best:  97.59%, tr:  97.82%, tr_best:  97.82%\n",
      "epoch-41  lr=['0.0001000'], tr/val_loss:  0.268946/  0.333895, val:  96.23%, val_best:  97.59%, tr:  97.77%, tr_best:  97.82%\n",
      "epoch-42  lr=['0.0001000'], tr/val_loss:  0.254331/  0.288765, val:  95.14%, val_best:  97.59%, tr:  97.94%, tr_best:  97.94%\n",
      "epoch-43  lr=['0.0001000'], tr/val_loss:  0.274091/  0.298689, val:  96.73%, val_best:  97.59%, tr:  97.80%, tr_best:  97.94%\n",
      "epoch-44  lr=['0.0001000'], tr/val_loss:  0.258215/  0.248510, val:  97.44%, val_best:  97.59%, tr:  97.91%, tr_best:  97.94%\n",
      "epoch-45  lr=['0.0001000'], tr/val_loss:  0.260109/  0.246699, val:  97.13%, val_best:  97.59%, tr:  97.93%, tr_best:  97.94%\n",
      "epoch-46  lr=['0.0001000'], tr/val_loss:  0.254397/  0.260260, val:  97.80%, val_best:  97.80%, tr:  97.96%, tr_best:  97.96%\n",
      "epoch-47  lr=['0.0001000'], tr/val_loss:  0.255388/  0.287030, val:  97.26%, val_best:  97.80%, tr:  97.89%, tr_best:  97.96%\n",
      "epoch-48  lr=['0.0001000'], tr/val_loss:  0.249398/  0.280571, val:  97.12%, val_best:  97.80%, tr:  97.96%, tr_best:  97.96%\n",
      "epoch-49  lr=['0.0001000'], tr/val_loss:  0.250187/  0.254690, val:  97.36%, val_best:  97.80%, tr:  98.09%, tr_best:  98.09%\n",
      "epoch-50  lr=['0.0001000'], tr/val_loss:  0.255312/  0.266406, val:  97.76%, val_best:  97.80%, tr:  98.06%, tr_best:  98.09%\n",
      "epoch-51  lr=['0.0001000'], tr/val_loss:  0.264434/  0.239763, val:  97.20%, val_best:  97.80%, tr:  97.99%, tr_best:  98.09%\n",
      "epoch-52  lr=['0.0001000'], tr/val_loss:  0.264695/  0.265139, val:  97.98%, val_best:  97.98%, tr:  98.11%, tr_best:  98.11%\n",
      "epoch-53  lr=['0.0001000'], tr/val_loss:  0.265907/  0.263177, val:  96.78%, val_best:  97.98%, tr:  98.11%, tr_best:  98.11%\n",
      "epoch-54  lr=['0.0001000'], tr/val_loss:  0.259672/  0.257957, val:  97.06%, val_best:  97.98%, tr:  98.12%, tr_best:  98.12%\n",
      "epoch-55  lr=['0.0001000'], tr/val_loss:  0.254170/  0.239979, val:  97.84%, val_best:  97.98%, tr:  98.24%, tr_best:  98.24%\n",
      "epoch-56  lr=['0.0001000'], tr/val_loss:  0.256006/  0.263383, val:  96.26%, val_best:  97.98%, tr:  98.27%, tr_best:  98.27%\n",
      "epoch-57  lr=['0.0001000'], tr/val_loss:  0.267139/  0.244170, val:  97.70%, val_best:  97.98%, tr:  98.18%, tr_best:  98.27%\n",
      "epoch-58  lr=['0.0001000'], tr/val_loss:  0.259251/  0.266806, val:  96.71%, val_best:  97.98%, tr:  98.28%, tr_best:  98.28%\n",
      "epoch-59  lr=['0.0001000'], tr/val_loss:  0.257158/  0.219386, val:  97.76%, val_best:  97.98%, tr:  98.26%, tr_best:  98.28%\n",
      "epoch-60  lr=['0.0001000'], tr/val_loss:  0.261951/  0.253470, val:  97.30%, val_best:  97.98%, tr:  98.28%, tr_best:  98.28%\n",
      "epoch-61  lr=['0.0001000'], tr/val_loss:  0.252358/  0.286450, val:  97.54%, val_best:  97.98%, tr:  98.33%, tr_best:  98.33%\n",
      "epoch-62  lr=['0.0001000'], tr/val_loss:  0.262412/  0.282640, val:  95.77%, val_best:  97.98%, tr:  98.33%, tr_best:  98.33%\n",
      "epoch-63  lr=['0.0001000'], tr/val_loss:  0.266608/  0.296734, val:  96.70%, val_best:  97.98%, tr:  98.42%, tr_best:  98.42%\n",
      "epoch-64  lr=['0.0001000'], tr/val_loss:  0.280574/  0.315390, val:  96.64%, val_best:  97.98%, tr:  98.28%, tr_best:  98.42%\n",
      "epoch-65  lr=['0.0001000'], tr/val_loss:  0.280056/  0.237569, val:  97.12%, val_best:  97.98%, tr:  98.46%, tr_best:  98.46%\n",
      "epoch-66  lr=['0.0001000'], tr/val_loss:  0.273414/  0.331960, val:  95.84%, val_best:  97.98%, tr:  98.32%, tr_best:  98.46%\n",
      "epoch-67  lr=['0.0001000'], tr/val_loss:  0.288664/  0.263256, val:  97.87%, val_best:  97.98%, tr:  98.41%, tr_best:  98.46%\n",
      "epoch-68  lr=['0.0001000'], tr/val_loss:  0.268363/  0.300338, val:  96.53%, val_best:  97.98%, tr:  98.42%, tr_best:  98.46%\n",
      "epoch-69  lr=['0.0001000'], tr/val_loss:  0.277326/  0.316517, val:  96.36%, val_best:  97.98%, tr:  98.46%, tr_best:  98.46%\n",
      "epoch-70  lr=['0.0001000'], tr/val_loss:  0.274346/  0.295292, val:  97.56%, val_best:  97.98%, tr:  98.42%, tr_best:  98.46%\n",
      "epoch-71  lr=['0.0001000'], tr/val_loss:  0.277733/  0.305177, val:  97.92%, val_best:  97.98%, tr:  98.45%, tr_best:  98.46%\n",
      "epoch-72  lr=['0.0001000'], tr/val_loss:  0.290766/  0.337053, val:  96.41%, val_best:  97.98%, tr:  98.48%, tr_best:  98.48%\n",
      "epoch-73  lr=['0.0001000'], tr/val_loss:  0.287430/  0.248343, val:  97.53%, val_best:  97.98%, tr:  98.55%, tr_best:  98.55%\n",
      "epoch-74  lr=['0.0001000'], tr/val_loss:  0.261206/  0.293760, val:  97.21%, val_best:  97.98%, tr:  98.53%, tr_best:  98.55%\n",
      "epoch-75  lr=['0.0001000'], tr/val_loss:  0.283871/  0.284053, val:  97.90%, val_best:  97.98%, tr:  98.51%, tr_best:  98.55%\n",
      "epoch-76  lr=['0.0001000'], tr/val_loss:  0.274413/  0.260864, val:  97.43%, val_best:  97.98%, tr:  98.61%, tr_best:  98.61%\n",
      "epoch-77  lr=['0.0001000'], tr/val_loss:  0.275097/  0.268451, val:  97.33%, val_best:  97.98%, tr:  98.58%, tr_best:  98.61%\n",
      "epoch-78  lr=['0.0001000'], tr/val_loss:  0.276138/  0.310323, val:  96.67%, val_best:  97.98%, tr:  98.56%, tr_best:  98.61%\n",
      "epoch-79  lr=['0.0001000'], tr/val_loss:  0.271410/  0.219931, val:  97.82%, val_best:  97.98%, tr:  98.71%, tr_best:  98.71%\n",
      "epoch-80  lr=['0.0001000'], tr/val_loss:  0.281532/  0.268731, val:  97.63%, val_best:  97.98%, tr:  98.60%, tr_best:  98.71%\n",
      "epoch-81  lr=['0.0001000'], tr/val_loss:  0.281034/  0.265149, val:  97.88%, val_best:  97.98%, tr:  98.72%, tr_best:  98.72%\n",
      "epoch-82  lr=['0.0001000'], tr/val_loss:  0.279727/  0.271948, val:  97.61%, val_best:  97.98%, tr:  98.66%, tr_best:  98.72%\n",
      "epoch-83  lr=['0.0001000'], tr/val_loss:  0.285299/  0.258369, val:  97.75%, val_best:  97.98%, tr:  98.69%, tr_best:  98.72%\n",
      "epoch-84  lr=['0.0001000'], tr/val_loss:  0.293590/  0.349444, val:  95.49%, val_best:  97.98%, tr:  98.71%, tr_best:  98.72%\n",
      "epoch-85  lr=['0.0001000'], tr/val_loss:  0.293089/  0.251675, val:  97.76%, val_best:  97.98%, tr:  98.67%, tr_best:  98.72%\n",
      "epoch-86  lr=['0.0001000'], tr/val_loss:  0.288551/  0.257370, val:  97.75%, val_best:  97.98%, tr:  98.69%, tr_best:  98.72%\n",
      "epoch-87  lr=['0.0001000'], tr/val_loss:  0.298963/  0.314016, val:  97.25%, val_best:  97.98%, tr:  98.69%, tr_best:  98.72%\n",
      "epoch-88  lr=['0.0001000'], tr/val_loss:  0.311224/  0.306616, val:  97.91%, val_best:  97.98%, tr:  98.70%, tr_best:  98.72%\n",
      "epoch-89  lr=['0.0001000'], tr/val_loss:  0.311223/  0.309950, val:  97.67%, val_best:  97.98%, tr:  98.68%, tr_best:  98.72%\n",
      "epoch-90  lr=['0.0001000'], tr/val_loss:  0.294356/  0.304477, val:  97.40%, val_best:  97.98%, tr:  98.79%, tr_best:  98.79%\n",
      "epoch-91  lr=['0.0001000'], tr/val_loss:  0.297517/  0.302420, val:  97.81%, val_best:  97.98%, tr:  98.71%, tr_best:  98.79%\n",
      "epoch-92  lr=['0.0001000'], tr/val_loss:  0.277364/  0.289131, val:  97.90%, val_best:  97.98%, tr:  98.78%, tr_best:  98.79%\n",
      "epoch-93  lr=['0.0001000'], tr/val_loss:  0.288651/  0.270678, val:  97.67%, val_best:  97.98%, tr:  98.79%, tr_best:  98.79%\n",
      "epoch-94  lr=['0.0001000'], tr/val_loss:  0.283427/  0.278836, val:  97.59%, val_best:  97.98%, tr:  98.76%, tr_best:  98.79%\n",
      "epoch-95  lr=['0.0001000'], tr/val_loss:  0.304374/  0.328839, val:  97.79%, val_best:  97.98%, tr:  98.78%, tr_best:  98.79%\n",
      "epoch-96  lr=['0.0001000'], tr/val_loss:  0.308714/  0.294660, val:  97.26%, val_best:  97.98%, tr:  98.84%, tr_best:  98.84%\n",
      "epoch-97  lr=['0.0001000'], tr/val_loss:  0.303619/  0.299191, val:  98.02%, val_best:  98.02%, tr:  98.81%, tr_best:  98.84%\n",
      "epoch-98  lr=['0.0001000'], tr/val_loss:  0.306811/  0.291777, val:  97.96%, val_best:  98.02%, tr:  98.83%, tr_best:  98.84%\n",
      "epoch-99  lr=['0.0001000'], tr/val_loss:  0.298250/  0.416576, val:  96.62%, val_best:  98.02%, tr:  98.85%, tr_best:  98.85%\n",
      "epoch-100 lr=['0.0001000'], tr/val_loss:  0.323068/  0.295160, val:  97.92%, val_best:  98.02%, tr:  98.83%, tr_best:  98.85%\n",
      "epoch-101 lr=['0.0001000'], tr/val_loss:  0.306250/  0.305986, val:  98.01%, val_best:  98.02%, tr:  98.92%, tr_best:  98.92%\n",
      "epoch-102 lr=['0.0001000'], tr/val_loss:  0.312741/  0.345420, val:  97.41%, val_best:  98.02%, tr:  98.81%, tr_best:  98.92%\n",
      "epoch-103 lr=['0.0001000'], tr/val_loss:  0.316975/  0.310175, val:  97.73%, val_best:  98.02%, tr:  98.92%, tr_best:  98.92%\n",
      "epoch-104 lr=['0.0001000'], tr/val_loss:  0.295927/  0.290060, val:  97.62%, val_best:  98.02%, tr:  98.95%, tr_best:  98.95%\n",
      "epoch-105 lr=['0.0001000'], tr/val_loss:  0.299646/  0.314702, val:  97.42%, val_best:  98.02%, tr:  98.92%, tr_best:  98.95%\n",
      "epoch-106 lr=['0.0001000'], tr/val_loss:  0.317264/  0.308089, val:  97.04%, val_best:  98.02%, tr:  98.84%, tr_best:  98.95%\n",
      "epoch-107 lr=['0.0001000'], tr/val_loss:  0.305111/  0.275925, val:  97.90%, val_best:  98.02%, tr:  98.95%, tr_best:  98.95%\n",
      "epoch-108 lr=['0.0001000'], tr/val_loss:  0.291102/  0.266245, val:  97.88%, val_best:  98.02%, tr:  98.89%, tr_best:  98.95%\n",
      "epoch-109 lr=['0.0001000'], tr/val_loss:  0.278585/  0.270575, val:  97.71%, val_best:  98.02%, tr:  98.94%, tr_best:  98.95%\n",
      "epoch-110 lr=['0.0001000'], tr/val_loss:  0.280561/  0.319742, val:  97.82%, val_best:  98.02%, tr:  98.88%, tr_best:  98.95%\n",
      "epoch-111 lr=['0.0001000'], tr/val_loss:  0.306470/  0.316455, val:  97.78%, val_best:  98.02%, tr:  98.94%, tr_best:  98.95%\n",
      "epoch-112 lr=['0.0001000'], tr/val_loss:  0.311014/  0.294416, val:  97.89%, val_best:  98.02%, tr:  98.95%, tr_best:  98.95%\n",
      "epoch-113 lr=['0.0001000'], tr/val_loss:  0.303750/  0.302014, val:  97.74%, val_best:  98.02%, tr:  98.98%, tr_best:  98.98%\n",
      "epoch-114 lr=['0.0001000'], tr/val_loss:  0.310244/  0.320134, val:  97.95%, val_best:  98.02%, tr:  98.98%, tr_best:  98.98%\n",
      "epoch-115 lr=['0.0001000'], tr/val_loss:  0.312797/  0.329359, val:  97.69%, val_best:  98.02%, tr:  98.99%, tr_best:  98.99%\n",
      "epoch-116 lr=['0.0001000'], tr/val_loss:  0.309324/  0.304812, val:  97.37%, val_best:  98.02%, tr:  99.02%, tr_best:  99.02%\n",
      "epoch-117 lr=['0.0001000'], tr/val_loss:  0.290564/  0.325047, val:  97.51%, val_best:  98.02%, tr:  99.05%, tr_best:  99.05%\n",
      "epoch-118 lr=['0.0001000'], tr/val_loss:  0.304921/  0.312683, val:  97.99%, val_best:  98.02%, tr:  99.02%, tr_best:  99.05%\n",
      "epoch-119 lr=['0.0001000'], tr/val_loss:  0.306083/  0.301530, val:  97.44%, val_best:  98.02%, tr:  99.02%, tr_best:  99.05%\n",
      "epoch-120 lr=['0.0001000'], tr/val_loss:  0.311369/  0.339059, val:  97.62%, val_best:  98.02%, tr:  99.04%, tr_best:  99.05%\n",
      "epoch-121 lr=['0.0001000'], tr/val_loss:  0.312750/  0.309819, val:  96.92%, val_best:  98.02%, tr:  99.11%, tr_best:  99.11%\n",
      "epoch-122 lr=['0.0001000'], tr/val_loss:  0.281809/  0.316143, val:  97.56%, val_best:  98.02%, tr:  99.08%, tr_best:  99.11%\n",
      "epoch-123 lr=['0.0001000'], tr/val_loss:  0.326436/  0.384121, val:  96.85%, val_best:  98.02%, tr:  99.03%, tr_best:  99.11%\n",
      "epoch-124 lr=['0.0001000'], tr/val_loss:  0.317779/  0.319654, val:  98.16%, val_best:  98.16%, tr:  99.14%, tr_best:  99.14%\n",
      "epoch-125 lr=['0.0001000'], tr/val_loss:  0.317202/  0.328541, val:  97.72%, val_best:  98.16%, tr:  99.09%, tr_best:  99.14%\n",
      "epoch-126 lr=['0.0001000'], tr/val_loss:  0.319043/  0.347022, val:  97.70%, val_best:  98.16%, tr:  99.12%, tr_best:  99.14%\n",
      "epoch-127 lr=['0.0001000'], tr/val_loss:  0.316956/  0.355693, val:  97.71%, val_best:  98.16%, tr:  99.07%, tr_best:  99.14%\n",
      "epoch-128 lr=['0.0001000'], tr/val_loss:  0.315955/  0.305684, val:  98.07%, val_best:  98.16%, tr:  99.15%, tr_best:  99.15%\n",
      "epoch-129 lr=['0.0001000'], tr/val_loss:  0.311946/  0.380555, val:  97.82%, val_best:  98.16%, tr:  99.05%, tr_best:  99.15%\n",
      "epoch-130 lr=['0.0001000'], tr/val_loss:  0.316642/  0.320472, val:  97.99%, val_best:  98.16%, tr:  99.15%, tr_best:  99.15%\n",
      "epoch-131 lr=['0.0001000'], tr/val_loss:  0.308016/  0.327243, val:  96.68%, val_best:  98.16%, tr:  99.07%, tr_best:  99.15%\n",
      "epoch-132 lr=['0.0001000'], tr/val_loss:  0.314823/  0.302692, val:  97.50%, val_best:  98.16%, tr:  99.14%, tr_best:  99.15%\n",
      "epoch-133 lr=['0.0001000'], tr/val_loss:  0.301437/  0.285447, val:  97.99%, val_best:  98.16%, tr:  99.13%, tr_best:  99.15%\n",
      "epoch-134 lr=['0.0001000'], tr/val_loss:  0.298822/  0.310983, val:  97.40%, val_best:  98.16%, tr:  99.15%, tr_best:  99.15%\n",
      "epoch-135 lr=['0.0001000'], tr/val_loss:  0.307783/  0.314088, val:  97.59%, val_best:  98.16%, tr:  99.04%, tr_best:  99.15%\n",
      "epoch-136 lr=['0.0001000'], tr/val_loss:  0.326280/  0.375803, val:  96.91%, val_best:  98.16%, tr:  99.12%, tr_best:  99.15%\n",
      "epoch-137 lr=['0.0001000'], tr/val_loss:  0.316155/  0.329276, val:  97.59%, val_best:  98.16%, tr:  99.14%, tr_best:  99.15%\n",
      "epoch-138 lr=['0.0001000'], tr/val_loss:  0.326908/  0.331035, val:  96.86%, val_best:  98.16%, tr:  99.12%, tr_best:  99.15%\n",
      "epoch-139 lr=['0.0001000'], tr/val_loss:  0.315390/  0.336057, val:  97.30%, val_best:  98.16%, tr:  99.20%, tr_best:  99.20%\n",
      "epoch-140 lr=['0.0001000'], tr/val_loss:  0.326476/  0.325475, val:  97.67%, val_best:  98.16%, tr:  99.12%, tr_best:  99.20%\n",
      "epoch-141 lr=['0.0001000'], tr/val_loss:  0.318653/  0.316728, val:  97.50%, val_best:  98.16%, tr:  99.22%, tr_best:  99.22%\n",
      "epoch-142 lr=['0.0001000'], tr/val_loss:  0.313784/  0.294068, val:  97.77%, val_best:  98.16%, tr:  99.19%, tr_best:  99.22%\n",
      "epoch-143 lr=['0.0001000'], tr/val_loss:  0.305760/  0.305135, val:  97.32%, val_best:  98.16%, tr:  99.19%, tr_best:  99.22%\n",
      "epoch-144 lr=['0.0001000'], tr/val_loss:  0.334507/  0.356223, val:  97.79%, val_best:  98.16%, tr:  99.15%, tr_best:  99.22%\n",
      "epoch-145 lr=['0.0001000'], tr/val_loss:  0.326482/  0.302494, val:  97.89%, val_best:  98.16%, tr:  99.24%, tr_best:  99.24%\n",
      "epoch-146 lr=['0.0001000'], tr/val_loss:  0.315407/  0.310971, val:  97.94%, val_best:  98.16%, tr:  99.21%, tr_best:  99.24%\n",
      "epoch-147 lr=['0.0001000'], tr/val_loss:  0.303164/  0.303568, val:  98.02%, val_best:  98.16%, tr:  99.26%, tr_best:  99.26%\n",
      "epoch-148 lr=['0.0001000'], tr/val_loss:  0.304636/  0.302702, val:  97.84%, val_best:  98.16%, tr:  99.25%, tr_best:  99.26%\n",
      "epoch-149 lr=['0.0001000'], tr/val_loss:  0.308785/  0.304456, val:  97.51%, val_best:  98.16%, tr:  99.23%, tr_best:  99.26%\n",
      "epoch-150 lr=['0.0001000'], tr/val_loss:  0.307654/  0.335000, val:  97.50%, val_best:  98.16%, tr:  99.24%, tr_best:  99.26%\n",
      "epoch-151 lr=['0.0001000'], tr/val_loss:  0.316603/  0.312706, val:  97.62%, val_best:  98.16%, tr:  99.17%, tr_best:  99.26%\n",
      "epoch-152 lr=['0.0001000'], tr/val_loss:  0.327245/  0.370484, val:  97.85%, val_best:  98.16%, tr:  99.24%, tr_best:  99.26%\n",
      "epoch-153 lr=['0.0001000'], tr/val_loss:  0.328391/  0.312849, val:  97.73%, val_best:  98.16%, tr:  99.21%, tr_best:  99.26%\n",
      "epoch-154 lr=['0.0001000'], tr/val_loss:  0.320999/  0.334188, val:  97.79%, val_best:  98.16%, tr:  99.20%, tr_best:  99.26%\n",
      "epoch-155 lr=['0.0001000'], tr/val_loss:  0.328495/  0.401563, val:  96.85%, val_best:  98.16%, tr:  99.28%, tr_best:  99.28%\n",
      "epoch-156 lr=['0.0001000'], tr/val_loss:  0.325828/  0.314295, val:  97.68%, val_best:  98.16%, tr:  99.22%, tr_best:  99.28%\n",
      "epoch-157 lr=['0.0001000'], tr/val_loss:  0.321004/  0.334401, val:  97.33%, val_best:  98.16%, tr:  99.27%, tr_best:  99.28%\n",
      "epoch-158 lr=['0.0001000'], tr/val_loss:  0.342314/  0.342358, val:  97.48%, val_best:  98.16%, tr:  99.24%, tr_best:  99.28%\n",
      "epoch-159 lr=['0.0001000'], tr/val_loss:  0.330383/  0.322552, val:  97.98%, val_best:  98.16%, tr:  99.33%, tr_best:  99.33%\n",
      "epoch-160 lr=['0.0001000'], tr/val_loss:  0.328252/  0.397593, val:  97.67%, val_best:  98.16%, tr:  99.26%, tr_best:  99.33%\n",
      "epoch-161 lr=['0.0001000'], tr/val_loss:  0.333158/  0.359324, val:  97.11%, val_best:  98.16%, tr:  99.26%, tr_best:  99.33%\n",
      "epoch-162 lr=['0.0001000'], tr/val_loss:  0.345253/  0.337905, val:  98.06%, val_best:  98.16%, tr:  99.24%, tr_best:  99.33%\n",
      "epoch-163 lr=['0.0001000'], tr/val_loss:  0.331130/  0.339595, val:  97.92%, val_best:  98.16%, tr:  99.29%, tr_best:  99.33%\n",
      "epoch-164 lr=['0.0001000'], tr/val_loss:  0.335237/  0.352761, val:  97.53%, val_best:  98.16%, tr:  99.32%, tr_best:  99.33%\n",
      "epoch-165 lr=['0.0001000'], tr/val_loss:  0.324436/  0.362171, val:  97.62%, val_best:  98.16%, tr:  99.36%, tr_best:  99.36%\n",
      "epoch-166 lr=['0.0001000'], tr/val_loss:  0.321816/  0.296174, val:  98.03%, val_best:  98.16%, tr:  99.27%, tr_best:  99.36%\n",
      "epoch-167 lr=['0.0001000'], tr/val_loss:  0.325344/  0.354727, val:  97.65%, val_best:  98.16%, tr:  99.31%, tr_best:  99.36%\n",
      "epoch-168 lr=['0.0001000'], tr/val_loss:  0.328376/  0.306368, val:  97.68%, val_best:  98.16%, tr:  99.30%, tr_best:  99.36%\n",
      "epoch-169 lr=['0.0001000'], tr/val_loss:  0.340759/  0.332877, val:  97.67%, val_best:  98.16%, tr:  99.31%, tr_best:  99.36%\n",
      "epoch-170 lr=['0.0001000'], tr/val_loss:  0.331045/  0.327746, val:  97.62%, val_best:  98.16%, tr:  99.34%, tr_best:  99.36%\n",
      "epoch-171 lr=['0.0001000'], tr/val_loss:  0.334510/  0.346494, val:  97.81%, val_best:  98.16%, tr:  99.29%, tr_best:  99.36%\n",
      "epoch-172 lr=['0.0001000'], tr/val_loss:  0.342270/  0.346641, val:  97.82%, val_best:  98.16%, tr:  99.30%, tr_best:  99.36%\n",
      "epoch-173 lr=['0.0001000'], tr/val_loss:  0.342961/  0.348129, val:  97.95%, val_best:  98.16%, tr:  99.39%, tr_best:  99.39%\n",
      "epoch-174 lr=['0.0001000'], tr/val_loss:  0.332631/  0.335436, val:  97.90%, val_best:  98.16%, tr:  99.38%, tr_best:  99.39%\n",
      "epoch-175 lr=['0.0001000'], tr/val_loss:  0.328306/  0.343376, val:  97.46%, val_best:  98.16%, tr:  99.33%, tr_best:  99.39%\n",
      "epoch-176 lr=['0.0001000'], tr/val_loss:  0.330805/  0.310486, val:  98.05%, val_best:  98.16%, tr:  99.35%, tr_best:  99.39%\n",
      "epoch-177 lr=['0.0001000'], tr/val_loss:  0.312918/  0.311201, val:  97.38%, val_best:  98.16%, tr:  99.35%, tr_best:  99.39%\n"
     ]
    }
   ],
   "source": [
    "### my_snn control board (Gesture) ########################\n",
    "decay = 0.5 # 0.0 # 0.875 0.25 0.125 0.75 0.5\n",
    "# nda 0.25 # ottt 0.5\n",
    "\n",
    "unique_name = 'main' ## 이거 설정하면 새로운 경로에 모두 save\n",
    "run_name = 'main' ## 이거 설정하면 새로운 경로에 모두 save\n",
    "\n",
    "\n",
    "\n",
    "wandb.init(project= f'my_snn {unique_name}',save_code=False, dir='/data2/bh_wandb', tags=[\"common\"])\n",
    "\n",
    "my_snn_system(  devices = \"4\",\n",
    "                single_step = True, # True # False # DFA_on이랑 같이 가라\n",
    "                unique_name = run_name,\n",
    "                my_seed = 42,\n",
    "                TIME = 10, # dvscifar 10 # ottt 6 or 10 # nda 10  # 제작하는 dvs에서 TIME넘거나 적으면 자르거나 PADDING함\n",
    "                BATCH = 16, # batch norm 할거면 2이상으로 해야함   # nda 256   #  ottt 128\n",
    "                IMAGE_SIZE = 17, # dvscifar 48 # MNIST 28 # CIFAR10 32 # PMNIST 28 #NMNIST 34 # GESTURE 128\n",
    "                # dvsgesture 128, dvs_cifar2 128, nmnist 34, n_caltech101 180,240, n_tidigits 64, heidelberg 700, \n",
    "\n",
    "                # DVS_CIFAR10 할거면 time 10으로 해라\n",
    "                which_data = 'NMNIST_TONIC',\n",
    "# 'CIFAR100' 'CIFAR10' 'MNIST' 'FASHION_MNIST' 'DVS_CIFAR10' 'PMNIST'아직\n",
    "# 'DVS_GESTURE', 'DVS_GESTURE_TONIC','DVS_CIFAR10_2','NMNIST','NMNIST_TONIC','CIFAR10','N_CALTECH101','n_tidigits','heidelberg'\n",
    "                # CLASS_NUM = 10,\n",
    "                data_path = '/data2', # YOU NEED TO CHANGE THIS\n",
    "                rate_coding = False, # True # False\n",
    "\n",
    "                lif_layer_v_init = 0.0,\n",
    "                lif_layer_v_decay = decay,\n",
    "                lif_layer_v_threshold = 0.5,   #nda 0.5  #ottt 1.0\n",
    "                lif_layer_v_reset = 10000.0, # 10000이상은 hardreset (내 LIF쓰기는 함 ㅇㅇ)\n",
    "                lif_layer_sg_width = 4.0, # 2.570969004857107 # sigmoid류에서는 alpha값 4.0, rectangle류에서는 width값 0.5\n",
    "\n",
    "                # synapse_conv_in_channels = IMAGE_PIXEL_CHANNEL,\n",
    "                synapse_conv_kernel_size = 3,\n",
    "                synapse_conv_stride = 1,\n",
    "                synapse_conv_padding = 1,\n",
    "\n",
    "                synapse_trace_const1 = 1, # 현재 trace구할 때 현재 spike에 곱해지는 상수. 걍 1로 두셈.\n",
    "                synapse_trace_const2 = decay, # 현재 trace구할 때 직전 trace에 곱해지는 상수. lif_layer_v_decay와 같게 할 것을 추천\n",
    "\n",
    "                # synapse_fc_out_features = CLASS_NUM,\n",
    "\n",
    "                pre_trained = False, # True # False\n",
    "                convTrue_fcFalse = False, # True # False\n",
    "\n",
    "                # 'P' for average pooling, 'D' for (1,1) aver pooling, 'M' for maxpooling, 'L' for linear classifier, [  ] for residual block\n",
    "                # conv에서 10000 이상은 depth-wise separable (BPTT만 지원), 20000이상은 depth-wise (BPTT만 지원)\n",
    "                # cfg = ['M', 'M', 32, 'P', 32, 'P', 32, 'P'], \n",
    "                # cfg = ['M', 'M', 64, 'P', 64, 'P', 64, 'P'], \n",
    "                # cfg = ['M', 'M', 64, 'M', 96, 'M', 128, 'M'], \n",
    "                cfg = [200, 200], \n",
    "                # cfg = ['M', 'M', 64, 'M', 96], \n",
    "                # cfg = ['M', 'M', 64, 'M', 96, 'L', 512, 512], \n",
    "                # cfg = ['M', 'M', 64], \n",
    "                # cfg = [64, 124, 64, 124],\n",
    "                # cfg = ['M','M',512], \n",
    "                # cfg = [512], \n",
    "                # cfg = ['M', 'M', 64, 128, 'P', 128, 'P'], \n",
    "                # cfg = ['M','M',512],\n",
    "                # cfg = ['M',200],\n",
    "                # cfg = [200,200],\n",
    "                # cfg = ['M','M',200,200],\n",
    "                # cfg = ([200],[200],[200],[2]), # (feature extractor, classifier, domain adapter, # of domain)\n",
    "                # cfg = (['M','M',200],[200],[200],[2]), # (feature extractor, classifier, domain adapter, # of domain)\n",
    "                # cfg = ['M',200,200],\n",
    "                # cfg = ['M','M',1024,512,256,128,64],\n",
    "                # cfg = [200,200],\n",
    "                # cfg = [12], #fc\n",
    "                # cfg = [12, 'M', 48, 'M', 12], \n",
    "                # cfg = [64,[64,64],64], # 끝에 linear classifier 하나 자동으로 붙습니다\n",
    "                # cfg = [64, 128, 'P', 256, 256, 'P', 512, 512, 'P', 512, 512, 'D'], #ottt\n",
    "                # cfg = [64, 128, 'P', 256, 256, 'P', 512, 512, 'P', 512, 512], \n",
    "                # cfg = [64, 128, 'M', 256, 256, 'M', 512, 512, 'M', 512, 512], \n",
    "                # cfg = [64, 'P', 128, 'P', 256, 256, 'P', 512, 512, 512, 512, 'D'], # nda\n",
    "                # cfg = [64, 'P', 128, 'P', 256, 256, 'P', 512, 512, 512, 512], # nda 128pixel\n",
    "                # cfg = [64, 'P', 128, 'P', 256, 256, 'P', 512, 512, 512, 512, 'L', 4096, 4096],\n",
    "                # cfg = [20001,10001], # depthwise, separable\n",
    "                # cfg = [64,20064,10001], # vanilla conv, depthwise, separable\n",
    "                # cfg = [8, 'P', 8, 'P', 8, 'P', 8,'P', 8, 'P'],\n",
    "                # cfg = [],        \n",
    "                \n",
    "                net_print = True, # True # False # True로 하길 추천\n",
    "                \n",
    "                pre_trained_path = f\"net_save/save_now_net_weights_{unique_name}.pth\",\n",
    "                learning_rate = 0.0001, #0.1 bptt, #0.01 ottt, # default 0.001  # ottt 0.1 # nda 0.001 # 0.00936191669529645\n",
    "                epoch_num = 10000,\n",
    "                tdBN_on = False,  # True # False\n",
    "                BN_on = False,  # True # False\n",
    "                \n",
    "                surrogate = 'hard_sigmoid', # 'sigmoid' 'rectangle' 'rough_rectangle' 'hard_sigmoid'\n",
    "                \n",
    "                BPTT_on = False,  # True # False # True이면 BPTT, False이면 OTTT  # depthwise, separable은 BPTT만 가능\n",
    "                \n",
    "                optimizer_what = 'SGD', # 'SGD' 'Adam', 'RMSprop'\n",
    "                scheduler_name = 'no', # 'no' 'StepLR' 'ExponentialLR' 'ReduceLROnPlateau' 'CosineAnnealingLR' 'OneCycleLR'\n",
    "                \n",
    "                ddp_on = False, # DECREPATED # fALSE\n",
    "\n",
    "                dvs_clipping = 1, #일반적으로 1 또는 2 # 100ms때는 5 # 숫자만큼 크면 spike 아니면 걍 0\n",
    "                # gesture, cifar-dvs2, nmnist, ncaltech101\n",
    "                # gesture: 100_000c1-5, 25_000c5, 10_000c5, 1_000c5, 1_000_000c5\n",
    "\n",
    "                dvs_duration = 5_000, # 10_000 # 25_000, # 0 아니면 time sampling # dvs number sampling OR time sampling # gesture, cifar-dvs2, nmnist, ncaltech101\n",
    "                # 있는 데이터들 #gesture 100_000 25_000 10_000 1_000 1_000_000 #nmnist 10000 #nmnist_tonic 10_000 25_000\n",
    "                # 한 숫자가 1us인듯 (spikingjelly코드에서)\n",
    "                # 한 장에 50 timestep만 생산함. 싫으면 my_snn/trying/spikingjelly_dvsgesture의__init__.py 를 참고해봐\n",
    "                # nmnist 5_000us, gesture는 100_000us, 25_000us\n",
    "\n",
    "                DFA_on = True, # True # False # single_step이랑 같이 켜야 됨.\n",
    "\n",
    "                trace_on = False,   # True # False\n",
    "                OTTT_input_trace_on = False, # True # False # 맨 처음 input에 trace 적용 # trace_on False면 의미없음.\n",
    "\n",
    "                exclude_class = True, # True # False # gesture에서 10번째 클래스 제외\n",
    "\n",
    "                merge_polarities = False, # True # False # tonic dvs dataset 에서 polarities 합치기\n",
    "                denoise_on = False, # True # False # &&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&\n",
    "\n",
    "                extra_train_dataset = 0, \n",
    "\n",
    "                num_workers = 2, # local wsl에서는 2가 맞고, 서버에서는 4가 좋더라.\n",
    "                chaching_on = True, # True # False # only for certain datasets (gesture_tonic, nmnist_tonic)\n",
    "                pin_memory = True, # True # False \n",
    "\n",
    "                UDA_on = False,  # DECREPATED # uda\n",
    "                alpha_uda = 1.0, # DECREPATED # uda\n",
    "\n",
    "                bias = True, # True # False \n",
    "\n",
    "                last_lif = False, # True # False \n",
    "\n",
    "                temporal_filter = 1, \n",
    "                initial_pooling = 1,\n",
    "\n",
    "                temporal_filter_accumulation = False, # True # False \n",
    "                ) \n",
    "\n",
    "# num_workers = 4 * num_GPU (or 8, 16, 2 * num_GPU)\n",
    "# entry * batch_size * num_worker = num_GPU * GPU_throughtput\n",
    "# num_workers = batch_size / num_GPU\n",
    "# num_workers = batch_size / num_CPU\n",
    "\n",
    "# sigmoid와 BN이 있어야 잘된다.\n",
    "# average pooling  \n",
    "# 이 낫다. \n",
    "\n",
    "# nda에서는 decay = 0.25, threshold = 0.5, width =1, surrogate = rectangle, batch = 256, tdBN = True\n",
    "## OTTT 에서는 decay = 0.5, threshold = 1.0, surrogate = sigmoid, batch = 128, BN = True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # sweep 하는 코드, 위 셀 주석처리 해야 됨.\n",
    "\n",
    "# # 이런 워닝 뜨는 거는 걍 너가 main 안에서  wandb.config.update(hyperparameters)할 때 물려서임. 어차피 근데 sweep에서 지정한 걸로 덮어짐 \n",
    "# # wandb: WARNING Config item 'BATCH' was locked by 'sweep' (ignored update).\n",
    "\n",
    "# unique_name_hyper = 'main'\n",
    "# sweep_configuration = {\n",
    "#     'method': 'bayes', # 'random', 'bayes'\n",
    "#     'name': f'my_snn_sweep{datetime.datetime.now().strftime(\"%Y%m%d_%H%M%S\")}',\n",
    "#     'metric': {'goal': 'maximize', 'name': 'val_acc_best'},\n",
    "#     'parameters': \n",
    "#     {\n",
    "#         # \"devices\": {\"values\": [\"1\"]},\n",
    "#         \"single_step\": {\"values\": [True]},\n",
    "#         # \"unique_name\": {\"values\": [unique_name_hyper]},\n",
    "#         \"my_seed\": {\"values\": [42]},\n",
    "#         \"TIME\": {\"values\": [10]},\n",
    "#         \"BATCH\": {\"values\": [16]},\n",
    "#         \"IMAGE_SIZE\": {\"values\": [128]},\n",
    "#         \"which_data\": {\"values\": ['DVS_GESTURE_TONIC']},\n",
    "#         \"data_path\": {\"values\": ['/data2']},\n",
    "#         \"rate_coding\": {\"values\": [False]},\n",
    "#         \"lif_layer_v_init\": {\"values\": [0.0]},\n",
    "#         \"lif_layer_v_decay\": {\"values\": [0.5]},\n",
    "#         \"lif_layer_v_threshold\": {\"values\": [0.25, 0.5, 0.75, 1.0]},\n",
    "#         \"lif_layer_v_reset\": {\"values\": [10000.0, 0.0]},\n",
    "#         \"lif_layer_sg_width\": {\"values\": [1.0,2.0,3.0,4.0,5.0]},\n",
    "\n",
    "#         \"synapse_conv_kernel_size\": {\"values\": [3]},\n",
    "#         \"synapse_conv_stride\": {\"values\": [1]},\n",
    "#         \"synapse_conv_padding\": {\"values\": [1]},\n",
    "\n",
    "#         \"synapse_trace_const1\": {\"values\": [1]},\n",
    "#         \"synapse_trace_const2\": {\"values\": [0, 0.5]},\n",
    "\n",
    "#         \"pre_trained\": {\"values\": [False]},\n",
    "#         \"convTrue_fcFalse\": {\"values\": [False]},\n",
    "\n",
    "#         \"cfg\": {\"values\": [['M','M',200,200]]},\n",
    "\n",
    "#         \"net_print\": {\"values\": [True]},\n",
    "\n",
    "#         \"pre_trained_path\": {\"values\": [\"net_save/save_now_net_weights_{unique_name}.pth\"]},\n",
    "#         \"learning_rate\": {\"values\": [0.001,0.01,0.1,0.0001]}, \n",
    "#         \"epoch_num\": {\"values\": [100]}, \n",
    "#         \"tdBN_on\": {\"values\": [False]},\n",
    "#         \"BN_on\": {\"values\": [False]},\n",
    "\n",
    "#         \"surrogate\": {\"values\": ['hard_sigmoid']},\n",
    "\n",
    "#         \"BPTT_on\": {\"values\": [False]},\n",
    "\n",
    "#         \"optimizer_what\": {\"values\": ['SGD']},\n",
    "#         \"scheduler_name\": {\"values\": ['no']},\n",
    "\n",
    "#         \"ddp_on\": {\"values\": [False]},\n",
    "\n",
    "#         \"dvs_clipping\": {\"values\": [5]}, \n",
    "\n",
    "#         \"dvs_duration\": {\"values\": [100_000]}, \n",
    "\n",
    "#         \"DFA_on\": {\"values\": [True, False]},\n",
    "\n",
    "#         \"trace_on\": {\"values\": [True]},\n",
    "#         \"OTTT_input_trace_on\": {\"values\": [False]},\n",
    "\n",
    "#         \"exclude_class\": {\"values\": [True]},\n",
    "\n",
    "#         \"merge_polarities\": {\"values\": [False]},\n",
    "#         \"denoise_on\": {\"values\": [True, False]},\n",
    "\n",
    "#         \"extra_train_dataset\": {\"values\": [0]},\n",
    "\n",
    "#         \"num_workers\": {\"values\": [2]},\n",
    "#         \"chaching_on\": {\"values\": [True]},\n",
    "#         \"pin_memory\": {\"values\": [True]},\n",
    "\n",
    "#         \"UDA_on\": {\"values\": [False]},\n",
    "#         \"alpha_uda\": {\"values\": [1.0]},\n",
    "\n",
    "#         \"bias\": {\"values\": [True]},\n",
    "\n",
    "#         \"last_lif\": {\"values\": [False]},\n",
    "\n",
    "#         \"temporal_filter\": {\"values\": [1]},\n",
    "#         \"initial_pooling\": {\"values\": [1]},\n",
    "\n",
    "#         \"temporal_filter_accumulation\": {\"values\": [False]},\n",
    "#      }\n",
    "# }\n",
    "\n",
    "# def hyper_iter():\n",
    "#     ### my_snn control board ########################\n",
    "#     wandb.init(save_code=False, dir='/data2/bh_wandb', tags=[\"sweep\"])\n",
    "\n",
    "#     my_snn_system(  \n",
    "#         devices  =  \"0\",\n",
    "#         single_step  =  wandb.config.single_step,\n",
    "#         unique_name  =  unique_name_hyper,\n",
    "#         my_seed  =  wandb.config.my_seed,\n",
    "#         TIME  =  wandb.config.TIME,\n",
    "#         BATCH  =  wandb.config.BATCH,\n",
    "#         IMAGE_SIZE  =  wandb.config.IMAGE_SIZE,\n",
    "#         which_data  =  wandb.config.which_data,\n",
    "#         data_path  =  wandb.config.data_path,\n",
    "#         rate_coding  =  wandb.config.rate_coding,\n",
    "#         lif_layer_v_init  =  wandb.config.lif_layer_v_init,\n",
    "#         lif_layer_v_decay  =  wandb.config.lif_layer_v_decay,\n",
    "#         lif_layer_v_threshold  =  wandb.config.lif_layer_v_threshold,\n",
    "#         lif_layer_v_reset  =  wandb.config.lif_layer_v_reset,\n",
    "#         lif_layer_sg_width  =  wandb.config.lif_layer_sg_width,\n",
    "#         synapse_conv_kernel_size  =  wandb.config.synapse_conv_kernel_size,\n",
    "#         synapse_conv_stride  =  wandb.config.synapse_conv_stride,\n",
    "#         synapse_conv_padding  =  wandb.config.synapse_conv_padding,\n",
    "#         synapse_trace_const1  =  wandb.config.synapse_trace_const1,\n",
    "#         synapse_trace_const2  =  wandb.config.synapse_trace_const2,\n",
    "#         pre_trained  =  wandb.config.pre_trained,\n",
    "#         convTrue_fcFalse  =  wandb.config.convTrue_fcFalse,\n",
    "#         cfg  =  wandb.config.cfg,\n",
    "#         net_print  =  wandb.config.net_print,\n",
    "#         pre_trained_path  =  wandb.config.pre_trained_path,\n",
    "#         learning_rate  =  wandb.config.learning_rate,\n",
    "#         epoch_num  =  wandb.config.epoch_num,\n",
    "#         tdBN_on  =  wandb.config.tdBN_on,\n",
    "#         BN_on  =  wandb.config.BN_on,\n",
    "#         surrogate  =  wandb.config.surrogate,\n",
    "#         BPTT_on  =  wandb.config.BPTT_on,\n",
    "#         optimizer_what  =  wandb.config.optimizer_what,\n",
    "#         scheduler_name  =  wandb.config.scheduler_name,\n",
    "#         ddp_on  =  wandb.config.ddp_on,\n",
    "#         dvs_clipping  =  wandb.config.dvs_clipping,\n",
    "#         dvs_duration  =  wandb.config.dvs_duration,\n",
    "#         DFA_on  =  wandb.config.DFA_on,\n",
    "#         trace_on  =  wandb.config.trace_on,\n",
    "#         OTTT_input_trace_on  =  wandb.config.OTTT_input_trace_on,\n",
    "#         exclude_class  =  wandb.config.exclude_class,\n",
    "#         merge_polarities  =  wandb.config.merge_polarities,\n",
    "#         denoise_on  =  wandb.config.denoise_on,\n",
    "#         extra_train_dataset  =  wandb.config.extra_train_dataset,\n",
    "#         num_workers  =  wandb.config.num_workers,\n",
    "#         chaching_on  =  wandb.config.chaching_on,\n",
    "#         pin_memory  =  wandb.config.pin_memory,\n",
    "#         UDA_on  =  wandb.config.UDA_on,\n",
    "#         alpha_uda  =  wandb.config.alpha_uda,\n",
    "#         bias  =  wandb.config.bias,\n",
    "#         last_lif  =  wandb.config.last_lif,\n",
    "#         temporal_filter  =  wandb.config.temporal_filter,\n",
    "#         initial_pooling  =  wandb.config.initial_pooling,\n",
    "#         temporal_filter_accumulation  =  wandb.config.temporal_filter_accumulation,\n",
    "#                         ) \n",
    "#     # sigmoid와 BN이 있어야 잘된다.\n",
    "#     # average pooling\n",
    "#     # 이 낫다. \n",
    "    \n",
    "#     # nda에서는 decay = 0.25, threshold = 0.5, width =1, surrogate = rectangle, batch = 256, tdBN = True\n",
    "#     ## OTTT 에서는 decay = 0.5, threshold = 1.0, surrogate = sigmoid, batch = 128, BN = True\n",
    "\n",
    "# # sweep_id = '6pj3lh8j'\n",
    "# sweep_id = wandb.sweep(sweep=sweep_configuration, project=f'my_snn {unique_name_hyper}')\n",
    "# wandb.agent(sweep_id, function=hyper_iter, count=10000, project=f'my_snn {unique_name_hyper}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wandb.finish() "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aedat2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
