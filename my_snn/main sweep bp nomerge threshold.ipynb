{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copyright (c) 2024 Byeonghyeon Kim \n",
    "# github site: https://github.com/bhkim003/ByeonghyeonKim\n",
    "# email: bhkim003@snu.ac.kr\n",
    " \n",
    "# Permission is hereby granted, free of charge, to any person obtaining a copy of\n",
    "# this software and associated documentation files (the \"Software\"), to deal in\n",
    "# the Software without restriction, including without limitation the rights to\n",
    "# use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of\n",
    "# the Software, and to permit persons to whom the Software is furnished to do so,\n",
    "# subject to the following conditions:\n",
    " \n",
    "# The above copyright notice and this permission notice shall be included in all\n",
    "# copies or substantial portions of the Software.\n",
    " \n",
    "# THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\n",
    "# IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS\n",
    "# FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR\n",
    "# COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER\n",
    "# IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN\n",
    "# CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_13566/3914466541.py:46: DeprecationWarning: The module snntorch.spikevision is deprecated. For loading neuromorphic datasets, we recommend using the Tonic project: https://github.com/neuromorphs/tonic\n",
      "  from snntorch.spikevision import spikedata\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "import argparse\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.optim as optim\n",
    "import torch.optim.lr_scheduler as lr_scheduler\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "import torchvision\n",
    "import torchvision.datasets\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import time\n",
    "\n",
    "from snntorch import spikegen\n",
    "import matplotlib.pyplot as plt\n",
    "import snntorch.spikeplot as splt\n",
    "from IPython.display import HTML\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "from apex.parallel import DistributedDataParallel as DDP\n",
    "\n",
    "import random\n",
    "import datetime\n",
    "\n",
    "import json\n",
    "\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "''' 레퍼런스\n",
    "https://spikingjelly.readthedocs.io/zh-cn/0.0.0.0.4/spikingjelly.datasets.html#module-spikingjelly.datasets\n",
    "https://github.com/GorkaAbad/Sneaky-Spikes/blob/main/datasets.py\n",
    "https://github.com/GorkaAbad/Sneaky-Spikes/blob/main/how_to.md\n",
    "https://github.com/nmi-lab/torchneuromorphic\n",
    "https://snntorch.readthedocs.io/en/latest/snntorch.spikevision.spikedata.html#shd\n",
    "'''\n",
    "\n",
    "import snntorch\n",
    "from snntorch.spikevision import spikedata\n",
    "\n",
    "from spikingjelly.datasets.dvs128_gesture import DVS128Gesture\n",
    "from spikingjelly.datasets.cifar10_dvs import CIFAR10DVS\n",
    "from spikingjelly.datasets.n_mnist import NMNIST\n",
    "# from spikingjelly.datasets.es_imagenet import ESImageNet\n",
    "from spikingjelly.datasets import split_to_train_test_set\n",
    "from spikingjelly.datasets.n_caltech101 import NCaltech101\n",
    "from spikingjelly.datasets import pad_sequence_collate, padded_sequence_mask\n",
    "\n",
    "import torchneuromorphic\n",
    "\n",
    "import wandb\n",
    "\n",
    "from torchviz import make_dot\n",
    "import graphviz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x600 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# my module import\n",
    "from modules import *\n",
    "\n",
    "# modules 폴더에 새모듈.py 만들면\n",
    "# modules/__init__py 파일에 form .새모듈 import * 하셈\n",
    "# 그리고 새모듈.py에서 from modules.새모듈 import * 하셈\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_snn_system(devices = \"0,1,2,3\",\n",
    "                    single_step = False, # True # False\n",
    "                    unique_name = 'main',\n",
    "                    my_seed = 42,\n",
    "                    TIME = 10,\n",
    "                    BATCH = 256,\n",
    "                    IMAGE_SIZE = 32,\n",
    "                    which_data = 'CIFAR10',\n",
    "                    # CLASS_NUM = 10,\n",
    "                    data_path = '/data2',\n",
    "                    rate_coding = True,\n",
    "    \n",
    "                    lif_layer_v_init = 0.0,\n",
    "                    lif_layer_v_decay = 0.6,\n",
    "                    lif_layer_v_threshold = 1.2,\n",
    "                    lif_layer_v_reset = 0.0,\n",
    "                    lif_layer_sg_width = 1,\n",
    "\n",
    "                    # synapse_conv_in_channels = IMAGE_PIXEL_CHANNEL,\n",
    "                    synapse_conv_kernel_size = 3,\n",
    "                    synapse_conv_stride = 1,\n",
    "                    synapse_conv_padding = 1,\n",
    "                    synapse_conv_trace_const1 = 1,\n",
    "                    synapse_conv_trace_const2 = 0.6,\n",
    "\n",
    "                    # synapse_fc_out_features = CLASS_NUM,\n",
    "                    synapse_fc_trace_const1 = 1,\n",
    "                    synapse_fc_trace_const2 = 0.6,\n",
    "\n",
    "                    pre_trained = False,\n",
    "                    convTrue_fcFalse = True,\n",
    "                    cfg = [64, 64],\n",
    "                    net_print = False, # True # False\n",
    "                    weight_count_print = False, # True # False\n",
    "                    pre_trained_path = \"net_save/save_now_net.pth\",\n",
    "                    learning_rate = 0.0001,\n",
    "                    epoch_num = 200,\n",
    "                    verbose_interval = 100, #숫자 크게 하면 꺼짐\n",
    "                    validation_interval = 10, #숫자 크게 하면 꺼짐\n",
    "                    tdBN_on = False,\n",
    "                    BN_on = False,\n",
    "\n",
    "                    surrogate = 'sigmoid',\n",
    "\n",
    "                    gradient_verbose = False,\n",
    "\n",
    "                    BPTT_on = False,\n",
    "\n",
    "                    optimizer_what = 'SGD', # 'SGD' 'Adam', 'RMSprop'\n",
    "                    scheduler_name = 'no',\n",
    "                    \n",
    "                    ddp_on = True,\n",
    "\n",
    "                    nda_net = False,\n",
    "                    \n",
    "                    domain_il_epoch = 0, # over 0, then domain il mode on\n",
    "\n",
    "                    dvs_clipping = 1, \n",
    "                    dvs_duration = 10005,\n",
    "\n",
    "                    OTTT_sWS_on = True, # True # False\n",
    "\n",
    "                    DFA_on = False, # True # False\n",
    "                    OTTT_input_trace_on = False, # True # False\n",
    "                 \n",
    "                    e_transport_swap = 5, # 1 이상이면 해당 숫자 에포크만큼 val_acc_best가 변화가 없으면 e_transport scheme (BP vs DFA) swap\n",
    "                    e_transport_swap_tr = 0, # 1 이상이면 해당 숫자 에포크만큼 val_acc_best가 변화가 없으면 e_transport scheme (BP vs DFA) swap\n",
    "                    e_transport_swap_coin = 0, # swap할 수 있는 coin 개수\n",
    "\n",
    "                    drop_rate = 0.5, \n",
    "\n",
    "                    exclude_class = True, # True # False # gesture에서 10번째 클래스 제외\n",
    "\n",
    "                    merge_polarities = True, # True # False # tonic dvs dataset 에서 polarities 합치기\n",
    "                  ):\n",
    "    ## hyperparameter check #############################################################\n",
    "    if OTTT_sWS_on == True:\n",
    "        assert BPTT_on == False and tdBN_on == False and BN_on == False\n",
    "        if convTrue_fcFalse == False:\n",
    "            assert single_step == True\n",
    "    if single_step == True:\n",
    "        assert BPTT_on == False and tdBN_on == False \n",
    "    if tdBN_on == True:\n",
    "        assert BPTT_on == True\n",
    "    if pre_trained == True:\n",
    "        print('\\n\\n')\n",
    "        print(\"Caution! pre_trained is True\\n\\n\"*3)    \n",
    "    if DFA_on == True:\n",
    "        assert single_step == True and BPTT_on == False and any(isinstance(item, list) for item in cfg) == False\n",
    "    if OTTT_input_trace_on == True:\n",
    "        assert BPTT_on == False and single_step == True\n",
    "    ######################################################################################\n",
    "\n",
    "\n",
    "    ## 함수 내 모든 로컬 변수 저장 ########################################################\n",
    "    hyperparameters = locals()\n",
    "    hyperparameters['current epoch'] = 0\n",
    "    ######################################################################################\n",
    "    \n",
    "    args_gpu = None\n",
    "    ## DDP settting ######################################################################\n",
    "    if (ddp_on == True):\n",
    "        parser = argparse.ArgumentParser(description='my_snn CIFAR10 Training')\n",
    "\n",
    "        # # local_rank는 command line에서 따로 줄 필요는 없지만, 선언은 필요\n",
    "        parser.add_argument(\"--local_rank\", default=0, type=int)\n",
    "\n",
    "        args = parser.parse_args() # 이거 적어줘야됨. parser argument선언하고\n",
    "\n",
    "        args.gpu = args.local_rank\n",
    "        args_gpu = args.gpu\n",
    "        torch.cuda.set_device(args.gpu)\n",
    "        torch.distributed.init_process_group(backend=\"nccl\", init_method=\"env://\")\n",
    "        args.world_size = torch.distributed.get_world_size()\n",
    "    #######################################################################################\n",
    "\n",
    "\n",
    "    ## wandb 세팅 ###################################################################\n",
    "    current_time = datetime.datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "    if (ddp_on == True and torch.distributed.get_rank() != 0):\n",
    "        wandb.finish()\n",
    "    if (ddp_on == False or torch.distributed.get_rank() == 0):\n",
    "        wandb.config.update(hyperparameters)\n",
    "        wandb.run.name = f'lr_{learning_rate}_{unique_name}_{which_data}_tstep{TIME}'\n",
    "        wandb.define_metric(\"summary_val_acc\", summary=\"max\")\n",
    "        wandb.run.log_code(\".\", \n",
    "                           include_fn=lambda path: path.endswith(\".py\") or path.endswith(\".ipynb\"),\n",
    "                           exclude_fn=lambda path: 'logs/' in path or 'net_save/' in path or 'result_save/' in path or 'trying/' in path or 'wandb/' in path or 'private/' in path\n",
    "                           )\n",
    "    ###################################################################################\n",
    "\n",
    "\n",
    "\n",
    "    ## gpu setting ##################################################################################################################\n",
    "    os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\" \n",
    "    os.environ[\"CUDA_VISIBLE_DEVICES\"]= devices\n",
    "    ###################################################################################################################################\n",
    "\n",
    "\n",
    "    ## seed setting ##################################################################################################################\n",
    "    seed_assign(my_seed)\n",
    "    ###################################################################################################################################\n",
    "    \n",
    "\n",
    "    ## data_loader 가져오기 ##################################################################################################################\n",
    "    # data loader, pixel channel, class num\n",
    "    train_loader, test_loader, synapse_conv_in_channels, CLASS_NUM = data_loader(\n",
    "            which_data,\n",
    "            data_path, \n",
    "            rate_coding, \n",
    "            BATCH, \n",
    "            IMAGE_SIZE,\n",
    "            ddp_on,\n",
    "            TIME,\n",
    "            dvs_clipping,\n",
    "            dvs_duration,\n",
    "            exclude_class,\n",
    "            merge_polarities)\n",
    "    synapse_fc_out_features = CLASS_NUM\n",
    "    ###########################################################################################################################################\n",
    "\n",
    "    \n",
    "    ## parameter number calculator (안 중요함) ##################################################################################################################\n",
    "    params_num = 0\n",
    "    img_size = IMAGE_SIZE \n",
    "    bias_param = 1 # 1 or 0\n",
    "    classifier_making = False\n",
    "    if (convTrue_fcFalse == True):\n",
    "        past_kernel = synapse_conv_in_channels\n",
    "        for kernel in cfg:\n",
    "            if (classifier_making == False):\n",
    "                if (type(kernel) == list):\n",
    "                    for residual_kernel in kernel:\n",
    "                        if (residual_kernel >= 10000 and residual_kernel < 20000): # separable\n",
    "                            residual_kernel -= 10000\n",
    "                            params_num += (synapse_conv_kernel_size**2 + bias_param) * past_kernel\n",
    "                            params_num += (1**2 * past_kernel + bias_param) * residual_kernel\n",
    "                            past_kernel = residual_kernel  \n",
    "                        elif (residual_kernel >= 20000 and residual_kernel < 30000): # depthwise\n",
    "                            residual_kernel -= 20000\n",
    "                            # 'past_kernel' should be same with 'kernel'\n",
    "                            params_num += (synapse_conv_kernel_size**2 + bias_param) * past_kernel\n",
    "                            past_kernel = residual_kernel  \n",
    "                        else:\n",
    "                            params_num += residual_kernel * ((synapse_conv_kernel_size**2) * past_kernel + bias_param)\n",
    "                            past_kernel = residual_kernel\n",
    "                elif (kernel == 'P' or kernel == 'M'):\n",
    "                    img_size = img_size // 2\n",
    "                elif (kernel == 'D'):\n",
    "                    img_size = 1\n",
    "                elif (kernel == 'L'):\n",
    "                    classifier_making = True\n",
    "                    past_kernel = past_kernel * (img_size**2)\n",
    "                else:\n",
    "                    if (kernel >= 10000 and kernel < 20000): # separable\n",
    "                        kernel -= 10000\n",
    "                        params_num += (synapse_conv_kernel_size**2 + bias_param) * past_kernel\n",
    "                        params_num += (1**2 * past_kernel + bias_param) * kernel\n",
    "                        past_kernel = kernel  \n",
    "                    elif (kernel >= 20000 and kernel < 30000): # depthwise\n",
    "                        kernel -= 20000\n",
    "                        # 'past_kernel' should be same with 'kernel'\n",
    "                        params_num += (synapse_conv_kernel_size**2 + bias_param) * past_kernel\n",
    "                        past_kernel = kernel  \n",
    "                    else:\n",
    "                        params_num += kernel * (synapse_conv_kernel_size**2 * past_kernel + bias_param)\n",
    "                        past_kernel = kernel    \n",
    "            else: # classifier making\n",
    "                params_num += (past_kernel + bias_param) * kernel\n",
    "                past_kernel = kernel\n",
    "        \n",
    "        \n",
    "        if classifier_making == False:\n",
    "            past_kernel = past_kernel*img_size*img_size\n",
    "\n",
    "        params_num += (past_kernel + bias_param) * synapse_fc_out_features\n",
    "    else:\n",
    "        past_in_channel = synapse_conv_in_channels*img_size*img_size\n",
    "        for in_channel in cfg:\n",
    "            if (type(in_channel) == list):\n",
    "                for residual_in_channel in in_channel:\n",
    "                    params_num += (past_in_channel + bias_param) * residual_in_channel\n",
    "                    past_in_channel = residual_in_channel\n",
    "            elif (in_channel == 'P' or in_channel == 'M'):\n",
    "                img_size = img_size // 2\n",
    "                past_in_channel = synapse_conv_in_channels*img_size*img_size\n",
    "            else:\n",
    "                params_num += (past_in_channel + bias_param) * in_channel\n",
    "                past_in_channel = in_channel\n",
    "        params_num += (past_in_channel + bias_param) * synapse_fc_out_features\n",
    "    ###########################################################################################################################################\n",
    "\n",
    "\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "    ### network setting #######################################################################################################################\n",
    "    if (convTrue_fcFalse == False):\n",
    "        if (single_step == False):\n",
    "            net = MY_SNN_FC(cfg, synapse_conv_in_channels, IMAGE_SIZE, synapse_fc_out_features,\n",
    "                        synapse_fc_trace_const1, synapse_fc_trace_const2, \n",
    "                        lif_layer_v_init, lif_layer_v_decay, \n",
    "                        lif_layer_v_threshold, lif_layer_v_reset,\n",
    "                        lif_layer_sg_width,\n",
    "                        tdBN_on,\n",
    "                        BN_on, TIME,\n",
    "                        surrogate,\n",
    "                        BPTT_on,\n",
    "                        DFA_on,\n",
    "                        drop_rate).to(device)\n",
    "        else:\n",
    "            net = MY_SNN_FC_sstep(cfg, synapse_conv_in_channels, IMAGE_SIZE, synapse_fc_out_features,\n",
    "                        synapse_fc_trace_const1, synapse_fc_trace_const2, \n",
    "                        lif_layer_v_init, lif_layer_v_decay, \n",
    "                        lif_layer_v_threshold, lif_layer_v_reset,\n",
    "                        lif_layer_sg_width,\n",
    "                        tdBN_on,\n",
    "                        BN_on, TIME,\n",
    "                        surrogate,\n",
    "                        BPTT_on,\n",
    "                        DFA_on,\n",
    "                        OTTT_sWS_on,\n",
    "                        drop_rate).to(device)\n",
    "    else:\n",
    "        if (single_step == False):\n",
    "            net = MY_SNN_CONV(cfg, synapse_conv_in_channels, IMAGE_SIZE,\n",
    "                        synapse_conv_kernel_size, synapse_conv_stride, \n",
    "                        synapse_conv_padding, synapse_conv_trace_const1, \n",
    "                        synapse_conv_trace_const2, \n",
    "                        lif_layer_v_init, lif_layer_v_decay, \n",
    "                        lif_layer_v_threshold, lif_layer_v_reset,\n",
    "                        lif_layer_sg_width,\n",
    "                        synapse_fc_out_features, synapse_fc_trace_const1, synapse_fc_trace_const2,\n",
    "                        tdBN_on,\n",
    "                        BN_on, TIME,\n",
    "                        surrogate,\n",
    "                        BPTT_on,\n",
    "                        OTTT_sWS_on,\n",
    "                        DFA_on,\n",
    "                        drop_rate).to(device)\n",
    "        else:\n",
    "            net = MY_SNN_CONV_sstep(cfg, synapse_conv_in_channels, IMAGE_SIZE,\n",
    "                        synapse_conv_kernel_size, synapse_conv_stride, \n",
    "                        synapse_conv_padding, synapse_conv_trace_const1, \n",
    "                        synapse_conv_trace_const2, \n",
    "                        lif_layer_v_init, lif_layer_v_decay, \n",
    "                        lif_layer_v_threshold, lif_layer_v_reset,\n",
    "                        lif_layer_sg_width,\n",
    "                        synapse_fc_out_features, synapse_fc_trace_const1, synapse_fc_trace_const2,\n",
    "                        tdBN_on,\n",
    "                        BN_on, TIME,\n",
    "                        surrogate,\n",
    "                        BPTT_on,\n",
    "                        OTTT_sWS_on,\n",
    "                        DFA_on,\n",
    "                        drop_rate).to(device)\n",
    "    if (nda_net == True):\n",
    "        net = VGG(cfg = cfg, num_classes=10, batch_norm = tdBN_on, in_c = synapse_conv_in_channels, \n",
    "                    lif_layer_v_threshold=lif_layer_v_threshold, lif_layer_v_decay=lif_layer_v_decay, lif_layer_sg_width=lif_layer_sg_width)\n",
    "        net.T = TIME\n",
    "    if ddp_on == False:\n",
    "        net = torch.nn.DataParallel(net) \n",
    "    \n",
    "    if pre_trained == True:\n",
    "        net.load_state_dict(torch.load(pre_trained_path))\n",
    "    \n",
    "    if ddp_on == True:\n",
    "        device = args.gpu\n",
    "        net = net.to(args.gpu)\n",
    "        net = DDP(net, delay_allreduce=True)\n",
    "\n",
    "    net = net.to(device)\n",
    "    if (net_print == True):\n",
    "        if ddp_on == False or torch.distributed.get_rank() == 0:\n",
    "            print(net)    \n",
    "    ####################################################################################################################################\n",
    "    \n",
    "\n",
    "    ## wandb logging ###########################################\n",
    "    if ddp_on == False or torch.distributed.get_rank() == 0:\n",
    "        wandb.watch(net, log=\"all\", log_freq = 10) #gradient, parameter logging해줌\n",
    "    ############################################################\n",
    "\n",
    "    ## param num and memory estimation except BN with MY own calculation some lines above ##########################################\n",
    "    if ddp_on == False or torch.distributed.get_rank() == 0:\n",
    "        real_param_num = sum(p.numel() for p in net.parameters() if p.requires_grad)\n",
    "        if (weight_count_print == True):\n",
    "            for name, param in net.named_parameters():\n",
    "                if param.requires_grad:\n",
    "                    print(f'Layer: {name} | Number of parameters: {param.numel()}')\n",
    "        # Batch norm 있으면 아래 두 개 서로 다를 수 있음.\n",
    "        # assert real_param_num == params_num, f'parameter number is not same. real_param_num: {real_param_num}, params_num: {params_num}'    \n",
    "        print('='*50)\n",
    "        print(f\"My Num of PARAMS: {params_num:,}, system's param_num : {real_param_num:,}\")\n",
    "        memory = params_num / 8 / 1024 / 1024 # MB\n",
    "        precision = 32\n",
    "        memory = memory * precision \n",
    "        print(f\"Memory: {memory:.2f}MiB at {precision}-bit\")\n",
    "        print('='*50)\n",
    "    ##############################################################################################################################\n",
    "\n",
    "\n",
    "\n",
    "    ## criterion ########################################## # loss 구해주는 친구\n",
    "    criterion = nn.CrossEntropyLoss().to(device)\n",
    "    if (OTTT_sWS_on == True):\n",
    "        # criterion = nn.CrossEntropyLoss().to(device)\n",
    "        criterion = lambda y_t, target_t: ((1 - 0.05) * F.cross_entropy(y_t, target_t) + 0.05 * F.mse_loss(y_t, F.one_hot(target_t, CLASS_NUM).float())) / TIME \n",
    "        if which_data == 'DVS_GESTURE':\n",
    "            criterion = lambda y_t, target_t: ((1 - 0.001) * F.cross_entropy(y_t, target_t) + 0.001 * F.mse_loss(y_t, F.one_hot(target_t, CLASS_NUM).float())) / TIME \n",
    "    ####################################################\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "    ## optimizer, scheduler ########################################################################\n",
    "    if(optimizer_what == 'SGD'):\n",
    "        # optimizer = optim.SGD(net.parameters(), lr=learning_rate, momentum=0.9)\n",
    "        optimizer = optim.SGD(net.parameters(), lr=learning_rate, momentum=0.9, weight_decay=0)\n",
    "    elif(optimizer_what == 'Adam'):\n",
    "        optimizer = torch.optim.Adam(net.parameters(), lr=learning_rate)\n",
    "        # optimizer = torch.optim.Adam(net.parameters(), lr=0.00001)\n",
    "        # optimizer = torch.optim.Adam(net.parameters(), lr=learning_rate/256 * BATCH, weight_decay=1e-4)\n",
    "        # optimizer = optim.Adam(net.parameters(), lr=learning_rate, weight_decay=0, betas=(0.9, 0.999))\n",
    "    elif(optimizer_what == 'RMSprop'):\n",
    "        pass\n",
    "\n",
    "\n",
    "    if (scheduler_name == 'StepLR'):\n",
    "        scheduler = lr_scheduler.StepLR(optimizer, step_size=10, gamma=0.1)\n",
    "    elif (scheduler_name == 'ExponentialLR'):\n",
    "        scheduler = lr_scheduler.ExponentialLR(optimizer, gamma=0.95)\n",
    "    elif (scheduler_name == 'ReduceLROnPlateau'):\n",
    "        scheduler = lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.1, patience=10)\n",
    "    elif (scheduler_name == 'CosineAnnealingLR'):\n",
    "        # scheduler = lr_scheduler.CosineAnnealingLR(optimizer, eta_min=0, T_max=50)\n",
    "        scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, eta_min=0, T_max=epoch_num)\n",
    "    elif (scheduler_name == 'OneCycleLR'):\n",
    "        scheduler = lr_scheduler.OneCycleLR(optimizer, max_lr=0.1, steps_per_epoch=len(train_loader), epochs=epoch_num)\n",
    "    else:\n",
    "        pass # 'no' scheduler\n",
    "    ## optimizer, scheduler ########################################################################\n",
    "\n",
    "\n",
    "    tr_acc = 0\n",
    "    tr_correct = 0\n",
    "    tr_total = 0\n",
    "    tr_acc_best = 0\n",
    "    tr_epoch_loss_temp = 0\n",
    "    tr_epoch_loss= 0\n",
    "    val_acc_best = 0\n",
    "    val_acc_now = 0\n",
    "    val_loss = 0\n",
    "    elapsed_time_val = 0\n",
    "    no_val_best_growth_count = 0\n",
    "    no_tr_best_growth_count = 0\n",
    "    iter_acc_array = np.array([])\n",
    "    tr_acc_array = np.array([])\n",
    "    val_acc_now_array = np.array([])\n",
    "    DFA_current = DFA_on\n",
    "    DFA_toggle = False\n",
    "    DFA_flag = 1.0 if DFA_current == True else 0.0\n",
    "    DFA_BP_toggle_trial = 0\n",
    "    iter_of_val = False\n",
    "    #======== EPOCH START ==========================================================================================\n",
    "    for epoch in range(epoch_num):\n",
    "        if (e_transport_swap > 0 or e_transport_swap_tr > 0):\n",
    "            assert not (e_transport_swap > 0 and e_transport_swap_tr > 0)\n",
    "            if e_transport_swap > 0 and no_val_best_growth_count == e_transport_swap:\n",
    "                if DFA_BP_toggle_trial < e_transport_swap_coin:\n",
    "                    net = BP_DFA_SWAP(net, convTrue_fcFalse, single_step, ddp_on, args_gpu)\n",
    "                    no_val_best_growth_count = 0\n",
    "                    DFA_current = not DFA_current\n",
    "                    DFA_toggle = True\n",
    "                    DFA_BP_toggle_trial = DFA_BP_toggle_trial + 1\n",
    "            if e_transport_swap_tr > 0 and no_tr_best_growth_count == e_transport_swap_tr:\n",
    "                if DFA_BP_toggle_trial < e_transport_swap_coin:\n",
    "                    net = BP_DFA_SWAP(net, convTrue_fcFalse, single_step, ddp_on, args_gpu)\n",
    "                    no_tr_best_growth_count = 0\n",
    "                    DFA_current = not DFA_current\n",
    "                    DFA_toggle = True\n",
    "                    DFA_BP_toggle_trial = DFA_BP_toggle_trial + 1\n",
    "\n",
    "        if ddp_on == False or torch.distributed.get_rank() == 0:\n",
    "            # print('EPOCH', epoch)\n",
    "            pass\n",
    "        epoch_start_time = time.time()\n",
    "\n",
    "        # if (domain_il_epoch>0 and which_data == 'PMNIST'):\n",
    "        #     k = epoch // domain_il_epoch\n",
    "        #     xtrain=data[k]['train']['x']\n",
    "        #     ytrain=data[k]['train']['y']\n",
    "        #     xtest =data[k]['test']['x']\n",
    "        #     ytest =data[k]['test']['y']\n",
    "\n",
    "        \n",
    "        ####### iterator : input_loading & tqdm을 통한 progress_bar 생성###################\n",
    "        iterator = enumerate(train_loader, 0)\n",
    "        if ddp_on == False or torch.distributed.get_rank() == 0:  \n",
    "            iterator = tqdm(iterator, total=len(train_loader), desc='train', dynamic_ncols=True, position=0, leave=True)\n",
    "        ##################################################################################   \n",
    "        \n",
    "        #### validation_interval이 batch size보다 작을 시 validation_interval을 batch size로 맞춰줌#############\n",
    "        validation_interval2 = validation_interval\n",
    "        if (validation_interval > len(train_loader)):\n",
    "            validation_interval2 = len(train_loader)\n",
    "        ##################################################################################################\n",
    "\n",
    "\n",
    "        ###### ITERATION START ##########################################################################################################\n",
    "        for i, data in iterator:\n",
    "            iter_one_train_time_start = time.time()\n",
    "            net.train() # train 모드로 바꿔줘야함\n",
    "\n",
    "            ### data loading & semi-pre-processing ################################################################################\n",
    "            if len(data) == 2:\n",
    "                inputs, labels = data\n",
    "                # 처리 로직 작성\n",
    "            elif len(data) == 3:\n",
    "                inputs, labels, x_len = data\n",
    "                # print('x_len',x_len)\n",
    "                # mask = padded_sequence_mask(x_len)\n",
    "                # max_time_step = x_len.max()\n",
    "                # min_time_step = x_len.min()\n",
    "            ## batch 크기 ######################################\n",
    "            real_batch = labels.size(0)\n",
    "            ###########################################################\n",
    "\n",
    "            ###########################################################################################################################        \n",
    "            if (which_data == 'n_tidigits'):\n",
    "                inputs = inputs.permute(0, 1, 3, 2, 4)\n",
    "                labels = labels[:, 0, :]\n",
    "                labels = torch.argmax(labels, dim=1)\n",
    "            elif (which_data == 'heidelberg'):\n",
    "                inputs = inputs.view(5, 1000, 1, 700, 1)\n",
    "                print(\"\\n\\n\\n경고!!!! heidelberg 이거 타임스텝이랑 채널 잘 바꿔줘라!!!\\n\\n\\n\\n\")\n",
    "            # print('inputs',inputs.size(),'\\nlabels',labels.size())\n",
    "            # print(labels)\n",
    "                \n",
    "            if (which_data == 'DVS_CIFAR10' or which_data == 'DVS_GESTURE' or which_data == 'DVS_GESTURE_TONIC' or which_data == 'DVS_CIFAR10_2' or which_data == 'NMNIST' or which_data == 'NMNIST_TONIC' or which_data == 'N_CALTECH101' or which_data == 'n_tidigits' or which_data == 'heidelberg'):\n",
    "                inputs = inputs.permute(1, 0, 2, 3, 4)\n",
    "            elif rate_coding == True :\n",
    "                inputs = spikegen.rate(inputs, num_steps=TIME)\n",
    "            else :\n",
    "                inputs = inputs.repeat(TIME, 1, 1, 1, 1)\n",
    "            # inputs: [Time, Batch, Channel, Height, Width]  \n",
    "            ####################################################################################################################### \n",
    "                \n",
    "            \n",
    "            # # dvs 데이터 시각화 코드 (확인 필요할 시 써라)\n",
    "            # ##############################################################################################\n",
    "            # dvs_visualization(inputs, labels, TIME, BATCH, my_seed)\n",
    "            # #####################################################################################################\n",
    "\n",
    "            ## to (device) #######################################\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "            ###########################################################\n",
    "\n",
    "\n",
    "            ## gradient 초기화 #######################################\n",
    "            optimizer.zero_grad()\n",
    "            ###########################################################\n",
    "            \n",
    "            ## DVS gesture에서 other label자리 매꾸기 ###############\n",
    "            if (which_data == 'DVS_GESTURE'):\n",
    "                labels[labels>2] -= 1\n",
    "            #######################################################\n",
    "\n",
    "            if single_step == False:\n",
    "                # net에 넣어줄때는 batch가 젤 앞 차원으로 와야함. # dataparallel때매##############################\n",
    "                # inputs: [Time, Batch, Channel, Height, Width]   \n",
    "                inputs = inputs.permute(1, 0, 2, 3, 4) # net에 넣어줄때는 batch가 젤 앞 차원으로 와야함. # dataparallel때매\n",
    "                # inputs: [Batch, Time, Channel, Height, Width] \n",
    "                #################################################################################################\n",
    "            else:\n",
    "                labels = labels.repeat(TIME, 1)\n",
    "                ## first input도 ottt trace 적용하기 위한 코드 (validation 시에는 필요X) ##########################\n",
    "                if OTTT_input_trace_on == True:\n",
    "                    spike = inputs\n",
    "                    trace = torch.full_like(spike, fill_value = 0.0, dtype = torch.float, requires_grad=False)\n",
    "                    inputs = []\n",
    "                    for t in range(TIME):\n",
    "                        trace[t] = trace[t-1]*synapse_conv_trace_const2 + spike[t]*synapse_conv_trace_const1\n",
    "                        inputs += [[spike[t], trace[t]]]\n",
    "                ##################################################################################################\n",
    "                        \n",
    "            if merge_polarities == True:\n",
    "                inputs = inputs[:,:,0,:,:]\n",
    "\n",
    "            if single_step == False:\n",
    "                ### input --> net --> output #####################################################\n",
    "                outputs = net(inputs)\n",
    "                ##################################################################################\n",
    "                ## loss, backward ##########################################\n",
    "                loss = criterion(outputs, labels)\n",
    "                loss.backward()\n",
    "                ############################################################\n",
    "                ## weight 업데이트!! ##################################\n",
    "                optimizer.step()\n",
    "                ################################################################\n",
    "            else:\n",
    "                outputs_all = []\n",
    "                loss = 0.0\n",
    "                for t in range(TIME):\n",
    "                    ### input[t] --> net --> output_one_time #########################################\n",
    "                    outputs_one_time = net(inputs[t])\n",
    "                    ##################################################################################\n",
    "                    one_time_loss = criterion(outputs_one_time, labels[t].contiguous())\n",
    "                    one_time_loss.backward() # one_time backward\n",
    "                    loss += one_time_loss.data\n",
    "                    outputs_all.append(outputs_one_time.detach())\n",
    "                optimizer.step() # full step time update\n",
    "                outputs_all = torch.stack(outputs_all, dim=1)\n",
    "                outputs = outputs_all.mean(1) # ottt꺼 쓸때\n",
    "                labels = labels[0]\n",
    "                loss /= TIME\n",
    "            tr_epoch_loss_temp += loss.data/len(train_loader)\n",
    "\n",
    "            ## net 그림 출력해보기 #################################################################\n",
    "            # print('시각화')\n",
    "            # make_dot(outputs, params=dict(list(net.named_parameters()))).render(\"net_torchviz\", format=\"png\")\n",
    "            # return 0\n",
    "            ##################################################################################\n",
    "\n",
    "            #### batch 어긋남 방지 ###############################################\n",
    "            assert real_batch == outputs.size(0), f'batch size is not same. real_batch: {real_batch}, outputs.size(0): {outputs.size(0)}'\n",
    "            #######################################################################\n",
    "            \n",
    "\n",
    "            ####### training accruacy save for print ###############################\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total = real_batch\n",
    "            correct = (predicted == labels).sum().item()\n",
    "            iter_acc = correct / total\n",
    "            tr_total += total\n",
    "            tr_correct += correct\n",
    "            if i % verbose_interval == verbose_interval-1:\n",
    "                if ddp_on == False or torch.distributed.get_rank() == 0:\n",
    "                    print(f'{epoch}-{i} training acc: {100 * iter_acc:.2f}%, lr={[f\"{lr}\" for lr in (param_group[\"lr\"] for param_group in optimizer.param_groups)]}, val_acc: {100 * val_acc_now:.2f}%')\n",
    "            iter_acc_string = f'epoch-{epoch:<3} iter_acc:{100 * iter_acc:7.2f}%, lr={[f\"{lr:9.7f}\" for lr in (param_group[\"lr\"] for param_group in optimizer.param_groups)]}'\n",
    "            iter_acc_string2 = f'epoch-{epoch:<3} lr={[f\"{lr:9.7f}\" for lr in (param_group[\"lr\"] for param_group in optimizer.param_groups)]}'\n",
    "            ################################################################\n",
    "            \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "            iter_one_train_time_end = time.time()\n",
    "            elapsed_time = iter_one_train_time_end - iter_one_train_time_start  # 실행 시간 계산\n",
    "\n",
    "            if (i % verbose_interval == verbose_interval-1):\n",
    "                if ddp_on == False or torch.distributed.get_rank() == 0:\n",
    "                    print(f\"iter_one_train_time: {elapsed_time} seconds, last one_val_time: {elapsed_time_val} seconds\\n\")\n",
    "\n",
    "            ##### validation ##################################################################################################################################\n",
    "            if i % validation_interval2 == validation_interval2-1:\n",
    "                iter_one_val_time_start = time.time()\n",
    "                tr_acc = tr_correct/tr_total\n",
    "                tr_correct = 0\n",
    "                tr_total = 0\n",
    "                val_loss = 0\n",
    "                correct = 0\n",
    "                total = 0\n",
    "                with torch.no_grad():\n",
    "                    net.eval() # eval 모드로 바꿔줘야함 \n",
    "                    for data in test_loader:\n",
    "                        ## data loading & semi-pre-processing ##########################################################\n",
    "                        if len(data) == 2:\n",
    "                            inputs, labels = data\n",
    "                            # 처리 로직 작성\n",
    "                        elif len(data) == 3:\n",
    "                            inputs, labels, x_len = data\n",
    "                            # print('x_len',x_len)\n",
    "                            # mask = padded_sequence_mask(x_len)\n",
    "                            # max_time_step = x_len.max()\n",
    "                            # min_time_step = x_len.min()\n",
    "                            # B, T, *spatial_dims = inputs.shape\n",
    "\n",
    "                        if (which_data == 'DVS_CIFAR10' or which_data == 'DVS_GESTURE' or which_data == 'DVS_GESTURE_TONIC' or which_data == 'DVS_CIFAR10_2' or which_data == 'NMNIST' or which_data == 'NMNIST_TONIC' or which_data == 'N_CALTECH101' or which_data == 'n_tidigits' or which_data == 'heidelberg'):\n",
    "                            inputs = inputs.permute(1, 0, 2, 3, 4)\n",
    "                        elif rate_coding == True :\n",
    "                            inputs = spikegen.rate(inputs, num_steps=TIME)\n",
    "                        else :\n",
    "                            inputs = inputs.repeat(TIME, 1, 1, 1, 1)\n",
    "                        # inputs: [Time, Batch, Channel, Height, Width]  \n",
    "                        ###################################################################################################\n",
    "\n",
    "                        inputs = inputs.to(device)\n",
    "                        labels = labels.to(device)\n",
    "                        real_batch = labels.size(0)\n",
    "                        \n",
    "                        ## DVS gesture에서 other label자리 매꾸기 ###############\n",
    "                        if (which_data == 'DVS_GESTURE'):\n",
    "                            labels[labels>2] -= 1\n",
    "                        #######################################################\n",
    "                        \n",
    "                        if merge_polarities == True:\n",
    "                            inputs = inputs[:,:,0,:,:]\n",
    "\n",
    "                        ## network 연산 시작 ############################################################################################################\n",
    "                        if single_step == False:\n",
    "                            outputs = net(inputs.permute(1, 0, 2, 3, 4)) #inputs: [Batch, Time, Channel, Height, Width]  \n",
    "                            val_loss += criterion(outputs, labels)/len(test_loader)\n",
    "                        else:\n",
    "                            outputs_all = []\n",
    "                            for t in range(TIME):\n",
    "                                outputs = net(inputs[t])\n",
    "                                val_loss_temp = criterion(outputs, labels)\n",
    "                                outputs_all.append(outputs.detach())\n",
    "                                val_loss += (val_loss_temp.data/TIME)/len(test_loader)\n",
    "                            outputs_all = torch.stack(outputs_all, dim=1)\n",
    "                            outputs = outputs_all.mean(1)\n",
    "                        #################################################################################################################################\n",
    "\n",
    "                        _, predicted = torch.max(outputs.data, 1)\n",
    "                        total += real_batch\n",
    "                        assert real_batch == outputs.size(0), f'batch size is not same. real_batch: {real_batch}, outputs.size(0): {outputs.size(0)}'\n",
    "                        correct += (predicted == labels).sum().item()\n",
    "\n",
    "                    val_acc_now = correct / total\n",
    "                    # print(f'{epoch}-{i} validation acc: {100 * val_acc_now:.2f}%, lr={[f\"{lr:.10f}\" for lr in (param_group[\"lr\"] for param_group in optimizer.param_groups)]}')\n",
    "\n",
    "                iter_one_val_time_end = time.time()\n",
    "                elapsed_time_val = iter_one_val_time_end - iter_one_val_time_start  # 실행 시간 계산\n",
    "                # print(f\"iter_one_val_time: {elapsed_time_val} seconds\")\n",
    "\n",
    "                # network save\n",
    "                if val_acc_best < val_acc_now:\n",
    "                    val_acc_best = val_acc_now\n",
    "                    if ddp_on == False or torch.distributed.get_rank() == 0:\n",
    "                        # wandb 키면 state_dict아닌거는 저장 안됨\n",
    "                        torch.save(net.state_dict(), f\"net_save/save_now_net_weights_{unique_name}.pth\")\n",
    "                        # torch.save(net, f\"net_save/save_now_net_{unique_name}.pth\")\n",
    "                        # torch.save(net.module.state_dict(), f\"net_save/save_now_net_weights2_{unique_name}.pth\")\n",
    "                        # torch.save(net.module, f\"net_save/save_now_net2_{unique_name}.pth\")\n",
    "                    no_val_best_growth_count = 0\n",
    "                else:\n",
    "                    no_val_best_growth_count = no_val_best_growth_count + 1\n",
    "\n",
    "                if tr_acc_best < tr_acc:\n",
    "                    tr_acc_best = tr_acc\n",
    "                    no_tr_best_growth_count = 0\n",
    "                else:\n",
    "                    no_tr_best_growth_count = no_tr_best_growth_count + 1\n",
    "\n",
    "                tr_epoch_loss = tr_epoch_loss_temp\n",
    "                tr_epoch_loss_temp = 0\n",
    "\n",
    "                if DFA_toggle == True:\n",
    "                    DFA_flag = 1.0 - DFA_flag\n",
    "                    DFA_toggle = False\n",
    "\n",
    "                iter_of_val = True\n",
    "            ####################################################################################################################################################\n",
    "            \n",
    "            ## progress bar update ############################################################################################################\n",
    "            if ddp_on == False or torch.distributed.get_rank() == 0:\n",
    "                if iter_of_val == False:\n",
    "                    iterator.set_description(f\"{iter_acc_string}, iter_loss:{loss:10.6f}, val_best:{100 * val_acc_best:7.2f}%\")  \n",
    "                else:\n",
    "                    iterator.set_description(f\"{iter_acc_string2}, tr/val_loss:{tr_epoch_loss:10.6f}/{val_loss:10.6f}, tr:{100 * tr_acc:7.2f}%, val:{100 * val_acc_now:7.2f}%, val_best:{100 * val_acc_best:7.2f}%\")  \n",
    "                    iter_of_val = False\n",
    "            ####################################################################################################################################\n",
    "            \n",
    "            ## wandb logging ############################################################################################################\n",
    "            if ddp_on == False or torch.distributed.get_rank() == 0:\n",
    "                wandb.log({\"iter_acc\": iter_acc})\n",
    "                wandb.log({\"tr_acc\": tr_acc})\n",
    "                wandb.log({\"val_acc_now\": val_acc_now})\n",
    "                wandb.log({\"val_acc_best\": val_acc_best})\n",
    "                wandb.log({\"summary_val_acc\": val_acc_now})\n",
    "                wandb.log({\"epoch\": epoch})\n",
    "                wandb.log({\"DFA_flag\": DFA_flag}) # DFA mode 바뀌자 마자 바뀌는 게 아니고 validation 한번 했을 때 바뀜.\n",
    "                wandb.log({\"val_loss\": val_loss}) \n",
    "                wandb.log({\"tr_epoch_loss\": tr_epoch_loss}) \n",
    "            ####################################################################################################################################\n",
    "            \n",
    "            \n",
    "            ## accuray 로컬에 저장 하기 위한 코드 #####################################################################################\n",
    "            iter_acc_array = np.append(iter_acc_array, iter_acc)\n",
    "            tr_acc_array = np.append(tr_acc_array, tr_acc)\n",
    "            val_acc_now_array = np.append(val_acc_now_array, val_acc_now)\n",
    "            base_name = f'{current_time}'\n",
    "            ####################################################################################################################\n",
    "            \n",
    "            iter_acc_file_name_time = f'result_save/{base_name}_iter_acc_array_{unique_name}.npy'\n",
    "            tr_acc_file_name_time = f'result_save/{base_name}_tr_acc_array_{unique_name}.npy'\n",
    "            val_acc_file_name_time = f'result_save/{base_name}_val_acc_now_array_{unique_name}.npy'\n",
    "            hyperparameters_file_name_time = f'result_save/{base_name}_hyperparameters_{unique_name}.json'\n",
    "\n",
    "            hyperparameters['current epoch'] = epoch\n",
    "\n",
    "            ### accuracy 세이브: 덮어쓰기 하기 싫으면 주석 풀어서 사용 (시간마다 새로 쓰기) 비추천 ########################\n",
    "            # if ddp_on == False or torch.distributed.get_rank() == 0:\n",
    "            #     np.save(iter_acc_file_name_time, iter_acc_array)\n",
    "            #     np.save(tr_acc_file_name_time, iter_acc_array)\n",
    "            #     np.save(val_acc_file_name_time, val_acc_now_array)\n",
    "            #     with open(hyperparameters_file_name_time, 'w') as f:\n",
    "            #         json.dump(hyperparameters, f, indent=4)\n",
    "            #########################################################################################################\n",
    "\n",
    "            ## accuracy 세이브 ###########################################################################################\n",
    "            if ddp_on == False or torch.distributed.get_rank() == 0:\n",
    "                np.save(f'result_save/iter_acc_array_{unique_name}.npy', iter_acc_array)\n",
    "                np.save(f'result_save/tr_acc_array_{unique_name}.npy', tr_acc_array)\n",
    "                np.save(f'result_save/val_acc_now_array_{unique_name}.npy', val_acc_now_array)\n",
    "                with open(f'result_save/hyperparameters_{unique_name}.json', 'w') as f:\n",
    "                    json.dump(hyperparameters, f, indent=4)\n",
    "            ##########################################################################################################\n",
    "        ###### ITERATION END ##########################################################################################################\n",
    "                \n",
    "\n",
    "        ## scheduler update #############################################################################\n",
    "        if (scheduler_name != 'no'):\n",
    "            if (scheduler_name == 'ReduceLROnPlateau'):\n",
    "                scheduler.step(val_loss)\n",
    "            else:\n",
    "                scheduler.step()\n",
    "        #################################################################################################\n",
    "        \n",
    "        # 실행 시간 계산\n",
    "        epoch_time_end = time.time()\n",
    "        # print(f\"epoch_time: {epoch_time_end - epoch_start_time} seconds\\n\") \n",
    "    #======== EPOCH END ==========================================================================================\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ### my_snn control board (Gesture) ########################\n",
    "# decay = 0.25 # 0.875 0.25 0.125 0.75 0.5\n",
    "# # nda 0.25 # ottt 0.5\n",
    "# const2 = False # trace 할거면 True, 안할거면 False\n",
    "\n",
    "# unique_name = 'main' ## 이거 설정하면 새로운 경로에 모두 save\n",
    "# run_name = 'main' ## 이거 설정하면 새로운 경로에 모두 save\n",
    "\n",
    "# if const2 == True:\n",
    "#     const2 = decay\n",
    "# else:\n",
    "#     const2 = 0.0\n",
    "\n",
    "# wandb.init(project= f'my_snn {unique_name}',save_code=True)\n",
    "\n",
    "# my_snn_system(  devices = \"2\",\n",
    "#                 single_step = True, # True # False\n",
    "#                 unique_name = run_name,\n",
    "#                 my_seed = 42,\n",
    "#                 TIME = 10 , # dvscifar 10 # ottt 6 or 10 # nda 10  # 제작하는 dvs에서 TIME넘거나 적으면 자르거나 PADDING함\n",
    "#                 BATCH = 16, # batch norm 할거면 2이상으로 해야함   # nda 256   #  ottt 128\n",
    "#                 IMAGE_SIZE = 128, # dvscifar 48 # MNIST 28 # CIFAR10 32 # PMNIST 28 #NMNIST 34 # GESTURE 128\n",
    "#                 # dvsgesture 128, dvs_cifar2 128, nmnist 34, n_caltech101 180,240, n_tidigits 64, heidelberg 700, \n",
    "#                 #pmnist는 28로 해야 됨. 나머지는 바꿔도 돌아는 감.\n",
    "\n",
    "#                 # DVS_CIFAR10 할거면 time 10으로 해라\n",
    "#                 which_data = 'DVS_GESTURE_TONIC',\n",
    "# # 'CIFAR100' 'CIFAR10' 'MNIST' 'FASHION_MNIST' 'DVS_CIFAR10' 'PMNIST'아직\n",
    "# # 'DVS_GESTURE', 'DVS_GESTURE_TONIC','DVS_CIFAR10_2','NMNIST','NMNIST_TONIC','N_CALTECH101','n_tidigits','heidelberg'\n",
    "#                 # CLASS_NUM = 10,\n",
    "#                 data_path = '/data2', # YOU NEED TO CHANGE THIS\n",
    "#                 rate_coding = False, # True # False\n",
    "#                 lif_layer_v_init = 0.0,\n",
    "#                 lif_layer_v_decay = decay,\n",
    "#                 lif_layer_v_threshold = 0.5,  # 10000이상으로 하면 NDA LIF 씀. #nda 0.5  #ottt 1.0\n",
    "#                 lif_layer_v_reset = 0, # 10000이상은 hardreset (내 LIF쓰기는 함 ㅇㅇ)\n",
    "#                 lif_layer_sg_width = 2.570969004857107, # sigmoid류에서는 alpha값 4.0, rectangle류에서는 width값 0.5\n",
    "\n",
    "#                 # synapse_conv_in_channels = IMAGE_PIXEL_CHANNEL,\n",
    "#                 synapse_conv_kernel_size = 3,\n",
    "#                 synapse_conv_stride = 1,\n",
    "#                 synapse_conv_padding = 1,\n",
    "#                 synapse_conv_trace_const1 = 1, # 현재 trace구할 때 현재 spike에 곱해지는 상수. 걍 1로 두셈.\n",
    "#                 synapse_conv_trace_const2 = const2, # 현재 trace구할 때 직전 trace에 곱해지는 상수. lif_layer_v_decay와 같게 할 것을 추천\n",
    "\n",
    "#                 # synapse_fc_out_features = CLASS_NUM,\n",
    "#                 synapse_fc_trace_const1 = 1, # 현재 trace구할 때 현재 spike에 곱해지는 상수. 걍 1로 두셈.\n",
    "#                 synapse_fc_trace_const2 = const2, # 현재 trace구할 때 직전 trace에 곱해지는 상수. lif_layer_v_decay와 같게 할 것을 추천\n",
    "\n",
    "#                 pre_trained = False, # True # False\n",
    "#                 convTrue_fcFalse = False, # True # False\n",
    "\n",
    "#                 # 'P' for average pooling, 'D' for (1,1) aver pooling, 'M' for maxpooling, 'L' for linear classifier, [  ] for residual block\n",
    "#                 # conv에서 10000 이상은 depth-wise separable (BPTT만 지원), 20000이상은 depth-wise (BPTT만 지원)\n",
    "#                 # cfg = [64, 64],\n",
    "#                 # cfg = [64, 124, 64, 124],\n",
    "#                 # cfg = ['M','M',512], \n",
    "#                 # cfg = [512], \n",
    "#                 # cfg = ['M', 'M', 64, 128, 'P', 128, 'P'], \n",
    "#                 # cfg = ['M','M',512],\n",
    "#                 # cfg = ['M','M',200,200],\n",
    "#                 cfg = ['M','M',200,200,200],\n",
    "#                 # cfg = ['M','M',1024,512,256,128,64],\n",
    "#                 # cfg = [200,200],\n",
    "#                 # cfg = [12], #fc\n",
    "#                 # cfg = [12, 'M', 48, 'M', 12], \n",
    "#                 # cfg = [64,[64,64],64], # 끝에 linear classifier 하나 자동으로 붙습니다\n",
    "#                 # cfg = [64, 128, 'P', 256, 256, 'P', 512, 512, 'P', 512, 512, 'D'], #ottt\n",
    "#                 # cfg = [64, 128, 'P', 256, 256, 'P', 512, 512, 'P', 512, 512], \n",
    "#                 # cfg = [64, 128, 'M', 256, 256, 'M', 512, 512, 'M', 512, 512], \n",
    "#                 # cfg = [64, 'P', 128, 'P', 256, 256, 'P', 512, 512, 512, 512, 'D'], # nda\n",
    "#                 # cfg = [64, 'P', 128, 'P', 256, 256, 'P', 512, 512, 512, 512], # nda 128pixel\n",
    "#                 # cfg = [64, 'P', 128, 'P', 256, 256, 'P', 512, 512, 512, 512, 'L', 4096, 4096],\n",
    "#                 # cfg = [20001,10001], # depthwise, separable\n",
    "#                 # cfg = [64,20064,10001], # vanilla conv, depthwise, separable\n",
    "#                 # cfg = [8, 'P', 8, 'P', 8, 'P', 8,'P', 8, 'P'],\n",
    "#                 # cfg = [],        \n",
    "                \n",
    "#                 net_print = True, # True # False # True로 하길 추천\n",
    "#                 weight_count_print = False, # True # False\n",
    "                \n",
    "#                 pre_trained_path = f\"net_save/save_now_net_weights_{unique_name}.pth\",\n",
    "#                 learning_rate = 0.001, #0.1 bptt, #0.01 ottt, # default 0.001  # ottt 0.1 # nda 0.001 # 0.00936191669529645\n",
    "#                 epoch_num = 60,\n",
    "#                 verbose_interval = 999999999, #이거 걍 건들지마셈 #숫자 크게 하면 꺼짐 #걍 중간중간 iter에서 끊어서 출력\n",
    "#                 validation_interval =  999999999,#999999999, #이거 걍 건들지마셈 #숫자 크게 하면 에포크 마지막 iter 때 val 함\n",
    "\n",
    "#                 tdBN_on = False,  # True # False\n",
    "#                 BN_on = False,  # True # False\n",
    "                \n",
    "#                 surrogate = 'hard_sigmoid', # 'sigmoid' 'rectangle' 'rough_rectangle' 'hard_sigmoid'\n",
    "                \n",
    "#                 gradient_verbose = False,  # True # False  # weight gradient 각 layer마다 띄워줌\n",
    "\n",
    "#                 BPTT_on = False,  # True # False # True이면 BPTT, False이면 OTTT  # depthwise, separable은 BPTT만 가능\n",
    "#                 optimizer_what = 'SGD', # 'SGD' 'Adam', 'RMSprop'\n",
    "#                 scheduler_name = 'CosineAnnealingLR', # 'no' 'StepLR' 'ExponentialLR' 'ReduceLROnPlateau' 'CosineAnnealingLR' 'OneCycleLR'\n",
    "                \n",
    "#                 ddp_on = False,   # True # False \n",
    "#                 # 지원 DATASET: cifar10, mnist\n",
    "\n",
    "#                 nda_net = False,   # True # False\n",
    "\n",
    "#                 domain_il_epoch = 0, # over 0, then domain il mode on # pmnist 쓸거면 HLOP 코드보고 더 디벨롭하셈. 지금 개발 hold함.\n",
    "                \n",
    "#                 dvs_clipping = 2, # 숫자만큼 크면 spike 아니면 걍 0\n",
    "#                 # gesture, cifar-dvs2, nmnist, ncaltech101\n",
    "\n",
    "#                 dvs_duration = 100_000, # 0 아니면 time sampling # dvs number sampling OR time sampling # gesture, cifar-dvs2, nmnist, ncaltech101\n",
    "#                 # 있는 데이터들 #gesture 100_000 25_000 10_000 1_000 1_000_000 #nmnist 10000 #nmnist_tonic 10_000 25_000\n",
    "#                 # 한 숫자가 1us인듯 (spikingjelly코드에서)\n",
    "#                 # 한 장에 50 timestep만 생산함. 싫으면 my_snn/trying/spikingjelly_dvsgesture의__init__.py 를 참고해봐\n",
    "\n",
    "#                 OTTT_sWS_on = False, # True # False # BPTT끄고, CONV에만 적용됨.\n",
    "\n",
    "#                 DFA_on = False, # True # False # residual은 dfa지원안함.\n",
    "#                 OTTT_input_trace_on = False, # True # False # 맨 처음 input에 trace 적용\n",
    "                 \n",
    "#                 e_transport_swap = 0, # 1 이상이면 해당 숫자 에포크만큼 val_acc_best가 변화가 없으면 e_transport scheme (BP vs DFA) swap\n",
    "#                 e_transport_swap_tr = 0, # 1 이상이면 해당 숫자 에포크만큼 tr_acc_best가 변화가 없으면 e_transport scheme (BP vs DFA) swap\n",
    "#                 e_transport_swap_coin = 1, # swap할 수 있는 coin 개수\n",
    "\n",
    "#                 drop_rate = 0.0, # drop_rate만큼 0으로 만듦. ex) 0.2면 activation의 20%를 0으로 만듦.\n",
    "\n",
    "#                 exclude_class = True, # True # False # gesture에서 10번째 클래스 제외\n",
    "\n",
    "#                 merge_polarities = False, # True # False # tonic dvs dataset 에서 polarities 합치기\n",
    "#                 ) \n",
    "# # sigmoid와 BN이 있어야 잘된다.\n",
    "# # average pooling  \n",
    "# # 이 낫다. \n",
    " \n",
    "# # nda에서는 decay = 0.25, threshold = 0.5, width =1, surrogate = rectangle, batch = 256, tdBN = True\n",
    "# ## OTTT 에서는 decay = 0.5, threshold = 1.0, surrogate = sigmoid, batch = 128, BN = True\n",
    "\n",
    "\n",
    "# # DDP 실행 코드\n",
    "# '''\n",
    "# ddp_on 키고, gpu 개수 만큼 batch size 나눠줘\n",
    "# CUDA_VISIBLE_DEVICES=0,1,2,3,4,5 python -m torch.distributed.launch --nproc_per_node=6 main_ddp.py\n",
    "# CUDA_VISIBLE_DEVICES=1,2,3 python -m torch.distributed.launch --nproc_per_node=3 main_ddp.py\n",
    "# CUDA_VISIBLE_DEVICES=0,1,2,3 python -m torch.distributed.launch --nproc_per_node=4 main_ddp.py\n",
    "# '''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ### my_snn control board (NMNIST) ########################\n",
    "# decay = 0.25 # 0.875 0.25 0.125 0.75 0.5\n",
    "# # nda 0.25 # ottt 0.5\n",
    "# const2 = False # trace 할거면 True, 안할거면 False\n",
    "\n",
    "# unique_name = 'main' ## 이거 설정하면 새로운 경로에 모두 save\n",
    "# run_name = 'main' ## 이거 설정하면 새로운 경로에 모두 save\n",
    "\n",
    "# if const2 == True:\n",
    "#     const2 = decay\n",
    "# else:\n",
    "#     const2 = 0.0\n",
    "\n",
    "# wandb.init(project= f'my_snn {unique_name}',save_code=True)\n",
    "\n",
    "# my_snn_system(  devices = \"4\",\n",
    "#                 single_step = True, # True # False\n",
    "#                 unique_name = run_name,\n",
    "#                 my_seed = 42,\n",
    "#                 TIME = 10 , # dvscifar 10 # ottt 6 or 10 # nda 10  # 제작하는 dvs에서 TIME넘거나 적으면 자르거나 PADDING함\n",
    "#                 BATCH = 128, # batch norm 할거면 2이상으로 해야함   # nda 256   #  ottt 128\n",
    "#                 IMAGE_SIZE = 34, # dvscifar 48 # MNIST 28 # CIFAR10 32 # PMNIST 28 #NMNIST 34 # GESTURE 128\n",
    "#                 # dvsgesture 128, dvs_cifar2 128, nmnist 34, n_caltech101 180,240, n_tidigits 64, heidelberg 700, \n",
    "#                 #pmnist는 28로 해야 됨. 나머지는 바꿔도 돌아는 감.\n",
    "\n",
    "#                 # DVS_CIFAR10 할거면 time 10으로 해라\n",
    "#                 which_data = 'NMNIST_TONIC',\n",
    "# # 'CIFAR100' 'CIFAR10' 'MNIST' 'FASHION_MNIST' 'DVS_CIFAR10' 'PMNIST'아직\n",
    "# # 'DVS_GESTURE', 'DVS_GESTURE_TONIC','DVS_CIFAR10_2','NMNIST','NMNIST_TONIC','N_CALTECH101','n_tidigits','heidelberg'\n",
    "#                 # CLASS_NUM = 10,\n",
    "#                 data_path = '/data2', # YOU NEED TO CHANGE THIS\n",
    "#                 rate_coding = False, # True # False\n",
    "#                 lif_layer_v_init = 0.0,\n",
    "#                 lif_layer_v_decay = decay,\n",
    "#                 lif_layer_v_threshold = 1.0,  # 10000이상으로 하면 NDA LIF 씀. #nda 0.5  #ottt 1.0\n",
    "#                 lif_layer_v_reset = 0, # 10000이상은 hardreset (내 LIF쓰기는 함 ㅇㅇ)\n",
    "#                 lif_layer_sg_width = 0.5, # # surrogate sigmoid 쓸 때는 의미없음\n",
    "\n",
    "#                 # synapse_conv_in_channels = IMAGE_PIXEL_CHANNEL,\n",
    "#                 synapse_conv_kernel_size = 3,\n",
    "#                 synapse_conv_stride = 1,\n",
    "#                 synapse_conv_padding = 1,\n",
    "#                 synapse_conv_trace_const1 = 1, # 현재 trace구할 때 현재 spike에 곱해지는 상수. 걍 1로 두셈.\n",
    "#                 synapse_conv_trace_const2 = const2, # 현재 trace구할 때 직전 trace에 곱해지는 상수. lif_layer_v_decay와 같게 할 것을 추천\n",
    "\n",
    "#                 # synapse_fc_out_features = CLASS_NUM,\n",
    "#                 synapse_fc_trace_const1 = 1, # 현재 trace구할 때 현재 spike에 곱해지는 상수. 걍 1로 두셈.\n",
    "#                 synapse_fc_trace_const2 = const2, # 현재 trace구할 때 직전 trace에 곱해지는 상수. lif_layer_v_decay와 같게 할 것을 추천\n",
    "\n",
    "#                 pre_trained = False, # True # False\n",
    "#                 convTrue_fcFalse = False, # True # False\n",
    "\n",
    "#                 # 'P' for average pooling, 'D' for (1,1) aver pooling, 'M' for maxpooling, 'L' for linear classifier, [  ] for residual block\n",
    "#                 # conv에서 10000 이상은 depth-wise separable (BPTT만 지원), 20000이상은 depth-wise (BPTT만 지원)\n",
    "#                 # cfg = [64, 64],\n",
    "#                 # cfg = [64, 124, 64, 124],\n",
    "#                 # cfg = ['M','M',512], \n",
    "#                 # cfg = [512], \n",
    "#                 # cfg = ['M', 'M', 64, 128, 'P', 128, 'P'], \n",
    "#                 # cfg = ['M','M',512],\n",
    "#                 # cfg = ['M','M',200,200],\n",
    "#                 # cfg = ['M','M',1024,512,256,128,64],\n",
    "#                 cfg = [200,200],\n",
    "#                 # cfg = [12], #fc\n",
    "#                 # cfg = [12, 'M', 48, 'M', 12], \n",
    "#                 # cfg = [64,[64,64],64], # 끝에 linear classifier 하나 자동으로 붙습니다\n",
    "#                 # cfg = [64, 128, 'P', 256, 256, 'P', 512, 512, 'P', 512, 512, 'D'], #ottt\n",
    "#                 # cfg = [64, 128, 'P', 256, 256, 'P', 512, 512, 'P', 512, 512], \n",
    "#                 # cfg = [64, 128, 'M', 256, 256, 'M', 512, 512, 'M', 512, 512], \n",
    "#                 # cfg = [64, 'P', 128, 'P', 256, 256, 'P', 512, 512, 512, 512, 'D'], # nda\n",
    "#                 # cfg = [64, 'P', 128, 'P', 256, 256, 'P', 512, 512, 512, 512], # nda 128pixel\n",
    "#                 # cfg = [64, 'P', 128, 'P', 256, 256, 'P', 512, 512, 512, 512, 'L', 4096, 4096],\n",
    "#                 # cfg = [20001,10001], # depthwise, separable\n",
    "#                 # cfg = [64,20064,10001], # vanilla conv, depthwise, separable\n",
    "#                 # cfg = [8, 'P', 8, 'P', 8, 'P', 8,'P', 8, 'P'],\n",
    "#                 # cfg = [],        \n",
    "                \n",
    "#                 net_print = True, # True # False # True로 하길 추천\n",
    "#                 weight_count_print = False, # True # False\n",
    "                \n",
    "#                 pre_trained_path = f\"net_save/save_now_net_weights_{unique_name}.pth\",\n",
    "#                 learning_rate = 0.009, # 0.001, # default 0.001  # ottt 0.1 # nda 0.001 \n",
    "#                 epoch_num = 300,\n",
    "#                 verbose_interval = 999999999, #이거 걍 건들지마셈 #숫자 크게 하면 꺼짐 #걍 중간중간 iter에서 끊어서 출력\n",
    "#                 validation_interval =  999999999,#999999999, #이거 걍 건들지마셈 #숫자 크게 하면 에포크 마지막 iter 때 val 함\n",
    "\n",
    "#                 tdBN_on = False,  # True # False\n",
    "#                 BN_on = False,  # True # False\n",
    "                \n",
    "#                 surrogate = 'hard_sigmoid', # 'rectangle' 'sigmoid' 'rough_rectangle' 'hard_sigmoid'\n",
    "                \n",
    "#                 gradient_verbose = False,  # True # False  # weight gradient 각 layer마다 띄워줌\n",
    "\n",
    "#                 BPTT_on = False,  # True # False # True이면 BPTT, False이면 OTTT  # depthwise, separable은 BPTT만 가능\n",
    "#                 optimizer_what = 'SGD', # 'SGD' 'Adam', 'RMSprop'\n",
    "#                 scheduler_name = 'CosineAnnealingLR', # 'no' 'StepLR' 'ExponentialLR' 'ReduceLROnPlateau' 'CosineAnnealingLR' 'OneCycleLR'\n",
    "                \n",
    "#                 ddp_on = False,   # True # False \n",
    "#                 # 지원 DATASET: cifar10, mnist\n",
    "\n",
    "#                 nda_net = False,   # True # False\n",
    "\n",
    "#                 domain_il_epoch = 0, # over 0, then domain il mode on # pmnist 쓸거면 HLOP 코드보고 더 디벨롭하셈. 지금 개발 hold함.\n",
    "                \n",
    "#                 dvs_clipping = 1, # 숫자만큼 크면 spike 아니면 걍 0\n",
    "#                 # gesture, cifar-dvs2, nmnist, ncaltech101\n",
    "\n",
    "#                 dvs_duration = 10_000, # 0 아니면 time sampling # dvs number sampling OR time sampling # gesture, cifar-dvs2, nmnist, ncaltech101\n",
    "#                 # 있는 데이터들 #gesture 100_000 25_000 10_000 1_000 1_000_000 #nmnist 10000 #nmnist_tonic 10_000 25_000\n",
    "#                 # 한 숫자가 1us인듯 (spikingjelly코드에서)\n",
    "#                 # 한 장에 50 timestep만 생산함. 싫으면 my_snn/trying/spikingjelly_dvsgesture의__init__.py 를 참고해봐\n",
    "\n",
    "#                 OTTT_sWS_on = False, # True # False # BPTT끄고, CONV에만 적용됨.\n",
    "\n",
    "#                 DFA_on = True, # True # False # residual은 dfa지원안함.\n",
    "#                 OTTT_input_trace_on = False, # True # False # 맨 처음 input에 trace 적용\n",
    "                 \n",
    "#                 e_transport_swap = 5, # 1 이상이면 해당 숫자 에포크만큼 val_acc_best가 변화가 없으면 e_transport scheme (BP vs DFA) swap\n",
    "#                 e_transport_swap_tr = 0, # 1 이상이면 해당 숫자 에포크만큼 tr_acc_best가 변화가 없으면 e_transport scheme (BP vs DFA) swap\n",
    "#                 e_transport_swap_coin = 1, # swap할 수 있는 coin 개수\n",
    "                \n",
    "#                 drop_rate = 0.0, # drop_rate만큼 0으로 만듦. ex) 0.2면 activation의 20%를 0으로 만듦.\n",
    "\n",
    "#                 exclude_class = True, # True # False # gesture에서 10번째 클래스 제외\n",
    "\n",
    "#                 merge_polarities = False, # True # False # tonic dvs dataset 에서 polarities 합치기\n",
    "#                 ) \n",
    "# # sigmoid와 BN이 있어야 잘된다.\n",
    "# # average pooling  \n",
    "# # 이 낫다. \n",
    " \n",
    "# # nda에서는 decay = 0.25, threshold = 0.5, width =1, surrogate = rectangle, batch = 256, tdBN = True\n",
    "# ## OTTT 에서는 decay = 0.5, threshold = 1.0, surrogate = sigmoid, batch = 128, BN = True\n",
    "\n",
    "\n",
    "# # DDP 실행 코드\n",
    "# '''\n",
    "# ddp_on 키고, gpu 개수 만큼 batch size 나눠줘\n",
    "# CUDA_VISIBLE_DEVICES=0,1,2,3,4,5 python -m torch.distributed.launch --nproc_per_node=6 main_ddp.py\n",
    "# CUDA_VISIBLE_DEVICES=1,2,3 python -m torch.distributed.launch --nproc_per_node=3 main_ddp.py\n",
    "# CUDA_VISIBLE_DEVICES=0,1,2,3 python -m torch.distributed.launch --nproc_per_node=4 main_ddp.py\n",
    "# '''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Create sweep with ID: yxynyr6h\n",
      "Sweep URL: https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/yxynyr6h\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: xeiqpmr5 with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBATCH: 16\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tDFA_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tIMAGE_SIZE: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tOTTT_input_trace_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tOTTT_sWS_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tTIME: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcfg: ['M', 'M', 200, 200]\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tconst2: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdecay: 0.25\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdrop_rate: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdvs_clipping: 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdvs_duration: 100000\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \te_transport_swap: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \te_transport_swap_coin: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \te_transport_swap_tr: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepoch_num: 60\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \texclude_class: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.01\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_sg_width: 2.570969004857107\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_reset: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_threshold: 1.170975914519612\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmerge_polarities: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tscheduler_name: CosineAnnealingLR\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsurrogate: hard_sigmoid\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \twhich_data: DVS_GESTURE_TONIC\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mbhkim003\u001b[0m (\u001b[33mbhkim003-seoul-national-university\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.17.7 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.17.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/nfs/home/bhkim003/github_folder/ByeonghyeonKim/my_snn/wandb/run-20240822_170452-xeiqpmr5</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/xeiqpmr5' target=\"_blank\">decent-sweep-1</a></strong> to <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/yxynyr6h' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/yxynyr6h</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/yxynyr6h' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/yxynyr6h</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/xeiqpmr5' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/xeiqpmr5</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BATCH' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'IMAGE_SIZE' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'which_data' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_threshold' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_reset' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_sg_width' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'cfg' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'learning_rate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'epoch_num' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'surrogate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'scheduler_name' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'dvs_clipping' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'dvs_duration' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'OTTT_sWS_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'DFA_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'OTTT_input_trace_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'e_transport_swap' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'e_transport_swap_tr' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'e_transport_swap_coin' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'drop_rate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'exclude_class' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'merge_polarities' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'TIME' was locked by 'sweep' (ignored update).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset_hash = 2bbd58b4e0d3c1e9ad501fad8a43feed\n",
      "cache path exists\n",
      "\n",
      "we will exclude the 'other' class. dvsgestrue 10 classes' indices exist. \n",
      "\n",
      "DataParallel(\n",
      "  (module): MY_SNN_FC_sstep(\n",
      "    (layers): MY_Sequential(\n",
      "      (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (2): DimChanger_for_FC_sstep()\n",
      "      (3): SYNAPSE_FC_trace_sstep()\n",
      "      (4): LIF_layer_trace_sstep()\n",
      "      (5): SYNAPSE_FC_trace_sstep()\n",
      "      (6): LIF_layer_trace_sstep()\n",
      "      (7): SYNAPSE_FC_trace_sstep()\n",
      "    )\n",
      "  )\n",
      ")\n",
      "==================================================\n",
      "My Num of PARAMS: 452,010, system's param_num : 452,010\n",
      "Memory: 1.72MiB at 32-bit\n",
      "==================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch-0   lr=['0.0100000'], tr/val_loss:  2.317507/  2.316367, tr:   9.70%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:05<00:00, 11.51it/s]\n",
      "epoch-1   lr=['0.0099931'], tr/val_loss:  1.960052/  1.536439, tr:  28.19%, val:  54.58%, val_best:  54.58%: 100%|██████████| 62/62 [00:04<00:00, 12.86it/s]\n",
      "epoch-2   lr=['0.0099726'], tr/val_loss:  1.238769/  1.258278, tr:  58.43%, val:  60.00%, val_best:  60.00%: 100%|██████████| 62/62 [00:05<00:00, 11.77it/s]\n",
      "epoch-3   lr=['0.0099384'], tr/val_loss:  1.065071/  1.209536, tr:  64.35%, val:  60.83%, val_best:  60.83%: 100%|██████████| 62/62 [00:05<00:00, 10.96it/s]\n",
      "epoch-4   lr=['0.0098907'], tr/val_loss:  1.018179/  1.170967, tr:  65.99%, val:  64.58%, val_best:  64.58%: 100%|██████████| 62/62 [00:05<00:00, 10.95it/s]\n",
      "epoch-5   lr=['0.0098296'], tr/val_loss:  0.891063/  1.205888, tr:  67.11%, val:  62.92%, val_best:  64.58%: 100%|██████████| 62/62 [00:05<00:00, 11.47it/s]\n",
      "epoch-6   lr=['0.0097553'], tr/val_loss:  0.779487/  1.241270, tr:  70.58%, val:  60.42%, val_best:  64.58%: 100%|██████████| 62/62 [00:05<00:00, 11.65it/s]\n",
      "epoch-7   lr=['0.0096679'], tr/val_loss:  0.773663/  1.318794, tr:  71.30%, val:  57.92%, val_best:  64.58%: 100%|██████████| 62/62 [00:05<00:00, 11.59it/s]\n",
      "epoch-8   lr=['0.0095677'], tr/val_loss:  0.766602/  1.097576, tr:  71.60%, val:  65.42%, val_best:  65.42%: 100%|██████████| 62/62 [00:05<00:00, 11.43it/s]\n",
      "epoch-9   lr=['0.0094550'], tr/val_loss:  0.612894/  1.215225, tr:  77.43%, val:  69.58%, val_best:  69.58%: 100%|██████████| 62/62 [00:05<00:00, 11.29it/s]\n",
      "epoch-10  lr=['0.0093301'], tr/val_loss:  0.601287/  1.100822, tr:  78.14%, val:  72.08%, val_best:  72.08%: 100%|██████████| 62/62 [00:05<00:00, 11.31it/s]\n",
      "epoch-11  lr=['0.0091934'], tr/val_loss:  0.555347/  1.323532, tr:  78.65%, val:  61.25%, val_best:  72.08%: 100%|██████████| 62/62 [00:05<00:00, 11.63it/s]\n",
      "epoch-12  lr=['0.0090451'], tr/val_loss:  0.538500/  1.235753, tr:  81.82%, val:  63.75%, val_best:  72.08%: 100%|██████████| 62/62 [00:05<00:00, 11.68it/s]\n",
      "epoch-13  lr=['0.0088857'], tr/val_loss:  0.480132/  1.292375, tr:  84.88%, val:  63.33%, val_best:  72.08%: 100%|██████████| 62/62 [00:05<00:00, 11.47it/s]\n",
      "epoch-14  lr=['0.0087157'], tr/val_loss:  0.428243/  1.250104, tr:  85.90%, val:  70.42%, val_best:  72.08%: 100%|██████████| 62/62 [00:05<00:00, 11.89it/s]\n",
      "epoch-15  lr=['0.0085355'], tr/val_loss:  0.422704/  1.314890, tr:  87.74%, val:  69.17%, val_best:  72.08%: 100%|██████████| 62/62 [00:05<00:00, 11.71it/s]\n",
      "epoch-16  lr=['0.0083457'], tr/val_loss:  0.354659/  1.371996, tr:  90.70%, val:  75.00%, val_best:  75.00%: 100%|██████████| 62/62 [00:06<00:00,  9.87it/s]\n",
      "epoch-17  lr=['0.0081466'], tr/val_loss:  0.348299/  1.265828, tr:  91.73%, val:  72.92%, val_best:  75.00%: 100%|██████████| 62/62 [00:06<00:00,  8.98it/s]\n",
      "epoch-18  lr=['0.0079389'], tr/val_loss:  0.319786/  1.352674, tr:  90.91%, val:  74.58%, val_best:  75.00%: 100%|██████████| 62/62 [00:19<00:00,  3.15it/s]\n",
      "epoch-19  lr=['0.0077232'], tr/val_loss:  0.250440/  1.391994, tr:  96.12%, val:  74.58%, val_best:  75.00%: 100%|██████████| 62/62 [00:40<00:00,  1.52it/s]\n",
      "epoch-20  lr=['0.0075000'], tr/val_loss:  0.242221/  1.347371, tr:  97.96%, val:  77.92%, val_best:  77.92%: 100%|██████████| 62/62 [00:21<00:00,  2.85it/s]\n",
      "epoch-21  lr=['0.0072700'], tr/val_loss:  0.156524/  1.573747, tr:  99.49%, val:  72.92%, val_best:  77.92%: 100%|██████████| 62/62 [00:21<00:00,  2.94it/s]\n",
      "epoch-22  lr=['0.0070337'], tr/val_loss:  0.169613/  1.436933, tr:  97.45%, val:  80.83%, val_best:  80.83%: 100%|██████████| 62/62 [00:20<00:00,  3.02it/s]\n",
      "epoch-23  lr=['0.0067918'], tr/val_loss:  0.155440/  1.512444, tr:  98.57%, val:  74.58%, val_best:  80.83%: 100%|██████████| 62/62 [00:21<00:00,  2.89it/s]\n",
      "epoch-24  lr=['0.0065451'], tr/val_loss:  0.103616/  1.569070, tr:  99.80%, val:  75.83%, val_best:  80.83%: 100%|██████████| 62/62 [00:21<00:00,  2.86it/s]\n",
      "epoch-25  lr=['0.0062941'], tr/val_loss:  0.073300/  1.509544, tr:  99.90%, val:  77.50%, val_best:  80.83%: 100%|██████████| 62/62 [00:17<00:00,  3.62it/s]\n",
      "epoch-26  lr=['0.0060396'], tr/val_loss:  0.039419/  1.542159, tr: 100.00%, val:  80.42%, val_best:  80.83%: 100%|██████████| 62/62 [00:21<00:00,  2.94it/s]\n",
      "epoch-27  lr=['0.0057822'], tr/val_loss:  0.027823/  1.647091, tr: 100.00%, val:  79.58%, val_best:  80.83%: 100%|██████████| 62/62 [00:20<00:00,  3.07it/s]\n",
      "epoch-28  lr=['0.0055226'], tr/val_loss:  0.019990/  1.601477, tr: 100.00%, val:  79.58%, val_best:  80.83%: 100%|██████████| 62/62 [00:19<00:00,  3.18it/s]\n",
      "epoch-29  lr=['0.0052617'], tr/val_loss:  0.016527/  1.630948, tr: 100.00%, val:  80.42%, val_best:  80.83%: 100%|██████████| 62/62 [00:20<00:00,  2.98it/s]\n",
      "epoch-30  lr=['0.0050000'], tr/val_loss:  0.011419/  1.643582, tr: 100.00%, val:  80.83%, val_best:  80.83%: 100%|██████████| 62/62 [00:18<00:00,  3.31it/s]\n",
      "epoch-31  lr=['0.0047383'], tr/val_loss:  0.009779/  1.659039, tr: 100.00%, val:  81.25%, val_best:  81.25%: 100%|██████████| 62/62 [00:20<00:00,  3.03it/s]\n",
      "epoch-32  lr=['0.0044774'], tr/val_loss:  0.006149/  1.648947, tr: 100.00%, val:  81.67%, val_best:  81.67%: 100%|██████████| 62/62 [00:21<00:00,  2.95it/s]\n",
      "epoch-33  lr=['0.0042178'], tr/val_loss:  0.005022/  1.707166, tr: 100.00%, val:  80.83%, val_best:  81.67%: 100%|██████████| 62/62 [00:21<00:00,  2.90it/s]\n",
      "epoch-34  lr=['0.0039604'], tr/val_loss:  0.004512/  1.704938, tr: 100.00%, val:  80.83%, val_best:  81.67%: 100%|██████████| 62/62 [00:16<00:00,  3.70it/s]\n",
      "epoch-35  lr=['0.0037059'], tr/val_loss:  0.003829/  1.712818, tr: 100.00%, val:  81.25%, val_best:  81.67%: 100%|██████████| 62/62 [00:17<00:00,  3.47it/s]\n",
      "epoch-36  lr=['0.0034549'], tr/val_loss:  0.003651/  1.709227, tr: 100.00%, val:  80.83%, val_best:  81.67%: 100%|██████████| 62/62 [00:21<00:00,  2.90it/s]\n",
      "epoch-37  lr=['0.0032082'], tr/val_loss:  0.003235/  1.698444, tr: 100.00%, val:  82.08%, val_best:  82.08%: 100%|██████████| 62/62 [00:21<00:00,  2.85it/s]\n",
      "epoch-38  lr=['0.0029663'], tr/val_loss:  0.002949/  1.711905, tr: 100.00%, val:  81.25%, val_best:  82.08%: 100%|██████████| 62/62 [00:21<00:00,  2.87it/s]\n",
      "epoch-39  lr=['0.0027300'], tr/val_loss:  0.002758/  1.710387, tr: 100.00%, val:  81.25%, val_best:  82.08%: 100%|██████████| 62/62 [00:23<00:00,  2.65it/s]\n",
      "epoch-40  lr=['0.0025000'], tr/val_loss:  0.002651/  1.717611, tr: 100.00%, val:  81.25%, val_best:  82.08%: 100%|██████████| 62/62 [00:18<00:00,  3.32it/s]\n",
      "epoch-41  lr=['0.0022768'], tr/val_loss:  0.002510/  1.728254, tr: 100.00%, val:  81.25%, val_best:  82.08%: 100%|██████████| 62/62 [00:21<00:00,  2.86it/s]\n",
      "epoch-42  lr=['0.0020611'], tr/val_loss:  0.002384/  1.730879, tr: 100.00%, val:  81.25%, val_best:  82.08%: 100%|██████████| 62/62 [00:20<00:00,  3.02it/s]\n",
      "epoch-43  lr=['0.0018534'], tr/val_loss:  0.002329/  1.733166, tr: 100.00%, val:  81.67%, val_best:  82.08%: 100%|██████████| 62/62 [00:21<00:00,  2.90it/s]\n",
      "epoch-44  lr=['0.0016543'], tr/val_loss:  0.002287/  1.732525, tr: 100.00%, val:  81.67%, val_best:  82.08%: 100%|██████████| 62/62 [00:20<00:00,  3.04it/s]\n",
      "epoch-45  lr=['0.0014645'], tr/val_loss:  0.002265/  1.740765, tr: 100.00%, val:  81.67%, val_best:  82.08%: 100%|██████████| 62/62 [00:19<00:00,  3.23it/s]\n",
      "epoch-46  lr=['0.0012843'], tr/val_loss:  0.002196/  1.735738, tr: 100.00%, val:  81.67%, val_best:  82.08%: 100%|██████████| 62/62 [00:20<00:00,  3.06it/s]\n",
      "epoch-47  lr=['0.0011143'], tr/val_loss:  0.002178/  1.736423, tr: 100.00%, val:  81.25%, val_best:  82.08%: 100%|██████████| 62/62 [00:21<00:00,  2.84it/s]\n",
      "epoch-48  lr=['0.0009549'], tr/val_loss:  0.002184/  1.736630, tr: 100.00%, val:  80.83%, val_best:  82.08%: 100%|██████████| 62/62 [00:19<00:00,  3.22it/s]\n",
      "epoch-49  lr=['0.0008066'], tr/val_loss:  0.002104/  1.736606, tr: 100.00%, val:  81.25%, val_best:  82.08%: 100%|██████████| 62/62 [00:18<00:00,  3.29it/s]\n",
      "epoch-50  lr=['0.0006699'], tr/val_loss:  0.002153/  1.735135, tr: 100.00%, val:  81.25%, val_best:  82.08%: 100%|██████████| 62/62 [00:21<00:00,  2.82it/s]\n",
      "epoch-51  lr=['0.0005450'], tr/val_loss:  0.002090/  1.734661, tr: 100.00%, val:  81.25%, val_best:  82.08%: 100%|██████████| 62/62 [00:16<00:00,  3.79it/s]\n",
      "epoch-52  lr=['0.0004323'], tr/val_loss:  0.002075/  1.734000, tr: 100.00%, val:  81.25%, val_best:  82.08%: 100%|██████████| 62/62 [00:21<00:00,  2.87it/s]\n",
      "epoch-53  lr=['0.0003321'], tr/val_loss:  0.002050/  1.736976, tr: 100.00%, val:  81.25%, val_best:  82.08%: 100%|██████████| 62/62 [00:19<00:00,  3.19it/s]\n",
      "epoch-54  lr=['0.0002447'], tr/val_loss:  0.002057/  1.732715, tr: 100.00%, val:  81.25%, val_best:  82.08%: 100%|██████████| 62/62 [00:17<00:00,  3.55it/s]\n",
      "epoch-55  lr=['0.0001704'], tr/val_loss:  0.002007/  1.732680, tr: 100.00%, val:  81.25%, val_best:  82.08%: 100%|██████████| 62/62 [00:17<00:00,  3.45it/s]\n",
      "epoch-56  lr=['0.0001093'], tr/val_loss:  0.002010/  1.729946, tr: 100.00%, val:  81.25%, val_best:  82.08%: 100%|██████████| 62/62 [00:16<00:00,  3.82it/s]\n",
      "epoch-57  lr=['0.0000616'], tr/val_loss:  0.001999/  1.731514, tr: 100.00%, val:  81.25%, val_best:  82.08%: 100%|██████████| 62/62 [00:18<00:00,  3.28it/s]\n",
      "epoch-58  lr=['0.0000274'], tr/val_loss:  0.001989/  1.731884, tr: 100.00%, val:  81.25%, val_best:  82.08%: 100%|██████████| 62/62 [00:24<00:00,  2.49it/s]\n",
      "epoch-59  lr=['0.0000069'], tr/val_loss:  0.002016/  1.731891, tr: 100.00%, val:  81.25%, val_best:  82.08%: 100%|██████████| 62/62 [00:20<00:00,  2.99it/s]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4eafdc0522864c4fa29c8f8c8ec3d82c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='4.142 MB of 4.142 MB uploaded (2.007 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "W&B sync reduced upload amount by 46.9%"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>DFA_flag</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>epoch</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇████</td></tr><tr><td>iter_acc</td><td>▁▄▅▇▆▅▆▆▇▇█▇████████████████████████████</td></tr><tr><td>summary_val_acc</td><td>▁▂▆▆▆▆▇▇▆▆▇▇▇▇██▇███████████████████████</td></tr><tr><td>tr_acc</td><td>▁▂▅▆▆▆▆▆▇▇▇▇▇███████████████████████████</td></tr><tr><td>tr_epoch_loss</td><td>▁█▅▄▄▃▃▃▃▃▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_acc_best</td><td>▁▂▆▆▇▇▇▇▇▇▇▇▇▇██████████████████████████</td></tr><tr><td>val_acc_now</td><td>▁▂▆▆▆▆▇▇▆▆▇▇▇▇██▇███████████████████████</td></tr><tr><td>val_loss</td><td>▁█▅▅▅▅▄▅▅▅▅▅▅▅▅▅▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>DFA_flag</td><td>0.0</td></tr><tr><td>epoch</td><td>59</td></tr><tr><td>iter_acc</td><td>1.0</td></tr><tr><td>tr_acc</td><td>1.0</td></tr><tr><td>tr_epoch_loss</td><td>0.00202</td></tr><tr><td>val_acc_best</td><td>0.82083</td></tr><tr><td>val_acc_now</td><td>0.8125</td></tr><tr><td>val_loss</td><td>1.73189</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">decent-sweep-1</strong> at: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/xeiqpmr5' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/xeiqpmr5</a><br/> View project at: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main</a><br/>Synced 7 W&B file(s), 0 media file(s), 12 artifact file(s) and 1 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20240822_170452-xeiqpmr5/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require(\"core\")`! See https://wandb.me/wandb-core for more information."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: x5hfxbka with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBATCH: 16\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tDFA_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tIMAGE_SIZE: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tOTTT_input_trace_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tOTTT_sWS_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tTIME: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcfg: ['M', 'M', 200, 200]\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tconst2: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdecay: 0.25\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdrop_rate: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdvs_clipping: 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdvs_duration: 100000\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \te_transport_swap: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \te_transport_swap_coin: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \te_transport_swap_tr: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepoch_num: 60\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \texclude_class: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.01\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_sg_width: 2.570969004857107\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_reset: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_threshold: 2.294718809915559\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmerge_polarities: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tscheduler_name: CosineAnnealingLR\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsurrogate: hard_sigmoid\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \twhich_data: DVS_GESTURE_TONIC\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.17.7 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.17.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/nfs/home/bhkim003/github_folder/ByeonghyeonKim/my_snn/wandb/run-20240822_172132-x5hfxbka</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/x5hfxbka' target=\"_blank\">deep-sweep-5</a></strong> to <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/yxynyr6h' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/yxynyr6h</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/yxynyr6h' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/yxynyr6h</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/x5hfxbka' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/x5hfxbka</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BATCH' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'IMAGE_SIZE' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'which_data' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_threshold' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_reset' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_sg_width' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'cfg' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'learning_rate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'epoch_num' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'surrogate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'scheduler_name' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'dvs_clipping' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'dvs_duration' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'OTTT_sWS_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'DFA_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'OTTT_input_trace_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'e_transport_swap' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'e_transport_swap_tr' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'e_transport_swap_coin' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'drop_rate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'exclude_class' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'merge_polarities' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'TIME' was locked by 'sweep' (ignored update).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset_hash = 2bbd58b4e0d3c1e9ad501fad8a43feed\n",
      "cache path exists\n",
      "\n",
      "we will exclude the 'other' class. dvsgestrue 10 classes' indices exist. \n",
      "\n",
      "DataParallel(\n",
      "  (module): MY_SNN_FC_sstep(\n",
      "    (layers): MY_Sequential(\n",
      "      (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (2): DimChanger_for_FC_sstep()\n",
      "      (3): SYNAPSE_FC_trace_sstep()\n",
      "      (4): LIF_layer_trace_sstep()\n",
      "      (5): SYNAPSE_FC_trace_sstep()\n",
      "      (6): LIF_layer_trace_sstep()\n",
      "      (7): SYNAPSE_FC_trace_sstep()\n",
      "    )\n",
      "  )\n",
      ")\n",
      "==================================================\n",
      "My Num of PARAMS: 452,010, system's param_num : 452,010\n",
      "Memory: 1.72MiB at 32-bit\n",
      "==================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch-0   lr=['0.0100000'], tr/val_loss:  2.317507/  2.316367, tr:   9.70%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:20<00:00,  3.01it/s]\n",
      "epoch-1   lr=['0.0099931'], tr/val_loss:  2.316254/  2.314931, tr:  10.21%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:17<00:00,  3.45it/s]\n",
      "epoch-2   lr=['0.0099726'], tr/val_loss:  2.315321/  2.315877, tr:   9.81%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:21<00:00,  2.89it/s]\n",
      "epoch-3   lr=['0.0099384'], tr/val_loss:  2.319123/  2.321801, tr:  10.42%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:22<00:00,  2.78it/s]\n",
      "epoch-4   lr=['0.0098907'], tr/val_loss:  2.328817/  2.310750, tr:   7.66%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:19<00:00,  3.13it/s]\n",
      "epoch-5   lr=['0.0098296'], tr/val_loss:  2.318780/  2.313111, tr:   8.58%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:19<00:00,  3.25it/s]\n",
      "epoch-6   lr=['0.0097553'], tr/val_loss:  2.326567/  2.312034, tr:   8.89%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:21<00:00,  2.86it/s]\n",
      "epoch-7   lr=['0.0096679'], tr/val_loss:  2.319906/  2.308871, tr:   8.89%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:21<00:00,  2.90it/s]\n",
      "epoch-8   lr=['0.0095677'], tr/val_loss:  2.315703/  2.318316, tr:   9.09%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:22<00:00,  2.75it/s]\n",
      "epoch-9   lr=['0.0094550'], tr/val_loss:  2.315776/  2.321137, tr:   9.81%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:21<00:00,  2.94it/s]\n",
      "epoch-10  lr=['0.0093301'], tr/val_loss:  2.319218/  2.310921, tr:   9.40%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:18<00:00,  3.27it/s]\n",
      "epoch-11  lr=['0.0091934'], tr/val_loss:  2.320658/  2.318817, tr:   9.60%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:06<00:00,  9.61it/s]\n",
      "epoch-12  lr=['0.0090451'], tr/val_loss:  2.323760/  2.306959, tr:   9.70%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:05<00:00, 10.65it/s]\n",
      "epoch-13  lr=['0.0088857'], tr/val_loss:  2.312257/  2.313825, tr:   8.78%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:05<00:00, 12.33it/s]\n",
      "epoch-14  lr=['0.0087157'], tr/val_loss:  2.321870/  2.310401, tr:   9.70%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:05<00:00, 12.39it/s]\n",
      "epoch-15  lr=['0.0085355'], tr/val_loss:  2.318407/  2.313874, tr:   9.60%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:05<00:00, 12.00it/s]\n",
      "epoch-16  lr=['0.0083457'], tr/val_loss:  2.317499/  2.312321, tr:  10.11%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:05<00:00, 11.87it/s]\n",
      "epoch-17  lr=['0.0081466'], tr/val_loss:  2.318669/  2.307941, tr:   8.89%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:04<00:00, 13.09it/s]\n",
      "epoch-18  lr=['0.0079389'], tr/val_loss:  2.325135/  2.306585, tr:   7.46%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:04<00:00, 12.47it/s]\n",
      "epoch-19  lr=['0.0077232'], tr/val_loss:  2.314244/  2.310251, tr:  10.01%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:05<00:00, 11.98it/s]\n",
      "epoch-20  lr=['0.0075000'], tr/val_loss:  2.312182/  2.307967, tr:   9.91%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:05<00:00, 11.91it/s]\n",
      "epoch-21  lr=['0.0072700'], tr/val_loss:  2.318818/  2.307295, tr:   9.30%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:06<00:00, 10.29it/s]\n",
      "epoch-22  lr=['0.0070337'], tr/val_loss:  2.313441/  2.307399, tr:   9.91%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:06<00:00,  9.90it/s]\n",
      "epoch-23  lr=['0.0067918'], tr/val_loss:  2.314248/  2.309416, tr:   7.76%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:06<00:00,  9.29it/s]\n",
      "epoch-24  lr=['0.0065451'], tr/val_loss:  2.318841/  2.305136, tr:   9.09%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:05<00:00, 11.03it/s]\n",
      "epoch-25  lr=['0.0062941'], tr/val_loss:  2.316903/  2.306750, tr:   7.97%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:06<00:00, 10.14it/s]\n",
      "epoch-26  lr=['0.0060396'], tr/val_loss:  2.311055/  2.305107, tr:   8.99%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:05<00:00, 10.62it/s]\n",
      "epoch-27  lr=['0.0057822'], tr/val_loss:  2.313828/  2.306802, tr:   8.58%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:05<00:00, 11.31it/s]\n",
      "epoch-28  lr=['0.0055226'], tr/val_loss:  2.315332/  2.308450, tr:   8.68%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:05<00:00, 10.38it/s]\n",
      "epoch-29  lr=['0.0052617'], tr/val_loss:  2.315842/  2.306032, tr:   7.15%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:06<00:00,  9.83it/s]\n",
      "epoch-30  lr=['0.0050000'], tr/val_loss:  2.312570/  2.303939, tr:   8.89%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:06<00:00,  9.54it/s]\n",
      "epoch-31  lr=['0.0047383'], tr/val_loss:  2.309263/  2.303903, tr:   9.09%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:05<00:00, 11.26it/s]\n",
      "epoch-32  lr=['0.0044774'], tr/val_loss:  2.311847/  2.302894, tr:   8.38%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:05<00:00, 10.42it/s]\n",
      "epoch-33  lr=['0.0042178'], tr/val_loss:  2.308722/  2.303530, tr:   9.50%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:06<00:00, 10.19it/s]\n",
      "epoch-34  lr=['0.0039604'], tr/val_loss:  2.313000/  2.304187, tr:   8.48%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:06<00:00, 10.10it/s]\n",
      "epoch-35  lr=['0.0037059'], tr/val_loss:  2.309877/  2.303538, tr:   9.09%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:06<00:00, 10.20it/s]\n",
      "epoch-36  lr=['0.0034549'], tr/val_loss:  2.309406/  2.303601, tr:   8.99%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:05<00:00, 11.02it/s]\n",
      "epoch-37  lr=['0.0032082'], tr/val_loss:  2.309686/  2.303400, tr:   7.66%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:06<00:00,  9.40it/s]\n",
      "epoch-38  lr=['0.0029663'], tr/val_loss:  2.308588/  2.303166, tr:   9.09%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:05<00:00, 10.92it/s]\n",
      "epoch-39  lr=['0.0027300'], tr/val_loss:  2.308727/  2.302884, tr:   8.89%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:05<00:00, 10.36it/s]\n",
      "epoch-40  lr=['0.0025000'], tr/val_loss:  2.308749/  2.302732, tr:   9.40%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:05<00:00, 10.78it/s]\n",
      "epoch-41  lr=['0.0022768'], tr/val_loss:  2.306803/  2.302942, tr:   9.19%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:06<00:00, 10.25it/s]\n",
      "epoch-42  lr=['0.0020611'], tr/val_loss:  2.306347/  2.302762, tr:   8.68%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:06<00:00, 10.08it/s]\n",
      "epoch-43  lr=['0.0018534'], tr/val_loss:  2.305991/  2.302857, tr:   8.99%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:05<00:00, 11.59it/s]\n",
      "epoch-44  lr=['0.0016543'], tr/val_loss:  2.305293/  2.302853, tr:  10.01%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:06<00:00, 10.29it/s]\n",
      "epoch-45  lr=['0.0014645'], tr/val_loss:  2.306396/  2.302847, tr:   8.48%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:06<00:00,  9.92it/s]\n",
      "epoch-46  lr=['0.0012843'], tr/val_loss:  2.305307/  2.302670, tr:  10.01%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:06<00:00,  9.93it/s]\n",
      "epoch-47  lr=['0.0011143'], tr/val_loss:  2.305197/  2.302644, tr:   9.30%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:05<00:00, 10.50it/s]\n",
      "epoch-48  lr=['0.0009549'], tr/val_loss:  2.304637/  2.302745, tr:   8.78%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:05<00:00, 11.07it/s]\n",
      "epoch-49  lr=['0.0008066'], tr/val_loss:  2.304113/  2.302645, tr:   8.89%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:05<00:00, 10.92it/s]\n",
      "epoch-50  lr=['0.0006699'], tr/val_loss:  2.304358/  2.302700, tr:   8.68%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:05<00:00, 10.67it/s]\n",
      "epoch-51  lr=['0.0005450'], tr/val_loss:  2.303610/  2.302717, tr:   9.81%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:05<00:00, 11.08it/s]\n",
      "epoch-52  lr=['0.0004323'], tr/val_loss:  2.303667/  2.302626, tr:   9.30%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:06<00:00, 10.08it/s]\n",
      "epoch-53  lr=['0.0003321'], tr/val_loss:  2.303300/  2.302634, tr:   9.19%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:06<00:00,  9.88it/s]\n",
      "epoch-54  lr=['0.0002447'], tr/val_loss:  2.303030/  2.302622, tr:   8.38%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:06<00:00,  9.18it/s]\n",
      "epoch-55  lr=['0.0001704'], tr/val_loss:  2.303107/  2.302625, tr:  10.01%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:05<00:00, 11.77it/s]\n",
      "epoch-56  lr=['0.0001093'], tr/val_loss:  2.302886/  2.302609, tr:  10.01%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:05<00:00, 11.32it/s]\n",
      "epoch-57  lr=['0.0000616'], tr/val_loss:  2.302670/  2.302610, tr:  10.01%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:06<00:00,  9.41it/s]\n",
      "epoch-58  lr=['0.0000274'], tr/val_loss:  2.302685/  2.302609, tr:  10.01%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:06<00:00, 10.22it/s]\n",
      "epoch-59  lr=['0.0000069'], tr/val_loss:  2.302528/  2.302609, tr:  10.01%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:05<00:00, 10.82it/s]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "925272a9e78b43b1985522b40c73ddeb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='4.380 MB of 4.380 MB uploaded (2.450 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "W&B sync reduced upload amount by 54.4%"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>DFA_flag</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>epoch</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇████</td></tr><tr><td>iter_acc</td><td>▁█▅▅▃▁▅█▆▃▆▅▃▃▁▃▃▃▁▁▁▁▆▅▁▃▁▅▃▅▃▅▃▃▅▅▁▃▅█</td></tr><tr><td>summary_val_acc</td><td>▁███████████████████████████████████████</td></tr><tr><td>tr_acc</td><td>▁███▇▇▇█▇███▇███▆▆▇▇▆▇▇▇▇▆▇▇▇▇██▇▇█▇▇███</td></tr><tr><td>tr_epoch_loss</td><td>▁███████████████████████████████████████</td></tr><tr><td>val_acc_best</td><td>▁███████████████████████████████████████</td></tr><tr><td>val_acc_now</td><td>▁███████████████████████████████████████</td></tr><tr><td>val_loss</td><td>▁███████████████████████████████████████</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>DFA_flag</td><td>0.0</td></tr><tr><td>epoch</td><td>59</td></tr><tr><td>iter_acc</td><td>0.33333</td></tr><tr><td>tr_acc</td><td>0.1001</td></tr><tr><td>tr_epoch_loss</td><td>2.30253</td></tr><tr><td>val_acc_best</td><td>0.1</td></tr><tr><td>val_acc_now</td><td>0.1</td></tr><tr><td>val_loss</td><td>2.30261</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">deep-sweep-5</strong> at: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/x5hfxbka' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/x5hfxbka</a><br/> View project at: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main</a><br/>Synced 7 W&B file(s), 0 media file(s), 14 artifact file(s) and 1 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20240822_172132-x5hfxbka/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require(\"core\")`! See https://wandb.me/wandb-core for more information."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: k750c825 with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBATCH: 16\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tDFA_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tIMAGE_SIZE: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tOTTT_input_trace_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tOTTT_sWS_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tTIME: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcfg: ['M', 'M', 200, 200]\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tconst2: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdecay: 0.25\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdrop_rate: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdvs_clipping: 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdvs_duration: 100000\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \te_transport_swap: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \te_transport_swap_coin: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \te_transport_swap_tr: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepoch_num: 60\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \texclude_class: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.01\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_sg_width: 2.570969004857107\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_reset: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_threshold: 0.5728755983116649\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmerge_polarities: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tscheduler_name: CosineAnnealingLR\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsurrogate: hard_sigmoid\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \twhich_data: DVS_GESTURE_TONIC\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.17.7 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.17.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/nfs/home/bhkim003/github_folder/ByeonghyeonKim/my_snn/wandb/run-20240822_173036-k750c825</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/k750c825' target=\"_blank\">charmed-sweep-8</a></strong> to <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/yxynyr6h' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/yxynyr6h</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/yxynyr6h' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/yxynyr6h</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/k750c825' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/k750c825</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BATCH' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'IMAGE_SIZE' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'which_data' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_threshold' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_reset' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_sg_width' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'cfg' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'learning_rate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'epoch_num' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'surrogate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'scheduler_name' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'dvs_clipping' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'dvs_duration' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'OTTT_sWS_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'DFA_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'OTTT_input_trace_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'e_transport_swap' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'e_transport_swap_tr' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'e_transport_swap_coin' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'drop_rate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'exclude_class' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'merge_polarities' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'TIME' was locked by 'sweep' (ignored update).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset_hash = 2bbd58b4e0d3c1e9ad501fad8a43feed\n",
      "cache path exists\n",
      "\n",
      "we will exclude the 'other' class. dvsgestrue 10 classes' indices exist. \n",
      "\n",
      "DataParallel(\n",
      "  (module): MY_SNN_FC_sstep(\n",
      "    (layers): MY_Sequential(\n",
      "      (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (2): DimChanger_for_FC_sstep()\n",
      "      (3): SYNAPSE_FC_trace_sstep()\n",
      "      (4): LIF_layer_trace_sstep()\n",
      "      (5): SYNAPSE_FC_trace_sstep()\n",
      "      (6): LIF_layer_trace_sstep()\n",
      "      (7): SYNAPSE_FC_trace_sstep()\n",
      "    )\n",
      "  )\n",
      ")\n",
      "==================================================\n",
      "My Num of PARAMS: 452,010, system's param_num : 452,010\n",
      "Memory: 1.72MiB at 32-bit\n",
      "==================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch-0   lr=['0.0100000'], tr/val_loss:  1.575868/  1.276310, tr:  45.56%, val:  56.67%, val_best:  56.67%: 100%|██████████| 62/62 [00:06<00:00, 10.14it/s]\n",
      "epoch-1   lr=['0.0099931'], tr/val_loss:  1.106101/  1.305547, tr:  60.37%, val:  54.17%, val_best:  56.67%: 100%|██████████| 62/62 [00:06<00:00,  9.84it/s]\n",
      "epoch-2   lr=['0.0099726'], tr/val_loss:  0.931158/  1.239807, tr:  65.37%, val:  58.75%, val_best:  58.75%: 100%|██████████| 62/62 [00:05<00:00, 10.75it/s]\n",
      "epoch-3   lr=['0.0099384'], tr/val_loss:  0.867546/  1.161727, tr:  69.87%, val:  61.67%, val_best:  61.67%: 100%|██████████| 62/62 [00:05<00:00, 10.56it/s]\n",
      "epoch-4   lr=['0.0098907'], tr/val_loss:  0.798340/  1.115372, tr:  70.68%, val:  64.17%, val_best:  64.17%: 100%|██████████| 62/62 [00:05<00:00, 10.60it/s]\n",
      "epoch-5   lr=['0.0098296'], tr/val_loss:  0.783373/  1.406623, tr:  71.20%, val:  61.25%, val_best:  64.17%: 100%|██████████| 62/62 [00:05<00:00, 10.82it/s]\n",
      "epoch-6   lr=['0.0097553'], tr/val_loss:  0.693603/  1.199136, tr:  72.73%, val:  61.67%, val_best:  64.17%: 100%|██████████| 62/62 [00:05<00:00, 10.46it/s]\n",
      "epoch-7   lr=['0.0096679'], tr/val_loss:  0.630177/  1.336745, tr:  76.40%, val:  59.17%, val_best:  64.17%: 100%|██████████| 62/62 [00:06<00:00, 10.04it/s]\n",
      "epoch-8   lr=['0.0095677'], tr/val_loss:  0.623871/  1.146978, tr:  75.89%, val:  67.50%, val_best:  67.50%: 100%|██████████| 62/62 [00:05<00:00, 10.75it/s]\n",
      "epoch-9   lr=['0.0094550'], tr/val_loss:  0.488528/  1.263507, tr:  83.45%, val:  67.08%, val_best:  67.50%: 100%|██████████| 62/62 [00:05<00:00, 10.83it/s]\n",
      "epoch-10  lr=['0.0093301'], tr/val_loss:  0.475900/  1.148418, tr:  85.90%, val:  70.42%, val_best:  70.42%: 100%|██████████| 62/62 [00:06<00:00,  9.62it/s]\n",
      "epoch-11  lr=['0.0091934'], tr/val_loss:  0.438707/  1.341795, tr:  84.68%, val:  65.00%, val_best:  70.42%: 100%|██████████| 62/62 [00:06<00:00,  9.58it/s]\n",
      "epoch-12  lr=['0.0090451'], tr/val_loss:  0.409887/  1.227274, tr:  89.58%, val:  74.58%, val_best:  74.58%: 100%|██████████| 62/62 [00:05<00:00, 10.84it/s]\n",
      "epoch-13  lr=['0.0088857'], tr/val_loss:  0.396468/  1.411512, tr:  89.38%, val:  67.92%, val_best:  74.58%: 100%|██████████| 62/62 [00:05<00:00, 10.36it/s]\n",
      "epoch-14  lr=['0.0087157'], tr/val_loss:  0.320016/  1.218685, tr:  93.16%, val:  75.83%, val_best:  75.83%: 100%|██████████| 62/62 [00:05<00:00, 11.12it/s]\n",
      "epoch-15  lr=['0.0085355'], tr/val_loss:  0.280341/  1.443146, tr:  95.20%, val:  71.67%, val_best:  75.83%: 100%|██████████| 62/62 [00:06<00:00, 10.11it/s]\n",
      "epoch-16  lr=['0.0083457'], tr/val_loss:  0.273414/  1.505575, tr:  94.79%, val:  75.42%, val_best:  75.83%: 100%|██████████| 62/62 [00:04<00:00, 12.65it/s]\n",
      "epoch-17  lr=['0.0081466'], tr/val_loss:  0.275907/  1.264093, tr:  94.89%, val:  76.25%, val_best:  76.25%: 100%|██████████| 62/62 [00:05<00:00, 11.70it/s]\n",
      "epoch-18  lr=['0.0079389'], tr/val_loss:  0.216068/  1.354679, tr:  96.32%, val:  75.00%, val_best:  76.25%: 100%|██████████| 62/62 [00:05<00:00, 11.50it/s]\n",
      "epoch-19  lr=['0.0077232'], tr/val_loss:  0.150729/  1.393103, tr:  98.98%, val:  75.83%, val_best:  76.25%: 100%|██████████| 62/62 [00:05<00:00, 11.87it/s]\n",
      "epoch-20  lr=['0.0075000'], tr/val_loss:  0.145953/  1.472992, tr:  98.98%, val:  75.83%, val_best:  76.25%: 100%|██████████| 62/62 [00:05<00:00, 11.90it/s]\n",
      "epoch-21  lr=['0.0072700'], tr/val_loss:  0.096294/  1.557995, tr:  99.90%, val:  75.00%, val_best:  76.25%: 100%|██████████| 62/62 [00:05<00:00, 11.99it/s]\n",
      "epoch-22  lr=['0.0070337'], tr/val_loss:  0.072568/  1.473750, tr:  99.39%, val:  80.00%, val_best:  80.00%: 100%|██████████| 62/62 [00:05<00:00, 12.06it/s]\n",
      "epoch-23  lr=['0.0067918'], tr/val_loss:  0.049217/  1.582783, tr: 100.00%, val:  74.17%, val_best:  80.00%: 100%|██████████| 62/62 [00:05<00:00, 12.09it/s]\n",
      "epoch-24  lr=['0.0065451'], tr/val_loss:  0.034821/  1.592729, tr: 100.00%, val:  78.33%, val_best:  80.00%: 100%|██████████| 62/62 [00:04<00:00, 12.53it/s]\n",
      "epoch-25  lr=['0.0062941'], tr/val_loss:  0.028246/  1.578416, tr: 100.00%, val:  78.75%, val_best:  80.00%: 100%|██████████| 62/62 [00:06<00:00,  9.62it/s]\n",
      "epoch-26  lr=['0.0060396'], tr/val_loss:  0.014903/  1.578668, tr: 100.00%, val:  77.08%, val_best:  80.00%: 100%|██████████| 62/62 [00:05<00:00, 10.48it/s]\n",
      "epoch-27  lr=['0.0057822'], tr/val_loss:  0.009419/  1.603749, tr: 100.00%, val:  77.08%, val_best:  80.00%: 100%|██████████| 62/62 [00:06<00:00, 10.24it/s]\n",
      "epoch-28  lr=['0.0055226'], tr/val_loss:  0.007786/  1.653895, tr: 100.00%, val:  78.75%, val_best:  80.00%: 100%|██████████| 62/62 [00:06<00:00,  9.79it/s]\n",
      "epoch-29  lr=['0.0052617'], tr/val_loss:  0.006484/  1.653954, tr: 100.00%, val:  78.75%, val_best:  80.00%: 100%|██████████| 62/62 [00:13<00:00,  4.45it/s]\n",
      "epoch-30  lr=['0.0050000'], tr/val_loss:  0.003882/  1.664349, tr: 100.00%, val:  78.33%, val_best:  80.00%: 100%|██████████| 62/62 [00:11<00:00,  5.32it/s]\n",
      "epoch-31  lr=['0.0047383'], tr/val_loss:  0.003201/  1.679179, tr: 100.00%, val:  77.50%, val_best:  80.00%: 100%|██████████| 62/62 [00:07<00:00,  8.69it/s]\n",
      "epoch-32  lr=['0.0044774'], tr/val_loss:  0.002908/  1.692226, tr: 100.00%, val:  78.33%, val_best:  80.00%: 100%|██████████| 62/62 [00:13<00:00,  4.63it/s]\n",
      "epoch-33  lr=['0.0042178'], tr/val_loss:  0.002646/  1.685768, tr: 100.00%, val:  77.50%, val_best:  80.00%: 100%|██████████| 62/62 [00:08<00:00,  6.98it/s]\n",
      "epoch-34  lr=['0.0039604'], tr/val_loss:  0.002575/  1.708066, tr: 100.00%, val:  77.50%, val_best:  80.00%: 100%|██████████| 62/62 [00:10<00:00,  6.19it/s]\n",
      "epoch-35  lr=['0.0037059'], tr/val_loss:  0.002224/  1.700232, tr: 100.00%, val:  77.08%, val_best:  80.00%: 100%|██████████| 62/62 [00:05<00:00, 11.00it/s]\n",
      "epoch-36  lr=['0.0034549'], tr/val_loss:  0.001985/  1.715592, tr: 100.00%, val:  77.08%, val_best:  80.00%: 100%|██████████| 62/62 [00:11<00:00,  5.49it/s]\n",
      "epoch-37  lr=['0.0032082'], tr/val_loss:  0.001891/  1.724970, tr: 100.00%, val:  77.50%, val_best:  80.00%: 100%|██████████| 62/62 [00:10<00:00,  6.12it/s]\n",
      "epoch-38  lr=['0.0029663'], tr/val_loss:  0.001734/  1.740343, tr: 100.00%, val:  78.75%, val_best:  80.00%: 100%|██████████| 62/62 [00:06<00:00,  9.50it/s]\n",
      "epoch-39  lr=['0.0027300'], tr/val_loss:  0.001696/  1.742114, tr: 100.00%, val:  79.17%, val_best:  80.00%: 100%|██████████| 62/62 [00:08<00:00,  7.41it/s]\n",
      "epoch-40  lr=['0.0025000'], tr/val_loss:  0.001664/  1.746824, tr: 100.00%, val:  77.92%, val_best:  80.00%: 100%|██████████| 62/62 [00:05<00:00, 11.08it/s]\n",
      "epoch-41  lr=['0.0022768'], tr/val_loss:  0.001571/  1.754580, tr: 100.00%, val:  78.33%, val_best:  80.00%: 100%|██████████| 62/62 [00:06<00:00, 10.25it/s]\n",
      "epoch-42  lr=['0.0020611'], tr/val_loss:  0.001520/  1.751501, tr: 100.00%, val:  78.75%, val_best:  80.00%: 100%|██████████| 62/62 [00:06<00:00,  9.37it/s]\n",
      "epoch-43  lr=['0.0018534'], tr/val_loss:  0.001509/  1.764419, tr: 100.00%, val:  78.75%, val_best:  80.00%: 100%|██████████| 62/62 [00:06<00:00,  9.85it/s]\n",
      "epoch-44  lr=['0.0016543'], tr/val_loss:  0.001502/  1.758895, tr: 100.00%, val:  78.75%, val_best:  80.00%: 100%|██████████| 62/62 [00:06<00:00, 10.25it/s]\n",
      "epoch-45  lr=['0.0014645'], tr/val_loss:  0.001511/  1.766034, tr: 100.00%, val:  78.33%, val_best:  80.00%: 100%|██████████| 62/62 [00:05<00:00, 10.39it/s]\n",
      "epoch-46  lr=['0.0012843'], tr/val_loss:  0.001482/  1.772489, tr: 100.00%, val:  78.33%, val_best:  80.00%: 100%|██████████| 62/62 [00:05<00:00, 10.64it/s]\n",
      "epoch-47  lr=['0.0011143'], tr/val_loss:  0.001447/  1.778670, tr: 100.00%, val:  78.33%, val_best:  80.00%: 100%|██████████| 62/62 [00:06<00:00, 10.05it/s]\n",
      "epoch-48  lr=['0.0009549'], tr/val_loss:  0.001408/  1.776255, tr: 100.00%, val:  78.33%, val_best:  80.00%: 100%|██████████| 62/62 [00:06<00:00,  9.73it/s]\n",
      "epoch-49  lr=['0.0008066'], tr/val_loss:  0.001409/  1.770477, tr: 100.00%, val:  78.75%, val_best:  80.00%: 100%|██████████| 62/62 [00:05<00:00, 11.61it/s]\n",
      "epoch-50  lr=['0.0006699'], tr/val_loss:  0.001401/  1.772841, tr: 100.00%, val:  78.33%, val_best:  80.00%: 100%|██████████| 62/62 [00:06<00:00, 10.21it/s]\n",
      "epoch-51  lr=['0.0005450'], tr/val_loss:  0.001389/  1.774684, tr: 100.00%, val:  78.33%, val_best:  80.00%: 100%|██████████| 62/62 [00:06<00:00,  9.81it/s]\n",
      "epoch-52  lr=['0.0004323'], tr/val_loss:  0.001375/  1.773278, tr: 100.00%, val:  78.33%, val_best:  80.00%: 100%|██████████| 62/62 [00:05<00:00, 10.93it/s]\n",
      "epoch-53  lr=['0.0003321'], tr/val_loss:  0.001382/  1.773838, tr: 100.00%, val:  77.92%, val_best:  80.00%: 100%|██████████| 62/62 [00:05<00:00, 10.47it/s]\n",
      "epoch-54  lr=['0.0002447'], tr/val_loss:  0.001398/  1.773624, tr: 100.00%, val:  78.33%, val_best:  80.00%: 100%|██████████| 62/62 [00:05<00:00, 10.53it/s]\n",
      "epoch-55  lr=['0.0001704'], tr/val_loss:  0.001357/  1.773424, tr: 100.00%, val:  78.33%, val_best:  80.00%: 100%|██████████| 62/62 [00:05<00:00, 11.41it/s]\n",
      "epoch-56  lr=['0.0001093'], tr/val_loss:  0.001361/  1.774157, tr: 100.00%, val:  78.33%, val_best:  80.00%: 100%|██████████| 62/62 [00:06<00:00,  9.67it/s]\n",
      "epoch-57  lr=['0.0000616'], tr/val_loss:  0.001363/  1.774214, tr: 100.00%, val:  78.33%, val_best:  80.00%: 100%|██████████| 62/62 [00:05<00:00, 10.41it/s]\n",
      "epoch-58  lr=['0.0000274'], tr/val_loss:  0.001349/  1.774146, tr: 100.00%, val:  78.33%, val_best:  80.00%: 100%|██████████| 62/62 [00:05<00:00, 10.40it/s]\n",
      "epoch-59  lr=['0.0000069'], tr/val_loss:  0.001351/  1.774151, tr: 100.00%, val:  78.33%, val_best:  80.00%: 100%|██████████| 62/62 [00:06<00:00, 10.26it/s]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "478fb159f36a4b3a89ec2d70e361d716",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='1.930 MB of 1.930 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>DFA_flag</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>epoch</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇████</td></tr><tr><td>iter_acc</td><td>▁▄▅▅▆▇▆▆▅▆▇▆▇███████████████████████████</td></tr><tr><td>summary_val_acc</td><td>▁▆▆▆▆▆▇▇▇███████▇███████████████████████</td></tr><tr><td>tr_acc</td><td>▁▄▆▆▆▆▆▇▇▇██████████████████████████████</td></tr><tr><td>tr_epoch_loss</td><td>▁█▅▅▄▄▄▃▃▃▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_acc_best</td><td>▁▆▆▆▇▇▇▇▇███████████████████████████████</td></tr><tr><td>val_acc_now</td><td>▁▆▆▆▆▆▇▇▇███████▇███████████████████████</td></tr><tr><td>val_loss</td><td>▁▆▆▆▇▆▆▆▆▆▆▇▆▆▇▇▇▇▇█████████████████████</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>DFA_flag</td><td>0.0</td></tr><tr><td>epoch</td><td>59</td></tr><tr><td>iter_acc</td><td>1.0</td></tr><tr><td>tr_acc</td><td>1.0</td></tr><tr><td>tr_epoch_loss</td><td>0.00135</td></tr><tr><td>val_acc_best</td><td>0.8</td></tr><tr><td>val_acc_now</td><td>0.78333</td></tr><tr><td>val_loss</td><td>1.77415</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">charmed-sweep-8</strong> at: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/k750c825' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/k750c825</a><br/> View project at: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main</a><br/>Synced 7 W&B file(s), 0 media file(s), 0 artifact file(s) and 1 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20240822_173036-k750c825/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require(\"core\")`! See https://wandb.me/wandb-core for more information."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: x7nb18tk with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBATCH: 16\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tDFA_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tIMAGE_SIZE: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tOTTT_input_trace_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tOTTT_sWS_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tTIME: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcfg: ['M', 'M', 200, 200]\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tconst2: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdecay: 0.25\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdrop_rate: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdvs_clipping: 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdvs_duration: 100000\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \te_transport_swap: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \te_transport_swap_coin: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \te_transport_swap_tr: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepoch_num: 60\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \texclude_class: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.01\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_sg_width: 2.570969004857107\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_reset: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_threshold: 0.24687642086309217\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmerge_polarities: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tscheduler_name: CosineAnnealingLR\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsurrogate: hard_sigmoid\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \twhich_data: DVS_GESTURE_TONIC\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.17.7 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.17.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/nfs/home/bhkim003/github_folder/ByeonghyeonKim/my_snn/wandb/run-20240822_173740-x7nb18tk</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/x7nb18tk' target=\"_blank\">robust-sweep-11</a></strong> to <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/yxynyr6h' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/yxynyr6h</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/yxynyr6h' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/yxynyr6h</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/x7nb18tk' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/x7nb18tk</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BATCH' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'IMAGE_SIZE' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'which_data' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_threshold' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_reset' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_sg_width' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'cfg' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'learning_rate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'epoch_num' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'surrogate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'scheduler_name' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'dvs_clipping' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'dvs_duration' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'OTTT_sWS_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'DFA_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'OTTT_input_trace_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'e_transport_swap' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'e_transport_swap_tr' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'e_transport_swap_coin' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'drop_rate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'exclude_class' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'merge_polarities' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'TIME' was locked by 'sweep' (ignored update).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset_hash = 2bbd58b4e0d3c1e9ad501fad8a43feed\n",
      "cache path exists\n",
      "\n",
      "we will exclude the 'other' class. dvsgestrue 10 classes' indices exist. \n",
      "\n",
      "DataParallel(\n",
      "  (module): MY_SNN_FC_sstep(\n",
      "    (layers): MY_Sequential(\n",
      "      (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (2): DimChanger_for_FC_sstep()\n",
      "      (3): SYNAPSE_FC_trace_sstep()\n",
      "      (4): LIF_layer_trace_sstep()\n",
      "      (5): SYNAPSE_FC_trace_sstep()\n",
      "      (6): LIF_layer_trace_sstep()\n",
      "      (7): SYNAPSE_FC_trace_sstep()\n",
      "    )\n",
      "  )\n",
      ")\n",
      "==================================================\n",
      "My Num of PARAMS: 452,010, system's param_num : 452,010\n",
      "Memory: 1.72MiB at 32-bit\n",
      "==================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch-0   lr=['0.0100000'], tr/val_loss:  1.511805/  1.348163, tr:  48.42%, val:  44.58%, val_best:  44.58%: 100%|██████████| 62/62 [00:06<00:00, 10.24it/s]\n",
      "epoch-1   lr=['0.0099931'], tr/val_loss:  1.109950/  1.419556, tr:  59.65%, val:  51.67%, val_best:  51.67%: 100%|██████████| 62/62 [00:06<00:00,  9.18it/s]\n",
      "epoch-2   lr=['0.0099726'], tr/val_loss:  0.959100/  1.237607, tr:  64.04%, val:  62.08%, val_best:  62.08%: 100%|██████████| 62/62 [00:06<00:00, 10.25it/s]\n",
      "epoch-3   lr=['0.0099384'], tr/val_loss:  0.839381/  1.110159, tr:  69.15%, val:  61.25%, val_best:  62.08%: 100%|██████████| 62/62 [00:06<00:00,  9.80it/s]\n",
      "epoch-4   lr=['0.0098907'], tr/val_loss:  0.798694/  1.225100, tr:  71.20%, val:  57.92%, val_best:  62.08%: 100%|██████████| 62/62 [00:05<00:00, 10.60it/s]\n",
      "epoch-5   lr=['0.0098296'], tr/val_loss:  0.761208/  1.329064, tr:  71.50%, val:  59.17%, val_best:  62.08%: 100%|██████████| 62/62 [00:05<00:00, 11.15it/s]\n",
      "epoch-6   lr=['0.0097553'], tr/val_loss:  0.673288/  1.318335, tr:  73.03%, val:  54.17%, val_best:  62.08%: 100%|██████████| 62/62 [00:05<00:00, 10.80it/s]\n",
      "epoch-7   lr=['0.0096679'], tr/val_loss:  0.671119/  1.325241, tr:  73.24%, val:  57.92%, val_best:  62.08%: 100%|██████████| 62/62 [00:05<00:00, 10.70it/s]\n",
      "epoch-8   lr=['0.0095677'], tr/val_loss:  0.623506/  1.183050, tr:  75.38%, val:  67.50%, val_best:  67.50%: 100%|██████████| 62/62 [00:06<00:00,  9.64it/s]\n",
      "epoch-9   lr=['0.0094550'], tr/val_loss:  0.485889/  1.347332, tr:  82.02%, val:  63.33%, val_best:  67.50%: 100%|██████████| 62/62 [00:05<00:00, 11.39it/s]\n",
      "epoch-10  lr=['0.0093301'], tr/val_loss:  0.486246/  1.106354, tr:  82.02%, val:  75.00%, val_best:  75.00%: 100%|██████████| 62/62 [00:05<00:00, 10.88it/s]\n",
      "epoch-11  lr=['0.0091934'], tr/val_loss:  0.467623/  1.403801, tr:  81.82%, val:  61.67%, val_best:  75.00%: 100%|██████████| 62/62 [00:05<00:00, 10.37it/s]\n",
      "epoch-12  lr=['0.0090451'], tr/val_loss:  0.491462/  1.310549, tr:  83.76%, val:  70.42%, val_best:  75.00%: 100%|██████████| 62/62 [00:06<00:00,  9.73it/s]\n",
      "epoch-13  lr=['0.0088857'], tr/val_loss:  0.393821/  1.255019, tr:  88.46%, val:  70.42%, val_best:  75.00%: 100%|██████████| 62/62 [00:06<00:00,  9.58it/s]\n",
      "epoch-14  lr=['0.0087157'], tr/val_loss:  0.322029/  1.183251, tr:  91.93%, val:  71.25%, val_best:  75.00%: 100%|██████████| 62/62 [00:06<00:00,  9.46it/s]\n",
      "epoch-15  lr=['0.0085355'], tr/val_loss:  0.307476/  1.375320, tr:  92.13%, val:  71.25%, val_best:  75.00%: 100%|██████████| 62/62 [00:05<00:00, 10.84it/s]\n",
      "epoch-16  lr=['0.0083457'], tr/val_loss:  0.285501/  1.431671, tr:  94.59%, val:  73.33%, val_best:  75.00%: 100%|██████████| 62/62 [00:06<00:00,  9.27it/s]\n",
      "epoch-17  lr=['0.0081466'], tr/val_loss:  0.274693/  1.320283, tr:  93.97%, val:  69.17%, val_best:  75.00%: 100%|██████████| 62/62 [00:05<00:00, 11.74it/s]\n",
      "epoch-18  lr=['0.0079389'], tr/val_loss:  0.250677/  1.348367, tr:  94.48%, val:  74.58%, val_best:  75.00%: 100%|██████████| 62/62 [00:05<00:00, 11.62it/s]\n",
      "epoch-19  lr=['0.0077232'], tr/val_loss:  0.186273/  1.438579, tr:  98.47%, val:  72.50%, val_best:  75.00%: 100%|██████████| 62/62 [00:05<00:00, 11.11it/s]\n",
      "epoch-20  lr=['0.0075000'], tr/val_loss:  0.143151/  1.328066, tr:  98.37%, val:  78.33%, val_best:  78.33%: 100%|██████████| 62/62 [00:05<00:00, 12.22it/s]\n",
      "epoch-21  lr=['0.0072700'], tr/val_loss:  0.118543/  1.561898, tr:  99.49%, val:  74.17%, val_best:  78.33%: 100%|██████████| 62/62 [00:05<00:00, 11.24it/s]\n",
      "epoch-22  lr=['0.0070337'], tr/val_loss:  0.104912/  1.455270, tr:  98.88%, val:  78.75%, val_best:  78.75%: 100%|██████████| 62/62 [00:05<00:00, 11.03it/s]\n",
      "epoch-23  lr=['0.0067918'], tr/val_loss:  0.069984/  1.562762, tr: 100.00%, val:  75.83%, val_best:  78.75%: 100%|██████████| 62/62 [00:05<00:00, 11.31it/s]\n",
      "epoch-24  lr=['0.0065451'], tr/val_loss:  0.048704/  1.642312, tr: 100.00%, val:  75.00%, val_best:  78.75%: 100%|██████████| 62/62 [00:05<00:00, 11.49it/s]\n",
      "epoch-25  lr=['0.0062941'], tr/val_loss:  0.042856/  1.576948, tr:  99.90%, val:  77.92%, val_best:  78.75%: 100%|██████████| 62/62 [00:05<00:00, 11.77it/s]\n",
      "epoch-26  lr=['0.0060396'], tr/val_loss:  0.022415/  1.595591, tr: 100.00%, val:  77.08%, val_best:  78.75%: 100%|██████████| 62/62 [00:05<00:00, 10.85it/s]\n",
      "epoch-27  lr=['0.0057822'], tr/val_loss:  0.013211/  1.638125, tr: 100.00%, val:  78.75%, val_best:  78.75%: 100%|██████████| 62/62 [00:06<00:00,  9.63it/s]\n",
      "epoch-28  lr=['0.0055226'], tr/val_loss:  0.018199/  1.642392, tr: 100.00%, val:  79.17%, val_best:  79.17%: 100%|██████████| 62/62 [00:05<00:00, 10.99it/s]\n",
      "epoch-29  lr=['0.0052617'], tr/val_loss:  0.012419/  1.641376, tr: 100.00%, val:  78.33%, val_best:  79.17%: 100%|██████████| 62/62 [00:05<00:00, 10.77it/s]\n",
      "epoch-30  lr=['0.0050000'], tr/val_loss:  0.005980/  1.652697, tr: 100.00%, val:  78.75%, val_best:  79.17%: 100%|██████████| 62/62 [00:05<00:00, 10.89it/s]\n",
      "epoch-31  lr=['0.0047383'], tr/val_loss:  0.003834/  1.658843, tr: 100.00%, val:  80.00%, val_best:  80.00%: 100%|██████████| 62/62 [00:06<00:00, 10.09it/s]\n",
      "epoch-32  lr=['0.0044774'], tr/val_loss:  0.003072/  1.650225, tr: 100.00%, val:  80.83%, val_best:  80.83%: 100%|██████████| 62/62 [00:05<00:00, 10.91it/s]\n",
      "epoch-33  lr=['0.0042178'], tr/val_loss:  0.002923/  1.669776, tr: 100.00%, val:  81.67%, val_best:  81.67%: 100%|██████████| 62/62 [00:05<00:00, 10.59it/s]\n",
      "epoch-34  lr=['0.0039604'], tr/val_loss:  0.002564/  1.680263, tr: 100.00%, val:  82.50%, val_best:  82.50%: 100%|██████████| 62/62 [00:06<00:00, 10.32it/s]\n",
      "epoch-35  lr=['0.0037059'], tr/val_loss:  0.002222/  1.682053, tr: 100.00%, val:  82.50%, val_best:  82.50%: 100%|██████████| 62/62 [00:05<00:00, 10.61it/s]\n",
      "epoch-36  lr=['0.0034549'], tr/val_loss:  0.002089/  1.679384, tr: 100.00%, val:  82.08%, val_best:  82.50%: 100%|██████████| 62/62 [00:05<00:00, 10.98it/s]\n",
      "epoch-37  lr=['0.0032082'], tr/val_loss:  0.001924/  1.687294, tr: 100.00%, val:  82.08%, val_best:  82.50%: 100%|██████████| 62/62 [00:06<00:00,  9.42it/s]\n",
      "epoch-38  lr=['0.0029663'], tr/val_loss:  0.001862/  1.690903, tr: 100.00%, val:  82.08%, val_best:  82.50%: 100%|██████████| 62/62 [00:06<00:00,  9.17it/s]\n",
      "epoch-39  lr=['0.0027300'], tr/val_loss:  0.001809/  1.699046, tr: 100.00%, val:  82.08%, val_best:  82.50%: 100%|██████████| 62/62 [00:06<00:00,  9.85it/s]\n",
      "epoch-40  lr=['0.0025000'], tr/val_loss:  0.001728/  1.702514, tr: 100.00%, val:  81.67%, val_best:  82.50%: 100%|██████████| 62/62 [00:06<00:00,  9.47it/s]\n",
      "epoch-41  lr=['0.0022768'], tr/val_loss:  0.001638/  1.695789, tr: 100.00%, val:  82.08%, val_best:  82.50%: 100%|██████████| 62/62 [00:05<00:00, 10.47it/s]\n",
      "epoch-42  lr=['0.0020611'], tr/val_loss:  0.001564/  1.694128, tr: 100.00%, val:  81.67%, val_best:  82.50%: 100%|██████████| 62/62 [00:06<00:00,  9.85it/s]\n",
      "epoch-43  lr=['0.0018534'], tr/val_loss:  0.001560/  1.700274, tr: 100.00%, val:  81.25%, val_best:  82.50%: 100%|██████████| 62/62 [00:06<00:00,  9.15it/s]\n",
      "epoch-44  lr=['0.0016543'], tr/val_loss:  0.001477/  1.696323, tr: 100.00%, val:  81.67%, val_best:  82.50%: 100%|██████████| 62/62 [00:05<00:00, 10.74it/s]\n",
      "epoch-45  lr=['0.0014645'], tr/val_loss:  0.001466/  1.696355, tr: 100.00%, val:  81.25%, val_best:  82.50%: 100%|██████████| 62/62 [00:06<00:00,  9.94it/s]\n",
      "epoch-46  lr=['0.0012843'], tr/val_loss:  0.001435/  1.701014, tr: 100.00%, val:  81.67%, val_best:  82.50%: 100%|██████████| 62/62 [00:06<00:00, 10.31it/s]\n",
      "epoch-47  lr=['0.0011143'], tr/val_loss:  0.001413/  1.703986, tr: 100.00%, val:  81.67%, val_best:  82.50%: 100%|██████████| 62/62 [00:05<00:00, 10.95it/s]\n",
      "epoch-48  lr=['0.0009549'], tr/val_loss:  0.001373/  1.708286, tr: 100.00%, val:  81.25%, val_best:  82.50%: 100%|██████████| 62/62 [00:06<00:00, 10.25it/s]\n",
      "epoch-49  lr=['0.0008066'], tr/val_loss:  0.001365/  1.708433, tr: 100.00%, val:  81.67%, val_best:  82.50%: 100%|██████████| 62/62 [00:06<00:00, 10.07it/s]\n",
      "epoch-50  lr=['0.0006699'], tr/val_loss:  0.001373/  1.705946, tr: 100.00%, val:  82.08%, val_best:  82.50%: 100%|██████████| 62/62 [00:06<00:00, 10.09it/s]\n",
      "epoch-51  lr=['0.0005450'], tr/val_loss:  0.001353/  1.705631, tr: 100.00%, val:  81.67%, val_best:  82.50%: 100%|██████████| 62/62 [00:05<00:00, 10.39it/s]\n",
      "epoch-52  lr=['0.0004323'], tr/val_loss:  0.001332/  1.708729, tr: 100.00%, val:  81.67%, val_best:  82.50%: 100%|██████████| 62/62 [00:06<00:00,  8.89it/s]\n",
      "epoch-53  lr=['0.0003321'], tr/val_loss:  0.001328/  1.709473, tr: 100.00%, val:  81.67%, val_best:  82.50%: 100%|██████████| 62/62 [00:05<00:00, 10.53it/s]\n",
      "epoch-54  lr=['0.0002447'], tr/val_loss:  0.001348/  1.712938, tr: 100.00%, val:  81.67%, val_best:  82.50%: 100%|██████████| 62/62 [00:06<00:00, 10.03it/s]\n",
      "epoch-55  lr=['0.0001704'], tr/val_loss:  0.001322/  1.712000, tr: 100.00%, val:  82.08%, val_best:  82.50%: 100%|██████████| 62/62 [00:06<00:00,  9.71it/s]\n",
      "epoch-56  lr=['0.0001093'], tr/val_loss:  0.001305/  1.712627, tr: 100.00%, val:  81.67%, val_best:  82.50%: 100%|██████████| 62/62 [00:05<00:00, 10.49it/s]\n",
      "epoch-57  lr=['0.0000616'], tr/val_loss:  0.001345/  1.713253, tr: 100.00%, val:  81.67%, val_best:  82.50%: 100%|██████████| 62/62 [00:06<00:00,  9.26it/s]\n",
      "epoch-58  lr=['0.0000274'], tr/val_loss:  0.001301/  1.713215, tr: 100.00%, val:  81.67%, val_best:  82.50%: 100%|██████████| 62/62 [00:06<00:00,  9.70it/s]\n",
      "epoch-59  lr=['0.0000069'], tr/val_loss:  0.001304/  1.713221, tr: 100.00%, val:  81.67%, val_best:  82.50%: 100%|██████████| 62/62 [00:07<00:00,  8.31it/s]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a80adbcb6ccd469b82d614b8f22f68bd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='1.937 MB of 1.937 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>DFA_flag</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>epoch</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇████</td></tr><tr><td>iter_acc</td><td>▂▁▃▁▅▅▃▃▅▅█▇▇███████████████████████████</td></tr><tr><td>summary_val_acc</td><td>▁▅▆▆▆▆▇▆▆▇▇▇▇▇██▇███████████████████████</td></tr><tr><td>tr_acc</td><td>▁▄▅▆▆▆▆▇▇▇▇█████████████████████████████</td></tr><tr><td>tr_epoch_loss</td><td>▁█▅▅▅▄▄▃▃▃▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_acc_best</td><td>▁▅▆▆▆▆▇▇▇▇▇▇▇▇██████████████████████████</td></tr><tr><td>val_acc_now</td><td>▁▅▆▆▆▆▇▆▆▇▇▇▇▇██▇███████████████████████</td></tr><tr><td>val_loss</td><td>▁▇▆▆▆▆▆▇▇▆▆▇▆▇▆▇▇▇██████████████████████</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>DFA_flag</td><td>0.0</td></tr><tr><td>epoch</td><td>59</td></tr><tr><td>iter_acc</td><td>1.0</td></tr><tr><td>tr_acc</td><td>1.0</td></tr><tr><td>tr_epoch_loss</td><td>0.0013</td></tr><tr><td>val_acc_best</td><td>0.825</td></tr><tr><td>val_acc_now</td><td>0.81667</td></tr><tr><td>val_loss</td><td>1.71322</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">robust-sweep-11</strong> at: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/x7nb18tk' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/x7nb18tk</a><br/> View project at: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main</a><br/>Synced 7 W&B file(s), 0 media file(s), 0 artifact file(s) and 1 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20240822_173740-x7nb18tk/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require(\"core\")`! See https://wandb.me/wandb-core for more information."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 7w89ebdk with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBATCH: 16\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tDFA_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tIMAGE_SIZE: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tOTTT_input_trace_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tOTTT_sWS_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tTIME: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcfg: ['M', 'M', 200, 200]\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tconst2: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdecay: 0.25\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdrop_rate: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdvs_clipping: 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdvs_duration: 100000\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \te_transport_swap: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \te_transport_swap_coin: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \te_transport_swap_tr: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepoch_num: 60\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \texclude_class: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.01\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_sg_width: 2.570969004857107\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_reset: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_threshold: 1.5029824165687162\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmerge_polarities: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tscheduler_name: CosineAnnealingLR\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsurrogate: hard_sigmoid\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \twhich_data: DVS_GESTURE_TONIC\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.17.7 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.17.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/nfs/home/bhkim003/github_folder/ByeonghyeonKim/my_snn/wandb/run-20240822_174415-7w89ebdk</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/7w89ebdk' target=\"_blank\">super-sweep-14</a></strong> to <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/yxynyr6h' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/yxynyr6h</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/yxynyr6h' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/yxynyr6h</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/7w89ebdk' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/7w89ebdk</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BATCH' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'IMAGE_SIZE' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'which_data' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_threshold' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_reset' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_sg_width' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'cfg' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'learning_rate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'epoch_num' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'surrogate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'scheduler_name' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'dvs_clipping' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'dvs_duration' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'OTTT_sWS_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'DFA_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'OTTT_input_trace_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'e_transport_swap' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'e_transport_swap_tr' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'e_transport_swap_coin' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'drop_rate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'exclude_class' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'merge_polarities' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'TIME' was locked by 'sweep' (ignored update).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset_hash = 2bbd58b4e0d3c1e9ad501fad8a43feed\n",
      "cache path exists\n",
      "\n",
      "we will exclude the 'other' class. dvsgestrue 10 classes' indices exist. \n",
      "\n",
      "DataParallel(\n",
      "  (module): MY_SNN_FC_sstep(\n",
      "    (layers): MY_Sequential(\n",
      "      (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (2): DimChanger_for_FC_sstep()\n",
      "      (3): SYNAPSE_FC_trace_sstep()\n",
      "      (4): LIF_layer_trace_sstep()\n",
      "      (5): SYNAPSE_FC_trace_sstep()\n",
      "      (6): LIF_layer_trace_sstep()\n",
      "      (7): SYNAPSE_FC_trace_sstep()\n",
      "    )\n",
      "  )\n",
      ")\n",
      "==================================================\n",
      "My Num of PARAMS: 452,010, system's param_num : 452,010\n",
      "Memory: 1.72MiB at 32-bit\n",
      "==================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch-0   lr=['0.0100000'], tr/val_loss:  2.317507/  2.316367, tr:   9.70%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:07<00:00,  8.48it/s]\n",
      "epoch-1   lr=['0.0099931'], tr/val_loss:  2.316254/  2.314931, tr:  10.21%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:05<00:00, 10.74it/s]\n",
      "epoch-2   lr=['0.0099726'], tr/val_loss:  2.315321/  2.315877, tr:   9.81%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:05<00:00, 10.95it/s]\n",
      "epoch-3   lr=['0.0099384'], tr/val_loss:  2.319123/  2.321801, tr:  10.42%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:06<00:00,  9.74it/s]\n",
      "epoch-4   lr=['0.0098907'], tr/val_loss:  2.328817/  2.310750, tr:   7.66%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:06<00:00, 10.25it/s]\n",
      "epoch-5   lr=['0.0098296'], tr/val_loss:  2.318780/  2.313111, tr:   8.58%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:06<00:00,  9.28it/s]\n",
      "epoch-6   lr=['0.0097553'], tr/val_loss:  2.326567/  2.312034, tr:   8.89%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:05<00:00, 10.67it/s]\n",
      "epoch-7   lr=['0.0096679'], tr/val_loss:  2.319906/  2.308871, tr:   8.89%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:05<00:00, 10.69it/s]\n",
      "epoch-8   lr=['0.0095677'], tr/val_loss:  2.315703/  2.318316, tr:   9.09%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:06<00:00,  9.21it/s]\n",
      "epoch-9   lr=['0.0094550'], tr/val_loss:  2.315776/  2.321137, tr:   9.81%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:05<00:00, 10.54it/s]\n",
      "epoch-10  lr=['0.0093301'], tr/val_loss:  2.319218/  2.310921, tr:   9.40%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:06<00:00,  8.88it/s]\n",
      "epoch-11  lr=['0.0091934'], tr/val_loss:  2.320658/  2.318817, tr:   9.60%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:05<00:00, 10.69it/s]\n",
      "epoch-12  lr=['0.0090451'], tr/val_loss:  2.323760/  2.306959, tr:   9.70%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:05<00:00, 10.47it/s]\n",
      "epoch-13  lr=['0.0088857'], tr/val_loss:  2.312257/  2.313825, tr:   8.78%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:05<00:00, 10.97it/s]\n",
      "epoch-14  lr=['0.0087157'], tr/val_loss:  2.321870/  2.310401, tr:   9.70%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:06<00:00,  9.84it/s]\n",
      "epoch-15  lr=['0.0085355'], tr/val_loss:  2.318407/  2.313874, tr:   9.60%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:06<00:00, 10.33it/s]\n",
      "epoch-16  lr=['0.0083457'], tr/val_loss:  2.317499/  2.312321, tr:  10.11%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:05<00:00, 12.37it/s]\n",
      "epoch-17  lr=['0.0081466'], tr/val_loss:  2.318669/  2.307941, tr:   8.89%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:05<00:00, 11.63it/s]\n",
      "epoch-18  lr=['0.0079389'], tr/val_loss:  2.325135/  2.306585, tr:   7.46%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:05<00:00, 11.57it/s]\n",
      "epoch-19  lr=['0.0077232'], tr/val_loss:  2.314244/  2.310251, tr:  10.01%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:05<00:00, 12.04it/s]\n",
      "epoch-20  lr=['0.0075000'], tr/val_loss:  2.312182/  2.307967, tr:   9.91%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:06<00:00, 10.13it/s]\n",
      "epoch-21  lr=['0.0072700'], tr/val_loss:  2.318818/  2.307295, tr:   9.30%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:05<00:00, 10.34it/s]\n",
      "epoch-22  lr=['0.0070337'], tr/val_loss:  2.313441/  2.307399, tr:   9.91%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:06<00:00,  9.91it/s]\n",
      "epoch-23  lr=['0.0067918'], tr/val_loss:  2.314248/  2.309416, tr:   7.76%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:05<00:00, 12.24it/s]\n",
      "epoch-24  lr=['0.0065451'], tr/val_loss:  2.318841/  2.305136, tr:   9.09%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:05<00:00, 11.82it/s]\n",
      "epoch-25  lr=['0.0062941'], tr/val_loss:  2.316903/  2.306750, tr:   7.97%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:05<00:00, 11.75it/s]\n",
      "epoch-26  lr=['0.0060396'], tr/val_loss:  2.311055/  2.305107, tr:   8.99%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:05<00:00, 11.36it/s]\n",
      "epoch-27  lr=['0.0057822'], tr/val_loss:  2.313828/  2.306802, tr:   8.58%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:06<00:00,  9.99it/s]\n",
      "epoch-28  lr=['0.0055226'], tr/val_loss:  2.315332/  2.308450, tr:   8.68%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:05<00:00, 10.34it/s]\n",
      "epoch-29  lr=['0.0052617'], tr/val_loss:  2.315842/  2.306032, tr:   7.15%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:06<00:00,  9.83it/s]\n",
      "epoch-30  lr=['0.0050000'], tr/val_loss:  2.312570/  2.303939, tr:   8.89%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:05<00:00, 10.90it/s]\n",
      "epoch-31  lr=['0.0047383'], tr/val_loss:  2.309263/  2.303903, tr:   9.09%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:05<00:00, 10.87it/s]\n",
      "epoch-32  lr=['0.0044774'], tr/val_loss:  2.311847/  2.302894, tr:   8.38%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:06<00:00,  9.42it/s]\n",
      "epoch-33  lr=['0.0042178'], tr/val_loss:  2.308722/  2.303530, tr:   9.50%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:05<00:00, 10.61it/s]\n",
      "epoch-34  lr=['0.0039604'], tr/val_loss:  2.313000/  2.304187, tr:   8.48%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:05<00:00, 10.84it/s]\n",
      "epoch-35  lr=['0.0037059'], tr/val_loss:  2.309877/  2.303538, tr:   9.09%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:06<00:00,  9.24it/s]\n",
      "epoch-36  lr=['0.0034549'], tr/val_loss:  2.309406/  2.303601, tr:   8.99%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:05<00:00, 11.51it/s]\n",
      "epoch-37  lr=['0.0032082'], tr/val_loss:  2.309686/  2.303400, tr:   7.66%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:06<00:00, 10.26it/s]\n",
      "epoch-38  lr=['0.0029663'], tr/val_loss:  2.308588/  2.303166, tr:   9.09%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:06<00:00,  9.43it/s]\n",
      "epoch-39  lr=['0.0027300'], tr/val_loss:  2.308727/  2.302884, tr:   8.89%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:05<00:00, 11.21it/s]\n",
      "epoch-40  lr=['0.0025000'], tr/val_loss:  2.308749/  2.302732, tr:   9.40%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:05<00:00, 10.85it/s]\n",
      "epoch-41  lr=['0.0022768'], tr/val_loss:  2.306803/  2.302942, tr:   9.19%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:06<00:00, 10.21it/s]\n",
      "epoch-42  lr=['0.0020611'], tr/val_loss:  2.306347/  2.302762, tr:   8.68%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:05<00:00, 10.50it/s]\n",
      "epoch-43  lr=['0.0018534'], tr/val_loss:  2.305991/  2.302857, tr:   8.99%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:06<00:00, 10.32it/s]\n",
      "epoch-44  lr=['0.0016543'], tr/val_loss:  2.305293/  2.302853, tr:  10.01%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:06<00:00,  9.82it/s]\n",
      "epoch-45  lr=['0.0014645'], tr/val_loss:  2.306396/  2.302847, tr:   8.48%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:06<00:00,  8.95it/s]\n",
      "epoch-46  lr=['0.0012843'], tr/val_loss:  2.305307/  2.302670, tr:  10.01%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:06<00:00,  9.72it/s]\n",
      "epoch-47  lr=['0.0011143'], tr/val_loss:  2.305197/  2.302644, tr:   9.30%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:06<00:00,  9.82it/s]\n",
      "epoch-48  lr=['0.0009549'], tr/val_loss:  2.304637/  2.302745, tr:   8.78%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:06<00:00,  9.95it/s]\n",
      "epoch-49  lr=['0.0008066'], tr/val_loss:  2.304113/  2.302645, tr:   8.89%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:06<00:00, 10.12it/s]\n",
      "epoch-50  lr=['0.0006699'], tr/val_loss:  2.304358/  2.302700, tr:   8.68%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:05<00:00, 10.69it/s]\n",
      "epoch-51  lr=['0.0005450'], tr/val_loss:  2.303610/  2.302717, tr:   9.81%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:06<00:00,  9.58it/s]\n",
      "epoch-52  lr=['0.0004323'], tr/val_loss:  2.303667/  2.302626, tr:   9.30%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:06<00:00,  9.22it/s]\n",
      "epoch-53  lr=['0.0003321'], tr/val_loss:  2.303300/  2.302634, tr:   9.19%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:05<00:00, 10.37it/s]\n",
      "epoch-54  lr=['0.0002447'], tr/val_loss:  2.303030/  2.302622, tr:   8.38%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:06<00:00,  9.70it/s]\n",
      "epoch-55  lr=['0.0001704'], tr/val_loss:  2.303107/  2.302625, tr:  10.01%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:05<00:00, 11.06it/s]\n",
      "epoch-56  lr=['0.0001093'], tr/val_loss:  2.302886/  2.302609, tr:  10.01%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:06<00:00,  9.67it/s]\n",
      "epoch-57  lr=['0.0000616'], tr/val_loss:  2.302670/  2.302610, tr:  10.01%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:06<00:00,  9.17it/s]\n",
      "epoch-58  lr=['0.0000274'], tr/val_loss:  2.302685/  2.302609, tr:  10.01%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:05<00:00, 10.37it/s]\n",
      "epoch-59  lr=['0.0000069'], tr/val_loss:  2.302528/  2.302609, tr:  10.01%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:06<00:00,  9.50it/s]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d00f657e1e4f4a21a124849d26c2df97",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='1.937 MB of 1.937 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>DFA_flag</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>epoch</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇████</td></tr><tr><td>iter_acc</td><td>▁█▅▅▃▁▅█▆▃▆▅▃▃▁▃▃▃▁▁▁▁▆▅▁▃▁▅▃▅▃▅▃▃▅▅▁▃▅█</td></tr><tr><td>summary_val_acc</td><td>▁███████████████████████████████████████</td></tr><tr><td>tr_acc</td><td>▁███▇▇▇█▇███▇███▆▆▇▇▆▇▇▇▇▆▇▇▇▇██▇▇█▇▇███</td></tr><tr><td>tr_epoch_loss</td><td>▁███████████████████████████████████████</td></tr><tr><td>val_acc_best</td><td>▁███████████████████████████████████████</td></tr><tr><td>val_acc_now</td><td>▁███████████████████████████████████████</td></tr><tr><td>val_loss</td><td>▁███████████████████████████████████████</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>DFA_flag</td><td>0.0</td></tr><tr><td>epoch</td><td>59</td></tr><tr><td>iter_acc</td><td>0.33333</td></tr><tr><td>tr_acc</td><td>0.1001</td></tr><tr><td>tr_epoch_loss</td><td>2.30253</td></tr><tr><td>val_acc_best</td><td>0.1</td></tr><tr><td>val_acc_now</td><td>0.1</td></tr><tr><td>val_loss</td><td>2.30261</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">super-sweep-14</strong> at: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/7w89ebdk' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/7w89ebdk</a><br/> View project at: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main</a><br/>Synced 7 W&B file(s), 0 media file(s), 0 artifact file(s) and 1 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20240822_174415-7w89ebdk/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require(\"core\")`! See https://wandb.me/wandb-core for more information."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 7o5auyde with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBATCH: 16\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tDFA_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tIMAGE_SIZE: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tOTTT_input_trace_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tOTTT_sWS_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tTIME: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcfg: ['M', 'M', 200, 200]\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tconst2: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdecay: 0.25\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdrop_rate: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdvs_clipping: 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdvs_duration: 100000\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \te_transport_swap: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \te_transport_swap_coin: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \te_transport_swap_tr: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepoch_num: 60\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \texclude_class: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.01\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_sg_width: 2.570969004857107\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_reset: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_threshold: 0.8931590647308035\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmerge_polarities: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tscheduler_name: CosineAnnealingLR\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsurrogate: hard_sigmoid\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \twhich_data: DVS_GESTURE_TONIC\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.17.7 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.17.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/nfs/home/bhkim003/github_folder/ByeonghyeonKim/my_snn/wandb/run-20240822_175048-7o5auyde</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/7o5auyde' target=\"_blank\">deft-sweep-17</a></strong> to <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/yxynyr6h' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/yxynyr6h</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/yxynyr6h' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/yxynyr6h</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/7o5auyde' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/7o5auyde</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BATCH' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'IMAGE_SIZE' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'which_data' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_threshold' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_reset' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_sg_width' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'cfg' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'learning_rate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'epoch_num' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'surrogate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'scheduler_name' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'dvs_clipping' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'dvs_duration' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'OTTT_sWS_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'DFA_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'OTTT_input_trace_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'e_transport_swap' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'e_transport_swap_tr' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'e_transport_swap_coin' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'drop_rate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'exclude_class' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'merge_polarities' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'TIME' was locked by 'sweep' (ignored update).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset_hash = 2bbd58b4e0d3c1e9ad501fad8a43feed\n",
      "cache path exists\n",
      "\n",
      "we will exclude the 'other' class. dvsgestrue 10 classes' indices exist. \n",
      "\n",
      "DataParallel(\n",
      "  (module): MY_SNN_FC_sstep(\n",
      "    (layers): MY_Sequential(\n",
      "      (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (2): DimChanger_for_FC_sstep()\n",
      "      (3): SYNAPSE_FC_trace_sstep()\n",
      "      (4): LIF_layer_trace_sstep()\n",
      "      (5): SYNAPSE_FC_trace_sstep()\n",
      "      (6): LIF_layer_trace_sstep()\n",
      "      (7): SYNAPSE_FC_trace_sstep()\n",
      "    )\n",
      "  )\n",
      ")\n",
      "==================================================\n",
      "My Num of PARAMS: 452,010, system's param_num : 452,010\n",
      "Memory: 1.72MiB at 32-bit\n",
      "==================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch-0   lr=['0.0100000'], tr/val_loss:  1.695882/  1.360517, tr:  41.57%, val:  50.42%, val_best:  50.42%: 100%|██████████| 62/62 [00:06<00:00,  9.56it/s]\n",
      "epoch-1   lr=['0.0099931'], tr/val_loss:  1.158505/  1.303704, tr:  59.55%, val:  55.00%, val_best:  55.00%: 100%|██████████| 62/62 [00:07<00:00,  8.56it/s]\n",
      "epoch-2   lr=['0.0099726'], tr/val_loss:  1.031323/  1.269234, tr:  63.74%, val:  60.83%, val_best:  60.83%: 100%|██████████| 62/62 [00:06<00:00, 10.05it/s]\n",
      "epoch-3   lr=['0.0099384'], tr/val_loss:  0.954866/  1.185508, tr:  65.68%, val:  63.33%, val_best:  63.33%: 100%|██████████| 62/62 [00:06<00:00,  9.32it/s]\n",
      "epoch-4   lr=['0.0098907'], tr/val_loss:  0.871075/  1.237851, tr:  67.31%, val:  63.75%, val_best:  63.75%: 100%|██████████| 62/62 [00:05<00:00, 10.34it/s]\n",
      "epoch-5   lr=['0.0098296'], tr/val_loss:  0.782475/  1.357603, tr:  72.32%, val:  58.75%, val_best:  63.75%: 100%|██████████| 62/62 [00:06<00:00,  9.11it/s]\n",
      "epoch-6   lr=['0.0097553'], tr/val_loss:  0.741359/  1.164609, tr:  73.44%, val:  60.00%, val_best:  63.75%: 100%|██████████| 62/62 [00:06<00:00,  9.77it/s]\n",
      "epoch-7   lr=['0.0096679'], tr/val_loss:  0.686295/  1.357813, tr:  74.97%, val:  60.00%, val_best:  63.75%: 100%|██████████| 62/62 [00:05<00:00, 11.24it/s]\n",
      "epoch-8   lr=['0.0095677'], tr/val_loss:  0.699273/  1.130965, tr:  73.75%, val:  63.75%, val_best:  63.75%: 100%|██████████| 62/62 [00:07<00:00,  8.29it/s]\n",
      "epoch-9   lr=['0.0094550'], tr/val_loss:  0.547120/  1.363034, tr:  78.96%, val:  63.33%, val_best:  63.75%: 100%|██████████| 62/62 [00:05<00:00, 10.63it/s]\n",
      "epoch-10  lr=['0.0093301'], tr/val_loss:  0.566435/  1.213377, tr:  78.24%, val:  68.33%, val_best:  68.33%: 100%|██████████| 62/62 [00:07<00:00,  8.23it/s]\n",
      "epoch-11  lr=['0.0091934'], tr/val_loss:  0.497768/  1.306346, tr:  80.80%, val:  65.00%, val_best:  68.33%: 100%|██████████| 62/62 [00:06<00:00,  9.91it/s]\n",
      "epoch-12  lr=['0.0090451'], tr/val_loss:  0.545046/  1.126592, tr:  82.02%, val:  69.58%, val_best:  69.58%: 100%|██████████| 62/62 [00:07<00:00,  8.33it/s]\n",
      "epoch-13  lr=['0.0088857'], tr/val_loss:  0.468076/  1.371774, tr:  84.07%, val:  65.42%, val_best:  69.58%: 100%|██████████| 62/62 [00:06<00:00, 10.10it/s]\n",
      "epoch-14  lr=['0.0087157'], tr/val_loss:  0.412395/  1.282388, tr:  85.50%, val:  68.75%, val_best:  69.58%: 100%|██████████| 62/62 [00:06<00:00,  9.09it/s]\n",
      "epoch-15  lr=['0.0085355'], tr/val_loss:  0.361153/  1.349937, tr:  90.40%, val:  69.58%, val_best:  69.58%: 100%|██████████| 62/62 [00:05<00:00, 10.91it/s]\n",
      "epoch-16  lr=['0.0083457'], tr/val_loss:  0.295035/  1.392014, tr:  93.67%, val:  72.92%, val_best:  72.92%: 100%|██████████| 62/62 [00:07<00:00,  8.72it/s]\n",
      "epoch-17  lr=['0.0081466'], tr/val_loss:  0.264943/  1.447750, tr:  94.48%, val:  69.17%, val_best:  72.92%: 100%|██████████| 62/62 [00:05<00:00, 12.19it/s]\n",
      "epoch-18  lr=['0.0079389'], tr/val_loss:  0.264295/  1.422236, tr:  95.20%, val:  73.33%, val_best:  73.33%: 100%|██████████| 62/62 [00:05<00:00, 11.28it/s]\n",
      "epoch-19  lr=['0.0077232'], tr/val_loss:  0.235088/  1.446129, tr:  96.83%, val:  73.33%, val_best:  73.33%: 100%|██████████| 62/62 [00:05<00:00, 10.41it/s]\n",
      "epoch-20  lr=['0.0075000'], tr/val_loss:  0.162112/  1.512272, tr:  99.28%, val:  75.83%, val_best:  75.83%: 100%|██████████| 62/62 [00:05<00:00, 11.45it/s]\n",
      "epoch-21  lr=['0.0072700'], tr/val_loss:  0.120504/  1.652352, tr:  99.69%, val:  72.92%, val_best:  75.83%: 100%|██████████| 62/62 [00:07<00:00,  8.61it/s]\n",
      "epoch-22  lr=['0.0070337'], tr/val_loss:  0.164323/  1.567205, tr:  96.73%, val:  73.33%, val_best:  75.83%: 100%|██████████| 62/62 [00:06<00:00,  9.80it/s]\n",
      "epoch-23  lr=['0.0067918'], tr/val_loss:  0.112451/  1.581053, tr:  99.59%, val:  75.83%, val_best:  75.83%: 100%|██████████| 62/62 [00:06<00:00, 10.33it/s]\n",
      "epoch-24  lr=['0.0065451'], tr/val_loss:  0.056646/  1.601510, tr: 100.00%, val:  77.92%, val_best:  77.92%: 100%|██████████| 62/62 [00:05<00:00, 10.73it/s]\n",
      "epoch-25  lr=['0.0062941'], tr/val_loss:  0.039585/  1.687697, tr: 100.00%, val:  78.75%, val_best:  78.75%: 100%|██████████| 62/62 [00:05<00:00, 11.52it/s]\n",
      "epoch-26  lr=['0.0060396'], tr/val_loss:  0.029669/  1.684862, tr: 100.00%, val:  79.58%, val_best:  79.58%: 100%|██████████| 62/62 [00:05<00:00, 10.54it/s]\n",
      "epoch-27  lr=['0.0057822'], tr/val_loss:  0.022761/  1.803694, tr: 100.00%, val:  77.08%, val_best:  79.58%: 100%|██████████| 62/62 [00:05<00:00, 11.96it/s]\n",
      "epoch-28  lr=['0.0055226'], tr/val_loss:  0.017081/  1.737108, tr: 100.00%, val:  80.83%, val_best:  80.83%: 100%|██████████| 62/62 [00:06<00:00,  9.58it/s]\n",
      "epoch-29  lr=['0.0052617'], tr/val_loss:  0.009993/  1.812236, tr: 100.00%, val:  77.50%, val_best:  80.83%: 100%|██████████| 62/62 [00:06<00:00,  9.57it/s]\n",
      "epoch-30  lr=['0.0050000'], tr/val_loss:  0.008001/  1.862376, tr: 100.00%, val:  76.67%, val_best:  80.83%: 100%|██████████| 62/62 [00:07<00:00,  8.30it/s]\n",
      "epoch-31  lr=['0.0047383'], tr/val_loss:  0.006101/  1.850373, tr: 100.00%, val:  77.08%, val_best:  80.83%: 100%|██████████| 62/62 [00:05<00:00, 10.60it/s]\n",
      "epoch-32  lr=['0.0044774'], tr/val_loss:  0.004680/  1.866701, tr: 100.00%, val:  77.08%, val_best:  80.83%: 100%|██████████| 62/62 [00:06<00:00,  9.28it/s]\n",
      "epoch-33  lr=['0.0042178'], tr/val_loss:  0.003856/  1.846438, tr: 100.00%, val:  77.50%, val_best:  80.83%: 100%|██████████| 62/62 [00:06<00:00, 10.21it/s]\n",
      "epoch-34  lr=['0.0039604'], tr/val_loss:  0.003321/  1.858955, tr: 100.00%, val:  77.50%, val_best:  80.83%: 100%|██████████| 62/62 [00:07<00:00,  8.24it/s]\n",
      "epoch-35  lr=['0.0037059'], tr/val_loss:  0.003067/  1.884567, tr: 100.00%, val:  78.33%, val_best:  80.83%: 100%|██████████| 62/62 [00:05<00:00, 11.35it/s]\n",
      "epoch-36  lr=['0.0034549'], tr/val_loss:  0.002936/  1.890676, tr: 100.00%, val:  77.50%, val_best:  80.83%: 100%|██████████| 62/62 [00:06<00:00,  9.54it/s]\n",
      "epoch-37  lr=['0.0032082'], tr/val_loss:  0.002662/  1.888646, tr: 100.00%, val:  77.50%, val_best:  80.83%: 100%|██████████| 62/62 [00:06<00:00,  9.99it/s]\n",
      "epoch-38  lr=['0.0029663'], tr/val_loss:  0.002490/  1.895074, tr: 100.00%, val:  77.50%, val_best:  80.83%: 100%|██████████| 62/62 [00:07<00:00,  8.56it/s]\n",
      "epoch-39  lr=['0.0027300'], tr/val_loss:  0.002368/  1.908508, tr: 100.00%, val:  77.92%, val_best:  80.83%: 100%|██████████| 62/62 [00:05<00:00, 10.54it/s]\n",
      "epoch-40  lr=['0.0025000'], tr/val_loss:  0.002265/  1.912070, tr: 100.00%, val:  78.33%, val_best:  80.83%: 100%|██████████| 62/62 [00:06<00:00,  9.55it/s]\n",
      "epoch-41  lr=['0.0022768'], tr/val_loss:  0.002170/  1.910009, tr: 100.00%, val:  78.75%, val_best:  80.83%: 100%|██████████| 62/62 [00:06<00:00, 10.30it/s]\n",
      "epoch-42  lr=['0.0020611'], tr/val_loss:  0.002037/  1.904308, tr: 100.00%, val:  78.33%, val_best:  80.83%: 100%|██████████| 62/62 [00:06<00:00,  9.90it/s]\n",
      "epoch-43  lr=['0.0018534'], tr/val_loss:  0.002068/  1.910265, tr: 100.00%, val:  78.33%, val_best:  80.83%: 100%|██████████| 62/62 [00:06<00:00,  9.32it/s]\n",
      "epoch-44  lr=['0.0016543'], tr/val_loss:  0.001948/  1.909275, tr: 100.00%, val:  78.33%, val_best:  80.83%: 100%|██████████| 62/62 [00:06<00:00,  9.21it/s]\n",
      "epoch-45  lr=['0.0014645'], tr/val_loss:  0.001901/  1.914070, tr: 100.00%, val:  78.75%, val_best:  80.83%: 100%|██████████| 62/62 [00:06<00:00,  8.86it/s]\n",
      "epoch-46  lr=['0.0012843'], tr/val_loss:  0.001911/  1.914528, tr: 100.00%, val:  78.33%, val_best:  80.83%: 100%|██████████| 62/62 [00:06<00:00,  9.17it/s]\n",
      "epoch-47  lr=['0.0011143'], tr/val_loss:  0.001838/  1.911140, tr: 100.00%, val:  78.33%, val_best:  80.83%: 100%|██████████| 62/62 [00:05<00:00, 10.52it/s]\n",
      "epoch-48  lr=['0.0009549'], tr/val_loss:  0.001851/  1.908207, tr: 100.00%, val:  78.33%, val_best:  80.83%: 100%|██████████| 62/62 [00:06<00:00,  9.01it/s]\n",
      "epoch-49  lr=['0.0008066'], tr/val_loss:  0.001798/  1.910888, tr: 100.00%, val:  78.33%, val_best:  80.83%: 100%|██████████| 62/62 [00:06<00:00,  9.44it/s]\n",
      "epoch-50  lr=['0.0006699'], tr/val_loss:  0.001822/  1.911572, tr: 100.00%, val:  78.33%, val_best:  80.83%: 100%|██████████| 62/62 [00:06<00:00,  9.01it/s]\n",
      "epoch-51  lr=['0.0005450'], tr/val_loss:  0.001748/  1.911522, tr: 100.00%, val:  78.33%, val_best:  80.83%: 100%|██████████| 62/62 [00:06<00:00,  9.85it/s]\n",
      "epoch-52  lr=['0.0004323'], tr/val_loss:  0.001762/  1.914839, tr: 100.00%, val:  78.33%, val_best:  80.83%: 100%|██████████| 62/62 [00:06<00:00,  9.11it/s]\n",
      "epoch-53  lr=['0.0003321'], tr/val_loss:  0.001702/  1.911496, tr: 100.00%, val:  78.33%, val_best:  80.83%: 100%|██████████| 62/62 [00:06<00:00,  9.85it/s]\n",
      "epoch-54  lr=['0.0002447'], tr/val_loss:  0.001757/  1.914385, tr: 100.00%, val:  78.33%, val_best:  80.83%: 100%|██████████| 62/62 [00:07<00:00,  8.82it/s]\n",
      "epoch-55  lr=['0.0001704'], tr/val_loss:  0.001713/  1.915282, tr: 100.00%, val:  78.33%, val_best:  80.83%: 100%|██████████| 62/62 [00:06<00:00,  9.54it/s]\n",
      "epoch-56  lr=['0.0001093'], tr/val_loss:  0.001677/  1.913398, tr: 100.00%, val:  78.33%, val_best:  80.83%: 100%|██████████| 62/62 [00:06<00:00,  9.78it/s]\n",
      "epoch-57  lr=['0.0000616'], tr/val_loss:  0.001673/  1.913022, tr: 100.00%, val:  78.33%, val_best:  80.83%: 100%|██████████| 62/62 [00:06<00:00,  9.16it/s]\n",
      "epoch-58  lr=['0.0000274'], tr/val_loss:  0.001658/  1.913219, tr: 100.00%, val:  78.33%, val_best:  80.83%: 100%|██████████| 62/62 [00:05<00:00, 10.70it/s]\n",
      "epoch-59  lr=['0.0000069'], tr/val_loss:  0.001674/  1.914029, tr: 100.00%, val:  78.33%, val_best:  80.83%: 100%|██████████| 62/62 [00:06<00:00,  8.86it/s]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0b2c9da3002b40289291c16b305ef626",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='1.937 MB of 1.937 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>DFA_flag</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>epoch</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇████</td></tr><tr><td>iter_acc</td><td>▂▃▂▁▅▅▅▅▆▆▇▇▇███████████████████████████</td></tr><tr><td>summary_val_acc</td><td>▁▅▆▆▆▆▇▆▇▇▇▇▇▇█▇████████████████████████</td></tr><tr><td>tr_acc</td><td>▁▄▅▆▆▆▆▇▇▇▇█████████████████████████████</td></tr><tr><td>tr_epoch_loss</td><td>▁█▅▅▄▄▄▃▃▃▃▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_acc_best</td><td>▁▅▆▆▇▇▇▇▇▇▇▇▇▇██████████████████████████</td></tr><tr><td>val_acc_now</td><td>▁▅▆▆▆▆▇▆▇▇▇▇▇▇█▇████████████████████████</td></tr><tr><td>val_loss</td><td>▁▆▆▅▆▅▅▆▆▅▆▆▆▆▇▇▇▇▇▇████████████████████</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>DFA_flag</td><td>0.0</td></tr><tr><td>epoch</td><td>59</td></tr><tr><td>iter_acc</td><td>1.0</td></tr><tr><td>tr_acc</td><td>1.0</td></tr><tr><td>tr_epoch_loss</td><td>0.00167</td></tr><tr><td>val_acc_best</td><td>0.80833</td></tr><tr><td>val_acc_now</td><td>0.78333</td></tr><tr><td>val_loss</td><td>1.91403</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">deft-sweep-17</strong> at: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/7o5auyde' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/7o5auyde</a><br/> View project at: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main</a><br/>Synced 7 W&B file(s), 0 media file(s), 0 artifact file(s) and 1 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20240822_175048-7o5auyde/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require(\"core\")`! See https://wandb.me/wandb-core for more information."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Sweep Agent: Waiting for job.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Job received.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 55l4oi72 with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBATCH: 16\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tDFA_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tIMAGE_SIZE: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tOTTT_input_trace_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tOTTT_sWS_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tTIME: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcfg: ['M', 'M', 200, 200]\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tconst2: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdecay: 0.25\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdrop_rate: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdvs_clipping: 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdvs_duration: 100000\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \te_transport_swap: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \te_transport_swap_coin: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \te_transport_swap_tr: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepoch_num: 60\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \texclude_class: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.01\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_sg_width: 2.570969004857107\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_reset: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_threshold: 2.5886268173423086\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmerge_polarities: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tscheduler_name: CosineAnnealingLR\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsurrogate: hard_sigmoid\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \twhich_data: DVS_GESTURE_TONIC\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.17.7 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.17.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/nfs/home/bhkim003/github_folder/ByeonghyeonKim/my_snn/wandb/run-20240822_175756-55l4oi72</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/55l4oi72' target=\"_blank\">stilted-sweep-20</a></strong> to <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/yxynyr6h' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/yxynyr6h</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/yxynyr6h' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/yxynyr6h</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/55l4oi72' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/55l4oi72</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BATCH' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'IMAGE_SIZE' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'which_data' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_threshold' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_reset' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_sg_width' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'cfg' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'learning_rate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'epoch_num' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'surrogate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'scheduler_name' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'dvs_clipping' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'dvs_duration' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'OTTT_sWS_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'DFA_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'OTTT_input_trace_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'e_transport_swap' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'e_transport_swap_tr' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'e_transport_swap_coin' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'drop_rate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'exclude_class' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'merge_polarities' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'TIME' was locked by 'sweep' (ignored update).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset_hash = 2bbd58b4e0d3c1e9ad501fad8a43feed\n",
      "cache path exists\n",
      "\n",
      "we will exclude the 'other' class. dvsgestrue 10 classes' indices exist. \n",
      "\n",
      "DataParallel(\n",
      "  (module): MY_SNN_FC_sstep(\n",
      "    (layers): MY_Sequential(\n",
      "      (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (2): DimChanger_for_FC_sstep()\n",
      "      (3): SYNAPSE_FC_trace_sstep()\n",
      "      (4): LIF_layer_trace_sstep()\n",
      "      (5): SYNAPSE_FC_trace_sstep()\n",
      "      (6): LIF_layer_trace_sstep()\n",
      "      (7): SYNAPSE_FC_trace_sstep()\n",
      "    )\n",
      "  )\n",
      ")\n",
      "==================================================\n",
      "My Num of PARAMS: 452,010, system's param_num : 452,010\n",
      "Memory: 1.72MiB at 32-bit\n",
      "==================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch-0   lr=['0.0100000'], tr/val_loss:  2.317507/  2.316367, tr:   9.70%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:07<00:00,  8.20it/s]\n",
      "epoch-1   lr=['0.0099931'], tr/val_loss:  2.316254/  2.314931, tr:  10.21%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:06<00:00,  9.33it/s]\n",
      "epoch-2   lr=['0.0099726'], tr/val_loss:  2.315321/  2.315877, tr:   9.81%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:06<00:00,  8.89it/s]\n",
      "epoch-3   lr=['0.0099384'], tr/val_loss:  2.319123/  2.321801, tr:  10.42%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:05<00:00, 10.42it/s]\n",
      "epoch-4   lr=['0.0098907'], tr/val_loss:  2.328817/  2.310750, tr:   7.66%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:06<00:00,  9.39it/s]\n",
      "epoch-5   lr=['0.0098296'], tr/val_loss:  2.318780/  2.313111, tr:   8.58%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:06<00:00,  9.75it/s]\n",
      "epoch-6   lr=['0.0097553'], tr/val_loss:  2.326567/  2.312034, tr:   8.89%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:05<00:00, 11.00it/s]\n",
      "epoch-7   lr=['0.0096679'], tr/val_loss:  2.319906/  2.308871, tr:   8.89%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:06<00:00,  8.88it/s]\n",
      "epoch-8   lr=['0.0095677'], tr/val_loss:  2.315703/  2.318316, tr:   9.09%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:05<00:00, 10.77it/s]\n",
      "epoch-9   lr=['0.0094550'], tr/val_loss:  2.315776/  2.321137, tr:   9.81%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:06<00:00,  9.17it/s]\n",
      "epoch-10  lr=['0.0093301'], tr/val_loss:  2.319218/  2.310921, tr:   9.40%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:06<00:00,  9.87it/s]\n",
      "epoch-11  lr=['0.0091934'], tr/val_loss:  2.320658/  2.318817, tr:   9.60%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:06<00:00,  8.86it/s]\n",
      "epoch-12  lr=['0.0090451'], tr/val_loss:  2.323760/  2.306959, tr:   9.70%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:05<00:00, 10.54it/s]\n",
      "epoch-13  lr=['0.0088857'], tr/val_loss:  2.312257/  2.313825, tr:   8.78%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:06<00:00,  9.11it/s]\n",
      "epoch-14  lr=['0.0087157'], tr/val_loss:  2.321870/  2.310401, tr:   9.70%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:05<00:00, 11.02it/s]\n",
      "epoch-15  lr=['0.0085355'], tr/val_loss:  2.318407/  2.313874, tr:   9.60%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:05<00:00, 10.56it/s]\n",
      "epoch-16  lr=['0.0083457'], tr/val_loss:  2.317499/  2.312321, tr:  10.11%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:05<00:00, 11.33it/s]\n",
      "epoch-17  lr=['0.0081466'], tr/val_loss:  2.318669/  2.307941, tr:   8.89%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:05<00:00, 10.43it/s]\n",
      "epoch-18  lr=['0.0079389'], tr/val_loss:  2.325135/  2.306585, tr:   7.46%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:06<00:00,  9.70it/s]\n",
      "epoch-19  lr=['0.0077232'], tr/val_loss:  2.314244/  2.310251, tr:  10.01%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:06<00:00,  9.58it/s]\n",
      "epoch-20  lr=['0.0075000'], tr/val_loss:  2.312182/  2.307967, tr:   9.91%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:05<00:00, 10.97it/s]\n",
      "epoch-21  lr=['0.0072700'], tr/val_loss:  2.318818/  2.307295, tr:   9.30%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:07<00:00,  8.51it/s]\n",
      "epoch-22  lr=['0.0070337'], tr/val_loss:  2.313441/  2.307399, tr:   9.91%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:05<00:00, 12.28it/s]\n",
      "epoch-23  lr=['0.0067918'], tr/val_loss:  2.314248/  2.309416, tr:   7.76%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:05<00:00, 11.36it/s]\n",
      "epoch-24  lr=['0.0065451'], tr/val_loss:  2.318841/  2.305136, tr:   9.09%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:05<00:00, 11.33it/s]\n",
      "epoch-25  lr=['0.0062941'], tr/val_loss:  2.316903/  2.306750, tr:   7.97%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:05<00:00, 10.74it/s]\n",
      "epoch-26  lr=['0.0060396'], tr/val_loss:  2.311055/  2.305107, tr:   8.99%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:07<00:00,  8.45it/s]\n",
      "epoch-27  lr=['0.0057822'], tr/val_loss:  2.313828/  2.306802, tr:   8.58%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:06<00:00, 10.22it/s]\n",
      "epoch-28  lr=['0.0055226'], tr/val_loss:  2.315332/  2.308450, tr:   8.68%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:06<00:00, 10.08it/s]\n",
      "epoch-29  lr=['0.0052617'], tr/val_loss:  2.315842/  2.306032, tr:   7.15%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:06<00:00,  9.48it/s]\n",
      "epoch-30  lr=['0.0050000'], tr/val_loss:  2.312570/  2.303939, tr:   8.89%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:05<00:00, 10.51it/s]\n",
      "epoch-31  lr=['0.0047383'], tr/val_loss:  2.309263/  2.303903, tr:   9.09%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:06<00:00, 10.27it/s]\n",
      "epoch-32  lr=['0.0044774'], tr/val_loss:  2.311847/  2.302894, tr:   8.38%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:05<00:00, 10.50it/s]\n",
      "epoch-33  lr=['0.0042178'], tr/val_loss:  2.308722/  2.303530, tr:   9.50%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:06<00:00,  9.96it/s]\n",
      "epoch-34  lr=['0.0039604'], tr/val_loss:  2.313000/  2.304187, tr:   8.48%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:06<00:00, 10.08it/s]\n",
      "epoch-35  lr=['0.0037059'], tr/val_loss:  2.309877/  2.303538, tr:   9.09%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:07<00:00,  8.85it/s]\n",
      "epoch-36  lr=['0.0034549'], tr/val_loss:  2.309406/  2.303601, tr:   8.99%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:06<00:00,  9.16it/s]\n",
      "epoch-37  lr=['0.0032082'], tr/val_loss:  2.309686/  2.303400, tr:   7.66%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:06<00:00,  9.81it/s]\n",
      "epoch-38  lr=['0.0029663'], tr/val_loss:  2.308588/  2.303166, tr:   9.09%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:06<00:00,  9.67it/s]\n",
      "epoch-39  lr=['0.0027300'], tr/val_loss:  2.308727/  2.302884, tr:   8.89%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:06<00:00,  9.40it/s]\n",
      "epoch-40  lr=['0.0025000'], tr/val_loss:  2.308749/  2.302732, tr:   9.40%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:06<00:00, 10.33it/s]\n",
      "epoch-41  lr=['0.0022768'], tr/val_loss:  2.306803/  2.302942, tr:   9.19%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:06<00:00,  9.68it/s]\n",
      "epoch-42  lr=['0.0020611'], tr/val_loss:  2.306347/  2.302762, tr:   8.68%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:06<00:00,  8.94it/s]\n",
      "epoch-43  lr=['0.0018534'], tr/val_loss:  2.305991/  2.302857, tr:   8.99%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:06<00:00,  8.99it/s]\n",
      "epoch-44  lr=['0.0016543'], tr/val_loss:  2.305293/  2.302853, tr:  10.01%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:06<00:00, 10.20it/s]\n",
      "epoch-45  lr=['0.0014645'], tr/val_loss:  2.306396/  2.302847, tr:   8.48%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:05<00:00, 10.58it/s]\n",
      "epoch-46  lr=['0.0012843'], tr/val_loss:  2.305307/  2.302670, tr:  10.01%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:05<00:00, 11.64it/s]\n",
      "epoch-47  lr=['0.0011143'], tr/val_loss:  2.305197/  2.302644, tr:   9.30%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:05<00:00, 10.52it/s]\n",
      "epoch-48  lr=['0.0009549'], tr/val_loss:  2.304637/  2.302745, tr:   8.78%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:05<00:00, 11.27it/s]\n",
      "epoch-49  lr=['0.0008066'], tr/val_loss:  2.304113/  2.302645, tr:   8.89%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:05<00:00, 12.05it/s]\n",
      "epoch-50  lr=['0.0006699'], tr/val_loss:  2.304358/  2.302700, tr:   8.68%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:06<00:00,  9.96it/s]\n",
      "epoch-51  lr=['0.0005450'], tr/val_loss:  2.303610/  2.302717, tr:   9.81%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:05<00:00, 11.14it/s]\n",
      "epoch-52  lr=['0.0004323'], tr/val_loss:  2.303667/  2.302626, tr:   9.30%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:06<00:00, 10.11it/s]\n",
      "epoch-53  lr=['0.0003321'], tr/val_loss:  2.303300/  2.302634, tr:   9.19%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:05<00:00, 11.58it/s]\n",
      "epoch-54  lr=['0.0002447'], tr/val_loss:  2.303030/  2.302622, tr:   8.38%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:05<00:00, 11.83it/s]\n",
      "epoch-55  lr=['0.0001704'], tr/val_loss:  2.303107/  2.302625, tr:  10.01%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:05<00:00, 11.44it/s]\n",
      "epoch-56  lr=['0.0001093'], tr/val_loss:  2.302886/  2.302609, tr:  10.01%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:05<00:00, 11.88it/s]\n",
      "epoch-57  lr=['0.0000616'], tr/val_loss:  2.302670/  2.302610, tr:  10.01%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:05<00:00, 10.46it/s]\n",
      "epoch-58  lr=['0.0000274'], tr/val_loss:  2.302685/  2.302609, tr:  10.01%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:05<00:00, 12.15it/s]\n",
      "epoch-59  lr=['0.0000069'], tr/val_loss:  2.302528/  2.302609, tr:  10.01%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:06<00:00,  9.73it/s]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6a2f027c54e1489fb37f2ba621098d48",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='1.937 MB of 1.937 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>DFA_flag</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>epoch</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇████</td></tr><tr><td>iter_acc</td><td>▁█▅▅▃▁▅█▆▃▆▅▃▃▁▃▃▃▁▁▁▁▆▅▁▃▁▅▃▅▃▅▃▃▅▅▁▃▅█</td></tr><tr><td>summary_val_acc</td><td>▁███████████████████████████████████████</td></tr><tr><td>tr_acc</td><td>▁███▇▇▇█▇███▇███▆▆▇▇▆▇▇▇▇▆▇▇▇▇██▇▇█▇▇███</td></tr><tr><td>tr_epoch_loss</td><td>▁███████████████████████████████████████</td></tr><tr><td>val_acc_best</td><td>▁███████████████████████████████████████</td></tr><tr><td>val_acc_now</td><td>▁███████████████████████████████████████</td></tr><tr><td>val_loss</td><td>▁███████████████████████████████████████</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>DFA_flag</td><td>0.0</td></tr><tr><td>epoch</td><td>59</td></tr><tr><td>iter_acc</td><td>0.33333</td></tr><tr><td>tr_acc</td><td>0.1001</td></tr><tr><td>tr_epoch_loss</td><td>2.30253</td></tr><tr><td>val_acc_best</td><td>0.1</td></tr><tr><td>val_acc_now</td><td>0.1</td></tr><tr><td>val_loss</td><td>2.30261</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">stilted-sweep-20</strong> at: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/55l4oi72' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/55l4oi72</a><br/> View project at: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main</a><br/>Synced 7 W&B file(s), 0 media file(s), 0 artifact file(s) and 1 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20240822_175756-55l4oi72/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require(\"core\")`! See https://wandb.me/wandb-core for more information."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: brr2pori with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBATCH: 16\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tDFA_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tIMAGE_SIZE: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tOTTT_input_trace_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tOTTT_sWS_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tTIME: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcfg: ['M', 'M', 200, 200]\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tconst2: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdecay: 0.25\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdrop_rate: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdvs_clipping: 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdvs_duration: 100000\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \te_transport_swap: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \te_transport_swap_coin: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \te_transport_swap_tr: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepoch_num: 60\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \texclude_class: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.01\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_sg_width: 2.570969004857107\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_reset: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_threshold: 0.837207229394151\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmerge_polarities: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tscheduler_name: CosineAnnealingLR\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsurrogate: hard_sigmoid\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \twhich_data: DVS_GESTURE_TONIC\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.17.7 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.17.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/nfs/home/bhkim003/github_folder/ByeonghyeonKim/my_snn/wandb/run-20240822_180435-brr2pori</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/brr2pori' target=\"_blank\">lucky-sweep-23</a></strong> to <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/yxynyr6h' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/yxynyr6h</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/yxynyr6h' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/yxynyr6h</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/brr2pori' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/brr2pori</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BATCH' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'IMAGE_SIZE' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'which_data' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_threshold' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_reset' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_sg_width' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'cfg' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'learning_rate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'epoch_num' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'surrogate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'scheduler_name' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'dvs_clipping' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'dvs_duration' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'OTTT_sWS_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'DFA_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'OTTT_input_trace_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'e_transport_swap' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'e_transport_swap_tr' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'e_transport_swap_coin' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'drop_rate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'exclude_class' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'merge_polarities' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'TIME' was locked by 'sweep' (ignored update).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset_hash = 2bbd58b4e0d3c1e9ad501fad8a43feed\n",
      "cache path exists\n",
      "\n",
      "we will exclude the 'other' class. dvsgestrue 10 classes' indices exist. \n",
      "\n",
      "DataParallel(\n",
      "  (module): MY_SNN_FC_sstep(\n",
      "    (layers): MY_Sequential(\n",
      "      (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (2): DimChanger_for_FC_sstep()\n",
      "      (3): SYNAPSE_FC_trace_sstep()\n",
      "      (4): LIF_layer_trace_sstep()\n",
      "      (5): SYNAPSE_FC_trace_sstep()\n",
      "      (6): LIF_layer_trace_sstep()\n",
      "      (7): SYNAPSE_FC_trace_sstep()\n",
      "    )\n",
      "  )\n",
      ")\n",
      "==================================================\n",
      "My Num of PARAMS: 452,010, system's param_num : 452,010\n",
      "Memory: 1.72MiB at 32-bit\n",
      "==================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch-0   lr=['0.0100000'], tr/val_loss:  1.684290/  1.301792, tr:  43.00%, val:  55.00%, val_best:  55.00%: 100%|██████████| 62/62 [00:05<00:00, 10.34it/s]\n",
      "epoch-1   lr=['0.0099931'], tr/val_loss:  1.109663/  1.356284, tr:  60.47%, val:  57.50%, val_best:  57.50%: 100%|██████████| 62/62 [00:05<00:00, 11.24it/s]\n",
      "epoch-2   lr=['0.0099726'], tr/val_loss:  0.993214/  1.276276, tr:  63.84%, val:  62.08%, val_best:  62.08%: 100%|██████████| 62/62 [00:05<00:00, 10.70it/s]\n",
      "epoch-3   lr=['0.0099384'], tr/val_loss:  0.876618/  1.193640, tr:  68.34%, val:  60.42%, val_best:  62.08%: 100%|██████████| 62/62 [00:05<00:00, 10.55it/s]\n",
      "epoch-4   lr=['0.0098907'], tr/val_loss:  0.834733/  1.225157, tr:  69.66%, val:  63.33%, val_best:  63.33%: 100%|██████████| 62/62 [00:05<00:00, 11.72it/s]\n",
      "epoch-5   lr=['0.0098296'], tr/val_loss:  0.794263/  1.288996, tr:  71.40%, val:  62.92%, val_best:  63.33%: 100%|██████████| 62/62 [00:05<00:00, 10.46it/s]\n",
      "epoch-6   lr=['0.0097553'], tr/val_loss:  0.716189/  1.173147, tr:  71.81%, val:  61.67%, val_best:  63.33%: 100%|██████████| 62/62 [00:05<00:00, 11.56it/s]\n",
      "epoch-7   lr=['0.0096679'], tr/val_loss:  0.688872/  1.321352, tr:  74.87%, val:  61.67%, val_best:  63.33%: 100%|██████████| 62/62 [00:05<00:00, 11.91it/s]\n",
      "epoch-8   lr=['0.0095677'], tr/val_loss:  0.646643/  1.152851, tr:  75.89%, val:  67.92%, val_best:  67.92%: 100%|██████████| 62/62 [00:05<00:00, 10.55it/s]\n",
      "epoch-9   lr=['0.0094550'], tr/val_loss:  0.507510/  1.279539, tr:  80.69%, val:  67.08%, val_best:  67.92%: 100%|██████████| 62/62 [00:05<00:00, 11.56it/s]\n",
      "epoch-10  lr=['0.0093301'], tr/val_loss:  0.488527/  1.147004, tr:  82.43%, val:  67.92%, val_best:  67.92%: 100%|██████████| 62/62 [00:05<00:00, 10.93it/s]\n",
      "epoch-11  lr=['0.0091934'], tr/val_loss:  0.468683/  1.358633, tr:  81.72%, val:  68.75%, val_best:  68.75%: 100%|██████████| 62/62 [00:05<00:00, 10.53it/s]\n",
      "epoch-12  lr=['0.0090451'], tr/val_loss:  0.461336/  1.282244, tr:  82.94%, val:  68.33%, val_best:  68.75%: 100%|██████████| 62/62 [00:05<00:00, 11.47it/s]\n",
      "epoch-13  lr=['0.0088857'], tr/val_loss:  0.413423/  1.385251, tr:  88.87%, val:  67.08%, val_best:  68.75%: 100%|██████████| 62/62 [00:06<00:00, 10.33it/s]\n",
      "epoch-14  lr=['0.0087157'], tr/val_loss:  0.358479/  1.287714, tr:  90.91%, val:  72.08%, val_best:  72.08%: 100%|██████████| 62/62 [00:05<00:00, 10.75it/s]\n",
      "epoch-15  lr=['0.0085355'], tr/val_loss:  0.302317/  1.387279, tr:  95.10%, val:  75.00%, val_best:  75.00%: 100%|██████████| 62/62 [00:06<00:00,  9.38it/s]\n",
      "epoch-16  lr=['0.0083457'], tr/val_loss:  0.297796/  1.454531, tr:  94.69%, val:  71.25%, val_best:  75.00%: 100%|██████████| 62/62 [00:06<00:00, 10.02it/s]\n",
      "epoch-17  lr=['0.0081466'], tr/val_loss:  0.305312/  1.431807, tr:  94.38%, val:  69.58%, val_best:  75.00%: 100%|██████████| 62/62 [00:07<00:00,  8.76it/s]\n",
      "epoch-18  lr=['0.0079389'], tr/val_loss:  0.302512/  1.369016, tr:  92.24%, val:  72.08%, val_best:  75.00%: 100%|██████████| 62/62 [00:06<00:00,  9.45it/s]\n",
      "epoch-19  lr=['0.0077232'], tr/val_loss:  0.200847/  1.426200, tr:  97.75%, val:  78.75%, val_best:  78.75%: 100%|██████████| 62/62 [00:06<00:00,  9.85it/s]\n",
      "epoch-20  lr=['0.0075000'], tr/val_loss:  0.173575/  1.403729, tr:  98.26%, val:  78.33%, val_best:  78.75%: 100%|██████████| 62/62 [00:06<00:00,  9.13it/s]\n",
      "epoch-21  lr=['0.0072700'], tr/val_loss:  0.130196/  1.377081, tr:  99.39%, val:  80.83%, val_best:  80.83%: 100%|██████████| 62/62 [00:06<00:00,  9.94it/s]\n",
      "epoch-22  lr=['0.0070337'], tr/val_loss:  0.096026/  1.366029, tr:  99.80%, val:  78.75%, val_best:  80.83%: 100%|██████████| 62/62 [00:05<00:00, 11.06it/s]\n",
      "epoch-23  lr=['0.0067918'], tr/val_loss:  0.065608/  1.405834, tr:  99.80%, val:  80.83%, val_best:  80.83%: 100%|██████████| 62/62 [00:05<00:00, 11.74it/s]\n",
      "epoch-24  lr=['0.0065451'], tr/val_loss:  0.048647/  1.470124, tr: 100.00%, val:  79.58%, val_best:  80.83%: 100%|██████████| 62/62 [00:05<00:00, 10.83it/s]\n",
      "epoch-25  lr=['0.0062941'], tr/val_loss:  0.040427/  1.516003, tr: 100.00%, val:  82.08%, val_best:  82.08%: 100%|██████████| 62/62 [00:06<00:00,  9.62it/s]\n",
      "epoch-26  lr=['0.0060396'], tr/val_loss:  0.022257/  1.488865, tr: 100.00%, val:  82.50%, val_best:  82.50%: 100%|██████████| 62/62 [00:06<00:00,  9.47it/s]\n",
      "epoch-27  lr=['0.0057822'], tr/val_loss:  0.016310/  1.528974, tr: 100.00%, val:  82.50%, val_best:  82.50%: 100%|██████████| 62/62 [00:05<00:00, 10.47it/s]\n",
      "epoch-28  lr=['0.0055226'], tr/val_loss:  0.009936/  1.616582, tr: 100.00%, val:  82.50%, val_best:  82.50%: 100%|██████████| 62/62 [00:06<00:00,  9.12it/s]\n",
      "epoch-29  lr=['0.0052617'], tr/val_loss:  0.006994/  1.564138, tr: 100.00%, val:  82.08%, val_best:  82.50%: 100%|██████████| 62/62 [00:06<00:00,  9.21it/s]\n",
      "epoch-30  lr=['0.0050000'], tr/val_loss:  0.005189/  1.556580, tr: 100.00%, val:  82.92%, val_best:  82.92%: 100%|██████████| 62/62 [00:05<00:00, 11.02it/s]\n",
      "epoch-31  lr=['0.0047383'], tr/val_loss:  0.004711/  1.568733, tr: 100.00%, val:  82.50%, val_best:  82.92%: 100%|██████████| 62/62 [00:06<00:00, 10.11it/s]\n",
      "epoch-32  lr=['0.0044774'], tr/val_loss:  0.003807/  1.581021, tr: 100.00%, val:  82.92%, val_best:  82.92%: 100%|██████████| 62/62 [00:06<00:00,  9.54it/s]\n",
      "epoch-33  lr=['0.0042178'], tr/val_loss:  0.003195/  1.595549, tr: 100.00%, val:  83.33%, val_best:  83.33%: 100%|██████████| 62/62 [00:07<00:00,  8.85it/s]\n",
      "epoch-34  lr=['0.0039604'], tr/val_loss:  0.003152/  1.599306, tr: 100.00%, val:  82.92%, val_best:  83.33%: 100%|██████████| 62/62 [00:05<00:00, 11.08it/s]\n",
      "epoch-35  lr=['0.0037059'], tr/val_loss:  0.002549/  1.608322, tr: 100.00%, val:  84.17%, val_best:  84.17%: 100%|██████████| 62/62 [00:06<00:00,  9.95it/s]\n",
      "epoch-36  lr=['0.0034549'], tr/val_loss:  0.002280/  1.613280, tr: 100.00%, val:  84.58%, val_best:  84.58%: 100%|██████████| 62/62 [00:06<00:00,  9.62it/s]\n",
      "epoch-37  lr=['0.0032082'], tr/val_loss:  0.002059/  1.621954, tr: 100.00%, val:  84.17%, val_best:  84.58%: 100%|██████████| 62/62 [00:06<00:00,  9.33it/s]\n",
      "epoch-38  lr=['0.0029663'], tr/val_loss:  0.001927/  1.621765, tr: 100.00%, val:  84.58%, val_best:  84.58%: 100%|██████████| 62/62 [00:06<00:00,  9.03it/s]\n",
      "epoch-39  lr=['0.0027300'], tr/val_loss:  0.001896/  1.631955, tr: 100.00%, val:  83.75%, val_best:  84.58%: 100%|██████████| 62/62 [00:06<00:00, 10.06it/s]\n",
      "epoch-40  lr=['0.0025000'], tr/val_loss:  0.001779/  1.636069, tr: 100.00%, val:  83.75%, val_best:  84.58%: 100%|██████████| 62/62 [00:06<00:00,  8.97it/s]\n",
      "epoch-41  lr=['0.0022768'], tr/val_loss:  0.001705/  1.634521, tr: 100.00%, val:  84.17%, val_best:  84.58%: 100%|██████████| 62/62 [00:06<00:00,  9.05it/s]\n",
      "epoch-42  lr=['0.0020611'], tr/val_loss:  0.001650/  1.637020, tr: 100.00%, val:  84.17%, val_best:  84.58%: 100%|██████████| 62/62 [00:07<00:00,  8.50it/s]\n",
      "epoch-43  lr=['0.0018534'], tr/val_loss:  0.001660/  1.639889, tr: 100.00%, val:  84.17%, val_best:  84.58%: 100%|██████████| 62/62 [00:06<00:00,  9.85it/s]\n",
      "epoch-44  lr=['0.0016543'], tr/val_loss:  0.001615/  1.645905, tr: 100.00%, val:  84.58%, val_best:  84.58%: 100%|██████████| 62/62 [00:06<00:00, 10.03it/s]\n",
      "epoch-45  lr=['0.0014645'], tr/val_loss:  0.001582/  1.638299, tr: 100.00%, val:  85.00%, val_best:  85.00%: 100%|██████████| 62/62 [00:06<00:00, 10.06it/s]\n",
      "epoch-46  lr=['0.0012843'], tr/val_loss:  0.001542/  1.644100, tr: 100.00%, val:  84.17%, val_best:  85.00%: 100%|██████████| 62/62 [00:06<00:00,  9.14it/s]\n",
      "epoch-47  lr=['0.0011143'], tr/val_loss:  0.001531/  1.646534, tr: 100.00%, val:  85.00%, val_best:  85.00%: 100%|██████████| 62/62 [00:06<00:00,  9.48it/s]\n",
      "epoch-48  lr=['0.0009549'], tr/val_loss:  0.001518/  1.648746, tr: 100.00%, val:  84.58%, val_best:  85.00%: 100%|██████████| 62/62 [00:06<00:00,  9.07it/s]\n",
      "epoch-49  lr=['0.0008066'], tr/val_loss:  0.001513/  1.643635, tr: 100.00%, val:  84.58%, val_best:  85.00%: 100%|██████████| 62/62 [00:06<00:00,  9.05it/s]\n",
      "epoch-50  lr=['0.0006699'], tr/val_loss:  0.001496/  1.650291, tr: 100.00%, val:  84.58%, val_best:  85.00%: 100%|██████████| 62/62 [00:06<00:00,  9.67it/s]\n",
      "epoch-51  lr=['0.0005450'], tr/val_loss:  0.001487/  1.645212, tr: 100.00%, val:  84.58%, val_best:  85.00%: 100%|██████████| 62/62 [00:06<00:00,  9.27it/s]\n",
      "epoch-52  lr=['0.0004323'], tr/val_loss:  0.001470/  1.645063, tr: 100.00%, val:  84.17%, val_best:  85.00%: 100%|██████████| 62/62 [00:07<00:00,  8.62it/s]\n",
      "epoch-53  lr=['0.0003321'], tr/val_loss:  0.001485/  1.646329, tr: 100.00%, val:  84.17%, val_best:  85.00%: 100%|██████████| 62/62 [00:05<00:00, 10.42it/s]\n",
      "epoch-54  lr=['0.0002447'], tr/val_loss:  0.001449/  1.646106, tr: 100.00%, val:  84.17%, val_best:  85.00%: 100%|██████████| 62/62 [00:05<00:00, 10.88it/s]\n",
      "epoch-55  lr=['0.0001704'], tr/val_loss:  0.001431/  1.646894, tr: 100.00%, val:  84.17%, val_best:  85.00%: 100%|██████████| 62/62 [00:06<00:00,  9.32it/s]\n",
      "epoch-56  lr=['0.0001093'], tr/val_loss:  0.001449/  1.650755, tr: 100.00%, val:  84.17%, val_best:  85.00%: 100%|██████████| 62/62 [00:05<00:00, 10.85it/s]\n",
      "epoch-57  lr=['0.0000616'], tr/val_loss:  0.001441/  1.650608, tr: 100.00%, val:  84.17%, val_best:  85.00%: 100%|██████████| 62/62 [00:07<00:00,  8.74it/s]\n",
      "epoch-58  lr=['0.0000274'], tr/val_loss:  0.001448/  1.650473, tr: 100.00%, val:  84.17%, val_best:  85.00%: 100%|██████████| 62/62 [00:06<00:00,  9.44it/s]\n",
      "epoch-59  lr=['0.0000069'], tr/val_loss:  0.001436/  1.650479, tr: 100.00%, val:  84.17%, val_best:  85.00%: 100%|██████████| 62/62 [00:05<00:00, 10.65it/s]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "79bb36439ab44b69a4dd08da55e6802f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='1.937 MB of 1.937 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>DFA_flag</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>epoch</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇████</td></tr><tr><td>iter_acc</td><td>▁▄▅▆▆▅▅▆▆▆█▆▇▇██████████████████████████</td></tr><tr><td>summary_val_acc</td><td>▁▆▆▆▆▆▇▇▇▇▇▇▇█▇█████████████████████████</td></tr><tr><td>tr_acc</td><td>▁▄▅▆▆▆▆▇▇▇▇█████████████████████████████</td></tr><tr><td>tr_epoch_loss</td><td>▁█▅▅▄▄▄▃▃▃▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_acc_best</td><td>▁▆▆▆▆▆▇▇▇▇▇▇▇▇▇█████████████████████████</td></tr><tr><td>val_acc_now</td><td>▁▆▆▆▆▆▇▇▇▇▇▇▇█▇█████████████████████████</td></tr><tr><td>val_loss</td><td>▁▇▆▆▆▆▆▆▇▆▆▇▇▇▇▇▇▇▇█████████████████████</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>DFA_flag</td><td>0.0</td></tr><tr><td>epoch</td><td>59</td></tr><tr><td>iter_acc</td><td>1.0</td></tr><tr><td>tr_acc</td><td>1.0</td></tr><tr><td>tr_epoch_loss</td><td>0.00144</td></tr><tr><td>val_acc_best</td><td>0.85</td></tr><tr><td>val_acc_now</td><td>0.84167</td></tr><tr><td>val_loss</td><td>1.65048</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">lucky-sweep-23</strong> at: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/brr2pori' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/brr2pori</a><br/> View project at: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main</a><br/>Synced 7 W&B file(s), 0 media file(s), 0 artifact file(s) and 1 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20240822_180435-brr2pori/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require(\"core\")`! See https://wandb.me/wandb-core for more information."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 26tf7m2y with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBATCH: 16\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tDFA_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tIMAGE_SIZE: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tOTTT_input_trace_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tOTTT_sWS_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tTIME: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcfg: ['M', 'M', 200, 200]\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tconst2: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdecay: 0.25\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdrop_rate: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdvs_clipping: 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdvs_duration: 100000\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \te_transport_swap: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \te_transport_swap_coin: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \te_transport_swap_tr: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepoch_num: 60\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \texclude_class: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.01\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_sg_width: 2.570969004857107\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_reset: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_threshold: 1.6156404801690871\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmerge_polarities: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tscheduler_name: CosineAnnealingLR\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsurrogate: hard_sigmoid\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \twhich_data: DVS_GESTURE_TONIC\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.17.7 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.17.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/nfs/home/bhkim003/github_folder/ByeonghyeonKim/my_snn/wandb/run-20240822_181118-26tf7m2y</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/26tf7m2y' target=\"_blank\">ethereal-sweep-26</a></strong> to <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/yxynyr6h' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/yxynyr6h</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/yxynyr6h' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/yxynyr6h</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/26tf7m2y' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/26tf7m2y</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BATCH' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'IMAGE_SIZE' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'which_data' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_threshold' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_reset' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_sg_width' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'cfg' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'learning_rate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'epoch_num' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'surrogate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'scheduler_name' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'dvs_clipping' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'dvs_duration' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'OTTT_sWS_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'DFA_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'OTTT_input_trace_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'e_transport_swap' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'e_transport_swap_tr' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'e_transport_swap_coin' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'drop_rate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'exclude_class' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'merge_polarities' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'TIME' was locked by 'sweep' (ignored update).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset_hash = 2bbd58b4e0d3c1e9ad501fad8a43feed\n",
      "cache path exists\n",
      "\n",
      "we will exclude the 'other' class. dvsgestrue 10 classes' indices exist. \n",
      "\n",
      "DataParallel(\n",
      "  (module): MY_SNN_FC_sstep(\n",
      "    (layers): MY_Sequential(\n",
      "      (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (2): DimChanger_for_FC_sstep()\n",
      "      (3): SYNAPSE_FC_trace_sstep()\n",
      "      (4): LIF_layer_trace_sstep()\n",
      "      (5): SYNAPSE_FC_trace_sstep()\n",
      "      (6): LIF_layer_trace_sstep()\n",
      "      (7): SYNAPSE_FC_trace_sstep()\n",
      "    )\n",
      "  )\n",
      ")\n",
      "==================================================\n",
      "My Num of PARAMS: 452,010, system's param_num : 452,010\n",
      "Memory: 1.72MiB at 32-bit\n",
      "==================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch-0   lr=['0.0100000'], tr/val_loss:  2.317507/  2.316367, tr:   9.70%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:06<00:00,  9.10it/s]\n",
      "epoch-1   lr=['0.0099931'], tr/val_loss:  2.316254/  2.314931, tr:  10.21%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:06<00:00,  9.39it/s]\n",
      "epoch-2   lr=['0.0099726'], tr/val_loss:  2.315321/  2.315877, tr:   9.81%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:06<00:00,  9.07it/s]\n",
      "epoch-3   lr=['0.0099384'], tr/val_loss:  2.319123/  2.321801, tr:  10.42%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:05<00:00, 10.50it/s]\n",
      "epoch-4   lr=['0.0098907'], tr/val_loss:  2.328817/  2.310750, tr:   7.66%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:05<00:00, 10.41it/s]\n",
      "epoch-5   lr=['0.0098296'], tr/val_loss:  2.318780/  2.313111, tr:   8.58%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:05<00:00, 10.54it/s]\n",
      "epoch-6   lr=['0.0097553'], tr/val_loss:  2.326567/  2.312034, tr:   8.89%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:05<00:00, 10.48it/s]\n",
      "epoch-7   lr=['0.0096679'], tr/val_loss:  2.319906/  2.308871, tr:   8.89%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:06<00:00,  9.04it/s]\n",
      "epoch-8   lr=['0.0095677'], tr/val_loss:  2.315703/  2.318316, tr:   9.09%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:05<00:00, 11.04it/s]\n",
      "epoch-9   lr=['0.0094550'], tr/val_loss:  2.315776/  2.321137, tr:   9.81%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:06<00:00,  9.38it/s]\n",
      "epoch-10  lr=['0.0093301'], tr/val_loss:  2.319218/  2.310921, tr:   9.40%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:05<00:00, 11.15it/s]\n",
      "epoch-11  lr=['0.0091934'], tr/val_loss:  2.320658/  2.318817, tr:   9.60%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:05<00:00, 11.19it/s]\n",
      "epoch-12  lr=['0.0090451'], tr/val_loss:  2.323760/  2.306959, tr:   9.70%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:05<00:00, 11.60it/s]\n",
      "epoch-13  lr=['0.0088857'], tr/val_loss:  2.312257/  2.313825, tr:   8.78%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:04<00:00, 12.72it/s]\n",
      "epoch-14  lr=['0.0087157'], tr/val_loss:  2.321870/  2.310401, tr:   9.70%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:07<00:00,  8.22it/s]\n",
      "epoch-15  lr=['0.0085355'], tr/val_loss:  2.318407/  2.313874, tr:   9.60%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:06<00:00, 10.31it/s]\n",
      "epoch-16  lr=['0.0083457'], tr/val_loss:  2.317499/  2.312321, tr:  10.11%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:05<00:00, 10.38it/s]\n",
      "epoch-17  lr=['0.0081466'], tr/val_loss:  2.318669/  2.307941, tr:   8.89%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:06<00:00,  9.63it/s]\n",
      "epoch-18  lr=['0.0079389'], tr/val_loss:  2.325135/  2.306585, tr:   7.46%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:06<00:00,  9.29it/s]\n",
      "epoch-19  lr=['0.0077232'], tr/val_loss:  2.314244/  2.310251, tr:  10.01%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:05<00:00, 10.36it/s]\n",
      "epoch-20  lr=['0.0075000'], tr/val_loss:  2.312182/  2.307967, tr:   9.91%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:06<00:00, 10.23it/s]\n",
      "epoch-21  lr=['0.0072700'], tr/val_loss:  2.318818/  2.307295, tr:   9.30%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:06<00:00,  9.65it/s]\n",
      "epoch-22  lr=['0.0070337'], tr/val_loss:  2.313441/  2.307399, tr:   9.91%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:05<00:00, 10.75it/s]\n",
      "epoch-23  lr=['0.0067918'], tr/val_loss:  2.314248/  2.309416, tr:   7.76%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:05<00:00, 11.57it/s]\n",
      "epoch-24  lr=['0.0065451'], tr/val_loss:  2.318841/  2.305136, tr:   9.09%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:05<00:00, 11.48it/s]\n",
      "epoch-25  lr=['0.0062941'], tr/val_loss:  2.316903/  2.306750, tr:   7.97%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:05<00:00, 10.79it/s]\n",
      "epoch-26  lr=['0.0060396'], tr/val_loss:  2.311055/  2.305107, tr:   8.99%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:06<00:00,  9.61it/s]\n",
      "epoch-27  lr=['0.0057822'], tr/val_loss:  2.313828/  2.306802, tr:   8.58%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:06<00:00, 10.08it/s]\n",
      "epoch-28  lr=['0.0055226'], tr/val_loss:  2.315332/  2.308450, tr:   8.68%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:07<00:00,  8.77it/s]\n",
      "epoch-29  lr=['0.0052617'], tr/val_loss:  2.315842/  2.306032, tr:   7.15%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:06<00:00, 10.27it/s]\n",
      "epoch-30  lr=['0.0050000'], tr/val_loss:  2.312570/  2.303939, tr:   8.89%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:06<00:00,  9.56it/s]\n",
      "epoch-31  lr=['0.0047383'], tr/val_loss:  2.309263/  2.303903, tr:   9.09%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:05<00:00, 10.86it/s]\n",
      "epoch-32  lr=['0.0044774'], tr/val_loss:  2.311847/  2.302894, tr:   8.38%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:06<00:00,  9.80it/s]\n",
      "epoch-33  lr=['0.0042178'], tr/val_loss:  2.308722/  2.303530, tr:   9.50%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:05<00:00, 11.19it/s]\n",
      "epoch-34  lr=['0.0039604'], tr/val_loss:  2.313000/  2.304187, tr:   8.48%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:06<00:00,  9.79it/s]\n",
      "epoch-35  lr=['0.0037059'], tr/val_loss:  2.309877/  2.303538, tr:   9.09%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:06<00:00, 10.32it/s]\n",
      "epoch-36  lr=['0.0034549'], tr/val_loss:  2.309406/  2.303601, tr:   8.99%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:06<00:00,  9.51it/s]\n",
      "epoch-37  lr=['0.0032082'], tr/val_loss:  2.309686/  2.303400, tr:   7.66%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:06<00:00,  9.77it/s]\n",
      "epoch-38  lr=['0.0029663'], tr/val_loss:  2.308588/  2.303166, tr:   9.09%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:06<00:00,  9.43it/s]\n",
      "epoch-39  lr=['0.0027300'], tr/val_loss:  2.308727/  2.302884, tr:   8.89%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:05<00:00, 11.71it/s]\n",
      "epoch-40  lr=['0.0025000'], tr/val_loss:  2.308749/  2.302732, tr:   9.40%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:05<00:00, 10.98it/s]\n",
      "epoch-41  lr=['0.0022768'], tr/val_loss:  2.306803/  2.302942, tr:   9.19%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:06<00:00,  9.48it/s]\n",
      "epoch-42  lr=['0.0020611'], tr/val_loss:  2.306347/  2.302762, tr:   8.68%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:05<00:00, 11.10it/s]\n",
      "epoch-43  lr=['0.0018534'], tr/val_loss:  2.305991/  2.302857, tr:   8.99%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:05<00:00, 10.85it/s]\n",
      "epoch-44  lr=['0.0016543'], tr/val_loss:  2.305293/  2.302853, tr:  10.01%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:06<00:00,  9.41it/s]\n",
      "epoch-45  lr=['0.0014645'], tr/val_loss:  2.306396/  2.302847, tr:   8.48%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:06<00:00,  9.74it/s]\n",
      "epoch-46  lr=['0.0012843'], tr/val_loss:  2.305307/  2.302670, tr:  10.01%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:05<00:00, 10.94it/s]\n",
      "epoch-47  lr=['0.0011143'], tr/val_loss:  2.305197/  2.302644, tr:   9.30%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:05<00:00, 10.65it/s]\n",
      "epoch-48  lr=['0.0009549'], tr/val_loss:  2.304637/  2.302745, tr:   8.78%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:05<00:00, 11.47it/s]\n",
      "epoch-49  lr=['0.0008066'], tr/val_loss:  2.304113/  2.302645, tr:   8.89%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:06<00:00,  9.54it/s]\n",
      "epoch-50  lr=['0.0006699'], tr/val_loss:  2.304358/  2.302700, tr:   8.68%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:06<00:00,  9.64it/s]\n",
      "epoch-51  lr=['0.0005450'], tr/val_loss:  2.303610/  2.302717, tr:   9.81%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:06<00:00, 10.21it/s]\n",
      "epoch-52  lr=['0.0004323'], tr/val_loss:  2.303667/  2.302626, tr:   9.30%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:06<00:00,  9.11it/s]\n",
      "epoch-53  lr=['0.0003321'], tr/val_loss:  2.303300/  2.302634, tr:   9.19%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:05<00:00, 11.70it/s]\n",
      "epoch-54  lr=['0.0002447'], tr/val_loss:  2.303030/  2.302622, tr:   8.38%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:06<00:00,  9.76it/s]\n",
      "epoch-55  lr=['0.0001704'], tr/val_loss:  2.303107/  2.302625, tr:  10.01%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:06<00:00,  9.36it/s]\n",
      "epoch-56  lr=['0.0001093'], tr/val_loss:  2.302886/  2.302609, tr:  10.01%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:06<00:00,  8.96it/s]\n",
      "epoch-57  lr=['0.0000616'], tr/val_loss:  2.302670/  2.302610, tr:  10.01%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:06<00:00, 10.14it/s]\n",
      "epoch-58  lr=['0.0000274'], tr/val_loss:  2.302685/  2.302609, tr:  10.01%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:07<00:00,  8.68it/s]\n",
      "epoch-59  lr=['0.0000069'], tr/val_loss:  2.302528/  2.302609, tr:  10.01%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:05<00:00, 11.53it/s]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "60e756d25d7a4f55898d82d8bdc18223",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='1.937 MB of 1.937 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>DFA_flag</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>epoch</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇████</td></tr><tr><td>iter_acc</td><td>▁█▅▅▃▁▅█▆▃▆▅▃▃▁▃▃▃▁▁▁▁▆▅▁▃▁▅▃▅▃▅▃▃▅▅▁▃▅█</td></tr><tr><td>summary_val_acc</td><td>▁███████████████████████████████████████</td></tr><tr><td>tr_acc</td><td>▁███▇▇▇█▇███▇███▆▆▇▇▆▇▇▇▇▆▇▇▇▇██▇▇█▇▇███</td></tr><tr><td>tr_epoch_loss</td><td>▁███████████████████████████████████████</td></tr><tr><td>val_acc_best</td><td>▁███████████████████████████████████████</td></tr><tr><td>val_acc_now</td><td>▁███████████████████████████████████████</td></tr><tr><td>val_loss</td><td>▁███████████████████████████████████████</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>DFA_flag</td><td>0.0</td></tr><tr><td>epoch</td><td>59</td></tr><tr><td>iter_acc</td><td>0.33333</td></tr><tr><td>tr_acc</td><td>0.1001</td></tr><tr><td>tr_epoch_loss</td><td>2.30253</td></tr><tr><td>val_acc_best</td><td>0.1</td></tr><tr><td>val_acc_now</td><td>0.1</td></tr><tr><td>val_loss</td><td>2.30261</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">ethereal-sweep-26</strong> at: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/26tf7m2y' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/26tf7m2y</a><br/> View project at: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main</a><br/>Synced 7 W&B file(s), 0 media file(s), 0 artifact file(s) and 1 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20240822_181118-26tf7m2y/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require(\"core\")`! See https://wandb.me/wandb-core for more information."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: sfm3uu9m with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBATCH: 16\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tDFA_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tIMAGE_SIZE: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tOTTT_input_trace_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tOTTT_sWS_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tTIME: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcfg: ['M', 'M', 200, 200]\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tconst2: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdecay: 0.25\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdrop_rate: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdvs_clipping: 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdvs_duration: 100000\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \te_transport_swap: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \te_transport_swap_coin: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \te_transport_swap_tr: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepoch_num: 60\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \texclude_class: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.01\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_sg_width: 2.570969004857107\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_reset: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_threshold: 2.1708646967578407\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmerge_polarities: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tscheduler_name: CosineAnnealingLR\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsurrogate: hard_sigmoid\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \twhich_data: DVS_GESTURE_TONIC\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.17.7 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.17.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/nfs/home/bhkim003/github_folder/ByeonghyeonKim/my_snn/wandb/run-20240822_181759-sfm3uu9m</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/sfm3uu9m' target=\"_blank\">hearty-sweep-29</a></strong> to <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/yxynyr6h' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/yxynyr6h</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/yxynyr6h' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/yxynyr6h</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/sfm3uu9m' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/sfm3uu9m</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BATCH' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'IMAGE_SIZE' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'which_data' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_threshold' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_reset' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_sg_width' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'cfg' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'learning_rate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'epoch_num' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'surrogate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'scheduler_name' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'dvs_clipping' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'dvs_duration' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'OTTT_sWS_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'DFA_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'OTTT_input_trace_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'e_transport_swap' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'e_transport_swap_tr' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'e_transport_swap_coin' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'drop_rate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'exclude_class' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'merge_polarities' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'TIME' was locked by 'sweep' (ignored update).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset_hash = 2bbd58b4e0d3c1e9ad501fad8a43feed\n",
      "cache path exists\n",
      "\n",
      "we will exclude the 'other' class. dvsgestrue 10 classes' indices exist. \n",
      "\n",
      "DataParallel(\n",
      "  (module): MY_SNN_FC_sstep(\n",
      "    (layers): MY_Sequential(\n",
      "      (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (2): DimChanger_for_FC_sstep()\n",
      "      (3): SYNAPSE_FC_trace_sstep()\n",
      "      (4): LIF_layer_trace_sstep()\n",
      "      (5): SYNAPSE_FC_trace_sstep()\n",
      "      (6): LIF_layer_trace_sstep()\n",
      "      (7): SYNAPSE_FC_trace_sstep()\n",
      "    )\n",
      "  )\n",
      ")\n",
      "==================================================\n",
      "My Num of PARAMS: 452,010, system's param_num : 452,010\n",
      "Memory: 1.72MiB at 32-bit\n",
      "==================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch-0   lr=['0.0100000'], tr/val_loss:  2.317507/  2.316367, tr:   9.70%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:06<00:00,  9.26it/s]\n",
      "epoch-1   lr=['0.0099931'], tr/val_loss:  2.316254/  2.314931, tr:  10.21%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:06<00:00,  8.99it/s]\n",
      "epoch-2   lr=['0.0099726'], tr/val_loss:  2.315321/  2.315877, tr:   9.81%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:06<00:00,  9.92it/s]\n",
      "epoch-3   lr=['0.0099384'], tr/val_loss:  2.319123/  2.321801, tr:  10.42%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:06<00:00,  9.05it/s]\n",
      "epoch-4   lr=['0.0098907'], tr/val_loss:  2.328817/  2.310750, tr:   7.66%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:05<00:00, 10.52it/s]\n",
      "epoch-5   lr=['0.0098296'], tr/val_loss:  2.318780/  2.313111, tr:   8.58%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:07<00:00,  8.83it/s]\n",
      "epoch-6   lr=['0.0097553'], tr/val_loss:  2.326567/  2.312034, tr:   8.89%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:06<00:00, 10.19it/s]\n",
      "epoch-7   lr=['0.0096679'], tr/val_loss:  2.319906/  2.308871, tr:   8.89%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:06<00:00,  9.85it/s]\n",
      "epoch-8   lr=['0.0095677'], tr/val_loss:  2.315703/  2.318316, tr:   9.09%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:06<00:00,  9.82it/s]\n",
      "epoch-9   lr=['0.0094550'], tr/val_loss:  2.315776/  2.321137, tr:   9.81%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:10<00:00,  5.64it/s]\n",
      "epoch-10  lr=['0.0093301'], tr/val_loss:  2.319218/  2.310921, tr:   9.40%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:14<00:00,  4.15it/s]\n",
      "epoch-11  lr=['0.0091934'], tr/val_loss:  2.320658/  2.318817, tr:   9.60%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:07<00:00,  8.19it/s]\n",
      "epoch-12  lr=['0.0090451'], tr/val_loss:  2.323760/  2.306959, tr:   9.70%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:06<00:00,  9.17it/s]\n",
      "epoch-13  lr=['0.0088857'], tr/val_loss:  2.312257/  2.313825, tr:   8.78%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:06<00:00,  9.96it/s]\n",
      "epoch-14  lr=['0.0087157'], tr/val_loss:  2.321870/  2.310401, tr:   9.70%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:15<00:00,  4.01it/s]\n",
      "epoch-15  lr=['0.0085355'], tr/val_loss:  2.318407/  2.313874, tr:   9.60%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:11<00:00,  5.24it/s]\n",
      "epoch-16  lr=['0.0083457'], tr/val_loss:  2.317499/  2.312321, tr:  10.11%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:05<00:00, 11.01it/s]\n",
      "epoch-17  lr=['0.0081466'], tr/val_loss:  2.318669/  2.307941, tr:   8.89%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:06<00:00, 10.32it/s]\n",
      "epoch-18  lr=['0.0079389'], tr/val_loss:  2.325135/  2.306585, tr:   7.46%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:06<00:00,  9.53it/s]\n",
      "epoch-19  lr=['0.0077232'], tr/val_loss:  2.314244/  2.310251, tr:  10.01%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:15<00:00,  3.99it/s]\n",
      "epoch-20  lr=['0.0075000'], tr/val_loss:  2.312182/  2.307967, tr:   9.91%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:13<00:00,  4.48it/s]\n",
      "epoch-21  lr=['0.0072700'], tr/val_loss:  2.318818/  2.307295, tr:   9.30%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:09<00:00,  6.88it/s]\n",
      "epoch-22  lr=['0.0070337'], tr/val_loss:  2.313441/  2.307399, tr:   9.91%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:06<00:00, 10.28it/s]\n",
      "epoch-23  lr=['0.0067918'], tr/val_loss:  2.314248/  2.309416, tr:   7.76%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:06<00:00,  9.90it/s]\n",
      "epoch-24  lr=['0.0065451'], tr/val_loss:  2.318841/  2.305136, tr:   9.09%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:09<00:00,  6.66it/s]\n",
      "epoch-25  lr=['0.0062941'], tr/val_loss:  2.316903/  2.306750, tr:   7.97%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:15<00:00,  4.10it/s]\n",
      "epoch-26  lr=['0.0060396'], tr/val_loss:  2.311055/  2.305107, tr:   8.99%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:18<00:00,  3.40it/s]\n",
      "epoch-27  lr=['0.0057822'], tr/val_loss:  2.313828/  2.306802, tr:   8.58%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:07<00:00,  8.04it/s]\n",
      "epoch-28  lr=['0.0055226'], tr/val_loss:  2.315332/  2.308450, tr:   8.68%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:07<00:00,  7.84it/s]\n",
      "epoch-29  lr=['0.0052617'], tr/val_loss:  2.315842/  2.306032, tr:   7.15%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:06<00:00,  9.35it/s]\n",
      "epoch-30  lr=['0.0050000'], tr/val_loss:  2.312570/  2.303939, tr:   8.89%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:10<00:00,  6.02it/s]\n",
      "epoch-31  lr=['0.0047383'], tr/val_loss:  2.309263/  2.303903, tr:   9.09%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:14<00:00,  4.19it/s]\n",
      "epoch-32  lr=['0.0044774'], tr/val_loss:  2.311847/  2.302894, tr:   8.38%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:18<00:00,  3.44it/s]\n",
      "epoch-33  lr=['0.0042178'], tr/val_loss:  2.308722/  2.303530, tr:   9.50%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:12<00:00,  4.83it/s]\n",
      "epoch-34  lr=['0.0039604'], tr/val_loss:  2.313000/  2.304187, tr:   8.48%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:15<00:00,  3.95it/s]\n",
      "epoch-35  lr=['0.0037059'], tr/val_loss:  2.309877/  2.303538, tr:   9.09%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:14<00:00,  4.22it/s]\n",
      "epoch-36  lr=['0.0034549'], tr/val_loss:  2.309406/  2.303601, tr:   8.99%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:14<00:00,  4.42it/s]\n",
      "epoch-37  lr=['0.0032082'], tr/val_loss:  2.309686/  2.303400, tr:   7.66%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:17<00:00,  3.62it/s]\n",
      "epoch-38  lr=['0.0029663'], tr/val_loss:  2.308588/  2.303166, tr:   9.09%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:18<00:00,  3.40it/s]\n",
      "epoch-39  lr=['0.0027300'], tr/val_loss:  2.308727/  2.302884, tr:   8.89%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:18<00:00,  3.42it/s]\n",
      "epoch-40  lr=['0.0025000'], tr/val_loss:  2.308749/  2.302732, tr:   9.40%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:15<00:00,  4.12it/s]\n",
      "epoch-41  lr=['0.0022768'], tr/val_loss:  2.306803/  2.302942, tr:   9.19%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:17<00:00,  3.51it/s]\n",
      "epoch-42  lr=['0.0020611'], tr/val_loss:  2.306347/  2.302762, tr:   8.68%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:16<00:00,  3.80it/s]\n",
      "epoch-43  lr=['0.0018534'], tr/val_loss:  2.305991/  2.302857, tr:   8.99%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:18<00:00,  3.34it/s]\n",
      "epoch-44  lr=['0.0016543'], tr/val_loss:  2.305293/  2.302853, tr:  10.01%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:20<00:00,  3.09it/s]\n",
      "epoch-45  lr=['0.0014645'], tr/val_loss:  2.306396/  2.302847, tr:   8.48%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:14<00:00,  4.32it/s]\n",
      "epoch-46  lr=['0.0012843'], tr/val_loss:  2.305307/  2.302670, tr:  10.01%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:17<00:00,  3.56it/s]\n",
      "epoch-47  lr=['0.0011143'], tr/val_loss:  2.305197/  2.302644, tr:   9.30%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:19<00:00,  3.22it/s]\n",
      "epoch-48  lr=['0.0009549'], tr/val_loss:  2.304637/  2.302745, tr:   8.78%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:15<00:00,  4.10it/s]\n",
      "epoch-49  lr=['0.0008066'], tr/val_loss:  2.304113/  2.302645, tr:   8.89%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:15<00:00,  3.92it/s]\n",
      "epoch-50  lr=['0.0006699'], tr/val_loss:  2.304358/  2.302700, tr:   8.68%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:15<00:00,  3.94it/s]\n",
      "epoch-51  lr=['0.0005450'], tr/val_loss:  2.303610/  2.302717, tr:   9.81%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:16<00:00,  3.84it/s]\n",
      "epoch-52  lr=['0.0004323'], tr/val_loss:  2.303667/  2.302626, tr:   9.30%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:17<00:00,  3.48it/s]\n",
      "epoch-53  lr=['0.0003321'], tr/val_loss:  2.303300/  2.302634, tr:   9.19%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:16<00:00,  3.76it/s]\n",
      "epoch-54  lr=['0.0002447'], tr/val_loss:  2.303030/  2.302622, tr:   8.38%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:21<00:00,  2.91it/s]\n",
      "epoch-55  lr=['0.0001704'], tr/val_loss:  2.303107/  2.302625, tr:  10.01%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:18<00:00,  3.29it/s]\n",
      "epoch-56  lr=['0.0001093'], tr/val_loss:  2.302886/  2.302609, tr:  10.01%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:22<00:00,  2.70it/s]\n",
      "epoch-57  lr=['0.0000616'], tr/val_loss:  2.302670/  2.302610, tr:  10.01%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:19<00:00,  3.20it/s]\n",
      "epoch-58  lr=['0.0000274'], tr/val_loss:  2.302685/  2.302609, tr:  10.01%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:19<00:00,  3.25it/s]\n",
      "epoch-59  lr=['0.0000069'], tr/val_loss:  2.302528/  2.302609, tr:  10.01%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:24<00:00,  2.57it/s]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "285525d81bdc4d0594f752fd77838c75",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='1.937 MB of 1.937 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>DFA_flag</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>epoch</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇████</td></tr><tr><td>iter_acc</td><td>▁█▅▅▃▁▅█▆▃▆▅▃▃▁▃▃▃▁▁▁▁▆▅▁▃▁▅▃▅▃▅▃▃▅▅▁▃▅█</td></tr><tr><td>summary_val_acc</td><td>▁███████████████████████████████████████</td></tr><tr><td>tr_acc</td><td>▁███▇▇▇█▇███▇███▆▆▇▇▆▇▇▇▇▆▇▇▇▇██▇▇█▇▇███</td></tr><tr><td>tr_epoch_loss</td><td>▁███████████████████████████████████████</td></tr><tr><td>val_acc_best</td><td>▁███████████████████████████████████████</td></tr><tr><td>val_acc_now</td><td>▁███████████████████████████████████████</td></tr><tr><td>val_loss</td><td>▁███████████████████████████████████████</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>DFA_flag</td><td>0.0</td></tr><tr><td>epoch</td><td>59</td></tr><tr><td>iter_acc</td><td>0.33333</td></tr><tr><td>tr_acc</td><td>0.1001</td></tr><tr><td>tr_epoch_loss</td><td>2.30253</td></tr><tr><td>val_acc_best</td><td>0.1</td></tr><tr><td>val_acc_now</td><td>0.1</td></tr><tr><td>val_loss</td><td>2.30261</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">hearty-sweep-29</strong> at: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/sfm3uu9m' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/sfm3uu9m</a><br/> View project at: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main</a><br/>Synced 7 W&B file(s), 0 media file(s), 0 artifact file(s) and 1 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20240822_181759-sfm3uu9m/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require(\"core\")`! See https://wandb.me/wandb-core for more information."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: yz6djyb2 with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBATCH: 16\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tDFA_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tIMAGE_SIZE: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tOTTT_input_trace_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tOTTT_sWS_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tTIME: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcfg: ['M', 'M', 200, 200]\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tconst2: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdecay: 0.25\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdrop_rate: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdvs_clipping: 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdvs_duration: 100000\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \te_transport_swap: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \te_transport_swap_coin: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \te_transport_swap_tr: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepoch_num: 60\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \texclude_class: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.01\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_sg_width: 2.570969004857107\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_reset: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_threshold: 0.9138700906779051\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmerge_polarities: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tscheduler_name: CosineAnnealingLR\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsurrogate: hard_sigmoid\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \twhich_data: DVS_GESTURE_TONIC\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.17.7 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.17.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/nfs/home/bhkim003/github_folder/ByeonghyeonKim/my_snn/wandb/run-20240822_183137-yz6djyb2</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/yz6djyb2' target=\"_blank\">fluent-sweep-32</a></strong> to <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/yxynyr6h' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/yxynyr6h</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/yxynyr6h' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/yxynyr6h</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/yz6djyb2' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/yz6djyb2</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BATCH' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'IMAGE_SIZE' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'which_data' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_threshold' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_reset' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_sg_width' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'cfg' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'learning_rate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'epoch_num' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'surrogate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'scheduler_name' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'dvs_clipping' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'dvs_duration' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'OTTT_sWS_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'DFA_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'OTTT_input_trace_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'e_transport_swap' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'e_transport_swap_tr' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'e_transport_swap_coin' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'drop_rate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'exclude_class' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'merge_polarities' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'TIME' was locked by 'sweep' (ignored update).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset_hash = 2bbd58b4e0d3c1e9ad501fad8a43feed\n",
      "cache path exists\n",
      "\n",
      "we will exclude the 'other' class. dvsgestrue 10 classes' indices exist. \n",
      "\n",
      "DataParallel(\n",
      "  (module): MY_SNN_FC_sstep(\n",
      "    (layers): MY_Sequential(\n",
      "      (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (2): DimChanger_for_FC_sstep()\n",
      "      (3): SYNAPSE_FC_trace_sstep()\n",
      "      (4): LIF_layer_trace_sstep()\n",
      "      (5): SYNAPSE_FC_trace_sstep()\n",
      "      (6): LIF_layer_trace_sstep()\n",
      "      (7): SYNAPSE_FC_trace_sstep()\n",
      "    )\n",
      "  )\n",
      ")\n",
      "==================================================\n",
      "My Num of PARAMS: 452,010, system's param_num : 452,010\n",
      "Memory: 1.72MiB at 32-bit\n",
      "==================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch-0   lr=['0.0100000'], tr/val_loss:  1.719878/  1.357362, tr:  40.45%, val:  52.08%, val_best:  52.08%: 100%|██████████| 62/62 [00:13<00:00,  4.51it/s]\n",
      "epoch-1   lr=['0.0099931'], tr/val_loss:  1.182754/  1.328785, tr:  57.41%, val:  52.50%, val_best:  52.50%: 100%|██████████| 62/62 [00:12<00:00,  4.79it/s]\n",
      "epoch-2   lr=['0.0099726'], tr/val_loss:  1.020922/  1.215686, tr:  64.35%, val:  63.33%, val_best:  63.33%: 100%|██████████| 62/62 [00:19<00:00,  3.13it/s]\n",
      "epoch-3   lr=['0.0099384'], tr/val_loss:  0.894890/  1.186840, tr:  68.95%, val:  60.83%, val_best:  63.33%: 100%|██████████| 62/62 [00:19<00:00,  3.22it/s]\n",
      "epoch-4   lr=['0.0098907'], tr/val_loss:  0.865545/  1.184528, tr:  69.05%, val:  60.00%, val_best:  63.33%: 100%|██████████| 62/62 [00:15<00:00,  3.91it/s]\n",
      "epoch-5   lr=['0.0098296'], tr/val_loss:  0.838576/  1.287732, tr:  67.62%, val:  61.67%, val_best:  63.33%: 100%|██████████| 62/62 [00:14<00:00,  4.17it/s]\n",
      "epoch-6   lr=['0.0097553'], tr/val_loss:  0.739832/  1.131212, tr:  72.52%, val:  60.83%, val_best:  63.33%: 100%|██████████| 62/62 [00:22<00:00,  2.79it/s]\n",
      "epoch-7   lr=['0.0096679'], tr/val_loss:  0.706886/  1.352844, tr:  72.11%, val:  57.50%, val_best:  63.33%: 100%|██████████| 62/62 [00:21<00:00,  2.83it/s]\n",
      "epoch-8   lr=['0.0095677'], tr/val_loss:  0.656648/  1.228687, tr:  75.79%, val:  64.17%, val_best:  64.17%: 100%|██████████| 62/62 [00:10<00:00,  6.14it/s]\n",
      "epoch-9   lr=['0.0094550'], tr/val_loss:  0.524682/  1.222476, tr:  80.49%, val:  70.42%, val_best:  70.42%: 100%|██████████| 62/62 [00:05<00:00, 10.36it/s]\n",
      "epoch-10  lr=['0.0093301'], tr/val_loss:  0.505221/  1.261231, tr:  82.43%, val:  65.83%, val_best:  70.42%: 100%|██████████| 62/62 [00:05<00:00, 11.43it/s]\n",
      "epoch-11  lr=['0.0091934'], tr/val_loss:  0.479180/  1.424238, tr:  82.12%, val:  64.58%, val_best:  70.42%: 100%|██████████| 62/62 [00:11<00:00,  5.62it/s]\n",
      "epoch-12  lr=['0.0090451'], tr/val_loss:  0.470766/  1.306889, tr:  84.68%, val:  71.67%, val_best:  71.67%: 100%|██████████| 62/62 [00:05<00:00, 11.15it/s]\n",
      "epoch-13  lr=['0.0088857'], tr/val_loss:  0.419905/  1.425607, tr:  88.15%, val:  67.92%, val_best:  71.67%: 100%|██████████| 62/62 [00:07<00:00,  8.66it/s]\n",
      "epoch-14  lr=['0.0087157'], tr/val_loss:  0.398762/  1.299950, tr:  89.79%, val:  70.00%, val_best:  71.67%: 100%|██████████| 62/62 [00:05<00:00, 10.65it/s]\n",
      "epoch-15  lr=['0.0085355'], tr/val_loss:  0.361261/  1.240687, tr:  92.65%, val:  73.33%, val_best:  73.33%: 100%|██████████| 62/62 [00:06<00:00,  9.63it/s]\n",
      "epoch-16  lr=['0.0083457'], tr/val_loss:  0.306971/  1.467487, tr:  93.97%, val:  70.00%, val_best:  73.33%: 100%|██████████| 62/62 [00:08<00:00,  7.48it/s]\n",
      "epoch-17  lr=['0.0081466'], tr/val_loss:  0.288205/  1.390859, tr:  94.69%, val:  71.25%, val_best:  73.33%: 100%|██████████| 62/62 [00:06<00:00,  9.91it/s]\n",
      "epoch-18  lr=['0.0079389'], tr/val_loss:  0.259141/  1.256888, tr:  93.05%, val:  77.92%, val_best:  77.92%: 100%|██████████| 62/62 [00:06<00:00, 10.15it/s]\n",
      "epoch-19  lr=['0.0077232'], tr/val_loss:  0.196615/  1.399784, tr:  98.26%, val:  77.08%, val_best:  77.92%: 100%|██████████| 62/62 [00:08<00:00,  7.11it/s]\n",
      "epoch-20  lr=['0.0075000'], tr/val_loss:  0.194682/  1.504215, tr:  98.47%, val:  72.50%, val_best:  77.92%: 100%|██████████| 62/62 [00:06<00:00,  9.92it/s]\n",
      "epoch-21  lr=['0.0072700'], tr/val_loss:  0.127727/  1.495890, tr:  99.39%, val:  75.00%, val_best:  77.92%: 100%|██████████| 62/62 [00:05<00:00, 12.01it/s]\n",
      "epoch-22  lr=['0.0070337'], tr/val_loss:  0.127110/  1.427155, tr:  97.85%, val:  75.83%, val_best:  77.92%: 100%|██████████| 62/62 [00:05<00:00, 12.07it/s]\n",
      "epoch-23  lr=['0.0067918'], tr/val_loss:  0.074957/  1.526851, tr:  99.90%, val:  75.42%, val_best:  77.92%: 100%|██████████| 62/62 [00:05<00:00, 10.46it/s]\n",
      "epoch-24  lr=['0.0065451'], tr/val_loss:  0.073069/  1.628020, tr:  99.90%, val:  73.33%, val_best:  77.92%: 100%|██████████| 62/62 [00:08<00:00,  7.23it/s]\n",
      "epoch-25  lr=['0.0062941'], tr/val_loss:  0.066498/  1.573175, tr:  99.90%, val:  76.67%, val_best:  77.92%: 100%|██████████| 62/62 [00:06<00:00, 10.26it/s]\n",
      "epoch-26  lr=['0.0060396'], tr/val_loss:  0.031692/  1.567639, tr: 100.00%, val:  78.75%, val_best:  78.75%: 100%|██████████| 62/62 [00:06<00:00,  9.35it/s]\n",
      "epoch-27  lr=['0.0057822'], tr/val_loss:  0.018764/  1.600565, tr: 100.00%, val:  77.50%, val_best:  78.75%: 100%|██████████| 62/62 [00:06<00:00,  9.43it/s]\n",
      "epoch-28  lr=['0.0055226'], tr/val_loss:  0.013533/  1.656403, tr: 100.00%, val:  78.33%, val_best:  78.75%: 100%|██████████| 62/62 [00:13<00:00,  4.71it/s]\n",
      "epoch-29  lr=['0.0052617'], tr/val_loss:  0.009643/  1.641003, tr: 100.00%, val:  79.17%, val_best:  79.17%: 100%|██████████| 62/62 [00:07<00:00,  8.58it/s]\n",
      "epoch-30  lr=['0.0050000'], tr/val_loss:  0.006532/  1.673498, tr: 100.00%, val:  80.00%, val_best:  80.00%: 100%|██████████| 62/62 [00:06<00:00,  9.49it/s]\n",
      "epoch-31  lr=['0.0047383'], tr/val_loss:  0.005316/  1.659192, tr: 100.00%, val:  79.58%, val_best:  80.00%: 100%|██████████| 62/62 [00:06<00:00, 10.29it/s]\n",
      "epoch-32  lr=['0.0044774'], tr/val_loss:  0.004324/  1.690113, tr: 100.00%, val:  77.50%, val_best:  80.00%: 100%|██████████| 62/62 [00:06<00:00, 10.00it/s]\n",
      "epoch-33  lr=['0.0042178'], tr/val_loss:  0.003228/  1.713007, tr: 100.00%, val:  78.33%, val_best:  80.00%: 100%|██████████| 62/62 [00:05<00:00, 10.48it/s]\n",
      "epoch-34  lr=['0.0039604'], tr/val_loss:  0.003062/  1.715825, tr: 100.00%, val:  78.33%, val_best:  80.00%: 100%|██████████| 62/62 [00:07<00:00,  8.23it/s]\n",
      "epoch-35  lr=['0.0037059'], tr/val_loss:  0.002970/  1.710959, tr: 100.00%, val:  77.50%, val_best:  80.00%: 100%|██████████| 62/62 [00:07<00:00,  8.28it/s]\n",
      "epoch-36  lr=['0.0034549'], tr/val_loss:  0.002621/  1.713212, tr: 100.00%, val:  77.92%, val_best:  80.00%: 100%|██████████| 62/62 [00:12<00:00,  4.97it/s]\n",
      "epoch-37  lr=['0.0032082'], tr/val_loss:  0.002344/  1.725630, tr: 100.00%, val:  78.75%, val_best:  80.00%: 100%|██████████| 62/62 [00:05<00:00, 10.54it/s]\n",
      "epoch-38  lr=['0.0029663'], tr/val_loss:  0.002117/  1.723314, tr: 100.00%, val:  77.92%, val_best:  80.00%: 100%|██████████| 62/62 [00:05<00:00, 10.35it/s]\n",
      "epoch-39  lr=['0.0027300'], tr/val_loss:  0.002044/  1.717889, tr: 100.00%, val:  78.33%, val_best:  80.00%: 100%|██████████| 62/62 [00:07<00:00,  8.47it/s]\n",
      "epoch-40  lr=['0.0025000'], tr/val_loss:  0.001947/  1.724331, tr: 100.00%, val:  77.92%, val_best:  80.00%: 100%|██████████| 62/62 [00:06<00:00,  9.18it/s]\n",
      "epoch-41  lr=['0.0022768'], tr/val_loss:  0.001887/  1.745935, tr: 100.00%, val:  77.50%, val_best:  80.00%: 100%|██████████| 62/62 [00:06<00:00,  9.36it/s]\n",
      "epoch-42  lr=['0.0020611'], tr/val_loss:  0.001869/  1.750200, tr: 100.00%, val:  78.33%, val_best:  80.00%: 100%|██████████| 62/62 [00:06<00:00,  9.51it/s]\n",
      "epoch-43  lr=['0.0018534'], tr/val_loss:  0.001751/  1.749990, tr: 100.00%, val:  78.33%, val_best:  80.00%: 100%|██████████| 62/62 [00:06<00:00,  9.15it/s]\n",
      "epoch-44  lr=['0.0016543'], tr/val_loss:  0.001685/  1.752177, tr: 100.00%, val:  77.92%, val_best:  80.00%: 100%|██████████| 62/62 [00:11<00:00,  5.54it/s]\n",
      "epoch-45  lr=['0.0014645'], tr/val_loss:  0.001650/  1.752260, tr: 100.00%, val:  78.33%, val_best:  80.00%: 100%|██████████| 62/62 [00:05<00:00, 10.33it/s]\n",
      "epoch-46  lr=['0.0012843'], tr/val_loss:  0.001641/  1.760240, tr: 100.00%, val:  77.50%, val_best:  80.00%: 100%|██████████| 62/62 [00:06<00:00,  9.38it/s]\n",
      "epoch-47  lr=['0.0011143'], tr/val_loss:  0.001624/  1.764392, tr: 100.00%, val:  77.50%, val_best:  80.00%: 100%|██████████| 62/62 [00:05<00:00, 10.39it/s]\n",
      "epoch-48  lr=['0.0009549'], tr/val_loss:  0.001623/  1.766378, tr: 100.00%, val:  77.92%, val_best:  80.00%: 100%|██████████| 62/62 [00:08<00:00,  7.43it/s]\n",
      "epoch-49  lr=['0.0008066'], tr/val_loss:  0.001598/  1.769737, tr: 100.00%, val:  77.92%, val_best:  80.00%: 100%|██████████| 62/62 [00:06<00:00,  8.95it/s]\n",
      "epoch-50  lr=['0.0006699'], tr/val_loss:  0.001615/  1.769110, tr: 100.00%, val:  77.92%, val_best:  80.00%: 100%|██████████| 62/62 [00:09<00:00,  6.48it/s]\n",
      "epoch-51  lr=['0.0005450'], tr/val_loss:  0.001561/  1.767323, tr: 100.00%, val:  77.92%, val_best:  80.00%: 100%|██████████| 62/62 [00:13<00:00,  4.54it/s]\n",
      "epoch-52  lr=['0.0004323'], tr/val_loss:  0.001563/  1.766124, tr: 100.00%, val:  77.50%, val_best:  80.00%: 100%|██████████| 62/62 [00:06<00:00, 10.19it/s]\n",
      "epoch-53  lr=['0.0003321'], tr/val_loss:  0.001562/  1.763316, tr: 100.00%, val:  77.50%, val_best:  80.00%: 100%|██████████| 62/62 [00:08<00:00,  7.51it/s]\n",
      "epoch-54  lr=['0.0002447'], tr/val_loss:  0.001568/  1.762627, tr: 100.00%, val:  77.50%, val_best:  80.00%: 100%|██████████| 62/62 [00:06<00:00,  9.34it/s]\n",
      "epoch-55  lr=['0.0001704'], tr/val_loss:  0.001561/  1.764183, tr: 100.00%, val:  77.50%, val_best:  80.00%: 100%|██████████| 62/62 [00:08<00:00,  7.60it/s]\n",
      "epoch-56  lr=['0.0001093'], tr/val_loss:  0.001539/  1.764376, tr: 100.00%, val:  77.50%, val_best:  80.00%: 100%|██████████| 62/62 [00:06<00:00,  8.92it/s]\n",
      "epoch-57  lr=['0.0000616'], tr/val_loss:  0.001527/  1.764613, tr: 100.00%, val:  77.50%, val_best:  80.00%: 100%|██████████| 62/62 [00:07<00:00,  8.86it/s]\n",
      "epoch-58  lr=['0.0000274'], tr/val_loss:  0.001539/  1.764483, tr: 100.00%, val:  77.50%, val_best:  80.00%: 100%|██████████| 62/62 [00:06<00:00, 10.07it/s]\n",
      "epoch-59  lr=['0.0000069'], tr/val_loss:  0.001533/  1.764490, tr: 100.00%, val:  77.50%, val_best:  80.00%: 100%|██████████| 62/62 [00:09<00:00,  6.83it/s]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f81513e0fb68417a8c34b2f2de6ba42b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='1.929 MB of 1.929 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>DFA_flag</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>epoch</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇████</td></tr><tr><td>iter_acc</td><td>▄▂▄▁▅▅▅▆▇▆█▆▇▇██████████████████████████</td></tr><tr><td>summary_val_acc</td><td>▁▆▇▆▆▆▇▇▇▇▇▇▇█▇█████████████████████████</td></tr><tr><td>tr_acc</td><td>▁▄▆▆▆▆▆▇▇▇▇█████████████████████████████</td></tr><tr><td>tr_epoch_loss</td><td>▁█▅▅▄▄▄▃▃▃▃▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_acc_best</td><td>▁▆▇▇▇▇▇▇▇▇▇▇▇███████████████████████████</td></tr><tr><td>val_acc_now</td><td>▁▆▇▆▆▆▇▇▇▇▇▇▇█▇█████████████████████████</td></tr><tr><td>val_loss</td><td>▁▆▆▆▆▅▆▆▇▆▆▇▇▇▇▇▇▇▇█▇███████████████████</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>DFA_flag</td><td>0.0</td></tr><tr><td>epoch</td><td>59</td></tr><tr><td>iter_acc</td><td>1.0</td></tr><tr><td>tr_acc</td><td>1.0</td></tr><tr><td>tr_epoch_loss</td><td>0.00153</td></tr><tr><td>val_acc_best</td><td>0.8</td></tr><tr><td>val_acc_now</td><td>0.775</td></tr><tr><td>val_loss</td><td>1.76449</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">fluent-sweep-32</strong> at: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/yz6djyb2' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/yz6djyb2</a><br/> View project at: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main</a><br/>Synced 7 W&B file(s), 0 media file(s), 0 artifact file(s) and 1 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20240822_183137-yz6djyb2/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require(\"core\")`! See https://wandb.me/wandb-core for more information."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: vgobf82c with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBATCH: 16\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tDFA_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tIMAGE_SIZE: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tOTTT_input_trace_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tOTTT_sWS_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tTIME: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcfg: ['M', 'M', 200, 200]\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tconst2: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdecay: 0.25\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdrop_rate: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdvs_clipping: 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdvs_duration: 100000\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \te_transport_swap: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \te_transport_swap_coin: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \te_transport_swap_tr: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepoch_num: 60\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \texclude_class: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.01\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_sg_width: 2.570969004857107\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_reset: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_threshold: 1.5835566180924685\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmerge_polarities: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tscheduler_name: CosineAnnealingLR\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsurrogate: hard_sigmoid\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \twhich_data: DVS_GESTURE_TONIC\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.17.7 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.17.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/nfs/home/bhkim003/github_folder/ByeonghyeonKim/my_snn/wandb/run-20240822_184057-vgobf82c</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/vgobf82c' target=\"_blank\">swift-sweep-35</a></strong> to <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/yxynyr6h' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/yxynyr6h</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/yxynyr6h' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/yxynyr6h</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/vgobf82c' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/vgobf82c</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BATCH' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'IMAGE_SIZE' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'which_data' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_threshold' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_reset' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_sg_width' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'cfg' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'learning_rate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'epoch_num' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'surrogate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'scheduler_name' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'dvs_clipping' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'dvs_duration' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'OTTT_sWS_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'DFA_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'OTTT_input_trace_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'e_transport_swap' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'e_transport_swap_tr' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'e_transport_swap_coin' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'drop_rate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'exclude_class' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'merge_polarities' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'TIME' was locked by 'sweep' (ignored update).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset_hash = 2bbd58b4e0d3c1e9ad501fad8a43feed\n",
      "cache path exists\n",
      "\n",
      "we will exclude the 'other' class. dvsgestrue 10 classes' indices exist. \n",
      "\n",
      "DataParallel(\n",
      "  (module): MY_SNN_FC_sstep(\n",
      "    (layers): MY_Sequential(\n",
      "      (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (2): DimChanger_for_FC_sstep()\n",
      "      (3): SYNAPSE_FC_trace_sstep()\n",
      "      (4): LIF_layer_trace_sstep()\n",
      "      (5): SYNAPSE_FC_trace_sstep()\n",
      "      (6): LIF_layer_trace_sstep()\n",
      "      (7): SYNAPSE_FC_trace_sstep()\n",
      "    )\n",
      "  )\n",
      ")\n",
      "==================================================\n",
      "My Num of PARAMS: 452,010, system's param_num : 452,010\n",
      "Memory: 1.72MiB at 32-bit\n",
      "==================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch-0   lr=['0.0100000'], tr/val_loss:  2.317507/  2.316367, tr:   9.70%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:07<00:00,  8.49it/s]\n",
      "epoch-1   lr=['0.0099931'], tr/val_loss:  2.316254/  2.314931, tr:  10.21%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:06<00:00, 10.16it/s]\n",
      "epoch-2   lr=['0.0099726'], tr/val_loss:  2.315321/  2.315877, tr:   9.81%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:07<00:00,  8.71it/s]\n",
      "epoch-3   lr=['0.0099384'], tr/val_loss:  2.319123/  2.321801, tr:  10.42%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:11<00:00,  5.23it/s]\n",
      "epoch-4   lr=['0.0098907'], tr/val_loss:  2.328817/  2.310750, tr:   7.66%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:06<00:00,  9.46it/s]\n",
      "epoch-5   lr=['0.0098296'], tr/val_loss:  2.318780/  2.313111, tr:   8.58%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:06<00:00,  9.33it/s]\n",
      "epoch-6   lr=['0.0097553'], tr/val_loss:  2.326567/  2.312034, tr:   8.89%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:09<00:00,  6.73it/s]\n",
      "epoch-7   lr=['0.0096679'], tr/val_loss:  2.319906/  2.308871, tr:   8.89%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:10<00:00,  5.94it/s]\n",
      "epoch-8   lr=['0.0095677'], tr/val_loss:  2.315703/  2.318316, tr:   9.09%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:06<00:00, 10.02it/s]\n",
      "epoch-9   lr=['0.0094550'], tr/val_loss:  2.315776/  2.321137, tr:   9.81%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:05<00:00, 11.79it/s]\n",
      "epoch-10  lr=['0.0093301'], tr/val_loss:  2.319218/  2.310921, tr:   9.40%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:06<00:00,  9.96it/s]\n",
      "epoch-11  lr=['0.0091934'], tr/val_loss:  2.320658/  2.318817, tr:   9.60%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:06<00:00,  9.54it/s]\n",
      "epoch-12  lr=['0.0090451'], tr/val_loss:  2.323760/  2.306959, tr:   9.70%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:05<00:00, 10.54it/s]\n",
      "epoch-13  lr=['0.0088857'], tr/val_loss:  2.312257/  2.313825, tr:   8.78%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:07<00:00,  8.62it/s]\n",
      "epoch-14  lr=['0.0087157'], tr/val_loss:  2.321870/  2.310401, tr:   9.70%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:05<00:00, 11.77it/s]\n",
      "epoch-15  lr=['0.0085355'], tr/val_loss:  2.318407/  2.313874, tr:   9.60%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:10<00:00,  5.92it/s]\n",
      "epoch-16  lr=['0.0083457'], tr/val_loss:  2.317499/  2.312321, tr:  10.11%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:05<00:00, 10.48it/s]\n",
      "epoch-17  lr=['0.0081466'], tr/val_loss:  2.318669/  2.307941, tr:   8.89%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:06<00:00, 10.04it/s]\n",
      "epoch-18  lr=['0.0079389'], tr/val_loss:  2.325135/  2.306585, tr:   7.46%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:06<00:00, 10.28it/s]\n",
      "epoch-19  lr=['0.0077232'], tr/val_loss:  2.314244/  2.310251, tr:  10.01%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:06<00:00,  9.35it/s]\n",
      "epoch-20  lr=['0.0075000'], tr/val_loss:  2.312182/  2.307967, tr:   9.91%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:05<00:00, 12.30it/s]\n",
      "epoch-21  lr=['0.0072700'], tr/val_loss:  2.318818/  2.307295, tr:   9.30%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:04<00:00, 14.06it/s]\n",
      "epoch-22  lr=['0.0070337'], tr/val_loss:  2.313441/  2.307399, tr:   9.91%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:05<00:00, 11.25it/s]\n",
      "epoch-23  lr=['0.0067918'], tr/val_loss:  2.314248/  2.309416, tr:   7.76%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:06<00:00,  9.46it/s]\n",
      "epoch-24  lr=['0.0065451'], tr/val_loss:  2.318841/  2.305136, tr:   9.09%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:05<00:00, 10.72it/s]\n",
      "epoch-25  lr=['0.0062941'], tr/val_loss:  2.316903/  2.306750, tr:   7.97%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:05<00:00, 11.07it/s]\n",
      "epoch-26  lr=['0.0060396'], tr/val_loss:  2.311055/  2.305107, tr:   8.99%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:06<00:00, 10.27it/s]\n",
      "epoch-27  lr=['0.0057822'], tr/val_loss:  2.313828/  2.306802, tr:   8.58%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:05<00:00, 10.55it/s]\n",
      "epoch-28  lr=['0.0055226'], tr/val_loss:  2.315332/  2.308450, tr:   8.68%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:05<00:00, 10.38it/s]\n",
      "epoch-29  lr=['0.0052617'], tr/val_loss:  2.315842/  2.306032, tr:   7.15%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:06<00:00,  9.55it/s]\n",
      "epoch-30  lr=['0.0050000'], tr/val_loss:  2.312570/  2.303939, tr:   8.89%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:05<00:00, 11.98it/s]\n",
      "epoch-31  lr=['0.0047383'], tr/val_loss:  2.309263/  2.303903, tr:   9.09%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:05<00:00, 10.65it/s]\n",
      "epoch-32  lr=['0.0044774'], tr/val_loss:  2.311847/  2.302894, tr:   8.38%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:06<00:00,  9.98it/s]\n",
      "epoch-33  lr=['0.0042178'], tr/val_loss:  2.308722/  2.303530, tr:   9.50%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:06<00:00,  9.70it/s]\n",
      "epoch-34  lr=['0.0039604'], tr/val_loss:  2.313000/  2.304187, tr:   8.48%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:06<00:00, 10.08it/s]\n",
      "epoch-35  lr=['0.0037059'], tr/val_loss:  2.309877/  2.303538, tr:   9.09%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:05<00:00, 10.80it/s]\n",
      "epoch-36  lr=['0.0034549'], tr/val_loss:  2.309406/  2.303601, tr:   8.99%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:06<00:00, 10.23it/s]\n",
      "epoch-37  lr=['0.0032082'], tr/val_loss:  2.309686/  2.303400, tr:   7.66%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:05<00:00, 10.65it/s]\n",
      "epoch-38  lr=['0.0029663'], tr/val_loss:  2.308588/  2.303166, tr:   9.09%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:06<00:00,  9.99it/s]\n",
      "epoch-39  lr=['0.0027300'], tr/val_loss:  2.308727/  2.302884, tr:   8.89%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:07<00:00,  8.45it/s]\n",
      "epoch-40  lr=['0.0025000'], tr/val_loss:  2.308749/  2.302732, tr:   9.40%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:06<00:00,  9.82it/s]\n",
      "epoch-41  lr=['0.0022768'], tr/val_loss:  2.306803/  2.302942, tr:   9.19%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:06<00:00, 10.18it/s]\n",
      "epoch-42  lr=['0.0020611'], tr/val_loss:  2.306347/  2.302762, tr:   8.68%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:05<00:00, 10.60it/s]\n",
      "epoch-43  lr=['0.0018534'], tr/val_loss:  2.305991/  2.302857, tr:   8.99%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:05<00:00, 10.70it/s]\n",
      "epoch-44  lr=['0.0016543'], tr/val_loss:  2.305293/  2.302853, tr:  10.01%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:05<00:00, 10.36it/s]\n",
      "epoch-45  lr=['0.0014645'], tr/val_loss:  2.306396/  2.302847, tr:   8.48%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:05<00:00, 10.84it/s]\n",
      "epoch-46  lr=['0.0012843'], tr/val_loss:  2.305307/  2.302670, tr:  10.01%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:07<00:00,  8.22it/s]\n",
      "epoch-47  lr=['0.0011143'], tr/val_loss:  2.305197/  2.302644, tr:   9.30%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:05<00:00, 10.79it/s]\n",
      "epoch-48  lr=['0.0009549'], tr/val_loss:  2.304637/  2.302745, tr:   8.78%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:10<00:00,  5.99it/s]\n",
      "epoch-49  lr=['0.0008066'], tr/val_loss:  2.304113/  2.302645, tr:   8.89%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:06<00:00,  9.55it/s]\n",
      "epoch-50  lr=['0.0006699'], tr/val_loss:  2.304358/  2.302700, tr:   8.68%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:06<00:00,  9.27it/s]\n",
      "epoch-51  lr=['0.0005450'], tr/val_loss:  2.303610/  2.302717, tr:   9.81%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:05<00:00, 10.74it/s]\n",
      "epoch-52  lr=['0.0004323'], tr/val_loss:  2.303667/  2.302626, tr:   9.30%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:06<00:00,  9.84it/s]\n",
      "epoch-53  lr=['0.0003321'], tr/val_loss:  2.303300/  2.302634, tr:   9.19%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:05<00:00, 11.52it/s]\n",
      "epoch-54  lr=['0.0002447'], tr/val_loss:  2.303030/  2.302622, tr:   8.38%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:05<00:00, 11.92it/s]\n",
      "epoch-55  lr=['0.0001704'], tr/val_loss:  2.303107/  2.302625, tr:  10.01%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:05<00:00, 10.60it/s]\n",
      "epoch-56  lr=['0.0001093'], tr/val_loss:  2.302886/  2.302609, tr:  10.01%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:05<00:00, 10.55it/s]\n",
      "epoch-57  lr=['0.0000616'], tr/val_loss:  2.302670/  2.302610, tr:  10.01%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:05<00:00, 10.47it/s]\n",
      "epoch-58  lr=['0.0000274'], tr/val_loss:  2.302685/  2.302609, tr:  10.01%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:05<00:00, 10.40it/s]\n",
      "epoch-59  lr=['0.0000069'], tr/val_loss:  2.302528/  2.302609, tr:  10.01%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:06<00:00, 10.25it/s]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6e46527d934945499d23f482bfef3063",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='5.721 MB of 5.721 MB uploaded (1.608 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "W&B sync reduced upload amount by 27.5%"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>DFA_flag</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>epoch</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇████</td></tr><tr><td>iter_acc</td><td>▁█▅▅▃▁▅█▆▃▆▅▃▃▁▃▃▃▁▁▁▁▆▅▁▃▁▅▃▅▃▅▃▃▅▅▁▃▅█</td></tr><tr><td>summary_val_acc</td><td>▁███████████████████████████████████████</td></tr><tr><td>tr_acc</td><td>▁███▇▇▇█▇███▇███▆▆▇▇▆▇▇▇▇▆▇▇▇▇██▇▇█▇▇███</td></tr><tr><td>tr_epoch_loss</td><td>▁███████████████████████████████████████</td></tr><tr><td>val_acc_best</td><td>▁███████████████████████████████████████</td></tr><tr><td>val_acc_now</td><td>▁███████████████████████████████████████</td></tr><tr><td>val_loss</td><td>▁███████████████████████████████████████</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>DFA_flag</td><td>0.0</td></tr><tr><td>epoch</td><td>59</td></tr><tr><td>iter_acc</td><td>0.33333</td></tr><tr><td>tr_acc</td><td>0.1001</td></tr><tr><td>tr_epoch_loss</td><td>2.30253</td></tr><tr><td>val_acc_best</td><td>0.1</td></tr><tr><td>val_acc_now</td><td>0.1</td></tr><tr><td>val_loss</td><td>2.30261</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">swift-sweep-35</strong> at: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/vgobf82c' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/vgobf82c</a><br/> View project at: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main</a><br/>Synced 7 W&B file(s), 0 media file(s), 14 artifact file(s) and 1 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20240822_184057-vgobf82c/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require(\"core\")`! See https://wandb.me/wandb-core for more information."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: iut89ila with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBATCH: 16\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tDFA_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tIMAGE_SIZE: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tOTTT_input_trace_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tOTTT_sWS_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tTIME: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcfg: ['M', 'M', 200, 200]\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tconst2: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdecay: 0.25\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdrop_rate: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdvs_clipping: 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdvs_duration: 100000\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \te_transport_swap: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \te_transport_swap_coin: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \te_transport_swap_tr: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepoch_num: 60\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \texclude_class: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.01\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_sg_width: 2.570969004857107\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_reset: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_threshold: 0.018057946064855113\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmerge_polarities: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tscheduler_name: CosineAnnealingLR\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsurrogate: hard_sigmoid\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \twhich_data: DVS_GESTURE_TONIC\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.17.7 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.17.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/nfs/home/bhkim003/github_folder/ByeonghyeonKim/my_snn/wandb/run-20240822_184806-iut89ila</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/iut89ila' target=\"_blank\">effortless-sweep-38</a></strong> to <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/yxynyr6h' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/yxynyr6h</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/yxynyr6h' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/yxynyr6h</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/iut89ila' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/iut89ila</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BATCH' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'IMAGE_SIZE' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'which_data' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_threshold' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_reset' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_sg_width' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'cfg' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'learning_rate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'epoch_num' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'surrogate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'scheduler_name' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'dvs_clipping' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'dvs_duration' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'OTTT_sWS_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'DFA_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'OTTT_input_trace_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'e_transport_swap' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'e_transport_swap_tr' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'e_transport_swap_coin' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'drop_rate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'exclude_class' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'merge_polarities' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'TIME' was locked by 'sweep' (ignored update).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset_hash = 2bbd58b4e0d3c1e9ad501fad8a43feed\n",
      "cache path exists\n",
      "\n",
      "we will exclude the 'other' class. dvsgestrue 10 classes' indices exist. \n",
      "\n",
      "DataParallel(\n",
      "  (module): MY_SNN_FC_sstep(\n",
      "    (layers): MY_Sequential(\n",
      "      (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (2): DimChanger_for_FC_sstep()\n",
      "      (3): SYNAPSE_FC_trace_sstep()\n",
      "      (4): LIF_layer_trace_sstep()\n",
      "      (5): SYNAPSE_FC_trace_sstep()\n",
      "      (6): LIF_layer_trace_sstep()\n",
      "      (7): SYNAPSE_FC_trace_sstep()\n",
      "    )\n",
      "  )\n",
      ")\n",
      "==================================================\n",
      "My Num of PARAMS: 452,010, system's param_num : 452,010\n",
      "Memory: 1.72MiB at 32-bit\n",
      "==================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch-0   lr=['0.0100000'], tr/val_loss:  1.679876/  1.385082, tr:  41.57%, val:  45.42%, val_best:  45.42%: 100%|██████████| 62/62 [00:06<00:00,  9.67it/s]\n",
      "epoch-1   lr=['0.0099931'], tr/val_loss:  1.165862/  1.520145, tr:  56.28%, val:  52.08%, val_best:  52.08%: 100%|██████████| 62/62 [00:05<00:00, 10.44it/s]\n",
      "epoch-2   lr=['0.0099726'], tr/val_loss:  1.007564/  1.298727, tr:  62.31%, val:  56.67%, val_best:  56.67%: 100%|██████████| 62/62 [00:05<00:00, 10.66it/s]\n",
      "epoch-3   lr=['0.0099384'], tr/val_loss:  0.887765/  1.144238, tr:  66.50%, val:  62.08%, val_best:  62.08%: 100%|██████████| 62/62 [00:07<00:00,  8.70it/s]\n",
      "epoch-4   lr=['0.0098907'], tr/val_loss:  0.795666/  1.170401, tr:  70.68%, val:  61.25%, val_best:  62.08%: 100%|██████████| 62/62 [00:06<00:00, 10.13it/s]\n",
      "epoch-5   lr=['0.0098296'], tr/val_loss:  0.747134/  1.297778, tr:  72.42%, val:  58.33%, val_best:  62.08%: 100%|██████████| 62/62 [00:05<00:00, 10.51it/s]\n",
      "epoch-6   lr=['0.0097553'], tr/val_loss:  0.732240/  1.207412, tr:  70.89%, val:  61.67%, val_best:  62.08%: 100%|██████████| 62/62 [00:05<00:00, 10.61it/s]\n",
      "epoch-7   lr=['0.0096679'], tr/val_loss:  0.684302/  1.366151, tr:  74.06%, val:  58.75%, val_best:  62.08%: 100%|██████████| 62/62 [00:06<00:00,  9.84it/s]\n",
      "epoch-8   lr=['0.0095677'], tr/val_loss:  0.612623/  1.172409, tr:  75.69%, val:  61.67%, val_best:  62.08%: 100%|██████████| 62/62 [00:06<00:00, 10.16it/s]\n",
      "epoch-9   lr=['0.0094550'], tr/val_loss:  0.482186/  1.423518, tr:  79.78%, val:  62.50%, val_best:  62.50%: 100%|██████████| 62/62 [00:06<00:00, 10.15it/s]\n",
      "epoch-10  lr=['0.0093301'], tr/val_loss:  0.498500/  1.293016, tr:  79.67%, val:  68.33%, val_best:  68.33%: 100%|██████████| 62/62 [00:06<00:00, 10.11it/s]\n",
      "epoch-11  lr=['0.0091934'], tr/val_loss:  0.450139/  1.399641, tr:  81.51%, val:  62.92%, val_best:  68.33%: 100%|██████████| 62/62 [00:05<00:00, 10.49it/s]\n",
      "epoch-12  lr=['0.0090451'], tr/val_loss:  0.470015/  1.238762, tr:  82.43%, val:  66.67%, val_best:  68.33%: 100%|██████████| 62/62 [00:07<00:00,  8.06it/s]\n",
      "epoch-13  lr=['0.0088857'], tr/val_loss:  0.418547/  1.213525, tr:  86.41%, val:  68.75%, val_best:  68.75%: 100%|██████████| 62/62 [00:06<00:00, 10.09it/s]\n",
      "epoch-14  lr=['0.0087157'], tr/val_loss:  0.360909/  1.230447, tr:  88.46%, val:  67.92%, val_best:  68.75%: 100%|██████████| 62/62 [00:05<00:00, 11.17it/s]\n",
      "epoch-15  lr=['0.0085355'], tr/val_loss:  0.347412/  1.378955, tr:  88.87%, val:  67.08%, val_best:  68.75%: 100%|██████████| 62/62 [00:06<00:00, 10.06it/s]\n",
      "epoch-16  lr=['0.0083457'], tr/val_loss:  0.305011/  1.354667, tr:  92.13%, val:  69.17%, val_best:  69.17%: 100%|██████████| 62/62 [00:05<00:00, 10.79it/s]\n",
      "epoch-17  lr=['0.0081466'], tr/val_loss:  0.306190/  1.292121, tr:  92.85%, val:  73.33%, val_best:  73.33%: 100%|██████████| 62/62 [00:05<00:00, 12.12it/s]\n",
      "epoch-18  lr=['0.0079389'], tr/val_loss:  0.292348/  1.383966, tr:  90.60%, val:  76.25%, val_best:  76.25%: 100%|██████████| 62/62 [00:05<00:00, 12.08it/s]\n",
      "epoch-19  lr=['0.0077232'], tr/val_loss:  0.189599/  1.376098, tr:  96.63%, val:  74.58%, val_best:  76.25%: 100%|██████████| 62/62 [00:05<00:00, 12.22it/s]\n",
      "epoch-20  lr=['0.0075000'], tr/val_loss:  0.157753/  1.369792, tr:  98.06%, val:  75.00%, val_best:  76.25%: 100%|██████████| 62/62 [00:04<00:00, 13.04it/s]\n",
      "epoch-21  lr=['0.0072700'], tr/val_loss:  0.125005/  1.496916, tr:  98.98%, val:  74.17%, val_best:  76.25%: 100%|██████████| 62/62 [00:05<00:00, 11.71it/s]\n",
      "epoch-22  lr=['0.0070337'], tr/val_loss:  0.128448/  1.398391, tr:  96.83%, val:  72.50%, val_best:  76.25%: 100%|██████████| 62/62 [00:05<00:00, 11.46it/s]\n",
      "epoch-23  lr=['0.0067918'], tr/val_loss:  0.092117/  1.446340, tr:  99.90%, val:  78.75%, val_best:  78.75%: 100%|██████████| 62/62 [00:05<00:00, 11.14it/s]\n",
      "epoch-24  lr=['0.0065451'], tr/val_loss:  0.054970/  1.521740, tr: 100.00%, val:  77.08%, val_best:  78.75%: 100%|██████████| 62/62 [00:05<00:00, 11.29it/s]\n",
      "epoch-25  lr=['0.0062941'], tr/val_loss:  0.037595/  1.521066, tr: 100.00%, val:  77.92%, val_best:  78.75%: 100%|██████████| 62/62 [00:05<00:00, 11.80it/s]\n",
      "epoch-26  lr=['0.0060396'], tr/val_loss:  0.021039/  1.491926, tr: 100.00%, val:  77.92%, val_best:  78.75%: 100%|██████████| 62/62 [00:05<00:00, 11.31it/s]\n",
      "epoch-27  lr=['0.0057822'], tr/val_loss:  0.016706/  1.517622, tr: 100.00%, val:  78.33%, val_best:  78.75%: 100%|██████████| 62/62 [00:05<00:00, 11.48it/s]\n",
      "epoch-28  lr=['0.0055226'], tr/val_loss:  0.011372/  1.537416, tr: 100.00%, val:  78.33%, val_best:  78.75%: 100%|██████████| 62/62 [00:05<00:00, 11.47it/s]\n",
      "epoch-29  lr=['0.0052617'], tr/val_loss:  0.008820/  1.563146, tr: 100.00%, val:  78.33%, val_best:  78.75%: 100%|██████████| 62/62 [00:05<00:00, 12.08it/s]\n",
      "epoch-30  lr=['0.0050000'], tr/val_loss:  0.005548/  1.576153, tr: 100.00%, val:  80.00%, val_best:  80.00%: 100%|██████████| 62/62 [00:05<00:00, 11.47it/s]\n",
      "epoch-31  lr=['0.0047383'], tr/val_loss:  0.004356/  1.574543, tr: 100.00%, val:  78.75%, val_best:  80.00%: 100%|██████████| 62/62 [00:05<00:00, 11.86it/s]\n",
      "epoch-32  lr=['0.0044774'], tr/val_loss:  0.003740/  1.591006, tr: 100.00%, val:  79.17%, val_best:  80.00%: 100%|██████████| 62/62 [00:05<00:00, 11.40it/s]\n",
      "epoch-33  lr=['0.0042178'], tr/val_loss:  0.003292/  1.584835, tr: 100.00%, val:  79.58%, val_best:  80.00%: 100%|██████████| 62/62 [00:05<00:00, 11.30it/s]\n",
      "epoch-34  lr=['0.0039604'], tr/val_loss:  0.002911/  1.578905, tr: 100.00%, val:  79.17%, val_best:  80.00%: 100%|██████████| 62/62 [00:06<00:00, 10.20it/s]\n",
      "epoch-35  lr=['0.0037059'], tr/val_loss:  0.002666/  1.597729, tr: 100.00%, val:  79.17%, val_best:  80.00%: 100%|██████████| 62/62 [00:05<00:00, 11.28it/s]\n",
      "epoch-36  lr=['0.0034549'], tr/val_loss:  0.002417/  1.605566, tr: 100.00%, val:  80.42%, val_best:  80.42%: 100%|██████████| 62/62 [00:05<00:00, 11.72it/s]\n",
      "epoch-37  lr=['0.0032082'], tr/val_loss:  0.002335/  1.590055, tr: 100.00%, val:  79.17%, val_best:  80.42%: 100%|██████████| 62/62 [00:05<00:00, 11.65it/s]\n",
      "epoch-38  lr=['0.0029663'], tr/val_loss:  0.002128/  1.595355, tr: 100.00%, val:  79.58%, val_best:  80.42%: 100%|██████████| 62/62 [00:05<00:00, 11.38it/s]\n",
      "epoch-39  lr=['0.0027300'], tr/val_loss:  0.002151/  1.597208, tr: 100.00%, val:  79.58%, val_best:  80.42%: 100%|██████████| 62/62 [00:05<00:00, 11.13it/s]\n",
      "epoch-40  lr=['0.0025000'], tr/val_loss:  0.001997/  1.602402, tr: 100.00%, val:  79.17%, val_best:  80.42%: 100%|██████████| 62/62 [00:05<00:00, 11.35it/s]\n",
      "epoch-41  lr=['0.0022768'], tr/val_loss:  0.001942/  1.614204, tr: 100.00%, val:  79.17%, val_best:  80.42%: 100%|██████████| 62/62 [00:05<00:00, 11.23it/s]\n",
      "epoch-42  lr=['0.0020611'], tr/val_loss:  0.001894/  1.610651, tr: 100.00%, val:  79.17%, val_best:  80.42%: 100%|██████████| 62/62 [00:05<00:00, 11.43it/s]\n",
      "epoch-43  lr=['0.0018534'], tr/val_loss:  0.001802/  1.603243, tr: 100.00%, val:  78.75%, val_best:  80.42%: 100%|██████████| 62/62 [00:05<00:00, 10.40it/s]\n",
      "epoch-44  lr=['0.0016543'], tr/val_loss:  0.001800/  1.607274, tr: 100.00%, val:  78.75%, val_best:  80.42%: 100%|██████████| 62/62 [00:06<00:00, 10.01it/s]\n",
      "epoch-45  lr=['0.0014645'], tr/val_loss:  0.001765/  1.607974, tr: 100.00%, val:  79.58%, val_best:  80.42%: 100%|██████████| 62/62 [00:05<00:00, 11.28it/s]\n",
      "epoch-46  lr=['0.0012843'], tr/val_loss:  0.001684/  1.610805, tr: 100.00%, val:  78.75%, val_best:  80.42%: 100%|██████████| 62/62 [00:06<00:00,  9.84it/s]\n",
      "epoch-47  lr=['0.0011143'], tr/val_loss:  0.001683/  1.614851, tr: 100.00%, val:  79.17%, val_best:  80.42%: 100%|██████████| 62/62 [00:05<00:00, 11.22it/s]\n",
      "epoch-48  lr=['0.0009549'], tr/val_loss:  0.001689/  1.615814, tr: 100.00%, val:  78.75%, val_best:  80.42%: 100%|██████████| 62/62 [00:05<00:00, 11.65it/s]\n",
      "epoch-49  lr=['0.0008066'], tr/val_loss:  0.001667/  1.619222, tr: 100.00%, val:  78.75%, val_best:  80.42%: 100%|██████████| 62/62 [00:05<00:00, 11.50it/s]\n",
      "epoch-50  lr=['0.0006699'], tr/val_loss:  0.001663/  1.620089, tr: 100.00%, val:  78.75%, val_best:  80.42%: 100%|██████████| 62/62 [00:05<00:00, 11.23it/s]\n",
      "epoch-51  lr=['0.0005450'], tr/val_loss:  0.001648/  1.623391, tr: 100.00%, val:  78.33%, val_best:  80.42%: 100%|██████████| 62/62 [00:05<00:00, 11.58it/s]\n",
      "epoch-52  lr=['0.0004323'], tr/val_loss:  0.001645/  1.623124, tr: 100.00%, val:  78.33%, val_best:  80.42%: 100%|██████████| 62/62 [00:05<00:00, 11.76it/s]\n",
      "epoch-53  lr=['0.0003321'], tr/val_loss:  0.001612/  1.620239, tr: 100.00%, val:  77.92%, val_best:  80.42%: 100%|██████████| 62/62 [00:05<00:00, 11.71it/s]\n",
      "epoch-54  lr=['0.0002447'], tr/val_loss:  0.001639/  1.621320, tr: 100.00%, val:  77.92%, val_best:  80.42%: 100%|██████████| 62/62 [00:05<00:00, 11.06it/s]\n",
      "epoch-55  lr=['0.0001704'], tr/val_loss:  0.001586/  1.624173, tr: 100.00%, val:  77.50%, val_best:  80.42%: 100%|██████████| 62/62 [00:05<00:00, 11.39it/s]\n",
      "epoch-56  lr=['0.0001093'], tr/val_loss:  0.001590/  1.623275, tr: 100.00%, val:  77.92%, val_best:  80.42%: 100%|██████████| 62/62 [00:05<00:00, 11.77it/s]\n",
      "epoch-57  lr=['0.0000616'], tr/val_loss:  0.001689/  1.623064, tr: 100.00%, val:  77.92%, val_best:  80.42%: 100%|██████████| 62/62 [00:05<00:00, 11.23it/s]\n",
      "epoch-58  lr=['0.0000274'], tr/val_loss:  0.001580/  1.623948, tr: 100.00%, val:  77.92%, val_best:  80.42%: 100%|██████████| 62/62 [00:05<00:00, 11.79it/s]\n",
      "epoch-59  lr=['0.0000069'], tr/val_loss:  0.001591/  1.623380, tr: 100.00%, val:  77.92%, val_best:  80.42%: 100%|██████████| 62/62 [00:05<00:00, 11.27it/s]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b48f762ecd084b688bd118d0a622ba0b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='3.438 MB of 3.438 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>DFA_flag</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>epoch</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇████</td></tr><tr><td>iter_acc</td><td>▁▄▅▆▅▇▆▅▆▇▇▇▇███████████████████████████</td></tr><tr><td>summary_val_acc</td><td>▁▅▆▆▆▆▆▆▇▇▇▇▇██▇████████████████████████</td></tr><tr><td>tr_acc</td><td>▁▄▅▆▆▆▆▇▇▇▇▇▇███████████████████████████</td></tr><tr><td>tr_epoch_loss</td><td>▁█▅▅▄▄▄▃▃▃▃▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_acc_best</td><td>▁▅▆▆▆▆▆▆▇▇▇▇▇███████████████████████████</td></tr><tr><td>val_acc_now</td><td>▁▅▆▆▆▆▆▆▇▇▇▇▇██▇████████████████████████</td></tr><tr><td>val_loss</td><td>▁▇▇▆▇▆▆▇▇▆▆▇▇▇▇▇▇█▇█████████████████████</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>DFA_flag</td><td>0.0</td></tr><tr><td>epoch</td><td>59</td></tr><tr><td>iter_acc</td><td>1.0</td></tr><tr><td>tr_acc</td><td>1.0</td></tr><tr><td>tr_epoch_loss</td><td>0.00159</td></tr><tr><td>val_acc_best</td><td>0.80417</td></tr><tr><td>val_acc_now</td><td>0.77917</td></tr><tr><td>val_loss</td><td>1.62338</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">effortless-sweep-38</strong> at: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/iut89ila' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/iut89ila</a><br/> View project at: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main</a><br/>Synced 7 W&B file(s), 0 media file(s), 0 artifact file(s) and 1 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20240822_184806-iut89ila/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require(\"core\")`! See https://wandb.me/wandb-core for more information."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Sweep Agent: Waiting for job.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Job received.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: vxaev59l with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBATCH: 16\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tDFA_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tIMAGE_SIZE: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tOTTT_input_trace_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tOTTT_sWS_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tTIME: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcfg: ['M', 'M', 200, 200]\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tconst2: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdecay: 0.25\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdrop_rate: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdvs_clipping: 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdvs_duration: 100000\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \te_transport_swap: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \te_transport_swap_coin: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \te_transport_swap_tr: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepoch_num: 60\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \texclude_class: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.01\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_sg_width: 2.570969004857107\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_reset: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_threshold: 0.5356684619228598\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmerge_polarities: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tscheduler_name: CosineAnnealingLR\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsurrogate: hard_sigmoid\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \twhich_data: DVS_GESTURE_TONIC\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.17.7 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.17.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/nfs/home/bhkim003/github_folder/ByeonghyeonKim/my_snn/wandb/run-20240822_185425-vxaev59l</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/vxaev59l' target=\"_blank\">fiery-sweep-40</a></strong> to <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/yxynyr6h' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/yxynyr6h</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/yxynyr6h' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/yxynyr6h</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/vxaev59l' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/vxaev59l</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BATCH' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'IMAGE_SIZE' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'which_data' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_threshold' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_reset' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_sg_width' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'cfg' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'learning_rate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'epoch_num' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'surrogate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'scheduler_name' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'dvs_clipping' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'dvs_duration' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'OTTT_sWS_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'DFA_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'OTTT_input_trace_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'e_transport_swap' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'e_transport_swap_tr' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'e_transport_swap_coin' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'drop_rate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'exclude_class' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'merge_polarities' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'TIME' was locked by 'sweep' (ignored update).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset_hash = 2bbd58b4e0d3c1e9ad501fad8a43feed\n",
      "cache path exists\n",
      "\n",
      "we will exclude the 'other' class. dvsgestrue 10 classes' indices exist. \n",
      "\n",
      "DataParallel(\n",
      "  (module): MY_SNN_FC_sstep(\n",
      "    (layers): MY_Sequential(\n",
      "      (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (2): DimChanger_for_FC_sstep()\n",
      "      (3): SYNAPSE_FC_trace_sstep()\n",
      "      (4): LIF_layer_trace_sstep()\n",
      "      (5): SYNAPSE_FC_trace_sstep()\n",
      "      (6): LIF_layer_trace_sstep()\n",
      "      (7): SYNAPSE_FC_trace_sstep()\n",
      "    )\n",
      "  )\n",
      ")\n",
      "==================================================\n",
      "My Num of PARAMS: 452,010, system's param_num : 452,010\n",
      "Memory: 1.72MiB at 32-bit\n",
      "==================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch-0   lr=['0.0100000'], tr/val_loss:  1.555508/  1.295166, tr:  46.78%, val:  54.17%, val_best:  54.17%: 100%|██████████| 62/62 [00:05<00:00, 11.14it/s]\n",
      "epoch-1   lr=['0.0099931'], tr/val_loss:  1.083353/  1.330256, tr:  60.98%, val:  51.67%, val_best:  54.17%: 100%|██████████| 62/62 [00:06<00:00,  9.97it/s]\n",
      "epoch-2   lr=['0.0099726'], tr/val_loss:  0.965180/  1.202430, tr:  64.04%, val:  62.92%, val_best:  62.92%: 100%|██████████| 62/62 [00:05<00:00, 11.67it/s]\n",
      "epoch-3   lr=['0.0099384'], tr/val_loss:  0.850845/  1.216915, tr:  69.36%, val:  58.33%, val_best:  62.92%: 100%|██████████| 62/62 [00:05<00:00, 11.61it/s]\n",
      "epoch-4   lr=['0.0098907'], tr/val_loss:  0.841582/  1.265450, tr:  67.93%, val:  57.50%, val_best:  62.92%: 100%|██████████| 62/62 [00:05<00:00, 11.61it/s]\n",
      "epoch-5   lr=['0.0098296'], tr/val_loss:  0.762017/  1.318110, tr:  73.03%, val:  62.50%, val_best:  62.92%: 100%|██████████| 62/62 [00:05<00:00, 12.07it/s]\n",
      "epoch-6   lr=['0.0097553'], tr/val_loss:  0.669901/  1.215641, tr:  74.06%, val:  60.83%, val_best:  62.92%: 100%|██████████| 62/62 [00:05<00:00, 11.95it/s]\n",
      "epoch-7   lr=['0.0096679'], tr/val_loss:  0.645445/  1.359183, tr:  76.40%, val:  60.83%, val_best:  62.92%: 100%|██████████| 62/62 [00:05<00:00, 11.90it/s]\n",
      "epoch-8   lr=['0.0095677'], tr/val_loss:  0.617140/  1.188681, tr:  75.49%, val:  66.25%, val_best:  66.25%: 100%|██████████| 62/62 [00:05<00:00, 11.61it/s]\n",
      "epoch-9   lr=['0.0094550'], tr/val_loss:  0.457409/  1.329631, tr:  82.64%, val:  67.92%, val_best:  67.92%: 100%|██████████| 62/62 [00:05<00:00, 11.59it/s]\n",
      "epoch-10  lr=['0.0093301'], tr/val_loss:  0.436176/  1.340773, tr:  85.50%, val:  68.33%, val_best:  68.33%: 100%|██████████| 62/62 [00:05<00:00, 11.54it/s]\n",
      "epoch-11  lr=['0.0091934'], tr/val_loss:  0.406934/  1.410721, tr:  85.19%, val:  65.00%, val_best:  68.33%: 100%|██████████| 62/62 [00:05<00:00, 10.80it/s]\n",
      "epoch-12  lr=['0.0090451'], tr/val_loss:  0.446954/  1.270299, tr:  86.72%, val:  71.67%, val_best:  71.67%: 100%|██████████| 62/62 [00:05<00:00, 11.57it/s]\n",
      "epoch-13  lr=['0.0088857'], tr/val_loss:  0.332011/  1.340243, tr:  91.93%, val:  72.92%, val_best:  72.92%: 100%|██████████| 62/62 [00:05<00:00, 11.68it/s]\n",
      "epoch-14  lr=['0.0087157'], tr/val_loss:  0.285494/  1.308780, tr:  94.48%, val:  72.50%, val_best:  72.92%: 100%|██████████| 62/62 [00:05<00:00, 11.51it/s]\n",
      "epoch-15  lr=['0.0085355'], tr/val_loss:  0.267263/  1.408682, tr:  95.40%, val:  75.42%, val_best:  75.42%: 100%|██████████| 62/62 [00:04<00:00, 12.46it/s]\n",
      "epoch-16  lr=['0.0083457'], tr/val_loss:  0.232394/  1.427246, tr:  95.61%, val:  74.58%, val_best:  75.42%: 100%|██████████| 62/62 [00:05<00:00, 12.21it/s]\n",
      "epoch-17  lr=['0.0081466'], tr/val_loss:  0.266515/  1.382522, tr:  95.40%, val:  73.75%, val_best:  75.42%: 100%|██████████| 62/62 [00:04<00:00, 12.43it/s]\n",
      "epoch-18  lr=['0.0079389'], tr/val_loss:  0.246319/  1.302200, tr:  96.94%, val:  76.25%, val_best:  76.25%: 100%|██████████| 62/62 [00:04<00:00, 12.80it/s]\n",
      "epoch-19  lr=['0.0077232'], tr/val_loss:  0.147719/  1.540109, tr:  98.67%, val:  72.92%, val_best:  76.25%: 100%|██████████| 62/62 [00:05<00:00, 12.11it/s]\n",
      "epoch-20  lr=['0.0075000'], tr/val_loss:  0.098742/  1.499675, tr: 100.00%, val:  78.75%, val_best:  78.75%: 100%|██████████| 62/62 [00:05<00:00, 11.81it/s]\n",
      "epoch-21  lr=['0.0072700'], tr/val_loss:  0.059864/  1.546144, tr: 100.00%, val:  77.50%, val_best:  78.75%: 100%|██████████| 62/62 [00:05<00:00, 11.74it/s]\n",
      "epoch-22  lr=['0.0070337'], tr/val_loss:  0.052860/  1.567854, tr:  99.59%, val:  77.08%, val_best:  78.75%: 100%|██████████| 62/62 [00:05<00:00, 11.89it/s]\n",
      "epoch-23  lr=['0.0067918'], tr/val_loss:  0.034973/  1.583171, tr:  99.90%, val:  75.83%, val_best:  78.75%: 100%|██████████| 62/62 [00:05<00:00, 10.60it/s]\n",
      "epoch-24  lr=['0.0065451'], tr/val_loss:  0.021292/  1.631319, tr: 100.00%, val:  77.92%, val_best:  78.75%: 100%|██████████| 62/62 [00:05<00:00, 11.77it/s]\n",
      "epoch-25  lr=['0.0062941'], tr/val_loss:  0.012780/  1.583153, tr: 100.00%, val:  79.17%, val_best:  79.17%: 100%|██████████| 62/62 [00:05<00:00, 11.91it/s]\n",
      "epoch-26  lr=['0.0060396'], tr/val_loss:  0.007926/  1.577801, tr: 100.00%, val:  79.17%, val_best:  79.17%: 100%|██████████| 62/62 [00:05<00:00, 12.19it/s]\n",
      "epoch-27  lr=['0.0057822'], tr/val_loss:  0.005229/  1.640393, tr: 100.00%, val:  79.17%, val_best:  79.17%: 100%|██████████| 62/62 [00:04<00:00, 12.71it/s]\n",
      "epoch-28  lr=['0.0055226'], tr/val_loss:  0.004059/  1.614145, tr: 100.00%, val:  81.25%, val_best:  81.25%: 100%|██████████| 62/62 [00:05<00:00, 11.52it/s]\n",
      "epoch-29  lr=['0.0052617'], tr/val_loss:  0.003415/  1.633460, tr: 100.00%, val:  79.58%, val_best:  81.25%: 100%|██████████| 62/62 [00:05<00:00, 10.52it/s]\n",
      "epoch-30  lr=['0.0050000'], tr/val_loss:  0.002909/  1.627059, tr: 100.00%, val:  80.42%, val_best:  81.25%: 100%|██████████| 62/62 [00:05<00:00, 11.10it/s]\n",
      "epoch-31  lr=['0.0047383'], tr/val_loss:  0.002480/  1.626198, tr: 100.00%, val:  80.83%, val_best:  81.25%: 100%|██████████| 62/62 [00:06<00:00, 10.29it/s]\n",
      "epoch-32  lr=['0.0044774'], tr/val_loss:  0.002489/  1.626274, tr: 100.00%, val:  80.83%, val_best:  81.25%: 100%|██████████| 62/62 [00:05<00:00, 10.44it/s]\n",
      "epoch-33  lr=['0.0042178'], tr/val_loss:  0.002102/  1.631285, tr: 100.00%, val:  80.83%, val_best:  81.25%: 100%|██████████| 62/62 [00:06<00:00,  9.61it/s]\n",
      "epoch-34  lr=['0.0039604'], tr/val_loss:  0.001949/  1.647594, tr: 100.00%, val:  81.25%, val_best:  81.25%: 100%|██████████| 62/62 [00:06<00:00, 10.31it/s]\n",
      "epoch-35  lr=['0.0037059'], tr/val_loss:  0.001878/  1.660239, tr: 100.00%, val:  81.67%, val_best:  81.67%: 100%|██████████| 62/62 [00:05<00:00, 10.64it/s]\n",
      "epoch-36  lr=['0.0034549'], tr/val_loss:  0.001745/  1.675416, tr: 100.00%, val:  81.67%, val_best:  81.67%: 100%|██████████| 62/62 [00:05<00:00, 11.14it/s]\n",
      "epoch-37  lr=['0.0032082'], tr/val_loss:  0.001646/  1.673920, tr: 100.00%, val:  81.67%, val_best:  81.67%: 100%|██████████| 62/62 [00:06<00:00,  9.89it/s]\n",
      "epoch-38  lr=['0.0029663'], tr/val_loss:  0.001569/  1.676846, tr: 100.00%, val:  82.08%, val_best:  82.08%: 100%|██████████| 62/62 [00:05<00:00, 10.63it/s]\n",
      "epoch-39  lr=['0.0027300'], tr/val_loss:  0.001513/  1.678628, tr: 100.00%, val:  82.08%, val_best:  82.08%: 100%|██████████| 62/62 [00:05<00:00, 10.88it/s]\n",
      "epoch-40  lr=['0.0025000'], tr/val_loss:  0.001432/  1.690584, tr: 100.00%, val:  81.67%, val_best:  82.08%: 100%|██████████| 62/62 [00:06<00:00,  9.92it/s]\n",
      "epoch-41  lr=['0.0022768'], tr/val_loss:  0.001406/  1.690694, tr: 100.00%, val:  81.67%, val_best:  82.08%: 100%|██████████| 62/62 [00:05<00:00, 10.79it/s]\n",
      "epoch-42  lr=['0.0020611'], tr/val_loss:  0.001333/  1.692060, tr: 100.00%, val:  80.83%, val_best:  82.08%: 100%|██████████| 62/62 [00:06<00:00, 10.17it/s]\n",
      "epoch-43  lr=['0.0018534'], tr/val_loss:  0.001333/  1.691750, tr: 100.00%, val:  80.83%, val_best:  82.08%: 100%|██████████| 62/62 [00:05<00:00, 10.49it/s]\n",
      "epoch-44  lr=['0.0016543'], tr/val_loss:  0.001285/  1.691797, tr: 100.00%, val:  80.83%, val_best:  82.08%: 100%|██████████| 62/62 [00:05<00:00, 10.43it/s]\n",
      "epoch-45  lr=['0.0014645'], tr/val_loss:  0.001288/  1.694753, tr: 100.00%, val:  80.83%, val_best:  82.08%: 100%|██████████| 62/62 [00:05<00:00, 10.81it/s]\n",
      "epoch-46  lr=['0.0012843'], tr/val_loss:  0.001269/  1.694824, tr: 100.00%, val:  81.25%, val_best:  82.08%: 100%|██████████| 62/62 [00:05<00:00, 10.74it/s]\n",
      "epoch-47  lr=['0.0011143'], tr/val_loss:  0.001250/  1.693759, tr: 100.00%, val:  80.83%, val_best:  82.08%: 100%|██████████| 62/62 [00:05<00:00, 10.80it/s]\n",
      "epoch-48  lr=['0.0009549'], tr/val_loss:  0.001244/  1.695286, tr: 100.00%, val:  80.83%, val_best:  82.08%: 100%|██████████| 62/62 [00:06<00:00,  9.60it/s]\n",
      "epoch-49  lr=['0.0008066'], tr/val_loss:  0.001246/  1.699515, tr: 100.00%, val:  80.83%, val_best:  82.08%: 100%|██████████| 62/62 [00:06<00:00, 10.23it/s]\n",
      "epoch-50  lr=['0.0006699'], tr/val_loss:  0.001236/  1.700718, tr: 100.00%, val:  81.25%, val_best:  82.08%: 100%|██████████| 62/62 [00:05<00:00, 10.40it/s]\n",
      "epoch-51  lr=['0.0005450'], tr/val_loss:  0.001207/  1.701052, tr: 100.00%, val:  81.25%, val_best:  82.08%: 100%|██████████| 62/62 [00:06<00:00, 10.09it/s]\n",
      "epoch-52  lr=['0.0004323'], tr/val_loss:  0.001198/  1.702966, tr: 100.00%, val:  81.25%, val_best:  82.08%: 100%|██████████| 62/62 [00:06<00:00,  9.92it/s]\n",
      "epoch-53  lr=['0.0003321'], tr/val_loss:  0.001185/  1.703002, tr: 100.00%, val:  81.25%, val_best:  82.08%: 100%|██████████| 62/62 [00:06<00:00,  9.87it/s]\n",
      "epoch-54  lr=['0.0002447'], tr/val_loss:  0.001695/  1.704262, tr: 100.00%, val:  81.25%, val_best:  82.08%: 100%|██████████| 62/62 [00:05<00:00, 10.38it/s]\n",
      "epoch-55  lr=['0.0001704'], tr/val_loss:  0.001187/  1.713082, tr: 100.00%, val:  80.42%, val_best:  82.08%: 100%|██████████| 62/62 [00:05<00:00, 10.68it/s]\n",
      "epoch-56  lr=['0.0001093'], tr/val_loss:  0.001205/  1.714537, tr: 100.00%, val:  80.42%, val_best:  82.08%: 100%|██████████| 62/62 [00:06<00:00, 10.28it/s]\n",
      "epoch-57  lr=['0.0000616'], tr/val_loss:  0.001209/  1.714438, tr: 100.00%, val:  80.42%, val_best:  82.08%: 100%|██████████| 62/62 [00:06<00:00,  8.86it/s]\n",
      "epoch-58  lr=['0.0000274'], tr/val_loss:  0.001193/  1.714854, tr: 100.00%, val:  80.42%, val_best:  82.08%: 100%|██████████| 62/62 [00:05<00:00, 10.83it/s]\n",
      "epoch-59  lr=['0.0000069'], tr/val_loss:  0.001193/  1.714860, tr: 100.00%, val:  80.42%, val_best:  82.08%: 100%|██████████| 62/62 [00:05<00:00, 10.43it/s]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a4b4400ae3c048b8ae3d0a0618f254d9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='3.438 MB of 3.438 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>DFA_flag</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>epoch</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇████</td></tr><tr><td>iter_acc</td><td>▂▆▅▁▆▆▆▆▆▇▇█▇███████████████████████████</td></tr><tr><td>summary_val_acc</td><td>▁▆▆▆▆▆▇▇▇▇▇▇▇▇██▇███████████████████████</td></tr><tr><td>tr_acc</td><td>▁▄▅▆▆▆▆▇▇▇██████████████████████████████</td></tr><tr><td>tr_epoch_loss</td><td>▁█▅▅▄▄▄▃▃▃▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_acc_best</td><td>▁▆▆▆▆▆▇▇▇▇▇▇▇███████████████████████████</td></tr><tr><td>val_acc_now</td><td>▁▆▆▆▆▆▇▇▇▇▇▇▇▇██▇███████████████████████</td></tr><tr><td>val_loss</td><td>▁▆▆▆▆▆▆▆▇▆▆▇▇▇▇▇▇▇▇█████████████████████</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>DFA_flag</td><td>0.0</td></tr><tr><td>epoch</td><td>59</td></tr><tr><td>iter_acc</td><td>1.0</td></tr><tr><td>tr_acc</td><td>1.0</td></tr><tr><td>tr_epoch_loss</td><td>0.00119</td></tr><tr><td>val_acc_best</td><td>0.82083</td></tr><tr><td>val_acc_now</td><td>0.80417</td></tr><tr><td>val_loss</td><td>1.71486</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">fiery-sweep-40</strong> at: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/vxaev59l' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/vxaev59l</a><br/> View project at: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main</a><br/>Synced 7 W&B file(s), 0 media file(s), 0 artifact file(s) and 1 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20240822_185425-vxaev59l/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require(\"core\")`! See https://wandb.me/wandb-core for more information."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: gfaj3ug7 with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBATCH: 16\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tDFA_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tIMAGE_SIZE: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tOTTT_input_trace_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tOTTT_sWS_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tTIME: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcfg: ['M', 'M', 200, 200]\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tconst2: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdecay: 0.25\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdrop_rate: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdvs_clipping: 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdvs_duration: 100000\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \te_transport_swap: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \te_transport_swap_coin: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \te_transport_swap_tr: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepoch_num: 60\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \texclude_class: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.01\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_sg_width: 2.570969004857107\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_reset: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_threshold: 0.7335125805064487\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmerge_polarities: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tscheduler_name: CosineAnnealingLR\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsurrogate: hard_sigmoid\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \twhich_data: DVS_GESTURE_TONIC\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.17.7 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.17.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/nfs/home/bhkim003/github_folder/ByeonghyeonKim/my_snn/wandb/run-20240822_190036-gfaj3ug7</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/gfaj3ug7' target=\"_blank\">driven-sweep-42</a></strong> to <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/yxynyr6h' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/yxynyr6h</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/yxynyr6h' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/yxynyr6h</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/gfaj3ug7' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/gfaj3ug7</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BATCH' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'IMAGE_SIZE' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'which_data' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_threshold' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_reset' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_sg_width' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'cfg' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'learning_rate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'epoch_num' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'surrogate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'scheduler_name' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'dvs_clipping' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'dvs_duration' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'OTTT_sWS_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'DFA_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'OTTT_input_trace_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'e_transport_swap' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'e_transport_swap_tr' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'e_transport_swap_coin' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'drop_rate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'exclude_class' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'merge_polarities' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'TIME' was locked by 'sweep' (ignored update).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset_hash = 2bbd58b4e0d3c1e9ad501fad8a43feed\n",
      "cache path exists\n",
      "\n",
      "we will exclude the 'other' class. dvsgestrue 10 classes' indices exist. \n",
      "\n",
      "DataParallel(\n",
      "  (module): MY_SNN_FC_sstep(\n",
      "    (layers): MY_Sequential(\n",
      "      (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (2): DimChanger_for_FC_sstep()\n",
      "      (3): SYNAPSE_FC_trace_sstep()\n",
      "      (4): LIF_layer_trace_sstep()\n",
      "      (5): SYNAPSE_FC_trace_sstep()\n",
      "      (6): LIF_layer_trace_sstep()\n",
      "      (7): SYNAPSE_FC_trace_sstep()\n",
      "    )\n",
      "  )\n",
      ")\n",
      "==================================================\n",
      "My Num of PARAMS: 452,010, system's param_num : 452,010\n",
      "Memory: 1.72MiB at 32-bit\n",
      "==================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch-0   lr=['0.0100000'], tr/val_loss:  1.626501/  1.298402, tr:  44.54%, val:  53.75%, val_best:  53.75%: 100%|██████████| 62/62 [00:06<00:00, 10.14it/s]\n",
      "epoch-1   lr=['0.0099931'], tr/val_loss:  1.136636/  1.293495, tr:  60.06%, val:  54.58%, val_best:  54.58%: 100%|██████████| 62/62 [00:05<00:00, 10.99it/s]\n",
      "epoch-2   lr=['0.0099726'], tr/val_loss:  1.011527/  1.154310, tr:  63.64%, val:  60.83%, val_best:  60.83%: 100%|██████████| 62/62 [00:05<00:00, 10.78it/s]\n",
      "epoch-3   lr=['0.0099384'], tr/val_loss:  0.881011/  1.101748, tr:  68.44%, val:  62.08%, val_best:  62.08%: 100%|██████████| 62/62 [00:06<00:00, 10.02it/s]\n",
      "epoch-4   lr=['0.0098907'], tr/val_loss:  0.816214/  1.176779, tr:  68.44%, val:  61.67%, val_best:  62.08%: 100%|██████████| 62/62 [00:06<00:00,  9.30it/s]\n",
      "epoch-5   lr=['0.0098296'], tr/val_loss:  0.759477/  1.272308, tr:  72.01%, val:  59.17%, val_best:  62.08%: 100%|██████████| 62/62 [00:06<00:00,  9.95it/s]\n",
      "epoch-6   lr=['0.0097553'], tr/val_loss:  0.687602/  1.115328, tr:  73.65%, val:  61.67%, val_best:  62.08%: 100%|██████████| 62/62 [00:06<00:00, 10.11it/s]\n",
      "epoch-7   lr=['0.0096679'], tr/val_loss:  0.671255/  1.341082, tr:  74.67%, val:  59.17%, val_best:  62.08%: 100%|██████████| 62/62 [00:05<00:00, 10.59it/s]\n",
      "epoch-8   lr=['0.0095677'], tr/val_loss:  0.647400/  1.246709, tr:  75.28%, val:  66.25%, val_best:  66.25%: 100%|██████████| 62/62 [00:06<00:00,  9.43it/s]\n",
      "epoch-9   lr=['0.0094550'], tr/val_loss:  0.530530/  1.271310, tr:  80.59%, val:  65.00%, val_best:  66.25%: 100%|██████████| 62/62 [00:05<00:00, 10.67it/s]\n",
      "epoch-10  lr=['0.0093301'], tr/val_loss:  0.514227/  1.201536, tr:  82.23%, val:  72.08%, val_best:  72.08%: 100%|██████████| 62/62 [00:05<00:00, 11.11it/s]\n",
      "epoch-11  lr=['0.0091934'], tr/val_loss:  0.474345/  1.376083, tr:  82.43%, val:  66.25%, val_best:  72.08%: 100%|██████████| 62/62 [00:06<00:00,  9.76it/s]\n",
      "epoch-12  lr=['0.0090451'], tr/val_loss:  0.447857/  1.220748, tr:  84.98%, val:  72.08%, val_best:  72.08%: 100%|██████████| 62/62 [00:05<00:00, 10.98it/s]\n",
      "epoch-13  lr=['0.0088857'], tr/val_loss:  0.436335/  1.387996, tr:  86.41%, val:  67.92%, val_best:  72.08%: 100%|██████████| 62/62 [00:07<00:00,  8.85it/s]\n",
      "epoch-14  lr=['0.0087157'], tr/val_loss:  0.348831/  1.258669, tr:  91.52%, val:  71.25%, val_best:  72.08%: 100%|██████████| 62/62 [00:05<00:00, 11.68it/s]\n",
      "epoch-15  lr=['0.0085355'], tr/val_loss:  0.331194/  1.309262, tr:  92.13%, val:  72.92%, val_best:  72.92%: 100%|██████████| 62/62 [00:05<00:00, 11.50it/s]\n",
      "epoch-16  lr=['0.0083457'], tr/val_loss:  0.247389/  1.385050, tr:  95.51%, val:  74.17%, val_best:  74.17%: 100%|██████████| 62/62 [00:05<00:00, 11.45it/s]\n",
      "epoch-17  lr=['0.0081466'], tr/val_loss:  0.253504/  1.340800, tr:  95.30%, val:  72.92%, val_best:  74.17%: 100%|██████████| 62/62 [00:04<00:00, 12.62it/s]\n",
      "epoch-18  lr=['0.0079389'], tr/val_loss:  0.236144/  1.297616, tr:  96.32%, val:  77.08%, val_best:  77.08%: 100%|██████████| 62/62 [00:06<00:00,  9.56it/s]\n",
      "epoch-19  lr=['0.0077232'], tr/val_loss:  0.183559/  1.382703, tr:  97.96%, val:  78.33%, val_best:  78.33%: 100%|██████████| 62/62 [00:05<00:00, 10.83it/s]\n",
      "epoch-20  lr=['0.0075000'], tr/val_loss:  0.157666/  1.291293, tr:  99.08%, val:  78.75%, val_best:  78.75%: 100%|██████████| 62/62 [00:05<00:00, 10.70it/s]\n",
      "epoch-21  lr=['0.0072700'], tr/val_loss:  0.092693/  1.450559, tr:  99.80%, val:  77.50%, val_best:  78.75%: 100%|██████████| 62/62 [00:05<00:00, 11.21it/s]\n",
      "epoch-22  lr=['0.0070337'], tr/val_loss:  0.071845/  1.453112, tr:  99.90%, val:  77.50%, val_best:  78.75%: 100%|██████████| 62/62 [00:06<00:00,  9.98it/s]\n",
      "epoch-23  lr=['0.0067918'], tr/val_loss:  0.044339/  1.474534, tr: 100.00%, val:  80.00%, val_best:  80.00%: 100%|██████████| 62/62 [00:06<00:00,  8.99it/s]\n",
      "epoch-24  lr=['0.0065451'], tr/val_loss:  0.055404/  1.582713, tr: 100.00%, val:  79.17%, val_best:  80.00%: 100%|██████████| 62/62 [00:05<00:00, 10.63it/s]\n",
      "epoch-25  lr=['0.0062941'], tr/val_loss:  0.047712/  1.602529, tr: 100.00%, val:  75.00%, val_best:  80.00%: 100%|██████████| 62/62 [00:05<00:00, 12.28it/s]\n",
      "epoch-26  lr=['0.0060396'], tr/val_loss:  0.025859/  1.678018, tr: 100.00%, val:  76.25%, val_best:  80.00%: 100%|██████████| 62/62 [00:05<00:00, 11.63it/s]\n",
      "epoch-27  lr=['0.0057822'], tr/val_loss:  0.017739/  1.620678, tr: 100.00%, val:  80.42%, val_best:  80.42%: 100%|██████████| 62/62 [00:05<00:00, 11.95it/s]\n",
      "epoch-28  lr=['0.0055226'], tr/val_loss:  0.009482/  1.634035, tr: 100.00%, val:  80.42%, val_best:  80.42%: 100%|██████████| 62/62 [00:05<00:00, 11.29it/s]\n",
      "epoch-29  lr=['0.0052617'], tr/val_loss:  0.006684/  1.691191, tr: 100.00%, val:  81.67%, val_best:  81.67%: 100%|██████████| 62/62 [00:05<00:00, 11.79it/s]\n",
      "epoch-30  lr=['0.0050000'], tr/val_loss:  0.005167/  1.704525, tr: 100.00%, val:  79.58%, val_best:  81.67%: 100%|██████████| 62/62 [00:05<00:00, 11.94it/s]\n",
      "epoch-31  lr=['0.0047383'], tr/val_loss:  0.004086/  1.694322, tr: 100.00%, val:  79.17%, val_best:  81.67%: 100%|██████████| 62/62 [00:05<00:00, 11.94it/s]\n",
      "epoch-32  lr=['0.0044774'], tr/val_loss:  0.003262/  1.695988, tr: 100.00%, val:  78.75%, val_best:  81.67%: 100%|██████████| 62/62 [00:05<00:00, 11.89it/s]\n",
      "epoch-33  lr=['0.0042178'], tr/val_loss:  0.002853/  1.706066, tr: 100.00%, val:  78.33%, val_best:  81.67%: 100%|██████████| 62/62 [00:05<00:00, 11.87it/s]\n",
      "epoch-34  lr=['0.0039604'], tr/val_loss:  0.002609/  1.720457, tr: 100.00%, val:  79.58%, val_best:  81.67%: 100%|██████████| 62/62 [00:05<00:00, 10.45it/s]\n",
      "epoch-35  lr=['0.0037059'], tr/val_loss:  0.002311/  1.720579, tr: 100.00%, val:  78.75%, val_best:  81.67%: 100%|██████████| 62/62 [00:05<00:00, 12.38it/s]\n",
      "epoch-36  lr=['0.0034549'], tr/val_loss:  0.002202/  1.739750, tr: 100.00%, val:  78.75%, val_best:  81.67%: 100%|██████████| 62/62 [00:05<00:00, 11.97it/s]\n",
      "epoch-37  lr=['0.0032082'], tr/val_loss:  0.002029/  1.732921, tr: 100.00%, val:  78.33%, val_best:  81.67%: 100%|██████████| 62/62 [00:05<00:00, 11.81it/s]\n",
      "epoch-38  lr=['0.0029663'], tr/val_loss:  0.001903/  1.751033, tr: 100.00%, val:  78.75%, val_best:  81.67%: 100%|██████████| 62/62 [00:05<00:00, 11.79it/s]\n",
      "epoch-39  lr=['0.0027300'], tr/val_loss:  0.001851/  1.740452, tr: 100.00%, val:  78.33%, val_best:  81.67%: 100%|██████████| 62/62 [00:05<00:00, 11.87it/s]\n",
      "epoch-40  lr=['0.0025000'], tr/val_loss:  0.001786/  1.738909, tr: 100.00%, val:  78.33%, val_best:  81.67%: 100%|██████████| 62/62 [00:05<00:00, 11.90it/s]\n",
      "epoch-41  lr=['0.0022768'], tr/val_loss:  0.001736/  1.735919, tr: 100.00%, val:  78.75%, val_best:  81.67%: 100%|██████████| 62/62 [00:04<00:00, 12.50it/s]\n",
      "epoch-42  lr=['0.0020611'], tr/val_loss:  0.001653/  1.741479, tr: 100.00%, val:  78.33%, val_best:  81.67%: 100%|██████████| 62/62 [00:05<00:00, 12.15it/s]\n",
      "epoch-43  lr=['0.0018534'], tr/val_loss:  0.001665/  1.746424, tr: 100.00%, val:  78.33%, val_best:  81.67%: 100%|██████████| 62/62 [00:05<00:00, 12.14it/s]\n",
      "epoch-44  lr=['0.0016543'], tr/val_loss:  0.001572/  1.752073, tr: 100.00%, val:  78.33%, val_best:  81.67%: 100%|██████████| 62/62 [00:05<00:00, 11.87it/s]\n",
      "epoch-45  lr=['0.0014645'], tr/val_loss:  0.001574/  1.751372, tr: 100.00%, val:  78.33%, val_best:  81.67%: 100%|██████████| 62/62 [00:05<00:00, 11.46it/s]\n",
      "epoch-46  lr=['0.0012843'], tr/val_loss:  0.001515/  1.746810, tr: 100.00%, val:  78.33%, val_best:  81.67%: 100%|██████████| 62/62 [00:05<00:00, 11.74it/s]\n",
      "epoch-47  lr=['0.0011143'], tr/val_loss:  0.001505/  1.744720, tr: 100.00%, val:  79.17%, val_best:  81.67%: 100%|██████████| 62/62 [00:05<00:00, 11.71it/s]\n",
      "epoch-48  lr=['0.0009549'], tr/val_loss:  0.001515/  1.744521, tr: 100.00%, val:  79.17%, val_best:  81.67%: 100%|██████████| 62/62 [00:05<00:00, 11.85it/s]\n",
      "epoch-49  lr=['0.0008066'], tr/val_loss:  0.001466/  1.749498, tr: 100.00%, val:  79.17%, val_best:  81.67%: 100%|██████████| 62/62 [00:05<00:00, 12.18it/s]\n",
      "epoch-50  lr=['0.0006699'], tr/val_loss:  0.001462/  1.751504, tr: 100.00%, val:  79.17%, val_best:  81.67%: 100%|██████████| 62/62 [00:05<00:00, 11.73it/s]\n",
      "epoch-51  lr=['0.0005450'], tr/val_loss:  0.001461/  1.757751, tr: 100.00%, val:  79.17%, val_best:  81.67%: 100%|██████████| 62/62 [00:05<00:00, 12.09it/s]\n",
      "epoch-52  lr=['0.0004323'], tr/val_loss:  0.001423/  1.754528, tr: 100.00%, val:  79.17%, val_best:  81.67%: 100%|██████████| 62/62 [00:05<00:00, 11.79it/s]\n",
      "epoch-53  lr=['0.0003321'], tr/val_loss:  0.001421/  1.758726, tr: 100.00%, val:  79.17%, val_best:  81.67%: 100%|██████████| 62/62 [00:05<00:00, 11.26it/s]\n",
      "epoch-54  lr=['0.0002447'], tr/val_loss:  0.001456/  1.756695, tr: 100.00%, val:  79.17%, val_best:  81.67%: 100%|██████████| 62/62 [00:05<00:00, 11.70it/s]\n",
      "epoch-55  lr=['0.0001704'], tr/val_loss:  0.001398/  1.755243, tr: 100.00%, val:  79.17%, val_best:  81.67%: 100%|██████████| 62/62 [00:05<00:00, 11.89it/s]\n",
      "epoch-56  lr=['0.0001093'], tr/val_loss:  0.001407/  1.756813, tr: 100.00%, val:  79.17%, val_best:  81.67%: 100%|██████████| 62/62 [00:05<00:00, 11.10it/s]\n",
      "epoch-57  lr=['0.0000616'], tr/val_loss:  0.001420/  1.756562, tr: 100.00%, val:  79.17%, val_best:  81.67%: 100%|██████████| 62/62 [00:05<00:00, 11.78it/s]\n",
      "epoch-58  lr=['0.0000274'], tr/val_loss:  0.001404/  1.756730, tr: 100.00%, val:  79.17%, val_best:  81.67%: 100%|██████████| 62/62 [00:05<00:00, 12.08it/s]\n",
      "epoch-59  lr=['0.0000069'], tr/val_loss:  0.001396/  1.756736, tr: 100.00%, val:  79.17%, val_best:  81.67%: 100%|██████████| 62/62 [00:05<00:00, 12.21it/s]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "28d17236cde843dfb84cdeaf02fe4913",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='3.438 MB of 3.438 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>DFA_flag</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>epoch</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇████</td></tr><tr><td>iter_acc</td><td>▁▄▃▃▅▅▅▆▆▆▇█▇███████████████████████████</td></tr><tr><td>summary_val_acc</td><td>▁▆▆▆▆▆▇▇▇▇▇▇▇████▇██████████████████████</td></tr><tr><td>tr_acc</td><td>▁▄▅▆▆▆▆▇▇▇▇█████████████████████████████</td></tr><tr><td>tr_epoch_loss</td><td>▁█▅▅▄▄▄▃▃▃▃▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_acc_best</td><td>▁▆▆▆▆▆▇▇▇▇▇▇▇███████████████████████████</td></tr><tr><td>val_acc_now</td><td>▁▆▆▆▆▆▇▇▇▇▇▇▇████▇██████████████████████</td></tr><tr><td>val_loss</td><td>▁▆▆▅▆▅▆▆▆▆▆▇▆▇▆▇▇▇██████████████████████</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>DFA_flag</td><td>0.0</td></tr><tr><td>epoch</td><td>59</td></tr><tr><td>iter_acc</td><td>1.0</td></tr><tr><td>tr_acc</td><td>1.0</td></tr><tr><td>tr_epoch_loss</td><td>0.0014</td></tr><tr><td>val_acc_best</td><td>0.81667</td></tr><tr><td>val_acc_now</td><td>0.79167</td></tr><tr><td>val_loss</td><td>1.75674</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">driven-sweep-42</strong> at: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/gfaj3ug7' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/gfaj3ug7</a><br/> View project at: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main</a><br/>Synced 7 W&B file(s), 0 media file(s), 0 artifact file(s) and 1 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20240822_190036-gfaj3ug7/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require(\"core\")`! See https://wandb.me/wandb-core for more information."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: hkqlkjwg with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBATCH: 16\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tDFA_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tIMAGE_SIZE: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tOTTT_input_trace_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tOTTT_sWS_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tTIME: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcfg: ['M', 'M', 200, 200]\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tconst2: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdecay: 0.25\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdrop_rate: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdvs_clipping: 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdvs_duration: 100000\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \te_transport_swap: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \te_transport_swap_coin: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \te_transport_swap_tr: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepoch_num: 60\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \texclude_class: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.01\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_sg_width: 2.570969004857107\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_reset: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_threshold: 0.4791925799446197\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmerge_polarities: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tscheduler_name: CosineAnnealingLR\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsurrogate: hard_sigmoid\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \twhich_data: DVS_GESTURE_TONIC\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.17.7 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.17.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/nfs/home/bhkim003/github_folder/ByeonghyeonKim/my_snn/wandb/run-20240822_190647-hkqlkjwg</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/hkqlkjwg' target=\"_blank\">brisk-sweep-44</a></strong> to <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/yxynyr6h' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/yxynyr6h</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/yxynyr6h' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/yxynyr6h</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/hkqlkjwg' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/hkqlkjwg</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BATCH' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'IMAGE_SIZE' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'which_data' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_threshold' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_reset' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_sg_width' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'cfg' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'learning_rate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'epoch_num' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'surrogate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'scheduler_name' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'dvs_clipping' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'dvs_duration' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'OTTT_sWS_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'DFA_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'OTTT_input_trace_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'e_transport_swap' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'e_transport_swap_tr' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'e_transport_swap_coin' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'drop_rate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'exclude_class' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'merge_polarities' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'TIME' was locked by 'sweep' (ignored update).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset_hash = 2bbd58b4e0d3c1e9ad501fad8a43feed\n",
      "cache path exists\n",
      "\n",
      "we will exclude the 'other' class. dvsgestrue 10 classes' indices exist. \n",
      "\n",
      "DataParallel(\n",
      "  (module): MY_SNN_FC_sstep(\n",
      "    (layers): MY_Sequential(\n",
      "      (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (2): DimChanger_for_FC_sstep()\n",
      "      (3): SYNAPSE_FC_trace_sstep()\n",
      "      (4): LIF_layer_trace_sstep()\n",
      "      (5): SYNAPSE_FC_trace_sstep()\n",
      "      (6): LIF_layer_trace_sstep()\n",
      "      (7): SYNAPSE_FC_trace_sstep()\n",
      "    )\n",
      "  )\n",
      ")\n",
      "==================================================\n",
      "My Num of PARAMS: 452,010, system's param_num : 452,010\n",
      "Memory: 1.72MiB at 32-bit\n",
      "==================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch-0   lr=['0.0100000'], tr/val_loss:  1.530620/  1.298223, tr:  47.40%, val:  55.00%, val_best:  55.00%: 100%|██████████| 62/62 [00:05<00:00, 11.98it/s]\n",
      "epoch-1   lr=['0.0099931'], tr/val_loss:  1.108306/  1.339362, tr:  59.75%, val:  55.00%, val_best:  55.00%: 100%|██████████| 62/62 [00:05<00:00, 11.99it/s]\n",
      "epoch-2   lr=['0.0099726'], tr/val_loss:  0.964549/  1.267476, tr:  64.45%, val:  64.58%, val_best:  64.58%: 100%|██████████| 62/62 [00:05<00:00, 12.02it/s]\n",
      "epoch-3   lr=['0.0099384'], tr/val_loss:  0.873545/  1.158372, tr:  68.23%, val:  60.42%, val_best:  64.58%: 100%|██████████| 62/62 [00:04<00:00, 12.56it/s]\n",
      "epoch-4   lr=['0.0098907'], tr/val_loss:  0.789570/  1.173318, tr:  70.28%, val:  65.00%, val_best:  65.00%: 100%|██████████| 62/62 [00:06<00:00,  9.44it/s]\n",
      "epoch-5   lr=['0.0098296'], tr/val_loss:  0.786519/  1.385713, tr:  70.99%, val:  61.25%, val_best:  65.00%: 100%|██████████| 62/62 [00:05<00:00, 10.66it/s]\n",
      "epoch-6   lr=['0.0097553'], tr/val_loss:  0.724656/  1.104965, tr:  74.26%, val:  62.92%, val_best:  65.00%: 100%|██████████| 62/62 [00:05<00:00, 10.62it/s]\n",
      "epoch-7   lr=['0.0096679'], tr/val_loss:  0.688832/  1.266398, tr:  75.18%, val:  60.00%, val_best:  65.00%: 100%|██████████| 62/62 [00:05<00:00, 10.99it/s]\n",
      "epoch-8   lr=['0.0095677'], tr/val_loss:  0.613303/  1.076528, tr:  76.10%, val:  67.50%, val_best:  67.50%: 100%|██████████| 62/62 [00:06<00:00, 10.02it/s]\n",
      "epoch-9   lr=['0.0094550'], tr/val_loss:  0.495822/  1.353011, tr:  82.74%, val:  65.42%, val_best:  67.50%: 100%|██████████| 62/62 [00:06<00:00,  9.62it/s]\n",
      "epoch-10  lr=['0.0093301'], tr/val_loss:  0.519602/  1.086939, tr:  82.64%, val:  72.08%, val_best:  72.08%: 100%|██████████| 62/62 [00:05<00:00, 11.20it/s]\n",
      "epoch-11  lr=['0.0091934'], tr/val_loss:  0.416462/  1.320975, tr:  85.80%, val:  68.75%, val_best:  72.08%: 100%|██████████| 62/62 [00:06<00:00, 10.01it/s]\n",
      "epoch-12  lr=['0.0090451'], tr/val_loss:  0.397144/  1.201467, tr:  89.58%, val:  78.33%, val_best:  78.33%: 100%|██████████| 62/62 [00:05<00:00, 10.79it/s]\n",
      "epoch-13  lr=['0.0088857'], tr/val_loss:  0.385128/  1.244672, tr:  87.54%, val:  75.00%, val_best:  78.33%: 100%|██████████| 62/62 [00:05<00:00, 12.25it/s]\n",
      "epoch-14  lr=['0.0087157'], tr/val_loss:  0.329067/  1.207731, tr:  91.32%, val:  75.83%, val_best:  78.33%: 100%|██████████| 62/62 [00:05<00:00, 12.15it/s]\n",
      "epoch-15  lr=['0.0085355'], tr/val_loss:  0.304359/  1.288774, tr:  93.05%, val:  76.67%, val_best:  78.33%: 100%|██████████| 62/62 [00:05<00:00, 12.07it/s]\n",
      "epoch-16  lr=['0.0083457'], tr/val_loss:  0.246948/  1.383530, tr:  96.22%, val:  73.75%, val_best:  78.33%: 100%|██████████| 62/62 [00:05<00:00, 11.78it/s]\n",
      "epoch-17  lr=['0.0081466'], tr/val_loss:  0.259550/  1.309649, tr:  94.59%, val:  74.58%, val_best:  78.33%: 100%|██████████| 62/62 [00:05<00:00, 12.05it/s]\n",
      "epoch-18  lr=['0.0079389'], tr/val_loss:  0.228453/  1.366531, tr:  96.83%, val:  79.17%, val_best:  79.17%: 100%|██████████| 62/62 [00:06<00:00,  9.45it/s]\n",
      "epoch-19  lr=['0.0077232'], tr/val_loss:  0.159719/  1.324341, tr:  98.57%, val:  79.17%, val_best:  79.17%: 100%|██████████| 62/62 [00:06<00:00, 10.09it/s]\n",
      "epoch-20  lr=['0.0075000'], tr/val_loss:  0.112641/  1.393405, tr:  99.59%, val:  83.33%, val_best:  83.33%: 100%|██████████| 62/62 [00:05<00:00, 10.62it/s]\n",
      "epoch-21  lr=['0.0072700'], tr/val_loss:  0.069299/  1.481597, tr: 100.00%, val:  80.83%, val_best:  83.33%: 100%|██████████| 62/62 [00:06<00:00, 10.09it/s]\n",
      "epoch-22  lr=['0.0070337'], tr/val_loss:  0.053410/  1.469181, tr:  99.90%, val:  79.58%, val_best:  83.33%: 100%|██████████| 62/62 [00:05<00:00, 10.56it/s]\n",
      "epoch-23  lr=['0.0067918'], tr/val_loss:  0.034815/  1.551656, tr: 100.00%, val:  78.75%, val_best:  83.33%: 100%|██████████| 62/62 [00:06<00:00,  9.69it/s]\n",
      "epoch-24  lr=['0.0065451'], tr/val_loss:  0.021081/  1.580769, tr: 100.00%, val:  78.75%, val_best:  83.33%: 100%|██████████| 62/62 [00:06<00:00, 10.25it/s]\n",
      "epoch-25  lr=['0.0062941'], tr/val_loss:  0.014125/  1.572095, tr: 100.00%, val:  82.92%, val_best:  83.33%: 100%|██████████| 62/62 [00:06<00:00, 10.27it/s]\n",
      "epoch-26  lr=['0.0060396'], tr/val_loss:  0.009296/  1.584756, tr: 100.00%, val:  83.33%, val_best:  83.33%: 100%|██████████| 62/62 [00:05<00:00, 10.57it/s]\n",
      "epoch-27  lr=['0.0057822'], tr/val_loss:  0.006768/  1.590299, tr: 100.00%, val:  82.50%, val_best:  83.33%: 100%|██████████| 62/62 [00:06<00:00, 10.15it/s]\n",
      "epoch-28  lr=['0.0055226'], tr/val_loss:  0.005043/  1.621377, tr: 100.00%, val:  82.92%, val_best:  83.33%: 100%|██████████| 62/62 [00:05<00:00, 10.45it/s]\n",
      "epoch-29  lr=['0.0052617'], tr/val_loss:  0.003837/  1.653558, tr: 100.00%, val:  81.67%, val_best:  83.33%: 100%|██████████| 62/62 [00:06<00:00,  9.82it/s]\n",
      "epoch-30  lr=['0.0050000'], tr/val_loss:  0.002858/  1.658467, tr: 100.00%, val:  81.25%, val_best:  83.33%: 100%|██████████| 62/62 [00:05<00:00, 10.63it/s]\n",
      "epoch-31  lr=['0.0047383'], tr/val_loss:  0.002457/  1.650923, tr: 100.00%, val:  82.08%, val_best:  83.33%: 100%|██████████| 62/62 [00:05<00:00, 10.64it/s]\n",
      "epoch-32  lr=['0.0044774'], tr/val_loss:  0.002157/  1.660065, tr: 100.00%, val:  81.67%, val_best:  83.33%: 100%|██████████| 62/62 [00:06<00:00, 10.31it/s]\n",
      "epoch-33  lr=['0.0042178'], tr/val_loss:  0.001967/  1.673364, tr: 100.00%, val:  82.08%, val_best:  83.33%: 100%|██████████| 62/62 [00:05<00:00, 10.58it/s]\n",
      "epoch-34  lr=['0.0039604'], tr/val_loss:  0.001784/  1.671594, tr: 100.00%, val:  81.25%, val_best:  83.33%: 100%|██████████| 62/62 [00:06<00:00,  9.94it/s]\n",
      "epoch-35  lr=['0.0037059'], tr/val_loss:  0.001701/  1.682516, tr: 100.00%, val:  81.25%, val_best:  83.33%: 100%|██████████| 62/62 [00:06<00:00,  9.78it/s]\n",
      "epoch-36  lr=['0.0034549'], tr/val_loss:  0.001635/  1.688552, tr: 100.00%, val:  81.25%, val_best:  83.33%: 100%|██████████| 62/62 [00:06<00:00,  9.52it/s]\n",
      "epoch-37  lr=['0.0032082'], tr/val_loss:  0.001534/  1.702047, tr: 100.00%, val:  81.67%, val_best:  83.33%: 100%|██████████| 62/62 [00:06<00:00,  9.02it/s]\n",
      "epoch-38  lr=['0.0029663'], tr/val_loss:  0.001458/  1.696652, tr: 100.00%, val:  81.25%, val_best:  83.33%: 100%|██████████| 62/62 [00:06<00:00,  9.98it/s]\n",
      "epoch-39  lr=['0.0027300'], tr/val_loss:  0.001391/  1.699218, tr: 100.00%, val:  81.67%, val_best:  83.33%: 100%|██████████| 62/62 [00:06<00:00, 10.10it/s]\n",
      "epoch-40  lr=['0.0025000'], tr/val_loss:  0.001385/  1.710093, tr: 100.00%, val:  81.67%, val_best:  83.33%: 100%|██████████| 62/62 [00:06<00:00, 10.06it/s]\n",
      "epoch-41  lr=['0.0022768'], tr/val_loss:  0.001353/  1.714882, tr: 100.00%, val:  81.67%, val_best:  83.33%: 100%|██████████| 62/62 [00:05<00:00, 10.35it/s]\n",
      "epoch-42  lr=['0.0020611'], tr/val_loss:  0.001289/  1.718655, tr: 100.00%, val:  81.67%, val_best:  83.33%: 100%|██████████| 62/62 [00:06<00:00,  9.28it/s]\n",
      "epoch-43  lr=['0.0018534'], tr/val_loss:  0.001280/  1.720104, tr: 100.00%, val:  81.67%, val_best:  83.33%: 100%|██████████| 62/62 [00:05<00:00, 10.66it/s]\n",
      "epoch-44  lr=['0.0016543'], tr/val_loss:  0.001216/  1.726165, tr: 100.00%, val:  81.25%, val_best:  83.33%: 100%|██████████| 62/62 [00:06<00:00, 10.13it/s]\n",
      "epoch-45  lr=['0.0014645'], tr/val_loss:  0.001237/  1.726814, tr: 100.00%, val:  81.25%, val_best:  83.33%: 100%|██████████| 62/62 [00:06<00:00,  9.65it/s]\n",
      "epoch-46  lr=['0.0012843'], tr/val_loss:  0.001213/  1.727342, tr: 100.00%, val:  81.25%, val_best:  83.33%: 100%|██████████| 62/62 [00:06<00:00,  9.55it/s]\n",
      "epoch-47  lr=['0.0011143'], tr/val_loss:  0.001214/  1.724925, tr: 100.00%, val:  81.67%, val_best:  83.33%: 100%|██████████| 62/62 [00:05<00:00, 10.55it/s]\n",
      "epoch-48  lr=['0.0009549'], tr/val_loss:  0.001161/  1.729093, tr: 100.00%, val:  81.25%, val_best:  83.33%: 100%|██████████| 62/62 [00:06<00:00, 10.23it/s]\n",
      "epoch-49  lr=['0.0008066'], tr/val_loss:  0.001149/  1.732928, tr: 100.00%, val:  81.25%, val_best:  83.33%: 100%|██████████| 62/62 [00:05<00:00, 10.40it/s]\n",
      "epoch-50  lr=['0.0006699'], tr/val_loss:  0.001166/  1.732324, tr: 100.00%, val:  81.67%, val_best:  83.33%: 100%|██████████| 62/62 [00:06<00:00, 10.11it/s]\n",
      "epoch-51  lr=['0.0005450'], tr/val_loss:  0.001134/  1.735859, tr: 100.00%, val:  81.25%, val_best:  83.33%: 100%|██████████| 62/62 [00:07<00:00,  8.85it/s]\n",
      "epoch-52  lr=['0.0004323'], tr/val_loss:  0.001140/  1.734572, tr: 100.00%, val:  81.25%, val_best:  83.33%: 100%|██████████| 62/62 [00:06<00:00, 10.26it/s]\n",
      "epoch-53  lr=['0.0003321'], tr/val_loss:  0.001131/  1.733229, tr: 100.00%, val:  81.25%, val_best:  83.33%: 100%|██████████| 62/62 [00:06<00:00,  9.98it/s]\n",
      "epoch-54  lr=['0.0002447'], tr/val_loss:  0.001123/  1.733663, tr: 100.00%, val:  81.25%, val_best:  83.33%: 100%|██████████| 62/62 [00:06<00:00, 10.19it/s]\n",
      "epoch-55  lr=['0.0001704'], tr/val_loss:  0.001117/  1.733378, tr: 100.00%, val:  81.25%, val_best:  83.33%: 100%|██████████| 62/62 [00:05<00:00, 10.63it/s]\n",
      "epoch-56  lr=['0.0001093'], tr/val_loss:  0.001109/  1.732539, tr: 100.00%, val:  81.25%, val_best:  83.33%: 100%|██████████| 62/62 [00:06<00:00, 10.33it/s]\n",
      "epoch-57  lr=['0.0000616'], tr/val_loss:  0.001116/  1.732907, tr: 100.00%, val:  81.25%, val_best:  83.33%: 100%|██████████| 62/62 [00:05<00:00, 10.84it/s]\n",
      "epoch-58  lr=['0.0000274'], tr/val_loss:  0.001118/  1.732687, tr: 100.00%, val:  81.25%, val_best:  83.33%: 100%|██████████| 62/62 [00:06<00:00,  9.97it/s]\n",
      "epoch-59  lr=['0.0000069'], tr/val_loss:  0.001121/  1.732691, tr: 100.00%, val:  81.25%, val_best:  83.33%: 100%|██████████| 62/62 [00:05<00:00, 10.69it/s]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "117573debf0c477fa84dbc5cf1c513d4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='3.438 MB of 3.438 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>DFA_flag</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>epoch</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇████</td></tr><tr><td>iter_acc</td><td>▁▃▃▃▆▅▅▅▇▆▇▇████████████████████████████</td></tr><tr><td>summary_val_acc</td><td>▁▆▆▆▆▆▇▆▇█▇▇▇███████████████████████████</td></tr><tr><td>tr_acc</td><td>▁▄▆▆▆▆▆▇▇▇▇█████████████████████████████</td></tr><tr><td>tr_epoch_loss</td><td>▁█▅▅▅▄▄▃▃▃▃▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_acc_best</td><td>▁▆▆▆▆▆▇▇▇███████████████████████████████</td></tr><tr><td>val_acc_now</td><td>▁▆▆▆▆▆▇▆▇█▇▇▇███████████████████████████</td></tr><tr><td>val_loss</td><td>▁▆▆▆▇▅▅▆▆▆▆▇▆▆▇▇▇▇▇█████████████████████</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>DFA_flag</td><td>0.0</td></tr><tr><td>epoch</td><td>59</td></tr><tr><td>iter_acc</td><td>1.0</td></tr><tr><td>tr_acc</td><td>1.0</td></tr><tr><td>tr_epoch_loss</td><td>0.00112</td></tr><tr><td>val_acc_best</td><td>0.83333</td></tr><tr><td>val_acc_now</td><td>0.8125</td></tr><tr><td>val_loss</td><td>1.73269</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">brisk-sweep-44</strong> at: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/hkqlkjwg' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/hkqlkjwg</a><br/> View project at: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main</a><br/>Synced 7 W&B file(s), 0 media file(s), 0 artifact file(s) and 1 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20240822_190647-hkqlkjwg/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require(\"core\")`! See https://wandb.me/wandb-core for more information."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Sweep Agent: Waiting for job.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Job received.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 8mxonj4n with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBATCH: 16\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tDFA_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tIMAGE_SIZE: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tOTTT_input_trace_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tOTTT_sWS_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tTIME: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcfg: ['M', 'M', 200, 200]\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tconst2: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdecay: 0.25\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdrop_rate: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdvs_clipping: 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdvs_duration: 100000\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \te_transport_swap: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \te_transport_swap_coin: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \te_transport_swap_tr: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepoch_num: 60\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \texclude_class: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.01\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_sg_width: 2.570969004857107\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_reset: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_threshold: 1.7585499523761543\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmerge_polarities: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tscheduler_name: CosineAnnealingLR\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsurrogate: hard_sigmoid\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \twhich_data: DVS_GESTURE_TONIC\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.17.7 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.17.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/nfs/home/bhkim003/github_folder/ByeonghyeonKim/my_snn/wandb/run-20240822_191324-8mxonj4n</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/8mxonj4n' target=\"_blank\">spring-sweep-46</a></strong> to <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/yxynyr6h' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/yxynyr6h</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/yxynyr6h' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/yxynyr6h</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/8mxonj4n' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/8mxonj4n</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BATCH' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'IMAGE_SIZE' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'which_data' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_threshold' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_reset' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_sg_width' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'cfg' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'learning_rate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'epoch_num' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'surrogate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'scheduler_name' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'dvs_clipping' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'dvs_duration' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'OTTT_sWS_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'DFA_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'OTTT_input_trace_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'e_transport_swap' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'e_transport_swap_tr' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'e_transport_swap_coin' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'drop_rate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'exclude_class' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'merge_polarities' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'TIME' was locked by 'sweep' (ignored update).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset_hash = 2bbd58b4e0d3c1e9ad501fad8a43feed\n",
      "cache path exists\n",
      "\n",
      "we will exclude the 'other' class. dvsgestrue 10 classes' indices exist. \n",
      "\n",
      "DataParallel(\n",
      "  (module): MY_SNN_FC_sstep(\n",
      "    (layers): MY_Sequential(\n",
      "      (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (2): DimChanger_for_FC_sstep()\n",
      "      (3): SYNAPSE_FC_trace_sstep()\n",
      "      (4): LIF_layer_trace_sstep()\n",
      "      (5): SYNAPSE_FC_trace_sstep()\n",
      "      (6): LIF_layer_trace_sstep()\n",
      "      (7): SYNAPSE_FC_trace_sstep()\n",
      "    )\n",
      "  )\n",
      ")\n",
      "==================================================\n",
      "My Num of PARAMS: 452,010, system's param_num : 452,010\n",
      "Memory: 1.72MiB at 32-bit\n",
      "==================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch-0   lr=['0.0100000'], tr/val_loss:  2.317507/  2.316367, tr:   9.70%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:06<00:00,  9.82it/s]\n",
      "epoch-1   lr=['0.0099931'], tr/val_loss:  2.316254/  2.314931, tr:  10.21%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:05<00:00, 10.39it/s]\n",
      "epoch-2   lr=['0.0099726'], tr/val_loss:  2.315321/  2.315877, tr:   9.81%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:05<00:00, 10.39it/s]\n",
      "epoch-3   lr=['0.0099384'], tr/val_loss:  2.319123/  2.321801, tr:  10.42%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:06<00:00, 10.30it/s]\n",
      "epoch-4   lr=['0.0098907'], tr/val_loss:  2.328817/  2.310750, tr:   7.66%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:05<00:00, 10.93it/s]\n",
      "epoch-5   lr=['0.0098296'], tr/val_loss:  2.318780/  2.313111, tr:   8.58%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:05<00:00, 11.24it/s]\n",
      "epoch-6   lr=['0.0097553'], tr/val_loss:  2.326567/  2.312034, tr:   8.89%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:06<00:00,  9.45it/s]\n",
      "epoch-7   lr=['0.0096679'], tr/val_loss:  2.319906/  2.308871, tr:   8.89%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:05<00:00, 10.48it/s]\n",
      "epoch-8   lr=['0.0095677'], tr/val_loss:  2.315703/  2.318316, tr:   9.09%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:05<00:00, 11.34it/s]\n",
      "epoch-9   lr=['0.0094550'], tr/val_loss:  2.315776/  2.321137, tr:   9.81%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:05<00:00, 11.00it/s]\n",
      "epoch-10  lr=['0.0093301'], tr/val_loss:  2.319218/  2.310921, tr:   9.40%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:05<00:00, 10.71it/s]\n",
      "epoch-11  lr=['0.0091934'], tr/val_loss:  2.320658/  2.318817, tr:   9.60%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:05<00:00, 12.28it/s]\n",
      "epoch-12  lr=['0.0090451'], tr/val_loss:  2.323760/  2.306959, tr:   9.70%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:05<00:00, 11.53it/s]\n",
      "epoch-13  lr=['0.0088857'], tr/val_loss:  2.312257/  2.313825, tr:   8.78%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:05<00:00, 11.76it/s]\n",
      "epoch-14  lr=['0.0087157'], tr/val_loss:  2.321870/  2.310401, tr:   9.70%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:05<00:00, 11.63it/s]\n",
      "epoch-15  lr=['0.0085355'], tr/val_loss:  2.318407/  2.313874, tr:   9.60%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:05<00:00, 11.39it/s]\n",
      "epoch-16  lr=['0.0083457'], tr/val_loss:  2.317499/  2.312321, tr:  10.11%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:06<00:00,  9.91it/s]\n",
      "epoch-17  lr=['0.0081466'], tr/val_loss:  2.318669/  2.307941, tr:   8.89%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:06<00:00,  9.63it/s]\n",
      "epoch-18  lr=['0.0079389'], tr/val_loss:  2.325135/  2.306585, tr:   7.46%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:05<00:00, 10.80it/s]\n",
      "epoch-19  lr=['0.0077232'], tr/val_loss:  2.314244/  2.310251, tr:  10.01%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:06<00:00, 10.14it/s]\n",
      "epoch-20  lr=['0.0075000'], tr/val_loss:  2.312182/  2.307967, tr:   9.91%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:05<00:00, 10.75it/s]\n",
      "epoch-21  lr=['0.0072700'], tr/val_loss:  2.318818/  2.307295, tr:   9.30%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:06<00:00, 10.14it/s]\n",
      "epoch-22  lr=['0.0070337'], tr/val_loss:  2.313441/  2.307399, tr:   9.91%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:05<00:00, 11.72it/s]\n",
      "epoch-23  lr=['0.0067918'], tr/val_loss:  2.314248/  2.309416, tr:   7.76%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:05<00:00, 11.06it/s]\n",
      "epoch-24  lr=['0.0065451'], tr/val_loss:  2.318841/  2.305136, tr:   9.09%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:05<00:00, 10.85it/s]\n",
      "epoch-25  lr=['0.0062941'], tr/val_loss:  2.316903/  2.306750, tr:   7.97%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:05<00:00, 10.43it/s]\n",
      "epoch-26  lr=['0.0060396'], tr/val_loss:  2.311055/  2.305107, tr:   8.99%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:06<00:00, 10.01it/s]\n",
      "epoch-27  lr=['0.0057822'], tr/val_loss:  2.313828/  2.306802, tr:   8.58%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:05<00:00, 11.89it/s]\n",
      "epoch-28  lr=['0.0055226'], tr/val_loss:  2.315332/  2.308450, tr:   8.68%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:06<00:00,  9.99it/s]\n",
      "epoch-29  lr=['0.0052617'], tr/val_loss:  2.315842/  2.306032, tr:   7.15%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:06<00:00,  9.11it/s]\n",
      "epoch-30  lr=['0.0050000'], tr/val_loss:  2.312570/  2.303939, tr:   8.89%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:05<00:00, 10.40it/s]\n",
      "epoch-31  lr=['0.0047383'], tr/val_loss:  2.309263/  2.303903, tr:   9.09%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:05<00:00, 11.06it/s]\n",
      "epoch-32  lr=['0.0044774'], tr/val_loss:  2.311847/  2.302894, tr:   8.38%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:05<00:00, 10.47it/s]\n",
      "epoch-33  lr=['0.0042178'], tr/val_loss:  2.308722/  2.303530, tr:   9.50%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:06<00:00, 10.32it/s]\n",
      "epoch-34  lr=['0.0039604'], tr/val_loss:  2.313000/  2.304187, tr:   8.48%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:05<00:00, 10.53it/s]\n",
      "epoch-35  lr=['0.0037059'], tr/val_loss:  2.309877/  2.303538, tr:   9.09%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:05<00:00, 10.97it/s]\n",
      "epoch-36  lr=['0.0034549'], tr/val_loss:  2.309406/  2.303601, tr:   8.99%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:07<00:00,  8.83it/s]\n",
      "epoch-37  lr=['0.0032082'], tr/val_loss:  2.309686/  2.303400, tr:   7.66%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:06<00:00,  9.89it/s]\n",
      "epoch-38  lr=['0.0029663'], tr/val_loss:  2.308588/  2.303166, tr:   9.09%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:06<00:00, 10.06it/s]\n",
      "epoch-39  lr=['0.0027300'], tr/val_loss:  2.308727/  2.302884, tr:   8.89%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:05<00:00, 10.54it/s]\n",
      "epoch-40  lr=['0.0025000'], tr/val_loss:  2.308749/  2.302732, tr:   9.40%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:05<00:00, 11.07it/s]\n",
      "epoch-41  lr=['0.0022768'], tr/val_loss:  2.306803/  2.302942, tr:   9.19%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:05<00:00, 10.64it/s]\n",
      "epoch-42  lr=['0.0020611'], tr/val_loss:  2.306347/  2.302762, tr:   8.68%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:05<00:00, 11.95it/s]\n",
      "epoch-43  lr=['0.0018534'], tr/val_loss:  2.305991/  2.302857, tr:   8.99%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:06<00:00, 10.28it/s]\n",
      "epoch-44  lr=['0.0016543'], tr/val_loss:  2.305293/  2.302853, tr:  10.01%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:05<00:00, 11.34it/s]\n",
      "epoch-45  lr=['0.0014645'], tr/val_loss:  2.306396/  2.302847, tr:   8.48%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:05<00:00, 10.81it/s]\n",
      "epoch-46  lr=['0.0012843'], tr/val_loss:  2.305307/  2.302670, tr:  10.01%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:06<00:00,  9.25it/s]\n",
      "epoch-47  lr=['0.0011143'], tr/val_loss:  2.305197/  2.302644, tr:   9.30%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:06<00:00, 10.31it/s]\n",
      "epoch-48  lr=['0.0009549'], tr/val_loss:  2.304637/  2.302745, tr:   8.78%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:05<00:00, 10.51it/s]\n",
      "epoch-49  lr=['0.0008066'], tr/val_loss:  2.304113/  2.302645, tr:   8.89%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:06<00:00, 10.15it/s]\n",
      "epoch-50  lr=['0.0006699'], tr/val_loss:  2.304358/  2.302700, tr:   8.68%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:05<00:00, 11.18it/s]\n",
      "epoch-51  lr=['0.0005450'], tr/val_loss:  2.303610/  2.302717, tr:   9.81%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:05<00:00, 10.93it/s]\n",
      "epoch-52  lr=['0.0004323'], tr/val_loss:  2.303667/  2.302626, tr:   9.30%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:05<00:00, 10.92it/s]\n",
      "epoch-53  lr=['0.0003321'], tr/val_loss:  2.303300/  2.302634, tr:   9.19%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:05<00:00, 10.91it/s]\n",
      "epoch-54  lr=['0.0002447'], tr/val_loss:  2.303030/  2.302622, tr:   8.38%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:06<00:00,  9.41it/s]\n",
      "epoch-55  lr=['0.0001704'], tr/val_loss:  2.303107/  2.302625, tr:  10.01%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:05<00:00, 10.65it/s]\n",
      "epoch-56  lr=['0.0001093'], tr/val_loss:  2.302886/  2.302609, tr:  10.01%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:05<00:00, 10.67it/s]\n",
      "epoch-57  lr=['0.0000616'], tr/val_loss:  2.302670/  2.302610, tr:  10.01%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:05<00:00, 11.35it/s]\n",
      "epoch-58  lr=['0.0000274'], tr/val_loss:  2.302685/  2.302609, tr:  10.01%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:06<00:00, 10.32it/s]\n",
      "epoch-59  lr=['0.0000069'], tr/val_loss:  2.302528/  2.302609, tr:  10.01%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:06<00:00,  9.75it/s]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cdad8c5b184e4432ad7e3995fff90396",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='3.438 MB of 3.438 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>DFA_flag</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>epoch</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇████</td></tr><tr><td>iter_acc</td><td>▁█▅▅▃▁▅█▆▃▆▅▃▃▁▃▃▃▁▁▁▁▆▅▁▃▁▅▃▅▃▅▃▃▅▅▁▃▅█</td></tr><tr><td>summary_val_acc</td><td>▁███████████████████████████████████████</td></tr><tr><td>tr_acc</td><td>▁███▇▇▇█▇███▇███▆▆▇▇▆▇▇▇▇▆▇▇▇▇██▇▇█▇▇███</td></tr><tr><td>tr_epoch_loss</td><td>▁███████████████████████████████████████</td></tr><tr><td>val_acc_best</td><td>▁███████████████████████████████████████</td></tr><tr><td>val_acc_now</td><td>▁███████████████████████████████████████</td></tr><tr><td>val_loss</td><td>▁███████████████████████████████████████</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>DFA_flag</td><td>0.0</td></tr><tr><td>epoch</td><td>59</td></tr><tr><td>iter_acc</td><td>0.33333</td></tr><tr><td>tr_acc</td><td>0.1001</td></tr><tr><td>tr_epoch_loss</td><td>2.30253</td></tr><tr><td>val_acc_best</td><td>0.1</td></tr><tr><td>val_acc_now</td><td>0.1</td></tr><tr><td>val_loss</td><td>2.30261</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">spring-sweep-46</strong> at: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/8mxonj4n' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/8mxonj4n</a><br/> View project at: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main</a><br/>Synced 7 W&B file(s), 0 media file(s), 0 artifact file(s) and 1 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20240822_191324-8mxonj4n/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require(\"core\")`! See https://wandb.me/wandb-core for more information."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: hx6mhv0x with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBATCH: 16\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tDFA_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tIMAGE_SIZE: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tOTTT_input_trace_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tOTTT_sWS_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tTIME: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcfg: ['M', 'M', 200, 200]\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tconst2: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdecay: 0.25\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdrop_rate: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdvs_clipping: 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdvs_duration: 100000\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \te_transport_swap: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \te_transport_swap_coin: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \te_transport_swap_tr: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepoch_num: 60\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \texclude_class: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.01\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_sg_width: 2.570969004857107\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_reset: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_threshold: 0.08358441988372034\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmerge_polarities: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tscheduler_name: CosineAnnealingLR\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsurrogate: hard_sigmoid\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \twhich_data: DVS_GESTURE_TONIC\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.17.7 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.17.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/nfs/home/bhkim003/github_folder/ByeonghyeonKim/my_snn/wandb/run-20240822_191946-hx6mhv0x</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/hx6mhv0x' target=\"_blank\">stilted-sweep-48</a></strong> to <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/yxynyr6h' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/yxynyr6h</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/yxynyr6h' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/yxynyr6h</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/hx6mhv0x' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/hx6mhv0x</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BATCH' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'IMAGE_SIZE' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'which_data' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_threshold' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_reset' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_sg_width' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'cfg' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'learning_rate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'epoch_num' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'surrogate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'scheduler_name' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'dvs_clipping' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'dvs_duration' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'OTTT_sWS_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'DFA_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'OTTT_input_trace_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'e_transport_swap' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'e_transport_swap_tr' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'e_transport_swap_coin' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'drop_rate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'exclude_class' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'merge_polarities' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'TIME' was locked by 'sweep' (ignored update).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset_hash = 2bbd58b4e0d3c1e9ad501fad8a43feed\n",
      "cache path exists\n",
      "\n",
      "we will exclude the 'other' class. dvsgestrue 10 classes' indices exist. \n",
      "\n",
      "DataParallel(\n",
      "  (module): MY_SNN_FC_sstep(\n",
      "    (layers): MY_Sequential(\n",
      "      (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (2): DimChanger_for_FC_sstep()\n",
      "      (3): SYNAPSE_FC_trace_sstep()\n",
      "      (4): LIF_layer_trace_sstep()\n",
      "      (5): SYNAPSE_FC_trace_sstep()\n",
      "      (6): LIF_layer_trace_sstep()\n",
      "      (7): SYNAPSE_FC_trace_sstep()\n",
      "    )\n",
      "  )\n",
      ")\n",
      "==================================================\n",
      "My Num of PARAMS: 452,010, system's param_num : 452,010\n",
      "Memory: 1.72MiB at 32-bit\n",
      "==================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch-0   lr=['0.0100000'], tr/val_loss:  1.617472/  1.369759, tr:  42.49%, val:  45.42%, val_best:  45.42%: 100%|██████████| 62/62 [00:06<00:00,  9.73it/s]\n",
      "epoch-1   lr=['0.0099931'], tr/val_loss:  1.118572/  1.337655, tr:  58.53%, val:  52.50%, val_best:  52.50%: 100%|██████████| 62/62 [00:06<00:00,  9.85it/s]\n",
      "epoch-2   lr=['0.0099726'], tr/val_loss:  0.954244/  1.243922, tr:  64.04%, val:  62.08%, val_best:  62.08%: 100%|██████████| 62/62 [00:05<00:00, 10.49it/s]\n",
      "epoch-3   lr=['0.0099384'], tr/val_loss:  0.843792/  1.122686, tr:  69.36%, val:  62.50%, val_best:  62.50%: 100%|██████████| 62/62 [00:07<00:00,  8.33it/s]\n",
      "epoch-4   lr=['0.0098907'], tr/val_loss:  0.789294/  1.135376, tr:  69.56%, val:  61.67%, val_best:  62.50%: 100%|██████████| 62/62 [00:05<00:00, 10.75it/s]\n",
      "epoch-5   lr=['0.0098296'], tr/val_loss:  0.757748/  1.349470, tr:  71.60%, val:  60.83%, val_best:  62.50%: 100%|██████████| 62/62 [00:06<00:00,  9.49it/s]\n",
      "epoch-6   lr=['0.0097553'], tr/val_loss:  0.677720/  1.239477, tr:  72.11%, val:  61.67%, val_best:  62.50%: 100%|██████████| 62/62 [00:05<00:00, 10.69it/s]\n",
      "epoch-7   lr=['0.0096679'], tr/val_loss:  0.678668/  1.399480, tr:  74.26%, val:  59.17%, val_best:  62.50%: 100%|██████████| 62/62 [00:06<00:00,  9.88it/s]\n",
      "epoch-8   lr=['0.0095677'], tr/val_loss:  0.698054/  1.226519, tr:  73.54%, val:  65.42%, val_best:  65.42%: 100%|██████████| 62/62 [00:06<00:00,  9.77it/s]\n",
      "epoch-9   lr=['0.0094550'], tr/val_loss:  0.522275/  1.255704, tr:  80.29%, val:  67.08%, val_best:  67.08%: 100%|██████████| 62/62 [00:05<00:00, 10.73it/s]\n",
      "epoch-10  lr=['0.0093301'], tr/val_loss:  0.524032/  1.178933, tr:  80.18%, val:  67.50%, val_best:  67.50%: 100%|██████████| 62/62 [00:06<00:00, 10.00it/s]\n",
      "epoch-11  lr=['0.0091934'], tr/val_loss:  0.475909/  1.395670, tr:  81.61%, val:  62.92%, val_best:  67.50%: 100%|██████████| 62/62 [00:06<00:00,  9.83it/s]\n",
      "epoch-12  lr=['0.0090451'], tr/val_loss:  0.464362/  1.288413, tr:  84.27%, val:  66.25%, val_best:  67.50%: 100%|██████████| 62/62 [00:05<00:00, 11.36it/s]\n",
      "epoch-13  lr=['0.0088857'], tr/val_loss:  0.413848/  1.303486, tr:  87.74%, val:  66.67%, val_best:  67.50%: 100%|██████████| 62/62 [00:05<00:00, 11.54it/s]\n",
      "epoch-14  lr=['0.0087157'], tr/val_loss:  0.386649/  1.230265, tr:  89.58%, val:  70.00%, val_best:  70.00%: 100%|██████████| 62/62 [00:05<00:00, 11.75it/s]\n",
      "epoch-15  lr=['0.0085355'], tr/val_loss:  0.346489/  1.376683, tr:  91.73%, val:  68.75%, val_best:  70.00%: 100%|██████████| 62/62 [00:05<00:00, 11.89it/s]\n",
      "epoch-16  lr=['0.0083457'], tr/val_loss:  0.290747/  1.470851, tr:  94.08%, val:  71.25%, val_best:  71.25%: 100%|██████████| 62/62 [00:05<00:00, 11.25it/s]\n",
      "epoch-17  lr=['0.0081466'], tr/val_loss:  0.280156/  1.401487, tr:  94.28%, val:  70.83%, val_best:  71.25%: 100%|██████████| 62/62 [00:06<00:00, 10.17it/s]\n",
      "epoch-18  lr=['0.0079389'], tr/val_loss:  0.234885/  1.307775, tr:  95.10%, val:  72.92%, val_best:  72.92%: 100%|██████████| 62/62 [00:06<00:00,  9.53it/s]\n",
      "epoch-19  lr=['0.0077232'], tr/val_loss:  0.154455/  1.359214, tr:  99.18%, val:  78.75%, val_best:  78.75%: 100%|██████████| 62/62 [00:05<00:00, 11.04it/s]\n",
      "epoch-20  lr=['0.0075000'], tr/val_loss:  0.145961/  1.381024, tr:  98.57%, val:  75.83%, val_best:  78.75%: 100%|██████████| 62/62 [00:05<00:00, 10.67it/s]\n",
      "epoch-21  lr=['0.0072700'], tr/val_loss:  0.083517/  1.458587, tr:  99.90%, val:  77.50%, val_best:  78.75%: 100%|██████████| 62/62 [00:06<00:00, 10.33it/s]\n",
      "epoch-22  lr=['0.0070337'], tr/val_loss:  0.073405/  1.477111, tr:  99.39%, val:  77.08%, val_best:  78.75%: 100%|██████████| 62/62 [00:06<00:00,  9.27it/s]\n",
      "epoch-23  lr=['0.0067918'], tr/val_loss:  0.056622/  1.498288, tr: 100.00%, val:  79.17%, val_best:  79.17%: 100%|██████████| 62/62 [00:06<00:00,  9.54it/s]\n",
      "epoch-24  lr=['0.0065451'], tr/val_loss:  0.033064/  1.569616, tr: 100.00%, val:  75.83%, val_best:  79.17%: 100%|██████████| 62/62 [00:06<00:00, 10.13it/s]\n",
      "epoch-25  lr=['0.0062941'], tr/val_loss:  0.038523/  1.654766, tr: 100.00%, val:  74.17%, val_best:  79.17%: 100%|██████████| 62/62 [00:05<00:00, 10.42it/s]\n",
      "epoch-26  lr=['0.0060396'], tr/val_loss:  0.018457/  1.540716, tr: 100.00%, val:  79.58%, val_best:  79.58%: 100%|██████████| 62/62 [00:05<00:00, 11.08it/s]\n",
      "epoch-27  lr=['0.0057822'], tr/val_loss:  0.011156/  1.592990, tr: 100.00%, val:  79.58%, val_best:  79.58%: 100%|██████████| 62/62 [00:06<00:00, 10.20it/s]\n",
      "epoch-28  lr=['0.0055226'], tr/val_loss:  0.007059/  1.619052, tr: 100.00%, val:  77.92%, val_best:  79.58%: 100%|██████████| 62/62 [00:05<00:00, 10.70it/s]\n",
      "epoch-29  lr=['0.0052617'], tr/val_loss:  0.005590/  1.625687, tr: 100.00%, val:  78.75%, val_best:  79.58%: 100%|██████████| 62/62 [00:06<00:00,  9.94it/s]\n",
      "epoch-30  lr=['0.0050000'], tr/val_loss:  0.003963/  1.654913, tr: 100.00%, val:  78.33%, val_best:  79.58%: 100%|██████████| 62/62 [00:05<00:00, 10.87it/s]\n",
      "epoch-31  lr=['0.0047383'], tr/val_loss:  0.003281/  1.654515, tr: 100.00%, val:  77.92%, val_best:  79.58%: 100%|██████████| 62/62 [00:09<00:00,  6.86it/s]\n",
      "epoch-32  lr=['0.0044774'], tr/val_loss:  0.002957/  1.656376, tr: 100.00%, val:  77.50%, val_best:  79.58%: 100%|██████████| 62/62 [00:08<00:00,  7.17it/s]\n",
      "epoch-33  lr=['0.0042178'], tr/val_loss:  0.002641/  1.667298, tr: 100.00%, val:  77.50%, val_best:  79.58%: 100%|██████████| 62/62 [00:07<00:00,  8.20it/s]\n",
      "epoch-34  lr=['0.0039604'], tr/val_loss:  0.002446/  1.678163, tr: 100.00%, val:  77.08%, val_best:  79.58%: 100%|██████████| 62/62 [00:08<00:00,  7.62it/s]\n",
      "epoch-35  lr=['0.0037059'], tr/val_loss:  0.002259/  1.688986, tr: 100.00%, val:  77.92%, val_best:  79.58%: 100%|██████████| 62/62 [00:07<00:00,  8.27it/s]\n",
      "epoch-36  lr=['0.0034549'], tr/val_loss:  0.002067/  1.694506, tr: 100.00%, val:  78.75%, val_best:  79.58%: 100%|██████████| 62/62 [00:07<00:00,  7.87it/s]\n",
      "epoch-37  lr=['0.0032082'], tr/val_loss:  0.001964/  1.701966, tr: 100.00%, val:  78.75%, val_best:  79.58%: 100%|██████████| 62/62 [00:07<00:00,  7.85it/s]\n",
      "epoch-38  lr=['0.0029663'], tr/val_loss:  0.001864/  1.701641, tr: 100.00%, val:  78.75%, val_best:  79.58%: 100%|██████████| 62/62 [00:05<00:00, 10.51it/s]\n",
      "epoch-39  lr=['0.0027300'], tr/val_loss:  0.001815/  1.706932, tr: 100.00%, val:  78.33%, val_best:  79.58%: 100%|██████████| 62/62 [00:05<00:00, 10.55it/s]\n",
      "epoch-40  lr=['0.0025000'], tr/val_loss:  0.001729/  1.716050, tr: 100.00%, val:  79.17%, val_best:  79.58%: 100%|██████████| 62/62 [00:05<00:00, 10.99it/s]\n",
      "epoch-41  lr=['0.0022768'], tr/val_loss:  0.001683/  1.721823, tr: 100.00%, val:  79.58%, val_best:  79.58%: 100%|██████████| 62/62 [00:05<00:00, 10.78it/s]\n",
      "epoch-42  lr=['0.0020611'], tr/val_loss:  0.001690/  1.736283, tr: 100.00%, val:  78.75%, val_best:  79.58%: 100%|██████████| 62/62 [00:05<00:00, 10.53it/s]\n",
      "epoch-43  lr=['0.0018534'], tr/val_loss:  0.001678/  1.749447, tr: 100.00%, val:  79.17%, val_best:  79.58%: 100%|██████████| 62/62 [00:05<00:00, 10.35it/s]\n",
      "epoch-44  lr=['0.0016543'], tr/val_loss:  0.001576/  1.749996, tr: 100.00%, val:  78.75%, val_best:  79.58%: 100%|██████████| 62/62 [00:05<00:00, 10.74it/s]\n",
      "epoch-45  lr=['0.0014645'], tr/val_loss:  0.001542/  1.745605, tr: 100.00%, val:  78.75%, val_best:  79.58%: 100%|██████████| 62/62 [00:05<00:00, 10.37it/s]\n",
      "epoch-46  lr=['0.0012843'], tr/val_loss:  0.001570/  1.747655, tr: 100.00%, val:  78.33%, val_best:  79.58%: 100%|██████████| 62/62 [00:05<00:00, 10.49it/s]\n",
      "epoch-47  lr=['0.0011143'], tr/val_loss:  0.001537/  1.745073, tr: 100.00%, val:  78.33%, val_best:  79.58%: 100%|██████████| 62/62 [00:05<00:00, 10.90it/s]\n",
      "epoch-48  lr=['0.0009549'], tr/val_loss:  0.001509/  1.750474, tr: 100.00%, val:  77.92%, val_best:  79.58%: 100%|██████████| 62/62 [00:06<00:00, 10.31it/s]\n",
      "epoch-49  lr=['0.0008066'], tr/val_loss:  0.001433/  1.752467, tr: 100.00%, val:  78.33%, val_best:  79.58%: 100%|██████████| 62/62 [00:05<00:00, 10.40it/s]\n",
      "epoch-50  lr=['0.0006699'], tr/val_loss:  0.001460/  1.755690, tr: 100.00%, val:  78.33%, val_best:  79.58%: 100%|██████████| 62/62 [00:05<00:00, 10.98it/s]\n",
      "epoch-51  lr=['0.0005450'], tr/val_loss:  0.001446/  1.752141, tr: 100.00%, val:  77.92%, val_best:  79.58%: 100%|██████████| 62/62 [00:06<00:00, 10.15it/s]\n",
      "epoch-52  lr=['0.0004323'], tr/val_loss:  0.001456/  1.752891, tr: 100.00%, val:  77.92%, val_best:  79.58%: 100%|██████████| 62/62 [00:06<00:00, 10.15it/s]\n",
      "epoch-53  lr=['0.0003321'], tr/val_loss:  0.001427/  1.751972, tr: 100.00%, val:  78.75%, val_best:  79.58%: 100%|██████████| 62/62 [00:06<00:00,  9.97it/s]\n",
      "epoch-54  lr=['0.0002447'], tr/val_loss:  0.001465/  1.751848, tr: 100.00%, val:  78.75%, val_best:  79.58%: 100%|██████████| 62/62 [00:06<00:00,  9.38it/s]\n",
      "epoch-55  lr=['0.0001704'], tr/val_loss:  0.001431/  1.751808, tr: 100.00%, val:  78.75%, val_best:  79.58%: 100%|██████████| 62/62 [00:05<00:00, 10.51it/s]\n",
      "epoch-56  lr=['0.0001093'], tr/val_loss:  0.001443/  1.753217, tr: 100.00%, val:  78.33%, val_best:  79.58%: 100%|██████████| 62/62 [00:06<00:00, 10.20it/s]\n",
      "epoch-57  lr=['0.0000616'], tr/val_loss:  0.001429/  1.752327, tr: 100.00%, val:  78.33%, val_best:  79.58%: 100%|██████████| 62/62 [00:06<00:00, 10.23it/s]\n",
      "epoch-58  lr=['0.0000274'], tr/val_loss:  0.001417/  1.752521, tr: 100.00%, val:  78.33%, val_best:  79.58%: 100%|██████████| 62/62 [00:06<00:00,  9.68it/s]\n",
      "epoch-59  lr=['0.0000069'], tr/val_loss:  0.001418/  1.752527, tr: 100.00%, val:  78.33%, val_best:  79.58%: 100%|██████████| 62/62 [00:06<00:00,  9.57it/s]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d192b2c8372b4f669ec6c0139cc5fa6a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='3.438 MB of 3.438 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>DFA_flag</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>epoch</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇████</td></tr><tr><td>iter_acc</td><td>▁▁▃▅▅▄▅▄▅▅▇▇████████████████████████████</td></tr><tr><td>summary_val_acc</td><td>▁▅▆▆▆▆▇▇▇▇▇▇▇███████████████████████████</td></tr><tr><td>tr_acc</td><td>▁▄▅▆▆▆▆▇▇▇▇█████████████████████████████</td></tr><tr><td>tr_epoch_loss</td><td>▁█▅▅▄▄▄▃▃▃▃▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_acc_best</td><td>▁▅▆▆▆▆▇▇▇▇▇▇▇███████████████████████████</td></tr><tr><td>val_acc_now</td><td>▁▅▆▆▆▆▇▇▇▇▇▇▇███████████████████████████</td></tr><tr><td>val_loss</td><td>▁▆▆▅▆▆▆▆▇▆▆▇▇▆▇▇▇█▇▇▇███████████████████</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>DFA_flag</td><td>0.0</td></tr><tr><td>epoch</td><td>59</td></tr><tr><td>iter_acc</td><td>1.0</td></tr><tr><td>tr_acc</td><td>1.0</td></tr><tr><td>tr_epoch_loss</td><td>0.00142</td></tr><tr><td>val_acc_best</td><td>0.79583</td></tr><tr><td>val_acc_now</td><td>0.78333</td></tr><tr><td>val_loss</td><td>1.75253</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">stilted-sweep-48</strong> at: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/hx6mhv0x' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/hx6mhv0x</a><br/> View project at: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main</a><br/>Synced 7 W&B file(s), 0 media file(s), 0 artifact file(s) and 1 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20240822_191946-hx6mhv0x/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require(\"core\")`! See https://wandb.me/wandb-core for more information."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 2ysfxfku with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBATCH: 16\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tDFA_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tIMAGE_SIZE: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tOTTT_input_trace_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tOTTT_sWS_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tTIME: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcfg: ['M', 'M', 200, 200]\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tconst2: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdecay: 0.25\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdrop_rate: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdvs_clipping: 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdvs_duration: 100000\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \te_transport_swap: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \te_transport_swap_coin: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \te_transport_swap_tr: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepoch_num: 60\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \texclude_class: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.01\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_sg_width: 2.570969004857107\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_reset: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_threshold: 1.8532594761092236\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmerge_polarities: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tscheduler_name: CosineAnnealingLR\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsurrogate: hard_sigmoid\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \twhich_data: DVS_GESTURE_TONIC\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.17.7 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.17.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/nfs/home/bhkim003/github_folder/ByeonghyeonKim/my_snn/wandb/run-20240822_192635-2ysfxfku</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/2ysfxfku' target=\"_blank\">efficient-sweep-50</a></strong> to <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/yxynyr6h' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/yxynyr6h</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/yxynyr6h' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/yxynyr6h</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/2ysfxfku' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/2ysfxfku</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BATCH' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'IMAGE_SIZE' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'which_data' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_threshold' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_reset' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_sg_width' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'cfg' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'learning_rate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'epoch_num' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'surrogate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'scheduler_name' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'dvs_clipping' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'dvs_duration' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'OTTT_sWS_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'DFA_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'OTTT_input_trace_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'e_transport_swap' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'e_transport_swap_tr' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'e_transport_swap_coin' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'drop_rate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'exclude_class' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'merge_polarities' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'TIME' was locked by 'sweep' (ignored update).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset_hash = 2bbd58b4e0d3c1e9ad501fad8a43feed\n",
      "cache path exists\n",
      "\n",
      "we will exclude the 'other' class. dvsgestrue 10 classes' indices exist. \n",
      "\n",
      "DataParallel(\n",
      "  (module): MY_SNN_FC_sstep(\n",
      "    (layers): MY_Sequential(\n",
      "      (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (2): DimChanger_for_FC_sstep()\n",
      "      (3): SYNAPSE_FC_trace_sstep()\n",
      "      (4): LIF_layer_trace_sstep()\n",
      "      (5): SYNAPSE_FC_trace_sstep()\n",
      "      (6): LIF_layer_trace_sstep()\n",
      "      (7): SYNAPSE_FC_trace_sstep()\n",
      "    )\n",
      "  )\n",
      ")\n",
      "==================================================\n",
      "My Num of PARAMS: 452,010, system's param_num : 452,010\n",
      "Memory: 1.72MiB at 32-bit\n",
      "==================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch-0   lr=['0.0100000'], tr/val_loss:  2.317507/  2.316367, tr:   9.70%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:06<00:00,  9.66it/s]\n",
      "epoch-1   lr=['0.0099931'], tr/val_loss:  2.316254/  2.314931, tr:  10.21%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:05<00:00, 10.61it/s]\n",
      "epoch-2   lr=['0.0099726'], tr/val_loss:  2.315321/  2.315877, tr:   9.81%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:05<00:00, 10.58it/s]\n",
      "epoch-3   lr=['0.0099384'], tr/val_loss:  2.319123/  2.321801, tr:  10.42%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:05<00:00, 10.41it/s]\n",
      "epoch-4   lr=['0.0098907'], tr/val_loss:  2.328817/  2.310750, tr:   7.66%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:05<00:00, 10.56it/s]\n",
      "epoch-5   lr=['0.0098296'], tr/val_loss:  2.318780/  2.313111, tr:   8.58%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:05<00:00, 10.91it/s]\n",
      "epoch-6   lr=['0.0097553'], tr/val_loss:  2.326567/  2.312034, tr:   8.89%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:05<00:00, 10.62it/s]\n",
      "epoch-7   lr=['0.0096679'], tr/val_loss:  2.319906/  2.308871, tr:   8.89%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:05<00:00, 10.53it/s]\n",
      "epoch-8   lr=['0.0095677'], tr/val_loss:  2.315703/  2.318316, tr:   9.09%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:05<00:00, 10.56it/s]\n",
      "epoch-9   lr=['0.0094550'], tr/val_loss:  2.315776/  2.321137, tr:   9.81%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:05<00:00, 10.58it/s]\n",
      "epoch-10  lr=['0.0093301'], tr/val_loss:  2.319218/  2.310921, tr:   9.40%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:05<00:00, 11.08it/s]\n",
      "epoch-11  lr=['0.0091934'], tr/val_loss:  2.320658/  2.318817, tr:   9.60%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:05<00:00, 11.76it/s]\n",
      "epoch-12  lr=['0.0090451'], tr/val_loss:  2.323760/  2.306959, tr:   9.70%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:05<00:00, 12.18it/s]\n",
      "epoch-13  lr=['0.0088857'], tr/val_loss:  2.312257/  2.313825, tr:   8.78%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:05<00:00, 12.17it/s]\n",
      "epoch-14  lr=['0.0087157'], tr/val_loss:  2.321870/  2.310401, tr:   9.70%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:04<00:00, 12.62it/s]\n",
      "epoch-15  lr=['0.0085355'], tr/val_loss:  2.318407/  2.313874, tr:   9.60%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:05<00:00, 12.08it/s]\n",
      "epoch-16  lr=['0.0083457'], tr/val_loss:  2.317499/  2.312321, tr:  10.11%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:04<00:00, 13.04it/s]\n",
      "epoch-17  lr=['0.0081466'], tr/val_loss:  2.318669/  2.307941, tr:   8.89%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:04<00:00, 12.62it/s]\n",
      "epoch-18  lr=['0.0079389'], tr/val_loss:  2.325135/  2.306585, tr:   7.46%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:05<00:00, 12.16it/s]\n",
      "epoch-19  lr=['0.0077232'], tr/val_loss:  2.314244/  2.310251, tr:  10.01%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:05<00:00, 11.69it/s]\n",
      "epoch-20  lr=['0.0075000'], tr/val_loss:  2.312182/  2.307967, tr:   9.91%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:05<00:00, 12.31it/s]\n",
      "epoch-21  lr=['0.0072700'], tr/val_loss:  2.318818/  2.307295, tr:   9.30%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:04<00:00, 12.52it/s]\n",
      "epoch-22  lr=['0.0070337'], tr/val_loss:  2.313441/  2.307399, tr:   9.91%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:04<00:00, 12.52it/s]\n",
      "epoch-23  lr=['0.0067918'], tr/val_loss:  2.314248/  2.309416, tr:   7.76%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:05<00:00, 12.10it/s]\n",
      "epoch-24  lr=['0.0065451'], tr/val_loss:  2.318841/  2.305136, tr:   9.09%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:05<00:00, 12.18it/s]\n",
      "epoch-25  lr=['0.0062941'], tr/val_loss:  2.316903/  2.306750, tr:   7.97%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:05<00:00, 11.97it/s]\n",
      "epoch-26  lr=['0.0060396'], tr/val_loss:  2.311055/  2.305107, tr:   8.99%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:05<00:00, 12.34it/s]\n",
      "epoch-27  lr=['0.0057822'], tr/val_loss:  2.313828/  2.306802, tr:   8.58%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:05<00:00, 11.85it/s]\n",
      "epoch-28  lr=['0.0055226'], tr/val_loss:  2.315332/  2.308450, tr:   8.68%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:05<00:00, 12.04it/s]\n",
      "epoch-29  lr=['0.0052617'], tr/val_loss:  2.315842/  2.306032, tr:   7.15%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:05<00:00, 12.31it/s]\n",
      "epoch-30  lr=['0.0050000'], tr/val_loss:  2.312570/  2.303939, tr:   8.89%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:04<00:00, 12.42it/s]\n",
      "epoch-31  lr=['0.0047383'], tr/val_loss:  2.309263/  2.303903, tr:   9.09%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:05<00:00, 12.01it/s]\n",
      "epoch-32  lr=['0.0044774'], tr/val_loss:  2.311847/  2.302894, tr:   8.38%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:05<00:00, 11.88it/s]\n",
      "epoch-33  lr=['0.0042178'], tr/val_loss:  2.308722/  2.303530, tr:   9.50%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:05<00:00, 11.92it/s]\n",
      "epoch-34  lr=['0.0039604'], tr/val_loss:  2.313000/  2.304187, tr:   8.48%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:05<00:00, 11.94it/s]\n",
      "epoch-35  lr=['0.0037059'], tr/val_loss:  2.309877/  2.303538, tr:   9.09%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:04<00:00, 12.72it/s]\n",
      "epoch-36  lr=['0.0034549'], tr/val_loss:  2.309406/  2.303601, tr:   8.99%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:04<00:00, 12.58it/s]\n",
      "epoch-37  lr=['0.0032082'], tr/val_loss:  2.309686/  2.303400, tr:   7.66%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:05<00:00, 11.75it/s]\n",
      "epoch-38  lr=['0.0029663'], tr/val_loss:  2.308588/  2.303166, tr:   9.09%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:05<00:00, 11.72it/s]\n",
      "epoch-39  lr=['0.0027300'], tr/val_loss:  2.308727/  2.302884, tr:   8.89%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:05<00:00, 12.30it/s]\n",
      "epoch-40  lr=['0.0025000'], tr/val_loss:  2.308749/  2.302732, tr:   9.40%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:05<00:00, 12.19it/s]\n",
      "epoch-41  lr=['0.0022768'], tr/val_loss:  2.306803/  2.302942, tr:   9.19%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:05<00:00, 12.18it/s]\n",
      "epoch-42  lr=['0.0020611'], tr/val_loss:  2.306347/  2.302762, tr:   8.68%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:04<00:00, 12.41it/s]\n",
      "epoch-43  lr=['0.0018534'], tr/val_loss:  2.305991/  2.302857, tr:   8.99%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:05<00:00, 12.15it/s]\n",
      "epoch-44  lr=['0.0016543'], tr/val_loss:  2.305293/  2.302853, tr:  10.01%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:05<00:00, 12.30it/s]\n",
      "epoch-45  lr=['0.0014645'], tr/val_loss:  2.306396/  2.302847, tr:   8.48%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:05<00:00, 12.03it/s]\n",
      "epoch-46  lr=['0.0012843'], tr/val_loss:  2.305307/  2.302670, tr:  10.01%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:05<00:00, 11.61it/s]\n",
      "epoch-47  lr=['0.0011143'], tr/val_loss:  2.305197/  2.302644, tr:   9.30%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:05<00:00, 11.55it/s]\n",
      "epoch-48  lr=['0.0009549'], tr/val_loss:  2.304637/  2.302745, tr:   8.78%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:05<00:00, 12.20it/s]\n",
      "epoch-49  lr=['0.0008066'], tr/val_loss:  2.304113/  2.302645, tr:   8.89%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:05<00:00, 11.96it/s]\n",
      "epoch-50  lr=['0.0006699'], tr/val_loss:  2.304358/  2.302700, tr:   8.68%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:05<00:00, 12.01it/s]\n",
      "epoch-51  lr=['0.0005450'], tr/val_loss:  2.303610/  2.302717, tr:   9.81%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:05<00:00, 12.07it/s]\n",
      "epoch-52  lr=['0.0004323'], tr/val_loss:  2.303667/  2.302626, tr:   9.30%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:05<00:00, 12.14it/s]\n",
      "epoch-53  lr=['0.0003321'], tr/val_loss:  2.303300/  2.302634, tr:   9.19%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:05<00:00, 12.40it/s]\n",
      "epoch-54  lr=['0.0002447'], tr/val_loss:  2.303030/  2.302622, tr:   8.38%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:05<00:00, 11.96it/s]\n",
      "epoch-55  lr=['0.0001704'], tr/val_loss:  2.303107/  2.302625, tr:  10.01%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:05<00:00, 11.83it/s]\n",
      "epoch-56  lr=['0.0001093'], tr/val_loss:  2.302886/  2.302609, tr:  10.01%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:05<00:00, 11.69it/s]\n",
      "epoch-57  lr=['0.0000616'], tr/val_loss:  2.302670/  2.302610, tr:  10.01%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:05<00:00, 11.98it/s]\n",
      "epoch-58  lr=['0.0000274'], tr/val_loss:  2.302685/  2.302609, tr:  10.01%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:05<00:00, 11.80it/s]\n",
      "epoch-59  lr=['0.0000069'], tr/val_loss:  2.302528/  2.302609, tr:  10.01%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:05<00:00, 12.25it/s]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c65e627ce8c644888ae7940ab62a5a1c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='3.438 MB of 3.438 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>DFA_flag</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>epoch</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇████</td></tr><tr><td>iter_acc</td><td>▁█▅▅▃▁▅█▆▃▆▅▃▃▁▃▃▃▁▁▁▁▆▅▁▃▁▅▃▅▃▅▃▃▅▅▁▃▅█</td></tr><tr><td>summary_val_acc</td><td>▁███████████████████████████████████████</td></tr><tr><td>tr_acc</td><td>▁███▇▇▇█▇███▇███▆▆▇▇▆▇▇▇▇▆▇▇▇▇██▇▇█▇▇███</td></tr><tr><td>tr_epoch_loss</td><td>▁███████████████████████████████████████</td></tr><tr><td>val_acc_best</td><td>▁███████████████████████████████████████</td></tr><tr><td>val_acc_now</td><td>▁███████████████████████████████████████</td></tr><tr><td>val_loss</td><td>▁███████████████████████████████████████</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>DFA_flag</td><td>0.0</td></tr><tr><td>epoch</td><td>59</td></tr><tr><td>iter_acc</td><td>0.33333</td></tr><tr><td>tr_acc</td><td>0.1001</td></tr><tr><td>tr_epoch_loss</td><td>2.30253</td></tr><tr><td>val_acc_best</td><td>0.1</td></tr><tr><td>val_acc_now</td><td>0.1</td></tr><tr><td>val_loss</td><td>2.30261</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">efficient-sweep-50</strong> at: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/2ysfxfku' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/2ysfxfku</a><br/> View project at: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main</a><br/>Synced 7 W&B file(s), 0 media file(s), 0 artifact file(s) and 1 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20240822_192635-2ysfxfku/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require(\"core\")`! See https://wandb.me/wandb-core for more information."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: xlk967am with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBATCH: 16\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tDFA_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tIMAGE_SIZE: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tOTTT_input_trace_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tOTTT_sWS_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tTIME: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcfg: ['M', 'M', 200, 200]\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tconst2: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdecay: 0.25\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdrop_rate: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdvs_clipping: 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdvs_duration: 100000\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \te_transport_swap: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \te_transport_swap_coin: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \te_transport_swap_tr: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepoch_num: 60\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \texclude_class: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.01\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_sg_width: 2.570969004857107\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_reset: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_threshold: 1.7179014501907588\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmerge_polarities: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tscheduler_name: CosineAnnealingLR\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsurrogate: hard_sigmoid\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \twhich_data: DVS_GESTURE_TONIC\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.17.7 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.17.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/nfs/home/bhkim003/github_folder/ByeonghyeonKim/my_snn/wandb/run-20240822_193227-xlk967am</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/xlk967am' target=\"_blank\">smart-sweep-52</a></strong> to <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/yxynyr6h' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/yxynyr6h</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/yxynyr6h' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/yxynyr6h</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/xlk967am' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/xlk967am</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BATCH' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'IMAGE_SIZE' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'which_data' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_threshold' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_reset' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_sg_width' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'cfg' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'learning_rate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'epoch_num' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'surrogate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'scheduler_name' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'dvs_clipping' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'dvs_duration' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'OTTT_sWS_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'DFA_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'OTTT_input_trace_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'e_transport_swap' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'e_transport_swap_tr' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'e_transport_swap_coin' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'drop_rate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'exclude_class' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'merge_polarities' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'TIME' was locked by 'sweep' (ignored update).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset_hash = 2bbd58b4e0d3c1e9ad501fad8a43feed\n",
      "cache path exists\n",
      "\n",
      "we will exclude the 'other' class. dvsgestrue 10 classes' indices exist. \n",
      "\n",
      "DataParallel(\n",
      "  (module): MY_SNN_FC_sstep(\n",
      "    (layers): MY_Sequential(\n",
      "      (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (2): DimChanger_for_FC_sstep()\n",
      "      (3): SYNAPSE_FC_trace_sstep()\n",
      "      (4): LIF_layer_trace_sstep()\n",
      "      (5): SYNAPSE_FC_trace_sstep()\n",
      "      (6): LIF_layer_trace_sstep()\n",
      "      (7): SYNAPSE_FC_trace_sstep()\n",
      "    )\n",
      "  )\n",
      ")\n",
      "==================================================\n",
      "My Num of PARAMS: 452,010, system's param_num : 452,010\n",
      "Memory: 1.72MiB at 32-bit\n",
      "==================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch-0   lr=['0.0100000'], tr/val_loss:  2.317507/  2.316367, tr:   9.70%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:05<00:00, 12.01it/s]\n",
      "epoch-1   lr=['0.0099931'], tr/val_loss:  2.316254/  2.314931, tr:  10.21%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:05<00:00, 11.74it/s]\n",
      "epoch-2   lr=['0.0099726'], tr/val_loss:  2.315321/  2.315877, tr:   9.81%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:04<00:00, 12.46it/s]\n",
      "epoch-3   lr=['0.0099384'], tr/val_loss:  2.319123/  2.321801, tr:  10.42%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:05<00:00, 11.42it/s]\n",
      "epoch-4   lr=['0.0098907'], tr/val_loss:  2.328817/  2.310750, tr:   7.66%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:05<00:00, 11.80it/s]\n",
      "epoch-5   lr=['0.0098296'], tr/val_loss:  2.318780/  2.313111, tr:   8.58%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:05<00:00, 12.06it/s]\n",
      "epoch-6   lr=['0.0097553'], tr/val_loss:  2.326567/  2.312034, tr:   8.89%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:04<00:00, 12.54it/s]\n",
      "epoch-7   lr=['0.0096679'], tr/val_loss:  2.319906/  2.308871, tr:   8.89%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:05<00:00, 11.90it/s]\n",
      "epoch-8   lr=['0.0095677'], tr/val_loss:  2.315703/  2.318316, tr:   9.09%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:05<00:00, 12.01it/s]\n",
      "epoch-9   lr=['0.0094550'], tr/val_loss:  2.315776/  2.321137, tr:   9.81%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:05<00:00, 12.32it/s]\n",
      "epoch-10  lr=['0.0093301'], tr/val_loss:  2.319218/  2.310921, tr:   9.40%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:05<00:00, 12.16it/s]\n",
      "epoch-11  lr=['0.0091934'], tr/val_loss:  2.320658/  2.318817, tr:   9.60%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:05<00:00, 12.11it/s]\n",
      "epoch-12  lr=['0.0090451'], tr/val_loss:  2.323760/  2.306959, tr:   9.70%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:05<00:00, 12.38it/s]\n",
      "epoch-13  lr=['0.0088857'], tr/val_loss:  2.312257/  2.313825, tr:   8.78%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:04<00:00, 12.55it/s]\n",
      "epoch-14  lr=['0.0087157'], tr/val_loss:  2.321870/  2.310401, tr:   9.70%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:04<00:00, 12.49it/s]\n",
      "epoch-15  lr=['0.0085355'], tr/val_loss:  2.318407/  2.313874, tr:   9.60%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:04<00:00, 12.55it/s]\n",
      "epoch-16  lr=['0.0083457'], tr/val_loss:  2.317499/  2.312321, tr:  10.11%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:04<00:00, 12.67it/s]\n",
      "epoch-17  lr=['0.0081466'], tr/val_loss:  2.318669/  2.307941, tr:   8.89%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:04<00:00, 12.47it/s]\n",
      "epoch-18  lr=['0.0079389'], tr/val_loss:  2.325135/  2.306585, tr:   7.46%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:05<00:00, 11.72it/s]\n",
      "epoch-19  lr=['0.0077232'], tr/val_loss:  2.314244/  2.310251, tr:  10.01%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:05<00:00, 12.19it/s]\n",
      "epoch-20  lr=['0.0075000'], tr/val_loss:  2.312182/  2.307967, tr:   9.91%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:05<00:00, 11.98it/s]\n",
      "epoch-21  lr=['0.0072700'], tr/val_loss:  2.318818/  2.307295, tr:   9.30%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:05<00:00, 12.12it/s]\n",
      "epoch-22  lr=['0.0070337'], tr/val_loss:  2.313441/  2.307399, tr:   9.91%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:05<00:00, 12.05it/s]\n",
      "epoch-23  lr=['0.0067918'], tr/val_loss:  2.314248/  2.309416, tr:   7.76%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:05<00:00, 12.38it/s]\n",
      "epoch-24  lr=['0.0065451'], tr/val_loss:  2.318841/  2.305136, tr:   9.09%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:05<00:00, 12.21it/s]\n",
      "epoch-25  lr=['0.0062941'], tr/val_loss:  2.316903/  2.306750, tr:   7.97%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:05<00:00, 11.72it/s]\n",
      "epoch-26  lr=['0.0060396'], tr/val_loss:  2.311055/  2.305107, tr:   8.99%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:05<00:00, 11.77it/s]\n",
      "epoch-27  lr=['0.0057822'], tr/val_loss:  2.313828/  2.306802, tr:   8.58%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:05<00:00, 12.36it/s]\n",
      "epoch-28  lr=['0.0055226'], tr/val_loss:  2.315332/  2.308450, tr:   8.68%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:05<00:00, 11.83it/s]\n",
      "epoch-29  lr=['0.0052617'], tr/val_loss:  2.315842/  2.306032, tr:   7.15%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:05<00:00, 12.31it/s]\n",
      "epoch-30  lr=['0.0050000'], tr/val_loss:  2.312570/  2.303939, tr:   8.89%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:05<00:00, 11.48it/s]\n",
      "epoch-31  lr=['0.0047383'], tr/val_loss:  2.309263/  2.303903, tr:   9.09%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:05<00:00, 11.81it/s]\n",
      "epoch-32  lr=['0.0044774'], tr/val_loss:  2.311847/  2.302894, tr:   8.38%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:05<00:00, 12.07it/s]\n",
      "epoch-33  lr=['0.0042178'], tr/val_loss:  2.308722/  2.303530, tr:   9.50%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:05<00:00, 12.10it/s]\n",
      "epoch-34  lr=['0.0039604'], tr/val_loss:  2.313000/  2.304187, tr:   8.48%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:05<00:00, 11.86it/s]\n",
      "epoch-35  lr=['0.0037059'], tr/val_loss:  2.309877/  2.303538, tr:   9.09%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:05<00:00, 12.05it/s]\n",
      "epoch-36  lr=['0.0034549'], tr/val_loss:  2.309406/  2.303601, tr:   8.99%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:05<00:00, 11.74it/s]\n",
      "epoch-37  lr=['0.0032082'], tr/val_loss:  2.309686/  2.303400, tr:   7.66%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:05<00:00, 11.78it/s]\n",
      "epoch-38  lr=['0.0029663'], tr/val_loss:  2.308588/  2.303166, tr:   9.09%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:05<00:00, 11.71it/s]\n",
      "epoch-39  lr=['0.0027300'], tr/val_loss:  2.308727/  2.302884, tr:   8.89%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:05<00:00, 11.78it/s]\n",
      "epoch-40  lr=['0.0025000'], tr/val_loss:  2.308749/  2.302732, tr:   9.40%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:05<00:00, 12.11it/s]\n",
      "epoch-41  lr=['0.0022768'], tr/val_loss:  2.306803/  2.302942, tr:   9.19%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:05<00:00, 11.79it/s]\n",
      "epoch-42  lr=['0.0020611'], tr/val_loss:  2.306347/  2.302762, tr:   8.68%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:05<00:00, 11.91it/s]\n",
      "epoch-43  lr=['0.0018534'], tr/val_loss:  2.305991/  2.302857, tr:   8.99%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:05<00:00, 12.34it/s]\n",
      "epoch-44  lr=['0.0016543'], tr/val_loss:  2.305293/  2.302853, tr:  10.01%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:05<00:00, 12.09it/s]\n",
      "epoch-45  lr=['0.0014645'], tr/val_loss:  2.306396/  2.302847, tr:   8.48%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:04<00:00, 12.41it/s]\n",
      "epoch-46  lr=['0.0012843'], tr/val_loss:  2.305307/  2.302670, tr:  10.01%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:05<00:00, 12.28it/s]\n",
      "epoch-47  lr=['0.0011143'], tr/val_loss:  2.305197/  2.302644, tr:   9.30%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:05<00:00, 11.98it/s]\n",
      "epoch-48  lr=['0.0009549'], tr/val_loss:  2.304637/  2.302745, tr:   8.78%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:05<00:00, 12.04it/s]\n",
      "epoch-49  lr=['0.0008066'], tr/val_loss:  2.304113/  2.302645, tr:   8.89%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:04<00:00, 12.46it/s]\n",
      "epoch-50  lr=['0.0006699'], tr/val_loss:  2.304358/  2.302700, tr:   8.68%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:04<00:00, 12.95it/s]\n",
      "epoch-51  lr=['0.0005450'], tr/val_loss:  2.303610/  2.302717, tr:   9.81%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:05<00:00, 12.00it/s]\n",
      "epoch-52  lr=['0.0004323'], tr/val_loss:  2.303667/  2.302626, tr:   9.30%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:05<00:00, 11.18it/s]\n",
      "epoch-53  lr=['0.0003321'], tr/val_loss:  2.303300/  2.302634, tr:   9.19%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:05<00:00, 10.88it/s]\n",
      "epoch-54  lr=['0.0002447'], tr/val_loss:  2.303030/  2.302622, tr:   8.38%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:05<00:00, 12.21it/s]\n",
      "epoch-55  lr=['0.0001704'], tr/val_loss:  2.303107/  2.302625, tr:  10.01%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:05<00:00, 12.09it/s]\n",
      "epoch-56  lr=['0.0001093'], tr/val_loss:  2.302886/  2.302609, tr:  10.01%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:04<00:00, 12.82it/s]\n",
      "epoch-57  lr=['0.0000616'], tr/val_loss:  2.302670/  2.302610, tr:  10.01%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:06<00:00,  9.85it/s]\n",
      "epoch-58  lr=['0.0000274'], tr/val_loss:  2.302685/  2.302609, tr:  10.01%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:05<00:00, 12.02it/s]\n",
      "epoch-59  lr=['0.0000069'], tr/val_loss:  2.302528/  2.302609, tr:  10.01%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:04<00:00, 12.40it/s]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5e3f35b4b12a437390ba49d660607a8e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='3.439 MB of 3.439 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>DFA_flag</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>epoch</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇████</td></tr><tr><td>iter_acc</td><td>▁█▅▅▃▁▅█▆▃▆▅▃▃▁▃▃▃▁▁▁▁▆▅▁▃▁▅▃▅▃▅▃▃▅▅▁▃▅█</td></tr><tr><td>summary_val_acc</td><td>▁███████████████████████████████████████</td></tr><tr><td>tr_acc</td><td>▁███▇▇▇█▇███▇███▆▆▇▇▆▇▇▇▇▆▇▇▇▇██▇▇█▇▇███</td></tr><tr><td>tr_epoch_loss</td><td>▁███████████████████████████████████████</td></tr><tr><td>val_acc_best</td><td>▁███████████████████████████████████████</td></tr><tr><td>val_acc_now</td><td>▁███████████████████████████████████████</td></tr><tr><td>val_loss</td><td>▁███████████████████████████████████████</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>DFA_flag</td><td>0.0</td></tr><tr><td>epoch</td><td>59</td></tr><tr><td>iter_acc</td><td>0.33333</td></tr><tr><td>tr_acc</td><td>0.1001</td></tr><tr><td>tr_epoch_loss</td><td>2.30253</td></tr><tr><td>val_acc_best</td><td>0.1</td></tr><tr><td>val_acc_now</td><td>0.1</td></tr><tr><td>val_loss</td><td>2.30261</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">smart-sweep-52</strong> at: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/xlk967am' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/xlk967am</a><br/> View project at: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main</a><br/>Synced 7 W&B file(s), 0 media file(s), 0 artifact file(s) and 1 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20240822_193227-xlk967am/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require(\"core\")`! See https://wandb.me/wandb-core for more information."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: hybxcnod with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBATCH: 16\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tDFA_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tIMAGE_SIZE: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tOTTT_input_trace_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tOTTT_sWS_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tTIME: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcfg: ['M', 'M', 200, 200]\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tconst2: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdecay: 0.25\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdrop_rate: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdvs_clipping: 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdvs_duration: 100000\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \te_transport_swap: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \te_transport_swap_coin: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \te_transport_swap_tr: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepoch_num: 60\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \texclude_class: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.01\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_sg_width: 2.570969004857107\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_reset: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_threshold: 1.6295587004374206\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmerge_polarities: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tscheduler_name: CosineAnnealingLR\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsurrogate: hard_sigmoid\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \twhich_data: DVS_GESTURE_TONIC\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.17.7 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.17.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/nfs/home/bhkim003/github_folder/ByeonghyeonKim/my_snn/wandb/run-20240822_193807-hybxcnod</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/hybxcnod' target=\"_blank\">volcanic-sweep-54</a></strong> to <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/yxynyr6h' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/yxynyr6h</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/yxynyr6h' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/yxynyr6h</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/hybxcnod' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/hybxcnod</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BATCH' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'IMAGE_SIZE' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'which_data' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_threshold' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_reset' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_sg_width' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'cfg' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'learning_rate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'epoch_num' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'surrogate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'scheduler_name' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'dvs_clipping' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'dvs_duration' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'OTTT_sWS_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'DFA_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'OTTT_input_trace_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'e_transport_swap' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'e_transport_swap_tr' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'e_transport_swap_coin' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'drop_rate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'exclude_class' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'merge_polarities' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'TIME' was locked by 'sweep' (ignored update).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset_hash = 2bbd58b4e0d3c1e9ad501fad8a43feed\n",
      "cache path exists\n",
      "\n",
      "we will exclude the 'other' class. dvsgestrue 10 classes' indices exist. \n",
      "\n",
      "DataParallel(\n",
      "  (module): MY_SNN_FC_sstep(\n",
      "    (layers): MY_Sequential(\n",
      "      (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (2): DimChanger_for_FC_sstep()\n",
      "      (3): SYNAPSE_FC_trace_sstep()\n",
      "      (4): LIF_layer_trace_sstep()\n",
      "      (5): SYNAPSE_FC_trace_sstep()\n",
      "      (6): LIF_layer_trace_sstep()\n",
      "      (7): SYNAPSE_FC_trace_sstep()\n",
      "    )\n",
      "  )\n",
      ")\n",
      "==================================================\n",
      "My Num of PARAMS: 452,010, system's param_num : 452,010\n",
      "Memory: 1.72MiB at 32-bit\n",
      "==================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch-0   lr=['0.0100000'], tr/val_loss:  2.317507/  2.316367, tr:   9.70%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:05<00:00, 11.83it/s]\n",
      "epoch-1   lr=['0.0099931'], tr/val_loss:  2.316254/  2.314931, tr:  10.21%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:04<00:00, 12.46it/s]\n",
      "epoch-2   lr=['0.0099726'], tr/val_loss:  2.315321/  2.315877, tr:   9.81%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:05<00:00, 12.00it/s]\n",
      "epoch-3   lr=['0.0099384'], tr/val_loss:  2.319123/  2.321801, tr:  10.42%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:05<00:00, 11.80it/s]\n",
      "epoch-4   lr=['0.0098907'], tr/val_loss:  2.328817/  2.310750, tr:   7.66%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:05<00:00, 12.26it/s]\n",
      "epoch-5   lr=['0.0098296'], tr/val_loss:  2.318780/  2.313111, tr:   8.58%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:05<00:00, 11.93it/s]\n",
      "epoch-6   lr=['0.0097553'], tr/val_loss:  2.326567/  2.312034, tr:   8.89%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:05<00:00, 12.05it/s]\n",
      "epoch-7   lr=['0.0096679'], tr/val_loss:  2.319906/  2.308871, tr:   8.89%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:04<00:00, 12.62it/s]\n",
      "epoch-8   lr=['0.0095677'], tr/val_loss:  2.315703/  2.318316, tr:   9.09%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:04<00:00, 12.41it/s]\n",
      "epoch-9   lr=['0.0094550'], tr/val_loss:  2.315776/  2.321137, tr:   9.81%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:04<00:00, 12.49it/s]\n",
      "epoch-10  lr=['0.0093301'], tr/val_loss:  2.319218/  2.310921, tr:   9.40%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:05<00:00, 12.35it/s]\n",
      "epoch-11  lr=['0.0091934'], tr/val_loss:  2.320658/  2.318817, tr:   9.60%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:05<00:00, 11.98it/s]\n",
      "epoch-12  lr=['0.0090451'], tr/val_loss:  2.323760/  2.306959, tr:   9.70%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:04<00:00, 12.63it/s]\n",
      "epoch-13  lr=['0.0088857'], tr/val_loss:  2.312257/  2.313825, tr:   8.78%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:04<00:00, 12.72it/s]\n",
      "epoch-14  lr=['0.0087157'], tr/val_loss:  2.321870/  2.310401, tr:   9.70%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:05<00:00, 12.34it/s]\n",
      "epoch-15  lr=['0.0085355'], tr/val_loss:  2.318407/  2.313874, tr:   9.60%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:04<00:00, 13.28it/s]\n",
      "epoch-16  lr=['0.0083457'], tr/val_loss:  2.317499/  2.312321, tr:  10.11%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:05<00:00, 12.29it/s]\n",
      "epoch-17  lr=['0.0081466'], tr/val_loss:  2.318669/  2.307941, tr:   8.89%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:05<00:00, 12.29it/s]\n",
      "epoch-18  lr=['0.0079389'], tr/val_loss:  2.325135/  2.306585, tr:   7.46%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:05<00:00, 11.99it/s]\n",
      "epoch-19  lr=['0.0077232'], tr/val_loss:  2.314244/  2.310251, tr:  10.01%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:05<00:00, 11.92it/s]\n",
      "epoch-20  lr=['0.0075000'], tr/val_loss:  2.312182/  2.307967, tr:   9.91%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:05<00:00, 12.29it/s]\n",
      "epoch-21  lr=['0.0072700'], tr/val_loss:  2.318818/  2.307295, tr:   9.30%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:05<00:00, 12.10it/s]\n",
      "epoch-22  lr=['0.0070337'], tr/val_loss:  2.313441/  2.307399, tr:   9.91%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:05<00:00, 12.00it/s]\n",
      "epoch-23  lr=['0.0067918'], tr/val_loss:  2.314248/  2.309416, tr:   7.76%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:05<00:00, 11.90it/s]\n",
      "epoch-24  lr=['0.0065451'], tr/val_loss:  2.318841/  2.305136, tr:   9.09%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:05<00:00, 11.96it/s]\n",
      "epoch-25  lr=['0.0062941'], tr/val_loss:  2.316903/  2.306750, tr:   7.97%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:05<00:00, 12.07it/s]\n",
      "epoch-26  lr=['0.0060396'], tr/val_loss:  2.311055/  2.305107, tr:   8.99%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:05<00:00, 12.04it/s]\n",
      "epoch-27  lr=['0.0057822'], tr/val_loss:  2.313828/  2.306802, tr:   8.58%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:05<00:00, 11.69it/s]\n",
      "epoch-28  lr=['0.0055226'], tr/val_loss:  2.315332/  2.308450, tr:   8.68%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:05<00:00, 12.18it/s]\n",
      "epoch-29  lr=['0.0052617'], tr/val_loss:  2.315842/  2.306032, tr:   7.15%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:05<00:00, 11.96it/s]\n",
      "epoch-30  lr=['0.0050000'], tr/val_loss:  2.312570/  2.303939, tr:   8.89%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:05<00:00, 12.39it/s]\n",
      "epoch-31  lr=['0.0047383'], tr/val_loss:  2.309263/  2.303903, tr:   9.09%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:04<00:00, 12.49it/s]\n",
      "epoch-32  lr=['0.0044774'], tr/val_loss:  2.311847/  2.302894, tr:   8.38%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:05<00:00, 11.75it/s]\n",
      "epoch-33  lr=['0.0042178'], tr/val_loss:  2.308722/  2.303530, tr:   9.50%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:05<00:00, 11.87it/s]\n",
      "epoch-34  lr=['0.0039604'], tr/val_loss:  2.313000/  2.304187, tr:   8.48%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:05<00:00, 11.85it/s]\n",
      "epoch-35  lr=['0.0037059'], tr/val_loss:  2.309877/  2.303538, tr:   9.09%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:04<00:00, 12.43it/s]\n",
      "epoch-36  lr=['0.0034549'], tr/val_loss:  2.309406/  2.303601, tr:   8.99%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:05<00:00, 12.04it/s]\n",
      "epoch-37  lr=['0.0032082'], tr/val_loss:  2.309686/  2.303400, tr:   7.66%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:04<00:00, 12.47it/s]\n",
      "epoch-38  lr=['0.0029663'], tr/val_loss:  2.308588/  2.303166, tr:   9.09%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:05<00:00, 12.05it/s]\n",
      "epoch-39  lr=['0.0027300'], tr/val_loss:  2.308727/  2.302884, tr:   8.89%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:05<00:00, 12.08it/s]\n",
      "epoch-40  lr=['0.0025000'], tr/val_loss:  2.308749/  2.302732, tr:   9.40%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:04<00:00, 12.55it/s]\n",
      "epoch-41  lr=['0.0022768'], tr/val_loss:  2.306803/  2.302942, tr:   9.19%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:04<00:00, 12.46it/s]\n",
      "epoch-42  lr=['0.0020611'], tr/val_loss:  2.306347/  2.302762, tr:   8.68%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:05<00:00, 12.05it/s]\n",
      "epoch-43  lr=['0.0018534'], tr/val_loss:  2.305991/  2.302857, tr:   8.99%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:05<00:00, 11.90it/s]\n",
      "epoch-44  lr=['0.0016543'], tr/val_loss:  2.305293/  2.302853, tr:  10.01%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:05<00:00, 12.09it/s]\n",
      "epoch-45  lr=['0.0014645'], tr/val_loss:  2.306396/  2.302847, tr:   8.48%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:05<00:00, 11.88it/s]\n",
      "epoch-46  lr=['0.0012843'], tr/val_loss:  2.305307/  2.302670, tr:  10.01%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:05<00:00, 12.16it/s]\n",
      "epoch-47  lr=['0.0011143'], tr/val_loss:  2.305197/  2.302644, tr:   9.30%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:05<00:00, 12.23it/s]\n",
      "epoch-48  lr=['0.0009549'], tr/val_loss:  2.304637/  2.302745, tr:   8.78%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:05<00:00, 12.19it/s]\n",
      "epoch-49  lr=['0.0008066'], tr/val_loss:  2.304113/  2.302645, tr:   8.89%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:05<00:00, 12.24it/s]\n",
      "epoch-50  lr=['0.0006699'], tr/val_loss:  2.304358/  2.302700, tr:   8.68%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:05<00:00, 11.92it/s]\n",
      "epoch-51  lr=['0.0005450'], tr/val_loss:  2.303610/  2.302717, tr:   9.81%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:05<00:00, 11.84it/s]\n",
      "epoch-52  lr=['0.0004323'], tr/val_loss:  2.303667/  2.302626, tr:   9.30%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:05<00:00, 11.94it/s]\n",
      "epoch-53  lr=['0.0003321'], tr/val_loss:  2.303300/  2.302634, tr:   9.19%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:05<00:00, 11.97it/s]\n",
      "epoch-54  lr=['0.0002447'], tr/val_loss:  2.303030/  2.302622, tr:   8.38%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:05<00:00, 12.27it/s]\n",
      "epoch-55  lr=['0.0001704'], tr/val_loss:  2.303107/  2.302625, tr:  10.01%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:05<00:00, 11.69it/s]\n",
      "epoch-56  lr=['0.0001093'], tr/val_loss:  2.302886/  2.302609, tr:  10.01%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:05<00:00, 12.30it/s]\n",
      "epoch-57  lr=['0.0000616'], tr/val_loss:  2.302670/  2.302610, tr:  10.01%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:04<00:00, 12.44it/s]\n",
      "epoch-58  lr=['0.0000274'], tr/val_loss:  2.302685/  2.302609, tr:  10.01%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:05<00:00, 12.32it/s]\n",
      "epoch-59  lr=['0.0000069'], tr/val_loss:  2.302528/  2.302609, tr:  10.01%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:04<00:00, 12.79it/s]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "636e8405f74c49ec9d4822a803293b42",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='3.438 MB of 3.438 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>DFA_flag</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>epoch</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇████</td></tr><tr><td>iter_acc</td><td>▁█▅▅▃▁▅█▆▃▆▅▃▃▁▃▃▃▁▁▁▁▆▅▁▃▁▅▃▅▃▅▃▃▅▅▁▃▅█</td></tr><tr><td>summary_val_acc</td><td>▁███████████████████████████████████████</td></tr><tr><td>tr_acc</td><td>▁███▇▇▇█▇███▇███▆▆▇▇▆▇▇▇▇▆▇▇▇▇██▇▇█▇▇███</td></tr><tr><td>tr_epoch_loss</td><td>▁███████████████████████████████████████</td></tr><tr><td>val_acc_best</td><td>▁███████████████████████████████████████</td></tr><tr><td>val_acc_now</td><td>▁███████████████████████████████████████</td></tr><tr><td>val_loss</td><td>▁███████████████████████████████████████</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>DFA_flag</td><td>0.0</td></tr><tr><td>epoch</td><td>59</td></tr><tr><td>iter_acc</td><td>0.33333</td></tr><tr><td>tr_acc</td><td>0.1001</td></tr><tr><td>tr_epoch_loss</td><td>2.30253</td></tr><tr><td>val_acc_best</td><td>0.1</td></tr><tr><td>val_acc_now</td><td>0.1</td></tr><tr><td>val_loss</td><td>2.30261</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">volcanic-sweep-54</strong> at: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/hybxcnod' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/hybxcnod</a><br/> View project at: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main</a><br/>Synced 7 W&B file(s), 0 media file(s), 0 artifact file(s) and 1 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20240822_193807-hybxcnod/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require(\"core\")`! See https://wandb.me/wandb-core for more information."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Sweep Agent: Waiting for job.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Job received.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: ue3gkif4 with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBATCH: 16\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tDFA_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tIMAGE_SIZE: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tOTTT_input_trace_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tOTTT_sWS_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tTIME: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcfg: ['M', 'M', 200, 200]\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tconst2: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdecay: 0.25\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdrop_rate: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdvs_clipping: 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdvs_duration: 100000\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \te_transport_swap: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \te_transport_swap_coin: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \te_transport_swap_tr: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepoch_num: 60\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \texclude_class: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.01\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_sg_width: 2.570969004857107\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_reset: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_threshold: 1.121304770463221\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmerge_polarities: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tscheduler_name: CosineAnnealingLR\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsurrogate: hard_sigmoid\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \twhich_data: DVS_GESTURE_TONIC\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.17.7 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.17.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/nfs/home/bhkim003/github_folder/ByeonghyeonKim/my_snn/wandb/run-20240822_194358-ue3gkif4</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/ue3gkif4' target=\"_blank\">deep-sweep-56</a></strong> to <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/yxynyr6h' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/yxynyr6h</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/yxynyr6h' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/yxynyr6h</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/ue3gkif4' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/ue3gkif4</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BATCH' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'IMAGE_SIZE' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'which_data' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_threshold' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_reset' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_sg_width' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'cfg' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'learning_rate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'epoch_num' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'surrogate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'scheduler_name' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'dvs_clipping' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'dvs_duration' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'OTTT_sWS_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'DFA_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'OTTT_input_trace_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'e_transport_swap' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'e_transport_swap_tr' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'e_transport_swap_coin' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'drop_rate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'exclude_class' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'merge_polarities' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'TIME' was locked by 'sweep' (ignored update).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset_hash = 2bbd58b4e0d3c1e9ad501fad8a43feed\n",
      "cache path exists\n",
      "\n",
      "we will exclude the 'other' class. dvsgestrue 10 classes' indices exist. \n",
      "\n",
      "DataParallel(\n",
      "  (module): MY_SNN_FC_sstep(\n",
      "    (layers): MY_Sequential(\n",
      "      (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (2): DimChanger_for_FC_sstep()\n",
      "      (3): SYNAPSE_FC_trace_sstep()\n",
      "      (4): LIF_layer_trace_sstep()\n",
      "      (5): SYNAPSE_FC_trace_sstep()\n",
      "      (6): LIF_layer_trace_sstep()\n",
      "      (7): SYNAPSE_FC_trace_sstep()\n",
      "    )\n",
      "  )\n",
      ")\n",
      "==================================================\n",
      "My Num of PARAMS: 452,010, system's param_num : 452,010\n",
      "Memory: 1.72MiB at 32-bit\n",
      "==================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch-0   lr=['0.0100000'], tr/val_loss:  2.302350/  2.085467, tr:  10.83%, val:  20.83%, val_best:  20.83%: 100%|██████████| 62/62 [00:05<00:00, 12.10it/s]\n",
      "epoch-1   lr=['0.0099931'], tr/val_loss:  1.469623/  1.414320, tr:  49.03%, val:  53.33%, val_best:  53.33%: 100%|██████████| 62/62 [00:05<00:00, 11.48it/s]\n",
      "epoch-2   lr=['0.0099726'], tr/val_loss:  1.124451/  1.262492, tr:  62.92%, val:  59.17%, val_best:  59.17%: 100%|██████████| 62/62 [00:05<00:00, 11.75it/s]\n",
      "epoch-3   lr=['0.0099384'], tr/val_loss:  1.018481/  1.175335, tr:  65.47%, val:  62.08%, val_best:  62.08%: 100%|██████████| 62/62 [00:05<00:00, 12.07it/s]\n",
      "epoch-4   lr=['0.0098907'], tr/val_loss:  0.947222/  1.248954, tr:  68.44%, val:  60.42%, val_best:  62.08%: 100%|██████████| 62/62 [00:05<00:00, 12.19it/s]\n",
      "epoch-5   lr=['0.0098296'], tr/val_loss:  0.879488/  1.232382, tr:  68.44%, val:  62.50%, val_best:  62.50%: 100%|██████████| 62/62 [00:05<00:00, 12.11it/s]\n",
      "epoch-6   lr=['0.0097553'], tr/val_loss:  0.808782/  1.202139, tr:  69.66%, val:  59.58%, val_best:  62.50%: 100%|██████████| 62/62 [00:05<00:00, 12.00it/s]\n",
      "epoch-7   lr=['0.0096679'], tr/val_loss:  0.804573/  1.348786, tr:  69.97%, val:  53.75%, val_best:  62.50%: 100%|██████████| 62/62 [00:05<00:00, 12.26it/s]\n",
      "epoch-8   lr=['0.0095677'], tr/val_loss:  0.746547/  1.174417, tr:  72.73%, val:  61.67%, val_best:  62.50%: 100%|██████████| 62/62 [00:05<00:00, 11.98it/s]\n",
      "epoch-9   lr=['0.0094550'], tr/val_loss:  0.586981/  1.287827, tr:  78.14%, val:  67.50%, val_best:  67.50%: 100%|██████████| 62/62 [00:05<00:00, 11.94it/s]\n",
      "epoch-10  lr=['0.0093301'], tr/val_loss:  0.574434/  1.189259, tr:  79.47%, val:  67.50%, val_best:  67.50%: 100%|██████████| 62/62 [00:04<00:00, 12.54it/s]\n",
      "epoch-11  lr=['0.0091934'], tr/val_loss:  0.490841/  1.355585, tr:  79.78%, val:  64.58%, val_best:  67.50%: 100%|██████████| 62/62 [00:04<00:00, 12.58it/s]\n",
      "epoch-12  lr=['0.0090451'], tr/val_loss:  0.534050/  1.229949, tr:  82.02%, val:  67.50%, val_best:  67.50%: 100%|██████████| 62/62 [00:04<00:00, 12.44it/s]\n",
      "epoch-13  lr=['0.0088857'], tr/val_loss:  0.482511/  1.211288, tr:  87.64%, val:  67.50%, val_best:  67.50%: 100%|██████████| 62/62 [00:04<00:00, 12.41it/s]\n",
      "epoch-14  lr=['0.0087157'], tr/val_loss:  0.436643/  1.216252, tr:  88.05%, val:  68.33%, val_best:  68.33%: 100%|██████████| 62/62 [00:04<00:00, 12.88it/s]\n",
      "epoch-15  lr=['0.0085355'], tr/val_loss:  0.379298/  1.235347, tr:  89.99%, val:  76.67%, val_best:  76.67%: 100%|██████████| 62/62 [00:05<00:00, 12.02it/s]\n",
      "epoch-16  lr=['0.0083457'], tr/val_loss:  0.354693/  1.340379, tr:  91.32%, val:  75.00%, val_best:  76.67%: 100%|██████████| 62/62 [00:05<00:00, 11.30it/s]\n",
      "epoch-17  lr=['0.0081466'], tr/val_loss:  0.334296/  1.373995, tr:  92.54%, val:  73.33%, val_best:  76.67%: 100%|██████████| 62/62 [00:05<00:00, 12.15it/s]\n",
      "epoch-18  lr=['0.0079389'], tr/val_loss:  0.267885/  1.392883, tr:  95.10%, val:  75.00%, val_best:  76.67%: 100%|██████████| 62/62 [00:05<00:00, 11.62it/s]\n",
      "epoch-19  lr=['0.0077232'], tr/val_loss:  0.222334/  1.495656, tr:  97.55%, val:  73.75%, val_best:  76.67%: 100%|██████████| 62/62 [00:05<00:00, 12.10it/s]\n",
      "epoch-20  lr=['0.0075000'], tr/val_loss:  0.214367/  1.371059, tr:  97.65%, val:  78.33%, val_best:  78.33%: 100%|██████████| 62/62 [00:05<00:00, 11.88it/s]\n",
      "epoch-21  lr=['0.0072700'], tr/val_loss:  0.139344/  1.573736, tr:  99.49%, val:  75.00%, val_best:  78.33%: 100%|██████████| 62/62 [00:05<00:00, 11.92it/s]\n",
      "epoch-22  lr=['0.0070337'], tr/val_loss:  0.148533/  1.434868, tr:  97.55%, val:  78.33%, val_best:  78.33%: 100%|██████████| 62/62 [00:05<00:00, 12.36it/s]\n",
      "epoch-23  lr=['0.0067918'], tr/val_loss:  0.096593/  1.584798, tr:  99.80%, val:  77.08%, val_best:  78.33%: 100%|██████████| 62/62 [00:05<00:00, 11.57it/s]\n",
      "epoch-24  lr=['0.0065451'], tr/val_loss:  0.092947/  1.537712, tr:  99.59%, val:  80.42%, val_best:  80.42%: 100%|██████████| 62/62 [00:05<00:00, 12.05it/s]\n",
      "epoch-25  lr=['0.0062941'], tr/val_loss:  0.070691/  1.637881, tr:  99.90%, val:  77.08%, val_best:  80.42%: 100%|██████████| 62/62 [00:05<00:00, 11.73it/s]\n",
      "epoch-26  lr=['0.0060396'], tr/val_loss:  0.036862/  1.627873, tr: 100.00%, val:  80.00%, val_best:  80.42%: 100%|██████████| 62/62 [00:05<00:00, 11.75it/s]\n",
      "epoch-27  lr=['0.0057822'], tr/val_loss:  0.027172/  1.645927, tr: 100.00%, val:  80.83%, val_best:  80.83%: 100%|██████████| 62/62 [00:05<00:00, 12.03it/s]\n",
      "epoch-28  lr=['0.0055226'], tr/val_loss:  0.019368/  1.674338, tr: 100.00%, val:  80.00%, val_best:  80.83%: 100%|██████████| 62/62 [00:05<00:00, 11.60it/s]\n",
      "epoch-29  lr=['0.0052617'], tr/val_loss:  0.013936/  1.756507, tr: 100.00%, val:  81.25%, val_best:  81.25%: 100%|██████████| 62/62 [00:05<00:00, 12.11it/s]\n",
      "epoch-30  lr=['0.0050000'], tr/val_loss:  0.010246/  1.678988, tr: 100.00%, val:  81.67%, val_best:  81.67%: 100%|██████████| 62/62 [00:05<00:00, 11.64it/s]\n",
      "epoch-31  lr=['0.0047383'], tr/val_loss:  0.010408/  1.716755, tr: 100.00%, val:  80.83%, val_best:  81.67%: 100%|██████████| 62/62 [00:05<00:00, 11.78it/s]\n",
      "epoch-32  lr=['0.0044774'], tr/val_loss:  0.007249/  1.684781, tr: 100.00%, val:  80.83%, val_best:  81.67%: 100%|██████████| 62/62 [00:05<00:00, 11.81it/s]\n",
      "epoch-33  lr=['0.0042178'], tr/val_loss:  0.005254/  1.759991, tr: 100.00%, val:  79.17%, val_best:  81.67%: 100%|██████████| 62/62 [00:05<00:00, 11.70it/s]\n",
      "epoch-34  lr=['0.0039604'], tr/val_loss:  0.004825/  1.747140, tr: 100.00%, val:  79.58%, val_best:  81.67%: 100%|██████████| 62/62 [00:04<00:00, 12.46it/s]\n",
      "epoch-35  lr=['0.0037059'], tr/val_loss:  0.003721/  1.756461, tr: 100.00%, val:  80.83%, val_best:  81.67%: 100%|██████████| 62/62 [00:05<00:00, 11.52it/s]\n",
      "epoch-36  lr=['0.0034549'], tr/val_loss:  0.003145/  1.763865, tr: 100.00%, val:  80.00%, val_best:  81.67%: 100%|██████████| 62/62 [00:05<00:00, 11.71it/s]\n",
      "epoch-37  lr=['0.0032082'], tr/val_loss:  0.002744/  1.764886, tr: 100.00%, val:  80.83%, val_best:  81.67%: 100%|██████████| 62/62 [00:05<00:00, 11.97it/s]\n",
      "epoch-38  lr=['0.0029663'], tr/val_loss:  0.002706/  1.775884, tr: 100.00%, val:  80.42%, val_best:  81.67%: 100%|██████████| 62/62 [00:05<00:00, 11.78it/s]\n",
      "epoch-39  lr=['0.0027300'], tr/val_loss:  0.002552/  1.769162, tr: 100.00%, val:  79.58%, val_best:  81.67%: 100%|██████████| 62/62 [00:05<00:00, 12.06it/s]\n",
      "epoch-40  lr=['0.0025000'], tr/val_loss:  0.002428/  1.784287, tr: 100.00%, val:  79.58%, val_best:  81.67%: 100%|██████████| 62/62 [00:05<00:00, 11.69it/s]\n",
      "epoch-41  lr=['0.0022768'], tr/val_loss:  0.002338/  1.783068, tr: 100.00%, val:  79.58%, val_best:  81.67%: 100%|██████████| 62/62 [00:05<00:00, 12.03it/s]\n",
      "epoch-42  lr=['0.0020611'], tr/val_loss:  0.002212/  1.785569, tr: 100.00%, val:  80.00%, val_best:  81.67%: 100%|██████████| 62/62 [00:05<00:00, 11.85it/s]\n",
      "epoch-43  lr=['0.0018534'], tr/val_loss:  0.002134/  1.786715, tr: 100.00%, val:  79.58%, val_best:  81.67%: 100%|██████████| 62/62 [00:05<00:00, 12.00it/s]\n",
      "epoch-44  lr=['0.0016543'], tr/val_loss:  0.002073/  1.785117, tr: 100.00%, val:  79.17%, val_best:  81.67%: 100%|██████████| 62/62 [00:05<00:00, 11.69it/s]\n",
      "epoch-45  lr=['0.0014645'], tr/val_loss:  0.002094/  1.791391, tr: 100.00%, val:  79.58%, val_best:  81.67%: 100%|██████████| 62/62 [00:05<00:00, 11.83it/s]\n",
      "epoch-46  lr=['0.0012843'], tr/val_loss:  0.002012/  1.792307, tr: 100.00%, val:  79.17%, val_best:  81.67%: 100%|██████████| 62/62 [00:05<00:00, 11.93it/s]\n",
      "epoch-47  lr=['0.0011143'], tr/val_loss:  0.001946/  1.799118, tr: 100.00%, val:  79.58%, val_best:  81.67%: 100%|██████████| 62/62 [00:04<00:00, 12.55it/s]\n",
      "epoch-48  lr=['0.0009549'], tr/val_loss:  0.001930/  1.794619, tr: 100.00%, val:  80.00%, val_best:  81.67%: 100%|██████████| 62/62 [00:05<00:00, 11.98it/s]\n",
      "epoch-49  lr=['0.0008066'], tr/val_loss:  0.001887/  1.790622, tr: 100.00%, val:  80.00%, val_best:  81.67%: 100%|██████████| 62/62 [00:05<00:00, 12.25it/s]\n",
      "epoch-50  lr=['0.0006699'], tr/val_loss:  0.001897/  1.794052, tr: 100.00%, val:  80.42%, val_best:  81.67%: 100%|██████████| 62/62 [00:05<00:00, 12.06it/s]\n",
      "epoch-51  lr=['0.0005450'], tr/val_loss:  0.001920/  1.798768, tr: 100.00%, val:  80.00%, val_best:  81.67%: 100%|██████████| 62/62 [00:05<00:00, 11.97it/s]\n",
      "epoch-52  lr=['0.0004323'], tr/val_loss:  0.001877/  1.801348, tr: 100.00%, val:  79.58%, val_best:  81.67%: 100%|██████████| 62/62 [00:04<00:00, 12.53it/s]\n",
      "epoch-53  lr=['0.0003321'], tr/val_loss:  0.001862/  1.802700, tr: 100.00%, val:  79.58%, val_best:  81.67%: 100%|██████████| 62/62 [00:05<00:00, 11.47it/s]\n",
      "epoch-54  lr=['0.0002447'], tr/val_loss:  0.001859/  1.803180, tr: 100.00%, val:  79.58%, val_best:  81.67%: 100%|██████████| 62/62 [00:05<00:00, 11.90it/s]\n",
      "epoch-55  lr=['0.0001704'], tr/val_loss:  0.001859/  1.803384, tr: 100.00%, val:  79.58%, val_best:  81.67%: 100%|██████████| 62/62 [00:05<00:00, 11.66it/s]\n",
      "epoch-56  lr=['0.0001093'], tr/val_loss:  0.001814/  1.804149, tr: 100.00%, val:  79.58%, val_best:  81.67%: 100%|██████████| 62/62 [00:05<00:00, 12.25it/s]\n",
      "epoch-57  lr=['0.0000616'], tr/val_loss:  0.001837/  1.804193, tr: 100.00%, val:  79.58%, val_best:  81.67%: 100%|██████████| 62/62 [00:05<00:00, 11.86it/s]\n",
      "epoch-58  lr=['0.0000274'], tr/val_loss:  0.001809/  1.804591, tr: 100.00%, val:  79.58%, val_best:  81.67%: 100%|██████████| 62/62 [00:05<00:00, 11.85it/s]\n",
      "epoch-59  lr=['0.0000069'], tr/val_loss:  0.001799/  1.804553, tr: 100.00%, val:  79.58%, val_best:  81.67%: 100%|██████████| 62/62 [00:05<00:00, 11.74it/s]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a1663c45c7ad47e2b3c0cb41a3c03026",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='3.438 MB of 3.438 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>DFA_flag</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>epoch</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇████</td></tr><tr><td>iter_acc</td><td>▁▄▅█▇▅▆▇▆▇██▇███████████████████████████</td></tr><tr><td>summary_val_acc</td><td>▁▃▆▆▆▆▆▇▇▇▇▇▇▇██████████████████████████</td></tr><tr><td>tr_acc</td><td>▁▂▅▆▆▆▆▆▇▇▇▇▇███████████████████████████</td></tr><tr><td>tr_epoch_loss</td><td>▁█▄▄▄▃▃▃▂▃▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_acc_best</td><td>▁▃▆▆▆▆▆▇▇▇▇█████████████████████████████</td></tr><tr><td>val_acc_now</td><td>▁▃▆▆▆▆▆▇▇▇▇▇▇▇██████████████████████████</td></tr><tr><td>val_loss</td><td>▁█▅▅▅▅▅▅▆▅▅▅▆▆▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>DFA_flag</td><td>0.0</td></tr><tr><td>epoch</td><td>59</td></tr><tr><td>iter_acc</td><td>1.0</td></tr><tr><td>tr_acc</td><td>1.0</td></tr><tr><td>tr_epoch_loss</td><td>0.0018</td></tr><tr><td>val_acc_best</td><td>0.81667</td></tr><tr><td>val_acc_now</td><td>0.79583</td></tr><tr><td>val_loss</td><td>1.80455</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">deep-sweep-56</strong> at: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/ue3gkif4' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/ue3gkif4</a><br/> View project at: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main</a><br/>Synced 7 W&B file(s), 0 media file(s), 0 artifact file(s) and 1 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20240822_194358-ue3gkif4/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require(\"core\")`! See https://wandb.me/wandb-core for more information."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 1qd4kp8d with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBATCH: 16\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tDFA_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tIMAGE_SIZE: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tOTTT_input_trace_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tOTTT_sWS_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tTIME: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcfg: ['M', 'M', 200, 200]\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tconst2: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdecay: 0.25\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdrop_rate: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdvs_clipping: 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdvs_duration: 100000\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \te_transport_swap: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \te_transport_swap_coin: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \te_transport_swap_tr: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepoch_num: 60\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \texclude_class: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.01\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_sg_width: 2.570969004857107\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_reset: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_threshold: 1.0125719071583843\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmerge_polarities: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tscheduler_name: CosineAnnealingLR\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsurrogate: hard_sigmoid\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \twhich_data: DVS_GESTURE_TONIC\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.17.7 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.17.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/nfs/home/bhkim003/github_folder/ByeonghyeonKim/my_snn/wandb/run-20240822_194939-1qd4kp8d</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/1qd4kp8d' target=\"_blank\">unique-sweep-58</a></strong> to <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/yxynyr6h' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/yxynyr6h</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/yxynyr6h' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/yxynyr6h</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/1qd4kp8d' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/1qd4kp8d</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BATCH' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'IMAGE_SIZE' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'which_data' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_threshold' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_reset' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_sg_width' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'cfg' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'learning_rate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'epoch_num' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'surrogate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'scheduler_name' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'dvs_clipping' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'dvs_duration' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'OTTT_sWS_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'DFA_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'OTTT_input_trace_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'e_transport_swap' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'e_transport_swap_tr' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'e_transport_swap_coin' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'drop_rate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'exclude_class' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'merge_polarities' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'TIME' was locked by 'sweep' (ignored update).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset_hash = 2bbd58b4e0d3c1e9ad501fad8a43feed\n",
      "cache path exists\n",
      "\n",
      "we will exclude the 'other' class. dvsgestrue 10 classes' indices exist. \n",
      "\n",
      "DataParallel(\n",
      "  (module): MY_SNN_FC_sstep(\n",
      "    (layers): MY_Sequential(\n",
      "      (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (2): DimChanger_for_FC_sstep()\n",
      "      (3): SYNAPSE_FC_trace_sstep()\n",
      "      (4): LIF_layer_trace_sstep()\n",
      "      (5): SYNAPSE_FC_trace_sstep()\n",
      "      (6): LIF_layer_trace_sstep()\n",
      "      (7): SYNAPSE_FC_trace_sstep()\n",
      "    )\n",
      "  )\n",
      ")\n",
      "==================================================\n",
      "My Num of PARAMS: 452,010, system's param_num : 452,010\n",
      "Memory: 1.72MiB at 32-bit\n",
      "==================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch-0   lr=['0.0100000'], tr/val_loss:  1.900885/  1.440690, tr:  33.09%, val:  47.50%, val_best:  47.50%: 100%|██████████| 62/62 [00:04<00:00, 12.57it/s]\n",
      "epoch-1   lr=['0.0099931'], tr/val_loss:  1.238076/  1.378232, tr:  57.81%, val:  50.42%, val_best:  50.42%: 100%|██████████| 62/62 [00:05<00:00, 12.36it/s]\n",
      "epoch-2   lr=['0.0099726'], tr/val_loss:  1.071656/  1.218136, tr:  62.41%, val:  62.92%, val_best:  62.92%: 100%|██████████| 62/62 [00:05<00:00, 12.31it/s]\n",
      "epoch-3   lr=['0.0099384'], tr/val_loss:  0.928356/  1.140803, tr:  68.13%, val:  62.50%, val_best:  62.92%: 100%|██████████| 62/62 [00:05<00:00, 12.26it/s]\n",
      "epoch-4   lr=['0.0098907'], tr/val_loss:  0.871255/  1.141983, tr:  69.77%, val:  65.00%, val_best:  65.00%: 100%|██████████| 62/62 [00:05<00:00, 11.74it/s]\n",
      "epoch-5   lr=['0.0098296'], tr/val_loss:  0.800510/  1.334015, tr:  69.46%, val:  60.42%, val_best:  65.00%: 100%|██████████| 62/62 [00:05<00:00, 12.04it/s]\n",
      "epoch-6   lr=['0.0097553'], tr/val_loss:  0.706695/  1.184894, tr:  73.14%, val:  62.92%, val_best:  65.00%: 100%|██████████| 62/62 [00:05<00:00, 12.31it/s]\n",
      "epoch-7   lr=['0.0096679'], tr/val_loss:  0.727647/  1.358310, tr:  74.26%, val:  60.83%, val_best:  65.00%: 100%|██████████| 62/62 [00:05<00:00, 12.07it/s]\n",
      "epoch-8   lr=['0.0095677'], tr/val_loss:  0.784610/  1.196293, tr:  70.99%, val:  64.58%, val_best:  65.00%: 100%|██████████| 62/62 [00:05<00:00, 12.09it/s]\n",
      "epoch-9   lr=['0.0094550'], tr/val_loss:  0.570532/  1.319346, tr:  77.53%, val:  66.67%, val_best:  66.67%: 100%|██████████| 62/62 [00:05<00:00, 11.18it/s]\n",
      "epoch-10  lr=['0.0093301'], tr/val_loss:  0.553319/  1.236312, tr:  80.59%, val:  68.75%, val_best:  68.75%: 100%|██████████| 62/62 [00:05<00:00, 11.76it/s]\n",
      "epoch-11  lr=['0.0091934'], tr/val_loss:  0.500886/  1.362531, tr:  79.78%, val:  68.75%, val_best:  68.75%: 100%|██████████| 62/62 [00:05<00:00, 12.20it/s]\n",
      "epoch-12  lr=['0.0090451'], tr/val_loss:  0.500020/  1.195353, tr:  83.04%, val:  71.25%, val_best:  71.25%: 100%|██████████| 62/62 [00:04<00:00, 12.93it/s]\n",
      "epoch-13  lr=['0.0088857'], tr/val_loss:  0.464369/  1.280797, tr:  86.01%, val:  65.83%, val_best:  71.25%: 100%|██████████| 62/62 [00:05<00:00, 12.20it/s]\n",
      "epoch-14  lr=['0.0087157'], tr/val_loss:  0.418822/  1.171676, tr:  86.52%, val:  73.75%, val_best:  73.75%: 100%|██████████| 62/62 [00:04<00:00, 13.13it/s]\n",
      "epoch-15  lr=['0.0085355'], tr/val_loss:  0.428867/  1.431108, tr:  87.84%, val:  69.58%, val_best:  73.75%: 100%|██████████| 62/62 [00:05<00:00, 12.34it/s]\n",
      "epoch-16  lr=['0.0083457'], tr/val_loss:  0.336505/  1.402738, tr:  91.22%, val:  72.92%, val_best:  73.75%: 100%|██████████| 62/62 [00:05<00:00, 12.38it/s]\n",
      "epoch-17  lr=['0.0081466'], tr/val_loss:  0.284684/  1.293072, tr:  94.18%, val:  73.33%, val_best:  73.75%: 100%|██████████| 62/62 [00:05<00:00, 12.13it/s]\n",
      "epoch-18  lr=['0.0079389'], tr/val_loss:  0.260304/  1.407072, tr:  94.79%, val:  73.33%, val_best:  73.75%: 100%|██████████| 62/62 [00:05<00:00, 11.67it/s]\n",
      "epoch-19  lr=['0.0077232'], tr/val_loss:  0.219373/  1.386709, tr:  96.63%, val:  75.83%, val_best:  75.83%: 100%|██████████| 62/62 [00:05<00:00, 11.41it/s]\n",
      "epoch-20  lr=['0.0075000'], tr/val_loss:  0.161861/  1.399753, tr:  98.67%, val:  77.50%, val_best:  77.50%: 100%|██████████| 62/62 [00:05<00:00, 12.37it/s]\n",
      "epoch-21  lr=['0.0072700'], tr/val_loss:  0.122622/  1.517679, tr:  99.59%, val:  75.42%, val_best:  77.50%: 100%|██████████| 62/62 [00:05<00:00, 11.58it/s]\n",
      "epoch-22  lr=['0.0070337'], tr/val_loss:  0.111208/  1.414477, tr:  98.57%, val:  77.50%, val_best:  77.50%: 100%|██████████| 62/62 [00:16<00:00,  3.68it/s]\n",
      "epoch-23  lr=['0.0067918'], tr/val_loss:  0.068260/  1.444318, tr: 100.00%, val:  76.25%, val_best:  77.50%: 100%|██████████| 62/62 [00:05<00:00, 10.97it/s]\n",
      "epoch-24  lr=['0.0065451'], tr/val_loss:  0.052014/  1.507441, tr: 100.00%, val:  80.83%, val_best:  80.83%: 100%|██████████| 62/62 [00:05<00:00, 10.40it/s]\n",
      "epoch-25  lr=['0.0062941'], tr/val_loss:  0.049651/  1.508083, tr: 100.00%, val:  75.00%, val_best:  80.83%: 100%|██████████| 62/62 [00:06<00:00,  9.61it/s]\n",
      "epoch-26  lr=['0.0060396'], tr/val_loss:  0.033988/  1.482311, tr: 100.00%, val:  80.00%, val_best:  80.83%: 100%|██████████| 62/62 [00:05<00:00, 10.58it/s]\n",
      "epoch-27  lr=['0.0057822'], tr/val_loss:  0.023132/  1.531501, tr: 100.00%, val:  78.33%, val_best:  80.83%: 100%|██████████| 62/62 [00:05<00:00, 11.20it/s]\n",
      "epoch-28  lr=['0.0055226'], tr/val_loss:  0.016601/  1.509272, tr: 100.00%, val:  82.08%, val_best:  82.08%: 100%|██████████| 62/62 [00:06<00:00,  9.83it/s]\n",
      "epoch-29  lr=['0.0052617'], tr/val_loss:  0.012691/  1.562509, tr: 100.00%, val:  80.42%, val_best:  82.08%: 100%|██████████| 62/62 [00:06<00:00, 10.08it/s]\n",
      "epoch-30  lr=['0.0050000'], tr/val_loss:  0.013545/  1.603711, tr: 100.00%, val:  80.00%, val_best:  82.08%: 100%|██████████| 62/62 [00:05<00:00, 10.75it/s]\n",
      "epoch-31  lr=['0.0047383'], tr/val_loss:  0.008577/  1.609716, tr: 100.00%, val:  78.75%, val_best:  82.08%: 100%|██████████| 62/62 [00:06<00:00,  9.89it/s]\n",
      "epoch-32  lr=['0.0044774'], tr/val_loss:  0.011860/  1.619348, tr: 100.00%, val:  79.58%, val_best:  82.08%: 100%|██████████| 62/62 [00:06<00:00,  9.90it/s]\n",
      "epoch-33  lr=['0.0042178'], tr/val_loss:  0.006604/  1.579249, tr: 100.00%, val:  81.67%, val_best:  82.08%: 100%|██████████| 62/62 [00:05<00:00, 10.40it/s]\n",
      "epoch-34  lr=['0.0039604'], tr/val_loss:  0.004856/  1.594740, tr: 100.00%, val:  82.08%, val_best:  82.08%: 100%|██████████| 62/62 [00:05<00:00, 11.07it/s]\n",
      "epoch-35  lr=['0.0037059'], tr/val_loss:  0.004188/  1.603065, tr: 100.00%, val:  82.08%, val_best:  82.08%: 100%|██████████| 62/62 [00:05<00:00, 10.92it/s]\n",
      "epoch-36  lr=['0.0034549'], tr/val_loss:  0.003586/  1.606528, tr: 100.00%, val:  81.25%, val_best:  82.08%: 100%|██████████| 62/62 [00:06<00:00, 10.23it/s]\n",
      "epoch-37  lr=['0.0032082'], tr/val_loss:  0.003077/  1.604491, tr: 100.00%, val:  80.83%, val_best:  82.08%: 100%|██████████| 62/62 [00:06<00:00, 10.14it/s]\n",
      "epoch-38  lr=['0.0029663'], tr/val_loss:  0.002774/  1.610222, tr: 100.00%, val:  81.25%, val_best:  82.08%: 100%|██████████| 62/62 [00:06<00:00, 10.27it/s]\n",
      "epoch-39  lr=['0.0027300'], tr/val_loss:  0.002705/  1.618448, tr: 100.00%, val:  81.25%, val_best:  82.08%: 100%|██████████| 62/62 [00:05<00:00, 10.66it/s]\n",
      "epoch-40  lr=['0.0025000'], tr/val_loss:  0.002460/  1.638064, tr: 100.00%, val:  81.67%, val_best:  82.08%: 100%|██████████| 62/62 [00:05<00:00, 10.55it/s]\n",
      "epoch-41  lr=['0.0022768'], tr/val_loss:  0.002376/  1.642304, tr: 100.00%, val:  80.83%, val_best:  82.08%: 100%|██████████| 62/62 [00:05<00:00, 10.73it/s]\n",
      "epoch-42  lr=['0.0020611'], tr/val_loss:  0.002266/  1.638376, tr: 100.00%, val:  81.25%, val_best:  82.08%: 100%|██████████| 62/62 [00:05<00:00, 10.41it/s]\n",
      "epoch-43  lr=['0.0018534'], tr/val_loss:  0.002269/  1.644274, tr: 100.00%, val:  81.25%, val_best:  82.08%: 100%|██████████| 62/62 [00:06<00:00,  9.75it/s]\n",
      "epoch-44  lr=['0.0016543'], tr/val_loss:  0.002162/  1.637300, tr: 100.00%, val:  81.25%, val_best:  82.08%: 100%|██████████| 62/62 [00:05<00:00, 10.39it/s]\n",
      "epoch-45  lr=['0.0014645'], tr/val_loss:  0.002052/  1.639530, tr: 100.00%, val:  81.25%, val_best:  82.08%: 100%|██████████| 62/62 [00:05<00:00, 10.90it/s]\n",
      "epoch-46  lr=['0.0012843'], tr/val_loss:  0.002054/  1.637847, tr: 100.00%, val:  81.25%, val_best:  82.08%: 100%|██████████| 62/62 [00:06<00:00, 10.29it/s]\n",
      "epoch-47  lr=['0.0011143'], tr/val_loss:  0.001995/  1.637517, tr: 100.00%, val:  81.25%, val_best:  82.08%: 100%|██████████| 62/62 [00:05<00:00, 10.76it/s]\n",
      "epoch-48  lr=['0.0009549'], tr/val_loss:  0.001999/  1.640673, tr: 100.00%, val:  81.25%, val_best:  82.08%: 100%|██████████| 62/62 [00:05<00:00, 10.65it/s]\n",
      "epoch-49  lr=['0.0008066'], tr/val_loss:  0.001917/  1.636014, tr: 100.00%, val:  81.25%, val_best:  82.08%: 100%|██████████| 62/62 [00:06<00:00,  9.78it/s]\n",
      "epoch-50  lr=['0.0006699'], tr/val_loss:  0.001971/  1.644782, tr: 100.00%, val:  81.25%, val_best:  82.08%: 100%|██████████| 62/62 [00:06<00:00, 10.07it/s]\n",
      "epoch-51  lr=['0.0005450'], tr/val_loss:  0.001924/  1.651293, tr: 100.00%, val:  80.83%, val_best:  82.08%: 100%|██████████| 62/62 [00:06<00:00,  9.63it/s]\n",
      "epoch-52  lr=['0.0004323'], tr/val_loss:  0.001898/  1.653190, tr: 100.00%, val:  81.25%, val_best:  82.08%: 100%|██████████| 62/62 [00:06<00:00,  9.27it/s]\n",
      "epoch-53  lr=['0.0003321'], tr/val_loss:  0.001889/  1.653373, tr: 100.00%, val:  81.25%, val_best:  82.08%: 100%|██████████| 62/62 [00:05<00:00, 10.61it/s]\n",
      "epoch-54  lr=['0.0002447'], tr/val_loss:  0.001868/  1.653852, tr: 100.00%, val:  81.25%, val_best:  82.08%: 100%|██████████| 62/62 [00:05<00:00, 11.03it/s]\n",
      "epoch-55  lr=['0.0001704'], tr/val_loss:  0.001841/  1.653887, tr: 100.00%, val:  81.25%, val_best:  82.08%: 100%|██████████| 62/62 [00:05<00:00, 10.85it/s]\n",
      "epoch-56  lr=['0.0001093'], tr/val_loss:  0.001851/  1.653423, tr: 100.00%, val:  81.25%, val_best:  82.08%: 100%|██████████| 62/62 [00:05<00:00, 10.68it/s]\n",
      "epoch-57  lr=['0.0000616'], tr/val_loss:  0.001854/  1.655004, tr: 100.00%, val:  81.25%, val_best:  82.08%: 100%|██████████| 62/62 [00:06<00:00, 10.10it/s]\n",
      "epoch-58  lr=['0.0000274'], tr/val_loss:  0.001832/  1.655134, tr: 100.00%, val:  81.25%, val_best:  82.08%: 100%|██████████| 62/62 [00:05<00:00, 10.92it/s]\n",
      "epoch-59  lr=['0.0000069'], tr/val_loss:  0.001824/  1.655140, tr: 100.00%, val:  81.25%, val_best:  82.08%: 100%|██████████| 62/62 [00:05<00:00, 10.58it/s]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f0320ff654d840c28a664b0b98347748",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='3.438 MB of 3.438 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>DFA_flag</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>epoch</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇████</td></tr><tr><td>iter_acc</td><td>▁▁▄▆▆▄▅▆▆▆▆▆▇███████████████████████████</td></tr><tr><td>summary_val_acc</td><td>▁▅▆▆▆▆▇▇▇▇▇▇▇▇███▇██████████████████████</td></tr><tr><td>tr_acc</td><td>▁▃▅▆▆▆▆▆▇▇▇▇████████████████████████████</td></tr><tr><td>tr_epoch_loss</td><td>▁█▅▄▄▄▄▃▃▃▃▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_acc_best</td><td>▁▅▆▆▇▇▇▇▇▇▇▇▇▇██████████████████████████</td></tr><tr><td>val_acc_now</td><td>▁▅▆▆▆▆▇▇▇▇▇▇▇▇███▇██████████████████████</td></tr><tr><td>val_loss</td><td>▁▇▆▆▇▆▆▇▇▆▆▇▆▇▇▇▇▇▇▇████████████████████</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>DFA_flag</td><td>0.0</td></tr><tr><td>epoch</td><td>59</td></tr><tr><td>iter_acc</td><td>1.0</td></tr><tr><td>tr_acc</td><td>1.0</td></tr><tr><td>tr_epoch_loss</td><td>0.00182</td></tr><tr><td>val_acc_best</td><td>0.82083</td></tr><tr><td>val_acc_now</td><td>0.8125</td></tr><tr><td>val_loss</td><td>1.65514</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">unique-sweep-58</strong> at: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/1qd4kp8d' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/1qd4kp8d</a><br/> View project at: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main</a><br/>Synced 7 W&B file(s), 0 media file(s), 0 artifact file(s) and 1 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20240822_194939-1qd4kp8d/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require(\"core\")`! See https://wandb.me/wandb-core for more information."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: u1w8f3nr with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBATCH: 16\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tDFA_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tIMAGE_SIZE: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tOTTT_input_trace_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tOTTT_sWS_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tTIME: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcfg: ['M', 'M', 200, 200]\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tconst2: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdecay: 0.25\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdrop_rate: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdvs_clipping: 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdvs_duration: 100000\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \te_transport_swap: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \te_transport_swap_coin: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \te_transport_swap_tr: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepoch_num: 60\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \texclude_class: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.01\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_sg_width: 2.570969004857107\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_reset: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_threshold: 2.065307191934283\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmerge_polarities: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tscheduler_name: CosineAnnealingLR\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsurrogate: hard_sigmoid\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \twhich_data: DVS_GESTURE_TONIC\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ff546090ef13490885c036d2ee3bceeb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.011113137586249246, max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.17.7 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.17.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/nfs/home/bhkim003/github_folder/ByeonghyeonKim/my_snn/wandb/run-20240822_195601-u1w8f3nr</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/u1w8f3nr' target=\"_blank\">confused-sweep-60</a></strong> to <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/yxynyr6h' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/yxynyr6h</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/yxynyr6h' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/yxynyr6h</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/u1w8f3nr' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/u1w8f3nr</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BATCH' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'IMAGE_SIZE' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'which_data' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_threshold' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_reset' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_sg_width' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'cfg' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'learning_rate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'epoch_num' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'surrogate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'scheduler_name' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'dvs_clipping' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'dvs_duration' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'OTTT_sWS_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'DFA_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'OTTT_input_trace_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'e_transport_swap' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'e_transport_swap_tr' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'e_transport_swap_coin' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'drop_rate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'exclude_class' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'merge_polarities' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'TIME' was locked by 'sweep' (ignored update).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset_hash = 2bbd58b4e0d3c1e9ad501fad8a43feed\n",
      "cache path exists\n",
      "\n",
      "we will exclude the 'other' class. dvsgestrue 10 classes' indices exist. \n",
      "\n",
      "DataParallel(\n",
      "  (module): MY_SNN_FC_sstep(\n",
      "    (layers): MY_Sequential(\n",
      "      (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (2): DimChanger_for_FC_sstep()\n",
      "      (3): SYNAPSE_FC_trace_sstep()\n",
      "      (4): LIF_layer_trace_sstep()\n",
      "      (5): SYNAPSE_FC_trace_sstep()\n",
      "      (6): LIF_layer_trace_sstep()\n",
      "      (7): SYNAPSE_FC_trace_sstep()\n",
      "    )\n",
      "  )\n",
      ")\n",
      "==================================================\n",
      "My Num of PARAMS: 452,010, system's param_num : 452,010\n",
      "Memory: 1.72MiB at 32-bit\n",
      "==================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch-0   lr=['0.0100000'], tr/val_loss:  2.317507/  2.316367, tr:   9.70%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:07<00:00,  8.77it/s]\n",
      "epoch-1   lr=['0.0099931'], tr/val_loss:  2.316254/  2.314931, tr:  10.21%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:06<00:00,  9.46it/s]\n",
      "epoch-2   lr=['0.0099726'], tr/val_loss:  2.315321/  2.315877, tr:   9.81%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:06<00:00, 10.10it/s]\n",
      "epoch-3   lr=['0.0099384'], tr/val_loss:  2.319123/  2.321801, tr:  10.42%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:06<00:00,  9.84it/s]\n",
      "epoch-4   lr=['0.0098907'], tr/val_loss:  2.328817/  2.310750, tr:   7.66%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:16<00:00,  3.72it/s]\n",
      "epoch-5   lr=['0.0098296'], tr/val_loss:  2.318780/  2.313111, tr:   8.58%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:30<00:00,  2.06it/s]\n",
      "epoch-6   lr=['0.0097553'], tr/val_loss:  2.326567/  2.312034, tr:   8.89%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:16<00:00,  3.78it/s]\n",
      "epoch-7   lr=['0.0096679'], tr/val_loss:  2.319906/  2.308871, tr:   8.89%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:12<00:00,  4.90it/s]\n",
      "epoch-8   lr=['0.0095677'], tr/val_loss:  2.315703/  2.318316, tr:   9.09%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:05<00:00, 10.64it/s]\n",
      "epoch-9   lr=['0.0094550'], tr/val_loss:  2.315776/  2.321137, tr:   9.81%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:06<00:00, 10.09it/s]\n",
      "epoch-10  lr=['0.0093301'], tr/val_loss:  2.319218/  2.310921, tr:   9.40%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:06<00:00,  9.30it/s]\n",
      "epoch-11  lr=['0.0091934'], tr/val_loss:  2.320658/  2.318817, tr:   9.60%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:06<00:00,  9.51it/s]\n",
      "epoch-12  lr=['0.0090451'], tr/val_loss:  2.323760/  2.306959, tr:   9.70%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:05<00:00, 10.67it/s]\n",
      "epoch-13  lr=['0.0088857'], tr/val_loss:  2.312257/  2.313825, tr:   8.78%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:07<00:00,  8.81it/s]\n",
      "epoch-14  lr=['0.0087157'], tr/val_loss:  2.321870/  2.310401, tr:   9.70%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:16<00:00,  3.69it/s]\n",
      "epoch-15  lr=['0.0085355'], tr/val_loss:  2.318407/  2.313874, tr:   9.60%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:20<00:00,  3.07it/s]\n",
      "epoch-16  lr=['0.0083457'], tr/val_loss:  2.317499/  2.312321, tr:  10.11%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:17<00:00,  3.61it/s]\n",
      "epoch-17  lr=['0.0081466'], tr/val_loss:  2.318669/  2.307941, tr:   8.89%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:16<00:00,  3.74it/s]\n",
      "epoch-18  lr=['0.0079389'], tr/val_loss:  2.325135/  2.306585, tr:   7.46%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:18<00:00,  3.27it/s]\n",
      "epoch-19  lr=['0.0077232'], tr/val_loss:  2.314244/  2.310251, tr:  10.01%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:21<00:00,  2.83it/s]\n",
      "epoch-20  lr=['0.0075000'], tr/val_loss:  2.312182/  2.307967, tr:   9.91%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:20<00:00,  3.09it/s]\n",
      "epoch-21  lr=['0.0072700'], tr/val_loss:  2.318818/  2.307295, tr:   9.30%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:16<00:00,  3.71it/s]\n",
      "epoch-22  lr=['0.0070337'], tr/val_loss:  2.313441/  2.307399, tr:   9.91%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:20<00:00,  3.06it/s]\n",
      "epoch-23  lr=['0.0067918'], tr/val_loss:  2.314248/  2.309416, tr:   7.76%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:18<00:00,  3.32it/s]\n",
      "epoch-24  lr=['0.0065451'], tr/val_loss:  2.318841/  2.305136, tr:   9.09%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:20<00:00,  3.04it/s]\n",
      "epoch-25  lr=['0.0062941'], tr/val_loss:  2.316903/  2.306750, tr:   7.97%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:17<00:00,  3.61it/s]\n",
      "epoch-26  lr=['0.0060396'], tr/val_loss:  2.311055/  2.305107, tr:   8.99%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:14<00:00,  4.23it/s]\n",
      "epoch-27  lr=['0.0057822'], tr/val_loss:  2.313828/  2.306802, tr:   8.58%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:16<00:00,  3.69it/s]\n",
      "epoch-28  lr=['0.0055226'], tr/val_loss:  2.315332/  2.308450, tr:   8.68%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:21<00:00,  2.86it/s]\n",
      "epoch-29  lr=['0.0052617'], tr/val_loss:  2.315842/  2.306032, tr:   7.15%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:20<00:00,  2.98it/s]\n",
      "epoch-30  lr=['0.0050000'], tr/val_loss:  2.312570/  2.303939, tr:   8.89%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:18<00:00,  3.32it/s]\n",
      "epoch-31  lr=['0.0047383'], tr/val_loss:  2.309263/  2.303903, tr:   9.09%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:16<00:00,  3.87it/s]\n",
      "epoch-32  lr=['0.0044774'], tr/val_loss:  2.311847/  2.302894, tr:   8.38%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:20<00:00,  3.01it/s]\n",
      "epoch-33  lr=['0.0042178'], tr/val_loss:  2.308722/  2.303530, tr:   9.50%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:15<00:00,  4.11it/s]\n",
      "epoch-34  lr=['0.0039604'], tr/val_loss:  2.313000/  2.304187, tr:   8.48%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:15<00:00,  3.99it/s]\n",
      "epoch-35  lr=['0.0037059'], tr/val_loss:  2.309877/  2.303538, tr:   9.09%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:18<00:00,  3.32it/s]\n",
      "epoch-36  lr=['0.0034549'], tr/val_loss:  2.309406/  2.303601, tr:   8.99%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:17<00:00,  3.48it/s]\n",
      "epoch-37  lr=['0.0032082'], tr/val_loss:  2.309686/  2.303400, tr:   7.66%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:17<00:00,  3.54it/s]\n",
      "epoch-38  lr=['0.0029663'], tr/val_loss:  2.308588/  2.303166, tr:   9.09%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:16<00:00,  3.80it/s]\n",
      "epoch-39  lr=['0.0027300'], tr/val_loss:  2.308727/  2.302884, tr:   8.89%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:18<00:00,  3.37it/s]\n",
      "epoch-40  lr=['0.0025000'], tr/val_loss:  2.308749/  2.302732, tr:   9.40%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:16<00:00,  3.71it/s]\n",
      "epoch-41  lr=['0.0022768'], tr/val_loss:  2.306803/  2.302942, tr:   9.19%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:19<00:00,  3.13it/s]\n",
      "epoch-42  lr=['0.0020611'], tr/val_loss:  2.306347/  2.302762, tr:   8.68%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:16<00:00,  3.71it/s]\n",
      "epoch-43  lr=['0.0018534'], tr/val_loss:  2.305991/  2.302857, tr:   8.99%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:17<00:00,  3.47it/s]\n",
      "epoch-44  lr=['0.0016543'], tr/val_loss:  2.305293/  2.302853, tr:  10.01%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:16<00:00,  3.82it/s]\n",
      "epoch-45  lr=['0.0014645'], tr/val_loss:  2.306396/  2.302847, tr:   8.48%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:16<00:00,  3.65it/s]\n",
      "epoch-46  lr=['0.0012843'], tr/val_loss:  2.305307/  2.302670, tr:  10.01%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:13<00:00,  4.67it/s]\n",
      "epoch-47  lr=['0.0011143'], tr/val_loss:  2.305197/  2.302644, tr:   9.30%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:05<00:00, 10.71it/s]\n",
      "epoch-48  iter_acc:  12.50%, lr=['0.0009549'], iter_loss:  2.302864, val_best:  10.00%:  98%|█████████▊| 61/62 [00:04<00:00, 13.06it/s]"
     ]
    }
   ],
   "source": [
    "# sweep 하는 코드, 위 셀 주석처리 해야 됨.\n",
    "\n",
    "# 이런 워닝 뜨는 거는 걍 너가 main 안에서  wandb.config.update(hyperparameters)할 때 물려서임. 어차피 근데 sweep에서 지정한 걸로 덮어짐 \n",
    "# wandb: WARNING Config item 'BATCH' was locked by 'sweep' (ignored update).\n",
    "\n",
    "unique_name_hyper = 'main'\n",
    "run_name = 'main'\n",
    "sweep_configuration = {\n",
    "    'method': 'bayes',\n",
    "    'name': f'my_snn_sweep{datetime.datetime.now().strftime(\"%Y%m%d_%H%M%S\")}',\n",
    "    'metric': {'goal': 'maximize', 'name': 'val_acc_best'},\n",
    "    'parameters': \n",
    "    {\n",
    "        \"learning_rate\": {\"values\": [0.01]}, #0.00936191669529645\n",
    "        \"BATCH\": {\"values\": [16]},\n",
    "        \"decay\": {\"values\": [0.25]},\n",
    "        \"IMAGE_SIZE\": {\"values\": [128]},\n",
    "        \"TIME\": {\"values\": [10]},\n",
    "        \"epoch_num\": {\"values\": [60]},\n",
    "        \"dvs_duration\": {\"values\": [100_000]},\n",
    "        \"dvs_clipping\": {\"values\": [2]},\n",
    "        \"which_data\": {\"values\": ['DVS_GESTURE_TONIC']},\n",
    "        \"OTTT_sWS_on\": {\"values\": [False]},\n",
    "        \"const2\": {\"values\": [False]},\n",
    "        \"surrogate\": {\"values\": ['hard_sigmoid']},\n",
    "        \"DFA_on\": {\"values\": [False]},\n",
    "        \"OTTT_input_trace_on\": {\"values\": [False]},\n",
    "        \"cfg\": {\"values\": [['M','M',200,200]]},\n",
    "        \"e_transport_swap\": {\"values\": [0]},\n",
    "        \"e_transport_swap_tr\": {\"values\": [0]},\n",
    "        \"drop_rate\": {\"values\": [0.0]}, # \"drop_rate\": {\"values\": [0.25,0.5,0.75]}, #\"drop_rate\": {\"min\": 0.25, \"max\": 0.75},\n",
    "        \"exclude_class\": {\"values\": [True]},\n",
    "        \"merge_polarities\": {\"values\": [False]},\n",
    "        \"lif_layer_v_reset\": {\"values\": [0]},\n",
    "        \"lif_layer_sg_width\": {\"values\": [2.570969004857107]},\n",
    "        \"e_transport_swap_coin\": {\"values\": [1]},\n",
    "        \"lif_layer_v_threshold\": {\"min\": 0.0, \"max\": 3.0},\n",
    "        \"scheduler_name\": {\"values\": ['CosineAnnealingLR']},  # 'no' 'StepLR' 'ExponentialLR' 'ReduceLROnPlateau' 'CosineAnnealingLR' 'OneCycleLR'\n",
    "     }\n",
    "}\n",
    "\n",
    "def hyper_iter():\n",
    "    ### my_snn control board ########################\n",
    "    unique_name = unique_name_hyper ## 이거 설정하면 새로운 경로에 모두 save\n",
    "    \n",
    "    wandb.init(save_code = True)\n",
    "    learning_rate  =  wandb.config.learning_rate\n",
    "    BATCH  =  wandb.config.BATCH\n",
    "    decay  =  wandb.config.decay\n",
    "    IMAGE_SIZE  =  wandb.config.IMAGE_SIZE\n",
    "    TIME  =  wandb.config.TIME\n",
    "    epoch_num  =  wandb.config.epoch_num \n",
    "    dvs_duration  =  wandb.config.dvs_duration\n",
    "    dvs_clipping  =  wandb.config.dvs_clipping\n",
    "    which_data  =  wandb.config.which_data\n",
    "    OTTT_sWS_on  =  wandb.config.OTTT_sWS_on\n",
    "    const2  =  wandb.config.const2\n",
    "    surrogate  =  wandb.config.surrogate\n",
    "    DFA_on  =  wandb.config.DFA_on\n",
    "    OTTT_input_trace_on  =  wandb.config.OTTT_input_trace_on\n",
    "    cfg  =  wandb.config.cfg\n",
    "    e_transport_swap  =  wandb.config.e_transport_swap\n",
    "    e_transport_swap_tr  =  wandb.config.e_transport_swap_tr\n",
    "    drop_rate  =  wandb.config.drop_rate\n",
    "    exclude_class  =  wandb.config.exclude_class\n",
    "    merge_polarities  =  wandb.config.merge_polarities\n",
    "    lif_layer_v_reset  =  wandb.config.lif_layer_v_reset\n",
    "    lif_layer_sg_width  =  wandb.config.lif_layer_sg_width\n",
    "    e_transport_swap_coin  =  wandb.config.e_transport_swap_coin\n",
    "    lif_layer_v_threshold  =  wandb.config.lif_layer_v_threshold\n",
    "    scheduler_name  =  wandb.config.scheduler_name\n",
    "    if const2 == True:\n",
    "        const2 = decay\n",
    "    else:\n",
    "        const2 = 0.0\n",
    "\n",
    "    my_snn_system(  devices = \"5\",\n",
    "                single_step = True, # True # False\n",
    "                unique_name = run_name,\n",
    "                my_seed = 42,\n",
    "                TIME = TIME , # dvscifar 10 # ottt 6 or 10 # nda 10  # 제작하는 dvs에서 TIME넘거나 적으면 자르거나 PADDING함\n",
    "                BATCH = BATCH, # batch norm 할거면 2이상으로 해야함   # nda 256   #  ottt 128\n",
    "                IMAGE_SIZE = IMAGE_SIZE, # dvscifar 48 # MNIST 28 # CIFAR10 32 # PMNIST 28 #NMNIST 34 # GESTURE 128\n",
    "                # dvsgesture 128, dvs_cifar2 128, nmnist 34, n_caltech101 180,240, n_tidigits 64, heidelberg 700, \n",
    "                #pmnist는 28로 해야 됨. 나머지는 바꿔도 돌아는 감.\n",
    "\n",
    "                # DVS_CIFAR10 할거면 time 10으로 해라\n",
    "                which_data = which_data,\n",
    "# 'CIFAR100' 'CIFAR10' 'MNIST' 'FASHION_MNIST' 'DVS_CIFAR10' 'PMNIST'아직\n",
    "# 'DVS_GESTURE', 'DVS_GESTURE_TONIC','DVS_CIFAR10_2','NMNIST','NMNIST_TONIC','N_CALTECH101','n_tidigits','heidelberg'\n",
    "                # CLASS_NUM = 10,\n",
    "                data_path = '/data2', # YOU NEED TO CHANGE THIS\n",
    "                rate_coding = False, # True # False\n",
    "                lif_layer_v_init = 0.0,\n",
    "                lif_layer_v_decay = decay,\n",
    "                lif_layer_v_threshold = lif_layer_v_threshold,  # 10000이상으로 하면 NDA LIF 씀. #nda 0.5  #ottt 1.0\n",
    "                lif_layer_v_reset = lif_layer_v_reset, # 10000이상은 hardreset (내 LIF쓰기는 함 ㅇㅇ)\n",
    "                lif_layer_sg_width = lif_layer_sg_width, # # surrogate sigmoid 쓸 때는 의미없음\n",
    "\n",
    "                # synapse_conv_in_channels = IMAGE_PIXEL_CHANNEL,\n",
    "                synapse_conv_kernel_size = 3,\n",
    "                synapse_conv_stride = 1,\n",
    "                synapse_conv_padding = 1,\n",
    "                synapse_conv_trace_const1 = 1, # 현재 trace구할 때 현재 spike에 곱해지는 상수. 걍 1로 두셈.\n",
    "                synapse_conv_trace_const2 = const2, # 현재 trace구할 때 직전 trace에 곱해지는 상수. lif_layer_v_decay와 같게 할 것을 추천\n",
    "\n",
    "                # synapse_fc_out_features = CLASS_NUM,\n",
    "                synapse_fc_trace_const1 = 1, # 현재 trace구할 때 현재 spike에 곱해지는 상수. 걍 1로 두셈.\n",
    "                synapse_fc_trace_const2 = const2, # 현재 trace구할 때 직전 trace에 곱해지는 상수. lif_layer_v_decay와 같게 할 것을 추천\n",
    "\n",
    "                pre_trained = False, # True # False\n",
    "                convTrue_fcFalse = False, # True # False\n",
    "\n",
    "                # 'P' for average pooling, 'D' for (1,1) aver pooling, 'M' for maxpooling, 'L' for linear classifier, [  ] for residual block\n",
    "                # conv에서 10000 이상은 depth-wise separable (BPTT만 지원), 20000이상은 depth-wise (BPTT만 지원)\n",
    "                # cfg = [64, 64],\n",
    "                # cfg = [64, 124, 64, 124],\n",
    "                # cfg = ['M','M',512], \n",
    "                # cfg = [512], \n",
    "                # cfg = ['M', 'M', 64, 128, 'P', 128, 'P'], \n",
    "                # cfg = ['M','M',200,200],\n",
    "                # cfg = [200,200],\n",
    "                cfg = cfg,\n",
    "                # cfg = [12], #fc\n",
    "                # cfg = [12, 'M', 48, 'M', 12], \n",
    "                # cfg = [64,[64,64],64], # 끝에 linear classifier 하나 자동으로 붙습니다\n",
    "                # cfg = [64, 128, 'P', 256, 256, 'P', 512, 512, 'P', 512, 512, 'D'], #ottt\n",
    "                # cfg = [64, 128, 'P', 256, 256, 'P', 512, 512, 'P', 512, 512], \n",
    "                # cfg = [64, 128, 'M', 256, 256, 'M', 512, 512, 'M', 512, 512], \n",
    "                # cfg = [64, 'P', 128, 'P', 256, 256, 'P', 512, 512, 512, 512, 'D'], # nda\n",
    "                # cfg = [64, 'P', 128, 'P', 256, 256, 'P', 512, 512, 512, 512], # nda 128pixel\n",
    "                # cfg = [64, 'P', 128, 'P', 256, 256, 'P', 512, 512, 512, 512, 'L', 4096, 4096],\n",
    "                # cfg = [20001,10001], # depthwise, separable\n",
    "                # cfg = [64,20064,10001], # vanilla conv, depthwise, separable\n",
    "                # cfg = [8, 'P', 8, 'P', 8, 'P', 8,'P', 8, 'P'],\n",
    "                # cfg = [], \n",
    "                \n",
    "                net_print = True, # True # False # True로 하길 추천\n",
    "                weight_count_print = False, # True # False\n",
    "                \n",
    "                pre_trained_path = f\"net_save/save_now_net_weights_{unique_name}.pth\",\n",
    "                learning_rate = learning_rate, # default 0.001  # ottt 0.1 # nda 0.001 \n",
    "                epoch_num = epoch_num,\n",
    "                verbose_interval = 999999999, #숫자 크게 하면 꺼짐 #걍 중간중간 iter에서 끊어서 출력\n",
    "                validation_interval =  999999999,#999999999, #숫자 크게 하면 에포크 마지막 iter 때 val 함\n",
    "\n",
    "                tdBN_on = False,  # True # False\n",
    "                BN_on = False,  # True # False\n",
    "                \n",
    "                surrogate = surrogate, # 'rectangle' 'sigmoid' 'rough_rectangle'\n",
    "                \n",
    "                gradient_verbose = False,  # True # False  # weight gradient 각 layer마다 띄워줌\n",
    "\n",
    "                BPTT_on = False,  # True # False # True이면 BPTT, False이면 OTTT  # depthwise, separable은 BPTT만 가능\n",
    "                optimizer_what = 'SGD', # 'SGD' 'Adam', 'RMSprop'\n",
    "                scheduler_name = scheduler_name, # 'no' 'StepLR' 'ExponentialLR' 'ReduceLROnPlateau' 'CosineAnnealingLR' 'OneCycleLR'\n",
    "                \n",
    "                ddp_on = False,   # True # False \n",
    "                # 지원 DATASET: cifar10, mnist\n",
    "\n",
    "                nda_net = False,   # True # False\n",
    "\n",
    "                domain_il_epoch = 0, # over 0, then domain il mode on # pmnist 쓸거면 HLOP 코드보고 더 디벨롭하셈. 지금 개발 hold함.\n",
    "                \n",
    "                dvs_clipping = dvs_clipping, # 숫자만큼 크면 spike 아니면 걍 0\n",
    "                # gesture, cifar-dvs2, nmnist, ncaltech101\n",
    "\n",
    "                dvs_duration = dvs_duration, # 0 아니면 time sampling # dvs number sampling OR time sampling # gesture, cifar-dvs2, nmnist, ncaltech101\n",
    "                # 있는 데이터들 #gesture 100_000 25_000 10_000 1_000 1_000_000 #nmnist 10000 #nmnist_tonic 10_000 25_000\n",
    "                # 한 숫자가 1us인듯 (spikingjelly코드에서)\n",
    "                # 한 장에 50 timestep만 생산함. 싫으면 my_snn/trying/spikingjelly_dvsgesture의__init__.py 를 참고해봐\n",
    "\n",
    "                OTTT_sWS_on = OTTT_sWS_on, # True # False # BPTT끄고, CONV에만 적용됨.\n",
    "\n",
    "                DFA_on = DFA_on, # True # False # residual은 dfa지원안함.\n",
    "                OTTT_input_trace_on = OTTT_input_trace_on, # True # False # 맨 처음 input에 trace 적용\n",
    "                 \n",
    "                e_transport_swap = e_transport_swap, # 1 이상이면 해당 숫자 에포크만큼 val_acc_best가 변화가 없으면 e_transport scheme (BP vs DFA) swap\n",
    "                e_transport_swap_tr = e_transport_swap_tr, # 1 이상이면 해당 숫자 에포크만큼 tr_acc_best가 변화가 없으면 e_transport scheme (BP vs DFA) swap\n",
    "                e_transport_swap_coin = e_transport_swap_coin, # swap할 수 있는 coin 개수\n",
    "                    \n",
    "                drop_rate = drop_rate,\n",
    "\n",
    "                exclude_class = exclude_class, # True # False # gesture에서 10번째 클래스 제외\n",
    "\n",
    "                merge_polarities = merge_polarities, # True # False # tonic dvs dataset 에서 polarities 합치기\n",
    "                    ) \n",
    "    # sigmoid와 BN이 있어야 잘된다.\n",
    "    # average pooling\n",
    "    # 이 낫다. \n",
    "    \n",
    "    # nda에서는 decay = 0.25, threshold = 0.5, width =1, surrogate = rectangle, batch = 256, tdBN = True\n",
    "    ## OTTT 에서는 decay = 0.5, threshold = 1.0, surrogate = sigmoid, batch = 128, BN = True\n",
    "\n",
    "sweep_id = wandb.sweep(sweep=sweep_configuration, project=f'my_snn {unique_name_hyper}')\n",
    "wandb.agent(sweep_id, function=hyper_iter, count=10000, project=f'my_snn {unique_name_hyper}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "# import matplotlib.pyplot as plt\n",
    "# import json\n",
    "# run_name = 'main_FINAL_TEST'\n",
    "\n",
    "# unique_name = run_name\n",
    "# def pad_array_to_match_length(array1, array2):\n",
    "#     if len(array1) > len(array2):\n",
    "#         padded_array2 = np.pad(array2, (0, len(array1) - len(array2)), 'constant')\n",
    "#         return array1, padded_array2\n",
    "#     elif len(array2) > len(array1):\n",
    "#         padded_array1 = np.pad(array1, (0, len(array2) - len(array1)), 'constant')\n",
    "#         return padded_array1, array2\n",
    "#     else:\n",
    "#         return array1, array2\n",
    "# def load_hyperparameters(filename=f'result_save/hyperparameters_{unique_name}.json'):\n",
    "#     with open(filename, 'r') as f:\n",
    "#         return json.load(f)\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# current_time = '20240628_110116'\n",
    "# base_name = f'{current_time}'\n",
    "# iter_acc_file_name = f'result_save/{base_name}_iter_acc_array_{unique_name}.npy'\n",
    "# val_acc_file_name = f'result_save/{base_name}_val_acc_now_array_{unique_name}.npy'\n",
    "# hyperparameters_file_name = f'result_save/{base_name}_hyperparameters_{unique_name}.json'\n",
    "\n",
    "# ### if you want to just see most recent train and val acc###########################\n",
    "# iter_acc_file_name = f'result_save/iter_acc_array_{unique_name}.npy'\n",
    "# tr_acc_file_name = f'result_save/tr_acc_array_{unique_name}.npy'\n",
    "# val_acc_file_name = f'result_save/val_acc_now_array_{unique_name}.npy'\n",
    "# hyperparameters_file_name = f'result_save/hyperparameters_{unique_name}.json'\n",
    "\n",
    "# loaded_iter_acc_array = np.load(iter_acc_file_name)*100\n",
    "# loaded_tr_acc_array = np.load(tr_acc_file_name)*100\n",
    "# loaded_val_acc_array = np.load(val_acc_file_name)*100\n",
    "# hyperparameters = load_hyperparameters(hyperparameters_file_name)\n",
    "\n",
    "# loaded_iter_acc_array, loaded_val_acc_array = pad_array_to_match_length(loaded_iter_acc_array, loaded_val_acc_array)\n",
    "# loaded_iter_acc_array, loaded_tr_acc_array = pad_array_to_match_length(loaded_iter_acc_array, loaded_tr_acc_array)\n",
    "# loaded_val_acc_array, loaded_tr_acc_array = pad_array_to_match_length(loaded_val_acc_array, loaded_tr_acc_array)\n",
    "\n",
    "# top_iter_acc = np.max(loaded_iter_acc_array)\n",
    "# top_tr_acc = np.max(loaded_tr_acc_array)\n",
    "# top_val_acc = np.max(loaded_val_acc_array)\n",
    "\n",
    "# which_data = hyperparameters['which_data']\n",
    "# BPTT_on = hyperparameters['BPTT_on']\n",
    "# current_epoch = hyperparameters['current epoch']\n",
    "# surrogate = hyperparameters['surrogate']\n",
    "# cfg = hyperparameters['cfg']\n",
    "# tdBN_on = hyperparameters['tdBN_on']\n",
    "# BN_on = hyperparameters['BN_on']\n",
    "\n",
    "\n",
    "# iterations = np.arange(len(loaded_iter_acc_array))\n",
    "\n",
    "# # 그래프 그리기\n",
    "# plt.figure(figsize=(10, 5))\n",
    "# plt.plot(iterations, loaded_iter_acc_array, label='Iter Accuracy', color='g', alpha=0.2)\n",
    "# plt.plot(iterations, loaded_tr_acc_array, label='Training Accuracy', color='b')\n",
    "# plt.plot(iterations, loaded_val_acc_array, label='Validation Accuracy', color='r')\n",
    "\n",
    "# # # 텍스트 추가\n",
    "# # plt.text(0.05, 0.95, f'Top Training Accuracy: {100*top_iter_acc:.2f}%', transform=plt.gca().transAxes, fontsize=12, verticalalignment='top', horizontalalignment='left', color='blue')\n",
    "# # plt.text(0.05, 0.90, f'Top Validation Accuracy: {100*top_val_acc:.2f}%', transform=plt.gca().transAxes, fontsize=12, verticalalignment='top', horizontalalignment='left', color='red')\n",
    "# # 텍스트 추가\n",
    "# plt.text(0.5, 0.10, f'Top Training Accuracy: {top_tr_acc:.2f}%', transform=plt.gca().transAxes, fontsize=12, verticalalignment='top', horizontalalignment='center', color='blue')\n",
    "# plt.text(0.5, 0.05, f'Top Validation Accuracy: {top_val_acc:.2f}%', transform=plt.gca().transAxes, fontsize=12, verticalalignment='top', horizontalalignment='center', color='red')\n",
    "\n",
    "# plt.xlabel('Iterations')\n",
    "# plt.ylabel('Accuracy [%]')\n",
    "\n",
    "# # 그래프 제목에 하이퍼파라미터 정보 추가\n",
    "# title = f'Training and Validation Accuracy over Iterations\\n\\nData: {which_data}, BPTT: {\"On\" if BPTT_on else \"Off\"}, Current Epoch: {current_epoch}, Surrogate: {surrogate},\\nCFG: {cfg}, tdBN: {\"On\" if tdBN_on else \"Off\"}, BN: {\"On\" if BN_on else \"Off\"}'\n",
    "\n",
    "# plt.title(title)\n",
    "\n",
    "# plt.legend(loc='lower right')\n",
    "# plt.xlim(0)  # x축을 0부터 시작\n",
    "# plt.grid(True)\n",
    "# plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nfs",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
