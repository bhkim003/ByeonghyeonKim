{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copyright (c) 2024 Byeonghyeon Kim \n",
    "# github site: https://github.com/bhkim003/ByeonghyeonKim\n",
    "# email: bhkim003@snu.ac.kr\n",
    " \n",
    "# Permission is hereby granted, free of charge, to any person obtaining a copy of\n",
    "# this software and associated documentation files (the \"Software\"), to deal in\n",
    "# the Software without restriction, including without limitation the rights to\n",
    "# use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of\n",
    "# the Software, and to permit persons to whom the Software is furnished to do so,\n",
    "# subject to the following conditions:\n",
    " \n",
    "# The above copyright notice and this permission notice shall be included in all\n",
    "# copies or substantial portions of the Software.\n",
    " \n",
    "# THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\n",
    "# IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS\n",
    "# FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR\n",
    "# COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER\n",
    "# IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN\n",
    "# CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_14918/3195203041.py:45: DeprecationWarning: The module snntorch.spikevision is deprecated. For loading neuromorphic datasets, we recommend using the Tonic project: https://github.com/neuromorphs/tonic\n",
      "  from snntorch.spikevision import spikedata\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.optim as optim\n",
    "import torch.optim.lr_scheduler as lr_scheduler\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "import torchvision\n",
    "import torchvision.datasets\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import time\n",
    "\n",
    "from snntorch import spikegen\n",
    "import matplotlib.pyplot as plt\n",
    "import snntorch.spikeplot as splt\n",
    "from IPython.display import HTML\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "from apex.parallel import DistributedDataParallel as DDP\n",
    "\n",
    "import random\n",
    "import datetime\n",
    "\n",
    "import json\n",
    "\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "''' 레퍼런스\n",
    "https://spikingjelly.readthedocs.io/zh-cn/0.0.0.0.4/spikingjelly.datasets.html#module-spikingjelly.datasets\n",
    "https://github.com/GorkaAbad/Sneaky-Spikes/blob/main/datasets.py\n",
    "https://github.com/GorkaAbad/Sneaky-Spikes/blob/main/how_to.md\n",
    "https://github.com/nmi-lab/torchneuromorphic\n",
    "https://snntorch.readthedocs.io/en/latest/snntorch.spikevision.spikedata.html#shd\n",
    "'''\n",
    "\n",
    "import snntorch\n",
    "from snntorch.spikevision import spikedata\n",
    "\n",
    "from spikingjelly.datasets.dvs128_gesture import DVS128Gesture\n",
    "from spikingjelly.datasets.cifar10_dvs import CIFAR10DVS\n",
    "from spikingjelly.datasets.n_mnist import NMNIST\n",
    "# from spikingjelly.datasets.es_imagenet import ESImageNet\n",
    "from spikingjelly.datasets import split_to_train_test_set\n",
    "from spikingjelly.datasets.n_caltech101 import NCaltech101\n",
    "from spikingjelly.datasets import pad_sequence_collate, padded_sequence_mask\n",
    "\n",
    "# import torchneuromorphic\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x600 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# my module import\n",
    "from modules import *\n",
    "\n",
    "# modules 폴더에 새모듈.py 만들면\n",
    "# modules/__init__py 파일에 form .새모듈 import * 하셈\n",
    "# 그리고 새모듈.py에서 from modules.새모듈 import * 하셈\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "\n",
    "import argparse\n",
    "import os\n",
    "import shutil\n",
    "import time\n",
    "import random\n",
    "import copy\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.parallel\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.optim as optim\n",
    "import torch.utils.data as data\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as datasets\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import PIL\n",
    "import time\n",
    "from pathlib import Path\n",
    "from PIL.Image import Image\n",
    "import math\n",
    "import torch.distributed as dist\n",
    "import collections\n",
    "from spikingjelly.activation_based import neuron, layer, functional\n",
    "from spikingjelly_codes.reference_codes import spiking_vggws_ottt as vggmodel\n",
    "from torchtoolbox.transform import Cutout\n",
    "from copy import deepcopy\n",
    "# /home/bhkim003/anaconda3/envs/aedat2_ottt/lib/python3.8/site-packages/spikingjelly-0.0.0.0.15-py3.8.egg/spikingjelly/activation_based/model\n",
    "import inspect\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_snn_system(devices = \"0,1,2,3\",\n",
    "                    unique_name = 'main',\n",
    "                    my_seed = 42,\n",
    "                    TIME = 10,\n",
    "                    BATCH = 256,\n",
    "                    IMAGE_SIZE = 32,\n",
    "                    which_data = 'CIFAR10',\n",
    "                    # CLASS_NUM = 10,\n",
    "                    data_path = '/data2',\n",
    "                    rate_coding = True,\n",
    "    \n",
    "                    lif_layer_v_init = 0.0,\n",
    "                    lif_layer_v_decay = 0.6,\n",
    "                    lif_layer_v_threshold = 1.2,\n",
    "                    lif_layer_v_reset = 0.0,\n",
    "                    lif_layer_sg_width = 1,\n",
    "\n",
    "                    # synapse_conv_in_channels = IMAGE_PIXEL_CHANNEL,\n",
    "                    synapse_conv_kernel_size = 3,\n",
    "                    synapse_conv_stride = 1,\n",
    "                    synapse_conv_padding = 1,\n",
    "                    synapse_conv_trace_const1 = 1,\n",
    "                    synapse_conv_trace_const2 = 0.6,\n",
    "\n",
    "                    # synapse_fc_out_features = CLASS_NUM,\n",
    "                    synapse_fc_trace_const1 = 1,\n",
    "                    synapse_fc_trace_const2 = 0.6,\n",
    "\n",
    "                    pre_trained = False,\n",
    "                    convTrue_fcFalse = True,\n",
    "                    cfg = [64, 64],\n",
    "                    net_print = False, # True # False\n",
    "                    weight_count_print = False, # True # False\n",
    "                    pre_trained_path = \"net_save/save_now_net.pth\",\n",
    "                    learning_rate = 0.0001,\n",
    "                    epoch_num = 200,\n",
    "                    verbose_interval = 100, #숫자 크게 하면 꺼짐\n",
    "                    validation_interval = 10, #숫자 크게 하면 꺼짐\n",
    "                    tdBN_on = False,\n",
    "                    BN_on = False,\n",
    "\n",
    "                    surrogate = 'sigmoid',\n",
    "\n",
    "                    gradient_verbose = False,\n",
    "\n",
    "                    BPTT_on = False,\n",
    "\n",
    "                    optimizer_what = 'SGD', # 'SGD' 'Adam', 'RMSprop'\n",
    "                    scheduler_name = 'no',\n",
    "                    \n",
    "                    ddp_on = True,\n",
    "\n",
    "                    nda_net = False,\n",
    "                    \n",
    "                    domain_il_epoch = 0, # over 0, then domain il mode on\n",
    "\n",
    "                    dvs_clipping = True, \n",
    "                    dvs_duration = 1000000,\n",
    "\n",
    "                    OTTT_sWS_on = True, # True # False\n",
    "                  ):\n",
    "    \n",
    "    if OTTT_sWS_on == True:\n",
    "        assert BPTT_on == False and tdBN_on == False and convTrue_fcFalse == True\n",
    "\n",
    "    # 함수 내 모든 로컬 변수 저장\n",
    "    hyperparameters = locals()\n",
    "    hyperparameters['current epoch'] = 0\n",
    "\n",
    "\n",
    "    ## gpu setting ##################################################################################################################\n",
    "    os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\" \n",
    "    os.environ[\"CUDA_VISIBLE_DEVICES\"]= devices\n",
    "    ###################################################################################################################################\n",
    "\n",
    "\n",
    "    ## seed setting ##################################################################################################################\n",
    "    torch.manual_seed(my_seed)\n",
    "    ###################################################################################################################################\n",
    "\n",
    "\n",
    "    ## data_loader 가져오기 ##################################################################################################################\n",
    "    # data loader, pixel channel, class num\n",
    "    train_loader, test_loader, synapse_conv_in_channels, CLASS_NUM = data_loader(\n",
    "            which_data,\n",
    "            data_path, \n",
    "            rate_coding, \n",
    "            BATCH, \n",
    "            IMAGE_SIZE,\n",
    "            ddp_on,\n",
    "            TIME,\n",
    "            dvs_clipping,\n",
    "            dvs_duration)\n",
    "    synapse_fc_out_features = CLASS_NUM\n",
    "    ###########################################################################################################################################\n",
    "\n",
    "    \n",
    "    ## parameter number calculator (안 중요함) ##################################################################################################################\n",
    "    params_num = 0\n",
    "    img_size = IMAGE_SIZE \n",
    "    bias_param = 1 # 1 or 0\n",
    "    classifier_making = False\n",
    "    if (convTrue_fcFalse == True):\n",
    "        past_kernel = synapse_conv_in_channels\n",
    "        for kernel in cfg:\n",
    "            if (classifier_making == False):\n",
    "                if (type(kernel) == list):\n",
    "                    for residual_kernel in kernel:\n",
    "                        if (residual_kernel >= 10000 and residual_kernel < 20000): # separable\n",
    "                            residual_kernel -= 10000\n",
    "                            params_num += (synapse_conv_kernel_size**2 + bias_param) * past_kernel\n",
    "                            params_num += (1**2 * past_kernel + bias_param) * residual_kernel\n",
    "                            past_kernel = residual_kernel  \n",
    "                        elif (residual_kernel >= 20000 and residual_kernel < 30000): # depthwise\n",
    "                            residual_kernel -= 20000\n",
    "                            # 'past_kernel' should be same with 'kernel'\n",
    "                            params_num += (synapse_conv_kernel_size**2 + bias_param) * past_kernel\n",
    "                            past_kernel = residual_kernel  \n",
    "                        else:\n",
    "                            params_num += residual_kernel * ((synapse_conv_kernel_size**2) * past_kernel + bias_param)\n",
    "                            past_kernel = residual_kernel\n",
    "                elif (kernel == 'P' or kernel == 'M'):\n",
    "                    img_size = img_size // 2\n",
    "                elif (kernel == 'D'):\n",
    "                    img_size = 1\n",
    "                elif (kernel == 'L'):\n",
    "                    classifier_making = True\n",
    "                    past_kernel = past_kernel * (img_size**2)\n",
    "                else:\n",
    "                    if (kernel >= 10000 and kernel < 20000): # separable\n",
    "                        kernel -= 10000\n",
    "                        params_num += (synapse_conv_kernel_size**2 + bias_param) * past_kernel\n",
    "                        params_num += (1**2 * past_kernel + bias_param) * kernel\n",
    "                        past_kernel = kernel  \n",
    "                    elif (kernel >= 20000 and kernel < 30000): # depthwise\n",
    "                        kernel -= 20000\n",
    "                        # 'past_kernel' should be same with 'kernel'\n",
    "                        params_num += (synapse_conv_kernel_size**2 + bias_param) * past_kernel\n",
    "                        past_kernel = kernel  \n",
    "                    else:\n",
    "                        params_num += kernel * (synapse_conv_kernel_size**2 * past_kernel + bias_param)\n",
    "                        past_kernel = kernel    \n",
    "            else: # classifier making\n",
    "                params_num += (past_kernel + bias_param) * kernel\n",
    "                past_kernel = kernel\n",
    "        \n",
    "        \n",
    "        if classifier_making == False:\n",
    "            past_kernel = past_kernel*img_size*img_size\n",
    "\n",
    "        params_num += (past_kernel + bias_param) * synapse_fc_out_features\n",
    "    else:\n",
    "        past_in_channel = synapse_conv_in_channels*img_size*img_size\n",
    "        for in_channel in cfg:\n",
    "            if (type(in_channel) == list):\n",
    "                for residual_in_channel in in_channel:\n",
    "                    params_num += (past_in_channel + bias_param) * residual_in_channel\n",
    "                    past_in_channel = residual_in_channel\n",
    "            # elif (in_channel == 'M'): #it's a holy FC layer!\n",
    "            #     img_size = img_size // 2\n",
    "            else:\n",
    "                print('past_in_channel', past_in_channel)\n",
    "                print('bias_param', bias_param)\n",
    "                print('in_channel', in_channel)\n",
    "                params_num += (past_in_channel + bias_param) * in_channel\n",
    "                past_in_channel = in_channel\n",
    "        params_num += (past_in_channel + bias_param) * synapse_fc_out_features\n",
    "    ###########################################################################################################################################\n",
    "\n",
    "\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "    ### network setting #######################################################################################################################\n",
    "    if pre_trained == False:\n",
    "        if (convTrue_fcFalse == False):\n",
    "            net = MY_SNN_FC(cfg, synapse_conv_in_channels, IMAGE_SIZE, synapse_fc_out_features,\n",
    "                     synapse_fc_trace_const1, synapse_fc_trace_const2, \n",
    "                     lif_layer_v_init, lif_layer_v_decay, \n",
    "                     lif_layer_v_threshold, lif_layer_v_reset,\n",
    "                     lif_layer_sg_width,\n",
    "                     tdBN_on,\n",
    "                     BN_on, TIME,\n",
    "                     surrogate,\n",
    "                     BPTT_on).to(device)\n",
    "        else:\n",
    "            net = MY_SNN_CONV(cfg, synapse_conv_in_channels, IMAGE_SIZE,\n",
    "                     synapse_conv_kernel_size, synapse_conv_stride, \n",
    "                     synapse_conv_padding, synapse_conv_trace_const1, \n",
    "                     synapse_conv_trace_const2, \n",
    "                     lif_layer_v_init, lif_layer_v_decay, \n",
    "                     lif_layer_v_threshold, lif_layer_v_reset,\n",
    "                     lif_layer_sg_width,\n",
    "                     synapse_fc_out_features, synapse_fc_trace_const1, synapse_fc_trace_const2,\n",
    "                     tdBN_on,\n",
    "                     BN_on, TIME,\n",
    "                     surrogate,\n",
    "                     BPTT_on,\n",
    "                     OTTT_sWS_on).to(device)\n",
    "        \n",
    "        if (nda_net == True):\n",
    "            net = VGG(cfg = cfg, num_classes=10, batch_norm = tdBN_on, in_c = synapse_conv_in_channels, \n",
    "                      lif_layer_v_threshold=lif_layer_v_threshold, lif_layer_v_decay=lif_layer_v_decay, lif_layer_sg_width=lif_layer_sg_width)\n",
    "            net.T = TIME\n",
    "        net = torch.nn.DataParallel(net)\n",
    "    else:\n",
    "        net = torch.load(pre_trained_path)\n",
    "\n",
    "    net = vggmodel.ottt_spiking_vggws(num_classes=10, spiking_neuron=neuron.OTTTLIFNode)\n",
    "    net = net.to(device)\n",
    "    if (net_print == True):\n",
    "        print(net)        \n",
    "    ####################################################################################################################################\n",
    "    \n",
    "\n",
    "    ## param num and memory estimation except BN with MY own calculation some lines above ##########################################\n",
    "    real_param_num = sum(p.numel() for p in net.parameters() if p.requires_grad)\n",
    "    if (weight_count_print == True):\n",
    "        for name, param in net.named_parameters():\n",
    "            if param.requires_grad:\n",
    "                print(f'Layer: {name} | Number of parameters: {param.numel()}')\n",
    "    # Batch norm 있으면 아래 두 개 서로 다를 수 있음.\n",
    "    # assert real_param_num == params_num, f'parameter number is not same. real_param_num: {real_param_num}, params_num: {params_num}'    \n",
    "    print('='*50)\n",
    "    print(f\"My Num of PARAMS: {params_num:,}, system's param_num : {real_param_num:,}\")\n",
    "    memory = params_num / 8 / 1024 / 1024 # MB\n",
    "    precision = 32\n",
    "    memory = memory * precision \n",
    "    print(f\"Memory: {memory:.2f}MiB at {precision}-bit\")\n",
    "    print('='*50)\n",
    "    ##############################################################################################################################\n",
    "\n",
    "\n",
    "\n",
    "    ## criterion ########################################## # loss 구해주는 친구\n",
    "    criterion = nn.CrossEntropyLoss().to(device)\n",
    "    if (OTTT_sWS_on == True):\n",
    "        # criterion = nn.CrossEntropyLoss().to(device)\n",
    "        criterion = lambda y_t, target_t: ((1 - 0.05) * F.cross_entropy(y_t, target_t) + 0.05 * F.mse_loss(y_t, F.one_hot(target_t, CLASS_NUM).float())) / TIME \n",
    "    ####################################################\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "    ## optimizer, scheduler ########################################################################\n",
    "    if(optimizer_what == 'SGD'):\n",
    "        # optimizer = optim.SGD(net.parameters(), lr=learning_rate, momentum=0.9)\n",
    "        optimizer = optim.SGD(net.parameters(), lr=learning_rate, momentum=0.9, weight_decay=0)\n",
    "    elif(optimizer_what == 'Adam'):\n",
    "        # optimizer = torch.optim.Adam(net.parameters(), lr=0.00001)\n",
    "        optimizer = torch.optim.Adam(net.parameters(), lr=learning_rate/256 * BATCH, weight_decay=1e-4)\n",
    "        # optimizer = optim.Adam(net.parameters(), lr=learning_rate, weight_decay=0, betas=(0.9, 0.999))\n",
    "    elif(optimizer_what == 'RMSprop'):\n",
    "        pass\n",
    "\n",
    "\n",
    "    if (scheduler_name == 'StepLR'):\n",
    "        scheduler = lr_scheduler.StepLR(optimizer, step_size=10, gamma=0.1)\n",
    "    elif (scheduler_name == 'ExponentialLR'):\n",
    "        scheduler = lr_scheduler.ExponentialLR(optimizer, gamma=0.95)\n",
    "    elif (scheduler_name == 'ReduceLROnPlateau'):\n",
    "        scheduler = lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.1, patience=10)\n",
    "    elif (scheduler_name == 'CosineAnnealingLR'):\n",
    "        # scheduler = lr_scheduler.CosineAnnealingLR(optimizer, eta_min=0, T_max=50)\n",
    "        scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, eta_min=0, T_max=epoch_num)\n",
    "    elif (scheduler_name == 'OneCycleLR'):\n",
    "        scheduler = lr_scheduler.OneCycleLR(optimizer, max_lr=0.1, steps_per_epoch=len(train_loader), epochs=100)\n",
    "    else:\n",
    "        pass # 'no' scheduler\n",
    "    ## optimizer, scheduler ########################################################################\n",
    "\n",
    "\n",
    "    tr_acc = 0\n",
    "    tr_correct = 0\n",
    "    tr_total = 0\n",
    "    val_acc = 0\n",
    "    val_acc_now = 0\n",
    "    elapsed_time_val = 0\n",
    "    iter_acc_array = np.array([])\n",
    "    tr_acc_array = np.array([])\n",
    "    val_acc_now_array = np.array([])\n",
    "    current_time = datetime.datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "    #======== EPOCH START ==========================================================================================\n",
    "    for epoch in range(epoch_num):\n",
    "        print('EPOCH', epoch)\n",
    "        epoch_start_time = time.time()\n",
    "        running_loss = 0.0\n",
    "\n",
    "        # if (domain_il_epoch>0 and which_data == 'PMNIST'):\n",
    "        #     k = epoch // domain_il_epoch\n",
    "        #     xtrain=data[k]['train']['x']\n",
    "        #     ytrain=data[k]['train']['y']\n",
    "        #     xtest =data[k]['test']['x']\n",
    "        #     ytest =data[k]['test']['y']\n",
    "\n",
    "        \n",
    "        ####### iterator : input_loading & tqdm을 통한 progress_bar 생성###################\n",
    "        iterator = enumerate(train_loader, 0)\n",
    "        if (ddp_on == True):\n",
    "            if torch.distributed.get_rank() == 0:   \n",
    "                iterator = tqdm(iterator, total=len(train_loader), desc='train', dynamic_ncols=True, position=0, leave=True)\n",
    "        else:\n",
    "            iterator = tqdm(iterator, total=len(train_loader), desc='train', dynamic_ncols=True, position=0, leave=True)\n",
    "        ##################################################################################   \n",
    "        \n",
    "        #### validation_interval이 batch size보다 작을 시 validation_interval을 batch size로 맞춰줌#############\n",
    "        validation_interval2 = validation_interval\n",
    "        if (validation_interval > len(iterator)):\n",
    "            validation_interval2 = len(iterator)\n",
    "        ##################################################################################################\n",
    "\n",
    "\n",
    "\n",
    "        ###### ITERATION START ##########################################################################################################\n",
    "        for i, data in iterator:\n",
    "            iter_one_train_time_start = time.time()\n",
    "            net.train() # train 모드로 바꿔줘야함\n",
    "\n",
    "            ### data loading & semi-pre-processing ################################################################################\n",
    "            if len(data) == 2:\n",
    "                inputs, labels = data\n",
    "                # 처리 로직 작성\n",
    "            elif len(data) == 3:\n",
    "                inputs, labels, x_len = data\n",
    "                # print('x_len',x_len)\n",
    "                # mask = padded_sequence_mask(x_len)\n",
    "                # max_time_step = x_len.max()\n",
    "                # min_time_step = x_len.min()\n",
    "            # print('inputs',inputs.size(),'\\nlabels',labels.size())\n",
    "                    \n",
    "            if (which_data == 'n_tidigits'):\n",
    "                inputs = inputs.permute(0, 1, 3, 2, 4)\n",
    "                labels = labels[:, 0, :]\n",
    "                labels = torch.argmax(labels, dim=1)\n",
    "            elif (which_data == 'heidelberg'):\n",
    "                inputs = inputs.view(5, 1000, 1, 700, 1)\n",
    "                print(\"\\n\\n\\n경고!!!! heidelberg 이거 타임스텝이랑 채널 잘 바꿔줘라!!!\\n\\n\\n\\n\")\n",
    "            # print('inputs',inputs.size(),'\\nlabels',labels.size())\n",
    "            # print(labels)\n",
    "                \n",
    "            if (which_data == 'DVS_CIFAR10' or which_data == 'DVS_GESTURE' or which_data == 'DVS_CIFAR10_2' or which_data == 'NMNIST' or which_data == 'N_CALTECH101' or which_data == 'n_tidigits' or which_data == 'heidelberg'):\n",
    "                inputs = inputs.permute(1, 0, 2, 3, 4)\n",
    "            elif rate_coding == True :\n",
    "                inputs = spikegen.rate(inputs, num_steps=TIME)\n",
    "            else :\n",
    "                inputs = inputs.repeat(TIME, 1, 1, 1, 1)\n",
    "            # inputs: [Time, Batch, Channel, Height, Width]  \n",
    "                \n",
    "            # # DVS에서 time duration으로 잘랐을 때는 timestep 맞춰주자 --> data 가져올 때, 그 함수 안에서 처리함.\n",
    "            # if (dvs_duration > 0): \n",
    "            #     # inputs.size(1)를 TIME으로 맞추기\n",
    "            #     T, *spatial_dims = inputs.shape\n",
    "            #     if T > TIME:\n",
    "            #         inputs = inputs[:TIME]\n",
    "            #     else:\n",
    "            #         inputs = torch.cat([inputs, torch.zeros(TIME - T, *spatial_dims)], dim=0)\n",
    "            # print('inputs',inputs.size(),'\\nlabels',labels.size())\n",
    "            ####################################################################################################################### \n",
    "                \n",
    "\n",
    "                \n",
    "            # # dvs 데이터 시각화 코드 (확인 필요할 시 써라)\n",
    "            # ##############################################################################################\n",
    "            # dvs_visualization(inputs, labels, TIME, BATCH)\n",
    "            # ######################################################################################################\n",
    "\n",
    "\n",
    "            ## device로 보내주기 ######################################\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "            ###########################################################\n",
    "\n",
    "\n",
    "            ## gradient 초기화 #######################################\n",
    "            optimizer.zero_grad()\n",
    "            ###########################################################\n",
    "\n",
    "\n",
    "            # net에 넣어줄때는 batch가 젤 앞 차원으로 와야함. # dataparallel때매##############################\n",
    "            # inputs: [Time, Batch, Channel, Height, Width]   \n",
    "            inputs = inputs.permute(1, 0, 2, 3, 4) # net에 넣어줄때는 batch가 젤 앞 차원으로 와야함. # dataparallel때매\n",
    "            # inputs: [Batch, Time, Channel, Height, Width] \n",
    "            #################################################################################################\n",
    "\n",
    "            y_all = []\n",
    "            if (inputs.size(0) == BATCH):\n",
    "                for t in range(TIME):\n",
    "                    ### input --> net --> output #####################################################\n",
    "                    outputs = net(inputs[:,t])\n",
    "                    ##################################################################################\n",
    "\n",
    "\n",
    "                    #### batch 어긋남 방지 ###############################################\n",
    "                    batch = BATCH \n",
    "                    if labels.size(0) != BATCH: \n",
    "                        batch = labels.size(0)\n",
    "                    #######################################################################\n",
    "                    \n",
    "\n",
    "\n",
    "                    ## loss, backward ##########################################\n",
    "                    loss = criterion(outputs[0:batch,:], labels)\n",
    "                    loss.backward()\n",
    "                    y_all.append(outputs.detach())\n",
    "                    ############################################################\n",
    "          \n",
    "                outputs = torch.stack(y_all, dim=0)\n",
    "                outputs = outputs.sum(axis=0)\n",
    "\n",
    "                ####### training accruacy save for print ###############################\n",
    "                _, predicted = torch.max(outputs.data, 1)\n",
    "                total = labels.size(0)\n",
    "                correct = (predicted == labels).sum().item()\n",
    "                tr_total += total\n",
    "                tr_correct += correct\n",
    "                iter_acc = correct / total\n",
    "                if i % verbose_interval == verbose_interval-1:\n",
    "                    print(f'{epoch}-{i} training acc: {100 * iter_acc:.2f}%, lr={[f\"{lr}\" for lr in (param_group[\"lr\"] for param_group in optimizer.param_groups)]}, val_acc: {100 * val_acc_now:.2f}%')\n",
    "                iter_acc_string = f'{epoch}-{i}/{len(train_loader)} iter_acc: {100 * iter_acc:.2f}%, lr={[f\"{lr}\" for lr in (param_group[\"lr\"] for param_group in optimizer.param_groups)]}'\n",
    "                ################################################################\n",
    "                    \n",
    "                ### gradinet verbose ##########################################\n",
    "                if (gradient_verbose == True):\n",
    "                    if (i % verbose_interval == verbose_interval-1):\n",
    "                        print('\\n\\nepoch', epoch, 'iter', i)\n",
    "                        for name, param in net.named_parameters():\n",
    "                            if param.requires_grad:\n",
    "                                print('\\n\\n\\n\\n' , name, param.grad)\n",
    "                ################################################################\n",
    "                \n",
    "\n",
    "                ## weight 업데이트!! ##################################\n",
    "                optimizer.step()\n",
    "                ################################################################\n",
    "\n",
    "\n",
    "                running_loss += loss.item()\n",
    "                # print(\"Epoch: {}, Iter: {}, Loss: {}\".format(epoch + 1, i + 1, running_loss / 100))\n",
    "\n",
    "                iter_one_train_time_end = time.time()\n",
    "                elapsed_time = iter_one_train_time_end - iter_one_train_time_start  # 실행 시간 계산\n",
    "\n",
    "                if (i % verbose_interval == verbose_interval-1):\n",
    "                    print(f\"iter_one_train_time: {elapsed_time} seconds, last one_val_time: {elapsed_time_val} seconds\\n\")\n",
    "\n",
    "                ##### validation ##################################################################################################################################\n",
    "            if i % validation_interval2 == validation_interval2-1:\n",
    "                iter_one_val_time_start = time.time()\n",
    "                tr_acc = tr_correct/tr_total\n",
    "                tr_correct = 0\n",
    "                tr_total = 0\n",
    "                correct = 0\n",
    "                total = 0\n",
    "                with torch.no_grad():\n",
    "                    net.eval() # eval 모드로 바꿔줘야함 \n",
    "                    for data in test_loader:\n",
    "                        ## data loading & semi-pre-processing ##########################################################\n",
    "                        if len(data) == 2:\n",
    "                            inputs, labels = data\n",
    "                            # 처리 로직 작성\n",
    "                        elif len(data) == 3:\n",
    "                            inputs, labels, x_len = data\n",
    "                            # print('x_len',x_len)\n",
    "                            # mask = padded_sequence_mask(x_len)\n",
    "                            # max_time_step = x_len.max()\n",
    "                            # min_time_step = x_len.min()\n",
    "                            # B, T, *spatial_dims = inputs.shape\n",
    "\n",
    "                        if (which_data == 'DVS_CIFAR10' or which_data == 'DVS_GESTURE' or which_data == 'DVS_CIFAR10_2' or which_data == 'NMNIST' or which_data == 'N_CALTECH101' or which_data == 'n_tidigits' or which_data == 'heidelberg'):\n",
    "                            inputs = inputs.permute(1, 0, 2, 3, 4)\n",
    "                        elif rate_coding == True :\n",
    "                            inputs = spikegen.rate(inputs, num_steps=TIME)\n",
    "                        else :\n",
    "                            inputs = inputs.repeat(TIME, 1, 1, 1, 1)\n",
    "                        # inputs: [Time, Batch, Channel, Height, Width]  \n",
    "                        ###################################################################################################\n",
    "\n",
    "                        inputs = inputs.to(device)\n",
    "                        labels = labels.to(device)\n",
    "\n",
    "                        if labels.size(0) == BATCH: \n",
    "                            y_all = []\n",
    "                            for t in range(TIME):\n",
    "                                y_t = net(inputs.permute(1, 0, 2, 3, 4)[:,t])\n",
    "                                y_all.append(y_t.detach())\n",
    "                            y_all = torch.stack(y_all, dim=0)\n",
    "                            outputs = y_all.sum(axis=0)\n",
    "\n",
    "                            _, predicted = torch.max(outputs.data, 1)\n",
    "                            total += labels.size(0)\n",
    "                            batch = BATCH \n",
    "                            if labels.size(0) != BATCH: \n",
    "                                batch = labels.size(0)\n",
    "                            correct += (predicted == labels).sum().item()\n",
    "                            val_loss = criterion(outputs[0:batch,:], labels)\n",
    "\n",
    "                    val_acc_now = correct / total\n",
    "                    # print(f'{epoch}-{i} validation acc: {100 * val_acc_now:.2f}%, lr={[f\"{lr:.10f}\" for lr in (param_group[\"lr\"] for param_group in optimizer.param_groups)]}')\n",
    "\n",
    "                iter_one_val_time_end = time.time()\n",
    "                elapsed_time_val = iter_one_val_time_end - iter_one_val_time_start  # 실행 시간 계산\n",
    "                # print(f\"iter_one_val_time: {elapsed_time_val} seconds\")\n",
    "\n",
    "                # network save\n",
    "                if val_acc < val_acc_now:\n",
    "                    val_acc = val_acc_now\n",
    "                    torch.save(net.state_dict(), f\"net_save/save_now_net_weights_{unique_name}.pth\")\n",
    "                    torch.save(net, f\"net_save/save_now_net_{unique_name}.pth\")\n",
    "                    # torch.save(net.module.state_dict(), f\"net_save/save_now_net_weights2_{unique_name}.pth\")\n",
    "                    # torch.save(net.module, f\"net_save/save_now_net2_{unique_name}.pth\")\n",
    "            ####################################################################################################################################################\n",
    "            iterator.set_description(f\"iter_acc: {iter_acc_string}, iter_loss: {loss}, val_acc: {100 * val_acc_now:.2f}%\")  \n",
    "\n",
    "            iter_acc_array = np.append(iter_acc_array, iter_acc)\n",
    "            tr_acc_array = np.append(tr_acc_array, tr_acc)\n",
    "            val_acc_now_array = np.append(val_acc_now_array, val_acc_now)\n",
    "            base_name = f'{current_time}'\n",
    "            iter_acc_file_name_time = f'result_save/{base_name}_iter_acc_array_{unique_name}.npy'\n",
    "            tr_acc_file_name_time = f'result_save/{base_name}_tr_acc_array_{unique_name}.npy'\n",
    "            val_acc_file_name_time = f'result_save/{base_name}_val_acc_now_array_{unique_name}.npy'\n",
    "            hyperparameters_file_name_time = f'result_save/{base_name}_hyperparameters_{unique_name}.json'\n",
    "\n",
    "            hyperparameters['current epoch'] = epoch\n",
    "\n",
    "            # # 덮어쓰기 하기 싫으면 주석 풀어서 사용 (시간마다 새로 쓰기)\n",
    "            # np.save(iter_acc_file_name_time, iter_acc_array)\n",
    "            # np.save(tr_acc_file_name_time, iter_acc_array)\n",
    "            # np.save(val_acc_file_name_time, val_acc_now_array)\n",
    "            # with open(hyperparameters_file_name_time, 'w') as f:\n",
    "            #     json.dump(hyperparameters, f, indent=4)\n",
    "\n",
    "            np.save(f'result_save/iter_acc_array_{unique_name}.npy', iter_acc_array)\n",
    "            np.save(f'result_save/tr_acc_array_{unique_name}.npy', tr_acc_array)\n",
    "            np.save(f'result_save/val_acc_now_array_{unique_name}.npy', val_acc_now_array)\n",
    "            with open(f'result_save/hyperparameters_{unique_name}.json', 'w') as f:\n",
    "                json.dump(hyperparameters, f, indent=4)\n",
    "    ###### ITERATION END ##########################################################################################################\n",
    "                \n",
    "\n",
    "        ## scheduler update #############################################################################\n",
    "        if (scheduler_name != 'no'):\n",
    "            if (scheduler_name == 'ReduceLROnPlateau'):\n",
    "                scheduler.step(val_loss)\n",
    "            else:\n",
    "                scheduler.step()\n",
    "        #################################################################################################\n",
    "        \n",
    "        # 실행 시간 계산\n",
    "        epoch_time_end = time.time()\n",
    "        print(f\"epoch_time: {epoch_time_end - epoch_start_time} seconds\\n\") \n",
    "        \n",
    "    #======== EPOCH END ==========================================================================================\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "cfg: [64, 128, 'A', 256, 256, 'A', 512, 512, 'A', 512, 512]\n",
      "weight_standardization: True\n",
      "num_classes: 10\n",
      "init_weights: True\n",
      "spiking_neuron: <class 'spikingjelly.activation_based.neuron.OTTTLIFNode'>\n",
      "light_classifier: True\n",
      "drop_rate: 0.0\n",
      "Contents of **kwargs: {}\n",
      "self.fc_hw: 1\n",
      "yes ws\n",
      "avepool\n",
      "avepool\n",
      "avepool\n",
      "OTTTSpikingVGG(\n",
      "  (features): OTTTSequential(\n",
      "    (0): WSConv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), step_mode=s)\n",
      "    (1): SIZE_CHECK_post_conv()\n",
      "    (2): OTTTLIFNode(\n",
      "      v_threshold=1.0, v_reset=None, detach_reset=True, step_mode=s, backend=torch, tau=2.0\n",
      "      (surrogate_function): Sigmoid(alpha=4.0, spiking=True)\n",
      "    )\n",
      "    (3): SIZE_CHECK_post_neuron()\n",
      "    (4): Scale()\n",
      "    (5): WSConv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), step_mode=s)\n",
      "    (6): SIZE_CHECK_post_conv()\n",
      "    (7): OTTTLIFNode(\n",
      "      v_threshold=1.0, v_reset=None, detach_reset=True, step_mode=s, backend=torch, tau=2.0\n",
      "      (surrogate_function): Sigmoid(alpha=4.0, spiking=True)\n",
      "    )\n",
      "    (8): SIZE_CHECK_post_neuron()\n",
      "    (9): Scale()\n",
      "    (10): AvgPool2d(kernel_size=2, stride=2, padding=0, step_mode=s)\n",
      "    (11): WSConv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), step_mode=s)\n",
      "    (12): SIZE_CHECK_post_conv()\n",
      "    (13): OTTTLIFNode(\n",
      "      v_threshold=1.0, v_reset=None, detach_reset=True, step_mode=s, backend=torch, tau=2.0\n",
      "      (surrogate_function): Sigmoid(alpha=4.0, spiking=True)\n",
      "    )\n",
      "    (14): SIZE_CHECK_post_neuron()\n",
      "    (15): Scale()\n",
      "    (16): WSConv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), step_mode=s)\n",
      "    (17): SIZE_CHECK_post_conv()\n",
      "    (18): OTTTLIFNode(\n",
      "      v_threshold=1.0, v_reset=None, detach_reset=True, step_mode=s, backend=torch, tau=2.0\n",
      "      (surrogate_function): Sigmoid(alpha=4.0, spiking=True)\n",
      "    )\n",
      "    (19): SIZE_CHECK_post_neuron()\n",
      "    (20): Scale()\n",
      "    (21): AvgPool2d(kernel_size=2, stride=2, padding=0, step_mode=s)\n",
      "    (22): WSConv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), step_mode=s)\n",
      "    (23): SIZE_CHECK_post_conv()\n",
      "    (24): OTTTLIFNode(\n",
      "      v_threshold=1.0, v_reset=None, detach_reset=True, step_mode=s, backend=torch, tau=2.0\n",
      "      (surrogate_function): Sigmoid(alpha=4.0, spiking=True)\n",
      "    )\n",
      "    (25): SIZE_CHECK_post_neuron()\n",
      "    (26): Scale()\n",
      "    (27): WSConv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), step_mode=s)\n",
      "    (28): SIZE_CHECK_post_conv()\n",
      "    (29): OTTTLIFNode(\n",
      "      v_threshold=1.0, v_reset=None, detach_reset=True, step_mode=s, backend=torch, tau=2.0\n",
      "      (surrogate_function): Sigmoid(alpha=4.0, spiking=True)\n",
      "    )\n",
      "    (30): SIZE_CHECK_post_neuron()\n",
      "    (31): Scale()\n",
      "    (32): AvgPool2d(kernel_size=2, stride=2, padding=0, step_mode=s)\n",
      "    (33): WSConv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), step_mode=s)\n",
      "    (34): SIZE_CHECK_post_conv()\n",
      "    (35): OTTTLIFNode(\n",
      "      v_threshold=1.0, v_reset=None, detach_reset=True, step_mode=s, backend=torch, tau=2.0\n",
      "      (surrogate_function): Sigmoid(alpha=4.0, spiking=True)\n",
      "    )\n",
      "    (36): SIZE_CHECK_post_neuron()\n",
      "    (37): Scale()\n",
      "    (38): WSConv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), step_mode=s)\n",
      "    (39): SIZE_CHECK_post_conv()\n",
      "    (40): OTTTLIFNode(\n",
      "      v_threshold=1.0, v_reset=None, detach_reset=True, step_mode=s, backend=torch, tau=2.0\n",
      "      (surrogate_function): Sigmoid(alpha=4.0, spiking=True)\n",
      "    )\n",
      "    (41): SIZE_CHECK_post_neuron()\n",
      "    (42): Scale()\n",
      "  )\n",
      "  (classifier): OTTTSequential(\n",
      "    (0): AdaptiveAvgPool2d(output_size=(1, 1), step_mode=s)\n",
      "    (1): Flatten(start_dim=1, end_dim=-1, step_mode=s)\n",
      "    (2): Linear(in_features=512, out_features=10, bias=True)\n",
      "  )\n",
      ")\n",
      "==================================================\n",
      "My Num of PARAMS: 9,225,610, system's param_num : 18,446,090\n",
      "Memory: 35.19MiB at 32-bit\n",
      "==================================================\n",
      "EPOCH 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "iter_acc: 0-132/391 iter_acc: 14.06%, lr=['0.1'], iter_loss: 0.3302217721939087, val_acc: 0.00%:  34%|███▍      | 133/391 [00:44<01:18,  3.27it/s] "
     ]
    }
   ],
   "source": [
    "### my_snn control board ########################\n",
    "decay = 0.5 # 0.875 0.25 0.125 0.75 0.5\n",
    "# nda 0.25 # ottt 0.5\n",
    "\n",
    "unique_name = 'main_ottt_conv' ## 이거 설정하면 새로운 경로에 모두 save\n",
    "\n",
    "my_snn_system(  devices = \"2,3\",\n",
    "                unique_name = unique_name,\n",
    "                my_seed = 42,\n",
    "                TIME = 6 , # dvscifar 10 # ottt 6 or 10 # nda 10  # 제작하는 dvs에서 TIME넘거나 적으면 자르거나 PADDING함\n",
    "                BATCH = 128, # batch norm 할거면 2이상으로 해야함   # nda 256   #  ottt 128\n",
    "                IMAGE_SIZE = 32, # dvscifar 48 # MNIST 28 # CIFAR10 32 # PMNIST 28\n",
    "                # dvsgesture 128, dvs_cifar2 128, nmnist 34, n_caltech101 180,240, n_tidigits 64, heidelberg 700, \n",
    "                #pmnist는 28로 해야 됨. 나머지는 바꿔도 돌아는 감.\n",
    "\n",
    "                # DVS_CIFAR10 할거면 time 10으로 해라\n",
    "                which_data = 'CIFAR10',\n",
    "# 'CIFAR100' 'CIFAR10' 'MNIST' 'FASHION_MNIST' 'DVS_CIFAR10' 'PMNIST'아직\n",
    "# 'DVS_GESTURE','DVS_CIFAR10_2','NMNIST','N_CALTECH101','n_tidigits','heidelberg'\n",
    "                # CLASS_NUM = 10,\n",
    "                data_path = '/data2', # YOU NEED TO CHANGE THIS\n",
    "                rate_coding = False, # True # False\n",
    "\n",
    "                lif_layer_v_init = 0.0,\n",
    "                lif_layer_v_decay = decay,\n",
    "                lif_layer_v_threshold = 1.0,  # 10000이상으로 하면 NDA LIF 씀. #nda 0.5  #ottt 1.0\n",
    "                lif_layer_v_reset = 0, # 10000이상은 hardreset (내 LIF쓰기는 함 ㅇㅇ)\n",
    "                lif_layer_sg_width = 1.0, # # surrogate sigmoid 쓸 때는 의미없음\n",
    "\n",
    "                # synapse_conv_in_channels = IMAGE_PIXEL_CHANNEL,\n",
    "                synapse_conv_kernel_size = 3,\n",
    "                synapse_conv_stride = 1,\n",
    "                synapse_conv_padding = 1,\n",
    "                synapse_conv_trace_const1 = 1,\n",
    "                synapse_conv_trace_const2 = decay, # lif_layer_v_decay\n",
    "\n",
    "                # synapse_fc_out_features = CLASS_NUM,\n",
    "                synapse_fc_trace_const1 = 1,\n",
    "                synapse_fc_trace_const2 = decay, # lif_layer_v_decay\n",
    "\n",
    "                pre_trained = False, # True # False\n",
    "                convTrue_fcFalse = True, # True # False\n",
    "\n",
    "                # 'P' for average pooling, 'D' for (1,1) aver pooling, 'M' for maxpooling, 'L' for linear classifier, [  ] for residual block\n",
    "                # conv에서 10000 이상은 depth-wise separable (BPTT만 지원), 20000이상은 depth-wise (BPTT만 지원)\n",
    "                # cfg = [64],\n",
    "                # cfg = [64,[64,64],64], # 끝에 linear classifier 하나 자동으로 붙습니다\n",
    "                cfg = [64, 128, 'P', 256, 256, 'P', 512, 512, 'P', 512, 512, 'D'], #ottt\n",
    "                # cfg = [64, 128, 'P', 256, 256, 'P', 512, 512, 'P', 512, 512], #ottt\n",
    "                # cfg = [64, 128, 'M', 256, 256, 'M', 512, 512, 'M', 512, 512], # ottt \n",
    "                # cfg = [64, 'P', 128, 'P', 256, 256, 'P', 512, 512, 512, 512, 'D'], # nda\n",
    "                # cfg = [64, 'P', 128, 'P', 256, 256, 'P', 512, 512, 512, 512], # nda 128pixel\n",
    "                # cfg = [64, 'P', 128, 'P', 256, 256, 'P', 512, 512, 512, 512, 'L', 4096, 4096],\n",
    "                # cfg = [20001,10001], # depthwise, separable\n",
    "                # cfg = [64,20064,10001], # vanilla conv, depthwise, separable\n",
    "                # cfg = [8, 'P', 8, 'P', 8, 'P', 8,'P', 8, 'P'],\n",
    "                # cfg = [], \n",
    "                \n",
    "                net_print = True, # True # False\n",
    "                weight_count_print = False, # True # False\n",
    "                \n",
    "                pre_trained_path = f\"net_save/save_now_net_{unique_name}.pth\",\n",
    "                learning_rate = 0.1, # default 0.001  # ottt 0.1 0.00001 # nda 0.001 \n",
    "                epoch_num = 300,\n",
    "                verbose_interval = 999999999, #숫자 크게 하면 꺼짐 #걍 중간중간 iter에서 끊어서 출력\n",
    "                validation_interval = 999999999, #숫자 크게 하면 에포크 마지막 iter 때 val 함\n",
    "\n",
    "                tdBN_on = False,  # True # False\n",
    "                BN_on = False,  # True # False\n",
    "                \n",
    "                surrogate = 'sigmoid', # 'rectangle' 'sigmoid' 'rough_rectangle'\n",
    "                \n",
    "                gradient_verbose = False,  # True # False  # weight gradient 각 layer마다 띄워줌\n",
    "\n",
    "                BPTT_on = False,  # True # False # True이면 BPTT, False이면 OTTT  # depthwise, separable은 BPTT만 가능\n",
    "                optimizer_what = 'SGD', # 'SGD' 'Adam', 'RMSprop'\n",
    "                scheduler_name = 'CosineAnnealingLR', # 'no' 'StepLR' 'ExponentialLR' 'ReduceLROnPlateau' 'CosineAnnealingLR' 'OneCycleLR'\n",
    "                \n",
    "                ddp_on = False,   # True # False\n",
    "\n",
    "                nda_net = False,   # True # False\n",
    "\n",
    "                domain_il_epoch = 0, # over 0, then domain il mode on # pmnist 쓸거면 HLOP 코드보고 더 디벨롭하셈. 지금 개발 hold함.\n",
    "                \n",
    "                dvs_clipping = True, # dvs zero&one  # gesture, cifar-dvs2, nmnist, ncaltech101\n",
    "                dvs_duration = 1000000, # 0 아니면 time sampling # dvs number sampling OR time sampling # gesture, cifar-dvs2, nmnist, ncaltech101\n",
    "                #있는 데이터들 #gesture 1000000 #nmnist 10000\n",
    "\n",
    "                OTTT_sWS_on = True, # True # False # BPTT끄고, CONV에만 적용됨.\n",
    "                \n",
    "                ) \n",
    "# sigmoid와 BN이 있어야 잘된다.\n",
    "# average pooling이 낫다. \n",
    "\n",
    "# nda에서는 decay = 0.25, threshold = 0.5, width =1, surrogate = rectangle, batch = 256, tdBN = True\n",
    "## OTTT 에서는 decay = 0.5, threshold = 1.0, surrogate = sigmoid, batch = 128, BN = True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "\n",
    "def pad_array_to_match_length(array1, array2):\n",
    "    if len(array1) > len(array2):\n",
    "        padded_array2 = np.pad(array2, (0, len(array1) - len(array2)), 'constant')\n",
    "        return array1, padded_array2\n",
    "    elif len(array2) > len(array1):\n",
    "        padded_array1 = np.pad(array1, (0, len(array2) - len(array1)), 'constant')\n",
    "        return padded_array1, array2\n",
    "    else:\n",
    "        return array1, array2\n",
    "def load_hyperparameters(filename=f'result_save/hyperparameters_{unique_name}.json'):\n",
    "    with open(filename, 'r') as f:\n",
    "        return json.load(f)\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "current_time = '20240628_110116'\n",
    "base_name = f'{current_time}'\n",
    "iter_acc_file_name = f'result_save/{base_name}_iter_acc_array_{unique_name}.npy'\n",
    "val_acc_file_name = f'result_save/{base_name}_val_acc_now_array_{unique_name}.npy'\n",
    "hyperparameters_file_name = f'result_save/{base_name}_hyperparameters_{unique_name}.json'\n",
    "\n",
    "### if you want to just see most recent train and val acc###########################\n",
    "iter_acc_file_name = f'result_save/iter_acc_array_{unique_name}.npy'\n",
    "tr_acc_file_name = f'result_save/tr_acc_array_{unique_name}.npy'\n",
    "val_acc_file_name = f'result_save/val_acc_now_array_{unique_name}.npy'\n",
    "hyperparameters_file_name = f'result_save/hyperparameters_{unique_name}.json'\n",
    "\n",
    "loaded_iter_acc_array = np.load(iter_acc_file_name)*100\n",
    "loaded_tr_acc_array = np.load(tr_acc_file_name)*100\n",
    "loaded_val_acc_array = np.load(val_acc_file_name)*100\n",
    "hyperparameters = load_hyperparameters(hyperparameters_file_name)\n",
    "\n",
    "loaded_iter_acc_array, loaded_val_acc_array = pad_array_to_match_length(loaded_iter_acc_array, loaded_val_acc_array)\n",
    "loaded_iter_acc_array, loaded_tr_acc_array = pad_array_to_match_length(loaded_iter_acc_array, loaded_tr_acc_array)\n",
    "loaded_val_acc_array, loaded_tr_acc_array = pad_array_to_match_length(loaded_val_acc_array, loaded_tr_acc_array)\n",
    "\n",
    "top_iter_acc = np.max(loaded_iter_acc_array)\n",
    "top_tr_acc = np.max(loaded_tr_acc_array)\n",
    "top_val_acc = np.max(loaded_val_acc_array)\n",
    "\n",
    "which_data = hyperparameters['which_data']\n",
    "BPTT_on = hyperparameters['BPTT_on']\n",
    "current_epoch = hyperparameters['current epoch']\n",
    "surrogate = hyperparameters['surrogate']\n",
    "cfg = hyperparameters['cfg']\n",
    "tdBN_on = hyperparameters['tdBN_on']\n",
    "BN_on = hyperparameters['BN_on']\n",
    "\n",
    "\n",
    "iterations = np.arange(len(loaded_iter_acc_array))\n",
    "\n",
    "# 그래프 그리기\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(iterations, loaded_iter_acc_array, label='Iter Accuracy', color='g', alpha=0.2)\n",
    "plt.plot(iterations, loaded_tr_acc_array, label='Training Accuracy', color='b')\n",
    "plt.plot(iterations, loaded_val_acc_array, label='Validation Accuracy', color='r')\n",
    "\n",
    "# # 텍스트 추가\n",
    "# plt.text(0.05, 0.95, f'Top Training Accuracy: {100*top_iter_acc:.2f}%', transform=plt.gca().transAxes, fontsize=12, verticalalignment='top', horizontalalignment='left', color='blue')\n",
    "# plt.text(0.05, 0.90, f'Top Validation Accuracy: {100*top_val_acc:.2f}%', transform=plt.gca().transAxes, fontsize=12, verticalalignment='top', horizontalalignment='left', color='red')\n",
    "# 텍스트 추가\n",
    "plt.text(0.5, 0.10, f'Top Training Accuracy: {top_tr_acc:.2f}%', transform=plt.gca().transAxes, fontsize=12, verticalalignment='top', horizontalalignment='center', color='blue')\n",
    "plt.text(0.5, 0.05, f'Top Validation Accuracy: {top_val_acc:.2f}%', transform=plt.gca().transAxes, fontsize=12, verticalalignment='top', horizontalalignment='center', color='red')\n",
    "\n",
    "plt.xlabel('Iterations')\n",
    "plt.ylabel('Accuracy [%]')\n",
    "\n",
    "# 그래프 제목에 하이퍼파라미터 정보 추가\n",
    "title = f'Training and Validation Accuracy over Iterations\\n\\nData: {which_data}, BPTT: {\"On\" if BPTT_on else \"Off\"}, Current Epoch: {current_epoch}, Surrogate: {surrogate},\\nCFG: {cfg}, tdBN: {\"On\" if tdBN_on else \"Off\"}, BN: {\"On\" if BN_on else \"Off\"}'\n",
    "\n",
    "plt.title(title)\n",
    "\n",
    "plt.legend(loc='lower right')\n",
    "plt.xlim(0)  # x축을 0부터 시작\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nfs",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
