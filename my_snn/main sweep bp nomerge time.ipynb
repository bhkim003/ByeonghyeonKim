{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copyright (c) 2024 Byeonghyeon Kim \n",
    "# github site: https://github.com/bhkim003/ByeonghyeonKim\n",
    "# email: bhkim003@snu.ac.kr\n",
    " \n",
    "# Permission is hereby granted, free of charge, to any person obtaining a copy of\n",
    "# this software and associated documentation files (the \"Software\"), to deal in\n",
    "# the Software without restriction, including without limitation the rights to\n",
    "# use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of\n",
    "# the Software, and to permit persons to whom the Software is furnished to do so,\n",
    "# subject to the following conditions:\n",
    " \n",
    "# The above copyright notice and this permission notice shall be included in all\n",
    "# copies or substantial portions of the Software.\n",
    " \n",
    "# THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\n",
    "# IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS\n",
    "# FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR\n",
    "# COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER\n",
    "# IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN\n",
    "# CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_31175/3914466541.py:46: DeprecationWarning: The module snntorch.spikevision is deprecated. For loading neuromorphic datasets, we recommend using the Tonic project: https://github.com/neuromorphs/tonic\n",
      "  from snntorch.spikevision import spikedata\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "import argparse\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.optim as optim\n",
    "import torch.optim.lr_scheduler as lr_scheduler\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "import torchvision\n",
    "import torchvision.datasets\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import time\n",
    "\n",
    "from snntorch import spikegen\n",
    "import matplotlib.pyplot as plt\n",
    "import snntorch.spikeplot as splt\n",
    "from IPython.display import HTML\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "from apex.parallel import DistributedDataParallel as DDP\n",
    "\n",
    "import random\n",
    "import datetime\n",
    "\n",
    "import json\n",
    "\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "''' 레퍼런스\n",
    "https://spikingjelly.readthedocs.io/zh-cn/0.0.0.0.4/spikingjelly.datasets.html#module-spikingjelly.datasets\n",
    "https://github.com/GorkaAbad/Sneaky-Spikes/blob/main/datasets.py\n",
    "https://github.com/GorkaAbad/Sneaky-Spikes/blob/main/how_to.md\n",
    "https://github.com/nmi-lab/torchneuromorphic\n",
    "https://snntorch.readthedocs.io/en/latest/snntorch.spikevision.spikedata.html#shd\n",
    "'''\n",
    "\n",
    "import snntorch\n",
    "from snntorch.spikevision import spikedata\n",
    "\n",
    "from spikingjelly.datasets.dvs128_gesture import DVS128Gesture\n",
    "from spikingjelly.datasets.cifar10_dvs import CIFAR10DVS\n",
    "from spikingjelly.datasets.n_mnist import NMNIST\n",
    "# from spikingjelly.datasets.es_imagenet import ESImageNet\n",
    "from spikingjelly.datasets import split_to_train_test_set\n",
    "from spikingjelly.datasets.n_caltech101 import NCaltech101\n",
    "from spikingjelly.datasets import pad_sequence_collate, padded_sequence_mask\n",
    "\n",
    "import torchneuromorphic\n",
    "\n",
    "import wandb\n",
    "\n",
    "from torchviz import make_dot\n",
    "import graphviz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x600 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# my module import\n",
    "from modules import *\n",
    "\n",
    "# modules 폴더에 새모듈.py 만들면\n",
    "# modules/__init__py 파일에 form .새모듈 import * 하셈\n",
    "# 그리고 새모듈.py에서 from modules.새모듈 import * 하셈\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_snn_system(devices = \"0,1,2,3\",\n",
    "                    single_step = False, # True # False\n",
    "                    unique_name = 'main',\n",
    "                    my_seed = 42,\n",
    "                    TIME = 10,\n",
    "                    BATCH = 256,\n",
    "                    IMAGE_SIZE = 32,\n",
    "                    which_data = 'CIFAR10',\n",
    "                    # CLASS_NUM = 10,\n",
    "                    data_path = '/data2',\n",
    "                    rate_coding = True,\n",
    "    \n",
    "                    lif_layer_v_init = 0.0,\n",
    "                    lif_layer_v_decay = 0.6,\n",
    "                    lif_layer_v_threshold = 1.2,\n",
    "                    lif_layer_v_reset = 0.0,\n",
    "                    lif_layer_sg_width = 1,\n",
    "\n",
    "                    # synapse_conv_in_channels = IMAGE_PIXEL_CHANNEL,\n",
    "                    synapse_conv_kernel_size = 3,\n",
    "                    synapse_conv_stride = 1,\n",
    "                    synapse_conv_padding = 1,\n",
    "                    synapse_conv_trace_const1 = 1,\n",
    "                    synapse_conv_trace_const2 = 0.6,\n",
    "\n",
    "                    # synapse_fc_out_features = CLASS_NUM,\n",
    "                    synapse_fc_trace_const1 = 1,\n",
    "                    synapse_fc_trace_const2 = 0.6,\n",
    "\n",
    "                    pre_trained = False,\n",
    "                    convTrue_fcFalse = True,\n",
    "                    cfg = [64, 64],\n",
    "                    net_print = False, # True # False\n",
    "                    weight_count_print = False, # True # False\n",
    "                    pre_trained_path = \"net_save/save_now_net.pth\",\n",
    "                    learning_rate = 0.0001,\n",
    "                    epoch_num = 200,\n",
    "                    verbose_interval = 100, #숫자 크게 하면 꺼짐\n",
    "                    validation_interval = 10, #숫자 크게 하면 꺼짐\n",
    "                    tdBN_on = False,\n",
    "                    BN_on = False,\n",
    "\n",
    "                    surrogate = 'sigmoid',\n",
    "\n",
    "                    gradient_verbose = False,\n",
    "\n",
    "                    BPTT_on = False,\n",
    "\n",
    "                    optimizer_what = 'SGD', # 'SGD' 'Adam', 'RMSprop'\n",
    "                    scheduler_name = 'no',\n",
    "                    \n",
    "                    ddp_on = True,\n",
    "\n",
    "                    nda_net = False,\n",
    "                    \n",
    "                    domain_il_epoch = 0, # over 0, then domain il mode on\n",
    "\n",
    "                    dvs_clipping = 1, \n",
    "                    dvs_duration = 10005,\n",
    "\n",
    "                    OTTT_sWS_on = True, # True # False\n",
    "\n",
    "                    DFA_on = False, # True # False\n",
    "                    OTTT_input_trace_on = False, # True # False\n",
    "                 \n",
    "                    e_transport_swap = 5, # 1 이상이면 해당 숫자 에포크만큼 val_acc_best가 변화가 없으면 e_transport scheme (BP vs DFA) swap\n",
    "                    e_transport_swap_tr = 0, # 1 이상이면 해당 숫자 에포크만큼 val_acc_best가 변화가 없으면 e_transport scheme (BP vs DFA) swap\n",
    "                    e_transport_swap_coin = 0, # swap할 수 있는 coin 개수\n",
    "\n",
    "                    drop_rate = 0.5, \n",
    "\n",
    "                    exclude_class = True, # True # False # gesture에서 10번째 클래스 제외\n",
    "\n",
    "                    merge_polarities = True, # True # False # tonic dvs dataset 에서 polarities 합치기\n",
    "                  ):\n",
    "    ## hyperparameter check #############################################################\n",
    "    if OTTT_sWS_on == True:\n",
    "        assert BPTT_on == False and tdBN_on == False and BN_on == False\n",
    "        if convTrue_fcFalse == False:\n",
    "            assert single_step == True\n",
    "    if single_step == True:\n",
    "        assert BPTT_on == False and tdBN_on == False \n",
    "    if tdBN_on == True:\n",
    "        assert BPTT_on == True\n",
    "    if pre_trained == True:\n",
    "        print('\\n\\n')\n",
    "        print(\"Caution! pre_trained is True\\n\\n\"*3)    \n",
    "    if DFA_on == True:\n",
    "        assert single_step == True and BPTT_on == False and any(isinstance(item, list) for item in cfg) == False\n",
    "    if OTTT_input_trace_on == True:\n",
    "        assert BPTT_on == False and single_step == True\n",
    "    ######################################################################################\n",
    "\n",
    "\n",
    "    ## 함수 내 모든 로컬 변수 저장 ########################################################\n",
    "    hyperparameters = locals()\n",
    "    hyperparameters['current epoch'] = 0\n",
    "    ######################################################################################\n",
    "    \n",
    "    args_gpu = None\n",
    "    ## DDP settting ######################################################################\n",
    "    if (ddp_on == True):\n",
    "        parser = argparse.ArgumentParser(description='my_snn CIFAR10 Training')\n",
    "\n",
    "        # # local_rank는 command line에서 따로 줄 필요는 없지만, 선언은 필요\n",
    "        parser.add_argument(\"--local_rank\", default=0, type=int)\n",
    "\n",
    "        args = parser.parse_args() # 이거 적어줘야됨. parser argument선언하고\n",
    "\n",
    "        args.gpu = args.local_rank\n",
    "        args_gpu = args.gpu\n",
    "        torch.cuda.set_device(args.gpu)\n",
    "        torch.distributed.init_process_group(backend=\"nccl\", init_method=\"env://\")\n",
    "        args.world_size = torch.distributed.get_world_size()\n",
    "    #######################################################################################\n",
    "\n",
    "\n",
    "    ## wandb 세팅 ###################################################################\n",
    "    current_time = datetime.datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "    if (ddp_on == True and torch.distributed.get_rank() != 0):\n",
    "        wandb.finish()\n",
    "    if (ddp_on == False or torch.distributed.get_rank() == 0):\n",
    "        wandb.config.update(hyperparameters)\n",
    "        wandb.run.name = f'lr_{learning_rate}_{unique_name}_{which_data}_tstep{TIME}'\n",
    "        wandb.define_metric(\"summary_val_acc\", summary=\"max\")\n",
    "        wandb.run.log_code(\".\", \n",
    "                           include_fn=lambda path: path.endswith(\".py\") or path.endswith(\".ipynb\"),\n",
    "                           exclude_fn=lambda path: 'logs/' in path or 'net_save/' in path or 'result_save/' in path or 'trying/' in path or 'wandb/' in path or 'private/' in path\n",
    "                           )\n",
    "    ###################################################################################\n",
    "\n",
    "\n",
    "\n",
    "    ## gpu setting ##################################################################################################################\n",
    "    os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\" \n",
    "    os.environ[\"CUDA_VISIBLE_DEVICES\"]= devices\n",
    "    ###################################################################################################################################\n",
    "\n",
    "\n",
    "    ## seed setting ##################################################################################################################\n",
    "    seed_assign(my_seed)\n",
    "    ###################################################################################################################################\n",
    "    \n",
    "\n",
    "    ## data_loader 가져오기 ##################################################################################################################\n",
    "    # data loader, pixel channel, class num\n",
    "    train_loader, test_loader, synapse_conv_in_channels, CLASS_NUM = data_loader(\n",
    "            which_data,\n",
    "            data_path, \n",
    "            rate_coding, \n",
    "            BATCH, \n",
    "            IMAGE_SIZE,\n",
    "            ddp_on,\n",
    "            TIME,\n",
    "            dvs_clipping,\n",
    "            dvs_duration,\n",
    "            exclude_class,\n",
    "            merge_polarities)\n",
    "    synapse_fc_out_features = CLASS_NUM\n",
    "    ###########################################################################################################################################\n",
    "\n",
    "    \n",
    "    ## parameter number calculator (안 중요함) ##################################################################################################################\n",
    "    params_num = 0\n",
    "    img_size = IMAGE_SIZE \n",
    "    bias_param = 1 # 1 or 0\n",
    "    classifier_making = False\n",
    "    if (convTrue_fcFalse == True):\n",
    "        past_kernel = synapse_conv_in_channels\n",
    "        for kernel in cfg:\n",
    "            if (classifier_making == False):\n",
    "                if (type(kernel) == list):\n",
    "                    for residual_kernel in kernel:\n",
    "                        if (residual_kernel >= 10000 and residual_kernel < 20000): # separable\n",
    "                            residual_kernel -= 10000\n",
    "                            params_num += (synapse_conv_kernel_size**2 + bias_param) * past_kernel\n",
    "                            params_num += (1**2 * past_kernel + bias_param) * residual_kernel\n",
    "                            past_kernel = residual_kernel  \n",
    "                        elif (residual_kernel >= 20000 and residual_kernel < 30000): # depthwise\n",
    "                            residual_kernel -= 20000\n",
    "                            # 'past_kernel' should be same with 'kernel'\n",
    "                            params_num += (synapse_conv_kernel_size**2 + bias_param) * past_kernel\n",
    "                            past_kernel = residual_kernel  \n",
    "                        else:\n",
    "                            params_num += residual_kernel * ((synapse_conv_kernel_size**2) * past_kernel + bias_param)\n",
    "                            past_kernel = residual_kernel\n",
    "                elif (kernel == 'P' or kernel == 'M'):\n",
    "                    img_size = img_size // 2\n",
    "                elif (kernel == 'D'):\n",
    "                    img_size = 1\n",
    "                elif (kernel == 'L'):\n",
    "                    classifier_making = True\n",
    "                    past_kernel = past_kernel * (img_size**2)\n",
    "                else:\n",
    "                    if (kernel >= 10000 and kernel < 20000): # separable\n",
    "                        kernel -= 10000\n",
    "                        params_num += (synapse_conv_kernel_size**2 + bias_param) * past_kernel\n",
    "                        params_num += (1**2 * past_kernel + bias_param) * kernel\n",
    "                        past_kernel = kernel  \n",
    "                    elif (kernel >= 20000 and kernel < 30000): # depthwise\n",
    "                        kernel -= 20000\n",
    "                        # 'past_kernel' should be same with 'kernel'\n",
    "                        params_num += (synapse_conv_kernel_size**2 + bias_param) * past_kernel\n",
    "                        past_kernel = kernel  \n",
    "                    else:\n",
    "                        params_num += kernel * (synapse_conv_kernel_size**2 * past_kernel + bias_param)\n",
    "                        past_kernel = kernel    \n",
    "            else: # classifier making\n",
    "                params_num += (past_kernel + bias_param) * kernel\n",
    "                past_kernel = kernel\n",
    "        \n",
    "        \n",
    "        if classifier_making == False:\n",
    "            past_kernel = past_kernel*img_size*img_size\n",
    "\n",
    "        params_num += (past_kernel + bias_param) * synapse_fc_out_features\n",
    "    else:\n",
    "        past_in_channel = synapse_conv_in_channels*img_size*img_size\n",
    "        for in_channel in cfg:\n",
    "            if (type(in_channel) == list):\n",
    "                for residual_in_channel in in_channel:\n",
    "                    params_num += (past_in_channel + bias_param) * residual_in_channel\n",
    "                    past_in_channel = residual_in_channel\n",
    "            elif (in_channel == 'P' or in_channel == 'M'):\n",
    "                img_size = img_size // 2\n",
    "                past_in_channel = synapse_conv_in_channels*img_size*img_size\n",
    "            else:\n",
    "                params_num += (past_in_channel + bias_param) * in_channel\n",
    "                past_in_channel = in_channel\n",
    "        params_num += (past_in_channel + bias_param) * synapse_fc_out_features\n",
    "    ###########################################################################################################################################\n",
    "\n",
    "\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "    ### network setting #######################################################################################################################\n",
    "    if (convTrue_fcFalse == False):\n",
    "        if (single_step == False):\n",
    "            net = MY_SNN_FC(cfg, synapse_conv_in_channels, IMAGE_SIZE, synapse_fc_out_features,\n",
    "                        synapse_fc_trace_const1, synapse_fc_trace_const2, \n",
    "                        lif_layer_v_init, lif_layer_v_decay, \n",
    "                        lif_layer_v_threshold, lif_layer_v_reset,\n",
    "                        lif_layer_sg_width,\n",
    "                        tdBN_on,\n",
    "                        BN_on, TIME,\n",
    "                        surrogate,\n",
    "                        BPTT_on,\n",
    "                        DFA_on,\n",
    "                        drop_rate).to(device)\n",
    "        else:\n",
    "            net = MY_SNN_FC_sstep(cfg, synapse_conv_in_channels, IMAGE_SIZE, synapse_fc_out_features,\n",
    "                        synapse_fc_trace_const1, synapse_fc_trace_const2, \n",
    "                        lif_layer_v_init, lif_layer_v_decay, \n",
    "                        lif_layer_v_threshold, lif_layer_v_reset,\n",
    "                        lif_layer_sg_width,\n",
    "                        tdBN_on,\n",
    "                        BN_on, TIME,\n",
    "                        surrogate,\n",
    "                        BPTT_on,\n",
    "                        DFA_on,\n",
    "                        OTTT_sWS_on,\n",
    "                        drop_rate).to(device)\n",
    "    else:\n",
    "        if (single_step == False):\n",
    "            net = MY_SNN_CONV(cfg, synapse_conv_in_channels, IMAGE_SIZE,\n",
    "                        synapse_conv_kernel_size, synapse_conv_stride, \n",
    "                        synapse_conv_padding, synapse_conv_trace_const1, \n",
    "                        synapse_conv_trace_const2, \n",
    "                        lif_layer_v_init, lif_layer_v_decay, \n",
    "                        lif_layer_v_threshold, lif_layer_v_reset,\n",
    "                        lif_layer_sg_width,\n",
    "                        synapse_fc_out_features, synapse_fc_trace_const1, synapse_fc_trace_const2,\n",
    "                        tdBN_on,\n",
    "                        BN_on, TIME,\n",
    "                        surrogate,\n",
    "                        BPTT_on,\n",
    "                        OTTT_sWS_on,\n",
    "                        DFA_on,\n",
    "                        drop_rate).to(device)\n",
    "        else:\n",
    "            net = MY_SNN_CONV_sstep(cfg, synapse_conv_in_channels, IMAGE_SIZE,\n",
    "                        synapse_conv_kernel_size, synapse_conv_stride, \n",
    "                        synapse_conv_padding, synapse_conv_trace_const1, \n",
    "                        synapse_conv_trace_const2, \n",
    "                        lif_layer_v_init, lif_layer_v_decay, \n",
    "                        lif_layer_v_threshold, lif_layer_v_reset,\n",
    "                        lif_layer_sg_width,\n",
    "                        synapse_fc_out_features, synapse_fc_trace_const1, synapse_fc_trace_const2,\n",
    "                        tdBN_on,\n",
    "                        BN_on, TIME,\n",
    "                        surrogate,\n",
    "                        BPTT_on,\n",
    "                        OTTT_sWS_on,\n",
    "                        DFA_on,\n",
    "                        drop_rate).to(device)\n",
    "    if (nda_net == True):\n",
    "        net = VGG(cfg = cfg, num_classes=10, batch_norm = tdBN_on, in_c = synapse_conv_in_channels, \n",
    "                    lif_layer_v_threshold=lif_layer_v_threshold, lif_layer_v_decay=lif_layer_v_decay, lif_layer_sg_width=lif_layer_sg_width)\n",
    "        net.T = TIME\n",
    "    if ddp_on == False:\n",
    "        net = torch.nn.DataParallel(net) \n",
    "    \n",
    "    if pre_trained == True:\n",
    "        net.load_state_dict(torch.load(pre_trained_path))\n",
    "    \n",
    "    if ddp_on == True:\n",
    "        device = args.gpu\n",
    "        net = net.to(args.gpu)\n",
    "        net = DDP(net, delay_allreduce=True)\n",
    "\n",
    "    net = net.to(device)\n",
    "    if (net_print == True):\n",
    "        if ddp_on == False or torch.distributed.get_rank() == 0:\n",
    "            print(net)    \n",
    "    ####################################################################################################################################\n",
    "    \n",
    "\n",
    "    ## wandb logging ###########################################\n",
    "    if ddp_on == False or torch.distributed.get_rank() == 0:\n",
    "        wandb.watch(net, log=\"all\", log_freq = 10) #gradient, parameter logging해줌\n",
    "    ############################################################\n",
    "\n",
    "    ## param num and memory estimation except BN with MY own calculation some lines above ##########################################\n",
    "    if ddp_on == False or torch.distributed.get_rank() == 0:\n",
    "        real_param_num = sum(p.numel() for p in net.parameters() if p.requires_grad)\n",
    "        if (weight_count_print == True):\n",
    "            for name, param in net.named_parameters():\n",
    "                if param.requires_grad:\n",
    "                    print(f'Layer: {name} | Number of parameters: {param.numel()}')\n",
    "        # Batch norm 있으면 아래 두 개 서로 다를 수 있음.\n",
    "        # assert real_param_num == params_num, f'parameter number is not same. real_param_num: {real_param_num}, params_num: {params_num}'    \n",
    "        print('='*50)\n",
    "        print(f\"My Num of PARAMS: {params_num:,}, system's param_num : {real_param_num:,}\")\n",
    "        memory = params_num / 8 / 1024 / 1024 # MB\n",
    "        precision = 32\n",
    "        memory = memory * precision \n",
    "        print(f\"Memory: {memory:.2f}MiB at {precision}-bit\")\n",
    "        print('='*50)\n",
    "    ##############################################################################################################################\n",
    "\n",
    "\n",
    "\n",
    "    ## criterion ########################################## # loss 구해주는 친구\n",
    "    criterion = nn.CrossEntropyLoss().to(device)\n",
    "    if (OTTT_sWS_on == True):\n",
    "        # criterion = nn.CrossEntropyLoss().to(device)\n",
    "        criterion = lambda y_t, target_t: ((1 - 0.05) * F.cross_entropy(y_t, target_t) + 0.05 * F.mse_loss(y_t, F.one_hot(target_t, CLASS_NUM).float())) / TIME \n",
    "        if which_data == 'DVS_GESTURE':\n",
    "            criterion = lambda y_t, target_t: ((1 - 0.001) * F.cross_entropy(y_t, target_t) + 0.001 * F.mse_loss(y_t, F.one_hot(target_t, CLASS_NUM).float())) / TIME \n",
    "    ####################################################\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "    ## optimizer, scheduler ########################################################################\n",
    "    if(optimizer_what == 'SGD'):\n",
    "        # optimizer = optim.SGD(net.parameters(), lr=learning_rate, momentum=0.9)\n",
    "        optimizer = optim.SGD(net.parameters(), lr=learning_rate, momentum=0.9, weight_decay=0)\n",
    "    elif(optimizer_what == 'Adam'):\n",
    "        optimizer = torch.optim.Adam(net.parameters(), lr=learning_rate)\n",
    "        # optimizer = torch.optim.Adam(net.parameters(), lr=0.00001)\n",
    "        # optimizer = torch.optim.Adam(net.parameters(), lr=learning_rate/256 * BATCH, weight_decay=1e-4)\n",
    "        # optimizer = optim.Adam(net.parameters(), lr=learning_rate, weight_decay=0, betas=(0.9, 0.999))\n",
    "    elif(optimizer_what == 'RMSprop'):\n",
    "        pass\n",
    "\n",
    "\n",
    "    if (scheduler_name == 'StepLR'):\n",
    "        scheduler = lr_scheduler.StepLR(optimizer, step_size=10, gamma=0.1)\n",
    "    elif (scheduler_name == 'ExponentialLR'):\n",
    "        scheduler = lr_scheduler.ExponentialLR(optimizer, gamma=0.95)\n",
    "    elif (scheduler_name == 'ReduceLROnPlateau'):\n",
    "        scheduler = lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.1, patience=10)\n",
    "    elif (scheduler_name == 'CosineAnnealingLR'):\n",
    "        # scheduler = lr_scheduler.CosineAnnealingLR(optimizer, eta_min=0, T_max=50)\n",
    "        scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, eta_min=0, T_max=epoch_num)\n",
    "    elif (scheduler_name == 'OneCycleLR'):\n",
    "        scheduler = lr_scheduler.OneCycleLR(optimizer, max_lr=0.1, steps_per_epoch=len(train_loader), epochs=epoch_num)\n",
    "    else:\n",
    "        pass # 'no' scheduler\n",
    "    ## optimizer, scheduler ########################################################################\n",
    "\n",
    "\n",
    "    tr_acc = 0\n",
    "    tr_correct = 0\n",
    "    tr_total = 0\n",
    "    tr_acc_best = 0\n",
    "    tr_epoch_loss_temp = 0\n",
    "    tr_epoch_loss= 0\n",
    "    val_acc_best = 0\n",
    "    val_acc_now = 0\n",
    "    val_loss = 0\n",
    "    elapsed_time_val = 0\n",
    "    no_val_best_growth_count = 0\n",
    "    no_tr_best_growth_count = 0\n",
    "    iter_acc_array = np.array([])\n",
    "    tr_acc_array = np.array([])\n",
    "    val_acc_now_array = np.array([])\n",
    "    DFA_current = DFA_on\n",
    "    DFA_toggle = False\n",
    "    DFA_flag = 1.0 if DFA_current == True else 0.0\n",
    "    DFA_BP_toggle_trial = 0\n",
    "    iter_of_val = False\n",
    "    #======== EPOCH START ==========================================================================================\n",
    "    for epoch in range(epoch_num):\n",
    "        if (e_transport_swap > 0 or e_transport_swap_tr > 0):\n",
    "            assert not (e_transport_swap > 0 and e_transport_swap_tr > 0)\n",
    "            if e_transport_swap > 0 and no_val_best_growth_count == e_transport_swap:\n",
    "                if DFA_BP_toggle_trial < e_transport_swap_coin:\n",
    "                    net = BP_DFA_SWAP(net, convTrue_fcFalse, single_step, ddp_on, args_gpu)\n",
    "                    no_val_best_growth_count = 0\n",
    "                    DFA_current = not DFA_current\n",
    "                    DFA_toggle = True\n",
    "                    DFA_BP_toggle_trial = DFA_BP_toggle_trial + 1\n",
    "            if e_transport_swap_tr > 0 and no_tr_best_growth_count == e_transport_swap_tr:\n",
    "                if DFA_BP_toggle_trial < e_transport_swap_coin:\n",
    "                    net = BP_DFA_SWAP(net, convTrue_fcFalse, single_step, ddp_on, args_gpu)\n",
    "                    no_tr_best_growth_count = 0\n",
    "                    DFA_current = not DFA_current\n",
    "                    DFA_toggle = True\n",
    "                    DFA_BP_toggle_trial = DFA_BP_toggle_trial + 1\n",
    "\n",
    "        if ddp_on == False or torch.distributed.get_rank() == 0:\n",
    "            # print('EPOCH', epoch)\n",
    "            pass\n",
    "        epoch_start_time = time.time()\n",
    "\n",
    "        # if (domain_il_epoch>0 and which_data == 'PMNIST'):\n",
    "        #     k = epoch // domain_il_epoch\n",
    "        #     xtrain=data[k]['train']['x']\n",
    "        #     ytrain=data[k]['train']['y']\n",
    "        #     xtest =data[k]['test']['x']\n",
    "        #     ytest =data[k]['test']['y']\n",
    "\n",
    "        \n",
    "        ####### iterator : input_loading & tqdm을 통한 progress_bar 생성###################\n",
    "        iterator = enumerate(train_loader, 0)\n",
    "        if ddp_on == False or torch.distributed.get_rank() == 0:  \n",
    "            iterator = tqdm(iterator, total=len(train_loader), desc='train', dynamic_ncols=True, position=0, leave=True)\n",
    "        ##################################################################################   \n",
    "        \n",
    "        #### validation_interval이 batch size보다 작을 시 validation_interval을 batch size로 맞춰줌#############\n",
    "        validation_interval2 = validation_interval\n",
    "        if (validation_interval > len(train_loader)):\n",
    "            validation_interval2 = len(train_loader)\n",
    "        ##################################################################################################\n",
    "\n",
    "\n",
    "        ###### ITERATION START ##########################################################################################################\n",
    "        for i, data in iterator:\n",
    "            iter_one_train_time_start = time.time()\n",
    "            net.train() # train 모드로 바꿔줘야함\n",
    "\n",
    "            ### data loading & semi-pre-processing ################################################################################\n",
    "            if len(data) == 2:\n",
    "                inputs, labels = data\n",
    "                # 처리 로직 작성\n",
    "            elif len(data) == 3:\n",
    "                inputs, labels, x_len = data\n",
    "                # print('x_len',x_len)\n",
    "                # mask = padded_sequence_mask(x_len)\n",
    "                # max_time_step = x_len.max()\n",
    "                # min_time_step = x_len.min()\n",
    "            ## batch 크기 ######################################\n",
    "            real_batch = labels.size(0)\n",
    "            ###########################################################\n",
    "\n",
    "            ###########################################################################################################################        \n",
    "            if (which_data == 'n_tidigits'):\n",
    "                inputs = inputs.permute(0, 1, 3, 2, 4)\n",
    "                labels = labels[:, 0, :]\n",
    "                labels = torch.argmax(labels, dim=1)\n",
    "            elif (which_data == 'heidelberg'):\n",
    "                inputs = inputs.view(5, 1000, 1, 700, 1)\n",
    "                print(\"\\n\\n\\n경고!!!! heidelberg 이거 타임스텝이랑 채널 잘 바꿔줘라!!!\\n\\n\\n\\n\")\n",
    "            # print('inputs',inputs.size(),'\\nlabels',labels.size())\n",
    "            # print(labels)\n",
    "                \n",
    "            if (which_data == 'DVS_CIFAR10' or which_data == 'DVS_GESTURE' or which_data == 'DVS_GESTURE_TONIC' or which_data == 'DVS_CIFAR10_2' or which_data == 'NMNIST' or which_data == 'NMNIST_TONIC' or which_data == 'N_CALTECH101' or which_data == 'n_tidigits' or which_data == 'heidelberg'):\n",
    "                inputs = inputs.permute(1, 0, 2, 3, 4)\n",
    "            elif rate_coding == True :\n",
    "                inputs = spikegen.rate(inputs, num_steps=TIME)\n",
    "            else :\n",
    "                inputs = inputs.repeat(TIME, 1, 1, 1, 1)\n",
    "            # inputs: [Time, Batch, Channel, Height, Width]  \n",
    "            ####################################################################################################################### \n",
    "                \n",
    "            \n",
    "            # # dvs 데이터 시각화 코드 (확인 필요할 시 써라)\n",
    "            # ##############################################################################################\n",
    "            # dvs_visualization(inputs, labels, TIME, BATCH, my_seed)\n",
    "            # #####################################################################################################\n",
    "\n",
    "            ## to (device) #######################################\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "            ###########################################################\n",
    "\n",
    "\n",
    "            ## gradient 초기화 #######################################\n",
    "            optimizer.zero_grad()\n",
    "            ###########################################################\n",
    "            \n",
    "            ## DVS gesture에서 other label자리 매꾸기 ###############\n",
    "            if (which_data == 'DVS_GESTURE'):\n",
    "                labels[labels>2] -= 1\n",
    "            #######################################################\n",
    "\n",
    "            if single_step == False:\n",
    "                # net에 넣어줄때는 batch가 젤 앞 차원으로 와야함. # dataparallel때매##############################\n",
    "                # inputs: [Time, Batch, Channel, Height, Width]   \n",
    "                inputs = inputs.permute(1, 0, 2, 3, 4) # net에 넣어줄때는 batch가 젤 앞 차원으로 와야함. # dataparallel때매\n",
    "                # inputs: [Batch, Time, Channel, Height, Width] \n",
    "                #################################################################################################\n",
    "            else:\n",
    "                labels = labels.repeat(TIME, 1)\n",
    "                ## first input도 ottt trace 적용하기 위한 코드 (validation 시에는 필요X) ##########################\n",
    "                if OTTT_input_trace_on == True:\n",
    "                    spike = inputs\n",
    "                    trace = torch.full_like(spike, fill_value = 0.0, dtype = torch.float, requires_grad=False)\n",
    "                    inputs = []\n",
    "                    for t in range(TIME):\n",
    "                        trace[t] = trace[t-1]*synapse_conv_trace_const2 + spike[t]*synapse_conv_trace_const1\n",
    "                        inputs += [[spike[t], trace[t]]]\n",
    "                ##################################################################################################\n",
    "                        \n",
    "            if merge_polarities == True:\n",
    "                inputs = inputs[:,:,0,:,:]\n",
    "\n",
    "            if single_step == False:\n",
    "                ### input --> net --> output #####################################################\n",
    "                outputs = net(inputs)\n",
    "                ##################################################################################\n",
    "                ## loss, backward ##########################################\n",
    "                loss = criterion(outputs, labels)\n",
    "                loss.backward()\n",
    "                ############################################################\n",
    "                ## weight 업데이트!! ##################################\n",
    "                optimizer.step()\n",
    "                ################################################################\n",
    "            else:\n",
    "                outputs_all = []\n",
    "                loss = 0.0\n",
    "                for t in range(TIME):\n",
    "                    ### input[t] --> net --> output_one_time #########################################\n",
    "                    outputs_one_time = net(inputs[t])\n",
    "                    ##################################################################################\n",
    "                    one_time_loss = criterion(outputs_one_time, labels[t].contiguous())\n",
    "                    one_time_loss.backward() # one_time backward\n",
    "                    loss += one_time_loss.data\n",
    "                    outputs_all.append(outputs_one_time.detach())\n",
    "                optimizer.step() # full step time update\n",
    "                outputs_all = torch.stack(outputs_all, dim=1)\n",
    "                outputs = outputs_all.mean(1) # ottt꺼 쓸때\n",
    "                labels = labels[0]\n",
    "                loss /= TIME\n",
    "            tr_epoch_loss_temp += loss.data/len(train_loader)\n",
    "\n",
    "            ## net 그림 출력해보기 #################################################################\n",
    "            # print('시각화')\n",
    "            # make_dot(outputs, params=dict(list(net.named_parameters()))).render(\"net_torchviz\", format=\"png\")\n",
    "            # return 0\n",
    "            ##################################################################################\n",
    "\n",
    "            #### batch 어긋남 방지 ###############################################\n",
    "            assert real_batch == outputs.size(0), f'batch size is not same. real_batch: {real_batch}, outputs.size(0): {outputs.size(0)}'\n",
    "            #######################################################################\n",
    "            \n",
    "\n",
    "            ####### training accruacy save for print ###############################\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total = real_batch\n",
    "            correct = (predicted == labels).sum().item()\n",
    "            iter_acc = correct / total\n",
    "            tr_total += total\n",
    "            tr_correct += correct\n",
    "            if i % verbose_interval == verbose_interval-1:\n",
    "                if ddp_on == False or torch.distributed.get_rank() == 0:\n",
    "                    print(f'{epoch}-{i} training acc: {100 * iter_acc:.2f}%, lr={[f\"{lr}\" for lr in (param_group[\"lr\"] for param_group in optimizer.param_groups)]}, val_acc: {100 * val_acc_now:.2f}%')\n",
    "            iter_acc_string = f'epoch-{epoch:<3} iter_acc:{100 * iter_acc:7.2f}%, lr={[f\"{lr:9.7f}\" for lr in (param_group[\"lr\"] for param_group in optimizer.param_groups)]}'\n",
    "            iter_acc_string2 = f'epoch-{epoch:<3} lr={[f\"{lr:9.7f}\" for lr in (param_group[\"lr\"] for param_group in optimizer.param_groups)]}'\n",
    "            ################################################################\n",
    "            \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "            iter_one_train_time_end = time.time()\n",
    "            elapsed_time = iter_one_train_time_end - iter_one_train_time_start  # 실행 시간 계산\n",
    "\n",
    "            if (i % verbose_interval == verbose_interval-1):\n",
    "                if ddp_on == False or torch.distributed.get_rank() == 0:\n",
    "                    print(f\"iter_one_train_time: {elapsed_time} seconds, last one_val_time: {elapsed_time_val} seconds\\n\")\n",
    "\n",
    "            ##### validation ##################################################################################################################################\n",
    "            if i % validation_interval2 == validation_interval2-1:\n",
    "                iter_one_val_time_start = time.time()\n",
    "                tr_acc = tr_correct/tr_total\n",
    "                tr_correct = 0\n",
    "                tr_total = 0\n",
    "                val_loss = 0\n",
    "                correct = 0\n",
    "                total = 0\n",
    "                with torch.no_grad():\n",
    "                    net.eval() # eval 모드로 바꿔줘야함 \n",
    "                    for data in test_loader:\n",
    "                        ## data loading & semi-pre-processing ##########################################################\n",
    "                        if len(data) == 2:\n",
    "                            inputs, labels = data\n",
    "                            # 처리 로직 작성\n",
    "                        elif len(data) == 3:\n",
    "                            inputs, labels, x_len = data\n",
    "                            # print('x_len',x_len)\n",
    "                            # mask = padded_sequence_mask(x_len)\n",
    "                            # max_time_step = x_len.max()\n",
    "                            # min_time_step = x_len.min()\n",
    "                            # B, T, *spatial_dims = inputs.shape\n",
    "\n",
    "                        if (which_data == 'DVS_CIFAR10' or which_data == 'DVS_GESTURE' or which_data == 'DVS_GESTURE_TONIC' or which_data == 'DVS_CIFAR10_2' or which_data == 'NMNIST' or which_data == 'NMNIST_TONIC' or which_data == 'N_CALTECH101' or which_data == 'n_tidigits' or which_data == 'heidelberg'):\n",
    "                            inputs = inputs.permute(1, 0, 2, 3, 4)\n",
    "                        elif rate_coding == True :\n",
    "                            inputs = spikegen.rate(inputs, num_steps=TIME)\n",
    "                        else :\n",
    "                            inputs = inputs.repeat(TIME, 1, 1, 1, 1)\n",
    "                        # inputs: [Time, Batch, Channel, Height, Width]  \n",
    "                        ###################################################################################################\n",
    "\n",
    "                        inputs = inputs.to(device)\n",
    "                        labels = labels.to(device)\n",
    "                        real_batch = labels.size(0)\n",
    "                        \n",
    "                        ## DVS gesture에서 other label자리 매꾸기 ###############\n",
    "                        if (which_data == 'DVS_GESTURE'):\n",
    "                            labels[labels>2] -= 1\n",
    "                        #######################################################\n",
    "                        \n",
    "                        if merge_polarities == True:\n",
    "                            inputs = inputs[:,:,0,:,:]\n",
    "\n",
    "                        ## network 연산 시작 ############################################################################################################\n",
    "                        if single_step == False:\n",
    "                            outputs = net(inputs.permute(1, 0, 2, 3, 4)) #inputs: [Batch, Time, Channel, Height, Width]  \n",
    "                            val_loss += criterion(outputs, labels)/len(test_loader)\n",
    "                        else:\n",
    "                            outputs_all = []\n",
    "                            for t in range(TIME):\n",
    "                                outputs = net(inputs[t])\n",
    "                                val_loss_temp = criterion(outputs, labels)\n",
    "                                outputs_all.append(outputs.detach())\n",
    "                                val_loss += (val_loss_temp.data/TIME)/len(test_loader)\n",
    "                            outputs_all = torch.stack(outputs_all, dim=1)\n",
    "                            outputs = outputs_all.mean(1)\n",
    "                        #################################################################################################################################\n",
    "\n",
    "                        _, predicted = torch.max(outputs.data, 1)\n",
    "                        total += real_batch\n",
    "                        assert real_batch == outputs.size(0), f'batch size is not same. real_batch: {real_batch}, outputs.size(0): {outputs.size(0)}'\n",
    "                        correct += (predicted == labels).sum().item()\n",
    "\n",
    "                    val_acc_now = correct / total\n",
    "                    # print(f'{epoch}-{i} validation acc: {100 * val_acc_now:.2f}%, lr={[f\"{lr:.10f}\" for lr in (param_group[\"lr\"] for param_group in optimizer.param_groups)]}')\n",
    "\n",
    "                iter_one_val_time_end = time.time()\n",
    "                elapsed_time_val = iter_one_val_time_end - iter_one_val_time_start  # 실행 시간 계산\n",
    "                # print(f\"iter_one_val_time: {elapsed_time_val} seconds\")\n",
    "\n",
    "                # network save\n",
    "                if val_acc_best < val_acc_now:\n",
    "                    val_acc_best = val_acc_now\n",
    "                    if ddp_on == False or torch.distributed.get_rank() == 0:\n",
    "                        # wandb 키면 state_dict아닌거는 저장 안됨\n",
    "                        torch.save(net.state_dict(), f\"net_save/save_now_net_weights_{unique_name}.pth\")\n",
    "                        # torch.save(net, f\"net_save/save_now_net_{unique_name}.pth\")\n",
    "                        # torch.save(net.module.state_dict(), f\"net_save/save_now_net_weights2_{unique_name}.pth\")\n",
    "                        # torch.save(net.module, f\"net_save/save_now_net2_{unique_name}.pth\")\n",
    "                    no_val_best_growth_count = 0\n",
    "                else:\n",
    "                    no_val_best_growth_count = no_val_best_growth_count + 1\n",
    "\n",
    "                if tr_acc_best < tr_acc:\n",
    "                    tr_acc_best = tr_acc\n",
    "                    no_tr_best_growth_count = 0\n",
    "                else:\n",
    "                    no_tr_best_growth_count = no_tr_best_growth_count + 1\n",
    "\n",
    "                tr_epoch_loss = tr_epoch_loss_temp\n",
    "                tr_epoch_loss_temp = 0\n",
    "\n",
    "                if DFA_toggle == True:\n",
    "                    DFA_flag = 1.0 - DFA_flag\n",
    "                    DFA_toggle = False\n",
    "\n",
    "                iter_of_val = True\n",
    "            ####################################################################################################################################################\n",
    "            \n",
    "            ## progress bar update ############################################################################################################\n",
    "            if ddp_on == False or torch.distributed.get_rank() == 0:\n",
    "                if iter_of_val == False:\n",
    "                    iterator.set_description(f\"{iter_acc_string}, iter_loss:{loss:10.6f}, val_best:{100 * val_acc_best:7.2f}%\")  \n",
    "                else:\n",
    "                    iterator.set_description(f\"{iter_acc_string2}, tr/val_loss:{tr_epoch_loss:10.6f}/{val_loss:10.6f}, tr:{100 * tr_acc:7.2f}%, val:{100 * val_acc_now:7.2f}%, val_best:{100 * val_acc_best:7.2f}%\")  \n",
    "                    iter_of_val = False\n",
    "            ####################################################################################################################################\n",
    "            \n",
    "            ## wandb logging ############################################################################################################\n",
    "            if ddp_on == False or torch.distributed.get_rank() == 0:\n",
    "                wandb.log({\"iter_acc\": iter_acc})\n",
    "                wandb.log({\"tr_acc\": tr_acc})\n",
    "                wandb.log({\"val_acc_now\": val_acc_now})\n",
    "                wandb.log({\"val_acc_best\": val_acc_best})\n",
    "                wandb.log({\"summary_val_acc\": val_acc_now})\n",
    "                wandb.log({\"epoch\": epoch})\n",
    "                wandb.log({\"DFA_flag\": DFA_flag}) # DFA mode 바뀌자 마자 바뀌는 게 아니고 validation 한번 했을 때 바뀜.\n",
    "                wandb.log({\"val_loss\": val_loss}) \n",
    "                wandb.log({\"tr_epoch_loss\": tr_epoch_loss}) \n",
    "            ####################################################################################################################################\n",
    "            \n",
    "            \n",
    "            ## accuray 로컬에 저장 하기 위한 코드 #####################################################################################\n",
    "            iter_acc_array = np.append(iter_acc_array, iter_acc)\n",
    "            tr_acc_array = np.append(tr_acc_array, tr_acc)\n",
    "            val_acc_now_array = np.append(val_acc_now_array, val_acc_now)\n",
    "            base_name = f'{current_time}'\n",
    "            ####################################################################################################################\n",
    "            \n",
    "            iter_acc_file_name_time = f'result_save/{base_name}_iter_acc_array_{unique_name}.npy'\n",
    "            tr_acc_file_name_time = f'result_save/{base_name}_tr_acc_array_{unique_name}.npy'\n",
    "            val_acc_file_name_time = f'result_save/{base_name}_val_acc_now_array_{unique_name}.npy'\n",
    "            hyperparameters_file_name_time = f'result_save/{base_name}_hyperparameters_{unique_name}.json'\n",
    "\n",
    "            hyperparameters['current epoch'] = epoch\n",
    "\n",
    "            ### accuracy 세이브: 덮어쓰기 하기 싫으면 주석 풀어서 사용 (시간마다 새로 쓰기) 비추천 ########################\n",
    "            # if ddp_on == False or torch.distributed.get_rank() == 0:\n",
    "            #     np.save(iter_acc_file_name_time, iter_acc_array)\n",
    "            #     np.save(tr_acc_file_name_time, iter_acc_array)\n",
    "            #     np.save(val_acc_file_name_time, val_acc_now_array)\n",
    "            #     with open(hyperparameters_file_name_time, 'w') as f:\n",
    "            #         json.dump(hyperparameters, f, indent=4)\n",
    "            #########################################################################################################\n",
    "\n",
    "            ## accuracy 세이브 ###########################################################################################\n",
    "            if ddp_on == False or torch.distributed.get_rank() == 0:\n",
    "                np.save(f'result_save/iter_acc_array_{unique_name}.npy', iter_acc_array)\n",
    "                np.save(f'result_save/tr_acc_array_{unique_name}.npy', tr_acc_array)\n",
    "                np.save(f'result_save/val_acc_now_array_{unique_name}.npy', val_acc_now_array)\n",
    "                with open(f'result_save/hyperparameters_{unique_name}.json', 'w') as f:\n",
    "                    json.dump(hyperparameters, f, indent=4)\n",
    "            ##########################################################################################################\n",
    "        ###### ITERATION END ##########################################################################################################\n",
    "                \n",
    "\n",
    "        ## scheduler update #############################################################################\n",
    "        if (scheduler_name != 'no'):\n",
    "            if (scheduler_name == 'ReduceLROnPlateau'):\n",
    "                scheduler.step(val_loss)\n",
    "            else:\n",
    "                scheduler.step()\n",
    "        #################################################################################################\n",
    "        \n",
    "        # 실행 시간 계산\n",
    "        epoch_time_end = time.time()\n",
    "        # print(f\"epoch_time: {epoch_time_end - epoch_start_time} seconds\\n\") \n",
    "    #======== EPOCH END ==========================================================================================\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ### my_snn control board (Gesture) ########################\n",
    "# decay = 0.25 # 0.875 0.25 0.125 0.75 0.5\n",
    "# # nda 0.25 # ottt 0.5\n",
    "# const2 = False # trace 할거면 True, 안할거면 False\n",
    "\n",
    "# unique_name = 'main' ## 이거 설정하면 새로운 경로에 모두 save\n",
    "# run_name = 'main' ## 이거 설정하면 새로운 경로에 모두 save\n",
    "\n",
    "# if const2 == True:\n",
    "#     const2 = decay\n",
    "# else:\n",
    "#     const2 = 0.0\n",
    "\n",
    "# wandb.init(project= f'my_snn {unique_name}',save_code=True)\n",
    "\n",
    "# my_snn_system(  devices = \"2\",\n",
    "#                 single_step = True, # True # False\n",
    "#                 unique_name = run_name,\n",
    "#                 my_seed = 42,\n",
    "#                 TIME = 10 , # dvscifar 10 # ottt 6 or 10 # nda 10  # 제작하는 dvs에서 TIME넘거나 적으면 자르거나 PADDING함\n",
    "#                 BATCH = 16, # batch norm 할거면 2이상으로 해야함   # nda 256   #  ottt 128\n",
    "#                 IMAGE_SIZE = 128, # dvscifar 48 # MNIST 28 # CIFAR10 32 # PMNIST 28 #NMNIST 34 # GESTURE 128\n",
    "#                 # dvsgesture 128, dvs_cifar2 128, nmnist 34, n_caltech101 180,240, n_tidigits 64, heidelberg 700, \n",
    "#                 #pmnist는 28로 해야 됨. 나머지는 바꿔도 돌아는 감.\n",
    "\n",
    "#                 # DVS_CIFAR10 할거면 time 10으로 해라\n",
    "#                 which_data = 'DVS_GESTURE_TONIC',\n",
    "# # 'CIFAR100' 'CIFAR10' 'MNIST' 'FASHION_MNIST' 'DVS_CIFAR10' 'PMNIST'아직\n",
    "# # 'DVS_GESTURE', 'DVS_GESTURE_TONIC','DVS_CIFAR10_2','NMNIST','NMNIST_TONIC','N_CALTECH101','n_tidigits','heidelberg'\n",
    "#                 # CLASS_NUM = 10,\n",
    "#                 data_path = '/data2', # YOU NEED TO CHANGE THIS\n",
    "#                 rate_coding = False, # True # False\n",
    "#                 lif_layer_v_init = 0.0,\n",
    "#                 lif_layer_v_decay = decay,\n",
    "#                 lif_layer_v_threshold = 0.5,  # 10000이상으로 하면 NDA LIF 씀. #nda 0.5  #ottt 1.0\n",
    "#                 lif_layer_v_reset = 0, # 10000이상은 hardreset (내 LIF쓰기는 함 ㅇㅇ)\n",
    "#                 lif_layer_sg_width = 2.570969004857107, # sigmoid류에서는 alpha값 4.0, rectangle류에서는 width값 0.5\n",
    "\n",
    "#                 # synapse_conv_in_channels = IMAGE_PIXEL_CHANNEL,\n",
    "#                 synapse_conv_kernel_size = 3,\n",
    "#                 synapse_conv_stride = 1,\n",
    "#                 synapse_conv_padding = 1,\n",
    "#                 synapse_conv_trace_const1 = 1, # 현재 trace구할 때 현재 spike에 곱해지는 상수. 걍 1로 두셈.\n",
    "#                 synapse_conv_trace_const2 = const2, # 현재 trace구할 때 직전 trace에 곱해지는 상수. lif_layer_v_decay와 같게 할 것을 추천\n",
    "\n",
    "#                 # synapse_fc_out_features = CLASS_NUM,\n",
    "#                 synapse_fc_trace_const1 = 1, # 현재 trace구할 때 현재 spike에 곱해지는 상수. 걍 1로 두셈.\n",
    "#                 synapse_fc_trace_const2 = const2, # 현재 trace구할 때 직전 trace에 곱해지는 상수. lif_layer_v_decay와 같게 할 것을 추천\n",
    "\n",
    "#                 pre_trained = False, # True # False\n",
    "#                 convTrue_fcFalse = False, # True # False\n",
    "\n",
    "#                 # 'P' for average pooling, 'D' for (1,1) aver pooling, 'M' for maxpooling, 'L' for linear classifier, [  ] for residual block\n",
    "#                 # conv에서 10000 이상은 depth-wise separable (BPTT만 지원), 20000이상은 depth-wise (BPTT만 지원)\n",
    "#                 # cfg = [64, 64],\n",
    "#                 # cfg = [64, 124, 64, 124],\n",
    "#                 # cfg = ['M','M',512], \n",
    "#                 # cfg = [512], \n",
    "#                 # cfg = ['M', 'M', 64, 128, 'P', 128, 'P'], \n",
    "#                 # cfg = ['M','M',512],\n",
    "#                 # cfg = ['M','M',200,200],\n",
    "#                 cfg = ['M','M',200,200,200],\n",
    "#                 # cfg = ['M','M',1024,512,256,128,64],\n",
    "#                 # cfg = [200,200],\n",
    "#                 # cfg = [12], #fc\n",
    "#                 # cfg = [12, 'M', 48, 'M', 12], \n",
    "#                 # cfg = [64,[64,64],64], # 끝에 linear classifier 하나 자동으로 붙습니다\n",
    "#                 # cfg = [64, 128, 'P', 256, 256, 'P', 512, 512, 'P', 512, 512, 'D'], #ottt\n",
    "#                 # cfg = [64, 128, 'P', 256, 256, 'P', 512, 512, 'P', 512, 512], \n",
    "#                 # cfg = [64, 128, 'M', 256, 256, 'M', 512, 512, 'M', 512, 512], \n",
    "#                 # cfg = [64, 'P', 128, 'P', 256, 256, 'P', 512, 512, 512, 512, 'D'], # nda\n",
    "#                 # cfg = [64, 'P', 128, 'P', 256, 256, 'P', 512, 512, 512, 512], # nda 128pixel\n",
    "#                 # cfg = [64, 'P', 128, 'P', 256, 256, 'P', 512, 512, 512, 512, 'L', 4096, 4096],\n",
    "#                 # cfg = [20001,10001], # depthwise, separable\n",
    "#                 # cfg = [64,20064,10001], # vanilla conv, depthwise, separable\n",
    "#                 # cfg = [8, 'P', 8, 'P', 8, 'P', 8,'P', 8, 'P'],\n",
    "#                 # cfg = [],        \n",
    "                \n",
    "#                 net_print = True, # True # False # True로 하길 추천\n",
    "#                 weight_count_print = False, # True # False\n",
    "                \n",
    "#                 pre_trained_path = f\"net_save/save_now_net_weights_{unique_name}.pth\",\n",
    "#                 learning_rate = 0.001, #0.1 bptt, #0.01 ottt, # default 0.001  # ottt 0.1 # nda 0.001 # 0.00936191669529645\n",
    "#                 epoch_num = 60,\n",
    "#                 verbose_interval = 999999999, #이거 걍 건들지마셈 #숫자 크게 하면 꺼짐 #걍 중간중간 iter에서 끊어서 출력\n",
    "#                 validation_interval =  999999999,#999999999, #이거 걍 건들지마셈 #숫자 크게 하면 에포크 마지막 iter 때 val 함\n",
    "\n",
    "#                 tdBN_on = False,  # True # False\n",
    "#                 BN_on = False,  # True # False\n",
    "                \n",
    "#                 surrogate = 'hard_sigmoid', # 'sigmoid' 'rectangle' 'rough_rectangle' 'hard_sigmoid'\n",
    "                \n",
    "#                 gradient_verbose = False,  # True # False  # weight gradient 각 layer마다 띄워줌\n",
    "\n",
    "#                 BPTT_on = False,  # True # False # True이면 BPTT, False이면 OTTT  # depthwise, separable은 BPTT만 가능\n",
    "#                 optimizer_what = 'SGD', # 'SGD' 'Adam', 'RMSprop'\n",
    "#                 scheduler_name = 'CosineAnnealingLR', # 'no' 'StepLR' 'ExponentialLR' 'ReduceLROnPlateau' 'CosineAnnealingLR' 'OneCycleLR'\n",
    "                \n",
    "#                 ddp_on = False,   # True # False \n",
    "#                 # 지원 DATASET: cifar10, mnist\n",
    "\n",
    "#                 nda_net = False,   # True # False\n",
    "\n",
    "#                 domain_il_epoch = 0, # over 0, then domain il mode on # pmnist 쓸거면 HLOP 코드보고 더 디벨롭하셈. 지금 개발 hold함.\n",
    "                \n",
    "#                 dvs_clipping = 2, # 숫자만큼 크면 spike 아니면 걍 0\n",
    "#                 # gesture, cifar-dvs2, nmnist, ncaltech101\n",
    "\n",
    "#                 dvs_duration = 100_000, # 0 아니면 time sampling # dvs number sampling OR time sampling # gesture, cifar-dvs2, nmnist, ncaltech101\n",
    "#                 # 있는 데이터들 #gesture 100_000 25_000 10_000 1_000 1_000_000 #nmnist 10000 #nmnist_tonic 10_000 25_000\n",
    "#                 # 한 숫자가 1us인듯 (spikingjelly코드에서)\n",
    "#                 # 한 장에 50 timestep만 생산함. 싫으면 my_snn/trying/spikingjelly_dvsgesture의__init__.py 를 참고해봐\n",
    "\n",
    "#                 OTTT_sWS_on = False, # True # False # BPTT끄고, CONV에만 적용됨.\n",
    "\n",
    "#                 DFA_on = False, # True # False # residual은 dfa지원안함.\n",
    "#                 OTTT_input_trace_on = False, # True # False # 맨 처음 input에 trace 적용\n",
    "                 \n",
    "#                 e_transport_swap = 0, # 1 이상이면 해당 숫자 에포크만큼 val_acc_best가 변화가 없으면 e_transport scheme (BP vs DFA) swap\n",
    "#                 e_transport_swap_tr = 0, # 1 이상이면 해당 숫자 에포크만큼 tr_acc_best가 변화가 없으면 e_transport scheme (BP vs DFA) swap\n",
    "#                 e_transport_swap_coin = 1, # swap할 수 있는 coin 개수\n",
    "\n",
    "#                 drop_rate = 0.0, # drop_rate만큼 0으로 만듦. ex) 0.2면 activation의 20%를 0으로 만듦.\n",
    "\n",
    "#                 exclude_class = True, # True # False # gesture에서 10번째 클래스 제외\n",
    "\n",
    "#                 merge_polarities = False, # True # False # tonic dvs dataset 에서 polarities 합치기\n",
    "#                 ) \n",
    "# # sigmoid와 BN이 있어야 잘된다.\n",
    "# # average pooling  \n",
    "# # 이 낫다. \n",
    " \n",
    "# # nda에서는 decay = 0.25, threshold = 0.5, width =1, surrogate = rectangle, batch = 256, tdBN = True\n",
    "# ## OTTT 에서는 decay = 0.5, threshold = 1.0, surrogate = sigmoid, batch = 128, BN = True\n",
    "\n",
    "\n",
    "# # DDP 실행 코드\n",
    "# '''\n",
    "# ddp_on 키고, gpu 개수 만큼 batch size 나눠줘\n",
    "# CUDA_VISIBLE_DEVICES=0,1,2,3,4,5 python -m torch.distributed.launch --nproc_per_node=6 main_ddp.py\n",
    "# CUDA_VISIBLE_DEVICES=1,2,3 python -m torch.distributed.launch --nproc_per_node=3 main_ddp.py\n",
    "# CUDA_VISIBLE_DEVICES=0,1,2,3 python -m torch.distributed.launch --nproc_per_node=4 main_ddp.py\n",
    "# '''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ### my_snn control board (NMNIST) ########################\n",
    "# decay = 0.25 # 0.875 0.25 0.125 0.75 0.5\n",
    "# # nda 0.25 # ottt 0.5\n",
    "# const2 = False # trace 할거면 True, 안할거면 False\n",
    "\n",
    "# unique_name = 'main' ## 이거 설정하면 새로운 경로에 모두 save\n",
    "# run_name = 'main' ## 이거 설정하면 새로운 경로에 모두 save\n",
    "\n",
    "# if const2 == True:\n",
    "#     const2 = decay\n",
    "# else:\n",
    "#     const2 = 0.0\n",
    "\n",
    "# wandb.init(project= f'my_snn {unique_name}',save_code=True)\n",
    "\n",
    "# my_snn_system(  devices = \"4\",\n",
    "#                 single_step = True, # True # False\n",
    "#                 unique_name = run_name,\n",
    "#                 my_seed = 42,\n",
    "#                 TIME = 10 , # dvscifar 10 # ottt 6 or 10 # nda 10  # 제작하는 dvs에서 TIME넘거나 적으면 자르거나 PADDING함\n",
    "#                 BATCH = 128, # batch norm 할거면 2이상으로 해야함   # nda 256   #  ottt 128\n",
    "#                 IMAGE_SIZE = 34, # dvscifar 48 # MNIST 28 # CIFAR10 32 # PMNIST 28 #NMNIST 34 # GESTURE 128\n",
    "#                 # dvsgesture 128, dvs_cifar2 128, nmnist 34, n_caltech101 180,240, n_tidigits 64, heidelberg 700, \n",
    "#                 #pmnist는 28로 해야 됨. 나머지는 바꿔도 돌아는 감.\n",
    "\n",
    "#                 # DVS_CIFAR10 할거면 time 10으로 해라\n",
    "#                 which_data = 'NMNIST_TONIC',\n",
    "# # 'CIFAR100' 'CIFAR10' 'MNIST' 'FASHION_MNIST' 'DVS_CIFAR10' 'PMNIST'아직\n",
    "# # 'DVS_GESTURE', 'DVS_GESTURE_TONIC','DVS_CIFAR10_2','NMNIST','NMNIST_TONIC','N_CALTECH101','n_tidigits','heidelberg'\n",
    "#                 # CLASS_NUM = 10,\n",
    "#                 data_path = '/data2', # YOU NEED TO CHANGE THIS\n",
    "#                 rate_coding = False, # True # False\n",
    "#                 lif_layer_v_init = 0.0,\n",
    "#                 lif_layer_v_decay = decay,\n",
    "#                 lif_layer_v_threshold = 1.0,  # 10000이상으로 하면 NDA LIF 씀. #nda 0.5  #ottt 1.0\n",
    "#                 lif_layer_v_reset = 0, # 10000이상은 hardreset (내 LIF쓰기는 함 ㅇㅇ)\n",
    "#                 lif_layer_sg_width = 0.5, # # surrogate sigmoid 쓸 때는 의미없음\n",
    "\n",
    "#                 # synapse_conv_in_channels = IMAGE_PIXEL_CHANNEL,\n",
    "#                 synapse_conv_kernel_size = 3,\n",
    "#                 synapse_conv_stride = 1,\n",
    "#                 synapse_conv_padding = 1,\n",
    "#                 synapse_conv_trace_const1 = 1, # 현재 trace구할 때 현재 spike에 곱해지는 상수. 걍 1로 두셈.\n",
    "#                 synapse_conv_trace_const2 = const2, # 현재 trace구할 때 직전 trace에 곱해지는 상수. lif_layer_v_decay와 같게 할 것을 추천\n",
    "\n",
    "#                 # synapse_fc_out_features = CLASS_NUM,\n",
    "#                 synapse_fc_trace_const1 = 1, # 현재 trace구할 때 현재 spike에 곱해지는 상수. 걍 1로 두셈.\n",
    "#                 synapse_fc_trace_const2 = const2, # 현재 trace구할 때 직전 trace에 곱해지는 상수. lif_layer_v_decay와 같게 할 것을 추천\n",
    "\n",
    "#                 pre_trained = False, # True # False\n",
    "#                 convTrue_fcFalse = False, # True # False\n",
    "\n",
    "#                 # 'P' for average pooling, 'D' for (1,1) aver pooling, 'M' for maxpooling, 'L' for linear classifier, [  ] for residual block\n",
    "#                 # conv에서 10000 이상은 depth-wise separable (BPTT만 지원), 20000이상은 depth-wise (BPTT만 지원)\n",
    "#                 # cfg = [64, 64],\n",
    "#                 # cfg = [64, 124, 64, 124],\n",
    "#                 # cfg = ['M','M',512], \n",
    "#                 # cfg = [512], \n",
    "#                 # cfg = ['M', 'M', 64, 128, 'P', 128, 'P'], \n",
    "#                 # cfg = ['M','M',512],\n",
    "#                 # cfg = ['M','M',200,200],\n",
    "#                 # cfg = ['M','M',1024,512,256,128,64],\n",
    "#                 cfg = [200,200],\n",
    "#                 # cfg = [12], #fc\n",
    "#                 # cfg = [12, 'M', 48, 'M', 12], \n",
    "#                 # cfg = [64,[64,64],64], # 끝에 linear classifier 하나 자동으로 붙습니다\n",
    "#                 # cfg = [64, 128, 'P', 256, 256, 'P', 512, 512, 'P', 512, 512, 'D'], #ottt\n",
    "#                 # cfg = [64, 128, 'P', 256, 256, 'P', 512, 512, 'P', 512, 512], \n",
    "#                 # cfg = [64, 128, 'M', 256, 256, 'M', 512, 512, 'M', 512, 512], \n",
    "#                 # cfg = [64, 'P', 128, 'P', 256, 256, 'P', 512, 512, 512, 512, 'D'], # nda\n",
    "#                 # cfg = [64, 'P', 128, 'P', 256, 256, 'P', 512, 512, 512, 512], # nda 128pixel\n",
    "#                 # cfg = [64, 'P', 128, 'P', 256, 256, 'P', 512, 512, 512, 512, 'L', 4096, 4096],\n",
    "#                 # cfg = [20001,10001], # depthwise, separable\n",
    "#                 # cfg = [64,20064,10001], # vanilla conv, depthwise, separable\n",
    "#                 # cfg = [8, 'P', 8, 'P', 8, 'P', 8,'P', 8, 'P'],\n",
    "#                 # cfg = [],        \n",
    "                \n",
    "#                 net_print = True, # True # False # True로 하길 추천\n",
    "#                 weight_count_print = False, # True # False\n",
    "                \n",
    "#                 pre_trained_path = f\"net_save/save_now_net_weights_{unique_name}.pth\",\n",
    "#                 learning_rate = 0.009, # 0.001, # default 0.001  # ottt 0.1 # nda 0.001 \n",
    "#                 epoch_num = 300,\n",
    "#                 verbose_interval = 999999999, #이거 걍 건들지마셈 #숫자 크게 하면 꺼짐 #걍 중간중간 iter에서 끊어서 출력\n",
    "#                 validation_interval =  999999999,#999999999, #이거 걍 건들지마셈 #숫자 크게 하면 에포크 마지막 iter 때 val 함\n",
    "\n",
    "#                 tdBN_on = False,  # True # False\n",
    "#                 BN_on = False,  # True # False\n",
    "                \n",
    "#                 surrogate = 'hard_sigmoid', # 'rectangle' 'sigmoid' 'rough_rectangle' 'hard_sigmoid'\n",
    "                \n",
    "#                 gradient_verbose = False,  # True # False  # weight gradient 각 layer마다 띄워줌\n",
    "\n",
    "#                 BPTT_on = False,  # True # False # True이면 BPTT, False이면 OTTT  # depthwise, separable은 BPTT만 가능\n",
    "#                 optimizer_what = 'SGD', # 'SGD' 'Adam', 'RMSprop'\n",
    "#                 scheduler_name = 'CosineAnnealingLR', # 'no' 'StepLR' 'ExponentialLR' 'ReduceLROnPlateau' 'CosineAnnealingLR' 'OneCycleLR'\n",
    "                \n",
    "#                 ddp_on = False,   # True # False \n",
    "#                 # 지원 DATASET: cifar10, mnist\n",
    "\n",
    "#                 nda_net = False,   # True # False\n",
    "\n",
    "#                 domain_il_epoch = 0, # over 0, then domain il mode on # pmnist 쓸거면 HLOP 코드보고 더 디벨롭하셈. 지금 개발 hold함.\n",
    "                \n",
    "#                 dvs_clipping = 1, # 숫자만큼 크면 spike 아니면 걍 0\n",
    "#                 # gesture, cifar-dvs2, nmnist, ncaltech101\n",
    "\n",
    "#                 dvs_duration = 10_000, # 0 아니면 time sampling # dvs number sampling OR time sampling # gesture, cifar-dvs2, nmnist, ncaltech101\n",
    "#                 # 있는 데이터들 #gesture 100_000 25_000 10_000 1_000 1_000_000 #nmnist 10000 #nmnist_tonic 10_000 25_000\n",
    "#                 # 한 숫자가 1us인듯 (spikingjelly코드에서)\n",
    "#                 # 한 장에 50 timestep만 생산함. 싫으면 my_snn/trying/spikingjelly_dvsgesture의__init__.py 를 참고해봐\n",
    "\n",
    "#                 OTTT_sWS_on = False, # True # False # BPTT끄고, CONV에만 적용됨.\n",
    "\n",
    "#                 DFA_on = True, # True # False # residual은 dfa지원안함.\n",
    "#                 OTTT_input_trace_on = False, # True # False # 맨 처음 input에 trace 적용\n",
    "                 \n",
    "#                 e_transport_swap = 5, # 1 이상이면 해당 숫자 에포크만큼 val_acc_best가 변화가 없으면 e_transport scheme (BP vs DFA) swap\n",
    "#                 e_transport_swap_tr = 0, # 1 이상이면 해당 숫자 에포크만큼 tr_acc_best가 변화가 없으면 e_transport scheme (BP vs DFA) swap\n",
    "#                 e_transport_swap_coin = 1, # swap할 수 있는 coin 개수\n",
    "                \n",
    "#                 drop_rate = 0.0, # drop_rate만큼 0으로 만듦. ex) 0.2면 activation의 20%를 0으로 만듦.\n",
    "\n",
    "#                 exclude_class = True, # True # False # gesture에서 10번째 클래스 제외\n",
    "\n",
    "#                 merge_polarities = False, # True # False # tonic dvs dataset 에서 polarities 합치기\n",
    "#                 ) \n",
    "# # sigmoid와 BN이 있어야 잘된다.\n",
    "# # average pooling  \n",
    "# # 이 낫다. \n",
    " \n",
    "# # nda에서는 decay = 0.25, threshold = 0.5, width =1, surrogate = rectangle, batch = 256, tdBN = True\n",
    "# ## OTTT 에서는 decay = 0.5, threshold = 1.0, surrogate = sigmoid, batch = 128, BN = True\n",
    "\n",
    "\n",
    "# # DDP 실행 코드\n",
    "# '''\n",
    "# ddp_on 키고, gpu 개수 만큼 batch size 나눠줘\n",
    "# CUDA_VISIBLE_DEVICES=0,1,2,3,4,5 python -m torch.distributed.launch --nproc_per_node=6 main_ddp.py\n",
    "# CUDA_VISIBLE_DEVICES=1,2,3 python -m torch.distributed.launch --nproc_per_node=3 main_ddp.py\n",
    "# CUDA_VISIBLE_DEVICES=0,1,2,3 python -m torch.distributed.launch --nproc_per_node=4 main_ddp.py\n",
    "# '''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Create sweep with ID: ofhv1t0y\n",
      "Sweep URL: https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/ofhv1t0y\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: scitz6uv with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBATCH: 16\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tDFA_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tIMAGE_SIZE: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tOTTT_input_trace_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tOTTT_sWS_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tTIME: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcfg: ['M', 'M', 200, 200]\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tconst2: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdecay: 0.25\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdrop_rate: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdvs_clipping: 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdvs_duration: 100000\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \te_transport_swap: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \te_transport_swap_coin: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \te_transport_swap_tr: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepoch_num: 60\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \texclude_class: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.01\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_sg_width: 2.570969004857107\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_reset: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_threshold: 0.8202197606747708\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmerge_polarities: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tscheduler_name: CosineAnnealingLR\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsurrogate: hard_sigmoid\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \twhich_data: DVS_GESTURE_TONIC\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mbhkim003\u001b[0m (\u001b[33mbhkim003-seoul-national-university\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.17.7 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.17.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/nfs/home/bhkim003/github_folder/ByeonghyeonKim/my_snn/wandb/run-20240822_195650-scitz6uv</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/scitz6uv' target=\"_blank\">golden-sweep-1</a></strong> to <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/ofhv1t0y' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/ofhv1t0y</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/ofhv1t0y' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/ofhv1t0y</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/scitz6uv' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/scitz6uv</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BATCH' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'IMAGE_SIZE' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'which_data' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_threshold' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_reset' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_sg_width' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'cfg' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'learning_rate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'epoch_num' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'surrogate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'scheduler_name' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'dvs_clipping' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'dvs_duration' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'OTTT_sWS_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'DFA_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'OTTT_input_trace_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'e_transport_swap' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'e_transport_swap_tr' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'e_transport_swap_coin' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'drop_rate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'exclude_class' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'merge_polarities' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'TIME' was locked by 'sweep' (ignored update).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset_hash = 2bbd58b4e0d3c1e9ad501fad8a43feed\n",
      "cache path exists\n",
      "\n",
      "we will exclude the 'other' class. dvsgestrue 10 classes' indices exist. \n",
      "\n",
      "DataParallel(\n",
      "  (module): MY_SNN_FC_sstep(\n",
      "    (layers): MY_Sequential(\n",
      "      (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (2): DimChanger_for_FC_sstep()\n",
      "      (3): SYNAPSE_FC_trace_sstep()\n",
      "      (4): LIF_layer_trace_sstep()\n",
      "      (5): SYNAPSE_FC_trace_sstep()\n",
      "      (6): LIF_layer_trace_sstep()\n",
      "      (7): SYNAPSE_FC_trace_sstep()\n",
      "    )\n",
      "  )\n",
      ")\n",
      "==================================================\n",
      "My Num of PARAMS: 452,010, system's param_num : 452,010\n",
      "Memory: 1.72MiB at 32-bit\n",
      "==================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch-0   iter_acc:  56.25%, lr=['0.0100000'], iter_loss:  1.263924, val_best:   0.00%:  32%|███▏      | 20/62 [00:16<00:34,  1.22it/s]"
     ]
    }
   ],
   "source": [
    "# sweep 하는 코드, 위 셀 주석처리 해야 됨.\n",
    "\n",
    "# 이런 워닝 뜨는 거는 걍 너가 main 안에서  wandb.config.update(hyperparameters)할 때 물려서임. 어차피 근데 sweep에서 지정한 걸로 덮어짐 \n",
    "# wandb: WARNING Config item 'BATCH' was locked by 'sweep' (ignored update).\n",
    "\n",
    "unique_name_hyper = 'main'\n",
    "run_name = 'main'\n",
    "sweep_configuration = {\n",
    "    'method': 'bayes',\n",
    "    'name': f'my_snn_sweep{datetime.datetime.now().strftime(\"%Y%m%d_%H%M%S\")}',\n",
    "    'metric': {'goal': 'maximize', 'name': 'val_acc_best'},\n",
    "    'parameters': \n",
    "    {\n",
    "        \"learning_rate\": {\"values\": [0.01]}, #0.00936191669529645\n",
    "        \"BATCH\": {\"values\": [16]},\n",
    "        \"decay\": {\"values\": [0.25]},\n",
    "        \"IMAGE_SIZE\": {\"values\": [128]},\n",
    "        \"TIME\": {\"values\": [4,5,6,7,8,9,10,11,12,13,14,15,16]},\n",
    "        \"epoch_num\": {\"values\": [60]},\n",
    "        \"dvs_duration\": {\"values\": [100_000]},\n",
    "        \"dvs_clipping\": {\"values\": [2]},\n",
    "        \"which_data\": {\"values\": ['DVS_GESTURE_TONIC']},\n",
    "        \"OTTT_sWS_on\": {\"values\": [False]},\n",
    "        \"const2\": {\"values\": [False]},\n",
    "        \"surrogate\": {\"values\": ['hard_sigmoid']},\n",
    "        \"DFA_on\": {\"values\": [False]},\n",
    "        \"OTTT_input_trace_on\": {\"values\": [False]},\n",
    "        \"cfg\": {\"values\": [['M','M',200,200]]},\n",
    "        \"e_transport_swap\": {\"values\": [0]},\n",
    "        \"e_transport_swap_tr\": {\"values\": [0]},\n",
    "        \"drop_rate\": {\"values\": [0.0]}, # \"drop_rate\": {\"values\": [0.25,0.5,0.75]}, #\"drop_rate\": {\"min\": 0.25, \"max\": 0.75},\n",
    "        \"exclude_class\": {\"values\": [True]},\n",
    "        \"merge_polarities\": {\"values\": [False]},\n",
    "        \"lif_layer_v_reset\": {\"values\": [0]},\n",
    "        \"lif_layer_sg_width\": {\"values\": [2.570969004857107]},\n",
    "        \"e_transport_swap_coin\": {\"values\": [1]},\n",
    "        \"lif_layer_v_threshold\": {\"values\": [1.085270539946095]},\n",
    "        \"scheduler_name\": {\"values\": ['CosineAnnealingLR']},  # 'no' 'StepLR' 'ExponentialLR' 'ReduceLROnPlateau' 'CosineAnnealingLR' 'OneCycleLR'\n",
    "     }\n",
    "}\n",
    "\n",
    "def hyper_iter():\n",
    "    ### my_snn control board ########################\n",
    "    unique_name = unique_name_hyper ## 이거 설정하면 새로운 경로에 모두 save\n",
    "    \n",
    "    wandb.init(save_code = True)\n",
    "    learning_rate  =  wandb.config.learning_rate\n",
    "    BATCH  =  wandb.config.BATCH\n",
    "    decay  =  wandb.config.decay\n",
    "    IMAGE_SIZE  =  wandb.config.IMAGE_SIZE\n",
    "    TIME  =  wandb.config.TIME\n",
    "    epoch_num  =  wandb.config.epoch_num \n",
    "    dvs_duration  =  wandb.config.dvs_duration\n",
    "    dvs_clipping  =  wandb.config.dvs_clipping\n",
    "    which_data  =  wandb.config.which_data\n",
    "    OTTT_sWS_on  =  wandb.config.OTTT_sWS_on\n",
    "    const2  =  wandb.config.const2\n",
    "    surrogate  =  wandb.config.surrogate\n",
    "    DFA_on  =  wandb.config.DFA_on\n",
    "    OTTT_input_trace_on  =  wandb.config.OTTT_input_trace_on\n",
    "    cfg  =  wandb.config.cfg\n",
    "    e_transport_swap  =  wandb.config.e_transport_swap\n",
    "    e_transport_swap_tr  =  wandb.config.e_transport_swap_tr\n",
    "    drop_rate  =  wandb.config.drop_rate\n",
    "    exclude_class  =  wandb.config.exclude_class\n",
    "    merge_polarities  =  wandb.config.merge_polarities\n",
    "    lif_layer_v_reset  =  wandb.config.lif_layer_v_reset\n",
    "    lif_layer_sg_width  =  wandb.config.lif_layer_sg_width\n",
    "    e_transport_swap_coin  =  wandb.config.e_transport_swap_coin\n",
    "    lif_layer_v_threshold  =  wandb.config.lif_layer_v_threshold\n",
    "    scheduler_name  =  wandb.config.scheduler_name\n",
    "    if const2 == True:\n",
    "        const2 = decay\n",
    "    else:\n",
    "        const2 = 0.0\n",
    "\n",
    "    my_snn_system(  devices = \"5\",\n",
    "                single_step = True, # True # False\n",
    "                unique_name = run_name,\n",
    "                my_seed = 42,\n",
    "                TIME = TIME , # dvscifar 10 # ottt 6 or 10 # nda 10  # 제작하는 dvs에서 TIME넘거나 적으면 자르거나 PADDING함\n",
    "                BATCH = BATCH, # batch norm 할거면 2이상으로 해야함   # nda 256   #  ottt 128\n",
    "                IMAGE_SIZE = IMAGE_SIZE, # dvscifar 48 # MNIST 28 # CIFAR10 32 # PMNIST 28 #NMNIST 34 # GESTURE 128\n",
    "                # dvsgesture 128, dvs_cifar2 128, nmnist 34, n_caltech101 180,240, n_tidigits 64, heidelberg 700, \n",
    "                #pmnist는 28로 해야 됨. 나머지는 바꿔도 돌아는 감.\n",
    "\n",
    "                # DVS_CIFAR10 할거면 time 10으로 해라\n",
    "                which_data = which_data,\n",
    "# 'CIFAR100' 'CIFAR10' 'MNIST' 'FASHION_MNIST' 'DVS_CIFAR10' 'PMNIST'아직\n",
    "# 'DVS_GESTURE', 'DVS_GESTURE_TONIC','DVS_CIFAR10_2','NMNIST','NMNIST_TONIC','N_CALTECH101','n_tidigits','heidelberg'\n",
    "                # CLASS_NUM = 10,\n",
    "                data_path = '/data2', # YOU NEED TO CHANGE THIS\n",
    "                rate_coding = False, # True # False\n",
    "                lif_layer_v_init = 0.0,\n",
    "                lif_layer_v_decay = decay,\n",
    "                lif_layer_v_threshold = lif_layer_v_threshold,  # 10000이상으로 하면 NDA LIF 씀. #nda 0.5  #ottt 1.0\n",
    "                lif_layer_v_reset = lif_layer_v_reset, # 10000이상은 hardreset (내 LIF쓰기는 함 ㅇㅇ)\n",
    "                lif_layer_sg_width = lif_layer_sg_width, # # surrogate sigmoid 쓸 때는 의미없음\n",
    "\n",
    "                # synapse_conv_in_channels = IMAGE_PIXEL_CHANNEL,\n",
    "                synapse_conv_kernel_size = 3,\n",
    "                synapse_conv_stride = 1,\n",
    "                synapse_conv_padding = 1,\n",
    "                synapse_conv_trace_const1 = 1, # 현재 trace구할 때 현재 spike에 곱해지는 상수. 걍 1로 두셈.\n",
    "                synapse_conv_trace_const2 = const2, # 현재 trace구할 때 직전 trace에 곱해지는 상수. lif_layer_v_decay와 같게 할 것을 추천\n",
    "\n",
    "                # synapse_fc_out_features = CLASS_NUM,\n",
    "                synapse_fc_trace_const1 = 1, # 현재 trace구할 때 현재 spike에 곱해지는 상수. 걍 1로 두셈.\n",
    "                synapse_fc_trace_const2 = const2, # 현재 trace구할 때 직전 trace에 곱해지는 상수. lif_layer_v_decay와 같게 할 것을 추천\n",
    "\n",
    "                pre_trained = False, # True # False\n",
    "                convTrue_fcFalse = False, # True # False\n",
    "\n",
    "                # 'P' for average pooling, 'D' for (1,1) aver pooling, 'M' for maxpooling, 'L' for linear classifier, [  ] for residual block\n",
    "                # conv에서 10000 이상은 depth-wise separable (BPTT만 지원), 20000이상은 depth-wise (BPTT만 지원)\n",
    "                # cfg = [64, 64],\n",
    "                # cfg = [64, 124, 64, 124],\n",
    "                # cfg = ['M','M',512], \n",
    "                # cfg = [512], \n",
    "                # cfg = ['M', 'M', 64, 128, 'P', 128, 'P'], \n",
    "                # cfg = ['M','M',200,200],\n",
    "                # cfg = [200,200],\n",
    "                cfg = cfg,\n",
    "                # cfg = [12], #fc\n",
    "                # cfg = [12, 'M', 48, 'M', 12], \n",
    "                # cfg = [64,[64,64],64], # 끝에 linear classifier 하나 자동으로 붙습니다\n",
    "                # cfg = [64, 128, 'P', 256, 256, 'P', 512, 512, 'P', 512, 512, 'D'], #ottt\n",
    "                # cfg = [64, 128, 'P', 256, 256, 'P', 512, 512, 'P', 512, 512], \n",
    "                # cfg = [64, 128, 'M', 256, 256, 'M', 512, 512, 'M', 512, 512], \n",
    "                # cfg = [64, 'P', 128, 'P', 256, 256, 'P', 512, 512, 512, 512, 'D'], # nda\n",
    "                # cfg = [64, 'P', 128, 'P', 256, 256, 'P', 512, 512, 512, 512], # nda 128pixel\n",
    "                # cfg = [64, 'P', 128, 'P', 256, 256, 'P', 512, 512, 512, 512, 'L', 4096, 4096],\n",
    "                # cfg = [20001,10001], # depthwise, separable\n",
    "                # cfg = [64,20064,10001], # vanilla conv, depthwise, separable\n",
    "                # cfg = [8, 'P', 8, 'P', 8, 'P', 8,'P', 8, 'P'],\n",
    "                # cfg = [], \n",
    "                \n",
    "                net_print = True, # True # False # True로 하길 추천\n",
    "                weight_count_print = False, # True # False\n",
    "                \n",
    "                pre_trained_path = f\"net_save/save_now_net_weights_{unique_name}.pth\",\n",
    "                learning_rate = learning_rate, # default 0.001  # ottt 0.1 # nda 0.001 \n",
    "                epoch_num = epoch_num,\n",
    "                verbose_interval = 999999999, #숫자 크게 하면 꺼짐 #걍 중간중간 iter에서 끊어서 출력\n",
    "                validation_interval =  999999999,#999999999, #숫자 크게 하면 에포크 마지막 iter 때 val 함\n",
    "\n",
    "                tdBN_on = False,  # True # False\n",
    "                BN_on = False,  # True # False\n",
    "                \n",
    "                surrogate = surrogate, # 'rectangle' 'sigmoid' 'rough_rectangle'\n",
    "                \n",
    "                gradient_verbose = False,  # True # False  # weight gradient 각 layer마다 띄워줌\n",
    "\n",
    "                BPTT_on = False,  # True # False # True이면 BPTT, False이면 OTTT  # depthwise, separable은 BPTT만 가능\n",
    "                optimizer_what = 'SGD', # 'SGD' 'Adam', 'RMSprop'\n",
    "                scheduler_name = scheduler_name, # 'no' 'StepLR' 'ExponentialLR' 'ReduceLROnPlateau' 'CosineAnnealingLR' 'OneCycleLR'\n",
    "                \n",
    "                ddp_on = False,   # True # False \n",
    "                # 지원 DATASET: cifar10, mnist\n",
    "\n",
    "                nda_net = False,   # True # False\n",
    "\n",
    "                domain_il_epoch = 0, # over 0, then domain il mode on # pmnist 쓸거면 HLOP 코드보고 더 디벨롭하셈. 지금 개발 hold함.\n",
    "                \n",
    "                dvs_clipping = dvs_clipping, # 숫자만큼 크면 spike 아니면 걍 0\n",
    "                # gesture, cifar-dvs2, nmnist, ncaltech101\n",
    "\n",
    "                dvs_duration = dvs_duration, # 0 아니면 time sampling # dvs number sampling OR time sampling # gesture, cifar-dvs2, nmnist, ncaltech101\n",
    "                # 있는 데이터들 #gesture 100_000 25_000 10_000 1_000 1_000_000 #nmnist 10000 #nmnist_tonic 10_000 25_000\n",
    "                # 한 숫자가 1us인듯 (spikingjelly코드에서)\n",
    "                # 한 장에 50 timestep만 생산함. 싫으면 my_snn/trying/spikingjelly_dvsgesture의__init__.py 를 참고해봐\n",
    "\n",
    "                OTTT_sWS_on = OTTT_sWS_on, # True # False # BPTT끄고, CONV에만 적용됨.\n",
    "\n",
    "                DFA_on = DFA_on, # True # False # residual은 dfa지원안함.\n",
    "                OTTT_input_trace_on = OTTT_input_trace_on, # True # False # 맨 처음 input에 trace 적용\n",
    "                 \n",
    "                e_transport_swap = e_transport_swap, # 1 이상이면 해당 숫자 에포크만큼 val_acc_best가 변화가 없으면 e_transport scheme (BP vs DFA) swap\n",
    "                e_transport_swap_tr = e_transport_swap_tr, # 1 이상이면 해당 숫자 에포크만큼 tr_acc_best가 변화가 없으면 e_transport scheme (BP vs DFA) swap\n",
    "                e_transport_swap_coin = e_transport_swap_coin, # swap할 수 있는 coin 개수\n",
    "                    \n",
    "                drop_rate = drop_rate,\n",
    "\n",
    "                exclude_class = exclude_class, # True # False # gesture에서 10번째 클래스 제외\n",
    "\n",
    "                merge_polarities = merge_polarities, # True # False # tonic dvs dataset 에서 polarities 합치기\n",
    "                    ) \n",
    "    # sigmoid와 BN이 있어야 잘된다.\n",
    "    # average pooling\n",
    "    # 이 낫다. \n",
    "    \n",
    "    # nda에서는 decay = 0.25, threshold = 0.5, width =1, surrogate = rectangle, batch = 256, tdBN = True\n",
    "    ## OTTT 에서는 decay = 0.5, threshold = 1.0, surrogate = sigmoid, batch = 128, BN = True\n",
    "\n",
    "sweep_id = wandb.sweep(sweep=sweep_configuration, project=f'my_snn {unique_name_hyper}')\n",
    "wandb.agent(sweep_id, function=hyper_iter, count=10000, project=f'my_snn {unique_name_hyper}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "# import matplotlib.pyplot as plt\n",
    "# import json\n",
    "# run_name = 'main_FINAL_TEST'\n",
    "\n",
    "# unique_name = run_name\n",
    "# def pad_array_to_match_length(array1, array2):\n",
    "#     if len(array1) > len(array2):\n",
    "#         padded_array2 = np.pad(array2, (0, len(array1) - len(array2)), 'constant')\n",
    "#         return array1, padded_array2\n",
    "#     elif len(array2) > len(array1):\n",
    "#         padded_array1 = np.pad(array1, (0, len(array2) - len(array1)), 'constant')\n",
    "#         return padded_array1, array2\n",
    "#     else:\n",
    "#         return array1, array2\n",
    "# def load_hyperparameters(filename=f'result_save/hyperparameters_{unique_name}.json'):\n",
    "#     with open(filename, 'r') as f:\n",
    "#         return json.load(f)\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# current_time = '20240628_110116'\n",
    "# base_name = f'{current_time}'\n",
    "# iter_acc_file_name = f'result_save/{base_name}_iter_acc_array_{unique_name}.npy'\n",
    "# val_acc_file_name = f'result_save/{base_name}_val_acc_now_array_{unique_name}.npy'\n",
    "# hyperparameters_file_name = f'result_save/{base_name}_hyperparameters_{unique_name}.json'\n",
    "\n",
    "# ### if you want to just see most recent train and val acc###########################\n",
    "# iter_acc_file_name = f'result_save/iter_acc_array_{unique_name}.npy'\n",
    "# tr_acc_file_name = f'result_save/tr_acc_array_{unique_name}.npy'\n",
    "# val_acc_file_name = f'result_save/val_acc_now_array_{unique_name}.npy'\n",
    "# hyperparameters_file_name = f'result_save/hyperparameters_{unique_name}.json'\n",
    "\n",
    "# loaded_iter_acc_array = np.load(iter_acc_file_name)*100\n",
    "# loaded_tr_acc_array = np.load(tr_acc_file_name)*100\n",
    "# loaded_val_acc_array = np.load(val_acc_file_name)*100\n",
    "# hyperparameters = load_hyperparameters(hyperparameters_file_name)\n",
    "\n",
    "# loaded_iter_acc_array, loaded_val_acc_array = pad_array_to_match_length(loaded_iter_acc_array, loaded_val_acc_array)\n",
    "# loaded_iter_acc_array, loaded_tr_acc_array = pad_array_to_match_length(loaded_iter_acc_array, loaded_tr_acc_array)\n",
    "# loaded_val_acc_array, loaded_tr_acc_array = pad_array_to_match_length(loaded_val_acc_array, loaded_tr_acc_array)\n",
    "\n",
    "# top_iter_acc = np.max(loaded_iter_acc_array)\n",
    "# top_tr_acc = np.max(loaded_tr_acc_array)\n",
    "# top_val_acc = np.max(loaded_val_acc_array)\n",
    "\n",
    "# which_data = hyperparameters['which_data']\n",
    "# BPTT_on = hyperparameters['BPTT_on']\n",
    "# current_epoch = hyperparameters['current epoch']\n",
    "# surrogate = hyperparameters['surrogate']\n",
    "# cfg = hyperparameters['cfg']\n",
    "# tdBN_on = hyperparameters['tdBN_on']\n",
    "# BN_on = hyperparameters['BN_on']\n",
    "\n",
    "\n",
    "# iterations = np.arange(len(loaded_iter_acc_array))\n",
    "\n",
    "# # 그래프 그리기\n",
    "# plt.figure(figsize=(10, 5))\n",
    "# plt.plot(iterations, loaded_iter_acc_array, label='Iter Accuracy', color='g', alpha=0.2)\n",
    "# plt.plot(iterations, loaded_tr_acc_array, label='Training Accuracy', color='b')\n",
    "# plt.plot(iterations, loaded_val_acc_array, label='Validation Accuracy', color='r')\n",
    "\n",
    "# # # 텍스트 추가\n",
    "# # plt.text(0.05, 0.95, f'Top Training Accuracy: {100*top_iter_acc:.2f}%', transform=plt.gca().transAxes, fontsize=12, verticalalignment='top', horizontalalignment='left', color='blue')\n",
    "# # plt.text(0.05, 0.90, f'Top Validation Accuracy: {100*top_val_acc:.2f}%', transform=plt.gca().transAxes, fontsize=12, verticalalignment='top', horizontalalignment='left', color='red')\n",
    "# # 텍스트 추가\n",
    "# plt.text(0.5, 0.10, f'Top Training Accuracy: {top_tr_acc:.2f}%', transform=plt.gca().transAxes, fontsize=12, verticalalignment='top', horizontalalignment='center', color='blue')\n",
    "# plt.text(0.5, 0.05, f'Top Validation Accuracy: {top_val_acc:.2f}%', transform=plt.gca().transAxes, fontsize=12, verticalalignment='top', horizontalalignment='center', color='red')\n",
    "\n",
    "# plt.xlabel('Iterations')\n",
    "# plt.ylabel('Accuracy [%]')\n",
    "\n",
    "# # 그래프 제목에 하이퍼파라미터 정보 추가\n",
    "# title = f'Training and Validation Accuracy over Iterations\\n\\nData: {which_data}, BPTT: {\"On\" if BPTT_on else \"Off\"}, Current Epoch: {current_epoch}, Surrogate: {surrogate},\\nCFG: {cfg}, tdBN: {\"On\" if tdBN_on else \"Off\"}, BN: {\"On\" if BN_on else \"Off\"}'\n",
    "\n",
    "# plt.title(title)\n",
    "\n",
    "# plt.legend(loc='lower right')\n",
    "# plt.xlim(0)  # x축을 0부터 시작\n",
    "# plt.grid(True)\n",
    "# plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nfs",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
