{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_14638/3748606120.py:46: DeprecationWarning: The module snntorch.spikevision is deprecated. For loading neuromorphic datasets, we recommend using the Tonic project: https://github.com/neuromorphs/tonic\n",
      "  from snntorch.spikevision import spikedata\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x600 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "import argparse\n",
    "import torch\n",
    "import torch.nn as nn \n",
    "import torch.nn.functional as F\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.optim as optim\n",
    "import torch.optim.lr_scheduler as lr_scheduler\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "import torchvision\n",
    "import torchvision.datasets\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import time\n",
    "\n",
    "from snntorch import spikegen\n",
    "import matplotlib.pyplot as plt\n",
    "import snntorch.spikeplot as splt\n",
    "from IPython.display import HTML\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "from apex.parallel import DistributedDataParallel as DDP\n",
    "\n",
    "import random\n",
    "import datetime\n",
    "\n",
    "import json\n",
    "\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "''' Î†àÌçºÎü∞Ïä§\n",
    "https://spikingjelly.readthedocs.io/zh-cn/0.0.0.0.4/spikingjelly.datasets.html#module-spikingjelly.datasets\n",
    "https://github.com/GorkaAbad/Sneaky-Spikes/blob/main/datasets.py\n",
    "https://github.com/GorkaAbad/Sneaky-Spikes/blob/main/how_to.md\n",
    "https://github.com/nmi-lab/torchneuromorphic\n",
    "https://snntorch.readthedocs.io/en/latest/snntorch.spikevision.spikedata.html#shd\n",
    "'''\n",
    "\n",
    "import snntorch\n",
    "from snntorch.spikevision import spikedata\n",
    "\n",
    "import modules.spikingjelly;\n",
    "from modules.spikingjelly.datasets.dvs128_gesture import DVS128Gesture\n",
    "from modules.spikingjelly.datasets.cifar10_dvs import CIFAR10DVS\n",
    "from modules.spikingjelly.datasets.n_mnist import NMNIST\n",
    "# from modules.spikingjelly.datasets.es_imagenet import ESImageNet\n",
    "from modules.spikingjelly.datasets import split_to_train_test_set\n",
    "from modules.spikingjelly.datasets.n_caltech101 import NCaltech101\n",
    "from modules.spikingjelly.datasets import pad_sequence_collate, padded_sequence_mask\n",
    "\n",
    "import modules.torchneuromorphic as torchneuromorphic\n",
    "\n",
    "import wandb\n",
    "\n",
    "from torchviz import make_dot\n",
    "import graphviz\n",
    "from turtle import shape\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# my module import\n",
    "from modules import *\n",
    "\n",
    "# modules Ìè¥ÎçîÏóê ÏÉàÎ™®Îìà.py ÎßåÎì§Î©¥\n",
    "# modules/__init__py ÌååÏùºÏóê form .ÏÉàÎ™®Îìà import * ÌïòÏÖà\n",
    "# Í∑∏Î¶¨Í≥† ÏÉàÎ™®Îìà.pyÏóêÏÑú from modules.ÏÉàÎ™®Îìà import * ÌïòÏÖà\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "from matplotlib.ft2font import EXTERNAL_STREAM\n",
    "\n",
    "\n",
    "def my_snn_system(devices = \"0,1,2,3\",\n",
    "                    single_step = False, # True # False\n",
    "                    unique_name = 'main',\n",
    "                    my_seed = 42,\n",
    "                    TIME = 10,\n",
    "                    BATCH = 256,\n",
    "                    IMAGE_SIZE = 32,\n",
    "                    which_data = 'CIFAR10',\n",
    "                    # CLASS_NUM = 10,\n",
    "                    data_path = '/data2',\n",
    "                    rate_coding = True,\n",
    "    \n",
    "                    lif_layer_v_init = 0.0,\n",
    "                    lif_layer_v_decay = 0.6,\n",
    "                    lif_layer_v_threshold = 1.2,\n",
    "                    lif_layer_v_reset = 0.0,\n",
    "                    lif_layer_sg_width = 1,\n",
    "\n",
    "                    # synapse_conv_in_channels = IMAGE_PIXEL_CHANNEL,\n",
    "                    synapse_conv_kernel_size = 3,\n",
    "                    synapse_conv_stride = 1,\n",
    "                    synapse_conv_padding = 1,\n",
    "\n",
    "                    synapse_trace_const1 = 1,\n",
    "                    synapse_trace_const2 = 0.6,\n",
    "\n",
    "                    # synapse_fc_out_features = CLASS_NUM,\n",
    "\n",
    "                    pre_trained = False,\n",
    "                    convTrue_fcFalse = True,\n",
    "\n",
    "                    cfg = [64, 64],\n",
    "                    net_print = False, # True # False\n",
    "                    \n",
    "                    pre_trained_path = \"net_save/save_now_net.pth\",\n",
    "                    learning_rate = 0.0001,\n",
    "                    epoch_num = 200,\n",
    "                    tdBN_on = False,\n",
    "                    BN_on = False,\n",
    "\n",
    "                    surrogate = 'sigmoid',\n",
    "\n",
    "                    BPTT_on = False,\n",
    "\n",
    "                    optimizer_what = 'SGD', # 'SGD' 'Adam', 'RMSprop'\n",
    "                    scheduler_name = 'no',\n",
    "                    \n",
    "                    ddp_on = False, # DECREPATED # fALSE\n",
    "\n",
    "                    dvs_clipping = 1, \n",
    "                    dvs_duration = 25_000,\n",
    "\n",
    "\n",
    "                    DFA_on = False, # True # False\n",
    "                    trace_on = False, \n",
    "                    OTTT_input_trace_on = False, # True # False\n",
    "                    \n",
    "                    exclude_class = True, # True # False # gestureÏóêÏÑú 10Î≤àÏß∏ ÌÅ¥ÎûòÏä§ Ï†úÏô∏\n",
    "\n",
    "                    merge_polarities = False, # True # False # tonic dvs dataset ÏóêÏÑú polarities Ìï©ÏπòÍ∏∞\n",
    "                    denoise_on = True, \n",
    "\n",
    "                    extra_train_dataset = 0, # DECREPATED # data_loaderÏóêÏÑú train datasetÏùÑ Î™áÍ∞ú Îçî Ïì∏Í±¥ÏßÄ \n",
    "\n",
    "                    num_workers = 2,\n",
    "                    chaching_on = True,\n",
    "                    pin_memory = True, # True # False\n",
    "                    \n",
    "                    UDA_on = False,  # DECREPATED # uda\n",
    "                    alpha_uda = 1.0, # DECREPATED # uda\n",
    "\n",
    "                    bias = True,\n",
    "\n",
    "                    last_lif = False,\n",
    "                        \n",
    "                    temporal_filter = 1, \n",
    "                    initial_pooling = 1,\n",
    "\n",
    "                    temporal_filter_accumulation = False,\n",
    "\n",
    "                    quantize_bit_list=[],\n",
    "                    scale_exp=[],\n",
    "                    ):\n",
    "    ## Ìï®Ïàò ÎÇ¥ Î™®Îì† Î°úÏª¨ Î≥ÄÏàò Ï†ÄÏû• ########################################################\n",
    "    hyperparameters = locals()\n",
    "    print('param', hyperparameters,'\\n')\n",
    "    hyperparameters['current epoch'] = 0\n",
    "    ######################################################################################\n",
    "\n",
    "    ## hyperparameter check #############################################################\n",
    "    if single_step == True:\n",
    "        assert BPTT_on == False and tdBN_on == False \n",
    "    if tdBN_on == True:\n",
    "        assert BPTT_on == True\n",
    "    if pre_trained == True:\n",
    "        print('\\n\\n')\n",
    "        print(\"Caution! pre_trained is True\\n\\n\"*3)    \n",
    "    if DFA_on == True:\n",
    "        assert single_step == True and BPTT_on == False \n",
    "    # assert single_step == DFA_on, 'DFAÎûë single_stepÍ≥µÏ°¥ÌïòÍ≤åÌï¥Îùº'\n",
    "    if trace_on:\n",
    "        assert BPTT_on == False and single_step == True\n",
    "    if OTTT_input_trace_on == True:\n",
    "        assert BPTT_on == False and single_step == True #and trace_on == True\n",
    "    if temporal_filter > 1:\n",
    "        assert convTrue_fcFalse == False\n",
    "    ######################################################################################\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "    ## wandb ÏÑ∏ÌåÖ ###################################################################\n",
    "    current_time = datetime.datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "    wandb.config.update(hyperparameters)\n",
    "    wandb.run.name = f'lr_{learning_rate}_{unique_name}_{which_data}_tstep{TIME}'\n",
    "    wandb.define_metric(\"summary_val_acc\", summary=\"max\")\n",
    "    # wandb.run.log_code(\".\", \n",
    "    #                     include_fn=lambda path: path.endswith(\".py\") or path.endswith(\".ipynb\"),\n",
    "    #                     exclude_fn=lambda path: 'logs/' in path or 'net_save/' in path or 'result_save/' in path or 'trying/' in path or 'wandb/' in path or 'private/' in path or '.git/' in path or 'tonic' in path or 'torchneuromorphic' in path or 'spikingjelly' in path \n",
    "    #                     )\n",
    "    ###################################################################################\n",
    "\n",
    "\n",
    "\n",
    "    ## gpu setting ##################################################################################################################\n",
    "    os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\" \n",
    "    os.environ[\"CUDA_VISIBLE_DEVICES\"]= devices\n",
    "    ###################################################################################################################################\n",
    "\n",
    "\n",
    "    ## seed setting ##################################################################################################################\n",
    "    seed_assign(my_seed)\n",
    "    ###################################################################################################################################\n",
    "    \n",
    "\n",
    "    ## data_loader Í∞ÄÏ†∏Ïò§Í∏∞ ##################################################################################################################\n",
    "    # data loader, pixel channel, class num\n",
    "    train_data_split_indices = []\n",
    "    train_loader, test_loader, synapse_conv_in_channels, CLASS_NUM, train_data_count = data_loader(\n",
    "            which_data,\n",
    "            data_path, \n",
    "            rate_coding, \n",
    "            BATCH, \n",
    "            IMAGE_SIZE,\n",
    "            ddp_on,\n",
    "            TIME*temporal_filter, \n",
    "            dvs_clipping,\n",
    "            dvs_duration,\n",
    "            exclude_class,\n",
    "            merge_polarities,\n",
    "            denoise_on,\n",
    "            my_seed,\n",
    "            extra_train_dataset,\n",
    "            num_workers,\n",
    "            chaching_on,\n",
    "            pin_memory,\n",
    "            train_data_split_indices,) \n",
    "    synapse_fc_out_features = CLASS_NUM\n",
    "\n",
    "    print('\\nlen(train_loader):', len(train_loader), 'BATCH:', BATCH, 'train_data_count:', train_data_count) \n",
    "    print('len(test_loader):', len(test_loader), 'BATCH:', BATCH)\n",
    "\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    print(f\"\\ndevice ==> {device}\\n\")\n",
    "    if device == \"cpu\":\n",
    "        print(\"=\"*50,\"\\n[WARNING]\\n[WARNING]\\n[WARNING]\\n: cpu mode\\n\\n\",\"=\"*50)\n",
    "\n",
    "    ### network setting #######################################################################################################################\n",
    "    if (convTrue_fcFalse == False):\n",
    "        net = REBORN_MY_SNN_FC(cfg, synapse_conv_in_channels*temporal_filter, IMAGE_SIZE//initial_pooling, synapse_fc_out_features,\n",
    "                    synapse_trace_const1, synapse_trace_const2, \n",
    "                    lif_layer_v_init, lif_layer_v_decay, \n",
    "                    lif_layer_v_threshold, lif_layer_v_reset,\n",
    "                    lif_layer_sg_width,\n",
    "                    tdBN_on,\n",
    "                    BN_on, TIME,\n",
    "                    surrogate,\n",
    "                    BPTT_on,\n",
    "                    DFA_on,\n",
    "                    bias,\n",
    "                    single_step,\n",
    "                    last_lif,\n",
    "                    trace_on,\n",
    "                    quantize_bit_list,\n",
    "                    scale_exp).to(device)\n",
    "    else:\n",
    "        net = REBORN_MY_SNN_CONV(cfg, synapse_conv_in_channels, IMAGE_SIZE//initial_pooling,\n",
    "                    synapse_conv_kernel_size, synapse_conv_stride, \n",
    "                    synapse_conv_padding, synapse_trace_const1, \n",
    "                    synapse_trace_const2, \n",
    "                    lif_layer_v_init, lif_layer_v_decay, \n",
    "                    lif_layer_v_threshold, lif_layer_v_reset,\n",
    "                    lif_layer_sg_width,\n",
    "                    synapse_fc_out_features, \n",
    "                    tdBN_on,\n",
    "                    BN_on, TIME,\n",
    "                    surrogate,\n",
    "                    BPTT_on,\n",
    "                    DFA_on,\n",
    "                    bias,\n",
    "                    single_step,\n",
    "                    last_lif,\n",
    "                    trace_on,\n",
    "                    quantize_bit_list,\n",
    "                    scale_exp).to(device)\n",
    "\n",
    "    net = torch.nn.DataParallel(net) \n",
    "    \n",
    "    if pre_trained == True:\n",
    "        # 1. Ï†ÑÏ≤¥ state_dict Î°úÎìú\n",
    "        checkpoint = torch.load(pre_trained_path)\n",
    "\n",
    "        # 2. ÌòÑÏû¨ Î™®Îç∏Ïùò state_dict Í∞ÄÏ†∏Ïò§Í∏∞\n",
    "        model_dict = net.state_dict()\n",
    "\n",
    "        # 3. 'SYNAPSE'Í∞Ä Ìè¨Ìï®Îêú keyÎßå ÌïÑÌÑ∞ÎßÅ (ÌòÑÏû¨ Î™®Îç∏ÏóêÎèÑ Ï°¥Ïû¨ÌïòÎäî keyÎßå)\n",
    "        filtered_dict = {k: v for k, v in checkpoint.items() if ('weight' in k or 'bias' in k) and k in model_dict}\n",
    "\n",
    "        # 4. ÏóÖÎç∞Ïù¥Ìä∏Îêú ÌÇ§ Ï∂úÎ†•\n",
    "        print(\"üîÑ ÏóÖÎç∞Ïù¥Ìä∏Îêú SYNAPSE Í¥ÄÎ†® Î†àÏù¥Ïñ¥Îì§:\")\n",
    "        for k in filtered_dict.keys():\n",
    "            print(f\" - {k}\")\n",
    "\n",
    "        # 5. Î™®Îç∏ dict ÏóÖÎç∞Ïù¥Ìä∏ Î∞è Î°úÎî©\n",
    "        model_dict.update(filtered_dict)\n",
    "        net.load_state_dict(model_dict)\n",
    "    \n",
    "    net = net.to(device)\n",
    "    if (net_print == True):\n",
    "        print(net)    \n",
    "\n",
    "    print(f\"\\n========================================================\\nTrainable parameters: {sum(p.numel() for p in net.parameters() if p.requires_grad):,}\\n========================================================\\n\")\n",
    "    ####################################################################################################################################\n",
    "    \n",
    "\n",
    "    ## wandb logging ###########################################\n",
    "    # wandb.watch(net, log=\"all\", log_freq = 10) #gradient, parameter loggingÌï¥Ï§å\n",
    "    ############################################################\n",
    "\n",
    "    ## criterion ########################################## # loss Íµ¨Ìï¥Ï£ºÎäî ÏπúÍµ¨\n",
    "    def my_cross_entropy_loss(logits, targets):\n",
    "        # logits: (batch_size, num_classes)\n",
    "        # targets: (batch_size,) -> ÌÅ¥ÎûòÏä§ Ïù∏Îç±Ïä§\n",
    "        log_probs = F.log_softmax(logits, dim=1)  # log(p_i)\n",
    "        loss = F.nll_loss(log_probs, targets)\n",
    "        # print(loss.shape)\n",
    "        return loss\n",
    "    \n",
    "    class CustomLossFunction(torch.autograd.Function):\n",
    "        @staticmethod\n",
    "        def forward(ctx, input, target):\n",
    "            ctx.save_for_backward(input, target)\n",
    "            return F.cross_entropy(input, target)\n",
    "\n",
    "        @staticmethod\n",
    "        def backward(ctx, grad_output):\n",
    "            # MAE Ïä§ÌÉÄÏùºÏùò gradientÎ•º ÌùâÎÇ¥ÎÉÑ\n",
    "            input, target = ctx.saved_tensors\n",
    "            input_argmax = input.argmax(dim=1)\n",
    "            input_one_hot = torch.zeros_like(input).scatter_(1, input_argmax.unsqueeze(1), 1.0)\n",
    "            target_one_hot = torch.zeros_like(input).scatter_(1, target.unsqueeze(1), 1.0)\n",
    "\n",
    "            # print('grad_output', grad_output) # Ïù¥Í±∞ Í±ç 1.0ÏûÑ\n",
    "            return input_one_hot - target_one_hot, None  # targetÏóêÎäî gradient ÏóÜÏùå\n",
    "\n",
    "    # Wrapper module\n",
    "    class CustomCriterion(torch.nn.Module):\n",
    "        def __init__(self):\n",
    "            super().__init__()\n",
    "\n",
    "        def forward(self, input, target):\n",
    "            return CustomLossFunction.apply(input, target)\n",
    "\n",
    "    # class CustomCriterion_mseloss(torch.autograd.Function):\n",
    "    #     @staticmethod\n",
    "    #     def forward(ctx, input, target):\n",
    "    #         \"\"\"\n",
    "    #         input: (batch_size, num_classes)\n",
    "    #         target: (batch_size,) -> ÌÅ¥ÎûòÏä§ Ïù∏Îç±Ïä§\n",
    "    #         \"\"\"\n",
    "    #         # targetÏùÑ one-hot Î≤°ÌÑ∞Î°ú Î≥ÄÌôò\n",
    "    #         target_one_hot = torch.zeros_like(input)\n",
    "    #         target_one_hot.scatter_(1, target.unsqueeze(1), 1.0)\n",
    "\n",
    "    #         ctx.save_for_backward(input, target_one_hot)\n",
    "            \n",
    "    #         # MSE Í≥ÑÏÇ∞\n",
    "    #         loss = F.mse_loss(input, target_one_hot, reduction='mean')\n",
    "    #         return loss\n",
    "\n",
    "    #     @staticmethod\n",
    "    #     def backward(ctx, grad_output):\n",
    "    #         input, target_one_hot = ctx.saved_tensors\n",
    "    #         # MSE gradient: 2 * (input - target) / N\n",
    "    #         N = input.numel()\n",
    "    #         grad_input = 2 * (input - target_one_hot) / N\n",
    "    #         # grad_input = grad_input * grad_output  # chain rule\n",
    "    #         return grad_input, None  # targetÏóêÎäî gradient ÏóÜÏùå\n",
    "        \n",
    "    # Wrapper module\n",
    "    class CustomCriterionMSE(nn.Module):\n",
    "        def __init__(self):\n",
    "            super().__init__()\n",
    "\n",
    "        def forward(self, input, target):\n",
    "            # return CustomCriterion_mseloss.apply(input, target)\n",
    "\n",
    "            # targetÏùÑ one-hot Î≤°ÌÑ∞Î°ú Î≥ÄÌôò\n",
    "            target_one_hot = torch.zeros_like(input)\n",
    "            target_one_hot.scatter_(1, target.unsqueeze(1), 1.0)\n",
    "\n",
    "            # MSE Í≥ÑÏÇ∞\n",
    "            loss = F.mse_loss(input, target_one_hot, reduction='mean')\n",
    "            # print(f'input {input}', f'target_one_hot {target_one_hot}', f'loss {loss}')\n",
    "            return loss\n",
    "\n",
    "    # criterion = nn.CrossEntropyLoss().to(device)\n",
    "    # criterion = CustomCriterion().to(device)\n",
    "    criterion = CustomCriterionMSE().to(device)\n",
    "    \n",
    "    # if (OTTT_sWS_on == True):\n",
    "    #     # criterion = nn.CrossEntropyLoss().to(device)\n",
    "        # criterion = lambda y_t, target_t: ((1 - 0.05) * F.cross_entropy(y_t, target_t) + 0.05 * F.mse_loss(y_t, F.one_hot(target_t, CLASS_NUM).float())) / TIME \n",
    "    #     if which_data == 'DVS_GESTURE':\n",
    "    #         criterion = lambda y_t, target_t: ((1 - 0.001) * F.cross_entropy(y_t, target_t) + 0.001 * F.mse_loss(y_t, F.one_hot(target_t, CLASS_NUM).float())) / TIME \n",
    "    ####################################################\n",
    "\n",
    "    ## optimizer, scheduler ########################################################################\n",
    "    class MySGD(torch.optim.Optimizer):\n",
    "        def __init__(self, params, lr=0.01, momentum=0.0, quantize_bit_list=[], scale_exp=[], net=None):\n",
    "            if momentum < 0.0 or momentum >= 1.0:\n",
    "                raise ValueError(f\"Invalid momentum value: {momentum}\")\n",
    "            \n",
    "            defaults = {'lr': lr, 'momentum': momentum}\n",
    "            super(MySGD, self).__init__(params, defaults)\n",
    "            self.step_count = 0\n",
    "            self.quantize_bit_list = quantize_bit_list\n",
    "            # self.quantize_bit_list = []\n",
    "            self.scale_exp = scale_exp\n",
    "            self.param_to_name = {param: name for name, param in net.module.named_parameters()} if net else {}\n",
    "\n",
    "        @torch.no_grad()\n",
    "        def step(self):\n",
    "            \"\"\"Î™®Îì† ÌååÎùºÎØ∏ÌÑ∞Ïóê ÎåÄÌï¥ gradient descent ÏàòÌñâ\"\"\"\n",
    "            loss = None\n",
    "            for group in self.param_groups:\n",
    "                lr = group['lr']\n",
    "                momentum = group['momentum']\n",
    "                for param in group['params']:\n",
    "                    if param.grad is None:\n",
    "                        continue\n",
    "                    name = self.param_to_name.get(param, 'unknown')\n",
    "                    # gradientÎ•º Ïù¥Ïö©Ìï¥ ÌååÎùºÎØ∏ÌÑ∞ ÏóÖÎç∞Ïù¥Ìä∏\n",
    "                    d_p = param.grad\n",
    "\n",
    "                    if momentum > 0.0:\n",
    "                        param_state = self.state[param]\n",
    "                        if 'momentum_buffer' not in param_state:\n",
    "                            # momentum buffer Ï¥àÍ∏∞Ìôî\n",
    "                            buf = param_state['momentum_buffer'] = torch.clone(d_p).detach()\n",
    "                        else:\n",
    "                            buf = param_state['momentum_buffer']\n",
    "                            buf.mul_(momentum).add_(d_p)\n",
    "                            # buf *= momentum \n",
    "                            # buf += d_p\n",
    "                        d_p = buf\n",
    "\n",
    "                    dw = -lr*d_p\n",
    "                                        \n",
    "                    # if 'layers.7.fc.weight' in name or 'layers.7.fc.bias' in name:\n",
    "                    #     dw = dw * 0.5\n",
    "\n",
    "                    if len(self.quantize_bit_list) != 0:\n",
    "                        if 'layers.1.fc.weight' in name:\n",
    "                            dw_bit = self.quantize_bit_list[0]\n",
    "                            if self.scale_exp != []:\n",
    "                                exp = self.scale_exp[0][0]\n",
    "                                scale_dw = 2**exp\n",
    "                            else:\n",
    "                                max_dw = dw.abs().max().item()\n",
    "                                assert max_dw > 0, f\"max_dw is zero for parameter {param.name if hasattr(param, 'name') else 'unknown'}\"\n",
    "                                scale_dw = 2**math.ceil(math.log2(max_dw / (2**(dw_bit-1) -1)))\n",
    "                        elif 'layers.1.fc.bias' in name:\n",
    "                            dw_bit = self.quantize_bit_list[0]\n",
    "                            if self.scale_exp != []:\n",
    "                                exp = self.scale_exp[0][1]\n",
    "                                scale_dw = 2**exp\n",
    "                            else:\n",
    "                                max_dw = dw.abs().max().item()\n",
    "                                assert max_dw > 0, f\"max_dw is zero for parameter {param.name if hasattr(param, 'name') else 'unknown'}\"\n",
    "                                scale_dw = 2**math.ceil(math.log2(max_dw / (2**(dw_bit-1) -1)))\n",
    "                        elif 'layers.4.fc.weight' in name:\n",
    "                            dw_bit = self.quantize_bit_list[1]\n",
    "                            if self.scale_exp != []:\n",
    "                                exp = self.scale_exp[1][0]\n",
    "                                scale_dw = 2**exp\n",
    "                            else:\n",
    "                                max_dw = dw.abs().max().item()\n",
    "                                assert max_dw > 0, f\"max_dw is zero for parameter {param.name if hasattr(param, 'name') else 'unknown'}\"\n",
    "                                scale_dw = 2**math.ceil(math.log2(max_dw / (2**(dw_bit-1) -1)))\n",
    "                        elif 'layers.4.fc.bias' in name:\n",
    "                            dw_bit = self.quantize_bit_list[1]\n",
    "                            if self.scale_exp != []:\n",
    "                                exp = self.scale_exp[1][1]\n",
    "                                scale_dw = 2**exp\n",
    "                            else:\n",
    "                                max_dw = dw.abs().max().item()\n",
    "                                assert max_dw > 0, f\"max_dw is zero for parameter {param.name if hasattr(param, 'name') else 'unknown'}\"\n",
    "                                scale_dw = 2**math.ceil(math.log2(max_dw / (2**(dw_bit-1) -1)))\n",
    "                        elif 'layers.7.fc.weight' in name:\n",
    "                            dw_bit = self.quantize_bit_list[2]\n",
    "                            if self.scale_exp != []:\n",
    "                                exp = self.scale_exp[2][0]\n",
    "                                scale_dw = 2**exp\n",
    "                            else:\n",
    "                                max_dw = dw.abs().max().item()\n",
    "                                assert max_dw > 0, f\"max_dw is zero for parameter {param.name if hasattr(param, 'name') else 'unknown'}\"\n",
    "                                scale_dw = 2**math.ceil(math.log2(max_dw / (2**(dw_bit-1) -1)))\n",
    "                        elif 'layers.7.fc.bias' in name:\n",
    "                            dw_bit = self.quantize_bit_list[2]\n",
    "                            if self.scale_exp != []:\n",
    "                                exp = self.scale_exp[2][1]\n",
    "                                scale_dw = 2**exp\n",
    "                                \n",
    "                            else:\n",
    "                                max_dw = dw.abs().max().item()\n",
    "                                assert max_dw > 0, f\"max_dw is zero for parameter {param.name if hasattr(param, 'name') else 'unknown'}\"\n",
    "                                scale_dw = 2**math.ceil(math.log2(max_dw / (2**(dw_bit-1) -1)))\n",
    "                        else:\n",
    "                            assert False, f\"Unknown parameter name: {name}\"\n",
    "\n",
    "\n",
    "                        # print(f'dw_bit{dw_bit}, exp{exp}')\n",
    "                        # print(f'name {name}, d_p: {d_p.shape}, unique elements: {d_p.unique().numel()}, values: {d_p.unique().tolist()}')\n",
    "                        # print(f'name {name}, dw: {dw.shape}, unique elements: {dw.unique().numel()}, values: {dw.unique().tolist()}')\n",
    "                        # dw = torch.clamp((dw / scale_dw + 0).round(), -2**(dw_bit-1) + 1, 2**(dw_bit-1) - 1) * scale_dw\n",
    "                        dw = torch.clamp(round_away_from_zero(dw / scale_dw + 0), -2**(dw_bit-1) + 1, 2**(dw_bit-1) - 1) * scale_dw\n",
    "                        # print(f'name {name}, dw_post: {dw.shape}, unique elements: {dw.unique().numel()}, values: {dw.unique().tolist()}')\n",
    "\n",
    "                    if 'layers.1.fc.weight' in name:\n",
    "                        ooo_fifo = 2\n",
    "                    elif 'layers.3.fc.weight' in name:\n",
    "                        ooo_fifo = 1\n",
    "                    elif 'layers.5.fc.weight' in name:\n",
    "                        ooo_fifo = 0\n",
    "                    else:\n",
    "                        assert False\n",
    "                        \n",
    "                    if ooo_fifo > 0:\n",
    "                        # ====== FIFO Ï≤òÎ¶¨ ======\n",
    "                        param_state = self.state[param]\n",
    "                        if 'fifo_buffer' not in param_state:\n",
    "                            param_state['fifo_buffer'] = []\n",
    "\n",
    "                        fifo = param_state['fifo_buffer']\n",
    "                        fifo.append(dw.clone())  # clone() to detach from current graph\n",
    "\n",
    "                        if len(fifo) == ooo_fifo+1:\n",
    "                            oldest_dw = fifo.pop(0)\n",
    "                            param.add_(oldest_dw)\n",
    "                    else: \n",
    "                        param.add_(dw)\n",
    "                        # param -= dw ÏúÑ Ïó∞ÏÇ∞Ïù¥Îûë Îã§Î¶Ñ. inmemoryÏó∞ÏÇ∞Ïù¥Îùº Ï¢Ä Îã§Î•∏ ÎìØ\n",
    "            return loss\n",
    "    \n",
    "    if(optimizer_what == 'SGD'):\n",
    "        optimizer = MySGD(net.parameters(), lr=learning_rate, momentum=0.0, quantize_bit_list=quantize_bit_list, scale_exp=scale_exp, net=net)\n",
    "        # optimizer = optim.SGD(net.parameters(), lr=learning_rate, momentum=0.0)\n",
    "        print(optimizer)\n",
    "    elif(optimizer_what == 'Adam'):\n",
    "        optimizer = torch.optim.Adam(net.parameters(), lr=learning_rate)\n",
    "        # optimizer = torch.optim.Adam(net.parameters(), lr=0.00001)\n",
    "        # optimizer = torch.optim.Adam(net.parameters(), lr=learning_rate/256 * BATCH, weight_decay=1e-4)\n",
    "        # optimizer = optim.Adam(net.parameters(), lr=learning_rate, weight_decay=0, betas=(0.9, 0.999))\n",
    "    elif(optimizer_what == 'RMSprop'):\n",
    "        pass\n",
    "\n",
    "\n",
    "    if (scheduler_name == 'StepLR'):\n",
    "        scheduler = lr_scheduler.StepLR(optimizer, step_size=10, gamma=0.1)\n",
    "    elif (scheduler_name == 'ExponentialLR'):\n",
    "        scheduler = lr_scheduler.ExponentialLR(optimizer, gamma=0.95)\n",
    "    elif (scheduler_name == 'ReduceLROnPlateau'):\n",
    "        scheduler = lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.1, patience=10)\n",
    "    elif (scheduler_name == 'CosineAnnealingLR'):\n",
    "        # scheduler = lr_scheduler.CosineAnnealingLR(optimizer, eta_min=0, T_max=50)\n",
    "        scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, eta_min=0, T_max=epoch_num)\n",
    "    elif (scheduler_name == 'OneCycleLR'):\n",
    "        scheduler = lr_scheduler.OneCycleLR(optimizer, max_lr=0.1, steps_per_epoch=len(train_loader), epochs=epoch_num)\n",
    "    else:\n",
    "        pass # 'no' scheduler\n",
    "    ## optimizer, scheduler ########################################################################\n",
    "\n",
    "\n",
    "    tr_acc = 0\n",
    "    tr_correct = 0\n",
    "    tr_total = 0\n",
    "    tr_acc_best = 0\n",
    "    tr_epoch_loss_temp = 0\n",
    "    tr_epoch_loss = 0\n",
    "    val_acc_best = 0\n",
    "    val_acc_now = 0\n",
    "    val_loss = 0\n",
    "    iter_of_val = False\n",
    "    total_backward_count = 0\n",
    "    real_backward_count = 0\n",
    "    #======== EPOCH START ==========================================================================================\n",
    "    for epoch in range(epoch_num):\n",
    "        epoch_start_time = time.time()\n",
    "        print('total_backward_count', total_backward_count, 'real_backward_count',real_backward_count, f'{100*real_backward_count/(total_backward_count+0.00000001):7.3f}%')\n",
    "        if epoch == 1:\n",
    "            for name, module in net.named_modules():\n",
    "                if isinstance(module, Feedback_Receiver):\n",
    "                    print(f\"[{name}] weight_fb parameter count: {module.weight_fb.numel():,}\")\n",
    "\n",
    "        max_val_box = []\n",
    "        max_val_scale_exp_8bit_box = []\n",
    "        max_val_scale_exp_16bit_box = []\n",
    "        perc_95_box = []\n",
    "        perc_95_scale_exp_8bit_box = []\n",
    "        perc_95_scale_exp_16bit_box = []\n",
    "        perc_99_box = []\n",
    "        perc_99_scale_exp_8bit_box = []\n",
    "        perc_99_scale_exp_16bit_box = []\n",
    "        perc_999_box = []\n",
    "        perc_999_scale_exp_8bit_box = []\n",
    "        perc_999_scale_exp_16bit_box = []\n",
    "        ##### weight ÌîÑÎ¶∞Ìä∏ ######################################################################\n",
    "        for name, param in net.module.named_parameters():\n",
    "            if ('weight' in name or 'bias' in name) and ('1' in name or '4' in name or '7' in name):\n",
    "                \n",
    "                data = param.detach().cpu().numpy().flatten()\n",
    "                abs_data = np.abs(data)\n",
    "\n",
    "                # ÌÜµÍ≥ÑÎüâ Í≥ÑÏÇ∞\n",
    "                mean = np.mean(data)\n",
    "                std = np.std(data)\n",
    "                abs_mean = np.mean(abs_data)\n",
    "                abs_std = np.std(abs_data)\n",
    "                eps = 1e-15\n",
    "\n",
    "                # Ï†àÎåÄÍ∞í Í∏∞Î∞ò max, percentiles\n",
    "                max_val = abs_data.max()\n",
    "                max_val_scale_exp_8bit = math.ceil(math.log2((eps+max_val)/ (2**(8-1) -1)))\n",
    "                max_val_scale_exp_16bit = math.ceil(math.log2((eps+max_val)/ (2**(16-1) -1)))\n",
    "                perc_95 = np.percentile(abs_data, 95)\n",
    "                perc_95_scale_exp_8bit = math.ceil(math.log2((eps+perc_95)/ (2**(8-1) -1)))\n",
    "                perc_95_scale_exp_16bit = math.ceil(math.log2((eps+perc_95)/ (2**(16-1) -1)))\n",
    "                perc_99 = np.percentile(abs_data, 99)\n",
    "                perc_99_scale_exp_8bit = math.ceil(math.log2((eps+perc_99)/ (2**(8-1) -1)))\n",
    "                perc_99_scale_exp_16bit = math.ceil(math.log2((eps+perc_99)/ (2**(16-1) -1)))\n",
    "                perc_999 = np.percentile(abs_data, 99.9)\n",
    "                perc_999_scale_exp_8bit = math.ceil(math.log2((eps+perc_999)/ (2**(8-1) -1)))\n",
    "                perc_999_scale_exp_16bit = math.ceil(math.log2((eps+perc_999)/ (2**(16-1) -1)))\n",
    "                \n",
    "                max_val_box.append(max_val)\n",
    "                max_val_scale_exp_8bit_box.append(max_val_scale_exp_8bit)\n",
    "                max_val_scale_exp_16bit_box.append(max_val_scale_exp_16bit)\n",
    "                perc_95_box.append(perc_95)\n",
    "                perc_95_scale_exp_8bit_box.append(perc_95_scale_exp_8bit)\n",
    "                perc_95_scale_exp_16bit_box.append(perc_95_scale_exp_16bit)\n",
    "                perc_99_box.append(perc_99)\n",
    "                perc_99_scale_exp_8bit_box.append(perc_99_scale_exp_8bit)\n",
    "                perc_99_scale_exp_16bit_box.append(perc_99_scale_exp_16bit)\n",
    "                perc_999_box.append(perc_999)\n",
    "                perc_999_scale_exp_8bit_box.append(perc_999_scale_exp_8bit)\n",
    "                perc_999_scale_exp_16bit_box.append(perc_999_scale_exp_16bit)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        ##### weight ÌîÑÎ¶∞Ìä∏ ######################################################################\n",
    "\n",
    "        ####### iterator : input_loading & tqdmÏùÑ ÌÜµÌïú progress_bar ÏÉùÏÑ±###################\n",
    "        iterator = enumerate(train_loader, 0)\n",
    "        # iterator = tqdm(iterator, total=len(train_loader), desc='train', dynamic_ncols=True, position=0, leave=True)\n",
    "        ##################################################################################   \n",
    "\n",
    "        ###### ITERATION START ##########################################################################################################\n",
    "        for i, data in iterator:\n",
    "            net.train() # train Î™®ÎìúÎ°ú Î∞îÍøîÏ§òÏïºÌï®\n",
    "            ### data loading & semi-pre-processing ################################################################################\n",
    "            if len(data) == 2:\n",
    "                inputs, labels = data\n",
    "                # Ï≤òÎ¶¨ Î°úÏßÅ ÏûëÏÑ±\n",
    "            elif len(data) == 3:\n",
    "                inputs, labels, x_len = data\n",
    "            else:\n",
    "                assert False, 'data length is not 2 or 3'\n",
    "            #######################################################################################################################\n",
    "            if extra_train_dataset == -1:\n",
    "                # print(inputs.shape)\n",
    "                assert BATCH == 1\n",
    "                now_T = inputs.shape[1]\n",
    "                now_time_steps = temporal_filter*TIME\n",
    "                # start_idx = random.randint(0, now_T - now_time_steps)\n",
    "                start_idx = random.choice(range(0, now_T - now_time_steps + 1, now_time_steps))\n",
    "                # start_idx = random.choice([i for i in range(0, now_T - now_time_steps + 1, now_time_steps)])\n",
    "                inputs = inputs[:, start_idx : start_idx + now_time_steps]\n",
    "                if dvs_clipping != 0:\n",
    "                    inputs[inputs<dvs_clipping] = 0.0\n",
    "                    inputs[inputs>=dvs_clipping] = 1.0\n",
    "            ## batch ÌÅ¨Í∏∞ ######################################\n",
    "            real_batch = labels.size(0)\n",
    "            ###########################################################\n",
    "\n",
    "            # Ï∞®Ïõê Ï†ÑÏ≤òÎ¶¨\n",
    "            ###########################################################################################################################        \n",
    "            if (which_data == 'DVS_CIFAR10' or which_data == 'DVS_GESTURE' or which_data == 'DVS_GESTURE_TONIC' or which_data == 'DVS_CIFAR10_2' or which_data == 'NMNIST' or which_data == 'NMNIST_TONIC' or which_data == 'N_CALTECH101' or which_data == 'n_tidigits' or which_data == 'heidelberg'):\n",
    "                inputs = inputs.permute(1, 0, 2, 3, 4)\n",
    "            elif rate_coding == True :\n",
    "                inputs = spikegen.rate(inputs, num_steps=TIME)\n",
    "            else :\n",
    "                inputs = inputs.repeat(TIME, 1, 1, 1, 1)\n",
    "            # inputs: [Time, Batch, Channel, Height, Width]  \n",
    "            ####################################################################################################################### \n",
    "                \n",
    "            # if i % 1000 == 999:\n",
    "            #     # SYNAPSE_FCÏóê ÏûàÎäî sparsity_print_and_reset() Ïã§Ìñâ\n",
    "            #     for name, module in net.module.named_modules():\n",
    "            #         if isinstance(module, SYNAPSE_FC):\n",
    "            #             module.sparsity_print_and_reset()\n",
    "\n",
    "                            \n",
    "            ## initial pooling #######################################################################\n",
    "            if (initial_pooling > 1):\n",
    "                pool = nn.MaxPool2d(kernel_size=2)\n",
    "                num_pooling_layers = int(math.log2(initial_pooling))\n",
    "                # Time, Batch, Channel Ï∞®ÏõêÏùÄ Í∑∏ÎåÄÎ°ú ÎëêÍ≥†, Height, Width Ï∞®ÏõêÏóê ÎåÄÌï¥ÏÑúÎßå pooling Ï†ÅÏö©\n",
    "                shape_temp = inputs.shape\n",
    "                inputs = inputs.reshape(shape_temp[0]*shape_temp[1], shape_temp[2], shape_temp[3], shape_temp[4])\n",
    "                for _ in range(num_pooling_layers):\n",
    "                    inputs = pool(inputs)\n",
    "                inputs = inputs.reshape(shape_temp[0], shape_temp[1], shape_temp[2], shape_temp[3]//initial_pooling, shape_temp[4]//initial_pooling)\n",
    "            ## initial pooling #######################################################################\n",
    "            ## temporal filtering ####################################################################\n",
    "            shape_temp = inputs.shape\n",
    "            if (temporal_filter > 1):\n",
    "                slice_bucket = []\n",
    "                for t_temp in range(TIME):\n",
    "                    start = t_temp * temporal_filter\n",
    "                    end = start + temporal_filter\n",
    "                    slice_concat = torch.movedim(inputs[start:end], 0, -2).reshape(shape_temp[1],shape_temp[2],shape_temp[3],-1)\n",
    "                    \n",
    "                    if temporal_filter_accumulation == True:\n",
    "                        if t_temp == 0:\n",
    "                            slice_bucket.append(slice_concat)\n",
    "                        else:\n",
    "                            slice_bucket.append(slice_concat+slice_bucket[t_temp-1])\n",
    "                    else:\n",
    "                        slice_bucket.append(slice_concat)\n",
    "\n",
    "                inputs = torch.stack(slice_bucket, dim=0)\n",
    "                if temporal_filter_accumulation == True and dvs_clipping > 0:\n",
    "                    inputs = (inputs != 0.0).float()\n",
    "            ## temporal filtering ####################################################################\n",
    "            ####################################################################################################################### \n",
    "                \n",
    "\n",
    "            # # dvs Îç∞Ïù¥ÌÑ∞ ÏãúÍ∞ÅÌôî ÏΩîÎìú (ÌôïÏù∏ ÌïÑÏöîÌï† Ïãú Ïç®Îùº)\n",
    "            # ##############################################################################################\n",
    "            # dvs_visualization(inputs, labels, TIME, BATCH, my_seed)\n",
    "            # #####################################################################################################\n",
    "\n",
    "            ## to (device) #######################################\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "            ###########################################################\n",
    "\n",
    "            # ## gradient Ï¥àÍ∏∞Ìôî #######################################\n",
    "            # optimizer.zero_grad()\n",
    "            # ###########################################################\n",
    "                            \n",
    "            if merge_polarities == True:\n",
    "                inputs = inputs[:,:,0:1,:,:]\n",
    "\n",
    "            if single_step == False:\n",
    "                # netÏóê ÎÑ£Ïñ¥Ï§ÑÎïåÎäî batchÍ∞Ä Ï†§ Ïïû Ï∞®ÏõêÏúºÎ°ú ÏôÄÏïºÌï®. # dataparallelÎïåÎß§##############################\n",
    "                # inputs: [Time, Batch, Channel, Height, Width]   \n",
    "                inputs = inputs.permute(1, 0, 2, 3, 4) # netÏóê ÎÑ£Ïñ¥Ï§ÑÎïåÎäî batchÍ∞Ä Ï†§ Ïïû Ï∞®ÏõêÏúºÎ°ú ÏôÄÏïºÌï®. # dataparallelÎïåÎß§\n",
    "                # inputs: [Batch, Time, Channel, Height, Width] \n",
    "                #################################################################################################\n",
    "            else:\n",
    "                labels = labels.repeat(TIME, 1)\n",
    "                ## first inputÎèÑ ottt trace Ï†ÅÏö©ÌïòÍ∏∞ ÏúÑÌïú ÏΩîÎìú (validation ÏãúÏóêÎäî ÌïÑÏöîX) ##########################\n",
    "                if trace_on == True and OTTT_input_trace_on == True:\n",
    "                    spike = inputs\n",
    "                    trace = torch.full_like(spike, fill_value = 0.0, dtype = torch.float, requires_grad=False)\n",
    "                    inputs = []\n",
    "                    for t in range(TIME):\n",
    "                        trace[t] = trace[t-1]*synapse_trace_const2 + spike[t]*synapse_trace_const1\n",
    "                        inputs += [[spike[t], trace[t]]]\n",
    "                ##################################################################################################\n",
    "\n",
    "\n",
    "            if single_step == False:\n",
    "                ### input --> net --> output #####################################################\n",
    "                outputs = net(inputs)\n",
    "                ##################################################################################\n",
    "                ## loss, backward ##########################################\n",
    "                iter_loss = criterion(outputs, labels)\n",
    "                iter_loss.backward()\n",
    "                ############################################################\n",
    "                ## weight ÏóÖÎç∞Ïù¥Ìä∏!! ##################################\n",
    "                optimizer.step()\n",
    "                ################################################################\n",
    "            else:\n",
    "                outputs_all = []\n",
    "                iter_loss = 0.0\n",
    "                for t in range(TIME):\n",
    "                    optimizer.step() # full step time update\n",
    "                    optimizer.zero_grad()\n",
    "                    ### input[t] --> net --> output_one_time #########################################\n",
    "                    outputs_one_time = net(inputs[t])\n",
    "                    ##################################################################################\n",
    "                    one_time_loss = criterion(outputs_one_time, labels[t].contiguous())\n",
    "                    one_time_loss.backward() # one_time backward\n",
    "                    iter_loss += one_time_loss.data\n",
    "                    outputs_all.append(outputs_one_time.detach())\n",
    "\n",
    "                    total_backward_count = total_backward_count + 1\n",
    "                    outputs_one_time_argmax = (outputs_one_time.detach()).argmax(dim=1)\n",
    "                    real_backward_count = real_backward_count + (outputs_one_time_argmax != labels[t]).sum().item()\n",
    "\n",
    "\n",
    "                outputs_all = torch.stack(outputs_all, dim=1)\n",
    "                outputs = outputs_all.mean(1) # otttÍ∫º Ïì∏Îïå\n",
    "                labels = labels[0]\n",
    "                iter_loss /= TIME\n",
    "\n",
    "            tr_epoch_loss_temp += iter_loss.data/len(train_loader)\n",
    "\n",
    "            ## net Í∑∏Î¶º Ï∂úÎ†•Ìï¥Î≥¥Í∏∞ #################################################################\n",
    "            # print('ÏãúÍ∞ÅÌôî')\n",
    "            # make_dot(outputs, params=dict(list(net.named_parameters()))).render(\"net_torchviz\", format=\"png\")\n",
    "            # return 0\n",
    "            ##################################################################################\n",
    "\n",
    "            #### batch Ïñ¥Í∏ãÎÇ® Î∞©ÏßÄ ###############################################\n",
    "            assert real_batch == outputs.size(0), f'batch size is not same. real_batch: {real_batch}, outputs.size(0): {outputs.size(0)}'\n",
    "            #######################################################################\n",
    "            \n",
    "\n",
    "            ####### training accruacy save for print ###############################\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total = real_batch\n",
    "            correct = (predicted == labels).sum().item()\n",
    "            iter_acc = correct / total\n",
    "            tr_total += total\n",
    "            tr_correct += correct\n",
    "            iter_acc_string = f'epoch-{epoch:<3} iter_acc:{100 * iter_acc:7.2f}%, lr={[f\"{lr:9.7f}\" for lr in (param_group[\"lr\"] for param_group in optimizer.param_groups)]}'\n",
    "            iter_acc_string2 = f'epoch-{epoch:<3} lr={[f\"{lr:9.7f}\" for lr in (param_group[\"lr\"] for param_group in optimizer.param_groups)]}'\n",
    "            ################################################################\n",
    "            \n",
    "\n",
    "            ##### validation ##################################################################################################################################\n",
    "            if i == len(train_loader)-1 :\n",
    "                iter_of_val = True\n",
    "\n",
    "                tr_acc = tr_correct/tr_total\n",
    "                tr_correct = 0\n",
    "                tr_total = 0\n",
    "\n",
    "                val_loss = 0\n",
    "                correct_val = 0\n",
    "                total_val = 0\n",
    "\n",
    "                with torch.no_grad():\n",
    "                    net.eval() # eval Î™®ÎìúÎ°ú Î∞îÍøîÏ§òÏïºÌï® \n",
    "                    for data_val in test_loader:\n",
    "                        ## data_val loading & semi-pre-processing ##########################################################\n",
    "                        if len(data_val) == 2:\n",
    "                            inputs_val, labels_val = data_val\n",
    "                        elif len(data_val) == 3:\n",
    "                            inputs_val, labels_val, x_len = data_val\n",
    "                        else:\n",
    "                            assert False, 'data_val length is not 2 or 3'\n",
    "\n",
    "                        if extra_train_dataset == -1:\n",
    "                            assert BATCH == 1\n",
    "                            now_T = inputs_val.shape[1]\n",
    "                            now_time_steps = temporal_filter*TIME\n",
    "                            start_idx = 0\n",
    "                            inputs_val = inputs_val[:, start_idx : start_idx + now_time_steps]\n",
    "\n",
    "                            if dvs_clipping != 0:\n",
    "                                inputs_val[inputs_val<dvs_clipping] = 0.0\n",
    "                                inputs_val[inputs_val>=dvs_clipping] = 1.0\n",
    "\n",
    "                        if (which_data == 'DVS_CIFAR10' or which_data == 'DVS_GESTURE' or which_data == 'DVS_GESTURE_TONIC' or which_data == 'DVS_CIFAR10_2' or which_data == 'NMNIST' or which_data == 'NMNIST_TONIC' or which_data == 'N_CALTECH101' or which_data == 'n_tidigits' or which_data == 'heidelberg'):\n",
    "                            inputs_val = inputs_val.permute(1, 0, 2, 3, 4)\n",
    "                        elif rate_coding == True :\n",
    "                            inputs_val = spikegen.rate(inputs_val, num_steps=TIME)\n",
    "                        else :\n",
    "                            inputs_val = inputs_val.repeat(TIME, 1, 1, 1, 1)\n",
    "                        # inputs_val: [Time, Batch, Channel, Height, Width]  \n",
    "                        ###################################################################################################\n",
    "\n",
    "                        \n",
    "                        ## initial pooling #######################################################################\n",
    "                        if (initial_pooling > 1):\n",
    "                            pool = nn.MaxPool2d(kernel_size=2)\n",
    "                            num_pooling_layers = int(math.log2(initial_pooling))\n",
    "                            # Time, Batch, Channel Ï∞®ÏõêÏùÄ Í∑∏ÎåÄÎ°ú ÎëêÍ≥†, Height, Width Ï∞®ÏõêÏóê ÎåÄÌï¥ÏÑúÎßå pooling Ï†ÅÏö©\n",
    "                            shape_temp = inputs_val.shape\n",
    "                            inputs_val = inputs_val.reshape(shape_temp[0]*shape_temp[1], shape_temp[2], shape_temp[3], shape_temp[4])\n",
    "                            for _ in range(num_pooling_layers):\n",
    "                                inputs_val = pool(inputs_val)\n",
    "                            inputs_val = inputs_val.reshape(shape_temp[0], shape_temp[1], shape_temp[2], shape_temp[3]//initial_pooling, shape_temp[4]//initial_pooling)\n",
    "                        ## initial pooling #######################################################################\n",
    "\n",
    "                        ## temporal filtering ####################################################################\n",
    "                        shape_temp = inputs_val.shape\n",
    "                        if (temporal_filter > 1):\n",
    "                            slice_bucket = []\n",
    "                            for t_temp in range(TIME):\n",
    "                                start = t_temp * temporal_filter\n",
    "                                end = start + temporal_filter\n",
    "                                slice_concat = torch.movedim(inputs_val[start:end], 0, -2).reshape(shape_temp[1],shape_temp[2],shape_temp[3],-1)\n",
    "                                \n",
    "                                if temporal_filter_accumulation == True:\n",
    "                                    if t_temp == 0:\n",
    "                                        slice_bucket.append(slice_concat)\n",
    "                                    else:\n",
    "                                        slice_bucket.append(slice_concat+slice_bucket[t_temp-1])\n",
    "                                else:\n",
    "                                    slice_bucket.append(slice_concat)\n",
    "\n",
    "                            inputs_val = torch.stack(slice_bucket, dim=0)\n",
    "                            if temporal_filter_accumulation == True and dvs_clipping > 0:\n",
    "                                inputs = (inputs != 0.0).float()\n",
    "                        ## temporal filtering ####################################################################\n",
    "                            \n",
    "                        inputs_val = inputs_val.to(device)\n",
    "                        labels_val = labels_val.to(device)\n",
    "                        real_batch = labels_val.size(0)\n",
    "                        \n",
    "                        if merge_polarities == True:\n",
    "                            inputs_val = inputs_val[:,:,0:1,:,:]\n",
    "\n",
    "                        ## network Ïó∞ÏÇ∞ ÏãúÏûë ############################################################################################################\n",
    "                        if single_step == False:\n",
    "                            outputs = net(inputs_val.permute(1, 0, 2, 3, 4)) #inputs_val: [Batch, Time, Channel, Height, Width]  \n",
    "                            val_loss += criterion(outputs, labels_val)/len(test_loader)\n",
    "                        else:\n",
    "                            outputs_all = []\n",
    "                            for t in range(TIME):\n",
    "                                outputs = net(inputs_val[t])\n",
    "                                val_loss_temp = criterion(outputs, labels_val)\n",
    "                                outputs_all.append(outputs.detach())\n",
    "                                val_loss += (val_loss_temp.data/TIME)/len(test_loader)\n",
    "                            outputs_all = torch.stack(outputs_all, dim=1)\n",
    "                            outputs = outputs_all.mean(1)\n",
    "                        #################################################################################################################################\n",
    "\n",
    "                        _, predicted = torch.max(outputs.data, 1)\n",
    "                        total_val += real_batch\n",
    "                        assert real_batch == outputs.size(0), f'batch size is not same. real_batch: {real_batch}, outputs.size(0): {outputs.size(0)}'\n",
    "                        correct_val += (predicted == labels_val).sum().item()\n",
    "\n",
    "                    val_acc_now = correct_val / total_val\n",
    "\n",
    "                if val_acc_best < val_acc_now:\n",
    "                    val_acc_best = val_acc_now\n",
    "                    # wandb ÌÇ§Î©¥ state_dictÏïÑÎãåÍ±∞Îäî Ï†ÄÏû• ÏïàÎê®\n",
    "                    # network save\n",
    "                    torch.save(net.state_dict(), f\"net_save/save_now_net_weights_{unique_name}.pth\")\n",
    "\n",
    "                if tr_acc_best < tr_acc:\n",
    "                    tr_acc_best = tr_acc\n",
    "\n",
    "                tr_epoch_loss = tr_epoch_loss_temp\n",
    "                tr_epoch_loss_temp = 0\n",
    "\n",
    "            ####################################################################################################################################################\n",
    "            \n",
    "            ## progress bar update ############################################################################################################\n",
    "            epoch_end_time = time.time()\n",
    "            epoch_time = epoch_end_time - epoch_start_time\n",
    "            if iter_of_val == False:\n",
    "                # iterator.set_description(f\"{iter_acc_string}, iter_loss:{iter_loss:10.6f}\") \n",
    "                pass \n",
    "            else:\n",
    "                # iterator.set_description(f\"{iter_acc_string2}, tr/val_loss:{tr_epoch_loss:10.6f}/{val_loss:10.6f}, tr:{100 * tr_acc:7.2f}%, tr_best:{100 * tr_acc_best:7.2f}%, val:{100 * val_acc_now:7.2f}%, val_best:{100 * val_acc_best:7.2f}%\")  \n",
    "                print(f\"{iter_acc_string2}, tr/val_loss:{tr_epoch_loss:10.6f}/{val_loss:10.6f}, val:{100 * val_acc_now:7.2f}%, val_best:{100 * val_acc_best:7.2f}%, tr:{100 * tr_acc:7.2f}%, tr_best:{100 * tr_acc_best:7.2f}%, epoch time: {epoch_time:.2f} seconds, {epoch_time/60:.2f} minutes\")\n",
    "                iter_of_val = False\n",
    "            ####################################################################################################################################\n",
    "            \n",
    "            ## wandb logging ############################################################################################################\n",
    "            if i == len(train_loader)-1 :\n",
    "                wandb.log({\"iter_acc\": iter_acc})\n",
    "                wandb.log({\"tr_acc\": tr_acc})\n",
    "                wandb.log({\"val_acc_now\": val_acc_now})\n",
    "                wandb.log({\"val_acc_best\": val_acc_best})\n",
    "                wandb.log({\"summary_val_acc\": val_acc_now})\n",
    "                wandb.log({\"epoch\": epoch})\n",
    "                wandb.log({\"val_loss\": val_loss}) \n",
    "                wandb.log({\"tr_epoch_loss\": tr_epoch_loss}) \n",
    "                for name, module in net.module.named_modules():\n",
    "                    if isinstance(module, SYNAPSE_FC):\n",
    "                        module.sparsity_print_and_reset()\n",
    "                \n",
    "                if epoch > 0:\n",
    "                    assert val_acc_best > 0.2\n",
    "                elif epoch > 10:\n",
    "                    assert val_acc_best > 0.4\n",
    "                elif epoch > 30:\n",
    "                    assert val_acc_best > 0.5\n",
    "                elif epoch > 100:\n",
    "                    assert val_acc_best > 0.6\n",
    "                    \n",
    "            ####################################################################################################################################\n",
    "            \n",
    "        ###### ITERATION END ##########################################################################################################\n",
    "\n",
    "        ## scheduler update #############################################################################\n",
    "        if (scheduler_name != 'no'):\n",
    "            if (scheduler_name == 'ReduceLROnPlateau'):\n",
    "                scheduler.step(val_loss)\n",
    "            else:\n",
    "                scheduler.step()\n",
    "        #################################################################################################\n",
    "        \n",
    "    #======== EPOCH END ==========================================================================================\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# unique_name = 'main' ## Ïù¥Í±∞ ÏÑ§Ï†ïÌïòÎ©¥ ÏÉàÎ°úÏö¥ Í≤ΩÎ°úÏóê Î™®Îëê save\n",
    "# wandb.init(project= f'my_snn {unique_name}',save_code=False, dir='/data2/bh_wandb', tags=[\"common\"])\n",
    "# ## wandb Í≥ºÍ±∞ ÌïòÏù¥ÌçºÌååÎùºÎØ∏ÌÑ∞ Í∞ÄÏ†∏ÏôÄÏÑú Î∂ôÏó¨ÎÑ£Í∏∞ (devices unique_nameÏùÄ ÎãàÍ∞Ä Ìï†ÎãπÌï¥Îùº)#################################\n",
    "# param = {'devices': '3', 'single_step': True, 'unique_name': 'main', 'my_seed': 42, 'TIME': 10, 'BATCH': 16, 'IMAGE_SIZE': 128, 'which_data': 'DVS_GESTURE_TONIC', 'data_path': '/data2', 'rate_coding': False, 'lif_layer_v_init': 0, 'lif_layer_v_decay': 0.25, 'lif_layer_v_threshold': 0.75, 'lif_layer_v_reset': 0, 'lif_layer_sg_width': 4, 'synapse_conv_kernel_size': 3, 'synapse_conv_stride': 1, 'synapse_conv_padding': 1, 'synapse_trace_const1': 1, 'synapse_trace_const2': 0, 'pre_trained': False, 'convTrue_fcFalse': False, 'cfg': [200, 200], 'net_print': True, 'pre_trained_path': 'net_save/save_now_net_weights_{unique_name}.pth', 'learning_rate': 0.001, 'epoch_num': 100, 'tdBN_on': False, 'BN_on': False, 'surrogate': 'hard_sigmoid', 'BPTT_on': False, 'optimizer_what': 'SGD', 'scheduler_name': 'no', 'ddp_on': False, 'dvs_clipping': 2, 'dvs_duration': 25000, 'DFA_on': True, 'trace_on': True, 'OTTT_input_trace_on': False, 'exclude_class': True, 'merge_polarities': False, 'denoise_on': True, 'extra_train_dataset': 0, 'num_workers': 2, 'chaching_on': True, 'pin_memory': True, 'UDA_on': False, 'alpha_uda': 1, 'bias': True, 'last_lif': False, 'temporal_filter': 5, 'initial_pooling': 8}\n",
    "# my_snn_system(devices = '0',single_step = param['single_step'],unique_name = unique_name,my_seed = param['my_seed'],TIME = param['TIME'],BATCH = param['BATCH'],IMAGE_SIZE = param['IMAGE_SIZE'],which_data = param['which_data'],data_path = param['data_path'],rate_coding = param['rate_coding'],lif_layer_v_init = param['lif_layer_v_init'],lif_layer_v_decay = param['lif_layer_v_decay'],lif_layer_v_threshold = param['lif_layer_v_threshold'],lif_layer_v_reset = param['lif_layer_v_reset'],lif_layer_sg_width = param['lif_layer_sg_width'],synapse_conv_kernel_size = param['synapse_conv_kernel_size'],synapse_conv_stride = param['synapse_conv_stride'],synapse_conv_padding = param['synapse_conv_padding'],synapse_trace_const1 = param['synapse_trace_const1'],synapse_trace_const2 = param['synapse_trace_const2'],pre_trained = param['pre_trained'],convTrue_fcFalse = param['convTrue_fcFalse'],cfg = param['cfg'],net_print = param['net_print'],pre_trained_path = param['pre_trained_path'],learning_rate = param['learning_rate'],epoch_num = param['epoch_num'],tdBN_on = param['tdBN_on'],BN_on = param['BN_on'],surrogate = param['surrogate'],BPTT_on = param['BPTT_on'],optimizer_what = param['optimizer_what'],scheduler_name = param['scheduler_name'],ddp_on = param['ddp_on'],dvs_clipping = param['dvs_clipping'],dvs_duration = param['dvs_duration'],DFA_on = param['DFA_on'],trace_on = param['trace_on'],OTTT_input_trace_on = param['OTTT_input_trace_on'],exclude_class = param['exclude_class'],merge_polarities = param['merge_polarities'],denoise_on = param['denoise_on'],extra_train_dataset = param['extra_train_dataset'],num_workers = param['num_workers'],chaching_on = param['chaching_on'],pin_memory = param['pin_memory'],UDA_on = param['UDA_on'],alpha_uda = param['alpha_uda'],bias = param['bias'],last_lif = param['last_lif'],temporal_filter = param['temporal_filter'],initial_pooling = param['initial_pooling'],temporal_filter_accumulation= param['temporal_filter_accumulation'])\n",
    "# #############################################################################\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for high_seed in [1,2,3]:\n",
    "#     ### my_snn control board (Gesture) ########################\n",
    "#     decay = 0.5 # 0.0 # 0.875 0.25 0.125 0.75 0.5\n",
    "#     # nda 0.25 # ottt 0.5\n",
    "\n",
    "#     unique_name = 'main'\n",
    "#     run_name = datetime.datetime.now().strftime(\"%Y%m%d_%H%M%S_\") + f\"{datetime.datetime.now().microsecond // 1000:03d}\"\n",
    "\n",
    "\n",
    "#     wandb.init(project= f'my_snn {unique_name}',save_code=False, dir='/data2/bh_wandb', tags=[\"common\"])\n",
    "\n",
    "#     my_snn_system(  devices = \"3\",\n",
    "#                     single_step = True, # True # False # DFA_onÏù¥Îûë Í∞ôÏù¥ Í∞ÄÎùº\n",
    "#                     unique_name = run_name,\n",
    "#                     my_seed = high_seed,\n",
    "#                     TIME = 10, # dvscifar 10 # ottt 6 or 10 # nda 10  # Ï†úÏûëÌïòÎäî dvsÏóêÏÑú TIMEÎÑòÍ±∞ÎÇò Ï†ÅÏúºÎ©¥ ÏûêÎ•¥Í±∞ÎÇò PADDINGÌï®\n",
    "#                     BATCH = 1, # batch norm Ìï†Í±∞Î©¥ 2Ïù¥ÏÉÅÏúºÎ°ú Ìï¥ÏïºÌï®   # nda 256   #  ottt 128\n",
    "#                     IMAGE_SIZE = 14, # dvscifar 48 # MNIST 28 # CIFAR10 32 # PMNIST 28 #NMNIST 34 # GESTURE 128\n",
    "#                     # dvsgesture 128, dvs_cifar2 128, nmnist 34, n_caltech101 180,240, n_tidigits 64, heidelberg 700, \n",
    "\n",
    "#                     # DVS_CIFAR10 Ìï†Í±∞Î©¥ time 10ÏúºÎ°ú Ìï¥Îùº\n",
    "#                     which_data = 'DVS_GESTURE_TONIC',\n",
    "#     # 'CIFAR100' 'CIFAR10' 'MNIST' 'FASHION_MNIST' 'DVS_CIFAR10' 'PMNIST'ÏïÑÏßÅ\n",
    "#     # 'DVS_GESTURE', 'DVS_GESTURE_TONIC','DVS_CIFAR10_2','NMNIST','NMNIST_TONIC','CIFAR10','N_CALTECH101','n_tidigits','heidelberg'\n",
    "#                     # CLASS_NUM = 10,\n",
    "#                     data_path = '/data2', # YOU NEED TO CHANGE THIS\n",
    "#                     rate_coding = False, # True # False\n",
    "\n",
    "#                     lif_layer_v_init = 0.0,\n",
    "#                     lif_layer_v_decay = decay,\n",
    "#                     lif_layer_v_threshold = 0.25,   #nda 0.5  #ottt 1.0\n",
    "#                     lif_layer_v_reset = 10000.0, # 10000Ïù¥ÏÉÅÏùÄ hardreset (ÎÇ¥ LIFÏì∞Í∏∞Îäî Ìï® „Öá„Öá)\n",
    "#                     lif_layer_sg_width = 4.0, # 2.570969004857107 # sigmoidÎ•òÏóêÏÑúÎäî alphaÍ∞í 4.0, rectangleÎ•òÏóêÏÑúÎäî widthÍ∞í 0.5\n",
    "\n",
    "#                     # synapse_conv_in_channels = IMAGE_PIXEL_CHANNEL,\n",
    "#                     synapse_conv_kernel_size = 3,\n",
    "#                     synapse_conv_stride = 1,\n",
    "#                     synapse_conv_padding = 1,\n",
    "\n",
    "#                     synapse_trace_const1 = 1, # ÌòÑÏû¨ traceÍµ¨Ìï† Îïå ÌòÑÏû¨ spikeÏóê Í≥±Ìï¥ÏßÄÎäî ÏÉÅÏàò. Í±ç 1Î°ú ÎëêÏÖà.\n",
    "#                     synapse_trace_const2 = decay, # ÌòÑÏû¨ traceÍµ¨Ìï† Îïå ÏßÅÏ†Ñ traceÏóê Í≥±Ìï¥ÏßÄÎäî ÏÉÅÏàò. lif_layer_v_decayÏôÄ Í∞ôÍ≤å Ìï† Í≤ÉÏùÑ Ï∂îÏ≤ú\n",
    "\n",
    "#                     # synapse_fc_out_features = CLASS_NUM,\n",
    "\n",
    "#                     pre_trained = False, # True # False\n",
    "#                     convTrue_fcFalse = False, # True # False\n",
    "\n",
    "#                     # 'P' for average pooling, 'D' for (1,1) aver pooling, 'M' for maxpooling, 'L' for linear classifier, [  ] for residual block\n",
    "#                     # convÏóêÏÑú 10000 Ïù¥ÏÉÅÏùÄ depth-wise separable (BPTTÎßå ÏßÄÏõê), 20000Ïù¥ÏÉÅÏùÄ depth-wise (BPTTÎßå ÏßÄÏõê)\n",
    "#                     # cfg = ['M', 'M', 32, 'P', 32, 'P', 32, 'P'], \n",
    "#                     # cfg = ['M', 'M', 64, 'P', 64, 'P', 64, 'P'], \n",
    "#                     # cfg = ['M', 'M', 64, 'M', 96, 'M', 128, 'M'], \n",
    "#                     cfg = [200, 200], \n",
    "#                     # cfg = ['M', 'M', 64, 'M', 96], \n",
    "#                     # cfg = ['M', 'M', 64, 'M', 96, 'L', 512, 512], \n",
    "#                     # cfg = ['M', 'M', 64], \n",
    "#                     # cfg = [64, 124, 64, 124],\n",
    "#                     # cfg = ['M','M',512], \n",
    "#                     # cfg = [512], \n",
    "#                     # cfg = ['M', 'M', 64, 128, 'P', 128, 'P'], \n",
    "#                     # cfg = ['M','M',512],\n",
    "#                     # cfg = ['M',200],\n",
    "#                     # cfg = [200,200],\n",
    "#                     # cfg = ['M','M',200,200],\n",
    "#                     # cfg = ([200],[200],[200],[2]), # (feature extractor, classifier, domain adapter, # of domain)\n",
    "#                     # cfg = (['M','M',200],[200],[200],[2]), # (feature extractor, classifier, domain adapter, # of domain)\n",
    "#                     # cfg = ['M',200,200],\n",
    "#                     # cfg = ['M','M',1024,512,256,128,64],\n",
    "#                     # cfg = [200,200],\n",
    "#                     # cfg = [12], #fc\n",
    "#                     # cfg = [12, 'M', 48, 'M', 12], \n",
    "#                     # cfg = [64,[64,64],64], # ÎÅùÏóê linear classifier ÌïòÎÇò ÏûêÎèôÏúºÎ°ú Î∂ôÏäµÎãàÎã§\n",
    "#                     # cfg = [64, 128, 'P', 256, 256, 'P', 512, 512, 'P', 512, 512, 'D'], #ottt\n",
    "#                     # cfg = [64, 128, 'P', 256, 256, 'P', 512, 512, 'P', 512, 512], \n",
    "#                     # cfg = [64, 128, 'M', 256, 256, 'M', 512, 512, 'M', 512, 512], \n",
    "#                     # cfg = [64, 'P', 128, 'P', 256, 256, 'P', 512, 512, 512, 512, 'D'], # nda\n",
    "#                     # cfg = [64, 'P', 128, 'P', 256, 256, 'P', 512, 512, 512, 512], # nda 128pixel\n",
    "#                     # cfg = [64, 'P', 128, 'P', 256, 256, 'P', 512, 512, 512, 512, 'L', 4096, 4096],\n",
    "#                     # cfg = [20001,10001], # depthwise, separable\n",
    "#                     # cfg = [64,20064,10001], # vanilla conv, depthwise, separable\n",
    "#                     # cfg = [8, 'P', 8, 'P', 8, 'P', 8,'P', 8, 'P'],\n",
    "#                     # cfg = [],        \n",
    "                    \n",
    "#                     net_print = True, # True # False # TrueÎ°ú ÌïòÍ∏∏ Ï∂îÏ≤ú\n",
    "                    \n",
    "#                     pre_trained_path = f\"net_save/save_now_net_weights_{unique_name}.pth\",\n",
    "#                     # learning_rate = 0.001, #0.1 bptt, #0.01 ottt, # default 0.001  # ottt 0.1 # nda 0.001 # 0.00936191669529645\n",
    "#                     learning_rate = 1/512, #0.1 bptt, #0.01 ottt, # default 0.001  # ottt 0.1 # nda 0.001 # 0.00936191669529645\n",
    "#                     epoch_num = 200,\n",
    "#                     tdBN_on = False,  # True # False\n",
    "#                     BN_on = False,  # True # False\n",
    "                    \n",
    "#                     surrogate = 'hard_sigmoid', # 'sigmoid' 'rectangle' 'rough_rectangle' 'hard_sigmoid'\n",
    "                    \n",
    "#                     BPTT_on = False,  # True # False # TrueÏù¥Î©¥ BPTT, FalseÏù¥Î©¥ OTTT  # depthwise, separableÏùÄ BPTTÎßå Í∞ÄÎä•\n",
    "                    \n",
    "#                     optimizer_what = 'SGD', # 'SGD' 'Adam', 'RMSprop'\n",
    "#                     scheduler_name = 'no', # 'no' 'StepLR' 'ExponentialLR' 'ReduceLROnPlateau' 'CosineAnnealingLR' 'OneCycleLR'\n",
    "                    \n",
    "#                     ddp_on = False, # DECREPATED # fALSE\n",
    "\n",
    "#                     dvs_clipping = 14, #ÏùºÎ∞òÏ†ÅÏúºÎ°ú 1 ÎòêÎäî 2 # 100msÎïåÎäî 5 # Ïà´ÏûêÎßåÌÅº ÌÅ¨Î©¥ spike ÏïÑÎãàÎ©¥ Í±ç 0\n",
    "#                     # gesture, cifar-dvs2, nmnist, ncaltech101\n",
    "#                     # gesture: 100_000c1-5, 25_000c5, 10_000c5, 1_000c5, 1_000_000c5\n",
    "\n",
    "#                     dvs_duration = 25_000, # 0 ÏïÑÎãàÎ©¥ time sampling # dvs number sampling OR time sampling # gesture, cifar-dvs2, nmnist, ncaltech101\n",
    "#                     # ÏûàÎäî Îç∞Ïù¥ÌÑ∞Îì§ #gesture 100_000 25_000 10_000 1_000 1_000_000 #nmnist 10000 #nmnist_tonic 10_000 25_000\n",
    "#                     # Ìïú Ïà´ÏûêÍ∞Ä 1usÏù∏ÎìØ (spikingjellyÏΩîÎìúÏóêÏÑú)\n",
    "#                     # Ìïú Ïû•Ïóê 50 timestepÎßå ÏÉùÏÇ∞Ìï®. Ïã´ÏúºÎ©¥ my_snn/trying/spikingjelly_dvsgestureÏùò__init__.py Î•º Ï∞∏Í≥†Ìï¥Î¥ê\n",
    "#                     # nmnist 5_000us, gestureÎäî 100_000us, 25_000us\n",
    "\n",
    "#                     DFA_on = False, # True # False # single_stepÏù¥Îûë Í∞ôÏù¥ ÏºúÏïº Îê®.\n",
    "\n",
    "#                     trace_on = False,   # True # False\n",
    "#                     OTTT_input_trace_on = False, # True # False # Îß® Ï≤òÏùå inputÏóê trace Ï†ÅÏö© # trace_on FalseÎ©¥ ÏùòÎØ∏ÏóÜÏùå.\n",
    "\n",
    "#                     exclude_class = True, # True # False # gestureÏóêÏÑú 10Î≤àÏß∏ ÌÅ¥ÎûòÏä§ Ï†úÏô∏\n",
    "\n",
    "#                     merge_polarities = True, # True # False # tonic dvs dataset ÏóêÏÑú polarities Ìï©ÏπòÍ∏∞\n",
    "#                     denoise_on = False, # True # False # &&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&\n",
    "\n",
    "#                     extra_train_dataset = -1, \n",
    "\n",
    "#                     num_workers = 2, # local wslÏóêÏÑúÎäî 2Í∞Ä ÎßûÍ≥†, ÏÑúÎ≤ÑÏóêÏÑúÎäî 4Í∞Ä Ï¢ãÎçîÎùº.\n",
    "#                     chaching_on = True, # True # False # only for certain datasets (gesture_tonic, nmnist_tonic)\n",
    "#                     pin_memory = True, # True # False \n",
    "\n",
    "#                     UDA_on = False,  # DECREPATED # uda\n",
    "#                     alpha_uda = 1.0, # DECREPATED # uda\n",
    "\n",
    "#                     bias = False, # True # False \n",
    "\n",
    "#                     last_lif = False, # True # False \n",
    "\n",
    "#                     temporal_filter = 5, \n",
    "#                     initial_pooling = 1,\n",
    "\n",
    "#                     temporal_filter_accumulation = False, # True # False \n",
    "\n",
    "#                     quantize_bit_list=[],\n",
    "#                     scale_exp=[[999,998],[999,999],[999,999]], # [[neuron_quant,feedback weight quant],[],[]]\n",
    "#     # 1w -11~-9\n",
    "#     # 1b -11~ -7\n",
    "#     # 2w -10~-8\n",
    "#     # 2b -10~-8\n",
    "#     # 3w -10\n",
    "#     # 3b -10\n",
    "#                     ) \n",
    "\n",
    "#     # num_workers = 4 * num_GPU (or 8, 16, 2 * num_GPU)\n",
    "#     # entry * batch_size * num_worker = num_GPU * GPU_throughtput\n",
    "#     # num_workers = batch_size / num_GPU\n",
    "#     # num_workers = batch_size / num_CPU\n",
    "\n",
    "#     # sigmoidÏôÄ BNÏù¥ ÏûàÏñ¥Ïïº ÏûòÎêúÎã§.\n",
    "#     # average pooling  \n",
    "#     # Ïù¥ ÎÇ´Îã§. \n",
    "\n",
    "#     # ndaÏóêÏÑúÎäî decay = 0.25, threshold = 0.5, width =1, surrogate = rectangle, batch = 256, tdBN = True\n",
    "#     ## OTTT ÏóêÏÑúÎäî decay = 0.5, threshold = 1.0, surrogate = sigmoid, batch = 128, BN = True\n",
    "\n",
    "#     wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Create sweep with ID: m41wfhay\n",
      "Sweep URL: https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/m41wfhay\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: slqhq9z9 with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBATCH: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBN_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBPTT_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tDFA_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tIMAGE_SIZE: 14\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tOTTT_input_trace_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tTIME: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tUDA_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \talpha_uda: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbias: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcfg: [200, 200]\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tchaching_on: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tconvTrue_fcFalse: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdata_path: /data2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tddp_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdenoise_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdvs_clipping: 14\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdvs_duration: 25000\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepoch_num: 200\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \texclude_class: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \textra_train_dataset: -1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tinitial_pooling: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlast_lif: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.00390625\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_sg_width: 4\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_decay: 0.5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_init: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_reset: 10000\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_threshold: 0.015625\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmerge_polarities: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmy_seed: 5622\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnet_print: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_workers: 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer_what: SGD\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tpin_memory: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tpre_trained: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tpre_trained_path: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \trate_coding: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tscheduler_name: no\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsingle_step: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsurrogate: hard_sigmoid\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_conv_kernel_size: 3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_conv_padding: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_conv_stride: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_trace_const1: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_trace_const2: 0.5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \ttdBN_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \ttemporal_filter: 5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \ttemporal_filter_accumulation: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \ttrace_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \twhich_data: DVS_GESTURE_TONIC\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mbhkim003\u001b[0m (\u001b[33mbhkim003-seoul-national-university\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.23.0 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.17.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/data2/bh_wandb/wandb/run-20251119_185311-slqhq9z9</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/slqhq9z9' target=\"_blank\">pious-sweep-1</a></strong> to <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/m41wfhay' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/m41wfhay</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/m41wfhay' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/m41wfhay</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/slqhq9z9' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/slqhq9z9</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'single_step' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'my_seed' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'TIME' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BATCH' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'IMAGE_SIZE' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'which_data' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'data_path' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'rate_coding' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_init' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_decay' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_threshold' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_reset' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_sg_width' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_conv_kernel_size' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_conv_stride' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_conv_padding' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_trace_const1' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_trace_const2' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'pre_trained' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'convTrue_fcFalse' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'cfg' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'net_print' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'pre_trained_path' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'learning_rate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'epoch_num' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'tdBN_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BN_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'surrogate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BPTT_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'optimizer_what' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'scheduler_name' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'ddp_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'dvs_clipping' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'dvs_duration' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'DFA_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'trace_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'OTTT_input_trace_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'exclude_class' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'merge_polarities' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'denoise_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'extra_train_dataset' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'num_workers' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'chaching_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'pin_memory' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'UDA_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'alpha_uda' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'bias' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'last_lif' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'temporal_filter' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'initial_pooling' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'temporal_filter_accumulation' was locked by 'sweep' (ignored update).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "param {'devices': '3', 'single_step': True, 'unique_name': '20251119_185320_647', 'my_seed': 5622, 'TIME': 10, 'BATCH': 1, 'IMAGE_SIZE': 14, 'which_data': 'DVS_GESTURE_TONIC', 'data_path': '/data2', 'rate_coding': False, 'lif_layer_v_init': 0, 'lif_layer_v_decay': 0.5, 'lif_layer_v_threshold': 0.015625, 'lif_layer_v_reset': 10000, 'lif_layer_sg_width': 4, 'synapse_conv_kernel_size': 3, 'synapse_conv_stride': 1, 'synapse_conv_padding': 1, 'synapse_trace_const1': 1, 'synapse_trace_const2': 0.5, 'pre_trained': False, 'convTrue_fcFalse': False, 'cfg': [200, 200], 'net_print': True, 'pre_trained_path': '', 'learning_rate': 0.00390625, 'epoch_num': 200, 'tdBN_on': False, 'BN_on': False, 'surrogate': 'hard_sigmoid', 'BPTT_on': False, 'optimizer_what': 'SGD', 'scheduler_name': 'no', 'ddp_on': False, 'dvs_clipping': 14, 'dvs_duration': 25000, 'DFA_on': False, 'trace_on': False, 'OTTT_input_trace_on': False, 'exclude_class': True, 'merge_polarities': True, 'denoise_on': False, 'extra_train_dataset': -1, 'num_workers': 2, 'chaching_on': True, 'pin_memory': True, 'UDA_on': False, 'alpha_uda': 1, 'bias': False, 'last_lif': False, 'temporal_filter': 5, 'initial_pooling': 1, 'temporal_filter_accumulation': False, 'quantize_bit_list': [], 'scale_exp': [[999, 998], [999, 999], [999, 999]]} \n",
      "\n",
      "Ïù¥ Îç∞Ïù¥ÌÑ∞ÏÖãÏùò Îç∞Ïù¥ÌÑ∞ Í∞úÏàòÎäî 979 ÏûÖÎãàÎã§. (test setÏùÄ ÏïàÎ∞îÎÄåÍ≤å Ìï¥ÎÜ®Îã§ ÏïåÏ†ú)\n",
      "Ïù¥ Îç∞Ïù¥ÌÑ∞ÏÖãÏùò Îç∞Ïù¥ÌÑ∞ Í∞úÏàòÎäî 240 ÏûÖÎãàÎã§. (test setÏùÄ ÏïàÎ∞îÎÄåÍ≤å Ìï¥ÎÜ®Îã§ ÏïåÏ†ú)\n",
      "dataset_hash = 0e8a8f2d81b4fe037308b5d792c4a037\n",
      "cache path exists\n",
      "\n",
      "len(train_loader): 979 BATCH: 1 train_data_count: 979\n",
      "len(test_loader): 240 BATCH: 1\n",
      "\n",
      "device ==> cuda\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " layer_count 1\n",
      "weight bias bit 0\n",
      "weight exp, bias exp None None\n",
      "bit_for_output 0 exp_for_output None \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "LIF 1 sg_bit 0\n",
      "\n",
      "\n",
      "++++++++++++++++++++++++\n",
      "\n",
      " lif layer 1 v_bit: 0, v_exp: None\n",
      "\n",
      "++++++++++++++++++++++++++++++++++++++++++++++\n",
      "\n",
      "\n",
      "\n",
      " layer_count 2\n",
      "weight bias bit 0\n",
      "weight exp, bias exp None None\n",
      "bit_for_output 0 exp_for_output None \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "LIF 2 sg_bit 0\n",
      "\n",
      "\n",
      "++++++++++++++++++++++++\n",
      "\n",
      " lif layer 2 v_bit: 0, v_exp: None\n",
      "\n",
      "++++++++++++++++++++++++++++++++++++++++++++++\n",
      "\n",
      "\n",
      "\n",
      " layer_count 3\n",
      "weight bias bit 0\n",
      "weight exp, bias exp None None\n",
      "bit_for_output 0 exp_for_output None \n",
      "\n",
      "\n",
      "\n",
      "DataParallel(\n",
      "  (module): REBORN_MY_SNN_FC(\n",
      "    (layers): REBORN_MY_Sequential(\n",
      "      (0): DimChanger_for_FC()\n",
      "      (1): SYNAPSE_FC(in_features=980, out_features=200, TIME=10, bias=False, sstep=True, time_different_weight=False, layer_count=1, quantize_bit_list=[], scale_exp=[[999, 998], [999, 999], [999, 999]], ANPI_MODE=False)\n",
      "      (2): LIF_layer(v_init=0, v_decay=0.5, v_threshold=0.015625, v_reset=10000, sg_width=4, surrogate=hard_sigmoid, BPTT_on=False, trace_const1=1, trace_const2=0.5, TIME=10, sstep=True, trace_on=False, layer_count=1, scale_exp=[[999, 998], [999, 999], [999, 999]], ANPI_MODE=False)\n",
      "      (3): SYNAPSE_FC(in_features=200, out_features=200, TIME=10, bias=False, sstep=True, time_different_weight=False, layer_count=2, quantize_bit_list=[], scale_exp=[[999, 998], [999, 999], [999, 999]], ANPI_MODE=False)\n",
      "      (4): LIF_layer(v_init=0, v_decay=0.5, v_threshold=0.015625, v_reset=10000, sg_width=4, surrogate=hard_sigmoid, BPTT_on=False, trace_const1=1, trace_const2=0.5, TIME=10, sstep=True, trace_on=False, layer_count=2, scale_exp=[[999, 998], [999, 999], [999, 999]], ANPI_MODE=False)\n",
      "      (5): SYNAPSE_FC(in_features=200, out_features=10, TIME=10, bias=False, sstep=True, time_different_weight=False, layer_count=3, quantize_bit_list=[], scale_exp=[[999, 998], [999, 999], [999, 999]], ANPI_MODE=False)\n",
      "    )\n",
      "  )\n",
      ")\n",
      "\n",
      "========================================================\n",
      "Trainable parameters: 238,000\n",
      "========================================================\n",
      "\n",
      "MySGD (\n",
      "Parameter Group 0\n",
      "    lr: 0.00390625\n",
      "    momentum: 0.0\n",
      ")\n",
      "total_backward_count 0 real_backward_count 0   0.000%\n",
      "epoch-0   lr=['0.0039062'], tr/val_loss:  0.068417/  0.080413, val:  51.25%, val_best:  51.25%, tr:  77.53%, tr_best:  77.53%, epoch time: 57.56 seconds, 0.96 minutes\n",
      "layer   1  Sparsity: 91.0990%\n",
      "layer   2  Sparsity: 61.5349%\n",
      "layer   3  Sparsity: 58.5581%\n",
      "total_backward_count 9790 real_backward_count 3478  35.526%\n",
      "epoch-1   lr=['0.0039062'], tr/val_loss:  0.053491/  0.081998, val:  46.25%, val_best:  51.25%, tr:  83.04%, tr_best:  83.04%, epoch time: 56.54 seconds, 0.94 minutes\n",
      "layer   1  Sparsity: 91.0789%\n",
      "layer   2  Sparsity: 61.3053%\n",
      "layer   3  Sparsity: 59.7498%\n",
      "total_backward_count 19580 real_backward_count 6153  31.425%\n",
      "epoch-2   lr=['0.0039062'], tr/val_loss:  0.049014/  0.079127, val:  50.00%, val_best:  51.25%, tr:  85.90%, tr_best:  85.90%, epoch time: 55.81 seconds, 0.93 minutes\n",
      "layer   1  Sparsity: 91.1016%\n",
      "layer   2  Sparsity: 61.0059%\n",
      "layer   3  Sparsity: 60.1813%\n",
      "total_backward_count 29370 real_backward_count 8518  29.002%\n",
      "epoch-3   lr=['0.0039062'], tr/val_loss:  0.047214/  0.072203, val:  56.25%, val_best:  56.25%, tr:  84.47%, tr_best:  85.90%, epoch time: 56.15 seconds, 0.94 minutes\n",
      "layer   1  Sparsity: 91.0653%\n",
      "layer   2  Sparsity: 60.6601%\n",
      "layer   3  Sparsity: 60.7699%\n",
      "total_backward_count 39160 real_backward_count 10855  27.720%\n",
      "epoch-4   lr=['0.0039062'], tr/val_loss:  0.045500/  0.069612, val:  57.50%, val_best:  57.50%, tr:  84.58%, tr_best:  85.90%, epoch time: 56.20 seconds, 0.94 minutes\n",
      "layer   1  Sparsity: 91.0571%\n",
      "layer   2  Sparsity: 60.2272%\n",
      "layer   3  Sparsity: 61.2915%\n",
      "total_backward_count 48950 real_backward_count 13082  26.725%\n",
      "epoch-5   lr=['0.0039062'], tr/val_loss:  0.044533/  0.073854, val:  55.83%, val_best:  57.50%, tr:  85.39%, tr_best:  85.90%, epoch time: 55.23 seconds, 0.92 minutes\n",
      "layer   1  Sparsity: 91.0803%\n",
      "layer   2  Sparsity: 59.8053%\n",
      "layer   3  Sparsity: 62.1359%\n",
      "total_backward_count 58740 real_backward_count 15342  26.118%\n",
      "epoch-6   lr=['0.0039062'], tr/val_loss:  0.043681/  0.069058, val:  57.08%, val_best:  57.50%, tr:  84.58%, tr_best:  85.90%, epoch time: 55.34 seconds, 0.92 minutes\n",
      "layer   1  Sparsity: 91.0823%\n",
      "layer   2  Sparsity: 59.6205%\n",
      "layer   3  Sparsity: 63.0089%\n",
      "total_backward_count 68530 real_backward_count 17559  25.622%\n",
      "epoch-7   lr=['0.0039062'], tr/val_loss:  0.043361/  0.063497, val:  57.50%, val_best:  57.50%, tr:  84.17%, tr_best:  85.90%, epoch time: 55.72 seconds, 0.93 minutes\n",
      "layer   1  Sparsity: 91.0797%\n",
      "layer   2  Sparsity: 59.3320%\n",
      "layer   3  Sparsity: 63.8763%\n",
      "total_backward_count 78320 real_backward_count 19805  25.287%\n",
      "epoch-8   lr=['0.0039062'], tr/val_loss:  0.041795/  0.063141, val:  62.08%, val_best:  62.08%, tr:  85.29%, tr_best:  85.90%, epoch time: 55.85 seconds, 0.93 minutes\n",
      "layer   1  Sparsity: 91.0914%\n",
      "layer   2  Sparsity: 59.1970%\n",
      "layer   3  Sparsity: 64.5527%\n",
      "total_backward_count 88110 real_backward_count 21915  24.872%\n",
      "epoch-9   lr=['0.0039062'], tr/val_loss:  0.041908/  0.066856, val:  61.25%, val_best:  62.08%, tr:  86.01%, tr_best:  86.01%, epoch time: 56.36 seconds, 0.94 minutes\n",
      "layer   1  Sparsity: 91.0949%\n",
      "layer   2  Sparsity: 58.9762%\n",
      "layer   3  Sparsity: 65.4917%\n",
      "total_backward_count 97900 real_backward_count 24086  24.603%\n",
      "epoch-10  lr=['0.0039062'], tr/val_loss:  0.041211/  0.059678, val:  67.08%, val_best:  67.08%, tr:  85.80%, tr_best:  86.01%, epoch time: 56.03 seconds, 0.93 minutes\n",
      "layer   1  Sparsity: 91.0991%\n",
      "layer   2  Sparsity: 58.8805%\n",
      "layer   3  Sparsity: 66.2289%\n",
      "total_backward_count 107690 real_backward_count 26261  24.386%\n",
      "epoch-11  lr=['0.0039062'], tr/val_loss:  0.040770/  0.057835, val:  67.50%, val_best:  67.50%, tr:  85.90%, tr_best:  86.01%, epoch time: 56.23 seconds, 0.94 minutes\n",
      "layer   1  Sparsity: 91.0796%\n",
      "layer   2  Sparsity: 58.8100%\n",
      "layer   3  Sparsity: 67.0205%\n",
      "total_backward_count 117480 real_backward_count 28420  24.191%\n",
      "epoch-12  lr=['0.0039062'], tr/val_loss:  0.040859/  0.058058, val:  63.33%, val_best:  67.50%, tr:  84.78%, tr_best:  86.01%, epoch time: 56.07 seconds, 0.93 minutes\n",
      "layer   1  Sparsity: 91.0628%\n",
      "layer   2  Sparsity: 58.7194%\n",
      "layer   3  Sparsity: 67.7125%\n",
      "total_backward_count 127270 real_backward_count 30666  24.095%\n",
      "epoch-13  lr=['0.0039062'], tr/val_loss:  0.040301/  0.069401, val:  57.50%, val_best:  67.50%, tr:  85.39%, tr_best:  86.01%, epoch time: 55.80 seconds, 0.93 minutes\n",
      "layer   1  Sparsity: 91.1124%\n",
      "layer   2  Sparsity: 58.6863%\n",
      "layer   3  Sparsity: 68.1872%\n",
      "total_backward_count 137060 real_backward_count 32835  23.957%\n",
      "epoch-14  lr=['0.0039062'], tr/val_loss:  0.040049/  0.061387, val:  65.42%, val_best:  67.50%, tr:  84.98%, tr_best:  86.01%, epoch time: 55.88 seconds, 0.93 minutes\n",
      "layer   1  Sparsity: 91.0532%\n",
      "layer   2  Sparsity: 58.6206%\n",
      "layer   3  Sparsity: 68.9065%\n",
      "total_backward_count 146850 real_backward_count 35036  23.858%\n",
      "epoch-15  lr=['0.0039062'], tr/val_loss:  0.038332/  0.055744, val:  71.25%, val_best:  71.25%, tr:  85.50%, tr_best:  86.01%, epoch time: 55.92 seconds, 0.93 minutes\n",
      "layer   1  Sparsity: 91.0746%\n",
      "layer   2  Sparsity: 58.6043%\n",
      "layer   3  Sparsity: 69.4978%\n",
      "total_backward_count 156640 real_backward_count 37133  23.706%\n",
      "epoch-16  lr=['0.0039062'], tr/val_loss:  0.038687/  0.060704, val:  60.83%, val_best:  71.25%, tr:  84.88%, tr_best:  86.01%, epoch time: 55.78 seconds, 0.93 minutes\n",
      "layer   1  Sparsity: 91.0873%\n",
      "layer   2  Sparsity: 58.6219%\n",
      "layer   3  Sparsity: 70.0380%\n",
      "total_backward_count 166430 real_backward_count 39304  23.616%\n",
      "epoch-17  lr=['0.0039062'], tr/val_loss:  0.038923/  0.062658, val:  55.42%, val_best:  71.25%, tr:  84.88%, tr_best:  86.01%, epoch time: 55.98 seconds, 0.93 minutes\n",
      "layer   1  Sparsity: 91.0666%\n",
      "layer   2  Sparsity: 58.6708%\n",
      "layer   3  Sparsity: 70.6306%\n",
      "total_backward_count 176220 real_backward_count 41515  23.559%\n",
      "epoch-18  lr=['0.0039062'], tr/val_loss:  0.038066/  0.061577, val:  60.42%, val_best:  71.25%, tr:  85.80%, tr_best:  86.01%, epoch time: 56.03 seconds, 0.93 minutes\n",
      "layer   1  Sparsity: 91.0706%\n",
      "layer   2  Sparsity: 58.6123%\n",
      "layer   3  Sparsity: 71.2686%\n",
      "total_backward_count 186010 real_backward_count 43637  23.459%\n",
      "epoch-19  lr=['0.0039062'], tr/val_loss:  0.037804/  0.063181, val:  57.50%, val_best:  71.25%, tr:  85.29%, tr_best:  86.01%, epoch time: 56.31 seconds, 0.94 minutes\n",
      "layer   1  Sparsity: 91.0857%\n",
      "layer   2  Sparsity: 58.6610%\n",
      "layer   3  Sparsity: 71.7244%\n",
      "total_backward_count 195800 real_backward_count 45778  23.380%\n",
      "epoch-20  lr=['0.0039062'], tr/val_loss:  0.037736/  0.055011, val:  69.58%, val_best:  71.25%, tr:  85.90%, tr_best:  86.01%, epoch time: 56.22 seconds, 0.94 minutes\n",
      "layer   1  Sparsity: 91.0885%\n",
      "layer   2  Sparsity: 58.6595%\n",
      "layer   3  Sparsity: 72.0928%\n",
      "total_backward_count 205590 real_backward_count 47872  23.285%\n",
      "epoch-21  lr=['0.0039062'], tr/val_loss:  0.037687/  0.057135, val:  68.33%, val_best:  71.25%, tr:  84.98%, tr_best:  86.01%, epoch time: 55.97 seconds, 0.93 minutes\n",
      "layer   1  Sparsity: 91.0903%\n",
      "layer   2  Sparsity: 58.5883%\n",
      "layer   3  Sparsity: 72.4105%\n",
      "total_backward_count 215380 real_backward_count 49996  23.213%\n",
      "epoch-22  lr=['0.0039062'], tr/val_loss:  0.037378/  0.056866, val:  67.08%, val_best:  71.25%, tr:  84.68%, tr_best:  86.01%, epoch time: 55.50 seconds, 0.93 minutes\n",
      "layer   1  Sparsity: 91.0384%\n",
      "layer   2  Sparsity: 58.5874%\n",
      "layer   3  Sparsity: 72.8843%\n",
      "total_backward_count 225170 real_backward_count 52167  23.168%\n",
      "epoch-23  lr=['0.0039062'], tr/val_loss:  0.036592/  0.053952, val:  72.08%, val_best:  72.08%, tr:  86.62%, tr_best:  86.62%, epoch time: 55.68 seconds, 0.93 minutes\n",
      "layer   1  Sparsity: 91.0581%\n",
      "layer   2  Sparsity: 58.5983%\n",
      "layer   3  Sparsity: 73.2637%\n",
      "total_backward_count 234960 real_backward_count 54200  23.068%\n",
      "epoch-24  lr=['0.0039062'], tr/val_loss:  0.036010/  0.056180, val:  62.08%, val_best:  72.08%, tr:  87.44%, tr_best:  87.44%, epoch time: 56.15 seconds, 0.94 minutes\n",
      "layer   1  Sparsity: 91.0482%\n",
      "layer   2  Sparsity: 58.6438%\n",
      "layer   3  Sparsity: 73.4251%\n",
      "total_backward_count 244750 real_backward_count 56282  22.996%\n",
      "epoch-25  lr=['0.0039062'], tr/val_loss:  0.036547/  0.053132, val:  74.58%, val_best:  74.58%, tr:  85.39%, tr_best:  87.44%, epoch time: 56.13 seconds, 0.94 minutes\n",
      "layer   1  Sparsity: 91.0735%\n",
      "layer   2  Sparsity: 58.6345%\n",
      "layer   3  Sparsity: 73.7443%\n",
      "total_backward_count 254540 real_backward_count 58403  22.945%\n",
      "epoch-26  lr=['0.0039062'], tr/val_loss:  0.036118/  0.054722, val:  65.83%, val_best:  74.58%, tr:  86.41%, tr_best:  87.44%, epoch time: 55.87 seconds, 0.93 minutes\n",
      "layer   1  Sparsity: 91.0650%\n",
      "layer   2  Sparsity: 58.6414%\n",
      "layer   3  Sparsity: 74.0649%\n",
      "total_backward_count 264330 real_backward_count 60516  22.894%\n",
      "epoch-27  lr=['0.0039062'], tr/val_loss:  0.035686/  0.054137, val:  73.33%, val_best:  74.58%, tr:  87.33%, tr_best:  87.44%, epoch time: 56.22 seconds, 0.94 minutes\n",
      "layer   1  Sparsity: 91.1103%\n",
      "layer   2  Sparsity: 58.6521%\n",
      "layer   3  Sparsity: 74.4432%\n",
      "total_backward_count 274120 real_backward_count 62568  22.825%\n",
      "epoch-28  lr=['0.0039062'], tr/val_loss:  0.035068/  0.058325, val:  65.42%, val_best:  74.58%, tr:  87.03%, tr_best:  87.44%, epoch time: 52.46 seconds, 0.87 minutes\n",
      "layer   1  Sparsity: 91.1323%\n",
      "layer   2  Sparsity: 58.6312%\n",
      "layer   3  Sparsity: 74.7082%\n",
      "total_backward_count 283910 real_backward_count 64564  22.741%\n",
      "epoch-29  lr=['0.0039062'], tr/val_loss:  0.035586/  0.059826, val:  62.50%, val_best:  74.58%, tr:  86.72%, tr_best:  87.44%, epoch time: 56.41 seconds, 0.94 minutes\n",
      "layer   1  Sparsity: 91.0836%\n",
      "layer   2  Sparsity: 58.6904%\n",
      "layer   3  Sparsity: 75.0468%\n",
      "total_backward_count 293700 real_backward_count 66611  22.680%\n",
      "epoch-30  lr=['0.0039062'], tr/val_loss:  0.034791/  0.056292, val:  69.17%, val_best:  74.58%, tr:  87.03%, tr_best:  87.44%, epoch time: 57.02 seconds, 0.95 minutes\n",
      "layer   1  Sparsity: 91.0987%\n",
      "layer   2  Sparsity: 58.6108%\n",
      "layer   3  Sparsity: 75.3365%\n",
      "total_backward_count 303490 real_backward_count 68633  22.615%\n",
      "epoch-31  lr=['0.0039062'], tr/val_loss:  0.034839/  0.053583, val:  71.67%, val_best:  74.58%, tr:  86.52%, tr_best:  87.44%, epoch time: 56.01 seconds, 0.93 minutes\n",
      "layer   1  Sparsity: 91.0711%\n",
      "layer   2  Sparsity: 58.5920%\n",
      "layer   3  Sparsity: 75.7027%\n",
      "total_backward_count 313280 real_backward_count 70673  22.559%\n",
      "epoch-32  lr=['0.0039062'], tr/val_loss:  0.034558/  0.055328, val:  71.67%, val_best:  74.58%, tr:  87.44%, tr_best:  87.44%, epoch time: 55.63 seconds, 0.93 minutes\n",
      "layer   1  Sparsity: 91.0918%\n",
      "layer   2  Sparsity: 58.6205%\n",
      "layer   3  Sparsity: 76.0424%\n",
      "total_backward_count 323070 real_backward_count 72638  22.484%\n",
      "epoch-33  lr=['0.0039062'], tr/val_loss:  0.034560/  0.054228, val:  72.08%, val_best:  74.58%, tr:  86.82%, tr_best:  87.44%, epoch time: 56.11 seconds, 0.94 minutes\n",
      "layer   1  Sparsity: 91.0797%\n",
      "layer   2  Sparsity: 58.6066%\n",
      "layer   3  Sparsity: 76.2444%\n",
      "total_backward_count 332860 real_backward_count 74677  22.435%\n",
      "epoch-34  lr=['0.0039062'], tr/val_loss:  0.033051/  0.055117, val:  68.33%, val_best:  74.58%, tr:  88.25%, tr_best:  88.25%, epoch time: 56.48 seconds, 0.94 minutes\n",
      "layer   1  Sparsity: 91.0897%\n",
      "layer   2  Sparsity: 58.6406%\n",
      "layer   3  Sparsity: 76.3732%\n",
      "total_backward_count 342650 real_backward_count 76579  22.349%\n",
      "epoch-35  lr=['0.0039062'], tr/val_loss:  0.033283/  0.055142, val:  70.00%, val_best:  74.58%, tr:  88.76%, tr_best:  88.76%, epoch time: 56.29 seconds, 0.94 minutes\n",
      "layer   1  Sparsity: 91.0396%\n",
      "layer   2  Sparsity: 58.6019%\n",
      "layer   3  Sparsity: 76.7003%\n",
      "total_backward_count 352440 real_backward_count 78490  22.270%\n",
      "epoch-36  lr=['0.0039062'], tr/val_loss:  0.033316/  0.058376, val:  59.17%, val_best:  74.58%, tr:  86.82%, tr_best:  88.76%, epoch time: 56.38 seconds, 0.94 minutes\n",
      "layer   1  Sparsity: 91.0899%\n",
      "layer   2  Sparsity: 58.8014%\n",
      "layer   3  Sparsity: 76.7454%\n",
      "total_backward_count 362230 real_backward_count 80427  22.203%\n",
      "epoch-37  lr=['0.0039062'], tr/val_loss:  0.033935/  0.052073, val:  74.17%, val_best:  74.58%, tr:  88.15%, tr_best:  88.76%, epoch time: 55.73 seconds, 0.93 minutes\n",
      "layer   1  Sparsity: 91.1071%\n",
      "layer   2  Sparsity: 58.8234%\n",
      "layer   3  Sparsity: 76.9878%\n",
      "total_backward_count 372020 real_backward_count 82425  22.156%\n",
      "epoch-38  lr=['0.0039062'], tr/val_loss:  0.032300/  0.054865, val:  65.42%, val_best:  74.58%, tr:  89.38%, tr_best:  89.38%, epoch time: 56.70 seconds, 0.94 minutes\n",
      "layer   1  Sparsity: 91.0654%\n",
      "layer   2  Sparsity: 58.8005%\n",
      "layer   3  Sparsity: 77.1568%\n",
      "total_backward_count 381810 real_backward_count 84294  22.077%\n",
      "epoch-39  lr=['0.0039062'], tr/val_loss:  0.032836/  0.059658, val:  65.42%, val_best:  74.58%, tr:  88.46%, tr_best:  89.38%, epoch time: 56.16 seconds, 0.94 minutes\n",
      "layer   1  Sparsity: 91.1023%\n",
      "layer   2  Sparsity: 58.8544%\n",
      "layer   3  Sparsity: 77.4194%\n",
      "total_backward_count 391600 real_backward_count 86226  22.019%\n",
      "epoch-40  lr=['0.0039062'], tr/val_loss:  0.031667/  0.053157, val:  71.67%, val_best:  74.58%, tr:  89.07%, tr_best:  89.38%, epoch time: 55.91 seconds, 0.93 minutes\n",
      "layer   1  Sparsity: 91.0421%\n",
      "layer   2  Sparsity: 58.8891%\n",
      "layer   3  Sparsity: 77.5523%\n",
      "total_backward_count 401390 real_backward_count 88046  21.935%\n",
      "epoch-41  lr=['0.0039062'], tr/val_loss:  0.032317/  0.051332, val:  75.83%, val_best:  75.83%, tr:  89.27%, tr_best:  89.38%, epoch time: 56.42 seconds, 0.94 minutes\n",
      "layer   1  Sparsity: 91.0715%\n",
      "layer   2  Sparsity: 58.9089%\n",
      "layer   3  Sparsity: 77.6681%\n",
      "total_backward_count 411180 real_backward_count 89930  21.871%\n",
      "epoch-42  lr=['0.0039062'], tr/val_loss:  0.032101/  0.058266, val:  65.42%, val_best:  75.83%, tr:  90.40%, tr_best:  90.40%, epoch time: 56.35 seconds, 0.94 minutes\n",
      "layer   1  Sparsity: 91.1188%\n",
      "layer   2  Sparsity: 58.9732%\n",
      "layer   3  Sparsity: 77.8781%\n",
      "total_backward_count 420970 real_backward_count 91788  21.804%\n",
      "epoch-43  lr=['0.0039062'], tr/val_loss:  0.031004/  0.052616, val:  72.50%, val_best:  75.83%, tr:  90.30%, tr_best:  90.40%, epoch time: 56.00 seconds, 0.93 minutes\n",
      "layer   1  Sparsity: 91.0863%\n",
      "layer   2  Sparsity: 58.8317%\n",
      "layer   3  Sparsity: 78.0185%\n",
      "total_backward_count 430760 real_backward_count 93562  21.720%\n",
      "epoch-44  lr=['0.0039062'], tr/val_loss:  0.030668/  0.057270, val:  64.17%, val_best:  75.83%, tr:  88.97%, tr_best:  90.40%, epoch time: 56.21 seconds, 0.94 minutes\n",
      "layer   1  Sparsity: 91.0866%\n",
      "layer   2  Sparsity: 58.8427%\n",
      "layer   3  Sparsity: 78.2158%\n",
      "total_backward_count 440550 real_backward_count 95379  21.650%\n",
      "epoch-45  lr=['0.0039062'], tr/val_loss:  0.030702/  0.056985, val:  69.17%, val_best:  75.83%, tr:  90.09%, tr_best:  90.40%, epoch time: 56.32 seconds, 0.94 minutes\n",
      "layer   1  Sparsity: 91.1117%\n",
      "layer   2  Sparsity: 58.9768%\n",
      "layer   3  Sparsity: 78.2434%\n",
      "total_backward_count 450340 real_backward_count 97145  21.571%\n",
      "epoch-46  lr=['0.0039062'], tr/val_loss:  0.030178/  0.054854, val:  70.83%, val_best:  75.83%, tr:  90.40%, tr_best:  90.40%, epoch time: 55.67 seconds, 0.93 minutes\n",
      "layer   1  Sparsity: 91.0792%\n",
      "layer   2  Sparsity: 59.0107%\n",
      "layer   3  Sparsity: 78.4722%\n",
      "total_backward_count 460130 real_backward_count 98879  21.489%\n",
      "epoch-47  lr=['0.0039062'], tr/val_loss:  0.030251/  0.052947, val:  71.25%, val_best:  75.83%, tr:  91.01%, tr_best:  91.01%, epoch time: 55.75 seconds, 0.93 minutes\n",
      "layer   1  Sparsity: 91.0466%\n",
      "layer   2  Sparsity: 58.9652%\n",
      "layer   3  Sparsity: 78.5787%\n",
      "total_backward_count 469920 real_backward_count 100596  21.407%\n",
      "epoch-48  lr=['0.0039062'], tr/val_loss:  0.030083/  0.053064, val:  71.25%, val_best:  75.83%, tr:  92.24%, tr_best:  92.24%, epoch time: 55.97 seconds, 0.93 minutes\n",
      "layer   1  Sparsity: 91.0647%\n",
      "layer   2  Sparsity: 59.1017%\n",
      "layer   3  Sparsity: 78.7178%\n",
      "total_backward_count 479710 real_backward_count 102311  21.328%\n",
      "epoch-49  lr=['0.0039062'], tr/val_loss:  0.029114/  0.055416, val:  69.17%, val_best:  75.83%, tr:  92.34%, tr_best:  92.34%, epoch time: 55.94 seconds, 0.93 minutes\n",
      "layer   1  Sparsity: 91.0523%\n",
      "layer   2  Sparsity: 58.9845%\n",
      "layer   3  Sparsity: 79.0099%\n",
      "total_backward_count 489500 real_backward_count 104015  21.249%\n",
      "epoch-50  lr=['0.0039062'], tr/val_loss:  0.028664/  0.053370, val:  74.58%, val_best:  75.83%, tr:  92.54%, tr_best:  92.54%, epoch time: 56.07 seconds, 0.93 minutes\n",
      "layer   1  Sparsity: 91.0508%\n",
      "layer   2  Sparsity: 59.0085%\n",
      "layer   3  Sparsity: 79.2196%\n",
      "total_backward_count 499290 real_backward_count 105640  21.158%\n",
      "epoch-51  lr=['0.0039062'], tr/val_loss:  0.029834/  0.054153, val:  77.08%, val_best:  77.08%, tr:  92.13%, tr_best:  92.54%, epoch time: 56.31 seconds, 0.94 minutes\n",
      "layer   1  Sparsity: 91.0621%\n",
      "layer   2  Sparsity: 59.0056%\n",
      "layer   3  Sparsity: 79.4362%\n",
      "total_backward_count 509080 real_backward_count 107362  21.089%\n",
      "epoch-52  lr=['0.0039062'], tr/val_loss:  0.028968/  0.055792, val:  68.75%, val_best:  77.08%, tr:  93.16%, tr_best:  93.16%, epoch time: 56.06 seconds, 0.93 minutes\n",
      "layer   1  Sparsity: 91.0752%\n",
      "layer   2  Sparsity: 59.0022%\n",
      "layer   3  Sparsity: 79.5664%\n",
      "total_backward_count 518870 real_backward_count 109037  21.014%\n",
      "epoch-53  lr=['0.0039062'], tr/val_loss:  0.028492/  0.056310, val:  70.00%, val_best:  77.08%, tr:  92.13%, tr_best:  93.16%, epoch time: 56.03 seconds, 0.93 minutes\n",
      "layer   1  Sparsity: 91.0899%\n",
      "layer   2  Sparsity: 59.1253%\n",
      "layer   3  Sparsity: 79.7019%\n",
      "total_backward_count 528660 real_backward_count 110654  20.931%\n",
      "epoch-54  lr=['0.0039062'], tr/val_loss:  0.027922/  0.056230, val:  68.33%, val_best:  77.08%, tr:  93.05%, tr_best:  93.16%, epoch time: 55.01 seconds, 0.92 minutes\n",
      "layer   1  Sparsity: 91.0316%\n",
      "layer   2  Sparsity: 59.1444%\n",
      "layer   3  Sparsity: 79.9152%\n",
      "total_backward_count 538450 real_backward_count 112239  20.845%\n",
      "epoch-55  lr=['0.0039062'], tr/val_loss:  0.027778/  0.050935, val:  77.92%, val_best:  77.92%, tr:  92.95%, tr_best:  93.16%, epoch time: 54.74 seconds, 0.91 minutes\n",
      "layer   1  Sparsity: 91.0524%\n",
      "layer   2  Sparsity: 59.1699%\n",
      "layer   3  Sparsity: 79.9670%\n",
      "total_backward_count 548240 real_backward_count 113821  20.761%\n",
      "epoch-56  lr=['0.0039062'], tr/val_loss:  0.027161/  0.061148, val:  61.67%, val_best:  77.92%, tr:  93.36%, tr_best:  93.36%, epoch time: 55.07 seconds, 0.92 minutes\n",
      "layer   1  Sparsity: 91.0575%\n",
      "layer   2  Sparsity: 59.2116%\n",
      "layer   3  Sparsity: 80.0549%\n",
      "total_backward_count 558030 real_backward_count 115366  20.674%\n",
      "epoch-57  lr=['0.0039062'], tr/val_loss:  0.027156/  0.050956, val:  77.50%, val_best:  77.92%, tr:  92.95%, tr_best:  93.36%, epoch time: 55.82 seconds, 0.93 minutes\n",
      "layer   1  Sparsity: 91.0932%\n",
      "layer   2  Sparsity: 59.1942%\n",
      "layer   3  Sparsity: 80.2038%\n",
      "total_backward_count 567820 real_backward_count 116935  20.594%\n",
      "epoch-58  lr=['0.0039062'], tr/val_loss:  0.027209/  0.053299, val:  79.58%, val_best:  79.58%, tr:  93.77%, tr_best:  93.77%, epoch time: 55.58 seconds, 0.93 minutes\n",
      "layer   1  Sparsity: 91.0817%\n",
      "layer   2  Sparsity: 59.2354%\n",
      "layer   3  Sparsity: 80.3240%\n",
      "total_backward_count 577610 real_backward_count 118475  20.511%\n",
      "epoch-59  lr=['0.0039062'], tr/val_loss:  0.025518/  0.052816, val:  74.17%, val_best:  79.58%, tr:  94.79%, tr_best:  94.79%, epoch time: 55.75 seconds, 0.93 minutes\n",
      "layer   1  Sparsity: 91.0923%\n",
      "layer   2  Sparsity: 59.1534%\n",
      "layer   3  Sparsity: 80.3246%\n",
      "total_backward_count 587400 real_backward_count 119880  20.409%\n",
      "epoch-60  lr=['0.0039062'], tr/val_loss:  0.026530/  0.055888, val:  67.92%, val_best:  79.58%, tr:  94.28%, tr_best:  94.79%, epoch time: 54.79 seconds, 0.91 minutes\n",
      "layer   1  Sparsity: 91.0894%\n",
      "layer   2  Sparsity: 59.1743%\n",
      "layer   3  Sparsity: 80.4902%\n",
      "total_backward_count 597190 real_backward_count 121422  20.332%\n",
      "epoch-61  lr=['0.0039062'], tr/val_loss:  0.025913/  0.049386, val:  78.75%, val_best:  79.58%, tr:  94.89%, tr_best:  94.89%, epoch time: 55.72 seconds, 0.93 minutes\n",
      "layer   1  Sparsity: 91.0804%\n",
      "layer   2  Sparsity: 59.1452%\n",
      "layer   3  Sparsity: 80.5740%\n",
      "total_backward_count 606980 real_backward_count 122898  20.247%\n",
      "epoch-62  lr=['0.0039062'], tr/val_loss:  0.025307/  0.049284, val:  78.75%, val_best:  79.58%, tr:  95.91%, tr_best:  95.91%, epoch time: 55.19 seconds, 0.92 minutes\n",
      "layer   1  Sparsity: 91.0552%\n",
      "layer   2  Sparsity: 59.1651%\n",
      "layer   3  Sparsity: 80.7032%\n",
      "total_backward_count 616770 real_backward_count 124301  20.154%\n",
      "epoch-63  lr=['0.0039062'], tr/val_loss:  0.024864/  0.049770, val:  79.58%, val_best:  79.58%, tr:  95.30%, tr_best:  95.91%, epoch time: 55.23 seconds, 0.92 minutes\n",
      "layer   1  Sparsity: 91.0974%\n",
      "layer   2  Sparsity: 59.0987%\n",
      "layer   3  Sparsity: 80.7285%\n",
      "total_backward_count 626560 real_backward_count 125728  20.066%\n",
      "epoch-64  lr=['0.0039062'], tr/val_loss:  0.024873/  0.050219, val:  75.00%, val_best:  79.58%, tr:  95.51%, tr_best:  95.91%, epoch time: 55.74 seconds, 0.93 minutes\n",
      "layer   1  Sparsity: 91.0597%\n",
      "layer   2  Sparsity: 59.1505%\n",
      "layer   3  Sparsity: 80.8550%\n",
      "total_backward_count 636350 real_backward_count 127132  19.978%\n",
      "epoch-65  lr=['0.0039062'], tr/val_loss:  0.024290/  0.047756, val:  83.75%, val_best:  83.75%, tr:  96.22%, tr_best:  96.22%, epoch time: 55.25 seconds, 0.92 minutes\n",
      "layer   1  Sparsity: 91.0996%\n",
      "layer   2  Sparsity: 59.2725%\n",
      "layer   3  Sparsity: 80.9420%\n",
      "total_backward_count 646140 real_backward_count 128439  19.878%\n",
      "epoch-66  lr=['0.0039062'], tr/val_loss:  0.024533/  0.049117, val:  77.50%, val_best:  83.75%, tr:  94.89%, tr_best:  96.22%, epoch time: 54.63 seconds, 0.91 minutes\n",
      "layer   1  Sparsity: 91.0804%\n",
      "layer   2  Sparsity: 59.2926%\n",
      "layer   3  Sparsity: 81.1086%\n",
      "total_backward_count 655930 real_backward_count 129832  19.794%\n",
      "epoch-67  lr=['0.0039062'], tr/val_loss:  0.023166/  0.046835, val:  82.50%, val_best:  83.75%, tr:  95.91%, tr_best:  96.22%, epoch time: 54.52 seconds, 0.91 minutes\n",
      "layer   1  Sparsity: 91.0457%\n",
      "layer   2  Sparsity: 59.3281%\n",
      "layer   3  Sparsity: 81.0920%\n",
      "total_backward_count 665720 real_backward_count 131109  19.694%\n",
      "epoch-68  lr=['0.0039062'], tr/val_loss:  0.023859/  0.049801, val:  76.25%, val_best:  83.75%, tr:  96.02%, tr_best:  96.22%, epoch time: 54.23 seconds, 0.90 minutes\n",
      "layer   1  Sparsity: 91.0435%\n",
      "layer   2  Sparsity: 59.3301%\n",
      "layer   3  Sparsity: 81.2824%\n",
      "total_backward_count 675510 real_backward_count 132416  19.602%\n",
      "epoch-69  lr=['0.0039062'], tr/val_loss:  0.022227/  0.052810, val:  75.42%, val_best:  83.75%, tr:  96.73%, tr_best:  96.73%, epoch time: 54.78 seconds, 0.91 minutes\n",
      "layer   1  Sparsity: 91.0832%\n",
      "layer   2  Sparsity: 59.3236%\n",
      "layer   3  Sparsity: 81.2499%\n",
      "total_backward_count 685300 real_backward_count 133594  19.494%\n",
      "epoch-70  lr=['0.0039062'], tr/val_loss:  0.022954/  0.049196, val:  77.08%, val_best:  83.75%, tr:  96.53%, tr_best:  96.73%, epoch time: 55.16 seconds, 0.92 minutes\n",
      "layer   1  Sparsity: 91.0955%\n",
      "layer   2  Sparsity: 59.2303%\n",
      "layer   3  Sparsity: 81.4859%\n",
      "total_backward_count 695090 real_backward_count 134879  19.405%\n",
      "epoch-71  lr=['0.0039062'], tr/val_loss:  0.023098/  0.049552, val:  75.83%, val_best:  83.75%, tr:  96.63%, tr_best:  96.73%, epoch time: 55.08 seconds, 0.92 minutes\n",
      "layer   1  Sparsity: 91.0834%\n",
      "layer   2  Sparsity: 59.3055%\n",
      "layer   3  Sparsity: 81.4676%\n",
      "total_backward_count 704880 real_backward_count 136196  19.322%\n",
      "epoch-72  lr=['0.0039062'], tr/val_loss:  0.021770/  0.047825, val:  82.08%, val_best:  83.75%, tr:  96.53%, tr_best:  96.73%, epoch time: 55.07 seconds, 0.92 minutes\n",
      "layer   1  Sparsity: 91.0673%\n",
      "layer   2  Sparsity: 59.2831%\n",
      "layer   3  Sparsity: 81.5769%\n",
      "total_backward_count 714670 real_backward_count 137384  19.223%\n",
      "epoch-73  lr=['0.0039062'], tr/val_loss:  0.022402/  0.045908, val:  83.33%, val_best:  83.75%, tr:  96.63%, tr_best:  96.73%, epoch time: 56.04 seconds, 0.93 minutes\n",
      "layer   1  Sparsity: 91.0661%\n",
      "layer   2  Sparsity: 59.2861%\n",
      "layer   3  Sparsity: 81.6360%\n",
      "total_backward_count 724460 real_backward_count 138578  19.128%\n",
      "epoch-74  lr=['0.0039062'], tr/val_loss:  0.022374/  0.048047, val:  80.42%, val_best:  83.75%, tr:  97.45%, tr_best:  97.45%, epoch time: 55.75 seconds, 0.93 minutes\n",
      "layer   1  Sparsity: 91.0817%\n",
      "layer   2  Sparsity: 59.3375%\n",
      "layer   3  Sparsity: 81.6829%\n",
      "total_backward_count 734250 real_backward_count 139800  19.040%\n",
      "epoch-75  lr=['0.0039062'], tr/val_loss:  0.022027/  0.048782, val:  80.00%, val_best:  83.75%, tr:  96.94%, tr_best:  97.45%, epoch time: 55.37 seconds, 0.92 minutes\n",
      "layer   1  Sparsity: 91.0911%\n",
      "layer   2  Sparsity: 59.2484%\n",
      "layer   3  Sparsity: 81.7983%\n",
      "total_backward_count 744040 real_backward_count 140986  18.949%\n",
      "epoch-76  lr=['0.0039062'], tr/val_loss:  0.021992/  0.046907, val:  82.92%, val_best:  83.75%, tr:  96.83%, tr_best:  97.45%, epoch time: 55.38 seconds, 0.92 minutes\n",
      "layer   1  Sparsity: 91.0898%\n",
      "layer   2  Sparsity: 59.2973%\n",
      "layer   3  Sparsity: 81.9667%\n",
      "total_backward_count 753830 real_backward_count 142176  18.860%\n",
      "epoch-77  lr=['0.0039062'], tr/val_loss:  0.021615/  0.046215, val:  82.50%, val_best:  83.75%, tr:  97.34%, tr_best:  97.45%, epoch time: 55.10 seconds, 0.92 minutes\n",
      "layer   1  Sparsity: 91.0922%\n",
      "layer   2  Sparsity: 59.1535%\n",
      "layer   3  Sparsity: 82.0052%\n",
      "total_backward_count 763620 real_backward_count 143352  18.773%\n",
      "epoch-78  lr=['0.0039062'], tr/val_loss:  0.020681/  0.047364, val:  81.25%, val_best:  83.75%, tr:  97.55%, tr_best:  97.55%, epoch time: 55.02 seconds, 0.92 minutes\n",
      "layer   1  Sparsity: 91.0785%\n",
      "layer   2  Sparsity: 59.1898%\n",
      "layer   3  Sparsity: 82.0084%\n",
      "total_backward_count 773410 real_backward_count 144463  18.679%\n",
      "epoch-79  lr=['0.0039062'], tr/val_loss:  0.020935/  0.045795, val:  82.92%, val_best:  83.75%, tr:  97.45%, tr_best:  97.55%, epoch time: 55.35 seconds, 0.92 minutes\n",
      "layer   1  Sparsity: 91.0810%\n",
      "layer   2  Sparsity: 59.2121%\n",
      "layer   3  Sparsity: 82.1260%\n",
      "total_backward_count 783200 real_backward_count 145607  18.591%\n",
      "epoch-80  lr=['0.0039062'], tr/val_loss:  0.020558/  0.046752, val:  82.92%, val_best:  83.75%, tr:  97.55%, tr_best:  97.55%, epoch time: 55.18 seconds, 0.92 minutes\n",
      "layer   1  Sparsity: 91.0781%\n",
      "layer   2  Sparsity: 59.1937%\n",
      "layer   3  Sparsity: 82.1828%\n",
      "total_backward_count 792990 real_backward_count 146712  18.501%\n",
      "epoch-81  lr=['0.0039062'], tr/val_loss:  0.020497/  0.045445, val:  81.25%, val_best:  83.75%, tr:  97.85%, tr_best:  97.85%, epoch time: 55.32 seconds, 0.92 minutes\n",
      "layer   1  Sparsity: 91.1029%\n",
      "layer   2  Sparsity: 59.1760%\n",
      "layer   3  Sparsity: 82.3056%\n",
      "total_backward_count 802780 real_backward_count 147820  18.414%\n",
      "epoch-82  lr=['0.0039062'], tr/val_loss:  0.020660/  0.046948, val:  82.50%, val_best:  83.75%, tr:  97.65%, tr_best:  97.85%, epoch time: 55.97 seconds, 0.93 minutes\n",
      "layer   1  Sparsity: 91.0708%\n",
      "layer   2  Sparsity: 59.1681%\n",
      "layer   3  Sparsity: 82.4255%\n",
      "total_backward_count 812570 real_backward_count 148929  18.328%\n",
      "epoch-83  lr=['0.0039062'], tr/val_loss:  0.020318/  0.048046, val:  79.58%, val_best:  83.75%, tr:  97.45%, tr_best:  97.85%, epoch time: 55.53 seconds, 0.93 minutes\n",
      "layer   1  Sparsity: 91.0975%\n",
      "layer   2  Sparsity: 59.2122%\n",
      "layer   3  Sparsity: 82.4089%\n",
      "total_backward_count 822360 real_backward_count 150004  18.241%\n",
      "epoch-84  lr=['0.0039062'], tr/val_loss:  0.020335/  0.046571, val:  78.75%, val_best:  83.75%, tr:  97.55%, tr_best:  97.85%, epoch time: 55.43 seconds, 0.92 minutes\n",
      "layer   1  Sparsity: 91.0784%\n",
      "layer   2  Sparsity: 59.1039%\n",
      "layer   3  Sparsity: 82.5811%\n",
      "total_backward_count 832150 real_backward_count 151085  18.156%\n",
      "epoch-85  lr=['0.0039062'], tr/val_loss:  0.020394/  0.042298, val:  85.42%, val_best:  85.42%, tr:  96.73%, tr_best:  97.85%, epoch time: 55.09 seconds, 0.92 minutes\n",
      "layer   1  Sparsity: 91.0491%\n",
      "layer   2  Sparsity: 59.1523%\n",
      "layer   3  Sparsity: 82.6449%\n",
      "total_backward_count 841940 real_backward_count 152192  18.076%\n",
      "epoch-86  lr=['0.0039062'], tr/val_loss:  0.019712/  0.046685, val:  80.83%, val_best:  85.42%, tr:  98.26%, tr_best:  98.26%, epoch time: 55.31 seconds, 0.92 minutes\n",
      "layer   1  Sparsity: 91.1068%\n",
      "layer   2  Sparsity: 59.1735%\n",
      "layer   3  Sparsity: 82.7267%\n",
      "total_backward_count 851730 real_backward_count 153209  17.988%\n",
      "epoch-87  lr=['0.0039062'], tr/val_loss:  0.020325/  0.043059, val:  82.92%, val_best:  85.42%, tr:  97.45%, tr_best:  98.26%, epoch time: 55.61 seconds, 0.93 minutes\n",
      "layer   1  Sparsity: 91.0911%\n",
      "layer   2  Sparsity: 59.2153%\n",
      "layer   3  Sparsity: 82.7288%\n",
      "total_backward_count 861520 real_backward_count 154336  17.914%\n",
      "epoch-88  lr=['0.0039062'], tr/val_loss:  0.018729/  0.048244, val:  81.67%, val_best:  85.42%, tr:  97.85%, tr_best:  98.26%, epoch time: 55.41 seconds, 0.92 minutes\n",
      "layer   1  Sparsity: 91.0739%\n",
      "layer   2  Sparsity: 59.1675%\n",
      "layer   3  Sparsity: 82.8416%\n",
      "total_backward_count 871310 real_backward_count 155304  17.824%\n",
      "epoch-89  lr=['0.0039062'], tr/val_loss:  0.018429/  0.042907, val:  86.25%, val_best:  86.25%, tr:  97.45%, tr_best:  98.26%, epoch time: 55.13 seconds, 0.92 minutes\n",
      "layer   1  Sparsity: 91.0906%\n",
      "layer   2  Sparsity: 59.1413%\n",
      "layer   3  Sparsity: 82.9365%\n",
      "total_backward_count 881100 real_backward_count 156298  17.739%\n",
      "epoch-90  lr=['0.0039062'], tr/val_loss:  0.018965/  0.043075, val:  85.42%, val_best:  86.25%, tr:  98.16%, tr_best:  98.26%, epoch time: 55.04 seconds, 0.92 minutes\n",
      "layer   1  Sparsity: 91.0644%\n",
      "layer   2  Sparsity: 59.2064%\n",
      "layer   3  Sparsity: 83.0170%\n",
      "total_backward_count 890890 real_backward_count 157320  17.659%\n",
      "epoch-91  lr=['0.0039062'], tr/val_loss:  0.018525/  0.045690, val:  83.33%, val_best:  86.25%, tr:  98.06%, tr_best:  98.26%, epoch time: 55.37 seconds, 0.92 minutes\n",
      "layer   1  Sparsity: 91.0695%\n",
      "layer   2  Sparsity: 59.1837%\n",
      "layer   3  Sparsity: 83.0748%\n",
      "total_backward_count 900680 real_backward_count 158290  17.574%\n",
      "epoch-92  lr=['0.0039062'], tr/val_loss:  0.019356/  0.046463, val:  80.42%, val_best:  86.25%, tr:  98.37%, tr_best:  98.37%, epoch time: 55.06 seconds, 0.92 minutes\n",
      "layer   1  Sparsity: 91.0517%\n",
      "layer   2  Sparsity: 59.2317%\n",
      "layer   3  Sparsity: 83.1235%\n",
      "total_backward_count 910470 real_backward_count 159324  17.499%\n",
      "epoch-93  lr=['0.0039062'], tr/val_loss:  0.018957/  0.042919, val:  85.42%, val_best:  86.25%, tr:  98.47%, tr_best:  98.47%, epoch time: 55.16 seconds, 0.92 minutes\n",
      "layer   1  Sparsity: 91.0391%\n",
      "layer   2  Sparsity: 59.2072%\n",
      "layer   3  Sparsity: 83.2313%\n",
      "total_backward_count 920260 real_backward_count 160337  17.423%\n",
      "epoch-94  lr=['0.0039062'], tr/val_loss:  0.017926/  0.045286, val:  81.25%, val_best:  86.25%, tr:  98.57%, tr_best:  98.57%, epoch time: 55.26 seconds, 0.92 minutes\n",
      "layer   1  Sparsity: 91.0510%\n",
      "layer   2  Sparsity: 59.2166%\n",
      "layer   3  Sparsity: 83.2433%\n",
      "total_backward_count 930050 real_backward_count 161259  17.339%\n",
      "epoch-95  lr=['0.0039062'], tr/val_loss:  0.018004/  0.045185, val:  79.17%, val_best:  86.25%, tr:  97.96%, tr_best:  98.57%, epoch time: 55.26 seconds, 0.92 minutes\n",
      "layer   1  Sparsity: 91.0508%\n",
      "layer   2  Sparsity: 59.1907%\n",
      "layer   3  Sparsity: 83.3589%\n",
      "total_backward_count 939840 real_backward_count 162196  17.258%\n",
      "epoch-96  lr=['0.0039062'], tr/val_loss:  0.018320/  0.042778, val:  85.00%, val_best:  86.25%, tr:  98.47%, tr_best:  98.57%, epoch time: 55.19 seconds, 0.92 minutes\n",
      "layer   1  Sparsity: 91.0878%\n",
      "layer   2  Sparsity: 59.1438%\n",
      "layer   3  Sparsity: 83.4543%\n",
      "total_backward_count 949630 real_backward_count 163180  17.184%\n",
      "epoch-97  lr=['0.0039062'], tr/val_loss:  0.017255/  0.044020, val:  80.83%, val_best:  86.25%, tr:  97.65%, tr_best:  98.57%, epoch time: 55.26 seconds, 0.92 minutes\n",
      "layer   1  Sparsity: 91.0852%\n",
      "layer   2  Sparsity: 59.0790%\n",
      "layer   3  Sparsity: 83.4788%\n",
      "total_backward_count 959420 real_backward_count 164062  17.100%\n",
      "epoch-98  lr=['0.0039062'], tr/val_loss:  0.016594/  0.042560, val:  86.25%, val_best:  86.25%, tr:  98.88%, tr_best:  98.88%, epoch time: 55.81 seconds, 0.93 minutes\n",
      "layer   1  Sparsity: 91.0637%\n",
      "layer   2  Sparsity: 59.1094%\n",
      "layer   3  Sparsity: 83.4731%\n",
      "total_backward_count 969210 real_backward_count 164875  17.011%\n",
      "epoch-99  lr=['0.0039062'], tr/val_loss:  0.017909/  0.044225, val:  82.92%, val_best:  86.25%, tr:  98.47%, tr_best:  98.88%, epoch time: 55.14 seconds, 0.92 minutes\n",
      "layer   1  Sparsity: 91.1269%\n",
      "layer   2  Sparsity: 59.2180%\n",
      "layer   3  Sparsity: 83.5768%\n",
      "total_backward_count 979000 real_backward_count 165784  16.934%\n",
      "epoch-100 lr=['0.0039062'], tr/val_loss:  0.017121/  0.044760, val:  81.25%, val_best:  86.25%, tr:  98.06%, tr_best:  98.88%, epoch time: 55.06 seconds, 0.92 minutes\n",
      "layer   1  Sparsity: 91.0744%\n",
      "layer   2  Sparsity: 59.2198%\n",
      "layer   3  Sparsity: 83.6721%\n",
      "total_backward_count 988790 real_backward_count 166672  16.856%\n",
      "epoch-101 lr=['0.0039062'], tr/val_loss:  0.017448/  0.040055, val:  85.83%, val_best:  86.25%, tr:  98.47%, tr_best:  98.88%, epoch time: 55.69 seconds, 0.93 minutes\n",
      "layer   1  Sparsity: 91.1095%\n",
      "layer   2  Sparsity: 59.1185%\n",
      "layer   3  Sparsity: 83.7828%\n",
      "total_backward_count 998580 real_backward_count 167601  16.784%\n",
      "epoch-102 lr=['0.0039062'], tr/val_loss:  0.016779/  0.040900, val:  86.25%, val_best:  86.25%, tr:  98.77%, tr_best:  98.88%, epoch time: 55.30 seconds, 0.92 minutes\n",
      "layer   1  Sparsity: 91.0984%\n",
      "layer   2  Sparsity: 59.1321%\n",
      "layer   3  Sparsity: 83.8216%\n",
      "total_backward_count 1008370 real_backward_count 168474  16.708%\n",
      "epoch-103 lr=['0.0039062'], tr/val_loss:  0.016610/  0.043660, val:  83.33%, val_best:  86.25%, tr:  98.37%, tr_best:  98.88%, epoch time: 55.10 seconds, 0.92 minutes\n",
      "layer   1  Sparsity: 91.0740%\n",
      "layer   2  Sparsity: 59.1427%\n",
      "layer   3  Sparsity: 83.8539%\n",
      "total_backward_count 1018160 real_backward_count 169325  16.630%\n",
      "epoch-104 lr=['0.0039062'], tr/val_loss:  0.016391/  0.041170, val:  84.58%, val_best:  86.25%, tr:  98.67%, tr_best:  98.88%, epoch time: 55.88 seconds, 0.93 minutes\n",
      "layer   1  Sparsity: 91.0523%\n",
      "layer   2  Sparsity: 59.1788%\n",
      "layer   3  Sparsity: 83.8966%\n",
      "total_backward_count 1027950 real_backward_count 170186  16.556%\n",
      "epoch-105 lr=['0.0039062'], tr/val_loss:  0.017074/  0.042809, val:  84.58%, val_best:  86.25%, tr:  98.57%, tr_best:  98.88%, epoch time: 55.43 seconds, 0.92 minutes\n",
      "layer   1  Sparsity: 91.0861%\n",
      "layer   2  Sparsity: 59.1833%\n",
      "layer   3  Sparsity: 83.9487%\n",
      "total_backward_count 1037740 real_backward_count 171086  16.486%\n",
      "epoch-106 lr=['0.0039062'], tr/val_loss:  0.016132/  0.040831, val:  85.00%, val_best:  86.25%, tr:  98.47%, tr_best:  98.88%, epoch time: 55.26 seconds, 0.92 minutes\n",
      "layer   1  Sparsity: 91.0828%\n",
      "layer   2  Sparsity: 59.1549%\n",
      "layer   3  Sparsity: 84.0039%\n",
      "total_backward_count 1047530 real_backward_count 171927  16.413%\n",
      "epoch-107 lr=['0.0039062'], tr/val_loss:  0.015645/  0.042720, val:  84.58%, val_best:  86.25%, tr:  98.77%, tr_best:  98.88%, epoch time: 55.43 seconds, 0.92 minutes\n",
      "layer   1  Sparsity: 91.0991%\n",
      "layer   2  Sparsity: 59.2161%\n",
      "layer   3  Sparsity: 84.0500%\n",
      "total_backward_count 1057320 real_backward_count 172711  16.335%\n",
      "epoch-108 lr=['0.0039062'], tr/val_loss:  0.015711/  0.042635, val:  83.75%, val_best:  86.25%, tr:  98.88%, tr_best:  98.88%, epoch time: 55.43 seconds, 0.92 minutes\n",
      "layer   1  Sparsity: 91.0783%\n",
      "layer   2  Sparsity: 59.1589%\n",
      "layer   3  Sparsity: 84.1194%\n",
      "total_backward_count 1067110 real_backward_count 173506  16.259%\n",
      "epoch-109 lr=['0.0039062'], tr/val_loss:  0.016185/  0.042259, val:  87.08%, val_best:  87.08%, tr:  98.77%, tr_best:  98.88%, epoch time: 55.25 seconds, 0.92 minutes\n",
      "layer   1  Sparsity: 91.0918%\n",
      "layer   2  Sparsity: 59.1929%\n",
      "layer   3  Sparsity: 84.1704%\n",
      "total_backward_count 1076900 real_backward_count 174342  16.189%\n",
      "epoch-110 lr=['0.0039062'], tr/val_loss:  0.016042/  0.042132, val:  84.58%, val_best:  87.08%, tr:  98.67%, tr_best:  98.88%, epoch time: 54.68 seconds, 0.91 minutes\n",
      "layer   1  Sparsity: 91.1205%\n",
      "layer   2  Sparsity: 59.2142%\n",
      "layer   3  Sparsity: 84.2420%\n",
      "total_backward_count 1086690 real_backward_count 175172  16.120%\n",
      "epoch-111 lr=['0.0039062'], tr/val_loss:  0.015703/  0.045606, val:  80.00%, val_best:  87.08%, tr:  98.98%, tr_best:  98.98%, epoch time: 55.21 seconds, 0.92 minutes\n",
      "layer   1  Sparsity: 91.1010%\n",
      "layer   2  Sparsity: 59.0853%\n",
      "layer   3  Sparsity: 84.2697%\n",
      "total_backward_count 1096480 real_backward_count 175964  16.048%\n",
      "epoch-112 lr=['0.0039062'], tr/val_loss:  0.015311/  0.044160, val:  83.75%, val_best:  87.08%, tr:  99.08%, tr_best:  99.08%, epoch time: 54.68 seconds, 0.91 minutes\n",
      "layer   1  Sparsity: 91.0658%\n",
      "layer   2  Sparsity: 59.0590%\n",
      "layer   3  Sparsity: 84.3938%\n",
      "total_backward_count 1106270 real_backward_count 176764  15.978%\n",
      "epoch-113 lr=['0.0039062'], tr/val_loss:  0.015908/  0.043806, val:  84.17%, val_best:  87.08%, tr:  98.98%, tr_best:  99.08%, epoch time: 55.14 seconds, 0.92 minutes\n",
      "layer   1  Sparsity: 91.1027%\n",
      "layer   2  Sparsity: 59.0833%\n",
      "layer   3  Sparsity: 84.4727%\n",
      "total_backward_count 1116060 real_backward_count 177585  15.912%\n",
      "epoch-114 lr=['0.0039062'], tr/val_loss:  0.015555/  0.042213, val:  83.33%, val_best:  87.08%, tr:  98.57%, tr_best:  99.08%, epoch time: 55.22 seconds, 0.92 minutes\n",
      "layer   1  Sparsity: 91.0841%\n",
      "layer   2  Sparsity: 59.1386%\n",
      "layer   3  Sparsity: 84.5581%\n",
      "total_backward_count 1125850 real_backward_count 178413  15.847%\n",
      "epoch-115 lr=['0.0039062'], tr/val_loss:  0.015390/  0.043800, val:  82.08%, val_best:  87.08%, tr:  98.77%, tr_best:  99.08%, epoch time: 54.52 seconds, 0.91 minutes\n",
      "layer   1  Sparsity: 91.0650%\n",
      "layer   2  Sparsity: 59.1269%\n",
      "layer   3  Sparsity: 84.6201%\n",
      "total_backward_count 1135640 real_backward_count 179214  15.781%\n",
      "epoch-116 lr=['0.0039062'], tr/val_loss:  0.015635/  0.041067, val:  86.67%, val_best:  87.08%, tr:  98.67%, tr_best:  99.08%, epoch time: 55.52 seconds, 0.93 minutes\n",
      "layer   1  Sparsity: 91.0938%\n",
      "layer   2  Sparsity: 59.0582%\n",
      "layer   3  Sparsity: 84.7141%\n",
      "total_backward_count 1145430 real_backward_count 180040  15.718%\n",
      "epoch-117 lr=['0.0039062'], tr/val_loss:  0.014768/  0.040255, val:  87.08%, val_best:  87.08%, tr:  99.18%, tr_best:  99.18%, epoch time: 55.77 seconds, 0.93 minutes\n",
      "layer   1  Sparsity: 91.0879%\n",
      "layer   2  Sparsity: 59.0673%\n",
      "layer   3  Sparsity: 84.7797%\n",
      "total_backward_count 1155220 real_backward_count 180787  15.650%\n",
      "epoch-118 lr=['0.0039062'], tr/val_loss:  0.014782/  0.042054, val:  83.33%, val_best:  87.08%, tr:  98.98%, tr_best:  99.18%, epoch time: 55.31 seconds, 0.92 minutes\n",
      "layer   1  Sparsity: 91.1060%\n",
      "layer   2  Sparsity: 59.1044%\n",
      "layer   3  Sparsity: 84.7562%\n",
      "total_backward_count 1165010 real_backward_count 181555  15.584%\n",
      "epoch-119 lr=['0.0039062'], tr/val_loss:  0.014382/  0.040133, val:  87.92%, val_best:  87.92%, tr:  98.77%, tr_best:  99.18%, epoch time: 55.17 seconds, 0.92 minutes\n",
      "layer   1  Sparsity: 91.1018%\n",
      "layer   2  Sparsity: 59.1383%\n",
      "layer   3  Sparsity: 84.7806%\n",
      "total_backward_count 1174800 real_backward_count 182275  15.515%\n",
      "epoch-120 lr=['0.0039062'], tr/val_loss:  0.014259/  0.043226, val:  82.50%, val_best:  87.92%, tr:  99.28%, tr_best:  99.28%, epoch time: 55.26 seconds, 0.92 minutes\n",
      "layer   1  Sparsity: 91.0700%\n",
      "layer   2  Sparsity: 59.0858%\n",
      "layer   3  Sparsity: 84.8661%\n",
      "total_backward_count 1184590 real_backward_count 183003  15.449%\n",
      "epoch-121 lr=['0.0039062'], tr/val_loss:  0.014370/  0.043570, val:  82.50%, val_best:  87.92%, tr:  98.77%, tr_best:  99.28%, epoch time: 54.73 seconds, 0.91 minutes\n",
      "layer   1  Sparsity: 91.0853%\n",
      "layer   2  Sparsity: 59.0671%\n",
      "layer   3  Sparsity: 84.9087%\n",
      "total_backward_count 1194380 real_backward_count 183745  15.384%\n",
      "epoch-122 lr=['0.0039062'], tr/val_loss:  0.014435/  0.040965, val:  87.50%, val_best:  87.92%, tr:  99.18%, tr_best:  99.28%, epoch time: 54.83 seconds, 0.91 minutes\n",
      "layer   1  Sparsity: 91.1018%\n",
      "layer   2  Sparsity: 59.0386%\n",
      "layer   3  Sparsity: 84.9521%\n",
      "total_backward_count 1204170 real_backward_count 184436  15.316%\n",
      "epoch-123 lr=['0.0039062'], tr/val_loss:  0.014778/  0.042540, val:  84.17%, val_best:  87.92%, tr:  99.18%, tr_best:  99.28%, epoch time: 55.31 seconds, 0.92 minutes\n",
      "layer   1  Sparsity: 91.0888%\n",
      "layer   2  Sparsity: 59.1067%\n",
      "layer   3  Sparsity: 84.9541%\n",
      "total_backward_count 1213960 real_backward_count 185184  15.255%\n",
      "epoch-124 lr=['0.0039062'], tr/val_loss:  0.014387/  0.040781, val:  83.75%, val_best:  87.92%, tr:  99.18%, tr_best:  99.28%, epoch time: 55.77 seconds, 0.93 minutes\n",
      "layer   1  Sparsity: 91.0567%\n",
      "layer   2  Sparsity: 59.1029%\n",
      "layer   3  Sparsity: 84.9924%\n",
      "total_backward_count 1223750 real_backward_count 185908  15.192%\n",
      "epoch-125 lr=['0.0039062'], tr/val_loss:  0.014011/  0.043282, val:  83.75%, val_best:  87.92%, tr:  99.18%, tr_best:  99.28%, epoch time: 55.13 seconds, 0.92 minutes\n",
      "layer   1  Sparsity: 91.0661%\n",
      "layer   2  Sparsity: 59.0788%\n",
      "layer   3  Sparsity: 85.0896%\n",
      "total_backward_count 1233540 real_backward_count 186621  15.129%\n",
      "epoch-126 lr=['0.0039062'], tr/val_loss:  0.014816/  0.038624, val:  88.33%, val_best:  88.33%, tr:  99.18%, tr_best:  99.28%, epoch time: 55.72 seconds, 0.93 minutes\n",
      "layer   1  Sparsity: 91.0773%\n",
      "layer   2  Sparsity: 59.0767%\n",
      "layer   3  Sparsity: 85.1340%\n",
      "total_backward_count 1243330 real_backward_count 187403  15.073%\n",
      "epoch-127 lr=['0.0039062'], tr/val_loss:  0.013855/  0.040608, val:  84.17%, val_best:  88.33%, tr:  99.08%, tr_best:  99.28%, epoch time: 55.22 seconds, 0.92 minutes\n",
      "layer   1  Sparsity: 91.0729%\n",
      "layer   2  Sparsity: 59.0682%\n",
      "layer   3  Sparsity: 85.1576%\n",
      "total_backward_count 1253120 real_backward_count 188110  15.011%\n",
      "epoch-128 lr=['0.0039062'], tr/val_loss:  0.014260/  0.041112, val:  86.67%, val_best:  88.33%, tr:  99.08%, tr_best:  99.28%, epoch time: 55.28 seconds, 0.92 minutes\n",
      "layer   1  Sparsity: 91.1244%\n",
      "layer   2  Sparsity: 58.9742%\n",
      "layer   3  Sparsity: 85.2425%\n",
      "total_backward_count 1262910 real_backward_count 188815  14.951%\n",
      "epoch-129 lr=['0.0039062'], tr/val_loss:  0.013496/  0.039550, val:  85.00%, val_best:  88.33%, tr:  99.39%, tr_best:  99.39%, epoch time: 55.03 seconds, 0.92 minutes\n",
      "layer   1  Sparsity: 91.0652%\n",
      "layer   2  Sparsity: 58.9067%\n",
      "layer   3  Sparsity: 85.3509%\n",
      "total_backward_count 1272700 real_backward_count 189476  14.888%\n",
      "epoch-130 lr=['0.0039062'], tr/val_loss:  0.014314/  0.040288, val:  86.67%, val_best:  88.33%, tr:  99.28%, tr_best:  99.39%, epoch time: 55.23 seconds, 0.92 minutes\n",
      "layer   1  Sparsity: 91.1292%\n",
      "layer   2  Sparsity: 58.9288%\n",
      "layer   3  Sparsity: 85.3621%\n",
      "total_backward_count 1282490 real_backward_count 190211  14.831%\n",
      "epoch-131 lr=['0.0039062'], tr/val_loss:  0.014267/  0.040884, val:  85.83%, val_best:  88.33%, tr:  98.88%, tr_best:  99.39%, epoch time: 55.25 seconds, 0.92 minutes\n",
      "layer   1  Sparsity: 91.0464%\n",
      "layer   2  Sparsity: 58.9890%\n",
      "layer   3  Sparsity: 85.3699%\n",
      "total_backward_count 1292280 real_backward_count 190942  14.776%\n",
      "epoch-132 lr=['0.0039062'], tr/val_loss:  0.012669/  0.041705, val:  85.83%, val_best:  88.33%, tr:  99.59%, tr_best:  99.59%, epoch time: 55.46 seconds, 0.92 minutes\n",
      "layer   1  Sparsity: 91.0770%\n",
      "layer   2  Sparsity: 58.8607%\n",
      "layer   3  Sparsity: 85.4063%\n",
      "total_backward_count 1302070 real_backward_count 191549  14.711%\n",
      "epoch-133 lr=['0.0039062'], tr/val_loss:  0.013346/  0.042629, val:  84.17%, val_best:  88.33%, tr:  99.39%, tr_best:  99.59%, epoch time: 55.22 seconds, 0.92 minutes\n",
      "layer   1  Sparsity: 91.0749%\n",
      "layer   2  Sparsity: 58.8502%\n",
      "layer   3  Sparsity: 85.4337%\n",
      "total_backward_count 1311860 real_backward_count 192225  14.653%\n",
      "epoch-134 lr=['0.0039062'], tr/val_loss:  0.013167/  0.040012, val:  84.58%, val_best:  88.33%, tr:  99.59%, tr_best:  99.59%, epoch time: 54.82 seconds, 0.91 minutes\n",
      "layer   1  Sparsity: 91.0846%\n",
      "layer   2  Sparsity: 58.9829%\n",
      "layer   3  Sparsity: 85.4234%\n",
      "total_backward_count 1321650 real_backward_count 192866  14.593%\n",
      "epoch-135 lr=['0.0039062'], tr/val_loss:  0.013345/  0.039352, val:  87.50%, val_best:  88.33%, tr:  99.59%, tr_best:  99.59%, epoch time: 55.33 seconds, 0.92 minutes\n",
      "layer   1  Sparsity: 91.0904%\n",
      "layer   2  Sparsity: 58.9589%\n",
      "layer   3  Sparsity: 85.4436%\n",
      "total_backward_count 1331440 real_backward_count 193519  14.535%\n",
      "epoch-136 lr=['0.0039062'], tr/val_loss:  0.013223/  0.039414, val:  88.75%, val_best:  88.75%, tr:  99.28%, tr_best:  99.59%, epoch time: 55.16 seconds, 0.92 minutes\n",
      "layer   1  Sparsity: 91.0943%\n",
      "layer   2  Sparsity: 58.8337%\n",
      "layer   3  Sparsity: 85.5654%\n",
      "total_backward_count 1341230 real_backward_count 194210  14.480%\n",
      "epoch-137 lr=['0.0039062'], tr/val_loss:  0.013789/  0.039832, val:  85.42%, val_best:  88.75%, tr:  99.39%, tr_best:  99.59%, epoch time: 56.18 seconds, 0.94 minutes\n",
      "layer   1  Sparsity: 91.0484%\n",
      "layer   2  Sparsity: 58.8863%\n",
      "layer   3  Sparsity: 85.6250%\n",
      "total_backward_count 1351020 real_backward_count 194913  14.427%\n",
      "epoch-138 lr=['0.0039062'], tr/val_loss:  0.012674/  0.041126, val:  86.25%, val_best:  88.75%, tr:  99.49%, tr_best:  99.59%, epoch time: 50.86 seconds, 0.85 minutes\n",
      "layer   1  Sparsity: 91.0770%\n",
      "layer   2  Sparsity: 58.7915%\n",
      "layer   3  Sparsity: 85.6767%\n",
      "total_backward_count 1360810 real_backward_count 195542  14.370%\n",
      "epoch-139 lr=['0.0039062'], tr/val_loss:  0.013013/  0.041593, val:  83.33%, val_best:  88.75%, tr:  99.39%, tr_best:  99.59%, epoch time: 55.43 seconds, 0.92 minutes\n",
      "layer   1  Sparsity: 91.0739%\n",
      "layer   2  Sparsity: 58.7890%\n",
      "layer   3  Sparsity: 85.6815%\n",
      "total_backward_count 1370600 real_backward_count 196189  14.314%\n",
      "epoch-140 lr=['0.0039062'], tr/val_loss:  0.012760/  0.039009, val:  88.33%, val_best:  88.75%, tr:  99.08%, tr_best:  99.59%, epoch time: 54.82 seconds, 0.91 minutes\n",
      "layer   1  Sparsity: 91.0971%\n",
      "layer   2  Sparsity: 58.8174%\n",
      "layer   3  Sparsity: 85.7546%\n",
      "total_backward_count 1380390 real_backward_count 196813  14.258%\n",
      "epoch-141 lr=['0.0039062'], tr/val_loss:  0.013170/  0.040277, val:  86.25%, val_best:  88.75%, tr:  98.88%, tr_best:  99.59%, epoch time: 55.22 seconds, 0.92 minutes\n",
      "layer   1  Sparsity: 91.0761%\n",
      "layer   2  Sparsity: 58.8283%\n",
      "layer   3  Sparsity: 85.7613%\n",
      "total_backward_count 1390180 real_backward_count 197462  14.204%\n",
      "epoch-142 lr=['0.0039062'], tr/val_loss:  0.012944/  0.041004, val:  86.25%, val_best:  88.75%, tr:  99.18%, tr_best:  99.59%, epoch time: 56.02 seconds, 0.93 minutes\n",
      "layer   1  Sparsity: 91.0919%\n",
      "layer   2  Sparsity: 58.8338%\n",
      "layer   3  Sparsity: 85.7828%\n",
      "total_backward_count 1399970 real_backward_count 198109  14.151%\n",
      "epoch-143 lr=['0.0039062'], tr/val_loss:  0.012369/  0.040267, val:  86.25%, val_best:  88.75%, tr:  99.28%, tr_best:  99.59%, epoch time: 55.01 seconds, 0.92 minutes\n",
      "layer   1  Sparsity: 91.0909%\n",
      "layer   2  Sparsity: 58.8512%\n",
      "layer   3  Sparsity: 85.8279%\n",
      "total_backward_count 1409760 real_backward_count 198747  14.098%\n",
      "epoch-144 lr=['0.0039062'], tr/val_loss:  0.012564/  0.041128, val:  84.58%, val_best:  88.75%, tr:  98.88%, tr_best:  99.59%, epoch time: 55.25 seconds, 0.92 minutes\n",
      "layer   1  Sparsity: 91.1023%\n",
      "layer   2  Sparsity: 58.8260%\n",
      "layer   3  Sparsity: 85.8685%\n",
      "total_backward_count 1419550 real_backward_count 199366  14.044%\n",
      "epoch-145 lr=['0.0039062'], tr/val_loss:  0.011749/  0.038141, val:  88.33%, val_best:  88.75%, tr:  99.39%, tr_best:  99.59%, epoch time: 55.79 seconds, 0.93 minutes\n",
      "layer   1  Sparsity: 91.0525%\n",
      "layer   2  Sparsity: 58.7890%\n",
      "layer   3  Sparsity: 85.9458%\n",
      "total_backward_count 1429340 real_backward_count 199937  13.988%\n",
      "epoch-146 lr=['0.0039062'], tr/val_loss:  0.012471/  0.040215, val:  85.42%, val_best:  88.75%, tr:  99.59%, tr_best:  99.59%, epoch time: 55.65 seconds, 0.93 minutes\n",
      "layer   1  Sparsity: 91.0907%\n",
      "layer   2  Sparsity: 58.8295%\n",
      "layer   3  Sparsity: 85.9187%\n",
      "total_backward_count 1439130 real_backward_count 200562  13.936%\n",
      "epoch-147 lr=['0.0039062'], tr/val_loss:  0.012697/  0.040951, val:  85.83%, val_best:  88.75%, tr:  99.49%, tr_best:  99.59%, epoch time: 54.54 seconds, 0.91 minutes\n",
      "layer   1  Sparsity: 91.0824%\n",
      "layer   2  Sparsity: 58.7847%\n",
      "layer   3  Sparsity: 85.9515%\n",
      "total_backward_count 1448920 real_backward_count 201204  13.886%\n",
      "epoch-148 lr=['0.0039062'], tr/val_loss:  0.011360/  0.038550, val:  89.17%, val_best:  89.17%, tr:  99.69%, tr_best:  99.69%, epoch time: 54.78 seconds, 0.91 minutes\n",
      "layer   1  Sparsity: 91.0493%\n",
      "layer   2  Sparsity: 58.8574%\n",
      "layer   3  Sparsity: 85.9522%\n",
      "total_backward_count 1458710 real_backward_count 201750  13.831%\n",
      "epoch-149 lr=['0.0039062'], tr/val_loss:  0.012345/  0.041243, val:  88.33%, val_best:  89.17%, tr:  99.39%, tr_best:  99.69%, epoch time: 54.41 seconds, 0.91 minutes\n",
      "layer   1  Sparsity: 91.1010%\n",
      "layer   2  Sparsity: 58.9833%\n",
      "layer   3  Sparsity: 85.9785%\n",
      "total_backward_count 1468500 real_backward_count 202362  13.780%\n",
      "epoch-150 lr=['0.0039062'], tr/val_loss:  0.012284/  0.040494, val:  85.42%, val_best:  89.17%, tr:  99.69%, tr_best:  99.69%, epoch time: 54.75 seconds, 0.91 minutes\n",
      "layer   1  Sparsity: 91.0530%\n",
      "layer   2  Sparsity: 58.9477%\n",
      "layer   3  Sparsity: 86.0469%\n",
      "total_backward_count 1478290 real_backward_count 202977  13.731%\n",
      "epoch-151 lr=['0.0039062'], tr/val_loss:  0.011927/  0.043574, val:  84.17%, val_best:  89.17%, tr:  99.28%, tr_best:  99.69%, epoch time: 55.37 seconds, 0.92 minutes\n",
      "layer   1  Sparsity: 91.0732%\n",
      "layer   2  Sparsity: 58.8763%\n",
      "layer   3  Sparsity: 86.0735%\n",
      "total_backward_count 1488080 real_backward_count 203559  13.679%\n",
      "epoch-152 lr=['0.0039062'], tr/val_loss:  0.011861/  0.041211, val:  86.67%, val_best:  89.17%, tr:  99.49%, tr_best:  99.69%, epoch time: 55.49 seconds, 0.92 minutes\n",
      "layer   1  Sparsity: 91.0571%\n",
      "layer   2  Sparsity: 58.8161%\n",
      "layer   3  Sparsity: 86.1212%\n",
      "total_backward_count 1497870 real_backward_count 204158  13.630%\n",
      "epoch-153 lr=['0.0039062'], tr/val_loss:  0.011771/  0.042140, val:  84.17%, val_best:  89.17%, tr:  99.28%, tr_best:  99.69%, epoch time: 55.29 seconds, 0.92 minutes\n",
      "layer   1  Sparsity: 91.0906%\n",
      "layer   2  Sparsity: 58.7565%\n",
      "layer   3  Sparsity: 86.1578%\n",
      "total_backward_count 1507660 real_backward_count 204753  13.581%\n",
      "epoch-154 lr=['0.0039062'], tr/val_loss:  0.012238/  0.039811, val:  85.83%, val_best:  89.17%, tr:  99.49%, tr_best:  99.69%, epoch time: 55.71 seconds, 0.93 minutes\n",
      "layer   1  Sparsity: 91.0999%\n",
      "layer   2  Sparsity: 58.7605%\n",
      "layer   3  Sparsity: 86.2156%\n",
      "total_backward_count 1517450 real_backward_count 205366  13.534%\n",
      "epoch-155 lr=['0.0039062'], tr/val_loss:  0.011475/  0.040214, val:  87.08%, val_best:  89.17%, tr: 100.00%, tr_best: 100.00%, epoch time: 55.10 seconds, 0.92 minutes\n",
      "layer   1  Sparsity: 91.0851%\n",
      "layer   2  Sparsity: 58.7276%\n",
      "layer   3  Sparsity: 86.2208%\n",
      "total_backward_count 1527240 real_backward_count 205925  13.483%\n",
      "epoch-156 lr=['0.0039062'], tr/val_loss:  0.011295/  0.042620, val:  84.17%, val_best:  89.17%, tr:  99.59%, tr_best: 100.00%, epoch time: 54.80 seconds, 0.91 minutes\n",
      "layer   1  Sparsity: 91.0989%\n",
      "layer   2  Sparsity: 58.6733%\n",
      "layer   3  Sparsity: 86.2997%\n",
      "total_backward_count 1537030 real_backward_count 206485  13.434%\n",
      "epoch-157 lr=['0.0039062'], tr/val_loss:  0.011699/  0.042292, val:  86.25%, val_best:  89.17%, tr:  99.69%, tr_best: 100.00%, epoch time: 54.70 seconds, 0.91 minutes\n",
      "layer   1  Sparsity: 91.0847%\n",
      "layer   2  Sparsity: 58.7672%\n",
      "layer   3  Sparsity: 86.3065%\n",
      "total_backward_count 1546820 real_backward_count 207053  13.386%\n",
      "epoch-158 lr=['0.0039062'], tr/val_loss:  0.011155/  0.039315, val:  87.92%, val_best:  89.17%, tr:  99.39%, tr_best: 100.00%, epoch time: 54.74 seconds, 0.91 minutes\n",
      "layer   1  Sparsity: 91.0923%\n",
      "layer   2  Sparsity: 58.7131%\n",
      "layer   3  Sparsity: 86.2818%\n",
      "total_backward_count 1556610 real_backward_count 207599  13.337%\n",
      "epoch-159 lr=['0.0039062'], tr/val_loss:  0.011497/  0.039518, val:  88.33%, val_best:  89.17%, tr:  99.28%, tr_best: 100.00%, epoch time: 54.54 seconds, 0.91 minutes\n",
      "layer   1  Sparsity: 91.0716%\n",
      "layer   2  Sparsity: 58.7808%\n",
      "layer   3  Sparsity: 86.3337%\n",
      "total_backward_count 1566400 real_backward_count 208170  13.290%\n",
      "epoch-160 lr=['0.0039062'], tr/val_loss:  0.011523/  0.041827, val:  85.00%, val_best:  89.17%, tr:  99.49%, tr_best: 100.00%, epoch time: 55.54 seconds, 0.93 minutes\n",
      "layer   1  Sparsity: 91.0690%\n",
      "layer   2  Sparsity: 58.7875%\n",
      "layer   3  Sparsity: 86.3957%\n",
      "total_backward_count 1576190 real_backward_count 208739  13.243%\n",
      "epoch-161 lr=['0.0039062'], tr/val_loss:  0.011349/  0.038453, val:  87.92%, val_best:  89.17%, tr:  99.28%, tr_best: 100.00%, epoch time: 55.75 seconds, 0.93 minutes\n",
      "layer   1  Sparsity: 91.0934%\n",
      "layer   2  Sparsity: 58.8621%\n",
      "layer   3  Sparsity: 86.3484%\n",
      "total_backward_count 1585980 real_backward_count 209331  13.199%\n",
      "epoch-162 lr=['0.0039062'], tr/val_loss:  0.011301/  0.040143, val:  87.08%, val_best:  89.17%, tr:  99.69%, tr_best: 100.00%, epoch time: 54.77 seconds, 0.91 minutes\n",
      "layer   1  Sparsity: 91.0889%\n",
      "layer   2  Sparsity: 58.7506%\n",
      "layer   3  Sparsity: 86.4082%\n",
      "total_backward_count 1595770 real_backward_count 209905  13.154%\n",
      "epoch-163 lr=['0.0039062'], tr/val_loss:  0.011564/  0.040473, val:  87.92%, val_best:  89.17%, tr:  99.18%, tr_best: 100.00%, epoch time: 55.12 seconds, 0.92 minutes\n",
      "layer   1  Sparsity: 91.0830%\n",
      "layer   2  Sparsity: 58.7893%\n",
      "layer   3  Sparsity: 86.3472%\n",
      "total_backward_count 1605560 real_backward_count 210491  13.110%\n",
      "epoch-164 lr=['0.0039062'], tr/val_loss:  0.011577/  0.040710, val:  86.67%, val_best:  89.17%, tr:  99.39%, tr_best: 100.00%, epoch time: 54.85 seconds, 0.91 minutes\n",
      "layer   1  Sparsity: 91.1036%\n",
      "layer   2  Sparsity: 58.7224%\n",
      "layer   3  Sparsity: 86.4615%\n",
      "total_backward_count 1615350 real_backward_count 211064  13.066%\n",
      "epoch-165 lr=['0.0039062'], tr/val_loss:  0.011256/  0.040736, val:  84.58%, val_best:  89.17%, tr:  99.69%, tr_best: 100.00%, epoch time: 55.49 seconds, 0.92 minutes\n",
      "layer   1  Sparsity: 91.0482%\n",
      "layer   2  Sparsity: 58.6526%\n",
      "layer   3  Sparsity: 86.4954%\n",
      "total_backward_count 1625140 real_backward_count 211641  13.023%\n",
      "epoch-166 lr=['0.0039062'], tr/val_loss:  0.011189/  0.039893, val:  86.25%, val_best:  89.17%, tr:  99.28%, tr_best: 100.00%, epoch time: 55.23 seconds, 0.92 minutes\n",
      "layer   1  Sparsity: 91.1195%\n",
      "layer   2  Sparsity: 58.6434%\n",
      "layer   3  Sparsity: 86.5035%\n",
      "total_backward_count 1634930 real_backward_count 212201  12.979%\n",
      "epoch-167 lr=['0.0039062'], tr/val_loss:  0.011268/  0.039986, val:  88.33%, val_best:  89.17%, tr:  99.69%, tr_best: 100.00%, epoch time: 55.09 seconds, 0.92 minutes\n",
      "layer   1  Sparsity: 91.0640%\n",
      "layer   2  Sparsity: 58.5890%\n",
      "layer   3  Sparsity: 86.5822%\n",
      "total_backward_count 1644720 real_backward_count 212784  12.937%\n",
      "epoch-168 lr=['0.0039062'], tr/val_loss:  0.010699/  0.040536, val:  86.25%, val_best:  89.17%, tr:  99.49%, tr_best: 100.00%, epoch time: 55.08 seconds, 0.92 minutes\n",
      "layer   1  Sparsity: 91.1121%\n",
      "layer   2  Sparsity: 58.6211%\n",
      "layer   3  Sparsity: 86.5919%\n",
      "total_backward_count 1654510 real_backward_count 213308  12.893%\n",
      "epoch-169 lr=['0.0039062'], tr/val_loss:  0.011299/  0.038739, val:  87.08%, val_best:  89.17%, tr:  99.49%, tr_best: 100.00%, epoch time: 55.14 seconds, 0.92 minutes\n",
      "layer   1  Sparsity: 91.0972%\n",
      "layer   2  Sparsity: 58.5877%\n",
      "layer   3  Sparsity: 86.6085%\n",
      "total_backward_count 1664300 real_backward_count 213875  12.851%\n",
      "epoch-170 lr=['0.0039062'], tr/val_loss:  0.010973/  0.039901, val:  86.25%, val_best:  89.17%, tr:  99.80%, tr_best: 100.00%, epoch time: 55.19 seconds, 0.92 minutes\n",
      "layer   1  Sparsity: 91.0532%\n",
      "layer   2  Sparsity: 58.6066%\n",
      "layer   3  Sparsity: 86.6583%\n",
      "total_backward_count 1674090 real_backward_count 214407  12.807%\n",
      "epoch-171 lr=['0.0039062'], tr/val_loss:  0.010726/  0.039758, val:  87.92%, val_best:  89.17%, tr:  99.39%, tr_best: 100.00%, epoch time: 54.71 seconds, 0.91 minutes\n",
      "layer   1  Sparsity: 91.0751%\n",
      "layer   2  Sparsity: 58.6464%\n",
      "layer   3  Sparsity: 86.6837%\n",
      "total_backward_count 1683880 real_backward_count 214950  12.765%\n",
      "epoch-172 lr=['0.0039062'], tr/val_loss:  0.010120/  0.038904, val:  89.17%, val_best:  89.17%, tr:  99.49%, tr_best: 100.00%, epoch time: 54.99 seconds, 0.92 minutes\n",
      "layer   1  Sparsity: 91.0690%\n",
      "layer   2  Sparsity: 58.6021%\n",
      "layer   3  Sparsity: 86.7291%\n",
      "total_backward_count 1693670 real_backward_count 215430  12.720%\n",
      "epoch-173 lr=['0.0039062'], tr/val_loss:  0.010510/  0.039964, val:  84.58%, val_best:  89.17%, tr:  99.39%, tr_best: 100.00%, epoch time: 55.19 seconds, 0.92 minutes\n",
      "layer   1  Sparsity: 91.0234%\n",
      "layer   2  Sparsity: 58.6958%\n",
      "layer   3  Sparsity: 86.6934%\n",
      "total_backward_count 1703460 real_backward_count 215929  12.676%\n",
      "epoch-174 lr=['0.0039062'], tr/val_loss:  0.010630/  0.041956, val:  84.58%, val_best:  89.17%, tr:  99.69%, tr_best: 100.00%, epoch time: 54.96 seconds, 0.92 minutes\n",
      "layer   1  Sparsity: 91.0673%\n",
      "layer   2  Sparsity: 58.6171%\n",
      "layer   3  Sparsity: 86.7149%\n",
      "total_backward_count 1713250 real_backward_count 216447  12.634%\n",
      "epoch-175 lr=['0.0039062'], tr/val_loss:  0.010855/  0.040962, val:  87.50%, val_best:  89.17%, tr:  99.39%, tr_best: 100.00%, epoch time: 54.92 seconds, 0.92 minutes\n",
      "layer   1  Sparsity: 91.1157%\n",
      "layer   2  Sparsity: 58.6650%\n",
      "layer   3  Sparsity: 86.7664%\n",
      "total_backward_count 1723040 real_backward_count 216988  12.593%\n",
      "epoch-176 lr=['0.0039062'], tr/val_loss:  0.010767/  0.038059, val:  89.17%, val_best:  89.17%, tr:  99.69%, tr_best: 100.00%, epoch time: 54.84 seconds, 0.91 minutes\n",
      "layer   1  Sparsity: 91.0990%\n",
      "layer   2  Sparsity: 58.5765%\n",
      "layer   3  Sparsity: 86.7861%\n",
      "total_backward_count 1732830 real_backward_count 217531  12.554%\n",
      "epoch-177 lr=['0.0039062'], tr/val_loss:  0.010458/  0.039080, val:  85.83%, val_best:  89.17%, tr:  99.39%, tr_best: 100.00%, epoch time: 55.44 seconds, 0.92 minutes\n",
      "layer   1  Sparsity: 91.0698%\n",
      "layer   2  Sparsity: 58.5813%\n",
      "layer   3  Sparsity: 86.7647%\n",
      "total_backward_count 1742620 real_backward_count 218041  12.512%\n",
      "epoch-178 lr=['0.0039062'], tr/val_loss:  0.010431/  0.039625, val:  86.25%, val_best:  89.17%, tr:  99.59%, tr_best: 100.00%, epoch time: 54.80 seconds, 0.91 minutes\n",
      "layer   1  Sparsity: 91.0607%\n",
      "layer   2  Sparsity: 58.5524%\n",
      "layer   3  Sparsity: 86.8214%\n",
      "total_backward_count 1752410 real_backward_count 218547  12.471%\n",
      "epoch-179 lr=['0.0039062'], tr/val_loss:  0.010705/  0.038860, val:  87.50%, val_best:  89.17%, tr:  99.59%, tr_best: 100.00%, epoch time: 55.44 seconds, 0.92 minutes\n",
      "layer   1  Sparsity: 91.0575%\n",
      "layer   2  Sparsity: 58.5414%\n",
      "layer   3  Sparsity: 86.8817%\n",
      "total_backward_count 1762200 real_backward_count 219091  12.433%\n",
      "epoch-180 lr=['0.0039062'], tr/val_loss:  0.010771/  0.040295, val:  88.33%, val_best:  89.17%, tr:  99.49%, tr_best: 100.00%, epoch time: 55.20 seconds, 0.92 minutes\n",
      "layer   1  Sparsity: 91.0824%\n",
      "layer   2  Sparsity: 58.5874%\n",
      "layer   3  Sparsity: 86.8853%\n",
      "total_backward_count 1771990 real_backward_count 219617  12.394%\n",
      "epoch-181 lr=['0.0039062'], tr/val_loss:  0.010364/  0.039986, val:  87.08%, val_best:  89.17%, tr:  99.28%, tr_best: 100.00%, epoch time: 55.14 seconds, 0.92 minutes\n",
      "layer   1  Sparsity: 91.0670%\n",
      "layer   2  Sparsity: 58.5660%\n",
      "layer   3  Sparsity: 86.9404%\n",
      "total_backward_count 1781780 real_backward_count 220150  12.356%\n",
      "epoch-182 lr=['0.0039062'], tr/val_loss:  0.010103/  0.039422, val:  86.25%, val_best:  89.17%, tr:  99.59%, tr_best: 100.00%, epoch time: 55.62 seconds, 0.93 minutes\n",
      "layer   1  Sparsity: 91.0528%\n",
      "layer   2  Sparsity: 58.5725%\n",
      "layer   3  Sparsity: 86.9073%\n",
      "total_backward_count 1791570 real_backward_count 220656  12.316%\n",
      "epoch-183 lr=['0.0039062'], tr/val_loss:  0.010251/  0.038402, val:  89.58%, val_best:  89.58%, tr:  99.49%, tr_best: 100.00%, epoch time: 55.49 seconds, 0.92 minutes\n",
      "layer   1  Sparsity: 91.1302%\n",
      "layer   2  Sparsity: 58.5053%\n",
      "layer   3  Sparsity: 86.9272%\n",
      "total_backward_count 1801360 real_backward_count 221126  12.276%\n",
      "epoch-184 lr=['0.0039062'], tr/val_loss:  0.010088/  0.039681, val:  87.50%, val_best:  89.58%, tr:  99.69%, tr_best: 100.00%, epoch time: 55.08 seconds, 0.92 minutes\n",
      "layer   1  Sparsity: 91.0690%\n",
      "layer   2  Sparsity: 58.5322%\n",
      "layer   3  Sparsity: 86.9392%\n",
      "total_backward_count 1811150 real_backward_count 221619  12.236%\n",
      "epoch-185 lr=['0.0039062'], tr/val_loss:  0.010337/  0.039816, val:  87.92%, val_best:  89.58%, tr:  99.49%, tr_best: 100.00%, epoch time: 55.37 seconds, 0.92 minutes\n",
      "layer   1  Sparsity: 91.0621%\n",
      "layer   2  Sparsity: 58.5734%\n",
      "layer   3  Sparsity: 86.9646%\n",
      "total_backward_count 1820940 real_backward_count 222131  12.199%\n",
      "epoch-186 lr=['0.0039062'], tr/val_loss:  0.009538/  0.039668, val:  87.08%, val_best:  89.58%, tr:  99.59%, tr_best: 100.00%, epoch time: 55.59 seconds, 0.93 minutes\n",
      "layer   1  Sparsity: 91.0937%\n",
      "layer   2  Sparsity: 58.6037%\n",
      "layer   3  Sparsity: 86.9459%\n",
      "total_backward_count 1830730 real_backward_count 222607  12.159%\n",
      "epoch-187 lr=['0.0039062'], tr/val_loss:  0.010042/  0.039362, val:  87.50%, val_best:  89.58%, tr:  99.59%, tr_best: 100.00%, epoch time: 54.96 seconds, 0.92 minutes\n",
      "layer   1  Sparsity: 91.0533%\n",
      "layer   2  Sparsity: 58.5731%\n",
      "layer   3  Sparsity: 86.9350%\n",
      "total_backward_count 1840520 real_backward_count 223096  12.121%\n",
      "epoch-188 lr=['0.0039062'], tr/val_loss:  0.010313/  0.038822, val:  87.92%, val_best:  89.58%, tr:  99.59%, tr_best: 100.00%, epoch time: 54.98 seconds, 0.92 minutes\n",
      "layer   1  Sparsity: 91.0522%\n",
      "layer   2  Sparsity: 58.6522%\n",
      "layer   3  Sparsity: 86.9987%\n",
      "total_backward_count 1850310 real_backward_count 223595  12.084%\n",
      "epoch-189 lr=['0.0039062'], tr/val_loss:  0.009642/  0.041041, val:  84.58%, val_best:  89.58%, tr:  99.59%, tr_best: 100.00%, epoch time: 55.41 seconds, 0.92 minutes\n",
      "layer   1  Sparsity: 91.0899%\n",
      "layer   2  Sparsity: 58.6727%\n",
      "layer   3  Sparsity: 86.9083%\n",
      "total_backward_count 1860100 real_backward_count 224043  12.045%\n",
      "epoch-190 lr=['0.0039062'], tr/val_loss:  0.009690/  0.040397, val:  86.67%, val_best:  89.58%, tr:  99.49%, tr_best: 100.00%, epoch time: 55.06 seconds, 0.92 minutes\n",
      "layer   1  Sparsity: 91.0987%\n",
      "layer   2  Sparsity: 58.5324%\n",
      "layer   3  Sparsity: 87.0318%\n",
      "total_backward_count 1869890 real_backward_count 224515  12.007%\n",
      "epoch-191 lr=['0.0039062'], tr/val_loss:  0.009755/  0.040175, val:  87.08%, val_best:  89.58%, tr:  99.49%, tr_best: 100.00%, epoch time: 54.77 seconds, 0.91 minutes\n",
      "layer   1  Sparsity: 91.0803%\n",
      "layer   2  Sparsity: 58.6461%\n",
      "layer   3  Sparsity: 87.0194%\n",
      "total_backward_count 1879680 real_backward_count 224963  11.968%\n",
      "epoch-192 lr=['0.0039062'], tr/val_loss:  0.009968/  0.039773, val:  87.08%, val_best:  89.58%, tr:  99.59%, tr_best: 100.00%, epoch time: 55.63 seconds, 0.93 minutes\n",
      "layer   1  Sparsity: 91.0749%\n",
      "layer   2  Sparsity: 58.5812%\n",
      "layer   3  Sparsity: 87.0769%\n",
      "total_backward_count 1889470 real_backward_count 225435  11.931%\n",
      "epoch-193 lr=['0.0039062'], tr/val_loss:  0.010163/  0.042740, val:  86.67%, val_best:  89.58%, tr:  99.59%, tr_best: 100.00%, epoch time: 55.11 seconds, 0.92 minutes\n",
      "layer   1  Sparsity: 91.0569%\n",
      "layer   2  Sparsity: 58.5735%\n",
      "layer   3  Sparsity: 87.0819%\n",
      "total_backward_count 1899260 real_backward_count 225947  11.897%\n",
      "epoch-194 lr=['0.0039062'], tr/val_loss:  0.009385/  0.039725, val:  87.92%, val_best:  89.58%, tr:  99.90%, tr_best: 100.00%, epoch time: 54.99 seconds, 0.92 minutes\n",
      "layer   1  Sparsity: 91.0709%\n",
      "layer   2  Sparsity: 58.5779%\n",
      "layer   3  Sparsity: 87.0600%\n",
      "total_backward_count 1909050 real_backward_count 226377  11.858%\n",
      "epoch-195 lr=['0.0039062'], tr/val_loss:  0.009816/  0.039786, val:  89.17%, val_best:  89.58%, tr:  99.28%, tr_best: 100.00%, epoch time: 54.93 seconds, 0.92 minutes\n",
      "layer   1  Sparsity: 91.1053%\n",
      "layer   2  Sparsity: 58.5664%\n",
      "layer   3  Sparsity: 87.1302%\n",
      "total_backward_count 1918840 real_backward_count 226854  11.822%\n",
      "epoch-196 lr=['0.0039062'], tr/val_loss:  0.009771/  0.040452, val:  86.25%, val_best:  89.58%, tr:  99.49%, tr_best: 100.00%, epoch time: 54.53 seconds, 0.91 minutes\n",
      "layer   1  Sparsity: 91.0847%\n",
      "layer   2  Sparsity: 58.5418%\n",
      "layer   3  Sparsity: 87.1630%\n",
      "total_backward_count 1928630 real_backward_count 227331  11.787%\n",
      "epoch-197 lr=['0.0039062'], tr/val_loss:  0.009715/  0.040955, val:  85.42%, val_best:  89.58%, tr:  99.69%, tr_best: 100.00%, epoch time: 55.41 seconds, 0.92 minutes\n",
      "layer   1  Sparsity: 91.0754%\n",
      "layer   2  Sparsity: 58.4439%\n",
      "layer   3  Sparsity: 87.2348%\n",
      "total_backward_count 1938420 real_backward_count 227799  11.752%\n",
      "epoch-198 lr=['0.0039062'], tr/val_loss:  0.009503/  0.041053, val:  85.42%, val_best:  89.58%, tr:  99.69%, tr_best: 100.00%, epoch time: 55.64 seconds, 0.93 minutes\n",
      "layer   1  Sparsity: 91.0719%\n",
      "layer   2  Sparsity: 58.4413%\n",
      "layer   3  Sparsity: 87.1865%\n",
      "total_backward_count 1948210 real_backward_count 228225  11.715%\n",
      "epoch-199 lr=['0.0039062'], tr/val_loss:  0.009415/  0.039961, val:  87.92%, val_best:  89.58%, tr:  99.59%, tr_best: 100.00%, epoch time: 54.71 seconds, 0.91 minutes\n",
      "layer   1  Sparsity: 91.0889%\n",
      "layer   2  Sparsity: 58.4518%\n",
      "layer   3  Sparsity: 87.2196%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "21ebe53e433543ffb3639c479b04b8ec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.006 MB of 0.006 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà</td></tr><tr><td>iter_acc</td><td>‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñÅ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà</td></tr><tr><td>summary_val_acc</td><td>‚ñÅ‚ñÉ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÖ‚ñÖ‚ñÜ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà</td></tr><tr><td>tr_acc</td><td>‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà</td></tr><tr><td>tr_epoch_loss</td><td>‚ñà‚ñá‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ</td></tr><tr><td>val_acc_best</td><td>‚ñÅ‚ñÇ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà</td></tr><tr><td>val_acc_now</td><td>‚ñÅ‚ñÉ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÖ‚ñÖ‚ñÜ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà</td></tr><tr><td>val_loss</td><td>‚ñà‚ñá‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÑ‚ñÉ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÇ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÇ‚ñÇ‚ñÅ‚ñÇ‚ñÅ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÅ</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>199</td></tr><tr><td>iter_acc</td><td>1.0</td></tr><tr><td>tr_acc</td><td>0.99591</td></tr><tr><td>tr_epoch_loss</td><td>0.00941</td></tr><tr><td>val_acc_best</td><td>0.89583</td></tr><tr><td>val_acc_now</td><td>0.87917</td></tr><tr><td>val_loss</td><td>0.03996</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">pious-sweep-1</strong> at: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/slqhq9z9' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/slqhq9z9</a><br/> View project at: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>/data2/bh_wandb/wandb/run-20251119_185311-slqhq9z9/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require(\"core\")`! See https://wandb.me/wandb-core for more information."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: xzlunj1t with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBATCH: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBN_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBPTT_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tDFA_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tIMAGE_SIZE: 14\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tOTTT_input_trace_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tTIME: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tUDA_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \talpha_uda: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbias: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcfg: [200, 200]\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tchaching_on: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tconvTrue_fcFalse: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdata_path: /data2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tddp_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdenoise_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdvs_clipping: 14\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdvs_duration: 25000\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepoch_num: 200\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \texclude_class: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \textra_train_dataset: -1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tinitial_pooling: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlast_lif: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.00390625\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_sg_width: 4\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_decay: 0.5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_init: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_reset: 10000\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_threshold: 0.015625\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmerge_polarities: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmy_seed: 12902\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnet_print: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_workers: 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer_what: SGD\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tpin_memory: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tpre_trained: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tpre_trained_path: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \trate_coding: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tscheduler_name: no\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsingle_step: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsurrogate: hard_sigmoid\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_conv_kernel_size: 3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_conv_padding: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_conv_stride: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_trace_const1: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_trace_const2: 0.5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \ttdBN_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \ttemporal_filter: 5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \ttemporal_filter_accumulation: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \ttrace_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \twhich_data: DVS_GESTURE_TONIC\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.23.0 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.17.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/data2/bh_wandb/wandb/run-20251119_215846-xzlunj1t</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/xzlunj1t' target=\"_blank\">worthy-sweep-2</a></strong> to <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/m41wfhay' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/m41wfhay</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/m41wfhay' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/m41wfhay</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/xzlunj1t' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/xzlunj1t</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'single_step' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'my_seed' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'TIME' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BATCH' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'IMAGE_SIZE' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'which_data' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'data_path' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'rate_coding' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_init' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_decay' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_threshold' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_reset' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_sg_width' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_conv_kernel_size' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_conv_stride' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_conv_padding' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_trace_const1' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_trace_const2' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'pre_trained' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'convTrue_fcFalse' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'cfg' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'net_print' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'pre_trained_path' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'learning_rate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'epoch_num' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'tdBN_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BN_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'surrogate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BPTT_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'optimizer_what' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'scheduler_name' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'ddp_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'dvs_clipping' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'dvs_duration' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'DFA_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'trace_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'OTTT_input_trace_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'exclude_class' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'merge_polarities' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'denoise_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'extra_train_dataset' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'num_workers' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'chaching_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'pin_memory' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'UDA_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'alpha_uda' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'bias' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'last_lif' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'temporal_filter' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'initial_pooling' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'temporal_filter_accumulation' was locked by 'sweep' (ignored update).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "param {'devices': '3', 'single_step': True, 'unique_name': '20251119_215856_149', 'my_seed': 12902, 'TIME': 10, 'BATCH': 1, 'IMAGE_SIZE': 14, 'which_data': 'DVS_GESTURE_TONIC', 'data_path': '/data2', 'rate_coding': False, 'lif_layer_v_init': 0, 'lif_layer_v_decay': 0.5, 'lif_layer_v_threshold': 0.015625, 'lif_layer_v_reset': 10000, 'lif_layer_sg_width': 4, 'synapse_conv_kernel_size': 3, 'synapse_conv_stride': 1, 'synapse_conv_padding': 1, 'synapse_trace_const1': 1, 'synapse_trace_const2': 0.5, 'pre_trained': False, 'convTrue_fcFalse': False, 'cfg': [200, 200], 'net_print': True, 'pre_trained_path': '', 'learning_rate': 0.00390625, 'epoch_num': 200, 'tdBN_on': False, 'BN_on': False, 'surrogate': 'hard_sigmoid', 'BPTT_on': False, 'optimizer_what': 'SGD', 'scheduler_name': 'no', 'ddp_on': False, 'dvs_clipping': 14, 'dvs_duration': 25000, 'DFA_on': False, 'trace_on': False, 'OTTT_input_trace_on': False, 'exclude_class': True, 'merge_polarities': True, 'denoise_on': False, 'extra_train_dataset': -1, 'num_workers': 2, 'chaching_on': True, 'pin_memory': True, 'UDA_on': False, 'alpha_uda': 1, 'bias': False, 'last_lif': False, 'temporal_filter': 5, 'initial_pooling': 1, 'temporal_filter_accumulation': False, 'quantize_bit_list': [], 'scale_exp': [[999, 998], [999, 999], [999, 999]]} \n",
      "\n",
      "Ïù¥ Îç∞Ïù¥ÌÑ∞ÏÖãÏùò Îç∞Ïù¥ÌÑ∞ Í∞úÏàòÎäî 979 ÏûÖÎãàÎã§. (test setÏùÄ ÏïàÎ∞îÎÄåÍ≤å Ìï¥ÎÜ®Îã§ ÏïåÏ†ú)\n",
      "Ïù¥ Îç∞Ïù¥ÌÑ∞ÏÖãÏùò Îç∞Ïù¥ÌÑ∞ Í∞úÏàòÎäî 240 ÏûÖÎãàÎã§. (test setÏùÄ ÏïàÎ∞îÎÄåÍ≤å Ìï¥ÎÜ®Îã§ ÏïåÏ†ú)\n",
      "dataset_hash = 0e8a8f2d81b4fe037308b5d792c4a037\n",
      "cache path exists\n",
      "\n",
      "len(train_loader): 979 BATCH: 1 train_data_count: 979\n",
      "len(test_loader): 240 BATCH: 1\n",
      "\n",
      "device ==> cuda\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " layer_count 1\n",
      "weight bias bit 0\n",
      "weight exp, bias exp None None\n",
      "bit_for_output 0 exp_for_output None \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "LIF 1 sg_bit 0\n",
      "\n",
      "\n",
      "++++++++++++++++++++++++\n",
      "\n",
      " lif layer 1 v_bit: 0, v_exp: None\n",
      "\n",
      "++++++++++++++++++++++++++++++++++++++++++++++\n",
      "\n",
      "\n",
      "\n",
      " layer_count 2\n",
      "weight bias bit 0\n",
      "weight exp, bias exp None None\n",
      "bit_for_output 0 exp_for_output None \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "LIF 2 sg_bit 0\n",
      "\n",
      "\n",
      "++++++++++++++++++++++++\n",
      "\n",
      " lif layer 2 v_bit: 0, v_exp: None\n",
      "\n",
      "++++++++++++++++++++++++++++++++++++++++++++++\n",
      "\n",
      "\n",
      "\n",
      " layer_count 3\n",
      "weight bias bit 0\n",
      "weight exp, bias exp None None\n",
      "bit_for_output 0 exp_for_output None \n",
      "\n",
      "\n",
      "\n",
      "DataParallel(\n",
      "  (module): REBORN_MY_SNN_FC(\n",
      "    (layers): REBORN_MY_Sequential(\n",
      "      (0): DimChanger_for_FC()\n",
      "      (1): SYNAPSE_FC(in_features=980, out_features=200, TIME=10, bias=False, sstep=True, time_different_weight=False, layer_count=1, quantize_bit_list=[], scale_exp=[[999, 998], [999, 999], [999, 999]], ANPI_MODE=False)\n",
      "      (2): LIF_layer(v_init=0, v_decay=0.5, v_threshold=0.015625, v_reset=10000, sg_width=4, surrogate=hard_sigmoid, BPTT_on=False, trace_const1=1, trace_const2=0.5, TIME=10, sstep=True, trace_on=False, layer_count=1, scale_exp=[[999, 998], [999, 999], [999, 999]], ANPI_MODE=False)\n",
      "      (3): SYNAPSE_FC(in_features=200, out_features=200, TIME=10, bias=False, sstep=True, time_different_weight=False, layer_count=2, quantize_bit_list=[], scale_exp=[[999, 998], [999, 999], [999, 999]], ANPI_MODE=False)\n",
      "      (4): LIF_layer(v_init=0, v_decay=0.5, v_threshold=0.015625, v_reset=10000, sg_width=4, surrogate=hard_sigmoid, BPTT_on=False, trace_const1=1, trace_const2=0.5, TIME=10, sstep=True, trace_on=False, layer_count=2, scale_exp=[[999, 998], [999, 999], [999, 999]], ANPI_MODE=False)\n",
      "      (5): SYNAPSE_FC(in_features=200, out_features=10, TIME=10, bias=False, sstep=True, time_different_weight=False, layer_count=3, quantize_bit_list=[], scale_exp=[[999, 998], [999, 999], [999, 999]], ANPI_MODE=False)\n",
      "    )\n",
      "  )\n",
      ")\n",
      "\n",
      "========================================================\n",
      "Trainable parameters: 238,000\n",
      "========================================================\n",
      "\n",
      "MySGD (\n",
      "Parameter Group 0\n",
      "    lr: 0.00390625\n",
      "    momentum: 0.0\n",
      ")\n",
      "total_backward_count 0 real_backward_count 0   0.000%\n",
      "epoch-0   lr=['0.0039062'], tr/val_loss:  0.065766/  0.089182, val:  39.58%, val_best:  39.58%, tr:  80.39%, tr_best:  80.39%, epoch time: 54.75 seconds, 0.91 minutes\n",
      "layer   1  Sparsity: 91.0681%\n",
      "layer   2  Sparsity: 59.9914%\n",
      "layer   3  Sparsity: 53.7175%\n",
      "total_backward_count 9790 real_backward_count 3208  32.768%\n",
      "epoch-1   lr=['0.0039062'], tr/val_loss:  0.051154/  0.079831, val:  47.08%, val_best:  47.08%, tr:  85.39%, tr_best:  85.39%, epoch time: 55.65 seconds, 0.93 minutes\n",
      "layer   1  Sparsity: 91.0807%\n",
      "layer   2  Sparsity: 59.9373%\n",
      "layer   3  Sparsity: 54.9676%\n",
      "total_backward_count 19580 real_backward_count 5663  28.922%\n",
      "epoch-2   lr=['0.0039062'], tr/val_loss:  0.047710/  0.074321, val:  50.83%, val_best:  50.83%, tr:  86.11%, tr_best:  86.11%, epoch time: 56.25 seconds, 0.94 minutes\n",
      "layer   1  Sparsity: 91.0864%\n",
      "layer   2  Sparsity: 59.7928%\n",
      "layer   3  Sparsity: 56.0141%\n",
      "total_backward_count 29370 real_backward_count 7944  27.048%\n",
      "epoch-3   lr=['0.0039062'], tr/val_loss:  0.045986/  0.074211, val:  46.67%, val_best:  50.83%, tr:  86.21%, tr_best:  86.21%, epoch time: 56.32 seconds, 0.94 minutes\n",
      "layer   1  Sparsity: 91.0764%\n",
      "layer   2  Sparsity: 59.6744%\n",
      "layer   3  Sparsity: 56.8425%\n",
      "total_backward_count 39160 real_backward_count 10120  25.843%\n",
      "epoch-4   lr=['0.0039062'], tr/val_loss:  0.045033/  0.066767, val:  62.08%, val_best:  62.08%, tr:  86.31%, tr_best:  86.31%, epoch time: 55.44 seconds, 0.92 minutes\n",
      "layer   1  Sparsity: 91.0901%\n",
      "layer   2  Sparsity: 59.4549%\n",
      "layer   3  Sparsity: 57.7073%\n",
      "total_backward_count 48950 real_backward_count 12292  25.111%\n",
      "epoch-5   lr=['0.0039062'], tr/val_loss:  0.043952/  0.073306, val:  56.67%, val_best:  62.08%, tr:  87.13%, tr_best:  87.13%, epoch time: 55.95 seconds, 0.93 minutes\n",
      "layer   1  Sparsity: 91.0716%\n",
      "layer   2  Sparsity: 59.2279%\n",
      "layer   3  Sparsity: 58.4820%\n",
      "total_backward_count 58740 real_backward_count 14430  24.566%\n",
      "epoch-6   lr=['0.0039062'], tr/val_loss:  0.041682/  0.067814, val:  60.83%, val_best:  62.08%, tr:  86.72%, tr_best:  87.13%, epoch time: 56.47 seconds, 0.94 minutes\n",
      "layer   1  Sparsity: 91.0617%\n",
      "layer   2  Sparsity: 59.0496%\n",
      "layer   3  Sparsity: 59.1544%\n",
      "total_backward_count 68530 real_backward_count 16428  23.972%\n",
      "epoch-7   lr=['0.0039062'], tr/val_loss:  0.041765/  0.064572, val:  61.25%, val_best:  62.08%, tr:  86.93%, tr_best:  87.13%, epoch time: 56.04 seconds, 0.93 minutes\n",
      "layer   1  Sparsity: 91.0851%\n",
      "layer   2  Sparsity: 59.0016%\n",
      "layer   3  Sparsity: 60.0233%\n",
      "total_backward_count 78320 real_backward_count 18526  23.654%\n",
      "epoch-8   lr=['0.0039062'], tr/val_loss:  0.041742/  0.065187, val:  60.42%, val_best:  62.08%, tr:  87.13%, tr_best:  87.13%, epoch time: 55.38 seconds, 0.92 minutes\n",
      "layer   1  Sparsity: 91.0831%\n",
      "layer   2  Sparsity: 58.9042%\n",
      "layer   3  Sparsity: 60.8568%\n",
      "total_backward_count 88110 real_backward_count 20634  23.418%\n",
      "epoch-9   lr=['0.0039062'], tr/val_loss:  0.040837/  0.066799, val:  59.58%, val_best:  62.08%, tr:  86.62%, tr_best:  87.13%, epoch time: 55.69 seconds, 0.93 minutes\n",
      "layer   1  Sparsity: 91.0833%\n",
      "layer   2  Sparsity: 58.7851%\n",
      "layer   3  Sparsity: 61.6247%\n",
      "total_backward_count 97900 real_backward_count 22711  23.198%\n",
      "epoch-10  lr=['0.0039062'], tr/val_loss:  0.040235/  0.072723, val:  52.92%, val_best:  62.08%, tr:  85.60%, tr_best:  87.13%, epoch time: 55.70 seconds, 0.93 minutes\n",
      "layer   1  Sparsity: 91.0603%\n",
      "layer   2  Sparsity: 58.7061%\n",
      "layer   3  Sparsity: 62.4412%\n",
      "total_backward_count 107690 real_backward_count 24737  22.971%\n",
      "epoch-11  lr=['0.0039062'], tr/val_loss:  0.039839/  0.061445, val:  64.17%, val_best:  64.17%, tr:  85.60%, tr_best:  87.13%, epoch time: 55.41 seconds, 0.92 minutes\n",
      "layer   1  Sparsity: 91.0486%\n",
      "layer   2  Sparsity: 58.6333%\n",
      "layer   3  Sparsity: 63.2922%\n",
      "total_backward_count 117480 real_backward_count 26836  22.843%\n",
      "epoch-12  lr=['0.0039062'], tr/val_loss:  0.039043/  0.061479, val:  68.75%, val_best:  68.75%, tr:  86.72%, tr_best:  87.13%, epoch time: 56.38 seconds, 0.94 minutes\n",
      "layer   1  Sparsity: 91.0711%\n",
      "layer   2  Sparsity: 58.5888%\n",
      "layer   3  Sparsity: 63.9593%\n",
      "total_backward_count 127270 real_backward_count 28874  22.687%\n",
      "epoch-13  lr=['0.0039062'], tr/val_loss:  0.039117/  0.066965, val:  59.58%, val_best:  68.75%, tr:  86.62%, tr_best:  87.13%, epoch time: 56.42 seconds, 0.94 minutes\n",
      "layer   1  Sparsity: 91.0237%\n",
      "layer   2  Sparsity: 58.5431%\n",
      "layer   3  Sparsity: 64.7028%\n",
      "total_backward_count 137060 real_backward_count 30906  22.549%\n",
      "epoch-14  lr=['0.0039062'], tr/val_loss:  0.039196/  0.060761, val:  60.83%, val_best:  68.75%, tr:  86.93%, tr_best:  87.13%, epoch time: 55.56 seconds, 0.93 minutes\n",
      "layer   1  Sparsity: 91.0802%\n",
      "layer   2  Sparsity: 58.4674%\n",
      "layer   3  Sparsity: 65.3995%\n",
      "total_backward_count 146850 real_backward_count 32994  22.468%\n",
      "epoch-15  lr=['0.0039062'], tr/val_loss:  0.038883/  0.059538, val:  67.50%, val_best:  68.75%, tr:  86.11%, tr_best:  87.13%, epoch time: 55.36 seconds, 0.92 minutes\n",
      "layer   1  Sparsity: 91.0988%\n",
      "layer   2  Sparsity: 58.4237%\n",
      "layer   3  Sparsity: 66.1843%\n",
      "total_backward_count 156640 real_backward_count 35098  22.407%\n",
      "epoch-16  lr=['0.0039062'], tr/val_loss:  0.038251/  0.061227, val:  62.50%, val_best:  68.75%, tr:  86.41%, tr_best:  87.13%, epoch time: 56.14 seconds, 0.94 minutes\n",
      "layer   1  Sparsity: 91.0765%\n",
      "layer   2  Sparsity: 58.3514%\n",
      "layer   3  Sparsity: 66.9081%\n",
      "total_backward_count 166430 real_backward_count 37201  22.352%\n",
      "epoch-17  lr=['0.0039062'], tr/val_loss:  0.037654/  0.066196, val:  61.67%, val_best:  68.75%, tr:  86.52%, tr_best:  87.13%, epoch time: 55.96 seconds, 0.93 minutes\n",
      "layer   1  Sparsity: 91.1158%\n",
      "layer   2  Sparsity: 58.2260%\n",
      "layer   3  Sparsity: 67.5155%\n",
      "total_backward_count 176220 real_backward_count 39270  22.285%\n",
      "epoch-18  lr=['0.0039062'], tr/val_loss:  0.037420/  0.057993, val:  67.92%, val_best:  68.75%, tr:  85.70%, tr_best:  87.13%, epoch time: 56.10 seconds, 0.93 minutes\n",
      "layer   1  Sparsity: 91.0758%\n",
      "layer   2  Sparsity: 58.1371%\n",
      "layer   3  Sparsity: 67.9573%\n",
      "total_backward_count 186010 real_backward_count 41345  22.227%\n",
      "epoch-19  lr=['0.0039062'], tr/val_loss:  0.037124/  0.059998, val:  65.42%, val_best:  68.75%, tr:  87.03%, tr_best:  87.13%, epoch time: 56.11 seconds, 0.94 minutes\n",
      "layer   1  Sparsity: 91.0500%\n",
      "layer   2  Sparsity: 58.0927%\n",
      "layer   3  Sparsity: 68.4590%\n",
      "total_backward_count 195800 real_backward_count 43408  22.170%\n",
      "epoch-20  lr=['0.0039062'], tr/val_loss:  0.036988/  0.057878, val:  64.17%, val_best:  68.75%, tr:  86.31%, tr_best:  87.13%, epoch time: 55.83 seconds, 0.93 minutes\n",
      "layer   1  Sparsity: 91.0738%\n",
      "layer   2  Sparsity: 58.0509%\n",
      "layer   3  Sparsity: 69.0016%\n",
      "total_backward_count 205590 real_backward_count 45441  22.103%\n",
      "epoch-21  lr=['0.0039062'], tr/val_loss:  0.036976/  0.053857, val:  71.25%, val_best:  71.25%, tr:  87.03%, tr_best:  87.13%, epoch time: 56.14 seconds, 0.94 minutes\n",
      "layer   1  Sparsity: 91.0494%\n",
      "layer   2  Sparsity: 58.0504%\n",
      "layer   3  Sparsity: 69.6290%\n",
      "total_backward_count 215380 real_backward_count 47537  22.071%\n",
      "epoch-22  lr=['0.0039062'], tr/val_loss:  0.036185/  0.053964, val:  70.42%, val_best:  71.25%, tr:  86.31%, tr_best:  87.13%, epoch time: 56.27 seconds, 0.94 minutes\n",
      "layer   1  Sparsity: 91.0919%\n",
      "layer   2  Sparsity: 58.0679%\n",
      "layer   3  Sparsity: 70.0204%\n",
      "total_backward_count 225170 real_backward_count 49543  22.002%\n",
      "epoch-23  lr=['0.0039062'], tr/val_loss:  0.036365/  0.060355, val:  65.83%, val_best:  71.25%, tr:  86.41%, tr_best:  87.13%, epoch time: 56.03 seconds, 0.93 minutes\n",
      "layer   1  Sparsity: 91.0700%\n",
      "layer   2  Sparsity: 58.0476%\n",
      "layer   3  Sparsity: 70.4738%\n",
      "total_backward_count 234960 real_backward_count 51600  21.961%\n",
      "epoch-24  lr=['0.0039062'], tr/val_loss:  0.035579/  0.053181, val:  76.25%, val_best:  76.25%, tr:  87.33%, tr_best:  87.33%, epoch time: 55.40 seconds, 0.92 minutes\n",
      "layer   1  Sparsity: 91.0864%\n",
      "layer   2  Sparsity: 57.9946%\n",
      "layer   3  Sparsity: 70.8702%\n",
      "total_backward_count 244750 real_backward_count 53590  21.896%\n",
      "epoch-25  lr=['0.0039062'], tr/val_loss:  0.035156/  0.055755, val:  68.33%, val_best:  76.25%, tr:  87.54%, tr_best:  87.54%, epoch time: 55.88 seconds, 0.93 minutes\n",
      "layer   1  Sparsity: 91.0603%\n",
      "layer   2  Sparsity: 58.0573%\n",
      "layer   3  Sparsity: 71.3611%\n",
      "total_backward_count 254540 real_backward_count 55528  21.815%\n",
      "epoch-26  lr=['0.0039062'], tr/val_loss:  0.035187/  0.056741, val:  67.50%, val_best:  76.25%, tr:  88.05%, tr_best:  88.05%, epoch time: 56.21 seconds, 0.94 minutes\n",
      "layer   1  Sparsity: 91.0574%\n",
      "layer   2  Sparsity: 57.9100%\n",
      "layer   3  Sparsity: 71.5928%\n",
      "total_backward_count 264330 real_backward_count 57492  21.750%\n",
      "epoch-27  lr=['0.0039062'], tr/val_loss:  0.034912/  0.054642, val:  69.17%, val_best:  76.25%, tr:  87.95%, tr_best:  88.05%, epoch time: 56.64 seconds, 0.94 minutes\n",
      "layer   1  Sparsity: 91.1004%\n",
      "layer   2  Sparsity: 57.9097%\n",
      "layer   3  Sparsity: 71.9904%\n",
      "total_backward_count 274120 real_backward_count 59469  21.695%\n",
      "epoch-28  lr=['0.0039062'], tr/val_loss:  0.034767/  0.053836, val:  73.33%, val_best:  76.25%, tr:  88.46%, tr_best:  88.46%, epoch time: 55.36 seconds, 0.92 minutes\n",
      "layer   1  Sparsity: 91.0873%\n",
      "layer   2  Sparsity: 57.8389%\n",
      "layer   3  Sparsity: 72.2797%\n",
      "total_backward_count 283910 real_backward_count 61412  21.631%\n",
      "epoch-29  lr=['0.0039062'], tr/val_loss:  0.034783/  0.056462, val:  71.67%, val_best:  76.25%, tr:  87.33%, tr_best:  88.46%, epoch time: 55.53 seconds, 0.93 minutes\n",
      "layer   1  Sparsity: 91.0815%\n",
      "layer   2  Sparsity: 57.8578%\n",
      "layer   3  Sparsity: 72.6258%\n",
      "total_backward_count 293700 real_backward_count 63384  21.581%\n",
      "epoch-30  lr=['0.0039062'], tr/val_loss:  0.033908/  0.055432, val:  67.50%, val_best:  76.25%, tr:  89.79%, tr_best:  89.79%, epoch time: 55.86 seconds, 0.93 minutes\n",
      "layer   1  Sparsity: 91.0847%\n",
      "layer   2  Sparsity: 57.8154%\n",
      "layer   3  Sparsity: 72.9953%\n",
      "total_backward_count 303490 real_backward_count 65303  21.517%\n",
      "epoch-31  lr=['0.0039062'], tr/val_loss:  0.033496/  0.058150, val:  67.92%, val_best:  76.25%, tr:  88.46%, tr_best:  89.79%, epoch time: 55.85 seconds, 0.93 minutes\n",
      "layer   1  Sparsity: 91.0292%\n",
      "layer   2  Sparsity: 57.8014%\n",
      "layer   3  Sparsity: 73.1252%\n",
      "total_backward_count 313280 real_backward_count 67181  21.444%\n",
      "epoch-32  lr=['0.0039062'], tr/val_loss:  0.034480/  0.055374, val:  66.25%, val_best:  76.25%, tr:  87.84%, tr_best:  89.79%, epoch time: 55.59 seconds, 0.93 minutes\n",
      "layer   1  Sparsity: 91.1000%\n",
      "layer   2  Sparsity: 57.8047%\n",
      "layer   3  Sparsity: 73.5247%\n",
      "total_backward_count 323070 real_backward_count 69170  21.410%\n",
      "epoch-33  lr=['0.0039062'], tr/val_loss:  0.033470/  0.057672, val:  63.75%, val_best:  76.25%, tr:  89.17%, tr_best:  89.79%, epoch time: 56.11 seconds, 0.94 minutes\n",
      "layer   1  Sparsity: 91.0624%\n",
      "layer   2  Sparsity: 57.7730%\n",
      "layer   3  Sparsity: 73.6039%\n",
      "total_backward_count 332860 real_backward_count 71067  21.350%\n",
      "epoch-34  lr=['0.0039062'], tr/val_loss:  0.034140/  0.052249, val:  73.75%, val_best:  76.25%, tr:  86.62%, tr_best:  89.79%, epoch time: 55.96 seconds, 0.93 minutes\n",
      "layer   1  Sparsity: 91.0800%\n",
      "layer   2  Sparsity: 57.7624%\n",
      "layer   3  Sparsity: 73.9495%\n",
      "total_backward_count 342650 real_backward_count 73058  21.321%\n",
      "epoch-35  lr=['0.0039062'], tr/val_loss:  0.033253/  0.057617, val:  67.92%, val_best:  76.25%, tr:  87.64%, tr_best:  89.79%, epoch time: 55.26 seconds, 0.92 minutes\n",
      "layer   1  Sparsity: 91.0334%\n",
      "layer   2  Sparsity: 57.7914%\n",
      "layer   3  Sparsity: 74.1044%\n",
      "total_backward_count 352440 real_backward_count 74916  21.256%\n",
      "epoch-36  lr=['0.0039062'], tr/val_loss:  0.032367/  0.052712, val:  73.33%, val_best:  76.25%, tr:  88.97%, tr_best:  89.79%, epoch time: 55.42 seconds, 0.92 minutes\n",
      "layer   1  Sparsity: 91.1015%\n",
      "layer   2  Sparsity: 57.8418%\n",
      "layer   3  Sparsity: 74.2788%\n",
      "total_backward_count 362230 real_backward_count 76738  21.185%\n",
      "epoch-37  lr=['0.0039062'], tr/val_loss:  0.032862/  0.052619, val:  70.00%, val_best:  76.25%, tr:  89.58%, tr_best:  89.79%, epoch time: 55.82 seconds, 0.93 minutes\n",
      "layer   1  Sparsity: 91.0794%\n",
      "layer   2  Sparsity: 57.8474%\n",
      "layer   3  Sparsity: 74.5766%\n",
      "total_backward_count 372020 real_backward_count 78633  21.137%\n",
      "epoch-38  lr=['0.0039062'], tr/val_loss:  0.032556/  0.056940, val:  62.92%, val_best:  76.25%, tr:  88.87%, tr_best:  89.79%, epoch time: 55.18 seconds, 0.92 minutes\n",
      "layer   1  Sparsity: 91.0705%\n",
      "layer   2  Sparsity: 57.9064%\n",
      "layer   3  Sparsity: 74.7790%\n",
      "total_backward_count 381810 real_backward_count 80509  21.086%\n",
      "epoch-39  lr=['0.0039062'], tr/val_loss:  0.032649/  0.052710, val:  76.67%, val_best:  76.67%, tr:  89.07%, tr_best:  89.79%, epoch time: 55.81 seconds, 0.93 minutes\n",
      "layer   1  Sparsity: 91.0914%\n",
      "layer   2  Sparsity: 57.8523%\n",
      "layer   3  Sparsity: 75.0916%\n",
      "total_backward_count 391600 real_backward_count 82414  21.045%\n",
      "epoch-40  lr=['0.0039062'], tr/val_loss:  0.031753/  0.056410, val:  64.17%, val_best:  76.67%, tr:  88.66%, tr_best:  89.79%, epoch time: 55.96 seconds, 0.93 minutes\n",
      "layer   1  Sparsity: 91.1067%\n",
      "layer   2  Sparsity: 57.8490%\n",
      "layer   3  Sparsity: 75.3781%\n",
      "total_backward_count 401390 real_backward_count 84223  20.983%\n",
      "epoch-41  lr=['0.0039062'], tr/val_loss:  0.032077/  0.052839, val:  73.75%, val_best:  76.67%, tr:  90.40%, tr_best:  90.40%, epoch time: 55.98 seconds, 0.93 minutes\n",
      "layer   1  Sparsity: 91.0590%\n",
      "layer   2  Sparsity: 57.8495%\n",
      "layer   3  Sparsity: 75.6108%\n",
      "total_backward_count 411180 real_backward_count 86046  20.927%\n",
      "epoch-42  lr=['0.0039062'], tr/val_loss:  0.031827/  0.053664, val:  75.00%, val_best:  76.67%, tr:  89.89%, tr_best:  90.40%, epoch time: 56.36 seconds, 0.94 minutes\n",
      "layer   1  Sparsity: 91.0814%\n",
      "layer   2  Sparsity: 57.8713%\n",
      "layer   3  Sparsity: 75.9127%\n",
      "total_backward_count 420970 real_backward_count 87860  20.871%\n",
      "epoch-43  lr=['0.0039062'], tr/val_loss:  0.031245/  0.054344, val:  69.58%, val_best:  76.67%, tr:  89.07%, tr_best:  90.40%, epoch time: 55.83 seconds, 0.93 minutes\n",
      "layer   1  Sparsity: 91.0685%\n",
      "layer   2  Sparsity: 57.9406%\n",
      "layer   3  Sparsity: 76.0050%\n",
      "total_backward_count 430760 real_backward_count 89687  20.821%\n",
      "epoch-44  lr=['0.0039062'], tr/val_loss:  0.031090/  0.053113, val:  69.58%, val_best:  76.67%, tr:  89.79%, tr_best:  90.40%, epoch time: 55.01 seconds, 0.92 minutes\n",
      "layer   1  Sparsity: 91.1075%\n",
      "layer   2  Sparsity: 58.0253%\n",
      "layer   3  Sparsity: 76.1391%\n",
      "total_backward_count 440550 real_backward_count 91462  20.761%\n",
      "epoch-45  lr=['0.0039062'], tr/val_loss:  0.030485/  0.056101, val:  68.75%, val_best:  76.67%, tr:  91.42%, tr_best:  91.42%, epoch time: 55.33 seconds, 0.92 minutes\n",
      "layer   1  Sparsity: 91.0436%\n",
      "layer   2  Sparsity: 57.9945%\n",
      "layer   3  Sparsity: 76.3200%\n",
      "total_backward_count 450340 real_backward_count 93190  20.693%\n",
      "epoch-46  lr=['0.0039062'], tr/val_loss:  0.030997/  0.055217, val:  70.00%, val_best:  76.67%, tr:  91.52%, tr_best:  91.52%, epoch time: 55.19 seconds, 0.92 minutes\n",
      "layer   1  Sparsity: 91.0821%\n",
      "layer   2  Sparsity: 58.1090%\n",
      "layer   3  Sparsity: 76.4780%\n",
      "total_backward_count 460130 real_backward_count 94936  20.632%\n",
      "epoch-47  lr=['0.0039062'], tr/val_loss:  0.030211/  0.051790, val:  71.25%, val_best:  76.67%, tr:  92.03%, tr_best:  92.03%, epoch time: 55.19 seconds, 0.92 minutes\n",
      "layer   1  Sparsity: 91.0621%\n",
      "layer   2  Sparsity: 58.1419%\n",
      "layer   3  Sparsity: 76.7115%\n",
      "total_backward_count 469920 real_backward_count 96646  20.566%\n",
      "epoch-48  lr=['0.0039062'], tr/val_loss:  0.029678/  0.057317, val:  65.83%, val_best:  76.67%, tr:  92.03%, tr_best:  92.03%, epoch time: 55.76 seconds, 0.93 minutes\n",
      "layer   1  Sparsity: 91.0602%\n",
      "layer   2  Sparsity: 58.1133%\n",
      "layer   3  Sparsity: 76.8750%\n",
      "total_backward_count 479710 real_backward_count 98317  20.495%\n",
      "epoch-49  lr=['0.0039062'], tr/val_loss:  0.029420/  0.050620, val:  75.83%, val_best:  76.67%, tr:  92.13%, tr_best:  92.13%, epoch time: 56.19 seconds, 0.94 minutes\n",
      "layer   1  Sparsity: 91.0557%\n",
      "layer   2  Sparsity: 58.0724%\n",
      "layer   3  Sparsity: 77.1724%\n",
      "total_backward_count 489500 real_backward_count 99947  20.418%\n",
      "epoch-50  lr=['0.0039062'], tr/val_loss:  0.029135/  0.054004, val:  67.92%, val_best:  76.67%, tr:  92.44%, tr_best:  92.44%, epoch time: 55.31 seconds, 0.92 minutes\n",
      "layer   1  Sparsity: 91.0889%\n",
      "layer   2  Sparsity: 58.2054%\n",
      "layer   3  Sparsity: 77.2518%\n",
      "total_backward_count 499290 real_backward_count 101555  20.340%\n",
      "epoch-51  lr=['0.0039062'], tr/val_loss:  0.028828/  0.053018, val:  75.42%, val_best:  76.67%, tr:  92.13%, tr_best:  92.44%, epoch time: 55.82 seconds, 0.93 minutes\n",
      "layer   1  Sparsity: 91.0434%\n",
      "layer   2  Sparsity: 58.2512%\n",
      "layer   3  Sparsity: 77.3949%\n",
      "total_backward_count 509080 real_backward_count 103194  20.271%\n",
      "epoch-52  lr=['0.0039062'], tr/val_loss:  0.028875/  0.050523, val:  70.42%, val_best:  76.67%, tr:  91.32%, tr_best:  92.44%, epoch time: 56.11 seconds, 0.94 minutes\n",
      "layer   1  Sparsity: 91.0813%\n",
      "layer   2  Sparsity: 58.3133%\n",
      "layer   3  Sparsity: 77.6989%\n",
      "total_backward_count 518870 real_backward_count 104805  20.199%\n",
      "epoch-53  lr=['0.0039062'], tr/val_loss:  0.028419/  0.048937, val:  78.75%, val_best:  78.75%, tr:  92.95%, tr_best:  92.95%, epoch time: 55.97 seconds, 0.93 minutes\n",
      "layer   1  Sparsity: 91.0852%\n",
      "layer   2  Sparsity: 58.2686%\n",
      "layer   3  Sparsity: 77.9242%\n",
      "total_backward_count 528660 real_backward_count 106425  20.131%\n",
      "epoch-54  lr=['0.0039062'], tr/val_loss:  0.028009/  0.058635, val:  70.42%, val_best:  78.75%, tr:  92.54%, tr_best:  92.95%, epoch time: 55.70 seconds, 0.93 minutes\n",
      "layer   1  Sparsity: 91.0426%\n",
      "layer   2  Sparsity: 58.3468%\n",
      "layer   3  Sparsity: 78.0105%\n",
      "total_backward_count 538450 real_backward_count 107999  20.057%\n",
      "epoch-55  lr=['0.0039062'], tr/val_loss:  0.027754/  0.050900, val:  79.58%, val_best:  79.58%, tr:  93.26%, tr_best:  93.26%, epoch time: 55.87 seconds, 0.93 minutes\n",
      "layer   1  Sparsity: 91.0742%\n",
      "layer   2  Sparsity: 58.3483%\n",
      "layer   3  Sparsity: 78.2625%\n",
      "total_backward_count 548240 real_backward_count 109568  19.985%\n",
      "epoch-56  lr=['0.0039062'], tr/val_loss:  0.027346/  0.053653, val:  69.17%, val_best:  79.58%, tr:  93.36%, tr_best:  93.36%, epoch time: 55.69 seconds, 0.93 minutes\n",
      "layer   1  Sparsity: 91.0566%\n",
      "layer   2  Sparsity: 58.4078%\n",
      "layer   3  Sparsity: 78.4681%\n",
      "total_backward_count 558030 real_backward_count 111089  19.907%\n",
      "epoch-57  lr=['0.0039062'], tr/val_loss:  0.027271/  0.053595, val:  69.17%, val_best:  79.58%, tr:  93.46%, tr_best:  93.46%, epoch time: 55.06 seconds, 0.92 minutes\n",
      "layer   1  Sparsity: 91.0569%\n",
      "layer   2  Sparsity: 58.5870%\n",
      "layer   3  Sparsity: 78.4928%\n",
      "total_backward_count 567820 real_backward_count 112601  19.830%\n",
      "epoch-58  lr=['0.0039062'], tr/val_loss:  0.027361/  0.049241, val:  74.58%, val_best:  79.58%, tr:  94.59%, tr_best:  94.59%, epoch time: 55.94 seconds, 0.93 minutes\n",
      "layer   1  Sparsity: 91.0667%\n",
      "layer   2  Sparsity: 58.6790%\n",
      "layer   3  Sparsity: 78.5671%\n",
      "total_backward_count 577610 real_backward_count 114126  19.758%\n",
      "epoch-59  lr=['0.0039062'], tr/val_loss:  0.027176/  0.050612, val:  75.42%, val_best:  79.58%, tr:  93.36%, tr_best:  94.59%, epoch time: 55.86 seconds, 0.93 minutes\n",
      "layer   1  Sparsity: 91.0823%\n",
      "layer   2  Sparsity: 58.7144%\n",
      "layer   3  Sparsity: 78.8085%\n",
      "total_backward_count 587400 real_backward_count 115664  19.691%\n",
      "epoch-60  lr=['0.0039062'], tr/val_loss:  0.026587/  0.049690, val:  74.58%, val_best:  79.58%, tr:  94.38%, tr_best:  94.59%, epoch time: 55.75 seconds, 0.93 minutes\n",
      "layer   1  Sparsity: 91.0564%\n",
      "layer   2  Sparsity: 58.8240%\n",
      "layer   3  Sparsity: 79.0393%\n",
      "total_backward_count 597190 real_backward_count 117154  19.618%\n",
      "epoch-61  lr=['0.0039062'], tr/val_loss:  0.026205/  0.049000, val:  76.25%, val_best:  79.58%, tr:  94.59%, tr_best:  94.59%, epoch time: 55.97 seconds, 0.93 minutes\n",
      "layer   1  Sparsity: 91.0702%\n",
      "layer   2  Sparsity: 58.8357%\n",
      "layer   3  Sparsity: 79.1879%\n",
      "total_backward_count 606980 real_backward_count 118600  19.539%\n",
      "epoch-62  lr=['0.0039062'], tr/val_loss:  0.026068/  0.052418, val:  74.17%, val_best:  79.58%, tr:  94.18%, tr_best:  94.59%, epoch time: 56.40 seconds, 0.94 minutes\n",
      "layer   1  Sparsity: 91.0815%\n",
      "layer   2  Sparsity: 58.8287%\n",
      "layer   3  Sparsity: 79.2865%\n",
      "total_backward_count 616770 real_backward_count 120067  19.467%\n",
      "epoch-63  lr=['0.0039062'], tr/val_loss:  0.025334/  0.046258, val:  84.17%, val_best:  84.17%, tr:  94.89%, tr_best:  94.89%, epoch time: 55.14 seconds, 0.92 minutes\n",
      "layer   1  Sparsity: 91.0783%\n",
      "layer   2  Sparsity: 58.8882%\n",
      "layer   3  Sparsity: 79.4153%\n",
      "total_backward_count 626560 real_backward_count 121426  19.380%\n",
      "epoch-64  lr=['0.0039062'], tr/val_loss:  0.024752/  0.049392, val:  76.67%, val_best:  84.17%, tr:  95.20%, tr_best:  95.20%, epoch time: 55.70 seconds, 0.93 minutes\n",
      "layer   1  Sparsity: 91.0609%\n",
      "layer   2  Sparsity: 58.8730%\n",
      "layer   3  Sparsity: 79.5679%\n",
      "total_backward_count 636350 real_backward_count 122802  19.298%\n",
      "epoch-65  lr=['0.0039062'], tr/val_loss:  0.025246/  0.046590, val:  82.50%, val_best:  84.17%, tr:  95.20%, tr_best:  95.20%, epoch time: 55.67 seconds, 0.93 minutes\n",
      "layer   1  Sparsity: 91.0804%\n",
      "layer   2  Sparsity: 58.8859%\n",
      "layer   3  Sparsity: 79.7174%\n",
      "total_backward_count 646140 real_backward_count 124230  19.226%\n",
      "epoch-66  lr=['0.0039062'], tr/val_loss:  0.024610/  0.045545, val:  81.25%, val_best:  84.17%, tr:  95.30%, tr_best:  95.30%, epoch time: 55.79 seconds, 0.93 minutes\n",
      "layer   1  Sparsity: 91.0801%\n",
      "layer   2  Sparsity: 59.0343%\n",
      "layer   3  Sparsity: 79.7719%\n",
      "total_backward_count 655930 real_backward_count 125599  19.148%\n",
      "epoch-67  lr=['0.0039062'], tr/val_loss:  0.024109/  0.049778, val:  76.67%, val_best:  84.17%, tr:  95.61%, tr_best:  95.61%, epoch time: 55.54 seconds, 0.93 minutes\n",
      "layer   1  Sparsity: 91.0866%\n",
      "layer   2  Sparsity: 59.1741%\n",
      "layer   3  Sparsity: 79.7605%\n",
      "total_backward_count 665720 real_backward_count 126935  19.067%\n",
      "epoch-68  lr=['0.0039062'], tr/val_loss:  0.024958/  0.047564, val:  81.67%, val_best:  84.17%, tr:  95.30%, tr_best:  95.61%, epoch time: 55.95 seconds, 0.93 minutes\n",
      "layer   1  Sparsity: 91.0844%\n",
      "layer   2  Sparsity: 59.1949%\n",
      "layer   3  Sparsity: 79.8364%\n",
      "total_backward_count 675510 real_backward_count 128298  18.993%\n",
      "epoch-69  lr=['0.0039062'], tr/val_loss:  0.023194/  0.050236, val:  77.08%, val_best:  84.17%, tr:  96.02%, tr_best:  96.02%, epoch time: 55.41 seconds, 0.92 minutes\n",
      "layer   1  Sparsity: 91.0715%\n",
      "layer   2  Sparsity: 59.2071%\n",
      "layer   3  Sparsity: 80.0372%\n",
      "total_backward_count 685300 real_backward_count 129528  18.901%\n",
      "epoch-70  lr=['0.0039062'], tr/val_loss:  0.024270/  0.049520, val:  73.75%, val_best:  84.17%, tr:  96.42%, tr_best:  96.42%, epoch time: 56.31 seconds, 0.94 minutes\n",
      "layer   1  Sparsity: 91.0907%\n",
      "layer   2  Sparsity: 59.2455%\n",
      "layer   3  Sparsity: 79.9800%\n",
      "total_backward_count 695090 real_backward_count 130867  18.827%\n",
      "epoch-71  lr=['0.0039062'], tr/val_loss:  0.023634/  0.047191, val:  81.25%, val_best:  84.17%, tr:  95.40%, tr_best:  96.42%, epoch time: 55.96 seconds, 0.93 minutes\n",
      "layer   1  Sparsity: 91.0915%\n",
      "layer   2  Sparsity: 59.3881%\n",
      "layer   3  Sparsity: 80.0648%\n",
      "total_backward_count 704880 real_backward_count 132198  18.755%\n",
      "epoch-72  lr=['0.0039062'], tr/val_loss:  0.022756/  0.045819, val:  80.00%, val_best:  84.17%, tr:  96.73%, tr_best:  96.73%, epoch time: 55.58 seconds, 0.93 minutes\n",
      "layer   1  Sparsity: 91.0664%\n",
      "layer   2  Sparsity: 59.3797%\n",
      "layer   3  Sparsity: 80.1660%\n",
      "total_backward_count 714670 real_backward_count 133438  18.671%\n",
      "epoch-73  lr=['0.0039062'], tr/val_loss:  0.023240/  0.044285, val:  85.00%, val_best:  85.00%, tr:  96.73%, tr_best:  96.73%, epoch time: 55.99 seconds, 0.93 minutes\n",
      "layer   1  Sparsity: 91.0547%\n",
      "layer   2  Sparsity: 59.3828%\n",
      "layer   3  Sparsity: 80.2541%\n",
      "total_backward_count 724460 real_backward_count 134734  18.598%\n",
      "epoch-74  lr=['0.0039062'], tr/val_loss:  0.022666/  0.045756, val:  83.33%, val_best:  85.00%, tr:  96.02%, tr_best:  96.73%, epoch time: 55.65 seconds, 0.93 minutes\n",
      "layer   1  Sparsity: 91.1059%\n",
      "layer   2  Sparsity: 59.3223%\n",
      "layer   3  Sparsity: 80.5252%\n",
      "total_backward_count 734250 real_backward_count 135954  18.516%\n",
      "epoch-75  lr=['0.0039062'], tr/val_loss:  0.022311/  0.049558, val:  76.67%, val_best:  85.00%, tr:  96.63%, tr_best:  96.73%, epoch time: 55.96 seconds, 0.93 minutes\n",
      "layer   1  Sparsity: 91.1047%\n",
      "layer   2  Sparsity: 59.2988%\n",
      "layer   3  Sparsity: 80.5571%\n",
      "total_backward_count 744040 real_backward_count 137174  18.436%\n",
      "epoch-76  lr=['0.0039062'], tr/val_loss:  0.022462/  0.045388, val:  83.75%, val_best:  85.00%, tr:  97.24%, tr_best:  97.24%, epoch time: 55.56 seconds, 0.93 minutes\n",
      "layer   1  Sparsity: 91.0907%\n",
      "layer   2  Sparsity: 59.2952%\n",
      "layer   3  Sparsity: 80.7432%\n",
      "total_backward_count 753830 real_backward_count 138416  18.362%\n",
      "epoch-77  lr=['0.0039062'], tr/val_loss:  0.022547/  0.050904, val:  74.17%, val_best:  85.00%, tr:  96.53%, tr_best:  97.24%, epoch time: 55.90 seconds, 0.93 minutes\n",
      "layer   1  Sparsity: 91.0886%\n",
      "layer   2  Sparsity: 59.2391%\n",
      "layer   3  Sparsity: 80.8533%\n",
      "total_backward_count 763620 real_backward_count 139646  18.287%\n",
      "epoch-78  lr=['0.0039062'], tr/val_loss:  0.021476/  0.045372, val:  81.67%, val_best:  85.00%, tr:  97.04%, tr_best:  97.24%, epoch time: 55.42 seconds, 0.92 minutes\n",
      "layer   1  Sparsity: 91.0891%\n",
      "layer   2  Sparsity: 59.3091%\n",
      "layer   3  Sparsity: 80.8524%\n",
      "total_backward_count 773410 real_backward_count 140793  18.204%\n",
      "epoch-79  lr=['0.0039062'], tr/val_loss:  0.021204/  0.046348, val:  78.75%, val_best:  85.00%, tr:  98.06%, tr_best:  98.06%, epoch time: 55.17 seconds, 0.92 minutes\n",
      "layer   1  Sparsity: 91.0719%\n",
      "layer   2  Sparsity: 59.3093%\n",
      "layer   3  Sparsity: 80.8421%\n",
      "total_backward_count 783200 real_backward_count 141913  18.120%\n",
      "epoch-80  lr=['0.0039062'], tr/val_loss:  0.021654/  0.045351, val:  83.33%, val_best:  85.00%, tr:  97.34%, tr_best:  98.06%, epoch time: 56.39 seconds, 0.94 minutes\n",
      "layer   1  Sparsity: 91.1085%\n",
      "layer   2  Sparsity: 59.4020%\n",
      "layer   3  Sparsity: 80.8961%\n",
      "total_backward_count 792990 real_backward_count 143107  18.047%\n",
      "epoch-81  lr=['0.0039062'], tr/val_loss:  0.021037/  0.044963, val:  83.75%, val_best:  85.00%, tr:  97.65%, tr_best:  98.06%, epoch time: 55.66 seconds, 0.93 minutes\n",
      "layer   1  Sparsity: 91.0458%\n",
      "layer   2  Sparsity: 59.4032%\n",
      "layer   3  Sparsity: 80.8843%\n",
      "total_backward_count 802780 real_backward_count 144269  17.971%\n",
      "epoch-82  lr=['0.0039062'], tr/val_loss:  0.020319/  0.043243, val:  83.33%, val_best:  85.00%, tr:  97.85%, tr_best:  98.06%, epoch time: 56.02 seconds, 0.93 minutes\n",
      "layer   1  Sparsity: 91.0810%\n",
      "layer   2  Sparsity: 59.3917%\n",
      "layer   3  Sparsity: 81.0348%\n",
      "total_backward_count 812570 real_backward_count 145355  17.888%\n",
      "epoch-83  lr=['0.0039062'], tr/val_loss:  0.020698/  0.045359, val:  82.50%, val_best:  85.00%, tr:  97.24%, tr_best:  98.06%, epoch time: 55.32 seconds, 0.92 minutes\n",
      "layer   1  Sparsity: 91.1113%\n",
      "layer   2  Sparsity: 59.4160%\n",
      "layer   3  Sparsity: 81.1109%\n",
      "total_backward_count 822360 real_backward_count 146503  17.815%\n",
      "epoch-84  lr=['0.0039062'], tr/val_loss:  0.020237/  0.046661, val:  77.92%, val_best:  85.00%, tr:  97.45%, tr_best:  98.06%, epoch time: 55.99 seconds, 0.93 minutes\n",
      "layer   1  Sparsity: 91.0939%\n",
      "layer   2  Sparsity: 59.4018%\n",
      "layer   3  Sparsity: 81.2697%\n",
      "total_backward_count 832150 real_backward_count 147629  17.741%\n",
      "epoch-85  lr=['0.0039062'], tr/val_loss:  0.019941/  0.044063, val:  85.00%, val_best:  85.00%, tr:  97.75%, tr_best:  98.06%, epoch time: 55.85 seconds, 0.93 minutes\n",
      "layer   1  Sparsity: 91.0888%\n",
      "layer   2  Sparsity: 59.5467%\n",
      "layer   3  Sparsity: 81.3071%\n",
      "total_backward_count 841940 real_backward_count 148745  17.667%\n",
      "epoch-86  lr=['0.0039062'], tr/val_loss:  0.020354/  0.044533, val:  78.75%, val_best:  85.00%, tr:  97.55%, tr_best:  98.06%, epoch time: 56.28 seconds, 0.94 minutes\n",
      "layer   1  Sparsity: 91.0991%\n",
      "layer   2  Sparsity: 59.5933%\n",
      "layer   3  Sparsity: 81.2678%\n",
      "total_backward_count 851730 real_backward_count 149847  17.593%\n",
      "epoch-87  lr=['0.0039062'], tr/val_loss:  0.019517/  0.043351, val:  82.08%, val_best:  85.00%, tr:  98.26%, tr_best:  98.26%, epoch time: 55.43 seconds, 0.92 minutes\n",
      "layer   1  Sparsity: 91.0528%\n",
      "layer   2  Sparsity: 59.5177%\n",
      "layer   3  Sparsity: 81.4507%\n",
      "total_backward_count 861520 real_backward_count 150869  17.512%\n",
      "epoch-88  lr=['0.0039062'], tr/val_loss:  0.019688/  0.043229, val:  84.17%, val_best:  85.00%, tr:  97.34%, tr_best:  98.26%, epoch time: 55.86 seconds, 0.93 minutes\n",
      "layer   1  Sparsity: 91.0361%\n",
      "layer   2  Sparsity: 59.4824%\n",
      "layer   3  Sparsity: 81.5054%\n",
      "total_backward_count 871310 real_backward_count 151933  17.437%\n",
      "epoch-89  lr=['0.0039062'], tr/val_loss:  0.019283/  0.042924, val:  84.17%, val_best:  85.00%, tr:  97.14%, tr_best:  98.26%, epoch time: 55.38 seconds, 0.92 minutes\n",
      "layer   1  Sparsity: 91.0929%\n",
      "layer   2  Sparsity: 59.5184%\n",
      "layer   3  Sparsity: 81.5753%\n",
      "total_backward_count 881100 real_backward_count 152969  17.361%\n",
      "epoch-90  lr=['0.0039062'], tr/val_loss:  0.018985/  0.043499, val:  84.58%, val_best:  85.00%, tr:  97.85%, tr_best:  98.26%, epoch time: 54.91 seconds, 0.92 minutes\n",
      "layer   1  Sparsity: 91.0807%\n",
      "layer   2  Sparsity: 59.4889%\n",
      "layer   3  Sparsity: 81.6447%\n",
      "total_backward_count 890890 real_backward_count 154011  17.287%\n",
      "epoch-91  lr=['0.0039062'], tr/val_loss:  0.018552/  0.041531, val:  85.83%, val_best:  85.83%, tr:  98.26%, tr_best:  98.26%, epoch time: 55.27 seconds, 0.92 minutes\n",
      "layer   1  Sparsity: 91.0772%\n",
      "layer   2  Sparsity: 59.5233%\n",
      "layer   3  Sparsity: 81.6850%\n",
      "total_backward_count 900680 real_backward_count 155000  17.209%\n",
      "epoch-92  lr=['0.0039062'], tr/val_loss:  0.019001/  0.043134, val:  85.42%, val_best:  85.83%, tr:  97.96%, tr_best:  98.26%, epoch time: 55.29 seconds, 0.92 minutes\n",
      "layer   1  Sparsity: 91.0939%\n",
      "layer   2  Sparsity: 59.5977%\n",
      "layer   3  Sparsity: 81.6762%\n",
      "total_backward_count 910470 real_backward_count 156015  17.136%\n",
      "epoch-93  lr=['0.0039062'], tr/val_loss:  0.019001/  0.041896, val:  84.17%, val_best:  85.83%, tr:  98.16%, tr_best:  98.26%, epoch time: 55.22 seconds, 0.92 minutes\n",
      "layer   1  Sparsity: 91.1053%\n",
      "layer   2  Sparsity: 59.5676%\n",
      "layer   3  Sparsity: 81.7231%\n",
      "total_backward_count 920260 real_backward_count 157073  17.068%\n",
      "epoch-94  lr=['0.0039062'], tr/val_loss:  0.019046/  0.045488, val:  79.17%, val_best:  85.83%, tr:  98.16%, tr_best:  98.26%, epoch time: 55.45 seconds, 0.92 minutes\n",
      "layer   1  Sparsity: 91.0730%\n",
      "layer   2  Sparsity: 59.5537%\n",
      "layer   3  Sparsity: 81.7383%\n",
      "total_backward_count 930050 real_backward_count 158113  17.000%\n",
      "epoch-95  lr=['0.0039062'], tr/val_loss:  0.018332/  0.044093, val:  82.92%, val_best:  85.83%, tr:  98.57%, tr_best:  98.57%, epoch time: 55.68 seconds, 0.93 minutes\n",
      "layer   1  Sparsity: 91.1021%\n",
      "layer   2  Sparsity: 59.5695%\n",
      "layer   3  Sparsity: 81.8874%\n",
      "total_backward_count 939840 real_backward_count 159120  16.931%\n",
      "epoch-96  lr=['0.0039062'], tr/val_loss:  0.018600/  0.045115, val:  82.50%, val_best:  85.83%, tr:  98.16%, tr_best:  98.57%, epoch time: 55.77 seconds, 0.93 minutes\n",
      "layer   1  Sparsity: 91.0936%\n",
      "layer   2  Sparsity: 59.5339%\n",
      "layer   3  Sparsity: 81.8928%\n",
      "total_backward_count 949630 real_backward_count 160140  16.863%\n",
      "epoch-97  lr=['0.0039062'], tr/val_loss:  0.017960/  0.042662, val:  82.92%, val_best:  85.83%, tr:  98.57%, tr_best:  98.57%, epoch time: 55.59 seconds, 0.93 minutes\n",
      "layer   1  Sparsity: 91.0833%\n",
      "layer   2  Sparsity: 59.5582%\n",
      "layer   3  Sparsity: 81.9612%\n",
      "total_backward_count 959420 real_backward_count 161113  16.793%\n",
      "epoch-98  lr=['0.0039062'], tr/val_loss:  0.018256/  0.045006, val:  80.42%, val_best:  85.83%, tr:  98.16%, tr_best:  98.57%, epoch time: 56.26 seconds, 0.94 minutes\n",
      "layer   1  Sparsity: 91.0890%\n",
      "layer   2  Sparsity: 59.5926%\n",
      "layer   3  Sparsity: 81.9288%\n",
      "total_backward_count 969210 real_backward_count 162111  16.726%\n",
      "epoch-99  lr=['0.0039062'], tr/val_loss:  0.018163/  0.044001, val:  84.17%, val_best:  85.83%, tr:  98.06%, tr_best:  98.57%, epoch time: 55.65 seconds, 0.93 minutes\n",
      "layer   1  Sparsity: 91.0636%\n",
      "layer   2  Sparsity: 59.5296%\n",
      "layer   3  Sparsity: 82.0643%\n",
      "total_backward_count 979000 real_backward_count 163073  16.657%\n",
      "epoch-100 lr=['0.0039062'], tr/val_loss:  0.017840/  0.044007, val:  83.33%, val_best:  85.83%, tr:  97.85%, tr_best:  98.57%, epoch time: 55.30 seconds, 0.92 minutes\n",
      "layer   1  Sparsity: 91.0934%\n",
      "layer   2  Sparsity: 59.4201%\n",
      "layer   3  Sparsity: 82.2198%\n",
      "total_backward_count 988790 real_backward_count 164033  16.589%\n",
      "epoch-101 lr=['0.0039062'], tr/val_loss:  0.017511/  0.043467, val:  84.58%, val_best:  85.83%, tr:  97.96%, tr_best:  98.57%, epoch time: 55.90 seconds, 0.93 minutes\n",
      "layer   1  Sparsity: 91.0846%\n",
      "layer   2  Sparsity: 59.3745%\n",
      "layer   3  Sparsity: 82.2553%\n",
      "total_backward_count 998580 real_backward_count 164958  16.519%\n",
      "epoch-102 lr=['0.0039062'], tr/val_loss:  0.017074/  0.043230, val:  81.67%, val_best:  85.83%, tr:  98.47%, tr_best:  98.57%, epoch time: 55.65 seconds, 0.93 minutes\n",
      "layer   1  Sparsity: 91.0213%\n",
      "layer   2  Sparsity: 59.4125%\n",
      "layer   3  Sparsity: 82.2319%\n",
      "total_backward_count 1008370 real_backward_count 165842  16.447%\n",
      "epoch-103 lr=['0.0039062'], tr/val_loss:  0.017423/  0.044096, val:  83.33%, val_best:  85.83%, tr:  98.57%, tr_best:  98.57%, epoch time: 55.86 seconds, 0.93 minutes\n",
      "layer   1  Sparsity: 91.0827%\n",
      "layer   2  Sparsity: 59.3637%\n",
      "layer   3  Sparsity: 82.3249%\n",
      "total_backward_count 1018160 real_backward_count 166767  16.379%\n",
      "epoch-104 lr=['0.0039062'], tr/val_loss:  0.018241/  0.041125, val:  86.25%, val_best:  86.25%, tr:  98.26%, tr_best:  98.57%, epoch time: 56.21 seconds, 0.94 minutes\n",
      "layer   1  Sparsity: 91.0741%\n",
      "layer   2  Sparsity: 59.3972%\n",
      "layer   3  Sparsity: 82.3576%\n",
      "total_backward_count 1027950 real_backward_count 167752  16.319%\n",
      "epoch-105 lr=['0.0039062'], tr/val_loss:  0.017460/  0.043683, val:  80.83%, val_best:  86.25%, tr:  98.77%, tr_best:  98.77%, epoch time: 56.05 seconds, 0.93 minutes\n",
      "layer   1  Sparsity: 91.0876%\n",
      "layer   2  Sparsity: 59.4027%\n",
      "layer   3  Sparsity: 82.3546%\n",
      "total_backward_count 1037740 real_backward_count 168700  16.256%\n",
      "epoch-106 lr=['0.0039062'], tr/val_loss:  0.017354/  0.041299, val:  86.67%, val_best:  86.67%, tr:  98.88%, tr_best:  98.88%, epoch time: 55.28 seconds, 0.92 minutes\n",
      "layer   1  Sparsity: 91.0491%\n",
      "layer   2  Sparsity: 59.4349%\n",
      "layer   3  Sparsity: 82.3471%\n",
      "total_backward_count 1047530 real_backward_count 169642  16.194%\n",
      "epoch-107 lr=['0.0039062'], tr/val_loss:  0.016538/  0.042254, val:  84.17%, val_best:  86.67%, tr:  98.88%, tr_best:  98.88%, epoch time: 56.09 seconds, 0.93 minutes\n",
      "layer   1  Sparsity: 91.0976%\n",
      "layer   2  Sparsity: 59.4286%\n",
      "layer   3  Sparsity: 82.3360%\n",
      "total_backward_count 1057320 real_backward_count 170518  16.127%\n",
      "epoch-108 lr=['0.0039062'], tr/val_loss:  0.016493/  0.044147, val:  83.75%, val_best:  86.67%, tr:  98.77%, tr_best:  98.88%, epoch time: 55.53 seconds, 0.93 minutes\n",
      "layer   1  Sparsity: 91.0796%\n",
      "layer   2  Sparsity: 59.4460%\n",
      "layer   3  Sparsity: 82.3526%\n",
      "total_backward_count 1067110 real_backward_count 171373  16.060%\n",
      "epoch-109 lr=['0.0039062'], tr/val_loss:  0.017086/  0.043056, val:  84.17%, val_best:  86.67%, tr:  98.47%, tr_best:  98.88%, epoch time: 56.13 seconds, 0.94 minutes\n",
      "layer   1  Sparsity: 91.0661%\n",
      "layer   2  Sparsity: 59.3780%\n",
      "layer   3  Sparsity: 82.3989%\n",
      "total_backward_count 1076900 real_backward_count 172290  15.999%\n",
      "epoch-110 lr=['0.0039062'], tr/val_loss:  0.016643/  0.041435, val:  82.50%, val_best:  86.67%, tr:  98.37%, tr_best:  98.88%, epoch time: 56.11 seconds, 0.94 minutes\n",
      "layer   1  Sparsity: 91.0704%\n",
      "layer   2  Sparsity: 59.4145%\n",
      "layer   3  Sparsity: 82.6064%\n",
      "total_backward_count 1086690 real_backward_count 173192  15.938%\n",
      "epoch-111 lr=['0.0039062'], tr/val_loss:  0.015946/  0.042769, val:  84.17%, val_best:  86.67%, tr:  98.77%, tr_best:  98.88%, epoch time: 55.94 seconds, 0.93 minutes\n",
      "layer   1  Sparsity: 91.0895%\n",
      "layer   2  Sparsity: 59.3293%\n",
      "layer   3  Sparsity: 82.6325%\n",
      "total_backward_count 1096480 real_backward_count 174053  15.874%\n",
      "epoch-112 lr=['0.0039062'], tr/val_loss:  0.016161/  0.041936, val:  84.58%, val_best:  86.67%, tr:  98.37%, tr_best:  98.88%, epoch time: 55.67 seconds, 0.93 minutes\n",
      "layer   1  Sparsity: 91.1225%\n",
      "layer   2  Sparsity: 59.3415%\n",
      "layer   3  Sparsity: 82.7204%\n",
      "total_backward_count 1106270 real_backward_count 174917  15.811%\n",
      "epoch-113 lr=['0.0039062'], tr/val_loss:  0.015136/  0.041437, val:  85.00%, val_best:  86.67%, tr:  98.47%, tr_best:  98.88%, epoch time: 56.29 seconds, 0.94 minutes\n",
      "layer   1  Sparsity: 91.0752%\n",
      "layer   2  Sparsity: 59.3674%\n",
      "layer   3  Sparsity: 82.8050%\n",
      "total_backward_count 1116060 real_backward_count 175671  15.740%\n",
      "epoch-114 lr=['0.0039062'], tr/val_loss:  0.015314/  0.042528, val:  83.33%, val_best:  86.67%, tr:  99.28%, tr_best:  99.28%, epoch time: 55.80 seconds, 0.93 minutes\n",
      "layer   1  Sparsity: 91.1080%\n",
      "layer   2  Sparsity: 59.2723%\n",
      "layer   3  Sparsity: 82.8391%\n",
      "total_backward_count 1125850 real_backward_count 176506  15.678%\n",
      "epoch-115 lr=['0.0039062'], tr/val_loss:  0.015897/  0.043498, val:  81.25%, val_best:  86.67%, tr:  98.47%, tr_best:  99.28%, epoch time: 56.39 seconds, 0.94 minutes\n",
      "layer   1  Sparsity: 91.0545%\n",
      "layer   2  Sparsity: 59.2923%\n",
      "layer   3  Sparsity: 82.8789%\n",
      "total_backward_count 1135640 real_backward_count 177349  15.617%\n",
      "epoch-116 lr=['0.0039062'], tr/val_loss:  0.016575/  0.040373, val:  85.42%, val_best:  86.67%, tr:  98.77%, tr_best:  99.28%, epoch time: 56.56 seconds, 0.94 minutes\n",
      "layer   1  Sparsity: 91.0647%\n",
      "layer   2  Sparsity: 59.3377%\n",
      "layer   3  Sparsity: 82.8721%\n",
      "total_backward_count 1145430 real_backward_count 178243  15.561%\n",
      "epoch-117 lr=['0.0039062'], tr/val_loss:  0.014615/  0.041127, val:  85.42%, val_best:  86.67%, tr:  99.28%, tr_best:  99.28%, epoch time: 55.63 seconds, 0.93 minutes\n",
      "layer   1  Sparsity: 91.0496%\n",
      "layer   2  Sparsity: 59.3277%\n",
      "layer   3  Sparsity: 82.8912%\n",
      "total_backward_count 1155220 real_backward_count 178979  15.493%\n",
      "epoch-118 lr=['0.0039062'], tr/val_loss:  0.015639/  0.040635, val:  85.42%, val_best:  86.67%, tr:  98.88%, tr_best:  99.28%, epoch time: 55.83 seconds, 0.93 minutes\n",
      "layer   1  Sparsity: 91.0916%\n",
      "layer   2  Sparsity: 59.2696%\n",
      "layer   3  Sparsity: 83.0289%\n",
      "total_backward_count 1165010 real_backward_count 179812  15.434%\n",
      "epoch-119 lr=['0.0039062'], tr/val_loss:  0.014894/  0.039676, val:  84.58%, val_best:  86.67%, tr:  98.67%, tr_best:  99.28%, epoch time: 52.23 seconds, 0.87 minutes\n",
      "layer   1  Sparsity: 91.0942%\n",
      "layer   2  Sparsity: 59.3155%\n",
      "layer   3  Sparsity: 83.0209%\n",
      "total_backward_count 1174800 real_backward_count 180584  15.371%\n",
      "epoch-120 lr=['0.0039062'], tr/val_loss:  0.015406/  0.041781, val:  83.75%, val_best:  86.67%, tr:  98.67%, tr_best:  99.28%, epoch time: 54.38 seconds, 0.91 minutes\n",
      "layer   1  Sparsity: 91.1050%\n",
      "layer   2  Sparsity: 59.3660%\n",
      "layer   3  Sparsity: 83.0538%\n",
      "total_backward_count 1184590 real_backward_count 181404  15.314%\n",
      "epoch-121 lr=['0.0039062'], tr/val_loss:  0.015643/  0.044430, val:  81.67%, val_best:  86.67%, tr:  99.39%, tr_best:  99.39%, epoch time: 55.95 seconds, 0.93 minutes\n",
      "layer   1  Sparsity: 91.0928%\n",
      "layer   2  Sparsity: 59.2813%\n",
      "layer   3  Sparsity: 83.1276%\n",
      "total_backward_count 1194380 real_backward_count 182255  15.259%\n",
      "epoch-122 lr=['0.0039062'], tr/val_loss:  0.014520/  0.040897, val:  85.83%, val_best:  86.67%, tr:  99.18%, tr_best:  99.39%, epoch time: 56.06 seconds, 0.93 minutes\n",
      "layer   1  Sparsity: 91.0572%\n",
      "layer   2  Sparsity: 59.3779%\n",
      "layer   3  Sparsity: 83.1064%\n",
      "total_backward_count 1204170 real_backward_count 183021  15.199%\n",
      "epoch-123 lr=['0.0039062'], tr/val_loss:  0.014506/  0.039915, val:  85.00%, val_best:  86.67%, tr:  99.18%, tr_best:  99.39%, epoch time: 55.42 seconds, 0.92 minutes\n",
      "layer   1  Sparsity: 91.0664%\n",
      "layer   2  Sparsity: 59.2511%\n",
      "layer   3  Sparsity: 83.2325%\n",
      "total_backward_count 1213960 real_backward_count 183768  15.138%\n",
      "epoch-124 lr=['0.0039062'], tr/val_loss:  0.014557/  0.039404, val:  85.83%, val_best:  86.67%, tr:  98.88%, tr_best:  99.39%, epoch time: 55.94 seconds, 0.93 minutes\n",
      "layer   1  Sparsity: 91.0950%\n",
      "layer   2  Sparsity: 59.2110%\n",
      "layer   3  Sparsity: 83.1964%\n",
      "total_backward_count 1223750 real_backward_count 184529  15.079%\n",
      "epoch-125 lr=['0.0039062'], tr/val_loss:  0.014942/  0.039467, val:  87.50%, val_best:  87.50%, tr:  99.18%, tr_best:  99.39%, epoch time: 55.59 seconds, 0.93 minutes\n",
      "layer   1  Sparsity: 91.0994%\n",
      "layer   2  Sparsity: 59.2494%\n",
      "layer   3  Sparsity: 83.2591%\n",
      "total_backward_count 1233540 real_backward_count 185319  15.023%\n",
      "epoch-126 lr=['0.0039062'], tr/val_loss:  0.014597/  0.039407, val:  87.08%, val_best:  87.50%, tr:  99.08%, tr_best:  99.39%, epoch time: 55.88 seconds, 0.93 minutes\n",
      "layer   1  Sparsity: 91.0942%\n",
      "layer   2  Sparsity: 59.1498%\n",
      "layer   3  Sparsity: 83.3359%\n",
      "total_backward_count 1243330 real_backward_count 186075  14.966%\n",
      "epoch-127 lr=['0.0039062'], tr/val_loss:  0.014645/  0.041020, val:  86.25%, val_best:  87.50%, tr:  98.77%, tr_best:  99.39%, epoch time: 55.63 seconds, 0.93 minutes\n",
      "layer   1  Sparsity: 91.0905%\n",
      "layer   2  Sparsity: 59.2969%\n",
      "layer   3  Sparsity: 83.3463%\n",
      "total_backward_count 1253120 real_backward_count 186848  14.911%\n",
      "epoch-128 lr=['0.0039062'], tr/val_loss:  0.014732/  0.043237, val:  81.67%, val_best:  87.50%, tr:  99.49%, tr_best:  99.49%, epoch time: 55.54 seconds, 0.93 minutes\n",
      "layer   1  Sparsity: 91.0998%\n",
      "layer   2  Sparsity: 59.3285%\n",
      "layer   3  Sparsity: 83.3007%\n",
      "total_backward_count 1262910 real_backward_count 187627  14.857%\n",
      "epoch-129 lr=['0.0039062'], tr/val_loss:  0.014805/  0.039589, val:  86.67%, val_best:  87.50%, tr:  99.08%, tr_best:  99.49%, epoch time: 55.92 seconds, 0.93 minutes\n",
      "layer   1  Sparsity: 91.0466%\n",
      "layer   2  Sparsity: 59.3824%\n",
      "layer   3  Sparsity: 83.3928%\n",
      "total_backward_count 1272700 real_backward_count 188439  14.806%\n",
      "epoch-130 lr=['0.0039062'], tr/val_loss:  0.014246/  0.040461, val:  85.00%, val_best:  87.50%, tr:  99.18%, tr_best:  99.49%, epoch time: 56.28 seconds, 0.94 minutes\n",
      "layer   1  Sparsity: 91.0432%\n",
      "layer   2  Sparsity: 59.3497%\n",
      "layer   3  Sparsity: 83.3998%\n",
      "total_backward_count 1282490 real_backward_count 189173  14.750%\n",
      "epoch-131 lr=['0.0039062'], tr/val_loss:  0.014272/  0.039158, val:  87.08%, val_best:  87.50%, tr:  99.08%, tr_best:  99.49%, epoch time: 55.50 seconds, 0.92 minutes\n",
      "layer   1  Sparsity: 91.0570%\n",
      "layer   2  Sparsity: 59.2307%\n",
      "layer   3  Sparsity: 83.4770%\n",
      "total_backward_count 1292280 real_backward_count 189935  14.698%\n",
      "epoch-132 lr=['0.0039062'], tr/val_loss:  0.014608/  0.041012, val:  84.58%, val_best:  87.50%, tr:  98.98%, tr_best:  99.49%, epoch time: 55.71 seconds, 0.93 minutes\n",
      "layer   1  Sparsity: 91.1158%\n",
      "layer   2  Sparsity: 59.2270%\n",
      "layer   3  Sparsity: 83.5247%\n",
      "total_backward_count 1302070 real_backward_count 190699  14.646%\n",
      "epoch-133 lr=['0.0039062'], tr/val_loss:  0.014600/  0.041343, val:  85.42%, val_best:  87.50%, tr:  99.28%, tr_best:  99.49%, epoch time: 55.38 seconds, 0.92 minutes\n",
      "layer   1  Sparsity: 91.0903%\n",
      "layer   2  Sparsity: 59.2772%\n",
      "layer   3  Sparsity: 83.5300%\n",
      "total_backward_count 1311860 real_backward_count 191453  14.594%\n",
      "epoch-134 lr=['0.0039062'], tr/val_loss:  0.013742/  0.039457, val:  85.00%, val_best:  87.50%, tr:  99.39%, tr_best:  99.49%, epoch time: 55.19 seconds, 0.92 minutes\n",
      "layer   1  Sparsity: 91.0469%\n",
      "layer   2  Sparsity: 59.2604%\n",
      "layer   3  Sparsity: 83.5895%\n",
      "total_backward_count 1321650 real_backward_count 192159  14.539%\n",
      "epoch-135 lr=['0.0039062'], tr/val_loss:  0.013393/  0.042760, val:  84.58%, val_best:  87.50%, tr:  99.28%, tr_best:  99.49%, epoch time: 54.66 seconds, 0.91 minutes\n",
      "layer   1  Sparsity: 91.0652%\n",
      "layer   2  Sparsity: 59.1987%\n",
      "layer   3  Sparsity: 83.5569%\n",
      "total_backward_count 1331440 real_backward_count 192866  14.486%\n",
      "epoch-136 lr=['0.0039062'], tr/val_loss:  0.013572/  0.039609, val:  85.00%, val_best:  87.50%, tr:  99.39%, tr_best:  99.49%, epoch time: 54.87 seconds, 0.91 minutes\n",
      "layer   1  Sparsity: 91.0757%\n",
      "layer   2  Sparsity: 59.2113%\n",
      "layer   3  Sparsity: 83.5485%\n",
      "total_backward_count 1341230 real_backward_count 193549  14.431%\n",
      "epoch-137 lr=['0.0039062'], tr/val_loss:  0.013508/  0.041645, val:  84.17%, val_best:  87.50%, tr:  99.08%, tr_best:  99.49%, epoch time: 55.22 seconds, 0.92 minutes\n",
      "layer   1  Sparsity: 91.0485%\n",
      "layer   2  Sparsity: 59.3069%\n",
      "layer   3  Sparsity: 83.5203%\n",
      "total_backward_count 1351020 real_backward_count 194259  14.379%\n",
      "epoch-138 lr=['0.0039062'], tr/val_loss:  0.013595/  0.040215, val:  85.42%, val_best:  87.50%, tr:  99.28%, tr_best:  99.49%, epoch time: 55.53 seconds, 0.93 minutes\n",
      "layer   1  Sparsity: 91.0710%\n",
      "layer   2  Sparsity: 59.2356%\n",
      "layer   3  Sparsity: 83.5660%\n",
      "total_backward_count 1360810 real_backward_count 194985  14.329%\n",
      "epoch-139 lr=['0.0039062'], tr/val_loss:  0.013617/  0.041119, val:  83.75%, val_best:  87.50%, tr:  99.59%, tr_best:  99.59%, epoch time: 55.76 seconds, 0.93 minutes\n",
      "layer   1  Sparsity: 91.0703%\n",
      "layer   2  Sparsity: 59.2147%\n",
      "layer   3  Sparsity: 83.5831%\n",
      "total_backward_count 1370600 real_backward_count 195733  14.281%\n",
      "epoch-140 lr=['0.0039062'], tr/val_loss:  0.013444/  0.041222, val:  84.17%, val_best:  87.50%, tr:  99.08%, tr_best:  99.59%, epoch time: 55.53 seconds, 0.93 minutes\n",
      "layer   1  Sparsity: 91.0597%\n",
      "layer   2  Sparsity: 59.2032%\n",
      "layer   3  Sparsity: 83.6763%\n",
      "total_backward_count 1380390 real_backward_count 196423  14.230%\n",
      "epoch-141 lr=['0.0039062'], tr/val_loss:  0.013400/  0.039494, val:  86.25%, val_best:  87.50%, tr:  99.69%, tr_best:  99.69%, epoch time: 55.89 seconds, 0.93 minutes\n",
      "layer   1  Sparsity: 91.0445%\n",
      "layer   2  Sparsity: 59.2271%\n",
      "layer   3  Sparsity: 83.7409%\n",
      "total_backward_count 1390180 real_backward_count 197098  14.178%\n",
      "epoch-142 lr=['0.0039062'], tr/val_loss:  0.013372/  0.040529, val:  84.58%, val_best:  87.50%, tr:  99.28%, tr_best:  99.69%, epoch time: 56.46 seconds, 0.94 minutes\n",
      "layer   1  Sparsity: 91.0555%\n",
      "layer   2  Sparsity: 59.2772%\n",
      "layer   3  Sparsity: 83.7704%\n",
      "total_backward_count 1399970 real_backward_count 197781  14.128%\n",
      "epoch-143 lr=['0.0039062'], tr/val_loss:  0.013437/  0.040165, val:  86.25%, val_best:  87.50%, tr:  98.98%, tr_best:  99.69%, epoch time: 55.54 seconds, 0.93 minutes\n",
      "layer   1  Sparsity: 91.0097%\n",
      "layer   2  Sparsity: 59.2564%\n",
      "layer   3  Sparsity: 83.7901%\n",
      "total_backward_count 1409760 real_backward_count 198488  14.080%\n",
      "epoch-144 lr=['0.0039062'], tr/val_loss:  0.012386/  0.038729, val:  87.50%, val_best:  87.50%, tr:  99.39%, tr_best:  99.69%, epoch time: 56.02 seconds, 0.93 minutes\n",
      "layer   1  Sparsity: 91.0848%\n",
      "layer   2  Sparsity: 59.2475%\n",
      "layer   3  Sparsity: 83.7886%\n",
      "total_backward_count 1419550 real_backward_count 199128  14.028%\n",
      "epoch-145 lr=['0.0039062'], tr/val_loss:  0.013013/  0.037891, val:  89.58%, val_best:  89.58%, tr:  99.28%, tr_best:  99.69%, epoch time: 55.83 seconds, 0.93 minutes\n",
      "layer   1  Sparsity: 91.0711%\n",
      "layer   2  Sparsity: 59.2219%\n",
      "layer   3  Sparsity: 83.7503%\n",
      "total_backward_count 1429340 real_backward_count 199813  13.979%\n",
      "epoch-146 lr=['0.0039062'], tr/val_loss:  0.012672/  0.039934, val:  86.25%, val_best:  89.58%, tr:  99.18%, tr_best:  99.69%, epoch time: 55.63 seconds, 0.93 minutes\n",
      "layer   1  Sparsity: 91.0809%\n",
      "layer   2  Sparsity: 59.2600%\n",
      "layer   3  Sparsity: 83.7750%\n",
      "total_backward_count 1439130 real_backward_count 200470  13.930%\n",
      "epoch-147 lr=['0.0039062'], tr/val_loss:  0.012974/  0.040007, val:  86.25%, val_best:  89.58%, tr:  98.88%, tr_best:  99.69%, epoch time: 55.53 seconds, 0.93 minutes\n",
      "layer   1  Sparsity: 91.0333%\n",
      "layer   2  Sparsity: 59.2731%\n",
      "layer   3  Sparsity: 83.8559%\n",
      "total_backward_count 1448920 real_backward_count 201155  13.883%\n",
      "epoch-148 lr=['0.0039062'], tr/val_loss:  0.012905/  0.039606, val:  86.25%, val_best:  89.58%, tr:  99.28%, tr_best:  99.69%, epoch time: 55.84 seconds, 0.93 minutes\n",
      "layer   1  Sparsity: 91.0908%\n",
      "layer   2  Sparsity: 59.2386%\n",
      "layer   3  Sparsity: 83.8723%\n",
      "total_backward_count 1458710 real_backward_count 201841  13.837%\n",
      "epoch-149 lr=['0.0039062'], tr/val_loss:  0.012063/  0.039822, val:  87.50%, val_best:  89.58%, tr:  99.39%, tr_best:  99.69%, epoch time: 55.95 seconds, 0.93 minutes\n",
      "layer   1  Sparsity: 91.0945%\n",
      "layer   2  Sparsity: 59.2100%\n",
      "layer   3  Sparsity: 83.9462%\n",
      "total_backward_count 1468500 real_backward_count 202460  13.787%\n",
      "epoch-150 lr=['0.0039062'], tr/val_loss:  0.013122/  0.039098, val:  86.67%, val_best:  89.58%, tr:  99.28%, tr_best:  99.69%, epoch time: 56.10 seconds, 0.94 minutes\n",
      "layer   1  Sparsity: 91.1015%\n",
      "layer   2  Sparsity: 59.2526%\n",
      "layer   3  Sparsity: 83.9547%\n",
      "total_backward_count 1478290 real_backward_count 203171  13.744%\n",
      "epoch-151 lr=['0.0039062'], tr/val_loss:  0.011918/  0.040530, val:  85.00%, val_best:  89.58%, tr:  99.49%, tr_best:  99.69%, epoch time: 56.79 seconds, 0.95 minutes\n",
      "layer   1  Sparsity: 91.0654%\n",
      "layer   2  Sparsity: 59.0959%\n",
      "layer   3  Sparsity: 83.9662%\n",
      "total_backward_count 1488080 real_backward_count 203770  13.693%\n",
      "epoch-152 lr=['0.0039062'], tr/val_loss:  0.013248/  0.039790, val:  86.25%, val_best:  89.58%, tr:  99.28%, tr_best:  99.69%, epoch time: 56.15 seconds, 0.94 minutes\n",
      "layer   1  Sparsity: 91.0817%\n",
      "layer   2  Sparsity: 59.1213%\n",
      "layer   3  Sparsity: 84.0045%\n",
      "total_backward_count 1497870 real_backward_count 204456  13.650%\n",
      "epoch-153 lr=['0.0039062'], tr/val_loss:  0.013128/  0.038632, val:  85.83%, val_best:  89.58%, tr:  99.28%, tr_best:  99.69%, epoch time: 56.09 seconds, 0.93 minutes\n",
      "layer   1  Sparsity: 91.0973%\n",
      "layer   2  Sparsity: 59.1603%\n",
      "layer   3  Sparsity: 83.9836%\n",
      "total_backward_count 1507660 real_backward_count 205159  13.608%\n",
      "epoch-154 lr=['0.0039062'], tr/val_loss:  0.012119/  0.040397, val:  86.25%, val_best:  89.58%, tr:  99.59%, tr_best:  99.69%, epoch time: 54.93 seconds, 0.92 minutes\n",
      "layer   1  Sparsity: 91.0976%\n",
      "layer   2  Sparsity: 59.2296%\n",
      "layer   3  Sparsity: 84.0130%\n",
      "total_backward_count 1517450 real_backward_count 205785  13.561%\n",
      "epoch-155 lr=['0.0039062'], tr/val_loss:  0.011959/  0.037233, val:  89.58%, val_best:  89.58%, tr:  99.18%, tr_best:  99.69%, epoch time: 56.09 seconds, 0.93 minutes\n",
      "layer   1  Sparsity: 91.0938%\n",
      "layer   2  Sparsity: 59.3018%\n",
      "layer   3  Sparsity: 84.0292%\n",
      "total_backward_count 1527240 real_backward_count 206389  13.514%\n",
      "epoch-156 lr=['0.0039062'], tr/val_loss:  0.012044/  0.038577, val:  87.08%, val_best:  89.58%, tr:  99.18%, tr_best:  99.69%, epoch time: 55.43 seconds, 0.92 minutes\n",
      "layer   1  Sparsity: 91.0893%\n",
      "layer   2  Sparsity: 59.2850%\n",
      "layer   3  Sparsity: 84.0338%\n",
      "total_backward_count 1537030 real_backward_count 207029  13.469%\n",
      "epoch-157 lr=['0.0039062'], tr/val_loss:  0.012247/  0.038559, val:  87.50%, val_best:  89.58%, tr:  99.18%, tr_best:  99.69%, epoch time: 55.46 seconds, 0.92 minutes\n",
      "layer   1  Sparsity: 91.0485%\n",
      "layer   2  Sparsity: 59.2589%\n",
      "layer   3  Sparsity: 84.0950%\n",
      "total_backward_count 1546820 real_backward_count 207693  13.427%\n",
      "epoch-158 lr=['0.0039062'], tr/val_loss:  0.011733/  0.038913, val:  87.08%, val_best:  89.58%, tr:  99.39%, tr_best:  99.69%, epoch time: 56.61 seconds, 0.94 minutes\n",
      "layer   1  Sparsity: 91.0913%\n",
      "layer   2  Sparsity: 59.1568%\n",
      "layer   3  Sparsity: 84.1365%\n",
      "total_backward_count 1556610 real_backward_count 208295  13.381%\n",
      "epoch-159 lr=['0.0039062'], tr/val_loss:  0.012463/  0.041038, val:  83.33%, val_best:  89.58%, tr:  99.28%, tr_best:  99.69%, epoch time: 56.09 seconds, 0.93 minutes\n",
      "layer   1  Sparsity: 91.0867%\n",
      "layer   2  Sparsity: 59.1274%\n",
      "layer   3  Sparsity: 84.2250%\n",
      "total_backward_count 1566400 real_backward_count 208942  13.339%\n",
      "epoch-160 lr=['0.0039062'], tr/val_loss:  0.012386/  0.042898, val:  82.92%, val_best:  89.58%, tr:  99.39%, tr_best:  99.69%, epoch time: 55.30 seconds, 0.92 minutes\n",
      "layer   1  Sparsity: 91.0586%\n",
      "layer   2  Sparsity: 59.1967%\n",
      "layer   3  Sparsity: 84.2175%\n",
      "total_backward_count 1576190 real_backward_count 209600  13.298%\n",
      "epoch-161 lr=['0.0039062'], tr/val_loss:  0.011478/  0.041131, val:  85.42%, val_best:  89.58%, tr:  99.39%, tr_best:  99.69%, epoch time: 55.91 seconds, 0.93 minutes\n",
      "layer   1  Sparsity: 91.1002%\n",
      "layer   2  Sparsity: 59.2804%\n",
      "layer   3  Sparsity: 84.2345%\n",
      "total_backward_count 1585980 real_backward_count 210188  13.253%\n",
      "epoch-162 lr=['0.0039062'], tr/val_loss:  0.011587/  0.041372, val:  83.75%, val_best:  89.58%, tr:  99.28%, tr_best:  99.69%, epoch time: 55.86 seconds, 0.93 minutes\n",
      "layer   1  Sparsity: 91.1100%\n",
      "layer   2  Sparsity: 59.2750%\n",
      "layer   3  Sparsity: 84.2603%\n",
      "total_backward_count 1595770 real_backward_count 210785  13.209%\n",
      "epoch-163 lr=['0.0039062'], tr/val_loss:  0.011641/  0.037938, val:  87.50%, val_best:  89.58%, tr:  99.28%, tr_best:  99.69%, epoch time: 56.09 seconds, 0.93 minutes\n",
      "layer   1  Sparsity: 91.0816%\n",
      "layer   2  Sparsity: 59.2384%\n",
      "layer   3  Sparsity: 84.2953%\n",
      "total_backward_count 1605560 real_backward_count 211387  13.166%\n",
      "epoch-164 lr=['0.0039062'], tr/val_loss:  0.011326/  0.039897, val:  85.00%, val_best:  89.58%, tr:  99.80%, tr_best:  99.80%, epoch time: 56.05 seconds, 0.93 minutes\n",
      "layer   1  Sparsity: 91.0844%\n",
      "layer   2  Sparsity: 59.2346%\n",
      "layer   3  Sparsity: 84.2997%\n",
      "total_backward_count 1615350 real_backward_count 211971  13.122%\n",
      "epoch-165 lr=['0.0039062'], tr/val_loss:  0.011365/  0.039326, val:  85.42%, val_best:  89.58%, tr:  99.39%, tr_best:  99.80%, epoch time: 56.10 seconds, 0.93 minutes\n",
      "layer   1  Sparsity: 91.1144%\n",
      "layer   2  Sparsity: 59.1667%\n",
      "layer   3  Sparsity: 84.3151%\n",
      "total_backward_count 1625140 real_backward_count 212548  13.079%\n",
      "epoch-166 lr=['0.0039062'], tr/val_loss:  0.011274/  0.038804, val:  87.50%, val_best:  89.58%, tr:  99.49%, tr_best:  99.80%, epoch time: 55.72 seconds, 0.93 minutes\n",
      "layer   1  Sparsity: 91.0873%\n",
      "layer   2  Sparsity: 59.1940%\n",
      "layer   3  Sparsity: 84.3438%\n",
      "total_backward_count 1634930 real_backward_count 213137  13.036%\n",
      "epoch-167 lr=['0.0039062'], tr/val_loss:  0.011462/  0.038900, val:  87.50%, val_best:  89.58%, tr:  99.59%, tr_best:  99.80%, epoch time: 56.06 seconds, 0.93 minutes\n",
      "layer   1  Sparsity: 91.0465%\n",
      "layer   2  Sparsity: 59.1602%\n",
      "layer   3  Sparsity: 84.4229%\n",
      "total_backward_count 1644720 real_backward_count 213715  12.994%\n",
      "epoch-168 lr=['0.0039062'], tr/val_loss:  0.010680/  0.037908, val:  87.50%, val_best:  89.58%, tr:  99.90%, tr_best:  99.90%, epoch time: 56.11 seconds, 0.94 minutes\n",
      "layer   1  Sparsity: 91.1077%\n",
      "layer   2  Sparsity: 59.1500%\n",
      "layer   3  Sparsity: 84.4135%\n",
      "total_backward_count 1654510 real_backward_count 214221  12.948%\n",
      "epoch-169 lr=['0.0039062'], tr/val_loss:  0.010793/  0.039484, val:  86.25%, val_best:  89.58%, tr:  99.49%, tr_best:  99.90%, epoch time: 55.50 seconds, 0.93 minutes\n",
      "layer   1  Sparsity: 91.0493%\n",
      "layer   2  Sparsity: 59.0315%\n",
      "layer   3  Sparsity: 84.4811%\n",
      "total_backward_count 1664300 real_backward_count 214765  12.904%\n",
      "epoch-170 lr=['0.0039062'], tr/val_loss:  0.010997/  0.040030, val:  85.42%, val_best:  89.58%, tr:  99.69%, tr_best:  99.90%, epoch time: 55.25 seconds, 0.92 minutes\n",
      "layer   1  Sparsity: 91.0465%\n",
      "layer   2  Sparsity: 59.1312%\n",
      "layer   3  Sparsity: 84.4350%\n",
      "total_backward_count 1674090 real_backward_count 215325  12.862%\n",
      "epoch-171 lr=['0.0039062'], tr/val_loss:  0.011363/  0.038928, val:  86.25%, val_best:  89.58%, tr:  99.49%, tr_best:  99.90%, epoch time: 55.06 seconds, 0.92 minutes\n",
      "layer   1  Sparsity: 91.0617%\n",
      "layer   2  Sparsity: 59.1156%\n",
      "layer   3  Sparsity: 84.4491%\n",
      "total_backward_count 1683880 real_backward_count 215901  12.822%\n",
      "epoch-172 lr=['0.0039062'], tr/val_loss:  0.011428/  0.038060, val:  87.08%, val_best:  89.58%, tr:  99.59%, tr_best:  99.90%, epoch time: 54.83 seconds, 0.91 minutes\n",
      "layer   1  Sparsity: 91.0693%\n",
      "layer   2  Sparsity: 59.1630%\n",
      "layer   3  Sparsity: 84.4772%\n",
      "total_backward_count 1693670 real_backward_count 216488  12.782%\n",
      "epoch-173 lr=['0.0039062'], tr/val_loss:  0.010711/  0.039618, val:  86.67%, val_best:  89.58%, tr:  99.39%, tr_best:  99.90%, epoch time: 55.82 seconds, 0.93 minutes\n",
      "layer   1  Sparsity: 91.0727%\n",
      "layer   2  Sparsity: 59.0781%\n",
      "layer   3  Sparsity: 84.5143%\n",
      "total_backward_count 1703460 real_backward_count 217024  12.740%\n",
      "epoch-174 lr=['0.0039062'], tr/val_loss:  0.010838/  0.039085, val:  87.08%, val_best:  89.58%, tr:  99.69%, tr_best:  99.90%, epoch time: 56.00 seconds, 0.93 minutes\n",
      "layer   1  Sparsity: 91.0723%\n",
      "layer   2  Sparsity: 59.1806%\n",
      "layer   3  Sparsity: 84.4551%\n",
      "total_backward_count 1713250 real_backward_count 217575  12.700%\n",
      "epoch-175 lr=['0.0039062'], tr/val_loss:  0.010423/  0.037847, val:  88.75%, val_best:  89.58%, tr:  99.80%, tr_best:  99.90%, epoch time: 55.71 seconds, 0.93 minutes\n",
      "layer   1  Sparsity: 91.0713%\n",
      "layer   2  Sparsity: 59.2329%\n",
      "layer   3  Sparsity: 84.4340%\n",
      "total_backward_count 1723040 real_backward_count 218106  12.658%\n",
      "epoch-176 lr=['0.0039062'], tr/val_loss:  0.010415/  0.039174, val:  87.50%, val_best:  89.58%, tr:  99.59%, tr_best:  99.90%, epoch time: 56.15 seconds, 0.94 minutes\n",
      "layer   1  Sparsity: 91.0628%\n",
      "layer   2  Sparsity: 59.1548%\n",
      "layer   3  Sparsity: 84.4798%\n",
      "total_backward_count 1732830 real_backward_count 218644  12.618%\n",
      "epoch-177 lr=['0.0039062'], tr/val_loss:  0.011043/  0.038838, val:  87.08%, val_best:  89.58%, tr:  99.39%, tr_best:  99.90%, epoch time: 55.84 seconds, 0.93 minutes\n",
      "layer   1  Sparsity: 91.0636%\n",
      "layer   2  Sparsity: 59.1746%\n",
      "layer   3  Sparsity: 84.5152%\n",
      "total_backward_count 1742620 real_backward_count 219228  12.580%\n",
      "epoch-178 lr=['0.0039062'], tr/val_loss:  0.010841/  0.041086, val:  85.00%, val_best:  89.58%, tr:  99.28%, tr_best:  99.90%, epoch time: 55.77 seconds, 0.93 minutes\n",
      "layer   1  Sparsity: 91.0732%\n",
      "layer   2  Sparsity: 59.1323%\n",
      "layer   3  Sparsity: 84.5587%\n",
      "total_backward_count 1752410 real_backward_count 219790  12.542%\n",
      "epoch-179 lr=['0.0039062'], tr/val_loss:  0.010762/  0.037351, val:  87.50%, val_best:  89.58%, tr:  99.49%, tr_best:  99.90%, epoch time: 55.51 seconds, 0.93 minutes\n",
      "layer   1  Sparsity: 91.1081%\n",
      "layer   2  Sparsity: 59.1947%\n",
      "layer   3  Sparsity: 84.5347%\n",
      "total_backward_count 1762200 real_backward_count 220350  12.504%\n",
      "epoch-180 lr=['0.0039062'], tr/val_loss:  0.011292/  0.038370, val:  89.17%, val_best:  89.58%, tr:  99.49%, tr_best:  99.90%, epoch time: 55.54 seconds, 0.93 minutes\n",
      "layer   1  Sparsity: 91.0566%\n",
      "layer   2  Sparsity: 59.2016%\n",
      "layer   3  Sparsity: 84.5866%\n",
      "total_backward_count 1771990 real_backward_count 220956  12.469%\n",
      "epoch-181 lr=['0.0039062'], tr/val_loss:  0.010340/  0.038067, val:  86.25%, val_best:  89.58%, tr:  99.69%, tr_best:  99.90%, epoch time: 55.71 seconds, 0.93 minutes\n",
      "layer   1  Sparsity: 91.0459%\n",
      "layer   2  Sparsity: 59.0722%\n",
      "layer   3  Sparsity: 84.6267%\n",
      "total_backward_count 1781780 real_backward_count 221493  12.431%\n",
      "epoch-182 lr=['0.0039062'], tr/val_loss:  0.011040/  0.038087, val:  87.92%, val_best:  89.58%, tr:  99.69%, tr_best:  99.90%, epoch time: 55.90 seconds, 0.93 minutes\n",
      "layer   1  Sparsity: 91.0699%\n",
      "layer   2  Sparsity: 59.0748%\n",
      "layer   3  Sparsity: 84.6920%\n",
      "total_backward_count 1791570 real_backward_count 222074  12.395%\n",
      "epoch-183 lr=['0.0039062'], tr/val_loss:  0.010068/  0.038571, val:  86.67%, val_best:  89.58%, tr:  99.80%, tr_best:  99.90%, epoch time: 54.85 seconds, 0.91 minutes\n",
      "layer   1  Sparsity: 91.0636%\n",
      "layer   2  Sparsity: 59.1185%\n",
      "layer   3  Sparsity: 84.6492%\n",
      "total_backward_count 1801360 real_backward_count 222579  12.356%\n",
      "epoch-184 lr=['0.0039062'], tr/val_loss:  0.010991/  0.038297, val:  86.67%, val_best:  89.58%, tr:  99.80%, tr_best:  99.90%, epoch time: 55.33 seconds, 0.92 minutes\n",
      "layer   1  Sparsity: 91.0818%\n",
      "layer   2  Sparsity: 59.0939%\n",
      "layer   3  Sparsity: 84.6654%\n",
      "total_backward_count 1811150 real_backward_count 223155  12.321%\n",
      "epoch-185 lr=['0.0039062'], tr/val_loss:  0.010638/  0.039732, val:  86.67%, val_best:  89.58%, tr:  99.39%, tr_best:  99.90%, epoch time: 56.72 seconds, 0.95 minutes\n",
      "layer   1  Sparsity: 91.0657%\n",
      "layer   2  Sparsity: 59.1536%\n",
      "layer   3  Sparsity: 84.6599%\n",
      "total_backward_count 1820940 real_backward_count 223694  12.285%\n",
      "epoch-186 lr=['0.0039062'], tr/val_loss:  0.010450/  0.039084, val:  87.50%, val_best:  89.58%, tr:  99.69%, tr_best:  99.90%, epoch time: 55.93 seconds, 0.93 minutes\n",
      "layer   1  Sparsity: 91.0619%\n",
      "layer   2  Sparsity: 59.1737%\n",
      "layer   3  Sparsity: 84.6657%\n",
      "total_backward_count 1830730 real_backward_count 224205  12.247%\n",
      "epoch-187 lr=['0.0039062'], tr/val_loss:  0.010966/  0.036683, val:  88.33%, val_best:  89.58%, tr:  99.28%, tr_best:  99.90%, epoch time: 55.87 seconds, 0.93 minutes\n",
      "layer   1  Sparsity: 91.0526%\n",
      "layer   2  Sparsity: 59.1815%\n",
      "layer   3  Sparsity: 84.7251%\n",
      "total_backward_count 1840520 real_backward_count 224782  12.213%\n",
      "epoch-188 lr=['0.0039062'], tr/val_loss:  0.009733/  0.038035, val:  89.17%, val_best:  89.58%, tr:  99.69%, tr_best:  99.90%, epoch time: 56.00 seconds, 0.93 minutes\n",
      "layer   1  Sparsity: 91.0816%\n",
      "layer   2  Sparsity: 59.1265%\n",
      "layer   3  Sparsity: 84.7620%\n",
      "total_backward_count 1850310 real_backward_count 225268  12.175%\n",
      "epoch-189 lr=['0.0039062'], tr/val_loss:  0.010401/  0.038713, val:  85.83%, val_best:  89.58%, tr:  99.08%, tr_best:  99.90%, epoch time: 55.70 seconds, 0.93 minutes\n",
      "layer   1  Sparsity: 91.0399%\n",
      "layer   2  Sparsity: 59.1322%\n",
      "layer   3  Sparsity: 84.7851%\n",
      "total_backward_count 1860100 real_backward_count 225813  12.140%\n",
      "epoch-190 lr=['0.0039062'], tr/val_loss:  0.010156/  0.038966, val:  85.42%, val_best:  89.58%, tr:  99.69%, tr_best:  99.90%, epoch time: 56.38 seconds, 0.94 minutes\n",
      "layer   1  Sparsity: 91.0966%\n",
      "layer   2  Sparsity: 59.1917%\n",
      "layer   3  Sparsity: 84.7786%\n",
      "total_backward_count 1869890 real_backward_count 226323  12.104%\n",
      "epoch-191 lr=['0.0039062'], tr/val_loss:  0.009708/  0.039202, val:  86.67%, val_best:  89.58%, tr:  99.59%, tr_best:  99.90%, epoch time: 55.54 seconds, 0.93 minutes\n",
      "layer   1  Sparsity: 91.0907%\n",
      "layer   2  Sparsity: 59.1240%\n",
      "layer   3  Sparsity: 84.8203%\n",
      "total_backward_count 1879680 real_backward_count 226816  12.067%\n",
      "epoch-192 lr=['0.0039062'], tr/val_loss:  0.010156/  0.039383, val:  86.67%, val_best:  89.58%, tr:  99.59%, tr_best:  99.90%, epoch time: 56.04 seconds, 0.93 minutes\n",
      "layer   1  Sparsity: 91.0556%\n",
      "layer   2  Sparsity: 59.1450%\n",
      "layer   3  Sparsity: 84.9040%\n",
      "total_backward_count 1889470 real_backward_count 227341  12.032%\n",
      "epoch-193 lr=['0.0039062'], tr/val_loss:  0.010165/  0.036601, val:  88.33%, val_best:  89.58%, tr:  99.59%, tr_best:  99.90%, epoch time: 55.82 seconds, 0.93 minutes\n",
      "layer   1  Sparsity: 91.1157%\n",
      "layer   2  Sparsity: 59.0821%\n",
      "layer   3  Sparsity: 85.0042%\n",
      "total_backward_count 1899260 real_backward_count 227869  11.998%\n",
      "epoch-194 lr=['0.0039062'], tr/val_loss:  0.010572/  0.037452, val:  87.92%, val_best:  89.58%, tr:  99.59%, tr_best:  99.90%, epoch time: 55.51 seconds, 0.93 minutes\n",
      "layer   1  Sparsity: 91.0676%\n",
      "layer   2  Sparsity: 59.1195%\n",
      "layer   3  Sparsity: 85.0187%\n",
      "total_backward_count 1909050 real_backward_count 228409  11.965%\n",
      "epoch-195 lr=['0.0039062'], tr/val_loss:  0.010034/  0.039038, val:  87.92%, val_best:  89.58%, tr:  99.49%, tr_best:  99.90%, epoch time: 55.54 seconds, 0.93 minutes\n",
      "layer   1  Sparsity: 91.0777%\n",
      "layer   2  Sparsity: 59.1701%\n",
      "layer   3  Sparsity: 84.9849%\n",
      "total_backward_count 1918840 real_backward_count 228928  11.931%\n",
      "epoch-196 lr=['0.0039062'], tr/val_loss:  0.009994/  0.036887, val:  87.92%, val_best:  89.58%, tr:  99.49%, tr_best:  99.90%, epoch time: 56.24 seconds, 0.94 minutes\n",
      "layer   1  Sparsity: 91.0456%\n",
      "layer   2  Sparsity: 59.1208%\n",
      "layer   3  Sparsity: 84.9818%\n",
      "total_backward_count 1928630 real_backward_count 229429  11.896%\n",
      "epoch-197 lr=['0.0039062'], tr/val_loss:  0.009889/  0.036999, val:  88.33%, val_best:  89.58%, tr:  99.69%, tr_best:  99.90%, epoch time: 55.86 seconds, 0.93 minutes\n",
      "layer   1  Sparsity: 91.0885%\n",
      "layer   2  Sparsity: 59.1278%\n",
      "layer   3  Sparsity: 85.0222%\n",
      "total_backward_count 1938420 real_backward_count 229929  11.862%\n",
      "epoch-198 lr=['0.0039062'], tr/val_loss:  0.009560/  0.036946, val:  89.58%, val_best:  89.58%, tr:  99.80%, tr_best:  99.90%, epoch time: 55.70 seconds, 0.93 minutes\n",
      "layer   1  Sparsity: 91.0990%\n",
      "layer   2  Sparsity: 59.0869%\n",
      "layer   3  Sparsity: 85.0317%\n",
      "total_backward_count 1948210 real_backward_count 230402  11.826%\n",
      "epoch-199 lr=['0.0039062'], tr/val_loss:  0.009807/  0.038021, val:  86.67%, val_best:  89.58%, tr:  99.59%, tr_best:  99.90%, epoch time: 55.97 seconds, 0.93 minutes\n",
      "layer   1  Sparsity: 91.1276%\n",
      "layer   2  Sparsity: 59.0049%\n",
      "layer   3  Sparsity: 85.1233%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c238bd55a1454bd1bdcd3409aceac0eb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.006 MB of 0.006 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà</td></tr><tr><td>iter_acc</td><td>‚ñà‚ñà‚ñà‚ñà‚ñà‚ñÅ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà</td></tr><tr><td>summary_val_acc</td><td>‚ñÅ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÖ‚ñÜ‚ñá‚ñÜ‚ñÜ‚ñá‚ñÜ‚ñá‚ñá‚ñà‚ñá‚ñá‚ñá‚ñá‚ñà‚ñá‚ñà‚ñà‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà</td></tr><tr><td>tr_acc</td><td>‚ñÅ‚ñÇ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà</td></tr><tr><td>tr_epoch_loss</td><td>‚ñà‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ</td></tr><tr><td>val_acc_best</td><td>‚ñÅ‚ñÉ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà</td></tr><tr><td>val_acc_now</td><td>‚ñÅ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÖ‚ñÜ‚ñá‚ñÜ‚ñÜ‚ñá‚ñÜ‚ñá‚ñá‚ñà‚ñá‚ñá‚ñá‚ñá‚ñà‚ñá‚ñà‚ñà‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà</td></tr><tr><td>val_loss</td><td>‚ñà‚ñá‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>199</td></tr><tr><td>iter_acc</td><td>1.0</td></tr><tr><td>tr_acc</td><td>0.99591</td></tr><tr><td>tr_epoch_loss</td><td>0.00981</td></tr><tr><td>val_acc_best</td><td>0.89583</td></tr><tr><td>val_acc_now</td><td>0.86667</td></tr><tr><td>val_loss</td><td>0.03802</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">worthy-sweep-2</strong> at: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/xzlunj1t' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/xzlunj1t</a><br/> View project at: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>/data2/bh_wandb/wandb/run-20251119_215846-xzlunj1t/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require(\"core\")`! See https://wandb.me/wandb-core for more information."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Sweep Agent: Waiting for job.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Job received.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 4bf1kkpb with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBATCH: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBN_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBPTT_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tDFA_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tIMAGE_SIZE: 14\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tOTTT_input_trace_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tTIME: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tUDA_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \talpha_uda: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbias: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcfg: [200, 200]\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tchaching_on: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tconvTrue_fcFalse: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdata_path: /data2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tddp_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdenoise_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdvs_clipping: 14\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdvs_duration: 25000\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepoch_num: 200\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \texclude_class: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \textra_train_dataset: -1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tinitial_pooling: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlast_lif: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.00390625\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_sg_width: 4\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_decay: 0.5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_init: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_reset: 10000\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_threshold: 0.015625\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmerge_polarities: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmy_seed: 428\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnet_print: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_workers: 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer_what: SGD\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tpin_memory: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tpre_trained: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tpre_trained_path: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \trate_coding: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tscheduler_name: no\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsingle_step: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsurrogate: hard_sigmoid\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_conv_kernel_size: 3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_conv_padding: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_conv_stride: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_trace_const1: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_trace_const2: 0.5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \ttdBN_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \ttemporal_filter: 5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \ttemporal_filter_accumulation: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \ttrace_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \twhich_data: DVS_GESTURE_TONIC\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.23.0 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.17.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/data2/bh_wandb/wandb/run-20251120_010533-4bf1kkpb</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/4bf1kkpb' target=\"_blank\">northern-sweep-3</a></strong> to <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/m41wfhay' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/m41wfhay</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/m41wfhay' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/m41wfhay</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/4bf1kkpb' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/4bf1kkpb</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'single_step' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'my_seed' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'TIME' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BATCH' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'IMAGE_SIZE' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'which_data' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'data_path' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'rate_coding' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_init' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_decay' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_threshold' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_reset' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_sg_width' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_conv_kernel_size' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_conv_stride' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_conv_padding' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_trace_const1' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_trace_const2' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'pre_trained' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'convTrue_fcFalse' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'cfg' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'net_print' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'pre_trained_path' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'learning_rate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'epoch_num' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'tdBN_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BN_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'surrogate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BPTT_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'optimizer_what' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'scheduler_name' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'ddp_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'dvs_clipping' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'dvs_duration' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'DFA_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'trace_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'OTTT_input_trace_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'exclude_class' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'merge_polarities' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'denoise_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'extra_train_dataset' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'num_workers' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'chaching_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'pin_memory' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'UDA_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'alpha_uda' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'bias' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'last_lif' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'temporal_filter' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'initial_pooling' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'temporal_filter_accumulation' was locked by 'sweep' (ignored update).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "param {'devices': '3', 'single_step': True, 'unique_name': '20251120_010542_673', 'my_seed': 428, 'TIME': 10, 'BATCH': 1, 'IMAGE_SIZE': 14, 'which_data': 'DVS_GESTURE_TONIC', 'data_path': '/data2', 'rate_coding': False, 'lif_layer_v_init': 0, 'lif_layer_v_decay': 0.5, 'lif_layer_v_threshold': 0.015625, 'lif_layer_v_reset': 10000, 'lif_layer_sg_width': 4, 'synapse_conv_kernel_size': 3, 'synapse_conv_stride': 1, 'synapse_conv_padding': 1, 'synapse_trace_const1': 1, 'synapse_trace_const2': 0.5, 'pre_trained': False, 'convTrue_fcFalse': False, 'cfg': [200, 200], 'net_print': True, 'pre_trained_path': '', 'learning_rate': 0.00390625, 'epoch_num': 200, 'tdBN_on': False, 'BN_on': False, 'surrogate': 'hard_sigmoid', 'BPTT_on': False, 'optimizer_what': 'SGD', 'scheduler_name': 'no', 'ddp_on': False, 'dvs_clipping': 14, 'dvs_duration': 25000, 'DFA_on': False, 'trace_on': False, 'OTTT_input_trace_on': False, 'exclude_class': True, 'merge_polarities': True, 'denoise_on': False, 'extra_train_dataset': -1, 'num_workers': 2, 'chaching_on': True, 'pin_memory': True, 'UDA_on': False, 'alpha_uda': 1, 'bias': False, 'last_lif': False, 'temporal_filter': 5, 'initial_pooling': 1, 'temporal_filter_accumulation': False, 'quantize_bit_list': [], 'scale_exp': [[999, 998], [999, 999], [999, 999]]} \n",
      "\n",
      "Ïù¥ Îç∞Ïù¥ÌÑ∞ÏÖãÏùò Îç∞Ïù¥ÌÑ∞ Í∞úÏàòÎäî 979 ÏûÖÎãàÎã§. (test setÏùÄ ÏïàÎ∞îÎÄåÍ≤å Ìï¥ÎÜ®Îã§ ÏïåÏ†ú)\n",
      "Ïù¥ Îç∞Ïù¥ÌÑ∞ÏÖãÏùò Îç∞Ïù¥ÌÑ∞ Í∞úÏàòÎäî 240 ÏûÖÎãàÎã§. (test setÏùÄ ÏïàÎ∞îÎÄåÍ≤å Ìï¥ÎÜ®Îã§ ÏïåÏ†ú)\n",
      "dataset_hash = 0e8a8f2d81b4fe037308b5d792c4a037\n",
      "cache path exists\n",
      "\n",
      "len(train_loader): 979 BATCH: 1 train_data_count: 979\n",
      "len(test_loader): 240 BATCH: 1\n",
      "\n",
      "device ==> cuda\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " layer_count 1\n",
      "weight bias bit 0\n",
      "weight exp, bias exp None None\n",
      "bit_for_output 0 exp_for_output None \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "LIF 1 sg_bit 0\n",
      "\n",
      "\n",
      "++++++++++++++++++++++++\n",
      "\n",
      " lif layer 1 v_bit: 0, v_exp: None\n",
      "\n",
      "++++++++++++++++++++++++++++++++++++++++++++++\n",
      "\n",
      "\n",
      "\n",
      " layer_count 2\n",
      "weight bias bit 0\n",
      "weight exp, bias exp None None\n",
      "bit_for_output 0 exp_for_output None \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "LIF 2 sg_bit 0\n",
      "\n",
      "\n",
      "++++++++++++++++++++++++\n",
      "\n",
      " lif layer 2 v_bit: 0, v_exp: None\n",
      "\n",
      "++++++++++++++++++++++++++++++++++++++++++++++\n",
      "\n",
      "\n",
      "\n",
      " layer_count 3\n",
      "weight bias bit 0\n",
      "weight exp, bias exp None None\n",
      "bit_for_output 0 exp_for_output None \n",
      "\n",
      "\n",
      "\n",
      "DataParallel(\n",
      "  (module): REBORN_MY_SNN_FC(\n",
      "    (layers): REBORN_MY_Sequential(\n",
      "      (0): DimChanger_for_FC()\n",
      "      (1): SYNAPSE_FC(in_features=980, out_features=200, TIME=10, bias=False, sstep=True, time_different_weight=False, layer_count=1, quantize_bit_list=[], scale_exp=[[999, 998], [999, 999], [999, 999]], ANPI_MODE=False)\n",
      "      (2): LIF_layer(v_init=0, v_decay=0.5, v_threshold=0.015625, v_reset=10000, sg_width=4, surrogate=hard_sigmoid, BPTT_on=False, trace_const1=1, trace_const2=0.5, TIME=10, sstep=True, trace_on=False, layer_count=1, scale_exp=[[999, 998], [999, 999], [999, 999]], ANPI_MODE=False)\n",
      "      (3): SYNAPSE_FC(in_features=200, out_features=200, TIME=10, bias=False, sstep=True, time_different_weight=False, layer_count=2, quantize_bit_list=[], scale_exp=[[999, 998], [999, 999], [999, 999]], ANPI_MODE=False)\n",
      "      (4): LIF_layer(v_init=0, v_decay=0.5, v_threshold=0.015625, v_reset=10000, sg_width=4, surrogate=hard_sigmoid, BPTT_on=False, trace_const1=1, trace_const2=0.5, TIME=10, sstep=True, trace_on=False, layer_count=2, scale_exp=[[999, 998], [999, 999], [999, 999]], ANPI_MODE=False)\n",
      "      (5): SYNAPSE_FC(in_features=200, out_features=10, TIME=10, bias=False, sstep=True, time_different_weight=False, layer_count=3, quantize_bit_list=[], scale_exp=[[999, 998], [999, 999], [999, 999]], ANPI_MODE=False)\n",
      "    )\n",
      "  )\n",
      ")\n",
      "\n",
      "========================================================\n",
      "Trainable parameters: 238,000\n",
      "========================================================\n",
      "\n",
      "MySGD (\n",
      "Parameter Group 0\n",
      "    lr: 0.00390625\n",
      "    momentum: 0.0\n",
      ")\n",
      "total_backward_count 0 real_backward_count 0   0.000%\n",
      "epoch-0   lr=['0.0039062'], tr/val_loss:  0.066891/  0.077109, val:  50.83%, val_best:  50.83%, tr:  80.39%, tr_best:  80.39%, epoch time: 55.58 seconds, 0.93 minutes\n",
      "layer   1  Sparsity: 91.1131%\n",
      "layer   2  Sparsity: 59.2623%\n",
      "layer   3  Sparsity: 57.6990%\n",
      "total_backward_count 9790 real_backward_count 3352  34.239%\n",
      "epoch-1   lr=['0.0039062'], tr/val_loss:  0.052383/  0.071956, val:  58.33%, val_best:  58.33%, tr:  85.19%, tr_best:  85.19%, epoch time: 56.84 seconds, 0.95 minutes\n",
      "layer   1  Sparsity: 91.0838%\n",
      "layer   2  Sparsity: 59.1934%\n",
      "layer   3  Sparsity: 59.2185%\n",
      "total_backward_count 19580 real_backward_count 5870  29.980%\n",
      "epoch-2   lr=['0.0039062'], tr/val_loss:  0.048706/  0.072496, val:  51.25%, val_best:  58.33%, tr:  86.11%, tr_best:  86.11%, epoch time: 56.00 seconds, 0.93 minutes\n",
      "layer   1  Sparsity: 91.0904%\n",
      "layer   2  Sparsity: 59.2375%\n",
      "layer   3  Sparsity: 60.0568%\n",
      "total_backward_count 29370 real_backward_count 8199  27.916%\n",
      "epoch-3   lr=['0.0039062'], tr/val_loss:  0.046883/  0.072250, val:  54.58%, val_best:  58.33%, tr:  84.27%, tr_best:  86.11%, epoch time: 55.70 seconds, 0.93 minutes\n",
      "layer   1  Sparsity: 91.0886%\n",
      "layer   2  Sparsity: 59.1326%\n",
      "layer   3  Sparsity: 60.8726%\n",
      "total_backward_count 39160 real_backward_count 10568  26.987%\n",
      "epoch-4   lr=['0.0039062'], tr/val_loss:  0.045617/  0.070482, val:  56.25%, val_best:  58.33%, tr:  84.37%, tr_best:  86.11%, epoch time: 55.89 seconds, 0.93 minutes\n",
      "layer   1  Sparsity: 91.0821%\n",
      "layer   2  Sparsity: 58.9320%\n",
      "layer   3  Sparsity: 61.6672%\n",
      "total_backward_count 48950 real_backward_count 12886  26.325%\n",
      "epoch-5   lr=['0.0039062'], tr/val_loss:  0.044369/  0.064801, val:  56.25%, val_best:  58.33%, tr:  86.62%, tr_best:  86.62%, epoch time: 55.60 seconds, 0.93 minutes\n",
      "layer   1  Sparsity: 91.0383%\n",
      "layer   2  Sparsity: 58.8576%\n",
      "layer   3  Sparsity: 62.3556%\n",
      "total_backward_count 58740 real_backward_count 15085  25.681%\n",
      "epoch-6   lr=['0.0039062'], tr/val_loss:  0.043589/  0.064484, val:  57.50%, val_best:  58.33%, tr:  84.78%, tr_best:  86.62%, epoch time: 55.72 seconds, 0.93 minutes\n",
      "layer   1  Sparsity: 91.0965%\n",
      "layer   2  Sparsity: 58.8483%\n",
      "layer   3  Sparsity: 63.2071%\n",
      "total_backward_count 68530 real_backward_count 17329  25.287%\n",
      "epoch-7   lr=['0.0039062'], tr/val_loss:  0.042961/  0.075823, val:  53.75%, val_best:  58.33%, tr:  84.88%, tr_best:  86.62%, epoch time: 55.25 seconds, 0.92 minutes\n",
      "layer   1  Sparsity: 91.0939%\n",
      "layer   2  Sparsity: 58.9568%\n",
      "layer   3  Sparsity: 63.9075%\n",
      "total_backward_count 78320 real_backward_count 19548  24.959%\n",
      "epoch-8   lr=['0.0039062'], tr/val_loss:  0.042358/  0.058266, val:  63.33%, val_best:  63.33%, tr:  84.47%, tr_best:  86.62%, epoch time: 55.74 seconds, 0.93 minutes\n",
      "layer   1  Sparsity: 91.0813%\n",
      "layer   2  Sparsity: 58.9266%\n",
      "layer   3  Sparsity: 64.6931%\n",
      "total_backward_count 88110 real_backward_count 21753  24.688%\n",
      "epoch-9   lr=['0.0039062'], tr/val_loss:  0.042258/  0.071562, val:  55.83%, val_best:  63.33%, tr:  85.19%, tr_best:  86.62%, epoch time: 56.18 seconds, 0.94 minutes\n",
      "layer   1  Sparsity: 91.0573%\n",
      "layer   2  Sparsity: 58.9220%\n",
      "layer   3  Sparsity: 65.3036%\n",
      "total_backward_count 97900 real_backward_count 23967  24.481%\n",
      "epoch-10  lr=['0.0039062'], tr/val_loss:  0.041378/  0.062569, val:  59.17%, val_best:  63.33%, tr:  85.60%, tr_best:  86.62%, epoch time: 56.17 seconds, 0.94 minutes\n",
      "layer   1  Sparsity: 91.0961%\n",
      "layer   2  Sparsity: 58.9555%\n",
      "layer   3  Sparsity: 65.9854%\n",
      "total_backward_count 107690 real_backward_count 26132  24.266%\n",
      "epoch-11  lr=['0.0039062'], tr/val_loss:  0.040617/  0.060962, val:  68.75%, val_best:  68.75%, tr:  85.60%, tr_best:  86.62%, epoch time: 55.85 seconds, 0.93 minutes\n",
      "layer   1  Sparsity: 91.0307%\n",
      "layer   2  Sparsity: 59.0818%\n",
      "layer   3  Sparsity: 66.7770%\n",
      "total_backward_count 117480 real_backward_count 28303  24.092%\n",
      "epoch-12  lr=['0.0039062'], tr/val_loss:  0.039804/  0.066559, val:  61.67%, val_best:  68.75%, tr:  85.29%, tr_best:  86.62%, epoch time: 56.83 seconds, 0.95 minutes\n",
      "layer   1  Sparsity: 91.0863%\n",
      "layer   2  Sparsity: 59.1261%\n",
      "layer   3  Sparsity: 67.5254%\n",
      "total_backward_count 127270 real_backward_count 30446  23.922%\n",
      "epoch-13  lr=['0.0039062'], tr/val_loss:  0.040359/  0.060014, val:  66.67%, val_best:  68.75%, tr:  84.17%, tr_best:  86.62%, epoch time: 55.58 seconds, 0.93 minutes\n",
      "layer   1  Sparsity: 91.0865%\n",
      "layer   2  Sparsity: 59.2606%\n",
      "layer   3  Sparsity: 68.1939%\n",
      "total_backward_count 137060 real_backward_count 32652  23.823%\n",
      "epoch-14  lr=['0.0039062'], tr/val_loss:  0.039072/  0.056655, val:  70.42%, val_best:  70.42%, tr:  85.80%, tr_best:  86.62%, epoch time: 55.76 seconds, 0.93 minutes\n",
      "layer   1  Sparsity: 91.0610%\n",
      "layer   2  Sparsity: 59.3096%\n",
      "layer   3  Sparsity: 68.7959%\n",
      "total_backward_count 146850 real_backward_count 34731  23.651%\n",
      "epoch-15  lr=['0.0039062'], tr/val_loss:  0.038862/  0.057423, val:  62.50%, val_best:  70.42%, tr:  85.39%, tr_best:  86.62%, epoch time: 55.83 seconds, 0.93 minutes\n",
      "layer   1  Sparsity: 91.0905%\n",
      "layer   2  Sparsity: 59.4239%\n",
      "layer   3  Sparsity: 69.3127%\n",
      "total_backward_count 156640 real_backward_count 36846  23.523%\n",
      "epoch-16  lr=['0.0039062'], tr/val_loss:  0.038050/  0.061998, val:  62.92%, val_best:  70.42%, tr:  85.90%, tr_best:  86.62%, epoch time: 55.27 seconds, 0.92 minutes\n",
      "layer   1  Sparsity: 91.0676%\n",
      "layer   2  Sparsity: 59.3964%\n",
      "layer   3  Sparsity: 69.8872%\n",
      "total_backward_count 166430 real_backward_count 38914  23.382%\n",
      "epoch-17  lr=['0.0039062'], tr/val_loss:  0.038014/  0.057759, val:  66.25%, val_best:  70.42%, tr:  84.37%, tr_best:  86.62%, epoch time: 55.57 seconds, 0.93 minutes\n",
      "layer   1  Sparsity: 91.0577%\n",
      "layer   2  Sparsity: 59.4856%\n",
      "layer   3  Sparsity: 70.4391%\n",
      "total_backward_count 176220 real_backward_count 41021  23.278%\n",
      "epoch-18  lr=['0.0039062'], tr/val_loss:  0.038291/  0.055353, val:  70.00%, val_best:  70.42%, tr:  84.17%, tr_best:  86.62%, epoch time: 56.51 seconds, 0.94 minutes\n",
      "layer   1  Sparsity: 91.0879%\n",
      "layer   2  Sparsity: 59.6286%\n",
      "layer   3  Sparsity: 71.2098%\n",
      "total_backward_count 186010 real_backward_count 43204  23.227%\n",
      "epoch-19  lr=['0.0039062'], tr/val_loss:  0.037358/  0.061061, val:  61.67%, val_best:  70.42%, tr:  87.33%, tr_best:  87.33%, epoch time: 55.94 seconds, 0.93 minutes\n",
      "layer   1  Sparsity: 91.1333%\n",
      "layer   2  Sparsity: 59.6961%\n",
      "layer   3  Sparsity: 71.6769%\n",
      "total_backward_count 195800 real_backward_count 45261  23.116%\n",
      "epoch-20  lr=['0.0039062'], tr/val_loss:  0.037058/  0.055754, val:  67.50%, val_best:  70.42%, tr:  86.52%, tr_best:  87.33%, epoch time: 55.28 seconds, 0.92 minutes\n",
      "layer   1  Sparsity: 91.1023%\n",
      "layer   2  Sparsity: 59.7845%\n",
      "layer   3  Sparsity: 72.2350%\n",
      "total_backward_count 205590 real_backward_count 47332  23.023%\n",
      "epoch-21  lr=['0.0039062'], tr/val_loss:  0.036871/  0.061406, val:  65.42%, val_best:  70.42%, tr:  85.90%, tr_best:  87.33%, epoch time: 55.19 seconds, 0.92 minutes\n",
      "layer   1  Sparsity: 91.0807%\n",
      "layer   2  Sparsity: 59.7337%\n",
      "layer   3  Sparsity: 72.7075%\n",
      "total_backward_count 215380 real_backward_count 49386  22.930%\n",
      "epoch-22  lr=['0.0039062'], tr/val_loss:  0.036560/  0.060526, val:  63.33%, val_best:  70.42%, tr:  87.54%, tr_best:  87.54%, epoch time: 55.83 seconds, 0.93 minutes\n",
      "layer   1  Sparsity: 91.0724%\n",
      "layer   2  Sparsity: 59.7740%\n",
      "layer   3  Sparsity: 73.0854%\n",
      "total_backward_count 225170 real_backward_count 51412  22.833%\n",
      "epoch-23  lr=['0.0039062'], tr/val_loss:  0.036870/  0.054593, val:  68.75%, val_best:  70.42%, tr:  85.09%, tr_best:  87.54%, epoch time: 55.13 seconds, 0.92 minutes\n",
      "layer   1  Sparsity: 91.0841%\n",
      "layer   2  Sparsity: 59.9026%\n",
      "layer   3  Sparsity: 73.5152%\n",
      "total_backward_count 234960 real_backward_count 53464  22.755%\n",
      "epoch-24  lr=['0.0039062'], tr/val_loss:  0.036570/  0.054932, val:  70.00%, val_best:  70.42%, tr:  86.52%, tr_best:  87.54%, epoch time: 55.48 seconds, 0.92 minutes\n",
      "layer   1  Sparsity: 91.0714%\n",
      "layer   2  Sparsity: 59.9093%\n",
      "layer   3  Sparsity: 73.9667%\n",
      "total_backward_count 244750 real_backward_count 55587  22.712%\n",
      "epoch-25  lr=['0.0039062'], tr/val_loss:  0.035428/  0.060398, val:  62.08%, val_best:  70.42%, tr:  88.05%, tr_best:  88.05%, epoch time: 55.23 seconds, 0.92 minutes\n",
      "layer   1  Sparsity: 91.0662%\n",
      "layer   2  Sparsity: 59.8992%\n",
      "layer   3  Sparsity: 74.4763%\n",
      "total_backward_count 254540 real_backward_count 57626  22.639%\n",
      "epoch-26  lr=['0.0039062'], tr/val_loss:  0.035518/  0.055536, val:  69.17%, val_best:  70.42%, tr:  86.52%, tr_best:  88.05%, epoch time: 55.00 seconds, 0.92 minutes\n",
      "layer   1  Sparsity: 91.0805%\n",
      "layer   2  Sparsity: 60.0388%\n",
      "layer   3  Sparsity: 74.7591%\n",
      "total_backward_count 264330 real_backward_count 59686  22.580%\n",
      "epoch-27  lr=['0.0039062'], tr/val_loss:  0.035138/  0.054507, val:  67.08%, val_best:  70.42%, tr:  87.44%, tr_best:  88.05%, epoch time: 56.28 seconds, 0.94 minutes\n",
      "layer   1  Sparsity: 91.0443%\n",
      "layer   2  Sparsity: 60.0745%\n",
      "layer   3  Sparsity: 75.0397%\n",
      "total_backward_count 274120 real_backward_count 61662  22.495%\n",
      "epoch-28  lr=['0.0039062'], tr/val_loss:  0.034626/  0.058648, val:  65.42%, val_best:  70.42%, tr:  87.74%, tr_best:  88.05%, epoch time: 55.51 seconds, 0.93 minutes\n",
      "layer   1  Sparsity: 91.0895%\n",
      "layer   2  Sparsity: 60.0890%\n",
      "layer   3  Sparsity: 75.5986%\n",
      "total_backward_count 283910 real_backward_count 63632  22.413%\n",
      "epoch-29  lr=['0.0039062'], tr/val_loss:  0.035185/  0.052815, val:  69.17%, val_best:  70.42%, tr:  85.60%, tr_best:  88.05%, epoch time: 55.46 seconds, 0.92 minutes\n",
      "layer   1  Sparsity: 91.0848%\n",
      "layer   2  Sparsity: 60.1036%\n",
      "layer   3  Sparsity: 75.9653%\n",
      "total_backward_count 293700 real_backward_count 65709  22.373%\n",
      "epoch-30  lr=['0.0039062'], tr/val_loss:  0.034989/  0.052885, val:  74.58%, val_best:  74.58%, tr:  86.72%, tr_best:  88.05%, epoch time: 55.90 seconds, 0.93 minutes\n",
      "layer   1  Sparsity: 91.0107%\n",
      "layer   2  Sparsity: 60.1369%\n",
      "layer   3  Sparsity: 76.2220%\n",
      "total_backward_count 303490 real_backward_count 67713  22.311%\n",
      "epoch-31  lr=['0.0039062'], tr/val_loss:  0.034441/  0.055236, val:  71.67%, val_best:  74.58%, tr:  87.13%, tr_best:  88.05%, epoch time: 56.07 seconds, 0.93 minutes\n",
      "layer   1  Sparsity: 91.0908%\n",
      "layer   2  Sparsity: 60.2457%\n",
      "layer   3  Sparsity: 76.5222%\n",
      "total_backward_count 313280 real_backward_count 69773  22.272%\n",
      "epoch-32  lr=['0.0039062'], tr/val_loss:  0.033622/  0.055147, val:  69.17%, val_best:  74.58%, tr:  86.72%, tr_best:  88.05%, epoch time: 55.83 seconds, 0.93 minutes\n",
      "layer   1  Sparsity: 91.0676%\n",
      "layer   2  Sparsity: 60.1660%\n",
      "layer   3  Sparsity: 76.7673%\n",
      "total_backward_count 323070 real_backward_count 71660  22.181%\n",
      "epoch-33  lr=['0.0039062'], tr/val_loss:  0.033195/  0.054119, val:  69.17%, val_best:  74.58%, tr:  87.23%, tr_best:  88.05%, epoch time: 55.54 seconds, 0.93 minutes\n",
      "layer   1  Sparsity: 91.0761%\n",
      "layer   2  Sparsity: 60.2267%\n",
      "layer   3  Sparsity: 77.0167%\n",
      "total_backward_count 332860 real_backward_count 73587  22.107%\n",
      "epoch-34  lr=['0.0039062'], tr/val_loss:  0.033058/  0.057186, val:  68.75%, val_best:  74.58%, tr:  88.97%, tr_best:  88.97%, epoch time: 51.18 seconds, 0.85 minutes\n",
      "layer   1  Sparsity: 91.0666%\n",
      "layer   2  Sparsity: 60.1995%\n",
      "layer   3  Sparsity: 77.0996%\n",
      "total_backward_count 342650 real_backward_count 75524  22.041%\n",
      "epoch-35  lr=['0.0039062'], tr/val_loss:  0.034086/  0.055039, val:  72.50%, val_best:  74.58%, tr:  87.74%, tr_best:  88.97%, epoch time: 55.69 seconds, 0.93 minutes\n",
      "layer   1  Sparsity: 91.0755%\n",
      "layer   2  Sparsity: 60.2004%\n",
      "layer   3  Sparsity: 77.3728%\n",
      "total_backward_count 352440 real_backward_count 77512  21.993%\n",
      "epoch-36  lr=['0.0039062'], tr/val_loss:  0.032720/  0.052231, val:  72.92%, val_best:  74.58%, tr:  88.66%, tr_best:  88.97%, epoch time: 55.40 seconds, 0.92 minutes\n",
      "layer   1  Sparsity: 91.0918%\n",
      "layer   2  Sparsity: 60.1932%\n",
      "layer   3  Sparsity: 77.6924%\n",
      "total_backward_count 362230 real_backward_count 79389  21.917%\n",
      "epoch-37  lr=['0.0039062'], tr/val_loss:  0.032434/  0.054553, val:  69.58%, val_best:  74.58%, tr:  88.66%, tr_best:  88.97%, epoch time: 55.20 seconds, 0.92 minutes\n",
      "layer   1  Sparsity: 91.0490%\n",
      "layer   2  Sparsity: 60.2948%\n",
      "layer   3  Sparsity: 77.8781%\n",
      "total_backward_count 372020 real_backward_count 81220  21.832%\n",
      "epoch-38  lr=['0.0039062'], tr/val_loss:  0.031819/  0.054930, val:  70.83%, val_best:  74.58%, tr:  90.30%, tr_best:  90.30%, epoch time: 55.63 seconds, 0.93 minutes\n",
      "layer   1  Sparsity: 91.0826%\n",
      "layer   2  Sparsity: 60.4411%\n",
      "layer   3  Sparsity: 77.9000%\n",
      "total_backward_count 381810 real_backward_count 83003  21.739%\n",
      "epoch-39  lr=['0.0039062'], tr/val_loss:  0.032325/  0.056945, val:  71.25%, val_best:  74.58%, tr:  88.66%, tr_best:  90.30%, epoch time: 55.55 seconds, 0.93 minutes\n",
      "layer   1  Sparsity: 91.0650%\n",
      "layer   2  Sparsity: 60.4308%\n",
      "layer   3  Sparsity: 78.0805%\n",
      "total_backward_count 391600 real_backward_count 84863  21.671%\n",
      "epoch-40  lr=['0.0039062'], tr/val_loss:  0.031594/  0.058887, val:  70.00%, val_best:  74.58%, tr:  89.07%, tr_best:  90.30%, epoch time: 56.25 seconds, 0.94 minutes\n",
      "layer   1  Sparsity: 91.0934%\n",
      "layer   2  Sparsity: 60.4603%\n",
      "layer   3  Sparsity: 78.3342%\n",
      "total_backward_count 401390 real_backward_count 86654  21.588%\n",
      "epoch-41  lr=['0.0039062'], tr/val_loss:  0.031507/  0.051588, val:  76.25%, val_best:  76.25%, tr:  90.19%, tr_best:  90.30%, epoch time: 56.30 seconds, 0.94 minutes\n",
      "layer   1  Sparsity: 91.0994%\n",
      "layer   2  Sparsity: 60.4628%\n",
      "layer   3  Sparsity: 78.5826%\n",
      "total_backward_count 411180 real_backward_count 88458  21.513%\n",
      "epoch-42  lr=['0.0039062'], tr/val_loss:  0.031019/  0.051276, val:  74.17%, val_best:  76.25%, tr:  91.01%, tr_best:  91.01%, epoch time: 55.98 seconds, 0.93 minutes\n",
      "layer   1  Sparsity: 91.1164%\n",
      "layer   2  Sparsity: 60.4867%\n",
      "layer   3  Sparsity: 78.8789%\n",
      "total_backward_count 420970 real_backward_count 90204  21.428%\n",
      "epoch-43  lr=['0.0039062'], tr/val_loss:  0.030454/  0.052205, val:  78.75%, val_best:  78.75%, tr:  90.91%, tr_best:  91.01%, epoch time: 56.12 seconds, 0.94 minutes\n",
      "layer   1  Sparsity: 91.0883%\n",
      "layer   2  Sparsity: 60.5413%\n",
      "layer   3  Sparsity: 78.9099%\n",
      "total_backward_count 430760 real_backward_count 91938  21.343%\n",
      "epoch-44  lr=['0.0039062'], tr/val_loss:  0.030427/  0.054558, val:  70.83%, val_best:  78.75%, tr:  90.70%, tr_best:  91.01%, epoch time: 55.90 seconds, 0.93 minutes\n",
      "layer   1  Sparsity: 91.0999%\n",
      "layer   2  Sparsity: 60.4397%\n",
      "layer   3  Sparsity: 79.1970%\n",
      "total_backward_count 440550 real_backward_count 93670  21.262%\n",
      "epoch-45  lr=['0.0039062'], tr/val_loss:  0.030142/  0.053482, val:  73.33%, val_best:  78.75%, tr:  90.50%, tr_best:  91.01%, epoch time: 55.63 seconds, 0.93 minutes\n",
      "layer   1  Sparsity: 91.0606%\n",
      "layer   2  Sparsity: 60.3363%\n",
      "layer   3  Sparsity: 79.3464%\n",
      "total_backward_count 450340 real_backward_count 95417  21.188%\n",
      "epoch-46  lr=['0.0039062'], tr/val_loss:  0.030036/  0.053709, val:  72.92%, val_best:  78.75%, tr:  91.32%, tr_best:  91.32%, epoch time: 55.78 seconds, 0.93 minutes\n",
      "layer   1  Sparsity: 91.0725%\n",
      "layer   2  Sparsity: 60.5411%\n",
      "layer   3  Sparsity: 79.4336%\n",
      "total_backward_count 460130 real_backward_count 97150  21.114%\n",
      "epoch-47  lr=['0.0039062'], tr/val_loss:  0.029821/  0.052162, val:  70.42%, val_best:  78.75%, tr:  90.91%, tr_best:  91.32%, epoch time: 55.63 seconds, 0.93 minutes\n",
      "layer   1  Sparsity: 91.0683%\n",
      "layer   2  Sparsity: 60.5389%\n",
      "layer   3  Sparsity: 79.5817%\n",
      "total_backward_count 469920 real_backward_count 98858  21.037%\n",
      "epoch-48  lr=['0.0039062'], tr/val_loss:  0.030025/  0.053739, val:  70.00%, val_best:  78.75%, tr:  90.91%, tr_best:  91.32%, epoch time: 55.91 seconds, 0.93 minutes\n",
      "layer   1  Sparsity: 91.0969%\n",
      "layer   2  Sparsity: 60.5144%\n",
      "layer   3  Sparsity: 79.8218%\n",
      "total_backward_count 479710 real_backward_count 100588  20.969%\n",
      "epoch-49  lr=['0.0039062'], tr/val_loss:  0.029431/  0.048146, val:  81.67%, val_best:  81.67%, tr:  90.60%, tr_best:  91.32%, epoch time: 56.22 seconds, 0.94 minutes\n",
      "layer   1  Sparsity: 91.0595%\n",
      "layer   2  Sparsity: 60.5139%\n",
      "layer   3  Sparsity: 80.0518%\n",
      "total_backward_count 489500 real_backward_count 102278  20.894%\n",
      "epoch-50  lr=['0.0039062'], tr/val_loss:  0.028970/  0.051860, val:  69.17%, val_best:  81.67%, tr:  91.83%, tr_best:  91.83%, epoch time: 55.56 seconds, 0.93 minutes\n",
      "layer   1  Sparsity: 91.0670%\n",
      "layer   2  Sparsity: 60.5412%\n",
      "layer   3  Sparsity: 80.1235%\n",
      "total_backward_count 499290 real_backward_count 103923  20.814%\n",
      "epoch-51  lr=['0.0039062'], tr/val_loss:  0.028414/  0.049780, val:  76.25%, val_best:  81.67%, tr:  91.83%, tr_best:  91.83%, epoch time: 56.19 seconds, 0.94 minutes\n",
      "layer   1  Sparsity: 91.0675%\n",
      "layer   2  Sparsity: 60.5838%\n",
      "layer   3  Sparsity: 80.1774%\n",
      "total_backward_count 509080 real_backward_count 105511  20.726%\n",
      "epoch-52  lr=['0.0039062'], tr/val_loss:  0.028089/  0.050169, val:  78.75%, val_best:  81.67%, tr:  92.54%, tr_best:  92.54%, epoch time: 55.97 seconds, 0.93 minutes\n",
      "layer   1  Sparsity: 91.0898%\n",
      "layer   2  Sparsity: 60.5962%\n",
      "layer   3  Sparsity: 80.2668%\n",
      "total_backward_count 518870 real_backward_count 107118  20.644%\n",
      "epoch-53  lr=['0.0039062'], tr/val_loss:  0.027297/  0.050456, val:  72.08%, val_best:  81.67%, tr:  92.54%, tr_best:  92.54%, epoch time: 55.81 seconds, 0.93 minutes\n",
      "layer   1  Sparsity: 91.0678%\n",
      "layer   2  Sparsity: 60.5470%\n",
      "layer   3  Sparsity: 80.3865%\n",
      "total_backward_count 528660 real_backward_count 108673  20.556%\n",
      "epoch-54  lr=['0.0039062'], tr/val_loss:  0.027547/  0.053001, val:  76.67%, val_best:  81.67%, tr:  92.54%, tr_best:  92.54%, epoch time: 56.46 seconds, 0.94 minutes\n",
      "layer   1  Sparsity: 91.0650%\n",
      "layer   2  Sparsity: 60.6070%\n",
      "layer   3  Sparsity: 80.4158%\n",
      "total_backward_count 538450 real_backward_count 110209  20.468%\n",
      "epoch-55  lr=['0.0039062'], tr/val_loss:  0.026880/  0.048450, val:  79.58%, val_best:  81.67%, tr:  93.46%, tr_best:  93.46%, epoch time: 56.17 seconds, 0.94 minutes\n",
      "layer   1  Sparsity: 91.0813%\n",
      "layer   2  Sparsity: 60.5703%\n",
      "layer   3  Sparsity: 80.5774%\n",
      "total_backward_count 548240 real_backward_count 111703  20.375%\n",
      "epoch-56  lr=['0.0039062'], tr/val_loss:  0.027191/  0.050435, val:  80.83%, val_best:  81.67%, tr:  93.67%, tr_best:  93.67%, epoch time: 55.50 seconds, 0.92 minutes\n",
      "layer   1  Sparsity: 91.0625%\n",
      "layer   2  Sparsity: 60.6557%\n",
      "layer   3  Sparsity: 80.5566%\n",
      "total_backward_count 558030 real_backward_count 113250  20.295%\n",
      "epoch-57  lr=['0.0039062'], tr/val_loss:  0.026841/  0.051429, val:  70.83%, val_best:  81.67%, tr:  93.56%, tr_best:  93.67%, epoch time: 57.28 seconds, 0.95 minutes\n",
      "layer   1  Sparsity: 91.1056%\n",
      "layer   2  Sparsity: 60.6559%\n",
      "layer   3  Sparsity: 80.8043%\n",
      "total_backward_count 567820 real_backward_count 114762  20.211%\n",
      "epoch-58  lr=['0.0039062'], tr/val_loss:  0.027408/  0.051029, val:  76.25%, val_best:  81.67%, tr:  93.67%, tr_best:  93.67%, epoch time: 55.65 seconds, 0.93 minutes\n",
      "layer   1  Sparsity: 91.0423%\n",
      "layer   2  Sparsity: 60.7434%\n",
      "layer   3  Sparsity: 81.0297%\n",
      "total_backward_count 577610 real_backward_count 116321  20.138%\n",
      "epoch-59  lr=['0.0039062'], tr/val_loss:  0.026449/  0.050261, val:  75.00%, val_best:  81.67%, tr:  93.97%, tr_best:  93.97%, epoch time: 55.71 seconds, 0.93 minutes\n",
      "layer   1  Sparsity: 91.0622%\n",
      "layer   2  Sparsity: 60.6970%\n",
      "layer   3  Sparsity: 81.1306%\n",
      "total_backward_count 587400 real_backward_count 117811  20.056%\n",
      "epoch-60  lr=['0.0039062'], tr/val_loss:  0.025620/  0.049863, val:  81.25%, val_best:  81.67%, tr:  94.28%, tr_best:  94.28%, epoch time: 55.96 seconds, 0.93 minutes\n",
      "layer   1  Sparsity: 91.0447%\n",
      "layer   2  Sparsity: 60.7559%\n",
      "layer   3  Sparsity: 81.2619%\n",
      "total_backward_count 597190 real_backward_count 119220  19.963%\n",
      "epoch-61  lr=['0.0039062'], tr/val_loss:  0.025624/  0.049792, val:  77.92%, val_best:  81.67%, tr:  94.28%, tr_best:  94.28%, epoch time: 55.98 seconds, 0.93 minutes\n",
      "layer   1  Sparsity: 91.0845%\n",
      "layer   2  Sparsity: 60.8081%\n",
      "layer   3  Sparsity: 81.2999%\n",
      "total_backward_count 606980 real_backward_count 120657  19.878%\n",
      "epoch-62  lr=['0.0039062'], tr/val_loss:  0.024821/  0.046234, val:  80.42%, val_best:  81.67%, tr:  94.89%, tr_best:  94.89%, epoch time: 55.66 seconds, 0.93 minutes\n",
      "layer   1  Sparsity: 91.0944%\n",
      "layer   2  Sparsity: 60.7809%\n",
      "layer   3  Sparsity: 81.2709%\n",
      "total_backward_count 616770 real_backward_count 122033  19.786%\n",
      "epoch-63  lr=['0.0039062'], tr/val_loss:  0.024957/  0.050210, val:  77.50%, val_best:  81.67%, tr:  94.08%, tr_best:  94.89%, epoch time: 55.75 seconds, 0.93 minutes\n",
      "layer   1  Sparsity: 91.0746%\n",
      "layer   2  Sparsity: 60.8411%\n",
      "layer   3  Sparsity: 81.3630%\n",
      "total_backward_count 626560 real_backward_count 123396  19.694%\n",
      "epoch-64  lr=['0.0039062'], tr/val_loss:  0.025314/  0.048695, val:  77.08%, val_best:  81.67%, tr:  94.89%, tr_best:  94.89%, epoch time: 56.01 seconds, 0.93 minutes\n",
      "layer   1  Sparsity: 91.0812%\n",
      "layer   2  Sparsity: 60.8153%\n",
      "layer   3  Sparsity: 81.5601%\n",
      "total_backward_count 636350 real_backward_count 124794  19.611%\n",
      "epoch-65  lr=['0.0039062'], tr/val_loss:  0.023740/  0.049100, val:  73.33%, val_best:  81.67%, tr:  95.71%, tr_best:  95.71%, epoch time: 55.93 seconds, 0.93 minutes\n",
      "layer   1  Sparsity: 91.0636%\n",
      "layer   2  Sparsity: 60.8759%\n",
      "layer   3  Sparsity: 81.5752%\n",
      "total_backward_count 646140 real_backward_count 126094  19.515%\n",
      "epoch-66  lr=['0.0039062'], tr/val_loss:  0.024280/  0.053406, val:  76.25%, val_best:  81.67%, tr:  96.42%, tr_best:  96.42%, epoch time: 55.93 seconds, 0.93 minutes\n",
      "layer   1  Sparsity: 91.0920%\n",
      "layer   2  Sparsity: 60.8273%\n",
      "layer   3  Sparsity: 81.6997%\n",
      "total_backward_count 655930 real_backward_count 127430  19.427%\n",
      "epoch-67  lr=['0.0039062'], tr/val_loss:  0.024330/  0.047619, val:  80.83%, val_best:  81.67%, tr:  94.28%, tr_best:  96.42%, epoch time: 55.37 seconds, 0.92 minutes\n",
      "layer   1  Sparsity: 91.0879%\n",
      "layer   2  Sparsity: 60.8114%\n",
      "layer   3  Sparsity: 81.9020%\n",
      "total_backward_count 665720 real_backward_count 128766  19.342%\n",
      "epoch-68  lr=['0.0039062'], tr/val_loss:  0.023963/  0.048251, val:  78.75%, val_best:  81.67%, tr:  95.61%, tr_best:  96.42%, epoch time: 55.07 seconds, 0.92 minutes\n",
      "layer   1  Sparsity: 91.0675%\n",
      "layer   2  Sparsity: 60.7192%\n",
      "layer   3  Sparsity: 82.0769%\n",
      "total_backward_count 675510 real_backward_count 130086  19.257%\n",
      "epoch-69  lr=['0.0039062'], tr/val_loss:  0.023622/  0.044699, val:  84.58%, val_best:  84.58%, tr:  96.22%, tr_best:  96.42%, epoch time: 55.52 seconds, 0.93 minutes\n",
      "layer   1  Sparsity: 91.0733%\n",
      "layer   2  Sparsity: 60.8059%\n",
      "layer   3  Sparsity: 82.1671%\n",
      "total_backward_count 685300 real_backward_count 131378  19.171%\n",
      "epoch-70  lr=['0.0039062'], tr/val_loss:  0.023108/  0.047041, val:  82.92%, val_best:  84.58%, tr:  96.42%, tr_best:  96.42%, epoch time: 55.53 seconds, 0.93 minutes\n",
      "layer   1  Sparsity: 91.0748%\n",
      "layer   2  Sparsity: 60.9594%\n",
      "layer   3  Sparsity: 82.1699%\n",
      "total_backward_count 695090 real_backward_count 132635  19.082%\n",
      "epoch-71  lr=['0.0039062'], tr/val_loss:  0.022716/  0.047259, val:  83.33%, val_best:  84.58%, tr:  96.02%, tr_best:  96.42%, epoch time: 55.24 seconds, 0.92 minutes\n",
      "layer   1  Sparsity: 91.0875%\n",
      "layer   2  Sparsity: 60.8220%\n",
      "layer   3  Sparsity: 82.3449%\n",
      "total_backward_count 704880 real_backward_count 133850  18.989%\n",
      "epoch-72  lr=['0.0039062'], tr/val_loss:  0.022530/  0.044003, val:  84.58%, val_best:  84.58%, tr:  96.53%, tr_best:  96.53%, epoch time: 56.69 seconds, 0.94 minutes\n",
      "layer   1  Sparsity: 91.0820%\n",
      "layer   2  Sparsity: 60.8861%\n",
      "layer   3  Sparsity: 82.4129%\n",
      "total_backward_count 714670 real_backward_count 135088  18.902%\n",
      "epoch-73  lr=['0.0039062'], tr/val_loss:  0.021852/  0.047704, val:  80.00%, val_best:  84.58%, tr:  96.83%, tr_best:  96.83%, epoch time: 55.73 seconds, 0.93 minutes\n",
      "layer   1  Sparsity: 91.0795%\n",
      "layer   2  Sparsity: 60.9511%\n",
      "layer   3  Sparsity: 82.4604%\n",
      "total_backward_count 724460 real_backward_count 136285  18.812%\n",
      "epoch-74  lr=['0.0039062'], tr/val_loss:  0.022678/  0.045077, val:  80.83%, val_best:  84.58%, tr:  96.42%, tr_best:  96.83%, epoch time: 55.81 seconds, 0.93 minutes\n",
      "layer   1  Sparsity: 91.0809%\n",
      "layer   2  Sparsity: 60.8639%\n",
      "layer   3  Sparsity: 82.6829%\n",
      "total_backward_count 734250 real_backward_count 137517  18.729%\n",
      "epoch-75  lr=['0.0039062'], tr/val_loss:  0.021372/  0.044618, val:  82.08%, val_best:  84.58%, tr:  97.14%, tr_best:  97.14%, epoch time: 56.58 seconds, 0.94 minutes\n",
      "layer   1  Sparsity: 91.0666%\n",
      "layer   2  Sparsity: 60.8349%\n",
      "layer   3  Sparsity: 82.7749%\n",
      "total_backward_count 744040 real_backward_count 138677  18.638%\n",
      "epoch-76  lr=['0.0039062'], tr/val_loss:  0.021405/  0.044762, val:  83.33%, val_best:  84.58%, tr:  97.14%, tr_best:  97.14%, epoch time: 55.88 seconds, 0.93 minutes\n",
      "layer   1  Sparsity: 91.0665%\n",
      "layer   2  Sparsity: 60.8959%\n",
      "layer   3  Sparsity: 82.8174%\n",
      "total_backward_count 753830 real_backward_count 139801  18.545%\n",
      "epoch-77  lr=['0.0039062'], tr/val_loss:  0.021769/  0.044608, val:  83.33%, val_best:  84.58%, tr:  96.83%, tr_best:  97.14%, epoch time: 55.48 seconds, 0.92 minutes\n",
      "layer   1  Sparsity: 91.0946%\n",
      "layer   2  Sparsity: 60.9151%\n",
      "layer   3  Sparsity: 82.8797%\n",
      "total_backward_count 763620 real_backward_count 140983  18.462%\n",
      "epoch-78  lr=['0.0039062'], tr/val_loss:  0.021554/  0.048710, val:  78.33%, val_best:  84.58%, tr:  96.53%, tr_best:  97.14%, epoch time: 56.10 seconds, 0.94 minutes\n",
      "layer   1  Sparsity: 91.0559%\n",
      "layer   2  Sparsity: 60.9989%\n",
      "layer   3  Sparsity: 82.9159%\n",
      "total_backward_count 773410 real_backward_count 142183  18.384%\n",
      "epoch-79  lr=['0.0039062'], tr/val_loss:  0.021560/  0.048714, val:  77.08%, val_best:  84.58%, tr:  96.53%, tr_best:  97.14%, epoch time: 55.57 seconds, 0.93 minutes\n",
      "layer   1  Sparsity: 91.0529%\n",
      "layer   2  Sparsity: 60.9519%\n",
      "layer   3  Sparsity: 83.1410%\n",
      "total_backward_count 783200 real_backward_count 143357  18.304%\n",
      "epoch-80  lr=['0.0039062'], tr/val_loss:  0.021152/  0.047100, val:  77.08%, val_best:  84.58%, tr:  97.65%, tr_best:  97.65%, epoch time: 55.52 seconds, 0.93 minutes\n",
      "layer   1  Sparsity: 91.0819%\n",
      "layer   2  Sparsity: 60.9197%\n",
      "layer   3  Sparsity: 83.1841%\n",
      "total_backward_count 792990 real_backward_count 144502  18.222%\n",
      "epoch-81  lr=['0.0039062'], tr/val_loss:  0.019772/  0.044567, val:  84.17%, val_best:  84.58%, tr:  97.65%, tr_best:  97.65%, epoch time: 56.49 seconds, 0.94 minutes\n",
      "layer   1  Sparsity: 91.0522%\n",
      "layer   2  Sparsity: 60.9404%\n",
      "layer   3  Sparsity: 83.2475%\n",
      "total_backward_count 802780 real_backward_count 145548  18.130%\n",
      "epoch-82  lr=['0.0039062'], tr/val_loss:  0.020134/  0.045656, val:  77.92%, val_best:  84.58%, tr:  97.24%, tr_best:  97.65%, epoch time: 55.70 seconds, 0.93 minutes\n",
      "layer   1  Sparsity: 91.0554%\n",
      "layer   2  Sparsity: 61.0039%\n",
      "layer   3  Sparsity: 83.2660%\n",
      "total_backward_count 812570 real_backward_count 146604  18.042%\n",
      "epoch-83  lr=['0.0039062'], tr/val_loss:  0.020081/  0.043407, val:  84.17%, val_best:  84.58%, tr:  97.55%, tr_best:  97.65%, epoch time: 56.04 seconds, 0.93 minutes\n",
      "layer   1  Sparsity: 91.0705%\n",
      "layer   2  Sparsity: 61.0662%\n",
      "layer   3  Sparsity: 83.2713%\n",
      "total_backward_count 822360 real_backward_count 147691  17.959%\n",
      "epoch-84  lr=['0.0039062'], tr/val_loss:  0.020444/  0.042093, val:  84.58%, val_best:  84.58%, tr:  97.34%, tr_best:  97.65%, epoch time: 56.08 seconds, 0.93 minutes\n",
      "layer   1  Sparsity: 91.0852%\n",
      "layer   2  Sparsity: 61.0567%\n",
      "layer   3  Sparsity: 83.3973%\n",
      "total_backward_count 832150 real_backward_count 148805  17.882%\n",
      "epoch-85  lr=['0.0039062'], tr/val_loss:  0.019758/  0.045928, val:  80.83%, val_best:  84.58%, tr:  97.65%, tr_best:  97.65%, epoch time: 55.69 seconds, 0.93 minutes\n",
      "layer   1  Sparsity: 91.0770%\n",
      "layer   2  Sparsity: 61.1064%\n",
      "layer   3  Sparsity: 83.4831%\n",
      "total_backward_count 841940 real_backward_count 149848  17.798%\n",
      "epoch-86  lr=['0.0039062'], tr/val_loss:  0.018861/  0.042209, val:  84.17%, val_best:  84.58%, tr:  98.47%, tr_best:  98.47%, epoch time: 56.00 seconds, 0.93 minutes\n",
      "layer   1  Sparsity: 91.0851%\n",
      "layer   2  Sparsity: 61.0980%\n",
      "layer   3  Sparsity: 83.5702%\n",
      "total_backward_count 851730 real_backward_count 150820  17.707%\n",
      "epoch-87  lr=['0.0039062'], tr/val_loss:  0.018930/  0.043757, val:  82.92%, val_best:  84.58%, tr:  98.98%, tr_best:  98.98%, epoch time: 56.10 seconds, 0.94 minutes\n",
      "layer   1  Sparsity: 91.1032%\n",
      "layer   2  Sparsity: 61.1219%\n",
      "layer   3  Sparsity: 83.5982%\n",
      "total_backward_count 861520 real_backward_count 151806  17.621%\n",
      "epoch-88  lr=['0.0039062'], tr/val_loss:  0.019050/  0.044697, val:  82.08%, val_best:  84.58%, tr:  98.16%, tr_best:  98.98%, epoch time: 55.37 seconds, 0.92 minutes\n",
      "layer   1  Sparsity: 91.0595%\n",
      "layer   2  Sparsity: 61.1527%\n",
      "layer   3  Sparsity: 83.6772%\n",
      "total_backward_count 871310 real_backward_count 152785  17.535%\n",
      "epoch-89  lr=['0.0039062'], tr/val_loss:  0.018929/  0.044516, val:  82.50%, val_best:  84.58%, tr:  97.75%, tr_best:  98.98%, epoch time: 55.88 seconds, 0.93 minutes\n",
      "layer   1  Sparsity: 91.0729%\n",
      "layer   2  Sparsity: 60.9808%\n",
      "layer   3  Sparsity: 83.7354%\n",
      "total_backward_count 881100 real_backward_count 153775  17.453%\n",
      "epoch-90  lr=['0.0039062'], tr/val_loss:  0.019389/  0.044265, val:  83.75%, val_best:  84.58%, tr:  97.45%, tr_best:  98.98%, epoch time: 55.95 seconds, 0.93 minutes\n",
      "layer   1  Sparsity: 91.0746%\n",
      "layer   2  Sparsity: 60.9850%\n",
      "layer   3  Sparsity: 83.8208%\n",
      "total_backward_count 890890 real_backward_count 154804  17.376%\n",
      "epoch-91  lr=['0.0039062'], tr/val_loss:  0.017701/  0.043900, val:  82.08%, val_best:  84.58%, tr:  98.47%, tr_best:  98.98%, epoch time: 55.48 seconds, 0.92 minutes\n",
      "layer   1  Sparsity: 91.0938%\n",
      "layer   2  Sparsity: 61.0620%\n",
      "layer   3  Sparsity: 83.8361%\n",
      "total_backward_count 900680 real_backward_count 155703  17.287%\n",
      "epoch-92  lr=['0.0039062'], tr/val_loss:  0.018028/  0.041786, val:  85.42%, val_best:  85.42%, tr:  98.26%, tr_best:  98.98%, epoch time: 55.62 seconds, 0.93 minutes\n",
      "layer   1  Sparsity: 91.0903%\n",
      "layer   2  Sparsity: 61.1663%\n",
      "layer   3  Sparsity: 83.8493%\n",
      "total_backward_count 910470 real_backward_count 156609  17.201%\n",
      "epoch-93  lr=['0.0039062'], tr/val_loss:  0.018220/  0.042097, val:  84.17%, val_best:  85.42%, tr:  97.96%, tr_best:  98.98%, epoch time: 55.94 seconds, 0.93 minutes\n",
      "layer   1  Sparsity: 91.0902%\n",
      "layer   2  Sparsity: 61.1297%\n",
      "layer   3  Sparsity: 83.9238%\n",
      "total_backward_count 920260 real_backward_count 157567  17.122%\n",
      "epoch-94  lr=['0.0039062'], tr/val_loss:  0.018525/  0.043289, val:  82.50%, val_best:  85.42%, tr:  98.37%, tr_best:  98.98%, epoch time: 55.75 seconds, 0.93 minutes\n",
      "layer   1  Sparsity: 91.1001%\n",
      "layer   2  Sparsity: 61.1306%\n",
      "layer   3  Sparsity: 83.9782%\n",
      "total_backward_count 930050 real_backward_count 158542  17.047%\n",
      "epoch-95  lr=['0.0039062'], tr/val_loss:  0.017906/  0.044181, val:  81.25%, val_best:  85.42%, tr:  98.16%, tr_best:  98.98%, epoch time: 55.38 seconds, 0.92 minutes\n",
      "layer   1  Sparsity: 91.1013%\n",
      "layer   2  Sparsity: 61.1511%\n",
      "layer   3  Sparsity: 83.9751%\n",
      "total_backward_count 939840 real_backward_count 159489  16.970%\n",
      "epoch-96  lr=['0.0039062'], tr/val_loss:  0.017870/  0.042776, val:  83.75%, val_best:  85.42%, tr:  98.57%, tr_best:  98.98%, epoch time: 55.42 seconds, 0.92 minutes\n",
      "layer   1  Sparsity: 91.0603%\n",
      "layer   2  Sparsity: 61.1168%\n",
      "layer   3  Sparsity: 83.9586%\n",
      "total_backward_count 949630 real_backward_count 160424  16.893%\n",
      "epoch-97  lr=['0.0039062'], tr/val_loss:  0.017479/  0.041800, val:  85.83%, val_best:  85.83%, tr:  98.77%, tr_best:  98.98%, epoch time: 55.34 seconds, 0.92 minutes\n",
      "layer   1  Sparsity: 91.0412%\n",
      "layer   2  Sparsity: 61.1706%\n",
      "layer   3  Sparsity: 83.9938%\n",
      "total_backward_count 959420 real_backward_count 161320  16.814%\n",
      "epoch-98  lr=['0.0039062'], tr/val_loss:  0.017479/  0.043131, val:  82.92%, val_best:  85.83%, tr:  98.37%, tr_best:  98.98%, epoch time: 55.70 seconds, 0.93 minutes\n",
      "layer   1  Sparsity: 91.1478%\n",
      "layer   2  Sparsity: 61.2080%\n",
      "layer   3  Sparsity: 83.9808%\n",
      "total_backward_count 969210 real_backward_count 162197  16.735%\n",
      "epoch-99  lr=['0.0039062'], tr/val_loss:  0.017345/  0.041621, val:  83.75%, val_best:  85.83%, tr:  97.85%, tr_best:  98.98%, epoch time: 55.55 seconds, 0.93 minutes\n",
      "layer   1  Sparsity: 91.1250%\n",
      "layer   2  Sparsity: 61.1754%\n",
      "layer   3  Sparsity: 84.2267%\n",
      "total_backward_count 979000 real_backward_count 163083  16.658%\n",
      "epoch-100 lr=['0.0039062'], tr/val_loss:  0.017200/  0.041916, val:  83.75%, val_best:  85.83%, tr:  97.65%, tr_best:  98.98%, epoch time: 56.19 seconds, 0.94 minutes\n",
      "layer   1  Sparsity: 91.0869%\n",
      "layer   2  Sparsity: 61.0350%\n",
      "layer   3  Sparsity: 84.2813%\n",
      "total_backward_count 988790 real_backward_count 163969  16.583%\n",
      "epoch-101 lr=['0.0039062'], tr/val_loss:  0.017081/  0.041402, val:  84.17%, val_best:  85.83%, tr:  98.26%, tr_best:  98.98%, epoch time: 56.90 seconds, 0.95 minutes\n",
      "layer   1  Sparsity: 91.0879%\n",
      "layer   2  Sparsity: 61.0175%\n",
      "layer   3  Sparsity: 84.3400%\n",
      "total_backward_count 998580 real_backward_count 164851  16.509%\n",
      "epoch-102 lr=['0.0039062'], tr/val_loss:  0.016947/  0.042135, val:  85.00%, val_best:  85.83%, tr:  98.47%, tr_best:  98.98%, epoch time: 56.27 seconds, 0.94 minutes\n",
      "layer   1  Sparsity: 91.0423%\n",
      "layer   2  Sparsity: 61.0383%\n",
      "layer   3  Sparsity: 84.3713%\n",
      "total_backward_count 1008370 real_backward_count 165713  16.434%\n",
      "epoch-103 lr=['0.0039062'], tr/val_loss:  0.017097/  0.042763, val:  83.33%, val_best:  85.83%, tr:  98.37%, tr_best:  98.98%, epoch time: 56.27 seconds, 0.94 minutes\n",
      "layer   1  Sparsity: 91.0807%\n",
      "layer   2  Sparsity: 61.0997%\n",
      "layer   3  Sparsity: 84.3463%\n",
      "total_backward_count 1018160 real_backward_count 166623  16.365%\n",
      "epoch-104 lr=['0.0039062'], tr/val_loss:  0.016424/  0.040637, val:  86.67%, val_best:  86.67%, tr:  98.77%, tr_best:  98.98%, epoch time: 55.85 seconds, 0.93 minutes\n",
      "layer   1  Sparsity: 91.0760%\n",
      "layer   2  Sparsity: 61.0752%\n",
      "layer   3  Sparsity: 84.4239%\n",
      "total_backward_count 1027950 real_backward_count 167446  16.289%\n",
      "epoch-105 lr=['0.0039062'], tr/val_loss:  0.017164/  0.043521, val:  83.75%, val_best:  86.67%, tr:  99.08%, tr_best:  99.08%, epoch time: 55.74 seconds, 0.93 minutes\n",
      "layer   1  Sparsity: 91.0376%\n",
      "layer   2  Sparsity: 61.0335%\n",
      "layer   3  Sparsity: 84.3760%\n",
      "total_backward_count 1037740 real_backward_count 168344  16.222%\n",
      "epoch-106 lr=['0.0039062'], tr/val_loss:  0.016722/  0.040991, val:  84.17%, val_best:  86.67%, tr:  98.77%, tr_best:  99.08%, epoch time: 55.97 seconds, 0.93 minutes\n",
      "layer   1  Sparsity: 91.0815%\n",
      "layer   2  Sparsity: 61.0097%\n",
      "layer   3  Sparsity: 84.4648%\n",
      "total_backward_count 1047530 real_backward_count 169207  16.153%\n",
      "epoch-107 lr=['0.0039062'], tr/val_loss:  0.016643/  0.043045, val:  85.00%, val_best:  86.67%, tr:  98.67%, tr_best:  99.08%, epoch time: 56.29 seconds, 0.94 minutes\n",
      "layer   1  Sparsity: 91.0438%\n",
      "layer   2  Sparsity: 60.9734%\n",
      "layer   3  Sparsity: 84.4730%\n",
      "total_backward_count 1057320 real_backward_count 170076  16.086%\n",
      "epoch-108 lr=['0.0039062'], tr/val_loss:  0.016066/  0.040349, val:  85.83%, val_best:  86.67%, tr:  98.77%, tr_best:  99.08%, epoch time: 55.90 seconds, 0.93 minutes\n",
      "layer   1  Sparsity: 91.0880%\n",
      "layer   2  Sparsity: 60.9016%\n",
      "layer   3  Sparsity: 84.4544%\n",
      "total_backward_count 1067110 real_backward_count 170896  16.015%\n",
      "epoch-109 lr=['0.0039062'], tr/val_loss:  0.015317/  0.040440, val:  83.33%, val_best:  86.67%, tr:  98.77%, tr_best:  99.08%, epoch time: 56.31 seconds, 0.94 minutes\n",
      "layer   1  Sparsity: 91.0610%\n",
      "layer   2  Sparsity: 60.8778%\n",
      "layer   3  Sparsity: 84.5057%\n",
      "total_backward_count 1076900 real_backward_count 171686  15.943%\n",
      "epoch-110 lr=['0.0039062'], tr/val_loss:  0.015959/  0.040935, val:  84.58%, val_best:  86.67%, tr:  97.96%, tr_best:  99.08%, epoch time: 56.03 seconds, 0.93 minutes\n",
      "layer   1  Sparsity: 91.0923%\n",
      "layer   2  Sparsity: 60.9347%\n",
      "layer   3  Sparsity: 84.4800%\n",
      "total_backward_count 1086690 real_backward_count 172530  15.877%\n",
      "epoch-111 lr=['0.0039062'], tr/val_loss:  0.016100/  0.040157, val:  85.42%, val_best:  86.67%, tr:  98.67%, tr_best:  99.08%, epoch time: 55.47 seconds, 0.92 minutes\n",
      "layer   1  Sparsity: 91.0775%\n",
      "layer   2  Sparsity: 60.9013%\n",
      "layer   3  Sparsity: 84.5003%\n",
      "total_backward_count 1096480 real_backward_count 173373  15.812%\n",
      "epoch-112 lr=['0.0039062'], tr/val_loss:  0.015821/  0.039568, val:  86.67%, val_best:  86.67%, tr:  98.88%, tr_best:  99.08%, epoch time: 55.12 seconds, 0.92 minutes\n",
      "layer   1  Sparsity: 91.0943%\n",
      "layer   2  Sparsity: 60.8237%\n",
      "layer   3  Sparsity: 84.5687%\n",
      "total_backward_count 1106270 real_backward_count 174168  15.744%\n",
      "epoch-113 lr=['0.0039062'], tr/val_loss:  0.015738/  0.043594, val:  80.42%, val_best:  86.67%, tr:  99.08%, tr_best:  99.08%, epoch time: 55.43 seconds, 0.92 minutes\n",
      "layer   1  Sparsity: 91.1341%\n",
      "layer   2  Sparsity: 60.7957%\n",
      "layer   3  Sparsity: 84.5455%\n",
      "total_backward_count 1116060 real_backward_count 174973  15.678%\n",
      "epoch-114 lr=['0.0039062'], tr/val_loss:  0.016205/  0.039838, val:  86.67%, val_best:  86.67%, tr:  98.67%, tr_best:  99.08%, epoch time: 55.45 seconds, 0.92 minutes\n",
      "layer   1  Sparsity: 91.0869%\n",
      "layer   2  Sparsity: 60.9143%\n",
      "layer   3  Sparsity: 84.5893%\n",
      "total_backward_count 1125850 real_backward_count 175832  15.618%\n",
      "epoch-115 lr=['0.0039062'], tr/val_loss:  0.015220/  0.042239, val:  83.75%, val_best:  86.67%, tr:  98.57%, tr_best:  99.08%, epoch time: 55.06 seconds, 0.92 minutes\n",
      "layer   1  Sparsity: 91.0931%\n",
      "layer   2  Sparsity: 60.9561%\n",
      "layer   3  Sparsity: 84.6180%\n",
      "total_backward_count 1135640 real_backward_count 176585  15.549%\n",
      "epoch-116 lr=['0.0039062'], tr/val_loss:  0.015521/  0.042757, val:  83.75%, val_best:  86.67%, tr:  98.88%, tr_best:  99.08%, epoch time: 56.01 seconds, 0.93 minutes\n",
      "layer   1  Sparsity: 91.0522%\n",
      "layer   2  Sparsity: 61.0036%\n",
      "layer   3  Sparsity: 84.6642%\n",
      "total_backward_count 1145430 real_backward_count 177379  15.486%\n",
      "epoch-117 lr=['0.0039062'], tr/val_loss:  0.015165/  0.040981, val:  84.58%, val_best:  86.67%, tr:  99.08%, tr_best:  99.08%, epoch time: 55.66 seconds, 0.93 minutes\n",
      "layer   1  Sparsity: 91.0669%\n",
      "layer   2  Sparsity: 60.9863%\n",
      "layer   3  Sparsity: 84.6459%\n",
      "total_backward_count 1155220 real_backward_count 178142  15.421%\n",
      "epoch-118 lr=['0.0039062'], tr/val_loss:  0.015289/  0.038766, val:  85.83%, val_best:  86.67%, tr:  98.47%, tr_best:  99.08%, epoch time: 56.38 seconds, 0.94 minutes\n",
      "layer   1  Sparsity: 91.1179%\n",
      "layer   2  Sparsity: 60.9266%\n",
      "layer   3  Sparsity: 84.7165%\n",
      "total_backward_count 1165010 real_backward_count 178932  15.359%\n",
      "epoch-119 lr=['0.0039062'], tr/val_loss:  0.014575/  0.044559, val:  81.25%, val_best:  86.67%, tr:  98.88%, tr_best:  99.08%, epoch time: 56.10 seconds, 0.94 minutes\n",
      "layer   1  Sparsity: 91.0968%\n",
      "layer   2  Sparsity: 60.9030%\n",
      "layer   3  Sparsity: 84.7530%\n",
      "total_backward_count 1174800 real_backward_count 179685  15.295%\n",
      "epoch-120 lr=['0.0039062'], tr/val_loss:  0.015266/  0.040228, val:  85.83%, val_best:  86.67%, tr:  98.77%, tr_best:  99.08%, epoch time: 55.50 seconds, 0.93 minutes\n",
      "layer   1  Sparsity: 91.1179%\n",
      "layer   2  Sparsity: 60.7415%\n",
      "layer   3  Sparsity: 84.8476%\n",
      "total_backward_count 1184590 real_backward_count 180473  15.235%\n",
      "epoch-121 lr=['0.0039062'], tr/val_loss:  0.014450/  0.039527, val:  87.92%, val_best:  87.92%, tr:  98.98%, tr_best:  99.08%, epoch time: 55.57 seconds, 0.93 minutes\n",
      "layer   1  Sparsity: 91.0801%\n",
      "layer   2  Sparsity: 60.7382%\n",
      "layer   3  Sparsity: 84.9204%\n",
      "total_backward_count 1194380 real_backward_count 181222  15.173%\n",
      "epoch-122 lr=['0.0039062'], tr/val_loss:  0.014779/  0.038812, val:  85.83%, val_best:  87.92%, tr:  98.77%, tr_best:  99.08%, epoch time: 56.10 seconds, 0.93 minutes\n",
      "layer   1  Sparsity: 91.1183%\n",
      "layer   2  Sparsity: 60.8030%\n",
      "layer   3  Sparsity: 84.9744%\n",
      "total_backward_count 1204170 real_backward_count 181999  15.114%\n",
      "epoch-123 lr=['0.0039062'], tr/val_loss:  0.014819/  0.039134, val:  86.25%, val_best:  87.92%, tr:  99.39%, tr_best:  99.39%, epoch time: 56.18 seconds, 0.94 minutes\n",
      "layer   1  Sparsity: 91.0565%\n",
      "layer   2  Sparsity: 60.8272%\n",
      "layer   3  Sparsity: 84.9671%\n",
      "total_backward_count 1213960 real_backward_count 182780  15.057%\n",
      "epoch-124 lr=['0.0039062'], tr/val_loss:  0.014280/  0.038329, val:  87.50%, val_best:  87.92%, tr:  99.08%, tr_best:  99.39%, epoch time: 55.70 seconds, 0.93 minutes\n",
      "layer   1  Sparsity: 91.0479%\n",
      "layer   2  Sparsity: 60.8118%\n",
      "layer   3  Sparsity: 84.9832%\n",
      "total_backward_count 1223750 real_backward_count 183492  14.994%\n",
      "epoch-125 lr=['0.0039062'], tr/val_loss:  0.014742/  0.042715, val:  85.83%, val_best:  87.92%, tr:  98.47%, tr_best:  99.39%, epoch time: 56.09 seconds, 0.93 minutes\n",
      "layer   1  Sparsity: 91.0659%\n",
      "layer   2  Sparsity: 60.9722%\n",
      "layer   3  Sparsity: 84.9833%\n",
      "total_backward_count 1233540 real_backward_count 184236  14.936%\n",
      "epoch-126 lr=['0.0039062'], tr/val_loss:  0.013924/  0.039781, val:  86.25%, val_best:  87.92%, tr:  99.08%, tr_best:  99.39%, epoch time: 55.85 seconds, 0.93 minutes\n",
      "layer   1  Sparsity: 91.0502%\n",
      "layer   2  Sparsity: 60.8691%\n",
      "layer   3  Sparsity: 85.0413%\n",
      "total_backward_count 1243330 real_backward_count 184911  14.872%\n",
      "epoch-127 lr=['0.0039062'], tr/val_loss:  0.014233/  0.040103, val:  85.00%, val_best:  87.92%, tr:  99.49%, tr_best:  99.49%, epoch time: 55.54 seconds, 0.93 minutes\n",
      "layer   1  Sparsity: 91.0970%\n",
      "layer   2  Sparsity: 60.9630%\n",
      "layer   3  Sparsity: 84.9774%\n",
      "total_backward_count 1253120 real_backward_count 185631  14.814%\n",
      "epoch-128 lr=['0.0039062'], tr/val_loss:  0.013715/  0.044641, val:  80.42%, val_best:  87.92%, tr:  99.18%, tr_best:  99.49%, epoch time: 56.30 seconds, 0.94 minutes\n",
      "layer   1  Sparsity: 91.1052%\n",
      "layer   2  Sparsity: 60.8163%\n",
      "layer   3  Sparsity: 85.0949%\n",
      "total_backward_count 1262910 real_backward_count 186331  14.754%\n",
      "epoch-129 lr=['0.0039062'], tr/val_loss:  0.013738/  0.039266, val:  86.67%, val_best:  87.92%, tr:  99.39%, tr_best:  99.49%, epoch time: 56.04 seconds, 0.93 minutes\n",
      "layer   1  Sparsity: 91.0835%\n",
      "layer   2  Sparsity: 60.8970%\n",
      "layer   3  Sparsity: 85.1264%\n",
      "total_backward_count 1272700 real_backward_count 187006  14.694%\n",
      "epoch-130 lr=['0.0039062'], tr/val_loss:  0.014061/  0.038930, val:  85.42%, val_best:  87.92%, tr:  98.77%, tr_best:  99.49%, epoch time: 55.95 seconds, 0.93 minutes\n",
      "layer   1  Sparsity: 91.0951%\n",
      "layer   2  Sparsity: 60.8470%\n",
      "layer   3  Sparsity: 85.1741%\n",
      "total_backward_count 1282490 real_backward_count 187714  14.637%\n",
      "epoch-131 lr=['0.0039062'], tr/val_loss:  0.013436/  0.040293, val:  86.25%, val_best:  87.92%, tr:  99.18%, tr_best:  99.49%, epoch time: 55.37 seconds, 0.92 minutes\n",
      "layer   1  Sparsity: 91.0480%\n",
      "layer   2  Sparsity: 60.8549%\n",
      "layer   3  Sparsity: 85.1748%\n",
      "total_backward_count 1292280 real_backward_count 188394  14.578%\n",
      "epoch-132 lr=['0.0039062'], tr/val_loss:  0.013954/  0.042599, val:  84.58%, val_best:  87.92%, tr:  99.49%, tr_best:  99.49%, epoch time: 55.33 seconds, 0.92 minutes\n",
      "layer   1  Sparsity: 91.0941%\n",
      "layer   2  Sparsity: 60.8909%\n",
      "layer   3  Sparsity: 85.2063%\n",
      "total_backward_count 1302070 real_backward_count 189090  14.522%\n",
      "epoch-133 lr=['0.0039062'], tr/val_loss:  0.013611/  0.045178, val:  81.67%, val_best:  87.92%, tr:  99.18%, tr_best:  99.49%, epoch time: 56.19 seconds, 0.94 minutes\n",
      "layer   1  Sparsity: 91.0893%\n",
      "layer   2  Sparsity: 60.9303%\n",
      "layer   3  Sparsity: 85.1326%\n",
      "total_backward_count 1311860 real_backward_count 189748  14.464%\n",
      "epoch-134 lr=['0.0039062'], tr/val_loss:  0.014055/  0.040290, val:  83.33%, val_best:  87.92%, tr:  99.49%, tr_best:  99.49%, epoch time: 56.27 seconds, 0.94 minutes\n",
      "layer   1  Sparsity: 91.0833%\n",
      "layer   2  Sparsity: 60.8945%\n",
      "layer   3  Sparsity: 85.2513%\n",
      "total_backward_count 1321650 real_backward_count 190476  14.412%\n",
      "epoch-135 lr=['0.0039062'], tr/val_loss:  0.013302/  0.038843, val:  83.33%, val_best:  87.92%, tr:  99.08%, tr_best:  99.49%, epoch time: 55.70 seconds, 0.93 minutes\n",
      "layer   1  Sparsity: 91.0661%\n",
      "layer   2  Sparsity: 60.8350%\n",
      "layer   3  Sparsity: 85.3410%\n",
      "total_backward_count 1331440 real_backward_count 191146  14.356%\n",
      "epoch-136 lr=['0.0039062'], tr/val_loss:  0.013497/  0.043076, val:  84.17%, val_best:  87.92%, tr:  99.18%, tr_best:  99.49%, epoch time: 56.06 seconds, 0.93 minutes\n",
      "layer   1  Sparsity: 91.0541%\n",
      "layer   2  Sparsity: 60.8297%\n",
      "layer   3  Sparsity: 85.3647%\n",
      "total_backward_count 1341230 real_backward_count 191848  14.304%\n",
      "epoch-137 lr=['0.0039062'], tr/val_loss:  0.013974/  0.040151, val:  84.17%, val_best:  87.92%, tr:  99.59%, tr_best:  99.59%, epoch time: 56.23 seconds, 0.94 minutes\n",
      "layer   1  Sparsity: 91.0642%\n",
      "layer   2  Sparsity: 60.9473%\n",
      "layer   3  Sparsity: 85.4051%\n",
      "total_backward_count 1351020 real_backward_count 192565  14.253%\n",
      "epoch-138 lr=['0.0039062'], tr/val_loss:  0.012966/  0.043272, val:  84.17%, val_best:  87.92%, tr:  99.39%, tr_best:  99.59%, epoch time: 56.03 seconds, 0.93 minutes\n",
      "layer   1  Sparsity: 91.0779%\n",
      "layer   2  Sparsity: 60.9161%\n",
      "layer   3  Sparsity: 85.4393%\n",
      "total_backward_count 1360810 real_backward_count 193199  14.197%\n",
      "epoch-139 lr=['0.0039062'], tr/val_loss:  0.013783/  0.039572, val:  87.08%, val_best:  87.92%, tr:  99.18%, tr_best:  99.59%, epoch time: 56.57 seconds, 0.94 minutes\n",
      "layer   1  Sparsity: 91.0809%\n",
      "layer   2  Sparsity: 60.9695%\n",
      "layer   3  Sparsity: 85.4326%\n",
      "total_backward_count 1370600 real_backward_count 193899  14.147%\n",
      "epoch-140 lr=['0.0039062'], tr/val_loss:  0.013115/  0.038472, val:  87.08%, val_best:  87.92%, tr:  99.18%, tr_best:  99.59%, epoch time: 56.16 seconds, 0.94 minutes\n",
      "layer   1  Sparsity: 91.0934%\n",
      "layer   2  Sparsity: 60.8595%\n",
      "layer   3  Sparsity: 85.4486%\n",
      "total_backward_count 1380390 real_backward_count 194549  14.094%\n",
      "epoch-141 lr=['0.0039062'], tr/val_loss:  0.012832/  0.040027, val:  85.00%, val_best:  87.92%, tr:  99.18%, tr_best:  99.59%, epoch time: 56.09 seconds, 0.93 minutes\n",
      "layer   1  Sparsity: 91.0901%\n",
      "layer   2  Sparsity: 60.8650%\n",
      "layer   3  Sparsity: 85.4833%\n",
      "total_backward_count 1390180 real_backward_count 195192  14.041%\n",
      "epoch-142 lr=['0.0039062'], tr/val_loss:  0.012795/  0.040672, val:  85.83%, val_best:  87.92%, tr:  99.59%, tr_best:  99.59%, epoch time: 56.12 seconds, 0.94 minutes\n",
      "layer   1  Sparsity: 91.0476%\n",
      "layer   2  Sparsity: 60.8110%\n",
      "layer   3  Sparsity: 85.5216%\n",
      "total_backward_count 1399970 real_backward_count 195835  13.989%\n",
      "epoch-143 lr=['0.0039062'], tr/val_loss:  0.013388/  0.041401, val:  82.50%, val_best:  87.92%, tr:  99.28%, tr_best:  99.59%, epoch time: 56.21 seconds, 0.94 minutes\n",
      "layer   1  Sparsity: 91.0237%\n",
      "layer   2  Sparsity: 60.8224%\n",
      "layer   3  Sparsity: 85.5961%\n",
      "total_backward_count 1409760 real_backward_count 196529  13.941%\n",
      "epoch-144 lr=['0.0039062'], tr/val_loss:  0.012788/  0.037864, val:  88.33%, val_best:  88.33%, tr:  99.18%, tr_best:  99.59%, epoch time: 55.81 seconds, 0.93 minutes\n",
      "layer   1  Sparsity: 91.0771%\n",
      "layer   2  Sparsity: 60.7753%\n",
      "layer   3  Sparsity: 85.5934%\n",
      "total_backward_count 1419550 real_backward_count 197169  13.890%\n",
      "epoch-145 lr=['0.0039062'], tr/val_loss:  0.012856/  0.038957, val:  86.67%, val_best:  88.33%, tr:  98.88%, tr_best:  99.59%, epoch time: 55.82 seconds, 0.93 minutes\n",
      "layer   1  Sparsity: 91.1022%\n",
      "layer   2  Sparsity: 60.7323%\n",
      "layer   3  Sparsity: 85.6870%\n",
      "total_backward_count 1429340 real_backward_count 197802  13.839%\n",
      "epoch-146 lr=['0.0039062'], tr/val_loss:  0.012773/  0.039671, val:  86.67%, val_best:  88.33%, tr:  99.49%, tr_best:  99.59%, epoch time: 55.70 seconds, 0.93 minutes\n",
      "layer   1  Sparsity: 91.0749%\n",
      "layer   2  Sparsity: 60.8522%\n",
      "layer   3  Sparsity: 85.6575%\n",
      "total_backward_count 1439130 real_backward_count 198431  13.788%\n",
      "epoch-147 lr=['0.0039062'], tr/val_loss:  0.013196/  0.040091, val:  85.42%, val_best:  88.33%, tr:  99.59%, tr_best:  99.59%, epoch time: 55.92 seconds, 0.93 minutes\n",
      "layer   1  Sparsity: 91.0685%\n",
      "layer   2  Sparsity: 60.8632%\n",
      "layer   3  Sparsity: 85.6766%\n",
      "total_backward_count 1448920 real_backward_count 199086  13.740%\n",
      "epoch-148 lr=['0.0039062'], tr/val_loss:  0.012512/  0.039467, val:  85.42%, val_best:  88.33%, tr:  99.28%, tr_best:  99.59%, epoch time: 55.29 seconds, 0.92 minutes\n",
      "layer   1  Sparsity: 91.0752%\n",
      "layer   2  Sparsity: 60.7991%\n",
      "layer   3  Sparsity: 85.7665%\n",
      "total_backward_count 1458710 real_backward_count 199714  13.691%\n",
      "epoch-149 lr=['0.0039062'], tr/val_loss:  0.012813/  0.038280, val:  86.25%, val_best:  88.33%, tr:  99.18%, tr_best:  99.59%, epoch time: 56.15 seconds, 0.94 minutes\n",
      "layer   1  Sparsity: 91.0821%\n",
      "layer   2  Sparsity: 60.8161%\n",
      "layer   3  Sparsity: 85.8199%\n",
      "total_backward_count 1468500 real_backward_count 200361  13.644%\n",
      "epoch-150 lr=['0.0039062'], tr/val_loss:  0.012717/  0.040071, val:  86.25%, val_best:  88.33%, tr:  99.49%, tr_best:  99.59%, epoch time: 56.05 seconds, 0.93 minutes\n",
      "layer   1  Sparsity: 91.0970%\n",
      "layer   2  Sparsity: 60.7790%\n",
      "layer   3  Sparsity: 85.8722%\n",
      "total_backward_count 1478290 real_backward_count 200997  13.597%\n",
      "epoch-151 lr=['0.0039062'], tr/val_loss:  0.012193/  0.040717, val:  84.58%, val_best:  88.33%, tr:  99.39%, tr_best:  99.59%, epoch time: 55.50 seconds, 0.93 minutes\n",
      "layer   1  Sparsity: 91.0973%\n",
      "layer   2  Sparsity: 60.7915%\n",
      "layer   3  Sparsity: 85.8315%\n",
      "total_backward_count 1488080 real_backward_count 201595  13.547%\n",
      "epoch-152 lr=['0.0039062'], tr/val_loss:  0.011768/  0.043546, val:  83.33%, val_best:  88.33%, tr:  99.69%, tr_best:  99.69%, epoch time: 55.73 seconds, 0.93 minutes\n",
      "layer   1  Sparsity: 91.0936%\n",
      "layer   2  Sparsity: 60.7907%\n",
      "layer   3  Sparsity: 85.8499%\n",
      "total_backward_count 1497870 real_backward_count 202168  13.497%\n",
      "epoch-153 lr=['0.0039062'], tr/val_loss:  0.011899/  0.038413, val:  86.25%, val_best:  88.33%, tr:  99.28%, tr_best:  99.69%, epoch time: 56.22 seconds, 0.94 minutes\n",
      "layer   1  Sparsity: 91.0993%\n",
      "layer   2  Sparsity: 60.7756%\n",
      "layer   3  Sparsity: 85.9253%\n",
      "total_backward_count 1507660 real_backward_count 202769  13.449%\n",
      "epoch-154 lr=['0.0039062'], tr/val_loss:  0.012285/  0.039311, val:  86.25%, val_best:  88.33%, tr:  99.90%, tr_best:  99.90%, epoch time: 55.37 seconds, 0.92 minutes\n",
      "layer   1  Sparsity: 91.0785%\n",
      "layer   2  Sparsity: 60.7568%\n",
      "layer   3  Sparsity: 85.9774%\n",
      "total_backward_count 1517450 real_backward_count 203400  13.404%\n",
      "epoch-155 lr=['0.0039062'], tr/val_loss:  0.012209/  0.038277, val:  86.25%, val_best:  88.33%, tr:  99.49%, tr_best:  99.90%, epoch time: 55.76 seconds, 0.93 minutes\n",
      "layer   1  Sparsity: 91.0763%\n",
      "layer   2  Sparsity: 60.7488%\n",
      "layer   3  Sparsity: 85.9568%\n",
      "total_backward_count 1527240 real_backward_count 203990  13.357%\n",
      "epoch-156 lr=['0.0039062'], tr/val_loss:  0.012138/  0.040531, val:  86.67%, val_best:  88.33%, tr:  99.49%, tr_best:  99.90%, epoch time: 55.34 seconds, 0.92 minutes\n",
      "layer   1  Sparsity: 91.0940%\n",
      "layer   2  Sparsity: 60.7819%\n",
      "layer   3  Sparsity: 85.9333%\n",
      "total_backward_count 1537030 real_backward_count 204586  13.310%\n",
      "epoch-157 lr=['0.0039062'], tr/val_loss:  0.012330/  0.039334, val:  84.17%, val_best:  88.33%, tr:  99.39%, tr_best:  99.90%, epoch time: 55.27 seconds, 0.92 minutes\n",
      "layer   1  Sparsity: 91.0326%\n",
      "layer   2  Sparsity: 60.7925%\n",
      "layer   3  Sparsity: 85.9524%\n",
      "total_backward_count 1546820 real_backward_count 205172  13.264%\n",
      "epoch-158 lr=['0.0039062'], tr/val_loss:  0.011772/  0.040348, val:  84.17%, val_best:  88.33%, tr:  99.49%, tr_best:  99.90%, epoch time: 55.75 seconds, 0.93 minutes\n",
      "layer   1  Sparsity: 91.0575%\n",
      "layer   2  Sparsity: 60.8685%\n",
      "layer   3  Sparsity: 85.9728%\n",
      "total_backward_count 1556610 real_backward_count 205727  13.216%\n",
      "epoch-159 lr=['0.0039062'], tr/val_loss:  0.012545/  0.040099, val:  85.00%, val_best:  88.33%, tr:  99.08%, tr_best:  99.90%, epoch time: 55.31 seconds, 0.92 minutes\n",
      "layer   1  Sparsity: 91.0647%\n",
      "layer   2  Sparsity: 60.7471%\n",
      "layer   3  Sparsity: 86.0035%\n",
      "total_backward_count 1566400 real_backward_count 206339  13.173%\n",
      "epoch-160 lr=['0.0039062'], tr/val_loss:  0.012348/  0.038437, val:  87.92%, val_best:  88.33%, tr:  99.08%, tr_best:  99.90%, epoch time: 55.50 seconds, 0.93 minutes\n",
      "layer   1  Sparsity: 91.0537%\n",
      "layer   2  Sparsity: 60.7238%\n",
      "layer   3  Sparsity: 85.9715%\n",
      "total_backward_count 1576190 real_backward_count 206945  13.129%\n",
      "epoch-161 lr=['0.0039062'], tr/val_loss:  0.013067/  0.036981, val:  88.75%, val_best:  88.75%, tr:  99.08%, tr_best:  99.90%, epoch time: 55.98 seconds, 0.93 minutes\n",
      "layer   1  Sparsity: 91.0670%\n",
      "layer   2  Sparsity: 60.7665%\n",
      "layer   3  Sparsity: 85.9733%\n",
      "total_backward_count 1585980 real_backward_count 207627  13.091%\n",
      "epoch-162 lr=['0.0039062'], tr/val_loss:  0.011598/  0.038264, val:  83.75%, val_best:  88.75%, tr:  99.39%, tr_best:  99.90%, epoch time: 56.65 seconds, 0.94 minutes\n",
      "layer   1  Sparsity: 91.0748%\n",
      "layer   2  Sparsity: 60.6772%\n",
      "layer   3  Sparsity: 86.0039%\n",
      "total_backward_count 1595770 real_backward_count 208196  13.047%\n",
      "epoch-163 lr=['0.0039062'], tr/val_loss:  0.012332/  0.039194, val:  85.83%, val_best:  88.75%, tr:  99.39%, tr_best:  99.90%, epoch time: 55.92 seconds, 0.93 minutes\n",
      "layer   1  Sparsity: 91.0794%\n",
      "layer   2  Sparsity: 60.6639%\n",
      "layer   3  Sparsity: 86.0605%\n",
      "total_backward_count 1605560 real_backward_count 208835  13.007%\n",
      "epoch-164 lr=['0.0039062'], tr/val_loss:  0.012047/  0.039865, val:  85.83%, val_best:  88.75%, tr:  99.28%, tr_best:  99.90%, epoch time: 55.59 seconds, 0.93 minutes\n",
      "layer   1  Sparsity: 91.1069%\n",
      "layer   2  Sparsity: 60.7277%\n",
      "layer   3  Sparsity: 86.0463%\n",
      "total_backward_count 1615350 real_backward_count 209421  12.964%\n",
      "epoch-165 lr=['0.0039062'], tr/val_loss:  0.011837/  0.040698, val:  85.83%, val_best:  88.75%, tr:  99.80%, tr_best:  99.90%, epoch time: 55.80 seconds, 0.93 minutes\n",
      "layer   1  Sparsity: 91.0075%\n",
      "layer   2  Sparsity: 60.7527%\n",
      "layer   3  Sparsity: 86.0736%\n",
      "total_backward_count 1625140 real_backward_count 210032  12.924%\n",
      "epoch-166 lr=['0.0039062'], tr/val_loss:  0.011426/  0.039330, val:  85.42%, val_best:  88.75%, tr:  99.28%, tr_best:  99.90%, epoch time: 55.79 seconds, 0.93 minutes\n",
      "layer   1  Sparsity: 91.0355%\n",
      "layer   2  Sparsity: 60.7405%\n",
      "layer   3  Sparsity: 86.1099%\n",
      "total_backward_count 1634930 real_backward_count 210582  12.880%\n",
      "epoch-167 lr=['0.0039062'], tr/val_loss:  0.011557/  0.038724, val:  85.83%, val_best:  88.75%, tr:  99.28%, tr_best:  99.90%, epoch time: 55.92 seconds, 0.93 minutes\n",
      "layer   1  Sparsity: 91.1202%\n",
      "layer   2  Sparsity: 60.6476%\n",
      "layer   3  Sparsity: 86.1082%\n",
      "total_backward_count 1644720 real_backward_count 211163  12.839%\n",
      "epoch-168 lr=['0.0039062'], tr/val_loss:  0.010739/  0.038834, val:  86.67%, val_best:  88.75%, tr:  99.69%, tr_best:  99.90%, epoch time: 56.01 seconds, 0.93 minutes\n",
      "layer   1  Sparsity: 91.0685%\n",
      "layer   2  Sparsity: 60.6373%\n",
      "layer   3  Sparsity: 86.1244%\n",
      "total_backward_count 1654510 real_backward_count 211677  12.794%\n",
      "epoch-169 lr=['0.0039062'], tr/val_loss:  0.011525/  0.039955, val:  86.25%, val_best:  88.75%, tr:  99.49%, tr_best:  99.90%, epoch time: 55.42 seconds, 0.92 minutes\n",
      "layer   1  Sparsity: 91.0803%\n",
      "layer   2  Sparsity: 60.6491%\n",
      "layer   3  Sparsity: 86.1641%\n",
      "total_backward_count 1664300 real_backward_count 212242  12.753%\n",
      "epoch-170 lr=['0.0039062'], tr/val_loss:  0.011209/  0.040830, val:  84.58%, val_best:  88.75%, tr:  99.39%, tr_best:  99.90%, epoch time: 55.62 seconds, 0.93 minutes\n",
      "layer   1  Sparsity: 91.0898%\n",
      "layer   2  Sparsity: 60.5952%\n",
      "layer   3  Sparsity: 86.2059%\n",
      "total_backward_count 1674090 real_backward_count 212802  12.712%\n",
      "epoch-171 lr=['0.0039062'], tr/val_loss:  0.011981/  0.038542, val:  86.25%, val_best:  88.75%, tr:  99.49%, tr_best:  99.90%, epoch time: 56.29 seconds, 0.94 minutes\n",
      "layer   1  Sparsity: 91.0735%\n",
      "layer   2  Sparsity: 60.6463%\n",
      "layer   3  Sparsity: 86.2789%\n",
      "total_backward_count 1683880 real_backward_count 213403  12.673%\n",
      "epoch-172 lr=['0.0039062'], tr/val_loss:  0.011322/  0.038617, val:  86.67%, val_best:  88.75%, tr:  99.49%, tr_best:  99.90%, epoch time: 56.29 seconds, 0.94 minutes\n",
      "layer   1  Sparsity: 91.0854%\n",
      "layer   2  Sparsity: 60.5359%\n",
      "layer   3  Sparsity: 86.2903%\n",
      "total_backward_count 1693670 real_backward_count 213974  12.634%\n",
      "epoch-173 lr=['0.0039062'], tr/val_loss:  0.010805/  0.036902, val:  90.00%, val_best:  90.00%, tr:  99.59%, tr_best:  99.90%, epoch time: 56.04 seconds, 0.93 minutes\n",
      "layer   1  Sparsity: 91.0872%\n",
      "layer   2  Sparsity: 60.5561%\n",
      "layer   3  Sparsity: 86.3003%\n",
      "total_backward_count 1703460 real_backward_count 214485  12.591%\n",
      "epoch-174 lr=['0.0039062'], tr/val_loss:  0.011166/  0.037552, val:  87.50%, val_best:  90.00%, tr:  99.49%, tr_best:  99.90%, epoch time: 55.94 seconds, 0.93 minutes\n",
      "layer   1  Sparsity: 91.0654%\n",
      "layer   2  Sparsity: 60.6378%\n",
      "layer   3  Sparsity: 86.3446%\n",
      "total_backward_count 1713250 real_backward_count 215023  12.551%\n",
      "epoch-175 lr=['0.0039062'], tr/val_loss:  0.010726/  0.038449, val:  86.25%, val_best:  90.00%, tr:  98.98%, tr_best:  99.90%, epoch time: 55.49 seconds, 0.92 minutes\n",
      "layer   1  Sparsity: 91.1246%\n",
      "layer   2  Sparsity: 60.7083%\n",
      "layer   3  Sparsity: 86.3627%\n",
      "total_backward_count 1723040 real_backward_count 215533  12.509%\n",
      "epoch-176 lr=['0.0039062'], tr/val_loss:  0.010900/  0.040819, val:  83.75%, val_best:  90.00%, tr:  99.90%, tr_best:  99.90%, epoch time: 55.38 seconds, 0.92 minutes\n",
      "layer   1  Sparsity: 91.0642%\n",
      "layer   2  Sparsity: 60.6625%\n",
      "layer   3  Sparsity: 86.3958%\n",
      "total_backward_count 1732830 real_backward_count 216047  12.468%\n",
      "epoch-177 lr=['0.0039062'], tr/val_loss:  0.010945/  0.038071, val:  89.58%, val_best:  90.00%, tr:  99.59%, tr_best:  99.90%, epoch time: 56.00 seconds, 0.93 minutes\n",
      "layer   1  Sparsity: 91.0859%\n",
      "layer   2  Sparsity: 60.5266%\n",
      "layer   3  Sparsity: 86.4811%\n",
      "total_backward_count 1742620 real_backward_count 216577  12.428%\n",
      "epoch-178 lr=['0.0039062'], tr/val_loss:  0.010801/  0.039498, val:  85.42%, val_best:  90.00%, tr:  99.49%, tr_best:  99.90%, epoch time: 56.48 seconds, 0.94 minutes\n",
      "layer   1  Sparsity: 91.0827%\n",
      "layer   2  Sparsity: 60.5439%\n",
      "layer   3  Sparsity: 86.4950%\n",
      "total_backward_count 1752410 real_backward_count 217085  12.388%\n",
      "epoch-179 lr=['0.0039062'], tr/val_loss:  0.010673/  0.037595, val:  88.75%, val_best:  90.00%, tr:  99.59%, tr_best:  99.90%, epoch time: 55.89 seconds, 0.93 minutes\n",
      "layer   1  Sparsity: 91.0807%\n",
      "layer   2  Sparsity: 60.5879%\n",
      "layer   3  Sparsity: 86.5022%\n",
      "total_backward_count 1762200 real_backward_count 217611  12.349%\n",
      "epoch-180 lr=['0.0039062'], tr/val_loss:  0.010256/  0.037503, val:  86.67%, val_best:  90.00%, tr:  99.69%, tr_best:  99.90%, epoch time: 56.01 seconds, 0.93 minutes\n",
      "layer   1  Sparsity: 91.0718%\n",
      "layer   2  Sparsity: 60.5264%\n",
      "layer   3  Sparsity: 86.5370%\n",
      "total_backward_count 1771990 real_backward_count 218102  12.308%\n",
      "epoch-181 lr=['0.0039062'], tr/val_loss:  0.010426/  0.037262, val:  88.75%, val_best:  90.00%, tr:  99.69%, tr_best:  99.90%, epoch time: 55.85 seconds, 0.93 minutes\n",
      "layer   1  Sparsity: 91.0972%\n",
      "layer   2  Sparsity: 60.5943%\n",
      "layer   3  Sparsity: 86.5961%\n",
      "total_backward_count 1781780 real_backward_count 218571  12.267%\n",
      "epoch-182 lr=['0.0039062'], tr/val_loss:  0.009986/  0.039911, val:  83.75%, val_best:  90.00%, tr:  99.59%, tr_best:  99.90%, epoch time: 56.16 seconds, 0.94 minutes\n",
      "layer   1  Sparsity: 91.0358%\n",
      "layer   2  Sparsity: 60.5067%\n",
      "layer   3  Sparsity: 86.6224%\n",
      "total_backward_count 1791570 real_backward_count 219041  12.226%\n",
      "epoch-183 lr=['0.0039062'], tr/val_loss:  0.010854/  0.038881, val:  87.50%, val_best:  90.00%, tr:  99.39%, tr_best:  99.90%, epoch time: 55.40 seconds, 0.92 minutes\n",
      "layer   1  Sparsity: 91.0298%\n",
      "layer   2  Sparsity: 60.5573%\n",
      "layer   3  Sparsity: 86.5884%\n",
      "total_backward_count 1801360 real_backward_count 219571  12.189%\n",
      "epoch-184 lr=['0.0039062'], tr/val_loss:  0.010741/  0.037668, val:  89.17%, val_best:  90.00%, tr:  99.59%, tr_best:  99.90%, epoch time: 55.87 seconds, 0.93 minutes\n",
      "layer   1  Sparsity: 91.1148%\n",
      "layer   2  Sparsity: 60.5912%\n",
      "layer   3  Sparsity: 86.6268%\n",
      "total_backward_count 1811150 real_backward_count 220113  12.153%\n",
      "epoch-185 lr=['0.0039062'], tr/val_loss:  0.010408/  0.037557, val:  87.50%, val_best:  90.00%, tr:  99.59%, tr_best:  99.90%, epoch time: 56.11 seconds, 0.94 minutes\n",
      "layer   1  Sparsity: 91.0479%\n",
      "layer   2  Sparsity: 60.5744%\n",
      "layer   3  Sparsity: 86.6274%\n",
      "total_backward_count 1820940 real_backward_count 220606  12.115%\n",
      "epoch-186 lr=['0.0039062'], tr/val_loss:  0.011092/  0.037780, val:  86.67%, val_best:  90.00%, tr:  99.59%, tr_best:  99.90%, epoch time: 56.31 seconds, 0.94 minutes\n",
      "layer   1  Sparsity: 91.0597%\n",
      "layer   2  Sparsity: 60.5320%\n",
      "layer   3  Sparsity: 86.7023%\n",
      "total_backward_count 1830730 real_backward_count 221156  12.080%\n",
      "epoch-187 lr=['0.0039062'], tr/val_loss:  0.010529/  0.039462, val:  85.00%, val_best:  90.00%, tr:  99.49%, tr_best:  99.90%, epoch time: 56.28 seconds, 0.94 minutes\n",
      "layer   1  Sparsity: 91.0723%\n",
      "layer   2  Sparsity: 60.6607%\n",
      "layer   3  Sparsity: 86.6574%\n",
      "total_backward_count 1840520 real_backward_count 221696  12.045%\n",
      "epoch-188 lr=['0.0039062'], tr/val_loss:  0.010637/  0.038388, val:  86.25%, val_best:  90.00%, tr:  99.80%, tr_best:  99.90%, epoch time: 55.38 seconds, 0.92 minutes\n",
      "layer   1  Sparsity: 91.0650%\n",
      "layer   2  Sparsity: 60.6050%\n",
      "layer   3  Sparsity: 86.6888%\n",
      "total_backward_count 1850310 real_backward_count 222189  12.008%\n",
      "epoch-189 lr=['0.0039062'], tr/val_loss:  0.010483/  0.039578, val:  86.67%, val_best:  90.00%, tr:  99.59%, tr_best:  99.90%, epoch time: 55.57 seconds, 0.93 minutes\n",
      "layer   1  Sparsity: 91.0590%\n",
      "layer   2  Sparsity: 60.5042%\n",
      "layer   3  Sparsity: 86.7534%\n",
      "total_backward_count 1860100 real_backward_count 222680  11.971%\n",
      "epoch-190 lr=['0.0039062'], tr/val_loss:  0.010839/  0.039146, val:  87.92%, val_best:  90.00%, tr:  99.39%, tr_best:  99.90%, epoch time: 55.52 seconds, 0.93 minutes\n",
      "layer   1  Sparsity: 91.0198%\n",
      "layer   2  Sparsity: 60.5767%\n",
      "layer   3  Sparsity: 86.7211%\n",
      "total_backward_count 1869890 real_backward_count 223207  11.937%\n",
      "epoch-191 lr=['0.0039062'], tr/val_loss:  0.010341/  0.037789, val:  87.92%, val_best:  90.00%, tr:  99.69%, tr_best:  99.90%, epoch time: 55.51 seconds, 0.93 minutes\n",
      "layer   1  Sparsity: 91.0691%\n",
      "layer   2  Sparsity: 60.6162%\n",
      "layer   3  Sparsity: 86.7066%\n",
      "total_backward_count 1879680 real_backward_count 223720  11.902%\n",
      "epoch-192 lr=['0.0039062'], tr/val_loss:  0.010826/  0.036988, val:  87.50%, val_best:  90.00%, tr:  99.80%, tr_best:  99.90%, epoch time: 56.01 seconds, 0.93 minutes\n",
      "layer   1  Sparsity: 91.0317%\n",
      "layer   2  Sparsity: 60.7268%\n",
      "layer   3  Sparsity: 86.7859%\n",
      "total_backward_count 1889470 real_backward_count 224258  11.869%\n",
      "epoch-193 lr=['0.0039062'], tr/val_loss:  0.010271/  0.038017, val:  85.42%, val_best:  90.00%, tr:  99.39%, tr_best:  99.90%, epoch time: 56.67 seconds, 0.94 minutes\n",
      "layer   1  Sparsity: 91.0831%\n",
      "layer   2  Sparsity: 60.6785%\n",
      "layer   3  Sparsity: 86.7644%\n",
      "total_backward_count 1899260 real_backward_count 224766  11.834%\n",
      "epoch-194 lr=['0.0039062'], tr/val_loss:  0.010683/  0.039634, val:  84.58%, val_best:  90.00%, tr:  99.49%, tr_best:  99.90%, epoch time: 55.07 seconds, 0.92 minutes\n",
      "layer   1  Sparsity: 91.0744%\n",
      "layer   2  Sparsity: 60.7115%\n",
      "layer   3  Sparsity: 86.8066%\n",
      "total_backward_count 1909050 real_backward_count 225291  11.801%\n",
      "epoch-195 lr=['0.0039062'], tr/val_loss:  0.010227/  0.039394, val:  86.67%, val_best:  90.00%, tr:  99.59%, tr_best:  99.90%, epoch time: 55.93 seconds, 0.93 minutes\n",
      "layer   1  Sparsity: 91.0419%\n",
      "layer   2  Sparsity: 60.6896%\n",
      "layer   3  Sparsity: 86.8541%\n",
      "total_backward_count 1918840 real_backward_count 225753  11.765%\n",
      "epoch-196 lr=['0.0039062'], tr/val_loss:  0.009530/  0.039202, val:  87.92%, val_best:  90.00%, tr:  99.90%, tr_best:  99.90%, epoch time: 55.48 seconds, 0.92 minutes\n",
      "layer   1  Sparsity: 91.0745%\n",
      "layer   2  Sparsity: 60.5962%\n",
      "layer   3  Sparsity: 86.8620%\n",
      "total_backward_count 1928630 real_backward_count 226194  11.728%\n",
      "epoch-197 lr=['0.0039062'], tr/val_loss:  0.009913/  0.037295, val:  87.92%, val_best:  90.00%, tr:  99.80%, tr_best:  99.90%, epoch time: 55.83 seconds, 0.93 minutes\n",
      "layer   1  Sparsity: 91.0795%\n",
      "layer   2  Sparsity: 60.5643%\n",
      "layer   3  Sparsity: 86.8720%\n",
      "total_backward_count 1938420 real_backward_count 226643  11.692%\n",
      "epoch-198 lr=['0.0039062'], tr/val_loss:  0.010347/  0.037932, val:  87.92%, val_best:  90.00%, tr:  99.69%, tr_best:  99.90%, epoch time: 55.95 seconds, 0.93 minutes\n",
      "layer   1  Sparsity: 91.0652%\n",
      "layer   2  Sparsity: 60.5035%\n",
      "layer   3  Sparsity: 86.8989%\n",
      "total_backward_count 1948210 real_backward_count 227138  11.659%\n",
      "epoch-199 lr=['0.0039062'], tr/val_loss:  0.009864/  0.037542, val:  85.42%, val_best:  90.00%, tr:  99.80%, tr_best:  99.90%, epoch time: 55.83 seconds, 0.93 minutes\n",
      "layer   1  Sparsity: 91.0546%\n",
      "layer   2  Sparsity: 60.5774%\n",
      "layer   3  Sparsity: 86.9057%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4b876a90035441539f24971dd085a32c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.006 MB of 0.006 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà</td></tr><tr><td>iter_acc</td><td>‚ñà‚ñà‚ñÅ‚ñà‚ñà‚ñà‚ñà‚ñÅ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà</td></tr><tr><td>summary_val_acc</td><td>‚ñÅ‚ñÅ‚ñÑ‚ñÇ‚ñÉ‚ñÇ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÖ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñá‚ñÜ‚ñá‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá</td></tr><tr><td>tr_acc</td><td>‚ñÅ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñá‚ñà‚ñá‚ñà‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà</td></tr><tr><td>tr_epoch_loss</td><td>‚ñà‚ñá‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ</td></tr><tr><td>val_acc_best</td><td>‚ñÅ‚ñÅ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà</td></tr><tr><td>val_acc_now</td><td>‚ñÅ‚ñÅ‚ñÑ‚ñÇ‚ñÉ‚ñÇ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÖ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñá‚ñÜ‚ñá‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá</td></tr><tr><td>val_loss</td><td>‚ñà‚ñá‚ñÜ‚ñÖ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÅ‚ñÅ</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>199</td></tr><tr><td>iter_acc</td><td>1.0</td></tr><tr><td>tr_acc</td><td>0.99796</td></tr><tr><td>tr_epoch_loss</td><td>0.00986</td></tr><tr><td>val_acc_best</td><td>0.9</td></tr><tr><td>val_acc_now</td><td>0.85417</td></tr><tr><td>val_loss</td><td>0.03754</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">northern-sweep-3</strong> at: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/4bf1kkpb' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/4bf1kkpb</a><br/> View project at: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>/data2/bh_wandb/wandb/run-20251120_010533-4bf1kkpb/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require(\"core\")`! See https://wandb.me/wandb-core for more information."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 89j6jxht with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBATCH: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBN_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBPTT_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tDFA_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tIMAGE_SIZE: 14\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tOTTT_input_trace_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tTIME: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tUDA_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \talpha_uda: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbias: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcfg: [200, 200]\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tchaching_on: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tconvTrue_fcFalse: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdata_path: /data2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tddp_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdenoise_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdvs_clipping: 14\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdvs_duration: 25000\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepoch_num: 200\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \texclude_class: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \textra_train_dataset: -1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tinitial_pooling: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlast_lif: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.00390625\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_sg_width: 4\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_decay: 0.5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_init: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_reset: 10000\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_threshold: 0.015625\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmerge_polarities: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmy_seed: 38825\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnet_print: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_workers: 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer_what: SGD\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tpin_memory: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tpre_trained: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tpre_trained_path: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \trate_coding: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tscheduler_name: no\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsingle_step: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsurrogate: hard_sigmoid\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_conv_kernel_size: 3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_conv_padding: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_conv_stride: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_trace_const1: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_trace_const2: 0.5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \ttdBN_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \ttemporal_filter: 5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \ttemporal_filter_accumulation: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \ttrace_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \twhich_data: DVS_GESTURE_TONIC\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.23.0 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.17.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/data2/bh_wandb/wandb/run-20251120_041226-89j6jxht</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/89j6jxht' target=\"_blank\">winter-sweep-4</a></strong> to <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/m41wfhay' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/m41wfhay</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/m41wfhay' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/m41wfhay</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/89j6jxht' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/89j6jxht</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'single_step' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'my_seed' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'TIME' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BATCH' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'IMAGE_SIZE' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'which_data' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'data_path' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'rate_coding' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_init' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_decay' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_threshold' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_reset' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_sg_width' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_conv_kernel_size' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_conv_stride' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_conv_padding' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_trace_const1' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_trace_const2' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'pre_trained' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'convTrue_fcFalse' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'cfg' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'net_print' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'pre_trained_path' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'learning_rate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'epoch_num' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'tdBN_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BN_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'surrogate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BPTT_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'optimizer_what' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'scheduler_name' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'ddp_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'dvs_clipping' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'dvs_duration' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'DFA_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'trace_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'OTTT_input_trace_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'exclude_class' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'merge_polarities' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'denoise_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'extra_train_dataset' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'num_workers' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'chaching_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'pin_memory' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'UDA_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'alpha_uda' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'bias' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'last_lif' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'temporal_filter' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'initial_pooling' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'temporal_filter_accumulation' was locked by 'sweep' (ignored update).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "param {'devices': '3', 'single_step': True, 'unique_name': '20251120_041236_256', 'my_seed': 38825, 'TIME': 10, 'BATCH': 1, 'IMAGE_SIZE': 14, 'which_data': 'DVS_GESTURE_TONIC', 'data_path': '/data2', 'rate_coding': False, 'lif_layer_v_init': 0, 'lif_layer_v_decay': 0.5, 'lif_layer_v_threshold': 0.015625, 'lif_layer_v_reset': 10000, 'lif_layer_sg_width': 4, 'synapse_conv_kernel_size': 3, 'synapse_conv_stride': 1, 'synapse_conv_padding': 1, 'synapse_trace_const1': 1, 'synapse_trace_const2': 0.5, 'pre_trained': False, 'convTrue_fcFalse': False, 'cfg': [200, 200], 'net_print': True, 'pre_trained_path': '', 'learning_rate': 0.00390625, 'epoch_num': 200, 'tdBN_on': False, 'BN_on': False, 'surrogate': 'hard_sigmoid', 'BPTT_on': False, 'optimizer_what': 'SGD', 'scheduler_name': 'no', 'ddp_on': False, 'dvs_clipping': 14, 'dvs_duration': 25000, 'DFA_on': False, 'trace_on': False, 'OTTT_input_trace_on': False, 'exclude_class': True, 'merge_polarities': True, 'denoise_on': False, 'extra_train_dataset': -1, 'num_workers': 2, 'chaching_on': True, 'pin_memory': True, 'UDA_on': False, 'alpha_uda': 1, 'bias': False, 'last_lif': False, 'temporal_filter': 5, 'initial_pooling': 1, 'temporal_filter_accumulation': False, 'quantize_bit_list': [], 'scale_exp': [[999, 998], [999, 999], [999, 999]]} \n",
      "\n",
      "Ïù¥ Îç∞Ïù¥ÌÑ∞ÏÖãÏùò Îç∞Ïù¥ÌÑ∞ Í∞úÏàòÎäî 979 ÏûÖÎãàÎã§. (test setÏùÄ ÏïàÎ∞îÎÄåÍ≤å Ìï¥ÎÜ®Îã§ ÏïåÏ†ú)\n",
      "Ïù¥ Îç∞Ïù¥ÌÑ∞ÏÖãÏùò Îç∞Ïù¥ÌÑ∞ Í∞úÏàòÎäî 240 ÏûÖÎãàÎã§. (test setÏùÄ ÏïàÎ∞îÎÄåÍ≤å Ìï¥ÎÜ®Îã§ ÏïåÏ†ú)\n",
      "dataset_hash = 0e8a8f2d81b4fe037308b5d792c4a037\n",
      "cache path exists\n",
      "\n",
      "len(train_loader): 979 BATCH: 1 train_data_count: 979\n",
      "len(test_loader): 240 BATCH: 1\n",
      "\n",
      "device ==> cuda\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " layer_count 1\n",
      "weight bias bit 0\n",
      "weight exp, bias exp None None\n",
      "bit_for_output 0 exp_for_output None \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "LIF 1 sg_bit 0\n",
      "\n",
      "\n",
      "++++++++++++++++++++++++\n",
      "\n",
      " lif layer 1 v_bit: 0, v_exp: None\n",
      "\n",
      "++++++++++++++++++++++++++++++++++++++++++++++\n",
      "\n",
      "\n",
      "\n",
      " layer_count 2\n",
      "weight bias bit 0\n",
      "weight exp, bias exp None None\n",
      "bit_for_output 0 exp_for_output None \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "LIF 2 sg_bit 0\n",
      "\n",
      "\n",
      "++++++++++++++++++++++++\n",
      "\n",
      " lif layer 2 v_bit: 0, v_exp: None\n",
      "\n",
      "++++++++++++++++++++++++++++++++++++++++++++++\n",
      "\n",
      "\n",
      "\n",
      " layer_count 3\n",
      "weight bias bit 0\n",
      "weight exp, bias exp None None\n",
      "bit_for_output 0 exp_for_output None \n",
      "\n",
      "\n",
      "\n",
      "DataParallel(\n",
      "  (module): REBORN_MY_SNN_FC(\n",
      "    (layers): REBORN_MY_Sequential(\n",
      "      (0): DimChanger_for_FC()\n",
      "      (1): SYNAPSE_FC(in_features=980, out_features=200, TIME=10, bias=False, sstep=True, time_different_weight=False, layer_count=1, quantize_bit_list=[], scale_exp=[[999, 998], [999, 999], [999, 999]], ANPI_MODE=False)\n",
      "      (2): LIF_layer(v_init=0, v_decay=0.5, v_threshold=0.015625, v_reset=10000, sg_width=4, surrogate=hard_sigmoid, BPTT_on=False, trace_const1=1, trace_const2=0.5, TIME=10, sstep=True, trace_on=False, layer_count=1, scale_exp=[[999, 998], [999, 999], [999, 999]], ANPI_MODE=False)\n",
      "      (3): SYNAPSE_FC(in_features=200, out_features=200, TIME=10, bias=False, sstep=True, time_different_weight=False, layer_count=2, quantize_bit_list=[], scale_exp=[[999, 998], [999, 999], [999, 999]], ANPI_MODE=False)\n",
      "      (4): LIF_layer(v_init=0, v_decay=0.5, v_threshold=0.015625, v_reset=10000, sg_width=4, surrogate=hard_sigmoid, BPTT_on=False, trace_const1=1, trace_const2=0.5, TIME=10, sstep=True, trace_on=False, layer_count=2, scale_exp=[[999, 998], [999, 999], [999, 999]], ANPI_MODE=False)\n",
      "      (5): SYNAPSE_FC(in_features=200, out_features=10, TIME=10, bias=False, sstep=True, time_different_weight=False, layer_count=3, quantize_bit_list=[], scale_exp=[[999, 998], [999, 999], [999, 999]], ANPI_MODE=False)\n",
      "    )\n",
      "  )\n",
      ")\n",
      "\n",
      "========================================================\n",
      "Trainable parameters: 238,000\n",
      "========================================================\n",
      "\n",
      "MySGD (\n",
      "Parameter Group 0\n",
      "    lr: 0.00390625\n",
      "    momentum: 0.0\n",
      ")\n",
      "total_backward_count 0 real_backward_count 0   0.000%\n",
      "epoch-0   lr=['0.0039062'], tr/val_loss:  0.068434/  0.087023, val:  37.50%, val_best:  37.50%, tr:  73.65%, tr_best:  73.65%, epoch time: 55.43 seconds, 0.92 minutes\n",
      "layer   1  Sparsity: 91.0322%\n",
      "layer   2  Sparsity: 58.5463%\n",
      "layer   3  Sparsity: 64.0162%\n",
      "total_backward_count 9790 real_backward_count 3685  37.640%\n",
      "epoch-1   lr=['0.0039062'], tr/val_loss:  0.053038/  0.072081, val:  57.08%, val_best:  57.08%, tr:  81.61%, tr_best:  81.61%, epoch time: 55.81 seconds, 0.93 minutes\n",
      "layer   1  Sparsity: 91.1122%\n",
      "layer   2  Sparsity: 58.6245%\n",
      "layer   3  Sparsity: 64.8322%\n",
      "total_backward_count 19580 real_backward_count 6441  32.896%\n",
      "epoch-2   lr=['0.0039062'], tr/val_loss:  0.049240/  0.070818, val:  55.83%, val_best:  57.08%, tr:  82.53%, tr_best:  82.53%, epoch time: 55.46 seconds, 0.92 minutes\n",
      "layer   1  Sparsity: 91.0648%\n",
      "layer   2  Sparsity: 58.6903%\n",
      "layer   3  Sparsity: 65.0998%\n",
      "total_backward_count 29370 real_backward_count 8967  30.531%\n",
      "epoch-3   lr=['0.0039062'], tr/val_loss:  0.047487/  0.065948, val:  61.67%, val_best:  61.67%, tr:  83.15%, tr_best:  83.15%, epoch time: 55.69 seconds, 0.93 minutes\n",
      "layer   1  Sparsity: 91.1051%\n",
      "layer   2  Sparsity: 58.5711%\n",
      "layer   3  Sparsity: 65.3070%\n",
      "total_backward_count 39160 real_backward_count 11396  29.101%\n",
      "epoch-4   lr=['0.0039062'], tr/val_loss:  0.045759/  0.062912, val:  61.67%, val_best:  61.67%, tr:  82.53%, tr_best:  83.15%, epoch time: 55.98 seconds, 0.93 minutes\n",
      "layer   1  Sparsity: 91.0580%\n",
      "layer   2  Sparsity: 58.3406%\n",
      "layer   3  Sparsity: 65.7909%\n",
      "total_backward_count 48950 real_backward_count 13778  28.147%\n",
      "epoch-5   lr=['0.0039062'], tr/val_loss:  0.045782/  0.064103, val:  63.75%, val_best:  63.75%, tr:  82.94%, tr_best:  83.15%, epoch time: 55.92 seconds, 0.93 minutes\n",
      "layer   1  Sparsity: 91.0352%\n",
      "layer   2  Sparsity: 58.2263%\n",
      "layer   3  Sparsity: 66.3467%\n",
      "total_backward_count 58740 real_backward_count 16233  27.635%\n",
      "epoch-6   lr=['0.0039062'], tr/val_loss:  0.044611/  0.058830, val:  67.50%, val_best:  67.50%, tr:  82.33%, tr_best:  83.15%, epoch time: 56.81 seconds, 0.95 minutes\n",
      "layer   1  Sparsity: 91.0899%\n",
      "layer   2  Sparsity: 58.1213%\n",
      "layer   3  Sparsity: 67.0907%\n",
      "total_backward_count 68530 real_backward_count 18669  27.242%\n",
      "epoch-7   lr=['0.0039062'], tr/val_loss:  0.043426/  0.060453, val:  62.50%, val_best:  67.50%, tr:  83.04%, tr_best:  83.15%, epoch time: 50.71 seconds, 0.85 minutes\n",
      "layer   1  Sparsity: 91.0618%\n",
      "layer   2  Sparsity: 58.0227%\n",
      "layer   3  Sparsity: 67.8115%\n",
      "total_backward_count 78320 real_backward_count 20976  26.782%\n",
      "epoch-8   lr=['0.0039062'], tr/val_loss:  0.042434/  0.063285, val:  61.67%, val_best:  67.50%, tr:  83.04%, tr_best:  83.15%, epoch time: 55.91 seconds, 0.93 minutes\n",
      "layer   1  Sparsity: 91.0638%\n",
      "layer   2  Sparsity: 57.8452%\n",
      "layer   3  Sparsity: 68.6440%\n",
      "total_backward_count 88110 real_backward_count 23326  26.474%\n",
      "epoch-9   lr=['0.0039062'], tr/val_loss:  0.042798/  0.060294, val:  63.33%, val_best:  67.50%, tr:  84.07%, tr_best:  84.07%, epoch time: 56.15 seconds, 0.94 minutes\n",
      "layer   1  Sparsity: 91.0948%\n",
      "layer   2  Sparsity: 57.7871%\n",
      "layer   3  Sparsity: 69.1700%\n",
      "total_backward_count 97900 real_backward_count 25681  26.232%\n",
      "epoch-10  lr=['0.0039062'], tr/val_loss:  0.042106/  0.060513, val:  62.50%, val_best:  67.50%, tr:  82.53%, tr_best:  84.07%, epoch time: 55.40 seconds, 0.92 minutes\n",
      "layer   1  Sparsity: 91.1030%\n",
      "layer   2  Sparsity: 57.7388%\n",
      "layer   3  Sparsity: 70.0333%\n",
      "total_backward_count 107690 real_backward_count 28069  26.065%\n",
      "epoch-11  lr=['0.0039062'], tr/val_loss:  0.041454/  0.061740, val:  63.33%, val_best:  67.50%, tr:  83.25%, tr_best:  84.07%, epoch time: 56.30 seconds, 0.94 minutes\n",
      "layer   1  Sparsity: 91.0542%\n",
      "layer   2  Sparsity: 57.6185%\n",
      "layer   3  Sparsity: 70.4693%\n",
      "total_backward_count 117480 real_backward_count 30431  25.903%\n",
      "epoch-12  lr=['0.0039062'], tr/val_loss:  0.040811/  0.058232, val:  67.92%, val_best:  67.92%, tr:  83.04%, tr_best:  84.07%, epoch time: 56.03 seconds, 0.93 minutes\n",
      "layer   1  Sparsity: 91.0722%\n",
      "layer   2  Sparsity: 57.5224%\n",
      "layer   3  Sparsity: 71.1023%\n",
      "total_backward_count 127270 real_backward_count 32752  25.734%\n",
      "epoch-13  lr=['0.0039062'], tr/val_loss:  0.040260/  0.060773, val:  64.58%, val_best:  67.92%, tr:  82.53%, tr_best:  84.07%, epoch time: 55.86 seconds, 0.93 minutes\n",
      "layer   1  Sparsity: 91.0719%\n",
      "layer   2  Sparsity: 57.4991%\n",
      "layer   3  Sparsity: 71.4890%\n",
      "total_backward_count 137060 real_backward_count 34993  25.531%\n",
      "epoch-14  lr=['0.0039062'], tr/val_loss:  0.040188/  0.058565, val:  61.67%, val_best:  67.92%, tr:  83.45%, tr_best:  84.07%, epoch time: 56.18 seconds, 0.94 minutes\n",
      "layer   1  Sparsity: 91.0765%\n",
      "layer   2  Sparsity: 57.4723%\n",
      "layer   3  Sparsity: 71.8256%\n",
      "total_backward_count 146850 real_backward_count 37285  25.390%\n",
      "epoch-15  lr=['0.0039062'], tr/val_loss:  0.039712/  0.063494, val:  57.92%, val_best:  67.92%, tr:  83.04%, tr_best:  84.07%, epoch time: 56.06 seconds, 0.93 minutes\n",
      "layer   1  Sparsity: 91.0680%\n",
      "layer   2  Sparsity: 57.4756%\n",
      "layer   3  Sparsity: 72.4484%\n",
      "total_backward_count 156640 real_backward_count 39594  25.277%\n",
      "epoch-16  lr=['0.0039062'], tr/val_loss:  0.039273/  0.060515, val:  64.58%, val_best:  67.92%, tr:  83.35%, tr_best:  84.07%, epoch time: 55.47 seconds, 0.92 minutes\n",
      "layer   1  Sparsity: 91.0483%\n",
      "layer   2  Sparsity: 57.4157%\n",
      "layer   3  Sparsity: 72.9600%\n",
      "total_backward_count 166430 real_backward_count 41837  25.138%\n",
      "epoch-17  lr=['0.0039062'], tr/val_loss:  0.039257/  0.055440, val:  66.25%, val_best:  67.92%, tr:  83.96%, tr_best:  84.07%, epoch time: 56.11 seconds, 0.94 minutes\n",
      "layer   1  Sparsity: 91.0933%\n",
      "layer   2  Sparsity: 57.3220%\n",
      "layer   3  Sparsity: 73.2383%\n",
      "total_backward_count 176220 real_backward_count 44047  24.995%\n",
      "epoch-18  lr=['0.0039062'], tr/val_loss:  0.039467/  0.058304, val:  67.92%, val_best:  67.92%, tr:  84.07%, tr_best:  84.07%, epoch time: 55.70 seconds, 0.93 minutes\n",
      "layer   1  Sparsity: 91.0452%\n",
      "layer   2  Sparsity: 57.3019%\n",
      "layer   3  Sparsity: 73.7826%\n",
      "total_backward_count 186010 real_backward_count 46360  24.923%\n",
      "epoch-19  lr=['0.0039062'], tr/val_loss:  0.037958/  0.057162, val:  67.50%, val_best:  67.92%, tr:  84.47%, tr_best:  84.47%, epoch time: 55.97 seconds, 0.93 minutes\n",
      "layer   1  Sparsity: 91.0914%\n",
      "layer   2  Sparsity: 57.3154%\n",
      "layer   3  Sparsity: 74.0810%\n",
      "total_backward_count 195800 real_backward_count 48542  24.792%\n",
      "epoch-20  lr=['0.0039062'], tr/val_loss:  0.037834/  0.058280, val:  65.83%, val_best:  67.92%, tr:  85.39%, tr_best:  85.39%, epoch time: 55.61 seconds, 0.93 minutes\n",
      "layer   1  Sparsity: 91.0954%\n",
      "layer   2  Sparsity: 57.3487%\n",
      "layer   3  Sparsity: 74.4287%\n",
      "total_backward_count 205590 real_backward_count 50719  24.670%\n",
      "epoch-21  lr=['0.0039062'], tr/val_loss:  0.037853/  0.059158, val:  69.58%, val_best:  69.58%, tr:  84.17%, tr_best:  85.39%, epoch time: 55.45 seconds, 0.92 minutes\n",
      "layer   1  Sparsity: 91.0754%\n",
      "layer   2  Sparsity: 57.3246%\n",
      "layer   3  Sparsity: 74.7796%\n",
      "total_backward_count 215380 real_backward_count 52912  24.567%\n",
      "epoch-22  lr=['0.0039062'], tr/val_loss:  0.037470/  0.058424, val:  66.67%, val_best:  69.58%, tr:  84.98%, tr_best:  85.39%, epoch time: 56.13 seconds, 0.94 minutes\n",
      "layer   1  Sparsity: 91.0505%\n",
      "layer   2  Sparsity: 57.2514%\n",
      "layer   3  Sparsity: 75.3003%\n",
      "total_backward_count 225170 real_backward_count 55095  24.468%\n",
      "epoch-23  lr=['0.0039062'], tr/val_loss:  0.037102/  0.063862, val:  62.08%, val_best:  69.58%, tr:  85.29%, tr_best:  85.39%, epoch time: 56.47 seconds, 0.94 minutes\n",
      "layer   1  Sparsity: 91.0866%\n",
      "layer   2  Sparsity: 57.2756%\n",
      "layer   3  Sparsity: 75.5201%\n",
      "total_backward_count 234960 real_backward_count 57243  24.363%\n",
      "epoch-24  lr=['0.0039062'], tr/val_loss:  0.037328/  0.059409, val:  64.58%, val_best:  69.58%, tr:  84.17%, tr_best:  85.39%, epoch time: 55.91 seconds, 0.93 minutes\n",
      "layer   1  Sparsity: 91.0831%\n",
      "layer   2  Sparsity: 57.1884%\n",
      "layer   3  Sparsity: 75.9429%\n",
      "total_backward_count 244750 real_backward_count 59426  24.280%\n",
      "epoch-25  lr=['0.0039062'], tr/val_loss:  0.036607/  0.055687, val:  64.58%, val_best:  69.58%, tr:  84.07%, tr_best:  85.39%, epoch time: 55.58 seconds, 0.93 minutes\n",
      "layer   1  Sparsity: 91.0681%\n",
      "layer   2  Sparsity: 57.2522%\n",
      "layer   3  Sparsity: 76.2505%\n",
      "total_backward_count 254540 real_backward_count 61575  24.191%\n",
      "epoch-26  lr=['0.0039062'], tr/val_loss:  0.035917/  0.055849, val:  66.67%, val_best:  69.58%, tr:  86.11%, tr_best:  86.11%, epoch time: 55.58 seconds, 0.93 minutes\n",
      "layer   1  Sparsity: 91.1021%\n",
      "layer   2  Sparsity: 57.1741%\n",
      "layer   3  Sparsity: 76.5936%\n",
      "total_backward_count 264330 real_backward_count 63654  24.081%\n",
      "epoch-27  lr=['0.0039062'], tr/val_loss:  0.036003/  0.053623, val:  71.25%, val_best:  71.25%, tr:  85.29%, tr_best:  86.11%, epoch time: 56.25 seconds, 0.94 minutes\n",
      "layer   1  Sparsity: 91.0619%\n",
      "layer   2  Sparsity: 57.1888%\n",
      "layer   3  Sparsity: 76.9007%\n",
      "total_backward_count 274120 real_backward_count 65770  23.993%\n",
      "epoch-28  lr=['0.0039062'], tr/val_loss:  0.036006/  0.053831, val:  69.17%, val_best:  71.25%, tr:  84.98%, tr_best:  86.11%, epoch time: 56.31 seconds, 0.94 minutes\n",
      "layer   1  Sparsity: 91.0925%\n",
      "layer   2  Sparsity: 57.1497%\n",
      "layer   3  Sparsity: 77.2453%\n",
      "total_backward_count 283910 real_backward_count 67897  23.915%\n",
      "epoch-29  lr=['0.0039062'], tr/val_loss:  0.035676/  0.055196, val:  67.50%, val_best:  71.25%, tr:  85.80%, tr_best:  86.11%, epoch time: 55.23 seconds, 0.92 minutes\n",
      "layer   1  Sparsity: 91.0854%\n",
      "layer   2  Sparsity: 57.0595%\n",
      "layer   3  Sparsity: 77.5378%\n",
      "total_backward_count 293700 real_backward_count 69973  23.825%\n",
      "epoch-30  lr=['0.0039062'], tr/val_loss:  0.035453/  0.055972, val:  67.50%, val_best:  71.25%, tr:  85.29%, tr_best:  86.11%, epoch time: 55.81 seconds, 0.93 minutes\n",
      "layer   1  Sparsity: 91.0734%\n",
      "layer   2  Sparsity: 56.9949%\n",
      "layer   3  Sparsity: 77.7661%\n",
      "total_backward_count 303490 real_backward_count 72083  23.751%\n",
      "epoch-31  lr=['0.0039062'], tr/val_loss:  0.035657/  0.056585, val:  68.75%, val_best:  71.25%, tr:  86.11%, tr_best:  86.11%, epoch time: 55.20 seconds, 0.92 minutes\n",
      "layer   1  Sparsity: 91.0582%\n",
      "layer   2  Sparsity: 57.0186%\n",
      "layer   3  Sparsity: 78.0142%\n",
      "total_backward_count 313280 real_backward_count 74177  23.678%\n",
      "epoch-32  lr=['0.0039062'], tr/val_loss:  0.035183/  0.052555, val:  75.00%, val_best:  75.00%, tr:  86.01%, tr_best:  86.11%, epoch time: 55.73 seconds, 0.93 minutes\n",
      "layer   1  Sparsity: 91.1134%\n",
      "layer   2  Sparsity: 57.0375%\n",
      "layer   3  Sparsity: 78.2733%\n",
      "total_backward_count 323070 real_backward_count 76272  23.609%\n",
      "epoch-33  lr=['0.0039062'], tr/val_loss:  0.034762/  0.052800, val:  72.50%, val_best:  75.00%, tr:  86.52%, tr_best:  86.52%, epoch time: 56.20 seconds, 0.94 minutes\n",
      "layer   1  Sparsity: 91.0994%\n",
      "layer   2  Sparsity: 57.0601%\n",
      "layer   3  Sparsity: 78.4112%\n",
      "total_backward_count 332860 real_backward_count 78350  23.538%\n",
      "epoch-34  lr=['0.0039062'], tr/val_loss:  0.034689/  0.055327, val:  74.17%, val_best:  75.00%, tr:  87.23%, tr_best:  87.23%, epoch time: 56.19 seconds, 0.94 minutes\n",
      "layer   1  Sparsity: 91.0623%\n",
      "layer   2  Sparsity: 57.0149%\n",
      "layer   3  Sparsity: 78.5228%\n",
      "total_backward_count 342650 real_backward_count 80359  23.452%\n",
      "epoch-35  lr=['0.0039062'], tr/val_loss:  0.033935/  0.052952, val:  69.17%, val_best:  75.00%, tr:  88.25%, tr_best:  88.25%, epoch time: 55.85 seconds, 0.93 minutes\n",
      "layer   1  Sparsity: 91.0656%\n",
      "layer   2  Sparsity: 56.9254%\n",
      "layer   3  Sparsity: 78.7906%\n",
      "total_backward_count 352440 real_backward_count 82316  23.356%\n",
      "epoch-36  lr=['0.0039062'], tr/val_loss:  0.034483/  0.055895, val:  65.83%, val_best:  75.00%, tr:  86.82%, tr_best:  88.25%, epoch time: 55.40 seconds, 0.92 minutes\n",
      "layer   1  Sparsity: 91.1001%\n",
      "layer   2  Sparsity: 56.9581%\n",
      "layer   3  Sparsity: 78.9998%\n",
      "total_backward_count 362230 real_backward_count 84400  23.300%\n",
      "epoch-37  lr=['0.0039062'], tr/val_loss:  0.033967/  0.057766, val:  69.58%, val_best:  75.00%, tr:  87.54%, tr_best:  88.25%, epoch time: 56.35 seconds, 0.94 minutes\n",
      "layer   1  Sparsity: 91.0989%\n",
      "layer   2  Sparsity: 56.9938%\n",
      "layer   3  Sparsity: 79.2040%\n",
      "total_backward_count 372020 real_backward_count 86389  23.222%\n",
      "epoch-38  lr=['0.0039062'], tr/val_loss:  0.033398/  0.052444, val:  72.08%, val_best:  75.00%, tr:  87.23%, tr_best:  88.25%, epoch time: 55.24 seconds, 0.92 minutes\n",
      "layer   1  Sparsity: 91.0840%\n",
      "layer   2  Sparsity: 57.0147%\n",
      "layer   3  Sparsity: 79.3662%\n",
      "total_backward_count 381810 real_backward_count 88400  23.153%\n",
      "epoch-39  lr=['0.0039062'], tr/val_loss:  0.032806/  0.053936, val:  73.75%, val_best:  75.00%, tr:  87.44%, tr_best:  88.25%, epoch time: 55.69 seconds, 0.93 minutes\n",
      "layer   1  Sparsity: 91.0954%\n",
      "layer   2  Sparsity: 56.9756%\n",
      "layer   3  Sparsity: 79.6159%\n",
      "total_backward_count 391600 real_backward_count 90329  23.067%\n",
      "epoch-40  lr=['0.0039062'], tr/val_loss:  0.032812/  0.052748, val:  70.00%, val_best:  75.00%, tr:  87.74%, tr_best:  88.25%, epoch time: 56.29 seconds, 0.94 minutes\n",
      "layer   1  Sparsity: 91.0815%\n",
      "layer   2  Sparsity: 56.9635%\n",
      "layer   3  Sparsity: 79.8375%\n",
      "total_backward_count 401390 real_backward_count 92298  22.995%\n",
      "epoch-41  lr=['0.0039062'], tr/val_loss:  0.033123/  0.053680, val:  67.50%, val_best:  75.00%, tr:  88.46%, tr_best:  88.46%, epoch time: 55.29 seconds, 0.92 minutes\n",
      "layer   1  Sparsity: 91.0779%\n",
      "layer   2  Sparsity: 56.9772%\n",
      "layer   3  Sparsity: 80.1541%\n",
      "total_backward_count 411180 real_backward_count 94259  22.924%\n",
      "epoch-42  lr=['0.0039062'], tr/val_loss:  0.032144/  0.050954, val:  75.42%, val_best:  75.42%, tr:  88.25%, tr_best:  88.46%, epoch time: 55.38 seconds, 0.92 minutes\n",
      "layer   1  Sparsity: 91.0772%\n",
      "layer   2  Sparsity: 57.0920%\n",
      "layer   3  Sparsity: 80.2596%\n",
      "total_backward_count 420970 real_backward_count 96169  22.845%\n",
      "epoch-43  lr=['0.0039062'], tr/val_loss:  0.031851/  0.053119, val:  74.17%, val_best:  75.42%, tr:  89.07%, tr_best:  89.07%, epoch time: 56.26 seconds, 0.94 minutes\n",
      "layer   1  Sparsity: 91.0913%\n",
      "layer   2  Sparsity: 57.0324%\n",
      "layer   3  Sparsity: 80.3546%\n",
      "total_backward_count 430760 real_backward_count 97989  22.748%\n",
      "epoch-44  lr=['0.0039062'], tr/val_loss:  0.031500/  0.051381, val:  77.08%, val_best:  77.08%, tr:  89.58%, tr_best:  89.58%, epoch time: 55.24 seconds, 0.92 minutes\n",
      "layer   1  Sparsity: 91.1198%\n",
      "layer   2  Sparsity: 57.1013%\n",
      "layer   3  Sparsity: 80.4464%\n",
      "total_backward_count 440550 real_backward_count 99853  22.666%\n",
      "epoch-45  lr=['0.0039062'], tr/val_loss:  0.031029/  0.049821, val:  77.92%, val_best:  77.92%, tr:  88.97%, tr_best:  89.58%, epoch time: 55.16 seconds, 0.92 minutes\n",
      "layer   1  Sparsity: 91.0759%\n",
      "layer   2  Sparsity: 57.0656%\n",
      "layer   3  Sparsity: 80.6674%\n",
      "total_backward_count 450340 real_backward_count 101633  22.568%\n",
      "epoch-46  lr=['0.0039062'], tr/val_loss:  0.031546/  0.058363, val:  63.75%, val_best:  77.92%, tr:  88.97%, tr_best:  89.58%, epoch time: 55.11 seconds, 0.92 minutes\n",
      "layer   1  Sparsity: 91.0382%\n",
      "layer   2  Sparsity: 57.0441%\n",
      "layer   3  Sparsity: 80.9096%\n",
      "total_backward_count 460130 real_backward_count 103484  22.490%\n",
      "epoch-47  lr=['0.0039062'], tr/val_loss:  0.031206/  0.056972, val:  65.00%, val_best:  77.92%, tr:  90.40%, tr_best:  90.40%, epoch time: 55.54 seconds, 0.93 minutes\n",
      "layer   1  Sparsity: 91.0783%\n",
      "layer   2  Sparsity: 57.1119%\n",
      "layer   3  Sparsity: 80.9027%\n",
      "total_backward_count 469920 real_backward_count 105295  22.407%\n",
      "epoch-48  lr=['0.0039062'], tr/val_loss:  0.030450/  0.054625, val:  69.17%, val_best:  77.92%, tr:  89.99%, tr_best:  90.40%, epoch time: 55.46 seconds, 0.92 minutes\n",
      "layer   1  Sparsity: 91.0572%\n",
      "layer   2  Sparsity: 57.1348%\n",
      "layer   3  Sparsity: 80.8872%\n",
      "total_backward_count 479710 real_backward_count 107059  22.317%\n",
      "epoch-49  lr=['0.0039062'], tr/val_loss:  0.030169/  0.051066, val:  77.92%, val_best:  77.92%, tr:  90.09%, tr_best:  90.40%, epoch time: 56.65 seconds, 0.94 minutes\n",
      "layer   1  Sparsity: 91.0618%\n",
      "layer   2  Sparsity: 57.1411%\n",
      "layer   3  Sparsity: 80.9027%\n",
      "total_backward_count 489500 real_backward_count 108819  22.231%\n",
      "epoch-50  lr=['0.0039062'], tr/val_loss:  0.029419/  0.051016, val:  72.50%, val_best:  77.92%, tr:  91.11%, tr_best:  91.11%, epoch time: 56.62 seconds, 0.94 minutes\n",
      "layer   1  Sparsity: 91.1015%\n",
      "layer   2  Sparsity: 57.1751%\n",
      "layer   3  Sparsity: 81.0667%\n",
      "total_backward_count 499290 real_backward_count 110501  22.132%\n",
      "epoch-51  lr=['0.0039062'], tr/val_loss:  0.030084/  0.052013, val:  77.50%, val_best:  77.92%, tr:  91.11%, tr_best:  91.11%, epoch time: 56.31 seconds, 0.94 minutes\n",
      "layer   1  Sparsity: 91.0449%\n",
      "layer   2  Sparsity: 57.1667%\n",
      "layer   3  Sparsity: 81.1773%\n",
      "total_backward_count 509080 real_backward_count 112262  22.052%\n",
      "epoch-52  lr=['0.0039062'], tr/val_loss:  0.029090/  0.048788, val:  82.08%, val_best:  82.08%, tr:  89.89%, tr_best:  91.11%, epoch time: 55.73 seconds, 0.93 minutes\n",
      "layer   1  Sparsity: 91.0921%\n",
      "layer   2  Sparsity: 57.1167%\n",
      "layer   3  Sparsity: 81.3723%\n",
      "total_backward_count 518870 real_backward_count 113932  21.958%\n",
      "epoch-53  lr=['0.0039062'], tr/val_loss:  0.028288/  0.052836, val:  72.92%, val_best:  82.08%, tr:  91.93%, tr_best:  91.93%, epoch time: 56.07 seconds, 0.93 minutes\n",
      "layer   1  Sparsity: 91.0527%\n",
      "layer   2  Sparsity: 57.1559%\n",
      "layer   3  Sparsity: 81.4166%\n",
      "total_backward_count 528660 real_backward_count 115544  21.856%\n",
      "epoch-54  lr=['0.0039062'], tr/val_loss:  0.028687/  0.053516, val:  67.08%, val_best:  82.08%, tr:  92.13%, tr_best:  92.13%, epoch time: 56.07 seconds, 0.93 minutes\n",
      "layer   1  Sparsity: 91.0923%\n",
      "layer   2  Sparsity: 57.1378%\n",
      "layer   3  Sparsity: 81.4297%\n",
      "total_backward_count 538450 real_backward_count 117220  21.770%\n",
      "epoch-55  lr=['0.0039062'], tr/val_loss:  0.028535/  0.051849, val:  74.58%, val_best:  82.08%, tr:  92.65%, tr_best:  92.65%, epoch time: 55.26 seconds, 0.92 minutes\n",
      "layer   1  Sparsity: 91.0339%\n",
      "layer   2  Sparsity: 57.2066%\n",
      "layer   3  Sparsity: 81.3791%\n",
      "total_backward_count 548240 real_backward_count 118874  21.683%\n",
      "epoch-56  lr=['0.0039062'], tr/val_loss:  0.028264/  0.051509, val:  70.00%, val_best:  82.08%, tr:  92.24%, tr_best:  92.65%, epoch time: 55.77 seconds, 0.93 minutes\n",
      "layer   1  Sparsity: 91.0714%\n",
      "layer   2  Sparsity: 57.1054%\n",
      "layer   3  Sparsity: 81.5932%\n",
      "total_backward_count 558030 real_backward_count 120534  21.600%\n",
      "epoch-57  lr=['0.0039062'], tr/val_loss:  0.028399/  0.050990, val:  78.33%, val_best:  82.08%, tr:  92.34%, tr_best:  92.65%, epoch time: 55.49 seconds, 0.92 minutes\n",
      "layer   1  Sparsity: 91.0625%\n",
      "layer   2  Sparsity: 57.2007%\n",
      "layer   3  Sparsity: 81.6548%\n",
      "total_backward_count 567820 real_backward_count 122195  21.520%\n",
      "epoch-58  lr=['0.0039062'], tr/val_loss:  0.027131/  0.049518, val:  80.83%, val_best:  82.08%, tr:  92.75%, tr_best:  92.75%, epoch time: 55.64 seconds, 0.93 minutes\n",
      "layer   1  Sparsity: 91.0806%\n",
      "layer   2  Sparsity: 57.2172%\n",
      "layer   3  Sparsity: 81.6841%\n",
      "total_backward_count 577610 real_backward_count 123737  21.422%\n",
      "epoch-59  lr=['0.0039062'], tr/val_loss:  0.027343/  0.051502, val:  75.42%, val_best:  82.08%, tr:  93.26%, tr_best:  93.26%, epoch time: 55.93 seconds, 0.93 minutes\n",
      "layer   1  Sparsity: 91.0884%\n",
      "layer   2  Sparsity: 57.2074%\n",
      "layer   3  Sparsity: 81.7590%\n",
      "total_backward_count 587400 real_backward_count 125294  21.330%\n",
      "epoch-60  lr=['0.0039062'], tr/val_loss:  0.026977/  0.057634, val:  68.75%, val_best:  82.08%, tr:  92.85%, tr_best:  93.26%, epoch time: 55.29 seconds, 0.92 minutes\n",
      "layer   1  Sparsity: 91.0526%\n",
      "layer   2  Sparsity: 57.2374%\n",
      "layer   3  Sparsity: 81.9140%\n",
      "total_backward_count 597190 real_backward_count 126836  21.239%\n",
      "epoch-61  lr=['0.0039062'], tr/val_loss:  0.026801/  0.055843, val:  72.92%, val_best:  82.08%, tr:  93.16%, tr_best:  93.26%, epoch time: 55.78 seconds, 0.93 minutes\n",
      "layer   1  Sparsity: 91.1114%\n",
      "layer   2  Sparsity: 57.2282%\n",
      "layer   3  Sparsity: 81.9880%\n",
      "total_backward_count 606980 real_backward_count 128358  21.147%\n",
      "epoch-62  lr=['0.0039062'], tr/val_loss:  0.025914/  0.052386, val:  73.75%, val_best:  82.08%, tr:  94.38%, tr_best:  94.38%, epoch time: 56.35 seconds, 0.94 minutes\n",
      "layer   1  Sparsity: 91.0919%\n",
      "layer   2  Sparsity: 57.2757%\n",
      "layer   3  Sparsity: 81.9066%\n",
      "total_backward_count 616770 real_backward_count 129769  21.040%\n",
      "epoch-63  lr=['0.0039062'], tr/val_loss:  0.025569/  0.048241, val:  80.83%, val_best:  82.08%, tr:  94.18%, tr_best:  94.38%, epoch time: 55.58 seconds, 0.93 minutes\n",
      "layer   1  Sparsity: 91.0971%\n",
      "layer   2  Sparsity: 57.2688%\n",
      "layer   3  Sparsity: 82.0855%\n",
      "total_backward_count 626560 real_backward_count 131207  20.941%\n",
      "epoch-64  lr=['0.0039062'], tr/val_loss:  0.026038/  0.048975, val:  77.08%, val_best:  82.08%, tr:  93.36%, tr_best:  94.38%, epoch time: 55.88 seconds, 0.93 minutes\n",
      "layer   1  Sparsity: 91.0919%\n",
      "layer   2  Sparsity: 57.1851%\n",
      "layer   3  Sparsity: 82.1828%\n",
      "total_backward_count 636350 real_backward_count 132685  20.851%\n",
      "epoch-65  lr=['0.0039062'], tr/val_loss:  0.025281/  0.048594, val:  81.25%, val_best:  82.08%, tr:  94.99%, tr_best:  94.99%, epoch time: 55.51 seconds, 0.93 minutes\n",
      "layer   1  Sparsity: 91.0709%\n",
      "layer   2  Sparsity: 57.2200%\n",
      "layer   3  Sparsity: 82.2700%\n",
      "total_backward_count 646140 real_backward_count 134083  20.751%\n",
      "epoch-66  lr=['0.0039062'], tr/val_loss:  0.024484/  0.048466, val:  80.42%, val_best:  82.08%, tr:  95.30%, tr_best:  95.30%, epoch time: 55.73 seconds, 0.93 minutes\n",
      "layer   1  Sparsity: 91.0935%\n",
      "layer   2  Sparsity: 57.2308%\n",
      "layer   3  Sparsity: 82.1646%\n",
      "total_backward_count 655930 real_backward_count 135475  20.654%\n",
      "epoch-67  lr=['0.0039062'], tr/val_loss:  0.024712/  0.050680, val:  69.17%, val_best:  82.08%, tr:  94.89%, tr_best:  95.30%, epoch time: 55.82 seconds, 0.93 minutes\n",
      "layer   1  Sparsity: 91.0574%\n",
      "layer   2  Sparsity: 57.2320%\n",
      "layer   3  Sparsity: 82.2014%\n",
      "total_backward_count 665720 real_backward_count 136828  20.553%\n",
      "epoch-68  lr=['0.0039062'], tr/val_loss:  0.024322/  0.052780, val:  75.00%, val_best:  82.08%, tr:  95.71%, tr_best:  95.71%, epoch time: 56.21 seconds, 0.94 minutes\n",
      "layer   1  Sparsity: 91.0702%\n",
      "layer   2  Sparsity: 57.2427%\n",
      "layer   3  Sparsity: 82.2294%\n",
      "total_backward_count 675510 real_backward_count 138158  20.452%\n",
      "epoch-69  lr=['0.0039062'], tr/val_loss:  0.024171/  0.051438, val:  72.08%, val_best:  82.08%, tr:  95.61%, tr_best:  95.71%, epoch time: 55.84 seconds, 0.93 minutes\n",
      "layer   1  Sparsity: 91.0969%\n",
      "layer   2  Sparsity: 57.3360%\n",
      "layer   3  Sparsity: 82.1593%\n",
      "total_backward_count 685300 real_backward_count 139459  20.350%\n",
      "epoch-70  lr=['0.0039062'], tr/val_loss:  0.023832/  0.047089, val:  81.67%, val_best:  82.08%, tr:  95.91%, tr_best:  95.91%, epoch time: 55.51 seconds, 0.93 minutes\n",
      "layer   1  Sparsity: 91.0318%\n",
      "layer   2  Sparsity: 57.4057%\n",
      "layer   3  Sparsity: 82.1795%\n",
      "total_backward_count 695090 real_backward_count 140756  20.250%\n",
      "epoch-71  lr=['0.0039062'], tr/val_loss:  0.022513/  0.049418, val:  77.08%, val_best:  82.08%, tr:  96.73%, tr_best:  96.73%, epoch time: 55.08 seconds, 0.92 minutes\n",
      "layer   1  Sparsity: 91.1094%\n",
      "layer   2  Sparsity: 57.3893%\n",
      "layer   3  Sparsity: 82.1174%\n",
      "total_backward_count 704880 real_backward_count 141959  20.139%\n",
      "epoch-72  lr=['0.0039062'], tr/val_loss:  0.023705/  0.048014, val:  78.75%, val_best:  82.08%, tr:  96.12%, tr_best:  96.73%, epoch time: 55.68 seconds, 0.93 minutes\n",
      "layer   1  Sparsity: 91.0594%\n",
      "layer   2  Sparsity: 57.3072%\n",
      "layer   3  Sparsity: 82.2500%\n",
      "total_backward_count 714670 real_backward_count 143284  20.049%\n",
      "epoch-73  lr=['0.0039062'], tr/val_loss:  0.023193/  0.046727, val:  82.08%, val_best:  82.08%, tr:  96.94%, tr_best:  96.94%, epoch time: 55.32 seconds, 0.92 minutes\n",
      "layer   1  Sparsity: 91.0892%\n",
      "layer   2  Sparsity: 57.3193%\n",
      "layer   3  Sparsity: 82.2263%\n",
      "total_backward_count 724460 real_backward_count 144526  19.949%\n",
      "epoch-74  lr=['0.0039062'], tr/val_loss:  0.022622/  0.047901, val:  80.83%, val_best:  82.08%, tr:  97.34%, tr_best:  97.34%, epoch time: 55.43 seconds, 0.92 minutes\n",
      "layer   1  Sparsity: 91.0803%\n",
      "layer   2  Sparsity: 57.2962%\n",
      "layer   3  Sparsity: 82.2140%\n",
      "total_backward_count 734250 real_backward_count 145740  19.849%\n",
      "epoch-75  lr=['0.0039062'], tr/val_loss:  0.023352/  0.047207, val:  81.25%, val_best:  82.08%, tr:  96.73%, tr_best:  97.34%, epoch time: 55.89 seconds, 0.93 minutes\n",
      "layer   1  Sparsity: 91.1037%\n",
      "layer   2  Sparsity: 57.2950%\n",
      "layer   3  Sparsity: 82.3104%\n",
      "total_backward_count 744040 real_backward_count 147015  19.759%\n",
      "epoch-76  lr=['0.0039062'], tr/val_loss:  0.021925/  0.046374, val:  80.83%, val_best:  82.08%, tr:  96.83%, tr_best:  97.34%, epoch time: 55.54 seconds, 0.93 minutes\n",
      "layer   1  Sparsity: 91.0737%\n",
      "layer   2  Sparsity: 57.2771%\n",
      "layer   3  Sparsity: 82.4071%\n",
      "total_backward_count 753830 real_backward_count 148216  19.662%\n",
      "epoch-77  lr=['0.0039062'], tr/val_loss:  0.022252/  0.045747, val:  83.33%, val_best:  83.33%, tr:  97.04%, tr_best:  97.34%, epoch time: 56.24 seconds, 0.94 minutes\n",
      "layer   1  Sparsity: 91.1027%\n",
      "layer   2  Sparsity: 57.2326%\n",
      "layer   3  Sparsity: 82.5267%\n",
      "total_backward_count 763620 real_backward_count 149455  19.572%\n",
      "epoch-78  lr=['0.0039062'], tr/val_loss:  0.021780/  0.048538, val:  77.50%, val_best:  83.33%, tr:  97.14%, tr_best:  97.34%, epoch time: 55.87 seconds, 0.93 minutes\n",
      "layer   1  Sparsity: 91.0590%\n",
      "layer   2  Sparsity: 57.2133%\n",
      "layer   3  Sparsity: 82.5581%\n",
      "total_backward_count 773410 real_backward_count 150642  19.478%\n",
      "epoch-79  lr=['0.0039062'], tr/val_loss:  0.022152/  0.044841, val:  79.58%, val_best:  83.33%, tr:  97.14%, tr_best:  97.34%, epoch time: 56.33 seconds, 0.94 minutes\n",
      "layer   1  Sparsity: 91.1118%\n",
      "layer   2  Sparsity: 57.2582%\n",
      "layer   3  Sparsity: 82.7653%\n",
      "total_backward_count 783200 real_backward_count 151811  19.383%\n",
      "epoch-80  lr=['0.0039062'], tr/val_loss:  0.021249/  0.045241, val:  81.67%, val_best:  83.33%, tr:  97.34%, tr_best:  97.34%, epoch time: 56.08 seconds, 0.93 minutes\n",
      "layer   1  Sparsity: 91.0973%\n",
      "layer   2  Sparsity: 57.4317%\n",
      "layer   3  Sparsity: 82.7824%\n",
      "total_backward_count 792990 real_backward_count 152959  19.289%\n",
      "epoch-81  lr=['0.0039062'], tr/val_loss:  0.021006/  0.043661, val:  85.00%, val_best:  85.00%, tr:  97.55%, tr_best:  97.55%, epoch time: 55.41 seconds, 0.92 minutes\n",
      "layer   1  Sparsity: 91.0958%\n",
      "layer   2  Sparsity: 57.4172%\n",
      "layer   3  Sparsity: 82.7849%\n",
      "total_backward_count 802780 real_backward_count 154088  19.194%\n",
      "epoch-82  lr=['0.0039062'], tr/val_loss:  0.021134/  0.045990, val:  81.67%, val_best:  85.00%, tr:  97.55%, tr_best:  97.55%, epoch time: 56.08 seconds, 0.93 minutes\n",
      "layer   1  Sparsity: 91.0226%\n",
      "layer   2  Sparsity: 57.3149%\n",
      "layer   3  Sparsity: 82.9370%\n",
      "total_backward_count 812570 real_backward_count 155212  19.101%\n",
      "epoch-83  lr=['0.0039062'], tr/val_loss:  0.020996/  0.047967, val:  77.92%, val_best:  85.00%, tr:  97.65%, tr_best:  97.65%, epoch time: 55.81 seconds, 0.93 minutes\n",
      "layer   1  Sparsity: 91.1077%\n",
      "layer   2  Sparsity: 57.2785%\n",
      "layer   3  Sparsity: 82.9110%\n",
      "total_backward_count 822360 real_backward_count 156351  19.012%\n",
      "epoch-84  lr=['0.0039062'], tr/val_loss:  0.020580/  0.047790, val:  73.75%, val_best:  85.00%, tr:  97.14%, tr_best:  97.65%, epoch time: 56.21 seconds, 0.94 minutes\n",
      "layer   1  Sparsity: 91.0516%\n",
      "layer   2  Sparsity: 57.3204%\n",
      "layer   3  Sparsity: 82.8651%\n",
      "total_backward_count 832150 real_backward_count 157453  18.921%\n",
      "epoch-85  lr=['0.0039062'], tr/val_loss:  0.020730/  0.047280, val:  81.25%, val_best:  85.00%, tr:  97.04%, tr_best:  97.65%, epoch time: 56.04 seconds, 0.93 minutes\n",
      "layer   1  Sparsity: 91.0526%\n",
      "layer   2  Sparsity: 57.3548%\n",
      "layer   3  Sparsity: 82.9204%\n",
      "total_backward_count 841940 real_backward_count 158582  18.835%\n",
      "epoch-86  lr=['0.0039062'], tr/val_loss:  0.020599/  0.042381, val:  83.75%, val_best:  85.00%, tr:  97.65%, tr_best:  97.65%, epoch time: 55.79 seconds, 0.93 minutes\n",
      "layer   1  Sparsity: 91.0552%\n",
      "layer   2  Sparsity: 57.3294%\n",
      "layer   3  Sparsity: 82.9932%\n",
      "total_backward_count 851730 real_backward_count 159695  18.749%\n",
      "epoch-87  lr=['0.0039062'], tr/val_loss:  0.020118/  0.043595, val:  82.08%, val_best:  85.00%, tr:  97.45%, tr_best:  97.65%, epoch time: 55.40 seconds, 0.92 minutes\n",
      "layer   1  Sparsity: 91.0684%\n",
      "layer   2  Sparsity: 57.3518%\n",
      "layer   3  Sparsity: 83.0862%\n",
      "total_backward_count 861520 real_backward_count 160791  18.664%\n",
      "epoch-88  lr=['0.0039062'], tr/val_loss:  0.020566/  0.046493, val:  81.25%, val_best:  85.00%, tr:  97.65%, tr_best:  97.65%, epoch time: 55.64 seconds, 0.93 minutes\n",
      "layer   1  Sparsity: 91.0473%\n",
      "layer   2  Sparsity: 57.3473%\n",
      "layer   3  Sparsity: 83.1606%\n",
      "total_backward_count 871310 real_backward_count 161938  18.586%\n",
      "epoch-89  lr=['0.0039062'], tr/val_loss:  0.019695/  0.041876, val:  84.58%, val_best:  85.00%, tr:  97.75%, tr_best:  97.75%, epoch time: 55.34 seconds, 0.92 minutes\n",
      "layer   1  Sparsity: 91.0475%\n",
      "layer   2  Sparsity: 57.4052%\n",
      "layer   3  Sparsity: 83.1523%\n",
      "total_backward_count 881100 real_backward_count 162984  18.498%\n",
      "epoch-90  lr=['0.0039062'], tr/val_loss:  0.019793/  0.044741, val:  80.83%, val_best:  85.00%, tr:  97.85%, tr_best:  97.85%, epoch time: 55.15 seconds, 0.92 minutes\n",
      "layer   1  Sparsity: 91.0504%\n",
      "layer   2  Sparsity: 57.4557%\n",
      "layer   3  Sparsity: 83.1898%\n",
      "total_backward_count 890890 real_backward_count 164030  18.412%\n",
      "epoch-91  lr=['0.0039062'], tr/val_loss:  0.019037/  0.048829, val:  77.92%, val_best:  85.00%, tr:  97.96%, tr_best:  97.96%, epoch time: 55.33 seconds, 0.92 minutes\n",
      "layer   1  Sparsity: 91.0830%\n",
      "layer   2  Sparsity: 57.3945%\n",
      "layer   3  Sparsity: 83.2649%\n",
      "total_backward_count 900680 real_backward_count 165029  18.323%\n",
      "epoch-92  lr=['0.0039062'], tr/val_loss:  0.019487/  0.044734, val:  84.17%, val_best:  85.00%, tr:  97.75%, tr_best:  97.96%, epoch time: 54.80 seconds, 0.91 minutes\n",
      "layer   1  Sparsity: 91.0993%\n",
      "layer   2  Sparsity: 57.4461%\n",
      "layer   3  Sparsity: 83.3785%\n",
      "total_backward_count 910470 real_backward_count 166083  18.241%\n",
      "epoch-93  lr=['0.0039062'], tr/val_loss:  0.019485/  0.041570, val:  84.17%, val_best:  85.00%, tr:  97.14%, tr_best:  97.96%, epoch time: 55.42 seconds, 0.92 minutes\n",
      "layer   1  Sparsity: 91.0566%\n",
      "layer   2  Sparsity: 57.4224%\n",
      "layer   3  Sparsity: 83.4512%\n",
      "total_backward_count 920260 real_backward_count 167117  18.160%\n",
      "epoch-94  lr=['0.0039062'], tr/val_loss:  0.019082/  0.046089, val:  80.00%, val_best:  85.00%, tr:  97.45%, tr_best:  97.96%, epoch time: 56.10 seconds, 0.93 minutes\n",
      "layer   1  Sparsity: 91.0615%\n",
      "layer   2  Sparsity: 57.4723%\n",
      "layer   3  Sparsity: 83.3313%\n",
      "total_backward_count 930050 real_backward_count 168143  18.079%\n",
      "epoch-95  lr=['0.0039062'], tr/val_loss:  0.018871/  0.042349, val:  84.17%, val_best:  85.00%, tr:  98.26%, tr_best:  98.26%, epoch time: 55.93 seconds, 0.93 minutes\n",
      "layer   1  Sparsity: 91.0863%\n",
      "layer   2  Sparsity: 57.4875%\n",
      "layer   3  Sparsity: 83.3434%\n",
      "total_backward_count 939840 real_backward_count 169126  17.995%\n",
      "epoch-96  lr=['0.0039062'], tr/val_loss:  0.018488/  0.041699, val:  85.83%, val_best:  85.83%, tr:  97.85%, tr_best:  98.26%, epoch time: 55.97 seconds, 0.93 minutes\n",
      "layer   1  Sparsity: 91.0636%\n",
      "layer   2  Sparsity: 57.5150%\n",
      "layer   3  Sparsity: 83.3556%\n",
      "total_backward_count 949630 real_backward_count 170088  17.911%\n",
      "epoch-97  lr=['0.0039062'], tr/val_loss:  0.018558/  0.040662, val:  86.67%, val_best:  86.67%, tr:  98.57%, tr_best:  98.57%, epoch time: 55.54 seconds, 0.93 minutes\n",
      "layer   1  Sparsity: 91.0659%\n",
      "layer   2  Sparsity: 57.4749%\n",
      "layer   3  Sparsity: 83.4991%\n",
      "total_backward_count 959420 real_backward_count 171048  17.828%\n",
      "epoch-98  lr=['0.0039062'], tr/val_loss:  0.018880/  0.042843, val:  85.42%, val_best:  86.67%, tr:  98.06%, tr_best:  98.57%, epoch time: 55.92 seconds, 0.93 minutes\n",
      "layer   1  Sparsity: 91.0634%\n",
      "layer   2  Sparsity: 57.4196%\n",
      "layer   3  Sparsity: 83.5372%\n",
      "total_backward_count 969210 real_backward_count 172053  17.752%\n",
      "epoch-99  lr=['0.0039062'], tr/val_loss:  0.018167/  0.043064, val:  84.17%, val_best:  86.67%, tr:  98.06%, tr_best:  98.57%, epoch time: 55.58 seconds, 0.93 minutes\n",
      "layer   1  Sparsity: 91.0788%\n",
      "layer   2  Sparsity: 57.4823%\n",
      "layer   3  Sparsity: 83.5911%\n",
      "total_backward_count 979000 real_backward_count 172984  17.669%\n",
      "epoch-100 lr=['0.0039062'], tr/val_loss:  0.017367/  0.041580, val:  85.83%, val_best:  86.67%, tr:  98.47%, tr_best:  98.57%, epoch time: 55.73 seconds, 0.93 minutes\n",
      "layer   1  Sparsity: 91.0728%\n",
      "layer   2  Sparsity: 57.4518%\n",
      "layer   3  Sparsity: 83.6290%\n",
      "total_backward_count 988790 real_backward_count 173863  17.583%\n",
      "epoch-101 lr=['0.0039062'], tr/val_loss:  0.017768/  0.041500, val:  85.42%, val_best:  86.67%, tr:  98.77%, tr_best:  98.77%, epoch time: 56.11 seconds, 0.94 minutes\n",
      "layer   1  Sparsity: 91.1235%\n",
      "layer   2  Sparsity: 57.4115%\n",
      "layer   3  Sparsity: 83.7404%\n",
      "total_backward_count 998580 real_backward_count 174775  17.502%\n",
      "epoch-102 lr=['0.0039062'], tr/val_loss:  0.018037/  0.043070, val:  83.75%, val_best:  86.67%, tr:  98.26%, tr_best:  98.77%, epoch time: 55.90 seconds, 0.93 minutes\n",
      "layer   1  Sparsity: 91.0721%\n",
      "layer   2  Sparsity: 57.4856%\n",
      "layer   3  Sparsity: 83.7674%\n",
      "total_backward_count 1008370 real_backward_count 175728  17.427%\n",
      "epoch-103 lr=['0.0039062'], tr/val_loss:  0.018124/  0.044956, val:  82.08%, val_best:  86.67%, tr:  97.75%, tr_best:  98.77%, epoch time: 56.11 seconds, 0.94 minutes\n",
      "layer   1  Sparsity: 91.0788%\n",
      "layer   2  Sparsity: 57.4577%\n",
      "layer   3  Sparsity: 83.8578%\n",
      "total_backward_count 1018160 real_backward_count 176704  17.355%\n",
      "epoch-104 lr=['0.0039062'], tr/val_loss:  0.017158/  0.041013, val:  87.92%, val_best:  87.92%, tr:  98.88%, tr_best:  98.88%, epoch time: 54.93 seconds, 0.92 minutes\n",
      "layer   1  Sparsity: 91.0406%\n",
      "layer   2  Sparsity: 57.4203%\n",
      "layer   3  Sparsity: 83.9972%\n",
      "total_backward_count 1027950 real_backward_count 177565  17.274%\n",
      "epoch-105 lr=['0.0039062'], tr/val_loss:  0.016826/  0.042296, val:  83.75%, val_best:  87.92%, tr:  98.98%, tr_best:  98.98%, epoch time: 55.71 seconds, 0.93 minutes\n",
      "layer   1  Sparsity: 91.0943%\n",
      "layer   2  Sparsity: 57.3832%\n",
      "layer   3  Sparsity: 83.9888%\n",
      "total_backward_count 1037740 real_backward_count 178438  17.195%\n",
      "epoch-106 lr=['0.0039062'], tr/val_loss:  0.016652/  0.042633, val:  84.58%, val_best:  87.92%, tr:  99.18%, tr_best:  99.18%, epoch time: 55.46 seconds, 0.92 minutes\n",
      "layer   1  Sparsity: 91.1109%\n",
      "layer   2  Sparsity: 57.4043%\n",
      "layer   3  Sparsity: 84.0248%\n",
      "total_backward_count 1047530 real_backward_count 179263  17.113%\n",
      "epoch-107 lr=['0.0039062'], tr/val_loss:  0.017411/  0.042490, val:  86.25%, val_best:  87.92%, tr:  98.26%, tr_best:  99.18%, epoch time: 55.66 seconds, 0.93 minutes\n",
      "layer   1  Sparsity: 91.0760%\n",
      "layer   2  Sparsity: 57.2416%\n",
      "layer   3  Sparsity: 84.1066%\n",
      "total_backward_count 1057320 real_backward_count 180185  17.042%\n",
      "epoch-108 lr=['0.0039062'], tr/val_loss:  0.016842/  0.041799, val:  84.58%, val_best:  87.92%, tr:  98.57%, tr_best:  99.18%, epoch time: 55.89 seconds, 0.93 minutes\n",
      "layer   1  Sparsity: 91.0727%\n",
      "layer   2  Sparsity: 57.3856%\n",
      "layer   3  Sparsity: 84.1222%\n",
      "total_backward_count 1067110 real_backward_count 181038  16.965%\n",
      "epoch-109 lr=['0.0039062'], tr/val_loss:  0.016554/  0.040316, val:  85.83%, val_best:  87.92%, tr:  99.08%, tr_best:  99.18%, epoch time: 55.52 seconds, 0.93 minutes\n",
      "layer   1  Sparsity: 91.1014%\n",
      "layer   2  Sparsity: 57.2778%\n",
      "layer   3  Sparsity: 84.1308%\n",
      "total_backward_count 1076900 real_backward_count 181911  16.892%\n",
      "epoch-110 lr=['0.0039062'], tr/val_loss:  0.016917/  0.041658, val:  84.58%, val_best:  87.92%, tr:  98.47%, tr_best:  99.18%, epoch time: 55.71 seconds, 0.93 minutes\n",
      "layer   1  Sparsity: 91.0879%\n",
      "layer   2  Sparsity: 57.2959%\n",
      "layer   3  Sparsity: 84.1973%\n",
      "total_backward_count 1086690 real_backward_count 182783  16.820%\n",
      "epoch-111 lr=['0.0039062'], tr/val_loss:  0.016533/  0.042044, val:  83.33%, val_best:  87.92%, tr:  98.57%, tr_best:  99.18%, epoch time: 56.22 seconds, 0.94 minutes\n",
      "layer   1  Sparsity: 91.0750%\n",
      "layer   2  Sparsity: 57.2657%\n",
      "layer   3  Sparsity: 84.2337%\n",
      "total_backward_count 1096480 real_backward_count 183647  16.749%\n",
      "epoch-112 lr=['0.0039062'], tr/val_loss:  0.016771/  0.042423, val:  83.75%, val_best:  87.92%, tr:  98.67%, tr_best:  99.18%, epoch time: 55.74 seconds, 0.93 minutes\n",
      "layer   1  Sparsity: 91.0908%\n",
      "layer   2  Sparsity: 57.2546%\n",
      "layer   3  Sparsity: 84.3089%\n",
      "total_backward_count 1106270 real_backward_count 184540  16.681%\n",
      "epoch-113 lr=['0.0039062'], tr/val_loss:  0.016660/  0.039414, val:  88.33%, val_best:  88.33%, tr:  98.57%, tr_best:  99.18%, epoch time: 55.34 seconds, 0.92 minutes\n",
      "layer   1  Sparsity: 91.0866%\n",
      "layer   2  Sparsity: 57.2829%\n",
      "layer   3  Sparsity: 84.3738%\n",
      "total_backward_count 1116060 real_backward_count 185425  16.614%\n",
      "epoch-114 lr=['0.0039062'], tr/val_loss:  0.016451/  0.041776, val:  85.00%, val_best:  88.33%, tr:  98.37%, tr_best:  99.18%, epoch time: 55.54 seconds, 0.93 minutes\n",
      "layer   1  Sparsity: 91.0912%\n",
      "layer   2  Sparsity: 57.3179%\n",
      "layer   3  Sparsity: 84.3998%\n",
      "total_backward_count 1125850 real_backward_count 186273  16.545%\n",
      "epoch-115 lr=['0.0039062'], tr/val_loss:  0.015932/  0.043166, val:  83.75%, val_best:  88.33%, tr:  99.08%, tr_best:  99.18%, epoch time: 55.48 seconds, 0.92 minutes\n",
      "layer   1  Sparsity: 91.0846%\n",
      "layer   2  Sparsity: 57.2932%\n",
      "layer   3  Sparsity: 84.5120%\n",
      "total_backward_count 1135640 real_backward_count 187089  16.474%\n",
      "epoch-116 lr=['0.0039062'], tr/val_loss:  0.015372/  0.042180, val:  84.58%, val_best:  88.33%, tr:  99.28%, tr_best:  99.28%, epoch time: 55.35 seconds, 0.92 minutes\n",
      "layer   1  Sparsity: 91.0749%\n",
      "layer   2  Sparsity: 57.3575%\n",
      "layer   3  Sparsity: 84.5379%\n",
      "total_backward_count 1145430 real_backward_count 187867  16.401%\n",
      "epoch-117 lr=['0.0039062'], tr/val_loss:  0.015212/  0.038578, val:  89.17%, val_best:  89.17%, tr:  99.39%, tr_best:  99.39%, epoch time: 56.35 seconds, 0.94 minutes\n",
      "layer   1  Sparsity: 91.0754%\n",
      "layer   2  Sparsity: 57.3909%\n",
      "layer   3  Sparsity: 84.5800%\n",
      "total_backward_count 1155220 real_backward_count 188630  16.328%\n",
      "epoch-118 lr=['0.0039062'], tr/val_loss:  0.016368/  0.037704, val:  88.75%, val_best:  89.17%, tr:  98.98%, tr_best:  99.39%, epoch time: 56.09 seconds, 0.93 minutes\n",
      "layer   1  Sparsity: 91.0910%\n",
      "layer   2  Sparsity: 57.3434%\n",
      "layer   3  Sparsity: 84.6600%\n",
      "total_backward_count 1165010 real_backward_count 189485  16.265%\n",
      "epoch-119 lr=['0.0039062'], tr/val_loss:  0.015557/  0.041411, val:  85.00%, val_best:  89.17%, tr:  98.88%, tr_best:  99.39%, epoch time: 55.41 seconds, 0.92 minutes\n",
      "layer   1  Sparsity: 91.0899%\n",
      "layer   2  Sparsity: 57.3523%\n",
      "layer   3  Sparsity: 84.7591%\n",
      "total_backward_count 1174800 real_backward_count 190261  16.195%\n",
      "epoch-120 lr=['0.0039062'], tr/val_loss:  0.015201/  0.039822, val:  88.33%, val_best:  89.17%, tr:  98.88%, tr_best:  99.39%, epoch time: 55.91 seconds, 0.93 minutes\n",
      "layer   1  Sparsity: 91.0760%\n",
      "layer   2  Sparsity: 57.3345%\n",
      "layer   3  Sparsity: 84.7660%\n",
      "total_backward_count 1184590 real_backward_count 191049  16.128%\n",
      "epoch-121 lr=['0.0039062'], tr/val_loss:  0.014881/  0.039112, val:  86.67%, val_best:  89.17%, tr:  98.47%, tr_best:  99.39%, epoch time: 55.63 seconds, 0.93 minutes\n",
      "layer   1  Sparsity: 91.0767%\n",
      "layer   2  Sparsity: 57.2447%\n",
      "layer   3  Sparsity: 84.8535%\n",
      "total_backward_count 1194380 real_backward_count 191771  16.056%\n",
      "epoch-122 lr=['0.0039062'], tr/val_loss:  0.015423/  0.042421, val:  86.25%, val_best:  89.17%, tr:  98.98%, tr_best:  99.39%, epoch time: 55.37 seconds, 0.92 minutes\n",
      "layer   1  Sparsity: 91.0628%\n",
      "layer   2  Sparsity: 57.2418%\n",
      "layer   3  Sparsity: 84.9370%\n",
      "total_backward_count 1204170 real_backward_count 192554  15.991%\n",
      "epoch-123 lr=['0.0039062'], tr/val_loss:  0.015546/  0.038171, val:  87.08%, val_best:  89.17%, tr:  98.98%, tr_best:  99.39%, epoch time: 55.98 seconds, 0.93 minutes\n",
      "layer   1  Sparsity: 91.0623%\n",
      "layer   2  Sparsity: 57.3075%\n",
      "layer   3  Sparsity: 84.9316%\n",
      "total_backward_count 1213960 real_backward_count 193374  15.929%\n",
      "epoch-124 lr=['0.0039062'], tr/val_loss:  0.014819/  0.039809, val:  85.42%, val_best:  89.17%, tr:  99.08%, tr_best:  99.39%, epoch time: 56.00 seconds, 0.93 minutes\n",
      "layer   1  Sparsity: 91.0743%\n",
      "layer   2  Sparsity: 57.3683%\n",
      "layer   3  Sparsity: 85.0356%\n",
      "total_backward_count 1223750 real_backward_count 194159  15.866%\n",
      "epoch-125 lr=['0.0039062'], tr/val_loss:  0.014790/  0.038865, val:  87.92%, val_best:  89.17%, tr:  99.28%, tr_best:  99.39%, epoch time: 55.83 seconds, 0.93 minutes\n",
      "layer   1  Sparsity: 91.0876%\n",
      "layer   2  Sparsity: 57.3170%\n",
      "layer   3  Sparsity: 85.1274%\n",
      "total_backward_count 1233540 real_backward_count 194936  15.803%\n",
      "epoch-126 lr=['0.0039062'], tr/val_loss:  0.015256/  0.040606, val:  85.00%, val_best:  89.17%, tr:  98.67%, tr_best:  99.39%, epoch time: 56.15 seconds, 0.94 minutes\n",
      "layer   1  Sparsity: 91.0656%\n",
      "layer   2  Sparsity: 57.3088%\n",
      "layer   3  Sparsity: 85.2381%\n",
      "total_backward_count 1243330 real_backward_count 195701  15.740%\n",
      "epoch-127 lr=['0.0039062'], tr/val_loss:  0.015061/  0.040071, val:  87.50%, val_best:  89.17%, tr:  99.28%, tr_best:  99.39%, epoch time: 55.88 seconds, 0.93 minutes\n",
      "layer   1  Sparsity: 91.1046%\n",
      "layer   2  Sparsity: 57.2714%\n",
      "layer   3  Sparsity: 85.3704%\n",
      "total_backward_count 1253120 real_backward_count 196467  15.678%\n",
      "epoch-128 lr=['0.0039062'], tr/val_loss:  0.015377/  0.041474, val:  85.00%, val_best:  89.17%, tr:  98.88%, tr_best:  99.39%, epoch time: 55.90 seconds, 0.93 minutes\n",
      "layer   1  Sparsity: 91.0897%\n",
      "layer   2  Sparsity: 57.3420%\n",
      "layer   3  Sparsity: 85.3936%\n",
      "total_backward_count 1262910 real_backward_count 197274  15.621%\n",
      "epoch-129 lr=['0.0039062'], tr/val_loss:  0.015155/  0.038422, val:  88.33%, val_best:  89.17%, tr:  98.37%, tr_best:  99.39%, epoch time: 56.64 seconds, 0.94 minutes\n",
      "layer   1  Sparsity: 91.0815%\n",
      "layer   2  Sparsity: 57.3329%\n",
      "layer   3  Sparsity: 85.4629%\n",
      "total_backward_count 1272700 real_backward_count 198063  15.562%\n",
      "epoch-130 lr=['0.0039062'], tr/val_loss:  0.014907/  0.038765, val:  87.08%, val_best:  89.17%, tr:  98.98%, tr_best:  99.39%, epoch time: 51.69 seconds, 0.86 minutes\n",
      "layer   1  Sparsity: 91.0362%\n",
      "layer   2  Sparsity: 57.2260%\n",
      "layer   3  Sparsity: 85.6281%\n",
      "total_backward_count 1282490 real_backward_count 198819  15.503%\n",
      "epoch-131 lr=['0.0039062'], tr/val_loss:  0.014352/  0.039349, val:  89.58%, val_best:  89.58%, tr:  99.28%, tr_best:  99.39%, epoch time: 55.57 seconds, 0.93 minutes\n",
      "layer   1  Sparsity: 91.0689%\n",
      "layer   2  Sparsity: 57.1909%\n",
      "layer   3  Sparsity: 85.7002%\n",
      "total_backward_count 1292280 real_backward_count 199538  15.441%\n",
      "epoch-132 lr=['0.0039062'], tr/val_loss:  0.014654/  0.039911, val:  86.25%, val_best:  89.58%, tr:  99.39%, tr_best:  99.39%, epoch time: 55.89 seconds, 0.93 minutes\n",
      "layer   1  Sparsity: 91.0591%\n",
      "layer   2  Sparsity: 57.2379%\n",
      "layer   3  Sparsity: 85.7392%\n",
      "total_backward_count 1302070 real_backward_count 200279  15.382%\n",
      "epoch-133 lr=['0.0039062'], tr/val_loss:  0.014786/  0.039212, val:  87.08%, val_best:  89.58%, tr:  98.98%, tr_best:  99.39%, epoch time: 55.67 seconds, 0.93 minutes\n",
      "layer   1  Sparsity: 91.1055%\n",
      "layer   2  Sparsity: 57.2990%\n",
      "layer   3  Sparsity: 85.8123%\n",
      "total_backward_count 1311860 real_backward_count 201052  15.326%\n",
      "epoch-134 lr=['0.0039062'], tr/val_loss:  0.014882/  0.039328, val:  88.75%, val_best:  89.58%, tr:  98.47%, tr_best:  99.39%, epoch time: 55.59 seconds, 0.93 minutes\n",
      "layer   1  Sparsity: 91.0382%\n",
      "layer   2  Sparsity: 57.3476%\n",
      "layer   3  Sparsity: 85.9633%\n",
      "total_backward_count 1321650 real_backward_count 201849  15.273%\n",
      "epoch-135 lr=['0.0039062'], tr/val_loss:  0.013958/  0.038227, val:  89.17%, val_best:  89.58%, tr:  99.18%, tr_best:  99.39%, epoch time: 55.09 seconds, 0.92 minutes\n",
      "layer   1  Sparsity: 91.1102%\n",
      "layer   2  Sparsity: 57.3313%\n",
      "layer   3  Sparsity: 86.0507%\n",
      "total_backward_count 1331440 real_backward_count 202564  15.214%\n",
      "epoch-136 lr=['0.0039062'], tr/val_loss:  0.013708/  0.038302, val:  87.92%, val_best:  89.58%, tr:  99.18%, tr_best:  99.39%, epoch time: 55.33 seconds, 0.92 minutes\n",
      "layer   1  Sparsity: 91.0569%\n",
      "layer   2  Sparsity: 57.2617%\n",
      "layer   3  Sparsity: 86.1340%\n",
      "total_backward_count 1341230 real_backward_count 203238  15.153%\n",
      "epoch-137 lr=['0.0039062'], tr/val_loss:  0.013941/  0.044861, val:  84.58%, val_best:  89.58%, tr:  99.18%, tr_best:  99.39%, epoch time: 55.41 seconds, 0.92 minutes\n",
      "layer   1  Sparsity: 91.0907%\n",
      "layer   2  Sparsity: 57.1494%\n",
      "layer   3  Sparsity: 86.2544%\n",
      "total_backward_count 1351020 real_backward_count 203940  15.095%\n",
      "epoch-138 lr=['0.0039062'], tr/val_loss:  0.013512/  0.038316, val:  85.83%, val_best:  89.58%, tr:  98.98%, tr_best:  99.39%, epoch time: 55.81 seconds, 0.93 minutes\n",
      "layer   1  Sparsity: 91.0863%\n",
      "layer   2  Sparsity: 57.1497%\n",
      "layer   3  Sparsity: 86.3655%\n",
      "total_backward_count 1360810 real_backward_count 204622  15.037%\n",
      "epoch-139 lr=['0.0039062'], tr/val_loss:  0.014712/  0.039016, val:  88.75%, val_best:  89.58%, tr:  98.98%, tr_best:  99.39%, epoch time: 55.81 seconds, 0.93 minutes\n",
      "layer   1  Sparsity: 91.0558%\n",
      "layer   2  Sparsity: 57.2154%\n",
      "layer   3  Sparsity: 86.3970%\n",
      "total_backward_count 1370600 real_backward_count 205358  14.983%\n",
      "epoch-140 lr=['0.0039062'], tr/val_loss:  0.013655/  0.038531, val:  87.50%, val_best:  89.58%, tr:  99.28%, tr_best:  99.39%, epoch time: 55.96 seconds, 0.93 minutes\n",
      "layer   1  Sparsity: 91.0962%\n",
      "layer   2  Sparsity: 57.2261%\n",
      "layer   3  Sparsity: 86.4065%\n",
      "total_backward_count 1380390 real_backward_count 206038  14.926%\n",
      "epoch-141 lr=['0.0039062'], tr/val_loss:  0.013819/  0.039763, val:  84.58%, val_best:  89.58%, tr:  99.28%, tr_best:  99.39%, epoch time: 56.06 seconds, 0.93 minutes\n",
      "layer   1  Sparsity: 91.0506%\n",
      "layer   2  Sparsity: 57.1896%\n",
      "layer   3  Sparsity: 86.4740%\n",
      "total_backward_count 1390180 real_backward_count 206728  14.871%\n",
      "epoch-142 lr=['0.0039062'], tr/val_loss:  0.013416/  0.041107, val:  84.58%, val_best:  89.58%, tr:  99.08%, tr_best:  99.39%, epoch time: 54.51 seconds, 0.91 minutes\n",
      "layer   1  Sparsity: 91.0824%\n",
      "layer   2  Sparsity: 57.1138%\n",
      "layer   3  Sparsity: 86.5705%\n",
      "total_backward_count 1399970 real_backward_count 207404  14.815%\n",
      "epoch-143 lr=['0.0039062'], tr/val_loss:  0.013262/  0.038936, val:  87.92%, val_best:  89.58%, tr:  99.28%, tr_best:  99.39%, epoch time: 55.78 seconds, 0.93 minutes\n",
      "layer   1  Sparsity: 91.0372%\n",
      "layer   2  Sparsity: 57.1250%\n",
      "layer   3  Sparsity: 86.5966%\n",
      "total_backward_count 1409760 real_backward_count 208072  14.759%\n",
      "epoch-144 lr=['0.0039062'], tr/val_loss:  0.013604/  0.039428, val:  86.67%, val_best:  89.58%, tr:  99.18%, tr_best:  99.39%, epoch time: 55.20 seconds, 0.92 minutes\n",
      "layer   1  Sparsity: 91.0747%\n",
      "layer   2  Sparsity: 57.1328%\n",
      "layer   3  Sparsity: 86.6332%\n",
      "total_backward_count 1419550 real_backward_count 208747  14.705%\n",
      "epoch-145 lr=['0.0039062'], tr/val_loss:  0.012956/  0.039743, val:  86.25%, val_best:  89.58%, tr:  99.18%, tr_best:  99.39%, epoch time: 55.97 seconds, 0.93 minutes\n",
      "layer   1  Sparsity: 91.0715%\n",
      "layer   2  Sparsity: 57.1506%\n",
      "layer   3  Sparsity: 86.7418%\n",
      "total_backward_count 1429340 real_backward_count 209379  14.649%\n",
      "epoch-146 lr=['0.0039062'], tr/val_loss:  0.012842/  0.039018, val:  85.42%, val_best:  89.58%, tr:  99.08%, tr_best:  99.39%, epoch time: 55.62 seconds, 0.93 minutes\n",
      "layer   1  Sparsity: 91.0281%\n",
      "layer   2  Sparsity: 57.0973%\n",
      "layer   3  Sparsity: 86.7771%\n",
      "total_backward_count 1439130 real_backward_count 210003  14.592%\n",
      "epoch-147 lr=['0.0039062'], tr/val_loss:  0.012937/  0.042945, val:  82.50%, val_best:  89.58%, tr:  99.18%, tr_best:  99.39%, epoch time: 55.37 seconds, 0.92 minutes\n",
      "layer   1  Sparsity: 91.0625%\n",
      "layer   2  Sparsity: 57.0936%\n",
      "layer   3  Sparsity: 86.8075%\n",
      "total_backward_count 1448920 real_backward_count 210660  14.539%\n",
      "epoch-148 lr=['0.0039062'], tr/val_loss:  0.012934/  0.038491, val:  85.83%, val_best:  89.58%, tr:  99.18%, tr_best:  99.39%, epoch time: 55.38 seconds, 0.92 minutes\n",
      "layer   1  Sparsity: 91.0816%\n",
      "layer   2  Sparsity: 57.0663%\n",
      "layer   3  Sparsity: 86.8387%\n",
      "total_backward_count 1458710 real_backward_count 211292  14.485%\n",
      "epoch-149 lr=['0.0039062'], tr/val_loss:  0.012961/  0.037639, val:  88.33%, val_best:  89.58%, tr:  99.39%, tr_best:  99.39%, epoch time: 56.02 seconds, 0.93 minutes\n",
      "layer   1  Sparsity: 91.1069%\n",
      "layer   2  Sparsity: 57.0782%\n",
      "layer   3  Sparsity: 86.9194%\n",
      "total_backward_count 1468500 real_backward_count 211954  14.433%\n",
      "epoch-150 lr=['0.0039062'], tr/val_loss:  0.012979/  0.039154, val:  88.33%, val_best:  89.58%, tr:  99.08%, tr_best:  99.39%, epoch time: 55.78 seconds, 0.93 minutes\n",
      "layer   1  Sparsity: 91.0710%\n",
      "layer   2  Sparsity: 57.1001%\n",
      "layer   3  Sparsity: 86.9343%\n",
      "total_backward_count 1478290 real_backward_count 212613  14.382%\n",
      "epoch-151 lr=['0.0039062'], tr/val_loss:  0.012523/  0.038363, val:  88.75%, val_best:  89.58%, tr:  99.69%, tr_best:  99.69%, epoch time: 55.45 seconds, 0.92 minutes\n",
      "layer   1  Sparsity: 91.0801%\n",
      "layer   2  Sparsity: 57.1636%\n",
      "layer   3  Sparsity: 86.9976%\n",
      "total_backward_count 1488080 real_backward_count 213230  14.329%\n",
      "epoch-152 lr=['0.0039062'], tr/val_loss:  0.012865/  0.037462, val:  87.92%, val_best:  89.58%, tr:  99.39%, tr_best:  99.69%, epoch time: 56.05 seconds, 0.93 minutes\n",
      "layer   1  Sparsity: 91.0689%\n",
      "layer   2  Sparsity: 57.1831%\n",
      "layer   3  Sparsity: 87.0084%\n",
      "total_backward_count 1497870 real_backward_count 213886  14.279%\n",
      "epoch-153 lr=['0.0039062'], tr/val_loss:  0.012567/  0.036666, val:  90.00%, val_best:  90.00%, tr:  99.08%, tr_best:  99.69%, epoch time: 56.16 seconds, 0.94 minutes\n",
      "layer   1  Sparsity: 91.1001%\n",
      "layer   2  Sparsity: 57.2130%\n",
      "layer   3  Sparsity: 87.0922%\n",
      "total_backward_count 1507660 real_backward_count 214522  14.229%\n",
      "epoch-154 lr=['0.0039062'], tr/val_loss:  0.012530/  0.038422, val:  88.33%, val_best:  90.00%, tr:  99.08%, tr_best:  99.69%, epoch time: 55.89 seconds, 0.93 minutes\n",
      "layer   1  Sparsity: 91.0523%\n",
      "layer   2  Sparsity: 57.2332%\n",
      "layer   3  Sparsity: 87.1558%\n",
      "total_backward_count 1517450 real_backward_count 215129  14.177%\n",
      "epoch-155 lr=['0.0039062'], tr/val_loss:  0.012122/  0.040232, val:  85.00%, val_best:  90.00%, tr:  99.49%, tr_best:  99.69%, epoch time: 56.00 seconds, 0.93 minutes\n",
      "layer   1  Sparsity: 91.0974%\n",
      "layer   2  Sparsity: 57.1886%\n",
      "layer   3  Sparsity: 87.2207%\n",
      "total_backward_count 1527240 real_backward_count 215739  14.126%\n",
      "epoch-156 lr=['0.0039062'], tr/val_loss:  0.012684/  0.038158, val:  85.83%, val_best:  90.00%, tr:  98.77%, tr_best:  99.69%, epoch time: 55.58 seconds, 0.93 minutes\n",
      "layer   1  Sparsity: 91.1078%\n",
      "layer   2  Sparsity: 57.1669%\n",
      "layer   3  Sparsity: 87.2840%\n",
      "total_backward_count 1537030 real_backward_count 216378  14.078%\n",
      "epoch-157 lr=['0.0039062'], tr/val_loss:  0.013047/  0.038872, val:  85.00%, val_best:  90.00%, tr:  99.18%, tr_best:  99.69%, epoch time: 56.16 seconds, 0.94 minutes\n",
      "layer   1  Sparsity: 91.0830%\n",
      "layer   2  Sparsity: 57.2271%\n",
      "layer   3  Sparsity: 87.3258%\n",
      "total_backward_count 1546820 real_backward_count 217036  14.031%\n",
      "epoch-158 lr=['0.0039062'], tr/val_loss:  0.012135/  0.039054, val:  87.92%, val_best:  90.00%, tr:  99.49%, tr_best:  99.69%, epoch time: 55.49 seconds, 0.92 minutes\n",
      "layer   1  Sparsity: 91.0646%\n",
      "layer   2  Sparsity: 57.0950%\n",
      "layer   3  Sparsity: 87.4313%\n",
      "total_backward_count 1556610 real_backward_count 217623  13.981%\n",
      "epoch-159 lr=['0.0039062'], tr/val_loss:  0.011943/  0.037718, val:  88.75%, val_best:  90.00%, tr:  99.49%, tr_best:  99.69%, epoch time: 55.87 seconds, 0.93 minutes\n",
      "layer   1  Sparsity: 91.0455%\n",
      "layer   2  Sparsity: 57.0989%\n",
      "layer   3  Sparsity: 87.4606%\n",
      "total_backward_count 1566400 real_backward_count 218210  13.931%\n",
      "epoch-160 lr=['0.0039062'], tr/val_loss:  0.012005/  0.038533, val:  87.92%, val_best:  90.00%, tr:  98.88%, tr_best:  99.69%, epoch time: 56.38 seconds, 0.94 minutes\n",
      "layer   1  Sparsity: 91.0610%\n",
      "layer   2  Sparsity: 57.0647%\n",
      "layer   3  Sparsity: 87.4979%\n",
      "total_backward_count 1576190 real_backward_count 218810  13.882%\n",
      "epoch-161 lr=['0.0039062'], tr/val_loss:  0.012382/  0.038965, val:  87.08%, val_best:  90.00%, tr:  98.98%, tr_best:  99.69%, epoch time: 55.66 seconds, 0.93 minutes\n",
      "layer   1  Sparsity: 91.0737%\n",
      "layer   2  Sparsity: 57.0890%\n",
      "layer   3  Sparsity: 87.4910%\n",
      "total_backward_count 1585980 real_backward_count 219417  13.835%\n",
      "epoch-162 lr=['0.0039062'], tr/val_loss:  0.011917/  0.038236, val:  88.75%, val_best:  90.00%, tr:  99.28%, tr_best:  99.69%, epoch time: 56.02 seconds, 0.93 minutes\n",
      "layer   1  Sparsity: 91.0343%\n",
      "layer   2  Sparsity: 57.0705%\n",
      "layer   3  Sparsity: 87.5548%\n",
      "total_backward_count 1595770 real_backward_count 220026  13.788%\n",
      "epoch-163 lr=['0.0039062'], tr/val_loss:  0.012019/  0.035313, val:  91.25%, val_best:  91.25%, tr:  99.08%, tr_best:  99.69%, epoch time: 55.53 seconds, 0.93 minutes\n",
      "layer   1  Sparsity: 91.0668%\n",
      "layer   2  Sparsity: 57.0797%\n",
      "layer   3  Sparsity: 87.6165%\n",
      "total_backward_count 1605560 real_backward_count 220633  13.742%\n",
      "epoch-164 lr=['0.0039062'], tr/val_loss:  0.012131/  0.040750, val:  86.67%, val_best:  91.25%, tr:  99.28%, tr_best:  99.69%, epoch time: 55.36 seconds, 0.92 minutes\n",
      "layer   1  Sparsity: 91.0988%\n",
      "layer   2  Sparsity: 57.0621%\n",
      "layer   3  Sparsity: 87.6466%\n",
      "total_backward_count 1615350 real_backward_count 221257  13.697%\n",
      "epoch-165 lr=['0.0039062'], tr/val_loss:  0.011666/  0.037024, val:  88.75%, val_best:  91.25%, tr:  99.49%, tr_best:  99.69%, epoch time: 55.32 seconds, 0.92 minutes\n",
      "layer   1  Sparsity: 91.0884%\n",
      "layer   2  Sparsity: 57.0705%\n",
      "layer   3  Sparsity: 87.7006%\n",
      "total_backward_count 1625140 real_backward_count 221864  13.652%\n",
      "epoch-166 lr=['0.0039062'], tr/val_loss:  0.011700/  0.037321, val:  87.92%, val_best:  91.25%, tr:  99.18%, tr_best:  99.69%, epoch time: 56.09 seconds, 0.93 minutes\n",
      "layer   1  Sparsity: 91.0763%\n",
      "layer   2  Sparsity: 57.0588%\n",
      "layer   3  Sparsity: 87.7375%\n",
      "total_backward_count 1634930 real_backward_count 222427  13.605%\n",
      "epoch-167 lr=['0.0039062'], tr/val_loss:  0.011119/  0.037418, val:  87.92%, val_best:  91.25%, tr:  99.28%, tr_best:  99.69%, epoch time: 55.71 seconds, 0.93 minutes\n",
      "layer   1  Sparsity: 91.0634%\n",
      "layer   2  Sparsity: 57.0712%\n",
      "layer   3  Sparsity: 87.7674%\n",
      "total_backward_count 1644720 real_backward_count 222955  13.556%\n",
      "epoch-168 lr=['0.0039062'], tr/val_loss:  0.011466/  0.039610, val:  87.08%, val_best:  91.25%, tr:  99.80%, tr_best:  99.80%, epoch time: 55.53 seconds, 0.93 minutes\n",
      "layer   1  Sparsity: 91.0864%\n",
      "layer   2  Sparsity: 57.0709%\n",
      "layer   3  Sparsity: 87.7642%\n",
      "total_backward_count 1654510 real_backward_count 223532  13.510%\n",
      "epoch-169 lr=['0.0039062'], tr/val_loss:  0.011703/  0.036439, val:  90.00%, val_best:  91.25%, tr:  99.49%, tr_best:  99.80%, epoch time: 55.98 seconds, 0.93 minutes\n",
      "layer   1  Sparsity: 91.0700%\n",
      "layer   2  Sparsity: 56.9767%\n",
      "layer   3  Sparsity: 87.8667%\n",
      "total_backward_count 1664300 real_backward_count 224117  13.466%\n",
      "epoch-170 lr=['0.0039062'], tr/val_loss:  0.011346/  0.038859, val:  89.17%, val_best:  91.25%, tr:  99.59%, tr_best:  99.80%, epoch time: 55.88 seconds, 0.93 minutes\n",
      "layer   1  Sparsity: 91.0751%\n",
      "layer   2  Sparsity: 57.0530%\n",
      "layer   3  Sparsity: 87.9668%\n",
      "total_backward_count 1674090 real_backward_count 224661  13.420%\n",
      "epoch-171 lr=['0.0039062'], tr/val_loss:  0.011620/  0.036309, val:  89.58%, val_best:  91.25%, tr:  99.49%, tr_best:  99.80%, epoch time: 56.33 seconds, 0.94 minutes\n",
      "layer   1  Sparsity: 91.0755%\n",
      "layer   2  Sparsity: 56.9568%\n",
      "layer   3  Sparsity: 88.0292%\n",
      "total_backward_count 1683880 real_backward_count 225249  13.377%\n",
      "epoch-172 lr=['0.0039062'], tr/val_loss:  0.011222/  0.036970, val:  88.75%, val_best:  91.25%, tr:  99.39%, tr_best:  99.80%, epoch time: 55.51 seconds, 0.93 minutes\n",
      "layer   1  Sparsity: 91.1021%\n",
      "layer   2  Sparsity: 57.0094%\n",
      "layer   3  Sparsity: 88.0255%\n",
      "total_backward_count 1693670 real_backward_count 225798  13.332%\n",
      "epoch-173 lr=['0.0039062'], tr/val_loss:  0.011571/  0.039252, val:  86.25%, val_best:  91.25%, tr:  99.28%, tr_best:  99.80%, epoch time: 56.27 seconds, 0.94 minutes\n",
      "layer   1  Sparsity: 91.1136%\n",
      "layer   2  Sparsity: 57.0904%\n",
      "layer   3  Sparsity: 88.0552%\n",
      "total_backward_count 1703460 real_backward_count 226381  13.289%\n",
      "epoch-174 lr=['0.0039062'], tr/val_loss:  0.011634/  0.036548, val:  90.00%, val_best:  91.25%, tr:  99.49%, tr_best:  99.80%, epoch time: 55.75 seconds, 0.93 minutes\n",
      "layer   1  Sparsity: 91.1158%\n",
      "layer   2  Sparsity: 57.1064%\n",
      "layer   3  Sparsity: 88.0442%\n",
      "total_backward_count 1713250 real_backward_count 226958  13.247%\n",
      "epoch-175 lr=['0.0039062'], tr/val_loss:  0.011860/  0.037179, val:  87.92%, val_best:  91.25%, tr:  99.80%, tr_best:  99.80%, epoch time: 56.57 seconds, 0.94 minutes\n",
      "layer   1  Sparsity: 91.0710%\n",
      "layer   2  Sparsity: 57.0921%\n",
      "layer   3  Sparsity: 88.1414%\n",
      "total_backward_count 1723040 real_backward_count 227551  13.206%\n",
      "epoch-176 lr=['0.0039062'], tr/val_loss:  0.010921/  0.036620, val:  87.50%, val_best:  91.25%, tr:  99.49%, tr_best:  99.80%, epoch time: 55.61 seconds, 0.93 minutes\n",
      "layer   1  Sparsity: 91.0937%\n",
      "layer   2  Sparsity: 57.0073%\n",
      "layer   3  Sparsity: 88.1861%\n",
      "total_backward_count 1732830 real_backward_count 228086  13.163%\n",
      "epoch-177 lr=['0.0039062'], tr/val_loss:  0.011272/  0.037463, val:  89.58%, val_best:  91.25%, tr:  99.18%, tr_best:  99.80%, epoch time: 56.11 seconds, 0.94 minutes\n",
      "layer   1  Sparsity: 91.0369%\n",
      "layer   2  Sparsity: 56.9037%\n",
      "layer   3  Sparsity: 88.2749%\n",
      "total_backward_count 1742620 real_backward_count 228648  13.121%\n",
      "epoch-178 lr=['0.0039062'], tr/val_loss:  0.011166/  0.037559, val:  89.17%, val_best:  91.25%, tr:  99.39%, tr_best:  99.80%, epoch time: 55.65 seconds, 0.93 minutes\n",
      "layer   1  Sparsity: 91.0652%\n",
      "layer   2  Sparsity: 56.8950%\n",
      "layer   3  Sparsity: 88.2797%\n",
      "total_backward_count 1752410 real_backward_count 229204  13.079%\n",
      "epoch-179 lr=['0.0039062'], tr/val_loss:  0.010676/  0.038392, val:  86.67%, val_best:  91.25%, tr:  99.80%, tr_best:  99.80%, epoch time: 55.09 seconds, 0.92 minutes\n",
      "layer   1  Sparsity: 91.0384%\n",
      "layer   2  Sparsity: 56.8539%\n",
      "layer   3  Sparsity: 88.3210%\n",
      "total_backward_count 1762200 real_backward_count 229722  13.036%\n",
      "epoch-180 lr=['0.0039062'], tr/val_loss:  0.010574/  0.036889, val:  88.33%, val_best:  91.25%, tr:  99.39%, tr_best:  99.80%, epoch time: 55.89 seconds, 0.93 minutes\n",
      "layer   1  Sparsity: 91.0934%\n",
      "layer   2  Sparsity: 56.8900%\n",
      "layer   3  Sparsity: 88.2760%\n",
      "total_backward_count 1771990 real_backward_count 230233  12.993%\n",
      "epoch-181 lr=['0.0039062'], tr/val_loss:  0.011012/  0.037508, val:  87.50%, val_best:  91.25%, tr:  99.59%, tr_best:  99.80%, epoch time: 55.46 seconds, 0.92 minutes\n",
      "layer   1  Sparsity: 91.0986%\n",
      "layer   2  Sparsity: 56.8661%\n",
      "layer   3  Sparsity: 88.3317%\n",
      "total_backward_count 1781780 real_backward_count 230786  12.953%\n",
      "epoch-182 lr=['0.0039062'], tr/val_loss:  0.010584/  0.039385, val:  87.92%, val_best:  91.25%, tr:  99.80%, tr_best:  99.80%, epoch time: 55.69 seconds, 0.93 minutes\n",
      "layer   1  Sparsity: 91.0545%\n",
      "layer   2  Sparsity: 56.8334%\n",
      "layer   3  Sparsity: 88.3990%\n",
      "total_backward_count 1791570 real_backward_count 231325  12.912%\n",
      "epoch-183 lr=['0.0039062'], tr/val_loss:  0.010629/  0.037920, val:  86.25%, val_best:  91.25%, tr:  99.59%, tr_best:  99.80%, epoch time: 55.38 seconds, 0.92 minutes\n",
      "layer   1  Sparsity: 91.0339%\n",
      "layer   2  Sparsity: 56.9119%\n",
      "layer   3  Sparsity: 88.3425%\n",
      "total_backward_count 1801360 real_backward_count 231853  12.871%\n",
      "epoch-184 lr=['0.0039062'], tr/val_loss:  0.010797/  0.036147, val:  90.42%, val_best:  91.25%, tr:  99.59%, tr_best:  99.80%, epoch time: 55.51 seconds, 0.93 minutes\n",
      "layer   1  Sparsity: 91.0728%\n",
      "layer   2  Sparsity: 56.8985%\n",
      "layer   3  Sparsity: 88.4385%\n",
      "total_backward_count 1811150 real_backward_count 232375  12.830%\n",
      "epoch-185 lr=['0.0039062'], tr/val_loss:  0.010346/  0.041421, val:  85.83%, val_best:  91.25%, tr:  99.49%, tr_best:  99.80%, epoch time: 55.15 seconds, 0.92 minutes\n",
      "layer   1  Sparsity: 91.1055%\n",
      "layer   2  Sparsity: 56.9585%\n",
      "layer   3  Sparsity: 88.3962%\n",
      "total_backward_count 1820940 real_backward_count 232858  12.788%\n",
      "epoch-186 lr=['0.0039062'], tr/val_loss:  0.010433/  0.037308, val:  89.17%, val_best:  91.25%, tr:  99.69%, tr_best:  99.80%, epoch time: 56.46 seconds, 0.94 minutes\n",
      "layer   1  Sparsity: 91.0748%\n",
      "layer   2  Sparsity: 56.9740%\n",
      "layer   3  Sparsity: 88.4636%\n",
      "total_backward_count 1830730 real_backward_count 233353  12.746%\n",
      "epoch-187 lr=['0.0039062'], tr/val_loss:  0.010989/  0.037126, val:  88.33%, val_best:  91.25%, tr:  99.69%, tr_best:  99.80%, epoch time: 55.73 seconds, 0.93 minutes\n",
      "layer   1  Sparsity: 91.0398%\n",
      "layer   2  Sparsity: 56.9656%\n",
      "layer   3  Sparsity: 88.5418%\n",
      "total_backward_count 1840520 real_backward_count 233896  12.708%\n",
      "epoch-188 lr=['0.0039062'], tr/val_loss:  0.010499/  0.038282, val:  89.17%, val_best:  91.25%, tr:  99.59%, tr_best:  99.80%, epoch time: 55.58 seconds, 0.93 minutes\n",
      "layer   1  Sparsity: 91.0975%\n",
      "layer   2  Sparsity: 56.9862%\n",
      "layer   3  Sparsity: 88.5628%\n",
      "total_backward_count 1850310 real_backward_count 234406  12.668%\n",
      "epoch-189 lr=['0.0039062'], tr/val_loss:  0.010600/  0.037324, val:  89.58%, val_best:  91.25%, tr:  99.39%, tr_best:  99.80%, epoch time: 55.86 seconds, 0.93 minutes\n",
      "layer   1  Sparsity: 91.0138%\n",
      "layer   2  Sparsity: 56.9504%\n",
      "layer   3  Sparsity: 88.5801%\n",
      "total_backward_count 1860100 real_backward_count 234919  12.629%\n",
      "epoch-190 lr=['0.0039062'], tr/val_loss:  0.010046/  0.036619, val:  89.17%, val_best:  91.25%, tr:  99.69%, tr_best:  99.80%, epoch time: 55.75 seconds, 0.93 minutes\n",
      "layer   1  Sparsity: 91.0867%\n",
      "layer   2  Sparsity: 56.9749%\n",
      "layer   3  Sparsity: 88.5342%\n",
      "total_backward_count 1869890 real_backward_count 235393  12.589%\n",
      "epoch-191 lr=['0.0039062'], tr/val_loss:  0.010876/  0.037508, val:  88.75%, val_best:  91.25%, tr:  99.39%, tr_best:  99.80%, epoch time: 55.76 seconds, 0.93 minutes\n",
      "layer   1  Sparsity: 91.0773%\n",
      "layer   2  Sparsity: 56.9622%\n",
      "layer   3  Sparsity: 88.5936%\n",
      "total_backward_count 1879680 real_backward_count 235935  12.552%\n",
      "epoch-192 lr=['0.0039062'], tr/val_loss:  0.010778/  0.036410, val:  89.58%, val_best:  91.25%, tr:  99.28%, tr_best:  99.80%, epoch time: 55.77 seconds, 0.93 minutes\n",
      "layer   1  Sparsity: 91.1070%\n",
      "layer   2  Sparsity: 56.9819%\n",
      "layer   3  Sparsity: 88.6383%\n",
      "total_backward_count 1889470 real_backward_count 236465  12.515%\n",
      "epoch-193 lr=['0.0039062'], tr/val_loss:  0.010068/  0.039000, val:  86.67%, val_best:  91.25%, tr:  99.59%, tr_best:  99.80%, epoch time: 55.70 seconds, 0.93 minutes\n",
      "layer   1  Sparsity: 91.0563%\n",
      "layer   2  Sparsity: 56.9804%\n",
      "layer   3  Sparsity: 88.6875%\n",
      "total_backward_count 1899260 real_backward_count 236933  12.475%\n",
      "epoch-194 lr=['0.0039062'], tr/val_loss:  0.010905/  0.038414, val:  86.67%, val_best:  91.25%, tr:  99.59%, tr_best:  99.80%, epoch time: 55.63 seconds, 0.93 minutes\n",
      "layer   1  Sparsity: 91.0715%\n",
      "layer   2  Sparsity: 56.9756%\n",
      "layer   3  Sparsity: 88.7029%\n",
      "total_backward_count 1909050 real_backward_count 237456  12.438%\n",
      "epoch-195 lr=['0.0039062'], tr/val_loss:  0.009802/  0.038443, val:  85.42%, val_best:  91.25%, tr:  99.49%, tr_best:  99.80%, epoch time: 55.91 seconds, 0.93 minutes\n",
      "layer   1  Sparsity: 91.0914%\n",
      "layer   2  Sparsity: 56.9370%\n",
      "layer   3  Sparsity: 88.7458%\n",
      "total_backward_count 1918840 real_backward_count 237922  12.399%\n",
      "epoch-196 lr=['0.0039062'], tr/val_loss:  0.009870/  0.038920, val:  84.58%, val_best:  91.25%, tr:  99.39%, tr_best:  99.80%, epoch time: 56.20 seconds, 0.94 minutes\n",
      "layer   1  Sparsity: 91.0643%\n",
      "layer   2  Sparsity: 56.9081%\n",
      "layer   3  Sparsity: 88.7971%\n",
      "total_backward_count 1928630 real_backward_count 238390  12.361%\n",
      "epoch-197 lr=['0.0039062'], tr/val_loss:  0.010379/  0.036725, val:  90.42%, val_best:  91.25%, tr:  99.39%, tr_best:  99.80%, epoch time: 55.36 seconds, 0.92 minutes\n",
      "layer   1  Sparsity: 91.1018%\n",
      "layer   2  Sparsity: 56.9303%\n",
      "layer   3  Sparsity: 88.9054%\n",
      "total_backward_count 1938420 real_backward_count 238914  12.325%\n",
      "epoch-198 lr=['0.0039062'], tr/val_loss:  0.009807/  0.036232, val:  90.83%, val_best:  91.25%, tr:  99.49%, tr_best:  99.80%, epoch time: 55.84 seconds, 0.93 minutes\n",
      "layer   1  Sparsity: 91.0808%\n",
      "layer   2  Sparsity: 56.9418%\n",
      "layer   3  Sparsity: 88.8713%\n",
      "total_backward_count 1948210 real_backward_count 239379  12.287%\n",
      "epoch-199 lr=['0.0039062'], tr/val_loss:  0.009771/  0.035397, val:  90.42%, val_best:  91.25%, tr:  99.49%, tr_best:  99.80%, epoch time: 56.46 seconds, 0.94 minutes\n",
      "layer   1  Sparsity: 91.0770%\n",
      "layer   2  Sparsity: 56.9337%\n",
      "layer   3  Sparsity: 88.8693%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "db298e8c13a448ac9bcb6857f98aaf62",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.006 MB of 0.006 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà</td></tr><tr><td>iter_acc</td><td>‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñÅ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà</td></tr><tr><td>summary_val_acc</td><td>‚ñÅ‚ñÇ‚ñÇ‚ñÅ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÉ‚ñÖ‚ñÜ‚ñá‚ñÜ‚ñÖ‚ñá‚ñá‚ñá‚ñÜ‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñà‚ñá‚ñà‚ñá‚ñá‚ñà‚ñá‚ñá‚ñá‚ñà</td></tr><tr><td>tr_acc</td><td>‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà</td></tr><tr><td>tr_epoch_loss</td><td>‚ñà‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ</td></tr><tr><td>val_acc_best</td><td>‚ñÅ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà</td></tr><tr><td>val_acc_now</td><td>‚ñÅ‚ñÇ‚ñÇ‚ñÅ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÉ‚ñÖ‚ñÜ‚ñá‚ñÜ‚ñÖ‚ñá‚ñá‚ñá‚ñÜ‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñà‚ñá‚ñà‚ñá‚ñá‚ñà‚ñá‚ñá‚ñá‚ñà</td></tr><tr><td>val_loss</td><td>‚ñà‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÇ‚ñÇ‚ñÅ‚ñÇ‚ñÅ‚ñÅ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÅ</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>199</td></tr><tr><td>iter_acc</td><td>1.0</td></tr><tr><td>tr_acc</td><td>0.99489</td></tr><tr><td>tr_epoch_loss</td><td>0.00977</td></tr><tr><td>val_acc_best</td><td>0.9125</td></tr><tr><td>val_acc_now</td><td>0.90417</td></tr><tr><td>val_loss</td><td>0.0354</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">winter-sweep-4</strong> at: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/89j6jxht' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/89j6jxht</a><br/> View project at: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>/data2/bh_wandb/wandb/run-20251120_041226-89j6jxht/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require(\"core\")`! See https://wandb.me/wandb-core for more information."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 0uwqlisi with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBATCH: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBN_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBPTT_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tDFA_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tIMAGE_SIZE: 14\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tOTTT_input_trace_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tTIME: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tUDA_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \talpha_uda: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbias: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcfg: [200, 200]\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tchaching_on: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tconvTrue_fcFalse: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdata_path: /data2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tddp_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdenoise_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdvs_clipping: 14\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdvs_duration: 25000\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepoch_num: 200\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \texclude_class: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \textra_train_dataset: -1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tinitial_pooling: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlast_lif: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.00390625\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_sg_width: 4\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_decay: 0.5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_init: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_reset: 10000\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_threshold: 0.015625\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmerge_polarities: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmy_seed: 20622\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnet_print: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_workers: 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer_what: SGD\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tpin_memory: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tpre_trained: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tpre_trained_path: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \trate_coding: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tscheduler_name: no\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsingle_step: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsurrogate: hard_sigmoid\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_conv_kernel_size: 3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_conv_padding: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_conv_stride: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_trace_const1: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_trace_const2: 0.5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \ttdBN_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \ttemporal_filter: 5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \ttemporal_filter_accumulation: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \ttrace_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \twhich_data: DVS_GESTURE_TONIC\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.23.0 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.17.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/data2/bh_wandb/wandb/run-20251120_071901-0uwqlisi</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/0uwqlisi' target=\"_blank\">sparkling-sweep-5</a></strong> to <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/m41wfhay' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/m41wfhay</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/m41wfhay' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/m41wfhay</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/0uwqlisi' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/0uwqlisi</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'single_step' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'my_seed' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'TIME' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BATCH' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'IMAGE_SIZE' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'which_data' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'data_path' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'rate_coding' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_init' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_decay' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_threshold' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_reset' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_sg_width' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_conv_kernel_size' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_conv_stride' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_conv_padding' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_trace_const1' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_trace_const2' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'pre_trained' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'convTrue_fcFalse' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'cfg' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'net_print' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'pre_trained_path' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'learning_rate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'epoch_num' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'tdBN_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BN_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'surrogate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BPTT_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'optimizer_what' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'scheduler_name' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'ddp_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'dvs_clipping' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'dvs_duration' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'DFA_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'trace_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'OTTT_input_trace_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'exclude_class' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'merge_polarities' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'denoise_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'extra_train_dataset' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'num_workers' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'chaching_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'pin_memory' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'UDA_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'alpha_uda' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'bias' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'last_lif' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'temporal_filter' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'initial_pooling' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'temporal_filter_accumulation' was locked by 'sweep' (ignored update).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "param {'devices': '3', 'single_step': True, 'unique_name': '20251120_071910_846', 'my_seed': 20622, 'TIME': 10, 'BATCH': 1, 'IMAGE_SIZE': 14, 'which_data': 'DVS_GESTURE_TONIC', 'data_path': '/data2', 'rate_coding': False, 'lif_layer_v_init': 0, 'lif_layer_v_decay': 0.5, 'lif_layer_v_threshold': 0.015625, 'lif_layer_v_reset': 10000, 'lif_layer_sg_width': 4, 'synapse_conv_kernel_size': 3, 'synapse_conv_stride': 1, 'synapse_conv_padding': 1, 'synapse_trace_const1': 1, 'synapse_trace_const2': 0.5, 'pre_trained': False, 'convTrue_fcFalse': False, 'cfg': [200, 200], 'net_print': True, 'pre_trained_path': '', 'learning_rate': 0.00390625, 'epoch_num': 200, 'tdBN_on': False, 'BN_on': False, 'surrogate': 'hard_sigmoid', 'BPTT_on': False, 'optimizer_what': 'SGD', 'scheduler_name': 'no', 'ddp_on': False, 'dvs_clipping': 14, 'dvs_duration': 25000, 'DFA_on': False, 'trace_on': False, 'OTTT_input_trace_on': False, 'exclude_class': True, 'merge_polarities': True, 'denoise_on': False, 'extra_train_dataset': -1, 'num_workers': 2, 'chaching_on': True, 'pin_memory': True, 'UDA_on': False, 'alpha_uda': 1, 'bias': False, 'last_lif': False, 'temporal_filter': 5, 'initial_pooling': 1, 'temporal_filter_accumulation': False, 'quantize_bit_list': [], 'scale_exp': [[999, 998], [999, 999], [999, 999]]} \n",
      "\n",
      "Ïù¥ Îç∞Ïù¥ÌÑ∞ÏÖãÏùò Îç∞Ïù¥ÌÑ∞ Í∞úÏàòÎäî 979 ÏûÖÎãàÎã§. (test setÏùÄ ÏïàÎ∞îÎÄåÍ≤å Ìï¥ÎÜ®Îã§ ÏïåÏ†ú)\n",
      "Ïù¥ Îç∞Ïù¥ÌÑ∞ÏÖãÏùò Îç∞Ïù¥ÌÑ∞ Í∞úÏàòÎäî 240 ÏûÖÎãàÎã§. (test setÏùÄ ÏïàÎ∞îÎÄåÍ≤å Ìï¥ÎÜ®Îã§ ÏïåÏ†ú)\n",
      "dataset_hash = 0e8a8f2d81b4fe037308b5d792c4a037\n",
      "cache path exists\n",
      "\n",
      "len(train_loader): 979 BATCH: 1 train_data_count: 979\n",
      "len(test_loader): 240 BATCH: 1\n",
      "\n",
      "device ==> cuda\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " layer_count 1\n",
      "weight bias bit 0\n",
      "weight exp, bias exp None None\n",
      "bit_for_output 0 exp_for_output None \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "LIF 1 sg_bit 0\n",
      "\n",
      "\n",
      "++++++++++++++++++++++++\n",
      "\n",
      " lif layer 1 v_bit: 0, v_exp: None\n",
      "\n",
      "++++++++++++++++++++++++++++++++++++++++++++++\n",
      "\n",
      "\n",
      "\n",
      " layer_count 2\n",
      "weight bias bit 0\n",
      "weight exp, bias exp None None\n",
      "bit_for_output 0 exp_for_output None \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "LIF 2 sg_bit 0\n",
      "\n",
      "\n",
      "++++++++++++++++++++++++\n",
      "\n",
      " lif layer 2 v_bit: 0, v_exp: None\n",
      "\n",
      "++++++++++++++++++++++++++++++++++++++++++++++\n",
      "\n",
      "\n",
      "\n",
      " layer_count 3\n",
      "weight bias bit 0\n",
      "weight exp, bias exp None None\n",
      "bit_for_output 0 exp_for_output None \n",
      "\n",
      "\n",
      "\n",
      "DataParallel(\n",
      "  (module): REBORN_MY_SNN_FC(\n",
      "    (layers): REBORN_MY_Sequential(\n",
      "      (0): DimChanger_for_FC()\n",
      "      (1): SYNAPSE_FC(in_features=980, out_features=200, TIME=10, bias=False, sstep=True, time_different_weight=False, layer_count=1, quantize_bit_list=[], scale_exp=[[999, 998], [999, 999], [999, 999]], ANPI_MODE=False)\n",
      "      (2): LIF_layer(v_init=0, v_decay=0.5, v_threshold=0.015625, v_reset=10000, sg_width=4, surrogate=hard_sigmoid, BPTT_on=False, trace_const1=1, trace_const2=0.5, TIME=10, sstep=True, trace_on=False, layer_count=1, scale_exp=[[999, 998], [999, 999], [999, 999]], ANPI_MODE=False)\n",
      "      (3): SYNAPSE_FC(in_features=200, out_features=200, TIME=10, bias=False, sstep=True, time_different_weight=False, layer_count=2, quantize_bit_list=[], scale_exp=[[999, 998], [999, 999], [999, 999]], ANPI_MODE=False)\n",
      "      (4): LIF_layer(v_init=0, v_decay=0.5, v_threshold=0.015625, v_reset=10000, sg_width=4, surrogate=hard_sigmoid, BPTT_on=False, trace_const1=1, trace_const2=0.5, TIME=10, sstep=True, trace_on=False, layer_count=2, scale_exp=[[999, 998], [999, 999], [999, 999]], ANPI_MODE=False)\n",
      "      (5): SYNAPSE_FC(in_features=200, out_features=10, TIME=10, bias=False, sstep=True, time_different_weight=False, layer_count=3, quantize_bit_list=[], scale_exp=[[999, 998], [999, 999], [999, 999]], ANPI_MODE=False)\n",
      "    )\n",
      "  )\n",
      ")\n",
      "\n",
      "========================================================\n",
      "Trainable parameters: 238,000\n",
      "========================================================\n",
      "\n",
      "MySGD (\n",
      "Parameter Group 0\n",
      "    lr: 0.00390625\n",
      "    momentum: 0.0\n",
      ")\n",
      "total_backward_count 0 real_backward_count 0   0.000%\n",
      "epoch-0   lr=['0.0039062'], tr/val_loss:  0.067178/  0.085026, val:  45.00%, val_best:  45.00%, tr:  78.96%, tr_best:  78.96%, epoch time: 56.11 seconds, 0.94 minutes\n",
      "layer   1  Sparsity: 91.0487%\n",
      "layer   2  Sparsity: 60.1872%\n",
      "layer   3  Sparsity: 56.6276%\n",
      "total_backward_count 9790 real_backward_count 3313  33.841%\n",
      "epoch-1   lr=['0.0039062'], tr/val_loss:  0.052398/  0.075082, val:  48.33%, val_best:  48.33%, tr:  83.45%, tr_best:  83.45%, epoch time: 56.03 seconds, 0.93 minutes\n",
      "layer   1  Sparsity: 91.1015%\n",
      "layer   2  Sparsity: 60.3838%\n",
      "layer   3  Sparsity: 58.2462%\n",
      "total_backward_count 19580 real_backward_count 5844  29.847%\n",
      "epoch-2   lr=['0.0039062'], tr/val_loss:  0.049004/  0.070830, val:  58.33%, val_best:  58.33%, tr:  86.31%, tr_best:  86.31%, epoch time: 55.77 seconds, 0.93 minutes\n",
      "layer   1  Sparsity: 91.0859%\n",
      "layer   2  Sparsity: 60.2639%\n",
      "layer   3  Sparsity: 59.3935%\n",
      "total_backward_count 29370 real_backward_count 8277  28.182%\n",
      "epoch-3   lr=['0.0039062'], tr/val_loss:  0.046844/  0.071942, val:  54.58%, val_best:  58.33%, tr:  85.60%, tr_best:  86.31%, epoch time: 56.07 seconds, 0.93 minutes\n",
      "layer   1  Sparsity: 91.0786%\n",
      "layer   2  Sparsity: 59.8850%\n",
      "layer   3  Sparsity: 60.3020%\n",
      "total_backward_count 39160 real_backward_count 10552  26.946%\n",
      "epoch-4   lr=['0.0039062'], tr/val_loss:  0.045005/  0.077131, val:  52.92%, val_best:  58.33%, tr:  86.41%, tr_best:  86.41%, epoch time: 55.46 seconds, 0.92 minutes\n",
      "layer   1  Sparsity: 91.0299%\n",
      "layer   2  Sparsity: 59.5952%\n",
      "layer   3  Sparsity: 61.0580%\n",
      "total_backward_count 48950 real_backward_count 12744  26.035%\n",
      "epoch-5   lr=['0.0039062'], tr/val_loss:  0.044115/  0.062632, val:  60.83%, val_best:  60.83%, tr:  85.29%, tr_best:  86.41%, epoch time: 55.73 seconds, 0.93 minutes\n",
      "layer   1  Sparsity: 91.0585%\n",
      "layer   2  Sparsity: 59.2687%\n",
      "layer   3  Sparsity: 62.1372%\n",
      "total_backward_count 58740 real_backward_count 14943  25.439%\n",
      "epoch-6   lr=['0.0039062'], tr/val_loss:  0.043656/  0.062728, val:  61.25%, val_best:  61.25%, tr:  84.37%, tr_best:  86.41%, epoch time: 55.62 seconds, 0.93 minutes\n",
      "layer   1  Sparsity: 91.1021%\n",
      "layer   2  Sparsity: 59.0233%\n",
      "layer   3  Sparsity: 63.1181%\n",
      "total_backward_count 68530 real_backward_count 17182  25.072%\n",
      "epoch-7   lr=['0.0039062'], tr/val_loss:  0.042521/  0.069295, val:  58.33%, val_best:  61.25%, tr:  84.68%, tr_best:  86.41%, epoch time: 55.76 seconds, 0.93 minutes\n",
      "layer   1  Sparsity: 91.0908%\n",
      "layer   2  Sparsity: 58.7444%\n",
      "layer   3  Sparsity: 63.9741%\n",
      "total_backward_count 78320 real_backward_count 19365  24.725%\n",
      "epoch-8   lr=['0.0039062'], tr/val_loss:  0.042576/  0.061210, val:  61.25%, val_best:  61.25%, tr:  84.27%, tr_best:  86.41%, epoch time: 55.08 seconds, 0.92 minutes\n",
      "layer   1  Sparsity: 91.0988%\n",
      "layer   2  Sparsity: 58.5699%\n",
      "layer   3  Sparsity: 65.0258%\n",
      "total_backward_count 88110 real_backward_count 21630  24.549%\n",
      "epoch-9   lr=['0.0039062'], tr/val_loss:  0.041679/  0.071660, val:  57.08%, val_best:  61.25%, tr:  84.78%, tr_best:  86.41%, epoch time: 55.86 seconds, 0.93 minutes\n",
      "layer   1  Sparsity: 91.1025%\n",
      "layer   2  Sparsity: 58.3584%\n",
      "layer   3  Sparsity: 65.5598%\n",
      "total_backward_count 97900 real_backward_count 23824  24.335%\n",
      "epoch-10  lr=['0.0039062'], tr/val_loss:  0.040634/  0.061868, val:  67.08%, val_best:  67.08%, tr:  84.98%, tr_best:  86.41%, epoch time: 55.54 seconds, 0.93 minutes\n",
      "layer   1  Sparsity: 91.0828%\n",
      "layer   2  Sparsity: 58.2226%\n",
      "layer   3  Sparsity: 66.1854%\n",
      "total_backward_count 107690 real_backward_count 25989  24.133%\n",
      "epoch-11  lr=['0.0039062'], tr/val_loss:  0.040983/  0.064203, val:  64.58%, val_best:  67.08%, tr:  85.09%, tr_best:  86.41%, epoch time: 55.86 seconds, 0.93 minutes\n",
      "layer   1  Sparsity: 91.0758%\n",
      "layer   2  Sparsity: 58.1862%\n",
      "layer   3  Sparsity: 66.8659%\n",
      "total_backward_count 117480 real_backward_count 28204  24.007%\n",
      "epoch-12  lr=['0.0039062'], tr/val_loss:  0.040387/  0.062259, val:  61.25%, val_best:  67.08%, tr:  85.09%, tr_best:  86.41%, epoch time: 56.02 seconds, 0.93 minutes\n",
      "layer   1  Sparsity: 91.1050%\n",
      "layer   2  Sparsity: 58.1851%\n",
      "layer   3  Sparsity: 67.4718%\n",
      "total_backward_count 127270 real_backward_count 30445  23.922%\n",
      "epoch-13  lr=['0.0039062'], tr/val_loss:  0.039756/  0.060029, val:  63.33%, val_best:  67.08%, tr:  84.98%, tr_best:  86.41%, epoch time: 56.27 seconds, 0.94 minutes\n",
      "layer   1  Sparsity: 91.0972%\n",
      "layer   2  Sparsity: 58.0672%\n",
      "layer   3  Sparsity: 68.0212%\n",
      "total_backward_count 137060 real_backward_count 32590  23.778%\n",
      "epoch-14  lr=['0.0039062'], tr/val_loss:  0.038793/  0.056709, val:  69.58%, val_best:  69.58%, tr:  85.39%, tr_best:  86.41%, epoch time: 55.57 seconds, 0.93 minutes\n",
      "layer   1  Sparsity: 91.0786%\n",
      "layer   2  Sparsity: 58.0357%\n",
      "layer   3  Sparsity: 68.6285%\n",
      "total_backward_count 146850 real_backward_count 34730  23.650%\n",
      "epoch-15  lr=['0.0039062'], tr/val_loss:  0.038485/  0.061604, val:  64.17%, val_best:  69.58%, tr:  85.39%, tr_best:  86.41%, epoch time: 55.64 seconds, 0.93 minutes\n",
      "layer   1  Sparsity: 91.0447%\n",
      "layer   2  Sparsity: 57.9591%\n",
      "layer   3  Sparsity: 69.1425%\n",
      "total_backward_count 156640 real_backward_count 36855  23.528%\n",
      "epoch-16  lr=['0.0039062'], tr/val_loss:  0.038943/  0.057654, val:  67.08%, val_best:  69.58%, tr:  82.94%, tr_best:  86.41%, epoch time: 55.89 seconds, 0.93 minutes\n",
      "layer   1  Sparsity: 91.0806%\n",
      "layer   2  Sparsity: 57.9774%\n",
      "layer   3  Sparsity: 69.6243%\n",
      "total_backward_count 166430 real_backward_count 39138  23.516%\n",
      "epoch-17  lr=['0.0039062'], tr/val_loss:  0.037957/  0.056473, val:  70.00%, val_best:  70.00%, tr:  86.01%, tr_best:  86.41%, epoch time: 56.40 seconds, 0.94 minutes\n",
      "layer   1  Sparsity: 91.0575%\n",
      "layer   2  Sparsity: 58.0322%\n",
      "layer   3  Sparsity: 70.1646%\n",
      "total_backward_count 176220 real_backward_count 41251  23.409%\n",
      "epoch-18  lr=['0.0039062'], tr/val_loss:  0.037507/  0.064170, val:  60.83%, val_best:  70.00%, tr:  85.60%, tr_best:  86.41%, epoch time: 55.36 seconds, 0.92 minutes\n",
      "layer   1  Sparsity: 91.0949%\n",
      "layer   2  Sparsity: 58.0071%\n",
      "layer   3  Sparsity: 70.5594%\n",
      "total_backward_count 186010 real_backward_count 43352  23.306%\n",
      "epoch-19  lr=['0.0039062'], tr/val_loss:  0.037149/  0.057416, val:  64.17%, val_best:  70.00%, tr:  86.01%, tr_best:  86.41%, epoch time: 56.00 seconds, 0.93 minutes\n",
      "layer   1  Sparsity: 91.1110%\n",
      "layer   2  Sparsity: 58.0089%\n",
      "layer   3  Sparsity: 71.0766%\n",
      "total_backward_count 195800 real_backward_count 45445  23.210%\n",
      "epoch-20  lr=['0.0039062'], tr/val_loss:  0.037428/  0.058463, val:  63.33%, val_best:  70.00%, tr:  85.09%, tr_best:  86.41%, epoch time: 55.42 seconds, 0.92 minutes\n",
      "layer   1  Sparsity: 91.0239%\n",
      "layer   2  Sparsity: 57.9618%\n",
      "layer   3  Sparsity: 71.5188%\n",
      "total_backward_count 205590 real_backward_count 47571  23.139%\n",
      "epoch-21  lr=['0.0039062'], tr/val_loss:  0.037170/  0.063287, val:  57.08%, val_best:  70.00%, tr:  87.03%, tr_best:  87.03%, epoch time: 55.43 seconds, 0.92 minutes\n",
      "layer   1  Sparsity: 91.0873%\n",
      "layer   2  Sparsity: 57.9795%\n",
      "layer   3  Sparsity: 71.8940%\n",
      "total_backward_count 215380 real_backward_count 49690  23.071%\n",
      "epoch-22  lr=['0.0039062'], tr/val_loss:  0.036122/  0.055652, val:  70.42%, val_best:  70.42%, tr:  86.21%, tr_best:  87.03%, epoch time: 55.35 seconds, 0.92 minutes\n",
      "layer   1  Sparsity: 91.0706%\n",
      "layer   2  Sparsity: 57.9492%\n",
      "layer   3  Sparsity: 72.3628%\n",
      "total_backward_count 225170 real_backward_count 51750  22.983%\n",
      "epoch-23  lr=['0.0039062'], tr/val_loss:  0.035823/  0.058439, val:  66.25%, val_best:  70.42%, tr:  86.93%, tr_best:  87.03%, epoch time: 55.05 seconds, 0.92 minutes\n",
      "layer   1  Sparsity: 91.0105%\n",
      "layer   2  Sparsity: 57.9224%\n",
      "layer   3  Sparsity: 72.5760%\n",
      "total_backward_count 234960 real_backward_count 53775  22.887%\n",
      "epoch-24  lr=['0.0039062'], tr/val_loss:  0.035962/  0.057830, val:  62.92%, val_best:  70.42%, tr:  87.23%, tr_best:  87.23%, epoch time: 55.76 seconds, 0.93 minutes\n",
      "layer   1  Sparsity: 91.0647%\n",
      "layer   2  Sparsity: 58.0438%\n",
      "layer   3  Sparsity: 72.9716%\n",
      "total_backward_count 244750 real_backward_count 55831  22.811%\n",
      "epoch-25  lr=['0.0039062'], tr/val_loss:  0.035847/  0.069941, val:  57.08%, val_best:  70.42%, tr:  88.05%, tr_best:  88.05%, epoch time: 55.11 seconds, 0.92 minutes\n",
      "layer   1  Sparsity: 91.0536%\n",
      "layer   2  Sparsity: 58.0296%\n",
      "layer   3  Sparsity: 73.3909%\n",
      "total_backward_count 254540 real_backward_count 57912  22.752%\n",
      "epoch-26  lr=['0.0039062'], tr/val_loss:  0.035733/  0.060321, val:  62.08%, val_best:  70.42%, tr:  86.31%, tr_best:  88.05%, epoch time: 55.71 seconds, 0.93 minutes\n",
      "layer   1  Sparsity: 91.1192%\n",
      "layer   2  Sparsity: 58.1554%\n",
      "layer   3  Sparsity: 73.8102%\n",
      "total_backward_count 264330 real_backward_count 59978  22.691%\n",
      "epoch-27  lr=['0.0039062'], tr/val_loss:  0.035730/  0.053168, val:  77.08%, val_best:  77.08%, tr:  86.72%, tr_best:  88.05%, epoch time: 56.17 seconds, 0.94 minutes\n",
      "layer   1  Sparsity: 91.0713%\n",
      "layer   2  Sparsity: 58.1830%\n",
      "layer   3  Sparsity: 74.2012%\n",
      "total_backward_count 274120 real_backward_count 62086  22.649%\n",
      "epoch-28  lr=['0.0039062'], tr/val_loss:  0.034888/  0.059473, val:  62.50%, val_best:  77.08%, tr:  87.54%, tr_best:  88.05%, epoch time: 55.90 seconds, 0.93 minutes\n",
      "layer   1  Sparsity: 91.0508%\n",
      "layer   2  Sparsity: 58.1746%\n",
      "layer   3  Sparsity: 74.5119%\n",
      "total_backward_count 283910 real_backward_count 64095  22.576%\n",
      "epoch-29  lr=['0.0039062'], tr/val_loss:  0.034740/  0.054585, val:  70.00%, val_best:  77.08%, tr:  86.82%, tr_best:  88.05%, epoch time: 55.73 seconds, 0.93 minutes\n",
      "layer   1  Sparsity: 91.0534%\n",
      "layer   2  Sparsity: 58.1212%\n",
      "layer   3  Sparsity: 74.7766%\n",
      "total_backward_count 293700 real_backward_count 66122  22.513%\n",
      "epoch-30  lr=['0.0039062'], tr/val_loss:  0.034704/  0.055865, val:  73.75%, val_best:  77.08%, tr:  86.41%, tr_best:  88.05%, epoch time: 56.24 seconds, 0.94 minutes\n",
      "layer   1  Sparsity: 91.0926%\n",
      "layer   2  Sparsity: 58.1826%\n",
      "layer   3  Sparsity: 74.9299%\n",
      "total_backward_count 303490 real_backward_count 68167  22.461%\n",
      "epoch-31  lr=['0.0039062'], tr/val_loss:  0.034164/  0.054717, val:  71.67%, val_best:  77.08%, tr:  87.13%, tr_best:  88.05%, epoch time: 55.77 seconds, 0.93 minutes\n",
      "layer   1  Sparsity: 91.0793%\n",
      "layer   2  Sparsity: 58.1441%\n",
      "layer   3  Sparsity: 75.2614%\n",
      "total_backward_count 313280 real_backward_count 70168  22.398%\n",
      "epoch-32  lr=['0.0039062'], tr/val_loss:  0.034233/  0.053942, val:  70.83%, val_best:  77.08%, tr:  88.56%, tr_best:  88.56%, epoch time: 55.38 seconds, 0.92 minutes\n",
      "layer   1  Sparsity: 91.0225%\n",
      "layer   2  Sparsity: 58.1073%\n",
      "layer   3  Sparsity: 75.4913%\n",
      "total_backward_count 323070 real_backward_count 72168  22.338%\n",
      "epoch-33  lr=['0.0039062'], tr/val_loss:  0.033525/  0.055352, val:  65.42%, val_best:  77.08%, tr:  87.95%, tr_best:  88.56%, epoch time: 56.05 seconds, 0.93 minutes\n",
      "layer   1  Sparsity: 91.1252%\n",
      "layer   2  Sparsity: 58.1689%\n",
      "layer   3  Sparsity: 75.5907%\n",
      "total_backward_count 332860 real_backward_count 74107  22.264%\n",
      "epoch-34  lr=['0.0039062'], tr/val_loss:  0.032907/  0.063668, val:  58.33%, val_best:  77.08%, tr:  89.38%, tr_best:  89.38%, epoch time: 55.82 seconds, 0.93 minutes\n",
      "layer   1  Sparsity: 91.1177%\n",
      "layer   2  Sparsity: 58.2297%\n",
      "layer   3  Sparsity: 75.6071%\n",
      "total_backward_count 342650 real_backward_count 75955  22.167%\n",
      "epoch-35  lr=['0.0039062'], tr/val_loss:  0.032197/  0.060844, val:  67.08%, val_best:  77.08%, tr:  88.66%, tr_best:  89.38%, epoch time: 55.51 seconds, 0.93 minutes\n",
      "layer   1  Sparsity: 91.0832%\n",
      "layer   2  Sparsity: 58.2490%\n",
      "layer   3  Sparsity: 75.7591%\n",
      "total_backward_count 352440 real_backward_count 77805  22.076%\n",
      "epoch-36  lr=['0.0039062'], tr/val_loss:  0.032110/  0.057105, val:  66.67%, val_best:  77.08%, tr:  90.09%, tr_best:  90.09%, epoch time: 55.75 seconds, 0.93 minutes\n",
      "layer   1  Sparsity: 91.0981%\n",
      "layer   2  Sparsity: 58.2945%\n",
      "layer   3  Sparsity: 75.9900%\n",
      "total_backward_count 362230 real_backward_count 79638  21.985%\n",
      "epoch-37  lr=['0.0039062'], tr/val_loss:  0.031795/  0.058410, val:  61.25%, val_best:  77.08%, tr:  88.66%, tr_best:  90.09%, epoch time: 55.53 seconds, 0.93 minutes\n",
      "layer   1  Sparsity: 91.0889%\n",
      "layer   2  Sparsity: 58.3505%\n",
      "layer   3  Sparsity: 76.1909%\n",
      "total_backward_count 372020 real_backward_count 81449  21.894%\n",
      "epoch-38  lr=['0.0039062'], tr/val_loss:  0.032162/  0.051990, val:  74.17%, val_best:  77.08%, tr:  90.30%, tr_best:  90.30%, epoch time: 55.72 seconds, 0.93 minutes\n",
      "layer   1  Sparsity: 91.0713%\n",
      "layer   2  Sparsity: 58.2646%\n",
      "layer   3  Sparsity: 76.5365%\n",
      "total_backward_count 381810 real_backward_count 83307  21.819%\n",
      "epoch-39  lr=['0.0039062'], tr/val_loss:  0.031733/  0.056021, val:  67.08%, val_best:  77.08%, tr:  90.09%, tr_best:  90.30%, epoch time: 56.21 seconds, 0.94 minutes\n",
      "layer   1  Sparsity: 91.0643%\n",
      "layer   2  Sparsity: 58.2398%\n",
      "layer   3  Sparsity: 76.8235%\n",
      "total_backward_count 391600 real_backward_count 85128  21.739%\n",
      "epoch-40  lr=['0.0039062'], tr/val_loss:  0.031793/  0.053032, val:  75.83%, val_best:  77.08%, tr:  89.68%, tr_best:  90.30%, epoch time: 56.04 seconds, 0.93 minutes\n",
      "layer   1  Sparsity: 91.1084%\n",
      "layer   2  Sparsity: 58.3057%\n",
      "layer   3  Sparsity: 77.0055%\n",
      "total_backward_count 401390 real_backward_count 86970  21.667%\n",
      "epoch-41  lr=['0.0039062'], tr/val_loss:  0.030515/  0.056713, val:  70.42%, val_best:  77.08%, tr:  90.81%, tr_best:  90.81%, epoch time: 55.57 seconds, 0.93 minutes\n",
      "layer   1  Sparsity: 91.0681%\n",
      "layer   2  Sparsity: 58.2913%\n",
      "layer   3  Sparsity: 77.2613%\n",
      "total_backward_count 411180 real_backward_count 88706  21.574%\n",
      "epoch-42  lr=['0.0039062'], tr/val_loss:  0.030835/  0.051640, val:  74.58%, val_best:  77.08%, tr:  90.30%, tr_best:  90.81%, epoch time: 56.01 seconds, 0.93 minutes\n",
      "layer   1  Sparsity: 91.0774%\n",
      "layer   2  Sparsity: 58.3155%\n",
      "layer   3  Sparsity: 77.5576%\n",
      "total_backward_count 420970 real_backward_count 90504  21.499%\n",
      "epoch-43  lr=['0.0039062'], tr/val_loss:  0.030666/  0.052199, val:  73.75%, val_best:  77.08%, tr:  89.99%, tr_best:  90.81%, epoch time: 55.83 seconds, 0.93 minutes\n",
      "layer   1  Sparsity: 91.0541%\n",
      "layer   2  Sparsity: 58.3726%\n",
      "layer   3  Sparsity: 77.7707%\n",
      "total_backward_count 430760 real_backward_count 92226  21.410%\n",
      "epoch-44  lr=['0.0039062'], tr/val_loss:  0.030546/  0.052760, val:  72.50%, val_best:  77.08%, tr:  91.22%, tr_best:  91.22%, epoch time: 55.75 seconds, 0.93 minutes\n",
      "layer   1  Sparsity: 91.0755%\n",
      "layer   2  Sparsity: 58.4799%\n",
      "layer   3  Sparsity: 77.8736%\n",
      "total_backward_count 440550 real_backward_count 93996  21.336%\n",
      "epoch-45  lr=['0.0039062'], tr/val_loss:  0.029526/  0.055069, val:  71.67%, val_best:  77.08%, tr:  91.01%, tr_best:  91.22%, epoch time: 56.14 seconds, 0.94 minutes\n",
      "layer   1  Sparsity: 91.0657%\n",
      "layer   2  Sparsity: 58.5757%\n",
      "layer   3  Sparsity: 78.0808%\n",
      "total_backward_count 450340 real_backward_count 95645  21.238%\n",
      "epoch-46  lr=['0.0039062'], tr/val_loss:  0.030128/  0.052091, val:  74.58%, val_best:  77.08%, tr:  91.83%, tr_best:  91.83%, epoch time: 56.28 seconds, 0.94 minutes\n",
      "layer   1  Sparsity: 91.0592%\n",
      "layer   2  Sparsity: 58.5737%\n",
      "layer   3  Sparsity: 78.2227%\n",
      "total_backward_count 460130 real_backward_count 97372  21.162%\n",
      "epoch-47  lr=['0.0039062'], tr/val_loss:  0.029242/  0.055448, val:  66.25%, val_best:  77.08%, tr:  91.93%, tr_best:  91.93%, epoch time: 55.80 seconds, 0.93 minutes\n",
      "layer   1  Sparsity: 91.0793%\n",
      "layer   2  Sparsity: 58.6411%\n",
      "layer   3  Sparsity: 78.2918%\n",
      "total_backward_count 469920 real_backward_count 99025  21.073%\n",
      "epoch-48  lr=['0.0039062'], tr/val_loss:  0.029085/  0.057745, val:  65.42%, val_best:  77.08%, tr:  91.52%, tr_best:  91.93%, epoch time: 55.37 seconds, 0.92 minutes\n",
      "layer   1  Sparsity: 91.0683%\n",
      "layer   2  Sparsity: 58.6311%\n",
      "layer   3  Sparsity: 78.5393%\n",
      "total_backward_count 479710 real_backward_count 100699  20.992%\n",
      "epoch-49  lr=['0.0039062'], tr/val_loss:  0.029491/  0.055171, val:  71.67%, val_best:  77.08%, tr:  91.22%, tr_best:  91.93%, epoch time: 56.48 seconds, 0.94 minutes\n",
      "layer   1  Sparsity: 91.0977%\n",
      "layer   2  Sparsity: 58.7075%\n",
      "layer   3  Sparsity: 78.5845%\n",
      "total_backward_count 489500 real_backward_count 102424  20.924%\n",
      "epoch-50  lr=['0.0039062'], tr/val_loss:  0.028533/  0.053607, val:  74.58%, val_best:  77.08%, tr:  91.62%, tr_best:  91.93%, epoch time: 55.98 seconds, 0.93 minutes\n",
      "layer   1  Sparsity: 91.0180%\n",
      "layer   2  Sparsity: 58.7487%\n",
      "layer   3  Sparsity: 78.9112%\n",
      "total_backward_count 499290 real_backward_count 104045  20.839%\n",
      "epoch-51  lr=['0.0039062'], tr/val_loss:  0.028052/  0.050205, val:  73.33%, val_best:  77.08%, tr:  93.16%, tr_best:  93.16%, epoch time: 55.73 seconds, 0.93 minutes\n",
      "layer   1  Sparsity: 91.0616%\n",
      "layer   2  Sparsity: 58.8726%\n",
      "layer   3  Sparsity: 79.0131%\n",
      "total_backward_count 509080 real_backward_count 105636  20.750%\n",
      "epoch-52  lr=['0.0039062'], tr/val_loss:  0.027904/  0.053675, val:  71.25%, val_best:  77.08%, tr:  93.46%, tr_best:  93.46%, epoch time: 56.29 seconds, 0.94 minutes\n",
      "layer   1  Sparsity: 91.0440%\n",
      "layer   2  Sparsity: 58.9162%\n",
      "layer   3  Sparsity: 79.2137%\n",
      "total_backward_count 518870 real_backward_count 107164  20.653%\n",
      "epoch-53  lr=['0.0039062'], tr/val_loss:  0.028645/  0.054207, val:  68.33%, val_best:  77.08%, tr:  94.08%, tr_best:  94.08%, epoch time: 55.87 seconds, 0.93 minutes\n",
      "layer   1  Sparsity: 91.0667%\n",
      "layer   2  Sparsity: 58.9501%\n",
      "layer   3  Sparsity: 79.4420%\n",
      "total_backward_count 528660 real_backward_count 108803  20.581%\n",
      "epoch-54  lr=['0.0039062'], tr/val_loss:  0.027524/  0.054778, val:  70.00%, val_best:  77.08%, tr:  93.56%, tr_best:  94.08%, epoch time: 55.88 seconds, 0.93 minutes\n",
      "layer   1  Sparsity: 91.0877%\n",
      "layer   2  Sparsity: 59.0317%\n",
      "layer   3  Sparsity: 79.4381%\n",
      "total_backward_count 538450 real_backward_count 110300  20.485%\n",
      "epoch-55  lr=['0.0039062'], tr/val_loss:  0.027314/  0.050069, val:  77.92%, val_best:  77.92%, tr:  93.56%, tr_best:  94.08%, epoch time: 55.66 seconds, 0.93 minutes\n",
      "layer   1  Sparsity: 91.0702%\n",
      "layer   2  Sparsity: 59.1186%\n",
      "layer   3  Sparsity: 79.4326%\n",
      "total_backward_count 548240 real_backward_count 111831  20.398%\n",
      "epoch-56  lr=['0.0039062'], tr/val_loss:  0.026960/  0.049221, val:  73.75%, val_best:  77.92%, tr:  93.16%, tr_best:  94.08%, epoch time: 56.35 seconds, 0.94 minutes\n",
      "layer   1  Sparsity: 91.0847%\n",
      "layer   2  Sparsity: 59.0974%\n",
      "layer   3  Sparsity: 79.6232%\n",
      "total_backward_count 558030 real_backward_count 113337  20.310%\n",
      "epoch-57  lr=['0.0039062'], tr/val_loss:  0.026680/  0.051061, val:  75.83%, val_best:  77.92%, tr:  94.59%, tr_best:  94.59%, epoch time: 55.73 seconds, 0.93 minutes\n",
      "layer   1  Sparsity: 91.0509%\n",
      "layer   2  Sparsity: 59.2067%\n",
      "layer   3  Sparsity: 79.6242%\n",
      "total_backward_count 567820 real_backward_count 114790  20.216%\n",
      "epoch-58  lr=['0.0039062'], tr/val_loss:  0.026253/  0.057308, val:  67.92%, val_best:  77.92%, tr:  94.59%, tr_best:  94.59%, epoch time: 55.56 seconds, 0.93 minutes\n",
      "layer   1  Sparsity: 91.1043%\n",
      "layer   2  Sparsity: 59.1751%\n",
      "layer   3  Sparsity: 79.6771%\n",
      "total_backward_count 577610 real_backward_count 116238  20.124%\n",
      "epoch-59  lr=['0.0039062'], tr/val_loss:  0.026324/  0.048660, val:  80.83%, val_best:  80.83%, tr:  92.85%, tr_best:  94.59%, epoch time: 56.23 seconds, 0.94 minutes\n",
      "layer   1  Sparsity: 91.0601%\n",
      "layer   2  Sparsity: 59.2265%\n",
      "layer   3  Sparsity: 79.7741%\n",
      "total_backward_count 587400 real_backward_count 117731  20.043%\n",
      "epoch-60  lr=['0.0039062'], tr/val_loss:  0.026529/  0.050553, val:  77.50%, val_best:  80.83%, tr:  93.16%, tr_best:  94.59%, epoch time: 56.23 seconds, 0.94 minutes\n",
      "layer   1  Sparsity: 91.0549%\n",
      "layer   2  Sparsity: 59.2283%\n",
      "layer   3  Sparsity: 79.8447%\n",
      "total_backward_count 597190 real_backward_count 119226  19.965%\n",
      "epoch-61  lr=['0.0039062'], tr/val_loss:  0.025884/  0.046592, val:  82.08%, val_best:  82.08%, tr:  94.69%, tr_best:  94.69%, epoch time: 55.89 seconds, 0.93 minutes\n",
      "layer   1  Sparsity: 91.0634%\n",
      "layer   2  Sparsity: 59.2445%\n",
      "layer   3  Sparsity: 79.9201%\n",
      "total_backward_count 606980 real_backward_count 120680  19.882%\n",
      "epoch-62  lr=['0.0039062'], tr/val_loss:  0.025781/  0.047319, val:  82.08%, val_best:  82.08%, tr:  94.28%, tr_best:  94.69%, epoch time: 56.11 seconds, 0.94 minutes\n",
      "layer   1  Sparsity: 91.0702%\n",
      "layer   2  Sparsity: 59.2845%\n",
      "layer   3  Sparsity: 80.0781%\n",
      "total_backward_count 616770 real_backward_count 122105  19.797%\n",
      "epoch-63  lr=['0.0039062'], tr/val_loss:  0.024867/  0.048638, val:  79.58%, val_best:  82.08%, tr:  94.79%, tr_best:  94.79%, epoch time: 56.04 seconds, 0.93 minutes\n",
      "layer   1  Sparsity: 91.0851%\n",
      "layer   2  Sparsity: 59.3664%\n",
      "layer   3  Sparsity: 80.0655%\n",
      "total_backward_count 626560 real_backward_count 123461  19.705%\n",
      "epoch-64  lr=['0.0039062'], tr/val_loss:  0.024146/  0.050300, val:  77.08%, val_best:  82.08%, tr:  95.40%, tr_best:  95.40%, epoch time: 55.05 seconds, 0.92 minutes\n",
      "layer   1  Sparsity: 91.0824%\n",
      "layer   2  Sparsity: 59.3379%\n",
      "layer   3  Sparsity: 80.2341%\n",
      "total_backward_count 636350 real_backward_count 124758  19.605%\n",
      "epoch-65  lr=['0.0039062'], tr/val_loss:  0.024162/  0.047276, val:  79.17%, val_best:  82.08%, tr:  94.99%, tr_best:  95.40%, epoch time: 56.08 seconds, 0.93 minutes\n",
      "layer   1  Sparsity: 91.0611%\n",
      "layer   2  Sparsity: 59.3349%\n",
      "layer   3  Sparsity: 80.2555%\n",
      "total_backward_count 646140 real_backward_count 126101  19.516%\n",
      "epoch-66  lr=['0.0039062'], tr/val_loss:  0.024513/  0.045653, val:  80.83%, val_best:  82.08%, tr:  95.40%, tr_best:  95.40%, epoch time: 55.58 seconds, 0.93 minutes\n",
      "layer   1  Sparsity: 91.1091%\n",
      "layer   2  Sparsity: 59.4968%\n",
      "layer   3  Sparsity: 80.2379%\n",
      "total_backward_count 655930 real_backward_count 127460  19.432%\n",
      "epoch-67  lr=['0.0039062'], tr/val_loss:  0.024114/  0.045505, val:  80.42%, val_best:  82.08%, tr:  95.20%, tr_best:  95.40%, epoch time: 55.74 seconds, 0.93 minutes\n",
      "layer   1  Sparsity: 91.0481%\n",
      "layer   2  Sparsity: 59.4671%\n",
      "layer   3  Sparsity: 80.4511%\n",
      "total_backward_count 665720 real_backward_count 128770  19.343%\n",
      "epoch-68  lr=['0.0039062'], tr/val_loss:  0.024733/  0.051279, val:  75.83%, val_best:  82.08%, tr:  95.81%, tr_best:  95.81%, epoch time: 56.06 seconds, 0.93 minutes\n",
      "layer   1  Sparsity: 91.0679%\n",
      "layer   2  Sparsity: 59.5408%\n",
      "layer   3  Sparsity: 80.6106%\n",
      "total_backward_count 675510 real_backward_count 130140  19.265%\n",
      "epoch-69  lr=['0.0039062'], tr/val_loss:  0.023112/  0.046847, val:  82.08%, val_best:  82.08%, tr:  96.53%, tr_best:  96.53%, epoch time: 55.58 seconds, 0.93 minutes\n",
      "layer   1  Sparsity: 91.0723%\n",
      "layer   2  Sparsity: 59.5989%\n",
      "layer   3  Sparsity: 80.6834%\n",
      "total_backward_count 685300 real_backward_count 131364  19.169%\n",
      "epoch-70  lr=['0.0039062'], tr/val_loss:  0.023561/  0.046089, val:  80.83%, val_best:  82.08%, tr:  96.53%, tr_best:  96.53%, epoch time: 55.21 seconds, 0.92 minutes\n",
      "layer   1  Sparsity: 91.0343%\n",
      "layer   2  Sparsity: 59.5526%\n",
      "layer   3  Sparsity: 80.7769%\n",
      "total_backward_count 695090 real_backward_count 132619  19.079%\n",
      "epoch-71  lr=['0.0039062'], tr/val_loss:  0.023100/  0.046272, val:  84.17%, val_best:  84.17%, tr:  96.94%, tr_best:  96.94%, epoch time: 55.83 seconds, 0.93 minutes\n",
      "layer   1  Sparsity: 91.1158%\n",
      "layer   2  Sparsity: 59.6008%\n",
      "layer   3  Sparsity: 80.8547%\n",
      "total_backward_count 704880 real_backward_count 133853  18.989%\n",
      "epoch-72  lr=['0.0039062'], tr/val_loss:  0.023047/  0.048276, val:  79.58%, val_best:  84.17%, tr:  97.55%, tr_best:  97.55%, epoch time: 56.35 seconds, 0.94 minutes\n",
      "layer   1  Sparsity: 91.0717%\n",
      "layer   2  Sparsity: 59.6437%\n",
      "layer   3  Sparsity: 80.8692%\n",
      "total_backward_count 714670 real_backward_count 135127  18.908%\n",
      "epoch-73  lr=['0.0039062'], tr/val_loss:  0.023105/  0.045994, val:  83.33%, val_best:  84.17%, tr:  96.94%, tr_best:  97.55%, epoch time: 55.67 seconds, 0.93 minutes\n",
      "layer   1  Sparsity: 91.1081%\n",
      "layer   2  Sparsity: 59.6947%\n",
      "layer   3  Sparsity: 80.9465%\n",
      "total_backward_count 724460 real_backward_count 136377  18.825%\n",
      "epoch-74  lr=['0.0039062'], tr/val_loss:  0.022715/  0.044302, val:  83.33%, val_best:  84.17%, tr:  96.73%, tr_best:  97.55%, epoch time: 56.30 seconds, 0.94 minutes\n",
      "layer   1  Sparsity: 91.0696%\n",
      "layer   2  Sparsity: 59.7143%\n",
      "layer   3  Sparsity: 81.0531%\n",
      "total_backward_count 734250 real_backward_count 137620  18.743%\n",
      "epoch-75  lr=['0.0039062'], tr/val_loss:  0.022582/  0.044642, val:  83.33%, val_best:  84.17%, tr:  97.24%, tr_best:  97.55%, epoch time: 55.81 seconds, 0.93 minutes\n",
      "layer   1  Sparsity: 91.0864%\n",
      "layer   2  Sparsity: 59.7852%\n",
      "layer   3  Sparsity: 81.0834%\n",
      "total_backward_count 744040 real_backward_count 138870  18.664%\n",
      "epoch-76  lr=['0.0039062'], tr/val_loss:  0.021966/  0.049337, val:  77.92%, val_best:  84.17%, tr:  97.24%, tr_best:  97.55%, epoch time: 55.61 seconds, 0.93 minutes\n",
      "layer   1  Sparsity: 91.1262%\n",
      "layer   2  Sparsity: 59.8232%\n",
      "layer   3  Sparsity: 81.2137%\n",
      "total_backward_count 753830 real_backward_count 140018  18.574%\n",
      "epoch-77  lr=['0.0039062'], tr/val_loss:  0.022493/  0.043890, val:  84.17%, val_best:  84.17%, tr:  97.55%, tr_best:  97.55%, epoch time: 56.05 seconds, 0.93 minutes\n",
      "layer   1  Sparsity: 91.0956%\n",
      "layer   2  Sparsity: 59.8544%\n",
      "layer   3  Sparsity: 81.2657%\n",
      "total_backward_count 763620 real_backward_count 141193  18.490%\n",
      "epoch-78  lr=['0.0039062'], tr/val_loss:  0.021781/  0.045132, val:  82.92%, val_best:  84.17%, tr:  97.14%, tr_best:  97.55%, epoch time: 55.88 seconds, 0.93 minutes\n",
      "layer   1  Sparsity: 91.0446%\n",
      "layer   2  Sparsity: 59.8745%\n",
      "layer   3  Sparsity: 81.3254%\n",
      "total_backward_count 773410 real_backward_count 142326  18.402%\n",
      "epoch-79  lr=['0.0039062'], tr/val_loss:  0.022500/  0.046213, val:  80.83%, val_best:  84.17%, tr:  96.63%, tr_best:  97.55%, epoch time: 56.41 seconds, 0.94 minutes\n",
      "layer   1  Sparsity: 91.0717%\n",
      "layer   2  Sparsity: 59.8367%\n",
      "layer   3  Sparsity: 81.3997%\n",
      "total_backward_count 783200 real_backward_count 143542  18.328%\n",
      "epoch-80  lr=['0.0039062'], tr/val_loss:  0.020779/  0.045322, val:  81.25%, val_best:  84.17%, tr:  97.96%, tr_best:  97.96%, epoch time: 56.31 seconds, 0.94 minutes\n",
      "layer   1  Sparsity: 91.0831%\n",
      "layer   2  Sparsity: 59.8204%\n",
      "layer   3  Sparsity: 81.5481%\n",
      "total_backward_count 792990 real_backward_count 144647  18.241%\n",
      "epoch-81  lr=['0.0039062'], tr/val_loss:  0.021420/  0.048048, val:  75.42%, val_best:  84.17%, tr:  97.04%, tr_best:  97.96%, epoch time: 55.70 seconds, 0.93 minutes\n",
      "layer   1  Sparsity: 91.0950%\n",
      "layer   2  Sparsity: 59.7630%\n",
      "layer   3  Sparsity: 81.7821%\n",
      "total_backward_count 802780 real_backward_count 145779  18.159%\n",
      "epoch-82  lr=['0.0039062'], tr/val_loss:  0.020706/  0.043947, val:  84.17%, val_best:  84.17%, tr:  97.24%, tr_best:  97.96%, epoch time: 55.33 seconds, 0.92 minutes\n",
      "layer   1  Sparsity: 91.0827%\n",
      "layer   2  Sparsity: 59.7300%\n",
      "layer   3  Sparsity: 81.8939%\n",
      "total_backward_count 812570 real_backward_count 146885  18.077%\n",
      "epoch-83  lr=['0.0039062'], tr/val_loss:  0.020722/  0.043627, val:  85.83%, val_best:  85.83%, tr:  98.37%, tr_best:  98.37%, epoch time: 55.81 seconds, 0.93 minutes\n",
      "layer   1  Sparsity: 91.0830%\n",
      "layer   2  Sparsity: 59.7639%\n",
      "layer   3  Sparsity: 81.8914%\n",
      "total_backward_count 822360 real_backward_count 147992  17.996%\n",
      "epoch-84  lr=['0.0039062'], tr/val_loss:  0.020006/  0.042824, val:  82.50%, val_best:  85.83%, tr:  97.85%, tr_best:  98.37%, epoch time: 55.64 seconds, 0.93 minutes\n",
      "layer   1  Sparsity: 91.0881%\n",
      "layer   2  Sparsity: 59.7922%\n",
      "layer   3  Sparsity: 81.9273%\n",
      "total_backward_count 832150 real_backward_count 149041  17.910%\n",
      "epoch-85  lr=['0.0039062'], tr/val_loss:  0.019972/  0.047434, val:  78.33%, val_best:  85.83%, tr:  97.85%, tr_best:  98.37%, epoch time: 55.90 seconds, 0.93 minutes\n",
      "layer   1  Sparsity: 91.0798%\n",
      "layer   2  Sparsity: 59.8880%\n",
      "layer   3  Sparsity: 81.9655%\n",
      "total_backward_count 841940 real_backward_count 150077  17.825%\n",
      "epoch-86  lr=['0.0039062'], tr/val_loss:  0.020773/  0.043046, val:  85.00%, val_best:  85.83%, tr:  97.34%, tr_best:  98.37%, epoch time: 56.18 seconds, 0.94 minutes\n",
      "layer   1  Sparsity: 91.0684%\n",
      "layer   2  Sparsity: 59.9053%\n",
      "layer   3  Sparsity: 81.9857%\n",
      "total_backward_count 851730 real_backward_count 151213  17.754%\n",
      "epoch-87  lr=['0.0039062'], tr/val_loss:  0.019805/  0.045611, val:  77.92%, val_best:  85.83%, tr:  97.24%, tr_best:  98.37%, epoch time: 55.44 seconds, 0.92 minutes\n",
      "layer   1  Sparsity: 91.1041%\n",
      "layer   2  Sparsity: 59.8707%\n",
      "layer   3  Sparsity: 82.0301%\n",
      "total_backward_count 861520 real_backward_count 152277  17.675%\n",
      "epoch-88  lr=['0.0039062'], tr/val_loss:  0.020132/  0.042474, val:  83.75%, val_best:  85.83%, tr:  97.65%, tr_best:  98.37%, epoch time: 56.06 seconds, 0.93 minutes\n",
      "layer   1  Sparsity: 91.0726%\n",
      "layer   2  Sparsity: 59.8760%\n",
      "layer   3  Sparsity: 82.1236%\n",
      "total_backward_count 871310 real_backward_count 153348  17.600%\n",
      "epoch-89  lr=['0.0039062'], tr/val_loss:  0.019558/  0.044485, val:  82.08%, val_best:  85.83%, tr:  98.57%, tr_best:  98.57%, epoch time: 55.60 seconds, 0.93 minutes\n",
      "layer   1  Sparsity: 91.1051%\n",
      "layer   2  Sparsity: 59.8532%\n",
      "layer   3  Sparsity: 82.1609%\n",
      "total_backward_count 881100 real_backward_count 154391  17.523%\n",
      "epoch-90  lr=['0.0039062'], tr/val_loss:  0.019727/  0.042821, val:  84.17%, val_best:  85.83%, tr:  98.06%, tr_best:  98.57%, epoch time: 55.93 seconds, 0.93 minutes\n",
      "layer   1  Sparsity: 91.0562%\n",
      "layer   2  Sparsity: 59.7963%\n",
      "layer   3  Sparsity: 82.2954%\n",
      "total_backward_count 890890 real_backward_count 155446  17.448%\n",
      "epoch-91  lr=['0.0039062'], tr/val_loss:  0.018578/  0.043974, val:  82.50%, val_best:  85.83%, tr:  98.47%, tr_best:  98.57%, epoch time: 55.80 seconds, 0.93 minutes\n",
      "layer   1  Sparsity: 91.0834%\n",
      "layer   2  Sparsity: 59.8228%\n",
      "layer   3  Sparsity: 82.3164%\n",
      "total_backward_count 900680 real_backward_count 156379  17.362%\n",
      "epoch-92  lr=['0.0039062'], tr/val_loss:  0.019810/  0.042399, val:  84.17%, val_best:  85.83%, tr:  98.06%, tr_best:  98.57%, epoch time: 55.99 seconds, 0.93 minutes\n",
      "layer   1  Sparsity: 91.0715%\n",
      "layer   2  Sparsity: 59.7838%\n",
      "layer   3  Sparsity: 82.4901%\n",
      "total_backward_count 910470 real_backward_count 157448  17.293%\n",
      "epoch-93  lr=['0.0039062'], tr/val_loss:  0.018063/  0.046325, val:  80.42%, val_best:  85.83%, tr:  98.88%, tr_best:  98.88%, epoch time: 55.77 seconds, 0.93 minutes\n",
      "layer   1  Sparsity: 91.0928%\n",
      "layer   2  Sparsity: 59.7653%\n",
      "layer   3  Sparsity: 82.4839%\n",
      "total_backward_count 920260 real_backward_count 158382  17.211%\n",
      "epoch-94  lr=['0.0039062'], tr/val_loss:  0.018262/  0.042688, val:  84.58%, val_best:  85.83%, tr:  98.47%, tr_best:  98.88%, epoch time: 55.94 seconds, 0.93 minutes\n",
      "layer   1  Sparsity: 91.0513%\n",
      "layer   2  Sparsity: 59.8249%\n",
      "layer   3  Sparsity: 82.5345%\n",
      "total_backward_count 930050 real_backward_count 159332  17.132%\n",
      "epoch-95  lr=['0.0039062'], tr/val_loss:  0.018717/  0.043827, val:  82.50%, val_best:  85.83%, tr:  98.47%, tr_best:  98.88%, epoch time: 55.80 seconds, 0.93 minutes\n",
      "layer   1  Sparsity: 91.0856%\n",
      "layer   2  Sparsity: 59.8587%\n",
      "layer   3  Sparsity: 82.5667%\n",
      "total_backward_count 939840 real_backward_count 160299  17.056%\n",
      "epoch-96  lr=['0.0039062'], tr/val_loss:  0.018408/  0.042367, val:  83.75%, val_best:  85.83%, tr:  98.26%, tr_best:  98.88%, epoch time: 51.71 seconds, 0.86 minutes\n",
      "layer   1  Sparsity: 91.1124%\n",
      "layer   2  Sparsity: 59.7388%\n",
      "layer   3  Sparsity: 82.6800%\n",
      "total_backward_count 949630 real_backward_count 161277  16.983%\n",
      "epoch-97  lr=['0.0039062'], tr/val_loss:  0.018430/  0.041128, val:  84.17%, val_best:  85.83%, tr:  97.96%, tr_best:  98.88%, epoch time: 56.25 seconds, 0.94 minutes\n",
      "layer   1  Sparsity: 91.1224%\n",
      "layer   2  Sparsity: 59.7938%\n",
      "layer   3  Sparsity: 82.6803%\n",
      "total_backward_count 959420 real_backward_count 162256  16.912%\n",
      "epoch-98  lr=['0.0039062'], tr/val_loss:  0.018126/  0.042214, val:  85.00%, val_best:  85.83%, tr:  98.06%, tr_best:  98.88%, epoch time: 55.37 seconds, 0.92 minutes\n",
      "layer   1  Sparsity: 91.0543%\n",
      "layer   2  Sparsity: 59.8100%\n",
      "layer   3  Sparsity: 82.8050%\n",
      "total_backward_count 969210 real_backward_count 163227  16.841%\n",
      "epoch-99  lr=['0.0039062'], tr/val_loss:  0.018462/  0.040869, val:  85.83%, val_best:  85.83%, tr:  98.98%, tr_best:  98.98%, epoch time: 55.95 seconds, 0.93 minutes\n",
      "layer   1  Sparsity: 91.0788%\n",
      "layer   2  Sparsity: 59.7302%\n",
      "layer   3  Sparsity: 82.9080%\n",
      "total_backward_count 979000 real_backward_count 164223  16.775%\n",
      "epoch-100 lr=['0.0039062'], tr/val_loss:  0.017781/  0.040821, val:  83.75%, val_best:  85.83%, tr:  98.57%, tr_best:  98.98%, epoch time: 56.02 seconds, 0.93 minutes\n",
      "layer   1  Sparsity: 91.0719%\n",
      "layer   2  Sparsity: 59.7282%\n",
      "layer   3  Sparsity: 82.9710%\n",
      "total_backward_count 988790 real_backward_count 165131  16.700%\n",
      "epoch-101 lr=['0.0039062'], tr/val_loss:  0.017945/  0.040739, val:  83.75%, val_best:  85.83%, tr:  98.88%, tr_best:  98.98%, epoch time: 56.00 seconds, 0.93 minutes\n",
      "layer   1  Sparsity: 91.0954%\n",
      "layer   2  Sparsity: 59.7075%\n",
      "layer   3  Sparsity: 83.0579%\n",
      "total_backward_count 998580 real_backward_count 166069  16.631%\n",
      "epoch-102 lr=['0.0039062'], tr/val_loss:  0.017891/  0.040821, val:  85.42%, val_best:  85.83%, tr:  98.47%, tr_best:  98.98%, epoch time: 56.37 seconds, 0.94 minutes\n",
      "layer   1  Sparsity: 91.0900%\n",
      "layer   2  Sparsity: 59.8023%\n",
      "layer   3  Sparsity: 83.1066%\n",
      "total_backward_count 1008370 real_backward_count 166972  16.559%\n",
      "epoch-103 lr=['0.0039062'], tr/val_loss:  0.017655/  0.041534, val:  84.17%, val_best:  85.83%, tr:  98.57%, tr_best:  98.98%, epoch time: 56.38 seconds, 0.94 minutes\n",
      "layer   1  Sparsity: 91.1035%\n",
      "layer   2  Sparsity: 59.7607%\n",
      "layer   3  Sparsity: 83.2000%\n",
      "total_backward_count 1018160 real_backward_count 167911  16.492%\n",
      "epoch-104 lr=['0.0039062'], tr/val_loss:  0.017936/  0.041270, val:  85.00%, val_best:  85.83%, tr:  97.85%, tr_best:  98.98%, epoch time: 56.04 seconds, 0.93 minutes\n",
      "layer   1  Sparsity: 91.1061%\n",
      "layer   2  Sparsity: 59.8221%\n",
      "layer   3  Sparsity: 83.2107%\n",
      "total_backward_count 1027950 real_backward_count 168869  16.428%\n",
      "epoch-105 lr=['0.0039062'], tr/val_loss:  0.017100/  0.041081, val:  84.58%, val_best:  85.83%, tr:  98.77%, tr_best:  98.98%, epoch time: 55.68 seconds, 0.93 minutes\n",
      "layer   1  Sparsity: 91.0732%\n",
      "layer   2  Sparsity: 59.7823%\n",
      "layer   3  Sparsity: 83.3393%\n",
      "total_backward_count 1037740 real_backward_count 169742  16.357%\n",
      "epoch-106 lr=['0.0039062'], tr/val_loss:  0.017308/  0.045193, val:  81.67%, val_best:  85.83%, tr:  98.88%, tr_best:  98.98%, epoch time: 55.69 seconds, 0.93 minutes\n",
      "layer   1  Sparsity: 91.0391%\n",
      "layer   2  Sparsity: 59.8042%\n",
      "layer   3  Sparsity: 83.3769%\n",
      "total_backward_count 1047530 real_backward_count 170647  16.290%\n",
      "epoch-107 lr=['0.0039062'], tr/val_loss:  0.016800/  0.042633, val:  85.00%, val_best:  85.83%, tr:  98.67%, tr_best:  98.98%, epoch time: 56.09 seconds, 0.93 minutes\n",
      "layer   1  Sparsity: 91.0986%\n",
      "layer   2  Sparsity: 59.8066%\n",
      "layer   3  Sparsity: 83.3683%\n",
      "total_backward_count 1057320 real_backward_count 171526  16.223%\n",
      "epoch-108 lr=['0.0039062'], tr/val_loss:  0.017251/  0.039284, val:  85.83%, val_best:  85.83%, tr:  98.47%, tr_best:  98.98%, epoch time: 55.26 seconds, 0.92 minutes\n",
      "layer   1  Sparsity: 91.0888%\n",
      "layer   2  Sparsity: 59.7557%\n",
      "layer   3  Sparsity: 83.4194%\n",
      "total_backward_count 1067110 real_backward_count 172472  16.163%\n",
      "epoch-109 lr=['0.0039062'], tr/val_loss:  0.016590/  0.041866, val:  84.17%, val_best:  85.83%, tr:  98.26%, tr_best:  98.98%, epoch time: 56.35 seconds, 0.94 minutes\n",
      "layer   1  Sparsity: 91.1022%\n",
      "layer   2  Sparsity: 59.6703%\n",
      "layer   3  Sparsity: 83.4921%\n",
      "total_backward_count 1076900 real_backward_count 173337  16.096%\n",
      "epoch-110 lr=['0.0039062'], tr/val_loss:  0.016698/  0.039850, val:  87.92%, val_best:  87.92%, tr:  98.88%, tr_best:  98.98%, epoch time: 55.51 seconds, 0.93 minutes\n",
      "layer   1  Sparsity: 91.1136%\n",
      "layer   2  Sparsity: 59.7444%\n",
      "layer   3  Sparsity: 83.5403%\n",
      "total_backward_count 1086690 real_backward_count 174205  16.031%\n",
      "epoch-111 lr=['0.0039062'], tr/val_loss:  0.016353/  0.042433, val:  82.08%, val_best:  87.92%, tr:  98.57%, tr_best:  98.98%, epoch time: 55.19 seconds, 0.92 minutes\n",
      "layer   1  Sparsity: 91.0983%\n",
      "layer   2  Sparsity: 59.7295%\n",
      "layer   3  Sparsity: 83.6307%\n",
      "total_backward_count 1096480 real_backward_count 175041  15.964%\n",
      "epoch-112 lr=['0.0039062'], tr/val_loss:  0.016075/  0.039402, val:  86.67%, val_best:  87.92%, tr:  99.18%, tr_best:  99.18%, epoch time: 55.20 seconds, 0.92 minutes\n",
      "layer   1  Sparsity: 91.0635%\n",
      "layer   2  Sparsity: 59.6868%\n",
      "layer   3  Sparsity: 83.7204%\n",
      "total_backward_count 1106270 real_backward_count 175858  15.896%\n",
      "epoch-113 lr=['0.0039062'], tr/val_loss:  0.016647/  0.041282, val:  82.92%, val_best:  87.92%, tr:  98.47%, tr_best:  99.18%, epoch time: 55.48 seconds, 0.92 minutes\n",
      "layer   1  Sparsity: 91.1097%\n",
      "layer   2  Sparsity: 59.7187%\n",
      "layer   3  Sparsity: 83.7416%\n",
      "total_backward_count 1116060 real_backward_count 176703  15.833%\n",
      "epoch-114 lr=['0.0039062'], tr/val_loss:  0.016185/  0.039886, val:  85.00%, val_best:  87.92%, tr:  98.67%, tr_best:  99.18%, epoch time: 55.11 seconds, 0.92 minutes\n",
      "layer   1  Sparsity: 91.0931%\n",
      "layer   2  Sparsity: 59.6126%\n",
      "layer   3  Sparsity: 83.8200%\n",
      "total_backward_count 1125850 real_backward_count 177552  15.770%\n",
      "epoch-115 lr=['0.0039062'], tr/val_loss:  0.015766/  0.038309, val:  86.67%, val_best:  87.92%, tr:  98.26%, tr_best:  99.18%, epoch time: 55.43 seconds, 0.92 minutes\n",
      "layer   1  Sparsity: 91.0615%\n",
      "layer   2  Sparsity: 59.6993%\n",
      "layer   3  Sparsity: 83.7384%\n",
      "total_backward_count 1135640 real_backward_count 178351  15.705%\n",
      "epoch-116 lr=['0.0039062'], tr/val_loss:  0.016737/  0.039615, val:  86.25%, val_best:  87.92%, tr:  98.57%, tr_best:  99.18%, epoch time: 55.78 seconds, 0.93 minutes\n",
      "layer   1  Sparsity: 91.0518%\n",
      "layer   2  Sparsity: 59.6453%\n",
      "layer   3  Sparsity: 83.8861%\n",
      "total_backward_count 1145430 real_backward_count 179239  15.648%\n",
      "epoch-117 lr=['0.0039062'], tr/val_loss:  0.016400/  0.038436, val:  86.67%, val_best:  87.92%, tr:  98.88%, tr_best:  99.18%, epoch time: 55.90 seconds, 0.93 minutes\n",
      "layer   1  Sparsity: 91.0961%\n",
      "layer   2  Sparsity: 59.6874%\n",
      "layer   3  Sparsity: 83.9237%\n",
      "total_backward_count 1155220 real_backward_count 180087  15.589%\n",
      "epoch-118 lr=['0.0039062'], tr/val_loss:  0.015358/  0.039170, val:  85.42%, val_best:  87.92%, tr:  99.08%, tr_best:  99.18%, epoch time: 55.67 seconds, 0.93 minutes\n",
      "layer   1  Sparsity: 91.0718%\n",
      "layer   2  Sparsity: 59.6458%\n",
      "layer   3  Sparsity: 84.0383%\n",
      "total_backward_count 1165010 real_backward_count 180884  15.526%\n",
      "epoch-119 lr=['0.0039062'], tr/val_loss:  0.015278/  0.042389, val:  83.33%, val_best:  87.92%, tr:  98.57%, tr_best:  99.18%, epoch time: 55.53 seconds, 0.93 minutes\n",
      "layer   1  Sparsity: 91.0794%\n",
      "layer   2  Sparsity: 59.5415%\n",
      "layer   3  Sparsity: 84.1175%\n",
      "total_backward_count 1174800 real_backward_count 181666  15.464%\n",
      "epoch-120 lr=['0.0039062'], tr/val_loss:  0.015266/  0.040851, val:  85.00%, val_best:  87.92%, tr:  98.67%, tr_best:  99.18%, epoch time: 55.63 seconds, 0.93 minutes\n",
      "layer   1  Sparsity: 91.0934%\n",
      "layer   2  Sparsity: 59.5655%\n",
      "layer   3  Sparsity: 84.1693%\n",
      "total_backward_count 1184590 real_backward_count 182445  15.402%\n",
      "epoch-121 lr=['0.0039062'], tr/val_loss:  0.015095/  0.040852, val:  85.42%, val_best:  87.92%, tr:  99.08%, tr_best:  99.18%, epoch time: 56.29 seconds, 0.94 minutes\n",
      "layer   1  Sparsity: 91.0519%\n",
      "layer   2  Sparsity: 59.6034%\n",
      "layer   3  Sparsity: 84.1909%\n",
      "total_backward_count 1194380 real_backward_count 183209  15.339%\n",
      "epoch-122 lr=['0.0039062'], tr/val_loss:  0.015644/  0.038392, val:  86.67%, val_best:  87.92%, tr:  98.67%, tr_best:  99.18%, epoch time: 55.68 seconds, 0.93 minutes\n",
      "layer   1  Sparsity: 91.0761%\n",
      "layer   2  Sparsity: 59.6664%\n",
      "layer   3  Sparsity: 84.2428%\n",
      "total_backward_count 1204170 real_backward_count 184025  15.282%\n",
      "epoch-123 lr=['0.0039062'], tr/val_loss:  0.015115/  0.040063, val:  84.17%, val_best:  87.92%, tr:  98.77%, tr_best:  99.18%, epoch time: 56.01 seconds, 0.93 minutes\n",
      "layer   1  Sparsity: 91.0715%\n",
      "layer   2  Sparsity: 59.6986%\n",
      "layer   3  Sparsity: 84.2652%\n",
      "total_backward_count 1213960 real_backward_count 184798  15.223%\n",
      "epoch-124 lr=['0.0039062'], tr/val_loss:  0.014810/  0.037628, val:  89.17%, val_best:  89.17%, tr:  99.08%, tr_best:  99.18%, epoch time: 55.90 seconds, 0.93 minutes\n",
      "layer   1  Sparsity: 91.0655%\n",
      "layer   2  Sparsity: 59.6011%\n",
      "layer   3  Sparsity: 84.3909%\n",
      "total_backward_count 1223750 real_backward_count 185519  15.160%\n",
      "epoch-125 lr=['0.0039062'], tr/val_loss:  0.015012/  0.037386, val:  88.33%, val_best:  89.17%, tr:  98.57%, tr_best:  99.18%, epoch time: 55.57 seconds, 0.93 minutes\n",
      "layer   1  Sparsity: 91.0821%\n",
      "layer   2  Sparsity: 59.5818%\n",
      "layer   3  Sparsity: 84.4326%\n",
      "total_backward_count 1233540 real_backward_count 186300  15.103%\n",
      "epoch-126 lr=['0.0039062'], tr/val_loss:  0.014303/  0.038078, val:  85.42%, val_best:  89.17%, tr:  99.18%, tr_best:  99.18%, epoch time: 55.74 seconds, 0.93 minutes\n",
      "layer   1  Sparsity: 91.0922%\n",
      "layer   2  Sparsity: 59.4607%\n",
      "layer   3  Sparsity: 84.5057%\n",
      "total_backward_count 1243330 real_backward_count 187045  15.044%\n",
      "epoch-127 lr=['0.0039062'], tr/val_loss:  0.014058/  0.037402, val:  87.92%, val_best:  89.17%, tr:  99.39%, tr_best:  99.39%, epoch time: 55.93 seconds, 0.93 minutes\n",
      "layer   1  Sparsity: 91.0613%\n",
      "layer   2  Sparsity: 59.4625%\n",
      "layer   3  Sparsity: 84.5568%\n",
      "total_backward_count 1253120 real_backward_count 187769  14.984%\n",
      "epoch-128 lr=['0.0039062'], tr/val_loss:  0.014626/  0.044608, val:  80.42%, val_best:  89.17%, tr:  98.47%, tr_best:  99.39%, epoch time: 56.22 seconds, 0.94 minutes\n",
      "layer   1  Sparsity: 91.1312%\n",
      "layer   2  Sparsity: 59.5044%\n",
      "layer   3  Sparsity: 84.5929%\n",
      "total_backward_count 1262910 real_backward_count 188529  14.928%\n",
      "epoch-129 lr=['0.0039062'], tr/val_loss:  0.014421/  0.038782, val:  85.83%, val_best:  89.17%, tr:  98.88%, tr_best:  99.39%, epoch time: 56.10 seconds, 0.93 minutes\n",
      "layer   1  Sparsity: 91.0693%\n",
      "layer   2  Sparsity: 59.4340%\n",
      "layer   3  Sparsity: 84.6731%\n",
      "total_backward_count 1272700 real_backward_count 189248  14.870%\n",
      "epoch-130 lr=['0.0039062'], tr/val_loss:  0.014079/  0.039410, val:  87.08%, val_best:  89.17%, tr:  99.28%, tr_best:  99.39%, epoch time: 55.45 seconds, 0.92 minutes\n",
      "layer   1  Sparsity: 91.0470%\n",
      "layer   2  Sparsity: 59.4684%\n",
      "layer   3  Sparsity: 84.6956%\n",
      "total_backward_count 1282490 real_backward_count 189947  14.811%\n",
      "epoch-131 lr=['0.0039062'], tr/val_loss:  0.014989/  0.040853, val:  84.17%, val_best:  89.17%, tr:  98.57%, tr_best:  99.39%, epoch time: 55.99 seconds, 0.93 minutes\n",
      "layer   1  Sparsity: 91.0922%\n",
      "layer   2  Sparsity: 59.4079%\n",
      "layer   3  Sparsity: 84.8059%\n",
      "total_backward_count 1292280 real_backward_count 190728  14.759%\n",
      "epoch-132 lr=['0.0039062'], tr/val_loss:  0.014580/  0.039948, val:  82.50%, val_best:  89.17%, tr:  99.18%, tr_best:  99.39%, epoch time: 55.42 seconds, 0.92 minutes\n",
      "layer   1  Sparsity: 91.0930%\n",
      "layer   2  Sparsity: 59.4868%\n",
      "layer   3  Sparsity: 84.8017%\n",
      "total_backward_count 1302070 real_backward_count 191471  14.705%\n",
      "epoch-133 lr=['0.0039062'], tr/val_loss:  0.014152/  0.038174, val:  86.25%, val_best:  89.17%, tr:  99.69%, tr_best:  99.69%, epoch time: 55.58 seconds, 0.93 minutes\n",
      "layer   1  Sparsity: 91.0870%\n",
      "layer   2  Sparsity: 59.4955%\n",
      "layer   3  Sparsity: 84.8365%\n",
      "total_backward_count 1311860 real_backward_count 192183  14.650%\n",
      "epoch-134 lr=['0.0039062'], tr/val_loss:  0.013920/  0.040193, val:  83.75%, val_best:  89.17%, tr:  99.28%, tr_best:  99.69%, epoch time: 56.13 seconds, 0.94 minutes\n",
      "layer   1  Sparsity: 91.0678%\n",
      "layer   2  Sparsity: 59.4853%\n",
      "layer   3  Sparsity: 84.8896%\n",
      "total_backward_count 1321650 real_backward_count 192904  14.596%\n",
      "epoch-135 lr=['0.0039062'], tr/val_loss:  0.013928/  0.036987, val:  88.33%, val_best:  89.17%, tr:  98.77%, tr_best:  99.69%, epoch time: 56.33 seconds, 0.94 minutes\n",
      "layer   1  Sparsity: 91.0492%\n",
      "layer   2  Sparsity: 59.3818%\n",
      "layer   3  Sparsity: 84.9432%\n",
      "total_backward_count 1331440 real_backward_count 193619  14.542%\n",
      "epoch-136 lr=['0.0039062'], tr/val_loss:  0.014518/  0.037945, val:  87.50%, val_best:  89.17%, tr:  98.98%, tr_best:  99.69%, epoch time: 55.98 seconds, 0.93 minutes\n",
      "layer   1  Sparsity: 91.0401%\n",
      "layer   2  Sparsity: 59.4173%\n",
      "layer   3  Sparsity: 84.9614%\n",
      "total_backward_count 1341230 real_backward_count 194365  14.492%\n",
      "epoch-137 lr=['0.0039062'], tr/val_loss:  0.013999/  0.038707, val:  86.67%, val_best:  89.17%, tr:  99.39%, tr_best:  99.69%, epoch time: 55.71 seconds, 0.93 minutes\n",
      "layer   1  Sparsity: 91.0749%\n",
      "layer   2  Sparsity: 59.3799%\n",
      "layer   3  Sparsity: 85.0252%\n",
      "total_backward_count 1351020 real_backward_count 195082  14.440%\n",
      "epoch-138 lr=['0.0039062'], tr/val_loss:  0.014248/  0.038837, val:  85.00%, val_best:  89.17%, tr:  99.18%, tr_best:  99.69%, epoch time: 55.10 seconds, 0.92 minutes\n",
      "layer   1  Sparsity: 91.0647%\n",
      "layer   2  Sparsity: 59.3091%\n",
      "layer   3  Sparsity: 85.1117%\n",
      "total_backward_count 1360810 real_backward_count 195811  14.389%\n",
      "epoch-139 lr=['0.0039062'], tr/val_loss:  0.013456/  0.038498, val:  87.92%, val_best:  89.17%, tr:  99.18%, tr_best:  99.69%, epoch time: 55.26 seconds, 0.92 minutes\n",
      "layer   1  Sparsity: 91.0739%\n",
      "layer   2  Sparsity: 59.3502%\n",
      "layer   3  Sparsity: 85.1546%\n",
      "total_backward_count 1370600 real_backward_count 196503  14.337%\n",
      "epoch-140 lr=['0.0039062'], tr/val_loss:  0.013551/  0.039963, val:  83.33%, val_best:  89.17%, tr:  98.88%, tr_best:  99.69%, epoch time: 55.49 seconds, 0.92 minutes\n",
      "layer   1  Sparsity: 91.0412%\n",
      "layer   2  Sparsity: 59.3685%\n",
      "layer   3  Sparsity: 85.1590%\n",
      "total_backward_count 1380390 real_backward_count 197192  14.285%\n",
      "epoch-141 lr=['0.0039062'], tr/val_loss:  0.013971/  0.039704, val:  85.00%, val_best:  89.17%, tr:  99.08%, tr_best:  99.69%, epoch time: 55.89 seconds, 0.93 minutes\n",
      "layer   1  Sparsity: 91.0867%\n",
      "layer   2  Sparsity: 59.3037%\n",
      "layer   3  Sparsity: 85.2594%\n",
      "total_backward_count 1390180 real_backward_count 197921  14.237%\n",
      "epoch-142 lr=['0.0039062'], tr/val_loss:  0.013460/  0.038660, val:  85.83%, val_best:  89.17%, tr:  98.57%, tr_best:  99.69%, epoch time: 55.68 seconds, 0.93 minutes\n",
      "layer   1  Sparsity: 91.0994%\n",
      "layer   2  Sparsity: 59.3330%\n",
      "layer   3  Sparsity: 85.3216%\n",
      "total_backward_count 1399970 real_backward_count 198626  14.188%\n",
      "epoch-143 lr=['0.0039062'], tr/val_loss:  0.013328/  0.041079, val:  84.17%, val_best:  89.17%, tr:  99.28%, tr_best:  99.69%, epoch time: 56.17 seconds, 0.94 minutes\n",
      "layer   1  Sparsity: 91.0377%\n",
      "layer   2  Sparsity: 59.2936%\n",
      "layer   3  Sparsity: 85.3976%\n",
      "total_backward_count 1409760 real_backward_count 199305  14.138%\n",
      "epoch-144 lr=['0.0039062'], tr/val_loss:  0.013610/  0.038526, val:  86.25%, val_best:  89.17%, tr:  99.49%, tr_best:  99.69%, epoch time: 56.28 seconds, 0.94 minutes\n",
      "layer   1  Sparsity: 91.0668%\n",
      "layer   2  Sparsity: 59.2990%\n",
      "layer   3  Sparsity: 85.4662%\n",
      "total_backward_count 1419550 real_backward_count 200008  14.090%\n",
      "epoch-145 lr=['0.0039062'], tr/val_loss:  0.013152/  0.038614, val:  87.08%, val_best:  89.17%, tr:  98.98%, tr_best:  99.69%, epoch time: 55.41 seconds, 0.92 minutes\n",
      "layer   1  Sparsity: 91.0134%\n",
      "layer   2  Sparsity: 59.3118%\n",
      "layer   3  Sparsity: 85.5092%\n",
      "total_backward_count 1429340 real_backward_count 200667  14.039%\n",
      "epoch-146 lr=['0.0039062'], tr/val_loss:  0.012933/  0.038623, val:  86.25%, val_best:  89.17%, tr:  99.28%, tr_best:  99.69%, epoch time: 55.02 seconds, 0.92 minutes\n",
      "layer   1  Sparsity: 91.0413%\n",
      "layer   2  Sparsity: 59.2737%\n",
      "layer   3  Sparsity: 85.5201%\n",
      "total_backward_count 1439130 real_backward_count 201317  13.989%\n",
      "epoch-147 lr=['0.0039062'], tr/val_loss:  0.012496/  0.037860, val:  85.83%, val_best:  89.17%, tr:  98.67%, tr_best:  99.69%, epoch time: 55.83 seconds, 0.93 minutes\n",
      "layer   1  Sparsity: 91.0357%\n",
      "layer   2  Sparsity: 59.2198%\n",
      "layer   3  Sparsity: 85.6228%\n",
      "total_backward_count 1448920 real_backward_count 201929  13.937%\n",
      "epoch-148 lr=['0.0039062'], tr/val_loss:  0.012852/  0.041921, val:  86.67%, val_best:  89.17%, tr:  99.18%, tr_best:  99.69%, epoch time: 55.36 seconds, 0.92 minutes\n",
      "layer   1  Sparsity: 91.0998%\n",
      "layer   2  Sparsity: 59.2384%\n",
      "layer   3  Sparsity: 85.6654%\n",
      "total_backward_count 1458710 real_backward_count 202586  13.888%\n",
      "epoch-149 lr=['0.0039062'], tr/val_loss:  0.013601/  0.040800, val:  84.58%, val_best:  89.17%, tr:  99.39%, tr_best:  99.69%, epoch time: 55.94 seconds, 0.93 minutes\n",
      "layer   1  Sparsity: 91.1091%\n",
      "layer   2  Sparsity: 59.2592%\n",
      "layer   3  Sparsity: 85.6361%\n",
      "total_backward_count 1468500 real_backward_count 203304  13.844%\n",
      "epoch-150 lr=['0.0039062'], tr/val_loss:  0.012700/  0.036685, val:  88.75%, val_best:  89.17%, tr:  99.08%, tr_best:  99.69%, epoch time: 55.95 seconds, 0.93 minutes\n",
      "layer   1  Sparsity: 91.1176%\n",
      "layer   2  Sparsity: 59.2642%\n",
      "layer   3  Sparsity: 85.6820%\n",
      "total_backward_count 1478290 real_backward_count 203948  13.796%\n",
      "epoch-151 lr=['0.0039062'], tr/val_loss:  0.012543/  0.037376, val:  85.42%, val_best:  89.17%, tr:  99.28%, tr_best:  99.69%, epoch time: 55.72 seconds, 0.93 minutes\n",
      "layer   1  Sparsity: 91.0574%\n",
      "layer   2  Sparsity: 59.2489%\n",
      "layer   3  Sparsity: 85.7576%\n",
      "total_backward_count 1488080 real_backward_count 204580  13.748%\n",
      "epoch-152 lr=['0.0039062'], tr/val_loss:  0.013035/  0.038280, val:  86.25%, val_best:  89.17%, tr:  99.18%, tr_best:  99.69%, epoch time: 56.40 seconds, 0.94 minutes\n",
      "layer   1  Sparsity: 91.1318%\n",
      "layer   2  Sparsity: 59.2192%\n",
      "layer   3  Sparsity: 85.8350%\n",
      "total_backward_count 1497870 real_backward_count 205249  13.703%\n",
      "epoch-153 lr=['0.0039062'], tr/val_loss:  0.012988/  0.036579, val:  87.50%, val_best:  89.17%, tr:  99.18%, tr_best:  99.69%, epoch time: 55.59 seconds, 0.93 minutes\n",
      "layer   1  Sparsity: 91.0985%\n",
      "layer   2  Sparsity: 59.2446%\n",
      "layer   3  Sparsity: 85.9267%\n",
      "total_backward_count 1507660 real_backward_count 205932  13.659%\n",
      "epoch-154 lr=['0.0039062'], tr/val_loss:  0.012026/  0.035772, val:  87.50%, val_best:  89.17%, tr:  99.28%, tr_best:  99.69%, epoch time: 55.75 seconds, 0.93 minutes\n",
      "layer   1  Sparsity: 91.0560%\n",
      "layer   2  Sparsity: 59.2897%\n",
      "layer   3  Sparsity: 85.9205%\n",
      "total_backward_count 1517450 real_backward_count 206546  13.611%\n",
      "epoch-155 lr=['0.0039062'], tr/val_loss:  0.012500/  0.036662, val:  86.67%, val_best:  89.17%, tr:  99.39%, tr_best:  99.69%, epoch time: 55.73 seconds, 0.93 minutes\n",
      "layer   1  Sparsity: 91.0645%\n",
      "layer   2  Sparsity: 59.1988%\n",
      "layer   3  Sparsity: 86.0524%\n",
      "total_backward_count 1527240 real_backward_count 207218  13.568%\n",
      "epoch-156 lr=['0.0039062'], tr/val_loss:  0.012152/  0.037958, val:  88.75%, val_best:  89.17%, tr:  99.28%, tr_best:  99.69%, epoch time: 55.98 seconds, 0.93 minutes\n",
      "layer   1  Sparsity: 91.0305%\n",
      "layer   2  Sparsity: 59.2242%\n",
      "layer   3  Sparsity: 86.0700%\n",
      "total_backward_count 1537030 real_backward_count 207830  13.522%\n",
      "epoch-157 lr=['0.0039062'], tr/val_loss:  0.012919/  0.037353, val:  87.92%, val_best:  89.17%, tr:  99.59%, tr_best:  99.69%, epoch time: 55.45 seconds, 0.92 minutes\n",
      "layer   1  Sparsity: 91.0753%\n",
      "layer   2  Sparsity: 59.1413%\n",
      "layer   3  Sparsity: 86.1379%\n",
      "total_backward_count 1546820 real_backward_count 208497  13.479%\n",
      "epoch-158 lr=['0.0039062'], tr/val_loss:  0.012530/  0.036835, val:  88.33%, val_best:  89.17%, tr:  99.18%, tr_best:  99.69%, epoch time: 55.88 seconds, 0.93 minutes\n",
      "layer   1  Sparsity: 91.0724%\n",
      "layer   2  Sparsity: 59.1881%\n",
      "layer   3  Sparsity: 86.1888%\n",
      "total_backward_count 1556610 real_backward_count 209168  13.437%\n",
      "epoch-159 lr=['0.0039062'], tr/val_loss:  0.012502/  0.036157, val:  88.33%, val_best:  89.17%, tr:  99.39%, tr_best:  99.69%, epoch time: 55.65 seconds, 0.93 minutes\n",
      "layer   1  Sparsity: 91.1142%\n",
      "layer   2  Sparsity: 59.1005%\n",
      "layer   3  Sparsity: 86.2735%\n",
      "total_backward_count 1566400 real_backward_count 209825  13.395%\n",
      "epoch-160 lr=['0.0039062'], tr/val_loss:  0.012368/  0.037484, val:  86.25%, val_best:  89.17%, tr:  99.39%, tr_best:  99.69%, epoch time: 55.87 seconds, 0.93 minutes\n",
      "layer   1  Sparsity: 91.0778%\n",
      "layer   2  Sparsity: 59.0398%\n",
      "layer   3  Sparsity: 86.3486%\n",
      "total_backward_count 1576190 real_backward_count 210455  13.352%\n",
      "epoch-161 lr=['0.0039062'], tr/val_loss:  0.012191/  0.039773, val:  87.08%, val_best:  89.17%, tr:  99.18%, tr_best:  99.69%, epoch time: 55.65 seconds, 0.93 minutes\n",
      "layer   1  Sparsity: 91.1063%\n",
      "layer   2  Sparsity: 59.1200%\n",
      "layer   3  Sparsity: 86.3485%\n",
      "total_backward_count 1585980 real_backward_count 211091  13.310%\n",
      "epoch-162 lr=['0.0039062'], tr/val_loss:  0.011431/  0.037139, val:  87.92%, val_best:  89.17%, tr:  99.59%, tr_best:  99.69%, epoch time: 56.25 seconds, 0.94 minutes\n",
      "layer   1  Sparsity: 91.0652%\n",
      "layer   2  Sparsity: 59.0664%\n",
      "layer   3  Sparsity: 86.3560%\n",
      "total_backward_count 1595770 real_backward_count 211657  13.264%\n",
      "epoch-163 lr=['0.0039062'], tr/val_loss:  0.011685/  0.036290, val:  90.00%, val_best:  90.00%, tr:  99.69%, tr_best:  99.69%, epoch time: 55.40 seconds, 0.92 minutes\n",
      "layer   1  Sparsity: 91.0504%\n",
      "layer   2  Sparsity: 59.0450%\n",
      "layer   3  Sparsity: 86.3838%\n",
      "total_backward_count 1605560 real_backward_count 212253  13.220%\n",
      "epoch-164 lr=['0.0039062'], tr/val_loss:  0.011403/  0.038885, val:  86.25%, val_best:  90.00%, tr:  99.69%, tr_best:  99.69%, epoch time: 55.80 seconds, 0.93 minutes\n",
      "layer   1  Sparsity: 91.0192%\n",
      "layer   2  Sparsity: 59.1243%\n",
      "layer   3  Sparsity: 86.4435%\n",
      "total_backward_count 1615350 real_backward_count 212835  13.176%\n",
      "epoch-165 lr=['0.0039062'], tr/val_loss:  0.011570/  0.036175, val:  87.50%, val_best:  90.00%, tr:  99.39%, tr_best:  99.69%, epoch time: 55.50 seconds, 0.92 minutes\n",
      "layer   1  Sparsity: 91.0852%\n",
      "layer   2  Sparsity: 59.1469%\n",
      "layer   3  Sparsity: 86.4859%\n",
      "total_backward_count 1625140 real_backward_count 213416  13.132%\n",
      "epoch-166 lr=['0.0039062'], tr/val_loss:  0.011300/  0.040555, val:  85.83%, val_best:  90.00%, tr:  99.39%, tr_best:  99.69%, epoch time: 55.67 seconds, 0.93 minutes\n",
      "layer   1  Sparsity: 91.0623%\n",
      "layer   2  Sparsity: 59.1767%\n",
      "layer   3  Sparsity: 86.4817%\n",
      "total_backward_count 1634930 real_backward_count 213993  13.089%\n",
      "epoch-167 lr=['0.0039062'], tr/val_loss:  0.011673/  0.035969, val:  89.17%, val_best:  90.00%, tr:  99.18%, tr_best:  99.69%, epoch time: 56.05 seconds, 0.93 minutes\n",
      "layer   1  Sparsity: 91.0562%\n",
      "layer   2  Sparsity: 59.1030%\n",
      "layer   3  Sparsity: 86.5922%\n",
      "total_backward_count 1644720 real_backward_count 214590  13.047%\n",
      "epoch-168 lr=['0.0039062'], tr/val_loss:  0.011254/  0.037773, val:  86.67%, val_best:  90.00%, tr:  99.59%, tr_best:  99.69%, epoch time: 55.93 seconds, 0.93 minutes\n",
      "layer   1  Sparsity: 91.0968%\n",
      "layer   2  Sparsity: 59.0539%\n",
      "layer   3  Sparsity: 86.6422%\n",
      "total_backward_count 1654510 real_backward_count 215145  13.004%\n",
      "epoch-169 lr=['0.0039062'], tr/val_loss:  0.011901/  0.038057, val:  87.50%, val_best:  90.00%, tr:  99.49%, tr_best:  99.69%, epoch time: 56.13 seconds, 0.94 minutes\n",
      "layer   1  Sparsity: 91.0554%\n",
      "layer   2  Sparsity: 59.0660%\n",
      "layer   3  Sparsity: 86.6680%\n",
      "total_backward_count 1664300 real_backward_count 215772  12.965%\n",
      "epoch-170 lr=['0.0039062'], tr/val_loss:  0.011790/  0.037195, val:  86.67%, val_best:  90.00%, tr:  99.59%, tr_best:  99.69%, epoch time: 56.07 seconds, 0.93 minutes\n",
      "layer   1  Sparsity: 91.0578%\n",
      "layer   2  Sparsity: 59.1569%\n",
      "layer   3  Sparsity: 86.7157%\n",
      "total_backward_count 1674090 real_backward_count 216373  12.925%\n",
      "epoch-171 lr=['0.0039062'], tr/val_loss:  0.010780/  0.037784, val:  89.58%, val_best:  90.00%, tr:  99.59%, tr_best:  99.69%, epoch time: 55.22 seconds, 0.92 minutes\n",
      "layer   1  Sparsity: 91.0700%\n",
      "layer   2  Sparsity: 59.1107%\n",
      "layer   3  Sparsity: 86.8074%\n",
      "total_backward_count 1683880 real_backward_count 216911  12.882%\n",
      "epoch-172 lr=['0.0039062'], tr/val_loss:  0.011414/  0.036557, val:  87.08%, val_best:  90.00%, tr:  99.39%, tr_best:  99.69%, epoch time: 54.83 seconds, 0.91 minutes\n",
      "layer   1  Sparsity: 91.1146%\n",
      "layer   2  Sparsity: 59.1798%\n",
      "layer   3  Sparsity: 86.8763%\n",
      "total_backward_count 1693670 real_backward_count 217506  12.842%\n",
      "epoch-173 lr=['0.0039062'], tr/val_loss:  0.011516/  0.039459, val:  86.67%, val_best:  90.00%, tr:  99.39%, tr_best:  99.69%, epoch time: 55.48 seconds, 0.92 minutes\n",
      "layer   1  Sparsity: 91.0673%\n",
      "layer   2  Sparsity: 59.0441%\n",
      "layer   3  Sparsity: 86.9406%\n",
      "total_backward_count 1703460 real_backward_count 218098  12.803%\n",
      "epoch-174 lr=['0.0039062'], tr/val_loss:  0.011198/  0.036511, val:  88.75%, val_best:  90.00%, tr:  99.39%, tr_best:  99.69%, epoch time: 56.32 seconds, 0.94 minutes\n",
      "layer   1  Sparsity: 91.0883%\n",
      "layer   2  Sparsity: 59.0359%\n",
      "layer   3  Sparsity: 87.0038%\n",
      "total_backward_count 1713250 real_backward_count 218656  12.763%\n",
      "epoch-175 lr=['0.0039062'], tr/val_loss:  0.010966/  0.040050, val:  85.83%, val_best:  90.00%, tr:  99.59%, tr_best:  99.69%, epoch time: 56.74 seconds, 0.95 minutes\n",
      "layer   1  Sparsity: 91.1050%\n",
      "layer   2  Sparsity: 58.9547%\n",
      "layer   3  Sparsity: 87.0304%\n",
      "total_backward_count 1723040 real_backward_count 219209  12.722%\n",
      "epoch-176 lr=['0.0039062'], tr/val_loss:  0.011233/  0.038164, val:  85.00%, val_best:  90.00%, tr:  99.28%, tr_best:  99.69%, epoch time: 55.71 seconds, 0.93 minutes\n",
      "layer   1  Sparsity: 91.1036%\n",
      "layer   2  Sparsity: 59.0370%\n",
      "layer   3  Sparsity: 87.0432%\n",
      "total_backward_count 1732830 real_backward_count 219774  12.683%\n",
      "epoch-177 lr=['0.0039062'], tr/val_loss:  0.011763/  0.037561, val:  87.08%, val_best:  90.00%, tr:  99.39%, tr_best:  99.69%, epoch time: 55.61 seconds, 0.93 minutes\n",
      "layer   1  Sparsity: 91.0550%\n",
      "layer   2  Sparsity: 59.0114%\n",
      "layer   3  Sparsity: 87.1431%\n",
      "total_backward_count 1742620 real_backward_count 220394  12.647%\n",
      "epoch-178 lr=['0.0039062'], tr/val_loss:  0.010728/  0.036378, val:  87.92%, val_best:  90.00%, tr:  99.59%, tr_best:  99.69%, epoch time: 56.11 seconds, 0.94 minutes\n",
      "layer   1  Sparsity: 91.0804%\n",
      "layer   2  Sparsity: 58.9977%\n",
      "layer   3  Sparsity: 87.1803%\n",
      "total_backward_count 1752410 real_backward_count 220936  12.608%\n",
      "epoch-179 lr=['0.0039062'], tr/val_loss:  0.010580/  0.036958, val:  87.50%, val_best:  90.00%, tr:  99.69%, tr_best:  99.69%, epoch time: 55.48 seconds, 0.92 minutes\n",
      "layer   1  Sparsity: 91.0625%\n",
      "layer   2  Sparsity: 58.9992%\n",
      "layer   3  Sparsity: 87.2017%\n",
      "total_backward_count 1762200 real_backward_count 221499  12.569%\n",
      "epoch-180 lr=['0.0039062'], tr/val_loss:  0.010825/  0.037606, val:  86.67%, val_best:  90.00%, tr:  99.59%, tr_best:  99.69%, epoch time: 56.15 seconds, 0.94 minutes\n",
      "layer   1  Sparsity: 91.0671%\n",
      "layer   2  Sparsity: 59.0727%\n",
      "layer   3  Sparsity: 87.1775%\n",
      "total_backward_count 1771990 real_backward_count 222061  12.532%\n",
      "epoch-181 lr=['0.0039062'], tr/val_loss:  0.011222/  0.037778, val:  87.50%, val_best:  90.00%, tr:  98.98%, tr_best:  99.69%, epoch time: 56.52 seconds, 0.94 minutes\n",
      "layer   1  Sparsity: 91.0840%\n",
      "layer   2  Sparsity: 59.1485%\n",
      "layer   3  Sparsity: 87.2419%\n",
      "total_backward_count 1781780 real_backward_count 222647  12.496%\n",
      "epoch-182 lr=['0.0039062'], tr/val_loss:  0.010476/  0.038098, val:  86.67%, val_best:  90.00%, tr:  99.28%, tr_best:  99.69%, epoch time: 56.04 seconds, 0.93 minutes\n",
      "layer   1  Sparsity: 91.1133%\n",
      "layer   2  Sparsity: 59.1605%\n",
      "layer   3  Sparsity: 87.3116%\n",
      "total_backward_count 1791570 real_backward_count 223160  12.456%\n",
      "epoch-183 lr=['0.0039062'], tr/val_loss:  0.011049/  0.037629, val:  87.08%, val_best:  90.00%, tr:  99.49%, tr_best:  99.69%, epoch time: 56.34 seconds, 0.94 minutes\n",
      "layer   1  Sparsity: 91.1072%\n",
      "layer   2  Sparsity: 59.1157%\n",
      "layer   3  Sparsity: 87.4055%\n",
      "total_backward_count 1801360 real_backward_count 223710  12.419%\n",
      "epoch-184 lr=['0.0039062'], tr/val_loss:  0.010291/  0.037073, val:  86.25%, val_best:  90.00%, tr:  99.59%, tr_best:  99.69%, epoch time: 56.45 seconds, 0.94 minutes\n",
      "layer   1  Sparsity: 91.0728%\n",
      "layer   2  Sparsity: 58.9520%\n",
      "layer   3  Sparsity: 87.4888%\n",
      "total_backward_count 1811150 real_backward_count 224209  12.379%\n",
      "epoch-185 lr=['0.0039062'], tr/val_loss:  0.010749/  0.038231, val:  87.08%, val_best:  90.00%, tr:  99.49%, tr_best:  99.69%, epoch time: 55.59 seconds, 0.93 minutes\n",
      "layer   1  Sparsity: 91.0715%\n",
      "layer   2  Sparsity: 58.9374%\n",
      "layer   3  Sparsity: 87.5314%\n",
      "total_backward_count 1820940 real_backward_count 224772  12.344%\n",
      "epoch-186 lr=['0.0039062'], tr/val_loss:  0.010781/  0.038059, val:  87.50%, val_best:  90.00%, tr:  99.49%, tr_best:  99.69%, epoch time: 55.90 seconds, 0.93 minutes\n",
      "layer   1  Sparsity: 91.0621%\n",
      "layer   2  Sparsity: 59.0530%\n",
      "layer   3  Sparsity: 87.5240%\n",
      "total_backward_count 1830730 real_backward_count 225337  12.309%\n",
      "epoch-187 lr=['0.0039062'], tr/val_loss:  0.010577/  0.036938, val:  86.25%, val_best:  90.00%, tr:  99.59%, tr_best:  99.69%, epoch time: 55.70 seconds, 0.93 minutes\n",
      "layer   1  Sparsity: 91.0426%\n",
      "layer   2  Sparsity: 59.0917%\n",
      "layer   3  Sparsity: 87.5746%\n",
      "total_backward_count 1840520 real_backward_count 225880  12.273%\n",
      "epoch-188 lr=['0.0039062'], tr/val_loss:  0.010610/  0.037308, val:  86.67%, val_best:  90.00%, tr:  99.59%, tr_best:  99.69%, epoch time: 55.64 seconds, 0.93 minutes\n",
      "layer   1  Sparsity: 91.0748%\n",
      "layer   2  Sparsity: 59.0148%\n",
      "layer   3  Sparsity: 87.6646%\n",
      "total_backward_count 1850310 real_backward_count 226435  12.238%\n",
      "epoch-189 lr=['0.0039062'], tr/val_loss:  0.010281/  0.036994, val:  86.67%, val_best:  90.00%, tr:  99.39%, tr_best:  99.69%, epoch time: 55.79 seconds, 0.93 minutes\n",
      "layer   1  Sparsity: 91.1071%\n",
      "layer   2  Sparsity: 59.0174%\n",
      "layer   3  Sparsity: 87.7026%\n",
      "total_backward_count 1860100 real_backward_count 226953  12.201%\n",
      "epoch-190 lr=['0.0039062'], tr/val_loss:  0.010623/  0.035551, val:  87.50%, val_best:  90.00%, tr:  99.49%, tr_best:  99.69%, epoch time: 55.52 seconds, 0.93 minutes\n",
      "layer   1  Sparsity: 91.0587%\n",
      "layer   2  Sparsity: 58.8783%\n",
      "layer   3  Sparsity: 87.7963%\n",
      "total_backward_count 1869890 real_backward_count 227501  12.167%\n",
      "epoch-191 lr=['0.0039062'], tr/val_loss:  0.009805/  0.038435, val:  84.58%, val_best:  90.00%, tr:  99.80%, tr_best:  99.80%, epoch time: 56.29 seconds, 0.94 minutes\n",
      "layer   1  Sparsity: 91.0919%\n",
      "layer   2  Sparsity: 58.8968%\n",
      "layer   3  Sparsity: 87.8149%\n",
      "total_backward_count 1879680 real_backward_count 227987  12.129%\n",
      "epoch-192 lr=['0.0039062'], tr/val_loss:  0.010044/  0.036921, val:  87.08%, val_best:  90.00%, tr:  99.49%, tr_best:  99.80%, epoch time: 56.44 seconds, 0.94 minutes\n",
      "layer   1  Sparsity: 91.1033%\n",
      "layer   2  Sparsity: 58.9266%\n",
      "layer   3  Sparsity: 87.8340%\n",
      "total_backward_count 1889470 real_backward_count 228511  12.094%\n",
      "epoch-193 lr=['0.0039062'], tr/val_loss:  0.010519/  0.037012, val:  87.50%, val_best:  90.00%, tr:  99.49%, tr_best:  99.80%, epoch time: 55.40 seconds, 0.92 minutes\n",
      "layer   1  Sparsity: 91.1215%\n",
      "layer   2  Sparsity: 58.8799%\n",
      "layer   3  Sparsity: 87.8820%\n",
      "total_backward_count 1899260 real_backward_count 229041  12.059%\n",
      "epoch-194 lr=['0.0039062'], tr/val_loss:  0.010216/  0.035006, val:  89.58%, val_best:  90.00%, tr:  99.28%, tr_best:  99.80%, epoch time: 56.20 seconds, 0.94 minutes\n",
      "layer   1  Sparsity: 91.0847%\n",
      "layer   2  Sparsity: 58.9219%\n",
      "layer   3  Sparsity: 87.8878%\n",
      "total_backward_count 1909050 real_backward_count 229580  12.026%\n",
      "epoch-195 lr=['0.0039062'], tr/val_loss:  0.010110/  0.037711, val:  87.08%, val_best:  90.00%, tr:  99.59%, tr_best:  99.80%, epoch time: 55.71 seconds, 0.93 minutes\n",
      "layer   1  Sparsity: 91.0825%\n",
      "layer   2  Sparsity: 58.8474%\n",
      "layer   3  Sparsity: 87.9623%\n",
      "total_backward_count 1918840 real_backward_count 230121  11.993%\n",
      "epoch-196 lr=['0.0039062'], tr/val_loss:  0.010164/  0.037473, val:  87.50%, val_best:  90.00%, tr:  99.28%, tr_best:  99.80%, epoch time: 55.98 seconds, 0.93 minutes\n",
      "layer   1  Sparsity: 91.0987%\n",
      "layer   2  Sparsity: 58.8775%\n",
      "layer   3  Sparsity: 87.9922%\n",
      "total_backward_count 1928630 real_backward_count 230636  11.959%\n",
      "epoch-197 lr=['0.0039062'], tr/val_loss:  0.010026/  0.036952, val:  87.08%, val_best:  90.00%, tr:  99.59%, tr_best:  99.80%, epoch time: 55.79 seconds, 0.93 minutes\n",
      "layer   1  Sparsity: 91.1320%\n",
      "layer   2  Sparsity: 58.8251%\n",
      "layer   3  Sparsity: 88.0211%\n",
      "total_backward_count 1938420 real_backward_count 231152  11.925%\n",
      "epoch-198 lr=['0.0039062'], tr/val_loss:  0.009474/  0.039042, val:  85.00%, val_best:  90.00%, tr:  99.69%, tr_best:  99.80%, epoch time: 56.10 seconds, 0.93 minutes\n",
      "layer   1  Sparsity: 91.0644%\n",
      "layer   2  Sparsity: 58.7920%\n",
      "layer   3  Sparsity: 88.0707%\n",
      "total_backward_count 1948210 real_backward_count 231627  11.889%\n",
      "epoch-199 lr=['0.0039062'], tr/val_loss:  0.010072/  0.036970, val:  86.25%, val_best:  90.00%, tr:  99.39%, tr_best:  99.80%, epoch time: 55.82 seconds, 0.93 minutes\n",
      "layer   1  Sparsity: 91.0852%\n",
      "layer   2  Sparsity: 58.7047%\n",
      "layer   3  Sparsity: 88.1429%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c8fe54557974463cbf6159a749783e87",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.006 MB of 0.006 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà</td></tr><tr><td>iter_acc</td><td>‚ñà‚ñÅ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà</td></tr><tr><td>summary_val_acc</td><td>‚ñÅ‚ñÉ‚ñÑ‚ñÑ‚ñÇ‚ñÇ‚ñÖ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñÜ‚ñá‚ñá‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñá‚ñà‚ñà‚ñá‚ñà‚ñá</td></tr><tr><td>tr_acc</td><td>‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà</td></tr><tr><td>tr_epoch_loss</td><td>‚ñà‚ñá‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ</td></tr><tr><td>val_acc_best</td><td>‚ñÅ‚ñÉ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà</td></tr><tr><td>val_acc_now</td><td>‚ñÅ‚ñÉ‚ñÑ‚ñÑ‚ñÇ‚ñÇ‚ñÖ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñÜ‚ñá‚ñá‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñá‚ñà‚ñà‚ñá‚ñà‚ñá</td></tr><tr><td>val_loss</td><td>‚ñà‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñÑ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>199</td></tr><tr><td>iter_acc</td><td>1.0</td></tr><tr><td>tr_acc</td><td>0.99387</td></tr><tr><td>tr_epoch_loss</td><td>0.01007</td></tr><tr><td>val_acc_best</td><td>0.9</td></tr><tr><td>val_acc_now</td><td>0.8625</td></tr><tr><td>val_loss</td><td>0.03697</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">sparkling-sweep-5</strong> at: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/0uwqlisi' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/0uwqlisi</a><br/> View project at: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>/data2/bh_wandb/wandb/run-20251120_071901-0uwqlisi/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require(\"core\")`! See https://wandb.me/wandb-core for more information."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: tvi9cmnu with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBATCH: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBN_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBPTT_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tDFA_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tIMAGE_SIZE: 14\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tOTTT_input_trace_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tTIME: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tUDA_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \talpha_uda: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbias: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcfg: [200, 200]\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tchaching_on: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tconvTrue_fcFalse: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdata_path: /data2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tddp_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdenoise_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdvs_clipping: 14\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdvs_duration: 25000\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepoch_num: 200\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \texclude_class: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \textra_train_dataset: -1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tinitial_pooling: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlast_lif: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.00390625\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_sg_width: 4\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_decay: 0.5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_init: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_reset: 10000\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_threshold: 0.015625\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmerge_polarities: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmy_seed: 38265\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnet_print: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_workers: 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer_what: SGD\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tpin_memory: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tpre_trained: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tpre_trained_path: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \trate_coding: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tscheduler_name: no\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsingle_step: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsurrogate: hard_sigmoid\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_conv_kernel_size: 3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_conv_padding: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_conv_stride: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_trace_const1: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_trace_const2: 0.5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \ttdBN_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \ttemporal_filter: 5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \ttemporal_filter_accumulation: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \ttrace_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \twhich_data: DVS_GESTURE_TONIC\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.23.0 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.17.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/data2/bh_wandb/wandb/run-20251120_102549-tvi9cmnu</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/tvi9cmnu' target=\"_blank\">effortless-sweep-6</a></strong> to <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/m41wfhay' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/m41wfhay</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/m41wfhay' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/m41wfhay</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/tvi9cmnu' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/tvi9cmnu</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'single_step' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'my_seed' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'TIME' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BATCH' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'IMAGE_SIZE' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'which_data' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'data_path' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'rate_coding' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_init' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_decay' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_threshold' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_reset' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_sg_width' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_conv_kernel_size' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_conv_stride' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_conv_padding' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_trace_const1' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_trace_const2' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'pre_trained' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'convTrue_fcFalse' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'cfg' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'net_print' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'pre_trained_path' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'learning_rate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'epoch_num' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'tdBN_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BN_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'surrogate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BPTT_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'optimizer_what' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'scheduler_name' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'ddp_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'dvs_clipping' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'dvs_duration' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'DFA_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'trace_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'OTTT_input_trace_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'exclude_class' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'merge_polarities' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'denoise_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'extra_train_dataset' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'num_workers' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'chaching_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'pin_memory' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'UDA_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'alpha_uda' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'bias' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'last_lif' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'temporal_filter' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'initial_pooling' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'temporal_filter_accumulation' was locked by 'sweep' (ignored update).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "param {'devices': '3', 'single_step': True, 'unique_name': '20251120_102558_997', 'my_seed': 38265, 'TIME': 10, 'BATCH': 1, 'IMAGE_SIZE': 14, 'which_data': 'DVS_GESTURE_TONIC', 'data_path': '/data2', 'rate_coding': False, 'lif_layer_v_init': 0, 'lif_layer_v_decay': 0.5, 'lif_layer_v_threshold': 0.015625, 'lif_layer_v_reset': 10000, 'lif_layer_sg_width': 4, 'synapse_conv_kernel_size': 3, 'synapse_conv_stride': 1, 'synapse_conv_padding': 1, 'synapse_trace_const1': 1, 'synapse_trace_const2': 0.5, 'pre_trained': False, 'convTrue_fcFalse': False, 'cfg': [200, 200], 'net_print': True, 'pre_trained_path': '', 'learning_rate': 0.00390625, 'epoch_num': 200, 'tdBN_on': False, 'BN_on': False, 'surrogate': 'hard_sigmoid', 'BPTT_on': False, 'optimizer_what': 'SGD', 'scheduler_name': 'no', 'ddp_on': False, 'dvs_clipping': 14, 'dvs_duration': 25000, 'DFA_on': False, 'trace_on': False, 'OTTT_input_trace_on': False, 'exclude_class': True, 'merge_polarities': True, 'denoise_on': False, 'extra_train_dataset': -1, 'num_workers': 2, 'chaching_on': True, 'pin_memory': True, 'UDA_on': False, 'alpha_uda': 1, 'bias': False, 'last_lif': False, 'temporal_filter': 5, 'initial_pooling': 1, 'temporal_filter_accumulation': False, 'quantize_bit_list': [], 'scale_exp': [[999, 998], [999, 999], [999, 999]]} \n",
      "\n",
      "Ïù¥ Îç∞Ïù¥ÌÑ∞ÏÖãÏùò Îç∞Ïù¥ÌÑ∞ Í∞úÏàòÎäî 979 ÏûÖÎãàÎã§. (test setÏùÄ ÏïàÎ∞îÎÄåÍ≤å Ìï¥ÎÜ®Îã§ ÏïåÏ†ú)\n",
      "Ïù¥ Îç∞Ïù¥ÌÑ∞ÏÖãÏùò Îç∞Ïù¥ÌÑ∞ Í∞úÏàòÎäî 240 ÏûÖÎãàÎã§. (test setÏùÄ ÏïàÎ∞îÎÄåÍ≤å Ìï¥ÎÜ®Îã§ ÏïåÏ†ú)\n",
      "dataset_hash = 0e8a8f2d81b4fe037308b5d792c4a037\n",
      "cache path exists\n",
      "\n",
      "len(train_loader): 979 BATCH: 1 train_data_count: 979\n",
      "len(test_loader): 240 BATCH: 1\n",
      "\n",
      "device ==> cuda\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " layer_count 1\n",
      "weight bias bit 0\n",
      "weight exp, bias exp None None\n",
      "bit_for_output 0 exp_for_output None \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "LIF 1 sg_bit 0\n",
      "\n",
      "\n",
      "++++++++++++++++++++++++\n",
      "\n",
      " lif layer 1 v_bit: 0, v_exp: None\n",
      "\n",
      "++++++++++++++++++++++++++++++++++++++++++++++\n",
      "\n",
      "\n",
      "\n",
      " layer_count 2\n",
      "weight bias bit 0\n",
      "weight exp, bias exp None None\n",
      "bit_for_output 0 exp_for_output None \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "LIF 2 sg_bit 0\n",
      "\n",
      "\n",
      "++++++++++++++++++++++++\n",
      "\n",
      " lif layer 2 v_bit: 0, v_exp: None\n",
      "\n",
      "++++++++++++++++++++++++++++++++++++++++++++++\n",
      "\n",
      "\n",
      "\n",
      " layer_count 3\n",
      "weight bias bit 0\n",
      "weight exp, bias exp None None\n",
      "bit_for_output 0 exp_for_output None \n",
      "\n",
      "\n",
      "\n",
      "DataParallel(\n",
      "  (module): REBORN_MY_SNN_FC(\n",
      "    (layers): REBORN_MY_Sequential(\n",
      "      (0): DimChanger_for_FC()\n",
      "      (1): SYNAPSE_FC(in_features=980, out_features=200, TIME=10, bias=False, sstep=True, time_different_weight=False, layer_count=1, quantize_bit_list=[], scale_exp=[[999, 998], [999, 999], [999, 999]], ANPI_MODE=False)\n",
      "      (2): LIF_layer(v_init=0, v_decay=0.5, v_threshold=0.015625, v_reset=10000, sg_width=4, surrogate=hard_sigmoid, BPTT_on=False, trace_const1=1, trace_const2=0.5, TIME=10, sstep=True, trace_on=False, layer_count=1, scale_exp=[[999, 998], [999, 999], [999, 999]], ANPI_MODE=False)\n",
      "      (3): SYNAPSE_FC(in_features=200, out_features=200, TIME=10, bias=False, sstep=True, time_different_weight=False, layer_count=2, quantize_bit_list=[], scale_exp=[[999, 998], [999, 999], [999, 999]], ANPI_MODE=False)\n",
      "      (4): LIF_layer(v_init=0, v_decay=0.5, v_threshold=0.015625, v_reset=10000, sg_width=4, surrogate=hard_sigmoid, BPTT_on=False, trace_const1=1, trace_const2=0.5, TIME=10, sstep=True, trace_on=False, layer_count=2, scale_exp=[[999, 998], [999, 999], [999, 999]], ANPI_MODE=False)\n",
      "      (5): SYNAPSE_FC(in_features=200, out_features=10, TIME=10, bias=False, sstep=True, time_different_weight=False, layer_count=3, quantize_bit_list=[], scale_exp=[[999, 998], [999, 999], [999, 999]], ANPI_MODE=False)\n",
      "    )\n",
      "  )\n",
      ")\n",
      "\n",
      "========================================================\n",
      "Trainable parameters: 238,000\n",
      "========================================================\n",
      "\n",
      "MySGD (\n",
      "Parameter Group 0\n",
      "    lr: 0.00390625\n",
      "    momentum: 0.0\n",
      ")\n",
      "total_backward_count 0 real_backward_count 0   0.000%\n",
      "epoch-0   lr=['0.0039062'], tr/val_loss:  0.067231/  0.094336, val:  29.17%, val_best:  29.17%, tr:  78.04%, tr_best:  78.04%, epoch time: 55.79 seconds, 0.93 minutes\n",
      "layer   1  Sparsity: 91.0897%\n",
      "layer   2  Sparsity: 58.8134%\n",
      "layer   3  Sparsity: 56.4918%\n",
      "total_backward_count 9790 real_backward_count 3374  34.464%\n",
      "epoch-1   lr=['0.0039062'], tr/val_loss:  0.052711/  0.074926, val:  54.58%, val_best:  54.58%, tr:  84.88%, tr_best:  84.88%, epoch time: 55.31 seconds, 0.92 minutes\n",
      "layer   1  Sparsity: 91.0555%\n",
      "layer   2  Sparsity: 58.5046%\n",
      "layer   3  Sparsity: 58.2188%\n",
      "total_backward_count 19580 real_backward_count 5947  30.373%\n",
      "epoch-2   lr=['0.0039062'], tr/val_loss:  0.048646/  0.079551, val:  47.08%, val_best:  54.58%, tr:  83.55%, tr_best:  84.88%, epoch time: 55.56 seconds, 0.93 minutes\n",
      "layer   1  Sparsity: 91.0850%\n",
      "layer   2  Sparsity: 58.1454%\n",
      "layer   3  Sparsity: 59.2088%\n",
      "total_backward_count 29370 real_backward_count 8326  28.349%\n",
      "epoch-3   lr=['0.0039062'], tr/val_loss:  0.047426/  0.072321, val:  54.17%, val_best:  54.58%, tr:  85.29%, tr_best:  85.29%, epoch time: 55.96 seconds, 0.93 minutes\n",
      "layer   1  Sparsity: 91.1236%\n",
      "layer   2  Sparsity: 57.8211%\n",
      "layer   3  Sparsity: 60.1056%\n",
      "total_backward_count 39160 real_backward_count 10696  27.314%\n",
      "epoch-4   lr=['0.0039062'], tr/val_loss:  0.045757/  0.074937, val:  52.08%, val_best:  54.58%, tr:  85.80%, tr_best:  85.80%, epoch time: 55.72 seconds, 0.93 minutes\n",
      "layer   1  Sparsity: 91.0451%\n",
      "layer   2  Sparsity: 57.4358%\n",
      "layer   3  Sparsity: 60.9305%\n",
      "total_backward_count 48950 real_backward_count 12962  26.480%\n",
      "epoch-5   lr=['0.0039062'], tr/val_loss:  0.044162/  0.072154, val:  52.50%, val_best:  54.58%, tr:  85.50%, tr_best:  85.80%, epoch time: 56.57 seconds, 0.94 minutes\n",
      "layer   1  Sparsity: 91.1029%\n",
      "layer   2  Sparsity: 57.1432%\n",
      "layer   3  Sparsity: 61.7462%\n",
      "total_backward_count 58740 real_backward_count 15140  25.775%\n",
      "epoch-6   lr=['0.0039062'], tr/val_loss:  0.043529/  0.081861, val:  44.58%, val_best:  54.58%, tr:  84.88%, tr_best:  85.80%, epoch time: 55.83 seconds, 0.93 minutes\n",
      "layer   1  Sparsity: 91.0665%\n",
      "layer   2  Sparsity: 56.9699%\n",
      "layer   3  Sparsity: 62.5559%\n",
      "total_backward_count 68530 real_backward_count 17269  25.199%\n",
      "epoch-7   lr=['0.0039062'], tr/val_loss:  0.043475/  0.066088, val:  59.17%, val_best:  59.17%, tr:  85.09%, tr_best:  85.80%, epoch time: 55.84 seconds, 0.93 minutes\n",
      "layer   1  Sparsity: 91.0872%\n",
      "layer   2  Sparsity: 56.7734%\n",
      "layer   3  Sparsity: 63.3814%\n",
      "total_backward_count 78320 real_backward_count 19477  24.868%\n",
      "epoch-8   lr=['0.0039062'], tr/val_loss:  0.042982/  0.068914, val:  57.08%, val_best:  59.17%, tr:  85.29%, tr_best:  85.80%, epoch time: 56.14 seconds, 0.94 minutes\n",
      "layer   1  Sparsity: 91.0644%\n",
      "layer   2  Sparsity: 56.7253%\n",
      "layer   3  Sparsity: 63.9798%\n",
      "total_backward_count 88110 real_backward_count 21730  24.662%\n",
      "epoch-9   lr=['0.0039062'], tr/val_loss:  0.041508/  0.065808, val:  59.17%, val_best:  59.17%, tr:  85.60%, tr_best:  85.80%, epoch time: 55.92 seconds, 0.93 minutes\n",
      "layer   1  Sparsity: 91.1000%\n",
      "layer   2  Sparsity: 56.6334%\n",
      "layer   3  Sparsity: 64.7341%\n",
      "total_backward_count 97900 real_backward_count 23903  24.416%\n",
      "epoch-10  lr=['0.0039062'], tr/val_loss:  0.041878/  0.069795, val:  58.33%, val_best:  59.17%, tr:  84.68%, tr_best:  85.80%, epoch time: 56.65 seconds, 0.94 minutes\n",
      "layer   1  Sparsity: 91.0367%\n",
      "layer   2  Sparsity: 56.5080%\n",
      "layer   3  Sparsity: 65.3510%\n",
      "total_backward_count 107690 real_backward_count 26102  24.238%\n",
      "epoch-11  lr=['0.0039062'], tr/val_loss:  0.040526/  0.068581, val:  55.83%, val_best:  59.17%, tr:  85.19%, tr_best:  85.80%, epoch time: 55.73 seconds, 0.93 minutes\n",
      "layer   1  Sparsity: 91.1024%\n",
      "layer   2  Sparsity: 56.3278%\n",
      "layer   3  Sparsity: 66.0479%\n",
      "total_backward_count 117480 real_backward_count 28167  23.976%\n",
      "epoch-12  lr=['0.0039062'], tr/val_loss:  0.040483/  0.071049, val:  58.33%, val_best:  59.17%, tr:  85.29%, tr_best:  85.80%, epoch time: 55.61 seconds, 0.93 minutes\n",
      "layer   1  Sparsity: 91.1025%\n",
      "layer   2  Sparsity: 56.2058%\n",
      "layer   3  Sparsity: 66.5952%\n",
      "total_backward_count 127270 real_backward_count 30279  23.791%\n"
     ]
    }
   ],
   "source": [
    "# sweep ÌïòÎäî ÏΩîÎìú, ÏúÑ ÏÖÄ Ï£ºÏÑùÏ≤òÎ¶¨ Ìï¥Ïïº Îê®.\n",
    "\n",
    "# Ïù¥Îü∞ ÏõåÎãù Îú®Îäî Í±∞Îäî Í±ç ÎÑàÍ∞Ä main ÏïàÏóêÏÑú  wandb.config.update(hyperparameters)Ìï† Îïå Î¨ºÎ†§ÏÑúÏûÑ. Ïñ¥Ï∞®Ìîº Í∑ºÎç∞ sweepÏóêÏÑú ÏßÄÏ†ïÌïú Í±∏Î°ú ÎçÆÏñ¥Ïßê \n",
    "# wandb: WARNING Config item 'BATCH' was locked by 'sweep' (ignored update).\n",
    "\n",
    "unique_name_hyper = 'main'\n",
    "sweep_configuration = {\n",
    "    'method': 'random', # 'random', 'bayes', 'grid'\n",
    "    'name': f'my_snn_sweep{datetime.datetime.now().strftime(\"%Y%m%d_%H%M%S\")}',\n",
    "    'metric': {'goal': 'maximize', 'name': 'val_acc_best'},\n",
    "    'parameters': \n",
    "    {\n",
    "        # \"devices\": {\"values\": [\"1\"]},\n",
    "        \"single_step\": {\"values\": [True]},\n",
    "        # \"unique_name\": {\"values\": [unique_name_hyper]},\n",
    "        \"my_seed\": {\"min\": 1, \"max\": 42000},\n",
    "        # \"my_seed\": {\"values\": [42]},\n",
    "        \"TIME\": {\"values\": [10]},\n",
    "        \"BATCH\": {\"values\": [1]},\n",
    "        \"IMAGE_SIZE\": {\"values\": [14]},\n",
    "        \"which_data\": {\"values\": ['DVS_GESTURE_TONIC']},\n",
    "        \"data_path\": {\"values\": ['/data2']},\n",
    "        \"rate_coding\": {\"values\": [False]},\n",
    "        \"lif_layer_v_init\": {\"values\": [0.0]},\n",
    "        \"lif_layer_v_decay\": {\"values\": [0.5]},\n",
    "        \"lif_layer_v_threshold\": {\"values\": [0.015625]},\n",
    "        \"lif_layer_v_reset\": {\"values\": [10000.0]},\n",
    "        \"lif_layer_sg_width\": {\"values\": [4.0]},\n",
    "        # \"lif_layer_sg_width\": {\"values\": [3.0, 6.0, 10.0, 15.0, 20.0]},\n",
    "\n",
    "        \"synapse_conv_kernel_size\": {\"values\": [3]},\n",
    "        \"synapse_conv_stride\": {\"values\": [1]},\n",
    "        \"synapse_conv_padding\": {\"values\": [1]},\n",
    "\n",
    "        \"synapse_trace_const1\": {\"values\": [1]},\n",
    "        \"synapse_trace_const2\": {\"values\": [0.5]},\n",
    "\n",
    "        \"pre_trained\": {\"values\": [False]},\n",
    "        \"convTrue_fcFalse\": {\"values\": [False]},\n",
    "\n",
    "        \"cfg\": {\"values\": [[200,200]]},\n",
    "\n",
    "        \"net_print\": {\"values\": [True]},\n",
    "\n",
    "        \"pre_trained_path\": {\"values\": [\"\"]},\n",
    "        \"learning_rate\": {\"values\": [1/256]}, \n",
    "        \"epoch_num\": {\"values\": [200]}, \n",
    "        \"tdBN_on\": {\"values\": [False]},\n",
    "        \"BN_on\": {\"values\": [False]},\n",
    "\n",
    "        \"surrogate\": {\"values\": ['hard_sigmoid']},\n",
    "\n",
    "        \"BPTT_on\": {\"values\": [False]},\n",
    "\n",
    "        \"optimizer_what\": {\"values\": ['SGD']},\n",
    "        \"scheduler_name\": {\"values\": ['no']},\n",
    "\n",
    "        \"ddp_on\": {\"values\": [False]},\n",
    "\n",
    "        \"dvs_clipping\": {\"values\": [14]}, \n",
    "\n",
    "        \"dvs_duration\": {\"values\": [25_000]}, \n",
    "\n",
    "        \"DFA_on\": {\"values\": [False]},\n",
    "\n",
    "        \"trace_on\": {\"values\": [False]},\n",
    "        \"OTTT_input_trace_on\": {\"values\": [False]},\n",
    "\n",
    "        \"exclude_class\": {\"values\": [True]},\n",
    "\n",
    "        \"merge_polarities\": {\"values\": [True]},\n",
    "        \"denoise_on\": {\"values\": [False]},\n",
    "\n",
    "        \"extra_train_dataset\": {\"values\": [-1]},\n",
    "\n",
    "        \"num_workers\": {\"values\": [2]},\n",
    "        \"chaching_on\": {\"values\": [True]},\n",
    "        \"pin_memory\": {\"values\": [True]},\n",
    "\n",
    "        \"UDA_on\": {\"values\": [False]},\n",
    "        \"alpha_uda\": {\"values\": [1.0]},\n",
    "\n",
    "        \"bias\": {\"values\": [False]},\n",
    "\n",
    "        \"last_lif\": {\"values\": [False]},\n",
    "\n",
    "        \"temporal_filter\": {\"values\": [5]},\n",
    "        \"initial_pooling\": {\"values\": [1]},\n",
    "\n",
    "        \"temporal_filter_accumulation\": {\"values\": [False]},\n",
    "\n",
    "        # \"quantize_bit_list_0\": {\"values\": [8]},\n",
    "        # \"quantize_bit_list_1\": {\"values\": [8]},\n",
    "        # \"quantize_bit_list_2\": {\"values\": [8]},\n",
    "\n",
    "\n",
    "        # \"scale_exp_1w\": {\"values\": [-10]},\n",
    "        # # \"scale_exp_1b\": {\"values\": [-11,-10,-9,-8,-7,-6]},\n",
    "        # \"scale_exp_2w\": {\"values\": [-10]},\n",
    "        # # \"scale_exp_2b\": {\"values\": [-10,-9,-8]},\n",
    "        # \"scale_exp_3w\": {\"values\": [-9]},\n",
    "        # # \"scale_exp_3b\": {\"values\": [-10,-9,-8,-7,-6]},\n",
    "     }\n",
    "}\n",
    "\n",
    "def hyper_iter():\n",
    "    ### my_snn control board ########################\n",
    "    wandb.init(save_code=False, dir='/data2/bh_wandb', tags=[\"sweep\"])\n",
    "\n",
    "    my_snn_system(  \n",
    "        devices  =  \"3\",\n",
    "        single_step  =  wandb.config.single_step,\n",
    "        unique_name  =  datetime.datetime.now().strftime(\"%Y%m%d_%H%M%S_\") + f\"{datetime.datetime.now().microsecond // 1000:03d}\",\n",
    "        my_seed  =  wandb.config.my_seed,\n",
    "        TIME  =  wandb.config.TIME,\n",
    "        BATCH  =  wandb.config.BATCH,\n",
    "        IMAGE_SIZE  =  wandb.config.IMAGE_SIZE,\n",
    "        which_data  =  wandb.config.which_data,\n",
    "        data_path  =  wandb.config.data_path,\n",
    "        rate_coding  =  wandb.config.rate_coding,\n",
    "        lif_layer_v_init  =  wandb.config.lif_layer_v_init,\n",
    "        lif_layer_v_decay  =  wandb.config.lif_layer_v_decay,\n",
    "        lif_layer_v_threshold  =  wandb.config.lif_layer_v_threshold,\n",
    "        lif_layer_v_reset  =  wandb.config.lif_layer_v_reset,\n",
    "        lif_layer_sg_width  =  wandb.config.lif_layer_sg_width,\n",
    "        synapse_conv_kernel_size  =  wandb.config.synapse_conv_kernel_size,\n",
    "        synapse_conv_stride  =  wandb.config.synapse_conv_stride,\n",
    "        synapse_conv_padding  =  wandb.config.synapse_conv_padding,\n",
    "        synapse_trace_const1  =  wandb.config.synapse_trace_const1,\n",
    "        synapse_trace_const2  =  wandb.config.synapse_trace_const2,\n",
    "        pre_trained  =  wandb.config.pre_trained,\n",
    "        convTrue_fcFalse  =  wandb.config.convTrue_fcFalse,\n",
    "        cfg  =  wandb.config.cfg,\n",
    "        net_print  =  wandb.config.net_print,\n",
    "        pre_trained_path  =  wandb.config.pre_trained_path,\n",
    "        learning_rate  =  wandb.config.learning_rate,\n",
    "        epoch_num  =  wandb.config.epoch_num,\n",
    "        tdBN_on  =  wandb.config.tdBN_on,\n",
    "        BN_on  =  wandb.config.BN_on,\n",
    "        surrogate  =  wandb.config.surrogate,\n",
    "        BPTT_on  =  wandb.config.BPTT_on,\n",
    "        optimizer_what  =  wandb.config.optimizer_what,\n",
    "        scheduler_name  =  wandb.config.scheduler_name,\n",
    "        ddp_on  =  wandb.config.ddp_on,\n",
    "        dvs_clipping  =  wandb.config.dvs_clipping,\n",
    "        dvs_duration  =  wandb.config.dvs_duration,\n",
    "        DFA_on  =  wandb.config.DFA_on,\n",
    "        trace_on  =  wandb.config.trace_on,\n",
    "        OTTT_input_trace_on  =  wandb.config.OTTT_input_trace_on,\n",
    "        exclude_class  =  wandb.config.exclude_class,\n",
    "        merge_polarities  =  wandb.config.merge_polarities,\n",
    "        denoise_on  =  wandb.config.denoise_on,\n",
    "        extra_train_dataset  =  wandb.config.extra_train_dataset,\n",
    "        num_workers  =  wandb.config.num_workers,\n",
    "        chaching_on  =  wandb.config.chaching_on,\n",
    "        pin_memory  =  wandb.config.pin_memory,\n",
    "        UDA_on  =  wandb.config.UDA_on,\n",
    "        alpha_uda  =  wandb.config.alpha_uda,\n",
    "        bias  =  wandb.config.bias,\n",
    "        last_lif  =  wandb.config.last_lif,\n",
    "        temporal_filter  =  wandb.config.temporal_filter,\n",
    "        initial_pooling  =  wandb.config.initial_pooling,\n",
    "        temporal_filter_accumulation  =  wandb.config.temporal_filter_accumulation,\n",
    "        quantize_bit_list  =  [],\n",
    "        scale_exp=[[999,998],[999,999],[999,999]], # [[neuron_quant,feedback weight quant],[],[]]\n",
    "                        ) \n",
    "    # sigmoidÏôÄ BNÏù¥ ÏûàÏñ¥Ïïº ÏûòÎêúÎã§.\n",
    "    # average pooling\n",
    "    # Ïù¥ ÎÇ´Îã§. \n",
    "    \n",
    "    # ndaÏóêÏÑúÎäî decay = 0.25, threshold = 0.5, width =1, surrogate = rectangle, batch = 256, tdBN = True\n",
    "    ## OTTT ÏóêÏÑúÎäî decay = 0.5, threshold = 1.0, surrogate = sigmoid, batch = 128, BN = True\n",
    "\n",
    "# sweep_id = 'm41wfhay'\n",
    "sweep_id = wandb.sweep(sweep=sweep_configuration, project=f'my_snn {unique_name_hyper}')\n",
    "wandb.agent(sweep_id, function=hyper_iter, count=10000, project=f'my_snn {unique_name_hyper}')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aedat2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
