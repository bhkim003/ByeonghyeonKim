{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ssp.train.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x600 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import torch   \n",
    "import torch.nn as nn \n",
    "import torch.nn.functional as F   \n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import torch.optim as optim\n",
    "from scipy import io\n",
    "import itertools\n",
    "import math\n",
    "import datetime\n",
    "import wandb\n",
    "import pickle\n",
    "import json\n",
    "import time\n",
    "import sys\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import accuracy_score\n",
    "from scipy.optimize import linear_sum_assignment\n",
    "from snntorch import spikegen\n",
    "\n",
    "\n",
    "# my module import\n",
    "from modules import *\n",
    "\n",
    "# modules 폴더에 새모듈.py 만들면\n",
    "# modules/__init__py 파일에 form .새모듈 import * 하셈\n",
    "# 그리고 새모듈.py에서 from modules.새모듈 import * 하셈"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cluster_train_system( \n",
    "    gpu = '4',\n",
    "    Conv_net = True,\n",
    "    SAE_net = True,\n",
    "\n",
    "    # hyperparameter\n",
    "    dataset_num = 16,\n",
    "    spike_length = 50,\n",
    "    num_cluster = 4,  # 클러스터 수 설정 # 논문엔 4개라는데 여기서는 3개로 했네\n",
    "    training_cycle = 2400, # 그 초기 몇개까지만 cluster update할지\n",
    "\n",
    "\n",
    "    batch_size = 32,\n",
    "    max_epoch = 7000,\n",
    "    learning_rate = 0.001,\n",
    "    normalize_on = False, # True or False #이거 안 씀 # 이거 별로 안 좋은 normalize같음 # 쓸 거면 다른 거 써라.\n",
    "    need_bias = False,\n",
    "    # first_layer_no_train = False\n",
    "    lif_add_at_first = False,\n",
    "    my_seed = 42,\n",
    "\n",
    "    TIME = 10, # SAE일 때만 유효\n",
    "    v_decay = 0.5,\n",
    "    v_threshold = 0.5,\n",
    "    v_reset = 10000.0, # 10000이상 일 시 hard reset\n",
    "    BPTT_on = True,\n",
    "\n",
    "    SAE_hidden_nomean = True,\n",
    "    current_time = '20250101_210938_786',\n",
    "\n",
    "    optimizer = 'Adam',\n",
    "    coarse_com_mode = True,\n",
    "    coarse_com_config = (2.0, -2.0), # (max, min)\n",
    "\n",
    "    sae_l2_norm_bridge = True,\n",
    "    sae_lif_bridge = False,\n",
    "\n",
    "    accuracy_check_epoch_term = 5,\n",
    "    \n",
    "    lif_add_at_last = False,\n",
    "\n",
    "    two_channel_input = False,\n",
    "\n",
    "    lateral_feature_num = 4,\n",
    "\n",
    "    lc_adc_on = False, \n",
    "\n",
    "    converted_net_forward = False,\n",
    "\n",
    "    pretrained_net = None, \n",
    "\n",
    "    vth_mul_on = False,\n",
    "    batch_norm_on = False,\n",
    "\n",
    "    l2_norm_loss_weight = 0.0,\n",
    "\n",
    "    QCFS_neuron_on = False,\n",
    "\n",
    "    quantize_level_num = 0,\n",
    "\n",
    "    fusion_net = False, # True False\n",
    "    repeat_coding = False,\n",
    "    \n",
    "    sae_relu_on = False,\n",
    "\n",
    "    conv1d_scaling = False,\n",
    "    ):\n",
    "    if coarse_com_mode == True:\n",
    "        assert coarse_com_config[0] > coarse_com_config[1], 'coarse_com_config[0] > coarse_com_config[1]이어야 함'\n",
    "        assert converted_net_forward == False\n",
    "        # assert SAE_net == True, 'coarse_com_mode는 SAE_net이 True일 때만 가능'\n",
    "    if two_channel_input == True:\n",
    "        assert Conv_net and coarse_com_mode, 'two_channel_input는 Conv_net이 True일 때만 가능'\n",
    "    if lc_adc_on == True:\n",
    "        assert coarse_com_mode and SAE_net, 'lc_adc_on은 coarse_com_mode와 SAE_net이 True일 때만 가능'\n",
    "    if converted_net_forward == True:\n",
    "        assert SAE_net == False, 'converted_net_forward는 SAE_net이 False일 때만 가능'\n",
    "    if conv1d_scaling:\n",
    "        assert Conv_net and coarse_com_mode and normalize_on\n",
    "    seed_assign(my_seed)\n",
    "    ## 함수 내 모든 로컬 변수 저장 ########################################################\n",
    "    hyperparameters = locals()\n",
    "    print(hyperparameters)\n",
    "    # JSON으로 저장\n",
    "    with open(f\"result_save/cluster_accuracy_history_{current_time}.json\", 'w') as f:\n",
    "        json.dump(hyperparameters, f, indent=4)\n",
    "    ######################################################################################\n",
    "\n",
    "    \n",
    "    wandb.config.update(hyperparameters)\n",
    "    wandb.run.name = f'{current_time}_SAE_net_{SAE_net}_v_threshold_{v_threshold}'\n",
    "    wandb.define_metric(\"best_mean_cluster_accuracy_post_training_cycle_all_dataset2\", summary=\"max\")\n",
    "\n",
    "\n",
    "    my_path_ground_BH = '/data2/spike_sorting/quiroga/BH/'\n",
    "\n",
    "\n",
    "    filename = [\"C_Easy1_noise005.mat\", \"C_Easy1_noise01.mat\", \"C_Easy1_noise015.mat\", \"C_Easy1_noise02.mat\",\n",
    "                \"C_Easy2_noise005.mat\", \"C_Easy2_noise01.mat\", \"C_Easy2_noise015.mat\", \"C_Easy2_noise02.mat\",\n",
    "                \"C_Difficult1_noise005.mat\", \"C_Difficult1_noise01.mat\", \"C_Difficult1_noise015.mat\", \"C_Difficult1_noise02.mat\",\n",
    "                \"C_Difficult2_noise005.mat\", \"C_Difficult2_noise01.mat\", \"C_Difficult2_noise015.mat\", \"C_Difficult2_noise02.mat\"]\n",
    "\n",
    "\n",
    "    spike_tot = [\"BH_Spike_e1n005.npy\", \"BH_Spike_e1n010.npy\", \"BH_Spike_e1n015.npy\", \"BH_Spike_e1n020.npy\",\n",
    "                \"BH_Spike_e2n005.npy\", \"BH_Spike_e2n010.npy\", \"BH_Spike_e2n015.npy\", \"BH_Spike_e2n020.npy\",\n",
    "                \"BH_Spike_d1n005.npy\", \"BH_Spike_d1n010.npy\", \"BH_Spike_d1n015.npy\", \"BH_Spike_d1n020.npy\",\n",
    "                \"BH_Spike_d2n005.npy\", \"BH_Spike_d2n010.npy\", \"BH_Spike_d2n015.npy\", \"BH_Spike_d2n020.npy\"]\n",
    "\n",
    "    label_tot = [\"BH_Label_e1n005.npy\", \"BH_Label_e1n010.npy\", \"BH_Label_e1n015.npy\", \"BH_Label_e1n020.npy\",\n",
    "                \"BH_Label_e2n005.npy\", \"BH_Label_e2n010.npy\", \"BH_Label_e2n015.npy\", \"BH_Label_e2n020.npy\",\n",
    "                \"BH_Label_d1n005.npy\", \"BH_Label_d1n010.npy\", \"BH_Label_d1n015.npy\", \"BH_Label_d1n020.npy\",\n",
    "                \"BH_Label_d2n005.npy\", \"BH_Label_d2n010.npy\", \"BH_Label_d2n015.npy\", \"BH_Label_d2n020.npy\"]\n",
    "\n",
    "    template =  [\"BH_Spike_TEMPLATE_e1n005.npy\", \"BH_Spike_TEMPLATE_e1n010.npy\", \"BH_Spike_TEMPLATE_e1n015.npy\", \"BH_Spike_TEMPLATE_e1n020.npy\",\n",
    "                \"BH_Spike_TEMPLATE_e2n005.npy\", \"BH_Spike_TEMPLATE_e2n010.npy\", \"BH_Spike_TEMPLATE_e2n015.npy\", \"BH_Spike_TEMPLATE_e2n020.npy\",\n",
    "                \"BH_Spike_TEMPLATE_d1n005.npy\", \"BH_Spike_TEMPLATE_d1n010.npy\", \"BH_Spike_TEMPLATE_d1n015.npy\", \"BH_Spike_TEMPLATE_d1n020.npy\",\n",
    "                \"BH_Spike_TEMPLATE_d2n005.npy\", \"BH_Spike_TEMPLATE_d2n010.npy\", \"BH_Spike_TEMPLATE_d2n015.npy\", \"BH_Spike_TEMPLATE_d2n020.npy\"]\n",
    "\n",
    "    AE_train_path_gt_detect = 'BH_quiroga_training_dataset_gt_detect.pt' \n",
    "    AE_test_path_gt_detect = 'BH_quiroga_test_dataset_gt_detect.pt'\n",
    "\n",
    "    AE_train_path_real_detect = 'BH_quiroga_training_dataset_real_detect.pt'\n",
    "    AE_test_path_real_detect = 'BH_quiroga_test_dataset_real_detect.pt'\n",
    "\n",
    "    AE_train_data = AE_train_path_real_detect #AE_train_path_gt_detect #AE_train_path_real_detect\n",
    "    AE_test_data = AE_test_path_real_detect #AE_test_path_gt_detect  #AE_test_path_real_detect\n",
    "\n",
    "    # thr_tot = np.array([0.5, 0.5, 0.55, 0.7, 0.5, 0.5, 0.55, 0.7, 0.5, 0.5, 0.55, 0.7, 0.5, 0.5, 0.55, 0.7])\n",
    "    cos_thr = np.array([0.95, 0.95, 0.95, 0.95, 0.95, 0.95, 0.95, 0.85, 0.95, 0.9, 0.8, 0.95, 0.95, 0.95, 0.95, 0.8])\n",
    "    # tem=10\n",
    "    # cos_thr = np.array([tem, tem, tem, tem, tem, tem, tem, tem, tem, tem, tem, tem, tem, tem, tem, tem, ])\n",
    "\n",
    "    print('cos_thr', cos_thr)\n",
    "    \n",
    "    os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\" \n",
    "    os.environ[\"CUDA_VISIBLE_DEVICES\"]= gpu\n",
    "\n",
    "\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "\n",
    "    if coarse_com_mode == True:\n",
    "        level_num = TIME\n",
    "        TIME = spike_length\n",
    "        spike_length = level_num\n",
    "        level_interval = (coarse_com_config[0] - coarse_com_config[1]) / (level_num-1)  # max - min\n",
    "        levels = [coarse_com_config[1] + level_interval * i for i in range(level_num)]\n",
    "        levels = torch.tensor(levels).to(torch.float).to(device)\n",
    "        levels = levels.repeat(TIME,1) \n",
    "        # print('levels', levels, levels.shape) # TIME, level_num\n",
    "\n",
    "    n_sample = spike_length\n",
    "\n",
    "    class spikedataset(Dataset):\n",
    "        def __init__(self, path, transform = None):    \n",
    "            self.transform = transform\n",
    "            self.spike = torch.load(path)\n",
    "            \n",
    "        def __getitem__(self, index):\n",
    "            spike = self.spike[index]            \n",
    "            if self.transform is not None:\n",
    "                spike = self.transform(spike)\n",
    "            return spike\n",
    "        \n",
    "        def __len__(self):\n",
    "            return len(self.spike)\n",
    "\n",
    "    train_dataset = spikedataset(my_path_ground_BH + AE_train_data)\n",
    "    train_loader = DataLoader(dataset = train_dataset, batch_size = batch_size, shuffle = True)\n",
    "\n",
    "    test_dataset = spikedataset(my_path_ground_BH + AE_test_data)\n",
    "    test_loader = DataLoader(dataset = test_dataset, batch_size = batch_size, shuffle = False)\n",
    "\n",
    "\n",
    "    # vth_mul_on = True # True False\n",
    "    # batch_norm_on = True # True False\n",
    "\n",
    "\n",
    "    # 모델 초기화\n",
    "    if SAE_net == False: # 여기서는 l2norm, lif bridge 둘 다 true면 l2norm먼저\n",
    "        assert two_channel_input == False\n",
    "\n",
    "        if Conv_net == True:\n",
    "            # input_channels = 2 if two_channel_input else 1\n",
    "            input_channels = TIME if coarse_com_mode else 1\n",
    "            if fusion_net == True:\n",
    "                assert False, '이거 맞음? 다시 확인'\n",
    "                net = FUSION_net_conv1(input_channels=input_channels, input_length=n_sample, encoder_ch = [32, 64, 96], fc_dim = lateral_feature_num, padding = 0, stride = 2, kernel_size = 3, \n",
    "                                    synapse_fc_trace_const1=1, \n",
    "                                    synapse_fc_trace_const2=v_decay, #안씀 \n",
    "                                    TIME=TIME, v_init=0.0, v_decay=v_decay, v_threshold=v_threshold, v_reset=v_reset, \n",
    "                                    sg_width=4.0, surrogate='sigmoid', BPTT_on=BPTT_on, need_bias=need_bias, lif_add_at_first=lif_add_at_first,\n",
    "                                    sae_l2_norm_bridge = sae_l2_norm_bridge, sae_lif_bridge = sae_lif_bridge, lif_add_at_last=lif_add_at_last, repeat_coding=repeat_coding).to(device)\n",
    "            else: \n",
    "                net = Autoencoder_conv1(input_channels=input_channels, input_length=n_sample, encoder_ch = [32, 64, 96], fc_dim = lateral_feature_num, padding = 0, stride = 2, kernel_size = 3, need_bias=need_bias, l2norm_bridge=sae_l2_norm_bridge, relu_bridge=sae_lif_bridge, activation_collector_on=False,\n",
    "                                        batch_norm_on=batch_norm_on, QCFS_neuron_on=QCFS_neuron_on).to(device)\n",
    "            net = torch.nn.DataParallel(net)\n",
    "            if converted_net_forward:\n",
    "                converted_net = SAE_converted_conv1(input_channels=input_channels, input_length=n_sample, encoder_ch = [32, 64, 96], fc_dim = lateral_feature_num, padding = 0, stride = 2, kernel_size = 3, \n",
    "                                    synapse_fc_trace_const1=1, \n",
    "                                    synapse_fc_trace_const2=v_decay, #안씀 \n",
    "                                    TIME=TIME, v_init=0.0, v_decay=v_decay, v_threshold=v_threshold, v_reset=v_reset, \n",
    "                                    sg_width=4.0, surrogate='sigmoid', BPTT_on=BPTT_on, need_bias=need_bias, lif_add_at_first=lif_add_at_first,\n",
    "                                    sae_l2_norm_bridge = sae_l2_norm_bridge, sae_lif_bridge = sae_lif_bridge, lif_add_at_last=lif_add_at_last,\n",
    "                                    vth_mul_on=vth_mul_on, batch_norm_on=batch_norm_on).to(device) # lif bridge는 무조건 들어가게 해놨음.\n",
    "                converted_net = torch.nn.DataParallel(converted_net)\n",
    "                print('converted_net', converted_net)\n",
    "        else:\n",
    "            n_sample = n_sample * TIME if coarse_com_mode else n_sample\n",
    "            net = Autoencoder_only_FC(encoder_ch=[400, lateral_feature_num], decoder_ch=[400,n_sample], n_sample=n_sample, need_bias=need_bias, l2norm_bridge=sae_l2_norm_bridge, relu_bridge=sae_lif_bridge, activation_collector_on=False,\n",
    "                                    batch_norm_on=batch_norm_on, QCFS_neuron_on=QCFS_neuron_on).to(device)\n",
    "            net = torch.nn.DataParallel(net)\n",
    "            if converted_net_forward:\n",
    "                converted_net = SAE_converted_fc(encoder_ch=[400, lateral_feature_num], \n",
    "                                    decoder_ch=[400, n_sample], \n",
    "                                    in_channels=n_sample, # in_channel 이 여기선 걍 lenght.\n",
    "                                    synapse_fc_trace_const1=1,\n",
    "                                    synapse_fc_trace_const2=v_decay,  #안씀 \n",
    "                                    TIME=TIME, v_init=0.0, v_decay=v_decay, v_threshold=v_threshold, v_reset=v_reset, \n",
    "                                    sg_width=4.0, surrogate='sigmoid', BPTT_on=BPTT_on, need_bias=need_bias, lif_add_at_first=lif_add_at_first,\n",
    "                                    sae_l2_norm_bridge = sae_l2_norm_bridge, sae_lif_bridge = sae_lif_bridge, lif_add_at_last=lif_add_at_last,\n",
    "                                    vth_mul_on=vth_mul_on, batch_norm_on=batch_norm_on).to(device) # lif bridge는 무조건 들어가게 해놨음.\n",
    "                converted_net = torch.nn.DataParallel(converted_net)\n",
    "                # print('converted_net', converted_net)\n",
    "    else:\n",
    "        if Conv_net == True: \n",
    "            input_channels = 1\n",
    "            input_channels = 2 if two_channel_input else 1\n",
    "            if fusion_net == True:  \n",
    "                assert coarse_com_mode == True\n",
    "                net = SAE_FUSION2_net_conv1(input_channels=input_channels, input_length=n_sample, encoder_ch = [32, 64, 96], fc_dim = lateral_feature_num, padding = 0, stride = 2, kernel_size = 3, \n",
    "                                    synapse_fc_trace_const1=1, \n",
    "                                    synapse_fc_trace_const2=v_decay, #안씀 \n",
    "                                    TIME=TIME, v_init=0.0, v_decay=v_decay, v_threshold=v_threshold, v_reset=v_reset, \n",
    "                                    sg_width=4.0, surrogate='sigmoid', BPTT_on=BPTT_on, need_bias=need_bias, lif_add_at_first=lif_add_at_first,\n",
    "                                    sae_l2_norm_bridge = sae_l2_norm_bridge, sae_lif_bridge = sae_lif_bridge, lif_add_at_last=lif_add_at_last, batch_norm_on=batch_norm_on, sae_relu_on=sae_relu_on).to(device)\n",
    "            else:\n",
    "                net = SAE_conv1(input_channels=input_channels, input_length=n_sample, encoder_ch = [32, 64, 96], fc_dim = lateral_feature_num, padding = 0, stride = 2, kernel_size = 3, \n",
    "                                    synapse_fc_trace_const1=1, \n",
    "                                    synapse_fc_trace_const2=v_decay, #안씀 \n",
    "                                    TIME=TIME, v_init=0.0, v_decay=v_decay, v_threshold=v_threshold, v_reset=v_reset, \n",
    "                                    sg_width=4.0, surrogate='sigmoid', BPTT_on=BPTT_on, need_bias=need_bias, lif_add_at_first=lif_add_at_first,\n",
    "                                    sae_l2_norm_bridge = sae_l2_norm_bridge, sae_lif_bridge = sae_lif_bridge, lif_add_at_last=lif_add_at_last, batch_norm_on=batch_norm_on, sae_relu_on=sae_relu_on).to(device)\n",
    "            # net = SAE_conv1_DR(input_channels=input_channels, input_length=n_sample, encoder_ch = [32, 64, 96], fc_dim = lateral_feature_num, padding = 0, stride = 2, kernel_size = 3, \n",
    "            #                     synapse_fc_trace_const1=1, \n",
    "            #                     synapse_fc_trace_const2=v_decay, #안씀 \n",
    "            #                     TIME=TIME, v_init=0.0, v_decay=v_decay, v_threshold=v_threshold, v_reset=v_reset, \n",
    "            #                     sg_width=4.0, surrogate='sigmoid', BPTT_on=BPTT_on, need_bias=need_bias, lif_add_at_first=lif_add_at_first,\n",
    "            #                     sae_l2_norm_bridge = sae_l2_norm_bridge, sae_lif_bridge = sae_lif_bridge, lif_add_at_last=lif_add_at_last, batch_norm_on=batch_norm_on).to(device)\n",
    "            net = torch.nn.DataParallel(net)\n",
    "        else:\n",
    "            net = SAE_fc_only(encoder_ch=[400, lateral_feature_num], \n",
    "                                decoder_ch=[400, n_sample], \n",
    "                                in_channels=n_sample, # in_channel 이 여기선 걍 lenght.\n",
    "                                synapse_fc_trace_const1=1,\n",
    "                                synapse_fc_trace_const2=v_decay,  #안씀 \n",
    "                                TIME=TIME, v_init=0.0, v_decay=v_decay, v_threshold=v_threshold, v_reset=v_reset, \n",
    "                                sg_width=4.0, surrogate='sigmoid', BPTT_on=BPTT_on, need_bias=need_bias, lif_add_at_first=lif_add_at_first,\n",
    "                                sae_l2_norm_bridge = sae_l2_norm_bridge, sae_lif_bridge = sae_lif_bridge, lif_add_at_last=lif_add_at_last, batch_norm_on=batch_norm_on, sae_relu_on=sae_relu_on).to(device)\n",
    "            net = torch.nn.DataParallel(net)\n",
    "\n",
    "    # net = torch.load('/home/bhkim003/github_folder/ByeonghyeonKim/my_snn/net_save/save_now_net_AE_re_e7000.pth')\n",
    "    # net = torch.load('/home/bhkim003/github_folder/ByeonghyeonKim/my_snn/net_save/save_now_net_20250101_210938_786.pth')\n",
    "    # load했으면 torch.nn.DataParallel 하지마\n",
    "    # net.module.load_state_dict(torch.load('/home/bhkim003/github_folder/ByeonghyeonKim/my_snn/net_save/save_now_net_annbase_20250108_210641_941.pth'))\n",
    "    if pretrained_net != None:\n",
    "        ######################## 모델이 달라서 dict로 weight만 넣고싶을 때\n",
    "        # # 저장된 가중치 로드\n",
    "        saved_state_dict = torch.load(pretrained_net)\n",
    "        current_state_dict = net.module.state_dict()\n",
    "\n",
    "        # 함수 호출로 가중치 매핑\n",
    "        updated_state_dict = map_and_load_weights(saved_state_dict, current_state_dict)\n",
    "\n",
    "        # 업데이트된 state_dict를 네트워크에 로드\n",
    "        net.module.load_state_dict(updated_state_dict)\n",
    "        ######################## 모델이 달라서 dict로 weight만 넣고싶을 때\n",
    "\n",
    "        ############## 일반적일 때\n",
    "        # net.module.load_state_dict(torch.load(pretrained_net))\n",
    "        ############## 일반적일 때\n",
    "    \n",
    "        # pre_net = Autoencoder_conv1(input_channels=input_channels, input_length=n_sample, encoder_ch = [32, 64, 96], fc_dim = lateral_feature_num, padding = 0, stride = 2, kernel_size = 3, need_bias=need_bias, l2norm_bridge=sae_l2_norm_bridge, relu_bridge=sae_lif_bridge, activation_collector_on=False,\n",
    "        #                         batch_norm_on=batch_norm_on, QCFS_neuron_on=False).to(device)\n",
    "        # pre_net = torch.nn.DataParallel(net)\n",
    "        # pre_net.module.load_state_dict(torch.load(pretrained_net))\n",
    "        # copy_weights(pre_net.module.encoder , net.module.encoder )\n",
    "        # copy_weights(pre_net.module.decoder , net.module.decoder  )\n",
    "\n",
    "        \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    wandb.watch(net, log=\"all\", log_freq = 10)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    if SAE_net == True:\n",
    "        assert 'SAE' in net.module.__class__.__name__\n",
    "\n",
    "\n",
    "\n",
    "    net = net.to(device)\n",
    "    print(f\"Total number of encoder parameters: {sum(p.numel() for p in net.module.encoder.parameters())}\")\n",
    "    print(net)\n",
    "    print('Device:',device)\n",
    "\n",
    "    \n",
    "    if optimizer == 'Adam':\n",
    "        optimizer = optim.Adam(net.parameters(), lr=learning_rate)\n",
    "    elif optimizer == 'SGD':\n",
    "        optimizer = optim.SGD(net.parameters(), lr = learning_rate, momentum = 0.9)\n",
    "    else:\n",
    "        assert False, 'optimizer를 잘못 입력했습니다.'\n",
    "        \n",
    "    loss_history = []\n",
    "    mean_cluster_accuracy_during_training_cycle_all_dataset_history = []\n",
    "    mean_cluster_accuracy_post_training_cycle_all_dataset_history = []\n",
    "    mean_cluster_accuracy_total_all_dataset_history = []\n",
    "\n",
    "    tau = np.zeros(num_cluster)\n",
    "\n",
    "    print(f\"\\nStart Training, current_time = {current_time}\")\n",
    "    mean_cluster_accuracy_post_training_cycle_all_dataset = 0\n",
    "    best_mean_cluster_accuracy_post_training_cycle_all_dataset = 0\n",
    "\n",
    "    if SAE_net == True:\n",
    "        assert 'SAE' in net.module.__class__.__name__\n",
    "        \n",
    "    k_means_acc_best = 0\n",
    "    min_loss = 9999999\n",
    "    min_loss_normal = 9999999\n",
    "    min_loss_coarse = 9999999\n",
    "    for epoch in range(max_epoch):\n",
    "        print()\n",
    "        l2_loss_bin= 0\n",
    "        ae_train_start_time = time.time()\n",
    "        running_loss = 0.0\n",
    "        running_loss_normal = 0.0\n",
    "        running_loss_coarse = 0.0\n",
    "        iter = 0\n",
    "        net.train()\n",
    "        # if True or max_epoch != 1:\n",
    "        wrong_element_sum = 0\n",
    "        same_data_num = 0\n",
    "        total_data_num = 0\n",
    "        if max_epoch != 1:\n",
    "            for data in train_loader:\n",
    "                optimizer.zero_grad()\n",
    "                total_data_num += len(data)\n",
    "                data = data.to(device)\n",
    "                scaling = (level_num-3)/level_num if conv1d_scaling else 1.0\n",
    "                data = zero_to_one_normalize_features(data, level_num=quantize_level_num, coarse_com_config=coarse_com_config, scaling=scaling) if normalize_on else data\n",
    "                # plot_origin_spike(data[0].cpu().detach().numpy())\n",
    "                spike_backup = data\n",
    "                spike = data\n",
    "                spike = spike.to(device) # batch, feature\n",
    "                spike_for_fusion2_net = spike\n",
    "                if coarse_com_mode == True and 'SAE' in net.module.__class__.__name__:\n",
    "                    spike = spike.unsqueeze(2).repeat(1, 1, level_num) # spike_length == level_num # (batch, time, feature)로 변환 \n",
    "                    spike = (spike > levels).to(torch.float) \n",
    "\n",
    "                    spike = (spike == 0).cumsum(dim=-1).eq(1).to(torch.float) if lc_adc_on == True else spike\n",
    "\n",
    "                    # spike: batch, time, level_num\n",
    "                    # levels: time, level_num\n",
    "                    if Conv_net == True:\n",
    "                        spike = spike.unsqueeze(-2) # batch, time, in_channel, feature or batch in_channel,feature\n",
    "                        if two_channel_input == True:\n",
    "                            spike_backup = spike_backup.to(device)\n",
    "                            spike_backup = spike_backup.unsqueeze(2).repeat(1, 1, level_num) # spike_length == level_num # (batch, time, feature)로 변환 \n",
    "                            spike_backup = (spike_backup <= levels).to(torch.float) \n",
    "                            spike_backup = (spike_backup == 1).cumsum(dim=-1).eq(1).to(torch.float) if lc_adc_on == True else spike_backup\n",
    "                            spike_backup = spike_backup.unsqueeze(-2)\n",
    "                            spike = torch.cat((spike, spike_backup), dim=-2)\n",
    "                    assert spike.shape[0] == batch_size and spike.shape[1] == TIME\n",
    "                elif 'SAE' in net.module.__class__.__name__:\n",
    "                    spike = spike.unsqueeze(-1).repeat(1, 1, TIME).permute(0,2,1) # (batch, time, feature)로 변환\n",
    "                    if Conv_net == True:\n",
    "                        spike = spike.unsqueeze(-2) # batch, time, in_channel, feature or batch in_channel,feature\n",
    "                else:\n",
    "                    if Conv_net == True:\n",
    "                        if coarse_com_mode == False:\n",
    "                            spike = spike.unsqueeze(-2) #batch in_channel,feature\n",
    "                        else:\n",
    "                            spike = spike.unsqueeze(2).repeat(1, 1, level_num) # spike_length == level_num # (batch, time, feature)로 변환 \n",
    "                            spike = (spike > levels).to(torch.float) \n",
    "\n",
    "                            spike = (spike == 0).cumsum(dim=-1).eq(1).to(torch.float) if lc_adc_on == True else spike\n",
    "\n",
    "                    else:\n",
    "                        if coarse_com_mode == False:\n",
    "                            pass\n",
    "                        else:\n",
    "                            spike = spike.unsqueeze(2).repeat(1, 1, level_num) # spike_length == level_num # (batch, time, feature)로 변환 \n",
    "                            spike = (spike > levels).to(torch.float) \n",
    "\n",
    "                            spike = (spike == 0).cumsum(dim=-1).eq(1).to(torch.float) if lc_adc_on == True else spike\n",
    "\n",
    "                            # spike: batch, time, feature\n",
    "                            spike = spike.reshape(spike.shape[0], -1)\n",
    "\n",
    "                    \n",
    "\n",
    "\n",
    "                    # if fusion_net == True:\n",
    "                    #     spike = spikegen.rate(spike, num_steps=TIME).transpose(0, 1)\n",
    "\n",
    "                # for i in range (3):\n",
    "                #     plot_spike(spike[i,:,0,:].cpu().numpy())\n",
    "                #     plot_spike(spike[i,:,1,:].cpu().numpy())\n",
    "                # assert False\n",
    "                        \n",
    "                # spike_class = net(spike) # batch, time, feature\n",
    "                encoded_spike = net.module.encoder(spike)\n",
    "                spike_class = net.module.decoder(encoded_spike)\n",
    "\n",
    "                loss = 0\n",
    "                loss_normal = torch.tensor(0.0)\n",
    "                loss_coarse = torch.tensor(0.0)\n",
    "                if coarse_com_mode == True and 'SAE' in net.module.__class__.__name__:\n",
    "                    criterion = nn.MSELoss().to(device)\n",
    "                    # loss1 = nn.MSELoss()(spike_class[..., 5:25], spike[..., 5:25])\n",
    "                    # loss2 = nn.MSELoss()(spike_class[..., 0:5], spike[..., 0:5])\n",
    "                    # loss3 = nn.MSELoss()(spike_class[..., 25:spike_length], spike[..., 25:spike_length])\n",
    "                    # loss = loss1 * 2.125 + (loss2 + loss3)/4\n",
    "\n",
    "                    # loss1 = nn.MSELoss()(spike_class[..., 5:25, :], spike[..., 5:25, :])\n",
    "                    # loss2 = nn.MSELoss()(spike_class[..., 0:5, :], spike[..., 0:5, :])\n",
    "                    # loss3 = nn.MSELoss()(spike_class[..., 25:spike_length, :], spike[..., 25:spike_length, :])\n",
    "                    # loss = loss1 * 2.125 + (loss2 + loss3)/4\n",
    "                    if fusion_net:\n",
    "                        spike = spike_for_fusion2_net\n",
    "                        spike = spike.squeeze()\n",
    "                        spike_class = spike_class.squeeze()\n",
    "                        # loss = criterion(spike_class, spike)\n",
    "                        loss1 = criterion(spike_class[..., 5:25], spike[..., 5:25])\n",
    "                        loss2 = criterion(spike_class[..., 0:5], spike[..., 0:5])\n",
    "                        loss3 = criterion(spike_class[..., 25:], spike[..., 25:])\n",
    "                        loss = loss1 * 2.125 + (loss2 + loss3)/4\n",
    "                        # coarse loss ######################################################\n",
    "                        loss_normal = criterion(spike_class, spike)\n",
    "                        level_num_in_loss = spike_length\n",
    "                        level_interval = (coarse_com_config[0] - coarse_com_config[1]) / (level_num_in_loss-1)  # max - min\n",
    "                        levels = [coarse_com_config[1] + level_interval * i for i in range(level_num_in_loss)]\n",
    "                        levels = torch.tensor(levels).to(torch.float).to(device)\n",
    "                        levels = levels.repeat(spike_length,1) \n",
    "\n",
    "                        spike = spike.squeeze()\n",
    "                        spike_class = spike_class.squeeze()\n",
    "                        # plot_origin_spike(spike_class[0].cpu().detach().numpy())\n",
    "                        spike = spike.unsqueeze(2).repeat(1, 1, level_num_in_loss) \n",
    "                        spike = (spike > levels).to(torch.float) \n",
    "                        spike_class = spike_class.unsqueeze(2).repeat(1, 1, level_num_in_loss) \n",
    "                        spike_class = (spike_class > levels).to(torch.float) \n",
    "                        # spike = spike[..., 0:-3, :]\n",
    "                        # spike_class = spike_class[..., 0:-3, :]\n",
    "                        loss_coarse = criterion(spike_class, spike)\n",
    "                        wrong_element_sum += torch.sum(torch.abs(spike - spike_class)).item() \n",
    "\n",
    "                        # plot_spike(spike_class[0].cpu().detach().numpy())\n",
    "                        # assert False\n",
    "                        # coarse loss ######################################################\n",
    "                    else:\n",
    "                        spike = spike.squeeze()\n",
    "                        spike_class = spike_class.squeeze()\n",
    "                        loss = criterion(spike_class, spike)\n",
    "\n",
    "                    for iii in range(spike.shape[0]):\n",
    "                        same_data_num = same_data_num + 1 if torch.eq(spike[iii], spike_class[iii]).all() else same_data_num\n",
    "                    wrong_element_sum += torch.sum(torch.abs(spike - spike_class)).item() \n",
    "\n",
    "                    # spike = spike.squeeze()\n",
    "                    # spike_class = spike_class.squeeze()\n",
    "                    # plot_spike(spike[0].cpu().detach().numpy())\n",
    "                    # plot_spike(spike_class[0].cpu().detach().numpy())\n",
    "                    # print('손실 절대값 합',np.sum(np.abs(spike[0].cpu().detach().numpy() - spike_class[0].cpu().detach().numpy())))\n",
    "                    # # assert False\n",
    "                elif 'SAE' in net.module.__class__.__name__:\n",
    "                    criterion = nn.MSELoss().to(device)\n",
    "                    loss1 = criterion(spike_class[..., 5:25], spike[..., 5:25])\n",
    "                    loss2 = criterion(spike_class[..., 0:5], spike[..., 0:5])\n",
    "                    loss3 = criterion(spike_class[..., 25:spike_length], spike[..., 25:spike_length])\n",
    "                    loss = loss1 * 2.125 + (loss2 + loss3)/4\n",
    "                    assert spike_length > 25, 'spike_length가 25보다 작음'\n",
    "                    # wrong_element_sum += torch.sum(torch.abs(spike - spike_class)).item() \n",
    "                else:\n",
    "                    criterion = nn.MSELoss().to(device)\n",
    "                    loss1 = criterion(spike_class[..., 5:25], spike[..., 5:25])\n",
    "                    loss2 = criterion(spike_class[..., 0:5], spike[..., 0:5])\n",
    "                    loss3 = criterion(spike_class[..., 25:spike_length], spike[..., 25:spike_length])\n",
    "                    loss = loss1 * 2.125 + (loss2 + loss3)/4\n",
    "                    assert spike_length > 25, 'spike_length가 25보다 작음'\n",
    "                    # wrong_element_sum += torch.sum(torch.abs(spike - spike_class)).item() \n",
    "\n",
    "                    if l2_norm_loss_weight > 0:\n",
    "                        assert len(encoded_spike.shape) == 2, 'time 성분 없는 걸로'\n",
    "                        l2_loss = l2_norm_loss(encoded_spike, target_norm=1.0)  # L2Norm Loss 계산, l2 1.0되게.\n",
    "                        loss = loss + l2_loss*l2_norm_loss_weight\n",
    "                        l2_loss_bin += l2_loss.item()\n",
    "\n",
    "                    # coarse loss ######################################################\n",
    "                    loss_normal = criterion(spike_class, spike)\n",
    "                    level_num_in_loss = quantize_level_num\n",
    "                    level_interval = (coarse_com_config[0] - coarse_com_config[1]) / (level_num_in_loss-1)  # max - min\n",
    "                    levels = [coarse_com_config[1] + level_interval * i for i in range(level_num_in_loss)]\n",
    "                    levels = torch.tensor(levels).to(torch.float).to(device)\n",
    "                    levels = levels.repeat(spike_length,1) \n",
    "\n",
    "                    spike = spike.squeeze()\n",
    "                    spike_class = spike_class.squeeze()\n",
    "                    # plot_origin_spike(spike_class[0].cpu().detach().numpy())\n",
    "                    spike = spike.unsqueeze(2).repeat(1, 1, level_num_in_loss) \n",
    "                    spike = (spike > levels).to(torch.float) \n",
    "                    spike_class = spike_class.unsqueeze(2).repeat(1, 1, level_num_in_loss) \n",
    "                    spike_class = (spike_class > levels).to(torch.float) \n",
    "                    # spike = spike[..., 0:-3, :]\n",
    "                    # spike_class = spike_class[..., 0:-3, :]\n",
    "                    loss_coarse = criterion(spike_class, spike)\n",
    "                    wrong_element_sum += torch.sum(torch.abs(spike - spike_class)).item() \n",
    "\n",
    "                    # plot_spike(spike_class[0].cpu().detach().numpy())\n",
    "                    # assert False\n",
    "                    # coarse loss ######################################################\n",
    "\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                running_loss += loss.item()\n",
    "                running_loss_normal += loss_normal.item()\n",
    "                running_loss_coarse += loss_coarse.item()\n",
    "                # print(f'\\nepoch-{epoch}, running_loss : {running_loss:.5f}, iter percent {iter/len(train_loader)*100:.2f}%')\n",
    "                iter += 1\n",
    "        else:\n",
    "            print('\\n\\n\\n max_epoch 1이면 Train 안함!!!!!!!!!!!!!!!!!!!!!')\n",
    "        if l2_norm_loss_weight > 0:\n",
    "            print('l2_loss_bin', l2_loss_bin/len(train_loader))\n",
    "        avg_loss = running_loss / len(train_loader)\n",
    "        assert not np.isnan(avg_loss), f\"Error: avg_loss is NaN! Running loss: {running_loss}, Length of train_loader: {len(train_loader)}\"\n",
    "        loss_history.append((epoch, avg_loss))\n",
    "        min_loss = min(min_loss, avg_loss)\n",
    "        min_loss_normal = min(min_loss_normal, running_loss_normal/len(train_loader))\n",
    "        min_loss_coarse = min(min_loss_coarse, running_loss_coarse/len(train_loader))\n",
    "        print(f'\\nepoch-{epoch} loss : {avg_loss:.8f}, loss_normal : {running_loss_normal/len(train_loader):.8f}, loss_coarse : {running_loss_coarse/len(train_loader):.8f}, min_loss : {min_loss:.8f}, min_loss_normal : {min_loss_normal:.8f}, min_loss_coarse : {min_loss_coarse:.8f}, wrong_element_sum : {wrong_element_sum:.8f}, same_data : {100*same_data_num/(total_data_num+1e-12):.2f}%')\n",
    "        print(f\"ae train 실행 시간: {time.time()-ae_train_start_time:.3f}초, 전체 시작 시간 {current_time}\")\n",
    "\n",
    "        # plot_activation_distribution(net)\n",
    "\n",
    "        if SAE_net == False and converted_net_forward == True:\n",
    "            source_encoder = net.module.encoder \n",
    "            target_encoder = converted_net.module.encoder  \n",
    "            copy_weights(source_encoder, target_encoder)\n",
    "\n",
    "        cluster_accuracy_during_training_cycle_all_dataset = np.zeros(dataset_num)\n",
    "        cluster_accuracy_post_training_cycle_all_dataset = np.zeros(dataset_num)\n",
    "        cluster_accuracy_total_all_dataset = np.zeros(dataset_num)    \n",
    "\n",
    "        k_means_acc = 0\n",
    "        converted_k_means_acc = 0\n",
    "        if(epoch % accuracy_check_epoch_term == 0 or epoch == 1 or epoch == max_epoch-1): \n",
    "            accuracy_check_start_time = time.time()\n",
    "            print(f'\\nepoch-{epoch} accuracy check')\n",
    "            k_means_bin_origin_feature = []\n",
    "            k_means_bin = []\n",
    "            converted_k_means_bin = []\n",
    "            for ds in range(dataset_num):\n",
    "                # print('\\n', spike_tot[ds])\n",
    "\n",
    "                spike_template = np.load(my_path_ground_BH + template[ds])\n",
    "                spike = np.load(my_path_ground_BH + spike_tot[ds])\n",
    "                label = np.load(my_path_ground_BH + label_tot[ds])\n",
    "                spike_template = torch.from_numpy(spike_template).to(device)\n",
    "                spike = torch.from_numpy(spike).to(device)\n",
    "                scaling = (level_num-3)/level_num if conv1d_scaling else 1.0\n",
    "                spike_template = zero_to_one_normalize_features(spike_template, level_num=quantize_level_num, coarse_com_config=coarse_com_config, scaling=scaling) if normalize_on else spike_template\n",
    "                spike = zero_to_one_normalize_features(spike, level_num=quantize_level_num, coarse_com_config=coarse_com_config, scaling=scaling) if normalize_on else spike\n",
    "                \n",
    "                hidden_size = lateral_feature_num*TIME if 'SAE' in net.module.__class__.__name__ and SAE_hidden_nomean == True and fusion_net == False else lateral_feature_num\n",
    "                hidden_size = lateral_feature_num if '_DR' in net.module.__class__.__name__  else hidden_size\n",
    "\n",
    "                Cluster = np.zeros((num_cluster, hidden_size))\n",
    "                assert Cluster.shape[-1] == hidden_size, '이거 hidden dim 4 아니게 할 거면 잘 바꿔라'\n",
    "                \n",
    "\n",
    "\n",
    "                net.eval()\n",
    "                with torch.no_grad():\n",
    "                    spike_torch = spike_template.float()\n",
    "                    spike_torch = spike_torch[:num_cluster]\n",
    "                    spike_backup = spike_torch\n",
    "                    spike_torch = spike_torch.to(device)\n",
    "                    if coarse_com_mode == True and 'SAE' in net.module.__class__.__name__:\n",
    "                        spike_torch = spike_torch.unsqueeze(2).repeat(1, 1, level_num) # spike_length == level_num # (batch, time, feature)로 변환 \n",
    "                        spike_torch = (spike_torch > levels).to(torch.float) \n",
    "                        spike_torch = (spike_torch == 0).cumsum(dim=-1).eq(1).to(torch.float) if lc_adc_on == True else spike_torch\n",
    "                        if Conv_net == True:\n",
    "                            spike_torch = spike_torch.unsqueeze(-2) # batch, time, in_channel, feature or batch in_channel,feature\n",
    "                            if two_channel_input == True:\n",
    "                                spike_backup = spike_backup.to(device)\n",
    "                                spike_backup = spike_backup.unsqueeze(2).repeat(1, 1, level_num) # spike_length == level_num # (batch, time, feature)로 변환 \n",
    "                                spike_backup = (spike_backup <= levels).to(torch.float) \n",
    "                                spike_backup = (spike_backup == 1).cumsum(dim=-1).eq(1).to(torch.float) if lc_adc_on == True else spike_backup\n",
    "                                spike_backup = spike_backup.unsqueeze(-2) # batch, time, in_channel, feature\n",
    "                                spike_torch = torch.cat((spike_torch, spike_backup), dim=-2)\n",
    "                    elif 'SAE' in net.module.__class__.__name__:\n",
    "                        spike_torch = spike_torch.unsqueeze(1).repeat(1, TIME, 1) # (batch, time, feature)로 변환\n",
    "                        if Conv_net == True:\n",
    "                            spike_torch = spike_torch.unsqueeze(-2) # batch, time, in_channel, feature or batch in_channel,feature\n",
    "                    else:\n",
    "                        # if Conv_net == True:\n",
    "                        #     spike_torch = spike_torch.unsqueeze(-2) #batch in_channel,feature\n",
    "                        if Conv_net == True:\n",
    "                            if coarse_com_mode == False:\n",
    "                                spike_torch = spike_torch.unsqueeze(-2) #batch in_channel,feature\n",
    "                            else:\n",
    "                                spike_torch = spike_torch.unsqueeze(2).repeat(1, 1, level_num) # spike_length == level_num # (batch, time, feature)로 변환 \n",
    "                                spike_torch = (spike_torch > levels).to(torch.float) \n",
    "\n",
    "                                spike_torch = (spike_torch == 0).cumsum(dim=-1).eq(1).to(torch.float) if lc_adc_on == True else spike_torch\n",
    "\n",
    "                        else:\n",
    "                            if coarse_com_mode == False:\n",
    "                                pass\n",
    "                            else:\n",
    "                                spike_torch = spike_torch.unsqueeze(2).repeat(1, 1, level_num) # spike_length == level_num # (batch, time, feature)로 변환 \n",
    "                                spike_torch = (spike_torch > levels).to(torch.float) \n",
    "\n",
    "                                spike_torch = (spike_torch == 0).cumsum(dim=-1).eq(1).to(torch.float) if lc_adc_on == True else spike_torch\n",
    "\n",
    "                                # spike: batch, time, feature\n",
    "                                spike_torch = spike_torch.reshape(spike_torch.shape[0], -1)\n",
    "\n",
    "                        if converted_net_forward == True:\n",
    "                            spike_torch_spikegen = spikegen.rate(spike_torch, num_steps=TIME).transpose(0, 1)\n",
    "                        # if fusion_net == True:\n",
    "                        #     spike_torch = spikegen.rate(spike_torch, num_steps=TIME).transpose(0, 1)\n",
    "                    ### forward #######################################################\n",
    "                    inner_inf = net.module.encoder(spike_torch)\n",
    "                    if SAE_net == False and converted_net_forward == True:\n",
    "                        converted_inner_inf = converted_net.module.encoder(spike_torch_spikegen)\n",
    "                    ### forward #######################################################\n",
    "\n",
    "                    # for i in range(3):\n",
    "                    #     plot_spike(spike_torch[i,:,:].cpu().numpy())\n",
    "                    #     plot_spike(inner_inf[i,:].cpu().numpy())\n",
    "                    #     plot_spike(net.module.decoder(inner_inf)[i,:,:].cpu().numpy())\n",
    "                        \n",
    "                    # if 'SAE' in net.module.__class__.__name__:\n",
    "                    #     tensors = [inner_inf[0][i] for i in range(TIME)] \n",
    "                    #     all_equal = all(torch.equal(tensors[0], t) for t in tensors)\n",
    "                    #     print(all_equal, inner_inf)\n",
    "\n",
    "                    if 'SAE' in net.module.__class__.__name__:\n",
    "                        if SAE_hidden_nomean == True:\n",
    "                            inner_inf = inner_inf.reshape(inner_inf.shape[0],-1)# time*feature 펼치기\n",
    "                        else:\n",
    "                            inner_inf = inner_inf.mean(dim=1)# Time 방향으로 평균\n",
    "                        # inner_inf = F.normalize(inner_inf, p=2, dim=1)\n",
    "                    Cluster = inner_inf.cpu().detach().numpy()\n",
    "\n",
    "                encoder_batch = 128\n",
    "                spike_hidden = np.zeros((len(spike), hidden_size))\n",
    "                converted_spike_hidden = np.zeros((len(spike), hidden_size))\n",
    "                net.eval()\n",
    "                with torch.no_grad():\n",
    "                    now_index = 0\n",
    "                    while (1):\n",
    "                        now_end_index = now_index+encoder_batch if now_index+encoder_batch < len(spike) else len(spike)\n",
    "                        spike_batch = spike[now_index:now_end_index] \n",
    "                        spike_torch = spike_batch\n",
    "                        spike_torch = spike_torch.float()\n",
    "                        spike_backup = spike_torch\n",
    "                        spike_torch = spike_torch.to(device)\n",
    "                        if coarse_com_mode == True and 'SAE' in net.module.__class__.__name__:\n",
    "                            spike_torch = spike_torch.unsqueeze(2).repeat(1, 1, level_num) # spike_length == level_num # (batch, time, feature)로 변환 \n",
    "                            spike_torch = (spike_torch > levels).to(torch.float) \n",
    "                            spike_torch = (spike_torch == 0).cumsum(dim=-1).eq(1).to(torch.float) if lc_adc_on == True else spike_torch\n",
    "                            if Conv_net == True:\n",
    "                                spike_torch = spike_torch.unsqueeze(-2) # batch, time, in_channel, feature or batch in_channel,feature\n",
    "                                if two_channel_input == True:\n",
    "                                    spike_backup = spike_backup.to(device)\n",
    "                                    spike_backup = spike_backup.unsqueeze(2).repeat(1, 1, level_num) # spike_length == level_num # (batch, time, feature)로 변환 \n",
    "                                    spike_backup = (spike_backup <= levels).to(torch.float) \n",
    "                                    spike_backup = (spike_backup == 1).cumsum(dim=-1).eq(1).to(torch.float) if lc_adc_on == True else spike_backup\n",
    "                                    spike_backup = spike_backup.unsqueeze(-2)\n",
    "                                    spike_torch = torch.cat((spike_torch, spike_backup), dim=-2)\n",
    "                        elif 'SAE' in net.module.__class__.__name__:\n",
    "                            spike_torch = spike_torch.unsqueeze(1).repeat(1, TIME, 1) # (batch, time, feature)로 변환\n",
    "                            if Conv_net == True:\n",
    "                                spike_torch = spike_torch.unsqueeze(-2) # batch, time, in_channel, feature or batch in_channel,feature\n",
    "                        else:\n",
    "                            # if Conv_net == True:\n",
    "                            #     spike_torch = spike_torch.unsqueeze(-2) #batch in_channel,feature\n",
    "                            if Conv_net == True:\n",
    "                                if coarse_com_mode == False:\n",
    "                                    spike_torch = spike_torch.unsqueeze(-2) #batch in_channel,feature\n",
    "                                else:\n",
    "                                    spike_torch = spike_torch.unsqueeze(2).repeat(1, 1, level_num) # spike_length == level_num # (batch, time, feature)로 변환 \n",
    "                                    spike_torch = (spike_torch > levels).to(torch.float) \n",
    "\n",
    "                                    spike_torch = (spike_torch == 0).cumsum(dim=-1).eq(1).to(torch.float) if lc_adc_on == True else spike_torch\n",
    "\n",
    "                            else:\n",
    "                                if coarse_com_mode == False:\n",
    "                                    pass\n",
    "                                else:\n",
    "                                    spike_torch = spike_torch.unsqueeze(2).repeat(1, 1, level_num) # spike_length == level_num # (batch, time, feature)로 변환 \n",
    "                                    spike_torch = (spike_torch > levels).to(torch.float) \n",
    "\n",
    "                                    spike_torch = (spike_torch == 0).cumsum(dim=-1).eq(1).to(torch.float) if lc_adc_on == True else spike_torch\n",
    "\n",
    "                                    # spike: batch, time, feature\n",
    "                                    spike_torch = spike_torch.reshape(spike_torch.shape[0], -1)\n",
    "                            if converted_net_forward == True:\n",
    "                                spike_torch_spikegen = spikegen.rate(spike_torch, num_steps=TIME).transpose(0, 1)\n",
    "                            # if fusion_net == True:\n",
    "                            #     spike_torch = spikegen.rate(spike_torch, num_steps=TIME).transpose(0, 1)\n",
    "                        ### forward #######################################################\n",
    "                        inner_inf = net.module.encoder(spike_torch)\n",
    "                        if SAE_net == False and converted_net_forward == True:\n",
    "                            converted_inner_inf = converted_net.module.encoder(spike_torch_spikegen)\n",
    "                        ### forward #######################################################\n",
    "                            \n",
    "                        if 'SAE' in net.module.__class__.__name__:\n",
    "                            if SAE_hidden_nomean == True:\n",
    "                                inner_inf = inner_inf.reshape(spike_batch.shape[0],-1)# 펼치기\n",
    "                            else:\n",
    "                                inner_inf = inner_inf.mean(dim=1)# Time 방향으로 평균\n",
    "                            # inner_inf = F.normalize(inner_inf, p=2, dim=1)\n",
    "                        spike_hidden[now_index:now_end_index] = inner_inf.cpu().detach().numpy()\n",
    "                        if SAE_net == False and converted_net_forward == True:\n",
    "                            converted_spike_hidden[now_index:now_end_index] = converted_inner_inf.cpu().detach().numpy()\n",
    "                        now_index += encoder_batch\n",
    "                        if (now_index >= len(spike)):\n",
    "                            break\n",
    "                    \n",
    "                spike_id = np.zeros(len(spike))\n",
    "                distance_sm = np.zeros(num_cluster)\n",
    "                tau = np.zeros(num_cluster)\n",
    "                \n",
    "                plot_tau = []\n",
    "                plot_denominator = []\n",
    "                plot_m = []\n",
    "                plot_max_tau = []\n",
    "                for spike_index in range(len(spike)): \n",
    "                    for q in range(num_cluster):\n",
    "                        tau[q] = np.dot(spike_hidden[spike_index, :], Cluster[q, :]) # 이거 l2norm 거쳐서 나온 거니까 분모 1임.\n",
    "                        denominator =  np.linalg.norm(spike_hidden[spike_index, :])*np.linalg.norm(Cluster[q, :]) + 1e-12\n",
    "                        plot_denominator.append(denominator)\n",
    "                        if 'SAE' in net.module.__class__.__name__: # AE 때는 l2norm거쳐서 나와서 괜찮음\n",
    "                            tau[q] = tau[q] / denominator\n",
    "\n",
    "                        plot_tau.append(tau[q])\n",
    "\n",
    "                    # for i in range(num_cluster): # l2 distance\n",
    "                    #     distance_sm[i] = np.sum(np.power(np.abs(Cluster[i] - spike_hidden[spike_index, :]), 2))\n",
    "                    distance_sm = np.sum(np.power(np.abs(Cluster - spike_hidden[spike_index, :]), 2), axis=1)\n",
    "\n",
    "                    m = np.argmin(distance_sm)\n",
    "                    plot_m.append(m)\n",
    "                    spike_id[spike_index] = m + 1\n",
    "                    # print(spike_tot[ds], spike_index,np.max(tau))\n",
    "                    plot_max_tau.append(np.max(tau))\n",
    "                    if(np.max(tau) >= cos_thr[ds] and spike_index < training_cycle): # 원래 1400 아니냐?\n",
    "                        Cluster[m] = (Cluster[m] * 15 + spike_hidden[spike_index, :])/16\n",
    "\n",
    "\n",
    "                \n",
    "                origin_kmeans_accuracy = cluster_spikes_with_accuracy_torch(features= spike, true_labels=label-1, n_clusters=3, init_point=None)\n",
    "                kmeans_accuracy = cluster_spikes_with_accuracy_torch(features= torch.tensor(spike_hidden).to(device), true_labels=label-1, n_clusters=3, init_point=None)\n",
    "                k_means_bin_origin_feature.append(origin_kmeans_accuracy)\n",
    "                k_means_bin.append(kmeans_accuracy)\n",
    "                if SAE_net == False and converted_net_forward == True:\n",
    "                    converted_kmeans_accuracy = cluster_spikes_with_accuracy_torch(features= torch.tensor(converted_spike_hidden).to(device), true_labels=label-1, n_clusters=3, init_point=None)\n",
    "                    converted_k_means_bin.append(converted_kmeans_accuracy)\n",
    "                # sklearn kmeans인데 cpu많이먹어서 버림.\n",
    "                # origin_kmeans_accuracy = cluster_spikes_with_accuracy(features= spike.cpu().detach().numpy(), true_labels=label-1, n_clusters=3, init_point=None)\n",
    "                # kmeans_accuracy = cluster_spikes_with_accuracy(features= spike_hidden, true_labels=label-1, n_clusters=3, init_point=None)\n",
    "                # k_means_bin_origin_feature.append(origin_kmeans_accuracy)\n",
    "                # k_means_bin.append(kmeans_accuracy)\n",
    "                # if SAE_net == False and converted_net_forward == True:\n",
    "                #     converted_kmeans_accuracy = cluster_spikes_with_accuracy(features= converted_spike_hidden, true_labels=label-1, n_clusters=3, init_point=None)\n",
    "                #     converted_k_means_bin.append(converted_kmeans_accuracy)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "                # print('Cluster',Cluster)\n",
    "                # print('spike_id', spike_id)\n",
    "\n",
    "                # spike id 분포 확인하기\n",
    "                # unique_elements, counts = np.unique(spike_id, return_counts=True)\n",
    "                # print(\"Unique elements:\", unique_elements)\n",
    "                # print(\"Counts:\", counts)\n",
    "\n",
    "                cluster_accuracy_during_training_cycle = np.zeros(math.factorial(num_cluster))\n",
    "                cluster_accuracy_post_training_cycle = np.zeros(math.factorial(num_cluster))\n",
    "                cluster_accuracy_total = np.zeros(math.factorial(num_cluster))\n",
    "                \n",
    "                label_converter_ground = list(range(1, num_cluster + 1)) # [1, 2, 3, 4] 생성\n",
    "                label_converter_permutations = list(itertools.permutations(label_converter_ground)) # 모든 순열 구하기\n",
    "                perm_i = 0\n",
    "                perm_start_time = time.time() \n",
    "                for perm in label_converter_permutations:\n",
    "                    label_converter = list(perm)\n",
    "                    # print(label_converter)\n",
    "                    correct_during_training_cycle = 0\n",
    "                    correct_post_training_cycle = 0\n",
    "\n",
    "                    assert len(spike_id) == len(label), 'spike_id랑 label 길이 같아야 됨.'\n",
    "                    for i in range(len(spike_id)):\n",
    "                        if(label_converter[int(spike_id[i]-1)] == label[i]):\n",
    "                            if i < training_cycle:\n",
    "                                correct_during_training_cycle += 1\n",
    "                            else:\n",
    "                                correct_post_training_cycle += 1\n",
    "\n",
    "                    cluster_accuracy_during_training_cycle[perm_i] = correct_during_training_cycle/training_cycle\n",
    "                    cluster_accuracy_post_training_cycle[perm_i] = correct_post_training_cycle/(len(spike_id)-training_cycle)\n",
    "                    cluster_accuracy_total[perm_i] = (correct_during_training_cycle+correct_post_training_cycle)/(len(spike_id))\n",
    "                    perm_i += 1\n",
    "                # print(f\"perm 실행 시간: {time.time()-perm_start_time:.3f}초\")\n",
    "                \n",
    "                cluster_accuracy_during_training_cycle_all_dataset[ds] = np.max(cluster_accuracy_during_training_cycle)\n",
    "                cluster_accuracy_post_training_cycle_all_dataset[ds] = cluster_accuracy_post_training_cycle[np.argmax(cluster_accuracy_during_training_cycle)]\n",
    "                cluster_accuracy_total_all_dataset[ds] = cluster_accuracy_total[np.argmax(cluster_accuracy_during_training_cycle)]\n",
    "                # plot_distributions(ds, plot_tau, plot_denominator, plot_m, plot_max_tau, cos_thr[ds],\n",
    "                #                    cluster_accuracy_during_training_cycle_all_dataset[ds], cluster_accuracy_post_training_cycle_all_dataset[ds], cluster_accuracy_total_all_dataset[ds])\n",
    "            print(f'k_means origin feature average accuracy : {100*sum(k_means_bin_origin_feature)/(len(k_means_bin_origin_feature)+1e-12):.8f}%, total {k_means_bin_origin_feature}')\n",
    "            \n",
    "            mean_cluster_accuracy_during_training_cycle_all_dataset = np.mean(cluster_accuracy_during_training_cycle_all_dataset)\n",
    "            mean_cluster_accuracy_post_training_cycle_all_dataset = np.mean(cluster_accuracy_post_training_cycle_all_dataset)\n",
    "            mean_cluster_accuracy_total_all_dataset = np.mean(cluster_accuracy_total_all_dataset)\n",
    "            \n",
    "            if SAE_net == False and converted_net_forward == True:\n",
    "                converted_k_means_acc = 100*sum(converted_k_means_bin)/len(converted_k_means_bin)\n",
    "                print(f'converted_kmeans average accuracy : {converted_k_means_acc:.8f}%, total {converted_k_means_bin}')\n",
    "            k_means_acc = 100*sum(k_means_bin)/len(k_means_bin)\n",
    "            if k_means_acc > k_means_acc_best:\n",
    "                # torch.save(net, f\"net_save/save_now_net_{current_time}.pth\")\n",
    "                torch.save(net.module.state_dict(), f\"net_save/save_now_net_{current_time}.pth\")\n",
    "                print('save model')\n",
    "                best_mean_cluster_accuracy_post_training_cycle_all_dataset = mean_cluster_accuracy_post_training_cycle_all_dataset\n",
    "            \n",
    "            k_means_acc_best = max(k_means_acc_best, k_means_acc)\n",
    "            print(f'kmeans average accuracy best : {k_means_acc_best:.2f}%, kmeans average accuracy : {k_means_acc:.8f}%, total {k_means_bin}')\n",
    "            print(f'cluster_accuracy_post_training_cycle_all_dataset : {cluster_accuracy_post_training_cycle_all_dataset}')\n",
    "\n",
    "            \n",
    "            mean_cluster_accuracy_during_training_cycle_all_dataset_history.append((epoch, mean_cluster_accuracy_during_training_cycle_all_dataset*100))\n",
    "            mean_cluster_accuracy_post_training_cycle_all_dataset_history.append((epoch, mean_cluster_accuracy_post_training_cycle_all_dataset*100))\n",
    "            mean_cluster_accuracy_total_all_dataset_history.append((epoch, mean_cluster_accuracy_total_all_dataset*100))\n",
    "            print(f\"mean_cluster_accuracy_during_training_cycle : {mean_cluster_accuracy_during_training_cycle_all_dataset*100:.2f}%, post_traincycle_acc : {mean_cluster_accuracy_post_training_cycle_all_dataset*100:.2f}%, total_acc : {mean_cluster_accuracy_total_all_dataset*100:.8f}%\")\n",
    "\n",
    "            # kmeans accuracy기준으로 좋은 거 저장할 거임\n",
    "            # if mean_cluster_accuracy_post_training_cycle_all_dataset > best_mean_cluster_accuracy_post_training_cycle_all_dataset:\n",
    "            #     # torch.save(net, f\"net_save/save_now_net_{current_time}.pth\")\n",
    "            #     torch.save(net.module.state_dict(), f\"net_save/save_now_net_{current_time}.pth\")\n",
    "            #     print('save model')\n",
    "            #     best_mean_cluster_accuracy_post_training_cycle_all_dataset = mean_cluster_accuracy_post_training_cycle_all_dataset\n",
    "            print(f\"best_mean_cluster_accuracy_post_training_cycle_all_dataset : {best_mean_cluster_accuracy_post_training_cycle_all_dataset*100:.2f}%\")\n",
    "            print(f\"accuracy_check 실행 시간: {time.time()-accuracy_check_start_time:.3f}초\")\n",
    "\n",
    "        wandb.log({\"avg_loss\": avg_loss})\n",
    "        wandb.log({\"mean_cluster_accuracy_post_training_cycle_all_dataset\": mean_cluster_accuracy_post_training_cycle_all_dataset})\n",
    "        wandb.log({\"best_mean_cluster_accuracy_post_training_cycle_all_dataset\": best_mean_cluster_accuracy_post_training_cycle_all_dataset})\n",
    "        wandb.log({\"best_mean_cluster_accuracy_post_training_cycle_all_dataset2\": best_mean_cluster_accuracy_post_training_cycle_all_dataset})\n",
    "        wandb.log({\"k_means_acc\": k_means_acc})\n",
    "        wandb.log({\"k_means_acc_best\": k_means_acc_best})\n",
    "        wandb.log({\"converted_k_means_acc\": converted_k_means_acc})\n",
    "\n",
    "\n",
    "        # 저장\n",
    "        with open(f\"result_save/cluster_accuracy_history_{current_time}.pkl\", \"wb\") as f:\n",
    "            pickle.dump({\n",
    "                \"loss_history\": loss_history,\n",
    "                \"mean_cluster_accuracy_during_training_cycle_all_dataset_history\": mean_cluster_accuracy_during_training_cycle_all_dataset_history,\n",
    "                \"mean_cluster_accuracy_post_training_cycle_all_dataset_history\": mean_cluster_accuracy_post_training_cycle_all_dataset_history,\n",
    "                \"mean_cluster_accuracy_total_all_dataset_history\": mean_cluster_accuracy_total_all_dataset_history,\n",
    "            }, f)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# gpu = '4'\n",
    "# Conv_net = True # True False\n",
    "# SAE_net = True # True False\n",
    "\n",
    "# # hyperparameter\n",
    "# dataset_num = 16\n",
    "# spike_length = 50 # coarse_com_mode일 때는 time step이 됨.\n",
    "# num_cluster = 4  # 클러스터 수 설정 # 논문엔 4개라는데 여기서는 3개로 했네\n",
    "# training_cycle = 1400 #1400 2400 # 그 초기 몇개까지만 cluster update할지\n",
    "\n",
    "\n",
    "# batch_size = 32\n",
    "# max_epoch = 10000\n",
    "# learning_rate = 0.0001\n",
    "# normalize_on = True # True or False # 0부터1까지 normalize\n",
    "# need_bias = False\n",
    "# # first_layer_no_train = False\n",
    "# lif_add_at_first = False\n",
    "# my_seed = 42\n",
    "\n",
    "# TIME = 50 # SAE일 때만 유효. coarse_com_mode일 때는 level_num이 됨. 즉 feature 개수.\n",
    "# v_decay = 0.25 # -cor\n",
    "# v_threshold = 0.25 # -cor\n",
    "# v_reset = 10000.0 # -cor # 10000이상 일 시 hard reset\n",
    "# BPTT_on = True # +cor # True False\n",
    "\n",
    "# SAE_hidden_nomean = True # True False\n",
    "\n",
    "# current_time = datetime.datetime.now().strftime(\"%Y%m%d_%H%M%S\") + f\"_{str(int(datetime.datetime.now().microsecond / 1000)).zfill(3)}\"\n",
    "\n",
    "# optimizer = 'SGD' #'Adam', 'SGD' # 둘다 준수함. loss 줄이는 거는 adam이 좋긴한데, cluster accuracy는 비슷함.\n",
    "\n",
    "# coarse_com_mode = True # True False\n",
    "# coarse_com_config = (1.0, -0.0) # (max, min) (2.0, -2.0) (3.0, -3.0)\n",
    "\n",
    "# sae_l2_norm_bridge = True # True False\n",
    "# sae_lif_bridge = False # True False\n",
    "\n",
    "# accuracy_check_epoch_term = 1\n",
    "\n",
    "# lif_add_at_last = False # True False\n",
    "\n",
    "# two_channel_input = False # True False\n",
    "\n",
    "# lateral_feature_num = 4\n",
    "\n",
    "# lc_adc_on = False # True False\n",
    "\n",
    "# converted_net_forward = False # True False\n",
    "\n",
    "# pretrained_net = None\n",
    "# # pretrained_net = '/home/bhkim003/github_folder/ByeonghyeonKim/my_snn/net_save/save_now_net_중요_20250110_203117_390.pth'\n",
    "# # pretrained_net = '/home/bhkim003/github_folder/ByeonghyeonKim/my_snn/net_save/save_now_net_중요_20250113_134126_881_이거_94나오는거.pth'\n",
    "# # pretrained_net =  '/home/bhkim003/github_folder/ByeonghyeonKim/my_snn/net_save/save_now_net_20250205_184901_132.pth'\n",
    "# # pretrained_net =  '/home/bhkim003/github_folder/ByeonghyeonKim/my_snn/net_save/save_now_net_20250205_185051_883.pth'\n",
    "\n",
    "# vth_mul_on = False # True False\n",
    "# batch_norm_on = False # True False\n",
    "\n",
    "# l2_norm_loss_weight = 0 #0.0001 #0.1 #  0 # 0초과면 작동\n",
    "\n",
    "# QCFS_neuron_on = False # True False\n",
    "\n",
    "# quantize_level_num = 0 # 0이면 quantize 안함. 1이상이면 그 수만큼 quantize함. # normalize_on 켜져야됨. 음수면 0~1norm안하고 quant함\n",
    "\n",
    "# fusion_net = True # True False # SAE_net False, Conv_net True로 해라. TIME 적절하게 설정해주고.\n",
    "# repeat_coding = False # True False #fusion_net에서 쓰이는 거임 # True면 repeat, False면 rate coding.\n",
    "\n",
    "# sae_relu_on = False # True False\n",
    "\n",
    "# conv1d_scaling = False # True False # conv1d때매 norm하고 (level_num-3)/level_num 곱해줌 # Conv_net and coarse_com_mode and normalize_on\n",
    "\n",
    "# wandb.init(project= f'spike_sorting just run',save_code=False)\n",
    "\n",
    "\n",
    "# cluster_train_system( \n",
    "#     gpu = gpu,\n",
    "#     Conv_net = Conv_net,\n",
    "#     SAE_net = SAE_net,\n",
    "\n",
    "#     # hyperparameter\n",
    "#     dataset_num = dataset_num,\n",
    "#     spike_length = spike_length,\n",
    "#     num_cluster = num_cluster,  # 클러스터 수 설정 # 논문엔 4개라는데 여기서는 3개로 했네\n",
    "#     training_cycle = training_cycle, # 그 초기 몇개까지만 cluster update할지\n",
    "\n",
    "\n",
    "#     batch_size = batch_size,\n",
    "#     max_epoch = max_epoch,\n",
    "#     learning_rate = learning_rate,\n",
    "#     normalize_on = normalize_on, # True or False #이거 안 씀 # 이거 별로 안 좋은 normalize같음 # 쓸 거면 다른 거 써라.\n",
    "#     need_bias = need_bias,\n",
    "#     # first_layer_no_train = False\n",
    "#     lif_add_at_first = lif_add_at_first,\n",
    "#     my_seed = my_seed,\n",
    "\n",
    "#     TIME = TIME, # SAE일 때만 유효\n",
    "#     v_decay = v_decay,\n",
    "#     v_threshold = v_threshold,\n",
    "#     v_reset = v_reset, # 10000이상 일 시 hard reset\n",
    "#     BPTT_on = BPTT_on,\n",
    "\n",
    "#     SAE_hidden_nomean = SAE_hidden_nomean,\n",
    "    \n",
    "#     current_time = current_time,\n",
    "\n",
    "#     optimizer = optimizer, #'Adam', 'SGD'\n",
    "\n",
    "#     coarse_com_mode = coarse_com_mode,\n",
    "#     coarse_com_config = coarse_com_config, # (max, min)\n",
    "\n",
    "    \n",
    "#     sae_l2_norm_bridge = sae_l2_norm_bridge,\n",
    "#     sae_lif_bridge = sae_lif_bridge,\n",
    "\n",
    "#     accuracy_check_epoch_term = accuracy_check_epoch_term,\n",
    "    \n",
    "#     lif_add_at_last = lif_add_at_last,\n",
    "\n",
    "#     two_channel_input = two_channel_input,\n",
    "\n",
    "#     lateral_feature_num = lateral_feature_num,\n",
    "\n",
    "#     lc_adc_on = lc_adc_on, \n",
    "\n",
    "#     converted_net_forward = converted_net_forward,\n",
    "\n",
    "#     pretrained_net = pretrained_net,\n",
    "\n",
    "#     vth_mul_on = vth_mul_on,\n",
    "#     batch_norm_on = batch_norm_on,\n",
    "\n",
    "#     l2_norm_loss_weight = l2_norm_loss_weight,\n",
    "    \n",
    "#     QCFS_neuron_on = QCFS_neuron_on, # True False\n",
    "\n",
    "#     quantize_level_num = quantize_level_num,\n",
    "\n",
    "#     fusion_net = fusion_net, # True False\n",
    "#     repeat_coding = repeat_coding,\n",
    "\n",
    "#     sae_relu_on = sae_relu_on,\n",
    "\n",
    "#     conv1d_scaling = conv1d_scaling,\n",
    "#     )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Create sweep with ID: kyd50db7\n",
      "Sweep URL: https://wandb.ai/bhkim003-seoul-national-university/spike_sorting%20cluster_train_system/sweeps/kyd50db7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: g1st9mzw with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBPTT_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tConv_net: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tQCFS_neuron_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tSAE_hidden_nomean: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tSAE_net: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tTIME: 50\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \taccuracy_check_epoch_term: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_norm_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 32\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcoarse_com_config: [2, -2]\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcoarse_com_mode: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tconv1d_scaling: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tconverted_net_forward: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdataset_num: 16\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tfusion_net: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tl2_norm_loss_weight: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlateral_feature_num: 4\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlc_adc_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.0001\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_add_at_first: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_add_at_last: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmax_epoch: 20\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmy_seed: 42\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tneed_bias: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnormalize_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_cluster: 4\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: SGD\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tpretrained_net: None\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tquantize_level_num: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \trepeat_coding: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsae_l2_norm_bridge: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsae_lif_bridge: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsae_relu_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tspike_length: 50\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \ttraining_cycle: 1400\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \ttwo_channel_input: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tv_decay: 0.125\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tv_reset: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tv_threshold: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tvth_mul_on: False\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mbhkim003\u001b[0m (\u001b[33mbhkim003-seoul-national-university\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.19.6 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.17.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/nfs/home/bhkim003/github_folder/ByeonghyeonKim/my_snn/wandb/run-20250212_004753-g1st9mzw</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/bhkim003-seoul-national-university/spike_sorting%20cluster_train_system/runs/g1st9mzw' target=\"_blank\">cerulean-sweep-1</a></strong> to <a href='https://wandb.ai/bhkim003-seoul-national-university/spike_sorting%20cluster_train_system' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/bhkim003-seoul-national-university/spike_sorting%20cluster_train_system/sweeps/kyd50db7' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/spike_sorting%20cluster_train_system/sweeps/kyd50db7</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/bhkim003-seoul-national-university/spike_sorting%20cluster_train_system' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/spike_sorting%20cluster_train_system</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/bhkim003-seoul-national-university/spike_sorting%20cluster_train_system/sweeps/kyd50db7' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/spike_sorting%20cluster_train_system/sweeps/kyd50db7</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/bhkim003-seoul-national-university/spike_sorting%20cluster_train_system/runs/g1st9mzw' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/spike_sorting%20cluster_train_system/runs/g1st9mzw</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'Conv_net' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'SAE_net' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'dataset_num' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'spike_length' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'num_cluster' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'training_cycle' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'batch_size' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'max_epoch' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'learning_rate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'normalize_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'need_bias' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_add_at_first' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'my_seed' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'TIME' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'v_decay' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'v_threshold' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'v_reset' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BPTT_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'SAE_hidden_nomean' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'optimizer' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'coarse_com_mode' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'sae_l2_norm_bridge' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'sae_lif_bridge' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'accuracy_check_epoch_term' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_add_at_last' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'two_channel_input' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lateral_feature_num' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lc_adc_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'converted_net_forward' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'pretrained_net' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'vth_mul_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'batch_norm_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'l2_norm_loss_weight' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'QCFS_neuron_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'quantize_level_num' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'fusion_net' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'repeat_coding' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'sae_relu_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'conv1d_scaling' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'coarse_com_config' was locked by 'sweep' (ignored update).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'gpu': '3', 'Conv_net': True, 'SAE_net': True, 'dataset_num': 16, 'spike_length': 50, 'num_cluster': 4, 'training_cycle': 1400, 'batch_size': 32, 'max_epoch': 20, 'learning_rate': 0.0001, 'normalize_on': False, 'need_bias': False, 'lif_add_at_first': False, 'my_seed': 42, 'TIME': 50, 'v_decay': 0.125, 'v_threshold': 1, 'v_reset': 0, 'BPTT_on': False, 'SAE_hidden_nomean': True, 'current_time': '20250212_004800_459', 'optimizer': 'SGD', 'coarse_com_mode': True, 'sae_l2_norm_bridge': True, 'sae_lif_bridge': False, 'accuracy_check_epoch_term': 1, 'lif_add_at_last': False, 'two_channel_input': False, 'lateral_feature_num': 4, 'lc_adc_on': False, 'converted_net_forward': False, 'pretrained_net': None, 'vth_mul_on': False, 'batch_norm_on': False, 'l2_norm_loss_weight': 0, 'QCFS_neuron_on': False, 'quantize_level_num': 0, 'fusion_net': True, 'repeat_coding': False, 'sae_relu_on': False, 'conv1d_scaling': False, 'coarse_com_config': [2, -2]}\n",
      "cos_thr [0.95 0.95 0.95 0.95 0.95 0.95 0.95 0.85 0.95 0.9  0.8  0.95 0.95 0.95\n",
      " 0.95 0.8 ]\n",
      "conv length [50, 24, 11, 5]\n",
      "Total number of encoder parameters: 120672\n",
      "DataParallel(\n",
      "  (module): SAE_FUSION2_net_conv1(\n",
      "    (activation_function): LIF_layer()\n",
      "    (encoder): Sequential(\n",
      "      (0): SSBH_DimChanger_one_two()\n",
      "      (1): SSBH_DimChanger_for_one_two_coupling()\n",
      "      (2): Conv1d(1, 32, kernel_size=(3,), stride=(2,), bias=False)\n",
      "      (3): SSBH_DimChanger_for_one_two_decoupling()\n",
      "      (4): LIF_layer()\n",
      "      (5): SSBH_DimChanger_for_one_two_coupling()\n",
      "      (6): Conv1d(32, 64, kernel_size=(3,), stride=(2,), bias=False)\n",
      "      (7): SSBH_DimChanger_for_one_two_decoupling()\n",
      "      (8): LIF_layer()\n",
      "      (9): SSBH_DimChanger_for_one_two_coupling()\n",
      "      (10): Conv1d(64, 96, kernel_size=(3,), stride=(2,), bias=False)\n",
      "      (11): SSBH_DimChanger_for_one_two_decoupling()\n",
      "      (12): LIF_layer()\n",
      "      (13): SSBH_DimChanger_for_one_two_coupling()\n",
      "      (14): SSBH_DimChanger_for_fc()\n",
      "      (15): SSBH_DimChanger_for_one_two_decoupling()\n",
      "      (16): SSBH_DimChanger_one_two()\n",
      "      (17): SSBH_DimChanger_for_two_three_coupling()\n",
      "      (18): Linear(in_features=24000, out_features=4, bias=False)\n",
      "      (19): SSBH_L2NormLayer()\n",
      "    )\n",
      "    (decoder): Sequential(\n",
      "      (0): Linear(in_features=4, out_features=480, bias=False)\n",
      "      (1): ReLU()\n",
      "      (2): SSBH_DimChanger_for_conv1()\n",
      "      (3): ConvTranspose1d(96, 64, kernel_size=(3,), stride=(2,), bias=False)\n",
      "      (4): ReLU()\n",
      "      (5): ConvTranspose1d(64, 32, kernel_size=(3,), stride=(2,), output_padding=(1,), bias=False)\n",
      "      (6): ReLU()\n",
      "      (7): ConvTranspose1d(32, 1, kernel_size=(3,), stride=(2,), output_padding=(1,), bias=False)\n",
      "    )\n",
      "  )\n",
      ")\n",
      "Device: cuda\n",
      "\n",
      "Start Training, current_time = 20250212_004800_459\n",
      "\n",
      "\n",
      "epoch-0 loss : 0.60153080, loss_normal : 0.14977584, loss_coarse : 0.06806728, min_loss : 0.60153080, min_loss_normal : 0.14977584, min_loss_coarse : 0.06806728, wrong_element_sum : 13068918.00000000, same_data : 0.00%\n",
      "ae train 실행 시간: 83.443초, 전체 시작 시간 20250212_004800_459\n",
      "\n",
      "epoch-0 accuracy check\n",
      "k_means origin feature average accuracy : 87.32910910%, total [0.9766647694934547, 0.9775695627484384, 0.9746908254242163, 0.9645941278065631, 0.9607038123167155, 0.9434659090909091, 0.8560539431251832, 0.6951219512195121, 0.973100798108188, 0.9364849187935035, 0.8338133640552995, 0.6833626244874048, 0.9565992865636147, 0.9246100519930676, 0.7389534883720931, 0.5768680217578013]\n",
      "save model\n",
      "kmeans average accuracy best : 34.22%, kmeans average accuracy : 34.22488434%, total [0.3392145702902675, 0.35122089721749006, 0.34167385677308026, 0.34484743811168683, 0.34222873900293255, 0.34488636363636366, 0.346232776311932, 0.3369256948383437, 0.3414129470883831, 0.3375870069605568, 0.33755760368663595, 0.3453427065026362, 0.3373959571938169, 0.34286539572501445, 0.3444767441860465, 0.34211279702261665]\n",
      "cluster_accuracy_post_training_cycle_all_dataset : [0.33301798 0.35815269 0.31872894 0.32256509 0.33930348 0.32169811\n",
      " 0.34957732 0.33678269 0.34140192 0.3203125  0.33638996 0.33018868\n",
      " 0.33095723 0.3457808  0.33823529 0.33922599]\n",
      "mean_cluster_accuracy_during_training_cycle : 34.14%, post_traincycle_acc : 33.51%, total_acc : 33.76835706%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 33.51%\n",
      "accuracy_check 실행 시간: 111.868초\n",
      "\n",
      "\n",
      "epoch-1 loss : 0.60153080, loss_normal : 0.14977584, loss_coarse : 0.06806728, min_loss : 0.60153080, min_loss_normal : 0.14977584, min_loss_coarse : 0.06806728, wrong_element_sum : 13068918.00000000, same_data : 0.00%\n",
      "ae train 실행 시간: 93.244초, 전체 시작 시간 20250212_004800_459\n",
      "\n",
      "epoch-1 accuracy check\n",
      "k_means origin feature average accuracy : 87.36864987%, total [0.9766647694934547, 0.9775695627484384, 0.9746908254242163, 0.9645941278065631, 0.9607038123167155, 0.9434659090909091, 0.8560539431251832, 0.6951219512195121, 0.973100798108188, 0.9364849187935035, 0.8341013824884793, 0.6839484475688342, 0.9565992865636147, 0.9246100519930676, 0.7398255813953488, 0.5814486115087317]\n",
      "kmeans average accuracy best : 34.22%, kmeans average accuracy : 34.22488434%, total [0.3392145702902675, 0.35122089721749006, 0.34167385677308026, 0.34484743811168683, 0.34222873900293255, 0.34488636363636366, 0.346232776311932, 0.3369256948383437, 0.3414129470883831, 0.3375870069605568, 0.33755760368663595, 0.3453427065026362, 0.3373959571938169, 0.34286539572501445, 0.3444767441860465, 0.34211279702261665]\n",
      "cluster_accuracy_post_training_cycle_all_dataset : [0.33301798 0.35815269 0.31872894 0.32256509 0.33930348 0.32169811\n",
      " 0.34957732 0.33678269 0.34140192 0.3203125  0.33638996 0.33018868\n",
      " 0.33095723 0.3457808  0.33823529 0.33922599]\n",
      "mean_cluster_accuracy_during_training_cycle : 34.14%, post_traincycle_acc : 33.51%, total_acc : 33.76835706%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 33.51%\n",
      "accuracy_check 실행 시간: 147.045초\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Sweep code\n",
    "\n",
    "\n",
    "from unittest import TextTestRunner\n",
    "\n",
    "\n",
    "unique_name_hyper = 'cluster_train_system'\n",
    "# run_name = 'spike_sorting'\n",
    "sweep_start_time =  datetime.datetime.now().strftime(\"%Y%m%d_%H%M%S\") + f\"_{str(int(datetime.datetime.now().microsecond / 1000)).zfill(3)}\"\n",
    "sweep_configuration = {\n",
    "    'method': 'bayes', # 'random', 'bayes'\n",
    "    'name': f'spike_sorting_{sweep_start_time}',\n",
    "    'metric': {'goal': 'maximize', 'name': 'k_means_acc_best'},\n",
    "    'parameters': \n",
    "    {\n",
    "        # \"gpu\": {\"values\": ['1']},  # 이건 sweep parameter아님. hyper_iter에서 직접 설정\n",
    "        \"Conv_net\": {\"values\": [True]}, \n",
    "        \"SAE_net\": {\"values\": [True]}, \n",
    "\n",
    "        \"dataset_num\": {\"values\": [16]}, \n",
    "        \"spike_length\": {\"values\": [50]},  \n",
    "        \"num_cluster\": {\"values\": [4]}, \n",
    "        \"training_cycle\": {\"values\": [1400]}, # [1400, 2400]\n",
    "\n",
    "        \"batch_size\": {\"values\": [32]}, \n",
    "        \"max_epoch\": {\"values\": [20]}, \n",
    "        \"learning_rate\": {\"values\": [0.001, 0.0001]},\n",
    "        \"normalize_on\": {\"values\": [False]},\n",
    "        \"need_bias\": {\"values\": [False]}, # [True, False]\n",
    "\n",
    "        \"lif_add_at_first\": {\"values\": [False]}, # [True, False]\n",
    "        \"my_seed\": {\"values\": [42]}, \n",
    "\n",
    "        \"TIME\": {\"values\": [50]}, #  [4,6,8,10]\n",
    "        \"v_decay\": {\"values\": [0.125, 0.25,0.50,0.75,1.0]}, # [0.25,0.50,0.75]\n",
    "        \"v_threshold\": {\"values\": [0.125, 0.25, 0.50, 0.75, 0.875, 1.0]}, # [0.25,0.50,0.75]\n",
    "        \"v_reset\": {\"values\": [0.0, 10000.0]},  # [0.0, 10000.0]\n",
    "        \"BPTT_on\": {\"values\": [True, False]},  # [True, False]\n",
    "\n",
    "        \"SAE_hidden_nomean\": {\"values\": [True]}, # [True, False]\n",
    "\n",
    "        # \"current_time\": {\"values\": [current_time]} #밑에서 직접설정됨.\n",
    "\n",
    "        \"optimizer\": {\"values\": ['Adam', 'SGD']}, # ['Adam', 'SGD']\n",
    "\n",
    "        \"coarse_com_mode\": {\"values\": [True]}, # [True, False]\n",
    "        \"coarse_com_config\": {\"values\": [(2.0, -2.0),(2.7,-2.0)]}, # ['Adam', 'SGD']\n",
    "\n",
    "        \"sae_l2_norm_bridge\": {\"values\": [True]}, # [True, False]\n",
    "        \"sae_lif_bridge\": {\"values\": [False]}, # [False, True]\n",
    "        \n",
    "        \"accuracy_check_epoch_term\": {\"values\": [1]}, \n",
    "\n",
    "        \"lif_add_at_last\": {\"values\": [False]},# [True, False]\n",
    "\n",
    "        \"two_channel_input\": {\"values\": [False]},# [True, False]\n",
    "\n",
    "        \"lateral_feature_num\": {\"values\": [4]},# [True, False]\n",
    "\n",
    "        \"lc_adc_on\": {\"values\": [False]},# [True, False]\n",
    "        \n",
    "        \"converted_net_forward\": {\"values\": [False]},# [True, False]\n",
    "\n",
    "        \"pretrained_net\": {\"values\": [None]},# [None]\n",
    "\n",
    "        \"vth_mul_on\": {\"values\": [False]},# [True, False]\n",
    "        \"batch_norm_on\": {\"values\": [False]},# [True, False]\n",
    "\n",
    "        \"l2_norm_loss_weight\": {\"values\": [0]},\n",
    "\n",
    "        \"QCFS_neuron_on\": {\"values\": [False]},   # [True, False]\n",
    "\n",
    "        \"quantize_level_num\": {\"values\": [0]}, \n",
    "\n",
    "        \"fusion_net\": {\"values\": [True]}, \n",
    "        \"repeat_coding\": {\"values\": [False]}, \n",
    "\n",
    "        \"sae_relu_on\": {\"values\": [False]}, \n",
    "\n",
    "        \"conv1d_scaling\": {\"values\": [False]}, \n",
    "     }\n",
    "}\n",
    "\n",
    "\n",
    "def hyper_iter():\n",
    "    ### my_snn control board ########################\n",
    "    wandb.init(save_code = False)\n",
    "    gpu  =  '3'\n",
    "    Conv_net  =  wandb.config.Conv_net\n",
    "    SAE_net  =  wandb.config.SAE_net\n",
    "\n",
    "    dataset_num  =  wandb.config.dataset_num\n",
    "    spike_length  =  wandb.config.spike_length\n",
    "    num_cluster  =  wandb.config.num_cluster\n",
    "    training_cycle  =  wandb.config.training_cycle\n",
    "\n",
    "    batch_size  =  wandb.config.batch_size\n",
    "    max_epoch  =  wandb.config.max_epoch\n",
    "    learning_rate  =  wandb.config.learning_rate\n",
    "    normalize_on  =  wandb.config.normalize_on\n",
    "    need_bias  =  wandb.config.need_bias\n",
    "\n",
    "    lif_add_at_first  =  wandb.config.lif_add_at_first\n",
    "    my_seed  =  wandb.config.my_seed\n",
    "\n",
    "\n",
    "    TIME  =  wandb.config.TIME\n",
    "    v_decay  =  wandb.config.v_decay\n",
    "    v_threshold  =  wandb.config.v_threshold\n",
    "    v_reset  =  wandb.config.v_reset\n",
    "    BPTT_on  =  wandb.config.BPTT_on\n",
    "\n",
    "    SAE_hidden_nomean  =  wandb.config.SAE_hidden_nomean\n",
    "    \n",
    "    current_time =  datetime.datetime.now().strftime(\"%Y%m%d_%H%M%S\") + f\"_{str(int(datetime.datetime.now().microsecond / 1000)).zfill(3)}\"\n",
    "\n",
    "    optimizer  =  wandb.config.optimizer\n",
    "\n",
    "    coarse_com_mode = wandb.config.coarse_com_mode\n",
    "    coarse_com_config = wandb.config.coarse_com_config # (max, min)\n",
    "\n",
    "    sae_l2_norm_bridge = wandb.config.sae_l2_norm_bridge\n",
    "    sae_lif_bridge = wandb.config.sae_lif_bridge\n",
    "\n",
    "    accuracy_check_epoch_term = wandb.config.accuracy_check_epoch_term\n",
    "\n",
    "    lif_add_at_last = wandb.config.lif_add_at_last\n",
    "\n",
    "    two_channel_input = wandb.config.two_channel_input\n",
    "\n",
    "    lateral_feature_num = wandb.config.lateral_feature_num\n",
    "\n",
    "    lc_adc_on = wandb.config.lc_adc_on\n",
    "\n",
    "    converted_net_forward = wandb.config.converted_net_forward\n",
    "\n",
    "    pretrained_net = wandb.config.pretrained_net\n",
    "\n",
    "    vth_mul_on = wandb.config.vth_mul_on\n",
    "    batch_norm_on = wandb.config.batch_norm_on\n",
    "\n",
    "    l2_norm_loss_weight = wandb.config.l2_norm_loss_weight\n",
    "\n",
    "    QCFS_neuron_on = wandb.config.QCFS_neuron_on\n",
    "\n",
    "    quantize_level_num = wandb.config.quantize_level_num\n",
    "\n",
    "    fusion_net = wandb.config.fusion_net\n",
    "    repeat_coding = wandb.config.repeat_coding\n",
    "\n",
    "    sae_relu_on = wandb.config.sae_relu_on\n",
    "\n",
    "    conv1d_scaling = wandb.config.conv1d_scaling\n",
    "\n",
    "    cluster_train_system( \n",
    "        gpu = gpu,\n",
    "        Conv_net = Conv_net,\n",
    "        SAE_net = SAE_net,\n",
    "\n",
    "        # hyperparameter\n",
    "        dataset_num = dataset_num,\n",
    "        spike_length = spike_length,\n",
    "        num_cluster = num_cluster,  # 클러스터 수 설정 # 논문엔 4개라는데 여기서는 3개로 했네\n",
    "        training_cycle = training_cycle, # 그 초기 몇개까지만 cluster update할지\n",
    "\n",
    "\n",
    "        batch_size = batch_size,\n",
    "        max_epoch = max_epoch,\n",
    "        learning_rate = learning_rate,\n",
    "        normalize_on = normalize_on, # True or False #이거 안 씀 # 이거 별로 안 좋은 normalize같음 # 쓸 거면 다른 거 써라.\n",
    "        need_bias = need_bias,\n",
    "        # first_layer_no_train = False\n",
    "        lif_add_at_first = lif_add_at_first,\n",
    "        my_seed = my_seed,\n",
    "\n",
    "        TIME = TIME, # SAE일 때만 유효\n",
    "        v_decay = v_decay,\n",
    "        v_threshold = v_threshold,\n",
    "        v_reset = v_reset, # 10000이상 일 시 hard reset\n",
    "        BPTT_on = BPTT_on,\n",
    "\n",
    "        SAE_hidden_nomean = SAE_hidden_nomean,\n",
    "\n",
    "        current_time = current_time,\n",
    "\n",
    "        optimizer = optimizer, #'Adam', 'SGD'\n",
    "\n",
    "        coarse_com_mode = coarse_com_mode,\n",
    "        coarse_com_config = coarse_com_config, # (max, min)\n",
    "        \n",
    "        sae_l2_norm_bridge = sae_l2_norm_bridge,\n",
    "        sae_lif_bridge = sae_lif_bridge,\n",
    "\n",
    "        accuracy_check_epoch_term = accuracy_check_epoch_term,\n",
    "\n",
    "        lif_add_at_last = lif_add_at_last,\n",
    "        \n",
    "        two_channel_input = two_channel_input,\n",
    "        \n",
    "        lateral_feature_num = lateral_feature_num,\n",
    "\n",
    "        lc_adc_on = lc_adc_on,\n",
    "\n",
    "        converted_net_forward = converted_net_forward,\n",
    "\n",
    "        pretrained_net = pretrained_net,\n",
    "\n",
    "        vth_mul_on = vth_mul_on,\n",
    "        batch_norm_on = batch_norm_on,\n",
    "\n",
    "        l2_norm_loss_weight = l2_norm_loss_weight,\n",
    "\n",
    "        QCFS_neuron_on = QCFS_neuron_on,\n",
    "\n",
    "        quantize_level_num = quantize_level_num,\n",
    "\n",
    "        fusion_net = fusion_net, \n",
    "        repeat_coding = repeat_coding, \n",
    "\n",
    "        sae_relu_on = sae_relu_on,\n",
    "\n",
    "        conv1d_scaling = conv1d_scaling,\n",
    "        )\n",
    "    \n",
    "# sweep_id = 'ygoj9jt4'\n",
    "sweep_id = wandb.sweep(sweep=sweep_configuration, project=f'spike_sorting {unique_name_hyper}')\n",
    "wandb.agent(sweep_id, function=hyper_iter, count=100000, project=f'spike_sorting {unique_name_hyper}')\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wandb.finish() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import matplotlib.pyplot as plt\n",
    "# from matplotlib.ticker import MaxNLocator\n",
    "# import pickle\n",
    "# import json\n",
    "\n",
    "# # current_time = '20250102_225243_972'\n",
    "\n",
    "# with open(f\"result_save/cluster_accuracy_history_{current_time}.pkl\", \"rb\") as f:\n",
    "#     data = pickle.load(f)\n",
    "\n",
    "\n",
    "# # JSON으로 저장\n",
    "# with open(f\"result_save/cluster_accuracy_history_{current_time}.json\", 'r') as f:\n",
    "#     loaded_hyperparameters = json.load(f)\n",
    "\n",
    "# loss_history = data['loss_history']\n",
    "# mean_cluster_accuracy_during_training_cycle_all_dataset_history = data['mean_cluster_accuracy_during_training_cycle_all_dataset_history']\n",
    "# mean_cluster_accuracy_post_training_cycle_all_dataset_history = data['mean_cluster_accuracy_post_training_cycle_all_dataset_history']\n",
    "# mean_cluster_accuracy_total_all_dataset_history = data['mean_cluster_accuracy_total_all_dataset_history']\n",
    "# print(data)\n",
    "# max_acc = 0\n",
    "# for i in mean_cluster_accuracy_post_training_cycle_all_dataset_history:\n",
    "#     if i[1] > max_acc:\n",
    "#         max_acc = i[1]\n",
    "\n",
    "# # 설정 정보 제목 작성\n",
    "# title = (\n",
    "#     f\"Dataset Num: {loaded_hyperparameters['dataset_num']}, Conv {loaded_hyperparameters['Conv_net']}, SAE {loaded_hyperparameters['SAE_net']}, Current time {loaded_hyperparameters['current_time']}, Spike Length: {loaded_hyperparameters['spike_length']}, Num Cluster: {loaded_hyperparameters['num_cluster']}, \"\n",
    "#     f\"Training Cycle: {loaded_hyperparameters['training_cycle']}, Batch Size: {loaded_hyperparameters['batch_size']}, Max Epoch: {loaded_hyperparameters['max_epoch']}, \\n\"\n",
    "#     f\"Learning Rate: {loaded_hyperparameters['learning_rate']}, Input Normalize: {loaded_hyperparameters['normalize_on']}, Need Bias: {loaded_hyperparameters['need_bias']}, \"\n",
    "#     f\"LIF Add at First: {loaded_hyperparameters['lif_add_at_first']}, TIME: {loaded_hyperparameters['TIME']}, Seed: {loaded_hyperparameters['my_seed']}, Best ACC: {max_acc:.2f}%\"\n",
    "# )\n",
    "\n",
    "# # 데이터 리스트와 라벨 설정 (Loss 제외)\n",
    "# data_list = [\n",
    "#     (\"Mean Cluster Accuracy (During Training Cycle)\", mean_cluster_accuracy_during_training_cycle_all_dataset_history),\n",
    "#     (\"Mean Cluster Accuracy (Post Training Cycle)\", mean_cluster_accuracy_post_training_cycle_all_dataset_history),\n",
    "#     (\"Mean Cluster Accuracy (Total)\", mean_cluster_accuracy_total_all_dataset_history),\n",
    "# ]\n",
    "\n",
    "# # 플롯 생성\n",
    "# fig, ax1 = plt.subplots(figsize=(12, 8))\n",
    "\n",
    "# # 첫 번째 y축: Accuracy 관련 데이터\n",
    "# for label, data in data_list:\n",
    "#     epochs, values = zip(*data)  # epoch, value 분리\n",
    "#     ax1.plot(epochs, values, label=label)\n",
    "\n",
    "# ax1.set_xlabel(\"Epoch\")\n",
    "# ax1.set_ylabel(\"Clurstering Accuracy [%]\", color=\"blue\")\n",
    "# ax1.tick_params(axis=\"y\", labelcolor=\"blue\")\n",
    "# ax1.legend(loc=\"center right\")\n",
    "# ax1.grid(True)\n",
    "\n",
    "# # x축을 정수만 표시하도록 설정\n",
    "# ax1.xaxis.set_major_locator(MaxNLocator(integer=True))\n",
    "\n",
    "# # 두 번째 y축: Loss History\n",
    "# ax2 = ax1.twinx()\n",
    "# epochs, values = zip(*loss_history)\n",
    "# ax2.plot(epochs, values, label=\"AE Loss History\", color=\"red\", linestyle=\"--\")\n",
    "# ax2.set_ylabel(\"Loss\", color=\"red\")\n",
    "# ax2.tick_params(axis=\"y\", labelcolor=\"red\")\n",
    "# ax2.legend(loc=\"center left\")\n",
    "\n",
    "# # 제목 추가\n",
    "# plt.title(title, fontsize=10)\n",
    "# plt.tight_layout()\n",
    "# plt.savefig(f'net_save/{current_time}', dpi=300, bbox_inches=\"tight\")  # dpi=300은 고해상도로 저장, bbox_inches=\"tight\"는 여백 최소화\n",
    "# plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# 데이터셋\n",
    "filename_for_plot = [\n",
    "    \"Easy1_noise05\", \"Easy1_noise10\", \"Easy1_noise15\", \"Easy1_noise20\",\n",
    "    \"Easy2_noise05\", \"Easy2_noise10\", \"Easy2_noise15\", \"Easy2_noise20\",\n",
    "    \"Difficult1_noise05\", \"Difficult1_noise10\", \"Difficult1_noise15\", \"Difficult1_noise20\",\n",
    "    \"Difficult2_noise05\", \"Difficult2_noise10\", \"Difficult2_noise15\", \"Difficult2_noise20\"\n",
    "]\n",
    "\n",
    "# Accuracy 데이터\n",
    "ANN_conv_accracy_set= [0.97935368, 0.97682709, 0.97028784, 0.96461825, 0.97524752, 0.95803571\n",
    ", 0.95746785, 0.92628774, 0.965412,  0.97805344, 0.94869403, 0.92110454\n",
    ", 0.96784232, 0.97551789, 0.91538462, 0.84446478]\n",
    "SNN_fc_accuracy_set = [0.97114475, 0.97643732, 0.84400578, 0.78977821, 0.96616915, 0.92830189\n",
    ", 0.86176032, 0.31984948, 0.80635401, 0.88769531, 0.61003861, 0.60377358\n",
    ", 0.9592668,  0.92870999, 0.78333333, 0.67271859]\n",
    "SNN_conv_accuracy_set = [0.97445601, 0.97737983, 0.97063072, 0.95998071, 0.96268657, 0.90566038\n",
    ", 0.82545997, 0.68391345, 0.96116994, 0.92138672, 0.80694981, 0.49602781\n",
    ", 0.83604888, 0.70611057, 0.69313725, 0.5819398 ]\n",
    "\n",
    "# 평균 계산\n",
    "average_ANN_conv = np.mean(ANN_conv_accracy_set)\n",
    "average_SNN_fc = np.mean(SNN_fc_accuracy_set)\n",
    "average_SNN_conv = np.mean(SNN_conv_accuracy_set)\n",
    "\n",
    "# 데이터 준비\n",
    "accuracies = np.array([ANN_conv_accracy_set, SNN_fc_accuracy_set, SNN_conv_accuracy_set])\n",
    "averages = np.array([average_ANN_conv, average_SNN_fc, average_SNN_conv])\n",
    "\n",
    "# 시각화\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "\n",
    "# 각 모델의 정확도 플롯\n",
    "ax.plot(accuracies[0], label='ANN Conv', marker='o', linestyle='-', color='blue')\n",
    "ax.plot(accuracies[1], label='SNN FC', marker='o', linestyle='-', color='green')\n",
    "ax.plot(accuracies[2], label='SNN Conv', marker='o', linestyle='-', color='red')\n",
    "\n",
    "# 평균값 플롯\n",
    "ax.axhline(y=average_ANN_conv, color='blue', linestyle='--', label=f'Average ANN Conv: {average_ANN_conv:.3f}')\n",
    "ax.axhline(y=average_SNN_fc, color='green', linestyle='--', label=f'Average SNN FC: {average_SNN_fc:.3f}')\n",
    "ax.axhline(y=average_SNN_conv, color='red', linestyle='--', label=f'Average SNN Conv: {average_SNN_conv:.3f}')\n",
    "\n",
    "# 레이블 추가\n",
    "ax.set_xticks(np.arange(len(filename_for_plot)))\n",
    "ax.set_xticklabels(filename_for_plot, rotation=45, ha='right')\n",
    "ax.set_ylabel('Accuracy')\n",
    "ax.set_title('Accuracy Comparison of Models on Datasets')\n",
    "ax.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import matplotlib.pyplot as plt\n",
    "import os  # 파일 경로 처리를 위한 모듈\n",
    "\n",
    "# CSV 파일 경로\n",
    "# csv_file_path = \"/home/bhkim003/github_folder/ByeonghyeonKim/my_snn/ae_test_deprecated/250115/sweep0_vth_mul.csv\" # vth_mul해서 sweep 돌린거\n",
    "csv_file_path = \"/home/bhkim003/github_folder/ByeonghyeonKim/my_snn/ae_test_deprecated/250115/sweep1.csv\"  #vth_mul안한거\n",
    "\n",
    "# 결과를 저장할 리스트\n",
    "tuple_list = []\n",
    "\n",
    "# CSV 파일 읽기\n",
    "with open(csv_file_path, 'r') as file:\n",
    "    reader = csv.DictReader(file)\n",
    "    for row in reader:\n",
    "        try:\n",
    "            # v_threshold, TIME, v_reset, converted_k_means_acc 값을 가져와 튜플로 변환\n",
    "            v_threshold = float(row[\"v_threshold\"])\n",
    "            time = int(row[\"TIME\"])\n",
    "            v_reset = int(row[\"v_reset\"])\n",
    "            converted_k_means_acc = float(row[\"converted_k_means_acc\"]) if row[\"converted_k_means_acc\"] else None\n",
    "\n",
    "            # 튜플 형태로 추가 (값이 None일 경우 처리할 수도 있음)\n",
    "            tuple_list.append((v_threshold, time, v_reset, converted_k_means_acc))\n",
    "        except ValueError as e:\n",
    "            print(f\"Error processing row {row}: {e}\")\n",
    "\n",
    "# 데이터를 TIME 기준으로 정렬\n",
    "tuple_list.sort(key=lambda x: x[1])  # TIME을 기준으로 오름차순 정렬\n",
    "\n",
    "# reset 방식에 따라 데이터를 나누기\n",
    "soft_reset = [t for t in tuple_list if t[2] == 0]\n",
    "hard_reset = [t for t in tuple_list if t[2] == 10000]\n",
    "\n",
    "# reset 방식과 v_threshold에 따라 색상 설정\n",
    "def plot_data(data, label_prefix, marker):\n",
    "    for v_threshold in [1.0]:  # v_threshold 기준으로 제한\n",
    "        filtered_data = [(t[1], t[3]) for t in data if t[0] == v_threshold]\n",
    "        if filtered_data:  # 해당 v_threshold 데이터가 있을 경우만 플롯\n",
    "            times, accuracies = zip(*filtered_data)  # x축(TIME), y축(converted_k_means_acc)\n",
    "            \n",
    "            plt.plot(\n",
    "                times,\n",
    "                accuracies,\n",
    "                marker,\n",
    "                label=f\"{label_prefix}, v_threshold={v_threshold}\",\n",
    "                linestyle=\"--\",\n",
    "            )\n",
    "            # 각 점에 accuracy 표시\n",
    "            for time, acc in filtered_data:\n",
    "                if acc == None:\n",
    "                    continue\n",
    "                plt.text(time, acc, f\"{acc:.2f}\", fontsize=8, ha=\"right\")\n",
    "\n",
    "# 그래프 초기화\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "# soft_reset (v_reset=0) 데이터 플롯\n",
    "plot_data(soft_reset, \"Soft Reset\", \"o\")\n",
    "\n",
    "# hard_reset (v_reset=10000) 데이터 플롯\n",
    "plot_data(hard_reset, \"Hard Reset\", \"x\")\n",
    "\n",
    "# baseline accuracy 가로선 추가\n",
    "baseline_accuracy = 94.43\n",
    "plt.axhline(y=baseline_accuracy, color=\"red\", linestyle=\"-\", label=f\"Baseline Accuracy ({baseline_accuracy}%)\")\n",
    "# baseline 텍스트 추가\n",
    "plt.text(\n",
    "    2000,  # x축 위치 (그래프 오른쪽 끝)\n",
    "    baseline_accuracy + 0.4,  # y축 위치 (baseline 위 약간)\n",
    "    f\"ANN Baseline ({baseline_accuracy}%)\",\n",
    "    color=\"red\",\n",
    "    fontsize=10,\n",
    "    ha=\"center\",\n",
    ")\n",
    "\n",
    "# CSV 파일 이름 가져오기\n",
    "csv_file_name = os.path.basename(csv_file_path)\n",
    "\n",
    "# 그래프 세부 설정\n",
    "plt.title(f\"Converted SNN K-Means Accuracy vs TIME STEP - {csv_file_name}\")\n",
    "plt.xlabel(\"TIME STEP\")\n",
    "plt.ylabel(\"Converted K-Means Accuracy [%]\")\n",
    "plt.legend(loc=\"lower right\")  # 범례를 오른쪽 아래로 이동\n",
    "plt.grid(True)\n",
    "\n",
    "# 그래프 출력\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aedat2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
