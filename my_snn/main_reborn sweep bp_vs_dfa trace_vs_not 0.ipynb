{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1572/3748606120.py:46: DeprecationWarning: The module snntorch.spikevision is deprecated. For loading neuromorphic datasets, we recommend using the Tonic project: https://github.com/neuromorphs/tonic\n",
      "  from snntorch.spikevision import spikedata\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x600 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "import argparse\n",
    "import torch\n",
    "import torch.nn as nn \n",
    "import torch.nn.functional as F\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.optim as optim\n",
    "import torch.optim.lr_scheduler as lr_scheduler\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "import torchvision\n",
    "import torchvision.datasets\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import time\n",
    "\n",
    "from snntorch import spikegen\n",
    "import matplotlib.pyplot as plt\n",
    "import snntorch.spikeplot as splt\n",
    "from IPython.display import HTML\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "from apex.parallel import DistributedDataParallel as DDP\n",
    "\n",
    "import random\n",
    "import datetime\n",
    "\n",
    "import json\n",
    "\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "''' 레퍼런스\n",
    "https://spikingjelly.readthedocs.io/zh-cn/0.0.0.0.4/spikingjelly.datasets.html#module-spikingjelly.datasets\n",
    "https://github.com/GorkaAbad/Sneaky-Spikes/blob/main/datasets.py\n",
    "https://github.com/GorkaAbad/Sneaky-Spikes/blob/main/how_to.md\n",
    "https://github.com/nmi-lab/torchneuromorphic\n",
    "https://snntorch.readthedocs.io/en/latest/snntorch.spikevision.spikedata.html#shd\n",
    "'''\n",
    "\n",
    "import snntorch\n",
    "from snntorch.spikevision import spikedata\n",
    "\n",
    "import modules.spikingjelly;\n",
    "from modules.spikingjelly.datasets.dvs128_gesture import DVS128Gesture\n",
    "from modules.spikingjelly.datasets.cifar10_dvs import CIFAR10DVS\n",
    "from modules.spikingjelly.datasets.n_mnist import NMNIST\n",
    "# from modules.spikingjelly.datasets.es_imagenet import ESImageNet\n",
    "from modules.spikingjelly.datasets import split_to_train_test_set\n",
    "from modules.spikingjelly.datasets.n_caltech101 import NCaltech101\n",
    "from modules.spikingjelly.datasets import pad_sequence_collate, padded_sequence_mask\n",
    "\n",
    "import modules.torchneuromorphic as torchneuromorphic\n",
    "\n",
    "import wandb\n",
    "\n",
    "from torchviz import make_dot\n",
    "import graphviz\n",
    "from turtle import shape\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# my module import\n",
    "from modules import *\n",
    "\n",
    "# modules 폴더에 새모듈.py 만들면\n",
    "# modules/__init__py 파일에 form .새모듈 import * 하셈\n",
    "# 그리고 새모듈.py에서 from modules.새모듈 import * 하셈\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def my_snn_system(devices = \"0,1,2,3\",\n",
    "                    single_step = False, # True # False\n",
    "                    unique_name = 'main',\n",
    "                    my_seed = 42,\n",
    "                    TIME = 10,\n",
    "                    BATCH = 256,\n",
    "                    IMAGE_SIZE = 32,\n",
    "                    which_data = 'CIFAR10',\n",
    "                    # CLASS_NUM = 10,\n",
    "                    data_path = '/data2',\n",
    "                    rate_coding = True,\n",
    "    \n",
    "                    lif_layer_v_init = 0.0,\n",
    "                    lif_layer_v_decay = 0.6,\n",
    "                    lif_layer_v_threshold = 1.2,\n",
    "                    lif_layer_v_reset = 0.0,\n",
    "                    lif_layer_sg_width = 1,\n",
    "\n",
    "                    # synapse_conv_in_channels = IMAGE_PIXEL_CHANNEL,\n",
    "                    synapse_conv_kernel_size = 3,\n",
    "                    synapse_conv_stride = 1,\n",
    "                    synapse_conv_padding = 1,\n",
    "\n",
    "                    synapse_trace_const1 = 1,\n",
    "                    synapse_trace_const2 = 0.6,\n",
    "\n",
    "                    # synapse_fc_out_features = CLASS_NUM,\n",
    "\n",
    "                    pre_trained = False,\n",
    "                    convTrue_fcFalse = True,\n",
    "\n",
    "                    cfg = [64, 64],\n",
    "                    net_print = False, # True # False\n",
    "                    \n",
    "                    pre_trained_path = \"net_save/save_now_net.pth\",\n",
    "                    learning_rate = 0.0001,\n",
    "                    epoch_num = 200,\n",
    "                    tdBN_on = False,\n",
    "                    BN_on = False,\n",
    "\n",
    "                    surrogate = 'sigmoid',\n",
    "\n",
    "                    BPTT_on = False,\n",
    "\n",
    "                    optimizer_what = 'SGD', # 'SGD' 'Adam', 'RMSprop'\n",
    "                    scheduler_name = 'no',\n",
    "                    \n",
    "                    ddp_on = False, # DECREPATED # fALSE\n",
    "\n",
    "                    dvs_clipping = 1, \n",
    "                    dvs_duration = 25_000,\n",
    "\n",
    "\n",
    "                    DFA_on = False, # True # False\n",
    "                    trace_on = False, \n",
    "                    OTTT_input_trace_on = False, # True # False\n",
    "                    \n",
    "                    exclude_class = True, # True # False # gesture에서 10번째 클래스 제외\n",
    "\n",
    "                    merge_polarities = False, # True # False # tonic dvs dataset 에서 polarities 합치기\n",
    "                    denoise_on = True, \n",
    "\n",
    "                    extra_train_dataset = 0, # DECREPATED # data_loader에서 train dataset을 몇개 더 쓸건지 \n",
    "\n",
    "                    num_workers = 2,\n",
    "                    chaching_on = True,\n",
    "                    pin_memory = True, # True # False\n",
    "                    \n",
    "                    UDA_on = False,  # DECREPATED # uda\n",
    "                    alpha_uda = 1.0, # DECREPATED # uda\n",
    "\n",
    "                    bias = True,\n",
    "\n",
    "                    last_lif = False,\n",
    "                    ):\n",
    "    ## 함수 내 모든 로컬 변수 저장 ########################################################\n",
    "    hyperparameters = locals()\n",
    "    hyperparameters['current epoch'] = 0\n",
    "    print('param', hyperparameters,'\\n')\n",
    "    ######################################################################################\n",
    "\n",
    "    ## hyperparameter check #############################################################\n",
    "    if single_step == True:\n",
    "        assert BPTT_on == False and tdBN_on == False \n",
    "    if tdBN_on == True:\n",
    "        assert BPTT_on == True\n",
    "    if pre_trained == True:\n",
    "        print('\\n\\n')\n",
    "        print(\"Caution! pre_trained is True\\n\\n\"*3)    \n",
    "    if DFA_on == True:\n",
    "        assert single_step == True and BPTT_on == False \n",
    "    # assert single_step == DFA_on, 'DFA랑 single_step공존하게해라'\n",
    "    if trace_on:\n",
    "        assert BPTT_on == False and single_step == True\n",
    "    if OTTT_input_trace_on == True:\n",
    "        assert BPTT_on == False and single_step == True and trace_on == True\n",
    "    ######################################################################################\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "    ## wandb 세팅 ###################################################################\n",
    "    current_time = datetime.datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "    wandb.config.update(hyperparameters)\n",
    "    wandb.run.name = f'lr_{learning_rate}_{unique_name}_{which_data}_tstep{TIME}'\n",
    "    wandb.define_metric(\"summary_val_acc\", summary=\"max\")\n",
    "    # wandb.run.log_code(\".\", \n",
    "    #                     include_fn=lambda path: path.endswith(\".py\") or path.endswith(\".ipynb\"),\n",
    "    #                     exclude_fn=lambda path: 'logs/' in path or 'net_save/' in path or 'result_save/' in path or 'trying/' in path or 'wandb/' in path or 'private/' in path or '.git/' in path or 'tonic' in path or 'torchneuromorphic' in path or 'spikingjelly' in path \n",
    "    #                     )\n",
    "    ###################################################################################\n",
    "\n",
    "\n",
    "\n",
    "    ## gpu setting ##################################################################################################################\n",
    "    os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\" \n",
    "    os.environ[\"CUDA_VISIBLE_DEVICES\"]= devices\n",
    "    ###################################################################################################################################\n",
    "\n",
    "\n",
    "    ## seed setting ##################################################################################################################\n",
    "    seed_assign(my_seed)\n",
    "    ###################################################################################################################################\n",
    "    \n",
    "\n",
    "    ## data_loader 가져오기 ##################################################################################################################\n",
    "    # data loader, pixel channel, class num\n",
    "    train_data_split_indices = []\n",
    "    train_loader, test_loader, synapse_conv_in_channels, CLASS_NUM, train_data_count = data_loader(\n",
    "            which_data,\n",
    "            data_path, \n",
    "            rate_coding, \n",
    "            BATCH, \n",
    "            IMAGE_SIZE,\n",
    "            ddp_on,\n",
    "            TIME, \n",
    "            dvs_clipping,\n",
    "            dvs_duration,\n",
    "            exclude_class,\n",
    "            merge_polarities,\n",
    "            denoise_on,\n",
    "            my_seed,\n",
    "            extra_train_dataset,\n",
    "            num_workers,\n",
    "            chaching_on,\n",
    "            pin_memory,\n",
    "            train_data_split_indices,) \n",
    "    synapse_fc_out_features = CLASS_NUM\n",
    "\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    print(f\"\\ndevice ==> {device}\\n\")\n",
    "    if device == \"cpu\":\n",
    "        print(\"=\"*50,\"\\n[WARNING]\\n[WARNING]\\n[WARNING]\\n: cpu mode\\n\\n\",\"=\"*50)\n",
    "\n",
    "    ### network setting #######################################################################################################################\n",
    "    if (convTrue_fcFalse == False):\n",
    "        net = REBORN_MY_SNN_FC(cfg, synapse_conv_in_channels, IMAGE_SIZE, synapse_fc_out_features,\n",
    "                    synapse_trace_const1, synapse_trace_const2, \n",
    "                    lif_layer_v_init, lif_layer_v_decay, \n",
    "                    lif_layer_v_threshold, lif_layer_v_reset,\n",
    "                    lif_layer_sg_width,\n",
    "                    tdBN_on,\n",
    "                    BN_on, TIME,\n",
    "                    surrogate,\n",
    "                    BPTT_on,\n",
    "                    DFA_on,\n",
    "                    bias,\n",
    "                    single_step,\n",
    "                    last_lif,\n",
    "                    trace_on).to(device)\n",
    "    else:\n",
    "        net = REBORN_MY_SNN_CONV(cfg, synapse_conv_in_channels, IMAGE_SIZE,\n",
    "                    synapse_conv_kernel_size, synapse_conv_stride, \n",
    "                    synapse_conv_padding, synapse_trace_const1, \n",
    "                    synapse_trace_const2, \n",
    "                    lif_layer_v_init, lif_layer_v_decay, \n",
    "                    lif_layer_v_threshold, lif_layer_v_reset,\n",
    "                    lif_layer_sg_width,\n",
    "                    synapse_fc_out_features, \n",
    "                    tdBN_on,\n",
    "                    BN_on, TIME,\n",
    "                    surrogate,\n",
    "                    BPTT_on,\n",
    "                    DFA_on,\n",
    "                    bias,\n",
    "                    single_step,\n",
    "                    last_lif,\n",
    "                    trace_on).to(device)\n",
    "\n",
    "    net = torch.nn.DataParallel(net) \n",
    "    \n",
    "    if pre_trained == True:\n",
    "        net.load_state_dict(torch.load(pre_trained_path))\n",
    "    \n",
    "    net = net.to(device)\n",
    "    if (net_print == True):\n",
    "        print(net)    \n",
    "\n",
    "    print(f\"\\n========================================================\\nTrainable parameters: {sum(p.numel() for p in net.parameters() if p.requires_grad):,}\\n========================================================\\n\")\n",
    "    ####################################################################################################################################\n",
    "    \n",
    "\n",
    "    ## wandb logging ###########################################\n",
    "    # wandb.watch(net, log=\"all\", log_freq = 10) #gradient, parameter logging해줌\n",
    "    ############################################################\n",
    "\n",
    "\n",
    "    ## criterion ########################################## # loss 구해주는 친구\n",
    "    criterion = nn.CrossEntropyLoss().to(device)\n",
    "    # if (OTTT_sWS_on == True):\n",
    "    #     # criterion = nn.CrossEntropyLoss().to(device)\n",
    "    #     criterion = lambda y_t, target_t: ((1 - 0.05) * F.cross_entropy(y_t, target_t) + 0.05 * F.mse_loss(y_t, F.one_hot(target_t, CLASS_NUM).float())) / TIME \n",
    "    #     if which_data == 'DVS_GESTURE':\n",
    "    #         criterion = lambda y_t, target_t: ((1 - 0.001) * F.cross_entropy(y_t, target_t) + 0.001 * F.mse_loss(y_t, F.one_hot(target_t, CLASS_NUM).float())) / TIME \n",
    "    ####################################################\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "    ## optimizer, scheduler ########################################################################\n",
    "    if(optimizer_what == 'SGD'):\n",
    "        optimizer = optim.SGD(net.parameters(), lr=learning_rate, momentum=0.9)\n",
    "        # optimizer = optim.SGD(net.parameters(), lr=learning_rate, momentum=0.9, weight_decay=0)\n",
    "    elif(optimizer_what == 'Adam'):\n",
    "        optimizer = torch.optim.Adam(net.parameters(), lr=learning_rate)\n",
    "        # optimizer = torch.optim.Adam(net.parameters(), lr=0.00001)\n",
    "        # optimizer = torch.optim.Adam(net.parameters(), lr=learning_rate/256 * BATCH, weight_decay=1e-4)\n",
    "        # optimizer = optim.Adam(net.parameters(), lr=learning_rate, weight_decay=0, betas=(0.9, 0.999))\n",
    "    elif(optimizer_what == 'RMSprop'):\n",
    "        pass\n",
    "\n",
    "\n",
    "    if (scheduler_name == 'StepLR'):\n",
    "        scheduler = lr_scheduler.StepLR(optimizer, step_size=10, gamma=0.1)\n",
    "    elif (scheduler_name == 'ExponentialLR'):\n",
    "        scheduler = lr_scheduler.ExponentialLR(optimizer, gamma=0.95)\n",
    "    elif (scheduler_name == 'ReduceLROnPlateau'):\n",
    "        scheduler = lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.1, patience=10)\n",
    "    elif (scheduler_name == 'CosineAnnealingLR'):\n",
    "        # scheduler = lr_scheduler.CosineAnnealingLR(optimizer, eta_min=0, T_max=50)\n",
    "        scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, eta_min=0, T_max=epoch_num)\n",
    "    elif (scheduler_name == 'OneCycleLR'):\n",
    "        scheduler = lr_scheduler.OneCycleLR(optimizer, max_lr=0.1, steps_per_epoch=len(train_loader), epochs=epoch_num)\n",
    "    else:\n",
    "        pass # 'no' scheduler\n",
    "    ## optimizer, scheduler ########################################################################\n",
    "\n",
    "\n",
    "    tr_acc = 0\n",
    "    tr_correct = 0\n",
    "    tr_total = 0\n",
    "    tr_acc_best = 0\n",
    "    tr_epoch_loss_temp = 0\n",
    "    tr_epoch_loss = 0\n",
    "    val_acc_best = 0\n",
    "    val_acc_now = 0\n",
    "    val_loss = 0\n",
    "    iter_of_val = False\n",
    "    #======== EPOCH START ==========================================================================================\n",
    "    for epoch in range(epoch_num):\n",
    "        if epoch == 1:\n",
    "            for name, module in net.named_modules():\n",
    "                if isinstance(module, Feedback_Receiver):\n",
    "                    print(f\"[{name}] weight_fb parameter count: {module.weight_fb.numel():,}\")\n",
    "        ####### iterator : input_loading & tqdm을 통한 progress_bar 생성###################\n",
    "        iterator = enumerate(train_loader, 0)\n",
    "        # iterator = tqdm(iterator, total=len(train_loader), desc='train', dynamic_ncols=True, position=0, leave=True)\n",
    "        ##################################################################################   \n",
    "\n",
    "        ###### ITERATION START ##########################################################################################################\n",
    "        for i, data in iterator:\n",
    "            net.train() # train 모드로 바꿔줘야함\n",
    "\n",
    "            ### data loading & semi-pre-processing ################################################################################\n",
    "            if len(data) == 2:\n",
    "                inputs, labels = data\n",
    "                # 처리 로직 작성\n",
    "            elif len(data) == 3:\n",
    "                inputs, labels, x_len = data\n",
    "            else:\n",
    "                assert False, 'data length is not 2 or 3'\n",
    "            #######################################################################################################################\n",
    "                \n",
    "            ## batch 크기 ######################################\n",
    "            real_batch = labels.size(0)\n",
    "            ###########################################################\n",
    "\n",
    "            # 차원 전처리\n",
    "            ###########################################################################################################################        \n",
    "            if (which_data == 'DVS_CIFAR10' or which_data == 'DVS_GESTURE' or which_data == 'DVS_GESTURE_TONIC' or which_data == 'DVS_CIFAR10_2' or which_data == 'NMNIST' or which_data == 'NMNIST_TONIC' or which_data == 'N_CALTECH101' or which_data == 'n_tidigits' or which_data == 'heidelberg'):\n",
    "                inputs = inputs.permute(1, 0, 2, 3, 4)\n",
    "            elif rate_coding == True :\n",
    "                inputs = spikegen.rate(inputs, num_steps=TIME)\n",
    "            else :\n",
    "                inputs = inputs.repeat(TIME, 1, 1, 1, 1)\n",
    "            # inputs: [Time, Batch, Channel, Height, Width]  \n",
    "            ####################################################################################################################### \n",
    "                \n",
    "            # # dvs 데이터 시각화 코드 (확인 필요할 시 써라)\n",
    "            # ##############################################################################################\n",
    "            # dvs_visualization(inputs, labels, TIME, BATCH, my_seed)\n",
    "            # #####################################################################################################\n",
    "\n",
    "            ## to (device) #######################################\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "            ###########################################################\n",
    "\n",
    "            ## gradient 초기화 #######################################\n",
    "            optimizer.zero_grad()\n",
    "            ###########################################################\n",
    "                            \n",
    "            if merge_polarities == True:\n",
    "                inputs = inputs[:,:,0:1,:,:]\n",
    "\n",
    "            if single_step == False:\n",
    "                # net에 넣어줄때는 batch가 젤 앞 차원으로 와야함. # dataparallel때매##############################\n",
    "                # inputs: [Time, Batch, Channel, Height, Width]   \n",
    "                inputs = inputs.permute(1, 0, 2, 3, 4) # net에 넣어줄때는 batch가 젤 앞 차원으로 와야함. # dataparallel때매\n",
    "                # inputs: [Batch, Time, Channel, Height, Width] \n",
    "                #################################################################################################\n",
    "            else:\n",
    "                labels = labels.repeat(TIME, 1)\n",
    "                ## first input도 ottt trace 적용하기 위한 코드 (validation 시에는 필요X) ##########################\n",
    "                if OTTT_input_trace_on == True:\n",
    "                    spike = inputs\n",
    "                    trace = torch.full_like(spike, fill_value = 0.0, dtype = torch.float, requires_grad=False)\n",
    "                    inputs = []\n",
    "                    for t in range(TIME):\n",
    "                        trace[t] = trace[t-1]*synapse_trace_const2 + spike[t]*synapse_trace_const1\n",
    "                        inputs += [[spike[t], trace[t]]]\n",
    "                ##################################################################################################\n",
    "\n",
    "\n",
    "            if single_step == False:\n",
    "                ### input --> net --> output #####################################################\n",
    "                outputs = net(inputs)\n",
    "                ##################################################################################\n",
    "                ## loss, backward ##########################################\n",
    "                iter_loss = criterion(outputs, labels)\n",
    "                iter_loss.backward()\n",
    "                ############################################################\n",
    "                ## weight 업데이트!! ##################################\n",
    "                optimizer.step()\n",
    "                ################################################################\n",
    "            else:\n",
    "                outputs_all = []\n",
    "                iter_loss = 0.0\n",
    "                for t in range(TIME):\n",
    "                    ### input[t] --> net --> output_one_time #########################################\n",
    "                    outputs_one_time = net(inputs[t])\n",
    "                    ##################################################################################\n",
    "                    one_time_loss = criterion(outputs_one_time, labels[t].contiguous())\n",
    "                    one_time_loss.backward() # one_time backward\n",
    "                    iter_loss += one_time_loss.data\n",
    "                    outputs_all.append(outputs_one_time.detach())\n",
    "                optimizer.step() # full step time update\n",
    "                outputs_all = torch.stack(outputs_all, dim=1)\n",
    "                outputs = outputs_all.mean(1) # ottt꺼 쓸때\n",
    "                labels = labels[0]\n",
    "                iter_loss /= TIME\n",
    "\n",
    "            tr_epoch_loss_temp += iter_loss.data/len(train_loader)\n",
    "\n",
    "            ## net 그림 출력해보기 #################################################################\n",
    "            # print('시각화')\n",
    "            # make_dot(outputs, params=dict(list(net.named_parameters()))).render(\"net_torchviz\", format=\"png\")\n",
    "            # return 0\n",
    "            ##################################################################################\n",
    "\n",
    "            #### batch 어긋남 방지 ###############################################\n",
    "            assert real_batch == outputs.size(0), f'batch size is not same. real_batch: {real_batch}, outputs.size(0): {outputs.size(0)}'\n",
    "            #######################################################################\n",
    "            \n",
    "\n",
    "            ####### training accruacy save for print ###############################\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total = real_batch\n",
    "            correct = (predicted == labels).sum().item()\n",
    "            iter_acc = correct / total\n",
    "            tr_total += total\n",
    "            tr_correct += correct\n",
    "            iter_acc_string = f'epoch-{epoch:<3} iter_acc:{100 * iter_acc:7.2f}%, lr={[f\"{lr:9.7f}\" for lr in (param_group[\"lr\"] for param_group in optimizer.param_groups)]}'\n",
    "            iter_acc_string2 = f'epoch-{epoch:<3} lr={[f\"{lr:9.7f}\" for lr in (param_group[\"lr\"] for param_group in optimizer.param_groups)]}'\n",
    "            ################################################################\n",
    "            \n",
    "\n",
    "            ##### validation ##################################################################################################################################\n",
    "            if i == len(train_loader)-1 :\n",
    "                iter_of_val = True\n",
    "\n",
    "                tr_acc = tr_correct/tr_total\n",
    "                tr_correct = 0\n",
    "                tr_total = 0\n",
    "\n",
    "                val_loss = 0\n",
    "                correct_val = 0\n",
    "                total_val = 0\n",
    "\n",
    "                with torch.no_grad():\n",
    "                    net.eval() # eval 모드로 바꿔줘야함 \n",
    "                    for data_val in test_loader:\n",
    "                        ## data_val loading & semi-pre-processing ##########################################################\n",
    "                        if len(data_val) == 2:\n",
    "                            inputs_val, labels_val = data_val\n",
    "                        elif len(data_val) == 3:\n",
    "                            inputs_val, labels_val, x_len = data_val\n",
    "                        else:\n",
    "                            assert False, 'data_val length is not 2 or 3'\n",
    "\n",
    "                        if (which_data == 'DVS_CIFAR10' or which_data == 'DVS_GESTURE' or which_data == 'DVS_GESTURE_TONIC' or which_data == 'DVS_CIFAR10_2' or which_data == 'NMNIST' or which_data == 'NMNIST_TONIC' or which_data == 'N_CALTECH101' or which_data == 'n_tidigits' or which_data == 'heidelberg'):\n",
    "                            inputs_val = inputs_val.permute(1, 0, 2, 3, 4)\n",
    "                        elif rate_coding == True :\n",
    "                            inputs_val = spikegen.rate(inputs_val, num_steps=TIME)\n",
    "                        else :\n",
    "                            inputs_val = inputs_val.repeat(TIME, 1, 1, 1, 1)\n",
    "                        # inputs_val: [Time, Batch, Channel, Height, Width]  \n",
    "                        ###################################################################################################\n",
    "\n",
    "                        inputs_val = inputs_val.to(device)\n",
    "                        labels_val = labels_val.to(device)\n",
    "                        real_batch = labels_val.size(0)\n",
    "                        \n",
    "                        if merge_polarities == True:\n",
    "                            inputs_val = inputs_val[:,:,0:1,:,:]\n",
    "\n",
    "                        ## network 연산 시작 ############################################################################################################\n",
    "                        if single_step == False:\n",
    "                            outputs = net(inputs_val.permute(1, 0, 2, 3, 4)) #inputs_val: [Batch, Time, Channel, Height, Width]  \n",
    "                            val_loss += criterion(outputs, labels_val)/len(test_loader)\n",
    "                        else:\n",
    "                            outputs_all = []\n",
    "                            for t in range(TIME):\n",
    "                                outputs = net(inputs_val[t])\n",
    "                                val_loss_temp = criterion(outputs, labels_val)\n",
    "                                outputs_all.append(outputs.detach())\n",
    "                                val_loss += (val_loss_temp.data/TIME)/len(test_loader)\n",
    "                            outputs_all = torch.stack(outputs_all, dim=1)\n",
    "                            outputs = outputs_all.mean(1)\n",
    "                        #################################################################################################################################\n",
    "\n",
    "                        _, predicted = torch.max(outputs.data, 1)\n",
    "                        total_val += real_batch\n",
    "                        assert real_batch == outputs.size(0), f'batch size is not same. real_batch: {real_batch}, outputs.size(0): {outputs.size(0)}'\n",
    "                        correct_val += (predicted == labels_val).sum().item()\n",
    "\n",
    "                    val_acc_now = correct_val / total_val\n",
    "\n",
    "                if val_acc_best < val_acc_now:\n",
    "                    val_acc_best = val_acc_now\n",
    "                    # wandb 키면 state_dict아닌거는 저장 안됨\n",
    "                    # network save\n",
    "                    # torch.save(net.state_dict(), f\"net_save/save_now_net_weights_{unique_name}.pth\")\n",
    "\n",
    "                if tr_acc_best < tr_acc:\n",
    "                    tr_acc_best = tr_acc\n",
    "\n",
    "                tr_epoch_loss = tr_epoch_loss_temp\n",
    "                tr_epoch_loss_temp = 0\n",
    "\n",
    "            ####################################################################################################################################################\n",
    "            \n",
    "            ## progress bar update ############################################################################################################\n",
    "            if iter_of_val == False:\n",
    "                # iterator.set_description(f\"{iter_acc_string}, iter_loss:{iter_loss:10.6f}\") \n",
    "                pass \n",
    "            else:\n",
    "                # iterator.set_description(f\"{iter_acc_string2}, tr/val_loss:{tr_epoch_loss:10.6f}/{val_loss:10.6f}, tr:{100 * tr_acc:7.2f}%, tr_best:{100 * tr_acc_best:7.2f}%, val:{100 * val_acc_now:7.2f}%, val_best:{100 * val_acc_best:7.2f}%\")  \n",
    "                print(f\"{iter_acc_string2}, tr/val_loss:{tr_epoch_loss:10.6f}/{val_loss:10.6f}, val:{100 * val_acc_now:7.2f}%, val_best:{100 * val_acc_best:7.2f}%, tr:{100 * tr_acc:7.2f}%, tr_best:{100 * tr_acc_best:7.2f}%\")\n",
    "                iter_of_val = False\n",
    "            ####################################################################################################################################\n",
    "            \n",
    "            ## wandb logging ############################################################################################################\n",
    "            wandb.log({\"iter_acc\": iter_acc})\n",
    "            wandb.log({\"tr_acc\": tr_acc})\n",
    "            wandb.log({\"val_acc_now\": val_acc_now})\n",
    "            wandb.log({\"val_acc_best\": val_acc_best})\n",
    "            wandb.log({\"summary_val_acc\": val_acc_now})\n",
    "            wandb.log({\"epoch\": epoch})\n",
    "            wandb.log({\"val_loss\": val_loss}) \n",
    "            wandb.log({\"tr_epoch_loss\": tr_epoch_loss})   \n",
    "            ####################################################################################################################################\n",
    "            \n",
    "        ###### ITERATION END ##########################################################################################################\n",
    "\n",
    "        ## scheduler update #############################################################################\n",
    "        if (scheduler_name != 'no'):\n",
    "            if (scheduler_name == 'ReduceLROnPlateau'):\n",
    "                scheduler.step(val_loss)\n",
    "            else:\n",
    "                scheduler.step()\n",
    "        #################################################################################################\n",
    "        \n",
    "    #======== EPOCH END ==========================================================================================\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ### my_snn control board (Gesture) ########################\n",
    "# decay = 0.25 # 0.875 0.25 0.125 0.75 0.5\n",
    "# # nda 0.25 # ottt 0.5\n",
    "# const2 = False # True # False\n",
    "\n",
    "# unique_name = 'main' ## 이거 설정하면 새로운 경로에 모두 save\n",
    "# run_name = 'main' ## 이거 설정하면 새로운 경로에 모두 save\n",
    "\n",
    "# if const2 == True:\n",
    "#     const2 = decay\n",
    "# else:\n",
    "#     const2 = 0.0\n",
    "\n",
    "# wandb.init(project= f'my_snn {unique_name}',save_code=False, dir='/data2/bh_wandb', tags=[\"common\"])\n",
    "\n",
    "# my_snn_system(  devices = \"5\",\n",
    "#                 single_step = True, # True # False # DFA_on이랑 같이 가라\n",
    "#                 unique_name = run_name,\n",
    "#                 my_seed = 42,\n",
    "#                 TIME = 10, # dvscifar 10 # ottt 6 or 10 # nda 10  # 제작하는 dvs에서 TIME넘거나 적으면 자르거나 PADDING함\n",
    "#                 BATCH = 16, # batch norm 할거면 2이상으로 해야함   # nda 256   #  ottt 128\n",
    "#                 IMAGE_SIZE = 128, # dvscifar 48 # MNIST 28 # CIFAR10 32 # PMNIST 28 #NMNIST 34 # GESTURE 128\n",
    "#                 # dvsgesture 128, dvs_cifar2 128, nmnist 34, n_caltech101 180,240, n_tidigits 64, heidelberg 700, \n",
    "\n",
    "#                 # DVS_CIFAR10 할거면 time 10으로 해라\n",
    "#                 which_data = 'DVS_GESTURE_TONIC',\n",
    "# # 'CIFAR100' 'CIFAR10' 'MNIST' 'FASHION_MNIST' 'DVS_CIFAR10' 'PMNIST'아직\n",
    "# # 'DVS_GESTURE', 'DVS_GESTURE_TONIC','DVS_CIFAR10_2','NMNIST','NMNIST_TONIC','CIFAR10','N_CALTECH101','n_tidigits','heidelberg'\n",
    "#                 # CLASS_NUM = 10,\n",
    "#                 data_path = '/data2', # YOU NEED TO CHANGE THIS\n",
    "#                 rate_coding = False, # True # False\n",
    "\n",
    "#                 lif_layer_v_init = 0.0,\n",
    "#                 lif_layer_v_decay = decay,\n",
    "#                 lif_layer_v_threshold = 0.720291189014991,   #nda 0.5  #ottt 1.0\n",
    "#                 lif_layer_v_reset = 10000, # 10000이상은 hardreset (내 LIF쓰기는 함 ㅇㅇ)\n",
    "#                 lif_layer_sg_width = 3.555718888923306, # 2.570969004857107 # sigmoid류에서는 alpha값 4.0, rectangle류에서는 width값 0.5\n",
    "\n",
    "#                 # synapse_conv_in_channels = IMAGE_PIXEL_CHANNEL,\n",
    "#                 synapse_conv_kernel_size = 3,\n",
    "#                 synapse_conv_stride = 1,\n",
    "#                 synapse_conv_padding = 1,\n",
    "\n",
    "#                 synapse_trace_const1 = 1, # 현재 trace구할 때 현재 spike에 곱해지는 상수. 걍 1로 두셈.\n",
    "#                 synapse_trace_const2 = const2, # 현재 trace구할 때 직전 trace에 곱해지는 상수. lif_layer_v_decay와 같게 할 것을 추천\n",
    "\n",
    "#                 # synapse_fc_out_features = CLASS_NUM,\n",
    "\n",
    "#                 pre_trained = False, # True # False\n",
    "#                 convTrue_fcFalse = False, # True # False\n",
    "\n",
    "#                 # 'P' for average pooling, 'D' for (1,1) aver pooling, 'M' for maxpooling, 'L' for linear classifier, [  ] for residual block\n",
    "#                 # conv에서 10000 이상은 depth-wise separable (BPTT만 지원), 20000이상은 depth-wise (BPTT만 지원)\n",
    "#                 # cfg = ['M', 'M', 32, 'P', 32, 'P', 32, 'P'], \n",
    "#                 # cfg = ['M', 'M', 64, 'P', 64, 'P', 64, 'P'], \n",
    "#                 # cfg = ['M', 'M', 64, 'M', 96, 'M', 128, 'M'], \n",
    "#                 cfg = ['M', 'M', 200, 200], \n",
    "#                 # cfg = ['M', 'M', 64, 'M', 96], \n",
    "#                 # cfg = ['M', 'M', 64, 'M', 96, 'L', 512, 512], \n",
    "#                 # cfg = ['M', 'M', 64], \n",
    "#                 # cfg = [64, 124, 64, 124],\n",
    "#                 # cfg = ['M','M',512], \n",
    "#                 # cfg = [512], \n",
    "#                 # cfg = ['M', 'M', 64, 128, 'P', 128, 'P'], \n",
    "#                 # cfg = ['M','M',512],\n",
    "#                 # cfg = ['M',200],\n",
    "#                 # cfg = [200,200],\n",
    "#                 # cfg = ['M','M',200,200],\n",
    "#                 # cfg = ([200],[200],[200],[2]), # (feature extractor, classifier, domain adapter, # of domain)\n",
    "#                 # cfg = (['M','M',200],[200],[200],[2]), # (feature extractor, classifier, domain adapter, # of domain)\n",
    "#                 # cfg = ['M',200,200],\n",
    "#                 # cfg = ['M','M',1024,512,256,128,64],\n",
    "#                 # cfg = [200,200],\n",
    "#                 # cfg = [12], #fc\n",
    "#                 # cfg = [12, 'M', 48, 'M', 12], \n",
    "#                 # cfg = [64,[64,64],64], # 끝에 linear classifier 하나 자동으로 붙습니다\n",
    "#                 # cfg = [64, 128, 'P', 256, 256, 'P', 512, 512, 'P', 512, 512, 'D'], #ottt\n",
    "#                 # cfg = [64, 128, 'P', 256, 256, 'P', 512, 512, 'P', 512, 512], \n",
    "#                 # cfg = [64, 128, 'M', 256, 256, 'M', 512, 512, 'M', 512, 512], \n",
    "#                 # cfg = [64, 'P', 128, 'P', 256, 256, 'P', 512, 512, 512, 512, 'D'], # nda\n",
    "#                 # cfg = [64, 'P', 128, 'P', 256, 256, 'P', 512, 512, 512, 512], # nda 128pixel\n",
    "#                 # cfg = [64, 'P', 128, 'P', 256, 256, 'P', 512, 512, 512, 512, 'L', 4096, 4096],\n",
    "#                 # cfg = [20001,10001], # depthwise, separable\n",
    "#                 # cfg = [64,20064,10001], # vanilla conv, depthwise, separable\n",
    "#                 # cfg = [8, 'P', 8, 'P', 8, 'P', 8,'P', 8, 'P'],\n",
    "#                 # cfg = [],        \n",
    "                \n",
    "#                 net_print = True, # True # False # True로 하길 추천\n",
    "                \n",
    "#                 pre_trained_path = f\"net_save/save_now_net_weights_{unique_name}.pth\",\n",
    "#                 learning_rate = 0.0001, #0.1 bptt, #0.01 ottt, # default 0.001  # ottt 0.1 # nda 0.001 # 0.00936191669529645\n",
    "#                 epoch_num = 10000,\n",
    "#                 tdBN_on = False,  # True # False\n",
    "#                 BN_on = False,  # True # False\n",
    "                \n",
    "#                 surrogate = 'hard_sigmoid', # 'sigmoid' 'rectangle' 'rough_rectangle' 'hard_sigmoid'\n",
    "                \n",
    "#                 BPTT_on = False,  # True # False # True이면 BPTT, False이면 OTTT  # depthwise, separable은 BPTT만 가능\n",
    "                \n",
    "#                 optimizer_what = 'SGD', # 'SGD' 'Adam', 'RMSprop'\n",
    "#                 scheduler_name = 'no', # 'no' 'StepLR' 'ExponentialLR' 'ReduceLROnPlateau' 'CosineAnnealingLR' 'OneCycleLR'\n",
    "                \n",
    "#                 ddp_on = False, # DECREPATED # fALSE\n",
    "\n",
    "#                 dvs_clipping = 5, #일반적으로 1 또는 2 # 100ms때는 5 # 숫자만큼 크면 spike 아니면 걍 0\n",
    "#                 # gesture, cifar-dvs2, nmnist, ncaltech101\n",
    "#                 # gesture: 100_000c1-5, 25_000c5, 10_000c5, 1_000c5, 1_000_000c5\n",
    "\n",
    "#                 dvs_duration = 100_000, # 0 아니면 time sampling # dvs number sampling OR time sampling # gesture, cifar-dvs2, nmnist, ncaltech101\n",
    "#                 # 있는 데이터들 #gesture 100_000 25_000 10_000 1_000 1_000_000 #nmnist 10000 #nmnist_tonic 10_000 25_000\n",
    "#                 # 한 숫자가 1us인듯 (spikingjelly코드에서)\n",
    "#                 # 한 장에 50 timestep만 생산함. 싫으면 my_snn/trying/spikingjelly_dvsgesture의__init__.py 를 참고해봐\n",
    "#                 # nmnist 5_000us, gesture는 100_000us, 25_000us\n",
    "\n",
    "#                 DFA_on = False, # True # False # single_step이랑 같이 켜야 됨.\n",
    "\n",
    "#                 trace_on = False,   # True # False\n",
    "#                 OTTT_input_trace_on = False, # True # False # 맨 처음 input에 trace 적용\n",
    "\n",
    "#                 exclude_class = True, # True # False # gesture에서 10번째 클래스 제외\n",
    "\n",
    "#                 merge_polarities = False, # True # False # tonic dvs dataset 에서 polarities 합치기\n",
    "#                 denoise_on = False, # True # False # &&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&\n",
    "\n",
    "#                 extra_train_dataset = 0, \n",
    "\n",
    "#                 num_workers = 2, # local wsl에서는 2가 맞고, 서버에서는 4가 좋더라.\n",
    "#                 chaching_on = True, # True # False # only for certain datasets (gesture_tonic, nmnist_tonic)\n",
    "#                 pin_memory = True, # True # False \n",
    "\n",
    "#                 UDA_on = False,  # DECREPATED # uda\n",
    "#                 alpha_uda = 1.0, # DECREPATED # uda\n",
    "\n",
    "#                 bias = True, # True # False \n",
    "\n",
    "#                 last_lif = False,\n",
    "#                 ) \n",
    "\n",
    "# # num_workers = 4 * num_GPU (or 8, 16, 2 * num_GPU)\n",
    "# # entry * batch_size * num_worker = num_GPU * GPU_throughtput\n",
    "# # num_workers = batch_size / num_GPU\n",
    "# # num_workers = batch_size / num_CPU\n",
    "\n",
    "# # sigmoid와 BN이 있어야 잘된다.\n",
    "# # average pooling  \n",
    "# # 이 낫다. \n",
    "\n",
    "# # nda에서는 decay = 0.25, threshold = 0.5, width =1, surrogate = rectangle, batch = 256, tdBN = True\n",
    "# ## OTTT 에서는 decay = 0.5, threshold = 1.0, surrogate = sigmoid, batch = 128, BN = True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Create sweep with ID: 6pj3lh8j\n",
      "Sweep URL: https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/6pj3lh8j\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 1l4xujl1 with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBATCH: 16\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBN_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBPTT_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tDFA_on: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tIMAGE_SIZE: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tOTTT_input_trace_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tTIME: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tUDA_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \talpha_uda: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbias: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcfg: ['M', 'M', 200, 200]\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tchaching_on: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tconvTrue_fcFalse: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdata_path: /data2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tddp_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdenoise_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdvs_clipping: 5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdvs_duration: 100000\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepoch_num: 100\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \texclude_class: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \textra_train_dataset: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlast_lif: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.001\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_sg_width: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_decay: 0.5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_init: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_reset: 10000\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_threshold: 0.75\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmerge_polarities: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmy_seed: 42\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnet_print: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_workers: 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer_what: SGD\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tpin_memory: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tpre_trained: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tpre_trained_path: net_save/save_now_net_weights_{unique_name}.pth\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \trate_coding: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tscheduler_name: no\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsingle_step: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsurrogate: hard_sigmoid\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_conv_kernel_size: 3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_conv_padding: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_conv_stride: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_trace_const1: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_trace_const2: 0.5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \ttdBN_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \ttrace_on: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \twhich_data: DVS_GESTURE_TONIC\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mbhkim003\u001b[0m (\u001b[33mbhkim003-seoul-national-university\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.19.10 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.17.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/data2/bh_wandb/wandb/run-20250429_224422-1l4xujl1</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/1l4xujl1' target=\"_blank\">ethereal-sweep-1</a></strong> to <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/6pj3lh8j' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/6pj3lh8j</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/6pj3lh8j' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/6pj3lh8j</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/1l4xujl1' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/1l4xujl1</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'single_step' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'my_seed' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'TIME' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BATCH' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'IMAGE_SIZE' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'which_data' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'data_path' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'rate_coding' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_init' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_decay' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_threshold' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_reset' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_sg_width' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_conv_kernel_size' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_conv_stride' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_conv_padding' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_trace_const1' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_trace_const2' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'pre_trained' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'convTrue_fcFalse' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'cfg' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'net_print' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'pre_trained_path' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'learning_rate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'epoch_num' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'tdBN_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BN_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'surrogate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BPTT_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'optimizer_what' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'scheduler_name' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'ddp_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'dvs_clipping' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'dvs_duration' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'DFA_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'trace_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'OTTT_input_trace_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'exclude_class' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'merge_polarities' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'denoise_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'extra_train_dataset' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'num_workers' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'chaching_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'pin_memory' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'UDA_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'alpha_uda' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'bias' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'last_lif' was locked by 'sweep' (ignored update).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "param {'devices': '0', 'single_step': True, 'unique_name': 'main', 'my_seed': 42, 'TIME': 10, 'BATCH': 16, 'IMAGE_SIZE': 128, 'which_data': 'DVS_GESTURE_TONIC', 'data_path': '/data2', 'rate_coding': False, 'lif_layer_v_init': 0, 'lif_layer_v_decay': 0.5, 'lif_layer_v_threshold': 0.75, 'lif_layer_v_reset': 10000, 'lif_layer_sg_width': 1, 'synapse_conv_kernel_size': 3, 'synapse_conv_stride': 1, 'synapse_conv_padding': 1, 'synapse_trace_const1': 1, 'synapse_trace_const2': 0.5, 'pre_trained': False, 'convTrue_fcFalse': False, 'cfg': ['M', 'M', 200, 200], 'net_print': True, 'pre_trained_path': 'net_save/save_now_net_weights_{unique_name}.pth', 'learning_rate': 0.001, 'epoch_num': 100, 'tdBN_on': False, 'BN_on': False, 'surrogate': 'hard_sigmoid', 'BPTT_on': False, 'optimizer_what': 'SGD', 'scheduler_name': 'no', 'ddp_on': False, 'dvs_clipping': 5, 'dvs_duration': 100000, 'DFA_on': True, 'trace_on': True, 'OTTT_input_trace_on': False, 'exclude_class': True, 'merge_polarities': False, 'denoise_on': False, 'extra_train_dataset': 0, 'num_workers': 2, 'chaching_on': True, 'pin_memory': True, 'UDA_on': False, 'alpha_uda': 1, 'bias': True, 'last_lif': False, 'current epoch': 0} \n",
      "\n",
      "dataset_hash = ffa516e60c3efd5e0208f72b4c36cb84\n",
      "cache path exists\n",
      "\n",
      "device ==> cuda\n",
      "\n",
      "DataParallel(\n",
      "  (module): REBORN_MY_SNN_FC(\n",
      "    (layers): REBORN_MY_Sequential(\n",
      "      (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (2): DimChanger_for_FC()\n",
      "      (3): SYNAPSE_FC(in_features=2048, out_features=200, TIME=10, bias=True, sstep=True)\n",
      "      (4): LIF_layer(v_init=0, v_decay=0.5, v_threshold=0.75, v_reset=10000, sg_width=1, surrogate=hard_sigmoid, BPTT_on=False, trace_const1=1, trace_const2=0.5, TIME=10, sstep=True, trace_on=True)\n",
      "      (5): Feedback_Receiver()\n",
      "      (6): SYNAPSE_FC(in_features=200, out_features=200, TIME=10, bias=True, sstep=True)\n",
      "      (7): LIF_layer(v_init=0, v_decay=0.5, v_threshold=0.75, v_reset=10000, sg_width=1, surrogate=hard_sigmoid, BPTT_on=False, trace_const1=1, trace_const2=0.5, TIME=10, sstep=True, trace_on=True)\n",
      "      (8): Feedback_Receiver()\n",
      "      (9): SYNAPSE_FC(in_features=200, out_features=10, TIME=10, bias=True, sstep=True)\n",
      "      (DFA_top): Top_Gradient()\n",
      "    )\n",
      "  )\n",
      ")\n",
      "\n",
      "========================================================\n",
      "Trainable parameters: 452,010\n",
      "========================================================\n",
      "\n",
      "epoch-0   lr=['0.0010000'], tr/val_loss:  2.305352/  2.302666, val:  11.67%, val_best:  11.67%, tr:   8.38%, tr_best:   8.38%\n",
      "[module.layers.5] weight_fb parameter count: 2,000\n",
      "[module.layers.8] weight_fb parameter count: 2,000\n",
      "epoch-1   lr=['0.0010000'], tr/val_loss:  2.291000/  2.238244, val:  16.67%, val_best:  16.67%, tr:  12.67%, tr_best:  12.67%\n",
      "epoch-2   lr=['0.0010000'], tr/val_loss:  2.019721/  1.895404, val:  43.33%, val_best:  43.33%, tr:  30.34%, tr_best:  30.34%\n",
      "epoch-3   lr=['0.0010000'], tr/val_loss:  1.676060/  1.719729, val:  49.58%, val_best:  49.58%, tr:  51.38%, tr_best:  51.38%\n",
      "epoch-4   lr=['0.0010000'], tr/val_loss:  1.549754/  1.688392, val:  52.08%, val_best:  52.08%, tr:  56.79%, tr_best:  56.79%\n",
      "epoch-5   lr=['0.0010000'], tr/val_loss:  1.485119/  1.647201, val:  54.17%, val_best:  54.17%, tr:  57.20%, tr_best:  57.20%\n",
      "epoch-6   lr=['0.0010000'], tr/val_loss:  1.452062/  1.631100, val:  56.67%, val_best:  56.67%, tr:  60.16%, tr_best:  60.16%\n",
      "epoch-7   lr=['0.0010000'], tr/val_loss:  1.424407/  1.621793, val:  57.08%, val_best:  57.08%, tr:  59.96%, tr_best:  60.16%\n",
      "epoch-8   lr=['0.0010000'], tr/val_loss:  1.394216/  1.619866, val:  59.58%, val_best:  59.58%, tr:  62.31%, tr_best:  62.31%\n",
      "epoch-9   lr=['0.0010000'], tr/val_loss:  1.380970/  1.609393, val:  59.17%, val_best:  59.58%, tr:  63.74%, tr_best:  63.74%\n",
      "epoch-10  lr=['0.0010000'], tr/val_loss:  1.373238/  1.626788, val:  60.42%, val_best:  60.42%, tr:  63.43%, tr_best:  63.74%\n",
      "epoch-11  lr=['0.0010000'], tr/val_loss:  1.350673/  1.593736, val:  60.83%, val_best:  60.83%, tr:  64.66%, tr_best:  64.66%\n",
      "epoch-12  lr=['0.0010000'], tr/val_loss:  1.345445/  1.611862, val:  60.42%, val_best:  60.83%, tr:  66.50%, tr_best:  66.50%\n",
      "epoch-13  lr=['0.0010000'], tr/val_loss:  1.343207/  1.641777, val:  60.83%, val_best:  60.83%, tr:  65.68%, tr_best:  66.50%\n",
      "epoch-14  lr=['0.0010000'], tr/val_loss:  1.294041/  1.742633, val:  57.08%, val_best:  60.83%, tr:  67.52%, tr_best:  67.52%\n",
      "epoch-15  lr=['0.0010000'], tr/val_loss:  1.298627/  1.634061, val:  66.67%, val_best:  66.67%, tr:  70.48%, tr_best:  70.48%\n",
      "epoch-16  lr=['0.0010000'], tr/val_loss:  1.304512/  1.671097, val:  60.42%, val_best:  66.67%, tr:  68.74%, tr_best:  70.48%\n",
      "epoch-17  lr=['0.0010000'], tr/val_loss:  1.280349/  1.659420, val:  63.75%, val_best:  66.67%, tr:  72.01%, tr_best:  72.01%\n",
      "epoch-18  lr=['0.0010000'], tr/val_loss:  1.272483/  1.746020, val:  62.92%, val_best:  66.67%, tr:  70.68%, tr_best:  72.01%\n",
      "epoch-19  lr=['0.0010000'], tr/val_loss:  1.275153/  1.760296, val:  59.58%, val_best:  66.67%, tr:  71.40%, tr_best:  72.01%\n",
      "epoch-20  lr=['0.0010000'], tr/val_loss:  1.265674/  1.770445, val:  63.75%, val_best:  66.67%, tr:  72.73%, tr_best:  72.73%\n",
      "epoch-21  lr=['0.0010000'], tr/val_loss:  1.270551/  1.782897, val:  65.42%, val_best:  66.67%, tr:  73.95%, tr_best:  73.95%\n",
      "epoch-22  lr=['0.0010000'], tr/val_loss:  1.280797/  1.831736, val:  60.83%, val_best:  66.67%, tr:  73.44%, tr_best:  73.95%\n",
      "epoch-23  lr=['0.0010000'], tr/val_loss:  1.224959/  1.832835, val:  62.08%, val_best:  66.67%, tr:  76.00%, tr_best:  76.00%\n",
      "epoch-24  lr=['0.0010000'], tr/val_loss:  1.229332/  1.913006, val:  62.50%, val_best:  66.67%, tr:  77.22%, tr_best:  77.22%\n",
      "epoch-25  lr=['0.0010000'], tr/val_loss:  1.240600/  1.867247, val:  68.75%, val_best:  68.75%, tr:  76.81%, tr_best:  77.22%\n",
      "epoch-26  lr=['0.0010000'], tr/val_loss:  1.236686/  1.863925, val:  67.08%, val_best:  68.75%, tr:  77.94%, tr_best:  77.94%\n",
      "epoch-27  lr=['0.0010000'], tr/val_loss:  1.231740/  1.991286, val:  63.75%, val_best:  68.75%, tr:  78.75%, tr_best:  78.75%\n",
      "epoch-28  lr=['0.0010000'], tr/val_loss:  1.233746/  1.961849, val:  68.75%, val_best:  68.75%, tr:  79.47%, tr_best:  79.47%\n",
      "epoch-29  lr=['0.0010000'], tr/val_loss:  1.209592/  2.082444, val:  64.58%, val_best:  68.75%, tr:  80.49%, tr_best:  80.49%\n",
      "epoch-30  lr=['0.0010000'], tr/val_loss:  1.204179/  2.143058, val:  62.08%, val_best:  68.75%, tr:  83.35%, tr_best:  83.35%\n",
      "epoch-31  lr=['0.0010000'], tr/val_loss:  1.246820/  2.157331, val:  63.75%, val_best:  68.75%, tr:  80.18%, tr_best:  83.35%\n",
      "epoch-32  lr=['0.0010000'], tr/val_loss:  1.238074/  2.184934, val:  65.42%, val_best:  68.75%, tr:  81.31%, tr_best:  83.35%\n",
      "epoch-33  lr=['0.0010000'], tr/val_loss:  1.237233/  2.227991, val:  66.67%, val_best:  68.75%, tr:  82.74%, tr_best:  83.35%\n",
      "epoch-34  lr=['0.0010000'], tr/val_loss:  1.218516/  2.282267, val:  61.67%, val_best:  68.75%, tr:  84.88%, tr_best:  84.88%\n",
      "epoch-35  lr=['0.0010000'], tr/val_loss:  1.254595/  2.421817, val:  61.67%, val_best:  68.75%, tr:  80.49%, tr_best:  84.88%\n",
      "epoch-36  lr=['0.0010000'], tr/val_loss:  1.231102/  2.374397, val:  62.92%, val_best:  68.75%, tr:  84.07%, tr_best:  84.88%\n",
      "epoch-37  lr=['0.0010000'], tr/val_loss:  1.246766/  2.392906, val:  65.00%, val_best:  68.75%, tr:  84.78%, tr_best:  84.88%\n",
      "epoch-38  lr=['0.0010000'], tr/val_loss:  1.245117/  2.445349, val:  65.42%, val_best:  68.75%, tr:  86.31%, tr_best:  86.31%\n",
      "epoch-39  lr=['0.0010000'], tr/val_loss:  1.256379/  2.520648, val:  66.25%, val_best:  68.75%, tr:  87.03%, tr_best:  87.03%\n",
      "epoch-40  lr=['0.0010000'], tr/val_loss:  1.262652/  2.592531, val:  66.25%, val_best:  68.75%, tr:  86.21%, tr_best:  87.03%\n",
      "epoch-41  lr=['0.0010000'], tr/val_loss:  1.277169/  2.678485, val:  61.25%, val_best:  68.75%, tr:  87.64%, tr_best:  87.64%\n",
      "epoch-42  lr=['0.0010000'], tr/val_loss:  1.250988/  2.646416, val:  65.83%, val_best:  68.75%, tr:  88.97%, tr_best:  88.97%\n",
      "epoch-43  lr=['0.0010000'], tr/val_loss:  1.263422/  2.722022, val:  64.58%, val_best:  68.75%, tr:  88.76%, tr_best:  88.97%\n",
      "epoch-44  lr=['0.0010000'], tr/val_loss:  1.250061/  2.752165, val:  65.00%, val_best:  68.75%, tr:  89.89%, tr_best:  89.89%\n",
      "epoch-45  lr=['0.0010000'], tr/val_loss:  1.246642/  2.811404, val:  65.83%, val_best:  68.75%, tr:  89.48%, tr_best:  89.89%\n",
      "epoch-46  lr=['0.0010000'], tr/val_loss:  1.261109/  2.902057, val:  66.67%, val_best:  68.75%, tr:  89.99%, tr_best:  89.99%\n",
      "epoch-47  lr=['0.0010000'], tr/val_loss:  1.258367/  2.907105, val:  67.08%, val_best:  68.75%, tr:  90.91%, tr_best:  90.91%\n",
      "epoch-48  lr=['0.0010000'], tr/val_loss:  1.304595/  2.966496, val:  65.42%, val_best:  68.75%, tr:  91.62%, tr_best:  91.62%\n",
      "epoch-49  lr=['0.0010000'], tr/val_loss:  1.291531/  3.015284, val:  66.25%, val_best:  68.75%, tr:  90.40%, tr_best:  91.62%\n",
      "epoch-50  lr=['0.0010000'], tr/val_loss:  1.293955/  3.141480, val:  62.92%, val_best:  68.75%, tr:  91.32%, tr_best:  91.62%\n",
      "epoch-51  lr=['0.0010000'], tr/val_loss:  1.337783/  3.166044, val:  67.50%, val_best:  68.75%, tr:  89.79%, tr_best:  91.62%\n",
      "epoch-52  lr=['0.0010000'], tr/val_loss:  1.295871/  3.243957, val:  64.17%, val_best:  68.75%, tr:  92.54%, tr_best:  92.54%\n",
      "epoch-53  lr=['0.0010000'], tr/val_loss:  1.313455/  3.284660, val:  67.92%, val_best:  68.75%, tr:  92.03%, tr_best:  92.54%\n",
      "epoch-54  lr=['0.0010000'], tr/val_loss:  1.317765/  3.376307, val:  68.75%, val_best:  68.75%, tr:  92.34%, tr_best:  92.54%\n",
      "epoch-55  lr=['0.0010000'], tr/val_loss:  1.329301/  3.479470, val:  68.75%, val_best:  68.75%, tr:  91.73%, tr_best:  92.54%\n",
      "epoch-56  lr=['0.0010000'], tr/val_loss:  1.322903/  3.581122, val:  66.25%, val_best:  68.75%, tr:  93.77%, tr_best:  93.77%\n",
      "epoch-57  lr=['0.0010000'], tr/val_loss:  1.353824/  3.536725, val:  67.08%, val_best:  68.75%, tr:  92.44%, tr_best:  93.77%\n",
      "epoch-58  lr=['0.0010000'], tr/val_loss:  1.347081/  3.651284, val:  69.17%, val_best:  69.17%, tr:  91.42%, tr_best:  93.77%\n",
      "epoch-59  lr=['0.0010000'], tr/val_loss:  1.345018/  3.671752, val:  70.42%, val_best:  70.42%, tr:  93.67%, tr_best:  93.77%\n",
      "epoch-60  lr=['0.0010000'], tr/val_loss:  1.352741/  3.685092, val:  72.08%, val_best:  72.08%, tr:  93.67%, tr_best:  93.77%\n",
      "epoch-61  lr=['0.0010000'], tr/val_loss:  1.362739/  3.805773, val:  65.83%, val_best:  72.08%, tr:  94.18%, tr_best:  94.18%\n",
      "epoch-62  lr=['0.0010000'], tr/val_loss:  1.401058/  3.900979, val:  64.58%, val_best:  72.08%, tr:  93.67%, tr_best:  94.18%\n",
      "epoch-63  lr=['0.0010000'], tr/val_loss:  1.340815/  3.883210, val:  67.08%, val_best:  72.08%, tr:  94.99%, tr_best:  94.99%\n",
      "epoch-64  lr=['0.0010000'], tr/val_loss:  1.388240/  4.041090, val:  68.33%, val_best:  72.08%, tr:  92.95%, tr_best:  94.99%\n",
      "epoch-65  lr=['0.0010000'], tr/val_loss:  1.374563/  4.017573, val:  66.67%, val_best:  72.08%, tr:  93.97%, tr_best:  94.99%\n",
      "epoch-66  lr=['0.0010000'], tr/val_loss:  1.376930/  4.108985, val:  67.08%, val_best:  72.08%, tr:  94.28%, tr_best:  94.99%\n",
      "epoch-67  lr=['0.0010000'], tr/val_loss:  1.421473/  4.139065, val:  67.08%, val_best:  72.08%, tr:  94.38%, tr_best:  94.99%\n",
      "epoch-68  lr=['0.0010000'], tr/val_loss:  1.397636/  4.332170, val:  67.92%, val_best:  72.08%, tr:  94.48%, tr_best:  94.99%\n",
      "epoch-69  lr=['0.0010000'], tr/val_loss:  1.441104/  4.307713, val:  65.42%, val_best:  72.08%, tr:  93.56%, tr_best:  94.99%\n",
      "epoch-70  lr=['0.0010000'], tr/val_loss:  1.403979/  4.325988, val:  69.17%, val_best:  72.08%, tr:  95.40%, tr_best:  95.40%\n",
      "epoch-71  lr=['0.0010000'], tr/val_loss:  1.416526/  4.479855, val:  65.83%, val_best:  72.08%, tr:  94.18%, tr_best:  95.40%\n",
      "epoch-72  lr=['0.0010000'], tr/val_loss:  1.418312/  4.519227, val:  67.50%, val_best:  72.08%, tr:  95.10%, tr_best:  95.40%\n",
      "epoch-73  lr=['0.0010000'], tr/val_loss:  1.454190/  4.434769, val:  70.42%, val_best:  72.08%, tr:  94.28%, tr_best:  95.40%\n",
      "epoch-74  lr=['0.0010000'], tr/val_loss:  1.387105/  4.549036, val:  70.42%, val_best:  72.08%, tr:  95.81%, tr_best:  95.81%\n",
      "epoch-75  lr=['0.0010000'], tr/val_loss:  1.432407/  4.673056, val:  65.83%, val_best:  72.08%, tr:  94.48%, tr_best:  95.81%\n",
      "epoch-76  lr=['0.0010000'], tr/val_loss:  1.396946/  4.854704, val:  66.67%, val_best:  72.08%, tr:  95.61%, tr_best:  95.81%\n",
      "epoch-77  lr=['0.0010000'], tr/val_loss:  1.401379/  4.785906, val:  71.25%, val_best:  72.08%, tr:  95.10%, tr_best:  95.81%\n",
      "epoch-78  lr=['0.0010000'], tr/val_loss:  1.428124/  4.891007, val:  70.00%, val_best:  72.08%, tr:  94.59%, tr_best:  95.81%\n",
      "epoch-79  lr=['0.0010000'], tr/val_loss:  1.388427/  4.852261, val:  70.00%, val_best:  72.08%, tr:  96.12%, tr_best:  96.12%\n",
      "epoch-80  lr=['0.0010000'], tr/val_loss:  1.377656/  5.012600, val:  66.67%, val_best:  72.08%, tr:  95.81%, tr_best:  96.12%\n",
      "epoch-81  lr=['0.0010000'], tr/val_loss:  1.398011/  4.929044, val:  70.00%, val_best:  72.08%, tr:  95.61%, tr_best:  96.12%\n",
      "epoch-82  lr=['0.0010000'], tr/val_loss:  1.407977/  5.091597, val:  66.67%, val_best:  72.08%, tr:  95.81%, tr_best:  96.12%\n",
      "epoch-83  lr=['0.0010000'], tr/val_loss:  1.424639/  5.217146, val:  68.33%, val_best:  72.08%, tr:  95.81%, tr_best:  96.12%\n",
      "epoch-84  lr=['0.0010000'], tr/val_loss:  1.454949/  5.207861, val:  69.58%, val_best:  72.08%, tr:  96.63%, tr_best:  96.63%\n",
      "epoch-85  lr=['0.0010000'], tr/val_loss:  1.435362/  5.290154, val:  66.25%, val_best:  72.08%, tr:  97.14%, tr_best:  97.14%\n",
      "epoch-86  lr=['0.0010000'], tr/val_loss:  1.435105/  5.331820, val:  70.42%, val_best:  72.08%, tr:  95.91%, tr_best:  97.14%\n",
      "epoch-87  lr=['0.0010000'], tr/val_loss:  1.459584/  5.488632, val:  67.08%, val_best:  72.08%, tr:  95.81%, tr_best:  97.14%\n",
      "epoch-88  lr=['0.0010000'], tr/val_loss:  1.418352/  5.435036, val:  69.17%, val_best:  72.08%, tr:  96.94%, tr_best:  97.14%\n",
      "epoch-89  lr=['0.0010000'], tr/val_loss:  1.399766/  5.552534, val:  69.58%, val_best:  72.08%, tr:  96.83%, tr_best:  97.14%\n",
      "epoch-90  lr=['0.0010000'], tr/val_loss:  1.424972/  5.498280, val:  69.17%, val_best:  72.08%, tr:  97.04%, tr_best:  97.14%\n",
      "epoch-91  lr=['0.0010000'], tr/val_loss:  1.432758/  5.735713, val:  67.50%, val_best:  72.08%, tr:  96.53%, tr_best:  97.14%\n",
      "epoch-92  lr=['0.0010000'], tr/val_loss:  1.435318/  5.712155, val:  69.58%, val_best:  72.08%, tr:  96.83%, tr_best:  97.14%\n",
      "epoch-93  lr=['0.0010000'], tr/val_loss:  1.440660/  5.693712, val:  68.75%, val_best:  72.08%, tr:  96.53%, tr_best:  97.14%\n",
      "epoch-94  lr=['0.0010000'], tr/val_loss:  1.453702/  5.868421, val:  69.17%, val_best:  72.08%, tr:  96.83%, tr_best:  97.14%\n",
      "epoch-95  lr=['0.0010000'], tr/val_loss:  1.470503/  5.974334, val:  65.83%, val_best:  72.08%, tr:  96.22%, tr_best:  97.14%\n",
      "epoch-96  lr=['0.0010000'], tr/val_loss:  1.478259/  6.145544, val:  67.08%, val_best:  72.08%, tr:  96.63%, tr_best:  97.14%\n",
      "epoch-97  lr=['0.0010000'], tr/val_loss:  1.513734/  6.075477, val:  70.42%, val_best:  72.08%, tr:  94.89%, tr_best:  97.14%\n",
      "epoch-98  lr=['0.0010000'], tr/val_loss:  1.478986/  6.122235, val:  71.25%, val_best:  72.08%, tr:  97.24%, tr_best:  97.24%\n",
      "epoch-99  lr=['0.0010000'], tr/val_loss:  1.493304/  6.196062, val:  64.17%, val_best:  72.08%, tr:  96.53%, tr_best:  97.24%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4f048b4b69994649a4dc7706c37f0555",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.006 MB of 0.006 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>iter_acc</td><td>▁▃▄▄▅▆▆▃▆▇██▇▇▇█████▇▇███▇▇██▇██▆██▇▇▇██</td></tr><tr><td>summary_val_acc</td><td>▁▅▆▆▇▇▆▇▇▇▇█▇▇▇▇▇▇▇█▇▇███▇▇███▇██▇████▇█</td></tr><tr><td>tr_acc</td><td>▁▃▅▅▅▆▆▆▆▆▆▇▇▇▇▇▇▇▇█▇███████████████████</td></tr><tr><td>tr_epoch_loss</td><td>█▆▃▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▂▂▂▂▂▂▂▂▂▂▂▂▂▂▃▃▂▂▃▃</td></tr><tr><td>val_acc_best</td><td>▁▅▆▆▇▇▇▇▇▇▇█████████████████████████████</td></tr><tr><td>val_acc_now</td><td>▁▅▆▆▇▇▆▇▇▇▇█▇▇▇▇▇▇▇█▇▇███▇▇███▇██▇████▇█</td></tr><tr><td>val_loss</td><td>▂▁▁▁▁▁▁▁▁▁▁▁▂▂▂▂▂▃▃▃▃▄▄▄▄▄▅▅▅▆▆▆▆▆▇▇▇▇██</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>99</td></tr><tr><td>iter_acc</td><td>1.0</td></tr><tr><td>tr_acc</td><td>0.96527</td></tr><tr><td>tr_epoch_loss</td><td>1.4933</td></tr><tr><td>val_acc_best</td><td>0.72083</td></tr><tr><td>val_acc_now</td><td>0.64167</td></tr><tr><td>val_loss</td><td>6.19606</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">ethereal-sweep-1</strong> at: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/1l4xujl1' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/1l4xujl1</a><br/> View project at: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>/data2/bh_wandb/wandb/run-20250429_224422-1l4xujl1/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require(\"core\")`! See https://wandb.me/wandb-core for more information."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: iatcxhts with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBATCH: 16\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBN_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBPTT_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tDFA_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tIMAGE_SIZE: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tOTTT_input_trace_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tTIME: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tUDA_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \talpha_uda: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbias: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcfg: ['M', 'M', 200, 200]\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tchaching_on: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tconvTrue_fcFalse: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdata_path: /data2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tddp_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdenoise_on: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdvs_clipping: 5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdvs_duration: 100000\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepoch_num: 100\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \texclude_class: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \textra_train_dataset: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlast_lif: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.001\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_sg_width: 3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_decay: 0.5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_init: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_reset: 10000\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_threshold: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmerge_polarities: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmy_seed: 42\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnet_print: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_workers: 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer_what: SGD\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tpin_memory: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tpre_trained: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tpre_trained_path: net_save/save_now_net_weights_{unique_name}.pth\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \trate_coding: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tscheduler_name: no\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsingle_step: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsurrogate: hard_sigmoid\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_conv_kernel_size: 3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_conv_padding: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_conv_stride: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_trace_const1: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_trace_const2: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \ttdBN_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \ttrace_on: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \twhich_data: DVS_GESTURE_TONIC\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5a0779c9f47a45de81773952814c9000",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.011112794554274942, max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.19.10 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.17.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/data2/bh_wandb/wandb/run-20250429_225122-iatcxhts</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/iatcxhts' target=\"_blank\">super-sweep-2</a></strong> to <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/6pj3lh8j' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/6pj3lh8j</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/6pj3lh8j' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/6pj3lh8j</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/iatcxhts' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/iatcxhts</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'single_step' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'my_seed' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'TIME' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BATCH' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'IMAGE_SIZE' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'which_data' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'data_path' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'rate_coding' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_init' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_decay' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_threshold' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_reset' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_sg_width' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_conv_kernel_size' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_conv_stride' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_conv_padding' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_trace_const1' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_trace_const2' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'pre_trained' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'convTrue_fcFalse' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'cfg' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'net_print' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'pre_trained_path' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'learning_rate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'epoch_num' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'tdBN_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BN_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'surrogate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BPTT_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'optimizer_what' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'scheduler_name' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'ddp_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'dvs_clipping' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'dvs_duration' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'DFA_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'trace_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'OTTT_input_trace_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'exclude_class' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'merge_polarities' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'denoise_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'extra_train_dataset' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'num_workers' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'chaching_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'pin_memory' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'UDA_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'alpha_uda' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'bias' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'last_lif' was locked by 'sweep' (ignored update).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "param {'devices': '0', 'single_step': True, 'unique_name': 'main', 'my_seed': 42, 'TIME': 10, 'BATCH': 16, 'IMAGE_SIZE': 128, 'which_data': 'DVS_GESTURE_TONIC', 'data_path': '/data2', 'rate_coding': False, 'lif_layer_v_init': 0, 'lif_layer_v_decay': 0.5, 'lif_layer_v_threshold': 1, 'lif_layer_v_reset': 10000, 'lif_layer_sg_width': 3, 'synapse_conv_kernel_size': 3, 'synapse_conv_stride': 1, 'synapse_conv_padding': 1, 'synapse_trace_const1': 1, 'synapse_trace_const2': 0, 'pre_trained': False, 'convTrue_fcFalse': False, 'cfg': ['M', 'M', 200, 200], 'net_print': True, 'pre_trained_path': 'net_save/save_now_net_weights_{unique_name}.pth', 'learning_rate': 0.001, 'epoch_num': 100, 'tdBN_on': False, 'BN_on': False, 'surrogate': 'hard_sigmoid', 'BPTT_on': False, 'optimizer_what': 'SGD', 'scheduler_name': 'no', 'ddp_on': False, 'dvs_clipping': 5, 'dvs_duration': 100000, 'DFA_on': False, 'trace_on': True, 'OTTT_input_trace_on': False, 'exclude_class': True, 'merge_polarities': False, 'denoise_on': True, 'extra_train_dataset': 0, 'num_workers': 2, 'chaching_on': True, 'pin_memory': True, 'UDA_on': False, 'alpha_uda': 1, 'bias': True, 'last_lif': False, 'current epoch': 0} \n",
      "\n",
      "dataset_hash = 63cc597115630ec173f3099200061e53\n",
      "cache path exists\n",
      "\n",
      "device ==> cuda\n",
      "\n",
      "DataParallel(\n",
      "  (module): REBORN_MY_SNN_FC(\n",
      "    (layers): REBORN_MY_Sequential(\n",
      "      (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (2): DimChanger_for_FC()\n",
      "      (3): SYNAPSE_FC(in_features=2048, out_features=200, TIME=10, bias=True, sstep=True)\n",
      "      (4): LIF_layer(v_init=0, v_decay=0.5, v_threshold=1, v_reset=10000, sg_width=3, surrogate=hard_sigmoid, BPTT_on=False, trace_const1=1, trace_const2=0, TIME=10, sstep=True, trace_on=True)\n",
      "      (5): SYNAPSE_FC(in_features=200, out_features=200, TIME=10, bias=True, sstep=True)\n",
      "      (6): LIF_layer(v_init=0, v_decay=0.5, v_threshold=1, v_reset=10000, sg_width=3, surrogate=hard_sigmoid, BPTT_on=False, trace_const1=1, trace_const2=0, TIME=10, sstep=True, trace_on=True)\n",
      "      (7): SYNAPSE_FC(in_features=200, out_features=10, TIME=10, bias=True, sstep=True)\n",
      "    )\n",
      "  )\n",
      ")\n",
      "\n",
      "========================================================\n",
      "Trainable parameters: 452,010\n",
      "========================================================\n",
      "\n",
      "epoch-0   lr=['0.0010000'], tr/val_loss:  2.305365/  2.302841, val:  10.00%, val_best:  10.00%, tr:   8.17%, tr_best:   8.17%\n",
      "epoch-1   lr=['0.0010000'], tr/val_loss:  2.304994/  2.302639, val:  10.00%, val_best:  10.00%, tr:   7.66%, tr_best:   8.17%\n",
      "epoch-2   lr=['0.0010000'], tr/val_loss:  2.305079/  2.302667, val:  10.00%, val_best:  10.00%, tr:   8.99%, tr_best:   8.99%\n",
      "epoch-3   lr=['0.0010000'], tr/val_loss:  2.304731/  2.302708, val:  10.00%, val_best:  10.00%, tr:   8.38%, tr_best:   8.99%\n",
      "epoch-4   lr=['0.0010000'], tr/val_loss:  2.304833/  2.302682, val:  10.00%, val_best:  10.00%, tr:   7.87%, tr_best:   8.99%\n",
      "epoch-5   lr=['0.0010000'], tr/val_loss:  2.304569/  2.302663, val:  10.00%, val_best:  10.00%, tr:   7.87%, tr_best:   8.99%\n",
      "epoch-6   lr=['0.0010000'], tr/val_loss:  2.305086/  2.302687, val:  10.00%, val_best:  10.00%, tr:   9.70%, tr_best:   9.70%\n",
      "epoch-7   lr=['0.0010000'], tr/val_loss:  2.304632/  2.302694, val:  10.00%, val_best:  10.00%, tr:   7.46%, tr_best:   9.70%\n",
      "epoch-8   lr=['0.0010000'], tr/val_loss:  2.304545/  2.302613, val:  10.00%, val_best:  10.00%, tr:   8.17%, tr_best:   9.70%\n",
      "epoch-9   lr=['0.0010000'], tr/val_loss:  2.305080/  2.302782, val:  10.00%, val_best:  10.00%, tr:   9.19%, tr_best:   9.70%\n",
      "epoch-10  lr=['0.0010000'], tr/val_loss:  2.304688/  2.302772, val:  10.00%, val_best:  10.00%, tr:  10.01%, tr_best:  10.01%\n",
      "epoch-11  lr=['0.0010000'], tr/val_loss:  2.304834/  2.302622, val:  10.00%, val_best:  10.00%, tr:   8.17%, tr_best:  10.01%\n",
      "epoch-12  lr=['0.0010000'], tr/val_loss:  2.304284/  2.302666, val:  10.00%, val_best:  10.00%, tr:   9.50%, tr_best:  10.01%\n",
      "epoch-13  lr=['0.0010000'], tr/val_loss:  2.304813/  2.302634, val:  10.00%, val_best:  10.00%, tr:   9.09%, tr_best:  10.01%\n",
      "epoch-14  lr=['0.0010000'], tr/val_loss:  2.305231/  2.302722, val:  10.00%, val_best:  10.00%, tr:   8.78%, tr_best:  10.01%\n",
      "epoch-15  lr=['0.0010000'], tr/val_loss:  2.305301/  2.302723, val:  10.00%, val_best:  10.00%, tr:   8.38%, tr_best:  10.01%\n",
      "epoch-16  lr=['0.0010000'], tr/val_loss:  2.304772/  2.302634, val:  10.00%, val_best:  10.00%, tr:   8.27%, tr_best:  10.01%\n",
      "epoch-17  lr=['0.0010000'], tr/val_loss:  2.303716/  2.302659, val:  10.00%, val_best:  10.00%, tr:  10.01%, tr_best:  10.01%\n",
      "epoch-18  lr=['0.0010000'], tr/val_loss:  2.304624/  2.302669, val:  10.00%, val_best:  10.00%, tr:   9.30%, tr_best:  10.01%\n",
      "epoch-19  lr=['0.0010000'], tr/val_loss:  2.305880/  2.302768, val:  10.00%, val_best:  10.00%, tr:   8.48%, tr_best:  10.01%\n",
      "epoch-20  lr=['0.0010000'], tr/val_loss:  2.305089/  2.302728, val:  10.00%, val_best:  10.00%, tr:   9.60%, tr_best:  10.01%\n",
      "epoch-21  lr=['0.0010000'], tr/val_loss:  2.304662/  2.302646, val:  10.00%, val_best:  10.00%, tr:   9.40%, tr_best:  10.01%\n",
      "epoch-22  lr=['0.0010000'], tr/val_loss:  2.305019/  2.302714, val:  10.00%, val_best:  10.00%, tr:  10.32%, tr_best:  10.32%\n",
      "epoch-23  lr=['0.0010000'], tr/val_loss:  2.304242/  2.302678, val:  10.00%, val_best:  10.00%, tr:   8.68%, tr_best:  10.32%\n",
      "epoch-24  lr=['0.0010000'], tr/val_loss:  2.303980/  2.302631, val:  10.00%, val_best:  10.00%, tr:   7.66%, tr_best:  10.32%\n",
      "epoch-25  lr=['0.0010000'], tr/val_loss:  2.304494/  2.302676, val:  10.00%, val_best:  10.00%, tr:   8.17%, tr_best:  10.32%\n",
      "epoch-26  lr=['0.0010000'], tr/val_loss:  2.304318/  2.302692, val:  10.00%, val_best:  10.00%, tr:   8.38%, tr_best:  10.32%\n",
      "epoch-27  lr=['0.0010000'], tr/val_loss:  2.304585/  2.302743, val:  10.00%, val_best:  10.00%, tr:   7.97%, tr_best:  10.32%\n",
      "epoch-28  lr=['0.0010000'], tr/val_loss:  2.304604/  2.302687, val:  10.00%, val_best:  10.00%, tr:   7.46%, tr_best:  10.32%\n",
      "epoch-29  lr=['0.0010000'], tr/val_loss:  2.304065/  2.302622, val:  10.00%, val_best:  10.00%, tr:   9.70%, tr_best:  10.32%\n",
      "epoch-30  lr=['0.0010000'], tr/val_loss:  2.304437/  2.302634, val:  10.00%, val_best:  10.00%, tr:   7.87%, tr_best:  10.32%\n",
      "epoch-31  lr=['0.0010000'], tr/val_loss:  2.304662/  2.302706, val:  10.00%, val_best:  10.00%, tr:   7.25%, tr_best:  10.32%\n",
      "epoch-32  lr=['0.0010000'], tr/val_loss:  2.305145/  2.302731, val:  10.00%, val_best:  10.00%, tr:   7.87%, tr_best:  10.32%\n",
      "epoch-33  lr=['0.0010000'], tr/val_loss:  2.304735/  2.302727, val:  10.00%, val_best:  10.00%, tr:   8.58%, tr_best:  10.32%\n",
      "epoch-34  lr=['0.0010000'], tr/val_loss:  2.304953/  2.302632, val:  10.00%, val_best:  10.00%, tr:   8.78%, tr_best:  10.32%\n",
      "epoch-35  lr=['0.0010000'], tr/val_loss:  2.304517/  2.302745, val:  10.00%, val_best:  10.00%, tr:   9.40%, tr_best:  10.32%\n",
      "epoch-36  lr=['0.0010000'], tr/val_loss:  2.304946/  2.302701, val:  10.00%, val_best:  10.00%, tr:   8.68%, tr_best:  10.32%\n",
      "epoch-37  lr=['0.0010000'], tr/val_loss:  2.305197/  2.302687, val:  10.00%, val_best:  10.00%, tr:   8.89%, tr_best:  10.32%\n",
      "epoch-38  lr=['0.0010000'], tr/val_loss:  2.304106/  2.302715, val:  10.00%, val_best:  10.00%, tr:   8.99%, tr_best:  10.32%\n",
      "epoch-39  lr=['0.0010000'], tr/val_loss:  2.304535/  2.302683, val:  10.00%, val_best:  10.00%, tr:   9.40%, tr_best:  10.32%\n",
      "epoch-40  lr=['0.0010000'], tr/val_loss:  2.304653/  2.302674, val:  10.00%, val_best:  10.00%, tr:   8.99%, tr_best:  10.32%\n",
      "epoch-41  lr=['0.0010000'], tr/val_loss:  2.304348/  2.302677, val:  10.00%, val_best:  10.00%, tr:   9.60%, tr_best:  10.32%\n",
      "epoch-42  lr=['0.0010000'], tr/val_loss:  2.304514/  2.302729, val:  10.00%, val_best:  10.00%, tr:   9.19%, tr_best:  10.32%\n",
      "epoch-43  lr=['0.0010000'], tr/val_loss:  2.304611/  2.302673, val:  10.00%, val_best:  10.00%, tr:   8.89%, tr_best:  10.32%\n",
      "epoch-44  lr=['0.0010000'], tr/val_loss:  2.304545/  2.302760, val:  10.00%, val_best:  10.00%, tr:   8.17%, tr_best:  10.32%\n",
      "epoch-45  lr=['0.0010000'], tr/val_loss:  2.304274/  2.302822, val:  10.00%, val_best:  10.00%, tr:   9.30%, tr_best:  10.32%\n",
      "epoch-46  lr=['0.0010000'], tr/val_loss:  2.304114/  2.302626, val:  10.00%, val_best:  10.00%, tr:   9.09%, tr_best:  10.32%\n",
      "epoch-47  lr=['0.0010000'], tr/val_loss:  2.304720/  2.302717, val:  10.00%, val_best:  10.00%, tr:   8.48%, tr_best:  10.32%\n",
      "epoch-48  lr=['0.0010000'], tr/val_loss:  2.304052/  2.302806, val:  10.00%, val_best:  10.00%, tr:   9.81%, tr_best:  10.32%\n",
      "epoch-49  lr=['0.0010000'], tr/val_loss:  2.304631/  2.302734, val:  10.00%, val_best:  10.00%, tr:   9.60%, tr_best:  10.32%\n",
      "epoch-50  lr=['0.0010000'], tr/val_loss:  2.304856/  2.302790, val:  10.00%, val_best:  10.00%, tr:  10.11%, tr_best:  10.32%\n",
      "epoch-51  lr=['0.0010000'], tr/val_loss:  2.303980/  2.302723, val:  10.00%, val_best:  10.00%, tr:   8.38%, tr_best:  10.32%\n",
      "epoch-52  lr=['0.0010000'], tr/val_loss:  2.305447/  2.302761, val:  10.00%, val_best:  10.00%, tr:   7.87%, tr_best:  10.32%\n",
      "epoch-53  lr=['0.0010000'], tr/val_loss:  2.304740/  2.302716, val:  10.00%, val_best:  10.00%, tr:   8.48%, tr_best:  10.32%\n",
      "epoch-54  lr=['0.0010000'], tr/val_loss:  2.304604/  2.302668, val:  10.00%, val_best:  10.00%, tr:   9.40%, tr_best:  10.32%\n",
      "epoch-55  lr=['0.0010000'], tr/val_loss:  2.304554/  2.302632, val:  10.00%, val_best:  10.00%, tr:   7.35%, tr_best:  10.32%\n",
      "epoch-56  lr=['0.0010000'], tr/val_loss:  2.305324/  2.302709, val:  10.00%, val_best:  10.00%, tr:  10.01%, tr_best:  10.32%\n",
      "epoch-57  lr=['0.0010000'], tr/val_loss:  2.304349/  2.302676, val:  10.00%, val_best:  10.00%, tr:   8.07%, tr_best:  10.32%\n",
      "epoch-58  lr=['0.0010000'], tr/val_loss:  2.304797/  2.302742, val:  10.00%, val_best:  10.00%, tr:   9.40%, tr_best:  10.32%\n",
      "epoch-59  lr=['0.0010000'], tr/val_loss:  2.305519/  2.302842, val:  10.00%, val_best:  10.00%, tr:   9.50%, tr_best:  10.32%\n",
      "epoch-60  lr=['0.0010000'], tr/val_loss:  2.304214/  2.302650, val:  10.00%, val_best:  10.00%, tr:   7.87%, tr_best:  10.32%\n",
      "epoch-61  lr=['0.0010000'], tr/val_loss:  2.304307/  2.302675, val:  10.00%, val_best:  10.00%, tr:   9.09%, tr_best:  10.32%\n",
      "epoch-62  lr=['0.0010000'], tr/val_loss:  2.304764/  2.302663, val:  10.00%, val_best:  10.00%, tr:   8.99%, tr_best:  10.32%\n",
      "epoch-63  lr=['0.0010000'], tr/val_loss:  2.304623/  2.302703, val:  10.00%, val_best:  10.00%, tr:   9.30%, tr_best:  10.32%\n",
      "epoch-64  lr=['0.0010000'], tr/val_loss:  2.303885/  2.302848, val:  10.00%, val_best:  10.00%, tr:   9.09%, tr_best:  10.32%\n",
      "epoch-65  lr=['0.0010000'], tr/val_loss:  2.304417/  2.302755, val:  10.00%, val_best:  10.00%, tr:   9.30%, tr_best:  10.32%\n",
      "epoch-66  lr=['0.0010000'], tr/val_loss:  2.303841/  2.302698, val:  10.00%, val_best:  10.00%, tr:   9.09%, tr_best:  10.32%\n",
      "epoch-67  lr=['0.0010000'], tr/val_loss:  2.305081/  2.302692, val:  10.00%, val_best:  10.00%, tr:  10.01%, tr_best:  10.32%\n",
      "epoch-68  lr=['0.0010000'], tr/val_loss:  2.305073/  2.302701, val:  10.00%, val_best:  10.00%, tr:   9.30%, tr_best:  10.32%\n",
      "epoch-69  lr=['0.0010000'], tr/val_loss:  2.304717/  2.302645, val:  10.00%, val_best:  10.00%, tr:   8.99%, tr_best:  10.32%\n",
      "epoch-70  lr=['0.0010000'], tr/val_loss:  2.305171/  2.302620, val:  10.00%, val_best:  10.00%, tr:   8.38%, tr_best:  10.32%\n",
      "epoch-71  lr=['0.0010000'], tr/val_loss:  2.305242/  2.302688, val:  10.00%, val_best:  10.00%, tr:   8.48%, tr_best:  10.32%\n",
      "epoch-72  lr=['0.0010000'], tr/val_loss:  2.304678/  2.302624, val:  10.00%, val_best:  10.00%, tr:   8.58%, tr_best:  10.32%\n",
      "epoch-73  lr=['0.0010000'], tr/val_loss:  2.304676/  2.302652, val:  10.00%, val_best:  10.00%, tr:   8.48%, tr_best:  10.32%\n",
      "epoch-74  lr=['0.0010000'], tr/val_loss:  2.304883/  2.302660, val:  10.00%, val_best:  10.00%, tr:   9.30%, tr_best:  10.32%\n",
      "epoch-75  lr=['0.0010000'], tr/val_loss:  2.305337/  2.302700, val:  10.00%, val_best:  10.00%, tr:   9.19%, tr_best:  10.32%\n",
      "epoch-76  lr=['0.0010000'], tr/val_loss:  2.305019/  2.302656, val:  10.00%, val_best:  10.00%, tr:   8.17%, tr_best:  10.32%\n",
      "epoch-77  lr=['0.0010000'], tr/val_loss:  2.305215/  2.302638, val:  10.00%, val_best:  10.00%, tr:   8.89%, tr_best:  10.32%\n",
      "epoch-78  lr=['0.0010000'], tr/val_loss:  2.304676/  2.302660, val:  10.00%, val_best:  10.00%, tr:   9.09%, tr_best:  10.32%\n",
      "epoch-79  lr=['0.0010000'], tr/val_loss:  2.304999/  2.302665, val:  10.00%, val_best:  10.00%, tr:   9.81%, tr_best:  10.32%\n",
      "epoch-80  lr=['0.0010000'], tr/val_loss:  2.304617/  2.302732, val:  10.00%, val_best:  10.00%, tr:   7.35%, tr_best:  10.32%\n",
      "epoch-81  lr=['0.0010000'], tr/val_loss:  2.304430/  2.302707, val:  10.00%, val_best:  10.00%, tr:   7.66%, tr_best:  10.32%\n",
      "epoch-82  lr=['0.0010000'], tr/val_loss:  2.304436/  2.302796, val:  10.00%, val_best:  10.00%, tr:   9.30%, tr_best:  10.32%\n",
      "epoch-83  lr=['0.0010000'], tr/val_loss:  2.305023/  2.302669, val:  10.00%, val_best:  10.00%, tr:   7.66%, tr_best:  10.32%\n",
      "epoch-84  lr=['0.0010000'], tr/val_loss:  2.304577/  2.302758, val:  10.00%, val_best:  10.00%, tr:   8.89%, tr_best:  10.32%\n",
      "epoch-85  lr=['0.0010000'], tr/val_loss:  2.304359/  2.302626, val:  10.00%, val_best:  10.00%, tr:   8.07%, tr_best:  10.32%\n",
      "epoch-86  lr=['0.0010000'], tr/val_loss:  2.305443/  2.302771, val:  10.00%, val_best:  10.00%, tr:   8.17%, tr_best:  10.32%\n",
      "epoch-87  lr=['0.0010000'], tr/val_loss:  2.304418/  2.302737, val:  10.00%, val_best:  10.00%, tr:   8.78%, tr_best:  10.32%\n",
      "epoch-88  lr=['0.0010000'], tr/val_loss:  2.305364/  2.302662, val:  10.00%, val_best:  10.00%, tr:   8.68%, tr_best:  10.32%\n",
      "epoch-89  lr=['0.0010000'], tr/val_loss:  2.304665/  2.302694, val:  10.00%, val_best:  10.00%, tr:   8.89%, tr_best:  10.32%\n",
      "epoch-90  lr=['0.0010000'], tr/val_loss:  2.305019/  2.302693, val:  10.00%, val_best:  10.00%, tr:   8.38%, tr_best:  10.32%\n",
      "epoch-91  lr=['0.0010000'], tr/val_loss:  2.304266/  2.302669, val:  10.00%, val_best:  10.00%, tr:  10.21%, tr_best:  10.32%\n",
      "epoch-92  lr=['0.0010000'], tr/val_loss:  2.304705/  2.302684, val:  10.00%, val_best:  10.00%, tr:   9.40%, tr_best:  10.32%\n",
      "epoch-93  lr=['0.0010000'], tr/val_loss:  2.304860/  2.302634, val:  10.00%, val_best:  10.00%, tr:   8.68%, tr_best:  10.32%\n",
      "epoch-94  lr=['0.0010000'], tr/val_loss:  2.304419/  2.302675, val:  10.00%, val_best:  10.00%, tr:   8.89%, tr_best:  10.32%\n",
      "epoch-95  lr=['0.0010000'], tr/val_loss:  2.304308/  2.302676, val:  10.00%, val_best:  10.00%, tr:   8.17%, tr_best:  10.32%\n",
      "epoch-96  lr=['0.0010000'], tr/val_loss:  2.304734/  2.302685, val:  10.00%, val_best:  10.00%, tr:  10.11%, tr_best:  10.32%\n",
      "epoch-97  lr=['0.0010000'], tr/val_loss:  2.304735/  2.302724, val:  10.00%, val_best:  10.00%, tr:   9.09%, tr_best:  10.32%\n",
      "epoch-98  lr=['0.0010000'], tr/val_loss:  2.305681/  2.302760, val:  10.00%, val_best:  10.00%, tr:  10.11%, tr_best:  10.32%\n",
      "epoch-99  lr=['0.0010000'], tr/val_loss:  2.304706/  2.302780, val:  10.00%, val_best:  10.00%, tr:   9.50%, tr_best:  10.32%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fe99140ebda1437ab9f23a9a3a38eb64",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.006 MB of 0.006 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>iter_acc</td><td>▃▆▁▃▃▃▃▃▃▃▃▁▃▆▃▆▆▃██▃▃▁▃▁▃▁▃▃▁▃▆▃▁▁▁█▃▁▃</td></tr><tr><td>summary_val_acc</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>tr_acc</td><td>▃▅▂▁▆▇▅█▄▆▂▄▇▂▆▅▆▆▃▄▇▂▆▃▇▅▆█▄▄▆▅▇▆▅▅▅▆▃▅</td></tr><tr><td>tr_epoch_loss</td><td>▆▅▅▄▅▃▆▁█▄▂▃▂▆▄▆▄▄▄▄▄▇▄▃▇▃▃▅▆▄▆▆▅▃▄▃▄▄▃▄</td></tr><tr><td>val_acc_best</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_acc_now</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_loss</td><td>█▂▃▃▆▂▄▂▆▂▁▃▁▅▅▃▃▄▅▄▅▅▃▃█▃▅▃▁▁▄▂▂▇▅▅▃▃▃▄</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>99</td></tr><tr><td>iter_acc</td><td>0.0</td></tr><tr><td>tr_acc</td><td>0.09499</td></tr><tr><td>tr_epoch_loss</td><td>2.30471</td></tr><tr><td>val_acc_best</td><td>0.1</td></tr><tr><td>val_acc_now</td><td>0.1</td></tr><tr><td>val_loss</td><td>2.30278</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">super-sweep-2</strong> at: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/iatcxhts' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/iatcxhts</a><br/> View project at: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>/data2/bh_wandb/wandb/run-20250429_225122-iatcxhts/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require(\"core\")`! See https://wandb.me/wandb-core for more information."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: cu7nz3xf with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBATCH: 16\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBN_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBPTT_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tDFA_on: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tIMAGE_SIZE: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tOTTT_input_trace_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tTIME: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tUDA_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \talpha_uda: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbias: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcfg: ['M', 'M', 200, 200]\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tchaching_on: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tconvTrue_fcFalse: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdata_path: /data2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tddp_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdenoise_on: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdvs_clipping: 5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdvs_duration: 100000\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepoch_num: 100\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \texclude_class: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \textra_train_dataset: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlast_lif: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.001\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_sg_width: 4\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_decay: 0.5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_init: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_reset: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_threshold: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmerge_polarities: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmy_seed: 42\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnet_print: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_workers: 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer_what: SGD\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tpin_memory: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tpre_trained: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tpre_trained_path: net_save/save_now_net_weights_{unique_name}.pth\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \trate_coding: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tscheduler_name: no\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsingle_step: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsurrogate: hard_sigmoid\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_conv_kernel_size: 3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_conv_padding: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_conv_stride: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_trace_const1: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_trace_const2: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \ttdBN_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \ttrace_on: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \twhich_data: DVS_GESTURE_TONIC\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.19.10 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.17.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/data2/bh_wandb/wandb/run-20250429_225741-cu7nz3xf</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/cu7nz3xf' target=\"_blank\">true-sweep-6</a></strong> to <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/6pj3lh8j' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/6pj3lh8j</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/6pj3lh8j' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/6pj3lh8j</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/cu7nz3xf' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/cu7nz3xf</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'single_step' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'my_seed' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'TIME' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BATCH' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'IMAGE_SIZE' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'which_data' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'data_path' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'rate_coding' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_init' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_decay' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_threshold' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_reset' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_sg_width' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_conv_kernel_size' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_conv_stride' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_conv_padding' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_trace_const1' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_trace_const2' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'pre_trained' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'convTrue_fcFalse' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'cfg' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'net_print' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'pre_trained_path' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'learning_rate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'epoch_num' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'tdBN_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BN_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'surrogate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BPTT_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'optimizer_what' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'scheduler_name' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'ddp_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'dvs_clipping' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'dvs_duration' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'DFA_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'trace_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'OTTT_input_trace_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'exclude_class' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'merge_polarities' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'denoise_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'extra_train_dataset' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'num_workers' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'chaching_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'pin_memory' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'UDA_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'alpha_uda' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'bias' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'last_lif' was locked by 'sweep' (ignored update).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "param {'devices': '0', 'single_step': True, 'unique_name': 'main', 'my_seed': 42, 'TIME': 10, 'BATCH': 16, 'IMAGE_SIZE': 128, 'which_data': 'DVS_GESTURE_TONIC', 'data_path': '/data2', 'rate_coding': False, 'lif_layer_v_init': 0, 'lif_layer_v_decay': 0.5, 'lif_layer_v_threshold': 1, 'lif_layer_v_reset': 0, 'lif_layer_sg_width': 4, 'synapse_conv_kernel_size': 3, 'synapse_conv_stride': 1, 'synapse_conv_padding': 1, 'synapse_trace_const1': 1, 'synapse_trace_const2': 0, 'pre_trained': False, 'convTrue_fcFalse': False, 'cfg': ['M', 'M', 200, 200], 'net_print': True, 'pre_trained_path': 'net_save/save_now_net_weights_{unique_name}.pth', 'learning_rate': 0.001, 'epoch_num': 100, 'tdBN_on': False, 'BN_on': False, 'surrogate': 'hard_sigmoid', 'BPTT_on': False, 'optimizer_what': 'SGD', 'scheduler_name': 'no', 'ddp_on': False, 'dvs_clipping': 5, 'dvs_duration': 100000, 'DFA_on': True, 'trace_on': True, 'OTTT_input_trace_on': False, 'exclude_class': True, 'merge_polarities': False, 'denoise_on': True, 'extra_train_dataset': 0, 'num_workers': 2, 'chaching_on': True, 'pin_memory': True, 'UDA_on': False, 'alpha_uda': 1, 'bias': True, 'last_lif': False, 'current epoch': 0} \n",
      "\n",
      "dataset_hash = 63cc597115630ec173f3099200061e53\n",
      "cache path exists\n",
      "\n",
      "device ==> cuda\n",
      "\n",
      "DataParallel(\n",
      "  (module): REBORN_MY_SNN_FC(\n",
      "    (layers): REBORN_MY_Sequential(\n",
      "      (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (2): DimChanger_for_FC()\n",
      "      (3): SYNAPSE_FC(in_features=2048, out_features=200, TIME=10, bias=True, sstep=True)\n",
      "      (4): LIF_layer(v_init=0, v_decay=0.5, v_threshold=1, v_reset=0, sg_width=4, surrogate=hard_sigmoid, BPTT_on=False, trace_const1=1, trace_const2=0, TIME=10, sstep=True, trace_on=True)\n",
      "      (5): Feedback_Receiver()\n",
      "      (6): SYNAPSE_FC(in_features=200, out_features=200, TIME=10, bias=True, sstep=True)\n",
      "      (7): LIF_layer(v_init=0, v_decay=0.5, v_threshold=1, v_reset=0, sg_width=4, surrogate=hard_sigmoid, BPTT_on=False, trace_const1=1, trace_const2=0, TIME=10, sstep=True, trace_on=True)\n",
      "      (8): Feedback_Receiver()\n",
      "      (9): SYNAPSE_FC(in_features=200, out_features=10, TIME=10, bias=True, sstep=True)\n",
      "      (DFA_top): Top_Gradient()\n",
      "    )\n",
      "  )\n",
      ")\n",
      "\n",
      "========================================================\n",
      "Trainable parameters: 452,010\n",
      "========================================================\n",
      "\n",
      "epoch-0   lr=['0.0010000'], tr/val_loss:  2.305365/  2.302841, val:  10.00%, val_best:  10.00%, tr:   8.17%, tr_best:   8.17%\n",
      "[module.layers.5] weight_fb parameter count: 2,000\n",
      "[module.layers.8] weight_fb parameter count: 2,000\n",
      "epoch-1   lr=['0.0010000'], tr/val_loss:  2.304994/  2.302639, val:  10.00%, val_best:  10.00%, tr:   7.66%, tr_best:   8.17%\n",
      "epoch-2   lr=['0.0010000'], tr/val_loss:  2.305079/  2.302667, val:  10.00%, val_best:  10.00%, tr:   8.99%, tr_best:   8.99%\n",
      "epoch-3   lr=['0.0010000'], tr/val_loss:  2.304731/  2.302708, val:  10.00%, val_best:  10.00%, tr:   8.38%, tr_best:   8.99%\n",
      "epoch-4   lr=['0.0010000'], tr/val_loss:  2.304839/  2.302794, val:  10.00%, val_best:  10.00%, tr:   7.87%, tr_best:   8.99%\n",
      "epoch-5   lr=['0.0010000'], tr/val_loss:  2.302737/  2.291961, val:  19.58%, val_best:  19.58%, tr:   9.50%, tr_best:   9.50%\n",
      "epoch-6   lr=['0.0010000'], tr/val_loss:  2.266796/  2.236328, val:  20.42%, val_best:  20.42%, tr:  19.71%, tr_best:  19.71%\n",
      "epoch-7   lr=['0.0010000'], tr/val_loss:  2.186410/  2.161002, val:  32.50%, val_best:  32.50%, tr:  27.17%, tr_best:  27.17%\n",
      "epoch-8   lr=['0.0010000'], tr/val_loss:  2.082799/  2.067548, val:  41.67%, val_best:  41.67%, tr:  38.71%, tr_best:  38.71%\n",
      "epoch-9   lr=['0.0010000'], tr/val_loss:  1.952861/  1.940935, val:  45.42%, val_best:  45.42%, tr:  42.90%, tr_best:  42.90%\n",
      "epoch-10  lr=['0.0010000'], tr/val_loss:  1.800347/  1.811367, val:  54.58%, val_best:  54.58%, tr:  50.15%, tr_best:  50.15%\n",
      "epoch-11  lr=['0.0010000'], tr/val_loss:  1.656689/  1.702327, val:  57.50%, val_best:  57.50%, tr:  55.57%, tr_best:  55.57%\n",
      "epoch-12  lr=['0.0010000'], tr/val_loss:  1.545854/  1.619129, val:  59.17%, val_best:  59.17%, tr:  58.63%, tr_best:  58.63%\n",
      "epoch-13  lr=['0.0010000'], tr/val_loss:  1.451780/  1.549810, val:  60.00%, val_best:  60.00%, tr:  61.29%, tr_best:  61.29%\n",
      "epoch-14  lr=['0.0010000'], tr/val_loss:  1.375289/  1.512620, val:  62.50%, val_best:  62.50%, tr:  63.43%, tr_best:  63.43%\n",
      "epoch-15  lr=['0.0010000'], tr/val_loss:  1.323032/  1.492978, val:  58.75%, val_best:  62.50%, tr:  63.33%, tr_best:  63.43%\n",
      "epoch-16  lr=['0.0010000'], tr/val_loss:  1.273119/  1.465512, val:  60.83%, val_best:  62.50%, tr:  64.86%, tr_best:  64.86%\n",
      "epoch-17  lr=['0.0010000'], tr/val_loss:  1.245289/  1.448282, val:  62.08%, val_best:  62.50%, tr:  66.70%, tr_best:  66.70%\n",
      "epoch-18  lr=['0.0010000'], tr/val_loss:  1.220606/  1.445683, val:  60.00%, val_best:  62.50%, tr:  66.70%, tr_best:  66.70%\n",
      "epoch-19  lr=['0.0010000'], tr/val_loss:  1.192438/  1.437663, val:  60.83%, val_best:  62.50%, tr:  64.66%, tr_best:  66.70%\n",
      "epoch-20  lr=['0.0010000'], tr/val_loss:  1.176531/  1.428948, val:  59.58%, val_best:  62.50%, tr:  66.91%, tr_best:  66.91%\n",
      "epoch-21  lr=['0.0010000'], tr/val_loss:  1.159013/  1.412774, val:  62.92%, val_best:  62.92%, tr:  66.50%, tr_best:  66.91%\n",
      "epoch-22  lr=['0.0010000'], tr/val_loss:  1.143948/  1.435108, val:  62.50%, val_best:  62.92%, tr:  67.11%, tr_best:  67.11%\n",
      "epoch-23  lr=['0.0010000'], tr/val_loss:  1.125733/  1.415102, val:  60.83%, val_best:  62.92%, tr:  70.17%, tr_best:  70.17%\n",
      "epoch-24  lr=['0.0010000'], tr/val_loss:  1.111999/  1.396812, val:  60.83%, val_best:  62.92%, tr:  70.58%, tr_best:  70.58%\n",
      "epoch-25  lr=['0.0010000'], tr/val_loss:  1.099694/  1.402632, val:  60.83%, val_best:  62.92%, tr:  71.40%, tr_best:  71.40%\n",
      "epoch-26  lr=['0.0010000'], tr/val_loss:  1.086627/  1.393039, val:  64.17%, val_best:  64.17%, tr:  69.25%, tr_best:  71.40%\n",
      "epoch-27  lr=['0.0010000'], tr/val_loss:  1.067708/  1.403563, val:  64.17%, val_best:  64.17%, tr:  73.54%, tr_best:  73.54%\n",
      "epoch-28  lr=['0.0010000'], tr/val_loss:  1.069132/  1.383270, val:  63.33%, val_best:  64.17%, tr:  73.14%, tr_best:  73.54%\n",
      "epoch-29  lr=['0.0010000'], tr/val_loss:  1.051620/  1.393721, val:  61.67%, val_best:  64.17%, tr:  71.50%, tr_best:  73.54%\n",
      "epoch-30  lr=['0.0010000'], tr/val_loss:  1.040305/  1.388195, val:  64.58%, val_best:  64.58%, tr:  73.44%, tr_best:  73.54%\n",
      "epoch-31  lr=['0.0010000'], tr/val_loss:  1.027143/  1.387356, val:  62.08%, val_best:  64.58%, tr:  74.26%, tr_best:  74.26%\n",
      "epoch-32  lr=['0.0010000'], tr/val_loss:  1.014339/  1.402500, val:  64.17%, val_best:  64.58%, tr:  76.92%, tr_best:  76.92%\n",
      "epoch-33  lr=['0.0010000'], tr/val_loss:  1.010321/  1.391248, val:  65.00%, val_best:  65.00%, tr:  76.40%, tr_best:  76.92%\n",
      "epoch-34  lr=['0.0010000'], tr/val_loss:  0.988287/  1.369101, val:  64.17%, val_best:  65.00%, tr:  78.14%, tr_best:  78.14%\n",
      "epoch-35  lr=['0.0010000'], tr/val_loss:  0.977015/  1.396498, val:  62.92%, val_best:  65.00%, tr:  78.04%, tr_best:  78.14%\n",
      "epoch-36  lr=['0.0010000'], tr/val_loss:  0.970611/  1.389613, val:  62.08%, val_best:  65.00%, tr:  78.04%, tr_best:  78.14%\n",
      "epoch-37  lr=['0.0010000'], tr/val_loss:  0.955624/  1.369336, val:  66.25%, val_best:  66.25%, tr:  80.18%, tr_best:  80.18%\n",
      "epoch-38  lr=['0.0010000'], tr/val_loss:  0.943998/  1.370078, val:  68.33%, val_best:  68.33%, tr:  81.31%, tr_best:  81.31%\n",
      "epoch-39  lr=['0.0010000'], tr/val_loss:  0.935331/  1.356675, val:  68.75%, val_best:  68.75%, tr:  81.10%, tr_best:  81.31%\n",
      "epoch-40  lr=['0.0010000'], tr/val_loss:  0.919247/  1.366666, val:  70.42%, val_best:  70.42%, tr:  81.00%, tr_best:  81.31%\n",
      "epoch-41  lr=['0.0010000'], tr/val_loss:  0.916312/  1.358485, val:  67.50%, val_best:  70.42%, tr:  86.31%, tr_best:  86.31%\n",
      "epoch-42  lr=['0.0010000'], tr/val_loss:  0.896736/  1.373175, val:  65.42%, val_best:  70.42%, tr:  85.60%, tr_best:  86.31%\n",
      "epoch-43  lr=['0.0010000'], tr/val_loss:  0.887402/  1.384500, val:  69.17%, val_best:  70.42%, tr:  84.07%, tr_best:  86.31%\n",
      "epoch-44  lr=['0.0010000'], tr/val_loss:  0.888845/  1.361765, val:  73.33%, val_best:  73.33%, tr:  84.68%, tr_best:  86.31%\n",
      "epoch-45  lr=['0.0010000'], tr/val_loss:  0.868302/  1.368583, val:  66.25%, val_best:  73.33%, tr:  87.33%, tr_best:  87.33%\n",
      "epoch-46  lr=['0.0010000'], tr/val_loss:  0.859508/  1.387539, val:  69.58%, val_best:  73.33%, tr:  88.25%, tr_best:  88.25%\n",
      "epoch-47  lr=['0.0010000'], tr/val_loss:  0.855600/  1.371193, val:  68.75%, val_best:  73.33%, tr:  87.03%, tr_best:  88.25%\n",
      "epoch-48  lr=['0.0010000'], tr/val_loss:  0.840254/  1.384091, val:  67.50%, val_best:  73.33%, tr:  89.48%, tr_best:  89.48%\n",
      "epoch-49  lr=['0.0010000'], tr/val_loss:  0.838546/  1.383812, val:  69.58%, val_best:  73.33%, tr:  89.27%, tr_best:  89.48%\n",
      "epoch-50  lr=['0.0010000'], tr/val_loss:  0.822158/  1.403087, val:  71.25%, val_best:  73.33%, tr:  90.81%, tr_best:  90.81%\n",
      "epoch-51  lr=['0.0010000'], tr/val_loss:  0.807220/  1.395932, val:  70.83%, val_best:  73.33%, tr:  89.68%, tr_best:  90.81%\n",
      "epoch-52  lr=['0.0010000'], tr/val_loss:  0.803955/  1.389699, val:  68.33%, val_best:  73.33%, tr:  90.70%, tr_best:  90.81%\n",
      "epoch-53  lr=['0.0010000'], tr/val_loss:  0.801618/  1.392427, val:  70.00%, val_best:  73.33%, tr:  90.81%, tr_best:  90.81%\n",
      "epoch-54  lr=['0.0010000'], tr/val_loss:  0.785652/  1.395489, val:  70.83%, val_best:  73.33%, tr:  91.62%, tr_best:  91.62%\n",
      "epoch-55  lr=['0.0010000'], tr/val_loss:  0.779742/  1.404399, val:  70.00%, val_best:  73.33%, tr:  90.70%, tr_best:  91.62%\n",
      "epoch-56  lr=['0.0010000'], tr/val_loss:  0.763507/  1.405151, val:  69.58%, val_best:  73.33%, tr:  93.46%, tr_best:  93.46%\n",
      "epoch-57  lr=['0.0010000'], tr/val_loss:  0.762329/  1.396639, val:  69.58%, val_best:  73.33%, tr:  93.05%, tr_best:  93.46%\n",
      "epoch-58  lr=['0.0010000'], tr/val_loss:  0.747362/  1.429974, val:  65.00%, val_best:  73.33%, tr:  93.67%, tr_best:  93.67%\n",
      "epoch-59  lr=['0.0010000'], tr/val_loss:  0.737557/  1.411750, val:  70.42%, val_best:  73.33%, tr:  93.46%, tr_best:  93.67%\n",
      "epoch-60  lr=['0.0010000'], tr/val_loss:  0.728932/  1.427939, val:  70.83%, val_best:  73.33%, tr:  92.65%, tr_best:  93.67%\n",
      "epoch-61  lr=['0.0010000'], tr/val_loss:  0.722172/  1.435444, val:  70.83%, val_best:  73.33%, tr:  93.26%, tr_best:  93.67%\n",
      "epoch-62  lr=['0.0010000'], tr/val_loss:  0.716608/  1.442987, val:  69.58%, val_best:  73.33%, tr:  94.48%, tr_best:  94.48%\n",
      "epoch-63  lr=['0.0010000'], tr/val_loss:  0.704773/  1.434689, val:  72.08%, val_best:  73.33%, tr:  94.79%, tr_best:  94.79%\n",
      "epoch-64  lr=['0.0010000'], tr/val_loss:  0.689880/  1.466010, val:  70.00%, val_best:  73.33%, tr:  94.79%, tr_best:  94.79%\n",
      "epoch-65  lr=['0.0010000'], tr/val_loss:  0.680298/  1.454194, val:  70.83%, val_best:  73.33%, tr:  95.10%, tr_best:  95.10%\n",
      "epoch-66  lr=['0.0010000'], tr/val_loss:  0.682321/  1.444279, val:  71.67%, val_best:  73.33%, tr:  95.30%, tr_best:  95.30%\n",
      "epoch-67  lr=['0.0010000'], tr/val_loss:  0.675721/  1.438770, val:  70.83%, val_best:  73.33%, tr:  95.40%, tr_best:  95.40%\n",
      "epoch-68  lr=['0.0010000'], tr/val_loss:  0.659858/  1.446472, val:  72.50%, val_best:  73.33%, tr:  94.89%, tr_best:  95.40%\n",
      "epoch-69  lr=['0.0010000'], tr/val_loss:  0.650880/  1.450955, val:  71.25%, val_best:  73.33%, tr:  96.12%, tr_best:  96.12%\n",
      "epoch-70  lr=['0.0010000'], tr/val_loss:  0.652450/  1.463676, val:  72.50%, val_best:  73.33%, tr:  96.02%, tr_best:  96.12%\n",
      "epoch-71  lr=['0.0010000'], tr/val_loss:  0.642968/  1.457084, val:  72.08%, val_best:  73.33%, tr:  95.61%, tr_best:  96.12%\n",
      "epoch-72  lr=['0.0010000'], tr/val_loss:  0.626107/  1.469027, val:  72.08%, val_best:  73.33%, tr:  96.32%, tr_best:  96.32%\n",
      "epoch-73  lr=['0.0010000'], tr/val_loss:  0.629863/  1.464179, val:  74.17%, val_best:  74.17%, tr:  95.71%, tr_best:  96.32%\n",
      "epoch-74  lr=['0.0010000'], tr/val_loss:  0.611284/  1.451782, val:  72.92%, val_best:  74.17%, tr:  96.02%, tr_best:  96.32%\n",
      "epoch-75  lr=['0.0010000'], tr/val_loss:  0.614725/  1.447522, val:  73.33%, val_best:  74.17%, tr:  96.42%, tr_best:  96.42%\n",
      "epoch-76  lr=['0.0010000'], tr/val_loss:  0.597748/  1.474535, val:  73.33%, val_best:  74.17%, tr:  96.53%, tr_best:  96.53%\n",
      "epoch-77  lr=['0.0010000'], tr/val_loss:  0.601079/  1.483882, val:  72.08%, val_best:  74.17%, tr:  97.24%, tr_best:  97.24%\n",
      "epoch-78  lr=['0.0010000'], tr/val_loss:  0.592147/  1.485951, val:  74.58%, val_best:  74.58%, tr:  96.83%, tr_best:  97.24%\n",
      "epoch-79  lr=['0.0010000'], tr/val_loss:  0.587543/  1.485109, val:  74.17%, val_best:  74.58%, tr:  96.73%, tr_best:  97.24%\n",
      "epoch-80  lr=['0.0010000'], tr/val_loss:  0.572523/  1.490754, val:  73.33%, val_best:  74.58%, tr:  97.24%, tr_best:  97.24%\n",
      "epoch-81  lr=['0.0010000'], tr/val_loss:  0.574700/  1.492756, val:  72.92%, val_best:  74.58%, tr:  96.83%, tr_best:  97.24%\n",
      "epoch-82  lr=['0.0010000'], tr/val_loss:  0.567389/  1.518716, val:  74.17%, val_best:  74.58%, tr:  97.24%, tr_best:  97.24%\n",
      "epoch-83  lr=['0.0010000'], tr/val_loss:  0.558111/  1.504690, val:  75.42%, val_best:  75.42%, tr:  97.45%, tr_best:  97.45%\n",
      "epoch-84  lr=['0.0010000'], tr/val_loss:  0.555666/  1.512300, val:  75.00%, val_best:  75.42%, tr:  97.75%, tr_best:  97.75%\n",
      "epoch-85  lr=['0.0010000'], tr/val_loss:  0.552338/  1.533643, val:  72.92%, val_best:  75.42%, tr:  97.65%, tr_best:  97.75%\n",
      "epoch-86  lr=['0.0010000'], tr/val_loss:  0.544004/  1.517139, val:  75.83%, val_best:  75.83%, tr:  97.14%, tr_best:  97.75%\n",
      "epoch-87  lr=['0.0010000'], tr/val_loss:  0.540543/  1.517835, val:  74.58%, val_best:  75.83%, tr:  97.75%, tr_best:  97.75%\n",
      "epoch-88  lr=['0.0010000'], tr/val_loss:  0.528469/  1.526515, val:  75.83%, val_best:  75.83%, tr:  97.45%, tr_best:  97.75%\n",
      "epoch-89  lr=['0.0010000'], tr/val_loss:  0.513347/  1.561749, val:  72.50%, val_best:  75.83%, tr:  98.37%, tr_best:  98.37%\n",
      "epoch-90  lr=['0.0010000'], tr/val_loss:  0.518259/  1.546387, val:  77.92%, val_best:  77.92%, tr:  97.85%, tr_best:  98.37%\n",
      "epoch-91  lr=['0.0010000'], tr/val_loss:  0.505479/  1.547917, val:  75.00%, val_best:  77.92%, tr:  97.75%, tr_best:  98.37%\n",
      "epoch-92  lr=['0.0010000'], tr/val_loss:  0.499188/  1.575493, val:  73.33%, val_best:  77.92%, tr:  98.16%, tr_best:  98.37%\n",
      "epoch-93  lr=['0.0010000'], tr/val_loss:  0.503374/  1.576961, val:  75.00%, val_best:  77.92%, tr:  98.57%, tr_best:  98.57%\n",
      "epoch-94  lr=['0.0010000'], tr/val_loss:  0.491868/  1.591583, val:  71.67%, val_best:  77.92%, tr:  98.37%, tr_best:  98.57%\n",
      "epoch-95  lr=['0.0010000'], tr/val_loss:  0.491460/  1.566375, val:  73.75%, val_best:  77.92%, tr:  98.57%, tr_best:  98.57%\n",
      "epoch-96  lr=['0.0010000'], tr/val_loss:  0.482069/  1.604511, val:  74.58%, val_best:  77.92%, tr:  98.67%, tr_best:  98.67%\n",
      "epoch-97  lr=['0.0010000'], tr/val_loss:  0.487517/  1.577257, val:  74.58%, val_best:  77.92%, tr:  97.65%, tr_best:  98.67%\n",
      "epoch-98  lr=['0.0010000'], tr/val_loss:  0.475124/  1.609044, val:  71.67%, val_best:  77.92%, tr:  98.57%, tr_best:  98.67%\n",
      "epoch-99  lr=['0.0010000'], tr/val_loss:  0.475442/  1.591582, val:  74.58%, val_best:  77.92%, tr:  98.57%, tr_best:  98.67%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b16d283a91b74a17ab0daebc1bafd6d4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.006 MB of 0.006 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>iter_acc</td><td>▁▂▁▃▄▅▆▅▄▆▆▇▆▆▆▇█▇███▇▆██████▇██▇██▇████</td></tr><tr><td>summary_val_acc</td><td>▁▁▁▃▅▆▇▇▆▇▆▇▇▇▇▇▇▇█▇▇▇█▇████████████████</td></tr><tr><td>tr_acc</td><td>▁▁▁▂▄▅▅▆▅▆▆▆▆▆▆▇▇▇▇▇▇▇▇█████████████████</td></tr><tr><td>tr_epoch_loss</td><td>████▇▅▄▄▄▄▃▃▃▃▃▃▃▃▃▂▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_acc_best</td><td>▁▁▁▃▅▆▆▆▆▆▆▇▇▇▇▇▇▇██████████████████████</td></tr><tr><td>val_acc_now</td><td>▁▁▁▃▅▆▇▇▆▇▆▇▇▇▇▇▇▇█▇▇▇█▇████████████████</td></tr><tr><td>val_loss</td><td>███▇▅▃▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▂▂▂▂▂▂▂▂▂▂▃▃▃▃</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>99</td></tr><tr><td>iter_acc</td><td>1.0</td></tr><tr><td>tr_acc</td><td>0.9857</td></tr><tr><td>tr_epoch_loss</td><td>0.47544</td></tr><tr><td>val_acc_best</td><td>0.77917</td></tr><tr><td>val_acc_now</td><td>0.74583</td></tr><tr><td>val_loss</td><td>1.59158</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">true-sweep-6</strong> at: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/cu7nz3xf' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/cu7nz3xf</a><br/> View project at: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>/data2/bh_wandb/wandb/run-20250429_225741-cu7nz3xf/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require(\"core\")`! See https://wandb.me/wandb-core for more information."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: x7e1kz5v with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBATCH: 16\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBN_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBPTT_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tDFA_on: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tIMAGE_SIZE: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tOTTT_input_trace_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tTIME: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tUDA_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \talpha_uda: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbias: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcfg: ['M', 'M', 200, 200]\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tchaching_on: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tconvTrue_fcFalse: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdata_path: /data2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tddp_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdenoise_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdvs_clipping: 5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdvs_duration: 100000\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepoch_num: 100\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \texclude_class: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \textra_train_dataset: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlast_lif: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_sg_width: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_decay: 0.5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_init: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_reset: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_threshold: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmerge_polarities: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmy_seed: 42\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnet_print: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_workers: 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer_what: SGD\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tpin_memory: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tpre_trained: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tpre_trained_path: net_save/save_now_net_weights_{unique_name}.pth\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \trate_coding: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tscheduler_name: no\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsingle_step: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsurrogate: hard_sigmoid\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_conv_kernel_size: 3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_conv_padding: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_conv_stride: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_trace_const1: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_trace_const2: 0.5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \ttdBN_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \ttrace_on: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \twhich_data: DVS_GESTURE_TONIC\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.19.10 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.17.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/data2/bh_wandb/wandb/run-20250429_230439-x7e1kz5v</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/x7e1kz5v' target=\"_blank\">ancient-sweep-10</a></strong> to <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/6pj3lh8j' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/6pj3lh8j</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/6pj3lh8j' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/6pj3lh8j</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/x7e1kz5v' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/x7e1kz5v</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'single_step' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'my_seed' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'TIME' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BATCH' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'IMAGE_SIZE' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'which_data' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'data_path' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'rate_coding' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_init' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_decay' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_threshold' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_reset' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_sg_width' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_conv_kernel_size' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_conv_stride' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_conv_padding' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_trace_const1' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_trace_const2' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'pre_trained' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'convTrue_fcFalse' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'cfg' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'net_print' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'pre_trained_path' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'learning_rate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'epoch_num' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'tdBN_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BN_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'surrogate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BPTT_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'optimizer_what' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'scheduler_name' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'ddp_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'dvs_clipping' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'dvs_duration' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'DFA_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'trace_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'OTTT_input_trace_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'exclude_class' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'merge_polarities' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'denoise_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'extra_train_dataset' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'num_workers' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'chaching_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'pin_memory' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'UDA_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'alpha_uda' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'bias' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'last_lif' was locked by 'sweep' (ignored update).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "param {'devices': '0', 'single_step': True, 'unique_name': 'main', 'my_seed': 42, 'TIME': 10, 'BATCH': 16, 'IMAGE_SIZE': 128, 'which_data': 'DVS_GESTURE_TONIC', 'data_path': '/data2', 'rate_coding': False, 'lif_layer_v_init': 0, 'lif_layer_v_decay': 0.5, 'lif_layer_v_threshold': 1, 'lif_layer_v_reset': 0, 'lif_layer_sg_width': 1, 'synapse_conv_kernel_size': 3, 'synapse_conv_stride': 1, 'synapse_conv_padding': 1, 'synapse_trace_const1': 1, 'synapse_trace_const2': 0.5, 'pre_trained': False, 'convTrue_fcFalse': False, 'cfg': ['M', 'M', 200, 200], 'net_print': True, 'pre_trained_path': 'net_save/save_now_net_weights_{unique_name}.pth', 'learning_rate': 0.1, 'epoch_num': 100, 'tdBN_on': False, 'BN_on': False, 'surrogate': 'hard_sigmoid', 'BPTT_on': False, 'optimizer_what': 'SGD', 'scheduler_name': 'no', 'ddp_on': False, 'dvs_clipping': 5, 'dvs_duration': 100000, 'DFA_on': True, 'trace_on': True, 'OTTT_input_trace_on': False, 'exclude_class': True, 'merge_polarities': False, 'denoise_on': False, 'extra_train_dataset': 0, 'num_workers': 2, 'chaching_on': True, 'pin_memory': True, 'UDA_on': False, 'alpha_uda': 1, 'bias': True, 'last_lif': False, 'current epoch': 0} \n",
      "\n",
      "dataset_hash = ffa516e60c3efd5e0208f72b4c36cb84\n",
      "cache path exists\n",
      "\n",
      "device ==> cuda\n",
      "\n",
      "DataParallel(\n",
      "  (module): REBORN_MY_SNN_FC(\n",
      "    (layers): REBORN_MY_Sequential(\n",
      "      (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (2): DimChanger_for_FC()\n",
      "      (3): SYNAPSE_FC(in_features=2048, out_features=200, TIME=10, bias=True, sstep=True)\n",
      "      (4): LIF_layer(v_init=0, v_decay=0.5, v_threshold=1, v_reset=0, sg_width=1, surrogate=hard_sigmoid, BPTT_on=False, trace_const1=1, trace_const2=0.5, TIME=10, sstep=True, trace_on=True)\n",
      "      (5): Feedback_Receiver()\n",
      "      (6): SYNAPSE_FC(in_features=200, out_features=200, TIME=10, bias=True, sstep=True)\n",
      "      (7): LIF_layer(v_init=0, v_decay=0.5, v_threshold=1, v_reset=0, sg_width=1, surrogate=hard_sigmoid, BPTT_on=False, trace_const1=1, trace_const2=0.5, TIME=10, sstep=True, trace_on=True)\n",
      "      (8): Feedback_Receiver()\n",
      "      (9): SYNAPSE_FC(in_features=200, out_features=10, TIME=10, bias=True, sstep=True)\n",
      "      (DFA_top): Top_Gradient()\n",
      "    )\n",
      "  )\n",
      ")\n",
      "\n",
      "========================================================\n",
      "Trainable parameters: 452,010\n",
      "========================================================\n",
      "\n",
      "epoch-0   lr=['0.1000000'], tr/val_loss: 29.879858/ 31.615450, val:  45.83%, val_best:  45.83%, tr:  30.95%, tr_best:  30.95%\n",
      "[module.layers.5] weight_fb parameter count: 2,000\n",
      "[module.layers.8] weight_fb parameter count: 2,000\n",
      "epoch-1   lr=['0.1000000'], tr/val_loss: 33.371964/ 45.426868, val:  35.83%, val_best:  45.83%, tr:  46.68%, tr_best:  46.68%\n",
      "epoch-2   lr=['0.1000000'], tr/val_loss: 28.679071/ 57.514214, val:  44.58%, val_best:  45.83%, tr:  55.77%, tr_best:  55.77%\n",
      "epoch-3   lr=['0.1000000'], tr/val_loss: 23.436556/ 24.415396, val:  46.25%, val_best:  46.25%, tr:  59.55%, tr_best:  59.55%\n",
      "epoch-4   lr=['0.1000000'], tr/val_loss: 23.693298/ 30.292583, val:  52.92%, val_best:  52.92%, tr:  60.67%, tr_best:  60.67%\n",
      "epoch-5   lr=['0.1000000'], tr/val_loss: 20.294081/ 38.452087, val:  45.83%, val_best:  52.92%, tr:  66.70%, tr_best:  66.70%\n",
      "epoch-6   lr=['0.1000000'], tr/val_loss: 21.617590/ 57.379242, val:  45.42%, val_best:  52.92%, tr:  68.13%, tr_best:  68.13%\n",
      "epoch-7   lr=['0.1000000'], tr/val_loss: 17.848648/ 29.760067, val:  57.08%, val_best:  57.08%, tr:  75.49%, tr_best:  75.49%\n",
      "epoch-8   lr=['0.1000000'], tr/val_loss:  9.283427/ 35.843269, val:  52.50%, val_best:  57.08%, tr:  84.58%, tr_best:  84.58%\n",
      "epoch-9   lr=['0.1000000'], tr/val_loss: 11.984549/ 40.241844, val:  57.08%, val_best:  57.08%, tr:  82.12%, tr_best:  84.58%\n",
      "epoch-10  lr=['0.1000000'], tr/val_loss:  6.687328/ 29.908276, val:  64.58%, val_best:  64.58%, tr:  90.70%, tr_best:  90.70%\n",
      "epoch-11  lr=['0.1000000'], tr/val_loss:  8.765985/ 38.871761, val:  62.08%, val_best:  64.58%, tr:  89.38%, tr_best:  90.70%\n",
      "epoch-12  lr=['0.1000000'], tr/val_loss:  7.927548/ 32.538330, val:  71.67%, val_best:  71.67%, tr:  91.32%, tr_best:  91.32%\n",
      "epoch-13  lr=['0.1000000'], tr/val_loss:  3.912651/ 38.555603, val:  68.75%, val_best:  71.67%, tr:  96.63%, tr_best:  96.63%\n",
      "epoch-14  lr=['0.1000000'], tr/val_loss:  3.279613/ 32.887962, val:  71.67%, val_best:  71.67%, tr:  96.63%, tr_best:  96.63%\n",
      "epoch-15  lr=['0.1000000'], tr/val_loss:  1.799478/ 34.948174, val:  72.92%, val_best:  72.92%, tr:  99.39%, tr_best:  99.39%\n",
      "epoch-16  lr=['0.1000000'], tr/val_loss:  1.985378/ 36.374863, val:  69.58%, val_best:  72.92%, tr:  98.77%, tr_best:  99.39%\n",
      "epoch-17  lr=['0.1000000'], tr/val_loss:  1.356374/ 37.117691, val:  71.67%, val_best:  72.92%, tr:  99.49%, tr_best:  99.49%\n",
      "epoch-18  lr=['0.1000000'], tr/val_loss:  1.017890/ 44.007404, val:  64.58%, val_best:  72.92%, tr:  99.49%, tr_best:  99.49%\n",
      "epoch-19  lr=['0.1000000'], tr/val_loss:  1.173206/ 40.852608, val:  66.67%, val_best:  72.92%, tr:  99.39%, tr_best:  99.49%\n",
      "epoch-20  lr=['0.1000000'], tr/val_loss:  0.900242/ 40.415623, val:  71.25%, val_best:  72.92%, tr:  99.69%, tr_best:  99.69%\n",
      "epoch-21  lr=['0.1000000'], tr/val_loss:  0.541370/ 43.854206, val:  66.67%, val_best:  72.92%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-22  lr=['0.1000000'], tr/val_loss:  0.592321/ 39.077549, val:  71.67%, val_best:  72.92%, tr:  99.90%, tr_best: 100.00%\n",
      "epoch-23  lr=['0.1000000'], tr/val_loss:  0.363730/ 41.116138, val:  71.67%, val_best:  72.92%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-24  lr=['0.1000000'], tr/val_loss:  0.407622/ 41.446712, val:  72.92%, val_best:  72.92%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-25  lr=['0.1000000'], tr/val_loss:  0.288420/ 39.479931, val:  78.75%, val_best:  78.75%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-26  lr=['0.1000000'], tr/val_loss:  0.219051/ 41.564606, val:  70.83%, val_best:  78.75%, tr:  99.90%, tr_best: 100.00%\n",
      "epoch-27  lr=['0.1000000'], tr/val_loss:  0.174149/ 43.476994, val:  70.00%, val_best:  78.75%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-28  lr=['0.1000000'], tr/val_loss:  0.150421/ 44.598354, val:  70.42%, val_best:  78.75%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-29  lr=['0.1000000'], tr/val_loss:  0.127835/ 44.381828, val:  70.42%, val_best:  78.75%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-30  lr=['0.1000000'], tr/val_loss:  0.140420/ 42.947418, val:  73.33%, val_best:  78.75%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-31  lr=['0.1000000'], tr/val_loss:  0.078586/ 43.551060, val:  72.50%, val_best:  78.75%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-32  lr=['0.1000000'], tr/val_loss:  0.072278/ 42.843456, val:  70.83%, val_best:  78.75%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-33  lr=['0.1000000'], tr/val_loss:  0.059192/ 42.404335, val:  73.75%, val_best:  78.75%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-34  lr=['0.1000000'], tr/val_loss:  0.126562/ 42.094753, val:  73.33%, val_best:  78.75%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-35  lr=['0.1000000'], tr/val_loss:  0.112375/ 42.086998, val:  73.75%, val_best:  78.75%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-36  lr=['0.1000000'], tr/val_loss:  0.082133/ 43.725006, val:  69.58%, val_best:  78.75%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-37  lr=['0.1000000'], tr/val_loss:  0.081661/ 42.724571, val:  73.33%, val_best:  78.75%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-38  lr=['0.1000000'], tr/val_loss:  0.057426/ 42.698368, val:  72.92%, val_best:  78.75%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-39  lr=['0.1000000'], tr/val_loss:  0.067734/ 43.164097, val:  73.75%, val_best:  78.75%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-40  lr=['0.1000000'], tr/val_loss:  0.048547/ 42.896149, val:  75.00%, val_best:  78.75%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-41  lr=['0.1000000'], tr/val_loss:  0.019912/ 43.550926, val:  73.75%, val_best:  78.75%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-42  lr=['0.1000000'], tr/val_loss:  0.059032/ 44.030510, val:  72.92%, val_best:  78.75%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-43  lr=['0.1000000'], tr/val_loss:  0.037523/ 42.928650, val:  74.17%, val_best:  78.75%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-44  lr=['0.1000000'], tr/val_loss:  0.016735/ 43.013725, val:  75.00%, val_best:  78.75%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-45  lr=['0.1000000'], tr/val_loss:  0.018932/ 42.581688, val:  74.58%, val_best:  78.75%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-46  lr=['0.1000000'], tr/val_loss:  0.009740/ 42.362766, val:  75.00%, val_best:  78.75%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-47  lr=['0.1000000'], tr/val_loss:  0.015773/ 41.860405, val:  74.58%, val_best:  78.75%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-48  lr=['0.1000000'], tr/val_loss:  0.020481/ 42.954605, val:  73.75%, val_best:  78.75%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-49  lr=['0.1000000'], tr/val_loss:  0.033010/ 43.681210, val:  72.92%, val_best:  78.75%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-50  lr=['0.1000000'], tr/val_loss:  0.005543/ 43.044777, val:  75.42%, val_best:  78.75%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-51  lr=['0.1000000'], tr/val_loss:  0.011057/ 43.333565, val:  75.42%, val_best:  78.75%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-52  lr=['0.1000000'], tr/val_loss:  0.003481/ 42.913025, val:  75.83%, val_best:  78.75%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-53  lr=['0.1000000'], tr/val_loss:  0.000498/ 43.222038, val:  75.00%, val_best:  78.75%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-54  lr=['0.1000000'], tr/val_loss:  0.013435/ 44.209045, val:  74.17%, val_best:  78.75%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-55  lr=['0.1000000'], tr/val_loss:  0.010039/ 44.261753, val:  75.42%, val_best:  78.75%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-56  lr=['0.1000000'], tr/val_loss:  0.009703/ 44.063133, val:  73.33%, val_best:  78.75%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-57  lr=['0.1000000'], tr/val_loss:  0.013619/ 44.388954, val:  74.17%, val_best:  78.75%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-58  lr=['0.1000000'], tr/val_loss:  0.019828/ 44.084007, val:  73.33%, val_best:  78.75%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-59  lr=['0.1000000'], tr/val_loss:  0.004536/ 44.331226, val:  74.58%, val_best:  78.75%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-60  lr=['0.1000000'], tr/val_loss:  0.006158/ 44.807205, val:  73.75%, val_best:  78.75%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-61  lr=['0.1000000'], tr/val_loss:  0.000643/ 44.172161, val:  73.75%, val_best:  78.75%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-62  lr=['0.1000000'], tr/val_loss:  0.000477/ 44.167534, val:  74.17%, val_best:  78.75%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-63  lr=['0.1000000'], tr/val_loss:  0.004103/ 44.302326, val:  74.17%, val_best:  78.75%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-64  lr=['0.1000000'], tr/val_loss:  0.001610/ 42.780766, val:  75.00%, val_best:  78.75%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-65  lr=['0.1000000'], tr/val_loss:  0.003766/ 43.418415, val:  75.83%, val_best:  78.75%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-66  lr=['0.1000000'], tr/val_loss:  0.000259/ 43.756886, val:  74.17%, val_best:  78.75%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-67  lr=['0.1000000'], tr/val_loss:  0.006089/ 43.305786, val:  74.17%, val_best:  78.75%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-68  lr=['0.1000000'], tr/val_loss:  0.002902/ 43.571651, val:  74.58%, val_best:  78.75%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-69  lr=['0.1000000'], tr/val_loss:  0.002188/ 44.048588, val:  75.00%, val_best:  78.75%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-70  lr=['0.1000000'], tr/val_loss:  0.006528/ 43.952259, val:  74.17%, val_best:  78.75%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-71  lr=['0.1000000'], tr/val_loss:  0.003694/ 42.731987, val:  75.42%, val_best:  78.75%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-72  lr=['0.1000000'], tr/val_loss:  0.006250/ 42.952518, val:  74.17%, val_best:  78.75%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-73  lr=['0.1000000'], tr/val_loss:  0.001616/ 43.495808, val:  74.58%, val_best:  78.75%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-74  lr=['0.1000000'], tr/val_loss:  0.015354/ 43.714046, val:  74.17%, val_best:  78.75%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-75  lr=['0.1000000'], tr/val_loss:  0.045851/ 43.358055, val:  75.42%, val_best:  78.75%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-76  lr=['0.1000000'], tr/val_loss:  0.050539/ 43.853794, val:  75.83%, val_best:  78.75%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-77  lr=['0.1000000'], tr/val_loss:  0.014420/ 43.029251, val:  74.58%, val_best:  78.75%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-78  lr=['0.1000000'], tr/val_loss:  0.015146/ 44.758801, val:  74.17%, val_best:  78.75%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-79  lr=['0.1000000'], tr/val_loss:  0.006251/ 43.950184, val:  74.58%, val_best:  78.75%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-80  lr=['0.1000000'], tr/val_loss:  0.015824/ 44.630325, val:  74.17%, val_best:  78.75%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-81  lr=['0.1000000'], tr/val_loss:  0.006753/ 45.104126, val:  74.58%, val_best:  78.75%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-82  lr=['0.1000000'], tr/val_loss:  0.015272/ 43.859962, val:  73.75%, val_best:  78.75%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-83  lr=['0.1000000'], tr/val_loss:  0.019360/ 45.182346, val:  73.33%, val_best:  78.75%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-84  lr=['0.1000000'], tr/val_loss:  0.004346/ 44.534771, val:  76.25%, val_best:  78.75%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-85  lr=['0.1000000'], tr/val_loss:  0.004878/ 45.103001, val:  74.58%, val_best:  78.75%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-86  lr=['0.1000000'], tr/val_loss:  0.009593/ 44.689152, val:  73.33%, val_best:  78.75%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-87  lr=['0.1000000'], tr/val_loss:  0.002651/ 44.524273, val:  73.33%, val_best:  78.75%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-88  lr=['0.1000000'], tr/val_loss:  0.003139/ 44.131935, val:  72.92%, val_best:  78.75%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-89  lr=['0.1000000'], tr/val_loss:  0.000103/ 44.271065, val:  74.58%, val_best:  78.75%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-90  lr=['0.1000000'], tr/val_loss:  0.000005/ 44.297775, val:  74.58%, val_best:  78.75%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-91  lr=['0.1000000'], tr/val_loss:  0.000003/ 44.283569, val:  74.58%, val_best:  78.75%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-92  lr=['0.1000000'], tr/val_loss:  0.000001/ 44.283699, val:  74.58%, val_best:  78.75%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-93  lr=['0.1000000'], tr/val_loss:  0.000001/ 44.283848, val:  74.17%, val_best:  78.75%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-94  lr=['0.1000000'], tr/val_loss:  0.000001/ 44.296982, val:  74.17%, val_best:  78.75%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-95  lr=['0.1000000'], tr/val_loss:  0.000001/ 44.324516, val:  74.17%, val_best:  78.75%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-96  lr=['0.1000000'], tr/val_loss:  0.000001/ 44.324650, val:  74.17%, val_best:  78.75%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-97  lr=['0.1000000'], tr/val_loss:  0.000001/ 44.349743, val:  74.17%, val_best:  78.75%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-98  lr=['0.1000000'], tr/val_loss:  0.000001/ 44.349800, val:  74.17%, val_best:  78.75%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-99  lr=['0.1000000'], tr/val_loss:  0.000001/ 44.339436, val:  74.17%, val_best:  78.75%, tr: 100.00%, tr_best: 100.00%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a5bdc00642434816bc35473f86ed1301",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.006 MB of 0.006 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>iter_acc</td><td>▁▅▅▆▇▇██████████████████████████████████</td></tr><tr><td>summary_val_acc</td><td>▁▁▃▄▄▇▇▇▆▆▇▇▇▇▇▇▇▇██▇████▇███████▇█▇████</td></tr><tr><td>tr_acc</td><td>▁▄▄▆▆▇██████████████████████████████████</td></tr><tr><td>tr_epoch_loss</td><td>██▇▅▄▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_acc_best</td><td>▁▁▃▃▃▆▆▇▇▇▇█████████████████████████████</td></tr><tr><td>val_acc_now</td><td>▁▁▃▄▄▇▇▇▆▆▇▇▇▇▇▇▇▇██▇████▇███████▇█▇████</td></tr><tr><td>val_loss</td><td>▁█▁▁▄▂▂▃▄▅▄▄▅▄▄▄▄▅▄▄▅▄▅▅▅▅▄▄▅▄▄▄▅▅▅▅▅▅▅▅</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>99</td></tr><tr><td>iter_acc</td><td>1.0</td></tr><tr><td>tr_acc</td><td>1.0</td></tr><tr><td>tr_epoch_loss</td><td>0.0</td></tr><tr><td>val_acc_best</td><td>0.7875</td></tr><tr><td>val_acc_now</td><td>0.74167</td></tr><tr><td>val_loss</td><td>44.33944</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">ancient-sweep-10</strong> at: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/x7e1kz5v' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/x7e1kz5v</a><br/> View project at: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>/data2/bh_wandb/wandb/run-20250429_230439-x7e1kz5v/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require(\"core\")`! See https://wandb.me/wandb-core for more information."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: lz43gll7 with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBATCH: 16\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBN_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBPTT_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tDFA_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tIMAGE_SIZE: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tOTTT_input_trace_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tTIME: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tUDA_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \talpha_uda: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbias: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcfg: ['M', 'M', 200, 200]\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tchaching_on: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tconvTrue_fcFalse: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdata_path: /data2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tddp_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdenoise_on: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdvs_clipping: 5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdvs_duration: 100000\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepoch_num: 100\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \texclude_class: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \textra_train_dataset: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlast_lif: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.0001\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_sg_width: 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_decay: 0.5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_init: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_reset: 10000\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_threshold: 0.25\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmerge_polarities: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmy_seed: 42\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnet_print: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_workers: 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer_what: SGD\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tpin_memory: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tpre_trained: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tpre_trained_path: net_save/save_now_net_weights_{unique_name}.pth\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \trate_coding: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tscheduler_name: no\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsingle_step: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsurrogate: hard_sigmoid\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_conv_kernel_size: 3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_conv_padding: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_conv_stride: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_trace_const1: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_trace_const2: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \ttdBN_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \ttrace_on: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \twhich_data: DVS_GESTURE_TONIC\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cc9273eb4c254e51b30f815159e3b0a6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.011112875455162591, max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.19.10 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.17.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/data2/bh_wandb/wandb/run-20250429_231152-lz43gll7</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/lz43gll7' target=\"_blank\">pleasant-sweep-14</a></strong> to <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/6pj3lh8j' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/6pj3lh8j</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/6pj3lh8j' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/6pj3lh8j</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/lz43gll7' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/lz43gll7</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'single_step' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'my_seed' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'TIME' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BATCH' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'IMAGE_SIZE' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'which_data' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'data_path' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'rate_coding' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_init' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_decay' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_threshold' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_reset' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_sg_width' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_conv_kernel_size' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_conv_stride' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_conv_padding' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_trace_const1' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_trace_const2' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'pre_trained' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'convTrue_fcFalse' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'cfg' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'net_print' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'pre_trained_path' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'learning_rate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'epoch_num' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'tdBN_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BN_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'surrogate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BPTT_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'optimizer_what' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'scheduler_name' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'ddp_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'dvs_clipping' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'dvs_duration' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'DFA_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'trace_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'OTTT_input_trace_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'exclude_class' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'merge_polarities' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'denoise_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'extra_train_dataset' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'num_workers' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'chaching_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'pin_memory' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'UDA_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'alpha_uda' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'bias' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'last_lif' was locked by 'sweep' (ignored update).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "param {'devices': '0', 'single_step': True, 'unique_name': 'main', 'my_seed': 42, 'TIME': 10, 'BATCH': 16, 'IMAGE_SIZE': 128, 'which_data': 'DVS_GESTURE_TONIC', 'data_path': '/data2', 'rate_coding': False, 'lif_layer_v_init': 0, 'lif_layer_v_decay': 0.5, 'lif_layer_v_threshold': 0.25, 'lif_layer_v_reset': 10000, 'lif_layer_sg_width': 2, 'synapse_conv_kernel_size': 3, 'synapse_conv_stride': 1, 'synapse_conv_padding': 1, 'synapse_trace_const1': 1, 'synapse_trace_const2': 0, 'pre_trained': False, 'convTrue_fcFalse': False, 'cfg': ['M', 'M', 200, 200], 'net_print': True, 'pre_trained_path': 'net_save/save_now_net_weights_{unique_name}.pth', 'learning_rate': 0.0001, 'epoch_num': 100, 'tdBN_on': False, 'BN_on': False, 'surrogate': 'hard_sigmoid', 'BPTT_on': False, 'optimizer_what': 'SGD', 'scheduler_name': 'no', 'ddp_on': False, 'dvs_clipping': 5, 'dvs_duration': 100000, 'DFA_on': False, 'trace_on': True, 'OTTT_input_trace_on': False, 'exclude_class': True, 'merge_polarities': False, 'denoise_on': True, 'extra_train_dataset': 0, 'num_workers': 2, 'chaching_on': True, 'pin_memory': True, 'UDA_on': False, 'alpha_uda': 1, 'bias': True, 'last_lif': False, 'current epoch': 0} \n",
      "\n",
      "dataset_hash = 63cc597115630ec173f3099200061e53\n",
      "cache path exists\n",
      "\n",
      "device ==> cuda\n",
      "\n",
      "DataParallel(\n",
      "  (module): REBORN_MY_SNN_FC(\n",
      "    (layers): REBORN_MY_Sequential(\n",
      "      (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (2): DimChanger_for_FC()\n",
      "      (3): SYNAPSE_FC(in_features=2048, out_features=200, TIME=10, bias=True, sstep=True)\n",
      "      (4): LIF_layer(v_init=0, v_decay=0.5, v_threshold=0.25, v_reset=10000, sg_width=2, surrogate=hard_sigmoid, BPTT_on=False, trace_const1=1, trace_const2=0, TIME=10, sstep=True, trace_on=True)\n",
      "      (5): SYNAPSE_FC(in_features=200, out_features=200, TIME=10, bias=True, sstep=True)\n",
      "      (6): LIF_layer(v_init=0, v_decay=0.5, v_threshold=0.25, v_reset=10000, sg_width=2, surrogate=hard_sigmoid, BPTT_on=False, trace_const1=1, trace_const2=0, TIME=10, sstep=True, trace_on=True)\n",
      "      (7): SYNAPSE_FC(in_features=200, out_features=10, TIME=10, bias=True, sstep=True)\n",
      "    )\n",
      "  )\n",
      ")\n",
      "\n",
      "========================================================\n",
      "Trainable parameters: 452,010\n",
      "========================================================\n",
      "\n",
      "epoch-0   lr=['0.0001000'], tr/val_loss:  2.302907/  2.296743, val:  12.08%, val_best:  12.08%, tr:  10.83%, tr_best:  10.83%\n",
      "epoch-1   lr=['0.0001000'], tr/val_loss:  2.294978/  2.288502, val:  16.25%, val_best:  16.25%, tr:  13.69%, tr_best:  13.69%\n",
      "epoch-2   lr=['0.0001000'], tr/val_loss:  2.284689/  2.279992, val:  22.92%, val_best:  22.92%, tr:  19.00%, tr_best:  19.00%\n",
      "epoch-3   lr=['0.0001000'], tr/val_loss:  2.275359/  2.271681, val:  22.50%, val_best:  22.92%, tr:  21.35%, tr_best:  21.35%\n",
      "epoch-4   lr=['0.0001000'], tr/val_loss:  2.263038/  2.262436, val:  25.42%, val_best:  25.42%, tr:  23.29%, tr_best:  23.29%\n",
      "epoch-5   lr=['0.0001000'], tr/val_loss:  2.247669/  2.249031, val:  27.92%, val_best:  27.92%, tr:  26.05%, tr_best:  26.05%\n",
      "epoch-6   lr=['0.0001000'], tr/val_loss:  2.231451/  2.234944, val:  29.58%, val_best:  29.58%, tr:  26.46%, tr_best:  26.46%\n",
      "epoch-7   lr=['0.0001000'], tr/val_loss:  2.210301/  2.217033, val:  29.17%, val_best:  29.58%, tr:  29.11%, tr_best:  29.11%\n",
      "epoch-8   lr=['0.0001000'], tr/val_loss:  2.188026/  2.197682, val:  31.25%, val_best:  31.25%, tr:  29.62%, tr_best:  29.62%\n",
      "epoch-9   lr=['0.0001000'], tr/val_loss:  2.163206/  2.175425, val:  34.58%, val_best:  34.58%, tr:  33.30%, tr_best:  33.30%\n",
      "epoch-10  lr=['0.0001000'], tr/val_loss:  2.136193/  2.150481, val:  37.50%, val_best:  37.50%, tr:  35.96%, tr_best:  35.96%\n",
      "epoch-11  lr=['0.0001000'], tr/val_loss:  2.103683/  2.121968, val:  38.33%, val_best:  38.33%, tr:  38.20%, tr_best:  38.20%\n",
      "epoch-12  lr=['0.0001000'], tr/val_loss:  2.069489/  2.095511, val:  41.25%, val_best:  41.25%, tr:  39.84%, tr_best:  39.84%\n",
      "epoch-13  lr=['0.0001000'], tr/val_loss:  2.035892/  2.063807, val:  42.92%, val_best:  42.92%, tr:  41.88%, tr_best:  41.88%\n",
      "epoch-14  lr=['0.0001000'], tr/val_loss:  2.000726/  2.029665, val:  45.83%, val_best:  45.83%, tr:  45.15%, tr_best:  45.15%\n",
      "epoch-15  lr=['0.0001000'], tr/val_loss:  1.959698/  1.998897, val:  48.75%, val_best:  48.75%, tr:  48.83%, tr_best:  48.83%\n",
      "epoch-16  lr=['0.0001000'], tr/val_loss:  1.925897/  1.969909, val:  49.58%, val_best:  49.58%, tr:  51.07%, tr_best:  51.07%\n",
      "epoch-17  lr=['0.0001000'], tr/val_loss:  1.888945/  1.936733, val:  53.33%, val_best:  53.33%, tr:  52.81%, tr_best:  52.81%\n",
      "epoch-18  lr=['0.0001000'], tr/val_loss:  1.848015/  1.907367, val:  52.50%, val_best:  53.33%, tr:  53.83%, tr_best:  53.83%\n",
      "epoch-19  lr=['0.0001000'], tr/val_loss:  1.809786/  1.877003, val:  51.25%, val_best:  53.33%, tr:  54.95%, tr_best:  54.95%\n",
      "epoch-20  lr=['0.0001000'], tr/val_loss:  1.775795/  1.852512, val:  53.75%, val_best:  53.75%, tr:  54.24%, tr_best:  54.95%\n",
      "epoch-21  lr=['0.0001000'], tr/val_loss:  1.745774/  1.829192, val:  52.50%, val_best:  53.75%, tr:  54.95%, tr_best:  54.95%\n",
      "epoch-22  lr=['0.0001000'], tr/val_loss:  1.720607/  1.808592, val:  52.50%, val_best:  53.75%, tr:  53.93%, tr_best:  54.95%\n",
      "epoch-23  lr=['0.0001000'], tr/val_loss:  1.691234/  1.787951, val:  52.50%, val_best:  53.75%, tr:  56.49%, tr_best:  56.49%\n",
      "epoch-24  lr=['0.0001000'], tr/val_loss:  1.665395/  1.769258, val:  54.58%, val_best:  54.58%, tr:  56.89%, tr_best:  56.89%\n",
      "epoch-25  lr=['0.0001000'], tr/val_loss:  1.645854/  1.750288, val:  55.42%, val_best:  55.42%, tr:  58.22%, tr_best:  58.22%\n",
      "epoch-26  lr=['0.0001000'], tr/val_loss:  1.622282/  1.733912, val:  55.83%, val_best:  55.83%, tr:  57.81%, tr_best:  58.22%\n",
      "epoch-27  lr=['0.0001000'], tr/val_loss:  1.602769/  1.714053, val:  55.83%, val_best:  55.83%, tr:  59.24%, tr_best:  59.24%\n",
      "epoch-28  lr=['0.0001000'], tr/val_loss:  1.585672/  1.702372, val:  56.25%, val_best:  56.25%, tr:  58.84%, tr_best:  59.24%\n",
      "epoch-29  lr=['0.0001000'], tr/val_loss:  1.562534/  1.690184, val:  55.83%, val_best:  56.25%, tr:  60.16%, tr_best:  60.16%\n",
      "epoch-30  lr=['0.0001000'], tr/val_loss:  1.550799/  1.677646, val:  56.25%, val_best:  56.25%, tr:  61.18%, tr_best:  61.18%\n",
      "epoch-31  lr=['0.0001000'], tr/val_loss:  1.533682/  1.666141, val:  56.25%, val_best:  56.25%, tr:  61.90%, tr_best:  61.90%\n",
      "epoch-32  lr=['0.0001000'], tr/val_loss:  1.517917/  1.652647, val:  56.25%, val_best:  56.25%, tr:  61.29%, tr_best:  61.90%\n",
      "epoch-33  lr=['0.0001000'], tr/val_loss:  1.507646/  1.642300, val:  54.17%, val_best:  56.25%, tr:  62.00%, tr_best:  62.00%\n",
      "epoch-34  lr=['0.0001000'], tr/val_loss:  1.491886/  1.633879, val:  53.33%, val_best:  56.25%, tr:  62.61%, tr_best:  62.61%\n",
      "epoch-35  lr=['0.0001000'], tr/val_loss:  1.471412/  1.618985, val:  57.08%, val_best:  57.08%, tr:  63.33%, tr_best:  63.33%\n",
      "epoch-36  lr=['0.0001000'], tr/val_loss:  1.460201/  1.610234, val:  55.83%, val_best:  57.08%, tr:  64.15%, tr_best:  64.15%\n",
      "epoch-37  lr=['0.0001000'], tr/val_loss:  1.451613/  1.602866, val:  55.00%, val_best:  57.08%, tr:  63.33%, tr_best:  64.15%\n",
      "epoch-38  lr=['0.0001000'], tr/val_loss:  1.440631/  1.595351, val:  57.08%, val_best:  57.08%, tr:  64.25%, tr_best:  64.25%\n",
      "epoch-39  lr=['0.0001000'], tr/val_loss:  1.434736/  1.588397, val:  60.42%, val_best:  60.42%, tr:  66.29%, tr_best:  66.29%\n",
      "epoch-40  lr=['0.0001000'], tr/val_loss:  1.418308/  1.580901, val:  55.42%, val_best:  60.42%, tr:  65.17%, tr_best:  66.29%\n",
      "epoch-41  lr=['0.0001000'], tr/val_loss:  1.411523/  1.573812, val:  58.33%, val_best:  60.42%, tr:  65.78%, tr_best:  66.29%\n",
      "epoch-42  lr=['0.0001000'], tr/val_loss:  1.396141/  1.564894, val:  59.58%, val_best:  60.42%, tr:  67.62%, tr_best:  67.62%\n",
      "epoch-43  lr=['0.0001000'], tr/val_loss:  1.393835/  1.560242, val:  58.33%, val_best:  60.42%, tr:  65.47%, tr_best:  67.62%\n",
      "epoch-44  lr=['0.0001000'], tr/val_loss:  1.383113/  1.556955, val:  57.92%, val_best:  60.42%, tr:  66.91%, tr_best:  67.62%\n",
      "epoch-45  lr=['0.0001000'], tr/val_loss:  1.373974/  1.552594, val:  58.33%, val_best:  60.42%, tr:  65.17%, tr_best:  67.62%\n",
      "epoch-46  lr=['0.0001000'], tr/val_loss:  1.362819/  1.543871, val:  56.67%, val_best:  60.42%, tr:  66.19%, tr_best:  67.62%\n",
      "epoch-47  lr=['0.0001000'], tr/val_loss:  1.357147/  1.539963, val:  58.75%, val_best:  60.42%, tr:  65.27%, tr_best:  67.62%\n",
      "epoch-48  lr=['0.0001000'], tr/val_loss:  1.349937/  1.535955, val:  60.00%, val_best:  60.42%, tr:  66.09%, tr_best:  67.62%\n",
      "epoch-49  lr=['0.0001000'], tr/val_loss:  1.346611/  1.530923, val:  61.67%, val_best:  61.67%, tr:  66.09%, tr_best:  67.62%\n",
      "epoch-50  lr=['0.0001000'], tr/val_loss:  1.337984/  1.527953, val:  57.92%, val_best:  61.67%, tr:  66.39%, tr_best:  67.62%\n",
      "epoch-51  lr=['0.0001000'], tr/val_loss:  1.326526/  1.527076, val:  61.25%, val_best:  61.67%, tr:  67.01%, tr_best:  67.62%\n",
      "epoch-52  lr=['0.0001000'], tr/val_loss:  1.315937/  1.522934, val:  58.75%, val_best:  61.67%, tr:  65.99%, tr_best:  67.62%\n",
      "epoch-53  lr=['0.0001000'], tr/val_loss:  1.310394/  1.520520, val:  60.83%, val_best:  61.67%, tr:  66.70%, tr_best:  67.62%\n",
      "epoch-54  lr=['0.0001000'], tr/val_loss:  1.307748/  1.515431, val:  57.08%, val_best:  61.67%, tr:  67.01%, tr_best:  67.62%\n",
      "epoch-55  lr=['0.0001000'], tr/val_loss:  1.299515/  1.513005, val:  59.58%, val_best:  61.67%, tr:  67.62%, tr_best:  67.62%\n",
      "epoch-56  lr=['0.0001000'], tr/val_loss:  1.287158/  1.506526, val:  59.58%, val_best:  61.67%, tr:  68.74%, tr_best:  68.74%\n",
      "epoch-57  lr=['0.0001000'], tr/val_loss:  1.291148/  1.504784, val:  60.42%, val_best:  61.67%, tr:  67.93%, tr_best:  68.74%\n",
      "epoch-58  lr=['0.0001000'], tr/val_loss:  1.278179/  1.502209, val:  58.75%, val_best:  61.67%, tr:  65.88%, tr_best:  68.74%\n",
      "epoch-59  lr=['0.0001000'], tr/val_loss:  1.282839/  1.497111, val:  60.42%, val_best:  61.67%, tr:  68.03%, tr_best:  68.74%\n",
      "epoch-60  lr=['0.0001000'], tr/val_loss:  1.275139/  1.492711, val:  59.58%, val_best:  61.67%, tr:  67.21%, tr_best:  68.74%\n",
      "epoch-61  lr=['0.0001000'], tr/val_loss:  1.278045/  1.486848, val:  61.67%, val_best:  61.67%, tr:  68.85%, tr_best:  68.85%\n",
      "epoch-62  lr=['0.0001000'], tr/val_loss:  1.268203/  1.485847, val:  59.58%, val_best:  61.67%, tr:  67.11%, tr_best:  68.85%\n",
      "epoch-63  lr=['0.0001000'], tr/val_loss:  1.256680/  1.484136, val:  61.25%, val_best:  61.67%, tr:  68.54%, tr_best:  68.85%\n",
      "epoch-64  lr=['0.0001000'], tr/val_loss:  1.247974/  1.476497, val:  59.58%, val_best:  61.67%, tr:  68.23%, tr_best:  68.85%\n",
      "epoch-65  lr=['0.0001000'], tr/val_loss:  1.246373/  1.470107, val:  60.00%, val_best:  61.67%, tr:  67.72%, tr_best:  68.85%\n",
      "epoch-66  lr=['0.0001000'], tr/val_loss:  1.245154/  1.467065, val:  61.25%, val_best:  61.67%, tr:  68.03%, tr_best:  68.85%\n",
      "epoch-67  lr=['0.0001000'], tr/val_loss:  1.242852/  1.462414, val:  61.25%, val_best:  61.67%, tr:  67.72%, tr_best:  68.85%\n",
      "epoch-68  lr=['0.0001000'], tr/val_loss:  1.230946/  1.461125, val:  60.83%, val_best:  61.67%, tr:  66.50%, tr_best:  68.85%\n",
      "epoch-69  lr=['0.0001000'], tr/val_loss:  1.232190/  1.453219, val:  61.67%, val_best:  61.67%, tr:  69.77%, tr_best:  69.77%\n",
      "epoch-70  lr=['0.0001000'], tr/val_loss:  1.227567/  1.449157, val:  62.08%, val_best:  62.08%, tr:  68.44%, tr_best:  69.77%\n",
      "epoch-71  lr=['0.0001000'], tr/val_loss:  1.217608/  1.445405, val:  61.25%, val_best:  62.08%, tr:  68.54%, tr_best:  69.77%\n",
      "epoch-72  lr=['0.0001000'], tr/val_loss:  1.214511/  1.445487, val:  62.92%, val_best:  62.92%, tr:  69.36%, tr_best:  69.77%\n",
      "epoch-73  lr=['0.0001000'], tr/val_loss:  1.207814/  1.438363, val:  60.42%, val_best:  62.92%, tr:  69.36%, tr_best:  69.77%\n",
      "epoch-74  lr=['0.0001000'], tr/val_loss:  1.200150/  1.438542, val:  62.08%, val_best:  62.92%, tr:  67.72%, tr_best:  69.77%\n",
      "epoch-75  lr=['0.0001000'], tr/val_loss:  1.198524/  1.433012, val:  62.50%, val_best:  62.92%, tr:  69.05%, tr_best:  69.77%\n",
      "epoch-76  lr=['0.0001000'], tr/val_loss:  1.194222/  1.428229, val:  64.17%, val_best:  64.17%, tr:  69.77%, tr_best:  69.77%\n",
      "epoch-77  lr=['0.0001000'], tr/val_loss:  1.194941/  1.425523, val:  61.25%, val_best:  64.17%, tr:  70.68%, tr_best:  70.68%\n",
      "epoch-78  lr=['0.0001000'], tr/val_loss:  1.187627/  1.422026, val:  60.42%, val_best:  64.17%, tr:  69.46%, tr_best:  70.68%\n",
      "epoch-79  lr=['0.0001000'], tr/val_loss:  1.190353/  1.421590, val:  61.67%, val_best:  64.17%, tr:  69.77%, tr_best:  70.68%\n",
      "epoch-80  lr=['0.0001000'], tr/val_loss:  1.179118/  1.420461, val:  61.25%, val_best:  64.17%, tr:  69.25%, tr_best:  70.68%\n",
      "epoch-81  lr=['0.0001000'], tr/val_loss:  1.179134/  1.413982, val:  60.42%, val_best:  64.17%, tr:  70.48%, tr_best:  70.68%\n",
      "epoch-82  lr=['0.0001000'], tr/val_loss:  1.175154/  1.412980, val:  63.33%, val_best:  64.17%, tr:  70.79%, tr_best:  70.79%\n",
      "epoch-83  lr=['0.0001000'], tr/val_loss:  1.171604/  1.410757, val:  62.08%, val_best:  64.17%, tr:  71.50%, tr_best:  71.50%\n",
      "epoch-84  lr=['0.0001000'], tr/val_loss:  1.173759/  1.410471, val:  61.25%, val_best:  64.17%, tr:  70.28%, tr_best:  71.50%\n",
      "epoch-85  lr=['0.0001000'], tr/val_loss:  1.168503/  1.406716, val:  64.58%, val_best:  64.58%, tr:  71.60%, tr_best:  71.60%\n",
      "epoch-86  lr=['0.0001000'], tr/val_loss:  1.159148/  1.402431, val:  62.92%, val_best:  64.58%, tr:  71.81%, tr_best:  71.81%\n",
      "epoch-87  lr=['0.0001000'], tr/val_loss:  1.155459/  1.396975, val:  62.50%, val_best:  64.58%, tr:  72.73%, tr_best:  72.73%\n",
      "epoch-88  lr=['0.0001000'], tr/val_loss:  1.151772/  1.397148, val:  62.50%, val_best:  64.58%, tr:  72.32%, tr_best:  72.73%\n",
      "epoch-89  lr=['0.0001000'], tr/val_loss:  1.144698/  1.394033, val:  59.58%, val_best:  64.58%, tr:  71.71%, tr_best:  72.73%\n",
      "epoch-90  lr=['0.0001000'], tr/val_loss:  1.144643/  1.394034, val:  62.08%, val_best:  64.58%, tr:  72.32%, tr_best:  72.73%\n",
      "epoch-91  lr=['0.0001000'], tr/val_loss:  1.132036/  1.388863, val:  63.33%, val_best:  64.58%, tr:  70.99%, tr_best:  72.73%\n",
      "epoch-92  lr=['0.0001000'], tr/val_loss:  1.134058/  1.387441, val:  62.08%, val_best:  64.58%, tr:  71.40%, tr_best:  72.73%\n",
      "epoch-93  lr=['0.0001000'], tr/val_loss:  1.135971/  1.385857, val:  58.33%, val_best:  64.58%, tr:  71.30%, tr_best:  72.73%\n",
      "epoch-94  lr=['0.0001000'], tr/val_loss:  1.128925/  1.385844, val:  61.25%, val_best:  64.58%, tr:  71.50%, tr_best:  72.73%\n",
      "epoch-95  lr=['0.0001000'], tr/val_loss:  1.127672/  1.383720, val:  65.00%, val_best:  65.00%, tr:  70.58%, tr_best:  72.73%\n",
      "epoch-96  lr=['0.0001000'], tr/val_loss:  1.122273/  1.389034, val:  62.08%, val_best:  65.00%, tr:  73.54%, tr_best:  73.54%\n",
      "epoch-97  lr=['0.0001000'], tr/val_loss:  1.118763/  1.381868, val:  65.00%, val_best:  65.00%, tr:  72.52%, tr_best:  73.54%\n",
      "epoch-98  lr=['0.0001000'], tr/val_loss:  1.123405/  1.380064, val:  59.58%, val_best:  65.00%, tr:  71.20%, tr_best:  73.54%\n",
      "epoch-99  lr=['0.0001000'], tr/val_loss:  1.113860/  1.378210, val:  62.50%, val_best:  65.00%, tr:  70.99%, tr_best:  73.54%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7c0f5695c55e473491de4c15857a4b85",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.006 MB of 0.006 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>iter_acc</td><td>▂▂▁▂▃▂▅▄▄▄▆▇▆▄▅▆▅▇▇▅▆▅▄▅▆▆▆▇▆▅▆▆▆▆█▆▅▅█▆</td></tr><tr><td>summary_val_acc</td><td>▁▂▃▃▄▅▅▆▆▆▇▇▇▇▇▇▇▇▇▇█▇▇▇▇█▇█████████▇███</td></tr><tr><td>tr_acc</td><td>▁▂▂▃▄▄▅▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇█▇▇████████████</td></tr><tr><td>tr_epoch_loss</td><td>███▇▇▇▆▆▅▅▄▄▄▃▃▃▃▃▃▂▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_acc_best</td><td>▁▂▃▃▄▅▅▆▆▇▇▇▇▇▇▇▇▇▇▇████████████████████</td></tr><tr><td>val_acc_now</td><td>▁▂▃▃▄▅▅▆▆▆▇▇▇▇▇▇▇▇▇▇█▇▇▇▇█▇█████████▇███</td></tr><tr><td>val_loss</td><td>███▇▇▆▆▅▅▄▄▄▃▃▃▃▃▂▂▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>99</td></tr><tr><td>iter_acc</td><td>1.0</td></tr><tr><td>tr_acc</td><td>0.70991</td></tr><tr><td>tr_epoch_loss</td><td>1.11386</td></tr><tr><td>val_acc_best</td><td>0.65</td></tr><tr><td>val_acc_now</td><td>0.625</td></tr><tr><td>val_loss</td><td>1.37821</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">pleasant-sweep-14</strong> at: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/lz43gll7' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/lz43gll7</a><br/> View project at: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>/data2/bh_wandb/wandb/run-20250429_231152-lz43gll7/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require(\"core\")`! See https://wandb.me/wandb-core for more information."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: oqhh6xfh with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBATCH: 16\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBN_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBPTT_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tDFA_on: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tIMAGE_SIZE: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tOTTT_input_trace_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tTIME: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tUDA_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \talpha_uda: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbias: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcfg: ['M', 'M', 200, 200]\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tchaching_on: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tconvTrue_fcFalse: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdata_path: /data2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tddp_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdenoise_on: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdvs_clipping: 5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdvs_duration: 100000\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepoch_num: 100\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \texclude_class: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \textra_train_dataset: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlast_lif: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.001\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_sg_width: 5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_decay: 0.5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_init: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_reset: 10000\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_threshold: 0.25\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmerge_polarities: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmy_seed: 42\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnet_print: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_workers: 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer_what: SGD\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tpin_memory: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tpre_trained: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tpre_trained_path: net_save/save_now_net_weights_{unique_name}.pth\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \trate_coding: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tscheduler_name: no\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsingle_step: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsurrogate: hard_sigmoid\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_conv_kernel_size: 3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_conv_padding: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_conv_stride: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_trace_const1: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_trace_const2: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \ttdBN_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \ttrace_on: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \twhich_data: DVS_GESTURE_TONIC\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a3bda6b998d8409daa871b1b9fd89947",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.01111274221394625, max=1.0)…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.19.10 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.17.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/data2/bh_wandb/wandb/run-20250429_231829-oqhh6xfh</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/oqhh6xfh' target=\"_blank\">cosmic-sweep-18</a></strong> to <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/6pj3lh8j' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/6pj3lh8j</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/6pj3lh8j' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/6pj3lh8j</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/oqhh6xfh' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/oqhh6xfh</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'single_step' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'my_seed' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'TIME' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BATCH' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'IMAGE_SIZE' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'which_data' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'data_path' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'rate_coding' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_init' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_decay' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_threshold' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_reset' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_sg_width' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_conv_kernel_size' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_conv_stride' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_conv_padding' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_trace_const1' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_trace_const2' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'pre_trained' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'convTrue_fcFalse' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'cfg' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'net_print' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'pre_trained_path' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'learning_rate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'epoch_num' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'tdBN_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BN_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'surrogate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BPTT_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'optimizer_what' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'scheduler_name' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'ddp_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'dvs_clipping' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'dvs_duration' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'DFA_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'trace_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'OTTT_input_trace_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'exclude_class' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'merge_polarities' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'denoise_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'extra_train_dataset' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'num_workers' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'chaching_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'pin_memory' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'UDA_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'alpha_uda' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'bias' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'last_lif' was locked by 'sweep' (ignored update).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "param {'devices': '0', 'single_step': True, 'unique_name': 'main', 'my_seed': 42, 'TIME': 10, 'BATCH': 16, 'IMAGE_SIZE': 128, 'which_data': 'DVS_GESTURE_TONIC', 'data_path': '/data2', 'rate_coding': False, 'lif_layer_v_init': 0, 'lif_layer_v_decay': 0.5, 'lif_layer_v_threshold': 0.25, 'lif_layer_v_reset': 10000, 'lif_layer_sg_width': 5, 'synapse_conv_kernel_size': 3, 'synapse_conv_stride': 1, 'synapse_conv_padding': 1, 'synapse_trace_const1': 1, 'synapse_trace_const2': 0, 'pre_trained': False, 'convTrue_fcFalse': False, 'cfg': ['M', 'M', 200, 200], 'net_print': True, 'pre_trained_path': 'net_save/save_now_net_weights_{unique_name}.pth', 'learning_rate': 0.001, 'epoch_num': 100, 'tdBN_on': False, 'BN_on': False, 'surrogate': 'hard_sigmoid', 'BPTT_on': False, 'optimizer_what': 'SGD', 'scheduler_name': 'no', 'ddp_on': False, 'dvs_clipping': 5, 'dvs_duration': 100000, 'DFA_on': True, 'trace_on': True, 'OTTT_input_trace_on': False, 'exclude_class': True, 'merge_polarities': False, 'denoise_on': True, 'extra_train_dataset': 0, 'num_workers': 2, 'chaching_on': True, 'pin_memory': True, 'UDA_on': False, 'alpha_uda': 1, 'bias': True, 'last_lif': False, 'current epoch': 0} \n",
      "\n",
      "dataset_hash = 63cc597115630ec173f3099200061e53\n",
      "cache path exists\n",
      "\n",
      "device ==> cuda\n",
      "\n",
      "DataParallel(\n",
      "  (module): REBORN_MY_SNN_FC(\n",
      "    (layers): REBORN_MY_Sequential(\n",
      "      (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (2): DimChanger_for_FC()\n",
      "      (3): SYNAPSE_FC(in_features=2048, out_features=200, TIME=10, bias=True, sstep=True)\n",
      "      (4): LIF_layer(v_init=0, v_decay=0.5, v_threshold=0.25, v_reset=10000, sg_width=5, surrogate=hard_sigmoid, BPTT_on=False, trace_const1=1, trace_const2=0, TIME=10, sstep=True, trace_on=True)\n",
      "      (5): Feedback_Receiver()\n",
      "      (6): SYNAPSE_FC(in_features=200, out_features=200, TIME=10, bias=True, sstep=True)\n",
      "      (7): LIF_layer(v_init=0, v_decay=0.5, v_threshold=0.25, v_reset=10000, sg_width=5, surrogate=hard_sigmoid, BPTT_on=False, trace_const1=1, trace_const2=0, TIME=10, sstep=True, trace_on=True)\n",
      "      (8): Feedback_Receiver()\n",
      "      (9): SYNAPSE_FC(in_features=200, out_features=10, TIME=10, bias=True, sstep=True)\n",
      "      (DFA_top): Top_Gradient()\n",
      "    )\n",
      "  )\n",
      ")\n",
      "\n",
      "========================================================\n",
      "Trainable parameters: 452,010\n",
      "========================================================\n",
      "\n",
      "epoch-0   lr=['0.0010000'], tr/val_loss:  2.072655/  1.655479, val:  41.25%, val_best:  41.25%, tr:  22.98%, tr_best:  22.98%\n",
      "[module.layers.5] weight_fb parameter count: 2,000\n",
      "[module.layers.8] weight_fb parameter count: 2,000\n",
      "epoch-1   lr=['0.0010000'], tr/val_loss:  1.394203/  1.476836, val:  55.00%, val_best:  55.00%, tr:  54.14%, tr_best:  54.14%\n",
      "epoch-2   lr=['0.0010000'], tr/val_loss:  1.202114/  1.408733, val:  60.00%, val_best:  60.00%, tr:  60.98%, tr_best:  60.98%\n",
      "epoch-3   lr=['0.0010000'], tr/val_loss:  1.092254/  1.366071, val:  59.58%, val_best:  60.00%, tr:  65.88%, tr_best:  65.88%\n",
      "epoch-4   lr=['0.0010000'], tr/val_loss:  1.047643/  1.311659, val:  62.50%, val_best:  62.50%, tr:  67.62%, tr_best:  67.62%\n",
      "epoch-5   lr=['0.0010000'], tr/val_loss:  0.989800/  1.295233, val:  66.25%, val_best:  66.25%, tr:  68.64%, tr_best:  68.64%\n",
      "epoch-6   lr=['0.0010000'], tr/val_loss:  0.927142/  1.294810, val:  58.75%, val_best:  66.25%, tr:  73.03%, tr_best:  73.03%\n",
      "epoch-7   lr=['0.0010000'], tr/val_loss:  0.897535/  1.235023, val:  67.92%, val_best:  67.92%, tr:  74.97%, tr_best:  74.97%\n",
      "epoch-8   lr=['0.0010000'], tr/val_loss:  0.860691/  1.261070, val:  70.00%, val_best:  70.00%, tr:  78.55%, tr_best:  78.55%\n",
      "epoch-9   lr=['0.0010000'], tr/val_loss:  0.806850/  1.292119, val:  66.67%, val_best:  70.00%, tr:  81.10%, tr_best:  81.10%\n",
      "epoch-10  lr=['0.0010000'], tr/val_loss:  0.775417/  1.355382, val:  60.00%, val_best:  70.00%, tr:  83.35%, tr_best:  83.35%\n",
      "epoch-11  lr=['0.0010000'], tr/val_loss:  0.711955/  1.194858, val:  71.67%, val_best:  71.67%, tr:  85.80%, tr_best:  85.80%\n",
      "epoch-12  lr=['0.0010000'], tr/val_loss:  0.692528/  1.216352, val:  71.25%, val_best:  71.67%, tr:  88.87%, tr_best:  88.87%\n",
      "epoch-13  lr=['0.0010000'], tr/val_loss:  0.659452/  1.250122, val:  70.00%, val_best:  71.67%, tr:  90.81%, tr_best:  90.81%\n",
      "epoch-14  lr=['0.0010000'], tr/val_loss:  0.610990/  1.389756, val:  67.50%, val_best:  71.67%, tr:  91.01%, tr_best:  91.01%\n",
      "epoch-15  lr=['0.0010000'], tr/val_loss:  0.595901/  1.288303, val:  70.00%, val_best:  71.67%, tr:  91.52%, tr_best:  91.52%\n",
      "epoch-16  lr=['0.0010000'], tr/val_loss:  0.590088/  1.244966, val:  73.75%, val_best:  73.75%, tr:  92.65%, tr_best:  92.65%\n",
      "epoch-17  lr=['0.0010000'], tr/val_loss:  0.529072/  1.249509, val:  74.58%, val_best:  74.58%, tr:  95.51%, tr_best:  95.51%\n",
      "epoch-18  lr=['0.0010000'], tr/val_loss:  0.516801/  1.316593, val:  72.08%, val_best:  74.58%, tr:  94.79%, tr_best:  95.51%\n",
      "epoch-19  lr=['0.0010000'], tr/val_loss:  0.490023/  1.306180, val:  73.33%, val_best:  74.58%, tr:  94.99%, tr_best:  95.51%\n",
      "epoch-20  lr=['0.0010000'], tr/val_loss:  0.455020/  1.312918, val:  72.50%, val_best:  74.58%, tr:  96.94%, tr_best:  96.94%\n",
      "epoch-21  lr=['0.0010000'], tr/val_loss:  0.443541/  1.320977, val:  75.42%, val_best:  75.42%, tr:  96.32%, tr_best:  96.94%\n",
      "epoch-22  lr=['0.0010000'], tr/val_loss:  0.423555/  1.328927, val:  75.42%, val_best:  75.42%, tr:  98.06%, tr_best:  98.06%\n",
      "epoch-23  lr=['0.0010000'], tr/val_loss:  0.416684/  1.325633, val:  76.67%, val_best:  76.67%, tr:  96.53%, tr_best:  98.06%\n",
      "epoch-24  lr=['0.0010000'], tr/val_loss:  0.369807/  1.340824, val:  76.25%, val_best:  76.67%, tr:  98.16%, tr_best:  98.16%\n",
      "epoch-25  lr=['0.0010000'], tr/val_loss:  0.359382/  1.332054, val:  78.33%, val_best:  78.33%, tr:  98.67%, tr_best:  98.67%\n",
      "epoch-26  lr=['0.0010000'], tr/val_loss:  0.374477/  1.335854, val:  79.58%, val_best:  79.58%, tr:  96.94%, tr_best:  98.67%\n",
      "epoch-27  lr=['0.0010000'], tr/val_loss:  0.331629/  1.373184, val:  77.50%, val_best:  79.58%, tr:  97.96%, tr_best:  98.67%\n",
      "epoch-28  lr=['0.0010000'], tr/val_loss:  0.312156/  1.368531, val:  81.25%, val_best:  81.25%, tr:  98.88%, tr_best:  98.88%\n",
      "epoch-29  lr=['0.0010000'], tr/val_loss:  0.301265/  1.470034, val:  75.00%, val_best:  81.25%, tr:  98.98%, tr_best:  98.98%\n",
      "epoch-30  lr=['0.0010000'], tr/val_loss:  0.287776/  1.410251, val:  78.33%, val_best:  81.25%, tr:  98.98%, tr_best:  98.98%\n",
      "epoch-31  lr=['0.0010000'], tr/val_loss:  0.284253/  1.467694, val:  77.50%, val_best:  81.25%, tr:  98.57%, tr_best:  98.98%\n",
      "epoch-32  lr=['0.0010000'], tr/val_loss:  0.272554/  1.496714, val:  77.08%, val_best:  81.25%, tr:  99.39%, tr_best:  99.39%\n",
      "epoch-33  lr=['0.0010000'], tr/val_loss:  0.269149/  1.502160, val:  76.67%, val_best:  81.25%, tr:  99.18%, tr_best:  99.39%\n",
      "epoch-34  lr=['0.0010000'], tr/val_loss:  0.256460/  1.536069, val:  77.08%, val_best:  81.25%, tr:  98.77%, tr_best:  99.39%\n",
      "epoch-35  lr=['0.0010000'], tr/val_loss:  0.243081/  1.526445, val:  75.83%, val_best:  81.25%, tr:  99.69%, tr_best:  99.69%\n",
      "epoch-36  lr=['0.0010000'], tr/val_loss:  0.224600/  1.480142, val:  80.83%, val_best:  81.25%, tr:  99.80%, tr_best:  99.80%\n",
      "epoch-37  lr=['0.0010000'], tr/val_loss:  0.218753/  1.572682, val:  79.17%, val_best:  81.25%, tr:  99.69%, tr_best:  99.80%\n",
      "epoch-38  lr=['0.0010000'], tr/val_loss:  0.217410/  1.562451, val:  78.33%, val_best:  81.25%, tr:  99.59%, tr_best:  99.80%\n",
      "epoch-39  lr=['0.0010000'], tr/val_loss:  0.213520/  1.548314, val:  80.00%, val_best:  81.25%, tr:  99.69%, tr_best:  99.80%\n",
      "epoch-40  lr=['0.0010000'], tr/val_loss:  0.203613/  1.595001, val:  79.17%, val_best:  81.25%, tr:  99.80%, tr_best:  99.80%\n",
      "epoch-41  lr=['0.0010000'], tr/val_loss:  0.192946/  1.609893, val:  77.50%, val_best:  81.25%, tr:  99.80%, tr_best:  99.80%\n",
      "epoch-42  lr=['0.0010000'], tr/val_loss:  0.192810/  1.610318, val:  80.83%, val_best:  81.25%, tr:  99.90%, tr_best:  99.90%\n",
      "epoch-43  lr=['0.0010000'], tr/val_loss:  0.177668/  1.631003, val:  80.83%, val_best:  81.25%, tr:  99.90%, tr_best:  99.90%\n",
      "epoch-44  lr=['0.0010000'], tr/val_loss:  0.172067/  1.628168, val:  81.67%, val_best:  81.67%, tr:  99.80%, tr_best:  99.90%\n",
      "epoch-45  lr=['0.0010000'], tr/val_loss:  0.161232/  1.629829, val:  82.50%, val_best:  82.50%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-46  lr=['0.0010000'], tr/val_loss:  0.156328/  1.634205, val:  81.25%, val_best:  82.50%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-47  lr=['0.0010000'], tr/val_loss:  0.148876/  1.674867, val:  82.92%, val_best:  82.92%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-48  lr=['0.0010000'], tr/val_loss:  0.151540/  1.676438, val:  82.08%, val_best:  82.92%, tr:  99.90%, tr_best: 100.00%\n",
      "epoch-49  lr=['0.0010000'], tr/val_loss:  0.141886/  1.697216, val:  82.08%, val_best:  82.92%, tr:  99.90%, tr_best: 100.00%\n",
      "epoch-50  lr=['0.0010000'], tr/val_loss:  0.136358/  1.723313, val:  81.25%, val_best:  82.92%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-51  lr=['0.0010000'], tr/val_loss:  0.132465/  1.751673, val:  80.00%, val_best:  82.92%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-52  lr=['0.0010000'], tr/val_loss:  0.127894/  1.758372, val:  80.42%, val_best:  82.92%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-53  lr=['0.0010000'], tr/val_loss:  0.123423/  1.788471, val:  81.25%, val_best:  82.92%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-54  lr=['0.0010000'], tr/val_loss:  0.121341/  1.763942, val:  82.50%, val_best:  82.92%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-55  lr=['0.0010000'], tr/val_loss:  0.114335/  1.796504, val:  81.25%, val_best:  82.92%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-56  lr=['0.0010000'], tr/val_loss:  0.111261/  1.816783, val:  81.25%, val_best:  82.92%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-57  lr=['0.0010000'], tr/val_loss:  0.110318/  1.798625, val:  81.67%, val_best:  82.92%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-58  lr=['0.0010000'], tr/val_loss:  0.104183/  1.816937, val:  82.08%, val_best:  82.92%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-59  lr=['0.0010000'], tr/val_loss:  0.103250/  1.840551, val:  82.08%, val_best:  82.92%, tr:  99.90%, tr_best: 100.00%\n",
      "epoch-60  lr=['0.0010000'], tr/val_loss:  0.097487/  1.852101, val:  82.50%, val_best:  82.92%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-61  lr=['0.0010000'], tr/val_loss:  0.098627/  1.851007, val:  80.83%, val_best:  82.92%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-62  lr=['0.0010000'], tr/val_loss:  0.093260/  1.864749, val:  82.08%, val_best:  82.92%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-63  lr=['0.0010000'], tr/val_loss:  0.091329/  1.883950, val:  82.08%, val_best:  82.92%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-64  lr=['0.0010000'], tr/val_loss:  0.087854/  1.886454, val:  81.67%, val_best:  82.92%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-65  lr=['0.0010000'], tr/val_loss:  0.086004/  1.888194, val:  82.92%, val_best:  82.92%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-66  lr=['0.0010000'], tr/val_loss:  0.085817/  1.922383, val:  82.08%, val_best:  82.92%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-67  lr=['0.0010000'], tr/val_loss:  0.082269/  1.912985, val:  82.08%, val_best:  82.92%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-68  lr=['0.0010000'], tr/val_loss:  0.080192/  1.917006, val:  82.08%, val_best:  82.92%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-69  lr=['0.0010000'], tr/val_loss:  0.076776/  1.923056, val:  81.67%, val_best:  82.92%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-70  lr=['0.0010000'], tr/val_loss:  0.077637/  1.953933, val:  81.25%, val_best:  82.92%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-71  lr=['0.0010000'], tr/val_loss:  0.080190/  1.962624, val:  82.08%, val_best:  82.92%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-72  lr=['0.0010000'], tr/val_loss:  0.072594/  1.991754, val:  80.00%, val_best:  82.92%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-73  lr=['0.0010000'], tr/val_loss:  0.073181/  1.969533, val:  81.67%, val_best:  82.92%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-74  lr=['0.0010000'], tr/val_loss:  0.071021/  1.965225, val:  82.08%, val_best:  82.92%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-75  lr=['0.0010000'], tr/val_loss:  0.065530/  1.979316, val:  82.92%, val_best:  82.92%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-76  lr=['0.0010000'], tr/val_loss:  0.065266/  1.991002, val:  81.67%, val_best:  82.92%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-77  lr=['0.0010000'], tr/val_loss:  0.063909/  2.014164, val:  82.08%, val_best:  82.92%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-78  lr=['0.0010000'], tr/val_loss:  0.064562/  2.036365, val:  81.67%, val_best:  82.92%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-79  lr=['0.0010000'], tr/val_loss:  0.062501/  1.998692, val:  82.08%, val_best:  82.92%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-80  lr=['0.0010000'], tr/val_loss:  0.059554/  2.058345, val:  81.25%, val_best:  82.92%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-81  lr=['0.0010000'], tr/val_loss:  0.058099/  2.039061, val:  83.75%, val_best:  83.75%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-82  lr=['0.0010000'], tr/val_loss:  0.055613/  2.074891, val:  81.67%, val_best:  83.75%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-83  lr=['0.0010000'], tr/val_loss:  0.055711/  2.089037, val:  80.42%, val_best:  83.75%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-84  lr=['0.0010000'], tr/val_loss:  0.055665/  2.063626, val:  83.75%, val_best:  83.75%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-85  lr=['0.0010000'], tr/val_loss:  0.057348/  2.103826, val:  82.08%, val_best:  83.75%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-86  lr=['0.0010000'], tr/val_loss:  0.055016/  2.092004, val:  81.25%, val_best:  83.75%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-87  lr=['0.0010000'], tr/val_loss:  0.053700/  2.105178, val:  82.50%, val_best:  83.75%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-88  lr=['0.0010000'], tr/val_loss:  0.051002/  2.101817, val:  83.33%, val_best:  83.75%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-89  lr=['0.0010000'], tr/val_loss:  0.050455/  2.098496, val:  82.08%, val_best:  83.75%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-90  lr=['0.0010000'], tr/val_loss:  0.048208/  2.108443, val:  84.17%, val_best:  84.17%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-91  lr=['0.0010000'], tr/val_loss:  0.048996/  2.146665, val:  81.25%, val_best:  84.17%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-92  lr=['0.0010000'], tr/val_loss:  0.045764/  2.158870, val:  82.08%, val_best:  84.17%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-93  lr=['0.0010000'], tr/val_loss:  0.048024/  2.168151, val:  82.08%, val_best:  84.17%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-94  lr=['0.0010000'], tr/val_loss:  0.045851/  2.175521, val:  82.08%, val_best:  84.17%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-95  lr=['0.0010000'], tr/val_loss:  0.045919/  2.182141, val:  81.67%, val_best:  84.17%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-96  lr=['0.0010000'], tr/val_loss:  0.045389/  2.214179, val:  82.08%, val_best:  84.17%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-97  lr=['0.0010000'], tr/val_loss:  0.044497/  2.212003, val:  82.50%, val_best:  84.17%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-98  lr=['0.0010000'], tr/val_loss:  0.043887/  2.214262, val:  79.58%, val_best:  84.17%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-99  lr=['0.0010000'], tr/val_loss:  0.045039/  2.196822, val:  83.33%, val_best:  84.17%, tr: 100.00%, tr_best: 100.00%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1bef108482ec465184ba83d575b982d0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.006 MB of 0.006 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>iter_acc</td><td>▁▇▄▄▆▆▇▅▇████▇██████████████████████████</td></tr><tr><td>summary_val_acc</td><td>▁▄▅▅▅▆▅▆▆▇▇▇▇▇▇▇▇████▇███████▇██████████</td></tr><tr><td>tr_acc</td><td>▁▄▅▆▆▇▇█████████████████████████████████</td></tr><tr><td>tr_epoch_loss</td><td>█▅▄▄▄▃▃▃▃▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_acc_best</td><td>▁▄▄▅▆▆▆▆▆▇▇▇████████████████████████████</td></tr><tr><td>val_acc_now</td><td>▁▄▅▅▅▆▅▆▆▇▇▇▇▇▇▇▇████▇███████▇██████████</td></tr><tr><td>val_loss</td><td>▄▂▂▁▂▁▂▁▂▂▂▂▃▃▃▄▃▄▄▄▄▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>99</td></tr><tr><td>iter_acc</td><td>1.0</td></tr><tr><td>tr_acc</td><td>1.0</td></tr><tr><td>tr_epoch_loss</td><td>0.04504</td></tr><tr><td>val_acc_best</td><td>0.84167</td></tr><tr><td>val_acc_now</td><td>0.83333</td></tr><tr><td>val_loss</td><td>2.19682</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">cosmic-sweep-18</strong> at: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/oqhh6xfh' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/oqhh6xfh</a><br/> View project at: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>/data2/bh_wandb/wandb/run-20250429_231829-oqhh6xfh/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require(\"core\")`! See https://wandb.me/wandb-core for more information."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Sweep Agent: Waiting for job.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Job received.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: bdspannj with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBATCH: 16\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBN_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBPTT_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tDFA_on: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tIMAGE_SIZE: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tOTTT_input_trace_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tTIME: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tUDA_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \talpha_uda: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbias: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcfg: ['M', 'M', 200, 200]\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tchaching_on: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tconvTrue_fcFalse: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdata_path: /data2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tddp_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdenoise_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdvs_clipping: 5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdvs_duration: 100000\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepoch_num: 100\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \texclude_class: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \textra_train_dataset: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlast_lif: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.001\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_sg_width: 5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_decay: 0.5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_init: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_reset: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_threshold: 0.25\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmerge_polarities: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmy_seed: 42\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnet_print: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_workers: 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer_what: SGD\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tpin_memory: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tpre_trained: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tpre_trained_path: net_save/save_now_net_weights_{unique_name}.pth\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \trate_coding: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tscheduler_name: no\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsingle_step: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsurrogate: hard_sigmoid\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_conv_kernel_size: 3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_conv_padding: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_conv_stride: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_trace_const1: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_trace_const2: 0.5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \ttdBN_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \ttrace_on: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \twhich_data: DVS_GESTURE_TONIC\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f37ee92aaecc408291c27771a2d88406",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.011112897946602768, max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.19.10 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.17.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/data2/bh_wandb/wandb/run-20250429_232546-bdspannj</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/bdspannj' target=\"_blank\">astral-sweep-22</a></strong> to <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/6pj3lh8j' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/6pj3lh8j</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/6pj3lh8j' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/6pj3lh8j</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/bdspannj' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/bdspannj</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'single_step' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'my_seed' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'TIME' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BATCH' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'IMAGE_SIZE' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'which_data' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'data_path' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'rate_coding' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_init' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_decay' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_threshold' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_reset' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_sg_width' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_conv_kernel_size' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_conv_stride' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_conv_padding' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_trace_const1' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_trace_const2' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'pre_trained' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'convTrue_fcFalse' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'cfg' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'net_print' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'pre_trained_path' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'learning_rate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'epoch_num' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'tdBN_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BN_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'surrogate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BPTT_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'optimizer_what' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'scheduler_name' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'ddp_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'dvs_clipping' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'dvs_duration' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'DFA_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'trace_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'OTTT_input_trace_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'exclude_class' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'merge_polarities' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'denoise_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'extra_train_dataset' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'num_workers' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'chaching_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'pin_memory' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'UDA_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'alpha_uda' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'bias' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'last_lif' was locked by 'sweep' (ignored update).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "param {'devices': '0', 'single_step': True, 'unique_name': 'main', 'my_seed': 42, 'TIME': 10, 'BATCH': 16, 'IMAGE_SIZE': 128, 'which_data': 'DVS_GESTURE_TONIC', 'data_path': '/data2', 'rate_coding': False, 'lif_layer_v_init': 0, 'lif_layer_v_decay': 0.5, 'lif_layer_v_threshold': 0.25, 'lif_layer_v_reset': 0, 'lif_layer_sg_width': 5, 'synapse_conv_kernel_size': 3, 'synapse_conv_stride': 1, 'synapse_conv_padding': 1, 'synapse_trace_const1': 1, 'synapse_trace_const2': 0.5, 'pre_trained': False, 'convTrue_fcFalse': False, 'cfg': ['M', 'M', 200, 200], 'net_print': True, 'pre_trained_path': 'net_save/save_now_net_weights_{unique_name}.pth', 'learning_rate': 0.001, 'epoch_num': 100, 'tdBN_on': False, 'BN_on': False, 'surrogate': 'hard_sigmoid', 'BPTT_on': False, 'optimizer_what': 'SGD', 'scheduler_name': 'no', 'ddp_on': False, 'dvs_clipping': 5, 'dvs_duration': 100000, 'DFA_on': True, 'trace_on': True, 'OTTT_input_trace_on': False, 'exclude_class': True, 'merge_polarities': False, 'denoise_on': False, 'extra_train_dataset': 0, 'num_workers': 2, 'chaching_on': True, 'pin_memory': True, 'UDA_on': False, 'alpha_uda': 1, 'bias': True, 'last_lif': False, 'current epoch': 0} \n",
      "\n",
      "dataset_hash = ffa516e60c3efd5e0208f72b4c36cb84\n",
      "cache path exists\n",
      "\n",
      "device ==> cuda\n",
      "\n",
      "DataParallel(\n",
      "  (module): REBORN_MY_SNN_FC(\n",
      "    (layers): REBORN_MY_Sequential(\n",
      "      (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (2): DimChanger_for_FC()\n",
      "      (3): SYNAPSE_FC(in_features=2048, out_features=200, TIME=10, bias=True, sstep=True)\n",
      "      (4): LIF_layer(v_init=0, v_decay=0.5, v_threshold=0.25, v_reset=0, sg_width=5, surrogate=hard_sigmoid, BPTT_on=False, trace_const1=1, trace_const2=0.5, TIME=10, sstep=True, trace_on=True)\n",
      "      (5): Feedback_Receiver()\n",
      "      (6): SYNAPSE_FC(in_features=200, out_features=200, TIME=10, bias=True, sstep=True)\n",
      "      (7): LIF_layer(v_init=0, v_decay=0.5, v_threshold=0.25, v_reset=0, sg_width=5, surrogate=hard_sigmoid, BPTT_on=False, trace_const1=1, trace_const2=0.5, TIME=10, sstep=True, trace_on=True)\n",
      "      (8): Feedback_Receiver()\n",
      "      (9): SYNAPSE_FC(in_features=200, out_features=10, TIME=10, bias=True, sstep=True)\n",
      "      (DFA_top): Top_Gradient()\n",
      "    )\n",
      "  )\n",
      ")\n",
      "\n",
      "========================================================\n",
      "Trainable parameters: 452,010\n",
      "========================================================\n",
      "\n",
      "epoch-0   lr=['0.0010000'], tr/val_loss:  1.868886/  1.540477, val:  45.83%, val_best:  45.83%, tr:  29.11%, tr_best:  29.11%\n",
      "[module.layers.5] weight_fb parameter count: 2,000\n",
      "[module.layers.8] weight_fb parameter count: 2,000\n",
      "epoch-1   lr=['0.0010000'], tr/val_loss:  1.198842/  1.350200, val:  56.67%, val_best:  56.67%, tr:  57.10%, tr_best:  57.10%\n",
      "epoch-2   lr=['0.0010000'], tr/val_loss:  1.029423/  1.299913, val:  57.92%, val_best:  57.92%, tr:  63.94%, tr_best:  63.94%\n",
      "epoch-3   lr=['0.0010000'], tr/val_loss:  0.885046/  1.400739, val:  57.08%, val_best:  57.92%, tr:  69.77%, tr_best:  69.77%\n",
      "epoch-4   lr=['0.0010000'], tr/val_loss:  0.793368/  1.210242, val:  65.00%, val_best:  65.00%, tr:  73.44%, tr_best:  73.44%\n",
      "epoch-5   lr=['0.0010000'], tr/val_loss:  0.708293/  1.237003, val:  62.50%, val_best:  65.00%, tr:  78.14%, tr_best:  78.14%\n",
      "epoch-6   lr=['0.0010000'], tr/val_loss:  0.624018/  1.233569, val:  64.17%, val_best:  65.00%, tr:  82.74%, tr_best:  82.74%\n",
      "epoch-7   lr=['0.0010000'], tr/val_loss:  0.557760/  1.312966, val:  66.25%, val_best:  66.25%, tr:  87.33%, tr_best:  87.33%\n",
      "epoch-8   lr=['0.0010000'], tr/val_loss:  0.488027/  1.350798, val:  73.33%, val_best:  73.33%, tr:  91.22%, tr_best:  91.22%\n",
      "epoch-9   lr=['0.0010000'], tr/val_loss:  0.412904/  1.450039, val:  67.50%, val_best:  73.33%, tr:  94.38%, tr_best:  94.38%\n",
      "epoch-10  lr=['0.0010000'], tr/val_loss:  0.371764/  1.526048, val:  71.25%, val_best:  73.33%, tr:  95.71%, tr_best:  95.71%\n",
      "epoch-11  lr=['0.0010000'], tr/val_loss:  0.296310/  1.458242, val:  75.42%, val_best:  75.42%, tr:  97.45%, tr_best:  97.45%\n",
      "epoch-12  lr=['0.0010000'], tr/val_loss:  0.256602/  1.546015, val:  71.25%, val_best:  75.42%, tr:  98.98%, tr_best:  98.98%\n",
      "epoch-13  lr=['0.0010000'], tr/val_loss:  0.236980/  1.600886, val:  72.08%, val_best:  75.42%, tr:  98.77%, tr_best:  98.98%\n",
      "epoch-14  lr=['0.0010000'], tr/val_loss:  0.198788/  1.818057, val:  68.33%, val_best:  75.42%, tr:  99.18%, tr_best:  99.18%\n",
      "epoch-15  lr=['0.0010000'], tr/val_loss:  0.163146/  1.724286, val:  73.75%, val_best:  75.42%, tr:  99.69%, tr_best:  99.69%\n",
      "epoch-16  lr=['0.0010000'], tr/val_loss:  0.161445/  1.734686, val:  75.00%, val_best:  75.42%, tr:  99.59%, tr_best:  99.69%\n",
      "epoch-17  lr=['0.0010000'], tr/val_loss:  0.134218/  1.790141, val:  74.17%, val_best:  75.42%, tr:  99.90%, tr_best:  99.90%\n",
      "epoch-18  lr=['0.0010000'], tr/val_loss:  0.119691/  1.842228, val:  74.58%, val_best:  75.42%, tr:  99.90%, tr_best:  99.90%\n",
      "epoch-19  lr=['0.0010000'], tr/val_loss:  0.098501/  1.917029, val:  75.00%, val_best:  75.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-20  lr=['0.0010000'], tr/val_loss:  0.082710/  1.972343, val:  75.00%, val_best:  75.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-21  lr=['0.0010000'], tr/val_loss:  0.077131/  1.994701, val:  73.75%, val_best:  75.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-22  lr=['0.0010000'], tr/val_loss:  0.071359/  2.042446, val:  73.75%, val_best:  75.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-23  lr=['0.0010000'], tr/val_loss:  0.060121/  2.071834, val:  74.58%, val_best:  75.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-24  lr=['0.0010000'], tr/val_loss:  0.052198/  2.092685, val:  74.58%, val_best:  75.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-25  lr=['0.0010000'], tr/val_loss:  0.047272/  2.160391, val:  73.75%, val_best:  75.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-26  lr=['0.0010000'], tr/val_loss:  0.042673/  2.155991, val:  74.58%, val_best:  75.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-27  lr=['0.0010000'], tr/val_loss:  0.038854/  2.213162, val:  73.33%, val_best:  75.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-28  lr=['0.0010000'], tr/val_loss:  0.036102/  2.208473, val:  74.17%, val_best:  75.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-29  lr=['0.0010000'], tr/val_loss:  0.034315/  2.284512, val:  72.08%, val_best:  75.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-30  lr=['0.0010000'], tr/val_loss:  0.033267/  2.304703, val:  73.33%, val_best:  75.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-31  lr=['0.0010000'], tr/val_loss:  0.030861/  2.317754, val:  73.33%, val_best:  75.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-32  lr=['0.0010000'], tr/val_loss:  0.028406/  2.333963, val:  72.92%, val_best:  75.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-33  lr=['0.0010000'], tr/val_loss:  0.025730/  2.356037, val:  74.58%, val_best:  75.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-34  lr=['0.0010000'], tr/val_loss:  0.027752/  2.344261, val:  74.17%, val_best:  75.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-35  lr=['0.0010000'], tr/val_loss:  0.024237/  2.386973, val:  74.58%, val_best:  75.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-36  lr=['0.0010000'], tr/val_loss:  0.020458/  2.389557, val:  74.58%, val_best:  75.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-37  lr=['0.0010000'], tr/val_loss:  0.020730/  2.401076, val:  75.42%, val_best:  75.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-38  lr=['0.0010000'], tr/val_loss:  0.019799/  2.409661, val:  73.75%, val_best:  75.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-39  lr=['0.0010000'], tr/val_loss:  0.019630/  2.432862, val:  74.58%, val_best:  75.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-40  lr=['0.0010000'], tr/val_loss:  0.016785/  2.450578, val:  72.50%, val_best:  75.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-41  lr=['0.0010000'], tr/val_loss:  0.016754/  2.479237, val:  73.75%, val_best:  75.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-42  lr=['0.0010000'], tr/val_loss:  0.014472/  2.477842, val:  74.17%, val_best:  75.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-43  lr=['0.0010000'], tr/val_loss:  0.015720/  2.499481, val:  72.92%, val_best:  75.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-44  lr=['0.0010000'], tr/val_loss:  0.014644/  2.513011, val:  72.08%, val_best:  75.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-45  lr=['0.0010000'], tr/val_loss:  0.014937/  2.521042, val:  73.75%, val_best:  75.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-46  lr=['0.0010000'], tr/val_loss:  0.013364/  2.522305, val:  73.75%, val_best:  75.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-47  lr=['0.0010000'], tr/val_loss:  0.013693/  2.544458, val:  72.50%, val_best:  75.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-48  lr=['0.0010000'], tr/val_loss:  0.014725/  2.543618, val:  74.17%, val_best:  75.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-49  lr=['0.0010000'], tr/val_loss:  0.014400/  2.582227, val:  74.17%, val_best:  75.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-50  lr=['0.0010000'], tr/val_loss:  0.012625/  2.593096, val:  72.50%, val_best:  75.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-51  lr=['0.0010000'], tr/val_loss:  0.012019/  2.596830, val:  74.58%, val_best:  75.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-52  lr=['0.0010000'], tr/val_loss:  0.011245/  2.603316, val:  74.17%, val_best:  75.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-53  lr=['0.0010000'], tr/val_loss:  0.012193/  2.620812, val:  74.58%, val_best:  75.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-54  lr=['0.0010000'], tr/val_loss:  0.012936/  2.626355, val:  73.75%, val_best:  75.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-55  lr=['0.0010000'], tr/val_loss:  0.010573/  2.603702, val:  75.00%, val_best:  75.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-56  lr=['0.0010000'], tr/val_loss:  0.009735/  2.594893, val:  74.58%, val_best:  75.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-57  lr=['0.0010000'], tr/val_loss:  0.009733/  2.622375, val:  74.17%, val_best:  75.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-58  lr=['0.0010000'], tr/val_loss:  0.008978/  2.616173, val:  74.58%, val_best:  75.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-59  lr=['0.0010000'], tr/val_loss:  0.009202/  2.632280, val:  75.42%, val_best:  75.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-60  lr=['0.0010000'], tr/val_loss:  0.009260/  2.648748, val:  74.17%, val_best:  75.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-61  lr=['0.0010000'], tr/val_loss:  0.007962/  2.643125, val:  75.42%, val_best:  75.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-62  lr=['0.0010000'], tr/val_loss:  0.008247/  2.644258, val:  75.42%, val_best:  75.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-63  lr=['0.0010000'], tr/val_loss:  0.009530/  2.669792, val:  73.75%, val_best:  75.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-64  lr=['0.0010000'], tr/val_loss:  0.008301/  2.683959, val:  74.58%, val_best:  75.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-65  lr=['0.0010000'], tr/val_loss:  0.007316/  2.700032, val:  73.75%, val_best:  75.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-66  lr=['0.0010000'], tr/val_loss:  0.006901/  2.686120, val:  73.75%, val_best:  75.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-67  lr=['0.0010000'], tr/val_loss:  0.006582/  2.702468, val:  73.75%, val_best:  75.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-68  lr=['0.0010000'], tr/val_loss:  0.006283/  2.709366, val:  74.17%, val_best:  75.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-69  lr=['0.0010000'], tr/val_loss:  0.005648/  2.715756, val:  74.58%, val_best:  75.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-70  lr=['0.0010000'], tr/val_loss:  0.006042/  2.735373, val:  74.17%, val_best:  75.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-71  lr=['0.0010000'], tr/val_loss:  0.006287/  2.723061, val:  74.58%, val_best:  75.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-72  lr=['0.0010000'], tr/val_loss:  0.005889/  2.721345, val:  74.58%, val_best:  75.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-73  lr=['0.0010000'], tr/val_loss:  0.005364/  2.746908, val:  73.75%, val_best:  75.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-74  lr=['0.0010000'], tr/val_loss:  0.005364/  2.738420, val:  73.75%, val_best:  75.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-75  lr=['0.0010000'], tr/val_loss:  0.005096/  2.744317, val:  74.58%, val_best:  75.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-76  lr=['0.0010000'], tr/val_loss:  0.004900/  2.765792, val:  75.00%, val_best:  75.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-77  lr=['0.0010000'], tr/val_loss:  0.005041/  2.777258, val:  75.00%, val_best:  75.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-78  lr=['0.0010000'], tr/val_loss:  0.005219/  2.777421, val:  74.58%, val_best:  75.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-79  lr=['0.0010000'], tr/val_loss:  0.004878/  2.777531, val:  74.17%, val_best:  75.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-80  lr=['0.0010000'], tr/val_loss:  0.004519/  2.783566, val:  74.17%, val_best:  75.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-81  lr=['0.0010000'], tr/val_loss:  0.005211/  2.774627, val:  74.58%, val_best:  75.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-82  lr=['0.0010000'], tr/val_loss:  0.004844/  2.776283, val:  74.17%, val_best:  75.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-83  lr=['0.0010000'], tr/val_loss:  0.004868/  2.778595, val:  75.00%, val_best:  75.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-84  lr=['0.0010000'], tr/val_loss:  0.004941/  2.770923, val:  75.42%, val_best:  75.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-85  lr=['0.0010000'], tr/val_loss:  0.005183/  2.807400, val:  73.33%, val_best:  75.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-86  lr=['0.0010000'], tr/val_loss:  0.004786/  2.811693, val:  73.75%, val_best:  75.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-87  lr=['0.0010000'], tr/val_loss:  0.004490/  2.815646, val:  73.75%, val_best:  75.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-88  lr=['0.0010000'], tr/val_loss:  0.004138/  2.814682, val:  74.17%, val_best:  75.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-89  lr=['0.0010000'], tr/val_loss:  0.003962/  2.840911, val:  73.75%, val_best:  75.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-90  lr=['0.0010000'], tr/val_loss:  0.004233/  2.840524, val:  73.75%, val_best:  75.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-91  lr=['0.0010000'], tr/val_loss:  0.004172/  2.852199, val:  72.92%, val_best:  75.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-92  lr=['0.0010000'], tr/val_loss:  0.004020/  2.847300, val:  75.00%, val_best:  75.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-93  lr=['0.0010000'], tr/val_loss:  0.003574/  2.854139, val:  73.75%, val_best:  75.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-94  lr=['0.0010000'], tr/val_loss:  0.003677/  2.864597, val:  74.17%, val_best:  75.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-95  lr=['0.0010000'], tr/val_loss:  0.003614/  2.880824, val:  74.58%, val_best:  75.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-96  lr=['0.0010000'], tr/val_loss:  0.003665/  2.893718, val:  73.33%, val_best:  75.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-97  lr=['0.0010000'], tr/val_loss:  0.003467/  2.887952, val:  74.58%, val_best:  75.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-98  lr=['0.0010000'], tr/val_loss:  0.003306/  2.901784, val:  72.92%, val_best:  75.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-99  lr=['0.0010000'], tr/val_loss:  0.003242/  2.902480, val:  72.92%, val_best:  75.42%, tr: 100.00%, tr_best: 100.00%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9371d61291d04ab784093c87ba2d53b2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.006 MB of 0.006 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>iter_acc</td><td>▁▇▆▆▇▇██████████████████████████████████</td></tr><tr><td>summary_val_acc</td><td>▁▄▆▆▆▇▆█████▇▇████▇▇████████████████████</td></tr><tr><td>tr_acc</td><td>▁▄▅▇▇███████████████████████████████████</td></tr><tr><td>tr_epoch_loss</td><td>█▅▄▃▃▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_acc_best</td><td>▁▄▆▆████████████████████████████████████</td></tr><tr><td>val_acc_now</td><td>▁▄▆▆▆▇▆█████▇▇████▇▇████████████████████</td></tr><tr><td>val_loss</td><td>▂▁▁▁▂▂▄▃▄▄▅▅▅▆▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇█████████</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>99</td></tr><tr><td>iter_acc</td><td>1.0</td></tr><tr><td>tr_acc</td><td>1.0</td></tr><tr><td>tr_epoch_loss</td><td>0.00324</td></tr><tr><td>val_acc_best</td><td>0.75417</td></tr><tr><td>val_acc_now</td><td>0.72917</td></tr><tr><td>val_loss</td><td>2.90248</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">astral-sweep-22</strong> at: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/bdspannj' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/bdspannj</a><br/> View project at: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>/data2/bh_wandb/wandb/run-20250429_232546-bdspannj/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require(\"core\")`! See https://wandb.me/wandb-core for more information."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: pbxh4eso with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBATCH: 16\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBN_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBPTT_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tDFA_on: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tIMAGE_SIZE: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tOTTT_input_trace_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tTIME: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tUDA_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \talpha_uda: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbias: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcfg: ['M', 'M', 200, 200]\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tchaching_on: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tconvTrue_fcFalse: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdata_path: /data2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tddp_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdenoise_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdvs_clipping: 5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdvs_duration: 100000\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepoch_num: 100\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \texclude_class: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \textra_train_dataset: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlast_lif: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.01\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_sg_width: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_decay: 0.5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_init: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_reset: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_threshold: 0.25\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmerge_polarities: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmy_seed: 42\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnet_print: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_workers: 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer_what: SGD\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tpin_memory: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tpre_trained: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tpre_trained_path: net_save/save_now_net_weights_{unique_name}.pth\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \trate_coding: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tscheduler_name: no\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsingle_step: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsurrogate: hard_sigmoid\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_conv_kernel_size: 3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_conv_padding: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_conv_stride: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_trace_const1: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_trace_const2: 0.5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \ttdBN_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \ttrace_on: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \twhich_data: DVS_GESTURE_TONIC\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.19.10 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.17.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/data2/bh_wandb/wandb/run-20250429_233249-pbxh4eso</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/pbxh4eso' target=\"_blank\">helpful-sweep-26</a></strong> to <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/6pj3lh8j' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/6pj3lh8j</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/6pj3lh8j' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/6pj3lh8j</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/pbxh4eso' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/pbxh4eso</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'single_step' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'my_seed' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'TIME' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BATCH' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'IMAGE_SIZE' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'which_data' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'data_path' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'rate_coding' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_init' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_decay' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_threshold' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_reset' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_sg_width' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_conv_kernel_size' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_conv_stride' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_conv_padding' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_trace_const1' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_trace_const2' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'pre_trained' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'convTrue_fcFalse' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'cfg' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'net_print' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'pre_trained_path' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'learning_rate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'epoch_num' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'tdBN_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BN_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'surrogate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BPTT_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'optimizer_what' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'scheduler_name' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'ddp_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'dvs_clipping' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'dvs_duration' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'DFA_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'trace_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'OTTT_input_trace_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'exclude_class' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'merge_polarities' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'denoise_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'extra_train_dataset' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'num_workers' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'chaching_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'pin_memory' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'UDA_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'alpha_uda' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'bias' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'last_lif' was locked by 'sweep' (ignored update).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "param {'devices': '0', 'single_step': True, 'unique_name': 'main', 'my_seed': 42, 'TIME': 10, 'BATCH': 16, 'IMAGE_SIZE': 128, 'which_data': 'DVS_GESTURE_TONIC', 'data_path': '/data2', 'rate_coding': False, 'lif_layer_v_init': 0, 'lif_layer_v_decay': 0.5, 'lif_layer_v_threshold': 0.25, 'lif_layer_v_reset': 0, 'lif_layer_sg_width': 1, 'synapse_conv_kernel_size': 3, 'synapse_conv_stride': 1, 'synapse_conv_padding': 1, 'synapse_trace_const1': 1, 'synapse_trace_const2': 0.5, 'pre_trained': False, 'convTrue_fcFalse': False, 'cfg': ['M', 'M', 200, 200], 'net_print': True, 'pre_trained_path': 'net_save/save_now_net_weights_{unique_name}.pth', 'learning_rate': 0.01, 'epoch_num': 100, 'tdBN_on': False, 'BN_on': False, 'surrogate': 'hard_sigmoid', 'BPTT_on': False, 'optimizer_what': 'SGD', 'scheduler_name': 'no', 'ddp_on': False, 'dvs_clipping': 5, 'dvs_duration': 100000, 'DFA_on': True, 'trace_on': True, 'OTTT_input_trace_on': False, 'exclude_class': True, 'merge_polarities': False, 'denoise_on': False, 'extra_train_dataset': 0, 'num_workers': 2, 'chaching_on': True, 'pin_memory': True, 'UDA_on': False, 'alpha_uda': 1, 'bias': True, 'last_lif': False, 'current epoch': 0} \n",
      "\n",
      "dataset_hash = ffa516e60c3efd5e0208f72b4c36cb84\n",
      "cache path exists\n",
      "\n",
      "device ==> cuda\n",
      "\n",
      "DataParallel(\n",
      "  (module): REBORN_MY_SNN_FC(\n",
      "    (layers): REBORN_MY_Sequential(\n",
      "      (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (2): DimChanger_for_FC()\n",
      "      (3): SYNAPSE_FC(in_features=2048, out_features=200, TIME=10, bias=True, sstep=True)\n",
      "      (4): LIF_layer(v_init=0, v_decay=0.5, v_threshold=0.25, v_reset=0, sg_width=1, surrogate=hard_sigmoid, BPTT_on=False, trace_const1=1, trace_const2=0.5, TIME=10, sstep=True, trace_on=True)\n",
      "      (5): Feedback_Receiver()\n",
      "      (6): SYNAPSE_FC(in_features=200, out_features=200, TIME=10, bias=True, sstep=True)\n",
      "      (7): LIF_layer(v_init=0, v_decay=0.5, v_threshold=0.25, v_reset=0, sg_width=1, surrogate=hard_sigmoid, BPTT_on=False, trace_const1=1, trace_const2=0.5, TIME=10, sstep=True, trace_on=True)\n",
      "      (8): Feedback_Receiver()\n",
      "      (9): SYNAPSE_FC(in_features=200, out_features=10, TIME=10, bias=True, sstep=True)\n",
      "      (DFA_top): Top_Gradient()\n",
      "    )\n",
      "  )\n",
      ")\n",
      "\n",
      "========================================================\n",
      "Trainable parameters: 452,010\n",
      "========================================================\n",
      "\n",
      "epoch-0   lr=['0.0100000'], tr/val_loss:  2.503669/  4.963148, val:  39.17%, val_best:  39.17%, tr:  34.01%, tr_best:  34.01%\n",
      "[module.layers.5] weight_fb parameter count: 2,000\n",
      "[module.layers.8] weight_fb parameter count: 2,000\n",
      "epoch-1   lr=['0.0100000'], tr/val_loss:  3.937032/  4.216144, val:  49.58%, val_best:  49.58%, tr:  42.29%, tr_best:  42.29%\n",
      "epoch-2   lr=['0.0100000'], tr/val_loss:  3.958833/  4.012508, val:  43.33%, val_best:  49.58%, tr:  55.36%, tr_best:  55.36%\n",
      "epoch-3   lr=['0.0100000'], tr/val_loss:  2.762637/  4.788441, val:  57.08%, val_best:  57.08%, tr:  60.88%, tr_best:  60.88%\n",
      "epoch-4   lr=['0.0100000'], tr/val_loss:  3.071386/  3.526334, val:  55.00%, val_best:  57.08%, tr:  61.49%, tr_best:  61.49%\n",
      "epoch-5   lr=['0.0100000'], tr/val_loss:  2.669860/  5.262634, val:  39.58%, val_best:  57.08%, tr:  67.01%, tr_best:  67.01%\n",
      "epoch-6   lr=['0.0100000'], tr/val_loss:  2.734665/  3.947920, val:  55.42%, val_best:  57.08%, tr:  65.99%, tr_best:  67.01%\n",
      "epoch-7   lr=['0.0100000'], tr/val_loss:  2.753634/  3.495977, val:  62.08%, val_best:  62.08%, tr:  67.72%, tr_best:  67.72%\n",
      "epoch-8   lr=['0.0100000'], tr/val_loss:  2.165284/  3.708152, val:  59.17%, val_best:  62.08%, tr:  75.59%, tr_best:  75.59%\n",
      "epoch-9   lr=['0.0100000'], tr/val_loss:  2.425370/  4.610687, val:  59.58%, val_best:  62.08%, tr:  74.06%, tr_best:  75.59%\n",
      "epoch-10  lr=['0.0100000'], tr/val_loss:  1.700684/  3.849767, val:  63.33%, val_best:  63.33%, tr:  81.82%, tr_best:  81.82%\n",
      "epoch-11  lr=['0.0100000'], tr/val_loss:  2.134919/  4.718184, val:  65.00%, val_best:  65.00%, tr:  80.18%, tr_best:  81.82%\n",
      "epoch-12  lr=['0.0100000'], tr/val_loss:  1.476773/  3.921806, val:  67.92%, val_best:  67.92%, tr:  86.52%, tr_best:  86.52%\n",
      "epoch-13  lr=['0.0100000'], tr/val_loss:  1.199597/  4.950042, val:  60.42%, val_best:  67.92%, tr:  91.01%, tr_best:  91.01%\n",
      "epoch-14  lr=['0.0100000'], tr/val_loss:  0.946792/  4.283746, val:  67.08%, val_best:  67.92%, tr:  92.44%, tr_best:  92.44%\n",
      "epoch-15  lr=['0.0100000'], tr/val_loss:  0.996080/  5.251200, val:  60.42%, val_best:  67.92%, tr:  92.24%, tr_best:  92.44%\n",
      "epoch-16  lr=['0.0100000'], tr/val_loss:  0.630884/  4.732636, val:  65.83%, val_best:  67.92%, tr:  96.73%, tr_best:  96.73%\n",
      "epoch-17  lr=['0.0100000'], tr/val_loss:  0.626638/  4.939404, val:  65.42%, val_best:  67.92%, tr:  97.04%, tr_best:  97.04%\n",
      "epoch-18  lr=['0.0100000'], tr/val_loss:  0.589466/  5.000634, val:  63.75%, val_best:  67.92%, tr:  97.24%, tr_best:  97.24%\n",
      "epoch-19  lr=['0.0100000'], tr/val_loss:  0.469373/  5.253811, val:  67.08%, val_best:  67.92%, tr:  98.67%, tr_best:  98.67%\n",
      "epoch-20  lr=['0.0100000'], tr/val_loss:  0.693398/  5.810117, val:  64.17%, val_best:  67.92%, tr:  95.20%, tr_best:  98.67%\n",
      "epoch-21  lr=['0.0100000'], tr/val_loss:  0.809329/  5.975043, val:  62.50%, val_best:  67.92%, tr:  95.40%, tr_best:  98.67%\n",
      "epoch-22  lr=['0.0100000'], tr/val_loss:  0.411453/  5.965905, val:  64.17%, val_best:  67.92%, tr:  98.57%, tr_best:  98.67%\n",
      "epoch-23  lr=['0.0100000'], tr/val_loss:  0.489961/  6.029598, val:  65.83%, val_best:  67.92%, tr:  98.47%, tr_best:  98.67%\n",
      "epoch-24  lr=['0.0100000'], tr/val_loss:  0.444133/  6.380871, val:  63.75%, val_best:  67.92%, tr:  98.98%, tr_best:  98.98%\n",
      "epoch-25  lr=['0.0100000'], tr/val_loss:  0.321225/  5.827341, val:  72.92%, val_best:  72.92%, tr:  99.39%, tr_best:  99.39%\n",
      "epoch-26  lr=['0.0100000'], tr/val_loss:  0.399725/  6.387766, val:  66.67%, val_best:  72.92%, tr:  98.47%, tr_best:  99.39%\n",
      "epoch-27  lr=['0.0100000'], tr/val_loss:  0.388629/  6.760312, val:  65.00%, val_best:  72.92%, tr:  98.57%, tr_best:  99.39%\n",
      "epoch-28  lr=['0.0100000'], tr/val_loss:  0.409292/  6.704301, val:  73.33%, val_best:  73.33%, tr:  98.57%, tr_best:  99.39%\n",
      "epoch-29  lr=['0.0100000'], tr/val_loss:  0.259671/  6.841270, val:  66.25%, val_best:  73.33%, tr:  99.90%, tr_best:  99.90%\n",
      "epoch-30  lr=['0.0100000'], tr/val_loss:  0.201923/  6.581762, val:  70.42%, val_best:  73.33%, tr:  99.80%, tr_best:  99.90%\n",
      "epoch-31  lr=['0.0100000'], tr/val_loss:  0.252937/  6.872006, val:  67.50%, val_best:  73.33%, tr:  99.90%, tr_best:  99.90%\n",
      "epoch-32  lr=['0.0100000'], tr/val_loss:  0.271536/  6.909353, val:  70.42%, val_best:  73.33%, tr:  99.18%, tr_best:  99.90%\n",
      "epoch-33  lr=['0.0100000'], tr/val_loss:  0.213245/  7.380481, val:  65.83%, val_best:  73.33%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-34  lr=['0.0100000'], tr/val_loss:  0.276721/  7.677198, val:  67.50%, val_best:  73.33%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-35  lr=['0.0100000'], tr/val_loss:  0.195425/  7.281458, val:  69.58%, val_best:  73.33%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-36  lr=['0.0100000'], tr/val_loss:  0.204083/  7.690673, val:  66.25%, val_best:  73.33%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-37  lr=['0.0100000'], tr/val_loss:  0.198169/  8.064405, val:  67.50%, val_best:  73.33%, tr:  99.80%, tr_best: 100.00%\n",
      "epoch-38  lr=['0.0100000'], tr/val_loss:  0.183065/  7.991152, val:  67.92%, val_best:  73.33%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-39  lr=['0.0100000'], tr/val_loss:  0.195244/  7.877870, val:  68.75%, val_best:  73.33%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-40  lr=['0.0100000'], tr/val_loss:  0.129048/  8.218621, val:  68.75%, val_best:  73.33%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-41  lr=['0.0100000'], tr/val_loss:  0.124613/  8.433738, val:  64.58%, val_best:  73.33%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-42  lr=['0.0100000'], tr/val_loss:  0.122122/  8.144193, val:  69.58%, val_best:  73.33%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-43  lr=['0.0100000'], tr/val_loss:  0.090874/  8.425656, val:  70.83%, val_best:  73.33%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-44  lr=['0.0100000'], tr/val_loss:  0.159698/  8.813735, val:  69.58%, val_best:  73.33%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-45  lr=['0.0100000'], tr/val_loss:  0.235749/  8.521513, val:  70.00%, val_best:  73.33%, tr:  99.90%, tr_best: 100.00%\n",
      "epoch-46  lr=['0.0100000'], tr/val_loss:  0.193587/  8.732387, val:  71.25%, val_best:  73.33%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-47  lr=['0.0100000'], tr/val_loss:  0.106461/  8.911486, val:  69.58%, val_best:  73.33%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-48  lr=['0.0100000'], tr/val_loss:  0.115350/  8.695052, val:  72.08%, val_best:  73.33%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-49  lr=['0.0100000'], tr/val_loss:  0.085259/  8.850033, val:  70.83%, val_best:  73.33%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-50  lr=['0.0100000'], tr/val_loss:  0.077344/  8.974107, val:  70.83%, val_best:  73.33%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-51  lr=['0.0100000'], tr/val_loss:  0.089823/  9.197337, val:  67.92%, val_best:  73.33%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-52  lr=['0.0100000'], tr/val_loss:  0.079758/  9.294926, val:  67.08%, val_best:  73.33%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-53  lr=['0.0100000'], tr/val_loss:  0.081857/  9.442208, val:  67.92%, val_best:  73.33%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-54  lr=['0.0100000'], tr/val_loss:  0.074320/  9.686124, val:  68.75%, val_best:  73.33%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-55  lr=['0.0100000'], tr/val_loss:  0.076880/  9.454491, val:  70.00%, val_best:  73.33%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-56  lr=['0.0100000'], tr/val_loss:  0.057215/  9.532625, val:  68.33%, val_best:  73.33%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-57  lr=['0.0100000'], tr/val_loss:  0.132718/  9.747094, val:  68.33%, val_best:  73.33%, tr:  99.80%, tr_best: 100.00%\n",
      "epoch-58  lr=['0.0100000'], tr/val_loss:  0.072336/  9.909523, val:  70.00%, val_best:  73.33%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-59  lr=['0.0100000'], tr/val_loss:  0.077107/  9.827073, val:  70.00%, val_best:  73.33%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-60  lr=['0.0100000'], tr/val_loss:  0.070450/ 10.351968, val:  67.92%, val_best:  73.33%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-61  lr=['0.0100000'], tr/val_loss:  0.049786/ 10.070358, val:  67.50%, val_best:  73.33%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-62  lr=['0.0100000'], tr/val_loss:  0.067585/ 10.310192, val:  69.17%, val_best:  73.33%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-63  lr=['0.0100000'], tr/val_loss:  0.055614/ 10.148213, val:  69.58%, val_best:  73.33%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-64  lr=['0.0100000'], tr/val_loss:  0.097038/ 10.429641, val:  68.75%, val_best:  73.33%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-65  lr=['0.0100000'], tr/val_loss:  0.072646/ 10.463409, val:  69.17%, val_best:  73.33%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-66  lr=['0.0100000'], tr/val_loss:  0.055438/ 10.799836, val:  67.92%, val_best:  73.33%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-67  lr=['0.0100000'], tr/val_loss:  0.062186/ 10.874621, val:  67.92%, val_best:  73.33%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-68  lr=['0.0100000'], tr/val_loss:  0.049331/ 10.822680, val:  68.33%, val_best:  73.33%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-69  lr=['0.0100000'], tr/val_loss:  0.033512/ 10.591765, val:  70.42%, val_best:  73.33%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-70  lr=['0.0100000'], tr/val_loss:  0.028616/ 10.733056, val:  68.75%, val_best:  73.33%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-71  lr=['0.0100000'], tr/val_loss:  0.033395/ 10.719879, val:  68.75%, val_best:  73.33%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-72  lr=['0.0100000'], tr/val_loss:  0.046528/ 10.932072, val:  69.17%, val_best:  73.33%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-73  lr=['0.0100000'], tr/val_loss:  0.051619/ 10.897018, val:  69.58%, val_best:  73.33%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-74  lr=['0.0100000'], tr/val_loss:  0.045853/ 10.915951, val:  70.00%, val_best:  73.33%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-75  lr=['0.0100000'], tr/val_loss:  0.032692/ 11.042583, val:  68.33%, val_best:  73.33%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-76  lr=['0.0100000'], tr/val_loss:  0.042981/ 11.143847, val:  68.75%, val_best:  73.33%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-77  lr=['0.0100000'], tr/val_loss:  0.041711/ 11.061902, val:  70.83%, val_best:  73.33%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-78  lr=['0.0100000'], tr/val_loss:  0.023522/ 10.894284, val:  69.17%, val_best:  73.33%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-79  lr=['0.0100000'], tr/val_loss:  0.023596/ 11.050441, val:  69.58%, val_best:  73.33%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-80  lr=['0.0100000'], tr/val_loss:  0.030929/ 11.020174, val:  70.83%, val_best:  73.33%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-81  lr=['0.0100000'], tr/val_loss:  0.044190/ 11.091753, val:  71.25%, val_best:  73.33%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-82  lr=['0.0100000'], tr/val_loss:  0.043057/ 11.434172, val:  68.33%, val_best:  73.33%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-83  lr=['0.0100000'], tr/val_loss:  0.088093/ 11.526285, val:  70.42%, val_best:  73.33%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-84  lr=['0.0100000'], tr/val_loss:  0.032106/ 11.647162, val:  68.33%, val_best:  73.33%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-85  lr=['0.0100000'], tr/val_loss:  0.048219/ 11.467930, val:  69.17%, val_best:  73.33%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-86  lr=['0.0100000'], tr/val_loss:  0.038996/ 11.438033, val:  71.67%, val_best:  73.33%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-87  lr=['0.0100000'], tr/val_loss:  0.017116/ 11.674014, val:  68.33%, val_best:  73.33%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-88  lr=['0.0100000'], tr/val_loss:  0.017703/ 11.402699, val:  70.42%, val_best:  73.33%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-89  lr=['0.0100000'], tr/val_loss:  0.027159/ 11.365440, val:  70.83%, val_best:  73.33%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-90  lr=['0.0100000'], tr/val_loss:  0.019653/ 11.572648, val:  68.75%, val_best:  73.33%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-91  lr=['0.0100000'], tr/val_loss:  0.016428/ 11.592078, val:  68.75%, val_best:  73.33%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-92  lr=['0.0100000'], tr/val_loss:  0.019243/ 11.434210, val:  70.42%, val_best:  73.33%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-93  lr=['0.0100000'], tr/val_loss:  0.024134/ 11.460732, val:  71.67%, val_best:  73.33%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-94  lr=['0.0100000'], tr/val_loss:  0.026932/ 11.643264, val:  68.75%, val_best:  73.33%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-95  lr=['0.0100000'], tr/val_loss:  0.030793/ 11.978926, val:  67.92%, val_best:  73.33%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-96  lr=['0.0100000'], tr/val_loss:  0.036857/ 11.700307, val:  71.67%, val_best:  73.33%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-97  lr=['0.0100000'], tr/val_loss:  0.065251/ 11.592716, val:  71.67%, val_best:  73.33%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-98  lr=['0.0100000'], tr/val_loss:  0.029931/ 11.829807, val:  70.42%, val_best:  73.33%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-99  lr=['0.0100000'], tr/val_loss:  0.029960/ 11.849826, val:  70.42%, val_best:  73.33%, tr: 100.00%, tr_best: 100.00%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d5a178613a644601a8815907485057d8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.006 MB of 0.006 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>iter_acc</td><td>▁▅▃▆▆▆▇█▇███████████████████████████████</td></tr><tr><td>summary_val_acc</td><td>▁▂▄▆▅▇▇▇▇▆▆▇▇██▇▇████▇▇▇█▇▇▇▇▇▇██▇▇▇██▇█</td></tr><tr><td>tr_acc</td><td>▁▃▄▅▅▇▇█████████████████████████████████</td></tr><tr><td>tr_epoch_loss</td><td>▅█▆▆▅▄▃▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_acc_best</td><td>▁▃▅▆▆▇▇▇▇▇▇█████████████████████████████</td></tr><tr><td>val_acc_now</td><td>▁▂▄▆▅▇▇▇▇▆▆▇▇██▇▇████▇▇▇█▇▇▇▇▇▇██▇▇▇██▇█</td></tr><tr><td>val_loss</td><td>▂▁▁▁▂▁▂▂▂▃▃▃▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇▇███▇███</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>99</td></tr><tr><td>iter_acc</td><td>1.0</td></tr><tr><td>tr_acc</td><td>1.0</td></tr><tr><td>tr_epoch_loss</td><td>0.02996</td></tr><tr><td>val_acc_best</td><td>0.73333</td></tr><tr><td>val_acc_now</td><td>0.70417</td></tr><tr><td>val_loss</td><td>11.84983</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">helpful-sweep-26</strong> at: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/pbxh4eso' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/pbxh4eso</a><br/> View project at: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>/data2/bh_wandb/wandb/run-20250429_233249-pbxh4eso/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require(\"core\")`! See https://wandb.me/wandb-core for more information."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Sweep Agent: Waiting for job.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Job received.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: zh5lysjg with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBATCH: 16\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBN_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBPTT_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tDFA_on: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tIMAGE_SIZE: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tOTTT_input_trace_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tTIME: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tUDA_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \talpha_uda: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbias: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcfg: ['M', 'M', 200, 200]\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tchaching_on: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tconvTrue_fcFalse: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdata_path: /data2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tddp_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdenoise_on: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdvs_clipping: 5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdvs_duration: 100000\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepoch_num: 100\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \texclude_class: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \textra_train_dataset: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlast_lif: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.001\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_sg_width: 5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_decay: 0.5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_init: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_reset: 10000\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_threshold: 0.25\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmerge_polarities: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmy_seed: 42\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnet_print: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_workers: 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer_what: SGD\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tpin_memory: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tpre_trained: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tpre_trained_path: net_save/save_now_net_weights_{unique_name}.pth\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \trate_coding: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tscheduler_name: no\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsingle_step: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsurrogate: hard_sigmoid\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_conv_kernel_size: 3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_conv_padding: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_conv_stride: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_trace_const1: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_trace_const2: 0.5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \ttdBN_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \ttrace_on: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \twhich_data: DVS_GESTURE_TONIC\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.19.10 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.17.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/data2/bh_wandb/wandb/run-20250429_234000-zh5lysjg</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/zh5lysjg' target=\"_blank\">dutiful-sweep-30</a></strong> to <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/6pj3lh8j' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/6pj3lh8j</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/6pj3lh8j' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/6pj3lh8j</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/zh5lysjg' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/zh5lysjg</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'single_step' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'my_seed' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'TIME' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BATCH' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'IMAGE_SIZE' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'which_data' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'data_path' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'rate_coding' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_init' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_decay' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_threshold' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_reset' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_sg_width' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_conv_kernel_size' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_conv_stride' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_conv_padding' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_trace_const1' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_trace_const2' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'pre_trained' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'convTrue_fcFalse' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'cfg' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'net_print' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'pre_trained_path' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'learning_rate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'epoch_num' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'tdBN_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BN_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'surrogate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BPTT_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'optimizer_what' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'scheduler_name' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'ddp_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'dvs_clipping' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'dvs_duration' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'DFA_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'trace_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'OTTT_input_trace_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'exclude_class' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'merge_polarities' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'denoise_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'extra_train_dataset' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'num_workers' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'chaching_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'pin_memory' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'UDA_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'alpha_uda' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'bias' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'last_lif' was locked by 'sweep' (ignored update).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "param {'devices': '0', 'single_step': True, 'unique_name': 'main', 'my_seed': 42, 'TIME': 10, 'BATCH': 16, 'IMAGE_SIZE': 128, 'which_data': 'DVS_GESTURE_TONIC', 'data_path': '/data2', 'rate_coding': False, 'lif_layer_v_init': 0, 'lif_layer_v_decay': 0.5, 'lif_layer_v_threshold': 0.25, 'lif_layer_v_reset': 10000, 'lif_layer_sg_width': 5, 'synapse_conv_kernel_size': 3, 'synapse_conv_stride': 1, 'synapse_conv_padding': 1, 'synapse_trace_const1': 1, 'synapse_trace_const2': 0.5, 'pre_trained': False, 'convTrue_fcFalse': False, 'cfg': ['M', 'M', 200, 200], 'net_print': True, 'pre_trained_path': 'net_save/save_now_net_weights_{unique_name}.pth', 'learning_rate': 0.001, 'epoch_num': 100, 'tdBN_on': False, 'BN_on': False, 'surrogate': 'hard_sigmoid', 'BPTT_on': False, 'optimizer_what': 'SGD', 'scheduler_name': 'no', 'ddp_on': False, 'dvs_clipping': 5, 'dvs_duration': 100000, 'DFA_on': True, 'trace_on': True, 'OTTT_input_trace_on': False, 'exclude_class': True, 'merge_polarities': False, 'denoise_on': True, 'extra_train_dataset': 0, 'num_workers': 2, 'chaching_on': True, 'pin_memory': True, 'UDA_on': False, 'alpha_uda': 1, 'bias': True, 'last_lif': False, 'current epoch': 0} \n",
      "\n",
      "dataset_hash = 63cc597115630ec173f3099200061e53\n",
      "cache path exists\n",
      "\n",
      "device ==> cuda\n",
      "\n",
      "DataParallel(\n",
      "  (module): REBORN_MY_SNN_FC(\n",
      "    (layers): REBORN_MY_Sequential(\n",
      "      (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (2): DimChanger_for_FC()\n",
      "      (3): SYNAPSE_FC(in_features=2048, out_features=200, TIME=10, bias=True, sstep=True)\n",
      "      (4): LIF_layer(v_init=0, v_decay=0.5, v_threshold=0.25, v_reset=10000, sg_width=5, surrogate=hard_sigmoid, BPTT_on=False, trace_const1=1, trace_const2=0.5, TIME=10, sstep=True, trace_on=True)\n",
      "      (5): Feedback_Receiver()\n",
      "      (6): SYNAPSE_FC(in_features=200, out_features=200, TIME=10, bias=True, sstep=True)\n",
      "      (7): LIF_layer(v_init=0, v_decay=0.5, v_threshold=0.25, v_reset=10000, sg_width=5, surrogate=hard_sigmoid, BPTT_on=False, trace_const1=1, trace_const2=0.5, TIME=10, sstep=True, trace_on=True)\n",
      "      (8): Feedback_Receiver()\n",
      "      (9): SYNAPSE_FC(in_features=200, out_features=10, TIME=10, bias=True, sstep=True)\n",
      "      (DFA_top): Top_Gradient()\n",
      "    )\n",
      "  )\n",
      ")\n",
      "\n",
      "========================================================\n",
      "Trainable parameters: 452,010\n",
      "========================================================\n",
      "\n",
      "epoch-0   lr=['0.0010000'], tr/val_loss:  1.990620/  1.614645, val:  46.67%, val_best:  46.67%, tr:  25.33%, tr_best:  25.33%\n",
      "[module.layers.5] weight_fb parameter count: 2,000\n",
      "[module.layers.8] weight_fb parameter count: 2,000\n",
      "epoch-1   lr=['0.0010000'], tr/val_loss:  1.358078/  1.534883, val:  54.58%, val_best:  54.58%, tr:  56.28%, tr_best:  56.28%\n",
      "epoch-2   lr=['0.0010000'], tr/val_loss:  1.237204/  1.496169, val:  56.25%, val_best:  56.25%, tr:  60.57%, tr_best:  60.57%\n",
      "epoch-3   lr=['0.0010000'], tr/val_loss:  1.088470/  1.548273, val:  55.00%, val_best:  56.25%, tr:  67.01%, tr_best:  67.01%\n",
      "epoch-4   lr=['0.0010000'], tr/val_loss:  1.039401/  1.400908, val:  59.17%, val_best:  59.17%, tr:  68.64%, tr_best:  68.64%\n",
      "epoch-5   lr=['0.0010000'], tr/val_loss:  1.017616/  1.456495, val:  57.08%, val_best:  59.17%, tr:  70.99%, tr_best:  70.99%\n",
      "epoch-6   lr=['0.0010000'], tr/val_loss:  0.985705/  1.409472, val:  57.50%, val_best:  59.17%, tr:  71.20%, tr_best:  71.20%\n",
      "epoch-7   lr=['0.0010000'], tr/val_loss:  0.924223/  1.550875, val:  60.83%, val_best:  60.83%, tr:  73.03%, tr_best:  73.03%\n",
      "epoch-8   lr=['0.0010000'], tr/val_loss:  0.911912/  1.445048, val:  64.58%, val_best:  64.58%, tr:  73.14%, tr_best:  73.14%\n",
      "epoch-9   lr=['0.0010000'], tr/val_loss:  0.853157/  1.518858, val:  60.83%, val_best:  64.58%, tr:  81.82%, tr_best:  81.82%\n",
      "epoch-10  lr=['0.0010000'], tr/val_loss:  0.856291/  1.645494, val:  62.92%, val_best:  64.58%, tr:  81.82%, tr_best:  81.82%\n",
      "epoch-11  lr=['0.0010000'], tr/val_loss:  0.755948/  1.477123, val:  71.25%, val_best:  71.25%, tr:  86.62%, tr_best:  86.62%\n",
      "epoch-12  lr=['0.0010000'], tr/val_loss:  0.724195/  1.533547, val:  72.08%, val_best:  72.08%, tr:  90.09%, tr_best:  90.09%\n",
      "epoch-13  lr=['0.0010000'], tr/val_loss:  0.683185/  1.546304, val:  70.42%, val_best:  72.08%, tr:  89.48%, tr_best:  90.09%\n",
      "epoch-14  lr=['0.0010000'], tr/val_loss:  0.632084/  1.664972, val:  69.17%, val_best:  72.08%, tr:  91.73%, tr_best:  91.73%\n",
      "epoch-15  lr=['0.0010000'], tr/val_loss:  0.616362/  1.693464, val:  70.00%, val_best:  72.08%, tr:  92.85%, tr_best:  92.85%\n",
      "epoch-16  lr=['0.0010000'], tr/val_loss:  0.588018/  1.674339, val:  72.92%, val_best:  72.92%, tr:  94.48%, tr_best:  94.48%\n",
      "epoch-17  lr=['0.0010000'], tr/val_loss:  0.572797/  1.753455, val:  71.25%, val_best:  72.92%, tr:  96.12%, tr_best:  96.12%\n",
      "epoch-18  lr=['0.0010000'], tr/val_loss:  0.546666/  1.891406, val:  69.58%, val_best:  72.92%, tr:  95.71%, tr_best:  96.12%\n",
      "epoch-19  lr=['0.0010000'], tr/val_loss:  0.522310/  1.798971, val:  71.67%, val_best:  72.92%, tr:  96.12%, tr_best:  96.12%\n",
      "epoch-20  lr=['0.0010000'], tr/val_loss:  0.495528/  1.912066, val:  71.25%, val_best:  72.92%, tr:  97.55%, tr_best:  97.55%\n",
      "epoch-21  lr=['0.0010000'], tr/val_loss:  0.484988/  1.956352, val:  71.25%, val_best:  72.92%, tr:  97.04%, tr_best:  97.55%\n",
      "epoch-22  lr=['0.0010000'], tr/val_loss:  0.462601/  1.919845, val:  75.83%, val_best:  75.83%, tr:  97.96%, tr_best:  97.96%\n",
      "epoch-23  lr=['0.0010000'], tr/val_loss:  0.467776/  1.945479, val:  72.50%, val_best:  75.83%, tr:  97.34%, tr_best:  97.96%\n",
      "epoch-24  lr=['0.0010000'], tr/val_loss:  0.423543/  2.013102, val:  74.17%, val_best:  75.83%, tr:  98.98%, tr_best:  98.98%\n",
      "epoch-25  lr=['0.0010000'], tr/val_loss:  0.409311/  2.012435, val:  77.92%, val_best:  77.92%, tr:  98.57%, tr_best:  98.98%\n",
      "epoch-26  lr=['0.0010000'], tr/val_loss:  0.441800/  2.044925, val:  77.92%, val_best:  77.92%, tr:  96.94%, tr_best:  98.98%\n",
      "epoch-27  lr=['0.0010000'], tr/val_loss:  0.400491/  2.156753, val:  74.17%, val_best:  77.92%, tr:  98.98%, tr_best:  98.98%\n",
      "epoch-28  lr=['0.0010000'], tr/val_loss:  0.369612/  2.102228, val:  77.92%, val_best:  77.92%, tr:  99.39%, tr_best:  99.39%\n",
      "epoch-29  lr=['0.0010000'], tr/val_loss:  0.359280/  2.312997, val:  72.08%, val_best:  77.92%, tr:  99.39%, tr_best:  99.39%\n",
      "epoch-30  lr=['0.0010000'], tr/val_loss:  0.343359/  2.257428, val:  77.50%, val_best:  77.92%, tr:  99.18%, tr_best:  99.39%\n",
      "epoch-31  lr=['0.0010000'], tr/val_loss:  0.341378/  2.311975, val:  80.00%, val_best:  80.00%, tr:  99.28%, tr_best:  99.39%\n",
      "epoch-32  lr=['0.0010000'], tr/val_loss:  0.343315/  2.412877, val:  76.25%, val_best:  80.00%, tr:  99.69%, tr_best:  99.69%\n",
      "epoch-33  lr=['0.0010000'], tr/val_loss:  0.345590/  2.443104, val:  78.75%, val_best:  80.00%, tr:  99.28%, tr_best:  99.69%\n",
      "epoch-34  lr=['0.0010000'], tr/val_loss:  0.323223/  2.578013, val:  75.42%, val_best:  80.00%, tr:  99.39%, tr_best:  99.69%\n",
      "epoch-35  lr=['0.0010000'], tr/val_loss:  0.310358/  2.606244, val:  73.75%, val_best:  80.00%, tr:  99.69%, tr_best:  99.69%\n",
      "epoch-36  lr=['0.0010000'], tr/val_loss:  0.303127/  2.496770, val:  78.33%, val_best:  80.00%, tr:  99.69%, tr_best:  99.69%\n",
      "epoch-37  lr=['0.0010000'], tr/val_loss:  0.287391/  2.627124, val:  77.50%, val_best:  80.00%, tr:  99.69%, tr_best:  99.69%\n",
      "epoch-38  lr=['0.0010000'], tr/val_loss:  0.281313/  2.645207, val:  77.08%, val_best:  80.00%, tr:  99.80%, tr_best:  99.80%\n",
      "epoch-39  lr=['0.0010000'], tr/val_loss:  0.292397/  2.612880, val:  78.75%, val_best:  80.00%, tr:  99.69%, tr_best:  99.80%\n",
      "epoch-40  lr=['0.0010000'], tr/val_loss:  0.267458/  2.751441, val:  75.83%, val_best:  80.00%, tr:  99.80%, tr_best:  99.80%\n",
      "epoch-41  lr=['0.0010000'], tr/val_loss:  0.246933/  2.734957, val:  75.83%, val_best:  80.00%, tr:  99.90%, tr_best:  99.90%\n",
      "epoch-42  lr=['0.0010000'], tr/val_loss:  0.246771/  2.791776, val:  76.25%, val_best:  80.00%, tr:  99.90%, tr_best:  99.90%\n",
      "epoch-43  lr=['0.0010000'], tr/val_loss:  0.243511/  2.860353, val:  75.42%, val_best:  80.00%, tr:  99.80%, tr_best:  99.90%\n",
      "epoch-44  lr=['0.0010000'], tr/val_loss:  0.223851/  2.807364, val:  79.17%, val_best:  80.00%, tr:  99.90%, tr_best:  99.90%\n",
      "epoch-45  lr=['0.0010000'], tr/val_loss:  0.212093/  2.841908, val:  77.50%, val_best:  80.00%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-46  lr=['0.0010000'], tr/val_loss:  0.219320/  2.879365, val:  78.33%, val_best:  80.00%, tr:  99.90%, tr_best: 100.00%\n",
      "epoch-47  lr=['0.0010000'], tr/val_loss:  0.200096/  2.882658, val:  77.92%, val_best:  80.00%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-48  lr=['0.0010000'], tr/val_loss:  0.204343/  2.915783, val:  79.58%, val_best:  80.00%, tr:  99.80%, tr_best: 100.00%\n",
      "epoch-49  lr=['0.0010000'], tr/val_loss:  0.196792/  3.023282, val:  78.75%, val_best:  80.00%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-50  lr=['0.0010000'], tr/val_loss:  0.190461/  3.041105, val:  77.50%, val_best:  80.00%, tr:  99.90%, tr_best: 100.00%\n",
      "epoch-51  lr=['0.0010000'], tr/val_loss:  0.184975/  3.030704, val:  80.00%, val_best:  80.00%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-52  lr=['0.0010000'], tr/val_loss:  0.191217/  3.020223, val:  77.92%, val_best:  80.00%, tr:  99.90%, tr_best: 100.00%\n",
      "epoch-53  lr=['0.0010000'], tr/val_loss:  0.182870/  3.097400, val:  78.33%, val_best:  80.00%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-54  lr=['0.0010000'], tr/val_loss:  0.185091/  3.106407, val:  79.58%, val_best:  80.00%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-55  lr=['0.0010000'], tr/val_loss:  0.176383/  3.256166, val:  78.33%, val_best:  80.00%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-56  lr=['0.0010000'], tr/val_loss:  0.173829/  3.347063, val:  74.58%, val_best:  80.00%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-57  lr=['0.0010000'], tr/val_loss:  0.164911/  3.303178, val:  77.92%, val_best:  80.00%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-58  lr=['0.0010000'], tr/val_loss:  0.162231/  3.336072, val:  75.00%, val_best:  80.00%, tr:  99.90%, tr_best: 100.00%\n",
      "epoch-59  lr=['0.0010000'], tr/val_loss:  0.158120/  3.353116, val:  78.33%, val_best:  80.00%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-60  lr=['0.0010000'], tr/val_loss:  0.144508/  3.342754, val:  78.33%, val_best:  80.00%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-61  lr=['0.0010000'], tr/val_loss:  0.144166/  3.424546, val:  77.92%, val_best:  80.00%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-62  lr=['0.0010000'], tr/val_loss:  0.141506/  3.401366, val:  77.08%, val_best:  80.00%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-63  lr=['0.0010000'], tr/val_loss:  0.137469/  3.458140, val:  78.75%, val_best:  80.00%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-64  lr=['0.0010000'], tr/val_loss:  0.133733/  3.503126, val:  78.33%, val_best:  80.00%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-65  lr=['0.0010000'], tr/val_loss:  0.129135/  3.532704, val:  76.67%, val_best:  80.00%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-66  lr=['0.0010000'], tr/val_loss:  0.123592/  3.605501, val:  76.25%, val_best:  80.00%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-67  lr=['0.0010000'], tr/val_loss:  0.123901/  3.594405, val:  76.67%, val_best:  80.00%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-68  lr=['0.0010000'], tr/val_loss:  0.123001/  3.596173, val:  77.92%, val_best:  80.00%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-69  lr=['0.0010000'], tr/val_loss:  0.115169/  3.636011, val:  78.33%, val_best:  80.00%, tr:  99.90%, tr_best: 100.00%\n",
      "epoch-70  lr=['0.0010000'], tr/val_loss:  0.110719/  3.614243, val:  77.50%, val_best:  80.00%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-71  lr=['0.0010000'], tr/val_loss:  0.138473/  3.764203, val:  77.50%, val_best:  80.00%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-72  lr=['0.0010000'], tr/val_loss:  0.125683/  3.804337, val:  77.50%, val_best:  80.00%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-73  lr=['0.0010000'], tr/val_loss:  0.117181/  3.707913, val:  78.33%, val_best:  80.00%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-74  lr=['0.0010000'], tr/val_loss:  0.114543/  3.710279, val:  78.33%, val_best:  80.00%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-75  lr=['0.0010000'], tr/val_loss:  0.113458/  3.818827, val:  76.25%, val_best:  80.00%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-76  lr=['0.0010000'], tr/val_loss:  0.106793/  3.818970, val:  76.25%, val_best:  80.00%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-77  lr=['0.0010000'], tr/val_loss:  0.112575/  3.880703, val:  77.50%, val_best:  80.00%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-78  lr=['0.0010000'], tr/val_loss:  0.111668/  3.866410, val:  77.92%, val_best:  80.00%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-79  lr=['0.0010000'], tr/val_loss:  0.106782/  3.934253, val:  78.75%, val_best:  80.00%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-80  lr=['0.0010000'], tr/val_loss:  0.104421/  3.921899, val:  78.75%, val_best:  80.00%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-81  lr=['0.0010000'], tr/val_loss:  0.097108/  3.927712, val:  77.92%, val_best:  80.00%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-82  lr=['0.0010000'], tr/val_loss:  0.088582/  3.954571, val:  78.75%, val_best:  80.00%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-83  lr=['0.0010000'], tr/val_loss:  0.106914/  4.028459, val:  77.08%, val_best:  80.00%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-84  lr=['0.0010000'], tr/val_loss:  0.086441/  3.981638, val:  77.92%, val_best:  80.00%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-85  lr=['0.0010000'], tr/val_loss:  0.090185/  4.003356, val:  78.33%, val_best:  80.00%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-86  lr=['0.0010000'], tr/val_loss:  0.088867/  4.022614, val:  77.50%, val_best:  80.00%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-87  lr=['0.0010000'], tr/val_loss:  0.086446/  4.072832, val:  78.33%, val_best:  80.00%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-88  lr=['0.0010000'], tr/val_loss:  0.083575/  4.054514, val:  79.17%, val_best:  80.00%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-89  lr=['0.0010000'], tr/val_loss:  0.084419/  4.092315, val:  78.33%, val_best:  80.00%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-90  lr=['0.0010000'], tr/val_loss:  0.094001/  4.043314, val:  78.75%, val_best:  80.00%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-91  lr=['0.0010000'], tr/val_loss:  0.088405/  4.097186, val:  78.33%, val_best:  80.00%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-92  lr=['0.0010000'], tr/val_loss:  0.079824/  4.089822, val:  79.58%, val_best:  80.00%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-93  lr=['0.0010000'], tr/val_loss:  0.087113/  4.095501, val:  79.58%, val_best:  80.00%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-94  lr=['0.0010000'], tr/val_loss:  0.083289/  4.190217, val:  76.67%, val_best:  80.00%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-95  lr=['0.0010000'], tr/val_loss:  0.078172/  4.108737, val:  79.17%, val_best:  80.00%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-96  lr=['0.0010000'], tr/val_loss:  0.075813/  4.196715, val:  77.92%, val_best:  80.00%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-97  lr=['0.0010000'], tr/val_loss:  0.084520/  4.179085, val:  78.75%, val_best:  80.00%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-98  lr=['0.0010000'], tr/val_loss:  0.084172/  4.199755, val:  76.67%, val_best:  80.00%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-99  lr=['0.0010000'], tr/val_loss:  0.076158/  4.245149, val:  79.17%, val_best:  80.00%, tr: 100.00%, tr_best: 100.00%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "94d93f7f68234607b8e6e1241b8dcd48",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.006 MB of 0.006 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>iter_acc</td><td>▁▆▄▁▄▅█▅████████████████████████████████</td></tr><tr><td>summary_val_acc</td><td>▁▃▄▄▄▆▆▆▆▆▇█▆▇▇██▇████████▇▇██▇█████████</td></tr><tr><td>tr_acc</td><td>▁▄▅▅▆▇▇█████████████████████████████████</td></tr><tr><td>tr_epoch_loss</td><td>█▅▅▄▄▃▃▃▃▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_acc_best</td><td>▁▃▄▄▅▆▆▇▇▇▇█████████████████████████████</td></tr><tr><td>val_acc_now</td><td>▁▃▄▄▄▆▆▆▆▆▇█▆▇▇██▇████████▇▇██▇█████████</td></tr><tr><td>val_loss</td><td>▂▁▁▁▁▁▂▂▂▂▃▃▃▄▄▄▄▅▅▅▅▅▅▆▆▆▆▇▇▇▇▇▇▇██████</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>99</td></tr><tr><td>iter_acc</td><td>1.0</td></tr><tr><td>tr_acc</td><td>1.0</td></tr><tr><td>tr_epoch_loss</td><td>0.07616</td></tr><tr><td>val_acc_best</td><td>0.8</td></tr><tr><td>val_acc_now</td><td>0.79167</td></tr><tr><td>val_loss</td><td>4.24515</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">dutiful-sweep-30</strong> at: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/zh5lysjg' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/zh5lysjg</a><br/> View project at: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>/data2/bh_wandb/wandb/run-20250429_234000-zh5lysjg/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require(\"core\")`! See https://wandb.me/wandb-core for more information."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: pzwe2ezr with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBATCH: 16\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBN_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBPTT_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tDFA_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tIMAGE_SIZE: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tOTTT_input_trace_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tTIME: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tUDA_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \talpha_uda: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbias: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcfg: ['M', 'M', 200, 200]\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tchaching_on: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tconvTrue_fcFalse: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdata_path: /data2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tddp_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdenoise_on: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdvs_clipping: 5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdvs_duration: 100000\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepoch_num: 100\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \texclude_class: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \textra_train_dataset: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlast_lif: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.001\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_sg_width: 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_decay: 0.5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_init: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_reset: 10000\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_threshold: 0.25\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmerge_polarities: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmy_seed: 42\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnet_print: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_workers: 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer_what: SGD\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tpin_memory: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tpre_trained: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tpre_trained_path: net_save/save_now_net_weights_{unique_name}.pth\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \trate_coding: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tscheduler_name: no\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsingle_step: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsurrogate: hard_sigmoid\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_conv_kernel_size: 3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_conv_padding: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_conv_stride: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_trace_const1: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_trace_const2: 0.5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \ttdBN_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \ttrace_on: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \twhich_data: DVS_GESTURE_TONIC\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.19.10 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.17.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/data2/bh_wandb/wandb/run-20250429_234712-pzwe2ezr</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/pzwe2ezr' target=\"_blank\">quiet-sweep-35</a></strong> to <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/6pj3lh8j' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/6pj3lh8j</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/6pj3lh8j' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/6pj3lh8j</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/pzwe2ezr' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/pzwe2ezr</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'single_step' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'my_seed' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'TIME' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BATCH' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'IMAGE_SIZE' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'which_data' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'data_path' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'rate_coding' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_init' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_decay' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_threshold' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_reset' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_sg_width' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_conv_kernel_size' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_conv_stride' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_conv_padding' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_trace_const1' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_trace_const2' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'pre_trained' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'convTrue_fcFalse' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'cfg' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'net_print' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'pre_trained_path' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'learning_rate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'epoch_num' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'tdBN_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BN_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'surrogate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BPTT_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'optimizer_what' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'scheduler_name' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'ddp_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'dvs_clipping' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'dvs_duration' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'DFA_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'trace_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'OTTT_input_trace_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'exclude_class' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'merge_polarities' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'denoise_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'extra_train_dataset' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'num_workers' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'chaching_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'pin_memory' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'UDA_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'alpha_uda' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'bias' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'last_lif' was locked by 'sweep' (ignored update).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "param {'devices': '0', 'single_step': True, 'unique_name': 'main', 'my_seed': 42, 'TIME': 10, 'BATCH': 16, 'IMAGE_SIZE': 128, 'which_data': 'DVS_GESTURE_TONIC', 'data_path': '/data2', 'rate_coding': False, 'lif_layer_v_init': 0, 'lif_layer_v_decay': 0.5, 'lif_layer_v_threshold': 0.25, 'lif_layer_v_reset': 10000, 'lif_layer_sg_width': 2, 'synapse_conv_kernel_size': 3, 'synapse_conv_stride': 1, 'synapse_conv_padding': 1, 'synapse_trace_const1': 1, 'synapse_trace_const2': 0.5, 'pre_trained': False, 'convTrue_fcFalse': False, 'cfg': ['M', 'M', 200, 200], 'net_print': True, 'pre_trained_path': 'net_save/save_now_net_weights_{unique_name}.pth', 'learning_rate': 0.001, 'epoch_num': 100, 'tdBN_on': False, 'BN_on': False, 'surrogate': 'hard_sigmoid', 'BPTT_on': False, 'optimizer_what': 'SGD', 'scheduler_name': 'no', 'ddp_on': False, 'dvs_clipping': 5, 'dvs_duration': 100000, 'DFA_on': False, 'trace_on': True, 'OTTT_input_trace_on': False, 'exclude_class': True, 'merge_polarities': False, 'denoise_on': True, 'extra_train_dataset': 0, 'num_workers': 2, 'chaching_on': True, 'pin_memory': True, 'UDA_on': False, 'alpha_uda': 1, 'bias': True, 'last_lif': False, 'current epoch': 0} \n",
      "\n",
      "dataset_hash = 63cc597115630ec173f3099200061e53\n",
      "cache path exists\n",
      "\n",
      "device ==> cuda\n",
      "\n",
      "DataParallel(\n",
      "  (module): REBORN_MY_SNN_FC(\n",
      "    (layers): REBORN_MY_Sequential(\n",
      "      (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (2): DimChanger_for_FC()\n",
      "      (3): SYNAPSE_FC(in_features=2048, out_features=200, TIME=10, bias=True, sstep=True)\n",
      "      (4): LIF_layer(v_init=0, v_decay=0.5, v_threshold=0.25, v_reset=10000, sg_width=2, surrogate=hard_sigmoid, BPTT_on=False, trace_const1=1, trace_const2=0.5, TIME=10, sstep=True, trace_on=True)\n",
      "      (5): SYNAPSE_FC(in_features=200, out_features=200, TIME=10, bias=True, sstep=True)\n",
      "      (6): LIF_layer(v_init=0, v_decay=0.5, v_threshold=0.25, v_reset=10000, sg_width=2, surrogate=hard_sigmoid, BPTT_on=False, trace_const1=1, trace_const2=0.5, TIME=10, sstep=True, trace_on=True)\n",
      "      (7): SYNAPSE_FC(in_features=200, out_features=10, TIME=10, bias=True, sstep=True)\n",
      "    )\n",
      "  )\n",
      ")\n",
      "\n",
      "========================================================\n",
      "Trainable parameters: 452,010\n",
      "========================================================\n",
      "\n",
      "epoch-0   lr=['0.0010000'], tr/val_loss:  2.259325/  2.166692, val:  25.42%, val_best:  25.42%, tr:  15.63%, tr_best:  15.63%\n",
      "epoch-1   lr=['0.0010000'], tr/val_loss:  1.951459/  1.832348, val:  47.92%, val_best:  47.92%, tr:  37.90%, tr_best:  37.90%\n",
      "epoch-2   lr=['0.0010000'], tr/val_loss:  1.623138/  1.666077, val:  55.42%, val_best:  55.42%, tr:  54.03%, tr_best:  54.03%\n",
      "epoch-3   lr=['0.0010000'], tr/val_loss:  1.460078/  1.635147, val:  57.08%, val_best:  57.08%, tr:  61.39%, tr_best:  61.39%\n",
      "epoch-4   lr=['0.0010000'], tr/val_loss:  1.385512/  1.555451, val:  60.42%, val_best:  60.42%, tr:  62.00%, tr_best:  62.00%\n",
      "epoch-5   lr=['0.0010000'], tr/val_loss:  1.316895/  1.531080, val:  59.58%, val_best:  60.42%, tr:  62.92%, tr_best:  62.92%\n",
      "epoch-6   lr=['0.0010000'], tr/val_loss:  1.249793/  1.511024, val:  59.58%, val_best:  60.42%, tr:  65.88%, tr_best:  65.88%\n",
      "epoch-7   lr=['0.0010000'], tr/val_loss:  1.203278/  1.482369, val:  61.67%, val_best:  61.67%, tr:  66.39%, tr_best:  66.39%\n",
      "epoch-8   lr=['0.0010000'], tr/val_loss:  1.161125/  1.456793, val:  65.83%, val_best:  65.83%, tr:  69.56%, tr_best:  69.56%\n",
      "epoch-9   lr=['0.0010000'], tr/val_loss:  1.130679/  1.528863, val:  60.00%, val_best:  65.83%, tr:  70.99%, tr_best:  70.99%\n",
      "epoch-10  lr=['0.0010000'], tr/val_loss:  1.108387/  1.563280, val:  55.00%, val_best:  65.83%, tr:  68.95%, tr_best:  70.99%\n",
      "epoch-11  lr=['0.0010000'], tr/val_loss:  1.054601/  1.435886, val:  68.33%, val_best:  68.33%, tr:  71.09%, tr_best:  71.09%\n",
      "epoch-12  lr=['0.0010000'], tr/val_loss:  1.048901/  1.472334, val:  59.17%, val_best:  68.33%, tr:  74.36%, tr_best:  74.36%\n",
      "epoch-13  lr=['0.0010000'], tr/val_loss:  1.017672/  1.569106, val:  62.50%, val_best:  68.33%, tr:  73.65%, tr_best:  74.36%\n",
      "epoch-14  lr=['0.0010000'], tr/val_loss:  0.974325/  1.656879, val:  59.58%, val_best:  68.33%, tr:  74.36%, tr_best:  74.36%\n",
      "epoch-15  lr=['0.0010000'], tr/val_loss:  0.980752/  1.572125, val:  60.83%, val_best:  68.33%, tr:  76.61%, tr_best:  76.61%\n",
      "epoch-16  lr=['0.0010000'], tr/val_loss:  0.983020/  1.537963, val:  64.58%, val_best:  68.33%, tr:  74.87%, tr_best:  76.61%\n",
      "epoch-17  lr=['0.0010000'], tr/val_loss:  0.914581/  1.668934, val:  62.08%, val_best:  68.33%, tr:  78.14%, tr_best:  78.14%\n",
      "epoch-18  lr=['0.0010000'], tr/val_loss:  0.931618/  1.708934, val:  62.50%, val_best:  68.33%, tr:  77.63%, tr_best:  78.14%\n",
      "epoch-19  lr=['0.0010000'], tr/val_loss:  0.924997/  1.702797, val:  65.42%, val_best:  68.33%, tr:  77.83%, tr_best:  78.14%\n",
      "epoch-20  lr=['0.0010000'], tr/val_loss:  0.895528/  1.803627, val:  62.08%, val_best:  68.33%, tr:  79.98%, tr_best:  79.98%\n",
      "epoch-21  lr=['0.0010000'], tr/val_loss:  0.870973/  1.802069, val:  61.25%, val_best:  68.33%, tr:  82.33%, tr_best:  82.33%\n",
      "epoch-22  lr=['0.0010000'], tr/val_loss:  0.875475/  1.817097, val:  62.50%, val_best:  68.33%, tr:  80.08%, tr_best:  82.33%\n",
      "epoch-23  lr=['0.0010000'], tr/val_loss:  0.852028/  1.992823, val:  60.00%, val_best:  68.33%, tr:  82.02%, tr_best:  82.33%\n",
      "epoch-24  lr=['0.0010000'], tr/val_loss:  0.817858/  1.996159, val:  59.58%, val_best:  68.33%, tr:  84.07%, tr_best:  84.07%\n",
      "epoch-25  lr=['0.0010000'], tr/val_loss:  0.836069/  1.881631, val:  67.50%, val_best:  68.33%, tr:  83.76%, tr_best:  84.07%\n",
      "epoch-26  lr=['0.0010000'], tr/val_loss:  0.846120/  1.998041, val:  70.00%, val_best:  70.00%, tr:  84.07%, tr_best:  84.07%\n",
      "epoch-27  lr=['0.0010000'], tr/val_loss:  0.806404/  2.054228, val:  62.92%, val_best:  70.00%, tr:  84.27%, tr_best:  84.27%\n",
      "epoch-28  lr=['0.0010000'], tr/val_loss:  0.791962/  2.007748, val:  68.75%, val_best:  70.00%, tr:  84.47%, tr_best:  84.47%\n",
      "epoch-29  lr=['0.0010000'], tr/val_loss:  0.819494/  2.359427, val:  60.42%, val_best:  70.00%, tr:  87.03%, tr_best:  87.03%\n",
      "epoch-30  lr=['0.0010000'], tr/val_loss:  0.782672/  2.213522, val:  62.08%, val_best:  70.00%, tr:  87.74%, tr_best:  87.74%\n",
      "epoch-31  lr=['0.0010000'], tr/val_loss:  0.785682/  2.318455, val:  67.08%, val_best:  70.00%, tr:  86.62%, tr_best:  87.74%\n",
      "epoch-32  lr=['0.0010000'], tr/val_loss:  0.812352/  2.263149, val:  68.75%, val_best:  70.00%, tr:  86.72%, tr_best:  87.74%\n",
      "epoch-33  lr=['0.0010000'], tr/val_loss:  0.814710/  2.259653, val:  67.92%, val_best:  70.00%, tr:  87.54%, tr_best:  87.74%\n",
      "epoch-34  lr=['0.0010000'], tr/val_loss:  0.742937/  2.467701, val:  60.42%, val_best:  70.00%, tr:  88.46%, tr_best:  88.46%\n",
      "epoch-35  lr=['0.0010000'], tr/val_loss:  0.757479/  2.534710, val:  59.58%, val_best:  70.00%, tr:  86.21%, tr_best:  88.46%\n",
      "epoch-36  lr=['0.0010000'], tr/val_loss:  0.681546/  2.297895, val:  67.50%, val_best:  70.00%, tr:  89.27%, tr_best:  89.27%\n",
      "epoch-37  lr=['0.0010000'], tr/val_loss:  0.701446/  2.512144, val:  63.75%, val_best:  70.00%, tr:  91.73%, tr_best:  91.73%\n",
      "epoch-38  lr=['0.0010000'], tr/val_loss:  0.710612/  2.657074, val:  65.00%, val_best:  70.00%, tr:  92.95%, tr_best:  92.95%\n",
      "epoch-39  lr=['0.0010000'], tr/val_loss:  0.657503/  2.521472, val:  63.75%, val_best:  70.00%, tr:  93.26%, tr_best:  93.26%\n",
      "epoch-40  lr=['0.0010000'], tr/val_loss:  0.682582/  2.741191, val:  62.92%, val_best:  70.00%, tr:  91.32%, tr_best:  93.26%\n",
      "epoch-41  lr=['0.0010000'], tr/val_loss:  0.655606/  2.770979, val:  59.17%, val_best:  70.00%, tr:  93.05%, tr_best:  93.26%\n",
      "epoch-42  lr=['0.0010000'], tr/val_loss:  0.632359/  2.721785, val:  67.08%, val_best:  70.00%, tr:  94.79%, tr_best:  94.79%\n",
      "epoch-43  lr=['0.0010000'], tr/val_loss:  0.633759/  2.736447, val:  65.00%, val_best:  70.00%, tr:  94.18%, tr_best:  94.79%\n",
      "epoch-44  lr=['0.0010000'], tr/val_loss:  0.632607/  2.656749, val:  67.92%, val_best:  70.00%, tr:  94.99%, tr_best:  94.99%\n",
      "epoch-45  lr=['0.0010000'], tr/val_loss:  0.615663/  2.725739, val:  68.75%, val_best:  70.00%, tr:  94.79%, tr_best:  94.99%\n",
      "epoch-46  lr=['0.0010000'], tr/val_loss:  0.594888/  2.853819, val:  66.25%, val_best:  70.00%, tr:  95.71%, tr_best:  95.71%\n",
      "epoch-47  lr=['0.0010000'], tr/val_loss:  0.578222/  3.049881, val:  65.42%, val_best:  70.00%, tr:  97.04%, tr_best:  97.04%\n",
      "epoch-48  lr=['0.0010000'], tr/val_loss:  0.607904/  2.996387, val:  67.92%, val_best:  70.00%, tr:  95.91%, tr_best:  97.04%\n",
      "epoch-49  lr=['0.0010000'], tr/val_loss:  0.567040/  3.018704, val:  69.58%, val_best:  70.00%, tr:  96.83%, tr_best:  97.04%\n",
      "epoch-50  lr=['0.0010000'], tr/val_loss:  0.532360/  3.186153, val:  66.25%, val_best:  70.00%, tr:  97.55%, tr_best:  97.55%\n",
      "epoch-51  lr=['0.0010000'], tr/val_loss:  0.575075/  3.053903, val:  67.08%, val_best:  70.00%, tr:  94.18%, tr_best:  97.55%\n",
      "epoch-52  lr=['0.0010000'], tr/val_loss:  0.514349/  3.110004, val:  67.08%, val_best:  70.00%, tr:  96.83%, tr_best:  97.55%\n",
      "epoch-53  lr=['0.0010000'], tr/val_loss:  0.518154/  3.457839, val:  65.83%, val_best:  70.00%, tr:  98.37%, tr_best:  98.37%\n",
      "epoch-54  lr=['0.0010000'], tr/val_loss:  0.505677/  3.216293, val:  69.58%, val_best:  70.00%, tr:  98.26%, tr_best:  98.37%\n",
      "epoch-55  lr=['0.0010000'], tr/val_loss:  0.527777/  3.308029, val:  67.92%, val_best:  70.00%, tr:  97.14%, tr_best:  98.37%\n",
      "epoch-56  lr=['0.0010000'], tr/val_loss:  0.491510/  3.531652, val:  64.17%, val_best:  70.00%, tr:  98.77%, tr_best:  98.77%\n",
      "epoch-57  lr=['0.0010000'], tr/val_loss:  0.559684/  3.381672, val:  65.00%, val_best:  70.00%, tr:  96.63%, tr_best:  98.77%\n",
      "epoch-58  lr=['0.0010000'], tr/val_loss:  0.539413/  3.329102, val:  67.08%, val_best:  70.00%, tr:  94.48%, tr_best:  98.77%\n",
      "epoch-59  lr=['0.0010000'], tr/val_loss:  0.516434/  3.457018, val:  70.83%, val_best:  70.83%, tr:  97.75%, tr_best:  98.77%\n",
      "epoch-60  lr=['0.0010000'], tr/val_loss:  0.485153/  3.732556, val:  64.17%, val_best:  70.83%, tr:  97.85%, tr_best:  98.77%\n",
      "epoch-61  lr=['0.0010000'], tr/val_loss:  0.535130/  3.417022, val:  71.25%, val_best:  71.25%, tr:  96.83%, tr_best:  98.77%\n",
      "epoch-62  lr=['0.0010000'], tr/val_loss:  0.446230/  3.361158, val:  69.17%, val_best:  71.25%, tr:  98.47%, tr_best:  98.77%\n",
      "epoch-63  lr=['0.0010000'], tr/val_loss:  0.424834/  3.410936, val:  73.75%, val_best:  73.75%, tr:  98.88%, tr_best:  98.88%\n",
      "epoch-64  lr=['0.0010000'], tr/val_loss:  0.435740/  3.347567, val:  71.67%, val_best:  73.75%, tr:  97.65%, tr_best:  98.88%\n",
      "epoch-65  lr=['0.0010000'], tr/val_loss:  0.381304/  3.313588, val:  71.25%, val_best:  73.75%, tr:  99.18%, tr_best:  99.18%\n",
      "epoch-66  lr=['0.0010000'], tr/val_loss:  0.393611/  3.409695, val:  72.08%, val_best:  73.75%, tr:  99.49%, tr_best:  99.49%\n",
      "epoch-67  lr=['0.0010000'], tr/val_loss:  0.414356/  3.359644, val:  73.75%, val_best:  73.75%, tr:  98.57%, tr_best:  99.49%\n",
      "epoch-68  lr=['0.0010000'], tr/val_loss:  0.412061/  3.412950, val:  71.67%, val_best:  73.75%, tr:  99.39%, tr_best:  99.49%\n",
      "epoch-69  lr=['0.0010000'], tr/val_loss:  0.420847/  3.498824, val:  72.08%, val_best:  73.75%, tr:  98.77%, tr_best:  99.49%\n",
      "epoch-70  lr=['0.0010000'], tr/val_loss:  0.378566/  3.353256, val:  71.25%, val_best:  73.75%, tr:  99.39%, tr_best:  99.49%\n",
      "epoch-71  lr=['0.0010000'], tr/val_loss:  0.437227/  3.585583, val:  72.50%, val_best:  73.75%, tr:  98.06%, tr_best:  99.49%\n",
      "epoch-72  lr=['0.0010000'], tr/val_loss:  0.419239/  3.353722, val:  72.50%, val_best:  73.75%, tr:  98.88%, tr_best:  99.49%\n",
      "epoch-73  lr=['0.0010000'], tr/val_loss:  0.389243/  3.548229, val:  67.92%, val_best:  73.75%, tr:  98.37%, tr_best:  99.49%\n",
      "epoch-74  lr=['0.0010000'], tr/val_loss:  0.355405/  3.541240, val:  72.92%, val_best:  73.75%, tr:  99.08%, tr_best:  99.49%\n",
      "epoch-75  lr=['0.0010000'], tr/val_loss:  0.352597/  3.526462, val:  70.42%, val_best:  73.75%, tr:  98.47%, tr_best:  99.49%\n",
      "epoch-76  lr=['0.0010000'], tr/val_loss:  0.337224/  3.475421, val:  71.67%, val_best:  73.75%, tr:  99.39%, tr_best:  99.49%\n",
      "epoch-77  lr=['0.0010000'], tr/val_loss:  0.360251/  3.710256, val:  69.58%, val_best:  73.75%, tr:  98.77%, tr_best:  99.49%\n",
      "epoch-78  lr=['0.0010000'], tr/val_loss:  0.380566/  3.617064, val:  72.50%, val_best:  73.75%, tr:  98.88%, tr_best:  99.49%\n",
      "epoch-79  lr=['0.0010000'], tr/val_loss:  0.325451/  3.572766, val:  72.08%, val_best:  73.75%, tr:  99.49%, tr_best:  99.49%\n",
      "epoch-80  lr=['0.0010000'], tr/val_loss:  0.308370/  3.665858, val:  71.67%, val_best:  73.75%, tr:  99.90%, tr_best:  99.90%\n",
      "epoch-81  lr=['0.0010000'], tr/val_loss:  0.266245/  3.580417, val:  70.42%, val_best:  73.75%, tr:  99.80%, tr_best:  99.90%\n",
      "epoch-82  lr=['0.0010000'], tr/val_loss:  0.278189/  3.626280, val:  71.25%, val_best:  73.75%, tr:  99.49%, tr_best:  99.90%\n",
      "epoch-83  lr=['0.0010000'], tr/val_loss:  0.352835/  3.735754, val:  70.83%, val_best:  73.75%, tr:  99.59%, tr_best:  99.90%\n",
      "epoch-84  lr=['0.0010000'], tr/val_loss:  0.314501/  3.713542, val:  70.42%, val_best:  73.75%, tr:  99.28%, tr_best:  99.90%\n",
      "epoch-85  lr=['0.0010000'], tr/val_loss:  0.353990/  3.794341, val:  70.42%, val_best:  73.75%, tr:  98.98%, tr_best:  99.90%\n",
      "epoch-86  lr=['0.0010000'], tr/val_loss:  0.290747/  3.757254, val:  70.42%, val_best:  73.75%, tr:  99.80%, tr_best:  99.90%\n",
      "epoch-87  lr=['0.0010000'], tr/val_loss:  0.318437/  3.547390, val:  72.50%, val_best:  73.75%, tr:  98.67%, tr_best:  99.90%\n",
      "epoch-88  lr=['0.0010000'], tr/val_loss:  0.290242/  3.610040, val:  73.75%, val_best:  73.75%, tr:  99.80%, tr_best:  99.90%\n",
      "epoch-89  lr=['0.0010000'], tr/val_loss:  0.257004/  3.746444, val:  73.75%, val_best:  73.75%, tr:  99.69%, tr_best:  99.90%\n",
      "epoch-90  lr=['0.0010000'], tr/val_loss:  0.253982/  3.726433, val:  70.83%, val_best:  73.75%, tr:  99.80%, tr_best:  99.90%\n",
      "epoch-91  lr=['0.0010000'], tr/val_loss:  0.232963/  3.734505, val:  72.08%, val_best:  73.75%, tr:  99.69%, tr_best:  99.90%\n",
      "epoch-92  lr=['0.0010000'], tr/val_loss:  0.194844/  3.748441, val:  72.50%, val_best:  73.75%, tr:  99.90%, tr_best:  99.90%\n",
      "epoch-93  lr=['0.0010000'], tr/val_loss:  0.219133/  3.755011, val:  72.92%, val_best:  73.75%, tr:  99.90%, tr_best:  99.90%\n",
      "epoch-94  lr=['0.0010000'], tr/val_loss:  0.205211/  3.758615, val:  72.50%, val_best:  73.75%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-95  lr=['0.0010000'], tr/val_loss:  0.236082/  3.739775, val:  73.33%, val_best:  73.75%, tr:  99.90%, tr_best: 100.00%\n",
      "epoch-96  lr=['0.0010000'], tr/val_loss:  0.224297/  3.839006, val:  73.75%, val_best:  73.75%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-97  lr=['0.0010000'], tr/val_loss:  0.232116/  3.776063, val:  75.00%, val_best:  75.00%, tr:  99.90%, tr_best: 100.00%\n",
      "epoch-98  lr=['0.0010000'], tr/val_loss:  0.197325/  3.764912, val:  75.42%, val_best:  75.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-99  lr=['0.0010000'], tr/val_loss:  0.181913/  3.835845, val:  74.17%, val_best:  75.42%, tr: 100.00%, tr_best: 100.00%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b2075ff385c74f70bb5295a8cb34ad90",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.006 MB of 0.006 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>iter_acc</td><td>▂▅▂▅▄▅▇▁▄▇█▆█▇▇▇█▆█▇███████▇████████████</td></tr><tr><td>summary_val_acc</td><td>▁▅▆▆▆▆▆▆▇▆▆▇▆▇▆▆▆▇▇▇▇▇▇▇▇▇▇█▇█▇▇█▇▇█████</td></tr><tr><td>tr_acc</td><td>▁▄▅▅▆▆▆▆▆▇▇▇▇▇▇▇▇███████████████████████</td></tr><tr><td>tr_epoch_loss</td><td>█▆▅▄▄▄▄▃▃▃▃▃▃▃▃▃▃▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁</td></tr><tr><td>val_acc_best</td><td>▁▅▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇██████████████</td></tr><tr><td>val_acc_now</td><td>▁▅▆▆▆▆▆▆▇▆▆▇▆▇▆▆▆▇▇▇▇▇▇▇▇▇▇█▇█▇▇█▇▇█████</td></tr><tr><td>val_loss</td><td>▃▂▁▁▁▁▂▂▂▂▃▃▄▃▄▄▄▅▅▆▆▆▆▇▇▇▇▇▇▇▇█▇██▇████</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>99</td></tr><tr><td>iter_acc</td><td>1.0</td></tr><tr><td>tr_acc</td><td>1.0</td></tr><tr><td>tr_epoch_loss</td><td>0.18191</td></tr><tr><td>val_acc_best</td><td>0.75417</td></tr><tr><td>val_acc_now</td><td>0.74167</td></tr><tr><td>val_loss</td><td>3.83585</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">quiet-sweep-35</strong> at: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/pzwe2ezr' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/pzwe2ezr</a><br/> View project at: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>/data2/bh_wandb/wandb/run-20250429_234712-pzwe2ezr/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require(\"core\")`! See https://wandb.me/wandb-core for more information."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 1idy6gss with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBATCH: 16\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBN_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBPTT_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tDFA_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tIMAGE_SIZE: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tOTTT_input_trace_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tTIME: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tUDA_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \talpha_uda: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbias: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcfg: ['M', 'M', 200, 200]\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tchaching_on: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tconvTrue_fcFalse: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdata_path: /data2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tddp_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdenoise_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdvs_clipping: 5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdvs_duration: 100000\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepoch_num: 100\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \texclude_class: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \textra_train_dataset: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlast_lif: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_sg_width: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_decay: 0.5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_init: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_reset: 10000\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_threshold: 0.25\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmerge_polarities: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmy_seed: 42\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnet_print: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_workers: 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer_what: SGD\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tpin_memory: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tpre_trained: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tpre_trained_path: net_save/save_now_net_weights_{unique_name}.pth\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \trate_coding: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tscheduler_name: no\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsingle_step: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsurrogate: hard_sigmoid\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_conv_kernel_size: 3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_conv_padding: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_conv_stride: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_trace_const1: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_trace_const2: 0.5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \ttdBN_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \ttrace_on: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \twhich_data: DVS_GESTURE_TONIC\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.19.10 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.17.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/data2/bh_wandb/wandb/run-20250429_235335-1idy6gss</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/1idy6gss' target=\"_blank\">wild-sweep-39</a></strong> to <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/6pj3lh8j' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/6pj3lh8j</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/6pj3lh8j' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/6pj3lh8j</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/1idy6gss' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/1idy6gss</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'single_step' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'my_seed' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'TIME' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BATCH' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'IMAGE_SIZE' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'which_data' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'data_path' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'rate_coding' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_init' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_decay' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_threshold' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_reset' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_sg_width' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_conv_kernel_size' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_conv_stride' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_conv_padding' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_trace_const1' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_trace_const2' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'pre_trained' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'convTrue_fcFalse' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'cfg' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'net_print' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'pre_trained_path' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'learning_rate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'epoch_num' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'tdBN_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BN_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'surrogate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BPTT_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'optimizer_what' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'scheduler_name' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'ddp_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'dvs_clipping' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'dvs_duration' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'DFA_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'trace_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'OTTT_input_trace_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'exclude_class' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'merge_polarities' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'denoise_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'extra_train_dataset' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'num_workers' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'chaching_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'pin_memory' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'UDA_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'alpha_uda' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'bias' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'last_lif' was locked by 'sweep' (ignored update).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "param {'devices': '0', 'single_step': True, 'unique_name': 'main', 'my_seed': 42, 'TIME': 10, 'BATCH': 16, 'IMAGE_SIZE': 128, 'which_data': 'DVS_GESTURE_TONIC', 'data_path': '/data2', 'rate_coding': False, 'lif_layer_v_init': 0, 'lif_layer_v_decay': 0.5, 'lif_layer_v_threshold': 0.25, 'lif_layer_v_reset': 10000, 'lif_layer_sg_width': 1, 'synapse_conv_kernel_size': 3, 'synapse_conv_stride': 1, 'synapse_conv_padding': 1, 'synapse_trace_const1': 1, 'synapse_trace_const2': 0.5, 'pre_trained': False, 'convTrue_fcFalse': False, 'cfg': ['M', 'M', 200, 200], 'net_print': True, 'pre_trained_path': 'net_save/save_now_net_weights_{unique_name}.pth', 'learning_rate': 0.1, 'epoch_num': 100, 'tdBN_on': False, 'BN_on': False, 'surrogate': 'hard_sigmoid', 'BPTT_on': False, 'optimizer_what': 'SGD', 'scheduler_name': 'no', 'ddp_on': False, 'dvs_clipping': 5, 'dvs_duration': 100000, 'DFA_on': False, 'trace_on': True, 'OTTT_input_trace_on': False, 'exclude_class': True, 'merge_polarities': False, 'denoise_on': False, 'extra_train_dataset': 0, 'num_workers': 2, 'chaching_on': True, 'pin_memory': True, 'UDA_on': False, 'alpha_uda': 1, 'bias': True, 'last_lif': False, 'current epoch': 0} \n",
      "\n",
      "dataset_hash = ffa516e60c3efd5e0208f72b4c36cb84\n",
      "cache path exists\n",
      "\n",
      "device ==> cuda\n",
      "\n",
      "DataParallel(\n",
      "  (module): REBORN_MY_SNN_FC(\n",
      "    (layers): REBORN_MY_Sequential(\n",
      "      (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (2): DimChanger_for_FC()\n",
      "      (3): SYNAPSE_FC(in_features=2048, out_features=200, TIME=10, bias=True, sstep=True)\n",
      "      (4): LIF_layer(v_init=0, v_decay=0.5, v_threshold=0.25, v_reset=10000, sg_width=1, surrogate=hard_sigmoid, BPTT_on=False, trace_const1=1, trace_const2=0.5, TIME=10, sstep=True, trace_on=True)\n",
      "      (5): SYNAPSE_FC(in_features=200, out_features=200, TIME=10, bias=True, sstep=True)\n",
      "      (6): LIF_layer(v_init=0, v_decay=0.5, v_threshold=0.25, v_reset=10000, sg_width=1, surrogate=hard_sigmoid, BPTT_on=False, trace_const1=1, trace_const2=0.5, TIME=10, sstep=True, trace_on=True)\n",
      "      (7): SYNAPSE_FC(in_features=200, out_features=10, TIME=10, bias=True, sstep=True)\n",
      "    )\n",
      "  )\n",
      ")\n",
      "\n",
      "========================================================\n",
      "Trainable parameters: 452,010\n",
      "========================================================\n",
      "\n",
      "epoch-0   lr=['0.1000000'], tr/val_loss:  2.330944/  3.348920, val:  31.25%, val_best:  31.25%, tr:  32.18%, tr_best:  32.18%\n",
      "epoch-1   lr=['0.1000000'], tr/val_loss:  2.283153/  2.116875, val:  37.50%, val_best:  37.50%, tr:  34.22%, tr_best:  34.22%\n",
      "epoch-2   lr=['0.1000000'], tr/val_loss:  1.980871/  2.265758, val:  41.25%, val_best:  41.25%, tr:  37.49%, tr_best:  37.49%\n",
      "epoch-3   lr=['0.1000000'], tr/val_loss:  1.816333/  2.139458, val:  33.33%, val_best:  41.25%, tr:  46.58%, tr_best:  46.58%\n",
      "epoch-4   lr=['0.1000000'], tr/val_loss:  1.889823/  2.457325, val:  46.25%, val_best:  46.25%, tr:  46.37%, tr_best:  46.58%\n",
      "epoch-5   lr=['0.1000000'], tr/val_loss:  1.716702/  2.520107, val:  41.25%, val_best:  46.25%, tr:  50.97%, tr_best:  50.97%\n",
      "epoch-6   lr=['0.1000000'], tr/val_loss:  1.934250/  1.761630, val:  47.08%, val_best:  47.08%, tr:  49.95%, tr_best:  50.97%\n",
      "epoch-7   lr=['0.1000000'], tr/val_loss:  1.785429/  2.667436, val:  42.92%, val_best:  47.08%, tr:  49.44%, tr_best:  50.97%\n",
      "epoch-8   lr=['0.1000000'], tr/val_loss:  1.977967/  1.846134, val:  56.25%, val_best:  56.25%, tr:  52.20%, tr_best:  52.20%\n",
      "epoch-9   lr=['0.1000000'], tr/val_loss:  1.805968/  1.746740, val:  50.00%, val_best:  56.25%, tr:  55.16%, tr_best:  55.16%\n",
      "epoch-10  lr=['0.1000000'], tr/val_loss:  1.766163/  2.507625, val:  51.67%, val_best:  56.25%, tr:  57.00%, tr_best:  57.00%\n",
      "epoch-11  lr=['0.1000000'], tr/val_loss:  1.898247/  2.563131, val:  46.25%, val_best:  56.25%, tr:  54.14%, tr_best:  57.00%\n",
      "epoch-12  lr=['0.1000000'], tr/val_loss:  2.057279/  2.391620, val:  51.67%, val_best:  56.25%, tr:  54.14%, tr_best:  57.00%\n",
      "epoch-13  lr=['0.1000000'], tr/val_loss:  2.318231/  3.585181, val:  29.58%, val_best:  56.25%, tr:  48.11%, tr_best:  57.00%\n",
      "epoch-14  lr=['0.1000000'], tr/val_loss:  2.400704/  4.852998, val:  49.58%, val_best:  56.25%, tr:  49.54%, tr_best:  57.00%\n",
      "epoch-15  lr=['0.1000000'], tr/val_loss:  3.791078/  4.965900, val:  33.33%, val_best:  56.25%, tr:  45.86%, tr_best:  57.00%\n",
      "epoch-16  lr=['0.1000000'], tr/val_loss:  2.952679/  2.709230, val:  40.83%, val_best:  56.25%, tr:  49.54%, tr_best:  57.00%\n",
      "epoch-17  lr=['0.1000000'], tr/val_loss:  2.720718/  3.523159, val:  33.75%, val_best:  56.25%, tr:  50.46%, tr_best:  57.00%\n",
      "epoch-18  lr=['0.1000000'], tr/val_loss:  2.679808/  2.970746, val:  51.25%, val_best:  56.25%, tr:  50.87%, tr_best:  57.00%\n",
      "epoch-19  lr=['0.1000000'], tr/val_loss:  2.747980/  3.375617, val:  45.83%, val_best:  56.25%, tr:  50.56%, tr_best:  57.00%\n",
      "epoch-20  lr=['0.1000000'], tr/val_loss:  2.557498/  2.716282, val:  46.67%, val_best:  56.25%, tr:  51.58%, tr_best:  57.00%\n",
      "epoch-21  lr=['0.1000000'], tr/val_loss:  2.278893/  2.528872, val:  47.50%, val_best:  56.25%, tr:  54.03%, tr_best:  57.00%\n",
      "epoch-22  lr=['0.1000000'], tr/val_loss:  2.180333/  2.793564, val:  45.00%, val_best:  56.25%, tr:  52.60%, tr_best:  57.00%\n",
      "epoch-23  lr=['0.1000000'], tr/val_loss:  2.193293/  2.944534, val:  47.50%, val_best:  56.25%, tr:  54.24%, tr_best:  57.00%\n",
      "epoch-24  lr=['0.1000000'], tr/val_loss:  2.083377/  2.756774, val:  45.00%, val_best:  56.25%, tr:  53.93%, tr_best:  57.00%\n",
      "epoch-25  lr=['0.1000000'], tr/val_loss:  3.201989/  4.040523, val:  48.75%, val_best:  56.25%, tr:  47.50%, tr_best:  57.00%\n",
      "epoch-26  lr=['0.1000000'], tr/val_loss:  2.582817/  3.442894, val:  48.33%, val_best:  56.25%, tr:  53.63%, tr_best:  57.00%\n",
      "epoch-27  lr=['0.1000000'], tr/val_loss:  2.427082/  4.126957, val:  48.75%, val_best:  56.25%, tr:  48.11%, tr_best:  57.00%\n",
      "epoch-28  lr=['0.1000000'], tr/val_loss:  2.543234/  4.017995, val:  43.33%, val_best:  56.25%, tr:  53.42%, tr_best:  57.00%\n",
      "epoch-29  lr=['0.1000000'], tr/val_loss:  2.353022/  3.039641, val:  44.58%, val_best:  56.25%, tr:  51.28%, tr_best:  57.00%\n",
      "epoch-30  lr=['0.1000000'], tr/val_loss:  2.421054/  2.675525, val:  46.25%, val_best:  56.25%, tr:  55.46%, tr_best:  57.00%\n",
      "epoch-31  lr=['0.1000000'], tr/val_loss:  2.026730/  3.284784, val:  50.00%, val_best:  56.25%, tr:  56.49%, tr_best:  57.00%\n",
      "epoch-32  lr=['0.1000000'], tr/val_loss:  2.651366/  2.573839, val:  47.08%, val_best:  56.25%, tr:  53.83%, tr_best:  57.00%\n",
      "epoch-33  lr=['0.1000000'], tr/val_loss:  2.199987/  3.219067, val:  51.25%, val_best:  56.25%, tr:  54.03%, tr_best:  57.00%\n",
      "epoch-34  lr=['0.1000000'], tr/val_loss:  2.442120/  3.279989, val:  50.83%, val_best:  56.25%, tr:  55.06%, tr_best:  57.00%\n",
      "epoch-35  lr=['0.1000000'], tr/val_loss:  2.301184/  2.916339, val:  50.00%, val_best:  56.25%, tr:  57.10%, tr_best:  57.10%\n",
      "epoch-36  lr=['0.1000000'], tr/val_loss:  2.123141/  3.119452, val:  54.17%, val_best:  56.25%, tr:  55.36%, tr_best:  57.10%\n",
      "epoch-37  lr=['0.1000000'], tr/val_loss:  2.954588/  4.216710, val:  47.50%, val_best:  56.25%, tr:  54.95%, tr_best:  57.10%\n",
      "epoch-38  lr=['0.1000000'], tr/val_loss:  2.206975/  3.035623, val:  48.75%, val_best:  56.25%, tr:  57.41%, tr_best:  57.41%\n",
      "epoch-39  lr=['0.1000000'], tr/val_loss:  2.123014/  5.049295, val:  40.42%, val_best:  56.25%, tr:  58.02%, tr_best:  58.02%\n",
      "epoch-40  lr=['0.1000000'], tr/val_loss:  2.873159/  2.532445, val:  47.50%, val_best:  56.25%, tr:  53.42%, tr_best:  58.02%\n",
      "epoch-41  lr=['0.1000000'], tr/val_loss:  2.088212/  3.194602, val:  47.92%, val_best:  56.25%, tr:  57.10%, tr_best:  58.02%\n",
      "epoch-42  lr=['0.1000000'], tr/val_loss:  2.040871/  3.155397, val:  41.25%, val_best:  56.25%, tr:  56.59%, tr_best:  58.02%\n",
      "epoch-43  lr=['0.1000000'], tr/val_loss:  2.102801/  3.690599, val:  45.83%, val_best:  56.25%, tr:  55.77%, tr_best:  58.02%\n",
      "epoch-44  lr=['0.1000000'], tr/val_loss:  2.170051/  5.141708, val:  44.58%, val_best:  56.25%, tr:  57.00%, tr_best:  58.02%\n",
      "epoch-45  lr=['0.1000000'], tr/val_loss:  3.092110/  4.027339, val:  43.33%, val_best:  56.25%, tr:  54.44%, tr_best:  58.02%\n",
      "epoch-46  lr=['0.1000000'], tr/val_loss:  2.975272/  4.152460, val:  42.92%, val_best:  56.25%, tr:  57.61%, tr_best:  58.02%\n",
      "epoch-47  lr=['0.1000000'], tr/val_loss:  2.553795/  4.311174, val:  46.25%, val_best:  56.25%, tr:  53.42%, tr_best:  58.02%\n",
      "epoch-48  lr=['0.1000000'], tr/val_loss:  3.101974/  4.383272, val:  44.17%, val_best:  56.25%, tr:  53.93%, tr_best:  58.02%\n",
      "epoch-49  lr=['0.1000000'], tr/val_loss:  2.767039/  3.985092, val:  50.00%, val_best:  56.25%, tr:  53.83%, tr_best:  58.02%\n",
      "epoch-50  lr=['0.1000000'], tr/val_loss:  3.079942/  4.895168, val:  51.67%, val_best:  56.25%, tr:  49.95%, tr_best:  58.02%\n",
      "epoch-51  lr=['0.1000000'], tr/val_loss:  3.157354/  2.975984, val:  51.67%, val_best:  56.25%, tr:  54.75%, tr_best:  58.02%\n",
      "epoch-52  lr=['0.1000000'], tr/val_loss:  2.662798/  3.128227, val:  53.33%, val_best:  56.25%, tr:  52.60%, tr_best:  58.02%\n",
      "epoch-53  lr=['0.1000000'], tr/val_loss:  2.604339/  4.094620, val:  43.33%, val_best:  56.25%, tr:  54.24%, tr_best:  58.02%\n",
      "epoch-54  lr=['0.1000000'], tr/val_loss:  2.482615/  3.326836, val:  40.00%, val_best:  56.25%, tr:  52.30%, tr_best:  58.02%\n",
      "epoch-55  lr=['0.1000000'], tr/val_loss:  2.376581/  4.630940, val:  42.08%, val_best:  56.25%, tr:  52.20%, tr_best:  58.02%\n",
      "epoch-56  lr=['0.1000000'], tr/val_loss:  2.970350/  6.429760, val:  51.25%, val_best:  56.25%, tr:  54.34%, tr_best:  58.02%\n",
      "epoch-57  lr=['0.1000000'], tr/val_loss:  4.069128/  4.221992, val:  32.50%, val_best:  56.25%, tr:  41.57%, tr_best:  58.02%\n",
      "epoch-58  lr=['0.1000000'], tr/val_loss:  2.996472/  5.608920, val:  42.50%, val_best:  56.25%, tr:  45.56%, tr_best:  58.02%\n",
      "epoch-59  lr=['0.1000000'], tr/val_loss:  2.635698/  3.897979, val:  25.42%, val_best:  56.25%, tr:  48.93%, tr_best:  58.02%\n",
      "epoch-60  lr=['0.1000000'], tr/val_loss:  2.525699/  4.773289, val:  38.33%, val_best:  56.25%, tr:  48.31%, tr_best:  58.02%\n",
      "epoch-61  lr=['0.1000000'], tr/val_loss:  2.952712/  4.077274, val:  39.17%, val_best:  56.25%, tr:  48.31%, tr_best:  58.02%\n",
      "epoch-62  lr=['0.1000000'], tr/val_loss:  2.645939/  4.753023, val:  44.58%, val_best:  56.25%, tr:  50.26%, tr_best:  58.02%\n",
      "epoch-63  lr=['0.1000000'], tr/val_loss:  3.079359/  4.644553, val:  37.92%, val_best:  56.25%, tr:  48.83%, tr_best:  58.02%\n",
      "epoch-64  lr=['0.1000000'], tr/val_loss:  2.755593/  3.903056, val:  37.50%, val_best:  56.25%, tr:  54.85%, tr_best:  58.02%\n",
      "epoch-65  lr=['0.1000000'], tr/val_loss:  2.800517/  3.587208, val:  45.83%, val_best:  56.25%, tr:  48.31%, tr_best:  58.02%\n",
      "epoch-66  lr=['0.1000000'], tr/val_loss:  2.771098/  3.941418, val:  41.25%, val_best:  56.25%, tr:  55.36%, tr_best:  58.02%\n",
      "epoch-67  lr=['0.1000000'], tr/val_loss:  3.128012/  3.633389, val:  48.33%, val_best:  56.25%, tr:  49.44%, tr_best:  58.02%\n",
      "epoch-68  lr=['0.1000000'], tr/val_loss:  2.656534/  3.733184, val:  46.25%, val_best:  56.25%, tr:  52.30%, tr_best:  58.02%\n",
      "epoch-69  lr=['0.1000000'], tr/val_loss:  2.753412/  3.954614, val:  47.08%, val_best:  56.25%, tr:  51.79%, tr_best:  58.02%\n",
      "epoch-70  lr=['0.1000000'], tr/val_loss:  2.958136/  5.414806, val:  39.17%, val_best:  56.25%, tr:  54.34%, tr_best:  58.02%\n",
      "epoch-71  lr=['0.1000000'], tr/val_loss:  3.212823/  3.438962, val:  44.17%, val_best:  56.25%, tr:  53.52%, tr_best:  58.02%\n",
      "epoch-72  lr=['0.1000000'], tr/val_loss:  2.602699/  3.333724, val:  46.67%, val_best:  56.25%, tr:  47.91%, tr_best:  58.02%\n",
      "epoch-73  lr=['0.1000000'], tr/val_loss:  2.682779/  4.554550, val:  45.00%, val_best:  56.25%, tr:  53.01%, tr_best:  58.02%\n",
      "epoch-74  lr=['0.1000000'], tr/val_loss:  3.028518/  7.526022, val:  37.92%, val_best:  56.25%, tr:  50.77%, tr_best:  58.02%\n",
      "epoch-75  lr=['0.1000000'], tr/val_loss:  3.035548/  5.542638, val:  44.17%, val_best:  56.25%, tr:  46.37%, tr_best:  58.02%\n",
      "epoch-76  lr=['0.1000000'], tr/val_loss:  2.943226/  3.898001, val:  42.08%, val_best:  56.25%, tr:  48.52%, tr_best:  58.02%\n",
      "epoch-77  lr=['0.1000000'], tr/val_loss:  4.393739/  6.143907, val:  42.08%, val_best:  56.25%, tr:  48.62%, tr_best:  58.02%\n",
      "epoch-78  lr=['0.1000000'], tr/val_loss:  6.257225/  6.888305, val:  39.58%, val_best:  56.25%, tr:  45.45%, tr_best:  58.02%\n",
      "epoch-79  lr=['0.1000000'], tr/val_loss:  3.796919/  5.804264, val:  43.33%, val_best:  56.25%, tr:  49.44%, tr_best:  58.02%\n",
      "epoch-80  lr=['0.1000000'], tr/val_loss:  3.233150/  5.174165, val:  49.17%, val_best:  56.25%, tr:  47.91%, tr_best:  58.02%\n",
      "epoch-81  lr=['0.1000000'], tr/val_loss:  3.083164/  5.224803, val:  26.67%, val_best:  56.25%, tr:  51.79%, tr_best:  58.02%\n",
      "epoch-82  lr=['0.1000000'], tr/val_loss:  3.311681/  4.785933, val:  45.83%, val_best:  56.25%, tr:  51.07%, tr_best:  58.02%\n",
      "epoch-83  lr=['0.1000000'], tr/val_loss:  3.303798/  5.827986, val:  36.25%, val_best:  56.25%, tr:  49.74%, tr_best:  58.02%\n",
      "epoch-84  lr=['0.1000000'], tr/val_loss:  4.393063/  5.692285, val:  52.92%, val_best:  56.25%, tr:  45.97%, tr_best:  58.02%\n",
      "epoch-85  lr=['0.1000000'], tr/val_loss:  3.263655/  4.985400, val:  43.75%, val_best:  56.25%, tr:  51.89%, tr_best:  58.02%\n",
      "epoch-86  lr=['0.1000000'], tr/val_loss:  3.731841/  3.880596, val:  47.50%, val_best:  56.25%, tr:  54.03%, tr_best:  58.02%\n",
      "epoch-87  lr=['0.1000000'], tr/val_loss:  3.747724/  6.786001, val:  47.50%, val_best:  56.25%, tr:  52.09%, tr_best:  58.02%\n",
      "epoch-88  lr=['0.1000000'], tr/val_loss:  4.079937/  6.877810, val:  34.17%, val_best:  56.25%, tr:  49.13%, tr_best:  58.02%\n",
      "epoch-89  lr=['0.1000000'], tr/val_loss:  4.136966/  6.533350, val:  40.00%, val_best:  56.25%, tr:  48.42%, tr_best:  58.02%\n",
      "epoch-90  lr=['0.1000000'], tr/val_loss:  4.368704/  3.553132, val:  35.00%, val_best:  56.25%, tr:  43.51%, tr_best:  58.02%\n",
      "epoch-91  lr=['0.1000000'], tr/val_loss:  3.116665/  4.982867, val:  41.67%, val_best:  56.25%, tr:  49.13%, tr_best:  58.02%\n",
      "epoch-92  lr=['0.1000000'], tr/val_loss:  4.422685/  5.507538, val:  41.25%, val_best:  56.25%, tr:  46.68%, tr_best:  58.02%\n",
      "epoch-93  lr=['0.1000000'], tr/val_loss:  4.667957/  9.938378, val:  42.92%, val_best:  56.25%, tr:  50.56%, tr_best:  58.02%\n",
      "epoch-94  lr=['0.1000000'], tr/val_loss:  8.168941/ 12.674913, val:  34.17%, val_best:  56.25%, tr:  41.27%, tr_best:  58.02%\n",
      "epoch-95  lr=['0.1000000'], tr/val_loss:  7.274389/  4.757894, val:  38.75%, val_best:  56.25%, tr:  35.55%, tr_best:  58.02%\n",
      "epoch-96  lr=['0.1000000'], tr/val_loss:  5.854661/  7.975565, val:  27.92%, val_best:  56.25%, tr:  41.57%, tr_best:  58.02%\n",
      "epoch-97  lr=['0.1000000'], tr/val_loss:  4.713124/  5.855269, val:  39.58%, val_best:  56.25%, tr:  39.73%, tr_best:  58.02%\n",
      "epoch-98  lr=['0.1000000'], tr/val_loss:  4.950351/  7.079043, val:  38.33%, val_best:  56.25%, tr:  43.92%, tr_best:  58.02%\n",
      "epoch-99  lr=['0.1000000'], tr/val_loss:  5.225423/  5.178465, val:  38.33%, val_best:  56.25%, tr:  44.23%, tr_best:  58.02%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "03f5767c0d694e3a950edc7183a1cb83",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.006 MB of 0.006 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>iter_acc</td><td>▃▅▄▅▅▄▄▅▄▆▄▆▇▅▆█▅▄▄▅▅█▅▅▅▅▆▅▆▅▄▄▆▅▆▄▄▅▁▄</td></tr><tr><td>summary_val_acc</td><td>▂▅▆▅▇█▇▃▆▇▆▇▆▆▇▇▅▅▆▆▇█▅▃▁▄▆▇▄▆▆▅▅▆█▇▅▅▄▅</td></tr><tr><td>tr_acc</td><td>▁▂▅▆▇▇▆▆▆▇▇▇▆▇█▇███▇▇▇▆▄▆▅▅▆▇▅▅▅▆▆▅▆▅▅▂▃</td></tr><tr><td>tr_epoch_loss</td><td>▂▁▁▁▁▁▂▂▂▂▁▂▂▂▂▂▁▁▁▂▂▂▂▄▂▂▂▃▂▂▃▄▄▃▄▄▄▄█▅</td></tr><tr><td>val_acc_best</td><td>▁▄▅▅████████████████████████████████████</td></tr><tr><td>val_acc_now</td><td>▂▅▆▅▇█▇▃▆▇▆▇▆▆▇▇▅▅▆▆▇█▅▃▁▄▆▇▄▆▆▅▅▆█▇▅▅▄▅</td></tr><tr><td>val_loss</td><td>▃▂▂▂▁▂▅▃▃▂▂▃▃▂▃▄▆▃▆▅▄▃▃▄▄▄▄▄▆▃▆▇▇▅▆██▆▅▇</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>99</td></tr><tr><td>iter_acc</td><td>0.33333</td></tr><tr><td>tr_acc</td><td>0.44229</td></tr><tr><td>tr_epoch_loss</td><td>5.22542</td></tr><tr><td>val_acc_best</td><td>0.5625</td></tr><tr><td>val_acc_now</td><td>0.38333</td></tr><tr><td>val_loss</td><td>5.17846</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">wild-sweep-39</strong> at: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/1idy6gss' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/1idy6gss</a><br/> View project at: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>/data2/bh_wandb/wandb/run-20250429_235335-1idy6gss/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require(\"core\")`! See https://wandb.me/wandb-core for more information."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 2evrh0ns with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBATCH: 16\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBN_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBPTT_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tDFA_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tIMAGE_SIZE: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tOTTT_input_trace_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tTIME: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tUDA_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \talpha_uda: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbias: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcfg: ['M', 'M', 200, 200]\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tchaching_on: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tconvTrue_fcFalse: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdata_path: /data2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tddp_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdenoise_on: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdvs_clipping: 5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdvs_duration: 100000\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepoch_num: 100\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \texclude_class: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \textra_train_dataset: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlast_lif: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.001\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_sg_width: 3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_decay: 0.5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_init: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_reset: 10000\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_threshold: 0.25\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmerge_polarities: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmy_seed: 42\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnet_print: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_workers: 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer_what: SGD\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tpin_memory: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tpre_trained: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tpre_trained_path: net_save/save_now_net_weights_{unique_name}.pth\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \trate_coding: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tscheduler_name: no\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsingle_step: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsurrogate: hard_sigmoid\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_conv_kernel_size: 3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_conv_padding: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_conv_stride: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_trace_const1: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_trace_const2: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \ttdBN_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \ttrace_on: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \twhich_data: DVS_GESTURE_TONIC\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4efc5dc9e2d6461abaeeb9e8ac1181c6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.011113227769318555, max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.19.10 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.17.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/data2/bh_wandb/wandb/run-20250430_000001-2evrh0ns</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/2evrh0ns' target=\"_blank\">serene-sweep-43</a></strong> to <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/6pj3lh8j' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/6pj3lh8j</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/6pj3lh8j' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/6pj3lh8j</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/2evrh0ns' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/2evrh0ns</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'single_step' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'my_seed' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'TIME' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BATCH' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'IMAGE_SIZE' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'which_data' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'data_path' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'rate_coding' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_init' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_decay' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_threshold' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_reset' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_sg_width' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_conv_kernel_size' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_conv_stride' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_conv_padding' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_trace_const1' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_trace_const2' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'pre_trained' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'convTrue_fcFalse' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'cfg' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'net_print' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'pre_trained_path' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'learning_rate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'epoch_num' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'tdBN_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BN_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'surrogate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BPTT_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'optimizer_what' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'scheduler_name' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'ddp_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'dvs_clipping' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'dvs_duration' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'DFA_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'trace_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'OTTT_input_trace_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'exclude_class' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'merge_polarities' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'denoise_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'extra_train_dataset' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'num_workers' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'chaching_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'pin_memory' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'UDA_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'alpha_uda' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'bias' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'last_lif' was locked by 'sweep' (ignored update).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "param {'devices': '0', 'single_step': True, 'unique_name': 'main', 'my_seed': 42, 'TIME': 10, 'BATCH': 16, 'IMAGE_SIZE': 128, 'which_data': 'DVS_GESTURE_TONIC', 'data_path': '/data2', 'rate_coding': False, 'lif_layer_v_init': 0, 'lif_layer_v_decay': 0.5, 'lif_layer_v_threshold': 0.25, 'lif_layer_v_reset': 10000, 'lif_layer_sg_width': 3, 'synapse_conv_kernel_size': 3, 'synapse_conv_stride': 1, 'synapse_conv_padding': 1, 'synapse_trace_const1': 1, 'synapse_trace_const2': 0, 'pre_trained': False, 'convTrue_fcFalse': False, 'cfg': ['M', 'M', 200, 200], 'net_print': True, 'pre_trained_path': 'net_save/save_now_net_weights_{unique_name}.pth', 'learning_rate': 0.001, 'epoch_num': 100, 'tdBN_on': False, 'BN_on': False, 'surrogate': 'hard_sigmoid', 'BPTT_on': False, 'optimizer_what': 'SGD', 'scheduler_name': 'no', 'ddp_on': False, 'dvs_clipping': 5, 'dvs_duration': 100000, 'DFA_on': False, 'trace_on': True, 'OTTT_input_trace_on': False, 'exclude_class': True, 'merge_polarities': False, 'denoise_on': True, 'extra_train_dataset': 0, 'num_workers': 2, 'chaching_on': True, 'pin_memory': True, 'UDA_on': False, 'alpha_uda': 1, 'bias': True, 'last_lif': False, 'current epoch': 0} \n",
      "\n",
      "dataset_hash = 63cc597115630ec173f3099200061e53\n",
      "cache path exists\n",
      "\n",
      "device ==> cuda\n",
      "\n",
      "DataParallel(\n",
      "  (module): REBORN_MY_SNN_FC(\n",
      "    (layers): REBORN_MY_Sequential(\n",
      "      (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (2): DimChanger_for_FC()\n",
      "      (3): SYNAPSE_FC(in_features=2048, out_features=200, TIME=10, bias=True, sstep=True)\n",
      "      (4): LIF_layer(v_init=0, v_decay=0.5, v_threshold=0.25, v_reset=10000, sg_width=3, surrogate=hard_sigmoid, BPTT_on=False, trace_const1=1, trace_const2=0, TIME=10, sstep=True, trace_on=True)\n",
      "      (5): SYNAPSE_FC(in_features=200, out_features=200, TIME=10, bias=True, sstep=True)\n",
      "      (6): LIF_layer(v_init=0, v_decay=0.5, v_threshold=0.25, v_reset=10000, sg_width=3, surrogate=hard_sigmoid, BPTT_on=False, trace_const1=1, trace_const2=0, TIME=10, sstep=True, trace_on=True)\n",
      "      (7): SYNAPSE_FC(in_features=200, out_features=10, TIME=10, bias=True, sstep=True)\n",
      "    )\n",
      "  )\n",
      ")\n",
      "\n",
      "========================================================\n",
      "Trainable parameters: 452,010\n",
      "========================================================\n",
      "\n",
      "epoch-0   lr=['0.0010000'], tr/val_loss:  2.244790/  2.117971, val:  30.00%, val_best:  30.00%, tr:  17.06%, tr_best:  17.06%\n",
      "epoch-1   lr=['0.0010000'], tr/val_loss:  1.844503/  1.726617, val:  53.33%, val_best:  53.33%, tr:  45.15%, tr_best:  45.15%\n",
      "epoch-2   lr=['0.0010000'], tr/val_loss:  1.516969/  1.577969, val:  59.17%, val_best:  59.17%, tr:  59.65%, tr_best:  59.65%\n",
      "epoch-3   lr=['0.0010000'], tr/val_loss:  1.358892/  1.518518, val:  60.00%, val_best:  60.00%, tr:  65.17%, tr_best:  65.17%\n",
      "epoch-4   lr=['0.0010000'], tr/val_loss:  1.275653/  1.454797, val:  59.58%, val_best:  60.00%, tr:  64.35%, tr_best:  65.17%\n",
      "epoch-5   lr=['0.0010000'], tr/val_loss:  1.194170/  1.388654, val:  61.25%, val_best:  61.25%, tr:  65.37%, tr_best:  65.37%\n",
      "epoch-6   lr=['0.0010000'], tr/val_loss:  1.130845/  1.353649, val:  61.25%, val_best:  61.25%, tr:  68.34%, tr_best:  68.34%\n",
      "epoch-7   lr=['0.0010000'], tr/val_loss:  1.087978/  1.326963, val:  59.58%, val_best:  61.25%, tr:  70.38%, tr_best:  70.38%\n",
      "epoch-8   lr=['0.0010000'], tr/val_loss:  1.043500/  1.304993, val:  68.33%, val_best:  68.33%, tr:  70.48%, tr_best:  70.48%\n",
      "epoch-9   lr=['0.0010000'], tr/val_loss:  1.015802/  1.303504, val:  61.67%, val_best:  68.33%, tr:  71.91%, tr_best:  71.91%\n",
      "epoch-10  lr=['0.0010000'], tr/val_loss:  0.994253/  1.319968, val:  59.58%, val_best:  68.33%, tr:  70.68%, tr_best:  71.91%\n",
      "epoch-11  lr=['0.0010000'], tr/val_loss:  0.957368/  1.239127, val:  67.08%, val_best:  68.33%, tr:  71.30%, tr_best:  71.91%\n",
      "epoch-12  lr=['0.0010000'], tr/val_loss:  0.944597/  1.237786, val:  63.33%, val_best:  68.33%, tr:  73.34%, tr_best:  73.34%\n",
      "epoch-13  lr=['0.0010000'], tr/val_loss:  0.922963/  1.254665, val:  65.00%, val_best:  68.33%, tr:  73.44%, tr_best:  73.44%\n",
      "epoch-14  lr=['0.0010000'], tr/val_loss:  0.880083/  1.313445, val:  61.25%, val_best:  68.33%, tr:  76.40%, tr_best:  76.40%\n",
      "epoch-15  lr=['0.0010000'], tr/val_loss:  0.865699/  1.260782, val:  65.42%, val_best:  68.33%, tr:  77.32%, tr_best:  77.32%\n",
      "epoch-16  lr=['0.0010000'], tr/val_loss:  0.869617/  1.206606, val:  68.33%, val_best:  68.33%, tr:  75.69%, tr_best:  77.32%\n",
      "epoch-17  lr=['0.0010000'], tr/val_loss:  0.812456/  1.211958, val:  65.83%, val_best:  68.33%, tr:  79.98%, tr_best:  79.98%\n",
      "epoch-18  lr=['0.0010000'], tr/val_loss:  0.800647/  1.286116, val:  62.92%, val_best:  68.33%, tr:  80.29%, tr_best:  80.29%\n",
      "epoch-19  lr=['0.0010000'], tr/val_loss:  0.792536/  1.259680, val:  64.58%, val_best:  68.33%, tr:  77.63%, tr_best:  80.29%\n",
      "epoch-20  lr=['0.0010000'], tr/val_loss:  0.750448/  1.226432, val:  70.83%, val_best:  70.83%, tr:  82.43%, tr_best:  82.43%\n",
      "epoch-21  lr=['0.0010000'], tr/val_loss:  0.738894/  1.238234, val:  71.25%, val_best:  71.25%, tr:  82.74%, tr_best:  82.74%\n",
      "epoch-22  lr=['0.0010000'], tr/val_loss:  0.744808/  1.242270, val:  69.58%, val_best:  71.25%, tr:  81.10%, tr_best:  82.74%\n",
      "epoch-23  lr=['0.0010000'], tr/val_loss:  0.706007/  1.257317, val:  69.58%, val_best:  71.25%, tr:  83.04%, tr_best:  83.04%\n",
      "epoch-24  lr=['0.0010000'], tr/val_loss:  0.679400/  1.273968, val:  65.42%, val_best:  71.25%, tr:  86.11%, tr_best:  86.11%\n",
      "epoch-25  lr=['0.0010000'], tr/val_loss:  0.664042/  1.267639, val:  70.00%, val_best:  71.25%, tr:  85.80%, tr_best:  86.11%\n",
      "epoch-26  lr=['0.0010000'], tr/val_loss:  0.657055/  1.270736, val:  71.67%, val_best:  71.67%, tr:  85.19%, tr_best:  86.11%\n",
      "epoch-27  lr=['0.0010000'], tr/val_loss:  0.630816/  1.311020, val:  71.25%, val_best:  71.67%, tr:  88.15%, tr_best:  88.15%\n",
      "epoch-28  lr=['0.0010000'], tr/val_loss:  0.623369/  1.268060, val:  73.75%, val_best:  73.75%, tr:  88.76%, tr_best:  88.76%\n",
      "epoch-29  lr=['0.0010000'], tr/val_loss:  0.610355/  1.352269, val:  63.33%, val_best:  73.75%, tr:  91.22%, tr_best:  91.22%\n",
      "epoch-30  lr=['0.0010000'], tr/val_loss:  0.585453/  1.333915, val:  69.58%, val_best:  73.75%, tr:  91.62%, tr_best:  91.62%\n",
      "epoch-31  lr=['0.0010000'], tr/val_loss:  0.595883/  1.357217, val:  70.42%, val_best:  73.75%, tr:  88.15%, tr_best:  91.62%\n",
      "epoch-32  lr=['0.0010000'], tr/val_loss:  0.582845/  1.342523, val:  72.08%, val_best:  73.75%, tr:  90.40%, tr_best:  91.62%\n",
      "epoch-33  lr=['0.0010000'], tr/val_loss:  0.565615/  1.315497, val:  75.00%, val_best:  75.00%, tr:  91.93%, tr_best:  91.93%\n",
      "epoch-34  lr=['0.0010000'], tr/val_loss:  0.538868/  1.394151, val:  66.67%, val_best:  75.00%, tr:  93.97%, tr_best:  93.97%\n",
      "epoch-35  lr=['0.0010000'], tr/val_loss:  0.547774/  1.391047, val:  68.75%, val_best:  75.00%, tr:  89.68%, tr_best:  93.97%\n",
      "epoch-36  lr=['0.0010000'], tr/val_loss:  0.506756/  1.320149, val:  75.83%, val_best:  75.83%, tr:  94.18%, tr_best:  94.18%\n",
      "epoch-37  lr=['0.0010000'], tr/val_loss:  0.501048/  1.382256, val:  75.83%, val_best:  75.83%, tr:  95.81%, tr_best:  95.81%\n",
      "epoch-38  lr=['0.0010000'], tr/val_loss:  0.491646/  1.421288, val:  71.67%, val_best:  75.83%, tr:  95.51%, tr_best:  95.81%\n",
      "epoch-39  lr=['0.0010000'], tr/val_loss:  0.481220/  1.397108, val:  74.17%, val_best:  75.83%, tr:  96.12%, tr_best:  96.12%\n",
      "epoch-40  lr=['0.0010000'], tr/val_loss:  0.477703/  1.398490, val:  74.58%, val_best:  75.83%, tr:  94.59%, tr_best:  96.12%\n",
      "epoch-41  lr=['0.0010000'], tr/val_loss:  0.455845/  1.453521, val:  72.08%, val_best:  75.83%, tr:  95.91%, tr_best:  96.12%\n",
      "epoch-42  lr=['0.0010000'], tr/val_loss:  0.436150/  1.413260, val:  75.00%, val_best:  75.83%, tr:  97.04%, tr_best:  97.04%\n",
      "epoch-43  lr=['0.0010000'], tr/val_loss:  0.432621/  1.442278, val:  72.08%, val_best:  75.83%, tr:  96.63%, tr_best:  97.04%\n",
      "epoch-44  lr=['0.0010000'], tr/val_loss:  0.429943/  1.469997, val:  75.42%, val_best:  75.83%, tr:  96.32%, tr_best:  97.04%\n",
      "epoch-45  lr=['0.0010000'], tr/val_loss:  0.409982/  1.455422, val:  77.08%, val_best:  77.08%, tr:  98.16%, tr_best:  98.16%\n",
      "epoch-46  lr=['0.0010000'], tr/val_loss:  0.408917/  1.473186, val:  75.00%, val_best:  77.08%, tr:  97.96%, tr_best:  98.16%\n",
      "epoch-47  lr=['0.0010000'], tr/val_loss:  0.390471/  1.499934, val:  77.08%, val_best:  77.08%, tr:  98.57%, tr_best:  98.57%\n",
      "epoch-48  lr=['0.0010000'], tr/val_loss:  0.398830/  1.484194, val:  79.17%, val_best:  79.17%, tr:  98.06%, tr_best:  98.57%\n",
      "epoch-49  lr=['0.0010000'], tr/val_loss:  0.385126/  1.509684, val:  77.92%, val_best:  79.17%, tr:  98.37%, tr_best:  98.57%\n",
      "epoch-50  lr=['0.0010000'], tr/val_loss:  0.372553/  1.542214, val:  72.08%, val_best:  79.17%, tr:  99.08%, tr_best:  99.08%\n",
      "epoch-51  lr=['0.0010000'], tr/val_loss:  0.389611/  1.484313, val:  77.50%, val_best:  79.17%, tr:  96.53%, tr_best:  99.08%\n",
      "epoch-52  lr=['0.0010000'], tr/val_loss:  0.346050/  1.533707, val:  75.42%, val_best:  79.17%, tr:  98.47%, tr_best:  99.08%\n",
      "epoch-53  lr=['0.0010000'], tr/val_loss:  0.344386/  1.612259, val:  75.42%, val_best:  79.17%, tr:  98.98%, tr_best:  99.08%\n",
      "epoch-54  lr=['0.0010000'], tr/val_loss:  0.347577/  1.545712, val:  77.92%, val_best:  79.17%, tr:  98.67%, tr_best:  99.08%\n",
      "epoch-55  lr=['0.0010000'], tr/val_loss:  0.329431/  1.582648, val:  72.92%, val_best:  79.17%, tr:  99.08%, tr_best:  99.08%\n",
      "epoch-56  lr=['0.0010000'], tr/val_loss:  0.325292/  1.632455, val:  72.92%, val_best:  79.17%, tr:  99.39%, tr_best:  99.39%\n",
      "epoch-57  lr=['0.0010000'], tr/val_loss:  0.326688/  1.592955, val:  78.33%, val_best:  79.17%, tr:  98.67%, tr_best:  99.39%\n",
      "epoch-58  lr=['0.0010000'], tr/val_loss:  0.319869/  1.613359, val:  74.17%, val_best:  79.17%, tr:  99.08%, tr_best:  99.39%\n",
      "epoch-59  lr=['0.0010000'], tr/val_loss:  0.311526/  1.617214, val:  79.58%, val_best:  79.58%, tr:  99.18%, tr_best:  99.39%\n",
      "epoch-60  lr=['0.0010000'], tr/val_loss:  0.289803/  1.633234, val:  77.50%, val_best:  79.58%, tr:  98.88%, tr_best:  99.39%\n",
      "epoch-61  lr=['0.0010000'], tr/val_loss:  0.302365/  1.638213, val:  78.75%, val_best:  79.58%, tr:  98.98%, tr_best:  99.39%\n",
      "epoch-62  lr=['0.0010000'], tr/val_loss:  0.285579/  1.648915, val:  75.42%, val_best:  79.58%, tr:  99.90%, tr_best:  99.90%\n",
      "epoch-63  lr=['0.0010000'], tr/val_loss:  0.274519/  1.640497, val:  79.58%, val_best:  79.58%, tr:  99.59%, tr_best:  99.90%\n",
      "epoch-64  lr=['0.0010000'], tr/val_loss:  0.274801/  1.698146, val:  76.25%, val_best:  79.58%, tr:  99.69%, tr_best:  99.90%\n",
      "epoch-65  lr=['0.0010000'], tr/val_loss:  0.258618/  1.670486, val:  78.33%, val_best:  79.58%, tr:  99.59%, tr_best:  99.90%\n",
      "epoch-66  lr=['0.0010000'], tr/val_loss:  0.260837/  1.671966, val:  77.50%, val_best:  79.58%, tr:  99.69%, tr_best:  99.90%\n",
      "epoch-67  lr=['0.0010000'], tr/val_loss:  0.254638/  1.678733, val:  78.75%, val_best:  79.58%, tr:  99.80%, tr_best:  99.90%\n",
      "epoch-68  lr=['0.0010000'], tr/val_loss:  0.254895/  1.722391, val:  76.25%, val_best:  79.58%, tr:  99.49%, tr_best:  99.90%\n",
      "epoch-69  lr=['0.0010000'], tr/val_loss:  0.249644/  1.683241, val:  76.67%, val_best:  79.58%, tr:  99.59%, tr_best:  99.90%\n",
      "epoch-70  lr=['0.0010000'], tr/val_loss:  0.238139/  1.736616, val:  78.75%, val_best:  79.58%, tr:  99.59%, tr_best:  99.90%\n",
      "epoch-71  lr=['0.0010000'], tr/val_loss:  0.245067/  1.754478, val:  77.50%, val_best:  79.58%, tr:  99.39%, tr_best:  99.90%\n",
      "epoch-72  lr=['0.0010000'], tr/val_loss:  0.234814/  1.770116, val:  74.17%, val_best:  79.58%, tr:  99.69%, tr_best:  99.90%\n",
      "epoch-73  lr=['0.0010000'], tr/val_loss:  0.234421/  1.775457, val:  73.33%, val_best:  79.58%, tr:  99.49%, tr_best:  99.90%\n",
      "epoch-74  lr=['0.0010000'], tr/val_loss:  0.220742/  1.747667, val:  77.92%, val_best:  79.58%, tr:  99.59%, tr_best:  99.90%\n",
      "epoch-75  lr=['0.0010000'], tr/val_loss:  0.215102/  1.789567, val:  75.83%, val_best:  79.58%, tr:  99.90%, tr_best:  99.90%\n",
      "epoch-76  lr=['0.0010000'], tr/val_loss:  0.216391/  1.755097, val:  77.50%, val_best:  79.58%, tr:  99.90%, tr_best:  99.90%\n",
      "epoch-77  lr=['0.0010000'], tr/val_loss:  0.207319/  1.798704, val:  79.17%, val_best:  79.58%, tr:  99.59%, tr_best:  99.90%\n",
      "epoch-78  lr=['0.0010000'], tr/val_loss:  0.212309/  1.822869, val:  75.42%, val_best:  79.58%, tr:  99.90%, tr_best:  99.90%\n",
      "epoch-79  lr=['0.0010000'], tr/val_loss:  0.198274/  1.814663, val:  77.08%, val_best:  79.58%, tr:  99.90%, tr_best:  99.90%\n",
      "epoch-80  lr=['0.0010000'], tr/val_loss:  0.189054/  1.841744, val:  77.50%, val_best:  79.58%, tr:  99.90%, tr_best:  99.90%\n",
      "epoch-81  lr=['0.0010000'], tr/val_loss:  0.189737/  1.809117, val:  78.75%, val_best:  79.58%, tr:  99.69%, tr_best:  99.90%\n",
      "epoch-82  lr=['0.0010000'], tr/val_loss:  0.186041/  1.860261, val:  76.67%, val_best:  79.58%, tr:  99.69%, tr_best:  99.90%\n",
      "epoch-83  lr=['0.0010000'], tr/val_loss:  0.183467/  1.921055, val:  75.83%, val_best:  79.58%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-84  lr=['0.0010000'], tr/val_loss:  0.177126/  1.831232, val:  80.42%, val_best:  80.42%, tr:  99.80%, tr_best: 100.00%\n",
      "epoch-85  lr=['0.0010000'], tr/val_loss:  0.182208/  1.910857, val:  75.42%, val_best:  80.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-86  lr=['0.0010000'], tr/val_loss:  0.168104/  1.876740, val:  77.50%, val_best:  80.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-87  lr=['0.0010000'], tr/val_loss:  0.171495/  1.900102, val:  79.17%, val_best:  80.42%, tr:  99.69%, tr_best: 100.00%\n",
      "epoch-88  lr=['0.0010000'], tr/val_loss:  0.165875/  1.883553, val:  79.58%, val_best:  80.42%, tr:  99.80%, tr_best: 100.00%\n",
      "epoch-89  lr=['0.0010000'], tr/val_loss:  0.153418/  1.946973, val:  75.83%, val_best:  80.42%, tr:  99.90%, tr_best: 100.00%\n",
      "epoch-90  lr=['0.0010000'], tr/val_loss:  0.161553/  1.917978, val:  77.92%, val_best:  80.42%, tr:  99.90%, tr_best: 100.00%\n",
      "epoch-91  lr=['0.0010000'], tr/val_loss:  0.151340/  1.972408, val:  75.42%, val_best:  80.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-92  lr=['0.0010000'], tr/val_loss:  0.143546/  1.948620, val:  77.08%, val_best:  80.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-93  lr=['0.0010000'], tr/val_loss:  0.147177/  1.980421, val:  75.42%, val_best:  80.42%, tr:  99.90%, tr_best: 100.00%\n",
      "epoch-94  lr=['0.0010000'], tr/val_loss:  0.137661/  2.004752, val:  77.92%, val_best:  80.42%, tr:  99.90%, tr_best: 100.00%\n",
      "epoch-95  lr=['0.0010000'], tr/val_loss:  0.138156/  2.013861, val:  77.50%, val_best:  80.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-96  lr=['0.0010000'], tr/val_loss:  0.131274/  2.055763, val:  76.67%, val_best:  80.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-97  lr=['0.0010000'], tr/val_loss:  0.136665/  1.984224, val:  78.75%, val_best:  80.42%, tr:  99.90%, tr_best: 100.00%\n",
      "epoch-98  lr=['0.0010000'], tr/val_loss:  0.126464/  2.055424, val:  75.42%, val_best:  80.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-99  lr=['0.0010000'], tr/val_loss:  0.126992/  2.088540, val:  77.92%, val_best:  80.42%, tr: 100.00%, tr_best: 100.00%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bbdc2a77f21e4d81856c99113b14ed83",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.006 MB of 0.006 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>iter_acc</td><td>▂▆▅▅▅▅▆▁▃▇█▇█▇▇▇█▇███████████▇██████▇███</td></tr><tr><td>summary_val_acc</td><td>▁▅▅▅▅▆▅▆▆▇▆▇▆▇▆▇▇▇▇██▇███████▇▇██▇██▇███</td></tr><tr><td>tr_acc</td><td>▁▅▅▅▆▆▆▆▆▇▇▇▇▇▇█████████████████████████</td></tr><tr><td>tr_epoch_loss</td><td>█▆▅▄▄▄▃▃▃▃▃▃▃▂▂▂▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_acc_best</td><td>▁▅▅▅▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇█████████████████████</td></tr><tr><td>val_acc_now</td><td>▁▅▅▅▅▆▅▆▆▇▆▇▆▇▆▇▇▇▇██▇███████▇▇██▇██▇███</td></tr><tr><td>val_loss</td><td>█▄▃▂▂▁▂▁▁▁▁▁▂▂▂▂▂▃▃▃▃▃▄▄▄▄▅▅▅▅▅▆▆▆▆▆▇▇▇▇</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>99</td></tr><tr><td>iter_acc</td><td>1.0</td></tr><tr><td>tr_acc</td><td>1.0</td></tr><tr><td>tr_epoch_loss</td><td>0.12699</td></tr><tr><td>val_acc_best</td><td>0.80417</td></tr><tr><td>val_acc_now</td><td>0.77917</td></tr><tr><td>val_loss</td><td>2.08854</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">serene-sweep-43</strong> at: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/2evrh0ns' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/2evrh0ns</a><br/> View project at: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>/data2/bh_wandb/wandb/run-20250430_000001-2evrh0ns/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require(\"core\")`! See https://wandb.me/wandb-core for more information."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: wlvvet35 with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBATCH: 16\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBN_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBPTT_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tDFA_on: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tIMAGE_SIZE: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tOTTT_input_trace_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tTIME: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tUDA_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \talpha_uda: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbias: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcfg: ['M', 'M', 200, 200]\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tchaching_on: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tconvTrue_fcFalse: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdata_path: /data2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tddp_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdenoise_on: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdvs_clipping: 5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdvs_duration: 100000\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepoch_num: 100\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \texclude_class: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \textra_train_dataset: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlast_lif: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.001\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_sg_width: 5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_decay: 0.5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_init: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_reset: 10000\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_threshold: 0.25\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmerge_polarities: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmy_seed: 42\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnet_print: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_workers: 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer_what: SGD\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tpin_memory: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tpre_trained: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tpre_trained_path: net_save/save_now_net_weights_{unique_name}.pth\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \trate_coding: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tscheduler_name: no\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsingle_step: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsurrogate: hard_sigmoid\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_conv_kernel_size: 3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_conv_padding: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_conv_stride: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_trace_const1: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_trace_const2: 0.5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \ttdBN_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \ttrace_on: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \twhich_data: DVS_GESTURE_TONIC\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.19.10 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.17.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/data2/bh_wandb/wandb/run-20250430_000628-wlvvet35</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/wlvvet35' target=\"_blank\">misty-sweep-46</a></strong> to <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/6pj3lh8j' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/6pj3lh8j</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/6pj3lh8j' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/6pj3lh8j</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/wlvvet35' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/wlvvet35</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'single_step' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'my_seed' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'TIME' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BATCH' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'IMAGE_SIZE' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'which_data' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'data_path' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'rate_coding' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_init' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_decay' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_threshold' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_reset' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_sg_width' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_conv_kernel_size' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_conv_stride' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_conv_padding' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_trace_const1' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_trace_const2' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'pre_trained' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'convTrue_fcFalse' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'cfg' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'net_print' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'pre_trained_path' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'learning_rate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'epoch_num' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'tdBN_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BN_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'surrogate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BPTT_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'optimizer_what' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'scheduler_name' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'ddp_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'dvs_clipping' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'dvs_duration' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'DFA_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'trace_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'OTTT_input_trace_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'exclude_class' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'merge_polarities' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'denoise_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'extra_train_dataset' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'num_workers' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'chaching_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'pin_memory' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'UDA_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'alpha_uda' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'bias' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'last_lif' was locked by 'sweep' (ignored update).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "param {'devices': '0', 'single_step': True, 'unique_name': 'main', 'my_seed': 42, 'TIME': 10, 'BATCH': 16, 'IMAGE_SIZE': 128, 'which_data': 'DVS_GESTURE_TONIC', 'data_path': '/data2', 'rate_coding': False, 'lif_layer_v_init': 0, 'lif_layer_v_decay': 0.5, 'lif_layer_v_threshold': 0.25, 'lif_layer_v_reset': 10000, 'lif_layer_sg_width': 5, 'synapse_conv_kernel_size': 3, 'synapse_conv_stride': 1, 'synapse_conv_padding': 1, 'synapse_trace_const1': 1, 'synapse_trace_const2': 0.5, 'pre_trained': False, 'convTrue_fcFalse': False, 'cfg': ['M', 'M', 200, 200], 'net_print': True, 'pre_trained_path': 'net_save/save_now_net_weights_{unique_name}.pth', 'learning_rate': 0.001, 'epoch_num': 100, 'tdBN_on': False, 'BN_on': False, 'surrogate': 'hard_sigmoid', 'BPTT_on': False, 'optimizer_what': 'SGD', 'scheduler_name': 'no', 'ddp_on': False, 'dvs_clipping': 5, 'dvs_duration': 100000, 'DFA_on': True, 'trace_on': True, 'OTTT_input_trace_on': False, 'exclude_class': True, 'merge_polarities': False, 'denoise_on': True, 'extra_train_dataset': 0, 'num_workers': 2, 'chaching_on': True, 'pin_memory': True, 'UDA_on': False, 'alpha_uda': 1, 'bias': True, 'last_lif': False, 'current epoch': 0} \n",
      "\n",
      "dataset_hash = 63cc597115630ec173f3099200061e53\n",
      "cache path exists\n",
      "\n",
      "device ==> cuda\n",
      "\n",
      "DataParallel(\n",
      "  (module): REBORN_MY_SNN_FC(\n",
      "    (layers): REBORN_MY_Sequential(\n",
      "      (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (2): DimChanger_for_FC()\n",
      "      (3): SYNAPSE_FC(in_features=2048, out_features=200, TIME=10, bias=True, sstep=True)\n",
      "      (4): LIF_layer(v_init=0, v_decay=0.5, v_threshold=0.25, v_reset=10000, sg_width=5, surrogate=hard_sigmoid, BPTT_on=False, trace_const1=1, trace_const2=0.5, TIME=10, sstep=True, trace_on=True)\n",
      "      (5): Feedback_Receiver()\n",
      "      (6): SYNAPSE_FC(in_features=200, out_features=200, TIME=10, bias=True, sstep=True)\n",
      "      (7): LIF_layer(v_init=0, v_decay=0.5, v_threshold=0.25, v_reset=10000, sg_width=5, surrogate=hard_sigmoid, BPTT_on=False, trace_const1=1, trace_const2=0.5, TIME=10, sstep=True, trace_on=True)\n",
      "      (8): Feedback_Receiver()\n",
      "      (9): SYNAPSE_FC(in_features=200, out_features=10, TIME=10, bias=True, sstep=True)\n",
      "      (DFA_top): Top_Gradient()\n",
      "    )\n",
      "  )\n",
      ")\n",
      "\n",
      "========================================================\n",
      "Trainable parameters: 452,010\n",
      "========================================================\n",
      "\n",
      "epoch-0   lr=['0.0010000'], tr/val_loss:  1.990620/  1.614645, val:  46.67%, val_best:  46.67%, tr:  25.33%, tr_best:  25.33%\n",
      "[module.layers.5] weight_fb parameter count: 2,000\n",
      "[module.layers.8] weight_fb parameter count: 2,000\n",
      "epoch-1   lr=['0.0010000'], tr/val_loss:  1.358078/  1.534883, val:  54.58%, val_best:  54.58%, tr:  56.28%, tr_best:  56.28%\n",
      "epoch-2   lr=['0.0010000'], tr/val_loss:  1.237204/  1.496169, val:  56.25%, val_best:  56.25%, tr:  60.57%, tr_best:  60.57%\n",
      "epoch-3   lr=['0.0010000'], tr/val_loss:  1.088470/  1.548273, val:  55.00%, val_best:  56.25%, tr:  67.01%, tr_best:  67.01%\n",
      "epoch-4   lr=['0.0010000'], tr/val_loss:  1.039401/  1.400908, val:  59.17%, val_best:  59.17%, tr:  68.64%, tr_best:  68.64%\n",
      "epoch-5   lr=['0.0010000'], tr/val_loss:  1.017616/  1.456495, val:  57.08%, val_best:  59.17%, tr:  70.99%, tr_best:  70.99%\n",
      "epoch-6   lr=['0.0010000'], tr/val_loss:  0.985705/  1.409472, val:  57.50%, val_best:  59.17%, tr:  71.20%, tr_best:  71.20%\n",
      "epoch-7   lr=['0.0010000'], tr/val_loss:  0.924223/  1.550875, val:  60.83%, val_best:  60.83%, tr:  73.03%, tr_best:  73.03%\n",
      "epoch-8   lr=['0.0010000'], tr/val_loss:  0.911912/  1.445048, val:  64.58%, val_best:  64.58%, tr:  73.14%, tr_best:  73.14%\n",
      "epoch-9   lr=['0.0010000'], tr/val_loss:  0.853157/  1.518858, val:  60.83%, val_best:  64.58%, tr:  81.82%, tr_best:  81.82%\n",
      "epoch-10  lr=['0.0010000'], tr/val_loss:  0.856291/  1.645494, val:  62.92%, val_best:  64.58%, tr:  81.82%, tr_best:  81.82%\n",
      "epoch-11  lr=['0.0010000'], tr/val_loss:  0.755948/  1.477123, val:  71.25%, val_best:  71.25%, tr:  86.62%, tr_best:  86.62%\n",
      "epoch-12  lr=['0.0010000'], tr/val_loss:  0.724195/  1.533547, val:  72.08%, val_best:  72.08%, tr:  90.09%, tr_best:  90.09%\n",
      "epoch-13  lr=['0.0010000'], tr/val_loss:  0.683185/  1.546304, val:  70.42%, val_best:  72.08%, tr:  89.48%, tr_best:  90.09%\n",
      "epoch-14  lr=['0.0010000'], tr/val_loss:  0.632084/  1.664972, val:  69.17%, val_best:  72.08%, tr:  91.73%, tr_best:  91.73%\n",
      "epoch-15  lr=['0.0010000'], tr/val_loss:  0.616362/  1.693464, val:  70.00%, val_best:  72.08%, tr:  92.85%, tr_best:  92.85%\n",
      "epoch-16  lr=['0.0010000'], tr/val_loss:  0.588018/  1.674339, val:  72.92%, val_best:  72.92%, tr:  94.48%, tr_best:  94.48%\n",
      "epoch-17  lr=['0.0010000'], tr/val_loss:  0.572797/  1.753455, val:  71.25%, val_best:  72.92%, tr:  96.12%, tr_best:  96.12%\n",
      "epoch-18  lr=['0.0010000'], tr/val_loss:  0.546666/  1.891406, val:  69.58%, val_best:  72.92%, tr:  95.71%, tr_best:  96.12%\n",
      "epoch-19  lr=['0.0010000'], tr/val_loss:  0.522310/  1.798971, val:  71.67%, val_best:  72.92%, tr:  96.12%, tr_best:  96.12%\n",
      "epoch-20  lr=['0.0010000'], tr/val_loss:  0.495528/  1.912066, val:  71.25%, val_best:  72.92%, tr:  97.55%, tr_best:  97.55%\n",
      "epoch-21  lr=['0.0010000'], tr/val_loss:  0.484988/  1.956352, val:  71.25%, val_best:  72.92%, tr:  97.04%, tr_best:  97.55%\n",
      "epoch-22  lr=['0.0010000'], tr/val_loss:  0.462601/  1.919845, val:  75.83%, val_best:  75.83%, tr:  97.96%, tr_best:  97.96%\n",
      "epoch-23  lr=['0.0010000'], tr/val_loss:  0.467776/  1.945479, val:  72.50%, val_best:  75.83%, tr:  97.34%, tr_best:  97.96%\n",
      "epoch-24  lr=['0.0010000'], tr/val_loss:  0.423543/  2.013102, val:  74.17%, val_best:  75.83%, tr:  98.98%, tr_best:  98.98%\n",
      "epoch-25  lr=['0.0010000'], tr/val_loss:  0.409311/  2.012435, val:  77.92%, val_best:  77.92%, tr:  98.57%, tr_best:  98.98%\n",
      "epoch-26  lr=['0.0010000'], tr/val_loss:  0.441800/  2.044925, val:  77.92%, val_best:  77.92%, tr:  96.94%, tr_best:  98.98%\n",
      "epoch-27  lr=['0.0010000'], tr/val_loss:  0.400491/  2.156753, val:  74.17%, val_best:  77.92%, tr:  98.98%, tr_best:  98.98%\n",
      "epoch-28  lr=['0.0010000'], tr/val_loss:  0.369612/  2.102228, val:  77.92%, val_best:  77.92%, tr:  99.39%, tr_best:  99.39%\n",
      "epoch-29  lr=['0.0010000'], tr/val_loss:  0.359280/  2.312997, val:  72.08%, val_best:  77.92%, tr:  99.39%, tr_best:  99.39%\n",
      "epoch-30  lr=['0.0010000'], tr/val_loss:  0.343359/  2.257428, val:  77.50%, val_best:  77.92%, tr:  99.18%, tr_best:  99.39%\n",
      "epoch-31  lr=['0.0010000'], tr/val_loss:  0.341378/  2.311975, val:  80.00%, val_best:  80.00%, tr:  99.28%, tr_best:  99.39%\n",
      "epoch-32  lr=['0.0010000'], tr/val_loss:  0.343315/  2.412877, val:  76.25%, val_best:  80.00%, tr:  99.69%, tr_best:  99.69%\n",
      "epoch-33  lr=['0.0010000'], tr/val_loss:  0.345590/  2.443104, val:  78.75%, val_best:  80.00%, tr:  99.28%, tr_best:  99.69%\n",
      "epoch-34  lr=['0.0010000'], tr/val_loss:  0.323223/  2.578013, val:  75.42%, val_best:  80.00%, tr:  99.39%, tr_best:  99.69%\n",
      "epoch-35  lr=['0.0010000'], tr/val_loss:  0.310358/  2.606244, val:  73.75%, val_best:  80.00%, tr:  99.69%, tr_best:  99.69%\n",
      "epoch-36  lr=['0.0010000'], tr/val_loss:  0.303127/  2.496770, val:  78.33%, val_best:  80.00%, tr:  99.69%, tr_best:  99.69%\n",
      "epoch-37  lr=['0.0010000'], tr/val_loss:  0.287391/  2.627124, val:  77.50%, val_best:  80.00%, tr:  99.69%, tr_best:  99.69%\n",
      "epoch-38  lr=['0.0010000'], tr/val_loss:  0.281313/  2.645207, val:  77.08%, val_best:  80.00%, tr:  99.80%, tr_best:  99.80%\n",
      "epoch-39  lr=['0.0010000'], tr/val_loss:  0.292397/  2.612880, val:  78.75%, val_best:  80.00%, tr:  99.69%, tr_best:  99.80%\n",
      "epoch-40  lr=['0.0010000'], tr/val_loss:  0.267458/  2.751441, val:  75.83%, val_best:  80.00%, tr:  99.80%, tr_best:  99.80%\n",
      "epoch-41  lr=['0.0010000'], tr/val_loss:  0.246933/  2.734957, val:  75.83%, val_best:  80.00%, tr:  99.90%, tr_best:  99.90%\n",
      "epoch-42  lr=['0.0010000'], tr/val_loss:  0.246771/  2.791776, val:  76.25%, val_best:  80.00%, tr:  99.90%, tr_best:  99.90%\n",
      "epoch-43  lr=['0.0010000'], tr/val_loss:  0.243511/  2.860353, val:  75.42%, val_best:  80.00%, tr:  99.80%, tr_best:  99.90%\n",
      "epoch-44  lr=['0.0010000'], tr/val_loss:  0.223851/  2.807364, val:  79.17%, val_best:  80.00%, tr:  99.90%, tr_best:  99.90%\n",
      "epoch-45  lr=['0.0010000'], tr/val_loss:  0.212093/  2.841908, val:  77.50%, val_best:  80.00%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-46  lr=['0.0010000'], tr/val_loss:  0.219320/  2.879365, val:  78.33%, val_best:  80.00%, tr:  99.90%, tr_best: 100.00%\n",
      "epoch-47  lr=['0.0010000'], tr/val_loss:  0.200096/  2.882658, val:  77.92%, val_best:  80.00%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-48  lr=['0.0010000'], tr/val_loss:  0.204343/  2.915783, val:  79.58%, val_best:  80.00%, tr:  99.80%, tr_best: 100.00%\n",
      "epoch-49  lr=['0.0010000'], tr/val_loss:  0.196792/  3.023282, val:  78.75%, val_best:  80.00%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-50  lr=['0.0010000'], tr/val_loss:  0.190461/  3.041105, val:  77.50%, val_best:  80.00%, tr:  99.90%, tr_best: 100.00%\n",
      "epoch-51  lr=['0.0010000'], tr/val_loss:  0.184975/  3.030704, val:  80.00%, val_best:  80.00%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-52  lr=['0.0010000'], tr/val_loss:  0.191217/  3.020223, val:  77.92%, val_best:  80.00%, tr:  99.90%, tr_best: 100.00%\n",
      "epoch-53  lr=['0.0010000'], tr/val_loss:  0.182870/  3.097400, val:  78.33%, val_best:  80.00%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-54  lr=['0.0010000'], tr/val_loss:  0.185091/  3.106407, val:  79.58%, val_best:  80.00%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-55  lr=['0.0010000'], tr/val_loss:  0.176383/  3.256166, val:  78.33%, val_best:  80.00%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-56  lr=['0.0010000'], tr/val_loss:  0.173829/  3.347063, val:  74.58%, val_best:  80.00%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-57  lr=['0.0010000'], tr/val_loss:  0.164911/  3.303178, val:  77.92%, val_best:  80.00%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-58  lr=['0.0010000'], tr/val_loss:  0.162231/  3.336072, val:  75.00%, val_best:  80.00%, tr:  99.90%, tr_best: 100.00%\n",
      "epoch-59  lr=['0.0010000'], tr/val_loss:  0.158120/  3.353116, val:  78.33%, val_best:  80.00%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-60  lr=['0.0010000'], tr/val_loss:  0.144508/  3.342754, val:  78.33%, val_best:  80.00%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-61  lr=['0.0010000'], tr/val_loss:  0.144166/  3.424546, val:  77.92%, val_best:  80.00%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-62  lr=['0.0010000'], tr/val_loss:  0.141506/  3.401366, val:  77.08%, val_best:  80.00%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-63  lr=['0.0010000'], tr/val_loss:  0.137469/  3.458140, val:  78.75%, val_best:  80.00%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-64  lr=['0.0010000'], tr/val_loss:  0.133733/  3.503126, val:  78.33%, val_best:  80.00%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-65  lr=['0.0010000'], tr/val_loss:  0.129135/  3.532704, val:  76.67%, val_best:  80.00%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-66  lr=['0.0010000'], tr/val_loss:  0.123592/  3.605501, val:  76.25%, val_best:  80.00%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-67  lr=['0.0010000'], tr/val_loss:  0.123901/  3.594405, val:  76.67%, val_best:  80.00%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-68  lr=['0.0010000'], tr/val_loss:  0.123001/  3.596173, val:  77.92%, val_best:  80.00%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-69  lr=['0.0010000'], tr/val_loss:  0.115169/  3.636011, val:  78.33%, val_best:  80.00%, tr:  99.90%, tr_best: 100.00%\n",
      "epoch-70  lr=['0.0010000'], tr/val_loss:  0.110719/  3.614243, val:  77.50%, val_best:  80.00%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-71  lr=['0.0010000'], tr/val_loss:  0.138473/  3.764203, val:  77.50%, val_best:  80.00%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-72  lr=['0.0010000'], tr/val_loss:  0.125683/  3.804337, val:  77.50%, val_best:  80.00%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-73  lr=['0.0010000'], tr/val_loss:  0.117181/  3.707913, val:  78.33%, val_best:  80.00%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-74  lr=['0.0010000'], tr/val_loss:  0.114543/  3.710279, val:  78.33%, val_best:  80.00%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-75  lr=['0.0010000'], tr/val_loss:  0.113458/  3.818827, val:  76.25%, val_best:  80.00%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-76  lr=['0.0010000'], tr/val_loss:  0.106793/  3.818970, val:  76.25%, val_best:  80.00%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-77  lr=['0.0010000'], tr/val_loss:  0.112575/  3.880703, val:  77.50%, val_best:  80.00%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-78  lr=['0.0010000'], tr/val_loss:  0.111668/  3.866410, val:  77.92%, val_best:  80.00%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-79  lr=['0.0010000'], tr/val_loss:  0.106782/  3.934253, val:  78.75%, val_best:  80.00%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-80  lr=['0.0010000'], tr/val_loss:  0.104421/  3.921899, val:  78.75%, val_best:  80.00%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-81  lr=['0.0010000'], tr/val_loss:  0.097108/  3.927712, val:  77.92%, val_best:  80.00%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-82  lr=['0.0010000'], tr/val_loss:  0.088582/  3.954571, val:  78.75%, val_best:  80.00%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-83  lr=['0.0010000'], tr/val_loss:  0.106914/  4.028459, val:  77.08%, val_best:  80.00%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-84  lr=['0.0010000'], tr/val_loss:  0.086441/  3.981638, val:  77.92%, val_best:  80.00%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-85  lr=['0.0010000'], tr/val_loss:  0.090185/  4.003356, val:  78.33%, val_best:  80.00%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-86  lr=['0.0010000'], tr/val_loss:  0.088867/  4.022614, val:  77.50%, val_best:  80.00%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-87  lr=['0.0010000'], tr/val_loss:  0.086446/  4.072832, val:  78.33%, val_best:  80.00%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-88  lr=['0.0010000'], tr/val_loss:  0.083575/  4.054514, val:  79.17%, val_best:  80.00%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-89  lr=['0.0010000'], tr/val_loss:  0.084419/  4.092315, val:  78.33%, val_best:  80.00%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-90  lr=['0.0010000'], tr/val_loss:  0.094001/  4.043314, val:  78.75%, val_best:  80.00%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-91  lr=['0.0010000'], tr/val_loss:  0.088405/  4.097186, val:  78.33%, val_best:  80.00%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-92  lr=['0.0010000'], tr/val_loss:  0.079824/  4.089822, val:  79.58%, val_best:  80.00%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-93  lr=['0.0010000'], tr/val_loss:  0.087113/  4.095501, val:  79.58%, val_best:  80.00%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-94  lr=['0.0010000'], tr/val_loss:  0.083289/  4.190217, val:  76.67%, val_best:  80.00%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-95  lr=['0.0010000'], tr/val_loss:  0.078172/  4.108737, val:  79.17%, val_best:  80.00%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-96  lr=['0.0010000'], tr/val_loss:  0.075813/  4.196715, val:  77.92%, val_best:  80.00%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-97  lr=['0.0010000'], tr/val_loss:  0.084520/  4.179085, val:  78.75%, val_best:  80.00%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-98  lr=['0.0010000'], tr/val_loss:  0.084172/  4.199755, val:  76.67%, val_best:  80.00%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-99  lr=['0.0010000'], tr/val_loss:  0.076158/  4.245149, val:  79.17%, val_best:  80.00%, tr: 100.00%, tr_best: 100.00%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a170f257de2f4b8fa03b12fa7cbe83f0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.006 MB of 0.006 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>iter_acc</td><td>▁▆▄▁▄▅█▅████████████████████████████████</td></tr><tr><td>summary_val_acc</td><td>▁▃▄▄▄▆▆▆▆▆▇█▆▇▇██▇████████▇▇██▇█████████</td></tr><tr><td>tr_acc</td><td>▁▄▅▅▆▇▇█████████████████████████████████</td></tr><tr><td>tr_epoch_loss</td><td>█▅▅▄▄▃▃▃▃▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_acc_best</td><td>▁▃▄▄▅▆▆▇▇▇▇█████████████████████████████</td></tr><tr><td>val_acc_now</td><td>▁▃▄▄▄▆▆▆▆▆▇█▆▇▇██▇████████▇▇██▇█████████</td></tr><tr><td>val_loss</td><td>▂▁▁▁▁▁▂▂▂▂▃▃▃▄▄▄▄▅▅▅▅▅▅▆▆▆▆▇▇▇▇▇▇▇██████</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>99</td></tr><tr><td>iter_acc</td><td>1.0</td></tr><tr><td>tr_acc</td><td>1.0</td></tr><tr><td>tr_epoch_loss</td><td>0.07616</td></tr><tr><td>val_acc_best</td><td>0.8</td></tr><tr><td>val_acc_now</td><td>0.79167</td></tr><tr><td>val_loss</td><td>4.24515</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">misty-sweep-46</strong> at: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/wlvvet35' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/wlvvet35</a><br/> View project at: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>/data2/bh_wandb/wandb/run-20250430_000628-wlvvet35/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require(\"core\")`! See https://wandb.me/wandb-core for more information."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: dgq420x7 with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBATCH: 16\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBN_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBPTT_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tDFA_on: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tIMAGE_SIZE: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tOTTT_input_trace_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tTIME: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tUDA_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \talpha_uda: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbias: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcfg: ['M', 'M', 200, 200]\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tchaching_on: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tconvTrue_fcFalse: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdata_path: /data2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tddp_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdenoise_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdvs_clipping: 5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdvs_duration: 100000\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepoch_num: 100\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \texclude_class: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \textra_train_dataset: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlast_lif: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.01\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_sg_width: 3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_decay: 0.5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_init: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_reset: 10000\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_threshold: 0.25\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmerge_polarities: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmy_seed: 42\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnet_print: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_workers: 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer_what: SGD\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tpin_memory: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tpre_trained: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tpre_trained_path: net_save/save_now_net_weights_{unique_name}.pth\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \trate_coding: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tscheduler_name: no\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsingle_step: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsurrogate: hard_sigmoid\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_conv_kernel_size: 3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_conv_padding: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_conv_stride: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_trace_const1: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_trace_const2: 0.5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \ttdBN_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \ttrace_on: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \twhich_data: DVS_GESTURE_TONIC\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fc71ecb15a3e4dbbaa7867aa45491e85",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.011112743719584412, max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.19.10 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.17.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/data2/bh_wandb/wandb/run-20250430_001340-dgq420x7</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/dgq420x7' target=\"_blank\">frosty-sweep-51</a></strong> to <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/6pj3lh8j' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/6pj3lh8j</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/6pj3lh8j' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/6pj3lh8j</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/dgq420x7' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/dgq420x7</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'single_step' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'my_seed' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'TIME' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BATCH' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'IMAGE_SIZE' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'which_data' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'data_path' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'rate_coding' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_init' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_decay' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_threshold' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_reset' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_sg_width' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_conv_kernel_size' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_conv_stride' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_conv_padding' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_trace_const1' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_trace_const2' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'pre_trained' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'convTrue_fcFalse' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'cfg' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'net_print' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'pre_trained_path' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'learning_rate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'epoch_num' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'tdBN_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BN_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'surrogate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BPTT_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'optimizer_what' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'scheduler_name' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'ddp_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'dvs_clipping' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'dvs_duration' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'DFA_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'trace_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'OTTT_input_trace_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'exclude_class' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'merge_polarities' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'denoise_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'extra_train_dataset' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'num_workers' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'chaching_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'pin_memory' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'UDA_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'alpha_uda' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'bias' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'last_lif' was locked by 'sweep' (ignored update).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "param {'devices': '0', 'single_step': True, 'unique_name': 'main', 'my_seed': 42, 'TIME': 10, 'BATCH': 16, 'IMAGE_SIZE': 128, 'which_data': 'DVS_GESTURE_TONIC', 'data_path': '/data2', 'rate_coding': False, 'lif_layer_v_init': 0, 'lif_layer_v_decay': 0.5, 'lif_layer_v_threshold': 0.25, 'lif_layer_v_reset': 10000, 'lif_layer_sg_width': 3, 'synapse_conv_kernel_size': 3, 'synapse_conv_stride': 1, 'synapse_conv_padding': 1, 'synapse_trace_const1': 1, 'synapse_trace_const2': 0.5, 'pre_trained': False, 'convTrue_fcFalse': False, 'cfg': ['M', 'M', 200, 200], 'net_print': True, 'pre_trained_path': 'net_save/save_now_net_weights_{unique_name}.pth', 'learning_rate': 0.01, 'epoch_num': 100, 'tdBN_on': False, 'BN_on': False, 'surrogate': 'hard_sigmoid', 'BPTT_on': False, 'optimizer_what': 'SGD', 'scheduler_name': 'no', 'ddp_on': False, 'dvs_clipping': 5, 'dvs_duration': 100000, 'DFA_on': True, 'trace_on': True, 'OTTT_input_trace_on': False, 'exclude_class': True, 'merge_polarities': False, 'denoise_on': False, 'extra_train_dataset': 0, 'num_workers': 2, 'chaching_on': True, 'pin_memory': True, 'UDA_on': False, 'alpha_uda': 1, 'bias': True, 'last_lif': False, 'current epoch': 0} \n",
      "\n",
      "dataset_hash = ffa516e60c3efd5e0208f72b4c36cb84\n",
      "cache path exists\n",
      "\n",
      "device ==> cuda\n",
      "\n",
      "DataParallel(\n",
      "  (module): REBORN_MY_SNN_FC(\n",
      "    (layers): REBORN_MY_Sequential(\n",
      "      (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (2): DimChanger_for_FC()\n",
      "      (3): SYNAPSE_FC(in_features=2048, out_features=200, TIME=10, bias=True, sstep=True)\n",
      "      (4): LIF_layer(v_init=0, v_decay=0.5, v_threshold=0.25, v_reset=10000, sg_width=3, surrogate=hard_sigmoid, BPTT_on=False, trace_const1=1, trace_const2=0.5, TIME=10, sstep=True, trace_on=True)\n",
      "      (5): Feedback_Receiver()\n",
      "      (6): SYNAPSE_FC(in_features=200, out_features=200, TIME=10, bias=True, sstep=True)\n",
      "      (7): LIF_layer(v_init=0, v_decay=0.5, v_threshold=0.25, v_reset=10000, sg_width=3, surrogate=hard_sigmoid, BPTT_on=False, trace_const1=1, trace_const2=0.5, TIME=10, sstep=True, trace_on=True)\n",
      "      (8): Feedback_Receiver()\n",
      "      (9): SYNAPSE_FC(in_features=200, out_features=10, TIME=10, bias=True, sstep=True)\n",
      "      (DFA_top): Top_Gradient()\n",
      "    )\n",
      "  )\n",
      ")\n",
      "\n",
      "========================================================\n",
      "Trainable parameters: 452,010\n",
      "========================================================\n",
      "\n",
      "epoch-0   lr=['0.0100000'], tr/val_loss:  3.322553/  8.577528, val:  34.58%, val_best:  34.58%, tr:  33.50%, tr_best:  33.50%\n",
      "[module.layers.5] weight_fb parameter count: 2,000\n",
      "[module.layers.8] weight_fb parameter count: 2,000\n",
      "epoch-1   lr=['0.0100000'], tr/val_loss:  5.177886/  5.730683, val:  38.75%, val_best:  38.75%, tr:  45.05%, tr_best:  45.05%\n",
      "epoch-2   lr=['0.0100000'], tr/val_loss:  4.499192/  6.939820, val:  39.17%, val_best:  39.17%, tr:  53.12%, tr_best:  53.12%\n",
      "epoch-3   lr=['0.0100000'], tr/val_loss:  3.264489/  5.608757, val:  43.33%, val_best:  43.33%, tr:  65.37%, tr_best:  65.37%\n",
      "epoch-4   lr=['0.0100000'], tr/val_loss:  3.768093/  4.031138, val:  62.92%, val_best:  62.92%, tr:  60.16%, tr_best:  65.37%\n",
      "epoch-5   lr=['0.0100000'], tr/val_loss:  2.798225/  5.504390, val:  45.83%, val_best:  62.92%, tr:  68.34%, tr_best:  68.34%\n",
      "epoch-6   lr=['0.0100000'], tr/val_loss:  1.822749/  3.228490, val:  67.08%, val_best:  67.08%, tr:  75.79%, tr_best:  75.79%\n",
      "epoch-7   lr=['0.0100000'], tr/val_loss:  1.512303/  5.735887, val:  52.50%, val_best:  67.08%, tr:  81.92%, tr_best:  81.92%\n",
      "epoch-8   lr=['0.0100000'], tr/val_loss:  1.556265/  3.709625, val:  60.42%, val_best:  67.08%, tr:  83.15%, tr_best:  83.15%\n",
      "epoch-9   lr=['0.0100000'], tr/val_loss:  1.860137/  5.318491, val:  63.75%, val_best:  67.08%, tr:  85.29%, tr_best:  85.29%\n",
      "epoch-10  lr=['0.0100000'], tr/val_loss:  1.168196/  5.305608, val:  60.00%, val_best:  67.08%, tr:  91.22%, tr_best:  91.22%\n",
      "epoch-11  lr=['0.0100000'], tr/val_loss:  0.858445/  4.793728, val:  68.75%, val_best:  68.75%, tr:  95.40%, tr_best:  95.40%\n",
      "epoch-12  lr=['0.0100000'], tr/val_loss:  0.837653/  4.724738, val:  75.00%, val_best:  75.00%, tr:  96.02%, tr_best:  96.02%\n",
      "epoch-13  lr=['0.0100000'], tr/val_loss:  0.611503/  4.888059, val:  72.08%, val_best:  75.00%, tr:  97.24%, tr_best:  97.24%\n",
      "epoch-14  lr=['0.0100000'], tr/val_loss:  0.400438/  4.839664, val:  76.67%, val_best:  76.67%, tr:  99.18%, tr_best:  99.18%\n",
      "epoch-15  lr=['0.0100000'], tr/val_loss:  0.285062/  4.950146, val:  72.08%, val_best:  76.67%, tr:  99.69%, tr_best:  99.69%\n",
      "epoch-16  lr=['0.0100000'], tr/val_loss:  0.183917/  5.200136, val:  71.67%, val_best:  76.67%, tr:  99.80%, tr_best:  99.80%\n",
      "epoch-17  lr=['0.0100000'], tr/val_loss:  0.180904/  5.330546, val:  72.08%, val_best:  76.67%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-18  lr=['0.0100000'], tr/val_loss:  0.175229/  5.275696, val:  76.25%, val_best:  76.67%, tr:  99.69%, tr_best: 100.00%\n",
      "epoch-19  lr=['0.0100000'], tr/val_loss:  0.111557/  5.709902, val:  73.75%, val_best:  76.67%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-20  lr=['0.0100000'], tr/val_loss:  0.098633/  5.641996, val:  75.83%, val_best:  76.67%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-21  lr=['0.0100000'], tr/val_loss:  0.064537/  5.629169, val:  76.25%, val_best:  76.67%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-22  lr=['0.0100000'], tr/val_loss:  0.068177/  6.058958, val:  71.67%, val_best:  76.67%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-23  lr=['0.0100000'], tr/val_loss:  0.071927/  5.713663, val:  75.42%, val_best:  76.67%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-24  lr=['0.0100000'], tr/val_loss:  0.031216/  5.854831, val:  77.08%, val_best:  77.08%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-25  lr=['0.0100000'], tr/val_loss:  0.028781/  5.939518, val:  75.83%, val_best:  77.08%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-26  lr=['0.0100000'], tr/val_loss:  0.029572/  5.889508, val:  74.17%, val_best:  77.08%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-27  lr=['0.0100000'], tr/val_loss:  0.030830/  5.976600, val:  75.42%, val_best:  77.08%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-28  lr=['0.0100000'], tr/val_loss:  0.022040/  5.877657, val:  75.83%, val_best:  77.08%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-29  lr=['0.0100000'], tr/val_loss:  0.016188/  5.898736, val:  77.08%, val_best:  77.08%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-30  lr=['0.0100000'], tr/val_loss:  0.011574/  6.011859, val:  76.25%, val_best:  77.08%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-31  lr=['0.0100000'], tr/val_loss:  0.013000/  6.014253, val:  76.25%, val_best:  77.08%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-32  lr=['0.0100000'], tr/val_loss:  0.011322/  6.108489, val:  76.67%, val_best:  77.08%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-33  lr=['0.0100000'], tr/val_loss:  0.017925/  6.180267, val:  76.25%, val_best:  77.08%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-34  lr=['0.0100000'], tr/val_loss:  0.011788/  6.178036, val:  75.42%, val_best:  77.08%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-35  lr=['0.0100000'], tr/val_loss:  0.008106/  6.212817, val:  76.25%, val_best:  77.08%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-36  lr=['0.0100000'], tr/val_loss:  0.009304/  6.287269, val:  76.25%, val_best:  77.08%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-37  lr=['0.0100000'], tr/val_loss:  0.009063/  6.174873, val:  77.50%, val_best:  77.50%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-38  lr=['0.0100000'], tr/val_loss:  0.010923/  6.335722, val:  75.00%, val_best:  77.50%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-39  lr=['0.0100000'], tr/val_loss:  0.011211/  6.302885, val:  76.25%, val_best:  77.50%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-40  lr=['0.0100000'], tr/val_loss:  0.012556/  6.191045, val:  75.42%, val_best:  77.50%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-41  lr=['0.0100000'], tr/val_loss:  0.008393/  6.156913, val:  77.08%, val_best:  77.50%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-42  lr=['0.0100000'], tr/val_loss:  0.005791/  6.175547, val:  77.08%, val_best:  77.50%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-43  lr=['0.0100000'], tr/val_loss:  0.007282/  6.363240, val:  76.25%, val_best:  77.50%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-44  lr=['0.0100000'], tr/val_loss:  0.006011/  6.314760, val:  76.25%, val_best:  77.50%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-45  lr=['0.0100000'], tr/val_loss:  0.006644/  6.302071, val:  77.50%, val_best:  77.50%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-46  lr=['0.0100000'], tr/val_loss:  0.005528/  6.394886, val:  77.08%, val_best:  77.50%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-47  lr=['0.0100000'], tr/val_loss:  0.002721/  6.382930, val:  77.08%, val_best:  77.50%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-48  lr=['0.0100000'], tr/val_loss:  0.001812/  6.491182, val:  77.50%, val_best:  77.50%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-49  lr=['0.0100000'], tr/val_loss:  0.001407/  6.440296, val:  77.92%, val_best:  77.92%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-50  lr=['0.0100000'], tr/val_loss:  0.003454/  6.462164, val:  77.50%, val_best:  77.92%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-51  lr=['0.0100000'], tr/val_loss:  0.005058/  6.340250, val:  77.50%, val_best:  77.92%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-52  lr=['0.0100000'], tr/val_loss:  0.002763/  6.387630, val:  76.67%, val_best:  77.92%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-53  lr=['0.0100000'], tr/val_loss:  0.005779/  6.457996, val:  77.50%, val_best:  77.92%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-54  lr=['0.0100000'], tr/val_loss:  0.002407/  6.489297, val:  77.50%, val_best:  77.92%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-55  lr=['0.0100000'], tr/val_loss:  0.002698/  6.500394, val:  77.08%, val_best:  77.92%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-56  lr=['0.0100000'], tr/val_loss:  0.001891/  6.484398, val:  77.50%, val_best:  77.92%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-57  lr=['0.0100000'], tr/val_loss:  0.001992/  6.504050, val:  77.50%, val_best:  77.92%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-58  lr=['0.0100000'], tr/val_loss:  0.000626/  6.556115, val:  76.67%, val_best:  77.92%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-59  lr=['0.0100000'], tr/val_loss:  0.000388/  6.538510, val:  77.50%, val_best:  77.92%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-60  lr=['0.0100000'], tr/val_loss:  0.002325/  6.480374, val:  77.08%, val_best:  77.92%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-61  lr=['0.0100000'], tr/val_loss:  0.002976/  6.382265, val:  79.17%, val_best:  79.17%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-62  lr=['0.0100000'], tr/val_loss:  0.001360/  6.527945, val:  77.92%, val_best:  79.17%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-63  lr=['0.0100000'], tr/val_loss:  0.001490/  6.577329, val:  77.08%, val_best:  79.17%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-64  lr=['0.0100000'], tr/val_loss:  0.002459/  6.560034, val:  76.67%, val_best:  79.17%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-65  lr=['0.0100000'], tr/val_loss:  0.000712/  6.549365, val:  77.08%, val_best:  79.17%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-66  lr=['0.0100000'], tr/val_loss:  0.000594/  6.539944, val:  77.50%, val_best:  79.17%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-67  lr=['0.0100000'], tr/val_loss:  0.001036/  6.555638, val:  76.67%, val_best:  79.17%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-68  lr=['0.0100000'], tr/val_loss:  0.000639/  6.501115, val:  77.08%, val_best:  79.17%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-69  lr=['0.0100000'], tr/val_loss:  0.001247/  6.492835, val:  77.50%, val_best:  79.17%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-70  lr=['0.0100000'], tr/val_loss:  0.001393/  6.527936, val:  76.25%, val_best:  79.17%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-71  lr=['0.0100000'], tr/val_loss:  0.000625/  6.563161, val:  76.67%, val_best:  79.17%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-72  lr=['0.0100000'], tr/val_loss:  0.000342/  6.517229, val:  76.67%, val_best:  79.17%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-73  lr=['0.0100000'], tr/val_loss:  0.000265/  6.554408, val:  76.25%, val_best:  79.17%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-74  lr=['0.0100000'], tr/val_loss:  0.000276/  6.561500, val:  76.67%, val_best:  79.17%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-75  lr=['0.0100000'], tr/val_loss:  0.000160/  6.556433, val:  76.67%, val_best:  79.17%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-76  lr=['0.0100000'], tr/val_loss:  0.000143/  6.570875, val:  76.67%, val_best:  79.17%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-77  lr=['0.0100000'], tr/val_loss:  0.000555/  6.594468, val:  75.83%, val_best:  79.17%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-78  lr=['0.0100000'], tr/val_loss:  0.000395/  6.565596, val:  75.83%, val_best:  79.17%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-79  lr=['0.0100000'], tr/val_loss:  0.000452/  6.617838, val:  76.67%, val_best:  79.17%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-80  lr=['0.0100000'], tr/val_loss:  0.000738/  6.564328, val:  77.08%, val_best:  79.17%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-81  lr=['0.0100000'], tr/val_loss:  0.000699/  6.625285, val:  76.25%, val_best:  79.17%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-82  lr=['0.0100000'], tr/val_loss:  0.000361/  6.589866, val:  77.50%, val_best:  79.17%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-83  lr=['0.0100000'], tr/val_loss:  0.000200/  6.584190, val:  77.08%, val_best:  79.17%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-84  lr=['0.0100000'], tr/val_loss:  0.000329/  6.574418, val:  77.50%, val_best:  79.17%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-85  lr=['0.0100000'], tr/val_loss:  0.000913/  6.661637, val:  76.25%, val_best:  79.17%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-86  lr=['0.0100000'], tr/val_loss:  0.000312/  6.624593, val:  76.25%, val_best:  79.17%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-87  lr=['0.0100000'], tr/val_loss:  0.001646/  6.605638, val:  76.25%, val_best:  79.17%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-88  lr=['0.0100000'], tr/val_loss:  0.001708/  6.539868, val:  77.50%, val_best:  79.17%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-89  lr=['0.0100000'], tr/val_loss:  0.000905/  6.445521, val:  77.08%, val_best:  79.17%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-90  lr=['0.0100000'], tr/val_loss:  0.000840/  6.489533, val:  76.25%, val_best:  79.17%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-91  lr=['0.0100000'], tr/val_loss:  0.000356/  6.488519, val:  77.08%, val_best:  79.17%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-92  lr=['0.0100000'], tr/val_loss:  0.000195/  6.490251, val:  77.08%, val_best:  79.17%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-93  lr=['0.0100000'], tr/val_loss:  0.000267/  6.530156, val:  77.08%, val_best:  79.17%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-94  lr=['0.0100000'], tr/val_loss:  0.000191/  6.541993, val:  77.08%, val_best:  79.17%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-95  lr=['0.0100000'], tr/val_loss:  0.000142/  6.546511, val:  77.92%, val_best:  79.17%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-96  lr=['0.0100000'], tr/val_loss:  0.000115/  6.532880, val:  77.92%, val_best:  79.17%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-97  lr=['0.0100000'], tr/val_loss:  0.000231/  6.534258, val:  77.08%, val_best:  79.17%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-98  lr=['0.0100000'], tr/val_loss:  0.000168/  6.532245, val:  77.92%, val_best:  79.17%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-99  lr=['0.0100000'], tr/val_loss:  0.000238/  6.544792, val:  77.92%, val_best:  79.17%, tr: 100.00%, tr_best: 100.00%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8a846dde0fef46dd98624ab0e689799b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.006 MB of 0.006 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>iter_acc</td><td>▁▃▆▇▆███████████████████████████████████</td></tr><tr><td>summary_val_acc</td><td>▁▂▅▄▆▇█▇▇██▇███████████████████▇████████</td></tr><tr><td>tr_acc</td><td>▁▃▄▆▆███████████████████████████████████</td></tr><tr><td>tr_epoch_loss</td><td>▆█▇▃▄▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_acc_best</td><td>▁▂▅▆▆▇██████████████████████████████████</td></tr><tr><td>val_acc_now</td><td>▁▂▅▄▆▇█▇▇██▇███████████████████▇████████</td></tr><tr><td>val_loss</td><td>█▅▁▄▃▂▂▃▄▃▄▄▄▄▄▄▄▄▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>99</td></tr><tr><td>iter_acc</td><td>1.0</td></tr><tr><td>tr_acc</td><td>1.0</td></tr><tr><td>tr_epoch_loss</td><td>0.00024</td></tr><tr><td>val_acc_best</td><td>0.79167</td></tr><tr><td>val_acc_now</td><td>0.77917</td></tr><tr><td>val_loss</td><td>6.54479</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">frosty-sweep-51</strong> at: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/dgq420x7' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/dgq420x7</a><br/> View project at: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>/data2/bh_wandb/wandb/run-20250430_001340-dgq420x7/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require(\"core\")`! See https://wandb.me/wandb-core for more information."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: dply299m with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBATCH: 16\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBN_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBPTT_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tDFA_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tIMAGE_SIZE: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tOTTT_input_trace_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tTIME: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tUDA_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \talpha_uda: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbias: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcfg: ['M', 'M', 200, 200]\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tchaching_on: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tconvTrue_fcFalse: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdata_path: /data2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tddp_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdenoise_on: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdvs_clipping: 5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdvs_duration: 100000\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepoch_num: 100\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \texclude_class: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \textra_train_dataset: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlast_lif: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.001\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_sg_width: 4\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_decay: 0.5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_init: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_reset: 10000\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_threshold: 0.25\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmerge_polarities: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmy_seed: 42\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnet_print: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_workers: 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer_what: SGD\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tpin_memory: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tpre_trained: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tpre_trained_path: net_save/save_now_net_weights_{unique_name}.pth\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \trate_coding: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tscheduler_name: no\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsingle_step: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsurrogate: hard_sigmoid\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_conv_kernel_size: 3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_conv_padding: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_conv_stride: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_trace_const1: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_trace_const2: 0.5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \ttdBN_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \ttrace_on: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \twhich_data: DVS_GESTURE_TONIC\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.19.10 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.17.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/data2/bh_wandb/wandb/run-20250430_002102-dply299m</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/dply299m' target=\"_blank\">electric-sweep-55</a></strong> to <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/6pj3lh8j' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/6pj3lh8j</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/6pj3lh8j' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/6pj3lh8j</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/dply299m' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/dply299m</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'single_step' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'my_seed' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'TIME' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BATCH' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'IMAGE_SIZE' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'which_data' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'data_path' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'rate_coding' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_init' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_decay' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_threshold' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_reset' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_sg_width' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_conv_kernel_size' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_conv_stride' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_conv_padding' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_trace_const1' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_trace_const2' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'pre_trained' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'convTrue_fcFalse' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'cfg' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'net_print' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'pre_trained_path' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'learning_rate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'epoch_num' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'tdBN_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BN_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'surrogate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BPTT_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'optimizer_what' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'scheduler_name' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'ddp_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'dvs_clipping' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'dvs_duration' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'DFA_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'trace_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'OTTT_input_trace_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'exclude_class' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'merge_polarities' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'denoise_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'extra_train_dataset' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'num_workers' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'chaching_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'pin_memory' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'UDA_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'alpha_uda' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'bias' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'last_lif' was locked by 'sweep' (ignored update).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "param {'devices': '0', 'single_step': True, 'unique_name': 'main', 'my_seed': 42, 'TIME': 10, 'BATCH': 16, 'IMAGE_SIZE': 128, 'which_data': 'DVS_GESTURE_TONIC', 'data_path': '/data2', 'rate_coding': False, 'lif_layer_v_init': 0, 'lif_layer_v_decay': 0.5, 'lif_layer_v_threshold': 0.25, 'lif_layer_v_reset': 10000, 'lif_layer_sg_width': 4, 'synapse_conv_kernel_size': 3, 'synapse_conv_stride': 1, 'synapse_conv_padding': 1, 'synapse_trace_const1': 1, 'synapse_trace_const2': 0.5, 'pre_trained': False, 'convTrue_fcFalse': False, 'cfg': ['M', 'M', 200, 200], 'net_print': True, 'pre_trained_path': 'net_save/save_now_net_weights_{unique_name}.pth', 'learning_rate': 0.001, 'epoch_num': 100, 'tdBN_on': False, 'BN_on': False, 'surrogate': 'hard_sigmoid', 'BPTT_on': False, 'optimizer_what': 'SGD', 'scheduler_name': 'no', 'ddp_on': False, 'dvs_clipping': 5, 'dvs_duration': 100000, 'DFA_on': False, 'trace_on': True, 'OTTT_input_trace_on': False, 'exclude_class': True, 'merge_polarities': False, 'denoise_on': True, 'extra_train_dataset': 0, 'num_workers': 2, 'chaching_on': True, 'pin_memory': True, 'UDA_on': False, 'alpha_uda': 1, 'bias': True, 'last_lif': False, 'current epoch': 0} \n",
      "\n",
      "dataset_hash = 63cc597115630ec173f3099200061e53\n",
      "cache path exists\n",
      "\n",
      "device ==> cuda\n",
      "\n",
      "DataParallel(\n",
      "  (module): REBORN_MY_SNN_FC(\n",
      "    (layers): REBORN_MY_Sequential(\n",
      "      (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (2): DimChanger_for_FC()\n",
      "      (3): SYNAPSE_FC(in_features=2048, out_features=200, TIME=10, bias=True, sstep=True)\n",
      "      (4): LIF_layer(v_init=0, v_decay=0.5, v_threshold=0.25, v_reset=10000, sg_width=4, surrogate=hard_sigmoid, BPTT_on=False, trace_const1=1, trace_const2=0.5, TIME=10, sstep=True, trace_on=True)\n",
      "      (5): SYNAPSE_FC(in_features=200, out_features=200, TIME=10, bias=True, sstep=True)\n",
      "      (6): LIF_layer(v_init=0, v_decay=0.5, v_threshold=0.25, v_reset=10000, sg_width=4, surrogate=hard_sigmoid, BPTT_on=False, trace_const1=1, trace_const2=0.5, TIME=10, sstep=True, trace_on=True)\n",
      "      (7): SYNAPSE_FC(in_features=200, out_features=10, TIME=10, bias=True, sstep=True)\n",
      "    )\n",
      "  )\n",
      ")\n",
      "\n",
      "========================================================\n",
      "Trainable parameters: 452,010\n",
      "========================================================\n",
      "\n",
      "epoch-0   lr=['0.0010000'], tr/val_loss:  2.164254/  1.881572, val:  43.75%, val_best:  43.75%, tr:  20.94%, tr_best:  20.94%\n",
      "epoch-1   lr=['0.0010000'], tr/val_loss:  1.572132/  1.582594, val:  53.75%, val_best:  53.75%, tr:  52.60%, tr_best:  52.60%\n",
      "epoch-2   lr=['0.0010000'], tr/val_loss:  1.347396/  1.507092, val:  56.67%, val_best:  56.67%, tr:  60.88%, tr_best:  60.88%\n",
      "epoch-3   lr=['0.0010000'], tr/val_loss:  1.190322/  1.532652, val:  61.25%, val_best:  61.25%, tr:  66.39%, tr_best:  66.39%\n",
      "epoch-4   lr=['0.0010000'], tr/val_loss:  1.092968/  1.451989, val:  59.58%, val_best:  61.25%, tr:  68.54%, tr_best:  68.54%\n",
      "epoch-5   lr=['0.0010000'], tr/val_loss:  1.051223/  1.408156, val:  62.08%, val_best:  62.08%, tr:  67.62%, tr_best:  68.54%\n",
      "epoch-6   lr=['0.0010000'], tr/val_loss:  0.973416/  1.394901, val:  62.08%, val_best:  62.08%, tr:  72.93%, tr_best:  72.93%\n",
      "epoch-7   lr=['0.0010000'], tr/val_loss:  0.921592/  1.395308, val:  61.67%, val_best:  62.08%, tr:  72.52%, tr_best:  72.93%\n",
      "epoch-8   lr=['0.0010000'], tr/val_loss:  0.901251/  1.429903, val:  62.92%, val_best:  62.92%, tr:  73.85%, tr_best:  73.85%\n",
      "epoch-9   lr=['0.0010000'], tr/val_loss:  0.838430/  1.453933, val:  67.08%, val_best:  67.08%, tr:  79.16%, tr_best:  79.16%\n",
      "epoch-10  lr=['0.0010000'], tr/val_loss:  0.819875/  1.502387, val:  61.25%, val_best:  67.08%, tr:  78.96%, tr_best:  79.16%\n",
      "epoch-11  lr=['0.0010000'], tr/val_loss:  0.758437/  1.447342, val:  69.17%, val_best:  69.17%, tr:  80.80%, tr_best:  80.80%\n",
      "epoch-12  lr=['0.0010000'], tr/val_loss:  0.764908/  1.408789, val:  72.50%, val_best:  72.50%, tr:  82.02%, tr_best:  82.02%\n",
      "epoch-13  lr=['0.0010000'], tr/val_loss:  0.735833/  1.550779, val:  64.58%, val_best:  72.50%, tr:  82.84%, tr_best:  82.84%\n",
      "epoch-14  lr=['0.0010000'], tr/val_loss:  0.671112/  2.001131, val:  66.25%, val_best:  72.50%, tr:  84.78%, tr_best:  84.78%\n",
      "epoch-15  lr=['0.0010000'], tr/val_loss:  0.681351/  1.735797, val:  66.67%, val_best:  72.50%, tr:  86.62%, tr_best:  86.62%\n",
      "epoch-16  lr=['0.0010000'], tr/val_loss:  0.610220/  1.719126, val:  72.92%, val_best:  72.92%, tr:  88.25%, tr_best:  88.25%\n",
      "epoch-17  lr=['0.0010000'], tr/val_loss:  0.610776/  1.727584, val:  72.50%, val_best:  72.92%, tr:  91.42%, tr_best:  91.42%\n",
      "epoch-18  lr=['0.0010000'], tr/val_loss:  0.570156/  1.897646, val:  65.00%, val_best:  72.92%, tr:  89.27%, tr_best:  91.42%\n",
      "epoch-19  lr=['0.0010000'], tr/val_loss:  0.585257/  1.967770, val:  65.42%, val_best:  72.92%, tr:  89.68%, tr_best:  91.42%\n",
      "epoch-20  lr=['0.0010000'], tr/val_loss:  0.543774/  2.114332, val:  63.75%, val_best:  72.92%, tr:  90.19%, tr_best:  91.42%\n",
      "epoch-21  lr=['0.0010000'], tr/val_loss:  0.497773/  2.095830, val:  64.58%, val_best:  72.92%, tr:  92.75%, tr_best:  92.75%\n",
      "epoch-22  lr=['0.0010000'], tr/val_loss:  0.473226/  2.228009, val:  71.67%, val_best:  72.92%, tr:  96.22%, tr_best:  96.22%\n",
      "epoch-23  lr=['0.0010000'], tr/val_loss:  0.520640/  2.183795, val:  70.83%, val_best:  72.92%, tr:  92.65%, tr_best:  96.22%\n",
      "epoch-24  lr=['0.0010000'], tr/val_loss:  0.405546/  2.347922, val:  70.00%, val_best:  72.92%, tr:  97.75%, tr_best:  97.75%\n",
      "epoch-25  lr=['0.0010000'], tr/val_loss:  0.395665/  2.146263, val:  72.50%, val_best:  72.92%, tr:  97.04%, tr_best:  97.75%\n",
      "epoch-26  lr=['0.0010000'], tr/val_loss:  0.391565/  2.272421, val:  71.25%, val_best:  72.92%, tr:  94.89%, tr_best:  97.75%\n",
      "epoch-27  lr=['0.0010000'], tr/val_loss:  0.364384/  2.395199, val:  74.17%, val_best:  74.17%, tr:  97.24%, tr_best:  97.75%\n",
      "epoch-28  lr=['0.0010000'], tr/val_loss:  0.314484/  2.296829, val:  78.33%, val_best:  78.33%, tr:  99.18%, tr_best:  99.18%\n",
      "epoch-29  lr=['0.0010000'], tr/val_loss:  0.291113/  2.429488, val:  68.75%, val_best:  78.33%, tr:  98.57%, tr_best:  99.18%\n",
      "epoch-30  lr=['0.0010000'], tr/val_loss:  0.267170/  2.329857, val:  77.08%, val_best:  78.33%, tr:  99.59%, tr_best:  99.59%\n",
      "epoch-31  lr=['0.0010000'], tr/val_loss:  0.246449/  2.525942, val:  75.00%, val_best:  78.33%, tr:  99.49%, tr_best:  99.59%\n",
      "epoch-32  lr=['0.0010000'], tr/val_loss:  0.297392/  2.569614, val:  77.08%, val_best:  78.33%, tr:  97.96%, tr_best:  99.59%\n",
      "epoch-33  lr=['0.0010000'], tr/val_loss:  0.275306/  2.703457, val:  72.08%, val_best:  78.33%, tr:  98.98%, tr_best:  99.59%\n",
      "epoch-34  lr=['0.0010000'], tr/val_loss:  0.271238/  2.667736, val:  77.92%, val_best:  78.33%, tr:  99.18%, tr_best:  99.59%\n",
      "epoch-35  lr=['0.0010000'], tr/val_loss:  0.242063/  2.696270, val:  75.00%, val_best:  78.33%, tr:  99.59%, tr_best:  99.59%\n",
      "epoch-36  lr=['0.0010000'], tr/val_loss:  0.215908/  2.592994, val:  77.08%, val_best:  78.33%, tr:  99.28%, tr_best:  99.59%\n",
      "epoch-37  lr=['0.0010000'], tr/val_loss:  0.200776/  2.823532, val:  75.00%, val_best:  78.33%, tr:  99.59%, tr_best:  99.59%\n",
      "epoch-38  lr=['0.0010000'], tr/val_loss:  0.225973/  2.888938, val:  75.00%, val_best:  78.33%, tr:  99.28%, tr_best:  99.59%\n",
      "epoch-39  lr=['0.0010000'], tr/val_loss:  0.207732/  2.815949, val:  72.50%, val_best:  78.33%, tr:  99.59%, tr_best:  99.59%\n",
      "epoch-40  lr=['0.0010000'], tr/val_loss:  0.189603/  2.770019, val:  77.08%, val_best:  78.33%, tr:  99.59%, tr_best:  99.59%\n",
      "epoch-41  lr=['0.0010000'], tr/val_loss:  0.151833/  2.954795, val:  73.75%, val_best:  78.33%, tr:  99.90%, tr_best:  99.90%\n",
      "epoch-42  lr=['0.0010000'], tr/val_loss:  0.152325/  2.875993, val:  78.33%, val_best:  78.33%, tr:  99.90%, tr_best:  99.90%\n",
      "epoch-43  lr=['0.0010000'], tr/val_loss:  0.148291/  2.894507, val:  76.67%, val_best:  78.33%, tr:  99.69%, tr_best:  99.90%\n",
      "epoch-44  lr=['0.0010000'], tr/val_loss:  0.161145/  2.927175, val:  74.58%, val_best:  78.33%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-45  lr=['0.0010000'], tr/val_loss:  0.124814/  2.914339, val:  77.08%, val_best:  78.33%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-46  lr=['0.0010000'], tr/val_loss:  0.117446/  3.031982, val:  78.33%, val_best:  78.33%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-47  lr=['0.0010000'], tr/val_loss:  0.096443/  3.032544, val:  77.92%, val_best:  78.33%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-48  lr=['0.0010000'], tr/val_loss:  0.122761/  3.047483, val:  77.08%, val_best:  78.33%, tr:  99.90%, tr_best: 100.00%\n",
      "epoch-49  lr=['0.0010000'], tr/val_loss:  0.095057/  3.150702, val:  76.25%, val_best:  78.33%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-50  lr=['0.0010000'], tr/val_loss:  0.079215/  3.183381, val:  74.58%, val_best:  78.33%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-51  lr=['0.0010000'], tr/val_loss:  0.070842/  3.127496, val:  75.83%, val_best:  78.33%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-52  lr=['0.0010000'], tr/val_loss:  0.063629/  3.146680, val:  77.50%, val_best:  78.33%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-53  lr=['0.0010000'], tr/val_loss:  0.053078/  3.230726, val:  77.08%, val_best:  78.33%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-54  lr=['0.0010000'], tr/val_loss:  0.066623/  3.196583, val:  78.75%, val_best:  78.75%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-55  lr=['0.0010000'], tr/val_loss:  0.081152/  3.176146, val:  77.50%, val_best:  78.75%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-56  lr=['0.0010000'], tr/val_loss:  0.054702/  3.316847, val:  77.50%, val_best:  78.75%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-57  lr=['0.0010000'], tr/val_loss:  0.046984/  3.340497, val:  76.67%, val_best:  78.75%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-58  lr=['0.0010000'], tr/val_loss:  0.062090/  3.406007, val:  74.58%, val_best:  78.75%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-59  lr=['0.0010000'], tr/val_loss:  0.053403/  3.365840, val:  76.25%, val_best:  78.75%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-60  lr=['0.0010000'], tr/val_loss:  0.051209/  3.365025, val:  77.08%, val_best:  78.75%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-61  lr=['0.0010000'], tr/val_loss:  0.042376/  3.393118, val:  78.33%, val_best:  78.75%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-62  lr=['0.0010000'], tr/val_loss:  0.047598/  3.451738, val:  76.25%, val_best:  78.75%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-63  lr=['0.0010000'], tr/val_loss:  0.034706/  3.426058, val:  80.83%, val_best:  80.83%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-64  lr=['0.0010000'], tr/val_loss:  0.042353/  3.515798, val:  80.00%, val_best:  80.83%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-65  lr=['0.0010000'], tr/val_loss:  0.038381/  3.480400, val:  79.58%, val_best:  80.83%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-66  lr=['0.0010000'], tr/val_loss:  0.053799/  3.494805, val:  78.33%, val_best:  80.83%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-67  lr=['0.0010000'], tr/val_loss:  0.048406/  3.544201, val:  78.33%, val_best:  80.83%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-68  lr=['0.0010000'], tr/val_loss:  0.040652/  3.477998, val:  78.75%, val_best:  80.83%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-69  lr=['0.0010000'], tr/val_loss:  0.035946/  3.549484, val:  75.83%, val_best:  80.83%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-70  lr=['0.0010000'], tr/val_loss:  0.036018/  3.599669, val:  77.50%, val_best:  80.83%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-71  lr=['0.0010000'], tr/val_loss:  0.039623/  3.613070, val:  76.25%, val_best:  80.83%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-72  lr=['0.0010000'], tr/val_loss:  0.032946/  3.636997, val:  75.00%, val_best:  80.83%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-73  lr=['0.0010000'], tr/val_loss:  0.031394/  3.688902, val:  73.75%, val_best:  80.83%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-74  lr=['0.0010000'], tr/val_loss:  0.030740/  3.652630, val:  78.33%, val_best:  80.83%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-75  lr=['0.0010000'], tr/val_loss:  0.027094/  3.663834, val:  77.08%, val_best:  80.83%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-76  lr=['0.0010000'], tr/val_loss:  0.024684/  3.664117, val:  78.33%, val_best:  80.83%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-77  lr=['0.0010000'], tr/val_loss:  0.022432/  3.657311, val:  78.33%, val_best:  80.83%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-78  lr=['0.0010000'], tr/val_loss:  0.022451/  3.740630, val:  77.92%, val_best:  80.83%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-79  lr=['0.0010000'], tr/val_loss:  0.028406/  3.772657, val:  78.33%, val_best:  80.83%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-80  lr=['0.0010000'], tr/val_loss:  0.028602/  3.716725, val:  74.17%, val_best:  80.83%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-81  lr=['0.0010000'], tr/val_loss:  0.025709/  3.765512, val:  76.25%, val_best:  80.83%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-82  lr=['0.0010000'], tr/val_loss:  0.024872/  3.704340, val:  75.83%, val_best:  80.83%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-83  lr=['0.0010000'], tr/val_loss:  0.023042/  3.774400, val:  76.25%, val_best:  80.83%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-84  lr=['0.0010000'], tr/val_loss:  0.018990/  3.746314, val:  77.92%, val_best:  80.83%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-85  lr=['0.0010000'], tr/val_loss:  0.024938/  3.754841, val:  77.92%, val_best:  80.83%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-86  lr=['0.0010000'], tr/val_loss:  0.028945/  3.749681, val:  74.58%, val_best:  80.83%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-87  lr=['0.0010000'], tr/val_loss:  0.022921/  3.748333, val:  78.75%, val_best:  80.83%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-88  lr=['0.0010000'], tr/val_loss:  0.026076/  3.785172, val:  75.42%, val_best:  80.83%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-89  lr=['0.0010000'], tr/val_loss:  0.022111/  3.796511, val:  75.83%, val_best:  80.83%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-90  lr=['0.0010000'], tr/val_loss:  0.022520/  3.804049, val:  76.25%, val_best:  80.83%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-91  lr=['0.0010000'], tr/val_loss:  0.022204/  3.853449, val:  75.00%, val_best:  80.83%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-92  lr=['0.0010000'], tr/val_loss:  0.019498/  3.831636, val:  76.25%, val_best:  80.83%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-93  lr=['0.0010000'], tr/val_loss:  0.018111/  3.781665, val:  75.83%, val_best:  80.83%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-94  lr=['0.0010000'], tr/val_loss:  0.016070/  3.818634, val:  74.17%, val_best:  80.83%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-95  lr=['0.0010000'], tr/val_loss:  0.011878/  3.862886, val:  77.08%, val_best:  80.83%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-96  lr=['0.0010000'], tr/val_loss:  0.011420/  3.913617, val:  73.75%, val_best:  80.83%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-97  lr=['0.0010000'], tr/val_loss:  0.014510/  3.882720, val:  77.92%, val_best:  80.83%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-98  lr=['0.0010000'], tr/val_loss:  0.010371/  3.858529, val:  75.42%, val_best:  80.83%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-99  lr=['0.0010000'], tr/val_loss:  0.010930/  3.968211, val:  74.17%, val_best:  80.83%, tr: 100.00%, tr_best: 100.00%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bb519174d3c54654bf66279913afdde2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.006 MB of 0.006 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>iter_acc</td><td>▁▆▄▃▄▅▇▁████▇███████████████████████████</td></tr><tr><td>summary_val_acc</td><td>▁▄▄▅▆▇▅▇▅▅▆▆▆█▇▇▇█▇█▇██▇▇████▇███▇██▇▇██</td></tr><tr><td>tr_acc</td><td>▁▅▅▆▆▆▇▇▇▇██████████████████████████████</td></tr><tr><td>tr_epoch_loss</td><td>█▅▅▄▄▃▃▃▃▃▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_acc_best</td><td>▁▃▄▄▅▆▆▇▇▇▇▇████████████████████████████</td></tr><tr><td>val_acc_now</td><td>▁▄▄▅▆▇▅▇▅▅▆▆▆█▇▇▇█▇█▇██▇▇████▇███▇██▇▇██</td></tr><tr><td>val_loss</td><td>▂▁▁▁▁▁▃▂▃▃▄▃▄▄▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇▇▇█▇██████</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>99</td></tr><tr><td>iter_acc</td><td>1.0</td></tr><tr><td>tr_acc</td><td>1.0</td></tr><tr><td>tr_epoch_loss</td><td>0.01093</td></tr><tr><td>val_acc_best</td><td>0.80833</td></tr><tr><td>val_acc_now</td><td>0.74167</td></tr><tr><td>val_loss</td><td>3.96821</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">electric-sweep-55</strong> at: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/dply299m' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/dply299m</a><br/> View project at: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>/data2/bh_wandb/wandb/run-20250430_002102-dply299m/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require(\"core\")`! See https://wandb.me/wandb-core for more information."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 831gwx1a with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBATCH: 16\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBN_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBPTT_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tDFA_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tIMAGE_SIZE: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tOTTT_input_trace_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tTIME: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tUDA_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \talpha_uda: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbias: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcfg: ['M', 'M', 200, 200]\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tchaching_on: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tconvTrue_fcFalse: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdata_path: /data2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tddp_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdenoise_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdvs_clipping: 5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdvs_duration: 100000\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepoch_num: 100\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \texclude_class: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \textra_train_dataset: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlast_lif: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.001\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_sg_width: 5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_decay: 0.5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_init: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_reset: 10000\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_threshold: 0.25\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmerge_polarities: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmy_seed: 42\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnet_print: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_workers: 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer_what: SGD\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tpin_memory: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tpre_trained: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tpre_trained_path: net_save/save_now_net_weights_{unique_name}.pth\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \trate_coding: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tscheduler_name: no\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsingle_step: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsurrogate: hard_sigmoid\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_conv_kernel_size: 3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_conv_padding: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_conv_stride: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_trace_const1: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_trace_const2: 0.5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \ttdBN_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \ttrace_on: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \twhich_data: DVS_GESTURE_TONIC\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.19.10 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.17.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/data2/bh_wandb/wandb/run-20250430_002725-831gwx1a</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/831gwx1a' target=\"_blank\">confused-sweep-59</a></strong> to <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/6pj3lh8j' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/6pj3lh8j</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/6pj3lh8j' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/6pj3lh8j</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/831gwx1a' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/831gwx1a</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'single_step' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'my_seed' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'TIME' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BATCH' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'IMAGE_SIZE' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'which_data' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'data_path' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'rate_coding' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_init' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_decay' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_threshold' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_reset' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_sg_width' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_conv_kernel_size' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_conv_stride' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_conv_padding' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_trace_const1' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_trace_const2' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'pre_trained' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'convTrue_fcFalse' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'cfg' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'net_print' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'pre_trained_path' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'learning_rate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'epoch_num' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'tdBN_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BN_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'surrogate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BPTT_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'optimizer_what' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'scheduler_name' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'ddp_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'dvs_clipping' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'dvs_duration' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'DFA_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'trace_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'OTTT_input_trace_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'exclude_class' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'merge_polarities' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'denoise_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'extra_train_dataset' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'num_workers' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'chaching_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'pin_memory' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'UDA_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'alpha_uda' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'bias' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'last_lif' was locked by 'sweep' (ignored update).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "param {'devices': '0', 'single_step': True, 'unique_name': 'main', 'my_seed': 42, 'TIME': 10, 'BATCH': 16, 'IMAGE_SIZE': 128, 'which_data': 'DVS_GESTURE_TONIC', 'data_path': '/data2', 'rate_coding': False, 'lif_layer_v_init': 0, 'lif_layer_v_decay': 0.5, 'lif_layer_v_threshold': 0.25, 'lif_layer_v_reset': 10000, 'lif_layer_sg_width': 5, 'synapse_conv_kernel_size': 3, 'synapse_conv_stride': 1, 'synapse_conv_padding': 1, 'synapse_trace_const1': 1, 'synapse_trace_const2': 0.5, 'pre_trained': False, 'convTrue_fcFalse': False, 'cfg': ['M', 'M', 200, 200], 'net_print': True, 'pre_trained_path': 'net_save/save_now_net_weights_{unique_name}.pth', 'learning_rate': 0.001, 'epoch_num': 100, 'tdBN_on': False, 'BN_on': False, 'surrogate': 'hard_sigmoid', 'BPTT_on': False, 'optimizer_what': 'SGD', 'scheduler_name': 'no', 'ddp_on': False, 'dvs_clipping': 5, 'dvs_duration': 100000, 'DFA_on': False, 'trace_on': True, 'OTTT_input_trace_on': False, 'exclude_class': True, 'merge_polarities': False, 'denoise_on': False, 'extra_train_dataset': 0, 'num_workers': 2, 'chaching_on': True, 'pin_memory': True, 'UDA_on': False, 'alpha_uda': 1, 'bias': True, 'last_lif': False, 'current epoch': 0} \n",
      "\n",
      "dataset_hash = ffa516e60c3efd5e0208f72b4c36cb84\n",
      "cache path exists\n",
      "\n",
      "device ==> cuda\n",
      "\n",
      "DataParallel(\n",
      "  (module): REBORN_MY_SNN_FC(\n",
      "    (layers): REBORN_MY_Sequential(\n",
      "      (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (2): DimChanger_for_FC()\n",
      "      (3): SYNAPSE_FC(in_features=2048, out_features=200, TIME=10, bias=True, sstep=True)\n",
      "      (4): LIF_layer(v_init=0, v_decay=0.5, v_threshold=0.25, v_reset=10000, sg_width=5, surrogate=hard_sigmoid, BPTT_on=False, trace_const1=1, trace_const2=0.5, TIME=10, sstep=True, trace_on=True)\n",
      "      (5): SYNAPSE_FC(in_features=200, out_features=200, TIME=10, bias=True, sstep=True)\n",
      "      (6): LIF_layer(v_init=0, v_decay=0.5, v_threshold=0.25, v_reset=10000, sg_width=5, surrogate=hard_sigmoid, BPTT_on=False, trace_const1=1, trace_const2=0.5, TIME=10, sstep=True, trace_on=True)\n",
      "      (7): SYNAPSE_FC(in_features=200, out_features=10, TIME=10, bias=True, sstep=True)\n",
      "    )\n",
      "  )\n",
      ")\n",
      "\n",
      "========================================================\n",
      "Trainable parameters: 452,010\n",
      "========================================================\n",
      "\n",
      "epoch-0   lr=['0.0010000'], tr/val_loss:  2.008364/  1.608458, val:  52.50%, val_best:  52.50%, tr:  30.03%, tr_best:  30.03%\n",
      "epoch-1   lr=['0.0010000'], tr/val_loss:  1.374709/  1.471918, val:  55.42%, val_best:  55.42%, tr:  57.81%, tr_best:  57.81%\n",
      "epoch-2   lr=['0.0010000'], tr/val_loss:  1.204977/  1.388918, val:  59.58%, val_best:  59.58%, tr:  62.21%, tr_best:  62.21%\n",
      "epoch-3   lr=['0.0010000'], tr/val_loss:  1.032300/  1.526812, val:  57.08%, val_best:  59.58%, tr:  67.62%, tr_best:  67.62%\n",
      "epoch-4   lr=['0.0010000'], tr/val_loss:  0.945360/  1.497551, val:  62.08%, val_best:  62.08%, tr:  70.38%, tr_best:  70.38%\n",
      "epoch-5   lr=['0.0010000'], tr/val_loss:  0.886835/  1.445980, val:  66.25%, val_best:  66.25%, tr:  72.93%, tr_best:  72.93%\n",
      "epoch-6   lr=['0.0010000'], tr/val_loss:  0.808012/  1.410287, val:  60.00%, val_best:  66.25%, tr:  78.35%, tr_best:  78.35%\n",
      "epoch-7   lr=['0.0010000'], tr/val_loss:  0.739172/  1.506575, val:  65.00%, val_best:  66.25%, tr:  77.22%, tr_best:  78.35%\n",
      "epoch-8   lr=['0.0010000'], tr/val_loss:  0.680080/  1.573759, val:  65.42%, val_best:  66.25%, tr:  80.18%, tr_best:  80.18%\n",
      "epoch-9   lr=['0.0010000'], tr/val_loss:  0.617143/  1.691453, val:  65.42%, val_best:  66.25%, tr:  86.82%, tr_best:  86.82%\n",
      "epoch-10  lr=['0.0010000'], tr/val_loss:  0.581684/  1.698720, val:  69.58%, val_best:  69.58%, tr:  87.74%, tr_best:  87.74%\n",
      "epoch-11  lr=['0.0010000'], tr/val_loss:  0.500964/  1.746773, val:  73.33%, val_best:  73.33%, tr:  90.09%, tr_best:  90.09%\n",
      "epoch-12  lr=['0.0010000'], tr/val_loss:  0.452154/  1.805467, val:  69.58%, val_best:  73.33%, tr:  93.56%, tr_best:  93.56%\n",
      "epoch-13  lr=['0.0010000'], tr/val_loss:  0.409395/  1.889858, val:  72.50%, val_best:  73.33%, tr:  93.87%, tr_best:  93.87%\n",
      "epoch-14  lr=['0.0010000'], tr/val_loss:  0.332563/  2.229170, val:  71.25%, val_best:  73.33%, tr:  94.99%, tr_best:  94.99%\n",
      "epoch-15  lr=['0.0010000'], tr/val_loss:  0.305346/  2.169692, val:  70.83%, val_best:  73.33%, tr:  97.96%, tr_best:  97.96%\n",
      "epoch-16  lr=['0.0010000'], tr/val_loss:  0.255759/  2.350931, val:  68.75%, val_best:  73.33%, tr:  98.67%, tr_best:  98.67%\n",
      "epoch-17  lr=['0.0010000'], tr/val_loss:  0.251347/  2.197459, val:  76.25%, val_best:  76.25%, tr:  99.08%, tr_best:  99.08%\n",
      "epoch-18  lr=['0.0010000'], tr/val_loss:  0.197419/  2.270770, val:  74.58%, val_best:  76.25%, tr:  98.67%, tr_best:  99.08%\n",
      "epoch-19  lr=['0.0010000'], tr/val_loss:  0.168556/  2.449761, val:  74.17%, val_best:  76.25%, tr:  99.90%, tr_best:  99.90%\n",
      "epoch-20  lr=['0.0010000'], tr/val_loss:  0.168059/  2.695299, val:  71.25%, val_best:  76.25%, tr:  99.59%, tr_best:  99.90%\n",
      "epoch-21  lr=['0.0010000'], tr/val_loss:  0.160893/  2.666319, val:  68.75%, val_best:  76.25%, tr:  99.69%, tr_best:  99.90%\n",
      "epoch-22  lr=['0.0010000'], tr/val_loss:  0.108310/  2.604903, val:  76.25%, val_best:  76.25%, tr:  99.90%, tr_best:  99.90%\n",
      "epoch-23  lr=['0.0010000'], tr/val_loss:  0.120111/  2.601001, val:  76.67%, val_best:  76.67%, tr:  99.28%, tr_best:  99.90%\n",
      "epoch-24  lr=['0.0010000'], tr/val_loss:  0.079443/  2.708733, val:  76.25%, val_best:  76.67%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-25  lr=['0.0010000'], tr/val_loss:  0.049571/  2.737780, val:  76.25%, val_best:  76.67%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-26  lr=['0.0010000'], tr/val_loss:  0.039638/  2.697255, val:  77.50%, val_best:  77.50%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-27  lr=['0.0010000'], tr/val_loss:  0.039905/  2.875513, val:  77.08%, val_best:  77.50%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-28  lr=['0.0010000'], tr/val_loss:  0.023695/  2.838433, val:  78.33%, val_best:  78.33%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-29  lr=['0.0010000'], tr/val_loss:  0.019868/  2.873804, val:  77.92%, val_best:  78.33%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-30  lr=['0.0010000'], tr/val_loss:  0.016261/  2.880155, val:  80.00%, val_best:  80.00%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-31  lr=['0.0010000'], tr/val_loss:  0.015449/  2.878868, val:  78.75%, val_best:  80.00%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-32  lr=['0.0010000'], tr/val_loss:  0.014415/  2.928833, val:  77.92%, val_best:  80.00%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-33  lr=['0.0010000'], tr/val_loss:  0.012970/  2.938431, val:  78.75%, val_best:  80.00%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-34  lr=['0.0010000'], tr/val_loss:  0.011393/  3.037414, val:  77.08%, val_best:  80.00%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-35  lr=['0.0010000'], tr/val_loss:  0.010638/  3.101221, val:  78.75%, val_best:  80.00%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-36  lr=['0.0010000'], tr/val_loss:  0.009004/  3.039071, val:  78.33%, val_best:  80.00%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-37  lr=['0.0010000'], tr/val_loss:  0.010360/  3.066433, val:  78.75%, val_best:  80.00%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-38  lr=['0.0010000'], tr/val_loss:  0.006780/  3.037152, val:  77.92%, val_best:  80.00%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-39  lr=['0.0010000'], tr/val_loss:  0.006596/  3.068453, val:  79.17%, val_best:  80.00%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-40  lr=['0.0010000'], tr/val_loss:  0.005337/  3.114017, val:  78.75%, val_best:  80.00%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-41  lr=['0.0010000'], tr/val_loss:  0.005951/  3.111064, val:  77.92%, val_best:  80.00%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-42  lr=['0.0010000'], tr/val_loss:  0.004758/  3.167670, val:  77.92%, val_best:  80.00%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-43  lr=['0.0010000'], tr/val_loss:  0.004250/  3.149670, val:  77.92%, val_best:  80.00%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-44  lr=['0.0010000'], tr/val_loss:  0.003208/  3.132931, val:  79.17%, val_best:  80.00%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-45  lr=['0.0010000'], tr/val_loss:  0.003688/  3.185057, val:  77.92%, val_best:  80.00%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-46  lr=['0.0010000'], tr/val_loss:  0.003528/  3.196795, val:  79.58%, val_best:  80.00%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-47  lr=['0.0010000'], tr/val_loss:  0.002923/  3.243393, val:  78.75%, val_best:  80.00%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-48  lr=['0.0010000'], tr/val_loss:  0.002326/  3.195115, val:  78.75%, val_best:  80.00%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-49  lr=['0.0010000'], tr/val_loss:  0.002400/  3.210095, val:  78.33%, val_best:  80.00%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-50  lr=['0.0010000'], tr/val_loss:  0.002603/  3.225904, val:  78.33%, val_best:  80.00%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-51  lr=['0.0010000'], tr/val_loss:  0.002443/  3.197799, val:  79.17%, val_best:  80.00%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-52  lr=['0.0010000'], tr/val_loss:  0.003612/  3.258526, val:  77.50%, val_best:  80.00%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-53  lr=['0.0010000'], tr/val_loss:  0.004137/  3.234734, val:  79.17%, val_best:  80.00%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-54  lr=['0.0010000'], tr/val_loss:  0.003802/  3.217031, val:  78.75%, val_best:  80.00%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-55  lr=['0.0010000'], tr/val_loss:  0.003825/  3.244654, val:  79.17%, val_best:  80.00%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-56  lr=['0.0010000'], tr/val_loss:  0.002428/  3.229712, val:  77.92%, val_best:  80.00%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-57  lr=['0.0010000'], tr/val_loss:  0.002093/  3.278054, val:  77.08%, val_best:  80.00%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-58  lr=['0.0010000'], tr/val_loss:  0.002160/  3.249174, val:  79.58%, val_best:  80.00%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-59  lr=['0.0010000'], tr/val_loss:  0.002025/  3.291715, val:  79.17%, val_best:  80.00%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-60  lr=['0.0010000'], tr/val_loss:  0.001790/  3.254856, val:  78.33%, val_best:  80.00%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-61  lr=['0.0010000'], tr/val_loss:  0.001516/  3.265167, val:  79.17%, val_best:  80.00%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-62  lr=['0.0010000'], tr/val_loss:  0.001461/  3.292719, val:  77.92%, val_best:  80.00%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-63  lr=['0.0010000'], tr/val_loss:  0.001477/  3.300766, val:  77.50%, val_best:  80.00%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-64  lr=['0.0010000'], tr/val_loss:  0.001682/  3.303293, val:  76.67%, val_best:  80.00%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-65  lr=['0.0010000'], tr/val_loss:  0.001970/  3.298305, val:  79.17%, val_best:  80.00%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-66  lr=['0.0010000'], tr/val_loss:  0.001939/  3.326146, val:  78.75%, val_best:  80.00%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-67  lr=['0.0010000'], tr/val_loss:  0.001428/  3.342084, val:  78.33%, val_best:  80.00%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-68  lr=['0.0010000'], tr/val_loss:  0.001377/  3.326409, val:  78.75%, val_best:  80.00%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-69  lr=['0.0010000'], tr/val_loss:  0.001342/  3.364409, val:  78.33%, val_best:  80.00%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-70  lr=['0.0010000'], tr/val_loss:  0.001373/  3.347101, val:  77.50%, val_best:  80.00%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-71  lr=['0.0010000'], tr/val_loss:  0.001265/  3.370033, val:  77.92%, val_best:  80.00%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-72  lr=['0.0010000'], tr/val_loss:  0.001071/  3.368817, val:  77.50%, val_best:  80.00%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-73  lr=['0.0010000'], tr/val_loss:  0.001040/  3.373309, val:  77.92%, val_best:  80.00%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-74  lr=['0.0010000'], tr/val_loss:  0.001253/  3.361948, val:  77.92%, val_best:  80.00%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-75  lr=['0.0010000'], tr/val_loss:  0.001431/  3.365650, val:  77.92%, val_best:  80.00%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-76  lr=['0.0010000'], tr/val_loss:  0.001217/  3.357425, val:  78.33%, val_best:  80.00%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-77  lr=['0.0010000'], tr/val_loss:  0.001101/  3.361525, val:  79.17%, val_best:  80.00%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-78  lr=['0.0010000'], tr/val_loss:  0.000970/  3.381468, val:  79.58%, val_best:  80.00%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-79  lr=['0.0010000'], tr/val_loss:  0.001038/  3.391617, val:  79.17%, val_best:  80.00%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-80  lr=['0.0010000'], tr/val_loss:  0.000997/  3.379458, val:  79.17%, val_best:  80.00%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-81  lr=['0.0010000'], tr/val_loss:  0.000913/  3.366438, val:  79.17%, val_best:  80.00%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-82  lr=['0.0010000'], tr/val_loss:  0.000953/  3.396550, val:  79.17%, val_best:  80.00%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-83  lr=['0.0010000'], tr/val_loss:  0.000921/  3.391519, val:  79.17%, val_best:  80.00%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-84  lr=['0.0010000'], tr/val_loss:  0.000862/  3.413682, val:  78.75%, val_best:  80.00%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-85  lr=['0.0010000'], tr/val_loss:  0.000884/  3.404688, val:  79.58%, val_best:  80.00%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-86  lr=['0.0010000'], tr/val_loss:  0.000955/  3.406603, val:  78.75%, val_best:  80.00%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-87  lr=['0.0010000'], tr/val_loss:  0.000880/  3.401722, val:  78.33%, val_best:  80.00%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-88  lr=['0.0010000'], tr/val_loss:  0.000807/  3.390507, val:  79.17%, val_best:  80.00%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-89  lr=['0.0010000'], tr/val_loss:  0.000954/  3.389870, val:  78.75%, val_best:  80.00%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-90  lr=['0.0010000'], tr/val_loss:  0.002133/  3.431521, val:  78.75%, val_best:  80.00%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-91  lr=['0.0010000'], tr/val_loss:  0.001350/  3.406967, val:  77.50%, val_best:  80.00%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-92  lr=['0.0010000'], tr/val_loss:  0.000966/  3.421370, val:  78.75%, val_best:  80.00%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-93  lr=['0.0010000'], tr/val_loss:  0.001067/  3.415986, val:  78.33%, val_best:  80.00%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-94  lr=['0.0010000'], tr/val_loss:  0.001020/  3.414259, val:  78.33%, val_best:  80.00%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-95  lr=['0.0010000'], tr/val_loss:  0.000902/  3.420812, val:  78.33%, val_best:  80.00%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-96  lr=['0.0010000'], tr/val_loss:  0.000876/  3.418736, val:  78.33%, val_best:  80.00%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-97  lr=['0.0010000'], tr/val_loss:  0.001342/  3.404874, val:  80.42%, val_best:  80.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-98  lr=['0.0010000'], tr/val_loss:  0.001989/  3.444068, val:  78.75%, val_best:  80.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-99  lr=['0.0010000'], tr/val_loss:  0.001697/  3.438380, val:  77.50%, val_best:  80.42%, tr: 100.00%, tr_best: 100.00%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5498ec83dade401cbb9d5e94c6cff750",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.006 MB of 0.006 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>iter_acc</td><td>▁▇▅▅▆▅██████████████████████████████████</td></tr><tr><td>summary_val_acc</td><td>▁▃▃▄▄▅▆▇▆▅▇▇▇▇███▇██▇▇█▇███▇▇▇▇████▇██▇█</td></tr><tr><td>tr_acc</td><td>▁▄▅▆▇▇▇█████████████████████████████████</td></tr><tr><td>tr_epoch_loss</td><td>█▅▄▄▃▃▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_acc_best</td><td>▁▃▃▄▄▆▆▇▇▇▇▇▇███████████████████████████</td></tr><tr><td>val_acc_now</td><td>▁▃▃▄▄▅▆▇▆▅▇▇▇▇███▇██▇▇█▇███▇▇▇▇████▇██▇█</td></tr><tr><td>val_loss</td><td>▂▁▁▁▂▂▄▄▅▅▆▆▆▆▇▇▇▇▇▇▇▇▇██▇██████████████</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>99</td></tr><tr><td>iter_acc</td><td>1.0</td></tr><tr><td>tr_acc</td><td>1.0</td></tr><tr><td>tr_epoch_loss</td><td>0.0017</td></tr><tr><td>val_acc_best</td><td>0.80417</td></tr><tr><td>val_acc_now</td><td>0.775</td></tr><tr><td>val_loss</td><td>3.43838</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">confused-sweep-59</strong> at: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/831gwx1a' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/831gwx1a</a><br/> View project at: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>/data2/bh_wandb/wandb/run-20250430_002725-831gwx1a/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require(\"core\")`! See https://wandb.me/wandb-core for more information."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Sweep Agent: Waiting for job.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Job received.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: hk7aj89b with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBATCH: 16\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBN_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBPTT_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tDFA_on: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tIMAGE_SIZE: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tOTTT_input_trace_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tTIME: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tUDA_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \talpha_uda: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbias: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcfg: ['M', 'M', 200, 200]\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tchaching_on: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tconvTrue_fcFalse: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdata_path: /data2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tddp_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdenoise_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdvs_clipping: 5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdvs_duration: 100000\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepoch_num: 100\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \texclude_class: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \textra_train_dataset: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlast_lif: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.001\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_sg_width: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_decay: 0.5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_init: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_reset: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_threshold: 0.25\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmerge_polarities: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmy_seed: 42\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnet_print: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_workers: 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer_what: SGD\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tpin_memory: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tpre_trained: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tpre_trained_path: net_save/save_now_net_weights_{unique_name}.pth\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \trate_coding: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tscheduler_name: no\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsingle_step: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsurrogate: hard_sigmoid\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_conv_kernel_size: 3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_conv_padding: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_conv_stride: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_trace_const1: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_trace_const2: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \ttdBN_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \ttrace_on: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \twhich_data: DVS_GESTURE_TONIC\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6881912bc2b845d7bfc9ea818aef71cd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.011112694499186344, max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.19.10 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.17.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/data2/bh_wandb/wandb/run-20250430_003349-hk7aj89b</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/hk7aj89b' target=\"_blank\">morning-sweep-63</a></strong> to <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/6pj3lh8j' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/6pj3lh8j</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/6pj3lh8j' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/6pj3lh8j</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/hk7aj89b' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/hk7aj89b</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'single_step' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'my_seed' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'TIME' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BATCH' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'IMAGE_SIZE' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'which_data' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'data_path' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'rate_coding' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_init' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_decay' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_threshold' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_reset' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_sg_width' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_conv_kernel_size' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_conv_stride' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_conv_padding' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_trace_const1' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_trace_const2' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'pre_trained' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'convTrue_fcFalse' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'cfg' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'net_print' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'pre_trained_path' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'learning_rate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'epoch_num' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'tdBN_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BN_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'surrogate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BPTT_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'optimizer_what' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'scheduler_name' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'ddp_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'dvs_clipping' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'dvs_duration' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'DFA_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'trace_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'OTTT_input_trace_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'exclude_class' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'merge_polarities' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'denoise_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'extra_train_dataset' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'num_workers' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'chaching_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'pin_memory' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'UDA_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'alpha_uda' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'bias' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'last_lif' was locked by 'sweep' (ignored update).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "param {'devices': '0', 'single_step': True, 'unique_name': 'main', 'my_seed': 42, 'TIME': 10, 'BATCH': 16, 'IMAGE_SIZE': 128, 'which_data': 'DVS_GESTURE_TONIC', 'data_path': '/data2', 'rate_coding': False, 'lif_layer_v_init': 0, 'lif_layer_v_decay': 0.5, 'lif_layer_v_threshold': 0.25, 'lif_layer_v_reset': 0, 'lif_layer_sg_width': 1, 'synapse_conv_kernel_size': 3, 'synapse_conv_stride': 1, 'synapse_conv_padding': 1, 'synapse_trace_const1': 1, 'synapse_trace_const2': 0, 'pre_trained': False, 'convTrue_fcFalse': False, 'cfg': ['M', 'M', 200, 200], 'net_print': True, 'pre_trained_path': 'net_save/save_now_net_weights_{unique_name}.pth', 'learning_rate': 0.001, 'epoch_num': 100, 'tdBN_on': False, 'BN_on': False, 'surrogate': 'hard_sigmoid', 'BPTT_on': False, 'optimizer_what': 'SGD', 'scheduler_name': 'no', 'ddp_on': False, 'dvs_clipping': 5, 'dvs_duration': 100000, 'DFA_on': True, 'trace_on': True, 'OTTT_input_trace_on': False, 'exclude_class': True, 'merge_polarities': False, 'denoise_on': False, 'extra_train_dataset': 0, 'num_workers': 2, 'chaching_on': True, 'pin_memory': True, 'UDA_on': False, 'alpha_uda': 1, 'bias': True, 'last_lif': False, 'current epoch': 0} \n",
      "\n",
      "dataset_hash = ffa516e60c3efd5e0208f72b4c36cb84\n",
      "cache path exists\n",
      "\n",
      "device ==> cuda\n",
      "\n",
      "DataParallel(\n",
      "  (module): REBORN_MY_SNN_FC(\n",
      "    (layers): REBORN_MY_Sequential(\n",
      "      (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (2): DimChanger_for_FC()\n",
      "      (3): SYNAPSE_FC(in_features=2048, out_features=200, TIME=10, bias=True, sstep=True)\n",
      "      (4): LIF_layer(v_init=0, v_decay=0.5, v_threshold=0.25, v_reset=0, sg_width=1, surrogate=hard_sigmoid, BPTT_on=False, trace_const1=1, trace_const2=0, TIME=10, sstep=True, trace_on=True)\n",
      "      (5): Feedback_Receiver()\n",
      "      (6): SYNAPSE_FC(in_features=200, out_features=200, TIME=10, bias=True, sstep=True)\n",
      "      (7): LIF_layer(v_init=0, v_decay=0.5, v_threshold=0.25, v_reset=0, sg_width=1, surrogate=hard_sigmoid, BPTT_on=False, trace_const1=1, trace_const2=0, TIME=10, sstep=True, trace_on=True)\n",
      "      (8): Feedback_Receiver()\n",
      "      (9): SYNAPSE_FC(in_features=200, out_features=10, TIME=10, bias=True, sstep=True)\n",
      "      (DFA_top): Top_Gradient()\n",
      "    )\n",
      "  )\n",
      ")\n",
      "\n",
      "========================================================\n",
      "Trainable parameters: 452,010\n",
      "========================================================\n",
      "\n",
      "epoch-0   lr=['0.0010000'], tr/val_loss:  2.200257/  1.963433, val:  33.75%, val_best:  33.75%, tr:  17.47%, tr_best:  17.47%\n",
      "[module.layers.5] weight_fb parameter count: 2,000\n",
      "[module.layers.8] weight_fb parameter count: 2,000\n",
      "epoch-1   lr=['0.0010000'], tr/val_loss:  1.612809/  1.502315, val:  52.50%, val_best:  52.50%, tr:  48.83%, tr_best:  48.83%\n",
      "epoch-2   lr=['0.0010000'], tr/val_loss:  1.319229/  1.399373, val:  54.17%, val_best:  54.17%, tr:  57.00%, tr_best:  57.00%\n",
      "epoch-3   lr=['0.0010000'], tr/val_loss:  1.204576/  1.362992, val:  57.08%, val_best:  57.08%, tr:  62.21%, tr_best:  62.21%\n",
      "epoch-4   lr=['0.0010000'], tr/val_loss:  1.144690/  1.348632, val:  57.92%, val_best:  57.92%, tr:  62.82%, tr_best:  62.82%\n",
      "epoch-5   lr=['0.0010000'], tr/val_loss:  1.085414/  1.291084, val:  62.08%, val_best:  62.08%, tr:  64.25%, tr_best:  64.25%\n",
      "epoch-6   lr=['0.0010000'], tr/val_loss:  1.028766/  1.270729, val:  63.33%, val_best:  63.33%, tr:  66.91%, tr_best:  66.91%\n",
      "epoch-7   lr=['0.0010000'], tr/val_loss:  1.002337/  1.260750, val:  64.17%, val_best:  64.17%, tr:  68.13%, tr_best:  68.13%\n",
      "epoch-8   lr=['0.0010000'], tr/val_loss:  0.961690/  1.261445, val:  63.33%, val_best:  64.17%, tr:  69.36%, tr_best:  69.36%\n",
      "epoch-9   lr=['0.0010000'], tr/val_loss:  0.939497/  1.258922, val:  60.83%, val_best:  64.17%, tr:  70.68%, tr_best:  70.68%\n",
      "epoch-10  lr=['0.0010000'], tr/val_loss:  0.922273/  1.269150, val:  60.00%, val_best:  64.17%, tr:  69.77%, tr_best:  70.68%\n",
      "epoch-11  lr=['0.0010000'], tr/val_loss:  0.891821/  1.224548, val:  62.08%, val_best:  64.17%, tr:  72.01%, tr_best:  72.01%\n",
      "epoch-12  lr=['0.0010000'], tr/val_loss:  0.880291/  1.230423, val:  59.58%, val_best:  64.17%, tr:  74.16%, tr_best:  74.16%\n",
      "epoch-13  lr=['0.0010000'], tr/val_loss:  0.863125/  1.228143, val:  64.17%, val_best:  64.17%, tr:  76.51%, tr_best:  76.51%\n",
      "epoch-14  lr=['0.0010000'], tr/val_loss:  0.821415/  1.307757, val:  60.42%, val_best:  64.17%, tr:  75.59%, tr_best:  76.51%\n",
      "epoch-15  lr=['0.0010000'], tr/val_loss:  0.805111/  1.212557, val:  67.50%, val_best:  67.50%, tr:  78.55%, tr_best:  78.55%\n",
      "epoch-16  lr=['0.0010000'], tr/val_loss:  0.807929/  1.224711, val:  62.92%, val_best:  67.50%, tr:  76.51%, tr_best:  78.55%\n",
      "epoch-17  lr=['0.0010000'], tr/val_loss:  0.769923/  1.214597, val:  65.83%, val_best:  67.50%, tr:  81.72%, tr_best:  81.72%\n",
      "epoch-18  lr=['0.0010000'], tr/val_loss:  0.747036/  1.271080, val:  63.33%, val_best:  67.50%, tr:  81.31%, tr_best:  81.72%\n",
      "epoch-19  lr=['0.0010000'], tr/val_loss:  0.743961/  1.244238, val:  65.42%, val_best:  67.50%, tr:  79.26%, tr_best:  81.72%\n",
      "epoch-20  lr=['0.0010000'], tr/val_loss:  0.715465/  1.235161, val:  64.17%, val_best:  67.50%, tr:  84.88%, tr_best:  84.88%\n",
      "epoch-21  lr=['0.0010000'], tr/val_loss:  0.707739/  1.200252, val:  67.08%, val_best:  67.50%, tr:  84.58%, tr_best:  84.88%\n",
      "epoch-22  lr=['0.0010000'], tr/val_loss:  0.709503/  1.228547, val:  70.42%, val_best:  70.42%, tr:  82.43%, tr_best:  84.88%\n",
      "epoch-23  lr=['0.0010000'], tr/val_loss:  0.668734/  1.248012, val:  65.83%, val_best:  70.42%, tr:  86.11%, tr_best:  86.11%\n",
      "epoch-24  lr=['0.0010000'], tr/val_loss:  0.654331/  1.247338, val:  65.00%, val_best:  70.42%, tr:  87.95%, tr_best:  87.95%\n",
      "epoch-25  lr=['0.0010000'], tr/val_loss:  0.644361/  1.229483, val:  71.25%, val_best:  71.25%, tr:  88.36%, tr_best:  88.36%\n",
      "epoch-26  lr=['0.0010000'], tr/val_loss:  0.632797/  1.228203, val:  70.42%, val_best:  71.25%, tr:  88.15%, tr_best:  88.36%\n",
      "epoch-27  lr=['0.0010000'], tr/val_loss:  0.618532/  1.276007, val:  70.00%, val_best:  71.25%, tr:  89.99%, tr_best:  89.99%\n",
      "epoch-28  lr=['0.0010000'], tr/val_loss:  0.609934/  1.261064, val:  70.42%, val_best:  71.25%, tr:  91.01%, tr_best:  91.01%\n",
      "epoch-29  lr=['0.0010000'], tr/val_loss:  0.577692/  1.303436, val:  65.83%, val_best:  71.25%, tr:  92.24%, tr_best:  92.24%\n",
      "epoch-30  lr=['0.0010000'], tr/val_loss:  0.571665/  1.291641, val:  65.42%, val_best:  71.25%, tr:  93.16%, tr_best:  93.16%\n",
      "epoch-31  lr=['0.0010000'], tr/val_loss:  0.577910/  1.321637, val:  66.25%, val_best:  71.25%, tr:  90.70%, tr_best:  93.16%\n",
      "epoch-32  lr=['0.0010000'], tr/val_loss:  0.558480/  1.314774, val:  67.50%, val_best:  71.25%, tr:  92.85%, tr_best:  93.16%\n",
      "epoch-33  lr=['0.0010000'], tr/val_loss:  0.560280/  1.317617, val:  69.17%, val_best:  71.25%, tr:  92.34%, tr_best:  93.16%\n",
      "epoch-34  lr=['0.0010000'], tr/val_loss:  0.532511/  1.363640, val:  64.58%, val_best:  71.25%, tr:  93.67%, tr_best:  93.67%\n",
      "epoch-35  lr=['0.0010000'], tr/val_loss:  0.538369/  1.354566, val:  67.50%, val_best:  71.25%, tr:  93.26%, tr_best:  93.67%\n",
      "epoch-36  lr=['0.0010000'], tr/val_loss:  0.508970/  1.347897, val:  65.83%, val_best:  71.25%, tr:  95.30%, tr_best:  95.30%\n",
      "epoch-37  lr=['0.0010000'], tr/val_loss:  0.509781/  1.359850, val:  67.92%, val_best:  71.25%, tr:  95.51%, tr_best:  95.51%\n",
      "epoch-38  lr=['0.0010000'], tr/val_loss:  0.499739/  1.371768, val:  69.58%, val_best:  71.25%, tr:  96.02%, tr_best:  96.02%\n",
      "epoch-39  lr=['0.0010000'], tr/val_loss:  0.490092/  1.371360, val:  70.00%, val_best:  71.25%, tr:  95.51%, tr_best:  96.02%\n",
      "epoch-40  lr=['0.0010000'], tr/val_loss:  0.479144/  1.397188, val:  69.58%, val_best:  71.25%, tr:  95.40%, tr_best:  96.02%\n",
      "epoch-41  lr=['0.0010000'], tr/val_loss:  0.472979/  1.397076, val:  67.50%, val_best:  71.25%, tr:  96.94%, tr_best:  96.94%\n",
      "epoch-42  lr=['0.0010000'], tr/val_loss:  0.457328/  1.426906, val:  66.67%, val_best:  71.25%, tr:  96.73%, tr_best:  96.94%\n",
      "epoch-43  lr=['0.0010000'], tr/val_loss:  0.451069/  1.433495, val:  69.58%, val_best:  71.25%, tr:  96.94%, tr_best:  96.94%\n",
      "epoch-44  lr=['0.0010000'], tr/val_loss:  0.444882/  1.419277, val:  67.50%, val_best:  71.25%, tr:  97.04%, tr_best:  97.04%\n",
      "epoch-45  lr=['0.0010000'], tr/val_loss:  0.437747/  1.444493, val:  68.75%, val_best:  71.25%, tr:  96.94%, tr_best:  97.04%\n",
      "epoch-46  lr=['0.0010000'], tr/val_loss:  0.422129/  1.450096, val:  65.83%, val_best:  71.25%, tr:  97.85%, tr_best:  97.85%\n",
      "epoch-47  lr=['0.0010000'], tr/val_loss:  0.423701/  1.481308, val:  66.67%, val_best:  71.25%, tr:  97.45%, tr_best:  97.85%\n",
      "epoch-48  lr=['0.0010000'], tr/val_loss:  0.413600/  1.457761, val:  67.50%, val_best:  71.25%, tr:  97.75%, tr_best:  97.85%\n",
      "epoch-49  lr=['0.0010000'], tr/val_loss:  0.414267/  1.492015, val:  67.08%, val_best:  71.25%, tr:  97.55%, tr_best:  97.85%\n",
      "epoch-50  lr=['0.0010000'], tr/val_loss:  0.406376/  1.521162, val:  67.50%, val_best:  71.25%, tr:  97.85%, tr_best:  97.85%\n",
      "epoch-51  lr=['0.0010000'], tr/val_loss:  0.397541/  1.535680, val:  69.17%, val_best:  71.25%, tr:  98.26%, tr_best:  98.26%\n",
      "epoch-52  lr=['0.0010000'], tr/val_loss:  0.388995/  1.545179, val:  65.00%, val_best:  71.25%, tr:  98.47%, tr_best:  98.47%\n",
      "epoch-53  lr=['0.0010000'], tr/val_loss:  0.390623/  1.544450, val:  64.58%, val_best:  71.25%, tr:  98.37%, tr_best:  98.47%\n",
      "epoch-54  lr=['0.0010000'], tr/val_loss:  0.375709/  1.551908, val:  66.67%, val_best:  71.25%, tr:  98.88%, tr_best:  98.88%\n",
      "epoch-55  lr=['0.0010000'], tr/val_loss:  0.379179/  1.546880, val:  68.33%, val_best:  71.25%, tr:  98.47%, tr_best:  98.88%\n",
      "epoch-56  lr=['0.0010000'], tr/val_loss:  0.374657/  1.570104, val:  65.83%, val_best:  71.25%, tr:  98.47%, tr_best:  98.88%\n",
      "epoch-57  lr=['0.0010000'], tr/val_loss:  0.366088/  1.565649, val:  69.58%, val_best:  71.25%, tr:  98.67%, tr_best:  98.88%\n",
      "epoch-58  lr=['0.0010000'], tr/val_loss:  0.356249/  1.597082, val:  64.17%, val_best:  71.25%, tr:  98.98%, tr_best:  98.98%\n",
      "epoch-59  lr=['0.0010000'], tr/val_loss:  0.349658/  1.581693, val:  65.42%, val_best:  71.25%, tr:  98.77%, tr_best:  98.98%\n",
      "epoch-60  lr=['0.0010000'], tr/val_loss:  0.351490/  1.581155, val:  67.08%, val_best:  71.25%, tr:  98.77%, tr_best:  98.98%\n",
      "epoch-61  lr=['0.0010000'], tr/val_loss:  0.341287/  1.606171, val:  65.42%, val_best:  71.25%, tr:  99.18%, tr_best:  99.18%\n",
      "epoch-62  lr=['0.0010000'], tr/val_loss:  0.339606/  1.620158, val:  65.42%, val_best:  71.25%, tr:  99.08%, tr_best:  99.18%\n",
      "epoch-63  lr=['0.0010000'], tr/val_loss:  0.335784/  1.613652, val:  67.08%, val_best:  71.25%, tr:  99.49%, tr_best:  99.49%\n",
      "epoch-64  lr=['0.0010000'], tr/val_loss:  0.331649/  1.657438, val:  68.33%, val_best:  71.25%, tr:  98.77%, tr_best:  99.49%\n",
      "epoch-65  lr=['0.0010000'], tr/val_loss:  0.325306/  1.652475, val:  67.08%, val_best:  71.25%, tr:  99.28%, tr_best:  99.49%\n",
      "epoch-66  lr=['0.0010000'], tr/val_loss:  0.327141/  1.655639, val:  65.83%, val_best:  71.25%, tr:  99.28%, tr_best:  99.49%\n",
      "epoch-67  lr=['0.0010000'], tr/val_loss:  0.323797/  1.647362, val:  67.92%, val_best:  71.25%, tr:  99.49%, tr_best:  99.49%\n",
      "epoch-68  lr=['0.0010000'], tr/val_loss:  0.319172/  1.683954, val:  65.00%, val_best:  71.25%, tr:  99.49%, tr_best:  99.49%\n",
      "epoch-69  lr=['0.0010000'], tr/val_loss:  0.300421/  1.679635, val:  67.08%, val_best:  71.25%, tr:  99.59%, tr_best:  99.59%\n",
      "epoch-70  lr=['0.0010000'], tr/val_loss:  0.304698/  1.700534, val:  66.67%, val_best:  71.25%, tr:  99.59%, tr_best:  99.59%\n",
      "epoch-71  lr=['0.0010000'], tr/val_loss:  0.303174/  1.741844, val:  63.75%, val_best:  71.25%, tr:  99.28%, tr_best:  99.59%\n",
      "epoch-72  lr=['0.0010000'], tr/val_loss:  0.300199/  1.744657, val:  65.00%, val_best:  71.25%, tr:  99.59%, tr_best:  99.59%\n",
      "epoch-73  lr=['0.0010000'], tr/val_loss:  0.299816/  1.701602, val:  68.33%, val_best:  71.25%, tr:  99.69%, tr_best:  99.69%\n",
      "epoch-74  lr=['0.0010000'], tr/val_loss:  0.290658/  1.733547, val:  67.08%, val_best:  71.25%, tr:  99.49%, tr_best:  99.69%\n",
      "epoch-75  lr=['0.0010000'], tr/val_loss:  0.288130/  1.741887, val:  66.25%, val_best:  71.25%, tr:  99.49%, tr_best:  99.69%\n",
      "epoch-76  lr=['0.0010000'], tr/val_loss:  0.280969/  1.775606, val:  67.08%, val_best:  71.25%, tr:  99.69%, tr_best:  99.69%\n",
      "epoch-77  lr=['0.0010000'], tr/val_loss:  0.285543/  1.774962, val:  67.92%, val_best:  71.25%, tr:  99.49%, tr_best:  99.69%\n",
      "epoch-78  lr=['0.0010000'], tr/val_loss:  0.282475/  1.766745, val:  63.33%, val_best:  71.25%, tr:  99.49%, tr_best:  99.69%\n",
      "epoch-79  lr=['0.0010000'], tr/val_loss:  0.270164/  1.779068, val:  67.08%, val_best:  71.25%, tr:  99.59%, tr_best:  99.69%\n",
      "epoch-80  lr=['0.0010000'], tr/val_loss:  0.269703/  1.795308, val:  67.08%, val_best:  71.25%, tr:  99.59%, tr_best:  99.69%\n",
      "epoch-81  lr=['0.0010000'], tr/val_loss:  0.270354/  1.780708, val:  66.25%, val_best:  71.25%, tr:  99.49%, tr_best:  99.69%\n",
      "epoch-82  lr=['0.0010000'], tr/val_loss:  0.266313/  1.814557, val:  65.83%, val_best:  71.25%, tr:  99.69%, tr_best:  99.69%\n",
      "epoch-83  lr=['0.0010000'], tr/val_loss:  0.263151/  1.832200, val:  66.67%, val_best:  71.25%, tr:  99.80%, tr_best:  99.80%\n",
      "epoch-84  lr=['0.0010000'], tr/val_loss:  0.254204/  1.823576, val:  68.75%, val_best:  71.25%, tr:  99.69%, tr_best:  99.80%\n",
      "epoch-85  lr=['0.0010000'], tr/val_loss:  0.252525/  1.844180, val:  65.42%, val_best:  71.25%, tr:  99.59%, tr_best:  99.80%\n",
      "epoch-86  lr=['0.0010000'], tr/val_loss:  0.254418/  1.857021, val:  67.92%, val_best:  71.25%, tr:  99.69%, tr_best:  99.80%\n",
      "epoch-87  lr=['0.0010000'], tr/val_loss:  0.248404/  1.874591, val:  65.83%, val_best:  71.25%, tr:  99.80%, tr_best:  99.80%\n",
      "epoch-88  lr=['0.0010000'], tr/val_loss:  0.250232/  1.882378, val:  65.00%, val_best:  71.25%, tr:  99.80%, tr_best:  99.80%\n",
      "epoch-89  lr=['0.0010000'], tr/val_loss:  0.241832/  1.904018, val:  65.83%, val_best:  71.25%, tr:  99.80%, tr_best:  99.80%\n",
      "epoch-90  lr=['0.0010000'], tr/val_loss:  0.246260/  1.900752, val:  65.83%, val_best:  71.25%, tr:  99.69%, tr_best:  99.80%\n",
      "epoch-91  lr=['0.0010000'], tr/val_loss:  0.238753/  1.916912, val:  65.00%, val_best:  71.25%, tr:  99.80%, tr_best:  99.80%\n",
      "epoch-92  lr=['0.0010000'], tr/val_loss:  0.234833/  1.923412, val:  67.92%, val_best:  71.25%, tr:  99.80%, tr_best:  99.80%\n",
      "epoch-93  lr=['0.0010000'], tr/val_loss:  0.235869/  1.904665, val:  67.92%, val_best:  71.25%, tr:  99.90%, tr_best:  99.90%\n",
      "epoch-94  lr=['0.0010000'], tr/val_loss:  0.236204/  1.945157, val:  64.17%, val_best:  71.25%, tr:  99.90%, tr_best:  99.90%\n",
      "epoch-95  lr=['0.0010000'], tr/val_loss:  0.232264/  1.944897, val:  65.42%, val_best:  71.25%, tr:  99.80%, tr_best:  99.90%\n",
      "epoch-96  lr=['0.0010000'], tr/val_loss:  0.226952/  1.957016, val:  64.58%, val_best:  71.25%, tr:  99.80%, tr_best:  99.90%\n",
      "epoch-97  lr=['0.0010000'], tr/val_loss:  0.228863/  1.949686, val:  68.33%, val_best:  71.25%, tr:  99.80%, tr_best:  99.90%\n",
      "epoch-98  lr=['0.0010000'], tr/val_loss:  0.220239/  1.953671, val:  67.08%, val_best:  71.25%, tr:  99.90%, tr_best:  99.90%\n",
      "epoch-99  lr=['0.0010000'], tr/val_loss:  0.228307/  1.972498, val:  64.58%, val_best:  71.25%, tr:  99.90%, tr_best:  99.90%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5584a25e8bf7487a9503d2cb662d4f30",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.006 MB of 0.006 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>iter_acc</td><td>▁▆▃▃▃▄▆▃▆▇▇█▇▆▇█▇▇██████████████████▇███</td></tr><tr><td>summary_val_acc</td><td>▁▅▆▇▆▆▆▇▇▇▇█▇▇▇██▇▇▇▇▇▇█▇▇▇█▇▇▇█▇▇█▇▇█▇█</td></tr><tr><td>tr_acc</td><td>▁▄▅▅▆▆▆▆▆▇▇▇▇▇▇█████████████████████████</td></tr><tr><td>tr_epoch_loss</td><td>█▅▄▄▄▃▃▃▃▃▃▂▂▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_acc_best</td><td>▁▅▆▇▇▇▇▇▇▇██████████████████████████████</td></tr><tr><td>val_acc_now</td><td>▁▅▆▇▆▆▆▇▇▇▇█▇▇▇██▇▇▇▇▇▇█▇▇▇█▇▇▇█▇▇█▇▇█▇█</td></tr><tr><td>val_loss</td><td>█▃▂▂▂▁▂▁▁▁▁▁▂▂▂▂▃▃▃▄▄▄▄▄▄▅▅▅▆▆▆▆▆▇▇▇▇███</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>99</td></tr><tr><td>iter_acc</td><td>1.0</td></tr><tr><td>tr_acc</td><td>0.99898</td></tr><tr><td>tr_epoch_loss</td><td>0.22831</td></tr><tr><td>val_acc_best</td><td>0.7125</td></tr><tr><td>val_acc_now</td><td>0.64583</td></tr><tr><td>val_loss</td><td>1.9725</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">morning-sweep-63</strong> at: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/hk7aj89b' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/hk7aj89b</a><br/> View project at: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>/data2/bh_wandb/wandb/run-20250430_003349-hk7aj89b/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require(\"core\")`! See https://wandb.me/wandb-core for more information."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Sweep Agent: Waiting for job.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Job received.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: mrpdrk2b with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBATCH: 16\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBN_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBPTT_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tDFA_on: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tIMAGE_SIZE: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tOTTT_input_trace_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tTIME: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tUDA_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \talpha_uda: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbias: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcfg: ['M', 'M', 200, 200]\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tchaching_on: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tconvTrue_fcFalse: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdata_path: /data2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tddp_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdenoise_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdvs_clipping: 5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdvs_duration: 100000\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepoch_num: 100\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \texclude_class: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \textra_train_dataset: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlast_lif: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.001\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_sg_width: 4\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_decay: 0.5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_init: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_reset: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_threshold: 0.25\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmerge_polarities: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmy_seed: 42\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnet_print: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_workers: 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer_what: SGD\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tpin_memory: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tpre_trained: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tpre_trained_path: net_save/save_now_net_weights_{unique_name}.pth\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \trate_coding: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tscheduler_name: no\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsingle_step: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsurrogate: hard_sigmoid\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_conv_kernel_size: 3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_conv_padding: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_conv_stride: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_trace_const1: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_trace_const2: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \ttdBN_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \ttrace_on: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \twhich_data: DVS_GESTURE_TONIC\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.19.10 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.17.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/data2/bh_wandb/wandb/run-20250430_004059-mrpdrk2b</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/mrpdrk2b' target=\"_blank\">still-sweep-67</a></strong> to <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/6pj3lh8j' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/6pj3lh8j</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/6pj3lh8j' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/6pj3lh8j</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/mrpdrk2b' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/mrpdrk2b</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'single_step' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'my_seed' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'TIME' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BATCH' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'IMAGE_SIZE' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'which_data' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'data_path' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'rate_coding' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_init' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_decay' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_threshold' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_reset' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_sg_width' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_conv_kernel_size' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_conv_stride' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_conv_padding' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_trace_const1' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_trace_const2' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'pre_trained' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'convTrue_fcFalse' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'cfg' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'net_print' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'pre_trained_path' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'learning_rate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'epoch_num' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'tdBN_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BN_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'surrogate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BPTT_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'optimizer_what' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'scheduler_name' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'ddp_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'dvs_clipping' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'dvs_duration' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'DFA_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'trace_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'OTTT_input_trace_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'exclude_class' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'merge_polarities' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'denoise_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'extra_train_dataset' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'num_workers' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'chaching_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'pin_memory' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'UDA_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'alpha_uda' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'bias' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'last_lif' was locked by 'sweep' (ignored update).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "param {'devices': '0', 'single_step': True, 'unique_name': 'main', 'my_seed': 42, 'TIME': 10, 'BATCH': 16, 'IMAGE_SIZE': 128, 'which_data': 'DVS_GESTURE_TONIC', 'data_path': '/data2', 'rate_coding': False, 'lif_layer_v_init': 0, 'lif_layer_v_decay': 0.5, 'lif_layer_v_threshold': 0.25, 'lif_layer_v_reset': 0, 'lif_layer_sg_width': 4, 'synapse_conv_kernel_size': 3, 'synapse_conv_stride': 1, 'synapse_conv_padding': 1, 'synapse_trace_const1': 1, 'synapse_trace_const2': 0, 'pre_trained': False, 'convTrue_fcFalse': False, 'cfg': ['M', 'M', 200, 200], 'net_print': True, 'pre_trained_path': 'net_save/save_now_net_weights_{unique_name}.pth', 'learning_rate': 0.001, 'epoch_num': 100, 'tdBN_on': False, 'BN_on': False, 'surrogate': 'hard_sigmoid', 'BPTT_on': False, 'optimizer_what': 'SGD', 'scheduler_name': 'no', 'ddp_on': False, 'dvs_clipping': 5, 'dvs_duration': 100000, 'DFA_on': True, 'trace_on': True, 'OTTT_input_trace_on': False, 'exclude_class': True, 'merge_polarities': False, 'denoise_on': False, 'extra_train_dataset': 0, 'num_workers': 2, 'chaching_on': True, 'pin_memory': True, 'UDA_on': False, 'alpha_uda': 1, 'bias': True, 'last_lif': False, 'current epoch': 0} \n",
      "\n",
      "dataset_hash = ffa516e60c3efd5e0208f72b4c36cb84\n",
      "cache path exists\n",
      "\n",
      "device ==> cuda\n",
      "\n",
      "DataParallel(\n",
      "  (module): REBORN_MY_SNN_FC(\n",
      "    (layers): REBORN_MY_Sequential(\n",
      "      (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (2): DimChanger_for_FC()\n",
      "      (3): SYNAPSE_FC(in_features=2048, out_features=200, TIME=10, bias=True, sstep=True)\n",
      "      (4): LIF_layer(v_init=0, v_decay=0.5, v_threshold=0.25, v_reset=0, sg_width=4, surrogate=hard_sigmoid, BPTT_on=False, trace_const1=1, trace_const2=0, TIME=10, sstep=True, trace_on=True)\n",
      "      (5): Feedback_Receiver()\n",
      "      (6): SYNAPSE_FC(in_features=200, out_features=200, TIME=10, bias=True, sstep=True)\n",
      "      (7): LIF_layer(v_init=0, v_decay=0.5, v_threshold=0.25, v_reset=0, sg_width=4, surrogate=hard_sigmoid, BPTT_on=False, trace_const1=1, trace_const2=0, TIME=10, sstep=True, trace_on=True)\n",
      "      (8): Feedback_Receiver()\n",
      "      (9): SYNAPSE_FC(in_features=200, out_features=10, TIME=10, bias=True, sstep=True)\n",
      "      (DFA_top): Top_Gradient()\n",
      "    )\n",
      "  )\n",
      ")\n",
      "\n",
      "========================================================\n",
      "Trainable parameters: 452,010\n",
      "========================================================\n",
      "\n",
      "epoch-0   lr=['0.0010000'], tr/val_loss:  1.992836/  1.530355, val:  43.75%, val_best:  43.75%, tr:  25.03%, tr_best:  25.03%\n",
      "[module.layers.5] weight_fb parameter count: 2,000\n",
      "[module.layers.8] weight_fb parameter count: 2,000\n",
      "epoch-1   lr=['0.0010000'], tr/val_loss:  1.270813/  1.365592, val:  54.58%, val_best:  54.58%, tr:  53.73%, tr_best:  53.73%\n",
      "epoch-2   lr=['0.0010000'], tr/val_loss:  1.069424/  1.281831, val:  57.08%, val_best:  57.08%, tr:  61.59%, tr_best:  61.59%\n",
      "epoch-3   lr=['0.0010000'], tr/val_loss:  0.933384/  1.251486, val:  61.25%, val_best:  61.25%, tr:  66.70%, tr_best:  66.70%\n",
      "epoch-4   lr=['0.0010000'], tr/val_loss:  0.866738/  1.182627, val:  65.83%, val_best:  65.83%, tr:  69.97%, tr_best:  69.97%\n",
      "epoch-5   lr=['0.0010000'], tr/val_loss:  0.786886/  1.128070, val:  68.33%, val_best:  68.33%, tr:  73.54%, tr_best:  73.54%\n",
      "epoch-6   lr=['0.0010000'], tr/val_loss:  0.703391/  1.155334, val:  62.50%, val_best:  68.33%, tr:  79.16%, tr_best:  79.16%\n",
      "epoch-7   lr=['0.0010000'], tr/val_loss:  0.662856/  1.105658, val:  74.17%, val_best:  74.17%, tr:  80.59%, tr_best:  80.59%\n",
      "epoch-8   lr=['0.0010000'], tr/val_loss:  0.586745/  1.165156, val:  70.00%, val_best:  74.17%, tr:  88.46%, tr_best:  88.46%\n",
      "epoch-9   lr=['0.0010000'], tr/val_loss:  0.531940/  1.184574, val:  71.25%, val_best:  74.17%, tr:  89.68%, tr_best:  89.68%\n",
      "epoch-10  lr=['0.0010000'], tr/val_loss:  0.481265/  1.274785, val:  68.33%, val_best:  74.17%, tr:  92.75%, tr_best:  92.75%\n",
      "epoch-11  lr=['0.0010000'], tr/val_loss:  0.411131/  1.205037, val:  71.25%, val_best:  74.17%, tr:  95.30%, tr_best:  95.30%\n",
      "epoch-12  lr=['0.0010000'], tr/val_loss:  0.380376/  1.218549, val:  72.92%, val_best:  74.17%, tr:  97.04%, tr_best:  97.04%\n",
      "epoch-13  lr=['0.0010000'], tr/val_loss:  0.355044/  1.233106, val:  73.33%, val_best:  74.17%, tr:  96.83%, tr_best:  97.04%\n",
      "epoch-14  lr=['0.0010000'], tr/val_loss:  0.313360/  1.399375, val:  67.08%, val_best:  74.17%, tr:  97.34%, tr_best:  97.34%\n",
      "epoch-15  lr=['0.0010000'], tr/val_loss:  0.281016/  1.315073, val:  68.75%, val_best:  74.17%, tr:  98.16%, tr_best:  98.16%\n",
      "epoch-16  lr=['0.0010000'], tr/val_loss:  0.276405/  1.278273, val:  71.67%, val_best:  74.17%, tr:  98.16%, tr_best:  98.16%\n",
      "epoch-17  lr=['0.0010000'], tr/val_loss:  0.230744/  1.304451, val:  73.33%, val_best:  74.17%, tr:  98.77%, tr_best:  98.77%\n",
      "epoch-18  lr=['0.0010000'], tr/val_loss:  0.217097/  1.367440, val:  72.50%, val_best:  74.17%, tr:  99.18%, tr_best:  99.18%\n",
      "epoch-19  lr=['0.0010000'], tr/val_loss:  0.189200/  1.388709, val:  72.92%, val_best:  74.17%, tr:  99.69%, tr_best:  99.69%\n",
      "epoch-20  lr=['0.0010000'], tr/val_loss:  0.168005/  1.429032, val:  71.67%, val_best:  74.17%, tr:  99.90%, tr_best:  99.90%\n",
      "epoch-21  lr=['0.0010000'], tr/val_loss:  0.156738/  1.423135, val:  74.17%, val_best:  74.17%, tr:  99.90%, tr_best:  99.90%\n",
      "epoch-22  lr=['0.0010000'], tr/val_loss:  0.155678/  1.448348, val:  72.50%, val_best:  74.17%, tr:  99.80%, tr_best:  99.90%\n",
      "epoch-23  lr=['0.0010000'], tr/val_loss:  0.137104/  1.465722, val:  72.92%, val_best:  74.17%, tr:  99.90%, tr_best:  99.90%\n",
      "epoch-24  lr=['0.0010000'], tr/val_loss:  0.117735/  1.489887, val:  72.92%, val_best:  74.17%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-25  lr=['0.0010000'], tr/val_loss:  0.113048/  1.494661, val:  74.58%, val_best:  74.58%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-26  lr=['0.0010000'], tr/val_loss:  0.111899/  1.517547, val:  74.58%, val_best:  74.58%, tr:  99.90%, tr_best: 100.00%\n",
      "epoch-27  lr=['0.0010000'], tr/val_loss:  0.094039/  1.552814, val:  72.50%, val_best:  74.58%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-28  lr=['0.0010000'], tr/val_loss:  0.085773/  1.558714, val:  74.17%, val_best:  74.58%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-29  lr=['0.0010000'], tr/val_loss:  0.080534/  1.610260, val:  72.08%, val_best:  74.58%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-30  lr=['0.0010000'], tr/val_loss:  0.074078/  1.616008, val:  73.75%, val_best:  74.58%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-31  lr=['0.0010000'], tr/val_loss:  0.076707/  1.639017, val:  75.42%, val_best:  75.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-32  lr=['0.0010000'], tr/val_loss:  0.064758/  1.633267, val:  76.25%, val_best:  76.25%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-33  lr=['0.0010000'], tr/val_loss:  0.065957/  1.667854, val:  72.08%, val_best:  76.25%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-34  lr=['0.0010000'], tr/val_loss:  0.062587/  1.702203, val:  74.17%, val_best:  76.25%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-35  lr=['0.0010000'], tr/val_loss:  0.057386/  1.693906, val:  74.17%, val_best:  76.25%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-36  lr=['0.0010000'], tr/val_loss:  0.053166/  1.707784, val:  74.58%, val_best:  76.25%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-37  lr=['0.0010000'], tr/val_loss:  0.051085/  1.738894, val:  73.33%, val_best:  76.25%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-38  lr=['0.0010000'], tr/val_loss:  0.050181/  1.742640, val:  76.67%, val_best:  76.67%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-39  lr=['0.0010000'], tr/val_loss:  0.047369/  1.752363, val:  75.00%, val_best:  76.67%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-40  lr=['0.0010000'], tr/val_loss:  0.044923/  1.768679, val:  74.17%, val_best:  76.67%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-41  lr=['0.0010000'], tr/val_loss:  0.040334/  1.768954, val:  74.17%, val_best:  76.67%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-42  lr=['0.0010000'], tr/val_loss:  0.039417/  1.797302, val:  74.17%, val_best:  76.67%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-43  lr=['0.0010000'], tr/val_loss:  0.038766/  1.812773, val:  73.75%, val_best:  76.67%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-44  lr=['0.0010000'], tr/val_loss:  0.038489/  1.810026, val:  73.33%, val_best:  76.67%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-45  lr=['0.0010000'], tr/val_loss:  0.035944/  1.837535, val:  73.75%, val_best:  76.67%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-46  lr=['0.0010000'], tr/val_loss:  0.032449/  1.834346, val:  73.33%, val_best:  76.67%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-47  lr=['0.0010000'], tr/val_loss:  0.031562/  1.855415, val:  73.33%, val_best:  76.67%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-48  lr=['0.0010000'], tr/val_loss:  0.030469/  1.863177, val:  74.58%, val_best:  76.67%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-49  lr=['0.0010000'], tr/val_loss:  0.028516/  1.870352, val:  73.75%, val_best:  76.67%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-50  lr=['0.0010000'], tr/val_loss:  0.027792/  1.918565, val:  71.25%, val_best:  76.67%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-51  lr=['0.0010000'], tr/val_loss:  0.026748/  1.908998, val:  74.17%, val_best:  76.67%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-52  lr=['0.0010000'], tr/val_loss:  0.026891/  1.912619, val:  73.75%, val_best:  76.67%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-53  lr=['0.0010000'], tr/val_loss:  0.028077/  1.918764, val:  72.08%, val_best:  76.67%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-54  lr=['0.0010000'], tr/val_loss:  0.025418/  1.924893, val:  74.17%, val_best:  76.67%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-55  lr=['0.0010000'], tr/val_loss:  0.023315/  1.923090, val:  73.75%, val_best:  76.67%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-56  lr=['0.0010000'], tr/val_loss:  0.022478/  1.936789, val:  72.50%, val_best:  76.67%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-57  lr=['0.0010000'], tr/val_loss:  0.021557/  1.945426, val:  72.92%, val_best:  76.67%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-58  lr=['0.0010000'], tr/val_loss:  0.021156/  1.942656, val:  75.00%, val_best:  76.67%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-59  lr=['0.0010000'], tr/val_loss:  0.019743/  1.953326, val:  75.42%, val_best:  76.67%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-60  lr=['0.0010000'], tr/val_loss:  0.020329/  1.953163, val:  75.00%, val_best:  76.67%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-61  lr=['0.0010000'], tr/val_loss:  0.019369/  1.960923, val:  73.33%, val_best:  76.67%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-62  lr=['0.0010000'], tr/val_loss:  0.017890/  1.973290, val:  75.00%, val_best:  76.67%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-63  lr=['0.0010000'], tr/val_loss:  0.017283/  1.984569, val:  73.75%, val_best:  76.67%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-64  lr=['0.0010000'], tr/val_loss:  0.016926/  1.986783, val:  73.33%, val_best:  76.67%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-65  lr=['0.0010000'], tr/val_loss:  0.016638/  2.007506, val:  73.75%, val_best:  76.67%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-66  lr=['0.0010000'], tr/val_loss:  0.016184/  2.003598, val:  73.75%, val_best:  76.67%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-67  lr=['0.0010000'], tr/val_loss:  0.015977/  2.000960, val:  74.17%, val_best:  76.67%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-68  lr=['0.0010000'], tr/val_loss:  0.015402/  2.013381, val:  73.75%, val_best:  76.67%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-69  lr=['0.0010000'], tr/val_loss:  0.014964/  2.022342, val:  73.33%, val_best:  76.67%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-70  lr=['0.0010000'], tr/val_loss:  0.014858/  2.019135, val:  74.58%, val_best:  76.67%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-71  lr=['0.0010000'], tr/val_loss:  0.015367/  2.032981, val:  74.17%, val_best:  76.67%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-72  lr=['0.0010000'], tr/val_loss:  0.014025/  2.042576, val:  73.75%, val_best:  76.67%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-73  lr=['0.0010000'], tr/val_loss:  0.013691/  2.045029, val:  73.33%, val_best:  76.67%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-74  lr=['0.0010000'], tr/val_loss:  0.013978/  2.043543, val:  74.17%, val_best:  76.67%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-75  lr=['0.0010000'], tr/val_loss:  0.013692/  2.051186, val:  74.58%, val_best:  76.67%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-76  lr=['0.0010000'], tr/val_loss:  0.012567/  2.055531, val:  73.75%, val_best:  76.67%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-77  lr=['0.0010000'], tr/val_loss:  0.012612/  2.053025, val:  75.42%, val_best:  76.67%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-78  lr=['0.0010000'], tr/val_loss:  0.011796/  2.063824, val:  74.17%, val_best:  76.67%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-79  lr=['0.0010000'], tr/val_loss:  0.011929/  2.070036, val:  74.17%, val_best:  76.67%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-80  lr=['0.0010000'], tr/val_loss:  0.011806/  2.073155, val:  73.75%, val_best:  76.67%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-81  lr=['0.0010000'], tr/val_loss:  0.011632/  2.079894, val:  73.33%, val_best:  76.67%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-82  lr=['0.0010000'], tr/val_loss:  0.011438/  2.081168, val:  74.17%, val_best:  76.67%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-83  lr=['0.0010000'], tr/val_loss:  0.011136/  2.092202, val:  74.17%, val_best:  76.67%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-84  lr=['0.0010000'], tr/val_loss:  0.011016/  2.103305, val:  73.33%, val_best:  76.67%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-85  lr=['0.0010000'], tr/val_loss:  0.010949/  2.107349, val:  72.92%, val_best:  76.67%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-86  lr=['0.0010000'], tr/val_loss:  0.010504/  2.118123, val:  73.33%, val_best:  76.67%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-87  lr=['0.0010000'], tr/val_loss:  0.010123/  2.105605, val:  72.92%, val_best:  76.67%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-88  lr=['0.0010000'], tr/val_loss:  0.010164/  2.123651, val:  72.92%, val_best:  76.67%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-89  lr=['0.0010000'], tr/val_loss:  0.009368/  2.132211, val:  73.33%, val_best:  76.67%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-90  lr=['0.0010000'], tr/val_loss:  0.009824/  2.126709, val:  73.75%, val_best:  76.67%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-91  lr=['0.0010000'], tr/val_loss:  0.009035/  2.133195, val:  73.75%, val_best:  76.67%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-92  lr=['0.0010000'], tr/val_loss:  0.009100/  2.135625, val:  73.33%, val_best:  76.67%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-93  lr=['0.0010000'], tr/val_loss:  0.009616/  2.147619, val:  72.50%, val_best:  76.67%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-94  lr=['0.0010000'], tr/val_loss:  0.009408/  2.143027, val:  75.00%, val_best:  76.67%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-95  lr=['0.0010000'], tr/val_loss:  0.009128/  2.150978, val:  73.75%, val_best:  76.67%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-96  lr=['0.0010000'], tr/val_loss:  0.008981/  2.144156, val:  73.75%, val_best:  76.67%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-97  lr=['0.0010000'], tr/val_loss:  0.008209/  2.152747, val:  73.33%, val_best:  76.67%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-98  lr=['0.0010000'], tr/val_loss:  0.008215/  2.172714, val:  72.92%, val_best:  76.67%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-99  lr=['0.0010000'], tr/val_loss:  0.008785/  2.173029, val:  72.50%, val_best:  76.67%, tr: 100.00%, tr_best: 100.00%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "80b81874306342119960a8471bbf9231",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.006 MB of 0.006 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>iter_acc</td><td>▁▆▅▇▆▇█▇████████████████████████████████</td></tr><tr><td>summary_val_acc</td><td>▁▄▆█▇▇▆▇▇█▇█▇██▇██▇▇▇▇█▇█▇▇██▇████▇▇▇▇▇▇</td></tr><tr><td>tr_acc</td><td>▁▄▅▆▇███████████████████████████████████</td></tr><tr><td>tr_epoch_loss</td><td>█▅▄▃▃▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_acc_best</td><td>▁▄▆▇▇▇▇▇▇▇▇█████████████████████████████</td></tr><tr><td>val_acc_now</td><td>▁▄▆█▇▇▆▇▇█▇█▇██▇██▇▇▇▇█▇█▇▇██▇████▇▇▇▇▇▇</td></tr><tr><td>val_loss</td><td>▄▂▂▁▂▂▃▂▃▃▄▄▄▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇███████</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>99</td></tr><tr><td>iter_acc</td><td>1.0</td></tr><tr><td>tr_acc</td><td>1.0</td></tr><tr><td>tr_epoch_loss</td><td>0.00878</td></tr><tr><td>val_acc_best</td><td>0.76667</td></tr><tr><td>val_acc_now</td><td>0.725</td></tr><tr><td>val_loss</td><td>2.17303</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">still-sweep-67</strong> at: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/mrpdrk2b' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/mrpdrk2b</a><br/> View project at: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>/data2/bh_wandb/wandb/run-20250430_004059-mrpdrk2b/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require(\"core\")`! See https://wandb.me/wandb-core for more information."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: j4tuwo0d with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBATCH: 16\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBN_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBPTT_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tDFA_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tIMAGE_SIZE: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tOTTT_input_trace_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tTIME: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tUDA_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \talpha_uda: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbias: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcfg: ['M', 'M', 200, 200]\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tchaching_on: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tconvTrue_fcFalse: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdata_path: /data2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tddp_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdenoise_on: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdvs_clipping: 5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdvs_duration: 100000\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepoch_num: 100\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \texclude_class: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \textra_train_dataset: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlast_lif: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.01\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_sg_width: 3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_decay: 0.5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_init: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_reset: 10000\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_threshold: 0.25\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmerge_polarities: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmy_seed: 42\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnet_print: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_workers: 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer_what: SGD\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tpin_memory: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tpre_trained: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tpre_trained_path: net_save/save_now_net_weights_{unique_name}.pth\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \trate_coding: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tscheduler_name: no\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsingle_step: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsurrogate: hard_sigmoid\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_conv_kernel_size: 3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_conv_padding: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_conv_stride: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_trace_const1: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_trace_const2: 0.5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \ttdBN_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \ttrace_on: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \twhich_data: DVS_GESTURE_TONIC\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.19.10 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.17.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/data2/bh_wandb/wandb/run-20250430_004759-j4tuwo0d</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/j4tuwo0d' target=\"_blank\">royal-sweep-71</a></strong> to <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/6pj3lh8j' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/6pj3lh8j</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/6pj3lh8j' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/6pj3lh8j</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/j4tuwo0d' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/j4tuwo0d</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'single_step' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'my_seed' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'TIME' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BATCH' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'IMAGE_SIZE' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'which_data' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'data_path' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'rate_coding' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_init' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_decay' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_threshold' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_reset' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_sg_width' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_conv_kernel_size' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_conv_stride' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_conv_padding' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_trace_const1' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_trace_const2' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'pre_trained' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'convTrue_fcFalse' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'cfg' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'net_print' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'pre_trained_path' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'learning_rate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'epoch_num' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'tdBN_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BN_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'surrogate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BPTT_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'optimizer_what' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'scheduler_name' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'ddp_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'dvs_clipping' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'dvs_duration' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'DFA_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'trace_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'OTTT_input_trace_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'exclude_class' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'merge_polarities' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'denoise_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'extra_train_dataset' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'num_workers' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'chaching_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'pin_memory' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'UDA_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'alpha_uda' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'bias' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'last_lif' was locked by 'sweep' (ignored update).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "param {'devices': '0', 'single_step': True, 'unique_name': 'main', 'my_seed': 42, 'TIME': 10, 'BATCH': 16, 'IMAGE_SIZE': 128, 'which_data': 'DVS_GESTURE_TONIC', 'data_path': '/data2', 'rate_coding': False, 'lif_layer_v_init': 0, 'lif_layer_v_decay': 0.5, 'lif_layer_v_threshold': 0.25, 'lif_layer_v_reset': 10000, 'lif_layer_sg_width': 3, 'synapse_conv_kernel_size': 3, 'synapse_conv_stride': 1, 'synapse_conv_padding': 1, 'synapse_trace_const1': 1, 'synapse_trace_const2': 0.5, 'pre_trained': False, 'convTrue_fcFalse': False, 'cfg': ['M', 'M', 200, 200], 'net_print': True, 'pre_trained_path': 'net_save/save_now_net_weights_{unique_name}.pth', 'learning_rate': 0.01, 'epoch_num': 100, 'tdBN_on': False, 'BN_on': False, 'surrogate': 'hard_sigmoid', 'BPTT_on': False, 'optimizer_what': 'SGD', 'scheduler_name': 'no', 'ddp_on': False, 'dvs_clipping': 5, 'dvs_duration': 100000, 'DFA_on': False, 'trace_on': True, 'OTTT_input_trace_on': False, 'exclude_class': True, 'merge_polarities': False, 'denoise_on': True, 'extra_train_dataset': 0, 'num_workers': 2, 'chaching_on': True, 'pin_memory': True, 'UDA_on': False, 'alpha_uda': 1, 'bias': True, 'last_lif': False, 'current epoch': 0} \n",
      "\n",
      "dataset_hash = 63cc597115630ec173f3099200061e53\n",
      "cache path exists\n",
      "\n",
      "device ==> cuda\n",
      "\n",
      "DataParallel(\n",
      "  (module): REBORN_MY_SNN_FC(\n",
      "    (layers): REBORN_MY_Sequential(\n",
      "      (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (2): DimChanger_for_FC()\n",
      "      (3): SYNAPSE_FC(in_features=2048, out_features=200, TIME=10, bias=True, sstep=True)\n",
      "      (4): LIF_layer(v_init=0, v_decay=0.5, v_threshold=0.25, v_reset=10000, sg_width=3, surrogate=hard_sigmoid, BPTT_on=False, trace_const1=1, trace_const2=0.5, TIME=10, sstep=True, trace_on=True)\n",
      "      (5): SYNAPSE_FC(in_features=200, out_features=200, TIME=10, bias=True, sstep=True)\n",
      "      (6): LIF_layer(v_init=0, v_decay=0.5, v_threshold=0.25, v_reset=10000, sg_width=3, surrogate=hard_sigmoid, BPTT_on=False, trace_const1=1, trace_const2=0.5, TIME=10, sstep=True, trace_on=True)\n",
      "      (7): SYNAPSE_FC(in_features=200, out_features=10, TIME=10, bias=True, sstep=True)\n",
      "    )\n",
      "  )\n",
      ")\n",
      "\n",
      "========================================================\n",
      "Trainable parameters: 452,010\n",
      "========================================================\n",
      "\n",
      "epoch-0   lr=['0.0100000'], tr/val_loss:  1.807602/  1.943693, val:  50.00%, val_best:  50.00%, tr:  42.19%, tr_best:  42.19%\n",
      "epoch-1   lr=['0.0100000'], tr/val_loss:  1.343371/  1.487084, val:  55.00%, val_best:  55.00%, tr:  55.98%, tr_best:  55.98%\n",
      "epoch-2   lr=['0.0100000'], tr/val_loss:  1.140737/  1.503360, val:  54.58%, val_best:  55.00%, tr:  63.43%, tr_best:  63.43%\n",
      "epoch-3   lr=['0.0100000'], tr/val_loss:  0.979391/  1.664214, val:  56.25%, val_best:  56.25%, tr:  69.97%, tr_best:  69.97%\n",
      "epoch-4   lr=['0.0100000'], tr/val_loss:  0.930276/  1.596942, val:  62.08%, val_best:  62.08%, tr:  71.50%, tr_best:  71.50%\n",
      "epoch-5   lr=['0.0100000'], tr/val_loss:  0.872797/  1.417326, val:  60.42%, val_best:  62.08%, tr:  74.16%, tr_best:  74.16%\n",
      "epoch-6   lr=['0.0100000'], tr/val_loss:  0.761184/  1.619627, val:  61.25%, val_best:  62.08%, tr:  76.92%, tr_best:  76.92%\n",
      "epoch-7   lr=['0.0100000'], tr/val_loss:  0.826692/  1.788126, val:  63.33%, val_best:  63.33%, tr:  75.59%, tr_best:  76.92%\n",
      "epoch-8   lr=['0.0100000'], tr/val_loss:  0.712920/  1.667601, val:  61.25%, val_best:  63.33%, tr:  78.14%, tr_best:  78.14%\n",
      "epoch-9   lr=['0.0100000'], tr/val_loss:  0.639059/  1.823044, val:  63.75%, val_best:  63.75%, tr:  83.04%, tr_best:  83.04%\n",
      "epoch-10  lr=['0.0100000'], tr/val_loss:  0.619464/  1.751089, val:  68.33%, val_best:  68.33%, tr:  83.96%, tr_best:  83.96%\n",
      "epoch-11  lr=['0.0100000'], tr/val_loss:  0.527896/  1.950047, val:  70.83%, val_best:  70.83%, tr:  88.66%, tr_best:  88.66%\n",
      "epoch-12  lr=['0.0100000'], tr/val_loss:  0.514485/  2.040685, val:  71.25%, val_best:  71.25%, tr:  91.22%, tr_best:  91.22%\n",
      "epoch-13  lr=['0.0100000'], tr/val_loss:  0.558904/  2.246868, val:  70.83%, val_best:  71.25%, tr:  87.54%, tr_best:  91.22%\n",
      "epoch-14  lr=['0.0100000'], tr/val_loss:  0.474106/  2.682702, val:  67.08%, val_best:  71.25%, tr:  90.91%, tr_best:  91.22%\n",
      "epoch-15  lr=['0.0100000'], tr/val_loss:  0.465716/  2.427172, val:  75.42%, val_best:  75.42%, tr:  93.46%, tr_best:  93.46%\n",
      "epoch-16  lr=['0.0100000'], tr/val_loss:  0.464525/  2.971596, val:  69.58%, val_best:  75.42%, tr:  95.61%, tr_best:  95.61%\n",
      "epoch-17  lr=['0.0100000'], tr/val_loss:  0.455333/  2.331978, val:  77.92%, val_best:  77.92%, tr:  95.40%, tr_best:  95.61%\n",
      "epoch-18  lr=['0.0100000'], tr/val_loss:  0.371937/  2.963763, val:  66.25%, val_best:  77.92%, tr:  95.81%, tr_best:  95.81%\n",
      "epoch-19  lr=['0.0100000'], tr/val_loss:  0.365914/  2.699731, val:  69.58%, val_best:  77.92%, tr:  97.24%, tr_best:  97.24%\n",
      "epoch-20  lr=['0.0100000'], tr/val_loss:  0.298137/  3.345849, val:  68.33%, val_best:  77.92%, tr:  97.55%, tr_best:  97.55%\n",
      "epoch-21  lr=['0.0100000'], tr/val_loss:  0.321726/  3.257840, val:  66.25%, val_best:  77.92%, tr:  97.85%, tr_best:  97.85%\n",
      "epoch-22  lr=['0.0100000'], tr/val_loss:  0.304324/  3.250632, val:  74.17%, val_best:  77.92%, tr:  98.26%, tr_best:  98.26%\n",
      "epoch-23  lr=['0.0100000'], tr/val_loss:  0.484390/  3.128731, val:  71.25%, val_best:  77.92%, tr:  96.12%, tr_best:  98.26%\n",
      "epoch-24  lr=['0.0100000'], tr/val_loss:  0.392684/  3.444197, val:  72.08%, val_best:  77.92%, tr:  97.85%, tr_best:  98.26%\n",
      "epoch-25  lr=['0.0100000'], tr/val_loss:  0.307534/  3.505903, val:  72.92%, val_best:  77.92%, tr:  98.98%, tr_best:  98.98%\n",
      "epoch-26  lr=['0.0100000'], tr/val_loss:  0.297274/  3.392249, val:  72.08%, val_best:  77.92%, tr:  97.85%, tr_best:  98.98%\n",
      "epoch-27  lr=['0.0100000'], tr/val_loss:  0.370338/  3.589126, val:  73.33%, val_best:  77.92%, tr:  98.26%, tr_best:  98.98%\n",
      "epoch-28  lr=['0.0100000'], tr/val_loss:  0.356984/  3.208543, val:  73.75%, val_best:  77.92%, tr:  98.77%, tr_best:  98.98%\n",
      "epoch-29  lr=['0.0100000'], tr/val_loss:  0.280930/  3.730371, val:  68.33%, val_best:  77.92%, tr:  98.88%, tr_best:  98.98%\n",
      "epoch-30  lr=['0.0100000'], tr/val_loss:  0.274916/  3.841038, val:  72.92%, val_best:  77.92%, tr:  99.18%, tr_best:  99.18%\n",
      "epoch-31  lr=['0.0100000'], tr/val_loss:  0.215997/  3.970310, val:  74.58%, val_best:  77.92%, tr:  99.59%, tr_best:  99.59%\n",
      "epoch-32  lr=['0.0100000'], tr/val_loss:  0.263000/  3.791868, val:  78.75%, val_best:  78.75%, tr:  99.49%, tr_best:  99.59%\n",
      "epoch-33  lr=['0.0100000'], tr/val_loss:  0.435393/  3.872882, val:  75.00%, val_best:  78.75%, tr:  98.77%, tr_best:  99.59%\n",
      "epoch-34  lr=['0.0100000'], tr/val_loss:  0.263637/  4.246627, val:  71.25%, val_best:  78.75%, tr:  99.18%, tr_best:  99.59%\n",
      "epoch-35  lr=['0.0100000'], tr/val_loss:  0.252738/  4.202889, val:  74.58%, val_best:  78.75%, tr:  99.69%, tr_best:  99.69%\n",
      "epoch-36  lr=['0.0100000'], tr/val_loss:  0.204241/  4.309837, val:  76.25%, val_best:  78.75%, tr:  99.69%, tr_best:  99.69%\n",
      "epoch-37  lr=['0.0100000'], tr/val_loss:  0.178282/  4.675664, val:  73.75%, val_best:  78.75%, tr:  99.90%, tr_best:  99.90%\n",
      "epoch-38  lr=['0.0100000'], tr/val_loss:  0.268615/  4.646324, val:  74.58%, val_best:  78.75%, tr:  99.18%, tr_best:  99.90%\n",
      "epoch-39  lr=['0.0100000'], tr/val_loss:  0.226136/  4.305432, val:  78.75%, val_best:  78.75%, tr:  99.69%, tr_best:  99.90%\n",
      "epoch-40  lr=['0.0100000'], tr/val_loss:  0.209070/  4.686126, val:  77.08%, val_best:  78.75%, tr:  99.69%, tr_best:  99.90%\n",
      "epoch-41  lr=['0.0100000'], tr/val_loss:  0.211894/  4.945598, val:  69.58%, val_best:  78.75%, tr:  99.90%, tr_best:  99.90%\n",
      "epoch-42  lr=['0.0100000'], tr/val_loss:  0.392222/  4.695116, val:  81.25%, val_best:  81.25%, tr:  98.67%, tr_best:  99.90%\n",
      "epoch-43  lr=['0.0100000'], tr/val_loss:  0.353369/  5.010156, val:  73.33%, val_best:  81.25%, tr:  99.39%, tr_best:  99.90%\n",
      "epoch-44  lr=['0.0100000'], tr/val_loss:  0.307500/  4.767645, val:  78.75%, val_best:  81.25%, tr:  99.69%, tr_best:  99.90%\n",
      "epoch-45  lr=['0.0100000'], tr/val_loss:  0.279446/  4.704995, val:  78.75%, val_best:  81.25%, tr:  99.49%, tr_best:  99.90%\n",
      "epoch-46  lr=['0.0100000'], tr/val_loss:  0.275495/  5.082043, val:  72.92%, val_best:  81.25%, tr:  99.28%, tr_best:  99.90%\n",
      "epoch-47  lr=['0.0100000'], tr/val_loss:  0.218495/  5.076435, val:  78.75%, val_best:  81.25%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-48  lr=['0.0100000'], tr/val_loss:  0.236926/  5.443343, val:  76.25%, val_best:  81.25%, tr:  99.39%, tr_best: 100.00%\n",
      "epoch-49  lr=['0.0100000'], tr/val_loss:  0.282128/  5.616348, val:  72.92%, val_best:  81.25%, tr:  99.39%, tr_best: 100.00%\n",
      "epoch-50  lr=['0.0100000'], tr/val_loss:  0.242016/  5.652843, val:  74.58%, val_best:  81.25%, tr:  99.90%, tr_best: 100.00%\n",
      "epoch-51  lr=['0.0100000'], tr/val_loss:  0.252841/  5.797311, val:  74.58%, val_best:  81.25%, tr:  99.90%, tr_best: 100.00%\n",
      "epoch-52  lr=['0.0100000'], tr/val_loss:  0.304966/  5.373289, val:  76.67%, val_best:  81.25%, tr:  99.39%, tr_best: 100.00%\n",
      "epoch-53  lr=['0.0100000'], tr/val_loss:  0.235214/  5.382409, val:  76.67%, val_best:  81.25%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-54  lr=['0.0100000'], tr/val_loss:  0.307090/  5.128083, val:  77.92%, val_best:  81.25%, tr:  99.80%, tr_best: 100.00%\n",
      "epoch-55  lr=['0.0100000'], tr/val_loss:  0.309787/  5.630109, val:  75.42%, val_best:  81.25%, tr:  99.39%, tr_best: 100.00%\n",
      "epoch-56  lr=['0.0100000'], tr/val_loss:  0.298143/  5.634556, val:  77.50%, val_best:  81.25%, tr:  99.90%, tr_best: 100.00%\n",
      "epoch-57  lr=['0.0100000'], tr/val_loss:  0.235390/  5.486821, val:  75.42%, val_best:  81.25%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-58  lr=['0.0100000'], tr/val_loss:  0.241720/  5.913943, val:  76.67%, val_best:  81.25%, tr:  99.59%, tr_best: 100.00%\n",
      "epoch-59  lr=['0.0100000'], tr/val_loss:  0.199251/  6.150976, val:  73.33%, val_best:  81.25%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-60  lr=['0.0100000'], tr/val_loss:  0.194424/  5.742156, val:  76.67%, val_best:  81.25%, tr:  99.80%, tr_best: 100.00%\n",
      "epoch-61  lr=['0.0100000'], tr/val_loss:  0.291781/  6.007802, val:  73.75%, val_best:  81.25%, tr:  99.49%, tr_best: 100.00%\n",
      "epoch-62  lr=['0.0100000'], tr/val_loss:  0.243076/  5.867474, val:  78.33%, val_best:  81.25%, tr:  99.80%, tr_best: 100.00%\n",
      "epoch-63  lr=['0.0100000'], tr/val_loss:  0.254151/  5.762816, val:  77.92%, val_best:  81.25%, tr:  99.90%, tr_best: 100.00%\n",
      "epoch-64  lr=['0.0100000'], tr/val_loss:  0.238314/  6.038248, val:  75.00%, val_best:  81.25%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-65  lr=['0.0100000'], tr/val_loss:  0.194818/  6.049289, val:  76.25%, val_best:  81.25%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-66  lr=['0.0100000'], tr/val_loss:  0.209407/  6.135689, val:  77.92%, val_best:  81.25%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-67  lr=['0.0100000'], tr/val_loss:  0.306488/  6.203729, val:  75.00%, val_best:  81.25%, tr:  99.69%, tr_best: 100.00%\n",
      "epoch-68  lr=['0.0100000'], tr/val_loss:  0.328533/  5.966366, val:  77.08%, val_best:  81.25%, tr:  99.80%, tr_best: 100.00%\n",
      "epoch-69  lr=['0.0100000'], tr/val_loss:  0.334299/  6.589964, val:  74.58%, val_best:  81.25%, tr:  99.90%, tr_best: 100.00%\n",
      "epoch-70  lr=['0.0100000'], tr/val_loss:  0.376189/  6.305938, val:  76.25%, val_best:  81.25%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-71  lr=['0.0100000'], tr/val_loss:  0.387821/  6.885556, val:  70.42%, val_best:  81.25%, tr:  99.59%, tr_best: 100.00%\n",
      "epoch-72  lr=['0.0100000'], tr/val_loss:  0.379371/  5.869914, val:  74.58%, val_best:  81.25%, tr:  99.59%, tr_best: 100.00%\n",
      "epoch-73  lr=['0.0100000'], tr/val_loss:  0.339759/  6.532969, val:  71.25%, val_best:  81.25%, tr:  99.80%, tr_best: 100.00%\n",
      "epoch-74  lr=['0.0100000'], tr/val_loss:  0.375545/  6.055756, val:  75.83%, val_best:  81.25%, tr:  99.59%, tr_best: 100.00%\n",
      "epoch-75  lr=['0.0100000'], tr/val_loss:  0.338036/  6.291332, val:  72.08%, val_best:  81.25%, tr:  99.69%, tr_best: 100.00%\n",
      "epoch-76  lr=['0.0100000'], tr/val_loss:  0.420243/  6.981617, val:  70.42%, val_best:  81.25%, tr:  99.49%, tr_best: 100.00%\n",
      "epoch-77  lr=['0.0100000'], tr/val_loss:  0.472939/  6.486759, val:  75.83%, val_best:  81.25%, tr:  99.28%, tr_best: 100.00%\n",
      "epoch-78  lr=['0.0100000'], tr/val_loss:  0.527862/  6.516730, val:  72.50%, val_best:  81.25%, tr:  98.98%, tr_best: 100.00%\n",
      "epoch-79  lr=['0.0100000'], tr/val_loss:  0.483742/  6.991666, val:  73.33%, val_best:  81.25%, tr:  99.39%, tr_best: 100.00%\n",
      "epoch-80  lr=['0.0100000'], tr/val_loss:  0.573864/  6.718577, val:  70.42%, val_best:  81.25%, tr:  99.08%, tr_best: 100.00%\n",
      "epoch-81  lr=['0.0100000'], tr/val_loss:  0.466373/  6.703947, val:  75.00%, val_best:  81.25%, tr:  99.69%, tr_best: 100.00%\n",
      "epoch-82  lr=['0.0100000'], tr/val_loss:  0.493052/  6.926220, val:  72.50%, val_best:  81.25%, tr:  99.49%, tr_best: 100.00%\n",
      "epoch-83  lr=['0.0100000'], tr/val_loss:  0.634394/  7.071473, val:  71.25%, val_best:  81.25%, tr:  99.08%, tr_best: 100.00%\n",
      "epoch-84  lr=['0.0100000'], tr/val_loss:  0.422586/  6.796896, val:  74.17%, val_best:  81.25%, tr:  99.59%, tr_best: 100.00%\n",
      "epoch-85  lr=['0.0100000'], tr/val_loss:  0.464169/  6.446936, val:  73.33%, val_best:  81.25%, tr:  99.39%, tr_best: 100.00%\n",
      "epoch-86  lr=['0.0100000'], tr/val_loss:  0.362989/  5.992157, val:  77.92%, val_best:  81.25%, tr:  99.80%, tr_best: 100.00%\n",
      "epoch-87  lr=['0.0100000'], tr/val_loss:  0.439520/  6.597155, val:  75.83%, val_best:  81.25%, tr:  99.49%, tr_best: 100.00%\n",
      "epoch-88  lr=['0.0100000'], tr/val_loss:  0.404875/  6.424419, val:  77.50%, val_best:  81.25%, tr:  99.59%, tr_best: 100.00%\n",
      "epoch-89  lr=['0.0100000'], tr/val_loss:  0.369876/  6.412877, val:  78.33%, val_best:  81.25%, tr:  99.59%, tr_best: 100.00%\n",
      "epoch-90  lr=['0.0100000'], tr/val_loss:  0.376247/  6.245628, val:  75.42%, val_best:  81.25%, tr:  99.80%, tr_best: 100.00%\n",
      "epoch-91  lr=['0.0100000'], tr/val_loss:  0.404882/  7.357091, val:  75.00%, val_best:  81.25%, tr:  99.49%, tr_best: 100.00%\n",
      "epoch-92  lr=['0.0100000'], tr/val_loss:  0.683962/  6.273801, val:  75.00%, val_best:  81.25%, tr:  99.39%, tr_best: 100.00%\n",
      "epoch-93  lr=['0.0100000'], tr/val_loss:  0.929271/  6.045011, val:  77.08%, val_best:  81.25%, tr:  97.04%, tr_best: 100.00%\n",
      "epoch-94  lr=['0.0100000'], tr/val_loss:  0.534962/  5.970780, val:  75.42%, val_best:  81.25%, tr:  99.08%, tr_best: 100.00%\n",
      "epoch-95  lr=['0.0100000'], tr/val_loss:  0.609481/  5.767433, val:  79.17%, val_best:  81.25%, tr:  99.49%, tr_best: 100.00%\n",
      "epoch-96  lr=['0.0100000'], tr/val_loss:  0.586288/  5.766468, val:  78.75%, val_best:  81.25%, tr:  99.08%, tr_best: 100.00%\n",
      "epoch-97  lr=['0.0100000'], tr/val_loss:  0.646140/  6.486327, val:  73.33%, val_best:  81.25%, tr:  98.98%, tr_best: 100.00%\n",
      "epoch-98  lr=['0.0100000'], tr/val_loss:  0.561301/  6.183436, val:  79.58%, val_best:  81.25%, tr:  98.88%, tr_best: 100.00%\n",
      "epoch-99  lr=['0.0100000'], tr/val_loss:  0.461806/  6.717836, val:  75.00%, val_best:  81.25%, tr:  99.69%, tr_best: 100.00%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a70065527d7344509e620dea42a85193",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.006 MB of 0.006 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>iter_acc</td><td>▁▇▅▄▅▆▇▇████████████▇████████████████▇██</td></tr><tr><td>summary_val_acc</td><td>▁▂▄▄▄▆▅▇▅▅▆▆▅▇▇▆▇█▇▇▆▇▇▇▆▆▇▇▇▇▆▇▆▆▆▇▇▇█▆</td></tr><tr><td>tr_acc</td><td>▁▄▅▅▆▇▇▇████████████████████████████████</td></tr><tr><td>tr_epoch_loss</td><td>█▅▄▄▃▂▂▂▂▂▂▂▁▁▁▁▁▂▂▁▁▂▂▁▁▁▁▂▂▂▂▂▂▂▂▂▂▃▃▃</td></tr><tr><td>val_acc_best</td><td>▁▂▄▄▄▆▆▇▇▇▇▇▇▇▇▇▇███████████████████████</td></tr><tr><td>val_acc_now</td><td>▁▂▄▄▄▆▅▇▅▅▆▆▅▇▇▆▇█▇▇▆▇▇▇▆▆▇▇▇▇▆▇▆▆▆▇▇▇█▆</td></tr><tr><td>val_loss</td><td>▂▁▁▁▁▂▃▂▃▃▃▃▄▄▄▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇▇▇███▇▇▇▆▇</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>99</td></tr><tr><td>iter_acc</td><td>1.0</td></tr><tr><td>tr_acc</td><td>0.99694</td></tr><tr><td>tr_epoch_loss</td><td>0.46181</td></tr><tr><td>val_acc_best</td><td>0.8125</td></tr><tr><td>val_acc_now</td><td>0.75</td></tr><tr><td>val_loss</td><td>6.71784</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">royal-sweep-71</strong> at: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/j4tuwo0d' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/j4tuwo0d</a><br/> View project at: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>/data2/bh_wandb/wandb/run-20250430_004759-j4tuwo0d/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require(\"core\")`! See https://wandb.me/wandb-core for more information."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: t5flggxm with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBATCH: 16\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBN_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBPTT_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tDFA_on: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tIMAGE_SIZE: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tOTTT_input_trace_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tTIME: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tUDA_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \talpha_uda: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbias: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcfg: ['M', 'M', 200, 200]\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tchaching_on: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tconvTrue_fcFalse: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdata_path: /data2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tddp_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdenoise_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdvs_clipping: 5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdvs_duration: 100000\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepoch_num: 100\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \texclude_class: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \textra_train_dataset: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlast_lif: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.0001\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_sg_width: 3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_decay: 0.5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_init: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_reset: 10000\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_threshold: 0.25\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmerge_polarities: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmy_seed: 42\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnet_print: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_workers: 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer_what: SGD\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tpin_memory: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tpre_trained: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tpre_trained_path: net_save/save_now_net_weights_{unique_name}.pth\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \trate_coding: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tscheduler_name: no\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsingle_step: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsurrogate: hard_sigmoid\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_conv_kernel_size: 3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_conv_padding: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_conv_stride: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_trace_const1: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_trace_const2: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \ttdBN_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \ttrace_on: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \twhich_data: DVS_GESTURE_TONIC\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.19.10 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.17.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/data2/bh_wandb/wandb/run-20250430_005411-t5flggxm</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/t5flggxm' target=\"_blank\">proud-sweep-75</a></strong> to <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/6pj3lh8j' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/6pj3lh8j</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/6pj3lh8j' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/6pj3lh8j</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/t5flggxm' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/t5flggxm</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'single_step' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'my_seed' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'TIME' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BATCH' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'IMAGE_SIZE' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'which_data' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'data_path' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'rate_coding' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_init' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_decay' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_threshold' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_reset' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_sg_width' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_conv_kernel_size' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_conv_stride' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_conv_padding' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_trace_const1' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_trace_const2' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'pre_trained' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'convTrue_fcFalse' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'cfg' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'net_print' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'pre_trained_path' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'learning_rate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'epoch_num' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'tdBN_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BN_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'surrogate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BPTT_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'optimizer_what' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'scheduler_name' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'ddp_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'dvs_clipping' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'dvs_duration' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'DFA_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'trace_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'OTTT_input_trace_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'exclude_class' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'merge_polarities' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'denoise_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'extra_train_dataset' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'num_workers' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'chaching_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'pin_memory' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'UDA_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'alpha_uda' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'bias' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'last_lif' was locked by 'sweep' (ignored update).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "param {'devices': '0', 'single_step': True, 'unique_name': 'main', 'my_seed': 42, 'TIME': 10, 'BATCH': 16, 'IMAGE_SIZE': 128, 'which_data': 'DVS_GESTURE_TONIC', 'data_path': '/data2', 'rate_coding': False, 'lif_layer_v_init': 0, 'lif_layer_v_decay': 0.5, 'lif_layer_v_threshold': 0.25, 'lif_layer_v_reset': 10000, 'lif_layer_sg_width': 3, 'synapse_conv_kernel_size': 3, 'synapse_conv_stride': 1, 'synapse_conv_padding': 1, 'synapse_trace_const1': 1, 'synapse_trace_const2': 0, 'pre_trained': False, 'convTrue_fcFalse': False, 'cfg': ['M', 'M', 200, 200], 'net_print': True, 'pre_trained_path': 'net_save/save_now_net_weights_{unique_name}.pth', 'learning_rate': 0.0001, 'epoch_num': 100, 'tdBN_on': False, 'BN_on': False, 'surrogate': 'hard_sigmoid', 'BPTT_on': False, 'optimizer_what': 'SGD', 'scheduler_name': 'no', 'ddp_on': False, 'dvs_clipping': 5, 'dvs_duration': 100000, 'DFA_on': True, 'trace_on': True, 'OTTT_input_trace_on': False, 'exclude_class': True, 'merge_polarities': False, 'denoise_on': False, 'extra_train_dataset': 0, 'num_workers': 2, 'chaching_on': True, 'pin_memory': True, 'UDA_on': False, 'alpha_uda': 1, 'bias': True, 'last_lif': False, 'current epoch': 0} \n",
      "\n",
      "dataset_hash = ffa516e60c3efd5e0208f72b4c36cb84\n",
      "cache path exists\n",
      "\n",
      "device ==> cuda\n",
      "\n",
      "DataParallel(\n",
      "  (module): REBORN_MY_SNN_FC(\n",
      "    (layers): REBORN_MY_Sequential(\n",
      "      (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (2): DimChanger_for_FC()\n",
      "      (3): SYNAPSE_FC(in_features=2048, out_features=200, TIME=10, bias=True, sstep=True)\n",
      "      (4): LIF_layer(v_init=0, v_decay=0.5, v_threshold=0.25, v_reset=10000, sg_width=3, surrogate=hard_sigmoid, BPTT_on=False, trace_const1=1, trace_const2=0, TIME=10, sstep=True, trace_on=True)\n",
      "      (5): Feedback_Receiver()\n",
      "      (6): SYNAPSE_FC(in_features=200, out_features=200, TIME=10, bias=True, sstep=True)\n",
      "      (7): LIF_layer(v_init=0, v_decay=0.5, v_threshold=0.25, v_reset=10000, sg_width=3, surrogate=hard_sigmoid, BPTT_on=False, trace_const1=1, trace_const2=0, TIME=10, sstep=True, trace_on=True)\n",
      "      (8): Feedback_Receiver()\n",
      "      (9): SYNAPSE_FC(in_features=200, out_features=10, TIME=10, bias=True, sstep=True)\n",
      "      (DFA_top): Top_Gradient()\n",
      "    )\n",
      "  )\n",
      ")\n",
      "\n",
      "========================================================\n",
      "Trainable parameters: 452,010\n",
      "========================================================\n",
      "\n",
      "epoch-0   lr=['0.0001000'], tr/val_loss:  2.302698/  2.292768, val:  17.08%, val_best:  17.08%, tr:  12.46%, tr_best:  12.46%\n",
      "[module.layers.5] weight_fb parameter count: 2,000\n",
      "[module.layers.8] weight_fb parameter count: 2,000\n",
      "epoch-1   lr=['0.0001000'], tr/val_loss:  2.274752/  2.258935, val:  15.42%, val_best:  17.08%, tr:  17.47%, tr_best:  17.47%\n",
      "epoch-2   lr=['0.0001000'], tr/val_loss:  2.204992/  2.174848, val:  20.00%, val_best:  20.00%, tr:  21.25%, tr_best:  21.25%\n",
      "epoch-3   lr=['0.0001000'], tr/val_loss:  2.085248/  2.052755, val:  36.67%, val_best:  36.67%, tr:  36.67%, tr_best:  36.67%\n",
      "epoch-4   lr=['0.0001000'], tr/val_loss:  1.932786/  1.907182, val:  44.17%, val_best:  44.17%, tr:  44.74%, tr_best:  44.74%\n",
      "epoch-5   lr=['0.0001000'], tr/val_loss:  1.774296/  1.786407, val:  41.25%, val_best:  44.17%, tr:  46.68%, tr_best:  46.68%\n",
      "epoch-6   lr=['0.0001000'], tr/val_loss:  1.659975/  1.691252, val:  42.50%, val_best:  44.17%, tr:  51.07%, tr_best:  51.07%\n",
      "epoch-7   lr=['0.0001000'], tr/val_loss:  1.557328/  1.623603, val:  46.25%, val_best:  46.25%, tr:  55.77%, tr_best:  55.77%\n",
      "epoch-8   lr=['0.0001000'], tr/val_loss:  1.489562/  1.574490, val:  49.58%, val_best:  49.58%, tr:  56.28%, tr_best:  56.28%\n",
      "epoch-9   lr=['0.0001000'], tr/val_loss:  1.433274/  1.536899, val:  47.92%, val_best:  49.58%, tr:  57.30%, tr_best:  57.30%\n",
      "epoch-10  lr=['0.0001000'], tr/val_loss:  1.385136/  1.509164, val:  52.08%, val_best:  52.08%, tr:  59.55%, tr_best:  59.55%\n",
      "epoch-11  lr=['0.0001000'], tr/val_loss:  1.355187/  1.487221, val:  52.50%, val_best:  52.50%, tr:  60.67%, tr_best:  60.67%\n",
      "epoch-12  lr=['0.0001000'], tr/val_loss:  1.330998/  1.467402, val:  52.08%, val_best:  52.50%, tr:  60.98%, tr_best:  60.98%\n",
      "epoch-13  lr=['0.0001000'], tr/val_loss:  1.303529/  1.456255, val:  55.00%, val_best:  55.00%, tr:  64.25%, tr_best:  64.25%\n",
      "epoch-14  lr=['0.0001000'], tr/val_loss:  1.270272/  1.438672, val:  55.00%, val_best:  55.00%, tr:  62.82%, tr_best:  64.25%\n",
      "epoch-15  lr=['0.0001000'], tr/val_loss:  1.249672/  1.429348, val:  55.42%, val_best:  55.42%, tr:  63.33%, tr_best:  64.25%\n",
      "epoch-16  lr=['0.0001000'], tr/val_loss:  1.218952/  1.416096, val:  57.50%, val_best:  57.50%, tr:  65.07%, tr_best:  65.07%\n",
      "epoch-17  lr=['0.0001000'], tr/val_loss:  1.208867/  1.400289, val:  56.67%, val_best:  57.50%, tr:  65.37%, tr_best:  65.37%\n",
      "epoch-18  lr=['0.0001000'], tr/val_loss:  1.190412/  1.393940, val:  58.75%, val_best:  58.75%, tr:  67.31%, tr_best:  67.31%\n",
      "epoch-19  lr=['0.0001000'], tr/val_loss:  1.170019/  1.384895, val:  61.25%, val_best:  61.25%, tr:  65.17%, tr_best:  67.31%\n",
      "epoch-20  lr=['0.0001000'], tr/val_loss:  1.153712/  1.379607, val:  59.17%, val_best:  61.25%, tr:  66.39%, tr_best:  67.31%\n",
      "epoch-21  lr=['0.0001000'], tr/val_loss:  1.136266/  1.371371, val:  60.00%, val_best:  61.25%, tr:  68.13%, tr_best:  68.13%\n",
      "epoch-22  lr=['0.0001000'], tr/val_loss:  1.118979/  1.368522, val:  59.58%, val_best:  61.25%, tr:  67.62%, tr_best:  68.13%\n",
      "epoch-23  lr=['0.0001000'], tr/val_loss:  1.101579/  1.357459, val:  61.67%, val_best:  61.67%, tr:  69.56%, tr_best:  69.56%\n",
      "epoch-24  lr=['0.0001000'], tr/val_loss:  1.091408/  1.349270, val:  62.08%, val_best:  62.08%, tr:  69.87%, tr_best:  69.87%\n",
      "epoch-25  lr=['0.0001000'], tr/val_loss:  1.079010/  1.341327, val:  60.83%, val_best:  62.08%, tr:  72.01%, tr_best:  72.01%\n",
      "epoch-26  lr=['0.0001000'], tr/val_loss:  1.067978/  1.329979, val:  61.25%, val_best:  62.08%, tr:  68.85%, tr_best:  72.01%\n",
      "epoch-27  lr=['0.0001000'], tr/val_loss:  1.053607/  1.319202, val:  63.33%, val_best:  63.33%, tr:  71.40%, tr_best:  72.01%\n",
      "epoch-28  lr=['0.0001000'], tr/val_loss:  1.056343/  1.308584, val:  63.33%, val_best:  63.33%, tr:  70.68%, tr_best:  72.01%\n",
      "epoch-29  lr=['0.0001000'], tr/val_loss:  1.039373/  1.312725, val:  62.50%, val_best:  63.33%, tr:  71.20%, tr_best:  72.01%\n",
      "epoch-30  lr=['0.0001000'], tr/val_loss:  1.026930/  1.310829, val:  64.17%, val_best:  64.17%, tr:  72.11%, tr_best:  72.11%\n",
      "epoch-31  lr=['0.0001000'], tr/val_loss:  1.020496/  1.306484, val:  64.58%, val_best:  64.58%, tr:  70.99%, tr_best:  72.11%\n",
      "epoch-32  lr=['0.0001000'], tr/val_loss:  1.012640/  1.304612, val:  64.17%, val_best:  64.58%, tr:  73.44%, tr_best:  73.44%\n",
      "epoch-33  lr=['0.0001000'], tr/val_loss:  1.010994/  1.296196, val:  65.00%, val_best:  65.00%, tr:  72.63%, tr_best:  73.44%\n",
      "epoch-34  lr=['0.0001000'], tr/val_loss:  0.995898/  1.289801, val:  66.25%, val_best:  66.25%, tr:  73.65%, tr_best:  73.65%\n",
      "epoch-35  lr=['0.0001000'], tr/val_loss:  0.987727/  1.293414, val:  65.83%, val_best:  66.25%, tr:  74.36%, tr_best:  74.36%\n",
      "epoch-36  lr=['0.0001000'], tr/val_loss:  0.986436/  1.287196, val:  66.25%, val_best:  66.25%, tr:  73.65%, tr_best:  74.36%\n",
      "epoch-37  lr=['0.0001000'], tr/val_loss:  0.974112/  1.281370, val:  63.75%, val_best:  66.25%, tr:  74.97%, tr_best:  74.97%\n",
      "epoch-38  lr=['0.0001000'], tr/val_loss:  0.973239/  1.280752, val:  65.00%, val_best:  66.25%, tr:  74.57%, tr_best:  74.97%\n",
      "epoch-39  lr=['0.0001000'], tr/val_loss:  0.963944/  1.275829, val:  65.00%, val_best:  66.25%, tr:  75.08%, tr_best:  75.08%\n",
      "epoch-40  lr=['0.0001000'], tr/val_loss:  0.952409/  1.275715, val:  65.83%, val_best:  66.25%, tr:  74.67%, tr_best:  75.08%\n",
      "epoch-41  lr=['0.0001000'], tr/val_loss:  0.955548/  1.272587, val:  67.50%, val_best:  67.50%, tr:  77.83%, tr_best:  77.83%\n",
      "epoch-42  lr=['0.0001000'], tr/val_loss:  0.935081/  1.272249, val:  68.75%, val_best:  68.75%, tr:  79.16%, tr_best:  79.16%\n",
      "epoch-43  lr=['0.0001000'], tr/val_loss:  0.936234/  1.270575, val:  66.25%, val_best:  68.75%, tr:  77.83%, tr_best:  79.16%\n",
      "epoch-44  lr=['0.0001000'], tr/val_loss:  0.929215/  1.260638, val:  65.42%, val_best:  68.75%, tr:  76.92%, tr_best:  79.16%\n",
      "epoch-45  lr=['0.0001000'], tr/val_loss:  0.921339/  1.262255, val:  69.17%, val_best:  69.17%, tr:  78.65%, tr_best:  79.16%\n",
      "epoch-46  lr=['0.0001000'], tr/val_loss:  0.915414/  1.262135, val:  68.33%, val_best:  69.17%, tr:  79.78%, tr_best:  79.78%\n",
      "epoch-47  lr=['0.0001000'], tr/val_loss:  0.918281/  1.257876, val:  68.33%, val_best:  69.17%, tr:  78.04%, tr_best:  79.78%\n",
      "epoch-48  lr=['0.0001000'], tr/val_loss:  0.908801/  1.261870, val:  68.33%, val_best:  69.17%, tr:  80.69%, tr_best:  80.69%\n",
      "epoch-49  lr=['0.0001000'], tr/val_loss:  0.899446/  1.256992, val:  65.83%, val_best:  69.17%, tr:  79.57%, tr_best:  80.69%\n",
      "epoch-50  lr=['0.0001000'], tr/val_loss:  0.893979/  1.256333, val:  65.83%, val_best:  69.17%, tr:  80.59%, tr_best:  80.69%\n",
      "epoch-51  lr=['0.0001000'], tr/val_loss:  0.892416/  1.253569, val:  71.25%, val_best:  71.25%, tr:  79.98%, tr_best:  80.69%\n",
      "epoch-52  lr=['0.0001000'], tr/val_loss:  0.883906/  1.256265, val:  67.92%, val_best:  71.25%, tr:  80.80%, tr_best:  80.80%\n",
      "epoch-53  lr=['0.0001000'], tr/val_loss:  0.875784/  1.251568, val:  70.00%, val_best:  71.25%, tr:  82.53%, tr_best:  82.53%\n",
      "epoch-54  lr=['0.0001000'], tr/val_loss:  0.870680/  1.255640, val:  69.58%, val_best:  71.25%, tr:  83.55%, tr_best:  83.55%\n",
      "epoch-55  lr=['0.0001000'], tr/val_loss:  0.865348/  1.258469, val:  70.83%, val_best:  71.25%, tr:  83.76%, tr_best:  83.76%\n",
      "epoch-56  lr=['0.0001000'], tr/val_loss:  0.853171/  1.251597, val:  69.58%, val_best:  71.25%, tr:  85.29%, tr_best:  85.29%\n",
      "epoch-57  lr=['0.0001000'], tr/val_loss:  0.851955/  1.259470, val:  69.17%, val_best:  71.25%, tr:  83.86%, tr_best:  85.29%\n",
      "epoch-58  lr=['0.0001000'], tr/val_loss:  0.841909/  1.255540, val:  68.33%, val_best:  71.25%, tr:  84.37%, tr_best:  85.29%\n",
      "epoch-59  lr=['0.0001000'], tr/val_loss:  0.839158/  1.255408, val:  68.75%, val_best:  71.25%, tr:  84.78%, tr_best:  85.29%\n",
      "epoch-60  lr=['0.0001000'], tr/val_loss:  0.832510/  1.254215, val:  69.58%, val_best:  71.25%, tr:  82.94%, tr_best:  85.29%\n",
      "epoch-61  lr=['0.0001000'], tr/val_loss:  0.833360/  1.259571, val:  68.75%, val_best:  71.25%, tr:  85.80%, tr_best:  85.80%\n",
      "epoch-62  lr=['0.0001000'], tr/val_loss:  0.826951/  1.255235, val:  70.00%, val_best:  71.25%, tr:  85.60%, tr_best:  85.80%\n",
      "epoch-63  lr=['0.0001000'], tr/val_loss:  0.818573/  1.248546, val:  70.42%, val_best:  71.25%, tr:  86.41%, tr_best:  86.41%\n",
      "epoch-64  lr=['0.0001000'], tr/val_loss:  0.810193/  1.257740, val:  69.17%, val_best:  71.25%, tr:  87.23%, tr_best:  87.23%\n",
      "epoch-65  lr=['0.0001000'], tr/val_loss:  0.811643/  1.256131, val:  70.00%, val_best:  71.25%, tr:  86.52%, tr_best:  87.23%\n",
      "epoch-66  lr=['0.0001000'], tr/val_loss:  0.806954/  1.246399, val:  72.50%, val_best:  72.50%, tr:  87.44%, tr_best:  87.44%\n",
      "epoch-67  lr=['0.0001000'], tr/val_loss:  0.809792/  1.260046, val:  70.42%, val_best:  72.50%, tr:  87.64%, tr_best:  87.64%\n",
      "epoch-68  lr=['0.0001000'], tr/val_loss:  0.795566/  1.254603, val:  72.08%, val_best:  72.50%, tr:  86.11%, tr_best:  87.64%\n",
      "epoch-69  lr=['0.0001000'], tr/val_loss:  0.788062/  1.258137, val:  70.83%, val_best:  72.50%, tr:  88.36%, tr_best:  88.36%\n",
      "epoch-70  lr=['0.0001000'], tr/val_loss:  0.784680/  1.262427, val:  70.83%, val_best:  72.50%, tr:  88.76%, tr_best:  88.76%\n",
      "epoch-71  lr=['0.0001000'], tr/val_loss:  0.778202/  1.254902, val:  69.58%, val_best:  72.50%, tr:  89.48%, tr_best:  89.48%\n",
      "epoch-72  lr=['0.0001000'], tr/val_loss:  0.770891/  1.256913, val:  70.83%, val_best:  72.50%, tr:  87.64%, tr_best:  89.48%\n",
      "epoch-73  lr=['0.0001000'], tr/val_loss:  0.769780/  1.253805, val:  70.42%, val_best:  72.50%, tr:  89.79%, tr_best:  89.79%\n",
      "epoch-74  lr=['0.0001000'], tr/val_loss:  0.762907/  1.256425, val:  69.58%, val_best:  72.50%, tr:  88.36%, tr_best:  89.79%\n",
      "epoch-75  lr=['0.0001000'], tr/val_loss:  0.762055/  1.254840, val:  70.00%, val_best:  72.50%, tr:  89.27%, tr_best:  89.79%\n",
      "epoch-76  lr=['0.0001000'], tr/val_loss:  0.745042/  1.268152, val:  69.58%, val_best:  72.50%, tr:  90.19%, tr_best:  90.19%\n",
      "epoch-77  lr=['0.0001000'], tr/val_loss:  0.754839/  1.263077, val:  70.83%, val_best:  72.50%, tr:  91.01%, tr_best:  91.01%\n",
      "epoch-78  lr=['0.0001000'], tr/val_loss:  0.741604/  1.259577, val:  71.67%, val_best:  72.50%, tr:  90.40%, tr_best:  91.01%\n",
      "epoch-79  lr=['0.0001000'], tr/val_loss:  0.739925/  1.266422, val:  70.42%, val_best:  72.50%, tr:  89.48%, tr_best:  91.01%\n",
      "epoch-80  lr=['0.0001000'], tr/val_loss:  0.734950/  1.262501, val:  71.67%, val_best:  72.50%, tr:  89.79%, tr_best:  91.01%\n",
      "epoch-81  lr=['0.0001000'], tr/val_loss:  0.729619/  1.267241, val:  71.67%, val_best:  72.50%, tr:  91.42%, tr_best:  91.42%\n",
      "epoch-82  lr=['0.0001000'], tr/val_loss:  0.727231/  1.262265, val:  71.67%, val_best:  72.50%, tr:  91.11%, tr_best:  91.42%\n",
      "epoch-83  lr=['0.0001000'], tr/val_loss:  0.724686/  1.267102, val:  73.33%, val_best:  73.33%, tr:  92.03%, tr_best:  92.03%\n",
      "epoch-84  lr=['0.0001000'], tr/val_loss:  0.722775/  1.276169, val:  71.67%, val_best:  73.33%, tr:  91.73%, tr_best:  92.03%\n",
      "epoch-85  lr=['0.0001000'], tr/val_loss:  0.718485/  1.276992, val:  70.83%, val_best:  73.33%, tr:  92.03%, tr_best:  92.03%\n",
      "epoch-86  lr=['0.0001000'], tr/val_loss:  0.709335/  1.275546, val:  72.08%, val_best:  73.33%, tr:  92.13%, tr_best:  92.13%\n",
      "epoch-87  lr=['0.0001000'], tr/val_loss:  0.709095/  1.272285, val:  72.08%, val_best:  73.33%, tr:  91.93%, tr_best:  92.13%\n",
      "epoch-88  lr=['0.0001000'], tr/val_loss:  0.701422/  1.280483, val:  70.00%, val_best:  73.33%, tr:  92.44%, tr_best:  92.44%\n",
      "epoch-89  lr=['0.0001000'], tr/val_loss:  0.694418/  1.285691, val:  70.42%, val_best:  73.33%, tr:  92.65%, tr_best:  92.65%\n",
      "epoch-90  lr=['0.0001000'], tr/val_loss:  0.695371/  1.278757, val:  72.08%, val_best:  73.33%, tr:  92.95%, tr_best:  92.95%\n",
      "epoch-91  lr=['0.0001000'], tr/val_loss:  0.682746/  1.277684, val:  71.67%, val_best:  73.33%, tr:  93.05%, tr_best:  93.05%\n",
      "epoch-92  lr=['0.0001000'], tr/val_loss:  0.689662/  1.289693, val:  70.83%, val_best:  73.33%, tr:  92.75%, tr_best:  93.05%\n",
      "epoch-93  lr=['0.0001000'], tr/val_loss:  0.683175/  1.289434, val:  73.33%, val_best:  73.33%, tr:  92.95%, tr_best:  93.05%\n",
      "epoch-94  lr=['0.0001000'], tr/val_loss:  0.681503/  1.288427, val:  71.25%, val_best:  73.33%, tr:  92.95%, tr_best:  93.05%\n",
      "epoch-95  lr=['0.0001000'], tr/val_loss:  0.671056/  1.288039, val:  71.25%, val_best:  73.33%, tr:  93.16%, tr_best:  93.16%\n",
      "epoch-96  lr=['0.0001000'], tr/val_loss:  0.668530/  1.291209, val:  71.67%, val_best:  73.33%, tr:  93.97%, tr_best:  93.97%\n",
      "epoch-97  lr=['0.0001000'], tr/val_loss:  0.665018/  1.293126, val:  72.92%, val_best:  73.33%, tr:  93.05%, tr_best:  93.97%\n",
      "epoch-98  lr=['0.0001000'], tr/val_loss:  0.663100/  1.292838, val:  72.50%, val_best:  73.33%, tr:  93.97%, tr_best:  93.97%\n",
      "epoch-99  lr=['0.0001000'], tr/val_loss:  0.656817/  1.297092, val:  73.75%, val_best:  73.75%, tr:  93.56%, tr_best:  93.97%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "06c35797289843bf8cc0c981b25ae443",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.006 MB of 0.006 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>iter_acc</td><td>▁▃▁▃▅▅▅▅▃▅▇▇▅▅▅▆▇▅▇▅▇▇▅▇█▇▇██▆▇▇▇▇▇▇▇▇█▇</td></tr><tr><td>summary_val_acc</td><td>▁▁▄▅▅▅▆▆▇▆▇▇▇▇▇▇▇▇▇▇▇▇██▇▇██████████████</td></tr><tr><td>tr_acc</td><td>▁▂▄▅▅▅▅▆▆▆▆▆▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇█████████████</td></tr><tr><td>tr_epoch_loss</td><td>██▆▅▄▄▄▃▃▃▃▃▃▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_acc_best</td><td>▁▁▄▅▅▅▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇███████████████████</td></tr><tr><td>val_acc_now</td><td>▁▁▄▅▅▅▆▆▇▆▇▇▇▇▇▇▇▇▇▇▇▇██▇▇██████████████</td></tr><tr><td>val_loss</td><td>█▇▅▃▃▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>99</td></tr><tr><td>iter_acc</td><td>1.0</td></tr><tr><td>tr_acc</td><td>0.93565</td></tr><tr><td>tr_epoch_loss</td><td>0.65682</td></tr><tr><td>val_acc_best</td><td>0.7375</td></tr><tr><td>val_acc_now</td><td>0.7375</td></tr><tr><td>val_loss</td><td>1.29709</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">proud-sweep-75</strong> at: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/t5flggxm' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/t5flggxm</a><br/> View project at: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>/data2/bh_wandb/wandb/run-20250430_005411-t5flggxm/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require(\"core\")`! See https://wandb.me/wandb-core for more information."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: yfy58is9 with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBATCH: 16\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBN_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBPTT_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tDFA_on: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tIMAGE_SIZE: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tOTTT_input_trace_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tTIME: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tUDA_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \talpha_uda: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbias: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcfg: ['M', 'M', 200, 200]\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tchaching_on: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tconvTrue_fcFalse: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdata_path: /data2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tddp_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdenoise_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdvs_clipping: 5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdvs_duration: 100000\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepoch_num: 100\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \texclude_class: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \textra_train_dataset: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlast_lif: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.001\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_sg_width: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_decay: 0.5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_init: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_reset: 10000\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_threshold: 0.25\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmerge_polarities: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmy_seed: 42\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnet_print: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_workers: 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer_what: SGD\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tpin_memory: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tpre_trained: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tpre_trained_path: net_save/save_now_net_weights_{unique_name}.pth\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \trate_coding: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tscheduler_name: no\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsingle_step: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsurrogate: hard_sigmoid\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_conv_kernel_size: 3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_conv_padding: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_conv_stride: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_trace_const1: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_trace_const2: 0.5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \ttdBN_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \ttrace_on: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \twhich_data: DVS_GESTURE_TONIC\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.19.10 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.17.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/data2/bh_wandb/wandb/run-20250430_010106-yfy58is9</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/yfy58is9' target=\"_blank\">youthful-sweep-79</a></strong> to <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/6pj3lh8j' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/6pj3lh8j</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/6pj3lh8j' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/6pj3lh8j</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/yfy58is9' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/yfy58is9</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'single_step' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'my_seed' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'TIME' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BATCH' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'IMAGE_SIZE' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'which_data' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'data_path' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'rate_coding' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_init' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_decay' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_threshold' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_reset' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_sg_width' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_conv_kernel_size' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_conv_stride' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_conv_padding' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_trace_const1' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_trace_const2' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'pre_trained' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'convTrue_fcFalse' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'cfg' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'net_print' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'pre_trained_path' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'learning_rate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'epoch_num' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'tdBN_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BN_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'surrogate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BPTT_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'optimizer_what' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'scheduler_name' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'ddp_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'dvs_clipping' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'dvs_duration' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'DFA_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'trace_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'OTTT_input_trace_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'exclude_class' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'merge_polarities' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'denoise_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'extra_train_dataset' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'num_workers' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'chaching_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'pin_memory' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'UDA_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'alpha_uda' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'bias' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'last_lif' was locked by 'sweep' (ignored update).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "param {'devices': '0', 'single_step': True, 'unique_name': 'main', 'my_seed': 42, 'TIME': 10, 'BATCH': 16, 'IMAGE_SIZE': 128, 'which_data': 'DVS_GESTURE_TONIC', 'data_path': '/data2', 'rate_coding': False, 'lif_layer_v_init': 0, 'lif_layer_v_decay': 0.5, 'lif_layer_v_threshold': 0.25, 'lif_layer_v_reset': 10000, 'lif_layer_sg_width': 1, 'synapse_conv_kernel_size': 3, 'synapse_conv_stride': 1, 'synapse_conv_padding': 1, 'synapse_trace_const1': 1, 'synapse_trace_const2': 0.5, 'pre_trained': False, 'convTrue_fcFalse': False, 'cfg': ['M', 'M', 200, 200], 'net_print': True, 'pre_trained_path': 'net_save/save_now_net_weights_{unique_name}.pth', 'learning_rate': 0.001, 'epoch_num': 100, 'tdBN_on': False, 'BN_on': False, 'surrogate': 'hard_sigmoid', 'BPTT_on': False, 'optimizer_what': 'SGD', 'scheduler_name': 'no', 'ddp_on': False, 'dvs_clipping': 5, 'dvs_duration': 100000, 'DFA_on': True, 'trace_on': True, 'OTTT_input_trace_on': False, 'exclude_class': True, 'merge_polarities': False, 'denoise_on': False, 'extra_train_dataset': 0, 'num_workers': 2, 'chaching_on': True, 'pin_memory': True, 'UDA_on': False, 'alpha_uda': 1, 'bias': True, 'last_lif': False, 'current epoch': 0} \n",
      "\n",
      "dataset_hash = ffa516e60c3efd5e0208f72b4c36cb84\n",
      "cache path exists\n",
      "\n",
      "device ==> cuda\n",
      "\n",
      "DataParallel(\n",
      "  (module): REBORN_MY_SNN_FC(\n",
      "    (layers): REBORN_MY_Sequential(\n",
      "      (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (2): DimChanger_for_FC()\n",
      "      (3): SYNAPSE_FC(in_features=2048, out_features=200, TIME=10, bias=True, sstep=True)\n",
      "      (4): LIF_layer(v_init=0, v_decay=0.5, v_threshold=0.25, v_reset=10000, sg_width=1, surrogate=hard_sigmoid, BPTT_on=False, trace_const1=1, trace_const2=0.5, TIME=10, sstep=True, trace_on=True)\n",
      "      (5): Feedback_Receiver()\n",
      "      (6): SYNAPSE_FC(in_features=200, out_features=200, TIME=10, bias=True, sstep=True)\n",
      "      (7): LIF_layer(v_init=0, v_decay=0.5, v_threshold=0.25, v_reset=10000, sg_width=1, surrogate=hard_sigmoid, BPTT_on=False, trace_const1=1, trace_const2=0.5, TIME=10, sstep=True, trace_on=True)\n",
      "      (8): Feedback_Receiver()\n",
      "      (9): SYNAPSE_FC(in_features=200, out_features=10, TIME=10, bias=True, sstep=True)\n",
      "      (DFA_top): Top_Gradient()\n",
      "    )\n",
      "  )\n",
      ")\n",
      "\n",
      "========================================================\n",
      "Trainable parameters: 452,010\n",
      "========================================================\n",
      "\n",
      "epoch-0   lr=['0.0010000'], tr/val_loss:  2.193166/  1.939117, val:  36.25%, val_best:  36.25%, tr:  18.39%, tr_best:  18.39%\n",
      "[module.layers.5] weight_fb parameter count: 2,000\n",
      "[module.layers.8] weight_fb parameter count: 2,000\n",
      "epoch-1   lr=['0.0010000'], tr/val_loss:  1.596445/  1.538843, val:  56.25%, val_best:  56.25%, tr:  49.44%, tr_best:  49.44%\n",
      "epoch-2   lr=['0.0010000'], tr/val_loss:  1.374148/  1.504866, val:  55.00%, val_best:  56.25%, tr:  57.61%, tr_best:  57.61%\n",
      "epoch-3   lr=['0.0010000'], tr/val_loss:  1.272936/  1.492908, val:  58.75%, val_best:  58.75%, tr:  63.84%, tr_best:  63.84%\n",
      "epoch-4   lr=['0.0010000'], tr/val_loss:  1.231004/  1.469412, val:  58.75%, val_best:  58.75%, tr:  63.13%, tr_best:  63.84%\n",
      "epoch-5   lr=['0.0010000'], tr/val_loss:  1.181969/  1.432151, val:  64.17%, val_best:  64.17%, tr:  65.37%, tr_best:  65.37%\n",
      "epoch-6   lr=['0.0010000'], tr/val_loss:  1.130880/  1.435866, val:  61.25%, val_best:  64.17%, tr:  67.72%, tr_best:  67.72%\n",
      "epoch-7   lr=['0.0010000'], tr/val_loss:  1.124110/  1.450976, val:  62.08%, val_best:  64.17%, tr:  67.93%, tr_best:  67.93%\n",
      "epoch-8   lr=['0.0010000'], tr/val_loss:  1.087939/  1.483909, val:  60.00%, val_best:  64.17%, tr:  70.48%, tr_best:  70.48%\n",
      "epoch-9   lr=['0.0010000'], tr/val_loss:  1.081649/  1.512360, val:  59.17%, val_best:  64.17%, tr:  72.73%, tr_best:  72.73%\n",
      "epoch-10  lr=['0.0010000'], tr/val_loss:  1.075077/  1.557770, val:  56.67%, val_best:  64.17%, tr:  72.11%, tr_best:  72.73%\n",
      "epoch-11  lr=['0.0010000'], tr/val_loss:  1.031409/  1.512975, val:  61.25%, val_best:  64.17%, tr:  75.69%, tr_best:  75.69%\n",
      "epoch-12  lr=['0.0010000'], tr/val_loss:  1.032472/  1.569944, val:  58.75%, val_best:  64.17%, tr:  75.49%, tr_best:  75.69%\n",
      "epoch-13  lr=['0.0010000'], tr/val_loss:  1.024697/  1.581399, val:  63.75%, val_best:  64.17%, tr:  78.04%, tr_best:  78.04%\n",
      "epoch-14  lr=['0.0010000'], tr/val_loss:  0.989958/  1.774732, val:  57.92%, val_best:  64.17%, tr:  77.83%, tr_best:  78.04%\n",
      "epoch-15  lr=['0.0010000'], tr/val_loss:  0.988663/  1.699107, val:  62.50%, val_best:  64.17%, tr:  78.86%, tr_best:  78.86%\n",
      "epoch-16  lr=['0.0010000'], tr/val_loss:  1.001385/  1.668627, val:  62.92%, val_best:  64.17%, tr:  78.75%, tr_best:  78.86%\n",
      "epoch-17  lr=['0.0010000'], tr/val_loss:  0.965800/  1.698771, val:  62.50%, val_best:  64.17%, tr:  84.58%, tr_best:  84.58%\n",
      "epoch-18  lr=['0.0010000'], tr/val_loss:  0.968380/  1.842503, val:  60.83%, val_best:  64.17%, tr:  82.84%, tr_best:  84.58%\n",
      "epoch-19  lr=['0.0010000'], tr/val_loss:  0.976029/  1.809729, val:  65.00%, val_best:  65.00%, tr:  81.51%, tr_best:  84.58%\n",
      "epoch-20  lr=['0.0010000'], tr/val_loss:  0.953923/  1.939612, val:  62.08%, val_best:  65.00%, tr:  85.19%, tr_best:  85.19%\n",
      "epoch-21  lr=['0.0010000'], tr/val_loss:  0.938328/  1.932675, val:  62.92%, val_best:  65.00%, tr:  85.19%, tr_best:  85.19%\n",
      "epoch-22  lr=['0.0010000'], tr/val_loss:  0.946192/  1.963732, val:  63.75%, val_best:  65.00%, tr:  85.09%, tr_best:  85.19%\n",
      "epoch-23  lr=['0.0010000'], tr/val_loss:  0.921071/  2.004754, val:  62.92%, val_best:  65.00%, tr:  88.87%, tr_best:  88.87%\n",
      "epoch-24  lr=['0.0010000'], tr/val_loss:  0.912818/  2.081909, val:  64.17%, val_best:  65.00%, tr:  90.40%, tr_best:  90.40%\n",
      "epoch-25  lr=['0.0010000'], tr/val_loss:  0.924512/  2.089756, val:  65.83%, val_best:  65.83%, tr:  89.89%, tr_best:  90.40%\n",
      "epoch-26  lr=['0.0010000'], tr/val_loss:  0.938146/  2.147205, val:  64.58%, val_best:  65.83%, tr:  89.27%, tr_best:  90.40%\n",
      "epoch-27  lr=['0.0010000'], tr/val_loss:  0.919848/  2.259307, val:  60.83%, val_best:  65.83%, tr:  90.91%, tr_best:  90.91%\n",
      "epoch-28  lr=['0.0010000'], tr/val_loss:  0.928758/  2.266344, val:  67.50%, val_best:  67.50%, tr:  90.40%, tr_best:  90.91%\n",
      "epoch-29  lr=['0.0010000'], tr/val_loss:  0.904377/  2.418868, val:  58.33%, val_best:  67.50%, tr:  93.36%, tr_best:  93.36%\n",
      "epoch-30  lr=['0.0010000'], tr/val_loss:  0.901257/  2.436279, val:  64.58%, val_best:  67.50%, tr:  93.46%, tr_best:  93.46%\n",
      "epoch-31  lr=['0.0010000'], tr/val_loss:  0.918823/  2.499423, val:  63.33%, val_best:  67.50%, tr:  91.32%, tr_best:  93.46%\n",
      "epoch-32  lr=['0.0010000'], tr/val_loss:  0.907202/  2.583228, val:  64.17%, val_best:  67.50%, tr:  92.13%, tr_best:  93.46%\n",
      "epoch-33  lr=['0.0010000'], tr/val_loss:  0.927218/  2.594553, val:  62.08%, val_best:  67.50%, tr:  92.75%, tr_best:  93.46%\n",
      "epoch-34  lr=['0.0010000'], tr/val_loss:  0.877721/  2.682896, val:  60.42%, val_best:  67.50%, tr:  95.71%, tr_best:  95.71%\n",
      "epoch-35  lr=['0.0010000'], tr/val_loss:  0.927637/  2.886584, val:  60.00%, val_best:  67.50%, tr:  91.52%, tr_best:  95.71%\n",
      "epoch-36  lr=['0.0010000'], tr/val_loss:  0.897621/  2.790205, val:  62.08%, val_best:  67.50%, tr:  93.97%, tr_best:  95.71%\n",
      "epoch-37  lr=['0.0010000'], tr/val_loss:  0.897012/  2.864525, val:  64.58%, val_best:  67.50%, tr:  95.30%, tr_best:  95.71%\n",
      "epoch-38  lr=['0.0010000'], tr/val_loss:  0.901069/  2.892008, val:  64.17%, val_best:  67.50%, tr:  95.91%, tr_best:  95.91%\n",
      "epoch-39  lr=['0.0010000'], tr/val_loss:  0.885706/  2.971587, val:  65.83%, val_best:  67.50%, tr:  96.73%, tr_best:  96.73%\n",
      "epoch-40  lr=['0.0010000'], tr/val_loss:  0.921253/  3.140809, val:  66.67%, val_best:  67.50%, tr:  93.77%, tr_best:  96.73%\n",
      "epoch-41  lr=['0.0010000'], tr/val_loss:  0.900491/  3.166608, val:  62.08%, val_best:  67.50%, tr:  96.02%, tr_best:  96.73%\n",
      "epoch-42  lr=['0.0010000'], tr/val_loss:  0.885927/  3.123917, val:  65.42%, val_best:  67.50%, tr:  96.22%, tr_best:  96.73%\n",
      "epoch-43  lr=['0.0010000'], tr/val_loss:  0.883350/  3.226336, val:  64.17%, val_best:  67.50%, tr:  96.73%, tr_best:  96.73%\n",
      "epoch-44  lr=['0.0010000'], tr/val_loss:  0.868177/  3.336858, val:  65.83%, val_best:  67.50%, tr:  96.53%, tr_best:  96.73%\n",
      "epoch-45  lr=['0.0010000'], tr/val_loss:  0.879438/  3.476895, val:  64.58%, val_best:  67.50%, tr:  97.24%, tr_best:  97.24%\n",
      "epoch-46  lr=['0.0010000'], tr/val_loss:  0.876472/  3.444482, val:  67.50%, val_best:  67.50%, tr:  97.04%, tr_best:  97.24%\n",
      "epoch-47  lr=['0.0010000'], tr/val_loss:  0.881349/  3.566679, val:  64.17%, val_best:  67.50%, tr:  97.45%, tr_best:  97.45%\n",
      "epoch-48  lr=['0.0010000'], tr/val_loss:  0.902812/  3.620230, val:  64.58%, val_best:  67.50%, tr:  97.85%, tr_best:  97.85%\n",
      "epoch-49  lr=['0.0010000'], tr/val_loss:  0.909536/  3.763088, val:  67.08%, val_best:  67.50%, tr:  96.02%, tr_best:  97.85%\n",
      "epoch-50  lr=['0.0010000'], tr/val_loss:  0.897933/  3.823657, val:  65.42%, val_best:  67.50%, tr:  96.83%, tr_best:  97.85%\n",
      "epoch-51  lr=['0.0010000'], tr/val_loss:  0.921506/  3.850721, val:  63.75%, val_best:  67.50%, tr:  96.22%, tr_best:  97.85%\n",
      "epoch-52  lr=['0.0010000'], tr/val_loss:  0.878395/  3.920132, val:  62.92%, val_best:  67.50%, tr:  98.16%, tr_best:  98.16%\n",
      "epoch-53  lr=['0.0010000'], tr/val_loss:  0.875459/  3.925065, val:  63.33%, val_best:  67.50%, tr:  97.85%, tr_best:  98.16%\n",
      "epoch-54  lr=['0.0010000'], tr/val_loss:  0.908434/  4.063511, val:  65.00%, val_best:  67.50%, tr:  97.45%, tr_best:  98.16%\n",
      "epoch-55  lr=['0.0010000'], tr/val_loss:  0.885495/  4.166838, val:  64.58%, val_best:  67.50%, tr:  97.45%, tr_best:  98.16%\n",
      "epoch-56  lr=['0.0010000'], tr/val_loss:  0.891168/  4.235428, val:  64.58%, val_best:  67.50%, tr:  97.96%, tr_best:  98.16%\n",
      "epoch-57  lr=['0.0010000'], tr/val_loss:  0.904209/  4.202693, val:  65.42%, val_best:  67.50%, tr:  98.16%, tr_best:  98.16%\n",
      "epoch-58  lr=['0.0010000'], tr/val_loss:  0.901683/  4.408100, val:  65.83%, val_best:  67.50%, tr:  97.75%, tr_best:  98.16%\n",
      "epoch-59  lr=['0.0010000'], tr/val_loss:  0.917671/  4.462821, val:  65.83%, val_best:  67.50%, tr:  97.85%, tr_best:  98.16%\n",
      "epoch-60  lr=['0.0010000'], tr/val_loss:  0.900324/  4.409728, val:  66.25%, val_best:  67.50%, tr:  98.06%, tr_best:  98.16%\n",
      "epoch-61  lr=['0.0010000'], tr/val_loss:  0.916592/  4.574003, val:  64.17%, val_best:  67.50%, tr:  97.96%, tr_best:  98.16%\n",
      "epoch-62  lr=['0.0010000'], tr/val_loss:  0.918912/  4.598024, val:  64.58%, val_best:  67.50%, tr:  97.75%, tr_best:  98.16%\n",
      "epoch-63  lr=['0.0010000'], tr/val_loss:  0.912576/  4.673869, val:  64.17%, val_best:  67.50%, tr:  98.47%, tr_best:  98.47%\n",
      "epoch-64  lr=['0.0010000'], tr/val_loss:  0.951523/  4.838566, val:  62.50%, val_best:  67.50%, tr:  97.14%, tr_best:  98.47%\n",
      "epoch-65  lr=['0.0010000'], tr/val_loss:  0.929579/  4.837544, val:  63.75%, val_best:  67.50%, tr:  98.57%, tr_best:  98.57%\n",
      "epoch-66  lr=['0.0010000'], tr/val_loss:  0.943912/  4.801209, val:  63.33%, val_best:  67.50%, tr:  98.77%, tr_best:  98.77%\n",
      "epoch-67  lr=['0.0010000'], tr/val_loss:  0.978586/  4.870781, val:  64.17%, val_best:  67.50%, tr:  98.26%, tr_best:  98.77%\n",
      "epoch-68  lr=['0.0010000'], tr/val_loss:  0.928512/  5.056540, val:  66.67%, val_best:  67.50%, tr:  98.88%, tr_best:  98.88%\n",
      "epoch-69  lr=['0.0010000'], tr/val_loss:  0.974683/  5.035474, val:  64.58%, val_best:  67.50%, tr:  97.85%, tr_best:  98.88%\n",
      "epoch-70  lr=['0.0010000'], tr/val_loss:  0.955963/  5.190147, val:  65.83%, val_best:  67.50%, tr:  98.98%, tr_best:  98.98%\n",
      "epoch-71  lr=['0.0010000'], tr/val_loss:  0.966961/  5.238400, val:  64.17%, val_best:  67.50%, tr:  98.06%, tr_best:  98.98%\n",
      "epoch-72  lr=['0.0010000'], tr/val_loss:  0.958911/  5.391454, val:  64.17%, val_best:  67.50%, tr:  98.67%, tr_best:  98.98%\n",
      "epoch-73  lr=['0.0010000'], tr/val_loss:  0.979799/  5.308387, val:  64.17%, val_best:  67.50%, tr:  98.37%, tr_best:  98.98%\n",
      "epoch-74  lr=['0.0010000'], tr/val_loss:  0.964715/  5.419832, val:  65.83%, val_best:  67.50%, tr:  98.37%, tr_best:  98.98%\n",
      "epoch-75  lr=['0.0010000'], tr/val_loss:  0.980169/  5.544930, val:  66.25%, val_best:  67.50%, tr:  98.37%, tr_best:  98.98%\n",
      "epoch-76  lr=['0.0010000'], tr/val_loss:  0.968358/  5.632122, val:  65.83%, val_best:  67.50%, tr:  98.16%, tr_best:  98.98%\n",
      "epoch-77  lr=['0.0010000'], tr/val_loss:  0.988867/  5.605183, val:  63.75%, val_best:  67.50%, tr:  98.77%, tr_best:  98.98%\n",
      "epoch-78  lr=['0.0010000'], tr/val_loss:  0.985602/  5.728496, val:  64.58%, val_best:  67.50%, tr:  98.37%, tr_best:  98.98%\n",
      "epoch-79  lr=['0.0010000'], tr/val_loss:  0.989630/  5.790163, val:  63.33%, val_best:  67.50%, tr:  98.98%, tr_best:  98.98%\n",
      "epoch-80  lr=['0.0010000'], tr/val_loss:  0.946726/  5.743594, val:  66.25%, val_best:  67.50%, tr:  98.37%, tr_best:  98.98%\n",
      "epoch-81  lr=['0.0010000'], tr/val_loss:  0.937975/  5.892830, val:  63.75%, val_best:  67.50%, tr:  98.67%, tr_best:  98.98%\n",
      "epoch-82  lr=['0.0010000'], tr/val_loss:  0.973990/  5.979602, val:  65.42%, val_best:  67.50%, tr:  98.37%, tr_best:  98.98%\n",
      "epoch-83  lr=['0.0010000'], tr/val_loss:  0.968340/  6.040612, val:  65.42%, val_best:  67.50%, tr:  98.57%, tr_best:  98.98%\n",
      "epoch-84  lr=['0.0010000'], tr/val_loss:  0.975842/  6.045587, val:  66.25%, val_best:  67.50%, tr:  99.18%, tr_best:  99.18%\n",
      "epoch-85  lr=['0.0010000'], tr/val_loss:  0.959686/  6.149115, val:  64.17%, val_best:  67.50%, tr:  99.18%, tr_best:  99.18%\n",
      "epoch-86  lr=['0.0010000'], tr/val_loss:  0.966483/  6.255885, val:  66.67%, val_best:  67.50%, tr:  98.47%, tr_best:  99.18%\n",
      "epoch-87  lr=['0.0010000'], tr/val_loss:  1.010518/  6.260497, val:  65.83%, val_best:  67.50%, tr:  98.57%, tr_best:  99.18%\n",
      "epoch-88  lr=['0.0010000'], tr/val_loss:  0.970384/  6.322037, val:  64.17%, val_best:  67.50%, tr:  99.18%, tr_best:  99.18%\n",
      "epoch-89  lr=['0.0010000'], tr/val_loss:  0.940430/  6.472783, val:  64.58%, val_best:  67.50%, tr:  98.88%, tr_best:  99.18%\n",
      "epoch-90  lr=['0.0010000'], tr/val_loss:  1.016080/  6.364972, val:  66.67%, val_best:  67.50%, tr:  98.88%, tr_best:  99.18%\n",
      "epoch-91  lr=['0.0010000'], tr/val_loss:  0.968965/  6.490075, val:  63.75%, val_best:  67.50%, tr:  98.67%, tr_best:  99.18%\n",
      "epoch-92  lr=['0.0010000'], tr/val_loss:  0.984306/  6.480693, val:  65.42%, val_best:  67.50%, tr:  99.08%, tr_best:  99.18%\n",
      "epoch-93  lr=['0.0010000'], tr/val_loss:  0.985216/  6.495708, val:  67.50%, val_best:  67.50%, tr:  98.98%, tr_best:  99.18%\n",
      "epoch-94  lr=['0.0010000'], tr/val_loss:  0.993391/  6.601977, val:  62.92%, val_best:  67.50%, tr:  98.57%, tr_best:  99.18%\n",
      "epoch-95  lr=['0.0010000'], tr/val_loss:  1.002850/  6.695262, val:  66.25%, val_best:  67.50%, tr:  98.88%, tr_best:  99.18%\n",
      "epoch-96  lr=['0.0010000'], tr/val_loss:  0.982645/  6.811234, val:  64.58%, val_best:  67.50%, tr:  98.47%, tr_best:  99.18%\n",
      "epoch-97  lr=['0.0010000'], tr/val_loss:  1.027471/  6.617285, val:  66.25%, val_best:  67.50%, tr:  98.26%, tr_best:  99.18%\n",
      "epoch-98  lr=['0.0010000'], tr/val_loss:  0.965649/  6.649284, val:  65.42%, val_best:  67.50%, tr:  99.28%, tr_best:  99.28%\n",
      "epoch-99  lr=['0.0010000'], tr/val_loss:  1.042163/  6.814491, val:  62.50%, val_best:  67.50%, tr:  99.08%, tr_best:  99.28%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "67290ee593d94e8d9f37b20e30f9cd4d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.006 MB of 0.006 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>iter_acc</td><td>▃▆▂▃▃▆▆▁▆▆██▆▇▆██▇██▇█▇██████▇▇█▇███▆▇██</td></tr><tr><td>summary_val_acc</td><td>▁▅▆▇▆▆▆▇█▇▇▇▆▇▆▇███▇█▇███▇▇▇█▇█▇▇███▇███</td></tr><tr><td>tr_acc</td><td>▁▄▅▅▆▆▆▇▆▇▇▇▇▇▇█████████████████████████</td></tr><tr><td>tr_epoch_loss</td><td>█▄▃▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▁▁▂▂▂▂▂▂▁▂▂▂</td></tr><tr><td>val_acc_best</td><td>▁▅▆▇▇▇▇▇▇▇▇█████████████████████████████</td></tr><tr><td>val_acc_now</td><td>▁▅▆▇▆▆▆▇█▇▇▇▆▇▆▇███▇█▇███▇▇▇█▇█▇▇███▇███</td></tr><tr><td>val_loss</td><td>▂▁▁▁▁▁▁▁▁▂▂▂▂▃▃▃▃▃▄▄▄▄▄▅▅▅▆▆▆▆▆▇▇▇▇▇████</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>99</td></tr><tr><td>iter_acc</td><td>1.0</td></tr><tr><td>tr_acc</td><td>0.99081</td></tr><tr><td>tr_epoch_loss</td><td>1.04216</td></tr><tr><td>val_acc_best</td><td>0.675</td></tr><tr><td>val_acc_now</td><td>0.625</td></tr><tr><td>val_loss</td><td>6.81449</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">youthful-sweep-79</strong> at: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/yfy58is9' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/yfy58is9</a><br/> View project at: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>/data2/bh_wandb/wandb/run-20250430_010106-yfy58is9/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require(\"core\")`! See https://wandb.me/wandb-core for more information."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: m0lvblle with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBATCH: 16\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBN_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBPTT_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tDFA_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tIMAGE_SIZE: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tOTTT_input_trace_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tTIME: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tUDA_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \talpha_uda: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbias: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcfg: ['M', 'M', 200, 200]\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tchaching_on: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tconvTrue_fcFalse: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdata_path: /data2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tddp_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdenoise_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdvs_clipping: 5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdvs_duration: 100000\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepoch_num: 100\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \texclude_class: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \textra_train_dataset: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlast_lif: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.001\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_sg_width: 4\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_decay: 0.5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_init: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_reset: 10000\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_threshold: 0.25\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmerge_polarities: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmy_seed: 42\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnet_print: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_workers: 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer_what: SGD\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tpin_memory: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tpre_trained: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tpre_trained_path: net_save/save_now_net_weights_{unique_name}.pth\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \trate_coding: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tscheduler_name: no\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsingle_step: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsurrogate: hard_sigmoid\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_conv_kernel_size: 3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_conv_padding: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_conv_stride: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_trace_const1: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_trace_const2: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \ttdBN_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \ttrace_on: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \twhich_data: DVS_GESTURE_TONIC\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.19.10 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.17.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/data2/bh_wandb/wandb/run-20250430_010806-m0lvblle</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/m0lvblle' target=\"_blank\">logical-sweep-83</a></strong> to <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/6pj3lh8j' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/6pj3lh8j</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/6pj3lh8j' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/6pj3lh8j</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/m0lvblle' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/m0lvblle</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'single_step' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'my_seed' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'TIME' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BATCH' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'IMAGE_SIZE' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'which_data' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'data_path' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'rate_coding' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_init' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_decay' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_threshold' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_reset' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_sg_width' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_conv_kernel_size' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_conv_stride' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_conv_padding' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_trace_const1' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_trace_const2' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'pre_trained' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'convTrue_fcFalse' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'cfg' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'net_print' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'pre_trained_path' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'learning_rate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'epoch_num' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'tdBN_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BN_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'surrogate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BPTT_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'optimizer_what' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'scheduler_name' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'ddp_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'dvs_clipping' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'dvs_duration' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'DFA_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'trace_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'OTTT_input_trace_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'exclude_class' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'merge_polarities' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'denoise_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'extra_train_dataset' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'num_workers' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'chaching_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'pin_memory' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'UDA_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'alpha_uda' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'bias' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'last_lif' was locked by 'sweep' (ignored update).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "param {'devices': '0', 'single_step': True, 'unique_name': 'main', 'my_seed': 42, 'TIME': 10, 'BATCH': 16, 'IMAGE_SIZE': 128, 'which_data': 'DVS_GESTURE_TONIC', 'data_path': '/data2', 'rate_coding': False, 'lif_layer_v_init': 0, 'lif_layer_v_decay': 0.5, 'lif_layer_v_threshold': 0.25, 'lif_layer_v_reset': 10000, 'lif_layer_sg_width': 4, 'synapse_conv_kernel_size': 3, 'synapse_conv_stride': 1, 'synapse_conv_padding': 1, 'synapse_trace_const1': 1, 'synapse_trace_const2': 0, 'pre_trained': False, 'convTrue_fcFalse': False, 'cfg': ['M', 'M', 200, 200], 'net_print': True, 'pre_trained_path': 'net_save/save_now_net_weights_{unique_name}.pth', 'learning_rate': 0.001, 'epoch_num': 100, 'tdBN_on': False, 'BN_on': False, 'surrogate': 'hard_sigmoid', 'BPTT_on': False, 'optimizer_what': 'SGD', 'scheduler_name': 'no', 'ddp_on': False, 'dvs_clipping': 5, 'dvs_duration': 100000, 'DFA_on': False, 'trace_on': True, 'OTTT_input_trace_on': False, 'exclude_class': True, 'merge_polarities': False, 'denoise_on': False, 'extra_train_dataset': 0, 'num_workers': 2, 'chaching_on': True, 'pin_memory': True, 'UDA_on': False, 'alpha_uda': 1, 'bias': True, 'last_lif': False, 'current epoch': 0} \n",
      "\n",
      "dataset_hash = ffa516e60c3efd5e0208f72b4c36cb84\n",
      "cache path exists\n",
      "\n",
      "device ==> cuda\n",
      "\n",
      "DataParallel(\n",
      "  (module): REBORN_MY_SNN_FC(\n",
      "    (layers): REBORN_MY_Sequential(\n",
      "      (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (2): DimChanger_for_FC()\n",
      "      (3): SYNAPSE_FC(in_features=2048, out_features=200, TIME=10, bias=True, sstep=True)\n",
      "      (4): LIF_layer(v_init=0, v_decay=0.5, v_threshold=0.25, v_reset=10000, sg_width=4, surrogate=hard_sigmoid, BPTT_on=False, trace_const1=1, trace_const2=0, TIME=10, sstep=True, trace_on=True)\n",
      "      (5): SYNAPSE_FC(in_features=200, out_features=200, TIME=10, bias=True, sstep=True)\n",
      "      (6): LIF_layer(v_init=0, v_decay=0.5, v_threshold=0.25, v_reset=10000, sg_width=4, surrogate=hard_sigmoid, BPTT_on=False, trace_const1=1, trace_const2=0, TIME=10, sstep=True, trace_on=True)\n",
      "      (7): SYNAPSE_FC(in_features=200, out_features=10, TIME=10, bias=True, sstep=True)\n",
      "    )\n",
      "  )\n",
      ")\n",
      "\n",
      "========================================================\n",
      "Trainable parameters: 452,010\n",
      "========================================================\n",
      "\n",
      "epoch-0   lr=['0.0010000'], tr/val_loss:  2.119906/  1.798722, val:  47.08%, val_best:  47.08%, tr:  25.84%, tr_best:  25.84%\n",
      "epoch-1   lr=['0.0010000'], tr/val_loss:  1.498139/  1.482899, val:  57.92%, val_best:  57.92%, tr:  54.85%, tr_best:  54.85%\n",
      "epoch-2   lr=['0.0010000'], tr/val_loss:  1.275502/  1.417621, val:  60.83%, val_best:  60.83%, tr:  60.67%, tr_best:  60.67%\n",
      "epoch-3   lr=['0.0010000'], tr/val_loss:  1.132880/  1.404141, val:  58.75%, val_best:  60.83%, tr:  66.39%, tr_best:  66.39%\n",
      "epoch-4   lr=['0.0010000'], tr/val_loss:  1.050707/  1.335295, val:  61.25%, val_best:  61.25%, tr:  66.60%, tr_best:  66.60%\n",
      "epoch-5   lr=['0.0010000'], tr/val_loss:  0.994519/  1.274327, val:  67.50%, val_best:  67.50%, tr:  68.54%, tr_best:  68.54%\n",
      "epoch-6   lr=['0.0010000'], tr/val_loss:  0.917140/  1.272290, val:  64.17%, val_best:  67.50%, tr:  73.95%, tr_best:  73.95%\n",
      "epoch-7   lr=['0.0010000'], tr/val_loss:  0.870917/  1.255608, val:  65.42%, val_best:  67.50%, tr:  75.28%, tr_best:  75.28%\n",
      "epoch-8   lr=['0.0010000'], tr/val_loss:  0.830058/  1.281231, val:  66.67%, val_best:  67.50%, tr:  75.38%, tr_best:  75.38%\n",
      "epoch-9   lr=['0.0010000'], tr/val_loss:  0.777959/  1.327255, val:  69.17%, val_best:  69.17%, tr:  80.08%, tr_best:  80.08%\n",
      "epoch-10  lr=['0.0010000'], tr/val_loss:  0.761296/  1.366208, val:  60.83%, val_best:  69.17%, tr:  79.06%, tr_best:  80.08%\n",
      "epoch-11  lr=['0.0010000'], tr/val_loss:  0.680403/  1.281086, val:  67.92%, val_best:  69.17%, tr:  83.96%, tr_best:  83.96%\n",
      "epoch-12  lr=['0.0010000'], tr/val_loss:  0.680950/  1.289386, val:  67.08%, val_best:  69.17%, tr:  86.01%, tr_best:  86.01%\n",
      "epoch-13  lr=['0.0010000'], tr/val_loss:  0.634140/  1.330117, val:  66.67%, val_best:  69.17%, tr:  86.72%, tr_best:  86.72%\n",
      "epoch-14  lr=['0.0010000'], tr/val_loss:  0.598379/  1.468913, val:  60.83%, val_best:  69.17%, tr:  87.23%, tr_best:  87.23%\n",
      "epoch-15  lr=['0.0010000'], tr/val_loss:  0.562766/  1.371020, val:  65.83%, val_best:  69.17%, tr:  89.89%, tr_best:  89.89%\n",
      "epoch-16  lr=['0.0010000'], tr/val_loss:  0.536251/  1.309611, val:  76.67%, val_best:  76.67%, tr:  90.19%, tr_best:  90.19%\n",
      "epoch-17  lr=['0.0010000'], tr/val_loss:  0.498089/  1.361294, val:  73.33%, val_best:  76.67%, tr:  94.08%, tr_best:  94.08%\n",
      "epoch-18  lr=['0.0010000'], tr/val_loss:  0.466700/  1.396907, val:  66.25%, val_best:  76.67%, tr:  93.26%, tr_best:  94.08%\n",
      "epoch-19  lr=['0.0010000'], tr/val_loss:  0.456353/  1.432056, val:  68.33%, val_best:  76.67%, tr:  92.75%, tr_best:  94.08%\n",
      "epoch-20  lr=['0.0010000'], tr/val_loss:  0.411640/  1.516255, val:  65.83%, val_best:  76.67%, tr:  95.20%, tr_best:  95.20%\n",
      "epoch-21  lr=['0.0010000'], tr/val_loss:  0.388730/  1.534884, val:  66.67%, val_best:  76.67%, tr:  95.51%, tr_best:  95.51%\n",
      "epoch-22  lr=['0.0010000'], tr/val_loss:  0.351109/  1.568959, val:  70.42%, val_best:  76.67%, tr:  97.75%, tr_best:  97.75%\n",
      "epoch-23  lr=['0.0010000'], tr/val_loss:  0.343258/  1.507550, val:  76.25%, val_best:  76.67%, tr:  97.75%, tr_best:  97.75%\n",
      "epoch-24  lr=['0.0010000'], tr/val_loss:  0.295646/  1.546793, val:  75.83%, val_best:  76.67%, tr:  99.49%, tr_best:  99.49%\n",
      "epoch-25  lr=['0.0010000'], tr/val_loss:  0.277555/  1.572357, val:  75.83%, val_best:  76.67%, tr:  98.98%, tr_best:  99.49%\n",
      "epoch-26  lr=['0.0010000'], tr/val_loss:  0.306027/  1.554983, val:  78.33%, val_best:  78.33%, tr:  96.53%, tr_best:  99.49%\n",
      "epoch-27  lr=['0.0010000'], tr/val_loss:  0.260314/  1.654903, val:  74.58%, val_best:  78.33%, tr:  99.39%, tr_best:  99.49%\n",
      "epoch-28  lr=['0.0010000'], tr/val_loss:  0.231371/  1.621731, val:  76.25%, val_best:  78.33%, tr:  99.90%, tr_best:  99.90%\n",
      "epoch-29  lr=['0.0010000'], tr/val_loss:  0.210768/  1.698014, val:  70.83%, val_best:  78.33%, tr:  99.80%, tr_best:  99.90%\n",
      "epoch-30  lr=['0.0010000'], tr/val_loss:  0.194701/  1.691470, val:  75.42%, val_best:  78.33%, tr:  99.80%, tr_best:  99.90%\n",
      "epoch-31  lr=['0.0010000'], tr/val_loss:  0.195472/  1.731359, val:  75.42%, val_best:  78.33%, tr:  98.88%, tr_best:  99.90%\n",
      "epoch-32  lr=['0.0010000'], tr/val_loss:  0.187172/  1.748920, val:  74.58%, val_best:  78.33%, tr:  99.59%, tr_best:  99.90%\n",
      "epoch-33  lr=['0.0010000'], tr/val_loss:  0.171064/  1.759247, val:  75.83%, val_best:  78.33%, tr:  99.90%, tr_best:  99.90%\n",
      "epoch-34  lr=['0.0010000'], tr/val_loss:  0.153550/  1.880896, val:  72.08%, val_best:  78.33%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-35  lr=['0.0010000'], tr/val_loss:  0.148940/  1.855163, val:  75.00%, val_best:  78.33%, tr:  99.80%, tr_best: 100.00%\n",
      "epoch-36  lr=['0.0010000'], tr/val_loss:  0.132065/  1.829297, val:  77.08%, val_best:  78.33%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-37  lr=['0.0010000'], tr/val_loss:  0.120644/  1.881434, val:  75.83%, val_best:  78.33%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-38  lr=['0.0010000'], tr/val_loss:  0.117643/  1.884315, val:  77.50%, val_best:  78.33%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-39  lr=['0.0010000'], tr/val_loss:  0.107424/  1.903832, val:  78.75%, val_best:  78.75%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-40  lr=['0.0010000'], tr/val_loss:  0.099748/  1.931768, val:  76.67%, val_best:  78.75%, tr:  99.80%, tr_best: 100.00%\n",
      "epoch-41  lr=['0.0010000'], tr/val_loss:  0.088788/  1.934684, val:  77.50%, val_best:  78.75%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-42  lr=['0.0010000'], tr/val_loss:  0.078754/  1.989633, val:  75.42%, val_best:  78.75%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-43  lr=['0.0010000'], tr/val_loss:  0.071473/  2.038657, val:  74.17%, val_best:  78.75%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-44  lr=['0.0010000'], tr/val_loss:  0.067931/  2.042653, val:  77.50%, val_best:  78.75%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-45  lr=['0.0010000'], tr/val_loss:  0.061954/  2.031253, val:  77.50%, val_best:  78.75%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-46  lr=['0.0010000'], tr/val_loss:  0.053446/  2.057682, val:  77.92%, val_best:  78.75%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-47  lr=['0.0010000'], tr/val_loss:  0.049523/  2.086511, val:  78.33%, val_best:  78.75%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-48  lr=['0.0010000'], tr/val_loss:  0.046743/  2.119257, val:  78.75%, val_best:  78.75%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-49  lr=['0.0010000'], tr/val_loss:  0.047233/  2.127284, val:  76.25%, val_best:  78.75%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-50  lr=['0.0010000'], tr/val_loss:  0.042760/  2.174753, val:  78.33%, val_best:  78.75%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-51  lr=['0.0010000'], tr/val_loss:  0.041598/  2.153108, val:  76.67%, val_best:  78.75%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-52  lr=['0.0010000'], tr/val_loss:  0.038466/  2.152211, val:  80.00%, val_best:  80.00%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-53  lr=['0.0010000'], tr/val_loss:  0.032262/  2.183511, val:  76.67%, val_best:  80.00%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-54  lr=['0.0010000'], tr/val_loss:  0.032521/  2.231649, val:  76.25%, val_best:  80.00%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-55  lr=['0.0010000'], tr/val_loss:  0.029771/  2.241211, val:  77.08%, val_best:  80.00%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-56  lr=['0.0010000'], tr/val_loss:  0.030390/  2.246595, val:  79.58%, val_best:  80.00%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-57  lr=['0.0010000'], tr/val_loss:  0.026826/  2.244196, val:  78.33%, val_best:  80.00%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-58  lr=['0.0010000'], tr/val_loss:  0.024250/  2.258537, val:  77.92%, val_best:  80.00%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-59  lr=['0.0010000'], tr/val_loss:  0.024533/  2.284912, val:  76.67%, val_best:  80.00%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-60  lr=['0.0010000'], tr/val_loss:  0.021294/  2.286628, val:  77.50%, val_best:  80.00%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-61  lr=['0.0010000'], tr/val_loss:  0.021853/  2.294553, val:  77.50%, val_best:  80.00%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-62  lr=['0.0010000'], tr/val_loss:  0.019385/  2.314095, val:  77.92%, val_best:  80.00%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-63  lr=['0.0010000'], tr/val_loss:  0.019799/  2.332610, val:  77.50%, val_best:  80.00%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-64  lr=['0.0010000'], tr/val_loss:  0.018027/  2.337652, val:  78.33%, val_best:  80.00%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-65  lr=['0.0010000'], tr/val_loss:  0.016088/  2.392687, val:  77.08%, val_best:  80.00%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-66  lr=['0.0010000'], tr/val_loss:  0.016422/  2.369056, val:  77.50%, val_best:  80.00%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-67  lr=['0.0010000'], tr/val_loss:  0.015787/  2.382256, val:  77.92%, val_best:  80.00%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-68  lr=['0.0010000'], tr/val_loss:  0.016702/  2.376570, val:  76.67%, val_best:  80.00%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-69  lr=['0.0010000'], tr/val_loss:  0.022294/  2.455824, val:  76.67%, val_best:  80.00%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-70  lr=['0.0010000'], tr/val_loss:  0.021153/  2.385131, val:  77.92%, val_best:  80.00%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-71  lr=['0.0010000'], tr/val_loss:  0.018614/  2.433754, val:  77.08%, val_best:  80.00%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-72  lr=['0.0010000'], tr/val_loss:  0.015277/  2.435776, val:  75.83%, val_best:  80.00%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-73  lr=['0.0010000'], tr/val_loss:  0.012704/  2.443070, val:  75.83%, val_best:  80.00%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-74  lr=['0.0010000'], tr/val_loss:  0.012890/  2.437957, val:  75.42%, val_best:  80.00%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-75  lr=['0.0010000'], tr/val_loss:  0.012460/  2.464751, val:  77.08%, val_best:  80.00%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-76  lr=['0.0010000'], tr/val_loss:  0.011724/  2.493489, val:  76.25%, val_best:  80.00%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-77  lr=['0.0010000'], tr/val_loss:  0.010691/  2.524996, val:  76.25%, val_best:  80.00%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-78  lr=['0.0010000'], tr/val_loss:  0.010804/  2.517975, val:  77.92%, val_best:  80.00%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-79  lr=['0.0010000'], tr/val_loss:  0.010099/  2.523021, val:  76.67%, val_best:  80.00%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-80  lr=['0.0010000'], tr/val_loss:  0.009342/  2.529535, val:  77.92%, val_best:  80.00%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-81  lr=['0.0010000'], tr/val_loss:  0.009371/  2.525211, val:  76.67%, val_best:  80.00%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-82  lr=['0.0010000'], tr/val_loss:  0.009914/  2.566594, val:  77.08%, val_best:  80.00%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-83  lr=['0.0010000'], tr/val_loss:  0.011196/  2.576654, val:  77.08%, val_best:  80.00%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-84  lr=['0.0010000'], tr/val_loss:  0.009497/  2.541268, val:  75.83%, val_best:  80.00%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-85  lr=['0.0010000'], tr/val_loss:  0.009188/  2.571992, val:  76.25%, val_best:  80.00%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-86  lr=['0.0010000'], tr/val_loss:  0.008824/  2.577959, val:  77.50%, val_best:  80.00%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-87  lr=['0.0010000'], tr/val_loss:  0.008260/  2.583002, val:  76.25%, val_best:  80.00%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-88  lr=['0.0010000'], tr/val_loss:  0.007798/  2.581729, val:  77.08%, val_best:  80.00%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-89  lr=['0.0010000'], tr/val_loss:  0.007411/  2.586444, val:  75.42%, val_best:  80.00%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-90  lr=['0.0010000'], tr/val_loss:  0.008570/  2.577061, val:  79.17%, val_best:  80.00%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-91  lr=['0.0010000'], tr/val_loss:  0.007884/  2.591349, val:  78.75%, val_best:  80.00%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-92  lr=['0.0010000'], tr/val_loss:  0.007503/  2.616768, val:  78.33%, val_best:  80.00%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-93  lr=['0.0010000'], tr/val_loss:  0.007420/  2.611906, val:  77.50%, val_best:  80.00%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-94  lr=['0.0010000'], tr/val_loss:  0.007744/  2.607092, val:  77.08%, val_best:  80.00%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-95  lr=['0.0010000'], tr/val_loss:  0.007286/  2.623841, val:  76.25%, val_best:  80.00%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-96  lr=['0.0010000'], tr/val_loss:  0.006907/  2.645463, val:  76.25%, val_best:  80.00%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-97  lr=['0.0010000'], tr/val_loss:  0.006553/  2.657627, val:  75.00%, val_best:  80.00%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-98  lr=['0.0010000'], tr/val_loss:  0.006815/  2.679493, val:  75.83%, val_best:  80.00%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-99  lr=['0.0010000'], tr/val_loss:  0.006743/  2.684079, val:  75.42%, val_best:  80.00%, tr: 100.00%, tr_best: 100.00%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "282b741088ac429fb019a4b92e558176",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.006 MB of 0.006 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>iter_acc</td><td>▁▄▂▃▄▆▆▂▇███████████████████████████████</td></tr><tr><td>summary_val_acc</td><td>▁▄▄▅▆▅▄▇▆▅▇█▆▇▇▇█▇▇█▇█▇█▇▇▇██▇▇▇▇▇▇▇▇█▇▇</td></tr><tr><td>tr_acc</td><td>▁▄▅▆▆▇▇▇▇███████████████████████████████</td></tr><tr><td>tr_epoch_loss</td><td>█▅▄▄▄▃▃▃▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_acc_best</td><td>▁▄▄▅▆▆▆▇▇▇▇█████████████████████████████</td></tr><tr><td>val_acc_now</td><td>▁▄▄▅▆▅▄▇▆▅▇█▆▇▇▇█▇▇█▇█▇█▇▇▇██▇▇▇▇▇▇▇▇█▇▇</td></tr><tr><td>val_loss</td><td>▄▂▁▁▁▁▂▂▂▂▂▂▃▃▄▄▄▅▅▅▅▅▆▆▆▆▇▇▇▇▇▇▇█▇█████</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>99</td></tr><tr><td>iter_acc</td><td>1.0</td></tr><tr><td>tr_acc</td><td>1.0</td></tr><tr><td>tr_epoch_loss</td><td>0.00674</td></tr><tr><td>val_acc_best</td><td>0.8</td></tr><tr><td>val_acc_now</td><td>0.75417</td></tr><tr><td>val_loss</td><td>2.68408</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">logical-sweep-83</strong> at: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/m0lvblle' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/m0lvblle</a><br/> View project at: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>/data2/bh_wandb/wandb/run-20250430_010806-m0lvblle/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require(\"core\")`! See https://wandb.me/wandb-core for more information."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: d6m9vbyn with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBATCH: 16\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBN_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBPTT_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tDFA_on: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tIMAGE_SIZE: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tOTTT_input_trace_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tTIME: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tUDA_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \talpha_uda: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbias: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcfg: ['M', 'M', 200, 200]\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tchaching_on: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tconvTrue_fcFalse: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdata_path: /data2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tddp_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdenoise_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdvs_clipping: 5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdvs_duration: 100000\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepoch_num: 100\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \texclude_class: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \textra_train_dataset: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlast_lif: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.01\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_sg_width: 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_decay: 0.5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_init: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_reset: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_threshold: 0.25\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmerge_polarities: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmy_seed: 42\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnet_print: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_workers: 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer_what: SGD\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tpin_memory: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tpre_trained: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tpre_trained_path: net_save/save_now_net_weights_{unique_name}.pth\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \trate_coding: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tscheduler_name: no\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsingle_step: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsurrogate: hard_sigmoid\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_conv_kernel_size: 3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_conv_padding: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_conv_stride: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_trace_const1: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_trace_const2: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \ttdBN_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \ttrace_on: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \twhich_data: DVS_GESTURE_TONIC\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.19.10 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.17.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/data2/bh_wandb/wandb/run-20250430_011429-d6m9vbyn</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/d6m9vbyn' target=\"_blank\">dry-sweep-87</a></strong> to <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/6pj3lh8j' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/6pj3lh8j</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/6pj3lh8j' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/6pj3lh8j</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/d6m9vbyn' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/d6m9vbyn</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'single_step' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'my_seed' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'TIME' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BATCH' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'IMAGE_SIZE' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'which_data' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'data_path' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'rate_coding' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_init' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_decay' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_threshold' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_reset' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_sg_width' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_conv_kernel_size' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_conv_stride' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_conv_padding' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_trace_const1' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_trace_const2' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'pre_trained' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'convTrue_fcFalse' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'cfg' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'net_print' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'pre_trained_path' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'learning_rate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'epoch_num' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'tdBN_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BN_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'surrogate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BPTT_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'optimizer_what' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'scheduler_name' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'ddp_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'dvs_clipping' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'dvs_duration' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'DFA_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'trace_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'OTTT_input_trace_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'exclude_class' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'merge_polarities' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'denoise_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'extra_train_dataset' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'num_workers' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'chaching_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'pin_memory' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'UDA_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'alpha_uda' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'bias' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'last_lif' was locked by 'sweep' (ignored update).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "param {'devices': '0', 'single_step': True, 'unique_name': 'main', 'my_seed': 42, 'TIME': 10, 'BATCH': 16, 'IMAGE_SIZE': 128, 'which_data': 'DVS_GESTURE_TONIC', 'data_path': '/data2', 'rate_coding': False, 'lif_layer_v_init': 0, 'lif_layer_v_decay': 0.5, 'lif_layer_v_threshold': 0.25, 'lif_layer_v_reset': 0, 'lif_layer_sg_width': 2, 'synapse_conv_kernel_size': 3, 'synapse_conv_stride': 1, 'synapse_conv_padding': 1, 'synapse_trace_const1': 1, 'synapse_trace_const2': 0, 'pre_trained': False, 'convTrue_fcFalse': False, 'cfg': ['M', 'M', 200, 200], 'net_print': True, 'pre_trained_path': 'net_save/save_now_net_weights_{unique_name}.pth', 'learning_rate': 0.01, 'epoch_num': 100, 'tdBN_on': False, 'BN_on': False, 'surrogate': 'hard_sigmoid', 'BPTT_on': False, 'optimizer_what': 'SGD', 'scheduler_name': 'no', 'ddp_on': False, 'dvs_clipping': 5, 'dvs_duration': 100000, 'DFA_on': True, 'trace_on': True, 'OTTT_input_trace_on': False, 'exclude_class': True, 'merge_polarities': False, 'denoise_on': False, 'extra_train_dataset': 0, 'num_workers': 2, 'chaching_on': True, 'pin_memory': True, 'UDA_on': False, 'alpha_uda': 1, 'bias': True, 'last_lif': False, 'current epoch': 0} \n",
      "\n",
      "dataset_hash = ffa516e60c3efd5e0208f72b4c36cb84\n",
      "cache path exists\n",
      "\n",
      "device ==> cuda\n",
      "\n",
      "DataParallel(\n",
      "  (module): REBORN_MY_SNN_FC(\n",
      "    (layers): REBORN_MY_Sequential(\n",
      "      (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (2): DimChanger_for_FC()\n",
      "      (3): SYNAPSE_FC(in_features=2048, out_features=200, TIME=10, bias=True, sstep=True)\n",
      "      (4): LIF_layer(v_init=0, v_decay=0.5, v_threshold=0.25, v_reset=0, sg_width=2, surrogate=hard_sigmoid, BPTT_on=False, trace_const1=1, trace_const2=0, TIME=10, sstep=True, trace_on=True)\n",
      "      (5): Feedback_Receiver()\n",
      "      (6): SYNAPSE_FC(in_features=200, out_features=200, TIME=10, bias=True, sstep=True)\n",
      "      (7): LIF_layer(v_init=0, v_decay=0.5, v_threshold=0.25, v_reset=0, sg_width=2, surrogate=hard_sigmoid, BPTT_on=False, trace_const1=1, trace_const2=0, TIME=10, sstep=True, trace_on=True)\n",
      "      (8): Feedback_Receiver()\n",
      "      (9): SYNAPSE_FC(in_features=200, out_features=10, TIME=10, bias=True, sstep=True)\n",
      "      (DFA_top): Top_Gradient()\n",
      "    )\n",
      "  )\n",
      ")\n",
      "\n",
      "========================================================\n",
      "Trainable parameters: 452,010\n",
      "========================================================\n",
      "\n",
      "epoch-0   lr=['0.0100000'], tr/val_loss:  2.023134/  3.001988, val:  43.75%, val_best:  43.75%, tr:  38.20%, tr_best:  38.20%\n",
      "[module.layers.5] weight_fb parameter count: 2,000\n",
      "[module.layers.8] weight_fb parameter count: 2,000\n",
      "epoch-1   lr=['0.0100000'], tr/val_loss:  2.111514/  2.514608, val:  52.92%, val_best:  52.92%, tr:  50.77%, tr_best:  50.77%\n",
      "epoch-2   lr=['0.0100000'], tr/val_loss:  2.031224/  2.193688, val:  52.08%, val_best:  52.92%, tr:  60.06%, tr_best:  60.06%\n",
      "epoch-3   lr=['0.0100000'], tr/val_loss:  1.370920/  2.623903, val:  53.75%, val_best:  53.75%, tr:  67.31%, tr_best:  67.31%\n",
      "epoch-4   lr=['0.0100000'], tr/val_loss:  1.466008/  1.990895, val:  55.42%, val_best:  55.42%, tr:  67.62%, tr_best:  67.62%\n",
      "epoch-5   lr=['0.0100000'], tr/val_loss:  1.304506/  1.992434, val:  51.25%, val_best:  55.42%, tr:  72.73%, tr_best:  72.73%\n",
      "epoch-6   lr=['0.0100000'], tr/val_loss:  0.951967/  2.401338, val:  58.33%, val_best:  58.33%, tr:  78.86%, tr_best:  78.86%\n",
      "epoch-7   lr=['0.0100000'], tr/val_loss:  1.001834/  1.689626, val:  68.33%, val_best:  68.33%, tr:  81.10%, tr_best:  81.10%\n",
      "epoch-8   lr=['0.0100000'], tr/val_loss:  0.698880/  1.995094, val:  62.50%, val_best:  68.33%, tr:  85.80%, tr_best:  85.80%\n",
      "epoch-9   lr=['0.0100000'], tr/val_loss:  0.597871/  2.574824, val:  55.83%, val_best:  68.33%, tr:  89.27%, tr_best:  89.27%\n",
      "epoch-10  lr=['0.0100000'], tr/val_loss:  0.511378/  2.299942, val:  59.17%, val_best:  68.33%, tr:  91.32%, tr_best:  91.32%\n",
      "epoch-11  lr=['0.0100000'], tr/val_loss:  0.530413/  2.122792, val:  71.67%, val_best:  71.67%, tr:  93.26%, tr_best:  93.26%\n",
      "epoch-12  lr=['0.0100000'], tr/val_loss:  0.198173/  2.044431, val:  73.33%, val_best:  73.33%, tr:  98.57%, tr_best:  98.57%\n",
      "epoch-13  lr=['0.0100000'], tr/val_loss:  0.163361/  2.141873, val:  71.67%, val_best:  73.33%, tr:  98.16%, tr_best:  98.57%\n",
      "epoch-14  lr=['0.0100000'], tr/val_loss:  0.102874/  2.337933, val:  70.00%, val_best:  73.33%, tr:  99.80%, tr_best:  99.80%\n",
      "epoch-15  lr=['0.0100000'], tr/val_loss:  0.070738/  2.226854, val:  71.25%, val_best:  73.33%, tr:  99.90%, tr_best:  99.90%\n",
      "epoch-16  lr=['0.0100000'], tr/val_loss:  0.054729/  2.301677, val:  69.58%, val_best:  73.33%, tr:  99.90%, tr_best:  99.90%\n",
      "epoch-17  lr=['0.0100000'], tr/val_loss:  0.045104/  2.297384, val:  74.58%, val_best:  74.58%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-18  lr=['0.0100000'], tr/val_loss:  0.030697/  2.323840, val:  72.08%, val_best:  74.58%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-19  lr=['0.0100000'], tr/val_loss:  0.022774/  2.367569, val:  74.17%, val_best:  74.58%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-20  lr=['0.0100000'], tr/val_loss:  0.017886/  2.453781, val:  74.17%, val_best:  74.58%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-21  lr=['0.0100000'], tr/val_loss:  0.015727/  2.398149, val:  74.58%, val_best:  74.58%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-22  lr=['0.0100000'], tr/val_loss:  0.014444/  2.456565, val:  72.50%, val_best:  74.58%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-23  lr=['0.0100000'], tr/val_loss:  0.012677/  2.500347, val:  74.58%, val_best:  74.58%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-24  lr=['0.0100000'], tr/val_loss:  0.008258/  2.516958, val:  72.50%, val_best:  74.58%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-25  lr=['0.0100000'], tr/val_loss:  0.007857/  2.522533, val:  73.33%, val_best:  74.58%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-26  lr=['0.0100000'], tr/val_loss:  0.006996/  2.561710, val:  73.75%, val_best:  74.58%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-27  lr=['0.0100000'], tr/val_loss:  0.006142/  2.592745, val:  72.08%, val_best:  74.58%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-28  lr=['0.0100000'], tr/val_loss:  0.005472/  2.581604, val:  73.33%, val_best:  74.58%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-29  lr=['0.0100000'], tr/val_loss:  0.004907/  2.614515, val:  72.08%, val_best:  74.58%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-30  lr=['0.0100000'], tr/val_loss:  0.004912/  2.639738, val:  72.50%, val_best:  74.58%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-31  lr=['0.0100000'], tr/val_loss:  0.004993/  2.641900, val:  72.92%, val_best:  74.58%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-32  lr=['0.0100000'], tr/val_loss:  0.004041/  2.623948, val:  75.42%, val_best:  75.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-33  lr=['0.0100000'], tr/val_loss:  0.003508/  2.675347, val:  74.17%, val_best:  75.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-34  lr=['0.0100000'], tr/val_loss:  0.003462/  2.715253, val:  73.75%, val_best:  75.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-35  lr=['0.0100000'], tr/val_loss:  0.003274/  2.694168, val:  74.58%, val_best:  75.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-36  lr=['0.0100000'], tr/val_loss:  0.002874/  2.681730, val:  74.17%, val_best:  75.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-37  lr=['0.0100000'], tr/val_loss:  0.002732/  2.713795, val:  74.58%, val_best:  75.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-38  lr=['0.0100000'], tr/val_loss:  0.002616/  2.726792, val:  74.58%, val_best:  75.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-39  lr=['0.0100000'], tr/val_loss:  0.002276/  2.720180, val:  73.75%, val_best:  75.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-40  lr=['0.0100000'], tr/val_loss:  0.002328/  2.754370, val:  73.33%, val_best:  75.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-41  lr=['0.0100000'], tr/val_loss:  0.002299/  2.769357, val:  74.17%, val_best:  75.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-42  lr=['0.0100000'], tr/val_loss:  0.002242/  2.773268, val:  73.33%, val_best:  75.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-43  lr=['0.0100000'], tr/val_loss:  0.001965/  2.778721, val:  72.92%, val_best:  75.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-44  lr=['0.0100000'], tr/val_loss:  0.001961/  2.788240, val:  73.75%, val_best:  75.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-45  lr=['0.0100000'], tr/val_loss:  0.002073/  2.795415, val:  74.58%, val_best:  75.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-46  lr=['0.0100000'], tr/val_loss:  0.001998/  2.821345, val:  74.17%, val_best:  75.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-47  lr=['0.0100000'], tr/val_loss:  0.001833/  2.823388, val:  73.33%, val_best:  75.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-48  lr=['0.0100000'], tr/val_loss:  0.001883/  2.838425, val:  73.75%, val_best:  75.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-49  lr=['0.0100000'], tr/val_loss:  0.002240/  2.845295, val:  74.17%, val_best:  75.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-50  lr=['0.0100000'], tr/val_loss:  0.001813/  2.855757, val:  74.17%, val_best:  75.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-51  lr=['0.0100000'], tr/val_loss:  0.001488/  2.845507, val:  73.33%, val_best:  75.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-52  lr=['0.0100000'], tr/val_loss:  0.001462/  2.866496, val:  74.58%, val_best:  75.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-53  lr=['0.0100000'], tr/val_loss:  0.001676/  2.862338, val:  74.17%, val_best:  75.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-54  lr=['0.0100000'], tr/val_loss:  0.001729/  2.864422, val:  73.75%, val_best:  75.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-55  lr=['0.0100000'], tr/val_loss:  0.001642/  2.877816, val:  73.33%, val_best:  75.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-56  lr=['0.0100000'], tr/val_loss:  0.001346/  2.896071, val:  73.75%, val_best:  75.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-57  lr=['0.0100000'], tr/val_loss:  0.001421/  2.903207, val:  72.50%, val_best:  75.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-58  lr=['0.0100000'], tr/val_loss:  0.001258/  2.910887, val:  72.92%, val_best:  75.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-59  lr=['0.0100000'], tr/val_loss:  0.001376/  2.914967, val:  73.75%, val_best:  75.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-60  lr=['0.0100000'], tr/val_loss:  0.001203/  2.911509, val:  74.58%, val_best:  75.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-61  lr=['0.0100000'], tr/val_loss:  0.001200/  2.922153, val:  74.17%, val_best:  75.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-62  lr=['0.0100000'], tr/val_loss:  0.001194/  2.923554, val:  74.17%, val_best:  75.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-63  lr=['0.0100000'], tr/val_loss:  0.001164/  2.929359, val:  74.58%, val_best:  75.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-64  lr=['0.0100000'], tr/val_loss:  0.001101/  2.950082, val:  73.33%, val_best:  75.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-65  lr=['0.0100000'], tr/val_loss:  0.001073/  2.955679, val:  74.17%, val_best:  75.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-66  lr=['0.0100000'], tr/val_loss:  0.001074/  2.955414, val:  73.75%, val_best:  75.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-67  lr=['0.0100000'], tr/val_loss:  0.001072/  2.970897, val:  72.50%, val_best:  75.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-68  lr=['0.0100000'], tr/val_loss:  0.001153/  2.962239, val:  74.17%, val_best:  75.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-69  lr=['0.0100000'], tr/val_loss:  0.001256/  2.978068, val:  74.58%, val_best:  75.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-70  lr=['0.0100000'], tr/val_loss:  0.001068/  2.963041, val:  73.33%, val_best:  75.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-71  lr=['0.0100000'], tr/val_loss:  0.001134/  2.970819, val:  74.17%, val_best:  75.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-72  lr=['0.0100000'], tr/val_loss:  0.001172/  2.982860, val:  74.17%, val_best:  75.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-73  lr=['0.0100000'], tr/val_loss:  0.001125/  2.995934, val:  74.17%, val_best:  75.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-74  lr=['0.0100000'], tr/val_loss:  0.001135/  2.976301, val:  74.17%, val_best:  75.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-75  lr=['0.0100000'], tr/val_loss:  0.001232/  2.994116, val:  73.33%, val_best:  75.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-76  lr=['0.0100000'], tr/val_loss:  0.001056/  2.984447, val:  74.17%, val_best:  75.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-77  lr=['0.0100000'], tr/val_loss:  0.000957/  3.008141, val:  73.33%, val_best:  75.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-78  lr=['0.0100000'], tr/val_loss:  0.000933/  3.010585, val:  74.17%, val_best:  75.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-79  lr=['0.0100000'], tr/val_loss:  0.000941/  3.021221, val:  73.75%, val_best:  75.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-80  lr=['0.0100000'], tr/val_loss:  0.000929/  3.013422, val:  73.75%, val_best:  75.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-81  lr=['0.0100000'], tr/val_loss:  0.000870/  3.014841, val:  74.17%, val_best:  75.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-82  lr=['0.0100000'], tr/val_loss:  0.000893/  3.017611, val:  73.75%, val_best:  75.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-83  lr=['0.0100000'], tr/val_loss:  0.000873/  3.025639, val:  75.00%, val_best:  75.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-84  lr=['0.0100000'], tr/val_loss:  0.000837/  3.036876, val:  73.33%, val_best:  75.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-85  lr=['0.0100000'], tr/val_loss:  0.000927/  3.029263, val:  72.50%, val_best:  75.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-86  lr=['0.0100000'], tr/val_loss:  0.000821/  3.049392, val:  74.17%, val_best:  75.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-87  lr=['0.0100000'], tr/val_loss:  0.000820/  3.041935, val:  72.92%, val_best:  75.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-88  lr=['0.0100000'], tr/val_loss:  0.000921/  3.056720, val:  74.17%, val_best:  75.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-89  lr=['0.0100000'], tr/val_loss:  0.000774/  3.044471, val:  72.92%, val_best:  75.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-90  lr=['0.0100000'], tr/val_loss:  0.000808/  3.052808, val:  72.50%, val_best:  75.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-91  lr=['0.0100000'], tr/val_loss:  0.000733/  3.063473, val:  72.92%, val_best:  75.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-92  lr=['0.0100000'], tr/val_loss:  0.000720/  3.061897, val:  72.50%, val_best:  75.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-93  lr=['0.0100000'], tr/val_loss:  0.000739/  3.057487, val:  73.75%, val_best:  75.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-94  lr=['0.0100000'], tr/val_loss:  0.000705/  3.069873, val:  72.92%, val_best:  75.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-95  lr=['0.0100000'], tr/val_loss:  0.000780/  3.065286, val:  72.50%, val_best:  75.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-96  lr=['0.0100000'], tr/val_loss:  0.000707/  3.080913, val:  73.33%, val_best:  75.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-97  lr=['0.0100000'], tr/val_loss:  0.000663/  3.077643, val:  73.75%, val_best:  75.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-98  lr=['0.0100000'], tr/val_loss:  0.000735/  3.078284, val:  74.17%, val_best:  75.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-99  lr=['0.0100000'], tr/val_loss:  0.000699/  3.085836, val:  73.75%, val_best:  75.42%, tr: 100.00%, tr_best: 100.00%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "08f6d1b0607d4a7abed715f251202777",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.006 MB of 0.006 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>iter_acc</td><td>▁▃▅▇▆▇██████████████████████████████████</td></tr><tr><td>summary_val_acc</td><td>▁▃▄▆▄█▇███▇█▇██████████▇███▇███████▇▇▇▇█</td></tr><tr><td>tr_acc</td><td>▁▃▄▆▇███████████████████████████████████</td></tr><tr><td>tr_epoch_loss</td><td>██▆▄▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_acc_best</td><td>▁▃▄▆▆███████████████████████████████████</td></tr><tr><td>val_acc_now</td><td>▁▃▄▆▄█▇███▇█▇██████████▇███▇███████▇▇▇▇█</td></tr><tr><td>val_loss</td><td>█▄▃▁▅▃▄▄▄▅▅▅▆▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇███████████</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>99</td></tr><tr><td>iter_acc</td><td>1.0</td></tr><tr><td>tr_acc</td><td>1.0</td></tr><tr><td>tr_epoch_loss</td><td>0.0007</td></tr><tr><td>val_acc_best</td><td>0.75417</td></tr><tr><td>val_acc_now</td><td>0.7375</td></tr><tr><td>val_loss</td><td>3.08584</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">dry-sweep-87</strong> at: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/d6m9vbyn' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/d6m9vbyn</a><br/> View project at: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>/data2/bh_wandb/wandb/run-20250430_011429-d6m9vbyn/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require(\"core\")`! See https://wandb.me/wandb-core for more information."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Sweep Agent: Waiting for job.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Job received.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: h9pfrizq with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBATCH: 16\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBN_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBPTT_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tDFA_on: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tIMAGE_SIZE: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tOTTT_input_trace_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tTIME: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tUDA_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \talpha_uda: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbias: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcfg: ['M', 'M', 200, 200]\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tchaching_on: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tconvTrue_fcFalse: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdata_path: /data2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tddp_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdenoise_on: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdvs_clipping: 5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdvs_duration: 100000\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepoch_num: 100\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \texclude_class: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \textra_train_dataset: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlast_lif: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_sg_width: 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_decay: 0.5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_init: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_reset: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_threshold: 0.25\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmerge_polarities: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmy_seed: 42\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnet_print: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_workers: 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer_what: SGD\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tpin_memory: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tpre_trained: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tpre_trained_path: net_save/save_now_net_weights_{unique_name}.pth\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \trate_coding: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tscheduler_name: no\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsingle_step: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsurrogate: hard_sigmoid\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_conv_kernel_size: 3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_conv_padding: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_conv_stride: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_trace_const1: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_trace_const2: 0.5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \ttdBN_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \ttrace_on: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \twhich_data: DVS_GESTURE_TONIC\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6dd062bb8bcb438ebb0fe5bbfc0544e2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.011113005876541137, max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.19.10 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.17.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/data2/bh_wandb/wandb/run-20250430_012138-h9pfrizq</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/h9pfrizq' target=\"_blank\">likely-sweep-91</a></strong> to <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/6pj3lh8j' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/6pj3lh8j</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/6pj3lh8j' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/6pj3lh8j</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/h9pfrizq' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/h9pfrizq</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'single_step' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'my_seed' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'TIME' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BATCH' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'IMAGE_SIZE' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'which_data' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'data_path' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'rate_coding' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_init' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_decay' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_threshold' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_reset' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_sg_width' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_conv_kernel_size' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_conv_stride' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_conv_padding' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_trace_const1' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_trace_const2' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'pre_trained' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'convTrue_fcFalse' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'cfg' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'net_print' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'pre_trained_path' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'learning_rate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'epoch_num' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'tdBN_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BN_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'surrogate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BPTT_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'optimizer_what' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'scheduler_name' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'ddp_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'dvs_clipping' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'dvs_duration' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'DFA_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'trace_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'OTTT_input_trace_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'exclude_class' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'merge_polarities' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'denoise_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'extra_train_dataset' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'num_workers' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'chaching_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'pin_memory' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'UDA_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'alpha_uda' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'bias' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'last_lif' was locked by 'sweep' (ignored update).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "param {'devices': '0', 'single_step': True, 'unique_name': 'main', 'my_seed': 42, 'TIME': 10, 'BATCH': 16, 'IMAGE_SIZE': 128, 'which_data': 'DVS_GESTURE_TONIC', 'data_path': '/data2', 'rate_coding': False, 'lif_layer_v_init': 0, 'lif_layer_v_decay': 0.5, 'lif_layer_v_threshold': 0.25, 'lif_layer_v_reset': 0, 'lif_layer_sg_width': 2, 'synapse_conv_kernel_size': 3, 'synapse_conv_stride': 1, 'synapse_conv_padding': 1, 'synapse_trace_const1': 1, 'synapse_trace_const2': 0.5, 'pre_trained': False, 'convTrue_fcFalse': False, 'cfg': ['M', 'M', 200, 200], 'net_print': True, 'pre_trained_path': 'net_save/save_now_net_weights_{unique_name}.pth', 'learning_rate': 0.1, 'epoch_num': 100, 'tdBN_on': False, 'BN_on': False, 'surrogate': 'hard_sigmoid', 'BPTT_on': False, 'optimizer_what': 'SGD', 'scheduler_name': 'no', 'ddp_on': False, 'dvs_clipping': 5, 'dvs_duration': 100000, 'DFA_on': True, 'trace_on': True, 'OTTT_input_trace_on': False, 'exclude_class': True, 'merge_polarities': False, 'denoise_on': True, 'extra_train_dataset': 0, 'num_workers': 2, 'chaching_on': True, 'pin_memory': True, 'UDA_on': False, 'alpha_uda': 1, 'bias': True, 'last_lif': False, 'current epoch': 0} \n",
      "\n",
      "dataset_hash = 63cc597115630ec173f3099200061e53\n",
      "cache path exists\n",
      "\n",
      "device ==> cuda\n",
      "\n",
      "DataParallel(\n",
      "  (module): REBORN_MY_SNN_FC(\n",
      "    (layers): REBORN_MY_Sequential(\n",
      "      (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (2): DimChanger_for_FC()\n",
      "      (3): SYNAPSE_FC(in_features=2048, out_features=200, TIME=10, bias=True, sstep=True)\n",
      "      (4): LIF_layer(v_init=0, v_decay=0.5, v_threshold=0.25, v_reset=0, sg_width=2, surrogate=hard_sigmoid, BPTT_on=False, trace_const1=1, trace_const2=0.5, TIME=10, sstep=True, trace_on=True)\n",
      "      (5): Feedback_Receiver()\n",
      "      (6): SYNAPSE_FC(in_features=200, out_features=200, TIME=10, bias=True, sstep=True)\n",
      "      (7): LIF_layer(v_init=0, v_decay=0.5, v_threshold=0.25, v_reset=0, sg_width=2, surrogate=hard_sigmoid, BPTT_on=False, trace_const1=1, trace_const2=0.5, TIME=10, sstep=True, trace_on=True)\n",
      "      (8): Feedback_Receiver()\n",
      "      (9): SYNAPSE_FC(in_features=200, out_features=10, TIME=10, bias=True, sstep=True)\n",
      "      (DFA_top): Top_Gradient()\n",
      "    )\n",
      "  )\n",
      ")\n",
      "\n",
      "========================================================\n",
      "Trainable parameters: 452,010\n",
      "========================================================\n",
      "\n",
      "epoch-0   lr=['0.1000000'], tr/val_loss: 73.062462/ 62.712994, val:  40.83%, val_best:  40.83%, tr:  26.25%, tr_best:  26.25%\n",
      "[module.layers.5] weight_fb parameter count: 2,000\n",
      "[module.layers.8] weight_fb parameter count: 2,000\n",
      "epoch-1   lr=['0.1000000'], tr/val_loss: 48.727184/ 36.323574, val:  44.17%, val_best:  44.17%, tr:  40.96%, tr_best:  40.96%\n",
      "epoch-2   lr=['0.1000000'], tr/val_loss: 27.953823/ 67.766357, val:  36.67%, val_best:  44.17%, tr:  54.03%, tr_best:  54.03%\n",
      "epoch-3   lr=['0.1000000'], tr/val_loss: 36.586460/ 39.313217, val:  54.17%, val_best:  54.17%, tr:  53.12%, tr_best:  54.03%\n",
      "epoch-4   lr=['0.1000000'], tr/val_loss: 36.790657/ 48.128754, val:  55.83%, val_best:  55.83%, tr:  52.09%, tr_best:  54.03%\n",
      "epoch-5   lr=['0.1000000'], tr/val_loss: 36.101292/ 66.155510, val:  44.17%, val_best:  55.83%, tr:  56.18%, tr_best:  56.18%\n",
      "epoch-6   lr=['0.1000000'], tr/val_loss: 30.806480/ 36.097267, val:  58.75%, val_best:  58.75%, tr:  64.76%, tr_best:  64.76%\n",
      "epoch-7   lr=['0.1000000'], tr/val_loss: 28.280203/ 63.594070, val:  32.50%, val_best:  58.75%, tr:  62.92%, tr_best:  64.76%\n",
      "epoch-8   lr=['0.1000000'], tr/val_loss: 24.479040/ 47.571873, val:  45.83%, val_best:  58.75%, tr:  65.07%, tr_best:  65.07%\n",
      "epoch-9   lr=['0.1000000'], tr/val_loss: 22.942385/ 35.460094, val:  58.33%, val_best:  58.75%, tr:  68.23%, tr_best:  68.23%\n",
      "epoch-10  lr=['0.1000000'], tr/val_loss: 17.889397/ 36.977951, val:  54.17%, val_best:  58.75%, tr:  74.87%, tr_best:  74.87%\n",
      "epoch-11  lr=['0.1000000'], tr/val_loss: 13.806804/ 36.136753, val:  50.00%, val_best:  58.75%, tr:  77.12%, tr_best:  77.12%\n",
      "epoch-12  lr=['0.1000000'], tr/val_loss: 19.440714/ 33.677872, val:  65.83%, val_best:  65.83%, tr:  76.20%, tr_best:  77.12%\n",
      "epoch-13  lr=['0.1000000'], tr/val_loss: 13.918588/ 47.281990, val:  53.33%, val_best:  65.83%, tr:  79.88%, tr_best:  79.88%\n",
      "epoch-14  lr=['0.1000000'], tr/val_loss: 12.377747/ 29.419312, val:  70.00%, val_best:  70.00%, tr:  85.50%, tr_best:  85.50%\n",
      "epoch-15  lr=['0.1000000'], tr/val_loss:  5.903659/ 34.827240, val:  62.92%, val_best:  70.00%, tr:  93.67%, tr_best:  93.67%\n",
      "epoch-16  lr=['0.1000000'], tr/val_loss:  6.015640/ 32.514950, val:  62.92%, val_best:  70.00%, tr:  93.16%, tr_best:  93.67%\n",
      "epoch-17  lr=['0.1000000'], tr/val_loss:  4.158886/ 32.335564, val:  67.50%, val_best:  70.00%, tr:  97.14%, tr_best:  97.14%\n",
      "epoch-18  lr=['0.1000000'], tr/val_loss:  4.104442/ 33.057064, val:  68.75%, val_best:  70.00%, tr:  96.63%, tr_best:  97.14%\n",
      "epoch-19  lr=['0.1000000'], tr/val_loss:  4.386081/ 36.628113, val:  65.42%, val_best:  70.00%, tr:  96.02%, tr_best:  97.14%\n",
      "epoch-20  lr=['0.1000000'], tr/val_loss:  3.136566/ 32.447052, val:  71.67%, val_best:  71.67%, tr:  97.55%, tr_best:  97.55%\n",
      "epoch-21  lr=['0.1000000'], tr/val_loss:  2.373895/ 33.992107, val:  65.83%, val_best:  71.67%, tr:  98.88%, tr_best:  98.88%\n",
      "epoch-22  lr=['0.1000000'], tr/val_loss:  1.777808/ 35.242638, val:  70.83%, val_best:  71.67%, tr:  99.18%, tr_best:  99.18%\n",
      "epoch-23  lr=['0.1000000'], tr/val_loss:  1.346974/ 36.958138, val:  72.92%, val_best:  72.92%, tr:  99.80%, tr_best:  99.80%\n",
      "epoch-24  lr=['0.1000000'], tr/val_loss:  1.410279/ 38.968197, val:  68.75%, val_best:  72.92%, tr:  99.39%, tr_best:  99.80%\n",
      "epoch-25  lr=['0.1000000'], tr/val_loss:  1.377105/ 39.091709, val:  67.08%, val_best:  72.92%, tr:  99.39%, tr_best:  99.80%\n",
      "epoch-26  lr=['0.1000000'], tr/val_loss:  1.027403/ 37.097275, val:  73.33%, val_best:  73.33%, tr:  99.49%, tr_best:  99.80%\n",
      "epoch-27  lr=['0.1000000'], tr/val_loss:  1.381123/ 40.875244, val:  72.92%, val_best:  73.33%, tr:  98.98%, tr_best:  99.80%\n",
      "epoch-28  lr=['0.1000000'], tr/val_loss:  0.896082/ 35.021217, val:  72.50%, val_best:  73.33%, tr:  99.69%, tr_best:  99.80%\n",
      "epoch-29  lr=['0.1000000'], tr/val_loss:  0.917275/ 41.246544, val:  66.25%, val_best:  73.33%, tr:  99.69%, tr_best:  99.80%\n",
      "epoch-30  lr=['0.1000000'], tr/val_loss:  0.506911/ 39.480194, val:  71.67%, val_best:  73.33%, tr:  99.90%, tr_best:  99.90%\n",
      "epoch-31  lr=['0.1000000'], tr/val_loss:  0.505302/ 38.872429, val:  71.67%, val_best:  73.33%, tr:  99.90%, tr_best:  99.90%\n",
      "epoch-32  lr=['0.1000000'], tr/val_loss:  0.318503/ 41.089451, val:  67.92%, val_best:  73.33%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-33  lr=['0.1000000'], tr/val_loss:  0.415576/ 40.776005, val:  70.83%, val_best:  73.33%, tr:  99.90%, tr_best: 100.00%\n",
      "epoch-34  lr=['0.1000000'], tr/val_loss:  0.339964/ 41.926315, val:  67.50%, val_best:  73.33%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-35  lr=['0.1000000'], tr/val_loss:  0.463883/ 40.467865, val:  69.58%, val_best:  73.33%, tr:  99.80%, tr_best: 100.00%\n",
      "epoch-36  lr=['0.1000000'], tr/val_loss:  0.230886/ 38.690338, val:  75.00%, val_best:  75.00%, tr:  99.90%, tr_best: 100.00%\n",
      "epoch-37  lr=['0.1000000'], tr/val_loss:  0.448152/ 38.912048, val:  71.25%, val_best:  75.00%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-38  lr=['0.1000000'], tr/val_loss:  0.269473/ 38.634979, val:  73.33%, val_best:  75.00%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-39  lr=['0.1000000'], tr/val_loss:  0.179929/ 39.736141, val:  70.83%, val_best:  75.00%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-40  lr=['0.1000000'], tr/val_loss:  0.169367/ 38.658745, val:  73.33%, val_best:  75.00%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-41  lr=['0.1000000'], tr/val_loss:  0.221253/ 39.838089, val:  72.50%, val_best:  75.00%, tr:  99.90%, tr_best: 100.00%\n",
      "epoch-42  lr=['0.1000000'], tr/val_loss:  0.145861/ 39.377766, val:  70.00%, val_best:  75.00%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-43  lr=['0.1000000'], tr/val_loss:  0.091435/ 38.811279, val:  70.42%, val_best:  75.00%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-44  lr=['0.1000000'], tr/val_loss:  0.096707/ 37.858398, val:  74.17%, val_best:  75.00%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-45  lr=['0.1000000'], tr/val_loss:  0.180971/ 40.959721, val:  68.33%, val_best:  75.00%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-46  lr=['0.1000000'], tr/val_loss:  0.170375/ 40.201096, val:  70.42%, val_best:  75.00%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-47  lr=['0.1000000'], tr/val_loss:  0.065969/ 39.474720, val:  72.50%, val_best:  75.00%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-48  lr=['0.1000000'], tr/val_loss:  0.069438/ 40.413048, val:  72.08%, val_best:  75.00%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-49  lr=['0.1000000'], tr/val_loss:  0.076751/ 39.785061, val:  72.92%, val_best:  75.00%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-50  lr=['0.1000000'], tr/val_loss:  0.091621/ 40.086452, val:  72.08%, val_best:  75.00%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-51  lr=['0.1000000'], tr/val_loss:  0.084891/ 40.414902, val:  70.00%, val_best:  75.00%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-52  lr=['0.1000000'], tr/val_loss:  0.082935/ 40.758743, val:  72.50%, val_best:  75.00%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-53  lr=['0.1000000'], tr/val_loss:  0.068182/ 39.105442, val:  70.00%, val_best:  75.00%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-54  lr=['0.1000000'], tr/val_loss:  0.064310/ 38.315304, val:  72.92%, val_best:  75.00%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-55  lr=['0.1000000'], tr/val_loss:  0.050849/ 39.604332, val:  72.08%, val_best:  75.00%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-56  lr=['0.1000000'], tr/val_loss:  0.045349/ 39.646748, val:  70.83%, val_best:  75.00%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-57  lr=['0.1000000'], tr/val_loss:  0.095188/ 39.623829, val:  73.75%, val_best:  75.00%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-58  lr=['0.1000000'], tr/val_loss:  0.049793/ 39.506763, val:  73.33%, val_best:  75.00%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-59  lr=['0.1000000'], tr/val_loss:  0.026106/ 38.869530, val:  71.25%, val_best:  75.00%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-60  lr=['0.1000000'], tr/val_loss:  0.049440/ 38.780575, val:  73.75%, val_best:  75.00%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-61  lr=['0.1000000'], tr/val_loss:  0.039492/ 38.860714, val:  72.08%, val_best:  75.00%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-62  lr=['0.1000000'], tr/val_loss:  0.009967/ 40.607567, val:  70.42%, val_best:  75.00%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-63  lr=['0.1000000'], tr/val_loss:  0.014978/ 40.242744, val:  70.83%, val_best:  75.00%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-64  lr=['0.1000000'], tr/val_loss:  0.019490/ 39.573135, val:  71.67%, val_best:  75.00%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-65  lr=['0.1000000'], tr/val_loss:  0.098090/ 41.486244, val:  68.33%, val_best:  75.00%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-66  lr=['0.1000000'], tr/val_loss:  0.038872/ 39.431850, val:  73.33%, val_best:  75.00%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-67  lr=['0.1000000'], tr/val_loss:  0.020985/ 41.372414, val:  69.58%, val_best:  75.00%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-68  lr=['0.1000000'], tr/val_loss:  0.022976/ 42.711113, val:  70.00%, val_best:  75.00%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-69  lr=['0.1000000'], tr/val_loss:  0.035895/ 42.364399, val:  69.17%, val_best:  75.00%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-70  lr=['0.1000000'], tr/val_loss:  0.030383/ 40.969711, val:  70.83%, val_best:  75.00%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-71  lr=['0.1000000'], tr/val_loss:  0.082569/ 40.401291, val:  69.17%, val_best:  75.00%, tr:  99.90%, tr_best: 100.00%\n",
      "epoch-72  lr=['0.1000000'], tr/val_loss:  0.037498/ 40.507854, val:  70.42%, val_best:  75.00%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-73  lr=['0.1000000'], tr/val_loss:  0.034545/ 41.780563, val:  70.83%, val_best:  75.00%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-74  lr=['0.1000000'], tr/val_loss:  0.009969/ 43.172520, val:  68.33%, val_best:  75.00%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-75  lr=['0.1000000'], tr/val_loss:  0.001204/ 42.303509, val:  68.33%, val_best:  75.00%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-76  lr=['0.1000000'], tr/val_loss:  0.034642/ 41.054287, val:  71.25%, val_best:  75.00%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-77  lr=['0.1000000'], tr/val_loss:  0.007766/ 39.330887, val:  72.92%, val_best:  75.00%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-78  lr=['0.1000000'], tr/val_loss:  0.001847/ 39.324657, val:  72.92%, val_best:  75.00%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-79  lr=['0.1000000'], tr/val_loss:  0.000284/ 39.581135, val:  71.67%, val_best:  75.00%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-80  lr=['0.1000000'], tr/val_loss:  0.000975/ 39.534897, val:  72.50%, val_best:  75.00%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-81  lr=['0.1000000'], tr/val_loss:  0.000068/ 39.761677, val:  71.67%, val_best:  75.00%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-82  lr=['0.1000000'], tr/val_loss:  0.000001/ 39.767467, val:  71.67%, val_best:  75.00%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-83  lr=['0.1000000'], tr/val_loss:  0.000001/ 39.739967, val:  71.67%, val_best:  75.00%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-84  lr=['0.1000000'], tr/val_loss:  0.000001/ 39.739010, val:  71.67%, val_best:  75.00%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-85  lr=['0.1000000'], tr/val_loss:  0.000001/ 39.737690, val:  71.67%, val_best:  75.00%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-86  lr=['0.1000000'], tr/val_loss:  0.000001/ 39.736748, val:  71.67%, val_best:  75.00%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-87  lr=['0.1000000'], tr/val_loss:  0.000001/ 39.736572, val:  71.67%, val_best:  75.00%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-88  lr=['0.1000000'], tr/val_loss:  0.000001/ 39.735725, val:  71.67%, val_best:  75.00%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-89  lr=['0.1000000'], tr/val_loss:  0.000000/ 39.736641, val:  71.67%, val_best:  75.00%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-90  lr=['0.1000000'], tr/val_loss:  0.000000/ 39.719971, val:  71.67%, val_best:  75.00%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-91  lr=['0.1000000'], tr/val_loss:  0.000000/ 39.718094, val:  71.67%, val_best:  75.00%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-92  lr=['0.1000000'], tr/val_loss:  0.000001/ 39.742317, val:  71.67%, val_best:  75.00%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-93  lr=['0.1000000'], tr/val_loss:  0.000000/ 39.741699, val:  71.67%, val_best:  75.00%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-94  lr=['0.1000000'], tr/val_loss:  0.000000/ 39.741261, val:  71.67%, val_best:  75.00%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-95  lr=['0.1000000'], tr/val_loss:  0.000000/ 39.740562, val:  71.67%, val_best:  75.00%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-96  lr=['0.1000000'], tr/val_loss:  0.000000/ 39.740070, val:  71.67%, val_best:  75.00%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-97  lr=['0.1000000'], tr/val_loss:  0.000000/ 39.739594, val:  71.67%, val_best:  75.00%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-98  lr=['0.1000000'], tr/val_loss:  0.000000/ 39.734539, val:  71.67%, val_best:  75.00%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-99  lr=['0.1000000'], tr/val_loss:  0.000000/ 39.734165, val:  71.67%, val_best:  75.00%, tr: 100.00%, tr_best: 100.00%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "207f8fc066a143939d1c778183736d28",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.006 MB of 0.006 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>iter_acc</td><td>▁▂▃▇▄▅██▇███████████████████████████████</td></tr><tr><td>summary_val_acc</td><td>▂▂▅▁▅▇▇▇▇▇▇█▇▇▇█▇▇████████▇▇▇▇▇█████████</td></tr><tr><td>tr_acc</td><td>▁▄▃▄▅▆▇█████████████████████████████████</td></tr><tr><td>tr_epoch_loss</td><td>█▄▅▄▃▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_acc_best</td><td>▁▂▄▅▅▆▇▇▇▇██████████████████████████████</td></tr><tr><td>val_acc_now</td><td>▂▂▅▁▅▇▇▇▇▇▇█▇▇▇█▇▇████████▇▇▇▇▇█████████</td></tr><tr><td>val_loss</td><td>▇█▄▇▂▂▁▂▂▂▃▂▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>99</td></tr><tr><td>iter_acc</td><td>1.0</td></tr><tr><td>tr_acc</td><td>1.0</td></tr><tr><td>tr_epoch_loss</td><td>0.0</td></tr><tr><td>val_acc_best</td><td>0.75</td></tr><tr><td>val_acc_now</td><td>0.71667</td></tr><tr><td>val_loss</td><td>39.73417</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">likely-sweep-91</strong> at: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/h9pfrizq' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/h9pfrizq</a><br/> View project at: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>/data2/bh_wandb/wandb/run-20250430_012138-h9pfrizq/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require(\"core\")`! See https://wandb.me/wandb-core for more information."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: ojymiwi8 with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBATCH: 16\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBN_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBPTT_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tDFA_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tIMAGE_SIZE: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tOTTT_input_trace_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tTIME: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tUDA_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \talpha_uda: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbias: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcfg: ['M', 'M', 200, 200]\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tchaching_on: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tconvTrue_fcFalse: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdata_path: /data2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tddp_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdenoise_on: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdvs_clipping: 5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdvs_duration: 100000\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepoch_num: 100\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \texclude_class: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \textra_train_dataset: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlast_lif: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.01\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_sg_width: 3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_decay: 0.5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_init: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_reset: 10000\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_threshold: 0.5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmerge_polarities: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmy_seed: 42\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnet_print: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_workers: 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer_what: SGD\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tpin_memory: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tpre_trained: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tpre_trained_path: net_save/save_now_net_weights_{unique_name}.pth\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \trate_coding: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tscheduler_name: no\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsingle_step: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsurrogate: hard_sigmoid\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_conv_kernel_size: 3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_conv_padding: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_conv_stride: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_trace_const1: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_trace_const2: 0.5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \ttdBN_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \ttrace_on: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \twhich_data: DVS_GESTURE_TONIC\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.19.10 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.17.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/data2/bh_wandb/wandb/run-20250430_012846-ojymiwi8</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/ojymiwi8' target=\"_blank\">cool-sweep-95</a></strong> to <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/6pj3lh8j' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/6pj3lh8j</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/6pj3lh8j' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/6pj3lh8j</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/ojymiwi8' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/ojymiwi8</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'single_step' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'my_seed' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'TIME' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BATCH' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'IMAGE_SIZE' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'which_data' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'data_path' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'rate_coding' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_init' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_decay' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_threshold' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_reset' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_sg_width' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_conv_kernel_size' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_conv_stride' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_conv_padding' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_trace_const1' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_trace_const2' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'pre_trained' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'convTrue_fcFalse' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'cfg' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'net_print' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'pre_trained_path' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'learning_rate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'epoch_num' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'tdBN_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BN_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'surrogate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BPTT_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'optimizer_what' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'scheduler_name' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'ddp_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'dvs_clipping' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'dvs_duration' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'DFA_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'trace_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'OTTT_input_trace_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'exclude_class' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'merge_polarities' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'denoise_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'extra_train_dataset' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'num_workers' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'chaching_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'pin_memory' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'UDA_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'alpha_uda' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'bias' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'last_lif' was locked by 'sweep' (ignored update).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "param {'devices': '0', 'single_step': True, 'unique_name': 'main', 'my_seed': 42, 'TIME': 10, 'BATCH': 16, 'IMAGE_SIZE': 128, 'which_data': 'DVS_GESTURE_TONIC', 'data_path': '/data2', 'rate_coding': False, 'lif_layer_v_init': 0, 'lif_layer_v_decay': 0.5, 'lif_layer_v_threshold': 0.5, 'lif_layer_v_reset': 10000, 'lif_layer_sg_width': 3, 'synapse_conv_kernel_size': 3, 'synapse_conv_stride': 1, 'synapse_conv_padding': 1, 'synapse_trace_const1': 1, 'synapse_trace_const2': 0.5, 'pre_trained': False, 'convTrue_fcFalse': False, 'cfg': ['M', 'M', 200, 200], 'net_print': True, 'pre_trained_path': 'net_save/save_now_net_weights_{unique_name}.pth', 'learning_rate': 0.01, 'epoch_num': 100, 'tdBN_on': False, 'BN_on': False, 'surrogate': 'hard_sigmoid', 'BPTT_on': False, 'optimizer_what': 'SGD', 'scheduler_name': 'no', 'ddp_on': False, 'dvs_clipping': 5, 'dvs_duration': 100000, 'DFA_on': False, 'trace_on': True, 'OTTT_input_trace_on': False, 'exclude_class': True, 'merge_polarities': False, 'denoise_on': True, 'extra_train_dataset': 0, 'num_workers': 2, 'chaching_on': True, 'pin_memory': True, 'UDA_on': False, 'alpha_uda': 1, 'bias': True, 'last_lif': False, 'current epoch': 0} \n",
      "\n",
      "dataset_hash = 63cc597115630ec173f3099200061e53\n",
      "cache path exists\n",
      "\n",
      "device ==> cuda\n",
      "\n",
      "DataParallel(\n",
      "  (module): REBORN_MY_SNN_FC(\n",
      "    (layers): REBORN_MY_Sequential(\n",
      "      (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (2): DimChanger_for_FC()\n",
      "      (3): SYNAPSE_FC(in_features=2048, out_features=200, TIME=10, bias=True, sstep=True)\n",
      "      (4): LIF_layer(v_init=0, v_decay=0.5, v_threshold=0.5, v_reset=10000, sg_width=3, surrogate=hard_sigmoid, BPTT_on=False, trace_const1=1, trace_const2=0.5, TIME=10, sstep=True, trace_on=True)\n",
      "      (5): SYNAPSE_FC(in_features=200, out_features=200, TIME=10, bias=True, sstep=True)\n",
      "      (6): LIF_layer(v_init=0, v_decay=0.5, v_threshold=0.5, v_reset=10000, sg_width=3, surrogate=hard_sigmoid, BPTT_on=False, trace_const1=1, trace_const2=0.5, TIME=10, sstep=True, trace_on=True)\n",
      "      (7): SYNAPSE_FC(in_features=200, out_features=10, TIME=10, bias=True, sstep=True)\n",
      "    )\n",
      "  )\n",
      ")\n",
      "\n",
      "========================================================\n",
      "Trainable parameters: 452,010\n",
      "========================================================\n",
      "\n",
      "epoch-0   lr=['0.0100000'], tr/val_loss:  2.139273/  1.916143, val:  46.67%, val_best:  46.67%, tr:  24.21%, tr_best:  24.21%\n",
      "epoch-1   lr=['0.0100000'], tr/val_loss:  1.483072/  1.498653, val:  56.25%, val_best:  56.25%, tr:  54.14%, tr_best:  54.14%\n",
      "epoch-2   lr=['0.0100000'], tr/val_loss:  1.309892/  1.522198, val:  57.08%, val_best:  57.08%, tr:  60.88%, tr_best:  60.88%\n",
      "epoch-3   lr=['0.0100000'], tr/val_loss:  1.065062/  1.582847, val:  58.75%, val_best:  58.75%, tr:  68.74%, tr_best:  68.74%\n",
      "epoch-4   lr=['0.0100000'], tr/val_loss:  1.032444/  1.479451, val:  61.67%, val_best:  61.67%, tr:  69.25%, tr_best:  69.25%\n",
      "epoch-5   lr=['0.0100000'], tr/val_loss:  0.982907/  1.651169, val:  51.25%, val_best:  61.67%, tr:  71.20%, tr_best:  71.20%\n",
      "epoch-6   lr=['0.0100000'], tr/val_loss:  0.901784/  1.578253, val:  61.67%, val_best:  61.67%, tr:  73.34%, tr_best:  73.34%\n",
      "epoch-7   lr=['0.0100000'], tr/val_loss:  0.881050/  1.886544, val:  59.17%, val_best:  61.67%, tr:  75.38%, tr_best:  75.38%\n",
      "epoch-8   lr=['0.0100000'], tr/val_loss:  0.802476/  1.757996, val:  63.33%, val_best:  63.33%, tr:  76.20%, tr_best:  76.20%\n",
      "epoch-9   lr=['0.0100000'], tr/val_loss:  0.739693/  2.060881, val:  61.67%, val_best:  63.33%, tr:  80.69%, tr_best:  80.69%\n",
      "epoch-10  lr=['0.0100000'], tr/val_loss:  0.723456/  1.857257, val:  65.83%, val_best:  65.83%, tr:  81.21%, tr_best:  81.21%\n",
      "epoch-11  lr=['0.0100000'], tr/val_loss:  0.685295/  2.335636, val:  65.00%, val_best:  65.83%, tr:  83.96%, tr_best:  83.96%\n",
      "epoch-12  lr=['0.0100000'], tr/val_loss:  0.645210/  1.882159, val:  76.25%, val_best:  76.25%, tr:  87.33%, tr_best:  87.33%\n",
      "epoch-13  lr=['0.0100000'], tr/val_loss:  0.642564/  2.212750, val:  73.75%, val_best:  76.25%, tr:  88.05%, tr_best:  88.05%\n",
      "epoch-14  lr=['0.0100000'], tr/val_loss:  0.535259/  2.850857, val:  67.92%, val_best:  76.25%, tr:  91.83%, tr_best:  91.83%\n",
      "epoch-15  lr=['0.0100000'], tr/val_loss:  0.616642/  2.661998, val:  67.92%, val_best:  76.25%, tr:  91.83%, tr_best:  91.83%\n",
      "epoch-16  lr=['0.0100000'], tr/val_loss:  0.587759/  2.536247, val:  77.92%, val_best:  77.92%, tr:  93.05%, tr_best:  93.05%\n",
      "epoch-17  lr=['0.0100000'], tr/val_loss:  0.501291/  2.501836, val:  72.92%, val_best:  77.92%, tr:  94.79%, tr_best:  94.79%\n",
      "epoch-18  lr=['0.0100000'], tr/val_loss:  0.478993/  2.769455, val:  71.67%, val_best:  77.92%, tr:  93.97%, tr_best:  94.79%\n",
      "epoch-19  lr=['0.0100000'], tr/val_loss:  0.608311/  2.770335, val:  71.67%, val_best:  77.92%, tr:  91.62%, tr_best:  94.79%\n",
      "epoch-20  lr=['0.0100000'], tr/val_loss:  0.547253/  3.112242, val:  75.00%, val_best:  77.92%, tr:  94.69%, tr_best:  94.79%\n",
      "epoch-21  lr=['0.0100000'], tr/val_loss:  0.438107/  3.081007, val:  70.83%, val_best:  77.92%, tr:  97.14%, tr_best:  97.14%\n",
      "epoch-22  lr=['0.0100000'], tr/val_loss:  0.438007/  3.391781, val:  74.17%, val_best:  77.92%, tr:  97.24%, tr_best:  97.24%\n",
      "epoch-23  lr=['0.0100000'], tr/val_loss:  0.560278/  3.297233, val:  75.83%, val_best:  77.92%, tr:  94.48%, tr_best:  97.24%\n",
      "epoch-24  lr=['0.0100000'], tr/val_loss:  0.403686/  3.372742, val:  76.25%, val_best:  77.92%, tr:  98.06%, tr_best:  98.06%\n",
      "epoch-25  lr=['0.0100000'], tr/val_loss:  0.360833/  3.386280, val:  74.58%, val_best:  77.92%, tr:  98.47%, tr_best:  98.47%\n",
      "epoch-26  lr=['0.0100000'], tr/val_loss:  0.382191/  3.792433, val:  75.42%, val_best:  77.92%, tr:  96.83%, tr_best:  98.47%\n",
      "epoch-27  lr=['0.0100000'], tr/val_loss:  0.303355/  3.875961, val:  72.08%, val_best:  77.92%, tr:  98.98%, tr_best:  98.98%\n",
      "epoch-28  lr=['0.0100000'], tr/val_loss:  0.282679/  3.889672, val:  76.67%, val_best:  77.92%, tr:  99.80%, tr_best:  99.80%\n",
      "epoch-29  lr=['0.0100000'], tr/val_loss:  0.249574/  4.098078, val:  70.83%, val_best:  77.92%, tr:  99.90%, tr_best:  99.90%\n",
      "epoch-30  lr=['0.0100000'], tr/val_loss:  0.306964/  3.702863, val:  77.50%, val_best:  77.92%, tr:  99.49%, tr_best:  99.90%\n",
      "epoch-31  lr=['0.0100000'], tr/val_loss:  0.244966/  3.899006, val:  77.50%, val_best:  77.92%, tr:  99.80%, tr_best:  99.90%\n",
      "epoch-32  lr=['0.0100000'], tr/val_loss:  0.362466/  4.444578, val:  73.75%, val_best:  77.92%, tr:  98.67%, tr_best:  99.90%\n",
      "epoch-33  lr=['0.0100000'], tr/val_loss:  0.387578/  4.263828, val:  80.00%, val_best:  80.00%, tr:  98.37%, tr_best:  99.90%\n",
      "epoch-34  lr=['0.0100000'], tr/val_loss:  0.396499/  4.036929, val:  76.25%, val_best:  80.00%, tr:  99.28%, tr_best:  99.90%\n",
      "epoch-35  lr=['0.0100000'], tr/val_loss:  0.324258/  4.553202, val:  73.75%, val_best:  80.00%, tr:  99.18%, tr_best:  99.90%\n",
      "epoch-36  lr=['0.0100000'], tr/val_loss:  0.309340/  4.579342, val:  77.50%, val_best:  80.00%, tr:  99.49%, tr_best:  99.90%\n",
      "epoch-37  lr=['0.0100000'], tr/val_loss:  0.353695/  4.753322, val:  75.42%, val_best:  80.00%, tr:  99.69%, tr_best:  99.90%\n",
      "epoch-38  lr=['0.0100000'], tr/val_loss:  0.335095/  4.778972, val:  72.50%, val_best:  80.00%, tr:  99.59%, tr_best:  99.90%\n",
      "epoch-39  lr=['0.0100000'], tr/val_loss:  0.376638/  5.003154, val:  75.00%, val_best:  80.00%, tr:  98.88%, tr_best:  99.90%\n",
      "epoch-40  lr=['0.0100000'], tr/val_loss:  0.289973/  4.649467, val:  77.92%, val_best:  80.00%, tr:  99.80%, tr_best:  99.90%\n",
      "epoch-41  lr=['0.0100000'], tr/val_loss:  0.311783/  4.808716, val:  70.42%, val_best:  80.00%, tr:  99.28%, tr_best:  99.90%\n",
      "epoch-42  lr=['0.0100000'], tr/val_loss:  0.271646/  5.060377, val:  76.67%, val_best:  80.00%, tr:  99.80%, tr_best:  99.90%\n",
      "epoch-43  lr=['0.0100000'], tr/val_loss:  0.339808/  4.712704, val:  75.83%, val_best:  80.00%, tr:  99.39%, tr_best:  99.90%\n",
      "epoch-44  lr=['0.0100000'], tr/val_loss:  0.299347/  5.777447, val:  72.92%, val_best:  80.00%, tr:  99.80%, tr_best:  99.90%\n",
      "epoch-45  lr=['0.0100000'], tr/val_loss:  0.379543/  4.984003, val:  77.08%, val_best:  80.00%, tr:  99.69%, tr_best:  99.90%\n",
      "epoch-46  lr=['0.0100000'], tr/val_loss:  0.355949/  5.210151, val:  74.58%, val_best:  80.00%, tr:  99.69%, tr_best:  99.90%\n",
      "epoch-47  lr=['0.0100000'], tr/val_loss:  0.297335/  4.958134, val:  80.00%, val_best:  80.00%, tr:  99.49%, tr_best:  99.90%\n",
      "epoch-48  lr=['0.0100000'], tr/val_loss:  0.218306/  5.091975, val:  78.75%, val_best:  80.00%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-49  lr=['0.0100000'], tr/val_loss:  0.273856/  5.310834, val:  77.92%, val_best:  80.00%, tr:  99.49%, tr_best: 100.00%\n",
      "epoch-50  lr=['0.0100000'], tr/val_loss:  0.301364/  5.716263, val:  75.00%, val_best:  80.00%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-51  lr=['0.0100000'], tr/val_loss:  0.657080/  5.537762, val:  73.75%, val_best:  80.00%, tr:  96.02%, tr_best: 100.00%\n",
      "epoch-52  lr=['0.0100000'], tr/val_loss:  0.420728/  5.208755, val:  77.92%, val_best:  80.00%, tr:  99.08%, tr_best: 100.00%\n",
      "epoch-53  lr=['0.0100000'], tr/val_loss:  0.395963/  5.772270, val:  71.67%, val_best:  80.00%, tr:  99.59%, tr_best: 100.00%\n",
      "epoch-54  lr=['0.0100000'], tr/val_loss:  0.381756/  5.340909, val:  75.42%, val_best:  80.00%, tr:  99.49%, tr_best: 100.00%\n",
      "epoch-55  lr=['0.0100000'], tr/val_loss:  0.528090/  5.462547, val:  75.42%, val_best:  80.00%, tr:  98.98%, tr_best: 100.00%\n",
      "epoch-56  lr=['0.0100000'], tr/val_loss:  0.444383/  5.826016, val:  77.08%, val_best:  80.00%, tr:  99.28%, tr_best: 100.00%\n",
      "epoch-57  lr=['0.0100000'], tr/val_loss:  0.521963/  5.691989, val:  75.83%, val_best:  80.00%, tr:  98.67%, tr_best: 100.00%\n",
      "epoch-58  lr=['0.0100000'], tr/val_loss:  0.664400/  5.781263, val:  71.67%, val_best:  80.00%, tr:  97.85%, tr_best: 100.00%\n",
      "epoch-59  lr=['0.0100000'], tr/val_loss:  0.387422/  5.648126, val:  77.08%, val_best:  80.00%, tr:  99.39%, tr_best: 100.00%\n",
      "epoch-60  lr=['0.0100000'], tr/val_loss:  0.399634/  6.730187, val:  69.58%, val_best:  80.00%, tr:  99.80%, tr_best: 100.00%\n",
      "epoch-61  lr=['0.0100000'], tr/val_loss:  0.567729/  6.763682, val:  73.33%, val_best:  80.00%, tr:  98.88%, tr_best: 100.00%\n",
      "epoch-62  lr=['0.0100000'], tr/val_loss:  0.534456/  6.240773, val:  74.58%, val_best:  80.00%, tr:  98.98%, tr_best: 100.00%\n",
      "epoch-63  lr=['0.0100000'], tr/val_loss:  0.376478/  5.911603, val:  77.08%, val_best:  80.00%, tr:  99.59%, tr_best: 100.00%\n",
      "epoch-64  lr=['0.0100000'], tr/val_loss:  0.322326/  6.019663, val:  76.67%, val_best:  80.00%, tr:  99.80%, tr_best: 100.00%\n",
      "epoch-65  lr=['0.0100000'], tr/val_loss:  0.328496/  6.129118, val:  75.83%, val_best:  80.00%, tr:  99.59%, tr_best: 100.00%\n",
      "epoch-66  lr=['0.0100000'], tr/val_loss:  0.345229/  6.567925, val:  76.67%, val_best:  80.00%, tr:  99.90%, tr_best: 100.00%\n",
      "epoch-67  lr=['0.0100000'], tr/val_loss:  0.388911/  6.521002, val:  77.50%, val_best:  80.00%, tr:  99.90%, tr_best: 100.00%\n",
      "epoch-68  lr=['0.0100000'], tr/val_loss:  0.371758/  6.478154, val:  77.92%, val_best:  80.00%, tr:  99.69%, tr_best: 100.00%\n",
      "epoch-69  lr=['0.0100000'], tr/val_loss:  0.434497/  6.715983, val:  76.67%, val_best:  80.00%, tr:  99.80%, tr_best: 100.00%\n",
      "epoch-70  lr=['0.0100000'], tr/val_loss:  0.434824/  6.414984, val:  75.00%, val_best:  80.00%, tr:  99.90%, tr_best: 100.00%\n",
      "epoch-71  lr=['0.0100000'], tr/val_loss:  0.404147/  7.181781, val:  71.25%, val_best:  80.00%, tr:  99.49%, tr_best: 100.00%\n",
      "epoch-72  lr=['0.0100000'], tr/val_loss:  0.431242/  7.298332, val:  74.17%, val_best:  80.00%, tr:  99.59%, tr_best: 100.00%\n",
      "epoch-73  lr=['0.0100000'], tr/val_loss:  0.530088/  6.739636, val:  78.75%, val_best:  80.00%, tr:  99.49%, tr_best: 100.00%\n",
      "epoch-74  lr=['0.0100000'], tr/val_loss:  0.474250/  6.966344, val:  75.83%, val_best:  80.00%, tr:  99.90%, tr_best: 100.00%\n",
      "epoch-75  lr=['0.0100000'], tr/val_loss:  0.476995/  6.943298, val:  79.17%, val_best:  80.00%, tr:  99.49%, tr_best: 100.00%\n",
      "epoch-76  lr=['0.0100000'], tr/val_loss:  0.527954/  6.514046, val:  77.50%, val_best:  80.00%, tr:  99.28%, tr_best: 100.00%\n",
      "epoch-77  lr=['0.0100000'], tr/val_loss:  0.599031/  6.550843, val:  74.17%, val_best:  80.00%, tr:  99.80%, tr_best: 100.00%\n",
      "epoch-78  lr=['0.0100000'], tr/val_loss:  0.818535/  7.546461, val:  73.33%, val_best:  80.00%, tr:  97.96%, tr_best: 100.00%\n",
      "epoch-79  lr=['0.0100000'], tr/val_loss:  0.805391/  7.413244, val:  74.17%, val_best:  80.00%, tr:  98.98%, tr_best: 100.00%\n",
      "epoch-80  lr=['0.0100000'], tr/val_loss:  0.687386/  6.506224, val:  75.83%, val_best:  80.00%, tr:  98.47%, tr_best: 100.00%\n",
      "epoch-81  lr=['0.0100000'], tr/val_loss:  0.610981/  7.050709, val:  75.00%, val_best:  80.00%, tr:  99.39%, tr_best: 100.00%\n",
      "epoch-82  lr=['0.0100000'], tr/val_loss:  0.551574/  7.398295, val:  71.25%, val_best:  80.00%, tr:  98.67%, tr_best: 100.00%\n",
      "epoch-83  lr=['0.0100000'], tr/val_loss:  0.635385/  6.985240, val:  80.42%, val_best:  80.42%, tr:  98.98%, tr_best: 100.00%\n",
      "epoch-84  lr=['0.0100000'], tr/val_loss:  0.529152/  7.644855, val:  76.67%, val_best:  80.42%, tr:  99.90%, tr_best: 100.00%\n",
      "epoch-85  lr=['0.0100000'], tr/val_loss:  0.541767/  7.122106, val:  77.92%, val_best:  80.42%, tr:  99.49%, tr_best: 100.00%\n",
      "epoch-86  lr=['0.0100000'], tr/val_loss:  0.774072/  6.844456, val:  74.58%, val_best:  80.42%, tr:  98.47%, tr_best: 100.00%\n",
      "epoch-87  lr=['0.0100000'], tr/val_loss:  0.578190/  6.896670, val:  77.50%, val_best:  80.42%, tr:  99.39%, tr_best: 100.00%\n",
      "epoch-88  lr=['0.0100000'], tr/val_loss:  0.530620/  7.310268, val:  78.75%, val_best:  80.42%, tr:  99.49%, tr_best: 100.00%\n",
      "epoch-89  lr=['0.0100000'], tr/val_loss:  0.545806/  7.003309, val:  75.00%, val_best:  80.42%, tr:  99.39%, tr_best: 100.00%\n",
      "epoch-90  lr=['0.0100000'], tr/val_loss:  0.496610/  6.542913, val:  79.17%, val_best:  80.42%, tr:  99.69%, tr_best: 100.00%\n",
      "epoch-91  lr=['0.0100000'], tr/val_loss:  0.637141/  8.149265, val:  68.75%, val_best:  80.42%, tr:  99.08%, tr_best: 100.00%\n",
      "epoch-92  lr=['0.0100000'], tr/val_loss:  0.586933/  7.625573, val:  75.83%, val_best:  80.42%, tr:  99.59%, tr_best: 100.00%\n",
      "epoch-93  lr=['0.0100000'], tr/val_loss:  0.616525/  7.695295, val:  73.75%, val_best:  80.42%, tr:  98.77%, tr_best: 100.00%\n",
      "epoch-94  lr=['0.0100000'], tr/val_loss:  0.558206/  7.036118, val:  79.58%, val_best:  80.42%, tr:  98.88%, tr_best: 100.00%\n",
      "epoch-95  lr=['0.0100000'], tr/val_loss:  0.834018/  8.565482, val:  73.75%, val_best:  80.42%, tr:  98.37%, tr_best: 100.00%\n",
      "epoch-96  lr=['0.0100000'], tr/val_loss:  0.711928/  7.962201, val:  74.17%, val_best:  80.42%, tr:  98.88%, tr_best: 100.00%\n",
      "epoch-97  lr=['0.0100000'], tr/val_loss:  0.844469/  8.327361, val:  73.75%, val_best:  80.42%, tr:  99.08%, tr_best: 100.00%\n",
      "epoch-98  lr=['0.0100000'], tr/val_loss:  0.820586/  7.793004, val:  75.42%, val_best:  80.42%, tr:  98.98%, tr_best: 100.00%\n",
      "epoch-99  lr=['0.0100000'], tr/val_loss:  0.834032/  8.481853, val:  69.17%, val_best:  80.42%, tr:  98.47%, tr_best: 100.00%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b8fbc4b73a6249118ede0c5f18defc0c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.006 MB of 0.006 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>iter_acc</td><td>▁▅▅▅▆▆▇▅▇████████▇██████████████████████</td></tr><tr><td>summary_val_acc</td><td>▁▃▄▄▄▇▅▇▆▆▇▇▆▇▇▇▇▇▇███▇▇▇▇▇▇▇▇█▇▇▆▇▇▇▇▇▇</td></tr><tr><td>tr_acc</td><td>▁▄▅▆▆▇▇█▇███████████████████████████████</td></tr><tr><td>tr_epoch_loss</td><td>█▅▄▃▃▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▂▁▂▂▂▁▂▂▂▂▂▃▂▂▂▂▂▃▃</td></tr><tr><td>val_acc_best</td><td>▁▃▄▄▄▇▇▇▇▇▇▇▇▇██████████████████████████</td></tr><tr><td>val_acc_now</td><td>▁▃▄▄▄▇▅▇▆▆▇▇▆▇▇▇▇▇▇███▇▇▇▇▇▇▇▇█▇▇▆▇▇▇▇▇▇</td></tr><tr><td>val_loss</td><td>▁▁▁▁▂▁▂▂▂▃▃▃▄▄▄▄▄▅▅▄▅▅▅▅▅▆▆▆▆▇▆▆▇▇▇▆▆▇██</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>99</td></tr><tr><td>iter_acc</td><td>1.0</td></tr><tr><td>tr_acc</td><td>0.98468</td></tr><tr><td>tr_epoch_loss</td><td>0.83403</td></tr><tr><td>val_acc_best</td><td>0.80417</td></tr><tr><td>val_acc_now</td><td>0.69167</td></tr><tr><td>val_loss</td><td>8.48185</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">cool-sweep-95</strong> at: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/ojymiwi8' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/ojymiwi8</a><br/> View project at: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>/data2/bh_wandb/wandb/run-20250430_012846-ojymiwi8/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require(\"core\")`! See https://wandb.me/wandb-core for more information."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: b43b73qr with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBATCH: 16\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBN_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBPTT_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tDFA_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tIMAGE_SIZE: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tOTTT_input_trace_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tTIME: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tUDA_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \talpha_uda: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbias: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcfg: ['M', 'M', 200, 200]\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tchaching_on: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tconvTrue_fcFalse: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdata_path: /data2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tddp_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdenoise_on: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdvs_clipping: 5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdvs_duration: 100000\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepoch_num: 100\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \texclude_class: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \textra_train_dataset: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlast_lif: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.01\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_sg_width: 5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_decay: 0.5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_init: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_reset: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_threshold: 0.75\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmerge_polarities: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmy_seed: 42\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnet_print: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_workers: 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer_what: SGD\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tpin_memory: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tpre_trained: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tpre_trained_path: net_save/save_now_net_weights_{unique_name}.pth\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \trate_coding: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tscheduler_name: no\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsingle_step: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsurrogate: hard_sigmoid\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_conv_kernel_size: 3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_conv_padding: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_conv_stride: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_trace_const1: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_trace_const2: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \ttdBN_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \ttrace_on: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \twhich_data: DVS_GESTURE_TONIC\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.19.10 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.17.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/data2/bh_wandb/wandb/run-20250430_013509-b43b73qr</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/b43b73qr' target=\"_blank\">dark-sweep-99</a></strong> to <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/6pj3lh8j' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/6pj3lh8j</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/6pj3lh8j' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/6pj3lh8j</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/b43b73qr' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/b43b73qr</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'single_step' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'my_seed' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'TIME' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BATCH' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'IMAGE_SIZE' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'which_data' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'data_path' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'rate_coding' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_init' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_decay' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_threshold' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_reset' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_sg_width' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_conv_kernel_size' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_conv_stride' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_conv_padding' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_trace_const1' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_trace_const2' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'pre_trained' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'convTrue_fcFalse' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'cfg' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'net_print' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'pre_trained_path' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'learning_rate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'epoch_num' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'tdBN_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BN_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'surrogate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BPTT_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'optimizer_what' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'scheduler_name' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'ddp_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'dvs_clipping' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'dvs_duration' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'DFA_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'trace_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'OTTT_input_trace_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'exclude_class' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'merge_polarities' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'denoise_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'extra_train_dataset' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'num_workers' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'chaching_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'pin_memory' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'UDA_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'alpha_uda' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'bias' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'last_lif' was locked by 'sweep' (ignored update).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "param {'devices': '0', 'single_step': True, 'unique_name': 'main', 'my_seed': 42, 'TIME': 10, 'BATCH': 16, 'IMAGE_SIZE': 128, 'which_data': 'DVS_GESTURE_TONIC', 'data_path': '/data2', 'rate_coding': False, 'lif_layer_v_init': 0, 'lif_layer_v_decay': 0.5, 'lif_layer_v_threshold': 0.75, 'lif_layer_v_reset': 0, 'lif_layer_sg_width': 5, 'synapse_conv_kernel_size': 3, 'synapse_conv_stride': 1, 'synapse_conv_padding': 1, 'synapse_trace_const1': 1, 'synapse_trace_const2': 0, 'pre_trained': False, 'convTrue_fcFalse': False, 'cfg': ['M', 'M', 200, 200], 'net_print': True, 'pre_trained_path': 'net_save/save_now_net_weights_{unique_name}.pth', 'learning_rate': 0.01, 'epoch_num': 100, 'tdBN_on': False, 'BN_on': False, 'surrogate': 'hard_sigmoid', 'BPTT_on': False, 'optimizer_what': 'SGD', 'scheduler_name': 'no', 'ddp_on': False, 'dvs_clipping': 5, 'dvs_duration': 100000, 'DFA_on': False, 'trace_on': True, 'OTTT_input_trace_on': False, 'exclude_class': True, 'merge_polarities': False, 'denoise_on': True, 'extra_train_dataset': 0, 'num_workers': 2, 'chaching_on': True, 'pin_memory': True, 'UDA_on': False, 'alpha_uda': 1, 'bias': True, 'last_lif': False, 'current epoch': 0} \n",
      "\n",
      "dataset_hash = 63cc597115630ec173f3099200061e53\n",
      "cache path exists\n",
      "\n",
      "device ==> cuda\n",
      "\n",
      "DataParallel(\n",
      "  (module): REBORN_MY_SNN_FC(\n",
      "    (layers): REBORN_MY_Sequential(\n",
      "      (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (2): DimChanger_for_FC()\n",
      "      (3): SYNAPSE_FC(in_features=2048, out_features=200, TIME=10, bias=True, sstep=True)\n",
      "      (4): LIF_layer(v_init=0, v_decay=0.5, v_threshold=0.75, v_reset=0, sg_width=5, surrogate=hard_sigmoid, BPTT_on=False, trace_const1=1, trace_const2=0, TIME=10, sstep=True, trace_on=True)\n",
      "      (5): SYNAPSE_FC(in_features=200, out_features=200, TIME=10, bias=True, sstep=True)\n",
      "      (6): LIF_layer(v_init=0, v_decay=0.5, v_threshold=0.75, v_reset=0, sg_width=5, surrogate=hard_sigmoid, BPTT_on=False, trace_const1=1, trace_const2=0, TIME=10, sstep=True, trace_on=True)\n",
      "      (7): SYNAPSE_FC(in_features=200, out_features=10, TIME=10, bias=True, sstep=True)\n",
      "    )\n",
      "  )\n",
      ")\n",
      "\n",
      "========================================================\n",
      "Trainable parameters: 452,010\n",
      "========================================================\n",
      "\n",
      "epoch-0   lr=['0.0100000'], tr/val_loss:  2.325702/  2.309367, val:  10.00%, val_best:  10.00%, tr:   8.89%, tr_best:   8.89%\n",
      "epoch-1   lr=['0.0100000'], tr/val_loss:  2.323408/  2.309339, val:  10.00%, val_best:  10.00%, tr:   9.40%, tr_best:   9.40%\n",
      "epoch-2   lr=['0.0100000'], tr/val_loss:  2.319913/  2.316170, val:  10.00%, val_best:  10.00%, tr:   8.89%, tr_best:   9.40%\n",
      "epoch-3   lr=['0.0100000'], tr/val_loss:  2.322621/  2.318868, val:  10.00%, val_best:  10.00%, tr:   9.09%, tr_best:   9.40%\n",
      "epoch-4   lr=['0.0100000'], tr/val_loss:  2.323630/  2.316624, val:  10.00%, val_best:  10.00%, tr:   8.68%, tr_best:   9.40%\n",
      "epoch-5   lr=['0.0100000'], tr/val_loss:  2.314643/  2.312522, val:  10.00%, val_best:  10.00%, tr:   9.50%, tr_best:   9.50%\n",
      "epoch-6   lr=['0.0100000'], tr/val_loss:  2.322383/  2.317189, val:  10.00%, val_best:  10.00%, tr:   9.91%, tr_best:   9.91%\n",
      "epoch-7   lr=['0.0100000'], tr/val_loss:  2.323500/  2.311199, val:  10.00%, val_best:  10.00%, tr:   9.09%, tr_best:   9.91%\n",
      "epoch-8   lr=['0.0100000'], tr/val_loss:  2.318820/  2.316814, val:  10.00%, val_best:  10.00%, tr:   9.60%, tr_best:   9.91%\n",
      "epoch-9   lr=['0.0100000'], tr/val_loss:  2.325358/  2.328855, val:  10.00%, val_best:  10.00%, tr:   9.81%, tr_best:   9.91%\n",
      "epoch-10  lr=['0.0100000'], tr/val_loss:  2.318062/  2.313319, val:  10.00%, val_best:  10.00%, tr:   8.78%, tr_best:   9.91%\n",
      "epoch-11  lr=['0.0100000'], tr/val_loss:  2.321499/  2.314362, val:  10.00%, val_best:  10.00%, tr:   9.91%, tr_best:   9.91%\n",
      "epoch-12  lr=['0.0100000'], tr/val_loss:  2.318739/  2.304731, val:  10.00%, val_best:  10.00%, tr:   9.09%, tr_best:   9.91%\n",
      "epoch-13  lr=['0.0100000'], tr/val_loss:  2.323381/  2.312831, val:  10.00%, val_best:  10.00%, tr:  10.52%, tr_best:  10.52%\n",
      "epoch-14  lr=['0.0100000'], tr/val_loss:  2.318632/  2.314031, val:  10.00%, val_best:  10.00%, tr:  11.24%, tr_best:  11.24%\n",
      "epoch-15  lr=['0.0100000'], tr/val_loss:  2.334141/  2.312476, val:  10.00%, val_best:  10.00%, tr:   8.78%, tr_best:  11.24%\n",
      "epoch-16  lr=['0.0100000'], tr/val_loss:  2.325246/  2.309235, val:  10.00%, val_best:  10.00%, tr:  10.73%, tr_best:  11.24%\n",
      "epoch-17  lr=['0.0100000'], tr/val_loss:  2.313498/  2.304715, val:  10.00%, val_best:  10.00%, tr:   7.97%, tr_best:  11.24%\n",
      "epoch-18  lr=['0.0100000'], tr/val_loss:  2.317416/  2.315703, val:  10.00%, val_best:  10.00%, tr:   8.27%, tr_best:  11.24%\n",
      "epoch-19  lr=['0.0100000'], tr/val_loss:  2.328925/  2.309338, val:  10.00%, val_best:  10.00%, tr:  10.21%, tr_best:  11.24%\n",
      "epoch-20  lr=['0.0100000'], tr/val_loss:  2.325712/  2.311423, val:  10.00%, val_best:  10.00%, tr:   8.78%, tr_best:  11.24%\n",
      "epoch-21  lr=['0.0100000'], tr/val_loss:  2.317473/  2.314049, val:  10.00%, val_best:  10.00%, tr:   8.99%, tr_best:  11.24%\n",
      "epoch-22  lr=['0.0100000'], tr/val_loss:  2.321084/  2.316247, val:  10.00%, val_best:  10.00%, tr:   8.78%, tr_best:  11.24%\n",
      "epoch-23  lr=['0.0100000'], tr/val_loss:  2.323519/  2.311760, val:  10.00%, val_best:  10.00%, tr:   7.97%, tr_best:  11.24%\n",
      "epoch-24  lr=['0.0100000'], tr/val_loss:  2.315132/  2.309812, val:  10.00%, val_best:  10.00%, tr:   9.40%, tr_best:  11.24%\n",
      "epoch-25  lr=['0.0100000'], tr/val_loss:  2.321132/  2.308563, val:  10.00%, val_best:  10.00%, tr:   7.56%, tr_best:  11.24%\n",
      "epoch-26  lr=['0.0100000'], tr/val_loss:  2.324926/  2.309820, val:  10.00%, val_best:  10.00%, tr:   9.09%, tr_best:  11.24%\n",
      "epoch-27  lr=['0.0100000'], tr/val_loss:  2.315943/  2.313346, val:  10.00%, val_best:  10.00%, tr:   8.27%, tr_best:  11.24%\n",
      "epoch-28  lr=['0.0100000'], tr/val_loss:  2.320931/  2.314629, val:  10.00%, val_best:  10.00%, tr:   8.07%, tr_best:  11.24%\n",
      "epoch-29  lr=['0.0100000'], tr/val_loss:  2.316856/  2.309039, val:  10.00%, val_best:  10.00%, tr:   8.58%, tr_best:  11.24%\n",
      "epoch-30  lr=['0.0100000'], tr/val_loss:  2.317568/  2.312462, val:  10.00%, val_best:  10.00%, tr:   8.89%, tr_best:  11.24%\n",
      "epoch-31  lr=['0.0100000'], tr/val_loss:  2.322536/  2.308460, val:  10.00%, val_best:  10.00%, tr:   8.99%, tr_best:  11.24%\n",
      "epoch-32  lr=['0.0100000'], tr/val_loss:  2.317184/  2.325424, val:  10.00%, val_best:  10.00%, tr:   9.91%, tr_best:  11.24%\n",
      "epoch-33  lr=['0.0100000'], tr/val_loss:  2.323347/  2.308666, val:  10.00%, val_best:  10.00%, tr:   8.68%, tr_best:  11.24%\n",
      "epoch-34  lr=['0.0100000'], tr/val_loss:  2.324209/  2.309332, val:  10.00%, val_best:  10.00%, tr:   8.27%, tr_best:  11.24%\n",
      "epoch-35  lr=['0.0100000'], tr/val_loss:  2.317179/  2.315681, val:  10.00%, val_best:  10.00%, tr:   9.30%, tr_best:  11.24%\n",
      "epoch-36  lr=['0.0100000'], tr/val_loss:  2.326358/  2.314513, val:  10.00%, val_best:  10.00%, tr:   8.68%, tr_best:  11.24%\n",
      "epoch-37  lr=['0.0100000'], tr/val_loss:  2.318460/  2.316844, val:  10.00%, val_best:  10.00%, tr:  10.11%, tr_best:  11.24%\n",
      "epoch-38  lr=['0.0100000'], tr/val_loss:  2.317593/  2.308844, val:  10.00%, val_best:  10.00%, tr:  10.21%, tr_best:  11.24%\n",
      "epoch-39  lr=['0.0100000'], tr/val_loss:  2.322765/  2.307623, val:  10.00%, val_best:  10.00%, tr:   8.48%, tr_best:  11.24%\n",
      "epoch-40  lr=['0.0100000'], tr/val_loss:  2.325134/  2.308829, val:  10.00%, val_best:  10.00%, tr:   8.99%, tr_best:  11.24%\n",
      "epoch-41  lr=['0.0100000'], tr/val_loss:  2.314856/  2.311282, val:  10.00%, val_best:  10.00%, tr:   8.99%, tr_best:  11.24%\n",
      "epoch-42  lr=['0.0100000'], tr/val_loss:  2.320183/  2.309368, val:  10.00%, val_best:  10.00%, tr:  10.52%, tr_best:  11.24%\n",
      "epoch-43  lr=['0.0100000'], tr/val_loss:  2.319872/  2.311711, val:  10.00%, val_best:  10.00%, tr:   9.70%, tr_best:  11.24%\n",
      "epoch-44  lr=['0.0100000'], tr/val_loss:  2.319850/  2.314886, val:  10.00%, val_best:  10.00%, tr:   7.97%, tr_best:  11.24%\n",
      "epoch-45  lr=['0.0100000'], tr/val_loss:  2.316781/  2.307194, val:  10.00%, val_best:  10.00%, tr:   8.68%, tr_best:  11.24%\n",
      "epoch-46  lr=['0.0100000'], tr/val_loss:  2.317213/  2.309639, val:  10.00%, val_best:  10.00%, tr:   8.58%, tr_best:  11.24%\n",
      "epoch-47  lr=['0.0100000'], tr/val_loss:  2.316024/  2.321777, val:  10.00%, val_best:  10.00%, tr:  10.11%, tr_best:  11.24%\n",
      "epoch-48  lr=['0.0100000'], tr/val_loss:  2.322300/  2.308692, val:  10.00%, val_best:  10.00%, tr:   7.76%, tr_best:  11.24%\n",
      "epoch-49  lr=['0.0100000'], tr/val_loss:  2.322022/  2.309639, val:  10.00%, val_best:  10.00%, tr:   9.50%, tr_best:  11.24%\n",
      "epoch-50  lr=['0.0100000'], tr/val_loss:  2.320133/  2.311189, val:  10.00%, val_best:  10.00%, tr:  10.01%, tr_best:  11.24%\n",
      "epoch-51  lr=['0.0100000'], tr/val_loss:  2.318374/  2.309343, val:  10.00%, val_best:  10.00%, tr:   9.40%, tr_best:  11.24%\n",
      "epoch-52  lr=['0.0100000'], tr/val_loss:  2.323557/  2.312201, val:  10.00%, val_best:  10.00%, tr:  10.21%, tr_best:  11.24%\n",
      "epoch-53  lr=['0.0100000'], tr/val_loss:  2.325249/  2.318944, val:  10.00%, val_best:  10.00%, tr:   9.40%, tr_best:  11.24%\n",
      "epoch-54  lr=['0.0100000'], tr/val_loss:  2.322435/  2.310744, val:  10.00%, val_best:  10.00%, tr:   9.19%, tr_best:  11.24%\n",
      "epoch-55  lr=['0.0100000'], tr/val_loss:  2.319107/  2.311890, val:  10.00%, val_best:  10.00%, tr:   9.40%, tr_best:  11.24%\n",
      "epoch-56  lr=['0.0100000'], tr/val_loss:  2.318825/  2.309790, val:  10.00%, val_best:  10.00%, tr:  10.21%, tr_best:  11.24%\n",
      "epoch-57  lr=['0.0100000'], tr/val_loss:  2.324973/  2.306278, val:  10.00%, val_best:  10.00%, tr:   7.76%, tr_best:  11.24%\n",
      "epoch-58  lr=['0.0100000'], tr/val_loss:  2.316925/  2.315704, val:  10.00%, val_best:  10.00%, tr:   9.09%, tr_best:  11.24%\n",
      "epoch-59  lr=['0.0100000'], tr/val_loss:  2.322272/  2.310759, val:  10.00%, val_best:  10.00%, tr:  10.32%, tr_best:  11.24%\n",
      "epoch-60  lr=['0.0100000'], tr/val_loss:  2.319633/  2.313704, val:  10.00%, val_best:  10.00%, tr:   9.09%, tr_best:  11.24%\n",
      "epoch-61  lr=['0.0100000'], tr/val_loss:  2.319135/  2.306101, val:  10.00%, val_best:  10.00%, tr:   7.66%, tr_best:  11.24%\n",
      "epoch-62  lr=['0.0100000'], tr/val_loss:  2.323344/  2.307318, val:  10.00%, val_best:  10.00%, tr:   7.87%, tr_best:  11.24%\n",
      "epoch-63  lr=['0.0100000'], tr/val_loss:  2.323301/  2.312440, val:  10.00%, val_best:  10.00%, tr:   7.15%, tr_best:  11.24%\n",
      "epoch-64  lr=['0.0100000'], tr/val_loss:  2.314006/  2.310386, val:  10.00%, val_best:  10.00%, tr:  10.21%, tr_best:  11.24%\n",
      "epoch-65  lr=['0.0100000'], tr/val_loss:  2.318532/  2.315302, val:  10.00%, val_best:  10.00%, tr:   8.78%, tr_best:  11.24%\n",
      "epoch-66  lr=['0.0100000'], tr/val_loss:  2.318847/  2.308046, val:  10.00%, val_best:  10.00%, tr:   8.99%, tr_best:  11.24%\n",
      "epoch-67  lr=['0.0100000'], tr/val_loss:  2.315717/  2.322596, val:  10.00%, val_best:  10.00%, tr:  10.32%, tr_best:  11.24%\n",
      "epoch-68  lr=['0.0100000'], tr/val_loss:  2.325798/  2.310406, val:  10.00%, val_best:  10.00%, tr:   8.27%, tr_best:  11.24%\n",
      "epoch-69  lr=['0.0100000'], tr/val_loss:  2.317781/  2.314536, val:  10.00%, val_best:  10.00%, tr:   8.58%, tr_best:  11.24%\n",
      "epoch-70  lr=['0.0100000'], tr/val_loss:  2.320998/  2.312184, val:  10.00%, val_best:  10.00%, tr:  10.21%, tr_best:  11.24%\n",
      "epoch-71  lr=['0.0100000'], tr/val_loss:  2.323415/  2.319147, val:  10.00%, val_best:  10.00%, tr:   9.19%, tr_best:  11.24%\n",
      "epoch-72  lr=['0.0100000'], tr/val_loss:  2.323264/  2.311337, val:  10.00%, val_best:  10.00%, tr:   7.76%, tr_best:  11.24%\n",
      "epoch-73  lr=['0.0100000'], tr/val_loss:  2.322191/  2.311279, val:  10.00%, val_best:  10.00%, tr:   9.30%, tr_best:  11.24%\n",
      "epoch-74  lr=['0.0100000'], tr/val_loss:  2.321045/  2.317480, val:  10.00%, val_best:  10.00%, tr:  10.42%, tr_best:  11.24%\n",
      "epoch-75  lr=['0.0100000'], tr/val_loss:  2.327291/  2.311272, val:  10.00%, val_best:  10.00%, tr:   8.68%, tr_best:  11.24%\n",
      "epoch-76  lr=['0.0100000'], tr/val_loss:  2.319391/  2.315876, val:  10.00%, val_best:  10.00%, tr:   9.81%, tr_best:  11.24%\n",
      "epoch-77  lr=['0.0100000'], tr/val_loss:  2.319038/  2.321109, val:  10.00%, val_best:  10.00%, tr:   8.58%, tr_best:  11.24%\n",
      "epoch-78  lr=['0.0100000'], tr/val_loss:  2.318532/  2.311095, val:  10.00%, val_best:  10.00%, tr:  10.32%, tr_best:  11.24%\n",
      "epoch-79  lr=['0.0100000'], tr/val_loss:  2.320800/  2.310123, val:  10.00%, val_best:  10.00%, tr:   9.30%, tr_best:  11.24%\n",
      "epoch-80  lr=['0.0100000'], tr/val_loss:  2.322366/  2.309981, val:  10.00%, val_best:  10.00%, tr:   8.07%, tr_best:  11.24%\n",
      "epoch-81  lr=['0.0100000'], tr/val_loss:  2.318656/  2.305710, val:  10.00%, val_best:  10.00%, tr:   9.30%, tr_best:  11.24%\n",
      "epoch-82  lr=['0.0100000'], tr/val_loss:  2.321045/  2.309697, val:  10.00%, val_best:  10.00%, tr:   8.78%, tr_best:  11.24%\n",
      "epoch-83  lr=['0.0100000'], tr/val_loss:  2.324742/  2.315970, val:  10.00%, val_best:  10.00%, tr:   9.50%, tr_best:  11.24%\n",
      "epoch-84  lr=['0.0100000'], tr/val_loss:  2.317994/  2.312845, val:  10.00%, val_best:  10.00%, tr:   9.91%, tr_best:  11.24%\n",
      "epoch-85  lr=['0.0100000'], tr/val_loss:  2.316085/  2.316632, val:  10.00%, val_best:  10.00%, tr:   8.89%, tr_best:  11.24%\n",
      "epoch-86  lr=['0.0100000'], tr/val_loss:  2.322831/  2.324681, val:  10.00%, val_best:  10.00%, tr:   8.99%, tr_best:  11.24%\n",
      "epoch-87  lr=['0.0100000'], tr/val_loss:  2.318426/  2.310144, val:  10.00%, val_best:  10.00%, tr:   8.78%, tr_best:  11.24%\n",
      "epoch-88  lr=['0.0100000'], tr/val_loss:  2.319360/  2.316563, val:  10.00%, val_best:  10.00%, tr:  10.42%, tr_best:  11.24%\n",
      "epoch-89  lr=['0.0100000'], tr/val_loss:  2.322934/  2.320799, val:  10.00%, val_best:  10.00%, tr:   9.40%, tr_best:  11.24%\n",
      "epoch-90  lr=['0.0100000'], tr/val_loss:  2.320748/  2.312796, val:  10.00%, val_best:  10.00%, tr:   8.89%, tr_best:  11.24%\n",
      "epoch-91  lr=['0.0100000'], tr/val_loss:  2.318540/  2.310683, val:  10.00%, val_best:  10.00%, tr:   9.60%, tr_best:  11.24%\n",
      "epoch-92  lr=['0.0100000'], tr/val_loss:  2.314051/  2.315422, val:  10.00%, val_best:  10.00%, tr:  10.73%, tr_best:  11.24%\n",
      "epoch-93  lr=['0.0100000'], tr/val_loss:  2.321696/  2.314612, val:  10.00%, val_best:  10.00%, tr:  10.11%, tr_best:  11.24%\n",
      "epoch-94  lr=['0.0100000'], tr/val_loss:  2.323909/  2.306177, val:  10.00%, val_best:  10.00%, tr:   7.15%, tr_best:  11.24%\n",
      "epoch-95  lr=['0.0100000'], tr/val_loss:  2.321943/  2.307636, val:  10.00%, val_best:  10.00%, tr:   8.07%, tr_best:  11.24%\n",
      "epoch-96  lr=['0.0100000'], tr/val_loss:  2.317030/  2.319769, val:  10.00%, val_best:  10.00%, tr:   9.09%, tr_best:  11.24%\n",
      "epoch-97  lr=['0.0100000'], tr/val_loss:  2.320492/  2.315406, val:  10.00%, val_best:  10.00%, tr:   9.91%, tr_best:  11.24%\n",
      "epoch-98  lr=['0.0100000'], tr/val_loss:  2.323087/  2.321030, val:  10.00%, val_best:  10.00%, tr:   9.70%, tr_best:  11.24%\n",
      "epoch-99  lr=['0.0100000'], tr/val_loss:  2.324332/  2.313588, val:  10.00%, val_best:  10.00%, tr:   8.17%, tr_best:  11.24%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "260cef66134e415fab2f51e74812ade9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.006 MB of 0.006 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>iter_acc</td><td>█▂▂▄▂▂▂▂▂▂▁▄▅▄▂▄▄▁▅▄▁▂▄▁▂▅▁▂▂▁▂▄▂▂▄▄▂▂█▄</td></tr><tr><td>summary_val_acc</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>tr_acc</td><td>▃▃▃▄▅▄█▂▆▄▄▄▃▅▄▆▃▇▂▆▅▆▄▁▆▁▃▆▆▁▃▃▄▃▅▃▄▇▂▅</td></tr><tr><td>tr_epoch_loss</td><td>▇▄▆▆▆▃▃▁█▃▂▆▃▃▃▃▅▄▄▂▅▆▅▆▅▄▃▂▄▅▇▄▄▄▃▃▅▁▅▄</td></tr><tr><td>val_acc_best</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_acc_now</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_loss</td><td>▂▄▄▃█▁▄▁▂▄▂▂▂▇▄▅▂▂▄▆▂▃▃▁▃▁▄▆▃▃▃▆▃▂▃▃▆▄▂▄</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>99</td></tr><tr><td>iter_acc</td><td>0.0</td></tr><tr><td>tr_acc</td><td>0.08172</td></tr><tr><td>tr_epoch_loss</td><td>2.32433</td></tr><tr><td>val_acc_best</td><td>0.1</td></tr><tr><td>val_acc_now</td><td>0.1</td></tr><tr><td>val_loss</td><td>2.31359</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">dark-sweep-99</strong> at: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/b43b73qr' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/b43b73qr</a><br/> View project at: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>/data2/bh_wandb/wandb/run-20250430_013509-b43b73qr/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require(\"core\")`! See https://wandb.me/wandb-core for more information."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 0f1p9gvm with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBATCH: 16\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBN_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBPTT_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tDFA_on: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tIMAGE_SIZE: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tOTTT_input_trace_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tTIME: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tUDA_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \talpha_uda: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbias: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcfg: ['M', 'M', 200, 200]\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tchaching_on: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tconvTrue_fcFalse: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdata_path: /data2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tddp_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdenoise_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdvs_clipping: 5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdvs_duration: 100000\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepoch_num: 100\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \texclude_class: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \textra_train_dataset: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlast_lif: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.01\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_sg_width: 3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_decay: 0.5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_init: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_reset: 10000\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_threshold: 0.5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmerge_polarities: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmy_seed: 42\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnet_print: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_workers: 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer_what: SGD\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tpin_memory: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tpre_trained: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tpre_trained_path: net_save/save_now_net_weights_{unique_name}.pth\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \trate_coding: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tscheduler_name: no\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsingle_step: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsurrogate: hard_sigmoid\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_conv_kernel_size: 3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_conv_padding: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_conv_stride: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_trace_const1: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_trace_const2: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \ttdBN_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \ttrace_on: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \twhich_data: DVS_GESTURE_TONIC\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.19.10 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.17.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/data2/bh_wandb/wandb/run-20250430_014127-0f1p9gvm</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/0f1p9gvm' target=\"_blank\">amber-sweep-103</a></strong> to <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/6pj3lh8j' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/6pj3lh8j</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/6pj3lh8j' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/6pj3lh8j</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/0f1p9gvm' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/0f1p9gvm</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'single_step' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'my_seed' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'TIME' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BATCH' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'IMAGE_SIZE' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'which_data' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'data_path' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'rate_coding' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_init' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_decay' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_threshold' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_reset' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_sg_width' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_conv_kernel_size' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_conv_stride' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_conv_padding' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_trace_const1' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_trace_const2' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'pre_trained' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'convTrue_fcFalse' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'cfg' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'net_print' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'pre_trained_path' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'learning_rate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'epoch_num' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'tdBN_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BN_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'surrogate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BPTT_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'optimizer_what' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'scheduler_name' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'ddp_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'dvs_clipping' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'dvs_duration' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'DFA_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'trace_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'OTTT_input_trace_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'exclude_class' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'merge_polarities' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'denoise_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'extra_train_dataset' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'num_workers' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'chaching_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'pin_memory' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'UDA_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'alpha_uda' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'bias' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'last_lif' was locked by 'sweep' (ignored update).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "param {'devices': '0', 'single_step': True, 'unique_name': 'main', 'my_seed': 42, 'TIME': 10, 'BATCH': 16, 'IMAGE_SIZE': 128, 'which_data': 'DVS_GESTURE_TONIC', 'data_path': '/data2', 'rate_coding': False, 'lif_layer_v_init': 0, 'lif_layer_v_decay': 0.5, 'lif_layer_v_threshold': 0.5, 'lif_layer_v_reset': 10000, 'lif_layer_sg_width': 3, 'synapse_conv_kernel_size': 3, 'synapse_conv_stride': 1, 'synapse_conv_padding': 1, 'synapse_trace_const1': 1, 'synapse_trace_const2': 0, 'pre_trained': False, 'convTrue_fcFalse': False, 'cfg': ['M', 'M', 200, 200], 'net_print': True, 'pre_trained_path': 'net_save/save_now_net_weights_{unique_name}.pth', 'learning_rate': 0.01, 'epoch_num': 100, 'tdBN_on': False, 'BN_on': False, 'surrogate': 'hard_sigmoid', 'BPTT_on': False, 'optimizer_what': 'SGD', 'scheduler_name': 'no', 'ddp_on': False, 'dvs_clipping': 5, 'dvs_duration': 100000, 'DFA_on': True, 'trace_on': True, 'OTTT_input_trace_on': False, 'exclude_class': True, 'merge_polarities': False, 'denoise_on': False, 'extra_train_dataset': 0, 'num_workers': 2, 'chaching_on': True, 'pin_memory': True, 'UDA_on': False, 'alpha_uda': 1, 'bias': True, 'last_lif': False, 'current epoch': 0} \n",
      "\n",
      "dataset_hash = ffa516e60c3efd5e0208f72b4c36cb84\n",
      "cache path exists\n",
      "\n",
      "device ==> cuda\n",
      "\n",
      "DataParallel(\n",
      "  (module): REBORN_MY_SNN_FC(\n",
      "    (layers): REBORN_MY_Sequential(\n",
      "      (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (2): DimChanger_for_FC()\n",
      "      (3): SYNAPSE_FC(in_features=2048, out_features=200, TIME=10, bias=True, sstep=True)\n",
      "      (4): LIF_layer(v_init=0, v_decay=0.5, v_threshold=0.5, v_reset=10000, sg_width=3, surrogate=hard_sigmoid, BPTT_on=False, trace_const1=1, trace_const2=0, TIME=10, sstep=True, trace_on=True)\n",
      "      (5): Feedback_Receiver()\n",
      "      (6): SYNAPSE_FC(in_features=200, out_features=200, TIME=10, bias=True, sstep=True)\n",
      "      (7): LIF_layer(v_init=0, v_decay=0.5, v_threshold=0.5, v_reset=10000, sg_width=3, surrogate=hard_sigmoid, BPTT_on=False, trace_const1=1, trace_const2=0, TIME=10, sstep=True, trace_on=True)\n",
      "      (8): Feedback_Receiver()\n",
      "      (9): SYNAPSE_FC(in_features=200, out_features=10, TIME=10, bias=True, sstep=True)\n",
      "      (DFA_top): Top_Gradient()\n",
      "    )\n",
      "  )\n",
      ")\n",
      "\n",
      "========================================================\n",
      "Trainable parameters: 452,010\n",
      "========================================================\n",
      "\n",
      "epoch-0   lr=['0.0100000'], tr/val_loss:  2.212517/  3.442651, val:  32.92%, val_best:  32.92%, tr:  33.50%, tr_best:  33.50%\n",
      "[module.layers.5] weight_fb parameter count: 2,000\n",
      "[module.layers.8] weight_fb parameter count: 2,000\n",
      "epoch-1   lr=['0.0100000'], tr/val_loss:  2.417575/  2.823373, val:  44.58%, val_best:  44.58%, tr:  47.80%, tr_best:  47.80%\n",
      "epoch-2   lr=['0.0100000'], tr/val_loss:  2.423273/  2.694598, val:  49.17%, val_best:  49.17%, tr:  54.14%, tr_best:  54.14%\n",
      "epoch-3   lr=['0.0100000'], tr/val_loss:  2.065602/  2.410695, val:  48.75%, val_best:  49.17%, tr:  58.84%, tr_best:  58.84%\n",
      "epoch-4   lr=['0.0100000'], tr/val_loss:  1.708500/  2.535792, val:  57.08%, val_best:  57.08%, tr:  63.53%, tr_best:  63.53%\n",
      "epoch-5   lr=['0.0100000'], tr/val_loss:  1.829138/  2.796714, val:  50.83%, val_best:  57.08%, tr:  64.76%, tr_best:  64.76%\n",
      "epoch-6   lr=['0.0100000'], tr/val_loss:  1.048142/  2.108891, val:  66.67%, val_best:  66.67%, tr:  77.22%, tr_best:  77.22%\n",
      "epoch-7   lr=['0.0100000'], tr/val_loss:  0.861757/  2.706281, val:  48.75%, val_best:  66.67%, tr:  82.94%, tr_best:  82.94%\n",
      "epoch-8   lr=['0.0100000'], tr/val_loss:  0.806389/  2.318466, val:  56.25%, val_best:  66.67%, tr:  84.78%, tr_best:  84.78%\n",
      "epoch-9   lr=['0.0100000'], tr/val_loss:  1.014609/  2.692507, val:  65.42%, val_best:  66.67%, tr:  84.47%, tr_best:  84.78%\n",
      "epoch-10  lr=['0.0100000'], tr/val_loss:  0.643528/  2.359138, val:  61.67%, val_best:  66.67%, tr:  91.52%, tr_best:  91.52%\n",
      "epoch-11  lr=['0.0100000'], tr/val_loss:  0.530232/  2.486243, val:  66.25%, val_best:  66.67%, tr:  93.77%, tr_best:  93.77%\n",
      "epoch-12  lr=['0.0100000'], tr/val_loss:  0.438304/  2.105812, val:  74.58%, val_best:  74.58%, tr:  95.91%, tr_best:  95.91%\n",
      "epoch-13  lr=['0.0100000'], tr/val_loss:  0.301887/  2.175591, val:  75.00%, val_best:  75.00%, tr:  97.96%, tr_best:  97.96%\n",
      "epoch-14  lr=['0.0100000'], tr/val_loss:  0.233666/  2.331037, val:  70.83%, val_best:  75.00%, tr:  99.08%, tr_best:  99.08%\n",
      "epoch-15  lr=['0.0100000'], tr/val_loss:  0.166850/  2.320513, val:  71.25%, val_best:  75.00%, tr:  99.18%, tr_best:  99.18%\n",
      "epoch-16  lr=['0.0100000'], tr/val_loss:  0.167203/  2.723333, val:  69.58%, val_best:  75.00%, tr:  99.08%, tr_best:  99.18%\n",
      "epoch-17  lr=['0.0100000'], tr/val_loss:  0.178072/  2.291267, val:  77.50%, val_best:  77.50%, tr:  98.88%, tr_best:  99.18%\n",
      "epoch-18  lr=['0.0100000'], tr/val_loss:  0.131346/  2.321377, val:  80.00%, val_best:  80.00%, tr:  99.49%, tr_best:  99.49%\n",
      "epoch-19  lr=['0.0100000'], tr/val_loss:  0.086724/  2.383587, val:  76.25%, val_best:  80.00%, tr:  99.69%, tr_best:  99.69%\n",
      "epoch-20  lr=['0.0100000'], tr/val_loss:  0.051204/  2.432794, val:  78.33%, val_best:  80.00%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-21  lr=['0.0100000'], tr/val_loss:  0.037810/  2.466272, val:  80.83%, val_best:  80.83%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-22  lr=['0.0100000'], tr/val_loss:  0.031024/  2.522445, val:  77.92%, val_best:  80.83%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-23  lr=['0.0100000'], tr/val_loss:  0.031448/  2.558514, val:  76.25%, val_best:  80.83%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-24  lr=['0.0100000'], tr/val_loss:  0.023237/  2.587413, val:  79.17%, val_best:  80.83%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-25  lr=['0.0100000'], tr/val_loss:  0.019419/  2.617845, val:  78.33%, val_best:  80.83%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-26  lr=['0.0100000'], tr/val_loss:  0.015912/  2.665649, val:  77.50%, val_best:  80.83%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-27  lr=['0.0100000'], tr/val_loss:  0.013581/  2.731645, val:  77.50%, val_best:  80.83%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-28  lr=['0.0100000'], tr/val_loss:  0.010726/  2.712156, val:  77.50%, val_best:  80.83%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-29  lr=['0.0100000'], tr/val_loss:  0.010324/  2.733888, val:  77.50%, val_best:  80.83%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-30  lr=['0.0100000'], tr/val_loss:  0.008792/  2.769008, val:  77.92%, val_best:  80.83%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-31  lr=['0.0100000'], tr/val_loss:  0.007517/  2.776324, val:  77.92%, val_best:  80.83%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-32  lr=['0.0100000'], tr/val_loss:  0.006522/  2.809243, val:  77.92%, val_best:  80.83%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-33  lr=['0.0100000'], tr/val_loss:  0.006266/  2.849944, val:  78.33%, val_best:  80.83%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-34  lr=['0.0100000'], tr/val_loss:  0.005794/  2.860604, val:  78.33%, val_best:  80.83%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-35  lr=['0.0100000'], tr/val_loss:  0.005730/  2.856730, val:  77.08%, val_best:  80.83%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-36  lr=['0.0100000'], tr/val_loss:  0.005027/  2.866205, val:  77.50%, val_best:  80.83%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-37  lr=['0.0100000'], tr/val_loss:  0.005169/  2.866027, val:  77.92%, val_best:  80.83%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-38  lr=['0.0100000'], tr/val_loss:  0.005859/  2.898084, val:  77.08%, val_best:  80.83%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-39  lr=['0.0100000'], tr/val_loss:  0.004406/  2.880821, val:  78.33%, val_best:  80.83%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-40  lr=['0.0100000'], tr/val_loss:  0.003911/  2.891849, val:  80.00%, val_best:  80.83%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-41  lr=['0.0100000'], tr/val_loss:  0.003509/  2.929490, val:  79.58%, val_best:  80.83%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-42  lr=['0.0100000'], tr/val_loss:  0.004684/  2.958037, val:  77.50%, val_best:  80.83%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-43  lr=['0.0100000'], tr/val_loss:  0.004319/  2.953186, val:  77.92%, val_best:  80.83%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-44  lr=['0.0100000'], tr/val_loss:  0.003866/  2.938460, val:  78.33%, val_best:  80.83%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-45  lr=['0.0100000'], tr/val_loss:  0.003509/  2.963450, val:  77.50%, val_best:  80.83%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-46  lr=['0.0100000'], tr/val_loss:  0.002893/  2.984104, val:  78.75%, val_best:  80.83%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-47  lr=['0.0100000'], tr/val_loss:  0.002713/  2.985497, val:  78.33%, val_best:  80.83%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-48  lr=['0.0100000'], tr/val_loss:  0.002475/  2.989914, val:  78.75%, val_best:  80.83%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-49  lr=['0.0100000'], tr/val_loss:  0.002295/  2.974999, val:  79.17%, val_best:  80.83%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-50  lr=['0.0100000'], tr/val_loss:  0.002710/  2.992969, val:  79.58%, val_best:  80.83%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-51  lr=['0.0100000'], tr/val_loss:  0.002487/  3.026740, val:  78.75%, val_best:  80.83%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-52  lr=['0.0100000'], tr/val_loss:  0.002229/  3.030620, val:  78.75%, val_best:  80.83%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-53  lr=['0.0100000'], tr/val_loss:  0.002215/  3.025777, val:  77.50%, val_best:  80.83%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-54  lr=['0.0100000'], tr/val_loss:  0.002279/  3.030626, val:  78.33%, val_best:  80.83%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-55  lr=['0.0100000'], tr/val_loss:  0.002045/  3.025046, val:  78.33%, val_best:  80.83%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-56  lr=['0.0100000'], tr/val_loss:  0.002039/  3.038850, val:  78.33%, val_best:  80.83%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-57  lr=['0.0100000'], tr/val_loss:  0.002168/  3.041540, val:  77.50%, val_best:  80.83%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-58  lr=['0.0100000'], tr/val_loss:  0.001922/  3.092152, val:  77.92%, val_best:  80.83%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-59  lr=['0.0100000'], tr/val_loss:  0.001714/  3.081734, val:  78.33%, val_best:  80.83%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-60  lr=['0.0100000'], tr/val_loss:  0.001664/  3.080120, val:  77.92%, val_best:  80.83%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-61  lr=['0.0100000'], tr/val_loss:  0.001844/  3.086825, val:  77.08%, val_best:  80.83%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-62  lr=['0.0100000'], tr/val_loss:  0.001761/  3.078923, val:  77.92%, val_best:  80.83%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-63  lr=['0.0100000'], tr/val_loss:  0.001660/  3.080009, val:  78.75%, val_best:  80.83%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-64  lr=['0.0100000'], tr/val_loss:  0.001495/  3.100622, val:  77.92%, val_best:  80.83%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-65  lr=['0.0100000'], tr/val_loss:  0.001455/  3.121654, val:  77.92%, val_best:  80.83%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-66  lr=['0.0100000'], tr/val_loss:  0.001426/  3.133242, val:  78.33%, val_best:  80.83%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-67  lr=['0.0100000'], tr/val_loss:  0.001505/  3.130351, val:  77.92%, val_best:  80.83%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-68  lr=['0.0100000'], tr/val_loss:  0.001468/  3.124062, val:  77.92%, val_best:  80.83%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-69  lr=['0.0100000'], tr/val_loss:  0.001387/  3.140421, val:  79.17%, val_best:  80.83%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-70  lr=['0.0100000'], tr/val_loss:  0.001467/  3.141939, val:  78.75%, val_best:  80.83%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-71  lr=['0.0100000'], tr/val_loss:  0.001327/  3.152230, val:  77.50%, val_best:  80.83%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-72  lr=['0.0100000'], tr/val_loss:  0.001296/  3.135962, val:  78.75%, val_best:  80.83%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-73  lr=['0.0100000'], tr/val_loss:  0.001249/  3.147618, val:  77.50%, val_best:  80.83%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-74  lr=['0.0100000'], tr/val_loss:  0.001446/  3.168566, val:  77.92%, val_best:  80.83%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-75  lr=['0.0100000'], tr/val_loss:  0.001444/  3.162172, val:  77.92%, val_best:  80.83%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-76  lr=['0.0100000'], tr/val_loss:  0.001388/  3.168259, val:  77.92%, val_best:  80.83%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-77  lr=['0.0100000'], tr/val_loss:  0.001378/  3.178508, val:  78.33%, val_best:  80.83%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-78  lr=['0.0100000'], tr/val_loss:  0.001635/  3.152913, val:  77.50%, val_best:  80.83%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-79  lr=['0.0100000'], tr/val_loss:  0.001467/  3.161248, val:  78.33%, val_best:  80.83%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-80  lr=['0.0100000'], tr/val_loss:  0.001266/  3.168734, val:  78.33%, val_best:  80.83%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-81  lr=['0.0100000'], tr/val_loss:  0.001111/  3.181070, val:  77.92%, val_best:  80.83%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-82  lr=['0.0100000'], tr/val_loss:  0.001176/  3.182685, val:  77.92%, val_best:  80.83%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-83  lr=['0.0100000'], tr/val_loss:  0.001098/  3.184164, val:  79.17%, val_best:  80.83%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-84  lr=['0.0100000'], tr/val_loss:  0.001161/  3.205371, val:  79.17%, val_best:  80.83%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-85  lr=['0.0100000'], tr/val_loss:  0.001206/  3.200452, val:  78.75%, val_best:  80.83%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-86  lr=['0.0100000'], tr/val_loss:  0.001107/  3.204673, val:  79.17%, val_best:  80.83%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-87  lr=['0.0100000'], tr/val_loss:  0.001020/  3.213379, val:  79.17%, val_best:  80.83%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-88  lr=['0.0100000'], tr/val_loss:  0.001029/  3.221446, val:  79.17%, val_best:  80.83%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-89  lr=['0.0100000'], tr/val_loss:  0.000975/  3.220671, val:  78.75%, val_best:  80.83%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-90  lr=['0.0100000'], tr/val_loss:  0.000955/  3.230337, val:  78.33%, val_best:  80.83%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-91  lr=['0.0100000'], tr/val_loss:  0.000979/  3.234960, val:  79.17%, val_best:  80.83%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-92  lr=['0.0100000'], tr/val_loss:  0.000989/  3.247226, val:  79.58%, val_best:  80.83%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-93  lr=['0.0100000'], tr/val_loss:  0.001209/  3.243289, val:  78.33%, val_best:  80.83%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-94  lr=['0.0100000'], tr/val_loss:  0.001118/  3.258136, val:  78.75%, val_best:  80.83%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-95  lr=['0.0100000'], tr/val_loss:  0.000944/  3.254681, val:  77.92%, val_best:  80.83%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-96  lr=['0.0100000'], tr/val_loss:  0.000944/  3.249970, val:  79.17%, val_best:  80.83%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-97  lr=['0.0100000'], tr/val_loss:  0.000912/  3.263617, val:  78.33%, val_best:  80.83%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-98  lr=['0.0100000'], tr/val_loss:  0.000931/  3.245214, val:  79.58%, val_best:  80.83%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-99  lr=['0.0100000'], tr/val_loss:  0.000896/  3.270121, val:  78.33%, val_best:  80.83%, tr: 100.00%, tr_best: 100.00%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ff1eacc67e4146668ccc08f9d0f8feba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.006 MB of 0.006 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>iter_acc</td><td>▁▄▄▇▇███████████████████████████████████</td></tr><tr><td>summary_val_acc</td><td>▁▃▅▃▆▇▇█▇█████▇██████████▇██████████████</td></tr><tr><td>tr_acc</td><td>▁▃▄▆▆███████████████████████████████████</td></tr><tr><td>tr_epoch_loss</td><td>▇█▆▃▄▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_acc_best</td><td>▁▃▅▆▆▇▇█████████████████████████████████</td></tr><tr><td>val_acc_now</td><td>▁▃▅▃▆▇▇█▇█████▇██████████▇██████████████</td></tr><tr><td>val_loss</td><td>█▄▃▄▄▁▂▂▂▃▄▄▄▅▅▅▅▅▅▆▆▆▆▆▆▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>99</td></tr><tr><td>iter_acc</td><td>1.0</td></tr><tr><td>tr_acc</td><td>1.0</td></tr><tr><td>tr_epoch_loss</td><td>0.0009</td></tr><tr><td>val_acc_best</td><td>0.80833</td></tr><tr><td>val_acc_now</td><td>0.78333</td></tr><tr><td>val_loss</td><td>3.27012</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">amber-sweep-103</strong> at: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/0f1p9gvm' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/0f1p9gvm</a><br/> View project at: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>/data2/bh_wandb/wandb/run-20250430_014127-0f1p9gvm/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require(\"core\")`! See https://wandb.me/wandb-core for more information."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Sweep Agent: Waiting for job.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Job received.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: bqb51gyv with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBATCH: 16\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBN_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBPTT_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tDFA_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tIMAGE_SIZE: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tOTTT_input_trace_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tTIME: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tUDA_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \talpha_uda: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbias: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcfg: ['M', 'M', 200, 200]\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tchaching_on: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tconvTrue_fcFalse: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdata_path: /data2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tddp_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdenoise_on: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdvs_clipping: 5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdvs_duration: 100000\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepoch_num: 100\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \texclude_class: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \textra_train_dataset: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlast_lif: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.001\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_sg_width: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_decay: 0.5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_init: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_reset: 10000\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_threshold: 0.25\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmerge_polarities: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmy_seed: 42\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnet_print: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_workers: 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer_what: SGD\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tpin_memory: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tpre_trained: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tpre_trained_path: net_save/save_now_net_weights_{unique_name}.pth\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \trate_coding: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tscheduler_name: no\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsingle_step: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsurrogate: hard_sigmoid\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_conv_kernel_size: 3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_conv_padding: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_conv_stride: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_trace_const1: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_trace_const2: 0.5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \ttdBN_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \ttrace_on: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \twhich_data: DVS_GESTURE_TONIC\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.19.10 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.17.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/data2/bh_wandb/wandb/run-20250430_014843-bqb51gyv</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/bqb51gyv' target=\"_blank\">fearless-sweep-107</a></strong> to <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/6pj3lh8j' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/6pj3lh8j</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/6pj3lh8j' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/6pj3lh8j</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/bqb51gyv' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/bqb51gyv</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'single_step' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'my_seed' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'TIME' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BATCH' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'IMAGE_SIZE' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'which_data' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'data_path' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'rate_coding' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_init' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_decay' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_threshold' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_reset' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_sg_width' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_conv_kernel_size' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_conv_stride' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_conv_padding' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_trace_const1' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_trace_const2' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'pre_trained' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'convTrue_fcFalse' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'cfg' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'net_print' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'pre_trained_path' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'learning_rate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'epoch_num' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'tdBN_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BN_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'surrogate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BPTT_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'optimizer_what' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'scheduler_name' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'ddp_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'dvs_clipping' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'dvs_duration' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'DFA_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'trace_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'OTTT_input_trace_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'exclude_class' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'merge_polarities' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'denoise_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'extra_train_dataset' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'num_workers' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'chaching_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'pin_memory' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'UDA_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'alpha_uda' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'bias' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'last_lif' was locked by 'sweep' (ignored update).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "param {'devices': '0', 'single_step': True, 'unique_name': 'main', 'my_seed': 42, 'TIME': 10, 'BATCH': 16, 'IMAGE_SIZE': 128, 'which_data': 'DVS_GESTURE_TONIC', 'data_path': '/data2', 'rate_coding': False, 'lif_layer_v_init': 0, 'lif_layer_v_decay': 0.5, 'lif_layer_v_threshold': 0.25, 'lif_layer_v_reset': 10000, 'lif_layer_sg_width': 1, 'synapse_conv_kernel_size': 3, 'synapse_conv_stride': 1, 'synapse_conv_padding': 1, 'synapse_trace_const1': 1, 'synapse_trace_const2': 0.5, 'pre_trained': False, 'convTrue_fcFalse': False, 'cfg': ['M', 'M', 200, 200], 'net_print': True, 'pre_trained_path': 'net_save/save_now_net_weights_{unique_name}.pth', 'learning_rate': 0.001, 'epoch_num': 100, 'tdBN_on': False, 'BN_on': False, 'surrogate': 'hard_sigmoid', 'BPTT_on': False, 'optimizer_what': 'SGD', 'scheduler_name': 'no', 'ddp_on': False, 'dvs_clipping': 5, 'dvs_duration': 100000, 'DFA_on': False, 'trace_on': True, 'OTTT_input_trace_on': False, 'exclude_class': True, 'merge_polarities': False, 'denoise_on': True, 'extra_train_dataset': 0, 'num_workers': 2, 'chaching_on': True, 'pin_memory': True, 'UDA_on': False, 'alpha_uda': 1, 'bias': True, 'last_lif': False, 'current epoch': 0} \n",
      "\n",
      "dataset_hash = 63cc597115630ec173f3099200061e53\n",
      "cache path exists\n",
      "\n",
      "device ==> cuda\n",
      "\n",
      "DataParallel(\n",
      "  (module): REBORN_MY_SNN_FC(\n",
      "    (layers): REBORN_MY_Sequential(\n",
      "      (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (2): DimChanger_for_FC()\n",
      "      (3): SYNAPSE_FC(in_features=2048, out_features=200, TIME=10, bias=True, sstep=True)\n",
      "      (4): LIF_layer(v_init=0, v_decay=0.5, v_threshold=0.25, v_reset=10000, sg_width=1, surrogate=hard_sigmoid, BPTT_on=False, trace_const1=1, trace_const2=0.5, TIME=10, sstep=True, trace_on=True)\n",
      "      (5): SYNAPSE_FC(in_features=200, out_features=200, TIME=10, bias=True, sstep=True)\n",
      "      (6): LIF_layer(v_init=0, v_decay=0.5, v_threshold=0.25, v_reset=10000, sg_width=1, surrogate=hard_sigmoid, BPTT_on=False, trace_const1=1, trace_const2=0.5, TIME=10, sstep=True, trace_on=True)\n",
      "      (7): SYNAPSE_FC(in_features=200, out_features=10, TIME=10, bias=True, sstep=True)\n",
      "    )\n",
      "  )\n",
      ")\n",
      "\n",
      "========================================================\n",
      "Trainable parameters: 452,010\n",
      "========================================================\n",
      "\n",
      "epoch-0   lr=['0.0010000'], tr/val_loss:  2.281256/  2.236278, val:  24.17%, val_best:  24.17%, tr:  13.07%, tr_best:  13.07%\n",
      "epoch-1   lr=['0.0010000'], tr/val_loss:  2.168968/  2.118688, val:  34.17%, val_best:  34.17%, tr:  26.35%, tr_best:  26.35%\n",
      "epoch-2   lr=['0.0010000'], tr/val_loss:  1.998518/  1.973606, val:  46.67%, val_best:  46.67%, tr:  39.12%, tr_best:  39.12%\n",
      "epoch-3   lr=['0.0010000'], tr/val_loss:  1.808780/  1.845806, val:  50.00%, val_best:  50.00%, tr:  46.99%, tr_best:  46.99%\n",
      "epoch-4   lr=['0.0010000'], tr/val_loss:  1.670350/  1.761221, val:  48.33%, val_best:  50.00%, tr:  53.52%, tr_best:  53.52%\n",
      "epoch-5   lr=['0.0010000'], tr/val_loss:  1.563874/  1.701393, val:  54.58%, val_best:  54.58%, tr:  57.51%, tr_best:  57.51%\n",
      "epoch-6   lr=['0.0010000'], tr/val_loss:  1.512920/  1.683004, val:  57.08%, val_best:  57.08%, tr:  60.67%, tr_best:  60.67%\n",
      "epoch-7   lr=['0.0010000'], tr/val_loss:  1.465359/  1.653486, val:  57.50%, val_best:  57.50%, tr:  60.67%, tr_best:  60.67%\n",
      "epoch-8   lr=['0.0010000'], tr/val_loss:  1.427895/  1.632757, val:  59.17%, val_best:  59.17%, tr:  60.57%, tr_best:  60.67%\n",
      "epoch-9   lr=['0.0010000'], tr/val_loss:  1.413491/  1.650457, val:  52.92%, val_best:  59.17%, tr:  63.43%, tr_best:  63.43%\n",
      "epoch-10  lr=['0.0010000'], tr/val_loss:  1.396569/  1.640223, val:  55.00%, val_best:  59.17%, tr:  62.51%, tr_best:  63.43%\n",
      "epoch-11  lr=['0.0010000'], tr/val_loss:  1.371094/  1.645255, val:  59.58%, val_best:  59.58%, tr:  65.07%, tr_best:  65.07%\n",
      "epoch-12  lr=['0.0010000'], tr/val_loss:  1.354871/  1.622378, val:  59.58%, val_best:  59.58%, tr:  65.78%, tr_best:  65.78%\n",
      "epoch-13  lr=['0.0010000'], tr/val_loss:  1.362880/  1.648576, val:  60.83%, val_best:  60.83%, tr:  66.70%, tr_best:  66.70%\n",
      "epoch-14  lr=['0.0010000'], tr/val_loss:  1.322955/  1.689742, val:  58.33%, val_best:  60.83%, tr:  65.88%, tr_best:  66.70%\n",
      "epoch-15  lr=['0.0010000'], tr/val_loss:  1.323968/  1.683986, val:  63.33%, val_best:  63.33%, tr:  67.21%, tr_best:  67.21%\n",
      "epoch-16  lr=['0.0010000'], tr/val_loss:  1.311844/  1.684635, val:  57.08%, val_best:  63.33%, tr:  67.93%, tr_best:  67.93%\n",
      "epoch-17  lr=['0.0010000'], tr/val_loss:  1.269262/  1.688249, val:  62.08%, val_best:  63.33%, tr:  71.91%, tr_best:  71.91%\n",
      "epoch-18  lr=['0.0010000'], tr/val_loss:  1.271008/  1.750124, val:  57.92%, val_best:  63.33%, tr:  72.83%, tr_best:  72.83%\n",
      "epoch-19  lr=['0.0010000'], tr/val_loss:  1.268923/  1.774460, val:  61.67%, val_best:  63.33%, tr:  69.77%, tr_best:  72.83%\n",
      "epoch-20  lr=['0.0010000'], tr/val_loss:  1.255078/  1.765552, val:  59.58%, val_best:  63.33%, tr:  73.95%, tr_best:  73.95%\n",
      "epoch-21  lr=['0.0010000'], tr/val_loss:  1.243724/  1.750225, val:  60.83%, val_best:  63.33%, tr:  71.50%, tr_best:  73.95%\n",
      "epoch-22  lr=['0.0010000'], tr/val_loss:  1.267105/  1.770011, val:  60.42%, val_best:  63.33%, tr:  71.81%, tr_best:  73.95%\n",
      "epoch-23  lr=['0.0010000'], tr/val_loss:  1.217294/  1.802576, val:  62.92%, val_best:  63.33%, tr:  75.18%, tr_best:  75.18%\n",
      "epoch-24  lr=['0.0010000'], tr/val_loss:  1.198767/  1.846818, val:  61.25%, val_best:  63.33%, tr:  76.20%, tr_best:  76.20%\n",
      "epoch-25  lr=['0.0010000'], tr/val_loss:  1.201529/  1.840060, val:  62.08%, val_best:  63.33%, tr:  75.89%, tr_best:  76.20%\n",
      "epoch-26  lr=['0.0010000'], tr/val_loss:  1.171439/  1.958434, val:  62.92%, val_best:  63.33%, tr:  75.08%, tr_best:  76.20%\n",
      "epoch-27  lr=['0.0010000'], tr/val_loss:  1.183259/  2.002282, val:  64.17%, val_best:  64.17%, tr:  78.14%, tr_best:  78.14%\n",
      "epoch-28  lr=['0.0010000'], tr/val_loss:  1.168718/  1.962517, val:  62.50%, val_best:  64.17%, tr:  75.89%, tr_best:  78.14%\n",
      "epoch-29  lr=['0.0010000'], tr/val_loss:  1.166164/  2.076759, val:  60.83%, val_best:  64.17%, tr:  78.45%, tr_best:  78.45%\n",
      "epoch-30  lr=['0.0010000'], tr/val_loss:  1.158993/  2.070206, val:  59.17%, val_best:  64.17%, tr:  80.18%, tr_best:  80.18%\n",
      "epoch-31  lr=['0.0010000'], tr/val_loss:  1.151621/  2.305538, val:  60.00%, val_best:  64.17%, tr:  76.92%, tr_best:  80.18%\n",
      "epoch-32  lr=['0.0010000'], tr/val_loss:  1.130068/  2.152054, val:  63.33%, val_best:  64.17%, tr:  78.65%, tr_best:  80.18%\n",
      "epoch-33  lr=['0.0010000'], tr/val_loss:  1.142067/  2.314422, val:  65.83%, val_best:  65.83%, tr:  80.39%, tr_best:  80.39%\n",
      "epoch-34  lr=['0.0010000'], tr/val_loss:  1.117192/  2.393082, val:  60.42%, val_best:  65.83%, tr:  78.75%, tr_best:  80.39%\n",
      "epoch-35  lr=['0.0010000'], tr/val_loss:  1.152742/  2.368165, val:  59.58%, val_best:  65.83%, tr:  76.00%, tr_best:  80.39%\n",
      "epoch-36  lr=['0.0010000'], tr/val_loss:  1.092824/  2.258287, val:  68.75%, val_best:  68.75%, tr:  80.69%, tr_best:  80.69%\n",
      "epoch-37  lr=['0.0010000'], tr/val_loss:  1.136653/  2.349795, val:  66.25%, val_best:  68.75%, tr:  80.49%, tr_best:  80.69%\n",
      "epoch-38  lr=['0.0010000'], tr/val_loss:  1.118038/  2.664464, val:  67.50%, val_best:  68.75%, tr:  82.43%, tr_best:  82.43%\n",
      "epoch-39  lr=['0.0010000'], tr/val_loss:  1.128126/  2.541017, val:  60.42%, val_best:  68.75%, tr:  82.33%, tr_best:  82.43%\n",
      "epoch-40  lr=['0.0010000'], tr/val_loss:  1.173753/  2.480733, val:  66.67%, val_best:  68.75%, tr:  79.88%, tr_best:  82.43%\n",
      "epoch-41  lr=['0.0010000'], tr/val_loss:  1.103968/  2.853765, val:  60.42%, val_best:  68.75%, tr:  84.58%, tr_best:  84.58%\n",
      "epoch-42  lr=['0.0010000'], tr/val_loss:  1.095403/  2.702437, val:  68.75%, val_best:  68.75%, tr:  83.96%, tr_best:  84.58%\n",
      "epoch-43  lr=['0.0010000'], tr/val_loss:  1.089863/  2.786071, val:  66.25%, val_best:  68.75%, tr:  82.84%, tr_best:  84.58%\n",
      "epoch-44  lr=['0.0010000'], tr/val_loss:  1.118600/  2.838596, val:  62.50%, val_best:  68.75%, tr:  83.35%, tr_best:  84.58%\n",
      "epoch-45  lr=['0.0010000'], tr/val_loss:  1.095817/  2.627625, val:  66.25%, val_best:  68.75%, tr:  84.98%, tr_best:  84.98%\n",
      "epoch-46  lr=['0.0010000'], tr/val_loss:  1.123775/  3.080333, val:  61.25%, val_best:  68.75%, tr:  86.21%, tr_best:  86.21%\n",
      "epoch-47  lr=['0.0010000'], tr/val_loss:  1.110566/  3.006935, val:  67.50%, val_best:  68.75%, tr:  84.78%, tr_best:  86.21%\n",
      "epoch-48  lr=['0.0010000'], tr/val_loss:  1.157048/  3.173591, val:  67.92%, val_best:  68.75%, tr:  86.01%, tr_best:  86.21%\n",
      "epoch-49  lr=['0.0010000'], tr/val_loss:  1.107682/  3.106712, val:  67.50%, val_best:  68.75%, tr:  83.96%, tr_best:  86.21%\n",
      "epoch-50  lr=['0.0010000'], tr/val_loss:  1.091877/  3.012962, val:  69.58%, val_best:  69.58%, tr:  84.98%, tr_best:  86.21%\n",
      "epoch-51  lr=['0.0010000'], tr/val_loss:  1.077016/  3.218703, val:  63.75%, val_best:  69.58%, tr:  84.78%, tr_best:  86.21%\n",
      "epoch-52  lr=['0.0010000'], tr/val_loss:  1.065688/  3.268191, val:  63.33%, val_best:  69.58%, tr:  86.93%, tr_best:  86.93%\n",
      "epoch-53  lr=['0.0010000'], tr/val_loss:  1.060537/  3.257894, val:  66.67%, val_best:  69.58%, tr:  88.87%, tr_best:  88.87%\n",
      "epoch-54  lr=['0.0010000'], tr/val_loss:  1.098270/  3.082893, val:  68.75%, val_best:  69.58%, tr:  87.74%, tr_best:  88.87%\n",
      "epoch-55  lr=['0.0010000'], tr/val_loss:  1.077489/  3.472328, val:  64.58%, val_best:  69.58%, tr:  86.82%, tr_best:  88.87%\n",
      "epoch-56  lr=['0.0010000'], tr/val_loss:  1.083052/  3.825838, val:  58.75%, val_best:  69.58%, tr:  87.23%, tr_best:  88.87%\n",
      "epoch-57  lr=['0.0010000'], tr/val_loss:  1.111774/  3.397553, val:  67.08%, val_best:  69.58%, tr:  87.03%, tr_best:  88.87%\n",
      "epoch-58  lr=['0.0010000'], tr/val_loss:  1.088806/  3.512193, val:  63.75%, val_best:  69.58%, tr:  86.52%, tr_best:  88.87%\n",
      "epoch-59  lr=['0.0010000'], tr/val_loss:  1.068916/  3.585066, val:  66.25%, val_best:  69.58%, tr:  87.64%, tr_best:  88.87%\n",
      "epoch-60  lr=['0.0010000'], tr/val_loss:  1.071541/  4.009542, val:  62.08%, val_best:  69.58%, tr:  89.17%, tr_best:  89.17%\n",
      "epoch-61  lr=['0.0010000'], tr/val_loss:  1.068114/  3.549655, val:  66.25%, val_best:  69.58%, tr:  88.87%, tr_best:  89.17%\n",
      "epoch-62  lr=['0.0010000'], tr/val_loss:  1.037822/  3.358868, val:  65.00%, val_best:  69.58%, tr:  89.38%, tr_best:  89.38%\n",
      "epoch-63  lr=['0.0010000'], tr/val_loss:  1.041645/  3.703207, val:  68.75%, val_best:  69.58%, tr:  91.73%, tr_best:  91.73%\n",
      "epoch-64  lr=['0.0010000'], tr/val_loss:  1.023824/  3.484334, val:  65.83%, val_best:  69.58%, tr:  89.58%, tr_best:  91.73%\n",
      "epoch-65  lr=['0.0010000'], tr/val_loss:  1.007073/  3.979007, val:  68.33%, val_best:  69.58%, tr:  88.97%, tr_best:  91.73%\n",
      "epoch-66  lr=['0.0010000'], tr/val_loss:  1.011701/  3.438095, val:  65.42%, val_best:  69.58%, tr:  91.42%, tr_best:  91.73%\n",
      "epoch-67  lr=['0.0010000'], tr/val_loss:  1.043236/  3.426079, val:  65.83%, val_best:  69.58%, tr:  91.73%, tr_best:  91.73%\n",
      "epoch-68  lr=['0.0010000'], tr/val_loss:  1.000000/  3.507076, val:  62.92%, val_best:  69.58%, tr:  90.70%, tr_best:  91.73%\n",
      "epoch-69  lr=['0.0010000'], tr/val_loss:  1.058429/  3.587040, val:  63.75%, val_best:  69.58%, tr:  87.74%, tr_best:  91.73%\n",
      "epoch-70  lr=['0.0010000'], tr/val_loss:  0.991615/  3.670096, val:  67.08%, val_best:  69.58%, tr:  90.40%, tr_best:  91.73%\n",
      "epoch-71  lr=['0.0010000'], tr/val_loss:  1.033996/  3.785107, val:  60.83%, val_best:  69.58%, tr:  89.89%, tr_best:  91.73%\n",
      "epoch-72  lr=['0.0010000'], tr/val_loss:  0.980103/  3.536301, val:  61.25%, val_best:  69.58%, tr:  92.54%, tr_best:  92.54%\n",
      "epoch-73  lr=['0.0010000'], tr/val_loss:  1.029173/  3.990701, val:  63.33%, val_best:  69.58%, tr:  88.97%, tr_best:  92.54%\n",
      "epoch-74  lr=['0.0010000'], tr/val_loss:  1.012259/  3.729860, val:  65.00%, val_best:  69.58%, tr:  91.01%, tr_best:  92.54%\n",
      "epoch-75  lr=['0.0010000'], tr/val_loss:  1.006918/  3.887493, val:  62.50%, val_best:  69.58%, tr:  90.81%, tr_best:  92.54%\n",
      "epoch-76  lr=['0.0010000'], tr/val_loss:  0.950402/  3.967897, val:  61.67%, val_best:  69.58%, tr:  91.42%, tr_best:  92.54%\n",
      "epoch-77  lr=['0.0010000'], tr/val_loss:  1.008077/  3.799717, val:  65.00%, val_best:  69.58%, tr:  88.56%, tr_best:  92.54%\n",
      "epoch-78  lr=['0.0010000'], tr/val_loss:  0.923720/  3.952341, val:  62.08%, val_best:  69.58%, tr:  91.32%, tr_best:  92.54%\n",
      "epoch-79  lr=['0.0010000'], tr/val_loss:  0.926696/  3.903915, val:  69.17%, val_best:  69.58%, tr:  91.83%, tr_best:  92.54%\n",
      "epoch-80  lr=['0.0010000'], tr/val_loss:  0.944119/  3.808437, val:  64.58%, val_best:  69.58%, tr:  90.70%, tr_best:  92.54%\n",
      "epoch-81  lr=['0.0010000'], tr/val_loss:  0.944965/  3.819913, val:  66.25%, val_best:  69.58%, tr:  91.73%, tr_best:  92.54%\n",
      "epoch-82  lr=['0.0010000'], tr/val_loss:  0.904357/  4.041475, val:  60.00%, val_best:  69.58%, tr:  92.65%, tr_best:  92.65%\n",
      "epoch-83  lr=['0.0010000'], tr/val_loss:  1.031136/  3.990607, val:  63.75%, val_best:  69.58%, tr:  89.79%, tr_best:  92.65%\n",
      "epoch-84  lr=['0.0010000'], tr/val_loss:  0.914459/  3.875223, val:  66.67%, val_best:  69.58%, tr:  94.38%, tr_best:  94.38%\n",
      "epoch-85  lr=['0.0010000'], tr/val_loss:  0.928667/  3.887707, val:  64.58%, val_best:  69.58%, tr:  93.77%, tr_best:  94.38%\n",
      "epoch-86  lr=['0.0010000'], tr/val_loss:  0.898142/  3.896263, val:  63.33%, val_best:  69.58%, tr:  93.97%, tr_best:  94.38%\n",
      "epoch-87  lr=['0.0010000'], tr/val_loss:  0.931764/  3.951588, val:  67.08%, val_best:  69.58%, tr:  90.19%, tr_best:  94.38%\n",
      "epoch-88  lr=['0.0010000'], tr/val_loss:  0.890435/  3.934170, val:  68.75%, val_best:  69.58%, tr:  91.83%, tr_best:  94.38%\n",
      "epoch-89  lr=['0.0010000'], tr/val_loss:  0.844352/  3.977200, val:  65.42%, val_best:  69.58%, tr:  94.79%, tr_best:  94.79%\n",
      "epoch-90  lr=['0.0010000'], tr/val_loss:  0.855800/  4.226499, val:  65.42%, val_best:  69.58%, tr:  94.18%, tr_best:  94.79%\n",
      "epoch-91  lr=['0.0010000'], tr/val_loss:  0.895206/  4.350040, val:  57.92%, val_best:  69.58%, tr:  91.32%, tr_best:  94.79%\n",
      "epoch-92  lr=['0.0010000'], tr/val_loss:  0.898914/  3.978185, val:  66.25%, val_best:  69.58%, tr:  91.52%, tr_best:  94.79%\n",
      "epoch-93  lr=['0.0010000'], tr/val_loss:  0.872958/  4.154763, val:  67.50%, val_best:  69.58%, tr:  92.44%, tr_best:  94.79%\n",
      "epoch-94  lr=['0.0010000'], tr/val_loss:  0.824172/  4.271844, val:  64.17%, val_best:  69.58%, tr:  94.18%, tr_best:  94.79%\n",
      "epoch-95  lr=['0.0010000'], tr/val_loss:  0.874562/  4.344711, val:  64.58%, val_best:  69.58%, tr:  93.16%, tr_best:  94.79%\n",
      "epoch-96  lr=['0.0010000'], tr/val_loss:  0.804922/  4.205698, val:  65.42%, val_best:  69.58%, tr:  94.48%, tr_best:  94.79%\n",
      "epoch-97  lr=['0.0010000'], tr/val_loss:  0.877579/  4.308939, val:  61.25%, val_best:  69.58%, tr:  93.87%, tr_best:  94.79%\n",
      "epoch-98  lr=['0.0010000'], tr/val_loss:  0.876963/  4.226209, val:  67.50%, val_best:  69.58%, tr:  93.26%, tr_best:  94.79%\n",
      "epoch-99  lr=['0.0010000'], tr/val_loss:  0.918131/  4.397591, val:  62.92%, val_best:  69.58%, tr:  92.34%, tr_best:  94.79%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "970e03a7c1784daea448afe1e564dd38",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.006 MB of 0.006 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>iter_acc</td><td>▂▄▁▃▂▅▅▂▃▅▅▇▅▆▅▇▇▆▇▇▆▇▆▇▇▇▇██▇▇█▆▇▆▇▇▆█▇</td></tr><tr><td>summary_val_acc</td><td>▁▅▅▆▅▇▆▇▇▇▇▇▇▇▇█▇█▇██▇█████▇█▇▇▇█▇██▇█▇▇</td></tr><tr><td>tr_acc</td><td>▁▃▄▅▅▆▆▆▆▆▆▆▇▇▆▇▇▇▇▇▇▇▇▇▇▇█████▇████████</td></tr><tr><td>tr_epoch_loss</td><td>█▇▅▄▄▃▃▃▃▃▃▃▃▂▃▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁</td></tr><tr><td>val_acc_best</td><td>▁▄▅▆▆▆▇▇▇▇▇▇▇▇▇█████████████████████████</td></tr><tr><td>val_acc_now</td><td>▁▅▅▆▅▇▆▇▇▇▇▇▇▇▇█▇█▇██▇█████▇█▇▇▇█▇██▇█▇▇</td></tr><tr><td>val_loss</td><td>▃▂▁▁▁▁▁▁▁▁▂▂▂▂▃▃▃▄▄▅▅▅▅▆▆▆▇▆▆▆▇▇▇▇▇▇▇▇██</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>99</td></tr><tr><td>iter_acc</td><td>1.0</td></tr><tr><td>tr_acc</td><td>0.92339</td></tr><tr><td>tr_epoch_loss</td><td>0.91813</td></tr><tr><td>val_acc_best</td><td>0.69583</td></tr><tr><td>val_acc_now</td><td>0.62917</td></tr><tr><td>val_loss</td><td>4.39759</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">fearless-sweep-107</strong> at: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/bqb51gyv' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/bqb51gyv</a><br/> View project at: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>/data2/bh_wandb/wandb/run-20250430_014843-bqb51gyv/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require(\"core\")`! See https://wandb.me/wandb-core for more information."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: zwgmdydq with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBATCH: 16\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBN_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBPTT_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tDFA_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tIMAGE_SIZE: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tOTTT_input_trace_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tTIME: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tUDA_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \talpha_uda: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbias: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcfg: ['M', 'M', 200, 200]\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tchaching_on: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tconvTrue_fcFalse: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdata_path: /data2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tddp_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdenoise_on: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdvs_clipping: 5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdvs_duration: 100000\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepoch_num: 100\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \texclude_class: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \textra_train_dataset: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlast_lif: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_sg_width: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_decay: 0.5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_init: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_reset: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_threshold: 0.75\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmerge_polarities: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmy_seed: 42\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnet_print: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_workers: 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer_what: SGD\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tpin_memory: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tpre_trained: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tpre_trained_path: net_save/save_now_net_weights_{unique_name}.pth\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \trate_coding: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tscheduler_name: no\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsingle_step: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsurrogate: hard_sigmoid\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_conv_kernel_size: 3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_conv_padding: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_conv_stride: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_trace_const1: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_trace_const2: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \ttdBN_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \ttrace_on: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \twhich_data: DVS_GESTURE_TONIC\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.19.10 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.17.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/data2/bh_wandb/wandb/run-20250430_015457-zwgmdydq</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/zwgmdydq' target=\"_blank\">young-sweep-110</a></strong> to <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/6pj3lh8j' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/6pj3lh8j</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/6pj3lh8j' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/6pj3lh8j</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/zwgmdydq' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/zwgmdydq</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'single_step' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'my_seed' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'TIME' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BATCH' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'IMAGE_SIZE' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'which_data' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'data_path' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'rate_coding' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_init' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_decay' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_threshold' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_reset' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_sg_width' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_conv_kernel_size' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_conv_stride' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_conv_padding' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_trace_const1' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_trace_const2' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'pre_trained' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'convTrue_fcFalse' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'cfg' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'net_print' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'pre_trained_path' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'learning_rate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'epoch_num' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'tdBN_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BN_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'surrogate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BPTT_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'optimizer_what' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'scheduler_name' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'ddp_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'dvs_clipping' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'dvs_duration' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'DFA_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'trace_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'OTTT_input_trace_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'exclude_class' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'merge_polarities' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'denoise_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'extra_train_dataset' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'num_workers' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'chaching_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'pin_memory' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'UDA_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'alpha_uda' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'bias' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'last_lif' was locked by 'sweep' (ignored update).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "param {'devices': '0', 'single_step': True, 'unique_name': 'main', 'my_seed': 42, 'TIME': 10, 'BATCH': 16, 'IMAGE_SIZE': 128, 'which_data': 'DVS_GESTURE_TONIC', 'data_path': '/data2', 'rate_coding': False, 'lif_layer_v_init': 0, 'lif_layer_v_decay': 0.5, 'lif_layer_v_threshold': 0.75, 'lif_layer_v_reset': 0, 'lif_layer_sg_width': 1, 'synapse_conv_kernel_size': 3, 'synapse_conv_stride': 1, 'synapse_conv_padding': 1, 'synapse_trace_const1': 1, 'synapse_trace_const2': 0, 'pre_trained': False, 'convTrue_fcFalse': False, 'cfg': ['M', 'M', 200, 200], 'net_print': True, 'pre_trained_path': 'net_save/save_now_net_weights_{unique_name}.pth', 'learning_rate': 0.1, 'epoch_num': 100, 'tdBN_on': False, 'BN_on': False, 'surrogate': 'hard_sigmoid', 'BPTT_on': False, 'optimizer_what': 'SGD', 'scheduler_name': 'no', 'ddp_on': False, 'dvs_clipping': 5, 'dvs_duration': 100000, 'DFA_on': False, 'trace_on': True, 'OTTT_input_trace_on': False, 'exclude_class': True, 'merge_polarities': False, 'denoise_on': True, 'extra_train_dataset': 0, 'num_workers': 2, 'chaching_on': True, 'pin_memory': True, 'UDA_on': False, 'alpha_uda': 1, 'bias': True, 'last_lif': False, 'current epoch': 0} \n",
      "\n",
      "dataset_hash = 63cc597115630ec173f3099200061e53\n",
      "cache path exists\n",
      "\n",
      "device ==> cuda\n",
      "\n",
      "DataParallel(\n",
      "  (module): REBORN_MY_SNN_FC(\n",
      "    (layers): REBORN_MY_Sequential(\n",
      "      (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (2): DimChanger_for_FC()\n",
      "      (3): SYNAPSE_FC(in_features=2048, out_features=200, TIME=10, bias=True, sstep=True)\n",
      "      (4): LIF_layer(v_init=0, v_decay=0.5, v_threshold=0.75, v_reset=0, sg_width=1, surrogate=hard_sigmoid, BPTT_on=False, trace_const1=1, trace_const2=0, TIME=10, sstep=True, trace_on=True)\n",
      "      (5): SYNAPSE_FC(in_features=200, out_features=200, TIME=10, bias=True, sstep=True)\n",
      "      (6): LIF_layer(v_init=0, v_decay=0.5, v_threshold=0.75, v_reset=0, sg_width=1, surrogate=hard_sigmoid, BPTT_on=False, trace_const1=1, trace_const2=0, TIME=10, sstep=True, trace_on=True)\n",
      "      (7): SYNAPSE_FC(in_features=200, out_features=10, TIME=10, bias=True, sstep=True)\n",
      "    )\n",
      "  )\n",
      ")\n",
      "\n",
      "========================================================\n",
      "Trainable parameters: 452,010\n",
      "========================================================\n",
      "\n",
      "epoch-0   lr=['0.1000000'], tr/val_loss:  2.239194/  2.168867, val:  43.33%, val_best:  43.33%, tr:  24.72%, tr_best:  24.72%\n",
      "epoch-1   lr=['0.1000000'], tr/val_loss:  1.630032/  2.172540, val:  42.50%, val_best:  43.33%, tr:  49.13%, tr_best:  49.13%\n",
      "epoch-2   lr=['0.1000000'], tr/val_loss:  1.469254/  1.838561, val:  50.00%, val_best:  50.00%, tr:  57.81%, tr_best:  57.81%\n",
      "epoch-3   lr=['0.1000000'], tr/val_loss:  1.213682/  1.628811, val:  48.75%, val_best:  50.00%, tr:  64.04%, tr_best:  64.04%\n",
      "epoch-4   lr=['0.1000000'], tr/val_loss:  1.177859/  1.445169, val:  57.92%, val_best:  57.92%, tr:  62.82%, tr_best:  64.04%\n",
      "epoch-5   lr=['0.1000000'], tr/val_loss:  1.004995/  1.706322, val:  48.75%, val_best:  57.92%, tr:  68.44%, tr_best:  68.44%\n",
      "epoch-6   lr=['0.1000000'], tr/val_loss:  0.972273/  1.641523, val:  54.17%, val_best:  57.92%, tr:  71.50%, tr_best:  71.50%\n",
      "epoch-7   lr=['0.1000000'], tr/val_loss:  1.120075/  1.728438, val:  54.58%, val_best:  57.92%, tr:  64.35%, tr_best:  71.50%\n",
      "epoch-8   lr=['0.1000000'], tr/val_loss:  0.934743/  1.637295, val:  58.33%, val_best:  58.33%, tr:  72.42%, tr_best:  72.42%\n",
      "epoch-9   lr=['0.1000000'], tr/val_loss:  0.779782/  1.521866, val:  57.50%, val_best:  58.33%, tr:  75.08%, tr_best:  75.08%\n",
      "epoch-10  lr=['0.1000000'], tr/val_loss:  0.793246/  1.713473, val:  59.17%, val_best:  59.17%, tr:  74.57%, tr_best:  75.08%\n",
      "epoch-11  lr=['0.1000000'], tr/val_loss:  0.769592/  1.820194, val:  60.42%, val_best:  60.42%, tr:  78.45%, tr_best:  78.45%\n",
      "epoch-12  lr=['0.1000000'], tr/val_loss:  0.752642/  1.502941, val:  62.50%, val_best:  62.50%, tr:  75.18%, tr_best:  78.45%\n",
      "epoch-13  lr=['0.1000000'], tr/val_loss:  0.697172/  1.495661, val:  62.50%, val_best:  62.50%, tr:  78.65%, tr_best:  78.65%\n",
      "epoch-14  lr=['0.1000000'], tr/val_loss:  0.627478/  1.655062, val:  71.67%, val_best:  71.67%, tr:  81.41%, tr_best:  81.41%\n",
      "epoch-15  lr=['0.1000000'], tr/val_loss:  0.539331/  1.773179, val:  63.33%, val_best:  71.67%, tr:  84.78%, tr_best:  84.78%\n",
      "epoch-16  lr=['0.1000000'], tr/val_loss:  0.546408/  1.645962, val:  68.33%, val_best:  71.67%, tr:  82.64%, tr_best:  84.78%\n",
      "epoch-17  lr=['0.1000000'], tr/val_loss:  0.444612/  1.468625, val:  67.92%, val_best:  71.67%, tr:  86.82%, tr_best:  86.82%\n",
      "epoch-18  lr=['0.1000000'], tr/val_loss:  0.452059/  1.762771, val:  63.75%, val_best:  71.67%, tr:  87.54%, tr_best:  87.54%\n",
      "epoch-19  lr=['0.1000000'], tr/val_loss:  0.465111/  1.724358, val:  71.25%, val_best:  71.67%, tr:  87.74%, tr_best:  87.74%\n",
      "epoch-20  lr=['0.1000000'], tr/val_loss:  0.441091/  1.593220, val:  77.50%, val_best:  77.50%, tr:  90.50%, tr_best:  90.50%\n",
      "epoch-21  lr=['0.1000000'], tr/val_loss:  0.409073/  2.301307, val:  65.00%, val_best:  77.50%, tr:  90.19%, tr_best:  90.50%\n",
      "epoch-22  lr=['0.1000000'], tr/val_loss:  0.293084/  1.807883, val:  71.67%, val_best:  77.50%, tr:  94.79%, tr_best:  94.79%\n",
      "epoch-23  lr=['0.1000000'], tr/val_loss:  0.268617/  1.862004, val:  73.75%, val_best:  77.50%, tr:  94.89%, tr_best:  94.89%\n",
      "epoch-24  lr=['0.1000000'], tr/val_loss:  0.189997/  1.928614, val:  77.08%, val_best:  77.50%, tr:  96.63%, tr_best:  96.63%\n",
      "epoch-25  lr=['0.1000000'], tr/val_loss:  0.187309/  1.895885, val:  75.42%, val_best:  77.50%, tr:  96.53%, tr_best:  96.63%\n",
      "epoch-26  lr=['0.1000000'], tr/val_loss:  0.144258/  2.022359, val:  75.00%, val_best:  77.50%, tr:  98.26%, tr_best:  98.26%\n",
      "epoch-27  lr=['0.1000000'], tr/val_loss:  0.116241/  2.117824, val:  77.08%, val_best:  77.50%, tr:  98.47%, tr_best:  98.47%\n",
      "epoch-28  lr=['0.1000000'], tr/val_loss:  0.127817/  2.211551, val:  73.75%, val_best:  77.50%, tr:  98.77%, tr_best:  98.77%\n",
      "epoch-29  lr=['0.1000000'], tr/val_loss:  0.109313/  2.275415, val:  73.75%, val_best:  77.50%, tr:  99.49%, tr_best:  99.49%\n",
      "epoch-30  lr=['0.1000000'], tr/val_loss:  0.197512/  2.134175, val:  73.33%, val_best:  77.50%, tr:  97.45%, tr_best:  99.49%\n",
      "epoch-31  lr=['0.1000000'], tr/val_loss:  0.126489/  2.243741, val:  74.17%, val_best:  77.50%, tr:  99.39%, tr_best:  99.49%\n",
      "epoch-32  lr=['0.1000000'], tr/val_loss:  0.120828/  2.218873, val:  74.17%, val_best:  77.50%, tr:  99.08%, tr_best:  99.49%\n",
      "epoch-33  lr=['0.1000000'], tr/val_loss:  0.180147/  2.240840, val:  72.08%, val_best:  77.50%, tr:  97.96%, tr_best:  99.49%\n",
      "epoch-34  lr=['0.1000000'], tr/val_loss:  0.086443/  2.386129, val:  72.50%, val_best:  77.50%, tr:  99.49%, tr_best:  99.49%\n",
      "epoch-35  lr=['0.1000000'], tr/val_loss:  0.111625/  2.345612, val:  73.33%, val_best:  77.50%, tr:  99.18%, tr_best:  99.49%\n",
      "epoch-36  lr=['0.1000000'], tr/val_loss:  0.076350/  2.374805, val:  72.92%, val_best:  77.50%, tr:  99.80%, tr_best:  99.80%\n",
      "epoch-37  lr=['0.1000000'], tr/val_loss:  0.061418/  2.453709, val:  72.92%, val_best:  77.50%, tr:  99.80%, tr_best:  99.80%\n",
      "epoch-38  lr=['0.1000000'], tr/val_loss:  0.026973/  2.495612, val:  76.25%, val_best:  77.50%, tr:  99.90%, tr_best:  99.90%\n",
      "epoch-39  lr=['0.1000000'], tr/val_loss:  0.030621/  2.341746, val:  77.50%, val_best:  77.50%, tr:  99.90%, tr_best:  99.90%\n",
      "epoch-40  lr=['0.1000000'], tr/val_loss:  0.045475/  2.411119, val:  75.83%, val_best:  77.50%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-41  lr=['0.1000000'], tr/val_loss:  0.027234/  2.472018, val:  74.58%, val_best:  77.50%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-42  lr=['0.1000000'], tr/val_loss:  0.018124/  2.423024, val:  77.92%, val_best:  77.92%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-43  lr=['0.1000000'], tr/val_loss:  0.012654/  2.428750, val:  77.50%, val_best:  77.92%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-44  lr=['0.1000000'], tr/val_loss:  0.004037/  2.353272, val:  79.58%, val_best:  79.58%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-45  lr=['0.1000000'], tr/val_loss:  0.002789/  2.357029, val:  78.33%, val_best:  79.58%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-46  lr=['0.1000000'], tr/val_loss:  0.008393/  2.394981, val:  81.67%, val_best:  81.67%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-47  lr=['0.1000000'], tr/val_loss:  0.005160/  2.533742, val:  76.25%, val_best:  81.67%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-48  lr=['0.1000000'], tr/val_loss:  0.003222/  2.472469, val:  76.67%, val_best:  81.67%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-49  lr=['0.1000000'], tr/val_loss:  0.001715/  2.514222, val:  78.75%, val_best:  81.67%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-50  lr=['0.1000000'], tr/val_loss:  0.000991/  2.537728, val:  79.17%, val_best:  81.67%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-51  lr=['0.1000000'], tr/val_loss:  0.007315/  2.467459, val:  80.00%, val_best:  81.67%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-52  lr=['0.1000000'], tr/val_loss:  0.002591/  2.494067, val:  76.25%, val_best:  81.67%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-53  lr=['0.1000000'], tr/val_loss:  0.002928/  2.631331, val:  75.00%, val_best:  81.67%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-54  lr=['0.1000000'], tr/val_loss:  0.001142/  2.549402, val:  76.25%, val_best:  81.67%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-55  lr=['0.1000000'], tr/val_loss:  0.001665/  2.636893, val:  77.08%, val_best:  81.67%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-56  lr=['0.1000000'], tr/val_loss:  0.001574/  2.639488, val:  77.08%, val_best:  81.67%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-57  lr=['0.1000000'], tr/val_loss:  0.001519/  2.616646, val:  76.67%, val_best:  81.67%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-58  lr=['0.1000000'], tr/val_loss:  0.000283/  2.669043, val:  75.83%, val_best:  81.67%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-59  lr=['0.1000000'], tr/val_loss:  0.000244/  2.684401, val:  75.83%, val_best:  81.67%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-60  lr=['0.1000000'], tr/val_loss:  0.000384/  2.683105, val:  77.92%, val_best:  81.67%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-61  lr=['0.1000000'], tr/val_loss:  0.000194/  2.702860, val:  77.08%, val_best:  81.67%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-62  lr=['0.1000000'], tr/val_loss:  0.000182/  2.703420, val:  78.33%, val_best:  81.67%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-63  lr=['0.1000000'], tr/val_loss:  0.000169/  2.707676, val:  77.92%, val_best:  81.67%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-64  lr=['0.1000000'], tr/val_loss:  0.000155/  2.692768, val:  78.33%, val_best:  81.67%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-65  lr=['0.1000000'], tr/val_loss:  0.000185/  2.706254, val:  77.08%, val_best:  81.67%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-66  lr=['0.1000000'], tr/val_loss:  0.000292/  2.744778, val:  77.08%, val_best:  81.67%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-67  lr=['0.1000000'], tr/val_loss:  0.000202/  2.685328, val:  78.33%, val_best:  81.67%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-68  lr=['0.1000000'], tr/val_loss:  0.000235/  2.732932, val:  76.25%, val_best:  81.67%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-69  lr=['0.1000000'], tr/val_loss:  0.000162/  2.740481, val:  76.67%, val_best:  81.67%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-70  lr=['0.1000000'], tr/val_loss:  0.000141/  2.727676, val:  76.25%, val_best:  81.67%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-71  lr=['0.1000000'], tr/val_loss:  0.000132/  2.720950, val:  76.25%, val_best:  81.67%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-72  lr=['0.1000000'], tr/val_loss:  0.000130/  2.723649, val:  76.25%, val_best:  81.67%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-73  lr=['0.1000000'], tr/val_loss:  0.000109/  2.732667, val:  76.25%, val_best:  81.67%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-74  lr=['0.1000000'], tr/val_loss:  0.000110/  2.736564, val:  76.25%, val_best:  81.67%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-75  lr=['0.1000000'], tr/val_loss:  0.000125/  2.736362, val:  76.67%, val_best:  81.67%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-76  lr=['0.1000000'], tr/val_loss:  0.000102/  2.730990, val:  76.25%, val_best:  81.67%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-77  lr=['0.1000000'], tr/val_loss:  0.000099/  2.737687, val:  76.67%, val_best:  81.67%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-78  lr=['0.1000000'], tr/val_loss:  0.000098/  2.743830, val:  77.08%, val_best:  81.67%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-79  lr=['0.1000000'], tr/val_loss:  0.000092/  2.751617, val:  77.50%, val_best:  81.67%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-80  lr=['0.1000000'], tr/val_loss:  0.000095/  2.757285, val:  77.50%, val_best:  81.67%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-81  lr=['0.1000000'], tr/val_loss:  0.000090/  2.770921, val:  77.92%, val_best:  81.67%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-82  lr=['0.1000000'], tr/val_loss:  0.000086/  2.777397, val:  77.92%, val_best:  81.67%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-83  lr=['0.1000000'], tr/val_loss:  0.000086/  2.773158, val:  77.92%, val_best:  81.67%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-84  lr=['0.1000000'], tr/val_loss:  0.000087/  2.783699, val:  77.92%, val_best:  81.67%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-85  lr=['0.1000000'], tr/val_loss:  0.000083/  2.780514, val:  77.50%, val_best:  81.67%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-86  lr=['0.1000000'], tr/val_loss:  0.000079/  2.782333, val:  77.50%, val_best:  81.67%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-87  lr=['0.1000000'], tr/val_loss:  0.000074/  2.791447, val:  77.50%, val_best:  81.67%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-88  lr=['0.1000000'], tr/val_loss:  0.000080/  2.792059, val:  77.50%, val_best:  81.67%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-89  lr=['0.1000000'], tr/val_loss:  0.000075/  2.799875, val:  77.50%, val_best:  81.67%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-90  lr=['0.1000000'], tr/val_loss:  0.000073/  2.804322, val:  77.50%, val_best:  81.67%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-91  lr=['0.1000000'], tr/val_loss:  0.000075/  2.808111, val:  77.50%, val_best:  81.67%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-92  lr=['0.1000000'], tr/val_loss:  0.000076/  2.809241, val:  77.50%, val_best:  81.67%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-93  lr=['0.1000000'], tr/val_loss:  0.000072/  2.817059, val:  77.50%, val_best:  81.67%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-94  lr=['0.1000000'], tr/val_loss:  0.000076/  2.816498, val:  77.92%, val_best:  81.67%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-95  lr=['0.1000000'], tr/val_loss:  0.000070/  2.811096, val:  78.75%, val_best:  81.67%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-96  lr=['0.1000000'], tr/val_loss:  0.000066/  2.816948, val:  78.75%, val_best:  81.67%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-97  lr=['0.1000000'], tr/val_loss:  0.000065/  2.817998, val:  78.75%, val_best:  81.67%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-98  lr=['0.1000000'], tr/val_loss:  0.000073/  2.816112, val:  79.17%, val_best:  81.67%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-99  lr=['0.1000000'], tr/val_loss:  0.000066/  2.818540, val:  79.17%, val_best:  81.67%, tr: 100.00%, tr_best: 100.00%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bc6424325c98487d9ca553b2dbf235b5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.006 MB of 0.006 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>iter_acc</td><td>▁▅▅▄▃▅▆▇▇███▇▇██████████████████████████</td></tr><tr><td>summary_val_acc</td><td>▁▂▄▃▄▅▆▆▆▅█▇▇▇▇▇███▇█▇▇▇▇███▇▇▇▇████████</td></tr><tr><td>tr_acc</td><td>▁▄▅▅▆▆▆▇▇▇██████████████████████████████</td></tr><tr><td>tr_epoch_loss</td><td>█▆▅▅▃▃▃▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_acc_best</td><td>▁▂▄▄▄▅▆▆▆▇▇▇▇▇▇▇▇▇██████████████████████</td></tr><tr><td>val_acc_now</td><td>▁▂▄▃▄▅▆▆▆▅█▇▇▇▇▇███▇█▇▇▇▇███▇▇▇▇████████</td></tr><tr><td>val_loss</td><td>▅▃▁▂▁▁▂▁▂▅▃▄▅▅▆▆▆▆▆▇▆▆▇▇▇▇▇▇████████████</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>99</td></tr><tr><td>iter_acc</td><td>1.0</td></tr><tr><td>tr_acc</td><td>1.0</td></tr><tr><td>tr_epoch_loss</td><td>7e-05</td></tr><tr><td>val_acc_best</td><td>0.81667</td></tr><tr><td>val_acc_now</td><td>0.79167</td></tr><tr><td>val_loss</td><td>2.81854</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">young-sweep-110</strong> at: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/zwgmdydq' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/zwgmdydq</a><br/> View project at: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>/data2/bh_wandb/wandb/run-20250430_015457-zwgmdydq/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require(\"core\")`! See https://wandb.me/wandb-core for more information."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: qjy0fjms with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBATCH: 16\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBN_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBPTT_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tDFA_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tIMAGE_SIZE: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tOTTT_input_trace_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tTIME: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tUDA_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \talpha_uda: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbias: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcfg: ['M', 'M', 200, 200]\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tchaching_on: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tconvTrue_fcFalse: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdata_path: /data2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tddp_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdenoise_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdvs_clipping: 5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdvs_duration: 100000\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepoch_num: 100\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \texclude_class: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \textra_train_dataset: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlast_lif: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.001\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_sg_width: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_decay: 0.5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_init: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_reset: 10000\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_threshold: 0.25\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmerge_polarities: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmy_seed: 42\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnet_print: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_workers: 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer_what: SGD\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tpin_memory: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tpre_trained: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tpre_trained_path: net_save/save_now_net_weights_{unique_name}.pth\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \trate_coding: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tscheduler_name: no\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsingle_step: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsurrogate: hard_sigmoid\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_conv_kernel_size: 3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_conv_padding: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_conv_stride: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_trace_const1: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_trace_const2: 0.5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \ttdBN_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \ttrace_on: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \twhich_data: DVS_GESTURE_TONIC\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c262faf790f24d9e8f68b02825c476e3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.011113068968471553, max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.19.10 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.17.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/data2/bh_wandb/wandb/run-20250430_020108-qjy0fjms</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/qjy0fjms' target=\"_blank\">tough-sweep-114</a></strong> to <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/6pj3lh8j' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/6pj3lh8j</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/6pj3lh8j' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/6pj3lh8j</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/qjy0fjms' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/qjy0fjms</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'single_step' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'my_seed' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'TIME' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BATCH' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'IMAGE_SIZE' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'which_data' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'data_path' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'rate_coding' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_init' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_decay' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_threshold' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_reset' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_sg_width' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_conv_kernel_size' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_conv_stride' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_conv_padding' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_trace_const1' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_trace_const2' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'pre_trained' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'convTrue_fcFalse' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'cfg' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'net_print' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'pre_trained_path' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'learning_rate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'epoch_num' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'tdBN_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BN_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'surrogate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BPTT_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'optimizer_what' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'scheduler_name' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'ddp_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'dvs_clipping' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'dvs_duration' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'DFA_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'trace_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'OTTT_input_trace_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'exclude_class' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'merge_polarities' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'denoise_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'extra_train_dataset' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'num_workers' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'chaching_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'pin_memory' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'UDA_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'alpha_uda' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'bias' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'last_lif' was locked by 'sweep' (ignored update).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "param {'devices': '0', 'single_step': True, 'unique_name': 'main', 'my_seed': 42, 'TIME': 10, 'BATCH': 16, 'IMAGE_SIZE': 128, 'which_data': 'DVS_GESTURE_TONIC', 'data_path': '/data2', 'rate_coding': False, 'lif_layer_v_init': 0, 'lif_layer_v_decay': 0.5, 'lif_layer_v_threshold': 0.25, 'lif_layer_v_reset': 10000, 'lif_layer_sg_width': 1, 'synapse_conv_kernel_size': 3, 'synapse_conv_stride': 1, 'synapse_conv_padding': 1, 'synapse_trace_const1': 1, 'synapse_trace_const2': 0.5, 'pre_trained': False, 'convTrue_fcFalse': False, 'cfg': ['M', 'M', 200, 200], 'net_print': True, 'pre_trained_path': 'net_save/save_now_net_weights_{unique_name}.pth', 'learning_rate': 0.001, 'epoch_num': 100, 'tdBN_on': False, 'BN_on': False, 'surrogate': 'hard_sigmoid', 'BPTT_on': False, 'optimizer_what': 'SGD', 'scheduler_name': 'no', 'ddp_on': False, 'dvs_clipping': 5, 'dvs_duration': 100000, 'DFA_on': False, 'trace_on': True, 'OTTT_input_trace_on': False, 'exclude_class': True, 'merge_polarities': False, 'denoise_on': False, 'extra_train_dataset': 0, 'num_workers': 2, 'chaching_on': True, 'pin_memory': True, 'UDA_on': False, 'alpha_uda': 1, 'bias': True, 'last_lif': False, 'current epoch': 0} \n",
      "\n",
      "dataset_hash = ffa516e60c3efd5e0208f72b4c36cb84\n",
      "cache path exists\n",
      "\n",
      "device ==> cuda\n",
      "\n",
      "DataParallel(\n",
      "  (module): REBORN_MY_SNN_FC(\n",
      "    (layers): REBORN_MY_Sequential(\n",
      "      (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (2): DimChanger_for_FC()\n",
      "      (3): SYNAPSE_FC(in_features=2048, out_features=200, TIME=10, bias=True, sstep=True)\n",
      "      (4): LIF_layer(v_init=0, v_decay=0.5, v_threshold=0.25, v_reset=10000, sg_width=1, surrogate=hard_sigmoid, BPTT_on=False, trace_const1=1, trace_const2=0.5, TIME=10, sstep=True, trace_on=True)\n",
      "      (5): SYNAPSE_FC(in_features=200, out_features=200, TIME=10, bias=True, sstep=True)\n",
      "      (6): LIF_layer(v_init=0, v_decay=0.5, v_threshold=0.25, v_reset=10000, sg_width=1, surrogate=hard_sigmoid, BPTT_on=False, trace_const1=1, trace_const2=0.5, TIME=10, sstep=True, trace_on=True)\n",
      "      (7): SYNAPSE_FC(in_features=200, out_features=10, TIME=10, bias=True, sstep=True)\n",
      "    )\n",
      "  )\n",
      ")\n",
      "\n",
      "========================================================\n",
      "Trainable parameters: 452,010\n",
      "========================================================\n",
      "\n",
      "epoch-0   lr=['0.0010000'], tr/val_loss:  2.253038/  2.173000, val:  23.33%, val_best:  23.33%, tr:  17.98%, tr_best:  17.98%\n",
      "epoch-1   lr=['0.0010000'], tr/val_loss:  2.026780/  1.935571, val:  45.00%, val_best:  45.00%, tr:  35.04%, tr_best:  35.04%\n",
      "epoch-2   lr=['0.0010000'], tr/val_loss:  1.752048/  1.739368, val:  46.67%, val_best:  46.67%, tr:  48.31%, tr_best:  48.31%\n",
      "epoch-3   lr=['0.0010000'], tr/val_loss:  1.557782/  1.628005, val:  52.50%, val_best:  52.50%, tr:  57.41%, tr_best:  57.41%\n",
      "epoch-4   lr=['0.0010000'], tr/val_loss:  1.465136/  1.600983, val:  51.67%, val_best:  52.50%, tr:  57.81%, tr_best:  57.81%\n",
      "epoch-5   lr=['0.0010000'], tr/val_loss:  1.391588/  1.561017, val:  55.83%, val_best:  55.83%, tr:  60.78%, tr_best:  60.78%\n",
      "epoch-6   lr=['0.0010000'], tr/val_loss:  1.353717/  1.543227, val:  56.25%, val_best:  56.25%, tr:  62.31%, tr_best:  62.31%\n",
      "epoch-7   lr=['0.0010000'], tr/val_loss:  1.316330/  1.538760, val:  56.67%, val_best:  56.67%, tr:  63.13%, tr_best:  63.13%\n",
      "epoch-8   lr=['0.0010000'], tr/val_loss:  1.282019/  1.518945, val:  62.50%, val_best:  62.50%, tr:  64.04%, tr_best:  64.04%\n",
      "epoch-9   lr=['0.0010000'], tr/val_loss:  1.258656/  1.524045, val:  60.42%, val_best:  62.50%, tr:  66.60%, tr_best:  66.60%\n",
      "epoch-10  lr=['0.0010000'], tr/val_loss:  1.238890/  1.539262, val:  61.25%, val_best:  62.50%, tr:  66.60%, tr_best:  66.60%\n",
      "epoch-11  lr=['0.0010000'], tr/val_loss:  1.209761/  1.534050, val:  61.25%, val_best:  62.50%, tr:  68.13%, tr_best:  68.13%\n",
      "epoch-12  lr=['0.0010000'], tr/val_loss:  1.195103/  1.544221, val:  60.83%, val_best:  62.50%, tr:  71.50%, tr_best:  71.50%\n",
      "epoch-13  lr=['0.0010000'], tr/val_loss:  1.180459/  1.568970, val:  60.83%, val_best:  62.50%, tr:  70.79%, tr_best:  71.50%\n",
      "epoch-14  lr=['0.0010000'], tr/val_loss:  1.139548/  1.619714, val:  58.75%, val_best:  62.50%, tr:  72.11%, tr_best:  72.11%\n",
      "epoch-15  lr=['0.0010000'], tr/val_loss:  1.143866/  1.595213, val:  63.75%, val_best:  63.75%, tr:  72.93%, tr_best:  72.93%\n",
      "epoch-16  lr=['0.0010000'], tr/val_loss:  1.134778/  1.657060, val:  60.83%, val_best:  63.75%, tr:  73.44%, tr_best:  73.44%\n",
      "epoch-17  lr=['0.0010000'], tr/val_loss:  1.096624/  1.614286, val:  67.50%, val_best:  67.50%, tr:  77.83%, tr_best:  77.83%\n",
      "epoch-18  lr=['0.0010000'], tr/val_loss:  1.072215/  1.762628, val:  61.25%, val_best:  67.50%, tr:  76.61%, tr_best:  77.83%\n",
      "epoch-19  lr=['0.0010000'], tr/val_loss:  1.086517/  1.789464, val:  65.00%, val_best:  67.50%, tr:  74.46%, tr_best:  77.83%\n",
      "epoch-20  lr=['0.0010000'], tr/val_loss:  1.049497/  1.856684, val:  63.33%, val_best:  67.50%, tr:  79.67%, tr_best:  79.67%\n",
      "epoch-21  lr=['0.0010000'], tr/val_loss:  1.046021/  1.884837, val:  65.83%, val_best:  67.50%, tr:  78.65%, tr_best:  79.67%\n",
      "epoch-22  lr=['0.0010000'], tr/val_loss:  1.065267/  1.819382, val:  63.33%, val_best:  67.50%, tr:  76.92%, tr_best:  79.67%\n",
      "epoch-23  lr=['0.0010000'], tr/val_loss:  1.013259/  1.920969, val:  65.83%, val_best:  67.50%, tr:  80.29%, tr_best:  80.29%\n",
      "epoch-24  lr=['0.0010000'], tr/val_loss:  1.008961/  2.005678, val:  60.00%, val_best:  67.50%, tr:  81.00%, tr_best:  81.00%\n",
      "epoch-25  lr=['0.0010000'], tr/val_loss:  0.990891/  2.030458, val:  67.92%, val_best:  67.92%, tr:  82.74%, tr_best:  82.74%\n",
      "epoch-26  lr=['0.0010000'], tr/val_loss:  0.978603/  2.085703, val:  70.00%, val_best:  70.00%, tr:  82.12%, tr_best:  82.74%\n",
      "epoch-27  lr=['0.0010000'], tr/val_loss:  0.961791/  2.132589, val:  69.17%, val_best:  70.00%, tr:  84.98%, tr_best:  84.98%\n",
      "epoch-28  lr=['0.0010000'], tr/val_loss:  0.987977/  2.184265, val:  67.50%, val_best:  70.00%, tr:  82.84%, tr_best:  84.98%\n",
      "epoch-29  lr=['0.0010000'], tr/val_loss:  0.961525/  2.400336, val:  60.42%, val_best:  70.00%, tr:  85.80%, tr_best:  85.80%\n",
      "epoch-30  lr=['0.0010000'], tr/val_loss:  0.930021/  2.360325, val:  62.50%, val_best:  70.00%, tr:  86.72%, tr_best:  86.72%\n",
      "epoch-31  lr=['0.0010000'], tr/val_loss:  0.956652/  2.553732, val:  60.42%, val_best:  70.00%, tr:  83.66%, tr_best:  86.72%\n",
      "epoch-32  lr=['0.0010000'], tr/val_loss:  0.941947/  2.665990, val:  67.50%, val_best:  70.00%, tr:  84.68%, tr_best:  86.72%\n",
      "epoch-33  lr=['0.0010000'], tr/val_loss:  0.943704/  2.717016, val:  67.08%, val_best:  70.00%, tr:  87.54%, tr_best:  87.54%\n",
      "epoch-34  lr=['0.0010000'], tr/val_loss:  0.907623/  2.857964, val:  63.33%, val_best:  70.00%, tr:  86.72%, tr_best:  87.54%\n",
      "epoch-35  lr=['0.0010000'], tr/val_loss:  0.930166/  2.960529, val:  61.25%, val_best:  70.00%, tr:  84.27%, tr_best:  87.54%\n",
      "epoch-36  lr=['0.0010000'], tr/val_loss:  0.904926/  2.720980, val:  67.50%, val_best:  70.00%, tr:  88.66%, tr_best:  88.66%\n",
      "epoch-37  lr=['0.0010000'], tr/val_loss:  0.919800/  2.889791, val:  64.17%, val_best:  70.00%, tr:  91.52%, tr_best:  91.52%\n",
      "epoch-38  lr=['0.0010000'], tr/val_loss:  0.884548/  3.289132, val:  62.50%, val_best:  70.00%, tr:  91.52%, tr_best:  91.52%\n",
      "epoch-39  lr=['0.0010000'], tr/val_loss:  0.912445/  3.193098, val:  63.33%, val_best:  70.00%, tr:  91.22%, tr_best:  91.52%\n",
      "epoch-40  lr=['0.0010000'], tr/val_loss:  0.910746/  3.172052, val:  65.00%, val_best:  70.00%, tr:  90.19%, tr_best:  91.52%\n",
      "epoch-41  lr=['0.0010000'], tr/val_loss:  0.913945/  3.414053, val:  60.00%, val_best:  70.00%, tr:  92.85%, tr_best:  92.85%\n",
      "epoch-42  lr=['0.0010000'], tr/val_loss:  0.868621/  3.295302, val:  68.75%, val_best:  70.00%, tr:  92.85%, tr_best:  92.85%\n",
      "epoch-43  lr=['0.0010000'], tr/val_loss:  0.881658/  3.571119, val:  63.33%, val_best:  70.00%, tr:  92.24%, tr_best:  92.85%\n",
      "epoch-44  lr=['0.0010000'], tr/val_loss:  0.833527/  3.471161, val:  65.83%, val_best:  70.00%, tr:  93.56%, tr_best:  93.56%\n",
      "epoch-45  lr=['0.0010000'], tr/val_loss:  0.856625/  3.679931, val:  65.00%, val_best:  70.00%, tr:  93.67%, tr_best:  93.67%\n",
      "epoch-46  lr=['0.0010000'], tr/val_loss:  0.830722/  3.818266, val:  67.92%, val_best:  70.00%, tr:  94.59%, tr_best:  94.59%\n",
      "epoch-47  lr=['0.0010000'], tr/val_loss:  0.803131/  4.066525, val:  63.33%, val_best:  70.00%, tr:  94.79%, tr_best:  94.79%\n",
      "epoch-48  lr=['0.0010000'], tr/val_loss:  0.885987/  4.139968, val:  63.75%, val_best:  70.00%, tr:  94.28%, tr_best:  94.79%\n",
      "epoch-49  lr=['0.0010000'], tr/val_loss:  0.848485/  4.313849, val:  64.17%, val_best:  70.00%, tr:  93.36%, tr_best:  94.79%\n",
      "epoch-50  lr=['0.0010000'], tr/val_loss:  0.824692/  4.196381, val:  66.67%, val_best:  70.00%, tr:  95.71%, tr_best:  95.71%\n",
      "epoch-51  lr=['0.0010000'], tr/val_loss:  0.805027/  4.313713, val:  69.58%, val_best:  70.00%, tr:  94.28%, tr_best:  95.71%\n",
      "epoch-52  lr=['0.0010000'], tr/val_loss:  0.761314/  4.462420, val:  61.25%, val_best:  70.00%, tr:  96.42%, tr_best:  96.42%\n",
      "epoch-53  lr=['0.0010000'], tr/val_loss:  0.777959/  4.571037, val:  63.75%, val_best:  70.00%, tr:  97.75%, tr_best:  97.75%\n",
      "epoch-54  lr=['0.0010000'], tr/val_loss:  0.802302/  4.706606, val:  67.08%, val_best:  70.00%, tr:  97.04%, tr_best:  97.75%\n",
      "epoch-55  lr=['0.0010000'], tr/val_loss:  0.780965/  4.956008, val:  62.08%, val_best:  70.00%, tr:  95.91%, tr_best:  97.75%\n",
      "epoch-56  lr=['0.0010000'], tr/val_loss:  0.814254/  5.033044, val:  60.00%, val_best:  70.00%, tr:  96.63%, tr_best:  97.75%\n",
      "epoch-57  lr=['0.0010000'], tr/val_loss:  0.831679/  5.065436, val:  65.00%, val_best:  70.00%, tr:  96.63%, tr_best:  97.75%\n",
      "epoch-58  lr=['0.0010000'], tr/val_loss:  0.776620/  5.545824, val:  56.25%, val_best:  70.00%, tr:  94.99%, tr_best:  97.75%\n",
      "epoch-59  lr=['0.0010000'], tr/val_loss:  0.778333/  5.414606, val:  63.33%, val_best:  70.00%, tr:  97.14%, tr_best:  97.75%\n",
      "epoch-60  lr=['0.0010000'], tr/val_loss:  0.765206/  5.232466, val:  63.75%, val_best:  70.00%, tr:  96.02%, tr_best:  97.75%\n",
      "epoch-61  lr=['0.0010000'], tr/val_loss:  0.840708/  5.645066, val:  62.92%, val_best:  70.00%, tr:  97.34%, tr_best:  97.75%\n",
      "epoch-62  lr=['0.0010000'], tr/val_loss:  0.791865/  5.185940, val:  66.67%, val_best:  70.00%, tr:  97.34%, tr_best:  97.75%\n",
      "epoch-63  lr=['0.0010000'], tr/val_loss:  0.738235/  5.504023, val:  60.83%, val_best:  70.00%, tr:  97.85%, tr_best:  97.85%\n",
      "epoch-64  lr=['0.0010000'], tr/val_loss:  0.756905/  5.575567, val:  61.25%, val_best:  70.00%, tr:  95.91%, tr_best:  97.85%\n",
      "epoch-65  lr=['0.0010000'], tr/val_loss:  0.711003/  5.852935, val:  63.75%, val_best:  70.00%, tr:  97.65%, tr_best:  97.85%\n",
      "epoch-66  lr=['0.0010000'], tr/val_loss:  0.703362/  5.521873, val:  63.75%, val_best:  70.00%, tr:  98.47%, tr_best:  98.47%\n",
      "epoch-67  lr=['0.0010000'], tr/val_loss:  0.754949/  5.695776, val:  64.58%, val_best:  70.00%, tr:  97.45%, tr_best:  98.47%\n",
      "epoch-68  lr=['0.0010000'], tr/val_loss:  0.715026/  5.879967, val:  61.67%, val_best:  70.00%, tr:  97.34%, tr_best:  98.47%\n",
      "epoch-69  lr=['0.0010000'], tr/val_loss:  0.780656/  6.028048, val:  63.33%, val_best:  70.00%, tr:  97.24%, tr_best:  98.47%\n",
      "epoch-70  lr=['0.0010000'], tr/val_loss:  0.700441/  5.754661, val:  67.50%, val_best:  70.00%, tr:  98.47%, tr_best:  98.47%\n",
      "epoch-71  lr=['0.0010000'], tr/val_loss:  0.729895/  6.073292, val:  62.92%, val_best:  70.00%, tr:  97.34%, tr_best:  98.47%\n",
      "epoch-72  lr=['0.0010000'], tr/val_loss:  0.727636/  6.084261, val:  61.67%, val_best:  70.00%, tr:  98.67%, tr_best:  98.67%\n",
      "epoch-73  lr=['0.0010000'], tr/val_loss:  0.725847/  6.686327, val:  57.50%, val_best:  70.00%, tr:  97.04%, tr_best:  98.67%\n",
      "epoch-74  lr=['0.0010000'], tr/val_loss:  0.653259/  6.122215, val:  60.83%, val_best:  70.00%, tr:  98.67%, tr_best:  98.67%\n",
      "epoch-75  lr=['0.0010000'], tr/val_loss:  0.685424/  6.553299, val:  60.00%, val_best:  70.00%, tr:  98.16%, tr_best:  98.67%\n",
      "epoch-76  lr=['0.0010000'], tr/val_loss:  0.685890/  6.503175, val:  60.00%, val_best:  70.00%, tr:  97.96%, tr_best:  98.67%\n",
      "epoch-77  lr=['0.0010000'], tr/val_loss:  0.737790/  6.496201, val:  61.67%, val_best:  70.00%, tr:  98.16%, tr_best:  98.67%\n",
      "epoch-78  lr=['0.0010000'], tr/val_loss:  0.709295/  6.628510, val:  60.42%, val_best:  70.00%, tr:  96.42%, tr_best:  98.67%\n",
      "epoch-79  lr=['0.0010000'], tr/val_loss:  0.716888/  6.314411, val:  62.08%, val_best:  70.00%, tr:  98.06%, tr_best:  98.67%\n",
      "epoch-80  lr=['0.0010000'], tr/val_loss:  0.672786/  6.382841, val:  59.58%, val_best:  70.00%, tr:  98.67%, tr_best:  98.67%\n",
      "epoch-81  lr=['0.0010000'], tr/val_loss:  0.623027/  6.508379, val:  62.92%, val_best:  70.00%, tr:  98.47%, tr_best:  98.67%\n",
      "epoch-82  lr=['0.0010000'], tr/val_loss:  0.567596/  6.492025, val:  60.42%, val_best:  70.00%, tr:  98.77%, tr_best:  98.77%\n",
      "epoch-83  lr=['0.0010000'], tr/val_loss:  0.630666/  6.672918, val:  61.25%, val_best:  70.00%, tr:  98.77%, tr_best:  98.77%\n",
      "epoch-84  lr=['0.0010000'], tr/val_loss:  0.615372/  6.293359, val:  66.67%, val_best:  70.00%, tr:  98.88%, tr_best:  98.88%\n",
      "epoch-85  lr=['0.0010000'], tr/val_loss:  0.586511/  6.658834, val:  62.92%, val_best:  70.00%, tr:  99.08%, tr_best:  99.08%\n",
      "epoch-86  lr=['0.0010000'], tr/val_loss:  0.576870/  6.460298, val:  63.33%, val_best:  70.00%, tr:  99.28%, tr_best:  99.28%\n",
      "epoch-87  lr=['0.0010000'], tr/val_loss:  0.553077/  6.445292, val:  65.42%, val_best:  70.00%, tr:  98.98%, tr_best:  99.28%\n",
      "epoch-88  lr=['0.0010000'], tr/val_loss:  0.566797/  6.489215, val:  68.33%, val_best:  70.00%, tr:  98.77%, tr_best:  99.28%\n",
      "epoch-89  lr=['0.0010000'], tr/val_loss:  0.609876/  6.699442, val:  62.92%, val_best:  70.00%, tr:  98.57%, tr_best:  99.28%\n",
      "epoch-90  lr=['0.0010000'], tr/val_loss:  0.549794/  6.963483, val:  62.08%, val_best:  70.00%, tr:  98.98%, tr_best:  99.28%\n",
      "epoch-91  lr=['0.0010000'], tr/val_loss:  0.590196/  7.006435, val:  57.50%, val_best:  70.00%, tr:  98.37%, tr_best:  99.28%\n",
      "epoch-92  lr=['0.0010000'], tr/val_loss:  0.520197/  6.631442, val:  65.00%, val_best:  70.00%, tr:  99.49%, tr_best:  99.49%\n",
      "epoch-93  lr=['0.0010000'], tr/val_loss:  0.583246/  6.888014, val:  63.75%, val_best:  70.00%, tr:  97.85%, tr_best:  99.49%\n",
      "epoch-94  lr=['0.0010000'], tr/val_loss:  0.492588/  6.953991, val:  62.50%, val_best:  70.00%, tr:  99.28%, tr_best:  99.49%\n",
      "epoch-95  lr=['0.0010000'], tr/val_loss:  0.475725/  7.254573, val:  59.58%, val_best:  70.00%, tr:  99.90%, tr_best:  99.90%\n",
      "epoch-96  lr=['0.0010000'], tr/val_loss:  0.504911/  6.759181, val:  63.33%, val_best:  70.00%, tr:  99.08%, tr_best:  99.90%\n",
      "epoch-97  lr=['0.0010000'], tr/val_loss:  0.490340/  6.960999, val:  62.08%, val_best:  70.00%, tr:  99.49%, tr_best:  99.90%\n",
      "epoch-98  lr=['0.0010000'], tr/val_loss:  0.504596/  7.130430, val:  62.92%, val_best:  70.00%, tr:  99.59%, tr_best:  99.90%\n",
      "epoch-99  lr=['0.0010000'], tr/val_loss:  0.508407/  7.027815, val:  62.50%, val_best:  70.00%, tr:  99.39%, tr_best:  99.90%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8f9903785a1a4a1c9595062df0977d28",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.006 MB of 0.006 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>iter_acc</td><td>▂▄▂▂▂▄▆▁▄▆▆█▅▆▆▇███▇██▆▇█▇██████████▇▇██</td></tr><tr><td>summary_val_acc</td><td>▁▅▅▆▇▇▆█▇▇▇█▇█▇▇▇█▇▇▇▇█▇▇▇▇▇█▇▇▇▇▇█▇▇▇▆▇</td></tr><tr><td>tr_acc</td><td>▁▄▄▅▅▆▆▆▆▆▆▆▇▇▇▇▇▇▇█▇███████████████████</td></tr><tr><td>tr_epoch_loss</td><td>█▆▅▄▄▄▄▃▃▃▃▃▃▃▃▃▃▃▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▁▂▁▂▁▁▁</td></tr><tr><td>val_acc_best</td><td>▁▅▅▆▇▇▇█████████████████████████████████</td></tr><tr><td>val_acc_now</td><td>▁▅▅▆▇▇▆█▇▇▇█▇█▇▇▇█▇▇▇▇█▇▇▇▇▇█▇▇▇▇▇█▇▇▇▆▇</td></tr><tr><td>val_loss</td><td>▂▁▁▁▁▁▁▁▁▁▂▂▂▂▃▃▃▃▃▄▄▅▅▅▆▆▆▆▆▇▇▇▇▇▇▇▇▇██</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>99</td></tr><tr><td>iter_acc</td><td>1.0</td></tr><tr><td>tr_acc</td><td>0.99387</td></tr><tr><td>tr_epoch_loss</td><td>0.50841</td></tr><tr><td>val_acc_best</td><td>0.7</td></tr><tr><td>val_acc_now</td><td>0.625</td></tr><tr><td>val_loss</td><td>7.02782</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">tough-sweep-114</strong> at: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/qjy0fjms' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/qjy0fjms</a><br/> View project at: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>/data2/bh_wandb/wandb/run-20250430_020108-qjy0fjms/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require(\"core\")`! See https://wandb.me/wandb-core for more information."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Sweep Agent: Waiting for job.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Job received.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: f5izzsh9 with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBATCH: 16\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBN_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBPTT_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tDFA_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tIMAGE_SIZE: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tOTTT_input_trace_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tTIME: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tUDA_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \talpha_uda: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbias: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcfg: ['M', 'M', 200, 200]\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tchaching_on: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tconvTrue_fcFalse: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdata_path: /data2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tddp_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdenoise_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdvs_clipping: 5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdvs_duration: 100000\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepoch_num: 100\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \texclude_class: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \textra_train_dataset: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlast_lif: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.01\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_sg_width: 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_decay: 0.5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_init: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_reset: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_threshold: 0.25\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmerge_polarities: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmy_seed: 42\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnet_print: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_workers: 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer_what: SGD\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tpin_memory: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tpre_trained: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tpre_trained_path: net_save/save_now_net_weights_{unique_name}.pth\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \trate_coding: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tscheduler_name: no\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsingle_step: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsurrogate: hard_sigmoid\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_conv_kernel_size: 3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_conv_padding: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_conv_stride: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_trace_const1: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_trace_const2: 0.5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \ttdBN_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \ttrace_on: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \twhich_data: DVS_GESTURE_TONIC\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.19.10 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.17.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/data2/bh_wandb/wandb/run-20250430_020731-f5izzsh9</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/f5izzsh9' target=\"_blank\">devout-sweep-118</a></strong> to <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/6pj3lh8j' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/6pj3lh8j</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/6pj3lh8j' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/6pj3lh8j</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/f5izzsh9' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/f5izzsh9</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'single_step' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'my_seed' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'TIME' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BATCH' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'IMAGE_SIZE' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'which_data' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'data_path' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'rate_coding' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_init' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_decay' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_threshold' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_reset' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_sg_width' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_conv_kernel_size' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_conv_stride' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_conv_padding' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_trace_const1' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_trace_const2' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'pre_trained' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'convTrue_fcFalse' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'cfg' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'net_print' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'pre_trained_path' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'learning_rate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'epoch_num' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'tdBN_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BN_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'surrogate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BPTT_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'optimizer_what' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'scheduler_name' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'ddp_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'dvs_clipping' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'dvs_duration' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'DFA_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'trace_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'OTTT_input_trace_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'exclude_class' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'merge_polarities' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'denoise_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'extra_train_dataset' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'num_workers' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'chaching_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'pin_memory' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'UDA_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'alpha_uda' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'bias' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'last_lif' was locked by 'sweep' (ignored update).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "param {'devices': '0', 'single_step': True, 'unique_name': 'main', 'my_seed': 42, 'TIME': 10, 'BATCH': 16, 'IMAGE_SIZE': 128, 'which_data': 'DVS_GESTURE_TONIC', 'data_path': '/data2', 'rate_coding': False, 'lif_layer_v_init': 0, 'lif_layer_v_decay': 0.5, 'lif_layer_v_threshold': 0.25, 'lif_layer_v_reset': 0, 'lif_layer_sg_width': 2, 'synapse_conv_kernel_size': 3, 'synapse_conv_stride': 1, 'synapse_conv_padding': 1, 'synapse_trace_const1': 1, 'synapse_trace_const2': 0.5, 'pre_trained': False, 'convTrue_fcFalse': False, 'cfg': ['M', 'M', 200, 200], 'net_print': True, 'pre_trained_path': 'net_save/save_now_net_weights_{unique_name}.pth', 'learning_rate': 0.01, 'epoch_num': 100, 'tdBN_on': False, 'BN_on': False, 'surrogate': 'hard_sigmoid', 'BPTT_on': False, 'optimizer_what': 'SGD', 'scheduler_name': 'no', 'ddp_on': False, 'dvs_clipping': 5, 'dvs_duration': 100000, 'DFA_on': False, 'trace_on': True, 'OTTT_input_trace_on': False, 'exclude_class': True, 'merge_polarities': False, 'denoise_on': False, 'extra_train_dataset': 0, 'num_workers': 2, 'chaching_on': True, 'pin_memory': True, 'UDA_on': False, 'alpha_uda': 1, 'bias': True, 'last_lif': False, 'current epoch': 0} \n",
      "\n",
      "dataset_hash = ffa516e60c3efd5e0208f72b4c36cb84\n",
      "cache path exists\n",
      "\n",
      "device ==> cuda\n",
      "\n",
      "DataParallel(\n",
      "  (module): REBORN_MY_SNN_FC(\n",
      "    (layers): REBORN_MY_Sequential(\n",
      "      (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (2): DimChanger_for_FC()\n",
      "      (3): SYNAPSE_FC(in_features=2048, out_features=200, TIME=10, bias=True, sstep=True)\n",
      "      (4): LIF_layer(v_init=0, v_decay=0.5, v_threshold=0.25, v_reset=0, sg_width=2, surrogate=hard_sigmoid, BPTT_on=False, trace_const1=1, trace_const2=0.5, TIME=10, sstep=True, trace_on=True)\n",
      "      (5): SYNAPSE_FC(in_features=200, out_features=200, TIME=10, bias=True, sstep=True)\n",
      "      (6): LIF_layer(v_init=0, v_decay=0.5, v_threshold=0.25, v_reset=0, sg_width=2, surrogate=hard_sigmoid, BPTT_on=False, trace_const1=1, trace_const2=0.5, TIME=10, sstep=True, trace_on=True)\n",
      "      (7): SYNAPSE_FC(in_features=200, out_features=10, TIME=10, bias=True, sstep=True)\n",
      "    )\n",
      "  )\n",
      ")\n",
      "\n",
      "========================================================\n",
      "Trainable parameters: 452,010\n",
      "========================================================\n",
      "\n",
      "epoch-0   lr=['0.0100000'], tr/val_loss:  1.749429/  1.742278, val:  48.75%, val_best:  48.75%, tr:  43.00%, tr_best:  43.00%\n",
      "epoch-1   lr=['0.0100000'], tr/val_loss:  1.302975/  1.404911, val:  52.92%, val_best:  52.92%, tr:  54.55%, tr_best:  54.55%\n",
      "epoch-2   lr=['0.0100000'], tr/val_loss:  1.095799/  1.347973, val:  57.92%, val_best:  57.92%, tr:  61.29%, tr_best:  61.29%\n",
      "epoch-3   lr=['0.0100000'], tr/val_loss:  0.880930/  1.489801, val:  55.00%, val_best:  57.92%, tr:  70.68%, tr_best:  70.68%\n",
      "epoch-4   lr=['0.0100000'], tr/val_loss:  0.795188/  1.384180, val:  64.58%, val_best:  64.58%, tr:  72.01%, tr_best:  72.01%\n",
      "epoch-5   lr=['0.0100000'], tr/val_loss:  0.691093/  1.850020, val:  53.33%, val_best:  64.58%, tr:  76.40%, tr_best:  76.40%\n",
      "epoch-6   lr=['0.0100000'], tr/val_loss:  0.665387/  1.399048, val:  63.75%, val_best:  64.58%, tr:  80.59%, tr_best:  80.59%\n",
      "epoch-7   lr=['0.0100000'], tr/val_loss:  0.660881/  1.626665, val:  60.00%, val_best:  64.58%, tr:  78.65%, tr_best:  80.59%\n",
      "epoch-8   lr=['0.0100000'], tr/val_loss:  0.523379/  1.619302, val:  65.83%, val_best:  65.83%, tr:  85.70%, tr_best:  85.70%\n",
      "epoch-9   lr=['0.0100000'], tr/val_loss:  0.427760/  1.688188, val:  63.75%, val_best:  65.83%, tr:  89.17%, tr_best:  89.17%\n",
      "epoch-10  lr=['0.0100000'], tr/val_loss:  0.452001/  1.667441, val:  72.08%, val_best:  72.08%, tr:  88.25%, tr_best:  89.17%\n",
      "epoch-11  lr=['0.0100000'], tr/val_loss:  0.381503/  1.934497, val:  71.25%, val_best:  72.08%, tr:  93.16%, tr_best:  93.16%\n",
      "epoch-12  lr=['0.0100000'], tr/val_loss:  0.287527/  1.931777, val:  75.42%, val_best:  75.42%, tr:  95.51%, tr_best:  95.51%\n",
      "epoch-13  lr=['0.0100000'], tr/val_loss:  0.238011/  1.772376, val:  74.58%, val_best:  75.42%, tr:  96.32%, tr_best:  96.32%\n",
      "epoch-14  lr=['0.0100000'], tr/val_loss:  0.273433/  2.279626, val:  75.00%, val_best:  75.42%, tr:  95.10%, tr_best:  96.32%\n",
      "epoch-15  lr=['0.0100000'], tr/val_loss:  0.225479/  2.360325, val:  66.67%, val_best:  75.42%, tr:  97.55%, tr_best:  97.55%\n",
      "epoch-16  lr=['0.0100000'], tr/val_loss:  0.147998/  2.279440, val:  74.58%, val_best:  75.42%, tr:  99.39%, tr_best:  99.39%\n",
      "epoch-17  lr=['0.0100000'], tr/val_loss:  0.130909/  2.500595, val:  70.83%, val_best:  75.42%, tr:  98.77%, tr_best:  99.39%\n",
      "epoch-18  lr=['0.0100000'], tr/val_loss:  0.087847/  2.719101, val:  72.92%, val_best:  75.42%, tr:  99.69%, tr_best:  99.69%\n",
      "epoch-19  lr=['0.0100000'], tr/val_loss:  0.146650/  2.810777, val:  71.25%, val_best:  75.42%, tr:  98.98%, tr_best:  99.69%\n",
      "epoch-20  lr=['0.0100000'], tr/val_loss:  0.137752/  2.802755, val:  68.75%, val_best:  75.42%, tr:  98.98%, tr_best:  99.69%\n",
      "epoch-21  lr=['0.0100000'], tr/val_loss:  0.124416/  3.301240, val:  63.33%, val_best:  75.42%, tr:  99.69%, tr_best:  99.69%\n",
      "epoch-22  lr=['0.0100000'], tr/val_loss:  0.069569/  3.141766, val:  71.25%, val_best:  75.42%, tr:  99.80%, tr_best:  99.80%\n",
      "epoch-23  lr=['0.0100000'], tr/val_loss:  0.089961/  3.152775, val:  71.67%, val_best:  75.42%, tr:  99.69%, tr_best:  99.80%\n",
      "epoch-24  lr=['0.0100000'], tr/val_loss:  0.140333/  2.775398, val:  75.83%, val_best:  75.83%, tr:  98.77%, tr_best:  99.80%\n",
      "epoch-25  lr=['0.0100000'], tr/val_loss:  0.137799/  3.143956, val:  68.33%, val_best:  75.83%, tr:  99.08%, tr_best:  99.80%\n",
      "epoch-26  lr=['0.0100000'], tr/val_loss:  0.066443/  2.901955, val:  73.75%, val_best:  75.83%, tr:  99.59%, tr_best:  99.80%\n",
      "epoch-27  lr=['0.0100000'], tr/val_loss:  0.043765/  2.957913, val:  75.83%, val_best:  75.83%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-28  lr=['0.0100000'], tr/val_loss:  0.031820/  2.913592, val:  76.25%, val_best:  76.25%, tr:  99.80%, tr_best: 100.00%\n",
      "epoch-29  lr=['0.0100000'], tr/val_loss:  0.028484/  2.936568, val:  71.67%, val_best:  76.25%, tr:  99.90%, tr_best: 100.00%\n",
      "epoch-30  lr=['0.0100000'], tr/val_loss:  0.016399/  3.334008, val:  76.25%, val_best:  76.25%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-31  lr=['0.0100000'], tr/val_loss:  0.008898/  3.140313, val:  78.33%, val_best:  78.33%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-32  lr=['0.0100000'], tr/val_loss:  0.006084/  3.139298, val:  76.67%, val_best:  78.33%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-33  lr=['0.0100000'], tr/val_loss:  0.023129/  3.205623, val:  72.92%, val_best:  78.33%, tr:  99.90%, tr_best: 100.00%\n",
      "epoch-34  lr=['0.0100000'], tr/val_loss:  0.092692/  3.078316, val:  75.83%, val_best:  78.33%, tr:  98.88%, tr_best: 100.00%\n",
      "epoch-35  lr=['0.0100000'], tr/val_loss:  0.056764/  3.147384, val:  74.58%, val_best:  78.33%, tr:  99.59%, tr_best: 100.00%\n",
      "epoch-36  lr=['0.0100000'], tr/val_loss:  0.028725/  3.012439, val:  78.33%, val_best:  78.33%, tr:  99.90%, tr_best: 100.00%\n",
      "epoch-37  lr=['0.0100000'], tr/val_loss:  0.011924/  3.200828, val:  77.08%, val_best:  78.33%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-38  lr=['0.0100000'], tr/val_loss:  0.007115/  3.269419, val:  76.67%, val_best:  78.33%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-39  lr=['0.0100000'], tr/val_loss:  0.010091/  3.188070, val:  77.08%, val_best:  78.33%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-40  lr=['0.0100000'], tr/val_loss:  0.004198/  3.190061, val:  76.67%, val_best:  78.33%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-41  lr=['0.0100000'], tr/val_loss:  0.006482/  3.219351, val:  76.67%, val_best:  78.33%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-42  lr=['0.0100000'], tr/val_loss:  0.007501/  3.327060, val:  76.25%, val_best:  78.33%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-43  lr=['0.0100000'], tr/val_loss:  0.005211/  3.300015, val:  77.08%, val_best:  78.33%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-44  lr=['0.0100000'], tr/val_loss:  0.004271/  3.240563, val:  78.33%, val_best:  78.33%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-45  lr=['0.0100000'], tr/val_loss:  0.027784/  3.239513, val:  75.42%, val_best:  78.33%, tr:  99.90%, tr_best: 100.00%\n",
      "epoch-46  lr=['0.0100000'], tr/val_loss:  0.015649/  3.038201, val:  75.42%, val_best:  78.33%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-47  lr=['0.0100000'], tr/val_loss:  0.004078/  3.269921, val:  76.25%, val_best:  78.33%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-48  lr=['0.0100000'], tr/val_loss:  0.002630/  3.174805, val:  78.75%, val_best:  78.75%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-49  lr=['0.0100000'], tr/val_loss:  0.000637/  3.179655, val:  79.58%, val_best:  79.58%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-50  lr=['0.0100000'], tr/val_loss:  0.000243/  3.183156, val:  78.75%, val_best:  79.58%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-51  lr=['0.0100000'], tr/val_loss:  0.000142/  3.197886, val:  78.75%, val_best:  79.58%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-52  lr=['0.0100000'], tr/val_loss:  0.000117/  3.194259, val:  79.17%, val_best:  79.58%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-53  lr=['0.0100000'], tr/val_loss:  0.000098/  3.192825, val:  79.17%, val_best:  79.58%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-54  lr=['0.0100000'], tr/val_loss:  0.000098/  3.179984, val:  79.58%, val_best:  79.58%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-55  lr=['0.0100000'], tr/val_loss:  0.000088/  3.200745, val:  79.17%, val_best:  79.58%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-56  lr=['0.0100000'], tr/val_loss:  0.000080/  3.208452, val:  78.75%, val_best:  79.58%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-57  lr=['0.0100000'], tr/val_loss:  0.000079/  3.214950, val:  78.75%, val_best:  79.58%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-58  lr=['0.0100000'], tr/val_loss:  0.000093/  3.212770, val:  78.75%, val_best:  79.58%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-59  lr=['0.0100000'], tr/val_loss:  0.000076/  3.229582, val:  77.50%, val_best:  79.58%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-60  lr=['0.0100000'], tr/val_loss:  0.000064/  3.224984, val:  77.92%, val_best:  79.58%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-61  lr=['0.0100000'], tr/val_loss:  0.000067/  3.223208, val:  78.33%, val_best:  79.58%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-62  lr=['0.0100000'], tr/val_loss:  0.000065/  3.218737, val:  78.33%, val_best:  79.58%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-63  lr=['0.0100000'], tr/val_loss:  0.000067/  3.201234, val:  78.33%, val_best:  79.58%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-64  lr=['0.0100000'], tr/val_loss:  0.000058/  3.202193, val:  77.50%, val_best:  79.58%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-65  lr=['0.0100000'], tr/val_loss:  0.000055/  3.207873, val:  77.08%, val_best:  79.58%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-66  lr=['0.0100000'], tr/val_loss:  0.000088/  3.198244, val:  77.50%, val_best:  79.58%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-67  lr=['0.0100000'], tr/val_loss:  0.000071/  3.200132, val:  78.33%, val_best:  79.58%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-68  lr=['0.0100000'], tr/val_loss:  0.000060/  3.220884, val:  78.33%, val_best:  79.58%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-69  lr=['0.0100000'], tr/val_loss:  0.000054/  3.222614, val:  78.33%, val_best:  79.58%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-70  lr=['0.0100000'], tr/val_loss:  0.000059/  3.216274, val:  78.33%, val_best:  79.58%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-71  lr=['0.0100000'], tr/val_loss:  0.000055/  3.226660, val:  78.33%, val_best:  79.58%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-72  lr=['0.0100000'], tr/val_loss:  0.000490/  3.255082, val:  78.33%, val_best:  79.58%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-73  lr=['0.0100000'], tr/val_loss:  0.000343/  3.309628, val:  78.75%, val_best:  79.58%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-74  lr=['0.0100000'], tr/val_loss:  0.000586/  3.332840, val:  77.50%, val_best:  79.58%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-75  lr=['0.0100000'], tr/val_loss:  0.000188/  3.340690, val:  79.58%, val_best:  79.58%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-76  lr=['0.0100000'], tr/val_loss:  0.000057/  3.334980, val:  79.58%, val_best:  79.58%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-77  lr=['0.0100000'], tr/val_loss:  0.000055/  3.328644, val:  79.58%, val_best:  79.58%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-78  lr=['0.0100000'], tr/val_loss:  0.000056/  3.331770, val:  79.58%, val_best:  79.58%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-79  lr=['0.0100000'], tr/val_loss:  0.000046/  3.328826, val:  79.58%, val_best:  79.58%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-80  lr=['0.0100000'], tr/val_loss:  0.000041/  3.330880, val:  79.58%, val_best:  79.58%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-81  lr=['0.0100000'], tr/val_loss:  0.000042/  3.335266, val:  79.58%, val_best:  79.58%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-82  lr=['0.0100000'], tr/val_loss:  0.000042/  3.336724, val:  79.58%, val_best:  79.58%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-83  lr=['0.0100000'], tr/val_loss:  0.000046/  3.340612, val:  79.58%, val_best:  79.58%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-84  lr=['0.0100000'], tr/val_loss:  0.000045/  3.350761, val:  79.58%, val_best:  79.58%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-85  lr=['0.0100000'], tr/val_loss:  0.000040/  3.351210, val:  79.58%, val_best:  79.58%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-86  lr=['0.0100000'], tr/val_loss:  0.000038/  3.351877, val:  79.58%, val_best:  79.58%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-87  lr=['0.0100000'], tr/val_loss:  0.000037/  3.350006, val:  79.58%, val_best:  79.58%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-88  lr=['0.0100000'], tr/val_loss:  0.000037/  3.347502, val:  79.58%, val_best:  79.58%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-89  lr=['0.0100000'], tr/val_loss:  0.000037/  3.345271, val:  79.58%, val_best:  79.58%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-90  lr=['0.0100000'], tr/val_loss:  0.000036/  3.353230, val:  79.58%, val_best:  79.58%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-91  lr=['0.0100000'], tr/val_loss:  0.000036/  3.358939, val:  79.58%, val_best:  79.58%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-92  lr=['0.0100000'], tr/val_loss:  0.000036/  3.357334, val:  79.58%, val_best:  79.58%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-93  lr=['0.0100000'], tr/val_loss:  0.000035/  3.366674, val:  79.58%, val_best:  79.58%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-94  lr=['0.0100000'], tr/val_loss:  0.000034/  3.367935, val:  79.58%, val_best:  79.58%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-95  lr=['0.0100000'], tr/val_loss:  0.000034/  3.361693, val:  79.58%, val_best:  79.58%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-96  lr=['0.0100000'], tr/val_loss:  0.000033/  3.378838, val:  79.58%, val_best:  79.58%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-97  lr=['0.0100000'], tr/val_loss:  0.000033/  3.387870, val:  79.58%, val_best:  79.58%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-98  lr=['0.0100000'], tr/val_loss:  0.000034/  3.391788, val:  79.58%, val_best:  79.58%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-99  lr=['0.0100000'], tr/val_loss:  0.000031/  3.395147, val:  79.58%, val_best:  79.58%, tr: 100.00%, tr_best: 100.00%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8901fe5c513749798a0c7a45ec5e3d03",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.006 MB of 0.006 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>iter_acc</td><td>▁▆▅▇▆▅██████████████████████████████████</td></tr><tr><td>summary_val_acc</td><td>▁▃▅▄▄▇▇▆▆▄▇▇▆▇▇▇▇▇█▇██████▇█████████████</td></tr><tr><td>tr_acc</td><td>▁▃▅▅▇▇▇█████████████████████████████████</td></tr><tr><td>tr_epoch_loss</td><td>█▅▄▄▃▂▂▂▂▁▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_acc_best</td><td>▁▃▅▅▅▇▇▇▇▇▇▇▇███████████████████████████</td></tr><tr><td>val_acc_now</td><td>▁▃▅▄▄▇▇▆▆▄▇▇▆▇▇▇▇▇█▇██████▇█████████████</td></tr><tr><td>val_loss</td><td>▂▁▁▂▂▃▄▅▆█▆▆▆▇▇▇▇█▇█▇▇▇▇▇▇▇▇▇███████████</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>99</td></tr><tr><td>iter_acc</td><td>1.0</td></tr><tr><td>tr_acc</td><td>1.0</td></tr><tr><td>tr_epoch_loss</td><td>3e-05</td></tr><tr><td>val_acc_best</td><td>0.79583</td></tr><tr><td>val_acc_now</td><td>0.79583</td></tr><tr><td>val_loss</td><td>3.39515</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">devout-sweep-118</strong> at: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/f5izzsh9' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/f5izzsh9</a><br/> View project at: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>/data2/bh_wandb/wandb/run-20250430_020731-f5izzsh9/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require(\"core\")`! See https://wandb.me/wandb-core for more information."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 9g35j62p with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBATCH: 16\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBN_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBPTT_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tDFA_on: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tIMAGE_SIZE: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tOTTT_input_trace_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tTIME: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tUDA_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \talpha_uda: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbias: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcfg: ['M', 'M', 200, 200]\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tchaching_on: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tconvTrue_fcFalse: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdata_path: /data2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tddp_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdenoise_on: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdvs_clipping: 5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdvs_duration: 100000\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepoch_num: 100\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \texclude_class: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \textra_train_dataset: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlast_lif: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_sg_width: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_decay: 0.5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_init: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_reset: 10000\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_threshold: 0.25\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmerge_polarities: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmy_seed: 42\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnet_print: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_workers: 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer_what: SGD\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tpin_memory: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tpre_trained: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tpre_trained_path: net_save/save_now_net_weights_{unique_name}.pth\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \trate_coding: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tscheduler_name: no\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsingle_step: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsurrogate: hard_sigmoid\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_conv_kernel_size: 3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_conv_padding: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_conv_stride: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_trace_const1: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_trace_const2: 0.5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \ttdBN_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \ttrace_on: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \twhich_data: DVS_GESTURE_TONIC\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "536f779a840d4327abed5da49e84b83c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.011112725791624851, max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.19.10 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.17.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/data2/bh_wandb/wandb/run-20250430_021340-9g35j62p</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/9g35j62p' target=\"_blank\">frosty-sweep-122</a></strong> to <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/6pj3lh8j' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/6pj3lh8j</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/6pj3lh8j' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/6pj3lh8j</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/9g35j62p' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/9g35j62p</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'single_step' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'my_seed' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'TIME' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BATCH' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'IMAGE_SIZE' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'which_data' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'data_path' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'rate_coding' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_init' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_decay' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_threshold' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_reset' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_sg_width' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_conv_kernel_size' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_conv_stride' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_conv_padding' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_trace_const1' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_trace_const2' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'pre_trained' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'convTrue_fcFalse' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'cfg' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'net_print' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'pre_trained_path' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'learning_rate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'epoch_num' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'tdBN_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BN_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'surrogate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BPTT_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'optimizer_what' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'scheduler_name' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'ddp_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'dvs_clipping' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'dvs_duration' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'DFA_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'trace_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'OTTT_input_trace_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'exclude_class' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'merge_polarities' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'denoise_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'extra_train_dataset' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'num_workers' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'chaching_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'pin_memory' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'UDA_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'alpha_uda' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'bias' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'last_lif' was locked by 'sweep' (ignored update).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "param {'devices': '0', 'single_step': True, 'unique_name': 'main', 'my_seed': 42, 'TIME': 10, 'BATCH': 16, 'IMAGE_SIZE': 128, 'which_data': 'DVS_GESTURE_TONIC', 'data_path': '/data2', 'rate_coding': False, 'lif_layer_v_init': 0, 'lif_layer_v_decay': 0.5, 'lif_layer_v_threshold': 0.25, 'lif_layer_v_reset': 10000, 'lif_layer_sg_width': 1, 'synapse_conv_kernel_size': 3, 'synapse_conv_stride': 1, 'synapse_conv_padding': 1, 'synapse_trace_const1': 1, 'synapse_trace_const2': 0.5, 'pre_trained': False, 'convTrue_fcFalse': False, 'cfg': ['M', 'M', 200, 200], 'net_print': True, 'pre_trained_path': 'net_save/save_now_net_weights_{unique_name}.pth', 'learning_rate': 0.1, 'epoch_num': 100, 'tdBN_on': False, 'BN_on': False, 'surrogate': 'hard_sigmoid', 'BPTT_on': False, 'optimizer_what': 'SGD', 'scheduler_name': 'no', 'ddp_on': False, 'dvs_clipping': 5, 'dvs_duration': 100000, 'DFA_on': True, 'trace_on': True, 'OTTT_input_trace_on': False, 'exclude_class': True, 'merge_polarities': False, 'denoise_on': True, 'extra_train_dataset': 0, 'num_workers': 2, 'chaching_on': True, 'pin_memory': True, 'UDA_on': False, 'alpha_uda': 1, 'bias': True, 'last_lif': False, 'current epoch': 0} \n",
      "\n",
      "dataset_hash = 63cc597115630ec173f3099200061e53\n",
      "cache path exists\n",
      "\n",
      "device ==> cuda\n",
      "\n",
      "DataParallel(\n",
      "  (module): REBORN_MY_SNN_FC(\n",
      "    (layers): REBORN_MY_Sequential(\n",
      "      (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (2): DimChanger_for_FC()\n",
      "      (3): SYNAPSE_FC(in_features=2048, out_features=200, TIME=10, bias=True, sstep=True)\n",
      "      (4): LIF_layer(v_init=0, v_decay=0.5, v_threshold=0.25, v_reset=10000, sg_width=1, surrogate=hard_sigmoid, BPTT_on=False, trace_const1=1, trace_const2=0.5, TIME=10, sstep=True, trace_on=True)\n",
      "      (5): Feedback_Receiver()\n",
      "      (6): SYNAPSE_FC(in_features=200, out_features=200, TIME=10, bias=True, sstep=True)\n",
      "      (7): LIF_layer(v_init=0, v_decay=0.5, v_threshold=0.25, v_reset=10000, sg_width=1, surrogate=hard_sigmoid, BPTT_on=False, trace_const1=1, trace_const2=0.5, TIME=10, sstep=True, trace_on=True)\n",
      "      (8): Feedback_Receiver()\n",
      "      (9): SYNAPSE_FC(in_features=200, out_features=10, TIME=10, bias=True, sstep=True)\n",
      "      (DFA_top): Top_Gradient()\n",
      "    )\n",
      "  )\n",
      ")\n",
      "\n",
      "========================================================\n",
      "Trainable parameters: 452,010\n",
      "========================================================\n",
      "\n",
      "epoch-0   lr=['0.1000000'], tr/val_loss: 40.985443/ 45.449806, val:  33.75%, val_best:  33.75%, tr:  30.03%, tr_best:  30.03%\n",
      "[module.layers.5] weight_fb parameter count: 2,000\n",
      "[module.layers.8] weight_fb parameter count: 2,000\n",
      "epoch-1   lr=['0.1000000'], tr/val_loss: 37.378090/ 42.210899, val:  49.17%, val_best:  49.17%, tr:  46.27%, tr_best:  46.27%\n",
      "epoch-2   lr=['0.1000000'], tr/val_loss: 34.025597/ 39.623707, val:  52.50%, val_best:  52.50%, tr:  53.12%, tr_best:  53.12%\n",
      "epoch-3   lr=['0.1000000'], tr/val_loss: 26.409613/ 30.285070, val:  53.75%, val_best:  53.75%, tr:  56.89%, tr_best:  56.89%\n",
      "epoch-4   lr=['0.1000000'], tr/val_loss: 23.354471/ 23.340433, val:  50.42%, val_best:  53.75%, tr:  61.49%, tr_best:  61.49%\n",
      "epoch-5   lr=['0.1000000'], tr/val_loss: 20.813431/ 42.986923, val:  45.42%, val_best:  53.75%, tr:  66.09%, tr_best:  66.09%\n",
      "epoch-6   lr=['0.1000000'], tr/val_loss: 22.130190/ 25.238939, val:  60.00%, val_best:  60.00%, tr:  68.03%, tr_best:  68.03%\n",
      "epoch-7   lr=['0.1000000'], tr/val_loss: 14.636162/ 40.822887, val:  46.25%, val_best:  60.00%, tr:  70.48%, tr_best:  70.48%\n",
      "epoch-8   lr=['0.1000000'], tr/val_loss: 14.425724/ 28.187872, val:  57.92%, val_best:  60.00%, tr:  74.46%, tr_best:  74.46%\n",
      "epoch-9   lr=['0.1000000'], tr/val_loss: 22.010883/ 49.985035, val:  51.67%, val_best:  60.00%, tr:  73.75%, tr_best:  74.46%\n",
      "epoch-10  lr=['0.1000000'], tr/val_loss: 19.581341/ 30.762058, val:  63.75%, val_best:  63.75%, tr:  78.65%, tr_best:  78.65%\n",
      "epoch-11  lr=['0.1000000'], tr/val_loss: 12.676733/ 41.558533, val:  55.00%, val_best:  63.75%, tr:  84.58%, tr_best:  84.58%\n",
      "epoch-12  lr=['0.1000000'], tr/val_loss: 13.339148/ 31.992613, val:  65.83%, val_best:  65.83%, tr:  85.09%, tr_best:  85.09%\n",
      "epoch-13  lr=['0.1000000'], tr/val_loss:  9.300929/ 34.632298, val:  65.83%, val_best:  65.83%, tr:  91.73%, tr_best:  91.73%\n",
      "epoch-14  lr=['0.1000000'], tr/val_loss: 11.145024/ 49.436676, val:  58.75%, val_best:  65.83%, tr:  89.48%, tr_best:  91.73%\n",
      "epoch-15  lr=['0.1000000'], tr/val_loss:  8.682887/ 39.061527, val:  67.50%, val_best:  67.50%, tr:  92.44%, tr_best:  92.44%\n",
      "epoch-16  lr=['0.1000000'], tr/val_loss:  8.326821/ 35.669716, val:  71.25%, val_best:  71.25%, tr:  94.18%, tr_best:  94.18%\n",
      "epoch-17  lr=['0.1000000'], tr/val_loss:  5.229808/ 36.349331, val:  73.33%, val_best:  73.33%, tr:  97.24%, tr_best:  97.24%\n",
      "epoch-18  lr=['0.1000000'], tr/val_loss:  5.343487/ 48.078636, val:  70.00%, val_best:  73.33%, tr:  97.04%, tr_best:  97.24%\n",
      "epoch-19  lr=['0.1000000'], tr/val_loss:  6.356637/ 37.711857, val:  75.00%, val_best:  75.00%, tr:  96.83%, tr_best:  97.24%\n",
      "epoch-20  lr=['0.1000000'], tr/val_loss:  4.050844/ 44.212097, val:  71.25%, val_best:  75.00%, tr:  98.47%, tr_best:  98.47%\n",
      "epoch-21  lr=['0.1000000'], tr/val_loss:  4.268899/ 43.957783, val:  72.50%, val_best:  75.00%, tr:  98.77%, tr_best:  98.77%\n",
      "epoch-22  lr=['0.1000000'], tr/val_loss:  2.967220/ 42.850708, val:  75.00%, val_best:  75.00%, tr:  99.18%, tr_best:  99.18%\n",
      "epoch-23  lr=['0.1000000'], tr/val_loss:  3.070831/ 42.658844, val:  76.25%, val_best:  76.25%, tr:  99.18%, tr_best:  99.18%\n",
      "epoch-24  lr=['0.1000000'], tr/val_loss:  2.249188/ 45.774029, val:  74.58%, val_best:  76.25%, tr:  99.80%, tr_best:  99.80%\n",
      "epoch-25  lr=['0.1000000'], tr/val_loss:  1.985772/ 42.719006, val:  77.08%, val_best:  77.08%, tr:  99.90%, tr_best:  99.90%\n",
      "epoch-26  lr=['0.1000000'], tr/val_loss:  2.278408/ 46.928074, val:  72.50%, val_best:  77.08%, tr:  99.80%, tr_best:  99.90%\n",
      "epoch-27  lr=['0.1000000'], tr/val_loss:  2.124462/ 49.079998, val:  76.25%, val_best:  77.08%, tr:  99.59%, tr_best:  99.90%\n",
      "epoch-28  lr=['0.1000000'], tr/val_loss:  1.749886/ 50.477028, val:  70.00%, val_best:  77.08%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-29  lr=['0.1000000'], tr/val_loss:  1.126847/ 52.242664, val:  72.50%, val_best:  77.08%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-30  lr=['0.1000000'], tr/val_loss:  0.985245/ 48.637768, val:  75.42%, val_best:  77.08%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-31  lr=['0.1000000'], tr/val_loss:  0.945000/ 52.514706, val:  74.58%, val_best:  77.08%, tr:  99.90%, tr_best: 100.00%\n",
      "epoch-32  lr=['0.1000000'], tr/val_loss:  0.900738/ 51.082081, val:  75.83%, val_best:  77.08%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-33  lr=['0.1000000'], tr/val_loss:  0.828196/ 55.274700, val:  73.33%, val_best:  77.08%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-34  lr=['0.1000000'], tr/val_loss:  0.770507/ 51.009613, val:  77.08%, val_best:  77.08%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-35  lr=['0.1000000'], tr/val_loss:  0.940019/ 53.883587, val:  74.17%, val_best:  77.08%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-36  lr=['0.1000000'], tr/val_loss:  0.571853/ 51.471596, val:  76.25%, val_best:  77.08%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-37  lr=['0.1000000'], tr/val_loss:  0.574043/ 52.763706, val:  75.42%, val_best:  77.08%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-38  lr=['0.1000000'], tr/val_loss:  0.582993/ 52.750763, val:  78.75%, val_best:  78.75%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-39  lr=['0.1000000'], tr/val_loss:  0.558584/ 56.316662, val:  75.42%, val_best:  78.75%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-40  lr=['0.1000000'], tr/val_loss:  0.717869/ 53.864506, val:  78.75%, val_best:  78.75%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-41  lr=['0.1000000'], tr/val_loss:  0.479977/ 53.678200, val:  79.58%, val_best:  79.58%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-42  lr=['0.1000000'], tr/val_loss:  0.360306/ 55.838326, val:  77.08%, val_best:  79.58%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-43  lr=['0.1000000'], tr/val_loss:  0.348320/ 53.159714, val:  80.42%, val_best:  80.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-44  lr=['0.1000000'], tr/val_loss:  0.354831/ 53.762962, val:  77.08%, val_best:  80.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-45  lr=['0.1000000'], tr/val_loss:  0.411519/ 55.615097, val:  76.25%, val_best:  80.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-46  lr=['0.1000000'], tr/val_loss:  0.289053/ 55.440277, val:  78.33%, val_best:  80.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-47  lr=['0.1000000'], tr/val_loss:  0.306648/ 55.274857, val:  76.25%, val_best:  80.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-48  lr=['0.1000000'], tr/val_loss:  0.264412/ 55.274990, val:  79.58%, val_best:  80.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-49  lr=['0.1000000'], tr/val_loss:  0.214195/ 55.936798, val:  77.92%, val_best:  80.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-50  lr=['0.1000000'], tr/val_loss:  0.209417/ 57.391632, val:  75.42%, val_best:  80.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-51  lr=['0.1000000'], tr/val_loss:  0.208887/ 56.782536, val:  77.50%, val_best:  80.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-52  lr=['0.1000000'], tr/val_loss:  0.151953/ 57.416492, val:  76.25%, val_best:  80.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-53  lr=['0.1000000'], tr/val_loss:  0.197132/ 56.119061, val:  76.67%, val_best:  80.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-54  lr=['0.1000000'], tr/val_loss:  0.199519/ 58.510021, val:  76.67%, val_best:  80.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-55  lr=['0.1000000'], tr/val_loss:  0.163852/ 58.016281, val:  76.67%, val_best:  80.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-56  lr=['0.1000000'], tr/val_loss:  0.294139/ 58.394550, val:  75.42%, val_best:  80.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-57  lr=['0.1000000'], tr/val_loss:  0.215025/ 58.873913, val:  75.83%, val_best:  80.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-58  lr=['0.1000000'], tr/val_loss:  0.175754/ 59.179077, val:  76.67%, val_best:  80.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-59  lr=['0.1000000'], tr/val_loss:  0.158252/ 58.712090, val:  77.08%, val_best:  80.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-60  lr=['0.1000000'], tr/val_loss:  0.104707/ 61.751366, val:  75.42%, val_best:  80.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-61  lr=['0.1000000'], tr/val_loss:  0.099385/ 58.634464, val:  75.83%, val_best:  80.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-62  lr=['0.1000000'], tr/val_loss:  0.090762/ 58.334858, val:  75.83%, val_best:  80.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-63  lr=['0.1000000'], tr/val_loss:  0.134787/ 58.043331, val:  76.67%, val_best:  80.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-64  lr=['0.1000000'], tr/val_loss:  0.223649/ 59.016827, val:  75.83%, val_best:  80.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-65  lr=['0.1000000'], tr/val_loss:  0.215340/ 57.978683, val:  77.92%, val_best:  80.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-66  lr=['0.1000000'], tr/val_loss:  0.118934/ 59.379940, val:  76.67%, val_best:  80.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-67  lr=['0.1000000'], tr/val_loss:  0.078003/ 59.674091, val:  77.08%, val_best:  80.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-68  lr=['0.1000000'], tr/val_loss:  0.074112/ 57.796425, val:  77.08%, val_best:  80.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-69  lr=['0.1000000'], tr/val_loss:  0.069598/ 58.480042, val:  75.42%, val_best:  80.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-70  lr=['0.1000000'], tr/val_loss:  0.048269/ 58.967537, val:  77.92%, val_best:  80.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-71  lr=['0.1000000'], tr/val_loss:  0.032444/ 59.934734, val:  76.67%, val_best:  80.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-72  lr=['0.1000000'], tr/val_loss:  0.071812/ 59.340427, val:  79.58%, val_best:  80.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-73  lr=['0.1000000'], tr/val_loss:  0.091283/ 60.546795, val:  76.67%, val_best:  80.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-74  lr=['0.1000000'], tr/val_loss:  0.057988/ 60.786831, val:  76.25%, val_best:  80.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-75  lr=['0.1000000'], tr/val_loss:  0.072083/ 61.630489, val:  73.33%, val_best:  80.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-76  lr=['0.1000000'], tr/val_loss:  0.091799/ 61.053619, val:  76.67%, val_best:  80.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-77  lr=['0.1000000'], tr/val_loss:  0.064936/ 59.552334, val:  77.50%, val_best:  80.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-78  lr=['0.1000000'], tr/val_loss:  0.123103/ 59.467968, val:  75.83%, val_best:  80.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-79  lr=['0.1000000'], tr/val_loss:  0.126800/ 60.617611, val:  75.00%, val_best:  80.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-80  lr=['0.1000000'], tr/val_loss:  0.183249/ 59.759407, val:  77.92%, val_best:  80.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-81  lr=['0.1000000'], tr/val_loss:  0.082279/ 61.063889, val:  77.92%, val_best:  80.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-82  lr=['0.1000000'], tr/val_loss:  0.109916/ 58.845005, val:  79.58%, val_best:  80.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-83  lr=['0.1000000'], tr/val_loss:  0.249839/ 62.035320, val:  77.92%, val_best:  80.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-84  lr=['0.1000000'], tr/val_loss:  0.238060/ 63.047340, val:  78.75%, val_best:  80.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-85  lr=['0.1000000'], tr/val_loss:  0.183209/ 61.914139, val:  77.92%, val_best:  80.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-86  lr=['0.1000000'], tr/val_loss:  0.088338/ 60.964233, val:  78.33%, val_best:  80.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-87  lr=['0.1000000'], tr/val_loss:  0.069504/ 61.840263, val:  77.50%, val_best:  80.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-88  lr=['0.1000000'], tr/val_loss:  0.256942/ 62.486610, val:  78.33%, val_best:  80.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-89  lr=['0.1000000'], tr/val_loss:  0.190676/ 59.578194, val:  77.92%, val_best:  80.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-90  lr=['0.1000000'], tr/val_loss:  0.105287/ 61.904644, val:  79.17%, val_best:  80.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-91  lr=['0.1000000'], tr/val_loss:  0.112147/ 62.536472, val:  77.08%, val_best:  80.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-92  lr=['0.1000000'], tr/val_loss:  0.095158/ 64.022881, val:  77.92%, val_best:  80.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-93  lr=['0.1000000'], tr/val_loss:  0.126606/ 62.067043, val:  80.00%, val_best:  80.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-94  lr=['0.1000000'], tr/val_loss:  0.096493/ 63.563915, val:  77.50%, val_best:  80.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-95  lr=['0.1000000'], tr/val_loss:  0.067159/ 61.980816, val:  77.50%, val_best:  80.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-96  lr=['0.1000000'], tr/val_loss:  0.072640/ 62.239780, val:  79.17%, val_best:  80.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-97  lr=['0.1000000'], tr/val_loss:  0.081709/ 64.773033, val:  75.42%, val_best:  80.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-98  lr=['0.1000000'], tr/val_loss:  0.100230/ 67.359901, val:  75.42%, val_best:  80.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-99  lr=['0.1000000'], tr/val_loss:  0.117827/ 62.475849, val:  79.17%, val_best:  80.42%, tr: 100.00%, tr_best: 100.00%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "028ab4b278a4491b91dc8157a0291f5d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.006 MB of 0.006 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>iter_acc</td><td>▁▁▄▇▄▇█▇████████████████████████████████</td></tr><tr><td>summary_val_acc</td><td>▁▄▄▃▄▆▅▇▇▇▇▇▇▇▇▇▇██▇█▇█▇█▇████▇█▇██████▇</td></tr><tr><td>tr_acc</td><td>▁▃▄▅▅▇▇█████████████████████████████████</td></tr><tr><td>tr_epoch_loss</td><td>█▇▅▃▅▃▃▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_acc_best</td><td>▁▄▄▅▅▆▆▇▇▇▇▇▇▇▇▇████████████████████████</td></tr><tr><td>val_acc_now</td><td>▁▄▄▃▄▆▅▇▇▇▇▇▇▇▇▇▇██▇█▇█▇█▇████▇█▇██████▇</td></tr><tr><td>val_loss</td><td>▅▄▁▄▆▂▅▃▃▄▅▅▆▆▆▆▇▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇██▇███</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>99</td></tr><tr><td>iter_acc</td><td>1.0</td></tr><tr><td>tr_acc</td><td>1.0</td></tr><tr><td>tr_epoch_loss</td><td>0.11783</td></tr><tr><td>val_acc_best</td><td>0.80417</td></tr><tr><td>val_acc_now</td><td>0.79167</td></tr><tr><td>val_loss</td><td>62.47585</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">frosty-sweep-122</strong> at: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/9g35j62p' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/9g35j62p</a><br/> View project at: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>/data2/bh_wandb/wandb/run-20250430_021340-9g35j62p/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require(\"core\")`! See https://wandb.me/wandb-core for more information."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: cw8r803s with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBATCH: 16\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBN_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBPTT_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tDFA_on: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tIMAGE_SIZE: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tOTTT_input_trace_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tTIME: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tUDA_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \talpha_uda: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbias: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcfg: ['M', 'M', 200, 200]\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tchaching_on: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tconvTrue_fcFalse: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdata_path: /data2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tddp_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdenoise_on: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdvs_clipping: 5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdvs_duration: 100000\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepoch_num: 100\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \texclude_class: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \textra_train_dataset: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlast_lif: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.001\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_sg_width: 3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_decay: 0.5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_init: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_reset: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_threshold: 0.25\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmerge_polarities: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmy_seed: 42\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnet_print: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_workers: 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer_what: SGD\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tpin_memory: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tpre_trained: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tpre_trained_path: net_save/save_now_net_weights_{unique_name}.pth\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \trate_coding: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tscheduler_name: no\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsingle_step: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsurrogate: hard_sigmoid\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_conv_kernel_size: 3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_conv_padding: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_conv_stride: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_trace_const1: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_trace_const2: 0.5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \ttdBN_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \ttrace_on: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \twhich_data: DVS_GESTURE_TONIC\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9c68dcd7abe84330ba0c64db72d52c27",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.011113361362367869, max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.19.10 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.17.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/data2/bh_wandb/wandb/run-20250430_022041-cw8r803s</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/cw8r803s' target=\"_blank\">rosy-sweep-127</a></strong> to <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/6pj3lh8j' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/6pj3lh8j</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/6pj3lh8j' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/6pj3lh8j</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/cw8r803s' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/cw8r803s</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'single_step' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'my_seed' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'TIME' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BATCH' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'IMAGE_SIZE' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'which_data' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'data_path' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'rate_coding' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_init' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_decay' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_threshold' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_reset' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_sg_width' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_conv_kernel_size' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_conv_stride' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_conv_padding' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_trace_const1' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_trace_const2' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'pre_trained' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'convTrue_fcFalse' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'cfg' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'net_print' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'pre_trained_path' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'learning_rate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'epoch_num' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'tdBN_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BN_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'surrogate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BPTT_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'optimizer_what' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'scheduler_name' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'ddp_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'dvs_clipping' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'dvs_duration' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'DFA_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'trace_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'OTTT_input_trace_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'exclude_class' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'merge_polarities' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'denoise_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'extra_train_dataset' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'num_workers' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'chaching_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'pin_memory' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'UDA_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'alpha_uda' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'bias' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'last_lif' was locked by 'sweep' (ignored update).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "param {'devices': '0', 'single_step': True, 'unique_name': 'main', 'my_seed': 42, 'TIME': 10, 'BATCH': 16, 'IMAGE_SIZE': 128, 'which_data': 'DVS_GESTURE_TONIC', 'data_path': '/data2', 'rate_coding': False, 'lif_layer_v_init': 0, 'lif_layer_v_decay': 0.5, 'lif_layer_v_threshold': 0.25, 'lif_layer_v_reset': 0, 'lif_layer_sg_width': 3, 'synapse_conv_kernel_size': 3, 'synapse_conv_stride': 1, 'synapse_conv_padding': 1, 'synapse_trace_const1': 1, 'synapse_trace_const2': 0.5, 'pre_trained': False, 'convTrue_fcFalse': False, 'cfg': ['M', 'M', 200, 200], 'net_print': True, 'pre_trained_path': 'net_save/save_now_net_weights_{unique_name}.pth', 'learning_rate': 0.001, 'epoch_num': 100, 'tdBN_on': False, 'BN_on': False, 'surrogate': 'hard_sigmoid', 'BPTT_on': False, 'optimizer_what': 'SGD', 'scheduler_name': 'no', 'ddp_on': False, 'dvs_clipping': 5, 'dvs_duration': 100000, 'DFA_on': True, 'trace_on': True, 'OTTT_input_trace_on': False, 'exclude_class': True, 'merge_polarities': False, 'denoise_on': True, 'extra_train_dataset': 0, 'num_workers': 2, 'chaching_on': True, 'pin_memory': True, 'UDA_on': False, 'alpha_uda': 1, 'bias': True, 'last_lif': False, 'current epoch': 0} \n",
      "\n",
      "dataset_hash = 63cc597115630ec173f3099200061e53\n",
      "cache path exists\n",
      "\n",
      "device ==> cuda\n",
      "\n",
      "DataParallel(\n",
      "  (module): REBORN_MY_SNN_FC(\n",
      "    (layers): REBORN_MY_Sequential(\n",
      "      (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (2): DimChanger_for_FC()\n",
      "      (3): SYNAPSE_FC(in_features=2048, out_features=200, TIME=10, bias=True, sstep=True)\n",
      "      (4): LIF_layer(v_init=0, v_decay=0.5, v_threshold=0.25, v_reset=0, sg_width=3, surrogate=hard_sigmoid, BPTT_on=False, trace_const1=1, trace_const2=0.5, TIME=10, sstep=True, trace_on=True)\n",
      "      (5): Feedback_Receiver()\n",
      "      (6): SYNAPSE_FC(in_features=200, out_features=200, TIME=10, bias=True, sstep=True)\n",
      "      (7): LIF_layer(v_init=0, v_decay=0.5, v_threshold=0.25, v_reset=0, sg_width=3, surrogate=hard_sigmoid, BPTT_on=False, trace_const1=1, trace_const2=0.5, TIME=10, sstep=True, trace_on=True)\n",
      "      (8): Feedback_Receiver()\n",
      "      (9): SYNAPSE_FC(in_features=200, out_features=10, TIME=10, bias=True, sstep=True)\n",
      "      (DFA_top): Top_Gradient()\n",
      "    )\n",
      "  )\n",
      ")\n",
      "\n",
      "========================================================\n",
      "Trainable parameters: 452,010\n",
      "========================================================\n",
      "\n",
      "epoch-0   lr=['0.0010000'], tr/val_loss:  2.011507/  1.584647, val:  45.00%, val_best:  45.00%, tr:  24.51%, tr_best:  24.51%\n",
      "[module.layers.5] weight_fb parameter count: 2,000\n",
      "[module.layers.8] weight_fb parameter count: 2,000\n",
      "epoch-1   lr=['0.0010000'], tr/val_loss:  1.314693/  1.443895, val:  55.42%, val_best:  55.42%, tr:  55.87%, tr_best:  55.87%\n",
      "epoch-2   lr=['0.0010000'], tr/val_loss:  1.146979/  1.420069, val:  55.42%, val_best:  55.42%, tr:  60.67%, tr_best:  60.67%\n",
      "epoch-3   lr=['0.0010000'], tr/val_loss:  1.025163/  1.396865, val:  57.92%, val_best:  57.92%, tr:  65.68%, tr_best:  65.68%\n",
      "epoch-4   lr=['0.0010000'], tr/val_loss:  0.960678/  1.315178, val:  62.92%, val_best:  62.92%, tr:  67.93%, tr_best:  67.93%\n",
      "epoch-5   lr=['0.0010000'], tr/val_loss:  0.935892/  1.257913, val:  62.08%, val_best:  62.92%, tr:  69.25%, tr_best:  69.25%\n",
      "epoch-6   lr=['0.0010000'], tr/val_loss:  0.871255/  1.283993, val:  60.42%, val_best:  62.92%, tr:  72.52%, tr_best:  72.52%\n",
      "epoch-7   lr=['0.0010000'], tr/val_loss:  0.846661/  1.308108, val:  62.08%, val_best:  62.92%, tr:  72.32%, tr_best:  72.52%\n",
      "epoch-8   lr=['0.0010000'], tr/val_loss:  0.816782/  1.310453, val:  67.92%, val_best:  67.92%, tr:  74.06%, tr_best:  74.06%\n",
      "epoch-9   lr=['0.0010000'], tr/val_loss:  0.785648/  1.371734, val:  60.42%, val_best:  67.92%, tr:  78.65%, tr_best:  78.65%\n",
      "epoch-10  lr=['0.0010000'], tr/val_loss:  0.765132/  1.391201, val:  58.33%, val_best:  67.92%, tr:  78.14%, tr_best:  78.65%\n",
      "epoch-11  lr=['0.0010000'], tr/val_loss:  0.701894/  1.258949, val:  70.42%, val_best:  70.42%, tr:  83.25%, tr_best:  83.25%\n",
      "epoch-12  lr=['0.0010000'], tr/val_loss:  0.680245/  1.298079, val:  68.75%, val_best:  70.42%, tr:  86.41%, tr_best:  86.41%\n",
      "epoch-13  lr=['0.0010000'], tr/val_loss:  0.657645/  1.348071, val:  67.50%, val_best:  70.42%, tr:  86.21%, tr_best:  86.41%\n",
      "epoch-14  lr=['0.0010000'], tr/val_loss:  0.617377/  1.526531, val:  67.08%, val_best:  70.42%, tr:  88.25%, tr_best:  88.25%\n",
      "epoch-15  lr=['0.0010000'], tr/val_loss:  0.590898/  1.476496, val:  66.25%, val_best:  70.42%, tr:  90.30%, tr_best:  90.30%\n",
      "epoch-16  lr=['0.0010000'], tr/val_loss:  0.599842/  1.425676, val:  69.17%, val_best:  70.42%, tr:  90.60%, tr_best:  90.60%\n",
      "epoch-17  lr=['0.0010000'], tr/val_loss:  0.550525/  1.494058, val:  68.33%, val_best:  70.42%, tr:  93.77%, tr_best:  93.77%\n",
      "epoch-18  lr=['0.0010000'], tr/val_loss:  0.554590/  1.595382, val:  63.75%, val_best:  70.42%, tr:  93.16%, tr_best:  93.77%\n",
      "epoch-19  lr=['0.0010000'], tr/val_loss:  0.543695/  1.547290, val:  65.42%, val_best:  70.42%, tr:  91.52%, tr_best:  93.77%\n",
      "epoch-20  lr=['0.0010000'], tr/val_loss:  0.514900/  1.731213, val:  64.17%, val_best:  70.42%, tr:  93.56%, tr_best:  93.77%\n",
      "epoch-21  lr=['0.0010000'], tr/val_loss:  0.516651/  1.639585, val:  66.67%, val_best:  70.42%, tr:  93.16%, tr_best:  93.77%\n",
      "epoch-22  lr=['0.0010000'], tr/val_loss:  0.470513/  1.642246, val:  68.33%, val_best:  70.42%, tr:  96.83%, tr_best:  96.83%\n",
      "epoch-23  lr=['0.0010000'], tr/val_loss:  0.488632/  1.662723, val:  70.00%, val_best:  70.42%, tr:  95.40%, tr_best:  96.83%\n",
      "epoch-24  lr=['0.0010000'], tr/val_loss:  0.440595/  1.665157, val:  69.58%, val_best:  70.42%, tr:  97.24%, tr_best:  97.24%\n",
      "epoch-25  lr=['0.0010000'], tr/val_loss:  0.423401/  1.695204, val:  69.17%, val_best:  70.42%, tr:  97.34%, tr_best:  97.34%\n",
      "epoch-26  lr=['0.0010000'], tr/val_loss:  0.452692/  1.738598, val:  70.42%, val_best:  70.42%, tr:  96.12%, tr_best:  97.34%\n",
      "epoch-27  lr=['0.0010000'], tr/val_loss:  0.431430/  1.798129, val:  68.33%, val_best:  70.42%, tr:  97.04%, tr_best:  97.34%\n",
      "epoch-28  lr=['0.0010000'], tr/val_loss:  0.414470/  1.741370, val:  71.67%, val_best:  71.67%, tr:  98.37%, tr_best:  98.37%\n",
      "epoch-29  lr=['0.0010000'], tr/val_loss:  0.388773/  1.895581, val:  66.67%, val_best:  71.67%, tr:  98.37%, tr_best:  98.37%\n",
      "epoch-30  lr=['0.0010000'], tr/val_loss:  0.389630/  1.855979, val:  69.17%, val_best:  71.67%, tr:  97.75%, tr_best:  98.37%\n",
      "epoch-31  lr=['0.0010000'], tr/val_loss:  0.396474/  1.913070, val:  71.25%, val_best:  71.67%, tr:  97.85%, tr_best:  98.37%\n",
      "epoch-32  lr=['0.0010000'], tr/val_loss:  0.415995/  1.914349, val:  70.83%, val_best:  71.67%, tr:  97.34%, tr_best:  98.37%\n",
      "epoch-33  lr=['0.0010000'], tr/val_loss:  0.404145/  1.910893, val:  73.75%, val_best:  73.75%, tr:  96.73%, tr_best:  98.37%\n",
      "epoch-34  lr=['0.0010000'], tr/val_loss:  0.369425/  1.986852, val:  70.83%, val_best:  73.75%, tr:  98.57%, tr_best:  98.57%\n",
      "epoch-35  lr=['0.0010000'], tr/val_loss:  0.363462/  2.022888, val:  70.83%, val_best:  73.75%, tr:  98.57%, tr_best:  98.57%\n",
      "epoch-36  lr=['0.0010000'], tr/val_loss:  0.338647/  1.991450, val:  71.25%, val_best:  73.75%, tr:  98.37%, tr_best:  98.57%\n",
      "epoch-37  lr=['0.0010000'], tr/val_loss:  0.342209/  2.133238, val:  68.75%, val_best:  73.75%, tr:  99.28%, tr_best:  99.28%\n",
      "epoch-38  lr=['0.0010000'], tr/val_loss:  0.349480/  2.092339, val:  69.58%, val_best:  73.75%, tr:  99.28%, tr_best:  99.28%\n",
      "epoch-39  lr=['0.0010000'], tr/val_loss:  0.349259/  2.053963, val:  72.92%, val_best:  73.75%, tr:  98.88%, tr_best:  99.28%\n",
      "epoch-40  lr=['0.0010000'], tr/val_loss:  0.324988/  2.175116, val:  69.58%, val_best:  73.75%, tr:  99.08%, tr_best:  99.28%\n",
      "epoch-41  lr=['0.0010000'], tr/val_loss:  0.292409/  2.197631, val:  70.00%, val_best:  73.75%, tr:  99.59%, tr_best:  99.59%\n",
      "epoch-42  lr=['0.0010000'], tr/val_loss:  0.285761/  2.188105, val:  68.75%, val_best:  73.75%, tr:  99.80%, tr_best:  99.80%\n",
      "epoch-43  lr=['0.0010000'], tr/val_loss:  0.289129/  2.313125, val:  68.33%, val_best:  73.75%, tr:  99.49%, tr_best:  99.80%\n",
      "epoch-44  lr=['0.0010000'], tr/val_loss:  0.297682/  2.275110, val:  70.42%, val_best:  73.75%, tr:  99.49%, tr_best:  99.80%\n",
      "epoch-45  lr=['0.0010000'], tr/val_loss:  0.276898/  2.337722, val:  68.33%, val_best:  73.75%, tr:  99.80%, tr_best:  99.80%\n",
      "epoch-46  lr=['0.0010000'], tr/val_loss:  0.269271/  2.342380, val:  69.17%, val_best:  73.75%, tr:  99.90%, tr_best:  99.90%\n",
      "epoch-47  lr=['0.0010000'], tr/val_loss:  0.255771/  2.387000, val:  69.17%, val_best:  73.75%, tr:  99.80%, tr_best:  99.90%\n",
      "epoch-48  lr=['0.0010000'], tr/val_loss:  0.261057/  2.362257, val:  71.25%, val_best:  73.75%, tr:  99.80%, tr_best:  99.90%\n",
      "epoch-49  lr=['0.0010000'], tr/val_loss:  0.262717/  2.425205, val:  70.83%, val_best:  73.75%, tr:  99.49%, tr_best:  99.90%\n",
      "epoch-50  lr=['0.0010000'], tr/val_loss:  0.241191/  2.416723, val:  70.00%, val_best:  73.75%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-51  lr=['0.0010000'], tr/val_loss:  0.249660/  2.494849, val:  67.92%, val_best:  73.75%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-52  lr=['0.0010000'], tr/val_loss:  0.230089/  2.570326, val:  69.58%, val_best:  73.75%, tr:  99.90%, tr_best: 100.00%\n",
      "epoch-53  lr=['0.0010000'], tr/val_loss:  0.234286/  2.590609, val:  69.58%, val_best:  73.75%, tr:  99.80%, tr_best: 100.00%\n",
      "epoch-54  lr=['0.0010000'], tr/val_loss:  0.248157/  2.615126, val:  68.75%, val_best:  73.75%, tr:  99.90%, tr_best: 100.00%\n",
      "epoch-55  lr=['0.0010000'], tr/val_loss:  0.231963/  2.713516, val:  69.17%, val_best:  73.75%, tr:  99.90%, tr_best: 100.00%\n",
      "epoch-56  lr=['0.0010000'], tr/val_loss:  0.247534/  2.739069, val:  70.42%, val_best:  73.75%, tr:  99.90%, tr_best: 100.00%\n",
      "epoch-57  lr=['0.0010000'], tr/val_loss:  0.244821/  2.711795, val:  69.17%, val_best:  73.75%, tr:  99.39%, tr_best: 100.00%\n",
      "epoch-58  lr=['0.0010000'], tr/val_loss:  0.231600/  2.895834, val:  67.50%, val_best:  73.75%, tr:  99.80%, tr_best: 100.00%\n",
      "epoch-59  lr=['0.0010000'], tr/val_loss:  0.227959/  2.752249, val:  70.83%, val_best:  73.75%, tr:  99.69%, tr_best: 100.00%\n",
      "epoch-60  lr=['0.0010000'], tr/val_loss:  0.227008/  2.826570, val:  70.42%, val_best:  73.75%, tr:  99.80%, tr_best: 100.00%\n",
      "epoch-61  lr=['0.0010000'], tr/val_loss:  0.215513/  2.837401, val:  71.25%, val_best:  73.75%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-62  lr=['0.0010000'], tr/val_loss:  0.197862/  2.841007, val:  70.00%, val_best:  73.75%, tr:  99.90%, tr_best: 100.00%\n",
      "epoch-63  lr=['0.0010000'], tr/val_loss:  0.206377/  2.859564, val:  70.83%, val_best:  73.75%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-64  lr=['0.0010000'], tr/val_loss:  0.194242/  2.928165, val:  71.67%, val_best:  73.75%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-65  lr=['0.0010000'], tr/val_loss:  0.200468/  2.849691, val:  71.25%, val_best:  73.75%, tr:  99.90%, tr_best: 100.00%\n",
      "epoch-66  lr=['0.0010000'], tr/val_loss:  0.192919/  2.958224, val:  67.50%, val_best:  73.75%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-67  lr=['0.0010000'], tr/val_loss:  0.184871/  2.933854, val:  71.67%, val_best:  73.75%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-68  lr=['0.0010000'], tr/val_loss:  0.194088/  2.991307, val:  71.25%, val_best:  73.75%, tr:  99.90%, tr_best: 100.00%\n",
      "epoch-69  lr=['0.0010000'], tr/val_loss:  0.177761/  3.076232, val:  70.00%, val_best:  73.75%, tr:  99.90%, tr_best: 100.00%\n",
      "epoch-70  lr=['0.0010000'], tr/val_loss:  0.184416/  3.046508, val:  70.00%, val_best:  73.75%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-71  lr=['0.0010000'], tr/val_loss:  0.185668/  3.127873, val:  70.83%, val_best:  73.75%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-72  lr=['0.0010000'], tr/val_loss:  0.186596/  3.223302, val:  70.83%, val_best:  73.75%, tr:  99.90%, tr_best: 100.00%\n",
      "epoch-73  lr=['0.0010000'], tr/val_loss:  0.188589/  3.170901, val:  70.83%, val_best:  73.75%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-74  lr=['0.0010000'], tr/val_loss:  0.168913/  3.147501, val:  71.67%, val_best:  73.75%, tr:  99.90%, tr_best: 100.00%\n",
      "epoch-75  lr=['0.0010000'], tr/val_loss:  0.174258/  3.258626, val:  68.75%, val_best:  73.75%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-76  lr=['0.0010000'], tr/val_loss:  0.178138/  3.254418, val:  70.42%, val_best:  73.75%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-77  lr=['0.0010000'], tr/val_loss:  0.171474/  3.305895, val:  69.58%, val_best:  73.75%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-78  lr=['0.0010000'], tr/val_loss:  0.176384/  3.308572, val:  68.33%, val_best:  73.75%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-79  lr=['0.0010000'], tr/val_loss:  0.168837/  3.335447, val:  68.75%, val_best:  73.75%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-80  lr=['0.0010000'], tr/val_loss:  0.170694/  3.343555, val:  68.33%, val_best:  73.75%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-81  lr=['0.0010000'], tr/val_loss:  0.167245/  3.356092, val:  70.42%, val_best:  73.75%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-82  lr=['0.0010000'], tr/val_loss:  0.178177/  3.364936, val:  71.67%, val_best:  73.75%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-83  lr=['0.0010000'], tr/val_loss:  0.178505/  3.400243, val:  67.08%, val_best:  73.75%, tr:  99.90%, tr_best: 100.00%\n",
      "epoch-84  lr=['0.0010000'], tr/val_loss:  0.158955/  3.355854, val:  69.58%, val_best:  73.75%, tr:  99.90%, tr_best: 100.00%\n",
      "epoch-85  lr=['0.0010000'], tr/val_loss:  0.169293/  3.399518, val:  72.08%, val_best:  73.75%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-86  lr=['0.0010000'], tr/val_loss:  0.158114/  3.425057, val:  70.83%, val_best:  73.75%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-87  lr=['0.0010000'], tr/val_loss:  0.181908/  3.433438, val:  69.58%, val_best:  73.75%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-88  lr=['0.0010000'], tr/val_loss:  0.164464/  3.442598, val:  70.42%, val_best:  73.75%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-89  lr=['0.0010000'], tr/val_loss:  0.153647/  3.482835, val:  69.58%, val_best:  73.75%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-90  lr=['0.0010000'], tr/val_loss:  0.174239/  3.463291, val:  69.17%, val_best:  73.75%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-91  lr=['0.0010000'], tr/val_loss:  0.151170/  3.546807, val:  67.50%, val_best:  73.75%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-92  lr=['0.0010000'], tr/val_loss:  0.150260/  3.600930, val:  68.75%, val_best:  73.75%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-93  lr=['0.0010000'], tr/val_loss:  0.156164/  3.563688, val:  70.00%, val_best:  73.75%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-94  lr=['0.0010000'], tr/val_loss:  0.143555/  3.634567, val:  69.17%, val_best:  73.75%, tr:  99.90%, tr_best: 100.00%\n",
      "epoch-95  lr=['0.0010000'], tr/val_loss:  0.146128/  3.648632, val:  68.33%, val_best:  73.75%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-96  lr=['0.0010000'], tr/val_loss:  0.130526/  3.809581, val:  68.75%, val_best:  73.75%, tr:  99.90%, tr_best: 100.00%\n",
      "epoch-97  lr=['0.0010000'], tr/val_loss:  0.151261/  3.616701, val:  70.83%, val_best:  73.75%, tr:  99.90%, tr_best: 100.00%\n",
      "epoch-98  lr=['0.0010000'], tr/val_loss:  0.128806/  3.687761, val:  69.58%, val_best:  73.75%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-99  lr=['0.0010000'], tr/val_loss:  0.124968/  3.716450, val:  69.58%, val_best:  73.75%, tr: 100.00%, tr_best: 100.00%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eb1d86e9f1fa4911ac95a747a78a2cfb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.006 MB of 0.006 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>iter_acc</td><td>▁▇▄▃▅▅▇▄▇███▇▇██████████████████████████</td></tr><tr><td>summary_val_acc</td><td>▁▄▅▅▅▇▇▇▆▆▇▇▆▇▇▇█▇▇▇▇▇▇▇▇███▇▇▇▇▇█▇▇▇▇▇▇</td></tr><tr><td>tr_acc</td><td>▁▄▅▅▆▇▇▇▇▇██████████████████████████████</td></tr><tr><td>tr_epoch_loss</td><td>█▅▄▄▃▃▃▃▂▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_acc_best</td><td>▁▄▅▅▇▇▇▇▇▇▇▇▇▇██████████████████████████</td></tr><tr><td>val_acc_now</td><td>▁▄▅▅▅▇▇▇▆▆▇▇▆▇▇▇█▇▇▇▇▇▇▇▇███▇▇▇▇▇█▇▇▇▇▇▇</td></tr><tr><td>val_loss</td><td>▂▁▁▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▅▅▅▅▆▆▆▆▇▇▇▇▇▇▇████</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>99</td></tr><tr><td>iter_acc</td><td>1.0</td></tr><tr><td>tr_acc</td><td>1.0</td></tr><tr><td>tr_epoch_loss</td><td>0.12497</td></tr><tr><td>val_acc_best</td><td>0.7375</td></tr><tr><td>val_acc_now</td><td>0.69583</td></tr><tr><td>val_loss</td><td>3.71645</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">rosy-sweep-127</strong> at: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/cw8r803s' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/cw8r803s</a><br/> View project at: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>/data2/bh_wandb/wandb/run-20250430_022041-cw8r803s/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require(\"core\")`! See https://wandb.me/wandb-core for more information."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Sweep Agent: Waiting for job.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Job received.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: ekgillcr with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBATCH: 16\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBN_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBPTT_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tDFA_on: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tIMAGE_SIZE: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tOTTT_input_trace_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tTIME: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tUDA_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \talpha_uda: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbias: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcfg: ['M', 'M', 200, 200]\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tchaching_on: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tconvTrue_fcFalse: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdata_path: /data2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tddp_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdenoise_on: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdvs_clipping: 5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdvs_duration: 100000\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepoch_num: 100\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \texclude_class: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \textra_train_dataset: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlast_lif: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_sg_width: 3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_decay: 0.5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_init: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_reset: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_threshold: 0.5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmerge_polarities: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmy_seed: 42\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnet_print: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_workers: 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer_what: SGD\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tpin_memory: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tpre_trained: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tpre_trained_path: net_save/save_now_net_weights_{unique_name}.pth\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \trate_coding: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tscheduler_name: no\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsingle_step: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsurrogate: hard_sigmoid\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_conv_kernel_size: 3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_conv_padding: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_conv_stride: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_trace_const1: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_trace_const2: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \ttdBN_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \ttrace_on: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \twhich_data: DVS_GESTURE_TONIC\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.19.10 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.17.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/data2/bh_wandb/wandb/run-20250430_022736-ekgillcr</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/ekgillcr' target=\"_blank\">good-sweep-131</a></strong> to <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/6pj3lh8j' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/6pj3lh8j</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/6pj3lh8j' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/6pj3lh8j</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/ekgillcr' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/ekgillcr</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'single_step' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'my_seed' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'TIME' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BATCH' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'IMAGE_SIZE' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'which_data' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'data_path' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'rate_coding' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_init' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_decay' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_threshold' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_reset' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_sg_width' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_conv_kernel_size' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_conv_stride' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_conv_padding' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_trace_const1' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_trace_const2' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'pre_trained' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'convTrue_fcFalse' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'cfg' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'net_print' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'pre_trained_path' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'learning_rate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'epoch_num' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'tdBN_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BN_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'surrogate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BPTT_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'optimizer_what' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'scheduler_name' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'ddp_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'dvs_clipping' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'dvs_duration' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'DFA_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'trace_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'OTTT_input_trace_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'exclude_class' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'merge_polarities' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'denoise_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'extra_train_dataset' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'num_workers' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'chaching_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'pin_memory' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'UDA_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'alpha_uda' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'bias' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'last_lif' was locked by 'sweep' (ignored update).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "param {'devices': '0', 'single_step': True, 'unique_name': 'main', 'my_seed': 42, 'TIME': 10, 'BATCH': 16, 'IMAGE_SIZE': 128, 'which_data': 'DVS_GESTURE_TONIC', 'data_path': '/data2', 'rate_coding': False, 'lif_layer_v_init': 0, 'lif_layer_v_decay': 0.5, 'lif_layer_v_threshold': 0.5, 'lif_layer_v_reset': 0, 'lif_layer_sg_width': 3, 'synapse_conv_kernel_size': 3, 'synapse_conv_stride': 1, 'synapse_conv_padding': 1, 'synapse_trace_const1': 1, 'synapse_trace_const2': 0, 'pre_trained': False, 'convTrue_fcFalse': False, 'cfg': ['M', 'M', 200, 200], 'net_print': True, 'pre_trained_path': 'net_save/save_now_net_weights_{unique_name}.pth', 'learning_rate': 0.1, 'epoch_num': 100, 'tdBN_on': False, 'BN_on': False, 'surrogate': 'hard_sigmoid', 'BPTT_on': False, 'optimizer_what': 'SGD', 'scheduler_name': 'no', 'ddp_on': False, 'dvs_clipping': 5, 'dvs_duration': 100000, 'DFA_on': True, 'trace_on': True, 'OTTT_input_trace_on': False, 'exclude_class': True, 'merge_polarities': False, 'denoise_on': True, 'extra_train_dataset': 0, 'num_workers': 2, 'chaching_on': True, 'pin_memory': True, 'UDA_on': False, 'alpha_uda': 1, 'bias': True, 'last_lif': False, 'current epoch': 0} \n",
      "\n",
      "dataset_hash = 63cc597115630ec173f3099200061e53\n",
      "cache path exists\n",
      "\n",
      "device ==> cuda\n",
      "\n",
      "DataParallel(\n",
      "  (module): REBORN_MY_SNN_FC(\n",
      "    (layers): REBORN_MY_Sequential(\n",
      "      (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (2): DimChanger_for_FC()\n",
      "      (3): SYNAPSE_FC(in_features=2048, out_features=200, TIME=10, bias=True, sstep=True)\n",
      "      (4): LIF_layer(v_init=0, v_decay=0.5, v_threshold=0.5, v_reset=0, sg_width=3, surrogate=hard_sigmoid, BPTT_on=False, trace_const1=1, trace_const2=0, TIME=10, sstep=True, trace_on=True)\n",
      "      (5): Feedback_Receiver()\n",
      "      (6): SYNAPSE_FC(in_features=200, out_features=200, TIME=10, bias=True, sstep=True)\n",
      "      (7): LIF_layer(v_init=0, v_decay=0.5, v_threshold=0.5, v_reset=0, sg_width=3, surrogate=hard_sigmoid, BPTT_on=False, trace_const1=1, trace_const2=0, TIME=10, sstep=True, trace_on=True)\n",
      "      (8): Feedback_Receiver()\n",
      "      (9): SYNAPSE_FC(in_features=200, out_features=10, TIME=10, bias=True, sstep=True)\n",
      "      (DFA_top): Top_Gradient()\n",
      "    )\n",
      "  )\n",
      ")\n",
      "\n",
      "========================================================\n",
      "Trainable parameters: 452,010\n",
      "========================================================\n",
      "\n",
      "epoch-0   lr=['0.1000000'], tr/val_loss: 24.465086/ 11.221424, val:  45.00%, val_best:  45.00%, tr:  24.82%, tr_best:  24.82%\n",
      "[module.layers.5] weight_fb parameter count: 2,000\n",
      "[module.layers.8] weight_fb parameter count: 2,000\n",
      "epoch-1   lr=['0.1000000'], tr/val_loss: 16.924528/ 20.529499, val:  41.25%, val_best:  45.00%, tr:  41.47%, tr_best:  41.47%\n",
      "epoch-2   lr=['0.1000000'], tr/val_loss: 21.997679/ 22.242786, val:  40.83%, val_best:  45.00%, tr:  46.99%, tr_best:  46.99%\n",
      "epoch-3   lr=['0.1000000'], tr/val_loss: 14.603514/ 23.574642, val:  41.25%, val_best:  45.00%, tr:  57.41%, tr_best:  57.41%\n",
      "epoch-4   lr=['0.1000000'], tr/val_loss: 13.187902/ 13.198679, val:  47.50%, val_best:  47.50%, tr:  56.08%, tr_best:  57.41%\n",
      "epoch-5   lr=['0.1000000'], tr/val_loss: 11.505589/ 13.530309, val:  46.25%, val_best:  47.50%, tr:  61.80%, tr_best:  61.80%\n",
      "epoch-6   lr=['0.1000000'], tr/val_loss:  9.995473/ 21.391710, val:  38.75%, val_best:  47.50%, tr:  60.27%, tr_best:  61.80%\n",
      "epoch-7   lr=['0.1000000'], tr/val_loss: 11.725746/ 15.267668, val:  50.00%, val_best:  50.00%, tr:  56.69%, tr_best:  61.80%\n",
      "epoch-8   lr=['0.1000000'], tr/val_loss:  8.703512/ 11.092419, val:  55.00%, val_best:  55.00%, tr:  65.88%, tr_best:  65.88%\n",
      "epoch-9   lr=['0.1000000'], tr/val_loss:  9.569154/ 11.758194, val:  56.67%, val_best:  56.67%, tr:  69.87%, tr_best:  69.87%\n",
      "epoch-10  lr=['0.1000000'], tr/val_loss:  9.441794/ 20.784678, val:  43.33%, val_best:  56.67%, tr:  66.19%, tr_best:  69.87%\n",
      "epoch-11  lr=['0.1000000'], tr/val_loss: 10.770412/ 23.122234, val:  54.17%, val_best:  56.67%, tr:  68.85%, tr_best:  69.87%\n",
      "epoch-12  lr=['0.1000000'], tr/val_loss:  9.356113/ 13.910014, val:  59.17%, val_best:  59.17%, tr:  71.60%, tr_best:  71.60%\n",
      "epoch-13  lr=['0.1000000'], tr/val_loss:  5.500765/ 11.945930, val:  60.00%, val_best:  60.00%, tr:  79.16%, tr_best:  79.16%\n",
      "epoch-14  lr=['0.1000000'], tr/val_loss:  5.793050/ 20.244196, val:  49.17%, val_best:  60.00%, tr:  79.47%, tr_best:  79.47%\n",
      "epoch-15  lr=['0.1000000'], tr/val_loss:  7.005648/ 20.981853, val:  50.42%, val_best:  60.00%, tr:  75.69%, tr_best:  79.47%\n",
      "epoch-16  lr=['0.1000000'], tr/val_loss:  5.247404/ 18.166574, val:  52.92%, val_best:  60.00%, tr:  81.61%, tr_best:  81.61%\n",
      "epoch-17  lr=['0.1000000'], tr/val_loss:  3.883472/ 13.537158, val:  60.00%, val_best:  60.00%, tr:  87.13%, tr_best:  87.13%\n",
      "epoch-18  lr=['0.1000000'], tr/val_loss:  3.825788/ 13.447630, val:  59.17%, val_best:  60.00%, tr:  88.66%, tr_best:  88.66%\n",
      "epoch-19  lr=['0.1000000'], tr/val_loss:  2.668621/ 11.829281, val:  65.00%, val_best:  65.00%, tr:  91.62%, tr_best:  91.62%\n",
      "epoch-20  lr=['0.1000000'], tr/val_loss:  3.859996/ 12.566369, val:  69.58%, val_best:  69.58%, tr:  89.38%, tr_best:  91.62%\n",
      "epoch-21  lr=['0.1000000'], tr/val_loss:  3.147727/ 12.743041, val:  67.92%, val_best:  69.58%, tr:  90.91%, tr_best:  91.62%\n",
      "epoch-22  lr=['0.1000000'], tr/val_loss:  1.102451/ 13.558100, val:  68.33%, val_best:  69.58%, tr:  98.88%, tr_best:  98.88%\n",
      "epoch-23  lr=['0.1000000'], tr/val_loss:  1.304312/ 12.901863, val:  67.50%, val_best:  69.58%, tr:  97.24%, tr_best:  98.88%\n",
      "epoch-24  lr=['0.1000000'], tr/val_loss:  0.679030/ 12.597117, val:  71.25%, val_best:  71.25%, tr:  99.49%, tr_best:  99.49%\n",
      "epoch-25  lr=['0.1000000'], tr/val_loss:  0.673100/ 12.307299, val:  73.33%, val_best:  73.33%, tr:  99.28%, tr_best:  99.49%\n",
      "epoch-26  lr=['0.1000000'], tr/val_loss:  0.525630/ 11.705005, val:  71.25%, val_best:  73.33%, tr:  99.69%, tr_best:  99.69%\n",
      "epoch-27  lr=['0.1000000'], tr/val_loss:  0.458731/ 11.557122, val:  68.33%, val_best:  73.33%, tr:  99.80%, tr_best:  99.80%\n",
      "epoch-28  lr=['0.1000000'], tr/val_loss:  0.327977/ 11.042440, val:  71.25%, val_best:  73.33%, tr:  99.59%, tr_best:  99.80%\n",
      "epoch-29  lr=['0.1000000'], tr/val_loss:  0.270541/ 12.534283, val:  70.83%, val_best:  73.33%, tr:  99.90%, tr_best:  99.90%\n",
      "epoch-30  lr=['0.1000000'], tr/val_loss:  0.272744/ 10.450353, val:  75.00%, val_best:  75.00%, tr:  99.69%, tr_best:  99.90%\n",
      "epoch-31  lr=['0.1000000'], tr/val_loss:  0.191227/ 10.406888, val:  74.17%, val_best:  75.00%, tr:  99.90%, tr_best:  99.90%\n",
      "epoch-32  lr=['0.1000000'], tr/val_loss:  0.147679/ 11.912457, val:  72.50%, val_best:  75.00%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-33  lr=['0.1000000'], tr/val_loss:  0.147301/ 11.354444, val:  71.67%, val_best:  75.00%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-34  lr=['0.1000000'], tr/val_loss:  0.241249/ 12.507911, val:  67.08%, val_best:  75.00%, tr:  99.90%, tr_best: 100.00%\n",
      "epoch-35  lr=['0.1000000'], tr/val_loss:  0.331028/ 12.272083, val:  68.33%, val_best:  75.00%, tr:  99.69%, tr_best: 100.00%\n",
      "epoch-36  lr=['0.1000000'], tr/val_loss:  0.198262/ 11.677608, val:  71.67%, val_best:  75.00%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-37  lr=['0.1000000'], tr/val_loss:  0.120950/ 11.674929, val:  75.83%, val_best:  75.83%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-38  lr=['0.1000000'], tr/val_loss:  0.082981/ 11.631287, val:  73.75%, val_best:  75.83%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-39  lr=['0.1000000'], tr/val_loss:  0.061266/ 11.400500, val:  77.08%, val_best:  77.08%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-40  lr=['0.1000000'], tr/val_loss:  0.068792/ 11.815742, val:  74.17%, val_best:  77.08%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-41  lr=['0.1000000'], tr/val_loss:  0.069851/ 11.565505, val:  74.17%, val_best:  77.08%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-42  lr=['0.1000000'], tr/val_loss:  0.054446/ 11.524766, val:  73.75%, val_best:  77.08%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-43  lr=['0.1000000'], tr/val_loss:  0.043558/ 11.570849, val:  74.17%, val_best:  77.08%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-44  lr=['0.1000000'], tr/val_loss:  0.049578/ 11.673040, val:  75.00%, val_best:  77.08%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-45  lr=['0.1000000'], tr/val_loss:  0.033672/ 11.264639, val:  75.83%, val_best:  77.08%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-46  lr=['0.1000000'], tr/val_loss:  0.112075/ 11.451718, val:  74.58%, val_best:  77.08%, tr:  99.69%, tr_best: 100.00%\n",
      "epoch-47  lr=['0.1000000'], tr/val_loss:  0.211611/ 11.683218, val:  75.83%, val_best:  77.08%, tr:  99.80%, tr_best: 100.00%\n",
      "epoch-48  lr=['0.1000000'], tr/val_loss:  0.087479/ 11.247904, val:  75.00%, val_best:  77.08%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-49  lr=['0.1000000'], tr/val_loss:  0.072232/ 11.866590, val:  76.67%, val_best:  77.08%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-50  lr=['0.1000000'], tr/val_loss:  0.059253/ 11.741501, val:  75.00%, val_best:  77.08%, tr:  99.90%, tr_best: 100.00%\n",
      "epoch-51  lr=['0.1000000'], tr/val_loss:  0.030162/ 11.785788, val:  75.83%, val_best:  77.08%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-52  lr=['0.1000000'], tr/val_loss:  0.046345/ 11.777366, val:  72.50%, val_best:  77.08%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-53  lr=['0.1000000'], tr/val_loss:  0.025321/ 11.452545, val:  75.42%, val_best:  77.08%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-54  lr=['0.1000000'], tr/val_loss:  0.031433/ 11.202094, val:  75.00%, val_best:  77.08%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-55  lr=['0.1000000'], tr/val_loss:  0.048481/ 12.691566, val:  70.42%, val_best:  77.08%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-56  lr=['0.1000000'], tr/val_loss:  0.025995/ 12.321888, val:  76.25%, val_best:  77.08%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-57  lr=['0.1000000'], tr/val_loss:  0.020613/ 11.470455, val:  74.17%, val_best:  77.08%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-58  lr=['0.1000000'], tr/val_loss:  0.024927/ 11.062531, val:  77.08%, val_best:  77.08%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-59  lr=['0.1000000'], tr/val_loss:  0.015249/ 11.742468, val:  74.17%, val_best:  77.08%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-60  lr=['0.1000000'], tr/val_loss:  0.005698/ 12.587677, val:  72.08%, val_best:  77.08%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-61  lr=['0.1000000'], tr/val_loss:  0.011366/ 11.908916, val:  74.17%, val_best:  77.08%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-62  lr=['0.1000000'], tr/val_loss:  0.008448/ 11.528816, val:  76.25%, val_best:  77.08%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-63  lr=['0.1000000'], tr/val_loss:  0.006137/ 11.814929, val:  73.75%, val_best:  77.08%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-64  lr=['0.1000000'], tr/val_loss:  0.004817/ 12.001459, val:  72.92%, val_best:  77.08%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-65  lr=['0.1000000'], tr/val_loss:  0.002933/ 11.975127, val:  75.00%, val_best:  77.08%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-66  lr=['0.1000000'], tr/val_loss:  0.011325/ 11.381379, val:  75.83%, val_best:  77.08%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-67  lr=['0.1000000'], tr/val_loss:  0.018606/ 11.731224, val:  75.83%, val_best:  77.08%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-68  lr=['0.1000000'], tr/val_loss:  0.010671/ 11.503443, val:  75.00%, val_best:  77.08%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-69  lr=['0.1000000'], tr/val_loss:  0.016840/ 11.828141, val:  75.83%, val_best:  77.08%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-70  lr=['0.1000000'], tr/val_loss:  0.010530/ 12.362610, val:  72.92%, val_best:  77.08%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-71  lr=['0.1000000'], tr/val_loss:  0.021607/ 12.267262, val:  75.00%, val_best:  77.08%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-72  lr=['0.1000000'], tr/val_loss:  0.019713/ 12.594703, val:  74.58%, val_best:  77.08%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-73  lr=['0.1000000'], tr/val_loss:  0.008820/ 12.164277, val:  74.17%, val_best:  77.08%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-74  lr=['0.1000000'], tr/val_loss:  0.006440/ 12.359854, val:  74.58%, val_best:  77.08%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-75  lr=['0.1000000'], tr/val_loss:  0.004227/ 12.032015, val:  75.42%, val_best:  77.08%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-76  lr=['0.1000000'], tr/val_loss:  0.002689/ 12.212693, val:  73.75%, val_best:  77.08%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-77  lr=['0.1000000'], tr/val_loss:  0.000312/ 12.077191, val:  75.00%, val_best:  77.08%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-78  lr=['0.1000000'], tr/val_loss:  0.000019/ 12.064880, val:  74.58%, val_best:  77.08%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-79  lr=['0.1000000'], tr/val_loss:  0.000015/ 12.062627, val:  74.58%, val_best:  77.08%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-80  lr=['0.1000000'], tr/val_loss:  0.000013/ 12.036951, val:  75.00%, val_best:  77.08%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-81  lr=['0.1000000'], tr/val_loss:  0.000014/ 11.998976, val:  74.58%, val_best:  77.08%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-82  lr=['0.1000000'], tr/val_loss:  0.000012/ 12.027419, val:  74.58%, val_best:  77.08%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-83  lr=['0.1000000'], tr/val_loss:  0.000011/ 12.015459, val:  75.00%, val_best:  77.08%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-84  lr=['0.1000000'], tr/val_loss:  0.000011/ 12.005929, val:  75.00%, val_best:  77.08%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-85  lr=['0.1000000'], tr/val_loss:  0.000012/ 11.990171, val:  75.42%, val_best:  77.08%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-86  lr=['0.1000000'], tr/val_loss:  0.000009/ 11.998073, val:  74.58%, val_best:  77.08%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-87  lr=['0.1000000'], tr/val_loss:  0.000009/ 11.996169, val:  75.00%, val_best:  77.08%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-88  lr=['0.1000000'], tr/val_loss:  0.000011/ 12.000100, val:  75.42%, val_best:  77.08%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-89  lr=['0.1000000'], tr/val_loss:  0.000012/ 12.000065, val:  75.42%, val_best:  77.08%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-90  lr=['0.1000000'], tr/val_loss:  0.000010/ 12.000521, val:  75.42%, val_best:  77.08%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-91  lr=['0.1000000'], tr/val_loss:  0.000009/ 11.994939, val:  75.42%, val_best:  77.08%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-92  lr=['0.1000000'], tr/val_loss:  0.000009/ 12.002653, val:  75.42%, val_best:  77.08%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-93  lr=['0.1000000'], tr/val_loss:  0.000009/ 12.017251, val:  75.42%, val_best:  77.08%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-94  lr=['0.1000000'], tr/val_loss:  0.000010/ 12.010416, val:  75.42%, val_best:  77.08%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-95  lr=['0.1000000'], tr/val_loss:  0.000009/ 12.023741, val:  75.42%, val_best:  77.08%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-96  lr=['0.1000000'], tr/val_loss:  0.000008/ 12.022435, val:  75.42%, val_best:  77.08%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-97  lr=['0.1000000'], tr/val_loss:  0.000010/ 12.053812, val:  75.42%, val_best:  77.08%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-98  lr=['0.1000000'], tr/val_loss:  0.000008/ 12.042973, val:  75.42%, val_best:  77.08%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-99  lr=['0.1000000'], tr/val_loss:  0.000008/ 12.043391, val:  75.42%, val_best:  77.08%, tr: 100.00%, tr_best: 100.00%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "829d6419d61242c98f6d1cfaac7e63dc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.006 MB of 0.006 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>iter_acc</td><td>▁▄▄▄▄▅▆▅▅███████████████████████████████</td></tr><tr><td>summary_val_acc</td><td>▂▁▂▃▄▅▃▅▆▆▇▇▇▇▆██▇███▇█▇▇▇██▇███████████</td></tr><tr><td>tr_acc</td><td>▁▃▄▄▅▅▆▇▇▇██████████████████████████████</td></tr><tr><td>tr_epoch_loss</td><td>█▇▅▄▄▄▃▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_acc_best</td><td>▁▁▂▂▄▄▄▄▅▆▇▇▇███████████████████████████</td></tr><tr><td>val_acc_now</td><td>▂▁▂▃▄▅▃▅▆▆▇▇▇▇▆██▇███▇█▇▇▇██▇███████████</td></tr><tr><td>val_loss</td><td>▁█▂▄▁▃▇▂▁▂▂▁▂▁▂▁▁▁▁▁▁▁▁▁▁▁▁▁▂▂▂▂▂▂▂▂▂▂▂▂</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>99</td></tr><tr><td>iter_acc</td><td>1.0</td></tr><tr><td>tr_acc</td><td>1.0</td></tr><tr><td>tr_epoch_loss</td><td>1e-05</td></tr><tr><td>val_acc_best</td><td>0.77083</td></tr><tr><td>val_acc_now</td><td>0.75417</td></tr><tr><td>val_loss</td><td>12.04339</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">good-sweep-131</strong> at: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/ekgillcr' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/ekgillcr</a><br/> View project at: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>/data2/bh_wandb/wandb/run-20250430_022736-ekgillcr/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require(\"core\")`! See https://wandb.me/wandb-core for more information."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: wfodtxzz with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBATCH: 16\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBN_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBPTT_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tDFA_on: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tIMAGE_SIZE: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tOTTT_input_trace_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tTIME: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tUDA_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \talpha_uda: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbias: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcfg: ['M', 'M', 200, 200]\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tchaching_on: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tconvTrue_fcFalse: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdata_path: /data2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tddp_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdenoise_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdvs_clipping: 5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdvs_duration: 100000\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepoch_num: 100\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \texclude_class: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \textra_train_dataset: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlast_lif: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.001\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_sg_width: 5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_decay: 0.5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_init: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_reset: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_threshold: 0.75\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmerge_polarities: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmy_seed: 42\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnet_print: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_workers: 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer_what: SGD\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tpin_memory: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tpre_trained: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tpre_trained_path: net_save/save_now_net_weights_{unique_name}.pth\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \trate_coding: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tscheduler_name: no\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsingle_step: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsurrogate: hard_sigmoid\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_conv_kernel_size: 3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_conv_padding: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_conv_stride: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_trace_const1: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_trace_const2: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \ttdBN_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \ttrace_on: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \twhich_data: DVS_GESTURE_TONIC\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.19.10 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.17.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/data2/bh_wandb/wandb/run-20250430_023420-wfodtxzz</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/wfodtxzz' target=\"_blank\">wild-sweep-135</a></strong> to <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/6pj3lh8j' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/6pj3lh8j</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/6pj3lh8j' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/6pj3lh8j</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/wfodtxzz' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/wfodtxzz</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'single_step' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'my_seed' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'TIME' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BATCH' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'IMAGE_SIZE' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'which_data' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'data_path' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'rate_coding' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_init' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_decay' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_threshold' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_reset' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_sg_width' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_conv_kernel_size' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_conv_stride' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_conv_padding' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_trace_const1' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_trace_const2' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'pre_trained' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'convTrue_fcFalse' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'cfg' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'net_print' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'pre_trained_path' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'learning_rate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'epoch_num' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'tdBN_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BN_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'surrogate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BPTT_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'optimizer_what' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'scheduler_name' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'ddp_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'dvs_clipping' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'dvs_duration' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'DFA_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'trace_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'OTTT_input_trace_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'exclude_class' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'merge_polarities' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'denoise_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'extra_train_dataset' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'num_workers' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'chaching_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'pin_memory' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'UDA_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'alpha_uda' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'bias' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'last_lif' was locked by 'sweep' (ignored update).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "param {'devices': '0', 'single_step': True, 'unique_name': 'main', 'my_seed': 42, 'TIME': 10, 'BATCH': 16, 'IMAGE_SIZE': 128, 'which_data': 'DVS_GESTURE_TONIC', 'data_path': '/data2', 'rate_coding': False, 'lif_layer_v_init': 0, 'lif_layer_v_decay': 0.5, 'lif_layer_v_threshold': 0.75, 'lif_layer_v_reset': 0, 'lif_layer_sg_width': 5, 'synapse_conv_kernel_size': 3, 'synapse_conv_stride': 1, 'synapse_conv_padding': 1, 'synapse_trace_const1': 1, 'synapse_trace_const2': 0, 'pre_trained': False, 'convTrue_fcFalse': False, 'cfg': ['M', 'M', 200, 200], 'net_print': True, 'pre_trained_path': 'net_save/save_now_net_weights_{unique_name}.pth', 'learning_rate': 0.001, 'epoch_num': 100, 'tdBN_on': False, 'BN_on': False, 'surrogate': 'hard_sigmoid', 'BPTT_on': False, 'optimizer_what': 'SGD', 'scheduler_name': 'no', 'ddp_on': False, 'dvs_clipping': 5, 'dvs_duration': 100000, 'DFA_on': True, 'trace_on': True, 'OTTT_input_trace_on': False, 'exclude_class': True, 'merge_polarities': False, 'denoise_on': False, 'extra_train_dataset': 0, 'num_workers': 2, 'chaching_on': True, 'pin_memory': True, 'UDA_on': False, 'alpha_uda': 1, 'bias': True, 'last_lif': False, 'current epoch': 0} \n",
      "\n",
      "dataset_hash = ffa516e60c3efd5e0208f72b4c36cb84\n",
      "cache path exists\n",
      "\n",
      "device ==> cuda\n",
      "\n",
      "DataParallel(\n",
      "  (module): REBORN_MY_SNN_FC(\n",
      "    (layers): REBORN_MY_Sequential(\n",
      "      (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (2): DimChanger_for_FC()\n",
      "      (3): SYNAPSE_FC(in_features=2048, out_features=200, TIME=10, bias=True, sstep=True)\n",
      "      (4): LIF_layer(v_init=0, v_decay=0.5, v_threshold=0.75, v_reset=0, sg_width=5, surrogate=hard_sigmoid, BPTT_on=False, trace_const1=1, trace_const2=0, TIME=10, sstep=True, trace_on=True)\n",
      "      (5): Feedback_Receiver()\n",
      "      (6): SYNAPSE_FC(in_features=200, out_features=200, TIME=10, bias=True, sstep=True)\n",
      "      (7): LIF_layer(v_init=0, v_decay=0.5, v_threshold=0.75, v_reset=0, sg_width=5, surrogate=hard_sigmoid, BPTT_on=False, trace_const1=1, trace_const2=0, TIME=10, sstep=True, trace_on=True)\n",
      "      (8): Feedback_Receiver()\n",
      "      (9): SYNAPSE_FC(in_features=200, out_features=10, TIME=10, bias=True, sstep=True)\n",
      "      (DFA_top): Top_Gradient()\n",
      "    )\n",
      "  )\n",
      ")\n",
      "\n",
      "========================================================\n",
      "Trainable parameters: 452,010\n",
      "========================================================\n",
      "\n",
      "epoch-0   lr=['0.0010000'], tr/val_loss:  2.305556/  2.302845, val:  12.92%, val_best:  12.92%, tr:   8.38%, tr_best:   8.38%\n",
      "[module.layers.5] weight_fb parameter count: 2,000\n",
      "[module.layers.8] weight_fb parameter count: 2,000\n",
      "epoch-1   lr=['0.0010000'], tr/val_loss:  2.263766/  2.154740, val:  22.08%, val_best:  22.08%, tr:  16.55%, tr_best:  16.55%\n",
      "epoch-2   lr=['0.0010000'], tr/val_loss:  1.885490/  1.705470, val:  45.42%, val_best:  45.42%, tr:  37.79%, tr_best:  37.79%\n",
      "epoch-3   lr=['0.0010000'], tr/val_loss:  1.496928/  1.509260, val:  52.08%, val_best:  52.08%, tr:  57.10%, tr_best:  57.10%\n",
      "epoch-4   lr=['0.0010000'], tr/val_loss:  1.310701/  1.439118, val:  55.42%, val_best:  55.42%, tr:  59.96%, tr_best:  59.96%\n",
      "epoch-5   lr=['0.0010000'], tr/val_loss:  1.201161/  1.371513, val:  61.25%, val_best:  61.25%, tr:  62.72%, tr_best:  62.72%\n",
      "epoch-6   lr=['0.0010000'], tr/val_loss:  1.126292/  1.348183, val:  62.08%, val_best:  62.08%, tr:  66.29%, tr_best:  66.29%\n",
      "epoch-7   lr=['0.0010000'], tr/val_loss:  1.070513/  1.327026, val:  64.58%, val_best:  64.58%, tr:  68.03%, tr_best:  68.03%\n",
      "epoch-8   lr=['0.0010000'], tr/val_loss:  1.012841/  1.314156, val:  65.83%, val_best:  65.83%, tr:  71.50%, tr_best:  71.50%\n",
      "epoch-9   lr=['0.0010000'], tr/val_loss:  0.976865/  1.308702, val:  65.00%, val_best:  65.83%, tr:  74.06%, tr_best:  74.06%\n",
      "epoch-10  lr=['0.0010000'], tr/val_loss:  0.942935/  1.323732, val:  66.25%, val_best:  66.25%, tr:  73.34%, tr_best:  74.06%\n",
      "epoch-11  lr=['0.0010000'], tr/val_loss:  0.888255/  1.295269, val:  67.50%, val_best:  67.50%, tr:  75.49%, tr_best:  75.49%\n",
      "epoch-12  lr=['0.0010000'], tr/val_loss:  0.855727/  1.313784, val:  67.08%, val_best:  67.50%, tr:  81.41%, tr_best:  81.41%\n",
      "epoch-13  lr=['0.0010000'], tr/val_loss:  0.817468/  1.315862, val:  65.83%, val_best:  67.50%, tr:  85.60%, tr_best:  85.60%\n",
      "epoch-14  lr=['0.0010000'], tr/val_loss:  0.750636/  1.393205, val:  63.33%, val_best:  67.50%, tr:  85.60%, tr_best:  85.60%\n",
      "epoch-15  lr=['0.0010000'], tr/val_loss:  0.715184/  1.339783, val:  68.33%, val_best:  68.33%, tr:  88.66%, tr_best:  88.66%\n",
      "epoch-16  lr=['0.0010000'], tr/val_loss:  0.699183/  1.315670, val:  70.83%, val_best:  70.83%, tr:  88.36%, tr_best:  88.66%\n",
      "epoch-17  lr=['0.0010000'], tr/val_loss:  0.644326/  1.322773, val:  71.25%, val_best:  71.25%, tr:  92.44%, tr_best:  92.44%\n",
      "epoch-18  lr=['0.0010000'], tr/val_loss:  0.605336/  1.384381, val:  70.00%, val_best:  71.25%, tr:  94.89%, tr_best:  94.89%\n",
      "epoch-19  lr=['0.0010000'], tr/val_loss:  0.573508/  1.386921, val:  70.00%, val_best:  71.25%, tr:  93.26%, tr_best:  94.89%\n",
      "epoch-20  lr=['0.0010000'], tr/val_loss:  0.545125/  1.412572, val:  69.17%, val_best:  71.25%, tr:  96.02%, tr_best:  96.02%\n",
      "epoch-21  lr=['0.0010000'], tr/val_loss:  0.516208/  1.384804, val:  74.58%, val_best:  74.58%, tr:  95.71%, tr_best:  96.02%\n",
      "epoch-22  lr=['0.0010000'], tr/val_loss:  0.502910/  1.404380, val:  74.58%, val_best:  74.58%, tr:  96.42%, tr_best:  96.42%\n",
      "epoch-23  lr=['0.0010000'], tr/val_loss:  0.464424/  1.432034, val:  72.08%, val_best:  74.58%, tr:  97.14%, tr_best:  97.14%\n",
      "epoch-24  lr=['0.0010000'], tr/val_loss:  0.433610/  1.434762, val:  73.75%, val_best:  74.58%, tr:  97.75%, tr_best:  97.75%\n",
      "epoch-25  lr=['0.0010000'], tr/val_loss:  0.415654/  1.450040, val:  73.33%, val_best:  74.58%, tr:  98.26%, tr_best:  98.26%\n",
      "epoch-26  lr=['0.0010000'], tr/val_loss:  0.400696/  1.480359, val:  76.67%, val_best:  76.67%, tr:  97.96%, tr_best:  98.26%\n",
      "epoch-27  lr=['0.0010000'], tr/val_loss:  0.375122/  1.510037, val:  72.50%, val_best:  76.67%, tr:  98.67%, tr_best:  98.67%\n",
      "epoch-28  lr=['0.0010000'], tr/val_loss:  0.358875/  1.504218, val:  78.33%, val_best:  78.33%, tr:  99.08%, tr_best:  99.08%\n",
      "epoch-29  lr=['0.0010000'], tr/val_loss:  0.334702/  1.561414, val:  72.08%, val_best:  78.33%, tr:  99.59%, tr_best:  99.59%\n",
      "epoch-30  lr=['0.0010000'], tr/val_loss:  0.321069/  1.552360, val:  75.42%, val_best:  78.33%, tr:  99.59%, tr_best:  99.59%\n",
      "epoch-31  lr=['0.0010000'], tr/val_loss:  0.310076/  1.579463, val:  73.33%, val_best:  78.33%, tr:  99.18%, tr_best:  99.59%\n",
      "epoch-32  lr=['0.0010000'], tr/val_loss:  0.294127/  1.590584, val:  74.58%, val_best:  78.33%, tr:  99.69%, tr_best:  99.69%\n",
      "epoch-33  lr=['0.0010000'], tr/val_loss:  0.289672/  1.626788, val:  75.83%, val_best:  78.33%, tr:  99.69%, tr_best:  99.69%\n",
      "epoch-34  lr=['0.0010000'], tr/val_loss:  0.278322/  1.653531, val:  74.58%, val_best:  78.33%, tr:  99.59%, tr_best:  99.69%\n",
      "epoch-35  lr=['0.0010000'], tr/val_loss:  0.259108/  1.692173, val:  75.83%, val_best:  78.33%, tr:  99.90%, tr_best:  99.90%\n",
      "epoch-36  lr=['0.0010000'], tr/val_loss:  0.240057/  1.685400, val:  74.17%, val_best:  78.33%, tr:  99.90%, tr_best:  99.90%\n",
      "epoch-37  lr=['0.0010000'], tr/val_loss:  0.234377/  1.701345, val:  76.25%, val_best:  78.33%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-38  lr=['0.0010000'], tr/val_loss:  0.228273/  1.696924, val:  77.08%, val_best:  78.33%, tr:  99.80%, tr_best: 100.00%\n",
      "epoch-39  lr=['0.0010000'], tr/val_loss:  0.220954/  1.754593, val:  75.00%, val_best:  78.33%, tr:  99.90%, tr_best: 100.00%\n",
      "epoch-40  lr=['0.0010000'], tr/val_loss:  0.204100/  1.714965, val:  77.50%, val_best:  78.33%, tr:  99.90%, tr_best: 100.00%\n",
      "epoch-41  lr=['0.0010000'], tr/val_loss:  0.196747/  1.765358, val:  78.33%, val_best:  78.33%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-42  lr=['0.0010000'], tr/val_loss:  0.185884/  1.771588, val:  79.17%, val_best:  79.17%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-43  lr=['0.0010000'], tr/val_loss:  0.179757/  1.798597, val:  77.08%, val_best:  79.17%, tr:  99.90%, tr_best: 100.00%\n",
      "epoch-44  lr=['0.0010000'], tr/val_loss:  0.174974/  1.802826, val:  77.08%, val_best:  79.17%, tr:  99.90%, tr_best: 100.00%\n",
      "epoch-45  lr=['0.0010000'], tr/val_loss:  0.162350/  1.827425, val:  77.50%, val_best:  79.17%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-46  lr=['0.0010000'], tr/val_loss:  0.157029/  1.817256, val:  78.33%, val_best:  79.17%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-47  lr=['0.0010000'], tr/val_loss:  0.150227/  1.867510, val:  75.83%, val_best:  79.17%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-48  lr=['0.0010000'], tr/val_loss:  0.144907/  1.847909, val:  77.08%, val_best:  79.17%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-49  lr=['0.0010000'], tr/val_loss:  0.139544/  1.903321, val:  76.67%, val_best:  79.17%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-50  lr=['0.0010000'], tr/val_loss:  0.133935/  1.912388, val:  75.42%, val_best:  79.17%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-51  lr=['0.0010000'], tr/val_loss:  0.128711/  1.917707, val:  77.08%, val_best:  79.17%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-52  lr=['0.0010000'], tr/val_loss:  0.125111/  1.926323, val:  76.67%, val_best:  79.17%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-53  lr=['0.0010000'], tr/val_loss:  0.123086/  1.938478, val:  77.08%, val_best:  79.17%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-54  lr=['0.0010000'], tr/val_loss:  0.121757/  1.961923, val:  76.67%, val_best:  79.17%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-55  lr=['0.0010000'], tr/val_loss:  0.111358/  1.949156, val:  76.67%, val_best:  79.17%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-56  lr=['0.0010000'], tr/val_loss:  0.108524/  1.964612, val:  77.92%, val_best:  79.17%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-57  lr=['0.0010000'], tr/val_loss:  0.107198/  1.968116, val:  75.83%, val_best:  79.17%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-58  lr=['0.0010000'], tr/val_loss:  0.105020/  1.981641, val:  77.50%, val_best:  79.17%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-59  lr=['0.0010000'], tr/val_loss:  0.100399/  1.999368, val:  76.67%, val_best:  79.17%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-60  lr=['0.0010000'], tr/val_loss:  0.095689/  2.026248, val:  77.08%, val_best:  79.17%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-61  lr=['0.0010000'], tr/val_loss:  0.094791/  2.043657, val:  76.25%, val_best:  79.17%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-62  lr=['0.0010000'], tr/val_loss:  0.089549/  2.035276, val:  77.08%, val_best:  79.17%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-63  lr=['0.0010000'], tr/val_loss:  0.086856/  2.050670, val:  77.92%, val_best:  79.17%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-64  lr=['0.0010000'], tr/val_loss:  0.085374/  2.069440, val:  75.42%, val_best:  79.17%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-65  lr=['0.0010000'], tr/val_loss:  0.081170/  2.093857, val:  76.25%, val_best:  79.17%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-66  lr=['0.0010000'], tr/val_loss:  0.076770/  2.106162, val:  77.08%, val_best:  79.17%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-67  lr=['0.0010000'], tr/val_loss:  0.078877/  2.096823, val:  76.67%, val_best:  79.17%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-68  lr=['0.0010000'], tr/val_loss:  0.073592/  2.102940, val:  75.42%, val_best:  79.17%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-69  lr=['0.0010000'], tr/val_loss:  0.068802/  2.121709, val:  75.83%, val_best:  79.17%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-70  lr=['0.0010000'], tr/val_loss:  0.068448/  2.122125, val:  77.08%, val_best:  79.17%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-71  lr=['0.0010000'], tr/val_loss:  0.076842/  2.141906, val:  76.67%, val_best:  79.17%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-72  lr=['0.0010000'], tr/val_loss:  0.072268/  2.174127, val:  74.58%, val_best:  79.17%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-73  lr=['0.0010000'], tr/val_loss:  0.069524/  2.154786, val:  76.67%, val_best:  79.17%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-74  lr=['0.0010000'], tr/val_loss:  0.065119/  2.149030, val:  76.25%, val_best:  79.17%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-75  lr=['0.0010000'], tr/val_loss:  0.063754/  2.154294, val:  76.67%, val_best:  79.17%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-76  lr=['0.0010000'], tr/val_loss:  0.058743/  2.182219, val:  76.67%, val_best:  79.17%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-77  lr=['0.0010000'], tr/val_loss:  0.056830/  2.195374, val:  75.83%, val_best:  79.17%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-78  lr=['0.0010000'], tr/val_loss:  0.054598/  2.214274, val:  75.42%, val_best:  79.17%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-79  lr=['0.0010000'], tr/val_loss:  0.054145/  2.204888, val:  76.25%, val_best:  79.17%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-80  lr=['0.0010000'], tr/val_loss:  0.054445/  2.236289, val:  75.42%, val_best:  79.17%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-81  lr=['0.0010000'], tr/val_loss:  0.054761/  2.199287, val:  79.17%, val_best:  79.17%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-82  lr=['0.0010000'], tr/val_loss:  0.051141/  2.262040, val:  75.00%, val_best:  79.17%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-83  lr=['0.0010000'], tr/val_loss:  0.051564/  2.263546, val:  75.42%, val_best:  79.17%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-84  lr=['0.0010000'], tr/val_loss:  0.048997/  2.250212, val:  77.08%, val_best:  79.17%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-85  lr=['0.0010000'], tr/val_loss:  0.048529/  2.266531, val:  76.25%, val_best:  79.17%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-86  lr=['0.0010000'], tr/val_loss:  0.048223/  2.267744, val:  77.92%, val_best:  79.17%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-87  lr=['0.0010000'], tr/val_loss:  0.046823/  2.255083, val:  78.33%, val_best:  79.17%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-88  lr=['0.0010000'], tr/val_loss:  0.043295/  2.267275, val:  77.08%, val_best:  79.17%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-89  lr=['0.0010000'], tr/val_loss:  0.043717/  2.279205, val:  79.17%, val_best:  79.17%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-90  lr=['0.0010000'], tr/val_loss:  0.044222/  2.295482, val:  77.92%, val_best:  79.17%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-91  lr=['0.0010000'], tr/val_loss:  0.041080/  2.309826, val:  78.33%, val_best:  79.17%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-92  lr=['0.0010000'], tr/val_loss:  0.042644/  2.311989, val:  77.50%, val_best:  79.17%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-93  lr=['0.0010000'], tr/val_loss:  0.038871/  2.326326, val:  78.75%, val_best:  79.17%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-94  lr=['0.0010000'], tr/val_loss:  0.040670/  2.330789, val:  76.67%, val_best:  79.17%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-95  lr=['0.0010000'], tr/val_loss:  0.038812/  2.346979, val:  79.17%, val_best:  79.17%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-96  lr=['0.0010000'], tr/val_loss:  0.037197/  2.390273, val:  77.92%, val_best:  79.17%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-97  lr=['0.0010000'], tr/val_loss:  0.036459/  2.365963, val:  77.92%, val_best:  79.17%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-98  lr=['0.0010000'], tr/val_loss:  0.035770/  2.374951, val:  77.08%, val_best:  79.17%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-99  lr=['0.0010000'], tr/val_loss:  0.037723/  2.366655, val:  77.08%, val_best:  79.17%, tr: 100.00%, tr_best: 100.00%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "98a869bcab9c4d5bb07e05619f4441b8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.006 MB of 0.006 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>iter_acc</td><td>▁▅▅▅▅▆▇▆▇███████████████████████████████</td></tr><tr><td>summary_val_acc</td><td>▁▄▅▆▇▇▆▇▇█▇█▇███████████████████████████</td></tr><tr><td>tr_acc</td><td>▁▃▅▆▆▇▇▇▇███████████████████████████████</td></tr><tr><td>tr_epoch_loss</td><td>█▇▅▄▄▄▃▃▃▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_acc_best</td><td>▁▄▅▆▇▇▇▇▇███████████████████████████████</td></tr><tr><td>val_acc_now</td><td>▁▄▅▆▇▇▆▇▇█▇█▇███████████████████████████</td></tr><tr><td>val_loss</td><td>█▄▂▁▁▁▂▁▂▂▂▂▃▃▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇▇▇███</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>99</td></tr><tr><td>iter_acc</td><td>1.0</td></tr><tr><td>tr_acc</td><td>1.0</td></tr><tr><td>tr_epoch_loss</td><td>0.03772</td></tr><tr><td>val_acc_best</td><td>0.79167</td></tr><tr><td>val_acc_now</td><td>0.77083</td></tr><tr><td>val_loss</td><td>2.36665</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">wild-sweep-135</strong> at: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/wfodtxzz' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/wfodtxzz</a><br/> View project at: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>/data2/bh_wandb/wandb/run-20250430_023420-wfodtxzz/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require(\"core\")`! See https://wandb.me/wandb-core for more information."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: s5npenpw with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBATCH: 16\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBN_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBPTT_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tDFA_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tIMAGE_SIZE: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tOTTT_input_trace_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tTIME: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tUDA_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \talpha_uda: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbias: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcfg: ['M', 'M', 200, 200]\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tchaching_on: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tconvTrue_fcFalse: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdata_path: /data2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tddp_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdenoise_on: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdvs_clipping: 5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdvs_duration: 100000\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepoch_num: 100\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \texclude_class: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \textra_train_dataset: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlast_lif: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.001\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_sg_width: 4\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_decay: 0.5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_init: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_reset: 10000\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_threshold: 0.25\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmerge_polarities: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmy_seed: 42\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnet_print: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_workers: 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer_what: SGD\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tpin_memory: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tpre_trained: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tpre_trained_path: net_save/save_now_net_weights_{unique_name}.pth\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \trate_coding: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tscheduler_name: no\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsingle_step: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsurrogate: hard_sigmoid\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_conv_kernel_size: 3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_conv_padding: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_conv_stride: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_trace_const1: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_trace_const2: 0.5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \ttdBN_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \ttrace_on: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \twhich_data: DVS_GESTURE_TONIC\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.19.10 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.17.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/data2/bh_wandb/wandb/run-20250430_024112-s5npenpw</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/s5npenpw' target=\"_blank\">splendid-sweep-139</a></strong> to <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/6pj3lh8j' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/6pj3lh8j</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/6pj3lh8j' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/6pj3lh8j</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/s5npenpw' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/s5npenpw</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'single_step' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'my_seed' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'TIME' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BATCH' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'IMAGE_SIZE' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'which_data' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'data_path' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'rate_coding' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_init' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_decay' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_threshold' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_reset' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_sg_width' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_conv_kernel_size' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_conv_stride' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_conv_padding' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_trace_const1' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_trace_const2' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'pre_trained' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'convTrue_fcFalse' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'cfg' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'net_print' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'pre_trained_path' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'learning_rate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'epoch_num' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'tdBN_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BN_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'surrogate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BPTT_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'optimizer_what' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'scheduler_name' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'ddp_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'dvs_clipping' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'dvs_duration' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'DFA_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'trace_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'OTTT_input_trace_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'exclude_class' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'merge_polarities' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'denoise_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'extra_train_dataset' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'num_workers' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'chaching_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'pin_memory' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'UDA_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'alpha_uda' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'bias' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'last_lif' was locked by 'sweep' (ignored update).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "param {'devices': '0', 'single_step': True, 'unique_name': 'main', 'my_seed': 42, 'TIME': 10, 'BATCH': 16, 'IMAGE_SIZE': 128, 'which_data': 'DVS_GESTURE_TONIC', 'data_path': '/data2', 'rate_coding': False, 'lif_layer_v_init': 0, 'lif_layer_v_decay': 0.5, 'lif_layer_v_threshold': 0.25, 'lif_layer_v_reset': 10000, 'lif_layer_sg_width': 4, 'synapse_conv_kernel_size': 3, 'synapse_conv_stride': 1, 'synapse_conv_padding': 1, 'synapse_trace_const1': 1, 'synapse_trace_const2': 0.5, 'pre_trained': False, 'convTrue_fcFalse': False, 'cfg': ['M', 'M', 200, 200], 'net_print': True, 'pre_trained_path': 'net_save/save_now_net_weights_{unique_name}.pth', 'learning_rate': 0.001, 'epoch_num': 100, 'tdBN_on': False, 'BN_on': False, 'surrogate': 'hard_sigmoid', 'BPTT_on': False, 'optimizer_what': 'SGD', 'scheduler_name': 'no', 'ddp_on': False, 'dvs_clipping': 5, 'dvs_duration': 100000, 'DFA_on': False, 'trace_on': True, 'OTTT_input_trace_on': False, 'exclude_class': True, 'merge_polarities': False, 'denoise_on': True, 'extra_train_dataset': 0, 'num_workers': 2, 'chaching_on': True, 'pin_memory': True, 'UDA_on': False, 'alpha_uda': 1, 'bias': True, 'last_lif': False, 'current epoch': 0} \n",
      "\n",
      "dataset_hash = 63cc597115630ec173f3099200061e53\n",
      "cache path exists\n",
      "\n",
      "device ==> cuda\n",
      "\n",
      "DataParallel(\n",
      "  (module): REBORN_MY_SNN_FC(\n",
      "    (layers): REBORN_MY_Sequential(\n",
      "      (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (2): DimChanger_for_FC()\n",
      "      (3): SYNAPSE_FC(in_features=2048, out_features=200, TIME=10, bias=True, sstep=True)\n",
      "      (4): LIF_layer(v_init=0, v_decay=0.5, v_threshold=0.25, v_reset=10000, sg_width=4, surrogate=hard_sigmoid, BPTT_on=False, trace_const1=1, trace_const2=0.5, TIME=10, sstep=True, trace_on=True)\n",
      "      (5): SYNAPSE_FC(in_features=200, out_features=200, TIME=10, bias=True, sstep=True)\n",
      "      (6): LIF_layer(v_init=0, v_decay=0.5, v_threshold=0.25, v_reset=10000, sg_width=4, surrogate=hard_sigmoid, BPTT_on=False, trace_const1=1, trace_const2=0.5, TIME=10, sstep=True, trace_on=True)\n",
      "      (7): SYNAPSE_FC(in_features=200, out_features=10, TIME=10, bias=True, sstep=True)\n",
      "    )\n",
      "  )\n",
      ")\n",
      "\n",
      "========================================================\n",
      "Trainable parameters: 452,010\n",
      "========================================================\n",
      "\n",
      "epoch-0   lr=['0.0010000'], tr/val_loss:  2.164254/  1.881572, val:  43.75%, val_best:  43.75%, tr:  20.94%, tr_best:  20.94%\n",
      "epoch-1   lr=['0.0010000'], tr/val_loss:  1.572132/  1.582594, val:  53.75%, val_best:  53.75%, tr:  52.60%, tr_best:  52.60%\n",
      "epoch-2   lr=['0.0010000'], tr/val_loss:  1.347396/  1.507092, val:  56.67%, val_best:  56.67%, tr:  60.88%, tr_best:  60.88%\n",
      "epoch-3   lr=['0.0010000'], tr/val_loss:  1.190322/  1.532652, val:  61.25%, val_best:  61.25%, tr:  66.39%, tr_best:  66.39%\n",
      "epoch-4   lr=['0.0010000'], tr/val_loss:  1.092968/  1.451989, val:  59.58%, val_best:  61.25%, tr:  68.54%, tr_best:  68.54%\n",
      "epoch-5   lr=['0.0010000'], tr/val_loss:  1.051223/  1.408156, val:  62.08%, val_best:  62.08%, tr:  67.62%, tr_best:  68.54%\n",
      "epoch-6   lr=['0.0010000'], tr/val_loss:  0.973416/  1.394901, val:  62.08%, val_best:  62.08%, tr:  72.93%, tr_best:  72.93%\n",
      "epoch-7   lr=['0.0010000'], tr/val_loss:  0.921592/  1.395308, val:  61.67%, val_best:  62.08%, tr:  72.52%, tr_best:  72.93%\n",
      "epoch-8   lr=['0.0010000'], tr/val_loss:  0.901251/  1.429903, val:  62.92%, val_best:  62.92%, tr:  73.85%, tr_best:  73.85%\n",
      "epoch-9   lr=['0.0010000'], tr/val_loss:  0.838430/  1.453933, val:  67.08%, val_best:  67.08%, tr:  79.16%, tr_best:  79.16%\n",
      "epoch-10  lr=['0.0010000'], tr/val_loss:  0.819875/  1.502387, val:  61.25%, val_best:  67.08%, tr:  78.96%, tr_best:  79.16%\n",
      "epoch-11  lr=['0.0010000'], tr/val_loss:  0.758437/  1.447342, val:  69.17%, val_best:  69.17%, tr:  80.80%, tr_best:  80.80%\n",
      "epoch-12  lr=['0.0010000'], tr/val_loss:  0.764908/  1.408789, val:  72.50%, val_best:  72.50%, tr:  82.02%, tr_best:  82.02%\n",
      "epoch-13  lr=['0.0010000'], tr/val_loss:  0.735833/  1.550779, val:  64.58%, val_best:  72.50%, tr:  82.84%, tr_best:  82.84%\n",
      "epoch-14  lr=['0.0010000'], tr/val_loss:  0.671112/  2.001131, val:  66.25%, val_best:  72.50%, tr:  84.78%, tr_best:  84.78%\n",
      "epoch-15  lr=['0.0010000'], tr/val_loss:  0.681351/  1.735797, val:  66.67%, val_best:  72.50%, tr:  86.62%, tr_best:  86.62%\n",
      "epoch-16  lr=['0.0010000'], tr/val_loss:  0.610220/  1.719126, val:  72.92%, val_best:  72.92%, tr:  88.25%, tr_best:  88.25%\n",
      "epoch-17  lr=['0.0010000'], tr/val_loss:  0.610776/  1.727584, val:  72.50%, val_best:  72.92%, tr:  91.42%, tr_best:  91.42%\n",
      "epoch-18  lr=['0.0010000'], tr/val_loss:  0.570156/  1.897646, val:  65.00%, val_best:  72.92%, tr:  89.27%, tr_best:  91.42%\n",
      "epoch-19  lr=['0.0010000'], tr/val_loss:  0.585257/  1.967770, val:  65.42%, val_best:  72.92%, tr:  89.68%, tr_best:  91.42%\n",
      "epoch-20  lr=['0.0010000'], tr/val_loss:  0.543774/  2.114332, val:  63.75%, val_best:  72.92%, tr:  90.19%, tr_best:  91.42%\n",
      "epoch-21  lr=['0.0010000'], tr/val_loss:  0.497773/  2.095830, val:  64.58%, val_best:  72.92%, tr:  92.75%, tr_best:  92.75%\n",
      "epoch-22  lr=['0.0010000'], tr/val_loss:  0.473226/  2.228009, val:  71.67%, val_best:  72.92%, tr:  96.22%, tr_best:  96.22%\n",
      "epoch-23  lr=['0.0010000'], tr/val_loss:  0.520640/  2.183795, val:  70.83%, val_best:  72.92%, tr:  92.65%, tr_best:  96.22%\n",
      "epoch-24  lr=['0.0010000'], tr/val_loss:  0.405546/  2.347922, val:  70.00%, val_best:  72.92%, tr:  97.75%, tr_best:  97.75%\n",
      "epoch-25  lr=['0.0010000'], tr/val_loss:  0.395665/  2.146263, val:  72.50%, val_best:  72.92%, tr:  97.04%, tr_best:  97.75%\n",
      "epoch-26  lr=['0.0010000'], tr/val_loss:  0.391565/  2.272421, val:  71.25%, val_best:  72.92%, tr:  94.89%, tr_best:  97.75%\n",
      "epoch-27  lr=['0.0010000'], tr/val_loss:  0.364384/  2.395199, val:  74.17%, val_best:  74.17%, tr:  97.24%, tr_best:  97.75%\n",
      "epoch-28  lr=['0.0010000'], tr/val_loss:  0.314484/  2.296829, val:  78.33%, val_best:  78.33%, tr:  99.18%, tr_best:  99.18%\n",
      "epoch-29  lr=['0.0010000'], tr/val_loss:  0.291113/  2.429488, val:  68.75%, val_best:  78.33%, tr:  98.57%, tr_best:  99.18%\n",
      "epoch-30  lr=['0.0010000'], tr/val_loss:  0.267170/  2.329857, val:  77.08%, val_best:  78.33%, tr:  99.59%, tr_best:  99.59%\n",
      "epoch-31  lr=['0.0010000'], tr/val_loss:  0.246449/  2.525942, val:  75.00%, val_best:  78.33%, tr:  99.49%, tr_best:  99.59%\n",
      "epoch-32  lr=['0.0010000'], tr/val_loss:  0.297392/  2.569614, val:  77.08%, val_best:  78.33%, tr:  97.96%, tr_best:  99.59%\n",
      "epoch-33  lr=['0.0010000'], tr/val_loss:  0.275306/  2.703457, val:  72.08%, val_best:  78.33%, tr:  98.98%, tr_best:  99.59%\n",
      "epoch-34  lr=['0.0010000'], tr/val_loss:  0.271238/  2.667736, val:  77.92%, val_best:  78.33%, tr:  99.18%, tr_best:  99.59%\n",
      "epoch-35  lr=['0.0010000'], tr/val_loss:  0.242063/  2.696270, val:  75.00%, val_best:  78.33%, tr:  99.59%, tr_best:  99.59%\n",
      "epoch-36  lr=['0.0010000'], tr/val_loss:  0.215908/  2.592994, val:  77.08%, val_best:  78.33%, tr:  99.28%, tr_best:  99.59%\n",
      "epoch-37  lr=['0.0010000'], tr/val_loss:  0.200776/  2.823532, val:  75.00%, val_best:  78.33%, tr:  99.59%, tr_best:  99.59%\n",
      "epoch-38  lr=['0.0010000'], tr/val_loss:  0.225973/  2.888938, val:  75.00%, val_best:  78.33%, tr:  99.28%, tr_best:  99.59%\n",
      "epoch-39  lr=['0.0010000'], tr/val_loss:  0.207732/  2.815949, val:  72.50%, val_best:  78.33%, tr:  99.59%, tr_best:  99.59%\n",
      "epoch-40  lr=['0.0010000'], tr/val_loss:  0.189603/  2.770019, val:  77.08%, val_best:  78.33%, tr:  99.59%, tr_best:  99.59%\n",
      "epoch-41  lr=['0.0010000'], tr/val_loss:  0.151833/  2.954795, val:  73.75%, val_best:  78.33%, tr:  99.90%, tr_best:  99.90%\n",
      "epoch-42  lr=['0.0010000'], tr/val_loss:  0.152325/  2.875993, val:  78.33%, val_best:  78.33%, tr:  99.90%, tr_best:  99.90%\n",
      "epoch-43  lr=['0.0010000'], tr/val_loss:  0.148291/  2.894507, val:  76.67%, val_best:  78.33%, tr:  99.69%, tr_best:  99.90%\n",
      "epoch-44  lr=['0.0010000'], tr/val_loss:  0.161145/  2.927175, val:  74.58%, val_best:  78.33%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-45  lr=['0.0010000'], tr/val_loss:  0.124814/  2.914339, val:  77.08%, val_best:  78.33%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-46  lr=['0.0010000'], tr/val_loss:  0.117446/  3.031982, val:  78.33%, val_best:  78.33%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-47  lr=['0.0010000'], tr/val_loss:  0.096443/  3.032544, val:  77.92%, val_best:  78.33%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-48  lr=['0.0010000'], tr/val_loss:  0.122761/  3.047483, val:  77.08%, val_best:  78.33%, tr:  99.90%, tr_best: 100.00%\n",
      "epoch-49  lr=['0.0010000'], tr/val_loss:  0.095057/  3.150702, val:  76.25%, val_best:  78.33%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-50  lr=['0.0010000'], tr/val_loss:  0.079215/  3.183381, val:  74.58%, val_best:  78.33%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-51  lr=['0.0010000'], tr/val_loss:  0.070842/  3.127496, val:  75.83%, val_best:  78.33%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-52  lr=['0.0010000'], tr/val_loss:  0.063629/  3.146680, val:  77.50%, val_best:  78.33%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-53  lr=['0.0010000'], tr/val_loss:  0.053078/  3.230726, val:  77.08%, val_best:  78.33%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-54  lr=['0.0010000'], tr/val_loss:  0.066623/  3.196583, val:  78.75%, val_best:  78.75%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-55  lr=['0.0010000'], tr/val_loss:  0.081152/  3.176146, val:  77.50%, val_best:  78.75%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-56  lr=['0.0010000'], tr/val_loss:  0.054702/  3.316847, val:  77.50%, val_best:  78.75%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-57  lr=['0.0010000'], tr/val_loss:  0.046984/  3.340497, val:  76.67%, val_best:  78.75%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-58  lr=['0.0010000'], tr/val_loss:  0.062090/  3.406007, val:  74.58%, val_best:  78.75%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-59  lr=['0.0010000'], tr/val_loss:  0.053403/  3.365840, val:  76.25%, val_best:  78.75%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-60  lr=['0.0010000'], tr/val_loss:  0.051209/  3.365025, val:  77.08%, val_best:  78.75%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-61  lr=['0.0010000'], tr/val_loss:  0.042376/  3.393118, val:  78.33%, val_best:  78.75%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-62  lr=['0.0010000'], tr/val_loss:  0.047598/  3.451738, val:  76.25%, val_best:  78.75%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-63  lr=['0.0010000'], tr/val_loss:  0.034706/  3.426058, val:  80.83%, val_best:  80.83%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-64  lr=['0.0010000'], tr/val_loss:  0.042353/  3.515798, val:  80.00%, val_best:  80.83%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-65  lr=['0.0010000'], tr/val_loss:  0.038381/  3.480400, val:  79.58%, val_best:  80.83%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-66  lr=['0.0010000'], tr/val_loss:  0.053799/  3.494805, val:  78.33%, val_best:  80.83%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-67  lr=['0.0010000'], tr/val_loss:  0.048406/  3.544201, val:  78.33%, val_best:  80.83%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-68  lr=['0.0010000'], tr/val_loss:  0.040652/  3.477998, val:  78.75%, val_best:  80.83%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-69  lr=['0.0010000'], tr/val_loss:  0.035946/  3.549484, val:  75.83%, val_best:  80.83%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-70  lr=['0.0010000'], tr/val_loss:  0.036018/  3.599669, val:  77.50%, val_best:  80.83%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-71  lr=['0.0010000'], tr/val_loss:  0.039623/  3.613070, val:  76.25%, val_best:  80.83%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-72  lr=['0.0010000'], tr/val_loss:  0.032946/  3.636997, val:  75.00%, val_best:  80.83%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-73  lr=['0.0010000'], tr/val_loss:  0.031394/  3.688902, val:  73.75%, val_best:  80.83%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-74  lr=['0.0010000'], tr/val_loss:  0.030740/  3.652630, val:  78.33%, val_best:  80.83%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-75  lr=['0.0010000'], tr/val_loss:  0.027094/  3.663834, val:  77.08%, val_best:  80.83%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-76  lr=['0.0010000'], tr/val_loss:  0.024684/  3.664117, val:  78.33%, val_best:  80.83%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-77  lr=['0.0010000'], tr/val_loss:  0.022432/  3.657311, val:  78.33%, val_best:  80.83%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-78  lr=['0.0010000'], tr/val_loss:  0.022451/  3.740630, val:  77.92%, val_best:  80.83%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-79  lr=['0.0010000'], tr/val_loss:  0.028406/  3.772657, val:  78.33%, val_best:  80.83%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-80  lr=['0.0010000'], tr/val_loss:  0.028602/  3.716725, val:  74.17%, val_best:  80.83%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-81  lr=['0.0010000'], tr/val_loss:  0.025709/  3.765512, val:  76.25%, val_best:  80.83%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-82  lr=['0.0010000'], tr/val_loss:  0.024872/  3.704340, val:  75.83%, val_best:  80.83%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-83  lr=['0.0010000'], tr/val_loss:  0.023042/  3.774400, val:  76.25%, val_best:  80.83%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-84  lr=['0.0010000'], tr/val_loss:  0.018990/  3.746314, val:  77.92%, val_best:  80.83%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-85  lr=['0.0010000'], tr/val_loss:  0.024938/  3.754841, val:  77.92%, val_best:  80.83%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-86  lr=['0.0010000'], tr/val_loss:  0.028945/  3.749681, val:  74.58%, val_best:  80.83%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-87  lr=['0.0010000'], tr/val_loss:  0.022921/  3.748333, val:  78.75%, val_best:  80.83%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-88  lr=['0.0010000'], tr/val_loss:  0.026076/  3.785172, val:  75.42%, val_best:  80.83%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-89  lr=['0.0010000'], tr/val_loss:  0.022111/  3.796511, val:  75.83%, val_best:  80.83%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-90  lr=['0.0010000'], tr/val_loss:  0.022520/  3.804049, val:  76.25%, val_best:  80.83%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-91  lr=['0.0010000'], tr/val_loss:  0.022204/  3.853449, val:  75.00%, val_best:  80.83%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-92  lr=['0.0010000'], tr/val_loss:  0.019498/  3.831636, val:  76.25%, val_best:  80.83%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-93  lr=['0.0010000'], tr/val_loss:  0.018111/  3.781665, val:  75.83%, val_best:  80.83%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-94  lr=['0.0010000'], tr/val_loss:  0.016070/  3.818634, val:  74.17%, val_best:  80.83%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-95  lr=['0.0010000'], tr/val_loss:  0.011878/  3.862886, val:  77.08%, val_best:  80.83%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-96  lr=['0.0010000'], tr/val_loss:  0.011420/  3.913617, val:  73.75%, val_best:  80.83%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-97  lr=['0.0010000'], tr/val_loss:  0.014510/  3.882720, val:  77.92%, val_best:  80.83%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-98  lr=['0.0010000'], tr/val_loss:  0.010371/  3.858529, val:  75.42%, val_best:  80.83%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-99  lr=['0.0010000'], tr/val_loss:  0.010930/  3.968211, val:  74.17%, val_best:  80.83%, tr: 100.00%, tr_best: 100.00%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "040b4a98861d4877b623c746b95609b5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.006 MB of 0.006 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>iter_acc</td><td>▁▆▄▃▄▅▇▁████▇███████████████████████████</td></tr><tr><td>summary_val_acc</td><td>▁▄▄▅▆▇▅▇▅▅▆▆▆█▇▇▇█▇█▇██▇▇████▇███▇██▇▇██</td></tr><tr><td>tr_acc</td><td>▁▅▅▆▆▆▇▇▇▇██████████████████████████████</td></tr><tr><td>tr_epoch_loss</td><td>█▅▅▄▄▃▃▃▃▃▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_acc_best</td><td>▁▃▄▄▅▆▆▇▇▇▇▇████████████████████████████</td></tr><tr><td>val_acc_now</td><td>▁▄▄▅▆▇▅▇▅▅▆▆▆█▇▇▇█▇█▇██▇▇████▇███▇██▇▇██</td></tr><tr><td>val_loss</td><td>▂▁▁▁▁▁▃▂▃▃▄▃▄▄▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇▇▇█▇██████</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>99</td></tr><tr><td>iter_acc</td><td>1.0</td></tr><tr><td>tr_acc</td><td>1.0</td></tr><tr><td>tr_epoch_loss</td><td>0.01093</td></tr><tr><td>val_acc_best</td><td>0.80833</td></tr><tr><td>val_acc_now</td><td>0.74167</td></tr><tr><td>val_loss</td><td>3.96821</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">splendid-sweep-139</strong> at: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/s5npenpw' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/s5npenpw</a><br/> View project at: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>/data2/bh_wandb/wandb/run-20250430_024112-s5npenpw/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require(\"core\")`! See https://wandb.me/wandb-core for more information."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: rn63j6a2 with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBATCH: 16\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBN_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBPTT_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tDFA_on: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tIMAGE_SIZE: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tOTTT_input_trace_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tTIME: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tUDA_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \talpha_uda: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbias: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcfg: ['M', 'M', 200, 200]\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tchaching_on: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tconvTrue_fcFalse: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdata_path: /data2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tddp_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdenoise_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdvs_clipping: 5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdvs_duration: 100000\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepoch_num: 100\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \texclude_class: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \textra_train_dataset: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlast_lif: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.01\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_sg_width: 3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_decay: 0.5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_init: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_reset: 10000\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_threshold: 0.75\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmerge_polarities: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmy_seed: 42\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnet_print: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_workers: 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer_what: SGD\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tpin_memory: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tpre_trained: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tpre_trained_path: net_save/save_now_net_weights_{unique_name}.pth\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \trate_coding: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tscheduler_name: no\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsingle_step: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsurrogate: hard_sigmoid\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_conv_kernel_size: 3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_conv_padding: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_conv_stride: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_trace_const1: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_trace_const2: 0.5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \ttdBN_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \ttrace_on: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \twhich_data: DVS_GESTURE_TONIC\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0d57a67cc3fb441ebfb25f1030ee9935",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.011113573900527425, max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.19.10 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.17.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/data2/bh_wandb/wandb/run-20250430_024722-rn63j6a2</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/rn63j6a2' target=\"_blank\">splendid-sweep-142</a></strong> to <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/6pj3lh8j' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/6pj3lh8j</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/6pj3lh8j' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/6pj3lh8j</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/rn63j6a2' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/rn63j6a2</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'single_step' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'my_seed' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'TIME' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BATCH' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'IMAGE_SIZE' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'which_data' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'data_path' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'rate_coding' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_init' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_decay' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_threshold' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_reset' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_sg_width' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_conv_kernel_size' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_conv_stride' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_conv_padding' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_trace_const1' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_trace_const2' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'pre_trained' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'convTrue_fcFalse' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'cfg' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'net_print' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'pre_trained_path' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'learning_rate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'epoch_num' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'tdBN_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BN_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'surrogate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BPTT_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'optimizer_what' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'scheduler_name' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'ddp_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'dvs_clipping' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'dvs_duration' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'DFA_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'trace_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'OTTT_input_trace_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'exclude_class' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'merge_polarities' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'denoise_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'extra_train_dataset' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'num_workers' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'chaching_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'pin_memory' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'UDA_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'alpha_uda' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'bias' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'last_lif' was locked by 'sweep' (ignored update).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "param {'devices': '0', 'single_step': True, 'unique_name': 'main', 'my_seed': 42, 'TIME': 10, 'BATCH': 16, 'IMAGE_SIZE': 128, 'which_data': 'DVS_GESTURE_TONIC', 'data_path': '/data2', 'rate_coding': False, 'lif_layer_v_init': 0, 'lif_layer_v_decay': 0.5, 'lif_layer_v_threshold': 0.75, 'lif_layer_v_reset': 10000, 'lif_layer_sg_width': 3, 'synapse_conv_kernel_size': 3, 'synapse_conv_stride': 1, 'synapse_conv_padding': 1, 'synapse_trace_const1': 1, 'synapse_trace_const2': 0.5, 'pre_trained': False, 'convTrue_fcFalse': False, 'cfg': ['M', 'M', 200, 200], 'net_print': True, 'pre_trained_path': 'net_save/save_now_net_weights_{unique_name}.pth', 'learning_rate': 0.01, 'epoch_num': 100, 'tdBN_on': False, 'BN_on': False, 'surrogate': 'hard_sigmoid', 'BPTT_on': False, 'optimizer_what': 'SGD', 'scheduler_name': 'no', 'ddp_on': False, 'dvs_clipping': 5, 'dvs_duration': 100000, 'DFA_on': True, 'trace_on': True, 'OTTT_input_trace_on': False, 'exclude_class': True, 'merge_polarities': False, 'denoise_on': False, 'extra_train_dataset': 0, 'num_workers': 2, 'chaching_on': True, 'pin_memory': True, 'UDA_on': False, 'alpha_uda': 1, 'bias': True, 'last_lif': False, 'current epoch': 0} \n",
      "\n",
      "dataset_hash = ffa516e60c3efd5e0208f72b4c36cb84\n",
      "cache path exists\n",
      "\n",
      "device ==> cuda\n",
      "\n",
      "DataParallel(\n",
      "  (module): REBORN_MY_SNN_FC(\n",
      "    (layers): REBORN_MY_Sequential(\n",
      "      (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (2): DimChanger_for_FC()\n",
      "      (3): SYNAPSE_FC(in_features=2048, out_features=200, TIME=10, bias=True, sstep=True)\n",
      "      (4): LIF_layer(v_init=0, v_decay=0.5, v_threshold=0.75, v_reset=10000, sg_width=3, surrogate=hard_sigmoid, BPTT_on=False, trace_const1=1, trace_const2=0.5, TIME=10, sstep=True, trace_on=True)\n",
      "      (5): Feedback_Receiver()\n",
      "      (6): SYNAPSE_FC(in_features=200, out_features=200, TIME=10, bias=True, sstep=True)\n",
      "      (7): LIF_layer(v_init=0, v_decay=0.5, v_threshold=0.75, v_reset=10000, sg_width=3, surrogate=hard_sigmoid, BPTT_on=False, trace_const1=1, trace_const2=0.5, TIME=10, sstep=True, trace_on=True)\n",
      "      (8): Feedback_Receiver()\n",
      "      (9): SYNAPSE_FC(in_features=200, out_features=10, TIME=10, bias=True, sstep=True)\n",
      "      (DFA_top): Top_Gradient()\n",
      "    )\n",
      "  )\n",
      ")\n",
      "\n",
      "========================================================\n",
      "Trainable parameters: 452,010\n",
      "========================================================\n",
      "\n",
      "epoch-0   lr=['0.0100000'], tr/val_loss:  2.694544/  3.805519, val:  42.50%, val_best:  42.50%, tr:  28.80%, tr_best:  28.80%\n",
      "[module.layers.5] weight_fb parameter count: 2,000\n",
      "[module.layers.8] weight_fb parameter count: 2,000\n",
      "epoch-1   lr=['0.0100000'], tr/val_loss:  3.312109/  4.432952, val:  47.08%, val_best:  47.08%, tr:  45.05%, tr_best:  45.05%\n",
      "epoch-2   lr=['0.0100000'], tr/val_loss:  3.986693/  4.026708, val:  45.00%, val_best:  47.08%, tr:  53.73%, tr_best:  53.73%\n",
      "epoch-3   lr=['0.0100000'], tr/val_loss:  2.977188/  3.667457, val:  52.50%, val_best:  52.50%, tr:  60.06%, tr_best:  60.06%\n",
      "epoch-4   lr=['0.0100000'], tr/val_loss:  2.990889/  3.239479, val:  57.92%, val_best:  57.92%, tr:  60.27%, tr_best:  60.27%\n",
      "epoch-5   lr=['0.0100000'], tr/val_loss:  3.103380/  3.959674, val:  50.83%, val_best:  57.92%, tr:  64.86%, tr_best:  64.86%\n",
      "epoch-6   lr=['0.0100000'], tr/val_loss:  1.898196/  4.782052, val:  56.25%, val_best:  57.92%, tr:  73.24%, tr_best:  73.24%\n",
      "epoch-7   lr=['0.0100000'], tr/val_loss:  2.090890/  4.174212, val:  56.67%, val_best:  57.92%, tr:  75.28%, tr_best:  75.28%\n",
      "epoch-8   lr=['0.0100000'], tr/val_loss:  1.992949/  4.051721, val:  61.67%, val_best:  61.67%, tr:  78.14%, tr_best:  78.14%\n",
      "epoch-9   lr=['0.0100000'], tr/val_loss:  2.561722/  6.070878, val:  56.25%, val_best:  61.67%, tr:  78.04%, tr_best:  78.14%\n",
      "epoch-10  lr=['0.0100000'], tr/val_loss:  1.664795/  3.996760, val:  70.83%, val_best:  70.83%, tr:  87.54%, tr_best:  87.54%\n",
      "epoch-11  lr=['0.0100000'], tr/val_loss:  1.065776/  4.994032, val:  62.50%, val_best:  70.83%, tr:  92.85%, tr_best:  92.85%\n",
      "epoch-12  lr=['0.0100000'], tr/val_loss:  1.205041/  4.583380, val:  71.67%, val_best:  71.67%, tr:  93.36%, tr_best:  93.36%\n",
      "epoch-13  lr=['0.0100000'], tr/val_loss:  0.868652/  5.035664, val:  71.67%, val_best:  71.67%, tr:  96.42%, tr_best:  96.42%\n",
      "epoch-14  lr=['0.0100000'], tr/val_loss:  0.710452/  5.034282, val:  70.00%, val_best:  71.67%, tr:  96.63%, tr_best:  96.63%\n",
      "epoch-15  lr=['0.0100000'], tr/val_loss:  0.518047/  5.217741, val:  73.75%, val_best:  73.75%, tr:  98.98%, tr_best:  98.98%\n",
      "epoch-16  lr=['0.0100000'], tr/val_loss:  0.438436/  5.699828, val:  70.83%, val_best:  73.75%, tr:  99.39%, tr_best:  99.39%\n",
      "epoch-17  lr=['0.0100000'], tr/val_loss:  0.523471/  5.702260, val:  75.42%, val_best:  75.42%, tr:  98.77%, tr_best:  99.39%\n",
      "epoch-18  lr=['0.0100000'], tr/val_loss:  0.389615/  5.909686, val:  69.58%, val_best:  75.42%, tr:  99.08%, tr_best:  99.39%\n",
      "epoch-19  lr=['0.0100000'], tr/val_loss:  0.296645/  6.017022, val:  72.50%, val_best:  75.42%, tr:  99.69%, tr_best:  99.69%\n",
      "epoch-20  lr=['0.0100000'], tr/val_loss:  0.223208/  5.990305, val:  75.83%, val_best:  75.83%, tr:  99.90%, tr_best:  99.90%\n",
      "epoch-21  lr=['0.0100000'], tr/val_loss:  0.180023/  6.190241, val:  74.58%, val_best:  75.83%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-22  lr=['0.0100000'], tr/val_loss:  0.159938/  6.567724, val:  75.00%, val_best:  75.83%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-23  lr=['0.0100000'], tr/val_loss:  0.176728/  6.730443, val:  72.50%, val_best:  75.83%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-24  lr=['0.0100000'], tr/val_loss:  0.124799/  6.557050, val:  76.25%, val_best:  76.25%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-25  lr=['0.0100000'], tr/val_loss:  0.116422/  6.752952, val:  74.58%, val_best:  76.25%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-26  lr=['0.0100000'], tr/val_loss:  0.085541/  7.089267, val:  73.33%, val_best:  76.25%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-27  lr=['0.0100000'], tr/val_loss:  0.087489/  7.160729, val:  74.17%, val_best:  76.25%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-28  lr=['0.0100000'], tr/val_loss:  0.074645/  7.207530, val:  73.33%, val_best:  76.25%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-29  lr=['0.0100000'], tr/val_loss:  0.059803/  7.366837, val:  72.50%, val_best:  76.25%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-30  lr=['0.0100000'], tr/val_loss:  0.055908/  7.392697, val:  75.42%, val_best:  76.25%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-31  lr=['0.0100000'], tr/val_loss:  0.070933/  7.577066, val:  75.42%, val_best:  76.25%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-32  lr=['0.0100000'], tr/val_loss:  0.057576/  7.442228, val:  75.00%, val_best:  76.25%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-33  lr=['0.0100000'], tr/val_loss:  0.055219/  7.654403, val:  73.75%, val_best:  76.25%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-34  lr=['0.0100000'], tr/val_loss:  0.043518/  7.741630, val:  75.00%, val_best:  76.25%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-35  lr=['0.0100000'], tr/val_loss:  0.051795/  7.541318, val:  75.42%, val_best:  76.25%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-36  lr=['0.0100000'], tr/val_loss:  0.031647/  7.653456, val:  75.00%, val_best:  76.25%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-37  lr=['0.0100000'], tr/val_loss:  0.044118/  7.844872, val:  71.67%, val_best:  76.25%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-38  lr=['0.0100000'], tr/val_loss:  0.035702/  7.934246, val:  74.58%, val_best:  76.25%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-39  lr=['0.0100000'], tr/val_loss:  0.027460/  7.909952, val:  72.92%, val_best:  76.25%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-40  lr=['0.0100000'], tr/val_loss:  0.018754/  7.952971, val:  73.75%, val_best:  76.25%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-41  lr=['0.0100000'], tr/val_loss:  0.023580/  7.963618, val:  72.50%, val_best:  76.25%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-42  lr=['0.0100000'], tr/val_loss:  0.025014/  8.045490, val:  75.00%, val_best:  76.25%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-43  lr=['0.0100000'], tr/val_loss:  0.016891/  7.981803, val:  75.00%, val_best:  76.25%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-44  lr=['0.0100000'], tr/val_loss:  0.019640/  7.943579, val:  75.00%, val_best:  76.25%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-45  lr=['0.0100000'], tr/val_loss:  0.028811/  8.094025, val:  75.00%, val_best:  76.25%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-46  lr=['0.0100000'], tr/val_loss:  0.020884/  8.341908, val:  72.08%, val_best:  76.25%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-47  lr=['0.0100000'], tr/val_loss:  0.024027/  8.093962, val:  76.25%, val_best:  76.25%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-48  lr=['0.0100000'], tr/val_loss:  0.018010/  8.296474, val:  75.00%, val_best:  76.25%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-49  lr=['0.0100000'], tr/val_loss:  0.012921/  8.429425, val:  73.75%, val_best:  76.25%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-50  lr=['0.0100000'], tr/val_loss:  0.015150/  8.420845, val:  74.58%, val_best:  76.25%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-51  lr=['0.0100000'], tr/val_loss:  0.015004/  8.311805, val:  75.00%, val_best:  76.25%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-52  lr=['0.0100000'], tr/val_loss:  0.018645/  8.646666, val:  72.50%, val_best:  76.25%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-53  lr=['0.0100000'], tr/val_loss:  0.014890/  8.470858, val:  75.00%, val_best:  76.25%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-54  lr=['0.0100000'], tr/val_loss:  0.013097/  8.574300, val:  73.33%, val_best:  76.25%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-55  lr=['0.0100000'], tr/val_loss:  0.008809/  8.532976, val:  74.17%, val_best:  76.25%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-56  lr=['0.0100000'], tr/val_loss:  0.008139/  8.614706, val:  75.00%, val_best:  76.25%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-57  lr=['0.0100000'], tr/val_loss:  0.006079/  8.509520, val:  76.25%, val_best:  76.25%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-58  lr=['0.0100000'], tr/val_loss:  0.008493/  8.581823, val:  74.17%, val_best:  76.25%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-59  lr=['0.0100000'], tr/val_loss:  0.013797/  8.672886, val:  74.58%, val_best:  76.25%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-60  lr=['0.0100000'], tr/val_loss:  0.008187/  8.514098, val:  73.33%, val_best:  76.25%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-61  lr=['0.0100000'], tr/val_loss:  0.008583/  8.568426, val:  74.58%, val_best:  76.25%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-62  lr=['0.0100000'], tr/val_loss:  0.007740/  8.584705, val:  75.42%, val_best:  76.25%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-63  lr=['0.0100000'], tr/val_loss:  0.006499/  8.454751, val:  75.00%, val_best:  76.25%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-64  lr=['0.0100000'], tr/val_loss:  0.005618/  8.565534, val:  73.33%, val_best:  76.25%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-65  lr=['0.0100000'], tr/val_loss:  0.008411/  8.605082, val:  74.58%, val_best:  76.25%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-66  lr=['0.0100000'], tr/val_loss:  0.004047/  8.633473, val:  73.75%, val_best:  76.25%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-67  lr=['0.0100000'], tr/val_loss:  0.008729/  8.676265, val:  72.08%, val_best:  76.25%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-68  lr=['0.0100000'], tr/val_loss:  0.008806/  8.541054, val:  76.67%, val_best:  76.67%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-69  lr=['0.0100000'], tr/val_loss:  0.009837/  8.537827, val:  76.25%, val_best:  76.67%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-70  lr=['0.0100000'], tr/val_loss:  0.004014/  8.590634, val:  76.25%, val_best:  76.67%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-71  lr=['0.0100000'], tr/val_loss:  0.005986/  8.713404, val:  75.42%, val_best:  76.67%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-72  lr=['0.0100000'], tr/val_loss:  0.003878/  8.695256, val:  74.58%, val_best:  76.67%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-73  lr=['0.0100000'], tr/val_loss:  0.007394/  8.656956, val:  75.83%, val_best:  76.67%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-74  lr=['0.0100000'], tr/val_loss:  0.004332/  8.765077, val:  74.17%, val_best:  76.67%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-75  lr=['0.0100000'], tr/val_loss:  0.004067/  8.735644, val:  74.17%, val_best:  76.67%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-76  lr=['0.0100000'], tr/val_loss:  0.003759/  8.747123, val:  76.25%, val_best:  76.67%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-77  lr=['0.0100000'], tr/val_loss:  0.005522/  8.842199, val:  75.83%, val_best:  76.67%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-78  lr=['0.0100000'], tr/val_loss:  0.006927/  8.914425, val:  75.83%, val_best:  76.67%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-79  lr=['0.0100000'], tr/val_loss:  0.004989/  8.785088, val:  77.92%, val_best:  77.92%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-80  lr=['0.0100000'], tr/val_loss:  0.002626/  8.799291, val:  76.25%, val_best:  77.92%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-81  lr=['0.0100000'], tr/val_loss:  0.002700/  8.847234, val:  75.00%, val_best:  77.92%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-82  lr=['0.0100000'], tr/val_loss:  0.003885/  8.923069, val:  73.75%, val_best:  77.92%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-83  lr=['0.0100000'], tr/val_loss:  0.002900/  8.818846, val:  75.83%, val_best:  77.92%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-84  lr=['0.0100000'], tr/val_loss:  0.003113/  8.868052, val:  74.17%, val_best:  77.92%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-85  lr=['0.0100000'], tr/val_loss:  0.005197/  8.816546, val:  75.42%, val_best:  77.92%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-86  lr=['0.0100000'], tr/val_loss:  0.008596/  9.086205, val:  75.42%, val_best:  77.92%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-87  lr=['0.0100000'], tr/val_loss:  0.002184/  9.042097, val:  75.42%, val_best:  77.92%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-88  lr=['0.0100000'], tr/val_loss:  0.003031/  9.050373, val:  75.00%, val_best:  77.92%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-89  lr=['0.0100000'], tr/val_loss:  0.003268/  9.014643, val:  73.75%, val_best:  77.92%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-90  lr=['0.0100000'], tr/val_loss:  0.004788/  8.949382, val:  75.42%, val_best:  77.92%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-91  lr=['0.0100000'], tr/val_loss:  0.005386/  9.133723, val:  74.17%, val_best:  77.92%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-92  lr=['0.0100000'], tr/val_loss:  0.003890/  9.078559, val:  73.75%, val_best:  77.92%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-93  lr=['0.0100000'], tr/val_loss:  0.002331/  9.228193, val:  72.92%, val_best:  77.92%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-94  lr=['0.0100000'], tr/val_loss:  0.002226/  9.233840, val:  73.33%, val_best:  77.92%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-95  lr=['0.0100000'], tr/val_loss:  0.002751/  9.227590, val:  72.50%, val_best:  77.92%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-96  lr=['0.0100000'], tr/val_loss:  0.002207/  9.162080, val:  73.75%, val_best:  77.92%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-97  lr=['0.0100000'], tr/val_loss:  0.001394/  9.167070, val:  74.17%, val_best:  77.92%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-98  lr=['0.0100000'], tr/val_loss:  0.000624/  9.173352, val:  74.58%, val_best:  77.92%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-99  lr=['0.0100000'], tr/val_loss:  0.000601/  9.146782, val:  74.17%, val_best:  77.92%, tr: 100.00%, tr_best: 100.00%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "40356fa4175b407899e6b9510e64e3b5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.006 MB of 0.006 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>iter_acc</td><td>▁▃▃▅▆▆██████████████████████████████████</td></tr><tr><td>summary_val_acc</td><td>▁▁▄▄▄▇▆█▇▇█▇▇▇█▇▇▇▇█▇▇▇█▇▇▇▇█▇▇██▇▇█▇▇▇▇</td></tr><tr><td>tr_acc</td><td>▁▃▄▆▆▇██████████████████████████████████</td></tr><tr><td>tr_epoch_loss</td><td>▆█▆▅▅▃▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_acc_best</td><td>▁▂▄▄▅▇▇█████████████████████████████████</td></tr><tr><td>val_acc_now</td><td>▁▁▄▄▄▇▆█▇▇█▇▇▇█▇▇▇▇█▇▇▇█▇▇▇▇█▇▇██▇▇█▇▇▇▇</td></tr><tr><td>val_loss</td><td>▂▂▁▂▄▃▃▄▄▄▅▆▆▆▆▆▆▇▆▇▇▇▇▇▇▇▇▇▇▇▇█▇███████</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>99</td></tr><tr><td>iter_acc</td><td>1.0</td></tr><tr><td>tr_acc</td><td>1.0</td></tr><tr><td>tr_epoch_loss</td><td>0.0006</td></tr><tr><td>val_acc_best</td><td>0.77917</td></tr><tr><td>val_acc_now</td><td>0.74167</td></tr><tr><td>val_loss</td><td>9.14678</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">splendid-sweep-142</strong> at: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/rn63j6a2' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/rn63j6a2</a><br/> View project at: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>/data2/bh_wandb/wandb/run-20250430_024722-rn63j6a2/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require(\"core\")`! See https://wandb.me/wandb-core for more information."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Sweep Agent: Waiting for job.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Job received.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: um9g8tdz with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBATCH: 16\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBN_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBPTT_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tDFA_on: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tIMAGE_SIZE: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tOTTT_input_trace_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tTIME: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tUDA_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \talpha_uda: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbias: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcfg: ['M', 'M', 200, 200]\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tchaching_on: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tconvTrue_fcFalse: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdata_path: /data2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tddp_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdenoise_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdvs_clipping: 5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdvs_duration: 100000\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepoch_num: 100\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \texclude_class: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \textra_train_dataset: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlast_lif: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.001\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_sg_width: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_decay: 0.5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_init: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_reset: 10000\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_threshold: 0.75\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmerge_polarities: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmy_seed: 42\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnet_print: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_workers: 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer_what: SGD\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tpin_memory: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tpre_trained: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tpre_trained_path: net_save/save_now_net_weights_{unique_name}.pth\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \trate_coding: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tscheduler_name: no\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsingle_step: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsurrogate: hard_sigmoid\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_conv_kernel_size: 3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_conv_padding: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_conv_stride: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_trace_const1: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_trace_const2: 0.5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \ttdBN_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \ttrace_on: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \twhich_data: DVS_GESTURE_TONIC\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.19.10 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.17.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/data2/bh_wandb/wandb/run-20250430_025401-um9g8tdz</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/um9g8tdz' target=\"_blank\">grateful-sweep-146</a></strong> to <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/6pj3lh8j' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/6pj3lh8j</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/6pj3lh8j' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/6pj3lh8j</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/um9g8tdz' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/um9g8tdz</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'single_step' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'my_seed' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'TIME' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BATCH' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'IMAGE_SIZE' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'which_data' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'data_path' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'rate_coding' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_init' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_decay' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_threshold' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_reset' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_sg_width' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_conv_kernel_size' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_conv_stride' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_conv_padding' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_trace_const1' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_trace_const2' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'pre_trained' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'convTrue_fcFalse' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'cfg' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'net_print' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'pre_trained_path' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'learning_rate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'epoch_num' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'tdBN_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BN_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'surrogate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BPTT_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'optimizer_what' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'scheduler_name' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'ddp_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'dvs_clipping' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'dvs_duration' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'DFA_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'trace_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'OTTT_input_trace_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'exclude_class' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'merge_polarities' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'denoise_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'extra_train_dataset' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'num_workers' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'chaching_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'pin_memory' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'UDA_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'alpha_uda' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'bias' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'last_lif' was locked by 'sweep' (ignored update).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "param {'devices': '0', 'single_step': True, 'unique_name': 'main', 'my_seed': 42, 'TIME': 10, 'BATCH': 16, 'IMAGE_SIZE': 128, 'which_data': 'DVS_GESTURE_TONIC', 'data_path': '/data2', 'rate_coding': False, 'lif_layer_v_init': 0, 'lif_layer_v_decay': 0.5, 'lif_layer_v_threshold': 0.75, 'lif_layer_v_reset': 10000, 'lif_layer_sg_width': 1, 'synapse_conv_kernel_size': 3, 'synapse_conv_stride': 1, 'synapse_conv_padding': 1, 'synapse_trace_const1': 1, 'synapse_trace_const2': 0.5, 'pre_trained': False, 'convTrue_fcFalse': False, 'cfg': ['M', 'M', 200, 200], 'net_print': True, 'pre_trained_path': 'net_save/save_now_net_weights_{unique_name}.pth', 'learning_rate': 0.001, 'epoch_num': 100, 'tdBN_on': False, 'BN_on': False, 'surrogate': 'hard_sigmoid', 'BPTT_on': False, 'optimizer_what': 'SGD', 'scheduler_name': 'no', 'ddp_on': False, 'dvs_clipping': 5, 'dvs_duration': 100000, 'DFA_on': True, 'trace_on': True, 'OTTT_input_trace_on': False, 'exclude_class': True, 'merge_polarities': False, 'denoise_on': False, 'extra_train_dataset': 0, 'num_workers': 2, 'chaching_on': True, 'pin_memory': True, 'UDA_on': False, 'alpha_uda': 1, 'bias': True, 'last_lif': False, 'current epoch': 0} \n",
      "\n",
      "dataset_hash = ffa516e60c3efd5e0208f72b4c36cb84\n",
      "cache path exists\n",
      "\n",
      "device ==> cuda\n",
      "\n",
      "DataParallel(\n",
      "  (module): REBORN_MY_SNN_FC(\n",
      "    (layers): REBORN_MY_Sequential(\n",
      "      (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (2): DimChanger_for_FC()\n",
      "      (3): SYNAPSE_FC(in_features=2048, out_features=200, TIME=10, bias=True, sstep=True)\n",
      "      (4): LIF_layer(v_init=0, v_decay=0.5, v_threshold=0.75, v_reset=10000, sg_width=1, surrogate=hard_sigmoid, BPTT_on=False, trace_const1=1, trace_const2=0.5, TIME=10, sstep=True, trace_on=True)\n",
      "      (5): Feedback_Receiver()\n",
      "      (6): SYNAPSE_FC(in_features=200, out_features=200, TIME=10, bias=True, sstep=True)\n",
      "      (7): LIF_layer(v_init=0, v_decay=0.5, v_threshold=0.75, v_reset=10000, sg_width=1, surrogate=hard_sigmoid, BPTT_on=False, trace_const1=1, trace_const2=0.5, TIME=10, sstep=True, trace_on=True)\n",
      "      (8): Feedback_Receiver()\n",
      "      (9): SYNAPSE_FC(in_features=200, out_features=10, TIME=10, bias=True, sstep=True)\n",
      "      (DFA_top): Top_Gradient()\n",
      "    )\n",
      "  )\n",
      ")\n",
      "\n",
      "========================================================\n",
      "Trainable parameters: 452,010\n",
      "========================================================\n",
      "\n",
      "epoch-0   lr=['0.0010000'], tr/val_loss:  2.305352/  2.302666, val:  11.67%, val_best:  11.67%, tr:   8.38%, tr_best:   8.38%\n",
      "[module.layers.5] weight_fb parameter count: 2,000\n",
      "[module.layers.8] weight_fb parameter count: 2,000\n",
      "epoch-1   lr=['0.0010000'], tr/val_loss:  2.291000/  2.238244, val:  16.67%, val_best:  16.67%, tr:  12.67%, tr_best:  12.67%\n",
      "epoch-2   lr=['0.0010000'], tr/val_loss:  2.019721/  1.895404, val:  43.33%, val_best:  43.33%, tr:  30.34%, tr_best:  30.34%\n",
      "epoch-3   lr=['0.0010000'], tr/val_loss:  1.676060/  1.719729, val:  49.58%, val_best:  49.58%, tr:  51.38%, tr_best:  51.38%\n",
      "epoch-4   lr=['0.0010000'], tr/val_loss:  1.549754/  1.688392, val:  52.08%, val_best:  52.08%, tr:  56.79%, tr_best:  56.79%\n",
      "epoch-5   lr=['0.0010000'], tr/val_loss:  1.485119/  1.647201, val:  54.17%, val_best:  54.17%, tr:  57.20%, tr_best:  57.20%\n",
      "epoch-6   lr=['0.0010000'], tr/val_loss:  1.452062/  1.631100, val:  56.67%, val_best:  56.67%, tr:  60.16%, tr_best:  60.16%\n",
      "epoch-7   lr=['0.0010000'], tr/val_loss:  1.424407/  1.621793, val:  57.08%, val_best:  57.08%, tr:  59.96%, tr_best:  60.16%\n",
      "epoch-8   lr=['0.0010000'], tr/val_loss:  1.394216/  1.619866, val:  59.58%, val_best:  59.58%, tr:  62.31%, tr_best:  62.31%\n",
      "epoch-9   lr=['0.0010000'], tr/val_loss:  1.380970/  1.609393, val:  59.17%, val_best:  59.58%, tr:  63.74%, tr_best:  63.74%\n",
      "epoch-10  lr=['0.0010000'], tr/val_loss:  1.373238/  1.626788, val:  60.42%, val_best:  60.42%, tr:  63.43%, tr_best:  63.74%\n",
      "epoch-11  lr=['0.0010000'], tr/val_loss:  1.350673/  1.593736, val:  60.83%, val_best:  60.83%, tr:  64.66%, tr_best:  64.66%\n",
      "epoch-12  lr=['0.0010000'], tr/val_loss:  1.345445/  1.611862, val:  60.42%, val_best:  60.83%, tr:  66.50%, tr_best:  66.50%\n",
      "epoch-13  lr=['0.0010000'], tr/val_loss:  1.343207/  1.641777, val:  60.83%, val_best:  60.83%, tr:  65.68%, tr_best:  66.50%\n",
      "epoch-14  lr=['0.0010000'], tr/val_loss:  1.294041/  1.742633, val:  57.08%, val_best:  60.83%, tr:  67.52%, tr_best:  67.52%\n",
      "epoch-15  lr=['0.0010000'], tr/val_loss:  1.298627/  1.634061, val:  66.67%, val_best:  66.67%, tr:  70.48%, tr_best:  70.48%\n",
      "epoch-16  lr=['0.0010000'], tr/val_loss:  1.304512/  1.671097, val:  60.42%, val_best:  66.67%, tr:  68.74%, tr_best:  70.48%\n",
      "epoch-17  lr=['0.0010000'], tr/val_loss:  1.280349/  1.659420, val:  63.75%, val_best:  66.67%, tr:  72.01%, tr_best:  72.01%\n",
      "epoch-18  lr=['0.0010000'], tr/val_loss:  1.272483/  1.746020, val:  62.92%, val_best:  66.67%, tr:  70.68%, tr_best:  72.01%\n",
      "epoch-19  lr=['0.0010000'], tr/val_loss:  1.275153/  1.760296, val:  59.58%, val_best:  66.67%, tr:  71.40%, tr_best:  72.01%\n",
      "epoch-20  lr=['0.0010000'], tr/val_loss:  1.265674/  1.770445, val:  63.75%, val_best:  66.67%, tr:  72.73%, tr_best:  72.73%\n",
      "epoch-21  lr=['0.0010000'], tr/val_loss:  1.270551/  1.782897, val:  65.42%, val_best:  66.67%, tr:  73.95%, tr_best:  73.95%\n",
      "epoch-22  lr=['0.0010000'], tr/val_loss:  1.280797/  1.831736, val:  60.83%, val_best:  66.67%, tr:  73.44%, tr_best:  73.95%\n",
      "epoch-23  lr=['0.0010000'], tr/val_loss:  1.224959/  1.832835, val:  62.08%, val_best:  66.67%, tr:  76.00%, tr_best:  76.00%\n",
      "epoch-24  lr=['0.0010000'], tr/val_loss:  1.229332/  1.913006, val:  62.50%, val_best:  66.67%, tr:  77.22%, tr_best:  77.22%\n",
      "epoch-25  lr=['0.0010000'], tr/val_loss:  1.240600/  1.867247, val:  68.75%, val_best:  68.75%, tr:  76.81%, tr_best:  77.22%\n",
      "epoch-26  lr=['0.0010000'], tr/val_loss:  1.236686/  1.863925, val:  67.08%, val_best:  68.75%, tr:  77.94%, tr_best:  77.94%\n",
      "epoch-27  lr=['0.0010000'], tr/val_loss:  1.231740/  1.991286, val:  63.75%, val_best:  68.75%, tr:  78.75%, tr_best:  78.75%\n",
      "epoch-28  lr=['0.0010000'], tr/val_loss:  1.233746/  1.961849, val:  68.75%, val_best:  68.75%, tr:  79.47%, tr_best:  79.47%\n",
      "epoch-29  lr=['0.0010000'], tr/val_loss:  1.209592/  2.082444, val:  64.58%, val_best:  68.75%, tr:  80.49%, tr_best:  80.49%\n",
      "epoch-30  lr=['0.0010000'], tr/val_loss:  1.204179/  2.143058, val:  62.08%, val_best:  68.75%, tr:  83.35%, tr_best:  83.35%\n",
      "epoch-31  lr=['0.0010000'], tr/val_loss:  1.246820/  2.157331, val:  63.75%, val_best:  68.75%, tr:  80.18%, tr_best:  83.35%\n",
      "epoch-32  lr=['0.0010000'], tr/val_loss:  1.238074/  2.184934, val:  65.42%, val_best:  68.75%, tr:  81.31%, tr_best:  83.35%\n",
      "epoch-33  lr=['0.0010000'], tr/val_loss:  1.237233/  2.227991, val:  66.67%, val_best:  68.75%, tr:  82.74%, tr_best:  83.35%\n",
      "epoch-34  lr=['0.0010000'], tr/val_loss:  1.218516/  2.282267, val:  61.67%, val_best:  68.75%, tr:  84.88%, tr_best:  84.88%\n",
      "epoch-35  lr=['0.0010000'], tr/val_loss:  1.254595/  2.421817, val:  61.67%, val_best:  68.75%, tr:  80.49%, tr_best:  84.88%\n",
      "epoch-36  lr=['0.0010000'], tr/val_loss:  1.231102/  2.374397, val:  62.92%, val_best:  68.75%, tr:  84.07%, tr_best:  84.88%\n",
      "epoch-37  lr=['0.0010000'], tr/val_loss:  1.246766/  2.392906, val:  65.00%, val_best:  68.75%, tr:  84.78%, tr_best:  84.88%\n",
      "epoch-38  lr=['0.0010000'], tr/val_loss:  1.245117/  2.445349, val:  65.42%, val_best:  68.75%, tr:  86.31%, tr_best:  86.31%\n",
      "epoch-39  lr=['0.0010000'], tr/val_loss:  1.256379/  2.520648, val:  66.25%, val_best:  68.75%, tr:  87.03%, tr_best:  87.03%\n",
      "epoch-40  lr=['0.0010000'], tr/val_loss:  1.262652/  2.592531, val:  66.25%, val_best:  68.75%, tr:  86.21%, tr_best:  87.03%\n",
      "epoch-41  lr=['0.0010000'], tr/val_loss:  1.277169/  2.678485, val:  61.25%, val_best:  68.75%, tr:  87.64%, tr_best:  87.64%\n",
      "epoch-42  lr=['0.0010000'], tr/val_loss:  1.250988/  2.646416, val:  65.83%, val_best:  68.75%, tr:  88.97%, tr_best:  88.97%\n",
      "epoch-43  lr=['0.0010000'], tr/val_loss:  1.263422/  2.722022, val:  64.58%, val_best:  68.75%, tr:  88.76%, tr_best:  88.97%\n",
      "epoch-44  lr=['0.0010000'], tr/val_loss:  1.250061/  2.752165, val:  65.00%, val_best:  68.75%, tr:  89.89%, tr_best:  89.89%\n",
      "epoch-45  lr=['0.0010000'], tr/val_loss:  1.246642/  2.811404, val:  65.83%, val_best:  68.75%, tr:  89.48%, tr_best:  89.89%\n",
      "epoch-46  lr=['0.0010000'], tr/val_loss:  1.261109/  2.902057, val:  66.67%, val_best:  68.75%, tr:  89.99%, tr_best:  89.99%\n",
      "epoch-47  lr=['0.0010000'], tr/val_loss:  1.258367/  2.907105, val:  67.08%, val_best:  68.75%, tr:  90.91%, tr_best:  90.91%\n",
      "epoch-48  lr=['0.0010000'], tr/val_loss:  1.304595/  2.966496, val:  65.42%, val_best:  68.75%, tr:  91.62%, tr_best:  91.62%\n",
      "epoch-49  lr=['0.0010000'], tr/val_loss:  1.291531/  3.015284, val:  66.25%, val_best:  68.75%, tr:  90.40%, tr_best:  91.62%\n",
      "epoch-50  lr=['0.0010000'], tr/val_loss:  1.293955/  3.141480, val:  62.92%, val_best:  68.75%, tr:  91.32%, tr_best:  91.62%\n",
      "epoch-51  lr=['0.0010000'], tr/val_loss:  1.337783/  3.166044, val:  67.50%, val_best:  68.75%, tr:  89.79%, tr_best:  91.62%\n",
      "epoch-52  lr=['0.0010000'], tr/val_loss:  1.295871/  3.243957, val:  64.17%, val_best:  68.75%, tr:  92.54%, tr_best:  92.54%\n",
      "epoch-53  lr=['0.0010000'], tr/val_loss:  1.313455/  3.284660, val:  67.92%, val_best:  68.75%, tr:  92.03%, tr_best:  92.54%\n",
      "epoch-54  lr=['0.0010000'], tr/val_loss:  1.317765/  3.376307, val:  68.75%, val_best:  68.75%, tr:  92.34%, tr_best:  92.54%\n",
      "epoch-55  lr=['0.0010000'], tr/val_loss:  1.329301/  3.479470, val:  68.75%, val_best:  68.75%, tr:  91.73%, tr_best:  92.54%\n",
      "epoch-56  lr=['0.0010000'], tr/val_loss:  1.322903/  3.581122, val:  66.25%, val_best:  68.75%, tr:  93.77%, tr_best:  93.77%\n",
      "epoch-57  lr=['0.0010000'], tr/val_loss:  1.353824/  3.536725, val:  67.08%, val_best:  68.75%, tr:  92.44%, tr_best:  93.77%\n",
      "epoch-58  lr=['0.0010000'], tr/val_loss:  1.347081/  3.651284, val:  69.17%, val_best:  69.17%, tr:  91.42%, tr_best:  93.77%\n",
      "epoch-59  lr=['0.0010000'], tr/val_loss:  1.345018/  3.671752, val:  70.42%, val_best:  70.42%, tr:  93.67%, tr_best:  93.77%\n",
      "epoch-60  lr=['0.0010000'], tr/val_loss:  1.352741/  3.685092, val:  72.08%, val_best:  72.08%, tr:  93.67%, tr_best:  93.77%\n",
      "epoch-61  lr=['0.0010000'], tr/val_loss:  1.362739/  3.805773, val:  65.83%, val_best:  72.08%, tr:  94.18%, tr_best:  94.18%\n",
      "epoch-62  lr=['0.0010000'], tr/val_loss:  1.401058/  3.900979, val:  64.58%, val_best:  72.08%, tr:  93.67%, tr_best:  94.18%\n",
      "epoch-63  lr=['0.0010000'], tr/val_loss:  1.340815/  3.883210, val:  67.08%, val_best:  72.08%, tr:  94.99%, tr_best:  94.99%\n",
      "epoch-64  lr=['0.0010000'], tr/val_loss:  1.388240/  4.041090, val:  68.33%, val_best:  72.08%, tr:  92.95%, tr_best:  94.99%\n",
      "epoch-65  lr=['0.0010000'], tr/val_loss:  1.374563/  4.017573, val:  66.67%, val_best:  72.08%, tr:  93.97%, tr_best:  94.99%\n",
      "epoch-66  lr=['0.0010000'], tr/val_loss:  1.376930/  4.108985, val:  67.08%, val_best:  72.08%, tr:  94.28%, tr_best:  94.99%\n",
      "epoch-67  lr=['0.0010000'], tr/val_loss:  1.421473/  4.139065, val:  67.08%, val_best:  72.08%, tr:  94.38%, tr_best:  94.99%\n",
      "epoch-68  lr=['0.0010000'], tr/val_loss:  1.397636/  4.332170, val:  67.92%, val_best:  72.08%, tr:  94.48%, tr_best:  94.99%\n",
      "epoch-69  lr=['0.0010000'], tr/val_loss:  1.441104/  4.307713, val:  65.42%, val_best:  72.08%, tr:  93.56%, tr_best:  94.99%\n",
      "epoch-70  lr=['0.0010000'], tr/val_loss:  1.403979/  4.325988, val:  69.17%, val_best:  72.08%, tr:  95.40%, tr_best:  95.40%\n",
      "epoch-71  lr=['0.0010000'], tr/val_loss:  1.416526/  4.479855, val:  65.83%, val_best:  72.08%, tr:  94.18%, tr_best:  95.40%\n",
      "epoch-72  lr=['0.0010000'], tr/val_loss:  1.418312/  4.519227, val:  67.50%, val_best:  72.08%, tr:  95.10%, tr_best:  95.40%\n",
      "epoch-73  lr=['0.0010000'], tr/val_loss:  1.454190/  4.434769, val:  70.42%, val_best:  72.08%, tr:  94.28%, tr_best:  95.40%\n",
      "epoch-74  lr=['0.0010000'], tr/val_loss:  1.387105/  4.549036, val:  70.42%, val_best:  72.08%, tr:  95.81%, tr_best:  95.81%\n",
      "epoch-75  lr=['0.0010000'], tr/val_loss:  1.432407/  4.673056, val:  65.83%, val_best:  72.08%, tr:  94.48%, tr_best:  95.81%\n",
      "epoch-76  lr=['0.0010000'], tr/val_loss:  1.396946/  4.854704, val:  66.67%, val_best:  72.08%, tr:  95.61%, tr_best:  95.81%\n",
      "epoch-77  lr=['0.0010000'], tr/val_loss:  1.401379/  4.785906, val:  71.25%, val_best:  72.08%, tr:  95.10%, tr_best:  95.81%\n",
      "epoch-78  lr=['0.0010000'], tr/val_loss:  1.428124/  4.891007, val:  70.00%, val_best:  72.08%, tr:  94.59%, tr_best:  95.81%\n",
      "epoch-79  lr=['0.0010000'], tr/val_loss:  1.388427/  4.852261, val:  70.00%, val_best:  72.08%, tr:  96.12%, tr_best:  96.12%\n",
      "epoch-80  lr=['0.0010000'], tr/val_loss:  1.377656/  5.012600, val:  66.67%, val_best:  72.08%, tr:  95.81%, tr_best:  96.12%\n",
      "epoch-81  lr=['0.0010000'], tr/val_loss:  1.398011/  4.929044, val:  70.00%, val_best:  72.08%, tr:  95.61%, tr_best:  96.12%\n",
      "epoch-82  lr=['0.0010000'], tr/val_loss:  1.407977/  5.091597, val:  66.67%, val_best:  72.08%, tr:  95.81%, tr_best:  96.12%\n",
      "epoch-83  lr=['0.0010000'], tr/val_loss:  1.424639/  5.217146, val:  68.33%, val_best:  72.08%, tr:  95.81%, tr_best:  96.12%\n",
      "epoch-84  lr=['0.0010000'], tr/val_loss:  1.454949/  5.207861, val:  69.58%, val_best:  72.08%, tr:  96.63%, tr_best:  96.63%\n",
      "epoch-85  lr=['0.0010000'], tr/val_loss:  1.435362/  5.290154, val:  66.25%, val_best:  72.08%, tr:  97.14%, tr_best:  97.14%\n",
      "epoch-86  lr=['0.0010000'], tr/val_loss:  1.435105/  5.331820, val:  70.42%, val_best:  72.08%, tr:  95.91%, tr_best:  97.14%\n",
      "epoch-87  lr=['0.0010000'], tr/val_loss:  1.459584/  5.488632, val:  67.08%, val_best:  72.08%, tr:  95.81%, tr_best:  97.14%\n",
      "epoch-88  lr=['0.0010000'], tr/val_loss:  1.418352/  5.435036, val:  69.17%, val_best:  72.08%, tr:  96.94%, tr_best:  97.14%\n",
      "epoch-89  lr=['0.0010000'], tr/val_loss:  1.399766/  5.552534, val:  69.58%, val_best:  72.08%, tr:  96.83%, tr_best:  97.14%\n",
      "epoch-90  lr=['0.0010000'], tr/val_loss:  1.424972/  5.498280, val:  69.17%, val_best:  72.08%, tr:  97.04%, tr_best:  97.14%\n",
      "epoch-91  lr=['0.0010000'], tr/val_loss:  1.432758/  5.735713, val:  67.50%, val_best:  72.08%, tr:  96.53%, tr_best:  97.14%\n",
      "epoch-92  lr=['0.0010000'], tr/val_loss:  1.435318/  5.712155, val:  69.58%, val_best:  72.08%, tr:  96.83%, tr_best:  97.14%\n",
      "epoch-93  lr=['0.0010000'], tr/val_loss:  1.440660/  5.693712, val:  68.75%, val_best:  72.08%, tr:  96.53%, tr_best:  97.14%\n",
      "epoch-94  lr=['0.0010000'], tr/val_loss:  1.453702/  5.868421, val:  69.17%, val_best:  72.08%, tr:  96.83%, tr_best:  97.14%\n",
      "epoch-95  lr=['0.0010000'], tr/val_loss:  1.470503/  5.974334, val:  65.83%, val_best:  72.08%, tr:  96.22%, tr_best:  97.14%\n",
      "epoch-96  lr=['0.0010000'], tr/val_loss:  1.478259/  6.145544, val:  67.08%, val_best:  72.08%, tr:  96.63%, tr_best:  97.14%\n",
      "epoch-97  lr=['0.0010000'], tr/val_loss:  1.513734/  6.075477, val:  70.42%, val_best:  72.08%, tr:  94.89%, tr_best:  97.14%\n",
      "epoch-98  lr=['0.0010000'], tr/val_loss:  1.478986/  6.122235, val:  71.25%, val_best:  72.08%, tr:  97.24%, tr_best:  97.24%\n",
      "epoch-99  lr=['0.0010000'], tr/val_loss:  1.493304/  6.196062, val:  64.17%, val_best:  72.08%, tr:  96.53%, tr_best:  97.24%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "61634cbe705d49d4ac05652f217d8204",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.006 MB of 0.006 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>iter_acc</td><td>▁▃▄▄▅▆▆▃▆▇██▇▇▇█████▇▇███▇▇██▇██▆██▇▇▇██</td></tr><tr><td>summary_val_acc</td><td>▁▅▆▆▇▇▆▇▇▇▇█▇▇▇▇▇▇▇█▇▇███▇▇███▇██▇████▇█</td></tr><tr><td>tr_acc</td><td>▁▃▅▅▅▆▆▆▆▆▆▇▇▇▇▇▇▇▇█▇███████████████████</td></tr><tr><td>tr_epoch_loss</td><td>█▆▃▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▂▂▂▂▂▂▂▂▂▂▂▂▂▂▃▃▂▂▃▃</td></tr><tr><td>val_acc_best</td><td>▁▅▆▆▇▇▇▇▇▇▇█████████████████████████████</td></tr><tr><td>val_acc_now</td><td>▁▅▆▆▇▇▆▇▇▇▇█▇▇▇▇▇▇▇█▇▇███▇▇███▇██▇████▇█</td></tr><tr><td>val_loss</td><td>▂▁▁▁▁▁▁▁▁▁▁▁▂▂▂▂▂▃▃▃▃▄▄▄▄▄▅▅▅▆▆▆▆▆▇▇▇▇██</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>99</td></tr><tr><td>iter_acc</td><td>1.0</td></tr><tr><td>tr_acc</td><td>0.96527</td></tr><tr><td>tr_epoch_loss</td><td>1.4933</td></tr><tr><td>val_acc_best</td><td>0.72083</td></tr><tr><td>val_acc_now</td><td>0.64167</td></tr><tr><td>val_loss</td><td>6.19606</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">grateful-sweep-146</strong> at: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/um9g8tdz' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/um9g8tdz</a><br/> View project at: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>/data2/bh_wandb/wandb/run-20250430_025401-um9g8tdz/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require(\"core\")`! See https://wandb.me/wandb-core for more information."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Sweep Agent: Waiting for job.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Job received.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 10p2282p with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBATCH: 16\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBN_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBPTT_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tDFA_on: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tIMAGE_SIZE: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tOTTT_input_trace_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tTIME: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tUDA_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \talpha_uda: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbias: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcfg: ['M', 'M', 200, 200]\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tchaching_on: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tconvTrue_fcFalse: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdata_path: /data2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tddp_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdenoise_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdvs_clipping: 5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdvs_duration: 100000\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepoch_num: 100\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \texclude_class: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \textra_train_dataset: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlast_lif: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_sg_width: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_decay: 0.5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_init: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_reset: 10000\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_threshold: 0.5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmerge_polarities: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmy_seed: 42\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnet_print: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_workers: 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer_what: SGD\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tpin_memory: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tpre_trained: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tpre_trained_path: net_save/save_now_net_weights_{unique_name}.pth\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \trate_coding: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tscheduler_name: no\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsingle_step: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsurrogate: hard_sigmoid\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_conv_kernel_size: 3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_conv_padding: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_conv_stride: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_trace_const1: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_trace_const2: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \ttdBN_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \ttrace_on: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \twhich_data: DVS_GESTURE_TONIC\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.19.10 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.17.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/data2/bh_wandb/wandb/run-20250430_030043-10p2282p</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/10p2282p' target=\"_blank\">dauntless-sweep-148</a></strong> to <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/6pj3lh8j' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/6pj3lh8j</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/6pj3lh8j' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/6pj3lh8j</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/10p2282p' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/10p2282p</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'single_step' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'my_seed' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'TIME' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BATCH' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'IMAGE_SIZE' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'which_data' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'data_path' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'rate_coding' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_init' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_decay' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_threshold' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_reset' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_sg_width' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_conv_kernel_size' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_conv_stride' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_conv_padding' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_trace_const1' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_trace_const2' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'pre_trained' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'convTrue_fcFalse' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'cfg' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'net_print' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'pre_trained_path' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'learning_rate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'epoch_num' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'tdBN_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BN_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'surrogate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BPTT_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'optimizer_what' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'scheduler_name' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'ddp_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'dvs_clipping' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'dvs_duration' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'DFA_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'trace_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'OTTT_input_trace_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'exclude_class' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'merge_polarities' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'denoise_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'extra_train_dataset' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'num_workers' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'chaching_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'pin_memory' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'UDA_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'alpha_uda' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'bias' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'last_lif' was locked by 'sweep' (ignored update).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "param {'devices': '0', 'single_step': True, 'unique_name': 'main', 'my_seed': 42, 'TIME': 10, 'BATCH': 16, 'IMAGE_SIZE': 128, 'which_data': 'DVS_GESTURE_TONIC', 'data_path': '/data2', 'rate_coding': False, 'lif_layer_v_init': 0, 'lif_layer_v_decay': 0.5, 'lif_layer_v_threshold': 0.5, 'lif_layer_v_reset': 10000, 'lif_layer_sg_width': 1, 'synapse_conv_kernel_size': 3, 'synapse_conv_stride': 1, 'synapse_conv_padding': 1, 'synapse_trace_const1': 1, 'synapse_trace_const2': 0, 'pre_trained': False, 'convTrue_fcFalse': False, 'cfg': ['M', 'M', 200, 200], 'net_print': True, 'pre_trained_path': 'net_save/save_now_net_weights_{unique_name}.pth', 'learning_rate': 0.1, 'epoch_num': 100, 'tdBN_on': False, 'BN_on': False, 'surrogate': 'hard_sigmoid', 'BPTT_on': False, 'optimizer_what': 'SGD', 'scheduler_name': 'no', 'ddp_on': False, 'dvs_clipping': 5, 'dvs_duration': 100000, 'DFA_on': True, 'trace_on': True, 'OTTT_input_trace_on': False, 'exclude_class': True, 'merge_polarities': False, 'denoise_on': False, 'extra_train_dataset': 0, 'num_workers': 2, 'chaching_on': True, 'pin_memory': True, 'UDA_on': False, 'alpha_uda': 1, 'bias': True, 'last_lif': False, 'current epoch': 0} \n",
      "\n",
      "dataset_hash = ffa516e60c3efd5e0208f72b4c36cb84\n",
      "cache path exists\n",
      "\n",
      "device ==> cuda\n",
      "\n",
      "DataParallel(\n",
      "  (module): REBORN_MY_SNN_FC(\n",
      "    (layers): REBORN_MY_Sequential(\n",
      "      (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (2): DimChanger_for_FC()\n",
      "      (3): SYNAPSE_FC(in_features=2048, out_features=200, TIME=10, bias=True, sstep=True)\n",
      "      (4): LIF_layer(v_init=0, v_decay=0.5, v_threshold=0.5, v_reset=10000, sg_width=1, surrogate=hard_sigmoid, BPTT_on=False, trace_const1=1, trace_const2=0, TIME=10, sstep=True, trace_on=True)\n",
      "      (5): Feedback_Receiver()\n",
      "      (6): SYNAPSE_FC(in_features=200, out_features=200, TIME=10, bias=True, sstep=True)\n",
      "      (7): LIF_layer(v_init=0, v_decay=0.5, v_threshold=0.5, v_reset=10000, sg_width=1, surrogate=hard_sigmoid, BPTT_on=False, trace_const1=1, trace_const2=0, TIME=10, sstep=True, trace_on=True)\n",
      "      (8): Feedback_Receiver()\n",
      "      (9): SYNAPSE_FC(in_features=200, out_features=10, TIME=10, bias=True, sstep=True)\n",
      "      (DFA_top): Top_Gradient()\n",
      "    )\n",
      "  )\n",
      ")\n",
      "\n",
      "========================================================\n",
      "Trainable parameters: 452,010\n",
      "========================================================\n",
      "\n",
      "epoch-0   lr=['0.1000000'], tr/val_loss: 22.391985/ 36.216331, val:  42.92%, val_best:  42.92%, tr:  26.76%, tr_best:  26.76%\n",
      "[module.layers.5] weight_fb parameter count: 2,000\n",
      "[module.layers.8] weight_fb parameter count: 2,000\n",
      "epoch-1   lr=['0.1000000'], tr/val_loss: 26.516769/ 15.619482, val:  48.75%, val_best:  48.75%, tr:  46.37%, tr_best:  46.37%\n",
      "epoch-2   lr=['0.1000000'], tr/val_loss: 25.743910/ 25.428526, val:  52.92%, val_best:  52.92%, tr:  48.93%, tr_best:  48.93%\n",
      "epoch-3   lr=['0.1000000'], tr/val_loss: 18.043474/ 32.935867, val:  33.75%, val_best:  52.92%, tr:  58.02%, tr_best:  58.02%\n",
      "epoch-4   lr=['0.1000000'], tr/val_loss: 23.726446/ 22.775215, val:  44.17%, val_best:  52.92%, tr:  54.03%, tr_best:  58.02%\n",
      "epoch-5   lr=['0.1000000'], tr/val_loss: 15.462407/ 21.823299, val:  50.42%, val_best:  52.92%, tr:  63.02%, tr_best:  63.02%\n",
      "epoch-6   lr=['0.1000000'], tr/val_loss: 10.960146/ 18.007313, val:  60.83%, val_best:  60.83%, tr:  70.17%, tr_best:  70.17%\n",
      "epoch-7   lr=['0.1000000'], tr/val_loss:  9.676378/ 29.617136, val:  39.17%, val_best:  60.83%, tr:  74.97%, tr_best:  74.97%\n",
      "epoch-8   lr=['0.1000000'], tr/val_loss:  9.374707/ 29.429070, val:  49.17%, val_best:  60.83%, tr:  76.81%, tr_best:  76.81%\n",
      "epoch-9   lr=['0.1000000'], tr/val_loss:  9.041233/ 20.109375, val:  63.75%, val_best:  63.75%, tr:  80.08%, tr_best:  80.08%\n",
      "epoch-10  lr=['0.1000000'], tr/val_loss:  5.088737/ 17.575108, val:  65.42%, val_best:  65.42%, tr:  88.66%, tr_best:  88.66%\n",
      "epoch-11  lr=['0.1000000'], tr/val_loss:  3.878597/ 19.047285, val:  60.42%, val_best:  65.42%, tr:  90.81%, tr_best:  90.81%\n",
      "epoch-12  lr=['0.1000000'], tr/val_loss:  5.149518/ 17.077507, val:  72.50%, val_best:  72.50%, tr:  90.30%, tr_best:  90.81%\n",
      "epoch-13  lr=['0.1000000'], tr/val_loss:  3.609358/ 21.422455, val:  61.25%, val_best:  72.50%, tr:  93.36%, tr_best:  93.36%\n",
      "epoch-14  lr=['0.1000000'], tr/val_loss:  1.914548/ 19.826715, val:  67.08%, val_best:  72.50%, tr:  97.24%, tr_best:  97.24%\n",
      "epoch-15  lr=['0.1000000'], tr/val_loss:  1.347104/ 19.976992, val:  63.75%, val_best:  72.50%, tr:  98.47%, tr_best:  98.47%\n",
      "epoch-16  lr=['0.1000000'], tr/val_loss:  1.613615/ 19.138876, val:  71.25%, val_best:  72.50%, tr:  96.32%, tr_best:  98.47%\n",
      "epoch-17  lr=['0.1000000'], tr/val_loss:  1.023598/ 16.694067, val:  76.67%, val_best:  76.67%, tr:  99.08%, tr_best:  99.08%\n",
      "epoch-18  lr=['0.1000000'], tr/val_loss:  0.963997/ 18.184666, val:  76.25%, val_best:  76.67%, tr:  99.08%, tr_best:  99.08%\n",
      "epoch-19  lr=['0.1000000'], tr/val_loss:  0.661482/ 17.943069, val:  75.83%, val_best:  76.67%, tr:  99.59%, tr_best:  99.59%\n",
      "epoch-20  lr=['0.1000000'], tr/val_loss:  0.663765/ 19.904661, val:  75.83%, val_best:  76.67%, tr:  99.28%, tr_best:  99.59%\n",
      "epoch-21  lr=['0.1000000'], tr/val_loss:  0.569391/ 20.161211, val:  67.92%, val_best:  76.67%, tr:  99.69%, tr_best:  99.69%\n",
      "epoch-22  lr=['0.1000000'], tr/val_loss:  0.236493/ 17.748362, val:  76.67%, val_best:  76.67%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-23  lr=['0.1000000'], tr/val_loss:  0.211452/ 17.370916, val:  76.25%, val_best:  76.67%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-24  lr=['0.1000000'], tr/val_loss:  0.109822/ 17.520254, val:  77.08%, val_best:  77.08%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-25  lr=['0.1000000'], tr/val_loss:  0.096381/ 17.486238, val:  78.75%, val_best:  78.75%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-26  lr=['0.1000000'], tr/val_loss:  0.080476/ 17.941343, val:  76.67%, val_best:  78.75%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-27  lr=['0.1000000'], tr/val_loss:  0.069841/ 17.703089, val:  79.17%, val_best:  79.17%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-28  lr=['0.1000000'], tr/val_loss:  0.090084/ 18.565254, val:  72.50%, val_best:  79.17%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-29  lr=['0.1000000'], tr/val_loss:  0.079270/ 18.321955, val:  74.17%, val_best:  79.17%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-30  lr=['0.1000000'], tr/val_loss:  0.046369/ 17.429972, val:  77.50%, val_best:  79.17%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-31  lr=['0.1000000'], tr/val_loss:  0.038390/ 18.098537, val:  76.67%, val_best:  79.17%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-32  lr=['0.1000000'], tr/val_loss:  0.053764/ 18.696331, val:  76.25%, val_best:  79.17%, tr:  99.90%, tr_best: 100.00%\n",
      "epoch-33  lr=['0.1000000'], tr/val_loss:  0.016250/ 17.797678, val:  77.92%, val_best:  79.17%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-34  lr=['0.1000000'], tr/val_loss:  0.016809/ 18.004137, val:  77.92%, val_best:  79.17%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-35  lr=['0.1000000'], tr/val_loss:  0.010210/ 18.285915, val:  77.92%, val_best:  79.17%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-36  lr=['0.1000000'], tr/val_loss:  0.029202/ 18.760900, val:  73.33%, val_best:  79.17%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-37  lr=['0.1000000'], tr/val_loss:  0.011514/ 18.360996, val:  78.33%, val_best:  79.17%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-38  lr=['0.1000000'], tr/val_loss:  0.023716/ 18.779617, val:  77.08%, val_best:  79.17%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-39  lr=['0.1000000'], tr/val_loss:  0.006451/ 18.444344, val:  75.83%, val_best:  79.17%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-40  lr=['0.1000000'], tr/val_loss:  0.006130/ 18.079594, val:  77.08%, val_best:  79.17%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-41  lr=['0.1000000'], tr/val_loss:  0.009902/ 18.397224, val:  80.42%, val_best:  80.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-42  lr=['0.1000000'], tr/val_loss:  0.004633/ 17.863522, val:  78.33%, val_best:  80.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-43  lr=['0.1000000'], tr/val_loss:  0.007480/ 17.962555, val:  77.92%, val_best:  80.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-44  lr=['0.1000000'], tr/val_loss:  0.008342/ 17.959812, val:  77.92%, val_best:  80.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-45  lr=['0.1000000'], tr/val_loss:  0.013014/ 17.998421, val:  78.75%, val_best:  80.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-46  lr=['0.1000000'], tr/val_loss:  0.008549/ 18.397787, val:  76.25%, val_best:  80.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-47  lr=['0.1000000'], tr/val_loss:  0.005229/ 18.420298, val:  78.33%, val_best:  80.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-48  lr=['0.1000000'], tr/val_loss:  0.004683/ 18.282726, val:  77.08%, val_best:  80.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-49  lr=['0.1000000'], tr/val_loss:  0.004065/ 18.548655, val:  77.50%, val_best:  80.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-50  lr=['0.1000000'], tr/val_loss:  0.004473/ 18.281265, val:  77.50%, val_best:  80.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-51  lr=['0.1000000'], tr/val_loss:  0.007314/ 18.710680, val:  79.17%, val_best:  80.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-52  lr=['0.1000000'], tr/val_loss:  0.008827/ 18.597923, val:  76.67%, val_best:  80.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-53  lr=['0.1000000'], tr/val_loss:  0.007214/ 18.320818, val:  78.33%, val_best:  80.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-54  lr=['0.1000000'], tr/val_loss:  0.022638/ 18.583965, val:  75.83%, val_best:  80.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-55  lr=['0.1000000'], tr/val_loss:  0.012288/ 18.752094, val:  73.75%, val_best:  80.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-56  lr=['0.1000000'], tr/val_loss:  0.009210/ 18.220327, val:  77.08%, val_best:  80.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-57  lr=['0.1000000'], tr/val_loss:  0.005071/ 18.390518, val:  77.92%, val_best:  80.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-58  lr=['0.1000000'], tr/val_loss:  0.003720/ 18.533215, val:  76.25%, val_best:  80.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-59  lr=['0.1000000'], tr/val_loss:  0.011158/ 18.630718, val:  76.25%, val_best:  80.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-60  lr=['0.1000000'], tr/val_loss:  0.004777/ 18.611727, val:  77.92%, val_best:  80.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-61  lr=['0.1000000'], tr/val_loss:  0.001103/ 18.522060, val:  78.75%, val_best:  80.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-62  lr=['0.1000000'], tr/val_loss:  0.000123/ 18.615030, val:  77.08%, val_best:  80.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-63  lr=['0.1000000'], tr/val_loss:  0.000033/ 18.604145, val:  77.50%, val_best:  80.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-64  lr=['0.1000000'], tr/val_loss:  0.000040/ 18.645300, val:  77.92%, val_best:  80.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-65  lr=['0.1000000'], tr/val_loss:  0.000013/ 18.611826, val:  77.92%, val_best:  80.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-66  lr=['0.1000000'], tr/val_loss:  0.000015/ 18.599939, val:  77.92%, val_best:  80.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-67  lr=['0.1000000'], tr/val_loss:  0.000015/ 18.602995, val:  77.92%, val_best:  80.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-68  lr=['0.1000000'], tr/val_loss:  0.000015/ 18.583635, val:  77.92%, val_best:  80.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-69  lr=['0.1000000'], tr/val_loss:  0.000010/ 18.593021, val:  77.50%, val_best:  80.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-70  lr=['0.1000000'], tr/val_loss:  0.000007/ 18.591352, val:  77.50%, val_best:  80.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-71  lr=['0.1000000'], tr/val_loss:  0.000006/ 18.605661, val:  77.50%, val_best:  80.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-72  lr=['0.1000000'], tr/val_loss:  0.000007/ 18.602674, val:  77.50%, val_best:  80.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-73  lr=['0.1000000'], tr/val_loss:  0.000005/ 18.612438, val:  77.50%, val_best:  80.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-74  lr=['0.1000000'], tr/val_loss:  0.000007/ 18.568962, val:  77.50%, val_best:  80.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-75  lr=['0.1000000'], tr/val_loss:  0.000004/ 18.540178, val:  77.50%, val_best:  80.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-76  lr=['0.1000000'], tr/val_loss:  0.000006/ 18.528099, val:  77.50%, val_best:  80.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-77  lr=['0.1000000'], tr/val_loss:  0.000004/ 18.543961, val:  77.50%, val_best:  80.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-78  lr=['0.1000000'], tr/val_loss:  0.000004/ 18.552954, val:  77.50%, val_best:  80.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-79  lr=['0.1000000'], tr/val_loss:  0.000005/ 18.543453, val:  77.92%, val_best:  80.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-80  lr=['0.1000000'], tr/val_loss:  0.000004/ 18.545656, val:  77.92%, val_best:  80.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-81  lr=['0.1000000'], tr/val_loss:  0.000004/ 18.554148, val:  77.92%, val_best:  80.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-82  lr=['0.1000000'], tr/val_loss:  0.000003/ 18.563387, val:  77.92%, val_best:  80.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-83  lr=['0.1000000'], tr/val_loss:  0.000002/ 18.551886, val:  77.92%, val_best:  80.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-84  lr=['0.1000000'], tr/val_loss:  0.000004/ 18.540735, val:  77.92%, val_best:  80.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-85  lr=['0.1000000'], tr/val_loss:  0.000005/ 18.554686, val:  77.50%, val_best:  80.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-86  lr=['0.1000000'], tr/val_loss:  0.000003/ 18.551912, val:  77.50%, val_best:  80.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-87  lr=['0.1000000'], tr/val_loss:  0.000002/ 18.558765, val:  77.50%, val_best:  80.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-88  lr=['0.1000000'], tr/val_loss:  0.000002/ 18.550617, val:  77.50%, val_best:  80.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-89  lr=['0.1000000'], tr/val_loss:  0.000002/ 18.561617, val:  77.50%, val_best:  80.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-90  lr=['0.1000000'], tr/val_loss:  0.000181/ 18.473179, val:  78.33%, val_best:  80.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-91  lr=['0.1000000'], tr/val_loss:  0.000288/ 18.376642, val:  79.17%, val_best:  80.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-92  lr=['0.1000000'], tr/val_loss:  0.000874/ 18.614643, val:  77.92%, val_best:  80.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-93  lr=['0.1000000'], tr/val_loss:  0.001757/ 18.288054, val:  79.17%, val_best:  80.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-94  lr=['0.1000000'], tr/val_loss:  0.000207/ 18.282455, val:  78.33%, val_best:  80.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-95  lr=['0.1000000'], tr/val_loss:  0.000144/ 18.317179, val:  78.33%, val_best:  80.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-96  lr=['0.1000000'], tr/val_loss:  0.001293/ 18.253080, val:  79.17%, val_best:  80.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-97  lr=['0.1000000'], tr/val_loss:  0.001437/ 18.284538, val:  80.83%, val_best:  80.83%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-98  lr=['0.1000000'], tr/val_loss:  0.001949/ 18.431776, val:  77.08%, val_best:  80.83%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-99  lr=['0.1000000'], tr/val_loss:  0.001676/ 18.320328, val:  79.58%, val_best:  80.83%, tr: 100.00%, tr_best: 100.00%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aed2f16a36454cb8b0bf97ecab4fa142",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.006 MB of 0.006 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>iter_acc</td><td>▁▄▅▅▇▇██████████████████████████████████</td></tr><tr><td>summary_val_acc</td><td>▂▃▂▁▅▇▆▇▇▆▇▇▇▇██▇███▇▇▇█▇███▇▇▇▇███▇▇███</td></tr><tr><td>tr_acc</td><td>▁▃▄▆▆▇██████████████████████████████████</td></tr><tr><td>tr_epoch_loss</td><td>▇█▇▄▃▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_acc_best</td><td>▁▃▃▄▅▆▆▇▇▇▇█████████████████████████████</td></tr><tr><td>val_acc_now</td><td>▂▃▂▁▅▇▆▇▇▆▇▇▇▇██▇███▇▇▇█▇███▇▇▇▇███▇▇███</td></tr><tr><td>val_loss</td><td>█▄▃▆▂▁▂▁▁▂▁▁▂▂▂▂▂▁▁▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>99</td></tr><tr><td>iter_acc</td><td>1.0</td></tr><tr><td>tr_acc</td><td>1.0</td></tr><tr><td>tr_epoch_loss</td><td>0.00168</td></tr><tr><td>val_acc_best</td><td>0.80833</td></tr><tr><td>val_acc_now</td><td>0.79583</td></tr><tr><td>val_loss</td><td>18.32033</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">dauntless-sweep-148</strong> at: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/10p2282p' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/10p2282p</a><br/> View project at: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>/data2/bh_wandb/wandb/run-20250430_030043-10p2282p/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require(\"core\")`! See https://wandb.me/wandb-core for more information."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 7tb9j7xi with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBATCH: 16\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBN_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBPTT_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tDFA_on: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tIMAGE_SIZE: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tOTTT_input_trace_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tTIME: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tUDA_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \talpha_uda: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbias: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcfg: ['M', 'M', 200, 200]\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tchaching_on: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tconvTrue_fcFalse: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdata_path: /data2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tddp_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdenoise_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdvs_clipping: 5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdvs_duration: 100000\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepoch_num: 100\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \texclude_class: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \textra_train_dataset: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlast_lif: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.001\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_sg_width: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_decay: 0.5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_init: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_reset: 10000\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_threshold: 0.25\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmerge_polarities: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmy_seed: 42\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnet_print: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_workers: 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer_what: SGD\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tpin_memory: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tpre_trained: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tpre_trained_path: net_save/save_now_net_weights_{unique_name}.pth\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \trate_coding: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tscheduler_name: no\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsingle_step: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsurrogate: hard_sigmoid\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_conv_kernel_size: 3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_conv_padding: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_conv_stride: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_trace_const1: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_trace_const2: 0.5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \ttdBN_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \ttrace_on: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \twhich_data: DVS_GESTURE_TONIC\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bbf05bdaf20f4a37ad1c87a08eb0aa63",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.011113168578594923, max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.19.10 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.17.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/data2/bh_wandb/wandb/run-20250430_030718-7tb9j7xi</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/7tb9j7xi' target=\"_blank\">summer-sweep-150</a></strong> to <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/6pj3lh8j' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/6pj3lh8j</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/6pj3lh8j' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/6pj3lh8j</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/7tb9j7xi' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/7tb9j7xi</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'single_step' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'my_seed' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'TIME' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BATCH' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'IMAGE_SIZE' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'which_data' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'data_path' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'rate_coding' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_init' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_decay' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_threshold' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_reset' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_sg_width' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_conv_kernel_size' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_conv_stride' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_conv_padding' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_trace_const1' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_trace_const2' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'pre_trained' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'convTrue_fcFalse' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'cfg' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'net_print' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'pre_trained_path' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'learning_rate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'epoch_num' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'tdBN_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BN_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'surrogate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BPTT_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'optimizer_what' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'scheduler_name' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'ddp_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'dvs_clipping' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'dvs_duration' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'DFA_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'trace_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'OTTT_input_trace_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'exclude_class' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'merge_polarities' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'denoise_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'extra_train_dataset' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'num_workers' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'chaching_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'pin_memory' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'UDA_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'alpha_uda' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'bias' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'last_lif' was locked by 'sweep' (ignored update).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "param {'devices': '0', 'single_step': True, 'unique_name': 'main', 'my_seed': 42, 'TIME': 10, 'BATCH': 16, 'IMAGE_SIZE': 128, 'which_data': 'DVS_GESTURE_TONIC', 'data_path': '/data2', 'rate_coding': False, 'lif_layer_v_init': 0, 'lif_layer_v_decay': 0.5, 'lif_layer_v_threshold': 0.25, 'lif_layer_v_reset': 10000, 'lif_layer_sg_width': 1, 'synapse_conv_kernel_size': 3, 'synapse_conv_stride': 1, 'synapse_conv_padding': 1, 'synapse_trace_const1': 1, 'synapse_trace_const2': 0.5, 'pre_trained': False, 'convTrue_fcFalse': False, 'cfg': ['M', 'M', 200, 200], 'net_print': True, 'pre_trained_path': 'net_save/save_now_net_weights_{unique_name}.pth', 'learning_rate': 0.001, 'epoch_num': 100, 'tdBN_on': False, 'BN_on': False, 'surrogate': 'hard_sigmoid', 'BPTT_on': False, 'optimizer_what': 'SGD', 'scheduler_name': 'no', 'ddp_on': False, 'dvs_clipping': 5, 'dvs_duration': 100000, 'DFA_on': True, 'trace_on': True, 'OTTT_input_trace_on': False, 'exclude_class': True, 'merge_polarities': False, 'denoise_on': False, 'extra_train_dataset': 0, 'num_workers': 2, 'chaching_on': True, 'pin_memory': True, 'UDA_on': False, 'alpha_uda': 1, 'bias': True, 'last_lif': False, 'current epoch': 0} \n",
      "\n",
      "dataset_hash = ffa516e60c3efd5e0208f72b4c36cb84\n",
      "cache path exists\n",
      "\n",
      "device ==> cuda\n",
      "\n",
      "DataParallel(\n",
      "  (module): REBORN_MY_SNN_FC(\n",
      "    (layers): REBORN_MY_Sequential(\n",
      "      (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (2): DimChanger_for_FC()\n",
      "      (3): SYNAPSE_FC(in_features=2048, out_features=200, TIME=10, bias=True, sstep=True)\n",
      "      (4): LIF_layer(v_init=0, v_decay=0.5, v_threshold=0.25, v_reset=10000, sg_width=1, surrogate=hard_sigmoid, BPTT_on=False, trace_const1=1, trace_const2=0.5, TIME=10, sstep=True, trace_on=True)\n",
      "      (5): Feedback_Receiver()\n",
      "      (6): SYNAPSE_FC(in_features=200, out_features=200, TIME=10, bias=True, sstep=True)\n",
      "      (7): LIF_layer(v_init=0, v_decay=0.5, v_threshold=0.25, v_reset=10000, sg_width=1, surrogate=hard_sigmoid, BPTT_on=False, trace_const1=1, trace_const2=0.5, TIME=10, sstep=True, trace_on=True)\n",
      "      (8): Feedback_Receiver()\n",
      "      (9): SYNAPSE_FC(in_features=200, out_features=10, TIME=10, bias=True, sstep=True)\n",
      "      (DFA_top): Top_Gradient()\n",
      "    )\n",
      "  )\n",
      ")\n",
      "\n",
      "========================================================\n",
      "Trainable parameters: 452,010\n",
      "========================================================\n",
      "\n",
      "epoch-0   lr=['0.0010000'], tr/val_loss:  2.193166/  1.939117, val:  36.25%, val_best:  36.25%, tr:  18.39%, tr_best:  18.39%\n",
      "[module.layers.5] weight_fb parameter count: 2,000\n",
      "[module.layers.8] weight_fb parameter count: 2,000\n",
      "epoch-1   lr=['0.0010000'], tr/val_loss:  1.596445/  1.538843, val:  56.25%, val_best:  56.25%, tr:  49.44%, tr_best:  49.44%\n",
      "epoch-2   lr=['0.0010000'], tr/val_loss:  1.374148/  1.504866, val:  55.00%, val_best:  56.25%, tr:  57.61%, tr_best:  57.61%\n",
      "epoch-3   lr=['0.0010000'], tr/val_loss:  1.272936/  1.492908, val:  58.75%, val_best:  58.75%, tr:  63.84%, tr_best:  63.84%\n",
      "epoch-4   lr=['0.0010000'], tr/val_loss:  1.231004/  1.469412, val:  58.75%, val_best:  58.75%, tr:  63.13%, tr_best:  63.84%\n",
      "epoch-5   lr=['0.0010000'], tr/val_loss:  1.181969/  1.432151, val:  64.17%, val_best:  64.17%, tr:  65.37%, tr_best:  65.37%\n",
      "epoch-6   lr=['0.0010000'], tr/val_loss:  1.130880/  1.435866, val:  61.25%, val_best:  64.17%, tr:  67.72%, tr_best:  67.72%\n",
      "epoch-7   lr=['0.0010000'], tr/val_loss:  1.124110/  1.450976, val:  62.08%, val_best:  64.17%, tr:  67.93%, tr_best:  67.93%\n",
      "epoch-8   lr=['0.0010000'], tr/val_loss:  1.087939/  1.483909, val:  60.00%, val_best:  64.17%, tr:  70.48%, tr_best:  70.48%\n",
      "epoch-9   lr=['0.0010000'], tr/val_loss:  1.081649/  1.512360, val:  59.17%, val_best:  64.17%, tr:  72.73%, tr_best:  72.73%\n",
      "epoch-10  lr=['0.0010000'], tr/val_loss:  1.075077/  1.557770, val:  56.67%, val_best:  64.17%, tr:  72.11%, tr_best:  72.73%\n",
      "epoch-11  lr=['0.0010000'], tr/val_loss:  1.031409/  1.512975, val:  61.25%, val_best:  64.17%, tr:  75.69%, tr_best:  75.69%\n",
      "epoch-12  lr=['0.0010000'], tr/val_loss:  1.032472/  1.569944, val:  58.75%, val_best:  64.17%, tr:  75.49%, tr_best:  75.69%\n",
      "epoch-13  lr=['0.0010000'], tr/val_loss:  1.024697/  1.581399, val:  63.75%, val_best:  64.17%, tr:  78.04%, tr_best:  78.04%\n",
      "epoch-14  lr=['0.0010000'], tr/val_loss:  0.989958/  1.774732, val:  57.92%, val_best:  64.17%, tr:  77.83%, tr_best:  78.04%\n",
      "epoch-15  lr=['0.0010000'], tr/val_loss:  0.988663/  1.699107, val:  62.50%, val_best:  64.17%, tr:  78.86%, tr_best:  78.86%\n",
      "epoch-16  lr=['0.0010000'], tr/val_loss:  1.001385/  1.668627, val:  62.92%, val_best:  64.17%, tr:  78.75%, tr_best:  78.86%\n",
      "epoch-17  lr=['0.0010000'], tr/val_loss:  0.965800/  1.698771, val:  62.50%, val_best:  64.17%, tr:  84.58%, tr_best:  84.58%\n",
      "epoch-18  lr=['0.0010000'], tr/val_loss:  0.968380/  1.842503, val:  60.83%, val_best:  64.17%, tr:  82.84%, tr_best:  84.58%\n",
      "epoch-19  lr=['0.0010000'], tr/val_loss:  0.976029/  1.809729, val:  65.00%, val_best:  65.00%, tr:  81.51%, tr_best:  84.58%\n",
      "epoch-20  lr=['0.0010000'], tr/val_loss:  0.953923/  1.939612, val:  62.08%, val_best:  65.00%, tr:  85.19%, tr_best:  85.19%\n",
      "epoch-21  lr=['0.0010000'], tr/val_loss:  0.938328/  1.932675, val:  62.92%, val_best:  65.00%, tr:  85.19%, tr_best:  85.19%\n",
      "epoch-22  lr=['0.0010000'], tr/val_loss:  0.946192/  1.963732, val:  63.75%, val_best:  65.00%, tr:  85.09%, tr_best:  85.19%\n",
      "epoch-23  lr=['0.0010000'], tr/val_loss:  0.921071/  2.004754, val:  62.92%, val_best:  65.00%, tr:  88.87%, tr_best:  88.87%\n",
      "epoch-24  lr=['0.0010000'], tr/val_loss:  0.912818/  2.081909, val:  64.17%, val_best:  65.00%, tr:  90.40%, tr_best:  90.40%\n",
      "epoch-25  lr=['0.0010000'], tr/val_loss:  0.924512/  2.089756, val:  65.83%, val_best:  65.83%, tr:  89.89%, tr_best:  90.40%\n",
      "epoch-26  lr=['0.0010000'], tr/val_loss:  0.938146/  2.147205, val:  64.58%, val_best:  65.83%, tr:  89.27%, tr_best:  90.40%\n",
      "epoch-27  lr=['0.0010000'], tr/val_loss:  0.919848/  2.259307, val:  60.83%, val_best:  65.83%, tr:  90.91%, tr_best:  90.91%\n",
      "epoch-28  lr=['0.0010000'], tr/val_loss:  0.928758/  2.266344, val:  67.50%, val_best:  67.50%, tr:  90.40%, tr_best:  90.91%\n",
      "epoch-29  lr=['0.0010000'], tr/val_loss:  0.904377/  2.418868, val:  58.33%, val_best:  67.50%, tr:  93.36%, tr_best:  93.36%\n",
      "epoch-30  lr=['0.0010000'], tr/val_loss:  0.901257/  2.436279, val:  64.58%, val_best:  67.50%, tr:  93.46%, tr_best:  93.46%\n",
      "epoch-31  lr=['0.0010000'], tr/val_loss:  0.918823/  2.499423, val:  63.33%, val_best:  67.50%, tr:  91.32%, tr_best:  93.46%\n",
      "epoch-32  lr=['0.0010000'], tr/val_loss:  0.907202/  2.583228, val:  64.17%, val_best:  67.50%, tr:  92.13%, tr_best:  93.46%\n",
      "epoch-33  lr=['0.0010000'], tr/val_loss:  0.927218/  2.594553, val:  62.08%, val_best:  67.50%, tr:  92.75%, tr_best:  93.46%\n",
      "epoch-34  lr=['0.0010000'], tr/val_loss:  0.877721/  2.682896, val:  60.42%, val_best:  67.50%, tr:  95.71%, tr_best:  95.71%\n",
      "epoch-35  lr=['0.0010000'], tr/val_loss:  0.927637/  2.886584, val:  60.00%, val_best:  67.50%, tr:  91.52%, tr_best:  95.71%\n",
      "epoch-36  lr=['0.0010000'], tr/val_loss:  0.897621/  2.790205, val:  62.08%, val_best:  67.50%, tr:  93.97%, tr_best:  95.71%\n",
      "epoch-37  lr=['0.0010000'], tr/val_loss:  0.897012/  2.864525, val:  64.58%, val_best:  67.50%, tr:  95.30%, tr_best:  95.71%\n",
      "epoch-38  lr=['0.0010000'], tr/val_loss:  0.901069/  2.892008, val:  64.17%, val_best:  67.50%, tr:  95.91%, tr_best:  95.91%\n",
      "epoch-39  lr=['0.0010000'], tr/val_loss:  0.885706/  2.971587, val:  65.83%, val_best:  67.50%, tr:  96.73%, tr_best:  96.73%\n",
      "epoch-40  lr=['0.0010000'], tr/val_loss:  0.921253/  3.140809, val:  66.67%, val_best:  67.50%, tr:  93.77%, tr_best:  96.73%\n",
      "epoch-41  lr=['0.0010000'], tr/val_loss:  0.900491/  3.166608, val:  62.08%, val_best:  67.50%, tr:  96.02%, tr_best:  96.73%\n",
      "epoch-42  lr=['0.0010000'], tr/val_loss:  0.885927/  3.123917, val:  65.42%, val_best:  67.50%, tr:  96.22%, tr_best:  96.73%\n",
      "epoch-43  lr=['0.0010000'], tr/val_loss:  0.883350/  3.226336, val:  64.17%, val_best:  67.50%, tr:  96.73%, tr_best:  96.73%\n",
      "epoch-44  lr=['0.0010000'], tr/val_loss:  0.868177/  3.336858, val:  65.83%, val_best:  67.50%, tr:  96.53%, tr_best:  96.73%\n",
      "epoch-45  lr=['0.0010000'], tr/val_loss:  0.879438/  3.476895, val:  64.58%, val_best:  67.50%, tr:  97.24%, tr_best:  97.24%\n",
      "epoch-46  lr=['0.0010000'], tr/val_loss:  0.876472/  3.444482, val:  67.50%, val_best:  67.50%, tr:  97.04%, tr_best:  97.24%\n",
      "epoch-47  lr=['0.0010000'], tr/val_loss:  0.881349/  3.566679, val:  64.17%, val_best:  67.50%, tr:  97.45%, tr_best:  97.45%\n",
      "epoch-48  lr=['0.0010000'], tr/val_loss:  0.902812/  3.620230, val:  64.58%, val_best:  67.50%, tr:  97.85%, tr_best:  97.85%\n",
      "epoch-49  lr=['0.0010000'], tr/val_loss:  0.909536/  3.763088, val:  67.08%, val_best:  67.50%, tr:  96.02%, tr_best:  97.85%\n",
      "epoch-50  lr=['0.0010000'], tr/val_loss:  0.897933/  3.823657, val:  65.42%, val_best:  67.50%, tr:  96.83%, tr_best:  97.85%\n",
      "epoch-51  lr=['0.0010000'], tr/val_loss:  0.921506/  3.850721, val:  63.75%, val_best:  67.50%, tr:  96.22%, tr_best:  97.85%\n",
      "epoch-52  lr=['0.0010000'], tr/val_loss:  0.878395/  3.920132, val:  62.92%, val_best:  67.50%, tr:  98.16%, tr_best:  98.16%\n",
      "epoch-53  lr=['0.0010000'], tr/val_loss:  0.875459/  3.925065, val:  63.33%, val_best:  67.50%, tr:  97.85%, tr_best:  98.16%\n",
      "epoch-54  lr=['0.0010000'], tr/val_loss:  0.908434/  4.063511, val:  65.00%, val_best:  67.50%, tr:  97.45%, tr_best:  98.16%\n",
      "epoch-55  lr=['0.0010000'], tr/val_loss:  0.885495/  4.166838, val:  64.58%, val_best:  67.50%, tr:  97.45%, tr_best:  98.16%\n",
      "epoch-56  lr=['0.0010000'], tr/val_loss:  0.891168/  4.235428, val:  64.58%, val_best:  67.50%, tr:  97.96%, tr_best:  98.16%\n",
      "epoch-57  lr=['0.0010000'], tr/val_loss:  0.904209/  4.202693, val:  65.42%, val_best:  67.50%, tr:  98.16%, tr_best:  98.16%\n",
      "epoch-58  lr=['0.0010000'], tr/val_loss:  0.901683/  4.408100, val:  65.83%, val_best:  67.50%, tr:  97.75%, tr_best:  98.16%\n",
      "epoch-59  lr=['0.0010000'], tr/val_loss:  0.917671/  4.462821, val:  65.83%, val_best:  67.50%, tr:  97.85%, tr_best:  98.16%\n",
      "epoch-60  lr=['0.0010000'], tr/val_loss:  0.900324/  4.409728, val:  66.25%, val_best:  67.50%, tr:  98.06%, tr_best:  98.16%\n",
      "epoch-61  lr=['0.0010000'], tr/val_loss:  0.916592/  4.574003, val:  64.17%, val_best:  67.50%, tr:  97.96%, tr_best:  98.16%\n",
      "epoch-62  lr=['0.0010000'], tr/val_loss:  0.918912/  4.598024, val:  64.58%, val_best:  67.50%, tr:  97.75%, tr_best:  98.16%\n",
      "epoch-63  lr=['0.0010000'], tr/val_loss:  0.912576/  4.673869, val:  64.17%, val_best:  67.50%, tr:  98.47%, tr_best:  98.47%\n",
      "epoch-64  lr=['0.0010000'], tr/val_loss:  0.951523/  4.838566, val:  62.50%, val_best:  67.50%, tr:  97.14%, tr_best:  98.47%\n",
      "epoch-65  lr=['0.0010000'], tr/val_loss:  0.929579/  4.837544, val:  63.75%, val_best:  67.50%, tr:  98.57%, tr_best:  98.57%\n",
      "epoch-66  lr=['0.0010000'], tr/val_loss:  0.943912/  4.801209, val:  63.33%, val_best:  67.50%, tr:  98.77%, tr_best:  98.77%\n",
      "epoch-67  lr=['0.0010000'], tr/val_loss:  0.978586/  4.870781, val:  64.17%, val_best:  67.50%, tr:  98.26%, tr_best:  98.77%\n",
      "epoch-68  lr=['0.0010000'], tr/val_loss:  0.928512/  5.056540, val:  66.67%, val_best:  67.50%, tr:  98.88%, tr_best:  98.88%\n",
      "epoch-69  lr=['0.0010000'], tr/val_loss:  0.974683/  5.035474, val:  64.58%, val_best:  67.50%, tr:  97.85%, tr_best:  98.88%\n",
      "epoch-70  lr=['0.0010000'], tr/val_loss:  0.955963/  5.190147, val:  65.83%, val_best:  67.50%, tr:  98.98%, tr_best:  98.98%\n",
      "epoch-71  lr=['0.0010000'], tr/val_loss:  0.966961/  5.238400, val:  64.17%, val_best:  67.50%, tr:  98.06%, tr_best:  98.98%\n",
      "epoch-72  lr=['0.0010000'], tr/val_loss:  0.958911/  5.391454, val:  64.17%, val_best:  67.50%, tr:  98.67%, tr_best:  98.98%\n",
      "epoch-73  lr=['0.0010000'], tr/val_loss:  0.979799/  5.308387, val:  64.17%, val_best:  67.50%, tr:  98.37%, tr_best:  98.98%\n",
      "epoch-74  lr=['0.0010000'], tr/val_loss:  0.964715/  5.419832, val:  65.83%, val_best:  67.50%, tr:  98.37%, tr_best:  98.98%\n",
      "epoch-75  lr=['0.0010000'], tr/val_loss:  0.980169/  5.544930, val:  66.25%, val_best:  67.50%, tr:  98.37%, tr_best:  98.98%\n",
      "epoch-76  lr=['0.0010000'], tr/val_loss:  0.968358/  5.632122, val:  65.83%, val_best:  67.50%, tr:  98.16%, tr_best:  98.98%\n",
      "epoch-77  lr=['0.0010000'], tr/val_loss:  0.988867/  5.605183, val:  63.75%, val_best:  67.50%, tr:  98.77%, tr_best:  98.98%\n",
      "epoch-78  lr=['0.0010000'], tr/val_loss:  0.985602/  5.728496, val:  64.58%, val_best:  67.50%, tr:  98.37%, tr_best:  98.98%\n",
      "epoch-79  lr=['0.0010000'], tr/val_loss:  0.989630/  5.790163, val:  63.33%, val_best:  67.50%, tr:  98.98%, tr_best:  98.98%\n",
      "epoch-80  lr=['0.0010000'], tr/val_loss:  0.946726/  5.743594, val:  66.25%, val_best:  67.50%, tr:  98.37%, tr_best:  98.98%\n",
      "epoch-81  lr=['0.0010000'], tr/val_loss:  0.937975/  5.892830, val:  63.75%, val_best:  67.50%, tr:  98.67%, tr_best:  98.98%\n",
      "epoch-82  lr=['0.0010000'], tr/val_loss:  0.973990/  5.979602, val:  65.42%, val_best:  67.50%, tr:  98.37%, tr_best:  98.98%\n",
      "epoch-83  lr=['0.0010000'], tr/val_loss:  0.968340/  6.040612, val:  65.42%, val_best:  67.50%, tr:  98.57%, tr_best:  98.98%\n",
      "epoch-84  lr=['0.0010000'], tr/val_loss:  0.975842/  6.045587, val:  66.25%, val_best:  67.50%, tr:  99.18%, tr_best:  99.18%\n",
      "epoch-85  lr=['0.0010000'], tr/val_loss:  0.959686/  6.149115, val:  64.17%, val_best:  67.50%, tr:  99.18%, tr_best:  99.18%\n",
      "epoch-86  lr=['0.0010000'], tr/val_loss:  0.966483/  6.255885, val:  66.67%, val_best:  67.50%, tr:  98.47%, tr_best:  99.18%\n",
      "epoch-87  lr=['0.0010000'], tr/val_loss:  1.010518/  6.260497, val:  65.83%, val_best:  67.50%, tr:  98.57%, tr_best:  99.18%\n",
      "epoch-88  lr=['0.0010000'], tr/val_loss:  0.970384/  6.322037, val:  64.17%, val_best:  67.50%, tr:  99.18%, tr_best:  99.18%\n",
      "epoch-89  lr=['0.0010000'], tr/val_loss:  0.940430/  6.472783, val:  64.58%, val_best:  67.50%, tr:  98.88%, tr_best:  99.18%\n",
      "epoch-90  lr=['0.0010000'], tr/val_loss:  1.016080/  6.364972, val:  66.67%, val_best:  67.50%, tr:  98.88%, tr_best:  99.18%\n",
      "epoch-91  lr=['0.0010000'], tr/val_loss:  0.968965/  6.490075, val:  63.75%, val_best:  67.50%, tr:  98.67%, tr_best:  99.18%\n",
      "epoch-92  lr=['0.0010000'], tr/val_loss:  0.984306/  6.480693, val:  65.42%, val_best:  67.50%, tr:  99.08%, tr_best:  99.18%\n",
      "epoch-93  lr=['0.0010000'], tr/val_loss:  0.985216/  6.495708, val:  67.50%, val_best:  67.50%, tr:  98.98%, tr_best:  99.18%\n",
      "epoch-94  lr=['0.0010000'], tr/val_loss:  0.993391/  6.601977, val:  62.92%, val_best:  67.50%, tr:  98.57%, tr_best:  99.18%\n",
      "epoch-95  lr=['0.0010000'], tr/val_loss:  1.002850/  6.695262, val:  66.25%, val_best:  67.50%, tr:  98.88%, tr_best:  99.18%\n",
      "epoch-96  lr=['0.0010000'], tr/val_loss:  0.982645/  6.811234, val:  64.58%, val_best:  67.50%, tr:  98.47%, tr_best:  99.18%\n",
      "epoch-97  lr=['0.0010000'], tr/val_loss:  1.027471/  6.617285, val:  66.25%, val_best:  67.50%, tr:  98.26%, tr_best:  99.18%\n",
      "epoch-98  lr=['0.0010000'], tr/val_loss:  0.965649/  6.649284, val:  65.42%, val_best:  67.50%, tr:  99.28%, tr_best:  99.28%\n",
      "epoch-99  lr=['0.0010000'], tr/val_loss:  1.042163/  6.814491, val:  62.50%, val_best:  67.50%, tr:  99.08%, tr_best:  99.28%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a969bfd03b7940f4b71e3fb1530a0872",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.006 MB of 0.006 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>iter_acc</td><td>▃▆▂▃▃▆▆▁▆▆██▆▇▆██▇██▇█▇██████▇▇█▇███▆▇██</td></tr><tr><td>summary_val_acc</td><td>▁▅▆▇▆▆▆▇█▇▇▇▆▇▆▇███▇█▇███▇▇▇█▇█▇▇███▇███</td></tr><tr><td>tr_acc</td><td>▁▄▅▅▆▆▆▇▆▇▇▇▇▇▇█████████████████████████</td></tr><tr><td>tr_epoch_loss</td><td>█▄▃▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▁▁▂▂▂▂▂▂▁▂▂▂</td></tr><tr><td>val_acc_best</td><td>▁▅▆▇▇▇▇▇▇▇▇█████████████████████████████</td></tr><tr><td>val_acc_now</td><td>▁▅▆▇▆▆▆▇█▇▇▇▆▇▆▇███▇█▇███▇▇▇█▇█▇▇███▇███</td></tr><tr><td>val_loss</td><td>▂▁▁▁▁▁▁▁▁▂▂▂▂▃▃▃▃▃▄▄▄▄▄▅▅▅▆▆▆▆▆▇▇▇▇▇████</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>99</td></tr><tr><td>iter_acc</td><td>1.0</td></tr><tr><td>tr_acc</td><td>0.99081</td></tr><tr><td>tr_epoch_loss</td><td>1.04216</td></tr><tr><td>val_acc_best</td><td>0.675</td></tr><tr><td>val_acc_now</td><td>0.625</td></tr><tr><td>val_loss</td><td>6.81449</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">summer-sweep-150</strong> at: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/7tb9j7xi' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/7tb9j7xi</a><br/> View project at: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>/data2/bh_wandb/wandb/run-20250430_030718-7tb9j7xi/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require(\"core\")`! See https://wandb.me/wandb-core for more information."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 6jv6hhoa with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBATCH: 16\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBN_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBPTT_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tDFA_on: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tIMAGE_SIZE: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tOTTT_input_trace_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tTIME: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tUDA_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \talpha_uda: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbias: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcfg: ['M', 'M', 200, 200]\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tchaching_on: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tconvTrue_fcFalse: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdata_path: /data2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tddp_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdenoise_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdvs_clipping: 5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdvs_duration: 100000\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepoch_num: 100\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \texclude_class: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \textra_train_dataset: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlast_lif: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.01\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_sg_width: 4\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_decay: 0.5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_init: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_reset: 10000\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_threshold: 0.25\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmerge_polarities: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmy_seed: 42\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnet_print: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_workers: 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer_what: SGD\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tpin_memory: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tpre_trained: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tpre_trained_path: net_save/save_now_net_weights_{unique_name}.pth\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \trate_coding: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tscheduler_name: no\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsingle_step: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsurrogate: hard_sigmoid\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_conv_kernel_size: 3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_conv_padding: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_conv_stride: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_trace_const1: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_trace_const2: 0.5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \ttdBN_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \ttrace_on: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \twhich_data: DVS_GESTURE_TONIC\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.19.10 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.17.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/data2/bh_wandb/wandb/run-20250430_031352-6jv6hhoa</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/6jv6hhoa' target=\"_blank\">avid-sweep-152</a></strong> to <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/6pj3lh8j' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/6pj3lh8j</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/6pj3lh8j' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/6pj3lh8j</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/6jv6hhoa' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/6jv6hhoa</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'single_step' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'my_seed' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'TIME' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BATCH' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'IMAGE_SIZE' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'which_data' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'data_path' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'rate_coding' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_init' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_decay' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_threshold' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_reset' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_sg_width' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_conv_kernel_size' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_conv_stride' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_conv_padding' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_trace_const1' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_trace_const2' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'pre_trained' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'convTrue_fcFalse' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'cfg' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'net_print' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'pre_trained_path' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'learning_rate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'epoch_num' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'tdBN_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BN_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'surrogate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BPTT_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'optimizer_what' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'scheduler_name' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'ddp_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'dvs_clipping' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'dvs_duration' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'DFA_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'trace_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'OTTT_input_trace_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'exclude_class' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'merge_polarities' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'denoise_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'extra_train_dataset' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'num_workers' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'chaching_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'pin_memory' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'UDA_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'alpha_uda' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'bias' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'last_lif' was locked by 'sweep' (ignored update).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "param {'devices': '0', 'single_step': True, 'unique_name': 'main', 'my_seed': 42, 'TIME': 10, 'BATCH': 16, 'IMAGE_SIZE': 128, 'which_data': 'DVS_GESTURE_TONIC', 'data_path': '/data2', 'rate_coding': False, 'lif_layer_v_init': 0, 'lif_layer_v_decay': 0.5, 'lif_layer_v_threshold': 0.25, 'lif_layer_v_reset': 10000, 'lif_layer_sg_width': 4, 'synapse_conv_kernel_size': 3, 'synapse_conv_stride': 1, 'synapse_conv_padding': 1, 'synapse_trace_const1': 1, 'synapse_trace_const2': 0.5, 'pre_trained': False, 'convTrue_fcFalse': False, 'cfg': ['M', 'M', 200, 200], 'net_print': True, 'pre_trained_path': 'net_save/save_now_net_weights_{unique_name}.pth', 'learning_rate': 0.01, 'epoch_num': 100, 'tdBN_on': False, 'BN_on': False, 'surrogate': 'hard_sigmoid', 'BPTT_on': False, 'optimizer_what': 'SGD', 'scheduler_name': 'no', 'ddp_on': False, 'dvs_clipping': 5, 'dvs_duration': 100000, 'DFA_on': True, 'trace_on': True, 'OTTT_input_trace_on': False, 'exclude_class': True, 'merge_polarities': False, 'denoise_on': False, 'extra_train_dataset': 0, 'num_workers': 2, 'chaching_on': True, 'pin_memory': True, 'UDA_on': False, 'alpha_uda': 1, 'bias': True, 'last_lif': False, 'current epoch': 0} \n",
      "\n",
      "dataset_hash = ffa516e60c3efd5e0208f72b4c36cb84\n",
      "cache path exists\n",
      "\n",
      "device ==> cuda\n",
      "\n",
      "DataParallel(\n",
      "  (module): REBORN_MY_SNN_FC(\n",
      "    (layers): REBORN_MY_Sequential(\n",
      "      (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (2): DimChanger_for_FC()\n",
      "      (3): SYNAPSE_FC(in_features=2048, out_features=200, TIME=10, bias=True, sstep=True)\n",
      "      (4): LIF_layer(v_init=0, v_decay=0.5, v_threshold=0.25, v_reset=10000, sg_width=4, surrogate=hard_sigmoid, BPTT_on=False, trace_const1=1, trace_const2=0.5, TIME=10, sstep=True, trace_on=True)\n",
      "      (5): Feedback_Receiver()\n",
      "      (6): SYNAPSE_FC(in_features=200, out_features=200, TIME=10, bias=True, sstep=True)\n",
      "      (7): LIF_layer(v_init=0, v_decay=0.5, v_threshold=0.25, v_reset=10000, sg_width=4, surrogate=hard_sigmoid, BPTT_on=False, trace_const1=1, trace_const2=0.5, TIME=10, sstep=True, trace_on=True)\n",
      "      (8): Feedback_Receiver()\n",
      "      (9): SYNAPSE_FC(in_features=200, out_features=10, TIME=10, bias=True, sstep=True)\n",
      "      (DFA_top): Top_Gradient()\n",
      "    )\n",
      "  )\n",
      ")\n",
      "\n",
      "========================================================\n",
      "Trainable parameters: 452,010\n",
      "========================================================\n",
      "\n",
      "epoch-0   lr=['0.0100000'], tr/val_loss:  3.411396/  3.961666, val:  34.58%, val_best:  34.58%, tr:  34.42%, tr_best:  34.42%\n",
      "[module.layers.5] weight_fb parameter count: 2,000\n",
      "[module.layers.8] weight_fb parameter count: 2,000\n",
      "epoch-1   lr=['0.0100000'], tr/val_loss:  3.328532/  4.816998, val:  43.33%, val_best:  43.33%, tr:  48.42%, tr_best:  48.42%\n",
      "epoch-2   lr=['0.0100000'], tr/val_loss:  3.937226/  5.331160, val:  42.92%, val_best:  43.33%, tr:  54.03%, tr_best:  54.03%\n",
      "epoch-3   lr=['0.0100000'], tr/val_loss:  2.720990/  4.471964, val:  45.42%, val_best:  45.42%, tr:  61.90%, tr_best:  61.90%\n",
      "epoch-4   lr=['0.0100000'], tr/val_loss:  2.928755/  5.125686, val:  50.00%, val_best:  50.00%, tr:  62.41%, tr_best:  62.41%\n",
      "epoch-5   lr=['0.0100000'], tr/val_loss:  2.909848/  4.679750, val:  49.17%, val_best:  50.00%, tr:  65.68%, tr_best:  65.68%\n",
      "epoch-6   lr=['0.0100000'], tr/val_loss:  1.649792/  3.749061, val:  60.42%, val_best:  60.42%, tr:  77.53%, tr_best:  77.53%\n",
      "epoch-7   lr=['0.0100000'], tr/val_loss:  1.331021/  3.443735, val:  61.25%, val_best:  61.25%, tr:  81.51%, tr_best:  81.51%\n",
      "epoch-8   lr=['0.0100000'], tr/val_loss:  1.428312/  4.727780, val:  60.00%, val_best:  61.25%, tr:  83.15%, tr_best:  83.15%\n",
      "epoch-9   lr=['0.0100000'], tr/val_loss:  1.935777/  5.408105, val:  57.92%, val_best:  61.25%, tr:  82.23%, tr_best:  83.15%\n",
      "epoch-10  lr=['0.0100000'], tr/val_loss:  1.196540/  4.525899, val:  63.33%, val_best:  63.33%, tr:  89.79%, tr_best:  89.79%\n",
      "epoch-11  lr=['0.0100000'], tr/val_loss:  0.928875/  4.573702, val:  70.42%, val_best:  70.42%, tr:  94.48%, tr_best:  94.48%\n",
      "epoch-12  lr=['0.0100000'], tr/val_loss:  0.676893/  4.645519, val:  75.42%, val_best:  75.42%, tr:  96.53%, tr_best:  96.53%\n",
      "epoch-13  lr=['0.0100000'], tr/val_loss:  0.472985/  5.233957, val:  71.25%, val_best:  75.42%, tr:  97.96%, tr_best:  97.96%\n",
      "epoch-14  lr=['0.0100000'], tr/val_loss:  0.285385/  5.040146, val:  72.08%, val_best:  75.42%, tr:  99.08%, tr_best:  99.08%\n",
      "epoch-15  lr=['0.0100000'], tr/val_loss:  0.191300/  5.237218, val:  71.25%, val_best:  75.42%, tr:  99.69%, tr_best:  99.69%\n",
      "epoch-16  lr=['0.0100000'], tr/val_loss:  0.173027/  4.949299, val:  74.58%, val_best:  75.42%, tr:  99.80%, tr_best:  99.80%\n",
      "epoch-17  lr=['0.0100000'], tr/val_loss:  0.143130/  4.977579, val:  73.75%, val_best:  75.42%, tr:  99.69%, tr_best:  99.80%\n",
      "epoch-18  lr=['0.0100000'], tr/val_loss:  0.156547/  5.292919, val:  75.42%, val_best:  75.42%, tr:  99.59%, tr_best:  99.80%\n",
      "epoch-19  lr=['0.0100000'], tr/val_loss:  0.074581/  5.461728, val:  69.58%, val_best:  75.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-20  lr=['0.0100000'], tr/val_loss:  0.056311/  5.426814, val:  75.00%, val_best:  75.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-21  lr=['0.0100000'], tr/val_loss:  0.039617/  5.577930, val:  75.00%, val_best:  75.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-22  lr=['0.0100000'], tr/val_loss:  0.035793/  5.547688, val:  75.00%, val_best:  75.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-23  lr=['0.0100000'], tr/val_loss:  0.042331/  5.672706, val:  76.25%, val_best:  76.25%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-24  lr=['0.0100000'], tr/val_loss:  0.018334/  5.677316, val:  75.83%, val_best:  76.25%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-25  lr=['0.0100000'], tr/val_loss:  0.019311/  5.715405, val:  75.42%, val_best:  76.25%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-26  lr=['0.0100000'], tr/val_loss:  0.016880/  5.657133, val:  74.17%, val_best:  76.25%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-27  lr=['0.0100000'], tr/val_loss:  0.013763/  5.785134, val:  73.33%, val_best:  76.25%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-28  lr=['0.0100000'], tr/val_loss:  0.012828/  5.784091, val:  74.17%, val_best:  76.25%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-29  lr=['0.0100000'], tr/val_loss:  0.010226/  5.810113, val:  73.33%, val_best:  76.25%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-30  lr=['0.0100000'], tr/val_loss:  0.008962/  5.757925, val:  73.33%, val_best:  76.25%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-31  lr=['0.0100000'], tr/val_loss:  0.008613/  5.807140, val:  76.25%, val_best:  76.25%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-32  lr=['0.0100000'], tr/val_loss:  0.007853/  5.869613, val:  72.92%, val_best:  76.25%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-33  lr=['0.0100000'], tr/val_loss:  0.010020/  5.943161, val:  72.92%, val_best:  76.25%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-34  lr=['0.0100000'], tr/val_loss:  0.004468/  5.869074, val:  75.00%, val_best:  76.25%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-35  lr=['0.0100000'], tr/val_loss:  0.004320/  5.894629, val:  75.00%, val_best:  76.25%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-36  lr=['0.0100000'], tr/val_loss:  0.004148/  5.821043, val:  75.00%, val_best:  76.25%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-37  lr=['0.0100000'], tr/val_loss:  0.004866/  5.878259, val:  74.17%, val_best:  76.25%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-38  lr=['0.0100000'], tr/val_loss:  0.006106/  5.933069, val:  73.33%, val_best:  76.25%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-39  lr=['0.0100000'], tr/val_loss:  0.003229/  5.847936, val:  73.33%, val_best:  76.25%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-40  lr=['0.0100000'], tr/val_loss:  0.005093/  5.901330, val:  72.08%, val_best:  76.25%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-41  lr=['0.0100000'], tr/val_loss:  0.005182/  5.947026, val:  75.83%, val_best:  76.25%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-42  lr=['0.0100000'], tr/val_loss:  0.002562/  5.956027, val:  73.33%, val_best:  76.25%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-43  lr=['0.0100000'], tr/val_loss:  0.002009/  5.902578, val:  74.58%, val_best:  76.25%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-44  lr=['0.0100000'], tr/val_loss:  0.001226/  5.848729, val:  76.25%, val_best:  76.25%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-45  lr=['0.0100000'], tr/val_loss:  0.001122/  5.914567, val:  73.75%, val_best:  76.25%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-46  lr=['0.0100000'], tr/val_loss:  0.001399/  5.888589, val:  75.00%, val_best:  76.25%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-47  lr=['0.0100000'], tr/val_loss:  0.003458/  6.025830, val:  72.08%, val_best:  76.25%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-48  lr=['0.0100000'], tr/val_loss:  0.001929/  5.952682, val:  74.17%, val_best:  76.25%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-49  lr=['0.0100000'], tr/val_loss:  0.002162/  6.005663, val:  73.75%, val_best:  76.25%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-50  lr=['0.0100000'], tr/val_loss:  0.001426/  5.971956, val:  75.00%, val_best:  76.25%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-51  lr=['0.0100000'], tr/val_loss:  0.002120/  6.029911, val:  74.58%, val_best:  76.25%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-52  lr=['0.0100000'], tr/val_loss:  0.001522/  5.921337, val:  74.58%, val_best:  76.25%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-53  lr=['0.0100000'], tr/val_loss:  0.003794/  5.978022, val:  75.00%, val_best:  76.25%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-54  lr=['0.0100000'], tr/val_loss:  0.003264/  5.994576, val:  75.83%, val_best:  76.25%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-55  lr=['0.0100000'], tr/val_loss:  0.002633/  6.016043, val:  75.00%, val_best:  76.25%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-56  lr=['0.0100000'], tr/val_loss:  0.002577/  5.994934, val:  75.00%, val_best:  76.25%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-57  lr=['0.0100000'], tr/val_loss:  0.002115/  5.968096, val:  75.42%, val_best:  76.25%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-58  lr=['0.0100000'], tr/val_loss:  0.000805/  6.058205, val:  74.58%, val_best:  76.25%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-59  lr=['0.0100000'], tr/val_loss:  0.000988/  6.041742, val:  75.42%, val_best:  76.25%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-60  lr=['0.0100000'], tr/val_loss:  0.001212/  6.115824, val:  72.92%, val_best:  76.25%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-61  lr=['0.0100000'], tr/val_loss:  0.001866/  6.059320, val:  72.92%, val_best:  76.25%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-62  lr=['0.0100000'], tr/val_loss:  0.001040/  5.971698, val:  74.58%, val_best:  76.25%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-63  lr=['0.0100000'], tr/val_loss:  0.000546/  6.038915, val:  74.58%, val_best:  76.25%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-64  lr=['0.0100000'], tr/val_loss:  0.000661/  6.010643, val:  74.58%, val_best:  76.25%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-65  lr=['0.0100000'], tr/val_loss:  0.000453/  6.035609, val:  73.75%, val_best:  76.25%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-66  lr=['0.0100000'], tr/val_loss:  0.000443/  6.038596, val:  74.17%, val_best:  76.25%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-67  lr=['0.0100000'], tr/val_loss:  0.000710/  6.002653, val:  75.00%, val_best:  76.25%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-68  lr=['0.0100000'], tr/val_loss:  0.001188/  6.154107, val:  72.92%, val_best:  76.25%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-69  lr=['0.0100000'], tr/val_loss:  0.001601/  6.107891, val:  75.00%, val_best:  76.25%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-70  lr=['0.0100000'], tr/val_loss:  0.001604/  6.144487, val:  74.58%, val_best:  76.25%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-71  lr=['0.0100000'], tr/val_loss:  0.000865/  6.191705, val:  73.75%, val_best:  76.25%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-72  lr=['0.0100000'], tr/val_loss:  0.000660/  6.117712, val:  74.58%, val_best:  76.25%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-73  lr=['0.0100000'], tr/val_loss:  0.000480/  6.076088, val:  75.42%, val_best:  76.25%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-74  lr=['0.0100000'], tr/val_loss:  0.000524/  6.154428, val:  73.75%, val_best:  76.25%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-75  lr=['0.0100000'], tr/val_loss:  0.000657/  6.083768, val:  74.58%, val_best:  76.25%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-76  lr=['0.0100000'], tr/val_loss:  0.000328/  6.072736, val:  75.00%, val_best:  76.25%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-77  lr=['0.0100000'], tr/val_loss:  0.000362/  6.074234, val:  75.42%, val_best:  76.25%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-78  lr=['0.0100000'], tr/val_loss:  0.000307/  6.077306, val:  75.42%, val_best:  76.25%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-79  lr=['0.0100000'], tr/val_loss:  0.001018/  6.100465, val:  74.58%, val_best:  76.25%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-80  lr=['0.0100000'], tr/val_loss:  0.000718/  6.121271, val:  74.58%, val_best:  76.25%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-81  lr=['0.0100000'], tr/val_loss:  0.001231/  6.060240, val:  75.42%, val_best:  76.25%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-82  lr=['0.0100000'], tr/val_loss:  0.000791/  6.042881, val:  75.42%, val_best:  76.25%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-83  lr=['0.0100000'], tr/val_loss:  0.000706/  6.121522, val:  74.58%, val_best:  76.25%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-84  lr=['0.0100000'], tr/val_loss:  0.001082/  6.043417, val:  74.17%, val_best:  76.25%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-85  lr=['0.0100000'], tr/val_loss:  0.000441/  6.065402, val:  73.75%, val_best:  76.25%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-86  lr=['0.0100000'], tr/val_loss:  0.000373/  6.089701, val:  75.00%, val_best:  76.25%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-87  lr=['0.0100000'], tr/val_loss:  0.000346/  6.071575, val:  75.42%, val_best:  76.25%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-88  lr=['0.0100000'], tr/val_loss:  0.000573/  6.081275, val:  75.00%, val_best:  76.25%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-89  lr=['0.0100000'], tr/val_loss:  0.000411/  6.081919, val:  76.25%, val_best:  76.25%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-90  lr=['0.0100000'], tr/val_loss:  0.000391/  6.075500, val:  76.25%, val_best:  76.25%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-91  lr=['0.0100000'], tr/val_loss:  0.000210/  6.096221, val:  75.83%, val_best:  76.25%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-92  lr=['0.0100000'], tr/val_loss:  0.000205/  6.122454, val:  75.42%, val_best:  76.25%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-93  lr=['0.0100000'], tr/val_loss:  0.000581/  6.112244, val:  76.25%, val_best:  76.25%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-94  lr=['0.0100000'], tr/val_loss:  0.001263/  6.096824, val:  75.42%, val_best:  76.25%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-95  lr=['0.0100000'], tr/val_loss:  0.001105/  6.184867, val:  73.75%, val_best:  76.25%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-96  lr=['0.0100000'], tr/val_loss:  0.000713/  6.126460, val:  75.00%, val_best:  76.25%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-97  lr=['0.0100000'], tr/val_loss:  0.000628/  6.131074, val:  75.42%, val_best:  76.25%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-98  lr=['0.0100000'], tr/val_loss:  0.000318/  6.119391, val:  74.58%, val_best:  76.25%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-99  lr=['0.0100000'], tr/val_loss:  0.000351/  6.147734, val:  74.58%, val_best:  76.25%, tr: 100.00%, tr_best: 100.00%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b73d2dbcb7024fc5924f0ca6716fde17",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.006 MB of 0.006 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>iter_acc</td><td>▁▃▅▆▅▇██████████████████████████████████</td></tr><tr><td>summary_val_acc</td><td>▁▂▄▅▅█▇█▇████▇█████▇█████▇██████████████</td></tr><tr><td>tr_acc</td><td>▁▃▄▆▆███████████████████████████████████</td></tr><tr><td>tr_epoch_loss</td><td>▇█▆▃▄▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_acc_best</td><td>▁▂▄▅▅███████████████████████████████████</td></tr><tr><td>val_acc_now</td><td>▁▂▄▅▅█▇█▇████▇█████▇█████▇██████████████</td></tr><tr><td>val_loss</td><td>▂▆▅▁▆▄▅▅▆▆▇▇▇▇▇▇▇▇▇██▇█▇████████████████</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>99</td></tr><tr><td>iter_acc</td><td>1.0</td></tr><tr><td>tr_acc</td><td>1.0</td></tr><tr><td>tr_epoch_loss</td><td>0.00035</td></tr><tr><td>val_acc_best</td><td>0.7625</td></tr><tr><td>val_acc_now</td><td>0.74583</td></tr><tr><td>val_loss</td><td>6.14773</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">avid-sweep-152</strong> at: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/6jv6hhoa' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/6jv6hhoa</a><br/> View project at: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>/data2/bh_wandb/wandb/run-20250430_031352-6jv6hhoa/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require(\"core\")`! See https://wandb.me/wandb-core for more information."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: h1tf6yoq with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBATCH: 16\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBN_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBPTT_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tDFA_on: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tIMAGE_SIZE: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tOTTT_input_trace_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tTIME: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tUDA_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \talpha_uda: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbias: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcfg: ['M', 'M', 200, 200]\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tchaching_on: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tconvTrue_fcFalse: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdata_path: /data2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tddp_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdenoise_on: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdvs_clipping: 5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdvs_duration: 100000\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepoch_num: 100\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \texclude_class: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \textra_train_dataset: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlast_lif: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.01\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_sg_width: 4\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_decay: 0.5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_init: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_reset: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_threshold: 0.75\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmerge_polarities: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmy_seed: 42\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnet_print: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_workers: 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer_what: SGD\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tpin_memory: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tpre_trained: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tpre_trained_path: net_save/save_now_net_weights_{unique_name}.pth\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \trate_coding: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tscheduler_name: no\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsingle_step: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsurrogate: hard_sigmoid\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_conv_kernel_size: 3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_conv_padding: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_conv_stride: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_trace_const1: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_trace_const2: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \ttdBN_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \ttrace_on: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \twhich_data: DVS_GESTURE_TONIC\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2fc71076c60d41e38a42620887034422",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.011113825455928842, max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.19.10 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.17.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/data2/bh_wandb/wandb/run-20250430_032033-h1tf6yoq</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/h1tf6yoq' target=\"_blank\">golden-sweep-154</a></strong> to <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/6pj3lh8j' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/6pj3lh8j</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/6pj3lh8j' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/6pj3lh8j</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/h1tf6yoq' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/h1tf6yoq</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'single_step' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'my_seed' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'TIME' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BATCH' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'IMAGE_SIZE' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'which_data' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'data_path' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'rate_coding' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_init' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_decay' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_threshold' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_reset' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_sg_width' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_conv_kernel_size' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_conv_stride' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_conv_padding' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_trace_const1' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_trace_const2' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'pre_trained' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'convTrue_fcFalse' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'cfg' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'net_print' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'pre_trained_path' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'learning_rate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'epoch_num' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'tdBN_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BN_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'surrogate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BPTT_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'optimizer_what' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'scheduler_name' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'ddp_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'dvs_clipping' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'dvs_duration' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'DFA_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'trace_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'OTTT_input_trace_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'exclude_class' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'merge_polarities' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'denoise_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'extra_train_dataset' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'num_workers' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'chaching_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'pin_memory' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'UDA_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'alpha_uda' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'bias' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'last_lif' was locked by 'sweep' (ignored update).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "param {'devices': '0', 'single_step': True, 'unique_name': 'main', 'my_seed': 42, 'TIME': 10, 'BATCH': 16, 'IMAGE_SIZE': 128, 'which_data': 'DVS_GESTURE_TONIC', 'data_path': '/data2', 'rate_coding': False, 'lif_layer_v_init': 0, 'lif_layer_v_decay': 0.5, 'lif_layer_v_threshold': 0.75, 'lif_layer_v_reset': 0, 'lif_layer_sg_width': 4, 'synapse_conv_kernel_size': 3, 'synapse_conv_stride': 1, 'synapse_conv_padding': 1, 'synapse_trace_const1': 1, 'synapse_trace_const2': 0, 'pre_trained': False, 'convTrue_fcFalse': False, 'cfg': ['M', 'M', 200, 200], 'net_print': True, 'pre_trained_path': 'net_save/save_now_net_weights_{unique_name}.pth', 'learning_rate': 0.01, 'epoch_num': 100, 'tdBN_on': False, 'BN_on': False, 'surrogate': 'hard_sigmoid', 'BPTT_on': False, 'optimizer_what': 'SGD', 'scheduler_name': 'no', 'ddp_on': False, 'dvs_clipping': 5, 'dvs_duration': 100000, 'DFA_on': True, 'trace_on': True, 'OTTT_input_trace_on': False, 'exclude_class': True, 'merge_polarities': False, 'denoise_on': True, 'extra_train_dataset': 0, 'num_workers': 2, 'chaching_on': True, 'pin_memory': True, 'UDA_on': False, 'alpha_uda': 1, 'bias': True, 'last_lif': False, 'current epoch': 0} \n",
      "\n",
      "dataset_hash = 63cc597115630ec173f3099200061e53\n",
      "cache path exists\n",
      "\n",
      "device ==> cuda\n",
      "\n",
      "DataParallel(\n",
      "  (module): REBORN_MY_SNN_FC(\n",
      "    (layers): REBORN_MY_Sequential(\n",
      "      (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (2): DimChanger_for_FC()\n",
      "      (3): SYNAPSE_FC(in_features=2048, out_features=200, TIME=10, bias=True, sstep=True)\n",
      "      (4): LIF_layer(v_init=0, v_decay=0.5, v_threshold=0.75, v_reset=0, sg_width=4, surrogate=hard_sigmoid, BPTT_on=False, trace_const1=1, trace_const2=0, TIME=10, sstep=True, trace_on=True)\n",
      "      (5): Feedback_Receiver()\n",
      "      (6): SYNAPSE_FC(in_features=200, out_features=200, TIME=10, bias=True, sstep=True)\n",
      "      (7): LIF_layer(v_init=0, v_decay=0.5, v_threshold=0.75, v_reset=0, sg_width=4, surrogate=hard_sigmoid, BPTT_on=False, trace_const1=1, trace_const2=0, TIME=10, sstep=True, trace_on=True)\n",
      "      (8): Feedback_Receiver()\n",
      "      (9): SYNAPSE_FC(in_features=200, out_features=10, TIME=10, bias=True, sstep=True)\n",
      "      (DFA_top): Top_Gradient()\n",
      "    )\n",
      "  )\n",
      ")\n",
      "\n",
      "========================================================\n",
      "Trainable parameters: 452,010\n",
      "========================================================\n",
      "\n",
      "epoch-0   lr=['0.0100000'], tr/val_loss:  2.041522/  1.743388, val:  40.83%, val_best:  40.83%, tr:  23.39%, tr_best:  23.39%\n",
      "[module.layers.5] weight_fb parameter count: 2,000\n",
      "[module.layers.8] weight_fb parameter count: 2,000\n",
      "epoch-1   lr=['0.0100000'], tr/val_loss:  1.415731/  1.781344, val:  56.25%, val_best:  56.25%, tr:  55.57%, tr_best:  55.57%\n",
      "epoch-2   lr=['0.0100000'], tr/val_loss:  1.487417/  1.866825, val:  51.67%, val_best:  56.25%, tr:  61.39%, tr_best:  61.39%\n",
      "epoch-3   lr=['0.0100000'], tr/val_loss:  1.136984/  1.655463, val:  57.50%, val_best:  57.50%, tr:  66.50%, tr_best:  66.50%\n",
      "epoch-4   lr=['0.0100000'], tr/val_loss:  1.027019/  1.447082, val:  62.50%, val_best:  62.50%, tr:  67.93%, tr_best:  67.93%\n",
      "epoch-5   lr=['0.0100000'], tr/val_loss:  0.903420/  1.660774, val:  57.92%, val_best:  62.50%, tr:  73.54%, tr_best:  73.54%\n",
      "epoch-6   lr=['0.0100000'], tr/val_loss:  0.924655/  1.459841, val:  61.25%, val_best:  62.50%, tr:  77.12%, tr_best:  77.12%\n",
      "epoch-7   lr=['0.0100000'], tr/val_loss:  0.880675/  1.527546, val:  66.67%, val_best:  66.67%, tr:  77.43%, tr_best:  77.43%\n",
      "epoch-8   lr=['0.0100000'], tr/val_loss:  0.752748/  1.521281, val:  66.25%, val_best:  66.67%, tr:  82.23%, tr_best:  82.23%\n",
      "epoch-9   lr=['0.0100000'], tr/val_loss:  0.637329/  1.717845, val:  62.92%, val_best:  66.67%, tr:  87.54%, tr_best:  87.54%\n",
      "epoch-10  lr=['0.0100000'], tr/val_loss:  0.565545/  1.464506, val:  73.75%, val_best:  73.75%, tr:  90.40%, tr_best:  90.40%\n",
      "epoch-11  lr=['0.0100000'], tr/val_loss:  0.503408/  1.596811, val:  70.83%, val_best:  73.75%, tr:  92.13%, tr_best:  92.13%\n",
      "epoch-12  lr=['0.0100000'], tr/val_loss:  0.380897/  1.476362, val:  77.50%, val_best:  77.50%, tr:  96.63%, tr_best:  96.63%\n",
      "epoch-13  lr=['0.0100000'], tr/val_loss:  0.294717/  1.526999, val:  78.75%, val_best:  78.75%, tr:  96.94%, tr_best:  96.94%\n",
      "epoch-14  lr=['0.0100000'], tr/val_loss:  0.266439/  1.609141, val:  76.25%, val_best:  78.75%, tr:  97.55%, tr_best:  97.55%\n",
      "epoch-15  lr=['0.0100000'], tr/val_loss:  0.203643/  1.715414, val:  77.92%, val_best:  78.75%, tr:  99.18%, tr_best:  99.18%\n",
      "epoch-16  lr=['0.0100000'], tr/val_loss:  0.149106/  1.782215, val:  76.67%, val_best:  78.75%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-17  lr=['0.0100000'], tr/val_loss:  0.156839/  1.792056, val:  78.33%, val_best:  78.75%, tr:  99.39%, tr_best: 100.00%\n",
      "epoch-18  lr=['0.0100000'], tr/val_loss:  0.120343/  1.775794, val:  77.08%, val_best:  78.75%, tr:  99.90%, tr_best: 100.00%\n",
      "epoch-19  lr=['0.0100000'], tr/val_loss:  0.107809/  1.865563, val:  79.58%, val_best:  79.58%, tr:  99.90%, tr_best: 100.00%\n",
      "epoch-20  lr=['0.0100000'], tr/val_loss:  0.088424/  1.858863, val:  78.33%, val_best:  79.58%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-21  lr=['0.0100000'], tr/val_loss:  0.077945/  1.886715, val:  77.92%, val_best:  79.58%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-22  lr=['0.0100000'], tr/val_loss:  0.062360/  1.950945, val:  79.58%, val_best:  79.58%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-23  lr=['0.0100000'], tr/val_loss:  0.059119/  1.985091, val:  78.33%, val_best:  79.58%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-24  lr=['0.0100000'], tr/val_loss:  0.051688/  2.007281, val:  81.25%, val_best:  81.25%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-25  lr=['0.0100000'], tr/val_loss:  0.047349/  2.026270, val:  81.67%, val_best:  81.67%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-26  lr=['0.0100000'], tr/val_loss:  0.043410/  2.020132, val:  82.92%, val_best:  82.92%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-27  lr=['0.0100000'], tr/val_loss:  0.036617/  2.075800, val:  82.50%, val_best:  82.92%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-28  lr=['0.0100000'], tr/val_loss:  0.032473/  2.141954, val:  82.08%, val_best:  82.92%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-29  lr=['0.0100000'], tr/val_loss:  0.031283/  2.195878, val:  81.25%, val_best:  82.92%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-30  lr=['0.0100000'], tr/val_loss:  0.032312/  2.168889, val:  81.25%, val_best:  82.92%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-31  lr=['0.0100000'], tr/val_loss:  0.025559/  2.192969, val:  81.67%, val_best:  82.92%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-32  lr=['0.0100000'], tr/val_loss:  0.022534/  2.207289, val:  82.08%, val_best:  82.92%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-33  lr=['0.0100000'], tr/val_loss:  0.026899/  2.249877, val:  81.25%, val_best:  82.92%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-34  lr=['0.0100000'], tr/val_loss:  0.025315/  2.283492, val:  80.83%, val_best:  82.92%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-35  lr=['0.0100000'], tr/val_loss:  0.022628/  2.306101, val:  82.50%, val_best:  82.92%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-36  lr=['0.0100000'], tr/val_loss:  0.020672/  2.296839, val:  81.67%, val_best:  82.92%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-37  lr=['0.0100000'], tr/val_loss:  0.021175/  2.333162, val:  83.33%, val_best:  83.33%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-38  lr=['0.0100000'], tr/val_loss:  0.018692/  2.315674, val:  82.50%, val_best:  83.33%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-39  lr=['0.0100000'], tr/val_loss:  0.023760/  2.334811, val:  84.17%, val_best:  84.17%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-40  lr=['0.0100000'], tr/val_loss:  0.018141/  2.325516, val:  83.75%, val_best:  84.17%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-41  lr=['0.0100000'], tr/val_loss:  0.015469/  2.328988, val:  82.50%, val_best:  84.17%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-42  lr=['0.0100000'], tr/val_loss:  0.015008/  2.421512, val:  82.08%, val_best:  84.17%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-43  lr=['0.0100000'], tr/val_loss:  0.015129/  2.413587, val:  81.25%, val_best:  84.17%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-44  lr=['0.0100000'], tr/val_loss:  0.013688/  2.401444, val:  84.17%, val_best:  84.17%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-45  lr=['0.0100000'], tr/val_loss:  0.013741/  2.430203, val:  82.92%, val_best:  84.17%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-46  lr=['0.0100000'], tr/val_loss:  0.013318/  2.443730, val:  83.75%, val_best:  84.17%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-47  lr=['0.0100000'], tr/val_loss:  0.014673/  2.442906, val:  81.67%, val_best:  84.17%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-48  lr=['0.0100000'], tr/val_loss:  0.014579/  2.457928, val:  82.92%, val_best:  84.17%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-49  lr=['0.0100000'], tr/val_loss:  0.012085/  2.498379, val:  82.50%, val_best:  84.17%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-50  lr=['0.0100000'], tr/val_loss:  0.011656/  2.523494, val:  80.83%, val_best:  84.17%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-51  lr=['0.0100000'], tr/val_loss:  0.011706/  2.545662, val:  82.08%, val_best:  84.17%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-52  lr=['0.0100000'], tr/val_loss:  0.010669/  2.543139, val:  81.67%, val_best:  84.17%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-53  lr=['0.0100000'], tr/val_loss:  0.009405/  2.561625, val:  80.83%, val_best:  84.17%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-54  lr=['0.0100000'], tr/val_loss:  0.011957/  2.562568, val:  81.67%, val_best:  84.17%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-55  lr=['0.0100000'], tr/val_loss:  0.011516/  2.559131, val:  82.08%, val_best:  84.17%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-56  lr=['0.0100000'], tr/val_loss:  0.010590/  2.599390, val:  80.42%, val_best:  84.17%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-57  lr=['0.0100000'], tr/val_loss:  0.010114/  2.540897, val:  80.42%, val_best:  84.17%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-58  lr=['0.0100000'], tr/val_loss:  0.010599/  2.600497, val:  80.42%, val_best:  84.17%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-59  lr=['0.0100000'], tr/val_loss:  0.009282/  2.566004, val:  81.67%, val_best:  84.17%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-60  lr=['0.0100000'], tr/val_loss:  0.009483/  2.608076, val:  81.25%, val_best:  84.17%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-61  lr=['0.0100000'], tr/val_loss:  0.008336/  2.587667, val:  82.50%, val_best:  84.17%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-62  lr=['0.0100000'], tr/val_loss:  0.008383/  2.625958, val:  82.08%, val_best:  84.17%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-63  lr=['0.0100000'], tr/val_loss:  0.008714/  2.604498, val:  81.25%, val_best:  84.17%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-64  lr=['0.0100000'], tr/val_loss:  0.007524/  2.642310, val:  80.83%, val_best:  84.17%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-65  lr=['0.0100000'], tr/val_loss:  0.007843/  2.629466, val:  83.75%, val_best:  84.17%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-66  lr=['0.0100000'], tr/val_loss:  0.008753/  2.633129, val:  82.08%, val_best:  84.17%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-67  lr=['0.0100000'], tr/val_loss:  0.008074/  2.672573, val:  81.67%, val_best:  84.17%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-68  lr=['0.0100000'], tr/val_loss:  0.006907/  2.655511, val:  81.67%, val_best:  84.17%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-69  lr=['0.0100000'], tr/val_loss:  0.006711/  2.694637, val:  82.08%, val_best:  84.17%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-70  lr=['0.0100000'], tr/val_loss:  0.006240/  2.667571, val:  83.33%, val_best:  84.17%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-71  lr=['0.0100000'], tr/val_loss:  0.009419/  2.722485, val:  83.33%, val_best:  84.17%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-72  lr=['0.0100000'], tr/val_loss:  0.008504/  2.697147, val:  81.67%, val_best:  84.17%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-73  lr=['0.0100000'], tr/val_loss:  0.008604/  2.701398, val:  82.08%, val_best:  84.17%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-74  lr=['0.0100000'], tr/val_loss:  0.008328/  2.745606, val:  82.50%, val_best:  84.17%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-75  lr=['0.0100000'], tr/val_loss:  0.008539/  2.730877, val:  82.92%, val_best:  84.17%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-76  lr=['0.0100000'], tr/val_loss:  0.006683/  2.711948, val:  84.17%, val_best:  84.17%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-77  lr=['0.0100000'], tr/val_loss:  0.006232/  2.743655, val:  82.92%, val_best:  84.17%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-78  lr=['0.0100000'], tr/val_loss:  0.006297/  2.740204, val:  82.92%, val_best:  84.17%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-79  lr=['0.0100000'], tr/val_loss:  0.005865/  2.731128, val:  82.92%, val_best:  84.17%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-80  lr=['0.0100000'], tr/val_loss:  0.005497/  2.730759, val:  83.75%, val_best:  84.17%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-81  lr=['0.0100000'], tr/val_loss:  0.005231/  2.768221, val:  82.08%, val_best:  84.17%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-82  lr=['0.0100000'], tr/val_loss:  0.005133/  2.778483, val:  81.25%, val_best:  84.17%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-83  lr=['0.0100000'], tr/val_loss:  0.005224/  2.782993, val:  83.33%, val_best:  84.17%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-84  lr=['0.0100000'], tr/val_loss:  0.005469/  2.768065, val:  82.92%, val_best:  84.17%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-85  lr=['0.0100000'], tr/val_loss:  0.004973/  2.799939, val:  82.08%, val_best:  84.17%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-86  lr=['0.0100000'], tr/val_loss:  0.005128/  2.792066, val:  83.75%, val_best:  84.17%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-87  lr=['0.0100000'], tr/val_loss:  0.004183/  2.792747, val:  82.50%, val_best:  84.17%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-88  lr=['0.0100000'], tr/val_loss:  0.005314/  2.769492, val:  82.92%, val_best:  84.17%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-89  lr=['0.0100000'], tr/val_loss:  0.004504/  2.792537, val:  82.50%, val_best:  84.17%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-90  lr=['0.0100000'], tr/val_loss:  0.004468/  2.809806, val:  83.33%, val_best:  84.17%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-91  lr=['0.0100000'], tr/val_loss:  0.003908/  2.824349, val:  81.25%, val_best:  84.17%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-92  lr=['0.0100000'], tr/val_loss:  0.004076/  2.840418, val:  80.83%, val_best:  84.17%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-93  lr=['0.0100000'], tr/val_loss:  0.004498/  2.816798, val:  82.08%, val_best:  84.17%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-94  lr=['0.0100000'], tr/val_loss:  0.004212/  2.832736, val:  80.42%, val_best:  84.17%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-95  lr=['0.0100000'], tr/val_loss:  0.004578/  2.852417, val:  81.25%, val_best:  84.17%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-96  lr=['0.0100000'], tr/val_loss:  0.003878/  2.856457, val:  81.25%, val_best:  84.17%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-97  lr=['0.0100000'], tr/val_loss:  0.003157/  2.836564, val:  81.25%, val_best:  84.17%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-98  lr=['0.0100000'], tr/val_loss:  0.003967/  2.844465, val:  80.83%, val_best:  84.17%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-99  lr=['0.0100000'], tr/val_loss:  0.005234/  2.829117, val:  81.67%, val_best:  84.17%, tr: 100.00%, tr_best: 100.00%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "193eefe4f72b4c23bbd4458864739af6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.006 MB of 0.006 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>iter_acc</td><td>▁▆▅▅▄███████████████████████████████████</td></tr><tr><td>summary_val_acc</td><td>▁▃▅▅▅▇▇▇▇▇█████████████▇█████████████▇██</td></tr><tr><td>tr_acc</td><td>▁▄▅▆▇███████████████████████████████████</td></tr><tr><td>tr_epoch_loss</td><td>█▆▅▄▃▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_acc_best</td><td>▁▃▅▅▅▇▇▇▇▇██████████████████████████████</td></tr><tr><td>val_acc_now</td><td>▁▃▅▅▅▇▇▇▇▇█████████████▇█████████████▇██</td></tr><tr><td>val_loss</td><td>▂▃▁▁▂▁▂▃▃▃▄▄▅▅▅▅▅▆▆▆▆▆▇▆▇▇▇▇▇▇▇▇▇███████</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>99</td></tr><tr><td>iter_acc</td><td>1.0</td></tr><tr><td>tr_acc</td><td>1.0</td></tr><tr><td>tr_epoch_loss</td><td>0.00523</td></tr><tr><td>val_acc_best</td><td>0.84167</td></tr><tr><td>val_acc_now</td><td>0.81667</td></tr><tr><td>val_loss</td><td>2.82912</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">golden-sweep-154</strong> at: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/h1tf6yoq' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/h1tf6yoq</a><br/> View project at: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>/data2/bh_wandb/wandb/run-20250430_032033-h1tf6yoq/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require(\"core\")`! See https://wandb.me/wandb-core for more information."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: pawqrnb6 with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBATCH: 16\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBN_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBPTT_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tDFA_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tIMAGE_SIZE: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tOTTT_input_trace_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tTIME: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tUDA_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \talpha_uda: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbias: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcfg: ['M', 'M', 200, 200]\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tchaching_on: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tconvTrue_fcFalse: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdata_path: /data2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tddp_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdenoise_on: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdvs_clipping: 5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdvs_duration: 100000\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepoch_num: 100\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \texclude_class: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \textra_train_dataset: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlast_lif: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_sg_width: 4\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_decay: 0.5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_init: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_reset: 10000\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_threshold: 0.5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmerge_polarities: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmy_seed: 42\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnet_print: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_workers: 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer_what: SGD\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tpin_memory: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tpre_trained: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tpre_trained_path: net_save/save_now_net_weights_{unique_name}.pth\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \trate_coding: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tscheduler_name: no\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsingle_step: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsurrogate: hard_sigmoid\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_conv_kernel_size: 3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_conv_padding: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_conv_stride: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_trace_const1: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_trace_const2: 0.5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \ttdBN_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \ttrace_on: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \twhich_data: DVS_GESTURE_TONIC\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.19.10 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.17.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/data2/bh_wandb/wandb/run-20250430_032707-pawqrnb6</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/pawqrnb6' target=\"_blank\">spring-sweep-156</a></strong> to <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/6pj3lh8j' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/6pj3lh8j</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/6pj3lh8j' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/6pj3lh8j</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/pawqrnb6' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/pawqrnb6</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'single_step' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'my_seed' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'TIME' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BATCH' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'IMAGE_SIZE' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'which_data' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'data_path' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'rate_coding' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_init' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_decay' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_threshold' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_reset' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_sg_width' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_conv_kernel_size' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_conv_stride' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_conv_padding' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_trace_const1' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_trace_const2' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'pre_trained' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'convTrue_fcFalse' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'cfg' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'net_print' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'pre_trained_path' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'learning_rate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'epoch_num' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'tdBN_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BN_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'surrogate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BPTT_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'optimizer_what' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'scheduler_name' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'ddp_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'dvs_clipping' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'dvs_duration' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'DFA_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'trace_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'OTTT_input_trace_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'exclude_class' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'merge_polarities' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'denoise_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'extra_train_dataset' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'num_workers' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'chaching_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'pin_memory' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'UDA_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'alpha_uda' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'bias' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'last_lif' was locked by 'sweep' (ignored update).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "param {'devices': '0', 'single_step': True, 'unique_name': 'main', 'my_seed': 42, 'TIME': 10, 'BATCH': 16, 'IMAGE_SIZE': 128, 'which_data': 'DVS_GESTURE_TONIC', 'data_path': '/data2', 'rate_coding': False, 'lif_layer_v_init': 0, 'lif_layer_v_decay': 0.5, 'lif_layer_v_threshold': 0.5, 'lif_layer_v_reset': 10000, 'lif_layer_sg_width': 4, 'synapse_conv_kernel_size': 3, 'synapse_conv_stride': 1, 'synapse_conv_padding': 1, 'synapse_trace_const1': 1, 'synapse_trace_const2': 0.5, 'pre_trained': False, 'convTrue_fcFalse': False, 'cfg': ['M', 'M', 200, 200], 'net_print': True, 'pre_trained_path': 'net_save/save_now_net_weights_{unique_name}.pth', 'learning_rate': 0.1, 'epoch_num': 100, 'tdBN_on': False, 'BN_on': False, 'surrogate': 'hard_sigmoid', 'BPTT_on': False, 'optimizer_what': 'SGD', 'scheduler_name': 'no', 'ddp_on': False, 'dvs_clipping': 5, 'dvs_duration': 100000, 'DFA_on': False, 'trace_on': True, 'OTTT_input_trace_on': False, 'exclude_class': True, 'merge_polarities': False, 'denoise_on': True, 'extra_train_dataset': 0, 'num_workers': 2, 'chaching_on': True, 'pin_memory': True, 'UDA_on': False, 'alpha_uda': 1, 'bias': True, 'last_lif': False, 'current epoch': 0} \n",
      "\n",
      "dataset_hash = 63cc597115630ec173f3099200061e53\n",
      "cache path exists\n",
      "\n",
      "device ==> cuda\n",
      "\n",
      "DataParallel(\n",
      "  (module): REBORN_MY_SNN_FC(\n",
      "    (layers): REBORN_MY_Sequential(\n",
      "      (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (2): DimChanger_for_FC()\n",
      "      (3): SYNAPSE_FC(in_features=2048, out_features=200, TIME=10, bias=True, sstep=True)\n",
      "      (4): LIF_layer(v_init=0, v_decay=0.5, v_threshold=0.5, v_reset=10000, sg_width=4, surrogate=hard_sigmoid, BPTT_on=False, trace_const1=1, trace_const2=0.5, TIME=10, sstep=True, trace_on=True)\n",
      "      (5): SYNAPSE_FC(in_features=200, out_features=200, TIME=10, bias=True, sstep=True)\n",
      "      (6): LIF_layer(v_init=0, v_decay=0.5, v_threshold=0.5, v_reset=10000, sg_width=4, surrogate=hard_sigmoid, BPTT_on=False, trace_const1=1, trace_const2=0.5, TIME=10, sstep=True, trace_on=True)\n",
      "      (7): SYNAPSE_FC(in_features=200, out_features=10, TIME=10, bias=True, sstep=True)\n",
      "    )\n",
      "  )\n",
      ")\n",
      "\n",
      "========================================================\n",
      "Trainable parameters: 452,010\n",
      "========================================================\n",
      "\n",
      "epoch-0   lr=['0.1000000'], tr/val_loss:  2.745603/  5.317639, val:  29.17%, val_best:  29.17%, tr:  29.11%, tr_best:  29.11%\n",
      "epoch-1   lr=['0.1000000'], tr/val_loss:  4.675456/  5.452350, val:  25.00%, val_best:  29.17%, tr:  29.21%, tr_best:  29.21%\n",
      "epoch-2   lr=['0.1000000'], tr/val_loss:  5.877503/  3.803891, val:  34.17%, val_best:  34.17%, tr:  30.64%, tr_best:  30.64%\n",
      "epoch-3   lr=['0.1000000'], tr/val_loss:  5.974053/  4.363550, val:  31.25%, val_best:  34.17%, tr:  31.46%, tr_best:  31.46%\n",
      "epoch-4   lr=['0.1000000'], tr/val_loss:  6.643719/  5.290923, val:  29.58%, val_best:  34.17%, tr:  30.13%, tr_best:  31.46%\n",
      "epoch-5   lr=['0.1000000'], tr/val_loss:  9.380608/ 11.232340, val:  15.83%, val_best:  34.17%, tr:  24.51%, tr_best:  31.46%\n",
      "epoch-6   lr=['0.1000000'], tr/val_loss: 10.148827/ 19.181171, val:  10.00%, val_best:  34.17%, tr:  18.49%, tr_best:  31.46%\n",
      "epoch-7   lr=['0.1000000'], tr/val_loss: 19.204035/ 20.787271, val:  10.00%, val_best:  34.17%, tr:   9.81%, tr_best:  31.46%\n",
      "epoch-8   lr=['0.1000000'], tr/val_loss: 19.718977/ 13.831263, val:  10.00%, val_best:  34.17%, tr:  11.13%, tr_best:  31.46%\n",
      "epoch-9   lr=['0.1000000'], tr/val_loss: 20.285568/ 24.179817, val:  10.00%, val_best:  34.17%, tr:  10.42%, tr_best:  31.46%\n",
      "epoch-10  lr=['0.1000000'], tr/val_loss: 20.641260/ 23.399721, val:  10.00%, val_best:  34.17%, tr:  10.52%, tr_best:  31.46%\n",
      "epoch-11  lr=['0.1000000'], tr/val_loss: 20.385647/ 20.645905, val:  10.00%, val_best:  34.17%, tr:  10.21%, tr_best:  31.46%\n",
      "epoch-12  lr=['0.1000000'], tr/val_loss: 20.716551/ 34.075878, val:  10.00%, val_best:  34.17%, tr:   8.99%, tr_best:  31.46%\n",
      "epoch-13  lr=['0.1000000'], tr/val_loss: 26.350960/ 14.686834, val:  10.00%, val_best:  34.17%, tr:   9.30%, tr_best:  31.46%\n",
      "epoch-14  lr=['0.1000000'], tr/val_loss: 18.107504/ 27.835876, val:  10.00%, val_best:  34.17%, tr:  10.83%, tr_best:  31.46%\n",
      "epoch-15  lr=['0.1000000'], tr/val_loss: 18.824183/ 16.739117, val:  10.00%, val_best:  34.17%, tr:  10.11%, tr_best:  31.46%\n",
      "epoch-16  lr=['0.1000000'], tr/val_loss: 17.538874/ 11.982935, val:  10.00%, val_best:  34.17%, tr:  10.21%, tr_best:  31.46%\n",
      "epoch-17  lr=['0.1000000'], tr/val_loss: 16.963291/ 16.948793, val:  10.00%, val_best:  34.17%, tr:  10.01%, tr_best:  31.46%\n",
      "epoch-18  lr=['0.1000000'], tr/val_loss: 18.293060/ 15.230721, val:  10.00%, val_best:  34.17%, tr:  11.64%, tr_best:  31.46%\n",
      "epoch-19  lr=['0.1000000'], tr/val_loss: 20.523188/ 16.685051, val:  10.00%, val_best:  34.17%, tr:   9.81%, tr_best:  31.46%\n",
      "epoch-20  lr=['0.1000000'], tr/val_loss: 21.928091/ 38.253376, val:  10.00%, val_best:  34.17%, tr:   9.19%, tr_best:  31.46%\n",
      "epoch-21  lr=['0.1000000'], tr/val_loss: 21.676435/ 16.339058, val:  10.00%, val_best:  34.17%, tr:  10.52%, tr_best:  31.46%\n",
      "epoch-22  lr=['0.1000000'], tr/val_loss: 19.928638/ 17.198492, val:  10.00%, val_best:  34.17%, tr:  10.32%, tr_best:  31.46%\n",
      "epoch-23  lr=['0.1000000'], tr/val_loss: 22.125660/ 20.418949, val:  10.00%, val_best:  34.17%, tr:   9.81%, tr_best:  31.46%\n",
      "epoch-24  lr=['0.1000000'], tr/val_loss: 18.636005/ 21.750572, val:  10.00%, val_best:  34.17%, tr:  10.01%, tr_best:  31.46%\n",
      "epoch-25  lr=['0.1000000'], tr/val_loss: 16.881573/ 29.419970, val:  10.00%, val_best:  34.17%, tr:  10.01%, tr_best:  31.46%\n",
      "epoch-26  lr=['0.1000000'], tr/val_loss: 18.668386/ 15.329121, val:  10.00%, val_best:  34.17%, tr:   9.91%, tr_best:  31.46%\n",
      "epoch-27  lr=['0.1000000'], tr/val_loss: 20.344027/ 17.549028, val:  10.00%, val_best:  34.17%, tr:   9.19%, tr_best:  31.46%\n",
      "epoch-28  lr=['0.1000000'], tr/val_loss: 20.330795/ 18.959162, val:  10.00%, val_best:  34.17%, tr:  10.52%, tr_best:  31.46%\n",
      "epoch-29  lr=['0.1000000'], tr/val_loss: 23.466225/ 22.409325, val:  10.00%, val_best:  34.17%, tr:  10.11%, tr_best:  31.46%\n",
      "epoch-30  lr=['0.1000000'], tr/val_loss: 19.526167/ 18.728815, val:  10.00%, val_best:  34.17%, tr:   8.78%, tr_best:  31.46%\n",
      "epoch-31  lr=['0.1000000'], tr/val_loss: 24.033033/ 22.295227, val:  10.00%, val_best:  34.17%, tr:  10.21%, tr_best:  31.46%\n",
      "epoch-32  lr=['0.1000000'], tr/val_loss: 19.171610/ 34.849804, val:  10.00%, val_best:  34.17%, tr:   9.60%, tr_best:  31.46%\n",
      "epoch-33  lr=['0.1000000'], tr/val_loss: 21.548557/ 17.113667, val:  10.00%, val_best:  34.17%, tr:   9.70%, tr_best:  31.46%\n",
      "epoch-34  lr=['0.1000000'], tr/val_loss: 22.870598/ 24.425125, val:  10.00%, val_best:  34.17%, tr:   9.81%, tr_best:  31.46%\n",
      "epoch-35  lr=['0.1000000'], tr/val_loss: 21.540157/ 19.891506, val:  10.00%, val_best:  34.17%, tr:  13.48%, tr_best:  31.46%\n",
      "epoch-36  lr=['0.1000000'], tr/val_loss: 19.695620/ 15.048978, val:  10.00%, val_best:  34.17%, tr:   7.87%, tr_best:  31.46%\n",
      "epoch-37  lr=['0.1000000'], tr/val_loss: 17.515486/ 12.399195, val:  10.00%, val_best:  34.17%, tr:  11.13%, tr_best:  31.46%\n",
      "epoch-38  lr=['0.1000000'], tr/val_loss: 16.461374/ 19.204361, val:  10.00%, val_best:  34.17%, tr:  10.52%, tr_best:  31.46%\n",
      "epoch-39  lr=['0.1000000'], tr/val_loss: 20.034544/ 22.825029, val:  10.00%, val_best:  34.17%, tr:   9.60%, tr_best:  31.46%\n",
      "epoch-40  lr=['0.1000000'], tr/val_loss: 18.902334/ 14.773403, val:  10.00%, val_best:  34.17%, tr:   9.60%, tr_best:  31.46%\n",
      "epoch-41  lr=['0.1000000'], tr/val_loss: 17.715229/ 17.959564, val:  10.00%, val_best:  34.17%, tr:  10.93%, tr_best:  31.46%\n",
      "epoch-42  lr=['0.1000000'], tr/val_loss: 16.053236/ 17.377394, val:  10.00%, val_best:  34.17%, tr:  10.32%, tr_best:  31.46%\n",
      "epoch-43  lr=['0.1000000'], tr/val_loss: 18.062872/ 33.891953, val:  10.00%, val_best:  34.17%, tr:   9.30%, tr_best:  31.46%\n",
      "epoch-44  lr=['0.1000000'], tr/val_loss: 22.774759/ 18.167910, val:  10.00%, val_best:  34.17%, tr:   9.70%, tr_best:  31.46%\n",
      "epoch-45  lr=['0.1000000'], tr/val_loss: 21.037100/ 24.949942, val:  10.00%, val_best:  34.17%, tr:   9.91%, tr_best:  31.46%\n",
      "epoch-46  lr=['0.1000000'], tr/val_loss: 19.849138/ 20.571320, val:  10.00%, val_best:  34.17%, tr:   9.60%, tr_best:  31.46%\n",
      "epoch-47  lr=['0.1000000'], tr/val_loss: 21.375219/ 21.643900, val:  10.00%, val_best:  34.17%, tr:  10.32%, tr_best:  31.46%\n",
      "epoch-48  lr=['0.1000000'], tr/val_loss: 20.886719/ 13.636359, val:  10.00%, val_best:  34.17%, tr:  11.54%, tr_best:  31.46%\n",
      "epoch-49  lr=['0.1000000'], tr/val_loss: 19.860235/ 23.908173, val:  10.00%, val_best:  34.17%, tr:   8.99%, tr_best:  31.46%\n",
      "epoch-50  lr=['0.1000000'], tr/val_loss: 20.079113/ 27.201105, val:  10.00%, val_best:  34.17%, tr:   9.81%, tr_best:  31.46%\n",
      "epoch-51  lr=['0.1000000'], tr/val_loss: 19.797928/ 19.348476, val:  10.00%, val_best:  34.17%, tr:   7.66%, tr_best:  31.46%\n",
      "epoch-52  lr=['0.1000000'], tr/val_loss: 19.486954/ 19.079903, val:  10.00%, val_best:  34.17%, tr:  10.83%, tr_best:  31.46%\n",
      "epoch-53  lr=['0.1000000'], tr/val_loss: 20.721214/ 32.704586, val:  10.00%, val_best:  34.17%, tr:   9.40%, tr_best:  31.46%\n",
      "epoch-54  lr=['0.1000000'], tr/val_loss: 19.886642/ 15.194327, val:  10.00%, val_best:  34.17%, tr:  10.73%, tr_best:  31.46%\n",
      "epoch-55  lr=['0.1000000'], tr/val_loss: 20.172659/ 18.976681, val:  10.00%, val_best:  34.17%, tr:   9.19%, tr_best:  31.46%\n",
      "epoch-56  lr=['0.1000000'], tr/val_loss: 18.059210/ 30.218971, val:  10.00%, val_best:  34.17%, tr:   8.89%, tr_best:  31.46%\n",
      "epoch-57  lr=['0.1000000'], tr/val_loss: 16.433626/  9.565213, val:  10.00%, val_best:  34.17%, tr:  11.24%, tr_best:  31.46%\n",
      "epoch-58  lr=['0.1000000'], tr/val_loss: 22.077990/ 21.506382, val:  10.00%, val_best:  34.17%, tr:   8.99%, tr_best:  31.46%\n",
      "epoch-59  lr=['0.1000000'], tr/val_loss: 17.053900/ 11.369298, val:  10.00%, val_best:  34.17%, tr:  10.11%, tr_best:  31.46%\n",
      "epoch-60  lr=['0.1000000'], tr/val_loss: 15.359859/ 20.253450, val:  10.00%, val_best:  34.17%, tr:   9.19%, tr_best:  31.46%\n",
      "epoch-61  lr=['0.1000000'], tr/val_loss: 17.371067/ 20.873289, val:  10.00%, val_best:  34.17%, tr:   9.70%, tr_best:  31.46%\n",
      "epoch-62  lr=['0.1000000'], tr/val_loss: 22.667431/ 33.317425, val:  10.00%, val_best:  34.17%, tr:   7.35%, tr_best:  31.46%\n",
      "epoch-63  lr=['0.1000000'], tr/val_loss: 26.043154/ 22.253611, val:  10.00%, val_best:  34.17%, tr:  11.75%, tr_best:  31.46%\n",
      "epoch-64  lr=['0.1000000'], tr/val_loss: 23.684692/ 21.038670, val:  10.00%, val_best:  34.17%, tr:  10.21%, tr_best:  31.46%\n",
      "epoch-65  lr=['0.1000000'], tr/val_loss: 19.588789/ 14.713614, val:  10.00%, val_best:  34.17%, tr:  10.21%, tr_best:  31.46%\n",
      "epoch-66  lr=['0.1000000'], tr/val_loss: 22.493502/ 25.352116, val:  10.00%, val_best:  34.17%, tr:   9.50%, tr_best:  31.46%\n",
      "epoch-67  lr=['0.1000000'], tr/val_loss: 26.568851/ 16.261971, val:  10.00%, val_best:  34.17%, tr:  10.52%, tr_best:  31.46%\n",
      "epoch-68  lr=['0.1000000'], tr/val_loss: 19.097303/ 10.258650, val:  10.00%, val_best:  34.17%, tr:   9.40%, tr_best:  31.46%\n",
      "epoch-69  lr=['0.1000000'], tr/val_loss: 16.226992/  8.170842, val:  10.00%, val_best:  34.17%, tr:   9.91%, tr_best:  31.46%\n",
      "epoch-70  lr=['0.1000000'], tr/val_loss: 17.303514/ 13.234605, val:  10.00%, val_best:  34.17%, tr:   8.99%, tr_best:  31.46%\n",
      "epoch-71  lr=['0.1000000'], tr/val_loss: 22.790827/ 12.579120, val:  10.00%, val_best:  34.17%, tr:  11.24%, tr_best:  31.46%\n",
      "epoch-72  lr=['0.1000000'], tr/val_loss: 22.272707/ 20.407917, val:  10.00%, val_best:  34.17%, tr:   9.50%, tr_best:  31.46%\n",
      "epoch-73  lr=['0.1000000'], tr/val_loss: 23.238432/ 22.190500, val:  10.00%, val_best:  34.17%, tr:   9.60%, tr_best:  31.46%\n",
      "epoch-74  lr=['0.1000000'], tr/val_loss: 20.718637/ 18.687634, val:  10.00%, val_best:  34.17%, tr:  12.46%, tr_best:  31.46%\n",
      "epoch-75  lr=['0.1000000'], tr/val_loss: 21.954388/ 17.398293, val:  10.00%, val_best:  34.17%, tr:   8.89%, tr_best:  31.46%\n",
      "epoch-76  lr=['0.1000000'], tr/val_loss: 18.934694/ 19.072632, val:  10.00%, val_best:  34.17%, tr:  10.01%, tr_best:  31.46%\n",
      "epoch-77  lr=['0.1000000'], tr/val_loss: 16.053669/ 18.908737, val:  10.00%, val_best:  34.17%, tr:  12.26%, tr_best:  31.46%\n",
      "epoch-78  lr=['0.1000000'], tr/val_loss: 22.443155/ 27.158222, val:  10.00%, val_best:  34.17%, tr:   8.99%, tr_best:  31.46%\n",
      "epoch-79  lr=['0.1000000'], tr/val_loss: 18.801140/ 24.665892, val:  10.00%, val_best:  34.17%, tr:  10.62%, tr_best:  31.46%\n",
      "epoch-80  lr=['0.1000000'], tr/val_loss: 17.386009/ 20.071045, val:  10.00%, val_best:  34.17%, tr:   9.50%, tr_best:  31.46%\n",
      "epoch-81  lr=['0.1000000'], tr/val_loss: 23.095774/ 18.983828, val:  10.00%, val_best:  34.17%, tr:  10.32%, tr_best:  31.46%\n",
      "epoch-82  lr=['0.1000000'], tr/val_loss: 25.759668/ 32.182388, val:  10.00%, val_best:  34.17%, tr:  11.13%, tr_best:  31.46%\n",
      "epoch-83  lr=['0.1000000'], tr/val_loss: 18.606863/  9.870749, val:  10.00%, val_best:  34.17%, tr:  10.32%, tr_best:  31.46%\n",
      "epoch-84  lr=['0.1000000'], tr/val_loss: 20.136446/ 16.195091, val:  10.00%, val_best:  34.17%, tr:  10.52%, tr_best:  31.46%\n",
      "epoch-85  lr=['0.1000000'], tr/val_loss: 19.302982/ 20.852629, val:  10.00%, val_best:  34.17%, tr:  10.73%, tr_best:  31.46%\n",
      "epoch-86  lr=['0.1000000'], tr/val_loss: 18.213078/ 20.151529, val:  10.00%, val_best:  34.17%, tr:  10.21%, tr_best:  31.46%\n",
      "epoch-87  lr=['0.1000000'], tr/val_loss: 19.168865/ 12.962777, val:  10.00%, val_best:  34.17%, tr:  10.93%, tr_best:  31.46%\n",
      "epoch-88  lr=['0.1000000'], tr/val_loss: 17.062824/ 19.898508, val:  10.00%, val_best:  34.17%, tr:   9.40%, tr_best:  31.46%\n",
      "epoch-89  lr=['0.1000000'], tr/val_loss: 19.475273/ 19.861588, val:  10.00%, val_best:  34.17%, tr:  10.11%, tr_best:  31.46%\n",
      "epoch-90  lr=['0.1000000'], tr/val_loss: 19.824667/ 18.299191, val:  10.00%, val_best:  34.17%, tr:   9.40%, tr_best:  31.46%\n",
      "epoch-91  lr=['0.1000000'], tr/val_loss: 20.377430/ 28.930922, val:  10.00%, val_best:  34.17%, tr:   9.40%, tr_best:  31.46%\n",
      "epoch-92  lr=['0.1000000'], tr/val_loss: 16.565851/ 17.275072, val:  10.00%, val_best:  34.17%, tr:  11.13%, tr_best:  31.46%\n",
      "epoch-93  lr=['0.1000000'], tr/val_loss: 22.448332/ 17.878925, val:  10.00%, val_best:  34.17%, tr:   8.58%, tr_best:  31.46%\n",
      "epoch-94  lr=['0.1000000'], tr/val_loss: 20.664795/ 20.509680, val:  10.00%, val_best:  34.17%, tr:   9.91%, tr_best:  31.46%\n",
      "epoch-95  lr=['0.1000000'], tr/val_loss: 18.425268/ 19.638983, val:  10.00%, val_best:  34.17%, tr:   9.30%, tr_best:  31.46%\n",
      "epoch-96  lr=['0.1000000'], tr/val_loss: 19.805595/ 30.024878, val:  10.00%, val_best:  34.17%, tr:   9.19%, tr_best:  31.46%\n",
      "epoch-97  lr=['0.1000000'], tr/val_loss: 20.180187/ 22.965755, val:  10.00%, val_best:  34.17%, tr:  10.42%, tr_best:  31.46%\n",
      "epoch-98  lr=['0.1000000'], tr/val_loss: 24.730829/ 32.521957, val:  10.00%, val_best:  34.17%, tr:  10.21%, tr_best:  31.46%\n",
      "epoch-99  lr=['0.1000000'], tr/val_loss: 28.500999/ 22.020535, val:  10.00%, val_best:  34.17%, tr:  11.24%, tr_best:  31.46%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f2202236ad2e47c49cc26d074818058d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.006 MB of 0.006 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>iter_acc</td><td>█▄▅▄▂▂▃▃▄▁▅▂▆▃▁▄▃▅▂▃▄▄▁▄▄▂▁▂▃▃▃▁▃▂▅▂▁▂▁▄</td></tr><tr><td>summary_val_acc</td><td>▇█▇▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>tr_acc</td><td>███▁▁▁▂▁▁▂▁▁▁▁▂▂▁▁▁▁▁▂▂▂▁▁▁▂▁▁▁▂▂▂▂▂▁▂▁▁</td></tr><tr><td>tr_epoch_loss</td><td>▁▂▂▆▆▆▆▅▆▇▆▆▇▆▇▅▆▅▇▆▆▆▆▅▅▅▆█▅▇▇▅▆█▆▆▆▅▆▆</td></tr><tr><td>val_acc_best</td><td>▁███████████████████████████████████████</td></tr><tr><td>val_acc_now</td><td>▇█▇▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_loss</td><td>▁▁▁▅▆█▆▄▄▄▅▄▅█▅▃▅▄▄▅▆▄▄▂▃▅▃▄▃▅▄▄▆▇▄▃▅▄▅▅</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>99</td></tr><tr><td>iter_acc</td><td>0.0</td></tr><tr><td>tr_acc</td><td>0.11236</td></tr><tr><td>tr_epoch_loss</td><td>28.501</td></tr><tr><td>val_acc_best</td><td>0.34167</td></tr><tr><td>val_acc_now</td><td>0.1</td></tr><tr><td>val_loss</td><td>22.02053</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">spring-sweep-156</strong> at: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/pawqrnb6' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/pawqrnb6</a><br/> View project at: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>/data2/bh_wandb/wandb/run-20250430_032707-pawqrnb6/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require(\"core\")`! See https://wandb.me/wandb-core for more information."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 0ov4viwv with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBATCH: 16\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBN_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBPTT_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tDFA_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tIMAGE_SIZE: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tOTTT_input_trace_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tTIME: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tUDA_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \talpha_uda: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbias: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcfg: ['M', 'M', 200, 200]\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tchaching_on: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tconvTrue_fcFalse: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdata_path: /data2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tddp_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdenoise_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdvs_clipping: 5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdvs_duration: 100000\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepoch_num: 100\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \texclude_class: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \textra_train_dataset: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlast_lif: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.01\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_sg_width: 5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_decay: 0.5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_init: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_reset: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_threshold: 0.25\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmerge_polarities: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmy_seed: 42\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnet_print: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_workers: 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer_what: SGD\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tpin_memory: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tpre_trained: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tpre_trained_path: net_save/save_now_net_weights_{unique_name}.pth\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \trate_coding: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tscheduler_name: no\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsingle_step: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsurrogate: hard_sigmoid\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_conv_kernel_size: 3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_conv_padding: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_conv_stride: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_trace_const1: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_trace_const2: 0.5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \ttdBN_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \ttrace_on: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \twhich_data: DVS_GESTURE_TONIC\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.19.10 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.17.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/data2/bh_wandb/wandb/run-20250430_033310-0ov4viwv</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/0ov4viwv' target=\"_blank\">olive-sweep-158</a></strong> to <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/6pj3lh8j' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/6pj3lh8j</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/6pj3lh8j' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/6pj3lh8j</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/0ov4viwv' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/0ov4viwv</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'single_step' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'my_seed' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'TIME' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BATCH' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'IMAGE_SIZE' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'which_data' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'data_path' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'rate_coding' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_init' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_decay' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_threshold' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_reset' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_sg_width' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_conv_kernel_size' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_conv_stride' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_conv_padding' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_trace_const1' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_trace_const2' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'pre_trained' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'convTrue_fcFalse' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'cfg' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'net_print' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'pre_trained_path' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'learning_rate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'epoch_num' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'tdBN_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BN_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'surrogate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BPTT_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'optimizer_what' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'scheduler_name' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'ddp_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'dvs_clipping' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'dvs_duration' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'DFA_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'trace_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'OTTT_input_trace_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'exclude_class' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'merge_polarities' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'denoise_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'extra_train_dataset' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'num_workers' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'chaching_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'pin_memory' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'UDA_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'alpha_uda' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'bias' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'last_lif' was locked by 'sweep' (ignored update).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "param {'devices': '0', 'single_step': True, 'unique_name': 'main', 'my_seed': 42, 'TIME': 10, 'BATCH': 16, 'IMAGE_SIZE': 128, 'which_data': 'DVS_GESTURE_TONIC', 'data_path': '/data2', 'rate_coding': False, 'lif_layer_v_init': 0, 'lif_layer_v_decay': 0.5, 'lif_layer_v_threshold': 0.25, 'lif_layer_v_reset': 0, 'lif_layer_sg_width': 5, 'synapse_conv_kernel_size': 3, 'synapse_conv_stride': 1, 'synapse_conv_padding': 1, 'synapse_trace_const1': 1, 'synapse_trace_const2': 0.5, 'pre_trained': False, 'convTrue_fcFalse': False, 'cfg': ['M', 'M', 200, 200], 'net_print': True, 'pre_trained_path': 'net_save/save_now_net_weights_{unique_name}.pth', 'learning_rate': 0.01, 'epoch_num': 100, 'tdBN_on': False, 'BN_on': False, 'surrogate': 'hard_sigmoid', 'BPTT_on': False, 'optimizer_what': 'SGD', 'scheduler_name': 'no', 'ddp_on': False, 'dvs_clipping': 5, 'dvs_duration': 100000, 'DFA_on': False, 'trace_on': True, 'OTTT_input_trace_on': False, 'exclude_class': True, 'merge_polarities': False, 'denoise_on': False, 'extra_train_dataset': 0, 'num_workers': 2, 'chaching_on': True, 'pin_memory': True, 'UDA_on': False, 'alpha_uda': 1, 'bias': True, 'last_lif': False, 'current epoch': 0} \n",
      "\n",
      "dataset_hash = ffa516e60c3efd5e0208f72b4c36cb84\n",
      "cache path exists\n",
      "\n",
      "device ==> cuda\n",
      "\n",
      "DataParallel(\n",
      "  (module): REBORN_MY_SNN_FC(\n",
      "    (layers): REBORN_MY_Sequential(\n",
      "      (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (2): DimChanger_for_FC()\n",
      "      (3): SYNAPSE_FC(in_features=2048, out_features=200, TIME=10, bias=True, sstep=True)\n",
      "      (4): LIF_layer(v_init=0, v_decay=0.5, v_threshold=0.25, v_reset=0, sg_width=5, surrogate=hard_sigmoid, BPTT_on=False, trace_const1=1, trace_const2=0.5, TIME=10, sstep=True, trace_on=True)\n",
      "      (5): SYNAPSE_FC(in_features=200, out_features=200, TIME=10, bias=True, sstep=True)\n",
      "      (6): LIF_layer(v_init=0, v_decay=0.5, v_threshold=0.25, v_reset=0, sg_width=5, surrogate=hard_sigmoid, BPTT_on=False, trace_const1=1, trace_const2=0.5, TIME=10, sstep=True, trace_on=True)\n",
      "      (7): SYNAPSE_FC(in_features=200, out_features=10, TIME=10, bias=True, sstep=True)\n",
      "    )\n",
      "  )\n",
      ")\n",
      "\n",
      "========================================================\n",
      "Trainable parameters: 452,010\n",
      "========================================================\n",
      "\n",
      "epoch-0   lr=['0.0100000'], tr/val_loss:  1.620018/  1.636192, val:  50.42%, val_best:  50.42%, tr:  46.07%, tr_best:  46.07%\n",
      "epoch-1   lr=['0.0100000'], tr/val_loss:  1.197180/  1.333462, val:  55.00%, val_best:  55.00%, tr:  57.00%, tr_best:  57.00%\n",
      "epoch-2   lr=['0.0100000'], tr/val_loss:  1.029815/  1.370323, val:  55.00%, val_best:  55.00%, tr:  61.39%, tr_best:  61.39%\n",
      "epoch-3   lr=['0.0100000'], tr/val_loss:  0.841715/  1.374807, val:  58.33%, val_best:  58.33%, tr:  71.30%, tr_best:  71.30%\n",
      "epoch-4   lr=['0.0100000'], tr/val_loss:  0.864384/  1.513463, val:  60.42%, val_best:  60.42%, tr:  67.52%, tr_best:  71.30%\n",
      "epoch-5   lr=['0.0100000'], tr/val_loss:  0.744942/  1.509213, val:  52.92%, val_best:  60.42%, tr:  73.75%, tr_best:  73.75%\n",
      "epoch-6   lr=['0.0100000'], tr/val_loss:  0.640428/  1.335696, val:  61.67%, val_best:  61.67%, tr:  77.22%, tr_best:  77.22%\n",
      "epoch-7   lr=['0.0100000'], tr/val_loss:  0.669994/  1.400092, val:  65.00%, val_best:  65.00%, tr:  75.08%, tr_best:  77.22%\n",
      "epoch-8   lr=['0.0100000'], tr/val_loss:  0.601453/  1.486360, val:  61.25%, val_best:  65.00%, tr:  76.40%, tr_best:  77.22%\n",
      "epoch-9   lr=['0.0100000'], tr/val_loss:  0.496532/  1.520722, val:  65.00%, val_best:  65.00%, tr:  84.07%, tr_best:  84.07%\n",
      "epoch-10  lr=['0.0100000'], tr/val_loss:  0.517717/  1.377529, val:  64.17%, val_best:  65.00%, tr:  84.17%, tr_best:  84.17%\n",
      "epoch-11  lr=['0.0100000'], tr/val_loss:  0.527334/  1.643961, val:  65.00%, val_best:  65.00%, tr:  84.68%, tr_best:  84.68%\n",
      "epoch-12  lr=['0.0100000'], tr/val_loss:  0.554054/  1.777181, val:  63.33%, val_best:  65.00%, tr:  84.68%, tr_best:  84.68%\n",
      "epoch-13  lr=['0.0100000'], tr/val_loss:  0.539636/  1.636158, val:  61.25%, val_best:  65.00%, tr:  84.98%, tr_best:  84.98%\n",
      "epoch-14  lr=['0.0100000'], tr/val_loss:  0.495719/  1.999864, val:  60.42%, val_best:  65.00%, tr:  86.01%, tr_best:  86.01%\n",
      "epoch-15  lr=['0.0100000'], tr/val_loss:  0.466374/  1.799927, val:  64.58%, val_best:  65.00%, tr:  87.84%, tr_best:  87.84%\n",
      "epoch-16  lr=['0.0100000'], tr/val_loss:  0.384515/  1.749717, val:  68.75%, val_best:  68.75%, tr:  92.24%, tr_best:  92.24%\n",
      "epoch-17  lr=['0.0100000'], tr/val_loss:  0.353185/  1.765931, val:  69.58%, val_best:  69.58%, tr:  93.77%, tr_best:  93.77%\n",
      "epoch-18  lr=['0.0100000'], tr/val_loss:  0.355654/  1.755291, val:  70.42%, val_best:  70.42%, tr:  91.62%, tr_best:  93.77%\n",
      "epoch-19  lr=['0.0100000'], tr/val_loss:  0.473503/  1.896926, val:  70.00%, val_best:  70.42%, tr:  89.79%, tr_best:  93.77%\n",
      "epoch-20  lr=['0.0100000'], tr/val_loss:  0.442668/  1.828112, val:  67.50%, val_best:  70.42%, tr:  90.81%, tr_best:  93.77%\n",
      "epoch-21  lr=['0.0100000'], tr/val_loss:  0.332129/  1.775834, val:  69.58%, val_best:  70.42%, tr:  93.87%, tr_best:  93.87%\n",
      "epoch-22  lr=['0.0100000'], tr/val_loss:  0.332560/  1.742605, val:  74.58%, val_best:  74.58%, tr:  94.48%, tr_best:  94.48%\n",
      "epoch-23  lr=['0.0100000'], tr/val_loss:  0.348884/  2.047803, val:  65.42%, val_best:  74.58%, tr:  92.95%, tr_best:  94.48%\n",
      "epoch-24  lr=['0.0100000'], tr/val_loss:  0.330985/  1.955101, val:  71.67%, val_best:  74.58%, tr:  94.59%, tr_best:  94.59%\n",
      "epoch-25  lr=['0.0100000'], tr/val_loss:  0.292830/  1.981370, val:  73.75%, val_best:  74.58%, tr:  97.45%, tr_best:  97.45%\n",
      "epoch-26  lr=['0.0100000'], tr/val_loss:  0.351208/  1.909431, val:  70.00%, val_best:  74.58%, tr:  95.40%, tr_best:  97.45%\n",
      "epoch-27  lr=['0.0100000'], tr/val_loss:  0.346968/  2.235969, val:  66.25%, val_best:  74.58%, tr:  94.28%, tr_best:  97.45%\n",
      "epoch-28  lr=['0.0100000'], tr/val_loss:  0.375566/  1.878436, val:  68.75%, val_best:  74.58%, tr:  94.89%, tr_best:  97.45%\n",
      "epoch-29  lr=['0.0100000'], tr/val_loss:  0.323804/  2.122917, val:  66.25%, val_best:  74.58%, tr:  95.71%, tr_best:  97.45%\n",
      "epoch-30  lr=['0.0100000'], tr/val_loss:  0.354335/  2.165982, val:  66.67%, val_best:  74.58%, tr:  97.04%, tr_best:  97.45%\n",
      "epoch-31  lr=['0.0100000'], tr/val_loss:  0.380653/  2.251983, val:  70.42%, val_best:  74.58%, tr:  94.48%, tr_best:  97.45%\n",
      "epoch-32  lr=['0.0100000'], tr/val_loss:  0.460027/  1.948004, val:  75.00%, val_best:  75.00%, tr:  91.52%, tr_best:  97.45%\n",
      "epoch-33  lr=['0.0100000'], tr/val_loss:  0.386161/  2.204630, val:  66.25%, val_best:  75.00%, tr:  94.18%, tr_best:  97.45%\n",
      "epoch-34  lr=['0.0100000'], tr/val_loss:  0.403022/  2.567544, val:  63.75%, val_best:  75.00%, tr:  95.61%, tr_best:  97.45%\n",
      "epoch-35  lr=['0.0100000'], tr/val_loss:  0.347079/  2.385012, val:  67.92%, val_best:  75.00%, tr:  95.81%, tr_best:  97.45%\n",
      "epoch-36  lr=['0.0100000'], tr/val_loss:  0.327350/  2.295297, val:  69.17%, val_best:  75.00%, tr:  96.53%, tr_best:  97.45%\n",
      "epoch-37  lr=['0.0100000'], tr/val_loss:  0.390144/  2.135935, val:  68.75%, val_best:  75.00%, tr:  94.59%, tr_best:  97.45%\n",
      "epoch-38  lr=['0.0100000'], tr/val_loss:  0.350758/  2.205465, val:  70.00%, val_best:  75.00%, tr:  96.73%, tr_best:  97.45%\n",
      "epoch-39  lr=['0.0100000'], tr/val_loss:  0.368612/  2.264335, val:  71.67%, val_best:  75.00%, tr:  95.10%, tr_best:  97.45%\n",
      "epoch-40  lr=['0.0100000'], tr/val_loss:  0.366267/  2.215621, val:  69.58%, val_best:  75.00%, tr:  95.81%, tr_best:  97.45%\n",
      "epoch-41  lr=['0.0100000'], tr/val_loss:  0.310440/  2.523981, val:  66.67%, val_best:  75.00%, tr:  97.24%, tr_best:  97.45%\n",
      "epoch-42  lr=['0.0100000'], tr/val_loss:  0.347177/  2.425656, val:  71.25%, val_best:  75.00%, tr:  96.63%, tr_best:  97.45%\n",
      "epoch-43  lr=['0.0100000'], tr/val_loss:  0.362352/  2.638367, val:  65.83%, val_best:  75.00%, tr:  96.22%, tr_best:  97.45%\n",
      "epoch-44  lr=['0.0100000'], tr/val_loss:  0.400926/  2.380152, val:  65.42%, val_best:  75.00%, tr:  94.79%, tr_best:  97.45%\n",
      "epoch-45  lr=['0.0100000'], tr/val_loss:  0.375557/  2.497312, val:  65.83%, val_best:  75.00%, tr:  95.40%, tr_best:  97.45%\n",
      "epoch-46  lr=['0.0100000'], tr/val_loss:  0.431726/  2.486984, val:  66.25%, val_best:  75.00%, tr:  95.51%, tr_best:  97.45%\n",
      "epoch-47  lr=['0.0100000'], tr/val_loss:  0.453549/  2.316757, val:  70.00%, val_best:  75.00%, tr:  94.79%, tr_best:  97.45%\n",
      "epoch-48  lr=['0.0100000'], tr/val_loss:  0.377393/  2.348039, val:  73.75%, val_best:  75.00%, tr:  95.91%, tr_best:  97.45%\n",
      "epoch-49  lr=['0.0100000'], tr/val_loss:  0.343670/  2.436769, val:  66.67%, val_best:  75.00%, tr:  97.14%, tr_best:  97.45%\n",
      "epoch-50  lr=['0.0100000'], tr/val_loss:  0.337810/  2.513303, val:  67.92%, val_best:  75.00%, tr:  96.63%, tr_best:  97.45%\n",
      "epoch-51  lr=['0.0100000'], tr/val_loss:  0.482529/  2.007025, val:  74.58%, val_best:  75.00%, tr:  92.85%, tr_best:  97.45%\n",
      "epoch-52  lr=['0.0100000'], tr/val_loss:  0.324834/  2.303869, val:  70.83%, val_best:  75.00%, tr:  97.45%, tr_best:  97.45%\n",
      "epoch-53  lr=['0.0100000'], tr/val_loss:  0.336155/  2.286513, val:  71.25%, val_best:  75.00%, tr:  96.63%, tr_best:  97.45%\n",
      "epoch-54  lr=['0.0100000'], tr/val_loss:  0.402429/  2.456593, val:  69.58%, val_best:  75.00%, tr:  94.69%, tr_best:  97.45%\n",
      "epoch-55  lr=['0.0100000'], tr/val_loss:  0.354888/  2.844150, val:  65.00%, val_best:  75.00%, tr:  96.94%, tr_best:  97.45%\n",
      "epoch-56  lr=['0.0100000'], tr/val_loss:  0.382577/  2.452626, val:  66.25%, val_best:  75.00%, tr:  96.94%, tr_best:  97.45%\n",
      "epoch-57  lr=['0.0100000'], tr/val_loss:  0.394309/  2.466664, val:  68.33%, val_best:  75.00%, tr:  95.81%, tr_best:  97.45%\n",
      "epoch-58  lr=['0.0100000'], tr/val_loss:  0.453194/  2.532701, val:  69.58%, val_best:  75.00%, tr:  95.71%, tr_best:  97.45%\n",
      "epoch-59  lr=['0.0100000'], tr/val_loss:  0.384499/  2.563659, val:  65.42%, val_best:  75.00%, tr:  96.12%, tr_best:  97.45%\n",
      "epoch-60  lr=['0.0100000'], tr/val_loss:  0.364284/  2.806091, val:  71.67%, val_best:  75.00%, tr:  97.45%, tr_best:  97.45%\n",
      "epoch-61  lr=['0.0100000'], tr/val_loss:  0.477854/  2.538950, val:  72.08%, val_best:  75.00%, tr:  94.79%, tr_best:  97.45%\n",
      "epoch-62  lr=['0.0100000'], tr/val_loss:  0.499233/  2.595646, val:  62.92%, val_best:  75.00%, tr:  95.51%, tr_best:  97.45%\n",
      "epoch-63  lr=['0.0100000'], tr/val_loss:  0.475800/  2.319894, val:  70.00%, val_best:  75.00%, tr:  93.87%, tr_best:  97.45%\n",
      "epoch-64  lr=['0.0100000'], tr/val_loss:  0.458612/  2.636219, val:  65.83%, val_best:  75.00%, tr:  94.08%, tr_best:  97.45%\n",
      "epoch-65  lr=['0.0100000'], tr/val_loss:  0.498880/  2.605120, val:  63.75%, val_best:  75.00%, tr:  92.65%, tr_best:  97.45%\n",
      "epoch-66  lr=['0.0100000'], tr/val_loss:  0.453094/  2.781249, val:  65.00%, val_best:  75.00%, tr:  94.59%, tr_best:  97.45%\n",
      "epoch-67  lr=['0.0100000'], tr/val_loss:  0.464435/  2.247671, val:  71.67%, val_best:  75.00%, tr:  96.22%, tr_best:  97.45%\n",
      "epoch-68  lr=['0.0100000'], tr/val_loss:  0.529308/  2.381948, val:  68.75%, val_best:  75.00%, tr:  93.87%, tr_best:  97.45%\n",
      "epoch-69  lr=['0.0100000'], tr/val_loss:  0.626598/  2.294591, val:  70.83%, val_best:  75.00%, tr:  92.03%, tr_best:  97.45%\n",
      "epoch-70  lr=['0.0100000'], tr/val_loss:  0.563002/  2.486475, val:  69.17%, val_best:  75.00%, tr:  94.89%, tr_best:  97.45%\n",
      "epoch-71  lr=['0.0100000'], tr/val_loss:  0.564860/  3.181516, val:  60.83%, val_best:  75.00%, tr:  93.67%, tr_best:  97.45%\n",
      "epoch-72  lr=['0.0100000'], tr/val_loss:  0.570084/  2.879924, val:  65.00%, val_best:  75.00%, tr:  92.95%, tr_best:  97.45%\n",
      "epoch-73  lr=['0.0100000'], tr/val_loss:  0.572910/  2.674161, val:  61.67%, val_best:  75.00%, tr:  93.56%, tr_best:  97.45%\n",
      "epoch-74  lr=['0.0100000'], tr/val_loss:  0.624757/  2.876647, val:  68.75%, val_best:  75.00%, tr:  93.56%, tr_best:  97.45%\n",
      "epoch-75  lr=['0.0100000'], tr/val_loss:  0.627634/  2.747961, val:  67.92%, val_best:  75.00%, tr:  92.95%, tr_best:  97.45%\n",
      "epoch-76  lr=['0.0100000'], tr/val_loss:  0.532533/  3.094651, val:  59.58%, val_best:  75.00%, tr:  93.46%, tr_best:  97.45%\n",
      "epoch-77  lr=['0.0100000'], tr/val_loss:  0.514718/  2.990876, val:  65.42%, val_best:  75.00%, tr:  94.69%, tr_best:  97.45%\n",
      "epoch-78  lr=['0.0100000'], tr/val_loss:  0.612987/  2.565862, val:  69.17%, val_best:  75.00%, tr:  93.36%, tr_best:  97.45%\n",
      "epoch-79  lr=['0.0100000'], tr/val_loss:  0.556489/  2.848040, val:  67.50%, val_best:  75.00%, tr:  93.67%, tr_best:  97.45%\n",
      "epoch-80  lr=['0.0100000'], tr/val_loss:  0.533623/  3.209906, val:  63.75%, val_best:  75.00%, tr:  94.59%, tr_best:  97.45%\n",
      "epoch-81  lr=['0.0100000'], tr/val_loss:  0.621267/  3.085202, val:  57.92%, val_best:  75.00%, tr:  91.93%, tr_best:  97.45%\n",
      "epoch-82  lr=['0.0100000'], tr/val_loss:  0.663135/  2.624198, val:  66.67%, val_best:  75.00%, tr:  90.70%, tr_best:  97.45%\n",
      "epoch-83  lr=['0.0100000'], tr/val_loss:  0.696831/  3.025375, val:  62.92%, val_best:  75.00%, tr:  89.89%, tr_best:  97.45%\n",
      "epoch-84  lr=['0.0100000'], tr/val_loss:  0.611381/  2.684839, val:  62.50%, val_best:  75.00%, tr:  93.36%, tr_best:  97.45%\n",
      "epoch-85  lr=['0.0100000'], tr/val_loss:  0.645683/  3.101111, val:  65.83%, val_best:  75.00%, tr:  92.95%, tr_best:  97.45%\n",
      "epoch-86  lr=['0.0100000'], tr/val_loss:  0.558952/  2.456386, val:  67.50%, val_best:  75.00%, tr:  93.46%, tr_best:  97.45%\n",
      "epoch-87  lr=['0.0100000'], tr/val_loss:  0.540118/  2.440440, val:  68.33%, val_best:  75.00%, tr:  93.67%, tr_best:  97.45%\n",
      "epoch-88  lr=['0.0100000'], tr/val_loss:  0.629889/  2.448814, val:  71.67%, val_best:  75.00%, tr:  91.52%, tr_best:  97.45%\n",
      "epoch-89  lr=['0.0100000'], tr/val_loss:  0.523949/  2.766521, val:  71.67%, val_best:  75.00%, tr:  94.89%, tr_best:  97.45%\n",
      "epoch-90  lr=['0.0100000'], tr/val_loss:  0.584801/  2.313253, val:  76.25%, val_best:  76.25%, tr:  93.46%, tr_best:  97.45%\n",
      "epoch-91  lr=['0.0100000'], tr/val_loss:  0.596934/  2.897528, val:  67.92%, val_best:  76.25%, tr:  94.08%, tr_best:  97.45%\n",
      "epoch-92  lr=['0.0100000'], tr/val_loss:  0.624614/  2.530895, val:  71.25%, val_best:  76.25%, tr:  91.73%, tr_best:  97.45%\n",
      "epoch-93  lr=['0.0100000'], tr/val_loss:  0.711405/  2.450955, val:  71.67%, val_best:  76.25%, tr:  91.52%, tr_best:  97.45%\n",
      "epoch-94  lr=['0.0100000'], tr/val_loss:  0.577434/  2.367346, val:  69.58%, val_best:  76.25%, tr:  93.26%, tr_best:  97.45%\n",
      "epoch-95  lr=['0.0100000'], tr/val_loss:  0.624654/  2.654476, val:  69.17%, val_best:  76.25%, tr:  92.24%, tr_best:  97.45%\n",
      "epoch-96  lr=['0.0100000'], tr/val_loss:  0.679426/  2.516052, val:  69.58%, val_best:  76.25%, tr:  91.52%, tr_best:  97.45%\n",
      "epoch-97  lr=['0.0100000'], tr/val_loss:  0.651718/  2.430730, val:  70.83%, val_best:  76.25%, tr:  92.85%, tr_best:  97.45%\n",
      "epoch-98  lr=['0.0100000'], tr/val_loss:  0.772249/  2.393053, val:  69.17%, val_best:  76.25%, tr:  90.50%, tr_best:  97.45%\n",
      "epoch-99  lr=['0.0100000'], tr/val_loss:  0.937962/  2.723194, val:  62.08%, val_best:  76.25%, tr:  86.41%, tr_best:  97.45%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1008a43f827340e9878cc8e395b898c3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.006 MB of 0.006 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>iter_acc</td><td>▁▇▄▄▆▆▆▄▆█████▇███▆▇████▇▇█▇▇▆▇▇▇▇▆▆▅▆█▆</td></tr><tr><td>summary_val_acc</td><td>▁▂▄▅▅▅▄▆▇▆▇▇▆█▆▆▇▇▅▇▆▇▆▆▅▇▅▇▆▅▆▅▆▆▄▆▇▇▆▇</td></tr><tr><td>tr_acc</td><td>▁▃▄▅▆▆▆▇▇████▇████████████▇██▇▇█▇▇▇▇█▇▇▇</td></tr><tr><td>tr_epoch_loss</td><td>█▅▄▃▂▂▂▁▂▁▁▁▁▂▁▁▁▁▁▂▁▁▁▁▁▂▂▂▂▂▃▂▂▃▃▂▂▃▃▃</td></tr><tr><td>val_acc_best</td><td>▁▂▄▅▅▅▅▆▆▆██████████████████████████████</td></tr><tr><td>val_acc_now</td><td>▁▂▄▅▅▅▄▆▇▆▇▇▆█▆▆▇▇▅▇▆▇▆▆▅▇▅▇▆▅▆▅▆▆▄▆▇▇▆▇</td></tr><tr><td>val_loss</td><td>▂▁▂▁▂▃▄▃▃▃▄▃▄▃▅▄▅▆▅▅▆▅▆▆▆▆▆▅▆█▇█▇▆▇▆▇▆▇▆</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>99</td></tr><tr><td>iter_acc</td><td>1.0</td></tr><tr><td>tr_acc</td><td>0.86415</td></tr><tr><td>tr_epoch_loss</td><td>0.93796</td></tr><tr><td>val_acc_best</td><td>0.7625</td></tr><tr><td>val_acc_now</td><td>0.62083</td></tr><tr><td>val_loss</td><td>2.72319</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">olive-sweep-158</strong> at: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/0ov4viwv' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/0ov4viwv</a><br/> View project at: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>/data2/bh_wandb/wandb/run-20250430_033310-0ov4viwv/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require(\"core\")`! See https://wandb.me/wandb-core for more information."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: acr9j4lx with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBATCH: 16\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBN_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBPTT_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tDFA_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tIMAGE_SIZE: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tOTTT_input_trace_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tTIME: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tUDA_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \talpha_uda: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbias: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcfg: ['M', 'M', 200, 200]\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tchaching_on: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tconvTrue_fcFalse: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdata_path: /data2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tddp_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdenoise_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdvs_clipping: 5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdvs_duration: 100000\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepoch_num: 100\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \texclude_class: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \textra_train_dataset: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlast_lif: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_sg_width: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_decay: 0.5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_init: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_reset: 10000\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_threshold: 0.25\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmerge_polarities: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmy_seed: 42\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnet_print: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_workers: 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer_what: SGD\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tpin_memory: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tpre_trained: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tpre_trained_path: net_save/save_now_net_weights_{unique_name}.pth\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \trate_coding: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tscheduler_name: no\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsingle_step: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsurrogate: hard_sigmoid\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_conv_kernel_size: 3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_conv_padding: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_conv_stride: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_trace_const1: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_trace_const2: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \ttdBN_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \ttrace_on: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \twhich_data: DVS_GESTURE_TONIC\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.19.10 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.17.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/data2/bh_wandb/wandb/run-20250430_033908-acr9j4lx</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/acr9j4lx' target=\"_blank\">wise-sweep-160</a></strong> to <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/6pj3lh8j' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/6pj3lh8j</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/6pj3lh8j' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/6pj3lh8j</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/acr9j4lx' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/acr9j4lx</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'single_step' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'my_seed' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'TIME' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BATCH' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'IMAGE_SIZE' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'which_data' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'data_path' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'rate_coding' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_init' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_decay' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_threshold' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_reset' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_sg_width' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_conv_kernel_size' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_conv_stride' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_conv_padding' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_trace_const1' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_trace_const2' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'pre_trained' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'convTrue_fcFalse' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'cfg' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'net_print' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'pre_trained_path' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'learning_rate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'epoch_num' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'tdBN_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BN_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'surrogate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BPTT_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'optimizer_what' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'scheduler_name' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'ddp_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'dvs_clipping' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'dvs_duration' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'DFA_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'trace_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'OTTT_input_trace_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'exclude_class' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'merge_polarities' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'denoise_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'extra_train_dataset' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'num_workers' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'chaching_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'pin_memory' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'UDA_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'alpha_uda' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'bias' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'last_lif' was locked by 'sweep' (ignored update).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "param {'devices': '0', 'single_step': True, 'unique_name': 'main', 'my_seed': 42, 'TIME': 10, 'BATCH': 16, 'IMAGE_SIZE': 128, 'which_data': 'DVS_GESTURE_TONIC', 'data_path': '/data2', 'rate_coding': False, 'lif_layer_v_init': 0, 'lif_layer_v_decay': 0.5, 'lif_layer_v_threshold': 0.25, 'lif_layer_v_reset': 10000, 'lif_layer_sg_width': 1, 'synapse_conv_kernel_size': 3, 'synapse_conv_stride': 1, 'synapse_conv_padding': 1, 'synapse_trace_const1': 1, 'synapse_trace_const2': 0, 'pre_trained': False, 'convTrue_fcFalse': False, 'cfg': ['M', 'M', 200, 200], 'net_print': True, 'pre_trained_path': 'net_save/save_now_net_weights_{unique_name}.pth', 'learning_rate': 0.1, 'epoch_num': 100, 'tdBN_on': False, 'BN_on': False, 'surrogate': 'hard_sigmoid', 'BPTT_on': False, 'optimizer_what': 'SGD', 'scheduler_name': 'no', 'ddp_on': False, 'dvs_clipping': 5, 'dvs_duration': 100000, 'DFA_on': False, 'trace_on': True, 'OTTT_input_trace_on': False, 'exclude_class': True, 'merge_polarities': False, 'denoise_on': False, 'extra_train_dataset': 0, 'num_workers': 2, 'chaching_on': True, 'pin_memory': True, 'UDA_on': False, 'alpha_uda': 1, 'bias': True, 'last_lif': False, 'current epoch': 0} \n",
      "\n",
      "dataset_hash = ffa516e60c3efd5e0208f72b4c36cb84\n",
      "cache path exists\n",
      "\n",
      "device ==> cuda\n",
      "\n",
      "DataParallel(\n",
      "  (module): REBORN_MY_SNN_FC(\n",
      "    (layers): REBORN_MY_Sequential(\n",
      "      (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (2): DimChanger_for_FC()\n",
      "      (3): SYNAPSE_FC(in_features=2048, out_features=200, TIME=10, bias=True, sstep=True)\n",
      "      (4): LIF_layer(v_init=0, v_decay=0.5, v_threshold=0.25, v_reset=10000, sg_width=1, surrogate=hard_sigmoid, BPTT_on=False, trace_const1=1, trace_const2=0, TIME=10, sstep=True, trace_on=True)\n",
      "      (5): SYNAPSE_FC(in_features=200, out_features=200, TIME=10, bias=True, sstep=True)\n",
      "      (6): LIF_layer(v_init=0, v_decay=0.5, v_threshold=0.25, v_reset=10000, sg_width=1, surrogate=hard_sigmoid, BPTT_on=False, trace_const1=1, trace_const2=0, TIME=10, sstep=True, trace_on=True)\n",
      "      (7): SYNAPSE_FC(in_features=200, out_features=10, TIME=10, bias=True, sstep=True)\n",
      "    )\n",
      "  )\n",
      ")\n",
      "\n",
      "========================================================\n",
      "Trainable parameters: 452,010\n",
      "========================================================\n",
      "\n",
      "epoch-0   lr=['0.1000000'], tr/val_loss:  2.126043/  2.082354, val:  48.75%, val_best:  48.75%, tr:  34.42%, tr_best:  34.42%\n",
      "epoch-1   lr=['0.1000000'], tr/val_loss:  1.598706/  1.919894, val:  41.25%, val_best:  48.75%, tr:  52.50%, tr_best:  52.50%\n",
      "epoch-2   lr=['0.1000000'], tr/val_loss:  1.422973/  1.603793, val:  53.33%, val_best:  53.33%, tr:  58.73%, tr_best:  58.73%\n",
      "epoch-3   lr=['0.1000000'], tr/val_loss:  1.175454/  1.617666, val:  52.50%, val_best:  53.33%, tr:  64.66%, tr_best:  64.66%\n",
      "epoch-4   lr=['0.1000000'], tr/val_loss:  1.201714/  1.594590, val:  58.33%, val_best:  58.33%, tr:  61.49%, tr_best:  64.66%\n",
      "epoch-5   lr=['0.1000000'], tr/val_loss:  1.044931/  1.974956, val:  49.58%, val_best:  58.33%, tr:  70.48%, tr_best:  70.48%\n",
      "epoch-6   lr=['0.1000000'], tr/val_loss:  0.989301/  1.545983, val:  56.67%, val_best:  58.33%, tr:  72.93%, tr_best:  72.93%\n",
      "epoch-7   lr=['0.1000000'], tr/val_loss:  0.957479/  1.963686, val:  55.00%, val_best:  58.33%, tr:  72.42%, tr_best:  72.93%\n",
      "epoch-8   lr=['0.1000000'], tr/val_loss:  0.839141/  1.655954, val:  60.00%, val_best:  60.00%, tr:  75.89%, tr_best:  75.89%\n",
      "epoch-9   lr=['0.1000000'], tr/val_loss:  0.746580/  1.801878, val:  55.00%, val_best:  60.00%, tr:  79.06%, tr_best:  79.06%\n",
      "epoch-10  lr=['0.1000000'], tr/val_loss:  0.712778/  1.631804, val:  67.08%, val_best:  67.08%, tr:  81.10%, tr_best:  81.10%\n",
      "epoch-11  lr=['0.1000000'], tr/val_loss:  0.592199/  1.638661, val:  70.83%, val_best:  70.83%, tr:  85.80%, tr_best:  85.80%\n",
      "epoch-12  lr=['0.1000000'], tr/val_loss:  0.539828/  1.687742, val:  73.75%, val_best:  73.75%, tr:  86.31%, tr_best:  86.31%\n",
      "epoch-13  lr=['0.1000000'], tr/val_loss:  0.470555/  1.874100, val:  70.83%, val_best:  73.75%, tr:  89.89%, tr_best:  89.89%\n",
      "epoch-14  lr=['0.1000000'], tr/val_loss:  0.375814/  2.341464, val:  65.42%, val_best:  73.75%, tr:  92.85%, tr_best:  92.85%\n",
      "epoch-15  lr=['0.1000000'], tr/val_loss:  0.304914/  2.346859, val:  68.75%, val_best:  73.75%, tr:  94.18%, tr_best:  94.18%\n",
      "epoch-16  lr=['0.1000000'], tr/val_loss:  0.267936/  2.262392, val:  74.17%, val_best:  74.17%, tr:  94.59%, tr_best:  94.59%\n",
      "epoch-17  lr=['0.1000000'], tr/val_loss:  0.194617/  2.222544, val:  71.25%, val_best:  74.17%, tr:  98.67%, tr_best:  98.67%\n",
      "epoch-18  lr=['0.1000000'], tr/val_loss:  0.169814/  2.402859, val:  70.42%, val_best:  74.17%, tr:  98.47%, tr_best:  98.67%\n",
      "epoch-19  lr=['0.1000000'], tr/val_loss:  0.247557/  2.073977, val:  78.33%, val_best:  78.33%, tr:  97.55%, tr_best:  98.67%\n",
      "epoch-20  lr=['0.1000000'], tr/val_loss:  0.153365/  2.319888, val:  73.33%, val_best:  78.33%, tr:  99.08%, tr_best:  99.08%\n",
      "epoch-21  lr=['0.1000000'], tr/val_loss:  0.122879/  2.331956, val:  77.92%, val_best:  78.33%, tr:  99.28%, tr_best:  99.28%\n",
      "epoch-22  lr=['0.1000000'], tr/val_loss:  0.080918/  2.588954, val:  74.17%, val_best:  78.33%, tr:  99.80%, tr_best:  99.80%\n",
      "epoch-23  lr=['0.1000000'], tr/val_loss:  0.066715/  2.452027, val:  80.42%, val_best:  80.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-24  lr=['0.1000000'], tr/val_loss:  0.035448/  2.631739, val:  77.92%, val_best:  80.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-25  lr=['0.1000000'], tr/val_loss:  0.029558/  2.596743, val:  79.17%, val_best:  80.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-26  lr=['0.1000000'], tr/val_loss:  0.027496/  2.915972, val:  75.00%, val_best:  80.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-27  lr=['0.1000000'], tr/val_loss:  0.015742/  2.636636, val:  79.17%, val_best:  80.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-28  lr=['0.1000000'], tr/val_loss:  0.018870/  2.771844, val:  76.67%, val_best:  80.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-29  lr=['0.1000000'], tr/val_loss:  0.015046/  2.927844, val:  77.08%, val_best:  80.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-30  lr=['0.1000000'], tr/val_loss:  0.014009/  2.857769, val:  78.33%, val_best:  80.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-31  lr=['0.1000000'], tr/val_loss:  0.010757/  2.879064, val:  79.17%, val_best:  80.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-32  lr=['0.1000000'], tr/val_loss:  0.006489/  2.984522, val:  77.08%, val_best:  80.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-33  lr=['0.1000000'], tr/val_loss:  0.002084/  3.075310, val:  77.50%, val_best:  80.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-34  lr=['0.1000000'], tr/val_loss:  0.002335/  3.104179, val:  76.67%, val_best:  80.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-35  lr=['0.1000000'], tr/val_loss:  0.001076/  3.182148, val:  76.67%, val_best:  80.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-36  lr=['0.1000000'], tr/val_loss:  0.000981/  3.185166, val:  77.50%, val_best:  80.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-37  lr=['0.1000000'], tr/val_loss:  0.000596/  3.270048, val:  76.25%, val_best:  80.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-38  lr=['0.1000000'], tr/val_loss:  0.004531/  3.281454, val:  76.25%, val_best:  80.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-39  lr=['0.1000000'], tr/val_loss:  0.053978/  3.035650, val:  75.42%, val_best:  80.42%, tr:  99.80%, tr_best: 100.00%\n",
      "epoch-40  lr=['0.1000000'], tr/val_loss:  0.016061/  3.246485, val:  76.67%, val_best:  80.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-41  lr=['0.1000000'], tr/val_loss:  0.032250/  3.126608, val:  75.00%, val_best:  80.42%, tr:  99.90%, tr_best: 100.00%\n",
      "epoch-42  lr=['0.1000000'], tr/val_loss:  0.038127/  3.193473, val:  74.58%, val_best:  80.42%, tr:  99.90%, tr_best: 100.00%\n",
      "epoch-43  lr=['0.1000000'], tr/val_loss:  0.049330/  2.981345, val:  75.00%, val_best:  80.42%, tr:  99.80%, tr_best: 100.00%\n",
      "epoch-44  lr=['0.1000000'], tr/val_loss:  0.021666/  2.984533, val:  75.83%, val_best:  80.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-45  lr=['0.1000000'], tr/val_loss:  0.055915/  2.954821, val:  70.00%, val_best:  80.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-46  lr=['0.1000000'], tr/val_loss:  0.025062/  2.919813, val:  77.92%, val_best:  80.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-47  lr=['0.1000000'], tr/val_loss:  0.029135/  3.048020, val:  72.50%, val_best:  80.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-48  lr=['0.1000000'], tr/val_loss:  0.114863/  2.959619, val:  75.83%, val_best:  80.42%, tr:  99.18%, tr_best: 100.00%\n",
      "epoch-49  lr=['0.1000000'], tr/val_loss:  0.034912/  2.896641, val:  75.00%, val_best:  80.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-50  lr=['0.1000000'], tr/val_loss:  0.009358/  3.130724, val:  78.75%, val_best:  80.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-51  lr=['0.1000000'], tr/val_loss:  0.007699/  2.966642, val:  77.08%, val_best:  80.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-52  lr=['0.1000000'], tr/val_loss:  0.003063/  2.916069, val:  78.75%, val_best:  80.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-53  lr=['0.1000000'], tr/val_loss:  0.004904/  3.059374, val:  77.50%, val_best:  80.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-54  lr=['0.1000000'], tr/val_loss:  0.005771/  3.037268, val:  80.00%, val_best:  80.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-55  lr=['0.1000000'], tr/val_loss:  0.009770/  3.189093, val:  76.25%, val_best:  80.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-56  lr=['0.1000000'], tr/val_loss:  0.012676/  3.106962, val:  77.50%, val_best:  80.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-57  lr=['0.1000000'], tr/val_loss:  0.004675/  3.153204, val:  76.25%, val_best:  80.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-58  lr=['0.1000000'], tr/val_loss:  0.003466/  3.015636, val:  79.58%, val_best:  80.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-59  lr=['0.1000000'], tr/val_loss:  0.001280/  3.010761, val:  80.42%, val_best:  80.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-60  lr=['0.1000000'], tr/val_loss:  0.000593/  3.020687, val:  79.58%, val_best:  80.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-61  lr=['0.1000000'], tr/val_loss:  0.000794/  3.025630, val:  80.00%, val_best:  80.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-62  lr=['0.1000000'], tr/val_loss:  0.000347/  3.011923, val:  79.17%, val_best:  80.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-63  lr=['0.1000000'], tr/val_loss:  0.000272/  3.040909, val:  77.92%, val_best:  80.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-64  lr=['0.1000000'], tr/val_loss:  0.000173/  3.071295, val:  78.75%, val_best:  80.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-65  lr=['0.1000000'], tr/val_loss:  0.000157/  3.080659, val:  79.17%, val_best:  80.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-66  lr=['0.1000000'], tr/val_loss:  0.000145/  3.080519, val:  79.17%, val_best:  80.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-67  lr=['0.1000000'], tr/val_loss:  0.000163/  3.090560, val:  78.75%, val_best:  80.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-68  lr=['0.1000000'], tr/val_loss:  0.000122/  3.091031, val:  78.33%, val_best:  80.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-69  lr=['0.1000000'], tr/val_loss:  0.000109/  3.085869, val:  78.33%, val_best:  80.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-70  lr=['0.1000000'], tr/val_loss:  0.000109/  3.090977, val:  78.33%, val_best:  80.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-71  lr=['0.1000000'], tr/val_loss:  0.000103/  3.097592, val:  78.33%, val_best:  80.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-72  lr=['0.1000000'], tr/val_loss:  0.000100/  3.100743, val:  78.33%, val_best:  80.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-73  lr=['0.1000000'], tr/val_loss:  0.000105/  3.098837, val:  78.33%, val_best:  80.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-74  lr=['0.1000000'], tr/val_loss:  0.000098/  3.098229, val:  78.75%, val_best:  80.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-75  lr=['0.1000000'], tr/val_loss:  0.000093/  3.113915, val:  78.33%, val_best:  80.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-76  lr=['0.1000000'], tr/val_loss:  0.000090/  3.098963, val:  78.75%, val_best:  80.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-77  lr=['0.1000000'], tr/val_loss:  0.000089/  3.091798, val:  79.17%, val_best:  80.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-78  lr=['0.1000000'], tr/val_loss:  0.000085/  3.094611, val:  79.17%, val_best:  80.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-79  lr=['0.1000000'], tr/val_loss:  0.000082/  3.098660, val:  79.17%, val_best:  80.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-80  lr=['0.1000000'], tr/val_loss:  0.000078/  3.095508, val:  79.17%, val_best:  80.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-81  lr=['0.1000000'], tr/val_loss:  0.000076/  3.091316, val:  79.17%, val_best:  80.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-82  lr=['0.1000000'], tr/val_loss:  0.000074/  3.092582, val:  79.58%, val_best:  80.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-83  lr=['0.1000000'], tr/val_loss:  0.000075/  3.105159, val:  79.58%, val_best:  80.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-84  lr=['0.1000000'], tr/val_loss:  0.000073/  3.098422, val:  79.58%, val_best:  80.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-85  lr=['0.1000000'], tr/val_loss:  0.000069/  3.109042, val:  79.58%, val_best:  80.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-86  lr=['0.1000000'], tr/val_loss:  0.000066/  3.113222, val:  79.17%, val_best:  80.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-87  lr=['0.1000000'], tr/val_loss:  0.000077/  3.111279, val:  79.17%, val_best:  80.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-88  lr=['0.1000000'], tr/val_loss:  0.000071/  3.112920, val:  79.17%, val_best:  80.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-89  lr=['0.1000000'], tr/val_loss:  0.000067/  3.122600, val:  79.17%, val_best:  80.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-90  lr=['0.1000000'], tr/val_loss:  0.000067/  3.120305, val:  79.17%, val_best:  80.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-91  lr=['0.1000000'], tr/val_loss:  0.000067/  3.118481, val:  79.17%, val_best:  80.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-92  lr=['0.1000000'], tr/val_loss:  0.000062/  3.129918, val:  79.17%, val_best:  80.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-93  lr=['0.1000000'], tr/val_loss:  0.000061/  3.138099, val:  79.17%, val_best:  80.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-94  lr=['0.1000000'], tr/val_loss:  0.000065/  3.136789, val:  79.17%, val_best:  80.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-95  lr=['0.1000000'], tr/val_loss:  0.000056/  3.133566, val:  79.17%, val_best:  80.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-96  lr=['0.1000000'], tr/val_loss:  0.000054/  3.139766, val:  79.58%, val_best:  80.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-97  lr=['0.1000000'], tr/val_loss:  0.000057/  3.135858, val:  79.58%, val_best:  80.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-98  lr=['0.1000000'], tr/val_loss:  0.000054/  3.142561, val:  79.58%, val_best:  80.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-99  lr=['0.1000000'], tr/val_loss:  0.000053/  3.142140, val:  79.58%, val_best:  80.42%, tr: 100.00%, tr_best: 100.00%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "06c895691203440f89f6f364fa999197",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.006 MB of 0.006 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>iter_acc</td><td>▁▇▅▅▅▆█▇████████████████████████████████</td></tr><tr><td>summary_val_acc</td><td>▁▂▃▂▂▇▅▆█▇▇▇▇▇▇▇▇▇▇▆▇██▇████████████████</td></tr><tr><td>tr_acc</td><td>▁▄▄▅▆▇▇█████████████████████████████████</td></tr><tr><td>tr_epoch_loss</td><td>█▆▅▄▃▃▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_acc_best</td><td>▁▂▃▃▃▇▇▇████████████████████████████████</td></tr><tr><td>val_acc_now</td><td>▁▂▃▂▂▇▅▆█▇▇▇▇▇▇▇▇▇▇▆▇██▇████████████████</td></tr><tr><td>val_loss</td><td>▃▁▁▃▂▁▄▄▃▄▅▇▇▇██▇█▇▇▆▇▇█▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>99</td></tr><tr><td>iter_acc</td><td>1.0</td></tr><tr><td>tr_acc</td><td>1.0</td></tr><tr><td>tr_epoch_loss</td><td>5e-05</td></tr><tr><td>val_acc_best</td><td>0.80417</td></tr><tr><td>val_acc_now</td><td>0.79583</td></tr><tr><td>val_loss</td><td>3.14214</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">wise-sweep-160</strong> at: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/acr9j4lx' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/acr9j4lx</a><br/> View project at: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>/data2/bh_wandb/wandb/run-20250430_033908-acr9j4lx/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require(\"core\")`! See https://wandb.me/wandb-core for more information."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 64fiovlc with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBATCH: 16\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBN_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBPTT_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tDFA_on: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tIMAGE_SIZE: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tOTTT_input_trace_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tTIME: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tUDA_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \talpha_uda: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbias: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcfg: ['M', 'M', 200, 200]\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tchaching_on: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tconvTrue_fcFalse: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdata_path: /data2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tddp_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdenoise_on: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdvs_clipping: 5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdvs_duration: 100000\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepoch_num: 100\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \texclude_class: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \textra_train_dataset: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlast_lif: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.0001\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_sg_width: 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_decay: 0.5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_init: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_reset: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_threshold: 0.75\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmerge_polarities: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmy_seed: 42\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnet_print: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_workers: 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer_what: SGD\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tpin_memory: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tpre_trained: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tpre_trained_path: net_save/save_now_net_weights_{unique_name}.pth\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \trate_coding: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tscheduler_name: no\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsingle_step: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsurrogate: hard_sigmoid\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_conv_kernel_size: 3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_conv_padding: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_conv_stride: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_trace_const1: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_trace_const2: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \ttdBN_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \ttrace_on: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \twhich_data: DVS_GESTURE_TONIC\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.19.10 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.17.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/data2/bh_wandb/wandb/run-20250430_034509-64fiovlc</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/64fiovlc' target=\"_blank\">solar-sweep-162</a></strong> to <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/6pj3lh8j' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/6pj3lh8j</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/6pj3lh8j' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/6pj3lh8j</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/64fiovlc' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/64fiovlc</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'single_step' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'my_seed' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'TIME' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BATCH' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'IMAGE_SIZE' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'which_data' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'data_path' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'rate_coding' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_init' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_decay' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_threshold' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_reset' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_sg_width' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_conv_kernel_size' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_conv_stride' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_conv_padding' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_trace_const1' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_trace_const2' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'pre_trained' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'convTrue_fcFalse' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'cfg' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'net_print' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'pre_trained_path' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'learning_rate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'epoch_num' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'tdBN_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BN_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'surrogate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BPTT_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'optimizer_what' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'scheduler_name' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'ddp_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'dvs_clipping' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'dvs_duration' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'DFA_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'trace_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'OTTT_input_trace_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'exclude_class' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'merge_polarities' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'denoise_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'extra_train_dataset' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'num_workers' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'chaching_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'pin_memory' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'UDA_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'alpha_uda' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'bias' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'last_lif' was locked by 'sweep' (ignored update).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "param {'devices': '0', 'single_step': True, 'unique_name': 'main', 'my_seed': 42, 'TIME': 10, 'BATCH': 16, 'IMAGE_SIZE': 128, 'which_data': 'DVS_GESTURE_TONIC', 'data_path': '/data2', 'rate_coding': False, 'lif_layer_v_init': 0, 'lif_layer_v_decay': 0.5, 'lif_layer_v_threshold': 0.75, 'lif_layer_v_reset': 0, 'lif_layer_sg_width': 2, 'synapse_conv_kernel_size': 3, 'synapse_conv_stride': 1, 'synapse_conv_padding': 1, 'synapse_trace_const1': 1, 'synapse_trace_const2': 0, 'pre_trained': False, 'convTrue_fcFalse': False, 'cfg': ['M', 'M', 200, 200], 'net_print': True, 'pre_trained_path': 'net_save/save_now_net_weights_{unique_name}.pth', 'learning_rate': 0.0001, 'epoch_num': 100, 'tdBN_on': False, 'BN_on': False, 'surrogate': 'hard_sigmoid', 'BPTT_on': False, 'optimizer_what': 'SGD', 'scheduler_name': 'no', 'ddp_on': False, 'dvs_clipping': 5, 'dvs_duration': 100000, 'DFA_on': True, 'trace_on': True, 'OTTT_input_trace_on': False, 'exclude_class': True, 'merge_polarities': False, 'denoise_on': True, 'extra_train_dataset': 0, 'num_workers': 2, 'chaching_on': True, 'pin_memory': True, 'UDA_on': False, 'alpha_uda': 1, 'bias': True, 'last_lif': False, 'current epoch': 0} \n",
      "\n",
      "dataset_hash = 63cc597115630ec173f3099200061e53\n",
      "cache path exists\n",
      "\n",
      "device ==> cuda\n",
      "\n",
      "DataParallel(\n",
      "  (module): REBORN_MY_SNN_FC(\n",
      "    (layers): REBORN_MY_Sequential(\n",
      "      (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (2): DimChanger_for_FC()\n",
      "      (3): SYNAPSE_FC(in_features=2048, out_features=200, TIME=10, bias=True, sstep=True)\n",
      "      (4): LIF_layer(v_init=0, v_decay=0.5, v_threshold=0.75, v_reset=0, sg_width=2, surrogate=hard_sigmoid, BPTT_on=False, trace_const1=1, trace_const2=0, TIME=10, sstep=True, trace_on=True)\n",
      "      (5): Feedback_Receiver()\n",
      "      (6): SYNAPSE_FC(in_features=200, out_features=200, TIME=10, bias=True, sstep=True)\n",
      "      (7): LIF_layer(v_init=0, v_decay=0.5, v_threshold=0.75, v_reset=0, sg_width=2, surrogate=hard_sigmoid, BPTT_on=False, trace_const1=1, trace_const2=0, TIME=10, sstep=True, trace_on=True)\n",
      "      (8): Feedback_Receiver()\n",
      "      (9): SYNAPSE_FC(in_features=200, out_features=10, TIME=10, bias=True, sstep=True)\n",
      "      (DFA_top): Top_Gradient()\n",
      "    )\n",
      "  )\n",
      ")\n",
      "\n",
      "========================================================\n",
      "Trainable parameters: 452,010\n",
      "========================================================\n",
      "\n",
      "epoch-0   lr=['0.0001000'], tr/val_loss:  2.303353/  2.303047, val:  10.00%, val_best:  10.00%, tr:  10.01%, tr_best:  10.01%\n",
      "[module.layers.5] weight_fb parameter count: 2,000\n",
      "[module.layers.8] weight_fb parameter count: 2,000\n",
      "epoch-1   lr=['0.0001000'], tr/val_loss:  2.303309/  2.302968, val:  10.00%, val_best:  10.00%, tr:  10.01%, tr_best:  10.01%\n",
      "epoch-2   lr=['0.0001000'], tr/val_loss:  2.303253/  2.302913, val:  10.00%, val_best:  10.00%, tr:  10.01%, tr_best:  10.01%\n",
      "epoch-3   lr=['0.0001000'], tr/val_loss:  2.303180/  2.302890, val:  10.00%, val_best:  10.00%, tr:  10.01%, tr_best:  10.01%\n",
      "epoch-4   lr=['0.0001000'], tr/val_loss:  2.303389/  2.302830, val:  10.00%, val_best:  10.00%, tr:  10.01%, tr_best:  10.01%\n",
      "epoch-5   lr=['0.0001000'], tr/val_loss:  2.302993/  2.302703, val:  10.42%, val_best:  10.42%, tr:  10.01%, tr_best:  10.01%\n",
      "epoch-6   lr=['0.0001000'], tr/val_loss:  2.302805/  2.302524, val:  10.83%, val_best:  10.83%, tr:  11.13%, tr_best:  11.13%\n",
      "epoch-7   lr=['0.0001000'], tr/val_loss:  2.302591/  2.302129, val:  10.83%, val_best:  10.83%, tr:  12.26%, tr_best:  12.26%\n",
      "epoch-8   lr=['0.0001000'], tr/val_loss:  2.301461/  2.301577, val:  10.00%, val_best:  10.83%, tr:  12.77%, tr_best:  12.77%\n",
      "epoch-9   lr=['0.0001000'], tr/val_loss:  2.299703/  2.299511, val:  10.00%, val_best:  10.83%, tr:  12.77%, tr_best:  12.77%\n",
      "epoch-10  lr=['0.0001000'], tr/val_loss:  2.297262/  2.296870, val:  11.25%, val_best:  11.25%, tr:  13.38%, tr_best:  13.38%\n",
      "epoch-11  lr=['0.0001000'], tr/val_loss:  2.291964/  2.291095, val:  12.92%, val_best:  12.92%, tr:  13.48%, tr_best:  13.48%\n",
      "epoch-12  lr=['0.0001000'], tr/val_loss:  2.282573/  2.281850, val:  13.75%, val_best:  13.75%, tr:  13.18%, tr_best:  13.48%\n",
      "epoch-13  lr=['0.0001000'], tr/val_loss:  2.267006/  2.266136, val:  15.42%, val_best:  15.42%, tr:  15.02%, tr_best:  15.02%\n",
      "epoch-14  lr=['0.0001000'], tr/val_loss:  2.243129/  2.241822, val:  14.58%, val_best:  15.42%, tr:  16.45%, tr_best:  16.45%\n",
      "epoch-15  lr=['0.0001000'], tr/val_loss:  2.206452/  2.208893, val:  19.58%, val_best:  19.58%, tr:  21.65%, tr_best:  21.65%\n",
      "epoch-16  lr=['0.0001000'], tr/val_loss:  2.163085/  2.169657, val:  26.25%, val_best:  26.25%, tr:  26.15%, tr_best:  26.15%\n",
      "epoch-17  lr=['0.0001000'], tr/val_loss:  2.111892/  2.123797, val:  31.67%, val_best:  31.67%, tr:  32.58%, tr_best:  32.58%\n",
      "epoch-18  lr=['0.0001000'], tr/val_loss:  2.056051/  2.078269, val:  32.08%, val_best:  32.08%, tr:  36.87%, tr_best:  36.87%\n",
      "epoch-19  lr=['0.0001000'], tr/val_loss:  1.995559/  2.032966, val:  40.00%, val_best:  40.00%, tr:  39.84%, tr_best:  39.84%\n",
      "epoch-20  lr=['0.0001000'], tr/val_loss:  1.944320/  1.987256, val:  40.00%, val_best:  40.00%, tr:  41.68%, tr_best:  41.68%\n",
      "epoch-21  lr=['0.0001000'], tr/val_loss:  1.887899/  1.941868, val:  44.58%, val_best:  44.58%, tr:  44.94%, tr_best:  44.94%\n",
      "epoch-22  lr=['0.0001000'], tr/val_loss:  1.839819/  1.905120, val:  45.83%, val_best:  45.83%, tr:  49.34%, tr_best:  49.34%\n",
      "epoch-23  lr=['0.0001000'], tr/val_loss:  1.792314/  1.869326, val:  47.92%, val_best:  47.92%, tr:  50.97%, tr_best:  50.97%\n",
      "epoch-24  lr=['0.0001000'], tr/val_loss:  1.750198/  1.838598, val:  47.50%, val_best:  47.92%, tr:  50.87%, tr_best:  50.97%\n",
      "epoch-25  lr=['0.0001000'], tr/val_loss:  1.719809/  1.811382, val:  47.50%, val_best:  47.92%, tr:  52.60%, tr_best:  52.60%\n",
      "epoch-26  lr=['0.0001000'], tr/val_loss:  1.684090/  1.789289, val:  46.25%, val_best:  47.92%, tr:  52.20%, tr_best:  52.60%\n",
      "epoch-27  lr=['0.0001000'], tr/val_loss:  1.652113/  1.766241, val:  49.17%, val_best:  49.17%, tr:  53.93%, tr_best:  53.93%\n",
      "epoch-28  lr=['0.0001000'], tr/val_loss:  1.627907/  1.746990, val:  48.75%, val_best:  49.17%, tr:  53.83%, tr_best:  53.93%\n",
      "epoch-29  lr=['0.0001000'], tr/val_loss:  1.599553/  1.728940, val:  49.58%, val_best:  49.58%, tr:  55.77%, tr_best:  55.77%\n",
      "epoch-30  lr=['0.0001000'], tr/val_loss:  1.581472/  1.714347, val:  46.67%, val_best:  49.58%, tr:  57.92%, tr_best:  57.92%\n",
      "epoch-31  lr=['0.0001000'], tr/val_loss:  1.556795/  1.699280, val:  49.58%, val_best:  49.58%, tr:  58.63%, tr_best:  58.63%\n",
      "epoch-32  lr=['0.0001000'], tr/val_loss:  1.531407/  1.679618, val:  46.67%, val_best:  49.58%, tr:  57.10%, tr_best:  58.63%\n",
      "epoch-33  lr=['0.0001000'], tr/val_loss:  1.519509/  1.664070, val:  50.42%, val_best:  50.42%, tr:  59.96%, tr_best:  59.96%\n",
      "epoch-34  lr=['0.0001000'], tr/val_loss:  1.500866/  1.652618, val:  49.58%, val_best:  50.42%, tr:  59.65%, tr_best:  59.96%\n",
      "epoch-35  lr=['0.0001000'], tr/val_loss:  1.480252/  1.639121, val:  49.58%, val_best:  50.42%, tr:  60.57%, tr_best:  60.57%\n",
      "epoch-36  lr=['0.0001000'], tr/val_loss:  1.466435/  1.628228, val:  50.42%, val_best:  50.42%, tr:  59.55%, tr_best:  60.57%\n",
      "epoch-37  lr=['0.0001000'], tr/val_loss:  1.452570/  1.622706, val:  52.08%, val_best:  52.08%, tr:  60.37%, tr_best:  60.57%\n",
      "epoch-38  lr=['0.0001000'], tr/val_loss:  1.439955/  1.611384, val:  51.25%, val_best:  52.08%, tr:  59.86%, tr_best:  60.57%\n",
      "epoch-39  lr=['0.0001000'], tr/val_loss:  1.427155/  1.601949, val:  55.42%, val_best:  55.42%, tr:  61.49%, tr_best:  61.49%\n",
      "epoch-40  lr=['0.0001000'], tr/val_loss:  1.410552/  1.596257, val:  54.58%, val_best:  55.42%, tr:  61.39%, tr_best:  61.49%\n",
      "epoch-41  lr=['0.0001000'], tr/val_loss:  1.404209/  1.584026, val:  57.50%, val_best:  57.50%, tr:  61.59%, tr_best:  61.59%\n",
      "epoch-42  lr=['0.0001000'], tr/val_loss:  1.389191/  1.578289, val:  55.00%, val_best:  57.50%, tr:  62.51%, tr_best:  62.51%\n",
      "epoch-43  lr=['0.0001000'], tr/val_loss:  1.380052/  1.569937, val:  54.17%, val_best:  57.50%, tr:  61.59%, tr_best:  62.51%\n",
      "epoch-44  lr=['0.0001000'], tr/val_loss:  1.372569/  1.565829, val:  54.17%, val_best:  57.50%, tr:  61.08%, tr_best:  62.51%\n",
      "epoch-45  lr=['0.0001000'], tr/val_loss:  1.362064/  1.562362, val:  55.42%, val_best:  57.50%, tr:  62.10%, tr_best:  62.51%\n",
      "epoch-46  lr=['0.0001000'], tr/val_loss:  1.349360/  1.553991, val:  57.50%, val_best:  57.50%, tr:  60.78%, tr_best:  62.51%\n",
      "epoch-47  lr=['0.0001000'], tr/val_loss:  1.342869/  1.549401, val:  55.42%, val_best:  57.50%, tr:  61.59%, tr_best:  62.51%\n",
      "epoch-48  lr=['0.0001000'], tr/val_loss:  1.336905/  1.541840, val:  55.83%, val_best:  57.50%, tr:  62.10%, tr_best:  62.51%\n",
      "epoch-49  lr=['0.0001000'], tr/val_loss:  1.328895/  1.537669, val:  56.25%, val_best:  57.50%, tr:  62.41%, tr_best:  62.51%\n",
      "epoch-50  lr=['0.0001000'], tr/val_loss:  1.322074/  1.533639, val:  56.67%, val_best:  57.50%, tr:  63.13%, tr_best:  63.13%\n",
      "epoch-51  lr=['0.0001000'], tr/val_loss:  1.309631/  1.525784, val:  58.33%, val_best:  58.33%, tr:  62.31%, tr_best:  63.13%\n",
      "epoch-52  lr=['0.0001000'], tr/val_loss:  1.299406/  1.520064, val:  54.58%, val_best:  58.33%, tr:  63.74%, tr_best:  63.74%\n",
      "epoch-53  lr=['0.0001000'], tr/val_loss:  1.293515/  1.520164, val:  55.42%, val_best:  58.33%, tr:  62.21%, tr_best:  63.74%\n",
      "epoch-54  lr=['0.0001000'], tr/val_loss:  1.291925/  1.514794, val:  55.42%, val_best:  58.33%, tr:  63.94%, tr_best:  63.94%\n",
      "epoch-55  lr=['0.0001000'], tr/val_loss:  1.282761/  1.513163, val:  56.25%, val_best:  58.33%, tr:  64.45%, tr_best:  64.45%\n",
      "epoch-56  lr=['0.0001000'], tr/val_loss:  1.268848/  1.510478, val:  57.50%, val_best:  58.33%, tr:  65.17%, tr_best:  65.17%\n",
      "epoch-57  lr=['0.0001000'], tr/val_loss:  1.270738/  1.503516, val:  57.08%, val_best:  58.33%, tr:  64.56%, tr_best:  65.17%\n",
      "epoch-58  lr=['0.0001000'], tr/val_loss:  1.257394/  1.499417, val:  57.92%, val_best:  58.33%, tr:  63.43%, tr_best:  65.17%\n",
      "epoch-59  lr=['0.0001000'], tr/val_loss:  1.260345/  1.496477, val:  57.50%, val_best:  58.33%, tr:  64.56%, tr_best:  65.17%\n",
      "epoch-60  lr=['0.0001000'], tr/val_loss:  1.252440/  1.490767, val:  57.50%, val_best:  58.33%, tr:  62.51%, tr_best:  65.17%\n",
      "epoch-61  lr=['0.0001000'], tr/val_loss:  1.256499/  1.484204, val:  57.50%, val_best:  58.33%, tr:  66.09%, tr_best:  66.09%\n",
      "epoch-62  lr=['0.0001000'], tr/val_loss:  1.246070/  1.484203, val:  57.50%, val_best:  58.33%, tr:  64.86%, tr_best:  66.09%\n",
      "epoch-63  lr=['0.0001000'], tr/val_loss:  1.235927/  1.482696, val:  57.92%, val_best:  58.33%, tr:  66.39%, tr_best:  66.39%\n",
      "epoch-64  lr=['0.0001000'], tr/val_loss:  1.225315/  1.476441, val:  58.33%, val_best:  58.33%, tr:  65.99%, tr_best:  66.39%\n",
      "epoch-65  lr=['0.0001000'], tr/val_loss:  1.226519/  1.475779, val:  56.67%, val_best:  58.33%, tr:  64.96%, tr_best:  66.39%\n",
      "epoch-66  lr=['0.0001000'], tr/val_loss:  1.222018/  1.473240, val:  56.25%, val_best:  58.33%, tr:  67.11%, tr_best:  67.11%\n",
      "epoch-67  lr=['0.0001000'], tr/val_loss:  1.219631/  1.469066, val:  58.75%, val_best:  58.75%, tr:  67.11%, tr_best:  67.11%\n",
      "epoch-68  lr=['0.0001000'], tr/val_loss:  1.208176/  1.466733, val:  57.92%, val_best:  58.75%, tr:  65.88%, tr_best:  67.11%\n",
      "epoch-69  lr=['0.0001000'], tr/val_loss:  1.208738/  1.461524, val:  57.92%, val_best:  58.75%, tr:  67.52%, tr_best:  67.52%\n",
      "epoch-70  lr=['0.0001000'], tr/val_loss:  1.198928/  1.456967, val:  57.92%, val_best:  58.75%, tr:  66.91%, tr_best:  67.52%\n",
      "epoch-71  lr=['0.0001000'], tr/val_loss:  1.196450/  1.456823, val:  59.17%, val_best:  59.17%, tr:  66.39%, tr_best:  67.52%\n",
      "epoch-72  lr=['0.0001000'], tr/val_loss:  1.188672/  1.454410, val:  59.58%, val_best:  59.58%, tr:  65.99%, tr_best:  67.52%\n",
      "epoch-73  lr=['0.0001000'], tr/val_loss:  1.184988/  1.448077, val:  57.08%, val_best:  59.58%, tr:  66.70%, tr_best:  67.52%\n",
      "epoch-74  lr=['0.0001000'], tr/val_loss:  1.178611/  1.449520, val:  57.50%, val_best:  59.58%, tr:  65.88%, tr_best:  67.52%\n",
      "epoch-75  lr=['0.0001000'], tr/val_loss:  1.177602/  1.446804, val:  58.33%, val_best:  59.58%, tr:  66.39%, tr_best:  67.52%\n",
      "epoch-76  lr=['0.0001000'], tr/val_loss:  1.171540/  1.445501, val:  58.75%, val_best:  59.58%, tr:  67.82%, tr_best:  67.82%\n",
      "epoch-77  lr=['0.0001000'], tr/val_loss:  1.172964/  1.442059, val:  57.08%, val_best:  59.58%, tr:  67.11%, tr_best:  67.82%\n",
      "epoch-78  lr=['0.0001000'], tr/val_loss:  1.168880/  1.443107, val:  56.67%, val_best:  59.58%, tr:  67.82%, tr_best:  67.82%\n",
      "epoch-79  lr=['0.0001000'], tr/val_loss:  1.168491/  1.437127, val:  58.33%, val_best:  59.58%, tr:  67.42%, tr_best:  67.82%\n",
      "epoch-80  lr=['0.0001000'], tr/val_loss:  1.155792/  1.434867, val:  62.08%, val_best:  62.08%, tr:  68.03%, tr_best:  68.03%\n",
      "epoch-81  lr=['0.0001000'], tr/val_loss:  1.157924/  1.432965, val:  59.58%, val_best:  62.08%, tr:  68.34%, tr_best:  68.34%\n",
      "epoch-82  lr=['0.0001000'], tr/val_loss:  1.152256/  1.431112, val:  58.33%, val_best:  62.08%, tr:  68.23%, tr_best:  68.34%\n",
      "epoch-83  lr=['0.0001000'], tr/val_loss:  1.151894/  1.427427, val:  61.25%, val_best:  62.08%, tr:  69.77%, tr_best:  69.77%\n",
      "epoch-84  lr=['0.0001000'], tr/val_loss:  1.150665/  1.424217, val:  56.67%, val_best:  62.08%, tr:  69.25%, tr_best:  69.77%\n",
      "epoch-85  lr=['0.0001000'], tr/val_loss:  1.147616/  1.421748, val:  57.92%, val_best:  62.08%, tr:  69.56%, tr_best:  69.77%\n",
      "epoch-86  lr=['0.0001000'], tr/val_loss:  1.136927/  1.419994, val:  58.33%, val_best:  62.08%, tr:  68.64%, tr_best:  69.77%\n",
      "epoch-87  lr=['0.0001000'], tr/val_loss:  1.134355/  1.413679, val:  61.25%, val_best:  62.08%, tr:  71.30%, tr_best:  71.30%\n",
      "epoch-88  lr=['0.0001000'], tr/val_loss:  1.129983/  1.415902, val:  58.33%, val_best:  62.08%, tr:  69.25%, tr_best:  71.30%\n",
      "epoch-89  lr=['0.0001000'], tr/val_loss:  1.125202/  1.410630, val:  57.08%, val_best:  62.08%, tr:  68.23%, tr_best:  71.30%\n",
      "epoch-90  lr=['0.0001000'], tr/val_loss:  1.125831/  1.414346, val:  57.50%, val_best:  62.08%, tr:  69.77%, tr_best:  71.30%\n",
      "epoch-91  lr=['0.0001000'], tr/val_loss:  1.111857/  1.413816, val:  61.25%, val_best:  62.08%, tr:  70.48%, tr_best:  71.30%\n",
      "epoch-92  lr=['0.0001000'], tr/val_loss:  1.117902/  1.408874, val:  61.25%, val_best:  62.08%, tr:  68.34%, tr_best:  71.30%\n",
      "epoch-93  lr=['0.0001000'], tr/val_loss:  1.119320/  1.409909, val:  57.50%, val_best:  62.08%, tr:  70.89%, tr_best:  71.30%\n",
      "epoch-94  lr=['0.0001000'], tr/val_loss:  1.108972/  1.405452, val:  57.08%, val_best:  62.08%, tr:  70.99%, tr_best:  71.30%\n",
      "epoch-95  lr=['0.0001000'], tr/val_loss:  1.108382/  1.404326, val:  60.42%, val_best:  62.08%, tr:  68.74%, tr_best:  71.30%\n",
      "epoch-96  lr=['0.0001000'], tr/val_loss:  1.102261/  1.402613, val:  57.50%, val_best:  62.08%, tr:  71.60%, tr_best:  71.60%\n",
      "epoch-97  lr=['0.0001000'], tr/val_loss:  1.103477/  1.398065, val:  60.42%, val_best:  62.08%, tr:  70.17%, tr_best:  71.60%\n",
      "epoch-98  lr=['0.0001000'], tr/val_loss:  1.105053/  1.399116, val:  60.83%, val_best:  62.08%, tr:  68.74%, tr_best:  71.60%\n",
      "epoch-99  lr=['0.0001000'], tr/val_loss:  1.093753/  1.396429, val:  60.00%, val_best:  62.08%, tr:  70.79%, tr_best:  71.60%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b1c39f7f84d1438f8451633b1a45c253",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.006 MB of 0.006 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>iter_acc</td><td>▂▂▂▁▃▂▃▅▅▄▆▇▆▅▇▄▆▆▇▆▇▇▅▅▇▇▇▆▇▆▆▇▇▆█▇▅▇▇▇</td></tr><tr><td>summary_val_acc</td><td>▁▁▁▁▁▂▂▄▅▆▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇████▇██▇█▇███</td></tr><tr><td>tr_acc</td><td>▁▁▁▁▁▁▂▄▄▅▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇█▇▇▇█████████</td></tr><tr><td>tr_epoch_loss</td><td>███████▇▆▆▅▄▄▃▃▃▃▃▃▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_acc_best</td><td>▁▁▁▁▁▂▂▄▅▆▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇█████████████</td></tr><tr><td>val_acc_now</td><td>▁▁▁▁▁▂▂▄▅▆▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇████▇██▇█▇███</td></tr><tr><td>val_loss</td><td>███████▇▆▅▄▄▄▃▃▃▃▂▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>99</td></tr><tr><td>iter_acc</td><td>1.0</td></tr><tr><td>tr_acc</td><td>0.70787</td></tr><tr><td>tr_epoch_loss</td><td>1.09375</td></tr><tr><td>val_acc_best</td><td>0.62083</td></tr><tr><td>val_acc_now</td><td>0.6</td></tr><tr><td>val_loss</td><td>1.39643</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">solar-sweep-162</strong> at: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/64fiovlc' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/64fiovlc</a><br/> View project at: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>/data2/bh_wandb/wandb/run-20250430_034509-64fiovlc/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require(\"core\")`! See https://wandb.me/wandb-core for more information."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Sweep Agent: Waiting for job.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Job received.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: zauax4ls with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBATCH: 16\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBN_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBPTT_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tDFA_on: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tIMAGE_SIZE: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tOTTT_input_trace_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tTIME: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tUDA_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \talpha_uda: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbias: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcfg: ['M', 'M', 200, 200]\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tchaching_on: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tconvTrue_fcFalse: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdata_path: /data2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tddp_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdenoise_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdvs_clipping: 5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdvs_duration: 100000\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepoch_num: 100\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \texclude_class: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \textra_train_dataset: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlast_lif: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.01\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_sg_width: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_decay: 0.5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_init: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_reset: 10000\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_threshold: 0.25\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmerge_polarities: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmy_seed: 42\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnet_print: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_workers: 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer_what: SGD\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tpin_memory: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tpre_trained: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tpre_trained_path: net_save/save_now_net_weights_{unique_name}.pth\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \trate_coding: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tscheduler_name: no\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsingle_step: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsurrogate: hard_sigmoid\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_conv_kernel_size: 3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_conv_padding: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_conv_stride: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_trace_const1: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_trace_const2: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \ttdBN_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \ttrace_on: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \twhich_data: DVS_GESTURE_TONIC\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.19.10 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.17.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/data2/bh_wandb/wandb/run-20250430_035155-zauax4ls</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/zauax4ls' target=\"_blank\">breezy-sweep-164</a></strong> to <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/6pj3lh8j' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/6pj3lh8j</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/6pj3lh8j' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/6pj3lh8j</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/zauax4ls' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/zauax4ls</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'single_step' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'my_seed' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'TIME' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BATCH' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'IMAGE_SIZE' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'which_data' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'data_path' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'rate_coding' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_init' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_decay' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_threshold' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_reset' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_sg_width' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_conv_kernel_size' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_conv_stride' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_conv_padding' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_trace_const1' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_trace_const2' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'pre_trained' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'convTrue_fcFalse' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'cfg' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'net_print' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'pre_trained_path' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'learning_rate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'epoch_num' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'tdBN_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BN_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'surrogate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BPTT_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'optimizer_what' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'scheduler_name' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'ddp_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'dvs_clipping' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'dvs_duration' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'DFA_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'trace_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'OTTT_input_trace_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'exclude_class' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'merge_polarities' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'denoise_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'extra_train_dataset' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'num_workers' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'chaching_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'pin_memory' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'UDA_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'alpha_uda' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'bias' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'last_lif' was locked by 'sweep' (ignored update).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "param {'devices': '0', 'single_step': True, 'unique_name': 'main', 'my_seed': 42, 'TIME': 10, 'BATCH': 16, 'IMAGE_SIZE': 128, 'which_data': 'DVS_GESTURE_TONIC', 'data_path': '/data2', 'rate_coding': False, 'lif_layer_v_init': 0, 'lif_layer_v_decay': 0.5, 'lif_layer_v_threshold': 0.25, 'lif_layer_v_reset': 10000, 'lif_layer_sg_width': 1, 'synapse_conv_kernel_size': 3, 'synapse_conv_stride': 1, 'synapse_conv_padding': 1, 'synapse_trace_const1': 1, 'synapse_trace_const2': 0, 'pre_trained': False, 'convTrue_fcFalse': False, 'cfg': ['M', 'M', 200, 200], 'net_print': True, 'pre_trained_path': 'net_save/save_now_net_weights_{unique_name}.pth', 'learning_rate': 0.01, 'epoch_num': 100, 'tdBN_on': False, 'BN_on': False, 'surrogate': 'hard_sigmoid', 'BPTT_on': False, 'optimizer_what': 'SGD', 'scheduler_name': 'no', 'ddp_on': False, 'dvs_clipping': 5, 'dvs_duration': 100000, 'DFA_on': True, 'trace_on': True, 'OTTT_input_trace_on': False, 'exclude_class': True, 'merge_polarities': False, 'denoise_on': False, 'extra_train_dataset': 0, 'num_workers': 2, 'chaching_on': True, 'pin_memory': True, 'UDA_on': False, 'alpha_uda': 1, 'bias': True, 'last_lif': False, 'current epoch': 0} \n",
      "\n",
      "dataset_hash = ffa516e60c3efd5e0208f72b4c36cb84\n",
      "cache path exists\n",
      "\n",
      "device ==> cuda\n",
      "\n",
      "DataParallel(\n",
      "  (module): REBORN_MY_SNN_FC(\n",
      "    (layers): REBORN_MY_Sequential(\n",
      "      (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (2): DimChanger_for_FC()\n",
      "      (3): SYNAPSE_FC(in_features=2048, out_features=200, TIME=10, bias=True, sstep=True)\n",
      "      (4): LIF_layer(v_init=0, v_decay=0.5, v_threshold=0.25, v_reset=10000, sg_width=1, surrogate=hard_sigmoid, BPTT_on=False, trace_const1=1, trace_const2=0, TIME=10, sstep=True, trace_on=True)\n",
      "      (5): Feedback_Receiver()\n",
      "      (6): SYNAPSE_FC(in_features=200, out_features=200, TIME=10, bias=True, sstep=True)\n",
      "      (7): LIF_layer(v_init=0, v_decay=0.5, v_threshold=0.25, v_reset=10000, sg_width=1, surrogate=hard_sigmoid, BPTT_on=False, trace_const1=1, trace_const2=0, TIME=10, sstep=True, trace_on=True)\n",
      "      (8): Feedback_Receiver()\n",
      "      (9): SYNAPSE_FC(in_features=200, out_features=10, TIME=10, bias=True, sstep=True)\n",
      "      (DFA_top): Top_Gradient()\n",
      "    )\n",
      "  )\n",
      ")\n",
      "\n",
      "========================================================\n",
      "Trainable parameters: 452,010\n",
      "========================================================\n",
      "\n",
      "epoch-0   lr=['0.0100000'], tr/val_loss:  1.928960/  2.586020, val:  42.50%, val_best:  42.50%, tr:  37.69%, tr_best:  37.69%\n",
      "[module.layers.5] weight_fb parameter count: 2,000\n",
      "[module.layers.8] weight_fb parameter count: 2,000\n",
      "epoch-1   lr=['0.0100000'], tr/val_loss:  2.028639/  3.069965, val:  46.25%, val_best:  46.25%, tr:  45.97%, tr_best:  45.97%\n",
      "epoch-2   lr=['0.0100000'], tr/val_loss:  3.219657/  4.076245, val:  35.83%, val_best:  46.25%, tr:  48.72%, tr_best:  48.72%\n",
      "epoch-3   lr=['0.0100000'], tr/val_loss:  2.540523/  3.197645, val:  48.75%, val_best:  48.75%, tr:  52.81%, tr_best:  52.81%\n",
      "epoch-4   lr=['0.0100000'], tr/val_loss:  2.442782/  2.571609, val:  59.17%, val_best:  59.17%, tr:  55.57%, tr_best:  55.57%\n",
      "epoch-5   lr=['0.0100000'], tr/val_loss:  2.542018/  2.862110, val:  52.50%, val_best:  59.17%, tr:  57.81%, tr_best:  57.81%\n",
      "epoch-6   lr=['0.0100000'], tr/val_loss:  1.789851/  2.655197, val:  57.50%, val_best:  59.17%, tr:  63.84%, tr_best:  63.84%\n",
      "epoch-7   lr=['0.0100000'], tr/val_loss:  1.573006/  3.451087, val:  42.92%, val_best:  59.17%, tr:  68.23%, tr_best:  68.23%\n",
      "epoch-8   lr=['0.0100000'], tr/val_loss:  1.514518/  1.895738, val:  60.83%, val_best:  60.83%, tr:  68.34%, tr_best:  68.34%\n",
      "epoch-9   lr=['0.0100000'], tr/val_loss:  1.948082/  3.626060, val:  50.83%, val_best:  60.83%, tr:  68.23%, tr_best:  68.34%\n",
      "epoch-10  lr=['0.0100000'], tr/val_loss:  1.582876/  2.290741, val:  64.17%, val_best:  64.17%, tr:  72.93%, tr_best:  72.93%\n",
      "epoch-11  lr=['0.0100000'], tr/val_loss:  1.296325/  3.291587, val:  50.83%, val_best:  64.17%, tr:  78.75%, tr_best:  78.75%\n",
      "epoch-12  lr=['0.0100000'], tr/val_loss:  1.748693/  2.725079, val:  54.58%, val_best:  64.17%, tr:  74.36%, tr_best:  78.75%\n",
      "epoch-13  lr=['0.0100000'], tr/val_loss:  1.291497/  3.581860, val:  49.58%, val_best:  64.17%, tr:  79.16%, tr_best:  79.16%\n",
      "epoch-14  lr=['0.0100000'], tr/val_loss:  1.281479/  2.636540, val:  64.17%, val_best:  64.17%, tr:  80.39%, tr_best:  80.39%\n",
      "epoch-15  lr=['0.0100000'], tr/val_loss:  0.982082/  2.555198, val:  65.42%, val_best:  65.42%, tr:  86.93%, tr_best:  86.93%\n",
      "epoch-16  lr=['0.0100000'], tr/val_loss:  0.982318/  3.321702, val:  61.67%, val_best:  65.42%, tr:  86.21%, tr_best:  86.93%\n",
      "epoch-17  lr=['0.0100000'], tr/val_loss:  0.916362/  3.364131, val:  57.08%, val_best:  65.42%, tr:  88.15%, tr_best:  88.15%\n",
      "epoch-18  lr=['0.0100000'], tr/val_loss:  0.805733/  2.667330, val:  66.25%, val_best:  66.25%, tr:  89.58%, tr_best:  89.58%\n",
      "epoch-19  lr=['0.0100000'], tr/val_loss:  0.672063/  2.728094, val:  65.00%, val_best:  66.25%, tr:  91.93%, tr_best:  91.93%\n",
      "epoch-20  lr=['0.0100000'], tr/val_loss:  0.938705/  3.475054, val:  59.17%, val_best:  66.25%, tr:  87.03%, tr_best:  91.93%\n",
      "epoch-21  lr=['0.0100000'], tr/val_loss:  1.038233/  3.758340, val:  60.00%, val_best:  66.25%, tr:  87.64%, tr_best:  91.93%\n",
      "epoch-22  lr=['0.0100000'], tr/val_loss:  0.651429/  2.851754, val:  67.50%, val_best:  67.50%, tr:  94.48%, tr_best:  94.48%\n",
      "epoch-23  lr=['0.0100000'], tr/val_loss:  0.510810/  3.217405, val:  60.83%, val_best:  67.50%, tr:  96.12%, tr_best:  96.12%\n",
      "epoch-24  lr=['0.0100000'], tr/val_loss:  0.467950/  2.961771, val:  64.17%, val_best:  67.50%, tr:  96.83%, tr_best:  96.83%\n",
      "epoch-25  lr=['0.0100000'], tr/val_loss:  0.416473/  2.841001, val:  65.00%, val_best:  67.50%, tr:  96.42%, tr_best:  96.83%\n",
      "epoch-26  lr=['0.0100000'], tr/val_loss:  0.421074/  3.138549, val:  65.42%, val_best:  67.50%, tr:  96.22%, tr_best:  96.83%\n",
      "epoch-27  lr=['0.0100000'], tr/val_loss:  0.441087/  3.127172, val:  70.00%, val_best:  70.00%, tr:  95.91%, tr_best:  96.83%\n",
      "epoch-28  lr=['0.0100000'], tr/val_loss:  0.595353/  2.858433, val:  72.08%, val_best:  72.08%, tr:  93.56%, tr_best:  96.83%\n",
      "epoch-29  lr=['0.0100000'], tr/val_loss:  0.370850/  2.942342, val:  73.75%, val_best:  73.75%, tr:  97.14%, tr_best:  97.14%\n",
      "epoch-30  lr=['0.0100000'], tr/val_loss:  0.312044/  2.982726, val:  70.83%, val_best:  73.75%, tr:  98.47%, tr_best:  98.47%\n",
      "epoch-31  lr=['0.0100000'], tr/val_loss:  0.288354/  3.082844, val:  71.67%, val_best:  73.75%, tr:  98.37%, tr_best:  98.47%\n",
      "epoch-32  lr=['0.0100000'], tr/val_loss:  0.355845/  3.304008, val:  69.58%, val_best:  73.75%, tr:  97.96%, tr_best:  98.47%\n",
      "epoch-33  lr=['0.0100000'], tr/val_loss:  0.387077/  3.420693, val:  67.50%, val_best:  73.75%, tr:  97.14%, tr_best:  98.47%\n",
      "epoch-34  lr=['0.0100000'], tr/val_loss:  0.221184/  3.614106, val:  65.00%, val_best:  73.75%, tr:  99.49%, tr_best:  99.49%\n",
      "epoch-35  lr=['0.0100000'], tr/val_loss:  0.232078/  3.379528, val:  67.50%, val_best:  73.75%, tr:  98.77%, tr_best:  99.49%\n",
      "epoch-36  lr=['0.0100000'], tr/val_loss:  0.187949/  3.263076, val:  68.75%, val_best:  73.75%, tr:  99.90%, tr_best:  99.90%\n",
      "epoch-37  lr=['0.0100000'], tr/val_loss:  0.275158/  4.041551, val:  63.75%, val_best:  73.75%, tr:  98.26%, tr_best:  99.90%\n",
      "epoch-38  lr=['0.0100000'], tr/val_loss:  0.282533/  3.671293, val:  68.33%, val_best:  73.75%, tr:  98.88%, tr_best:  99.90%\n",
      "epoch-39  lr=['0.0100000'], tr/val_loss:  0.243689/  3.365167, val:  69.58%, val_best:  73.75%, tr:  98.37%, tr_best:  99.90%\n",
      "epoch-40  lr=['0.0100000'], tr/val_loss:  0.161179/  3.309496, val:  68.75%, val_best:  73.75%, tr:  99.49%, tr_best:  99.90%\n",
      "epoch-41  lr=['0.0100000'], tr/val_loss:  0.159264/  3.694841, val:  71.25%, val_best:  73.75%, tr:  99.49%, tr_best:  99.90%\n",
      "epoch-42  lr=['0.0100000'], tr/val_loss:  0.128478/  3.473939, val:  71.25%, val_best:  73.75%, tr:  99.90%, tr_best:  99.90%\n",
      "epoch-43  lr=['0.0100000'], tr/val_loss:  0.124075/  3.488140, val:  72.92%, val_best:  73.75%, tr:  99.80%, tr_best:  99.90%\n",
      "epoch-44  lr=['0.0100000'], tr/val_loss:  0.121529/  3.575097, val:  68.33%, val_best:  73.75%, tr:  99.69%, tr_best:  99.90%\n",
      "epoch-45  lr=['0.0100000'], tr/val_loss:  0.099494/  3.541976, val:  71.67%, val_best:  73.75%, tr:  99.90%, tr_best:  99.90%\n",
      "epoch-46  lr=['0.0100000'], tr/val_loss:  0.105396/  3.645833, val:  69.58%, val_best:  73.75%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-47  lr=['0.0100000'], tr/val_loss:  0.097440/  3.754463, val:  68.75%, val_best:  73.75%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-48  lr=['0.0100000'], tr/val_loss:  0.103599/  3.635423, val:  72.50%, val_best:  73.75%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-49  lr=['0.0100000'], tr/val_loss:  0.088985/  3.680380, val:  70.42%, val_best:  73.75%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-50  lr=['0.0100000'], tr/val_loss:  0.083437/  3.764715, val:  70.83%, val_best:  73.75%, tr:  99.90%, tr_best: 100.00%\n",
      "epoch-51  lr=['0.0100000'], tr/val_loss:  0.072371/  3.773951, val:  71.67%, val_best:  73.75%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-52  lr=['0.0100000'], tr/val_loss:  0.079538/  3.825913, val:  70.42%, val_best:  73.75%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-53  lr=['0.0100000'], tr/val_loss:  0.067237/  3.901459, val:  70.00%, val_best:  73.75%, tr:  99.90%, tr_best: 100.00%\n",
      "epoch-54  lr=['0.0100000'], tr/val_loss:  0.065379/  3.871553, val:  71.67%, val_best:  73.75%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-55  lr=['0.0100000'], tr/val_loss:  0.050155/  3.835580, val:  72.50%, val_best:  73.75%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-56  lr=['0.0100000'], tr/val_loss:  0.041710/  3.892232, val:  72.92%, val_best:  73.75%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-57  lr=['0.0100000'], tr/val_loss:  0.059880/  3.880735, val:  72.08%, val_best:  73.75%, tr:  99.90%, tr_best: 100.00%\n",
      "epoch-58  lr=['0.0100000'], tr/val_loss:  0.052353/  3.929569, val:  74.17%, val_best:  74.17%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-59  lr=['0.0100000'], tr/val_loss:  0.039819/  3.975447, val:  71.67%, val_best:  74.17%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-60  lr=['0.0100000'], tr/val_loss:  0.031060/  4.002695, val:  71.25%, val_best:  74.17%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-61  lr=['0.0100000'], tr/val_loss:  0.061081/  4.083247, val:  72.50%, val_best:  74.17%, tr:  99.80%, tr_best: 100.00%\n",
      "epoch-62  lr=['0.0100000'], tr/val_loss:  0.047982/  4.061571, val:  74.17%, val_best:  74.17%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-63  lr=['0.0100000'], tr/val_loss:  0.032500/  4.081172, val:  72.92%, val_best:  74.17%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-64  lr=['0.0100000'], tr/val_loss:  0.041262/  4.170502, val:  73.33%, val_best:  74.17%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-65  lr=['0.0100000'], tr/val_loss:  0.027127/  4.061062, val:  74.17%, val_best:  74.17%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-66  lr=['0.0100000'], tr/val_loss:  0.028293/  4.148133, val:  71.67%, val_best:  74.17%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-67  lr=['0.0100000'], tr/val_loss:  0.028743/  4.107833, val:  72.50%, val_best:  74.17%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-68  lr=['0.0100000'], tr/val_loss:  0.031681/  4.139636, val:  74.17%, val_best:  74.17%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-69  lr=['0.0100000'], tr/val_loss:  0.024212/  4.146400, val:  72.50%, val_best:  74.17%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-70  lr=['0.0100000'], tr/val_loss:  0.021069/  4.174095, val:  75.00%, val_best:  75.00%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-71  lr=['0.0100000'], tr/val_loss:  0.024652/  4.205960, val:  74.17%, val_best:  75.00%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-72  lr=['0.0100000'], tr/val_loss:  0.021024/  4.271937, val:  71.25%, val_best:  75.00%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-73  lr=['0.0100000'], tr/val_loss:  0.021771/  4.244502, val:  73.33%, val_best:  75.00%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-74  lr=['0.0100000'], tr/val_loss:  0.019623/  4.252148, val:  75.42%, val_best:  75.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-75  lr=['0.0100000'], tr/val_loss:  0.020069/  4.285434, val:  72.92%, val_best:  75.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-76  lr=['0.0100000'], tr/val_loss:  0.021887/  4.371557, val:  74.17%, val_best:  75.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-77  lr=['0.0100000'], tr/val_loss:  0.016482/  4.348726, val:  75.42%, val_best:  75.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-78  lr=['0.0100000'], tr/val_loss:  0.019072/  4.381913, val:  75.00%, val_best:  75.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-79  lr=['0.0100000'], tr/val_loss:  0.018717/  4.335823, val:  74.58%, val_best:  75.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-80  lr=['0.0100000'], tr/val_loss:  0.014701/  4.301388, val:  76.25%, val_best:  76.25%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-81  lr=['0.0100000'], tr/val_loss:  0.014663/  4.363518, val:  74.58%, val_best:  76.25%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-82  lr=['0.0100000'], tr/val_loss:  0.013623/  4.365258, val:  75.00%, val_best:  76.25%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-83  lr=['0.0100000'], tr/val_loss:  0.018412/  4.495077, val:  71.25%, val_best:  76.25%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-84  lr=['0.0100000'], tr/val_loss:  0.018834/  4.389337, val:  74.17%, val_best:  76.25%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-85  lr=['0.0100000'], tr/val_loss:  0.021303/  4.409808, val:  73.75%, val_best:  76.25%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-86  lr=['0.0100000'], tr/val_loss:  0.017120/  4.424475, val:  75.42%, val_best:  76.25%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-87  lr=['0.0100000'], tr/val_loss:  0.016479/  4.438114, val:  72.92%, val_best:  76.25%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-88  lr=['0.0100000'], tr/val_loss:  0.011736/  4.443849, val:  73.33%, val_best:  76.25%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-89  lr=['0.0100000'], tr/val_loss:  0.011288/  4.449883, val:  73.33%, val_best:  76.25%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-90  lr=['0.0100000'], tr/val_loss:  0.010152/  4.487400, val:  75.00%, val_best:  76.25%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-91  lr=['0.0100000'], tr/val_loss:  0.010892/  4.535608, val:  74.58%, val_best:  76.25%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-92  lr=['0.0100000'], tr/val_loss:  0.010987/  4.506854, val:  74.58%, val_best:  76.25%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-93  lr=['0.0100000'], tr/val_loss:  0.011189/  4.519120, val:  74.58%, val_best:  76.25%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-94  lr=['0.0100000'], tr/val_loss:  0.009931/  4.619758, val:  75.00%, val_best:  76.25%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-95  lr=['0.0100000'], tr/val_loss:  0.010117/  4.639515, val:  74.17%, val_best:  76.25%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-96  lr=['0.0100000'], tr/val_loss:  0.010191/  4.679977, val:  72.92%, val_best:  76.25%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-97  lr=['0.0100000'], tr/val_loss:  0.010267/  4.581577, val:  74.17%, val_best:  76.25%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-98  lr=['0.0100000'], tr/val_loss:  0.009052/  4.655974, val:  74.17%, val_best:  76.25%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-99  lr=['0.0100000'], tr/val_loss:  0.008358/  4.629512, val:  74.17%, val_best:  76.25%, tr: 100.00%, tr_best: 100.00%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ab3fa81beabd4ad7ba1678c924e20ba4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.006 MB of 0.006 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>iter_acc</td><td>▁▅▃▅▅▅▇▇▇▇██████████████████████████████</td></tr><tr><td>summary_val_acc</td><td>▂▁▅▂▄▄▆▅▆▅▆▆█▇▇▆▇▇▇▇▇▇▇▇▇▇█▇█▇██████████</td></tr><tr><td>tr_acc</td><td>▁▂▃▄▄▅▆▇▇▇██████████████████████████████</td></tr><tr><td>tr_epoch_loss</td><td>▅█▆▄▅▅▄▃▂▃▂▂▂▂▁▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_acc_best</td><td>▁▂▄▄▅▅▅▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇████████████████</td></tr><tr><td>val_acc_now</td><td>▂▁▅▂▄▄▆▅▆▅▆▆█▇▇▆▇▇▇▇▇▇▇▇▇▇█▇█▇██████████</td></tr><tr><td>val_loss</td><td>▁▆▁▄▅▂▁▄▂▅▂▃▂▃▄▆▄▄▄▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇▇▇███</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>99</td></tr><tr><td>iter_acc</td><td>1.0</td></tr><tr><td>tr_acc</td><td>1.0</td></tr><tr><td>tr_epoch_loss</td><td>0.00836</td></tr><tr><td>val_acc_best</td><td>0.7625</td></tr><tr><td>val_acc_now</td><td>0.74167</td></tr><tr><td>val_loss</td><td>4.62951</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">breezy-sweep-164</strong> at: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/zauax4ls' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/zauax4ls</a><br/> View project at: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>/data2/bh_wandb/wandb/run-20250430_035155-zauax4ls/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require(\"core\")`! See https://wandb.me/wandb-core for more information."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Sweep Agent: Waiting for job.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Job received.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 7ocdngkq with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBATCH: 16\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBN_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBPTT_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tDFA_on: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tIMAGE_SIZE: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tOTTT_input_trace_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tTIME: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tUDA_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \talpha_uda: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbias: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcfg: ['M', 'M', 200, 200]\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tchaching_on: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tconvTrue_fcFalse: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdata_path: /data2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tddp_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdenoise_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdvs_clipping: 5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdvs_duration: 100000\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepoch_num: 100\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \texclude_class: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \textra_train_dataset: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlast_lif: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_sg_width: 4\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_decay: 0.5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_init: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_reset: 10000\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_threshold: 0.5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmerge_polarities: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmy_seed: 42\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnet_print: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_workers: 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer_what: SGD\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tpin_memory: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tpre_trained: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tpre_trained_path: net_save/save_now_net_weights_{unique_name}.pth\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \trate_coding: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tscheduler_name: no\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsingle_step: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsurrogate: hard_sigmoid\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_conv_kernel_size: 3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_conv_padding: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_conv_stride: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_trace_const1: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_trace_const2: 0.5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \ttdBN_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \ttrace_on: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \twhich_data: DVS_GESTURE_TONIC\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "de161703adab4b25bbfb820d3ff81e61",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.011113631642527051, max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.19.10 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.17.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/data2/bh_wandb/wandb/run-20250430_035838-7ocdngkq</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/7ocdngkq' target=\"_blank\">azure-sweep-166</a></strong> to <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/6pj3lh8j' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/6pj3lh8j</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/6pj3lh8j' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/6pj3lh8j</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/7ocdngkq' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/7ocdngkq</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'single_step' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'my_seed' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'TIME' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BATCH' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'IMAGE_SIZE' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'which_data' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'data_path' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'rate_coding' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_init' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_decay' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_threshold' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_reset' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_sg_width' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_conv_kernel_size' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_conv_stride' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_conv_padding' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_trace_const1' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_trace_const2' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'pre_trained' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'convTrue_fcFalse' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'cfg' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'net_print' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'pre_trained_path' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'learning_rate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'epoch_num' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'tdBN_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BN_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'surrogate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BPTT_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'optimizer_what' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'scheduler_name' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'ddp_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'dvs_clipping' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'dvs_duration' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'DFA_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'trace_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'OTTT_input_trace_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'exclude_class' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'merge_polarities' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'denoise_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'extra_train_dataset' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'num_workers' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'chaching_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'pin_memory' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'UDA_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'alpha_uda' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'bias' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'last_lif' was locked by 'sweep' (ignored update).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "param {'devices': '0', 'single_step': True, 'unique_name': 'main', 'my_seed': 42, 'TIME': 10, 'BATCH': 16, 'IMAGE_SIZE': 128, 'which_data': 'DVS_GESTURE_TONIC', 'data_path': '/data2', 'rate_coding': False, 'lif_layer_v_init': 0, 'lif_layer_v_decay': 0.5, 'lif_layer_v_threshold': 0.5, 'lif_layer_v_reset': 10000, 'lif_layer_sg_width': 4, 'synapse_conv_kernel_size': 3, 'synapse_conv_stride': 1, 'synapse_conv_padding': 1, 'synapse_trace_const1': 1, 'synapse_trace_const2': 0.5, 'pre_trained': False, 'convTrue_fcFalse': False, 'cfg': ['M', 'M', 200, 200], 'net_print': True, 'pre_trained_path': 'net_save/save_now_net_weights_{unique_name}.pth', 'learning_rate': 0.1, 'epoch_num': 100, 'tdBN_on': False, 'BN_on': False, 'surrogate': 'hard_sigmoid', 'BPTT_on': False, 'optimizer_what': 'SGD', 'scheduler_name': 'no', 'ddp_on': False, 'dvs_clipping': 5, 'dvs_duration': 100000, 'DFA_on': True, 'trace_on': True, 'OTTT_input_trace_on': False, 'exclude_class': True, 'merge_polarities': False, 'denoise_on': False, 'extra_train_dataset': 0, 'num_workers': 2, 'chaching_on': True, 'pin_memory': True, 'UDA_on': False, 'alpha_uda': 1, 'bias': True, 'last_lif': False, 'current epoch': 0} \n",
      "\n",
      "dataset_hash = ffa516e60c3efd5e0208f72b4c36cb84\n",
      "cache path exists\n",
      "\n",
      "device ==> cuda\n",
      "\n",
      "DataParallel(\n",
      "  (module): REBORN_MY_SNN_FC(\n",
      "    (layers): REBORN_MY_Sequential(\n",
      "      (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (2): DimChanger_for_FC()\n",
      "      (3): SYNAPSE_FC(in_features=2048, out_features=200, TIME=10, bias=True, sstep=True)\n",
      "      (4): LIF_layer(v_init=0, v_decay=0.5, v_threshold=0.5, v_reset=10000, sg_width=4, surrogate=hard_sigmoid, BPTT_on=False, trace_const1=1, trace_const2=0.5, TIME=10, sstep=True, trace_on=True)\n",
      "      (5): Feedback_Receiver()\n",
      "      (6): SYNAPSE_FC(in_features=200, out_features=200, TIME=10, bias=True, sstep=True)\n",
      "      (7): LIF_layer(v_init=0, v_decay=0.5, v_threshold=0.5, v_reset=10000, sg_width=4, surrogate=hard_sigmoid, BPTT_on=False, trace_const1=1, trace_const2=0.5, TIME=10, sstep=True, trace_on=True)\n",
      "      (8): Feedback_Receiver()\n",
      "      (9): SYNAPSE_FC(in_features=200, out_features=10, TIME=10, bias=True, sstep=True)\n",
      "      (DFA_top): Top_Gradient()\n",
      "    )\n",
      "  )\n",
      ")\n",
      "\n",
      "========================================================\n",
      "Trainable parameters: 452,010\n",
      "========================================================\n",
      "\n",
      "epoch-0   lr=['0.1000000'], tr/val_loss:132.769852/ 62.325058, val:  26.25%, val_best:  26.25%, tr:  16.14%, tr_best:  16.14%\n",
      "[module.layers.5] weight_fb parameter count: 2,000\n",
      "[module.layers.8] weight_fb parameter count: 2,000\n",
      "epoch-1   lr=['0.1000000'], tr/val_loss: 49.696239/ 53.040783, val:  20.00%, val_best:  26.25%, tr:  27.68%, tr_best:  27.68%\n",
      "epoch-2   lr=['0.1000000'], tr/val_loss: 61.099026/ 60.421013, val:  33.33%, val_best:  33.33%, tr:  29.72%, tr_best:  29.72%\n",
      "epoch-3   lr=['0.1000000'], tr/val_loss: 43.286880/ 37.147919, val:  36.67%, val_best:  36.67%, tr:  35.04%, tr_best:  35.04%\n",
      "epoch-4   lr=['0.1000000'], tr/val_loss: 53.111465/ 55.453552, val:  35.42%, val_best:  36.67%, tr:  35.14%, tr_best:  35.14%\n",
      "epoch-5   lr=['0.1000000'], tr/val_loss: 37.872066/ 63.640720, val:  33.75%, val_best:  36.67%, tr:  43.92%, tr_best:  43.92%\n",
      "epoch-6   lr=['0.1000000'], tr/val_loss: 31.772413/ 48.049721, val:  32.50%, val_best:  36.67%, tr:  46.07%, tr_best:  46.07%\n",
      "epoch-7   lr=['0.1000000'], tr/val_loss: 34.316326/ 45.393078, val:  35.42%, val_best:  36.67%, tr:  45.86%, tr_best:  46.07%\n",
      "epoch-8   lr=['0.1000000'], tr/val_loss: 25.281605/ 35.617855, val:  45.83%, val_best:  45.83%, tr:  58.63%, tr_best:  58.63%\n",
      "epoch-9   lr=['0.1000000'], tr/val_loss: 29.990046/ 35.504494, val:  51.25%, val_best:  51.25%, tr:  52.71%, tr_best:  58.63%\n",
      "epoch-10  lr=['0.1000000'], tr/val_loss: 27.563215/ 49.932961, val:  41.67%, val_best:  51.25%, tr:  59.65%, tr_best:  59.65%\n",
      "epoch-11  lr=['0.1000000'], tr/val_loss: 30.754059/ 43.316250, val:  38.33%, val_best:  51.25%, tr:  58.02%, tr_best:  59.65%\n",
      "epoch-12  lr=['0.1000000'], tr/val_loss: 27.818378/ 38.229744, val:  49.58%, val_best:  51.25%, tr:  63.23%, tr_best:  63.23%\n",
      "epoch-13  lr=['0.1000000'], tr/val_loss: 24.139465/ 63.623856, val:  32.50%, val_best:  51.25%, tr:  67.52%, tr_best:  67.52%\n",
      "epoch-14  lr=['0.1000000'], tr/val_loss: 23.496405/ 42.902878, val:  45.42%, val_best:  51.25%, tr:  64.66%, tr_best:  67.52%\n",
      "epoch-15  lr=['0.1000000'], tr/val_loss: 16.481768/ 37.954987, val:  54.58%, val_best:  54.58%, tr:  73.34%, tr_best:  73.34%\n",
      "epoch-16  lr=['0.1000000'], tr/val_loss: 19.484846/ 48.871281, val:  48.33%, val_best:  54.58%, tr:  71.30%, tr_best:  73.34%\n",
      "epoch-17  lr=['0.1000000'], tr/val_loss: 19.083120/ 57.025928, val:  45.00%, val_best:  54.58%, tr:  71.81%, tr_best:  73.34%\n",
      "epoch-18  lr=['0.1000000'], tr/val_loss: 19.786165/ 54.294346, val:  52.08%, val_best:  54.58%, tr:  75.08%, tr_best:  75.08%\n",
      "epoch-19  lr=['0.1000000'], tr/val_loss: 15.532130/ 48.170815, val:  45.42%, val_best:  54.58%, tr:  80.08%, tr_best:  80.08%\n",
      "epoch-20  lr=['0.1000000'], tr/val_loss: 18.286798/ 48.426720, val:  52.50%, val_best:  54.58%, tr:  80.49%, tr_best:  80.49%\n",
      "epoch-21  lr=['0.1000000'], tr/val_loss: 14.245438/ 46.206669, val:  57.50%, val_best:  57.50%, tr:  81.72%, tr_best:  81.72%\n",
      "epoch-22  lr=['0.1000000'], tr/val_loss: 10.901704/ 42.772270, val:  60.42%, val_best:  60.42%, tr:  88.66%, tr_best:  88.66%\n",
      "epoch-23  lr=['0.1000000'], tr/val_loss: 10.522414/ 37.421928, val:  62.92%, val_best:  62.92%, tr:  90.70%, tr_best:  90.70%\n",
      "epoch-24  lr=['0.1000000'], tr/val_loss:  8.009375/ 39.149967, val:  67.50%, val_best:  67.50%, tr:  93.67%, tr_best:  93.67%\n",
      "epoch-25  lr=['0.1000000'], tr/val_loss:  9.834580/ 40.471790, val:  69.17%, val_best:  69.17%, tr:  90.40%, tr_best:  93.67%\n",
      "epoch-26  lr=['0.1000000'], tr/val_loss:  9.107901/ 44.676418, val:  64.17%, val_best:  69.17%, tr:  90.70%, tr_best:  93.67%\n",
      "epoch-27  lr=['0.1000000'], tr/val_loss:  7.595381/ 40.260555, val:  65.42%, val_best:  69.17%, tr:  94.69%, tr_best:  94.69%\n",
      "epoch-28  lr=['0.1000000'], tr/val_loss:  7.011493/ 46.469234, val:  62.50%, val_best:  69.17%, tr:  95.91%, tr_best:  95.91%\n",
      "epoch-29  lr=['0.1000000'], tr/val_loss:  7.143715/ 46.086948, val:  62.92%, val_best:  69.17%, tr:  96.42%, tr_best:  96.42%\n",
      "epoch-30  lr=['0.1000000'], tr/val_loss:  7.520859/ 43.704037, val:  65.00%, val_best:  69.17%, tr:  94.48%, tr_best:  96.42%\n",
      "epoch-31  lr=['0.1000000'], tr/val_loss:  6.110770/ 43.994007, val:  70.83%, val_best:  70.83%, tr:  98.37%, tr_best:  98.37%\n",
      "epoch-32  lr=['0.1000000'], tr/val_loss:  5.079112/ 46.510296, val:  67.08%, val_best:  70.83%, tr:  98.57%, tr_best:  98.57%\n",
      "epoch-33  lr=['0.1000000'], tr/val_loss:  4.956523/ 43.278893, val:  74.17%, val_best:  74.17%, tr:  98.47%, tr_best:  98.57%\n",
      "epoch-34  lr=['0.1000000'], tr/val_loss:  3.702523/ 48.526443, val:  67.08%, val_best:  74.17%, tr:  99.28%, tr_best:  99.28%\n",
      "epoch-35  lr=['0.1000000'], tr/val_loss:  4.233860/ 43.627335, val:  70.83%, val_best:  74.17%, tr:  98.67%, tr_best:  99.28%\n",
      "epoch-36  lr=['0.1000000'], tr/val_loss:  3.777889/ 46.328156, val:  72.50%, val_best:  74.17%, tr:  99.28%, tr_best:  99.28%\n",
      "epoch-37  lr=['0.1000000'], tr/val_loss:  3.567884/ 48.380150, val:  71.25%, val_best:  74.17%, tr:  99.49%, tr_best:  99.49%\n",
      "epoch-38  lr=['0.1000000'], tr/val_loss:  2.722483/ 47.341694, val:  71.25%, val_best:  74.17%, tr:  99.59%, tr_best:  99.59%\n",
      "epoch-39  lr=['0.1000000'], tr/val_loss:  2.822599/ 49.382874, val:  67.50%, val_best:  74.17%, tr:  99.28%, tr_best:  99.59%\n",
      "epoch-40  lr=['0.1000000'], tr/val_loss:  2.706525/ 49.854168, val:  69.17%, val_best:  74.17%, tr:  99.69%, tr_best:  99.69%\n",
      "epoch-41  lr=['0.1000000'], tr/val_loss:  2.658560/ 49.329460, val:  66.67%, val_best:  74.17%, tr:  99.69%, tr_best:  99.69%\n",
      "epoch-42  lr=['0.1000000'], tr/val_loss:  3.707387/ 50.042969, val:  71.25%, val_best:  74.17%, tr:  98.77%, tr_best:  99.69%\n",
      "epoch-43  lr=['0.1000000'], tr/val_loss:  2.334719/ 48.485897, val:  73.75%, val_best:  74.17%, tr:  99.69%, tr_best:  99.69%\n",
      "epoch-44  lr=['0.1000000'], tr/val_loss:  2.110787/ 47.989819, val:  75.00%, val_best:  75.00%, tr:  99.69%, tr_best:  99.69%\n",
      "epoch-45  lr=['0.1000000'], tr/val_loss:  2.373017/ 52.505077, val:  70.83%, val_best:  75.00%, tr:  99.69%, tr_best:  99.69%\n",
      "epoch-46  lr=['0.1000000'], tr/val_loss:  1.960389/ 48.600517, val:  72.50%, val_best:  75.00%, tr:  99.69%, tr_best:  99.69%\n",
      "epoch-47  lr=['0.1000000'], tr/val_loss:  1.882935/ 48.671204, val:  70.83%, val_best:  75.00%, tr:  99.90%, tr_best:  99.90%\n",
      "epoch-48  lr=['0.1000000'], tr/val_loss:  1.903380/ 49.345158, val:  70.83%, val_best:  75.00%, tr:  99.80%, tr_best:  99.90%\n",
      "epoch-49  lr=['0.1000000'], tr/val_loss:  1.794734/ 54.605175, val:  70.83%, val_best:  75.00%, tr:  99.80%, tr_best:  99.90%\n",
      "epoch-50  lr=['0.1000000'], tr/val_loss:  1.627717/ 50.763493, val:  72.50%, val_best:  75.00%, tr:  99.90%, tr_best:  99.90%\n",
      "epoch-51  lr=['0.1000000'], tr/val_loss:  1.567030/ 50.752586, val:  74.17%, val_best:  75.00%, tr:  99.90%, tr_best:  99.90%\n",
      "epoch-52  lr=['0.1000000'], tr/val_loss:  1.388138/ 51.926083, val:  73.33%, val_best:  75.00%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-53  lr=['0.1000000'], tr/val_loss:  1.334003/ 53.624378, val:  71.25%, val_best:  75.00%, tr:  99.90%, tr_best: 100.00%\n",
      "epoch-54  lr=['0.1000000'], tr/val_loss:  1.315842/ 48.669266, val:  69.58%, val_best:  75.00%, tr:  99.90%, tr_best: 100.00%\n",
      "epoch-55  lr=['0.1000000'], tr/val_loss:  1.572085/ 53.087124, val:  71.67%, val_best:  75.00%, tr:  99.80%, tr_best: 100.00%\n",
      "epoch-56  lr=['0.1000000'], tr/val_loss:  1.299639/ 55.143566, val:  69.58%, val_best:  75.00%, tr:  99.69%, tr_best: 100.00%\n",
      "epoch-57  lr=['0.1000000'], tr/val_loss:  1.289786/ 54.349831, val:  72.50%, val_best:  75.00%, tr:  99.80%, tr_best: 100.00%\n",
      "epoch-58  lr=['0.1000000'], tr/val_loss:  1.442843/ 54.037697, val:  74.17%, val_best:  75.00%, tr:  99.90%, tr_best: 100.00%\n",
      "epoch-59  lr=['0.1000000'], tr/val_loss:  1.444649/ 55.576988, val:  69.17%, val_best:  75.00%, tr:  99.80%, tr_best: 100.00%\n",
      "epoch-60  lr=['0.1000000'], tr/val_loss:  1.032880/ 55.129208, val:  70.83%, val_best:  75.00%, tr:  99.90%, tr_best: 100.00%\n",
      "epoch-61  lr=['0.1000000'], tr/val_loss:  0.846789/ 54.672897, val:  70.83%, val_best:  75.00%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-62  lr=['0.1000000'], tr/val_loss:  0.738154/ 54.783871, val:  70.42%, val_best:  75.00%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-63  lr=['0.1000000'], tr/val_loss:  0.924198/ 55.250580, val:  72.08%, val_best:  75.00%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-64  lr=['0.1000000'], tr/val_loss:  0.870035/ 56.940281, val:  71.67%, val_best:  75.00%, tr:  99.90%, tr_best: 100.00%\n",
      "epoch-65  lr=['0.1000000'], tr/val_loss:  0.847828/ 56.520420, val:  70.83%, val_best:  75.00%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-66  lr=['0.1000000'], tr/val_loss:  0.887645/ 56.217209, val:  71.67%, val_best:  75.00%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-67  lr=['0.1000000'], tr/val_loss:  0.782591/ 54.833244, val:  70.42%, val_best:  75.00%, tr:  99.90%, tr_best: 100.00%\n",
      "epoch-68  lr=['0.1000000'], tr/val_loss:  0.745082/ 55.089691, val:  71.67%, val_best:  75.00%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-69  lr=['0.1000000'], tr/val_loss:  0.748516/ 57.937374, val:  73.33%, val_best:  75.00%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-70  lr=['0.1000000'], tr/val_loss:  0.817307/ 55.608643, val:  73.75%, val_best:  75.00%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-71  lr=['0.1000000'], tr/val_loss:  1.010069/ 56.414623, val:  70.83%, val_best:  75.00%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-72  lr=['0.1000000'], tr/val_loss:  0.719646/ 56.227734, val:  72.08%, val_best:  75.00%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-73  lr=['0.1000000'], tr/val_loss:  0.672717/ 56.735760, val:  72.50%, val_best:  75.00%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-74  lr=['0.1000000'], tr/val_loss:  1.071387/ 56.886745, val:  73.33%, val_best:  75.00%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-75  lr=['0.1000000'], tr/val_loss:  0.808281/ 58.280319, val:  72.08%, val_best:  75.00%, tr:  99.80%, tr_best: 100.00%\n",
      "epoch-76  lr=['0.1000000'], tr/val_loss:  0.768661/ 57.949749, val:  72.92%, val_best:  75.00%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-77  lr=['0.1000000'], tr/val_loss:  0.785142/ 60.331013, val:  67.08%, val_best:  75.00%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-78  lr=['0.1000000'], tr/val_loss:  0.872124/ 56.716972, val:  72.50%, val_best:  75.00%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-79  lr=['0.1000000'], tr/val_loss:  0.697455/ 57.525120, val:  72.92%, val_best:  75.00%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-80  lr=['0.1000000'], tr/val_loss:  0.665088/ 58.714115, val:  73.75%, val_best:  75.00%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-81  lr=['0.1000000'], tr/val_loss:  0.574662/ 58.744400, val:  71.67%, val_best:  75.00%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-82  lr=['0.1000000'], tr/val_loss:  0.489968/ 56.672569, val:  74.58%, val_best:  75.00%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-83  lr=['0.1000000'], tr/val_loss:  0.569576/ 57.809299, val:  72.50%, val_best:  75.00%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-84  lr=['0.1000000'], tr/val_loss:  0.481199/ 58.270370, val:  74.58%, val_best:  75.00%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-85  lr=['0.1000000'], tr/val_loss:  0.633396/ 58.222073, val:  75.42%, val_best:  75.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-86  lr=['0.1000000'], tr/val_loss:  0.612138/ 59.217354, val:  70.42%, val_best:  75.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-87  lr=['0.1000000'], tr/val_loss:  0.709040/ 57.831944, val:  72.50%, val_best:  75.42%, tr:  99.90%, tr_best: 100.00%\n",
      "epoch-88  lr=['0.1000000'], tr/val_loss:  0.865401/ 60.611702, val:  72.08%, val_best:  75.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-89  lr=['0.1000000'], tr/val_loss:  0.597875/ 63.035419, val:  69.58%, val_best:  75.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-90  lr=['0.1000000'], tr/val_loss:  0.518505/ 61.916233, val:  72.50%, val_best:  75.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-91  lr=['0.1000000'], tr/val_loss:  0.426116/ 60.336460, val:  70.00%, val_best:  75.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-92  lr=['0.1000000'], tr/val_loss:  0.336742/ 59.383961, val:  72.92%, val_best:  75.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-93  lr=['0.1000000'], tr/val_loss:  0.324313/ 61.207409, val:  70.42%, val_best:  75.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-94  lr=['0.1000000'], tr/val_loss:  0.412991/ 59.511189, val:  72.08%, val_best:  75.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-95  lr=['0.1000000'], tr/val_loss:  0.452718/ 61.162395, val:  69.17%, val_best:  75.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-96  lr=['0.1000000'], tr/val_loss:  0.323055/ 59.291553, val:  71.67%, val_best:  75.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-97  lr=['0.1000000'], tr/val_loss:  0.486156/ 60.993481, val:  72.08%, val_best:  75.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-98  lr=['0.1000000'], tr/val_loss:  0.599375/ 58.050644, val:  74.17%, val_best:  75.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-99  lr=['0.1000000'], tr/val_loss:  0.417789/ 58.874779, val:  73.75%, val_best:  75.42%, tr: 100.00%, tr_best: 100.00%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7213ea72b2244ec08c3e33fdd624bc69",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.006 MB of 0.006 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>iter_acc</td><td>▁▃▃▅▅▆▅▆▇█▇█████████████████████████████</td></tr><tr><td>summary_val_acc</td><td>▁▂▂▂▅▄▄▄▄▅▇▆▆▇▇▇▇▇█▇▇█▇█▇▇▇▇███▇████▇█▇█</td></tr><tr><td>tr_acc</td><td>▁▂▃▃▄▅▅▆▆▆▇▇████████████████████████████</td></tr><tr><td>tr_epoch_loss</td><td>█▄▄▃▃▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_acc_best</td><td>▁▂▂▂▅▅▅▅▅▅▇▇▇▇██████████████████████████</td></tr><tr><td>val_acc_now</td><td>▁▂▂▂▅▄▄▄▄▅▇▆▆▇▇▇▇▇█▇▇█▇█▇▇▇▇███▇████▇█▇█</td></tr><tr><td>val_loss</td><td>█▇▆▄▁▂▃▆▄▄▂▃▄▄▃▄▅▅▄▄▆▅▄▆▆▆▆▆▆▆▇▇▇▆▇▇█▇█▇</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>99</td></tr><tr><td>iter_acc</td><td>1.0</td></tr><tr><td>tr_acc</td><td>1.0</td></tr><tr><td>tr_epoch_loss</td><td>0.41779</td></tr><tr><td>val_acc_best</td><td>0.75417</td></tr><tr><td>val_acc_now</td><td>0.7375</td></tr><tr><td>val_loss</td><td>58.87478</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">azure-sweep-166</strong> at: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/7ocdngkq' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/7ocdngkq</a><br/> View project at: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>/data2/bh_wandb/wandb/run-20250430_035838-7ocdngkq/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require(\"core\")`! See https://wandb.me/wandb-core for more information."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: dmt2o6sn with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBATCH: 16\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBN_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBPTT_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tDFA_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tIMAGE_SIZE: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tOTTT_input_trace_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tTIME: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tUDA_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \talpha_uda: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbias: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcfg: ['M', 'M', 200, 200]\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tchaching_on: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tconvTrue_fcFalse: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdata_path: /data2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tddp_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdenoise_on: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdvs_clipping: 5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdvs_duration: 100000\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepoch_num: 100\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \texclude_class: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \textra_train_dataset: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlast_lif: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.001\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_sg_width: 5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_decay: 0.5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_init: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_reset: 10000\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_threshold: 0.75\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmerge_polarities: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmy_seed: 42\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnet_print: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_workers: 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer_what: SGD\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tpin_memory: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tpre_trained: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tpre_trained_path: net_save/save_now_net_weights_{unique_name}.pth\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \trate_coding: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tscheduler_name: no\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsingle_step: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsurrogate: hard_sigmoid\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_conv_kernel_size: 3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_conv_padding: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_conv_stride: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_trace_const1: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_trace_const2: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \ttdBN_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \ttrace_on: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \twhich_data: DVS_GESTURE_TONIC\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.19.10 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.17.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/data2/bh_wandb/wandb/run-20250430_040516-dmt2o6sn</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/dmt2o6sn' target=\"_blank\">fast-sweep-168</a></strong> to <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/6pj3lh8j' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/6pj3lh8j</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/6pj3lh8j' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/6pj3lh8j</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/dmt2o6sn' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/dmt2o6sn</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'single_step' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'my_seed' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'TIME' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BATCH' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'IMAGE_SIZE' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'which_data' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'data_path' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'rate_coding' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_init' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_decay' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_threshold' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_reset' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_sg_width' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_conv_kernel_size' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_conv_stride' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_conv_padding' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_trace_const1' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_trace_const2' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'pre_trained' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'convTrue_fcFalse' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'cfg' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'net_print' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'pre_trained_path' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'learning_rate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'epoch_num' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'tdBN_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BN_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'surrogate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BPTT_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'optimizer_what' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'scheduler_name' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'ddp_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'dvs_clipping' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'dvs_duration' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'DFA_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'trace_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'OTTT_input_trace_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'exclude_class' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'merge_polarities' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'denoise_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'extra_train_dataset' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'num_workers' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'chaching_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'pin_memory' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'UDA_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'alpha_uda' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'bias' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'last_lif' was locked by 'sweep' (ignored update).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "param {'devices': '0', 'single_step': True, 'unique_name': 'main', 'my_seed': 42, 'TIME': 10, 'BATCH': 16, 'IMAGE_SIZE': 128, 'which_data': 'DVS_GESTURE_TONIC', 'data_path': '/data2', 'rate_coding': False, 'lif_layer_v_init': 0, 'lif_layer_v_decay': 0.5, 'lif_layer_v_threshold': 0.75, 'lif_layer_v_reset': 10000, 'lif_layer_sg_width': 5, 'synapse_conv_kernel_size': 3, 'synapse_conv_stride': 1, 'synapse_conv_padding': 1, 'synapse_trace_const1': 1, 'synapse_trace_const2': 0, 'pre_trained': False, 'convTrue_fcFalse': False, 'cfg': ['M', 'M', 200, 200], 'net_print': True, 'pre_trained_path': 'net_save/save_now_net_weights_{unique_name}.pth', 'learning_rate': 0.001, 'epoch_num': 100, 'tdBN_on': False, 'BN_on': False, 'surrogate': 'hard_sigmoid', 'BPTT_on': False, 'optimizer_what': 'SGD', 'scheduler_name': 'no', 'ddp_on': False, 'dvs_clipping': 5, 'dvs_duration': 100000, 'DFA_on': False, 'trace_on': True, 'OTTT_input_trace_on': False, 'exclude_class': True, 'merge_polarities': False, 'denoise_on': True, 'extra_train_dataset': 0, 'num_workers': 2, 'chaching_on': True, 'pin_memory': True, 'UDA_on': False, 'alpha_uda': 1, 'bias': True, 'last_lif': False, 'current epoch': 0} \n",
      "\n",
      "dataset_hash = 63cc597115630ec173f3099200061e53\n",
      "cache path exists\n",
      "\n",
      "device ==> cuda\n",
      "\n",
      "DataParallel(\n",
      "  (module): REBORN_MY_SNN_FC(\n",
      "    (layers): REBORN_MY_Sequential(\n",
      "      (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (2): DimChanger_for_FC()\n",
      "      (3): SYNAPSE_FC(in_features=2048, out_features=200, TIME=10, bias=True, sstep=True)\n",
      "      (4): LIF_layer(v_init=0, v_decay=0.5, v_threshold=0.75, v_reset=10000, sg_width=5, surrogate=hard_sigmoid, BPTT_on=False, trace_const1=1, trace_const2=0, TIME=10, sstep=True, trace_on=True)\n",
      "      (5): SYNAPSE_FC(in_features=200, out_features=200, TIME=10, bias=True, sstep=True)\n",
      "      (6): LIF_layer(v_init=0, v_decay=0.5, v_threshold=0.75, v_reset=10000, sg_width=5, surrogate=hard_sigmoid, BPTT_on=False, trace_const1=1, trace_const2=0, TIME=10, sstep=True, trace_on=True)\n",
      "      (7): SYNAPSE_FC(in_features=200, out_features=10, TIME=10, bias=True, sstep=True)\n",
      "    )\n",
      "  )\n",
      ")\n",
      "\n",
      "========================================================\n",
      "Trainable parameters: 452,010\n",
      "========================================================\n",
      "\n",
      "epoch-0   lr=['0.0010000'], tr/val_loss:  2.305365/  2.302841, val:  10.00%, val_best:  10.00%, tr:   8.17%, tr_best:   8.17%\n",
      "epoch-1   lr=['0.0010000'], tr/val_loss:  2.304994/  2.302639, val:  10.00%, val_best:  10.00%, tr:   7.66%, tr_best:   8.17%\n",
      "epoch-2   lr=['0.0010000'], tr/val_loss:  2.305079/  2.302667, val:  10.00%, val_best:  10.00%, tr:   8.99%, tr_best:   8.99%\n",
      "epoch-3   lr=['0.0010000'], tr/val_loss:  2.304731/  2.302708, val:  10.00%, val_best:  10.00%, tr:   8.38%, tr_best:   8.99%\n",
      "epoch-4   lr=['0.0010000'], tr/val_loss:  2.304833/  2.302682, val:  10.00%, val_best:  10.00%, tr:   7.87%, tr_best:   8.99%\n",
      "epoch-5   lr=['0.0010000'], tr/val_loss:  2.304569/  2.302663, val:  10.00%, val_best:  10.00%, tr:   7.87%, tr_best:   8.99%\n",
      "epoch-6   lr=['0.0010000'], tr/val_loss:  2.305086/  2.302687, val:  10.00%, val_best:  10.00%, tr:   9.70%, tr_best:   9.70%\n",
      "epoch-7   lr=['0.0010000'], tr/val_loss:  2.304632/  2.302694, val:  10.00%, val_best:  10.00%, tr:   7.46%, tr_best:   9.70%\n",
      "epoch-8   lr=['0.0010000'], tr/val_loss:  2.304545/  2.302613, val:  10.00%, val_best:  10.00%, tr:   8.17%, tr_best:   9.70%\n",
      "epoch-9   lr=['0.0010000'], tr/val_loss:  2.305080/  2.302782, val:  10.00%, val_best:  10.00%, tr:   9.19%, tr_best:   9.70%\n",
      "epoch-10  lr=['0.0010000'], tr/val_loss:  2.304688/  2.302772, val:  10.00%, val_best:  10.00%, tr:  10.01%, tr_best:  10.01%\n",
      "epoch-11  lr=['0.0010000'], tr/val_loss:  2.304834/  2.302622, val:  10.00%, val_best:  10.00%, tr:   8.17%, tr_best:  10.01%\n",
      "epoch-12  lr=['0.0010000'], tr/val_loss:  2.304284/  2.302666, val:  10.00%, val_best:  10.00%, tr:   9.50%, tr_best:  10.01%\n",
      "epoch-13  lr=['0.0010000'], tr/val_loss:  2.304813/  2.302634, val:  10.00%, val_best:  10.00%, tr:   9.09%, tr_best:  10.01%\n",
      "epoch-14  lr=['0.0010000'], tr/val_loss:  2.305231/  2.302722, val:  10.00%, val_best:  10.00%, tr:   8.78%, tr_best:  10.01%\n",
      "epoch-15  lr=['0.0010000'], tr/val_loss:  2.305301/  2.302723, val:  10.00%, val_best:  10.00%, tr:   8.38%, tr_best:  10.01%\n",
      "epoch-16  lr=['0.0010000'], tr/val_loss:  2.304772/  2.302634, val:  10.00%, val_best:  10.00%, tr:   8.27%, tr_best:  10.01%\n",
      "epoch-17  lr=['0.0010000'], tr/val_loss:  2.303716/  2.302659, val:  10.00%, val_best:  10.00%, tr:  10.01%, tr_best:  10.01%\n",
      "epoch-18  lr=['0.0010000'], tr/val_loss:  2.304624/  2.302669, val:  10.00%, val_best:  10.00%, tr:   9.30%, tr_best:  10.01%\n",
      "epoch-19  lr=['0.0010000'], tr/val_loss:  2.305880/  2.302768, val:  10.00%, val_best:  10.00%, tr:   8.48%, tr_best:  10.01%\n",
      "epoch-20  lr=['0.0010000'], tr/val_loss:  2.305089/  2.302728, val:  10.00%, val_best:  10.00%, tr:   9.60%, tr_best:  10.01%\n",
      "epoch-21  lr=['0.0010000'], tr/val_loss:  2.304662/  2.302646, val:  10.00%, val_best:  10.00%, tr:   9.40%, tr_best:  10.01%\n",
      "epoch-22  lr=['0.0010000'], tr/val_loss:  2.305019/  2.302714, val:  10.00%, val_best:  10.00%, tr:  10.32%, tr_best:  10.32%\n",
      "epoch-23  lr=['0.0010000'], tr/val_loss:  2.304242/  2.302678, val:  10.00%, val_best:  10.00%, tr:   8.68%, tr_best:  10.32%\n",
      "epoch-24  lr=['0.0010000'], tr/val_loss:  2.303980/  2.302631, val:  10.00%, val_best:  10.00%, tr:   7.66%, tr_best:  10.32%\n",
      "epoch-25  lr=['0.0010000'], tr/val_loss:  2.304494/  2.302676, val:  10.00%, val_best:  10.00%, tr:   8.17%, tr_best:  10.32%\n",
      "epoch-26  lr=['0.0010000'], tr/val_loss:  2.304318/  2.302692, val:  10.00%, val_best:  10.00%, tr:   8.38%, tr_best:  10.32%\n",
      "epoch-27  lr=['0.0010000'], tr/val_loss:  2.304585/  2.302743, val:  10.00%, val_best:  10.00%, tr:   7.97%, tr_best:  10.32%\n",
      "epoch-28  lr=['0.0010000'], tr/val_loss:  2.304604/  2.302687, val:  10.00%, val_best:  10.00%, tr:   7.46%, tr_best:  10.32%\n",
      "epoch-29  lr=['0.0010000'], tr/val_loss:  2.304065/  2.302622, val:  10.00%, val_best:  10.00%, tr:   9.70%, tr_best:  10.32%\n",
      "epoch-30  lr=['0.0010000'], tr/val_loss:  2.304437/  2.302634, val:  10.00%, val_best:  10.00%, tr:   7.87%, tr_best:  10.32%\n",
      "epoch-31  lr=['0.0010000'], tr/val_loss:  2.304662/  2.302706, val:  10.00%, val_best:  10.00%, tr:   7.25%, tr_best:  10.32%\n",
      "epoch-32  lr=['0.0010000'], tr/val_loss:  2.305145/  2.302731, val:  10.00%, val_best:  10.00%, tr:   7.87%, tr_best:  10.32%\n",
      "epoch-33  lr=['0.0010000'], tr/val_loss:  2.304735/  2.302727, val:  10.00%, val_best:  10.00%, tr:   8.58%, tr_best:  10.32%\n",
      "epoch-34  lr=['0.0010000'], tr/val_loss:  2.304953/  2.302632, val:  10.00%, val_best:  10.00%, tr:   8.78%, tr_best:  10.32%\n",
      "epoch-35  lr=['0.0010000'], tr/val_loss:  2.304517/  2.302745, val:  10.00%, val_best:  10.00%, tr:   9.40%, tr_best:  10.32%\n",
      "epoch-36  lr=['0.0010000'], tr/val_loss:  2.304946/  2.302701, val:  10.00%, val_best:  10.00%, tr:   8.68%, tr_best:  10.32%\n",
      "epoch-37  lr=['0.0010000'], tr/val_loss:  2.305197/  2.302687, val:  10.00%, val_best:  10.00%, tr:   8.89%, tr_best:  10.32%\n",
      "epoch-38  lr=['0.0010000'], tr/val_loss:  2.304106/  2.302715, val:  10.00%, val_best:  10.00%, tr:   8.99%, tr_best:  10.32%\n",
      "epoch-39  lr=['0.0010000'], tr/val_loss:  2.304535/  2.302683, val:  10.00%, val_best:  10.00%, tr:   9.40%, tr_best:  10.32%\n",
      "epoch-40  lr=['0.0010000'], tr/val_loss:  2.304653/  2.302674, val:  10.00%, val_best:  10.00%, tr:   8.99%, tr_best:  10.32%\n",
      "epoch-41  lr=['0.0010000'], tr/val_loss:  2.304348/  2.302677, val:  10.00%, val_best:  10.00%, tr:   9.60%, tr_best:  10.32%\n",
      "epoch-42  lr=['0.0010000'], tr/val_loss:  2.304514/  2.302729, val:  10.00%, val_best:  10.00%, tr:   9.19%, tr_best:  10.32%\n",
      "epoch-43  lr=['0.0010000'], tr/val_loss:  2.304611/  2.302673, val:  10.00%, val_best:  10.00%, tr:   8.89%, tr_best:  10.32%\n",
      "epoch-44  lr=['0.0010000'], tr/val_loss:  2.304545/  2.302760, val:  10.00%, val_best:  10.00%, tr:   8.17%, tr_best:  10.32%\n",
      "epoch-45  lr=['0.0010000'], tr/val_loss:  2.304274/  2.302822, val:  10.00%, val_best:  10.00%, tr:   9.30%, tr_best:  10.32%\n",
      "epoch-46  lr=['0.0010000'], tr/val_loss:  2.304114/  2.302626, val:  10.00%, val_best:  10.00%, tr:   9.09%, tr_best:  10.32%\n",
      "epoch-47  lr=['0.0010000'], tr/val_loss:  2.304720/  2.302717, val:  10.00%, val_best:  10.00%, tr:   8.48%, tr_best:  10.32%\n",
      "epoch-48  lr=['0.0010000'], tr/val_loss:  2.304052/  2.302806, val:  10.00%, val_best:  10.00%, tr:   9.81%, tr_best:  10.32%\n",
      "epoch-49  lr=['0.0010000'], tr/val_loss:  2.304631/  2.302734, val:  10.00%, val_best:  10.00%, tr:   9.60%, tr_best:  10.32%\n",
      "epoch-50  lr=['0.0010000'], tr/val_loss:  2.304856/  2.302790, val:  10.00%, val_best:  10.00%, tr:  10.11%, tr_best:  10.32%\n",
      "epoch-51  lr=['0.0010000'], tr/val_loss:  2.303980/  2.302723, val:  10.00%, val_best:  10.00%, tr:   8.38%, tr_best:  10.32%\n",
      "epoch-52  lr=['0.0010000'], tr/val_loss:  2.305447/  2.302761, val:  10.00%, val_best:  10.00%, tr:   7.87%, tr_best:  10.32%\n",
      "epoch-53  lr=['0.0010000'], tr/val_loss:  2.304740/  2.302716, val:  10.00%, val_best:  10.00%, tr:   8.48%, tr_best:  10.32%\n",
      "epoch-54  lr=['0.0010000'], tr/val_loss:  2.304604/  2.302668, val:  10.00%, val_best:  10.00%, tr:   9.40%, tr_best:  10.32%\n",
      "epoch-55  lr=['0.0010000'], tr/val_loss:  2.304554/  2.302632, val:  10.00%, val_best:  10.00%, tr:   7.35%, tr_best:  10.32%\n",
      "epoch-56  lr=['0.0010000'], tr/val_loss:  2.305324/  2.302709, val:  10.00%, val_best:  10.00%, tr:  10.01%, tr_best:  10.32%\n",
      "epoch-57  lr=['0.0010000'], tr/val_loss:  2.304349/  2.302676, val:  10.00%, val_best:  10.00%, tr:   8.07%, tr_best:  10.32%\n",
      "epoch-58  lr=['0.0010000'], tr/val_loss:  2.304797/  2.302742, val:  10.00%, val_best:  10.00%, tr:   9.40%, tr_best:  10.32%\n",
      "epoch-59  lr=['0.0010000'], tr/val_loss:  2.305519/  2.302842, val:  10.00%, val_best:  10.00%, tr:   9.50%, tr_best:  10.32%\n",
      "epoch-60  lr=['0.0010000'], tr/val_loss:  2.304214/  2.302650, val:  10.00%, val_best:  10.00%, tr:   7.87%, tr_best:  10.32%\n",
      "epoch-61  lr=['0.0010000'], tr/val_loss:  2.304307/  2.302675, val:  10.00%, val_best:  10.00%, tr:   9.09%, tr_best:  10.32%\n",
      "epoch-62  lr=['0.0010000'], tr/val_loss:  2.304764/  2.302663, val:  10.00%, val_best:  10.00%, tr:   8.99%, tr_best:  10.32%\n",
      "epoch-63  lr=['0.0010000'], tr/val_loss:  2.304623/  2.302703, val:  10.00%, val_best:  10.00%, tr:   9.30%, tr_best:  10.32%\n",
      "epoch-64  lr=['0.0010000'], tr/val_loss:  2.303885/  2.302848, val:  10.00%, val_best:  10.00%, tr:   9.09%, tr_best:  10.32%\n",
      "epoch-65  lr=['0.0010000'], tr/val_loss:  2.304417/  2.302755, val:  10.00%, val_best:  10.00%, tr:   9.30%, tr_best:  10.32%\n",
      "epoch-66  lr=['0.0010000'], tr/val_loss:  2.303841/  2.302698, val:  10.00%, val_best:  10.00%, tr:   9.09%, tr_best:  10.32%\n",
      "epoch-67  lr=['0.0010000'], tr/val_loss:  2.305081/  2.302692, val:  10.00%, val_best:  10.00%, tr:  10.01%, tr_best:  10.32%\n",
      "epoch-68  lr=['0.0010000'], tr/val_loss:  2.305073/  2.302701, val:  10.00%, val_best:  10.00%, tr:   9.30%, tr_best:  10.32%\n",
      "epoch-69  lr=['0.0010000'], tr/val_loss:  2.304717/  2.302645, val:  10.00%, val_best:  10.00%, tr:   8.99%, tr_best:  10.32%\n",
      "epoch-70  lr=['0.0010000'], tr/val_loss:  2.305171/  2.302620, val:  10.00%, val_best:  10.00%, tr:   8.38%, tr_best:  10.32%\n",
      "epoch-71  lr=['0.0010000'], tr/val_loss:  2.305242/  2.302688, val:  10.00%, val_best:  10.00%, tr:   8.48%, tr_best:  10.32%\n",
      "epoch-72  lr=['0.0010000'], tr/val_loss:  2.304678/  2.302624, val:  10.00%, val_best:  10.00%, tr:   8.58%, tr_best:  10.32%\n",
      "epoch-73  lr=['0.0010000'], tr/val_loss:  2.304676/  2.302652, val:  10.00%, val_best:  10.00%, tr:   8.48%, tr_best:  10.32%\n",
      "epoch-74  lr=['0.0010000'], tr/val_loss:  2.304883/  2.302660, val:  10.00%, val_best:  10.00%, tr:   9.30%, tr_best:  10.32%\n",
      "epoch-75  lr=['0.0010000'], tr/val_loss:  2.305337/  2.302700, val:  10.00%, val_best:  10.00%, tr:   9.19%, tr_best:  10.32%\n",
      "epoch-76  lr=['0.0010000'], tr/val_loss:  2.305019/  2.302656, val:  10.00%, val_best:  10.00%, tr:   8.17%, tr_best:  10.32%\n",
      "epoch-77  lr=['0.0010000'], tr/val_loss:  2.305215/  2.302638, val:  10.00%, val_best:  10.00%, tr:   8.89%, tr_best:  10.32%\n",
      "epoch-78  lr=['0.0010000'], tr/val_loss:  2.304676/  2.302660, val:  10.00%, val_best:  10.00%, tr:   9.09%, tr_best:  10.32%\n",
      "epoch-79  lr=['0.0010000'], tr/val_loss:  2.304999/  2.302665, val:  10.00%, val_best:  10.00%, tr:   9.81%, tr_best:  10.32%\n",
      "epoch-80  lr=['0.0010000'], tr/val_loss:  2.304617/  2.302732, val:  10.00%, val_best:  10.00%, tr:   7.35%, tr_best:  10.32%\n",
      "epoch-81  lr=['0.0010000'], tr/val_loss:  2.304430/  2.302707, val:  10.00%, val_best:  10.00%, tr:   7.66%, tr_best:  10.32%\n",
      "epoch-82  lr=['0.0010000'], tr/val_loss:  2.304436/  2.302796, val:  10.00%, val_best:  10.00%, tr:   9.30%, tr_best:  10.32%\n",
      "epoch-83  lr=['0.0010000'], tr/val_loss:  2.305023/  2.302669, val:  10.00%, val_best:  10.00%, tr:   7.66%, tr_best:  10.32%\n",
      "epoch-84  lr=['0.0010000'], tr/val_loss:  2.304577/  2.302758, val:  10.00%, val_best:  10.00%, tr:   8.89%, tr_best:  10.32%\n",
      "epoch-85  lr=['0.0010000'], tr/val_loss:  2.304359/  2.302626, val:  10.00%, val_best:  10.00%, tr:   8.07%, tr_best:  10.32%\n",
      "epoch-86  lr=['0.0010000'], tr/val_loss:  2.305443/  2.302771, val:  10.00%, val_best:  10.00%, tr:   8.17%, tr_best:  10.32%\n",
      "epoch-87  lr=['0.0010000'], tr/val_loss:  2.304418/  2.302737, val:  10.00%, val_best:  10.00%, tr:   8.78%, tr_best:  10.32%\n",
      "epoch-88  lr=['0.0010000'], tr/val_loss:  2.305364/  2.302662, val:  10.00%, val_best:  10.00%, tr:   8.68%, tr_best:  10.32%\n",
      "epoch-89  lr=['0.0010000'], tr/val_loss:  2.304665/  2.302694, val:  10.00%, val_best:  10.00%, tr:   8.89%, tr_best:  10.32%\n",
      "epoch-90  lr=['0.0010000'], tr/val_loss:  2.305019/  2.302693, val:  10.00%, val_best:  10.00%, tr:   8.38%, tr_best:  10.32%\n",
      "epoch-91  lr=['0.0010000'], tr/val_loss:  2.304266/  2.302669, val:  10.00%, val_best:  10.00%, tr:  10.21%, tr_best:  10.32%\n",
      "epoch-92  lr=['0.0010000'], tr/val_loss:  2.304705/  2.302684, val:  10.00%, val_best:  10.00%, tr:   9.40%, tr_best:  10.32%\n",
      "epoch-93  lr=['0.0010000'], tr/val_loss:  2.304860/  2.302634, val:  10.00%, val_best:  10.00%, tr:   8.68%, tr_best:  10.32%\n",
      "epoch-94  lr=['0.0010000'], tr/val_loss:  2.304419/  2.302675, val:  10.00%, val_best:  10.00%, tr:   8.89%, tr_best:  10.32%\n",
      "epoch-95  lr=['0.0010000'], tr/val_loss:  2.304308/  2.302676, val:  10.00%, val_best:  10.00%, tr:   8.17%, tr_best:  10.32%\n",
      "epoch-96  lr=['0.0010000'], tr/val_loss:  2.304734/  2.302685, val:  10.00%, val_best:  10.00%, tr:  10.11%, tr_best:  10.32%\n",
      "epoch-97  lr=['0.0010000'], tr/val_loss:  2.304735/  2.302724, val:  10.00%, val_best:  10.00%, tr:   9.09%, tr_best:  10.32%\n",
      "epoch-98  lr=['0.0010000'], tr/val_loss:  2.305681/  2.302760, val:  10.00%, val_best:  10.00%, tr:  10.11%, tr_best:  10.32%\n",
      "epoch-99  lr=['0.0010000'], tr/val_loss:  2.304706/  2.302780, val:  10.00%, val_best:  10.00%, tr:   9.50%, tr_best:  10.32%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ecf6c294056d439288364dc9966cac48",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.006 MB of 0.006 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>iter_acc</td><td>▃▆▁▃▃▃▃▃▃▃▃▁▃▆▃▆▆▃██▃▃▁▃▁▃▁▃▃▁▃▆▃▁▁▁█▃▁▃</td></tr><tr><td>summary_val_acc</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>tr_acc</td><td>▃▅▂▁▆▇▅█▄▆▂▄▇▂▆▅▆▆▃▄▇▂▆▃▇▅▆█▄▄▆▅▇▆▅▅▅▆▃▅</td></tr><tr><td>tr_epoch_loss</td><td>▆▅▅▄▅▃▆▁█▄▂▃▂▆▄▆▄▄▄▄▄▇▄▃▇▃▃▅▆▄▆▆▅▃▄▃▄▄▃▄</td></tr><tr><td>val_acc_best</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_acc_now</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_loss</td><td>█▂▃▃▆▂▄▂▆▂▁▃▁▅▅▃▃▄▅▄▅▅▃▃█▃▅▃▁▁▄▂▂▇▅▅▃▃▃▄</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>99</td></tr><tr><td>iter_acc</td><td>0.0</td></tr><tr><td>tr_acc</td><td>0.09499</td></tr><tr><td>tr_epoch_loss</td><td>2.30471</td></tr><tr><td>val_acc_best</td><td>0.1</td></tr><tr><td>val_acc_now</td><td>0.1</td></tr><tr><td>val_loss</td><td>2.30278</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">fast-sweep-168</strong> at: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/dmt2o6sn' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/dmt2o6sn</a><br/> View project at: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>/data2/bh_wandb/wandb/run-20250430_040516-dmt2o6sn/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require(\"core\")`! See https://wandb.me/wandb-core for more information."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: kaq4q9qx with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBATCH: 16\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBN_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBPTT_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tDFA_on: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tIMAGE_SIZE: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tOTTT_input_trace_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tTIME: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tUDA_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \talpha_uda: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbias: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcfg: ['M', 'M', 200, 200]\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tchaching_on: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tconvTrue_fcFalse: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdata_path: /data2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tddp_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdenoise_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdvs_clipping: 5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdvs_duration: 100000\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepoch_num: 100\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \texclude_class: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \textra_train_dataset: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlast_lif: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.001\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_sg_width: 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_decay: 0.5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_init: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_reset: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_threshold: 0.25\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmerge_polarities: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmy_seed: 42\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnet_print: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_workers: 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer_what: SGD\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tpin_memory: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tpre_trained: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tpre_trained_path: net_save/save_now_net_weights_{unique_name}.pth\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \trate_coding: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tscheduler_name: no\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsingle_step: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsurrogate: hard_sigmoid\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_conv_kernel_size: 3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_conv_padding: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_conv_stride: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_trace_const1: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_trace_const2: 0.5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \ttdBN_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \ttrace_on: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \twhich_data: DVS_GESTURE_TONIC\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.19.10 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.17.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/data2/bh_wandb/wandb/run-20250430_041118-kaq4q9qx</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/kaq4q9qx' target=\"_blank\">radiant-sweep-170</a></strong> to <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/6pj3lh8j' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/6pj3lh8j</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/6pj3lh8j' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/6pj3lh8j</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/kaq4q9qx' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/kaq4q9qx</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'single_step' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'my_seed' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'TIME' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BATCH' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'IMAGE_SIZE' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'which_data' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'data_path' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'rate_coding' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_init' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_decay' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_threshold' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_reset' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_sg_width' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_conv_kernel_size' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_conv_stride' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_conv_padding' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_trace_const1' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_trace_const2' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'pre_trained' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'convTrue_fcFalse' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'cfg' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'net_print' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'pre_trained_path' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'learning_rate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'epoch_num' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'tdBN_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BN_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'surrogate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BPTT_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'optimizer_what' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'scheduler_name' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'ddp_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'dvs_clipping' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'dvs_duration' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'DFA_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'trace_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'OTTT_input_trace_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'exclude_class' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'merge_polarities' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'denoise_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'extra_train_dataset' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'num_workers' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'chaching_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'pin_memory' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'UDA_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'alpha_uda' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'bias' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'last_lif' was locked by 'sweep' (ignored update).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "param {'devices': '0', 'single_step': True, 'unique_name': 'main', 'my_seed': 42, 'TIME': 10, 'BATCH': 16, 'IMAGE_SIZE': 128, 'which_data': 'DVS_GESTURE_TONIC', 'data_path': '/data2', 'rate_coding': False, 'lif_layer_v_init': 0, 'lif_layer_v_decay': 0.5, 'lif_layer_v_threshold': 0.25, 'lif_layer_v_reset': 0, 'lif_layer_sg_width': 2, 'synapse_conv_kernel_size': 3, 'synapse_conv_stride': 1, 'synapse_conv_padding': 1, 'synapse_trace_const1': 1, 'synapse_trace_const2': 0.5, 'pre_trained': False, 'convTrue_fcFalse': False, 'cfg': ['M', 'M', 200, 200], 'net_print': True, 'pre_trained_path': 'net_save/save_now_net_weights_{unique_name}.pth', 'learning_rate': 0.001, 'epoch_num': 100, 'tdBN_on': False, 'BN_on': False, 'surrogate': 'hard_sigmoid', 'BPTT_on': False, 'optimizer_what': 'SGD', 'scheduler_name': 'no', 'ddp_on': False, 'dvs_clipping': 5, 'dvs_duration': 100000, 'DFA_on': True, 'trace_on': True, 'OTTT_input_trace_on': False, 'exclude_class': True, 'merge_polarities': False, 'denoise_on': False, 'extra_train_dataset': 0, 'num_workers': 2, 'chaching_on': True, 'pin_memory': True, 'UDA_on': False, 'alpha_uda': 1, 'bias': True, 'last_lif': False, 'current epoch': 0} \n",
      "\n",
      "dataset_hash = ffa516e60c3efd5e0208f72b4c36cb84\n",
      "cache path exists\n",
      "\n",
      "device ==> cuda\n",
      "\n",
      "DataParallel(\n",
      "  (module): REBORN_MY_SNN_FC(\n",
      "    (layers): REBORN_MY_Sequential(\n",
      "      (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (2): DimChanger_for_FC()\n",
      "      (3): SYNAPSE_FC(in_features=2048, out_features=200, TIME=10, bias=True, sstep=True)\n",
      "      (4): LIF_layer(v_init=0, v_decay=0.5, v_threshold=0.25, v_reset=0, sg_width=2, surrogate=hard_sigmoid, BPTT_on=False, trace_const1=1, trace_const2=0.5, TIME=10, sstep=True, trace_on=True)\n",
      "      (5): Feedback_Receiver()\n",
      "      (6): SYNAPSE_FC(in_features=200, out_features=200, TIME=10, bias=True, sstep=True)\n",
      "      (7): LIF_layer(v_init=0, v_decay=0.5, v_threshold=0.25, v_reset=0, sg_width=2, surrogate=hard_sigmoid, BPTT_on=False, trace_const1=1, trace_const2=0.5, TIME=10, sstep=True, trace_on=True)\n",
      "      (8): Feedback_Receiver()\n",
      "      (9): SYNAPSE_FC(in_features=200, out_features=10, TIME=10, bias=True, sstep=True)\n",
      "      (DFA_top): Top_Gradient()\n",
      "    )\n",
      "  )\n",
      ")\n",
      "\n",
      "========================================================\n",
      "Trainable parameters: 452,010\n",
      "========================================================\n",
      "\n",
      "epoch-0   lr=['0.0010000'], tr/val_loss:  2.007849/  1.565417, val:  43.75%, val_best:  43.75%, tr:  25.03%, tr_best:  25.03%\n",
      "[module.layers.5] weight_fb parameter count: 2,000\n",
      "[module.layers.8] weight_fb parameter count: 2,000\n",
      "epoch-1   lr=['0.0010000'], tr/val_loss:  1.323269/  1.429568, val:  51.67%, val_best:  51.67%, tr:  54.34%, tr_best:  54.34%\n",
      "epoch-2   lr=['0.0010000'], tr/val_loss:  1.173709/  1.400553, val:  54.58%, val_best:  54.58%, tr:  58.73%, tr_best:  58.73%\n",
      "epoch-3   lr=['0.0010000'], tr/val_loss:  1.036636/  1.405511, val:  57.50%, val_best:  57.50%, tr:  65.58%, tr_best:  65.58%\n",
      "epoch-4   lr=['0.0010000'], tr/val_loss:  0.970302/  1.303158, val:  59.58%, val_best:  59.58%, tr:  67.93%, tr_best:  67.93%\n",
      "epoch-5   lr=['0.0010000'], tr/val_loss:  0.928441/  1.256284, val:  65.00%, val_best:  65.00%, tr:  69.66%, tr_best:  69.66%\n",
      "epoch-6   lr=['0.0010000'], tr/val_loss:  0.861428/  1.253414, val:  62.50%, val_best:  65.00%, tr:  73.44%, tr_best:  73.44%\n",
      "epoch-7   lr=['0.0010000'], tr/val_loss:  0.836347/  1.306047, val:  65.83%, val_best:  65.83%, tr:  74.06%, tr_best:  74.06%\n",
      "epoch-8   lr=['0.0010000'], tr/val_loss:  0.805460/  1.322491, val:  67.08%, val_best:  67.08%, tr:  75.08%, tr_best:  75.08%\n",
      "epoch-9   lr=['0.0010000'], tr/val_loss:  0.768022/  1.416504, val:  59.58%, val_best:  67.08%, tr:  80.18%, tr_best:  80.18%\n",
      "epoch-10  lr=['0.0010000'], tr/val_loss:  0.744346/  1.486244, val:  60.42%, val_best:  67.08%, tr:  80.80%, tr_best:  80.80%\n",
      "epoch-11  lr=['0.0010000'], tr/val_loss:  0.669890/  1.329080, val:  70.00%, val_best:  70.00%, tr:  83.96%, tr_best:  83.96%\n",
      "epoch-12  lr=['0.0010000'], tr/val_loss:  0.646208/  1.378895, val:  70.42%, val_best:  70.42%, tr:  88.05%, tr_best:  88.05%\n",
      "epoch-13  lr=['0.0010000'], tr/val_loss:  0.606187/  1.414698, val:  69.17%, val_best:  70.42%, tr:  90.30%, tr_best:  90.30%\n",
      "epoch-14  lr=['0.0010000'], tr/val_loss:  0.567097/  1.579422, val:  65.00%, val_best:  70.42%, tr:  90.40%, tr_best:  90.40%\n",
      "epoch-15  lr=['0.0010000'], tr/val_loss:  0.537657/  1.572292, val:  65.42%, val_best:  70.42%, tr:  92.75%, tr_best:  92.75%\n",
      "epoch-16  lr=['0.0010000'], tr/val_loss:  0.539513/  1.532057, val:  67.50%, val_best:  70.42%, tr:  93.77%, tr_best:  93.77%\n",
      "epoch-17  lr=['0.0010000'], tr/val_loss:  0.498677/  1.614767, val:  68.75%, val_best:  70.42%, tr:  95.71%, tr_best:  95.71%\n",
      "epoch-18  lr=['0.0010000'], tr/val_loss:  0.491463/  1.765510, val:  63.33%, val_best:  70.42%, tr:  95.81%, tr_best:  95.81%\n",
      "epoch-19  lr=['0.0010000'], tr/val_loss:  0.483969/  1.753350, val:  67.08%, val_best:  70.42%, tr:  94.28%, tr_best:  95.81%\n",
      "epoch-20  lr=['0.0010000'], tr/val_loss:  0.461769/  1.828582, val:  62.08%, val_best:  70.42%, tr:  95.91%, tr_best:  95.91%\n",
      "epoch-21  lr=['0.0010000'], tr/val_loss:  0.444924/  1.824708, val:  65.83%, val_best:  70.42%, tr:  96.53%, tr_best:  96.53%\n",
      "epoch-22  lr=['0.0010000'], tr/val_loss:  0.440916/  1.948393, val:  62.50%, val_best:  70.42%, tr:  97.14%, tr_best:  97.14%\n",
      "epoch-23  lr=['0.0010000'], tr/val_loss:  0.416775/  1.950535, val:  65.00%, val_best:  70.42%, tr:  96.83%, tr_best:  97.14%\n",
      "epoch-24  lr=['0.0010000'], tr/val_loss:  0.399946/  1.958265, val:  65.42%, val_best:  70.42%, tr:  98.47%, tr_best:  98.47%\n",
      "epoch-25  lr=['0.0010000'], tr/val_loss:  0.375480/  1.995910, val:  68.75%, val_best:  70.42%, tr:  98.67%, tr_best:  98.67%\n",
      "epoch-26  lr=['0.0010000'], tr/val_loss:  0.403844/  2.093623, val:  66.67%, val_best:  70.42%, tr:  96.83%, tr_best:  98.67%\n",
      "epoch-27  lr=['0.0010000'], tr/val_loss:  0.368805/  2.186205, val:  62.92%, val_best:  70.42%, tr:  98.57%, tr_best:  98.67%\n",
      "epoch-28  lr=['0.0010000'], tr/val_loss:  0.353746/  2.171611, val:  69.58%, val_best:  70.42%, tr:  99.39%, tr_best:  99.39%\n",
      "epoch-29  lr=['0.0010000'], tr/val_loss:  0.334615/  2.291924, val:  63.75%, val_best:  70.42%, tr:  99.28%, tr_best:  99.39%\n",
      "epoch-30  lr=['0.0010000'], tr/val_loss:  0.334122/  2.299945, val:  69.17%, val_best:  70.42%, tr:  99.18%, tr_best:  99.39%\n",
      "epoch-31  lr=['0.0010000'], tr/val_loss:  0.321587/  2.362353, val:  65.83%, val_best:  70.42%, tr:  98.98%, tr_best:  99.39%\n",
      "epoch-32  lr=['0.0010000'], tr/val_loss:  0.322405/  2.365868, val:  69.17%, val_best:  70.42%, tr:  99.18%, tr_best:  99.39%\n",
      "epoch-33  lr=['0.0010000'], tr/val_loss:  0.311590/  2.399657, val:  65.42%, val_best:  70.42%, tr:  99.59%, tr_best:  99.59%\n",
      "epoch-34  lr=['0.0010000'], tr/val_loss:  0.293704/  2.524293, val:  65.83%, val_best:  70.42%, tr:  99.69%, tr_best:  99.69%\n",
      "epoch-35  lr=['0.0010000'], tr/val_loss:  0.309601/  2.526775, val:  66.67%, val_best:  70.42%, tr:  99.49%, tr_best:  99.69%\n",
      "epoch-36  lr=['0.0010000'], tr/val_loss:  0.288224/  2.536476, val:  66.25%, val_best:  70.42%, tr:  99.39%, tr_best:  99.69%\n",
      "epoch-37  lr=['0.0010000'], tr/val_loss:  0.263717/  2.614729, val:  64.58%, val_best:  70.42%, tr:  99.80%, tr_best:  99.80%\n",
      "epoch-38  lr=['0.0010000'], tr/val_loss:  0.270008/  2.624046, val:  65.00%, val_best:  70.42%, tr:  99.59%, tr_best:  99.80%\n",
      "epoch-39  lr=['0.0010000'], tr/val_loss:  0.261669/  2.688289, val:  65.83%, val_best:  70.42%, tr:  99.59%, tr_best:  99.80%\n",
      "epoch-40  lr=['0.0010000'], tr/val_loss:  0.264950/  2.775618, val:  68.33%, val_best:  70.42%, tr:  99.69%, tr_best:  99.80%\n",
      "epoch-41  lr=['0.0010000'], tr/val_loss:  0.258720/  2.788832, val:  64.17%, val_best:  70.42%, tr:  99.69%, tr_best:  99.80%\n",
      "epoch-42  lr=['0.0010000'], tr/val_loss:  0.242871/  2.798048, val:  67.92%, val_best:  70.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-43  lr=['0.0010000'], tr/val_loss:  0.260693/  2.903164, val:  66.25%, val_best:  70.42%, tr:  99.90%, tr_best: 100.00%\n",
      "epoch-44  lr=['0.0010000'], tr/val_loss:  0.242125/  2.964726, val:  67.08%, val_best:  70.42%, tr:  99.69%, tr_best: 100.00%\n",
      "epoch-45  lr=['0.0010000'], tr/val_loss:  0.232564/  2.963949, val:  67.08%, val_best:  70.42%, tr:  99.90%, tr_best: 100.00%\n",
      "epoch-46  lr=['0.0010000'], tr/val_loss:  0.235766/  2.995975, val:  65.00%, val_best:  70.42%, tr:  99.90%, tr_best: 100.00%\n",
      "epoch-47  lr=['0.0010000'], tr/val_loss:  0.225573/  3.150798, val:  65.00%, val_best:  70.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-48  lr=['0.0010000'], tr/val_loss:  0.238496/  3.039989, val:  68.33%, val_best:  70.42%, tr:  99.80%, tr_best: 100.00%\n",
      "epoch-49  lr=['0.0010000'], tr/val_loss:  0.242544/  3.205051, val:  67.08%, val_best:  70.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-50  lr=['0.0010000'], tr/val_loss:  0.209145/  3.268563, val:  63.75%, val_best:  70.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-51  lr=['0.0010000'], tr/val_loss:  0.225158/  3.221506, val:  66.25%, val_best:  70.42%, tr:  99.80%, tr_best: 100.00%\n",
      "epoch-52  lr=['0.0010000'], tr/val_loss:  0.202298/  3.317571, val:  64.58%, val_best:  70.42%, tr:  99.80%, tr_best: 100.00%\n",
      "epoch-53  lr=['0.0010000'], tr/val_loss:  0.191598/  3.337388, val:  65.00%, val_best:  70.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-54  lr=['0.0010000'], tr/val_loss:  0.184830/  3.405065, val:  65.42%, val_best:  70.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-55  lr=['0.0010000'], tr/val_loss:  0.185530/  3.464525, val:  63.75%, val_best:  70.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-56  lr=['0.0010000'], tr/val_loss:  0.189409/  3.502273, val:  65.42%, val_best:  70.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-57  lr=['0.0010000'], tr/val_loss:  0.187915/  3.549896, val:  63.33%, val_best:  70.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-58  lr=['0.0010000'], tr/val_loss:  0.176732/  3.600696, val:  67.50%, val_best:  70.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-59  lr=['0.0010000'], tr/val_loss:  0.174016/  3.684161, val:  65.42%, val_best:  70.42%, tr:  99.90%, tr_best: 100.00%\n",
      "epoch-60  lr=['0.0010000'], tr/val_loss:  0.163204/  3.649122, val:  64.58%, val_best:  70.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-61  lr=['0.0010000'], tr/val_loss:  0.158698/  3.731511, val:  64.58%, val_best:  70.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-62  lr=['0.0010000'], tr/val_loss:  0.162408/  3.728475, val:  64.17%, val_best:  70.42%, tr:  99.90%, tr_best: 100.00%\n",
      "epoch-63  lr=['0.0010000'], tr/val_loss:  0.157262/  3.812711, val:  64.17%, val_best:  70.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-64  lr=['0.0010000'], tr/val_loss:  0.175734/  3.844702, val:  65.00%, val_best:  70.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-65  lr=['0.0010000'], tr/val_loss:  0.152366/  3.850598, val:  65.42%, val_best:  70.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-66  lr=['0.0010000'], tr/val_loss:  0.156215/  3.892855, val:  65.00%, val_best:  70.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-67  lr=['0.0010000'], tr/val_loss:  0.154331/  3.954949, val:  62.92%, val_best:  70.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-68  lr=['0.0010000'], tr/val_loss:  0.156970/  4.056862, val:  63.75%, val_best:  70.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-69  lr=['0.0010000'], tr/val_loss:  0.183809/  3.969005, val:  65.00%, val_best:  70.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-70  lr=['0.0010000'], tr/val_loss:  0.147863/  4.077610, val:  64.58%, val_best:  70.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-71  lr=['0.0010000'], tr/val_loss:  0.160372/  4.054020, val:  66.25%, val_best:  70.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-72  lr=['0.0010000'], tr/val_loss:  0.150239/  4.171999, val:  65.00%, val_best:  70.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-73  lr=['0.0010000'], tr/val_loss:  0.155237/  4.144114, val:  63.33%, val_best:  70.42%, tr:  99.90%, tr_best: 100.00%\n",
      "epoch-74  lr=['0.0010000'], tr/val_loss:  0.142051/  4.176569, val:  65.83%, val_best:  70.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-75  lr=['0.0010000'], tr/val_loss:  0.148744/  4.203733, val:  64.17%, val_best:  70.42%, tr:  99.90%, tr_best: 100.00%\n",
      "epoch-76  lr=['0.0010000'], tr/val_loss:  0.161937/  4.255033, val:  64.17%, val_best:  70.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-77  lr=['0.0010000'], tr/val_loss:  0.150938/  4.327878, val:  62.50%, val_best:  70.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-78  lr=['0.0010000'], tr/val_loss:  0.139610/  4.340270, val:  65.42%, val_best:  70.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-79  lr=['0.0010000'], tr/val_loss:  0.126764/  4.405076, val:  65.00%, val_best:  70.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-80  lr=['0.0010000'], tr/val_loss:  0.127919/  4.461441, val:  62.92%, val_best:  70.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-81  lr=['0.0010000'], tr/val_loss:  0.139615/  4.435988, val:  61.67%, val_best:  70.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-82  lr=['0.0010000'], tr/val_loss:  0.143295/  4.514951, val:  64.58%, val_best:  70.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-83  lr=['0.0010000'], tr/val_loss:  0.132169/  4.514896, val:  66.67%, val_best:  70.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-84  lr=['0.0010000'], tr/val_loss:  0.143847/  4.481551, val:  65.83%, val_best:  70.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-85  lr=['0.0010000'], tr/val_loss:  0.137505/  4.529276, val:  63.33%, val_best:  70.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-86  lr=['0.0010000'], tr/val_loss:  0.136991/  4.590755, val:  64.17%, val_best:  70.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-87  lr=['0.0010000'], tr/val_loss:  0.143691/  4.633200, val:  63.33%, val_best:  70.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-88  lr=['0.0010000'], tr/val_loss:  0.134788/  4.644016, val:  62.08%, val_best:  70.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-89  lr=['0.0010000'], tr/val_loss:  0.137480/  4.649119, val:  64.17%, val_best:  70.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-90  lr=['0.0010000'], tr/val_loss:  0.130925/  4.668377, val:  65.00%, val_best:  70.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-91  lr=['0.0010000'], tr/val_loss:  0.127290/  4.753328, val:  63.33%, val_best:  70.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-92  lr=['0.0010000'], tr/val_loss:  0.120203/  4.760028, val:  61.25%, val_best:  70.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-93  lr=['0.0010000'], tr/val_loss:  0.130869/  4.769228, val:  63.33%, val_best:  70.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-94  lr=['0.0010000'], tr/val_loss:  0.135882/  4.856189, val:  64.17%, val_best:  70.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-95  lr=['0.0010000'], tr/val_loss:  0.143449/  4.871269, val:  63.75%, val_best:  70.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-96  lr=['0.0010000'], tr/val_loss:  0.143305/  4.943291, val:  63.33%, val_best:  70.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-97  lr=['0.0010000'], tr/val_loss:  0.127994/  4.900231, val:  63.75%, val_best:  70.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-98  lr=['0.0010000'], tr/val_loss:  0.131795/  4.882963, val:  63.33%, val_best:  70.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-99  lr=['0.0010000'], tr/val_loss:  0.157396/  4.994504, val:  64.17%, val_best:  70.42%, tr: 100.00%, tr_best: 100.00%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6a6b9260934f43c7b634699053bfadba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.006 MB of 0.006 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>iter_acc</td><td>▁▇▃▃▃▇▆▆▇█████▇█████████████████████████</td></tr><tr><td>summary_val_acc</td><td>▁▄▅▇▅█▇█▇▇▇▇▆█▇▆▇▇▇▇▇▆▇▆▇▆▇▆▆▇▆▆▇▆▇▆▆▆▆▆</td></tr><tr><td>tr_acc</td><td>▁▄▅▆▆▇▇█▇███████████████████████████████</td></tr><tr><td>tr_epoch_loss</td><td>█▅▄▄▃▃▃▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_acc_best</td><td>▁▄▅▇▇███████████████████████████████████</td></tr><tr><td>val_acc_now</td><td>▁▄▅▇▅█▇█▇▇▇▇▆█▇▆▇▇▇▇▇▆▇▆▇▆▇▆▆▇▆▆▇▆▇▆▆▆▆▆</td></tr><tr><td>val_loss</td><td>▂▁▁▁▁▁▂▂▂▂▂▃▃▃▃▄▄▄▄▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇▇████</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>99</td></tr><tr><td>iter_acc</td><td>1.0</td></tr><tr><td>tr_acc</td><td>1.0</td></tr><tr><td>tr_epoch_loss</td><td>0.1574</td></tr><tr><td>val_acc_best</td><td>0.70417</td></tr><tr><td>val_acc_now</td><td>0.64167</td></tr><tr><td>val_loss</td><td>4.9945</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">radiant-sweep-170</strong> at: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/kaq4q9qx' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/kaq4q9qx</a><br/> View project at: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>/data2/bh_wandb/wandb/run-20250430_041118-kaq4q9qx/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require(\"core\")`! See https://wandb.me/wandb-core for more information."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: j09c5yoo with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBATCH: 16\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBN_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBPTT_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tDFA_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tIMAGE_SIZE: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tOTTT_input_trace_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tTIME: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tUDA_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \talpha_uda: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbias: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcfg: ['M', 'M', 200, 200]\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tchaching_on: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tconvTrue_fcFalse: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdata_path: /data2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tddp_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdenoise_on: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdvs_clipping: 5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdvs_duration: 100000\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepoch_num: 100\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \texclude_class: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \textra_train_dataset: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlast_lif: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.0001\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_sg_width: 4\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_decay: 0.5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_init: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_reset: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_threshold: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmerge_polarities: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmy_seed: 42\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnet_print: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_workers: 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer_what: SGD\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tpin_memory: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tpre_trained: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tpre_trained_path: net_save/save_now_net_weights_{unique_name}.pth\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \trate_coding: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tscheduler_name: no\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsingle_step: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsurrogate: hard_sigmoid\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_conv_kernel_size: 3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_conv_padding: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_conv_stride: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_trace_const1: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_trace_const2: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \ttdBN_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \ttrace_on: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \twhich_data: DVS_GESTURE_TONIC\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.19.10 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.17.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/data2/bh_wandb/wandb/run-20250430_041748-j09c5yoo</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/j09c5yoo' target=\"_blank\">zesty-sweep-172</a></strong> to <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/6pj3lh8j' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/6pj3lh8j</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/6pj3lh8j' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/6pj3lh8j</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/j09c5yoo' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/j09c5yoo</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'single_step' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'my_seed' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'TIME' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BATCH' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'IMAGE_SIZE' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'which_data' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'data_path' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'rate_coding' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_init' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_decay' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_threshold' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_reset' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_sg_width' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_conv_kernel_size' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_conv_stride' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_conv_padding' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_trace_const1' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_trace_const2' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'pre_trained' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'convTrue_fcFalse' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'cfg' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'net_print' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'pre_trained_path' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'learning_rate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'epoch_num' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'tdBN_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BN_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'surrogate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BPTT_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'optimizer_what' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'scheduler_name' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'ddp_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'dvs_clipping' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'dvs_duration' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'DFA_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'trace_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'OTTT_input_trace_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'exclude_class' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'merge_polarities' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'denoise_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'extra_train_dataset' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'num_workers' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'chaching_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'pin_memory' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'UDA_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'alpha_uda' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'bias' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'last_lif' was locked by 'sweep' (ignored update).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "param {'devices': '0', 'single_step': True, 'unique_name': 'main', 'my_seed': 42, 'TIME': 10, 'BATCH': 16, 'IMAGE_SIZE': 128, 'which_data': 'DVS_GESTURE_TONIC', 'data_path': '/data2', 'rate_coding': False, 'lif_layer_v_init': 0, 'lif_layer_v_decay': 0.5, 'lif_layer_v_threshold': 1, 'lif_layer_v_reset': 0, 'lif_layer_sg_width': 4, 'synapse_conv_kernel_size': 3, 'synapse_conv_stride': 1, 'synapse_conv_padding': 1, 'synapse_trace_const1': 1, 'synapse_trace_const2': 0, 'pre_trained': False, 'convTrue_fcFalse': False, 'cfg': ['M', 'M', 200, 200], 'net_print': True, 'pre_trained_path': 'net_save/save_now_net_weights_{unique_name}.pth', 'learning_rate': 0.0001, 'epoch_num': 100, 'tdBN_on': False, 'BN_on': False, 'surrogate': 'hard_sigmoid', 'BPTT_on': False, 'optimizer_what': 'SGD', 'scheduler_name': 'no', 'ddp_on': False, 'dvs_clipping': 5, 'dvs_duration': 100000, 'DFA_on': False, 'trace_on': True, 'OTTT_input_trace_on': False, 'exclude_class': True, 'merge_polarities': False, 'denoise_on': True, 'extra_train_dataset': 0, 'num_workers': 2, 'chaching_on': True, 'pin_memory': True, 'UDA_on': False, 'alpha_uda': 1, 'bias': True, 'last_lif': False, 'current epoch': 0} \n",
      "\n",
      "dataset_hash = 63cc597115630ec173f3099200061e53\n",
      "cache path exists\n",
      "\n",
      "device ==> cuda\n",
      "\n",
      "DataParallel(\n",
      "  (module): REBORN_MY_SNN_FC(\n",
      "    (layers): REBORN_MY_Sequential(\n",
      "      (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (2): DimChanger_for_FC()\n",
      "      (3): SYNAPSE_FC(in_features=2048, out_features=200, TIME=10, bias=True, sstep=True)\n",
      "      (4): LIF_layer(v_init=0, v_decay=0.5, v_threshold=1, v_reset=0, sg_width=4, surrogate=hard_sigmoid, BPTT_on=False, trace_const1=1, trace_const2=0, TIME=10, sstep=True, trace_on=True)\n",
      "      (5): SYNAPSE_FC(in_features=200, out_features=200, TIME=10, bias=True, sstep=True)\n",
      "      (6): LIF_layer(v_init=0, v_decay=0.5, v_threshold=1, v_reset=0, sg_width=4, surrogate=hard_sigmoid, BPTT_on=False, trace_const1=1, trace_const2=0, TIME=10, sstep=True, trace_on=True)\n",
      "      (7): SYNAPSE_FC(in_features=200, out_features=10, TIME=10, bias=True, sstep=True)\n",
      "    )\n",
      "  )\n",
      ")\n",
      "\n",
      "========================================================\n",
      "Trainable parameters: 452,010\n",
      "========================================================\n",
      "\n",
      "epoch-0   lr=['0.0001000'], tr/val_loss:  2.303353/  2.303047, val:  10.00%, val_best:  10.00%, tr:  10.01%, tr_best:  10.01%\n",
      "epoch-1   lr=['0.0001000'], tr/val_loss:  2.303309/  2.302968, val:  10.00%, val_best:  10.00%, tr:  10.01%, tr_best:  10.01%\n",
      "epoch-2   lr=['0.0001000'], tr/val_loss:  2.303253/  2.302913, val:  10.00%, val_best:  10.00%, tr:  10.01%, tr_best:  10.01%\n",
      "epoch-3   lr=['0.0001000'], tr/val_loss:  2.303180/  2.302890, val:  10.00%, val_best:  10.00%, tr:  10.01%, tr_best:  10.01%\n",
      "epoch-4   lr=['0.0001000'], tr/val_loss:  2.303389/  2.302858, val:  10.00%, val_best:  10.00%, tr:  10.01%, tr_best:  10.01%\n",
      "epoch-5   lr=['0.0001000'], tr/val_loss:  2.303003/  2.302804, val:  10.00%, val_best:  10.00%, tr:  10.01%, tr_best:  10.01%\n",
      "epoch-6   lr=['0.0001000'], tr/val_loss:  2.302944/  2.302766, val:  10.00%, val_best:  10.00%, tr:  10.01%, tr_best:  10.01%\n",
      "epoch-7   lr=['0.0001000'], tr/val_loss:  2.303002/  2.302772, val:  10.00%, val_best:  10.00%, tr:  10.01%, tr_best:  10.01%\n",
      "epoch-8   lr=['0.0001000'], tr/val_loss:  2.302786/  2.302740, val:  10.00%, val_best:  10.00%, tr:  10.01%, tr_best:  10.01%\n",
      "epoch-9   lr=['0.0001000'], tr/val_loss:  2.302638/  2.302746, val:  10.00%, val_best:  10.00%, tr:  10.01%, tr_best:  10.01%\n",
      "epoch-10  lr=['0.0001000'], tr/val_loss:  2.303135/  2.302742, val:  10.00%, val_best:  10.00%, tr:   9.19%, tr_best:  10.01%\n",
      "epoch-11  lr=['0.0001000'], tr/val_loss:  2.303039/  2.302714, val:  10.00%, val_best:  10.00%, tr:   8.89%, tr_best:  10.01%\n",
      "epoch-12  lr=['0.0001000'], tr/val_loss:  2.302702/  2.302692, val:  10.00%, val_best:  10.00%, tr:  10.01%, tr_best:  10.01%\n",
      "epoch-13  lr=['0.0001000'], tr/val_loss:  2.302847/  2.302688, val:  10.00%, val_best:  10.00%, tr:  10.01%, tr_best:  10.01%\n",
      "epoch-14  lr=['0.0001000'], tr/val_loss:  2.303035/  2.302699, val:  10.00%, val_best:  10.00%, tr:  10.01%, tr_best:  10.01%\n",
      "epoch-15  lr=['0.0001000'], tr/val_loss:  2.302881/  2.302661, val:  10.00%, val_best:  10.00%, tr:  10.01%, tr_best:  10.01%\n",
      "epoch-16  lr=['0.0001000'], tr/val_loss:  2.302944/  2.302657, val:  10.00%, val_best:  10.00%, tr:   9.60%, tr_best:  10.01%\n",
      "epoch-17  lr=['0.0001000'], tr/val_loss:  2.302719/  2.302647, val:  10.00%, val_best:  10.00%, tr:  10.01%, tr_best:  10.01%\n",
      "epoch-18  lr=['0.0001000'], tr/val_loss:  2.302800/  2.302642, val:  10.00%, val_best:  10.00%, tr:  10.01%, tr_best:  10.01%\n",
      "epoch-19  lr=['0.0001000'], tr/val_loss:  2.302750/  2.302643, val:  10.00%, val_best:  10.00%, tr:  10.01%, tr_best:  10.01%\n",
      "epoch-20  lr=['0.0001000'], tr/val_loss:  2.302774/  2.302649, val:  10.00%, val_best:  10.00%, tr:   9.50%, tr_best:  10.01%\n",
      "epoch-21  lr=['0.0001000'], tr/val_loss:  2.302997/  2.302649, val:  10.00%, val_best:  10.00%, tr:  10.11%, tr_best:  10.11%\n",
      "epoch-22  lr=['0.0001000'], tr/val_loss:  2.302886/  2.302623, val:  10.00%, val_best:  10.00%, tr:  10.01%, tr_best:  10.11%\n",
      "epoch-23  lr=['0.0001000'], tr/val_loss:  2.302808/  2.302628, val:  10.00%, val_best:  10.00%, tr:  10.01%, tr_best:  10.11%\n",
      "epoch-24  lr=['0.0001000'], tr/val_loss:  2.302805/  2.302622, val:  10.00%, val_best:  10.00%, tr:  10.01%, tr_best:  10.11%\n",
      "epoch-25  lr=['0.0001000'], tr/val_loss:  2.302895/  2.302615, val:  10.00%, val_best:  10.00%, tr:   8.38%, tr_best:  10.11%\n",
      "epoch-26  lr=['0.0001000'], tr/val_loss:  2.302811/  2.302609, val:  10.00%, val_best:  10.00%, tr:  10.01%, tr_best:  10.11%\n",
      "epoch-27  lr=['0.0001000'], tr/val_loss:  2.302836/  2.302608, val:  10.00%, val_best:  10.00%, tr:  10.01%, tr_best:  10.11%\n",
      "epoch-28  lr=['0.0001000'], tr/val_loss:  2.302742/  2.302602, val:  10.00%, val_best:  10.00%, tr:  10.01%, tr_best:  10.11%\n",
      "epoch-29  lr=['0.0001000'], tr/val_loss:  2.302640/  2.302599, val:  10.00%, val_best:  10.00%, tr:  10.01%, tr_best:  10.11%\n",
      "epoch-30  lr=['0.0001000'], tr/val_loss:  2.302813/  2.302604, val:  10.00%, val_best:  10.00%, tr:  10.01%, tr_best:  10.11%\n",
      "epoch-31  lr=['0.0001000'], tr/val_loss:  2.302789/  2.302609, val:  10.00%, val_best:  10.00%, tr:  10.01%, tr_best:  10.11%\n",
      "epoch-32  lr=['0.0001000'], tr/val_loss:  2.302845/  2.302606, val:  10.00%, val_best:  10.00%, tr:  10.01%, tr_best:  10.11%\n",
      "epoch-33  lr=['0.0001000'], tr/val_loss:  2.302791/  2.302604, val:  10.00%, val_best:  10.00%, tr:  10.01%, tr_best:  10.11%\n",
      "epoch-34  lr=['0.0001000'], tr/val_loss:  2.302884/  2.302604, val:  10.00%, val_best:  10.00%, tr:  10.01%, tr_best:  10.11%\n",
      "epoch-35  lr=['0.0001000'], tr/val_loss:  2.302788/  2.302602, val:  10.00%, val_best:  10.00%, tr:  10.01%, tr_best:  10.11%\n",
      "epoch-36  lr=['0.0001000'], tr/val_loss:  2.302829/  2.302599, val:  10.00%, val_best:  10.00%, tr:   8.68%, tr_best:  10.11%\n",
      "epoch-37  lr=['0.0001000'], tr/val_loss:  2.302872/  2.302601, val:  10.00%, val_best:  10.00%, tr:  10.01%, tr_best:  10.11%\n",
      "epoch-38  lr=['0.0001000'], tr/val_loss:  2.302744/  2.302599, val:  10.00%, val_best:  10.00%, tr:   9.30%, tr_best:  10.11%\n",
      "epoch-39  lr=['0.0001000'], tr/val_loss:  2.302754/  2.302598, val:  10.00%, val_best:  10.00%, tr:   8.68%, tr_best:  10.11%\n",
      "epoch-40  lr=['0.0001000'], tr/val_loss:  2.302806/  2.302597, val:  10.00%, val_best:  10.00%, tr:   8.78%, tr_best:  10.11%\n",
      "epoch-41  lr=['0.0001000'], tr/val_loss:  2.302747/  2.302596, val:  10.00%, val_best:  10.00%, tr:   8.07%, tr_best:  10.11%\n",
      "epoch-42  lr=['0.0001000'], tr/val_loss:  2.302743/  2.302602, val:  10.00%, val_best:  10.00%, tr:  10.01%, tr_best:  10.11%\n",
      "epoch-43  lr=['0.0001000'], tr/val_loss:  2.302774/  2.302598, val:  10.00%, val_best:  10.00%, tr:   9.09%, tr_best:  10.11%\n",
      "epoch-44  lr=['0.0001000'], tr/val_loss:  2.302738/  2.302598, val:  10.00%, val_best:  10.00%, tr:   8.38%, tr_best:  10.11%\n",
      "epoch-45  lr=['0.0001000'], tr/val_loss:  2.302781/  2.302605, val:  10.00%, val_best:  10.00%, tr:   9.30%, tr_best:  10.11%\n",
      "epoch-46  lr=['0.0001000'], tr/val_loss:  2.302685/  2.302597, val:  10.00%, val_best:  10.00%, tr:   8.68%, tr_best:  10.11%\n",
      "epoch-47  lr=['0.0001000'], tr/val_loss:  2.302820/  2.302601, val:  10.00%, val_best:  10.00%, tr:   9.09%, tr_best:  10.11%\n",
      "epoch-48  lr=['0.0001000'], tr/val_loss:  2.302758/  2.302609, val:  10.00%, val_best:  10.00%, tr:   9.60%, tr_best:  10.11%\n",
      "epoch-49  lr=['0.0001000'], tr/val_loss:  2.302779/  2.302603, val:  10.00%, val_best:  10.00%, tr:   8.27%, tr_best:  10.11%\n",
      "epoch-50  lr=['0.0001000'], tr/val_loss:  2.302781/  2.302607, val:  10.00%, val_best:  10.00%, tr:   8.27%, tr_best:  10.11%\n",
      "epoch-51  lr=['0.0001000'], tr/val_loss:  2.302691/  2.302607, val:  10.00%, val_best:  10.00%, tr:   7.76%, tr_best:  10.11%\n",
      "epoch-52  lr=['0.0001000'], tr/val_loss:  2.302883/  2.302611, val:  10.00%, val_best:  10.00%, tr:   8.17%, tr_best:  10.11%\n",
      "epoch-53  lr=['0.0001000'], tr/val_loss:  2.302826/  2.302607, val:  10.00%, val_best:  10.00%, tr:   8.89%, tr_best:  10.11%\n",
      "epoch-54  lr=['0.0001000'], tr/val_loss:  2.302753/  2.302602, val:  10.00%, val_best:  10.00%, tr:   9.19%, tr_best:  10.11%\n",
      "epoch-55  lr=['0.0001000'], tr/val_loss:  2.302773/  2.302601, val:  10.00%, val_best:  10.00%, tr:  10.01%, tr_best:  10.11%\n",
      "epoch-56  lr=['0.0001000'], tr/val_loss:  2.302884/  2.302602, val:  10.00%, val_best:  10.00%, tr:   9.09%, tr_best:  10.11%\n",
      "epoch-57  lr=['0.0001000'], tr/val_loss:  2.302813/  2.302602, val:  10.00%, val_best:  10.00%, tr:   8.27%, tr_best:  10.11%\n",
      "epoch-58  lr=['0.0001000'], tr/val_loss:  2.302797/  2.302603, val:  10.00%, val_best:  10.00%, tr:   9.09%, tr_best:  10.11%\n",
      "epoch-59  lr=['0.0001000'], tr/val_loss:  2.302886/  2.302601, val:  10.00%, val_best:  10.00%, tr:   9.70%, tr_best:  10.11%\n",
      "epoch-60  lr=['0.0001000'], tr/val_loss:  2.302739/  2.302602, val:  10.00%, val_best:  10.00%, tr:   8.78%, tr_best:  10.11%\n",
      "epoch-61  lr=['0.0001000'], tr/val_loss:  2.302776/  2.302601, val:  10.00%, val_best:  10.00%, tr:   9.30%, tr_best:  10.11%\n",
      "epoch-62  lr=['0.0001000'], tr/val_loss:  2.302853/  2.302598, val:  10.00%, val_best:  10.00%, tr:   8.48%, tr_best:  10.11%\n",
      "epoch-63  lr=['0.0001000'], tr/val_loss:  2.302755/  2.302597, val:  10.00%, val_best:  10.00%, tr:  10.01%, tr_best:  10.11%\n",
      "epoch-64  lr=['0.0001000'], tr/val_loss:  2.302690/  2.302604, val:  10.00%, val_best:  10.00%, tr:  10.11%, tr_best:  10.11%\n",
      "epoch-65  lr=['0.0001000'], tr/val_loss:  2.302775/  2.302602, val:  10.00%, val_best:  10.00%, tr:  10.01%, tr_best:  10.11%\n",
      "epoch-66  lr=['0.0001000'], tr/val_loss:  2.302693/  2.302601, val:  10.00%, val_best:  10.00%, tr:  10.01%, tr_best:  10.11%\n",
      "epoch-67  lr=['0.0001000'], tr/val_loss:  2.302906/  2.302607, val:  10.00%, val_best:  10.00%, tr:   8.78%, tr_best:  10.11%\n",
      "epoch-68  lr=['0.0001000'], tr/val_loss:  2.302793/  2.302599, val:  10.00%, val_best:  10.00%, tr:   9.19%, tr_best:  10.11%\n",
      "epoch-69  lr=['0.0001000'], tr/val_loss:  2.302770/  2.302602, val:  10.00%, val_best:  10.00%, tr:  10.01%, tr_best:  10.11%\n",
      "epoch-70  lr=['0.0001000'], tr/val_loss:  2.302866/  2.302597, val:  10.00%, val_best:  10.00%, tr:   9.50%, tr_best:  10.11%\n",
      "epoch-71  lr=['0.0001000'], tr/val_loss:  2.302885/  2.302596, val:  10.00%, val_best:  10.00%, tr:   8.58%, tr_best:  10.11%\n",
      "epoch-72  lr=['0.0001000'], tr/val_loss:  2.302852/  2.302598, val:  10.00%, val_best:  10.00%, tr:  10.01%, tr_best:  10.11%\n",
      "epoch-73  lr=['0.0001000'], tr/val_loss:  2.302803/  2.302592, val:  10.00%, val_best:  10.00%, tr:   9.09%, tr_best:  10.11%\n",
      "epoch-74  lr=['0.0001000'], tr/val_loss:  2.302764/  2.302594, val:  10.00%, val_best:  10.00%, tr:   8.48%, tr_best:  10.11%\n",
      "epoch-75  lr=['0.0001000'], tr/val_loss:  2.302853/  2.302596, val:  10.00%, val_best:  10.00%, tr:  10.01%, tr_best:  10.11%\n",
      "epoch-76  lr=['0.0001000'], tr/val_loss:  2.302876/  2.302599, val:  10.00%, val_best:  10.00%, tr:   9.70%, tr_best:  10.11%\n",
      "epoch-77  lr=['0.0001000'], tr/val_loss:  2.302864/  2.302595, val:  10.00%, val_best:  10.00%, tr:   8.78%, tr_best:  10.11%\n",
      "epoch-78  lr=['0.0001000'], tr/val_loss:  2.302786/  2.302591, val:  10.00%, val_best:  10.00%, tr:  10.01%, tr_best:  10.11%\n",
      "epoch-79  lr=['0.0001000'], tr/val_loss:  2.302822/  2.302595, val:  10.00%, val_best:  10.00%, tr:   9.30%, tr_best:  10.11%\n",
      "epoch-80  lr=['0.0001000'], tr/val_loss:  2.302797/  2.302598, val:  10.00%, val_best:  10.00%, tr:   7.66%, tr_best:  10.11%\n",
      "epoch-81  lr=['0.0001000'], tr/val_loss:  2.302728/  2.302593, val:  10.00%, val_best:  10.00%, tr:   8.89%, tr_best:  10.11%\n",
      "epoch-82  lr=['0.0001000'], tr/val_loss:  2.302796/  2.302601, val:  10.00%, val_best:  10.00%, tr:  10.42%, tr_best:  10.42%\n",
      "epoch-83  lr=['0.0001000'], tr/val_loss:  2.302846/  2.302593, val:  10.00%, val_best:  10.00%, tr:   8.68%, tr_best:  10.42%\n",
      "epoch-84  lr=['0.0001000'], tr/val_loss:  2.302759/  2.302595, val:  10.00%, val_best:  10.00%, tr:  10.01%, tr_best:  10.42%\n",
      "epoch-85  lr=['0.0001000'], tr/val_loss:  2.302730/  2.302597, val:  10.00%, val_best:  10.00%, tr:   9.09%, tr_best:  10.42%\n",
      "epoch-86  lr=['0.0001000'], tr/val_loss:  2.302884/  2.302599, val:  10.00%, val_best:  10.00%, tr:   8.68%, tr_best:  10.42%\n",
      "epoch-87  lr=['0.0001000'], tr/val_loss:  2.302802/  2.302597, val:  10.00%, val_best:  10.00%, tr:  10.01%, tr_best:  10.42%\n",
      "epoch-88  lr=['0.0001000'], tr/val_loss:  2.302900/  2.302597, val:  10.00%, val_best:  10.00%, tr:  10.01%, tr_best:  10.42%\n",
      "epoch-89  lr=['0.0001000'], tr/val_loss:  2.302804/  2.302595, val:  10.00%, val_best:  10.00%, tr:  10.01%, tr_best:  10.42%\n",
      "epoch-90  lr=['0.0001000'], tr/val_loss:  2.302787/  2.302590, val:  10.00%, val_best:  10.00%, tr:   9.50%, tr_best:  10.42%\n",
      "epoch-91  lr=['0.0001000'], tr/val_loss:  2.302755/  2.302593, val:  10.00%, val_best:  10.00%, tr:   9.91%, tr_best:  10.42%\n",
      "epoch-92  lr=['0.0001000'], tr/val_loss:  2.302809/  2.302600, val:  10.00%, val_best:  10.00%, tr:   8.48%, tr_best:  10.42%\n",
      "epoch-93  lr=['0.0001000'], tr/val_loss:  2.302807/  2.302593, val:  10.00%, val_best:  10.00%, tr:   8.78%, tr_best:  10.42%\n",
      "epoch-94  lr=['0.0001000'], tr/val_loss:  2.302743/  2.302597, val:  10.00%, val_best:  10.00%, tr:   8.99%, tr_best:  10.42%\n",
      "epoch-95  lr=['0.0001000'], tr/val_loss:  2.302758/  2.302598, val:  10.00%, val_best:  10.00%, tr:   9.81%, tr_best:  10.42%\n",
      "epoch-96  lr=['0.0001000'], tr/val_loss:  2.302812/  2.302597, val:  10.00%, val_best:  10.00%, tr:   8.78%, tr_best:  10.42%\n",
      "epoch-97  lr=['0.0001000'], tr/val_loss:  2.302837/  2.302595, val:  10.00%, val_best:  10.00%, tr:   8.17%, tr_best:  10.42%\n",
      "epoch-98  lr=['0.0001000'], tr/val_loss:  2.302900/  2.302598, val:  10.00%, val_best:  10.00%, tr:   9.60%, tr_best:  10.42%\n",
      "epoch-99  lr=['0.0001000'], tr/val_loss:  2.302818/  2.302597, val:  10.00%, val_best:  10.00%, tr:   9.50%, tr_best:  10.42%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c1b159afe518475e892345bb2bcc8e60",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.006 MB of 0.006 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>iter_acc</td><td>▂▄▂▂▂▄▄▅▅▁▇▅█▄▁▄▅▄▅▁▇▂▇▄▁▄▅▂▁▁▄▂▂▁▇▁▄▄▁▂</td></tr><tr><td>summary_val_acc</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>tr_acc</td><td>▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▃▇▂▄▁▁▄▁▆▄▇▃▅▇▇▃▄█▇▇▇▂▆▁</td></tr><tr><td>tr_epoch_loss</td><td>█▇█▄▁▂▅▂▂▄▃▃▁▃▂▃▂▂▂▃▂▃▂▃▃▂▂▃▃▃▃▃▃▂▂▃▃▃▂▃</td></tr><tr><td>val_acc_best</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_acc_now</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_loss</td><td>█▆▅▄▃▂▃▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>99</td></tr><tr><td>iter_acc</td><td>0.0</td></tr><tr><td>tr_acc</td><td>0.09499</td></tr><tr><td>tr_epoch_loss</td><td>2.30282</td></tr><tr><td>val_acc_best</td><td>0.1</td></tr><tr><td>val_acc_now</td><td>0.1</td></tr><tr><td>val_loss</td><td>2.3026</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">zesty-sweep-172</strong> at: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/j09c5yoo' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/j09c5yoo</a><br/> View project at: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>/data2/bh_wandb/wandb/run-20250430_041748-j09c5yoo/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require(\"core\")`! See https://wandb.me/wandb-core for more information."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Sweep Agent: Waiting for job.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Job received.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: crfuze2w with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBATCH: 16\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBN_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBPTT_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tDFA_on: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tIMAGE_SIZE: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tOTTT_input_trace_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tTIME: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tUDA_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \talpha_uda: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbias: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcfg: ['M', 'M', 200, 200]\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tchaching_on: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tconvTrue_fcFalse: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdata_path: /data2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tddp_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdenoise_on: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdvs_clipping: 5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdvs_duration: 100000\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepoch_num: 100\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \texclude_class: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \textra_train_dataset: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlast_lif: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.001\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_sg_width: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_decay: 0.5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_init: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_reset: 10000\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_threshold: 0.25\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmerge_polarities: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmy_seed: 42\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnet_print: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_workers: 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer_what: SGD\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tpin_memory: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tpre_trained: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tpre_trained_path: net_save/save_now_net_weights_{unique_name}.pth\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \trate_coding: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tscheduler_name: no\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsingle_step: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsurrogate: hard_sigmoid\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_conv_kernel_size: 3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_conv_padding: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_conv_stride: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_trace_const1: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_trace_const2: 0.5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \ttdBN_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \ttrace_on: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \twhich_data: DVS_GESTURE_TONIC\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.19.10 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.17.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/data2/bh_wandb/wandb/run-20250430_042355-crfuze2w</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/crfuze2w' target=\"_blank\">misty-sweep-174</a></strong> to <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/6pj3lh8j' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/6pj3lh8j</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/6pj3lh8j' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/6pj3lh8j</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/crfuze2w' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/crfuze2w</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'single_step' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'my_seed' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'TIME' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BATCH' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'IMAGE_SIZE' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'which_data' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'data_path' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'rate_coding' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_init' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_decay' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_threshold' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_reset' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_sg_width' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_conv_kernel_size' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_conv_stride' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_conv_padding' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_trace_const1' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_trace_const2' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'pre_trained' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'convTrue_fcFalse' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'cfg' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'net_print' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'pre_trained_path' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'learning_rate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'epoch_num' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'tdBN_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BN_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'surrogate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BPTT_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'optimizer_what' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'scheduler_name' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'ddp_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'dvs_clipping' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'dvs_duration' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'DFA_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'trace_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'OTTT_input_trace_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'exclude_class' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'merge_polarities' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'denoise_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'extra_train_dataset' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'num_workers' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'chaching_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'pin_memory' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'UDA_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'alpha_uda' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'bias' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'last_lif' was locked by 'sweep' (ignored update).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "param {'devices': '0', 'single_step': True, 'unique_name': 'main', 'my_seed': 42, 'TIME': 10, 'BATCH': 16, 'IMAGE_SIZE': 128, 'which_data': 'DVS_GESTURE_TONIC', 'data_path': '/data2', 'rate_coding': False, 'lif_layer_v_init': 0, 'lif_layer_v_decay': 0.5, 'lif_layer_v_threshold': 0.25, 'lif_layer_v_reset': 10000, 'lif_layer_sg_width': 1, 'synapse_conv_kernel_size': 3, 'synapse_conv_stride': 1, 'synapse_conv_padding': 1, 'synapse_trace_const1': 1, 'synapse_trace_const2': 0.5, 'pre_trained': False, 'convTrue_fcFalse': False, 'cfg': ['M', 'M', 200, 200], 'net_print': True, 'pre_trained_path': 'net_save/save_now_net_weights_{unique_name}.pth', 'learning_rate': 0.001, 'epoch_num': 100, 'tdBN_on': False, 'BN_on': False, 'surrogate': 'hard_sigmoid', 'BPTT_on': False, 'optimizer_what': 'SGD', 'scheduler_name': 'no', 'ddp_on': False, 'dvs_clipping': 5, 'dvs_duration': 100000, 'DFA_on': True, 'trace_on': True, 'OTTT_input_trace_on': False, 'exclude_class': True, 'merge_polarities': False, 'denoise_on': True, 'extra_train_dataset': 0, 'num_workers': 2, 'chaching_on': True, 'pin_memory': True, 'UDA_on': False, 'alpha_uda': 1, 'bias': True, 'last_lif': False, 'current epoch': 0} \n",
      "\n",
      "dataset_hash = 63cc597115630ec173f3099200061e53\n",
      "cache path exists\n",
      "\n",
      "device ==> cuda\n",
      "\n",
      "DataParallel(\n",
      "  (module): REBORN_MY_SNN_FC(\n",
      "    (layers): REBORN_MY_Sequential(\n",
      "      (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (2): DimChanger_for_FC()\n",
      "      (3): SYNAPSE_FC(in_features=2048, out_features=200, TIME=10, bias=True, sstep=True)\n",
      "      (4): LIF_layer(v_init=0, v_decay=0.5, v_threshold=0.25, v_reset=10000, sg_width=1, surrogate=hard_sigmoid, BPTT_on=False, trace_const1=1, trace_const2=0.5, TIME=10, sstep=True, trace_on=True)\n",
      "      (5): Feedback_Receiver()\n",
      "      (6): SYNAPSE_FC(in_features=200, out_features=200, TIME=10, bias=True, sstep=True)\n",
      "      (7): LIF_layer(v_init=0, v_decay=0.5, v_threshold=0.25, v_reset=10000, sg_width=1, surrogate=hard_sigmoid, BPTT_on=False, trace_const1=1, trace_const2=0.5, TIME=10, sstep=True, trace_on=True)\n",
      "      (8): Feedback_Receiver()\n",
      "      (9): SYNAPSE_FC(in_features=200, out_features=10, TIME=10, bias=True, sstep=True)\n",
      "      (DFA_top): Top_Gradient()\n",
      "    )\n",
      "  )\n",
      ")\n",
      "\n",
      "========================================================\n",
      "Trainable parameters: 452,010\n",
      "========================================================\n",
      "\n",
      "epoch-0   lr=['0.0010000'], tr/val_loss:  2.249688/  2.086843, val:  30.42%, val_best:  30.42%, tr:  13.07%, tr_best:  13.07%\n",
      "[module.layers.5] weight_fb parameter count: 2,000\n",
      "[module.layers.8] weight_fb parameter count: 2,000\n",
      "epoch-1   lr=['0.0010000'], tr/val_loss:  1.765588/  1.660657, val:  55.42%, val_best:  55.42%, tr:  47.09%, tr_best:  47.09%\n",
      "epoch-2   lr=['0.0010000'], tr/val_loss:  1.483854/  1.581530, val:  55.00%, val_best:  55.42%, tr:  57.71%, tr_best:  57.71%\n",
      "epoch-3   lr=['0.0010000'], tr/val_loss:  1.386709/  1.594645, val:  57.92%, val_best:  57.92%, tr:  63.02%, tr_best:  63.02%\n",
      "epoch-4   lr=['0.0010000'], tr/val_loss:  1.345829/  1.579688, val:  58.33%, val_best:  58.33%, tr:  63.33%, tr_best:  63.33%\n",
      "epoch-5   lr=['0.0010000'], tr/val_loss:  1.299947/  1.525339, val:  61.67%, val_best:  61.67%, tr:  64.25%, tr_best:  64.25%\n",
      "epoch-6   lr=['0.0010000'], tr/val_loss:  1.261400/  1.525917, val:  58.75%, val_best:  61.67%, tr:  68.54%, tr_best:  68.54%\n",
      "epoch-7   lr=['0.0010000'], tr/val_loss:  1.233940/  1.508984, val:  60.42%, val_best:  61.67%, tr:  66.70%, tr_best:  68.54%\n",
      "epoch-8   lr=['0.0010000'], tr/val_loss:  1.201495/  1.499626, val:  61.67%, val_best:  61.67%, tr:  68.85%, tr_best:  68.85%\n",
      "epoch-9   lr=['0.0010000'], tr/val_loss:  1.193981/  1.533095, val:  58.33%, val_best:  61.67%, tr:  69.05%, tr_best:  69.05%\n",
      "epoch-10  lr=['0.0010000'], tr/val_loss:  1.196877/  1.543401, val:  55.00%, val_best:  61.67%, tr:  68.54%, tr_best:  69.05%\n",
      "epoch-11  lr=['0.0010000'], tr/val_loss:  1.175961/  1.516275, val:  59.17%, val_best:  61.67%, tr:  69.87%, tr_best:  69.87%\n",
      "epoch-12  lr=['0.0010000'], tr/val_loss:  1.181185/  1.537432, val:  61.25%, val_best:  61.67%, tr:  72.52%, tr_best:  72.52%\n",
      "epoch-13  lr=['0.0010000'], tr/val_loss:  1.179085/  1.576012, val:  62.92%, val_best:  62.92%, tr:  69.87%, tr_best:  72.52%\n",
      "epoch-14  lr=['0.0010000'], tr/val_loss:  1.138338/  1.677289, val:  59.17%, val_best:  62.92%, tr:  72.11%, tr_best:  72.52%\n",
      "epoch-15  lr=['0.0010000'], tr/val_loss:  1.149489/  1.625042, val:  64.17%, val_best:  64.17%, tr:  72.73%, tr_best:  72.73%\n",
      "epoch-16  lr=['0.0010000'], tr/val_loss:  1.163525/  1.611856, val:  62.08%, val_best:  64.17%, tr:  73.24%, tr_best:  73.24%\n",
      "epoch-17  lr=['0.0010000'], tr/val_loss:  1.125450/  1.625416, val:  63.75%, val_best:  64.17%, tr:  76.81%, tr_best:  76.81%\n",
      "epoch-18  lr=['0.0010000'], tr/val_loss:  1.134050/  1.738672, val:  58.75%, val_best:  64.17%, tr:  75.89%, tr_best:  76.81%\n",
      "epoch-19  lr=['0.0010000'], tr/val_loss:  1.153451/  1.678366, val:  60.83%, val_best:  64.17%, tr:  74.67%, tr_best:  76.81%\n",
      "epoch-20  lr=['0.0010000'], tr/val_loss:  1.135502/  1.701033, val:  58.75%, val_best:  64.17%, tr:  76.92%, tr_best:  76.92%\n",
      "epoch-21  lr=['0.0010000'], tr/val_loss:  1.130076/  1.720966, val:  61.67%, val_best:  64.17%, tr:  76.61%, tr_best:  76.92%\n",
      "epoch-22  lr=['0.0010000'], tr/val_loss:  1.163562/  1.741799, val:  64.17%, val_best:  64.17%, tr:  75.59%, tr_best:  76.92%\n",
      "epoch-23  lr=['0.0010000'], tr/val_loss:  1.146374/  1.730862, val:  60.83%, val_best:  64.17%, tr:  77.12%, tr_best:  77.12%\n",
      "epoch-24  lr=['0.0010000'], tr/val_loss:  1.123061/  1.792816, val:  62.08%, val_best:  64.17%, tr:  79.47%, tr_best:  79.47%\n",
      "epoch-25  lr=['0.0010000'], tr/val_loss:  1.134208/  1.787250, val:  63.75%, val_best:  64.17%, tr:  77.53%, tr_best:  79.47%\n",
      "epoch-26  lr=['0.0010000'], tr/val_loss:  1.143269/  1.814676, val:  62.50%, val_best:  64.17%, tr:  78.65%, tr_best:  79.47%\n",
      "epoch-27  lr=['0.0010000'], tr/val_loss:  1.132403/  1.890875, val:  61.67%, val_best:  64.17%, tr:  79.78%, tr_best:  79.78%\n",
      "epoch-28  lr=['0.0010000'], tr/val_loss:  1.153525/  1.827217, val:  65.42%, val_best:  65.42%, tr:  79.57%, tr_best:  79.78%\n",
      "epoch-29  lr=['0.0010000'], tr/val_loss:  1.143086/  1.949143, val:  60.42%, val_best:  65.42%, tr:  81.00%, tr_best:  81.00%\n",
      "epoch-30  lr=['0.0010000'], tr/val_loss:  1.139841/  1.978809, val:  58.33%, val_best:  65.42%, tr:  81.41%, tr_best:  81.41%\n",
      "epoch-31  lr=['0.0010000'], tr/val_loss:  1.178879/  1.964509, val:  59.58%, val_best:  65.42%, tr:  78.86%, tr_best:  81.41%\n",
      "epoch-32  lr=['0.0010000'], tr/val_loss:  1.184489/  2.049477, val:  63.75%, val_best:  65.42%, tr:  80.18%, tr_best:  81.41%\n",
      "epoch-33  lr=['0.0010000'], tr/val_loss:  1.183146/  2.074434, val:  62.50%, val_best:  65.42%, tr:  80.49%, tr_best:  81.41%\n",
      "epoch-34  lr=['0.0010000'], tr/val_loss:  1.178063/  2.067715, val:  59.58%, val_best:  65.42%, tr:  81.61%, tr_best:  81.61%\n",
      "epoch-35  lr=['0.0010000'], tr/val_loss:  1.209885/  2.140364, val:  57.50%, val_best:  65.42%, tr:  78.04%, tr_best:  81.61%\n",
      "epoch-36  lr=['0.0010000'], tr/val_loss:  1.183079/  2.095544, val:  62.08%, val_best:  65.42%, tr:  80.90%, tr_best:  81.61%\n",
      "epoch-37  lr=['0.0010000'], tr/val_loss:  1.184770/  2.146307, val:  61.67%, val_best:  65.42%, tr:  82.64%, tr_best:  82.64%\n",
      "epoch-38  lr=['0.0010000'], tr/val_loss:  1.217671/  2.159943, val:  60.83%, val_best:  65.42%, tr:  83.15%, tr_best:  83.15%\n",
      "epoch-39  lr=['0.0010000'], tr/val_loss:  1.217097/  2.229299, val:  60.00%, val_best:  65.42%, tr:  83.45%, tr_best:  83.45%\n",
      "epoch-40  lr=['0.0010000'], tr/val_loss:  1.236371/  2.309313, val:  62.50%, val_best:  65.42%, tr:  81.51%, tr_best:  83.45%\n",
      "epoch-41  lr=['0.0010000'], tr/val_loss:  1.224400/  2.302989, val:  56.25%, val_best:  65.42%, tr:  85.19%, tr_best:  85.19%\n",
      "epoch-42  lr=['0.0010000'], tr/val_loss:  1.202619/  2.264207, val:  63.33%, val_best:  65.42%, tr:  84.07%, tr_best:  85.19%\n",
      "epoch-43  lr=['0.0010000'], tr/val_loss:  1.202395/  2.357728, val:  61.67%, val_best:  65.42%, tr:  83.96%, tr_best:  85.19%\n",
      "epoch-44  lr=['0.0010000'], tr/val_loss:  1.199564/  2.369157, val:  60.83%, val_best:  65.42%, tr:  85.60%, tr_best:  85.60%\n",
      "epoch-45  lr=['0.0010000'], tr/val_loss:  1.179768/  2.413094, val:  62.08%, val_best:  65.42%, tr:  85.50%, tr_best:  85.60%\n",
      "epoch-46  lr=['0.0010000'], tr/val_loss:  1.187522/  2.424812, val:  65.00%, val_best:  65.42%, tr:  86.93%, tr_best:  86.93%\n",
      "epoch-47  lr=['0.0010000'], tr/val_loss:  1.204694/  2.461926, val:  62.50%, val_best:  65.42%, tr:  85.60%, tr_best:  86.93%\n",
      "epoch-48  lr=['0.0010000'], tr/val_loss:  1.246797/  2.442895, val:  63.33%, val_best:  65.42%, tr:  87.03%, tr_best:  87.03%\n",
      "epoch-49  lr=['0.0010000'], tr/val_loss:  1.225912/  2.457179, val:  64.58%, val_best:  65.42%, tr:  84.37%, tr_best:  87.03%\n",
      "epoch-50  lr=['0.0010000'], tr/val_loss:  1.215997/  2.562309, val:  62.08%, val_best:  65.42%, tr:  87.03%, tr_best:  87.03%\n",
      "epoch-51  lr=['0.0010000'], tr/val_loss:  1.267083/  2.561768, val:  62.08%, val_best:  65.42%, tr:  83.25%, tr_best:  87.03%\n",
      "epoch-52  lr=['0.0010000'], tr/val_loss:  1.197785/  2.557398, val:  58.75%, val_best:  65.42%, tr:  87.44%, tr_best:  87.44%\n",
      "epoch-53  lr=['0.0010000'], tr/val_loss:  1.242027/  2.560267, val:  64.17%, val_best:  65.42%, tr:  88.56%, tr_best:  88.56%\n",
      "epoch-54  lr=['0.0010000'], tr/val_loss:  1.243283/  2.622912, val:  62.50%, val_best:  65.42%, tr:  87.03%, tr_best:  88.56%\n",
      "epoch-55  lr=['0.0010000'], tr/val_loss:  1.229242/  2.689175, val:  58.75%, val_best:  65.42%, tr:  87.03%, tr_best:  88.56%\n",
      "epoch-56  lr=['0.0010000'], tr/val_loss:  1.247518/  2.768139, val:  56.25%, val_best:  65.42%, tr:  87.33%, tr_best:  88.56%\n",
      "epoch-57  lr=['0.0010000'], tr/val_loss:  1.287959/  2.646809, val:  61.25%, val_best:  65.42%, tr:  87.64%, tr_best:  88.56%\n",
      "epoch-58  lr=['0.0010000'], tr/val_loss:  1.263312/  2.755226, val:  62.08%, val_best:  65.42%, tr:  86.11%, tr_best:  88.56%\n",
      "epoch-59  lr=['0.0010000'], tr/val_loss:  1.266731/  2.791077, val:  62.50%, val_best:  65.42%, tr:  87.44%, tr_best:  88.56%\n",
      "epoch-60  lr=['0.0010000'], tr/val_loss:  1.267159/  2.786042, val:  60.42%, val_best:  65.42%, tr:  87.95%, tr_best:  88.56%\n",
      "epoch-61  lr=['0.0010000'], tr/val_loss:  1.294323/  2.783850, val:  61.67%, val_best:  65.42%, tr:  88.46%, tr_best:  88.56%\n",
      "epoch-62  lr=['0.0010000'], tr/val_loss:  1.274477/  2.806093, val:  64.58%, val_best:  65.42%, tr:  88.56%, tr_best:  88.56%\n",
      "epoch-63  lr=['0.0010000'], tr/val_loss:  1.265724/  2.821729, val:  61.67%, val_best:  65.42%, tr:  88.97%, tr_best:  88.97%\n",
      "epoch-64  lr=['0.0010000'], tr/val_loss:  1.290131/  2.991645, val:  61.67%, val_best:  65.42%, tr:  86.21%, tr_best:  88.97%\n",
      "epoch-65  lr=['0.0010000'], tr/val_loss:  1.273423/  2.865278, val:  65.00%, val_best:  65.42%, tr:  87.74%, tr_best:  88.97%\n",
      "epoch-66  lr=['0.0010000'], tr/val_loss:  1.292002/  2.951731, val:  63.75%, val_best:  65.42%, tr:  89.07%, tr_best:  89.07%\n",
      "epoch-67  lr=['0.0010000'], tr/val_loss:  1.305833/  2.953071, val:  63.75%, val_best:  65.42%, tr:  89.58%, tr_best:  89.58%\n",
      "epoch-68  lr=['0.0010000'], tr/val_loss:  1.269004/  3.147831, val:  62.92%, val_best:  65.42%, tr:  89.79%, tr_best:  89.79%\n",
      "epoch-69  lr=['0.0010000'], tr/val_loss:  1.288325/  3.016754, val:  63.33%, val_best:  65.42%, tr:  87.95%, tr_best:  89.79%\n",
      "epoch-70  lr=['0.0010000'], tr/val_loss:  1.308914/  2.982117, val:  65.00%, val_best:  65.42%, tr:  89.38%, tr_best:  89.79%\n",
      "epoch-71  lr=['0.0010000'], tr/val_loss:  1.310362/  3.198519, val:  60.83%, val_best:  65.42%, tr:  88.76%, tr_best:  89.79%\n",
      "epoch-72  lr=['0.0010000'], tr/val_loss:  1.307446/  3.240734, val:  60.83%, val_best:  65.42%, tr:  88.36%, tr_best:  89.79%\n",
      "epoch-73  lr=['0.0010000'], tr/val_loss:  1.399593/  3.159294, val:  60.83%, val_best:  65.42%, tr:  85.50%, tr_best:  89.79%\n",
      "epoch-74  lr=['0.0010000'], tr/val_loss:  1.351373/  3.231224, val:  62.08%, val_best:  65.42%, tr:  86.72%, tr_best:  89.79%\n",
      "epoch-75  lr=['0.0010000'], tr/val_loss:  1.369988/  3.302769, val:  60.00%, val_best:  65.42%, tr:  87.03%, tr_best:  89.79%\n",
      "epoch-76  lr=['0.0010000'], tr/val_loss:  1.336734/  3.356052, val:  61.67%, val_best:  65.42%, tr:  87.54%, tr_best:  89.79%\n",
      "epoch-77  lr=['0.0010000'], tr/val_loss:  1.394391/  3.374965, val:  65.83%, val_best:  65.83%, tr:  86.11%, tr_best:  89.79%\n",
      "epoch-78  lr=['0.0010000'], tr/val_loss:  1.372764/  3.351156, val:  65.00%, val_best:  65.83%, tr:  87.84%, tr_best:  89.79%\n",
      "epoch-79  lr=['0.0010000'], tr/val_loss:  1.346701/  3.323825, val:  64.58%, val_best:  65.83%, tr:  89.58%, tr_best:  89.79%\n",
      "epoch-80  lr=['0.0010000'], tr/val_loss:  1.300065/  3.434783, val:  64.17%, val_best:  65.83%, tr:  89.17%, tr_best:  89.79%\n",
      "epoch-81  lr=['0.0010000'], tr/val_loss:  1.351488/  3.398349, val:  64.58%, val_best:  65.83%, tr:  89.07%, tr_best:  89.79%\n",
      "epoch-82  lr=['0.0010000'], tr/val_loss:  1.381360/  3.553397, val:  61.67%, val_best:  65.83%, tr:  87.74%, tr_best:  89.79%\n",
      "epoch-83  lr=['0.0010000'], tr/val_loss:  1.383744/  3.733177, val:  61.25%, val_best:  65.83%, tr:  88.15%, tr_best:  89.79%\n",
      "epoch-84  lr=['0.0010000'], tr/val_loss:  1.378951/  3.476229, val:  67.92%, val_best:  67.92%, tr:  91.22%, tr_best:  91.22%\n",
      "epoch-85  lr=['0.0010000'], tr/val_loss:  1.369744/  3.540482, val:  62.92%, val_best:  67.92%, tr:  92.34%, tr_best:  92.34%\n",
      "epoch-86  lr=['0.0010000'], tr/val_loss:  1.385034/  3.730007, val:  62.50%, val_best:  67.92%, tr:  91.11%, tr_best:  92.34%\n",
      "epoch-87  lr=['0.0010000'], tr/val_loss:  1.408858/  3.585234, val:  67.08%, val_best:  67.92%, tr:  91.52%, tr_best:  92.34%\n",
      "epoch-88  lr=['0.0010000'], tr/val_loss:  1.381719/  3.715673, val:  66.67%, val_best:  67.92%, tr:  91.32%, tr_best:  92.34%\n",
      "epoch-89  lr=['0.0010000'], tr/val_loss:  1.393335/  3.793804, val:  62.92%, val_best:  67.92%, tr:  91.83%, tr_best:  92.34%\n",
      "epoch-90  lr=['0.0010000'], tr/val_loss:  1.404123/  3.640363, val:  67.08%, val_best:  67.92%, tr:  92.65%, tr_best:  92.65%\n",
      "epoch-91  lr=['0.0010000'], tr/val_loss:  1.403269/  3.821787, val:  60.42%, val_best:  67.92%, tr:  90.19%, tr_best:  92.65%\n",
      "epoch-92  lr=['0.0010000'], tr/val_loss:  1.398819/  3.808229, val:  62.08%, val_best:  67.92%, tr:  90.19%, tr_best:  92.65%\n",
      "epoch-93  lr=['0.0010000'], tr/val_loss:  1.417491/  3.754564, val:  63.75%, val_best:  67.92%, tr:  89.27%, tr_best:  92.65%\n",
      "epoch-94  lr=['0.0010000'], tr/val_loss:  1.446484/  3.903407, val:  65.00%, val_best:  67.92%, tr:  90.81%, tr_best:  92.65%\n",
      "epoch-95  lr=['0.0010000'], tr/val_loss:  1.450996/  3.838077, val:  65.00%, val_best:  67.92%, tr:  91.32%, tr_best:  92.65%\n",
      "epoch-96  lr=['0.0010000'], tr/val_loss:  1.427751/  4.144279, val:  61.67%, val_best:  67.92%, tr:  93.46%, tr_best:  93.46%\n",
      "epoch-97  lr=['0.0010000'], tr/val_loss:  1.475739/  3.919349, val:  67.50%, val_best:  67.92%, tr:  89.58%, tr_best:  93.46%\n",
      "epoch-98  lr=['0.0010000'], tr/val_loss:  1.432446/  4.001995, val:  63.33%, val_best:  67.92%, tr:  91.42%, tr_best:  93.46%\n",
      "epoch-99  lr=['0.0010000'], tr/val_loss:  1.489653/  4.055667, val:  63.75%, val_best:  67.92%, tr:  90.70%, tr_best:  93.46%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "49caa7ab63f041ab8a43a33613258ba7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.006 MB of 0.006 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>iter_acc</td><td>▁▆▃▃▃▄▅▁▄▆▇█▆▆▃▇▆▆▇▇▅█▆▇█▆▆▇█▆▆█▄█▆▆▅▆█▆</td></tr><tr><td>summary_val_acc</td><td>▁▆▆▇▆▇▆▇▇▇▇▇▇▇▆▇▇▇▇▇▇▆▇▇▇▇▇▇▇▇▇█▇▇██▇▇▇█</td></tr><tr><td>tr_acc</td><td>▁▅▅▆▆▆▆▇▆▇▇▇▇▇▇▇▇▇▇▇▇██████████▇████████</td></tr><tr><td>tr_epoch_loss</td><td>█▃▂▂▁▁▁▁▁▁▁▁▁▁▂▁▂▁▁▂▂▁▂▂▂▂▂▂▂▂▃▃▂▃▃▃▃▃▃▃</td></tr><tr><td>val_acc_best</td><td>▁▆▆▇▇▇▇▇▇▇▇▇████████████████████████████</td></tr><tr><td>val_acc_now</td><td>▁▆▆▇▆▇▆▇▇▇▇▇▇▇▆▇▇▇▇▇▇▆▇▇▇▇▇▇▇▇▇█▇▇██▇▇▇█</td></tr><tr><td>val_loss</td><td>▃▁▁▁▁▁▁▁▁▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▆▆▆▆▇▇▇████</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>99</td></tr><tr><td>iter_acc</td><td>1.0</td></tr><tr><td>tr_acc</td><td>0.90705</td></tr><tr><td>tr_epoch_loss</td><td>1.48965</td></tr><tr><td>val_acc_best</td><td>0.67917</td></tr><tr><td>val_acc_now</td><td>0.6375</td></tr><tr><td>val_loss</td><td>4.05567</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">misty-sweep-174</strong> at: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/crfuze2w' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/crfuze2w</a><br/> View project at: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>/data2/bh_wandb/wandb/run-20250430_042355-crfuze2w/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require(\"core\")`! See https://wandb.me/wandb-core for more information."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: p92xo0e1 with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBATCH: 16\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBN_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBPTT_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tDFA_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tIMAGE_SIZE: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tOTTT_input_trace_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tTIME: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tUDA_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \talpha_uda: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbias: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcfg: ['M', 'M', 200, 200]\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tchaching_on: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tconvTrue_fcFalse: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdata_path: /data2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tddp_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdenoise_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdvs_clipping: 5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdvs_duration: 100000\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepoch_num: 100\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \texclude_class: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \textra_train_dataset: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlast_lif: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.001\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_sg_width: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_decay: 0.5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_init: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_reset: 10000\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_threshold: 0.75\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmerge_polarities: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmy_seed: 42\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnet_print: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_workers: 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer_what: SGD\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tpin_memory: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tpre_trained: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tpre_trained_path: net_save/save_now_net_weights_{unique_name}.pth\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \trate_coding: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tscheduler_name: no\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsingle_step: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsurrogate: hard_sigmoid\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_conv_kernel_size: 3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_conv_padding: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_conv_stride: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_trace_const1: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_trace_const2: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \ttdBN_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \ttrace_on: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \twhich_data: DVS_GESTURE_TONIC\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.19.10 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.17.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/data2/bh_wandb/wandb/run-20250430_043040-p92xo0e1</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/p92xo0e1' target=\"_blank\">electric-sweep-176</a></strong> to <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/6pj3lh8j' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/6pj3lh8j</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/6pj3lh8j' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/6pj3lh8j</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/p92xo0e1' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/p92xo0e1</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'single_step' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'my_seed' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'TIME' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BATCH' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'IMAGE_SIZE' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'which_data' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'data_path' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'rate_coding' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_init' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_decay' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_threshold' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_reset' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_sg_width' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_conv_kernel_size' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_conv_stride' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_conv_padding' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_trace_const1' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_trace_const2' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'pre_trained' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'convTrue_fcFalse' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'cfg' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'net_print' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'pre_trained_path' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'learning_rate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'epoch_num' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'tdBN_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BN_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'surrogate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BPTT_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'optimizer_what' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'scheduler_name' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'ddp_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'dvs_clipping' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'dvs_duration' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'DFA_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'trace_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'OTTT_input_trace_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'exclude_class' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'merge_polarities' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'denoise_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'extra_train_dataset' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'num_workers' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'chaching_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'pin_memory' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'UDA_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'alpha_uda' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'bias' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'last_lif' was locked by 'sweep' (ignored update).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "param {'devices': '0', 'single_step': True, 'unique_name': 'main', 'my_seed': 42, 'TIME': 10, 'BATCH': 16, 'IMAGE_SIZE': 128, 'which_data': 'DVS_GESTURE_TONIC', 'data_path': '/data2', 'rate_coding': False, 'lif_layer_v_init': 0, 'lif_layer_v_decay': 0.5, 'lif_layer_v_threshold': 0.75, 'lif_layer_v_reset': 10000, 'lif_layer_sg_width': 1, 'synapse_conv_kernel_size': 3, 'synapse_conv_stride': 1, 'synapse_conv_padding': 1, 'synapse_trace_const1': 1, 'synapse_trace_const2': 0, 'pre_trained': False, 'convTrue_fcFalse': False, 'cfg': ['M', 'M', 200, 200], 'net_print': True, 'pre_trained_path': 'net_save/save_now_net_weights_{unique_name}.pth', 'learning_rate': 0.001, 'epoch_num': 100, 'tdBN_on': False, 'BN_on': False, 'surrogate': 'hard_sigmoid', 'BPTT_on': False, 'optimizer_what': 'SGD', 'scheduler_name': 'no', 'ddp_on': False, 'dvs_clipping': 5, 'dvs_duration': 100000, 'DFA_on': False, 'trace_on': True, 'OTTT_input_trace_on': False, 'exclude_class': True, 'merge_polarities': False, 'denoise_on': False, 'extra_train_dataset': 0, 'num_workers': 2, 'chaching_on': True, 'pin_memory': True, 'UDA_on': False, 'alpha_uda': 1, 'bias': True, 'last_lif': False, 'current epoch': 0} \n",
      "\n",
      "dataset_hash = ffa516e60c3efd5e0208f72b4c36cb84\n",
      "cache path exists\n",
      "\n",
      "device ==> cuda\n",
      "\n",
      "DataParallel(\n",
      "  (module): REBORN_MY_SNN_FC(\n",
      "    (layers): REBORN_MY_Sequential(\n",
      "      (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (2): DimChanger_for_FC()\n",
      "      (3): SYNAPSE_FC(in_features=2048, out_features=200, TIME=10, bias=True, sstep=True)\n",
      "      (4): LIF_layer(v_init=0, v_decay=0.5, v_threshold=0.75, v_reset=10000, sg_width=1, surrogate=hard_sigmoid, BPTT_on=False, trace_const1=1, trace_const2=0, TIME=10, sstep=True, trace_on=True)\n",
      "      (5): SYNAPSE_FC(in_features=200, out_features=200, TIME=10, bias=True, sstep=True)\n",
      "      (6): LIF_layer(v_init=0, v_decay=0.5, v_threshold=0.75, v_reset=10000, sg_width=1, surrogate=hard_sigmoid, BPTT_on=False, trace_const1=1, trace_const2=0, TIME=10, sstep=True, trace_on=True)\n",
      "      (7): SYNAPSE_FC(in_features=200, out_features=10, TIME=10, bias=True, sstep=True)\n",
      "    )\n",
      "  )\n",
      ")\n",
      "\n",
      "========================================================\n",
      "Trainable parameters: 452,010\n",
      "========================================================\n",
      "\n",
      "epoch-0   lr=['0.0010000'], tr/val_loss:  2.305365/  2.302841, val:  10.00%, val_best:  10.00%, tr:   8.17%, tr_best:   8.17%\n",
      "epoch-1   lr=['0.0010000'], tr/val_loss:  2.304994/  2.302639, val:  10.00%, val_best:  10.00%, tr:   7.66%, tr_best:   8.17%\n",
      "epoch-2   lr=['0.0010000'], tr/val_loss:  2.305079/  2.302667, val:  10.00%, val_best:  10.00%, tr:   8.99%, tr_best:   8.99%\n",
      "epoch-3   lr=['0.0010000'], tr/val_loss:  2.304731/  2.302708, val:  10.00%, val_best:  10.00%, tr:   8.38%, tr_best:   8.99%\n",
      "epoch-4   lr=['0.0010000'], tr/val_loss:  2.304833/  2.302682, val:  10.00%, val_best:  10.00%, tr:   7.87%, tr_best:   8.99%\n",
      "epoch-5   lr=['0.0010000'], tr/val_loss:  2.304569/  2.302663, val:  10.00%, val_best:  10.00%, tr:   7.87%, tr_best:   8.99%\n",
      "epoch-6   lr=['0.0010000'], tr/val_loss:  2.305080/  2.302701, val:  10.00%, val_best:  10.00%, tr:   9.70%, tr_best:   9.70%\n",
      "epoch-7   lr=['0.0010000'], tr/val_loss:  2.304619/  2.302690, val:  10.00%, val_best:  10.00%, tr:   7.46%, tr_best:   9.70%\n",
      "epoch-8   lr=['0.0010000'], tr/val_loss:  2.304499/  2.302505, val:  10.00%, val_best:  10.00%, tr:   8.17%, tr_best:   9.70%\n",
      "epoch-9   lr=['0.0010000'], tr/val_loss:  2.304740/  2.302316, val:  10.00%, val_best:  10.00%, tr:   9.40%, tr_best:   9.70%\n",
      "epoch-10  lr=['0.0010000'], tr/val_loss:  2.302925/  2.300640, val:  10.42%, val_best:  10.42%, tr:  10.52%, tr_best:  10.52%\n",
      "epoch-11  lr=['0.0010000'], tr/val_loss:  2.297202/  2.293021, val:  14.17%, val_best:  14.17%, tr:  12.16%, tr_best:  12.16%\n",
      "epoch-12  lr=['0.0010000'], tr/val_loss:  2.276384/  2.269532, val:  21.25%, val_best:  21.25%, tr:  17.77%, tr_best:  17.77%\n",
      "epoch-13  lr=['0.0010000'], tr/val_loss:  2.235213/  2.238236, val:  19.17%, val_best:  21.25%, tr:  17.67%, tr_best:  17.77%\n",
      "epoch-14  lr=['0.0010000'], tr/val_loss:  2.185432/  2.193743, val:  26.67%, val_best:  26.67%, tr:  21.86%, tr_best:  21.86%\n",
      "epoch-15  lr=['0.0010000'], tr/val_loss:  2.117921/  2.120716, val:  35.83%, val_best:  35.83%, tr:  33.20%, tr_best:  33.20%\n",
      "epoch-16  lr=['0.0010000'], tr/val_loss:  2.021634/  2.034148, val:  39.58%, val_best:  39.58%, tr:  39.12%, tr_best:  39.12%\n",
      "epoch-17  lr=['0.0010000'], tr/val_loss:  1.913374/  1.930696, val:  47.08%, val_best:  47.08%, tr:  44.33%, tr_best:  44.33%\n",
      "epoch-18  lr=['0.0010000'], tr/val_loss:  1.796446/  1.839556, val:  46.67%, val_best:  47.08%, tr:  47.70%, tr_best:  47.70%\n",
      "epoch-19  lr=['0.0010000'], tr/val_loss:  1.704976/  1.756160, val:  51.25%, val_best:  51.25%, tr:  46.58%, tr_best:  47.70%\n",
      "epoch-20  lr=['0.0010000'], tr/val_loss:  1.625470/  1.701240, val:  47.50%, val_best:  51.25%, tr:  50.87%, tr_best:  50.87%\n",
      "epoch-21  lr=['0.0010000'], tr/val_loss:  1.560436/  1.657211, val:  49.58%, val_best:  51.25%, tr:  54.44%, tr_best:  54.44%\n",
      "epoch-22  lr=['0.0010000'], tr/val_loss:  1.521039/  1.628651, val:  50.00%, val_best:  51.25%, tr:  55.26%, tr_best:  55.26%\n",
      "epoch-23  lr=['0.0010000'], tr/val_loss:  1.482926/  1.595828, val:  52.50%, val_best:  52.50%, tr:  56.79%, tr_best:  56.79%\n",
      "epoch-24  lr=['0.0010000'], tr/val_loss:  1.445381/  1.570990, val:  56.67%, val_best:  56.67%, tr:  58.84%, tr_best:  58.84%\n",
      "epoch-25  lr=['0.0010000'], tr/val_loss:  1.419680/  1.547724, val:  59.17%, val_best:  59.17%, tr:  57.30%, tr_best:  58.84%\n",
      "epoch-26  lr=['0.0010000'], tr/val_loss:  1.399079/  1.524175, val:  55.83%, val_best:  59.17%, tr:  58.63%, tr_best:  58.84%\n",
      "epoch-27  lr=['0.0010000'], tr/val_loss:  1.370396/  1.504542, val:  54.58%, val_best:  59.17%, tr:  59.75%, tr_best:  59.75%\n",
      "epoch-28  lr=['0.0010000'], tr/val_loss:  1.360890/  1.492250, val:  59.17%, val_best:  59.17%, tr:  58.53%, tr_best:  59.75%\n",
      "epoch-29  lr=['0.0010000'], tr/val_loss:  1.332756/  1.483245, val:  56.25%, val_best:  59.17%, tr:  60.47%, tr_best:  60.47%\n",
      "epoch-30  lr=['0.0010000'], tr/val_loss:  1.316038/  1.485823, val:  56.25%, val_best:  59.17%, tr:  60.98%, tr_best:  60.98%\n",
      "epoch-31  lr=['0.0010000'], tr/val_loss:  1.300516/  1.459195, val:  58.75%, val_best:  59.17%, tr:  60.88%, tr_best:  60.98%\n",
      "epoch-32  lr=['0.0010000'], tr/val_loss:  1.287184/  1.457172, val:  56.67%, val_best:  59.17%, tr:  62.21%, tr_best:  62.21%\n",
      "epoch-33  lr=['0.0010000'], tr/val_loss:  1.278392/  1.437501, val:  59.58%, val_best:  59.58%, tr:  60.06%, tr_best:  62.21%\n",
      "epoch-34  lr=['0.0010000'], tr/val_loss:  1.261783/  1.427161, val:  58.33%, val_best:  59.58%, tr:  60.37%, tr_best:  62.21%\n",
      "epoch-35  lr=['0.0010000'], tr/val_loss:  1.241432/  1.435626, val:  56.25%, val_best:  59.58%, tr:  62.21%, tr_best:  62.21%\n",
      "epoch-36  lr=['0.0010000'], tr/val_loss:  1.238365/  1.429685, val:  56.25%, val_best:  59.58%, tr:  62.61%, tr_best:  62.61%\n",
      "epoch-37  lr=['0.0010000'], tr/val_loss:  1.223014/  1.407980, val:  61.25%, val_best:  61.25%, tr:  61.39%, tr_best:  62.61%\n",
      "epoch-38  lr=['0.0010000'], tr/val_loss:  1.214600/  1.414094, val:  58.75%, val_best:  61.25%, tr:  62.41%, tr_best:  62.61%\n",
      "epoch-39  lr=['0.0010000'], tr/val_loss:  1.201222/  1.404445, val:  58.75%, val_best:  61.25%, tr:  63.02%, tr_best:  63.02%\n",
      "epoch-40  lr=['0.0010000'], tr/val_loss:  1.187644/  1.413851, val:  58.75%, val_best:  61.25%, tr:  63.64%, tr_best:  63.64%\n",
      "epoch-41  lr=['0.0010000'], tr/val_loss:  1.178402/  1.399540, val:  61.25%, val_best:  61.25%, tr:  64.66%, tr_best:  64.66%\n",
      "epoch-42  lr=['0.0010000'], tr/val_loss:  1.163885/  1.397718, val:  60.00%, val_best:  61.25%, tr:  64.25%, tr_best:  64.66%\n",
      "epoch-43  lr=['0.0010000'], tr/val_loss:  1.157605/  1.404261, val:  58.33%, val_best:  61.25%, tr:  64.25%, tr_best:  64.66%\n",
      "epoch-44  lr=['0.0010000'], tr/val_loss:  1.144127/  1.382667, val:  61.25%, val_best:  61.25%, tr:  65.07%, tr_best:  65.07%\n",
      "epoch-45  lr=['0.0010000'], tr/val_loss:  1.136283/  1.374023, val:  60.83%, val_best:  61.25%, tr:  65.68%, tr_best:  65.68%\n",
      "epoch-46  lr=['0.0010000'], tr/val_loss:  1.125993/  1.395683, val:  58.75%, val_best:  61.25%, tr:  63.74%, tr_best:  65.68%\n",
      "epoch-47  lr=['0.0010000'], tr/val_loss:  1.126348/  1.379531, val:  60.83%, val_best:  61.25%, tr:  66.60%, tr_best:  66.60%\n",
      "epoch-48  lr=['0.0010000'], tr/val_loss:  1.118272/  1.377537, val:  61.25%, val_best:  61.25%, tr:  66.29%, tr_best:  66.60%\n",
      "epoch-49  lr=['0.0010000'], tr/val_loss:  1.111538/  1.365219, val:  62.50%, val_best:  62.50%, tr:  67.21%, tr_best:  67.21%\n",
      "epoch-50  lr=['0.0010000'], tr/val_loss:  1.094878/  1.371280, val:  59.58%, val_best:  62.50%, tr:  66.70%, tr_best:  67.21%\n",
      "epoch-51  lr=['0.0010000'], tr/val_loss:  1.091127/  1.372573, val:  62.92%, val_best:  62.92%, tr:  66.50%, tr_best:  67.21%\n",
      "epoch-52  lr=['0.0010000'], tr/val_loss:  1.092063/  1.364774, val:  60.42%, val_best:  62.92%, tr:  66.39%, tr_best:  67.21%\n",
      "epoch-53  lr=['0.0010000'], tr/val_loss:  1.080999/  1.348604, val:  64.58%, val_best:  64.58%, tr:  67.31%, tr_best:  67.31%\n",
      "epoch-54  lr=['0.0010000'], tr/val_loss:  1.065552/  1.356488, val:  63.33%, val_best:  64.58%, tr:  69.36%, tr_best:  69.36%\n",
      "epoch-55  lr=['0.0010000'], tr/val_loss:  1.054914/  1.355881, val:  61.67%, val_best:  64.58%, tr:  67.93%, tr_best:  69.36%\n",
      "epoch-56  lr=['0.0010000'], tr/val_loss:  1.045641/  1.351367, val:  65.00%, val_best:  65.00%, tr:  69.36%, tr_best:  69.36%\n",
      "epoch-57  lr=['0.0010000'], tr/val_loss:  1.040552/  1.349608, val:  61.25%, val_best:  65.00%, tr:  67.21%, tr_best:  69.36%\n",
      "epoch-58  lr=['0.0010000'], tr/val_loss:  1.025557/  1.361011, val:  63.75%, val_best:  65.00%, tr:  69.77%, tr_best:  69.77%\n",
      "epoch-59  lr=['0.0010000'], tr/val_loss:  1.032284/  1.340064, val:  66.67%, val_best:  66.67%, tr:  69.15%, tr_best:  69.77%\n",
      "epoch-60  lr=['0.0010000'], tr/val_loss:  1.023108/  1.338670, val:  62.92%, val_best:  66.67%, tr:  68.44%, tr_best:  69.77%\n",
      "epoch-61  lr=['0.0010000'], tr/val_loss:  1.020914/  1.340918, val:  62.92%, val_best:  66.67%, tr:  69.25%, tr_best:  69.77%\n",
      "epoch-62  lr=['0.0010000'], tr/val_loss:  1.017419/  1.342698, val:  62.92%, val_best:  66.67%, tr:  70.58%, tr_best:  70.58%\n",
      "epoch-63  lr=['0.0010000'], tr/val_loss:  1.000457/  1.324744, val:  63.75%, val_best:  66.67%, tr:  70.28%, tr_best:  70.58%\n",
      "epoch-64  lr=['0.0010000'], tr/val_loss:  0.985699/  1.358338, val:  65.00%, val_best:  66.67%, tr:  69.77%, tr_best:  70.58%\n",
      "epoch-65  lr=['0.0010000'], tr/val_loss:  0.990489/  1.343223, val:  63.33%, val_best:  66.67%, tr:  70.79%, tr_best:  70.79%\n",
      "epoch-66  lr=['0.0010000'], tr/val_loss:  0.989032/  1.331384, val:  66.67%, val_best:  66.67%, tr:  70.68%, tr_best:  70.79%\n",
      "epoch-67  lr=['0.0010000'], tr/val_loss:  0.989163/  1.335017, val:  63.75%, val_best:  66.67%, tr:  72.42%, tr_best:  72.42%\n",
      "epoch-68  lr=['0.0010000'], tr/val_loss:  0.974374/  1.335407, val:  62.92%, val_best:  66.67%, tr:  71.81%, tr_best:  72.42%\n",
      "epoch-69  lr=['0.0010000'], tr/val_loss:  0.962125/  1.330537, val:  66.67%, val_best:  66.67%, tr:  71.40%, tr_best:  72.42%\n",
      "epoch-70  lr=['0.0010000'], tr/val_loss:  0.963592/  1.336569, val:  65.00%, val_best:  66.67%, tr:  72.11%, tr_best:  72.42%\n",
      "epoch-71  lr=['0.0010000'], tr/val_loss:  0.951317/  1.358059, val:  64.17%, val_best:  66.67%, tr:  74.26%, tr_best:  74.26%\n",
      "epoch-72  lr=['0.0010000'], tr/val_loss:  0.942836/  1.349337, val:  63.75%, val_best:  66.67%, tr:  74.67%, tr_best:  74.67%\n",
      "epoch-73  lr=['0.0010000'], tr/val_loss:  0.951430/  1.345737, val:  64.58%, val_best:  66.67%, tr:  72.83%, tr_best:  74.67%\n",
      "epoch-74  lr=['0.0010000'], tr/val_loss:  0.936002/  1.346007, val:  65.42%, val_best:  66.67%, tr:  72.93%, tr_best:  74.67%\n",
      "epoch-75  lr=['0.0010000'], tr/val_loss:  0.937158/  1.338172, val:  66.67%, val_best:  66.67%, tr:  72.93%, tr_best:  74.67%\n",
      "epoch-76  lr=['0.0010000'], tr/val_loss:  0.919589/  1.348216, val:  65.83%, val_best:  66.67%, tr:  74.67%, tr_best:  74.67%\n",
      "epoch-77  lr=['0.0010000'], tr/val_loss:  0.932007/  1.359063, val:  65.42%, val_best:  66.67%, tr:  74.16%, tr_best:  74.67%\n",
      "epoch-78  lr=['0.0010000'], tr/val_loss:  0.919085/  1.338573, val:  66.25%, val_best:  66.67%, tr:  74.46%, tr_best:  74.67%\n",
      "epoch-79  lr=['0.0010000'], tr/val_loss:  0.917049/  1.352698, val:  65.83%, val_best:  66.67%, tr:  75.89%, tr_best:  75.89%\n",
      "epoch-80  lr=['0.0010000'], tr/val_loss:  0.904263/  1.346254, val:  65.00%, val_best:  66.67%, tr:  73.85%, tr_best:  75.89%\n",
      "epoch-81  lr=['0.0010000'], tr/val_loss:  0.905800/  1.352110, val:  62.08%, val_best:  66.67%, tr:  73.65%, tr_best:  75.89%\n",
      "epoch-82  lr=['0.0010000'], tr/val_loss:  0.898570/  1.343203, val:  65.00%, val_best:  66.67%, tr:  73.75%, tr_best:  75.89%\n",
      "epoch-83  lr=['0.0010000'], tr/val_loss:  0.900357/  1.346828, val:  67.50%, val_best:  67.50%, tr:  76.71%, tr_best:  76.71%\n",
      "epoch-84  lr=['0.0010000'], tr/val_loss:  0.891970/  1.343423, val:  65.83%, val_best:  67.50%, tr:  76.81%, tr_best:  76.81%\n",
      "epoch-85  lr=['0.0010000'], tr/val_loss:  0.894295/  1.363688, val:  62.08%, val_best:  67.50%, tr:  77.22%, tr_best:  77.22%\n",
      "epoch-86  lr=['0.0010000'], tr/val_loss:  0.878292/  1.348996, val:  65.42%, val_best:  67.50%, tr:  74.97%, tr_best:  77.22%\n",
      "epoch-87  lr=['0.0010000'], tr/val_loss:  0.884089/  1.343747, val:  67.92%, val_best:  67.92%, tr:  78.75%, tr_best:  78.75%\n",
      "epoch-88  lr=['0.0010000'], tr/val_loss:  0.872590/  1.361964, val:  65.00%, val_best:  67.92%, tr:  76.40%, tr_best:  78.75%\n",
      "epoch-89  lr=['0.0010000'], tr/val_loss:  0.866914/  1.392727, val:  64.17%, val_best:  67.92%, tr:  77.73%, tr_best:  78.75%\n",
      "epoch-90  lr=['0.0010000'], tr/val_loss:  0.873768/  1.358134, val:  69.17%, val_best:  69.17%, tr:  73.95%, tr_best:  78.75%\n",
      "epoch-91  lr=['0.0010000'], tr/val_loss:  0.856826/  1.356740, val:  66.67%, val_best:  69.17%, tr:  77.22%, tr_best:  78.75%\n",
      "epoch-92  lr=['0.0010000'], tr/val_loss:  0.856895/  1.382667, val:  65.83%, val_best:  69.17%, tr:  77.43%, tr_best:  78.75%\n",
      "epoch-93  lr=['0.0010000'], tr/val_loss:  0.865155/  1.365626, val:  65.00%, val_best:  69.17%, tr:  76.10%, tr_best:  78.75%\n",
      "epoch-94  lr=['0.0010000'], tr/val_loss:  0.847984/  1.367937, val:  67.92%, val_best:  69.17%, tr:  76.51%, tr_best:  78.75%\n",
      "epoch-95  lr=['0.0010000'], tr/val_loss:  0.842548/  1.369490, val:  65.83%, val_best:  69.17%, tr:  77.83%, tr_best:  78.75%\n",
      "epoch-96  lr=['0.0010000'], tr/val_loss:  0.840574/  1.392949, val:  63.33%, val_best:  69.17%, tr:  78.65%, tr_best:  78.75%\n",
      "epoch-97  lr=['0.0010000'], tr/val_loss:  0.834043/  1.368629, val:  67.50%, val_best:  69.17%, tr:  76.71%, tr_best:  78.75%\n",
      "epoch-98  lr=['0.0010000'], tr/val_loss:  0.831969/  1.389201, val:  68.33%, val_best:  69.17%, tr:  79.06%, tr_best:  79.06%\n",
      "epoch-99  lr=['0.0010000'], tr/val_loss:  0.834875/  1.375500, val:  68.75%, val_best:  69.17%, tr:  77.53%, tr_best:  79.06%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d57b8878a6ab482bb22a27b1263f1865",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.006 MB of 0.006 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>iter_acc</td><td>▁▂▁▁▁▂▃▄▄▅▆█▆▄▅▆▆▅▇▅▅▆▅▅▇█▇▇▇▅▇▇▅▇▆▆▅▇█▆</td></tr><tr><td>summary_val_acc</td><td>▁▁▁▁▁▂▃▅▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇█▇▇▇█▇██████████</td></tr><tr><td>tr_acc</td><td>▁▁▁▁▁▂▂▅▅▆▆▆▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇█▇█████████</td></tr><tr><td>tr_epoch_loss</td><td>██████▇▆▅▄▄▄▃▃▃▃▃▃▂▂▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_acc_best</td><td>▁▁▁▁▁▂▃▅▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇█████████████████</td></tr><tr><td>val_acc_now</td><td>▁▁▁▁▁▂▃▅▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇█▇▇▇█▇██████████</td></tr><tr><td>val_loss</td><td>██████▇▅▄▃▃▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>99</td></tr><tr><td>iter_acc</td><td>1.0</td></tr><tr><td>tr_acc</td><td>0.77528</td></tr><tr><td>tr_epoch_loss</td><td>0.83488</td></tr><tr><td>val_acc_best</td><td>0.69167</td></tr><tr><td>val_acc_now</td><td>0.6875</td></tr><tr><td>val_loss</td><td>1.3755</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">electric-sweep-176</strong> at: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/p92xo0e1' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/p92xo0e1</a><br/> View project at: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>/data2/bh_wandb/wandb/run-20250430_043040-p92xo0e1/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require(\"core\")`! See https://wandb.me/wandb-core for more information."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Sweep Agent: Waiting for job.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Job received.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: g4f4hks8 with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBATCH: 16\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBN_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBPTT_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tDFA_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tIMAGE_SIZE: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tOTTT_input_trace_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tTIME: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tUDA_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \talpha_uda: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbias: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcfg: ['M', 'M', 200, 200]\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tchaching_on: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tconvTrue_fcFalse: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdata_path: /data2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tddp_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdenoise_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdvs_clipping: 5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdvs_duration: 100000\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepoch_num: 100\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \texclude_class: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \textra_train_dataset: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlast_lif: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.001\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_sg_width: 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_decay: 0.5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_init: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_reset: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_threshold: 0.5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmerge_polarities: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmy_seed: 42\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnet_print: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_workers: 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer_what: SGD\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tpin_memory: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tpre_trained: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tpre_trained_path: net_save/save_now_net_weights_{unique_name}.pth\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \trate_coding: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tscheduler_name: no\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsingle_step: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsurrogate: hard_sigmoid\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_conv_kernel_size: 3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_conv_padding: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_conv_stride: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_trace_const1: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_trace_const2: 0.5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \ttdBN_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \ttrace_on: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \twhich_data: DVS_GESTURE_TONIC\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.19.10 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.17.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/data2/bh_wandb/wandb/run-20250430_043647-g4f4hks8</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/g4f4hks8' target=\"_blank\">classic-sweep-178</a></strong> to <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/6pj3lh8j' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/6pj3lh8j</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/6pj3lh8j' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/6pj3lh8j</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/g4f4hks8' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/g4f4hks8</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'single_step' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'my_seed' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'TIME' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BATCH' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'IMAGE_SIZE' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'which_data' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'data_path' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'rate_coding' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_init' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_decay' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_threshold' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_reset' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_sg_width' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_conv_kernel_size' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_conv_stride' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_conv_padding' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_trace_const1' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_trace_const2' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'pre_trained' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'convTrue_fcFalse' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'cfg' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'net_print' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'pre_trained_path' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'learning_rate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'epoch_num' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'tdBN_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BN_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'surrogate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BPTT_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'optimizer_what' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'scheduler_name' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'ddp_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'dvs_clipping' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'dvs_duration' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'DFA_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'trace_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'OTTT_input_trace_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'exclude_class' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'merge_polarities' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'denoise_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'extra_train_dataset' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'num_workers' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'chaching_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'pin_memory' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'UDA_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'alpha_uda' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'bias' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'last_lif' was locked by 'sweep' (ignored update).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "param {'devices': '0', 'single_step': True, 'unique_name': 'main', 'my_seed': 42, 'TIME': 10, 'BATCH': 16, 'IMAGE_SIZE': 128, 'which_data': 'DVS_GESTURE_TONIC', 'data_path': '/data2', 'rate_coding': False, 'lif_layer_v_init': 0, 'lif_layer_v_decay': 0.5, 'lif_layer_v_threshold': 0.5, 'lif_layer_v_reset': 0, 'lif_layer_sg_width': 2, 'synapse_conv_kernel_size': 3, 'synapse_conv_stride': 1, 'synapse_conv_padding': 1, 'synapse_trace_const1': 1, 'synapse_trace_const2': 0.5, 'pre_trained': False, 'convTrue_fcFalse': False, 'cfg': ['M', 'M', 200, 200], 'net_print': True, 'pre_trained_path': 'net_save/save_now_net_weights_{unique_name}.pth', 'learning_rate': 0.001, 'epoch_num': 100, 'tdBN_on': False, 'BN_on': False, 'surrogate': 'hard_sigmoid', 'BPTT_on': False, 'optimizer_what': 'SGD', 'scheduler_name': 'no', 'ddp_on': False, 'dvs_clipping': 5, 'dvs_duration': 100000, 'DFA_on': False, 'trace_on': True, 'OTTT_input_trace_on': False, 'exclude_class': True, 'merge_polarities': False, 'denoise_on': False, 'extra_train_dataset': 0, 'num_workers': 2, 'chaching_on': True, 'pin_memory': True, 'UDA_on': False, 'alpha_uda': 1, 'bias': True, 'last_lif': False, 'current epoch': 0} \n",
      "\n",
      "dataset_hash = ffa516e60c3efd5e0208f72b4c36cb84\n",
      "cache path exists\n",
      "\n",
      "device ==> cuda\n",
      "\n",
      "DataParallel(\n",
      "  (module): REBORN_MY_SNN_FC(\n",
      "    (layers): REBORN_MY_Sequential(\n",
      "      (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (2): DimChanger_for_FC()\n",
      "      (3): SYNAPSE_FC(in_features=2048, out_features=200, TIME=10, bias=True, sstep=True)\n",
      "      (4): LIF_layer(v_init=0, v_decay=0.5, v_threshold=0.5, v_reset=0, sg_width=2, surrogate=hard_sigmoid, BPTT_on=False, trace_const1=1, trace_const2=0.5, TIME=10, sstep=True, trace_on=True)\n",
      "      (5): SYNAPSE_FC(in_features=200, out_features=200, TIME=10, bias=True, sstep=True)\n",
      "      (6): LIF_layer(v_init=0, v_decay=0.5, v_threshold=0.5, v_reset=0, sg_width=2, surrogate=hard_sigmoid, BPTT_on=False, trace_const1=1, trace_const2=0.5, TIME=10, sstep=True, trace_on=True)\n",
      "      (7): SYNAPSE_FC(in_features=200, out_features=10, TIME=10, bias=True, sstep=True)\n",
      "    )\n",
      "  )\n",
      ")\n",
      "\n",
      "========================================================\n",
      "Trainable parameters: 452,010\n",
      "========================================================\n",
      "\n",
      "epoch-0   lr=['0.0010000'], tr/val_loss:  2.305335/  2.302730, val:  10.42%, val_best:  10.42%, tr:   8.27%, tr_best:   8.27%\n",
      "epoch-1   lr=['0.0010000'], tr/val_loss:  2.298928/  2.285923, val:  15.00%, val_best:  15.00%, tr:  10.11%, tr_best:  10.11%\n",
      "epoch-2   lr=['0.0010000'], tr/val_loss:  2.190251/  2.102463, val:  30.42%, val_best:  30.42%, tr:  22.68%, tr_best:  22.68%\n",
      "epoch-3   lr=['0.0010000'], tr/val_loss:  1.854487/  1.751195, val:  45.00%, val_best:  45.00%, tr:  42.70%, tr_best:  42.70%\n",
      "epoch-4   lr=['0.0010000'], tr/val_loss:  1.541854/  1.592240, val:  49.58%, val_best:  49.58%, tr:  52.09%, tr_best:  52.09%\n",
      "epoch-5   lr=['0.0010000'], tr/val_loss:  1.375954/  1.485968, val:  55.00%, val_best:  55.00%, tr:  57.20%, tr_best:  57.20%\n",
      "epoch-6   lr=['0.0010000'], tr/val_loss:  1.267380/  1.412376, val:  55.42%, val_best:  55.42%, tr:  60.78%, tr_best:  60.78%\n",
      "epoch-7   lr=['0.0010000'], tr/val_loss:  1.196653/  1.368890, val:  57.50%, val_best:  57.50%, tr:  61.90%, tr_best:  61.90%\n",
      "epoch-8   lr=['0.0010000'], tr/val_loss:  1.119388/  1.348692, val:  59.17%, val_best:  59.17%, tr:  63.84%, tr_best:  63.84%\n",
      "epoch-9   lr=['0.0010000'], tr/val_loss:  1.073525/  1.317918, val:  60.00%, val_best:  60.00%, tr:  68.23%, tr_best:  68.23%\n",
      "epoch-10  lr=['0.0010000'], tr/val_loss:  1.031259/  1.337530, val:  60.00%, val_best:  60.00%, tr:  66.91%, tr_best:  68.23%\n",
      "epoch-11  lr=['0.0010000'], tr/val_loss:  0.983959/  1.285505, val:  64.17%, val_best:  64.17%, tr:  69.66%, tr_best:  69.66%\n",
      "epoch-12  lr=['0.0010000'], tr/val_loss:  0.960951/  1.307489, val:  62.92%, val_best:  64.17%, tr:  71.81%, tr_best:  71.81%\n",
      "epoch-13  lr=['0.0010000'], tr/val_loss:  0.919833/  1.316090, val:  66.25%, val_best:  66.25%, tr:  73.54%, tr_best:  73.54%\n",
      "epoch-14  lr=['0.0010000'], tr/val_loss:  0.861376/  1.345087, val:  61.25%, val_best:  66.25%, tr:  74.46%, tr_best:  74.46%\n",
      "epoch-15  lr=['0.0010000'], tr/val_loss:  0.838058/  1.380210, val:  63.33%, val_best:  66.25%, tr:  76.40%, tr_best:  76.40%\n",
      "epoch-16  lr=['0.0010000'], tr/val_loss:  0.861367/  1.304255, val:  67.50%, val_best:  67.50%, tr:  75.69%, tr_best:  76.40%\n",
      "epoch-17  lr=['0.0010000'], tr/val_loss:  0.784357/  1.330564, val:  67.92%, val_best:  67.92%, tr:  79.16%, tr_best:  79.16%\n",
      "epoch-18  lr=['0.0010000'], tr/val_loss:  0.764478/  1.388069, val:  65.00%, val_best:  67.92%, tr:  79.67%, tr_best:  79.67%\n",
      "epoch-19  lr=['0.0010000'], tr/val_loss:  0.741361/  1.461209, val:  60.83%, val_best:  67.92%, tr:  78.04%, tr_best:  79.67%\n",
      "epoch-20  lr=['0.0010000'], tr/val_loss:  0.708434/  1.472666, val:  63.75%, val_best:  67.92%, tr:  82.23%, tr_best:  82.23%\n",
      "epoch-21  lr=['0.0010000'], tr/val_loss:  0.689522/  1.420932, val:  71.67%, val_best:  71.67%, tr:  82.94%, tr_best:  82.94%\n",
      "epoch-22  lr=['0.0010000'], tr/val_loss:  0.711677/  1.423519, val:  69.17%, val_best:  71.67%, tr:  81.31%, tr_best:  82.94%\n",
      "epoch-23  lr=['0.0010000'], tr/val_loss:  0.642195/  1.501303, val:  72.08%, val_best:  72.08%, tr:  83.86%, tr_best:  83.86%\n",
      "epoch-24  lr=['0.0010000'], tr/val_loss:  0.606339/  1.585730, val:  66.25%, val_best:  72.08%, tr:  89.38%, tr_best:  89.38%\n",
      "epoch-25  lr=['0.0010000'], tr/val_loss:  0.592687/  1.603682, val:  72.08%, val_best:  72.08%, tr:  86.52%, tr_best:  89.38%\n",
      "epoch-26  lr=['0.0010000'], tr/val_loss:  0.579996/  1.653817, val:  69.58%, val_best:  72.08%, tr:  88.25%, tr_best:  89.38%\n",
      "epoch-27  lr=['0.0010000'], tr/val_loss:  0.572333/  1.765298, val:  72.08%, val_best:  72.08%, tr:  88.97%, tr_best:  89.38%\n",
      "epoch-28  lr=['0.0010000'], tr/val_loss:  0.568824/  1.815350, val:  69.17%, val_best:  72.08%, tr:  90.09%, tr_best:  90.09%\n",
      "epoch-29  lr=['0.0010000'], tr/val_loss:  0.524710/  1.927538, val:  65.00%, val_best:  72.08%, tr:  92.75%, tr_best:  92.75%\n",
      "epoch-30  lr=['0.0010000'], tr/val_loss:  0.506414/  1.924554, val:  68.33%, val_best:  72.08%, tr:  92.95%, tr_best:  92.95%\n",
      "epoch-31  lr=['0.0010000'], tr/val_loss:  0.513724/  1.950304, val:  68.75%, val_best:  72.08%, tr:  92.34%, tr_best:  92.95%\n",
      "epoch-32  lr=['0.0010000'], tr/val_loss:  0.484339/  2.035247, val:  65.00%, val_best:  72.08%, tr:  93.56%, tr_best:  93.56%\n",
      "epoch-33  lr=['0.0010000'], tr/val_loss:  0.461529/  2.038419, val:  68.33%, val_best:  72.08%, tr:  94.89%, tr_best:  94.89%\n",
      "epoch-34  lr=['0.0010000'], tr/val_loss:  0.441696/  2.142639, val:  63.75%, val_best:  72.08%, tr:  95.81%, tr_best:  95.81%\n",
      "epoch-35  lr=['0.0010000'], tr/val_loss:  0.471520/  2.293758, val:  63.75%, val_best:  72.08%, tr:  91.52%, tr_best:  95.81%\n",
      "epoch-36  lr=['0.0010000'], tr/val_loss:  0.432118/  2.194885, val:  67.50%, val_best:  72.08%, tr:  95.20%, tr_best:  95.81%\n",
      "epoch-37  lr=['0.0010000'], tr/val_loss:  0.381729/  2.336020, val:  70.00%, val_best:  72.08%, tr:  96.94%, tr_best:  96.94%\n",
      "epoch-38  lr=['0.0010000'], tr/val_loss:  0.412720/  2.415828, val:  65.00%, val_best:  72.08%, tr:  96.63%, tr_best:  96.94%\n",
      "epoch-39  lr=['0.0010000'], tr/val_loss:  0.397501/  2.390092, val:  67.50%, val_best:  72.08%, tr:  96.42%, tr_best:  96.94%\n",
      "epoch-40  lr=['0.0010000'], tr/val_loss:  0.392429/  2.516358, val:  68.33%, val_best:  72.08%, tr:  96.22%, tr_best:  96.94%\n",
      "epoch-41  lr=['0.0010000'], tr/val_loss:  0.367740/  2.497230, val:  65.83%, val_best:  72.08%, tr:  97.04%, tr_best:  97.04%\n",
      "epoch-42  lr=['0.0010000'], tr/val_loss:  0.313856/  2.517081, val:  69.17%, val_best:  72.08%, tr:  98.67%, tr_best:  98.67%\n",
      "epoch-43  lr=['0.0010000'], tr/val_loss:  0.334586/  2.640560, val:  65.83%, val_best:  72.08%, tr:  97.85%, tr_best:  98.67%\n",
      "epoch-44  lr=['0.0010000'], tr/val_loss:  0.337923/  2.678982, val:  69.17%, val_best:  72.08%, tr:  97.75%, tr_best:  98.67%\n",
      "epoch-45  lr=['0.0010000'], tr/val_loss:  0.307559/  2.750584, val:  67.92%, val_best:  72.08%, tr:  98.67%, tr_best:  98.67%\n",
      "epoch-46  lr=['0.0010000'], tr/val_loss:  0.310683/  2.784333, val:  70.42%, val_best:  72.08%, tr:  98.88%, tr_best:  98.88%\n",
      "epoch-47  lr=['0.0010000'], tr/val_loss:  0.283356/  2.859270, val:  69.17%, val_best:  72.08%, tr:  99.39%, tr_best:  99.39%\n",
      "epoch-48  lr=['0.0010000'], tr/val_loss:  0.337596/  2.823620, val:  72.92%, val_best:  72.92%, tr:  99.18%, tr_best:  99.39%\n",
      "epoch-49  lr=['0.0010000'], tr/val_loss:  0.261117/  2.926277, val:  71.67%, val_best:  72.92%, tr:  99.80%, tr_best:  99.80%\n",
      "epoch-50  lr=['0.0010000'], tr/val_loss:  0.230336/  2.997247, val:  72.92%, val_best:  72.92%, tr:  99.69%, tr_best:  99.80%\n",
      "epoch-51  lr=['0.0010000'], tr/val_loss:  0.244130/  3.060686, val:  70.00%, val_best:  72.92%, tr:  99.39%, tr_best:  99.80%\n",
      "epoch-52  lr=['0.0010000'], tr/val_loss:  0.217510/  3.211040, val:  70.00%, val_best:  72.92%, tr:  99.39%, tr_best:  99.80%\n",
      "epoch-53  lr=['0.0010000'], tr/val_loss:  0.210469/  3.324006, val:  67.50%, val_best:  72.92%, tr:  99.80%, tr_best:  99.80%\n",
      "epoch-54  lr=['0.0010000'], tr/val_loss:  0.193709/  3.316955, val:  69.17%, val_best:  72.92%, tr:  99.90%, tr_best:  99.90%\n",
      "epoch-55  lr=['0.0010000'], tr/val_loss:  0.206788/  3.331807, val:  67.50%, val_best:  72.92%, tr:  99.59%, tr_best:  99.90%\n",
      "epoch-56  lr=['0.0010000'], tr/val_loss:  0.175577/  3.394658, val:  68.33%, val_best:  72.92%, tr:  99.80%, tr_best:  99.90%\n",
      "epoch-57  lr=['0.0010000'], tr/val_loss:  0.178744/  3.473814, val:  68.75%, val_best:  72.92%, tr:  99.90%, tr_best:  99.90%\n",
      "epoch-58  lr=['0.0010000'], tr/val_loss:  0.188294/  3.536150, val:  68.75%, val_best:  72.92%, tr:  99.59%, tr_best:  99.90%\n",
      "epoch-59  lr=['0.0010000'], tr/val_loss:  0.174675/  3.546414, val:  71.25%, val_best:  72.92%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-60  lr=['0.0010000'], tr/val_loss:  0.171084/  3.806917, val:  68.75%, val_best:  72.92%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-61  lr=['0.0010000'], tr/val_loss:  0.186628/  3.810340, val:  64.17%, val_best:  72.92%, tr:  99.39%, tr_best: 100.00%\n",
      "epoch-62  lr=['0.0010000'], tr/val_loss:  0.164831/  3.805079, val:  68.33%, val_best:  72.92%, tr:  99.90%, tr_best: 100.00%\n",
      "epoch-63  lr=['0.0010000'], tr/val_loss:  0.135631/  3.839828, val:  69.17%, val_best:  72.92%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-64  lr=['0.0010000'], tr/val_loss:  0.144701/  3.799099, val:  70.00%, val_best:  72.92%, tr:  99.90%, tr_best: 100.00%\n",
      "epoch-65  lr=['0.0010000'], tr/val_loss:  0.149732/  3.896490, val:  69.58%, val_best:  72.92%, tr:  99.59%, tr_best: 100.00%\n",
      "epoch-66  lr=['0.0010000'], tr/val_loss:  0.116518/  3.950154, val:  71.25%, val_best:  72.92%, tr:  99.90%, tr_best: 100.00%\n",
      "epoch-67  lr=['0.0010000'], tr/val_loss:  0.108677/  4.027049, val:  73.33%, val_best:  73.33%, tr:  99.90%, tr_best: 100.00%\n",
      "epoch-68  lr=['0.0010000'], tr/val_loss:  0.106556/  4.024544, val:  68.33%, val_best:  73.33%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-69  lr=['0.0010000'], tr/val_loss:  0.118445/  4.068649, val:  69.58%, val_best:  73.33%, tr:  99.90%, tr_best: 100.00%\n",
      "epoch-70  lr=['0.0010000'], tr/val_loss:  0.095056/  4.090245, val:  71.25%, val_best:  73.33%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-71  lr=['0.0010000'], tr/val_loss:  0.105595/  4.099461, val:  71.67%, val_best:  73.33%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-72  lr=['0.0010000'], tr/val_loss:  0.100965/  4.210424, val:  67.92%, val_best:  73.33%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-73  lr=['0.0010000'], tr/val_loss:  0.093544/  4.372069, val:  68.75%, val_best:  73.33%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-74  lr=['0.0010000'], tr/val_loss:  0.074393/  4.273476, val:  69.58%, val_best:  73.33%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-75  lr=['0.0010000'], tr/val_loss:  0.087237/  4.458177, val:  68.33%, val_best:  73.33%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-76  lr=['0.0010000'], tr/val_loss:  0.073673/  4.375652, val:  68.75%, val_best:  73.33%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-77  lr=['0.0010000'], tr/val_loss:  0.074078/  4.412556, val:  70.42%, val_best:  73.33%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-78  lr=['0.0010000'], tr/val_loss:  0.090579/  4.587612, val:  68.33%, val_best:  73.33%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-79  lr=['0.0010000'], tr/val_loss:  0.076993/  4.579108, val:  68.33%, val_best:  73.33%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-80  lr=['0.0010000'], tr/val_loss:  0.065054/  4.529312, val:  71.25%, val_best:  73.33%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-81  lr=['0.0010000'], tr/val_loss:  0.064361/  4.533854, val:  70.42%, val_best:  73.33%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-82  lr=['0.0010000'], tr/val_loss:  0.074212/  4.592847, val:  71.25%, val_best:  73.33%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-83  lr=['0.0010000'], tr/val_loss:  0.062271/  4.692473, val:  69.58%, val_best:  73.33%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-84  lr=['0.0010000'], tr/val_loss:  0.077649/  4.612799, val:  72.08%, val_best:  73.33%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-85  lr=['0.0010000'], tr/val_loss:  0.052686/  4.756680, val:  67.50%, val_best:  73.33%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-86  lr=['0.0010000'], tr/val_loss:  0.056763/  4.773787, val:  68.33%, val_best:  73.33%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-87  lr=['0.0010000'], tr/val_loss:  0.047203/  4.711028, val:  70.00%, val_best:  73.33%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-88  lr=['0.0010000'], tr/val_loss:  0.042547/  4.695083, val:  71.25%, val_best:  73.33%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-89  lr=['0.0010000'], tr/val_loss:  0.055819/  4.723274, val:  67.50%, val_best:  73.33%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-90  lr=['0.0010000'], tr/val_loss:  0.048479/  4.753573, val:  70.00%, val_best:  73.33%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-91  lr=['0.0010000'], tr/val_loss:  0.049483/  4.781561, val:  68.75%, val_best:  73.33%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-92  lr=['0.0010000'], tr/val_loss:  0.053327/  4.920493, val:  69.17%, val_best:  73.33%, tr:  99.90%, tr_best: 100.00%\n",
      "epoch-93  lr=['0.0010000'], tr/val_loss:  0.046289/  4.857379, val:  70.00%, val_best:  73.33%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-94  lr=['0.0010000'], tr/val_loss:  0.045625/  4.911509, val:  69.58%, val_best:  73.33%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-95  lr=['0.0010000'], tr/val_loss:  0.043175/  4.839859, val:  71.25%, val_best:  73.33%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-96  lr=['0.0010000'], tr/val_loss:  0.041049/  4.998406, val:  67.50%, val_best:  73.33%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-97  lr=['0.0010000'], tr/val_loss:  0.035018/  4.904465, val:  72.50%, val_best:  73.33%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-98  lr=['0.0010000'], tr/val_loss:  0.026374/  4.928275, val:  70.00%, val_best:  73.33%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-99  lr=['0.0010000'], tr/val_loss:  0.043702/  5.070998, val:  70.42%, val_best:  73.33%, tr: 100.00%, tr_best: 100.00%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1ca7c7bb473e4c57b56b024ddf90d05b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.006 MB of 0.006 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>iter_acc</td><td>▁▄▅▅▄▇▇▃▆▇█▇█▇▇█████████████████████████</td></tr><tr><td>summary_val_acc</td><td>▁▃▅▆▇▇▇▇▇█▇█▇▇▇█▇██████▇█▇███▇▇█▇███▇███</td></tr><tr><td>tr_acc</td><td>▁▂▄▅▆▆▆▆▆▇▇▇▇█▇█████████████████████████</td></tr><tr><td>tr_epoch_loss</td><td>██▆▅▄▄▄▃▃▃▃▃▃▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_acc_best</td><td>▁▃▅▆▇▇▇▇▇███████████████████████████████</td></tr><tr><td>val_acc_now</td><td>▁▃▅▆▇▇▇▇▇█▇█▇▇▇█▇██████▇█▇███▇▇█▇███▇███</td></tr><tr><td>val_loss</td><td>▃▃▂▁▁▁▁▁▁▁▂▂▂▂▃▃▃▃▄▄▄▅▅▅▅▆▆▆▆▇▇▇▇▇▇█████</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>99</td></tr><tr><td>iter_acc</td><td>1.0</td></tr><tr><td>tr_acc</td><td>1.0</td></tr><tr><td>tr_epoch_loss</td><td>0.0437</td></tr><tr><td>val_acc_best</td><td>0.73333</td></tr><tr><td>val_acc_now</td><td>0.70417</td></tr><tr><td>val_loss</td><td>5.071</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">classic-sweep-178</strong> at: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/g4f4hks8' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/g4f4hks8</a><br/> View project at: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>/data2/bh_wandb/wandb/run-20250430_043647-g4f4hks8/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require(\"core\")`! See https://wandb.me/wandb-core for more information."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: cwzymixu with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBATCH: 16\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBN_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBPTT_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tDFA_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tIMAGE_SIZE: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tOTTT_input_trace_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tTIME: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tUDA_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \talpha_uda: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbias: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcfg: ['M', 'M', 200, 200]\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tchaching_on: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tconvTrue_fcFalse: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdata_path: /data2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tddp_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdenoise_on: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdvs_clipping: 5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdvs_duration: 100000\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepoch_num: 100\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \texclude_class: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \textra_train_dataset: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlast_lif: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.001\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_sg_width: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_decay: 0.5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_init: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_reset: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_threshold: 0.25\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmerge_polarities: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmy_seed: 42\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnet_print: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_workers: 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer_what: SGD\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tpin_memory: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tpre_trained: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tpre_trained_path: net_save/save_now_net_weights_{unique_name}.pth\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \trate_coding: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tscheduler_name: no\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsingle_step: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsurrogate: hard_sigmoid\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_conv_kernel_size: 3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_conv_padding: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_conv_stride: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_trace_const1: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_trace_const2: 0.5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \ttdBN_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \ttrace_on: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \twhich_data: DVS_GESTURE_TONIC\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.19.10 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.17.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/data2/bh_wandb/wandb/run-20250430_044239-cwzymixu</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/cwzymixu' target=\"_blank\">twilight-sweep-180</a></strong> to <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/6pj3lh8j' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/6pj3lh8j</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/6pj3lh8j' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/6pj3lh8j</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/cwzymixu' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/cwzymixu</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'single_step' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'my_seed' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'TIME' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BATCH' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'IMAGE_SIZE' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'which_data' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'data_path' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'rate_coding' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_init' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_decay' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_threshold' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_reset' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_sg_width' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_conv_kernel_size' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_conv_stride' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_conv_padding' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_trace_const1' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_trace_const2' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'pre_trained' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'convTrue_fcFalse' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'cfg' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'net_print' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'pre_trained_path' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'learning_rate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'epoch_num' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'tdBN_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BN_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'surrogate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BPTT_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'optimizer_what' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'scheduler_name' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'ddp_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'dvs_clipping' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'dvs_duration' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'DFA_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'trace_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'OTTT_input_trace_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'exclude_class' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'merge_polarities' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'denoise_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'extra_train_dataset' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'num_workers' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'chaching_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'pin_memory' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'UDA_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'alpha_uda' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'bias' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'last_lif' was locked by 'sweep' (ignored update).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "param {'devices': '0', 'single_step': True, 'unique_name': 'main', 'my_seed': 42, 'TIME': 10, 'BATCH': 16, 'IMAGE_SIZE': 128, 'which_data': 'DVS_GESTURE_TONIC', 'data_path': '/data2', 'rate_coding': False, 'lif_layer_v_init': 0, 'lif_layer_v_decay': 0.5, 'lif_layer_v_threshold': 0.25, 'lif_layer_v_reset': 0, 'lif_layer_sg_width': 1, 'synapse_conv_kernel_size': 3, 'synapse_conv_stride': 1, 'synapse_conv_padding': 1, 'synapse_trace_const1': 1, 'synapse_trace_const2': 0.5, 'pre_trained': False, 'convTrue_fcFalse': False, 'cfg': ['M', 'M', 200, 200], 'net_print': True, 'pre_trained_path': 'net_save/save_now_net_weights_{unique_name}.pth', 'learning_rate': 0.001, 'epoch_num': 100, 'tdBN_on': False, 'BN_on': False, 'surrogate': 'hard_sigmoid', 'BPTT_on': False, 'optimizer_what': 'SGD', 'scheduler_name': 'no', 'ddp_on': False, 'dvs_clipping': 5, 'dvs_duration': 100000, 'DFA_on': False, 'trace_on': True, 'OTTT_input_trace_on': False, 'exclude_class': True, 'merge_polarities': False, 'denoise_on': True, 'extra_train_dataset': 0, 'num_workers': 2, 'chaching_on': True, 'pin_memory': True, 'UDA_on': False, 'alpha_uda': 1, 'bias': True, 'last_lif': False, 'current epoch': 0} \n",
      "\n",
      "dataset_hash = 63cc597115630ec173f3099200061e53\n",
      "cache path exists\n",
      "\n",
      "device ==> cuda\n",
      "\n",
      "DataParallel(\n",
      "  (module): REBORN_MY_SNN_FC(\n",
      "    (layers): REBORN_MY_Sequential(\n",
      "      (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (2): DimChanger_for_FC()\n",
      "      (3): SYNAPSE_FC(in_features=2048, out_features=200, TIME=10, bias=True, sstep=True)\n",
      "      (4): LIF_layer(v_init=0, v_decay=0.5, v_threshold=0.25, v_reset=0, sg_width=1, surrogate=hard_sigmoid, BPTT_on=False, trace_const1=1, trace_const2=0.5, TIME=10, sstep=True, trace_on=True)\n",
      "      (5): SYNAPSE_FC(in_features=200, out_features=200, TIME=10, bias=True, sstep=True)\n",
      "      (6): LIF_layer(v_init=0, v_decay=0.5, v_threshold=0.25, v_reset=0, sg_width=1, surrogate=hard_sigmoid, BPTT_on=False, trace_const1=1, trace_const2=0.5, TIME=10, sstep=True, trace_on=True)\n",
      "      (7): SYNAPSE_FC(in_features=200, out_features=10, TIME=10, bias=True, sstep=True)\n",
      "    )\n",
      "  )\n",
      ")\n",
      "\n",
      "========================================================\n",
      "Trainable parameters: 452,010\n",
      "========================================================\n",
      "\n",
      "epoch-0   lr=['0.0010000'], tr/val_loss:  2.271144/  2.213912, val:  23.75%, val_best:  23.75%, tr:  13.69%, tr_best:  13.69%\n",
      "epoch-1   lr=['0.0010000'], tr/val_loss:  2.119504/  2.065082, val:  38.33%, val_best:  38.33%, tr:  27.89%, tr_best:  27.89%\n",
      "epoch-2   lr=['0.0010000'], tr/val_loss:  1.917099/  1.901326, val:  46.25%, val_best:  46.25%, tr:  40.86%, tr_best:  40.86%\n",
      "epoch-3   lr=['0.0010000'], tr/val_loss:  1.712377/  1.767536, val:  50.00%, val_best:  50.00%, tr:  48.93%, tr_best:  48.93%\n",
      "epoch-4   lr=['0.0010000'], tr/val_loss:  1.567230/  1.685006, val:  50.42%, val_best:  50.42%, tr:  54.34%, tr_best:  54.34%\n",
      "epoch-5   lr=['0.0010000'], tr/val_loss:  1.459769/  1.610650, val:  54.58%, val_best:  54.58%, tr:  56.59%, tr_best:  56.59%\n",
      "epoch-6   lr=['0.0010000'], tr/val_loss:  1.398363/  1.574295, val:  57.50%, val_best:  57.50%, tr:  60.47%, tr_best:  60.47%\n",
      "epoch-7   lr=['0.0010000'], tr/val_loss:  1.341755/  1.544551, val:  55.83%, val_best:  57.50%, tr:  60.67%, tr_best:  60.67%\n",
      "epoch-8   lr=['0.0010000'], tr/val_loss:  1.300183/  1.523292, val:  60.00%, val_best:  60.00%, tr:  61.08%, tr_best:  61.08%\n",
      "epoch-9   lr=['0.0010000'], tr/val_loss:  1.271581/  1.513263, val:  53.75%, val_best:  60.00%, tr:  64.15%, tr_best:  64.15%\n",
      "epoch-10  lr=['0.0010000'], tr/val_loss:  1.239508/  1.501374, val:  59.58%, val_best:  60.00%, tr:  63.74%, tr_best:  64.15%\n",
      "epoch-11  lr=['0.0010000'], tr/val_loss:  1.207462/  1.475154, val:  59.17%, val_best:  60.00%, tr:  64.96%, tr_best:  64.96%\n",
      "epoch-12  lr=['0.0010000'], tr/val_loss:  1.185769/  1.452586, val:  55.83%, val_best:  60.00%, tr:  66.91%, tr_best:  66.91%\n",
      "epoch-13  lr=['0.0010000'], tr/val_loss:  1.169933/  1.438281, val:  59.58%, val_best:  60.00%, tr:  66.80%, tr_best:  66.91%\n",
      "epoch-14  lr=['0.0010000'], tr/val_loss:  1.118432/  1.456435, val:  58.33%, val_best:  60.00%, tr:  68.44%, tr_best:  68.44%\n",
      "epoch-15  lr=['0.0010000'], tr/val_loss:  1.113631/  1.436250, val:  61.67%, val_best:  61.67%, tr:  69.15%, tr_best:  69.15%\n",
      "epoch-16  lr=['0.0010000'], tr/val_loss:  1.099342/  1.413429, val:  57.08%, val_best:  61.67%, tr:  69.66%, tr_best:  69.66%\n",
      "epoch-17  lr=['0.0010000'], tr/val_loss:  1.063788/  1.389606, val:  63.33%, val_best:  63.33%, tr:  73.95%, tr_best:  73.95%\n",
      "epoch-18  lr=['0.0010000'], tr/val_loss:  1.044016/  1.458339, val:  57.50%, val_best:  63.33%, tr:  73.44%, tr_best:  73.95%\n",
      "epoch-19  lr=['0.0010000'], tr/val_loss:  1.037125/  1.461781, val:  60.42%, val_best:  63.33%, tr:  70.17%, tr_best:  73.95%\n",
      "epoch-20  lr=['0.0010000'], tr/val_loss:  1.008587/  1.436370, val:  59.58%, val_best:  63.33%, tr:  75.59%, tr_best:  75.59%\n",
      "epoch-21  lr=['0.0010000'], tr/val_loss:  0.995020/  1.407226, val:  62.92%, val_best:  63.33%, tr:  76.40%, tr_best:  76.40%\n",
      "epoch-22  lr=['0.0010000'], tr/val_loss:  1.010781/  1.402310, val:  60.83%, val_best:  63.33%, tr:  72.63%, tr_best:  76.40%\n",
      "epoch-23  lr=['0.0010000'], tr/val_loss:  0.974947/  1.412822, val:  65.83%, val_best:  65.83%, tr:  77.12%, tr_best:  77.12%\n",
      "epoch-24  lr=['0.0010000'], tr/val_loss:  0.953457/  1.447899, val:  62.08%, val_best:  65.83%, tr:  78.14%, tr_best:  78.14%\n",
      "epoch-25  lr=['0.0010000'], tr/val_loss:  0.945204/  1.432182, val:  65.00%, val_best:  65.83%, tr:  78.75%, tr_best:  78.75%\n",
      "epoch-26  lr=['0.0010000'], tr/val_loss:  0.930286/  1.402901, val:  68.33%, val_best:  68.33%, tr:  77.73%, tr_best:  78.75%\n",
      "epoch-27  lr=['0.0010000'], tr/val_loss:  0.918623/  1.467899, val:  61.67%, val_best:  68.33%, tr:  80.29%, tr_best:  80.29%\n",
      "epoch-28  lr=['0.0010000'], tr/val_loss:  0.905570/  1.433413, val:  68.33%, val_best:  68.33%, tr:  79.98%, tr_best:  80.29%\n",
      "epoch-29  lr=['0.0010000'], tr/val_loss:  0.891169/  1.499568, val:  60.00%, val_best:  68.33%, tr:  81.61%, tr_best:  81.61%\n",
      "epoch-30  lr=['0.0010000'], tr/val_loss:  0.884161/  1.466674, val:  64.17%, val_best:  68.33%, tr:  82.02%, tr_best:  82.02%\n",
      "epoch-31  lr=['0.0010000'], tr/val_loss:  0.885212/  1.528810, val:  63.75%, val_best:  68.33%, tr:  78.96%, tr_best:  82.02%\n",
      "epoch-32  lr=['0.0010000'], tr/val_loss:  0.878800/  1.503499, val:  65.42%, val_best:  68.33%, tr:  80.59%, tr_best:  82.02%\n",
      "epoch-33  lr=['0.0010000'], tr/val_loss:  0.867940/  1.545360, val:  66.67%, val_best:  68.33%, tr:  83.04%, tr_best:  83.04%\n",
      "epoch-34  lr=['0.0010000'], tr/val_loss:  0.855133/  1.529981, val:  64.58%, val_best:  68.33%, tr:  82.74%, tr_best:  83.04%\n",
      "epoch-35  lr=['0.0010000'], tr/val_loss:  0.860671/  1.592199, val:  60.42%, val_best:  68.33%, tr:  82.12%, tr_best:  83.04%\n",
      "epoch-36  lr=['0.0010000'], tr/val_loss:  0.830630/  1.523988, val:  66.67%, val_best:  68.33%, tr:  83.76%, tr_best:  83.76%\n",
      "epoch-37  lr=['0.0010000'], tr/val_loss:  0.835012/  1.568986, val:  67.08%, val_best:  68.33%, tr:  85.90%, tr_best:  85.90%\n",
      "epoch-38  lr=['0.0010000'], tr/val_loss:  0.827137/  1.553537, val:  68.33%, val_best:  68.33%, tr:  86.31%, tr_best:  86.31%\n",
      "epoch-39  lr=['0.0010000'], tr/val_loss:  0.821829/  1.581612, val:  66.25%, val_best:  68.33%, tr:  85.80%, tr_best:  86.31%\n",
      "epoch-40  lr=['0.0010000'], tr/val_loss:  0.808516/  1.545291, val:  67.92%, val_best:  68.33%, tr:  85.50%, tr_best:  86.31%\n",
      "epoch-41  lr=['0.0010000'], tr/val_loss:  0.816658/  1.600840, val:  65.83%, val_best:  68.33%, tr:  87.44%, tr_best:  87.44%\n",
      "epoch-42  lr=['0.0010000'], tr/val_loss:  0.802062/  1.613271, val:  67.50%, val_best:  68.33%, tr:  87.23%, tr_best:  87.44%\n",
      "epoch-43  lr=['0.0010000'], tr/val_loss:  0.792263/  1.652269, val:  67.50%, val_best:  68.33%, tr:  86.93%, tr_best:  87.44%\n",
      "epoch-44  lr=['0.0010000'], tr/val_loss:  0.785542/  1.618566, val:  68.75%, val_best:  68.75%, tr:  87.23%, tr_best:  87.44%\n",
      "epoch-45  lr=['0.0010000'], tr/val_loss:  0.773058/  1.674953, val:  66.67%, val_best:  68.75%, tr:  88.15%, tr_best:  88.15%\n",
      "epoch-46  lr=['0.0010000'], tr/val_loss:  0.779096/  1.682626, val:  67.08%, val_best:  68.75%, tr:  88.76%, tr_best:  88.76%\n",
      "epoch-47  lr=['0.0010000'], tr/val_loss:  0.765017/  1.753861, val:  67.92%, val_best:  68.75%, tr:  87.84%, tr_best:  88.76%\n",
      "epoch-48  lr=['0.0010000'], tr/val_loss:  0.774353/  1.697718, val:  70.42%, val_best:  70.42%, tr:  90.09%, tr_best:  90.09%\n",
      "epoch-49  lr=['0.0010000'], tr/val_loss:  0.757714/  1.744035, val:  69.17%, val_best:  70.42%, tr:  89.48%, tr_best:  90.09%\n",
      "epoch-50  lr=['0.0010000'], tr/val_loss:  0.749776/  1.773715, val:  70.83%, val_best:  70.83%, tr:  89.99%, tr_best:  90.09%\n",
      "epoch-51  lr=['0.0010000'], tr/val_loss:  0.735386/  1.857619, val:  68.33%, val_best:  70.83%, tr:  89.48%, tr_best:  90.09%\n",
      "epoch-52  lr=['0.0010000'], tr/val_loss:  0.727392/  1.871766, val:  63.33%, val_best:  70.83%, tr:  91.11%, tr_best:  91.11%\n",
      "epoch-53  lr=['0.0010000'], tr/val_loss:  0.736892/  1.886971, val:  67.08%, val_best:  70.83%, tr:  91.22%, tr_best:  91.22%\n",
      "epoch-54  lr=['0.0010000'], tr/val_loss:  0.737400/  1.844973, val:  69.58%, val_best:  70.83%, tr:  90.60%, tr_best:  91.22%\n",
      "epoch-55  lr=['0.0010000'], tr/val_loss:  0.726919/  1.898565, val:  67.92%, val_best:  70.83%, tr:  90.60%, tr_best:  91.22%\n",
      "epoch-56  lr=['0.0010000'], tr/val_loss:  0.727255/  2.010104, val:  61.25%, val_best:  70.83%, tr:  90.60%, tr_best:  91.22%\n",
      "epoch-57  lr=['0.0010000'], tr/val_loss:  0.733125/  1.929105, val:  67.50%, val_best:  70.83%, tr:  90.30%, tr_best:  91.22%\n",
      "epoch-58  lr=['0.0010000'], tr/val_loss:  0.706081/  2.015479, val:  62.08%, val_best:  70.83%, tr:  90.50%, tr_best:  91.22%\n",
      "epoch-59  lr=['0.0010000'], tr/val_loss:  0.704463/  1.999632, val:  65.00%, val_best:  70.83%, tr:  91.83%, tr_best:  91.83%\n",
      "epoch-60  lr=['0.0010000'], tr/val_loss:  0.697379/  2.012823, val:  66.67%, val_best:  70.83%, tr:  92.54%, tr_best:  92.54%\n",
      "epoch-61  lr=['0.0010000'], tr/val_loss:  0.699366/  2.049498, val:  66.67%, val_best:  70.83%, tr:  93.16%, tr_best:  93.16%\n",
      "epoch-62  lr=['0.0010000'], tr/val_loss:  0.696666/  1.982021, val:  66.25%, val_best:  70.83%, tr:  91.62%, tr_best:  93.16%\n",
      "epoch-63  lr=['0.0010000'], tr/val_loss:  0.690303/  1.949631, val:  68.33%, val_best:  70.83%, tr:  93.16%, tr_best:  93.16%\n",
      "epoch-64  lr=['0.0010000'], tr/val_loss:  0.682222/  2.182542, val:  66.67%, val_best:  70.83%, tr:  93.16%, tr_best:  93.16%\n",
      "epoch-65  lr=['0.0010000'], tr/val_loss:  0.678254/  2.093792, val:  68.33%, val_best:  70.83%, tr:  93.26%, tr_best:  93.26%\n",
      "epoch-66  lr=['0.0010000'], tr/val_loss:  0.657245/  2.104634, val:  64.17%, val_best:  70.83%, tr:  94.28%, tr_best:  94.28%\n",
      "epoch-67  lr=['0.0010000'], tr/val_loss:  0.678574/  2.185186, val:  65.42%, val_best:  70.83%, tr:  93.46%, tr_best:  94.28%\n",
      "epoch-68  lr=['0.0010000'], tr/val_loss:  0.669829/  2.143760, val:  65.83%, val_best:  70.83%, tr:  93.77%, tr_best:  94.28%\n",
      "epoch-69  lr=['0.0010000'], tr/val_loss:  0.663757/  2.222388, val:  63.33%, val_best:  70.83%, tr:  93.46%, tr_best:  94.28%\n",
      "epoch-70  lr=['0.0010000'], tr/val_loss:  0.664197/  2.173170, val:  68.75%, val_best:  70.83%, tr:  93.67%, tr_best:  94.28%\n",
      "epoch-71  lr=['0.0010000'], tr/val_loss:  0.658573/  2.264093, val:  66.25%, val_best:  70.83%, tr:  94.08%, tr_best:  94.28%\n",
      "epoch-72  lr=['0.0010000'], tr/val_loss:  0.649531/  2.311089, val:  66.67%, val_best:  70.83%, tr:  94.28%, tr_best:  94.28%\n",
      "epoch-73  lr=['0.0010000'], tr/val_loss:  0.697815/  2.388317, val:  62.50%, val_best:  70.83%, tr:  93.46%, tr_best:  94.28%\n",
      "epoch-74  lr=['0.0010000'], tr/val_loss:  0.679183/  2.287027, val:  64.58%, val_best:  70.83%, tr:  93.77%, tr_best:  94.28%\n",
      "epoch-75  lr=['0.0010000'], tr/val_loss:  0.661421/  2.334292, val:  65.83%, val_best:  70.83%, tr:  93.56%, tr_best:  94.28%\n",
      "epoch-76  lr=['0.0010000'], tr/val_loss:  0.641969/  2.338767, val:  62.08%, val_best:  70.83%, tr:  94.99%, tr_best:  94.99%\n",
      "epoch-77  lr=['0.0010000'], tr/val_loss:  0.654468/  2.357919, val:  64.58%, val_best:  70.83%, tr:  93.87%, tr_best:  94.99%\n",
      "epoch-78  lr=['0.0010000'], tr/val_loss:  0.643049/  2.393985, val:  67.08%, val_best:  70.83%, tr:  93.46%, tr_best:  94.99%\n",
      "epoch-79  lr=['0.0010000'], tr/val_loss:  0.629749/  2.407182, val:  67.50%, val_best:  70.83%, tr:  93.77%, tr_best:  94.99%\n",
      "epoch-80  lr=['0.0010000'], tr/val_loss:  0.630240/  2.430224, val:  63.75%, val_best:  70.83%, tr:  94.69%, tr_best:  94.99%\n",
      "epoch-81  lr=['0.0010000'], tr/val_loss:  0.629139/  2.470051, val:  67.50%, val_best:  70.83%, tr:  95.40%, tr_best:  95.40%\n",
      "epoch-82  lr=['0.0010000'], tr/val_loss:  0.626601/  2.557223, val:  63.75%, val_best:  70.83%, tr:  94.08%, tr_best:  95.40%\n",
      "epoch-83  lr=['0.0010000'], tr/val_loss:  0.650782/  2.664475, val:  62.08%, val_best:  70.83%, tr:  94.08%, tr_best:  95.40%\n",
      "epoch-84  lr=['0.0010000'], tr/val_loss:  0.633163/  2.498292, val:  65.42%, val_best:  70.83%, tr:  96.42%, tr_best:  96.42%\n",
      "epoch-85  lr=['0.0010000'], tr/val_loss:  0.640605/  2.526422, val:  66.25%, val_best:  70.83%, tr:  95.10%, tr_best:  96.42%\n",
      "epoch-86  lr=['0.0010000'], tr/val_loss:  0.621260/  2.476778, val:  65.00%, val_best:  70.83%, tr:  94.48%, tr_best:  96.42%\n",
      "epoch-87  lr=['0.0010000'], tr/val_loss:  0.620244/  2.573562, val:  65.83%, val_best:  70.83%, tr:  95.51%, tr_best:  96.42%\n",
      "epoch-88  lr=['0.0010000'], tr/val_loss:  0.620359/  2.622973, val:  62.08%, val_best:  70.83%, tr:  95.81%, tr_best:  96.42%\n",
      "epoch-89  lr=['0.0010000'], tr/val_loss:  0.605548/  2.640956, val:  65.42%, val_best:  70.83%, tr:  96.32%, tr_best:  96.42%\n",
      "epoch-90  lr=['0.0010000'], tr/val_loss:  0.629322/  2.612954, val:  62.50%, val_best:  70.83%, tr:  95.30%, tr_best:  96.42%\n",
      "epoch-91  lr=['0.0010000'], tr/val_loss:  0.619542/  2.711474, val:  61.25%, val_best:  70.83%, tr:  94.89%, tr_best:  96.42%\n",
      "epoch-92  lr=['0.0010000'], tr/val_loss:  0.627735/  2.750376, val:  60.00%, val_best:  70.83%, tr:  95.40%, tr_best:  96.42%\n",
      "epoch-93  lr=['0.0010000'], tr/val_loss:  0.637624/  2.683571, val:  64.17%, val_best:  70.83%, tr:  94.99%, tr_best:  96.42%\n",
      "epoch-94  lr=['0.0010000'], tr/val_loss:  0.619945/  2.644697, val:  65.83%, val_best:  70.83%, tr:  96.12%, tr_best:  96.42%\n",
      "epoch-95  lr=['0.0010000'], tr/val_loss:  0.630613/  2.787121, val:  66.25%, val_best:  70.83%, tr:  94.89%, tr_best:  96.42%\n",
      "epoch-96  lr=['0.0010000'], tr/val_loss:  0.599588/  2.837799, val:  59.17%, val_best:  70.83%, tr:  96.22%, tr_best:  96.42%\n",
      "epoch-97  lr=['0.0010000'], tr/val_loss:  0.616224/  2.720553, val:  66.25%, val_best:  70.83%, tr:  94.89%, tr_best:  96.42%\n",
      "epoch-98  lr=['0.0010000'], tr/val_loss:  0.590106/  2.774406, val:  64.58%, val_best:  70.83%, tr:  96.63%, tr_best:  96.63%\n",
      "epoch-99  lr=['0.0010000'], tr/val_loss:  0.609097/  2.823443, val:  62.92%, val_best:  70.83%, tr:  96.12%, tr_best:  96.63%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2a9793ef36c044d0ac040d52420afc59",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.006 MB of 0.006 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>iter_acc</td><td>▂▄▁▃▁▄▆▂▄▅▅▇▄▆▆▇▇▆█▇▇█▆▇█▇▇██▇█▇▅█▇▇▇▇██</td></tr><tr><td>summary_val_acc</td><td>▁▄▅▆▆▆▆▇▇▇▇█▇▇▇█▇████▇██▇██▇██▇▇█▇▇▇▇▇▇▇</td></tr><tr><td>tr_acc</td><td>▁▃▄▅▅▆▆▆▆▆▆▆▇▇▇▇▇▇▇▇▇██▇████████████████</td></tr><tr><td>tr_epoch_loss</td><td>█▇▅▄▄▃▃▃▃▃▂▂▂▂▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_acc_best</td><td>▁▄▅▆▆▆▆▇▇▇▇█████████████████████████████</td></tr><tr><td>val_acc_now</td><td>▁▄▅▆▆▆▆▇▇▇▇█▇▇▇█▇████▇██▇██▇██▇▇█▇▇▇▇▇▇▇</td></tr><tr><td>val_loss</td><td>▅▄▂▂▂▁▁▁▁▁▁▁▂▂▂▂▂▂▂▃▃▃▃▄▄▄▅▅▅▆▆▆▆▇▇▇▇███</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>99</td></tr><tr><td>iter_acc</td><td>1.0</td></tr><tr><td>tr_acc</td><td>0.96118</td></tr><tr><td>tr_epoch_loss</td><td>0.6091</td></tr><tr><td>val_acc_best</td><td>0.70833</td></tr><tr><td>val_acc_now</td><td>0.62917</td></tr><tr><td>val_loss</td><td>2.82344</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">twilight-sweep-180</strong> at: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/cwzymixu' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/cwzymixu</a><br/> View project at: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>/data2/bh_wandb/wandb/run-20250430_044239-cwzymixu/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require(\"core\")`! See https://wandb.me/wandb-core for more information."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: b04ycbty with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBATCH: 16\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBN_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBPTT_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tDFA_on: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tIMAGE_SIZE: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tOTTT_input_trace_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tTIME: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tUDA_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \talpha_uda: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbias: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcfg: ['M', 'M', 200, 200]\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tchaching_on: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tconvTrue_fcFalse: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdata_path: /data2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tddp_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdenoise_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdvs_clipping: 5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdvs_duration: 100000\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepoch_num: 100\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \texclude_class: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \textra_train_dataset: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlast_lif: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.001\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_sg_width: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_decay: 0.5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_init: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_reset: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_threshold: 0.5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmerge_polarities: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmy_seed: 42\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnet_print: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_workers: 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer_what: SGD\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tpin_memory: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tpre_trained: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tpre_trained_path: net_save/save_now_net_weights_{unique_name}.pth\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \trate_coding: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tscheduler_name: no\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsingle_step: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsurrogate: hard_sigmoid\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_conv_kernel_size: 3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_conv_padding: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_conv_stride: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_trace_const1: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_trace_const2: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \ttdBN_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \ttrace_on: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \twhich_data: DVS_GESTURE_TONIC\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.19.10 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.17.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/data2/bh_wandb/wandb/run-20250430_044825-b04ycbty</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/b04ycbty' target=\"_blank\">helpful-sweep-182</a></strong> to <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/6pj3lh8j' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/6pj3lh8j</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/6pj3lh8j' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/6pj3lh8j</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/b04ycbty' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/b04ycbty</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'single_step' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'my_seed' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'TIME' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BATCH' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'IMAGE_SIZE' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'which_data' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'data_path' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'rate_coding' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_init' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_decay' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_threshold' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_reset' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_sg_width' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_conv_kernel_size' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_conv_stride' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_conv_padding' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_trace_const1' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_trace_const2' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'pre_trained' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'convTrue_fcFalse' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'cfg' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'net_print' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'pre_trained_path' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'learning_rate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'epoch_num' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'tdBN_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BN_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'surrogate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BPTT_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'optimizer_what' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'scheduler_name' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'ddp_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'dvs_clipping' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'dvs_duration' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'DFA_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'trace_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'OTTT_input_trace_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'exclude_class' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'merge_polarities' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'denoise_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'extra_train_dataset' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'num_workers' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'chaching_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'pin_memory' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'UDA_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'alpha_uda' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'bias' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'last_lif' was locked by 'sweep' (ignored update).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "param {'devices': '0', 'single_step': True, 'unique_name': 'main', 'my_seed': 42, 'TIME': 10, 'BATCH': 16, 'IMAGE_SIZE': 128, 'which_data': 'DVS_GESTURE_TONIC', 'data_path': '/data2', 'rate_coding': False, 'lif_layer_v_init': 0, 'lif_layer_v_decay': 0.5, 'lif_layer_v_threshold': 0.5, 'lif_layer_v_reset': 0, 'lif_layer_sg_width': 1, 'synapse_conv_kernel_size': 3, 'synapse_conv_stride': 1, 'synapse_conv_padding': 1, 'synapse_trace_const1': 1, 'synapse_trace_const2': 0, 'pre_trained': False, 'convTrue_fcFalse': False, 'cfg': ['M', 'M', 200, 200], 'net_print': True, 'pre_trained_path': 'net_save/save_now_net_weights_{unique_name}.pth', 'learning_rate': 0.001, 'epoch_num': 100, 'tdBN_on': False, 'BN_on': False, 'surrogate': 'hard_sigmoid', 'BPTT_on': False, 'optimizer_what': 'SGD', 'scheduler_name': 'no', 'ddp_on': False, 'dvs_clipping': 5, 'dvs_duration': 100000, 'DFA_on': True, 'trace_on': True, 'OTTT_input_trace_on': False, 'exclude_class': True, 'merge_polarities': False, 'denoise_on': False, 'extra_train_dataset': 0, 'num_workers': 2, 'chaching_on': True, 'pin_memory': True, 'UDA_on': False, 'alpha_uda': 1, 'bias': True, 'last_lif': False, 'current epoch': 0} \n",
      "\n",
      "dataset_hash = ffa516e60c3efd5e0208f72b4c36cb84\n",
      "cache path exists\n",
      "\n",
      "device ==> cuda\n",
      "\n",
      "DataParallel(\n",
      "  (module): REBORN_MY_SNN_FC(\n",
      "    (layers): REBORN_MY_Sequential(\n",
      "      (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (2): DimChanger_for_FC()\n",
      "      (3): SYNAPSE_FC(in_features=2048, out_features=200, TIME=10, bias=True, sstep=True)\n",
      "      (4): LIF_layer(v_init=0, v_decay=0.5, v_threshold=0.5, v_reset=0, sg_width=1, surrogate=hard_sigmoid, BPTT_on=False, trace_const1=1, trace_const2=0, TIME=10, sstep=True, trace_on=True)\n",
      "      (5): Feedback_Receiver()\n",
      "      (6): SYNAPSE_FC(in_features=200, out_features=200, TIME=10, bias=True, sstep=True)\n",
      "      (7): LIF_layer(v_init=0, v_decay=0.5, v_threshold=0.5, v_reset=0, sg_width=1, surrogate=hard_sigmoid, BPTT_on=False, trace_const1=1, trace_const2=0, TIME=10, sstep=True, trace_on=True)\n",
      "      (8): Feedback_Receiver()\n",
      "      (9): SYNAPSE_FC(in_features=200, out_features=10, TIME=10, bias=True, sstep=True)\n",
      "      (DFA_top): Top_Gradient()\n",
      "    )\n",
      "  )\n",
      ")\n",
      "\n",
      "========================================================\n",
      "Trainable parameters: 452,010\n",
      "========================================================\n",
      "\n",
      "epoch-0   lr=['0.0010000'], tr/val_loss:  2.303858/  2.292209, val:  15.00%, val_best:  15.00%, tr:   9.50%, tr_best:   9.50%\n",
      "[module.layers.5] weight_fb parameter count: 2,000\n",
      "[module.layers.8] weight_fb parameter count: 2,000\n",
      "epoch-1   lr=['0.0010000'], tr/val_loss:  2.168602/  1.992253, val:  37.08%, val_best:  37.08%, tr:  21.86%, tr_best:  21.86%\n",
      "epoch-2   lr=['0.0010000'], tr/val_loss:  1.713968/  1.647874, val:  47.92%, val_best:  47.92%, tr:  47.19%, tr_best:  47.19%\n",
      "epoch-3   lr=['0.0010000'], tr/val_loss:  1.452438/  1.512744, val:  52.50%, val_best:  52.50%, tr:  57.30%, tr_best:  57.30%\n",
      "epoch-4   lr=['0.0010000'], tr/val_loss:  1.337565/  1.458885, val:  53.75%, val_best:  53.75%, tr:  57.81%, tr_best:  57.81%\n",
      "epoch-5   lr=['0.0010000'], tr/val_loss:  1.261509/  1.392988, val:  58.33%, val_best:  58.33%, tr:  58.94%, tr_best:  58.94%\n",
      "epoch-6   lr=['0.0010000'], tr/val_loss:  1.216334/  1.368062, val:  57.08%, val_best:  58.33%, tr:  61.70%, tr_best:  61.70%\n",
      "epoch-7   lr=['0.0010000'], tr/val_loss:  1.174295/  1.341409, val:  59.17%, val_best:  59.17%, tr:  62.92%, tr_best:  62.92%\n",
      "epoch-8   lr=['0.0010000'], tr/val_loss:  1.129948/  1.313629, val:  62.92%, val_best:  62.92%, tr:  63.74%, tr_best:  63.74%\n",
      "epoch-9   lr=['0.0010000'], tr/val_loss:  1.107322/  1.306988, val:  62.08%, val_best:  62.92%, tr:  67.72%, tr_best:  67.72%\n",
      "epoch-10  lr=['0.0010000'], tr/val_loss:  1.081254/  1.321232, val:  61.25%, val_best:  62.92%, tr:  66.29%, tr_best:  67.72%\n",
      "epoch-11  lr=['0.0010000'], tr/val_loss:  1.054062/  1.280520, val:  63.75%, val_best:  63.75%, tr:  65.68%, tr_best:  67.72%\n",
      "epoch-12  lr=['0.0010000'], tr/val_loss:  1.041023/  1.279126, val:  62.50%, val_best:  63.75%, tr:  69.05%, tr_best:  69.05%\n",
      "epoch-13  lr=['0.0010000'], tr/val_loss:  1.033543/  1.278092, val:  65.00%, val_best:  65.00%, tr:  68.54%, tr_best:  69.05%\n",
      "epoch-14  lr=['0.0010000'], tr/val_loss:  0.989860/  1.329947, val:  61.25%, val_best:  65.00%, tr:  69.97%, tr_best:  69.97%\n",
      "epoch-15  lr=['0.0010000'], tr/val_loss:  0.980014/  1.254902, val:  67.50%, val_best:  67.50%, tr:  71.50%, tr_best:  71.50%\n",
      "epoch-16  lr=['0.0010000'], tr/val_loss:  0.966145/  1.250206, val:  67.50%, val_best:  67.50%, tr:  70.79%, tr_best:  71.50%\n",
      "epoch-17  lr=['0.0010000'], tr/val_loss:  0.941172/  1.227785, val:  68.75%, val_best:  68.75%, tr:  75.38%, tr_best:  75.38%\n",
      "epoch-18  lr=['0.0010000'], tr/val_loss:  0.921471/  1.277983, val:  64.17%, val_best:  68.75%, tr:  73.95%, tr_best:  75.38%\n",
      "epoch-19  lr=['0.0010000'], tr/val_loss:  0.918174/  1.272566, val:  62.08%, val_best:  68.75%, tr:  72.52%, tr_best:  75.38%\n",
      "epoch-20  lr=['0.0010000'], tr/val_loss:  0.890179/  1.251075, val:  65.42%, val_best:  68.75%, tr:  76.61%, tr_best:  76.61%\n",
      "epoch-21  lr=['0.0010000'], tr/val_loss:  0.884067/  1.233335, val:  68.33%, val_best:  68.75%, tr:  77.12%, tr_best:  77.12%\n",
      "epoch-22  lr=['0.0010000'], tr/val_loss:  0.884414/  1.243220, val:  69.58%, val_best:  69.58%, tr:  74.97%, tr_best:  77.12%\n",
      "epoch-23  lr=['0.0010000'], tr/val_loss:  0.849258/  1.236265, val:  65.83%, val_best:  69.58%, tr:  77.63%, tr_best:  77.63%\n",
      "epoch-24  lr=['0.0010000'], tr/val_loss:  0.836306/  1.246835, val:  64.17%, val_best:  69.58%, tr:  79.78%, tr_best:  79.78%\n",
      "epoch-25  lr=['0.0010000'], tr/val_loss:  0.819415/  1.236825, val:  68.33%, val_best:  69.58%, tr:  81.51%, tr_best:  81.51%\n",
      "epoch-26  lr=['0.0010000'], tr/val_loss:  0.810173/  1.229143, val:  65.83%, val_best:  69.58%, tr:  80.49%, tr_best:  81.51%\n",
      "epoch-27  lr=['0.0010000'], tr/val_loss:  0.787963/  1.263792, val:  65.00%, val_best:  69.58%, tr:  83.86%, tr_best:  83.86%\n",
      "epoch-28  lr=['0.0010000'], tr/val_loss:  0.788478/  1.233977, val:  70.00%, val_best:  70.00%, tr:  83.35%, tr_best:  83.86%\n",
      "epoch-29  lr=['0.0010000'], tr/val_loss:  0.757254/  1.276831, val:  64.17%, val_best:  70.00%, tr:  86.01%, tr_best:  86.01%\n",
      "epoch-30  lr=['0.0010000'], tr/val_loss:  0.748509/  1.268789, val:  65.83%, val_best:  70.00%, tr:  86.82%, tr_best:  86.82%\n",
      "epoch-31  lr=['0.0010000'], tr/val_loss:  0.759583/  1.291382, val:  64.17%, val_best:  70.00%, tr:  82.94%, tr_best:  86.82%\n",
      "epoch-32  lr=['0.0010000'], tr/val_loss:  0.737192/  1.268540, val:  67.08%, val_best:  70.00%, tr:  86.62%, tr_best:  86.82%\n",
      "epoch-33  lr=['0.0010000'], tr/val_loss:  0.727287/  1.283121, val:  69.17%, val_best:  70.00%, tr:  86.82%, tr_best:  86.82%\n",
      "epoch-34  lr=['0.0010000'], tr/val_loss:  0.707743/  1.300245, val:  65.42%, val_best:  70.00%, tr:  87.95%, tr_best:  87.95%\n",
      "epoch-35  lr=['0.0010000'], tr/val_loss:  0.714024/  1.307082, val:  66.67%, val_best:  70.00%, tr:  87.13%, tr_best:  87.95%\n",
      "epoch-36  lr=['0.0010000'], tr/val_loss:  0.684764/  1.297185, val:  67.92%, val_best:  70.00%, tr:  89.07%, tr_best:  89.07%\n",
      "epoch-37  lr=['0.0010000'], tr/val_loss:  0.676598/  1.297166, val:  69.58%, val_best:  70.00%, tr:  90.70%, tr_best:  90.70%\n",
      "epoch-38  lr=['0.0010000'], tr/val_loss:  0.673878/  1.310000, val:  67.08%, val_best:  70.00%, tr:  91.22%, tr_best:  91.22%\n",
      "epoch-39  lr=['0.0010000'], tr/val_loss:  0.661789/  1.311705, val:  66.25%, val_best:  70.00%, tr:  91.01%, tr_best:  91.22%\n",
      "epoch-40  lr=['0.0010000'], tr/val_loss:  0.649481/  1.337699, val:  66.67%, val_best:  70.00%, tr:  90.50%, tr_best:  91.22%\n",
      "epoch-41  lr=['0.0010000'], tr/val_loss:  0.651048/  1.323981, val:  67.92%, val_best:  70.00%, tr:  92.54%, tr_best:  92.54%\n",
      "epoch-42  lr=['0.0010000'], tr/val_loss:  0.628668/  1.346223, val:  65.42%, val_best:  70.00%, tr:  92.54%, tr_best:  92.54%\n",
      "epoch-43  lr=['0.0010000'], tr/val_loss:  0.628663/  1.370083, val:  69.58%, val_best:  70.00%, tr:  92.54%, tr_best:  92.54%\n",
      "epoch-44  lr=['0.0010000'], tr/val_loss:  0.616885/  1.360376, val:  65.83%, val_best:  70.00%, tr:  91.93%, tr_best:  92.54%\n",
      "epoch-45  lr=['0.0010000'], tr/val_loss:  0.608133/  1.369783, val:  69.17%, val_best:  70.00%, tr:  92.75%, tr_best:  92.75%\n",
      "epoch-46  lr=['0.0010000'], tr/val_loss:  0.594606/  1.390755, val:  66.67%, val_best:  70.00%, tr:  94.18%, tr_best:  94.18%\n",
      "epoch-47  lr=['0.0010000'], tr/val_loss:  0.593019/  1.397860, val:  66.25%, val_best:  70.00%, tr:  94.18%, tr_best:  94.18%\n",
      "epoch-48  lr=['0.0010000'], tr/val_loss:  0.591661/  1.384358, val:  66.25%, val_best:  70.00%, tr:  95.20%, tr_best:  95.20%\n",
      "epoch-49  lr=['0.0010000'], tr/val_loss:  0.588464/  1.404226, val:  67.08%, val_best:  70.00%, tr:  94.38%, tr_best:  95.20%\n",
      "epoch-50  lr=['0.0010000'], tr/val_loss:  0.578967/  1.419142, val:  66.67%, val_best:  70.00%, tr:  95.20%, tr_best:  95.20%\n",
      "epoch-51  lr=['0.0010000'], tr/val_loss:  0.568588/  1.436009, val:  68.75%, val_best:  70.00%, tr:  95.10%, tr_best:  95.20%\n",
      "epoch-52  lr=['0.0010000'], tr/val_loss:  0.557804/  1.456308, val:  65.42%, val_best:  70.00%, tr:  94.59%, tr_best:  95.20%\n",
      "epoch-53  lr=['0.0010000'], tr/val_loss:  0.563919/  1.424584, val:  66.67%, val_best:  70.00%, tr:  94.79%, tr_best:  95.20%\n",
      "epoch-54  lr=['0.0010000'], tr/val_loss:  0.542692/  1.452152, val:  68.75%, val_best:  70.00%, tr:  95.81%, tr_best:  95.81%\n",
      "epoch-55  lr=['0.0010000'], tr/val_loss:  0.545610/  1.446335, val:  67.08%, val_best:  70.00%, tr:  95.51%, tr_best:  95.81%\n",
      "epoch-56  lr=['0.0010000'], tr/val_loss:  0.534482/  1.477798, val:  67.08%, val_best:  70.00%, tr:  96.12%, tr_best:  96.12%\n",
      "epoch-57  lr=['0.0010000'], tr/val_loss:  0.525847/  1.470864, val:  65.00%, val_best:  70.00%, tr:  96.63%, tr_best:  96.63%\n",
      "epoch-58  lr=['0.0010000'], tr/val_loss:  0.513014/  1.486675, val:  68.33%, val_best:  70.00%, tr:  96.73%, tr_best:  96.73%\n",
      "epoch-59  lr=['0.0010000'], tr/val_loss:  0.511854/  1.482582, val:  69.17%, val_best:  70.00%, tr:  96.73%, tr_best:  96.73%\n",
      "epoch-60  lr=['0.0010000'], tr/val_loss:  0.512199/  1.495999, val:  68.75%, val_best:  70.00%, tr:  96.12%, tr_best:  96.73%\n",
      "epoch-61  lr=['0.0010000'], tr/val_loss:  0.503474/  1.504888, val:  66.25%, val_best:  70.00%, tr:  97.34%, tr_best:  97.34%\n",
      "epoch-62  lr=['0.0010000'], tr/val_loss:  0.504339/  1.527805, val:  66.25%, val_best:  70.00%, tr:  97.04%, tr_best:  97.34%\n",
      "epoch-63  lr=['0.0010000'], tr/val_loss:  0.493393/  1.517191, val:  67.92%, val_best:  70.00%, tr:  96.73%, tr_best:  97.34%\n",
      "epoch-64  lr=['0.0010000'], tr/val_loss:  0.494963/  1.551601, val:  67.50%, val_best:  70.00%, tr:  96.63%, tr_best:  97.34%\n",
      "epoch-65  lr=['0.0010000'], tr/val_loss:  0.488975/  1.538453, val:  69.58%, val_best:  70.00%, tr:  96.63%, tr_best:  97.34%\n",
      "epoch-66  lr=['0.0010000'], tr/val_loss:  0.486834/  1.527778, val:  69.58%, val_best:  70.00%, tr:  97.45%, tr_best:  97.45%\n",
      "epoch-67  lr=['0.0010000'], tr/val_loss:  0.488077/  1.539855, val:  67.08%, val_best:  70.00%, tr:  97.34%, tr_best:  97.45%\n",
      "epoch-68  lr=['0.0010000'], tr/val_loss:  0.473360/  1.537810, val:  69.17%, val_best:  70.00%, tr:  97.04%, tr_best:  97.45%\n",
      "epoch-69  lr=['0.0010000'], tr/val_loss:  0.470352/  1.574325, val:  66.25%, val_best:  70.00%, tr:  97.65%, tr_best:  97.65%\n",
      "epoch-70  lr=['0.0010000'], tr/val_loss:  0.464616/  1.567242, val:  69.58%, val_best:  70.00%, tr:  98.26%, tr_best:  98.26%\n",
      "epoch-71  lr=['0.0010000'], tr/val_loss:  0.464008/  1.585060, val:  67.50%, val_best:  70.00%, tr:  97.04%, tr_best:  98.26%\n",
      "epoch-72  lr=['0.0010000'], tr/val_loss:  0.461141/  1.603534, val:  66.25%, val_best:  70.00%, tr:  97.34%, tr_best:  98.26%\n",
      "epoch-73  lr=['0.0010000'], tr/val_loss:  0.463213/  1.577845, val:  68.33%, val_best:  70.00%, tr:  98.06%, tr_best:  98.26%\n",
      "epoch-74  lr=['0.0010000'], tr/val_loss:  0.450254/  1.598994, val:  67.92%, val_best:  70.00%, tr:  98.37%, tr_best:  98.37%\n",
      "epoch-75  lr=['0.0010000'], tr/val_loss:  0.448290/  1.590328, val:  69.17%, val_best:  70.00%, tr:  97.75%, tr_best:  98.37%\n",
      "epoch-76  lr=['0.0010000'], tr/val_loss:  0.434239/  1.624148, val:  67.08%, val_best:  70.00%, tr:  97.85%, tr_best:  98.37%\n",
      "epoch-77  lr=['0.0010000'], tr/val_loss:  0.440506/  1.625061, val:  66.67%, val_best:  70.00%, tr:  98.37%, tr_best:  98.37%\n",
      "epoch-78  lr=['0.0010000'], tr/val_loss:  0.446341/  1.627461, val:  69.17%, val_best:  70.00%, tr:  98.06%, tr_best:  98.37%\n",
      "epoch-79  lr=['0.0010000'], tr/val_loss:  0.422506/  1.618093, val:  70.42%, val_best:  70.42%, tr:  97.96%, tr_best:  98.37%\n",
      "epoch-80  lr=['0.0010000'], tr/val_loss:  0.415443/  1.639280, val:  66.67%, val_best:  70.42%, tr:  98.26%, tr_best:  98.37%\n",
      "epoch-81  lr=['0.0010000'], tr/val_loss:  0.421654/  1.637445, val:  69.17%, val_best:  70.42%, tr:  97.96%, tr_best:  98.37%\n",
      "epoch-82  lr=['0.0010000'], tr/val_loss:  0.417395/  1.652725, val:  66.25%, val_best:  70.42%, tr:  98.57%, tr_best:  98.57%\n",
      "epoch-83  lr=['0.0010000'], tr/val_loss:  0.412329/  1.672570, val:  69.17%, val_best:  70.42%, tr:  98.77%, tr_best:  98.77%\n",
      "epoch-84  lr=['0.0010000'], tr/val_loss:  0.402966/  1.650104, val:  68.75%, val_best:  70.42%, tr:  98.98%, tr_best:  98.98%\n",
      "epoch-85  lr=['0.0010000'], tr/val_loss:  0.406237/  1.674207, val:  70.00%, val_best:  70.42%, tr:  98.77%, tr_best:  98.98%\n",
      "epoch-86  lr=['0.0010000'], tr/val_loss:  0.400451/  1.670149, val:  69.17%, val_best:  70.42%, tr:  98.57%, tr_best:  98.98%\n",
      "epoch-87  lr=['0.0010000'], tr/val_loss:  0.398935/  1.708671, val:  69.17%, val_best:  70.42%, tr:  98.57%, tr_best:  98.98%\n",
      "epoch-88  lr=['0.0010000'], tr/val_loss:  0.391107/  1.679298, val:  69.17%, val_best:  70.42%, tr:  98.98%, tr_best:  98.98%\n",
      "epoch-89  lr=['0.0010000'], tr/val_loss:  0.383078/  1.702215, val:  66.67%, val_best:  70.42%, tr:  98.98%, tr_best:  98.98%\n",
      "epoch-90  lr=['0.0010000'], tr/val_loss:  0.393304/  1.689408, val:  70.00%, val_best:  70.42%, tr:  98.88%, tr_best:  98.98%\n",
      "epoch-91  lr=['0.0010000'], tr/val_loss:  0.382427/  1.718399, val:  70.00%, val_best:  70.42%, tr:  99.08%, tr_best:  99.08%\n",
      "epoch-92  lr=['0.0010000'], tr/val_loss:  0.379787/  1.727420, val:  66.25%, val_best:  70.42%, tr:  98.88%, tr_best:  99.08%\n",
      "epoch-93  lr=['0.0010000'], tr/val_loss:  0.382630/  1.709301, val:  69.17%, val_best:  70.42%, tr:  99.39%, tr_best:  99.39%\n",
      "epoch-94  lr=['0.0010000'], tr/val_loss:  0.375821/  1.759670, val:  69.58%, val_best:  70.42%, tr:  99.28%, tr_best:  99.39%\n",
      "epoch-95  lr=['0.0010000'], tr/val_loss:  0.375501/  1.738552, val:  68.33%, val_best:  70.42%, tr:  99.28%, tr_best:  99.39%\n",
      "epoch-96  lr=['0.0010000'], tr/val_loss:  0.372641/  1.773629, val:  68.75%, val_best:  70.42%, tr:  99.28%, tr_best:  99.39%\n",
      "epoch-97  lr=['0.0010000'], tr/val_loss:  0.369117/  1.741970, val:  71.25%, val_best:  71.25%, tr:  98.88%, tr_best:  99.39%\n",
      "epoch-98  lr=['0.0010000'], tr/val_loss:  0.358245/  1.755338, val:  68.33%, val_best:  71.25%, tr:  99.59%, tr_best:  99.59%\n",
      "epoch-99  lr=['0.0010000'], tr/val_loss:  0.368107/  1.771012, val:  70.00%, val_best:  71.25%, tr:  99.28%, tr_best:  99.59%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4d372aff47084189835355ff5e6a16b4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.006 MB of 0.006 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>iter_acc</td><td>▁▅▄▃▃▅▆▂▄▆▇▇▇▆▆▇█▇█▇██▇██████▆█▇▆██▇▇███</td></tr><tr><td>summary_val_acc</td><td>▁▅▆▆▇▇▇█▇█▇▇▇▇▇█▇▇▇▇▇▇█▇█▇█▇█▇█▇█▇██▇▇██</td></tr><tr><td>tr_acc</td><td>▁▄▅▅▆▆▆▆▆▆▆▇▇▇▇▇▇▇▇█████████████████████</td></tr><tr><td>tr_epoch_loss</td><td>█▆▅▄▄▃▃▃▃▃▃▃▂▂▂▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_acc_best</td><td>▁▅▆▆▇▇▇█████████████████████████████████</td></tr><tr><td>val_acc_now</td><td>▁▅▆▆▇▇▇█▇█▇▇▇▇▇█▇▇▇▇▇▇█▇█▇█▇█▇█▇█▇██▇▇██</td></tr><tr><td>val_loss</td><td>█▄▃▂▂▁▂▁▁▁▁▁▁▁▂▁▂▂▂▂▂▃▂▃▃▃▃▃▃▃▃▄▄▄▄▄▄▄▄▄</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>99</td></tr><tr><td>iter_acc</td><td>1.0</td></tr><tr><td>tr_acc</td><td>0.99285</td></tr><tr><td>tr_epoch_loss</td><td>0.36811</td></tr><tr><td>val_acc_best</td><td>0.7125</td></tr><tr><td>val_acc_now</td><td>0.7</td></tr><tr><td>val_loss</td><td>1.77101</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">helpful-sweep-182</strong> at: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/b04ycbty' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/b04ycbty</a><br/> View project at: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>/data2/bh_wandb/wandb/run-20250430_044825-b04ycbty/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require(\"core\")`! See https://wandb.me/wandb-core for more information."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Sweep Agent: Waiting for job.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Job received.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: ncuwinrs with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBATCH: 16\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBN_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBPTT_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tDFA_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tIMAGE_SIZE: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tOTTT_input_trace_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tTIME: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tUDA_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \talpha_uda: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbias: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcfg: ['M', 'M', 200, 200]\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tchaching_on: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tconvTrue_fcFalse: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdata_path: /data2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tddp_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdenoise_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdvs_clipping: 5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdvs_duration: 100000\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepoch_num: 100\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \texclude_class: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \textra_train_dataset: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlast_lif: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.0001\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_sg_width: 4\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_decay: 0.5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_init: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_reset: 10000\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_threshold: 0.25\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmerge_polarities: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmy_seed: 42\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnet_print: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_workers: 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer_what: SGD\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tpin_memory: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tpre_trained: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tpre_trained_path: net_save/save_now_net_weights_{unique_name}.pth\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \trate_coding: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tscheduler_name: no\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsingle_step: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsurrogate: hard_sigmoid\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_conv_kernel_size: 3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_conv_padding: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_conv_stride: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_trace_const1: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_trace_const2: 0.5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \ttdBN_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \ttrace_on: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \twhich_data: DVS_GESTURE_TONIC\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.19.10 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.17.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/data2/bh_wandb/wandb/run-20250430_045503-ncuwinrs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/ncuwinrs' target=\"_blank\">likely-sweep-184</a></strong> to <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/6pj3lh8j' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/6pj3lh8j</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/6pj3lh8j' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/6pj3lh8j</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/ncuwinrs' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/ncuwinrs</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'single_step' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'my_seed' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'TIME' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BATCH' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'IMAGE_SIZE' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'which_data' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'data_path' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'rate_coding' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_init' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_decay' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_threshold' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_reset' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_sg_width' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_conv_kernel_size' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_conv_stride' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_conv_padding' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_trace_const1' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_trace_const2' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'pre_trained' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'convTrue_fcFalse' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'cfg' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'net_print' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'pre_trained_path' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'learning_rate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'epoch_num' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'tdBN_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BN_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'surrogate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BPTT_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'optimizer_what' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'scheduler_name' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'ddp_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'dvs_clipping' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'dvs_duration' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'DFA_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'trace_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'OTTT_input_trace_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'exclude_class' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'merge_polarities' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'denoise_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'extra_train_dataset' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'num_workers' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'chaching_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'pin_memory' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'UDA_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'alpha_uda' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'bias' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'last_lif' was locked by 'sweep' (ignored update).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "param {'devices': '0', 'single_step': True, 'unique_name': 'main', 'my_seed': 42, 'TIME': 10, 'BATCH': 16, 'IMAGE_SIZE': 128, 'which_data': 'DVS_GESTURE_TONIC', 'data_path': '/data2', 'rate_coding': False, 'lif_layer_v_init': 0, 'lif_layer_v_decay': 0.5, 'lif_layer_v_threshold': 0.25, 'lif_layer_v_reset': 10000, 'lif_layer_sg_width': 4, 'synapse_conv_kernel_size': 3, 'synapse_conv_stride': 1, 'synapse_conv_padding': 1, 'synapse_trace_const1': 1, 'synapse_trace_const2': 0.5, 'pre_trained': False, 'convTrue_fcFalse': False, 'cfg': ['M', 'M', 200, 200], 'net_print': True, 'pre_trained_path': 'net_save/save_now_net_weights_{unique_name}.pth', 'learning_rate': 0.0001, 'epoch_num': 100, 'tdBN_on': False, 'BN_on': False, 'surrogate': 'hard_sigmoid', 'BPTT_on': False, 'optimizer_what': 'SGD', 'scheduler_name': 'no', 'ddp_on': False, 'dvs_clipping': 5, 'dvs_duration': 100000, 'DFA_on': False, 'trace_on': True, 'OTTT_input_trace_on': False, 'exclude_class': True, 'merge_polarities': False, 'denoise_on': False, 'extra_train_dataset': 0, 'num_workers': 2, 'chaching_on': True, 'pin_memory': True, 'UDA_on': False, 'alpha_uda': 1, 'bias': True, 'last_lif': False, 'current epoch': 0} \n",
      "\n",
      "dataset_hash = ffa516e60c3efd5e0208f72b4c36cb84\n",
      "cache path exists\n",
      "\n",
      "device ==> cuda\n",
      "\n",
      "DataParallel(\n",
      "  (module): REBORN_MY_SNN_FC(\n",
      "    (layers): REBORN_MY_Sequential(\n",
      "      (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (2): DimChanger_for_FC()\n",
      "      (3): SYNAPSE_FC(in_features=2048, out_features=200, TIME=10, bias=True, sstep=True)\n",
      "      (4): LIF_layer(v_init=0, v_decay=0.5, v_threshold=0.25, v_reset=10000, sg_width=4, surrogate=hard_sigmoid, BPTT_on=False, trace_const1=1, trace_const2=0.5, TIME=10, sstep=True, trace_on=True)\n",
      "      (5): SYNAPSE_FC(in_features=200, out_features=200, TIME=10, bias=True, sstep=True)\n",
      "      (6): LIF_layer(v_init=0, v_decay=0.5, v_threshold=0.25, v_reset=10000, sg_width=4, surrogate=hard_sigmoid, BPTT_on=False, trace_const1=1, trace_const2=0.5, TIME=10, sstep=True, trace_on=True)\n",
      "      (7): SYNAPSE_FC(in_features=200, out_features=10, TIME=10, bias=True, sstep=True)\n",
      "    )\n",
      "  )\n",
      ")\n",
      "\n",
      "========================================================\n",
      "Trainable parameters: 452,010\n",
      "========================================================\n",
      "\n",
      "epoch-0   lr=['0.0001000'], tr/val_loss:  2.291880/  2.270808, val:  25.00%, val_best:  25.00%, tr:  13.99%, tr_best:  13.99%\n",
      "epoch-1   lr=['0.0001000'], tr/val_loss:  2.237747/  2.216265, val:  25.00%, val_best:  25.00%, tr:  26.46%, tr_best:  26.46%\n",
      "epoch-2   lr=['0.0001000'], tr/val_loss:  2.158710/  2.133271, val:  28.75%, val_best:  28.75%, tr:  31.15%, tr_best:  31.15%\n",
      "epoch-3   lr=['0.0001000'], tr/val_loss:  2.041898/  2.014980, val:  35.42%, val_best:  35.42%, tr:  36.36%, tr_best:  36.36%\n",
      "epoch-4   lr=['0.0001000'], tr/val_loss:  1.896256/  1.889628, val:  44.17%, val_best:  44.17%, tr:  44.43%, tr_best:  44.43%\n",
      "epoch-5   lr=['0.0001000'], tr/val_loss:  1.748099/  1.772367, val:  52.08%, val_best:  52.08%, tr:  51.58%, tr_best:  51.58%\n",
      "epoch-6   lr=['0.0001000'], tr/val_loss:  1.638729/  1.683801, val:  51.25%, val_best:  52.08%, tr:  54.44%, tr_best:  54.44%\n",
      "epoch-7   lr=['0.0001000'], tr/val_loss:  1.539507/  1.620188, val:  51.67%, val_best:  52.08%, tr:  56.28%, tr_best:  56.28%\n",
      "epoch-8   lr=['0.0001000'], tr/val_loss:  1.472672/  1.569295, val:  51.67%, val_best:  52.08%, tr:  58.84%, tr_best:  58.84%\n",
      "epoch-9   lr=['0.0001000'], tr/val_loss:  1.413925/  1.540248, val:  54.58%, val_best:  54.58%, tr:  59.35%, tr_best:  59.35%\n",
      "epoch-10  lr=['0.0001000'], tr/val_loss:  1.367932/  1.518119, val:  57.08%, val_best:  57.08%, tr:  61.80%, tr_best:  61.80%\n",
      "epoch-11  lr=['0.0001000'], tr/val_loss:  1.333848/  1.497510, val:  57.50%, val_best:  57.50%, tr:  61.49%, tr_best:  61.80%\n",
      "epoch-12  lr=['0.0001000'], tr/val_loss:  1.309448/  1.479422, val:  58.75%, val_best:  58.75%, tr:  63.33%, tr_best:  63.33%\n",
      "epoch-13  lr=['0.0001000'], tr/val_loss:  1.274219/  1.453078, val:  58.75%, val_best:  58.75%, tr:  65.47%, tr_best:  65.47%\n",
      "epoch-14  lr=['0.0001000'], tr/val_loss:  1.233719/  1.440511, val:  61.67%, val_best:  61.67%, tr:  64.76%, tr_best:  65.47%\n",
      "epoch-15  lr=['0.0001000'], tr/val_loss:  1.211459/  1.425827, val:  61.67%, val_best:  61.67%, tr:  65.58%, tr_best:  65.58%\n",
      "epoch-16  lr=['0.0001000'], tr/val_loss:  1.177989/  1.417976, val:  62.92%, val_best:  62.92%, tr:  66.70%, tr_best:  66.70%\n",
      "epoch-17  lr=['0.0001000'], tr/val_loss:  1.160033/  1.409971, val:  65.00%, val_best:  65.00%, tr:  70.28%, tr_best:  70.28%\n",
      "epoch-18  lr=['0.0001000'], tr/val_loss:  1.136146/  1.412413, val:  61.25%, val_best:  65.00%, tr:  69.56%, tr_best:  70.28%\n",
      "epoch-19  lr=['0.0001000'], tr/val_loss:  1.114133/  1.406669, val:  62.50%, val_best:  65.00%, tr:  68.03%, tr_best:  70.28%\n",
      "epoch-20  lr=['0.0001000'], tr/val_loss:  1.100747/  1.398512, val:  62.50%, val_best:  65.00%, tr:  70.17%, tr_best:  70.28%\n",
      "epoch-21  lr=['0.0001000'], tr/val_loss:  1.081393/  1.390615, val:  63.33%, val_best:  65.00%, tr:  69.36%, tr_best:  70.28%\n",
      "epoch-22  lr=['0.0001000'], tr/val_loss:  1.070916/  1.403631, val:  62.50%, val_best:  65.00%, tr:  69.36%, tr_best:  70.28%\n",
      "epoch-23  lr=['0.0001000'], tr/val_loss:  1.051012/  1.390382, val:  63.75%, val_best:  65.00%, tr:  73.75%, tr_best:  73.75%\n",
      "epoch-24  lr=['0.0001000'], tr/val_loss:  1.043203/  1.389802, val:  64.17%, val_best:  65.00%, tr:  72.83%, tr_best:  73.75%\n",
      "epoch-25  lr=['0.0001000'], tr/val_loss:  1.027005/  1.387312, val:  65.42%, val_best:  65.42%, tr:  74.46%, tr_best:  74.46%\n",
      "epoch-26  lr=['0.0001000'], tr/val_loss:  1.013845/  1.379179, val:  67.50%, val_best:  67.50%, tr:  71.40%, tr_best:  74.46%\n",
      "epoch-27  lr=['0.0001000'], tr/val_loss:  1.000873/  1.389217, val:  66.25%, val_best:  67.50%, tr:  74.26%, tr_best:  74.46%\n",
      "epoch-28  lr=['0.0001000'], tr/val_loss:  1.003676/  1.375755, val:  67.92%, val_best:  67.92%, tr:  73.54%, tr_best:  74.46%\n",
      "epoch-29  lr=['0.0001000'], tr/val_loss:  0.980573/  1.380359, val:  66.25%, val_best:  67.92%, tr:  73.75%, tr_best:  74.46%\n",
      "epoch-30  lr=['0.0001000'], tr/val_loss:  0.966132/  1.374784, val:  64.17%, val_best:  67.92%, tr:  73.85%, tr_best:  74.46%\n",
      "epoch-31  lr=['0.0001000'], tr/val_loss:  0.957393/  1.395083, val:  64.58%, val_best:  67.92%, tr:  75.89%, tr_best:  75.89%\n",
      "epoch-32  lr=['0.0001000'], tr/val_loss:  0.945597/  1.395291, val:  67.08%, val_best:  67.92%, tr:  78.45%, tr_best:  78.45%\n",
      "epoch-33  lr=['0.0001000'], tr/val_loss:  0.940043/  1.400489, val:  62.50%, val_best:  67.92%, tr:  76.92%, tr_best:  78.45%\n",
      "epoch-34  lr=['0.0001000'], tr/val_loss:  0.924317/  1.381571, val:  67.50%, val_best:  67.92%, tr:  76.40%, tr_best:  78.45%\n",
      "epoch-35  lr=['0.0001000'], tr/val_loss:  0.909652/  1.399213, val:  65.83%, val_best:  67.92%, tr:  78.55%, tr_best:  78.55%\n",
      "epoch-36  lr=['0.0001000'], tr/val_loss:  0.895365/  1.404877, val:  61.25%, val_best:  67.92%, tr:  78.45%, tr_best:  78.55%\n",
      "epoch-37  lr=['0.0001000'], tr/val_loss:  0.892515/  1.387748, val:  67.92%, val_best:  67.92%, tr:  79.98%, tr_best:  79.98%\n",
      "epoch-38  lr=['0.0001000'], tr/val_loss:  0.888280/  1.403591, val:  65.42%, val_best:  67.92%, tr:  80.59%, tr_best:  80.59%\n",
      "epoch-39  lr=['0.0001000'], tr/val_loss:  0.876579/  1.411001, val:  68.75%, val_best:  68.75%, tr:  80.39%, tr_best:  80.59%\n",
      "epoch-40  lr=['0.0001000'], tr/val_loss:  0.859804/  1.409213, val:  70.00%, val_best:  70.00%, tr:  80.08%, tr_best:  80.59%\n",
      "epoch-41  lr=['0.0001000'], tr/val_loss:  0.862451/  1.416988, val:  69.17%, val_best:  70.00%, tr:  84.27%, tr_best:  84.27%\n",
      "epoch-42  lr=['0.0001000'], tr/val_loss:  0.837594/  1.422313, val:  70.83%, val_best:  70.83%, tr:  83.86%, tr_best:  84.27%\n",
      "epoch-43  lr=['0.0001000'], tr/val_loss:  0.837487/  1.439984, val:  70.42%, val_best:  70.83%, tr:  82.94%, tr_best:  84.27%\n",
      "epoch-44  lr=['0.0001000'], tr/val_loss:  0.822694/  1.434338, val:  67.50%, val_best:  70.83%, tr:  81.51%, tr_best:  84.27%\n",
      "epoch-45  lr=['0.0001000'], tr/val_loss:  0.812676/  1.442480, val:  67.08%, val_best:  70.83%, tr:  84.98%, tr_best:  84.98%\n",
      "epoch-46  lr=['0.0001000'], tr/val_loss:  0.806235/  1.465301, val:  69.17%, val_best:  70.83%, tr:  85.60%, tr_best:  85.60%\n",
      "epoch-47  lr=['0.0001000'], tr/val_loss:  0.807378/  1.459584, val:  67.92%, val_best:  70.83%, tr:  82.33%, tr_best:  85.60%\n",
      "epoch-48  lr=['0.0001000'], tr/val_loss:  0.799996/  1.462873, val:  69.58%, val_best:  70.83%, tr:  85.19%, tr_best:  85.60%\n",
      "epoch-49  lr=['0.0001000'], tr/val_loss:  0.782770/  1.469377, val:  69.58%, val_best:  70.83%, tr:  84.17%, tr_best:  85.60%\n",
      "epoch-50  lr=['0.0001000'], tr/val_loss:  0.776169/  1.473082, val:  67.50%, val_best:  70.83%, tr:  85.39%, tr_best:  85.60%\n",
      "epoch-51  lr=['0.0001000'], tr/val_loss:  0.763633/  1.472373, val:  72.08%, val_best:  72.08%, tr:  84.78%, tr_best:  85.60%\n",
      "epoch-52  lr=['0.0001000'], tr/val_loss:  0.759737/  1.488658, val:  68.33%, val_best:  72.08%, tr:  84.98%, tr_best:  85.60%\n",
      "epoch-53  lr=['0.0001000'], tr/val_loss:  0.756089/  1.476337, val:  71.67%, val_best:  72.08%, tr:  87.44%, tr_best:  87.44%\n",
      "epoch-54  lr=['0.0001000'], tr/val_loss:  0.742976/  1.506180, val:  72.08%, val_best:  72.08%, tr:  88.36%, tr_best:  88.36%\n",
      "epoch-55  lr=['0.0001000'], tr/val_loss:  0.734388/  1.516059, val:  70.83%, val_best:  72.08%, tr:  87.84%, tr_best:  88.36%\n",
      "epoch-56  lr=['0.0001000'], tr/val_loss:  0.722085/  1.514117, val:  70.42%, val_best:  72.08%, tr:  90.81%, tr_best:  90.81%\n",
      "epoch-57  lr=['0.0001000'], tr/val_loss:  0.722675/  1.519652, val:  70.42%, val_best:  72.08%, tr:  87.84%, tr_best:  90.81%\n",
      "epoch-58  lr=['0.0001000'], tr/val_loss:  0.709394/  1.539378, val:  68.33%, val_best:  72.08%, tr:  87.74%, tr_best:  90.81%\n",
      "epoch-59  lr=['0.0001000'], tr/val_loss:  0.705155/  1.535435, val:  67.92%, val_best:  72.08%, tr:  88.66%, tr_best:  90.81%\n",
      "epoch-60  lr=['0.0001000'], tr/val_loss:  0.697094/  1.536928, val:  70.83%, val_best:  72.08%, tr:  87.03%, tr_best:  90.81%\n",
      "epoch-61  lr=['0.0001000'], tr/val_loss:  0.691130/  1.548148, val:  70.42%, val_best:  72.08%, tr:  89.68%, tr_best:  90.81%\n",
      "epoch-62  lr=['0.0001000'], tr/val_loss:  0.687160/  1.551219, val:  70.00%, val_best:  72.08%, tr:  91.01%, tr_best:  91.01%\n",
      "epoch-63  lr=['0.0001000'], tr/val_loss:  0.675487/  1.557055, val:  71.25%, val_best:  72.08%, tr:  92.24%, tr_best:  92.24%\n",
      "epoch-64  lr=['0.0001000'], tr/val_loss:  0.660816/  1.595102, val:  70.00%, val_best:  72.08%, tr:  91.73%, tr_best:  92.24%\n",
      "epoch-65  lr=['0.0001000'], tr/val_loss:  0.661589/  1.601824, val:  70.42%, val_best:  72.08%, tr:  91.11%, tr_best:  92.24%\n",
      "epoch-66  lr=['0.0001000'], tr/val_loss:  0.656101/  1.594857, val:  70.42%, val_best:  72.08%, tr:  91.11%, tr_best:  92.24%\n",
      "epoch-67  lr=['0.0001000'], tr/val_loss:  0.651906/  1.615110, val:  69.17%, val_best:  72.08%, tr:  92.54%, tr_best:  92.54%\n",
      "epoch-68  lr=['0.0001000'], tr/val_loss:  0.638830/  1.605360, val:  72.50%, val_best:  72.50%, tr:  89.17%, tr_best:  92.54%\n",
      "epoch-69  lr=['0.0001000'], tr/val_loss:  0.630694/  1.622622, val:  71.25%, val_best:  72.50%, tr:  92.44%, tr_best:  92.54%\n",
      "epoch-70  lr=['0.0001000'], tr/val_loss:  0.617260/  1.634359, val:  72.08%, val_best:  72.50%, tr:  92.54%, tr_best:  92.54%\n",
      "epoch-71  lr=['0.0001000'], tr/val_loss:  0.612456/  1.653409, val:  67.92%, val_best:  72.50%, tr:  94.69%, tr_best:  94.69%\n",
      "epoch-72  lr=['0.0001000'], tr/val_loss:  0.612243/  1.658630, val:  70.42%, val_best:  72.50%, tr:  92.75%, tr_best:  94.69%\n",
      "epoch-73  lr=['0.0001000'], tr/val_loss:  0.611175/  1.670766, val:  69.58%, val_best:  72.50%, tr:  93.56%, tr_best:  94.69%\n",
      "epoch-74  lr=['0.0001000'], tr/val_loss:  0.593225/  1.674336, val:  71.67%, val_best:  72.50%, tr:  93.05%, tr_best:  94.69%\n",
      "epoch-75  lr=['0.0001000'], tr/val_loss:  0.590896/  1.670853, val:  71.67%, val_best:  72.50%, tr:  93.05%, tr_best:  94.69%\n",
      "epoch-76  lr=['0.0001000'], tr/val_loss:  0.575723/  1.695098, val:  72.08%, val_best:  72.50%, tr:  94.79%, tr_best:  94.79%\n",
      "epoch-77  lr=['0.0001000'], tr/val_loss:  0.579316/  1.711316, val:  73.33%, val_best:  73.33%, tr:  94.79%, tr_best:  94.79%\n",
      "epoch-78  lr=['0.0001000'], tr/val_loss:  0.567727/  1.722082, val:  70.42%, val_best:  73.33%, tr:  95.10%, tr_best:  95.10%\n",
      "epoch-79  lr=['0.0001000'], tr/val_loss:  0.555404/  1.717279, val:  72.92%, val_best:  73.33%, tr:  94.69%, tr_best:  95.10%\n",
      "epoch-80  lr=['0.0001000'], tr/val_loss:  0.551458/  1.721017, val:  69.58%, val_best:  73.33%, tr:  94.89%, tr_best:  95.10%\n",
      "epoch-81  lr=['0.0001000'], tr/val_loss:  0.542791/  1.744801, val:  71.67%, val_best:  73.33%, tr:  96.63%, tr_best:  96.63%\n",
      "epoch-82  lr=['0.0001000'], tr/val_loss:  0.530900/  1.753384, val:  70.00%, val_best:  73.33%, tr:  96.83%, tr_best:  96.83%\n",
      "epoch-83  lr=['0.0001000'], tr/val_loss:  0.535381/  1.771306, val:  70.00%, val_best:  73.33%, tr:  96.94%, tr_best:  96.94%\n",
      "epoch-84  lr=['0.0001000'], tr/val_loss:  0.532803/  1.767917, val:  72.92%, val_best:  73.33%, tr:  96.83%, tr_best:  96.94%\n",
      "epoch-85  lr=['0.0001000'], tr/val_loss:  0.523707/  1.822000, val:  68.33%, val_best:  73.33%, tr:  97.14%, tr_best:  97.14%\n",
      "epoch-86  lr=['0.0001000'], tr/val_loss:  0.516406/  1.806190, val:  71.67%, val_best:  73.33%, tr:  95.81%, tr_best:  97.14%\n",
      "epoch-87  lr=['0.0001000'], tr/val_loss:  0.506380/  1.836660, val:  69.17%, val_best:  73.33%, tr:  97.34%, tr_best:  97.34%\n",
      "epoch-88  lr=['0.0001000'], tr/val_loss:  0.499937/  1.823088, val:  70.42%, val_best:  73.33%, tr:  97.45%, tr_best:  97.45%\n",
      "epoch-89  lr=['0.0001000'], tr/val_loss:  0.494666/  1.858912, val:  69.17%, val_best:  73.33%, tr:  97.24%, tr_best:  97.45%\n",
      "epoch-90  lr=['0.0001000'], tr/val_loss:  0.497165/  1.835578, val:  72.50%, val_best:  73.33%, tr:  97.55%, tr_best:  97.55%\n",
      "epoch-91  lr=['0.0001000'], tr/val_loss:  0.485037/  1.867218, val:  72.08%, val_best:  73.33%, tr:  97.34%, tr_best:  97.55%\n",
      "epoch-92  lr=['0.0001000'], tr/val_loss:  0.473732/  1.905592, val:  70.83%, val_best:  73.33%, tr:  98.26%, tr_best:  98.26%\n",
      "epoch-93  lr=['0.0001000'], tr/val_loss:  0.473049/  1.890897, val:  71.25%, val_best:  73.33%, tr:  97.34%, tr_best:  98.26%\n",
      "epoch-94  lr=['0.0001000'], tr/val_loss:  0.465543/  1.914122, val:  68.33%, val_best:  73.33%, tr:  98.37%, tr_best:  98.37%\n",
      "epoch-95  lr=['0.0001000'], tr/val_loss:  0.455312/  1.939580, val:  72.08%, val_best:  73.33%, tr:  97.85%, tr_best:  98.37%\n",
      "epoch-96  lr=['0.0001000'], tr/val_loss:  0.447406/  1.981976, val:  70.83%, val_best:  73.33%, tr:  98.67%, tr_best:  98.67%\n",
      "epoch-97  lr=['0.0001000'], tr/val_loss:  0.447138/  1.941023, val:  73.75%, val_best:  73.75%, tr:  96.63%, tr_best:  98.67%\n",
      "epoch-98  lr=['0.0001000'], tr/val_loss:  0.434230/  1.972731, val:  71.25%, val_best:  73.75%, tr:  98.88%, tr_best:  98.88%\n",
      "epoch-99  lr=['0.0001000'], tr/val_loss:  0.441102/  1.965990, val:  72.92%, val_best:  73.75%, tr:  97.96%, tr_best:  98.88%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7a19dce0c2174f3ea0b190947685c671",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.006 MB of 0.006 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>iter_acc</td><td>▁▃▁▃▃▅▆▅▃▇▆▇▅▇▇▇▇▆█▇▇▇▆▇▇█▇▇▇▇▇▇▇▇▇▇▇▇██</td></tr><tr><td>summary_val_acc</td><td>▁▂▄▅▅▆▆▇▆▇▇▇▇▇▇▇▇█▇▇▇▇██▇██▇█████▇█▇▇███</td></tr><tr><td>tr_acc</td><td>▁▂▄▅▅▅▅▆▅▆▆▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇█████████████</td></tr><tr><td>tr_epoch_loss</td><td>█▇▆▅▅▄▄▄▄▃▃▃▃▃▃▃▃▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁</td></tr><tr><td>val_acc_best</td><td>▁▂▄▅▅▆▆▇▇▇▇▇▇▇▇▇▇███████████████████████</td></tr><tr><td>val_acc_now</td><td>▁▂▄▅▅▆▆▇▆▇▇▇▇▇▇▇▇█▇▇▇▇██▇██▇█████▇█▇▇███</td></tr><tr><td>val_loss</td><td>█▇▅▃▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▂▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▅▅▅▅▅</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>99</td></tr><tr><td>iter_acc</td><td>1.0</td></tr><tr><td>tr_acc</td><td>0.97957</td></tr><tr><td>tr_epoch_loss</td><td>0.4411</td></tr><tr><td>val_acc_best</td><td>0.7375</td></tr><tr><td>val_acc_now</td><td>0.72917</td></tr><tr><td>val_loss</td><td>1.96599</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">likely-sweep-184</strong> at: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/ncuwinrs' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/ncuwinrs</a><br/> View project at: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>/data2/bh_wandb/wandb/run-20250430_045503-ncuwinrs/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require(\"core\")`! See https://wandb.me/wandb-core for more information."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: pdqzxyuh with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBATCH: 16\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBN_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBPTT_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tDFA_on: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tIMAGE_SIZE: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tOTTT_input_trace_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tTIME: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tUDA_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \talpha_uda: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbias: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcfg: ['M', 'M', 200, 200]\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tchaching_on: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tconvTrue_fcFalse: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdata_path: /data2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tddp_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdenoise_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdvs_clipping: 5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdvs_duration: 100000\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepoch_num: 100\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \texclude_class: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \textra_train_dataset: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlast_lif: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.001\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_sg_width: 5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_decay: 0.5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_init: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_reset: 10000\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_threshold: 0.25\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmerge_polarities: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmy_seed: 42\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnet_print: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_workers: 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer_what: SGD\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tpin_memory: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tpre_trained: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tpre_trained_path: net_save/save_now_net_weights_{unique_name}.pth\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \trate_coding: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tscheduler_name: no\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsingle_step: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsurrogate: hard_sigmoid\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_conv_kernel_size: 3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_conv_padding: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_conv_stride: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_trace_const1: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_trace_const2: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \ttdBN_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \ttrace_on: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \twhich_data: DVS_GESTURE_TONIC\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5d34f675faa543458028341846f38ad4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.011112845311355259, max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.19.10 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.17.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/data2/bh_wandb/wandb/run-20250430_050054-pdqzxyuh</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/pdqzxyuh' target=\"_blank\">radiant-sweep-186</a></strong> to <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/6pj3lh8j' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/6pj3lh8j</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/6pj3lh8j' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/6pj3lh8j</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/pdqzxyuh' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/pdqzxyuh</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'single_step' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'my_seed' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'TIME' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BATCH' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'IMAGE_SIZE' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'which_data' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'data_path' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'rate_coding' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_init' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_decay' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_threshold' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_reset' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_sg_width' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_conv_kernel_size' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_conv_stride' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_conv_padding' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_trace_const1' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_trace_const2' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'pre_trained' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'convTrue_fcFalse' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'cfg' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'net_print' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'pre_trained_path' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'learning_rate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'epoch_num' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'tdBN_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BN_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'surrogate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BPTT_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'optimizer_what' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'scheduler_name' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'ddp_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'dvs_clipping' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'dvs_duration' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'DFA_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'trace_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'OTTT_input_trace_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'exclude_class' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'merge_polarities' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'denoise_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'extra_train_dataset' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'num_workers' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'chaching_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'pin_memory' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'UDA_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'alpha_uda' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'bias' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'last_lif' was locked by 'sweep' (ignored update).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "param {'devices': '0', 'single_step': True, 'unique_name': 'main', 'my_seed': 42, 'TIME': 10, 'BATCH': 16, 'IMAGE_SIZE': 128, 'which_data': 'DVS_GESTURE_TONIC', 'data_path': '/data2', 'rate_coding': False, 'lif_layer_v_init': 0, 'lif_layer_v_decay': 0.5, 'lif_layer_v_threshold': 0.25, 'lif_layer_v_reset': 10000, 'lif_layer_sg_width': 5, 'synapse_conv_kernel_size': 3, 'synapse_conv_stride': 1, 'synapse_conv_padding': 1, 'synapse_trace_const1': 1, 'synapse_trace_const2': 0, 'pre_trained': False, 'convTrue_fcFalse': False, 'cfg': ['M', 'M', 200, 200], 'net_print': True, 'pre_trained_path': 'net_save/save_now_net_weights_{unique_name}.pth', 'learning_rate': 0.001, 'epoch_num': 100, 'tdBN_on': False, 'BN_on': False, 'surrogate': 'hard_sigmoid', 'BPTT_on': False, 'optimizer_what': 'SGD', 'scheduler_name': 'no', 'ddp_on': False, 'dvs_clipping': 5, 'dvs_duration': 100000, 'DFA_on': True, 'trace_on': True, 'OTTT_input_trace_on': False, 'exclude_class': True, 'merge_polarities': False, 'denoise_on': False, 'extra_train_dataset': 0, 'num_workers': 2, 'chaching_on': True, 'pin_memory': True, 'UDA_on': False, 'alpha_uda': 1, 'bias': True, 'last_lif': False, 'current epoch': 0} \n",
      "\n",
      "dataset_hash = ffa516e60c3efd5e0208f72b4c36cb84\n",
      "cache path exists\n",
      "\n",
      "device ==> cuda\n",
      "\n",
      "DataParallel(\n",
      "  (module): REBORN_MY_SNN_FC(\n",
      "    (layers): REBORN_MY_Sequential(\n",
      "      (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (2): DimChanger_for_FC()\n",
      "      (3): SYNAPSE_FC(in_features=2048, out_features=200, TIME=10, bias=True, sstep=True)\n",
      "      (4): LIF_layer(v_init=0, v_decay=0.5, v_threshold=0.25, v_reset=10000, sg_width=5, surrogate=hard_sigmoid, BPTT_on=False, trace_const1=1, trace_const2=0, TIME=10, sstep=True, trace_on=True)\n",
      "      (5): Feedback_Receiver()\n",
      "      (6): SYNAPSE_FC(in_features=200, out_features=200, TIME=10, bias=True, sstep=True)\n",
      "      (7): LIF_layer(v_init=0, v_decay=0.5, v_threshold=0.25, v_reset=10000, sg_width=5, surrogate=hard_sigmoid, BPTT_on=False, trace_const1=1, trace_const2=0, TIME=10, sstep=True, trace_on=True)\n",
      "      (8): Feedback_Receiver()\n",
      "      (9): SYNAPSE_FC(in_features=200, out_features=10, TIME=10, bias=True, sstep=True)\n",
      "      (DFA_top): Top_Gradient()\n",
      "    )\n",
      "  )\n",
      ")\n",
      "\n",
      "========================================================\n",
      "Trainable parameters: 452,010\n",
      "========================================================\n",
      "\n",
      "epoch-0   lr=['0.0010000'], tr/val_loss:  2.028139/  1.592847, val:  46.25%, val_best:  46.25%, tr:  24.51%, tr_best:  24.51%\n",
      "[module.layers.5] weight_fb parameter count: 2,000\n",
      "[module.layers.8] weight_fb parameter count: 2,000\n",
      "epoch-1   lr=['0.0010000'], tr/val_loss:  1.359148/  1.452800, val:  54.58%, val_best:  54.58%, tr:  53.22%, tr_best:  53.22%\n",
      "epoch-2   lr=['0.0010000'], tr/val_loss:  1.172410/  1.370669, val:  58.33%, val_best:  58.33%, tr:  60.98%, tr_best:  60.98%\n",
      "epoch-3   lr=['0.0010000'], tr/val_loss:  1.037907/  1.375689, val:  59.17%, val_best:  59.17%, tr:  67.11%, tr_best:  67.11%\n",
      "epoch-4   lr=['0.0010000'], tr/val_loss:  0.980912/  1.278879, val:  62.92%, val_best:  62.92%, tr:  67.82%, tr_best:  67.82%\n",
      "epoch-5   lr=['0.0010000'], tr/val_loss:  0.906009/  1.242650, val:  69.17%, val_best:  69.17%, tr:  70.89%, tr_best:  70.89%\n",
      "epoch-6   lr=['0.0010000'], tr/val_loss:  0.828173/  1.270944, val:  62.08%, val_best:  69.17%, tr:  77.53%, tr_best:  77.53%\n",
      "epoch-7   lr=['0.0010000'], tr/val_loss:  0.792747/  1.225965, val:  71.67%, val_best:  71.67%, tr:  79.78%, tr_best:  79.78%\n",
      "epoch-8   lr=['0.0010000'], tr/val_loss:  0.724543/  1.258821, val:  70.83%, val_best:  71.67%, tr:  84.37%, tr_best:  84.37%\n",
      "epoch-9   lr=['0.0010000'], tr/val_loss:  0.652725/  1.299900, val:  70.00%, val_best:  71.67%, tr:  88.66%, tr_best:  88.66%\n",
      "epoch-10  lr=['0.0010000'], tr/val_loss:  0.629645/  1.380174, val:  65.42%, val_best:  71.67%, tr:  89.99%, tr_best:  89.99%\n",
      "epoch-11  lr=['0.0010000'], tr/val_loss:  0.541935/  1.249633, val:  75.83%, val_best:  75.83%, tr:  93.87%, tr_best:  93.87%\n",
      "epoch-12  lr=['0.0010000'], tr/val_loss:  0.514340/  1.305119, val:  72.50%, val_best:  75.83%, tr:  96.12%, tr_best:  96.12%\n",
      "epoch-13  lr=['0.0010000'], tr/val_loss:  0.479788/  1.319019, val:  73.33%, val_best:  75.83%, tr:  95.91%, tr_best:  96.12%\n",
      "epoch-14  lr=['0.0010000'], tr/val_loss:  0.437470/  1.439117, val:  69.17%, val_best:  75.83%, tr:  95.91%, tr_best:  96.12%\n",
      "epoch-15  lr=['0.0010000'], tr/val_loss:  0.397095/  1.374266, val:  72.08%, val_best:  75.83%, tr:  96.83%, tr_best:  96.83%\n",
      "epoch-16  lr=['0.0010000'], tr/val_loss:  0.383447/  1.362620, val:  75.00%, val_best:  75.83%, tr:  97.65%, tr_best:  97.65%\n",
      "epoch-17  lr=['0.0010000'], tr/val_loss:  0.339613/  1.387274, val:  75.42%, val_best:  75.83%, tr:  98.37%, tr_best:  98.37%\n",
      "epoch-18  lr=['0.0010000'], tr/val_loss:  0.310731/  1.443095, val:  74.17%, val_best:  75.83%, tr:  98.88%, tr_best:  98.88%\n",
      "epoch-19  lr=['0.0010000'], tr/val_loss:  0.281602/  1.457281, val:  72.50%, val_best:  75.83%, tr:  99.59%, tr_best:  99.59%\n",
      "epoch-20  lr=['0.0010000'], tr/val_loss:  0.260330/  1.496386, val:  75.42%, val_best:  75.83%, tr:  99.18%, tr_best:  99.59%\n",
      "epoch-21  lr=['0.0010000'], tr/val_loss:  0.237807/  1.511728, val:  76.67%, val_best:  76.67%, tr:  99.49%, tr_best:  99.59%\n",
      "epoch-22  lr=['0.0010000'], tr/val_loss:  0.233115/  1.537873, val:  73.33%, val_best:  76.67%, tr:  99.28%, tr_best:  99.59%\n",
      "epoch-23  lr=['0.0010000'], tr/val_loss:  0.218707/  1.539712, val:  76.25%, val_best:  76.67%, tr:  99.49%, tr_best:  99.59%\n",
      "epoch-24  lr=['0.0010000'], tr/val_loss:  0.185400/  1.580727, val:  76.67%, val_best:  76.67%, tr:  99.90%, tr_best:  99.90%\n",
      "epoch-25  lr=['0.0010000'], tr/val_loss:  0.175556/  1.591241, val:  77.08%, val_best:  77.08%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-26  lr=['0.0010000'], tr/val_loss:  0.170726/  1.620739, val:  76.67%, val_best:  77.08%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-27  lr=['0.0010000'], tr/val_loss:  0.147543/  1.666804, val:  75.83%, val_best:  77.08%, tr:  99.90%, tr_best: 100.00%\n",
      "epoch-28  lr=['0.0010000'], tr/val_loss:  0.140338/  1.658522, val:  79.17%, val_best:  79.17%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-29  lr=['0.0010000'], tr/val_loss:  0.129106/  1.711643, val:  77.92%, val_best:  79.17%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-30  lr=['0.0010000'], tr/val_loss:  0.118277/  1.714618, val:  77.50%, val_best:  79.17%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-31  lr=['0.0010000'], tr/val_loss:  0.114229/  1.745297, val:  77.08%, val_best:  79.17%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-32  lr=['0.0010000'], tr/val_loss:  0.108794/  1.746772, val:  78.75%, val_best:  79.17%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-33  lr=['0.0010000'], tr/val_loss:  0.099719/  1.769329, val:  76.67%, val_best:  79.17%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-34  lr=['0.0010000'], tr/val_loss:  0.094765/  1.777351, val:  76.67%, val_best:  79.17%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-35  lr=['0.0010000'], tr/val_loss:  0.085538/  1.819155, val:  79.17%, val_best:  79.17%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-36  lr=['0.0010000'], tr/val_loss:  0.081991/  1.806224, val:  80.42%, val_best:  80.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-37  lr=['0.0010000'], tr/val_loss:  0.077478/  1.839087, val:  77.92%, val_best:  80.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-38  lr=['0.0010000'], tr/val_loss:  0.073880/  1.856295, val:  79.17%, val_best:  80.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-39  lr=['0.0010000'], tr/val_loss:  0.068541/  1.871885, val:  78.33%, val_best:  80.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-40  lr=['0.0010000'], tr/val_loss:  0.066091/  1.877254, val:  78.33%, val_best:  80.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-41  lr=['0.0010000'], tr/val_loss:  0.059582/  1.883103, val:  78.33%, val_best:  80.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-42  lr=['0.0010000'], tr/val_loss:  0.057150/  1.898186, val:  79.17%, val_best:  80.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-43  lr=['0.0010000'], tr/val_loss:  0.053055/  1.930614, val:  77.50%, val_best:  80.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-44  lr=['0.0010000'], tr/val_loss:  0.052040/  1.934664, val:  78.33%, val_best:  80.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-45  lr=['0.0010000'], tr/val_loss:  0.047080/  1.948691, val:  78.33%, val_best:  80.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-46  lr=['0.0010000'], tr/val_loss:  0.045153/  1.947651, val:  80.00%, val_best:  80.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-47  lr=['0.0010000'], tr/val_loss:  0.042373/  1.971918, val:  77.50%, val_best:  80.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-48  lr=['0.0010000'], tr/val_loss:  0.040820/  1.993019, val:  78.75%, val_best:  80.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-49  lr=['0.0010000'], tr/val_loss:  0.042922/  2.003283, val:  78.33%, val_best:  80.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-50  lr=['0.0010000'], tr/val_loss:  0.037908/  2.015486, val:  79.58%, val_best:  80.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-51  lr=['0.0010000'], tr/val_loss:  0.036576/  2.016422, val:  78.33%, val_best:  80.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-52  lr=['0.0010000'], tr/val_loss:  0.034765/  2.030987, val:  77.92%, val_best:  80.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-53  lr=['0.0010000'], tr/val_loss:  0.034194/  2.035668, val:  79.17%, val_best:  80.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-54  lr=['0.0010000'], tr/val_loss:  0.032217/  2.053547, val:  79.17%, val_best:  80.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-55  lr=['0.0010000'], tr/val_loss:  0.031153/  2.057937, val:  79.58%, val_best:  80.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-56  lr=['0.0010000'], tr/val_loss:  0.028815/  2.072199, val:  78.75%, val_best:  80.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-57  lr=['0.0010000'], tr/val_loss:  0.030262/  2.071578, val:  79.58%, val_best:  80.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-58  lr=['0.0010000'], tr/val_loss:  0.027974/  2.084116, val:  79.58%, val_best:  80.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-59  lr=['0.0010000'], tr/val_loss:  0.025928/  2.110423, val:  79.58%, val_best:  80.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-60  lr=['0.0010000'], tr/val_loss:  0.025309/  2.109636, val:  79.58%, val_best:  80.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-61  lr=['0.0010000'], tr/val_loss:  0.023703/  2.136156, val:  78.75%, val_best:  80.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-62  lr=['0.0010000'], tr/val_loss:  0.023794/  2.131308, val:  80.00%, val_best:  80.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-63  lr=['0.0010000'], tr/val_loss:  0.022915/  2.144013, val:  78.75%, val_best:  80.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-64  lr=['0.0010000'], tr/val_loss:  0.021853/  2.155857, val:  79.58%, val_best:  80.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-65  lr=['0.0010000'], tr/val_loss:  0.021353/  2.187888, val:  79.17%, val_best:  80.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-66  lr=['0.0010000'], tr/val_loss:  0.020484/  2.182837, val:  80.42%, val_best:  80.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-67  lr=['0.0010000'], tr/val_loss:  0.020200/  2.198571, val:  79.17%, val_best:  80.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-68  lr=['0.0010000'], tr/val_loss:  0.020592/  2.214689, val:  80.00%, val_best:  80.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-69  lr=['0.0010000'], tr/val_loss:  0.020009/  2.217655, val:  78.75%, val_best:  80.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-70  lr=['0.0010000'], tr/val_loss:  0.018754/  2.232708, val:  80.00%, val_best:  80.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-71  lr=['0.0010000'], tr/val_loss:  0.018889/  2.237149, val:  78.33%, val_best:  80.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-72  lr=['0.0010000'], tr/val_loss:  0.019099/  2.249823, val:  79.58%, val_best:  80.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-73  lr=['0.0010000'], tr/val_loss:  0.018795/  2.238959, val:  79.58%, val_best:  80.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-74  lr=['0.0010000'], tr/val_loss:  0.016490/  2.259507, val:  80.00%, val_best:  80.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-75  lr=['0.0010000'], tr/val_loss:  0.016898/  2.268950, val:  78.33%, val_best:  80.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-76  lr=['0.0010000'], tr/val_loss:  0.016593/  2.282781, val:  78.33%, val_best:  80.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-77  lr=['0.0010000'], tr/val_loss:  0.015691/  2.288814, val:  79.17%, val_best:  80.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-78  lr=['0.0010000'], tr/val_loss:  0.015454/  2.300466, val:  78.33%, val_best:  80.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-79  lr=['0.0010000'], tr/val_loss:  0.015195/  2.309854, val:  77.50%, val_best:  80.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-80  lr=['0.0010000'], tr/val_loss:  0.014882/  2.329836, val:  80.42%, val_best:  80.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-81  lr=['0.0010000'], tr/val_loss:  0.015891/  2.327632, val:  77.92%, val_best:  80.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-82  lr=['0.0010000'], tr/val_loss:  0.014352/  2.339455, val:  79.17%, val_best:  80.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-83  lr=['0.0010000'], tr/val_loss:  0.014717/  2.340610, val:  77.92%, val_best:  80.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-84  lr=['0.0010000'], tr/val_loss:  0.015021/  2.330253, val:  78.33%, val_best:  80.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-85  lr=['0.0010000'], tr/val_loss:  0.013652/  2.373216, val:  77.50%, val_best:  80.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-86  lr=['0.0010000'], tr/val_loss:  0.012952/  2.371182, val:  77.08%, val_best:  80.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-87  lr=['0.0010000'], tr/val_loss:  0.012821/  2.375852, val:  78.75%, val_best:  80.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-88  lr=['0.0010000'], tr/val_loss:  0.012033/  2.373488, val:  79.58%, val_best:  80.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-89  lr=['0.0010000'], tr/val_loss:  0.011957/  2.383958, val:  79.17%, val_best:  80.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-90  lr=['0.0010000'], tr/val_loss:  0.011447/  2.386796, val:  79.58%, val_best:  80.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-91  lr=['0.0010000'], tr/val_loss:  0.011099/  2.401892, val:  78.75%, val_best:  80.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-92  lr=['0.0010000'], tr/val_loss:  0.010223/  2.404218, val:  79.58%, val_best:  80.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-93  lr=['0.0010000'], tr/val_loss:  0.010221/  2.395703, val:  79.17%, val_best:  80.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-94  lr=['0.0010000'], tr/val_loss:  0.010546/  2.391907, val:  78.33%, val_best:  80.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-95  lr=['0.0010000'], tr/val_loss:  0.010309/  2.413658, val:  79.58%, val_best:  80.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-96  lr=['0.0010000'], tr/val_loss:  0.009576/  2.423692, val:  78.75%, val_best:  80.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-97  lr=['0.0010000'], tr/val_loss:  0.009929/  2.426923, val:  78.75%, val_best:  80.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-98  lr=['0.0010000'], tr/val_loss:  0.009222/  2.417862, val:  80.00%, val_best:  80.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-99  lr=['0.0010000'], tr/val_loss:  0.009844/  2.435319, val:  78.75%, val_best:  80.42%, tr: 100.00%, tr_best: 100.00%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d5f4b39a083641048946f63cffed60cd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.006 MB of 0.006 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>iter_acc</td><td>▁▆▅▆▆▇█▇▇███████████████████████████████</td></tr><tr><td>summary_val_acc</td><td>▁▄▄▆▆▆▆▇▆▇▇▇███████▇████████████▇███████</td></tr><tr><td>tr_acc</td><td>▁▄▅▆▇███████████████████████████████████</td></tr><tr><td>tr_epoch_loss</td><td>█▅▄▄▃▃▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_acc_best</td><td>▁▃▄▆▆▇▇▇▇▇▇▇████████████████████████████</td></tr><tr><td>val_acc_now</td><td>▁▄▄▆▆▆▆▇▆▇▇▇███████▇████████████▇███████</td></tr><tr><td>val_loss</td><td>▃▂▁▁▁▁▂▂▂▃▃▃▄▄▄▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇▇▇▇▇█████</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>99</td></tr><tr><td>iter_acc</td><td>1.0</td></tr><tr><td>tr_acc</td><td>1.0</td></tr><tr><td>tr_epoch_loss</td><td>0.00984</td></tr><tr><td>val_acc_best</td><td>0.80417</td></tr><tr><td>val_acc_now</td><td>0.7875</td></tr><tr><td>val_loss</td><td>2.43532</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">radiant-sweep-186</strong> at: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/pdqzxyuh' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/pdqzxyuh</a><br/> View project at: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>/data2/bh_wandb/wandb/run-20250430_050054-pdqzxyuh/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require(\"core\")`! See https://wandb.me/wandb-core for more information."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: icjbhlz2 with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBATCH: 16\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBN_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBPTT_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tDFA_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tIMAGE_SIZE: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tOTTT_input_trace_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tTIME: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tUDA_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \talpha_uda: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbias: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcfg: ['M', 'M', 200, 200]\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tchaching_on: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tconvTrue_fcFalse: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdata_path: /data2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tddp_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdenoise_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdvs_clipping: 5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdvs_duration: 100000\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepoch_num: 100\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \texclude_class: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \textra_train_dataset: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlast_lif: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.001\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_sg_width: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_decay: 0.5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_init: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_reset: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_threshold: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmerge_polarities: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmy_seed: 42\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnet_print: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_workers: 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer_what: SGD\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tpin_memory: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tpre_trained: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tpre_trained_path: net_save/save_now_net_weights_{unique_name}.pth\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \trate_coding: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tscheduler_name: no\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsingle_step: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsurrogate: hard_sigmoid\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_conv_kernel_size: 3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_conv_padding: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_conv_stride: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_trace_const1: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_trace_const2: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \ttdBN_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \ttrace_on: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \twhich_data: DVS_GESTURE_TONIC\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.19.10 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.17.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/data2/bh_wandb/wandb/run-20250430_050739-icjbhlz2</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/icjbhlz2' target=\"_blank\">colorful-sweep-188</a></strong> to <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/6pj3lh8j' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/6pj3lh8j</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/6pj3lh8j' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/6pj3lh8j</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/icjbhlz2' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/icjbhlz2</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'single_step' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'my_seed' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'TIME' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BATCH' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'IMAGE_SIZE' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'which_data' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'data_path' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'rate_coding' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_init' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_decay' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_threshold' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_reset' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_sg_width' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_conv_kernel_size' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_conv_stride' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_conv_padding' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_trace_const1' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_trace_const2' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'pre_trained' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'convTrue_fcFalse' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'cfg' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'net_print' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'pre_trained_path' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'learning_rate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'epoch_num' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'tdBN_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BN_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'surrogate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BPTT_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'optimizer_what' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'scheduler_name' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'ddp_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'dvs_clipping' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'dvs_duration' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'DFA_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'trace_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'OTTT_input_trace_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'exclude_class' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'merge_polarities' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'denoise_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'extra_train_dataset' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'num_workers' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'chaching_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'pin_memory' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'UDA_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'alpha_uda' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'bias' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'last_lif' was locked by 'sweep' (ignored update).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "param {'devices': '0', 'single_step': True, 'unique_name': 'main', 'my_seed': 42, 'TIME': 10, 'BATCH': 16, 'IMAGE_SIZE': 128, 'which_data': 'DVS_GESTURE_TONIC', 'data_path': '/data2', 'rate_coding': False, 'lif_layer_v_init': 0, 'lif_layer_v_decay': 0.5, 'lif_layer_v_threshold': 1, 'lif_layer_v_reset': 0, 'lif_layer_sg_width': 1, 'synapse_conv_kernel_size': 3, 'synapse_conv_stride': 1, 'synapse_conv_padding': 1, 'synapse_trace_const1': 1, 'synapse_trace_const2': 0, 'pre_trained': False, 'convTrue_fcFalse': False, 'cfg': ['M', 'M', 200, 200], 'net_print': True, 'pre_trained_path': 'net_save/save_now_net_weights_{unique_name}.pth', 'learning_rate': 0.001, 'epoch_num': 100, 'tdBN_on': False, 'BN_on': False, 'surrogate': 'hard_sigmoid', 'BPTT_on': False, 'optimizer_what': 'SGD', 'scheduler_name': 'no', 'ddp_on': False, 'dvs_clipping': 5, 'dvs_duration': 100000, 'DFA_on': False, 'trace_on': True, 'OTTT_input_trace_on': False, 'exclude_class': True, 'merge_polarities': False, 'denoise_on': False, 'extra_train_dataset': 0, 'num_workers': 2, 'chaching_on': True, 'pin_memory': True, 'UDA_on': False, 'alpha_uda': 1, 'bias': True, 'last_lif': False, 'current epoch': 0} \n",
      "\n",
      "dataset_hash = ffa516e60c3efd5e0208f72b4c36cb84\n",
      "cache path exists\n",
      "\n",
      "device ==> cuda\n",
      "\n",
      "DataParallel(\n",
      "  (module): REBORN_MY_SNN_FC(\n",
      "    (layers): REBORN_MY_Sequential(\n",
      "      (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (2): DimChanger_for_FC()\n",
      "      (3): SYNAPSE_FC(in_features=2048, out_features=200, TIME=10, bias=True, sstep=True)\n",
      "      (4): LIF_layer(v_init=0, v_decay=0.5, v_threshold=1, v_reset=0, sg_width=1, surrogate=hard_sigmoid, BPTT_on=False, trace_const1=1, trace_const2=0, TIME=10, sstep=True, trace_on=True)\n",
      "      (5): SYNAPSE_FC(in_features=200, out_features=200, TIME=10, bias=True, sstep=True)\n",
      "      (6): LIF_layer(v_init=0, v_decay=0.5, v_threshold=1, v_reset=0, sg_width=1, surrogate=hard_sigmoid, BPTT_on=False, trace_const1=1, trace_const2=0, TIME=10, sstep=True, trace_on=True)\n",
      "      (7): SYNAPSE_FC(in_features=200, out_features=10, TIME=10, bias=True, sstep=True)\n",
      "    )\n",
      "  )\n",
      ")\n",
      "\n",
      "========================================================\n",
      "Trainable parameters: 452,010\n",
      "========================================================\n",
      "\n",
      "epoch-0   lr=['0.0010000'], tr/val_loss:  2.305365/  2.302841, val:  10.00%, val_best:  10.00%, tr:   8.17%, tr_best:   8.17%\n",
      "epoch-1   lr=['0.0010000'], tr/val_loss:  2.304994/  2.302639, val:  10.00%, val_best:  10.00%, tr:   7.66%, tr_best:   8.17%\n",
      "epoch-2   lr=['0.0010000'], tr/val_loss:  2.305079/  2.302667, val:  10.00%, val_best:  10.00%, tr:   8.99%, tr_best:   8.99%\n",
      "epoch-3   lr=['0.0010000'], tr/val_loss:  2.304731/  2.302708, val:  10.00%, val_best:  10.00%, tr:   8.38%, tr_best:   8.99%\n",
      "epoch-4   lr=['0.0010000'], tr/val_loss:  2.304833/  2.302682, val:  10.00%, val_best:  10.00%, tr:   7.87%, tr_best:   8.99%\n",
      "epoch-5   lr=['0.0010000'], tr/val_loss:  2.304569/  2.302663, val:  10.00%, val_best:  10.00%, tr:   7.87%, tr_best:   8.99%\n",
      "epoch-6   lr=['0.0010000'], tr/val_loss:  2.305086/  2.302687, val:  10.00%, val_best:  10.00%, tr:   9.70%, tr_best:   9.70%\n",
      "epoch-7   lr=['0.0010000'], tr/val_loss:  2.304632/  2.302694, val:  10.00%, val_best:  10.00%, tr:   7.46%, tr_best:   9.70%\n",
      "epoch-8   lr=['0.0010000'], tr/val_loss:  2.304545/  2.302613, val:  10.00%, val_best:  10.00%, tr:   8.17%, tr_best:   9.70%\n",
      "epoch-9   lr=['0.0010000'], tr/val_loss:  2.305080/  2.302782, val:  10.00%, val_best:  10.00%, tr:   9.19%, tr_best:   9.70%\n",
      "epoch-10  lr=['0.0010000'], tr/val_loss:  2.304688/  2.302772, val:  10.00%, val_best:  10.00%, tr:  10.01%, tr_best:  10.01%\n",
      "epoch-11  lr=['0.0010000'], tr/val_loss:  2.304834/  2.302622, val:  10.00%, val_best:  10.00%, tr:   8.17%, tr_best:  10.01%\n",
      "epoch-12  lr=['0.0010000'], tr/val_loss:  2.304284/  2.302666, val:  10.00%, val_best:  10.00%, tr:   9.50%, tr_best:  10.01%\n",
      "epoch-13  lr=['0.0010000'], tr/val_loss:  2.304813/  2.302646, val:  10.00%, val_best:  10.00%, tr:   9.09%, tr_best:  10.01%\n",
      "epoch-14  lr=['0.0010000'], tr/val_loss:  2.305227/  2.302654, val:  10.00%, val_best:  10.00%, tr:   8.78%, tr_best:  10.01%\n",
      "epoch-15  lr=['0.0010000'], tr/val_loss:  2.305094/  2.302232, val:  10.00%, val_best:  10.00%, tr:   8.38%, tr_best:  10.01%\n",
      "epoch-16  lr=['0.0010000'], tr/val_loss:  2.303698/  2.300982, val:  10.83%, val_best:  10.83%, tr:   9.40%, tr_best:  10.01%\n",
      "epoch-17  lr=['0.0010000'], tr/val_loss:  2.298471/  2.296557, val:  11.67%, val_best:  11.67%, tr:  13.18%, tr_best:  13.18%\n",
      "epoch-18  lr=['0.0010000'], tr/val_loss:  2.283513/  2.280128, val:  19.17%, val_best:  19.17%, tr:  13.99%, tr_best:  13.99%\n",
      "epoch-19  lr=['0.0010000'], tr/val_loss:  2.244952/  2.244793, val:  17.50%, val_best:  19.17%, tr:  16.96%, tr_best:  16.96%\n",
      "epoch-20  lr=['0.0010000'], tr/val_loss:  2.194065/  2.206013, val:  26.25%, val_best:  26.25%, tr:  19.20%, tr_best:  19.20%\n",
      "epoch-21  lr=['0.0010000'], tr/val_loss:  2.132865/  2.149580, val:  27.92%, val_best:  27.92%, tr:  30.85%, tr_best:  30.85%\n",
      "epoch-22  lr=['0.0010000'], tr/val_loss:  2.048735/  2.066487, val:  33.33%, val_best:  33.33%, tr:  32.28%, tr_best:  32.28%\n",
      "epoch-23  lr=['0.0010000'], tr/val_loss:  1.952207/  1.977929, val:  40.83%, val_best:  40.83%, tr:  36.47%, tr_best:  36.47%\n",
      "epoch-24  lr=['0.0010000'], tr/val_loss:  1.847654/  1.886724, val:  47.08%, val_best:  47.08%, tr:  42.49%, tr_best:  42.49%\n",
      "epoch-25  lr=['0.0010000'], tr/val_loss:  1.748536/  1.796554, val:  47.08%, val_best:  47.08%, tr:  44.74%, tr_best:  44.74%\n",
      "epoch-26  lr=['0.0010000'], tr/val_loss:  1.655017/  1.722308, val:  46.25%, val_best:  47.08%, tr:  46.58%, tr_best:  46.58%\n",
      "epoch-27  lr=['0.0010000'], tr/val_loss:  1.575448/  1.664504, val:  49.17%, val_best:  49.17%, tr:  49.95%, tr_best:  49.95%\n",
      "epoch-28  lr=['0.0010000'], tr/val_loss:  1.524170/  1.621396, val:  52.08%, val_best:  52.08%, tr:  51.38%, tr_best:  51.38%\n",
      "epoch-29  lr=['0.0010000'], tr/val_loss:  1.468466/  1.585149, val:  50.42%, val_best:  52.08%, tr:  52.81%, tr_best:  52.81%\n",
      "epoch-30  lr=['0.0010000'], tr/val_loss:  1.431542/  1.566319, val:  50.42%, val_best:  52.08%, tr:  55.57%, tr_best:  55.57%\n",
      "epoch-31  lr=['0.0010000'], tr/val_loss:  1.397860/  1.523582, val:  53.75%, val_best:  53.75%, tr:  54.75%, tr_best:  55.57%\n",
      "epoch-32  lr=['0.0010000'], tr/val_loss:  1.366038/  1.511245, val:  54.17%, val_best:  54.17%, tr:  56.59%, tr_best:  56.59%\n",
      "epoch-33  lr=['0.0010000'], tr/val_loss:  1.349783/  1.488443, val:  54.17%, val_best:  54.17%, tr:  56.08%, tr_best:  56.59%\n",
      "epoch-34  lr=['0.0010000'], tr/val_loss:  1.327245/  1.466972, val:  55.83%, val_best:  55.83%, tr:  57.61%, tr_best:  57.61%\n",
      "epoch-35  lr=['0.0010000'], tr/val_loss:  1.297376/  1.467054, val:  56.67%, val_best:  56.67%, tr:  57.30%, tr_best:  57.61%\n",
      "epoch-36  lr=['0.0010000'], tr/val_loss:  1.285881/  1.445177, val:  54.17%, val_best:  56.67%, tr:  58.84%, tr_best:  58.84%\n",
      "epoch-37  lr=['0.0010000'], tr/val_loss:  1.263414/  1.427626, val:  56.67%, val_best:  56.67%, tr:  60.27%, tr_best:  60.27%\n",
      "epoch-38  lr=['0.0010000'], tr/val_loss:  1.252828/  1.425227, val:  53.75%, val_best:  56.67%, tr:  59.45%, tr_best:  60.27%\n",
      "epoch-39  lr=['0.0010000'], tr/val_loss:  1.234639/  1.412354, val:  56.67%, val_best:  56.67%, tr:  61.29%, tr_best:  61.29%\n",
      "epoch-40  lr=['0.0010000'], tr/val_loss:  1.218829/  1.408826, val:  55.00%, val_best:  56.67%, tr:  59.24%, tr_best:  61.29%\n",
      "epoch-41  lr=['0.0010000'], tr/val_loss:  1.205501/  1.399122, val:  56.67%, val_best:  56.67%, tr:  61.49%, tr_best:  61.49%\n",
      "epoch-42  lr=['0.0010000'], tr/val_loss:  1.186620/  1.391878, val:  57.50%, val_best:  57.50%, tr:  61.80%, tr_best:  61.80%\n",
      "epoch-43  lr=['0.0010000'], tr/val_loss:  1.174782/  1.386770, val:  59.17%, val_best:  59.17%, tr:  60.57%, tr_best:  61.80%\n",
      "epoch-44  lr=['0.0010000'], tr/val_loss:  1.157711/  1.381048, val:  57.50%, val_best:  59.17%, tr:  61.18%, tr_best:  61.80%\n",
      "epoch-45  lr=['0.0010000'], tr/val_loss:  1.148990/  1.368418, val:  59.17%, val_best:  59.17%, tr:  62.61%, tr_best:  62.61%\n",
      "epoch-46  lr=['0.0010000'], tr/val_loss:  1.127508/  1.379318, val:  56.25%, val_best:  59.17%, tr:  61.80%, tr_best:  62.61%\n",
      "epoch-47  lr=['0.0010000'], tr/val_loss:  1.130443/  1.361639, val:  57.50%, val_best:  59.17%, tr:  64.25%, tr_best:  64.25%\n",
      "epoch-48  lr=['0.0010000'], tr/val_loss:  1.113261/  1.355827, val:  59.17%, val_best:  59.17%, tr:  64.04%, tr_best:  64.25%\n",
      "epoch-49  lr=['0.0010000'], tr/val_loss:  1.102956/  1.339539, val:  59.58%, val_best:  59.58%, tr:  64.76%, tr_best:  64.76%\n",
      "epoch-50  lr=['0.0010000'], tr/val_loss:  1.092792/  1.337198, val:  58.75%, val_best:  59.58%, tr:  65.58%, tr_best:  65.58%\n",
      "epoch-51  lr=['0.0010000'], tr/val_loss:  1.079401/  1.322046, val:  60.42%, val_best:  60.42%, tr:  64.86%, tr_best:  65.58%\n",
      "epoch-52  lr=['0.0010000'], tr/val_loss:  1.073529/  1.325107, val:  60.83%, val_best:  60.83%, tr:  65.88%, tr_best:  65.88%\n",
      "epoch-53  lr=['0.0010000'], tr/val_loss:  1.062738/  1.318367, val:  62.50%, val_best:  62.50%, tr:  65.68%, tr_best:  65.88%\n",
      "epoch-54  lr=['0.0010000'], tr/val_loss:  1.050422/  1.324710, val:  59.58%, val_best:  62.50%, tr:  66.80%, tr_best:  66.80%\n",
      "epoch-55  lr=['0.0010000'], tr/val_loss:  1.040303/  1.320586, val:  60.00%, val_best:  62.50%, tr:  67.93%, tr_best:  67.93%\n",
      "epoch-56  lr=['0.0010000'], tr/val_loss:  1.026348/  1.316693, val:  62.08%, val_best:  62.50%, tr:  68.23%, tr_best:  68.23%\n",
      "epoch-57  lr=['0.0010000'], tr/val_loss:  1.019041/  1.319185, val:  61.25%, val_best:  62.50%, tr:  66.09%, tr_best:  68.23%\n",
      "epoch-58  lr=['0.0010000'], tr/val_loss:  1.005825/  1.316020, val:  62.92%, val_best:  62.92%, tr:  68.95%, tr_best:  68.95%\n",
      "epoch-59  lr=['0.0010000'], tr/val_loss:  1.007431/  1.299038, val:  63.75%, val_best:  63.75%, tr:  69.36%, tr_best:  69.36%\n",
      "epoch-60  lr=['0.0010000'], tr/val_loss:  0.989251/  1.301855, val:  60.00%, val_best:  63.75%, tr:  68.34%, tr_best:  69.36%\n",
      "epoch-61  lr=['0.0010000'], tr/val_loss:  0.991045/  1.305343, val:  61.25%, val_best:  63.75%, tr:  70.07%, tr_best:  70.07%\n",
      "epoch-62  lr=['0.0010000'], tr/val_loss:  0.986847/  1.296861, val:  61.67%, val_best:  63.75%, tr:  70.79%, tr_best:  70.79%\n",
      "epoch-63  lr=['0.0010000'], tr/val_loss:  0.964649/  1.288295, val:  62.08%, val_best:  63.75%, tr:  69.66%, tr_best:  70.79%\n",
      "epoch-64  lr=['0.0010000'], tr/val_loss:  0.954361/  1.306583, val:  63.75%, val_best:  63.75%, tr:  70.48%, tr_best:  70.79%\n",
      "epoch-65  lr=['0.0010000'], tr/val_loss:  0.955481/  1.292167, val:  63.75%, val_best:  63.75%, tr:  70.07%, tr_best:  70.79%\n",
      "epoch-66  lr=['0.0010000'], tr/val_loss:  0.950084/  1.287401, val:  62.50%, val_best:  63.75%, tr:  70.99%, tr_best:  70.99%\n",
      "epoch-67  lr=['0.0010000'], tr/val_loss:  0.948499/  1.294310, val:  62.92%, val_best:  63.75%, tr:  72.93%, tr_best:  72.93%\n",
      "epoch-68  lr=['0.0010000'], tr/val_loss:  0.936104/  1.291777, val:  60.83%, val_best:  63.75%, tr:  70.58%, tr_best:  72.93%\n",
      "epoch-69  lr=['0.0010000'], tr/val_loss:  0.920957/  1.287982, val:  61.67%, val_best:  63.75%, tr:  71.20%, tr_best:  72.93%\n",
      "epoch-70  lr=['0.0010000'], tr/val_loss:  0.916501/  1.286142, val:  63.33%, val_best:  63.75%, tr:  71.71%, tr_best:  72.93%\n",
      "epoch-71  lr=['0.0010000'], tr/val_loss:  0.907981/  1.294289, val:  62.08%, val_best:  63.75%, tr:  72.63%, tr_best:  72.93%\n",
      "epoch-72  lr=['0.0010000'], tr/val_loss:  0.902791/  1.296246, val:  63.75%, val_best:  63.75%, tr:  72.22%, tr_best:  72.93%\n",
      "epoch-73  lr=['0.0010000'], tr/val_loss:  0.905917/  1.289707, val:  62.50%, val_best:  63.75%, tr:  71.09%, tr_best:  72.93%\n",
      "epoch-74  lr=['0.0010000'], tr/val_loss:  0.891441/  1.286716, val:  62.08%, val_best:  63.75%, tr:  71.50%, tr_best:  72.93%\n",
      "epoch-75  lr=['0.0010000'], tr/val_loss:  0.890795/  1.289369, val:  64.17%, val_best:  64.17%, tr:  72.01%, tr_best:  72.93%\n",
      "epoch-76  lr=['0.0010000'], tr/val_loss:  0.877024/  1.295089, val:  65.00%, val_best:  65.00%, tr:  73.65%, tr_best:  73.65%\n",
      "epoch-77  lr=['0.0010000'], tr/val_loss:  0.883740/  1.300710, val:  61.25%, val_best:  65.00%, tr:  72.93%, tr_best:  73.65%\n",
      "epoch-78  lr=['0.0010000'], tr/val_loss:  0.873229/  1.287178, val:  62.92%, val_best:  65.00%, tr:  74.97%, tr_best:  74.97%\n",
      "epoch-79  lr=['0.0010000'], tr/val_loss:  0.866373/  1.298981, val:  63.75%, val_best:  65.00%, tr:  73.44%, tr_best:  74.97%\n",
      "epoch-80  lr=['0.0010000'], tr/val_loss:  0.856832/  1.286579, val:  61.67%, val_best:  65.00%, tr:  73.44%, tr_best:  74.97%\n",
      "epoch-81  lr=['0.0010000'], tr/val_loss:  0.860130/  1.295243, val:  61.67%, val_best:  65.00%, tr:  73.34%, tr_best:  74.97%\n",
      "epoch-82  lr=['0.0010000'], tr/val_loss:  0.843831/  1.299495, val:  63.33%, val_best:  65.00%, tr:  75.59%, tr_best:  75.59%\n",
      "epoch-83  lr=['0.0010000'], tr/val_loss:  0.849447/  1.293949, val:  65.83%, val_best:  65.83%, tr:  76.20%, tr_best:  76.20%\n",
      "epoch-84  lr=['0.0010000'], tr/val_loss:  0.849678/  1.295250, val:  62.92%, val_best:  65.83%, tr:  75.79%, tr_best:  76.20%\n",
      "epoch-85  lr=['0.0010000'], tr/val_loss:  0.839564/  1.321531, val:  63.75%, val_best:  65.83%, tr:  77.53%, tr_best:  77.53%\n",
      "epoch-86  lr=['0.0010000'], tr/val_loss:  0.824174/  1.307929, val:  62.08%, val_best:  65.83%, tr:  76.00%, tr_best:  77.53%\n",
      "epoch-87  lr=['0.0010000'], tr/val_loss:  0.824458/  1.304956, val:  66.67%, val_best:  66.67%, tr:  77.43%, tr_best:  77.53%\n",
      "epoch-88  lr=['0.0010000'], tr/val_loss:  0.817836/  1.311997, val:  64.58%, val_best:  66.67%, tr:  75.89%, tr_best:  77.53%\n",
      "epoch-89  lr=['0.0010000'], tr/val_loss:  0.807227/  1.344811, val:  62.08%, val_best:  66.67%, tr:  77.63%, tr_best:  77.63%\n",
      "epoch-90  lr=['0.0010000'], tr/val_loss:  0.816934/  1.310664, val:  65.42%, val_best:  66.67%, tr:  75.18%, tr_best:  77.63%\n",
      "epoch-91  lr=['0.0010000'], tr/val_loss:  0.794455/  1.300047, val:  62.50%, val_best:  66.67%, tr:  78.14%, tr_best:  78.14%\n",
      "epoch-92  lr=['0.0010000'], tr/val_loss:  0.799748/  1.323378, val:  64.58%, val_best:  66.67%, tr:  76.51%, tr_best:  78.14%\n",
      "epoch-93  lr=['0.0010000'], tr/val_loss:  0.797913/  1.308169, val:  65.00%, val_best:  66.67%, tr:  77.63%, tr_best:  78.14%\n",
      "epoch-94  lr=['0.0010000'], tr/val_loss:  0.794446/  1.317665, val:  65.42%, val_best:  66.67%, tr:  76.30%, tr_best:  78.14%\n",
      "epoch-95  lr=['0.0010000'], tr/val_loss:  0.777490/  1.316923, val:  65.42%, val_best:  66.67%, tr:  78.86%, tr_best:  78.86%\n",
      "epoch-96  lr=['0.0010000'], tr/val_loss:  0.778207/  1.314270, val:  65.00%, val_best:  66.67%, tr:  80.18%, tr_best:  80.18%\n",
      "epoch-97  lr=['0.0010000'], tr/val_loss:  0.771998/  1.299485, val:  65.42%, val_best:  66.67%, tr:  77.22%, tr_best:  80.18%\n",
      "epoch-98  lr=['0.0010000'], tr/val_loss:  0.769857/  1.330960, val:  65.42%, val_best:  66.67%, tr:  78.55%, tr_best:  80.18%\n",
      "epoch-99  lr=['0.0010000'], tr/val_loss:  0.766414/  1.310362, val:  65.00%, val_best:  66.67%, tr:  78.65%, tr_best:  80.18%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f37f7090d1744e1e9521843975839745",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.006 MB of 0.006 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>iter_acc</td><td>▁▂▁▁▁▁▁▂▂▃▅▆▄▄▄▅▅▅▇▆▅▆▅▅▇▆▇▇▇▅▆▆▅▇▆▆▅▇█▇</td></tr><tr><td>summary_val_acc</td><td>▁▁▁▁▁▁▁▁▂▃▆▅▆▆▇▇▇▇▇▇▇▇▇▇█▇█████▇████▇███</td></tr><tr><td>tr_acc</td><td>▁▁▁▁▁▁▁▂▂▃▄▅▅▆▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇███████</td></tr><tr><td>tr_epoch_loss</td><td>█████████▇▆▅▄▄▃▃▃▃▃▃▃▂▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁</td></tr><tr><td>val_acc_best</td><td>▁▁▁▁▁▁▁▁▂▃▆▆▆▆▇▇▇▇▇▇▇▇▇▇████████████████</td></tr><tr><td>val_acc_now</td><td>▁▁▁▁▁▁▁▁▂▃▆▅▆▆▇▇▇▇▇▇▇▇▇▇█▇█████▇████▇███</td></tr><tr><td>val_loss</td><td>█████████▇▅▄▃▃▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>99</td></tr><tr><td>iter_acc</td><td>1.0</td></tr><tr><td>tr_acc</td><td>0.78652</td></tr><tr><td>tr_epoch_loss</td><td>0.76641</td></tr><tr><td>val_acc_best</td><td>0.66667</td></tr><tr><td>val_acc_now</td><td>0.65</td></tr><tr><td>val_loss</td><td>1.31036</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">colorful-sweep-188</strong> at: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/icjbhlz2' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/icjbhlz2</a><br/> View project at: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>/data2/bh_wandb/wandb/run-20250430_050739-icjbhlz2/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require(\"core\")`! See https://wandb.me/wandb-core for more information."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: yswfcmf4 with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBATCH: 16\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBN_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBPTT_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tDFA_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tIMAGE_SIZE: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tOTTT_input_trace_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tTIME: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tUDA_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \talpha_uda: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbias: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcfg: ['M', 'M', 200, 200]\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tchaching_on: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tconvTrue_fcFalse: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdata_path: /data2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tddp_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdenoise_on: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdvs_clipping: 5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdvs_duration: 100000\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepoch_num: 100\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \texclude_class: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \textra_train_dataset: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlast_lif: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.001\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_sg_width: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_decay: 0.5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_init: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_reset: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_threshold: 0.5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmerge_polarities: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmy_seed: 42\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnet_print: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_workers: 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer_what: SGD\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tpin_memory: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tpre_trained: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tpre_trained_path: net_save/save_now_net_weights_{unique_name}.pth\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \trate_coding: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tscheduler_name: no\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsingle_step: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsurrogate: hard_sigmoid\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_conv_kernel_size: 3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_conv_padding: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_conv_stride: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_trace_const1: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_trace_const2: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \ttdBN_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \ttrace_on: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \twhich_data: DVS_GESTURE_TONIC\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.19.10 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.17.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/data2/bh_wandb/wandb/run-20250430_051333-yswfcmf4</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/yswfcmf4' target=\"_blank\">radiant-sweep-190</a></strong> to <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/6pj3lh8j' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/6pj3lh8j</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/6pj3lh8j' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/6pj3lh8j</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/yswfcmf4' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/yswfcmf4</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'single_step' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'my_seed' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'TIME' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BATCH' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'IMAGE_SIZE' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'which_data' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'data_path' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'rate_coding' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_init' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_decay' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_threshold' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_reset' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_sg_width' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_conv_kernel_size' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_conv_stride' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_conv_padding' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_trace_const1' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_trace_const2' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'pre_trained' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'convTrue_fcFalse' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'cfg' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'net_print' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'pre_trained_path' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'learning_rate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'epoch_num' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'tdBN_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BN_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'surrogate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BPTT_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'optimizer_what' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'scheduler_name' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'ddp_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'dvs_clipping' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'dvs_duration' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'DFA_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'trace_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'OTTT_input_trace_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'exclude_class' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'merge_polarities' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'denoise_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'extra_train_dataset' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'num_workers' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'chaching_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'pin_memory' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'UDA_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'alpha_uda' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'bias' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'last_lif' was locked by 'sweep' (ignored update).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "param {'devices': '0', 'single_step': True, 'unique_name': 'main', 'my_seed': 42, 'TIME': 10, 'BATCH': 16, 'IMAGE_SIZE': 128, 'which_data': 'DVS_GESTURE_TONIC', 'data_path': '/data2', 'rate_coding': False, 'lif_layer_v_init': 0, 'lif_layer_v_decay': 0.5, 'lif_layer_v_threshold': 0.5, 'lif_layer_v_reset': 0, 'lif_layer_sg_width': 1, 'synapse_conv_kernel_size': 3, 'synapse_conv_stride': 1, 'synapse_conv_padding': 1, 'synapse_trace_const1': 1, 'synapse_trace_const2': 0, 'pre_trained': False, 'convTrue_fcFalse': False, 'cfg': ['M', 'M', 200, 200], 'net_print': True, 'pre_trained_path': 'net_save/save_now_net_weights_{unique_name}.pth', 'learning_rate': 0.001, 'epoch_num': 100, 'tdBN_on': False, 'BN_on': False, 'surrogate': 'hard_sigmoid', 'BPTT_on': False, 'optimizer_what': 'SGD', 'scheduler_name': 'no', 'ddp_on': False, 'dvs_clipping': 5, 'dvs_duration': 100000, 'DFA_on': False, 'trace_on': True, 'OTTT_input_trace_on': False, 'exclude_class': True, 'merge_polarities': False, 'denoise_on': True, 'extra_train_dataset': 0, 'num_workers': 2, 'chaching_on': True, 'pin_memory': True, 'UDA_on': False, 'alpha_uda': 1, 'bias': True, 'last_lif': False, 'current epoch': 0} \n",
      "\n",
      "dataset_hash = 63cc597115630ec173f3099200061e53\n",
      "cache path exists\n",
      "\n",
      "device ==> cuda\n",
      "\n",
      "DataParallel(\n",
      "  (module): REBORN_MY_SNN_FC(\n",
      "    (layers): REBORN_MY_Sequential(\n",
      "      (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (2): DimChanger_for_FC()\n",
      "      (3): SYNAPSE_FC(in_features=2048, out_features=200, TIME=10, bias=True, sstep=True)\n",
      "      (4): LIF_layer(v_init=0, v_decay=0.5, v_threshold=0.5, v_reset=0, sg_width=1, surrogate=hard_sigmoid, BPTT_on=False, trace_const1=1, trace_const2=0, TIME=10, sstep=True, trace_on=True)\n",
      "      (5): SYNAPSE_FC(in_features=200, out_features=200, TIME=10, bias=True, sstep=True)\n",
      "      (6): LIF_layer(v_init=0, v_decay=0.5, v_threshold=0.5, v_reset=0, sg_width=1, surrogate=hard_sigmoid, BPTT_on=False, trace_const1=1, trace_const2=0, TIME=10, sstep=True, trace_on=True)\n",
      "      (7): SYNAPSE_FC(in_features=200, out_features=10, TIME=10, bias=True, sstep=True)\n",
      "    )\n",
      "  )\n",
      ")\n",
      "\n",
      "========================================================\n",
      "Trainable parameters: 452,010\n",
      "========================================================\n",
      "\n",
      "epoch-0   lr=['0.0010000'], tr/val_loss:  2.305365/  2.302841, val:  10.00%, val_best:  10.00%, tr:   8.17%, tr_best:   8.17%\n",
      "epoch-1   lr=['0.0010000'], tr/val_loss:  2.304994/  2.302639, val:  10.00%, val_best:  10.00%, tr:   7.66%, tr_best:   8.17%\n",
      "epoch-2   lr=['0.0010000'], tr/val_loss:  2.305096/  2.302658, val:  10.00%, val_best:  10.00%, tr:   8.99%, tr_best:   8.99%\n",
      "epoch-3   lr=['0.0010000'], tr/val_loss:  2.304735/  2.302727, val:  10.00%, val_best:  10.00%, tr:   8.27%, tr_best:   8.99%\n",
      "epoch-4   lr=['0.0010000'], tr/val_loss:  2.304764/  2.302583, val:  10.83%, val_best:  10.83%, tr:   8.17%, tr_best:   8.99%\n",
      "epoch-5   lr=['0.0010000'], tr/val_loss:  2.304108/  2.301949, val:  10.00%, val_best:  10.83%, tr:   8.27%, tr_best:   8.99%\n",
      "epoch-6   lr=['0.0010000'], tr/val_loss:  2.303110/  2.300555, val:  11.67%, val_best:  11.67%, tr:  11.64%, tr_best:  11.64%\n",
      "epoch-7   lr=['0.0010000'], tr/val_loss:  2.297648/  2.295352, val:  16.67%, val_best:  16.67%, tr:  13.18%, tr_best:  13.18%\n",
      "epoch-8   lr=['0.0010000'], tr/val_loss:  2.279468/  2.279875, val:  15.83%, val_best:  16.67%, tr:  16.75%, tr_best:  16.75%\n",
      "epoch-9   lr=['0.0010000'], tr/val_loss:  2.244174/  2.255273, val:  21.25%, val_best:  21.25%, tr:  18.59%, tr_best:  18.59%\n",
      "epoch-10  lr=['0.0010000'], tr/val_loss:  2.202443/  2.223512, val:  28.33%, val_best:  28.33%, tr:  22.37%, tr_best:  22.37%\n",
      "epoch-11  lr=['0.0010000'], tr/val_loss:  2.155884/  2.175553, val:  36.25%, val_best:  36.25%, tr:  27.48%, tr_best:  27.48%\n",
      "epoch-12  lr=['0.0010000'], tr/val_loss:  2.082253/  2.093220, val:  38.75%, val_best:  38.75%, tr:  35.85%, tr_best:  35.85%\n",
      "epoch-13  lr=['0.0010000'], tr/val_loss:  1.969021/  1.987634, val:  40.42%, val_best:  40.42%, tr:  43.51%, tr_best:  43.51%\n",
      "epoch-14  lr=['0.0010000'], tr/val_loss:  1.845898/  1.887970, val:  48.33%, val_best:  48.33%, tr:  45.35%, tr_best:  45.35%\n",
      "epoch-15  lr=['0.0010000'], tr/val_loss:  1.731291/  1.805317, val:  48.75%, val_best:  48.75%, tr:  49.44%, tr_best:  49.44%\n",
      "epoch-16  lr=['0.0010000'], tr/val_loss:  1.640273/  1.731377, val:  49.58%, val_best:  49.58%, tr:  51.69%, tr_best:  51.69%\n",
      "epoch-17  lr=['0.0010000'], tr/val_loss:  1.568917/  1.671375, val:  49.58%, val_best:  49.58%, tr:  53.63%, tr_best:  53.63%\n",
      "epoch-18  lr=['0.0010000'], tr/val_loss:  1.501940/  1.634598, val:  48.33%, val_best:  49.58%, tr:  57.20%, tr_best:  57.20%\n",
      "epoch-19  lr=['0.0010000'], tr/val_loss:  1.456175/  1.607936, val:  48.75%, val_best:  49.58%, tr:  55.36%, tr_best:  57.20%\n",
      "epoch-20  lr=['0.0010000'], tr/val_loss:  1.412154/  1.575655, val:  48.33%, val_best:  49.58%, tr:  57.61%, tr_best:  57.61%\n",
      "epoch-21  lr=['0.0010000'], tr/val_loss:  1.372841/  1.554667, val:  51.25%, val_best:  51.25%, tr:  58.63%, tr_best:  58.63%\n",
      "epoch-22  lr=['0.0010000'], tr/val_loss:  1.355471/  1.532932, val:  53.33%, val_best:  53.33%, tr:  58.32%, tr_best:  58.63%\n",
      "epoch-23  lr=['0.0010000'], tr/val_loss:  1.315694/  1.508384, val:  50.42%, val_best:  53.33%, tr:  61.49%, tr_best:  61.49%\n",
      "epoch-24  lr=['0.0010000'], tr/val_loss:  1.290979/  1.494020, val:  53.33%, val_best:  53.33%, tr:  62.31%, tr_best:  62.31%\n",
      "epoch-25  lr=['0.0010000'], tr/val_loss:  1.270141/  1.462083, val:  55.83%, val_best:  55.83%, tr:  61.80%, tr_best:  62.31%\n",
      "epoch-26  lr=['0.0010000'], tr/val_loss:  1.250724/  1.435709, val:  56.25%, val_best:  56.25%, tr:  60.27%, tr_best:  62.31%\n",
      "epoch-27  lr=['0.0010000'], tr/val_loss:  1.229350/  1.421818, val:  57.08%, val_best:  57.08%, tr:  62.41%, tr_best:  62.41%\n",
      "epoch-28  lr=['0.0010000'], tr/val_loss:  1.218200/  1.411407, val:  56.67%, val_best:  57.08%, tr:  62.72%, tr_best:  62.72%\n",
      "epoch-29  lr=['0.0010000'], tr/val_loss:  1.197459/  1.402075, val:  55.83%, val_best:  57.08%, tr:  63.23%, tr_best:  63.23%\n",
      "epoch-30  lr=['0.0010000'], tr/val_loss:  1.181881/  1.400040, val:  55.00%, val_best:  57.08%, tr:  64.25%, tr_best:  64.25%\n",
      "epoch-31  lr=['0.0010000'], tr/val_loss:  1.171957/  1.381776, val:  55.83%, val_best:  57.08%, tr:  63.53%, tr_best:  64.25%\n",
      "epoch-32  lr=['0.0010000'], tr/val_loss:  1.154694/  1.394811, val:  59.17%, val_best:  59.17%, tr:  66.09%, tr_best:  66.09%\n",
      "epoch-33  lr=['0.0010000'], tr/val_loss:  1.146358/  1.375470, val:  57.50%, val_best:  59.17%, tr:  66.29%, tr_best:  66.29%\n",
      "epoch-34  lr=['0.0010000'], tr/val_loss:  1.130311/  1.347824, val:  59.58%, val_best:  59.58%, tr:  65.68%, tr_best:  66.29%\n",
      "epoch-35  lr=['0.0010000'], tr/val_loss:  1.110353/  1.356374, val:  57.92%, val_best:  59.58%, tr:  65.88%, tr_best:  66.29%\n",
      "epoch-36  lr=['0.0010000'], tr/val_loss:  1.107481/  1.347598, val:  58.33%, val_best:  59.58%, tr:  66.70%, tr_best:  66.70%\n",
      "epoch-37  lr=['0.0010000'], tr/val_loss:  1.094237/  1.329283, val:  62.08%, val_best:  62.08%, tr:  68.23%, tr_best:  68.23%\n",
      "epoch-38  lr=['0.0010000'], tr/val_loss:  1.087206/  1.327825, val:  58.75%, val_best:  62.08%, tr:  68.74%, tr_best:  68.74%\n",
      "epoch-39  lr=['0.0010000'], tr/val_loss:  1.076208/  1.319117, val:  59.58%, val_best:  62.08%, tr:  68.44%, tr_best:  68.74%\n",
      "epoch-40  lr=['0.0010000'], tr/val_loss:  1.061619/  1.317894, val:  58.75%, val_best:  62.08%, tr:  67.82%, tr_best:  68.74%\n",
      "epoch-41  lr=['0.0010000'], tr/val_loss:  1.057338/  1.315534, val:  61.67%, val_best:  62.08%, tr:  70.89%, tr_best:  70.89%\n",
      "epoch-42  lr=['0.0010000'], tr/val_loss:  1.039782/  1.304278, val:  63.33%, val_best:  63.33%, tr:  71.20%, tr_best:  71.20%\n",
      "epoch-43  lr=['0.0010000'], tr/val_loss:  1.037823/  1.305005, val:  60.83%, val_best:  63.33%, tr:  69.36%, tr_best:  71.20%\n",
      "epoch-44  lr=['0.0010000'], tr/val_loss:  1.028168/  1.293521, val:  59.17%, val_best:  63.33%, tr:  68.95%, tr_best:  71.20%\n",
      "epoch-45  lr=['0.0010000'], tr/val_loss:  1.012406/  1.290553, val:  62.50%, val_best:  63.33%, tr:  71.09%, tr_best:  71.20%\n",
      "epoch-46  lr=['0.0010000'], tr/val_loss:  1.007120/  1.303748, val:  60.00%, val_best:  63.33%, tr:  70.68%, tr_best:  71.20%\n",
      "epoch-47  lr=['0.0010000'], tr/val_loss:  1.006931/  1.283756, val:  62.08%, val_best:  63.33%, tr:  69.66%, tr_best:  71.20%\n",
      "epoch-48  lr=['0.0010000'], tr/val_loss:  0.995081/  1.277798, val:  62.50%, val_best:  63.33%, tr:  72.01%, tr_best:  72.01%\n",
      "epoch-49  lr=['0.0010000'], tr/val_loss:  0.988918/  1.267120, val:  61.25%, val_best:  63.33%, tr:  69.97%, tr_best:  72.01%\n",
      "epoch-50  lr=['0.0010000'], tr/val_loss:  0.976777/  1.282294, val:  60.42%, val_best:  63.33%, tr:  72.01%, tr_best:  72.01%\n",
      "epoch-51  lr=['0.0010000'], tr/val_loss:  0.971477/  1.274745, val:  62.50%, val_best:  63.33%, tr:  72.32%, tr_best:  72.32%\n",
      "epoch-52  lr=['0.0010000'], tr/val_loss:  0.967830/  1.271485, val:  62.92%, val_best:  63.33%, tr:  70.48%, tr_best:  72.32%\n",
      "epoch-53  lr=['0.0010000'], tr/val_loss:  0.960934/  1.269077, val:  64.58%, val_best:  64.58%, tr:  72.63%, tr_best:  72.63%\n",
      "epoch-54  lr=['0.0010000'], tr/val_loss:  0.955846/  1.263673, val:  60.83%, val_best:  64.58%, tr:  73.03%, tr_best:  73.03%\n",
      "epoch-55  lr=['0.0010000'], tr/val_loss:  0.951295/  1.262338, val:  62.50%, val_best:  64.58%, tr:  73.14%, tr_best:  73.14%\n",
      "epoch-56  lr=['0.0010000'], tr/val_loss:  0.941338/  1.261093, val:  62.92%, val_best:  64.58%, tr:  74.97%, tr_best:  74.97%\n",
      "epoch-57  lr=['0.0010000'], tr/val_loss:  0.934506/  1.255893, val:  61.67%, val_best:  64.58%, tr:  73.85%, tr_best:  74.97%\n",
      "epoch-58  lr=['0.0010000'], tr/val_loss:  0.928522/  1.262231, val:  62.50%, val_best:  64.58%, tr:  73.75%, tr_best:  74.97%\n",
      "epoch-59  lr=['0.0010000'], tr/val_loss:  0.932937/  1.246776, val:  62.08%, val_best:  64.58%, tr:  73.14%, tr_best:  74.97%\n",
      "epoch-60  lr=['0.0010000'], tr/val_loss:  0.922331/  1.242424, val:  60.00%, val_best:  64.58%, tr:  72.01%, tr_best:  74.97%\n",
      "epoch-61  lr=['0.0010000'], tr/val_loss:  0.927630/  1.252295, val:  61.25%, val_best:  64.58%, tr:  73.65%, tr_best:  74.97%\n",
      "epoch-62  lr=['0.0010000'], tr/val_loss:  0.919937/  1.237889, val:  63.33%, val_best:  64.58%, tr:  75.79%, tr_best:  75.79%\n",
      "epoch-63  lr=['0.0010000'], tr/val_loss:  0.906111/  1.230172, val:  58.75%, val_best:  64.58%, tr:  73.75%, tr_best:  75.79%\n",
      "epoch-64  lr=['0.0010000'], tr/val_loss:  0.900287/  1.258694, val:  61.67%, val_best:  64.58%, tr:  74.46%, tr_best:  75.79%\n",
      "epoch-65  lr=['0.0010000'], tr/val_loss:  0.900471/  1.242647, val:  62.92%, val_best:  64.58%, tr:  74.46%, tr_best:  75.79%\n",
      "epoch-66  lr=['0.0010000'], tr/val_loss:  0.896941/  1.223915, val:  67.50%, val_best:  67.50%, tr:  75.18%, tr_best:  75.79%\n",
      "epoch-67  lr=['0.0010000'], tr/val_loss:  0.906210/  1.244170, val:  62.08%, val_best:  67.50%, tr:  76.71%, tr_best:  76.71%\n",
      "epoch-68  lr=['0.0010000'], tr/val_loss:  0.888872/  1.241760, val:  61.25%, val_best:  67.50%, tr:  74.36%, tr_best:  76.71%\n",
      "epoch-69  lr=['0.0010000'], tr/val_loss:  0.882140/  1.231780, val:  67.08%, val_best:  67.50%, tr:  75.49%, tr_best:  76.71%\n",
      "epoch-70  lr=['0.0010000'], tr/val_loss:  0.879181/  1.238455, val:  62.50%, val_best:  67.50%, tr:  75.79%, tr_best:  76.71%\n",
      "epoch-71  lr=['0.0010000'], tr/val_loss:  0.869433/  1.250386, val:  62.92%, val_best:  67.50%, tr:  76.71%, tr_best:  76.71%\n",
      "epoch-72  lr=['0.0010000'], tr/val_loss:  0.862235/  1.259092, val:  62.50%, val_best:  67.50%, tr:  76.92%, tr_best:  76.92%\n",
      "epoch-73  lr=['0.0010000'], tr/val_loss:  0.868671/  1.237282, val:  60.83%, val_best:  67.50%, tr:  75.28%, tr_best:  76.92%\n",
      "epoch-74  lr=['0.0010000'], tr/val_loss:  0.857247/  1.240453, val:  61.67%, val_best:  67.50%, tr:  74.57%, tr_best:  76.92%\n",
      "epoch-75  lr=['0.0010000'], tr/val_loss:  0.860618/  1.229734, val:  64.58%, val_best:  67.50%, tr:  76.51%, tr_best:  76.92%\n",
      "epoch-76  lr=['0.0010000'], tr/val_loss:  0.842753/  1.245531, val:  64.17%, val_best:  67.50%, tr:  78.24%, tr_best:  78.24%\n",
      "epoch-77  lr=['0.0010000'], tr/val_loss:  0.849976/  1.262758, val:  60.00%, val_best:  67.50%, tr:  76.71%, tr_best:  78.24%\n",
      "epoch-78  lr=['0.0010000'], tr/val_loss:  0.845735/  1.244547, val:  67.92%, val_best:  67.92%, tr:  77.53%, tr_best:  78.24%\n",
      "epoch-79  lr=['0.0010000'], tr/val_loss:  0.835075/  1.260167, val:  60.83%, val_best:  67.92%, tr:  76.00%, tr_best:  78.24%\n",
      "epoch-80  lr=['0.0010000'], tr/val_loss:  0.829617/  1.232015, val:  61.67%, val_best:  67.92%, tr:  75.89%, tr_best:  78.24%\n",
      "epoch-81  lr=['0.0010000'], tr/val_loss:  0.832165/  1.246413, val:  61.67%, val_best:  67.92%, tr:  75.89%, tr_best:  78.24%\n",
      "epoch-82  lr=['0.0010000'], tr/val_loss:  0.820799/  1.249053, val:  67.08%, val_best:  67.92%, tr:  78.04%, tr_best:  78.24%\n",
      "epoch-83  lr=['0.0010000'], tr/val_loss:  0.817419/  1.241693, val:  67.50%, val_best:  67.92%, tr:  79.57%, tr_best:  79.57%\n",
      "epoch-84  lr=['0.0010000'], tr/val_loss:  0.819789/  1.243441, val:  62.08%, val_best:  67.92%, tr:  80.18%, tr_best:  80.18%\n",
      "epoch-85  lr=['0.0010000'], tr/val_loss:  0.812491/  1.254008, val:  62.50%, val_best:  67.92%, tr:  80.39%, tr_best:  80.39%\n",
      "epoch-86  lr=['0.0010000'], tr/val_loss:  0.805454/  1.247182, val:  65.42%, val_best:  67.92%, tr:  78.86%, tr_best:  80.39%\n",
      "epoch-87  lr=['0.0010000'], tr/val_loss:  0.805582/  1.240115, val:  67.08%, val_best:  67.92%, tr:  80.69%, tr_best:  80.69%\n",
      "epoch-88  lr=['0.0010000'], tr/val_loss:  0.793152/  1.260102, val:  62.50%, val_best:  67.92%, tr:  79.26%, tr_best:  80.69%\n",
      "epoch-89  lr=['0.0010000'], tr/val_loss:  0.784192/  1.285646, val:  59.17%, val_best:  67.92%, tr:  81.31%, tr_best:  81.31%\n",
      "epoch-90  lr=['0.0010000'], tr/val_loss:  0.793666/  1.250211, val:  62.92%, val_best:  67.92%, tr:  78.75%, tr_best:  81.31%\n",
      "epoch-91  lr=['0.0010000'], tr/val_loss:  0.777654/  1.245639, val:  65.83%, val_best:  67.92%, tr:  80.29%, tr_best:  81.31%\n",
      "epoch-92  lr=['0.0010000'], tr/val_loss:  0.782696/  1.257532, val:  62.08%, val_best:  67.92%, tr:  78.14%, tr_best:  81.31%\n",
      "epoch-93  lr=['0.0010000'], tr/val_loss:  0.781053/  1.256205, val:  65.00%, val_best:  67.92%, tr:  80.29%, tr_best:  81.31%\n",
      "epoch-94  lr=['0.0010000'], tr/val_loss:  0.780280/  1.262112, val:  68.75%, val_best:  68.75%, tr:  79.98%, tr_best:  81.31%\n",
      "epoch-95  lr=['0.0010000'], tr/val_loss:  0.771178/  1.258531, val:  64.17%, val_best:  68.75%, tr:  81.21%, tr_best:  81.31%\n",
      "epoch-96  lr=['0.0010000'], tr/val_loss:  0.766061/  1.264429, val:  64.58%, val_best:  68.75%, tr:  83.96%, tr_best:  83.96%\n",
      "epoch-97  lr=['0.0010000'], tr/val_loss:  0.768297/  1.241145, val:  70.42%, val_best:  70.42%, tr:  79.37%, tr_best:  83.96%\n",
      "epoch-98  lr=['0.0010000'], tr/val_loss:  0.760433/  1.273827, val:  61.25%, val_best:  70.42%, tr:  82.33%, tr_best:  83.96%\n",
      "epoch-99  lr=['0.0010000'], tr/val_loss:  0.763880/  1.251539, val:  65.42%, val_best:  70.42%, tr:  81.31%, tr_best:  83.96%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f750a30c183044b5ad3ebb41e8e068fe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.006 MB of 0.006 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>iter_acc</td><td>▁▂▁▁▂▃▅▄▃▆▆▇▇▅▅▅▆▆▇▇▆▆▅▅▇█▇▇▆▅▇▇▅▆▆▇▆▇█▇</td></tr><tr><td>summary_val_acc</td><td>▁▁▁▂▂▄▅▆▅▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇█▇█▇▇▇█</td></tr><tr><td>tr_acc</td><td>▁▁▁▁▂▄▅▅▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇█▇███▇███████</td></tr><tr><td>tr_epoch_loss</td><td>█████▇▆▅▄▄▃▃▃▃▃▂▂▂▂▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_acc_best</td><td>▁▁▁▂▂▄▅▆▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇█████████████</td></tr><tr><td>val_acc_now</td><td>▁▁▁▂▂▄▅▆▅▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇█▇█▇▇▇█</td></tr><tr><td>val_loss</td><td>█████▇▅▄▃▃▃▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>99</td></tr><tr><td>iter_acc</td><td>1.0</td></tr><tr><td>tr_acc</td><td>0.81307</td></tr><tr><td>tr_epoch_loss</td><td>0.76388</td></tr><tr><td>val_acc_best</td><td>0.70417</td></tr><tr><td>val_acc_now</td><td>0.65417</td></tr><tr><td>val_loss</td><td>1.25154</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">radiant-sweep-190</strong> at: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/yswfcmf4' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/yswfcmf4</a><br/> View project at: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>/data2/bh_wandb/wandb/run-20250430_051333-yswfcmf4/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require(\"core\")`! See https://wandb.me/wandb-core for more information."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: plr1l26s with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBATCH: 16\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBN_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBPTT_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tDFA_on: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tIMAGE_SIZE: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tOTTT_input_trace_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tTIME: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tUDA_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \talpha_uda: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbias: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcfg: ['M', 'M', 200, 200]\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tchaching_on: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tconvTrue_fcFalse: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdata_path: /data2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tddp_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdenoise_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdvs_clipping: 5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdvs_duration: 100000\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepoch_num: 100\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \texclude_class: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \textra_train_dataset: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlast_lif: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.001\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_sg_width: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_decay: 0.5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_init: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_reset: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_threshold: 0.25\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmerge_polarities: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmy_seed: 42\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnet_print: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_workers: 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer_what: SGD\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tpin_memory: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tpre_trained: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tpre_trained_path: net_save/save_now_net_weights_{unique_name}.pth\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \trate_coding: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tscheduler_name: no\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsingle_step: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsurrogate: hard_sigmoid\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_conv_kernel_size: 3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_conv_padding: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_conv_stride: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_trace_const1: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_trace_const2: 0.5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \ttdBN_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \ttrace_on: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \twhich_data: DVS_GESTURE_TONIC\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.19.10 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.17.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/data2/bh_wandb/wandb/run-20250430_051928-plr1l26s</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/plr1l26s' target=\"_blank\">generous-sweep-191</a></strong> to <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/6pj3lh8j' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/6pj3lh8j</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/6pj3lh8j' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/6pj3lh8j</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/plr1l26s' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/plr1l26s</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'single_step' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'my_seed' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'TIME' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BATCH' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'IMAGE_SIZE' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'which_data' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'data_path' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'rate_coding' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_init' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_decay' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_threshold' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_reset' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_sg_width' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_conv_kernel_size' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_conv_stride' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_conv_padding' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_trace_const1' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_trace_const2' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'pre_trained' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'convTrue_fcFalse' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'cfg' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'net_print' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'pre_trained_path' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'learning_rate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'epoch_num' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'tdBN_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BN_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'surrogate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BPTT_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'optimizer_what' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'scheduler_name' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'ddp_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'dvs_clipping' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'dvs_duration' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'DFA_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'trace_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'OTTT_input_trace_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'exclude_class' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'merge_polarities' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'denoise_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'extra_train_dataset' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'num_workers' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'chaching_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'pin_memory' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'UDA_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'alpha_uda' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'bias' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'last_lif' was locked by 'sweep' (ignored update).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "param {'devices': '0', 'single_step': True, 'unique_name': 'main', 'my_seed': 42, 'TIME': 10, 'BATCH': 16, 'IMAGE_SIZE': 128, 'which_data': 'DVS_GESTURE_TONIC', 'data_path': '/data2', 'rate_coding': False, 'lif_layer_v_init': 0, 'lif_layer_v_decay': 0.5, 'lif_layer_v_threshold': 0.25, 'lif_layer_v_reset': 0, 'lif_layer_sg_width': 1, 'synapse_conv_kernel_size': 3, 'synapse_conv_stride': 1, 'synapse_conv_padding': 1, 'synapse_trace_const1': 1, 'synapse_trace_const2': 0.5, 'pre_trained': False, 'convTrue_fcFalse': False, 'cfg': ['M', 'M', 200, 200], 'net_print': True, 'pre_trained_path': 'net_save/save_now_net_weights_{unique_name}.pth', 'learning_rate': 0.001, 'epoch_num': 100, 'tdBN_on': False, 'BN_on': False, 'surrogate': 'hard_sigmoid', 'BPTT_on': False, 'optimizer_what': 'SGD', 'scheduler_name': 'no', 'ddp_on': False, 'dvs_clipping': 5, 'dvs_duration': 100000, 'DFA_on': True, 'trace_on': True, 'OTTT_input_trace_on': False, 'exclude_class': True, 'merge_polarities': False, 'denoise_on': False, 'extra_train_dataset': 0, 'num_workers': 2, 'chaching_on': True, 'pin_memory': True, 'UDA_on': False, 'alpha_uda': 1, 'bias': True, 'last_lif': False, 'current epoch': 0} \n",
      "\n",
      "dataset_hash = ffa516e60c3efd5e0208f72b4c36cb84\n",
      "cache path exists\n",
      "\n",
      "device ==> cuda\n",
      "\n",
      "DataParallel(\n",
      "  (module): REBORN_MY_SNN_FC(\n",
      "    (layers): REBORN_MY_Sequential(\n",
      "      (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (2): DimChanger_for_FC()\n",
      "      (3): SYNAPSE_FC(in_features=2048, out_features=200, TIME=10, bias=True, sstep=True)\n",
      "      (4): LIF_layer(v_init=0, v_decay=0.5, v_threshold=0.25, v_reset=0, sg_width=1, surrogate=hard_sigmoid, BPTT_on=False, trace_const1=1, trace_const2=0.5, TIME=10, sstep=True, trace_on=True)\n",
      "      (5): Feedback_Receiver()\n",
      "      (6): SYNAPSE_FC(in_features=200, out_features=200, TIME=10, bias=True, sstep=True)\n",
      "      (7): LIF_layer(v_init=0, v_decay=0.5, v_threshold=0.25, v_reset=0, sg_width=1, surrogate=hard_sigmoid, BPTT_on=False, trace_const1=1, trace_const2=0.5, TIME=10, sstep=True, trace_on=True)\n",
      "      (8): Feedback_Receiver()\n",
      "      (9): SYNAPSE_FC(in_features=200, out_features=10, TIME=10, bias=True, sstep=True)\n",
      "      (DFA_top): Top_Gradient()\n",
      "    )\n",
      "  )\n",
      ")\n",
      "\n",
      "========================================================\n",
      "Trainable parameters: 452,010\n",
      "========================================================\n",
      "\n",
      "epoch-0   lr=['0.0010000'], tr/val_loss:  2.144575/  1.817533, val:  41.25%, val_best:  41.25%, tr:  21.25%, tr_best:  21.25%\n",
      "[module.layers.5] weight_fb parameter count: 2,000\n",
      "[module.layers.8] weight_fb parameter count: 2,000\n",
      "epoch-1   lr=['0.0010000'], tr/val_loss:  1.491291/  1.456961, val:  53.75%, val_best:  53.75%, tr:  52.30%, tr_best:  52.30%\n",
      "epoch-2   lr=['0.0010000'], tr/val_loss:  1.279740/  1.418671, val:  53.75%, val_best:  53.75%, tr:  58.02%, tr_best:  58.02%\n",
      "epoch-3   lr=['0.0010000'], tr/val_loss:  1.175622/  1.402506, val:  55.83%, val_best:  55.83%, tr:  63.23%, tr_best:  63.23%\n",
      "epoch-4   lr=['0.0010000'], tr/val_loss:  1.119980/  1.366083, val:  58.75%, val_best:  58.75%, tr:  63.64%, tr_best:  63.64%\n",
      "epoch-5   lr=['0.0010000'], tr/val_loss:  1.060521/  1.300567, val:  65.83%, val_best:  65.83%, tr:  65.37%, tr_best:  65.37%\n",
      "epoch-6   lr=['0.0010000'], tr/val_loss:  1.000824/  1.301821, val:  61.25%, val_best:  65.83%, tr:  70.68%, tr_best:  70.68%\n",
      "epoch-7   lr=['0.0010000'], tr/val_loss:  0.985290/  1.314859, val:  61.25%, val_best:  65.83%, tr:  69.05%, tr_best:  70.68%\n",
      "epoch-8   lr=['0.0010000'], tr/val_loss:  0.949520/  1.354883, val:  64.58%, val_best:  65.83%, tr:  71.20%, tr_best:  71.20%\n",
      "epoch-9   lr=['0.0010000'], tr/val_loss:  0.934873/  1.356147, val:  57.92%, val_best:  65.83%, tr:  73.44%, tr_best:  73.44%\n",
      "epoch-10  lr=['0.0010000'], tr/val_loss:  0.923953/  1.396143, val:  56.67%, val_best:  65.83%, tr:  73.44%, tr_best:  73.44%\n",
      "epoch-11  lr=['0.0010000'], tr/val_loss:  0.875370/  1.339741, val:  62.50%, val_best:  65.83%, tr:  76.71%, tr_best:  76.71%\n",
      "epoch-12  lr=['0.0010000'], tr/val_loss:  0.883515/  1.354796, val:  62.50%, val_best:  65.83%, tr:  77.02%, tr_best:  77.02%\n",
      "epoch-13  lr=['0.0010000'], tr/val_loss:  0.864338/  1.359563, val:  63.75%, val_best:  65.83%, tr:  77.22%, tr_best:  77.22%\n",
      "epoch-14  lr=['0.0010000'], tr/val_loss:  0.817443/  1.511845, val:  62.50%, val_best:  65.83%, tr:  79.37%, tr_best:  79.37%\n",
      "epoch-15  lr=['0.0010000'], tr/val_loss:  0.809220/  1.439581, val:  61.67%, val_best:  65.83%, tr:  81.72%, tr_best:  81.72%\n",
      "epoch-16  lr=['0.0010000'], tr/val_loss:  0.819770/  1.386554, val:  64.17%, val_best:  65.83%, tr:  81.10%, tr_best:  81.72%\n",
      "epoch-17  lr=['0.0010000'], tr/val_loss:  0.783346/  1.407303, val:  67.08%, val_best:  67.08%, tr:  84.68%, tr_best:  84.68%\n",
      "epoch-18  lr=['0.0010000'], tr/val_loss:  0.762966/  1.542733, val:  59.17%, val_best:  67.08%, tr:  84.07%, tr_best:  84.68%\n",
      "epoch-19  lr=['0.0010000'], tr/val_loss:  0.764121/  1.509853, val:  67.08%, val_best:  67.08%, tr:  83.96%, tr_best:  84.68%\n",
      "epoch-20  lr=['0.0010000'], tr/val_loss:  0.738797/  1.569989, val:  62.92%, val_best:  67.08%, tr:  86.62%, tr_best:  86.62%\n",
      "epoch-21  lr=['0.0010000'], tr/val_loss:  0.716952/  1.523091, val:  64.17%, val_best:  67.08%, tr:  86.72%, tr_best:  86.72%\n",
      "epoch-22  lr=['0.0010000'], tr/val_loss:  0.725320/  1.552056, val:  63.33%, val_best:  67.08%, tr:  85.90%, tr_best:  86.72%\n",
      "epoch-23  lr=['0.0010000'], tr/val_loss:  0.698502/  1.585925, val:  65.00%, val_best:  67.08%, tr:  89.38%, tr_best:  89.38%\n",
      "epoch-24  lr=['0.0010000'], tr/val_loss:  0.677743/  1.635015, val:  64.58%, val_best:  67.08%, tr:  91.11%, tr_best:  91.11%\n",
      "epoch-25  lr=['0.0010000'], tr/val_loss:  0.680546/  1.617494, val:  67.92%, val_best:  67.92%, tr:  90.60%, tr_best:  91.11%\n",
      "epoch-26  lr=['0.0010000'], tr/val_loss:  0.685079/  1.622059, val:  68.33%, val_best:  68.33%, tr:  90.09%, tr_best:  91.11%\n",
      "epoch-27  lr=['0.0010000'], tr/val_loss:  0.668759/  1.668863, val:  67.50%, val_best:  68.33%, tr:  90.91%, tr_best:  91.11%\n",
      "epoch-28  lr=['0.0010000'], tr/val_loss:  0.670493/  1.717578, val:  68.33%, val_best:  68.33%, tr:  91.01%, tr_best:  91.11%\n",
      "epoch-29  lr=['0.0010000'], tr/val_loss:  0.621386/  1.749446, val:  64.17%, val_best:  68.33%, tr:  93.77%, tr_best:  93.77%\n",
      "epoch-30  lr=['0.0010000'], tr/val_loss:  0.624418/  1.789540, val:  65.83%, val_best:  68.33%, tr:  93.67%, tr_best:  93.77%\n",
      "epoch-31  lr=['0.0010000'], tr/val_loss:  0.636828/  1.767424, val:  65.00%, val_best:  68.33%, tr:  92.03%, tr_best:  93.77%\n",
      "epoch-32  lr=['0.0010000'], tr/val_loss:  0.626651/  1.795750, val:  65.83%, val_best:  68.33%, tr:  93.87%, tr_best:  93.87%\n",
      "epoch-33  lr=['0.0010000'], tr/val_loss:  0.638346/  1.848629, val:  63.33%, val_best:  68.33%, tr:  92.24%, tr_best:  93.87%\n",
      "epoch-34  lr=['0.0010000'], tr/val_loss:  0.597420/  1.957576, val:  63.33%, val_best:  68.33%, tr:  95.10%, tr_best:  95.10%\n",
      "epoch-35  lr=['0.0010000'], tr/val_loss:  0.611032/  1.996146, val:  63.33%, val_best:  68.33%, tr:  93.46%, tr_best:  95.10%\n",
      "epoch-36  lr=['0.0010000'], tr/val_loss:  0.591873/  1.939366, val:  65.83%, val_best:  68.33%, tr:  95.51%, tr_best:  95.51%\n",
      "epoch-37  lr=['0.0010000'], tr/val_loss:  0.591366/  1.982105, val:  65.00%, val_best:  68.33%, tr:  96.53%, tr_best:  96.53%\n",
      "epoch-38  lr=['0.0010000'], tr/val_loss:  0.582523/  2.001446, val:  68.33%, val_best:  68.33%, tr:  96.94%, tr_best:  96.94%\n",
      "epoch-39  lr=['0.0010000'], tr/val_loss:  0.564702/  2.022887, val:  67.50%, val_best:  68.33%, tr:  96.42%, tr_best:  96.94%\n",
      "epoch-40  lr=['0.0010000'], tr/val_loss:  0.565151/  2.120297, val:  67.92%, val_best:  68.33%, tr:  95.71%, tr_best:  96.94%\n",
      "epoch-41  lr=['0.0010000'], tr/val_loss:  0.557068/  2.140752, val:  65.83%, val_best:  68.33%, tr:  96.73%, tr_best:  96.94%\n",
      "epoch-42  lr=['0.0010000'], tr/val_loss:  0.525257/  2.118379, val:  66.25%, val_best:  68.33%, tr:  97.75%, tr_best:  97.75%\n",
      "epoch-43  lr=['0.0010000'], tr/val_loss:  0.539178/  2.197912, val:  63.75%, val_best:  68.33%, tr:  97.34%, tr_best:  97.75%\n",
      "epoch-44  lr=['0.0010000'], tr/val_loss:  0.522206/  2.220392, val:  66.25%, val_best:  68.33%, tr:  97.75%, tr_best:  97.75%\n",
      "epoch-45  lr=['0.0010000'], tr/val_loss:  0.512232/  2.242227, val:  66.67%, val_best:  68.33%, tr:  97.75%, tr_best:  97.75%\n",
      "epoch-46  lr=['0.0010000'], tr/val_loss:  0.501202/  2.228575, val:  67.08%, val_best:  68.33%, tr:  98.47%, tr_best:  98.47%\n",
      "epoch-47  lr=['0.0010000'], tr/val_loss:  0.494333/  2.312970, val:  65.42%, val_best:  68.33%, tr:  98.67%, tr_best:  98.67%\n",
      "epoch-48  lr=['0.0010000'], tr/val_loss:  0.494586/  2.318042, val:  66.25%, val_best:  68.33%, tr:  98.57%, tr_best:  98.67%\n",
      "epoch-49  lr=['0.0010000'], tr/val_loss:  0.508738/  2.396864, val:  64.58%, val_best:  68.33%, tr:  98.06%, tr_best:  98.67%\n",
      "epoch-50  lr=['0.0010000'], tr/val_loss:  0.490841/  2.432610, val:  65.00%, val_best:  68.33%, tr:  98.67%, tr_best:  98.67%\n",
      "epoch-51  lr=['0.0010000'], tr/val_loss:  0.501619/  2.443867, val:  65.42%, val_best:  68.33%, tr:  98.57%, tr_best:  98.67%\n",
      "epoch-52  lr=['0.0010000'], tr/val_loss:  0.482933/  2.479905, val:  68.33%, val_best:  68.33%, tr:  99.18%, tr_best:  99.18%\n",
      "epoch-53  lr=['0.0010000'], tr/val_loss:  0.477838/  2.538728, val:  66.67%, val_best:  68.33%, tr:  99.39%, tr_best:  99.39%\n",
      "epoch-54  lr=['0.0010000'], tr/val_loss:  0.479183/  2.583109, val:  65.83%, val_best:  68.33%, tr:  99.08%, tr_best:  99.39%\n",
      "epoch-55  lr=['0.0010000'], tr/val_loss:  0.468027/  2.644629, val:  66.67%, val_best:  68.33%, tr:  99.39%, tr_best:  99.39%\n",
      "epoch-56  lr=['0.0010000'], tr/val_loss:  0.473856/  2.653191, val:  65.42%, val_best:  68.33%, tr:  99.28%, tr_best:  99.39%\n",
      "epoch-57  lr=['0.0010000'], tr/val_loss:  0.480465/  2.618025, val:  68.33%, val_best:  68.33%, tr:  99.49%, tr_best:  99.49%\n",
      "epoch-58  lr=['0.0010000'], tr/val_loss:  0.452467/  2.733135, val:  62.50%, val_best:  68.33%, tr:  99.39%, tr_best:  99.49%\n",
      "epoch-59  lr=['0.0010000'], tr/val_loss:  0.458238/  2.680492, val:  67.92%, val_best:  68.33%, tr:  99.08%, tr_best:  99.49%\n",
      "epoch-60  lr=['0.0010000'], tr/val_loss:  0.466325/  2.711759, val:  67.08%, val_best:  68.33%, tr:  99.28%, tr_best:  99.49%\n",
      "epoch-61  lr=['0.0010000'], tr/val_loss:  0.461355/  2.762516, val:  67.50%, val_best:  68.33%, tr:  99.49%, tr_best:  99.49%\n",
      "epoch-62  lr=['0.0010000'], tr/val_loss:  0.448615/  2.830178, val:  65.00%, val_best:  68.33%, tr:  99.59%, tr_best:  99.59%\n",
      "epoch-63  lr=['0.0010000'], tr/val_loss:  0.442779/  2.875696, val:  66.25%, val_best:  68.33%, tr:  99.59%, tr_best:  99.59%\n",
      "epoch-64  lr=['0.0010000'], tr/val_loss:  0.452675/  2.929097, val:  65.42%, val_best:  68.33%, tr:  99.18%, tr_best:  99.59%\n",
      "epoch-65  lr=['0.0010000'], tr/val_loss:  0.441500/  2.885522, val:  65.83%, val_best:  68.33%, tr:  99.28%, tr_best:  99.59%\n",
      "epoch-66  lr=['0.0010000'], tr/val_loss:  0.448056/  2.954639, val:  64.58%, val_best:  68.33%, tr:  99.08%, tr_best:  99.59%\n",
      "epoch-67  lr=['0.0010000'], tr/val_loss:  0.472065/  2.912072, val:  68.33%, val_best:  68.33%, tr:  99.18%, tr_best:  99.59%\n",
      "epoch-68  lr=['0.0010000'], tr/val_loss:  0.455693/  3.063578, val:  63.75%, val_best:  68.33%, tr:  98.67%, tr_best:  99.59%\n",
      "epoch-69  lr=['0.0010000'], tr/val_loss:  0.457066/  3.023675, val:  68.75%, val_best:  68.75%, tr:  98.77%, tr_best:  99.59%\n",
      "epoch-70  lr=['0.0010000'], tr/val_loss:  0.445481/  3.087715, val:  65.00%, val_best:  68.75%, tr:  99.49%, tr_best:  99.59%\n",
      "epoch-71  lr=['0.0010000'], tr/val_loss:  0.458703/  3.106065, val:  62.92%, val_best:  68.75%, tr:  98.98%, tr_best:  99.59%\n",
      "epoch-72  lr=['0.0010000'], tr/val_loss:  0.456814/  3.125111, val:  65.00%, val_best:  68.75%, tr:  99.08%, tr_best:  99.59%\n",
      "epoch-73  lr=['0.0010000'], tr/val_loss:  0.452207/  3.070091, val:  67.08%, val_best:  68.75%, tr:  99.69%, tr_best:  99.69%\n",
      "epoch-74  lr=['0.0010000'], tr/val_loss:  0.436011/  3.146578, val:  64.58%, val_best:  68.75%, tr:  99.28%, tr_best:  99.69%\n",
      "epoch-75  lr=['0.0010000'], tr/val_loss:  0.432641/  3.278949, val:  65.00%, val_best:  68.75%, tr:  99.49%, tr_best:  99.69%\n",
      "epoch-76  lr=['0.0010000'], tr/val_loss:  0.430715/  3.224578, val:  64.58%, val_best:  68.75%, tr:  99.59%, tr_best:  99.69%\n",
      "epoch-77  lr=['0.0010000'], tr/val_loss:  0.435468/  3.271761, val:  65.83%, val_best:  68.75%, tr:  99.49%, tr_best:  99.69%\n",
      "epoch-78  lr=['0.0010000'], tr/val_loss:  0.444355/  3.210975, val:  66.67%, val_best:  68.75%, tr:  99.18%, tr_best:  99.69%\n",
      "epoch-79  lr=['0.0010000'], tr/val_loss:  0.419681/  3.283675, val:  67.08%, val_best:  68.75%, tr:  99.69%, tr_best:  99.69%\n",
      "epoch-80  lr=['0.0010000'], tr/val_loss:  0.430523/  3.323857, val:  65.00%, val_best:  68.75%, tr:  99.08%, tr_best:  99.69%\n",
      "epoch-81  lr=['0.0010000'], tr/val_loss:  0.411631/  3.358387, val:  67.50%, val_best:  68.75%, tr:  99.39%, tr_best:  99.69%\n",
      "epoch-82  lr=['0.0010000'], tr/val_loss:  0.424088/  3.491949, val:  64.58%, val_best:  68.75%, tr:  99.49%, tr_best:  99.69%\n",
      "epoch-83  lr=['0.0010000'], tr/val_loss:  0.428729/  3.484405, val:  64.17%, val_best:  68.75%, tr:  99.18%, tr_best:  99.69%\n",
      "epoch-84  lr=['0.0010000'], tr/val_loss:  0.420097/  3.429357, val:  66.25%, val_best:  68.75%, tr:  99.80%, tr_best:  99.80%\n",
      "epoch-85  lr=['0.0010000'], tr/val_loss:  0.406717/  3.461854, val:  65.42%, val_best:  68.75%, tr:  99.69%, tr_best:  99.80%\n",
      "epoch-86  lr=['0.0010000'], tr/val_loss:  0.403112/  3.600858, val:  66.67%, val_best:  68.75%, tr:  99.59%, tr_best:  99.80%\n",
      "epoch-87  lr=['0.0010000'], tr/val_loss:  0.411629/  3.637316, val:  63.75%, val_best:  68.75%, tr:  99.59%, tr_best:  99.80%\n",
      "epoch-88  lr=['0.0010000'], tr/val_loss:  0.412038/  3.625228, val:  66.25%, val_best:  68.75%, tr:  99.49%, tr_best:  99.80%\n",
      "epoch-89  lr=['0.0010000'], tr/val_loss:  0.406560/  3.561375, val:  65.42%, val_best:  68.75%, tr:  99.59%, tr_best:  99.80%\n",
      "epoch-90  lr=['0.0010000'], tr/val_loss:  0.414159/  3.600652, val:  65.83%, val_best:  68.75%, tr:  99.39%, tr_best:  99.80%\n",
      "epoch-91  lr=['0.0010000'], tr/val_loss:  0.415171/  3.754240, val:  63.75%, val_best:  68.75%, tr:  99.49%, tr_best:  99.80%\n",
      "epoch-92  lr=['0.0010000'], tr/val_loss:  0.403950/  3.739951, val:  64.58%, val_best:  68.75%, tr:  99.59%, tr_best:  99.80%\n",
      "epoch-93  lr=['0.0010000'], tr/val_loss:  0.415218/  3.729659, val:  65.42%, val_best:  68.75%, tr:  99.80%, tr_best:  99.80%\n",
      "epoch-94  lr=['0.0010000'], tr/val_loss:  0.422088/  3.777289, val:  64.17%, val_best:  68.75%, tr:  99.90%, tr_best:  99.90%\n",
      "epoch-95  lr=['0.0010000'], tr/val_loss:  0.404644/  3.859814, val:  66.25%, val_best:  68.75%, tr:  99.69%, tr_best:  99.90%\n",
      "epoch-96  lr=['0.0010000'], tr/val_loss:  0.400590/  3.955474, val:  63.75%, val_best:  68.75%, tr:  99.69%, tr_best:  99.90%\n",
      "epoch-97  lr=['0.0010000'], tr/val_loss:  0.398874/  3.932581, val:  64.58%, val_best:  68.75%, tr:  99.69%, tr_best:  99.90%\n",
      "epoch-98  lr=['0.0010000'], tr/val_loss:  0.372370/  3.934501, val:  65.00%, val_best:  68.75%, tr:  99.80%, tr_best:  99.90%\n",
      "epoch-99  lr=['0.0010000'], tr/val_loss:  0.389008/  4.001581, val:  63.75%, val_best:  68.75%, tr:  99.80%, tr_best:  99.90%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "86f9594f5a88451e9050df939c5e59b9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.006 MB of 0.006 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>iter_acc</td><td>▁▆▁▃▄▅▅▂▅███▇▅███▇██▇██████▇████████████</td></tr><tr><td>summary_val_acc</td><td>▁▄▆▆▅▆▆██▇▇█▇▇▇▇█▇▇▇▇█▇███▇█▇▇▇▇█▇▇▇▇▇▇▇</td></tr><tr><td>tr_acc</td><td>▁▄▅▅▆▆▆▇▇▇▇▇▇▇▇█████████████████████████</td></tr><tr><td>tr_epoch_loss</td><td>█▅▄▃▃▃▃▃▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_acc_best</td><td>▁▄▅▇▇▇▇█████████████████████████████████</td></tr><tr><td>val_acc_now</td><td>▁▄▆▆▅▆▆██▇▇█▇▇▇▇█▇▇▇▇█▇███▇█▇▇▇▇█▇▇▇▇▇▇▇</td></tr><tr><td>val_loss</td><td>▂▁▁▁▁▁▂▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▅▅▅▅▆▆▆▆▆▇▇▇▇▇██</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>99</td></tr><tr><td>iter_acc</td><td>1.0</td></tr><tr><td>tr_acc</td><td>0.99796</td></tr><tr><td>tr_epoch_loss</td><td>0.38901</td></tr><tr><td>val_acc_best</td><td>0.6875</td></tr><tr><td>val_acc_now</td><td>0.6375</td></tr><tr><td>val_loss</td><td>4.00158</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">generous-sweep-191</strong> at: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/plr1l26s' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/plr1l26s</a><br/> View project at: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>/data2/bh_wandb/wandb/run-20250430_051928-plr1l26s/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require(\"core\")`! See https://wandb.me/wandb-core for more information."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Sweep Agent: Waiting for job.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Job received.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: rgn2rset with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBATCH: 16\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBN_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBPTT_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tDFA_on: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tIMAGE_SIZE: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tOTTT_input_trace_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tTIME: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tUDA_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \talpha_uda: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbias: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcfg: ['M', 'M', 200, 200]\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tchaching_on: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tconvTrue_fcFalse: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdata_path: /data2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tddp_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdenoise_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdvs_clipping: 5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdvs_duration: 100000\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepoch_num: 100\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \texclude_class: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \textra_train_dataset: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlast_lif: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.001\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_sg_width: 4\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_decay: 0.5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_init: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_reset: 10000\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_threshold: 0.25\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmerge_polarities: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmy_seed: 42\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnet_print: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_workers: 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer_what: SGD\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tpin_memory: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tpre_trained: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tpre_trained_path: net_save/save_now_net_weights_{unique_name}.pth\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \trate_coding: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tscheduler_name: no\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsingle_step: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsurrogate: hard_sigmoid\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_conv_kernel_size: 3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_conv_padding: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_conv_stride: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_trace_const1: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_trace_const2: 0.5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \ttdBN_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \ttrace_on: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \twhich_data: DVS_GESTURE_TONIC\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.19.10 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.17.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/data2/bh_wandb/wandb/run-20250430_052611-rgn2rset</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/rgn2rset' target=\"_blank\">magic-sweep-194</a></strong> to <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/6pj3lh8j' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/6pj3lh8j</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/6pj3lh8j' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/6pj3lh8j</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/rgn2rset' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/rgn2rset</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'single_step' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'my_seed' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'TIME' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BATCH' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'IMAGE_SIZE' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'which_data' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'data_path' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'rate_coding' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_init' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_decay' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_threshold' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_reset' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_sg_width' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_conv_kernel_size' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_conv_stride' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_conv_padding' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_trace_const1' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_trace_const2' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'pre_trained' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'convTrue_fcFalse' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'cfg' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'net_print' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'pre_trained_path' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'learning_rate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'epoch_num' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'tdBN_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BN_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'surrogate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BPTT_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'optimizer_what' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'scheduler_name' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'ddp_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'dvs_clipping' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'dvs_duration' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'DFA_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'trace_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'OTTT_input_trace_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'exclude_class' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'merge_polarities' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'denoise_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'extra_train_dataset' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'num_workers' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'chaching_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'pin_memory' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'UDA_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'alpha_uda' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'bias' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'last_lif' was locked by 'sweep' (ignored update).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "param {'devices': '0', 'single_step': True, 'unique_name': 'main', 'my_seed': 42, 'TIME': 10, 'BATCH': 16, 'IMAGE_SIZE': 128, 'which_data': 'DVS_GESTURE_TONIC', 'data_path': '/data2', 'rate_coding': False, 'lif_layer_v_init': 0, 'lif_layer_v_decay': 0.5, 'lif_layer_v_threshold': 0.25, 'lif_layer_v_reset': 10000, 'lif_layer_sg_width': 4, 'synapse_conv_kernel_size': 3, 'synapse_conv_stride': 1, 'synapse_conv_padding': 1, 'synapse_trace_const1': 1, 'synapse_trace_const2': 0.5, 'pre_trained': False, 'convTrue_fcFalse': False, 'cfg': ['M', 'M', 200, 200], 'net_print': True, 'pre_trained_path': 'net_save/save_now_net_weights_{unique_name}.pth', 'learning_rate': 0.001, 'epoch_num': 100, 'tdBN_on': False, 'BN_on': False, 'surrogate': 'hard_sigmoid', 'BPTT_on': False, 'optimizer_what': 'SGD', 'scheduler_name': 'no', 'ddp_on': False, 'dvs_clipping': 5, 'dvs_duration': 100000, 'DFA_on': True, 'trace_on': True, 'OTTT_input_trace_on': False, 'exclude_class': True, 'merge_polarities': False, 'denoise_on': False, 'extra_train_dataset': 0, 'num_workers': 2, 'chaching_on': True, 'pin_memory': True, 'UDA_on': False, 'alpha_uda': 1, 'bias': True, 'last_lif': False, 'current epoch': 0} \n",
      "\n",
      "dataset_hash = ffa516e60c3efd5e0208f72b4c36cb84\n",
      "cache path exists\n",
      "\n",
      "device ==> cuda\n",
      "\n",
      "DataParallel(\n",
      "  (module): REBORN_MY_SNN_FC(\n",
      "    (layers): REBORN_MY_Sequential(\n",
      "      (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (2): DimChanger_for_FC()\n",
      "      (3): SYNAPSE_FC(in_features=2048, out_features=200, TIME=10, bias=True, sstep=True)\n",
      "      (4): LIF_layer(v_init=0, v_decay=0.5, v_threshold=0.25, v_reset=10000, sg_width=4, surrogate=hard_sigmoid, BPTT_on=False, trace_const1=1, trace_const2=0.5, TIME=10, sstep=True, trace_on=True)\n",
      "      (5): Feedback_Receiver()\n",
      "      (6): SYNAPSE_FC(in_features=200, out_features=200, TIME=10, bias=True, sstep=True)\n",
      "      (7): LIF_layer(v_init=0, v_decay=0.5, v_threshold=0.25, v_reset=10000, sg_width=4, surrogate=hard_sigmoid, BPTT_on=False, trace_const1=1, trace_const2=0.5, TIME=10, sstep=True, trace_on=True)\n",
      "      (8): Feedback_Receiver()\n",
      "      (9): SYNAPSE_FC(in_features=200, out_features=10, TIME=10, bias=True, sstep=True)\n",
      "      (DFA_top): Top_Gradient()\n",
      "    )\n",
      "  )\n",
      ")\n",
      "\n",
      "========================================================\n",
      "Trainable parameters: 452,010\n",
      "========================================================\n",
      "\n",
      "epoch-0   lr=['0.0010000'], tr/val_loss:  1.962614/  1.642167, val:  40.83%, val_best:  40.83%, tr:  25.94%, tr_best:  25.94%\n",
      "[module.layers.5] weight_fb parameter count: 2,000\n",
      "[module.layers.8] weight_fb parameter count: 2,000\n",
      "epoch-1   lr=['0.0010000'], tr/val_loss:  1.342926/  1.488586, val:  55.00%, val_best:  55.00%, tr:  54.34%, tr_best:  54.34%\n",
      "epoch-2   lr=['0.0010000'], tr/val_loss:  1.216579/  1.432874, val:  58.33%, val_best:  58.33%, tr:  61.08%, tr_best:  61.08%\n",
      "epoch-3   lr=['0.0010000'], tr/val_loss:  1.043826/  1.539286, val:  55.42%, val_best:  58.33%, tr:  67.31%, tr_best:  67.31%\n",
      "epoch-4   lr=['0.0010000'], tr/val_loss:  1.012517/  1.367443, val:  62.08%, val_best:  62.08%, tr:  67.72%, tr_best:  67.72%\n",
      "epoch-5   lr=['0.0010000'], tr/val_loss:  0.969981/  1.384725, val:  65.42%, val_best:  65.42%, tr:  71.40%, tr_best:  71.40%\n",
      "epoch-6   lr=['0.0010000'], tr/val_loss:  0.908254/  1.414234, val:  58.75%, val_best:  65.42%, tr:  73.54%, tr_best:  73.54%\n",
      "epoch-7   lr=['0.0010000'], tr/val_loss:  0.858366/  1.565493, val:  62.08%, val_best:  65.42%, tr:  76.81%, tr_best:  76.81%\n",
      "epoch-8   lr=['0.0010000'], tr/val_loss:  0.831658/  1.482582, val:  67.08%, val_best:  67.08%, tr:  76.30%, tr_best:  76.81%\n",
      "epoch-9   lr=['0.0010000'], tr/val_loss:  0.744022/  1.562559, val:  62.50%, val_best:  67.08%, tr:  85.39%, tr_best:  85.39%\n",
      "epoch-10  lr=['0.0010000'], tr/val_loss:  0.743354/  1.656556, val:  62.50%, val_best:  67.08%, tr:  86.82%, tr_best:  86.82%\n",
      "epoch-11  lr=['0.0010000'], tr/val_loss:  0.637644/  1.552947, val:  73.33%, val_best:  73.33%, tr:  90.40%, tr_best:  90.40%\n",
      "epoch-12  lr=['0.0010000'], tr/val_loss:  0.599880/  1.657126, val:  70.83%, val_best:  73.33%, tr:  94.08%, tr_best:  94.08%\n",
      "epoch-13  lr=['0.0010000'], tr/val_loss:  0.567113/  1.705080, val:  72.50%, val_best:  73.33%, tr:  93.87%, tr_best:  94.08%\n",
      "epoch-14  lr=['0.0010000'], tr/val_loss:  0.497240/  1.805810, val:  72.08%, val_best:  73.33%, tr:  95.30%, tr_best:  95.30%\n",
      "epoch-15  lr=['0.0010000'], tr/val_loss:  0.462377/  1.838268, val:  73.33%, val_best:  73.33%, tr:  97.65%, tr_best:  97.65%\n",
      "epoch-16  lr=['0.0010000'], tr/val_loss:  0.433103/  1.919030, val:  72.50%, val_best:  73.33%, tr:  97.75%, tr_best:  97.75%\n",
      "epoch-17  lr=['0.0010000'], tr/val_loss:  0.410736/  1.956096, val:  69.17%, val_best:  73.33%, tr:  98.47%, tr_best:  98.47%\n",
      "epoch-18  lr=['0.0010000'], tr/val_loss:  0.416760/  2.003270, val:  74.17%, val_best:  74.17%, tr:  97.75%, tr_best:  98.47%\n",
      "epoch-19  lr=['0.0010000'], tr/val_loss:  0.366627/  2.121347, val:  70.83%, val_best:  74.17%, tr:  98.77%, tr_best:  98.77%\n",
      "epoch-20  lr=['0.0010000'], tr/val_loss:  0.336827/  2.202686, val:  68.75%, val_best:  74.17%, tr:  99.08%, tr_best:  99.08%\n",
      "epoch-21  lr=['0.0010000'], tr/val_loss:  0.313072/  2.243307, val:  71.67%, val_best:  74.17%, tr:  99.28%, tr_best:  99.28%\n",
      "epoch-22  lr=['0.0010000'], tr/val_loss:  0.289788/  2.244341, val:  72.92%, val_best:  74.17%, tr:  99.90%, tr_best:  99.90%\n",
      "epoch-23  lr=['0.0010000'], tr/val_loss:  0.292511/  2.268433, val:  75.00%, val_best:  75.00%, tr:  99.08%, tr_best:  99.90%\n",
      "epoch-24  lr=['0.0010000'], tr/val_loss:  0.260112/  2.355186, val:  73.33%, val_best:  75.00%, tr:  99.49%, tr_best:  99.90%\n",
      "epoch-25  lr=['0.0010000'], tr/val_loss:  0.243905/  2.387046, val:  75.00%, val_best:  75.00%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-26  lr=['0.0010000'], tr/val_loss:  0.245541/  2.424107, val:  73.75%, val_best:  75.00%, tr:  99.59%, tr_best: 100.00%\n",
      "epoch-27  lr=['0.0010000'], tr/val_loss:  0.226032/  2.490451, val:  75.42%, val_best:  75.42%, tr:  99.69%, tr_best: 100.00%\n",
      "epoch-28  lr=['0.0010000'], tr/val_loss:  0.206129/  2.545635, val:  76.67%, val_best:  76.67%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-29  lr=['0.0010000'], tr/val_loss:  0.185431/  2.639602, val:  74.58%, val_best:  76.67%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-30  lr=['0.0010000'], tr/val_loss:  0.168218/  2.616242, val:  75.83%, val_best:  76.67%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-31  lr=['0.0010000'], tr/val_loss:  0.176404/  2.710536, val:  74.17%, val_best:  76.67%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-32  lr=['0.0010000'], tr/val_loss:  0.161809/  2.734105, val:  75.83%, val_best:  76.67%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-33  lr=['0.0010000'], tr/val_loss:  0.150051/  2.786067, val:  74.17%, val_best:  76.67%, tr:  99.80%, tr_best: 100.00%\n",
      "epoch-34  lr=['0.0010000'], tr/val_loss:  0.145217/  2.858659, val:  73.75%, val_best:  76.67%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-35  lr=['0.0010000'], tr/val_loss:  0.140729/  2.894262, val:  74.58%, val_best:  76.67%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-36  lr=['0.0010000'], tr/val_loss:  0.127941/  2.888525, val:  76.25%, val_best:  76.67%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-37  lr=['0.0010000'], tr/val_loss:  0.121223/  2.964072, val:  72.50%, val_best:  76.67%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-38  lr=['0.0010000'], tr/val_loss:  0.112494/  2.997260, val:  76.25%, val_best:  76.67%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-39  lr=['0.0010000'], tr/val_loss:  0.108429/  3.038450, val:  73.75%, val_best:  76.67%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-40  lr=['0.0010000'], tr/val_loss:  0.099578/  3.108197, val:  74.17%, val_best:  76.67%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-41  lr=['0.0010000'], tr/val_loss:  0.098977/  3.130912, val:  75.00%, val_best:  76.67%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-42  lr=['0.0010000'], tr/val_loss:  0.089539/  3.130435, val:  75.42%, val_best:  76.67%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-43  lr=['0.0010000'], tr/val_loss:  0.085274/  3.202323, val:  73.33%, val_best:  76.67%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-44  lr=['0.0010000'], tr/val_loss:  0.084809/  3.260016, val:  75.00%, val_best:  76.67%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-45  lr=['0.0010000'], tr/val_loss:  0.081939/  3.258081, val:  76.25%, val_best:  76.67%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-46  lr=['0.0010000'], tr/val_loss:  0.068226/  3.286006, val:  75.83%, val_best:  76.67%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-47  lr=['0.0010000'], tr/val_loss:  0.073598/  3.357875, val:  74.17%, val_best:  76.67%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-48  lr=['0.0010000'], tr/val_loss:  0.068117/  3.341837, val:  75.42%, val_best:  76.67%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-49  lr=['0.0010000'], tr/val_loss:  0.069768/  3.337809, val:  75.00%, val_best:  76.67%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-50  lr=['0.0010000'], tr/val_loss:  0.062260/  3.421775, val:  74.17%, val_best:  76.67%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-51  lr=['0.0010000'], tr/val_loss:  0.066240/  3.441897, val:  74.58%, val_best:  76.67%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-52  lr=['0.0010000'], tr/val_loss:  0.060377/  3.420574, val:  76.25%, val_best:  76.67%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-53  lr=['0.0010000'], tr/val_loss:  0.059038/  3.468502, val:  76.25%, val_best:  76.67%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-54  lr=['0.0010000'], tr/val_loss:  0.052216/  3.435520, val:  76.67%, val_best:  76.67%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-55  lr=['0.0010000'], tr/val_loss:  0.047282/  3.502662, val:  76.67%, val_best:  76.67%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-56  lr=['0.0010000'], tr/val_loss:  0.047850/  3.526477, val:  77.08%, val_best:  77.08%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-57  lr=['0.0010000'], tr/val_loss:  0.048218/  3.580616, val:  77.50%, val_best:  77.50%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-58  lr=['0.0010000'], tr/val_loss:  0.045138/  3.548485, val:  76.25%, val_best:  77.50%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-59  lr=['0.0010000'], tr/val_loss:  0.039832/  3.603865, val:  76.67%, val_best:  77.50%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-60  lr=['0.0010000'], tr/val_loss:  0.038687/  3.615597, val:  76.25%, val_best:  77.50%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-61  lr=['0.0010000'], tr/val_loss:  0.037846/  3.641562, val:  75.42%, val_best:  77.50%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-62  lr=['0.0010000'], tr/val_loss:  0.037871/  3.696943, val:  75.42%, val_best:  77.50%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-63  lr=['0.0010000'], tr/val_loss:  0.040430/  3.640948, val:  75.00%, val_best:  77.50%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-64  lr=['0.0010000'], tr/val_loss:  0.037768/  3.690131, val:  76.25%, val_best:  77.50%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-65  lr=['0.0010000'], tr/val_loss:  0.034937/  3.710269, val:  74.58%, val_best:  77.50%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-66  lr=['0.0010000'], tr/val_loss:  0.039974/  3.734374, val:  76.25%, val_best:  77.50%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-67  lr=['0.0010000'], tr/val_loss:  0.036382/  3.759443, val:  75.00%, val_best:  77.50%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-68  lr=['0.0010000'], tr/val_loss:  0.036759/  3.791939, val:  76.67%, val_best:  77.50%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-69  lr=['0.0010000'], tr/val_loss:  0.034145/  3.802752, val:  75.83%, val_best:  77.50%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-70  lr=['0.0010000'], tr/val_loss:  0.033403/  3.749593, val:  77.50%, val_best:  77.50%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-71  lr=['0.0010000'], tr/val_loss:  0.037656/  3.790287, val:  75.83%, val_best:  77.50%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-72  lr=['0.0010000'], tr/val_loss:  0.030665/  3.835779, val:  76.67%, val_best:  77.50%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-73  lr=['0.0010000'], tr/val_loss:  0.030683/  3.798043, val:  76.25%, val_best:  77.50%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-74  lr=['0.0010000'], tr/val_loss:  0.027959/  3.856090, val:  75.83%, val_best:  77.50%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-75  lr=['0.0010000'], tr/val_loss:  0.028424/  3.862133, val:  76.67%, val_best:  77.50%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-76  lr=['0.0010000'], tr/val_loss:  0.023419/  3.902559, val:  76.25%, val_best:  77.50%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-77  lr=['0.0010000'], tr/val_loss:  0.023323/  3.879580, val:  77.50%, val_best:  77.50%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-78  lr=['0.0010000'], tr/val_loss:  0.019774/  3.903840, val:  75.83%, val_best:  77.50%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-79  lr=['0.0010000'], tr/val_loss:  0.025346/  3.952504, val:  76.67%, val_best:  77.50%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-80  lr=['0.0010000'], tr/val_loss:  0.024023/  3.920918, val:  77.92%, val_best:  77.92%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-81  lr=['0.0010000'], tr/val_loss:  0.021462/  3.960685, val:  76.25%, val_best:  77.92%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-82  lr=['0.0010000'], tr/val_loss:  0.021218/  4.015070, val:  75.83%, val_best:  77.92%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-83  lr=['0.0010000'], tr/val_loss:  0.024416/  4.010184, val:  76.67%, val_best:  77.92%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-84  lr=['0.0010000'], tr/val_loss:  0.025374/  4.033717, val:  75.42%, val_best:  77.92%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-85  lr=['0.0010000'], tr/val_loss:  0.022054/  4.042339, val:  77.50%, val_best:  77.92%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-86  lr=['0.0010000'], tr/val_loss:  0.021995/  4.076827, val:  76.25%, val_best:  77.92%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-87  lr=['0.0010000'], tr/val_loss:  0.021550/  4.073510, val:  77.08%, val_best:  77.92%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-88  lr=['0.0010000'], tr/val_loss:  0.023486/  4.128570, val:  76.67%, val_best:  77.92%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-89  lr=['0.0010000'], tr/val_loss:  0.020566/  4.136041, val:  77.08%, val_best:  77.92%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-90  lr=['0.0010000'], tr/val_loss:  0.022121/  4.101490, val:  77.08%, val_best:  77.92%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-91  lr=['0.0010000'], tr/val_loss:  0.018727/  4.149881, val:  76.67%, val_best:  77.92%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-92  lr=['0.0010000'], tr/val_loss:  0.017806/  4.119419, val:  75.83%, val_best:  77.92%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-93  lr=['0.0010000'], tr/val_loss:  0.018637/  4.131205, val:  77.50%, val_best:  77.92%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-94  lr=['0.0010000'], tr/val_loss:  0.019320/  4.155246, val:  77.08%, val_best:  77.92%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-95  lr=['0.0010000'], tr/val_loss:  0.016726/  4.161989, val:  77.92%, val_best:  77.92%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-96  lr=['0.0010000'], tr/val_loss:  0.016293/  4.164411, val:  75.83%, val_best:  77.92%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-97  lr=['0.0010000'], tr/val_loss:  0.016141/  4.174523, val:  76.67%, val_best:  77.92%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-98  lr=['0.0010000'], tr/val_loss:  0.015867/  4.124198, val:  77.08%, val_best:  77.92%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-99  lr=['0.0010000'], tr/val_loss:  0.017377/  4.177671, val:  76.67%, val_best:  77.92%, tr: 100.00%, tr_best: 100.00%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "81c4040b921f4749a9abfeaa28ca1125",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.006 MB of 0.006 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>iter_acc</td><td>▁▅▅▃▆▆█▆▇███████████████████████████████</td></tr><tr><td>summary_val_acc</td><td>▁▄▅▅▅▇▇▆▇▇▇▇▇█▇▇▇█▇▇▇█████▇▇████████████</td></tr><tr><td>tr_acc</td><td>▁▄▅▆▇▇██████████████████████████████████</td></tr><tr><td>tr_epoch_loss</td><td>█▅▅▄▄▃▃▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_acc_best</td><td>▁▄▅▆▆▇▇▇▇▇▇▇████████████████████████████</td></tr><tr><td>val_acc_now</td><td>▁▄▅▅▅▇▇▆▇▇▇▇▇█▇▇▇█▇▇▇█████▇▇████████████</td></tr><tr><td>val_loss</td><td>▂▁▁▁▁▂▂▂▃▃▃▄▄▄▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇███████</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>99</td></tr><tr><td>iter_acc</td><td>1.0</td></tr><tr><td>tr_acc</td><td>1.0</td></tr><tr><td>tr_epoch_loss</td><td>0.01738</td></tr><tr><td>val_acc_best</td><td>0.77917</td></tr><tr><td>val_acc_now</td><td>0.76667</td></tr><tr><td>val_loss</td><td>4.17767</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">magic-sweep-194</strong> at: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/rgn2rset' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/rgn2rset</a><br/> View project at: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>/data2/bh_wandb/wandb/run-20250430_052611-rgn2rset/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require(\"core\")`! See https://wandb.me/wandb-core for more information."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: k1xl7ipb with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBATCH: 16\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBN_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBPTT_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tDFA_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tIMAGE_SIZE: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tOTTT_input_trace_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tTIME: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tUDA_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \talpha_uda: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbias: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcfg: ['M', 'M', 200, 200]\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tchaching_on: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tconvTrue_fcFalse: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdata_path: /data2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tddp_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdenoise_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdvs_clipping: 5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdvs_duration: 100000\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepoch_num: 100\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \texclude_class: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \textra_train_dataset: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlast_lif: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.001\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_sg_width: 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_decay: 0.5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_init: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_reset: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_threshold: 0.25\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmerge_polarities: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmy_seed: 42\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnet_print: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_workers: 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer_what: SGD\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tpin_memory: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tpre_trained: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tpre_trained_path: net_save/save_now_net_weights_{unique_name}.pth\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \trate_coding: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tscheduler_name: no\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsingle_step: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsurrogate: hard_sigmoid\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_conv_kernel_size: 3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_conv_padding: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_conv_stride: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_trace_const1: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_trace_const2: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \ttdBN_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \ttrace_on: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \twhich_data: DVS_GESTURE_TONIC\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.19.10 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.17.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/data2/bh_wandb/wandb/run-20250430_053255-k1xl7ipb</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/k1xl7ipb' target=\"_blank\">fancy-sweep-196</a></strong> to <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/6pj3lh8j' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/6pj3lh8j</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/6pj3lh8j' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/6pj3lh8j</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/k1xl7ipb' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/k1xl7ipb</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'single_step' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'my_seed' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'TIME' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BATCH' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'IMAGE_SIZE' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'which_data' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'data_path' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'rate_coding' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_init' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_decay' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_threshold' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_reset' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_sg_width' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_conv_kernel_size' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_conv_stride' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_conv_padding' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_trace_const1' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_trace_const2' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'pre_trained' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'convTrue_fcFalse' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'cfg' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'net_print' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'pre_trained_path' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'learning_rate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'epoch_num' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'tdBN_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BN_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'surrogate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BPTT_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'optimizer_what' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'scheduler_name' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'ddp_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'dvs_clipping' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'dvs_duration' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'DFA_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'trace_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'OTTT_input_trace_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'exclude_class' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'merge_polarities' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'denoise_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'extra_train_dataset' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'num_workers' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'chaching_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'pin_memory' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'UDA_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'alpha_uda' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'bias' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'last_lif' was locked by 'sweep' (ignored update).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "param {'devices': '0', 'single_step': True, 'unique_name': 'main', 'my_seed': 42, 'TIME': 10, 'BATCH': 16, 'IMAGE_SIZE': 128, 'which_data': 'DVS_GESTURE_TONIC', 'data_path': '/data2', 'rate_coding': False, 'lif_layer_v_init': 0, 'lif_layer_v_decay': 0.5, 'lif_layer_v_threshold': 0.25, 'lif_layer_v_reset': 0, 'lif_layer_sg_width': 2, 'synapse_conv_kernel_size': 3, 'synapse_conv_stride': 1, 'synapse_conv_padding': 1, 'synapse_trace_const1': 1, 'synapse_trace_const2': 0, 'pre_trained': False, 'convTrue_fcFalse': False, 'cfg': ['M', 'M', 200, 200], 'net_print': True, 'pre_trained_path': 'net_save/save_now_net_weights_{unique_name}.pth', 'learning_rate': 0.001, 'epoch_num': 100, 'tdBN_on': False, 'BN_on': False, 'surrogate': 'hard_sigmoid', 'BPTT_on': False, 'optimizer_what': 'SGD', 'scheduler_name': 'no', 'ddp_on': False, 'dvs_clipping': 5, 'dvs_duration': 100000, 'DFA_on': False, 'trace_on': True, 'OTTT_input_trace_on': False, 'exclude_class': True, 'merge_polarities': False, 'denoise_on': False, 'extra_train_dataset': 0, 'num_workers': 2, 'chaching_on': True, 'pin_memory': True, 'UDA_on': False, 'alpha_uda': 1, 'bias': True, 'last_lif': False, 'current epoch': 0} \n",
      "\n",
      "dataset_hash = ffa516e60c3efd5e0208f72b4c36cb84\n",
      "cache path exists\n",
      "\n",
      "device ==> cuda\n",
      "\n",
      "DataParallel(\n",
      "  (module): REBORN_MY_SNN_FC(\n",
      "    (layers): REBORN_MY_Sequential(\n",
      "      (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (2): DimChanger_for_FC()\n",
      "      (3): SYNAPSE_FC(in_features=2048, out_features=200, TIME=10, bias=True, sstep=True)\n",
      "      (4): LIF_layer(v_init=0, v_decay=0.5, v_threshold=0.25, v_reset=0, sg_width=2, surrogate=hard_sigmoid, BPTT_on=False, trace_const1=1, trace_const2=0, TIME=10, sstep=True, trace_on=True)\n",
      "      (5): SYNAPSE_FC(in_features=200, out_features=200, TIME=10, bias=True, sstep=True)\n",
      "      (6): LIF_layer(v_init=0, v_decay=0.5, v_threshold=0.25, v_reset=0, sg_width=2, surrogate=hard_sigmoid, BPTT_on=False, trace_const1=1, trace_const2=0, TIME=10, sstep=True, trace_on=True)\n",
      "      (7): SYNAPSE_FC(in_features=200, out_features=10, TIME=10, bias=True, sstep=True)\n",
      "    )\n",
      "  )\n",
      ")\n",
      "\n",
      "========================================================\n",
      "Trainable parameters: 452,010\n",
      "========================================================\n",
      "\n",
      "epoch-0   lr=['0.0010000'], tr/val_loss:  2.216654/  2.060891, val:  30.42%, val_best:  30.42%, tr:  20.43%, tr_best:  20.43%\n",
      "epoch-1   lr=['0.0010000'], tr/val_loss:  1.779135/  1.644150, val:  50.83%, val_best:  50.83%, tr:  46.17%, tr_best:  46.17%\n",
      "epoch-2   lr=['0.0010000'], tr/val_loss:  1.445981/  1.477175, val:  52.92%, val_best:  52.92%, tr:  56.08%, tr_best:  56.08%\n",
      "epoch-3   lr=['0.0010000'], tr/val_loss:  1.287499/  1.413946, val:  56.25%, val_best:  56.25%, tr:  63.43%, tr_best:  63.43%\n",
      "epoch-4   lr=['0.0010000'], tr/val_loss:  1.205913/  1.359470, val:  58.75%, val_best:  58.75%, tr:  62.21%, tr_best:  63.43%\n",
      "epoch-5   lr=['0.0010000'], tr/val_loss:  1.130453/  1.298448, val:  64.17%, val_best:  64.17%, tr:  63.43%, tr_best:  63.43%\n",
      "epoch-6   lr=['0.0010000'], tr/val_loss:  1.064726/  1.270564, val:  63.33%, val_best:  64.17%, tr:  66.91%, tr_best:  66.91%\n",
      "epoch-7   lr=['0.0010000'], tr/val_loss:  1.017963/  1.258458, val:  62.50%, val_best:  64.17%, tr:  68.74%, tr_best:  68.74%\n",
      "epoch-8   lr=['0.0010000'], tr/val_loss:  0.966367/  1.236025, val:  66.67%, val_best:  66.67%, tr:  70.79%, tr_best:  70.79%\n",
      "epoch-9   lr=['0.0010000'], tr/val_loss:  0.936174/  1.214990, val:  62.50%, val_best:  66.67%, tr:  72.73%, tr_best:  72.73%\n",
      "epoch-10  lr=['0.0010000'], tr/val_loss:  0.912327/  1.220777, val:  63.75%, val_best:  66.67%, tr:  72.83%, tr_best:  72.83%\n",
      "epoch-11  lr=['0.0010000'], tr/val_loss:  0.873218/  1.191651, val:  62.92%, val_best:  66.67%, tr:  74.87%, tr_best:  74.87%\n",
      "epoch-12  lr=['0.0010000'], tr/val_loss:  0.857983/  1.178742, val:  65.00%, val_best:  66.67%, tr:  77.32%, tr_best:  77.32%\n",
      "epoch-13  lr=['0.0010000'], tr/val_loss:  0.829596/  1.182205, val:  64.58%, val_best:  66.67%, tr:  79.47%, tr_best:  79.47%\n",
      "epoch-14  lr=['0.0010000'], tr/val_loss:  0.786867/  1.215481, val:  62.08%, val_best:  66.67%, tr:  78.65%, tr_best:  79.47%\n",
      "epoch-15  lr=['0.0010000'], tr/val_loss:  0.767232/  1.186797, val:  70.83%, val_best:  70.83%, tr:  81.10%, tr_best:  81.10%\n",
      "epoch-16  lr=['0.0010000'], tr/val_loss:  0.766614/  1.150965, val:  71.67%, val_best:  71.67%, tr:  79.16%, tr_best:  81.10%\n",
      "epoch-17  lr=['0.0010000'], tr/val_loss:  0.721505/  1.140240, val:  74.58%, val_best:  74.58%, tr:  84.58%, tr_best:  84.58%\n",
      "epoch-18  lr=['0.0010000'], tr/val_loss:  0.688408/  1.222054, val:  66.25%, val_best:  74.58%, tr:  85.29%, tr_best:  85.29%\n",
      "epoch-19  lr=['0.0010000'], tr/val_loss:  0.681219/  1.235685, val:  66.25%, val_best:  74.58%, tr:  81.72%, tr_best:  85.29%\n",
      "epoch-20  lr=['0.0010000'], tr/val_loss:  0.644468/  1.200313, val:  70.83%, val_best:  74.58%, tr:  86.62%, tr_best:  86.62%\n",
      "epoch-21  lr=['0.0010000'], tr/val_loss:  0.628864/  1.192714, val:  70.42%, val_best:  74.58%, tr:  88.05%, tr_best:  88.05%\n",
      "epoch-22  lr=['0.0010000'], tr/val_loss:  0.636801/  1.196259, val:  73.75%, val_best:  74.58%, tr:  84.88%, tr_best:  88.05%\n",
      "epoch-23  lr=['0.0010000'], tr/val_loss:  0.600424/  1.206346, val:  70.42%, val_best:  74.58%, tr:  88.15%, tr_best:  88.15%\n",
      "epoch-24  lr=['0.0010000'], tr/val_loss:  0.570699/  1.233746, val:  70.83%, val_best:  74.58%, tr:  89.99%, tr_best:  89.99%\n",
      "epoch-25  lr=['0.0010000'], tr/val_loss:  0.546721/  1.242764, val:  71.67%, val_best:  74.58%, tr:  89.79%, tr_best:  89.99%\n",
      "epoch-26  lr=['0.0010000'], tr/val_loss:  0.536629/  1.229247, val:  70.42%, val_best:  74.58%, tr:  89.48%, tr_best:  89.99%\n",
      "epoch-27  lr=['0.0010000'], tr/val_loss:  0.505557/  1.294031, val:  68.75%, val_best:  74.58%, tr:  92.44%, tr_best:  92.44%\n",
      "epoch-28  lr=['0.0010000'], tr/val_loss:  0.500957/  1.275712, val:  70.42%, val_best:  74.58%, tr:  92.24%, tr_best:  92.44%\n",
      "epoch-29  lr=['0.0010000'], tr/val_loss:  0.476629/  1.322448, val:  65.42%, val_best:  74.58%, tr:  94.79%, tr_best:  94.79%\n",
      "epoch-30  lr=['0.0010000'], tr/val_loss:  0.460718/  1.334281, val:  68.75%, val_best:  74.58%, tr:  95.71%, tr_best:  95.71%\n",
      "epoch-31  lr=['0.0010000'], tr/val_loss:  0.460128/  1.351234, val:  68.75%, val_best:  74.58%, tr:  93.36%, tr_best:  95.71%\n",
      "epoch-32  lr=['0.0010000'], tr/val_loss:  0.440186/  1.351176, val:  69.58%, val_best:  74.58%, tr:  95.81%, tr_best:  95.81%\n",
      "epoch-33  lr=['0.0010000'], tr/val_loss:  0.431837/  1.374167, val:  68.33%, val_best:  74.58%, tr:  95.61%, tr_best:  95.81%\n",
      "epoch-34  lr=['0.0010000'], tr/val_loss:  0.403662/  1.436649, val:  67.50%, val_best:  74.58%, tr:  97.14%, tr_best:  97.14%\n",
      "epoch-35  lr=['0.0010000'], tr/val_loss:  0.417744/  1.467212, val:  65.00%, val_best:  74.58%, tr:  93.77%, tr_best:  97.14%\n",
      "epoch-36  lr=['0.0010000'], tr/val_loss:  0.380750/  1.397826, val:  70.42%, val_best:  74.58%, tr:  96.94%, tr_best:  97.14%\n",
      "epoch-37  lr=['0.0010000'], tr/val_loss:  0.364786/  1.444445, val:  67.08%, val_best:  74.58%, tr:  97.75%, tr_best:  97.75%\n",
      "epoch-38  lr=['0.0010000'], tr/val_loss:  0.355898/  1.473857, val:  68.75%, val_best:  74.58%, tr:  98.37%, tr_best:  98.37%\n",
      "epoch-39  lr=['0.0010000'], tr/val_loss:  0.347167/  1.512747, val:  68.33%, val_best:  74.58%, tr:  98.67%, tr_best:  98.67%\n",
      "epoch-40  lr=['0.0010000'], tr/val_loss:  0.340730/  1.505259, val:  69.17%, val_best:  74.58%, tr:  98.16%, tr_best:  98.67%\n",
      "epoch-41  lr=['0.0010000'], tr/val_loss:  0.319258/  1.516787, val:  70.42%, val_best:  74.58%, tr:  98.57%, tr_best:  98.67%\n",
      "epoch-42  lr=['0.0010000'], tr/val_loss:  0.302603/  1.500744, val:  71.67%, val_best:  74.58%, tr:  99.39%, tr_best:  99.39%\n",
      "epoch-43  lr=['0.0010000'], tr/val_loss:  0.305634/  1.562080, val:  69.17%, val_best:  74.58%, tr:  98.47%, tr_best:  99.39%\n",
      "epoch-44  lr=['0.0010000'], tr/val_loss:  0.289520/  1.567587, val:  69.17%, val_best:  74.58%, tr:  99.08%, tr_best:  99.39%\n",
      "epoch-45  lr=['0.0010000'], tr/val_loss:  0.279334/  1.583711, val:  70.00%, val_best:  74.58%, tr:  99.59%, tr_best:  99.59%\n",
      "epoch-46  lr=['0.0010000'], tr/val_loss:  0.265231/  1.586333, val:  69.58%, val_best:  74.58%, tr:  99.28%, tr_best:  99.59%\n",
      "epoch-47  lr=['0.0010000'], tr/val_loss:  0.247543/  1.603848, val:  69.58%, val_best:  74.58%, tr:  99.59%, tr_best:  99.59%\n",
      "epoch-48  lr=['0.0010000'], tr/val_loss:  0.253618/  1.617032, val:  72.08%, val_best:  74.58%, tr:  99.59%, tr_best:  99.59%\n",
      "epoch-49  lr=['0.0010000'], tr/val_loss:  0.239540/  1.656589, val:  72.08%, val_best:  74.58%, tr:  99.90%, tr_best:  99.90%\n",
      "epoch-50  lr=['0.0010000'], tr/val_loss:  0.232402/  1.675607, val:  69.58%, val_best:  74.58%, tr:  99.69%, tr_best:  99.90%\n",
      "epoch-51  lr=['0.0010000'], tr/val_loss:  0.230221/  1.647068, val:  72.92%, val_best:  74.58%, tr:  99.49%, tr_best:  99.90%\n",
      "epoch-52  lr=['0.0010000'], tr/val_loss:  0.210645/  1.693825, val:  68.75%, val_best:  74.58%, tr:  99.90%, tr_best:  99.90%\n",
      "epoch-53  lr=['0.0010000'], tr/val_loss:  0.210658/  1.709860, val:  70.83%, val_best:  74.58%, tr:  99.90%, tr_best:  99.90%\n",
      "epoch-54  lr=['0.0010000'], tr/val_loss:  0.203777/  1.719201, val:  68.75%, val_best:  74.58%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-55  lr=['0.0010000'], tr/val_loss:  0.190932/  1.741002, val:  70.83%, val_best:  74.58%, tr:  99.90%, tr_best: 100.00%\n",
      "epoch-56  lr=['0.0010000'], tr/val_loss:  0.184333/  1.735294, val:  71.25%, val_best:  74.58%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-57  lr=['0.0010000'], tr/val_loss:  0.184165/  1.777531, val:  71.25%, val_best:  74.58%, tr:  99.90%, tr_best: 100.00%\n",
      "epoch-58  lr=['0.0010000'], tr/val_loss:  0.176561/  1.808160, val:  71.25%, val_best:  74.58%, tr:  99.90%, tr_best: 100.00%\n",
      "epoch-59  lr=['0.0010000'], tr/val_loss:  0.173541/  1.816286, val:  72.50%, val_best:  74.58%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-60  lr=['0.0010000'], tr/val_loss:  0.164435/  1.802094, val:  72.08%, val_best:  74.58%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-61  lr=['0.0010000'], tr/val_loss:  0.157302/  1.852210, val:  70.00%, val_best:  74.58%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-62  lr=['0.0010000'], tr/val_loss:  0.159053/  1.855553, val:  72.50%, val_best:  74.58%, tr:  99.80%, tr_best: 100.00%\n",
      "epoch-63  lr=['0.0010000'], tr/val_loss:  0.148576/  1.863846, val:  69.17%, val_best:  74.58%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-64  lr=['0.0010000'], tr/val_loss:  0.155788/  1.908864, val:  69.58%, val_best:  74.58%, tr:  99.90%, tr_best: 100.00%\n",
      "epoch-65  lr=['0.0010000'], tr/val_loss:  0.142266/  1.904292, val:  70.00%, val_best:  74.58%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-66  lr=['0.0010000'], tr/val_loss:  0.138989/  1.943282, val:  69.58%, val_best:  74.58%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-67  lr=['0.0010000'], tr/val_loss:  0.138472/  1.928047, val:  70.00%, val_best:  74.58%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-68  lr=['0.0010000'], tr/val_loss:  0.134681/  1.945577, val:  70.42%, val_best:  74.58%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-69  lr=['0.0010000'], tr/val_loss:  0.126527/  1.953957, val:  69.17%, val_best:  74.58%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-70  lr=['0.0010000'], tr/val_loss:  0.118830/  1.978659, val:  68.75%, val_best:  74.58%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-71  lr=['0.0010000'], tr/val_loss:  0.128453/  2.017430, val:  68.75%, val_best:  74.58%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-72  lr=['0.0010000'], tr/val_loss:  0.112932/  2.022899, val:  68.75%, val_best:  74.58%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-73  lr=['0.0010000'], tr/val_loss:  0.110891/  2.024907, val:  69.58%, val_best:  74.58%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-74  lr=['0.0010000'], tr/val_loss:  0.108607/  2.062394, val:  69.17%, val_best:  74.58%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-75  lr=['0.0010000'], tr/val_loss:  0.106986/  2.080556, val:  70.00%, val_best:  74.58%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-76  lr=['0.0010000'], tr/val_loss:  0.108803/  2.107413, val:  68.75%, val_best:  74.58%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-77  lr=['0.0010000'], tr/val_loss:  0.098692/  2.092711, val:  70.83%, val_best:  74.58%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-78  lr=['0.0010000'], tr/val_loss:  0.107389/  2.137888, val:  70.00%, val_best:  74.58%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-79  lr=['0.0010000'], tr/val_loss:  0.101752/  2.148481, val:  71.25%, val_best:  74.58%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-80  lr=['0.0010000'], tr/val_loss:  0.092729/  2.140817, val:  68.75%, val_best:  74.58%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-81  lr=['0.0010000'], tr/val_loss:  0.090823/  2.146414, val:  70.83%, val_best:  74.58%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-82  lr=['0.0010000'], tr/val_loss:  0.089198/  2.193096, val:  70.00%, val_best:  74.58%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-83  lr=['0.0010000'], tr/val_loss:  0.086116/  2.256483, val:  68.75%, val_best:  74.58%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-84  lr=['0.0010000'], tr/val_loss:  0.085152/  2.217839, val:  70.00%, val_best:  74.58%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-85  lr=['0.0010000'], tr/val_loss:  0.085134/  2.223672, val:  69.58%, val_best:  74.58%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-86  lr=['0.0010000'], tr/val_loss:  0.076806/  2.241819, val:  69.17%, val_best:  74.58%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-87  lr=['0.0010000'], tr/val_loss:  0.080065/  2.275090, val:  69.58%, val_best:  74.58%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-88  lr=['0.0010000'], tr/val_loss:  0.076464/  2.277931, val:  70.83%, val_best:  74.58%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-89  lr=['0.0010000'], tr/val_loss:  0.072978/  2.292897, val:  70.00%, val_best:  74.58%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-90  lr=['0.0010000'], tr/val_loss:  0.077493/  2.267241, val:  70.00%, val_best:  74.58%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-91  lr=['0.0010000'], tr/val_loss:  0.069553/  2.309449, val:  70.42%, val_best:  74.58%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-92  lr=['0.0010000'], tr/val_loss:  0.072986/  2.305090, val:  68.75%, val_best:  74.58%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-93  lr=['0.0010000'], tr/val_loss:  0.065255/  2.300679, val:  70.42%, val_best:  74.58%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-94  lr=['0.0010000'], tr/val_loss:  0.063573/  2.345931, val:  70.00%, val_best:  74.58%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-95  lr=['0.0010000'], tr/val_loss:  0.068055/  2.353020, val:  69.17%, val_best:  74.58%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-96  lr=['0.0010000'], tr/val_loss:  0.060933/  2.357913, val:  71.25%, val_best:  74.58%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-97  lr=['0.0010000'], tr/val_loss:  0.071308/  2.365698, val:  70.42%, val_best:  74.58%, tr:  99.80%, tr_best: 100.00%\n",
      "epoch-98  lr=['0.0010000'], tr/val_loss:  0.060142/  2.369514, val:  69.58%, val_best:  74.58%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-99  lr=['0.0010000'], tr/val_loss:  0.059939/  2.368631, val:  70.42%, val_best:  74.58%, tr: 100.00%, tr_best: 100.00%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "41bc6a3e1d1a47488f44559b2b375f8e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.006 MB of 0.006 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>iter_acc</td><td>▂▅▃▅▁▅▅▁▅▇▆█▇▇▇█████████████████████████</td></tr><tr><td>summary_val_acc</td><td>▁▅▅▆▆▆▆█▇▇▇▇▇▇▆▇▇█▇▇█▇▇▇█▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇</td></tr><tr><td>tr_acc</td><td>▁▄▅▅▆▆▆▇▆▇▇▇██▇█████████████████████████</td></tr><tr><td>tr_epoch_loss</td><td>█▅▅▄▄▄▃▃▃▃▃▃▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_acc_best</td><td>▁▅▅▆▇▇▇█████████████████████████████████</td></tr><tr><td>val_acc_now</td><td>▁▅▅▆▆▆▆█▇▇▇▇▇▇▆▇▇█▇▇█▇▇▇█▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇</td></tr><tr><td>val_loss</td><td>▆▃▂▂▁▁▁▁▂▁▂▂▂▂▃▃▃▃▃▄▄▄▄▅▅▅▅▆▆▆▆▆▇▇▇▇████</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>99</td></tr><tr><td>iter_acc</td><td>1.0</td></tr><tr><td>tr_acc</td><td>1.0</td></tr><tr><td>tr_epoch_loss</td><td>0.05994</td></tr><tr><td>val_acc_best</td><td>0.74583</td></tr><tr><td>val_acc_now</td><td>0.70417</td></tr><tr><td>val_loss</td><td>2.36863</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">fancy-sweep-196</strong> at: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/k1xl7ipb' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/k1xl7ipb</a><br/> View project at: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>/data2/bh_wandb/wandb/run-20250430_053255-k1xl7ipb/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require(\"core\")`! See https://wandb.me/wandb-core for more information."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Sweep Agent: Waiting for job.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Job received.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: f22fqv66 with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBATCH: 16\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBN_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBPTT_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tDFA_on: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tIMAGE_SIZE: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tOTTT_input_trace_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tTIME: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tUDA_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \talpha_uda: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbias: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcfg: ['M', 'M', 200, 200]\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tchaching_on: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tconvTrue_fcFalse: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdata_path: /data2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tddp_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdenoise_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdvs_clipping: 5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdvs_duration: 100000\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepoch_num: 100\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \texclude_class: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \textra_train_dataset: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlast_lif: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.001\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_sg_width: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_decay: 0.5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_init: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_reset: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_threshold: 0.25\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmerge_polarities: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmy_seed: 42\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnet_print: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_workers: 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer_what: SGD\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tpin_memory: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tpre_trained: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tpre_trained_path: net_save/save_now_net_weights_{unique_name}.pth\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \trate_coding: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tscheduler_name: no\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsingle_step: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsurrogate: hard_sigmoid\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_conv_kernel_size: 3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_conv_padding: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_conv_stride: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_trace_const1: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_trace_const2: 0.5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \ttdBN_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \ttrace_on: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \twhich_data: DVS_GESTURE_TONIC\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.19.10 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.17.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/data2/bh_wandb/wandb/run-20250430_053857-f22fqv66</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/f22fqv66' target=\"_blank\">exalted-sweep-197</a></strong> to <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/6pj3lh8j' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/6pj3lh8j</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/6pj3lh8j' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/6pj3lh8j</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/f22fqv66' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/f22fqv66</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'single_step' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'my_seed' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'TIME' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BATCH' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'IMAGE_SIZE' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'which_data' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'data_path' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'rate_coding' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_init' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_decay' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_threshold' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_reset' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_sg_width' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_conv_kernel_size' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_conv_stride' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_conv_padding' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_trace_const1' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_trace_const2' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'pre_trained' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'convTrue_fcFalse' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'cfg' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'net_print' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'pre_trained_path' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'learning_rate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'epoch_num' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'tdBN_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BN_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'surrogate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BPTT_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'optimizer_what' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'scheduler_name' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'ddp_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'dvs_clipping' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'dvs_duration' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'DFA_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'trace_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'OTTT_input_trace_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'exclude_class' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'merge_polarities' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'denoise_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'extra_train_dataset' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'num_workers' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'chaching_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'pin_memory' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'UDA_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'alpha_uda' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'bias' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'last_lif' was locked by 'sweep' (ignored update).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "param {'devices': '0', 'single_step': True, 'unique_name': 'main', 'my_seed': 42, 'TIME': 10, 'BATCH': 16, 'IMAGE_SIZE': 128, 'which_data': 'DVS_GESTURE_TONIC', 'data_path': '/data2', 'rate_coding': False, 'lif_layer_v_init': 0, 'lif_layer_v_decay': 0.5, 'lif_layer_v_threshold': 0.25, 'lif_layer_v_reset': 0, 'lif_layer_sg_width': 1, 'synapse_conv_kernel_size': 3, 'synapse_conv_stride': 1, 'synapse_conv_padding': 1, 'synapse_trace_const1': 1, 'synapse_trace_const2': 0.5, 'pre_trained': False, 'convTrue_fcFalse': False, 'cfg': ['M', 'M', 200, 200], 'net_print': True, 'pre_trained_path': 'net_save/save_now_net_weights_{unique_name}.pth', 'learning_rate': 0.001, 'epoch_num': 100, 'tdBN_on': False, 'BN_on': False, 'surrogate': 'hard_sigmoid', 'BPTT_on': False, 'optimizer_what': 'SGD', 'scheduler_name': 'no', 'ddp_on': False, 'dvs_clipping': 5, 'dvs_duration': 100000, 'DFA_on': True, 'trace_on': True, 'OTTT_input_trace_on': False, 'exclude_class': True, 'merge_polarities': False, 'denoise_on': False, 'extra_train_dataset': 0, 'num_workers': 2, 'chaching_on': True, 'pin_memory': True, 'UDA_on': False, 'alpha_uda': 1, 'bias': True, 'last_lif': False, 'current epoch': 0} \n",
      "\n",
      "dataset_hash = ffa516e60c3efd5e0208f72b4c36cb84\n",
      "cache path exists\n",
      "\n",
      "device ==> cuda\n",
      "\n",
      "DataParallel(\n",
      "  (module): REBORN_MY_SNN_FC(\n",
      "    (layers): REBORN_MY_Sequential(\n",
      "      (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (2): DimChanger_for_FC()\n",
      "      (3): SYNAPSE_FC(in_features=2048, out_features=200, TIME=10, bias=True, sstep=True)\n",
      "      (4): LIF_layer(v_init=0, v_decay=0.5, v_threshold=0.25, v_reset=0, sg_width=1, surrogate=hard_sigmoid, BPTT_on=False, trace_const1=1, trace_const2=0.5, TIME=10, sstep=True, trace_on=True)\n",
      "      (5): Feedback_Receiver()\n",
      "      (6): SYNAPSE_FC(in_features=200, out_features=200, TIME=10, bias=True, sstep=True)\n",
      "      (7): LIF_layer(v_init=0, v_decay=0.5, v_threshold=0.25, v_reset=0, sg_width=1, surrogate=hard_sigmoid, BPTT_on=False, trace_const1=1, trace_const2=0.5, TIME=10, sstep=True, trace_on=True)\n",
      "      (8): Feedback_Receiver()\n",
      "      (9): SYNAPSE_FC(in_features=200, out_features=10, TIME=10, bias=True, sstep=True)\n",
      "      (DFA_top): Top_Gradient()\n",
      "    )\n",
      "  )\n",
      ")\n",
      "\n",
      "========================================================\n",
      "Trainable parameters: 452,010\n",
      "========================================================\n",
      "\n",
      "epoch-0   lr=['0.0010000'], tr/val_loss:  2.144575/  1.817533, val:  41.25%, val_best:  41.25%, tr:  21.25%, tr_best:  21.25%\n",
      "[module.layers.5] weight_fb parameter count: 2,000\n",
      "[module.layers.8] weight_fb parameter count: 2,000\n",
      "epoch-1   lr=['0.0010000'], tr/val_loss:  1.491291/  1.456961, val:  53.75%, val_best:  53.75%, tr:  52.30%, tr_best:  52.30%\n",
      "epoch-2   lr=['0.0010000'], tr/val_loss:  1.279740/  1.418671, val:  53.75%, val_best:  53.75%, tr:  58.02%, tr_best:  58.02%\n",
      "epoch-3   lr=['0.0010000'], tr/val_loss:  1.175622/  1.402506, val:  55.83%, val_best:  55.83%, tr:  63.23%, tr_best:  63.23%\n",
      "epoch-4   lr=['0.0010000'], tr/val_loss:  1.119980/  1.366083, val:  58.75%, val_best:  58.75%, tr:  63.64%, tr_best:  63.64%\n",
      "epoch-5   lr=['0.0010000'], tr/val_loss:  1.060521/  1.300567, val:  65.83%, val_best:  65.83%, tr:  65.37%, tr_best:  65.37%\n",
      "epoch-6   lr=['0.0010000'], tr/val_loss:  1.000824/  1.301821, val:  61.25%, val_best:  65.83%, tr:  70.68%, tr_best:  70.68%\n",
      "epoch-7   lr=['0.0010000'], tr/val_loss:  0.985290/  1.314859, val:  61.25%, val_best:  65.83%, tr:  69.05%, tr_best:  70.68%\n",
      "epoch-8   lr=['0.0010000'], tr/val_loss:  0.949520/  1.354883, val:  64.58%, val_best:  65.83%, tr:  71.20%, tr_best:  71.20%\n",
      "epoch-9   lr=['0.0010000'], tr/val_loss:  0.934873/  1.356147, val:  57.92%, val_best:  65.83%, tr:  73.44%, tr_best:  73.44%\n",
      "epoch-10  lr=['0.0010000'], tr/val_loss:  0.923953/  1.396143, val:  56.67%, val_best:  65.83%, tr:  73.44%, tr_best:  73.44%\n",
      "epoch-11  lr=['0.0010000'], tr/val_loss:  0.875370/  1.339741, val:  62.50%, val_best:  65.83%, tr:  76.71%, tr_best:  76.71%\n",
      "epoch-12  lr=['0.0010000'], tr/val_loss:  0.883515/  1.354796, val:  62.50%, val_best:  65.83%, tr:  77.02%, tr_best:  77.02%\n",
      "epoch-13  lr=['0.0010000'], tr/val_loss:  0.864338/  1.359563, val:  63.75%, val_best:  65.83%, tr:  77.22%, tr_best:  77.22%\n",
      "epoch-14  lr=['0.0010000'], tr/val_loss:  0.817443/  1.511845, val:  62.50%, val_best:  65.83%, tr:  79.37%, tr_best:  79.37%\n",
      "epoch-15  lr=['0.0010000'], tr/val_loss:  0.809220/  1.439581, val:  61.67%, val_best:  65.83%, tr:  81.72%, tr_best:  81.72%\n",
      "epoch-16  lr=['0.0010000'], tr/val_loss:  0.819770/  1.386554, val:  64.17%, val_best:  65.83%, tr:  81.10%, tr_best:  81.72%\n",
      "epoch-17  lr=['0.0010000'], tr/val_loss:  0.783346/  1.407303, val:  67.08%, val_best:  67.08%, tr:  84.68%, tr_best:  84.68%\n",
      "epoch-18  lr=['0.0010000'], tr/val_loss:  0.762966/  1.542733, val:  59.17%, val_best:  67.08%, tr:  84.07%, tr_best:  84.68%\n",
      "epoch-19  lr=['0.0010000'], tr/val_loss:  0.764121/  1.509853, val:  67.08%, val_best:  67.08%, tr:  83.96%, tr_best:  84.68%\n",
      "epoch-20  lr=['0.0010000'], tr/val_loss:  0.738797/  1.569989, val:  62.92%, val_best:  67.08%, tr:  86.62%, tr_best:  86.62%\n",
      "epoch-21  lr=['0.0010000'], tr/val_loss:  0.716952/  1.523091, val:  64.17%, val_best:  67.08%, tr:  86.72%, tr_best:  86.72%\n",
      "epoch-22  lr=['0.0010000'], tr/val_loss:  0.725320/  1.552056, val:  63.33%, val_best:  67.08%, tr:  85.90%, tr_best:  86.72%\n",
      "epoch-23  lr=['0.0010000'], tr/val_loss:  0.698502/  1.585925, val:  65.00%, val_best:  67.08%, tr:  89.38%, tr_best:  89.38%\n",
      "epoch-24  lr=['0.0010000'], tr/val_loss:  0.677743/  1.635015, val:  64.58%, val_best:  67.08%, tr:  91.11%, tr_best:  91.11%\n",
      "epoch-25  lr=['0.0010000'], tr/val_loss:  0.680546/  1.617494, val:  67.92%, val_best:  67.92%, tr:  90.60%, tr_best:  91.11%\n",
      "epoch-26  lr=['0.0010000'], tr/val_loss:  0.685079/  1.622059, val:  68.33%, val_best:  68.33%, tr:  90.09%, tr_best:  91.11%\n",
      "epoch-27  lr=['0.0010000'], tr/val_loss:  0.668759/  1.668863, val:  67.50%, val_best:  68.33%, tr:  90.91%, tr_best:  91.11%\n",
      "epoch-28  lr=['0.0010000'], tr/val_loss:  0.670493/  1.717578, val:  68.33%, val_best:  68.33%, tr:  91.01%, tr_best:  91.11%\n",
      "epoch-29  lr=['0.0010000'], tr/val_loss:  0.621386/  1.749446, val:  64.17%, val_best:  68.33%, tr:  93.77%, tr_best:  93.77%\n",
      "epoch-30  lr=['0.0010000'], tr/val_loss:  0.624418/  1.789540, val:  65.83%, val_best:  68.33%, tr:  93.67%, tr_best:  93.77%\n",
      "epoch-31  lr=['0.0010000'], tr/val_loss:  0.636828/  1.767424, val:  65.00%, val_best:  68.33%, tr:  92.03%, tr_best:  93.77%\n",
      "epoch-32  lr=['0.0010000'], tr/val_loss:  0.626651/  1.795750, val:  65.83%, val_best:  68.33%, tr:  93.87%, tr_best:  93.87%\n",
      "epoch-33  lr=['0.0010000'], tr/val_loss:  0.638346/  1.848629, val:  63.33%, val_best:  68.33%, tr:  92.24%, tr_best:  93.87%\n",
      "epoch-34  lr=['0.0010000'], tr/val_loss:  0.597420/  1.957576, val:  63.33%, val_best:  68.33%, tr:  95.10%, tr_best:  95.10%\n",
      "epoch-35  lr=['0.0010000'], tr/val_loss:  0.611032/  1.996146, val:  63.33%, val_best:  68.33%, tr:  93.46%, tr_best:  95.10%\n",
      "epoch-36  lr=['0.0010000'], tr/val_loss:  0.591873/  1.939366, val:  65.83%, val_best:  68.33%, tr:  95.51%, tr_best:  95.51%\n",
      "epoch-37  lr=['0.0010000'], tr/val_loss:  0.591366/  1.982105, val:  65.00%, val_best:  68.33%, tr:  96.53%, tr_best:  96.53%\n",
      "epoch-38  lr=['0.0010000'], tr/val_loss:  0.582523/  2.001446, val:  68.33%, val_best:  68.33%, tr:  96.94%, tr_best:  96.94%\n",
      "epoch-39  lr=['0.0010000'], tr/val_loss:  0.564702/  2.022887, val:  67.50%, val_best:  68.33%, tr:  96.42%, tr_best:  96.94%\n",
      "epoch-40  lr=['0.0010000'], tr/val_loss:  0.565151/  2.120297, val:  67.92%, val_best:  68.33%, tr:  95.71%, tr_best:  96.94%\n",
      "epoch-41  lr=['0.0010000'], tr/val_loss:  0.557068/  2.140752, val:  65.83%, val_best:  68.33%, tr:  96.73%, tr_best:  96.94%\n",
      "epoch-42  lr=['0.0010000'], tr/val_loss:  0.525257/  2.118379, val:  66.25%, val_best:  68.33%, tr:  97.75%, tr_best:  97.75%\n",
      "epoch-43  lr=['0.0010000'], tr/val_loss:  0.539178/  2.197912, val:  63.75%, val_best:  68.33%, tr:  97.34%, tr_best:  97.75%\n",
      "epoch-44  lr=['0.0010000'], tr/val_loss:  0.522206/  2.220392, val:  66.25%, val_best:  68.33%, tr:  97.75%, tr_best:  97.75%\n",
      "epoch-45  lr=['0.0010000'], tr/val_loss:  0.512232/  2.242227, val:  66.67%, val_best:  68.33%, tr:  97.75%, tr_best:  97.75%\n",
      "epoch-46  lr=['0.0010000'], tr/val_loss:  0.501202/  2.228575, val:  67.08%, val_best:  68.33%, tr:  98.47%, tr_best:  98.47%\n",
      "epoch-47  lr=['0.0010000'], tr/val_loss:  0.494333/  2.312970, val:  65.42%, val_best:  68.33%, tr:  98.67%, tr_best:  98.67%\n",
      "epoch-48  lr=['0.0010000'], tr/val_loss:  0.494586/  2.318042, val:  66.25%, val_best:  68.33%, tr:  98.57%, tr_best:  98.67%\n",
      "epoch-49  lr=['0.0010000'], tr/val_loss:  0.508738/  2.396864, val:  64.58%, val_best:  68.33%, tr:  98.06%, tr_best:  98.67%\n",
      "epoch-50  lr=['0.0010000'], tr/val_loss:  0.490841/  2.432610, val:  65.00%, val_best:  68.33%, tr:  98.67%, tr_best:  98.67%\n",
      "epoch-51  lr=['0.0010000'], tr/val_loss:  0.501619/  2.443867, val:  65.42%, val_best:  68.33%, tr:  98.57%, tr_best:  98.67%\n",
      "epoch-52  lr=['0.0010000'], tr/val_loss:  0.482933/  2.479905, val:  68.33%, val_best:  68.33%, tr:  99.18%, tr_best:  99.18%\n",
      "epoch-53  lr=['0.0010000'], tr/val_loss:  0.477838/  2.538728, val:  66.67%, val_best:  68.33%, tr:  99.39%, tr_best:  99.39%\n",
      "epoch-54  lr=['0.0010000'], tr/val_loss:  0.479183/  2.583109, val:  65.83%, val_best:  68.33%, tr:  99.08%, tr_best:  99.39%\n",
      "epoch-55  lr=['0.0010000'], tr/val_loss:  0.468027/  2.644629, val:  66.67%, val_best:  68.33%, tr:  99.39%, tr_best:  99.39%\n",
      "epoch-56  lr=['0.0010000'], tr/val_loss:  0.473856/  2.653191, val:  65.42%, val_best:  68.33%, tr:  99.28%, tr_best:  99.39%\n",
      "epoch-57  lr=['0.0010000'], tr/val_loss:  0.480465/  2.618025, val:  68.33%, val_best:  68.33%, tr:  99.49%, tr_best:  99.49%\n",
      "epoch-58  lr=['0.0010000'], tr/val_loss:  0.452467/  2.733135, val:  62.50%, val_best:  68.33%, tr:  99.39%, tr_best:  99.49%\n",
      "epoch-59  lr=['0.0010000'], tr/val_loss:  0.458238/  2.680492, val:  67.92%, val_best:  68.33%, tr:  99.08%, tr_best:  99.49%\n",
      "epoch-60  lr=['0.0010000'], tr/val_loss:  0.466325/  2.711759, val:  67.08%, val_best:  68.33%, tr:  99.28%, tr_best:  99.49%\n",
      "epoch-61  lr=['0.0010000'], tr/val_loss:  0.461355/  2.762516, val:  67.50%, val_best:  68.33%, tr:  99.49%, tr_best:  99.49%\n",
      "epoch-62  lr=['0.0010000'], tr/val_loss:  0.448615/  2.830178, val:  65.00%, val_best:  68.33%, tr:  99.59%, tr_best:  99.59%\n",
      "epoch-63  lr=['0.0010000'], tr/val_loss:  0.442779/  2.875696, val:  66.25%, val_best:  68.33%, tr:  99.59%, tr_best:  99.59%\n",
      "epoch-64  lr=['0.0010000'], tr/val_loss:  0.452675/  2.929097, val:  65.42%, val_best:  68.33%, tr:  99.18%, tr_best:  99.59%\n",
      "epoch-65  lr=['0.0010000'], tr/val_loss:  0.441500/  2.885522, val:  65.83%, val_best:  68.33%, tr:  99.28%, tr_best:  99.59%\n",
      "epoch-66  lr=['0.0010000'], tr/val_loss:  0.448056/  2.954639, val:  64.58%, val_best:  68.33%, tr:  99.08%, tr_best:  99.59%\n",
      "epoch-67  lr=['0.0010000'], tr/val_loss:  0.472065/  2.912072, val:  68.33%, val_best:  68.33%, tr:  99.18%, tr_best:  99.59%\n",
      "epoch-68  lr=['0.0010000'], tr/val_loss:  0.455693/  3.063578, val:  63.75%, val_best:  68.33%, tr:  98.67%, tr_best:  99.59%\n",
      "epoch-69  lr=['0.0010000'], tr/val_loss:  0.457066/  3.023675, val:  68.75%, val_best:  68.75%, tr:  98.77%, tr_best:  99.59%\n",
      "epoch-70  lr=['0.0010000'], tr/val_loss:  0.445481/  3.087715, val:  65.00%, val_best:  68.75%, tr:  99.49%, tr_best:  99.59%\n",
      "epoch-71  lr=['0.0010000'], tr/val_loss:  0.458703/  3.106065, val:  62.92%, val_best:  68.75%, tr:  98.98%, tr_best:  99.59%\n",
      "epoch-72  lr=['0.0010000'], tr/val_loss:  0.456814/  3.125111, val:  65.00%, val_best:  68.75%, tr:  99.08%, tr_best:  99.59%\n",
      "epoch-73  lr=['0.0010000'], tr/val_loss:  0.452207/  3.070091, val:  67.08%, val_best:  68.75%, tr:  99.69%, tr_best:  99.69%\n",
      "epoch-74  lr=['0.0010000'], tr/val_loss:  0.436011/  3.146578, val:  64.58%, val_best:  68.75%, tr:  99.28%, tr_best:  99.69%\n",
      "epoch-75  lr=['0.0010000'], tr/val_loss:  0.432641/  3.278949, val:  65.00%, val_best:  68.75%, tr:  99.49%, tr_best:  99.69%\n",
      "epoch-76  lr=['0.0010000'], tr/val_loss:  0.430715/  3.224578, val:  64.58%, val_best:  68.75%, tr:  99.59%, tr_best:  99.69%\n",
      "epoch-77  lr=['0.0010000'], tr/val_loss:  0.435468/  3.271761, val:  65.83%, val_best:  68.75%, tr:  99.49%, tr_best:  99.69%\n",
      "epoch-78  lr=['0.0010000'], tr/val_loss:  0.444355/  3.210975, val:  66.67%, val_best:  68.75%, tr:  99.18%, tr_best:  99.69%\n",
      "epoch-79  lr=['0.0010000'], tr/val_loss:  0.419681/  3.283675, val:  67.08%, val_best:  68.75%, tr:  99.69%, tr_best:  99.69%\n",
      "epoch-80  lr=['0.0010000'], tr/val_loss:  0.430523/  3.323857, val:  65.00%, val_best:  68.75%, tr:  99.08%, tr_best:  99.69%\n",
      "epoch-81  lr=['0.0010000'], tr/val_loss:  0.411631/  3.358387, val:  67.50%, val_best:  68.75%, tr:  99.39%, tr_best:  99.69%\n",
      "epoch-82  lr=['0.0010000'], tr/val_loss:  0.424088/  3.491949, val:  64.58%, val_best:  68.75%, tr:  99.49%, tr_best:  99.69%\n",
      "epoch-83  lr=['0.0010000'], tr/val_loss:  0.428729/  3.484405, val:  64.17%, val_best:  68.75%, tr:  99.18%, tr_best:  99.69%\n",
      "epoch-84  lr=['0.0010000'], tr/val_loss:  0.420097/  3.429357, val:  66.25%, val_best:  68.75%, tr:  99.80%, tr_best:  99.80%\n",
      "epoch-85  lr=['0.0010000'], tr/val_loss:  0.406717/  3.461854, val:  65.42%, val_best:  68.75%, tr:  99.69%, tr_best:  99.80%\n",
      "epoch-86  lr=['0.0010000'], tr/val_loss:  0.403112/  3.600858, val:  66.67%, val_best:  68.75%, tr:  99.59%, tr_best:  99.80%\n",
      "epoch-87  lr=['0.0010000'], tr/val_loss:  0.411629/  3.637316, val:  63.75%, val_best:  68.75%, tr:  99.59%, tr_best:  99.80%\n",
      "epoch-88  lr=['0.0010000'], tr/val_loss:  0.412038/  3.625228, val:  66.25%, val_best:  68.75%, tr:  99.49%, tr_best:  99.80%\n",
      "epoch-89  lr=['0.0010000'], tr/val_loss:  0.406560/  3.561375, val:  65.42%, val_best:  68.75%, tr:  99.59%, tr_best:  99.80%\n",
      "epoch-90  lr=['0.0010000'], tr/val_loss:  0.414159/  3.600652, val:  65.83%, val_best:  68.75%, tr:  99.39%, tr_best:  99.80%\n",
      "epoch-91  lr=['0.0010000'], tr/val_loss:  0.415171/  3.754240, val:  63.75%, val_best:  68.75%, tr:  99.49%, tr_best:  99.80%\n",
      "epoch-92  lr=['0.0010000'], tr/val_loss:  0.403950/  3.739951, val:  64.58%, val_best:  68.75%, tr:  99.59%, tr_best:  99.80%\n",
      "epoch-93  lr=['0.0010000'], tr/val_loss:  0.415218/  3.729659, val:  65.42%, val_best:  68.75%, tr:  99.80%, tr_best:  99.80%\n",
      "epoch-94  lr=['0.0010000'], tr/val_loss:  0.422088/  3.777289, val:  64.17%, val_best:  68.75%, tr:  99.90%, tr_best:  99.90%\n",
      "epoch-95  lr=['0.0010000'], tr/val_loss:  0.404644/  3.859814, val:  66.25%, val_best:  68.75%, tr:  99.69%, tr_best:  99.90%\n",
      "epoch-96  lr=['0.0010000'], tr/val_loss:  0.400590/  3.955474, val:  63.75%, val_best:  68.75%, tr:  99.69%, tr_best:  99.90%\n",
      "epoch-97  lr=['0.0010000'], tr/val_loss:  0.398874/  3.932581, val:  64.58%, val_best:  68.75%, tr:  99.69%, tr_best:  99.90%\n",
      "epoch-98  lr=['0.0010000'], tr/val_loss:  0.372370/  3.934501, val:  65.00%, val_best:  68.75%, tr:  99.80%, tr_best:  99.90%\n",
      "epoch-99  lr=['0.0010000'], tr/val_loss:  0.389008/  4.001581, val:  63.75%, val_best:  68.75%, tr:  99.80%, tr_best:  99.90%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3ce6a15a626d433882b977b338d0b4fc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.006 MB of 0.006 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>iter_acc</td><td>▁▆▁▃▄▅▅▂▅███▇▅███▇██▇██████▇████████████</td></tr><tr><td>summary_val_acc</td><td>▁▄▆▆▅▆▆██▇▇█▇▇▇▇█▇▇▇▇█▇███▇█▇▇▇▇█▇▇▇▇▇▇▇</td></tr><tr><td>tr_acc</td><td>▁▄▅▅▆▆▆▇▇▇▇▇▇▇▇█████████████████████████</td></tr><tr><td>tr_epoch_loss</td><td>█▅▄▃▃▃▃▃▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_acc_best</td><td>▁▄▅▇▇▇▇█████████████████████████████████</td></tr><tr><td>val_acc_now</td><td>▁▄▆▆▅▆▆██▇▇█▇▇▇▇█▇▇▇▇█▇███▇█▇▇▇▇█▇▇▇▇▇▇▇</td></tr><tr><td>val_loss</td><td>▂▁▁▁▁▁▂▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▅▅▅▅▆▆▆▆▆▇▇▇▇▇██</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>99</td></tr><tr><td>iter_acc</td><td>1.0</td></tr><tr><td>tr_acc</td><td>0.99796</td></tr><tr><td>tr_epoch_loss</td><td>0.38901</td></tr><tr><td>val_acc_best</td><td>0.6875</td></tr><tr><td>val_acc_now</td><td>0.6375</td></tr><tr><td>val_loss</td><td>4.00158</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">exalted-sweep-197</strong> at: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/f22fqv66' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/f22fqv66</a><br/> View project at: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>/data2/bh_wandb/wandb/run-20250430_053857-f22fqv66/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require(\"core\")`! See https://wandb.me/wandb-core for more information."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Sweep Agent: Waiting for job.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Job received.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 79ttnd4t with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBATCH: 16\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBN_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBPTT_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tDFA_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tIMAGE_SIZE: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tOTTT_input_trace_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tTIME: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tUDA_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \talpha_uda: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbias: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcfg: ['M', 'M', 200, 200]\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tchaching_on: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tconvTrue_fcFalse: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdata_path: /data2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tddp_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdenoise_on: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdvs_clipping: 5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdvs_duration: 100000\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepoch_num: 100\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \texclude_class: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \textra_train_dataset: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlast_lif: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_sg_width: 5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_decay: 0.5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_init: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_reset: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_threshold: 0.25\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmerge_polarities: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmy_seed: 42\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnet_print: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_workers: 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer_what: SGD\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tpin_memory: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tpre_trained: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tpre_trained_path: net_save/save_now_net_weights_{unique_name}.pth\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \trate_coding: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tscheduler_name: no\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsingle_step: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsurrogate: hard_sigmoid\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_conv_kernel_size: 3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_conv_padding: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_conv_stride: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_trace_const1: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_trace_const2: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \ttdBN_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \ttrace_on: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \twhich_data: DVS_GESTURE_TONIC\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.19.10 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.17.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/data2/bh_wandb/wandb/run-20250430_054625-79ttnd4t</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/79ttnd4t' target=\"_blank\">ruby-sweep-200</a></strong> to <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/6pj3lh8j' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/6pj3lh8j</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/6pj3lh8j' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/6pj3lh8j</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/79ttnd4t' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/79ttnd4t</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'single_step' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'my_seed' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'TIME' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BATCH' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'IMAGE_SIZE' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'which_data' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'data_path' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'rate_coding' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_init' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_decay' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_threshold' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_reset' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_sg_width' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_conv_kernel_size' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_conv_stride' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_conv_padding' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_trace_const1' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_trace_const2' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'pre_trained' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'convTrue_fcFalse' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'cfg' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'net_print' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'pre_trained_path' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'learning_rate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'epoch_num' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'tdBN_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BN_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'surrogate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BPTT_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'optimizer_what' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'scheduler_name' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'ddp_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'dvs_clipping' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'dvs_duration' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'DFA_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'trace_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'OTTT_input_trace_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'exclude_class' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'merge_polarities' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'denoise_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'extra_train_dataset' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'num_workers' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'chaching_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'pin_memory' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'UDA_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'alpha_uda' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'bias' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'last_lif' was locked by 'sweep' (ignored update).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "param {'devices': '0', 'single_step': True, 'unique_name': 'main', 'my_seed': 42, 'TIME': 10, 'BATCH': 16, 'IMAGE_SIZE': 128, 'which_data': 'DVS_GESTURE_TONIC', 'data_path': '/data2', 'rate_coding': False, 'lif_layer_v_init': 0, 'lif_layer_v_decay': 0.5, 'lif_layer_v_threshold': 0.25, 'lif_layer_v_reset': 0, 'lif_layer_sg_width': 5, 'synapse_conv_kernel_size': 3, 'synapse_conv_stride': 1, 'synapse_conv_padding': 1, 'synapse_trace_const1': 1, 'synapse_trace_const2': 0, 'pre_trained': False, 'convTrue_fcFalse': False, 'cfg': ['M', 'M', 200, 200], 'net_print': True, 'pre_trained_path': 'net_save/save_now_net_weights_{unique_name}.pth', 'learning_rate': 0.1, 'epoch_num': 100, 'tdBN_on': False, 'BN_on': False, 'surrogate': 'hard_sigmoid', 'BPTT_on': False, 'optimizer_what': 'SGD', 'scheduler_name': 'no', 'ddp_on': False, 'dvs_clipping': 5, 'dvs_duration': 100000, 'DFA_on': False, 'trace_on': True, 'OTTT_input_trace_on': False, 'exclude_class': True, 'merge_polarities': False, 'denoise_on': True, 'extra_train_dataset': 0, 'num_workers': 2, 'chaching_on': True, 'pin_memory': True, 'UDA_on': False, 'alpha_uda': 1, 'bias': True, 'last_lif': False, 'current epoch': 0} \n",
      "\n",
      "dataset_hash = 63cc597115630ec173f3099200061e53\n",
      "cache path exists\n",
      "\n",
      "device ==> cuda\n",
      "\n",
      "DataParallel(\n",
      "  (module): REBORN_MY_SNN_FC(\n",
      "    (layers): REBORN_MY_Sequential(\n",
      "      (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (2): DimChanger_for_FC()\n",
      "      (3): SYNAPSE_FC(in_features=2048, out_features=200, TIME=10, bias=True, sstep=True)\n",
      "      (4): LIF_layer(v_init=0, v_decay=0.5, v_threshold=0.25, v_reset=0, sg_width=5, surrogate=hard_sigmoid, BPTT_on=False, trace_const1=1, trace_const2=0, TIME=10, sstep=True, trace_on=True)\n",
      "      (5): SYNAPSE_FC(in_features=200, out_features=200, TIME=10, bias=True, sstep=True)\n",
      "      (6): LIF_layer(v_init=0, v_decay=0.5, v_threshold=0.25, v_reset=0, sg_width=5, surrogate=hard_sigmoid, BPTT_on=False, trace_const1=1, trace_const2=0, TIME=10, sstep=True, trace_on=True)\n",
      "      (7): SYNAPSE_FC(in_features=200, out_features=10, TIME=10, bias=True, sstep=True)\n",
      "    )\n",
      "  )\n",
      ")\n",
      "\n",
      "========================================================\n",
      "Trainable parameters: 452,010\n",
      "========================================================\n",
      "\n",
      "epoch-0   lr=['0.1000000'], tr/val_loss:  2.448219/  4.092346, val:  42.50%, val_best:  42.50%, tr:  35.75%, tr_best:  35.75%\n",
      "epoch-1   lr=['0.1000000'], tr/val_loss:  2.952480/  5.153693, val:  18.75%, val_best:  42.50%, tr:  36.36%, tr_best:  36.36%\n",
      "epoch-2   lr=['0.1000000'], tr/val_loss:  3.461688/  2.607175, val:  20.00%, val_best:  42.50%, tr:  27.48%, tr_best:  36.36%\n",
      "epoch-3   lr=['0.1000000'], tr/val_loss:  3.610590/  3.153970, val:  27.50%, val_best:  42.50%, tr:  28.80%, tr_best:  36.36%\n",
      "epoch-4   lr=['0.1000000'], tr/val_loss:  3.327405/  2.512822, val:  25.00%, val_best:  42.50%, tr:  25.64%, tr_best:  36.36%\n",
      "epoch-5   lr=['0.1000000'], tr/val_loss:  3.300317/  3.440423, val:  19.17%, val_best:  42.50%, tr:  27.17%, tr_best:  36.36%\n",
      "epoch-6   lr=['0.1000000'], tr/val_loss:  2.877478/  2.755845, val:  28.75%, val_best:  42.50%, tr:  27.89%, tr_best:  36.36%\n",
      "epoch-7   lr=['0.1000000'], tr/val_loss:  3.828017/  3.737038, val:  20.00%, val_best:  42.50%, tr:  24.51%, tr_best:  36.36%\n",
      "epoch-8   lr=['0.1000000'], tr/val_loss:  3.551816/  4.066401, val:  25.00%, val_best:  42.50%, tr:  25.54%, tr_best:  36.36%\n",
      "epoch-9   lr=['0.1000000'], tr/val_loss:  3.170838/  4.107774, val:  27.08%, val_best:  42.50%, tr:  27.68%, tr_best:  36.36%\n",
      "epoch-10  lr=['0.1000000'], tr/val_loss:  4.343871/  4.113514, val:  23.75%, val_best:  42.50%, tr:  23.49%, tr_best:  36.36%\n",
      "epoch-11  lr=['0.1000000'], tr/val_loss:  4.316092/  2.725493, val:  27.08%, val_best:  42.50%, tr:  23.29%, tr_best:  36.36%\n",
      "epoch-12  lr=['0.1000000'], tr/val_loss:  3.400550/  3.105755, val:  29.17%, val_best:  42.50%, tr:  24.31%, tr_best:  36.36%\n",
      "epoch-13  lr=['0.1000000'], tr/val_loss:  4.057975/  4.617524, val:  20.42%, val_best:  42.50%, tr:  25.64%, tr_best:  36.36%\n",
      "epoch-14  lr=['0.1000000'], tr/val_loss:  3.211210/  5.255288, val:  26.25%, val_best:  42.50%, tr:  27.17%, tr_best:  36.36%\n",
      "epoch-15  lr=['0.1000000'], tr/val_loss:  3.882902/  3.808830, val:  25.42%, val_best:  42.50%, tr:  26.15%, tr_best:  36.36%\n",
      "epoch-16  lr=['0.1000000'], tr/val_loss:  4.040216/  4.172449, val:  27.50%, val_best:  42.50%, tr:  25.13%, tr_best:  36.36%\n",
      "epoch-17  lr=['0.1000000'], tr/val_loss:  4.148850/  3.401636, val:  28.75%, val_best:  42.50%, tr:  25.74%, tr_best:  36.36%\n",
      "epoch-18  lr=['0.1000000'], tr/val_loss:  3.140374/  4.664324, val:  32.08%, val_best:  42.50%, tr:  26.15%, tr_best:  36.36%\n",
      "epoch-19  lr=['0.1000000'], tr/val_loss:  4.594037/  6.148160, val:  18.75%, val_best:  42.50%, tr:  27.17%, tr_best:  36.36%\n",
      "epoch-20  lr=['0.1000000'], tr/val_loss:  4.768002/  4.412919, val:  30.00%, val_best:  42.50%, tr:  24.41%, tr_best:  36.36%\n",
      "epoch-21  lr=['0.1000000'], tr/val_loss:  3.900442/  4.360536, val:  22.92%, val_best:  42.50%, tr:  25.74%, tr_best:  36.36%\n",
      "epoch-22  lr=['0.1000000'], tr/val_loss:  4.401895/  3.388826, val:  24.17%, val_best:  42.50%, tr:  26.46%, tr_best:  36.36%\n",
      "epoch-23  lr=['0.1000000'], tr/val_loss:  3.931901/  3.370629, val:  27.08%, val_best:  42.50%, tr:  29.62%, tr_best:  36.36%\n",
      "epoch-24  lr=['0.1000000'], tr/val_loss:  3.403163/  3.575389, val:  24.58%, val_best:  42.50%, tr:  28.80%, tr_best:  36.36%\n",
      "epoch-25  lr=['0.1000000'], tr/val_loss:  4.216846/  4.338555, val:  25.83%, val_best:  42.50%, tr:  24.31%, tr_best:  36.36%\n",
      "epoch-26  lr=['0.1000000'], tr/val_loss:  3.431473/  3.546727, val:  29.58%, val_best:  42.50%, tr:  25.43%, tr_best:  36.36%\n",
      "epoch-27  lr=['0.1000000'], tr/val_loss:  3.226142/  3.463448, val:  30.42%, val_best:  42.50%, tr:  25.23%, tr_best:  36.36%\n",
      "epoch-28  lr=['0.1000000'], tr/val_loss:  4.176338/  4.432234, val:  29.17%, val_best:  42.50%, tr:  28.09%, tr_best:  36.36%\n",
      "epoch-29  lr=['0.1000000'], tr/val_loss:  4.381275/  2.954366, val:  10.00%, val_best:  42.50%, tr:  18.49%, tr_best:  36.36%\n",
      "epoch-30  lr=['0.1000000'], tr/val_loss:  3.805373/  4.051086, val:  16.25%, val_best:  42.50%, tr:  16.75%, tr_best:  36.36%\n",
      "epoch-31  lr=['0.1000000'], tr/val_loss:  4.736128/  4.992465, val:  16.25%, val_best:  42.50%, tr:  17.26%, tr_best:  36.36%\n",
      "epoch-32  lr=['0.1000000'], tr/val_loss:  5.089223/  4.404470, val:  25.00%, val_best:  42.50%, tr:  17.88%, tr_best:  36.36%\n",
      "epoch-33  lr=['0.1000000'], tr/val_loss:  4.133123/  4.381704, val:  20.83%, val_best:  42.50%, tr:  19.00%, tr_best:  36.36%\n",
      "epoch-34  lr=['0.1000000'], tr/val_loss:  4.533505/  8.795813, val:  15.00%, val_best:  42.50%, tr:  19.51%, tr_best:  36.36%\n",
      "epoch-35  lr=['0.1000000'], tr/val_loss:  4.699578/  3.974878, val:  14.58%, val_best:  42.50%, tr:  18.59%, tr_best:  36.36%\n",
      "epoch-36  lr=['0.1000000'], tr/val_loss:  3.576538/  3.786849, val:  20.00%, val_best:  42.50%, tr:  19.61%, tr_best:  36.36%\n",
      "epoch-37  lr=['0.1000000'], tr/val_loss:  4.164759/  5.974380, val:  10.00%, val_best:  42.50%, tr:  18.69%, tr_best:  36.36%\n",
      "epoch-38  lr=['0.1000000'], tr/val_loss:  4.149957/  3.478309, val:  19.17%, val_best:  42.50%, tr:  18.18%, tr_best:  36.36%\n",
      "epoch-39  lr=['0.1000000'], tr/val_loss:  3.826983/  3.073600, val:  27.92%, val_best:  42.50%, tr:  17.88%, tr_best:  36.36%\n",
      "epoch-40  lr=['0.1000000'], tr/val_loss:  3.242475/  3.353849, val:  20.00%, val_best:  42.50%, tr:  21.96%, tr_best:  36.36%\n",
      "epoch-41  lr=['0.1000000'], tr/val_loss:  4.206542/  4.019656, val:  20.00%, val_best:  42.50%, tr:  19.51%, tr_best:  36.36%\n",
      "epoch-42  lr=['0.1000000'], tr/val_loss:  4.552932/  5.070785, val:  10.00%, val_best:  42.50%, tr:  18.39%, tr_best:  36.36%\n",
      "epoch-43  lr=['0.1000000'], tr/val_loss:  6.321408/  9.102879, val:  19.17%, val_best:  42.50%, tr:  17.67%, tr_best:  36.36%\n",
      "epoch-44  lr=['0.1000000'], tr/val_loss:  4.589480/  3.107387, val:  18.75%, val_best:  42.50%, tr:  18.08%, tr_best:  36.36%\n",
      "epoch-45  lr=['0.1000000'], tr/val_loss:  3.780438/  5.024476, val:  10.00%, val_best:  42.50%, tr:  18.08%, tr_best:  36.36%\n",
      "epoch-46  lr=['0.1000000'], tr/val_loss:  4.238036/  6.550352, val:  10.00%, val_best:  42.50%, tr:  18.90%, tr_best:  36.36%\n",
      "epoch-47  lr=['0.1000000'], tr/val_loss:  4.480468/  4.224965, val:  19.17%, val_best:  42.50%, tr:  20.33%, tr_best:  36.36%\n",
      "epoch-48  lr=['0.1000000'], tr/val_loss:  3.469593/  5.706103, val:  11.67%, val_best:  42.50%, tr:  20.22%, tr_best:  36.36%\n",
      "epoch-49  lr=['0.1000000'], tr/val_loss:  5.259829/  5.092421, val:  20.00%, val_best:  42.50%, tr:  16.65%, tr_best:  36.36%\n",
      "epoch-50  lr=['0.1000000'], tr/val_loss:  4.654817/  9.121492, val:  15.83%, val_best:  42.50%, tr:  18.28%, tr_best:  36.36%\n",
      "epoch-51  lr=['0.1000000'], tr/val_loss:  4.498508/  6.524764, val:  10.00%, val_best:  42.50%, tr:  16.45%, tr_best:  36.36%\n",
      "epoch-52  lr=['0.1000000'], tr/val_loss:  5.055273/  4.074111, val:  21.67%, val_best:  42.50%, tr:  19.00%, tr_best:  36.36%\n",
      "epoch-53  lr=['0.1000000'], tr/val_loss:  4.166047/  6.030861, val:  12.08%, val_best:  42.50%, tr:  19.51%, tr_best:  36.36%\n",
      "epoch-54  lr=['0.1000000'], tr/val_loss:  4.485622/  2.970524, val:  18.33%, val_best:  42.50%, tr:  19.20%, tr_best:  36.36%\n",
      "epoch-55  lr=['0.1000000'], tr/val_loss:  4.036369/  2.869370, val:  18.75%, val_best:  42.50%, tr:  18.59%, tr_best:  36.36%\n",
      "epoch-56  lr=['0.1000000'], tr/val_loss:  4.043991/  7.542554, val:  20.00%, val_best:  42.50%, tr:  20.12%, tr_best:  36.36%\n",
      "epoch-57  lr=['0.1000000'], tr/val_loss:  4.342535/  4.476575, val:  18.75%, val_best:  42.50%, tr:  19.41%, tr_best:  36.36%\n",
      "epoch-58  lr=['0.1000000'], tr/val_loss:  3.916110/  4.524834, val:  20.83%, val_best:  42.50%, tr:  18.18%, tr_best:  36.36%\n",
      "epoch-59  lr=['0.1000000'], tr/val_loss:  3.920027/  6.179045, val:  18.33%, val_best:  42.50%, tr:  22.68%, tr_best:  36.36%\n",
      "epoch-60  lr=['0.1000000'], tr/val_loss:  4.243494/  3.489806, val:  19.58%, val_best:  42.50%, tr:  18.90%, tr_best:  36.36%\n",
      "epoch-61  lr=['0.1000000'], tr/val_loss:  4.352355/  5.513671, val:  20.00%, val_best:  42.50%, tr:  19.00%, tr_best:  36.36%\n",
      "epoch-62  lr=['0.1000000'], tr/val_loss:  5.177906/  7.660593, val:  11.25%, val_best:  42.50%, tr:  17.26%, tr_best:  36.36%\n",
      "epoch-63  lr=['0.1000000'], tr/val_loss:  5.491536/  4.146752, val:  20.00%, val_best:  42.50%, tr:  16.65%, tr_best:  36.36%\n",
      "epoch-64  lr=['0.1000000'], tr/val_loss:  3.791927/  4.326230, val:  24.58%, val_best:  42.50%, tr:  22.37%, tr_best:  36.36%\n",
      "epoch-65  lr=['0.1000000'], tr/val_loss:  3.521171/  4.103807, val:  18.75%, val_best:  42.50%, tr:  20.63%, tr_best:  36.36%\n",
      "epoch-66  lr=['0.1000000'], tr/val_loss:  3.301724/  4.665936, val:  17.08%, val_best:  42.50%, tr:  20.22%, tr_best:  36.36%\n",
      "epoch-67  lr=['0.1000000'], tr/val_loss:  4.021813/  3.796932, val:  16.25%, val_best:  42.50%, tr:  18.49%, tr_best:  36.36%\n",
      "epoch-68  lr=['0.1000000'], tr/val_loss:  3.763664/  3.643310, val:  19.17%, val_best:  42.50%, tr:  18.08%, tr_best:  36.36%\n",
      "epoch-69  lr=['0.1000000'], tr/val_loss:  4.615980/  7.187016, val:  20.00%, val_best:  42.50%, tr:  16.65%, tr_best:  36.36%\n",
      "epoch-70  lr=['0.1000000'], tr/val_loss:  4.728230/  5.808611, val:  19.58%, val_best:  42.50%, tr:  21.96%, tr_best:  36.36%\n",
      "epoch-71  lr=['0.1000000'], tr/val_loss:  3.642747/  3.902295, val:  28.33%, val_best:  42.50%, tr:  27.99%, tr_best:  36.36%\n",
      "epoch-72  lr=['0.1000000'], tr/val_loss:  3.663824/  4.398776, val:  25.00%, val_best:  42.50%, tr:  25.74%, tr_best:  36.36%\n",
      "epoch-73  lr=['0.1000000'], tr/val_loss:  4.032463/  3.021630, val:  32.50%, val_best:  42.50%, tr:  25.13%, tr_best:  36.36%\n",
      "epoch-74  lr=['0.1000000'], tr/val_loss:  3.185339/  4.297225, val:  20.42%, val_best:  42.50%, tr:  27.17%, tr_best:  36.36%\n",
      "epoch-75  lr=['0.1000000'], tr/val_loss:  3.618440/  2.953925, val:  25.42%, val_best:  42.50%, tr:  28.60%, tr_best:  36.36%\n",
      "epoch-76  lr=['0.1000000'], tr/val_loss:  3.375843/  3.349464, val:  24.58%, val_best:  42.50%, tr:  25.64%, tr_best:  36.36%\n",
      "epoch-77  lr=['0.1000000'], tr/val_loss:  3.180921/  5.686557, val:  20.00%, val_best:  42.50%, tr:  28.29%, tr_best:  36.36%\n",
      "epoch-78  lr=['0.1000000'], tr/val_loss:  3.796919/  5.124572, val:  22.08%, val_best:  42.50%, tr:  31.36%, tr_best:  36.36%\n",
      "epoch-79  lr=['0.1000000'], tr/val_loss:  3.714303/  5.147515, val:  30.00%, val_best:  42.50%, tr:  30.03%, tr_best:  36.36%\n",
      "epoch-80  lr=['0.1000000'], tr/val_loss:  3.938396/  4.258386, val:  29.17%, val_best:  42.50%, tr:  25.84%, tr_best:  36.36%\n",
      "epoch-81  lr=['0.1000000'], tr/val_loss:  3.596904/  5.007172, val:  20.00%, val_best:  42.50%, tr:  26.76%, tr_best:  36.36%\n",
      "epoch-82  lr=['0.1000000'], tr/val_loss:  3.856385/  3.929132, val:  29.17%, val_best:  42.50%, tr:  27.07%, tr_best:  36.36%\n",
      "epoch-83  lr=['0.1000000'], tr/val_loss:  3.594746/  4.426995, val:  27.92%, val_best:  42.50%, tr:  25.54%, tr_best:  36.36%\n",
      "epoch-84  lr=['0.1000000'], tr/val_loss:  4.437721/  3.770720, val:  26.25%, val_best:  42.50%, tr:  27.68%, tr_best:  36.36%\n",
      "epoch-85  lr=['0.1000000'], tr/val_loss:  3.498287/  5.123460, val:  22.08%, val_best:  42.50%, tr:  26.97%, tr_best:  36.36%\n",
      "epoch-86  lr=['0.1000000'], tr/val_loss:  3.969364/  3.765904, val:  28.75%, val_best:  42.50%, tr:  25.84%, tr_best:  36.36%\n",
      "epoch-87  lr=['0.1000000'], tr/val_loss:  3.205201/  3.222533, val:  29.58%, val_best:  42.50%, tr:  25.43%, tr_best:  36.36%\n",
      "epoch-88  lr=['0.1000000'], tr/val_loss:  3.493572/  2.922624, val:  30.00%, val_best:  42.50%, tr:  28.50%, tr_best:  36.36%\n",
      "epoch-89  lr=['0.1000000'], tr/val_loss:  2.955672/  3.494520, val:  32.92%, val_best:  42.50%, tr:  29.62%, tr_best:  36.36%\n",
      "epoch-90  lr=['0.1000000'], tr/val_loss:  3.376311/  4.020737, val:  29.17%, val_best:  42.50%, tr:  29.83%, tr_best:  36.36%\n",
      "epoch-91  lr=['0.1000000'], tr/val_loss:  3.489762/  3.695497, val:  15.42%, val_best:  42.50%, tr:  24.31%, tr_best:  36.36%\n",
      "epoch-92  lr=['0.1000000'], tr/val_loss:  3.505622/  3.943834, val:  17.50%, val_best:  42.50%, tr:  17.36%, tr_best:  36.36%\n",
      "epoch-93  lr=['0.1000000'], tr/val_loss:  3.220919/  4.160336, val:  18.75%, val_best:  42.50%, tr:  20.12%, tr_best:  36.36%\n",
      "epoch-94  lr=['0.1000000'], tr/val_loss:  3.759054/  4.764435, val:  18.75%, val_best:  42.50%, tr:  21.55%, tr_best:  36.36%\n",
      "epoch-95  lr=['0.1000000'], tr/val_loss:  3.770270/  4.336833, val:  19.58%, val_best:  42.50%, tr:  16.75%, tr_best:  36.36%\n",
      "epoch-96  lr=['0.1000000'], tr/val_loss:  3.731904/  2.867257, val:  18.33%, val_best:  42.50%, tr:  19.00%, tr_best:  36.36%\n",
      "epoch-97  lr=['0.1000000'], tr/val_loss:  4.308729/  2.735834, val:  19.58%, val_best:  42.50%, tr:  19.00%, tr_best:  36.36%\n",
      "epoch-98  lr=['0.1000000'], tr/val_loss:  3.805139/  3.939532, val:  18.33%, val_best:  42.50%, tr:  16.14%, tr_best:  36.36%\n",
      "epoch-99  lr=['0.1000000'], tr/val_loss:  4.301467/  3.533271, val:  23.33%, val_best:  42.50%, tr:  18.39%, tr_best:  36.36%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cdc637e776044dd7b74d03f62e4a1ab0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.006 MB of 0.006 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>iter_acc</td><td>▆▅▂▃▇▃▅▆▅▅█▅▄▅▁▃▃▄▅▄▄▅▃▃▅▄▄▅▆▄▆▅▆▄▅▄▄▅▁▅</td></tr><tr><td>summary_val_acc</td><td>█▃▄▃▅▅▄▅▃▄▄▅▁▄▂▁▅▁▃▃▃▄▃▃▃▃▃▂▃▄▄▃▅▅▄▅▆▃▃▃</td></tr><tr><td>tr_acc</td><td>█▅▄▄▅▄▅▄▅▄▅▄▂▁▂▂▁▂▂▂▁▂▂▂▃▂▂▂▃▄▅▅▆▅▅▄▆▁▁▂</td></tr><tr><td>tr_epoch_loss</td><td>▁▄▃▄▃▃▃▅▆▅▃▃▆█▇▅▄▆▆▆█▇▆▆▅▆▄▅▇▄▄▃▄▅▆▃▂▄▄▆</td></tr><tr><td>val_acc_best</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_acc_now</td><td>█▃▄▃▅▅▄▅▃▄▄▅▁▄▂▁▅▁▃▃▃▄▃▃▃▃▃▂▃▄▄▃▅▅▄▅▆▃▃▃</td></tr><tr><td>val_loss</td><td>▄▁▁▃▄▂▆▃█▅▃▃▂▅▄█▂▆▂▄▆▄▂▅█▇▄▃▇▅▂▇▆▄▃▂▃▄▄▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>99</td></tr><tr><td>iter_acc</td><td>0.0</td></tr><tr><td>tr_acc</td><td>0.18386</td></tr><tr><td>tr_epoch_loss</td><td>4.30147</td></tr><tr><td>val_acc_best</td><td>0.425</td></tr><tr><td>val_acc_now</td><td>0.23333</td></tr><tr><td>val_loss</td><td>3.53327</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">ruby-sweep-200</strong> at: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/79ttnd4t' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/79ttnd4t</a><br/> View project at: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>/data2/bh_wandb/wandb/run-20250430_054625-79ttnd4t/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require(\"core\")`! See https://wandb.me/wandb-core for more information."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: zccgh4bs with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBATCH: 16\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBN_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBPTT_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tDFA_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tIMAGE_SIZE: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tOTTT_input_trace_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tTIME: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tUDA_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \talpha_uda: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbias: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcfg: ['M', 'M', 200, 200]\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tchaching_on: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tconvTrue_fcFalse: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdata_path: /data2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tddp_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdenoise_on: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdvs_clipping: 5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdvs_duration: 100000\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepoch_num: 100\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \texclude_class: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \textra_train_dataset: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlast_lif: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.001\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_sg_width: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_decay: 0.5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_init: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_reset: 10000\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_threshold: 0.25\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmerge_polarities: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmy_seed: 42\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnet_print: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_workers: 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer_what: SGD\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tpin_memory: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tpre_trained: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tpre_trained_path: net_save/save_now_net_weights_{unique_name}.pth\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \trate_coding: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tscheduler_name: no\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsingle_step: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsurrogate: hard_sigmoid\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_conv_kernel_size: 3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_conv_padding: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_conv_stride: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_trace_const1: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_trace_const2: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \ttdBN_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \ttrace_on: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \twhich_data: DVS_GESTURE_TONIC\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.19.10 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.17.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/data2/bh_wandb/wandb/run-20250430_055226-zccgh4bs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/zccgh4bs' target=\"_blank\">brisk-sweep-201</a></strong> to <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/6pj3lh8j' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/6pj3lh8j</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/6pj3lh8j' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/6pj3lh8j</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/zccgh4bs' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/zccgh4bs</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'single_step' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'my_seed' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'TIME' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BATCH' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'IMAGE_SIZE' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'which_data' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'data_path' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'rate_coding' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_init' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_decay' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_threshold' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_reset' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_sg_width' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_conv_kernel_size' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_conv_stride' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_conv_padding' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_trace_const1' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_trace_const2' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'pre_trained' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'convTrue_fcFalse' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'cfg' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'net_print' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'pre_trained_path' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'learning_rate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'epoch_num' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'tdBN_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BN_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'surrogate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BPTT_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'optimizer_what' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'scheduler_name' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'ddp_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'dvs_clipping' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'dvs_duration' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'DFA_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'trace_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'OTTT_input_trace_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'exclude_class' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'merge_polarities' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'denoise_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'extra_train_dataset' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'num_workers' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'chaching_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'pin_memory' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'UDA_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'alpha_uda' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'bias' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'last_lif' was locked by 'sweep' (ignored update).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "param {'devices': '0', 'single_step': True, 'unique_name': 'main', 'my_seed': 42, 'TIME': 10, 'BATCH': 16, 'IMAGE_SIZE': 128, 'which_data': 'DVS_GESTURE_TONIC', 'data_path': '/data2', 'rate_coding': False, 'lif_layer_v_init': 0, 'lif_layer_v_decay': 0.5, 'lif_layer_v_threshold': 0.25, 'lif_layer_v_reset': 10000, 'lif_layer_sg_width': 1, 'synapse_conv_kernel_size': 3, 'synapse_conv_stride': 1, 'synapse_conv_padding': 1, 'synapse_trace_const1': 1, 'synapse_trace_const2': 0, 'pre_trained': False, 'convTrue_fcFalse': False, 'cfg': ['M', 'M', 200, 200], 'net_print': True, 'pre_trained_path': 'net_save/save_now_net_weights_{unique_name}.pth', 'learning_rate': 0.001, 'epoch_num': 100, 'tdBN_on': False, 'BN_on': False, 'surrogate': 'hard_sigmoid', 'BPTT_on': False, 'optimizer_what': 'SGD', 'scheduler_name': 'no', 'ddp_on': False, 'dvs_clipping': 5, 'dvs_duration': 100000, 'DFA_on': False, 'trace_on': True, 'OTTT_input_trace_on': False, 'exclude_class': True, 'merge_polarities': False, 'denoise_on': True, 'extra_train_dataset': 0, 'num_workers': 2, 'chaching_on': True, 'pin_memory': True, 'UDA_on': False, 'alpha_uda': 1, 'bias': True, 'last_lif': False, 'current epoch': 0} \n",
      "\n",
      "dataset_hash = 63cc597115630ec173f3099200061e53\n",
      "cache path exists\n",
      "\n",
      "device ==> cuda\n",
      "\n",
      "DataParallel(\n",
      "  (module): REBORN_MY_SNN_FC(\n",
      "    (layers): REBORN_MY_Sequential(\n",
      "      (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (2): DimChanger_for_FC()\n",
      "      (3): SYNAPSE_FC(in_features=2048, out_features=200, TIME=10, bias=True, sstep=True)\n",
      "      (4): LIF_layer(v_init=0, v_decay=0.5, v_threshold=0.25, v_reset=10000, sg_width=1, surrogate=hard_sigmoid, BPTT_on=False, trace_const1=1, trace_const2=0, TIME=10, sstep=True, trace_on=True)\n",
      "      (5): SYNAPSE_FC(in_features=200, out_features=200, TIME=10, bias=True, sstep=True)\n",
      "      (6): LIF_layer(v_init=0, v_decay=0.5, v_threshold=0.25, v_reset=10000, sg_width=1, surrogate=hard_sigmoid, BPTT_on=False, trace_const1=1, trace_const2=0, TIME=10, sstep=True, trace_on=True)\n",
      "      (7): SYNAPSE_FC(in_features=200, out_features=10, TIME=10, bias=True, sstep=True)\n",
      "    )\n",
      "  )\n",
      ")\n",
      "\n",
      "========================================================\n",
      "Trainable parameters: 452,010\n",
      "========================================================\n",
      "\n",
      "epoch-0   lr=['0.0010000'], tr/val_loss:  2.291226/  2.262563, val:  21.67%, val_best:  21.67%, tr:  12.87%, tr_best:  12.87%\n",
      "epoch-1   lr=['0.0010000'], tr/val_loss:  2.226794/  2.197138, val:  30.00%, val_best:  30.00%, tr:  24.92%, tr_best:  24.92%\n",
      "epoch-2   lr=['0.0010000'], tr/val_loss:  2.122399/  2.090609, val:  43.33%, val_best:  43.33%, tr:  32.89%, tr_best:  32.89%\n",
      "epoch-3   lr=['0.0010000'], tr/val_loss:  1.981584/  1.970841, val:  48.33%, val_best:  48.33%, tr:  41.68%, tr_best:  41.68%\n",
      "epoch-4   lr=['0.0010000'], tr/val_loss:  1.838591/  1.864843, val:  52.08%, val_best:  52.08%, tr:  49.03%, tr_best:  49.03%\n",
      "epoch-5   lr=['0.0010000'], tr/val_loss:  1.708440/  1.771031, val:  49.58%, val_best:  52.08%, tr:  53.73%, tr_best:  53.73%\n",
      "epoch-6   lr=['0.0010000'], tr/val_loss:  1.619611/  1.705889, val:  53.33%, val_best:  53.33%, tr:  56.28%, tr_best:  56.28%\n",
      "epoch-7   lr=['0.0010000'], tr/val_loss:  1.546571/  1.663146, val:  55.42%, val_best:  55.42%, tr:  59.55%, tr_best:  59.55%\n",
      "epoch-8   lr=['0.0010000'], tr/val_loss:  1.497638/  1.623710, val:  56.67%, val_best:  56.67%, tr:  60.16%, tr_best:  60.16%\n",
      "epoch-9   lr=['0.0010000'], tr/val_loss:  1.454307/  1.600733, val:  55.00%, val_best:  56.67%, tr:  61.18%, tr_best:  61.18%\n",
      "epoch-10  lr=['0.0010000'], tr/val_loss:  1.419487/  1.571013, val:  58.75%, val_best:  58.75%, tr:  60.47%, tr_best:  61.18%\n",
      "epoch-11  lr=['0.0010000'], tr/val_loss:  1.388129/  1.559669, val:  56.25%, val_best:  58.75%, tr:  61.39%, tr_best:  61.39%\n",
      "epoch-12  lr=['0.0010000'], tr/val_loss:  1.370566/  1.545035, val:  60.00%, val_best:  60.00%, tr:  61.80%, tr_best:  61.80%\n",
      "epoch-13  lr=['0.0010000'], tr/val_loss:  1.345960/  1.527287, val:  57.50%, val_best:  60.00%, tr:  65.37%, tr_best:  65.37%\n",
      "epoch-14  lr=['0.0010000'], tr/val_loss:  1.312908/  1.510120, val:  55.83%, val_best:  60.00%, tr:  63.23%, tr_best:  65.37%\n",
      "epoch-15  lr=['0.0010000'], tr/val_loss:  1.302367/  1.505145, val:  58.33%, val_best:  60.00%, tr:  62.41%, tr_best:  65.37%\n",
      "epoch-16  lr=['0.0010000'], tr/val_loss:  1.280016/  1.494407, val:  55.42%, val_best:  60.00%, tr:  64.35%, tr_best:  65.37%\n",
      "epoch-17  lr=['0.0010000'], tr/val_loss:  1.262773/  1.468826, val:  59.58%, val_best:  60.00%, tr:  65.99%, tr_best:  65.99%\n",
      "epoch-18  lr=['0.0010000'], tr/val_loss:  1.243869/  1.469148, val:  57.08%, val_best:  60.00%, tr:  66.60%, tr_best:  66.60%\n",
      "epoch-19  lr=['0.0010000'], tr/val_loss:  1.234196/  1.453676, val:  57.08%, val_best:  60.00%, tr:  64.15%, tr_best:  66.60%\n",
      "epoch-20  lr=['0.0010000'], tr/val_loss:  1.206181/  1.445538, val:  58.33%, val_best:  60.00%, tr:  66.09%, tr_best:  66.60%\n",
      "epoch-21  lr=['0.0010000'], tr/val_loss:  1.194310/  1.433717, val:  61.25%, val_best:  61.25%, tr:  67.62%, tr_best:  67.62%\n",
      "epoch-22  lr=['0.0010000'], tr/val_loss:  1.190008/  1.437136, val:  58.75%, val_best:  61.25%, tr:  65.17%, tr_best:  67.62%\n",
      "epoch-23  lr=['0.0010000'], tr/val_loss:  1.171175/  1.427524, val:  62.08%, val_best:  62.08%, tr:  69.15%, tr_best:  69.15%\n",
      "epoch-24  lr=['0.0010000'], tr/val_loss:  1.149975/  1.414636, val:  59.58%, val_best:  62.08%, tr:  69.77%, tr_best:  69.77%\n",
      "epoch-25  lr=['0.0010000'], tr/val_loss:  1.145411/  1.407644, val:  63.75%, val_best:  63.75%, tr:  69.15%, tr_best:  69.77%\n",
      "epoch-26  lr=['0.0010000'], tr/val_loss:  1.133959/  1.392657, val:  64.17%, val_best:  64.17%, tr:  68.95%, tr_best:  69.77%\n",
      "epoch-27  lr=['0.0010000'], tr/val_loss:  1.117488/  1.402194, val:  61.25%, val_best:  64.17%, tr:  71.81%, tr_best:  71.81%\n",
      "epoch-28  lr=['0.0010000'], tr/val_loss:  1.114650/  1.384160, val:  61.67%, val_best:  64.17%, tr:  69.77%, tr_best:  71.81%\n",
      "epoch-29  lr=['0.0010000'], tr/val_loss:  1.096739/  1.380825, val:  58.75%, val_best:  64.17%, tr:  70.79%, tr_best:  71.81%\n",
      "epoch-30  lr=['0.0010000'], tr/val_loss:  1.091045/  1.371749, val:  60.83%, val_best:  64.17%, tr:  69.77%, tr_best:  71.81%\n",
      "epoch-31  lr=['0.0010000'], tr/val_loss:  1.081943/  1.377722, val:  62.50%, val_best:  64.17%, tr:  70.99%, tr_best:  71.81%\n",
      "epoch-32  lr=['0.0010000'], tr/val_loss:  1.069469/  1.389074, val:  61.25%, val_best:  64.17%, tr:  73.95%, tr_best:  73.95%\n",
      "epoch-33  lr=['0.0010000'], tr/val_loss:  1.063368/  1.375488, val:  62.50%, val_best:  64.17%, tr:  72.73%, tr_best:  73.95%\n",
      "epoch-34  lr=['0.0010000'], tr/val_loss:  1.052292/  1.350606, val:  64.58%, val_best:  64.58%, tr:  72.42%, tr_best:  73.95%\n",
      "epoch-35  lr=['0.0010000'], tr/val_loss:  1.038437/  1.369132, val:  61.25%, val_best:  64.58%, tr:  73.03%, tr_best:  73.95%\n",
      "epoch-36  lr=['0.0010000'], tr/val_loss:  1.033957/  1.362166, val:  60.42%, val_best:  64.58%, tr:  73.75%, tr_best:  73.95%\n",
      "epoch-37  lr=['0.0010000'], tr/val_loss:  1.028793/  1.338969, val:  64.58%, val_best:  64.58%, tr:  75.28%, tr_best:  75.28%\n",
      "epoch-38  lr=['0.0010000'], tr/val_loss:  1.021361/  1.322225, val:  65.00%, val_best:  65.00%, tr:  75.49%, tr_best:  75.49%\n",
      "epoch-39  lr=['0.0010000'], tr/val_loss:  1.011171/  1.323596, val:  67.50%, val_best:  67.50%, tr:  74.77%, tr_best:  75.49%\n",
      "epoch-40  lr=['0.0010000'], tr/val_loss:  0.996047/  1.330288, val:  64.17%, val_best:  67.50%, tr:  73.75%, tr_best:  75.49%\n",
      "epoch-41  lr=['0.0010000'], tr/val_loss:  0.994030/  1.319227, val:  65.83%, val_best:  67.50%, tr:  78.45%, tr_best:  78.45%\n",
      "epoch-42  lr=['0.0010000'], tr/val_loss:  0.978745/  1.313682, val:  64.58%, val_best:  67.50%, tr:  77.22%, tr_best:  78.45%\n",
      "epoch-43  lr=['0.0010000'], tr/val_loss:  0.976769/  1.314901, val:  63.33%, val_best:  67.50%, tr:  75.69%, tr_best:  78.45%\n",
      "epoch-44  lr=['0.0010000'], tr/val_loss:  0.973642/  1.312907, val:  68.33%, val_best:  68.33%, tr:  74.16%, tr_best:  78.45%\n",
      "epoch-45  lr=['0.0010000'], tr/val_loss:  0.957314/  1.300470, val:  66.25%, val_best:  68.33%, tr:  77.73%, tr_best:  78.45%\n",
      "epoch-46  lr=['0.0010000'], tr/val_loss:  0.953706/  1.316113, val:  67.08%, val_best:  68.33%, tr:  78.04%, tr_best:  78.45%\n",
      "epoch-47  lr=['0.0010000'], tr/val_loss:  0.949879/  1.311043, val:  65.00%, val_best:  68.33%, tr:  76.61%, tr_best:  78.45%\n",
      "epoch-48  lr=['0.0010000'], tr/val_loss:  0.951113/  1.311507, val:  67.50%, val_best:  68.33%, tr:  80.29%, tr_best:  80.29%\n",
      "epoch-49  lr=['0.0010000'], tr/val_loss:  0.942748/  1.294629, val:  65.42%, val_best:  68.33%, tr:  75.59%, tr_best:  80.29%\n",
      "epoch-50  lr=['0.0010000'], tr/val_loss:  0.929699/  1.307492, val:  65.00%, val_best:  68.33%, tr:  79.57%, tr_best:  80.29%\n",
      "epoch-51  lr=['0.0010000'], tr/val_loss:  0.924737/  1.313879, val:  68.33%, val_best:  68.33%, tr:  77.83%, tr_best:  80.29%\n",
      "epoch-52  lr=['0.0010000'], tr/val_loss:  0.920991/  1.313448, val:  60.83%, val_best:  68.33%, tr:  78.14%, tr_best:  80.29%\n",
      "epoch-53  lr=['0.0010000'], tr/val_loss:  0.918137/  1.294773, val:  67.92%, val_best:  68.33%, tr:  77.73%, tr_best:  80.29%\n",
      "epoch-54  lr=['0.0010000'], tr/val_loss:  0.910030/  1.311904, val:  66.67%, val_best:  68.33%, tr:  80.49%, tr_best:  80.49%\n",
      "epoch-55  lr=['0.0010000'], tr/val_loss:  0.899498/  1.316216, val:  67.92%, val_best:  68.33%, tr:  79.26%, tr_best:  80.49%\n",
      "epoch-56  lr=['0.0010000'], tr/val_loss:  0.889800/  1.316038, val:  64.17%, val_best:  68.33%, tr:  83.15%, tr_best:  83.15%\n",
      "epoch-57  lr=['0.0010000'], tr/val_loss:  0.893640/  1.301918, val:  63.33%, val_best:  68.33%, tr:  82.23%, tr_best:  83.15%\n",
      "epoch-58  lr=['0.0010000'], tr/val_loss:  0.875685/  1.327973, val:  63.75%, val_best:  68.33%, tr:  80.18%, tr_best:  83.15%\n",
      "epoch-59  lr=['0.0010000'], tr/val_loss:  0.881230/  1.308731, val:  69.17%, val_best:  69.17%, tr:  80.90%, tr_best:  83.15%\n",
      "epoch-60  lr=['0.0010000'], tr/val_loss:  0.876863/  1.307161, val:  65.83%, val_best:  69.17%, tr:  79.67%, tr_best:  83.15%\n",
      "epoch-61  lr=['0.0010000'], tr/val_loss:  0.872204/  1.323400, val:  65.83%, val_best:  69.17%, tr:  82.33%, tr_best:  83.15%\n",
      "epoch-62  lr=['0.0010000'], tr/val_loss:  0.869627/  1.319818, val:  67.92%, val_best:  69.17%, tr:  84.17%, tr_best:  84.17%\n",
      "epoch-63  lr=['0.0010000'], tr/val_loss:  0.859880/  1.300537, val:  68.33%, val_best:  69.17%, tr:  84.47%, tr_best:  84.47%\n",
      "epoch-64  lr=['0.0010000'], tr/val_loss:  0.846593/  1.354111, val:  63.33%, val_best:  69.17%, tr:  83.86%, tr_best:  84.47%\n",
      "epoch-65  lr=['0.0010000'], tr/val_loss:  0.848980/  1.343405, val:  64.58%, val_best:  69.17%, tr:  82.74%, tr_best:  84.47%\n",
      "epoch-66  lr=['0.0010000'], tr/val_loss:  0.848458/  1.317158, val:  70.42%, val_best:  70.42%, tr:  82.33%, tr_best:  84.47%\n",
      "epoch-67  lr=['0.0010000'], tr/val_loss:  0.852612/  1.330100, val:  64.58%, val_best:  70.42%, tr:  84.17%, tr_best:  84.47%\n",
      "epoch-68  lr=['0.0010000'], tr/val_loss:  0.834399/  1.330367, val:  64.58%, val_best:  70.42%, tr:  81.61%, tr_best:  84.47%\n",
      "epoch-69  lr=['0.0010000'], tr/val_loss:  0.826423/  1.335395, val:  67.50%, val_best:  70.42%, tr:  85.39%, tr_best:  85.39%\n",
      "epoch-70  lr=['0.0010000'], tr/val_loss:  0.827093/  1.346238, val:  67.50%, val_best:  70.42%, tr:  84.47%, tr_best:  85.39%\n",
      "epoch-71  lr=['0.0010000'], tr/val_loss:  0.816498/  1.368155, val:  60.83%, val_best:  70.42%, tr:  86.41%, tr_best:  86.41%\n",
      "epoch-72  lr=['0.0010000'], tr/val_loss:  0.811053/  1.376341, val:  61.67%, val_best:  70.42%, tr:  85.90%, tr_best:  86.41%\n",
      "epoch-73  lr=['0.0010000'], tr/val_loss:  0.825768/  1.347697, val:  65.00%, val_best:  70.42%, tr:  85.09%, tr_best:  86.41%\n",
      "epoch-74  lr=['0.0010000'], tr/val_loss:  0.807949/  1.346545, val:  66.25%, val_best:  70.42%, tr:  86.01%, tr_best:  86.41%\n",
      "epoch-75  lr=['0.0010000'], tr/val_loss:  0.816280/  1.343462, val:  68.33%, val_best:  70.42%, tr:  83.96%, tr_best:  86.41%\n",
      "epoch-76  lr=['0.0010000'], tr/val_loss:  0.795494/  1.356621, val:  67.92%, val_best:  70.42%, tr:  85.60%, tr_best:  86.41%\n",
      "epoch-77  lr=['0.0010000'], tr/val_loss:  0.813072/  1.367792, val:  63.75%, val_best:  70.42%, tr:  86.31%, tr_best:  86.41%\n",
      "epoch-78  lr=['0.0010000'], tr/val_loss:  0.797813/  1.350766, val:  69.58%, val_best:  70.42%, tr:  87.13%, tr_best:  87.13%\n",
      "epoch-79  lr=['0.0010000'], tr/val_loss:  0.792662/  1.358648, val:  64.58%, val_best:  70.42%, tr:  85.70%, tr_best:  87.13%\n",
      "epoch-80  lr=['0.0010000'], tr/val_loss:  0.786989/  1.367459, val:  68.33%, val_best:  70.42%, tr:  85.80%, tr_best:  87.13%\n",
      "epoch-81  lr=['0.0010000'], tr/val_loss:  0.791787/  1.356481, val:  65.83%, val_best:  70.42%, tr:  85.70%, tr_best:  87.13%\n",
      "epoch-82  lr=['0.0010000'], tr/val_loss:  0.780600/  1.355493, val:  67.50%, val_best:  70.42%, tr:  87.13%, tr_best:  87.13%\n",
      "epoch-83  lr=['0.0010000'], tr/val_loss:  0.783068/  1.348840, val:  70.42%, val_best:  70.42%, tr:  89.17%, tr_best:  89.17%\n",
      "epoch-84  lr=['0.0010000'], tr/val_loss:  0.775147/  1.362694, val:  67.92%, val_best:  70.42%, tr:  89.17%, tr_best:  89.17%\n",
      "epoch-85  lr=['0.0010000'], tr/val_loss:  0.772074/  1.382532, val:  66.67%, val_best:  70.42%, tr:  89.07%, tr_best:  89.17%\n",
      "epoch-86  lr=['0.0010000'], tr/val_loss:  0.761540/  1.353581, val:  71.25%, val_best:  71.25%, tr:  86.93%, tr_best:  89.17%\n",
      "epoch-87  lr=['0.0010000'], tr/val_loss:  0.760388/  1.354806, val:  68.75%, val_best:  71.25%, tr:  89.68%, tr_best:  89.68%\n",
      "epoch-88  lr=['0.0010000'], tr/val_loss:  0.750785/  1.367211, val:  67.50%, val_best:  71.25%, tr:  89.38%, tr_best:  89.68%\n",
      "epoch-89  lr=['0.0010000'], tr/val_loss:  0.747085/  1.403151, val:  65.00%, val_best:  71.25%, tr:  88.76%, tr_best:  89.68%\n",
      "epoch-90  lr=['0.0010000'], tr/val_loss:  0.749522/  1.348405, val:  70.42%, val_best:  71.25%, tr:  88.46%, tr_best:  89.68%\n",
      "epoch-91  lr=['0.0010000'], tr/val_loss:  0.738451/  1.353116, val:  72.08%, val_best:  72.08%, tr:  89.17%, tr_best:  89.68%\n",
      "epoch-92  lr=['0.0010000'], tr/val_loss:  0.737961/  1.395453, val:  65.83%, val_best:  72.08%, tr:  88.66%, tr_best:  89.68%\n",
      "epoch-93  lr=['0.0010000'], tr/val_loss:  0.747235/  1.374128, val:  64.58%, val_best:  72.08%, tr:  87.74%, tr_best:  89.68%\n",
      "epoch-94  lr=['0.0010000'], tr/val_loss:  0.743427/  1.372280, val:  67.92%, val_best:  72.08%, tr:  88.25%, tr_best:  89.68%\n",
      "epoch-95  lr=['0.0010000'], tr/val_loss:  0.736625/  1.386616, val:  70.00%, val_best:  72.08%, tr:  89.48%, tr_best:  89.68%\n",
      "epoch-96  lr=['0.0010000'], tr/val_loss:  0.732772/  1.414046, val:  69.17%, val_best:  72.08%, tr:  90.09%, tr_best:  90.09%\n",
      "epoch-97  lr=['0.0010000'], tr/val_loss:  0.737089/  1.340491, val:  72.92%, val_best:  72.92%, tr:  86.62%, tr_best:  90.09%\n",
      "epoch-98  lr=['0.0010000'], tr/val_loss:  0.720904/  1.374116, val:  65.83%, val_best:  72.92%, tr:  89.58%, tr_best:  90.09%\n",
      "epoch-99  lr=['0.0010000'], tr/val_loss:  0.739165/  1.351306, val:  70.00%, val_best:  72.92%, tr:  88.25%, tr_best:  90.09%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d7b2d5d8ef1a4376bad34c7e85256887",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.006 MB of 0.006 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>iter_acc</td><td>▂▃▁▄▂▅▆▃▄▅▅▆▆▅▅▆▆▅▇▇▆▇▅▆▇█▇▇▇▅▆▇▅▆▆▇▆▇█▇</td></tr><tr><td>summary_val_acc</td><td>▁▄▅▆▆▆▆▆▆▆▆▇▆▆▆▇▇▇▇▇▇▆▇▇▇▇▇▇▇▆▇▇▇▇▇▇▇▇██</td></tr><tr><td>tr_acc</td><td>▁▃▄▅▅▅▆▆▆▆▆▆▆▇▆▇▇▇▇▇▇▇▇▇▇▇▇▇██▇█████████</td></tr><tr><td>tr_epoch_loss</td><td>█▇▆▅▄▄▄▃▃▃▃▃▃▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_acc_best</td><td>▁▄▅▆▆▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇█████████████</td></tr><tr><td>val_acc_now</td><td>▁▄▅▆▆▆▆▆▆▆▆▇▆▆▆▇▇▇▇▇▇▆▇▇▇▇▇▇▇▆▇▇▇▇▇▇▇▇██</td></tr><tr><td>val_loss</td><td>█▇▅▄▃▃▃▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▁▂▁▁▁▁▂▂▂▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>99</td></tr><tr><td>iter_acc</td><td>1.0</td></tr><tr><td>tr_acc</td><td>0.88253</td></tr><tr><td>tr_epoch_loss</td><td>0.73917</td></tr><tr><td>val_acc_best</td><td>0.72917</td></tr><tr><td>val_acc_now</td><td>0.7</td></tr><tr><td>val_loss</td><td>1.35131</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">brisk-sweep-201</strong> at: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/zccgh4bs' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/zccgh4bs</a><br/> View project at: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>/data2/bh_wandb/wandb/run-20250430_055226-zccgh4bs/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require(\"core\")`! See https://wandb.me/wandb-core for more information."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Sweep Agent: Waiting for job.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Job received.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: ml1omndf with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBATCH: 16\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBN_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBPTT_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tDFA_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tIMAGE_SIZE: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tOTTT_input_trace_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tTIME: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tUDA_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \talpha_uda: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbias: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcfg: ['M', 'M', 200, 200]\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tchaching_on: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tconvTrue_fcFalse: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdata_path: /data2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tddp_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdenoise_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdvs_clipping: 5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdvs_duration: 100000\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepoch_num: 100\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \texclude_class: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \textra_train_dataset: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlast_lif: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.001\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_sg_width: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_decay: 0.5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_init: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_reset: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_threshold: 0.75\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmerge_polarities: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmy_seed: 42\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnet_print: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_workers: 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer_what: SGD\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tpin_memory: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tpre_trained: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tpre_trained_path: net_save/save_now_net_weights_{unique_name}.pth\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \trate_coding: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tscheduler_name: no\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsingle_step: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsurrogate: hard_sigmoid\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_conv_kernel_size: 3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_conv_padding: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_conv_stride: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_trace_const1: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_trace_const2: 0.5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \ttdBN_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \ttrace_on: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \twhich_data: DVS_GESTURE_TONIC\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1f8842b6130d4bbdabc3ced989916817",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.011113726585689519, max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.19.10 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.17.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/data2/bh_wandb/wandb/run-20250430_055839-ml1omndf</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/ml1omndf' target=\"_blank\">legendary-sweep-203</a></strong> to <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/6pj3lh8j' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/6pj3lh8j</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/6pj3lh8j' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/6pj3lh8j</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/ml1omndf' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/ml1omndf</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'single_step' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'my_seed' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'TIME' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BATCH' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'IMAGE_SIZE' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'which_data' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'data_path' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'rate_coding' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_init' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_decay' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_threshold' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_reset' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_sg_width' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_conv_kernel_size' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_conv_stride' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_conv_padding' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_trace_const1' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_trace_const2' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'pre_trained' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'convTrue_fcFalse' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'cfg' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'net_print' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'pre_trained_path' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'learning_rate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'epoch_num' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'tdBN_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BN_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'surrogate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BPTT_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'optimizer_what' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'scheduler_name' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'ddp_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'dvs_clipping' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'dvs_duration' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'DFA_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'trace_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'OTTT_input_trace_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'exclude_class' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'merge_polarities' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'denoise_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'extra_train_dataset' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'num_workers' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'chaching_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'pin_memory' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'UDA_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'alpha_uda' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'bias' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'last_lif' was locked by 'sweep' (ignored update).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "param {'devices': '0', 'single_step': True, 'unique_name': 'main', 'my_seed': 42, 'TIME': 10, 'BATCH': 16, 'IMAGE_SIZE': 128, 'which_data': 'DVS_GESTURE_TONIC', 'data_path': '/data2', 'rate_coding': False, 'lif_layer_v_init': 0, 'lif_layer_v_decay': 0.5, 'lif_layer_v_threshold': 0.75, 'lif_layer_v_reset': 0, 'lif_layer_sg_width': 1, 'synapse_conv_kernel_size': 3, 'synapse_conv_stride': 1, 'synapse_conv_padding': 1, 'synapse_trace_const1': 1, 'synapse_trace_const2': 0.5, 'pre_trained': False, 'convTrue_fcFalse': False, 'cfg': ['M', 'M', 200, 200], 'net_print': True, 'pre_trained_path': 'net_save/save_now_net_weights_{unique_name}.pth', 'learning_rate': 0.001, 'epoch_num': 100, 'tdBN_on': False, 'BN_on': False, 'surrogate': 'hard_sigmoid', 'BPTT_on': False, 'optimizer_what': 'SGD', 'scheduler_name': 'no', 'ddp_on': False, 'dvs_clipping': 5, 'dvs_duration': 100000, 'DFA_on': False, 'trace_on': True, 'OTTT_input_trace_on': False, 'exclude_class': True, 'merge_polarities': False, 'denoise_on': False, 'extra_train_dataset': 0, 'num_workers': 2, 'chaching_on': True, 'pin_memory': True, 'UDA_on': False, 'alpha_uda': 1, 'bias': True, 'last_lif': False, 'current epoch': 0} \n",
      "\n",
      "dataset_hash = ffa516e60c3efd5e0208f72b4c36cb84\n",
      "cache path exists\n",
      "\n",
      "device ==> cuda\n",
      "\n",
      "DataParallel(\n",
      "  (module): REBORN_MY_SNN_FC(\n",
      "    (layers): REBORN_MY_Sequential(\n",
      "      (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (2): DimChanger_for_FC()\n",
      "      (3): SYNAPSE_FC(in_features=2048, out_features=200, TIME=10, bias=True, sstep=True)\n",
      "      (4): LIF_layer(v_init=0, v_decay=0.5, v_threshold=0.75, v_reset=0, sg_width=1, surrogate=hard_sigmoid, BPTT_on=False, trace_const1=1, trace_const2=0.5, TIME=10, sstep=True, trace_on=True)\n",
      "      (5): SYNAPSE_FC(in_features=200, out_features=200, TIME=10, bias=True, sstep=True)\n",
      "      (6): LIF_layer(v_init=0, v_decay=0.5, v_threshold=0.75, v_reset=0, sg_width=1, surrogate=hard_sigmoid, BPTT_on=False, trace_const1=1, trace_const2=0.5, TIME=10, sstep=True, trace_on=True)\n",
      "      (7): SYNAPSE_FC(in_features=200, out_features=10, TIME=10, bias=True, sstep=True)\n",
      "    )\n",
      "  )\n",
      ")\n",
      "\n",
      "========================================================\n",
      "Trainable parameters: 452,010\n",
      "========================================================\n",
      "\n",
      "epoch-0   lr=['0.0010000'], tr/val_loss:  2.305365/  2.302841, val:  10.00%, val_best:  10.00%, tr:   8.17%, tr_best:   8.17%\n",
      "epoch-1   lr=['0.0010000'], tr/val_loss:  2.304994/  2.302639, val:  10.00%, val_best:  10.00%, tr:   7.66%, tr_best:   8.17%\n",
      "epoch-2   lr=['0.0010000'], tr/val_loss:  2.305079/  2.302667, val:  10.00%, val_best:  10.00%, tr:   8.99%, tr_best:   8.99%\n",
      "epoch-3   lr=['0.0010000'], tr/val_loss:  2.304731/  2.302708, val:  10.00%, val_best:  10.00%, tr:   8.38%, tr_best:   8.99%\n",
      "epoch-4   lr=['0.0010000'], tr/val_loss:  2.304833/  2.302682, val:  10.00%, val_best:  10.00%, tr:   7.87%, tr_best:   8.99%\n",
      "epoch-5   lr=['0.0010000'], tr/val_loss:  2.304569/  2.302678, val:  10.00%, val_best:  10.00%, tr:   7.87%, tr_best:   8.99%\n",
      "epoch-6   lr=['0.0010000'], tr/val_loss:  2.305086/  2.302692, val:  10.42%, val_best:  10.42%, tr:   9.70%, tr_best:   9.70%\n",
      "epoch-7   lr=['0.0010000'], tr/val_loss:  2.304578/  2.302605, val:  10.83%, val_best:  10.83%, tr:   7.46%, tr_best:   9.70%\n",
      "epoch-8   lr=['0.0010000'], tr/val_loss:  2.303967/  2.301540, val:  10.00%, val_best:  10.83%, tr:   9.09%, tr_best:   9.70%\n",
      "epoch-9   lr=['0.0010000'], tr/val_loss:  2.299943/  2.294095, val:  12.50%, val_best:  12.50%, tr:   9.81%, tr_best:   9.81%\n",
      "epoch-10  lr=['0.0010000'], tr/val_loss:  2.270424/  2.260002, val:  15.42%, val_best:  15.42%, tr:  12.26%, tr_best:  12.26%\n",
      "epoch-11  lr=['0.0010000'], tr/val_loss:  2.202444/  2.209955, val:  25.42%, val_best:  25.42%, tr:  19.00%, tr_best:  19.00%\n",
      "epoch-12  lr=['0.0010000'], tr/val_loss:  2.115154/  2.117708, val:  32.50%, val_best:  32.50%, tr:  26.46%, tr_best:  26.46%\n",
      "epoch-13  lr=['0.0010000'], tr/val_loss:  1.988570/  2.001790, val:  33.33%, val_best:  33.33%, tr:  32.69%, tr_best:  32.69%\n",
      "epoch-14  lr=['0.0010000'], tr/val_loss:  1.845194/  1.865532, val:  44.17%, val_best:  44.17%, tr:  39.84%, tr_best:  39.84%\n",
      "epoch-15  lr=['0.0010000'], tr/val_loss:  1.686317/  1.738357, val:  48.75%, val_best:  48.75%, tr:  46.99%, tr_best:  46.99%\n",
      "epoch-16  lr=['0.0010000'], tr/val_loss:  1.564167/  1.642392, val:  46.67%, val_best:  48.75%, tr:  50.26%, tr_best:  50.26%\n",
      "epoch-17  lr=['0.0010000'], tr/val_loss:  1.482118/  1.578729, val:  49.17%, val_best:  49.17%, tr:  53.12%, tr_best:  53.12%\n",
      "epoch-18  lr=['0.0010000'], tr/val_loss:  1.406648/  1.541989, val:  51.25%, val_best:  51.25%, tr:  56.59%, tr_best:  56.59%\n",
      "epoch-19  lr=['0.0010000'], tr/val_loss:  1.370283/  1.505280, val:  50.00%, val_best:  51.25%, tr:  54.65%, tr_best:  56.59%\n",
      "epoch-20  lr=['0.0010000'], tr/val_loss:  1.323681/  1.479611, val:  56.25%, val_best:  56.25%, tr:  58.63%, tr_best:  58.63%\n",
      "epoch-21  lr=['0.0010000'], tr/val_loss:  1.289840/  1.454361, val:  55.00%, val_best:  56.25%, tr:  59.65%, tr_best:  59.65%\n",
      "epoch-22  lr=['0.0010000'], tr/val_loss:  1.270684/  1.447147, val:  54.17%, val_best:  56.25%, tr:  58.94%, tr_best:  59.65%\n",
      "epoch-23  lr=['0.0010000'], tr/val_loss:  1.235217/  1.434011, val:  56.67%, val_best:  56.67%, tr:  62.21%, tr_best:  62.21%\n",
      "epoch-24  lr=['0.0010000'], tr/val_loss:  1.211346/  1.437036, val:  54.58%, val_best:  56.67%, tr:  63.74%, tr_best:  63.74%\n",
      "epoch-25  lr=['0.0010000'], tr/val_loss:  1.185623/  1.405257, val:  59.58%, val_best:  59.58%, tr:  63.02%, tr_best:  63.74%\n",
      "epoch-26  lr=['0.0010000'], tr/val_loss:  1.168075/  1.376401, val:  60.42%, val_best:  60.42%, tr:  63.53%, tr_best:  63.74%\n",
      "epoch-27  lr=['0.0010000'], tr/val_loss:  1.142474/  1.395305, val:  56.67%, val_best:  60.42%, tr:  64.96%, tr_best:  64.96%\n",
      "epoch-28  lr=['0.0010000'], tr/val_loss:  1.134599/  1.368719, val:  60.00%, val_best:  60.42%, tr:  65.78%, tr_best:  65.78%\n",
      "epoch-29  lr=['0.0010000'], tr/val_loss:  1.100705/  1.381211, val:  59.58%, val_best:  60.42%, tr:  66.50%, tr_best:  66.50%\n",
      "epoch-30  lr=['0.0010000'], tr/val_loss:  1.091833/  1.395167, val:  57.50%, val_best:  60.42%, tr:  68.34%, tr_best:  68.34%\n",
      "epoch-31  lr=['0.0010000'], tr/val_loss:  1.069926/  1.378220, val:  60.83%, val_best:  60.83%, tr:  68.34%, tr_best:  68.34%\n",
      "epoch-32  lr=['0.0010000'], tr/val_loss:  1.060265/  1.398887, val:  60.00%, val_best:  60.83%, tr:  69.66%, tr_best:  69.66%\n",
      "epoch-33  lr=['0.0010000'], tr/val_loss:  1.053213/  1.394466, val:  60.00%, val_best:  60.83%, tr:  69.77%, tr_best:  69.77%\n",
      "epoch-34  lr=['0.0010000'], tr/val_loss:  1.043877/  1.374999, val:  60.83%, val_best:  60.83%, tr:  69.66%, tr_best:  69.77%\n",
      "epoch-35  lr=['0.0010000'], tr/val_loss:  1.019655/  1.424538, val:  60.42%, val_best:  60.83%, tr:  69.87%, tr_best:  69.87%\n",
      "epoch-36  lr=['0.0010000'], tr/val_loss:  1.006574/  1.415181, val:  60.00%, val_best:  60.83%, tr:  71.71%, tr_best:  71.71%\n",
      "epoch-37  lr=['0.0010000'], tr/val_loss:  1.000838/  1.398317, val:  62.50%, val_best:  62.50%, tr:  72.11%, tr_best:  72.11%\n",
      "epoch-38  lr=['0.0010000'], tr/val_loss:  0.993934/  1.407006, val:  66.25%, val_best:  66.25%, tr:  73.14%, tr_best:  73.14%\n",
      "epoch-39  lr=['0.0010000'], tr/val_loss:  0.979558/  1.404796, val:  62.08%, val_best:  66.25%, tr:  73.75%, tr_best:  73.75%\n",
      "epoch-40  lr=['0.0010000'], tr/val_loss:  0.959952/  1.431960, val:  62.92%, val_best:  66.25%, tr:  72.32%, tr_best:  73.75%\n",
      "epoch-41  lr=['0.0010000'], tr/val_loss:  0.963005/  1.462468, val:  61.25%, val_best:  66.25%, tr:  74.77%, tr_best:  74.77%\n",
      "epoch-42  lr=['0.0010000'], tr/val_loss:  0.940458/  1.437482, val:  63.33%, val_best:  66.25%, tr:  75.89%, tr_best:  75.89%\n",
      "epoch-43  lr=['0.0010000'], tr/val_loss:  0.939269/  1.454968, val:  62.92%, val_best:  66.25%, tr:  73.24%, tr_best:  75.89%\n",
      "epoch-44  lr=['0.0010000'], tr/val_loss:  0.914862/  1.465074, val:  65.42%, val_best:  66.25%, tr:  73.34%, tr_best:  75.89%\n",
      "epoch-45  lr=['0.0010000'], tr/val_loss:  0.905886/  1.450929, val:  66.67%, val_best:  66.67%, tr:  74.67%, tr_best:  75.89%\n",
      "epoch-46  lr=['0.0010000'], tr/val_loss:  0.894771/  1.499118, val:  64.17%, val_best:  66.67%, tr:  75.28%, tr_best:  75.89%\n",
      "epoch-47  lr=['0.0010000'], tr/val_loss:  0.886196/  1.515078, val:  63.75%, val_best:  66.67%, tr:  75.79%, tr_best:  75.89%\n",
      "epoch-48  lr=['0.0010000'], tr/val_loss:  0.872762/  1.501341, val:  64.58%, val_best:  66.67%, tr:  76.61%, tr_best:  76.61%\n",
      "epoch-49  lr=['0.0010000'], tr/val_loss:  0.878014/  1.542875, val:  65.83%, val_best:  66.67%, tr:  74.87%, tr_best:  76.61%\n",
      "epoch-50  lr=['0.0010000'], tr/val_loss:  0.853243/  1.540827, val:  65.42%, val_best:  66.67%, tr:  78.35%, tr_best:  78.35%\n",
      "epoch-51  lr=['0.0010000'], tr/val_loss:  0.843603/  1.565602, val:  67.08%, val_best:  67.08%, tr:  76.81%, tr_best:  78.35%\n",
      "epoch-52  lr=['0.0010000'], tr/val_loss:  0.855286/  1.568605, val:  63.75%, val_best:  67.08%, tr:  77.02%, tr_best:  78.35%\n",
      "epoch-53  lr=['0.0010000'], tr/val_loss:  0.841183/  1.595010, val:  65.00%, val_best:  67.08%, tr:  77.12%, tr_best:  78.35%\n",
      "epoch-54  lr=['0.0010000'], tr/val_loss:  0.838932/  1.574252, val:  64.17%, val_best:  67.08%, tr:  80.18%, tr_best:  80.18%\n",
      "epoch-55  lr=['0.0010000'], tr/val_loss:  0.824403/  1.600441, val:  70.00%, val_best:  70.00%, tr:  79.26%, tr_best:  80.18%\n",
      "epoch-56  lr=['0.0010000'], tr/val_loss:  0.808715/  1.626341, val:  67.08%, val_best:  70.00%, tr:  80.59%, tr_best:  80.59%\n",
      "epoch-57  lr=['0.0010000'], tr/val_loss:  0.799409/  1.624112, val:  68.33%, val_best:  70.00%, tr:  80.59%, tr_best:  80.59%\n",
      "epoch-58  lr=['0.0010000'], tr/val_loss:  0.792833/  1.674312, val:  66.67%, val_best:  70.00%, tr:  80.59%, tr_best:  80.59%\n",
      "epoch-59  lr=['0.0010000'], tr/val_loss:  0.785600/  1.672383, val:  68.75%, val_best:  70.00%, tr:  79.98%, tr_best:  80.59%\n",
      "epoch-60  lr=['0.0010000'], tr/val_loss:  0.770094/  1.675687, val:  65.42%, val_best:  70.00%, tr:  81.21%, tr_best:  81.21%\n",
      "epoch-61  lr=['0.0010000'], tr/val_loss:  0.771602/  1.721173, val:  67.08%, val_best:  70.00%, tr:  81.31%, tr_best:  81.31%\n",
      "epoch-62  lr=['0.0010000'], tr/val_loss:  0.757950/  1.751224, val:  65.42%, val_best:  70.00%, tr:  83.04%, tr_best:  83.04%\n",
      "epoch-63  lr=['0.0010000'], tr/val_loss:  0.756777/  1.732271, val:  69.17%, val_best:  70.00%, tr:  82.23%, tr_best:  83.04%\n",
      "epoch-64  lr=['0.0010000'], tr/val_loss:  0.736834/  1.822402, val:  67.92%, val_best:  70.00%, tr:  84.17%, tr_best:  84.17%\n",
      "epoch-65  lr=['0.0010000'], tr/val_loss:  0.734945/  1.845289, val:  62.50%, val_best:  70.00%, tr:  84.27%, tr_best:  84.27%\n",
      "epoch-66  lr=['0.0010000'], tr/val_loss:  0.731587/  1.859237, val:  69.17%, val_best:  70.00%, tr:  83.25%, tr_best:  84.27%\n",
      "epoch-67  lr=['0.0010000'], tr/val_loss:  0.732662/  1.866322, val:  65.42%, val_best:  70.00%, tr:  86.52%, tr_best:  86.52%\n",
      "epoch-68  lr=['0.0010000'], tr/val_loss:  0.732346/  1.837548, val:  70.00%, val_best:  70.00%, tr:  83.25%, tr_best:  86.52%\n",
      "epoch-69  lr=['0.0010000'], tr/val_loss:  0.710583/  1.923011, val:  67.50%, val_best:  70.00%, tr:  85.50%, tr_best:  86.52%\n",
      "epoch-70  lr=['0.0010000'], tr/val_loss:  0.710475/  1.889472, val:  72.50%, val_best:  72.50%, tr:  84.98%, tr_best:  86.52%\n",
      "epoch-71  lr=['0.0010000'], tr/val_loss:  0.685166/  1.911716, val:  64.58%, val_best:  72.50%, tr:  88.46%, tr_best:  88.46%\n",
      "epoch-72  lr=['0.0010000'], tr/val_loss:  0.679388/  2.030478, val:  68.33%, val_best:  72.50%, tr:  88.76%, tr_best:  88.76%\n",
      "epoch-73  lr=['0.0010000'], tr/val_loss:  0.695424/  2.074100, val:  65.42%, val_best:  72.50%, tr:  86.52%, tr_best:  88.76%\n",
      "epoch-74  lr=['0.0010000'], tr/val_loss:  0.675277/  2.046684, val:  67.92%, val_best:  72.50%, tr:  88.66%, tr_best:  88.76%\n",
      "epoch-75  lr=['0.0010000'], tr/val_loss:  0.663942/  2.077215, val:  67.92%, val_best:  72.50%, tr:  87.64%, tr_best:  88.76%\n",
      "epoch-76  lr=['0.0010000'], tr/val_loss:  0.659064/  2.136604, val:  68.75%, val_best:  72.50%, tr:  89.48%, tr_best:  89.48%\n",
      "epoch-77  lr=['0.0010000'], tr/val_loss:  0.671153/  2.165533, val:  69.17%, val_best:  72.50%, tr:  88.05%, tr_best:  89.48%\n",
      "epoch-78  lr=['0.0010000'], tr/val_loss:  0.661566/  2.157546, val:  68.33%, val_best:  72.50%, tr:  89.79%, tr_best:  89.79%\n",
      "epoch-79  lr=['0.0010000'], tr/val_loss:  0.635396/  2.201176, val:  70.00%, val_best:  72.50%, tr:  90.50%, tr_best:  90.50%\n",
      "epoch-80  lr=['0.0010000'], tr/val_loss:  0.630756/  2.288043, val:  66.67%, val_best:  72.50%, tr:  90.40%, tr_best:  90.50%\n",
      "epoch-81  lr=['0.0010000'], tr/val_loss:  0.644452/  2.277617, val:  65.00%, val_best:  72.50%, tr:  89.48%, tr_best:  90.50%\n",
      "epoch-82  lr=['0.0010000'], tr/val_loss:  0.628664/  2.329779, val:  70.42%, val_best:  72.50%, tr:  89.58%, tr_best:  90.50%\n",
      "epoch-83  lr=['0.0010000'], tr/val_loss:  0.619447/  2.315113, val:  67.50%, val_best:  72.50%, tr:  93.05%, tr_best:  93.05%\n",
      "epoch-84  lr=['0.0010000'], tr/val_loss:  0.619964/  2.368186, val:  65.00%, val_best:  72.50%, tr:  92.65%, tr_best:  93.05%\n",
      "epoch-85  lr=['0.0010000'], tr/val_loss:  0.618439/  2.424010, val:  66.25%, val_best:  72.50%, tr:  93.26%, tr_best:  93.26%\n",
      "epoch-86  lr=['0.0010000'], tr/val_loss:  0.607208/  2.394167, val:  65.42%, val_best:  72.50%, tr:  92.13%, tr_best:  93.26%\n",
      "epoch-87  lr=['0.0010000'], tr/val_loss:  0.593150/  2.555636, val:  67.08%, val_best:  72.50%, tr:  93.26%, tr_best:  93.26%\n",
      "epoch-88  lr=['0.0010000'], tr/val_loss:  0.564583/  2.449780, val:  71.67%, val_best:  72.50%, tr:  93.36%, tr_best:  93.36%\n",
      "epoch-89  lr=['0.0010000'], tr/val_loss:  0.572620/  2.539556, val:  68.75%, val_best:  72.50%, tr:  93.97%, tr_best:  93.97%\n",
      "epoch-90  lr=['0.0010000'], tr/val_loss:  0.584314/  2.534222, val:  67.92%, val_best:  72.50%, tr:  93.46%, tr_best:  93.97%\n",
      "epoch-91  lr=['0.0010000'], tr/val_loss:  0.567558/  2.627516, val:  64.17%, val_best:  72.50%, tr:  93.46%, tr_best:  93.97%\n",
      "epoch-92  lr=['0.0010000'], tr/val_loss:  0.591228/  2.707949, val:  66.67%, val_best:  72.50%, tr:  93.97%, tr_best:  93.97%\n",
      "epoch-93  lr=['0.0010000'], tr/val_loss:  0.569379/  2.652816, val:  65.83%, val_best:  72.50%, tr:  94.79%, tr_best:  94.79%\n",
      "epoch-94  lr=['0.0010000'], tr/val_loss:  0.554341/  2.676510, val:  67.50%, val_best:  72.50%, tr:  94.89%, tr_best:  94.89%\n",
      "epoch-95  lr=['0.0010000'], tr/val_loss:  0.548696/  2.687173, val:  67.92%, val_best:  72.50%, tr:  95.81%, tr_best:  95.81%\n",
      "epoch-96  lr=['0.0010000'], tr/val_loss:  0.561579/  2.771037, val:  64.17%, val_best:  72.50%, tr:  96.22%, tr_best:  96.22%\n",
      "epoch-97  lr=['0.0010000'], tr/val_loss:  0.553217/  2.814017, val:  65.83%, val_best:  72.50%, tr:  93.46%, tr_best:  96.22%\n",
      "epoch-98  lr=['0.0010000'], tr/val_loss:  0.536903/  2.882017, val:  63.33%, val_best:  72.50%, tr:  96.32%, tr_best:  96.32%\n",
      "epoch-99  lr=['0.0010000'], tr/val_loss:  0.548783/  2.811540, val:  64.17%, val_best:  72.50%, tr:  95.81%, tr_best:  96.32%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b1fabb477a1d411fbcdcae762c1b94fc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.006 MB of 0.006 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>iter_acc</td><td>▁▂▁▁▁▄▅▄▄▆▆▆▆▆▅▆▇▆█▆▆▇▅▆█▇█▇▇██▇▆███████</td></tr><tr><td>summary_val_acc</td><td>▁▁▁▁▁▄▅▅▅▆▆▇▇▇▇▇▇▇▇▇▇▇▇██▇▇▇██▇███▇▇█▇▇▇</td></tr><tr><td>tr_acc</td><td>▁▁▁▁▁▃▄▅▅▅▅▅▆▆▆▆▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇████████</td></tr><tr><td>tr_epoch_loss</td><td>█████▇▆▅▄▄▄▃▃▃▃▃▃▃▂▂▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_acc_best</td><td>▁▁▁▁▁▄▅▅▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇█████████████████</td></tr><tr><td>val_acc_now</td><td>▁▁▁▁▁▄▅▅▅▆▆▇▇▇▇▇▇▇▇▇▇▇▇██▇▇▇██▇███▇▇█▇▇▇</td></tr><tr><td>val_loss</td><td>▆▆▆▆▅▅▃▂▂▁▁▁▁▁▁▁▁▁▁▂▂▂▂▂▂▃▃▃▃▄▄▅▅▆▆▇▇▇▇█</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>99</td></tr><tr><td>iter_acc</td><td>1.0</td></tr><tr><td>tr_acc</td><td>0.95812</td></tr><tr><td>tr_epoch_loss</td><td>0.54878</td></tr><tr><td>val_acc_best</td><td>0.725</td></tr><tr><td>val_acc_now</td><td>0.64167</td></tr><tr><td>val_loss</td><td>2.81154</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">legendary-sweep-203</strong> at: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/ml1omndf' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/ml1omndf</a><br/> View project at: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>/data2/bh_wandb/wandb/run-20250430_055839-ml1omndf/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require(\"core\")`! See https://wandb.me/wandb-core for more information."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: z769swh7 with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBATCH: 16\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBN_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBPTT_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tDFA_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tIMAGE_SIZE: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tOTTT_input_trace_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tTIME: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tUDA_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \talpha_uda: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbias: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcfg: ['M', 'M', 200, 200]\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tchaching_on: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tconvTrue_fcFalse: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdata_path: /data2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tddp_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdenoise_on: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdvs_clipping: 5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdvs_duration: 100000\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepoch_num: 100\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \texclude_class: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \textra_train_dataset: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlast_lif: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.001\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_sg_width: 5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_decay: 0.5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_init: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_reset: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_threshold: 0.25\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmerge_polarities: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmy_seed: 42\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnet_print: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_workers: 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer_what: SGD\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tpin_memory: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tpre_trained: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tpre_trained_path: net_save/save_now_net_weights_{unique_name}.pth\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \trate_coding: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tscheduler_name: no\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsingle_step: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsurrogate: hard_sigmoid\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_conv_kernel_size: 3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_conv_padding: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_conv_stride: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_trace_const1: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_trace_const2: 0.5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \ttdBN_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \ttrace_on: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \twhich_data: DVS_GESTURE_TONIC\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.19.10 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.17.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/data2/bh_wandb/wandb/run-20250430_060434-z769swh7</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/z769swh7' target=\"_blank\">genial-sweep-205</a></strong> to <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/6pj3lh8j' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/6pj3lh8j</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/6pj3lh8j' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/6pj3lh8j</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/z769swh7' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/z769swh7</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'single_step' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'my_seed' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'TIME' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BATCH' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'IMAGE_SIZE' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'which_data' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'data_path' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'rate_coding' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_init' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_decay' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_threshold' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_reset' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_sg_width' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_conv_kernel_size' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_conv_stride' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_conv_padding' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_trace_const1' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_trace_const2' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'pre_trained' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'convTrue_fcFalse' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'cfg' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'net_print' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'pre_trained_path' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'learning_rate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'epoch_num' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'tdBN_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BN_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'surrogate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BPTT_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'optimizer_what' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'scheduler_name' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'ddp_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'dvs_clipping' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'dvs_duration' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'DFA_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'trace_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'OTTT_input_trace_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'exclude_class' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'merge_polarities' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'denoise_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'extra_train_dataset' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'num_workers' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'chaching_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'pin_memory' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'UDA_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'alpha_uda' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'bias' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'last_lif' was locked by 'sweep' (ignored update).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "param {'devices': '0', 'single_step': True, 'unique_name': 'main', 'my_seed': 42, 'TIME': 10, 'BATCH': 16, 'IMAGE_SIZE': 128, 'which_data': 'DVS_GESTURE_TONIC', 'data_path': '/data2', 'rate_coding': False, 'lif_layer_v_init': 0, 'lif_layer_v_decay': 0.5, 'lif_layer_v_threshold': 0.25, 'lif_layer_v_reset': 0, 'lif_layer_sg_width': 5, 'synapse_conv_kernel_size': 3, 'synapse_conv_stride': 1, 'synapse_conv_padding': 1, 'synapse_trace_const1': 1, 'synapse_trace_const2': 0.5, 'pre_trained': False, 'convTrue_fcFalse': False, 'cfg': ['M', 'M', 200, 200], 'net_print': True, 'pre_trained_path': 'net_save/save_now_net_weights_{unique_name}.pth', 'learning_rate': 0.001, 'epoch_num': 100, 'tdBN_on': False, 'BN_on': False, 'surrogate': 'hard_sigmoid', 'BPTT_on': False, 'optimizer_what': 'SGD', 'scheduler_name': 'no', 'ddp_on': False, 'dvs_clipping': 5, 'dvs_duration': 100000, 'DFA_on': False, 'trace_on': True, 'OTTT_input_trace_on': False, 'exclude_class': True, 'merge_polarities': False, 'denoise_on': True, 'extra_train_dataset': 0, 'num_workers': 2, 'chaching_on': True, 'pin_memory': True, 'UDA_on': False, 'alpha_uda': 1, 'bias': True, 'last_lif': False, 'current epoch': 0} \n",
      "\n",
      "dataset_hash = 63cc597115630ec173f3099200061e53\n",
      "cache path exists\n",
      "\n",
      "device ==> cuda\n",
      "\n",
      "DataParallel(\n",
      "  (module): REBORN_MY_SNN_FC(\n",
      "    (layers): REBORN_MY_Sequential(\n",
      "      (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (2): DimChanger_for_FC()\n",
      "      (3): SYNAPSE_FC(in_features=2048, out_features=200, TIME=10, bias=True, sstep=True)\n",
      "      (4): LIF_layer(v_init=0, v_decay=0.5, v_threshold=0.25, v_reset=0, sg_width=5, surrogate=hard_sigmoid, BPTT_on=False, trace_const1=1, trace_const2=0.5, TIME=10, sstep=True, trace_on=True)\n",
      "      (5): SYNAPSE_FC(in_features=200, out_features=200, TIME=10, bias=True, sstep=True)\n",
      "      (6): LIF_layer(v_init=0, v_decay=0.5, v_threshold=0.25, v_reset=0, sg_width=5, surrogate=hard_sigmoid, BPTT_on=False, trace_const1=1, trace_const2=0.5, TIME=10, sstep=True, trace_on=True)\n",
      "      (7): SYNAPSE_FC(in_features=200, out_features=10, TIME=10, bias=True, sstep=True)\n",
      "    )\n",
      "  )\n",
      ")\n",
      "\n",
      "========================================================\n",
      "Trainable parameters: 452,010\n",
      "========================================================\n",
      "\n",
      "epoch-0   lr=['0.0010000'], tr/val_loss:  2.068266/  1.700351, val:  48.75%, val_best:  48.75%, tr:  27.27%, tr_best:  27.27%\n",
      "epoch-1   lr=['0.0010000'], tr/val_loss:  1.392196/  1.467773, val:  55.00%, val_best:  55.00%, tr:  58.02%, tr_best:  58.02%\n",
      "epoch-2   lr=['0.0010000'], tr/val_loss:  1.172344/  1.382650, val:  57.08%, val_best:  57.08%, tr:  63.02%, tr_best:  63.02%\n",
      "epoch-3   lr=['0.0010000'], tr/val_loss:  0.999226/  1.400992, val:  61.25%, val_best:  61.25%, tr:  69.15%, tr_best:  69.15%\n",
      "epoch-4   lr=['0.0010000'], tr/val_loss:  0.899221/  1.353709, val:  59.17%, val_best:  61.25%, tr:  70.89%, tr_best:  70.89%\n",
      "epoch-5   lr=['0.0010000'], tr/val_loss:  0.862621/  1.280040, val:  62.50%, val_best:  62.50%, tr:  71.09%, tr_best:  71.09%\n",
      "epoch-6   lr=['0.0010000'], tr/val_loss:  0.786291/  1.199338, val:  64.58%, val_best:  64.58%, tr:  75.69%, tr_best:  75.69%\n",
      "epoch-7   lr=['0.0010000'], tr/val_loss:  0.715117/  1.244693, val:  67.50%, val_best:  67.50%, tr:  77.43%, tr_best:  77.43%\n",
      "epoch-8   lr=['0.0010000'], tr/val_loss:  0.677812/  1.296384, val:  62.08%, val_best:  67.50%, tr:  79.47%, tr_best:  79.47%\n",
      "epoch-9   lr=['0.0010000'], tr/val_loss:  0.610055/  1.290170, val:  70.83%, val_best:  70.83%, tr:  85.39%, tr_best:  85.39%\n",
      "epoch-10  lr=['0.0010000'], tr/val_loss:  0.582473/  1.348368, val:  66.67%, val_best:  70.83%, tr:  85.09%, tr_best:  85.39%\n",
      "epoch-11  lr=['0.0010000'], tr/val_loss:  0.570765/  1.334414, val:  70.83%, val_best:  70.83%, tr:  87.33%, tr_best:  87.33%\n",
      "epoch-12  lr=['0.0010000'], tr/val_loss:  0.511547/  1.245349, val:  75.00%, val_best:  75.00%, tr:  90.70%, tr_best:  90.70%\n",
      "epoch-13  lr=['0.0010000'], tr/val_loss:  0.485419/  1.332124, val:  72.92%, val_best:  75.00%, tr:  90.91%, tr_best:  90.91%\n",
      "epoch-14  lr=['0.0010000'], tr/val_loss:  0.426336/  1.632107, val:  71.67%, val_best:  75.00%, tr:  92.44%, tr_best:  92.44%\n",
      "epoch-15  lr=['0.0010000'], tr/val_loss:  0.404565/  1.469109, val:  70.83%, val_best:  75.00%, tr:  93.46%, tr_best:  93.46%\n",
      "epoch-16  lr=['0.0010000'], tr/val_loss:  0.352957/  1.483523, val:  72.08%, val_best:  75.00%, tr:  95.61%, tr_best:  95.61%\n",
      "epoch-17  lr=['0.0010000'], tr/val_loss:  0.322761/  1.645724, val:  72.08%, val_best:  75.00%, tr:  97.24%, tr_best:  97.24%\n",
      "epoch-18  lr=['0.0010000'], tr/val_loss:  0.309799/  1.544214, val:  73.75%, val_best:  75.00%, tr:  96.42%, tr_best:  97.24%\n",
      "epoch-19  lr=['0.0010000'], tr/val_loss:  0.270481/  1.695898, val:  70.00%, val_best:  75.00%, tr:  97.34%, tr_best:  97.34%\n",
      "epoch-20  lr=['0.0010000'], tr/val_loss:  0.246566/  1.816962, val:  70.00%, val_best:  75.00%, tr:  97.96%, tr_best:  97.96%\n",
      "epoch-21  lr=['0.0010000'], tr/val_loss:  0.244204/  1.802959, val:  75.00%, val_best:  75.00%, tr:  97.96%, tr_best:  97.96%\n",
      "epoch-22  lr=['0.0010000'], tr/val_loss:  0.208647/  1.781052, val:  73.33%, val_best:  75.00%, tr:  99.18%, tr_best:  99.18%\n",
      "epoch-23  lr=['0.0010000'], tr/val_loss:  0.188361/  1.955799, val:  72.50%, val_best:  75.00%, tr:  99.59%, tr_best:  99.59%\n",
      "epoch-24  lr=['0.0010000'], tr/val_loss:  0.171723/  1.987151, val:  69.58%, val_best:  75.00%, tr:  99.69%, tr_best:  99.69%\n",
      "epoch-25  lr=['0.0010000'], tr/val_loss:  0.161115/  1.978145, val:  73.75%, val_best:  75.00%, tr:  99.18%, tr_best:  99.69%\n",
      "epoch-26  lr=['0.0010000'], tr/val_loss:  0.150113/  1.947644, val:  75.42%, val_best:  75.42%, tr:  98.67%, tr_best:  99.69%\n",
      "epoch-27  lr=['0.0010000'], tr/val_loss:  0.134924/  1.953318, val:  74.17%, val_best:  75.42%, tr:  99.49%, tr_best:  99.69%\n",
      "epoch-28  lr=['0.0010000'], tr/val_loss:  0.100357/  2.061892, val:  77.50%, val_best:  77.50%, tr:  99.90%, tr_best:  99.90%\n",
      "epoch-29  lr=['0.0010000'], tr/val_loss:  0.114116/  2.081933, val:  74.17%, val_best:  77.50%, tr:  99.28%, tr_best:  99.90%\n",
      "epoch-30  lr=['0.0010000'], tr/val_loss:  0.084360/  2.199537, val:  75.00%, val_best:  77.50%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-31  lr=['0.0010000'], tr/val_loss:  0.074991/  2.213019, val:  76.25%, val_best:  77.50%, tr:  99.90%, tr_best: 100.00%\n",
      "epoch-32  lr=['0.0010000'], tr/val_loss:  0.093259/  2.233294, val:  75.42%, val_best:  77.50%, tr:  99.90%, tr_best: 100.00%\n",
      "epoch-33  lr=['0.0010000'], tr/val_loss:  0.152645/  2.246106, val:  76.25%, val_best:  77.50%, tr:  99.49%, tr_best: 100.00%\n",
      "epoch-34  lr=['0.0010000'], tr/val_loss:  0.117925/  2.305640, val:  72.50%, val_best:  77.50%, tr:  99.59%, tr_best: 100.00%\n",
      "epoch-35  lr=['0.0010000'], tr/val_loss:  0.088397/  2.321704, val:  73.33%, val_best:  77.50%, tr:  99.90%, tr_best: 100.00%\n",
      "epoch-36  lr=['0.0010000'], tr/val_loss:  0.068670/  2.333693, val:  73.33%, val_best:  77.50%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-37  lr=['0.0010000'], tr/val_loss:  0.056005/  2.402865, val:  73.75%, val_best:  77.50%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-38  lr=['0.0010000'], tr/val_loss:  0.046331/  2.396343, val:  75.00%, val_best:  77.50%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-39  lr=['0.0010000'], tr/val_loss:  0.038529/  2.393706, val:  76.25%, val_best:  77.50%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-40  lr=['0.0010000'], tr/val_loss:  0.044108/  2.424641, val:  75.00%, val_best:  77.50%, tr:  99.90%, tr_best: 100.00%\n",
      "epoch-41  lr=['0.0010000'], tr/val_loss:  0.038956/  2.452046, val:  76.25%, val_best:  77.50%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-42  lr=['0.0010000'], tr/val_loss:  0.030110/  2.447395, val:  75.42%, val_best:  77.50%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-43  lr=['0.0010000'], tr/val_loss:  0.029612/  2.475801, val:  75.42%, val_best:  77.50%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-44  lr=['0.0010000'], tr/val_loss:  0.022894/  2.504871, val:  76.67%, val_best:  77.50%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-45  lr=['0.0010000'], tr/val_loss:  0.019782/  2.505883, val:  74.58%, val_best:  77.50%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-46  lr=['0.0010000'], tr/val_loss:  0.017078/  2.554895, val:  75.42%, val_best:  77.50%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-47  lr=['0.0010000'], tr/val_loss:  0.020470/  2.601043, val:  76.67%, val_best:  77.50%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-48  lr=['0.0010000'], tr/val_loss:  0.020118/  2.651493, val:  74.58%, val_best:  77.50%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-49  lr=['0.0010000'], tr/val_loss:  0.016355/  2.590083, val:  76.67%, val_best:  77.50%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-50  lr=['0.0010000'], tr/val_loss:  0.013415/  2.606244, val:  75.83%, val_best:  77.50%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-51  lr=['0.0010000'], tr/val_loss:  0.014513/  2.644428, val:  74.58%, val_best:  77.50%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-52  lr=['0.0010000'], tr/val_loss:  0.012664/  2.627578, val:  74.58%, val_best:  77.50%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-53  lr=['0.0010000'], tr/val_loss:  0.010992/  2.645514, val:  75.42%, val_best:  77.50%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-54  lr=['0.0010000'], tr/val_loss:  0.011088/  2.668406, val:  77.08%, val_best:  77.50%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-55  lr=['0.0010000'], tr/val_loss:  0.018083/  2.643971, val:  74.58%, val_best:  77.50%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-56  lr=['0.0010000'], tr/val_loss:  0.013726/  2.659718, val:  76.67%, val_best:  77.50%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-57  lr=['0.0010000'], tr/val_loss:  0.012552/  2.760134, val:  75.83%, val_best:  77.50%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-58  lr=['0.0010000'], tr/val_loss:  0.012475/  2.710140, val:  76.67%, val_best:  77.50%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-59  lr=['0.0010000'], tr/val_loss:  0.011891/  2.748389, val:  76.25%, val_best:  77.50%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-60  lr=['0.0010000'], tr/val_loss:  0.010027/  2.773970, val:  78.75%, val_best:  78.75%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-61  lr=['0.0010000'], tr/val_loss:  0.009863/  2.739439, val:  76.67%, val_best:  78.75%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-62  lr=['0.0010000'], tr/val_loss:  0.008672/  2.805374, val:  76.25%, val_best:  78.75%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-63  lr=['0.0010000'], tr/val_loss:  0.008044/  2.793980, val:  77.08%, val_best:  78.75%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-64  lr=['0.0010000'], tr/val_loss:  0.008597/  2.852173, val:  76.67%, val_best:  78.75%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-65  lr=['0.0010000'], tr/val_loss:  0.007355/  2.863141, val:  75.83%, val_best:  78.75%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-66  lr=['0.0010000'], tr/val_loss:  0.006508/  2.877620, val:  76.25%, val_best:  78.75%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-67  lr=['0.0010000'], tr/val_loss:  0.008001/  2.814757, val:  76.67%, val_best:  78.75%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-68  lr=['0.0010000'], tr/val_loss:  0.007393/  2.832829, val:  77.08%, val_best:  78.75%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-69  lr=['0.0010000'], tr/val_loss:  0.006744/  2.866101, val:  77.92%, val_best:  78.75%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-70  lr=['0.0010000'], tr/val_loss:  0.004155/  2.866856, val:  78.33%, val_best:  78.75%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-71  lr=['0.0010000'], tr/val_loss:  0.005743/  2.880489, val:  77.08%, val_best:  78.75%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-72  lr=['0.0010000'], tr/val_loss:  0.008653/  2.881894, val:  77.50%, val_best:  78.75%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-73  lr=['0.0010000'], tr/val_loss:  0.004719/  2.934080, val:  76.25%, val_best:  78.75%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-74  lr=['0.0010000'], tr/val_loss:  0.006418/  2.894602, val:  77.08%, val_best:  78.75%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-75  lr=['0.0010000'], tr/val_loss:  0.006773/  2.924126, val:  77.92%, val_best:  78.75%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-76  lr=['0.0010000'], tr/val_loss:  0.006080/  2.984729, val:  76.25%, val_best:  78.75%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-77  lr=['0.0010000'], tr/val_loss:  0.006635/  2.905877, val:  77.92%, val_best:  78.75%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-78  lr=['0.0010000'], tr/val_loss:  0.004969/  2.887335, val:  78.75%, val_best:  78.75%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-79  lr=['0.0010000'], tr/val_loss:  0.007066/  2.953857, val:  74.58%, val_best:  78.75%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-80  lr=['0.0010000'], tr/val_loss:  0.005045/  2.943638, val:  77.50%, val_best:  78.75%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-81  lr=['0.0010000'], tr/val_loss:  0.004778/  2.979922, val:  75.42%, val_best:  78.75%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-82  lr=['0.0010000'], tr/val_loss:  0.004980/  2.956156, val:  76.25%, val_best:  78.75%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-83  lr=['0.0010000'], tr/val_loss:  0.007967/  3.002008, val:  75.00%, val_best:  78.75%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-84  lr=['0.0010000'], tr/val_loss:  0.005545/  3.000422, val:  74.58%, val_best:  78.75%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-85  lr=['0.0010000'], tr/val_loss:  0.005629/  2.977282, val:  75.00%, val_best:  78.75%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-86  lr=['0.0010000'], tr/val_loss:  0.018892/  2.970629, val:  75.83%, val_best:  78.75%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-87  lr=['0.0010000'], tr/val_loss:  0.013078/  3.009232, val:  74.58%, val_best:  78.75%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-88  lr=['0.0010000'], tr/val_loss:  0.010269/  3.006114, val:  76.25%, val_best:  78.75%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-89  lr=['0.0010000'], tr/val_loss:  0.007424/  3.001834, val:  77.50%, val_best:  78.75%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-90  lr=['0.0010000'], tr/val_loss:  0.014092/  3.040445, val:  75.00%, val_best:  78.75%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-91  lr=['0.0010000'], tr/val_loss:  0.012080/  3.051530, val:  78.33%, val_best:  78.75%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-92  lr=['0.0010000'], tr/val_loss:  0.005073/  3.020257, val:  76.25%, val_best:  78.75%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-93  lr=['0.0010000'], tr/val_loss:  0.008467/  3.072286, val:  75.83%, val_best:  78.75%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-94  lr=['0.0010000'], tr/val_loss:  0.004019/  3.068269, val:  75.83%, val_best:  78.75%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-95  lr=['0.0010000'], tr/val_loss:  0.004510/  3.077678, val:  76.25%, val_best:  78.75%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-96  lr=['0.0010000'], tr/val_loss:  0.011880/  3.202138, val:  72.50%, val_best:  78.75%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-97  lr=['0.0010000'], tr/val_loss:  0.019227/  3.077197, val:  77.50%, val_best:  78.75%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-98  lr=['0.0010000'], tr/val_loss:  0.011626/  3.052382, val:  77.08%, val_best:  78.75%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-99  lr=['0.0010000'], tr/val_loss:  0.018370/  3.152646, val:  75.00%, val_best:  78.75%, tr: 100.00%, tr_best: 100.00%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8db5f87290cd4c19b81918169ea35719",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.006 MB of 0.006 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>iter_acc</td><td>▁▇▅▅▅▇▇▇████████████████████████████████</td></tr><tr><td>summary_val_acc</td><td>▁▃▃▅▆▇▆▇▆▇▆▇▇▇▇▇█▇███▇█▇██▇█████▇█▇▇████</td></tr><tr><td>tr_acc</td><td>▁▄▅▆▇▇▇█████████████████████████████████</td></tr><tr><td>tr_epoch_loss</td><td>█▅▄▃▃▃▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_acc_best</td><td>▁▃▄▅▆▇▇▇▇▇▇▇████████████████████████████</td></tr><tr><td>val_acc_now</td><td>▁▃▃▅▆▇▆▇▆▇▆▇▇▇▇▇█▇███▇█▇██▇█████▇█▇▇████</td></tr><tr><td>val_loss</td><td>▃▂▁▁▁▁▂▃▃▃▄▄▄▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇▇▇▇▇████████</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>99</td></tr><tr><td>iter_acc</td><td>1.0</td></tr><tr><td>tr_acc</td><td>1.0</td></tr><tr><td>tr_epoch_loss</td><td>0.01837</td></tr><tr><td>val_acc_best</td><td>0.7875</td></tr><tr><td>val_acc_now</td><td>0.75</td></tr><tr><td>val_loss</td><td>3.15265</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">genial-sweep-205</strong> at: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/z769swh7' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/z769swh7</a><br/> View project at: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>/data2/bh_wandb/wandb/run-20250430_060434-z769swh7/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require(\"core\")`! See https://wandb.me/wandb-core for more information."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 5hud9myp with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBATCH: 16\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBN_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBPTT_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tDFA_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tIMAGE_SIZE: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tOTTT_input_trace_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tTIME: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tUDA_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \talpha_uda: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbias: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcfg: ['M', 'M', 200, 200]\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tchaching_on: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tconvTrue_fcFalse: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdata_path: /data2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tddp_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdenoise_on: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdvs_clipping: 5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdvs_duration: 100000\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepoch_num: 100\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \texclude_class: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \textra_train_dataset: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlast_lif: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.001\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_sg_width: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_decay: 0.5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_init: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_reset: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_threshold: 0.25\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmerge_polarities: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmy_seed: 42\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnet_print: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_workers: 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer_what: SGD\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tpin_memory: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tpre_trained: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tpre_trained_path: net_save/save_now_net_weights_{unique_name}.pth\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \trate_coding: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tscheduler_name: no\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsingle_step: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsurrogate: hard_sigmoid\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_conv_kernel_size: 3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_conv_padding: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_conv_stride: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_trace_const1: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_trace_const2: 0.5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \ttdBN_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \ttrace_on: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \twhich_data: DVS_GESTURE_TONIC\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.19.10 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.17.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/data2/bh_wandb/wandb/run-20250430_061031-5hud9myp</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/5hud9myp' target=\"_blank\">fluent-sweep-207</a></strong> to <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/6pj3lh8j' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/6pj3lh8j</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/6pj3lh8j' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/6pj3lh8j</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/5hud9myp' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/5hud9myp</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'single_step' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'my_seed' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'TIME' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BATCH' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'IMAGE_SIZE' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'which_data' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'data_path' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'rate_coding' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_init' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_decay' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_threshold' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_reset' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_sg_width' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_conv_kernel_size' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_conv_stride' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_conv_padding' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_trace_const1' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_trace_const2' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'pre_trained' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'convTrue_fcFalse' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'cfg' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'net_print' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'pre_trained_path' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'learning_rate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'epoch_num' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'tdBN_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BN_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'surrogate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BPTT_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'optimizer_what' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'scheduler_name' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'ddp_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'dvs_clipping' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'dvs_duration' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'DFA_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'trace_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'OTTT_input_trace_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'exclude_class' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'merge_polarities' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'denoise_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'extra_train_dataset' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'num_workers' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'chaching_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'pin_memory' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'UDA_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'alpha_uda' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'bias' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'last_lif' was locked by 'sweep' (ignored update).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "param {'devices': '0', 'single_step': True, 'unique_name': 'main', 'my_seed': 42, 'TIME': 10, 'BATCH': 16, 'IMAGE_SIZE': 128, 'which_data': 'DVS_GESTURE_TONIC', 'data_path': '/data2', 'rate_coding': False, 'lif_layer_v_init': 0, 'lif_layer_v_decay': 0.5, 'lif_layer_v_threshold': 0.25, 'lif_layer_v_reset': 0, 'lif_layer_sg_width': 1, 'synapse_conv_kernel_size': 3, 'synapse_conv_stride': 1, 'synapse_conv_padding': 1, 'synapse_trace_const1': 1, 'synapse_trace_const2': 0.5, 'pre_trained': False, 'convTrue_fcFalse': False, 'cfg': ['M', 'M', 200, 200], 'net_print': True, 'pre_trained_path': 'net_save/save_now_net_weights_{unique_name}.pth', 'learning_rate': 0.001, 'epoch_num': 100, 'tdBN_on': False, 'BN_on': False, 'surrogate': 'hard_sigmoid', 'BPTT_on': False, 'optimizer_what': 'SGD', 'scheduler_name': 'no', 'ddp_on': False, 'dvs_clipping': 5, 'dvs_duration': 100000, 'DFA_on': False, 'trace_on': True, 'OTTT_input_trace_on': False, 'exclude_class': True, 'merge_polarities': False, 'denoise_on': True, 'extra_train_dataset': 0, 'num_workers': 2, 'chaching_on': True, 'pin_memory': True, 'UDA_on': False, 'alpha_uda': 1, 'bias': True, 'last_lif': False, 'current epoch': 0} \n",
      "\n",
      "dataset_hash = 63cc597115630ec173f3099200061e53\n",
      "cache path exists\n",
      "\n",
      "device ==> cuda\n",
      "\n",
      "DataParallel(\n",
      "  (module): REBORN_MY_SNN_FC(\n",
      "    (layers): REBORN_MY_Sequential(\n",
      "      (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (2): DimChanger_for_FC()\n",
      "      (3): SYNAPSE_FC(in_features=2048, out_features=200, TIME=10, bias=True, sstep=True)\n",
      "      (4): LIF_layer(v_init=0, v_decay=0.5, v_threshold=0.25, v_reset=0, sg_width=1, surrogate=hard_sigmoid, BPTT_on=False, trace_const1=1, trace_const2=0.5, TIME=10, sstep=True, trace_on=True)\n",
      "      (5): SYNAPSE_FC(in_features=200, out_features=200, TIME=10, bias=True, sstep=True)\n",
      "      (6): LIF_layer(v_init=0, v_decay=0.5, v_threshold=0.25, v_reset=0, sg_width=1, surrogate=hard_sigmoid, BPTT_on=False, trace_const1=1, trace_const2=0.5, TIME=10, sstep=True, trace_on=True)\n",
      "      (7): SYNAPSE_FC(in_features=200, out_features=10, TIME=10, bias=True, sstep=True)\n",
      "    )\n",
      "  )\n",
      ")\n",
      "\n",
      "========================================================\n",
      "Trainable parameters: 452,010\n",
      "========================================================\n",
      "\n",
      "epoch-0   lr=['0.0010000'], tr/val_loss:  2.271144/  2.213912, val:  23.75%, val_best:  23.75%, tr:  13.69%, tr_best:  13.69%\n",
      "epoch-1   lr=['0.0010000'], tr/val_loss:  2.119504/  2.065082, val:  38.33%, val_best:  38.33%, tr:  27.89%, tr_best:  27.89%\n",
      "epoch-2   lr=['0.0010000'], tr/val_loss:  1.917099/  1.901326, val:  46.25%, val_best:  46.25%, tr:  40.86%, tr_best:  40.86%\n",
      "epoch-3   lr=['0.0010000'], tr/val_loss:  1.712377/  1.767536, val:  50.00%, val_best:  50.00%, tr:  48.93%, tr_best:  48.93%\n",
      "epoch-4   lr=['0.0010000'], tr/val_loss:  1.567230/  1.685006, val:  50.42%, val_best:  50.42%, tr:  54.34%, tr_best:  54.34%\n",
      "epoch-5   lr=['0.0010000'], tr/val_loss:  1.459769/  1.610650, val:  54.58%, val_best:  54.58%, tr:  56.59%, tr_best:  56.59%\n",
      "epoch-6   lr=['0.0010000'], tr/val_loss:  1.398363/  1.574295, val:  57.50%, val_best:  57.50%, tr:  60.47%, tr_best:  60.47%\n",
      "epoch-7   lr=['0.0010000'], tr/val_loss:  1.341755/  1.544551, val:  55.83%, val_best:  57.50%, tr:  60.67%, tr_best:  60.67%\n",
      "epoch-8   lr=['0.0010000'], tr/val_loss:  1.300183/  1.523292, val:  60.00%, val_best:  60.00%, tr:  61.08%, tr_best:  61.08%\n",
      "epoch-9   lr=['0.0010000'], tr/val_loss:  1.271581/  1.513263, val:  53.75%, val_best:  60.00%, tr:  64.15%, tr_best:  64.15%\n",
      "epoch-10  lr=['0.0010000'], tr/val_loss:  1.239508/  1.501374, val:  59.58%, val_best:  60.00%, tr:  63.74%, tr_best:  64.15%\n",
      "epoch-11  lr=['0.0010000'], tr/val_loss:  1.207462/  1.475154, val:  59.17%, val_best:  60.00%, tr:  64.96%, tr_best:  64.96%\n",
      "epoch-12  lr=['0.0010000'], tr/val_loss:  1.185769/  1.452586, val:  55.83%, val_best:  60.00%, tr:  66.91%, tr_best:  66.91%\n",
      "epoch-13  lr=['0.0010000'], tr/val_loss:  1.169933/  1.438281, val:  59.58%, val_best:  60.00%, tr:  66.80%, tr_best:  66.91%\n",
      "epoch-14  lr=['0.0010000'], tr/val_loss:  1.118432/  1.456435, val:  58.33%, val_best:  60.00%, tr:  68.44%, tr_best:  68.44%\n",
      "epoch-15  lr=['0.0010000'], tr/val_loss:  1.113631/  1.436250, val:  61.67%, val_best:  61.67%, tr:  69.15%, tr_best:  69.15%\n",
      "epoch-16  lr=['0.0010000'], tr/val_loss:  1.099342/  1.413429, val:  57.08%, val_best:  61.67%, tr:  69.66%, tr_best:  69.66%\n",
      "epoch-17  lr=['0.0010000'], tr/val_loss:  1.063788/  1.389606, val:  63.33%, val_best:  63.33%, tr:  73.95%, tr_best:  73.95%\n",
      "epoch-18  lr=['0.0010000'], tr/val_loss:  1.044016/  1.458339, val:  57.50%, val_best:  63.33%, tr:  73.44%, tr_best:  73.95%\n",
      "epoch-19  lr=['0.0010000'], tr/val_loss:  1.037125/  1.461781, val:  60.42%, val_best:  63.33%, tr:  70.17%, tr_best:  73.95%\n",
      "epoch-20  lr=['0.0010000'], tr/val_loss:  1.008587/  1.436370, val:  59.58%, val_best:  63.33%, tr:  75.59%, tr_best:  75.59%\n",
      "epoch-21  lr=['0.0010000'], tr/val_loss:  0.995020/  1.407226, val:  62.92%, val_best:  63.33%, tr:  76.40%, tr_best:  76.40%\n",
      "epoch-22  lr=['0.0010000'], tr/val_loss:  1.010781/  1.402310, val:  60.83%, val_best:  63.33%, tr:  72.63%, tr_best:  76.40%\n",
      "epoch-23  lr=['0.0010000'], tr/val_loss:  0.974947/  1.412822, val:  65.83%, val_best:  65.83%, tr:  77.12%, tr_best:  77.12%\n",
      "epoch-24  lr=['0.0010000'], tr/val_loss:  0.953457/  1.447899, val:  62.08%, val_best:  65.83%, tr:  78.14%, tr_best:  78.14%\n",
      "epoch-25  lr=['0.0010000'], tr/val_loss:  0.945204/  1.432182, val:  65.00%, val_best:  65.83%, tr:  78.75%, tr_best:  78.75%\n",
      "epoch-26  lr=['0.0010000'], tr/val_loss:  0.930286/  1.402901, val:  68.33%, val_best:  68.33%, tr:  77.73%, tr_best:  78.75%\n",
      "epoch-27  lr=['0.0010000'], tr/val_loss:  0.918623/  1.467899, val:  61.67%, val_best:  68.33%, tr:  80.29%, tr_best:  80.29%\n",
      "epoch-28  lr=['0.0010000'], tr/val_loss:  0.905570/  1.433413, val:  68.33%, val_best:  68.33%, tr:  79.98%, tr_best:  80.29%\n",
      "epoch-29  lr=['0.0010000'], tr/val_loss:  0.891169/  1.499568, val:  60.00%, val_best:  68.33%, tr:  81.61%, tr_best:  81.61%\n",
      "epoch-30  lr=['0.0010000'], tr/val_loss:  0.884161/  1.466674, val:  64.17%, val_best:  68.33%, tr:  82.02%, tr_best:  82.02%\n",
      "epoch-31  lr=['0.0010000'], tr/val_loss:  0.885212/  1.528810, val:  63.75%, val_best:  68.33%, tr:  78.96%, tr_best:  82.02%\n",
      "epoch-32  lr=['0.0010000'], tr/val_loss:  0.878800/  1.503499, val:  65.42%, val_best:  68.33%, tr:  80.59%, tr_best:  82.02%\n",
      "epoch-33  lr=['0.0010000'], tr/val_loss:  0.867940/  1.545360, val:  66.67%, val_best:  68.33%, tr:  83.04%, tr_best:  83.04%\n",
      "epoch-34  lr=['0.0010000'], tr/val_loss:  0.855133/  1.529981, val:  64.58%, val_best:  68.33%, tr:  82.74%, tr_best:  83.04%\n",
      "epoch-35  lr=['0.0010000'], tr/val_loss:  0.860671/  1.592199, val:  60.42%, val_best:  68.33%, tr:  82.12%, tr_best:  83.04%\n",
      "epoch-36  lr=['0.0010000'], tr/val_loss:  0.830630/  1.523988, val:  66.67%, val_best:  68.33%, tr:  83.76%, tr_best:  83.76%\n",
      "epoch-37  lr=['0.0010000'], tr/val_loss:  0.835012/  1.568986, val:  67.08%, val_best:  68.33%, tr:  85.90%, tr_best:  85.90%\n",
      "epoch-38  lr=['0.0010000'], tr/val_loss:  0.827137/  1.553537, val:  68.33%, val_best:  68.33%, tr:  86.31%, tr_best:  86.31%\n",
      "epoch-39  lr=['0.0010000'], tr/val_loss:  0.821829/  1.581612, val:  66.25%, val_best:  68.33%, tr:  85.80%, tr_best:  86.31%\n",
      "epoch-40  lr=['0.0010000'], tr/val_loss:  0.808516/  1.545291, val:  67.92%, val_best:  68.33%, tr:  85.50%, tr_best:  86.31%\n",
      "epoch-41  lr=['0.0010000'], tr/val_loss:  0.816658/  1.600840, val:  65.83%, val_best:  68.33%, tr:  87.44%, tr_best:  87.44%\n",
      "epoch-42  lr=['0.0010000'], tr/val_loss:  0.802062/  1.613271, val:  67.50%, val_best:  68.33%, tr:  87.23%, tr_best:  87.44%\n",
      "epoch-43  lr=['0.0010000'], tr/val_loss:  0.792263/  1.652269, val:  67.50%, val_best:  68.33%, tr:  86.93%, tr_best:  87.44%\n",
      "epoch-44  lr=['0.0010000'], tr/val_loss:  0.785542/  1.618566, val:  68.75%, val_best:  68.75%, tr:  87.23%, tr_best:  87.44%\n",
      "epoch-45  lr=['0.0010000'], tr/val_loss:  0.773058/  1.674953, val:  66.67%, val_best:  68.75%, tr:  88.15%, tr_best:  88.15%\n",
      "epoch-46  lr=['0.0010000'], tr/val_loss:  0.779096/  1.682626, val:  67.08%, val_best:  68.75%, tr:  88.76%, tr_best:  88.76%\n",
      "epoch-47  lr=['0.0010000'], tr/val_loss:  0.765017/  1.753861, val:  67.92%, val_best:  68.75%, tr:  87.84%, tr_best:  88.76%\n",
      "epoch-48  lr=['0.0010000'], tr/val_loss:  0.774353/  1.697718, val:  70.42%, val_best:  70.42%, tr:  90.09%, tr_best:  90.09%\n",
      "epoch-49  lr=['0.0010000'], tr/val_loss:  0.757714/  1.744035, val:  69.17%, val_best:  70.42%, tr:  89.48%, tr_best:  90.09%\n",
      "epoch-50  lr=['0.0010000'], tr/val_loss:  0.749776/  1.773715, val:  70.83%, val_best:  70.83%, tr:  89.99%, tr_best:  90.09%\n",
      "epoch-51  lr=['0.0010000'], tr/val_loss:  0.735386/  1.857619, val:  68.33%, val_best:  70.83%, tr:  89.48%, tr_best:  90.09%\n",
      "epoch-52  lr=['0.0010000'], tr/val_loss:  0.727392/  1.871766, val:  63.33%, val_best:  70.83%, tr:  91.11%, tr_best:  91.11%\n",
      "epoch-53  lr=['0.0010000'], tr/val_loss:  0.736892/  1.886971, val:  67.08%, val_best:  70.83%, tr:  91.22%, tr_best:  91.22%\n",
      "epoch-54  lr=['0.0010000'], tr/val_loss:  0.737400/  1.844973, val:  69.58%, val_best:  70.83%, tr:  90.60%, tr_best:  91.22%\n",
      "epoch-55  lr=['0.0010000'], tr/val_loss:  0.726919/  1.898565, val:  67.92%, val_best:  70.83%, tr:  90.60%, tr_best:  91.22%\n",
      "epoch-56  lr=['0.0010000'], tr/val_loss:  0.727255/  2.010104, val:  61.25%, val_best:  70.83%, tr:  90.60%, tr_best:  91.22%\n",
      "epoch-57  lr=['0.0010000'], tr/val_loss:  0.733125/  1.929105, val:  67.50%, val_best:  70.83%, tr:  90.30%, tr_best:  91.22%\n",
      "epoch-58  lr=['0.0010000'], tr/val_loss:  0.706081/  2.015479, val:  62.08%, val_best:  70.83%, tr:  90.50%, tr_best:  91.22%\n",
      "epoch-59  lr=['0.0010000'], tr/val_loss:  0.704463/  1.999632, val:  65.00%, val_best:  70.83%, tr:  91.83%, tr_best:  91.83%\n",
      "epoch-60  lr=['0.0010000'], tr/val_loss:  0.697379/  2.012823, val:  66.67%, val_best:  70.83%, tr:  92.54%, tr_best:  92.54%\n",
      "epoch-61  lr=['0.0010000'], tr/val_loss:  0.699366/  2.049498, val:  66.67%, val_best:  70.83%, tr:  93.16%, tr_best:  93.16%\n",
      "epoch-62  lr=['0.0010000'], tr/val_loss:  0.696666/  1.982021, val:  66.25%, val_best:  70.83%, tr:  91.62%, tr_best:  93.16%\n",
      "epoch-63  lr=['0.0010000'], tr/val_loss:  0.690303/  1.949631, val:  68.33%, val_best:  70.83%, tr:  93.16%, tr_best:  93.16%\n",
      "epoch-64  lr=['0.0010000'], tr/val_loss:  0.682222/  2.182542, val:  66.67%, val_best:  70.83%, tr:  93.16%, tr_best:  93.16%\n",
      "epoch-65  lr=['0.0010000'], tr/val_loss:  0.678254/  2.093792, val:  68.33%, val_best:  70.83%, tr:  93.26%, tr_best:  93.26%\n",
      "epoch-66  lr=['0.0010000'], tr/val_loss:  0.657245/  2.104634, val:  64.17%, val_best:  70.83%, tr:  94.28%, tr_best:  94.28%\n",
      "epoch-67  lr=['0.0010000'], tr/val_loss:  0.678574/  2.185186, val:  65.42%, val_best:  70.83%, tr:  93.46%, tr_best:  94.28%\n",
      "epoch-68  lr=['0.0010000'], tr/val_loss:  0.669829/  2.143760, val:  65.83%, val_best:  70.83%, tr:  93.77%, tr_best:  94.28%\n",
      "epoch-69  lr=['0.0010000'], tr/val_loss:  0.663757/  2.222388, val:  63.33%, val_best:  70.83%, tr:  93.46%, tr_best:  94.28%\n",
      "epoch-70  lr=['0.0010000'], tr/val_loss:  0.664197/  2.173170, val:  68.75%, val_best:  70.83%, tr:  93.67%, tr_best:  94.28%\n",
      "epoch-71  lr=['0.0010000'], tr/val_loss:  0.658573/  2.264093, val:  66.25%, val_best:  70.83%, tr:  94.08%, tr_best:  94.28%\n",
      "epoch-72  lr=['0.0010000'], tr/val_loss:  0.649531/  2.311089, val:  66.67%, val_best:  70.83%, tr:  94.28%, tr_best:  94.28%\n",
      "epoch-73  lr=['0.0010000'], tr/val_loss:  0.697815/  2.388317, val:  62.50%, val_best:  70.83%, tr:  93.46%, tr_best:  94.28%\n",
      "epoch-74  lr=['0.0010000'], tr/val_loss:  0.679183/  2.287027, val:  64.58%, val_best:  70.83%, tr:  93.77%, tr_best:  94.28%\n",
      "epoch-75  lr=['0.0010000'], tr/val_loss:  0.661421/  2.334292, val:  65.83%, val_best:  70.83%, tr:  93.56%, tr_best:  94.28%\n",
      "epoch-76  lr=['0.0010000'], tr/val_loss:  0.641969/  2.338767, val:  62.08%, val_best:  70.83%, tr:  94.99%, tr_best:  94.99%\n",
      "epoch-77  lr=['0.0010000'], tr/val_loss:  0.654468/  2.357919, val:  64.58%, val_best:  70.83%, tr:  93.87%, tr_best:  94.99%\n",
      "epoch-78  lr=['0.0010000'], tr/val_loss:  0.643049/  2.393985, val:  67.08%, val_best:  70.83%, tr:  93.46%, tr_best:  94.99%\n",
      "epoch-79  lr=['0.0010000'], tr/val_loss:  0.629749/  2.407182, val:  67.50%, val_best:  70.83%, tr:  93.77%, tr_best:  94.99%\n",
      "epoch-80  lr=['0.0010000'], tr/val_loss:  0.630240/  2.430224, val:  63.75%, val_best:  70.83%, tr:  94.69%, tr_best:  94.99%\n",
      "epoch-81  lr=['0.0010000'], tr/val_loss:  0.629139/  2.470051, val:  67.50%, val_best:  70.83%, tr:  95.40%, tr_best:  95.40%\n",
      "epoch-82  lr=['0.0010000'], tr/val_loss:  0.626601/  2.557223, val:  63.75%, val_best:  70.83%, tr:  94.08%, tr_best:  95.40%\n",
      "epoch-83  lr=['0.0010000'], tr/val_loss:  0.650782/  2.664475, val:  62.08%, val_best:  70.83%, tr:  94.08%, tr_best:  95.40%\n",
      "epoch-84  lr=['0.0010000'], tr/val_loss:  0.633163/  2.498292, val:  65.42%, val_best:  70.83%, tr:  96.42%, tr_best:  96.42%\n",
      "epoch-85  lr=['0.0010000'], tr/val_loss:  0.640605/  2.526422, val:  66.25%, val_best:  70.83%, tr:  95.10%, tr_best:  96.42%\n",
      "epoch-86  lr=['0.0010000'], tr/val_loss:  0.621260/  2.476778, val:  65.00%, val_best:  70.83%, tr:  94.48%, tr_best:  96.42%\n",
      "epoch-87  lr=['0.0010000'], tr/val_loss:  0.620244/  2.573562, val:  65.83%, val_best:  70.83%, tr:  95.51%, tr_best:  96.42%\n",
      "epoch-88  lr=['0.0010000'], tr/val_loss:  0.620359/  2.622973, val:  62.08%, val_best:  70.83%, tr:  95.81%, tr_best:  96.42%\n",
      "epoch-89  lr=['0.0010000'], tr/val_loss:  0.605548/  2.640956, val:  65.42%, val_best:  70.83%, tr:  96.32%, tr_best:  96.42%\n",
      "epoch-90  lr=['0.0010000'], tr/val_loss:  0.629322/  2.612954, val:  62.50%, val_best:  70.83%, tr:  95.30%, tr_best:  96.42%\n",
      "epoch-91  lr=['0.0010000'], tr/val_loss:  0.619542/  2.711474, val:  61.25%, val_best:  70.83%, tr:  94.89%, tr_best:  96.42%\n",
      "epoch-92  lr=['0.0010000'], tr/val_loss:  0.627735/  2.750376, val:  60.00%, val_best:  70.83%, tr:  95.40%, tr_best:  96.42%\n",
      "epoch-93  lr=['0.0010000'], tr/val_loss:  0.637624/  2.683571, val:  64.17%, val_best:  70.83%, tr:  94.99%, tr_best:  96.42%\n",
      "epoch-94  lr=['0.0010000'], tr/val_loss:  0.619945/  2.644697, val:  65.83%, val_best:  70.83%, tr:  96.12%, tr_best:  96.42%\n",
      "epoch-95  lr=['0.0010000'], tr/val_loss:  0.630613/  2.787121, val:  66.25%, val_best:  70.83%, tr:  94.89%, tr_best:  96.42%\n",
      "epoch-96  lr=['0.0010000'], tr/val_loss:  0.599588/  2.837799, val:  59.17%, val_best:  70.83%, tr:  96.22%, tr_best:  96.42%\n",
      "epoch-97  lr=['0.0010000'], tr/val_loss:  0.616224/  2.720553, val:  66.25%, val_best:  70.83%, tr:  94.89%, tr_best:  96.42%\n",
      "epoch-98  lr=['0.0010000'], tr/val_loss:  0.590106/  2.774406, val:  64.58%, val_best:  70.83%, tr:  96.63%, tr_best:  96.63%\n",
      "epoch-99  lr=['0.0010000'], tr/val_loss:  0.609097/  2.823443, val:  62.92%, val_best:  70.83%, tr:  96.12%, tr_best:  96.63%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eed1e9133dc442949806dbd18a62d233",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.006 MB of 0.006 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>iter_acc</td><td>▂▄▁▃▁▄▆▂▄▅▅▇▄▆▆▇▇▆█▇▇█▆▇█▇▇██▇█▇▅█▇▇▇▇██</td></tr><tr><td>summary_val_acc</td><td>▁▄▅▆▆▆▆▇▇▇▇█▇▇▇█▇████▇██▇██▇██▇▇█▇▇▇▇▇▇▇</td></tr><tr><td>tr_acc</td><td>▁▃▄▅▅▆▆▆▆▆▆▆▇▇▇▇▇▇▇▇▇██▇████████████████</td></tr><tr><td>tr_epoch_loss</td><td>█▇▅▄▄▃▃▃▃▃▂▂▂▂▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_acc_best</td><td>▁▄▅▆▆▆▆▇▇▇▇█████████████████████████████</td></tr><tr><td>val_acc_now</td><td>▁▄▅▆▆▆▆▇▇▇▇█▇▇▇█▇████▇██▇██▇██▇▇█▇▇▇▇▇▇▇</td></tr><tr><td>val_loss</td><td>▅▄▂▂▂▁▁▁▁▁▁▁▂▂▂▂▂▂▂▃▃▃▃▄▄▄▅▅▅▆▆▆▆▇▇▇▇███</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>99</td></tr><tr><td>iter_acc</td><td>1.0</td></tr><tr><td>tr_acc</td><td>0.96118</td></tr><tr><td>tr_epoch_loss</td><td>0.6091</td></tr><tr><td>val_acc_best</td><td>0.70833</td></tr><tr><td>val_acc_now</td><td>0.62917</td></tr><tr><td>val_loss</td><td>2.82344</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">fluent-sweep-207</strong> at: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/5hud9myp' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/5hud9myp</a><br/> View project at: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>/data2/bh_wandb/wandb/run-20250430_061031-5hud9myp/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require(\"core\")`! See https://wandb.me/wandb-core for more information."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: y0eroj7y with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBATCH: 16\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBN_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBPTT_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tDFA_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tIMAGE_SIZE: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tOTTT_input_trace_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tTIME: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tUDA_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \talpha_uda: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbias: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcfg: ['M', 'M', 200, 200]\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tchaching_on: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tconvTrue_fcFalse: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdata_path: /data2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tddp_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdenoise_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdvs_clipping: 5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdvs_duration: 100000\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepoch_num: 100\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \texclude_class: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \textra_train_dataset: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlast_lif: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.01\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_sg_width: 3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_decay: 0.5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_init: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_reset: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_threshold: 0.5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmerge_polarities: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmy_seed: 42\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnet_print: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_workers: 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer_what: SGD\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tpin_memory: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tpre_trained: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tpre_trained_path: net_save/save_now_net_weights_{unique_name}.pth\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \trate_coding: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tscheduler_name: no\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsingle_step: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsurrogate: hard_sigmoid\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_conv_kernel_size: 3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_conv_padding: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_conv_stride: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_trace_const1: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_trace_const2: 0.5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \ttdBN_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \ttrace_on: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \twhich_data: DVS_GESTURE_TONIC\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.19.10 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.17.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/data2/bh_wandb/wandb/run-20250430_061621-y0eroj7y</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/y0eroj7y' target=\"_blank\">comfy-sweep-209</a></strong> to <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/6pj3lh8j' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/6pj3lh8j</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/6pj3lh8j' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/6pj3lh8j</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/y0eroj7y' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/y0eroj7y</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'single_step' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'my_seed' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'TIME' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BATCH' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'IMAGE_SIZE' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'which_data' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'data_path' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'rate_coding' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_init' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_decay' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_threshold' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_reset' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_sg_width' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_conv_kernel_size' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_conv_stride' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_conv_padding' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_trace_const1' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_trace_const2' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'pre_trained' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'convTrue_fcFalse' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'cfg' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'net_print' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'pre_trained_path' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'learning_rate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'epoch_num' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'tdBN_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BN_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'surrogate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BPTT_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'optimizer_what' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'scheduler_name' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'ddp_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'dvs_clipping' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'dvs_duration' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'DFA_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'trace_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'OTTT_input_trace_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'exclude_class' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'merge_polarities' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'denoise_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'extra_train_dataset' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'num_workers' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'chaching_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'pin_memory' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'UDA_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'alpha_uda' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'bias' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'last_lif' was locked by 'sweep' (ignored update).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "param {'devices': '0', 'single_step': True, 'unique_name': 'main', 'my_seed': 42, 'TIME': 10, 'BATCH': 16, 'IMAGE_SIZE': 128, 'which_data': 'DVS_GESTURE_TONIC', 'data_path': '/data2', 'rate_coding': False, 'lif_layer_v_init': 0, 'lif_layer_v_decay': 0.5, 'lif_layer_v_threshold': 0.5, 'lif_layer_v_reset': 0, 'lif_layer_sg_width': 3, 'synapse_conv_kernel_size': 3, 'synapse_conv_stride': 1, 'synapse_conv_padding': 1, 'synapse_trace_const1': 1, 'synapse_trace_const2': 0.5, 'pre_trained': False, 'convTrue_fcFalse': False, 'cfg': ['M', 'M', 200, 200], 'net_print': True, 'pre_trained_path': 'net_save/save_now_net_weights_{unique_name}.pth', 'learning_rate': 0.01, 'epoch_num': 100, 'tdBN_on': False, 'BN_on': False, 'surrogate': 'hard_sigmoid', 'BPTT_on': False, 'optimizer_what': 'SGD', 'scheduler_name': 'no', 'ddp_on': False, 'dvs_clipping': 5, 'dvs_duration': 100000, 'DFA_on': False, 'trace_on': True, 'OTTT_input_trace_on': False, 'exclude_class': True, 'merge_polarities': False, 'denoise_on': False, 'extra_train_dataset': 0, 'num_workers': 2, 'chaching_on': True, 'pin_memory': True, 'UDA_on': False, 'alpha_uda': 1, 'bias': True, 'last_lif': False, 'current epoch': 0} \n",
      "\n",
      "dataset_hash = ffa516e60c3efd5e0208f72b4c36cb84\n",
      "cache path exists\n",
      "\n",
      "device ==> cuda\n",
      "\n",
      "DataParallel(\n",
      "  (module): REBORN_MY_SNN_FC(\n",
      "    (layers): REBORN_MY_Sequential(\n",
      "      (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (2): DimChanger_for_FC()\n",
      "      (3): SYNAPSE_FC(in_features=2048, out_features=200, TIME=10, bias=True, sstep=True)\n",
      "      (4): LIF_layer(v_init=0, v_decay=0.5, v_threshold=0.5, v_reset=0, sg_width=3, surrogate=hard_sigmoid, BPTT_on=False, trace_const1=1, trace_const2=0.5, TIME=10, sstep=True, trace_on=True)\n",
      "      (5): SYNAPSE_FC(in_features=200, out_features=200, TIME=10, bias=True, sstep=True)\n",
      "      (6): LIF_layer(v_init=0, v_decay=0.5, v_threshold=0.5, v_reset=0, sg_width=3, surrogate=hard_sigmoid, BPTT_on=False, trace_const1=1, trace_const2=0.5, TIME=10, sstep=True, trace_on=True)\n",
      "      (7): SYNAPSE_FC(in_features=200, out_features=10, TIME=10, bias=True, sstep=True)\n",
      "    )\n",
      "  )\n",
      ")\n",
      "\n",
      "========================================================\n",
      "Trainable parameters: 452,010\n",
      "========================================================\n",
      "\n",
      "epoch-0   lr=['0.0100000'], tr/val_loss:  1.947583/  1.611433, val:  45.42%, val_best:  45.42%, tr:  30.44%, tr_best:  30.44%\n",
      "epoch-1   lr=['0.0100000'], tr/val_loss:  1.311774/  1.463763, val:  53.33%, val_best:  53.33%, tr:  53.12%, tr_best:  53.12%\n",
      "epoch-2   lr=['0.0100000'], tr/val_loss:  1.056788/  1.392542, val:  55.42%, val_best:  55.42%, tr:  62.21%, tr_best:  62.21%\n",
      "epoch-3   lr=['0.0100000'], tr/val_loss:  0.864173/  1.355584, val:  59.58%, val_best:  59.58%, tr:  70.99%, tr_best:  70.99%\n",
      "epoch-4   lr=['0.0100000'], tr/val_loss:  0.837176/  1.523733, val:  63.75%, val_best:  63.75%, tr:  70.79%, tr_best:  70.99%\n",
      "epoch-5   lr=['0.0100000'], tr/val_loss:  0.706775/  1.363721, val:  61.25%, val_best:  63.75%, tr:  74.67%, tr_best:  74.67%\n",
      "epoch-6   lr=['0.0100000'], tr/val_loss:  0.634133/  1.518275, val:  59.58%, val_best:  63.75%, tr:  77.43%, tr_best:  77.43%\n",
      "epoch-7   lr=['0.0100000'], tr/val_loss:  0.600084/  1.513945, val:  64.58%, val_best:  64.58%, tr:  80.18%, tr_best:  80.18%\n",
      "epoch-8   lr=['0.0100000'], tr/val_loss:  0.504726/  1.545624, val:  62.92%, val_best:  64.58%, tr:  83.45%, tr_best:  83.45%\n",
      "epoch-9   lr=['0.0100000'], tr/val_loss:  0.483532/  1.643956, val:  70.42%, val_best:  70.42%, tr:  86.72%, tr_best:  86.72%\n",
      "epoch-10  lr=['0.0100000'], tr/val_loss:  0.531862/  1.569299, val:  70.42%, val_best:  70.42%, tr:  85.90%, tr_best:  86.72%\n",
      "epoch-11  lr=['0.0100000'], tr/val_loss:  0.489128/  1.776087, val:  69.58%, val_best:  70.42%, tr:  87.54%, tr_best:  87.54%\n",
      "epoch-12  lr=['0.0100000'], tr/val_loss:  0.407808/  1.626505, val:  71.25%, val_best:  71.25%, tr:  90.40%, tr_best:  90.40%\n",
      "epoch-13  lr=['0.0100000'], tr/val_loss:  0.325134/  1.804552, val:  69.17%, val_best:  71.25%, tr:  91.42%, tr_best:  91.42%\n",
      "epoch-14  lr=['0.0100000'], tr/val_loss:  0.277222/  2.325161, val:  71.25%, val_best:  71.25%, tr:  93.87%, tr_best:  93.87%\n",
      "epoch-15  lr=['0.0100000'], tr/val_loss:  0.275332/  2.167478, val:  70.83%, val_best:  71.25%, tr:  96.94%, tr_best:  96.94%\n",
      "epoch-16  lr=['0.0100000'], tr/val_loss:  0.267590/  2.062378, val:  73.33%, val_best:  73.33%, tr:  96.42%, tr_best:  96.94%\n",
      "epoch-17  lr=['0.0100000'], tr/val_loss:  0.231266/  2.029062, val:  72.92%, val_best:  73.33%, tr:  97.65%, tr_best:  97.65%\n",
      "epoch-18  lr=['0.0100000'], tr/val_loss:  0.214876/  2.100786, val:  75.00%, val_best:  75.00%, tr:  96.94%, tr_best:  97.65%\n",
      "epoch-19  lr=['0.0100000'], tr/val_loss:  0.247384/  2.592422, val:  70.83%, val_best:  75.00%, tr:  98.16%, tr_best:  98.16%\n",
      "epoch-20  lr=['0.0100000'], tr/val_loss:  0.166996/  2.435597, val:  73.33%, val_best:  75.00%, tr:  99.18%, tr_best:  99.18%\n",
      "epoch-21  lr=['0.0100000'], tr/val_loss:  0.213424/  2.609054, val:  68.33%, val_best:  75.00%, tr:  98.26%, tr_best:  99.18%\n",
      "epoch-22  lr=['0.0100000'], tr/val_loss:  0.181729/  2.352847, val:  78.75%, val_best:  78.75%, tr:  98.47%, tr_best:  99.18%\n",
      "epoch-23  lr=['0.0100000'], tr/val_loss:  0.125655/  2.421187, val:  77.08%, val_best:  78.75%, tr:  99.39%, tr_best:  99.39%\n",
      "epoch-24  lr=['0.0100000'], tr/val_loss:  0.118477/  2.640837, val:  75.42%, val_best:  78.75%, tr:  99.28%, tr_best:  99.39%\n",
      "epoch-25  lr=['0.0100000'], tr/val_loss:  0.079190/  2.425645, val:  79.17%, val_best:  79.17%, tr:  99.80%, tr_best:  99.80%\n",
      "epoch-26  lr=['0.0100000'], tr/val_loss:  0.066681/  2.791831, val:  75.00%, val_best:  79.17%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-27  lr=['0.0100000'], tr/val_loss:  0.040600/  2.859900, val:  79.17%, val_best:  79.17%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-28  lr=['0.0100000'], tr/val_loss:  0.090807/  2.991354, val:  72.50%, val_best:  79.17%, tr:  99.59%, tr_best: 100.00%\n",
      "epoch-29  lr=['0.0100000'], tr/val_loss:  0.154037/  2.862586, val:  70.83%, val_best:  79.17%, tr:  99.49%, tr_best: 100.00%\n",
      "epoch-30  lr=['0.0100000'], tr/val_loss:  0.104725/  3.094624, val:  76.25%, val_best:  79.17%, tr:  99.80%, tr_best: 100.00%\n",
      "epoch-31  lr=['0.0100000'], tr/val_loss:  0.098938/  2.925593, val:  77.08%, val_best:  79.17%, tr:  99.90%, tr_best: 100.00%\n",
      "epoch-32  lr=['0.0100000'], tr/val_loss:  0.087627/  2.819882, val:  75.83%, val_best:  79.17%, tr:  99.59%, tr_best: 100.00%\n",
      "epoch-33  lr=['0.0100000'], tr/val_loss:  0.140324/  2.773813, val:  76.67%, val_best:  79.17%, tr:  99.28%, tr_best: 100.00%\n",
      "epoch-34  lr=['0.0100000'], tr/val_loss:  0.118798/  3.030248, val:  72.50%, val_best:  79.17%, tr:  99.39%, tr_best: 100.00%\n",
      "epoch-35  lr=['0.0100000'], tr/val_loss:  0.068394/  3.184928, val:  74.58%, val_best:  79.17%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-36  lr=['0.0100000'], tr/val_loss:  0.046325/  3.240652, val:  75.83%, val_best:  79.17%, tr:  99.90%, tr_best: 100.00%\n",
      "epoch-37  lr=['0.0100000'], tr/val_loss:  0.029800/  3.448691, val:  75.42%, val_best:  79.17%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-38  lr=['0.0100000'], tr/val_loss:  0.047896/  3.351423, val:  75.42%, val_best:  79.17%, tr:  99.90%, tr_best: 100.00%\n",
      "epoch-39  lr=['0.0100000'], tr/val_loss:  0.120162/  3.438547, val:  72.08%, val_best:  79.17%, tr:  99.18%, tr_best: 100.00%\n",
      "epoch-40  lr=['0.0100000'], tr/val_loss:  0.130084/  3.458283, val:  72.50%, val_best:  79.17%, tr:  99.49%, tr_best: 100.00%\n",
      "epoch-41  lr=['0.0100000'], tr/val_loss:  0.173429/  3.248468, val:  75.42%, val_best:  79.17%, tr:  98.98%, tr_best: 100.00%\n",
      "epoch-42  lr=['0.0100000'], tr/val_loss:  0.071784/  3.135494, val:  77.50%, val_best:  79.17%, tr:  99.90%, tr_best: 100.00%\n",
      "epoch-43  lr=['0.0100000'], tr/val_loss:  0.103435/  3.385356, val:  76.67%, val_best:  79.17%, tr:  99.28%, tr_best: 100.00%\n",
      "epoch-44  lr=['0.0100000'], tr/val_loss:  0.061153/  3.427056, val:  76.67%, val_best:  79.17%, tr:  99.90%, tr_best: 100.00%\n",
      "epoch-45  lr=['0.0100000'], tr/val_loss:  0.042151/  3.528187, val:  77.08%, val_best:  79.17%, tr:  99.90%, tr_best: 100.00%\n",
      "epoch-46  lr=['0.0100000'], tr/val_loss:  0.048832/  3.640409, val:  75.42%, val_best:  79.17%, tr:  99.80%, tr_best: 100.00%\n",
      "epoch-47  lr=['0.0100000'], tr/val_loss:  0.065043/  3.606627, val:  76.67%, val_best:  79.17%, tr:  99.69%, tr_best: 100.00%\n",
      "epoch-48  lr=['0.0100000'], tr/val_loss:  0.040423/  3.623008, val:  75.42%, val_best:  79.17%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-49  lr=['0.0100000'], tr/val_loss:  0.040935/  3.735484, val:  75.00%, val_best:  79.17%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-50  lr=['0.0100000'], tr/val_loss:  0.066944/  3.677696, val:  76.67%, val_best:  79.17%, tr:  99.69%, tr_best: 100.00%\n",
      "epoch-51  lr=['0.0100000'], tr/val_loss:  0.043713/  3.568613, val:  74.17%, val_best:  79.17%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-52  lr=['0.0100000'], tr/val_loss:  0.043661/  3.573176, val:  76.67%, val_best:  79.17%, tr:  99.80%, tr_best: 100.00%\n",
      "epoch-53  lr=['0.0100000'], tr/val_loss:  0.080013/  3.528712, val:  74.58%, val_best:  79.17%, tr:  99.90%, tr_best: 100.00%\n",
      "epoch-54  lr=['0.0100000'], tr/val_loss:  0.036262/  3.500246, val:  78.75%, val_best:  79.17%, tr:  99.90%, tr_best: 100.00%\n",
      "epoch-55  lr=['0.0100000'], tr/val_loss:  0.024568/  3.660307, val:  76.25%, val_best:  79.17%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-56  lr=['0.0100000'], tr/val_loss:  0.019806/  3.697827, val:  77.50%, val_best:  79.17%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-57  lr=['0.0100000'], tr/val_loss:  0.041029/  4.037681, val:  75.42%, val_best:  79.17%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-58  lr=['0.0100000'], tr/val_loss:  0.077415/  3.735623, val:  75.83%, val_best:  79.17%, tr:  99.59%, tr_best: 100.00%\n",
      "epoch-59  lr=['0.0100000'], tr/val_loss:  0.041748/  3.866682, val:  73.75%, val_best:  79.17%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-60  lr=['0.0100000'], tr/val_loss:  0.068689/  3.739866, val:  77.50%, val_best:  79.17%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-61  lr=['0.0100000'], tr/val_loss:  0.078993/  4.339666, val:  72.50%, val_best:  79.17%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-62  lr=['0.0100000'], tr/val_loss:  0.057526/  3.744812, val:  77.50%, val_best:  79.17%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-63  lr=['0.0100000'], tr/val_loss:  0.060221/  3.780684, val:  79.58%, val_best:  79.58%, tr:  99.90%, tr_best: 100.00%\n",
      "epoch-64  lr=['0.0100000'], tr/val_loss:  0.074748/  3.953532, val:  75.42%, val_best:  79.58%, tr:  99.90%, tr_best: 100.00%\n",
      "epoch-65  lr=['0.0100000'], tr/val_loss:  0.047738/  4.008229, val:  75.83%, val_best:  79.58%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-66  lr=['0.0100000'], tr/val_loss:  0.034034/  4.011147, val:  78.75%, val_best:  79.58%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-67  lr=['0.0100000'], tr/val_loss:  0.073802/  4.094209, val:  74.17%, val_best:  79.58%, tr:  99.90%, tr_best: 100.00%\n",
      "epoch-68  lr=['0.0100000'], tr/val_loss:  0.070668/  3.970168, val:  78.75%, val_best:  79.58%, tr:  99.59%, tr_best: 100.00%\n",
      "epoch-69  lr=['0.0100000'], tr/val_loss:  0.035636/  4.041033, val:  75.00%, val_best:  79.58%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-70  lr=['0.0100000'], tr/val_loss:  0.044615/  4.038845, val:  74.58%, val_best:  79.58%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-71  lr=['0.0100000'], tr/val_loss:  0.043982/  4.033761, val:  77.92%, val_best:  79.58%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-72  lr=['0.0100000'], tr/val_loss:  0.028528/  3.836328, val:  78.75%, val_best:  79.58%, tr:  99.90%, tr_best: 100.00%\n",
      "epoch-73  lr=['0.0100000'], tr/val_loss:  0.031705/  4.005413, val:  76.25%, val_best:  79.58%, tr:  99.90%, tr_best: 100.00%\n",
      "epoch-74  lr=['0.0100000'], tr/val_loss:  0.039865/  4.683316, val:  71.25%, val_best:  79.58%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-75  lr=['0.0100000'], tr/val_loss:  0.130167/  4.573278, val:  68.75%, val_best:  79.58%, tr:  99.08%, tr_best: 100.00%\n",
      "epoch-76  lr=['0.0100000'], tr/val_loss:  0.094508/  3.979136, val:  75.42%, val_best:  79.58%, tr:  99.69%, tr_best: 100.00%\n",
      "epoch-77  lr=['0.0100000'], tr/val_loss:  0.118042/  4.038382, val:  70.83%, val_best:  79.58%, tr:  99.49%, tr_best: 100.00%\n",
      "epoch-78  lr=['0.0100000'], tr/val_loss:  0.173501/  4.065866, val:  70.42%, val_best:  79.58%, tr:  99.18%, tr_best: 100.00%\n",
      "epoch-79  lr=['0.0100000'], tr/val_loss:  0.046387/  3.743820, val:  75.83%, val_best:  79.58%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-80  lr=['0.0100000'], tr/val_loss:  0.030302/  4.114831, val:  74.58%, val_best:  79.58%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-81  lr=['0.0100000'], tr/val_loss:  0.043204/  3.915668, val:  73.75%, val_best:  79.58%, tr:  99.90%, tr_best: 100.00%\n",
      "epoch-82  lr=['0.0100000'], tr/val_loss:  0.061408/  4.170593, val:  76.25%, val_best:  79.58%, tr:  99.90%, tr_best: 100.00%\n",
      "epoch-83  lr=['0.0100000'], tr/val_loss:  0.053181/  4.099908, val:  76.67%, val_best:  79.58%, tr:  99.90%, tr_best: 100.00%\n",
      "epoch-84  lr=['0.0100000'], tr/val_loss:  0.038609/  4.171946, val:  74.17%, val_best:  79.58%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-85  lr=['0.0100000'], tr/val_loss:  0.045322/  4.346420, val:  75.00%, val_best:  79.58%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-86  lr=['0.0100000'], tr/val_loss:  0.053756/  4.043512, val:  78.33%, val_best:  79.58%, tr:  99.90%, tr_best: 100.00%\n",
      "epoch-87  lr=['0.0100000'], tr/val_loss:  0.045046/  4.439563, val:  75.00%, val_best:  79.58%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-88  lr=['0.0100000'], tr/val_loss:  0.044817/  4.493750, val:  73.75%, val_best:  79.58%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-89  lr=['0.0100000'], tr/val_loss:  0.044124/  4.485063, val:  74.17%, val_best:  79.58%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-90  lr=['0.0100000'], tr/val_loss:  0.064735/  4.466746, val:  71.25%, val_best:  79.58%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-91  lr=['0.0100000'], tr/val_loss:  0.071105/  4.321843, val:  75.42%, val_best:  79.58%, tr:  99.90%, tr_best: 100.00%\n",
      "epoch-92  lr=['0.0100000'], tr/val_loss:  0.039768/  4.586693, val:  74.17%, val_best:  79.58%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-93  lr=['0.0100000'], tr/val_loss:  0.053274/  4.330345, val:  73.75%, val_best:  79.58%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-94  lr=['0.0100000'], tr/val_loss:  0.067519/  4.395521, val:  75.83%, val_best:  79.58%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-95  lr=['0.0100000'], tr/val_loss:  0.063728/  4.654677, val:  74.58%, val_best:  79.58%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-96  lr=['0.0100000'], tr/val_loss:  0.046521/  4.714171, val:  73.75%, val_best:  79.58%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-97  lr=['0.0100000'], tr/val_loss:  0.054475/  4.913707, val:  70.83%, val_best:  79.58%, tr:  99.90%, tr_best: 100.00%\n",
      "epoch-98  lr=['0.0100000'], tr/val_loss:  0.059761/  4.690642, val:  75.83%, val_best:  79.58%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-99  lr=['0.0100000'], tr/val_loss:  0.052678/  4.227996, val:  77.50%, val_best:  79.58%, tr: 100.00%, tr_best: 100.00%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "745b575dbd1c45e6ac383743dde1bcf6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.006 MB of 0.006 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>iter_acc</td><td>▁▇▆█▆▅█▇█▇██████████████████████████████</td></tr><tr><td>summary_val_acc</td><td>▁▃▅▅▆▆▆▇▆▆▇▇▆▇▇▇▇███▇██▇▇▇▇▇▇█▆▆▇▇▇▇▇▇▇▆</td></tr><tr><td>tr_acc</td><td>▁▄▅▆▇▇▇█████████████████████████████████</td></tr><tr><td>tr_epoch_loss</td><td>█▅▄▃▃▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_acc_best</td><td>▁▃▅▅▆▆▆▇▇▇██████████████████████████████</td></tr><tr><td>val_acc_now</td><td>▁▃▅▅▆▆▆▇▆▆▇▇▆▇▇▇▇███▇██▇▇▇▇▇▇█▆▆▇▇▇▇▇▇▇▆</td></tr><tr><td>val_loss</td><td>▁▁▁▁▁▁▃▂▃▃▃▄▄▄▅▅▅▄▅▅▆▅▅▆▆▇▆▆▆▆▇▆▆▇▇▇▇▇▇█</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>99</td></tr><tr><td>iter_acc</td><td>1.0</td></tr><tr><td>tr_acc</td><td>1.0</td></tr><tr><td>tr_epoch_loss</td><td>0.05268</td></tr><tr><td>val_acc_best</td><td>0.79583</td></tr><tr><td>val_acc_now</td><td>0.775</td></tr><tr><td>val_loss</td><td>4.228</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">comfy-sweep-209</strong> at: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/y0eroj7y' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/y0eroj7y</a><br/> View project at: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>/data2/bh_wandb/wandb/run-20250430_061621-y0eroj7y/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require(\"core\")`! See https://wandb.me/wandb-core for more information."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: ygzznwrc with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBATCH: 16\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBN_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBPTT_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tDFA_on: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tIMAGE_SIZE: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tOTTT_input_trace_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tTIME: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tUDA_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \talpha_uda: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbias: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcfg: ['M', 'M', 200, 200]\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tchaching_on: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tconvTrue_fcFalse: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdata_path: /data2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tddp_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdenoise_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdvs_clipping: 5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdvs_duration: 100000\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepoch_num: 100\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \texclude_class: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \textra_train_dataset: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlast_lif: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.01\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_sg_width: 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_decay: 0.5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_init: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_reset: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_threshold: 0.25\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmerge_polarities: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmy_seed: 42\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnet_print: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_workers: 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer_what: SGD\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tpin_memory: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tpre_trained: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tpre_trained_path: net_save/save_now_net_weights_{unique_name}.pth\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \trate_coding: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tscheduler_name: no\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsingle_step: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsurrogate: hard_sigmoid\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_conv_kernel_size: 3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_conv_padding: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_conv_stride: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_trace_const1: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_trace_const2: 0.5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \ttdBN_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \ttrace_on: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \twhich_data: DVS_GESTURE_TONIC\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.19.10 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.17.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/data2/bh_wandb/wandb/run-20250430_062212-ygzznwrc</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/ygzznwrc' target=\"_blank\">rich-sweep-211</a></strong> to <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/6pj3lh8j' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/6pj3lh8j</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/6pj3lh8j' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/6pj3lh8j</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/ygzznwrc' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/ygzznwrc</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'single_step' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'my_seed' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'TIME' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BATCH' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'IMAGE_SIZE' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'which_data' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'data_path' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'rate_coding' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_init' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_decay' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_threshold' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_reset' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_sg_width' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_conv_kernel_size' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_conv_stride' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_conv_padding' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_trace_const1' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_trace_const2' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'pre_trained' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'convTrue_fcFalse' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'cfg' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'net_print' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'pre_trained_path' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'learning_rate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'epoch_num' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'tdBN_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BN_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'surrogate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BPTT_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'optimizer_what' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'scheduler_name' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'ddp_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'dvs_clipping' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'dvs_duration' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'DFA_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'trace_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'OTTT_input_trace_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'exclude_class' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'merge_polarities' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'denoise_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'extra_train_dataset' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'num_workers' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'chaching_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'pin_memory' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'UDA_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'alpha_uda' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'bias' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'last_lif' was locked by 'sweep' (ignored update).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "param {'devices': '0', 'single_step': True, 'unique_name': 'main', 'my_seed': 42, 'TIME': 10, 'BATCH': 16, 'IMAGE_SIZE': 128, 'which_data': 'DVS_GESTURE_TONIC', 'data_path': '/data2', 'rate_coding': False, 'lif_layer_v_init': 0, 'lif_layer_v_decay': 0.5, 'lif_layer_v_threshold': 0.25, 'lif_layer_v_reset': 0, 'lif_layer_sg_width': 2, 'synapse_conv_kernel_size': 3, 'synapse_conv_stride': 1, 'synapse_conv_padding': 1, 'synapse_trace_const1': 1, 'synapse_trace_const2': 0.5, 'pre_trained': False, 'convTrue_fcFalse': False, 'cfg': ['M', 'M', 200, 200], 'net_print': True, 'pre_trained_path': 'net_save/save_now_net_weights_{unique_name}.pth', 'learning_rate': 0.01, 'epoch_num': 100, 'tdBN_on': False, 'BN_on': False, 'surrogate': 'hard_sigmoid', 'BPTT_on': False, 'optimizer_what': 'SGD', 'scheduler_name': 'no', 'ddp_on': False, 'dvs_clipping': 5, 'dvs_duration': 100000, 'DFA_on': True, 'trace_on': True, 'OTTT_input_trace_on': False, 'exclude_class': True, 'merge_polarities': False, 'denoise_on': False, 'extra_train_dataset': 0, 'num_workers': 2, 'chaching_on': True, 'pin_memory': True, 'UDA_on': False, 'alpha_uda': 1, 'bias': True, 'last_lif': False, 'current epoch': 0} \n",
      "\n",
      "dataset_hash = ffa516e60c3efd5e0208f72b4c36cb84\n",
      "cache path exists\n",
      "\n",
      "device ==> cuda\n",
      "\n",
      "DataParallel(\n",
      "  (module): REBORN_MY_SNN_FC(\n",
      "    (layers): REBORN_MY_Sequential(\n",
      "      (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (2): DimChanger_for_FC()\n",
      "      (3): SYNAPSE_FC(in_features=2048, out_features=200, TIME=10, bias=True, sstep=True)\n",
      "      (4): LIF_layer(v_init=0, v_decay=0.5, v_threshold=0.25, v_reset=0, sg_width=2, surrogate=hard_sigmoid, BPTT_on=False, trace_const1=1, trace_const2=0.5, TIME=10, sstep=True, trace_on=True)\n",
      "      (5): Feedback_Receiver()\n",
      "      (6): SYNAPSE_FC(in_features=200, out_features=200, TIME=10, bias=True, sstep=True)\n",
      "      (7): LIF_layer(v_init=0, v_decay=0.5, v_threshold=0.25, v_reset=0, sg_width=2, surrogate=hard_sigmoid, BPTT_on=False, trace_const1=1, trace_const2=0.5, TIME=10, sstep=True, trace_on=True)\n",
      "      (8): Feedback_Receiver()\n",
      "      (9): SYNAPSE_FC(in_features=200, out_features=10, TIME=10, bias=True, sstep=True)\n",
      "      (DFA_top): Top_Gradient()\n",
      "    )\n",
      "  )\n",
      ")\n",
      "\n",
      "========================================================\n",
      "Trainable parameters: 452,010\n",
      "========================================================\n",
      "\n",
      "epoch-0   lr=['0.0100000'], tr/val_loss:  2.862437/  5.009102, val:  33.75%, val_best:  33.75%, tr:  34.42%, tr_best:  34.42%\n",
      "[module.layers.5] weight_fb parameter count: 2,000\n",
      "[module.layers.8] weight_fb parameter count: 2,000\n",
      "epoch-1   lr=['0.0100000'], tr/val_loss:  3.406891/  4.245020, val:  50.00%, val_best:  50.00%, tr:  51.07%, tr_best:  51.07%\n",
      "epoch-2   lr=['0.0100000'], tr/val_loss:  4.026637/  5.462057, val:  52.08%, val_best:  52.08%, tr:  55.16%, tr_best:  55.16%\n",
      "epoch-3   lr=['0.0100000'], tr/val_loss:  2.652951/  5.538231, val:  37.08%, val_best:  52.08%, tr:  64.15%, tr_best:  64.15%\n",
      "epoch-4   lr=['0.0100000'], tr/val_loss:  3.578669/  3.920694, val:  55.00%, val_best:  55.00%, tr:  60.57%, tr_best:  64.15%\n",
      "epoch-5   lr=['0.0100000'], tr/val_loss:  2.303785/  6.458194, val:  42.08%, val_best:  55.00%, tr:  70.58%, tr_best:  70.58%\n",
      "epoch-6   lr=['0.0100000'], tr/val_loss:  1.788066/  4.359780, val:  57.92%, val_best:  57.92%, tr:  74.57%, tr_best:  74.57%\n",
      "epoch-7   lr=['0.0100000'], tr/val_loss:  1.964189/  4.198009, val:  59.17%, val_best:  59.17%, tr:  78.96%, tr_best:  78.96%\n",
      "epoch-8   lr=['0.0100000'], tr/val_loss:  1.264598/  3.879519, val:  62.92%, val_best:  62.92%, tr:  85.50%, tr_best:  85.50%\n",
      "epoch-9   lr=['0.0100000'], tr/val_loss:  1.272372/  4.751075, val:  59.58%, val_best:  62.92%, tr:  86.72%, tr_best:  86.72%\n",
      "epoch-10  lr=['0.0100000'], tr/val_loss:  0.815721/  4.000327, val:  67.50%, val_best:  67.50%, tr:  92.75%, tr_best:  92.75%\n",
      "epoch-11  lr=['0.0100000'], tr/val_loss:  1.216871/  4.522370, val:  68.75%, val_best:  68.75%, tr:  90.81%, tr_best:  92.75%\n",
      "epoch-12  lr=['0.0100000'], tr/val_loss:  0.528951/  4.712665, val:  70.83%, val_best:  70.83%, tr:  96.83%, tr_best:  96.83%\n",
      "epoch-13  lr=['0.0100000'], tr/val_loss:  0.345412/  4.938185, val:  65.00%, val_best:  70.83%, tr:  98.47%, tr_best:  98.47%\n",
      "epoch-14  lr=['0.0100000'], tr/val_loss:  0.361344/  5.177459, val:  65.42%, val_best:  70.83%, tr:  98.06%, tr_best:  98.47%\n",
      "epoch-15  lr=['0.0100000'], tr/val_loss:  0.221989/  4.852916, val:  70.42%, val_best:  70.83%, tr:  99.59%, tr_best:  99.59%\n",
      "epoch-16  lr=['0.0100000'], tr/val_loss:  0.173498/  4.705749, val:  70.42%, val_best:  70.83%, tr:  99.80%, tr_best:  99.80%\n",
      "epoch-17  lr=['0.0100000'], tr/val_loss:  0.138368/  4.754208, val:  73.75%, val_best:  73.75%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-18  lr=['0.0100000'], tr/val_loss:  0.086149/  5.104984, val:  69.17%, val_best:  73.75%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-19  lr=['0.0100000'], tr/val_loss:  0.081228/  5.018371, val:  72.08%, val_best:  73.75%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-20  lr=['0.0100000'], tr/val_loss:  0.056010/  5.032334, val:  72.08%, val_best:  73.75%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-21  lr=['0.0100000'], tr/val_loss:  0.051640/  5.328952, val:  70.42%, val_best:  73.75%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-22  lr=['0.0100000'], tr/val_loss:  0.033248/  5.277039, val:  71.67%, val_best:  73.75%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-23  lr=['0.0100000'], tr/val_loss:  0.029268/  5.269660, val:  71.67%, val_best:  73.75%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-24  lr=['0.0100000'], tr/val_loss:  0.022157/  5.251469, val:  71.25%, val_best:  73.75%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-25  lr=['0.0100000'], tr/val_loss:  0.018972/  5.221611, val:  71.67%, val_best:  73.75%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-26  lr=['0.0100000'], tr/val_loss:  0.025690/  5.246654, val:  71.25%, val_best:  73.75%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-27  lr=['0.0100000'], tr/val_loss:  0.017086/  5.340919, val:  71.25%, val_best:  73.75%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-28  lr=['0.0100000'], tr/val_loss:  0.017855/  5.352916, val:  70.42%, val_best:  73.75%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-29  lr=['0.0100000'], tr/val_loss:  0.012402/  5.352382, val:  70.42%, val_best:  73.75%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-30  lr=['0.0100000'], tr/val_loss:  0.010653/  5.283897, val:  71.67%, val_best:  73.75%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-31  lr=['0.0100000'], tr/val_loss:  0.007408/  5.285176, val:  71.67%, val_best:  73.75%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-32  lr=['0.0100000'], tr/val_loss:  0.004853/  5.320117, val:  70.83%, val_best:  73.75%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-33  lr=['0.0100000'], tr/val_loss:  0.003567/  5.326584, val:  71.25%, val_best:  73.75%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-34  lr=['0.0100000'], tr/val_loss:  0.004067/  5.320882, val:  70.42%, val_best:  73.75%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-35  lr=['0.0100000'], tr/val_loss:  0.004006/  5.272813, val:  70.42%, val_best:  73.75%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-36  lr=['0.0100000'], tr/val_loss:  0.004328/  5.386992, val:  70.42%, val_best:  73.75%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-37  lr=['0.0100000'], tr/val_loss:  0.002419/  5.415913, val:  71.25%, val_best:  73.75%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-38  lr=['0.0100000'], tr/val_loss:  0.003522/  5.421573, val:  70.42%, val_best:  73.75%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-39  lr=['0.0100000'], tr/val_loss:  0.005911/  5.373739, val:  72.08%, val_best:  73.75%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-40  lr=['0.0100000'], tr/val_loss:  0.008890/  5.482132, val:  71.25%, val_best:  73.75%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-41  lr=['0.0100000'], tr/val_loss:  0.003294/  5.471335, val:  71.67%, val_best:  73.75%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-42  lr=['0.0100000'], tr/val_loss:  0.002396/  5.505539, val:  71.67%, val_best:  73.75%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-43  lr=['0.0100000'], tr/val_loss:  0.002252/  5.466811, val:  71.67%, val_best:  73.75%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-44  lr=['0.0100000'], tr/val_loss:  0.002075/  5.440212, val:  72.92%, val_best:  73.75%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-45  lr=['0.0100000'], tr/val_loss:  0.001605/  5.419465, val:  72.50%, val_best:  73.75%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-46  lr=['0.0100000'], tr/val_loss:  0.001827/  5.444560, val:  74.17%, val_best:  74.17%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-47  lr=['0.0100000'], tr/val_loss:  0.001757/  5.474415, val:  70.42%, val_best:  74.17%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-48  lr=['0.0100000'], tr/val_loss:  0.002127/  5.448020, val:  72.08%, val_best:  74.17%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-49  lr=['0.0100000'], tr/val_loss:  0.000906/  5.419746, val:  72.08%, val_best:  74.17%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-50  lr=['0.0100000'], tr/val_loss:  0.001251/  5.374532, val:  72.50%, val_best:  74.17%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-51  lr=['0.0100000'], tr/val_loss:  0.001567/  5.568386, val:  72.08%, val_best:  74.17%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-52  lr=['0.0100000'], tr/val_loss:  0.001296/  5.522381, val:  72.08%, val_best:  74.17%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-53  lr=['0.0100000'], tr/val_loss:  0.001441/  5.505293, val:  71.67%, val_best:  74.17%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-54  lr=['0.0100000'], tr/val_loss:  0.001330/  5.499094, val:  72.08%, val_best:  74.17%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-55  lr=['0.0100000'], tr/val_loss:  0.000741/  5.488082, val:  71.67%, val_best:  74.17%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-56  lr=['0.0100000'], tr/val_loss:  0.000677/  5.526916, val:  72.08%, val_best:  74.17%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-57  lr=['0.0100000'], tr/val_loss:  0.000614/  5.450961, val:  72.08%, val_best:  74.17%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-58  lr=['0.0100000'], tr/val_loss:  0.000767/  5.450663, val:  71.67%, val_best:  74.17%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-59  lr=['0.0100000'], tr/val_loss:  0.000979/  5.433461, val:  72.50%, val_best:  74.17%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-60  lr=['0.0100000'], tr/val_loss:  0.000725/  5.472289, val:  71.67%, val_best:  74.17%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-61  lr=['0.0100000'], tr/val_loss:  0.000978/  5.468332, val:  72.50%, val_best:  74.17%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-62  lr=['0.0100000'], tr/val_loss:  0.000571/  5.470284, val:  71.67%, val_best:  74.17%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-63  lr=['0.0100000'], tr/val_loss:  0.000871/  5.440756, val:  72.92%, val_best:  74.17%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-64  lr=['0.0100000'], tr/val_loss:  0.002033/  5.496743, val:  71.25%, val_best:  74.17%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-65  lr=['0.0100000'], tr/val_loss:  0.001448/  5.474222, val:  72.08%, val_best:  74.17%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-66  lr=['0.0100000'], tr/val_loss:  0.001459/  5.444936, val:  72.08%, val_best:  74.17%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-67  lr=['0.0100000'], tr/val_loss:  0.000631/  5.533602, val:  72.92%, val_best:  74.17%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-68  lr=['0.0100000'], tr/val_loss:  0.001079/  5.476973, val:  72.50%, val_best:  74.17%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-69  lr=['0.0100000'], tr/val_loss:  0.001633/  5.485777, val:  72.08%, val_best:  74.17%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-70  lr=['0.0100000'], tr/val_loss:  0.001132/  5.468853, val:  73.33%, val_best:  74.17%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-71  lr=['0.0100000'], tr/val_loss:  0.000719/  5.568374, val:  72.08%, val_best:  74.17%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-72  lr=['0.0100000'], tr/val_loss:  0.000556/  5.505986, val:  72.50%, val_best:  74.17%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-73  lr=['0.0100000'], tr/val_loss:  0.000544/  5.503250, val:  72.92%, val_best:  74.17%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-74  lr=['0.0100000'], tr/val_loss:  0.000442/  5.478510, val:  72.08%, val_best:  74.17%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-75  lr=['0.0100000'], tr/val_loss:  0.000381/  5.498048, val:  72.50%, val_best:  74.17%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-76  lr=['0.0100000'], tr/val_loss:  0.000339/  5.507565, val:  73.75%, val_best:  74.17%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-77  lr=['0.0100000'], tr/val_loss:  0.000303/  5.506681, val:  72.92%, val_best:  74.17%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-78  lr=['0.0100000'], tr/val_loss:  0.000356/  5.488746, val:  73.33%, val_best:  74.17%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-79  lr=['0.0100000'], tr/val_loss:  0.000342/  5.491224, val:  73.75%, val_best:  74.17%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-80  lr=['0.0100000'], tr/val_loss:  0.000408/  5.518064, val:  73.33%, val_best:  74.17%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-81  lr=['0.0100000'], tr/val_loss:  0.000300/  5.477611, val:  72.92%, val_best:  74.17%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-82  lr=['0.0100000'], tr/val_loss:  0.000415/  5.508226, val:  72.92%, val_best:  74.17%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-83  lr=['0.0100000'], tr/val_loss:  0.000392/  5.494097, val:  72.50%, val_best:  74.17%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-84  lr=['0.0100000'], tr/val_loss:  0.000642/  5.486656, val:  73.33%, val_best:  74.17%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-85  lr=['0.0100000'], tr/val_loss:  0.000376/  5.508854, val:  72.92%, val_best:  74.17%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-86  lr=['0.0100000'], tr/val_loss:  0.000437/  5.533734, val:  71.67%, val_best:  74.17%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-87  lr=['0.0100000'], tr/val_loss:  0.000881/  5.528561, val:  72.08%, val_best:  74.17%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-88  lr=['0.0100000'], tr/val_loss:  0.000728/  5.482636, val:  72.92%, val_best:  74.17%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-89  lr=['0.0100000'], tr/val_loss:  0.000707/  5.488565, val:  73.33%, val_best:  74.17%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-90  lr=['0.0100000'], tr/val_loss:  0.000800/  5.495811, val:  72.50%, val_best:  74.17%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-91  lr=['0.0100000'], tr/val_loss:  0.002103/  5.537024, val:  72.50%, val_best:  74.17%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-92  lr=['0.0100000'], tr/val_loss:  0.000944/  5.519409, val:  74.17%, val_best:  74.17%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-93  lr=['0.0100000'], tr/val_loss:  0.000986/  5.545987, val:  73.75%, val_best:  74.17%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-94  lr=['0.0100000'], tr/val_loss:  0.000665/  5.502789, val:  74.17%, val_best:  74.17%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-95  lr=['0.0100000'], tr/val_loss:  0.000841/  5.571984, val:  73.75%, val_best:  74.17%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-96  lr=['0.0100000'], tr/val_loss:  0.001005/  5.527832, val:  73.33%, val_best:  74.17%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-97  lr=['0.0100000'], tr/val_loss:  0.000366/  5.550931, val:  72.50%, val_best:  74.17%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-98  lr=['0.0100000'], tr/val_loss:  0.000549/  5.553586, val:  72.92%, val_best:  74.17%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-99  lr=['0.0100000'], tr/val_loss:  0.000279/  5.544325, val:  72.92%, val_best:  74.17%, tr: 100.00%, tr_best: 100.00%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "185cbcef92044b34af8ff327186e0329",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.006 MB of 0.006 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>iter_acc</td><td>▁▂▅█▇███████████████████████████████████</td></tr><tr><td>summary_val_acc</td><td>▁▄▅▅▅▇▆██▇▇▇▇▇▇▇███▇████████████████████</td></tr><tr><td>tr_acc</td><td>▁▃▄▆▇███████████████████████████████████</td></tr><tr><td>tr_epoch_loss</td><td>▆█▇▄▃▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_acc_best</td><td>▁▄▅▅▆▇▇█████████████████████████████████</td></tr><tr><td>val_acc_now</td><td>▁▄▅▅▅▇▆██▇▇▇▇▇▇▇███▇████████████████████</td></tr><tr><td>val_loss</td><td>▆█▁▂▅▄▆▅▆▇▇▇▇▇▇▇▇█▇█▇██▇▇███████████████</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>99</td></tr><tr><td>iter_acc</td><td>1.0</td></tr><tr><td>tr_acc</td><td>1.0</td></tr><tr><td>tr_epoch_loss</td><td>0.00028</td></tr><tr><td>val_acc_best</td><td>0.74167</td></tr><tr><td>val_acc_now</td><td>0.72917</td></tr><tr><td>val_loss</td><td>5.54432</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">rich-sweep-211</strong> at: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/ygzznwrc' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/ygzznwrc</a><br/> View project at: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>/data2/bh_wandb/wandb/run-20250430_062212-ygzznwrc/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require(\"core\")`! See https://wandb.me/wandb-core for more information."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Sweep Agent: Waiting for job.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Job received.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: qljsn2qt with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBATCH: 16\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBN_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBPTT_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tDFA_on: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tIMAGE_SIZE: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tOTTT_input_trace_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tTIME: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tUDA_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \talpha_uda: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbias: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcfg: ['M', 'M', 200, 200]\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tchaching_on: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tconvTrue_fcFalse: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdata_path: /data2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tddp_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdenoise_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdvs_clipping: 5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdvs_duration: 100000\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepoch_num: 100\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \texclude_class: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \textra_train_dataset: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlast_lif: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.0001\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_sg_width: 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_decay: 0.5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_init: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_reset: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_threshold: 0.25\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmerge_polarities: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmy_seed: 42\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnet_print: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_workers: 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer_what: SGD\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tpin_memory: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tpre_trained: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tpre_trained_path: net_save/save_now_net_weights_{unique_name}.pth\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \trate_coding: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tscheduler_name: no\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsingle_step: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsurrogate: hard_sigmoid\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_conv_kernel_size: 3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_conv_padding: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_conv_stride: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_trace_const1: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_trace_const2: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \ttdBN_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \ttrace_on: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \twhich_data: DVS_GESTURE_TONIC\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.19.10 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.17.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/data2/bh_wandb/wandb/run-20250430_062901-qljsn2qt</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/qljsn2qt' target=\"_blank\">bumbling-sweep-213</a></strong> to <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/6pj3lh8j' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/6pj3lh8j</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/6pj3lh8j' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/6pj3lh8j</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/qljsn2qt' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/qljsn2qt</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'single_step' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'my_seed' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'TIME' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BATCH' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'IMAGE_SIZE' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'which_data' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'data_path' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'rate_coding' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_init' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_decay' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_threshold' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_reset' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_sg_width' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_conv_kernel_size' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_conv_stride' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_conv_padding' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_trace_const1' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_trace_const2' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'pre_trained' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'convTrue_fcFalse' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'cfg' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'net_print' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'pre_trained_path' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'learning_rate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'epoch_num' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'tdBN_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BN_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'surrogate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BPTT_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'optimizer_what' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'scheduler_name' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'ddp_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'dvs_clipping' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'dvs_duration' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'DFA_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'trace_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'OTTT_input_trace_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'exclude_class' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'merge_polarities' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'denoise_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'extra_train_dataset' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'num_workers' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'chaching_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'pin_memory' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'UDA_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'alpha_uda' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'bias' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'last_lif' was locked by 'sweep' (ignored update).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "param {'devices': '0', 'single_step': True, 'unique_name': 'main', 'my_seed': 42, 'TIME': 10, 'BATCH': 16, 'IMAGE_SIZE': 128, 'which_data': 'DVS_GESTURE_TONIC', 'data_path': '/data2', 'rate_coding': False, 'lif_layer_v_init': 0, 'lif_layer_v_decay': 0.5, 'lif_layer_v_threshold': 0.25, 'lif_layer_v_reset': 0, 'lif_layer_sg_width': 2, 'synapse_conv_kernel_size': 3, 'synapse_conv_stride': 1, 'synapse_conv_padding': 1, 'synapse_trace_const1': 1, 'synapse_trace_const2': 0, 'pre_trained': False, 'convTrue_fcFalse': False, 'cfg': ['M', 'M', 200, 200], 'net_print': True, 'pre_trained_path': 'net_save/save_now_net_weights_{unique_name}.pth', 'learning_rate': 0.0001, 'epoch_num': 100, 'tdBN_on': False, 'BN_on': False, 'surrogate': 'hard_sigmoid', 'BPTT_on': False, 'optimizer_what': 'SGD', 'scheduler_name': 'no', 'ddp_on': False, 'dvs_clipping': 5, 'dvs_duration': 100000, 'DFA_on': True, 'trace_on': True, 'OTTT_input_trace_on': False, 'exclude_class': True, 'merge_polarities': False, 'denoise_on': False, 'extra_train_dataset': 0, 'num_workers': 2, 'chaching_on': True, 'pin_memory': True, 'UDA_on': False, 'alpha_uda': 1, 'bias': True, 'last_lif': False, 'current epoch': 0} \n",
      "\n",
      "dataset_hash = ffa516e60c3efd5e0208f72b4c36cb84\n",
      "cache path exists\n",
      "\n",
      "device ==> cuda\n",
      "\n",
      "DataParallel(\n",
      "  (module): REBORN_MY_SNN_FC(\n",
      "    (layers): REBORN_MY_Sequential(\n",
      "      (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (2): DimChanger_for_FC()\n",
      "      (3): SYNAPSE_FC(in_features=2048, out_features=200, TIME=10, bias=True, sstep=True)\n",
      "      (4): LIF_layer(v_init=0, v_decay=0.5, v_threshold=0.25, v_reset=0, sg_width=2, surrogate=hard_sigmoid, BPTT_on=False, trace_const1=1, trace_const2=0, TIME=10, sstep=True, trace_on=True)\n",
      "      (5): Feedback_Receiver()\n",
      "      (6): SYNAPSE_FC(in_features=200, out_features=200, TIME=10, bias=True, sstep=True)\n",
      "      (7): LIF_layer(v_init=0, v_decay=0.5, v_threshold=0.25, v_reset=0, sg_width=2, surrogate=hard_sigmoid, BPTT_on=False, trace_const1=1, trace_const2=0, TIME=10, sstep=True, trace_on=True)\n",
      "      (8): Feedback_Receiver()\n",
      "      (9): SYNAPSE_FC(in_features=200, out_features=10, TIME=10, bias=True, sstep=True)\n",
      "      (DFA_top): Top_Gradient()\n",
      "    )\n",
      "  )\n",
      ")\n",
      "\n",
      "========================================================\n",
      "Trainable parameters: 452,010\n",
      "========================================================\n",
      "\n",
      "epoch-0   lr=['0.0001000'], tr/val_loss:  2.303330/  2.291018, val:  15.42%, val_best:  15.42%, tr:  13.28%, tr_best:  13.28%\n",
      "[module.layers.5] weight_fb parameter count: 2,000\n",
      "[module.layers.8] weight_fb parameter count: 2,000\n",
      "epoch-1   lr=['0.0001000'], tr/val_loss:  2.274832/  2.257420, val:  16.67%, val_best:  16.67%, tr:  18.49%, tr_best:  18.49%\n",
      "epoch-2   lr=['0.0001000'], tr/val_loss:  2.210362/  2.186072, val:  21.25%, val_best:  21.25%, tr:  24.51%, tr_best:  24.51%\n",
      "epoch-3   lr=['0.0001000'], tr/val_loss:  2.107879/  2.085763, val:  31.67%, val_best:  31.67%, tr:  31.77%, tr_best:  31.77%\n",
      "epoch-4   lr=['0.0001000'], tr/val_loss:  1.983566/  1.971362, val:  40.00%, val_best:  40.00%, tr:  38.71%, tr_best:  38.71%\n",
      "epoch-5   lr=['0.0001000'], tr/val_loss:  1.846030/  1.850559, val:  40.42%, val_best:  40.42%, tr:  45.76%, tr_best:  45.76%\n",
      "epoch-6   lr=['0.0001000'], tr/val_loss:  1.731218/  1.745690, val:  42.50%, val_best:  42.50%, tr:  48.93%, tr_best:  48.93%\n",
      "epoch-7   lr=['0.0001000'], tr/val_loss:  1.616774/  1.668149, val:  44.17%, val_best:  44.17%, tr:  52.71%, tr_best:  52.71%\n",
      "epoch-8   lr=['0.0001000'], tr/val_loss:  1.536437/  1.600870, val:  45.83%, val_best:  45.83%, tr:  53.93%, tr_best:  53.93%\n",
      "epoch-9   lr=['0.0001000'], tr/val_loss:  1.464822/  1.551916, val:  47.92%, val_best:  47.92%, tr:  54.34%, tr_best:  54.34%\n",
      "epoch-10  lr=['0.0001000'], tr/val_loss:  1.412754/  1.507424, val:  52.92%, val_best:  52.92%, tr:  57.71%, tr_best:  57.71%\n",
      "epoch-11  lr=['0.0001000'], tr/val_loss:  1.368538/  1.474619, val:  53.75%, val_best:  53.75%, tr:  58.73%, tr_best:  58.73%\n",
      "epoch-12  lr=['0.0001000'], tr/val_loss:  1.333736/  1.446024, val:  53.33%, val_best:  53.75%, tr:  59.55%, tr_best:  59.55%\n",
      "epoch-13  lr=['0.0001000'], tr/val_loss:  1.302445/  1.422244, val:  55.42%, val_best:  55.42%, tr:  61.59%, tr_best:  61.59%\n",
      "epoch-14  lr=['0.0001000'], tr/val_loss:  1.265880/  1.406200, val:  54.17%, val_best:  55.42%, tr:  62.92%, tr_best:  62.92%\n",
      "epoch-15  lr=['0.0001000'], tr/val_loss:  1.237069/  1.386609, val:  57.08%, val_best:  57.08%, tr:  63.33%, tr_best:  63.33%\n",
      "epoch-16  lr=['0.0001000'], tr/val_loss:  1.207828/  1.371800, val:  59.58%, val_best:  59.58%, tr:  63.94%, tr_best:  63.94%\n",
      "epoch-17  lr=['0.0001000'], tr/val_loss:  1.194569/  1.361184, val:  60.42%, val_best:  60.42%, tr:  64.45%, tr_best:  64.45%\n",
      "epoch-18  lr=['0.0001000'], tr/val_loss:  1.174444/  1.351543, val:  56.67%, val_best:  60.42%, tr:  64.96%, tr_best:  64.96%\n",
      "epoch-19  lr=['0.0001000'], tr/val_loss:  1.153882/  1.339507, val:  57.50%, val_best:  60.42%, tr:  63.43%, tr_best:  64.96%\n",
      "epoch-20  lr=['0.0001000'], tr/val_loss:  1.133340/  1.331090, val:  58.33%, val_best:  60.42%, tr:  65.07%, tr_best:  65.07%\n",
      "epoch-21  lr=['0.0001000'], tr/val_loss:  1.117349/  1.319896, val:  59.17%, val_best:  60.42%, tr:  66.60%, tr_best:  66.60%\n",
      "epoch-22  lr=['0.0001000'], tr/val_loss:  1.101409/  1.313486, val:  59.58%, val_best:  60.42%, tr:  65.37%, tr_best:  66.60%\n",
      "epoch-23  lr=['0.0001000'], tr/val_loss:  1.082339/  1.304010, val:  60.83%, val_best:  60.83%, tr:  67.01%, tr_best:  67.01%\n",
      "epoch-24  lr=['0.0001000'], tr/val_loss:  1.071987/  1.299961, val:  57.92%, val_best:  60.83%, tr:  67.52%, tr_best:  67.52%\n",
      "epoch-25  lr=['0.0001000'], tr/val_loss:  1.056276/  1.294413, val:  63.75%, val_best:  63.75%, tr:  69.15%, tr_best:  69.15%\n",
      "epoch-26  lr=['0.0001000'], tr/val_loss:  1.044209/  1.284758, val:  63.33%, val_best:  63.75%, tr:  68.95%, tr_best:  69.15%\n",
      "epoch-27  lr=['0.0001000'], tr/val_loss:  1.029155/  1.273483, val:  61.67%, val_best:  63.75%, tr:  69.46%, tr_best:  69.46%\n",
      "epoch-28  lr=['0.0001000'], tr/val_loss:  1.034844/  1.267108, val:  60.00%, val_best:  63.75%, tr:  68.85%, tr_best:  69.46%\n",
      "epoch-29  lr=['0.0001000'], tr/val_loss:  1.012939/  1.265165, val:  63.33%, val_best:  63.75%, tr:  70.28%, tr_best:  70.28%\n",
      "epoch-30  lr=['0.0001000'], tr/val_loss:  1.000514/  1.258012, val:  62.50%, val_best:  63.75%, tr:  70.38%, tr_best:  70.38%\n",
      "epoch-31  lr=['0.0001000'], tr/val_loss:  0.991948/  1.257324, val:  64.17%, val_best:  64.17%, tr:  69.56%, tr_best:  70.38%\n",
      "epoch-32  lr=['0.0001000'], tr/val_loss:  0.984661/  1.254904, val:  62.92%, val_best:  64.17%, tr:  70.89%, tr_best:  70.89%\n",
      "epoch-33  lr=['0.0001000'], tr/val_loss:  0.985837/  1.248225, val:  62.50%, val_best:  64.17%, tr:  71.40%, tr_best:  71.40%\n",
      "epoch-34  lr=['0.0001000'], tr/val_loss:  0.965819/  1.243850, val:  62.08%, val_best:  64.17%, tr:  71.09%, tr_best:  71.40%\n",
      "epoch-35  lr=['0.0001000'], tr/val_loss:  0.956230/  1.236120, val:  63.75%, val_best:  64.17%, tr:  72.93%, tr_best:  72.93%\n",
      "epoch-36  lr=['0.0001000'], tr/val_loss:  0.951747/  1.234787, val:  63.75%, val_best:  64.17%, tr:  72.11%, tr_best:  72.93%\n",
      "epoch-37  lr=['0.0001000'], tr/val_loss:  0.940446/  1.229569, val:  64.58%, val_best:  64.58%, tr:  72.52%, tr_best:  72.93%\n",
      "epoch-38  lr=['0.0001000'], tr/val_loss:  0.937800/  1.231427, val:  66.25%, val_best:  66.25%, tr:  72.22%, tr_best:  72.93%\n",
      "epoch-39  lr=['0.0001000'], tr/val_loss:  0.931519/  1.228585, val:  65.00%, val_best:  66.25%, tr:  74.77%, tr_best:  74.77%\n",
      "epoch-40  lr=['0.0001000'], tr/val_loss:  0.916817/  1.226452, val:  62.92%, val_best:  66.25%, tr:  72.83%, tr_best:  74.77%\n",
      "epoch-41  lr=['0.0001000'], tr/val_loss:  0.923974/  1.224375, val:  66.67%, val_best:  66.67%, tr:  75.49%, tr_best:  75.49%\n",
      "epoch-42  lr=['0.0001000'], tr/val_loss:  0.902439/  1.217259, val:  65.83%, val_best:  66.67%, tr:  74.77%, tr_best:  75.49%\n",
      "epoch-43  lr=['0.0001000'], tr/val_loss:  0.899794/  1.215592, val:  65.00%, val_best:  66.67%, tr:  74.67%, tr_best:  75.49%\n",
      "epoch-44  lr=['0.0001000'], tr/val_loss:  0.894325/  1.215614, val:  63.33%, val_best:  66.67%, tr:  74.16%, tr_best:  75.49%\n",
      "epoch-45  lr=['0.0001000'], tr/val_loss:  0.885827/  1.206064, val:  67.08%, val_best:  67.08%, tr:  75.89%, tr_best:  75.89%\n",
      "epoch-46  lr=['0.0001000'], tr/val_loss:  0.880505/  1.205408, val:  65.83%, val_best:  67.08%, tr:  75.49%, tr_best:  75.89%\n",
      "epoch-47  lr=['0.0001000'], tr/val_loss:  0.883283/  1.202398, val:  66.25%, val_best:  67.08%, tr:  75.08%, tr_best:  75.89%\n",
      "epoch-48  lr=['0.0001000'], tr/val_loss:  0.875634/  1.205132, val:  65.83%, val_best:  67.08%, tr:  77.12%, tr_best:  77.12%\n",
      "epoch-49  lr=['0.0001000'], tr/val_loss:  0.864115/  1.201975, val:  65.42%, val_best:  67.08%, tr:  76.51%, tr_best:  77.12%\n",
      "epoch-50  lr=['0.0001000'], tr/val_loss:  0.858424/  1.198314, val:  66.25%, val_best:  67.08%, tr:  77.32%, tr_best:  77.32%\n",
      "epoch-51  lr=['0.0001000'], tr/val_loss:  0.856278/  1.193304, val:  66.25%, val_best:  67.08%, tr:  77.02%, tr_best:  77.32%\n",
      "epoch-52  lr=['0.0001000'], tr/val_loss:  0.845071/  1.192205, val:  65.42%, val_best:  67.08%, tr:  78.04%, tr_best:  78.04%\n",
      "epoch-53  lr=['0.0001000'], tr/val_loss:  0.837599/  1.193955, val:  65.42%, val_best:  67.08%, tr:  77.73%, tr_best:  78.04%\n",
      "epoch-54  lr=['0.0001000'], tr/val_loss:  0.837074/  1.197545, val:  65.42%, val_best:  67.08%, tr:  78.24%, tr_best:  78.24%\n",
      "epoch-55  lr=['0.0001000'], tr/val_loss:  0.832490/  1.196330, val:  68.33%, val_best:  68.33%, tr:  79.37%, tr_best:  79.37%\n",
      "epoch-56  lr=['0.0001000'], tr/val_loss:  0.818904/  1.196859, val:  65.42%, val_best:  68.33%, tr:  80.59%, tr_best:  80.59%\n",
      "epoch-57  lr=['0.0001000'], tr/val_loss:  0.817560/  1.193432, val:  65.00%, val_best:  68.33%, tr:  79.57%, tr_best:  80.59%\n",
      "epoch-58  lr=['0.0001000'], tr/val_loss:  0.811148/  1.192387, val:  65.00%, val_best:  68.33%, tr:  79.47%, tr_best:  80.59%\n",
      "epoch-59  lr=['0.0001000'], tr/val_loss:  0.810075/  1.185730, val:  66.25%, val_best:  68.33%, tr:  80.80%, tr_best:  80.80%\n",
      "epoch-60  lr=['0.0001000'], tr/val_loss:  0.804691/  1.186887, val:  67.92%, val_best:  68.33%, tr:  79.06%, tr_best:  80.80%\n",
      "epoch-61  lr=['0.0001000'], tr/val_loss:  0.804976/  1.186871, val:  67.08%, val_best:  68.33%, tr:  81.31%, tr_best:  81.31%\n",
      "epoch-62  lr=['0.0001000'], tr/val_loss:  0.796429/  1.183938, val:  66.25%, val_best:  68.33%, tr:  80.69%, tr_best:  81.31%\n",
      "epoch-63  lr=['0.0001000'], tr/val_loss:  0.785212/  1.178747, val:  67.92%, val_best:  68.33%, tr:  82.64%, tr_best:  82.64%\n",
      "epoch-64  lr=['0.0001000'], tr/val_loss:  0.777637/  1.177998, val:  67.92%, val_best:  68.33%, tr:  82.94%, tr_best:  82.94%\n",
      "epoch-65  lr=['0.0001000'], tr/val_loss:  0.780541/  1.180737, val:  65.83%, val_best:  68.33%, tr:  82.53%, tr_best:  82.94%\n",
      "epoch-66  lr=['0.0001000'], tr/val_loss:  0.776937/  1.176011, val:  67.92%, val_best:  68.33%, tr:  82.94%, tr_best:  82.94%\n",
      "epoch-67  lr=['0.0001000'], tr/val_loss:  0.778956/  1.178419, val:  67.92%, val_best:  68.33%, tr:  83.35%, tr_best:  83.35%\n",
      "epoch-68  lr=['0.0001000'], tr/val_loss:  0.764330/  1.180500, val:  67.50%, val_best:  68.33%, tr:  83.15%, tr_best:  83.35%\n",
      "epoch-69  lr=['0.0001000'], tr/val_loss:  0.759823/  1.177229, val:  66.67%, val_best:  68.33%, tr:  83.86%, tr_best:  83.86%\n",
      "epoch-70  lr=['0.0001000'], tr/val_loss:  0.754694/  1.182374, val:  66.67%, val_best:  68.33%, tr:  83.86%, tr_best:  83.86%\n",
      "epoch-71  lr=['0.0001000'], tr/val_loss:  0.752089/  1.183625, val:  66.25%, val_best:  68.33%, tr:  84.17%, tr_best:  84.17%\n",
      "epoch-72  lr=['0.0001000'], tr/val_loss:  0.743460/  1.180606, val:  67.08%, val_best:  68.33%, tr:  82.53%, tr_best:  84.17%\n",
      "epoch-73  lr=['0.0001000'], tr/val_loss:  0.740121/  1.181429, val:  66.67%, val_best:  68.33%, tr:  85.29%, tr_best:  85.29%\n",
      "epoch-74  lr=['0.0001000'], tr/val_loss:  0.734561/  1.177730, val:  67.08%, val_best:  68.33%, tr:  84.37%, tr_best:  85.29%\n",
      "epoch-75  lr=['0.0001000'], tr/val_loss:  0.731607/  1.175144, val:  67.08%, val_best:  68.33%, tr:  85.39%, tr_best:  85.39%\n",
      "epoch-76  lr=['0.0001000'], tr/val_loss:  0.719811/  1.180287, val:  66.25%, val_best:  68.33%, tr:  85.39%, tr_best:  85.39%\n",
      "epoch-77  lr=['0.0001000'], tr/val_loss:  0.726341/  1.175391, val:  66.67%, val_best:  68.33%, tr:  85.39%, tr_best:  85.39%\n",
      "epoch-78  lr=['0.0001000'], tr/val_loss:  0.719579/  1.173690, val:  66.67%, val_best:  68.33%, tr:  85.90%, tr_best:  85.90%\n",
      "epoch-79  lr=['0.0001000'], tr/val_loss:  0.717962/  1.172370, val:  67.92%, val_best:  68.33%, tr:  86.41%, tr_best:  86.41%\n",
      "epoch-80  lr=['0.0001000'], tr/val_loss:  0.708885/  1.175632, val:  67.92%, val_best:  68.33%, tr:  86.82%, tr_best:  86.82%\n",
      "epoch-81  lr=['0.0001000'], tr/val_loss:  0.706898/  1.173984, val:  66.25%, val_best:  68.33%, tr:  87.13%, tr_best:  87.13%\n",
      "epoch-82  lr=['0.0001000'], tr/val_loss:  0.700270/  1.171657, val:  66.25%, val_best:  68.33%, tr:  87.44%, tr_best:  87.44%\n",
      "epoch-83  lr=['0.0001000'], tr/val_loss:  0.699782/  1.172514, val:  67.08%, val_best:  68.33%, tr:  87.64%, tr_best:  87.64%\n",
      "epoch-84  lr=['0.0001000'], tr/val_loss:  0.699522/  1.176734, val:  66.67%, val_best:  68.33%, tr:  87.64%, tr_best:  87.64%\n",
      "epoch-85  lr=['0.0001000'], tr/val_loss:  0.698217/  1.175672, val:  67.50%, val_best:  68.33%, tr:  87.44%, tr_best:  87.64%\n",
      "epoch-86  lr=['0.0001000'], tr/val_loss:  0.686921/  1.175620, val:  68.75%, val_best:  68.75%, tr:  86.93%, tr_best:  87.64%\n",
      "epoch-87  lr=['0.0001000'], tr/val_loss:  0.683143/  1.174316, val:  67.50%, val_best:  68.75%, tr:  88.25%, tr_best:  88.25%\n",
      "epoch-88  lr=['0.0001000'], tr/val_loss:  0.682398/  1.186219, val:  67.08%, val_best:  68.75%, tr:  88.66%, tr_best:  88.66%\n",
      "epoch-89  lr=['0.0001000'], tr/val_loss:  0.672029/  1.186324, val:  66.67%, val_best:  68.75%, tr:  88.76%, tr_best:  88.76%\n",
      "epoch-90  lr=['0.0001000'], tr/val_loss:  0.674710/  1.183021, val:  67.92%, val_best:  68.75%, tr:  88.66%, tr_best:  88.76%\n",
      "epoch-91  lr=['0.0001000'], tr/val_loss:  0.661651/  1.183720, val:  67.50%, val_best:  68.75%, tr:  88.87%, tr_best:  88.87%\n",
      "epoch-92  lr=['0.0001000'], tr/val_loss:  0.665182/  1.181565, val:  67.08%, val_best:  68.75%, tr:  89.17%, tr_best:  89.17%\n",
      "epoch-93  lr=['0.0001000'], tr/val_loss:  0.664376/  1.182841, val:  68.33%, val_best:  68.75%, tr:  89.99%, tr_best:  89.99%\n",
      "epoch-94  lr=['0.0001000'], tr/val_loss:  0.658183/  1.180402, val:  70.00%, val_best:  70.00%, tr:  90.40%, tr_best:  90.40%\n",
      "epoch-95  lr=['0.0001000'], tr/val_loss:  0.648832/  1.183708, val:  66.67%, val_best:  70.00%, tr:  89.79%, tr_best:  90.40%\n",
      "epoch-96  lr=['0.0001000'], tr/val_loss:  0.649422/  1.187638, val:  68.33%, val_best:  70.00%, tr:  90.30%, tr_best:  90.40%\n",
      "epoch-97  lr=['0.0001000'], tr/val_loss:  0.639003/  1.183171, val:  70.83%, val_best:  70.83%, tr:  89.27%, tr_best:  90.40%\n",
      "epoch-98  lr=['0.0001000'], tr/val_loss:  0.639805/  1.179547, val:  69.17%, val_best:  70.83%, tr:  90.70%, tr_best:  90.70%\n",
      "epoch-99  lr=['0.0001000'], tr/val_loss:  0.633682/  1.184387, val:  70.00%, val_best:  70.83%, tr:  89.17%, tr_best:  90.70%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c19e2a31942d44f7ae82e776855b9c49",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.006 MB of 0.006 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>iter_acc</td><td>▂▃▁▃▄▄▅▄▃▅▅▇▅▅▅▅▇▅▇▅▆▆▅▅█▆▇█▇▆▇▇▆▆▇▆▆▆█▇</td></tr><tr><td>summary_val_acc</td><td>▁▂▄▅▅▆▆▇▆▇▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇█▇█▇██▇█▇▇█▇█▇█</td></tr><tr><td>tr_acc</td><td>▁▂▃▅▅▅▆▆▆▆▆▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇██████████</td></tr><tr><td>tr_epoch_loss</td><td>██▇▅▄▄▄▃▃▃▃▃▃▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_acc_best</td><td>▁▂▄▅▅▆▆▇▇▇▇▇▇▇▇▇▇▇▇█████████████████████</td></tr><tr><td>val_acc_now</td><td>▁▂▄▅▅▆▆▇▆▇▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇█▇█▇██▇█▇▇█▇█▇█</td></tr><tr><td>val_loss</td><td>█▇▆▄▃▃▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>99</td></tr><tr><td>iter_acc</td><td>1.0</td></tr><tr><td>tr_acc</td><td>0.89173</td></tr><tr><td>tr_epoch_loss</td><td>0.63368</td></tr><tr><td>val_acc_best</td><td>0.70833</td></tr><tr><td>val_acc_now</td><td>0.7</td></tr><tr><td>val_loss</td><td>1.18439</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">bumbling-sweep-213</strong> at: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/qljsn2qt' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/qljsn2qt</a><br/> View project at: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>/data2/bh_wandb/wandb/run-20250430_062901-qljsn2qt/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require(\"core\")`! See https://wandb.me/wandb-core for more information."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Sweep Agent: Waiting for job.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Job received.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: cg8ltzwe with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBATCH: 16\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBN_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBPTT_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tDFA_on: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tIMAGE_SIZE: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tOTTT_input_trace_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tTIME: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tUDA_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \talpha_uda: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbias: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcfg: ['M', 'M', 200, 200]\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tchaching_on: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tconvTrue_fcFalse: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdata_path: /data2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tddp_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdenoise_on: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdvs_clipping: 5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdvs_duration: 100000\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepoch_num: 100\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \texclude_class: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \textra_train_dataset: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlast_lif: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.001\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_sg_width: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_decay: 0.5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_init: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_reset: 10000\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_threshold: 0.25\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmerge_polarities: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmy_seed: 42\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnet_print: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_workers: 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer_what: SGD\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tpin_memory: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tpre_trained: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tpre_trained_path: net_save/save_now_net_weights_{unique_name}.pth\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \trate_coding: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tscheduler_name: no\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsingle_step: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsurrogate: hard_sigmoid\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_conv_kernel_size: 3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_conv_padding: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_conv_stride: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_trace_const1: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_trace_const2: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \ttdBN_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \ttrace_on: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \twhich_data: DVS_GESTURE_TONIC\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.19.10 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.17.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/data2/bh_wandb/wandb/run-20250430_063550-cg8ltzwe</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/cg8ltzwe' target=\"_blank\">restful-sweep-215</a></strong> to <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/6pj3lh8j' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/6pj3lh8j</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/6pj3lh8j' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/6pj3lh8j</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/cg8ltzwe' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/cg8ltzwe</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'single_step' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'my_seed' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'TIME' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BATCH' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'IMAGE_SIZE' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'which_data' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'data_path' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'rate_coding' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_init' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_decay' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_threshold' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_reset' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_sg_width' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_conv_kernel_size' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_conv_stride' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_conv_padding' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_trace_const1' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_trace_const2' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'pre_trained' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'convTrue_fcFalse' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'cfg' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'net_print' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'pre_trained_path' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'learning_rate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'epoch_num' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'tdBN_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BN_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'surrogate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BPTT_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'optimizer_what' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'scheduler_name' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'ddp_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'dvs_clipping' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'dvs_duration' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'DFA_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'trace_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'OTTT_input_trace_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'exclude_class' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'merge_polarities' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'denoise_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'extra_train_dataset' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'num_workers' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'chaching_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'pin_memory' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'UDA_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'alpha_uda' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'bias' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'last_lif' was locked by 'sweep' (ignored update).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "param {'devices': '0', 'single_step': True, 'unique_name': 'main', 'my_seed': 42, 'TIME': 10, 'BATCH': 16, 'IMAGE_SIZE': 128, 'which_data': 'DVS_GESTURE_TONIC', 'data_path': '/data2', 'rate_coding': False, 'lif_layer_v_init': 0, 'lif_layer_v_decay': 0.5, 'lif_layer_v_threshold': 0.25, 'lif_layer_v_reset': 10000, 'lif_layer_sg_width': 1, 'synapse_conv_kernel_size': 3, 'synapse_conv_stride': 1, 'synapse_conv_padding': 1, 'synapse_trace_const1': 1, 'synapse_trace_const2': 0, 'pre_trained': False, 'convTrue_fcFalse': False, 'cfg': ['M', 'M', 200, 200], 'net_print': True, 'pre_trained_path': 'net_save/save_now_net_weights_{unique_name}.pth', 'learning_rate': 0.001, 'epoch_num': 100, 'tdBN_on': False, 'BN_on': False, 'surrogate': 'hard_sigmoid', 'BPTT_on': False, 'optimizer_what': 'SGD', 'scheduler_name': 'no', 'ddp_on': False, 'dvs_clipping': 5, 'dvs_duration': 100000, 'DFA_on': True, 'trace_on': True, 'OTTT_input_trace_on': False, 'exclude_class': True, 'merge_polarities': False, 'denoise_on': True, 'extra_train_dataset': 0, 'num_workers': 2, 'chaching_on': True, 'pin_memory': True, 'UDA_on': False, 'alpha_uda': 1, 'bias': True, 'last_lif': False, 'current epoch': 0} \n",
      "\n",
      "dataset_hash = 63cc597115630ec173f3099200061e53\n",
      "cache path exists\n",
      "\n",
      "device ==> cuda\n",
      "\n",
      "DataParallel(\n",
      "  (module): REBORN_MY_SNN_FC(\n",
      "    (layers): REBORN_MY_Sequential(\n",
      "      (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (2): DimChanger_for_FC()\n",
      "      (3): SYNAPSE_FC(in_features=2048, out_features=200, TIME=10, bias=True, sstep=True)\n",
      "      (4): LIF_layer(v_init=0, v_decay=0.5, v_threshold=0.25, v_reset=10000, sg_width=1, surrogate=hard_sigmoid, BPTT_on=False, trace_const1=1, trace_const2=0, TIME=10, sstep=True, trace_on=True)\n",
      "      (5): Feedback_Receiver()\n",
      "      (6): SYNAPSE_FC(in_features=200, out_features=200, TIME=10, bias=True, sstep=True)\n",
      "      (7): LIF_layer(v_init=0, v_decay=0.5, v_threshold=0.25, v_reset=10000, sg_width=1, surrogate=hard_sigmoid, BPTT_on=False, trace_const1=1, trace_const2=0, TIME=10, sstep=True, trace_on=True)\n",
      "      (8): Feedback_Receiver()\n",
      "      (9): SYNAPSE_FC(in_features=200, out_features=10, TIME=10, bias=True, sstep=True)\n",
      "      (DFA_top): Top_Gradient()\n",
      "    )\n",
      "  )\n",
      ")\n",
      "\n",
      "========================================================\n",
      "Trainable parameters: 452,010\n",
      "========================================================\n",
      "\n",
      "epoch-0   lr=['0.0010000'], tr/val_loss:  2.270306/  2.163778, val:  26.25%, val_best:  26.25%, tr:  11.75%, tr_best:  11.75%\n",
      "[module.layers.5] weight_fb parameter count: 2,000\n",
      "[module.layers.8] weight_fb parameter count: 2,000\n",
      "epoch-1   lr=['0.0010000'], tr/val_loss:  1.900458/  1.750313, val:  52.50%, val_best:  52.50%, tr:  40.14%, tr_best:  40.14%\n",
      "epoch-2   lr=['0.0010000'], tr/val_loss:  1.547570/  1.598625, val:  56.25%, val_best:  56.25%, tr:  57.41%, tr_best:  57.41%\n",
      "epoch-3   lr=['0.0010000'], tr/val_loss:  1.407523/  1.535488, val:  57.50%, val_best:  57.50%, tr:  61.18%, tr_best:  61.18%\n",
      "epoch-4   lr=['0.0010000'], tr/val_loss:  1.335643/  1.504710, val:  60.83%, val_best:  60.83%, tr:  61.90%, tr_best:  61.90%\n",
      "epoch-5   lr=['0.0010000'], tr/val_loss:  1.272357/  1.458155, val:  62.08%, val_best:  62.08%, tr:  63.84%, tr_best:  63.84%\n",
      "epoch-6   lr=['0.0010000'], tr/val_loss:  1.237103/  1.444987, val:  62.08%, val_best:  62.08%, tr:  64.35%, tr_best:  64.35%\n",
      "epoch-7   lr=['0.0010000'], tr/val_loss:  1.204521/  1.408037, val:  60.83%, val_best:  62.08%, tr:  66.60%, tr_best:  66.60%\n",
      "epoch-8   lr=['0.0010000'], tr/val_loss:  1.166575/  1.397674, val:  62.50%, val_best:  62.50%, tr:  66.60%, tr_best:  66.60%\n",
      "epoch-9   lr=['0.0010000'], tr/val_loss:  1.147685/  1.395401, val:  59.58%, val_best:  62.50%, tr:  69.46%, tr_best:  69.46%\n",
      "epoch-10  lr=['0.0010000'], tr/val_loss:  1.121967/  1.396326, val:  59.17%, val_best:  62.50%, tr:  69.25%, tr_best:  69.46%\n",
      "epoch-11  lr=['0.0010000'], tr/val_loss:  1.103052/  1.370950, val:  61.67%, val_best:  62.50%, tr:  68.34%, tr_best:  69.46%\n",
      "epoch-12  lr=['0.0010000'], tr/val_loss:  1.095066/  1.360308, val:  63.75%, val_best:  63.75%, tr:  68.54%, tr_best:  69.46%\n",
      "epoch-13  lr=['0.0010000'], tr/val_loss:  1.080545/  1.347267, val:  63.33%, val_best:  63.75%, tr:  70.38%, tr_best:  70.38%\n",
      "epoch-14  lr=['0.0010000'], tr/val_loss:  1.048573/  1.395936, val:  59.17%, val_best:  63.75%, tr:  69.56%, tr_best:  70.38%\n",
      "epoch-15  lr=['0.0010000'], tr/val_loss:  1.048385/  1.346268, val:  62.50%, val_best:  63.75%, tr:  71.09%, tr_best:  71.09%\n",
      "epoch-16  lr=['0.0010000'], tr/val_loss:  1.035045/  1.336759, val:  62.92%, val_best:  63.75%, tr:  70.58%, tr_best:  71.09%\n",
      "epoch-17  lr=['0.0010000'], tr/val_loss:  1.017158/  1.311127, val:  67.92%, val_best:  67.92%, tr:  74.26%, tr_best:  74.26%\n",
      "epoch-18  lr=['0.0010000'], tr/val_loss:  1.011123/  1.350126, val:  62.50%, val_best:  67.92%, tr:  74.36%, tr_best:  74.36%\n",
      "epoch-19  lr=['0.0010000'], tr/val_loss:  1.005409/  1.334152, val:  60.83%, val_best:  67.92%, tr:  70.58%, tr_best:  74.36%\n",
      "epoch-20  lr=['0.0010000'], tr/val_loss:  0.982527/  1.317477, val:  66.67%, val_best:  67.92%, tr:  74.06%, tr_best:  74.36%\n",
      "epoch-21  lr=['0.0010000'], tr/val_loss:  0.979388/  1.308521, val:  67.50%, val_best:  67.92%, tr:  74.57%, tr_best:  74.57%\n",
      "epoch-22  lr=['0.0010000'], tr/val_loss:  0.981507/  1.332686, val:  63.33%, val_best:  67.92%, tr:  72.93%, tr_best:  74.57%\n",
      "epoch-23  lr=['0.0010000'], tr/val_loss:  0.957867/  1.322754, val:  62.92%, val_best:  67.92%, tr:  74.26%, tr_best:  74.57%\n",
      "epoch-24  lr=['0.0010000'], tr/val_loss:  0.938146/  1.326139, val:  64.17%, val_best:  67.92%, tr:  77.94%, tr_best:  77.94%\n",
      "epoch-25  lr=['0.0010000'], tr/val_loss:  0.943520/  1.303173, val:  66.25%, val_best:  67.92%, tr:  76.00%, tr_best:  77.94%\n",
      "epoch-26  lr=['0.0010000'], tr/val_loss:  0.936586/  1.300667, val:  64.58%, val_best:  67.92%, tr:  74.87%, tr_best:  77.94%\n",
      "epoch-27  lr=['0.0010000'], tr/val_loss:  0.914859/  1.329099, val:  62.50%, val_best:  67.92%, tr:  79.16%, tr_best:  79.16%\n",
      "epoch-28  lr=['0.0010000'], tr/val_loss:  0.914797/  1.290783, val:  67.92%, val_best:  67.92%, tr:  78.04%, tr_best:  79.16%\n",
      "epoch-29  lr=['0.0010000'], tr/val_loss:  0.896026/  1.321613, val:  61.67%, val_best:  67.92%, tr:  80.08%, tr_best:  80.08%\n",
      "epoch-30  lr=['0.0010000'], tr/val_loss:  0.892514/  1.312131, val:  61.67%, val_best:  67.92%, tr:  81.00%, tr_best:  81.00%\n",
      "epoch-31  lr=['0.0010000'], tr/val_loss:  0.905273/  1.340049, val:  61.67%, val_best:  67.92%, tr:  77.32%, tr_best:  81.00%\n",
      "epoch-32  lr=['0.0010000'], tr/val_loss:  0.887955/  1.323148, val:  62.08%, val_best:  67.92%, tr:  79.88%, tr_best:  81.00%\n",
      "epoch-33  lr=['0.0010000'], tr/val_loss:  0.874939/  1.345428, val:  66.67%, val_best:  67.92%, tr:  82.12%, tr_best:  82.12%\n",
      "epoch-34  lr=['0.0010000'], tr/val_loss:  0.862426/  1.338186, val:  65.00%, val_best:  67.92%, tr:  80.59%, tr_best:  82.12%\n",
      "epoch-35  lr=['0.0010000'], tr/val_loss:  0.870964/  1.344460, val:  65.42%, val_best:  67.92%, tr:  80.59%, tr_best:  82.12%\n",
      "epoch-36  lr=['0.0010000'], tr/val_loss:  0.842716/  1.332763, val:  66.67%, val_best:  67.92%, tr:  82.74%, tr_best:  82.74%\n",
      "epoch-37  lr=['0.0010000'], tr/val_loss:  0.852091/  1.326181, val:  67.08%, val_best:  67.92%, tr:  84.88%, tr_best:  84.88%\n",
      "epoch-38  lr=['0.0010000'], tr/val_loss:  0.845138/  1.322604, val:  69.17%, val_best:  69.17%, tr:  84.27%, tr_best:  84.88%\n",
      "epoch-39  lr=['0.0010000'], tr/val_loss:  0.833200/  1.329200, val:  64.17%, val_best:  69.17%, tr:  86.01%, tr_best:  86.01%\n",
      "epoch-40  lr=['0.0010000'], tr/val_loss:  0.832923/  1.336820, val:  65.83%, val_best:  69.17%, tr:  84.58%, tr_best:  86.01%\n",
      "epoch-41  lr=['0.0010000'], tr/val_loss:  0.822696/  1.345672, val:  65.83%, val_best:  69.17%, tr:  86.93%, tr_best:  86.93%\n",
      "epoch-42  lr=['0.0010000'], tr/val_loss:  0.820472/  1.339002, val:  64.17%, val_best:  69.17%, tr:  85.09%, tr_best:  86.93%\n",
      "epoch-43  lr=['0.0010000'], tr/val_loss:  0.805753/  1.360670, val:  67.92%, val_best:  69.17%, tr:  86.52%, tr_best:  86.93%\n",
      "epoch-44  lr=['0.0010000'], tr/val_loss:  0.807334/  1.345130, val:  67.92%, val_best:  69.17%, tr:  85.70%, tr_best:  86.93%\n",
      "epoch-45  lr=['0.0010000'], tr/val_loss:  0.797568/  1.340272, val:  68.33%, val_best:  69.17%, tr:  86.62%, tr_best:  86.93%\n",
      "epoch-46  lr=['0.0010000'], tr/val_loss:  0.790684/  1.358526, val:  66.67%, val_best:  69.17%, tr:  87.74%, tr_best:  87.74%\n",
      "epoch-47  lr=['0.0010000'], tr/val_loss:  0.787241/  1.356203, val:  67.50%, val_best:  69.17%, tr:  87.84%, tr_best:  87.84%\n",
      "epoch-48  lr=['0.0010000'], tr/val_loss:  0.794696/  1.350355, val:  69.17%, val_best:  69.17%, tr:  90.09%, tr_best:  90.09%\n",
      "epoch-49  lr=['0.0010000'], tr/val_loss:  0.793579/  1.342504, val:  68.33%, val_best:  69.17%, tr:  86.72%, tr_best:  90.09%\n",
      "epoch-50  lr=['0.0010000'], tr/val_loss:  0.787115/  1.358008, val:  69.17%, val_best:  69.17%, tr:  88.66%, tr_best:  90.09%\n",
      "epoch-51  lr=['0.0010000'], tr/val_loss:  0.781443/  1.373490, val:  67.08%, val_best:  69.17%, tr:  87.84%, tr_best:  90.09%\n",
      "epoch-52  lr=['0.0010000'], tr/val_loss:  0.767366/  1.403645, val:  64.58%, val_best:  69.17%, tr:  87.44%, tr_best:  90.09%\n",
      "epoch-53  lr=['0.0010000'], tr/val_loss:  0.772246/  1.356492, val:  67.08%, val_best:  69.17%, tr:  87.44%, tr_best:  90.09%\n",
      "epoch-54  lr=['0.0010000'], tr/val_loss:  0.764991/  1.385389, val:  67.50%, val_best:  69.17%, tr:  89.68%, tr_best:  90.09%\n",
      "epoch-55  lr=['0.0010000'], tr/val_loss:  0.766094/  1.382858, val:  67.92%, val_best:  69.17%, tr:  87.74%, tr_best:  90.09%\n",
      "epoch-56  lr=['0.0010000'], tr/val_loss:  0.760705/  1.424356, val:  67.08%, val_best:  69.17%, tr:  89.17%, tr_best:  90.09%\n",
      "epoch-57  lr=['0.0010000'], tr/val_loss:  0.762481/  1.380894, val:  67.08%, val_best:  69.17%, tr:  88.97%, tr_best:  90.09%\n",
      "epoch-58  lr=['0.0010000'], tr/val_loss:  0.739720/  1.400695, val:  66.67%, val_best:  69.17%, tr:  89.58%, tr_best:  90.09%\n",
      "epoch-59  lr=['0.0010000'], tr/val_loss:  0.742840/  1.379439, val:  70.42%, val_best:  70.42%, tr:  89.38%, tr_best:  90.09%\n",
      "epoch-60  lr=['0.0010000'], tr/val_loss:  0.742371/  1.367163, val:  67.50%, val_best:  70.42%, tr:  90.81%, tr_best:  90.81%\n",
      "epoch-61  lr=['0.0010000'], tr/val_loss:  0.739193/  1.394047, val:  68.75%, val_best:  70.42%, tr:  90.09%, tr_best:  90.81%\n",
      "epoch-62  lr=['0.0010000'], tr/val_loss:  0.740467/  1.408408, val:  67.08%, val_best:  70.42%, tr:  90.09%, tr_best:  90.81%\n",
      "epoch-63  lr=['0.0010000'], tr/val_loss:  0.732710/  1.370149, val:  67.92%, val_best:  70.42%, tr:  91.93%, tr_best:  91.93%\n",
      "epoch-64  lr=['0.0010000'], tr/val_loss:  0.732389/  1.442714, val:  65.83%, val_best:  70.42%, tr:  90.60%, tr_best:  91.93%\n",
      "epoch-65  lr=['0.0010000'], tr/val_loss:  0.728885/  1.403430, val:  69.17%, val_best:  70.42%, tr:  90.60%, tr_best:  91.93%\n",
      "epoch-66  lr=['0.0010000'], tr/val_loss:  0.726669/  1.386374, val:  69.17%, val_best:  70.42%, tr:  90.81%, tr_best:  91.93%\n",
      "epoch-67  lr=['0.0010000'], tr/val_loss:  0.731075/  1.395202, val:  70.83%, val_best:  70.83%, tr:  91.11%, tr_best:  91.93%\n",
      "epoch-68  lr=['0.0010000'], tr/val_loss:  0.714254/  1.403214, val:  68.75%, val_best:  70.83%, tr:  90.50%, tr_best:  91.93%\n",
      "epoch-69  lr=['0.0010000'], tr/val_loss:  0.719445/  1.402364, val:  65.83%, val_best:  70.83%, tr:  91.93%, tr_best:  91.93%\n",
      "epoch-70  lr=['0.0010000'], tr/val_loss:  0.711303/  1.402334, val:  68.33%, val_best:  70.83%, tr:  91.62%, tr_best:  91.93%\n",
      "epoch-71  lr=['0.0010000'], tr/val_loss:  0.704909/  1.462035, val:  65.83%, val_best:  70.83%, tr:  91.83%, tr_best:  91.93%\n",
      "epoch-72  lr=['0.0010000'], tr/val_loss:  0.702362/  1.455827, val:  65.42%, val_best:  70.83%, tr:  92.65%, tr_best:  92.65%\n",
      "epoch-73  lr=['0.0010000'], tr/val_loss:  0.713248/  1.420898, val:  70.00%, val_best:  70.83%, tr:  90.40%, tr_best:  92.65%\n",
      "epoch-74  lr=['0.0010000'], tr/val_loss:  0.696053/  1.428615, val:  67.08%, val_best:  70.83%, tr:  93.26%, tr_best:  93.26%\n",
      "epoch-75  lr=['0.0010000'], tr/val_loss:  0.700552/  1.445522, val:  65.42%, val_best:  70.83%, tr:  91.11%, tr_best:  93.26%\n",
      "epoch-76  lr=['0.0010000'], tr/val_loss:  0.687419/  1.468625, val:  67.08%, val_best:  70.83%, tr:  91.93%, tr_best:  93.26%\n",
      "epoch-77  lr=['0.0010000'], tr/val_loss:  0.705423/  1.459609, val:  65.83%, val_best:  70.83%, tr:  91.52%, tr_best:  93.26%\n",
      "epoch-78  lr=['0.0010000'], tr/val_loss:  0.702876/  1.449637, val:  65.83%, val_best:  70.83%, tr:  91.11%, tr_best:  93.26%\n",
      "epoch-79  lr=['0.0010000'], tr/val_loss:  0.687894/  1.429662, val:  67.50%, val_best:  70.83%, tr:  92.13%, tr_best:  93.26%\n",
      "epoch-80  lr=['0.0010000'], tr/val_loss:  0.675603/  1.459595, val:  67.92%, val_best:  70.83%, tr:  92.65%, tr_best:  93.26%\n",
      "epoch-81  lr=['0.0010000'], tr/val_loss:  0.685795/  1.430127, val:  67.08%, val_best:  70.83%, tr:  92.24%, tr_best:  93.26%\n",
      "epoch-82  lr=['0.0010000'], tr/val_loss:  0.684002/  1.462995, val:  66.25%, val_best:  70.83%, tr:  92.13%, tr_best:  93.26%\n",
      "epoch-83  lr=['0.0010000'], tr/val_loss:  0.679428/  1.458654, val:  70.42%, val_best:  70.83%, tr:  92.54%, tr_best:  93.26%\n",
      "epoch-84  lr=['0.0010000'], tr/val_loss:  0.684194/  1.435114, val:  67.92%, val_best:  70.83%, tr:  93.87%, tr_best:  93.87%\n",
      "epoch-85  lr=['0.0010000'], tr/val_loss:  0.671389/  1.469934, val:  63.75%, val_best:  70.83%, tr:  94.18%, tr_best:  94.18%\n",
      "epoch-86  lr=['0.0010000'], tr/val_loss:  0.668378/  1.456429, val:  69.17%, val_best:  70.83%, tr:  92.34%, tr_best:  94.18%\n",
      "epoch-87  lr=['0.0010000'], tr/val_loss:  0.668733/  1.484133, val:  68.33%, val_best:  70.83%, tr:  94.08%, tr_best:  94.18%\n",
      "epoch-88  lr=['0.0010000'], tr/val_loss:  0.661195/  1.467824, val:  67.50%, val_best:  70.83%, tr:  93.46%, tr_best:  94.18%\n",
      "epoch-89  lr=['0.0010000'], tr/val_loss:  0.654995/  1.504701, val:  66.67%, val_best:  70.83%, tr:  93.97%, tr_best:  94.18%\n",
      "epoch-90  lr=['0.0010000'], tr/val_loss:  0.659697/  1.446663, val:  68.33%, val_best:  70.83%, tr:  93.97%, tr_best:  94.18%\n",
      "epoch-91  lr=['0.0010000'], tr/val_loss:  0.657555/  1.482988, val:  66.67%, val_best:  70.83%, tr:  93.26%, tr_best:  94.18%\n",
      "epoch-92  lr=['0.0010000'], tr/val_loss:  0.651710/  1.529077, val:  63.75%, val_best:  70.83%, tr:  93.05%, tr_best:  94.18%\n",
      "epoch-93  lr=['0.0010000'], tr/val_loss:  0.650787/  1.489415, val:  68.33%, val_best:  70.83%, tr:  93.67%, tr_best:  94.18%\n",
      "epoch-94  lr=['0.0010000'], tr/val_loss:  0.654612/  1.542794, val:  65.42%, val_best:  70.83%, tr:  93.36%, tr_best:  94.18%\n",
      "epoch-95  lr=['0.0010000'], tr/val_loss:  0.658225/  1.555622, val:  64.58%, val_best:  70.83%, tr:  93.05%, tr_best:  94.18%\n",
      "epoch-96  lr=['0.0010000'], tr/val_loss:  0.658700/  1.589399, val:  67.92%, val_best:  70.83%, tr:  92.85%, tr_best:  94.18%\n",
      "epoch-97  lr=['0.0010000'], tr/val_loss:  0.657821/  1.514124, val:  67.08%, val_best:  70.83%, tr:  91.01%, tr_best:  94.18%\n",
      "epoch-98  lr=['0.0010000'], tr/val_loss:  0.643226/  1.534510, val:  65.42%, val_best:  70.83%, tr:  93.56%, tr_best:  94.18%\n",
      "epoch-99  lr=['0.0010000'], tr/val_loss:  0.661665/  1.529029, val:  65.00%, val_best:  70.83%, tr:  92.65%, tr_best:  94.18%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6a49e508697646c28e1996ad620c1f22",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.006 MB of 0.006 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>iter_acc</td><td>▂▆▃▃▃▅▆▁▃▅▄▇▅▆▅▇█▇▇▇██▇▇██▇██▅██▅▇▆▇▇▇█▇</td></tr><tr><td>summary_val_acc</td><td>▁▆▆▆▆▇▆█▆▇▇▇▇▇▇▇▇▇█▇█▇▇▇█████▇▇▇▇▇██▇▇▇▇</td></tr><tr><td>tr_acc</td><td>▁▅▅▆▆▆▆▆▆▆▇▆▇▇▇▇▇▇▇▇▇▇██████████████████</td></tr><tr><td>tr_epoch_loss</td><td>█▅▄▃▃▃▃▃▃▂▂▂▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_acc_best</td><td>▁▆▆▇▇▇▇█████████████████████████████████</td></tr><tr><td>val_acc_now</td><td>▁▆▆▆▆▇▆█▆▇▇▇▇▇▇▇▇▇█▇█▇▇▇█████▇▇▇▇▇██▇▇▇▇</td></tr><tr><td>val_loss</td><td>█▃▃▂▂▁▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▃▃▃▃</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>99</td></tr><tr><td>iter_acc</td><td>1.0</td></tr><tr><td>tr_acc</td><td>0.92646</td></tr><tr><td>tr_epoch_loss</td><td>0.66167</td></tr><tr><td>val_acc_best</td><td>0.70833</td></tr><tr><td>val_acc_now</td><td>0.65</td></tr><tr><td>val_loss</td><td>1.52903</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">restful-sweep-215</strong> at: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/cg8ltzwe' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/cg8ltzwe</a><br/> View project at: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>/data2/bh_wandb/wandb/run-20250430_063550-cg8ltzwe/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require(\"core\")`! See https://wandb.me/wandb-core for more information."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Sweep Agent: Waiting for job.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Job received.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: if37kz0i with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBATCH: 16\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBN_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBPTT_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tDFA_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tIMAGE_SIZE: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tOTTT_input_trace_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tTIME: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tUDA_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \talpha_uda: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbias: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcfg: ['M', 'M', 200, 200]\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tchaching_on: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tconvTrue_fcFalse: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdata_path: /data2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tddp_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdenoise_on: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdvs_clipping: 5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdvs_duration: 100000\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepoch_num: 100\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \texclude_class: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \textra_train_dataset: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlast_lif: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.001\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_sg_width: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_decay: 0.5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_init: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_reset: 10000\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_threshold: 0.25\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmerge_polarities: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmy_seed: 42\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnet_print: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_workers: 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer_what: SGD\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tpin_memory: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tpre_trained: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tpre_trained_path: net_save/save_now_net_weights_{unique_name}.pth\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \trate_coding: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tscheduler_name: no\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsingle_step: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsurrogate: hard_sigmoid\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_conv_kernel_size: 3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_conv_padding: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_conv_stride: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_trace_const1: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_trace_const2: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \ttdBN_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \ttrace_on: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \twhich_data: DVS_GESTURE_TONIC\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6efaf38770074f9fa0ad02b2e15a2d59",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.011113643842852778, max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.19.10 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.17.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/data2/bh_wandb/wandb/run-20250430_064244-if37kz0i</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/if37kz0i' target=\"_blank\">feasible-sweep-217</a></strong> to <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/6pj3lh8j' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/6pj3lh8j</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/6pj3lh8j' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/6pj3lh8j</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/if37kz0i' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/if37kz0i</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'single_step' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'my_seed' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'TIME' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BATCH' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'IMAGE_SIZE' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'which_data' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'data_path' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'rate_coding' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_init' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_decay' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_threshold' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_reset' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_sg_width' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_conv_kernel_size' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_conv_stride' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_conv_padding' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_trace_const1' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_trace_const2' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'pre_trained' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'convTrue_fcFalse' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'cfg' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'net_print' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'pre_trained_path' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'learning_rate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'epoch_num' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'tdBN_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BN_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'surrogate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BPTT_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'optimizer_what' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'scheduler_name' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'ddp_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'dvs_clipping' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'dvs_duration' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'DFA_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'trace_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'OTTT_input_trace_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'exclude_class' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'merge_polarities' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'denoise_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'extra_train_dataset' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'num_workers' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'chaching_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'pin_memory' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'UDA_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'alpha_uda' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'bias' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'last_lif' was locked by 'sweep' (ignored update).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "param {'devices': '0', 'single_step': True, 'unique_name': 'main', 'my_seed': 42, 'TIME': 10, 'BATCH': 16, 'IMAGE_SIZE': 128, 'which_data': 'DVS_GESTURE_TONIC', 'data_path': '/data2', 'rate_coding': False, 'lif_layer_v_init': 0, 'lif_layer_v_decay': 0.5, 'lif_layer_v_threshold': 0.25, 'lif_layer_v_reset': 10000, 'lif_layer_sg_width': 1, 'synapse_conv_kernel_size': 3, 'synapse_conv_stride': 1, 'synapse_conv_padding': 1, 'synapse_trace_const1': 1, 'synapse_trace_const2': 0, 'pre_trained': False, 'convTrue_fcFalse': False, 'cfg': ['M', 'M', 200, 200], 'net_print': True, 'pre_trained_path': 'net_save/save_now_net_weights_{unique_name}.pth', 'learning_rate': 0.001, 'epoch_num': 100, 'tdBN_on': False, 'BN_on': False, 'surrogate': 'hard_sigmoid', 'BPTT_on': False, 'optimizer_what': 'SGD', 'scheduler_name': 'no', 'ddp_on': False, 'dvs_clipping': 5, 'dvs_duration': 100000, 'DFA_on': False, 'trace_on': True, 'OTTT_input_trace_on': False, 'exclude_class': True, 'merge_polarities': False, 'denoise_on': True, 'extra_train_dataset': 0, 'num_workers': 2, 'chaching_on': True, 'pin_memory': True, 'UDA_on': False, 'alpha_uda': 1, 'bias': True, 'last_lif': False, 'current epoch': 0} \n",
      "\n",
      "dataset_hash = 63cc597115630ec173f3099200061e53\n",
      "cache path exists\n",
      "\n",
      "device ==> cuda\n",
      "\n",
      "DataParallel(\n",
      "  (module): REBORN_MY_SNN_FC(\n",
      "    (layers): REBORN_MY_Sequential(\n",
      "      (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (2): DimChanger_for_FC()\n",
      "      (3): SYNAPSE_FC(in_features=2048, out_features=200, TIME=10, bias=True, sstep=True)\n",
      "      (4): LIF_layer(v_init=0, v_decay=0.5, v_threshold=0.25, v_reset=10000, sg_width=1, surrogate=hard_sigmoid, BPTT_on=False, trace_const1=1, trace_const2=0, TIME=10, sstep=True, trace_on=True)\n",
      "      (5): SYNAPSE_FC(in_features=200, out_features=200, TIME=10, bias=True, sstep=True)\n",
      "      (6): LIF_layer(v_init=0, v_decay=0.5, v_threshold=0.25, v_reset=10000, sg_width=1, surrogate=hard_sigmoid, BPTT_on=False, trace_const1=1, trace_const2=0, TIME=10, sstep=True, trace_on=True)\n",
      "      (7): SYNAPSE_FC(in_features=200, out_features=10, TIME=10, bias=True, sstep=True)\n",
      "    )\n",
      "  )\n",
      ")\n",
      "\n",
      "========================================================\n",
      "Trainable parameters: 452,010\n",
      "========================================================\n",
      "\n",
      "epoch-0   lr=['0.0010000'], tr/val_loss:  2.291226/  2.262563, val:  21.67%, val_best:  21.67%, tr:  12.87%, tr_best:  12.87%\n",
      "epoch-1   lr=['0.0010000'], tr/val_loss:  2.226794/  2.197138, val:  30.00%, val_best:  30.00%, tr:  24.92%, tr_best:  24.92%\n",
      "epoch-2   lr=['0.0010000'], tr/val_loss:  2.122399/  2.090609, val:  43.33%, val_best:  43.33%, tr:  32.89%, tr_best:  32.89%\n",
      "epoch-3   lr=['0.0010000'], tr/val_loss:  1.981584/  1.970841, val:  48.33%, val_best:  48.33%, tr:  41.68%, tr_best:  41.68%\n",
      "epoch-4   lr=['0.0010000'], tr/val_loss:  1.838591/  1.864843, val:  52.08%, val_best:  52.08%, tr:  49.03%, tr_best:  49.03%\n",
      "epoch-5   lr=['0.0010000'], tr/val_loss:  1.708440/  1.771031, val:  49.58%, val_best:  52.08%, tr:  53.73%, tr_best:  53.73%\n",
      "epoch-6   lr=['0.0010000'], tr/val_loss:  1.619611/  1.705889, val:  53.33%, val_best:  53.33%, tr:  56.28%, tr_best:  56.28%\n",
      "epoch-7   lr=['0.0010000'], tr/val_loss:  1.546571/  1.663146, val:  55.42%, val_best:  55.42%, tr:  59.55%, tr_best:  59.55%\n",
      "epoch-8   lr=['0.0010000'], tr/val_loss:  1.497638/  1.623710, val:  56.67%, val_best:  56.67%, tr:  60.16%, tr_best:  60.16%\n",
      "epoch-9   lr=['0.0010000'], tr/val_loss:  1.454307/  1.600733, val:  55.00%, val_best:  56.67%, tr:  61.18%, tr_best:  61.18%\n",
      "epoch-10  lr=['0.0010000'], tr/val_loss:  1.419487/  1.571013, val:  58.75%, val_best:  58.75%, tr:  60.47%, tr_best:  61.18%\n",
      "epoch-11  lr=['0.0010000'], tr/val_loss:  1.388129/  1.559669, val:  56.25%, val_best:  58.75%, tr:  61.39%, tr_best:  61.39%\n",
      "epoch-12  lr=['0.0010000'], tr/val_loss:  1.370566/  1.545035, val:  60.00%, val_best:  60.00%, tr:  61.80%, tr_best:  61.80%\n",
      "epoch-13  lr=['0.0010000'], tr/val_loss:  1.345960/  1.527287, val:  57.50%, val_best:  60.00%, tr:  65.37%, tr_best:  65.37%\n",
      "epoch-14  lr=['0.0010000'], tr/val_loss:  1.312908/  1.510120, val:  55.83%, val_best:  60.00%, tr:  63.23%, tr_best:  65.37%\n",
      "epoch-15  lr=['0.0010000'], tr/val_loss:  1.302367/  1.505145, val:  58.33%, val_best:  60.00%, tr:  62.41%, tr_best:  65.37%\n",
      "epoch-16  lr=['0.0010000'], tr/val_loss:  1.280016/  1.494407, val:  55.42%, val_best:  60.00%, tr:  64.35%, tr_best:  65.37%\n",
      "epoch-17  lr=['0.0010000'], tr/val_loss:  1.262773/  1.468826, val:  59.58%, val_best:  60.00%, tr:  65.99%, tr_best:  65.99%\n",
      "epoch-18  lr=['0.0010000'], tr/val_loss:  1.243869/  1.469148, val:  57.08%, val_best:  60.00%, tr:  66.60%, tr_best:  66.60%\n",
      "epoch-19  lr=['0.0010000'], tr/val_loss:  1.234196/  1.453676, val:  57.08%, val_best:  60.00%, tr:  64.15%, tr_best:  66.60%\n",
      "epoch-20  lr=['0.0010000'], tr/val_loss:  1.206181/  1.445538, val:  58.33%, val_best:  60.00%, tr:  66.09%, tr_best:  66.60%\n",
      "epoch-21  lr=['0.0010000'], tr/val_loss:  1.194310/  1.433717, val:  61.25%, val_best:  61.25%, tr:  67.62%, tr_best:  67.62%\n",
      "epoch-22  lr=['0.0010000'], tr/val_loss:  1.190008/  1.437136, val:  58.75%, val_best:  61.25%, tr:  65.17%, tr_best:  67.62%\n",
      "epoch-23  lr=['0.0010000'], tr/val_loss:  1.171175/  1.427524, val:  62.08%, val_best:  62.08%, tr:  69.15%, tr_best:  69.15%\n",
      "epoch-24  lr=['0.0010000'], tr/val_loss:  1.149975/  1.414636, val:  59.58%, val_best:  62.08%, tr:  69.77%, tr_best:  69.77%\n",
      "epoch-25  lr=['0.0010000'], tr/val_loss:  1.145411/  1.407644, val:  63.75%, val_best:  63.75%, tr:  69.15%, tr_best:  69.77%\n",
      "epoch-26  lr=['0.0010000'], tr/val_loss:  1.133959/  1.392657, val:  64.17%, val_best:  64.17%, tr:  68.95%, tr_best:  69.77%\n",
      "epoch-27  lr=['0.0010000'], tr/val_loss:  1.117488/  1.402194, val:  61.25%, val_best:  64.17%, tr:  71.81%, tr_best:  71.81%\n",
      "epoch-28  lr=['0.0010000'], tr/val_loss:  1.114650/  1.384160, val:  61.67%, val_best:  64.17%, tr:  69.77%, tr_best:  71.81%\n",
      "epoch-29  lr=['0.0010000'], tr/val_loss:  1.096739/  1.380825, val:  58.75%, val_best:  64.17%, tr:  70.79%, tr_best:  71.81%\n",
      "epoch-30  lr=['0.0010000'], tr/val_loss:  1.091045/  1.371749, val:  60.83%, val_best:  64.17%, tr:  69.77%, tr_best:  71.81%\n",
      "epoch-31  lr=['0.0010000'], tr/val_loss:  1.081943/  1.377722, val:  62.50%, val_best:  64.17%, tr:  70.99%, tr_best:  71.81%\n",
      "epoch-32  lr=['0.0010000'], tr/val_loss:  1.069469/  1.389074, val:  61.25%, val_best:  64.17%, tr:  73.95%, tr_best:  73.95%\n",
      "epoch-33  lr=['0.0010000'], tr/val_loss:  1.063368/  1.375488, val:  62.50%, val_best:  64.17%, tr:  72.73%, tr_best:  73.95%\n",
      "epoch-34  lr=['0.0010000'], tr/val_loss:  1.052292/  1.350606, val:  64.58%, val_best:  64.58%, tr:  72.42%, tr_best:  73.95%\n",
      "epoch-35  lr=['0.0010000'], tr/val_loss:  1.038437/  1.369132, val:  61.25%, val_best:  64.58%, tr:  73.03%, tr_best:  73.95%\n",
      "epoch-36  lr=['0.0010000'], tr/val_loss:  1.033957/  1.362166, val:  60.42%, val_best:  64.58%, tr:  73.75%, tr_best:  73.95%\n",
      "epoch-37  lr=['0.0010000'], tr/val_loss:  1.028793/  1.338969, val:  64.58%, val_best:  64.58%, tr:  75.28%, tr_best:  75.28%\n",
      "epoch-38  lr=['0.0010000'], tr/val_loss:  1.021361/  1.322225, val:  65.00%, val_best:  65.00%, tr:  75.49%, tr_best:  75.49%\n",
      "epoch-39  lr=['0.0010000'], tr/val_loss:  1.011171/  1.323596, val:  67.50%, val_best:  67.50%, tr:  74.77%, tr_best:  75.49%\n",
      "epoch-40  lr=['0.0010000'], tr/val_loss:  0.996047/  1.330288, val:  64.17%, val_best:  67.50%, tr:  73.75%, tr_best:  75.49%\n",
      "epoch-41  lr=['0.0010000'], tr/val_loss:  0.994030/  1.319227, val:  65.83%, val_best:  67.50%, tr:  78.45%, tr_best:  78.45%\n",
      "epoch-42  lr=['0.0010000'], tr/val_loss:  0.978745/  1.313682, val:  64.58%, val_best:  67.50%, tr:  77.22%, tr_best:  78.45%\n",
      "epoch-43  lr=['0.0010000'], tr/val_loss:  0.976769/  1.314901, val:  63.33%, val_best:  67.50%, tr:  75.69%, tr_best:  78.45%\n",
      "epoch-44  lr=['0.0010000'], tr/val_loss:  0.973642/  1.312907, val:  68.33%, val_best:  68.33%, tr:  74.16%, tr_best:  78.45%\n",
      "epoch-45  lr=['0.0010000'], tr/val_loss:  0.957314/  1.300470, val:  66.25%, val_best:  68.33%, tr:  77.73%, tr_best:  78.45%\n",
      "epoch-46  lr=['0.0010000'], tr/val_loss:  0.953706/  1.316113, val:  67.08%, val_best:  68.33%, tr:  78.04%, tr_best:  78.45%\n",
      "epoch-47  lr=['0.0010000'], tr/val_loss:  0.949879/  1.311043, val:  65.00%, val_best:  68.33%, tr:  76.61%, tr_best:  78.45%\n",
      "epoch-48  lr=['0.0010000'], tr/val_loss:  0.951113/  1.311507, val:  67.50%, val_best:  68.33%, tr:  80.29%, tr_best:  80.29%\n",
      "epoch-49  lr=['0.0010000'], tr/val_loss:  0.942748/  1.294629, val:  65.42%, val_best:  68.33%, tr:  75.59%, tr_best:  80.29%\n",
      "epoch-50  lr=['0.0010000'], tr/val_loss:  0.929699/  1.307492, val:  65.00%, val_best:  68.33%, tr:  79.57%, tr_best:  80.29%\n",
      "epoch-51  lr=['0.0010000'], tr/val_loss:  0.924737/  1.313879, val:  68.33%, val_best:  68.33%, tr:  77.83%, tr_best:  80.29%\n",
      "epoch-52  lr=['0.0010000'], tr/val_loss:  0.920991/  1.313448, val:  60.83%, val_best:  68.33%, tr:  78.14%, tr_best:  80.29%\n",
      "epoch-53  lr=['0.0010000'], tr/val_loss:  0.918137/  1.294773, val:  67.92%, val_best:  68.33%, tr:  77.73%, tr_best:  80.29%\n",
      "epoch-54  lr=['0.0010000'], tr/val_loss:  0.910030/  1.311904, val:  66.67%, val_best:  68.33%, tr:  80.49%, tr_best:  80.49%\n",
      "epoch-55  lr=['0.0010000'], tr/val_loss:  0.899498/  1.316216, val:  67.92%, val_best:  68.33%, tr:  79.26%, tr_best:  80.49%\n",
      "epoch-56  lr=['0.0010000'], tr/val_loss:  0.889800/  1.316038, val:  64.17%, val_best:  68.33%, tr:  83.15%, tr_best:  83.15%\n",
      "epoch-57  lr=['0.0010000'], tr/val_loss:  0.893640/  1.301918, val:  63.33%, val_best:  68.33%, tr:  82.23%, tr_best:  83.15%\n",
      "epoch-58  lr=['0.0010000'], tr/val_loss:  0.875685/  1.327973, val:  63.75%, val_best:  68.33%, tr:  80.18%, tr_best:  83.15%\n",
      "epoch-59  lr=['0.0010000'], tr/val_loss:  0.881230/  1.308731, val:  69.17%, val_best:  69.17%, tr:  80.90%, tr_best:  83.15%\n",
      "epoch-60  lr=['0.0010000'], tr/val_loss:  0.876863/  1.307161, val:  65.83%, val_best:  69.17%, tr:  79.67%, tr_best:  83.15%\n",
      "epoch-61  lr=['0.0010000'], tr/val_loss:  0.872204/  1.323400, val:  65.83%, val_best:  69.17%, tr:  82.33%, tr_best:  83.15%\n",
      "epoch-62  lr=['0.0010000'], tr/val_loss:  0.869627/  1.319818, val:  67.92%, val_best:  69.17%, tr:  84.17%, tr_best:  84.17%\n",
      "epoch-63  lr=['0.0010000'], tr/val_loss:  0.859880/  1.300537, val:  68.33%, val_best:  69.17%, tr:  84.47%, tr_best:  84.47%\n",
      "epoch-64  lr=['0.0010000'], tr/val_loss:  0.846593/  1.354111, val:  63.33%, val_best:  69.17%, tr:  83.86%, tr_best:  84.47%\n",
      "epoch-65  lr=['0.0010000'], tr/val_loss:  0.848980/  1.343405, val:  64.58%, val_best:  69.17%, tr:  82.74%, tr_best:  84.47%\n",
      "epoch-66  lr=['0.0010000'], tr/val_loss:  0.848458/  1.317158, val:  70.42%, val_best:  70.42%, tr:  82.33%, tr_best:  84.47%\n",
      "epoch-67  lr=['0.0010000'], tr/val_loss:  0.852612/  1.330100, val:  64.58%, val_best:  70.42%, tr:  84.17%, tr_best:  84.47%\n",
      "epoch-68  lr=['0.0010000'], tr/val_loss:  0.834399/  1.330367, val:  64.58%, val_best:  70.42%, tr:  81.61%, tr_best:  84.47%\n",
      "epoch-69  lr=['0.0010000'], tr/val_loss:  0.826423/  1.335395, val:  67.50%, val_best:  70.42%, tr:  85.39%, tr_best:  85.39%\n",
      "epoch-70  lr=['0.0010000'], tr/val_loss:  0.827093/  1.346238, val:  67.50%, val_best:  70.42%, tr:  84.47%, tr_best:  85.39%\n",
      "epoch-71  lr=['0.0010000'], tr/val_loss:  0.816498/  1.368155, val:  60.83%, val_best:  70.42%, tr:  86.41%, tr_best:  86.41%\n",
      "epoch-72  lr=['0.0010000'], tr/val_loss:  0.811053/  1.376341, val:  61.67%, val_best:  70.42%, tr:  85.90%, tr_best:  86.41%\n",
      "epoch-73  lr=['0.0010000'], tr/val_loss:  0.825768/  1.347697, val:  65.00%, val_best:  70.42%, tr:  85.09%, tr_best:  86.41%\n",
      "epoch-74  lr=['0.0010000'], tr/val_loss:  0.807949/  1.346545, val:  66.25%, val_best:  70.42%, tr:  86.01%, tr_best:  86.41%\n",
      "epoch-75  lr=['0.0010000'], tr/val_loss:  0.816280/  1.343462, val:  68.33%, val_best:  70.42%, tr:  83.96%, tr_best:  86.41%\n",
      "epoch-76  lr=['0.0010000'], tr/val_loss:  0.795494/  1.356621, val:  67.92%, val_best:  70.42%, tr:  85.60%, tr_best:  86.41%\n",
      "epoch-77  lr=['0.0010000'], tr/val_loss:  0.813072/  1.367792, val:  63.75%, val_best:  70.42%, tr:  86.31%, tr_best:  86.41%\n",
      "epoch-78  lr=['0.0010000'], tr/val_loss:  0.797813/  1.350766, val:  69.58%, val_best:  70.42%, tr:  87.13%, tr_best:  87.13%\n",
      "epoch-79  lr=['0.0010000'], tr/val_loss:  0.792662/  1.358648, val:  64.58%, val_best:  70.42%, tr:  85.70%, tr_best:  87.13%\n",
      "epoch-80  lr=['0.0010000'], tr/val_loss:  0.786989/  1.367459, val:  68.33%, val_best:  70.42%, tr:  85.80%, tr_best:  87.13%\n",
      "epoch-81  lr=['0.0010000'], tr/val_loss:  0.791787/  1.356481, val:  65.83%, val_best:  70.42%, tr:  85.70%, tr_best:  87.13%\n",
      "epoch-82  lr=['0.0010000'], tr/val_loss:  0.780600/  1.355493, val:  67.50%, val_best:  70.42%, tr:  87.13%, tr_best:  87.13%\n",
      "epoch-83  lr=['0.0010000'], tr/val_loss:  0.783068/  1.348840, val:  70.42%, val_best:  70.42%, tr:  89.17%, tr_best:  89.17%\n",
      "epoch-84  lr=['0.0010000'], tr/val_loss:  0.775147/  1.362694, val:  67.92%, val_best:  70.42%, tr:  89.17%, tr_best:  89.17%\n",
      "epoch-85  lr=['0.0010000'], tr/val_loss:  0.772074/  1.382532, val:  66.67%, val_best:  70.42%, tr:  89.07%, tr_best:  89.17%\n",
      "epoch-86  lr=['0.0010000'], tr/val_loss:  0.761540/  1.353581, val:  71.25%, val_best:  71.25%, tr:  86.93%, tr_best:  89.17%\n",
      "epoch-87  lr=['0.0010000'], tr/val_loss:  0.760388/  1.354806, val:  68.75%, val_best:  71.25%, tr:  89.68%, tr_best:  89.68%\n",
      "epoch-88  lr=['0.0010000'], tr/val_loss:  0.750785/  1.367211, val:  67.50%, val_best:  71.25%, tr:  89.38%, tr_best:  89.68%\n",
      "epoch-89  lr=['0.0010000'], tr/val_loss:  0.747085/  1.403151, val:  65.00%, val_best:  71.25%, tr:  88.76%, tr_best:  89.68%\n",
      "epoch-90  lr=['0.0010000'], tr/val_loss:  0.749522/  1.348405, val:  70.42%, val_best:  71.25%, tr:  88.46%, tr_best:  89.68%\n",
      "epoch-91  lr=['0.0010000'], tr/val_loss:  0.738451/  1.353116, val:  72.08%, val_best:  72.08%, tr:  89.17%, tr_best:  89.68%\n",
      "epoch-92  lr=['0.0010000'], tr/val_loss:  0.737961/  1.395453, val:  65.83%, val_best:  72.08%, tr:  88.66%, tr_best:  89.68%\n",
      "epoch-93  lr=['0.0010000'], tr/val_loss:  0.747235/  1.374128, val:  64.58%, val_best:  72.08%, tr:  87.74%, tr_best:  89.68%\n",
      "epoch-94  lr=['0.0010000'], tr/val_loss:  0.743427/  1.372280, val:  67.92%, val_best:  72.08%, tr:  88.25%, tr_best:  89.68%\n",
      "epoch-95  lr=['0.0010000'], tr/val_loss:  0.736625/  1.386616, val:  70.00%, val_best:  72.08%, tr:  89.48%, tr_best:  89.68%\n",
      "epoch-96  lr=['0.0010000'], tr/val_loss:  0.732772/  1.414046, val:  69.17%, val_best:  72.08%, tr:  90.09%, tr_best:  90.09%\n",
      "epoch-97  lr=['0.0010000'], tr/val_loss:  0.737089/  1.340491, val:  72.92%, val_best:  72.92%, tr:  86.62%, tr_best:  90.09%\n",
      "epoch-98  lr=['0.0010000'], tr/val_loss:  0.720904/  1.374116, val:  65.83%, val_best:  72.92%, tr:  89.58%, tr_best:  90.09%\n",
      "epoch-99  lr=['0.0010000'], tr/val_loss:  0.739165/  1.351306, val:  70.00%, val_best:  72.92%, tr:  88.25%, tr_best:  90.09%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7e32d73ca68f4c0e87cc64299c60212e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.006 MB of 0.006 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>iter_acc</td><td>▂▃▁▄▂▅▆▃▄▅▅▆▆▅▅▆▆▅▇▇▆▇▅▆▇█▇▇▇▅▆▇▅▆▆▇▆▇█▇</td></tr><tr><td>summary_val_acc</td><td>▁▄▅▆▆▆▆▆▆▆▆▇▆▆▆▇▇▇▇▇▇▆▇▇▇▇▇▇▇▆▇▇▇▇▇▇▇▇██</td></tr><tr><td>tr_acc</td><td>▁▃▄▅▅▅▆▆▆▆▆▆▆▇▆▇▇▇▇▇▇▇▇▇▇▇▇▇██▇█████████</td></tr><tr><td>tr_epoch_loss</td><td>█▇▆▅▄▄▄▃▃▃▃▃▃▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_acc_best</td><td>▁▄▅▆▆▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇█████████████</td></tr><tr><td>val_acc_now</td><td>▁▄▅▆▆▆▆▆▆▆▆▇▆▆▆▇▇▇▇▇▇▆▇▇▇▇▇▇▇▆▇▇▇▇▇▇▇▇██</td></tr><tr><td>val_loss</td><td>█▇▅▄▃▃▃▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▁▂▁▁▁▁▂▂▂▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>99</td></tr><tr><td>iter_acc</td><td>1.0</td></tr><tr><td>tr_acc</td><td>0.88253</td></tr><tr><td>tr_epoch_loss</td><td>0.73917</td></tr><tr><td>val_acc_best</td><td>0.72917</td></tr><tr><td>val_acc_now</td><td>0.7</td></tr><tr><td>val_loss</td><td>1.35131</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">feasible-sweep-217</strong> at: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/if37kz0i' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/if37kz0i</a><br/> View project at: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>/data2/bh_wandb/wandb/run-20250430_064244-if37kz0i/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require(\"core\")`! See https://wandb.me/wandb-core for more information."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: s1imw8bo with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBATCH: 16\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBN_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBPTT_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tDFA_on: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tIMAGE_SIZE: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tOTTT_input_trace_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tTIME: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tUDA_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \talpha_uda: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbias: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcfg: ['M', 'M', 200, 200]\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tchaching_on: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tconvTrue_fcFalse: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdata_path: /data2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tddp_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdenoise_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdvs_clipping: 5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdvs_duration: 100000\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepoch_num: 100\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \texclude_class: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \textra_train_dataset: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlast_lif: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.001\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_sg_width: 5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_decay: 0.5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_init: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_reset: 10000\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_threshold: 0.75\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmerge_polarities: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmy_seed: 42\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnet_print: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_workers: 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer_what: SGD\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tpin_memory: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tpre_trained: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tpre_trained_path: net_save/save_now_net_weights_{unique_name}.pth\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \trate_coding: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tscheduler_name: no\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsingle_step: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsurrogate: hard_sigmoid\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_conv_kernel_size: 3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_conv_padding: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_conv_stride: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_trace_const1: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_trace_const2: 0.5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \ttdBN_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \ttrace_on: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \twhich_data: DVS_GESTURE_TONIC\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.19.10 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.17.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/data2/bh_wandb/wandb/run-20250430_064846-s1imw8bo</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/s1imw8bo' target=\"_blank\">dulcet-sweep-219</a></strong> to <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/6pj3lh8j' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/6pj3lh8j</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/6pj3lh8j' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/6pj3lh8j</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/s1imw8bo' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/s1imw8bo</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'single_step' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'my_seed' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'TIME' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BATCH' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'IMAGE_SIZE' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'which_data' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'data_path' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'rate_coding' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_init' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_decay' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_threshold' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_reset' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_sg_width' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_conv_kernel_size' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_conv_stride' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_conv_padding' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_trace_const1' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_trace_const2' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'pre_trained' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'convTrue_fcFalse' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'cfg' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'net_print' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'pre_trained_path' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'learning_rate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'epoch_num' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'tdBN_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BN_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'surrogate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BPTT_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'optimizer_what' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'scheduler_name' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'ddp_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'dvs_clipping' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'dvs_duration' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'DFA_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'trace_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'OTTT_input_trace_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'exclude_class' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'merge_polarities' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'denoise_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'extra_train_dataset' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'num_workers' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'chaching_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'pin_memory' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'UDA_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'alpha_uda' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'bias' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'last_lif' was locked by 'sweep' (ignored update).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "param {'devices': '0', 'single_step': True, 'unique_name': 'main', 'my_seed': 42, 'TIME': 10, 'BATCH': 16, 'IMAGE_SIZE': 128, 'which_data': 'DVS_GESTURE_TONIC', 'data_path': '/data2', 'rate_coding': False, 'lif_layer_v_init': 0, 'lif_layer_v_decay': 0.5, 'lif_layer_v_threshold': 0.75, 'lif_layer_v_reset': 10000, 'lif_layer_sg_width': 5, 'synapse_conv_kernel_size': 3, 'synapse_conv_stride': 1, 'synapse_conv_padding': 1, 'synapse_trace_const1': 1, 'synapse_trace_const2': 0.5, 'pre_trained': False, 'convTrue_fcFalse': False, 'cfg': ['M', 'M', 200, 200], 'net_print': True, 'pre_trained_path': 'net_save/save_now_net_weights_{unique_name}.pth', 'learning_rate': 0.001, 'epoch_num': 100, 'tdBN_on': False, 'BN_on': False, 'surrogate': 'hard_sigmoid', 'BPTT_on': False, 'optimizer_what': 'SGD', 'scheduler_name': 'no', 'ddp_on': False, 'dvs_clipping': 5, 'dvs_duration': 100000, 'DFA_on': True, 'trace_on': True, 'OTTT_input_trace_on': False, 'exclude_class': True, 'merge_polarities': False, 'denoise_on': False, 'extra_train_dataset': 0, 'num_workers': 2, 'chaching_on': True, 'pin_memory': True, 'UDA_on': False, 'alpha_uda': 1, 'bias': True, 'last_lif': False, 'current epoch': 0} \n",
      "\n",
      "dataset_hash = ffa516e60c3efd5e0208f72b4c36cb84\n",
      "cache path exists\n",
      "\n",
      "device ==> cuda\n",
      "\n",
      "DataParallel(\n",
      "  (module): REBORN_MY_SNN_FC(\n",
      "    (layers): REBORN_MY_Sequential(\n",
      "      (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (2): DimChanger_for_FC()\n",
      "      (3): SYNAPSE_FC(in_features=2048, out_features=200, TIME=10, bias=True, sstep=True)\n",
      "      (4): LIF_layer(v_init=0, v_decay=0.5, v_threshold=0.75, v_reset=10000, sg_width=5, surrogate=hard_sigmoid, BPTT_on=False, trace_const1=1, trace_const2=0.5, TIME=10, sstep=True, trace_on=True)\n",
      "      (5): Feedback_Receiver()\n",
      "      (6): SYNAPSE_FC(in_features=200, out_features=200, TIME=10, bias=True, sstep=True)\n",
      "      (7): LIF_layer(v_init=0, v_decay=0.5, v_threshold=0.75, v_reset=10000, sg_width=5, surrogate=hard_sigmoid, BPTT_on=False, trace_const1=1, trace_const2=0.5, TIME=10, sstep=True, trace_on=True)\n",
      "      (8): Feedback_Receiver()\n",
      "      (9): SYNAPSE_FC(in_features=200, out_features=10, TIME=10, bias=True, sstep=True)\n",
      "      (DFA_top): Top_Gradient()\n",
      "    )\n",
      "  )\n",
      ")\n",
      "\n",
      "========================================================\n",
      "Trainable parameters: 452,010\n",
      "========================================================\n",
      "\n",
      "epoch-0   lr=['0.0010000'], tr/val_loss:  2.305421/  2.301930, val:  12.08%, val_best:  12.08%, tr:   8.38%, tr_best:   8.38%\n",
      "[module.layers.5] weight_fb parameter count: 2,000\n",
      "[module.layers.8] weight_fb parameter count: 2,000\n",
      "epoch-1   lr=['0.0010000'], tr/val_loss:  2.232267/  2.054792, val:  28.75%, val_best:  28.75%, tr:  17.06%, tr_best:  17.06%\n",
      "epoch-2   lr=['0.0010000'], tr/val_loss:  1.764527/  1.661139, val:  47.08%, val_best:  47.08%, tr:  43.62%, tr_best:  43.62%\n",
      "epoch-3   lr=['0.0010000'], tr/val_loss:  1.471248/  1.573581, val:  55.00%, val_best:  55.00%, tr:  59.24%, tr_best:  59.24%\n",
      "epoch-4   lr=['0.0010000'], tr/val_loss:  1.368678/  1.576366, val:  59.58%, val_best:  59.58%, tr:  59.96%, tr_best:  59.96%\n",
      "epoch-5   lr=['0.0010000'], tr/val_loss:  1.308345/  1.539834, val:  62.50%, val_best:  62.50%, tr:  63.23%, tr_best:  63.23%\n",
      "epoch-6   lr=['0.0010000'], tr/val_loss:  1.222791/  1.530743, val:  60.83%, val_best:  62.50%, tr:  67.31%, tr_best:  67.31%\n",
      "epoch-7   lr=['0.0010000'], tr/val_loss:  1.196677/  1.500341, val:  65.42%, val_best:  65.42%, tr:  66.39%, tr_best:  67.31%\n",
      "epoch-8   lr=['0.0010000'], tr/val_loss:  1.146195/  1.550992, val:  63.33%, val_best:  65.42%, tr:  69.25%, tr_best:  69.25%\n",
      "epoch-9   lr=['0.0010000'], tr/val_loss:  1.117561/  1.553078, val:  64.17%, val_best:  65.42%, tr:  73.85%, tr_best:  73.85%\n",
      "epoch-10  lr=['0.0010000'], tr/val_loss:  1.103590/  1.636919, val:  60.00%, val_best:  65.42%, tr:  72.22%, tr_best:  73.85%\n",
      "epoch-11  lr=['0.0010000'], tr/val_loss:  1.022436/  1.607798, val:  67.50%, val_best:  67.50%, tr:  77.63%, tr_best:  77.63%\n",
      "epoch-12  lr=['0.0010000'], tr/val_loss:  1.019101/  1.656517, val:  64.17%, val_best:  67.50%, tr:  81.00%, tr_best:  81.00%\n",
      "epoch-13  lr=['0.0010000'], tr/val_loss:  0.989147/  1.699292, val:  64.17%, val_best:  67.50%, tr:  80.90%, tr_best:  81.00%\n",
      "epoch-14  lr=['0.0010000'], tr/val_loss:  0.914086/  1.894002, val:  64.58%, val_best:  67.50%, tr:  84.27%, tr_best:  84.27%\n",
      "epoch-15  lr=['0.0010000'], tr/val_loss:  0.896792/  1.799311, val:  67.08%, val_best:  67.50%, tr:  86.52%, tr_best:  86.52%\n",
      "epoch-16  lr=['0.0010000'], tr/val_loss:  0.883374/  1.782570, val:  73.75%, val_best:  73.75%, tr:  87.54%, tr_best:  87.54%\n",
      "epoch-17  lr=['0.0010000'], tr/val_loss:  0.806420/  1.860772, val:  71.67%, val_best:  73.75%, tr:  93.05%, tr_best:  93.05%\n",
      "epoch-18  lr=['0.0010000'], tr/val_loss:  0.770284/  1.959273, val:  70.00%, val_best:  73.75%, tr:  92.85%, tr_best:  93.05%\n",
      "epoch-19  lr=['0.0010000'], tr/val_loss:  0.749957/  1.958598, val:  73.33%, val_best:  73.75%, tr:  92.34%, tr_best:  93.05%\n",
      "epoch-20  lr=['0.0010000'], tr/val_loss:  0.705909/  2.086792, val:  70.42%, val_best:  73.75%, tr:  95.51%, tr_best:  95.51%\n",
      "epoch-21  lr=['0.0010000'], tr/val_loss:  0.697589/  2.136744, val:  70.42%, val_best:  73.75%, tr:  96.12%, tr_best:  96.12%\n",
      "epoch-22  lr=['0.0010000'], tr/val_loss:  0.693019/  2.184541, val:  73.75%, val_best:  73.75%, tr:  95.91%, tr_best:  96.12%\n",
      "epoch-23  lr=['0.0010000'], tr/val_loss:  0.660592/  2.271872, val:  73.33%, val_best:  73.75%, tr:  96.63%, tr_best:  96.63%\n",
      "epoch-24  lr=['0.0010000'], tr/val_loss:  0.614047/  2.354091, val:  75.42%, val_best:  75.42%, tr:  97.45%, tr_best:  97.45%\n",
      "epoch-25  lr=['0.0010000'], tr/val_loss:  0.588672/  2.360204, val:  75.83%, val_best:  75.83%, tr:  98.26%, tr_best:  98.26%\n",
      "epoch-26  lr=['0.0010000'], tr/val_loss:  0.603671/  2.487494, val:  76.67%, val_best:  76.67%, tr:  96.94%, tr_best:  98.26%\n",
      "epoch-27  lr=['0.0010000'], tr/val_loss:  0.536761/  2.577038, val:  76.67%, val_best:  76.67%, tr:  98.67%, tr_best:  98.67%\n",
      "epoch-28  lr=['0.0010000'], tr/val_loss:  0.523166/  2.613013, val:  76.67%, val_best:  76.67%, tr:  98.88%, tr_best:  98.88%\n",
      "epoch-29  lr=['0.0010000'], tr/val_loss:  0.500503/  2.719820, val:  72.92%, val_best:  76.67%, tr:  99.28%, tr_best:  99.28%\n",
      "epoch-30  lr=['0.0010000'], tr/val_loss:  0.484980/  2.744065, val:  76.25%, val_best:  76.67%, tr:  99.18%, tr_best:  99.28%\n",
      "epoch-31  lr=['0.0010000'], tr/val_loss:  0.476361/  2.823750, val:  74.17%, val_best:  76.67%, tr:  99.08%, tr_best:  99.28%\n",
      "epoch-32  lr=['0.0010000'], tr/val_loss:  0.446354/  2.862709, val:  75.83%, val_best:  76.67%, tr:  99.18%, tr_best:  99.28%\n",
      "epoch-33  lr=['0.0010000'], tr/val_loss:  0.435957/  2.946568, val:  75.83%, val_best:  76.67%, tr:  99.39%, tr_best:  99.39%\n",
      "epoch-34  lr=['0.0010000'], tr/val_loss:  0.427384/  3.012042, val:  75.42%, val_best:  76.67%, tr:  99.39%, tr_best:  99.39%\n",
      "epoch-35  lr=['0.0010000'], tr/val_loss:  0.400467/  3.107027, val:  75.42%, val_best:  76.67%, tr:  99.69%, tr_best:  99.69%\n",
      "epoch-36  lr=['0.0010000'], tr/val_loss:  0.381524/  3.140943, val:  78.33%, val_best:  78.33%, tr:  99.69%, tr_best:  99.69%\n",
      "epoch-37  lr=['0.0010000'], tr/val_loss:  0.374965/  3.213683, val:  77.08%, val_best:  78.33%, tr:  99.80%, tr_best:  99.80%\n",
      "epoch-38  lr=['0.0010000'], tr/val_loss:  0.369815/  3.268889, val:  78.75%, val_best:  78.75%, tr:  99.90%, tr_best:  99.90%\n",
      "epoch-39  lr=['0.0010000'], tr/val_loss:  0.351361/  3.431359, val:  76.67%, val_best:  78.75%, tr:  99.80%, tr_best:  99.90%\n",
      "epoch-40  lr=['0.0010000'], tr/val_loss:  0.347186/  3.445166, val:  77.92%, val_best:  78.75%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-41  lr=['0.0010000'], tr/val_loss:  0.329004/  3.527858, val:  77.08%, val_best:  78.75%, tr:  99.80%, tr_best: 100.00%\n",
      "epoch-42  lr=['0.0010000'], tr/val_loss:  0.307258/  3.567184, val:  77.08%, val_best:  78.75%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-43  lr=['0.0010000'], tr/val_loss:  0.293493/  3.698624, val:  76.25%, val_best:  78.75%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-44  lr=['0.0010000'], tr/val_loss:  0.279032/  3.743318, val:  77.50%, val_best:  78.75%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-45  lr=['0.0010000'], tr/val_loss:  0.276817/  3.832233, val:  77.08%, val_best:  78.75%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-46  lr=['0.0010000'], tr/val_loss:  0.261440/  3.857187, val:  76.67%, val_best:  78.75%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-47  lr=['0.0010000'], tr/val_loss:  0.261335/  3.913499, val:  78.33%, val_best:  78.75%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-48  lr=['0.0010000'], tr/val_loss:  0.264156/  3.967743, val:  76.25%, val_best:  78.75%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-49  lr=['0.0010000'], tr/val_loss:  0.249526/  4.065042, val:  77.08%, val_best:  78.75%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-50  lr=['0.0010000'], tr/val_loss:  0.233833/  4.138327, val:  75.83%, val_best:  78.75%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-51  lr=['0.0010000'], tr/val_loss:  0.227245/  4.145787, val:  76.67%, val_best:  78.75%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-52  lr=['0.0010000'], tr/val_loss:  0.234273/  4.258533, val:  74.17%, val_best:  78.75%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-53  lr=['0.0010000'], tr/val_loss:  0.225575/  4.203343, val:  77.08%, val_best:  78.75%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-54  lr=['0.0010000'], tr/val_loss:  0.216985/  4.362624, val:  76.25%, val_best:  78.75%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-55  lr=['0.0010000'], tr/val_loss:  0.213557/  4.378163, val:  75.42%, val_best:  78.75%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-56  lr=['0.0010000'], tr/val_loss:  0.201729/  4.469839, val:  75.42%, val_best:  78.75%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-57  lr=['0.0010000'], tr/val_loss:  0.211575/  4.453057, val:  76.67%, val_best:  78.75%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-58  lr=['0.0010000'], tr/val_loss:  0.192059/  4.511151, val:  76.67%, val_best:  78.75%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-59  lr=['0.0010000'], tr/val_loss:  0.190123/  4.566477, val:  77.50%, val_best:  78.75%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-60  lr=['0.0010000'], tr/val_loss:  0.198204/  4.600033, val:  77.08%, val_best:  78.75%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-61  lr=['0.0010000'], tr/val_loss:  0.179196/  4.694234, val:  75.42%, val_best:  78.75%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-62  lr=['0.0010000'], tr/val_loss:  0.171160/  4.677919, val:  76.67%, val_best:  78.75%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-63  lr=['0.0010000'], tr/val_loss:  0.169308/  4.735870, val:  76.25%, val_best:  78.75%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-64  lr=['0.0010000'], tr/val_loss:  0.180270/  4.795314, val:  77.08%, val_best:  78.75%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-65  lr=['0.0010000'], tr/val_loss:  0.169980/  4.797355, val:  77.50%, val_best:  78.75%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-66  lr=['0.0010000'], tr/val_loss:  0.178599/  4.912406, val:  76.25%, val_best:  78.75%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-67  lr=['0.0010000'], tr/val_loss:  0.181496/  4.923919, val:  74.58%, val_best:  78.75%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-68  lr=['0.0010000'], tr/val_loss:  0.169991/  4.930745, val:  76.25%, val_best:  78.75%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-69  lr=['0.0010000'], tr/val_loss:  0.160369/  5.014086, val:  76.25%, val_best:  78.75%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-70  lr=['0.0010000'], tr/val_loss:  0.152203/  5.070110, val:  76.25%, val_best:  78.75%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-71  lr=['0.0010000'], tr/val_loss:  0.168389/  5.106311, val:  77.08%, val_best:  78.75%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-72  lr=['0.0010000'], tr/val_loss:  0.164477/  5.178230, val:  76.25%, val_best:  78.75%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-73  lr=['0.0010000'], tr/val_loss:  0.135398/  5.183074, val:  77.08%, val_best:  78.75%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-74  lr=['0.0010000'], tr/val_loss:  0.138206/  5.233105, val:  77.08%, val_best:  78.75%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-75  lr=['0.0010000'], tr/val_loss:  0.131713/  5.328681, val:  75.83%, val_best:  78.75%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-76  lr=['0.0010000'], tr/val_loss:  0.126327/  5.316539, val:  76.67%, val_best:  78.75%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-77  lr=['0.0010000'], tr/val_loss:  0.127051/  5.399606, val:  76.67%, val_best:  78.75%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-78  lr=['0.0010000'], tr/val_loss:  0.127734/  5.381164, val:  76.67%, val_best:  78.75%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-79  lr=['0.0010000'], tr/val_loss:  0.131625/  5.418076, val:  75.00%, val_best:  78.75%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-80  lr=['0.0010000'], tr/val_loss:  0.136690/  5.395747, val:  77.92%, val_best:  78.75%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-81  lr=['0.0010000'], tr/val_loss:  0.121675/  5.454359, val:  76.67%, val_best:  78.75%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-82  lr=['0.0010000'], tr/val_loss:  0.117968/  5.551033, val:  77.08%, val_best:  78.75%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-83  lr=['0.0010000'], tr/val_loss:  0.131310/  5.602678, val:  77.50%, val_best:  78.75%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-84  lr=['0.0010000'], tr/val_loss:  0.119729/  5.555190, val:  78.33%, val_best:  78.75%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-85  lr=['0.0010000'], tr/val_loss:  0.126269/  5.658952, val:  77.08%, val_best:  78.75%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-86  lr=['0.0010000'], tr/val_loss:  0.112440/  5.679550, val:  76.67%, val_best:  78.75%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-87  lr=['0.0010000'], tr/val_loss:  0.112979/  5.679608, val:  77.92%, val_best:  78.75%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-88  lr=['0.0010000'], tr/val_loss:  0.118996/  5.721935, val:  76.25%, val_best:  78.75%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-89  lr=['0.0010000'], tr/val_loss:  0.114126/  5.766365, val:  76.25%, val_best:  78.75%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-90  lr=['0.0010000'], tr/val_loss:  0.112350/  5.703468, val:  77.50%, val_best:  78.75%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-91  lr=['0.0010000'], tr/val_loss:  0.117664/  5.882695, val:  76.67%, val_best:  78.75%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-92  lr=['0.0010000'], tr/val_loss:  0.088443/  5.893390, val:  75.83%, val_best:  78.75%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-93  lr=['0.0010000'], tr/val_loss:  0.094665/  5.859564, val:  78.33%, val_best:  78.75%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-94  lr=['0.0010000'], tr/val_loss:  0.104446/  5.888567, val:  76.25%, val_best:  78.75%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-95  lr=['0.0010000'], tr/val_loss:  0.094004/  5.989358, val:  76.25%, val_best:  78.75%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-96  lr=['0.0010000'], tr/val_loss:  0.097730/  6.079072, val:  75.42%, val_best:  78.75%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-97  lr=['0.0010000'], tr/val_loss:  0.102675/  5.998694, val:  76.25%, val_best:  78.75%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-98  lr=['0.0010000'], tr/val_loss:  0.095598/  6.026530, val:  77.08%, val_best:  78.75%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-99  lr=['0.0010000'], tr/val_loss:  0.093448/  6.116590, val:  77.08%, val_best:  78.75%, tr: 100.00%, tr_best: 100.00%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "463a57f926fb44b790de20c2ecb96667",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.006 MB of 0.006 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>iter_acc</td><td>▁▅▄▄▄▇▇▆▇▇██████████████████████████████</td></tr><tr><td>summary_val_acc</td><td>▁▅▆▇▇▇▇▇▇▇██▇███████████████████████████</td></tr><tr><td>tr_acc</td><td>▁▄▅▅▆▇▇▇▇███████████████████████████████</td></tr><tr><td>tr_epoch_loss</td><td>█▆▅▄▄▄▄▃▃▃▃▃▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_acc_best</td><td>▁▅▆▇▇▇▇▇▇▇██████████████████████████████</td></tr><tr><td>val_acc_now</td><td>▁▅▆▇▇▇▇▇▇▇██▇███████████████████████████</td></tr><tr><td>val_loss</td><td>▂▁▁▁▁▁▂▂▂▂▂▃▃▃▄▄▄▄▄▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇▇█████</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>99</td></tr><tr><td>iter_acc</td><td>1.0</td></tr><tr><td>tr_acc</td><td>1.0</td></tr><tr><td>tr_epoch_loss</td><td>0.09345</td></tr><tr><td>val_acc_best</td><td>0.7875</td></tr><tr><td>val_acc_now</td><td>0.77083</td></tr><tr><td>val_loss</td><td>6.11659</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">dulcet-sweep-219</strong> at: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/s1imw8bo' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/s1imw8bo</a><br/> View project at: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>/data2/bh_wandb/wandb/run-20250430_064846-s1imw8bo/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require(\"core\")`! See https://wandb.me/wandb-core for more information."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Sweep Agent: Waiting for job.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Job received.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 9zaldufl with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBATCH: 16\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBN_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBPTT_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tDFA_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tIMAGE_SIZE: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tOTTT_input_trace_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tTIME: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tUDA_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \talpha_uda: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbias: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcfg: ['M', 'M', 200, 200]\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tchaching_on: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tconvTrue_fcFalse: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdata_path: /data2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tddp_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdenoise_on: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdvs_clipping: 5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdvs_duration: 100000\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepoch_num: 100\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \texclude_class: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \textra_train_dataset: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlast_lif: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.0001\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_sg_width: 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_decay: 0.5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_init: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_reset: 10000\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_threshold: 0.75\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmerge_polarities: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmy_seed: 42\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnet_print: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_workers: 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer_what: SGD\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tpin_memory: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tpre_trained: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tpre_trained_path: net_save/save_now_net_weights_{unique_name}.pth\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \trate_coding: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tscheduler_name: no\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsingle_step: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsurrogate: hard_sigmoid\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_conv_kernel_size: 3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_conv_padding: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_conv_stride: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_trace_const1: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_trace_const2: 0.5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \ttdBN_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \ttrace_on: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \twhich_data: DVS_GESTURE_TONIC\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.19.10 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.17.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/data2/bh_wandb/wandb/run-20250430_065531-9zaldufl</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/9zaldufl' target=\"_blank\">floral-sweep-221</a></strong> to <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/6pj3lh8j' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/6pj3lh8j</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/6pj3lh8j' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/6pj3lh8j</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/9zaldufl' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/9zaldufl</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'single_step' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'my_seed' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'TIME' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BATCH' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'IMAGE_SIZE' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'which_data' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'data_path' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'rate_coding' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_init' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_decay' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_threshold' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_reset' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_sg_width' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_conv_kernel_size' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_conv_stride' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_conv_padding' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_trace_const1' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_trace_const2' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'pre_trained' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'convTrue_fcFalse' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'cfg' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'net_print' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'pre_trained_path' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'learning_rate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'epoch_num' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'tdBN_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BN_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'surrogate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BPTT_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'optimizer_what' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'scheduler_name' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'ddp_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'dvs_clipping' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'dvs_duration' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'DFA_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'trace_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'OTTT_input_trace_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'exclude_class' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'merge_polarities' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'denoise_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'extra_train_dataset' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'num_workers' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'chaching_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'pin_memory' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'UDA_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'alpha_uda' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'bias' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'last_lif' was locked by 'sweep' (ignored update).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "param {'devices': '0', 'single_step': True, 'unique_name': 'main', 'my_seed': 42, 'TIME': 10, 'BATCH': 16, 'IMAGE_SIZE': 128, 'which_data': 'DVS_GESTURE_TONIC', 'data_path': '/data2', 'rate_coding': False, 'lif_layer_v_init': 0, 'lif_layer_v_decay': 0.5, 'lif_layer_v_threshold': 0.75, 'lif_layer_v_reset': 10000, 'lif_layer_sg_width': 2, 'synapse_conv_kernel_size': 3, 'synapse_conv_stride': 1, 'synapse_conv_padding': 1, 'synapse_trace_const1': 1, 'synapse_trace_const2': 0.5, 'pre_trained': False, 'convTrue_fcFalse': False, 'cfg': ['M', 'M', 200, 200], 'net_print': True, 'pre_trained_path': 'net_save/save_now_net_weights_{unique_name}.pth', 'learning_rate': 0.0001, 'epoch_num': 100, 'tdBN_on': False, 'BN_on': False, 'surrogate': 'hard_sigmoid', 'BPTT_on': False, 'optimizer_what': 'SGD', 'scheduler_name': 'no', 'ddp_on': False, 'dvs_clipping': 5, 'dvs_duration': 100000, 'DFA_on': False, 'trace_on': True, 'OTTT_input_trace_on': False, 'exclude_class': True, 'merge_polarities': False, 'denoise_on': True, 'extra_train_dataset': 0, 'num_workers': 2, 'chaching_on': True, 'pin_memory': True, 'UDA_on': False, 'alpha_uda': 1, 'bias': True, 'last_lif': False, 'current epoch': 0} \n",
      "\n",
      "dataset_hash = 63cc597115630ec173f3099200061e53\n",
      "cache path exists\n",
      "\n",
      "device ==> cuda\n",
      "\n",
      "DataParallel(\n",
      "  (module): REBORN_MY_SNN_FC(\n",
      "    (layers): REBORN_MY_Sequential(\n",
      "      (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (2): DimChanger_for_FC()\n",
      "      (3): SYNAPSE_FC(in_features=2048, out_features=200, TIME=10, bias=True, sstep=True)\n",
      "      (4): LIF_layer(v_init=0, v_decay=0.5, v_threshold=0.75, v_reset=10000, sg_width=2, surrogate=hard_sigmoid, BPTT_on=False, trace_const1=1, trace_const2=0.5, TIME=10, sstep=True, trace_on=True)\n",
      "      (5): SYNAPSE_FC(in_features=200, out_features=200, TIME=10, bias=True, sstep=True)\n",
      "      (6): LIF_layer(v_init=0, v_decay=0.5, v_threshold=0.75, v_reset=10000, sg_width=2, surrogate=hard_sigmoid, BPTT_on=False, trace_const1=1, trace_const2=0.5, TIME=10, sstep=True, trace_on=True)\n",
      "      (7): SYNAPSE_FC(in_features=200, out_features=10, TIME=10, bias=True, sstep=True)\n",
      "    )\n",
      "  )\n",
      ")\n",
      "\n",
      "========================================================\n",
      "Trainable parameters: 452,010\n",
      "========================================================\n",
      "\n",
      "epoch-0   lr=['0.0001000'], tr/val_loss:  2.303353/  2.303047, val:  10.00%, val_best:  10.00%, tr:  10.01%, tr_best:  10.01%\n",
      "epoch-1   lr=['0.0001000'], tr/val_loss:  2.303309/  2.302968, val:  10.00%, val_best:  10.00%, tr:  10.01%, tr_best:  10.01%\n",
      "epoch-2   lr=['0.0001000'], tr/val_loss:  2.303253/  2.302913, val:  10.00%, val_best:  10.00%, tr:  10.01%, tr_best:  10.01%\n",
      "epoch-3   lr=['0.0001000'], tr/val_loss:  2.303180/  2.302890, val:  10.00%, val_best:  10.00%, tr:  10.01%, tr_best:  10.01%\n",
      "epoch-4   lr=['0.0001000'], tr/val_loss:  2.303389/  2.302858, val:  10.00%, val_best:  10.00%, tr:  10.01%, tr_best:  10.01%\n",
      "epoch-5   lr=['0.0001000'], tr/val_loss:  2.303003/  2.302804, val:  10.00%, val_best:  10.00%, tr:  10.01%, tr_best:  10.01%\n",
      "epoch-6   lr=['0.0001000'], tr/val_loss:  2.302944/  2.302766, val:  10.00%, val_best:  10.00%, tr:  10.01%, tr_best:  10.01%\n",
      "epoch-7   lr=['0.0001000'], tr/val_loss:  2.303002/  2.302772, val:  10.00%, val_best:  10.00%, tr:  10.01%, tr_best:  10.01%\n",
      "epoch-8   lr=['0.0001000'], tr/val_loss:  2.302786/  2.302740, val:  10.00%, val_best:  10.00%, tr:  10.01%, tr_best:  10.01%\n",
      "epoch-9   lr=['0.0001000'], tr/val_loss:  2.302638/  2.302746, val:  10.00%, val_best:  10.00%, tr:  10.01%, tr_best:  10.01%\n",
      "epoch-10  lr=['0.0001000'], tr/val_loss:  2.303135/  2.302742, val:  10.00%, val_best:  10.00%, tr:   9.19%, tr_best:  10.01%\n",
      "epoch-11  lr=['0.0001000'], tr/val_loss:  2.303039/  2.302714, val:  10.00%, val_best:  10.00%, tr:   8.89%, tr_best:  10.01%\n",
      "epoch-12  lr=['0.0001000'], tr/val_loss:  2.302702/  2.302692, val:  10.00%, val_best:  10.00%, tr:  10.01%, tr_best:  10.01%\n",
      "epoch-13  lr=['0.0001000'], tr/val_loss:  2.302847/  2.302688, val:  10.00%, val_best:  10.00%, tr:  10.01%, tr_best:  10.01%\n",
      "epoch-14  lr=['0.0001000'], tr/val_loss:  2.303035/  2.302699, val:  10.00%, val_best:  10.00%, tr:  10.01%, tr_best:  10.01%\n",
      "epoch-15  lr=['0.0001000'], tr/val_loss:  2.302881/  2.302661, val:  10.00%, val_best:  10.00%, tr:  10.01%, tr_best:  10.01%\n",
      "epoch-16  lr=['0.0001000'], tr/val_loss:  2.302944/  2.302657, val:  10.00%, val_best:  10.00%, tr:   9.60%, tr_best:  10.01%\n",
      "epoch-17  lr=['0.0001000'], tr/val_loss:  2.302719/  2.302647, val:  10.00%, val_best:  10.00%, tr:  10.01%, tr_best:  10.01%\n",
      "epoch-18  lr=['0.0001000'], tr/val_loss:  2.302800/  2.302642, val:  10.00%, val_best:  10.00%, tr:  10.01%, tr_best:  10.01%\n",
      "epoch-19  lr=['0.0001000'], tr/val_loss:  2.302750/  2.302643, val:  10.00%, val_best:  10.00%, tr:  10.01%, tr_best:  10.01%\n",
      "epoch-20  lr=['0.0001000'], tr/val_loss:  2.302774/  2.302649, val:  10.00%, val_best:  10.00%, tr:   9.50%, tr_best:  10.01%\n",
      "epoch-21  lr=['0.0001000'], tr/val_loss:  2.302997/  2.302649, val:  10.00%, val_best:  10.00%, tr:  10.11%, tr_best:  10.11%\n",
      "epoch-22  lr=['0.0001000'], tr/val_loss:  2.302886/  2.302623, val:  10.00%, val_best:  10.00%, tr:  10.01%, tr_best:  10.11%\n",
      "epoch-23  lr=['0.0001000'], tr/val_loss:  2.302808/  2.302628, val:  10.00%, val_best:  10.00%, tr:  10.01%, tr_best:  10.11%\n",
      "epoch-24  lr=['0.0001000'], tr/val_loss:  2.302805/  2.302622, val:  10.00%, val_best:  10.00%, tr:  10.01%, tr_best:  10.11%\n",
      "epoch-25  lr=['0.0001000'], tr/val_loss:  2.302895/  2.302615, val:  10.00%, val_best:  10.00%, tr:   8.38%, tr_best:  10.11%\n",
      "epoch-26  lr=['0.0001000'], tr/val_loss:  2.302811/  2.302609, val:  10.00%, val_best:  10.00%, tr:  10.01%, tr_best:  10.11%\n",
      "epoch-27  lr=['0.0001000'], tr/val_loss:  2.302836/  2.302608, val:  10.00%, val_best:  10.00%, tr:  10.01%, tr_best:  10.11%\n",
      "epoch-28  lr=['0.0001000'], tr/val_loss:  2.302742/  2.302602, val:  10.00%, val_best:  10.00%, tr:  10.01%, tr_best:  10.11%\n",
      "epoch-29  lr=['0.0001000'], tr/val_loss:  2.302640/  2.302599, val:  10.00%, val_best:  10.00%, tr:  10.01%, tr_best:  10.11%\n",
      "epoch-30  lr=['0.0001000'], tr/val_loss:  2.302813/  2.302604, val:  10.00%, val_best:  10.00%, tr:  10.01%, tr_best:  10.11%\n",
      "epoch-31  lr=['0.0001000'], tr/val_loss:  2.302789/  2.302609, val:  10.00%, val_best:  10.00%, tr:  10.01%, tr_best:  10.11%\n",
      "epoch-32  lr=['0.0001000'], tr/val_loss:  2.302845/  2.302606, val:  10.00%, val_best:  10.00%, tr:  10.01%, tr_best:  10.11%\n",
      "epoch-33  lr=['0.0001000'], tr/val_loss:  2.302791/  2.302604, val:  10.00%, val_best:  10.00%, tr:  10.01%, tr_best:  10.11%\n",
      "epoch-34  lr=['0.0001000'], tr/val_loss:  2.302884/  2.302604, val:  10.00%, val_best:  10.00%, tr:  10.01%, tr_best:  10.11%\n",
      "epoch-35  lr=['0.0001000'], tr/val_loss:  2.302788/  2.302602, val:  10.00%, val_best:  10.00%, tr:  10.01%, tr_best:  10.11%\n",
      "epoch-36  lr=['0.0001000'], tr/val_loss:  2.302829/  2.302599, val:  10.00%, val_best:  10.00%, tr:   8.68%, tr_best:  10.11%\n",
      "epoch-37  lr=['0.0001000'], tr/val_loss:  2.302872/  2.302601, val:  10.00%, val_best:  10.00%, tr:  10.01%, tr_best:  10.11%\n",
      "epoch-38  lr=['0.0001000'], tr/val_loss:  2.302744/  2.302599, val:  10.00%, val_best:  10.00%, tr:   9.30%, tr_best:  10.11%\n",
      "epoch-39  lr=['0.0001000'], tr/val_loss:  2.302754/  2.302598, val:  10.00%, val_best:  10.00%, tr:   8.68%, tr_best:  10.11%\n",
      "epoch-40  lr=['0.0001000'], tr/val_loss:  2.302806/  2.302597, val:  10.00%, val_best:  10.00%, tr:   8.78%, tr_best:  10.11%\n",
      "epoch-41  lr=['0.0001000'], tr/val_loss:  2.302741/  2.302596, val:  10.00%, val_best:  10.00%, tr:   8.17%, tr_best:  10.11%\n",
      "epoch-42  lr=['0.0001000'], tr/val_loss:  2.302734/  2.302602, val:  10.00%, val_best:  10.00%, tr:  10.11%, tr_best:  10.11%\n",
      "epoch-43  lr=['0.0001000'], tr/val_loss:  2.302764/  2.302581, val:  10.00%, val_best:  10.00%, tr:   9.19%, tr_best:  10.11%\n",
      "epoch-44  lr=['0.0001000'], tr/val_loss:  2.302725/  2.302537, val:  10.42%, val_best:  10.42%, tr:   8.48%, tr_best:  10.11%\n",
      "epoch-45  lr=['0.0001000'], tr/val_loss:  2.302778/  2.302563, val:  10.00%, val_best:  10.42%, tr:   9.30%, tr_best:  10.11%\n",
      "epoch-46  lr=['0.0001000'], tr/val_loss:  2.302679/  2.302558, val:  10.42%, val_best:  10.42%, tr:   8.68%, tr_best:  10.11%\n",
      "epoch-47  lr=['0.0001000'], tr/val_loss:  2.302795/  2.302545, val:  10.42%, val_best:  10.42%, tr:   9.40%, tr_best:  10.11%\n",
      "epoch-48  lr=['0.0001000'], tr/val_loss:  2.302694/  2.302584, val:  10.42%, val_best:  10.42%, tr:  10.01%, tr_best:  10.11%\n",
      "epoch-49  lr=['0.0001000'], tr/val_loss:  2.302733/  2.302573, val:  10.42%, val_best:  10.42%, tr:   8.48%, tr_best:  10.11%\n",
      "epoch-50  lr=['0.0001000'], tr/val_loss:  2.302629/  2.302473, val:  10.42%, val_best:  10.42%, tr:   8.99%, tr_best:  10.11%\n",
      "epoch-51  lr=['0.0001000'], tr/val_loss:  2.302516/  2.302457, val:  10.42%, val_best:  10.42%, tr:   8.68%, tr_best:  10.11%\n",
      "epoch-52  lr=['0.0001000'], tr/val_loss:  2.302540/  2.302341, val:  10.42%, val_best:  10.42%, tr:   8.58%, tr_best:  10.11%\n",
      "epoch-53  lr=['0.0001000'], tr/val_loss:  2.302343/  2.302213, val:  10.00%, val_best:  10.42%, tr:  10.11%, tr_best:  10.11%\n",
      "epoch-54  lr=['0.0001000'], tr/val_loss:  2.302023/  2.302001, val:  10.00%, val_best:  10.42%, tr:  10.11%, tr_best:  10.11%\n",
      "epoch-55  lr=['0.0001000'], tr/val_loss:  2.301664/  2.301777, val:  10.00%, val_best:  10.42%, tr:  10.01%, tr_best:  10.11%\n",
      "epoch-56  lr=['0.0001000'], tr/val_loss:  2.301416/  2.301623, val:  10.83%, val_best:  10.83%, tr:  11.34%, tr_best:  11.34%\n",
      "epoch-57  lr=['0.0001000'], tr/val_loss:  2.300717/  2.301299, val:  10.42%, val_best:  10.83%, tr:  10.01%, tr_best:  11.34%\n",
      "epoch-58  lr=['0.0001000'], tr/val_loss:  2.299873/  2.300902, val:  11.25%, val_best:  11.25%, tr:  12.97%, tr_best:  12.97%\n",
      "epoch-59  lr=['0.0001000'], tr/val_loss:  2.298766/  2.299764, val:  12.92%, val_best:  12.92%, tr:  13.38%, tr_best:  13.38%\n",
      "epoch-60  lr=['0.0001000'], tr/val_loss:  2.296729/  2.298826, val:  13.75%, val_best:  13.75%, tr:  14.61%, tr_best:  14.61%\n",
      "epoch-61  lr=['0.0001000'], tr/val_loss:  2.294699/  2.297588, val:  14.58%, val_best:  14.58%, tr:  15.63%, tr_best:  15.63%\n",
      "epoch-62  lr=['0.0001000'], tr/val_loss:  2.291800/  2.296008, val:  16.25%, val_best:  16.25%, tr:  15.22%, tr_best:  15.63%\n",
      "epoch-63  lr=['0.0001000'], tr/val_loss:  2.287949/  2.293815, val:  17.92%, val_best:  17.92%, tr:  16.65%, tr_best:  16.65%\n",
      "epoch-64  lr=['0.0001000'], tr/val_loss:  2.281257/  2.290808, val:  13.33%, val_best:  17.92%, tr:  15.63%, tr_best:  16.65%\n",
      "epoch-65  lr=['0.0001000'], tr/val_loss:  2.275756/  2.287112, val:  13.75%, val_best:  17.92%, tr:  15.22%, tr_best:  16.65%\n",
      "epoch-66  lr=['0.0001000'], tr/val_loss:  2.270123/  2.281942, val:  12.92%, val_best:  17.92%, tr:  16.55%, tr_best:  16.65%\n",
      "epoch-67  lr=['0.0001000'], tr/val_loss:  2.262872/  2.277200, val:  15.42%, val_best:  17.92%, tr:  13.99%, tr_best:  16.65%\n",
      "epoch-68  lr=['0.0001000'], tr/val_loss:  2.251533/  2.272265, val:  15.83%, val_best:  17.92%, tr:  16.75%, tr_best:  16.75%\n",
      "epoch-69  lr=['0.0001000'], tr/val_loss:  2.246885/  2.267668, val:  20.42%, val_best:  20.42%, tr:  16.65%, tr_best:  16.75%\n",
      "epoch-70  lr=['0.0001000'], tr/val_loss:  2.236167/  2.264297, val:  21.25%, val_best:  21.25%, tr:  20.02%, tr_best:  20.02%\n",
      "epoch-71  lr=['0.0001000'], tr/val_loss:  2.231643/  2.259701, val:  20.42%, val_best:  21.25%, tr:  22.78%, tr_best:  22.78%\n",
      "epoch-72  lr=['0.0001000'], tr/val_loss:  2.225379/  2.257624, val:  22.92%, val_best:  22.92%, tr:  24.41%, tr_best:  24.41%\n",
      "epoch-73  lr=['0.0001000'], tr/val_loss:  2.216141/  2.253102, val:  23.33%, val_best:  23.33%, tr:  26.15%, tr_best:  26.15%\n",
      "epoch-74  lr=['0.0001000'], tr/val_loss:  2.215554/  2.249026, val:  25.00%, val_best:  25.00%, tr:  22.57%, tr_best:  26.15%\n",
      "epoch-75  lr=['0.0001000'], tr/val_loss:  2.208938/  2.245533, val:  22.92%, val_best:  25.00%, tr:  25.33%, tr_best:  26.15%\n",
      "epoch-76  lr=['0.0001000'], tr/val_loss:  2.203794/  2.242488, val:  24.58%, val_best:  25.00%, tr:  25.84%, tr_best:  26.15%\n",
      "epoch-77  lr=['0.0001000'], tr/val_loss:  2.201467/  2.236729, val:  26.25%, val_best:  26.25%, tr:  29.72%, tr_best:  29.72%\n",
      "epoch-78  lr=['0.0001000'], tr/val_loss:  2.192549/  2.231504, val:  26.67%, val_best:  26.67%, tr:  28.80%, tr_best:  29.72%\n",
      "epoch-79  lr=['0.0001000'], tr/val_loss:  2.187144/  2.224568, val:  30.00%, val_best:  30.00%, tr:  30.13%, tr_best:  30.13%\n",
      "epoch-80  lr=['0.0001000'], tr/val_loss:  2.178561/  2.219088, val:  28.33%, val_best:  30.00%, tr:  29.62%, tr_best:  30.13%\n",
      "epoch-81  lr=['0.0001000'], tr/val_loss:  2.172215/  2.213620, val:  27.08%, val_best:  30.00%, tr:  32.79%, tr_best:  32.79%\n",
      "epoch-82  lr=['0.0001000'], tr/val_loss:  2.163267/  2.203003, val:  32.08%, val_best:  32.08%, tr:  32.79%, tr_best:  32.79%\n",
      "epoch-83  lr=['0.0001000'], tr/val_loss:  2.152654/  2.192140, val:  33.33%, val_best:  33.33%, tr:  35.34%, tr_best:  35.34%\n",
      "epoch-84  lr=['0.0001000'], tr/val_loss:  2.137479/  2.179858, val:  36.25%, val_best:  36.25%, tr:  38.10%, tr_best:  38.10%\n",
      "epoch-85  lr=['0.0001000'], tr/val_loss:  2.124854/  2.166392, val:  40.00%, val_best:  40.00%, tr:  39.12%, tr_best:  39.12%\n",
      "epoch-86  lr=['0.0001000'], tr/val_loss:  2.108791/  2.149893, val:  40.42%, val_best:  40.42%, tr:  40.86%, tr_best:  40.86%\n",
      "epoch-87  lr=['0.0001000'], tr/val_loss:  2.084733/  2.132230, val:  41.67%, val_best:  41.67%, tr:  39.94%, tr_best:  40.86%\n",
      "epoch-88  lr=['0.0001000'], tr/val_loss:  2.066860/  2.113061, val:  42.92%, val_best:  42.92%, tr:  42.29%, tr_best:  42.29%\n",
      "epoch-89  lr=['0.0001000'], tr/val_loss:  2.044932/  2.095813, val:  38.75%, val_best:  42.92%, tr:  42.90%, tr_best:  42.90%\n",
      "epoch-90  lr=['0.0001000'], tr/val_loss:  2.013084/  2.068439, val:  41.67%, val_best:  42.92%, tr:  44.74%, tr_best:  44.74%\n",
      "epoch-91  lr=['0.0001000'], tr/val_loss:  1.986515/  2.039984, val:  43.33%, val_best:  43.33%, tr:  45.35%, tr_best:  45.35%\n",
      "epoch-92  lr=['0.0001000'], tr/val_loss:  1.953541/  2.012250, val:  45.42%, val_best:  45.42%, tr:  46.27%, tr_best:  46.27%\n",
      "epoch-93  lr=['0.0001000'], tr/val_loss:  1.927962/  1.987001, val:  45.42%, val_best:  45.42%, tr:  48.21%, tr_best:  48.21%\n",
      "epoch-94  lr=['0.0001000'], tr/val_loss:  1.897243/  1.960735, val:  45.42%, val_best:  45.42%, tr:  47.29%, tr_best:  48.21%\n",
      "epoch-95  lr=['0.0001000'], tr/val_loss:  1.867779/  1.935701, val:  45.83%, val_best:  45.83%, tr:  48.11%, tr_best:  48.21%\n",
      "epoch-96  lr=['0.0001000'], tr/val_loss:  1.831936/  1.910247, val:  45.42%, val_best:  45.83%, tr:  49.13%, tr_best:  49.13%\n",
      "epoch-97  lr=['0.0001000'], tr/val_loss:  1.807633/  1.882477, val:  50.83%, val_best:  50.83%, tr:  50.56%, tr_best:  50.56%\n",
      "epoch-98  lr=['0.0001000'], tr/val_loss:  1.782563/  1.858560, val:  50.42%, val_best:  50.83%, tr:  50.05%, tr_best:  50.56%\n",
      "epoch-99  lr=['0.0001000'], tr/val_loss:  1.756990/  1.839209, val:  50.42%, val_best:  50.83%, tr:  53.12%, tr_best:  53.12%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c2df7336b9164a9dae6de6326fd0af18",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.006 MB of 0.006 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>iter_acc</td><td>▂▂▂▂▂▂▂▃▃▁▄▃▄▂▁▂▃▂▃▁▄▂▄▂▂▂▃▃▄▅▄▄▄▆▆▆▅▆█▆</td></tr><tr><td>summary_val_acc</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▂▂▃▃▃▄▄▅▆▆▆▇▇█</td></tr><tr><td>tr_acc</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▂▂▂▃▄▄▅▅▅▆▆▇▇██</td></tr><tr><td>tr_epoch_loss</td><td>███████████████████████████▇▇▇▇▇▆▆▆▅▄▃▂▁</td></tr><tr><td>val_acc_best</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▂▂▃▃▄▄▄▅▆▆▇▇▇█</td></tr><tr><td>val_acc_now</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▂▂▃▃▃▄▄▅▆▆▆▇▇█</td></tr><tr><td>val_loss</td><td>████████████████████████████▇▇▇▇▇▆▆▅▅▃▂▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>99</td></tr><tr><td>iter_acc</td><td>1.0</td></tr><tr><td>tr_acc</td><td>0.53115</td></tr><tr><td>tr_epoch_loss</td><td>1.75699</td></tr><tr><td>val_acc_best</td><td>0.50833</td></tr><tr><td>val_acc_now</td><td>0.50417</td></tr><tr><td>val_loss</td><td>1.83921</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">floral-sweep-221</strong> at: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/9zaldufl' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/9zaldufl</a><br/> View project at: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>/data2/bh_wandb/wandb/run-20250430_065531-9zaldufl/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require(\"core\")`! See https://wandb.me/wandb-core for more information."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: zrarkg7p with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBATCH: 16\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBN_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBPTT_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tDFA_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tIMAGE_SIZE: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tOTTT_input_trace_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tTIME: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tUDA_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \talpha_uda: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbias: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcfg: ['M', 'M', 200, 200]\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tchaching_on: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tconvTrue_fcFalse: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdata_path: /data2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tddp_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdenoise_on: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdvs_clipping: 5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdvs_duration: 100000\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepoch_num: 100\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \texclude_class: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \textra_train_dataset: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlast_lif: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.001\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_sg_width: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_decay: 0.5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_init: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_reset: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_threshold: 0.25\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmerge_polarities: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmy_seed: 42\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnet_print: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_workers: 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer_what: SGD\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tpin_memory: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tpre_trained: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tpre_trained_path: net_save/save_now_net_weights_{unique_name}.pth\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \trate_coding: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tscheduler_name: no\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsingle_step: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsurrogate: hard_sigmoid\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_conv_kernel_size: 3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_conv_padding: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_conv_stride: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_trace_const1: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_trace_const2: 0.5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \ttdBN_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \ttrace_on: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \twhich_data: DVS_GESTURE_TONIC\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.19.10 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.17.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/data2/bh_wandb/wandb/run-20250430_070123-zrarkg7p</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/zrarkg7p' target=\"_blank\">earnest-sweep-223</a></strong> to <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/6pj3lh8j' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/6pj3lh8j</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/6pj3lh8j' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/6pj3lh8j</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/zrarkg7p' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/zrarkg7p</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'single_step' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'my_seed' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'TIME' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BATCH' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'IMAGE_SIZE' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'which_data' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'data_path' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'rate_coding' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_init' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_decay' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_threshold' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_reset' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_sg_width' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_conv_kernel_size' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_conv_stride' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_conv_padding' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_trace_const1' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_trace_const2' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'pre_trained' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'convTrue_fcFalse' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'cfg' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'net_print' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'pre_trained_path' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'learning_rate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'epoch_num' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'tdBN_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BN_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'surrogate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BPTT_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'optimizer_what' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'scheduler_name' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'ddp_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'dvs_clipping' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'dvs_duration' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'DFA_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'trace_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'OTTT_input_trace_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'exclude_class' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'merge_polarities' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'denoise_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'extra_train_dataset' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'num_workers' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'chaching_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'pin_memory' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'UDA_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'alpha_uda' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'bias' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'last_lif' was locked by 'sweep' (ignored update).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "param {'devices': '0', 'single_step': True, 'unique_name': 'main', 'my_seed': 42, 'TIME': 10, 'BATCH': 16, 'IMAGE_SIZE': 128, 'which_data': 'DVS_GESTURE_TONIC', 'data_path': '/data2', 'rate_coding': False, 'lif_layer_v_init': 0, 'lif_layer_v_decay': 0.5, 'lif_layer_v_threshold': 0.25, 'lif_layer_v_reset': 0, 'lif_layer_sg_width': 1, 'synapse_conv_kernel_size': 3, 'synapse_conv_stride': 1, 'synapse_conv_padding': 1, 'synapse_trace_const1': 1, 'synapse_trace_const2': 0.5, 'pre_trained': False, 'convTrue_fcFalse': False, 'cfg': ['M', 'M', 200, 200], 'net_print': True, 'pre_trained_path': 'net_save/save_now_net_weights_{unique_name}.pth', 'learning_rate': 0.001, 'epoch_num': 100, 'tdBN_on': False, 'BN_on': False, 'surrogate': 'hard_sigmoid', 'BPTT_on': False, 'optimizer_what': 'SGD', 'scheduler_name': 'no', 'ddp_on': False, 'dvs_clipping': 5, 'dvs_duration': 100000, 'DFA_on': False, 'trace_on': True, 'OTTT_input_trace_on': False, 'exclude_class': True, 'merge_polarities': False, 'denoise_on': True, 'extra_train_dataset': 0, 'num_workers': 2, 'chaching_on': True, 'pin_memory': True, 'UDA_on': False, 'alpha_uda': 1, 'bias': True, 'last_lif': False, 'current epoch': 0} \n",
      "\n",
      "dataset_hash = 63cc597115630ec173f3099200061e53\n",
      "cache path exists\n",
      "\n",
      "device ==> cuda\n",
      "\n",
      "DataParallel(\n",
      "  (module): REBORN_MY_SNN_FC(\n",
      "    (layers): REBORN_MY_Sequential(\n",
      "      (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (2): DimChanger_for_FC()\n",
      "      (3): SYNAPSE_FC(in_features=2048, out_features=200, TIME=10, bias=True, sstep=True)\n",
      "      (4): LIF_layer(v_init=0, v_decay=0.5, v_threshold=0.25, v_reset=0, sg_width=1, surrogate=hard_sigmoid, BPTT_on=False, trace_const1=1, trace_const2=0.5, TIME=10, sstep=True, trace_on=True)\n",
      "      (5): SYNAPSE_FC(in_features=200, out_features=200, TIME=10, bias=True, sstep=True)\n",
      "      (6): LIF_layer(v_init=0, v_decay=0.5, v_threshold=0.25, v_reset=0, sg_width=1, surrogate=hard_sigmoid, BPTT_on=False, trace_const1=1, trace_const2=0.5, TIME=10, sstep=True, trace_on=True)\n",
      "      (7): SYNAPSE_FC(in_features=200, out_features=10, TIME=10, bias=True, sstep=True)\n",
      "    )\n",
      "  )\n",
      ")\n",
      "\n",
      "========================================================\n",
      "Trainable parameters: 452,010\n",
      "========================================================\n",
      "\n",
      "epoch-0   lr=['0.0010000'], tr/val_loss:  2.271144/  2.213912, val:  23.75%, val_best:  23.75%, tr:  13.69%, tr_best:  13.69%\n",
      "epoch-1   lr=['0.0010000'], tr/val_loss:  2.119504/  2.065082, val:  38.33%, val_best:  38.33%, tr:  27.89%, tr_best:  27.89%\n",
      "epoch-2   lr=['0.0010000'], tr/val_loss:  1.917099/  1.901326, val:  46.25%, val_best:  46.25%, tr:  40.86%, tr_best:  40.86%\n",
      "epoch-3   lr=['0.0010000'], tr/val_loss:  1.712377/  1.767536, val:  50.00%, val_best:  50.00%, tr:  48.93%, tr_best:  48.93%\n",
      "epoch-4   lr=['0.0010000'], tr/val_loss:  1.567230/  1.685006, val:  50.42%, val_best:  50.42%, tr:  54.34%, tr_best:  54.34%\n",
      "epoch-5   lr=['0.0010000'], tr/val_loss:  1.459769/  1.610650, val:  54.58%, val_best:  54.58%, tr:  56.59%, tr_best:  56.59%\n",
      "epoch-6   lr=['0.0010000'], tr/val_loss:  1.398363/  1.574295, val:  57.50%, val_best:  57.50%, tr:  60.47%, tr_best:  60.47%\n",
      "epoch-7   lr=['0.0010000'], tr/val_loss:  1.341755/  1.544551, val:  55.83%, val_best:  57.50%, tr:  60.67%, tr_best:  60.67%\n",
      "epoch-8   lr=['0.0010000'], tr/val_loss:  1.300183/  1.523292, val:  60.00%, val_best:  60.00%, tr:  61.08%, tr_best:  61.08%\n",
      "epoch-9   lr=['0.0010000'], tr/val_loss:  1.271581/  1.513263, val:  53.75%, val_best:  60.00%, tr:  64.15%, tr_best:  64.15%\n",
      "epoch-10  lr=['0.0010000'], tr/val_loss:  1.239508/  1.501374, val:  59.58%, val_best:  60.00%, tr:  63.74%, tr_best:  64.15%\n",
      "epoch-11  lr=['0.0010000'], tr/val_loss:  1.207462/  1.475154, val:  59.17%, val_best:  60.00%, tr:  64.96%, tr_best:  64.96%\n",
      "epoch-12  lr=['0.0010000'], tr/val_loss:  1.185769/  1.452586, val:  55.83%, val_best:  60.00%, tr:  66.91%, tr_best:  66.91%\n",
      "epoch-13  lr=['0.0010000'], tr/val_loss:  1.169933/  1.438281, val:  59.58%, val_best:  60.00%, tr:  66.80%, tr_best:  66.91%\n",
      "epoch-14  lr=['0.0010000'], tr/val_loss:  1.118432/  1.456435, val:  58.33%, val_best:  60.00%, tr:  68.44%, tr_best:  68.44%\n",
      "epoch-15  lr=['0.0010000'], tr/val_loss:  1.113631/  1.436250, val:  61.67%, val_best:  61.67%, tr:  69.15%, tr_best:  69.15%\n",
      "epoch-16  lr=['0.0010000'], tr/val_loss:  1.099342/  1.413429, val:  57.08%, val_best:  61.67%, tr:  69.66%, tr_best:  69.66%\n",
      "epoch-17  lr=['0.0010000'], tr/val_loss:  1.063788/  1.389606, val:  63.33%, val_best:  63.33%, tr:  73.95%, tr_best:  73.95%\n",
      "epoch-18  lr=['0.0010000'], tr/val_loss:  1.044016/  1.458339, val:  57.50%, val_best:  63.33%, tr:  73.44%, tr_best:  73.95%\n",
      "epoch-19  lr=['0.0010000'], tr/val_loss:  1.037125/  1.461781, val:  60.42%, val_best:  63.33%, tr:  70.17%, tr_best:  73.95%\n",
      "epoch-20  lr=['0.0010000'], tr/val_loss:  1.008587/  1.436370, val:  59.58%, val_best:  63.33%, tr:  75.59%, tr_best:  75.59%\n",
      "epoch-21  lr=['0.0010000'], tr/val_loss:  0.995020/  1.407226, val:  62.92%, val_best:  63.33%, tr:  76.40%, tr_best:  76.40%\n",
      "epoch-22  lr=['0.0010000'], tr/val_loss:  1.010781/  1.402310, val:  60.83%, val_best:  63.33%, tr:  72.63%, tr_best:  76.40%\n",
      "epoch-23  lr=['0.0010000'], tr/val_loss:  0.974947/  1.412822, val:  65.83%, val_best:  65.83%, tr:  77.12%, tr_best:  77.12%\n",
      "epoch-24  lr=['0.0010000'], tr/val_loss:  0.953457/  1.447899, val:  62.08%, val_best:  65.83%, tr:  78.14%, tr_best:  78.14%\n",
      "epoch-25  lr=['0.0010000'], tr/val_loss:  0.945204/  1.432182, val:  65.00%, val_best:  65.83%, tr:  78.75%, tr_best:  78.75%\n",
      "epoch-26  lr=['0.0010000'], tr/val_loss:  0.930286/  1.402901, val:  68.33%, val_best:  68.33%, tr:  77.73%, tr_best:  78.75%\n",
      "epoch-27  lr=['0.0010000'], tr/val_loss:  0.918623/  1.467899, val:  61.67%, val_best:  68.33%, tr:  80.29%, tr_best:  80.29%\n",
      "epoch-28  lr=['0.0010000'], tr/val_loss:  0.905570/  1.433413, val:  68.33%, val_best:  68.33%, tr:  79.98%, tr_best:  80.29%\n",
      "epoch-29  lr=['0.0010000'], tr/val_loss:  0.891169/  1.499568, val:  60.00%, val_best:  68.33%, tr:  81.61%, tr_best:  81.61%\n",
      "epoch-30  lr=['0.0010000'], tr/val_loss:  0.884161/  1.466674, val:  64.17%, val_best:  68.33%, tr:  82.02%, tr_best:  82.02%\n",
      "epoch-31  lr=['0.0010000'], tr/val_loss:  0.885212/  1.528810, val:  63.75%, val_best:  68.33%, tr:  78.96%, tr_best:  82.02%\n",
      "epoch-32  lr=['0.0010000'], tr/val_loss:  0.878800/  1.503499, val:  65.42%, val_best:  68.33%, tr:  80.59%, tr_best:  82.02%\n",
      "epoch-33  lr=['0.0010000'], tr/val_loss:  0.867940/  1.545360, val:  66.67%, val_best:  68.33%, tr:  83.04%, tr_best:  83.04%\n",
      "epoch-34  lr=['0.0010000'], tr/val_loss:  0.855133/  1.529981, val:  64.58%, val_best:  68.33%, tr:  82.74%, tr_best:  83.04%\n",
      "epoch-35  lr=['0.0010000'], tr/val_loss:  0.860671/  1.592199, val:  60.42%, val_best:  68.33%, tr:  82.12%, tr_best:  83.04%\n",
      "epoch-36  lr=['0.0010000'], tr/val_loss:  0.830630/  1.523988, val:  66.67%, val_best:  68.33%, tr:  83.76%, tr_best:  83.76%\n",
      "epoch-37  lr=['0.0010000'], tr/val_loss:  0.835012/  1.568986, val:  67.08%, val_best:  68.33%, tr:  85.90%, tr_best:  85.90%\n",
      "epoch-38  lr=['0.0010000'], tr/val_loss:  0.827137/  1.553537, val:  68.33%, val_best:  68.33%, tr:  86.31%, tr_best:  86.31%\n",
      "epoch-39  lr=['0.0010000'], tr/val_loss:  0.821829/  1.581612, val:  66.25%, val_best:  68.33%, tr:  85.80%, tr_best:  86.31%\n",
      "epoch-40  lr=['0.0010000'], tr/val_loss:  0.808516/  1.545291, val:  67.92%, val_best:  68.33%, tr:  85.50%, tr_best:  86.31%\n",
      "epoch-41  lr=['0.0010000'], tr/val_loss:  0.816658/  1.600840, val:  65.83%, val_best:  68.33%, tr:  87.44%, tr_best:  87.44%\n",
      "epoch-42  lr=['0.0010000'], tr/val_loss:  0.802062/  1.613271, val:  67.50%, val_best:  68.33%, tr:  87.23%, tr_best:  87.44%\n",
      "epoch-43  lr=['0.0010000'], tr/val_loss:  0.792263/  1.652269, val:  67.50%, val_best:  68.33%, tr:  86.93%, tr_best:  87.44%\n",
      "epoch-44  lr=['0.0010000'], tr/val_loss:  0.785542/  1.618566, val:  68.75%, val_best:  68.75%, tr:  87.23%, tr_best:  87.44%\n",
      "epoch-45  lr=['0.0010000'], tr/val_loss:  0.773058/  1.674953, val:  66.67%, val_best:  68.75%, tr:  88.15%, tr_best:  88.15%\n",
      "epoch-46  lr=['0.0010000'], tr/val_loss:  0.779096/  1.682626, val:  67.08%, val_best:  68.75%, tr:  88.76%, tr_best:  88.76%\n",
      "epoch-47  lr=['0.0010000'], tr/val_loss:  0.765017/  1.753861, val:  67.92%, val_best:  68.75%, tr:  87.84%, tr_best:  88.76%\n",
      "epoch-48  lr=['0.0010000'], tr/val_loss:  0.774353/  1.697718, val:  70.42%, val_best:  70.42%, tr:  90.09%, tr_best:  90.09%\n",
      "epoch-49  lr=['0.0010000'], tr/val_loss:  0.757714/  1.744035, val:  69.17%, val_best:  70.42%, tr:  89.48%, tr_best:  90.09%\n",
      "epoch-50  lr=['0.0010000'], tr/val_loss:  0.749776/  1.773715, val:  70.83%, val_best:  70.83%, tr:  89.99%, tr_best:  90.09%\n",
      "epoch-51  lr=['0.0010000'], tr/val_loss:  0.735386/  1.857619, val:  68.33%, val_best:  70.83%, tr:  89.48%, tr_best:  90.09%\n",
      "epoch-52  lr=['0.0010000'], tr/val_loss:  0.727392/  1.871766, val:  63.33%, val_best:  70.83%, tr:  91.11%, tr_best:  91.11%\n",
      "epoch-53  lr=['0.0010000'], tr/val_loss:  0.736892/  1.886971, val:  67.08%, val_best:  70.83%, tr:  91.22%, tr_best:  91.22%\n",
      "epoch-54  lr=['0.0010000'], tr/val_loss:  0.737400/  1.844973, val:  69.58%, val_best:  70.83%, tr:  90.60%, tr_best:  91.22%\n",
      "epoch-55  lr=['0.0010000'], tr/val_loss:  0.726919/  1.898565, val:  67.92%, val_best:  70.83%, tr:  90.60%, tr_best:  91.22%\n",
      "epoch-56  lr=['0.0010000'], tr/val_loss:  0.727255/  2.010104, val:  61.25%, val_best:  70.83%, tr:  90.60%, tr_best:  91.22%\n",
      "epoch-57  lr=['0.0010000'], tr/val_loss:  0.733125/  1.929105, val:  67.50%, val_best:  70.83%, tr:  90.30%, tr_best:  91.22%\n",
      "epoch-58  lr=['0.0010000'], tr/val_loss:  0.706081/  2.015479, val:  62.08%, val_best:  70.83%, tr:  90.50%, tr_best:  91.22%\n",
      "epoch-59  lr=['0.0010000'], tr/val_loss:  0.704463/  1.999632, val:  65.00%, val_best:  70.83%, tr:  91.83%, tr_best:  91.83%\n",
      "epoch-60  lr=['0.0010000'], tr/val_loss:  0.697379/  2.012823, val:  66.67%, val_best:  70.83%, tr:  92.54%, tr_best:  92.54%\n",
      "epoch-61  lr=['0.0010000'], tr/val_loss:  0.699366/  2.049498, val:  66.67%, val_best:  70.83%, tr:  93.16%, tr_best:  93.16%\n",
      "epoch-62  lr=['0.0010000'], tr/val_loss:  0.696666/  1.982021, val:  66.25%, val_best:  70.83%, tr:  91.62%, tr_best:  93.16%\n",
      "epoch-63  lr=['0.0010000'], tr/val_loss:  0.690303/  1.949631, val:  68.33%, val_best:  70.83%, tr:  93.16%, tr_best:  93.16%\n",
      "epoch-64  lr=['0.0010000'], tr/val_loss:  0.682222/  2.182542, val:  66.67%, val_best:  70.83%, tr:  93.16%, tr_best:  93.16%\n",
      "epoch-65  lr=['0.0010000'], tr/val_loss:  0.678254/  2.093792, val:  68.33%, val_best:  70.83%, tr:  93.26%, tr_best:  93.26%\n",
      "epoch-66  lr=['0.0010000'], tr/val_loss:  0.657245/  2.104634, val:  64.17%, val_best:  70.83%, tr:  94.28%, tr_best:  94.28%\n",
      "epoch-67  lr=['0.0010000'], tr/val_loss:  0.678574/  2.185186, val:  65.42%, val_best:  70.83%, tr:  93.46%, tr_best:  94.28%\n",
      "epoch-68  lr=['0.0010000'], tr/val_loss:  0.669829/  2.143760, val:  65.83%, val_best:  70.83%, tr:  93.77%, tr_best:  94.28%\n",
      "epoch-69  lr=['0.0010000'], tr/val_loss:  0.663757/  2.222388, val:  63.33%, val_best:  70.83%, tr:  93.46%, tr_best:  94.28%\n",
      "epoch-70  lr=['0.0010000'], tr/val_loss:  0.664197/  2.173170, val:  68.75%, val_best:  70.83%, tr:  93.67%, tr_best:  94.28%\n",
      "epoch-71  lr=['0.0010000'], tr/val_loss:  0.658573/  2.264093, val:  66.25%, val_best:  70.83%, tr:  94.08%, tr_best:  94.28%\n",
      "epoch-72  lr=['0.0010000'], tr/val_loss:  0.649531/  2.311089, val:  66.67%, val_best:  70.83%, tr:  94.28%, tr_best:  94.28%\n",
      "epoch-73  lr=['0.0010000'], tr/val_loss:  0.697815/  2.388317, val:  62.50%, val_best:  70.83%, tr:  93.46%, tr_best:  94.28%\n",
      "epoch-74  lr=['0.0010000'], tr/val_loss:  0.679183/  2.287027, val:  64.58%, val_best:  70.83%, tr:  93.77%, tr_best:  94.28%\n",
      "epoch-75  lr=['0.0010000'], tr/val_loss:  0.661421/  2.334292, val:  65.83%, val_best:  70.83%, tr:  93.56%, tr_best:  94.28%\n",
      "epoch-76  lr=['0.0010000'], tr/val_loss:  0.641969/  2.338767, val:  62.08%, val_best:  70.83%, tr:  94.99%, tr_best:  94.99%\n",
      "epoch-77  lr=['0.0010000'], tr/val_loss:  0.654468/  2.357919, val:  64.58%, val_best:  70.83%, tr:  93.87%, tr_best:  94.99%\n",
      "epoch-78  lr=['0.0010000'], tr/val_loss:  0.643049/  2.393985, val:  67.08%, val_best:  70.83%, tr:  93.46%, tr_best:  94.99%\n",
      "epoch-79  lr=['0.0010000'], tr/val_loss:  0.629749/  2.407182, val:  67.50%, val_best:  70.83%, tr:  93.77%, tr_best:  94.99%\n",
      "epoch-80  lr=['0.0010000'], tr/val_loss:  0.630240/  2.430224, val:  63.75%, val_best:  70.83%, tr:  94.69%, tr_best:  94.99%\n",
      "epoch-81  lr=['0.0010000'], tr/val_loss:  0.629139/  2.470051, val:  67.50%, val_best:  70.83%, tr:  95.40%, tr_best:  95.40%\n",
      "epoch-82  lr=['0.0010000'], tr/val_loss:  0.626601/  2.557223, val:  63.75%, val_best:  70.83%, tr:  94.08%, tr_best:  95.40%\n",
      "epoch-83  lr=['0.0010000'], tr/val_loss:  0.650782/  2.664475, val:  62.08%, val_best:  70.83%, tr:  94.08%, tr_best:  95.40%\n",
      "epoch-84  lr=['0.0010000'], tr/val_loss:  0.633163/  2.498292, val:  65.42%, val_best:  70.83%, tr:  96.42%, tr_best:  96.42%\n",
      "epoch-85  lr=['0.0010000'], tr/val_loss:  0.640605/  2.526422, val:  66.25%, val_best:  70.83%, tr:  95.10%, tr_best:  96.42%\n",
      "epoch-86  lr=['0.0010000'], tr/val_loss:  0.621260/  2.476778, val:  65.00%, val_best:  70.83%, tr:  94.48%, tr_best:  96.42%\n",
      "epoch-87  lr=['0.0010000'], tr/val_loss:  0.620244/  2.573562, val:  65.83%, val_best:  70.83%, tr:  95.51%, tr_best:  96.42%\n",
      "epoch-88  lr=['0.0010000'], tr/val_loss:  0.620359/  2.622973, val:  62.08%, val_best:  70.83%, tr:  95.81%, tr_best:  96.42%\n",
      "epoch-89  lr=['0.0010000'], tr/val_loss:  0.605548/  2.640956, val:  65.42%, val_best:  70.83%, tr:  96.32%, tr_best:  96.42%\n",
      "epoch-90  lr=['0.0010000'], tr/val_loss:  0.629322/  2.612954, val:  62.50%, val_best:  70.83%, tr:  95.30%, tr_best:  96.42%\n",
      "epoch-91  lr=['0.0010000'], tr/val_loss:  0.619542/  2.711474, val:  61.25%, val_best:  70.83%, tr:  94.89%, tr_best:  96.42%\n",
      "epoch-92  lr=['0.0010000'], tr/val_loss:  0.627735/  2.750376, val:  60.00%, val_best:  70.83%, tr:  95.40%, tr_best:  96.42%\n",
      "epoch-93  lr=['0.0010000'], tr/val_loss:  0.637624/  2.683571, val:  64.17%, val_best:  70.83%, tr:  94.99%, tr_best:  96.42%\n",
      "epoch-94  lr=['0.0010000'], tr/val_loss:  0.619945/  2.644697, val:  65.83%, val_best:  70.83%, tr:  96.12%, tr_best:  96.42%\n",
      "epoch-95  lr=['0.0010000'], tr/val_loss:  0.630613/  2.787121, val:  66.25%, val_best:  70.83%, tr:  94.89%, tr_best:  96.42%\n",
      "epoch-96  lr=['0.0010000'], tr/val_loss:  0.599588/  2.837799, val:  59.17%, val_best:  70.83%, tr:  96.22%, tr_best:  96.42%\n",
      "epoch-97  lr=['0.0010000'], tr/val_loss:  0.616224/  2.720553, val:  66.25%, val_best:  70.83%, tr:  94.89%, tr_best:  96.42%\n",
      "epoch-98  lr=['0.0010000'], tr/val_loss:  0.590106/  2.774406, val:  64.58%, val_best:  70.83%, tr:  96.63%, tr_best:  96.63%\n",
      "epoch-99  lr=['0.0010000'], tr/val_loss:  0.609097/  2.823443, val:  62.92%, val_best:  70.83%, tr:  96.12%, tr_best:  96.63%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1f043e9eab784e7daea00a339217bd51",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.006 MB of 0.006 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>iter_acc</td><td>▂▄▁▃▁▄▆▂▄▅▅▇▄▆▆▇▇▆█▇▇█▆▇█▇▇██▇█▇▅█▇▇▇▇██</td></tr><tr><td>summary_val_acc</td><td>▁▄▅▆▆▆▆▇▇▇▇█▇▇▇█▇████▇██▇██▇██▇▇█▇▇▇▇▇▇▇</td></tr><tr><td>tr_acc</td><td>▁▃▄▅▅▆▆▆▆▆▆▆▇▇▇▇▇▇▇▇▇██▇████████████████</td></tr><tr><td>tr_epoch_loss</td><td>█▇▅▄▄▃▃▃▃▃▂▂▂▂▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_acc_best</td><td>▁▄▅▆▆▆▆▇▇▇▇█████████████████████████████</td></tr><tr><td>val_acc_now</td><td>▁▄▅▆▆▆▆▇▇▇▇█▇▇▇█▇████▇██▇██▇██▇▇█▇▇▇▇▇▇▇</td></tr><tr><td>val_loss</td><td>▅▄▂▂▂▁▁▁▁▁▁▁▂▂▂▂▂▂▂▃▃▃▃▄▄▄▅▅▅▆▆▆▆▇▇▇▇███</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>99</td></tr><tr><td>iter_acc</td><td>1.0</td></tr><tr><td>tr_acc</td><td>0.96118</td></tr><tr><td>tr_epoch_loss</td><td>0.6091</td></tr><tr><td>val_acc_best</td><td>0.70833</td></tr><tr><td>val_acc_now</td><td>0.62917</td></tr><tr><td>val_loss</td><td>2.82344</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">earnest-sweep-223</strong> at: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/zrarkg7p' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/zrarkg7p</a><br/> View project at: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>/data2/bh_wandb/wandb/run-20250430_070123-zrarkg7p/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require(\"core\")`! See https://wandb.me/wandb-core for more information."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: uohseozy with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBATCH: 16\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBN_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBPTT_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tDFA_on: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tIMAGE_SIZE: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tOTTT_input_trace_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tTIME: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tUDA_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \talpha_uda: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbias: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcfg: ['M', 'M', 200, 200]\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tchaching_on: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tconvTrue_fcFalse: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdata_path: /data2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tddp_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdenoise_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdvs_clipping: 5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdvs_duration: 100000\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepoch_num: 100\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \texclude_class: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \textra_train_dataset: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlast_lif: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.0001\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_sg_width: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_decay: 0.5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_init: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_reset: 10000\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_threshold: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmerge_polarities: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmy_seed: 42\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnet_print: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_workers: 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer_what: SGD\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tpin_memory: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tpre_trained: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tpre_trained_path: net_save/save_now_net_weights_{unique_name}.pth\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \trate_coding: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tscheduler_name: no\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsingle_step: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsurrogate: hard_sigmoid\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_conv_kernel_size: 3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_conv_padding: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_conv_stride: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_trace_const1: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_trace_const2: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \ttdBN_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \ttrace_on: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \twhich_data: DVS_GESTURE_TONIC\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.19.10 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.17.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/data2/bh_wandb/wandb/run-20250430_070724-uohseozy</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/uohseozy' target=\"_blank\">drawn-sweep-225</a></strong> to <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/6pj3lh8j' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/6pj3lh8j</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/6pj3lh8j' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/6pj3lh8j</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/uohseozy' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/uohseozy</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'single_step' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'my_seed' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'TIME' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BATCH' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'IMAGE_SIZE' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'which_data' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'data_path' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'rate_coding' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_init' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_decay' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_threshold' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_reset' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_sg_width' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_conv_kernel_size' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_conv_stride' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_conv_padding' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_trace_const1' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_trace_const2' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'pre_trained' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'convTrue_fcFalse' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'cfg' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'net_print' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'pre_trained_path' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'learning_rate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'epoch_num' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'tdBN_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BN_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'surrogate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BPTT_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'optimizer_what' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'scheduler_name' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'ddp_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'dvs_clipping' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'dvs_duration' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'DFA_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'trace_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'OTTT_input_trace_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'exclude_class' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'merge_polarities' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'denoise_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'extra_train_dataset' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'num_workers' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'chaching_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'pin_memory' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'UDA_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'alpha_uda' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'bias' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'last_lif' was locked by 'sweep' (ignored update).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "param {'devices': '0', 'single_step': True, 'unique_name': 'main', 'my_seed': 42, 'TIME': 10, 'BATCH': 16, 'IMAGE_SIZE': 128, 'which_data': 'DVS_GESTURE_TONIC', 'data_path': '/data2', 'rate_coding': False, 'lif_layer_v_init': 0, 'lif_layer_v_decay': 0.5, 'lif_layer_v_threshold': 1, 'lif_layer_v_reset': 10000, 'lif_layer_sg_width': 1, 'synapse_conv_kernel_size': 3, 'synapse_conv_stride': 1, 'synapse_conv_padding': 1, 'synapse_trace_const1': 1, 'synapse_trace_const2': 0, 'pre_trained': False, 'convTrue_fcFalse': False, 'cfg': ['M', 'M', 200, 200], 'net_print': True, 'pre_trained_path': 'net_save/save_now_net_weights_{unique_name}.pth', 'learning_rate': 0.0001, 'epoch_num': 100, 'tdBN_on': False, 'BN_on': False, 'surrogate': 'hard_sigmoid', 'BPTT_on': False, 'optimizer_what': 'SGD', 'scheduler_name': 'no', 'ddp_on': False, 'dvs_clipping': 5, 'dvs_duration': 100000, 'DFA_on': True, 'trace_on': True, 'OTTT_input_trace_on': False, 'exclude_class': True, 'merge_polarities': False, 'denoise_on': False, 'extra_train_dataset': 0, 'num_workers': 2, 'chaching_on': True, 'pin_memory': True, 'UDA_on': False, 'alpha_uda': 1, 'bias': True, 'last_lif': False, 'current epoch': 0} \n",
      "\n",
      "dataset_hash = ffa516e60c3efd5e0208f72b4c36cb84\n",
      "cache path exists\n",
      "\n",
      "device ==> cuda\n",
      "\n",
      "DataParallel(\n",
      "  (module): REBORN_MY_SNN_FC(\n",
      "    (layers): REBORN_MY_Sequential(\n",
      "      (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (2): DimChanger_for_FC()\n",
      "      (3): SYNAPSE_FC(in_features=2048, out_features=200, TIME=10, bias=True, sstep=True)\n",
      "      (4): LIF_layer(v_init=0, v_decay=0.5, v_threshold=1, v_reset=10000, sg_width=1, surrogate=hard_sigmoid, BPTT_on=False, trace_const1=1, trace_const2=0, TIME=10, sstep=True, trace_on=True)\n",
      "      (5): Feedback_Receiver()\n",
      "      (6): SYNAPSE_FC(in_features=200, out_features=200, TIME=10, bias=True, sstep=True)\n",
      "      (7): LIF_layer(v_init=0, v_decay=0.5, v_threshold=1, v_reset=10000, sg_width=1, surrogate=hard_sigmoid, BPTT_on=False, trace_const1=1, trace_const2=0, TIME=10, sstep=True, trace_on=True)\n",
      "      (8): Feedback_Receiver()\n",
      "      (9): SYNAPSE_FC(in_features=200, out_features=10, TIME=10, bias=True, sstep=True)\n",
      "      (DFA_top): Top_Gradient()\n",
      "    )\n",
      "  )\n",
      ")\n",
      "\n",
      "========================================================\n",
      "Trainable parameters: 452,010\n",
      "========================================================\n",
      "\n",
      "epoch-0   lr=['0.0001000'], tr/val_loss:  2.303353/  2.303047, val:  10.00%, val_best:  10.00%, tr:  10.01%, tr_best:  10.01%\n",
      "[module.layers.5] weight_fb parameter count: 2,000\n",
      "[module.layers.8] weight_fb parameter count: 2,000\n",
      "epoch-1   lr=['0.0001000'], tr/val_loss:  2.303309/  2.302968, val:  10.00%, val_best:  10.00%, tr:  10.01%, tr_best:  10.01%\n",
      "epoch-2   lr=['0.0001000'], tr/val_loss:  2.303253/  2.302913, val:  10.00%, val_best:  10.00%, tr:  10.01%, tr_best:  10.01%\n",
      "epoch-3   lr=['0.0001000'], tr/val_loss:  2.303180/  2.302890, val:  10.00%, val_best:  10.00%, tr:  10.01%, tr_best:  10.01%\n",
      "epoch-4   lr=['0.0001000'], tr/val_loss:  2.303389/  2.302858, val:  10.00%, val_best:  10.00%, tr:  10.01%, tr_best:  10.01%\n",
      "epoch-5   lr=['0.0001000'], tr/val_loss:  2.303003/  2.302804, val:  10.00%, val_best:  10.00%, tr:  10.01%, tr_best:  10.01%\n",
      "epoch-6   lr=['0.0001000'], tr/val_loss:  2.302944/  2.302766, val:  10.00%, val_best:  10.00%, tr:  10.01%, tr_best:  10.01%\n",
      "epoch-7   lr=['0.0001000'], tr/val_loss:  2.303002/  2.302772, val:  10.00%, val_best:  10.00%, tr:  10.01%, tr_best:  10.01%\n",
      "epoch-8   lr=['0.0001000'], tr/val_loss:  2.302786/  2.302740, val:  10.00%, val_best:  10.00%, tr:  10.01%, tr_best:  10.01%\n",
      "epoch-9   lr=['0.0001000'], tr/val_loss:  2.302635/  2.302746, val:  10.00%, val_best:  10.00%, tr:  10.01%, tr_best:  10.01%\n",
      "epoch-10  lr=['0.0001000'], tr/val_loss:  2.303134/  2.302705, val:  10.42%, val_best:  10.42%, tr:   9.19%, tr_best:  10.01%\n",
      "epoch-11  lr=['0.0001000'], tr/val_loss:  2.303025/  2.302681, val:  10.00%, val_best:  10.42%, tr:   9.09%, tr_best:  10.01%\n",
      "epoch-12  lr=['0.0001000'], tr/val_loss:  2.302653/  2.302617, val:  10.42%, val_best:  10.42%, tr:  10.42%, tr_best:  10.42%\n",
      "epoch-13  lr=['0.0001000'], tr/val_loss:  2.302727/  2.302569, val:  10.42%, val_best:  10.42%, tr:  10.52%, tr_best:  10.52%\n",
      "epoch-14  lr=['0.0001000'], tr/val_loss:  2.302849/  2.302527, val:  10.83%, val_best:  10.83%, tr:  11.24%, tr_best:  11.24%\n",
      "epoch-15  lr=['0.0001000'], tr/val_loss:  2.302574/  2.302402, val:  11.25%, val_best:  11.25%, tr:  11.95%, tr_best:  11.95%\n",
      "epoch-16  lr=['0.0001000'], tr/val_loss:  2.302430/  2.302144, val:  11.67%, val_best:  11.67%, tr:  12.87%, tr_best:  12.87%\n",
      "epoch-17  lr=['0.0001000'], tr/val_loss:  2.301958/  2.301921, val:  11.67%, val_best:  11.67%, tr:  13.38%, tr_best:  13.38%\n",
      "epoch-18  lr=['0.0001000'], tr/val_loss:  2.301435/  2.301417, val:  12.08%, val_best:  12.08%, tr:  13.48%, tr_best:  13.48%\n",
      "epoch-19  lr=['0.0001000'], tr/val_loss:  2.300490/  2.300590, val:  12.92%, val_best:  12.92%, tr:  13.69%, tr_best:  13.69%\n",
      "epoch-20  lr=['0.0001000'], tr/val_loss:  2.298650/  2.299344, val:  12.92%, val_best:  12.92%, tr:  13.69%, tr_best:  13.69%\n",
      "epoch-21  lr=['0.0001000'], tr/val_loss:  2.296091/  2.296970, val:  13.33%, val_best:  13.33%, tr:  13.69%, tr_best:  13.69%\n",
      "epoch-22  lr=['0.0001000'], tr/val_loss:  2.292109/  2.293022, val:  13.33%, val_best:  13.33%, tr:  14.20%, tr_best:  14.20%\n",
      "epoch-23  lr=['0.0001000'], tr/val_loss:  2.286716/  2.288050, val:  14.17%, val_best:  14.17%, tr:  14.20%, tr_best:  14.20%\n",
      "epoch-24  lr=['0.0001000'], tr/val_loss:  2.278727/  2.280196, val:  15.83%, val_best:  15.83%, tr:  14.30%, tr_best:  14.30%\n",
      "epoch-25  lr=['0.0001000'], tr/val_loss:  2.269013/  2.270165, val:  17.50%, val_best:  17.50%, tr:  16.85%, tr_best:  16.85%\n",
      "epoch-26  lr=['0.0001000'], tr/val_loss:  2.253971/  2.257035, val:  20.83%, val_best:  20.83%, tr:  19.92%, tr_best:  19.92%\n",
      "epoch-27  lr=['0.0001000'], tr/val_loss:  2.236587/  2.240644, val:  20.83%, val_best:  20.83%, tr:  24.21%, tr_best:  24.21%\n",
      "epoch-28  lr=['0.0001000'], tr/val_loss:  2.216208/  2.223207, val:  18.33%, val_best:  20.83%, tr:  28.40%, tr_best:  28.40%\n",
      "epoch-29  lr=['0.0001000'], tr/val_loss:  2.190489/  2.202284, val:  30.42%, val_best:  30.42%, tr:  27.99%, tr_best:  28.40%\n",
      "epoch-30  lr=['0.0001000'], tr/val_loss:  2.167029/  2.181231, val:  29.58%, val_best:  30.42%, tr:  30.64%, tr_best:  30.64%\n",
      "epoch-31  lr=['0.0001000'], tr/val_loss:  2.137848/  2.155749, val:  32.08%, val_best:  32.08%, tr:  34.53%, tr_best:  34.53%\n",
      "epoch-32  lr=['0.0001000'], tr/val_loss:  2.108135/  2.132259, val:  35.00%, val_best:  35.00%, tr:  35.34%, tr_best:  35.34%\n",
      "epoch-33  lr=['0.0001000'], tr/val_loss:  2.082650/  2.109235, val:  34.58%, val_best:  35.00%, tr:  36.26%, tr_best:  36.26%\n",
      "epoch-34  lr=['0.0001000'], tr/val_loss:  2.059922/  2.086392, val:  34.58%, val_best:  35.00%, tr:  36.98%, tr_best:  36.98%\n",
      "epoch-35  lr=['0.0001000'], tr/val_loss:  2.025980/  2.063199, val:  40.83%, val_best:  40.83%, tr:  39.12%, tr_best:  39.12%\n",
      "epoch-36  lr=['0.0001000'], tr/val_loss:  2.005484/  2.039632, val:  42.50%, val_best:  42.50%, tr:  41.47%, tr_best:  41.47%\n",
      "epoch-37  lr=['0.0001000'], tr/val_loss:  1.976033/  2.014774, val:  43.75%, val_best:  43.75%, tr:  42.19%, tr_best:  42.19%\n",
      "epoch-38  lr=['0.0001000'], tr/val_loss:  1.948572/  1.993841, val:  46.67%, val_best:  46.67%, tr:  45.25%, tr_best:  45.25%\n",
      "epoch-39  lr=['0.0001000'], tr/val_loss:  1.926412/  1.969543, val:  45.83%, val_best:  46.67%, tr:  46.68%, tr_best:  46.68%\n",
      "epoch-40  lr=['0.0001000'], tr/val_loss:  1.893986/  1.948569, val:  46.67%, val_best:  46.67%, tr:  47.29%, tr_best:  47.29%\n",
      "epoch-41  lr=['0.0001000'], tr/val_loss:  1.867382/  1.926000, val:  46.67%, val_best:  46.67%, tr:  47.40%, tr_best:  47.40%\n",
      "epoch-42  lr=['0.0001000'], tr/val_loss:  1.838350/  1.902776, val:  48.33%, val_best:  48.33%, tr:  49.74%, tr_best:  49.74%\n",
      "epoch-43  lr=['0.0001000'], tr/val_loss:  1.818456/  1.882975, val:  47.08%, val_best:  48.33%, tr:  51.69%, tr_best:  51.69%\n",
      "epoch-44  lr=['0.0001000'], tr/val_loss:  1.794024/  1.865877, val:  45.42%, val_best:  48.33%, tr:  50.77%, tr_best:  51.69%\n",
      "epoch-45  lr=['0.0001000'], tr/val_loss:  1.774608/  1.848442, val:  45.00%, val_best:  48.33%, tr:  50.87%, tr_best:  51.69%\n",
      "epoch-46  lr=['0.0001000'], tr/val_loss:  1.744497/  1.830436, val:  46.25%, val_best:  48.33%, tr:  52.50%, tr_best:  52.50%\n",
      "epoch-47  lr=['0.0001000'], tr/val_loss:  1.729011/  1.816908, val:  45.00%, val_best:  48.33%, tr:  52.20%, tr_best:  52.50%\n",
      "epoch-48  lr=['0.0001000'], tr/val_loss:  1.711027/  1.801955, val:  46.67%, val_best:  48.33%, tr:  53.73%, tr_best:  53.73%\n",
      "epoch-49  lr=['0.0001000'], tr/val_loss:  1.700983/  1.789386, val:  44.58%, val_best:  48.33%, tr:  54.14%, tr_best:  54.14%\n",
      "epoch-50  lr=['0.0001000'], tr/val_loss:  1.683142/  1.778181, val:  47.08%, val_best:  48.33%, tr:  55.36%, tr_best:  55.36%\n",
      "epoch-51  lr=['0.0001000'], tr/val_loss:  1.667257/  1.766829, val:  47.92%, val_best:  48.33%, tr:  54.24%, tr_best:  55.36%\n",
      "epoch-52  lr=['0.0001000'], tr/val_loss:  1.649995/  1.754930, val:  47.92%, val_best:  48.33%, tr:  55.67%, tr_best:  55.67%\n",
      "epoch-53  lr=['0.0001000'], tr/val_loss:  1.641351/  1.744493, val:  50.00%, val_best:  50.00%, tr:  56.69%, tr_best:  56.69%\n",
      "epoch-54  lr=['0.0001000'], tr/val_loss:  1.628847/  1.735431, val:  50.00%, val_best:  50.00%, tr:  55.77%, tr_best:  56.69%\n",
      "epoch-55  lr=['0.0001000'], tr/val_loss:  1.615680/  1.723375, val:  50.83%, val_best:  50.83%, tr:  57.41%, tr_best:  57.41%\n",
      "epoch-56  lr=['0.0001000'], tr/val_loss:  1.602169/  1.717337, val:  52.08%, val_best:  52.08%, tr:  58.73%, tr_best:  58.73%\n",
      "epoch-57  lr=['0.0001000'], tr/val_loss:  1.599645/  1.711005, val:  52.50%, val_best:  52.50%, tr:  58.12%, tr_best:  58.73%\n",
      "epoch-58  lr=['0.0001000'], tr/val_loss:  1.581259/  1.704609, val:  52.50%, val_best:  52.50%, tr:  57.41%, tr_best:  58.73%\n",
      "epoch-59  lr=['0.0001000'], tr/val_loss:  1.580861/  1.696539, val:  50.42%, val_best:  52.50%, tr:  58.32%, tr_best:  58.73%\n",
      "epoch-60  lr=['0.0001000'], tr/val_loss:  1.572153/  1.690796, val:  51.67%, val_best:  52.50%, tr:  58.63%, tr_best:  58.73%\n",
      "epoch-61  lr=['0.0001000'], tr/val_loss:  1.565807/  1.685541, val:  51.67%, val_best:  52.50%, tr:  59.35%, tr_best:  59.35%\n",
      "epoch-62  lr=['0.0001000'], tr/val_loss:  1.557329/  1.682591, val:  52.50%, val_best:  52.50%, tr:  59.04%, tr_best:  59.35%\n",
      "epoch-63  lr=['0.0001000'], tr/val_loss:  1.547765/  1.676053, val:  52.92%, val_best:  52.92%, tr:  59.14%, tr_best:  59.35%\n",
      "epoch-64  lr=['0.0001000'], tr/val_loss:  1.533033/  1.668674, val:  54.58%, val_best:  54.58%, tr:  59.45%, tr_best:  59.45%\n",
      "epoch-65  lr=['0.0001000'], tr/val_loss:  1.531411/  1.662422, val:  53.33%, val_best:  54.58%, tr:  60.88%, tr_best:  60.88%\n",
      "epoch-66  lr=['0.0001000'], tr/val_loss:  1.524534/  1.658281, val:  55.42%, val_best:  55.42%, tr:  59.55%, tr_best:  60.88%\n",
      "epoch-67  lr=['0.0001000'], tr/val_loss:  1.520473/  1.652577, val:  55.42%, val_best:  55.42%, tr:  60.57%, tr_best:  60.88%\n",
      "epoch-68  lr=['0.0001000'], tr/val_loss:  1.510661/  1.649633, val:  55.00%, val_best:  55.42%, tr:  58.53%, tr_best:  60.88%\n",
      "epoch-69  lr=['0.0001000'], tr/val_loss:  1.506791/  1.644202, val:  55.42%, val_best:  55.42%, tr:  61.08%, tr_best:  61.08%\n",
      "epoch-70  lr=['0.0001000'], tr/val_loss:  1.503346/  1.638320, val:  57.50%, val_best:  57.50%, tr:  62.21%, tr_best:  62.21%\n",
      "epoch-71  lr=['0.0001000'], tr/val_loss:  1.491994/  1.636795, val:  56.67%, val_best:  57.50%, tr:  59.24%, tr_best:  62.21%\n",
      "epoch-72  lr=['0.0001000'], tr/val_loss:  1.486781/  1.633764, val:  56.25%, val_best:  57.50%, tr:  59.55%, tr_best:  62.21%\n",
      "epoch-73  lr=['0.0001000'], tr/val_loss:  1.478108/  1.628130, val:  55.83%, val_best:  57.50%, tr:  60.57%, tr_best:  62.21%\n",
      "epoch-74  lr=['0.0001000'], tr/val_loss:  1.470021/  1.623686, val:  57.92%, val_best:  57.92%, tr:  59.55%, tr_best:  62.21%\n",
      "epoch-75  lr=['0.0001000'], tr/val_loss:  1.470605/  1.620104, val:  57.92%, val_best:  57.92%, tr:  60.57%, tr_best:  62.21%\n",
      "epoch-76  lr=['0.0001000'], tr/val_loss:  1.469544/  1.616299, val:  56.25%, val_best:  57.92%, tr:  60.47%, tr_best:  62.21%\n",
      "epoch-77  lr=['0.0001000'], tr/val_loss:  1.463578/  1.610622, val:  57.92%, val_best:  57.92%, tr:  61.80%, tr_best:  62.21%\n",
      "epoch-78  lr=['0.0001000'], tr/val_loss:  1.457923/  1.612055, val:  57.92%, val_best:  57.92%, tr:  61.90%, tr_best:  62.21%\n",
      "epoch-79  lr=['0.0001000'], tr/val_loss:  1.457335/  1.607642, val:  58.33%, val_best:  58.33%, tr:  62.10%, tr_best:  62.21%\n",
      "epoch-80  lr=['0.0001000'], tr/val_loss:  1.449213/  1.604093, val:  59.17%, val_best:  59.17%, tr:  62.82%, tr_best:  62.82%\n",
      "epoch-81  lr=['0.0001000'], tr/val_loss:  1.447928/  1.599687, val:  57.92%, val_best:  59.17%, tr:  62.10%, tr_best:  62.82%\n",
      "epoch-82  lr=['0.0001000'], tr/val_loss:  1.440646/  1.597424, val:  58.33%, val_best:  59.17%, tr:  63.43%, tr_best:  63.43%\n",
      "epoch-83  lr=['0.0001000'], tr/val_loss:  1.439176/  1.597304, val:  58.33%, val_best:  59.17%, tr:  64.35%, tr_best:  64.35%\n",
      "epoch-84  lr=['0.0001000'], tr/val_loss:  1.436526/  1.592139, val:  60.42%, val_best:  60.42%, tr:  62.82%, tr_best:  64.35%\n",
      "epoch-85  lr=['0.0001000'], tr/val_loss:  1.433344/  1.589384, val:  57.92%, val_best:  60.42%, tr:  63.23%, tr_best:  64.35%\n",
      "epoch-86  lr=['0.0001000'], tr/val_loss:  1.424188/  1.584205, val:  59.58%, val_best:  60.42%, tr:  63.23%, tr_best:  64.35%\n",
      "epoch-87  lr=['0.0001000'], tr/val_loss:  1.425337/  1.581472, val:  59.58%, val_best:  60.42%, tr:  63.74%, tr_best:  64.35%\n",
      "epoch-88  lr=['0.0001000'], tr/val_loss:  1.419130/  1.579878, val:  58.75%, val_best:  60.42%, tr:  62.72%, tr_best:  64.35%\n",
      "epoch-89  lr=['0.0001000'], tr/val_loss:  1.415820/  1.579744, val:  61.25%, val_best:  61.25%, tr:  63.23%, tr_best:  64.35%\n",
      "epoch-90  lr=['0.0001000'], tr/val_loss:  1.412250/  1.574789, val:  60.83%, val_best:  61.25%, tr:  63.74%, tr_best:  64.35%\n",
      "epoch-91  lr=['0.0001000'], tr/val_loss:  1.402300/  1.572116, val:  61.67%, val_best:  61.67%, tr:  63.02%, tr_best:  64.35%\n",
      "epoch-92  lr=['0.0001000'], tr/val_loss:  1.405487/  1.568978, val:  59.17%, val_best:  61.67%, tr:  62.21%, tr_best:  64.35%\n",
      "epoch-93  lr=['0.0001000'], tr/val_loss:  1.407403/  1.564256, val:  62.08%, val_best:  62.08%, tr:  63.84%, tr_best:  64.35%\n",
      "epoch-94  lr=['0.0001000'], tr/val_loss:  1.394585/  1.567044, val:  60.42%, val_best:  62.08%, tr:  64.45%, tr_best:  64.45%\n",
      "epoch-95  lr=['0.0001000'], tr/val_loss:  1.397259/  1.565075, val:  62.92%, val_best:  62.92%, tr:  62.82%, tr_best:  64.45%\n",
      "epoch-96  lr=['0.0001000'], tr/val_loss:  1.387677/  1.563213, val:  61.25%, val_best:  62.92%, tr:  63.23%, tr_best:  64.45%\n",
      "epoch-97  lr=['0.0001000'], tr/val_loss:  1.390746/  1.559508, val:  60.00%, val_best:  62.92%, tr:  64.76%, tr_best:  64.76%\n",
      "epoch-98  lr=['0.0001000'], tr/val_loss:  1.388797/  1.557716, val:  63.75%, val_best:  63.75%, tr:  61.18%, tr_best:  64.76%\n",
      "epoch-99  lr=['0.0001000'], tr/val_loss:  1.381102/  1.555060, val:  62.08%, val_best:  63.75%, tr:  65.07%, tr_best:  65.07%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ee78022aceb7486cbcc15ac7f417d7a7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.006 MB of 0.006 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>iter_acc</td><td>▁▂▁▁▁▂▂▃▂▂▃▃▃▁▄▄▄▆▅▅▆▅▄▅▅▅▆▆▆▆▆▅▆▅█▆▄▇▆▅</td></tr><tr><td>summary_val_acc</td><td>▁▁▁▁▁▁▁▁▁▁▂▂▄▄▅▅▆▆▆▆▆▆▆▇▆▇▇▇▇▇▇▇▇▇██████</td></tr><tr><td>tr_acc</td><td>▁▁▁▁▁▁▁▁▁▁▂▂▃▄▅▅▆▆▆▆▇▇▇▇▇▇█▇█▇▇█████████</td></tr><tr><td>tr_epoch_loss</td><td>████████████▇▇▆▅▅▄▄▄▃▃▃▃▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁</td></tr><tr><td>val_acc_best</td><td>▁▁▁▁▁▁▁▁▁▁▂▂▄▄▅▅▆▆▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇███████</td></tr><tr><td>val_acc_now</td><td>▁▁▁▁▁▁▁▁▁▁▂▂▄▄▅▅▆▆▆▆▆▆▆▇▆▇▇▇▇▇▇▇▇▇██████</td></tr><tr><td>val_loss</td><td>████████████▇▆▆▅▅▄▄▃▃▃▃▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>99</td></tr><tr><td>iter_acc</td><td>1.0</td></tr><tr><td>tr_acc</td><td>0.65066</td></tr><tr><td>tr_epoch_loss</td><td>1.3811</td></tr><tr><td>val_acc_best</td><td>0.6375</td></tr><tr><td>val_acc_now</td><td>0.62083</td></tr><tr><td>val_loss</td><td>1.55506</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">drawn-sweep-225</strong> at: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/uohseozy' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/uohseozy</a><br/> View project at: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>/data2/bh_wandb/wandb/run-20250430_070724-uohseozy/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require(\"core\")`! See https://wandb.me/wandb-core for more information."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Sweep Agent: Waiting for job.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Job received.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: jrnwfhbn with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBATCH: 16\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBN_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBPTT_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tDFA_on: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tIMAGE_SIZE: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tOTTT_input_trace_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tTIME: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tUDA_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \talpha_uda: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbias: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcfg: ['M', 'M', 200, 200]\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tchaching_on: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tconvTrue_fcFalse: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdata_path: /data2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tddp_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdenoise_on: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdvs_clipping: 5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdvs_duration: 100000\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepoch_num: 100\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \texclude_class: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \textra_train_dataset: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlast_lif: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.001\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_sg_width: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_decay: 0.5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_init: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_reset: 10000\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_threshold: 0.25\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmerge_polarities: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmy_seed: 42\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnet_print: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_workers: 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer_what: SGD\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tpin_memory: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tpre_trained: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tpre_trained_path: net_save/save_now_net_weights_{unique_name}.pth\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \trate_coding: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tscheduler_name: no\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsingle_step: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsurrogate: hard_sigmoid\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_conv_kernel_size: 3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_conv_padding: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_conv_stride: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_trace_const1: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_trace_const2: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \ttdBN_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \ttrace_on: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \twhich_data: DVS_GESTURE_TONIC\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.19.10 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.17.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/data2/bh_wandb/wandb/run-20250430_071419-jrnwfhbn</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/jrnwfhbn' target=\"_blank\">balmy-sweep-227</a></strong> to <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/6pj3lh8j' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/6pj3lh8j</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/6pj3lh8j' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/6pj3lh8j</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/jrnwfhbn' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/jrnwfhbn</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'single_step' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'my_seed' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'TIME' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BATCH' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'IMAGE_SIZE' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'which_data' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'data_path' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'rate_coding' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_init' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_decay' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_threshold' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_reset' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_sg_width' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_conv_kernel_size' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_conv_stride' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_conv_padding' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_trace_const1' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_trace_const2' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'pre_trained' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'convTrue_fcFalse' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'cfg' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'net_print' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'pre_trained_path' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'learning_rate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'epoch_num' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'tdBN_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BN_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'surrogate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BPTT_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'optimizer_what' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'scheduler_name' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'ddp_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'dvs_clipping' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'dvs_duration' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'DFA_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'trace_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'OTTT_input_trace_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'exclude_class' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'merge_polarities' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'denoise_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'extra_train_dataset' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'num_workers' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'chaching_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'pin_memory' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'UDA_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'alpha_uda' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'bias' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'last_lif' was locked by 'sweep' (ignored update).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "param {'devices': '0', 'single_step': True, 'unique_name': 'main', 'my_seed': 42, 'TIME': 10, 'BATCH': 16, 'IMAGE_SIZE': 128, 'which_data': 'DVS_GESTURE_TONIC', 'data_path': '/data2', 'rate_coding': False, 'lif_layer_v_init': 0, 'lif_layer_v_decay': 0.5, 'lif_layer_v_threshold': 0.25, 'lif_layer_v_reset': 10000, 'lif_layer_sg_width': 1, 'synapse_conv_kernel_size': 3, 'synapse_conv_stride': 1, 'synapse_conv_padding': 1, 'synapse_trace_const1': 1, 'synapse_trace_const2': 0, 'pre_trained': False, 'convTrue_fcFalse': False, 'cfg': ['M', 'M', 200, 200], 'net_print': True, 'pre_trained_path': 'net_save/save_now_net_weights_{unique_name}.pth', 'learning_rate': 0.001, 'epoch_num': 100, 'tdBN_on': False, 'BN_on': False, 'surrogate': 'hard_sigmoid', 'BPTT_on': False, 'optimizer_what': 'SGD', 'scheduler_name': 'no', 'ddp_on': False, 'dvs_clipping': 5, 'dvs_duration': 100000, 'DFA_on': True, 'trace_on': True, 'OTTT_input_trace_on': False, 'exclude_class': True, 'merge_polarities': False, 'denoise_on': True, 'extra_train_dataset': 0, 'num_workers': 2, 'chaching_on': True, 'pin_memory': True, 'UDA_on': False, 'alpha_uda': 1, 'bias': True, 'last_lif': False, 'current epoch': 0} \n",
      "\n",
      "dataset_hash = 63cc597115630ec173f3099200061e53\n",
      "cache path exists\n",
      "\n",
      "device ==> cuda\n",
      "\n",
      "DataParallel(\n",
      "  (module): REBORN_MY_SNN_FC(\n",
      "    (layers): REBORN_MY_Sequential(\n",
      "      (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (2): DimChanger_for_FC()\n",
      "      (3): SYNAPSE_FC(in_features=2048, out_features=200, TIME=10, bias=True, sstep=True)\n",
      "      (4): LIF_layer(v_init=0, v_decay=0.5, v_threshold=0.25, v_reset=10000, sg_width=1, surrogate=hard_sigmoid, BPTT_on=False, trace_const1=1, trace_const2=0, TIME=10, sstep=True, trace_on=True)\n",
      "      (5): Feedback_Receiver()\n",
      "      (6): SYNAPSE_FC(in_features=200, out_features=200, TIME=10, bias=True, sstep=True)\n",
      "      (7): LIF_layer(v_init=0, v_decay=0.5, v_threshold=0.25, v_reset=10000, sg_width=1, surrogate=hard_sigmoid, BPTT_on=False, trace_const1=1, trace_const2=0, TIME=10, sstep=True, trace_on=True)\n",
      "      (8): Feedback_Receiver()\n",
      "      (9): SYNAPSE_FC(in_features=200, out_features=10, TIME=10, bias=True, sstep=True)\n",
      "      (DFA_top): Top_Gradient()\n",
      "    )\n",
      "  )\n",
      ")\n",
      "\n",
      "========================================================\n",
      "Trainable parameters: 452,010\n",
      "========================================================\n",
      "\n",
      "epoch-0   lr=['0.0010000'], tr/val_loss:  2.270306/  2.163778, val:  26.25%, val_best:  26.25%, tr:  11.75%, tr_best:  11.75%\n",
      "[module.layers.5] weight_fb parameter count: 2,000\n",
      "[module.layers.8] weight_fb parameter count: 2,000\n",
      "epoch-1   lr=['0.0010000'], tr/val_loss:  1.900458/  1.750313, val:  52.50%, val_best:  52.50%, tr:  40.14%, tr_best:  40.14%\n",
      "epoch-2   lr=['0.0010000'], tr/val_loss:  1.547570/  1.598625, val:  56.25%, val_best:  56.25%, tr:  57.41%, tr_best:  57.41%\n",
      "epoch-3   lr=['0.0010000'], tr/val_loss:  1.407523/  1.535488, val:  57.50%, val_best:  57.50%, tr:  61.18%, tr_best:  61.18%\n",
      "epoch-4   lr=['0.0010000'], tr/val_loss:  1.335643/  1.504710, val:  60.83%, val_best:  60.83%, tr:  61.90%, tr_best:  61.90%\n",
      "epoch-5   lr=['0.0010000'], tr/val_loss:  1.272357/  1.458155, val:  62.08%, val_best:  62.08%, tr:  63.84%, tr_best:  63.84%\n",
      "epoch-6   lr=['0.0010000'], tr/val_loss:  1.237103/  1.444987, val:  62.08%, val_best:  62.08%, tr:  64.35%, tr_best:  64.35%\n",
      "epoch-7   lr=['0.0010000'], tr/val_loss:  1.204521/  1.408037, val:  60.83%, val_best:  62.08%, tr:  66.60%, tr_best:  66.60%\n",
      "epoch-8   lr=['0.0010000'], tr/val_loss:  1.166575/  1.397674, val:  62.50%, val_best:  62.50%, tr:  66.60%, tr_best:  66.60%\n",
      "epoch-9   lr=['0.0010000'], tr/val_loss:  1.147685/  1.395401, val:  59.58%, val_best:  62.50%, tr:  69.46%, tr_best:  69.46%\n",
      "epoch-10  lr=['0.0010000'], tr/val_loss:  1.121967/  1.396326, val:  59.17%, val_best:  62.50%, tr:  69.25%, tr_best:  69.46%\n",
      "epoch-11  lr=['0.0010000'], tr/val_loss:  1.103052/  1.370950, val:  61.67%, val_best:  62.50%, tr:  68.34%, tr_best:  69.46%\n",
      "epoch-12  lr=['0.0010000'], tr/val_loss:  1.095066/  1.360308, val:  63.75%, val_best:  63.75%, tr:  68.54%, tr_best:  69.46%\n",
      "epoch-13  lr=['0.0010000'], tr/val_loss:  1.080545/  1.347267, val:  63.33%, val_best:  63.75%, tr:  70.38%, tr_best:  70.38%\n",
      "epoch-14  lr=['0.0010000'], tr/val_loss:  1.048573/  1.395936, val:  59.17%, val_best:  63.75%, tr:  69.56%, tr_best:  70.38%\n",
      "epoch-15  lr=['0.0010000'], tr/val_loss:  1.048385/  1.346268, val:  62.50%, val_best:  63.75%, tr:  71.09%, tr_best:  71.09%\n",
      "epoch-16  lr=['0.0010000'], tr/val_loss:  1.035045/  1.336759, val:  62.92%, val_best:  63.75%, tr:  70.58%, tr_best:  71.09%\n",
      "epoch-17  lr=['0.0010000'], tr/val_loss:  1.017158/  1.311127, val:  67.92%, val_best:  67.92%, tr:  74.26%, tr_best:  74.26%\n",
      "epoch-18  lr=['0.0010000'], tr/val_loss:  1.011123/  1.350126, val:  62.50%, val_best:  67.92%, tr:  74.36%, tr_best:  74.36%\n",
      "epoch-19  lr=['0.0010000'], tr/val_loss:  1.005409/  1.334152, val:  60.83%, val_best:  67.92%, tr:  70.58%, tr_best:  74.36%\n",
      "epoch-20  lr=['0.0010000'], tr/val_loss:  0.982527/  1.317477, val:  66.67%, val_best:  67.92%, tr:  74.06%, tr_best:  74.36%\n",
      "epoch-21  lr=['0.0010000'], tr/val_loss:  0.979388/  1.308521, val:  67.50%, val_best:  67.92%, tr:  74.57%, tr_best:  74.57%\n",
      "epoch-22  lr=['0.0010000'], tr/val_loss:  0.981507/  1.332686, val:  63.33%, val_best:  67.92%, tr:  72.93%, tr_best:  74.57%\n",
      "epoch-23  lr=['0.0010000'], tr/val_loss:  0.957867/  1.322754, val:  62.92%, val_best:  67.92%, tr:  74.26%, tr_best:  74.57%\n",
      "epoch-24  lr=['0.0010000'], tr/val_loss:  0.938146/  1.326139, val:  64.17%, val_best:  67.92%, tr:  77.94%, tr_best:  77.94%\n",
      "epoch-25  lr=['0.0010000'], tr/val_loss:  0.943520/  1.303173, val:  66.25%, val_best:  67.92%, tr:  76.00%, tr_best:  77.94%\n",
      "epoch-26  lr=['0.0010000'], tr/val_loss:  0.936586/  1.300667, val:  64.58%, val_best:  67.92%, tr:  74.87%, tr_best:  77.94%\n",
      "epoch-27  lr=['0.0010000'], tr/val_loss:  0.914859/  1.329099, val:  62.50%, val_best:  67.92%, tr:  79.16%, tr_best:  79.16%\n",
      "epoch-28  lr=['0.0010000'], tr/val_loss:  0.914797/  1.290783, val:  67.92%, val_best:  67.92%, tr:  78.04%, tr_best:  79.16%\n",
      "epoch-29  lr=['0.0010000'], tr/val_loss:  0.896026/  1.321613, val:  61.67%, val_best:  67.92%, tr:  80.08%, tr_best:  80.08%\n",
      "epoch-30  lr=['0.0010000'], tr/val_loss:  0.892514/  1.312131, val:  61.67%, val_best:  67.92%, tr:  81.00%, tr_best:  81.00%\n",
      "epoch-31  lr=['0.0010000'], tr/val_loss:  0.905273/  1.340049, val:  61.67%, val_best:  67.92%, tr:  77.32%, tr_best:  81.00%\n",
      "epoch-32  lr=['0.0010000'], tr/val_loss:  0.887955/  1.323148, val:  62.08%, val_best:  67.92%, tr:  79.88%, tr_best:  81.00%\n",
      "epoch-33  lr=['0.0010000'], tr/val_loss:  0.874939/  1.345428, val:  66.67%, val_best:  67.92%, tr:  82.12%, tr_best:  82.12%\n",
      "epoch-34  lr=['0.0010000'], tr/val_loss:  0.862426/  1.338186, val:  65.00%, val_best:  67.92%, tr:  80.59%, tr_best:  82.12%\n",
      "epoch-35  lr=['0.0010000'], tr/val_loss:  0.870964/  1.344460, val:  65.42%, val_best:  67.92%, tr:  80.59%, tr_best:  82.12%\n",
      "epoch-36  lr=['0.0010000'], tr/val_loss:  0.842716/  1.332763, val:  66.67%, val_best:  67.92%, tr:  82.74%, tr_best:  82.74%\n",
      "epoch-37  lr=['0.0010000'], tr/val_loss:  0.852091/  1.326181, val:  67.08%, val_best:  67.92%, tr:  84.88%, tr_best:  84.88%\n",
      "epoch-38  lr=['0.0010000'], tr/val_loss:  0.845138/  1.322604, val:  69.17%, val_best:  69.17%, tr:  84.27%, tr_best:  84.88%\n",
      "epoch-39  lr=['0.0010000'], tr/val_loss:  0.833200/  1.329200, val:  64.17%, val_best:  69.17%, tr:  86.01%, tr_best:  86.01%\n",
      "epoch-40  lr=['0.0010000'], tr/val_loss:  0.832923/  1.336820, val:  65.83%, val_best:  69.17%, tr:  84.58%, tr_best:  86.01%\n",
      "epoch-41  lr=['0.0010000'], tr/val_loss:  0.822696/  1.345672, val:  65.83%, val_best:  69.17%, tr:  86.93%, tr_best:  86.93%\n",
      "epoch-42  lr=['0.0010000'], tr/val_loss:  0.820472/  1.339002, val:  64.17%, val_best:  69.17%, tr:  85.09%, tr_best:  86.93%\n",
      "epoch-43  lr=['0.0010000'], tr/val_loss:  0.805753/  1.360670, val:  67.92%, val_best:  69.17%, tr:  86.52%, tr_best:  86.93%\n",
      "epoch-44  lr=['0.0010000'], tr/val_loss:  0.807334/  1.345130, val:  67.92%, val_best:  69.17%, tr:  85.70%, tr_best:  86.93%\n",
      "epoch-45  lr=['0.0010000'], tr/val_loss:  0.797568/  1.340272, val:  68.33%, val_best:  69.17%, tr:  86.62%, tr_best:  86.93%\n",
      "epoch-46  lr=['0.0010000'], tr/val_loss:  0.790684/  1.358526, val:  66.67%, val_best:  69.17%, tr:  87.74%, tr_best:  87.74%\n",
      "epoch-47  lr=['0.0010000'], tr/val_loss:  0.787241/  1.356203, val:  67.50%, val_best:  69.17%, tr:  87.84%, tr_best:  87.84%\n",
      "epoch-48  lr=['0.0010000'], tr/val_loss:  0.794696/  1.350355, val:  69.17%, val_best:  69.17%, tr:  90.09%, tr_best:  90.09%\n",
      "epoch-49  lr=['0.0010000'], tr/val_loss:  0.793579/  1.342504, val:  68.33%, val_best:  69.17%, tr:  86.72%, tr_best:  90.09%\n",
      "epoch-50  lr=['0.0010000'], tr/val_loss:  0.787115/  1.358008, val:  69.17%, val_best:  69.17%, tr:  88.66%, tr_best:  90.09%\n",
      "epoch-51  lr=['0.0010000'], tr/val_loss:  0.781443/  1.373490, val:  67.08%, val_best:  69.17%, tr:  87.84%, tr_best:  90.09%\n",
      "epoch-52  lr=['0.0010000'], tr/val_loss:  0.767366/  1.403645, val:  64.58%, val_best:  69.17%, tr:  87.44%, tr_best:  90.09%\n",
      "epoch-53  lr=['0.0010000'], tr/val_loss:  0.772246/  1.356492, val:  67.08%, val_best:  69.17%, tr:  87.44%, tr_best:  90.09%\n",
      "epoch-54  lr=['0.0010000'], tr/val_loss:  0.764991/  1.385389, val:  67.50%, val_best:  69.17%, tr:  89.68%, tr_best:  90.09%\n",
      "epoch-55  lr=['0.0010000'], tr/val_loss:  0.766094/  1.382858, val:  67.92%, val_best:  69.17%, tr:  87.74%, tr_best:  90.09%\n",
      "epoch-56  lr=['0.0010000'], tr/val_loss:  0.760705/  1.424356, val:  67.08%, val_best:  69.17%, tr:  89.17%, tr_best:  90.09%\n",
      "epoch-57  lr=['0.0010000'], tr/val_loss:  0.762481/  1.380894, val:  67.08%, val_best:  69.17%, tr:  88.97%, tr_best:  90.09%\n",
      "epoch-58  lr=['0.0010000'], tr/val_loss:  0.739720/  1.400695, val:  66.67%, val_best:  69.17%, tr:  89.58%, tr_best:  90.09%\n",
      "epoch-59  lr=['0.0010000'], tr/val_loss:  0.742840/  1.379439, val:  70.42%, val_best:  70.42%, tr:  89.38%, tr_best:  90.09%\n",
      "epoch-60  lr=['0.0010000'], tr/val_loss:  0.742371/  1.367163, val:  67.50%, val_best:  70.42%, tr:  90.81%, tr_best:  90.81%\n",
      "epoch-61  lr=['0.0010000'], tr/val_loss:  0.739193/  1.394047, val:  68.75%, val_best:  70.42%, tr:  90.09%, tr_best:  90.81%\n",
      "epoch-62  lr=['0.0010000'], tr/val_loss:  0.740467/  1.408408, val:  67.08%, val_best:  70.42%, tr:  90.09%, tr_best:  90.81%\n",
      "epoch-63  lr=['0.0010000'], tr/val_loss:  0.732710/  1.370149, val:  67.92%, val_best:  70.42%, tr:  91.93%, tr_best:  91.93%\n",
      "epoch-64  lr=['0.0010000'], tr/val_loss:  0.732389/  1.442714, val:  65.83%, val_best:  70.42%, tr:  90.60%, tr_best:  91.93%\n",
      "epoch-65  lr=['0.0010000'], tr/val_loss:  0.728885/  1.403430, val:  69.17%, val_best:  70.42%, tr:  90.60%, tr_best:  91.93%\n",
      "epoch-66  lr=['0.0010000'], tr/val_loss:  0.726669/  1.386374, val:  69.17%, val_best:  70.42%, tr:  90.81%, tr_best:  91.93%\n",
      "epoch-67  lr=['0.0010000'], tr/val_loss:  0.731075/  1.395202, val:  70.83%, val_best:  70.83%, tr:  91.11%, tr_best:  91.93%\n",
      "epoch-68  lr=['0.0010000'], tr/val_loss:  0.714254/  1.403214, val:  68.75%, val_best:  70.83%, tr:  90.50%, tr_best:  91.93%\n",
      "epoch-69  lr=['0.0010000'], tr/val_loss:  0.719445/  1.402364, val:  65.83%, val_best:  70.83%, tr:  91.93%, tr_best:  91.93%\n",
      "epoch-70  lr=['0.0010000'], tr/val_loss:  0.711303/  1.402334, val:  68.33%, val_best:  70.83%, tr:  91.62%, tr_best:  91.93%\n",
      "epoch-71  lr=['0.0010000'], tr/val_loss:  0.704909/  1.462035, val:  65.83%, val_best:  70.83%, tr:  91.83%, tr_best:  91.93%\n",
      "epoch-72  lr=['0.0010000'], tr/val_loss:  0.702362/  1.455827, val:  65.42%, val_best:  70.83%, tr:  92.65%, tr_best:  92.65%\n",
      "epoch-73  lr=['0.0010000'], tr/val_loss:  0.713248/  1.420898, val:  70.00%, val_best:  70.83%, tr:  90.40%, tr_best:  92.65%\n",
      "epoch-74  lr=['0.0010000'], tr/val_loss:  0.696053/  1.428615, val:  67.08%, val_best:  70.83%, tr:  93.26%, tr_best:  93.26%\n",
      "epoch-75  lr=['0.0010000'], tr/val_loss:  0.700552/  1.445522, val:  65.42%, val_best:  70.83%, tr:  91.11%, tr_best:  93.26%\n",
      "epoch-76  lr=['0.0010000'], tr/val_loss:  0.687419/  1.468625, val:  67.08%, val_best:  70.83%, tr:  91.93%, tr_best:  93.26%\n",
      "epoch-77  lr=['0.0010000'], tr/val_loss:  0.705423/  1.459609, val:  65.83%, val_best:  70.83%, tr:  91.52%, tr_best:  93.26%\n",
      "epoch-78  lr=['0.0010000'], tr/val_loss:  0.702876/  1.449637, val:  65.83%, val_best:  70.83%, tr:  91.11%, tr_best:  93.26%\n",
      "epoch-79  lr=['0.0010000'], tr/val_loss:  0.687894/  1.429662, val:  67.50%, val_best:  70.83%, tr:  92.13%, tr_best:  93.26%\n",
      "epoch-80  lr=['0.0010000'], tr/val_loss:  0.675603/  1.459595, val:  67.92%, val_best:  70.83%, tr:  92.65%, tr_best:  93.26%\n",
      "epoch-81  lr=['0.0010000'], tr/val_loss:  0.685795/  1.430127, val:  67.08%, val_best:  70.83%, tr:  92.24%, tr_best:  93.26%\n",
      "epoch-82  lr=['0.0010000'], tr/val_loss:  0.684002/  1.462995, val:  66.25%, val_best:  70.83%, tr:  92.13%, tr_best:  93.26%\n",
      "epoch-83  lr=['0.0010000'], tr/val_loss:  0.679428/  1.458654, val:  70.42%, val_best:  70.83%, tr:  92.54%, tr_best:  93.26%\n",
      "epoch-84  lr=['0.0010000'], tr/val_loss:  0.684194/  1.435114, val:  67.92%, val_best:  70.83%, tr:  93.87%, tr_best:  93.87%\n",
      "epoch-85  lr=['0.0010000'], tr/val_loss:  0.671389/  1.469934, val:  63.75%, val_best:  70.83%, tr:  94.18%, tr_best:  94.18%\n",
      "epoch-86  lr=['0.0010000'], tr/val_loss:  0.668378/  1.456429, val:  69.17%, val_best:  70.83%, tr:  92.34%, tr_best:  94.18%\n",
      "epoch-87  lr=['0.0010000'], tr/val_loss:  0.668733/  1.484133, val:  68.33%, val_best:  70.83%, tr:  94.08%, tr_best:  94.18%\n",
      "epoch-88  lr=['0.0010000'], tr/val_loss:  0.661195/  1.467824, val:  67.50%, val_best:  70.83%, tr:  93.46%, tr_best:  94.18%\n",
      "epoch-89  lr=['0.0010000'], tr/val_loss:  0.654995/  1.504701, val:  66.67%, val_best:  70.83%, tr:  93.97%, tr_best:  94.18%\n",
      "epoch-90  lr=['0.0010000'], tr/val_loss:  0.659697/  1.446663, val:  68.33%, val_best:  70.83%, tr:  93.97%, tr_best:  94.18%\n",
      "epoch-91  lr=['0.0010000'], tr/val_loss:  0.657555/  1.482988, val:  66.67%, val_best:  70.83%, tr:  93.26%, tr_best:  94.18%\n",
      "epoch-92  lr=['0.0010000'], tr/val_loss:  0.651710/  1.529077, val:  63.75%, val_best:  70.83%, tr:  93.05%, tr_best:  94.18%\n",
      "epoch-93  lr=['0.0010000'], tr/val_loss:  0.650787/  1.489415, val:  68.33%, val_best:  70.83%, tr:  93.67%, tr_best:  94.18%\n",
      "epoch-94  lr=['0.0010000'], tr/val_loss:  0.654612/  1.542794, val:  65.42%, val_best:  70.83%, tr:  93.36%, tr_best:  94.18%\n",
      "epoch-95  lr=['0.0010000'], tr/val_loss:  0.658225/  1.555622, val:  64.58%, val_best:  70.83%, tr:  93.05%, tr_best:  94.18%\n",
      "epoch-96  lr=['0.0010000'], tr/val_loss:  0.658700/  1.589399, val:  67.92%, val_best:  70.83%, tr:  92.85%, tr_best:  94.18%\n",
      "epoch-97  lr=['0.0010000'], tr/val_loss:  0.657821/  1.514124, val:  67.08%, val_best:  70.83%, tr:  91.01%, tr_best:  94.18%\n",
      "epoch-98  lr=['0.0010000'], tr/val_loss:  0.643226/  1.534510, val:  65.42%, val_best:  70.83%, tr:  93.56%, tr_best:  94.18%\n",
      "epoch-99  lr=['0.0010000'], tr/val_loss:  0.661665/  1.529029, val:  65.00%, val_best:  70.83%, tr:  92.65%, tr_best:  94.18%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "405efd451831439a80f11010b24d455d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.006 MB of 0.006 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>iter_acc</td><td>▂▆▃▃▃▅▆▁▃▅▄▇▅▆▅▇█▇▇▇██▇▇██▇██▅██▅▇▆▇▇▇█▇</td></tr><tr><td>summary_val_acc</td><td>▁▆▆▆▆▇▆█▆▇▇▇▇▇▇▇▇▇█▇█▇▇▇█████▇▇▇▇▇██▇▇▇▇</td></tr><tr><td>tr_acc</td><td>▁▅▅▆▆▆▆▆▆▆▇▆▇▇▇▇▇▇▇▇▇▇██████████████████</td></tr><tr><td>tr_epoch_loss</td><td>█▅▄▃▃▃▃▃▃▂▂▂▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_acc_best</td><td>▁▆▆▇▇▇▇█████████████████████████████████</td></tr><tr><td>val_acc_now</td><td>▁▆▆▆▆▇▆█▆▇▇▇▇▇▇▇▇▇█▇█▇▇▇█████▇▇▇▇▇██▇▇▇▇</td></tr><tr><td>val_loss</td><td>█▃▃▂▂▁▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▃▃▃▃</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>99</td></tr><tr><td>iter_acc</td><td>1.0</td></tr><tr><td>tr_acc</td><td>0.92646</td></tr><tr><td>tr_epoch_loss</td><td>0.66167</td></tr><tr><td>val_acc_best</td><td>0.70833</td></tr><tr><td>val_acc_now</td><td>0.65</td></tr><tr><td>val_loss</td><td>1.52903</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">balmy-sweep-227</strong> at: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/jrnwfhbn' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/jrnwfhbn</a><br/> View project at: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>/data2/bh_wandb/wandb/run-20250430_071419-jrnwfhbn/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require(\"core\")`! See https://wandb.me/wandb-core for more information."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 2l075vuy with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBATCH: 16\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBN_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBPTT_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tDFA_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tIMAGE_SIZE: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tOTTT_input_trace_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tTIME: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tUDA_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \talpha_uda: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbias: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcfg: ['M', 'M', 200, 200]\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tchaching_on: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tconvTrue_fcFalse: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdata_path: /data2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tddp_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdenoise_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdvs_clipping: 5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdvs_duration: 100000\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepoch_num: 100\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \texclude_class: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \textra_train_dataset: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlast_lif: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.001\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_sg_width: 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_decay: 0.5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_init: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_reset: 10000\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_threshold: 0.75\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmerge_polarities: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmy_seed: 42\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnet_print: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_workers: 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer_what: SGD\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tpin_memory: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tpre_trained: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tpre_trained_path: net_save/save_now_net_weights_{unique_name}.pth\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \trate_coding: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tscheduler_name: no\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsingle_step: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsurrogate: hard_sigmoid\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_conv_kernel_size: 3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_conv_padding: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_conv_stride: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_trace_const1: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_trace_const2: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \ttdBN_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \ttrace_on: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \twhich_data: DVS_GESTURE_TONIC\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.19.10 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.17.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/data2/bh_wandb/wandb/run-20250430_072052-2l075vuy</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/2l075vuy' target=\"_blank\">happy-sweep-229</a></strong> to <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/6pj3lh8j' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/6pj3lh8j</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/6pj3lh8j' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/6pj3lh8j</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/2l075vuy' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/2l075vuy</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'single_step' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'my_seed' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'TIME' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BATCH' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'IMAGE_SIZE' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'which_data' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'data_path' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'rate_coding' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_init' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_decay' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_threshold' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_reset' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_sg_width' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_conv_kernel_size' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_conv_stride' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_conv_padding' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_trace_const1' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_trace_const2' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'pre_trained' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'convTrue_fcFalse' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'cfg' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'net_print' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'pre_trained_path' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'learning_rate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'epoch_num' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'tdBN_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BN_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'surrogate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BPTT_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'optimizer_what' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'scheduler_name' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'ddp_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'dvs_clipping' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'dvs_duration' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'DFA_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'trace_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'OTTT_input_trace_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'exclude_class' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'merge_polarities' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'denoise_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'extra_train_dataset' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'num_workers' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'chaching_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'pin_memory' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'UDA_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'alpha_uda' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'bias' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'last_lif' was locked by 'sweep' (ignored update).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "param {'devices': '0', 'single_step': True, 'unique_name': 'main', 'my_seed': 42, 'TIME': 10, 'BATCH': 16, 'IMAGE_SIZE': 128, 'which_data': 'DVS_GESTURE_TONIC', 'data_path': '/data2', 'rate_coding': False, 'lif_layer_v_init': 0, 'lif_layer_v_decay': 0.5, 'lif_layer_v_threshold': 0.75, 'lif_layer_v_reset': 10000, 'lif_layer_sg_width': 2, 'synapse_conv_kernel_size': 3, 'synapse_conv_stride': 1, 'synapse_conv_padding': 1, 'synapse_trace_const1': 1, 'synapse_trace_const2': 0, 'pre_trained': False, 'convTrue_fcFalse': False, 'cfg': ['M', 'M', 200, 200], 'net_print': True, 'pre_trained_path': 'net_save/save_now_net_weights_{unique_name}.pth', 'learning_rate': 0.001, 'epoch_num': 100, 'tdBN_on': False, 'BN_on': False, 'surrogate': 'hard_sigmoid', 'BPTT_on': False, 'optimizer_what': 'SGD', 'scheduler_name': 'no', 'ddp_on': False, 'dvs_clipping': 5, 'dvs_duration': 100000, 'DFA_on': False, 'trace_on': True, 'OTTT_input_trace_on': False, 'exclude_class': True, 'merge_polarities': False, 'denoise_on': False, 'extra_train_dataset': 0, 'num_workers': 2, 'chaching_on': True, 'pin_memory': True, 'UDA_on': False, 'alpha_uda': 1, 'bias': True, 'last_lif': False, 'current epoch': 0} \n",
      "\n",
      "dataset_hash = ffa516e60c3efd5e0208f72b4c36cb84\n",
      "cache path exists\n",
      "\n",
      "device ==> cuda\n",
      "\n",
      "DataParallel(\n",
      "  (module): REBORN_MY_SNN_FC(\n",
      "    (layers): REBORN_MY_Sequential(\n",
      "      (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (2): DimChanger_for_FC()\n",
      "      (3): SYNAPSE_FC(in_features=2048, out_features=200, TIME=10, bias=True, sstep=True)\n",
      "      (4): LIF_layer(v_init=0, v_decay=0.5, v_threshold=0.75, v_reset=10000, sg_width=2, surrogate=hard_sigmoid, BPTT_on=False, trace_const1=1, trace_const2=0, TIME=10, sstep=True, trace_on=True)\n",
      "      (5): SYNAPSE_FC(in_features=200, out_features=200, TIME=10, bias=True, sstep=True)\n",
      "      (6): LIF_layer(v_init=0, v_decay=0.5, v_threshold=0.75, v_reset=10000, sg_width=2, surrogate=hard_sigmoid, BPTT_on=False, trace_const1=1, trace_const2=0, TIME=10, sstep=True, trace_on=True)\n",
      "      (7): SYNAPSE_FC(in_features=200, out_features=10, TIME=10, bias=True, sstep=True)\n",
      "    )\n",
      "  )\n",
      ")\n",
      "\n",
      "========================================================\n",
      "Trainable parameters: 452,010\n",
      "========================================================\n",
      "\n",
      "epoch-0   lr=['0.0010000'], tr/val_loss:  2.305365/  2.302841, val:  10.00%, val_best:  10.00%, tr:   8.17%, tr_best:   8.17%\n",
      "epoch-1   lr=['0.0010000'], tr/val_loss:  2.304994/  2.302639, val:  10.00%, val_best:  10.00%, tr:   7.66%, tr_best:   8.17%\n",
      "epoch-2   lr=['0.0010000'], tr/val_loss:  2.305073/  2.302682, val:  10.00%, val_best:  10.00%, tr:   8.99%, tr_best:   8.99%\n",
      "epoch-3   lr=['0.0010000'], tr/val_loss:  2.304692/  2.302443, val:  10.42%, val_best:  10.42%, tr:   8.27%, tr_best:   8.99%\n",
      "epoch-4   lr=['0.0010000'], tr/val_loss:  2.302412/  2.297489, val:  17.50%, val_best:  17.50%, tr:   9.09%, tr_best:   9.09%\n",
      "epoch-5   lr=['0.0010000'], tr/val_loss:  2.276176/  2.256529, val:  20.83%, val_best:  20.83%, tr:  15.73%, tr_best:  15.73%\n",
      "epoch-6   lr=['0.0010000'], tr/val_loss:  2.189294/  2.156853, val:  35.83%, val_best:  35.83%, tr:  24.41%, tr_best:  24.41%\n",
      "epoch-7   lr=['0.0010000'], tr/val_loss:  2.017906/  1.958527, val:  37.92%, val_best:  37.92%, tr:  37.69%, tr_best:  37.69%\n",
      "epoch-8   lr=['0.0010000'], tr/val_loss:  1.789710/  1.770809, val:  48.75%, val_best:  48.75%, tr:  43.51%, tr_best:  43.51%\n",
      "epoch-9   lr=['0.0010000'], tr/val_loss:  1.627141/  1.680801, val:  49.17%, val_best:  49.17%, tr:  53.42%, tr_best:  53.42%\n",
      "epoch-10  lr=['0.0010000'], tr/val_loss:  1.525944/  1.606394, val:  53.33%, val_best:  53.33%, tr:  53.12%, tr_best:  53.42%\n",
      "epoch-11  lr=['0.0010000'], tr/val_loss:  1.461870/  1.544421, val:  55.83%, val_best:  55.83%, tr:  56.08%, tr_best:  56.08%\n",
      "epoch-12  lr=['0.0010000'], tr/val_loss:  1.417475/  1.510389, val:  57.08%, val_best:  57.08%, tr:  57.10%, tr_best:  57.10%\n",
      "epoch-13  lr=['0.0010000'], tr/val_loss:  1.378139/  1.490860, val:  56.25%, val_best:  57.08%, tr:  57.41%, tr_best:  57.41%\n",
      "epoch-14  lr=['0.0010000'], tr/val_loss:  1.316994/  1.517066, val:  55.00%, val_best:  57.08%, tr:  60.57%, tr_best:  60.57%\n",
      "epoch-15  lr=['0.0010000'], tr/val_loss:  1.303409/  1.466598, val:  59.58%, val_best:  59.58%, tr:  60.67%, tr_best:  60.67%\n",
      "epoch-16  lr=['0.0010000'], tr/val_loss:  1.271128/  1.460045, val:  55.00%, val_best:  59.58%, tr:  61.29%, tr_best:  61.29%\n",
      "epoch-17  lr=['0.0010000'], tr/val_loss:  1.234525/  1.425571, val:  60.00%, val_best:  60.00%, tr:  63.64%, tr_best:  63.64%\n",
      "epoch-18  lr=['0.0010000'], tr/val_loss:  1.207505/  1.458804, val:  57.92%, val_best:  60.00%, tr:  63.94%, tr_best:  63.94%\n",
      "epoch-19  lr=['0.0010000'], tr/val_loss:  1.202557/  1.467959, val:  55.83%, val_best:  60.00%, tr:  64.35%, tr_best:  64.35%\n",
      "epoch-20  lr=['0.0010000'], tr/val_loss:  1.161223/  1.435737, val:  60.42%, val_best:  60.42%, tr:  65.88%, tr_best:  65.88%\n",
      "epoch-21  lr=['0.0010000'], tr/val_loss:  1.145062/  1.412142, val:  60.42%, val_best:  60.42%, tr:  64.35%, tr_best:  65.88%\n",
      "epoch-22  lr=['0.0010000'], tr/val_loss:  1.143074/  1.405713, val:  62.08%, val_best:  62.08%, tr:  66.50%, tr_best:  66.50%\n",
      "epoch-23  lr=['0.0010000'], tr/val_loss:  1.104186/  1.384640, val:  64.17%, val_best:  64.17%, tr:  66.09%, tr_best:  66.50%\n",
      "epoch-24  lr=['0.0010000'], tr/val_loss:  1.084006/  1.401150, val:  60.83%, val_best:  64.17%, tr:  68.34%, tr_best:  68.34%\n",
      "epoch-25  lr=['0.0010000'], tr/val_loss:  1.073405/  1.368930, val:  62.50%, val_best:  64.17%, tr:  67.31%, tr_best:  68.34%\n",
      "epoch-26  lr=['0.0010000'], tr/val_loss:  1.058006/  1.351905, val:  67.08%, val_best:  67.08%, tr:  68.64%, tr_best:  68.64%\n",
      "epoch-27  lr=['0.0010000'], tr/val_loss:  1.037141/  1.400456, val:  60.83%, val_best:  67.08%, tr:  70.17%, tr_best:  70.17%\n",
      "epoch-28  lr=['0.0010000'], tr/val_loss:  1.036229/  1.361247, val:  62.92%, val_best:  67.08%, tr:  70.79%, tr_best:  70.79%\n",
      "epoch-29  lr=['0.0010000'], tr/val_loss:  1.007429/  1.368635, val:  63.33%, val_best:  67.08%, tr:  72.42%, tr_best:  72.42%\n",
      "epoch-30  lr=['0.0010000'], tr/val_loss:  0.991146/  1.375375, val:  62.50%, val_best:  67.08%, tr:  70.89%, tr_best:  72.42%\n",
      "epoch-31  lr=['0.0010000'], tr/val_loss:  0.992019/  1.388954, val:  61.25%, val_best:  67.08%, tr:  69.36%, tr_best:  72.42%\n",
      "epoch-32  lr=['0.0010000'], tr/val_loss:  0.978900/  1.379263, val:  65.42%, val_best:  67.08%, tr:  71.09%, tr_best:  72.42%\n",
      "epoch-33  lr=['0.0010000'], tr/val_loss:  0.962586/  1.369268, val:  65.42%, val_best:  67.08%, tr:  73.24%, tr_best:  73.24%\n",
      "epoch-34  lr=['0.0010000'], tr/val_loss:  0.941303/  1.370611, val:  65.00%, val_best:  67.08%, tr:  71.09%, tr_best:  73.24%\n",
      "epoch-35  lr=['0.0010000'], tr/val_loss:  0.940195/  1.404364, val:  62.92%, val_best:  67.08%, tr:  72.32%, tr_best:  73.24%\n",
      "epoch-36  lr=['0.0010000'], tr/val_loss:  0.916215/  1.372151, val:  65.00%, val_best:  67.08%, tr:  73.14%, tr_best:  73.24%\n",
      "epoch-37  lr=['0.0010000'], tr/val_loss:  0.913708/  1.384520, val:  64.58%, val_best:  67.08%, tr:  75.79%, tr_best:  75.79%\n",
      "epoch-38  lr=['0.0010000'], tr/val_loss:  0.903560/  1.366378, val:  62.92%, val_best:  67.08%, tr:  74.97%, tr_best:  75.79%\n",
      "epoch-39  lr=['0.0010000'], tr/val_loss:  0.885550/  1.385789, val:  64.17%, val_best:  67.08%, tr:  75.28%, tr_best:  75.79%\n",
      "epoch-40  lr=['0.0010000'], tr/val_loss:  0.875853/  1.371514, val:  64.17%, val_best:  67.08%, tr:  75.69%, tr_best:  75.79%\n",
      "epoch-41  lr=['0.0010000'], tr/val_loss:  0.863718/  1.392289, val:  66.67%, val_best:  67.08%, tr:  79.37%, tr_best:  79.37%\n",
      "epoch-42  lr=['0.0010000'], tr/val_loss:  0.845929/  1.400088, val:  62.92%, val_best:  67.08%, tr:  77.22%, tr_best:  79.37%\n",
      "epoch-43  lr=['0.0010000'], tr/val_loss:  0.840711/  1.389070, val:  63.33%, val_best:  67.08%, tr:  79.67%, tr_best:  79.67%\n",
      "epoch-44  lr=['0.0010000'], tr/val_loss:  0.826702/  1.389252, val:  66.25%, val_best:  67.08%, tr:  78.14%, tr_best:  79.67%\n",
      "epoch-45  lr=['0.0010000'], tr/val_loss:  0.812249/  1.388664, val:  65.42%, val_best:  67.08%, tr:  79.57%, tr_best:  79.67%\n",
      "epoch-46  lr=['0.0010000'], tr/val_loss:  0.801666/  1.408214, val:  66.25%, val_best:  67.08%, tr:  80.90%, tr_best:  80.90%\n",
      "epoch-47  lr=['0.0010000'], tr/val_loss:  0.796674/  1.416944, val:  69.17%, val_best:  69.17%, tr:  79.78%, tr_best:  80.90%\n",
      "epoch-48  lr=['0.0010000'], tr/val_loss:  0.793836/  1.429643, val:  70.00%, val_best:  70.00%, tr:  82.53%, tr_best:  82.53%\n",
      "epoch-49  lr=['0.0010000'], tr/val_loss:  0.780534/  1.403553, val:  69.58%, val_best:  70.00%, tr:  79.88%, tr_best:  82.53%\n",
      "epoch-50  lr=['0.0010000'], tr/val_loss:  0.774389/  1.417503, val:  67.08%, val_best:  70.00%, tr:  81.92%, tr_best:  82.53%\n",
      "epoch-51  lr=['0.0010000'], tr/val_loss:  0.751755/  1.417777, val:  71.67%, val_best:  71.67%, tr:  83.55%, tr_best:  83.55%\n",
      "epoch-52  lr=['0.0010000'], tr/val_loss:  0.741871/  1.488380, val:  64.58%, val_best:  71.67%, tr:  82.23%, tr_best:  83.55%\n",
      "epoch-53  lr=['0.0010000'], tr/val_loss:  0.738030/  1.439900, val:  68.75%, val_best:  71.67%, tr:  82.64%, tr_best:  83.55%\n",
      "epoch-54  lr=['0.0010000'], tr/val_loss:  0.720283/  1.440325, val:  70.42%, val_best:  71.67%, tr:  86.93%, tr_best:  86.93%\n",
      "epoch-55  lr=['0.0010000'], tr/val_loss:  0.719638/  1.458344, val:  70.42%, val_best:  71.67%, tr:  83.45%, tr_best:  86.93%\n",
      "epoch-56  lr=['0.0010000'], tr/val_loss:  0.705556/  1.508419, val:  65.83%, val_best:  71.67%, tr:  86.31%, tr_best:  86.93%\n",
      "epoch-57  lr=['0.0010000'], tr/val_loss:  0.705195/  1.470353, val:  68.75%, val_best:  71.67%, tr:  85.09%, tr_best:  86.93%\n",
      "epoch-58  lr=['0.0010000'], tr/val_loss:  0.672903/  1.495888, val:  66.25%, val_best:  71.67%, tr:  85.70%, tr_best:  86.93%\n",
      "epoch-59  lr=['0.0010000'], tr/val_loss:  0.673977/  1.489834, val:  68.75%, val_best:  71.67%, tr:  88.36%, tr_best:  88.36%\n",
      "epoch-60  lr=['0.0010000'], tr/val_loss:  0.668500/  1.502289, val:  72.08%, val_best:  72.08%, tr:  87.64%, tr_best:  88.36%\n",
      "epoch-61  lr=['0.0010000'], tr/val_loss:  0.667460/  1.534970, val:  67.50%, val_best:  72.08%, tr:  88.66%, tr_best:  88.66%\n",
      "epoch-62  lr=['0.0010000'], tr/val_loss:  0.659257/  1.510700, val:  71.67%, val_best:  72.08%, tr:  88.97%, tr_best:  88.97%\n",
      "epoch-63  lr=['0.0010000'], tr/val_loss:  0.646577/  1.515270, val:  69.58%, val_best:  72.08%, tr:  89.58%, tr_best:  89.58%\n",
      "epoch-64  lr=['0.0010000'], tr/val_loss:  0.638113/  1.553645, val:  70.42%, val_best:  72.08%, tr:  88.76%, tr_best:  89.58%\n",
      "epoch-65  lr=['0.0010000'], tr/val_loss:  0.629276/  1.544271, val:  70.00%, val_best:  72.08%, tr:  87.84%, tr_best:  89.58%\n",
      "epoch-66  lr=['0.0010000'], tr/val_loss:  0.627064/  1.534808, val:  67.08%, val_best:  72.08%, tr:  89.48%, tr_best:  89.58%\n",
      "epoch-67  lr=['0.0010000'], tr/val_loss:  0.622122/  1.546976, val:  72.92%, val_best:  72.92%, tr:  89.38%, tr_best:  89.58%\n",
      "epoch-68  lr=['0.0010000'], tr/val_loss:  0.606682/  1.564600, val:  70.00%, val_best:  72.92%, tr:  88.25%, tr_best:  89.58%\n",
      "epoch-69  lr=['0.0010000'], tr/val_loss:  0.604825/  1.555486, val:  70.00%, val_best:  72.92%, tr:  91.32%, tr_best:  91.32%\n",
      "epoch-70  lr=['0.0010000'], tr/val_loss:  0.585484/  1.559497, val:  71.25%, val_best:  72.92%, tr:  91.93%, tr_best:  91.93%\n",
      "epoch-71  lr=['0.0010000'], tr/val_loss:  0.579618/  1.595830, val:  65.83%, val_best:  72.92%, tr:  91.73%, tr_best:  91.93%\n",
      "epoch-72  lr=['0.0010000'], tr/val_loss:  0.572585/  1.607608, val:  69.58%, val_best:  72.92%, tr:  92.85%, tr_best:  92.85%\n",
      "epoch-73  lr=['0.0010000'], tr/val_loss:  0.574248/  1.623535, val:  72.50%, val_best:  72.92%, tr:  92.85%, tr_best:  92.85%\n",
      "epoch-74  lr=['0.0010000'], tr/val_loss:  0.549895/  1.616399, val:  72.92%, val_best:  72.92%, tr:  94.08%, tr_best:  94.08%\n",
      "epoch-75  lr=['0.0010000'], tr/val_loss:  0.551134/  1.631726, val:  69.58%, val_best:  72.92%, tr:  92.44%, tr_best:  94.08%\n",
      "epoch-76  lr=['0.0010000'], tr/val_loss:  0.534142/  1.672592, val:  68.75%, val_best:  72.92%, tr:  93.67%, tr_best:  94.08%\n",
      "epoch-77  lr=['0.0010000'], tr/val_loss:  0.549368/  1.626144, val:  71.25%, val_best:  72.92%, tr:  93.05%, tr_best:  94.08%\n",
      "epoch-78  lr=['0.0010000'], tr/val_loss:  0.533122/  1.635517, val:  70.42%, val_best:  72.92%, tr:  93.05%, tr_best:  94.08%\n",
      "epoch-79  lr=['0.0010000'], tr/val_loss:  0.517198/  1.679027, val:  70.83%, val_best:  72.92%, tr:  93.56%, tr_best:  94.08%\n",
      "epoch-80  lr=['0.0010000'], tr/val_loss:  0.502733/  1.687005, val:  73.33%, val_best:  73.33%, tr:  95.30%, tr_best:  95.30%\n",
      "epoch-81  lr=['0.0010000'], tr/val_loss:  0.511376/  1.699188, val:  72.50%, val_best:  73.33%, tr:  95.30%, tr_best:  95.30%\n",
      "epoch-82  lr=['0.0010000'], tr/val_loss:  0.499272/  1.716568, val:  69.17%, val_best:  73.33%, tr:  93.26%, tr_best:  95.30%\n",
      "epoch-83  lr=['0.0010000'], tr/val_loss:  0.491946/  1.736850, val:  70.00%, val_best:  73.33%, tr:  96.73%, tr_best:  96.73%\n",
      "epoch-84  lr=['0.0010000'], tr/val_loss:  0.490241/  1.731763, val:  75.00%, val_best:  75.00%, tr:  97.14%, tr_best:  97.14%\n",
      "epoch-85  lr=['0.0010000'], tr/val_loss:  0.485247/  1.770084, val:  65.00%, val_best:  75.00%, tr:  96.63%, tr_best:  97.14%\n",
      "epoch-86  lr=['0.0010000'], tr/val_loss:  0.470209/  1.752658, val:  73.33%, val_best:  75.00%, tr:  94.99%, tr_best:  97.14%\n",
      "epoch-87  lr=['0.0010000'], tr/val_loss:  0.461560/  1.794353, val:  70.42%, val_best:  75.00%, tr:  96.73%, tr_best:  97.14%\n",
      "epoch-88  lr=['0.0010000'], tr/val_loss:  0.448360/  1.777093, val:  76.67%, val_best:  76.67%, tr:  97.55%, tr_best:  97.55%\n",
      "epoch-89  lr=['0.0010000'], tr/val_loss:  0.432181/  1.827382, val:  75.83%, val_best:  76.67%, tr:  98.47%, tr_best:  98.47%\n",
      "epoch-90  lr=['0.0010000'], tr/val_loss:  0.442236/  1.810546, val:  72.50%, val_best:  76.67%, tr:  97.85%, tr_best:  98.47%\n",
      "epoch-91  lr=['0.0010000'], tr/val_loss:  0.429202/  1.849055, val:  68.33%, val_best:  76.67%, tr:  97.85%, tr_best:  98.47%\n",
      "epoch-92  lr=['0.0010000'], tr/val_loss:  0.418660/  1.881980, val:  74.17%, val_best:  76.67%, tr:  98.37%, tr_best:  98.47%\n",
      "epoch-93  lr=['0.0010000'], tr/val_loss:  0.421331/  1.854201, val:  71.25%, val_best:  76.67%, tr:  98.26%, tr_best:  98.47%\n",
      "epoch-94  lr=['0.0010000'], tr/val_loss:  0.408520/  1.897270, val:  70.42%, val_best:  76.67%, tr:  98.67%, tr_best:  98.67%\n",
      "epoch-95  lr=['0.0010000'], tr/val_loss:  0.402838/  1.933123, val:  71.67%, val_best:  76.67%, tr:  97.65%, tr_best:  98.67%\n",
      "epoch-96  lr=['0.0010000'], tr/val_loss:  0.401852/  1.954252, val:  68.75%, val_best:  76.67%, tr:  98.26%, tr_best:  98.67%\n",
      "epoch-97  lr=['0.0010000'], tr/val_loss:  0.394672/  1.913104, val:  74.17%, val_best:  76.67%, tr:  97.85%, tr_best:  98.67%\n",
      "epoch-98  lr=['0.0010000'], tr/val_loss:  0.380638/  1.941750, val:  73.75%, val_best:  76.67%, tr:  98.88%, tr_best:  98.88%\n",
      "epoch-99  lr=['0.0010000'], tr/val_loss:  0.379828/  1.945345, val:  71.25%, val_best:  76.67%, tr:  98.77%, tr_best:  98.88%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "093b30cc3ad943559b4f5ab6e334f726",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.006 MB of 0.006 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>iter_acc</td><td>▁▂▁▃▄▅▆▄▄▆▆▆▅▆▆▆█▇▇▆▇▇▆███▆██▇█▇▅███▇▇██</td></tr><tr><td>summary_val_acc</td><td>▁▁▂▄▅▆▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇██▇▇█▇▇█▇████</td></tr><tr><td>tr_acc</td><td>▁▁▁▃▅▅▅▅▅▅▆▆▆▆▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇███████████</td></tr><tr><td>tr_epoch_loss</td><td>███▇▆▅▄▄▄▄▄▃▃▃▃▃▃▃▃▂▂▂▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁</td></tr><tr><td>val_acc_best</td><td>▁▁▂▄▅▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇███████████████</td></tr><tr><td>val_acc_now</td><td>▁▁▂▄▅▆▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇██▇▇█▇▇█▇████</td></tr><tr><td>val_loss</td><td>███▅▃▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▂▂▂▂▂▂▂▃▃▃▃▃▄▄▄▅▅▅▅</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>99</td></tr><tr><td>iter_acc</td><td>1.0</td></tr><tr><td>tr_acc</td><td>0.98774</td></tr><tr><td>tr_epoch_loss</td><td>0.37983</td></tr><tr><td>val_acc_best</td><td>0.76667</td></tr><tr><td>val_acc_now</td><td>0.7125</td></tr><tr><td>val_loss</td><td>1.94535</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">happy-sweep-229</strong> at: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/2l075vuy' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/2l075vuy</a><br/> View project at: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>/data2/bh_wandb/wandb/run-20250430_072052-2l075vuy/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require(\"core\")`! See https://wandb.me/wandb-core for more information."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: vmdbbjrn with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBATCH: 16\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBN_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBPTT_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tDFA_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tIMAGE_SIZE: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tOTTT_input_trace_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tTIME: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tUDA_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \talpha_uda: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbias: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcfg: ['M', 'M', 200, 200]\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tchaching_on: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tconvTrue_fcFalse: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdata_path: /data2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tddp_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdenoise_on: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdvs_clipping: 5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdvs_duration: 100000\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepoch_num: 100\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \texclude_class: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \textra_train_dataset: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlast_lif: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.001\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_sg_width: 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_decay: 0.5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_init: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_reset: 10000\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_threshold: 0.25\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmerge_polarities: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmy_seed: 42\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnet_print: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_workers: 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer_what: SGD\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tpin_memory: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tpre_trained: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tpre_trained_path: net_save/save_now_net_weights_{unique_name}.pth\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \trate_coding: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tscheduler_name: no\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsingle_step: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsurrogate: hard_sigmoid\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_conv_kernel_size: 3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_conv_padding: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_conv_stride: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_trace_const1: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_trace_const2: 0.5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \ttdBN_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \ttrace_on: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \twhich_data: DVS_GESTURE_TONIC\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.19.10 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.17.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/data2/bh_wandb/wandb/run-20250430_072649-vmdbbjrn</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/vmdbbjrn' target=\"_blank\">unique-sweep-230</a></strong> to <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/6pj3lh8j' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/6pj3lh8j</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/6pj3lh8j' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/6pj3lh8j</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/vmdbbjrn' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/vmdbbjrn</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'single_step' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'my_seed' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'TIME' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BATCH' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'IMAGE_SIZE' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'which_data' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'data_path' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'rate_coding' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_init' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_decay' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_threshold' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_reset' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_sg_width' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_conv_kernel_size' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_conv_stride' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_conv_padding' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_trace_const1' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_trace_const2' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'pre_trained' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'convTrue_fcFalse' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'cfg' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'net_print' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'pre_trained_path' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'learning_rate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'epoch_num' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'tdBN_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BN_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'surrogate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BPTT_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'optimizer_what' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'scheduler_name' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'ddp_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'dvs_clipping' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'dvs_duration' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'DFA_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'trace_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'OTTT_input_trace_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'exclude_class' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'merge_polarities' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'denoise_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'extra_train_dataset' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'num_workers' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'chaching_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'pin_memory' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'UDA_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'alpha_uda' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'bias' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'last_lif' was locked by 'sweep' (ignored update).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "param {'devices': '0', 'single_step': True, 'unique_name': 'main', 'my_seed': 42, 'TIME': 10, 'BATCH': 16, 'IMAGE_SIZE': 128, 'which_data': 'DVS_GESTURE_TONIC', 'data_path': '/data2', 'rate_coding': False, 'lif_layer_v_init': 0, 'lif_layer_v_decay': 0.5, 'lif_layer_v_threshold': 0.25, 'lif_layer_v_reset': 10000, 'lif_layer_sg_width': 2, 'synapse_conv_kernel_size': 3, 'synapse_conv_stride': 1, 'synapse_conv_padding': 1, 'synapse_trace_const1': 1, 'synapse_trace_const2': 0.5, 'pre_trained': False, 'convTrue_fcFalse': False, 'cfg': ['M', 'M', 200, 200], 'net_print': True, 'pre_trained_path': 'net_save/save_now_net_weights_{unique_name}.pth', 'learning_rate': 0.001, 'epoch_num': 100, 'tdBN_on': False, 'BN_on': False, 'surrogate': 'hard_sigmoid', 'BPTT_on': False, 'optimizer_what': 'SGD', 'scheduler_name': 'no', 'ddp_on': False, 'dvs_clipping': 5, 'dvs_duration': 100000, 'DFA_on': False, 'trace_on': True, 'OTTT_input_trace_on': False, 'exclude_class': True, 'merge_polarities': False, 'denoise_on': True, 'extra_train_dataset': 0, 'num_workers': 2, 'chaching_on': True, 'pin_memory': True, 'UDA_on': False, 'alpha_uda': 1, 'bias': True, 'last_lif': False, 'current epoch': 0} \n",
      "\n",
      "dataset_hash = 63cc597115630ec173f3099200061e53\n",
      "cache path exists\n",
      "\n",
      "device ==> cuda\n",
      "\n",
      "DataParallel(\n",
      "  (module): REBORN_MY_SNN_FC(\n",
      "    (layers): REBORN_MY_Sequential(\n",
      "      (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (2): DimChanger_for_FC()\n",
      "      (3): SYNAPSE_FC(in_features=2048, out_features=200, TIME=10, bias=True, sstep=True)\n",
      "      (4): LIF_layer(v_init=0, v_decay=0.5, v_threshold=0.25, v_reset=10000, sg_width=2, surrogate=hard_sigmoid, BPTT_on=False, trace_const1=1, trace_const2=0.5, TIME=10, sstep=True, trace_on=True)\n",
      "      (5): SYNAPSE_FC(in_features=200, out_features=200, TIME=10, bias=True, sstep=True)\n",
      "      (6): LIF_layer(v_init=0, v_decay=0.5, v_threshold=0.25, v_reset=10000, sg_width=2, surrogate=hard_sigmoid, BPTT_on=False, trace_const1=1, trace_const2=0.5, TIME=10, sstep=True, trace_on=True)\n",
      "      (7): SYNAPSE_FC(in_features=200, out_features=10, TIME=10, bias=True, sstep=True)\n",
      "    )\n",
      "  )\n",
      ")\n",
      "\n",
      "========================================================\n",
      "Trainable parameters: 452,010\n",
      "========================================================\n",
      "\n",
      "epoch-0   lr=['0.0010000'], tr/val_loss:  2.259325/  2.166692, val:  25.42%, val_best:  25.42%, tr:  15.63%, tr_best:  15.63%\n",
      "epoch-1   lr=['0.0010000'], tr/val_loss:  1.951459/  1.832348, val:  47.92%, val_best:  47.92%, tr:  37.90%, tr_best:  37.90%\n",
      "epoch-2   lr=['0.0010000'], tr/val_loss:  1.623138/  1.666077, val:  55.42%, val_best:  55.42%, tr:  54.03%, tr_best:  54.03%\n",
      "epoch-3   lr=['0.0010000'], tr/val_loss:  1.460078/  1.635147, val:  57.08%, val_best:  57.08%, tr:  61.39%, tr_best:  61.39%\n",
      "epoch-4   lr=['0.0010000'], tr/val_loss:  1.385512/  1.555451, val:  60.42%, val_best:  60.42%, tr:  62.00%, tr_best:  62.00%\n",
      "epoch-5   lr=['0.0010000'], tr/val_loss:  1.316895/  1.531080, val:  59.58%, val_best:  60.42%, tr:  62.92%, tr_best:  62.92%\n",
      "epoch-6   lr=['0.0010000'], tr/val_loss:  1.249793/  1.511024, val:  59.58%, val_best:  60.42%, tr:  65.88%, tr_best:  65.88%\n",
      "epoch-7   lr=['0.0010000'], tr/val_loss:  1.203278/  1.482369, val:  61.67%, val_best:  61.67%, tr:  66.39%, tr_best:  66.39%\n",
      "epoch-8   lr=['0.0010000'], tr/val_loss:  1.161125/  1.456793, val:  65.83%, val_best:  65.83%, tr:  69.56%, tr_best:  69.56%\n",
      "epoch-9   lr=['0.0010000'], tr/val_loss:  1.130679/  1.528863, val:  60.00%, val_best:  65.83%, tr:  70.99%, tr_best:  70.99%\n",
      "epoch-10  lr=['0.0010000'], tr/val_loss:  1.108387/  1.563280, val:  55.00%, val_best:  65.83%, tr:  68.95%, tr_best:  70.99%\n",
      "epoch-11  lr=['0.0010000'], tr/val_loss:  1.054601/  1.435886, val:  68.33%, val_best:  68.33%, tr:  71.09%, tr_best:  71.09%\n",
      "epoch-12  lr=['0.0010000'], tr/val_loss:  1.048901/  1.472334, val:  59.17%, val_best:  68.33%, tr:  74.36%, tr_best:  74.36%\n",
      "epoch-13  lr=['0.0010000'], tr/val_loss:  1.017672/  1.569106, val:  62.50%, val_best:  68.33%, tr:  73.65%, tr_best:  74.36%\n",
      "epoch-14  lr=['0.0010000'], tr/val_loss:  0.974325/  1.656879, val:  59.58%, val_best:  68.33%, tr:  74.36%, tr_best:  74.36%\n",
      "epoch-15  lr=['0.0010000'], tr/val_loss:  0.980752/  1.572125, val:  60.83%, val_best:  68.33%, tr:  76.61%, tr_best:  76.61%\n",
      "epoch-16  lr=['0.0010000'], tr/val_loss:  0.983020/  1.537963, val:  64.58%, val_best:  68.33%, tr:  74.87%, tr_best:  76.61%\n",
      "epoch-17  lr=['0.0010000'], tr/val_loss:  0.914581/  1.668934, val:  62.08%, val_best:  68.33%, tr:  78.14%, tr_best:  78.14%\n",
      "epoch-18  lr=['0.0010000'], tr/val_loss:  0.931618/  1.708934, val:  62.50%, val_best:  68.33%, tr:  77.63%, tr_best:  78.14%\n",
      "epoch-19  lr=['0.0010000'], tr/val_loss:  0.924997/  1.702797, val:  65.42%, val_best:  68.33%, tr:  77.83%, tr_best:  78.14%\n",
      "epoch-20  lr=['0.0010000'], tr/val_loss:  0.895528/  1.803627, val:  62.08%, val_best:  68.33%, tr:  79.98%, tr_best:  79.98%\n",
      "epoch-21  lr=['0.0010000'], tr/val_loss:  0.870973/  1.802069, val:  61.25%, val_best:  68.33%, tr:  82.33%, tr_best:  82.33%\n",
      "epoch-22  lr=['0.0010000'], tr/val_loss:  0.875475/  1.817097, val:  62.50%, val_best:  68.33%, tr:  80.08%, tr_best:  82.33%\n",
      "epoch-23  lr=['0.0010000'], tr/val_loss:  0.852028/  1.992823, val:  60.00%, val_best:  68.33%, tr:  82.02%, tr_best:  82.33%\n",
      "epoch-24  lr=['0.0010000'], tr/val_loss:  0.817858/  1.996159, val:  59.58%, val_best:  68.33%, tr:  84.07%, tr_best:  84.07%\n",
      "epoch-25  lr=['0.0010000'], tr/val_loss:  0.836069/  1.881631, val:  67.50%, val_best:  68.33%, tr:  83.76%, tr_best:  84.07%\n",
      "epoch-26  lr=['0.0010000'], tr/val_loss:  0.846120/  1.998041, val:  70.00%, val_best:  70.00%, tr:  84.07%, tr_best:  84.07%\n",
      "epoch-27  lr=['0.0010000'], tr/val_loss:  0.806404/  2.054228, val:  62.92%, val_best:  70.00%, tr:  84.27%, tr_best:  84.27%\n",
      "epoch-28  lr=['0.0010000'], tr/val_loss:  0.791962/  2.007748, val:  68.75%, val_best:  70.00%, tr:  84.47%, tr_best:  84.47%\n",
      "epoch-29  lr=['0.0010000'], tr/val_loss:  0.819494/  2.359427, val:  60.42%, val_best:  70.00%, tr:  87.03%, tr_best:  87.03%\n",
      "epoch-30  lr=['0.0010000'], tr/val_loss:  0.782672/  2.213522, val:  62.08%, val_best:  70.00%, tr:  87.74%, tr_best:  87.74%\n",
      "epoch-31  lr=['0.0010000'], tr/val_loss:  0.785682/  2.318455, val:  67.08%, val_best:  70.00%, tr:  86.62%, tr_best:  87.74%\n",
      "epoch-32  lr=['0.0010000'], tr/val_loss:  0.812352/  2.263149, val:  68.75%, val_best:  70.00%, tr:  86.72%, tr_best:  87.74%\n",
      "epoch-33  lr=['0.0010000'], tr/val_loss:  0.814710/  2.259653, val:  67.92%, val_best:  70.00%, tr:  87.54%, tr_best:  87.74%\n",
      "epoch-34  lr=['0.0010000'], tr/val_loss:  0.742937/  2.467701, val:  60.42%, val_best:  70.00%, tr:  88.46%, tr_best:  88.46%\n",
      "epoch-35  lr=['0.0010000'], tr/val_loss:  0.757479/  2.534710, val:  59.58%, val_best:  70.00%, tr:  86.21%, tr_best:  88.46%\n",
      "epoch-36  lr=['0.0010000'], tr/val_loss:  0.681546/  2.297895, val:  67.50%, val_best:  70.00%, tr:  89.27%, tr_best:  89.27%\n",
      "epoch-37  lr=['0.0010000'], tr/val_loss:  0.701446/  2.512144, val:  63.75%, val_best:  70.00%, tr:  91.73%, tr_best:  91.73%\n",
      "epoch-38  lr=['0.0010000'], tr/val_loss:  0.710612/  2.657074, val:  65.00%, val_best:  70.00%, tr:  92.95%, tr_best:  92.95%\n",
      "epoch-39  lr=['0.0010000'], tr/val_loss:  0.657503/  2.521472, val:  63.75%, val_best:  70.00%, tr:  93.26%, tr_best:  93.26%\n",
      "epoch-40  lr=['0.0010000'], tr/val_loss:  0.682582/  2.741191, val:  62.92%, val_best:  70.00%, tr:  91.32%, tr_best:  93.26%\n",
      "epoch-41  lr=['0.0010000'], tr/val_loss:  0.655606/  2.770979, val:  59.17%, val_best:  70.00%, tr:  93.05%, tr_best:  93.26%\n",
      "epoch-42  lr=['0.0010000'], tr/val_loss:  0.632359/  2.721785, val:  67.08%, val_best:  70.00%, tr:  94.79%, tr_best:  94.79%\n",
      "epoch-43  lr=['0.0010000'], tr/val_loss:  0.633759/  2.736447, val:  65.00%, val_best:  70.00%, tr:  94.18%, tr_best:  94.79%\n",
      "epoch-44  lr=['0.0010000'], tr/val_loss:  0.632607/  2.656749, val:  67.92%, val_best:  70.00%, tr:  94.99%, tr_best:  94.99%\n",
      "epoch-45  lr=['0.0010000'], tr/val_loss:  0.615663/  2.725739, val:  68.75%, val_best:  70.00%, tr:  94.79%, tr_best:  94.99%\n",
      "epoch-46  lr=['0.0010000'], tr/val_loss:  0.594888/  2.853819, val:  66.25%, val_best:  70.00%, tr:  95.71%, tr_best:  95.71%\n",
      "epoch-47  lr=['0.0010000'], tr/val_loss:  0.578222/  3.049881, val:  65.42%, val_best:  70.00%, tr:  97.04%, tr_best:  97.04%\n",
      "epoch-48  lr=['0.0010000'], tr/val_loss:  0.607904/  2.996387, val:  67.92%, val_best:  70.00%, tr:  95.91%, tr_best:  97.04%\n",
      "epoch-49  lr=['0.0010000'], tr/val_loss:  0.567040/  3.018704, val:  69.58%, val_best:  70.00%, tr:  96.83%, tr_best:  97.04%\n",
      "epoch-50  lr=['0.0010000'], tr/val_loss:  0.532360/  3.186153, val:  66.25%, val_best:  70.00%, tr:  97.55%, tr_best:  97.55%\n",
      "epoch-51  lr=['0.0010000'], tr/val_loss:  0.575075/  3.053903, val:  67.08%, val_best:  70.00%, tr:  94.18%, tr_best:  97.55%\n",
      "epoch-52  lr=['0.0010000'], tr/val_loss:  0.514349/  3.110004, val:  67.08%, val_best:  70.00%, tr:  96.83%, tr_best:  97.55%\n",
      "epoch-53  lr=['0.0010000'], tr/val_loss:  0.518154/  3.457839, val:  65.83%, val_best:  70.00%, tr:  98.37%, tr_best:  98.37%\n",
      "epoch-54  lr=['0.0010000'], tr/val_loss:  0.505677/  3.216293, val:  69.58%, val_best:  70.00%, tr:  98.26%, tr_best:  98.37%\n",
      "epoch-55  lr=['0.0010000'], tr/val_loss:  0.527777/  3.308029, val:  67.92%, val_best:  70.00%, tr:  97.14%, tr_best:  98.37%\n",
      "epoch-56  lr=['0.0010000'], tr/val_loss:  0.491510/  3.531652, val:  64.17%, val_best:  70.00%, tr:  98.77%, tr_best:  98.77%\n",
      "epoch-57  lr=['0.0010000'], tr/val_loss:  0.559684/  3.381672, val:  65.00%, val_best:  70.00%, tr:  96.63%, tr_best:  98.77%\n",
      "epoch-58  lr=['0.0010000'], tr/val_loss:  0.539413/  3.329102, val:  67.08%, val_best:  70.00%, tr:  94.48%, tr_best:  98.77%\n",
      "epoch-59  lr=['0.0010000'], tr/val_loss:  0.516434/  3.457018, val:  70.83%, val_best:  70.83%, tr:  97.75%, tr_best:  98.77%\n",
      "epoch-60  lr=['0.0010000'], tr/val_loss:  0.485153/  3.732556, val:  64.17%, val_best:  70.83%, tr:  97.85%, tr_best:  98.77%\n",
      "epoch-61  lr=['0.0010000'], tr/val_loss:  0.535130/  3.417022, val:  71.25%, val_best:  71.25%, tr:  96.83%, tr_best:  98.77%\n",
      "epoch-62  lr=['0.0010000'], tr/val_loss:  0.446230/  3.361158, val:  69.17%, val_best:  71.25%, tr:  98.47%, tr_best:  98.77%\n",
      "epoch-63  lr=['0.0010000'], tr/val_loss:  0.424834/  3.410936, val:  73.75%, val_best:  73.75%, tr:  98.88%, tr_best:  98.88%\n",
      "epoch-64  lr=['0.0010000'], tr/val_loss:  0.435740/  3.347567, val:  71.67%, val_best:  73.75%, tr:  97.65%, tr_best:  98.88%\n",
      "epoch-65  lr=['0.0010000'], tr/val_loss:  0.381304/  3.313588, val:  71.25%, val_best:  73.75%, tr:  99.18%, tr_best:  99.18%\n",
      "epoch-66  lr=['0.0010000'], tr/val_loss:  0.393611/  3.409695, val:  72.08%, val_best:  73.75%, tr:  99.49%, tr_best:  99.49%\n",
      "epoch-67  lr=['0.0010000'], tr/val_loss:  0.414356/  3.359644, val:  73.75%, val_best:  73.75%, tr:  98.57%, tr_best:  99.49%\n",
      "epoch-68  lr=['0.0010000'], tr/val_loss:  0.412061/  3.412950, val:  71.67%, val_best:  73.75%, tr:  99.39%, tr_best:  99.49%\n",
      "epoch-69  lr=['0.0010000'], tr/val_loss:  0.420847/  3.498824, val:  72.08%, val_best:  73.75%, tr:  98.77%, tr_best:  99.49%\n",
      "epoch-70  lr=['0.0010000'], tr/val_loss:  0.378566/  3.353256, val:  71.25%, val_best:  73.75%, tr:  99.39%, tr_best:  99.49%\n",
      "epoch-71  lr=['0.0010000'], tr/val_loss:  0.437227/  3.585583, val:  72.50%, val_best:  73.75%, tr:  98.06%, tr_best:  99.49%\n",
      "epoch-72  lr=['0.0010000'], tr/val_loss:  0.419239/  3.353722, val:  72.50%, val_best:  73.75%, tr:  98.88%, tr_best:  99.49%\n",
      "epoch-73  lr=['0.0010000'], tr/val_loss:  0.389243/  3.548229, val:  67.92%, val_best:  73.75%, tr:  98.37%, tr_best:  99.49%\n",
      "epoch-74  lr=['0.0010000'], tr/val_loss:  0.355405/  3.541240, val:  72.92%, val_best:  73.75%, tr:  99.08%, tr_best:  99.49%\n",
      "epoch-75  lr=['0.0010000'], tr/val_loss:  0.352597/  3.526462, val:  70.42%, val_best:  73.75%, tr:  98.47%, tr_best:  99.49%\n",
      "epoch-76  lr=['0.0010000'], tr/val_loss:  0.337224/  3.475421, val:  71.67%, val_best:  73.75%, tr:  99.39%, tr_best:  99.49%\n",
      "epoch-77  lr=['0.0010000'], tr/val_loss:  0.360251/  3.710256, val:  69.58%, val_best:  73.75%, tr:  98.77%, tr_best:  99.49%\n",
      "epoch-78  lr=['0.0010000'], tr/val_loss:  0.380566/  3.617064, val:  72.50%, val_best:  73.75%, tr:  98.88%, tr_best:  99.49%\n",
      "epoch-79  lr=['0.0010000'], tr/val_loss:  0.325451/  3.572766, val:  72.08%, val_best:  73.75%, tr:  99.49%, tr_best:  99.49%\n",
      "epoch-80  lr=['0.0010000'], tr/val_loss:  0.308370/  3.665858, val:  71.67%, val_best:  73.75%, tr:  99.90%, tr_best:  99.90%\n",
      "epoch-81  lr=['0.0010000'], tr/val_loss:  0.266245/  3.580417, val:  70.42%, val_best:  73.75%, tr:  99.80%, tr_best:  99.90%\n",
      "epoch-82  lr=['0.0010000'], tr/val_loss:  0.278189/  3.626280, val:  71.25%, val_best:  73.75%, tr:  99.49%, tr_best:  99.90%\n",
      "epoch-83  lr=['0.0010000'], tr/val_loss:  0.352835/  3.735754, val:  70.83%, val_best:  73.75%, tr:  99.59%, tr_best:  99.90%\n",
      "epoch-84  lr=['0.0010000'], tr/val_loss:  0.314501/  3.713542, val:  70.42%, val_best:  73.75%, tr:  99.28%, tr_best:  99.90%\n",
      "epoch-85  lr=['0.0010000'], tr/val_loss:  0.353990/  3.794341, val:  70.42%, val_best:  73.75%, tr:  98.98%, tr_best:  99.90%\n",
      "epoch-86  lr=['0.0010000'], tr/val_loss:  0.290747/  3.757254, val:  70.42%, val_best:  73.75%, tr:  99.80%, tr_best:  99.90%\n",
      "epoch-87  lr=['0.0010000'], tr/val_loss:  0.318437/  3.547390, val:  72.50%, val_best:  73.75%, tr:  98.67%, tr_best:  99.90%\n",
      "epoch-88  lr=['0.0010000'], tr/val_loss:  0.290242/  3.610040, val:  73.75%, val_best:  73.75%, tr:  99.80%, tr_best:  99.90%\n",
      "epoch-89  lr=['0.0010000'], tr/val_loss:  0.257004/  3.746444, val:  73.75%, val_best:  73.75%, tr:  99.69%, tr_best:  99.90%\n",
      "epoch-90  lr=['0.0010000'], tr/val_loss:  0.253982/  3.726433, val:  70.83%, val_best:  73.75%, tr:  99.80%, tr_best:  99.90%\n",
      "epoch-91  lr=['0.0010000'], tr/val_loss:  0.232963/  3.734505, val:  72.08%, val_best:  73.75%, tr:  99.69%, tr_best:  99.90%\n",
      "epoch-92  lr=['0.0010000'], tr/val_loss:  0.194844/  3.748441, val:  72.50%, val_best:  73.75%, tr:  99.90%, tr_best:  99.90%\n",
      "epoch-93  lr=['0.0010000'], tr/val_loss:  0.219133/  3.755011, val:  72.92%, val_best:  73.75%, tr:  99.90%, tr_best:  99.90%\n",
      "epoch-94  lr=['0.0010000'], tr/val_loss:  0.205211/  3.758615, val:  72.50%, val_best:  73.75%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-95  lr=['0.0010000'], tr/val_loss:  0.236082/  3.739775, val:  73.33%, val_best:  73.75%, tr:  99.90%, tr_best: 100.00%\n",
      "epoch-96  lr=['0.0010000'], tr/val_loss:  0.224297/  3.839006, val:  73.75%, val_best:  73.75%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-97  lr=['0.0010000'], tr/val_loss:  0.232116/  3.776063, val:  75.00%, val_best:  75.00%, tr:  99.90%, tr_best: 100.00%\n",
      "epoch-98  lr=['0.0010000'], tr/val_loss:  0.197325/  3.764912, val:  75.42%, val_best:  75.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-99  lr=['0.0010000'], tr/val_loss:  0.181913/  3.835845, val:  74.17%, val_best:  75.42%, tr: 100.00%, tr_best: 100.00%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bc1ed562e45541f589ff28d8c71b2a20",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.006 MB of 0.006 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>iter_acc</td><td>▂▅▂▅▄▅▇▁▄▇█▆█▇▇▇█▆█▇███████▇████████████</td></tr><tr><td>summary_val_acc</td><td>▁▅▆▆▆▆▆▆▇▆▆▇▆▇▆▆▆▇▇▇▇▇▇▇▇▇▇█▇█▇▇█▇▇█████</td></tr><tr><td>tr_acc</td><td>▁▄▅▅▆▆▆▆▆▇▇▇▇▇▇▇▇███████████████████████</td></tr><tr><td>tr_epoch_loss</td><td>█▆▅▄▄▄▄▃▃▃▃▃▃▃▃▃▃▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁</td></tr><tr><td>val_acc_best</td><td>▁▅▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇██████████████</td></tr><tr><td>val_acc_now</td><td>▁▅▆▆▆▆▆▆▇▆▆▇▆▇▆▆▆▇▇▇▇▇▇▇▇▇▇█▇█▇▇█▇▇█████</td></tr><tr><td>val_loss</td><td>▃▂▁▁▁▁▂▂▂▂▃▃▄▃▄▄▄▅▅▆▆▆▆▇▇▇▇▇▇▇▇█▇██▇████</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>99</td></tr><tr><td>iter_acc</td><td>1.0</td></tr><tr><td>tr_acc</td><td>1.0</td></tr><tr><td>tr_epoch_loss</td><td>0.18191</td></tr><tr><td>val_acc_best</td><td>0.75417</td></tr><tr><td>val_acc_now</td><td>0.74167</td></tr><tr><td>val_loss</td><td>3.83585</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">unique-sweep-230</strong> at: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/vmdbbjrn' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/vmdbbjrn</a><br/> View project at: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>/data2/bh_wandb/wandb/run-20250430_072649-vmdbbjrn/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require(\"core\")`! See https://wandb.me/wandb-core for more information."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 8qu8lho5 with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBATCH: 16\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBN_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBPTT_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tDFA_on: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tIMAGE_SIZE: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tOTTT_input_trace_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tTIME: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tUDA_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \talpha_uda: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbias: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcfg: ['M', 'M', 200, 200]\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tchaching_on: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tconvTrue_fcFalse: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdata_path: /data2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tddp_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdenoise_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdvs_clipping: 5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdvs_duration: 100000\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepoch_num: 100\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \texclude_class: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \textra_train_dataset: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlast_lif: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.001\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_sg_width: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_decay: 0.5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_init: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_reset: 10000\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_threshold: 0.75\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmerge_polarities: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmy_seed: 42\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnet_print: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_workers: 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer_what: SGD\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tpin_memory: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tpre_trained: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tpre_trained_path: net_save/save_now_net_weights_{unique_name}.pth\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \trate_coding: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tscheduler_name: no\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsingle_step: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsurrogate: hard_sigmoid\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_conv_kernel_size: 3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_conv_padding: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_conv_stride: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_trace_const1: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_trace_const2: 0.5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \ttdBN_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \ttrace_on: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \twhich_data: DVS_GESTURE_TONIC\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.19.10 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.17.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/data2/bh_wandb/wandb/run-20250430_073246-8qu8lho5</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/8qu8lho5' target=\"_blank\">honest-sweep-232</a></strong> to <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/6pj3lh8j' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/6pj3lh8j</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/6pj3lh8j' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/6pj3lh8j</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/8qu8lho5' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/8qu8lho5</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'single_step' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'my_seed' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'TIME' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BATCH' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'IMAGE_SIZE' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'which_data' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'data_path' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'rate_coding' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_init' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_decay' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_threshold' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_reset' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_sg_width' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_conv_kernel_size' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_conv_stride' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_conv_padding' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_trace_const1' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_trace_const2' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'pre_trained' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'convTrue_fcFalse' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'cfg' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'net_print' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'pre_trained_path' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'learning_rate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'epoch_num' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'tdBN_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BN_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'surrogate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BPTT_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'optimizer_what' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'scheduler_name' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'ddp_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'dvs_clipping' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'dvs_duration' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'DFA_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'trace_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'OTTT_input_trace_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'exclude_class' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'merge_polarities' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'denoise_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'extra_train_dataset' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'num_workers' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'chaching_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'pin_memory' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'UDA_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'alpha_uda' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'bias' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'last_lif' was locked by 'sweep' (ignored update).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "param {'devices': '0', 'single_step': True, 'unique_name': 'main', 'my_seed': 42, 'TIME': 10, 'BATCH': 16, 'IMAGE_SIZE': 128, 'which_data': 'DVS_GESTURE_TONIC', 'data_path': '/data2', 'rate_coding': False, 'lif_layer_v_init': 0, 'lif_layer_v_decay': 0.5, 'lif_layer_v_threshold': 0.75, 'lif_layer_v_reset': 10000, 'lif_layer_sg_width': 1, 'synapse_conv_kernel_size': 3, 'synapse_conv_stride': 1, 'synapse_conv_padding': 1, 'synapse_trace_const1': 1, 'synapse_trace_const2': 0.5, 'pre_trained': False, 'convTrue_fcFalse': False, 'cfg': ['M', 'M', 200, 200], 'net_print': True, 'pre_trained_path': 'net_save/save_now_net_weights_{unique_name}.pth', 'learning_rate': 0.001, 'epoch_num': 100, 'tdBN_on': False, 'BN_on': False, 'surrogate': 'hard_sigmoid', 'BPTT_on': False, 'optimizer_what': 'SGD', 'scheduler_name': 'no', 'ddp_on': False, 'dvs_clipping': 5, 'dvs_duration': 100000, 'DFA_on': True, 'trace_on': True, 'OTTT_input_trace_on': False, 'exclude_class': True, 'merge_polarities': False, 'denoise_on': False, 'extra_train_dataset': 0, 'num_workers': 2, 'chaching_on': True, 'pin_memory': True, 'UDA_on': False, 'alpha_uda': 1, 'bias': True, 'last_lif': False, 'current epoch': 0} \n",
      "\n",
      "dataset_hash = ffa516e60c3efd5e0208f72b4c36cb84\n",
      "cache path exists\n",
      "\n",
      "device ==> cuda\n",
      "\n",
      "DataParallel(\n",
      "  (module): REBORN_MY_SNN_FC(\n",
      "    (layers): REBORN_MY_Sequential(\n",
      "      (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (2): DimChanger_for_FC()\n",
      "      (3): SYNAPSE_FC(in_features=2048, out_features=200, TIME=10, bias=True, sstep=True)\n",
      "      (4): LIF_layer(v_init=0, v_decay=0.5, v_threshold=0.75, v_reset=10000, sg_width=1, surrogate=hard_sigmoid, BPTT_on=False, trace_const1=1, trace_const2=0.5, TIME=10, sstep=True, trace_on=True)\n",
      "      (5): Feedback_Receiver()\n",
      "      (6): SYNAPSE_FC(in_features=200, out_features=200, TIME=10, bias=True, sstep=True)\n",
      "      (7): LIF_layer(v_init=0, v_decay=0.5, v_threshold=0.75, v_reset=10000, sg_width=1, surrogate=hard_sigmoid, BPTT_on=False, trace_const1=1, trace_const2=0.5, TIME=10, sstep=True, trace_on=True)\n",
      "      (8): Feedback_Receiver()\n",
      "      (9): SYNAPSE_FC(in_features=200, out_features=10, TIME=10, bias=True, sstep=True)\n",
      "      (DFA_top): Top_Gradient()\n",
      "    )\n",
      "  )\n",
      ")\n",
      "\n",
      "========================================================\n",
      "Trainable parameters: 452,010\n",
      "========================================================\n",
      "\n",
      "epoch-0   lr=['0.0010000'], tr/val_loss:  2.305352/  2.302666, val:  11.67%, val_best:  11.67%, tr:   8.38%, tr_best:   8.38%\n",
      "[module.layers.5] weight_fb parameter count: 2,000\n",
      "[module.layers.8] weight_fb parameter count: 2,000\n",
      "epoch-1   lr=['0.0010000'], tr/val_loss:  2.291000/  2.238244, val:  16.67%, val_best:  16.67%, tr:  12.67%, tr_best:  12.67%\n",
      "epoch-2   lr=['0.0010000'], tr/val_loss:  2.019721/  1.895404, val:  43.33%, val_best:  43.33%, tr:  30.34%, tr_best:  30.34%\n",
      "epoch-3   lr=['0.0010000'], tr/val_loss:  1.676060/  1.719729, val:  49.58%, val_best:  49.58%, tr:  51.38%, tr_best:  51.38%\n",
      "epoch-4   lr=['0.0010000'], tr/val_loss:  1.549754/  1.688392, val:  52.08%, val_best:  52.08%, tr:  56.79%, tr_best:  56.79%\n",
      "epoch-5   lr=['0.0010000'], tr/val_loss:  1.485119/  1.647201, val:  54.17%, val_best:  54.17%, tr:  57.20%, tr_best:  57.20%\n",
      "epoch-6   lr=['0.0010000'], tr/val_loss:  1.452062/  1.631100, val:  56.67%, val_best:  56.67%, tr:  60.16%, tr_best:  60.16%\n",
      "epoch-7   lr=['0.0010000'], tr/val_loss:  1.424407/  1.621793, val:  57.08%, val_best:  57.08%, tr:  59.96%, tr_best:  60.16%\n",
      "epoch-8   lr=['0.0010000'], tr/val_loss:  1.394216/  1.619866, val:  59.58%, val_best:  59.58%, tr:  62.31%, tr_best:  62.31%\n",
      "epoch-9   lr=['0.0010000'], tr/val_loss:  1.380970/  1.609393, val:  59.17%, val_best:  59.58%, tr:  63.74%, tr_best:  63.74%\n",
      "epoch-10  lr=['0.0010000'], tr/val_loss:  1.373238/  1.626788, val:  60.42%, val_best:  60.42%, tr:  63.43%, tr_best:  63.74%\n",
      "epoch-11  lr=['0.0010000'], tr/val_loss:  1.350673/  1.593736, val:  60.83%, val_best:  60.83%, tr:  64.66%, tr_best:  64.66%\n",
      "epoch-12  lr=['0.0010000'], tr/val_loss:  1.345445/  1.611862, val:  60.42%, val_best:  60.83%, tr:  66.50%, tr_best:  66.50%\n",
      "epoch-13  lr=['0.0010000'], tr/val_loss:  1.343207/  1.641777, val:  60.83%, val_best:  60.83%, tr:  65.68%, tr_best:  66.50%\n",
      "epoch-14  lr=['0.0010000'], tr/val_loss:  1.294041/  1.742633, val:  57.08%, val_best:  60.83%, tr:  67.52%, tr_best:  67.52%\n",
      "epoch-15  lr=['0.0010000'], tr/val_loss:  1.298627/  1.634061, val:  66.67%, val_best:  66.67%, tr:  70.48%, tr_best:  70.48%\n",
      "epoch-16  lr=['0.0010000'], tr/val_loss:  1.304512/  1.671097, val:  60.42%, val_best:  66.67%, tr:  68.74%, tr_best:  70.48%\n",
      "epoch-17  lr=['0.0010000'], tr/val_loss:  1.280349/  1.659420, val:  63.75%, val_best:  66.67%, tr:  72.01%, tr_best:  72.01%\n",
      "epoch-18  lr=['0.0010000'], tr/val_loss:  1.272483/  1.746020, val:  62.92%, val_best:  66.67%, tr:  70.68%, tr_best:  72.01%\n",
      "epoch-19  lr=['0.0010000'], tr/val_loss:  1.275153/  1.760296, val:  59.58%, val_best:  66.67%, tr:  71.40%, tr_best:  72.01%\n",
      "epoch-20  lr=['0.0010000'], tr/val_loss:  1.265674/  1.770445, val:  63.75%, val_best:  66.67%, tr:  72.73%, tr_best:  72.73%\n",
      "epoch-21  lr=['0.0010000'], tr/val_loss:  1.270551/  1.782897, val:  65.42%, val_best:  66.67%, tr:  73.95%, tr_best:  73.95%\n",
      "epoch-22  lr=['0.0010000'], tr/val_loss:  1.280797/  1.831736, val:  60.83%, val_best:  66.67%, tr:  73.44%, tr_best:  73.95%\n",
      "epoch-23  lr=['0.0010000'], tr/val_loss:  1.224959/  1.832835, val:  62.08%, val_best:  66.67%, tr:  76.00%, tr_best:  76.00%\n",
      "epoch-24  lr=['0.0010000'], tr/val_loss:  1.229332/  1.913006, val:  62.50%, val_best:  66.67%, tr:  77.22%, tr_best:  77.22%\n",
      "epoch-25  lr=['0.0010000'], tr/val_loss:  1.240600/  1.867247, val:  68.75%, val_best:  68.75%, tr:  76.81%, tr_best:  77.22%\n",
      "epoch-26  lr=['0.0010000'], tr/val_loss:  1.236686/  1.863925, val:  67.08%, val_best:  68.75%, tr:  77.94%, tr_best:  77.94%\n",
      "epoch-27  lr=['0.0010000'], tr/val_loss:  1.231740/  1.991286, val:  63.75%, val_best:  68.75%, tr:  78.75%, tr_best:  78.75%\n",
      "epoch-28  lr=['0.0010000'], tr/val_loss:  1.233746/  1.961849, val:  68.75%, val_best:  68.75%, tr:  79.47%, tr_best:  79.47%\n",
      "epoch-29  lr=['0.0010000'], tr/val_loss:  1.209592/  2.082444, val:  64.58%, val_best:  68.75%, tr:  80.49%, tr_best:  80.49%\n",
      "epoch-30  lr=['0.0010000'], tr/val_loss:  1.204179/  2.143058, val:  62.08%, val_best:  68.75%, tr:  83.35%, tr_best:  83.35%\n",
      "epoch-31  lr=['0.0010000'], tr/val_loss:  1.246820/  2.157331, val:  63.75%, val_best:  68.75%, tr:  80.18%, tr_best:  83.35%\n",
      "epoch-32  lr=['0.0010000'], tr/val_loss:  1.238074/  2.184934, val:  65.42%, val_best:  68.75%, tr:  81.31%, tr_best:  83.35%\n",
      "epoch-33  lr=['0.0010000'], tr/val_loss:  1.237233/  2.227991, val:  66.67%, val_best:  68.75%, tr:  82.74%, tr_best:  83.35%\n",
      "epoch-34  lr=['0.0010000'], tr/val_loss:  1.218516/  2.282267, val:  61.67%, val_best:  68.75%, tr:  84.88%, tr_best:  84.88%\n",
      "epoch-35  lr=['0.0010000'], tr/val_loss:  1.254595/  2.421817, val:  61.67%, val_best:  68.75%, tr:  80.49%, tr_best:  84.88%\n",
      "epoch-36  lr=['0.0010000'], tr/val_loss:  1.231102/  2.374397, val:  62.92%, val_best:  68.75%, tr:  84.07%, tr_best:  84.88%\n",
      "epoch-37  lr=['0.0010000'], tr/val_loss:  1.246766/  2.392906, val:  65.00%, val_best:  68.75%, tr:  84.78%, tr_best:  84.88%\n",
      "epoch-38  lr=['0.0010000'], tr/val_loss:  1.245117/  2.445349, val:  65.42%, val_best:  68.75%, tr:  86.31%, tr_best:  86.31%\n",
      "epoch-39  lr=['0.0010000'], tr/val_loss:  1.256379/  2.520648, val:  66.25%, val_best:  68.75%, tr:  87.03%, tr_best:  87.03%\n",
      "epoch-40  lr=['0.0010000'], tr/val_loss:  1.262652/  2.592531, val:  66.25%, val_best:  68.75%, tr:  86.21%, tr_best:  87.03%\n",
      "epoch-41  lr=['0.0010000'], tr/val_loss:  1.277169/  2.678485, val:  61.25%, val_best:  68.75%, tr:  87.64%, tr_best:  87.64%\n",
      "epoch-42  lr=['0.0010000'], tr/val_loss:  1.250988/  2.646416, val:  65.83%, val_best:  68.75%, tr:  88.97%, tr_best:  88.97%\n",
      "epoch-43  lr=['0.0010000'], tr/val_loss:  1.263422/  2.722022, val:  64.58%, val_best:  68.75%, tr:  88.76%, tr_best:  88.97%\n",
      "epoch-44  lr=['0.0010000'], tr/val_loss:  1.250061/  2.752165, val:  65.00%, val_best:  68.75%, tr:  89.89%, tr_best:  89.89%\n",
      "epoch-45  lr=['0.0010000'], tr/val_loss:  1.246642/  2.811404, val:  65.83%, val_best:  68.75%, tr:  89.48%, tr_best:  89.89%\n",
      "epoch-46  lr=['0.0010000'], tr/val_loss:  1.261109/  2.902057, val:  66.67%, val_best:  68.75%, tr:  89.99%, tr_best:  89.99%\n",
      "epoch-47  lr=['0.0010000'], tr/val_loss:  1.258367/  2.907105, val:  67.08%, val_best:  68.75%, tr:  90.91%, tr_best:  90.91%\n",
      "epoch-48  lr=['0.0010000'], tr/val_loss:  1.304595/  2.966496, val:  65.42%, val_best:  68.75%, tr:  91.62%, tr_best:  91.62%\n",
      "epoch-49  lr=['0.0010000'], tr/val_loss:  1.291531/  3.015284, val:  66.25%, val_best:  68.75%, tr:  90.40%, tr_best:  91.62%\n",
      "epoch-50  lr=['0.0010000'], tr/val_loss:  1.293955/  3.141480, val:  62.92%, val_best:  68.75%, tr:  91.32%, tr_best:  91.62%\n",
      "epoch-51  lr=['0.0010000'], tr/val_loss:  1.337783/  3.166044, val:  67.50%, val_best:  68.75%, tr:  89.79%, tr_best:  91.62%\n",
      "epoch-52  lr=['0.0010000'], tr/val_loss:  1.295871/  3.243957, val:  64.17%, val_best:  68.75%, tr:  92.54%, tr_best:  92.54%\n",
      "epoch-53  lr=['0.0010000'], tr/val_loss:  1.313455/  3.284660, val:  67.92%, val_best:  68.75%, tr:  92.03%, tr_best:  92.54%\n",
      "epoch-54  lr=['0.0010000'], tr/val_loss:  1.317765/  3.376307, val:  68.75%, val_best:  68.75%, tr:  92.34%, tr_best:  92.54%\n",
      "epoch-55  lr=['0.0010000'], tr/val_loss:  1.329301/  3.479470, val:  68.75%, val_best:  68.75%, tr:  91.73%, tr_best:  92.54%\n",
      "epoch-56  lr=['0.0010000'], tr/val_loss:  1.322903/  3.581122, val:  66.25%, val_best:  68.75%, tr:  93.77%, tr_best:  93.77%\n",
      "epoch-57  lr=['0.0010000'], tr/val_loss:  1.353824/  3.536725, val:  67.08%, val_best:  68.75%, tr:  92.44%, tr_best:  93.77%\n",
      "epoch-58  lr=['0.0010000'], tr/val_loss:  1.347081/  3.651284, val:  69.17%, val_best:  69.17%, tr:  91.42%, tr_best:  93.77%\n",
      "epoch-59  lr=['0.0010000'], tr/val_loss:  1.345018/  3.671752, val:  70.42%, val_best:  70.42%, tr:  93.67%, tr_best:  93.77%\n",
      "epoch-60  lr=['0.0010000'], tr/val_loss:  1.352741/  3.685092, val:  72.08%, val_best:  72.08%, tr:  93.67%, tr_best:  93.77%\n",
      "epoch-61  lr=['0.0010000'], tr/val_loss:  1.362739/  3.805773, val:  65.83%, val_best:  72.08%, tr:  94.18%, tr_best:  94.18%\n",
      "epoch-62  lr=['0.0010000'], tr/val_loss:  1.401058/  3.900979, val:  64.58%, val_best:  72.08%, tr:  93.67%, tr_best:  94.18%\n",
      "epoch-63  lr=['0.0010000'], tr/val_loss:  1.340815/  3.883210, val:  67.08%, val_best:  72.08%, tr:  94.99%, tr_best:  94.99%\n",
      "epoch-64  lr=['0.0010000'], tr/val_loss:  1.388240/  4.041090, val:  68.33%, val_best:  72.08%, tr:  92.95%, tr_best:  94.99%\n",
      "epoch-65  lr=['0.0010000'], tr/val_loss:  1.374563/  4.017573, val:  66.67%, val_best:  72.08%, tr:  93.97%, tr_best:  94.99%\n",
      "epoch-66  lr=['0.0010000'], tr/val_loss:  1.376930/  4.108985, val:  67.08%, val_best:  72.08%, tr:  94.28%, tr_best:  94.99%\n",
      "epoch-67  lr=['0.0010000'], tr/val_loss:  1.421473/  4.139065, val:  67.08%, val_best:  72.08%, tr:  94.38%, tr_best:  94.99%\n",
      "epoch-68  lr=['0.0010000'], tr/val_loss:  1.397636/  4.332170, val:  67.92%, val_best:  72.08%, tr:  94.48%, tr_best:  94.99%\n",
      "epoch-69  lr=['0.0010000'], tr/val_loss:  1.441104/  4.307713, val:  65.42%, val_best:  72.08%, tr:  93.56%, tr_best:  94.99%\n",
      "epoch-70  lr=['0.0010000'], tr/val_loss:  1.403979/  4.325988, val:  69.17%, val_best:  72.08%, tr:  95.40%, tr_best:  95.40%\n",
      "epoch-71  lr=['0.0010000'], tr/val_loss:  1.416526/  4.479855, val:  65.83%, val_best:  72.08%, tr:  94.18%, tr_best:  95.40%\n",
      "epoch-72  lr=['0.0010000'], tr/val_loss:  1.418312/  4.519227, val:  67.50%, val_best:  72.08%, tr:  95.10%, tr_best:  95.40%\n",
      "epoch-73  lr=['0.0010000'], tr/val_loss:  1.454190/  4.434769, val:  70.42%, val_best:  72.08%, tr:  94.28%, tr_best:  95.40%\n",
      "epoch-74  lr=['0.0010000'], tr/val_loss:  1.387105/  4.549036, val:  70.42%, val_best:  72.08%, tr:  95.81%, tr_best:  95.81%\n",
      "epoch-75  lr=['0.0010000'], tr/val_loss:  1.432407/  4.673056, val:  65.83%, val_best:  72.08%, tr:  94.48%, tr_best:  95.81%\n",
      "epoch-76  lr=['0.0010000'], tr/val_loss:  1.396946/  4.854704, val:  66.67%, val_best:  72.08%, tr:  95.61%, tr_best:  95.81%\n",
      "epoch-77  lr=['0.0010000'], tr/val_loss:  1.401379/  4.785906, val:  71.25%, val_best:  72.08%, tr:  95.10%, tr_best:  95.81%\n",
      "epoch-78  lr=['0.0010000'], tr/val_loss:  1.428124/  4.891007, val:  70.00%, val_best:  72.08%, tr:  94.59%, tr_best:  95.81%\n",
      "epoch-79  lr=['0.0010000'], tr/val_loss:  1.388427/  4.852261, val:  70.00%, val_best:  72.08%, tr:  96.12%, tr_best:  96.12%\n",
      "epoch-80  lr=['0.0010000'], tr/val_loss:  1.377656/  5.012600, val:  66.67%, val_best:  72.08%, tr:  95.81%, tr_best:  96.12%\n",
      "epoch-81  lr=['0.0010000'], tr/val_loss:  1.398011/  4.929044, val:  70.00%, val_best:  72.08%, tr:  95.61%, tr_best:  96.12%\n",
      "epoch-82  lr=['0.0010000'], tr/val_loss:  1.407977/  5.091597, val:  66.67%, val_best:  72.08%, tr:  95.81%, tr_best:  96.12%\n",
      "epoch-83  lr=['0.0010000'], tr/val_loss:  1.424639/  5.217146, val:  68.33%, val_best:  72.08%, tr:  95.81%, tr_best:  96.12%\n",
      "epoch-84  lr=['0.0010000'], tr/val_loss:  1.454949/  5.207861, val:  69.58%, val_best:  72.08%, tr:  96.63%, tr_best:  96.63%\n",
      "epoch-85  lr=['0.0010000'], tr/val_loss:  1.435362/  5.290154, val:  66.25%, val_best:  72.08%, tr:  97.14%, tr_best:  97.14%\n",
      "epoch-86  lr=['0.0010000'], tr/val_loss:  1.435105/  5.331820, val:  70.42%, val_best:  72.08%, tr:  95.91%, tr_best:  97.14%\n",
      "epoch-87  lr=['0.0010000'], tr/val_loss:  1.459584/  5.488632, val:  67.08%, val_best:  72.08%, tr:  95.81%, tr_best:  97.14%\n",
      "epoch-88  lr=['0.0010000'], tr/val_loss:  1.418352/  5.435036, val:  69.17%, val_best:  72.08%, tr:  96.94%, tr_best:  97.14%\n",
      "epoch-89  lr=['0.0010000'], tr/val_loss:  1.399766/  5.552534, val:  69.58%, val_best:  72.08%, tr:  96.83%, tr_best:  97.14%\n",
      "epoch-90  lr=['0.0010000'], tr/val_loss:  1.424972/  5.498280, val:  69.17%, val_best:  72.08%, tr:  97.04%, tr_best:  97.14%\n",
      "epoch-91  lr=['0.0010000'], tr/val_loss:  1.432758/  5.735713, val:  67.50%, val_best:  72.08%, tr:  96.53%, tr_best:  97.14%\n",
      "epoch-92  lr=['0.0010000'], tr/val_loss:  1.435318/  5.712155, val:  69.58%, val_best:  72.08%, tr:  96.83%, tr_best:  97.14%\n",
      "epoch-93  lr=['0.0010000'], tr/val_loss:  1.440660/  5.693712, val:  68.75%, val_best:  72.08%, tr:  96.53%, tr_best:  97.14%\n",
      "epoch-94  lr=['0.0010000'], tr/val_loss:  1.453702/  5.868421, val:  69.17%, val_best:  72.08%, tr:  96.83%, tr_best:  97.14%\n",
      "epoch-95  lr=['0.0010000'], tr/val_loss:  1.470503/  5.974334, val:  65.83%, val_best:  72.08%, tr:  96.22%, tr_best:  97.14%\n",
      "epoch-96  lr=['0.0010000'], tr/val_loss:  1.478259/  6.145544, val:  67.08%, val_best:  72.08%, tr:  96.63%, tr_best:  97.14%\n",
      "epoch-97  lr=['0.0010000'], tr/val_loss:  1.513734/  6.075477, val:  70.42%, val_best:  72.08%, tr:  94.89%, tr_best:  97.14%\n",
      "epoch-98  lr=['0.0010000'], tr/val_loss:  1.478986/  6.122235, val:  71.25%, val_best:  72.08%, tr:  97.24%, tr_best:  97.24%\n",
      "epoch-99  lr=['0.0010000'], tr/val_loss:  1.493304/  6.196062, val:  64.17%, val_best:  72.08%, tr:  96.53%, tr_best:  97.24%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d6f3af589e6046758a63992a62f5de89",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.006 MB of 0.006 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>iter_acc</td><td>▁▃▄▄▅▆▆▃▆▇██▇▇▇█████▇▇███▇▇██▇██▆██▇▇▇██</td></tr><tr><td>summary_val_acc</td><td>▁▅▆▆▇▇▆▇▇▇▇█▇▇▇▇▇▇▇█▇▇███▇▇███▇██▇████▇█</td></tr><tr><td>tr_acc</td><td>▁▃▅▅▅▆▆▆▆▆▆▇▇▇▇▇▇▇▇█▇███████████████████</td></tr><tr><td>tr_epoch_loss</td><td>█▆▃▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▂▂▂▂▂▂▂▂▂▂▂▂▂▂▃▃▂▂▃▃</td></tr><tr><td>val_acc_best</td><td>▁▅▆▆▇▇▇▇▇▇▇█████████████████████████████</td></tr><tr><td>val_acc_now</td><td>▁▅▆▆▇▇▆▇▇▇▇█▇▇▇▇▇▇▇█▇▇███▇▇███▇██▇████▇█</td></tr><tr><td>val_loss</td><td>▂▁▁▁▁▁▁▁▁▁▁▁▂▂▂▂▂▃▃▃▃▄▄▄▄▄▅▅▅▆▆▆▆▆▇▇▇▇██</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>99</td></tr><tr><td>iter_acc</td><td>1.0</td></tr><tr><td>tr_acc</td><td>0.96527</td></tr><tr><td>tr_epoch_loss</td><td>1.4933</td></tr><tr><td>val_acc_best</td><td>0.72083</td></tr><tr><td>val_acc_now</td><td>0.64167</td></tr><tr><td>val_loss</td><td>6.19606</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">honest-sweep-232</strong> at: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/8qu8lho5' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/8qu8lho5</a><br/> View project at: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>/data2/bh_wandb/wandb/run-20250430_073246-8qu8lho5/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require(\"core\")`! See https://wandb.me/wandb-core for more information."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: vmxn4jt1 with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBATCH: 16\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBN_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBPTT_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tDFA_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tIMAGE_SIZE: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tOTTT_input_trace_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tTIME: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tUDA_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \talpha_uda: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbias: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcfg: ['M', 'M', 200, 200]\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tchaching_on: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tconvTrue_fcFalse: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdata_path: /data2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tddp_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdenoise_on: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdvs_clipping: 5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdvs_duration: 100000\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepoch_num: 100\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \texclude_class: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \textra_train_dataset: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlast_lif: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.001\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_sg_width: 3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_decay: 0.5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_init: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_reset: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_threshold: 0.75\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmerge_polarities: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmy_seed: 42\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnet_print: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_workers: 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer_what: SGD\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tpin_memory: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tpre_trained: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tpre_trained_path: net_save/save_now_net_weights_{unique_name}.pth\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \trate_coding: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tscheduler_name: no\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsingle_step: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsurrogate: hard_sigmoid\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_conv_kernel_size: 3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_conv_padding: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_conv_stride: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_trace_const1: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_trace_const2: 0.5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \ttdBN_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \ttrace_on: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \twhich_data: DVS_GESTURE_TONIC\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.19.10 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.17.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/data2/bh_wandb/wandb/run-20250430_073924-vmxn4jt1</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/vmxn4jt1' target=\"_blank\">elated-sweep-234</a></strong> to <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/6pj3lh8j' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/6pj3lh8j</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/6pj3lh8j' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/6pj3lh8j</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/vmxn4jt1' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/vmxn4jt1</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'single_step' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'my_seed' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'TIME' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BATCH' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'IMAGE_SIZE' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'which_data' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'data_path' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'rate_coding' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_init' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_decay' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_threshold' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_reset' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_sg_width' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_conv_kernel_size' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_conv_stride' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_conv_padding' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_trace_const1' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_trace_const2' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'pre_trained' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'convTrue_fcFalse' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'cfg' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'net_print' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'pre_trained_path' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'learning_rate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'epoch_num' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'tdBN_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BN_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'surrogate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BPTT_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'optimizer_what' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'scheduler_name' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'ddp_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'dvs_clipping' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'dvs_duration' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'DFA_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'trace_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'OTTT_input_trace_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'exclude_class' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'merge_polarities' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'denoise_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'extra_train_dataset' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'num_workers' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'chaching_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'pin_memory' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'UDA_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'alpha_uda' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'bias' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'last_lif' was locked by 'sweep' (ignored update).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "param {'devices': '0', 'single_step': True, 'unique_name': 'main', 'my_seed': 42, 'TIME': 10, 'BATCH': 16, 'IMAGE_SIZE': 128, 'which_data': 'DVS_GESTURE_TONIC', 'data_path': '/data2', 'rate_coding': False, 'lif_layer_v_init': 0, 'lif_layer_v_decay': 0.5, 'lif_layer_v_threshold': 0.75, 'lif_layer_v_reset': 0, 'lif_layer_sg_width': 3, 'synapse_conv_kernel_size': 3, 'synapse_conv_stride': 1, 'synapse_conv_padding': 1, 'synapse_trace_const1': 1, 'synapse_trace_const2': 0.5, 'pre_trained': False, 'convTrue_fcFalse': False, 'cfg': ['M', 'M', 200, 200], 'net_print': True, 'pre_trained_path': 'net_save/save_now_net_weights_{unique_name}.pth', 'learning_rate': 0.001, 'epoch_num': 100, 'tdBN_on': False, 'BN_on': False, 'surrogate': 'hard_sigmoid', 'BPTT_on': False, 'optimizer_what': 'SGD', 'scheduler_name': 'no', 'ddp_on': False, 'dvs_clipping': 5, 'dvs_duration': 100000, 'DFA_on': False, 'trace_on': True, 'OTTT_input_trace_on': False, 'exclude_class': True, 'merge_polarities': False, 'denoise_on': True, 'extra_train_dataset': 0, 'num_workers': 2, 'chaching_on': True, 'pin_memory': True, 'UDA_on': False, 'alpha_uda': 1, 'bias': True, 'last_lif': False, 'current epoch': 0} \n",
      "\n",
      "dataset_hash = 63cc597115630ec173f3099200061e53\n",
      "cache path exists\n",
      "\n",
      "device ==> cuda\n",
      "\n",
      "DataParallel(\n",
      "  (module): REBORN_MY_SNN_FC(\n",
      "    (layers): REBORN_MY_Sequential(\n",
      "      (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (2): DimChanger_for_FC()\n",
      "      (3): SYNAPSE_FC(in_features=2048, out_features=200, TIME=10, bias=True, sstep=True)\n",
      "      (4): LIF_layer(v_init=0, v_decay=0.5, v_threshold=0.75, v_reset=0, sg_width=3, surrogate=hard_sigmoid, BPTT_on=False, trace_const1=1, trace_const2=0.5, TIME=10, sstep=True, trace_on=True)\n",
      "      (5): SYNAPSE_FC(in_features=200, out_features=200, TIME=10, bias=True, sstep=True)\n",
      "      (6): LIF_layer(v_init=0, v_decay=0.5, v_threshold=0.75, v_reset=0, sg_width=3, surrogate=hard_sigmoid, BPTT_on=False, trace_const1=1, trace_const2=0.5, TIME=10, sstep=True, trace_on=True)\n",
      "      (7): SYNAPSE_FC(in_features=200, out_features=10, TIME=10, bias=True, sstep=True)\n",
      "    )\n",
      "  )\n",
      ")\n",
      "\n",
      "========================================================\n",
      "Trainable parameters: 452,010\n",
      "========================================================\n",
      "\n",
      "epoch-0   lr=['0.0010000'], tr/val_loss:  2.305365/  2.302841, val:  10.00%, val_best:  10.00%, tr:   8.17%, tr_best:   8.17%\n",
      "epoch-1   lr=['0.0010000'], tr/val_loss:  2.304994/  2.302639, val:  10.00%, val_best:  10.00%, tr:   7.66%, tr_best:   8.17%\n",
      "epoch-2   lr=['0.0010000'], tr/val_loss:  2.305079/  2.302667, val:  10.00%, val_best:  10.00%, tr:   8.99%, tr_best:   8.99%\n",
      "epoch-3   lr=['0.0010000'], tr/val_loss:  2.304731/  2.302708, val:  10.00%, val_best:  10.00%, tr:   8.38%, tr_best:   8.99%\n",
      "epoch-4   lr=['0.0010000'], tr/val_loss:  2.304833/  2.302682, val:  10.00%, val_best:  10.00%, tr:   7.87%, tr_best:   8.99%\n",
      "epoch-5   lr=['0.0010000'], tr/val_loss:  2.304569/  2.302663, val:  10.00%, val_best:  10.00%, tr:   7.87%, tr_best:   8.99%\n",
      "epoch-6   lr=['0.0010000'], tr/val_loss:  2.305086/  2.302675, val:  10.00%, val_best:  10.00%, tr:   9.70%, tr_best:   9.70%\n",
      "epoch-7   lr=['0.0010000'], tr/val_loss:  2.304543/  2.302057, val:  10.83%, val_best:  10.83%, tr:   7.35%, tr_best:   9.70%\n",
      "epoch-8   lr=['0.0010000'], tr/val_loss:  2.299011/  2.291285, val:  12.08%, val_best:  12.08%, tr:  11.64%, tr_best:  11.64%\n",
      "epoch-9   lr=['0.0010000'], tr/val_loss:  2.237182/  2.232189, val:  19.17%, val_best:  19.17%, tr:  14.30%, tr_best:  14.30%\n",
      "epoch-10  lr=['0.0010000'], tr/val_loss:  2.158723/  2.147399, val:  32.92%, val_best:  32.92%, tr:  20.63%, tr_best:  20.63%\n",
      "epoch-11  lr=['0.0010000'], tr/val_loss:  2.036207/  1.991074, val:  37.50%, val_best:  37.50%, tr:  32.18%, tr_best:  32.18%\n",
      "epoch-12  lr=['0.0010000'], tr/val_loss:  1.832694/  1.794349, val:  48.33%, val_best:  48.33%, tr:  42.39%, tr_best:  42.39%\n",
      "epoch-13  lr=['0.0010000'], tr/val_loss:  1.612579/  1.603545, val:  55.00%, val_best:  55.00%, tr:  50.36%, tr_best:  50.36%\n",
      "epoch-14  lr=['0.0010000'], tr/val_loss:  1.391884/  1.540003, val:  53.75%, val_best:  55.00%, tr:  58.22%, tr_best:  58.22%\n",
      "epoch-15  lr=['0.0010000'], tr/val_loss:  1.304305/  1.498363, val:  56.25%, val_best:  56.25%, tr:  59.45%, tr_best:  59.45%\n",
      "epoch-16  lr=['0.0010000'], tr/val_loss:  1.233010/  1.442962, val:  59.58%, val_best:  59.58%, tr:  61.49%, tr_best:  61.49%\n",
      "epoch-17  lr=['0.0010000'], tr/val_loss:  1.160904/  1.410161, val:  60.00%, val_best:  60.00%, tr:  65.47%, tr_best:  65.47%\n",
      "epoch-18  lr=['0.0010000'], tr/val_loss:  1.124717/  1.461523, val:  58.75%, val_best:  60.00%, tr:  65.88%, tr_best:  65.88%\n",
      "epoch-19  lr=['0.0010000'], tr/val_loss:  1.092905/  1.427984, val:  60.00%, val_best:  60.00%, tr:  67.52%, tr_best:  67.52%\n",
      "epoch-20  lr=['0.0010000'], tr/val_loss:  1.046218/  1.416330, val:  59.17%, val_best:  60.00%, tr:  69.66%, tr_best:  69.66%\n",
      "epoch-21  lr=['0.0010000'], tr/val_loss:  1.008681/  1.413498, val:  59.17%, val_best:  60.00%, tr:  68.85%, tr_best:  69.66%\n",
      "epoch-22  lr=['0.0010000'], tr/val_loss:  1.001991/  1.423829, val:  61.25%, val_best:  61.25%, tr:  69.46%, tr_best:  69.66%\n",
      "epoch-23  lr=['0.0010000'], tr/val_loss:  0.964316/  1.423360, val:  59.58%, val_best:  61.25%, tr:  71.50%, tr_best:  71.50%\n",
      "epoch-24  lr=['0.0010000'], tr/val_loss:  0.921968/  1.423269, val:  62.50%, val_best:  62.50%, tr:  74.36%, tr_best:  74.36%\n",
      "epoch-25  lr=['0.0010000'], tr/val_loss:  0.895209/  1.436681, val:  63.33%, val_best:  63.33%, tr:  74.57%, tr_best:  74.57%\n",
      "epoch-26  lr=['0.0010000'], tr/val_loss:  0.889606/  1.484014, val:  61.67%, val_best:  63.33%, tr:  72.83%, tr_best:  74.57%\n",
      "epoch-27  lr=['0.0010000'], tr/val_loss:  0.862492/  1.514322, val:  61.25%, val_best:  63.33%, tr:  76.30%, tr_best:  76.30%\n",
      "epoch-28  lr=['0.0010000'], tr/val_loss:  0.840970/  1.461765, val:  61.67%, val_best:  63.33%, tr:  76.40%, tr_best:  76.40%\n",
      "epoch-29  lr=['0.0010000'], tr/val_loss:  0.821771/  1.559940, val:  60.42%, val_best:  63.33%, tr:  77.02%, tr_best:  77.02%\n",
      "epoch-30  lr=['0.0010000'], tr/val_loss:  0.786403/  1.516794, val:  61.25%, val_best:  63.33%, tr:  79.78%, tr_best:  79.78%\n",
      "epoch-31  lr=['0.0010000'], tr/val_loss:  0.783050/  1.591195, val:  61.25%, val_best:  63.33%, tr:  77.02%, tr_best:  79.78%\n",
      "epoch-32  lr=['0.0010000'], tr/val_loss:  0.755385/  1.618029, val:  65.00%, val_best:  65.00%, tr:  80.59%, tr_best:  80.59%\n",
      "epoch-33  lr=['0.0010000'], tr/val_loss:  0.735595/  1.625657, val:  64.17%, val_best:  65.00%, tr:  82.02%, tr_best:  82.02%\n",
      "epoch-34  lr=['0.0010000'], tr/val_loss:  0.715666/  1.666672, val:  62.50%, val_best:  65.00%, tr:  81.51%, tr_best:  82.02%\n",
      "epoch-35  lr=['0.0010000'], tr/val_loss:  0.695953/  1.662664, val:  62.08%, val_best:  65.00%, tr:  81.10%, tr_best:  82.02%\n",
      "epoch-36  lr=['0.0010000'], tr/val_loss:  0.664976/  1.609409, val:  66.67%, val_best:  66.67%, tr:  82.53%, tr_best:  82.53%\n",
      "epoch-37  lr=['0.0010000'], tr/val_loss:  0.656216/  1.721725, val:  64.58%, val_best:  66.67%, tr:  83.55%, tr_best:  83.55%\n",
      "epoch-38  lr=['0.0010000'], tr/val_loss:  0.652886/  1.769354, val:  64.58%, val_best:  66.67%, tr:  84.27%, tr_best:  84.27%\n",
      "epoch-39  lr=['0.0010000'], tr/val_loss:  0.639099/  1.628708, val:  66.67%, val_best:  66.67%, tr:  86.52%, tr_best:  86.52%\n",
      "epoch-40  lr=['0.0010000'], tr/val_loss:  0.629980/  1.672987, val:  70.00%, val_best:  70.00%, tr:  85.39%, tr_best:  86.52%\n",
      "epoch-41  lr=['0.0010000'], tr/val_loss:  0.587409/  1.841415, val:  63.33%, val_best:  70.00%, tr:  88.15%, tr_best:  88.15%\n",
      "epoch-42  lr=['0.0010000'], tr/val_loss:  0.585182/  1.713418, val:  72.08%, val_best:  72.08%, tr:  87.95%, tr_best:  88.15%\n",
      "epoch-43  lr=['0.0010000'], tr/val_loss:  0.575263/  1.749547, val:  70.83%, val_best:  72.08%, tr:  88.46%, tr_best:  88.46%\n",
      "epoch-44  lr=['0.0010000'], tr/val_loss:  0.567628/  1.831088, val:  68.75%, val_best:  72.08%, tr:  87.74%, tr_best:  88.46%\n",
      "epoch-45  lr=['0.0010000'], tr/val_loss:  0.532324/  1.848820, val:  69.17%, val_best:  72.08%, tr:  91.11%, tr_best:  91.11%\n",
      "epoch-46  lr=['0.0010000'], tr/val_loss:  0.531644/  1.913397, val:  69.58%, val_best:  72.08%, tr:  91.73%, tr_best:  91.73%\n",
      "epoch-47  lr=['0.0010000'], tr/val_loss:  0.512970/  1.934956, val:  69.58%, val_best:  72.08%, tr:  92.44%, tr_best:  92.44%\n",
      "epoch-48  lr=['0.0010000'], tr/val_loss:  0.534607/  1.959295, val:  71.67%, val_best:  72.08%, tr:  94.08%, tr_best:  94.08%\n",
      "epoch-49  lr=['0.0010000'], tr/val_loss:  0.525164/  1.913532, val:  69.58%, val_best:  72.08%, tr:  91.32%, tr_best:  94.08%\n",
      "epoch-50  lr=['0.0010000'], tr/val_loss:  0.470554/  1.962698, val:  73.75%, val_best:  73.75%, tr:  95.20%, tr_best:  95.20%\n",
      "epoch-51  lr=['0.0010000'], tr/val_loss:  0.458463/  2.047404, val:  70.42%, val_best:  73.75%, tr:  93.36%, tr_best:  95.20%\n",
      "epoch-52  lr=['0.0010000'], tr/val_loss:  0.442604/  2.074333, val:  72.08%, val_best:  73.75%, tr:  96.02%, tr_best:  96.02%\n",
      "epoch-53  lr=['0.0010000'], tr/val_loss:  0.420209/  2.158509, val:  70.83%, val_best:  73.75%, tr:  96.94%, tr_best:  96.94%\n",
      "epoch-54  lr=['0.0010000'], tr/val_loss:  0.411188/  2.131587, val:  74.17%, val_best:  74.17%, tr:  96.83%, tr_best:  96.94%\n",
      "epoch-55  lr=['0.0010000'], tr/val_loss:  0.412993/  2.143072, val:  73.33%, val_best:  74.17%, tr:  96.22%, tr_best:  96.94%\n",
      "epoch-56  lr=['0.0010000'], tr/val_loss:  0.395425/  2.249178, val:  71.67%, val_best:  74.17%, tr:  97.85%, tr_best:  97.85%\n",
      "epoch-57  lr=['0.0010000'], tr/val_loss:  0.420932/  2.300036, val:  65.42%, val_best:  74.17%, tr:  96.94%, tr_best:  97.85%\n",
      "epoch-58  lr=['0.0010000'], tr/val_loss:  0.377761/  2.308128, val:  68.33%, val_best:  74.17%, tr:  97.14%, tr_best:  97.85%\n",
      "epoch-59  lr=['0.0010000'], tr/val_loss:  0.367945/  2.416687, val:  68.75%, val_best:  74.17%, tr:  98.57%, tr_best:  98.57%\n",
      "epoch-60  lr=['0.0010000'], tr/val_loss:  0.333417/  2.498662, val:  68.33%, val_best:  74.17%, tr:  98.57%, tr_best:  98.57%\n",
      "epoch-61  lr=['0.0010000'], tr/val_loss:  0.338904/  2.377132, val:  70.83%, val_best:  74.17%, tr:  97.96%, tr_best:  98.57%\n",
      "epoch-62  lr=['0.0010000'], tr/val_loss:  0.323907/  2.428123, val:  71.25%, val_best:  74.17%, tr:  99.08%, tr_best:  99.08%\n",
      "epoch-63  lr=['0.0010000'], tr/val_loss:  0.301313/  2.482983, val:  69.17%, val_best:  74.17%, tr:  99.59%, tr_best:  99.59%\n",
      "epoch-64  lr=['0.0010000'], tr/val_loss:  0.319332/  2.498609, val:  70.42%, val_best:  74.17%, tr:  98.26%, tr_best:  99.59%\n",
      "epoch-65  lr=['0.0010000'], tr/val_loss:  0.295528/  2.510128, val:  70.83%, val_best:  74.17%, tr:  99.18%, tr_best:  99.59%\n",
      "epoch-66  lr=['0.0010000'], tr/val_loss:  0.291844/  2.581409, val:  73.33%, val_best:  74.17%, tr:  99.49%, tr_best:  99.59%\n",
      "epoch-67  lr=['0.0010000'], tr/val_loss:  0.271895/  2.593685, val:  73.33%, val_best:  74.17%, tr:  99.59%, tr_best:  99.59%\n",
      "epoch-68  lr=['0.0010000'], tr/val_loss:  0.309136/  2.654195, val:  71.67%, val_best:  74.17%, tr:  99.59%, tr_best:  99.59%\n",
      "epoch-69  lr=['0.0010000'], tr/val_loss:  0.285097/  2.633487, val:  72.50%, val_best:  74.17%, tr:  99.18%, tr_best:  99.59%\n",
      "epoch-70  lr=['0.0010000'], tr/val_loss:  0.260289/  2.777462, val:  71.25%, val_best:  74.17%, tr:  99.69%, tr_best:  99.69%\n",
      "epoch-71  lr=['0.0010000'], tr/val_loss:  0.272190/  2.715539, val:  72.92%, val_best:  74.17%, tr:  99.49%, tr_best:  99.69%\n",
      "epoch-72  lr=['0.0010000'], tr/val_loss:  0.274259/  2.799756, val:  71.67%, val_best:  74.17%, tr:  99.39%, tr_best:  99.69%\n",
      "epoch-73  lr=['0.0010000'], tr/val_loss:  0.236606/  2.845451, val:  71.25%, val_best:  74.17%, tr:  99.80%, tr_best:  99.80%\n",
      "epoch-74  lr=['0.0010000'], tr/val_loss:  0.224236/  2.845547, val:  71.67%, val_best:  74.17%, tr:  99.90%, tr_best:  99.90%\n",
      "epoch-75  lr=['0.0010000'], tr/val_loss:  0.209370/  2.948280, val:  70.83%, val_best:  74.17%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-76  lr=['0.0010000'], tr/val_loss:  0.196720/  2.994101, val:  70.83%, val_best:  74.17%, tr:  99.90%, tr_best: 100.00%\n",
      "epoch-77  lr=['0.0010000'], tr/val_loss:  0.220200/  3.055378, val:  73.33%, val_best:  74.17%, tr:  99.90%, tr_best: 100.00%\n",
      "epoch-78  lr=['0.0010000'], tr/val_loss:  0.234436/  2.993375, val:  74.17%, val_best:  74.17%, tr:  99.39%, tr_best: 100.00%\n",
      "epoch-79  lr=['0.0010000'], tr/val_loss:  0.192221/  3.097527, val:  71.67%, val_best:  74.17%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-80  lr=['0.0010000'], tr/val_loss:  0.173373/  3.068929, val:  71.67%, val_best:  74.17%, tr:  99.90%, tr_best: 100.00%\n",
      "epoch-81  lr=['0.0010000'], tr/val_loss:  0.161259/  3.144039, val:  74.58%, val_best:  74.58%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-82  lr=['0.0010000'], tr/val_loss:  0.160752/  3.123925, val:  72.08%, val_best:  74.58%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-83  lr=['0.0010000'], tr/val_loss:  0.159197/  3.177574, val:  70.83%, val_best:  74.58%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-84  lr=['0.0010000'], tr/val_loss:  0.159168/  3.165034, val:  75.42%, val_best:  75.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-85  lr=['0.0010000'], tr/val_loss:  0.155319/  3.297764, val:  73.75%, val_best:  75.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-86  lr=['0.0010000'], tr/val_loss:  0.148731/  3.305116, val:  72.92%, val_best:  75.42%, tr:  99.80%, tr_best: 100.00%\n",
      "epoch-87  lr=['0.0010000'], tr/val_loss:  0.152296/  3.282193, val:  73.33%, val_best:  75.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-88  lr=['0.0010000'], tr/val_loss:  0.139103/  3.322772, val:  75.83%, val_best:  75.83%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-89  lr=['0.0010000'], tr/val_loss:  0.122423/  3.446293, val:  71.25%, val_best:  75.83%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-90  lr=['0.0010000'], tr/val_loss:  0.125501/  3.534153, val:  72.92%, val_best:  75.83%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-91  lr=['0.0010000'], tr/val_loss:  0.117357/  3.527579, val:  73.33%, val_best:  75.83%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-92  lr=['0.0010000'], tr/val_loss:  0.128200/  3.549241, val:  75.00%, val_best:  75.83%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-93  lr=['0.0010000'], tr/val_loss:  0.119054/  3.489995, val:  72.92%, val_best:  75.83%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-94  lr=['0.0010000'], tr/val_loss:  0.095179/  3.608744, val:  74.58%, val_best:  75.83%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-95  lr=['0.0010000'], tr/val_loss:  0.094395/  3.666489, val:  73.33%, val_best:  75.83%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-96  lr=['0.0010000'], tr/val_loss:  0.101472/  3.672841, val:  72.92%, val_best:  75.83%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-97  lr=['0.0010000'], tr/val_loss:  0.093554/  3.577457, val:  74.17%, val_best:  75.83%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-98  lr=['0.0010000'], tr/val_loss:  0.085800/  3.762838, val:  72.08%, val_best:  75.83%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-99  lr=['0.0010000'], tr/val_loss:  0.098645/  3.709057, val:  74.17%, val_best:  75.83%, tr: 100.00%, tr_best: 100.00%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "87ffde290eb644ba9e2680298b3da383",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.006 MB of 0.006 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>iter_acc</td><td>▁▂▁▁▁▅▆▄▅▆▆▇▆▇▆▇███▇▇███████████████████</td></tr><tr><td>summary_val_acc</td><td>▁▁▁▁▂▅▆▆▆▆▇▇▆▇▇▇▇█▇▇▇██▇▇███████████████</td></tr><tr><td>tr_acc</td><td>▁▁▁▁▂▄▅▅▆▆▆▆▆▇▇▇▇▇▇▇▇███████████████████</td></tr><tr><td>tr_epoch_loss</td><td>█████▇▅▄▄▄▄▄▃▃▃▃▃▃▃▂▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_acc_best</td><td>▁▁▁▁▂▅▆▆▆▆▇▇▇▇▇▇▇███████████████████████</td></tr><tr><td>val_acc_now</td><td>▁▁▁▁▂▅▆▆▆▆▇▇▆▇▇▇▇█▇▇▇██▇▇███████████████</td></tr><tr><td>val_loss</td><td>▄▄▄▄▄▂▁▁▁▁▁▁▁▂▂▂▂▂▂▃▃▃▃▄▄▄▄▅▅▅▆▆▆▆▆▇▇███</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>99</td></tr><tr><td>iter_acc</td><td>1.0</td></tr><tr><td>tr_acc</td><td>1.0</td></tr><tr><td>tr_epoch_loss</td><td>0.09864</td></tr><tr><td>val_acc_best</td><td>0.75833</td></tr><tr><td>val_acc_now</td><td>0.74167</td></tr><tr><td>val_loss</td><td>3.70906</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">elated-sweep-234</strong> at: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/vmxn4jt1' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/vmxn4jt1</a><br/> View project at: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>/data2/bh_wandb/wandb/run-20250430_073924-vmxn4jt1/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require(\"core\")`! See https://wandb.me/wandb-core for more information."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: uvpd117o with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBATCH: 16\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBN_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBPTT_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tDFA_on: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tIMAGE_SIZE: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tOTTT_input_trace_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tTIME: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tUDA_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \talpha_uda: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbias: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcfg: ['M', 'M', 200, 200]\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tchaching_on: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tconvTrue_fcFalse: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdata_path: /data2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tddp_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdenoise_on: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdvs_clipping: 5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdvs_duration: 100000\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepoch_num: 100\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \texclude_class: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \textra_train_dataset: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlast_lif: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.001\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_sg_width: 5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_decay: 0.5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_init: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_reset: 10000\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_threshold: 0.5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmerge_polarities: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmy_seed: 42\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnet_print: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_workers: 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer_what: SGD\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tpin_memory: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tpre_trained: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tpre_trained_path: net_save/save_now_net_weights_{unique_name}.pth\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \trate_coding: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tscheduler_name: no\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsingle_step: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsurrogate: hard_sigmoid\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_conv_kernel_size: 3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_conv_padding: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_conv_stride: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_trace_const1: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_trace_const2: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \ttdBN_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \ttrace_on: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \twhich_data: DVS_GESTURE_TONIC\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.19.10 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.17.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/data2/bh_wandb/wandb/run-20250430_074515-uvpd117o</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/uvpd117o' target=\"_blank\">youthful-sweep-236</a></strong> to <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/6pj3lh8j' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/6pj3lh8j</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/6pj3lh8j' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/6pj3lh8j</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/uvpd117o' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/uvpd117o</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'single_step' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'my_seed' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'TIME' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BATCH' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'IMAGE_SIZE' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'which_data' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'data_path' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'rate_coding' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_init' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_decay' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_threshold' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_reset' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_sg_width' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_conv_kernel_size' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_conv_stride' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_conv_padding' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_trace_const1' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_trace_const2' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'pre_trained' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'convTrue_fcFalse' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'cfg' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'net_print' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'pre_trained_path' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'learning_rate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'epoch_num' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'tdBN_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BN_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'surrogate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BPTT_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'optimizer_what' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'scheduler_name' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'ddp_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'dvs_clipping' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'dvs_duration' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'DFA_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'trace_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'OTTT_input_trace_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'exclude_class' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'merge_polarities' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'denoise_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'extra_train_dataset' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'num_workers' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'chaching_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'pin_memory' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'UDA_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'alpha_uda' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'bias' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'last_lif' was locked by 'sweep' (ignored update).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "param {'devices': '0', 'single_step': True, 'unique_name': 'main', 'my_seed': 42, 'TIME': 10, 'BATCH': 16, 'IMAGE_SIZE': 128, 'which_data': 'DVS_GESTURE_TONIC', 'data_path': '/data2', 'rate_coding': False, 'lif_layer_v_init': 0, 'lif_layer_v_decay': 0.5, 'lif_layer_v_threshold': 0.5, 'lif_layer_v_reset': 10000, 'lif_layer_sg_width': 5, 'synapse_conv_kernel_size': 3, 'synapse_conv_stride': 1, 'synapse_conv_padding': 1, 'synapse_trace_const1': 1, 'synapse_trace_const2': 0, 'pre_trained': False, 'convTrue_fcFalse': False, 'cfg': ['M', 'M', 200, 200], 'net_print': True, 'pre_trained_path': 'net_save/save_now_net_weights_{unique_name}.pth', 'learning_rate': 0.001, 'epoch_num': 100, 'tdBN_on': False, 'BN_on': False, 'surrogate': 'hard_sigmoid', 'BPTT_on': False, 'optimizer_what': 'SGD', 'scheduler_name': 'no', 'ddp_on': False, 'dvs_clipping': 5, 'dvs_duration': 100000, 'DFA_on': True, 'trace_on': True, 'OTTT_input_trace_on': False, 'exclude_class': True, 'merge_polarities': False, 'denoise_on': True, 'extra_train_dataset': 0, 'num_workers': 2, 'chaching_on': True, 'pin_memory': True, 'UDA_on': False, 'alpha_uda': 1, 'bias': True, 'last_lif': False, 'current epoch': 0} \n",
      "\n",
      "dataset_hash = 63cc597115630ec173f3099200061e53\n",
      "cache path exists\n",
      "\n",
      "device ==> cuda\n",
      "\n",
      "DataParallel(\n",
      "  (module): REBORN_MY_SNN_FC(\n",
      "    (layers): REBORN_MY_Sequential(\n",
      "      (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (2): DimChanger_for_FC()\n",
      "      (3): SYNAPSE_FC(in_features=2048, out_features=200, TIME=10, bias=True, sstep=True)\n",
      "      (4): LIF_layer(v_init=0, v_decay=0.5, v_threshold=0.5, v_reset=10000, sg_width=5, surrogate=hard_sigmoid, BPTT_on=False, trace_const1=1, trace_const2=0, TIME=10, sstep=True, trace_on=True)\n",
      "      (5): Feedback_Receiver()\n",
      "      (6): SYNAPSE_FC(in_features=200, out_features=200, TIME=10, bias=True, sstep=True)\n",
      "      (7): LIF_layer(v_init=0, v_decay=0.5, v_threshold=0.5, v_reset=10000, sg_width=5, surrogate=hard_sigmoid, BPTT_on=False, trace_const1=1, trace_const2=0, TIME=10, sstep=True, trace_on=True)\n",
      "      (8): Feedback_Receiver()\n",
      "      (9): SYNAPSE_FC(in_features=200, out_features=10, TIME=10, bias=True, sstep=True)\n",
      "      (DFA_top): Top_Gradient()\n",
      "    )\n",
      "  )\n",
      ")\n",
      "\n",
      "========================================================\n",
      "Trainable parameters: 452,010\n",
      "========================================================\n",
      "\n",
      "epoch-0   lr=['0.0010000'], tr/val_loss:  2.296865/  2.236556, val:  10.00%, val_best:  10.00%, tr:   8.78%, tr_best:   8.78%\n",
      "[module.layers.5] weight_fb parameter count: 2,000\n",
      "[module.layers.8] weight_fb parameter count: 2,000\n",
      "epoch-1   lr=['0.0010000'], tr/val_loss:  1.874541/  1.662358, val:  55.42%, val_best:  55.42%, tr:  37.49%, tr_best:  37.49%\n",
      "epoch-2   lr=['0.0010000'], tr/val_loss:  1.463419/  1.557704, val:  55.83%, val_best:  55.83%, tr:  57.81%, tr_best:  57.81%\n",
      "epoch-3   lr=['0.0010000'], tr/val_loss:  1.298406/  1.499862, val:  57.92%, val_best:  57.92%, tr:  64.66%, tr_best:  64.66%\n",
      "epoch-4   lr=['0.0010000'], tr/val_loss:  1.228890/  1.452645, val:  60.42%, val_best:  60.42%, tr:  64.86%, tr_best:  64.86%\n",
      "epoch-5   lr=['0.0010000'], tr/val_loss:  1.168455/  1.399279, val:  64.17%, val_best:  64.17%, tr:  66.09%, tr_best:  66.09%\n",
      "epoch-6   lr=['0.0010000'], tr/val_loss:  1.110704/  1.384134, val:  62.92%, val_best:  64.17%, tr:  70.89%, tr_best:  70.89%\n",
      "epoch-7   lr=['0.0010000'], tr/val_loss:  1.077227/  1.347596, val:  62.08%, val_best:  64.17%, tr:  69.46%, tr_best:  70.89%\n",
      "epoch-8   lr=['0.0010000'], tr/val_loss:  1.042533/  1.349630, val:  67.50%, val_best:  67.50%, tr:  70.48%, tr_best:  70.89%\n",
      "epoch-9   lr=['0.0010000'], tr/val_loss:  1.008625/  1.363574, val:  64.17%, val_best:  67.50%, tr:  74.46%, tr_best:  74.46%\n",
      "epoch-10  lr=['0.0010000'], tr/val_loss:  0.985024/  1.389233, val:  62.50%, val_best:  67.50%, tr:  73.54%, tr_best:  74.46%\n",
      "epoch-11  lr=['0.0010000'], tr/val_loss:  0.940821/  1.317487, val:  65.42%, val_best:  67.50%, tr:  77.12%, tr_best:  77.12%\n",
      "epoch-12  lr=['0.0010000'], tr/val_loss:  0.917289/  1.325646, val:  65.42%, val_best:  67.50%, tr:  80.59%, tr_best:  80.59%\n",
      "epoch-13  lr=['0.0010000'], tr/val_loss:  0.890666/  1.329599, val:  65.42%, val_best:  67.50%, tr:  81.41%, tr_best:  81.41%\n",
      "epoch-14  lr=['0.0010000'], tr/val_loss:  0.835860/  1.462698, val:  60.83%, val_best:  67.50%, tr:  83.15%, tr_best:  83.15%\n",
      "epoch-15  lr=['0.0010000'], tr/val_loss:  0.815778/  1.346977, val:  67.50%, val_best:  67.50%, tr:  86.72%, tr_best:  86.72%\n",
      "epoch-16  lr=['0.0010000'], tr/val_loss:  0.805901/  1.310035, val:  71.25%, val_best:  71.25%, tr:  83.86%, tr_best:  86.72%\n",
      "epoch-17  lr=['0.0010000'], tr/val_loss:  0.743655/  1.303868, val:  71.67%, val_best:  71.67%, tr:  90.30%, tr_best:  90.30%\n",
      "epoch-18  lr=['0.0010000'], tr/val_loss:  0.733230/  1.371329, val:  69.17%, val_best:  71.67%, tr:  89.68%, tr_best:  90.30%\n",
      "epoch-19  lr=['0.0010000'], tr/val_loss:  0.705532/  1.340017, val:  74.17%, val_best:  74.17%, tr:  88.15%, tr_best:  90.30%\n",
      "epoch-20  lr=['0.0010000'], tr/val_loss:  0.678280/  1.342089, val:  69.17%, val_best:  74.17%, tr:  92.34%, tr_best:  92.34%\n",
      "epoch-21  lr=['0.0010000'], tr/val_loss:  0.656517/  1.354603, val:  72.92%, val_best:  74.17%, tr:  92.75%, tr_best:  92.75%\n",
      "epoch-22  lr=['0.0010000'], tr/val_loss:  0.644810/  1.343390, val:  75.42%, val_best:  75.42%, tr:  93.67%, tr_best:  93.67%\n",
      "epoch-23  lr=['0.0010000'], tr/val_loss:  0.618588/  1.374325, val:  76.25%, val_best:  76.25%, tr:  93.77%, tr_best:  93.77%\n",
      "epoch-24  lr=['0.0010000'], tr/val_loss:  0.580944/  1.382521, val:  73.75%, val_best:  76.25%, tr:  95.20%, tr_best:  95.20%\n",
      "epoch-25  lr=['0.0010000'], tr/val_loss:  0.572506/  1.368191, val:  76.25%, val_best:  76.25%, tr:  94.99%, tr_best:  95.20%\n",
      "epoch-26  lr=['0.0010000'], tr/val_loss:  0.563482/  1.383180, val:  78.75%, val_best:  78.75%, tr:  94.48%, tr_best:  95.20%\n",
      "epoch-27  lr=['0.0010000'], tr/val_loss:  0.533099/  1.418693, val:  72.92%, val_best:  78.75%, tr:  95.81%, tr_best:  95.81%\n",
      "epoch-28  lr=['0.0010000'], tr/val_loss:  0.516726/  1.390352, val:  79.17%, val_best:  79.17%, tr:  97.34%, tr_best:  97.34%\n",
      "epoch-29  lr=['0.0010000'], tr/val_loss:  0.511037/  1.448192, val:  73.75%, val_best:  79.17%, tr:  96.83%, tr_best:  97.34%\n",
      "epoch-30  lr=['0.0010000'], tr/val_loss:  0.482567/  1.432166, val:  76.25%, val_best:  79.17%, tr:  97.24%, tr_best:  97.34%\n",
      "epoch-31  lr=['0.0010000'], tr/val_loss:  0.477196/  1.463871, val:  75.83%, val_best:  79.17%, tr:  96.12%, tr_best:  97.34%\n",
      "epoch-32  lr=['0.0010000'], tr/val_loss:  0.468192/  1.480660, val:  76.25%, val_best:  79.17%, tr:  97.34%, tr_best:  97.34%\n",
      "epoch-33  lr=['0.0010000'], tr/val_loss:  0.459061/  1.475697, val:  76.67%, val_best:  79.17%, tr:  97.75%, tr_best:  97.75%\n",
      "epoch-34  lr=['0.0010000'], tr/val_loss:  0.443432/  1.507985, val:  75.00%, val_best:  79.17%, tr:  97.65%, tr_best:  97.75%\n",
      "epoch-35  lr=['0.0010000'], tr/val_loss:  0.431417/  1.524130, val:  75.83%, val_best:  79.17%, tr:  97.85%, tr_best:  97.85%\n",
      "epoch-36  lr=['0.0010000'], tr/val_loss:  0.399434/  1.497355, val:  77.50%, val_best:  79.17%, tr:  98.47%, tr_best:  98.47%\n",
      "epoch-37  lr=['0.0010000'], tr/val_loss:  0.403779/  1.553091, val:  77.92%, val_best:  79.17%, tr:  98.77%, tr_best:  98.77%\n",
      "epoch-38  lr=['0.0010000'], tr/val_loss:  0.388915/  1.541225, val:  77.50%, val_best:  79.17%, tr:  98.16%, tr_best:  98.77%\n",
      "epoch-39  lr=['0.0010000'], tr/val_loss:  0.380584/  1.546930, val:  79.17%, val_best:  79.17%, tr:  98.37%, tr_best:  98.77%\n",
      "epoch-40  lr=['0.0010000'], tr/val_loss:  0.373297/  1.596007, val:  77.08%, val_best:  79.17%, tr:  98.47%, tr_best:  98.77%\n",
      "epoch-41  lr=['0.0010000'], tr/val_loss:  0.359962/  1.589684, val:  76.67%, val_best:  79.17%, tr:  98.98%, tr_best:  98.98%\n",
      "epoch-42  lr=['0.0010000'], tr/val_loss:  0.354921/  1.564190, val:  81.25%, val_best:  81.25%, tr:  98.88%, tr_best:  98.98%\n",
      "epoch-43  lr=['0.0010000'], tr/val_loss:  0.330931/  1.596582, val:  78.33%, val_best:  81.25%, tr:  99.28%, tr_best:  99.28%\n",
      "epoch-44  lr=['0.0010000'], tr/val_loss:  0.327936/  1.584628, val:  79.58%, val_best:  81.25%, tr:  99.08%, tr_best:  99.28%\n",
      "epoch-45  lr=['0.0010000'], tr/val_loss:  0.312913/  1.622727, val:  79.58%, val_best:  81.25%, tr:  99.39%, tr_best:  99.39%\n",
      "epoch-46  lr=['0.0010000'], tr/val_loss:  0.306681/  1.623375, val:  80.42%, val_best:  81.25%, tr:  99.49%, tr_best:  99.49%\n",
      "epoch-47  lr=['0.0010000'], tr/val_loss:  0.296039/  1.657290, val:  79.58%, val_best:  81.25%, tr:  99.90%, tr_best:  99.90%\n",
      "epoch-48  lr=['0.0010000'], tr/val_loss:  0.293386/  1.633437, val:  81.67%, val_best:  81.67%, tr:  99.69%, tr_best:  99.90%\n",
      "epoch-49  lr=['0.0010000'], tr/val_loss:  0.286338/  1.666612, val:  81.67%, val_best:  81.67%, tr:  99.59%, tr_best:  99.90%\n",
      "epoch-50  lr=['0.0010000'], tr/val_loss:  0.279020/  1.712053, val:  82.50%, val_best:  82.50%, tr:  99.59%, tr_best:  99.90%\n",
      "epoch-51  lr=['0.0010000'], tr/val_loss:  0.268550/  1.718600, val:  79.58%, val_best:  82.50%, tr:  99.69%, tr_best:  99.90%\n",
      "epoch-52  lr=['0.0010000'], tr/val_loss:  0.261994/  1.721570, val:  80.00%, val_best:  82.50%, tr:  99.69%, tr_best:  99.90%\n",
      "epoch-53  lr=['0.0010000'], tr/val_loss:  0.260163/  1.752943, val:  80.83%, val_best:  82.50%, tr:  99.69%, tr_best:  99.90%\n",
      "epoch-54  lr=['0.0010000'], tr/val_loss:  0.255940/  1.751336, val:  81.67%, val_best:  82.50%, tr:  99.80%, tr_best:  99.90%\n",
      "epoch-55  lr=['0.0010000'], tr/val_loss:  0.238653/  1.788869, val:  80.42%, val_best:  82.50%, tr:  99.90%, tr_best:  99.90%\n",
      "epoch-56  lr=['0.0010000'], tr/val_loss:  0.228817/  1.805831, val:  79.17%, val_best:  82.50%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-57  lr=['0.0010000'], tr/val_loss:  0.237788/  1.800289, val:  80.42%, val_best:  82.50%, tr:  99.80%, tr_best: 100.00%\n",
      "epoch-58  lr=['0.0010000'], tr/val_loss:  0.220879/  1.827814, val:  80.83%, val_best:  82.50%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-59  lr=['0.0010000'], tr/val_loss:  0.222246/  1.834605, val:  81.67%, val_best:  82.50%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-60  lr=['0.0010000'], tr/val_loss:  0.212448/  1.829992, val:  81.67%, val_best:  82.50%, tr:  99.80%, tr_best: 100.00%\n",
      "epoch-61  lr=['0.0010000'], tr/val_loss:  0.213349/  1.851746, val:  82.50%, val_best:  82.50%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-62  lr=['0.0010000'], tr/val_loss:  0.205461/  1.850290, val:  80.42%, val_best:  82.50%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-63  lr=['0.0010000'], tr/val_loss:  0.200869/  1.871160, val:  82.50%, val_best:  82.50%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-64  lr=['0.0010000'], tr/val_loss:  0.194090/  1.894805, val:  81.25%, val_best:  82.50%, tr:  99.80%, tr_best: 100.00%\n",
      "epoch-65  lr=['0.0010000'], tr/val_loss:  0.185558/  1.888241, val:  82.50%, val_best:  82.50%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-66  lr=['0.0010000'], tr/val_loss:  0.185427/  1.910474, val:  81.67%, val_best:  82.50%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-67  lr=['0.0010000'], tr/val_loss:  0.182613/  1.940005, val:  81.67%, val_best:  82.50%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-68  lr=['0.0010000'], tr/val_loss:  0.180389/  1.928059, val:  81.67%, val_best:  82.50%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-69  lr=['0.0010000'], tr/val_loss:  0.168311/  1.959444, val:  81.25%, val_best:  82.50%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-70  lr=['0.0010000'], tr/val_loss:  0.166046/  1.990721, val:  81.67%, val_best:  82.50%, tr:  99.90%, tr_best: 100.00%\n",
      "epoch-71  lr=['0.0010000'], tr/val_loss:  0.171124/  1.978571, val:  81.25%, val_best:  82.50%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-72  lr=['0.0010000'], tr/val_loss:  0.159309/  2.023595, val:  81.25%, val_best:  82.50%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-73  lr=['0.0010000'], tr/val_loss:  0.159395/  2.009304, val:  81.25%, val_best:  82.50%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-74  lr=['0.0010000'], tr/val_loss:  0.155222/  2.022102, val:  81.25%, val_best:  82.50%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-75  lr=['0.0010000'], tr/val_loss:  0.151204/  2.046901, val:  79.17%, val_best:  82.50%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-76  lr=['0.0010000'], tr/val_loss:  0.146269/  2.054862, val:  79.58%, val_best:  82.50%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-77  lr=['0.0010000'], tr/val_loss:  0.146598/  2.070654, val:  81.67%, val_best:  82.50%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-78  lr=['0.0010000'], tr/val_loss:  0.142158/  2.091094, val:  81.25%, val_best:  82.50%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-79  lr=['0.0010000'], tr/val_loss:  0.144248/  2.086977, val:  81.25%, val_best:  82.50%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-80  lr=['0.0010000'], tr/val_loss:  0.137779/  2.097517, val:  81.67%, val_best:  82.50%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-81  lr=['0.0010000'], tr/val_loss:  0.134391/  2.095987, val:  82.08%, val_best:  82.50%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-82  lr=['0.0010000'], tr/val_loss:  0.132981/  2.125561, val:  81.25%, val_best:  82.50%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-83  lr=['0.0010000'], tr/val_loss:  0.132305/  2.169937, val:  79.17%, val_best:  82.50%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-84  lr=['0.0010000'], tr/val_loss:  0.128851/  2.140849, val:  82.08%, val_best:  82.50%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-85  lr=['0.0010000'], tr/val_loss:  0.134262/  2.195688, val:  79.17%, val_best:  82.50%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-86  lr=['0.0010000'], tr/val_loss:  0.126616/  2.170353, val:  81.25%, val_best:  82.50%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-87  lr=['0.0010000'], tr/val_loss:  0.122086/  2.202959, val:  81.25%, val_best:  82.50%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-88  lr=['0.0010000'], tr/val_loss:  0.116344/  2.198207, val:  81.67%, val_best:  82.50%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-89  lr=['0.0010000'], tr/val_loss:  0.116480/  2.199645, val:  82.08%, val_best:  82.50%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-90  lr=['0.0010000'], tr/val_loss:  0.112048/  2.202270, val:  80.83%, val_best:  82.50%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-91  lr=['0.0010000'], tr/val_loss:  0.108442/  2.226799, val:  80.83%, val_best:  82.50%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-92  lr=['0.0010000'], tr/val_loss:  0.107860/  2.257619, val:  80.00%, val_best:  82.50%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-93  lr=['0.0010000'], tr/val_loss:  0.106012/  2.221844, val:  81.67%, val_best:  82.50%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-94  lr=['0.0010000'], tr/val_loss:  0.104685/  2.247047, val:  82.92%, val_best:  82.92%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-95  lr=['0.0010000'], tr/val_loss:  0.100731/  2.260942, val:  81.67%, val_best:  82.92%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-96  lr=['0.0010000'], tr/val_loss:  0.096040/  2.310864, val:  81.67%, val_best:  82.92%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-97  lr=['0.0010000'], tr/val_loss:  0.099364/  2.294726, val:  81.67%, val_best:  82.92%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-98  lr=['0.0010000'], tr/val_loss:  0.095172/  2.303420, val:  82.08%, val_best:  82.92%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-99  lr=['0.0010000'], tr/val_loss:  0.100411/  2.311126, val:  80.42%, val_best:  82.92%, tr: 100.00%, tr_best: 100.00%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "87c5dba01a354686b2d7edf43f0f5b91",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.006 MB of 0.006 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>iter_acc</td><td>▁▇▄▅▆▅▇▅▇███▇▇██████████████████████████</td></tr><tr><td>summary_val_acc</td><td>▁▅▆▆▆▆▆▇▇▇▇█▇▇▇█████████████████████████</td></tr><tr><td>tr_acc</td><td>▁▅▅▆▆▇▇▇▇▇██████████████████████████████</td></tr><tr><td>tr_epoch_loss</td><td>█▅▅▄▄▄▃▃▃▃▃▂▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_acc_best</td><td>▁▅▆▆▇▇▇▇▇▇▇█████████████████████████████</td></tr><tr><td>val_acc_now</td><td>▁▅▆▆▆▆▆▇▇▇▇█▇▇▇█████████████████████████</td></tr><tr><td>val_loss</td><td>█▃▂▁▁▁▂▁▁▁▂▂▂▂▃▃▃▃▃▃▄▄▄▅▅▅▅▅▆▆▆▆▇▇▇▇▇███</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>99</td></tr><tr><td>iter_acc</td><td>1.0</td></tr><tr><td>tr_acc</td><td>1.0</td></tr><tr><td>tr_epoch_loss</td><td>0.10041</td></tr><tr><td>val_acc_best</td><td>0.82917</td></tr><tr><td>val_acc_now</td><td>0.80417</td></tr><tr><td>val_loss</td><td>2.31113</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">youthful-sweep-236</strong> at: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/uvpd117o' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/uvpd117o</a><br/> View project at: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>/data2/bh_wandb/wandb/run-20250430_074515-uvpd117o/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require(\"core\")`! See https://wandb.me/wandb-core for more information."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Sweep Agent: Waiting for job.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Job received.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: p430oqzs with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBATCH: 16\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBN_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBPTT_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tDFA_on: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tIMAGE_SIZE: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tOTTT_input_trace_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tTIME: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tUDA_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \talpha_uda: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbias: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcfg: ['M', 'M', 200, 200]\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tchaching_on: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tconvTrue_fcFalse: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdata_path: /data2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tddp_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdenoise_on: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdvs_clipping: 5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdvs_duration: 100000\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepoch_num: 100\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \texclude_class: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \textra_train_dataset: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlast_lif: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_sg_width: 3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_decay: 0.5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_init: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_reset: 10000\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_threshold: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmerge_polarities: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmy_seed: 42\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnet_print: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_workers: 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer_what: SGD\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tpin_memory: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tpre_trained: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tpre_trained_path: net_save/save_now_net_weights_{unique_name}.pth\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \trate_coding: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tscheduler_name: no\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsingle_step: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsurrogate: hard_sigmoid\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_conv_kernel_size: 3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_conv_padding: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_conv_stride: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_trace_const1: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_trace_const2: 0.5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \ttdBN_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \ttrace_on: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \twhich_data: DVS_GESTURE_TONIC\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.19.10 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.17.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/data2/bh_wandb/wandb/run-20250430_075159-p430oqzs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/p430oqzs' target=\"_blank\">devoted-sweep-238</a></strong> to <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/6pj3lh8j' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/6pj3lh8j</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/6pj3lh8j' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/6pj3lh8j</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/p430oqzs' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/p430oqzs</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'single_step' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'my_seed' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'TIME' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BATCH' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'IMAGE_SIZE' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'which_data' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'data_path' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'rate_coding' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_init' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_decay' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_threshold' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_reset' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_sg_width' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_conv_kernel_size' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_conv_stride' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_conv_padding' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_trace_const1' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_trace_const2' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'pre_trained' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'convTrue_fcFalse' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'cfg' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'net_print' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'pre_trained_path' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'learning_rate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'epoch_num' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'tdBN_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BN_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'surrogate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BPTT_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'optimizer_what' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'scheduler_name' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'ddp_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'dvs_clipping' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'dvs_duration' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'DFA_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'trace_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'OTTT_input_trace_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'exclude_class' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'merge_polarities' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'denoise_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'extra_train_dataset' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'num_workers' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'chaching_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'pin_memory' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'UDA_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'alpha_uda' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'bias' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'last_lif' was locked by 'sweep' (ignored update).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "param {'devices': '0', 'single_step': True, 'unique_name': 'main', 'my_seed': 42, 'TIME': 10, 'BATCH': 16, 'IMAGE_SIZE': 128, 'which_data': 'DVS_GESTURE_TONIC', 'data_path': '/data2', 'rate_coding': False, 'lif_layer_v_init': 0, 'lif_layer_v_decay': 0.5, 'lif_layer_v_threshold': 1, 'lif_layer_v_reset': 10000, 'lif_layer_sg_width': 3, 'synapse_conv_kernel_size': 3, 'synapse_conv_stride': 1, 'synapse_conv_padding': 1, 'synapse_trace_const1': 1, 'synapse_trace_const2': 0.5, 'pre_trained': False, 'convTrue_fcFalse': False, 'cfg': ['M', 'M', 200, 200], 'net_print': True, 'pre_trained_path': 'net_save/save_now_net_weights_{unique_name}.pth', 'learning_rate': 0.1, 'epoch_num': 100, 'tdBN_on': False, 'BN_on': False, 'surrogate': 'hard_sigmoid', 'BPTT_on': False, 'optimizer_what': 'SGD', 'scheduler_name': 'no', 'ddp_on': False, 'dvs_clipping': 5, 'dvs_duration': 100000, 'DFA_on': True, 'trace_on': True, 'OTTT_input_trace_on': False, 'exclude_class': True, 'merge_polarities': False, 'denoise_on': True, 'extra_train_dataset': 0, 'num_workers': 2, 'chaching_on': True, 'pin_memory': True, 'UDA_on': False, 'alpha_uda': 1, 'bias': True, 'last_lif': False, 'current epoch': 0} \n",
      "\n",
      "dataset_hash = 63cc597115630ec173f3099200061e53\n",
      "cache path exists\n",
      "\n",
      "device ==> cuda\n",
      "\n",
      "DataParallel(\n",
      "  (module): REBORN_MY_SNN_FC(\n",
      "    (layers): REBORN_MY_Sequential(\n",
      "      (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (2): DimChanger_for_FC()\n",
      "      (3): SYNAPSE_FC(in_features=2048, out_features=200, TIME=10, bias=True, sstep=True)\n",
      "      (4): LIF_layer(v_init=0, v_decay=0.5, v_threshold=1, v_reset=10000, sg_width=3, surrogate=hard_sigmoid, BPTT_on=False, trace_const1=1, trace_const2=0.5, TIME=10, sstep=True, trace_on=True)\n",
      "      (5): Feedback_Receiver()\n",
      "      (6): SYNAPSE_FC(in_features=200, out_features=200, TIME=10, bias=True, sstep=True)\n",
      "      (7): LIF_layer(v_init=0, v_decay=0.5, v_threshold=1, v_reset=10000, sg_width=3, surrogate=hard_sigmoid, BPTT_on=False, trace_const1=1, trace_const2=0.5, TIME=10, sstep=True, trace_on=True)\n",
      "      (8): Feedback_Receiver()\n",
      "      (9): SYNAPSE_FC(in_features=200, out_features=10, TIME=10, bias=True, sstep=True)\n",
      "      (DFA_top): Top_Gradient()\n",
      "    )\n",
      "  )\n",
      ")\n",
      "\n",
      "========================================================\n",
      "Trainable parameters: 452,010\n",
      "========================================================\n",
      "\n",
      "epoch-0   lr=['0.1000000'], tr/val_loss: 10.482671/ 20.722488, val:  40.83%, val_best:  40.83%, tr:  28.50%, tr_best:  28.50%\n",
      "[module.layers.5] weight_fb parameter count: 2,000\n",
      "[module.layers.8] weight_fb parameter count: 2,000\n",
      "epoch-1   lr=['0.1000000'], tr/val_loss: 17.052391/ 12.426332, val:  50.83%, val_best:  50.83%, tr:  42.29%, tr_best:  42.29%\n",
      "epoch-2   lr=['0.1000000'], tr/val_loss: 17.730124/ 28.754547, val:  41.67%, val_best:  50.83%, tr:  50.77%, tr_best:  50.77%\n",
      "epoch-3   lr=['0.1000000'], tr/val_loss: 14.938411/ 15.441981, val:  50.00%, val_best:  50.83%, tr:  57.20%, tr_best:  57.20%\n",
      "epoch-4   lr=['0.1000000'], tr/val_loss: 13.042999/ 18.581890, val:  49.58%, val_best:  50.83%, tr:  60.37%, tr_best:  60.37%\n",
      "epoch-5   lr=['0.1000000'], tr/val_loss: 16.195833/ 17.996790, val:  57.50%, val_best:  57.50%, tr:  61.29%, tr_best:  61.29%\n",
      "epoch-6   lr=['0.1000000'], tr/val_loss: 12.593246/ 20.864027, val:  48.75%, val_best:  57.50%, tr:  65.47%, tr_best:  65.47%\n",
      "epoch-7   lr=['0.1000000'], tr/val_loss: 11.249013/ 29.673971, val:  40.42%, val_best:  57.50%, tr:  65.88%, tr_best:  65.88%\n",
      "epoch-8   lr=['0.1000000'], tr/val_loss: 12.997124/ 16.813473, val:  60.42%, val_best:  60.42%, tr:  65.37%, tr_best:  65.88%\n",
      "epoch-9   lr=['0.1000000'], tr/val_loss: 15.323451/ 25.369417, val:  53.33%, val_best:  60.42%, tr:  68.85%, tr_best:  68.85%\n",
      "epoch-10  lr=['0.1000000'], tr/val_loss: 12.838545/ 18.678478, val:  60.42%, val_best:  60.42%, tr:  68.44%, tr_best:  68.85%\n",
      "epoch-11  lr=['0.1000000'], tr/val_loss: 14.189131/ 20.096786, val:  61.67%, val_best:  61.67%, tr:  74.16%, tr_best:  74.16%\n",
      "epoch-12  lr=['0.1000000'], tr/val_loss: 11.700196/ 23.095036, val:  61.67%, val_best:  61.67%, tr:  76.20%, tr_best:  76.20%\n",
      "epoch-13  lr=['0.1000000'], tr/val_loss:  9.563033/ 22.004423, val:  65.42%, val_best:  65.42%, tr:  83.66%, tr_best:  83.66%\n",
      "epoch-14  lr=['0.1000000'], tr/val_loss:  9.300242/ 23.776270, val:  70.00%, val_best:  70.00%, tr:  84.37%, tr_best:  84.37%\n",
      "epoch-15  lr=['0.1000000'], tr/val_loss:  7.355525/ 30.327692, val:  60.83%, val_best:  70.00%, tr:  88.76%, tr_best:  88.76%\n",
      "epoch-16  lr=['0.1000000'], tr/val_loss:  6.699559/ 24.774214, val:  69.17%, val_best:  70.00%, tr:  91.22%, tr_best:  91.22%\n",
      "epoch-17  lr=['0.1000000'], tr/val_loss:  6.458284/ 26.324438, val:  71.25%, val_best:  71.25%, tr:  92.44%, tr_best:  92.44%\n",
      "epoch-18  lr=['0.1000000'], tr/val_loss:  4.712522/ 26.661655, val:  70.83%, val_best:  71.25%, tr:  96.12%, tr_best:  96.12%\n",
      "epoch-19  lr=['0.1000000'], tr/val_loss:  4.068950/ 25.646334, val:  74.17%, val_best:  74.17%, tr:  97.75%, tr_best:  97.75%\n",
      "epoch-20  lr=['0.1000000'], tr/val_loss:  3.649416/ 25.580318, val:  73.75%, val_best:  74.17%, tr:  97.34%, tr_best:  97.75%\n",
      "epoch-21  lr=['0.1000000'], tr/val_loss:  4.467634/ 33.139961, val:  69.58%, val_best:  74.17%, tr:  97.96%, tr_best:  97.96%\n",
      "epoch-22  lr=['0.1000000'], tr/val_loss:  3.559743/ 29.811476, val:  74.58%, val_best:  74.58%, tr:  98.57%, tr_best:  98.57%\n",
      "epoch-23  lr=['0.1000000'], tr/val_loss:  3.433375/ 32.730820, val:  73.75%, val_best:  74.58%, tr:  97.96%, tr_best:  98.57%\n",
      "epoch-24  lr=['0.1000000'], tr/val_loss:  2.641736/ 30.859434, val:  78.33%, val_best:  78.33%, tr:  99.49%, tr_best:  99.49%\n",
      "epoch-25  lr=['0.1000000'], tr/val_loss:  2.544581/ 33.332127, val:  76.67%, val_best:  78.33%, tr:  99.39%, tr_best:  99.49%\n",
      "epoch-26  lr=['0.1000000'], tr/val_loss:  2.162471/ 34.983734, val:  76.67%, val_best:  78.33%, tr:  99.39%, tr_best:  99.49%\n",
      "epoch-27  lr=['0.1000000'], tr/val_loss:  2.143199/ 36.225533, val:  73.33%, val_best:  78.33%, tr:  99.28%, tr_best:  99.49%\n",
      "epoch-28  lr=['0.1000000'], tr/val_loss:  1.871462/ 31.893780, val:  78.75%, val_best:  78.75%, tr:  99.69%, tr_best:  99.69%\n",
      "epoch-29  lr=['0.1000000'], tr/val_loss:  1.944735/ 35.648483, val:  77.50%, val_best:  78.75%, tr:  99.59%, tr_best:  99.69%\n",
      "epoch-30  lr=['0.1000000'], tr/val_loss:  1.847965/ 36.094711, val:  78.75%, val_best:  78.75%, tr:  99.59%, tr_best:  99.69%\n",
      "epoch-31  lr=['0.1000000'], tr/val_loss:  1.542583/ 34.987289, val:  77.92%, val_best:  78.75%, tr:  99.80%, tr_best:  99.80%\n",
      "epoch-32  lr=['0.1000000'], tr/val_loss:  1.458376/ 36.257046, val:  77.08%, val_best:  78.75%, tr:  99.80%, tr_best:  99.80%\n",
      "epoch-33  lr=['0.1000000'], tr/val_loss:  1.223360/ 36.171360, val:  80.83%, val_best:  80.83%, tr:  99.80%, tr_best:  99.80%\n",
      "epoch-34  lr=['0.1000000'], tr/val_loss:  1.320418/ 40.773319, val:  75.83%, val_best:  80.83%, tr:  99.49%, tr_best:  99.80%\n",
      "epoch-35  lr=['0.1000000'], tr/val_loss:  1.199302/ 38.951138, val:  79.58%, val_best:  80.83%, tr:  99.90%, tr_best:  99.90%\n",
      "epoch-36  lr=['0.1000000'], tr/val_loss:  0.981602/ 38.961960, val:  78.75%, val_best:  80.83%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-37  lr=['0.1000000'], tr/val_loss:  0.923887/ 39.971455, val:  78.75%, val_best:  80.83%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-38  lr=['0.1000000'], tr/val_loss:  1.004703/ 37.803352, val:  80.42%, val_best:  80.83%, tr:  99.90%, tr_best: 100.00%\n",
      "epoch-39  lr=['0.1000000'], tr/val_loss:  0.965686/ 39.641415, val:  78.75%, val_best:  80.83%, tr:  99.80%, tr_best: 100.00%\n",
      "epoch-40  lr=['0.1000000'], tr/val_loss:  0.852677/ 38.809464, val:  77.92%, val_best:  80.83%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-41  lr=['0.1000000'], tr/val_loss:  0.792763/ 41.048210, val:  79.58%, val_best:  80.83%, tr:  99.90%, tr_best: 100.00%\n",
      "epoch-42  lr=['0.1000000'], tr/val_loss:  0.804673/ 40.360291, val:  78.33%, val_best:  80.83%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-43  lr=['0.1000000'], tr/val_loss:  0.486866/ 41.405781, val:  79.17%, val_best:  80.83%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-44  lr=['0.1000000'], tr/val_loss:  0.642935/ 42.149250, val:  79.17%, val_best:  80.83%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-45  lr=['0.1000000'], tr/val_loss:  0.696450/ 41.033752, val:  80.00%, val_best:  80.83%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-46  lr=['0.1000000'], tr/val_loss:  0.535563/ 41.215153, val:  76.67%, val_best:  80.83%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-47  lr=['0.1000000'], tr/val_loss:  0.506244/ 41.672028, val:  80.42%, val_best:  80.83%, tr:  99.90%, tr_best: 100.00%\n",
      "epoch-48  lr=['0.1000000'], tr/val_loss:  0.551348/ 41.593941, val:  78.33%, val_best:  80.83%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-49  lr=['0.1000000'], tr/val_loss:  0.587848/ 42.943047, val:  77.08%, val_best:  80.83%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-50  lr=['0.1000000'], tr/val_loss:  0.548882/ 44.076881, val:  76.67%, val_best:  80.83%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-51  lr=['0.1000000'], tr/val_loss:  0.672828/ 43.207775, val:  77.08%, val_best:  80.83%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-52  lr=['0.1000000'], tr/val_loss:  0.493641/ 44.042721, val:  76.67%, val_best:  80.83%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-53  lr=['0.1000000'], tr/val_loss:  0.503169/ 42.627274, val:  78.75%, val_best:  80.83%, tr:  99.90%, tr_best: 100.00%\n",
      "epoch-54  lr=['0.1000000'], tr/val_loss:  0.336374/ 44.963215, val:  76.25%, val_best:  80.83%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-55  lr=['0.1000000'], tr/val_loss:  0.439215/ 44.495399, val:  78.33%, val_best:  80.83%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-56  lr=['0.1000000'], tr/val_loss:  0.419358/ 45.407375, val:  76.25%, val_best:  80.83%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-57  lr=['0.1000000'], tr/val_loss:  0.335500/ 46.447258, val:  78.75%, val_best:  80.83%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-58  lr=['0.1000000'], tr/val_loss:  0.433267/ 46.590878, val:  74.58%, val_best:  80.83%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-59  lr=['0.1000000'], tr/val_loss:  0.343349/ 46.679443, val:  79.17%, val_best:  80.83%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-60  lr=['0.1000000'], tr/val_loss:  0.353773/ 46.086109, val:  80.83%, val_best:  80.83%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-61  lr=['0.1000000'], tr/val_loss:  0.530749/ 45.555191, val:  78.75%, val_best:  80.83%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-62  lr=['0.1000000'], tr/val_loss:  0.489530/ 48.323898, val:  77.50%, val_best:  80.83%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-63  lr=['0.1000000'], tr/val_loss:  0.525286/ 48.808628, val:  78.75%, val_best:  80.83%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-64  lr=['0.1000000'], tr/val_loss:  0.413300/ 48.821308, val:  76.25%, val_best:  80.83%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-65  lr=['0.1000000'], tr/val_loss:  0.338945/ 47.090370, val:  77.92%, val_best:  80.83%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-66  lr=['0.1000000'], tr/val_loss:  0.507257/ 47.196369, val:  79.58%, val_best:  80.83%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-67  lr=['0.1000000'], tr/val_loss:  0.418566/ 45.859859, val:  81.67%, val_best:  81.67%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-68  lr=['0.1000000'], tr/val_loss:  0.346139/ 48.168186, val:  75.83%, val_best:  81.67%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-69  lr=['0.1000000'], tr/val_loss:  0.325192/ 47.757339, val:  78.33%, val_best:  81.67%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-70  lr=['0.1000000'], tr/val_loss:  0.348390/ 48.629799, val:  77.92%, val_best:  81.67%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-71  lr=['0.1000000'], tr/val_loss:  0.262048/ 49.721897, val:  77.92%, val_best:  81.67%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-72  lr=['0.1000000'], tr/val_loss:  0.220061/ 48.497120, val:  77.92%, val_best:  81.67%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-73  lr=['0.1000000'], tr/val_loss:  0.223897/ 49.760162, val:  75.83%, val_best:  81.67%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-74  lr=['0.1000000'], tr/val_loss:  0.201082/ 48.833626, val:  75.42%, val_best:  81.67%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-75  lr=['0.1000000'], tr/val_loss:  0.208716/ 50.125828, val:  76.25%, val_best:  81.67%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-76  lr=['0.1000000'], tr/val_loss:  0.234476/ 49.199734, val:  78.75%, val_best:  81.67%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-77  lr=['0.1000000'], tr/val_loss:  0.153425/ 49.403927, val:  78.75%, val_best:  81.67%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-78  lr=['0.1000000'], tr/val_loss:  0.267174/ 48.980938, val:  77.92%, val_best:  81.67%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-79  lr=['0.1000000'], tr/val_loss:  0.200461/ 48.692589, val:  79.17%, val_best:  81.67%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-80  lr=['0.1000000'], tr/val_loss:  0.189364/ 48.268856, val:  78.75%, val_best:  81.67%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-81  lr=['0.1000000'], tr/val_loss:  0.089387/ 48.817993, val:  77.92%, val_best:  81.67%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-82  lr=['0.1000000'], tr/val_loss:  0.128072/ 47.691563, val:  78.75%, val_best:  81.67%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-83  lr=['0.1000000'], tr/val_loss:  0.155781/ 47.353931, val:  77.50%, val_best:  81.67%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-84  lr=['0.1000000'], tr/val_loss:  0.134249/ 49.161259, val:  77.92%, val_best:  81.67%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-85  lr=['0.1000000'], tr/val_loss:  0.174486/ 49.951302, val:  78.75%, val_best:  81.67%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-86  lr=['0.1000000'], tr/val_loss:  0.203401/ 48.554867, val:  79.58%, val_best:  81.67%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-87  lr=['0.1000000'], tr/val_loss:  0.304898/ 49.114361, val:  78.75%, val_best:  81.67%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-88  lr=['0.1000000'], tr/val_loss:  0.283314/ 51.093136, val:  77.08%, val_best:  81.67%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-89  lr=['0.1000000'], tr/val_loss:  0.119113/ 50.607681, val:  79.58%, val_best:  81.67%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-90  lr=['0.1000000'], tr/val_loss:  0.193977/ 50.320213, val:  80.00%, val_best:  81.67%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-91  lr=['0.1000000'], tr/val_loss:  0.152066/ 49.801922, val:  77.50%, val_best:  81.67%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-92  lr=['0.1000000'], tr/val_loss:  0.157014/ 50.145172, val:  77.92%, val_best:  81.67%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-93  lr=['0.1000000'], tr/val_loss:  0.085596/ 49.457394, val:  77.50%, val_best:  81.67%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-94  lr=['0.1000000'], tr/val_loss:  0.141924/ 49.094891, val:  77.92%, val_best:  81.67%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-95  lr=['0.1000000'], tr/val_loss:  0.127686/ 49.194782, val:  77.08%, val_best:  81.67%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-96  lr=['0.1000000'], tr/val_loss:  0.129313/ 50.913265, val:  75.42%, val_best:  81.67%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-97  lr=['0.1000000'], tr/val_loss:  0.115690/ 50.601177, val:  80.83%, val_best:  81.67%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-98  lr=['0.1000000'], tr/val_loss:  0.130709/ 50.562447, val:  78.75%, val_best:  81.67%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-99  lr=['0.1000000'], tr/val_loss:  0.124923/ 49.340393, val:  77.92%, val_best:  81.67%, tr: 100.00%, tr_best: 100.00%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aad81efe90af4ac4918fb28b32303044",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.006 MB of 0.006 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>iter_acc</td><td>▁▅▅▅▅▆█▇▇███████████████████████████████</td></tr><tr><td>summary_val_acc</td><td>▁▁▃▁▃▅▆▆▇▆▇▇▇▇███▇██▇▇▇███▇█▇▇▇███▇██▇▇█</td></tr><tr><td>tr_acc</td><td>▁▃▄▅▅▆▆▇████████████████████████████████</td></tr><tr><td>tr_epoch_loss</td><td>▅█▆▅▇▆▅▄▃▃▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_acc_best</td><td>▁▃▃▄▄▅▆▆▇▇▇▇████████████████████████████</td></tr><tr><td>val_acc_now</td><td>▁▁▃▁▃▅▆▆▇▆▇▇▇▇███▇██▇▇▇███▇█▇▇▇███▇██▇▇█</td></tr><tr><td>val_loss</td><td>▁▃▁▃▂▂▂▃▃▄▄▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇▇▇█████▇██████</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>99</td></tr><tr><td>iter_acc</td><td>1.0</td></tr><tr><td>tr_acc</td><td>1.0</td></tr><tr><td>tr_epoch_loss</td><td>0.12492</td></tr><tr><td>val_acc_best</td><td>0.81667</td></tr><tr><td>val_acc_now</td><td>0.77917</td></tr><tr><td>val_loss</td><td>49.34039</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">devoted-sweep-238</strong> at: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/p430oqzs' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/p430oqzs</a><br/> View project at: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>/data2/bh_wandb/wandb/run-20250430_075159-p430oqzs/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require(\"core\")`! See https://wandb.me/wandb-core for more information."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: yqxy5zfm with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBATCH: 16\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBN_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBPTT_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tDFA_on: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tIMAGE_SIZE: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tOTTT_input_trace_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tTIME: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tUDA_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \talpha_uda: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbias: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcfg: ['M', 'M', 200, 200]\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tchaching_on: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tconvTrue_fcFalse: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdata_path: /data2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tddp_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdenoise_on: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdvs_clipping: 5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdvs_duration: 100000\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepoch_num: 100\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \texclude_class: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \textra_train_dataset: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlast_lif: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.001\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_sg_width: 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_decay: 0.5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_init: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_reset: 10000\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_threshold: 0.25\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmerge_polarities: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmy_seed: 42\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnet_print: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_workers: 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer_what: SGD\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tpin_memory: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tpre_trained: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tpre_trained_path: net_save/save_now_net_weights_{unique_name}.pth\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \trate_coding: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tscheduler_name: no\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsingle_step: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsurrogate: hard_sigmoid\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_conv_kernel_size: 3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_conv_padding: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_conv_stride: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_trace_const1: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_trace_const2: 0.5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \ttdBN_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \ttrace_on: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \twhich_data: DVS_GESTURE_TONIC\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.19.10 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.17.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/data2/bh_wandb/wandb/run-20250430_075840-yqxy5zfm</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/yqxy5zfm' target=\"_blank\">bright-sweep-240</a></strong> to <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/6pj3lh8j' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/6pj3lh8j</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/6pj3lh8j' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/6pj3lh8j</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/yqxy5zfm' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/yqxy5zfm</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'single_step' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'my_seed' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'TIME' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BATCH' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'IMAGE_SIZE' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'which_data' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'data_path' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'rate_coding' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_init' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_decay' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_threshold' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_reset' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_sg_width' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_conv_kernel_size' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_conv_stride' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_conv_padding' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_trace_const1' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_trace_const2' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'pre_trained' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'convTrue_fcFalse' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'cfg' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'net_print' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'pre_trained_path' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'learning_rate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'epoch_num' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'tdBN_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BN_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'surrogate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BPTT_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'optimizer_what' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'scheduler_name' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'ddp_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'dvs_clipping' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'dvs_duration' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'DFA_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'trace_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'OTTT_input_trace_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'exclude_class' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'merge_polarities' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'denoise_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'extra_train_dataset' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'num_workers' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'chaching_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'pin_memory' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'UDA_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'alpha_uda' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'bias' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'last_lif' was locked by 'sweep' (ignored update).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "param {'devices': '0', 'single_step': True, 'unique_name': 'main', 'my_seed': 42, 'TIME': 10, 'BATCH': 16, 'IMAGE_SIZE': 128, 'which_data': 'DVS_GESTURE_TONIC', 'data_path': '/data2', 'rate_coding': False, 'lif_layer_v_init': 0, 'lif_layer_v_decay': 0.5, 'lif_layer_v_threshold': 0.25, 'lif_layer_v_reset': 10000, 'lif_layer_sg_width': 2, 'synapse_conv_kernel_size': 3, 'synapse_conv_stride': 1, 'synapse_conv_padding': 1, 'synapse_trace_const1': 1, 'synapse_trace_const2': 0.5, 'pre_trained': False, 'convTrue_fcFalse': False, 'cfg': ['M', 'M', 200, 200], 'net_print': True, 'pre_trained_path': 'net_save/save_now_net_weights_{unique_name}.pth', 'learning_rate': 0.001, 'epoch_num': 100, 'tdBN_on': False, 'BN_on': False, 'surrogate': 'hard_sigmoid', 'BPTT_on': False, 'optimizer_what': 'SGD', 'scheduler_name': 'no', 'ddp_on': False, 'dvs_clipping': 5, 'dvs_duration': 100000, 'DFA_on': True, 'trace_on': True, 'OTTT_input_trace_on': False, 'exclude_class': True, 'merge_polarities': False, 'denoise_on': True, 'extra_train_dataset': 0, 'num_workers': 2, 'chaching_on': True, 'pin_memory': True, 'UDA_on': False, 'alpha_uda': 1, 'bias': True, 'last_lif': False, 'current epoch': 0} \n",
      "\n",
      "dataset_hash = 63cc597115630ec173f3099200061e53\n",
      "cache path exists\n",
      "\n",
      "device ==> cuda\n",
      "\n",
      "DataParallel(\n",
      "  (module): REBORN_MY_SNN_FC(\n",
      "    (layers): REBORN_MY_Sequential(\n",
      "      (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (2): DimChanger_for_FC()\n",
      "      (3): SYNAPSE_FC(in_features=2048, out_features=200, TIME=10, bias=True, sstep=True)\n",
      "      (4): LIF_layer(v_init=0, v_decay=0.5, v_threshold=0.25, v_reset=10000, sg_width=2, surrogate=hard_sigmoid, BPTT_on=False, trace_const1=1, trace_const2=0.5, TIME=10, sstep=True, trace_on=True)\n",
      "      (5): Feedback_Receiver()\n",
      "      (6): SYNAPSE_FC(in_features=200, out_features=200, TIME=10, bias=True, sstep=True)\n",
      "      (7): LIF_layer(v_init=0, v_decay=0.5, v_threshold=0.25, v_reset=10000, sg_width=2, surrogate=hard_sigmoid, BPTT_on=False, trace_const1=1, trace_const2=0.5, TIME=10, sstep=True, trace_on=True)\n",
      "      (8): Feedback_Receiver()\n",
      "      (9): SYNAPSE_FC(in_features=200, out_features=10, TIME=10, bias=True, sstep=True)\n",
      "      (DFA_top): Top_Gradient()\n",
      "    )\n",
      "  )\n",
      ")\n",
      "\n",
      "========================================================\n",
      "Trainable parameters: 452,010\n",
      "========================================================\n",
      "\n",
      "epoch-0   lr=['0.0010000'], tr/val_loss:  2.152110/  1.792060, val:  47.08%, val_best:  47.08%, tr:  19.00%, tr_best:  19.00%\n",
      "[module.layers.5] weight_fb parameter count: 2,000\n",
      "[module.layers.8] weight_fb parameter count: 2,000\n",
      "epoch-1   lr=['0.0010000'], tr/val_loss:  1.510275/  1.572159, val:  55.00%, val_best:  55.00%, tr:  51.58%, tr_best:  51.58%\n",
      "epoch-2   lr=['0.0010000'], tr/val_loss:  1.349281/  1.551867, val:  55.83%, val_best:  55.83%, tr:  60.06%, tr_best:  60.06%\n",
      "epoch-3   lr=['0.0010000'], tr/val_loss:  1.238410/  1.543102, val:  59.17%, val_best:  59.17%, tr:  65.37%, tr_best:  65.37%\n",
      "epoch-4   lr=['0.0010000'], tr/val_loss:  1.190854/  1.484418, val:  62.08%, val_best:  62.08%, tr:  66.91%, tr_best:  66.91%\n",
      "epoch-5   lr=['0.0010000'], tr/val_loss:  1.155934/  1.462400, val:  57.08%, val_best:  62.08%, tr:  66.80%, tr_best:  66.91%\n",
      "epoch-6   lr=['0.0010000'], tr/val_loss:  1.099372/  1.512515, val:  59.58%, val_best:  62.08%, tr:  71.30%, tr_best:  71.30%\n",
      "epoch-7   lr=['0.0010000'], tr/val_loss:  1.102944/  1.498126, val:  59.17%, val_best:  62.08%, tr:  66.80%, tr_best:  71.30%\n",
      "epoch-8   lr=['0.0010000'], tr/val_loss:  1.090495/  1.544965, val:  62.92%, val_best:  62.92%, tr:  69.56%, tr_best:  71.30%\n",
      "epoch-9   lr=['0.0010000'], tr/val_loss:  1.087683/  1.603111, val:  54.17%, val_best:  62.92%, tr:  72.42%, tr_best:  72.42%\n",
      "epoch-10  lr=['0.0010000'], tr/val_loss:  1.091091/  1.727580, val:  51.25%, val_best:  62.92%, tr:  70.99%, tr_best:  72.42%\n",
      "epoch-11  lr=['0.0010000'], tr/val_loss:  1.050543/  1.549838, val:  63.33%, val_best:  63.33%, tr:  72.93%, tr_best:  72.93%\n",
      "epoch-12  lr=['0.0010000'], tr/val_loss:  1.047898/  1.560024, val:  61.67%, val_best:  63.33%, tr:  75.08%, tr_best:  75.08%\n",
      "epoch-13  lr=['0.0010000'], tr/val_loss:  1.056469/  1.697932, val:  60.42%, val_best:  63.33%, tr:  73.95%, tr_best:  75.08%\n",
      "epoch-14  lr=['0.0010000'], tr/val_loss:  1.013290/  1.811721, val:  62.08%, val_best:  63.33%, tr:  77.12%, tr_best:  77.12%\n",
      "epoch-15  lr=['0.0010000'], tr/val_loss:  1.019201/  1.728753, val:  61.67%, val_best:  63.33%, tr:  75.69%, tr_best:  77.12%\n",
      "epoch-16  lr=['0.0010000'], tr/val_loss:  1.024053/  1.680688, val:  65.00%, val_best:  65.00%, tr:  78.45%, tr_best:  78.45%\n",
      "epoch-17  lr=['0.0010000'], tr/val_loss:  1.007796/  1.697730, val:  63.33%, val_best:  65.00%, tr:  81.21%, tr_best:  81.21%\n",
      "epoch-18  lr=['0.0010000'], tr/val_loss:  1.023044/  1.862347, val:  60.00%, val_best:  65.00%, tr:  78.55%, tr_best:  81.21%\n",
      "epoch-19  lr=['0.0010000'], tr/val_loss:  1.033598/  1.800207, val:  60.42%, val_best:  65.00%, tr:  81.10%, tr_best:  81.21%\n",
      "epoch-20  lr=['0.0010000'], tr/val_loss:  1.032050/  1.965893, val:  62.08%, val_best:  65.00%, tr:  79.88%, tr_best:  81.21%\n",
      "epoch-21  lr=['0.0010000'], tr/val_loss:  1.005456/  2.010644, val:  62.08%, val_best:  65.00%, tr:  82.43%, tr_best:  82.43%\n",
      "epoch-22  lr=['0.0010000'], tr/val_loss:  0.996776/  1.937038, val:  60.00%, val_best:  65.00%, tr:  84.27%, tr_best:  84.27%\n",
      "epoch-23  lr=['0.0010000'], tr/val_loss:  1.014718/  1.918990, val:  63.75%, val_best:  65.00%, tr:  81.41%, tr_best:  84.27%\n",
      "epoch-24  lr=['0.0010000'], tr/val_loss:  0.957657/  1.906195, val:  64.58%, val_best:  65.00%, tr:  85.60%, tr_best:  85.60%\n",
      "epoch-25  lr=['0.0010000'], tr/val_loss:  0.972319/  1.943717, val:  62.08%, val_best:  65.00%, tr:  84.98%, tr_best:  85.60%\n",
      "epoch-26  lr=['0.0010000'], tr/val_loss:  1.056204/  1.983847, val:  65.83%, val_best:  65.83%, tr:  82.43%, tr_best:  85.60%\n",
      "epoch-27  lr=['0.0010000'], tr/val_loss:  0.991289/  2.097948, val:  60.83%, val_best:  65.83%, tr:  86.21%, tr_best:  86.21%\n",
      "epoch-28  lr=['0.0010000'], tr/val_loss:  0.954400/  2.002200, val:  70.00%, val_best:  70.00%, tr:  87.74%, tr_best:  87.74%\n",
      "epoch-29  lr=['0.0010000'], tr/val_loss:  0.963233/  2.217412, val:  61.25%, val_best:  70.00%, tr:  89.38%, tr_best:  89.38%\n",
      "epoch-30  lr=['0.0010000'], tr/val_loss:  0.961358/  2.174287, val:  62.50%, val_best:  70.00%, tr:  89.68%, tr_best:  89.68%\n",
      "epoch-31  lr=['0.0010000'], tr/val_loss:  0.963725/  2.109461, val:  64.58%, val_best:  70.00%, tr:  87.44%, tr_best:  89.68%\n",
      "epoch-32  lr=['0.0010000'], tr/val_loss:  1.056294/  2.203326, val:  64.58%, val_best:  70.00%, tr:  84.58%, tr_best:  89.68%\n",
      "epoch-33  lr=['0.0010000'], tr/val_loss:  1.024360/  2.287613, val:  61.67%, val_best:  70.00%, tr:  87.03%, tr_best:  89.68%\n",
      "epoch-34  lr=['0.0010000'], tr/val_loss:  0.965887/  2.249180, val:  62.08%, val_best:  70.00%, tr:  90.91%, tr_best:  90.91%\n",
      "epoch-35  lr=['0.0010000'], tr/val_loss:  0.949957/  2.211762, val:  67.08%, val_best:  70.00%, tr:  89.07%, tr_best:  90.91%\n",
      "epoch-36  lr=['0.0010000'], tr/val_loss:  0.937761/  2.241916, val:  66.67%, val_best:  70.00%, tr:  90.50%, tr_best:  90.91%\n",
      "epoch-37  lr=['0.0010000'], tr/val_loss:  1.021579/  2.577090, val:  61.25%, val_best:  70.00%, tr:  88.05%, tr_best:  90.91%\n",
      "epoch-38  lr=['0.0010000'], tr/val_loss:  1.048516/  2.458439, val:  65.83%, val_best:  70.00%, tr:  88.66%, tr_best:  90.91%\n",
      "epoch-39  lr=['0.0010000'], tr/val_loss:  0.975588/  2.358578, val:  68.75%, val_best:  70.00%, tr:  91.62%, tr_best:  91.62%\n",
      "epoch-40  lr=['0.0010000'], tr/val_loss:  0.980192/  2.418291, val:  65.42%, val_best:  70.00%, tr:  89.07%, tr_best:  91.62%\n",
      "epoch-41  lr=['0.0010000'], tr/val_loss:  0.968994/  2.592066, val:  60.42%, val_best:  70.00%, tr:  92.34%, tr_best:  92.34%\n",
      "epoch-42  lr=['0.0010000'], tr/val_loss:  0.999740/  2.405569, val:  67.08%, val_best:  70.00%, tr:  91.22%, tr_best:  92.34%\n",
      "epoch-43  lr=['0.0010000'], tr/val_loss:  0.974135/  2.638014, val:  58.75%, val_best:  70.00%, tr:  91.73%, tr_best:  92.34%\n",
      "epoch-44  lr=['0.0010000'], tr/val_loss:  1.011620/  2.601874, val:  63.75%, val_best:  70.00%, tr:  90.19%, tr_best:  92.34%\n",
      "epoch-45  lr=['0.0010000'], tr/val_loss:  0.976759/  2.447460, val:  67.92%, val_best:  70.00%, tr:  90.91%, tr_best:  92.34%\n",
      "epoch-46  lr=['0.0010000'], tr/val_loss:  0.977949/  2.435647, val:  70.42%, val_best:  70.42%, tr:  91.42%, tr_best:  92.34%\n",
      "epoch-47  lr=['0.0010000'], tr/val_loss:  0.940787/  2.487557, val:  70.42%, val_best:  70.42%, tr:  93.77%, tr_best:  93.77%\n",
      "epoch-48  lr=['0.0010000'], tr/val_loss:  0.970906/  2.463987, val:  74.58%, val_best:  74.58%, tr:  93.46%, tr_best:  93.77%\n",
      "epoch-49  lr=['0.0010000'], tr/val_loss:  0.945778/  2.518673, val:  72.92%, val_best:  74.58%, tr:  94.38%, tr_best:  94.38%\n",
      "epoch-50  lr=['0.0010000'], tr/val_loss:  0.901148/  2.714671, val:  60.00%, val_best:  74.58%, tr:  95.30%, tr_best:  95.30%\n",
      "epoch-51  lr=['0.0010000'], tr/val_loss:  0.959655/  2.621342, val:  67.50%, val_best:  74.58%, tr:  91.01%, tr_best:  95.30%\n",
      "epoch-52  lr=['0.0010000'], tr/val_loss:  0.890213/  2.595981, val:  69.58%, val_best:  74.58%, tr:  93.56%, tr_best:  95.30%\n",
      "epoch-53  lr=['0.0010000'], tr/val_loss:  0.898935/  2.679411, val:  67.50%, val_best:  74.58%, tr:  95.30%, tr_best:  95.30%\n",
      "epoch-54  lr=['0.0010000'], tr/val_loss:  0.903984/  2.557392, val:  70.83%, val_best:  74.58%, tr:  95.30%, tr_best:  95.30%\n",
      "epoch-55  lr=['0.0010000'], tr/val_loss:  0.872991/  2.654962, val:  68.33%, val_best:  74.58%, tr:  95.51%, tr_best:  95.51%\n",
      "epoch-56  lr=['0.0010000'], tr/val_loss:  0.890283/  2.919296, val:  67.08%, val_best:  74.58%, tr:  95.10%, tr_best:  95.51%\n",
      "epoch-57  lr=['0.0010000'], tr/val_loss:  0.942381/  2.719405, val:  67.08%, val_best:  74.58%, tr:  94.59%, tr_best:  95.51%\n",
      "epoch-58  lr=['0.0010000'], tr/val_loss:  0.867942/  2.777651, val:  68.33%, val_best:  74.58%, tr:  94.69%, tr_best:  95.51%\n",
      "epoch-59  lr=['0.0010000'], tr/val_loss:  0.889342/  2.780082, val:  70.00%, val_best:  74.58%, tr:  95.40%, tr_best:  95.51%\n",
      "epoch-60  lr=['0.0010000'], tr/val_loss:  0.891760/  2.883093, val:  66.25%, val_best:  74.58%, tr:  95.61%, tr_best:  95.61%\n",
      "epoch-61  lr=['0.0010000'], tr/val_loss:  0.932025/  2.931294, val:  68.33%, val_best:  74.58%, tr:  94.59%, tr_best:  95.61%\n",
      "epoch-62  lr=['0.0010000'], tr/val_loss:  0.888184/  2.819584, val:  70.00%, val_best:  74.58%, tr:  95.61%, tr_best:  95.61%\n",
      "epoch-63  lr=['0.0010000'], tr/val_loss:  0.876072/  2.737810, val:  74.58%, val_best:  74.58%, tr:  96.83%, tr_best:  96.83%\n",
      "epoch-64  lr=['0.0010000'], tr/val_loss:  0.897091/  2.959965, val:  67.50%, val_best:  74.58%, tr:  95.20%, tr_best:  96.83%\n",
      "epoch-65  lr=['0.0010000'], tr/val_loss:  0.857328/  2.802096, val:  73.75%, val_best:  74.58%, tr:  96.53%, tr_best:  96.83%\n",
      "epoch-66  lr=['0.0010000'], tr/val_loss:  0.873015/  2.939008, val:  69.58%, val_best:  74.58%, tr:  96.63%, tr_best:  96.83%\n",
      "epoch-67  lr=['0.0010000'], tr/val_loss:  0.886038/  2.960126, val:  71.25%, val_best:  74.58%, tr:  97.34%, tr_best:  97.34%\n",
      "epoch-68  lr=['0.0010000'], tr/val_loss:  0.832741/  3.050748, val:  71.25%, val_best:  74.58%, tr:  97.34%, tr_best:  97.34%\n",
      "epoch-69  lr=['0.0010000'], tr/val_loss:  0.890358/  2.955117, val:  72.92%, val_best:  74.58%, tr:  96.73%, tr_best:  97.34%\n",
      "epoch-70  lr=['0.0010000'], tr/val_loss:  0.840820/  2.916163, val:  74.58%, val_best:  74.58%, tr:  97.55%, tr_best:  97.55%\n",
      "epoch-71  lr=['0.0010000'], tr/val_loss:  0.904994/  3.109473, val:  70.42%, val_best:  74.58%, tr:  96.53%, tr_best:  97.55%\n",
      "epoch-72  lr=['0.0010000'], tr/val_loss:  0.882297/  3.129663, val:  70.83%, val_best:  74.58%, tr:  97.24%, tr_best:  97.55%\n",
      "epoch-73  lr=['0.0010000'], tr/val_loss:  0.925897/  3.271962, val:  69.17%, val_best:  74.58%, tr:  95.30%, tr_best:  97.55%\n",
      "epoch-74  lr=['0.0010000'], tr/val_loss:  0.854261/  3.107845, val:  74.17%, val_best:  74.58%, tr:  97.65%, tr_best:  97.65%\n",
      "epoch-75  lr=['0.0010000'], tr/val_loss:  0.856264/  3.250779, val:  69.58%, val_best:  74.58%, tr:  96.02%, tr_best:  97.65%\n",
      "epoch-76  lr=['0.0010000'], tr/val_loss:  0.838714/  3.285772, val:  67.08%, val_best:  74.58%, tr:  97.24%, tr_best:  97.65%\n",
      "epoch-77  lr=['0.0010000'], tr/val_loss:  0.894707/  3.240006, val:  69.58%, val_best:  74.58%, tr:  95.91%, tr_best:  97.65%\n",
      "epoch-78  lr=['0.0010000'], tr/val_loss:  0.898581/  3.204844, val:  75.83%, val_best:  75.83%, tr:  96.12%, tr_best:  97.65%\n",
      "epoch-79  lr=['0.0010000'], tr/val_loss:  0.848118/  3.230155, val:  75.42%, val_best:  75.83%, tr:  97.34%, tr_best:  97.65%\n",
      "epoch-80  lr=['0.0010000'], tr/val_loss:  0.827213/  3.234516, val:  72.08%, val_best:  75.83%, tr:  97.96%, tr_best:  97.96%\n",
      "epoch-81  lr=['0.0010000'], tr/val_loss:  0.874499/  3.315087, val:  74.17%, val_best:  75.83%, tr:  97.75%, tr_best:  97.96%\n",
      "epoch-82  lr=['0.0010000'], tr/val_loss:  0.867268/  3.486682, val:  71.67%, val_best:  75.83%, tr:  96.42%, tr_best:  97.96%\n",
      "epoch-83  lr=['0.0010000'], tr/val_loss:  0.876508/  3.539445, val:  73.33%, val_best:  75.83%, tr:  97.55%, tr_best:  97.96%\n",
      "epoch-84  lr=['0.0010000'], tr/val_loss:  0.855172/  3.323780, val:  75.00%, val_best:  75.83%, tr:  97.65%, tr_best:  97.96%\n",
      "epoch-85  lr=['0.0010000'], tr/val_loss:  0.869770/  3.373609, val:  74.58%, val_best:  75.83%, tr:  97.85%, tr_best:  97.96%\n",
      "epoch-86  lr=['0.0010000'], tr/val_loss:  0.809820/  3.521346, val:  72.50%, val_best:  75.83%, tr:  98.16%, tr_best:  98.16%\n",
      "epoch-87  lr=['0.0010000'], tr/val_loss:  0.841517/  3.468464, val:  73.33%, val_best:  75.83%, tr:  97.55%, tr_best:  98.16%\n",
      "epoch-88  lr=['0.0010000'], tr/val_loss:  0.810418/  3.552731, val:  75.42%, val_best:  75.83%, tr:  97.85%, tr_best:  98.16%\n",
      "epoch-89  lr=['0.0010000'], tr/val_loss:  0.784784/  3.603274, val:  74.17%, val_best:  75.83%, tr:  98.67%, tr_best:  98.67%\n",
      "epoch-90  lr=['0.0010000'], tr/val_loss:  0.797325/  3.481141, val:  74.58%, val_best:  75.83%, tr:  98.16%, tr_best:  98.67%\n",
      "epoch-91  lr=['0.0010000'], tr/val_loss:  0.778274/  3.647163, val:  74.17%, val_best:  75.83%, tr:  98.26%, tr_best:  98.67%\n",
      "epoch-92  lr=['0.0010000'], tr/val_loss:  0.784622/  3.675775, val:  73.33%, val_best:  75.83%, tr:  98.37%, tr_best:  98.67%\n",
      "epoch-93  lr=['0.0010000'], tr/val_loss:  0.798891/  3.604552, val:  73.33%, val_best:  75.83%, tr:  98.47%, tr_best:  98.67%\n",
      "epoch-94  lr=['0.0010000'], tr/val_loss:  0.822201/  3.719591, val:  72.08%, val_best:  75.83%, tr:  98.16%, tr_best:  98.67%\n",
      "epoch-95  lr=['0.0010000'], tr/val_loss:  0.862727/  3.768031, val:  71.67%, val_best:  75.83%, tr:  97.45%, tr_best:  98.67%\n",
      "epoch-96  lr=['0.0010000'], tr/val_loss:  0.825441/  3.935399, val:  67.50%, val_best:  75.83%, tr:  97.65%, tr_best:  98.67%\n",
      "epoch-97  lr=['0.0010000'], tr/val_loss:  0.828437/  3.733259, val:  73.75%, val_best:  75.83%, tr:  97.65%, tr_best:  98.67%\n",
      "epoch-98  lr=['0.0010000'], tr/val_loss:  0.815865/  3.785608, val:  71.25%, val_best:  75.83%, tr:  98.77%, tr_best:  98.77%\n",
      "epoch-99  lr=['0.0010000'], tr/val_loss:  0.799362/  3.775161, val:  72.92%, val_best:  75.83%, tr:  98.67%, tr_best:  98.77%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "edca626b0d484e51b0afce1e132c88ec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.006 MB of 0.006 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>iter_acc</td><td>▂▇▄▃▅▄▆▁▄█▆▇▇▅▇▆▇▇█▇▇█████▇███▇█▇▇▇█▇▇█▇</td></tr><tr><td>summary_val_acc</td><td>▁▃▅▄▃▅▅▅▄▅▅▆▅▅▆▅▆▆▅▇▇▇▇▆▇▆█▇█▇▇▇█▇█▇█▇▇█</td></tr><tr><td>tr_acc</td><td>▁▅▅▅▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇█████████████████████</td></tr><tr><td>tr_epoch_loss</td><td>█▄▃▃▃▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▁▂▁▁▁▂▁▁▁▁▁▁▁▁</td></tr><tr><td>val_acc_best</td><td>▁▃▅▅▅▅▅▅▅▅▅▆▇▇▇▇▇▇▇▇████████████████████</td></tr><tr><td>val_acc_now</td><td>▁▃▅▄▃▅▅▅▄▅▅▆▅▅▆▅▆▆▅▇▇▇▇▆▇▆█▇█▇▇▇█▇█▇█▇▇█</td></tr><tr><td>val_loss</td><td>▂▁▁▁▁▁▂▂▂▃▂▃▃▃▃▄▄▄▄▄▄▄▄▅▅▅▅▆▅▆▆▆▆▇▇▇▇███</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>99</td></tr><tr><td>iter_acc</td><td>1.0</td></tr><tr><td>tr_acc</td><td>0.98672</td></tr><tr><td>tr_epoch_loss</td><td>0.79936</td></tr><tr><td>val_acc_best</td><td>0.75833</td></tr><tr><td>val_acc_now</td><td>0.72917</td></tr><tr><td>val_loss</td><td>3.77516</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">bright-sweep-240</strong> at: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/yqxy5zfm' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/yqxy5zfm</a><br/> View project at: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>/data2/bh_wandb/wandb/run-20250430_075840-yqxy5zfm/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require(\"core\")`! See https://wandb.me/wandb-core for more information."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 91si7po0 with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBATCH: 16\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBN_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBPTT_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tDFA_on: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tIMAGE_SIZE: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tOTTT_input_trace_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tTIME: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tUDA_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \talpha_uda: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbias: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcfg: ['M', 'M', 200, 200]\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tchaching_on: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tconvTrue_fcFalse: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdata_path: /data2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tddp_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdenoise_on: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdvs_clipping: 5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdvs_duration: 100000\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepoch_num: 100\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \texclude_class: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \textra_train_dataset: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlast_lif: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.001\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_sg_width: 4\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_decay: 0.5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_init: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_reset: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_threshold: 0.75\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmerge_polarities: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmy_seed: 42\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnet_print: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_workers: 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer_what: SGD\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tpin_memory: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tpre_trained: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tpre_trained_path: net_save/save_now_net_weights_{unique_name}.pth\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \trate_coding: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tscheduler_name: no\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsingle_step: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsurrogate: hard_sigmoid\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_conv_kernel_size: 3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_conv_padding: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_conv_stride: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_trace_const1: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_trace_const2: 0.5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \ttdBN_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \ttrace_on: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \twhich_data: DVS_GESTURE_TONIC\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.19.10 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.17.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/data2/bh_wandb/wandb/run-20250430_080514-91si7po0</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/91si7po0' target=\"_blank\">chocolate-sweep-242</a></strong> to <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/6pj3lh8j' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/6pj3lh8j</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/6pj3lh8j' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/6pj3lh8j</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/91si7po0' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/91si7po0</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'single_step' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'my_seed' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'TIME' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BATCH' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'IMAGE_SIZE' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'which_data' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'data_path' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'rate_coding' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_init' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_decay' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_threshold' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_reset' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_sg_width' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_conv_kernel_size' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_conv_stride' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_conv_padding' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_trace_const1' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_trace_const2' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'pre_trained' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'convTrue_fcFalse' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'cfg' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'net_print' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'pre_trained_path' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'learning_rate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'epoch_num' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'tdBN_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BN_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'surrogate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BPTT_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'optimizer_what' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'scheduler_name' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'ddp_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'dvs_clipping' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'dvs_duration' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'DFA_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'trace_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'OTTT_input_trace_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'exclude_class' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'merge_polarities' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'denoise_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'extra_train_dataset' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'num_workers' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'chaching_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'pin_memory' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'UDA_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'alpha_uda' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'bias' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'last_lif' was locked by 'sweep' (ignored update).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "param {'devices': '0', 'single_step': True, 'unique_name': 'main', 'my_seed': 42, 'TIME': 10, 'BATCH': 16, 'IMAGE_SIZE': 128, 'which_data': 'DVS_GESTURE_TONIC', 'data_path': '/data2', 'rate_coding': False, 'lif_layer_v_init': 0, 'lif_layer_v_decay': 0.5, 'lif_layer_v_threshold': 0.75, 'lif_layer_v_reset': 0, 'lif_layer_sg_width': 4, 'synapse_conv_kernel_size': 3, 'synapse_conv_stride': 1, 'synapse_conv_padding': 1, 'synapse_trace_const1': 1, 'synapse_trace_const2': 0.5, 'pre_trained': False, 'convTrue_fcFalse': False, 'cfg': ['M', 'M', 200, 200], 'net_print': True, 'pre_trained_path': 'net_save/save_now_net_weights_{unique_name}.pth', 'learning_rate': 0.001, 'epoch_num': 100, 'tdBN_on': False, 'BN_on': False, 'surrogate': 'hard_sigmoid', 'BPTT_on': False, 'optimizer_what': 'SGD', 'scheduler_name': 'no', 'ddp_on': False, 'dvs_clipping': 5, 'dvs_duration': 100000, 'DFA_on': True, 'trace_on': True, 'OTTT_input_trace_on': False, 'exclude_class': True, 'merge_polarities': False, 'denoise_on': True, 'extra_train_dataset': 0, 'num_workers': 2, 'chaching_on': True, 'pin_memory': True, 'UDA_on': False, 'alpha_uda': 1, 'bias': True, 'last_lif': False, 'current epoch': 0} \n",
      "\n",
      "dataset_hash = 63cc597115630ec173f3099200061e53\n",
      "cache path exists\n",
      "\n",
      "device ==> cuda\n",
      "\n",
      "DataParallel(\n",
      "  (module): REBORN_MY_SNN_FC(\n",
      "    (layers): REBORN_MY_Sequential(\n",
      "      (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (2): DimChanger_for_FC()\n",
      "      (3): SYNAPSE_FC(in_features=2048, out_features=200, TIME=10, bias=True, sstep=True)\n",
      "      (4): LIF_layer(v_init=0, v_decay=0.5, v_threshold=0.75, v_reset=0, sg_width=4, surrogate=hard_sigmoid, BPTT_on=False, trace_const1=1, trace_const2=0.5, TIME=10, sstep=True, trace_on=True)\n",
      "      (5): Feedback_Receiver()\n",
      "      (6): SYNAPSE_FC(in_features=200, out_features=200, TIME=10, bias=True, sstep=True)\n",
      "      (7): LIF_layer(v_init=0, v_decay=0.5, v_threshold=0.75, v_reset=0, sg_width=4, surrogate=hard_sigmoid, BPTT_on=False, trace_const1=1, trace_const2=0.5, TIME=10, sstep=True, trace_on=True)\n",
      "      (8): Feedback_Receiver()\n",
      "      (9): SYNAPSE_FC(in_features=200, out_features=10, TIME=10, bias=True, sstep=True)\n",
      "      (DFA_top): Top_Gradient()\n",
      "    )\n",
      "  )\n",
      ")\n",
      "\n",
      "========================================================\n",
      "Trainable parameters: 452,010\n",
      "========================================================\n",
      "\n",
      "epoch-0   lr=['0.0010000'], tr/val_loss:  2.305365/  2.302811, val:  10.42%, val_best:  10.42%, tr:   8.17%, tr_best:   8.17%\n",
      "[module.layers.5] weight_fb parameter count: 2,000\n",
      "[module.layers.8] weight_fb parameter count: 2,000\n",
      "epoch-1   lr=['0.0010000'], tr/val_loss:  2.274444/  2.181778, val:  16.25%, val_best:  16.25%, tr:  11.54%, tr_best:  11.54%\n",
      "epoch-2   lr=['0.0010000'], tr/val_loss:  1.883212/  1.741029, val:  49.58%, val_best:  49.58%, tr:  34.42%, tr_best:  34.42%\n",
      "epoch-3   lr=['0.0010000'], tr/val_loss:  1.479563/  1.579075, val:  54.58%, val_best:  54.58%, tr:  57.61%, tr_best:  57.61%\n",
      "epoch-4   lr=['0.0010000'], tr/val_loss:  1.320227/  1.516584, val:  57.50%, val_best:  57.50%, tr:  61.49%, tr_best:  61.49%\n",
      "epoch-5   lr=['0.0010000'], tr/val_loss:  1.241185/  1.458720, val:  62.08%, val_best:  62.08%, tr:  62.61%, tr_best:  62.61%\n",
      "epoch-6   lr=['0.0010000'], tr/val_loss:  1.159040/  1.454714, val:  59.17%, val_best:  62.08%, tr:  66.60%, tr_best:  66.60%\n",
      "epoch-7   lr=['0.0010000'], tr/val_loss:  1.123605/  1.443690, val:  62.08%, val_best:  62.08%, tr:  66.39%, tr_best:  66.60%\n",
      "epoch-8   lr=['0.0010000'], tr/val_loss:  1.076357/  1.426228, val:  64.17%, val_best:  64.17%, tr:  67.72%, tr_best:  67.72%\n",
      "epoch-9   lr=['0.0010000'], tr/val_loss:  1.047090/  1.438072, val:  61.25%, val_best:  64.17%, tr:  70.99%, tr_best:  70.99%\n",
      "epoch-10  lr=['0.0010000'], tr/val_loss:  1.030491/  1.469872, val:  56.67%, val_best:  64.17%, tr:  70.48%, tr_best:  70.99%\n",
      "epoch-11  lr=['0.0010000'], tr/val_loss:  0.985267/  1.425848, val:  63.33%, val_best:  64.17%, tr:  73.34%, tr_best:  73.34%\n",
      "epoch-12  lr=['0.0010000'], tr/val_loss:  0.971748/  1.433898, val:  59.58%, val_best:  64.17%, tr:  75.28%, tr_best:  75.28%\n",
      "epoch-13  lr=['0.0010000'], tr/val_loss:  0.956739/  1.468063, val:  62.92%, val_best:  64.17%, tr:  75.59%, tr_best:  75.59%\n",
      "epoch-14  lr=['0.0010000'], tr/val_loss:  0.885539/  1.621143, val:  60.00%, val_best:  64.17%, tr:  80.59%, tr_best:  80.59%\n",
      "epoch-15  lr=['0.0010000'], tr/val_loss:  0.885070/  1.536814, val:  62.92%, val_best:  64.17%, tr:  81.41%, tr_best:  81.41%\n",
      "epoch-16  lr=['0.0010000'], tr/val_loss:  0.873487/  1.499978, val:  68.33%, val_best:  68.33%, tr:  79.67%, tr_best:  81.41%\n",
      "epoch-17  lr=['0.0010000'], tr/val_loss:  0.815765/  1.521487, val:  66.67%, val_best:  68.33%, tr:  85.19%, tr_best:  85.19%\n",
      "epoch-18  lr=['0.0010000'], tr/val_loss:  0.808962/  1.649059, val:  65.42%, val_best:  68.33%, tr:  86.11%, tr_best:  86.11%\n",
      "epoch-19  lr=['0.0010000'], tr/val_loss:  0.794242/  1.580608, val:  67.50%, val_best:  68.33%, tr:  84.27%, tr_best:  86.11%\n",
      "epoch-20  lr=['0.0010000'], tr/val_loss:  0.769981/  1.633140, val:  65.42%, val_best:  68.33%, tr:  88.76%, tr_best:  88.76%\n",
      "epoch-21  lr=['0.0010000'], tr/val_loss:  0.747624/  1.626314, val:  70.42%, val_best:  70.42%, tr:  88.97%, tr_best:  88.97%\n",
      "epoch-22  lr=['0.0010000'], tr/val_loss:  0.734551/  1.662645, val:  68.75%, val_best:  70.42%, tr:  89.68%, tr_best:  89.68%\n",
      "epoch-23  lr=['0.0010000'], tr/val_loss:  0.706827/  1.697818, val:  69.17%, val_best:  70.42%, tr:  91.01%, tr_best:  91.01%\n",
      "epoch-24  lr=['0.0010000'], tr/val_loss:  0.687968/  1.708084, val:  68.75%, val_best:  70.42%, tr:  93.36%, tr_best:  93.36%\n",
      "epoch-25  lr=['0.0010000'], tr/val_loss:  0.662809/  1.725150, val:  72.92%, val_best:  72.92%, tr:  93.46%, tr_best:  93.46%\n",
      "epoch-26  lr=['0.0010000'], tr/val_loss:  0.663153/  1.721867, val:  74.58%, val_best:  74.58%, tr:  92.03%, tr_best:  93.46%\n",
      "epoch-27  lr=['0.0010000'], tr/val_loss:  0.627488/  1.839077, val:  68.75%, val_best:  74.58%, tr:  94.79%, tr_best:  94.79%\n",
      "epoch-28  lr=['0.0010000'], tr/val_loss:  0.623164/  1.784449, val:  73.75%, val_best:  74.58%, tr:  95.71%, tr_best:  95.71%\n",
      "epoch-29  lr=['0.0010000'], tr/val_loss:  0.611240/  1.903139, val:  68.33%, val_best:  74.58%, tr:  96.32%, tr_best:  96.32%\n",
      "epoch-30  lr=['0.0010000'], tr/val_loss:  0.601521/  1.882118, val:  72.92%, val_best:  74.58%, tr:  96.02%, tr_best:  96.32%\n",
      "epoch-31  lr=['0.0010000'], tr/val_loss:  0.595543/  1.932038, val:  72.08%, val_best:  74.58%, tr:  94.89%, tr_best:  96.32%\n",
      "epoch-32  lr=['0.0010000'], tr/val_loss:  0.588650/  1.994997, val:  71.67%, val_best:  74.58%, tr:  96.53%, tr_best:  96.53%\n",
      "epoch-33  lr=['0.0010000'], tr/val_loss:  0.578866/  2.035495, val:  74.58%, val_best:  74.58%, tr:  96.83%, tr_best:  96.83%\n",
      "epoch-34  lr=['0.0010000'], tr/val_loss:  0.574919/  2.037275, val:  73.75%, val_best:  74.58%, tr:  96.12%, tr_best:  96.83%\n",
      "epoch-35  lr=['0.0010000'], tr/val_loss:  0.547260/  2.086202, val:  74.58%, val_best:  74.58%, tr:  97.14%, tr_best:  97.14%\n",
      "epoch-36  lr=['0.0010000'], tr/val_loss:  0.519642/  2.141231, val:  75.00%, val_best:  75.00%, tr:  97.75%, tr_best:  97.75%\n",
      "epoch-37  lr=['0.0010000'], tr/val_loss:  0.536090/  2.198709, val:  75.42%, val_best:  75.42%, tr:  97.96%, tr_best:  97.96%\n",
      "epoch-38  lr=['0.0010000'], tr/val_loss:  0.508437/  2.230531, val:  75.42%, val_best:  75.42%, tr:  98.06%, tr_best:  98.06%\n",
      "epoch-39  lr=['0.0010000'], tr/val_loss:  0.509125/  2.264332, val:  75.83%, val_best:  75.83%, tr:  98.57%, tr_best:  98.57%\n",
      "epoch-40  lr=['0.0010000'], tr/val_loss:  0.485903/  2.342306, val:  75.00%, val_best:  75.83%, tr:  98.77%, tr_best:  98.77%\n",
      "epoch-41  lr=['0.0010000'], tr/val_loss:  0.480495/  2.365586, val:  74.17%, val_best:  75.83%, tr:  98.88%, tr_best:  98.88%\n",
      "epoch-42  lr=['0.0010000'], tr/val_loss:  0.486692/  2.353457, val:  74.58%, val_best:  75.83%, tr:  98.98%, tr_best:  98.98%\n",
      "epoch-43  lr=['0.0010000'], tr/val_loss:  0.451886/  2.429762, val:  76.25%, val_best:  76.25%, tr:  98.98%, tr_best:  98.98%\n",
      "epoch-44  lr=['0.0010000'], tr/val_loss:  0.461213/  2.426522, val:  78.33%, val_best:  78.33%, tr:  98.77%, tr_best:  98.98%\n",
      "epoch-45  lr=['0.0010000'], tr/val_loss:  0.452699/  2.489457, val:  75.83%, val_best:  78.33%, tr:  98.98%, tr_best:  98.98%\n",
      "epoch-46  lr=['0.0010000'], tr/val_loss:  0.428896/  2.513921, val:  77.08%, val_best:  78.33%, tr:  99.28%, tr_best:  99.28%\n",
      "epoch-47  lr=['0.0010000'], tr/val_loss:  0.422134/  2.619094, val:  72.92%, val_best:  78.33%, tr:  99.59%, tr_best:  99.59%\n",
      "epoch-48  lr=['0.0010000'], tr/val_loss:  0.419116/  2.563040, val:  77.50%, val_best:  78.33%, tr:  99.39%, tr_best:  99.59%\n",
      "epoch-49  lr=['0.0010000'], tr/val_loss:  0.410882/  2.655837, val:  75.42%, val_best:  78.33%, tr:  99.39%, tr_best:  99.59%\n",
      "epoch-50  lr=['0.0010000'], tr/val_loss:  0.409851/  2.669197, val:  77.08%, val_best:  78.33%, tr:  99.49%, tr_best:  99.59%\n",
      "epoch-51  lr=['0.0010000'], tr/val_loss:  0.403233/  2.681030, val:  77.50%, val_best:  78.33%, tr:  99.49%, tr_best:  99.59%\n",
      "epoch-52  lr=['0.0010000'], tr/val_loss:  0.387724/  2.720288, val:  76.67%, val_best:  78.33%, tr:  99.69%, tr_best:  99.69%\n",
      "epoch-53  lr=['0.0010000'], tr/val_loss:  0.386382/  2.758774, val:  77.50%, val_best:  78.33%, tr:  99.59%, tr_best:  99.69%\n",
      "epoch-54  lr=['0.0010000'], tr/val_loss:  0.388392/  2.818429, val:  79.17%, val_best:  79.17%, tr:  99.69%, tr_best:  99.69%\n",
      "epoch-55  lr=['0.0010000'], tr/val_loss:  0.356915/  2.909835, val:  77.08%, val_best:  79.17%, tr:  99.80%, tr_best:  99.80%\n",
      "epoch-56  lr=['0.0010000'], tr/val_loss:  0.356313/  2.906371, val:  75.83%, val_best:  79.17%, tr:  99.59%, tr_best:  99.80%\n",
      "epoch-57  lr=['0.0010000'], tr/val_loss:  0.370399/  2.930929, val:  78.75%, val_best:  79.17%, tr:  99.69%, tr_best:  99.80%\n",
      "epoch-58  lr=['0.0010000'], tr/val_loss:  0.351974/  2.983765, val:  75.42%, val_best:  79.17%, tr:  99.80%, tr_best:  99.80%\n",
      "epoch-59  lr=['0.0010000'], tr/val_loss:  0.349981/  3.029146, val:  75.83%, val_best:  79.17%, tr:  99.80%, tr_best:  99.80%\n",
      "epoch-60  lr=['0.0010000'], tr/val_loss:  0.328473/  3.069834, val:  77.50%, val_best:  79.17%, tr:  99.90%, tr_best:  99.90%\n",
      "epoch-61  lr=['0.0010000'], tr/val_loss:  0.345911/  3.133818, val:  77.08%, val_best:  79.17%, tr:  99.80%, tr_best:  99.90%\n",
      "epoch-62  lr=['0.0010000'], tr/val_loss:  0.344230/  3.122941, val:  77.08%, val_best:  79.17%, tr:  99.80%, tr_best:  99.90%\n",
      "epoch-63  lr=['0.0010000'], tr/val_loss:  0.327178/  3.150013, val:  80.00%, val_best:  80.00%, tr:  99.90%, tr_best:  99.90%\n",
      "epoch-64  lr=['0.0010000'], tr/val_loss:  0.325166/  3.272672, val:  77.92%, val_best:  80.00%, tr:  99.90%, tr_best:  99.90%\n",
      "epoch-65  lr=['0.0010000'], tr/val_loss:  0.318807/  3.225689, val:  79.17%, val_best:  80.00%, tr:  99.80%, tr_best:  99.90%\n",
      "epoch-66  lr=['0.0010000'], tr/val_loss:  0.319058/  3.301500, val:  77.50%, val_best:  80.00%, tr:  99.90%, tr_best:  99.90%\n",
      "epoch-67  lr=['0.0010000'], tr/val_loss:  0.332334/  3.334648, val:  77.50%, val_best:  80.00%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-68  lr=['0.0010000'], tr/val_loss:  0.333177/  3.405103, val:  76.67%, val_best:  80.00%, tr:  99.80%, tr_best: 100.00%\n",
      "epoch-69  lr=['0.0010000'], tr/val_loss:  0.317303/  3.381676, val:  79.17%, val_best:  80.00%, tr:  99.90%, tr_best: 100.00%\n",
      "epoch-70  lr=['0.0010000'], tr/val_loss:  0.307088/  3.424836, val:  77.50%, val_best:  80.00%, tr:  99.69%, tr_best: 100.00%\n",
      "epoch-71  lr=['0.0010000'], tr/val_loss:  0.313088/  3.500137, val:  78.33%, val_best:  80.00%, tr:  99.80%, tr_best: 100.00%\n",
      "epoch-72  lr=['0.0010000'], tr/val_loss:  0.285936/  3.528277, val:  78.75%, val_best:  80.00%, tr:  99.80%, tr_best: 100.00%\n",
      "epoch-73  lr=['0.0010000'], tr/val_loss:  0.298866/  3.508347, val:  79.58%, val_best:  80.00%, tr:  99.90%, tr_best: 100.00%\n",
      "epoch-74  lr=['0.0010000'], tr/val_loss:  0.286429/  3.572151, val:  78.75%, val_best:  80.00%, tr:  99.80%, tr_best: 100.00%\n",
      "epoch-75  lr=['0.0010000'], tr/val_loss:  0.281370/  3.640395, val:  80.42%, val_best:  80.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-76  lr=['0.0010000'], tr/val_loss:  0.280897/  3.648683, val:  78.75%, val_best:  80.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-77  lr=['0.0010000'], tr/val_loss:  0.275938/  3.711414, val:  78.75%, val_best:  80.42%, tr:  99.90%, tr_best: 100.00%\n",
      "epoch-78  lr=['0.0010000'], tr/val_loss:  0.285398/  3.749564, val:  79.58%, val_best:  80.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-79  lr=['0.0010000'], tr/val_loss:  0.286298/  3.767229, val:  78.75%, val_best:  80.42%, tr:  99.90%, tr_best: 100.00%\n",
      "epoch-80  lr=['0.0010000'], tr/val_loss:  0.282236/  3.891832, val:  77.50%, val_best:  80.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-81  lr=['0.0010000'], tr/val_loss:  0.277932/  3.826974, val:  79.58%, val_best:  80.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-82  lr=['0.0010000'], tr/val_loss:  0.270796/  3.884245, val:  80.00%, val_best:  80.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-83  lr=['0.0010000'], tr/val_loss:  0.268059/  3.956523, val:  77.50%, val_best:  80.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-84  lr=['0.0010000'], tr/val_loss:  0.260155/  3.940510, val:  80.83%, val_best:  80.83%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-85  lr=['0.0010000'], tr/val_loss:  0.259784/  4.019740, val:  78.33%, val_best:  80.83%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-86  lr=['0.0010000'], tr/val_loss:  0.273430/  4.059772, val:  79.17%, val_best:  80.83%, tr:  99.90%, tr_best: 100.00%\n",
      "epoch-87  lr=['0.0010000'], tr/val_loss:  0.242924/  4.107878, val:  77.08%, val_best:  80.83%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-88  lr=['0.0010000'], tr/val_loss:  0.242933/  4.145691, val:  77.08%, val_best:  80.83%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-89  lr=['0.0010000'], tr/val_loss:  0.228664/  4.223286, val:  77.92%, val_best:  80.83%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-90  lr=['0.0010000'], tr/val_loss:  0.229916/  4.184412, val:  79.17%, val_best:  80.83%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-91  lr=['0.0010000'], tr/val_loss:  0.246714/  4.272774, val:  77.92%, val_best:  80.83%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-92  lr=['0.0010000'], tr/val_loss:  0.239691/  4.267675, val:  79.58%, val_best:  80.83%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-93  lr=['0.0010000'], tr/val_loss:  0.236820/  4.281102, val:  80.42%, val_best:  80.83%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-94  lr=['0.0010000'], tr/val_loss:  0.229890/  4.372252, val:  78.75%, val_best:  80.83%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-95  lr=['0.0010000'], tr/val_loss:  0.229181/  4.363671, val:  78.75%, val_best:  80.83%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-96  lr=['0.0010000'], tr/val_loss:  0.217757/  4.336006, val:  79.17%, val_best:  80.83%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-97  lr=['0.0010000'], tr/val_loss:  0.224285/  4.384509, val:  79.17%, val_best:  80.83%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-98  lr=['0.0010000'], tr/val_loss:  0.209148/  4.405687, val:  76.67%, val_best:  80.83%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-99  lr=['0.0010000'], tr/val_loss:  0.211601/  4.509612, val:  79.17%, val_best:  80.83%, tr: 100.00%, tr_best: 100.00%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "90cea9eee8444222a25467654cfc98b7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.006 MB of 0.006 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>iter_acc</td><td>▁▅▄▆▆▆▇▅█████▇██████████████████████████</td></tr><tr><td>summary_val_acc</td><td>▁▅▆▆▆▆▆▇▇▇▇▇▇▇▇▇█▇█▇▇███████████████████</td></tr><tr><td>tr_acc</td><td>▁▃▅▅▆▆▇▇▇▇▇▇████████████████████████████</td></tr><tr><td>tr_epoch_loss</td><td>█▇▅▄▄▄▃▃▃▃▃▂▂▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_acc_best</td><td>▁▅▆▆▆▆▆▇▇▇▇▇▇▇▇▇████████████████████████</td></tr><tr><td>val_acc_now</td><td>▁▅▆▆▆▆▆▇▇▇▇▇▇▇▇▇█▇█▇▇███████████████████</td></tr><tr><td>val_loss</td><td>▃▂▁▁▁▁▁▁▁▁▂▂▂▂▃▃▃▃▃▄▄▄▄▅▅▅▅▆▆▆▆▆▇▇▇▇████</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>99</td></tr><tr><td>iter_acc</td><td>1.0</td></tr><tr><td>tr_acc</td><td>1.0</td></tr><tr><td>tr_epoch_loss</td><td>0.2116</td></tr><tr><td>val_acc_best</td><td>0.80833</td></tr><tr><td>val_acc_now</td><td>0.79167</td></tr><tr><td>val_loss</td><td>4.50961</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">chocolate-sweep-242</strong> at: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/91si7po0' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/91si7po0</a><br/> View project at: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>/data2/bh_wandb/wandb/run-20250430_080514-91si7po0/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require(\"core\")`! See https://wandb.me/wandb-core for more information."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Sweep Agent: Waiting for job.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Job received.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: uq04vqwq with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBATCH: 16\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBN_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBPTT_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tDFA_on: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tIMAGE_SIZE: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tOTTT_input_trace_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tTIME: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tUDA_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \talpha_uda: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbias: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcfg: ['M', 'M', 200, 200]\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tchaching_on: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tconvTrue_fcFalse: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdata_path: /data2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tddp_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdenoise_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdvs_clipping: 5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdvs_duration: 100000\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepoch_num: 100\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \texclude_class: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \textra_train_dataset: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlast_lif: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.0001\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_sg_width: 5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_decay: 0.5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_init: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_reset: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_threshold: 0.75\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmerge_polarities: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmy_seed: 42\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnet_print: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_workers: 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer_what: SGD\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tpin_memory: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tpre_trained: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tpre_trained_path: net_save/save_now_net_weights_{unique_name}.pth\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \trate_coding: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tscheduler_name: no\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsingle_step: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsurrogate: hard_sigmoid\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_conv_kernel_size: 3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_conv_padding: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_conv_stride: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_trace_const1: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_trace_const2: 0.5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \ttdBN_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \ttrace_on: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \twhich_data: DVS_GESTURE_TONIC\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.19.10 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.17.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/data2/bh_wandb/wandb/run-20250430_081152-uq04vqwq</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/uq04vqwq' target=\"_blank\">swept-sweep-244</a></strong> to <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/6pj3lh8j' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/6pj3lh8j</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/6pj3lh8j' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/6pj3lh8j</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/uq04vqwq' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/uq04vqwq</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'single_step' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'my_seed' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'TIME' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BATCH' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'IMAGE_SIZE' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'which_data' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'data_path' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'rate_coding' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_init' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_decay' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_threshold' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_reset' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_sg_width' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_conv_kernel_size' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_conv_stride' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_conv_padding' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_trace_const1' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_trace_const2' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'pre_trained' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'convTrue_fcFalse' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'cfg' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'net_print' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'pre_trained_path' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'learning_rate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'epoch_num' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'tdBN_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BN_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'surrogate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BPTT_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'optimizer_what' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'scheduler_name' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'ddp_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'dvs_clipping' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'dvs_duration' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'DFA_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'trace_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'OTTT_input_trace_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'exclude_class' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'merge_polarities' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'denoise_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'extra_train_dataset' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'num_workers' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'chaching_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'pin_memory' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'UDA_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'alpha_uda' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'bias' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'last_lif' was locked by 'sweep' (ignored update).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "param {'devices': '0', 'single_step': True, 'unique_name': 'main', 'my_seed': 42, 'TIME': 10, 'BATCH': 16, 'IMAGE_SIZE': 128, 'which_data': 'DVS_GESTURE_TONIC', 'data_path': '/data2', 'rate_coding': False, 'lif_layer_v_init': 0, 'lif_layer_v_decay': 0.5, 'lif_layer_v_threshold': 0.75, 'lif_layer_v_reset': 0, 'lif_layer_sg_width': 5, 'synapse_conv_kernel_size': 3, 'synapse_conv_stride': 1, 'synapse_conv_padding': 1, 'synapse_trace_const1': 1, 'synapse_trace_const2': 0.5, 'pre_trained': False, 'convTrue_fcFalse': False, 'cfg': ['M', 'M', 200, 200], 'net_print': True, 'pre_trained_path': 'net_save/save_now_net_weights_{unique_name}.pth', 'learning_rate': 0.0001, 'epoch_num': 100, 'tdBN_on': False, 'BN_on': False, 'surrogate': 'hard_sigmoid', 'BPTT_on': False, 'optimizer_what': 'SGD', 'scheduler_name': 'no', 'ddp_on': False, 'dvs_clipping': 5, 'dvs_duration': 100000, 'DFA_on': True, 'trace_on': True, 'OTTT_input_trace_on': False, 'exclude_class': True, 'merge_polarities': False, 'denoise_on': False, 'extra_train_dataset': 0, 'num_workers': 2, 'chaching_on': True, 'pin_memory': True, 'UDA_on': False, 'alpha_uda': 1, 'bias': True, 'last_lif': False, 'current epoch': 0} \n",
      "\n",
      "dataset_hash = ffa516e60c3efd5e0208f72b4c36cb84\n",
      "cache path exists\n",
      "\n",
      "device ==> cuda\n",
      "\n",
      "DataParallel(\n",
      "  (module): REBORN_MY_SNN_FC(\n",
      "    (layers): REBORN_MY_Sequential(\n",
      "      (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (2): DimChanger_for_FC()\n",
      "      (3): SYNAPSE_FC(in_features=2048, out_features=200, TIME=10, bias=True, sstep=True)\n",
      "      (4): LIF_layer(v_init=0, v_decay=0.5, v_threshold=0.75, v_reset=0, sg_width=5, surrogate=hard_sigmoid, BPTT_on=False, trace_const1=1, trace_const2=0.5, TIME=10, sstep=True, trace_on=True)\n",
      "      (5): Feedback_Receiver()\n",
      "      (6): SYNAPSE_FC(in_features=200, out_features=200, TIME=10, bias=True, sstep=True)\n",
      "      (7): LIF_layer(v_init=0, v_decay=0.5, v_threshold=0.75, v_reset=0, sg_width=5, surrogate=hard_sigmoid, BPTT_on=False, trace_const1=1, trace_const2=0.5, TIME=10, sstep=True, trace_on=True)\n",
      "      (8): Feedback_Receiver()\n",
      "      (9): SYNAPSE_FC(in_features=200, out_features=10, TIME=10, bias=True, sstep=True)\n",
      "      (DFA_top): Top_Gradient()\n",
      "    )\n",
      "  )\n",
      ")\n",
      "\n",
      "========================================================\n",
      "Trainable parameters: 452,010\n",
      "========================================================\n",
      "\n",
      "epoch-0   lr=['0.0001000'], tr/val_loss:  2.303353/  2.303047, val:  10.00%, val_best:  10.00%, tr:  10.01%, tr_best:  10.01%\n",
      "[module.layers.5] weight_fb parameter count: 2,000\n",
      "[module.layers.8] weight_fb parameter count: 2,000\n",
      "epoch-1   lr=['0.0001000'], tr/val_loss:  2.303309/  2.302968, val:  10.00%, val_best:  10.00%, tr:  10.01%, tr_best:  10.01%\n",
      "epoch-2   lr=['0.0001000'], tr/val_loss:  2.303253/  2.302913, val:  10.00%, val_best:  10.00%, tr:  10.01%, tr_best:  10.01%\n",
      "epoch-3   lr=['0.0001000'], tr/val_loss:  2.303181/  2.302909, val:  10.00%, val_best:  10.00%, tr:  10.01%, tr_best:  10.01%\n",
      "epoch-4   lr=['0.0001000'], tr/val_loss:  2.303429/  2.302888, val:  10.00%, val_best:  10.00%, tr:  10.01%, tr_best:  10.01%\n",
      "epoch-5   lr=['0.0001000'], tr/val_loss:  2.302926/  2.302461, val:  10.42%, val_best:  10.42%, tr:  10.52%, tr_best:  10.52%\n",
      "epoch-6   lr=['0.0001000'], tr/val_loss:  2.300390/  2.298291, val:  12.92%, val_best:  12.92%, tr:  11.64%, tr_best:  11.64%\n",
      "epoch-7   lr=['0.0001000'], tr/val_loss:  2.291934/  2.286795, val:  13.33%, val_best:  13.33%, tr:  12.67%, tr_best:  12.67%\n",
      "epoch-8   lr=['0.0001000'], tr/val_loss:  2.273489/  2.267545, val:  12.08%, val_best:  13.33%, tr:  11.95%, tr_best:  12.67%\n",
      "epoch-9   lr=['0.0001000'], tr/val_loss:  2.245582/  2.241165, val:  15.42%, val_best:  15.42%, tr:  13.59%, tr_best:  13.59%\n",
      "epoch-10  lr=['0.0001000'], tr/val_loss:  2.210779/  2.201594, val:  19.17%, val_best:  19.17%, tr:  16.34%, tr_best:  16.34%\n",
      "epoch-11  lr=['0.0001000'], tr/val_loss:  2.154101/  2.148565, val:  25.83%, val_best:  25.83%, tr:  24.21%, tr_best:  24.21%\n",
      "epoch-12  lr=['0.0001000'], tr/val_loss:  2.083848/  2.087213, val:  30.42%, val_best:  30.42%, tr:  25.84%, tr_best:  25.84%\n",
      "epoch-13  lr=['0.0001000'], tr/val_loss:  2.012789/  2.022111, val:  36.25%, val_best:  36.25%, tr:  31.05%, tr_best:  31.05%\n",
      "epoch-14  lr=['0.0001000'], tr/val_loss:  1.938209/  1.951231, val:  40.00%, val_best:  40.00%, tr:  32.58%, tr_best:  32.58%\n",
      "epoch-15  lr=['0.0001000'], tr/val_loss:  1.854788/  1.880021, val:  45.42%, val_best:  45.42%, tr:  41.47%, tr_best:  41.47%\n",
      "epoch-16  lr=['0.0001000'], tr/val_loss:  1.784681/  1.815092, val:  47.50%, val_best:  47.50%, tr:  43.72%, tr_best:  43.72%\n",
      "epoch-17  lr=['0.0001000'], tr/val_loss:  1.714891/  1.758187, val:  50.00%, val_best:  50.00%, tr:  50.56%, tr_best:  50.56%\n",
      "epoch-18  lr=['0.0001000'], tr/val_loss:  1.651557/  1.712417, val:  50.42%, val_best:  50.42%, tr:  51.99%, tr_best:  51.99%\n",
      "epoch-19  lr=['0.0001000'], tr/val_loss:  1.597848/  1.672125, val:  48.75%, val_best:  50.42%, tr:  53.32%, tr_best:  53.32%\n",
      "epoch-20  lr=['0.0001000'], tr/val_loss:  1.549241/  1.635651, val:  51.25%, val_best:  51.25%, tr:  55.06%, tr_best:  55.06%\n",
      "epoch-21  lr=['0.0001000'], tr/val_loss:  1.510075/  1.608137, val:  50.42%, val_best:  51.25%, tr:  57.71%, tr_best:  57.71%\n",
      "epoch-22  lr=['0.0001000'], tr/val_loss:  1.477342/  1.581679, val:  50.42%, val_best:  51.25%, tr:  57.10%, tr_best:  57.71%\n",
      "epoch-23  lr=['0.0001000'], tr/val_loss:  1.437949/  1.555286, val:  52.92%, val_best:  52.92%, tr:  59.75%, tr_best:  59.75%\n",
      "epoch-24  lr=['0.0001000'], tr/val_loss:  1.410668/  1.536026, val:  53.75%, val_best:  53.75%, tr:  60.67%, tr_best:  60.67%\n",
      "epoch-25  lr=['0.0001000'], tr/val_loss:  1.386495/  1.520016, val:  53.75%, val_best:  53.75%, tr:  61.29%, tr_best:  61.29%\n",
      "epoch-26  lr=['0.0001000'], tr/val_loss:  1.362724/  1.508338, val:  54.58%, val_best:  54.58%, tr:  60.16%, tr_best:  61.29%\n",
      "epoch-27  lr=['0.0001000'], tr/val_loss:  1.335625/  1.491726, val:  56.25%, val_best:  56.25%, tr:  63.13%, tr_best:  63.13%\n",
      "epoch-28  lr=['0.0001000'], tr/val_loss:  1.323489/  1.476245, val:  57.08%, val_best:  57.08%, tr:  63.13%, tr_best:  63.13%\n",
      "epoch-29  lr=['0.0001000'], tr/val_loss:  1.296484/  1.462313, val:  60.00%, val_best:  60.00%, tr:  64.15%, tr_best:  64.15%\n",
      "epoch-30  lr=['0.0001000'], tr/val_loss:  1.281165/  1.455404, val:  58.33%, val_best:  60.00%, tr:  64.25%, tr_best:  64.25%\n",
      "epoch-31  lr=['0.0001000'], tr/val_loss:  1.259903/  1.449294, val:  60.00%, val_best:  60.00%, tr:  62.92%, tr_best:  64.25%\n",
      "epoch-32  lr=['0.0001000'], tr/val_loss:  1.244425/  1.439379, val:  59.17%, val_best:  60.00%, tr:  65.99%, tr_best:  65.99%\n",
      "epoch-33  lr=['0.0001000'], tr/val_loss:  1.237633/  1.439754, val:  60.83%, val_best:  60.83%, tr:  65.47%, tr_best:  65.99%\n",
      "epoch-34  lr=['0.0001000'], tr/val_loss:  1.215446/  1.429754, val:  60.83%, val_best:  60.83%, tr:  67.21%, tr_best:  67.21%\n",
      "epoch-35  lr=['0.0001000'], tr/val_loss:  1.195521/  1.421937, val:  61.67%, val_best:  61.67%, tr:  66.60%, tr_best:  67.21%\n",
      "epoch-36  lr=['0.0001000'], tr/val_loss:  1.188225/  1.418568, val:  62.08%, val_best:  62.08%, tr:  67.62%, tr_best:  67.62%\n",
      "epoch-37  lr=['0.0001000'], tr/val_loss:  1.175783/  1.418838, val:  64.17%, val_best:  64.17%, tr:  68.85%, tr_best:  68.85%\n",
      "epoch-38  lr=['0.0001000'], tr/val_loss:  1.164247/  1.410970, val:  63.75%, val_best:  64.17%, tr:  68.54%, tr_best:  68.85%\n",
      "epoch-39  lr=['0.0001000'], tr/val_loss:  1.154908/  1.412104, val:  62.50%, val_best:  64.17%, tr:  69.87%, tr_best:  69.87%\n",
      "epoch-40  lr=['0.0001000'], tr/val_loss:  1.137724/  1.411359, val:  64.17%, val_best:  64.17%, tr:  68.64%, tr_best:  69.87%\n",
      "epoch-41  lr=['0.0001000'], tr/val_loss:  1.137451/  1.407934, val:  63.75%, val_best:  64.17%, tr:  71.71%, tr_best:  71.71%\n",
      "epoch-42  lr=['0.0001000'], tr/val_loss:  1.117908/  1.411953, val:  62.50%, val_best:  64.17%, tr:  72.32%, tr_best:  72.32%\n",
      "epoch-43  lr=['0.0001000'], tr/val_loss:  1.111325/  1.402683, val:  64.58%, val_best:  64.58%, tr:  71.71%, tr_best:  72.32%\n",
      "epoch-44  lr=['0.0001000'], tr/val_loss:  1.102537/  1.405130, val:  62.08%, val_best:  64.58%, tr:  69.36%, tr_best:  72.32%\n",
      "epoch-45  lr=['0.0001000'], tr/val_loss:  1.094222/  1.398606, val:  64.17%, val_best:  64.58%, tr:  71.81%, tr_best:  72.32%\n",
      "epoch-46  lr=['0.0001000'], tr/val_loss:  1.080374/  1.403273, val:  61.25%, val_best:  64.58%, tr:  73.03%, tr_best:  73.03%\n",
      "epoch-47  lr=['0.0001000'], tr/val_loss:  1.081658/  1.395112, val:  61.25%, val_best:  64.58%, tr:  71.30%, tr_best:  73.03%\n",
      "epoch-48  lr=['0.0001000'], tr/val_loss:  1.073250/  1.395864, val:  63.75%, val_best:  64.58%, tr:  74.36%, tr_best:  74.36%\n",
      "epoch-49  lr=['0.0001000'], tr/val_loss:  1.061492/  1.395379, val:  65.00%, val_best:  65.00%, tr:  73.54%, tr_best:  74.36%\n",
      "epoch-50  lr=['0.0001000'], tr/val_loss:  1.056012/  1.396592, val:  63.75%, val_best:  65.00%, tr:  73.95%, tr_best:  74.36%\n",
      "epoch-51  lr=['0.0001000'], tr/val_loss:  1.047227/  1.397724, val:  63.75%, val_best:  65.00%, tr:  74.36%, tr_best:  74.36%\n",
      "epoch-52  lr=['0.0001000'], tr/val_loss:  1.032883/  1.386048, val:  66.67%, val_best:  66.67%, tr:  74.97%, tr_best:  74.97%\n",
      "epoch-53  lr=['0.0001000'], tr/val_loss:  1.028360/  1.387021, val:  67.92%, val_best:  67.92%, tr:  76.10%, tr_best:  76.10%\n",
      "epoch-54  lr=['0.0001000'], tr/val_loss:  1.024073/  1.394207, val:  65.83%, val_best:  67.92%, tr:  78.55%, tr_best:  78.55%\n",
      "epoch-55  lr=['0.0001000'], tr/val_loss:  1.015736/  1.393874, val:  64.17%, val_best:  67.92%, tr:  77.83%, tr_best:  78.55%\n",
      "epoch-56  lr=['0.0001000'], tr/val_loss:  1.000475/  1.396022, val:  65.42%, val_best:  67.92%, tr:  78.14%, tr_best:  78.55%\n",
      "epoch-57  lr=['0.0001000'], tr/val_loss:  0.996526/  1.402561, val:  67.08%, val_best:  67.92%, tr:  78.86%, tr_best:  78.86%\n",
      "epoch-58  lr=['0.0001000'], tr/val_loss:  0.986154/  1.394744, val:  66.25%, val_best:  67.92%, tr:  77.32%, tr_best:  78.86%\n",
      "epoch-59  lr=['0.0001000'], tr/val_loss:  0.983707/  1.393485, val:  67.50%, val_best:  67.92%, tr:  78.65%, tr_best:  78.86%\n",
      "epoch-60  lr=['0.0001000'], tr/val_loss:  0.974962/  1.402107, val:  65.00%, val_best:  67.92%, tr:  77.63%, tr_best:  78.86%\n",
      "epoch-61  lr=['0.0001000'], tr/val_loss:  0.973309/  1.399603, val:  66.67%, val_best:  67.92%, tr:  78.75%, tr_best:  78.86%\n",
      "epoch-62  lr=['0.0001000'], tr/val_loss:  0.965535/  1.404418, val:  68.33%, val_best:  68.33%, tr:  79.98%, tr_best:  79.98%\n",
      "epoch-63  lr=['0.0001000'], tr/val_loss:  0.950378/  1.398114, val:  68.75%, val_best:  68.75%, tr:  81.82%, tr_best:  81.82%\n",
      "epoch-64  lr=['0.0001000'], tr/val_loss:  0.942538/  1.401373, val:  67.50%, val_best:  68.75%, tr:  81.51%, tr_best:  81.82%\n",
      "epoch-65  lr=['0.0001000'], tr/val_loss:  0.944800/  1.402674, val:  67.50%, val_best:  68.75%, tr:  81.72%, tr_best:  81.82%\n",
      "epoch-66  lr=['0.0001000'], tr/val_loss:  0.940029/  1.399265, val:  68.75%, val_best:  68.75%, tr:  82.94%, tr_best:  82.94%\n",
      "epoch-67  lr=['0.0001000'], tr/val_loss:  0.933873/  1.406788, val:  69.17%, val_best:  69.17%, tr:  83.35%, tr_best:  83.35%\n",
      "epoch-68  lr=['0.0001000'], tr/val_loss:  0.919260/  1.412682, val:  69.17%, val_best:  69.17%, tr:  81.21%, tr_best:  83.35%\n",
      "epoch-69  lr=['0.0001000'], tr/val_loss:  0.914186/  1.413387, val:  69.58%, val_best:  69.58%, tr:  83.96%, tr_best:  83.96%\n",
      "epoch-70  lr=['0.0001000'], tr/val_loss:  0.910110/  1.412772, val:  70.00%, val_best:  70.00%, tr:  84.37%, tr_best:  84.37%\n",
      "epoch-71  lr=['0.0001000'], tr/val_loss:  0.899729/  1.413897, val:  70.00%, val_best:  70.00%, tr:  83.55%, tr_best:  84.37%\n",
      "epoch-72  lr=['0.0001000'], tr/val_loss:  0.891407/  1.414077, val:  68.75%, val_best:  70.00%, tr:  84.17%, tr_best:  84.37%\n",
      "epoch-73  lr=['0.0001000'], tr/val_loss:  0.886081/  1.415101, val:  67.92%, val_best:  70.00%, tr:  85.29%, tr_best:  85.29%\n",
      "epoch-74  lr=['0.0001000'], tr/val_loss:  0.879542/  1.422910, val:  68.33%, val_best:  70.00%, tr:  84.78%, tr_best:  85.29%\n",
      "epoch-75  lr=['0.0001000'], tr/val_loss:  0.875178/  1.422862, val:  68.33%, val_best:  70.00%, tr:  84.68%, tr_best:  85.29%\n",
      "epoch-76  lr=['0.0001000'], tr/val_loss:  0.859296/  1.424325, val:  68.75%, val_best:  70.00%, tr:  86.01%, tr_best:  86.01%\n",
      "epoch-77  lr=['0.0001000'], tr/val_loss:  0.863319/  1.427211, val:  68.75%, val_best:  70.00%, tr:  86.01%, tr_best:  86.01%\n",
      "epoch-78  lr=['0.0001000'], tr/val_loss:  0.855392/  1.426275, val:  69.17%, val_best:  70.00%, tr:  85.90%, tr_best:  86.01%\n",
      "epoch-79  lr=['0.0001000'], tr/val_loss:  0.847308/  1.428660, val:  70.42%, val_best:  70.42%, tr:  85.50%, tr_best:  86.01%\n",
      "epoch-80  lr=['0.0001000'], tr/val_loss:  0.836064/  1.424244, val:  69.58%, val_best:  70.42%, tr:  86.82%, tr_best:  86.82%\n",
      "epoch-81  lr=['0.0001000'], tr/val_loss:  0.832522/  1.430477, val:  71.25%, val_best:  71.25%, tr:  87.74%, tr_best:  87.74%\n",
      "epoch-82  lr=['0.0001000'], tr/val_loss:  0.824706/  1.429970, val:  71.67%, val_best:  71.67%, tr:  87.13%, tr_best:  87.74%\n",
      "epoch-83  lr=['0.0001000'], tr/val_loss:  0.822724/  1.435070, val:  70.42%, val_best:  71.67%, tr:  88.66%, tr_best:  88.66%\n",
      "epoch-84  lr=['0.0001000'], tr/val_loss:  0.824849/  1.445410, val:  70.83%, val_best:  71.67%, tr:  88.66%, tr_best:  88.66%\n",
      "epoch-85  lr=['0.0001000'], tr/val_loss:  0.821984/  1.449040, val:  70.42%, val_best:  71.67%, tr:  89.68%, tr_best:  89.68%\n",
      "epoch-86  lr=['0.0001000'], tr/val_loss:  0.797390/  1.451554, val:  70.00%, val_best:  71.67%, tr:  89.58%, tr_best:  89.68%\n",
      "epoch-87  lr=['0.0001000'], tr/val_loss:  0.798814/  1.457311, val:  70.00%, val_best:  71.67%, tr:  89.38%, tr_best:  89.68%\n",
      "epoch-88  lr=['0.0001000'], tr/val_loss:  0.788648/  1.466034, val:  70.83%, val_best:  71.67%, tr:  89.99%, tr_best:  89.99%\n",
      "epoch-89  lr=['0.0001000'], tr/val_loss:  0.782336/  1.472398, val:  68.75%, val_best:  71.67%, tr:  90.30%, tr_best:  90.30%\n",
      "epoch-90  lr=['0.0001000'], tr/val_loss:  0.779668/  1.466135, val:  72.08%, val_best:  72.08%, tr:  90.60%, tr_best:  90.60%\n",
      "epoch-91  lr=['0.0001000'], tr/val_loss:  0.763999/  1.481084, val:  71.67%, val_best:  72.08%, tr:  90.40%, tr_best:  90.60%\n",
      "epoch-92  lr=['0.0001000'], tr/val_loss:  0.773164/  1.482455, val:  71.67%, val_best:  72.08%, tr:  91.11%, tr_best:  91.11%\n",
      "epoch-93  lr=['0.0001000'], tr/val_loss:  0.766590/  1.487521, val:  70.42%, val_best:  72.08%, tr:  91.62%, tr_best:  91.62%\n",
      "epoch-94  lr=['0.0001000'], tr/val_loss:  0.760815/  1.498047, val:  71.25%, val_best:  72.08%, tr:  91.22%, tr_best:  91.62%\n",
      "epoch-95  lr=['0.0001000'], tr/val_loss:  0.747020/  1.502351, val:  71.25%, val_best:  72.08%, tr:  91.32%, tr_best:  91.62%\n",
      "epoch-96  lr=['0.0001000'], tr/val_loss:  0.744098/  1.499971, val:  70.42%, val_best:  72.08%, tr:  92.03%, tr_best:  92.03%\n",
      "epoch-97  lr=['0.0001000'], tr/val_loss:  0.738069/  1.505840, val:  70.42%, val_best:  72.08%, tr:  91.73%, tr_best:  92.03%\n",
      "epoch-98  lr=['0.0001000'], tr/val_loss:  0.737532/  1.510493, val:  70.42%, val_best:  72.08%, tr:  92.44%, tr_best:  92.44%\n",
      "epoch-99  lr=['0.0001000'], tr/val_loss:  0.729987/  1.532237, val:  70.83%, val_best:  72.08%, tr:  91.73%, tr_best:  92.44%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7bfae9d1edef44adb3e14e21a764d153",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.006 MB of 0.006 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>iter_acc</td><td>▁▁▁▁▁▁▃▃▃▅▅▅▅▅▆▆▆▆▇▆▇▇▅▆▇▇▇█▇▆▇▇▇▇█▇████</td></tr><tr><td>summary_val_acc</td><td>▁▁▁▁▂▃▄▆▅▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇█▇██████████████</td></tr><tr><td>tr_acc</td><td>▁▁▁▁▁▂▃▄▅▅▅▅▆▆▆▆▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇█▇███████</td></tr><tr><td>tr_epoch_loss</td><td>█████▇▆▅▅▄▄▄▃▃▃▃▃▃▃▃▂▂▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁</td></tr><tr><td>val_acc_best</td><td>▁▁▁▁▂▃▄▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇██████████████████</td></tr><tr><td>val_acc_now</td><td>▁▁▁▁▂▃▄▆▅▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇█▇██████████████</td></tr><tr><td>val_loss</td><td>█████▆▅▄▃▃▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▂▂▂▂</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>99</td></tr><tr><td>iter_acc</td><td>1.0</td></tr><tr><td>tr_acc</td><td>0.91726</td></tr><tr><td>tr_epoch_loss</td><td>0.72999</td></tr><tr><td>val_acc_best</td><td>0.72083</td></tr><tr><td>val_acc_now</td><td>0.70833</td></tr><tr><td>val_loss</td><td>1.53224</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">swept-sweep-244</strong> at: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/uq04vqwq' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/uq04vqwq</a><br/> View project at: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>/data2/bh_wandb/wandb/run-20250430_081152-uq04vqwq/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require(\"core\")`! See https://wandb.me/wandb-core for more information."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Sweep Agent: Waiting for job.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Job received.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 7hdwoz7j with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBATCH: 16\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBN_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBPTT_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tDFA_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tIMAGE_SIZE: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tOTTT_input_trace_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tTIME: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tUDA_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \talpha_uda: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbias: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcfg: ['M', 'M', 200, 200]\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tchaching_on: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tconvTrue_fcFalse: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdata_path: /data2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tddp_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdenoise_on: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdvs_clipping: 5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdvs_duration: 100000\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepoch_num: 100\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \texclude_class: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \textra_train_dataset: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlast_lif: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.01\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_sg_width: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_decay: 0.5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_init: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_reset: 10000\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_threshold: 0.25\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmerge_polarities: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmy_seed: 42\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnet_print: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_workers: 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer_what: SGD\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tpin_memory: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tpre_trained: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tpre_trained_path: net_save/save_now_net_weights_{unique_name}.pth\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \trate_coding: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tscheduler_name: no\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsingle_step: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsurrogate: hard_sigmoid\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_conv_kernel_size: 3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_conv_padding: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_conv_stride: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_trace_const1: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_trace_const2: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \ttdBN_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \ttrace_on: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \twhich_data: DVS_GESTURE_TONIC\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.19.10 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.17.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/data2/bh_wandb/wandb/run-20250430_081831-7hdwoz7j</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/7hdwoz7j' target=\"_blank\">summer-sweep-246</a></strong> to <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/6pj3lh8j' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/6pj3lh8j</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/6pj3lh8j' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/6pj3lh8j</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/7hdwoz7j' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/7hdwoz7j</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'single_step' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'my_seed' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'TIME' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BATCH' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'IMAGE_SIZE' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'which_data' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'data_path' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'rate_coding' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_init' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_decay' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_threshold' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_reset' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_sg_width' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_conv_kernel_size' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_conv_stride' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_conv_padding' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_trace_const1' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_trace_const2' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'pre_trained' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'convTrue_fcFalse' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'cfg' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'net_print' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'pre_trained_path' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'learning_rate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'epoch_num' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'tdBN_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BN_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'surrogate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BPTT_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'optimizer_what' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'scheduler_name' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'ddp_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'dvs_clipping' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'dvs_duration' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'DFA_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'trace_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'OTTT_input_trace_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'exclude_class' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'merge_polarities' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'denoise_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'extra_train_dataset' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'num_workers' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'chaching_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'pin_memory' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'UDA_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'alpha_uda' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'bias' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'last_lif' was locked by 'sweep' (ignored update).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "param {'devices': '0', 'single_step': True, 'unique_name': 'main', 'my_seed': 42, 'TIME': 10, 'BATCH': 16, 'IMAGE_SIZE': 128, 'which_data': 'DVS_GESTURE_TONIC', 'data_path': '/data2', 'rate_coding': False, 'lif_layer_v_init': 0, 'lif_layer_v_decay': 0.5, 'lif_layer_v_threshold': 0.25, 'lif_layer_v_reset': 10000, 'lif_layer_sg_width': 1, 'synapse_conv_kernel_size': 3, 'synapse_conv_stride': 1, 'synapse_conv_padding': 1, 'synapse_trace_const1': 1, 'synapse_trace_const2': 0, 'pre_trained': False, 'convTrue_fcFalse': False, 'cfg': ['M', 'M', 200, 200], 'net_print': True, 'pre_trained_path': 'net_save/save_now_net_weights_{unique_name}.pth', 'learning_rate': 0.01, 'epoch_num': 100, 'tdBN_on': False, 'BN_on': False, 'surrogate': 'hard_sigmoid', 'BPTT_on': False, 'optimizer_what': 'SGD', 'scheduler_name': 'no', 'ddp_on': False, 'dvs_clipping': 5, 'dvs_duration': 100000, 'DFA_on': False, 'trace_on': True, 'OTTT_input_trace_on': False, 'exclude_class': True, 'merge_polarities': False, 'denoise_on': True, 'extra_train_dataset': 0, 'num_workers': 2, 'chaching_on': True, 'pin_memory': True, 'UDA_on': False, 'alpha_uda': 1, 'bias': True, 'last_lif': False, 'current epoch': 0} \n",
      "\n",
      "dataset_hash = 63cc597115630ec173f3099200061e53\n",
      "cache path exists\n",
      "\n",
      "device ==> cuda\n",
      "\n",
      "DataParallel(\n",
      "  (module): REBORN_MY_SNN_FC(\n",
      "    (layers): REBORN_MY_Sequential(\n",
      "      (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (2): DimChanger_for_FC()\n",
      "      (3): SYNAPSE_FC(in_features=2048, out_features=200, TIME=10, bias=True, sstep=True)\n",
      "      (4): LIF_layer(v_init=0, v_decay=0.5, v_threshold=0.25, v_reset=10000, sg_width=1, surrogate=hard_sigmoid, BPTT_on=False, trace_const1=1, trace_const2=0, TIME=10, sstep=True, trace_on=True)\n",
      "      (5): SYNAPSE_FC(in_features=200, out_features=200, TIME=10, bias=True, sstep=True)\n",
      "      (6): LIF_layer(v_init=0, v_decay=0.5, v_threshold=0.25, v_reset=10000, sg_width=1, surrogate=hard_sigmoid, BPTT_on=False, trace_const1=1, trace_const2=0, TIME=10, sstep=True, trace_on=True)\n",
      "      (7): SYNAPSE_FC(in_features=200, out_features=10, TIME=10, bias=True, sstep=True)\n",
      "    )\n",
      "  )\n",
      ")\n",
      "\n",
      "========================================================\n",
      "Trainable parameters: 452,010\n",
      "========================================================\n",
      "\n",
      "epoch-0   lr=['0.0100000'], tr/val_loss:  2.093464/  1.804163, val:  39.58%, val_best:  39.58%, tr:  25.84%, tr_best:  25.84%\n",
      "epoch-1   lr=['0.0100000'], tr/val_loss:  1.520452/  1.567530, val:  52.08%, val_best:  52.08%, tr:  53.22%, tr_best:  53.22%\n",
      "epoch-2   lr=['0.0100000'], tr/val_loss:  1.369658/  1.455434, val:  57.08%, val_best:  57.08%, tr:  56.18%, tr_best:  56.18%\n",
      "epoch-3   lr=['0.0100000'], tr/val_loss:  1.192250/  1.481138, val:  54.58%, val_best:  57.08%, tr:  64.35%, tr_best:  64.35%\n",
      "epoch-4   lr=['0.0100000'], tr/val_loss:  1.106115/  1.427329, val:  55.83%, val_best:  57.08%, tr:  65.27%, tr_best:  65.27%\n",
      "epoch-5   lr=['0.0100000'], tr/val_loss:  1.066340/  1.334103, val:  59.17%, val_best:  59.17%, tr:  65.58%, tr_best:  65.58%\n",
      "epoch-6   lr=['0.0100000'], tr/val_loss:  0.997525/  1.287843, val:  57.92%, val_best:  59.17%, tr:  67.72%, tr_best:  67.72%\n",
      "epoch-7   lr=['0.0100000'], tr/val_loss:  0.964460/  1.376679, val:  57.50%, val_best:  59.17%, tr:  69.15%, tr_best:  69.15%\n",
      "epoch-8   lr=['0.0100000'], tr/val_loss:  0.937245/  1.328882, val:  57.50%, val_best:  59.17%, tr:  70.17%, tr_best:  70.17%\n",
      "epoch-9   lr=['0.0100000'], tr/val_loss:  0.883630/  1.412973, val:  58.33%, val_best:  59.17%, tr:  75.38%, tr_best:  75.38%\n",
      "epoch-10  lr=['0.0100000'], tr/val_loss:  0.865954/  1.520998, val:  53.75%, val_best:  59.17%, tr:  76.00%, tr_best:  76.00%\n",
      "epoch-11  lr=['0.0100000'], tr/val_loss:  0.811049/  1.310763, val:  64.58%, val_best:  64.58%, tr:  77.02%, tr_best:  77.02%\n",
      "epoch-12  lr=['0.0100000'], tr/val_loss:  0.830196/  1.280111, val:  67.92%, val_best:  67.92%, tr:  79.06%, tr_best:  79.06%\n",
      "epoch-13  lr=['0.0100000'], tr/val_loss:  0.807603/  1.452106, val:  57.08%, val_best:  67.92%, tr:  78.45%, tr_best:  79.06%\n",
      "epoch-14  lr=['0.0100000'], tr/val_loss:  0.754391/  1.540796, val:  62.92%, val_best:  67.92%, tr:  79.26%, tr_best:  79.26%\n",
      "epoch-15  lr=['0.0100000'], tr/val_loss:  0.755722/  1.456823, val:  60.42%, val_best:  67.92%, tr:  80.18%, tr_best:  80.18%\n",
      "epoch-16  lr=['0.0100000'], tr/val_loss:  0.726351/  1.358274, val:  67.92%, val_best:  67.92%, tr:  82.43%, tr_best:  82.43%\n",
      "epoch-17  lr=['0.0100000'], tr/val_loss:  0.720681/  1.360861, val:  64.17%, val_best:  67.92%, tr:  84.78%, tr_best:  84.78%\n",
      "epoch-18  lr=['0.0100000'], tr/val_loss:  0.705024/  1.454148, val:  60.42%, val_best:  67.92%, tr:  84.47%, tr_best:  84.78%\n",
      "epoch-19  lr=['0.0100000'], tr/val_loss:  0.685147/  1.459065, val:  62.08%, val_best:  67.92%, tr:  84.07%, tr_best:  84.78%\n",
      "epoch-20  lr=['0.0100000'], tr/val_loss:  0.651998/  1.594554, val:  58.75%, val_best:  67.92%, tr:  83.45%, tr_best:  84.78%\n",
      "epoch-21  lr=['0.0100000'], tr/val_loss:  0.655439/  1.679971, val:  56.67%, val_best:  67.92%, tr:  84.47%, tr_best:  84.78%\n",
      "epoch-22  lr=['0.0100000'], tr/val_loss:  0.659277/  1.446213, val:  63.33%, val_best:  67.92%, tr:  86.93%, tr_best:  86.93%\n",
      "epoch-23  lr=['0.0100000'], tr/val_loss:  0.631546/  1.469632, val:  67.08%, val_best:  67.92%, tr:  86.72%, tr_best:  86.93%\n",
      "epoch-24  lr=['0.0100000'], tr/val_loss:  0.541929/  1.539254, val:  64.58%, val_best:  67.92%, tr:  92.75%, tr_best:  92.75%\n",
      "epoch-25  lr=['0.0100000'], tr/val_loss:  0.526375/  1.493806, val:  64.58%, val_best:  67.92%, tr:  92.13%, tr_best:  92.75%\n",
      "epoch-26  lr=['0.0100000'], tr/val_loss:  0.563400/  1.425582, val:  69.58%, val_best:  69.58%, tr:  89.48%, tr_best:  92.75%\n",
      "epoch-27  lr=['0.0100000'], tr/val_loss:  0.516438/  1.498469, val:  62.50%, val_best:  69.58%, tr:  92.13%, tr_best:  92.75%\n",
      "epoch-28  lr=['0.0100000'], tr/val_loss:  0.482236/  1.511911, val:  68.33%, val_best:  69.58%, tr:  93.36%, tr_best:  93.36%\n",
      "epoch-29  lr=['0.0100000'], tr/val_loss:  0.488506/  1.705535, val:  60.83%, val_best:  69.58%, tr:  93.97%, tr_best:  93.97%\n",
      "epoch-30  lr=['0.0100000'], tr/val_loss:  0.440447/  1.599422, val:  69.58%, val_best:  69.58%, tr:  95.40%, tr_best:  95.40%\n",
      "epoch-31  lr=['0.0100000'], tr/val_loss:  0.458646/  1.564845, val:  70.00%, val_best:  70.00%, tr:  94.28%, tr_best:  95.40%\n",
      "epoch-32  lr=['0.0100000'], tr/val_loss:  0.478007/  1.583848, val:  65.83%, val_best:  70.00%, tr:  92.24%, tr_best:  95.40%\n",
      "epoch-33  lr=['0.0100000'], tr/val_loss:  0.502189/  1.626638, val:  65.42%, val_best:  70.00%, tr:  92.75%, tr_best:  95.40%\n",
      "epoch-34  lr=['0.0100000'], tr/val_loss:  0.449297/  1.704894, val:  62.92%, val_best:  70.00%, tr:  93.77%, tr_best:  95.40%\n",
      "epoch-35  lr=['0.0100000'], tr/val_loss:  0.439292/  1.607047, val:  66.67%, val_best:  70.00%, tr:  93.77%, tr_best:  95.40%\n",
      "epoch-36  lr=['0.0100000'], tr/val_loss:  0.427201/  1.683868, val:  67.08%, val_best:  70.00%, tr:  94.69%, tr_best:  95.40%\n",
      "epoch-37  lr=['0.0100000'], tr/val_loss:  0.407383/  1.856389, val:  64.17%, val_best:  70.00%, tr:  95.30%, tr_best:  95.40%\n",
      "epoch-38  lr=['0.0100000'], tr/val_loss:  0.410504/  1.818621, val:  65.83%, val_best:  70.00%, tr:  95.71%, tr_best:  95.71%\n",
      "epoch-39  lr=['0.0100000'], tr/val_loss:  0.375028/  1.681108, val:  68.75%, val_best:  70.00%, tr:  95.71%, tr_best:  95.71%\n",
      "epoch-40  lr=['0.0100000'], tr/val_loss:  0.369680/  1.786931, val:  67.08%, val_best:  70.00%, tr:  96.02%, tr_best:  96.02%\n",
      "epoch-41  lr=['0.0100000'], tr/val_loss:  0.353128/  1.946096, val:  64.17%, val_best:  70.00%, tr:  97.85%, tr_best:  97.85%\n",
      "epoch-42  lr=['0.0100000'], tr/val_loss:  0.361808/  1.770810, val:  70.83%, val_best:  70.83%, tr:  97.14%, tr_best:  97.85%\n",
      "epoch-43  lr=['0.0100000'], tr/val_loss:  0.330391/  1.831651, val:  66.67%, val_best:  70.83%, tr:  97.65%, tr_best:  97.85%\n",
      "epoch-44  lr=['0.0100000'], tr/val_loss:  0.347390/  1.828241, val:  69.17%, val_best:  70.83%, tr:  96.73%, tr_best:  97.85%\n",
      "epoch-45  lr=['0.0100000'], tr/val_loss:  0.300920/  1.840622, val:  70.00%, val_best:  70.83%, tr:  98.26%, tr_best:  98.26%\n",
      "epoch-46  lr=['0.0100000'], tr/val_loss:  0.297843/  1.875064, val:  69.58%, val_best:  70.83%, tr:  98.77%, tr_best:  98.77%\n",
      "epoch-47  lr=['0.0100000'], tr/val_loss:  0.281356/  1.973221, val:  67.92%, val_best:  70.83%, tr:  98.98%, tr_best:  98.98%\n",
      "epoch-48  lr=['0.0100000'], tr/val_loss:  0.295709/  2.083009, val:  71.67%, val_best:  71.67%, tr:  98.37%, tr_best:  98.98%\n",
      "epoch-49  lr=['0.0100000'], tr/val_loss:  0.281896/  1.865638, val:  74.58%, val_best:  74.58%, tr:  99.08%, tr_best:  99.08%\n",
      "epoch-50  lr=['0.0100000'], tr/val_loss:  0.240162/  2.134051, val:  65.83%, val_best:  74.58%, tr:  99.39%, tr_best:  99.39%\n",
      "epoch-51  lr=['0.0100000'], tr/val_loss:  0.284868/  1.894991, val:  70.00%, val_best:  74.58%, tr:  97.24%, tr_best:  99.39%\n",
      "epoch-52  lr=['0.0100000'], tr/val_loss:  0.246165/  1.916287, val:  74.17%, val_best:  74.58%, tr:  99.18%, tr_best:  99.39%\n",
      "epoch-53  lr=['0.0100000'], tr/val_loss:  0.232005/  2.041743, val:  70.42%, val_best:  74.58%, tr:  99.39%, tr_best:  99.39%\n",
      "epoch-54  lr=['0.0100000'], tr/val_loss:  0.235775/  1.991914, val:  71.67%, val_best:  74.58%, tr:  99.18%, tr_best:  99.39%\n",
      "epoch-55  lr=['0.0100000'], tr/val_loss:  0.219433/  2.126981, val:  70.83%, val_best:  74.58%, tr:  99.28%, tr_best:  99.39%\n",
      "epoch-56  lr=['0.0100000'], tr/val_loss:  0.215058/  2.151287, val:  72.92%, val_best:  74.58%, tr:  99.69%, tr_best:  99.69%\n",
      "epoch-57  lr=['0.0100000'], tr/val_loss:  0.227326/  2.060086, val:  73.75%, val_best:  74.58%, tr:  98.98%, tr_best:  99.69%\n",
      "epoch-58  lr=['0.0100000'], tr/val_loss:  0.234116/  2.154521, val:  72.50%, val_best:  74.58%, tr:  98.57%, tr_best:  99.69%\n",
      "epoch-59  lr=['0.0100000'], tr/val_loss:  0.214557/  2.092553, val:  72.50%, val_best:  74.58%, tr:  99.69%, tr_best:  99.69%\n",
      "epoch-60  lr=['0.0100000'], tr/val_loss:  0.193943/  2.289439, val:  69.58%, val_best:  74.58%, tr:  99.80%, tr_best:  99.80%\n",
      "epoch-61  lr=['0.0100000'], tr/val_loss:  0.230466/  2.254577, val:  71.25%, val_best:  74.58%, tr:  98.77%, tr_best:  99.80%\n",
      "epoch-62  lr=['0.0100000'], tr/val_loss:  0.196010/  2.195013, val:  71.67%, val_best:  74.58%, tr:  99.28%, tr_best:  99.80%\n",
      "epoch-63  lr=['0.0100000'], tr/val_loss:  0.179501/  2.230398, val:  69.58%, val_best:  74.58%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-64  lr=['0.0100000'], tr/val_loss:  0.164791/  2.298924, val:  71.67%, val_best:  74.58%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-65  lr=['0.0100000'], tr/val_loss:  0.174406/  2.258972, val:  70.83%, val_best:  74.58%, tr:  99.90%, tr_best: 100.00%\n",
      "epoch-66  lr=['0.0100000'], tr/val_loss:  0.177679/  2.236066, val:  71.25%, val_best:  74.58%, tr:  99.80%, tr_best: 100.00%\n",
      "epoch-67  lr=['0.0100000'], tr/val_loss:  0.162292/  2.304641, val:  72.08%, val_best:  74.58%, tr:  99.80%, tr_best: 100.00%\n",
      "epoch-68  lr=['0.0100000'], tr/val_loss:  0.150654/  2.292658, val:  72.92%, val_best:  74.58%, tr:  99.90%, tr_best: 100.00%\n",
      "epoch-69  lr=['0.0100000'], tr/val_loss:  0.151153/  2.357902, val:  70.83%, val_best:  74.58%, tr:  99.80%, tr_best: 100.00%\n",
      "epoch-70  lr=['0.0100000'], tr/val_loss:  0.147497/  2.400547, val:  72.50%, val_best:  74.58%, tr:  99.90%, tr_best: 100.00%\n",
      "epoch-71  lr=['0.0100000'], tr/val_loss:  0.165482/  2.390926, val:  70.83%, val_best:  74.58%, tr:  99.90%, tr_best: 100.00%\n",
      "epoch-72  lr=['0.0100000'], tr/val_loss:  0.160051/  2.486716, val:  69.17%, val_best:  74.58%, tr:  99.69%, tr_best: 100.00%\n",
      "epoch-73  lr=['0.0100000'], tr/val_loss:  0.152720/  2.306225, val:  70.83%, val_best:  74.58%, tr:  99.59%, tr_best: 100.00%\n",
      "epoch-74  lr=['0.0100000'], tr/val_loss:  0.152459/  2.307351, val:  73.33%, val_best:  74.58%, tr:  99.90%, tr_best: 100.00%\n",
      "epoch-75  lr=['0.0100000'], tr/val_loss:  0.135091/  2.411253, val:  69.17%, val_best:  74.58%, tr:  99.90%, tr_best: 100.00%\n",
      "epoch-76  lr=['0.0100000'], tr/val_loss:  0.134465/  2.368247, val:  72.08%, val_best:  74.58%, tr:  99.90%, tr_best: 100.00%\n",
      "epoch-77  lr=['0.0100000'], tr/val_loss:  0.131638/  2.461327, val:  71.25%, val_best:  74.58%, tr:  99.80%, tr_best: 100.00%\n",
      "epoch-78  lr=['0.0100000'], tr/val_loss:  0.127624/  2.543429, val:  72.50%, val_best:  74.58%, tr:  99.90%, tr_best: 100.00%\n",
      "epoch-79  lr=['0.0100000'], tr/val_loss:  0.131922/  2.428130, val:  70.00%, val_best:  74.58%, tr:  99.90%, tr_best: 100.00%\n",
      "epoch-80  lr=['0.0100000'], tr/val_loss:  0.123996/  2.568675, val:  71.67%, val_best:  74.58%, tr:  99.90%, tr_best: 100.00%\n",
      "epoch-81  lr=['0.0100000'], tr/val_loss:  0.117457/  2.519698, val:  72.08%, val_best:  74.58%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-82  lr=['0.0100000'], tr/val_loss:  0.123900/  2.626960, val:  71.25%, val_best:  74.58%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-83  lr=['0.0100000'], tr/val_loss:  0.110118/  2.599102, val:  70.83%, val_best:  74.58%, tr:  99.90%, tr_best: 100.00%\n",
      "epoch-84  lr=['0.0100000'], tr/val_loss:  0.106610/  2.553875, val:  73.75%, val_best:  74.58%, tr:  99.90%, tr_best: 100.00%\n",
      "epoch-85  lr=['0.0100000'], tr/val_loss:  0.144267/  2.619868, val:  71.25%, val_best:  74.58%, tr:  99.90%, tr_best: 100.00%\n",
      "epoch-86  lr=['0.0100000'], tr/val_loss:  0.125064/  2.527791, val:  72.50%, val_best:  74.58%, tr:  99.90%, tr_best: 100.00%\n",
      "epoch-87  lr=['0.0100000'], tr/val_loss:  0.113542/  2.537629, val:  71.67%, val_best:  74.58%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-88  lr=['0.0100000'], tr/val_loss:  0.125017/  2.624168, val:  70.83%, val_best:  74.58%, tr:  99.80%, tr_best: 100.00%\n",
      "epoch-89  lr=['0.0100000'], tr/val_loss:  0.121864/  2.581174, val:  73.33%, val_best:  74.58%, tr:  99.90%, tr_best: 100.00%\n",
      "epoch-90  lr=['0.0100000'], tr/val_loss:  0.118482/  2.658443, val:  71.25%, val_best:  74.58%, tr:  99.80%, tr_best: 100.00%\n",
      "epoch-91  lr=['0.0100000'], tr/val_loss:  0.111355/  2.656394, val:  72.50%, val_best:  74.58%, tr:  99.80%, tr_best: 100.00%\n",
      "epoch-92  lr=['0.0100000'], tr/val_loss:  0.093434/  2.589508, val:  72.50%, val_best:  74.58%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-93  lr=['0.0100000'], tr/val_loss:  0.082917/  2.743308, val:  72.50%, val_best:  74.58%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-94  lr=['0.0100000'], tr/val_loss:  0.079807/  2.784933, val:  72.50%, val_best:  74.58%, tr:  99.90%, tr_best: 100.00%\n",
      "epoch-95  lr=['0.0100000'], tr/val_loss:  0.084540/  2.748539, val:  73.33%, val_best:  74.58%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-96  lr=['0.0100000'], tr/val_loss:  0.095694/  2.796452, val:  74.58%, val_best:  74.58%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-97  lr=['0.0100000'], tr/val_loss:  0.094616/  2.809004, val:  73.75%, val_best:  74.58%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-98  lr=['0.0100000'], tr/val_loss:  0.088823/  2.759193, val:  72.08%, val_best:  74.58%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-99  lr=['0.0100000'], tr/val_loss:  0.084213/  2.845663, val:  72.08%, val_best:  74.58%, tr: 100.00%, tr_best: 100.00%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c309dcdd7f6841ce9415fca8a13b67aa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.006 MB of 0.006 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>iter_acc</td><td>▁▆▄▄▅▆▇▄▆▇▇▇▇▆▇██▇█▇████████████████▇███</td></tr><tr><td>summary_val_acc</td><td>▁▄▄▅▅▇▆▆▅▄▆▇▅▆▆▆▇▇▇▇██▇██▇▇██▇▇▇▇▇█▇████</td></tr><tr><td>tr_acc</td><td>▁▄▅▅▆▆▆▇▆▇▇▇▇▇▇█████████████████████████</td></tr><tr><td>tr_epoch_loss</td><td>█▅▅▄▄▄▃▃▃▃▃▃▂▂▂▂▂▂▂▂▂▂▂▁▁▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_acc_best</td><td>▁▄▄▅▅▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇████████████████████</td></tr><tr><td>val_acc_now</td><td>▁▄▄▅▅▇▆▆▅▄▆▇▅▆▆▆▇▇▇▇██▇██▇▇██▇▇▇▇▇█▇████</td></tr><tr><td>val_loss</td><td>▃▂▂▁▂▁▂▁▂▃▂▂▃▂▂▄▃▃▄▄▄▄▄▅▅▅▅▆▆▇▆▆▆▇▇▇▇▇██</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>99</td></tr><tr><td>iter_acc</td><td>1.0</td></tr><tr><td>tr_acc</td><td>1.0</td></tr><tr><td>tr_epoch_loss</td><td>0.08421</td></tr><tr><td>val_acc_best</td><td>0.74583</td></tr><tr><td>val_acc_now</td><td>0.72083</td></tr><tr><td>val_loss</td><td>2.84566</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">summer-sweep-246</strong> at: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/7hdwoz7j' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/7hdwoz7j</a><br/> View project at: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>/data2/bh_wandb/wandb/run-20250430_081831-7hdwoz7j/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require(\"core\")`! See https://wandb.me/wandb-core for more information."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Sweep Agent: Waiting for job.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Job received.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: pr30xfu2 with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBATCH: 16\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBN_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBPTT_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tDFA_on: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tIMAGE_SIZE: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tOTTT_input_trace_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tTIME: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tUDA_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \talpha_uda: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbias: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcfg: ['M', 'M', 200, 200]\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tchaching_on: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tconvTrue_fcFalse: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdata_path: /data2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tddp_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdenoise_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdvs_clipping: 5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdvs_duration: 100000\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepoch_num: 100\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \texclude_class: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \textra_train_dataset: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlast_lif: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.001\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_sg_width: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_decay: 0.5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_init: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_reset: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_threshold: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmerge_polarities: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmy_seed: 42\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnet_print: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_workers: 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer_what: SGD\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tpin_memory: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tpre_trained: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tpre_trained_path: net_save/save_now_net_weights_{unique_name}.pth\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \trate_coding: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tscheduler_name: no\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsingle_step: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsurrogate: hard_sigmoid\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_conv_kernel_size: 3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_conv_padding: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_conv_stride: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_trace_const1: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_trace_const2: 0.5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \ttdBN_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \ttrace_on: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \twhich_data: DVS_GESTURE_TONIC\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.19.10 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.17.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/data2/bh_wandb/wandb/run-20250430_082433-pr30xfu2</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/pr30xfu2' target=\"_blank\">divine-sweep-248</a></strong> to <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/6pj3lh8j' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/6pj3lh8j</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/6pj3lh8j' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/6pj3lh8j</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/pr30xfu2' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/pr30xfu2</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'single_step' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'my_seed' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'TIME' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BATCH' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'IMAGE_SIZE' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'which_data' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'data_path' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'rate_coding' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_init' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_decay' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_threshold' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_reset' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_sg_width' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_conv_kernel_size' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_conv_stride' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_conv_padding' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_trace_const1' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_trace_const2' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'pre_trained' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'convTrue_fcFalse' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'cfg' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'net_print' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'pre_trained_path' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'learning_rate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'epoch_num' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'tdBN_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BN_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'surrogate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BPTT_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'optimizer_what' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'scheduler_name' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'ddp_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'dvs_clipping' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'dvs_duration' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'DFA_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'trace_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'OTTT_input_trace_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'exclude_class' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'merge_polarities' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'denoise_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'extra_train_dataset' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'num_workers' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'chaching_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'pin_memory' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'UDA_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'alpha_uda' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'bias' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'last_lif' was locked by 'sweep' (ignored update).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "param {'devices': '0', 'single_step': True, 'unique_name': 'main', 'my_seed': 42, 'TIME': 10, 'BATCH': 16, 'IMAGE_SIZE': 128, 'which_data': 'DVS_GESTURE_TONIC', 'data_path': '/data2', 'rate_coding': False, 'lif_layer_v_init': 0, 'lif_layer_v_decay': 0.5, 'lif_layer_v_threshold': 1, 'lif_layer_v_reset': 0, 'lif_layer_sg_width': 1, 'synapse_conv_kernel_size': 3, 'synapse_conv_stride': 1, 'synapse_conv_padding': 1, 'synapse_trace_const1': 1, 'synapse_trace_const2': 0.5, 'pre_trained': False, 'convTrue_fcFalse': False, 'cfg': ['M', 'M', 200, 200], 'net_print': True, 'pre_trained_path': 'net_save/save_now_net_weights_{unique_name}.pth', 'learning_rate': 0.001, 'epoch_num': 100, 'tdBN_on': False, 'BN_on': False, 'surrogate': 'hard_sigmoid', 'BPTT_on': False, 'optimizer_what': 'SGD', 'scheduler_name': 'no', 'ddp_on': False, 'dvs_clipping': 5, 'dvs_duration': 100000, 'DFA_on': True, 'trace_on': True, 'OTTT_input_trace_on': False, 'exclude_class': True, 'merge_polarities': False, 'denoise_on': False, 'extra_train_dataset': 0, 'num_workers': 2, 'chaching_on': True, 'pin_memory': True, 'UDA_on': False, 'alpha_uda': 1, 'bias': True, 'last_lif': False, 'current epoch': 0} \n",
      "\n",
      "dataset_hash = ffa516e60c3efd5e0208f72b4c36cb84\n",
      "cache path exists\n",
      "\n",
      "device ==> cuda\n",
      "\n",
      "DataParallel(\n",
      "  (module): REBORN_MY_SNN_FC(\n",
      "    (layers): REBORN_MY_Sequential(\n",
      "      (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (2): DimChanger_for_FC()\n",
      "      (3): SYNAPSE_FC(in_features=2048, out_features=200, TIME=10, bias=True, sstep=True)\n",
      "      (4): LIF_layer(v_init=0, v_decay=0.5, v_threshold=1, v_reset=0, sg_width=1, surrogate=hard_sigmoid, BPTT_on=False, trace_const1=1, trace_const2=0.5, TIME=10, sstep=True, trace_on=True)\n",
      "      (5): Feedback_Receiver()\n",
      "      (6): SYNAPSE_FC(in_features=200, out_features=200, TIME=10, bias=True, sstep=True)\n",
      "      (7): LIF_layer(v_init=0, v_decay=0.5, v_threshold=1, v_reset=0, sg_width=1, surrogate=hard_sigmoid, BPTT_on=False, trace_const1=1, trace_const2=0.5, TIME=10, sstep=True, trace_on=True)\n",
      "      (8): Feedback_Receiver()\n",
      "      (9): SYNAPSE_FC(in_features=200, out_features=10, TIME=10, bias=True, sstep=True)\n",
      "      (DFA_top): Top_Gradient()\n",
      "    )\n",
      "  )\n",
      ")\n",
      "\n",
      "========================================================\n",
      "Trainable parameters: 452,010\n",
      "========================================================\n",
      "\n",
      "epoch-0   lr=['0.0010000'], tr/val_loss:  2.305365/  2.302841, val:  10.00%, val_best:  10.00%, tr:   8.17%, tr_best:   8.17%\n",
      "[module.layers.5] weight_fb parameter count: 2,000\n",
      "[module.layers.8] weight_fb parameter count: 2,000\n",
      "epoch-1   lr=['0.0010000'], tr/val_loss:  2.304374/  2.299635, val:   6.67%, val_best:  10.00%, tr:   7.97%, tr_best:   8.17%\n",
      "epoch-2   lr=['0.0010000'], tr/val_loss:  2.197280/  2.058508, val:  28.75%, val_best:  28.75%, tr:  19.61%, tr_best:  19.61%\n",
      "epoch-3   lr=['0.0010000'], tr/val_loss:  1.839323/  1.775866, val:  42.50%, val_best:  42.50%, tr:  43.92%, tr_best:  43.92%\n",
      "epoch-4   lr=['0.0010000'], tr/val_loss:  1.597310/  1.686410, val:  45.00%, val_best:  45.00%, tr:  50.46%, tr_best:  50.46%\n",
      "epoch-5   lr=['0.0010000'], tr/val_loss:  1.481050/  1.615976, val:  50.42%, val_best:  50.42%, tr:  54.14%, tr_best:  54.14%\n",
      "epoch-6   lr=['0.0010000'], tr/val_loss:  1.427966/  1.580297, val:  52.50%, val_best:  52.50%, tr:  58.94%, tr_best:  58.94%\n",
      "epoch-7   lr=['0.0010000'], tr/val_loss:  1.379950/  1.556726, val:  53.33%, val_best:  53.33%, tr:  58.22%, tr_best:  58.94%\n",
      "epoch-8   lr=['0.0010000'], tr/val_loss:  1.342350/  1.537640, val:  55.42%, val_best:  55.42%, tr:  59.24%, tr_best:  59.24%\n",
      "epoch-9   lr=['0.0010000'], tr/val_loss:  1.314457/  1.505494, val:  55.42%, val_best:  55.42%, tr:  61.90%, tr_best:  61.90%\n",
      "epoch-10  lr=['0.0010000'], tr/val_loss:  1.296664/  1.533799, val:  55.83%, val_best:  55.83%, tr:  60.57%, tr_best:  61.90%\n",
      "epoch-11  lr=['0.0010000'], tr/val_loss:  1.266336/  1.485144, val:  58.33%, val_best:  58.33%, tr:  63.02%, tr_best:  63.02%\n",
      "epoch-12  lr=['0.0010000'], tr/val_loss:  1.259606/  1.497879, val:  55.42%, val_best:  58.33%, tr:  64.66%, tr_best:  64.66%\n",
      "epoch-13  lr=['0.0010000'], tr/val_loss:  1.256024/  1.515892, val:  57.50%, val_best:  58.33%, tr:  62.21%, tr_best:  64.66%\n",
      "epoch-14  lr=['0.0010000'], tr/val_loss:  1.204026/  1.581016, val:  57.50%, val_best:  58.33%, tr:  64.35%, tr_best:  64.66%\n",
      "epoch-15  lr=['0.0010000'], tr/val_loss:  1.193279/  1.487236, val:  60.42%, val_best:  60.42%, tr:  66.70%, tr_best:  66.70%\n",
      "epoch-16  lr=['0.0010000'], tr/val_loss:  1.191211/  1.490985, val:  58.33%, val_best:  60.42%, tr:  65.37%, tr_best:  66.70%\n",
      "epoch-17  lr=['0.0010000'], tr/val_loss:  1.160727/  1.461730, val:  63.33%, val_best:  63.33%, tr:  69.66%, tr_best:  69.66%\n",
      "epoch-18  lr=['0.0010000'], tr/val_loss:  1.141790/  1.534175, val:  60.83%, val_best:  63.33%, tr:  68.54%, tr_best:  69.66%\n",
      "epoch-19  lr=['0.0010000'], tr/val_loss:  1.137603/  1.532426, val:  57.92%, val_best:  63.33%, tr:  69.25%, tr_best:  69.66%\n",
      "epoch-20  lr=['0.0010000'], tr/val_loss:  1.118186/  1.533040, val:  59.17%, val_best:  63.33%, tr:  69.56%, tr_best:  69.66%\n",
      "epoch-21  lr=['0.0010000'], tr/val_loss:  1.106885/  1.512548, val:  62.08%, val_best:  63.33%, tr:  71.09%, tr_best:  71.09%\n",
      "epoch-22  lr=['0.0010000'], tr/val_loss:  1.117360/  1.550229, val:  60.42%, val_best:  63.33%, tr:  70.68%, tr_best:  71.09%\n",
      "epoch-23  lr=['0.0010000'], tr/val_loss:  1.079232/  1.540204, val:  62.92%, val_best:  63.33%, tr:  73.34%, tr_best:  73.34%\n",
      "epoch-24  lr=['0.0010000'], tr/val_loss:  1.078699/  1.581895, val:  60.42%, val_best:  63.33%, tr:  74.36%, tr_best:  74.36%\n",
      "epoch-25  lr=['0.0010000'], tr/val_loss:  1.066981/  1.533974, val:  67.92%, val_best:  67.92%, tr:  74.57%, tr_best:  74.57%\n",
      "epoch-26  lr=['0.0010000'], tr/val_loss:  1.063107/  1.525718, val:  67.50%, val_best:  67.92%, tr:  75.08%, tr_best:  75.08%\n",
      "epoch-27  lr=['0.0010000'], tr/val_loss:  1.036752/  1.592986, val:  64.58%, val_best:  67.92%, tr:  76.92%, tr_best:  76.92%\n",
      "epoch-28  lr=['0.0010000'], tr/val_loss:  1.049563/  1.578045, val:  67.08%, val_best:  67.92%, tr:  77.83%, tr_best:  77.83%\n",
      "epoch-29  lr=['0.0010000'], tr/val_loss:  1.005791/  1.636983, val:  61.67%, val_best:  67.92%, tr:  79.37%, tr_best:  79.37%\n",
      "epoch-30  lr=['0.0010000'], tr/val_loss:  0.999990/  1.652911, val:  62.50%, val_best:  67.92%, tr:  81.82%, tr_best:  81.82%\n",
      "epoch-31  lr=['0.0010000'], tr/val_loss:  1.043386/  1.689833, val:  63.33%, val_best:  67.92%, tr:  78.14%, tr_best:  81.82%\n",
      "epoch-32  lr=['0.0010000'], tr/val_loss:  1.015183/  1.681602, val:  67.08%, val_best:  67.92%, tr:  81.00%, tr_best:  81.82%\n",
      "epoch-33  lr=['0.0010000'], tr/val_loss:  1.005350/  1.712121, val:  67.08%, val_best:  67.92%, tr:  82.53%, tr_best:  82.53%\n",
      "epoch-34  lr=['0.0010000'], tr/val_loss:  0.978159/  1.727949, val:  62.50%, val_best:  67.92%, tr:  82.94%, tr_best:  82.94%\n",
      "epoch-35  lr=['0.0010000'], tr/val_loss:  0.997581/  1.801120, val:  62.50%, val_best:  67.92%, tr:  79.78%, tr_best:  82.94%\n",
      "epoch-36  lr=['0.0010000'], tr/val_loss:  0.959987/  1.750764, val:  66.25%, val_best:  67.92%, tr:  84.47%, tr_best:  84.47%\n",
      "epoch-37  lr=['0.0010000'], tr/val_loss:  0.956224/  1.744513, val:  67.92%, val_best:  67.92%, tr:  85.50%, tr_best:  85.50%\n",
      "epoch-38  lr=['0.0010000'], tr/val_loss:  0.954652/  1.764015, val:  65.83%, val_best:  67.92%, tr:  86.62%, tr_best:  86.62%\n",
      "epoch-39  lr=['0.0010000'], tr/val_loss:  0.950876/  1.811654, val:  65.42%, val_best:  67.92%, tr:  87.54%, tr_best:  87.54%\n",
      "epoch-40  lr=['0.0010000'], tr/val_loss:  0.960224/  1.847135, val:  65.83%, val_best:  67.92%, tr:  85.50%, tr_best:  87.54%\n",
      "epoch-41  lr=['0.0010000'], tr/val_loss:  0.959540/  1.866900, val:  61.67%, val_best:  67.92%, tr:  88.25%, tr_best:  88.25%\n",
      "epoch-42  lr=['0.0010000'], tr/val_loss:  0.927410/  1.887729, val:  64.58%, val_best:  67.92%, tr:  88.76%, tr_best:  88.76%\n",
      "epoch-43  lr=['0.0010000'], tr/val_loss:  0.934468/  1.925532, val:  67.50%, val_best:  67.92%, tr:  89.07%, tr_best:  89.07%\n",
      "epoch-44  lr=['0.0010000'], tr/val_loss:  0.918325/  1.923809, val:  68.33%, val_best:  68.33%, tr:  88.36%, tr_best:  89.07%\n",
      "epoch-45  lr=['0.0010000'], tr/val_loss:  0.921361/  1.978947, val:  67.50%, val_best:  68.33%, tr:  89.27%, tr_best:  89.27%\n",
      "epoch-46  lr=['0.0010000'], tr/val_loss:  0.910413/  1.979244, val:  67.08%, val_best:  68.33%, tr:  90.70%, tr_best:  90.70%\n",
      "epoch-47  lr=['0.0010000'], tr/val_loss:  0.914306/  2.044676, val:  66.25%, val_best:  68.33%, tr:  91.22%, tr_best:  91.22%\n",
      "epoch-48  lr=['0.0010000'], tr/val_loss:  0.917385/  2.018812, val:  68.33%, val_best:  68.33%, tr:  92.03%, tr_best:  92.03%\n",
      "epoch-49  lr=['0.0010000'], tr/val_loss:  0.918221/  2.048461, val:  70.83%, val_best:  70.83%, tr:  91.11%, tr_best:  92.03%\n",
      "epoch-50  lr=['0.0010000'], tr/val_loss:  0.920258/  2.120745, val:  67.50%, val_best:  70.83%, tr:  91.93%, tr_best:  92.03%\n",
      "epoch-51  lr=['0.0010000'], tr/val_loss:  0.915812/  2.137349, val:  67.08%, val_best:  70.83%, tr:  90.09%, tr_best:  92.03%\n",
      "epoch-52  lr=['0.0010000'], tr/val_loss:  0.902635/  2.163193, val:  64.58%, val_best:  70.83%, tr:  92.03%, tr_best:  92.03%\n",
      "epoch-53  lr=['0.0010000'], tr/val_loss:  0.900816/  2.170486, val:  67.50%, val_best:  70.83%, tr:  92.34%, tr_best:  92.34%\n",
      "epoch-54  lr=['0.0010000'], tr/val_loss:  0.890100/  2.250692, val:  67.92%, val_best:  70.83%, tr:  92.24%, tr_best:  92.34%\n",
      "epoch-55  lr=['0.0010000'], tr/val_loss:  0.895196/  2.240507, val:  67.50%, val_best:  70.83%, tr:  93.05%, tr_best:  93.05%\n",
      "epoch-56  lr=['0.0010000'], tr/val_loss:  0.882567/  2.295749, val:  67.08%, val_best:  70.83%, tr:  94.59%, tr_best:  94.59%\n",
      "epoch-57  lr=['0.0010000'], tr/val_loss:  0.889395/  2.329280, val:  67.50%, val_best:  70.83%, tr:  93.77%, tr_best:  94.59%\n",
      "epoch-58  lr=['0.0010000'], tr/val_loss:  0.876968/  2.387404, val:  65.00%, val_best:  70.83%, tr:  94.18%, tr_best:  94.59%\n",
      "epoch-59  lr=['0.0010000'], tr/val_loss:  0.873688/  2.408730, val:  69.17%, val_best:  70.83%, tr:  94.69%, tr_best:  94.69%\n",
      "epoch-60  lr=['0.0010000'], tr/val_loss:  0.879394/  2.429233, val:  66.25%, val_best:  70.83%, tr:  94.59%, tr_best:  94.69%\n",
      "epoch-61  lr=['0.0010000'], tr/val_loss:  0.873123/  2.469038, val:  67.92%, val_best:  70.83%, tr:  94.89%, tr_best:  94.89%\n",
      "epoch-62  lr=['0.0010000'], tr/val_loss:  0.882174/  2.537404, val:  66.67%, val_best:  70.83%, tr:  94.99%, tr_best:  94.99%\n",
      "epoch-63  lr=['0.0010000'], tr/val_loss:  0.871209/  2.497063, val:  68.33%, val_best:  70.83%, tr:  94.89%, tr_best:  94.99%\n",
      "epoch-64  lr=['0.0010000'], tr/val_loss:  0.874219/  2.560055, val:  67.92%, val_best:  70.83%, tr:  95.10%, tr_best:  95.10%\n",
      "epoch-65  lr=['0.0010000'], tr/val_loss:  0.868631/  2.614784, val:  67.92%, val_best:  70.83%, tr:  95.40%, tr_best:  95.40%\n",
      "epoch-66  lr=['0.0010000'], tr/val_loss:  0.867508/  2.659272, val:  65.00%, val_best:  70.83%, tr:  96.42%, tr_best:  96.42%\n",
      "epoch-67  lr=['0.0010000'], tr/val_loss:  0.898721/  2.654312, val:  67.08%, val_best:  70.83%, tr:  95.71%, tr_best:  96.42%\n",
      "epoch-68  lr=['0.0010000'], tr/val_loss:  0.868245/  2.733796, val:  63.33%, val_best:  70.83%, tr:  95.40%, tr_best:  96.42%\n",
      "epoch-69  lr=['0.0010000'], tr/val_loss:  0.870986/  2.765218, val:  63.75%, val_best:  70.83%, tr:  95.51%, tr_best:  96.42%\n",
      "epoch-70  lr=['0.0010000'], tr/val_loss:  0.859034/  2.727818, val:  69.58%, val_best:  70.83%, tr:  96.12%, tr_best:  96.42%\n",
      "epoch-71  lr=['0.0010000'], tr/val_loss:  0.865933/  2.856556, val:  63.75%, val_best:  70.83%, tr:  96.12%, tr_best:  96.42%\n",
      "epoch-72  lr=['0.0010000'], tr/val_loss:  0.854863/  2.867594, val:  67.08%, val_best:  70.83%, tr:  96.83%, tr_best:  96.83%\n",
      "epoch-73  lr=['0.0010000'], tr/val_loss:  0.875097/  2.899873, val:  65.42%, val_best:  70.83%, tr:  95.71%, tr_best:  96.83%\n",
      "epoch-74  lr=['0.0010000'], tr/val_loss:  0.850333/  2.929080, val:  66.25%, val_best:  70.83%, tr:  96.32%, tr_best:  96.83%\n",
      "epoch-75  lr=['0.0010000'], tr/val_loss:  0.839993/  2.949992, val:  66.25%, val_best:  70.83%, tr:  96.22%, tr_best:  96.83%\n",
      "epoch-76  lr=['0.0010000'], tr/val_loss:  0.848668/  3.009877, val:  65.42%, val_best:  70.83%, tr:  96.53%, tr_best:  96.83%\n",
      "epoch-77  lr=['0.0010000'], tr/val_loss:  0.853499/  3.032028, val:  67.92%, val_best:  70.83%, tr:  97.04%, tr_best:  97.04%\n",
      "epoch-78  lr=['0.0010000'], tr/val_loss:  0.863954/  3.071200, val:  65.83%, val_best:  70.83%, tr:  97.04%, tr_best:  97.04%\n",
      "epoch-79  lr=['0.0010000'], tr/val_loss:  0.848963/  3.073809, val:  65.42%, val_best:  70.83%, tr:  96.94%, tr_best:  97.04%\n",
      "epoch-80  lr=['0.0010000'], tr/val_loss:  0.840370/  3.178583, val:  67.08%, val_best:  70.83%, tr:  96.53%, tr_best:  97.04%\n",
      "epoch-81  lr=['0.0010000'], tr/val_loss:  0.845689/  3.152691, val:  67.08%, val_best:  70.83%, tr:  96.63%, tr_best:  97.04%\n",
      "epoch-82  lr=['0.0010000'], tr/val_loss:  0.842123/  3.242631, val:  66.25%, val_best:  70.83%, tr:  97.34%, tr_best:  97.34%\n",
      "epoch-83  lr=['0.0010000'], tr/val_loss:  0.847314/  3.239038, val:  67.92%, val_best:  70.83%, tr:  96.83%, tr_best:  97.34%\n",
      "epoch-84  lr=['0.0010000'], tr/val_loss:  0.822374/  3.343992, val:  63.33%, val_best:  70.83%, tr:  97.34%, tr_best:  97.34%\n",
      "epoch-85  lr=['0.0010000'], tr/val_loss:  0.835723/  3.338382, val:  67.50%, val_best:  70.83%, tr:  97.14%, tr_best:  97.34%\n",
      "epoch-86  lr=['0.0010000'], tr/val_loss:  0.845128/  3.424592, val:  67.92%, val_best:  70.83%, tr:  96.42%, tr_best:  97.34%\n",
      "epoch-87  lr=['0.0010000'], tr/val_loss:  0.835686/  3.495909, val:  68.33%, val_best:  70.83%, tr:  97.65%, tr_best:  97.65%\n",
      "epoch-88  lr=['0.0010000'], tr/val_loss:  0.831344/  3.498628, val:  69.58%, val_best:  70.83%, tr:  97.45%, tr_best:  97.65%\n",
      "epoch-89  lr=['0.0010000'], tr/val_loss:  0.824977/  3.559321, val:  66.67%, val_best:  70.83%, tr:  97.85%, tr_best:  97.85%\n",
      "epoch-90  lr=['0.0010000'], tr/val_loss:  0.840590/  3.528235, val:  69.17%, val_best:  70.83%, tr:  97.85%, tr_best:  97.85%\n",
      "epoch-91  lr=['0.0010000'], tr/val_loss:  0.840373/  3.590786, val:  67.50%, val_best:  70.83%, tr:  97.96%, tr_best:  97.96%\n",
      "epoch-92  lr=['0.0010000'], tr/val_loss:  0.828343/  3.758821, val:  67.50%, val_best:  70.83%, tr:  98.26%, tr_best:  98.26%\n",
      "epoch-93  lr=['0.0010000'], tr/val_loss:  0.835409/  3.696653, val:  66.67%, val_best:  70.83%, tr:  97.85%, tr_best:  98.26%\n",
      "epoch-94  lr=['0.0010000'], tr/val_loss:  0.816047/  3.776576, val:  68.33%, val_best:  70.83%, tr:  98.16%, tr_best:  98.26%\n",
      "epoch-95  lr=['0.0010000'], tr/val_loss:  0.819273/  3.823885, val:  67.50%, val_best:  70.83%, tr:  98.26%, tr_best:  98.26%\n",
      "epoch-96  lr=['0.0010000'], tr/val_loss:  0.822703/  3.900467, val:  67.08%, val_best:  70.83%, tr:  97.65%, tr_best:  98.26%\n",
      "epoch-97  lr=['0.0010000'], tr/val_loss:  0.827357/  3.864823, val:  69.58%, val_best:  70.83%, tr:  97.55%, tr_best:  98.26%\n",
      "epoch-98  lr=['0.0010000'], tr/val_loss:  0.816174/  3.950669, val:  67.08%, val_best:  70.83%, tr:  98.16%, tr_best:  98.26%\n",
      "epoch-99  lr=['0.0010000'], tr/val_loss:  0.846256/  3.934578, val:  66.67%, val_best:  70.83%, tr:  97.96%, tr_best:  98.26%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6ade7a57ea2e4ab7870fdddd118fe4e1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.006 MB of 0.006 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>iter_acc</td><td>▁▃▃▃▅▅▆▃▅▇█▇█▇▆▇███▇██▇██████▇██▆███████</td></tr><tr><td>summary_val_acc</td><td>▁▃▅▆▆▆▆▇▇▇▇█▇█▇█▇▇█▇█▇████████▇█▇▇▇█████</td></tr><tr><td>tr_acc</td><td>▁▂▄▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇▇▇▇███████████████████</td></tr><tr><td>tr_epoch_loss</td><td>█▇▅▄▃▃▃▃▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_acc_best</td><td>▁▃▅▆▆▇▇▇▇▇▇█████████████████████████████</td></tr><tr><td>val_acc_now</td><td>▁▃▅▆▆▆▆▇▇▇▇█▇█▇█▇▇█▇█▇████████▇█▇▇▇█████</td></tr><tr><td>val_loss</td><td>▃▃▂▁▁▁▁▁▁▁▁▁▂▂▂▂▂▂▂▃▃▃▃▄▄▄▄▄▅▅▅▆▆▆▆▇▇███</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>99</td></tr><tr><td>iter_acc</td><td>1.0</td></tr><tr><td>tr_acc</td><td>0.97957</td></tr><tr><td>tr_epoch_loss</td><td>0.84626</td></tr><tr><td>val_acc_best</td><td>0.70833</td></tr><tr><td>val_acc_now</td><td>0.66667</td></tr><tr><td>val_loss</td><td>3.93458</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">divine-sweep-248</strong> at: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/pr30xfu2' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/pr30xfu2</a><br/> View project at: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>/data2/bh_wandb/wandb/run-20250430_082433-pr30xfu2/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require(\"core\")`! See https://wandb.me/wandb-core for more information."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 1trhzvd1 with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBATCH: 16\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBN_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBPTT_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tDFA_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tIMAGE_SIZE: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tOTTT_input_trace_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tTIME: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tUDA_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \talpha_uda: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbias: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcfg: ['M', 'M', 200, 200]\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tchaching_on: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tconvTrue_fcFalse: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdata_path: /data2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tddp_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdenoise_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdvs_clipping: 5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdvs_duration: 100000\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepoch_num: 100\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \texclude_class: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \textra_train_dataset: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlast_lif: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.001\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_sg_width: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_decay: 0.5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_init: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_reset: 10000\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_threshold: 0.25\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmerge_polarities: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmy_seed: 42\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnet_print: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_workers: 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer_what: SGD\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tpin_memory: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tpre_trained: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tpre_trained_path: net_save/save_now_net_weights_{unique_name}.pth\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \trate_coding: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tscheduler_name: no\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsingle_step: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsurrogate: hard_sigmoid\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_conv_kernel_size: 3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_conv_padding: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_conv_stride: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_trace_const1: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_trace_const2: 0.5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \ttdBN_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \ttrace_on: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \twhich_data: DVS_GESTURE_TONIC\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c98d27870f37476daf1f7eabb0407d2d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.011113486418293583, max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.19.10 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.17.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/data2/bh_wandb/wandb/run-20250430_083107-1trhzvd1</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/1trhzvd1' target=\"_blank\">mild-sweep-250</a></strong> to <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/6pj3lh8j' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/6pj3lh8j</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/6pj3lh8j' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/6pj3lh8j</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/1trhzvd1' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/1trhzvd1</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'single_step' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'my_seed' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'TIME' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BATCH' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'IMAGE_SIZE' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'which_data' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'data_path' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'rate_coding' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_init' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_decay' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_threshold' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_reset' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_sg_width' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_conv_kernel_size' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_conv_stride' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_conv_padding' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_trace_const1' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_trace_const2' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'pre_trained' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'convTrue_fcFalse' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'cfg' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'net_print' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'pre_trained_path' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'learning_rate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'epoch_num' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'tdBN_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BN_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'surrogate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BPTT_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'optimizer_what' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'scheduler_name' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'ddp_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'dvs_clipping' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'dvs_duration' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'DFA_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'trace_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'OTTT_input_trace_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'exclude_class' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'merge_polarities' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'denoise_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'extra_train_dataset' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'num_workers' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'chaching_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'pin_memory' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'UDA_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'alpha_uda' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'bias' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'last_lif' was locked by 'sweep' (ignored update).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "param {'devices': '0', 'single_step': True, 'unique_name': 'main', 'my_seed': 42, 'TIME': 10, 'BATCH': 16, 'IMAGE_SIZE': 128, 'which_data': 'DVS_GESTURE_TONIC', 'data_path': '/data2', 'rate_coding': False, 'lif_layer_v_init': 0, 'lif_layer_v_decay': 0.5, 'lif_layer_v_threshold': 0.25, 'lif_layer_v_reset': 10000, 'lif_layer_sg_width': 1, 'synapse_conv_kernel_size': 3, 'synapse_conv_stride': 1, 'synapse_conv_padding': 1, 'synapse_trace_const1': 1, 'synapse_trace_const2': 0.5, 'pre_trained': False, 'convTrue_fcFalse': False, 'cfg': ['M', 'M', 200, 200], 'net_print': True, 'pre_trained_path': 'net_save/save_now_net_weights_{unique_name}.pth', 'learning_rate': 0.001, 'epoch_num': 100, 'tdBN_on': False, 'BN_on': False, 'surrogate': 'hard_sigmoid', 'BPTT_on': False, 'optimizer_what': 'SGD', 'scheduler_name': 'no', 'ddp_on': False, 'dvs_clipping': 5, 'dvs_duration': 100000, 'DFA_on': False, 'trace_on': True, 'OTTT_input_trace_on': False, 'exclude_class': True, 'merge_polarities': False, 'denoise_on': False, 'extra_train_dataset': 0, 'num_workers': 2, 'chaching_on': True, 'pin_memory': True, 'UDA_on': False, 'alpha_uda': 1, 'bias': True, 'last_lif': False, 'current epoch': 0} \n",
      "\n",
      "dataset_hash = ffa516e60c3efd5e0208f72b4c36cb84\n",
      "cache path exists\n",
      "\n",
      "device ==> cuda\n",
      "\n",
      "DataParallel(\n",
      "  (module): REBORN_MY_SNN_FC(\n",
      "    (layers): REBORN_MY_Sequential(\n",
      "      (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (2): DimChanger_for_FC()\n",
      "      (3): SYNAPSE_FC(in_features=2048, out_features=200, TIME=10, bias=True, sstep=True)\n",
      "      (4): LIF_layer(v_init=0, v_decay=0.5, v_threshold=0.25, v_reset=10000, sg_width=1, surrogate=hard_sigmoid, BPTT_on=False, trace_const1=1, trace_const2=0.5, TIME=10, sstep=True, trace_on=True)\n",
      "      (5): SYNAPSE_FC(in_features=200, out_features=200, TIME=10, bias=True, sstep=True)\n",
      "      (6): LIF_layer(v_init=0, v_decay=0.5, v_threshold=0.25, v_reset=10000, sg_width=1, surrogate=hard_sigmoid, BPTT_on=False, trace_const1=1, trace_const2=0.5, TIME=10, sstep=True, trace_on=True)\n",
      "      (7): SYNAPSE_FC(in_features=200, out_features=10, TIME=10, bias=True, sstep=True)\n",
      "    )\n",
      "  )\n",
      ")\n",
      "\n",
      "========================================================\n",
      "Trainable parameters: 452,010\n",
      "========================================================\n",
      "\n",
      "epoch-0   lr=['0.0010000'], tr/val_loss:  2.253038/  2.173000, val:  23.33%, val_best:  23.33%, tr:  17.98%, tr_best:  17.98%\n",
      "epoch-1   lr=['0.0010000'], tr/val_loss:  2.026780/  1.935571, val:  45.00%, val_best:  45.00%, tr:  35.04%, tr_best:  35.04%\n",
      "epoch-2   lr=['0.0010000'], tr/val_loss:  1.752048/  1.739368, val:  46.67%, val_best:  46.67%, tr:  48.31%, tr_best:  48.31%\n",
      "epoch-3   lr=['0.0010000'], tr/val_loss:  1.557782/  1.628005, val:  52.50%, val_best:  52.50%, tr:  57.41%, tr_best:  57.41%\n",
      "epoch-4   lr=['0.0010000'], tr/val_loss:  1.465136/  1.600983, val:  51.67%, val_best:  52.50%, tr:  57.81%, tr_best:  57.81%\n",
      "epoch-5   lr=['0.0010000'], tr/val_loss:  1.391588/  1.561017, val:  55.83%, val_best:  55.83%, tr:  60.78%, tr_best:  60.78%\n",
      "epoch-6   lr=['0.0010000'], tr/val_loss:  1.353717/  1.543227, val:  56.25%, val_best:  56.25%, tr:  62.31%, tr_best:  62.31%\n",
      "epoch-7   lr=['0.0010000'], tr/val_loss:  1.316330/  1.538760, val:  56.67%, val_best:  56.67%, tr:  63.13%, tr_best:  63.13%\n",
      "epoch-8   lr=['0.0010000'], tr/val_loss:  1.282019/  1.518945, val:  62.50%, val_best:  62.50%, tr:  64.04%, tr_best:  64.04%\n",
      "epoch-9   lr=['0.0010000'], tr/val_loss:  1.258656/  1.524045, val:  60.42%, val_best:  62.50%, tr:  66.60%, tr_best:  66.60%\n",
      "epoch-10  lr=['0.0010000'], tr/val_loss:  1.238890/  1.539262, val:  61.25%, val_best:  62.50%, tr:  66.60%, tr_best:  66.60%\n",
      "epoch-11  lr=['0.0010000'], tr/val_loss:  1.209761/  1.534050, val:  61.25%, val_best:  62.50%, tr:  68.13%, tr_best:  68.13%\n",
      "epoch-12  lr=['0.0010000'], tr/val_loss:  1.195103/  1.544221, val:  60.83%, val_best:  62.50%, tr:  71.50%, tr_best:  71.50%\n",
      "epoch-13  lr=['0.0010000'], tr/val_loss:  1.180459/  1.568970, val:  60.83%, val_best:  62.50%, tr:  70.79%, tr_best:  71.50%\n",
      "epoch-14  lr=['0.0010000'], tr/val_loss:  1.139548/  1.619714, val:  58.75%, val_best:  62.50%, tr:  72.11%, tr_best:  72.11%\n",
      "epoch-15  lr=['0.0010000'], tr/val_loss:  1.143866/  1.595213, val:  63.75%, val_best:  63.75%, tr:  72.93%, tr_best:  72.93%\n",
      "epoch-16  lr=['0.0010000'], tr/val_loss:  1.134778/  1.657060, val:  60.83%, val_best:  63.75%, tr:  73.44%, tr_best:  73.44%\n",
      "epoch-17  lr=['0.0010000'], tr/val_loss:  1.096624/  1.614286, val:  67.50%, val_best:  67.50%, tr:  77.83%, tr_best:  77.83%\n",
      "epoch-18  lr=['0.0010000'], tr/val_loss:  1.072215/  1.762628, val:  61.25%, val_best:  67.50%, tr:  76.61%, tr_best:  77.83%\n",
      "epoch-19  lr=['0.0010000'], tr/val_loss:  1.086517/  1.789464, val:  65.00%, val_best:  67.50%, tr:  74.46%, tr_best:  77.83%\n",
      "epoch-20  lr=['0.0010000'], tr/val_loss:  1.049497/  1.856684, val:  63.33%, val_best:  67.50%, tr:  79.67%, tr_best:  79.67%\n",
      "epoch-21  lr=['0.0010000'], tr/val_loss:  1.046021/  1.884837, val:  65.83%, val_best:  67.50%, tr:  78.65%, tr_best:  79.67%\n",
      "epoch-22  lr=['0.0010000'], tr/val_loss:  1.065267/  1.819382, val:  63.33%, val_best:  67.50%, tr:  76.92%, tr_best:  79.67%\n",
      "epoch-23  lr=['0.0010000'], tr/val_loss:  1.013259/  1.920969, val:  65.83%, val_best:  67.50%, tr:  80.29%, tr_best:  80.29%\n",
      "epoch-24  lr=['0.0010000'], tr/val_loss:  1.008961/  2.005678, val:  60.00%, val_best:  67.50%, tr:  81.00%, tr_best:  81.00%\n",
      "epoch-25  lr=['0.0010000'], tr/val_loss:  0.990891/  2.030458, val:  67.92%, val_best:  67.92%, tr:  82.74%, tr_best:  82.74%\n",
      "epoch-26  lr=['0.0010000'], tr/val_loss:  0.978603/  2.085703, val:  70.00%, val_best:  70.00%, tr:  82.12%, tr_best:  82.74%\n",
      "epoch-27  lr=['0.0010000'], tr/val_loss:  0.961791/  2.132589, val:  69.17%, val_best:  70.00%, tr:  84.98%, tr_best:  84.98%\n",
      "epoch-28  lr=['0.0010000'], tr/val_loss:  0.987977/  2.184265, val:  67.50%, val_best:  70.00%, tr:  82.84%, tr_best:  84.98%\n",
      "epoch-29  lr=['0.0010000'], tr/val_loss:  0.961525/  2.400336, val:  60.42%, val_best:  70.00%, tr:  85.80%, tr_best:  85.80%\n",
      "epoch-30  lr=['0.0010000'], tr/val_loss:  0.930021/  2.360325, val:  62.50%, val_best:  70.00%, tr:  86.72%, tr_best:  86.72%\n",
      "epoch-31  lr=['0.0010000'], tr/val_loss:  0.956652/  2.553732, val:  60.42%, val_best:  70.00%, tr:  83.66%, tr_best:  86.72%\n",
      "epoch-32  lr=['0.0010000'], tr/val_loss:  0.941947/  2.665990, val:  67.50%, val_best:  70.00%, tr:  84.68%, tr_best:  86.72%\n",
      "epoch-33  lr=['0.0010000'], tr/val_loss:  0.943704/  2.717016, val:  67.08%, val_best:  70.00%, tr:  87.54%, tr_best:  87.54%\n",
      "epoch-34  lr=['0.0010000'], tr/val_loss:  0.907623/  2.857964, val:  63.33%, val_best:  70.00%, tr:  86.72%, tr_best:  87.54%\n",
      "epoch-35  lr=['0.0010000'], tr/val_loss:  0.930166/  2.960529, val:  61.25%, val_best:  70.00%, tr:  84.27%, tr_best:  87.54%\n",
      "epoch-36  lr=['0.0010000'], tr/val_loss:  0.904926/  2.720980, val:  67.50%, val_best:  70.00%, tr:  88.66%, tr_best:  88.66%\n",
      "epoch-37  lr=['0.0010000'], tr/val_loss:  0.919800/  2.889791, val:  64.17%, val_best:  70.00%, tr:  91.52%, tr_best:  91.52%\n",
      "epoch-38  lr=['0.0010000'], tr/val_loss:  0.884548/  3.289132, val:  62.50%, val_best:  70.00%, tr:  91.52%, tr_best:  91.52%\n",
      "epoch-39  lr=['0.0010000'], tr/val_loss:  0.912445/  3.193098, val:  63.33%, val_best:  70.00%, tr:  91.22%, tr_best:  91.52%\n",
      "epoch-40  lr=['0.0010000'], tr/val_loss:  0.910746/  3.172052, val:  65.00%, val_best:  70.00%, tr:  90.19%, tr_best:  91.52%\n",
      "epoch-41  lr=['0.0010000'], tr/val_loss:  0.913945/  3.414053, val:  60.00%, val_best:  70.00%, tr:  92.85%, tr_best:  92.85%\n",
      "epoch-42  lr=['0.0010000'], tr/val_loss:  0.868621/  3.295302, val:  68.75%, val_best:  70.00%, tr:  92.85%, tr_best:  92.85%\n",
      "epoch-43  lr=['0.0010000'], tr/val_loss:  0.881658/  3.571119, val:  63.33%, val_best:  70.00%, tr:  92.24%, tr_best:  92.85%\n",
      "epoch-44  lr=['0.0010000'], tr/val_loss:  0.833527/  3.471161, val:  65.83%, val_best:  70.00%, tr:  93.56%, tr_best:  93.56%\n",
      "epoch-45  lr=['0.0010000'], tr/val_loss:  0.856625/  3.679931, val:  65.00%, val_best:  70.00%, tr:  93.67%, tr_best:  93.67%\n",
      "epoch-46  lr=['0.0010000'], tr/val_loss:  0.830722/  3.818266, val:  67.92%, val_best:  70.00%, tr:  94.59%, tr_best:  94.59%\n",
      "epoch-47  lr=['0.0010000'], tr/val_loss:  0.803131/  4.066525, val:  63.33%, val_best:  70.00%, tr:  94.79%, tr_best:  94.79%\n",
      "epoch-48  lr=['0.0010000'], tr/val_loss:  0.885987/  4.139968, val:  63.75%, val_best:  70.00%, tr:  94.28%, tr_best:  94.79%\n",
      "epoch-49  lr=['0.0010000'], tr/val_loss:  0.848485/  4.313849, val:  64.17%, val_best:  70.00%, tr:  93.36%, tr_best:  94.79%\n",
      "epoch-50  lr=['0.0010000'], tr/val_loss:  0.824692/  4.196381, val:  66.67%, val_best:  70.00%, tr:  95.71%, tr_best:  95.71%\n",
      "epoch-51  lr=['0.0010000'], tr/val_loss:  0.805027/  4.313713, val:  69.58%, val_best:  70.00%, tr:  94.28%, tr_best:  95.71%\n",
      "epoch-52  lr=['0.0010000'], tr/val_loss:  0.761314/  4.462420, val:  61.25%, val_best:  70.00%, tr:  96.42%, tr_best:  96.42%\n",
      "epoch-53  lr=['0.0010000'], tr/val_loss:  0.777959/  4.571037, val:  63.75%, val_best:  70.00%, tr:  97.75%, tr_best:  97.75%\n",
      "epoch-54  lr=['0.0010000'], tr/val_loss:  0.802302/  4.706606, val:  67.08%, val_best:  70.00%, tr:  97.04%, tr_best:  97.75%\n",
      "epoch-55  lr=['0.0010000'], tr/val_loss:  0.780965/  4.956008, val:  62.08%, val_best:  70.00%, tr:  95.91%, tr_best:  97.75%\n",
      "epoch-56  lr=['0.0010000'], tr/val_loss:  0.814254/  5.033044, val:  60.00%, val_best:  70.00%, tr:  96.63%, tr_best:  97.75%\n",
      "epoch-57  lr=['0.0010000'], tr/val_loss:  0.831679/  5.065436, val:  65.00%, val_best:  70.00%, tr:  96.63%, tr_best:  97.75%\n",
      "epoch-58  lr=['0.0010000'], tr/val_loss:  0.776620/  5.545824, val:  56.25%, val_best:  70.00%, tr:  94.99%, tr_best:  97.75%\n",
      "epoch-59  lr=['0.0010000'], tr/val_loss:  0.778333/  5.414606, val:  63.33%, val_best:  70.00%, tr:  97.14%, tr_best:  97.75%\n",
      "epoch-60  lr=['0.0010000'], tr/val_loss:  0.765206/  5.232466, val:  63.75%, val_best:  70.00%, tr:  96.02%, tr_best:  97.75%\n",
      "epoch-61  lr=['0.0010000'], tr/val_loss:  0.840708/  5.645066, val:  62.92%, val_best:  70.00%, tr:  97.34%, tr_best:  97.75%\n",
      "epoch-62  lr=['0.0010000'], tr/val_loss:  0.791865/  5.185940, val:  66.67%, val_best:  70.00%, tr:  97.34%, tr_best:  97.75%\n",
      "epoch-63  lr=['0.0010000'], tr/val_loss:  0.738235/  5.504023, val:  60.83%, val_best:  70.00%, tr:  97.85%, tr_best:  97.85%\n",
      "epoch-64  lr=['0.0010000'], tr/val_loss:  0.756905/  5.575567, val:  61.25%, val_best:  70.00%, tr:  95.91%, tr_best:  97.85%\n",
      "epoch-65  lr=['0.0010000'], tr/val_loss:  0.711003/  5.852935, val:  63.75%, val_best:  70.00%, tr:  97.65%, tr_best:  97.85%\n",
      "epoch-66  lr=['0.0010000'], tr/val_loss:  0.703362/  5.521873, val:  63.75%, val_best:  70.00%, tr:  98.47%, tr_best:  98.47%\n",
      "epoch-67  lr=['0.0010000'], tr/val_loss:  0.754949/  5.695776, val:  64.58%, val_best:  70.00%, tr:  97.45%, tr_best:  98.47%\n",
      "epoch-68  lr=['0.0010000'], tr/val_loss:  0.715026/  5.879967, val:  61.67%, val_best:  70.00%, tr:  97.34%, tr_best:  98.47%\n",
      "epoch-69  lr=['0.0010000'], tr/val_loss:  0.780656/  6.028048, val:  63.33%, val_best:  70.00%, tr:  97.24%, tr_best:  98.47%\n",
      "epoch-70  lr=['0.0010000'], tr/val_loss:  0.700441/  5.754661, val:  67.50%, val_best:  70.00%, tr:  98.47%, tr_best:  98.47%\n",
      "epoch-71  lr=['0.0010000'], tr/val_loss:  0.729895/  6.073292, val:  62.92%, val_best:  70.00%, tr:  97.34%, tr_best:  98.47%\n",
      "epoch-72  lr=['0.0010000'], tr/val_loss:  0.727636/  6.084261, val:  61.67%, val_best:  70.00%, tr:  98.67%, tr_best:  98.67%\n",
      "epoch-73  lr=['0.0010000'], tr/val_loss:  0.725847/  6.686327, val:  57.50%, val_best:  70.00%, tr:  97.04%, tr_best:  98.67%\n",
      "epoch-74  lr=['0.0010000'], tr/val_loss:  0.653259/  6.122215, val:  60.83%, val_best:  70.00%, tr:  98.67%, tr_best:  98.67%\n",
      "epoch-75  lr=['0.0010000'], tr/val_loss:  0.685424/  6.553299, val:  60.00%, val_best:  70.00%, tr:  98.16%, tr_best:  98.67%\n",
      "epoch-76  lr=['0.0010000'], tr/val_loss:  0.685890/  6.503175, val:  60.00%, val_best:  70.00%, tr:  97.96%, tr_best:  98.67%\n",
      "epoch-77  lr=['0.0010000'], tr/val_loss:  0.737790/  6.496201, val:  61.67%, val_best:  70.00%, tr:  98.16%, tr_best:  98.67%\n",
      "epoch-78  lr=['0.0010000'], tr/val_loss:  0.709295/  6.628510, val:  60.42%, val_best:  70.00%, tr:  96.42%, tr_best:  98.67%\n",
      "epoch-79  lr=['0.0010000'], tr/val_loss:  0.716888/  6.314411, val:  62.08%, val_best:  70.00%, tr:  98.06%, tr_best:  98.67%\n",
      "epoch-80  lr=['0.0010000'], tr/val_loss:  0.672786/  6.382841, val:  59.58%, val_best:  70.00%, tr:  98.67%, tr_best:  98.67%\n",
      "epoch-81  lr=['0.0010000'], tr/val_loss:  0.623027/  6.508379, val:  62.92%, val_best:  70.00%, tr:  98.47%, tr_best:  98.67%\n",
      "epoch-82  lr=['0.0010000'], tr/val_loss:  0.567596/  6.492025, val:  60.42%, val_best:  70.00%, tr:  98.77%, tr_best:  98.77%\n",
      "epoch-83  lr=['0.0010000'], tr/val_loss:  0.630666/  6.672918, val:  61.25%, val_best:  70.00%, tr:  98.77%, tr_best:  98.77%\n",
      "epoch-84  lr=['0.0010000'], tr/val_loss:  0.615372/  6.293359, val:  66.67%, val_best:  70.00%, tr:  98.88%, tr_best:  98.88%\n",
      "epoch-85  lr=['0.0010000'], tr/val_loss:  0.586511/  6.658834, val:  62.92%, val_best:  70.00%, tr:  99.08%, tr_best:  99.08%\n",
      "epoch-86  lr=['0.0010000'], tr/val_loss:  0.576870/  6.460298, val:  63.33%, val_best:  70.00%, tr:  99.28%, tr_best:  99.28%\n",
      "epoch-87  lr=['0.0010000'], tr/val_loss:  0.553077/  6.445292, val:  65.42%, val_best:  70.00%, tr:  98.98%, tr_best:  99.28%\n",
      "epoch-88  lr=['0.0010000'], tr/val_loss:  0.566797/  6.489215, val:  68.33%, val_best:  70.00%, tr:  98.77%, tr_best:  99.28%\n",
      "epoch-89  lr=['0.0010000'], tr/val_loss:  0.609876/  6.699442, val:  62.92%, val_best:  70.00%, tr:  98.57%, tr_best:  99.28%\n",
      "epoch-90  lr=['0.0010000'], tr/val_loss:  0.549794/  6.963483, val:  62.08%, val_best:  70.00%, tr:  98.98%, tr_best:  99.28%\n",
      "epoch-91  lr=['0.0010000'], tr/val_loss:  0.590196/  7.006435, val:  57.50%, val_best:  70.00%, tr:  98.37%, tr_best:  99.28%\n",
      "epoch-92  lr=['0.0010000'], tr/val_loss:  0.520197/  6.631442, val:  65.00%, val_best:  70.00%, tr:  99.49%, tr_best:  99.49%\n",
      "epoch-93  lr=['0.0010000'], tr/val_loss:  0.583246/  6.888014, val:  63.75%, val_best:  70.00%, tr:  97.85%, tr_best:  99.49%\n",
      "epoch-94  lr=['0.0010000'], tr/val_loss:  0.492588/  6.953991, val:  62.50%, val_best:  70.00%, tr:  99.28%, tr_best:  99.49%\n",
      "epoch-95  lr=['0.0010000'], tr/val_loss:  0.475725/  7.254573, val:  59.58%, val_best:  70.00%, tr:  99.90%, tr_best:  99.90%\n",
      "epoch-96  lr=['0.0010000'], tr/val_loss:  0.504911/  6.759181, val:  63.33%, val_best:  70.00%, tr:  99.08%, tr_best:  99.90%\n",
      "epoch-97  lr=['0.0010000'], tr/val_loss:  0.490340/  6.960999, val:  62.08%, val_best:  70.00%, tr:  99.49%, tr_best:  99.90%\n",
      "epoch-98  lr=['0.0010000'], tr/val_loss:  0.504596/  7.130430, val:  62.92%, val_best:  70.00%, tr:  99.59%, tr_best:  99.90%\n",
      "epoch-99  lr=['0.0010000'], tr/val_loss:  0.508407/  7.027815, val:  62.50%, val_best:  70.00%, tr:  99.39%, tr_best:  99.90%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8a4479af57b347598bc49a3b10595f1b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.006 MB of 0.006 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>iter_acc</td><td>▂▄▂▂▂▄▆▁▄▆▆█▅▆▆▇███▇██▆▇█▇██████████▇▇██</td></tr><tr><td>summary_val_acc</td><td>▁▅▅▆▇▇▆█▇▇▇█▇█▇▇▇█▇▇▇▇█▇▇▇▇▇█▇▇▇▇▇█▇▇▇▆▇</td></tr><tr><td>tr_acc</td><td>▁▄▄▅▅▆▆▆▆▆▆▆▇▇▇▇▇▇▇█▇███████████████████</td></tr><tr><td>tr_epoch_loss</td><td>█▆▅▄▄▄▄▃▃▃▃▃▃▃▃▃▃▃▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▁▂▁▂▁▁▁</td></tr><tr><td>val_acc_best</td><td>▁▅▅▆▇▇▇█████████████████████████████████</td></tr><tr><td>val_acc_now</td><td>▁▅▅▆▇▇▆█▇▇▇█▇█▇▇▇█▇▇▇▇█▇▇▇▇▇█▇▇▇▇▇█▇▇▇▆▇</td></tr><tr><td>val_loss</td><td>▂▁▁▁▁▁▁▁▁▁▂▂▂▂▃▃▃▃▃▄▄▅▅▅▆▆▆▆▆▇▇▇▇▇▇▇▇▇██</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>99</td></tr><tr><td>iter_acc</td><td>1.0</td></tr><tr><td>tr_acc</td><td>0.99387</td></tr><tr><td>tr_epoch_loss</td><td>0.50841</td></tr><tr><td>val_acc_best</td><td>0.7</td></tr><tr><td>val_acc_now</td><td>0.625</td></tr><tr><td>val_loss</td><td>7.02782</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">mild-sweep-250</strong> at: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/1trhzvd1' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/1trhzvd1</a><br/> View project at: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>/data2/bh_wandb/wandb/run-20250430_083107-1trhzvd1/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require(\"core\")`! See https://wandb.me/wandb-core for more information."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: wzgrpym0 with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBATCH: 16\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBN_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBPTT_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tDFA_on: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tIMAGE_SIZE: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tOTTT_input_trace_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tTIME: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tUDA_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \talpha_uda: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbias: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcfg: ['M', 'M', 200, 200]\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tchaching_on: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tconvTrue_fcFalse: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdata_path: /data2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tddp_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdenoise_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdvs_clipping: 5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdvs_duration: 100000\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepoch_num: 100\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \texclude_class: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \textra_train_dataset: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlast_lif: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.01\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_sg_width: 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_decay: 0.5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_init: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_reset: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_threshold: 0.5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmerge_polarities: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmy_seed: 42\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnet_print: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_workers: 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer_what: SGD\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tpin_memory: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tpre_trained: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tpre_trained_path: net_save/save_now_net_weights_{unique_name}.pth\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \trate_coding: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tscheduler_name: no\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsingle_step: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsurrogate: hard_sigmoid\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_conv_kernel_size: 3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_conv_padding: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_conv_stride: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_trace_const1: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_trace_const2: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \ttdBN_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \ttrace_on: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \twhich_data: DVS_GESTURE_TONIC\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.19.10 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.17.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/data2/bh_wandb/wandb/run-20250430_083709-wzgrpym0</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/wzgrpym0' target=\"_blank\">flowing-sweep-252</a></strong> to <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/6pj3lh8j' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/6pj3lh8j</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/6pj3lh8j' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/6pj3lh8j</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/wzgrpym0' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/wzgrpym0</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'single_step' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'my_seed' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'TIME' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BATCH' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'IMAGE_SIZE' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'which_data' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'data_path' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'rate_coding' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_init' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_decay' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_threshold' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_reset' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_sg_width' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_conv_kernel_size' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_conv_stride' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_conv_padding' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_trace_const1' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_trace_const2' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'pre_trained' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'convTrue_fcFalse' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'cfg' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'net_print' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'pre_trained_path' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'learning_rate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'epoch_num' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'tdBN_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BN_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'surrogate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BPTT_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'optimizer_what' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'scheduler_name' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'ddp_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'dvs_clipping' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'dvs_duration' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'DFA_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'trace_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'OTTT_input_trace_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'exclude_class' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'merge_polarities' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'denoise_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'extra_train_dataset' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'num_workers' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'chaching_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'pin_memory' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'UDA_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'alpha_uda' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'bias' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'last_lif' was locked by 'sweep' (ignored update).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "param {'devices': '0', 'single_step': True, 'unique_name': 'main', 'my_seed': 42, 'TIME': 10, 'BATCH': 16, 'IMAGE_SIZE': 128, 'which_data': 'DVS_GESTURE_TONIC', 'data_path': '/data2', 'rate_coding': False, 'lif_layer_v_init': 0, 'lif_layer_v_decay': 0.5, 'lif_layer_v_threshold': 0.5, 'lif_layer_v_reset': 0, 'lif_layer_sg_width': 2, 'synapse_conv_kernel_size': 3, 'synapse_conv_stride': 1, 'synapse_conv_padding': 1, 'synapse_trace_const1': 1, 'synapse_trace_const2': 0, 'pre_trained': False, 'convTrue_fcFalse': False, 'cfg': ['M', 'M', 200, 200], 'net_print': True, 'pre_trained_path': 'net_save/save_now_net_weights_{unique_name}.pth', 'learning_rate': 0.01, 'epoch_num': 100, 'tdBN_on': False, 'BN_on': False, 'surrogate': 'hard_sigmoid', 'BPTT_on': False, 'optimizer_what': 'SGD', 'scheduler_name': 'no', 'ddp_on': False, 'dvs_clipping': 5, 'dvs_duration': 100000, 'DFA_on': True, 'trace_on': True, 'OTTT_input_trace_on': False, 'exclude_class': True, 'merge_polarities': False, 'denoise_on': False, 'extra_train_dataset': 0, 'num_workers': 2, 'chaching_on': True, 'pin_memory': True, 'UDA_on': False, 'alpha_uda': 1, 'bias': True, 'last_lif': False, 'current epoch': 0} \n",
      "\n",
      "dataset_hash = ffa516e60c3efd5e0208f72b4c36cb84\n",
      "cache path exists\n",
      "\n",
      "device ==> cuda\n",
      "\n",
      "DataParallel(\n",
      "  (module): REBORN_MY_SNN_FC(\n",
      "    (layers): REBORN_MY_Sequential(\n",
      "      (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (2): DimChanger_for_FC()\n",
      "      (3): SYNAPSE_FC(in_features=2048, out_features=200, TIME=10, bias=True, sstep=True)\n",
      "      (4): LIF_layer(v_init=0, v_decay=0.5, v_threshold=0.5, v_reset=0, sg_width=2, surrogate=hard_sigmoid, BPTT_on=False, trace_const1=1, trace_const2=0, TIME=10, sstep=True, trace_on=True)\n",
      "      (5): Feedback_Receiver()\n",
      "      (6): SYNAPSE_FC(in_features=200, out_features=200, TIME=10, bias=True, sstep=True)\n",
      "      (7): LIF_layer(v_init=0, v_decay=0.5, v_threshold=0.5, v_reset=0, sg_width=2, surrogate=hard_sigmoid, BPTT_on=False, trace_const1=1, trace_const2=0, TIME=10, sstep=True, trace_on=True)\n",
      "      (8): Feedback_Receiver()\n",
      "      (9): SYNAPSE_FC(in_features=200, out_features=10, TIME=10, bias=True, sstep=True)\n",
      "      (DFA_top): Top_Gradient()\n",
      "    )\n",
      "  )\n",
      ")\n",
      "\n",
      "========================================================\n",
      "Trainable parameters: 452,010\n",
      "========================================================\n",
      "\n",
      "epoch-0   lr=['0.0100000'], tr/val_loss:  2.112054/  2.797109, val:  47.92%, val_best:  47.92%, tr:  32.69%, tr_best:  32.69%\n",
      "[module.layers.5] weight_fb parameter count: 2,000\n",
      "[module.layers.8] weight_fb parameter count: 2,000\n",
      "epoch-1   lr=['0.0100000'], tr/val_loss:  2.016702/  2.758697, val:  49.58%, val_best:  49.58%, tr:  50.66%, tr_best:  50.66%\n",
      "epoch-2   lr=['0.0100000'], tr/val_loss:  1.866657/  2.103809, val:  50.83%, val_best:  50.83%, tr:  61.08%, tr_best:  61.08%\n",
      "epoch-3   lr=['0.0100000'], tr/val_loss:  1.470614/  2.481122, val:  46.67%, val_best:  50.83%, tr:  64.56%, tr_best:  64.56%\n",
      "epoch-4   lr=['0.0100000'], tr/val_loss:  1.314657/  2.206217, val:  58.33%, val_best:  58.33%, tr:  67.93%, tr_best:  67.93%\n",
      "epoch-5   lr=['0.0100000'], tr/val_loss:  1.265880/  2.056586, val:  49.58%, val_best:  58.33%, tr:  71.20%, tr_best:  71.20%\n",
      "epoch-6   lr=['0.0100000'], tr/val_loss:  0.983768/  2.478153, val:  53.33%, val_best:  58.33%, tr:  77.83%, tr_best:  77.83%\n",
      "epoch-7   lr=['0.0100000'], tr/val_loss:  1.088148/  2.169285, val:  62.08%, val_best:  62.08%, tr:  79.37%, tr_best:  79.37%\n",
      "epoch-8   lr=['0.0100000'], tr/val_loss:  0.782817/  1.815949, val:  67.92%, val_best:  67.92%, tr:  84.98%, tr_best:  84.98%\n",
      "epoch-9   lr=['0.0100000'], tr/val_loss:  0.578971/  2.256926, val:  62.08%, val_best:  67.92%, tr:  89.38%, tr_best:  89.38%\n",
      "epoch-10  lr=['0.0100000'], tr/val_loss:  0.484814/  1.965308, val:  65.83%, val_best:  67.92%, tr:  93.36%, tr_best:  93.36%\n",
      "epoch-11  lr=['0.0100000'], tr/val_loss:  0.530886/  2.244266, val:  70.00%, val_best:  70.00%, tr:  91.93%, tr_best:  93.36%\n",
      "epoch-12  lr=['0.0100000'], tr/val_loss:  0.325127/  1.889895, val:  76.25%, val_best:  76.25%, tr:  96.63%, tr_best:  96.63%\n",
      "epoch-13  lr=['0.0100000'], tr/val_loss:  0.208283/  1.971354, val:  75.83%, val_best:  76.25%, tr:  98.57%, tr_best:  98.57%\n",
      "epoch-14  lr=['0.0100000'], tr/val_loss:  0.134811/  2.172499, val:  69.17%, val_best:  76.25%, tr:  99.39%, tr_best:  99.39%\n",
      "epoch-15  lr=['0.0100000'], tr/val_loss:  0.097092/  2.270545, val:  66.67%, val_best:  76.25%, tr:  99.90%, tr_best:  99.90%\n",
      "epoch-16  lr=['0.0100000'], tr/val_loss:  0.078177/  2.139054, val:  73.33%, val_best:  76.25%, tr:  99.90%, tr_best:  99.90%\n",
      "epoch-17  lr=['0.0100000'], tr/val_loss:  0.062879/  2.117683, val:  74.17%, val_best:  76.25%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-18  lr=['0.0100000'], tr/val_loss:  0.053730/  2.217994, val:  72.92%, val_best:  76.25%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-19  lr=['0.0100000'], tr/val_loss:  0.043468/  2.347183, val:  72.92%, val_best:  76.25%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-20  lr=['0.0100000'], tr/val_loss:  0.032598/  2.329072, val:  73.33%, val_best:  76.25%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-21  lr=['0.0100000'], tr/val_loss:  0.024911/  2.342681, val:  74.58%, val_best:  76.25%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-22  lr=['0.0100000'], tr/val_loss:  0.024755/  2.339781, val:  74.17%, val_best:  76.25%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-23  lr=['0.0100000'], tr/val_loss:  0.024211/  2.417031, val:  74.58%, val_best:  76.25%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-24  lr=['0.0100000'], tr/val_loss:  0.019275/  2.473841, val:  73.33%, val_best:  76.25%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-25  lr=['0.0100000'], tr/val_loss:  0.016926/  2.494201, val:  75.00%, val_best:  76.25%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-26  lr=['0.0100000'], tr/val_loss:  0.013321/  2.503714, val:  72.92%, val_best:  76.25%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-27  lr=['0.0100000'], tr/val_loss:  0.011928/  2.552448, val:  73.33%, val_best:  76.25%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-28  lr=['0.0100000'], tr/val_loss:  0.011348/  2.533459, val:  74.58%, val_best:  76.25%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-29  lr=['0.0100000'], tr/val_loss:  0.010755/  2.599713, val:  75.42%, val_best:  76.25%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-30  lr=['0.0100000'], tr/val_loss:  0.009768/  2.609738, val:  73.75%, val_best:  76.25%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-31  lr=['0.0100000'], tr/val_loss:  0.009234/  2.620919, val:  74.58%, val_best:  76.25%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-32  lr=['0.0100000'], tr/val_loss:  0.008102/  2.643328, val:  73.33%, val_best:  76.25%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-33  lr=['0.0100000'], tr/val_loss:  0.007422/  2.682070, val:  73.75%, val_best:  76.25%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-34  lr=['0.0100000'], tr/val_loss:  0.007787/  2.671732, val:  75.00%, val_best:  76.25%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-35  lr=['0.0100000'], tr/val_loss:  0.007548/  2.697567, val:  72.08%, val_best:  76.25%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-36  lr=['0.0100000'], tr/val_loss:  0.006301/  2.691860, val:  73.75%, val_best:  76.25%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-37  lr=['0.0100000'], tr/val_loss:  0.006082/  2.748153, val:  72.92%, val_best:  76.25%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-38  lr=['0.0100000'], tr/val_loss:  0.005473/  2.744855, val:  72.50%, val_best:  76.25%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-39  lr=['0.0100000'], tr/val_loss:  0.005227/  2.755907, val:  73.75%, val_best:  76.25%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-40  lr=['0.0100000'], tr/val_loss:  0.005382/  2.802148, val:  72.50%, val_best:  76.25%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-41  lr=['0.0100000'], tr/val_loss:  0.004599/  2.812788, val:  72.50%, val_best:  76.25%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-42  lr=['0.0100000'], tr/val_loss:  0.004054/  2.816810, val:  72.50%, val_best:  76.25%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-43  lr=['0.0100000'], tr/val_loss:  0.003639/  2.817137, val:  73.33%, val_best:  76.25%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-44  lr=['0.0100000'], tr/val_loss:  0.003524/  2.840726, val:  73.33%, val_best:  76.25%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-45  lr=['0.0100000'], tr/val_loss:  0.003589/  2.855155, val:  74.17%, val_best:  76.25%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-46  lr=['0.0100000'], tr/val_loss:  0.003441/  2.879783, val:  73.33%, val_best:  76.25%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-47  lr=['0.0100000'], tr/val_loss:  0.003521/  2.870943, val:  71.67%, val_best:  76.25%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-48  lr=['0.0100000'], tr/val_loss:  0.003025/  2.893681, val:  73.33%, val_best:  76.25%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-49  lr=['0.0100000'], tr/val_loss:  0.003080/  2.912357, val:  73.33%, val_best:  76.25%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-50  lr=['0.0100000'], tr/val_loss:  0.002896/  2.919915, val:  71.67%, val_best:  76.25%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-51  lr=['0.0100000'], tr/val_loss:  0.002830/  2.924850, val:  72.50%, val_best:  76.25%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-52  lr=['0.0100000'], tr/val_loss:  0.002510/  2.921473, val:  71.67%, val_best:  76.25%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-53  lr=['0.0100000'], tr/val_loss:  0.002625/  2.911996, val:  73.33%, val_best:  76.25%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-54  lr=['0.0100000'], tr/val_loss:  0.002775/  2.932203, val:  73.33%, val_best:  76.25%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-55  lr=['0.0100000'], tr/val_loss:  0.002331/  2.932156, val:  72.92%, val_best:  76.25%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-56  lr=['0.0100000'], tr/val_loss:  0.002547/  2.952598, val:  73.33%, val_best:  76.25%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-57  lr=['0.0100000'], tr/val_loss:  0.002787/  2.959287, val:  74.58%, val_best:  76.25%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-58  lr=['0.0100000'], tr/val_loss:  0.002286/  2.958703, val:  74.17%, val_best:  76.25%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-59  lr=['0.0100000'], tr/val_loss:  0.002080/  2.988215, val:  74.17%, val_best:  76.25%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-60  lr=['0.0100000'], tr/val_loss:  0.001742/  2.984399, val:  74.17%, val_best:  76.25%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-61  lr=['0.0100000'], tr/val_loss:  0.002196/  2.990875, val:  73.33%, val_best:  76.25%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-62  lr=['0.0100000'], tr/val_loss:  0.001958/  3.010255, val:  74.58%, val_best:  76.25%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-63  lr=['0.0100000'], tr/val_loss:  0.002151/  3.015614, val:  74.58%, val_best:  76.25%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-64  lr=['0.0100000'], tr/val_loss:  0.001956/  3.031232, val:  74.17%, val_best:  76.25%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-65  lr=['0.0100000'], tr/val_loss:  0.001840/  3.046416, val:  73.75%, val_best:  76.25%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-66  lr=['0.0100000'], tr/val_loss:  0.001706/  3.031741, val:  73.33%, val_best:  76.25%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-67  lr=['0.0100000'], tr/val_loss:  0.001823/  3.061142, val:  73.33%, val_best:  76.25%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-68  lr=['0.0100000'], tr/val_loss:  0.002338/  3.024059, val:  73.33%, val_best:  76.25%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-69  lr=['0.0100000'], tr/val_loss:  0.002079/  3.037160, val:  74.58%, val_best:  76.25%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-70  lr=['0.0100000'], tr/val_loss:  0.001887/  3.051626, val:  74.17%, val_best:  76.25%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-71  lr=['0.0100000'], tr/val_loss:  0.001678/  3.059763, val:  73.75%, val_best:  76.25%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-72  lr=['0.0100000'], tr/val_loss:  0.001608/  3.054780, val:  74.17%, val_best:  76.25%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-73  lr=['0.0100000'], tr/val_loss:  0.001543/  3.059997, val:  74.17%, val_best:  76.25%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-74  lr=['0.0100000'], tr/val_loss:  0.001474/  3.060157, val:  75.00%, val_best:  76.25%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-75  lr=['0.0100000'], tr/val_loss:  0.001569/  3.091324, val:  73.75%, val_best:  76.25%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-76  lr=['0.0100000'], tr/val_loss:  0.001542/  3.082211, val:  74.17%, val_best:  76.25%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-77  lr=['0.0100000'], tr/val_loss:  0.001443/  3.080828, val:  74.17%, val_best:  76.25%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-78  lr=['0.0100000'], tr/val_loss:  0.001405/  3.077229, val:  74.58%, val_best:  76.25%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-79  lr=['0.0100000'], tr/val_loss:  0.001498/  3.084501, val:  73.75%, val_best:  76.25%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-80  lr=['0.0100000'], tr/val_loss:  0.001618/  3.102895, val:  72.92%, val_best:  76.25%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-81  lr=['0.0100000'], tr/val_loss:  0.001346/  3.100511, val:  74.17%, val_best:  76.25%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-82  lr=['0.0100000'], tr/val_loss:  0.001546/  3.117571, val:  74.58%, val_best:  76.25%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-83  lr=['0.0100000'], tr/val_loss:  0.001716/  3.109541, val:  74.17%, val_best:  76.25%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-84  lr=['0.0100000'], tr/val_loss:  0.001490/  3.121340, val:  73.75%, val_best:  76.25%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-85  lr=['0.0100000'], tr/val_loss:  0.001721/  3.101376, val:  74.17%, val_best:  76.25%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-86  lr=['0.0100000'], tr/val_loss:  0.001353/  3.127167, val:  73.33%, val_best:  76.25%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-87  lr=['0.0100000'], tr/val_loss:  0.001272/  3.130372, val:  73.33%, val_best:  76.25%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-88  lr=['0.0100000'], tr/val_loss:  0.001358/  3.129255, val:  74.58%, val_best:  76.25%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-89  lr=['0.0100000'], tr/val_loss:  0.001208/  3.146096, val:  73.33%, val_best:  76.25%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-90  lr=['0.0100000'], tr/val_loss:  0.001238/  3.157794, val:  72.92%, val_best:  76.25%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-91  lr=['0.0100000'], tr/val_loss:  0.001235/  3.151755, val:  73.75%, val_best:  76.25%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-92  lr=['0.0100000'], tr/val_loss:  0.001281/  3.151500, val:  73.75%, val_best:  76.25%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-93  lr=['0.0100000'], tr/val_loss:  0.001237/  3.158912, val:  73.75%, val_best:  76.25%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-94  lr=['0.0100000'], tr/val_loss:  0.001134/  3.150590, val:  73.75%, val_best:  76.25%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-95  lr=['0.0100000'], tr/val_loss:  0.001103/  3.150613, val:  73.33%, val_best:  76.25%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-96  lr=['0.0100000'], tr/val_loss:  0.001051/  3.172180, val:  73.33%, val_best:  76.25%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-97  lr=['0.0100000'], tr/val_loss:  0.001127/  3.165431, val:  73.33%, val_best:  76.25%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-98  lr=['0.0100000'], tr/val_loss:  0.001056/  3.160066, val:  73.75%, val_best:  76.25%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-99  lr=['0.0100000'], tr/val_loss:  0.001308/  3.174333, val:  72.92%, val_best:  76.25%, tr: 100.00%, tr_best: 100.00%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "66e706610d094cc795a6dfb8239683e7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.006 MB of 0.006 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>iter_acc</td><td>▁▆▅▆▅███████████████████████████████████</td></tr><tr><td>summary_val_acc</td><td>▁▂▄▅▅█▆▇▇█▇▇█▇▇▇▇▇▇▇▇▇▇█▇▇▇▇▇▇▇▇▇█▇▇▇▇▇▇</td></tr><tr><td>tr_acc</td><td>▁▄▅▆▇███████████████████████████████████</td></tr><tr><td>tr_epoch_loss</td><td>█▇▅▅▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_acc_best</td><td>▁▂▄▅▆███████████████████████████████████</td></tr><tr><td>val_acc_now</td><td>▁▂▄▅▅█▆▇▇█▇▇█▇▇▇▇▇▇▇▇▇▇█▇▇▇▇▇▇▇▇▇█▇▇▇▇▇▇</td></tr><tr><td>val_loss</td><td>▆▂▃▃▃▁▃▂▄▃▄▄▅▅▅▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇██████████</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>99</td></tr><tr><td>iter_acc</td><td>1.0</td></tr><tr><td>tr_acc</td><td>1.0</td></tr><tr><td>tr_epoch_loss</td><td>0.00131</td></tr><tr><td>val_acc_best</td><td>0.7625</td></tr><tr><td>val_acc_now</td><td>0.72917</td></tr><tr><td>val_loss</td><td>3.17433</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">flowing-sweep-252</strong> at: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/wzgrpym0' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/wzgrpym0</a><br/> View project at: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>/data2/bh_wandb/wandb/run-20250430_083709-wzgrpym0/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require(\"core\")`! See https://wandb.me/wandb-core for more information."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: ehanwohh with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBATCH: 16\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBN_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBPTT_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tDFA_on: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tIMAGE_SIZE: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tOTTT_input_trace_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tTIME: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tUDA_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \talpha_uda: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbias: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcfg: ['M', 'M', 200, 200]\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tchaching_on: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tconvTrue_fcFalse: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdata_path: /data2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tddp_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdenoise_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdvs_clipping: 5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdvs_duration: 100000\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepoch_num: 100\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \texclude_class: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \textra_train_dataset: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlast_lif: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.001\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_sg_width: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_decay: 0.5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_init: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_reset: 10000\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_threshold: 0.25\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmerge_polarities: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmy_seed: 42\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnet_print: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_workers: 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer_what: SGD\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tpin_memory: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tpre_trained: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tpre_trained_path: net_save/save_now_net_weights_{unique_name}.pth\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \trate_coding: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tscheduler_name: no\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsingle_step: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsurrogate: hard_sigmoid\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_conv_kernel_size: 3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_conv_padding: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_conv_stride: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_trace_const1: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_trace_const2: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \ttdBN_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \ttrace_on: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \twhich_data: DVS_GESTURE_TONIC\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.19.10 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.17.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/data2/bh_wandb/wandb/run-20250430_084349-ehanwohh</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/ehanwohh' target=\"_blank\">celestial-sweep-254</a></strong> to <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/6pj3lh8j' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/6pj3lh8j</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/6pj3lh8j' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/6pj3lh8j</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/ehanwohh' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/ehanwohh</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'single_step' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'my_seed' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'TIME' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BATCH' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'IMAGE_SIZE' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'which_data' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'data_path' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'rate_coding' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_init' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_decay' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_threshold' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_reset' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_sg_width' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_conv_kernel_size' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_conv_stride' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_conv_padding' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_trace_const1' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_trace_const2' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'pre_trained' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'convTrue_fcFalse' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'cfg' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'net_print' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'pre_trained_path' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'learning_rate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'epoch_num' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'tdBN_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BN_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'surrogate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BPTT_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'optimizer_what' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'scheduler_name' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'ddp_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'dvs_clipping' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'dvs_duration' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'DFA_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'trace_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'OTTT_input_trace_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'exclude_class' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'merge_polarities' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'denoise_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'extra_train_dataset' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'num_workers' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'chaching_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'pin_memory' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'UDA_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'alpha_uda' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'bias' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'last_lif' was locked by 'sweep' (ignored update).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "param {'devices': '0', 'single_step': True, 'unique_name': 'main', 'my_seed': 42, 'TIME': 10, 'BATCH': 16, 'IMAGE_SIZE': 128, 'which_data': 'DVS_GESTURE_TONIC', 'data_path': '/data2', 'rate_coding': False, 'lif_layer_v_init': 0, 'lif_layer_v_decay': 0.5, 'lif_layer_v_threshold': 0.25, 'lif_layer_v_reset': 10000, 'lif_layer_sg_width': 1, 'synapse_conv_kernel_size': 3, 'synapse_conv_stride': 1, 'synapse_conv_padding': 1, 'synapse_trace_const1': 1, 'synapse_trace_const2': 0, 'pre_trained': False, 'convTrue_fcFalse': False, 'cfg': ['M', 'M', 200, 200], 'net_print': True, 'pre_trained_path': 'net_save/save_now_net_weights_{unique_name}.pth', 'learning_rate': 0.001, 'epoch_num': 100, 'tdBN_on': False, 'BN_on': False, 'surrogate': 'hard_sigmoid', 'BPTT_on': False, 'optimizer_what': 'SGD', 'scheduler_name': 'no', 'ddp_on': False, 'dvs_clipping': 5, 'dvs_duration': 100000, 'DFA_on': True, 'trace_on': True, 'OTTT_input_trace_on': False, 'exclude_class': True, 'merge_polarities': False, 'denoise_on': False, 'extra_train_dataset': 0, 'num_workers': 2, 'chaching_on': True, 'pin_memory': True, 'UDA_on': False, 'alpha_uda': 1, 'bias': True, 'last_lif': False, 'current epoch': 0} \n",
      "\n",
      "dataset_hash = ffa516e60c3efd5e0208f72b4c36cb84\n",
      "cache path exists\n",
      "\n",
      "device ==> cuda\n",
      "\n",
      "DataParallel(\n",
      "  (module): REBORN_MY_SNN_FC(\n",
      "    (layers): REBORN_MY_Sequential(\n",
      "      (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (2): DimChanger_for_FC()\n",
      "      (3): SYNAPSE_FC(in_features=2048, out_features=200, TIME=10, bias=True, sstep=True)\n",
      "      (4): LIF_layer(v_init=0, v_decay=0.5, v_threshold=0.25, v_reset=10000, sg_width=1, surrogate=hard_sigmoid, BPTT_on=False, trace_const1=1, trace_const2=0, TIME=10, sstep=True, trace_on=True)\n",
      "      (5): Feedback_Receiver()\n",
      "      (6): SYNAPSE_FC(in_features=200, out_features=200, TIME=10, bias=True, sstep=True)\n",
      "      (7): LIF_layer(v_init=0, v_decay=0.5, v_threshold=0.25, v_reset=10000, sg_width=1, surrogate=hard_sigmoid, BPTT_on=False, trace_const1=1, trace_const2=0, TIME=10, sstep=True, trace_on=True)\n",
      "      (8): Feedback_Receiver()\n",
      "      (9): SYNAPSE_FC(in_features=200, out_features=10, TIME=10, bias=True, sstep=True)\n",
      "      (DFA_top): Top_Gradient()\n",
      "    )\n",
      "  )\n",
      ")\n",
      "\n",
      "========================================================\n",
      "Trainable parameters: 452,010\n",
      "========================================================\n",
      "\n",
      "epoch-0   lr=['0.0010000'], tr/val_loss:  2.234967/  2.061121, val:  29.58%, val_best:  29.58%, tr:  17.57%, tr_best:  17.57%\n",
      "[module.layers.5] weight_fb parameter count: 2,000\n",
      "[module.layers.8] weight_fb parameter count: 2,000\n",
      "epoch-1   lr=['0.0010000'], tr/val_loss:  1.738926/  1.608841, val:  50.83%, val_best:  50.83%, tr:  47.09%, tr_best:  47.09%\n",
      "epoch-2   lr=['0.0010000'], tr/val_loss:  1.422773/  1.489018, val:  53.75%, val_best:  53.75%, tr:  55.87%, tr_best:  55.87%\n",
      "epoch-3   lr=['0.0010000'], tr/val_loss:  1.307245/  1.457123, val:  57.08%, val_best:  57.08%, tr:  62.31%, tr_best:  62.31%\n",
      "epoch-4   lr=['0.0010000'], tr/val_loss:  1.249867/  1.431987, val:  56.25%, val_best:  57.08%, tr:  61.08%, tr_best:  62.31%\n",
      "epoch-5   lr=['0.0010000'], tr/val_loss:  1.189873/  1.380758, val:  61.25%, val_best:  61.25%, tr:  63.94%, tr_best:  63.94%\n",
      "epoch-6   lr=['0.0010000'], tr/val_loss:  1.142655/  1.373085, val:  60.83%, val_best:  61.25%, tr:  65.17%, tr_best:  65.17%\n",
      "epoch-7   lr=['0.0010000'], tr/val_loss:  1.116557/  1.364406, val:  62.08%, val_best:  62.08%, tr:  67.52%, tr_best:  67.52%\n",
      "epoch-8   lr=['0.0010000'], tr/val_loss:  1.084894/  1.351569, val:  62.92%, val_best:  62.92%, tr:  65.99%, tr_best:  67.52%\n",
      "epoch-9   lr=['0.0010000'], tr/val_loss:  1.064984/  1.350940, val:  58.33%, val_best:  62.92%, tr:  69.05%, tr_best:  69.05%\n",
      "epoch-10  lr=['0.0010000'], tr/val_loss:  1.049128/  1.355504, val:  58.33%, val_best:  62.92%, tr:  67.52%, tr_best:  69.05%\n",
      "epoch-11  lr=['0.0010000'], tr/val_loss:  1.020496/  1.324944, val:  62.92%, val_best:  62.92%, tr:  68.34%, tr_best:  69.05%\n",
      "epoch-12  lr=['0.0010000'], tr/val_loss:  1.006819/  1.326215, val:  62.50%, val_best:  62.92%, tr:  71.30%, tr_best:  71.30%\n",
      "epoch-13  lr=['0.0010000'], tr/val_loss:  0.996611/  1.332188, val:  65.00%, val_best:  65.00%, tr:  71.91%, tr_best:  71.91%\n",
      "epoch-14  lr=['0.0010000'], tr/val_loss:  0.955537/  1.421634, val:  57.92%, val_best:  65.00%, tr:  74.26%, tr_best:  74.26%\n",
      "epoch-15  lr=['0.0010000'], tr/val_loss:  0.945024/  1.327622, val:  67.08%, val_best:  67.08%, tr:  75.89%, tr_best:  75.89%\n",
      "epoch-16  lr=['0.0010000'], tr/val_loss:  0.943797/  1.336183, val:  62.92%, val_best:  67.08%, tr:  73.24%, tr_best:  75.89%\n",
      "epoch-17  lr=['0.0010000'], tr/val_loss:  0.912031/  1.324563, val:  63.33%, val_best:  67.08%, tr:  76.71%, tr_best:  76.71%\n",
      "epoch-18  lr=['0.0010000'], tr/val_loss:  0.894008/  1.375068, val:  62.92%, val_best:  67.08%, tr:  77.43%, tr_best:  77.43%\n",
      "epoch-19  lr=['0.0010000'], tr/val_loss:  0.893091/  1.368630, val:  59.17%, val_best:  67.08%, tr:  76.00%, tr_best:  77.43%\n",
      "epoch-20  lr=['0.0010000'], tr/val_loss:  0.866064/  1.347265, val:  62.50%, val_best:  67.08%, tr:  80.59%, tr_best:  80.59%\n",
      "epoch-21  lr=['0.0010000'], tr/val_loss:  0.860625/  1.327593, val:  65.42%, val_best:  67.08%, tr:  81.10%, tr_best:  81.10%\n",
      "epoch-22  lr=['0.0010000'], tr/val_loss:  0.862020/  1.337723, val:  64.17%, val_best:  67.08%, tr:  79.06%, tr_best:  81.10%\n",
      "epoch-23  lr=['0.0010000'], tr/val_loss:  0.823188/  1.335982, val:  65.42%, val_best:  67.08%, tr:  81.00%, tr_best:  81.10%\n",
      "epoch-24  lr=['0.0010000'], tr/val_loss:  0.818568/  1.363360, val:  65.83%, val_best:  67.08%, tr:  82.02%, tr_best:  82.02%\n",
      "epoch-25  lr=['0.0010000'], tr/val_loss:  0.806455/  1.339213, val:  69.17%, val_best:  69.17%, tr:  83.55%, tr_best:  83.55%\n",
      "epoch-26  lr=['0.0010000'], tr/val_loss:  0.798156/  1.339790, val:  69.58%, val_best:  69.58%, tr:  83.04%, tr_best:  83.55%\n",
      "epoch-27  lr=['0.0010000'], tr/val_loss:  0.778962/  1.381735, val:  67.08%, val_best:  69.58%, tr:  85.29%, tr_best:  85.29%\n",
      "epoch-28  lr=['0.0010000'], tr/val_loss:  0.777060/  1.343981, val:  69.58%, val_best:  69.58%, tr:  85.80%, tr_best:  85.80%\n",
      "epoch-29  lr=['0.0010000'], tr/val_loss:  0.744970/  1.385240, val:  64.17%, val_best:  69.58%, tr:  88.25%, tr_best:  88.25%\n",
      "epoch-30  lr=['0.0010000'], tr/val_loss:  0.738726/  1.406730, val:  64.17%, val_best:  69.58%, tr:  89.38%, tr_best:  89.38%\n",
      "epoch-31  lr=['0.0010000'], tr/val_loss:  0.753120/  1.438836, val:  62.50%, val_best:  69.58%, tr:  85.80%, tr_best:  89.38%\n",
      "epoch-32  lr=['0.0010000'], tr/val_loss:  0.733585/  1.430078, val:  67.50%, val_best:  69.58%, tr:  87.84%, tr_best:  89.38%\n",
      "epoch-33  lr=['0.0010000'], tr/val_loss:  0.734338/  1.416422, val:  70.42%, val_best:  70.42%, tr:  86.31%, tr_best:  89.38%\n",
      "epoch-34  lr=['0.0010000'], tr/val_loss:  0.707585/  1.472151, val:  64.17%, val_best:  70.42%, tr:  90.09%, tr_best:  90.09%\n",
      "epoch-35  lr=['0.0010000'], tr/val_loss:  0.721022/  1.483300, val:  66.67%, val_best:  70.42%, tr:  86.52%, tr_best:  90.09%\n",
      "epoch-36  lr=['0.0010000'], tr/val_loss:  0.686502/  1.444601, val:  66.67%, val_best:  70.42%, tr:  90.40%, tr_best:  90.40%\n",
      "epoch-37  lr=['0.0010000'], tr/val_loss:  0.689668/  1.474282, val:  67.92%, val_best:  70.42%, tr:  92.24%, tr_best:  92.24%\n",
      "epoch-38  lr=['0.0010000'], tr/val_loss:  0.677990/  1.479877, val:  68.33%, val_best:  70.42%, tr:  92.65%, tr_best:  92.65%\n",
      "epoch-39  lr=['0.0010000'], tr/val_loss:  0.659619/  1.491713, val:  67.08%, val_best:  70.42%, tr:  93.26%, tr_best:  93.26%\n",
      "epoch-40  lr=['0.0010000'], tr/val_loss:  0.658571/  1.526029, val:  67.92%, val_best:  70.42%, tr:  92.44%, tr_best:  93.26%\n",
      "epoch-41  lr=['0.0010000'], tr/val_loss:  0.654195/  1.530487, val:  67.50%, val_best:  70.42%, tr:  93.46%, tr_best:  93.46%\n",
      "epoch-42  lr=['0.0010000'], tr/val_loss:  0.634350/  1.518000, val:  67.08%, val_best:  70.42%, tr:  94.38%, tr_best:  94.38%\n",
      "epoch-43  lr=['0.0010000'], tr/val_loss:  0.637497/  1.550039, val:  65.83%, val_best:  70.42%, tr:  93.87%, tr_best:  94.38%\n",
      "epoch-44  lr=['0.0010000'], tr/val_loss:  0.620649/  1.532519, val:  67.92%, val_best:  70.42%, tr:  93.67%, tr_best:  94.38%\n",
      "epoch-45  lr=['0.0010000'], tr/val_loss:  0.612245/  1.554516, val:  67.50%, val_best:  70.42%, tr:  94.08%, tr_best:  94.38%\n",
      "epoch-46  lr=['0.0010000'], tr/val_loss:  0.604333/  1.554752, val:  68.75%, val_best:  70.42%, tr:  95.81%, tr_best:  95.81%\n",
      "epoch-47  lr=['0.0010000'], tr/val_loss:  0.603936/  1.572185, val:  67.92%, val_best:  70.42%, tr:  96.42%, tr_best:  96.42%\n",
      "epoch-48  lr=['0.0010000'], tr/val_loss:  0.608456/  1.561018, val:  66.25%, val_best:  70.42%, tr:  96.42%, tr_best:  96.42%\n",
      "epoch-49  lr=['0.0010000'], tr/val_loss:  0.603189/  1.593188, val:  68.33%, val_best:  70.42%, tr:  95.61%, tr_best:  96.42%\n",
      "epoch-50  lr=['0.0010000'], tr/val_loss:  0.594222/  1.605322, val:  67.08%, val_best:  70.42%, tr:  95.30%, tr_best:  96.42%\n",
      "epoch-51  lr=['0.0010000'], tr/val_loss:  0.595460/  1.624553, val:  68.33%, val_best:  70.42%, tr:  94.79%, tr_best:  96.42%\n",
      "epoch-52  lr=['0.0010000'], tr/val_loss:  0.569343/  1.629437, val:  65.83%, val_best:  70.42%, tr:  96.42%, tr_best:  96.42%\n",
      "epoch-53  lr=['0.0010000'], tr/val_loss:  0.567569/  1.626719, val:  67.50%, val_best:  70.42%, tr:  97.04%, tr_best:  97.04%\n",
      "epoch-54  lr=['0.0010000'], tr/val_loss:  0.561377/  1.641724, val:  67.92%, val_best:  70.42%, tr:  97.04%, tr_best:  97.04%\n",
      "epoch-55  lr=['0.0010000'], tr/val_loss:  0.562167/  1.633065, val:  69.58%, val_best:  70.42%, tr:  96.83%, tr_best:  97.04%\n",
      "epoch-56  lr=['0.0010000'], tr/val_loss:  0.556739/  1.667689, val:  69.17%, val_best:  70.42%, tr:  96.53%, tr_best:  97.04%\n",
      "epoch-57  lr=['0.0010000'], tr/val_loss:  0.549942/  1.651380, val:  66.25%, val_best:  70.42%, tr:  97.14%, tr_best:  97.14%\n",
      "epoch-58  lr=['0.0010000'], tr/val_loss:  0.540810/  1.705611, val:  66.25%, val_best:  70.42%, tr:  97.65%, tr_best:  97.65%\n",
      "epoch-59  lr=['0.0010000'], tr/val_loss:  0.537680/  1.657638, val:  70.83%, val_best:  70.83%, tr:  97.45%, tr_best:  97.65%\n",
      "epoch-60  lr=['0.0010000'], tr/val_loss:  0.528761/  1.642384, val:  68.75%, val_best:  70.83%, tr:  97.04%, tr_best:  97.65%\n",
      "epoch-61  lr=['0.0010000'], tr/val_loss:  0.526995/  1.702654, val:  65.00%, val_best:  70.83%, tr:  98.26%, tr_best:  98.26%\n",
      "epoch-62  lr=['0.0010000'], tr/val_loss:  0.530881/  1.707739, val:  68.33%, val_best:  70.83%, tr:  96.94%, tr_best:  98.26%\n",
      "epoch-63  lr=['0.0010000'], tr/val_loss:  0.517172/  1.691157, val:  67.08%, val_best:  70.83%, tr:  98.47%, tr_best:  98.47%\n",
      "epoch-64  lr=['0.0010000'], tr/val_loss:  0.512872/  1.760991, val:  66.25%, val_best:  70.83%, tr:  97.04%, tr_best:  98.47%\n",
      "epoch-65  lr=['0.0010000'], tr/val_loss:  0.505203/  1.724881, val:  66.67%, val_best:  70.83%, tr:  97.34%, tr_best:  98.47%\n",
      "epoch-66  lr=['0.0010000'], tr/val_loss:  0.506203/  1.756307, val:  66.67%, val_best:  70.83%, tr:  97.96%, tr_best:  98.47%\n",
      "epoch-67  lr=['0.0010000'], tr/val_loss:  0.501620/  1.745774, val:  68.75%, val_best:  70.83%, tr:  98.26%, tr_best:  98.47%\n",
      "epoch-68  lr=['0.0010000'], tr/val_loss:  0.494596/  1.791627, val:  67.08%, val_best:  70.83%, tr:  97.85%, tr_best:  98.47%\n",
      "epoch-69  lr=['0.0010000'], tr/val_loss:  0.493313/  1.785776, val:  67.08%, val_best:  70.83%, tr:  97.14%, tr_best:  98.47%\n",
      "epoch-70  lr=['0.0010000'], tr/val_loss:  0.490915/  1.800159, val:  68.33%, val_best:  70.83%, tr:  98.26%, tr_best:  98.47%\n",
      "epoch-71  lr=['0.0010000'], tr/val_loss:  0.489275/  1.853169, val:  64.58%, val_best:  70.83%, tr:  97.45%, tr_best:  98.47%\n",
      "epoch-72  lr=['0.0010000'], tr/val_loss:  0.486605/  1.846004, val:  67.50%, val_best:  70.83%, tr:  98.37%, tr_best:  98.47%\n",
      "epoch-73  lr=['0.0010000'], tr/val_loss:  0.490110/  1.814264, val:  67.92%, val_best:  70.83%, tr:  97.34%, tr_best:  98.47%\n",
      "epoch-74  lr=['0.0010000'], tr/val_loss:  0.472672/  1.826997, val:  69.58%, val_best:  70.83%, tr:  98.16%, tr_best:  98.47%\n",
      "epoch-75  lr=['0.0010000'], tr/val_loss:  0.478486/  1.843027, val:  67.92%, val_best:  70.83%, tr:  97.65%, tr_best:  98.47%\n",
      "epoch-76  lr=['0.0010000'], tr/val_loss:  0.474308/  1.879273, val:  65.00%, val_best:  70.83%, tr:  98.26%, tr_best:  98.47%\n",
      "epoch-77  lr=['0.0010000'], tr/val_loss:  0.476142/  1.860383, val:  69.17%, val_best:  70.83%, tr:  98.06%, tr_best:  98.47%\n",
      "epoch-78  lr=['0.0010000'], tr/val_loss:  0.479643/  1.875527, val:  70.42%, val_best:  70.83%, tr:  97.96%, tr_best:  98.47%\n",
      "epoch-79  lr=['0.0010000'], tr/val_loss:  0.457298/  1.874949, val:  69.17%, val_best:  70.83%, tr:  98.77%, tr_best:  98.77%\n",
      "epoch-80  lr=['0.0010000'], tr/val_loss:  0.455175/  1.879494, val:  66.25%, val_best:  70.83%, tr:  98.67%, tr_best:  98.77%\n",
      "epoch-81  lr=['0.0010000'], tr/val_loss:  0.453979/  1.863412, val:  68.33%, val_best:  70.83%, tr:  98.67%, tr_best:  98.77%\n",
      "epoch-82  lr=['0.0010000'], tr/val_loss:  0.450708/  1.919294, val:  65.42%, val_best:  70.83%, tr:  98.88%, tr_best:  98.88%\n",
      "epoch-83  lr=['0.0010000'], tr/val_loss:  0.454146/  1.884817, val:  70.42%, val_best:  70.83%, tr:  98.57%, tr_best:  98.88%\n",
      "epoch-84  lr=['0.0010000'], tr/val_loss:  0.458613/  1.865002, val:  70.42%, val_best:  70.83%, tr:  99.08%, tr_best:  99.08%\n",
      "epoch-85  lr=['0.0010000'], tr/val_loss:  0.442279/  1.924083, val:  65.83%, val_best:  70.83%, tr:  99.08%, tr_best:  99.08%\n",
      "epoch-86  lr=['0.0010000'], tr/val_loss:  0.446300/  1.895893, val:  71.25%, val_best:  71.25%, tr:  98.26%, tr_best:  99.08%\n",
      "epoch-87  lr=['0.0010000'], tr/val_loss:  0.441874/  1.938737, val:  68.75%, val_best:  71.25%, tr:  98.88%, tr_best:  99.08%\n",
      "epoch-88  lr=['0.0010000'], tr/val_loss:  0.432040/  1.906217, val:  69.58%, val_best:  71.25%, tr:  99.28%, tr_best:  99.28%\n",
      "epoch-89  lr=['0.0010000'], tr/val_loss:  0.431620/  1.932650, val:  67.50%, val_best:  71.25%, tr:  98.98%, tr_best:  99.28%\n",
      "epoch-90  lr=['0.0010000'], tr/val_loss:  0.441171/  1.918897, val:  68.75%, val_best:  71.25%, tr:  98.98%, tr_best:  99.28%\n",
      "epoch-91  lr=['0.0010000'], tr/val_loss:  0.430123/  1.957517, val:  65.42%, val_best:  71.25%, tr:  98.67%, tr_best:  99.28%\n",
      "epoch-92  lr=['0.0010000'], tr/val_loss:  0.428286/  1.967104, val:  66.25%, val_best:  71.25%, tr:  99.18%, tr_best:  99.28%\n",
      "epoch-93  lr=['0.0010000'], tr/val_loss:  0.429558/  1.956058, val:  65.83%, val_best:  71.25%, tr:  99.28%, tr_best:  99.28%\n",
      "epoch-94  lr=['0.0010000'], tr/val_loss:  0.430956/  1.989213, val:  66.67%, val_best:  71.25%, tr:  98.98%, tr_best:  99.28%\n",
      "epoch-95  lr=['0.0010000'], tr/val_loss:  0.422269/  2.002620, val:  67.50%, val_best:  71.25%, tr:  99.18%, tr_best:  99.28%\n",
      "epoch-96  lr=['0.0010000'], tr/val_loss:  0.421672/  2.038894, val:  66.67%, val_best:  71.25%, tr:  98.98%, tr_best:  99.28%\n",
      "epoch-97  lr=['0.0010000'], tr/val_loss:  0.429826/  2.000259, val:  67.92%, val_best:  71.25%, tr:  97.85%, tr_best:  99.28%\n",
      "epoch-98  lr=['0.0010000'], tr/val_loss:  0.407535/  1.988403, val:  67.50%, val_best:  71.25%, tr:  99.28%, tr_best:  99.28%\n",
      "epoch-99  lr=['0.0010000'], tr/val_loss:  0.415734/  2.015249, val:  65.00%, val_best:  71.25%, tr:  98.77%, tr_best:  99.28%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "946edff1b02c4e16a1a6ae145795559f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.006 MB of 0.006 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>iter_acc</td><td>▂▇▄▄▄▅▆▁▅▇▇▇▇▆▇█▇▇████████▇██▇██▇███▇███</td></tr><tr><td>summary_val_acc</td><td>▁▅▆▇▆▇▆▇▆▇▇█▇▇▇█▇▇███▇█▇█▇▇██▇███▇██▇▇▇█</td></tr><tr><td>tr_acc</td><td>▁▄▅▅▅▆▆▆▆▆▇▇▇▇▇▇▇███████████████████████</td></tr><tr><td>tr_epoch_loss</td><td>█▅▄▄▃▃▃▃▃▃▃▂▂▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_acc_best</td><td>▁▅▆▆▇▇▇▇▇▇▇█████████████████████████████</td></tr><tr><td>val_acc_now</td><td>▁▅▆▇▆▇▆▇▆▇▇█▇▇▇█▇▇███▇█▇█▇▇██▇███▇██▇▇▇█</td></tr><tr><td>val_loss</td><td>█▃▂▁▁▁▂▁▁▁▁▁▂▂▃▂▃▃▃▃▄▄▄▄▄▅▅▅▆▆▆▆▆▇▆▇▇▇▇▇</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>99</td></tr><tr><td>iter_acc</td><td>1.0</td></tr><tr><td>tr_acc</td><td>0.98774</td></tr><tr><td>tr_epoch_loss</td><td>0.41573</td></tr><tr><td>val_acc_best</td><td>0.7125</td></tr><tr><td>val_acc_now</td><td>0.65</td></tr><tr><td>val_loss</td><td>2.01525</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">celestial-sweep-254</strong> at: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/ehanwohh' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/ehanwohh</a><br/> View project at: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>/data2/bh_wandb/wandb/run-20250430_084349-ehanwohh/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require(\"core\")`! See https://wandb.me/wandb-core for more information."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 3j0jo68j with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBATCH: 16\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBN_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBPTT_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tDFA_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tIMAGE_SIZE: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tOTTT_input_trace_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tTIME: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tUDA_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \talpha_uda: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbias: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcfg: ['M', 'M', 200, 200]\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tchaching_on: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tconvTrue_fcFalse: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdata_path: /data2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tddp_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdenoise_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdvs_clipping: 5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdvs_duration: 100000\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepoch_num: 100\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \texclude_class: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \textra_train_dataset: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlast_lif: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.001\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_sg_width: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_decay: 0.5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_init: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_reset: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_threshold: 0.75\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmerge_polarities: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmy_seed: 42\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnet_print: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_workers: 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer_what: SGD\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tpin_memory: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tpre_trained: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tpre_trained_path: net_save/save_now_net_weights_{unique_name}.pth\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \trate_coding: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tscheduler_name: no\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsingle_step: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsurrogate: hard_sigmoid\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_conv_kernel_size: 3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_conv_padding: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_conv_stride: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_trace_const1: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_trace_const2: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \ttdBN_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \ttrace_on: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \twhich_data: DVS_GESTURE_TONIC\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.19.10 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.17.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/data2/bh_wandb/wandb/run-20250430_085034-3j0jo68j</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/3j0jo68j' target=\"_blank\">likely-sweep-256</a></strong> to <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/6pj3lh8j' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/6pj3lh8j</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/6pj3lh8j' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/6pj3lh8j</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/3j0jo68j' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/3j0jo68j</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'single_step' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'my_seed' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'TIME' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BATCH' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'IMAGE_SIZE' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'which_data' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'data_path' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'rate_coding' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_init' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_decay' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_threshold' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_reset' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_sg_width' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_conv_kernel_size' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_conv_stride' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_conv_padding' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_trace_const1' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_trace_const2' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'pre_trained' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'convTrue_fcFalse' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'cfg' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'net_print' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'pre_trained_path' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'learning_rate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'epoch_num' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'tdBN_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BN_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'surrogate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BPTT_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'optimizer_what' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'scheduler_name' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'ddp_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'dvs_clipping' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'dvs_duration' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'DFA_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'trace_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'OTTT_input_trace_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'exclude_class' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'merge_polarities' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'denoise_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'extra_train_dataset' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'num_workers' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'chaching_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'pin_memory' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'UDA_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'alpha_uda' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'bias' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'last_lif' was locked by 'sweep' (ignored update).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "param {'devices': '0', 'single_step': True, 'unique_name': 'main', 'my_seed': 42, 'TIME': 10, 'BATCH': 16, 'IMAGE_SIZE': 128, 'which_data': 'DVS_GESTURE_TONIC', 'data_path': '/data2', 'rate_coding': False, 'lif_layer_v_init': 0, 'lif_layer_v_decay': 0.5, 'lif_layer_v_threshold': 0.75, 'lif_layer_v_reset': 0, 'lif_layer_sg_width': 1, 'synapse_conv_kernel_size': 3, 'synapse_conv_stride': 1, 'synapse_conv_padding': 1, 'synapse_trace_const1': 1, 'synapse_trace_const2': 0, 'pre_trained': False, 'convTrue_fcFalse': False, 'cfg': ['M', 'M', 200, 200], 'net_print': True, 'pre_trained_path': 'net_save/save_now_net_weights_{unique_name}.pth', 'learning_rate': 0.001, 'epoch_num': 100, 'tdBN_on': False, 'BN_on': False, 'surrogate': 'hard_sigmoid', 'BPTT_on': False, 'optimizer_what': 'SGD', 'scheduler_name': 'no', 'ddp_on': False, 'dvs_clipping': 5, 'dvs_duration': 100000, 'DFA_on': False, 'trace_on': True, 'OTTT_input_trace_on': False, 'exclude_class': True, 'merge_polarities': False, 'denoise_on': False, 'extra_train_dataset': 0, 'num_workers': 2, 'chaching_on': True, 'pin_memory': True, 'UDA_on': False, 'alpha_uda': 1, 'bias': True, 'last_lif': False, 'current epoch': 0} \n",
      "\n",
      "dataset_hash = ffa516e60c3efd5e0208f72b4c36cb84\n",
      "cache path exists\n",
      "\n",
      "device ==> cuda\n",
      "\n",
      "DataParallel(\n",
      "  (module): REBORN_MY_SNN_FC(\n",
      "    (layers): REBORN_MY_Sequential(\n",
      "      (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (2): DimChanger_for_FC()\n",
      "      (3): SYNAPSE_FC(in_features=2048, out_features=200, TIME=10, bias=True, sstep=True)\n",
      "      (4): LIF_layer(v_init=0, v_decay=0.5, v_threshold=0.75, v_reset=0, sg_width=1, surrogate=hard_sigmoid, BPTT_on=False, trace_const1=1, trace_const2=0, TIME=10, sstep=True, trace_on=True)\n",
      "      (5): SYNAPSE_FC(in_features=200, out_features=200, TIME=10, bias=True, sstep=True)\n",
      "      (6): LIF_layer(v_init=0, v_decay=0.5, v_threshold=0.75, v_reset=0, sg_width=1, surrogate=hard_sigmoid, BPTT_on=False, trace_const1=1, trace_const2=0, TIME=10, sstep=True, trace_on=True)\n",
      "      (7): SYNAPSE_FC(in_features=200, out_features=10, TIME=10, bias=True, sstep=True)\n",
      "    )\n",
      "  )\n",
      ")\n",
      "\n",
      "========================================================\n",
      "Trainable parameters: 452,010\n",
      "========================================================\n",
      "\n",
      "epoch-0   lr=['0.0010000'], tr/val_loss:  2.305365/  2.302841, val:  10.00%, val_best:  10.00%, tr:   8.17%, tr_best:   8.17%\n",
      "epoch-1   lr=['0.0010000'], tr/val_loss:  2.304994/  2.302639, val:  10.00%, val_best:  10.00%, tr:   7.66%, tr_best:   8.17%\n",
      "epoch-2   lr=['0.0010000'], tr/val_loss:  2.305079/  2.302667, val:  10.00%, val_best:  10.00%, tr:   8.99%, tr_best:   8.99%\n",
      "epoch-3   lr=['0.0010000'], tr/val_loss:  2.304731/  2.302708, val:  10.00%, val_best:  10.00%, tr:   8.38%, tr_best:   8.99%\n",
      "epoch-4   lr=['0.0010000'], tr/val_loss:  2.304833/  2.302682, val:  10.00%, val_best:  10.00%, tr:   7.87%, tr_best:   8.99%\n",
      "epoch-5   lr=['0.0010000'], tr/val_loss:  2.304569/  2.302663, val:  10.00%, val_best:  10.00%, tr:   7.87%, tr_best:   8.99%\n",
      "epoch-6   lr=['0.0010000'], tr/val_loss:  2.305083/  2.302701, val:  10.00%, val_best:  10.00%, tr:   9.70%, tr_best:   9.70%\n",
      "epoch-7   lr=['0.0010000'], tr/val_loss:  2.304608/  2.302707, val:  10.42%, val_best:  10.42%, tr:   7.46%, tr_best:   9.70%\n",
      "epoch-8   lr=['0.0010000'], tr/val_loss:  2.304415/  2.302429, val:   9.58%, val_best:  10.42%, tr:   8.38%, tr_best:   9.70%\n",
      "epoch-9   lr=['0.0010000'], tr/val_loss:  2.304352/  2.301672, val:  10.42%, val_best:  10.42%, tr:   9.19%, tr_best:   9.70%\n",
      "epoch-10  lr=['0.0010000'], tr/val_loss:  2.301033/  2.297719, val:  10.83%, val_best:  10.83%, tr:  10.73%, tr_best:  10.73%\n",
      "epoch-11  lr=['0.0010000'], tr/val_loss:  2.289144/  2.284337, val:  14.17%, val_best:  14.17%, tr:  12.46%, tr_best:  12.46%\n",
      "epoch-12  lr=['0.0010000'], tr/val_loss:  2.252194/  2.249887, val:  20.00%, val_best:  20.00%, tr:  18.69%, tr_best:  18.69%\n",
      "epoch-13  lr=['0.0010000'], tr/val_loss:  2.196875/  2.205824, val:  29.58%, val_best:  29.58%, tr:  19.92%, tr_best:  19.92%\n",
      "epoch-14  lr=['0.0010000'], tr/val_loss:  2.128753/  2.139140, val:  32.92%, val_best:  32.92%, tr:  25.43%, tr_best:  25.43%\n",
      "epoch-15  lr=['0.0010000'], tr/val_loss:  2.031920/  2.040772, val:  36.67%, val_best:  36.67%, tr:  34.63%, tr_best:  34.63%\n",
      "epoch-16  lr=['0.0010000'], tr/val_loss:  1.915434/  1.937572, val:  42.92%, val_best:  42.92%, tr:  40.45%, tr_best:  40.45%\n",
      "epoch-17  lr=['0.0010000'], tr/val_loss:  1.795134/  1.828046, val:  46.25%, val_best:  46.25%, tr:  44.23%, tr_best:  44.23%\n",
      "epoch-18  lr=['0.0010000'], tr/val_loss:  1.674060/  1.738066, val:  47.50%, val_best:  47.50%, tr:  47.91%, tr_best:  47.91%\n",
      "epoch-19  lr=['0.0010000'], tr/val_loss:  1.583916/  1.670929, val:  49.58%, val_best:  49.58%, tr:  47.40%, tr_best:  47.91%\n",
      "epoch-20  lr=['0.0010000'], tr/val_loss:  1.516682/  1.621242, val:  47.50%, val_best:  49.58%, tr:  51.07%, tr_best:  51.07%\n",
      "epoch-21  lr=['0.0010000'], tr/val_loss:  1.459616/  1.584080, val:  50.00%, val_best:  50.00%, tr:  53.83%, tr_best:  53.83%\n",
      "epoch-22  lr=['0.0010000'], tr/val_loss:  1.421688/  1.550777, val:  54.17%, val_best:  54.17%, tr:  54.55%, tr_best:  54.55%\n",
      "epoch-23  lr=['0.0010000'], tr/val_loss:  1.378976/  1.524027, val:  54.58%, val_best:  54.58%, tr:  57.30%, tr_best:  57.30%\n",
      "epoch-24  lr=['0.0010000'], tr/val_loss:  1.345043/  1.499318, val:  56.67%, val_best:  56.67%, tr:  58.94%, tr_best:  58.94%\n",
      "epoch-25  lr=['0.0010000'], tr/val_loss:  1.318475/  1.471272, val:  55.42%, val_best:  56.67%, tr:  57.00%, tr_best:  58.94%\n",
      "epoch-26  lr=['0.0010000'], tr/val_loss:  1.293493/  1.446691, val:  55.00%, val_best:  56.67%, tr:  58.94%, tr_best:  58.94%\n",
      "epoch-27  lr=['0.0010000'], tr/val_loss:  1.265036/  1.428966, val:  56.67%, val_best:  56.67%, tr:  59.04%, tr_best:  59.04%\n",
      "epoch-28  lr=['0.0010000'], tr/val_loss:  1.254488/  1.413823, val:  56.25%, val_best:  56.67%, tr:  59.96%, tr_best:  59.96%\n",
      "epoch-29  lr=['0.0010000'], tr/val_loss:  1.223947/  1.403415, val:  53.75%, val_best:  56.67%, tr:  60.47%, tr_best:  60.47%\n",
      "epoch-30  lr=['0.0010000'], tr/val_loss:  1.207743/  1.400833, val:  53.75%, val_best:  56.67%, tr:  61.49%, tr_best:  61.49%\n",
      "epoch-31  lr=['0.0010000'], tr/val_loss:  1.190792/  1.378956, val:  57.08%, val_best:  57.08%, tr:  61.39%, tr_best:  61.49%\n",
      "epoch-32  lr=['0.0010000'], tr/val_loss:  1.173898/  1.377950, val:  58.33%, val_best:  58.33%, tr:  63.23%, tr_best:  63.23%\n",
      "epoch-33  lr=['0.0010000'], tr/val_loss:  1.165500/  1.358947, val:  57.50%, val_best:  58.33%, tr:  61.70%, tr_best:  63.23%\n",
      "epoch-34  lr=['0.0010000'], tr/val_loss:  1.142139/  1.340049, val:  57.92%, val_best:  58.33%, tr:  62.61%, tr_best:  63.23%\n",
      "epoch-35  lr=['0.0010000'], tr/val_loss:  1.119631/  1.347286, val:  58.33%, val_best:  58.33%, tr:  63.23%, tr_best:  63.23%\n",
      "epoch-36  lr=['0.0010000'], tr/val_loss:  1.111184/  1.333692, val:  57.50%, val_best:  58.33%, tr:  64.35%, tr_best:  64.35%\n",
      "epoch-37  lr=['0.0010000'], tr/val_loss:  1.096463/  1.323113, val:  61.67%, val_best:  61.67%, tr:  64.96%, tr_best:  64.96%\n",
      "epoch-38  lr=['0.0010000'], tr/val_loss:  1.087067/  1.323128, val:  57.08%, val_best:  61.67%, tr:  65.47%, tr_best:  65.47%\n",
      "epoch-39  lr=['0.0010000'], tr/val_loss:  1.068989/  1.308931, val:  60.00%, val_best:  61.67%, tr:  66.39%, tr_best:  66.39%\n",
      "epoch-40  lr=['0.0010000'], tr/val_loss:  1.056788/  1.305247, val:  62.92%, val_best:  62.92%, tr:  63.43%, tr_best:  66.39%\n",
      "epoch-41  lr=['0.0010000'], tr/val_loss:  1.051601/  1.297224, val:  60.00%, val_best:  62.92%, tr:  67.93%, tr_best:  67.93%\n",
      "epoch-42  lr=['0.0010000'], tr/val_loss:  1.029117/  1.295047, val:  60.83%, val_best:  62.92%, tr:  66.70%, tr_best:  67.93%\n",
      "epoch-43  lr=['0.0010000'], tr/val_loss:  1.023379/  1.295685, val:  61.67%, val_best:  62.92%, tr:  67.52%, tr_best:  67.93%\n",
      "epoch-44  lr=['0.0010000'], tr/val_loss:  1.007172/  1.289299, val:  62.08%, val_best:  62.92%, tr:  68.03%, tr_best:  68.03%\n",
      "epoch-45  lr=['0.0010000'], tr/val_loss:  0.996358/  1.276643, val:  61.67%, val_best:  62.92%, tr:  69.46%, tr_best:  69.46%\n",
      "epoch-46  lr=['0.0010000'], tr/val_loss:  0.985111/  1.290235, val:  61.25%, val_best:  62.92%, tr:  68.85%, tr_best:  69.46%\n",
      "epoch-47  lr=['0.0010000'], tr/val_loss:  0.988237/  1.290247, val:  60.83%, val_best:  62.92%, tr:  69.36%, tr_best:  69.46%\n",
      "epoch-48  lr=['0.0010000'], tr/val_loss:  0.978099/  1.278946, val:  60.83%, val_best:  62.92%, tr:  69.15%, tr_best:  69.46%\n",
      "epoch-49  lr=['0.0010000'], tr/val_loss:  0.967768/  1.269218, val:  64.17%, val_best:  64.17%, tr:  68.23%, tr_best:  69.46%\n",
      "epoch-50  lr=['0.0010000'], tr/val_loss:  0.956317/  1.281602, val:  60.83%, val_best:  64.17%, tr:  70.07%, tr_best:  70.07%\n",
      "epoch-51  lr=['0.0010000'], tr/val_loss:  0.948518/  1.265274, val:  64.58%, val_best:  64.58%, tr:  69.87%, tr_best:  70.07%\n",
      "epoch-52  lr=['0.0010000'], tr/val_loss:  0.947431/  1.272149, val:  63.33%, val_best:  64.58%, tr:  69.87%, tr_best:  70.07%\n",
      "epoch-53  lr=['0.0010000'], tr/val_loss:  0.934407/  1.260431, val:  67.08%, val_best:  67.08%, tr:  71.30%, tr_best:  71.30%\n",
      "epoch-54  lr=['0.0010000'], tr/val_loss:  0.923584/  1.274025, val:  62.08%, val_best:  67.08%, tr:  71.60%, tr_best:  71.60%\n",
      "epoch-55  lr=['0.0010000'], tr/val_loss:  0.913001/  1.260859, val:  65.00%, val_best:  67.08%, tr:  73.24%, tr_best:  73.24%\n",
      "epoch-56  lr=['0.0010000'], tr/val_loss:  0.900412/  1.257683, val:  65.42%, val_best:  67.08%, tr:  73.75%, tr_best:  73.75%\n",
      "epoch-57  lr=['0.0010000'], tr/val_loss:  0.896978/  1.262905, val:  66.25%, val_best:  67.08%, tr:  72.83%, tr_best:  73.75%\n",
      "epoch-58  lr=['0.0010000'], tr/val_loss:  0.883533/  1.276003, val:  65.00%, val_best:  67.08%, tr:  72.01%, tr_best:  73.75%\n",
      "epoch-59  lr=['0.0010000'], tr/val_loss:  0.889863/  1.263737, val:  64.17%, val_best:  67.08%, tr:  72.22%, tr_best:  73.75%\n",
      "epoch-60  lr=['0.0010000'], tr/val_loss:  0.878457/  1.259848, val:  62.92%, val_best:  67.08%, tr:  71.50%, tr_best:  73.75%\n",
      "epoch-61  lr=['0.0010000'], tr/val_loss:  0.877838/  1.260389, val:  65.00%, val_best:  67.08%, tr:  73.34%, tr_best:  73.75%\n",
      "epoch-62  lr=['0.0010000'], tr/val_loss:  0.870337/  1.264962, val:  62.92%, val_best:  67.08%, tr:  74.57%, tr_best:  74.57%\n",
      "epoch-63  lr=['0.0010000'], tr/val_loss:  0.854991/  1.257392, val:  65.00%, val_best:  67.08%, tr:  73.14%, tr_best:  74.57%\n",
      "epoch-64  lr=['0.0010000'], tr/val_loss:  0.846049/  1.283253, val:  61.67%, val_best:  67.08%, tr:  74.77%, tr_best:  74.77%\n",
      "epoch-65  lr=['0.0010000'], tr/val_loss:  0.844372/  1.265521, val:  61.67%, val_best:  67.08%, tr:  74.87%, tr_best:  74.87%\n",
      "epoch-66  lr=['0.0010000'], tr/val_loss:  0.842656/  1.259839, val:  65.42%, val_best:  67.08%, tr:  74.57%, tr_best:  74.87%\n",
      "epoch-67  lr=['0.0010000'], tr/val_loss:  0.842144/  1.277846, val:  63.33%, val_best:  67.08%, tr:  76.00%, tr_best:  76.00%\n",
      "epoch-68  lr=['0.0010000'], tr/val_loss:  0.828740/  1.275990, val:  63.75%, val_best:  67.08%, tr:  75.28%, tr_best:  76.00%\n",
      "epoch-69  lr=['0.0010000'], tr/val_loss:  0.820042/  1.275623, val:  64.58%, val_best:  67.08%, tr:  75.69%, tr_best:  76.00%\n",
      "epoch-70  lr=['0.0010000'], tr/val_loss:  0.811864/  1.280213, val:  64.58%, val_best:  67.08%, tr:  76.30%, tr_best:  76.30%\n",
      "epoch-71  lr=['0.0010000'], tr/val_loss:  0.803354/  1.291527, val:  62.50%, val_best:  67.08%, tr:  76.61%, tr_best:  76.61%\n",
      "epoch-72  lr=['0.0010000'], tr/val_loss:  0.799714/  1.297887, val:  65.00%, val_best:  67.08%, tr:  76.20%, tr_best:  76.61%\n",
      "epoch-73  lr=['0.0010000'], tr/val_loss:  0.802400/  1.286885, val:  63.33%, val_best:  67.08%, tr:  75.28%, tr_best:  76.61%\n",
      "epoch-74  lr=['0.0010000'], tr/val_loss:  0.788033/  1.284983, val:  62.92%, val_best:  67.08%, tr:  74.87%, tr_best:  76.61%\n",
      "epoch-75  lr=['0.0010000'], tr/val_loss:  0.791896/  1.278403, val:  67.50%, val_best:  67.50%, tr:  76.61%, tr_best:  76.61%\n",
      "epoch-76  lr=['0.0010000'], tr/val_loss:  0.770098/  1.293749, val:  65.83%, val_best:  67.50%, tr:  77.73%, tr_best:  77.73%\n",
      "epoch-77  lr=['0.0010000'], tr/val_loss:  0.786196/  1.304875, val:  64.17%, val_best:  67.50%, tr:  77.73%, tr_best:  77.73%\n",
      "epoch-78  lr=['0.0010000'], tr/val_loss:  0.775848/  1.284890, val:  65.83%, val_best:  67.50%, tr:  78.65%, tr_best:  78.65%\n",
      "epoch-79  lr=['0.0010000'], tr/val_loss:  0.758541/  1.297486, val:  64.17%, val_best:  67.50%, tr:  78.96%, tr_best:  78.96%\n",
      "epoch-80  lr=['0.0010000'], tr/val_loss:  0.752219/  1.299960, val:  62.50%, val_best:  67.50%, tr:  78.04%, tr_best:  78.96%\n",
      "epoch-81  lr=['0.0010000'], tr/val_loss:  0.756388/  1.295685, val:  63.33%, val_best:  67.50%, tr:  78.86%, tr_best:  78.96%\n",
      "epoch-82  lr=['0.0010000'], tr/val_loss:  0.741953/  1.304229, val:  66.67%, val_best:  67.50%, tr:  78.96%, tr_best:  78.96%\n",
      "epoch-83  lr=['0.0010000'], tr/val_loss:  0.742929/  1.285022, val:  68.75%, val_best:  68.75%, tr:  80.39%, tr_best:  80.39%\n",
      "epoch-84  lr=['0.0010000'], tr/val_loss:  0.740396/  1.294914, val:  66.67%, val_best:  68.75%, tr:  82.12%, tr_best:  82.12%\n",
      "epoch-85  lr=['0.0010000'], tr/val_loss:  0.734239/  1.308131, val:  65.00%, val_best:  68.75%, tr:  81.92%, tr_best:  82.12%\n",
      "epoch-86  lr=['0.0010000'], tr/val_loss:  0.719190/  1.302355, val:  66.67%, val_best:  68.75%, tr:  80.90%, tr_best:  82.12%\n",
      "epoch-87  lr=['0.0010000'], tr/val_loss:  0.717184/  1.296071, val:  68.75%, val_best:  68.75%, tr:  83.25%, tr_best:  83.25%\n",
      "epoch-88  lr=['0.0010000'], tr/val_loss:  0.712152/  1.314696, val:  65.00%, val_best:  68.75%, tr:  80.08%, tr_best:  83.25%\n",
      "epoch-89  lr=['0.0010000'], tr/val_loss:  0.702404/  1.334584, val:  64.58%, val_best:  68.75%, tr:  82.12%, tr_best:  83.25%\n",
      "epoch-90  lr=['0.0010000'], tr/val_loss:  0.710129/  1.323049, val:  68.75%, val_best:  68.75%, tr:  80.80%, tr_best:  83.25%\n",
      "epoch-91  lr=['0.0010000'], tr/val_loss:  0.691019/  1.323363, val:  67.08%, val_best:  68.75%, tr:  83.86%, tr_best:  83.86%\n",
      "epoch-92  lr=['0.0010000'], tr/val_loss:  0.692165/  1.331189, val:  67.08%, val_best:  68.75%, tr:  81.41%, tr_best:  83.86%\n",
      "epoch-93  lr=['0.0010000'], tr/val_loss:  0.693716/  1.327685, val:  69.17%, val_best:  69.17%, tr:  83.25%, tr_best:  83.86%\n",
      "epoch-94  lr=['0.0010000'], tr/val_loss:  0.687860/  1.339606, val:  67.50%, val_best:  69.17%, tr:  81.00%, tr_best:  83.86%\n",
      "epoch-95  lr=['0.0010000'], tr/val_loss:  0.672576/  1.325776, val:  68.75%, val_best:  69.17%, tr:  82.84%, tr_best:  83.86%\n",
      "epoch-96  lr=['0.0010000'], tr/val_loss:  0.675624/  1.346071, val:  66.67%, val_best:  69.17%, tr:  85.09%, tr_best:  85.09%\n",
      "epoch-97  lr=['0.0010000'], tr/val_loss:  0.665271/  1.331502, val:  69.58%, val_best:  69.58%, tr:  81.92%, tr_best:  85.09%\n",
      "epoch-98  lr=['0.0010000'], tr/val_loss:  0.669430/  1.354253, val:  67.92%, val_best:  69.58%, tr:  84.58%, tr_best:  85.09%\n",
      "epoch-99  lr=['0.0010000'], tr/val_loss:  0.669783/  1.337558, val:  70.00%, val_best:  70.00%, tr:  84.47%, tr_best:  85.09%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e85539db090e492eab868076f0414973",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.006 MB of 0.006 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>iter_acc</td><td>▁▂▁▁▁▃▃▄▃▆▆▆▆▅▅▅▆▅█▆▅▆▅▅▇▇▇▇▆▅▆▇▅▇▅▆▆▇█▇</td></tr><tr><td>summary_val_acc</td><td>▁▁▁▁▁▂▄▅▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇█▇▇▇▇▇▇█▇▇███▇███</td></tr><tr><td>tr_acc</td><td>▁▁▁▁▁▂▃▄▅▅▆▆▆▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇████████</td></tr><tr><td>tr_epoch_loss</td><td>██████▇▆▅▄▄▄▃▃▃▃▃▃▂▂▂▂▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁</td></tr><tr><td>val_acc_best</td><td>▁▁▁▁▁▂▄▅▆▆▆▆▆▇▇▇▇▇▇▇▇▇██████████████████</td></tr><tr><td>val_acc_now</td><td>▁▁▁▁▁▂▄▅▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇█▇▇▇▇▇▇█▇▇███▇███</td></tr><tr><td>val_loss</td><td>██████▇▅▄▃▃▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>99</td></tr><tr><td>iter_acc</td><td>1.0</td></tr><tr><td>tr_acc</td><td>0.84474</td></tr><tr><td>tr_epoch_loss</td><td>0.66978</td></tr><tr><td>val_acc_best</td><td>0.7</td></tr><tr><td>val_acc_now</td><td>0.7</td></tr><tr><td>val_loss</td><td>1.33756</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">likely-sweep-256</strong> at: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/3j0jo68j' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/3j0jo68j</a><br/> View project at: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>/data2/bh_wandb/wandb/run-20250430_085034-3j0jo68j/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require(\"core\")`! See https://wandb.me/wandb-core for more information."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Sweep Agent: Waiting for job.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Job received.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: va9u7k62 with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBATCH: 16\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBN_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBPTT_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tDFA_on: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tIMAGE_SIZE: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tOTTT_input_trace_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tTIME: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tUDA_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \talpha_uda: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbias: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcfg: ['M', 'M', 200, 200]\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tchaching_on: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tconvTrue_fcFalse: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdata_path: /data2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tddp_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdenoise_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdvs_clipping: 5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdvs_duration: 100000\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepoch_num: 100\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \texclude_class: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \textra_train_dataset: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlast_lif: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.0001\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_sg_width: 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_decay: 0.5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_init: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_reset: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_threshold: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmerge_polarities: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmy_seed: 42\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnet_print: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_workers: 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer_what: SGD\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tpin_memory: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tpre_trained: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tpre_trained_path: net_save/save_now_net_weights_{unique_name}.pth\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \trate_coding: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tscheduler_name: no\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsingle_step: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsurrogate: hard_sigmoid\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_conv_kernel_size: 3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_conv_padding: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_conv_stride: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_trace_const1: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_trace_const2: 0.5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \ttdBN_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \ttrace_on: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \twhich_data: DVS_GESTURE_TONIC\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.19.10 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.17.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/data2/bh_wandb/wandb/run-20250430_085642-va9u7k62</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/va9u7k62' target=\"_blank\">whole-sweep-258</a></strong> to <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/6pj3lh8j' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/6pj3lh8j</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/6pj3lh8j' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/6pj3lh8j</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/va9u7k62' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/va9u7k62</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'single_step' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'my_seed' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'TIME' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BATCH' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'IMAGE_SIZE' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'which_data' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'data_path' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'rate_coding' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_init' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_decay' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_threshold' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_reset' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_sg_width' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_conv_kernel_size' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_conv_stride' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_conv_padding' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_trace_const1' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_trace_const2' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'pre_trained' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'convTrue_fcFalse' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'cfg' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'net_print' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'pre_trained_path' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'learning_rate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'epoch_num' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'tdBN_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BN_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'surrogate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BPTT_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'optimizer_what' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'scheduler_name' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'ddp_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'dvs_clipping' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'dvs_duration' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'DFA_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'trace_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'OTTT_input_trace_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'exclude_class' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'merge_polarities' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'denoise_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'extra_train_dataset' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'num_workers' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'chaching_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'pin_memory' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'UDA_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'alpha_uda' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'bias' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'last_lif' was locked by 'sweep' (ignored update).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "param {'devices': '0', 'single_step': True, 'unique_name': 'main', 'my_seed': 42, 'TIME': 10, 'BATCH': 16, 'IMAGE_SIZE': 128, 'which_data': 'DVS_GESTURE_TONIC', 'data_path': '/data2', 'rate_coding': False, 'lif_layer_v_init': 0, 'lif_layer_v_decay': 0.5, 'lif_layer_v_threshold': 1, 'lif_layer_v_reset': 0, 'lif_layer_sg_width': 2, 'synapse_conv_kernel_size': 3, 'synapse_conv_stride': 1, 'synapse_conv_padding': 1, 'synapse_trace_const1': 1, 'synapse_trace_const2': 0.5, 'pre_trained': False, 'convTrue_fcFalse': False, 'cfg': ['M', 'M', 200, 200], 'net_print': True, 'pre_trained_path': 'net_save/save_now_net_weights_{unique_name}.pth', 'learning_rate': 0.0001, 'epoch_num': 100, 'tdBN_on': False, 'BN_on': False, 'surrogate': 'hard_sigmoid', 'BPTT_on': False, 'optimizer_what': 'SGD', 'scheduler_name': 'no', 'ddp_on': False, 'dvs_clipping': 5, 'dvs_duration': 100000, 'DFA_on': True, 'trace_on': True, 'OTTT_input_trace_on': False, 'exclude_class': True, 'merge_polarities': False, 'denoise_on': False, 'extra_train_dataset': 0, 'num_workers': 2, 'chaching_on': True, 'pin_memory': True, 'UDA_on': False, 'alpha_uda': 1, 'bias': True, 'last_lif': False, 'current epoch': 0} \n",
      "\n",
      "dataset_hash = ffa516e60c3efd5e0208f72b4c36cb84\n",
      "cache path exists\n",
      "\n",
      "device ==> cuda\n",
      "\n",
      "DataParallel(\n",
      "  (module): REBORN_MY_SNN_FC(\n",
      "    (layers): REBORN_MY_Sequential(\n",
      "      (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (2): DimChanger_for_FC()\n",
      "      (3): SYNAPSE_FC(in_features=2048, out_features=200, TIME=10, bias=True, sstep=True)\n",
      "      (4): LIF_layer(v_init=0, v_decay=0.5, v_threshold=1, v_reset=0, sg_width=2, surrogate=hard_sigmoid, BPTT_on=False, trace_const1=1, trace_const2=0.5, TIME=10, sstep=True, trace_on=True)\n",
      "      (5): Feedback_Receiver()\n",
      "      (6): SYNAPSE_FC(in_features=200, out_features=200, TIME=10, bias=True, sstep=True)\n",
      "      (7): LIF_layer(v_init=0, v_decay=0.5, v_threshold=1, v_reset=0, sg_width=2, surrogate=hard_sigmoid, BPTT_on=False, trace_const1=1, trace_const2=0.5, TIME=10, sstep=True, trace_on=True)\n",
      "      (8): Feedback_Receiver()\n",
      "      (9): SYNAPSE_FC(in_features=200, out_features=10, TIME=10, bias=True, sstep=True)\n",
      "      (DFA_top): Top_Gradient()\n",
      "    )\n",
      "  )\n",
      ")\n",
      "\n",
      "========================================================\n",
      "Trainable parameters: 452,010\n",
      "========================================================\n",
      "\n",
      "epoch-0   lr=['0.0001000'], tr/val_loss:  2.303353/  2.303047, val:  10.00%, val_best:  10.00%, tr:  10.01%, tr_best:  10.01%\n",
      "[module.layers.5] weight_fb parameter count: 2,000\n",
      "[module.layers.8] weight_fb parameter count: 2,000\n",
      "epoch-1   lr=['0.0001000'], tr/val_loss:  2.303309/  2.302968, val:  10.00%, val_best:  10.00%, tr:  10.01%, tr_best:  10.01%\n",
      "epoch-2   lr=['0.0001000'], tr/val_loss:  2.303253/  2.302913, val:  10.00%, val_best:  10.00%, tr:  10.01%, tr_best:  10.01%\n",
      "epoch-3   lr=['0.0001000'], tr/val_loss:  2.303180/  2.302890, val:  10.00%, val_best:  10.00%, tr:  10.01%, tr_best:  10.01%\n",
      "epoch-4   lr=['0.0001000'], tr/val_loss:  2.303389/  2.302858, val:  10.00%, val_best:  10.00%, tr:  10.01%, tr_best:  10.01%\n",
      "epoch-5   lr=['0.0001000'], tr/val_loss:  2.303003/  2.302804, val:  10.00%, val_best:  10.00%, tr:  10.01%, tr_best:  10.01%\n",
      "epoch-6   lr=['0.0001000'], tr/val_loss:  2.302938/  2.302720, val:  10.83%, val_best:  10.83%, tr:   9.91%, tr_best:  10.01%\n",
      "epoch-7   lr=['0.0001000'], tr/val_loss:  2.302854/  2.302560, val:  10.83%, val_best:  10.83%, tr:  10.73%, tr_best:  10.73%\n",
      "epoch-8   lr=['0.0001000'], tr/val_loss:  2.301850/  2.301905, val:  12.08%, val_best:  12.08%, tr:  12.56%, tr_best:  12.56%\n",
      "epoch-9   lr=['0.0001000'], tr/val_loss:  2.300014/  2.299596, val:  12.50%, val_best:  12.50%, tr:  13.79%, tr_best:  13.79%\n",
      "epoch-10  lr=['0.0001000'], tr/val_loss:  2.295757/  2.293708, val:  13.75%, val_best:  13.75%, tr:  13.79%, tr_best:  13.79%\n",
      "epoch-11  lr=['0.0001000'], tr/val_loss:  2.284320/  2.279217, val:  14.58%, val_best:  14.58%, tr:  12.97%, tr_best:  13.79%\n",
      "epoch-12  lr=['0.0001000'], tr/val_loss:  2.258980/  2.250829, val:  17.50%, val_best:  17.50%, tr:  14.10%, tr_best:  14.10%\n",
      "epoch-13  lr=['0.0001000'], tr/val_loss:  2.216767/  2.205510, val:  21.67%, val_best:  21.67%, tr:  19.82%, tr_best:  19.82%\n",
      "epoch-14  lr=['0.0001000'], tr/val_loss:  2.160669/  2.153185, val:  22.92%, val_best:  22.92%, tr:  21.35%, tr_best:  21.35%\n",
      "epoch-15  lr=['0.0001000'], tr/val_loss:  2.093920/  2.101458, val:  25.42%, val_best:  25.42%, tr:  23.80%, tr_best:  23.80%\n",
      "epoch-16  lr=['0.0001000'], tr/val_loss:  2.036196/  2.052910, val:  30.42%, val_best:  30.42%, tr:  27.78%, tr_best:  27.78%\n",
      "epoch-17  lr=['0.0001000'], tr/val_loss:  1.976262/  2.002702, val:  33.75%, val_best:  33.75%, tr:  31.36%, tr_best:  31.36%\n",
      "epoch-18  lr=['0.0001000'], tr/val_loss:  1.911925/  1.951219, val:  37.92%, val_best:  37.92%, tr:  35.65%, tr_best:  35.65%\n",
      "epoch-19  lr=['0.0001000'], tr/val_loss:  1.845176/  1.897337, val:  40.83%, val_best:  40.83%, tr:  40.76%, tr_best:  40.76%\n",
      "epoch-20  lr=['0.0001000'], tr/val_loss:  1.788343/  1.848661, val:  43.75%, val_best:  43.75%, tr:  41.68%, tr_best:  41.68%\n",
      "epoch-21  lr=['0.0001000'], tr/val_loss:  1.736842/  1.810503, val:  42.92%, val_best:  43.75%, tr:  45.05%, tr_best:  45.05%\n",
      "epoch-22  lr=['0.0001000'], tr/val_loss:  1.697893/  1.777622, val:  44.58%, val_best:  44.58%, tr:  48.62%, tr_best:  48.62%\n",
      "epoch-23  lr=['0.0001000'], tr/val_loss:  1.654321/  1.747388, val:  45.00%, val_best:  45.00%, tr:  51.17%, tr_best:  51.17%\n",
      "epoch-24  lr=['0.0001000'], tr/val_loss:  1.622987/  1.723605, val:  43.75%, val_best:  45.00%, tr:  53.63%, tr_best:  53.63%\n",
      "epoch-25  lr=['0.0001000'], tr/val_loss:  1.597423/  1.697027, val:  44.58%, val_best:  45.00%, tr:  53.63%, tr_best:  53.63%\n",
      "epoch-26  lr=['0.0001000'], tr/val_loss:  1.568805/  1.675024, val:  45.83%, val_best:  45.83%, tr:  52.40%, tr_best:  53.63%\n",
      "epoch-27  lr=['0.0001000'], tr/val_loss:  1.538492/  1.649724, val:  47.50%, val_best:  47.50%, tr:  57.51%, tr_best:  57.51%\n",
      "epoch-28  lr=['0.0001000'], tr/val_loss:  1.524260/  1.628042, val:  49.58%, val_best:  49.58%, tr:  56.49%, tr_best:  57.51%\n",
      "epoch-29  lr=['0.0001000'], tr/val_loss:  1.492530/  1.617802, val:  50.00%, val_best:  50.00%, tr:  58.12%, tr_best:  58.12%\n",
      "epoch-30  lr=['0.0001000'], tr/val_loss:  1.481381/  1.604287, val:  50.42%, val_best:  50.42%, tr:  58.63%, tr_best:  58.63%\n",
      "epoch-31  lr=['0.0001000'], tr/val_loss:  1.456898/  1.592246, val:  52.08%, val_best:  52.08%, tr:  58.53%, tr_best:  58.63%\n",
      "epoch-32  lr=['0.0001000'], tr/val_loss:  1.439248/  1.581963, val:  52.92%, val_best:  52.92%, tr:  58.84%, tr_best:  58.84%\n",
      "epoch-33  lr=['0.0001000'], tr/val_loss:  1.436196/  1.574735, val:  52.92%, val_best:  52.92%, tr:  60.27%, tr_best:  60.27%\n",
      "epoch-34  lr=['0.0001000'], tr/val_loss:  1.418077/  1.562777, val:  55.00%, val_best:  55.00%, tr:  60.27%, tr_best:  60.27%\n",
      "epoch-35  lr=['0.0001000'], tr/val_loss:  1.398371/  1.551824, val:  53.75%, val_best:  55.00%, tr:  59.04%, tr_best:  60.27%\n",
      "epoch-36  lr=['0.0001000'], tr/val_loss:  1.390952/  1.550849, val:  52.08%, val_best:  55.00%, tr:  60.47%, tr_best:  60.47%\n",
      "epoch-37  lr=['0.0001000'], tr/val_loss:  1.377916/  1.548833, val:  51.67%, val_best:  55.00%, tr:  61.29%, tr_best:  61.29%\n",
      "epoch-38  lr=['0.0001000'], tr/val_loss:  1.369648/  1.535604, val:  55.42%, val_best:  55.42%, tr:  60.37%, tr_best:  61.29%\n",
      "epoch-39  lr=['0.0001000'], tr/val_loss:  1.359540/  1.535915, val:  57.92%, val_best:  57.92%, tr:  61.59%, tr_best:  61.59%\n",
      "epoch-40  lr=['0.0001000'], tr/val_loss:  1.343558/  1.536228, val:  54.17%, val_best:  57.92%, tr:  61.29%, tr_best:  61.59%\n",
      "epoch-41  lr=['0.0001000'], tr/val_loss:  1.342651/  1.531181, val:  56.67%, val_best:  57.92%, tr:  63.02%, tr_best:  63.02%\n",
      "epoch-42  lr=['0.0001000'], tr/val_loss:  1.327901/  1.527621, val:  55.00%, val_best:  57.92%, tr:  63.74%, tr_best:  63.74%\n",
      "epoch-43  lr=['0.0001000'], tr/val_loss:  1.323072/  1.521072, val:  56.25%, val_best:  57.92%, tr:  63.13%, tr_best:  63.74%\n",
      "epoch-44  lr=['0.0001000'], tr/val_loss:  1.313199/  1.527371, val:  55.83%, val_best:  57.92%, tr:  62.72%, tr_best:  63.74%\n",
      "epoch-45  lr=['0.0001000'], tr/val_loss:  1.306541/  1.519795, val:  56.25%, val_best:  57.92%, tr:  63.74%, tr_best:  63.74%\n",
      "epoch-46  lr=['0.0001000'], tr/val_loss:  1.295707/  1.513475, val:  60.83%, val_best:  60.83%, tr:  61.59%, tr_best:  63.74%\n",
      "epoch-47  lr=['0.0001000'], tr/val_loss:  1.296609/  1.517090, val:  57.92%, val_best:  60.83%, tr:  62.31%, tr_best:  63.74%\n",
      "epoch-48  lr=['0.0001000'], tr/val_loss:  1.286442/  1.511635, val:  59.17%, val_best:  60.83%, tr:  63.74%, tr_best:  63.74%\n",
      "epoch-49  lr=['0.0001000'], tr/val_loss:  1.280688/  1.508829, val:  56.25%, val_best:  60.83%, tr:  63.64%, tr_best:  63.74%\n",
      "epoch-50  lr=['0.0001000'], tr/val_loss:  1.277445/  1.512368, val:  57.92%, val_best:  60.83%, tr:  64.04%, tr_best:  64.04%\n",
      "epoch-51  lr=['0.0001000'], tr/val_loss:  1.269882/  1.505761, val:  59.58%, val_best:  60.83%, tr:  63.84%, tr_best:  64.04%\n",
      "epoch-52  lr=['0.0001000'], tr/val_loss:  1.258565/  1.502698, val:  58.33%, val_best:  60.83%, tr:  63.74%, tr_best:  64.04%\n",
      "epoch-53  lr=['0.0001000'], tr/val_loss:  1.257251/  1.503927, val:  60.42%, val_best:  60.83%, tr:  64.66%, tr_best:  64.66%\n",
      "epoch-54  lr=['0.0001000'], tr/val_loss:  1.251640/  1.500693, val:  60.42%, val_best:  60.83%, tr:  67.01%, tr_best:  67.01%\n",
      "epoch-55  lr=['0.0001000'], tr/val_loss:  1.242520/  1.498746, val:  57.50%, val_best:  60.83%, tr:  66.60%, tr_best:  67.01%\n",
      "epoch-56  lr=['0.0001000'], tr/val_loss:  1.229476/  1.491177, val:  59.58%, val_best:  60.83%, tr:  67.31%, tr_best:  67.31%\n",
      "epoch-57  lr=['0.0001000'], tr/val_loss:  1.230585/  1.493446, val:  59.17%, val_best:  60.83%, tr:  66.91%, tr_best:  67.31%\n",
      "epoch-58  lr=['0.0001000'], tr/val_loss:  1.221754/  1.493436, val:  59.58%, val_best:  60.83%, tr:  65.37%, tr_best:  67.31%\n",
      "epoch-59  lr=['0.0001000'], tr/val_loss:  1.223583/  1.489334, val:  60.42%, val_best:  60.83%, tr:  67.01%, tr_best:  67.31%\n",
      "epoch-60  lr=['0.0001000'], tr/val_loss:  1.216731/  1.479708, val:  59.58%, val_best:  60.83%, tr:  64.35%, tr_best:  67.31%\n",
      "epoch-61  lr=['0.0001000'], tr/val_loss:  1.217915/  1.479927, val:  61.67%, val_best:  61.67%, tr:  65.58%, tr_best:  67.31%\n",
      "epoch-62  lr=['0.0001000'], tr/val_loss:  1.211864/  1.472959, val:  60.83%, val_best:  61.67%, tr:  66.39%, tr_best:  67.31%\n",
      "epoch-63  lr=['0.0001000'], tr/val_loss:  1.195427/  1.474419, val:  59.58%, val_best:  61.67%, tr:  67.82%, tr_best:  67.82%\n",
      "epoch-64  lr=['0.0001000'], tr/val_loss:  1.186375/  1.468938, val:  61.67%, val_best:  61.67%, tr:  69.05%, tr_best:  69.05%\n",
      "epoch-65  lr=['0.0001000'], tr/val_loss:  1.189801/  1.476568, val:  60.42%, val_best:  61.67%, tr:  67.42%, tr_best:  69.05%\n",
      "epoch-66  lr=['0.0001000'], tr/val_loss:  1.188884/  1.474936, val:  59.17%, val_best:  61.67%, tr:  69.97%, tr_best:  69.97%\n",
      "epoch-67  lr=['0.0001000'], tr/val_loss:  1.181834/  1.470261, val:  62.08%, val_best:  62.08%, tr:  69.97%, tr_best:  69.97%\n",
      "epoch-68  lr=['0.0001000'], tr/val_loss:  1.175669/  1.472209, val:  58.33%, val_best:  62.08%, tr:  65.88%, tr_best:  69.97%\n",
      "epoch-69  lr=['0.0001000'], tr/val_loss:  1.170304/  1.467947, val:  62.92%, val_best:  62.92%, tr:  70.07%, tr_best:  70.07%\n",
      "epoch-70  lr=['0.0001000'], tr/val_loss:  1.165306/  1.470618, val:  62.50%, val_best:  62.92%, tr:  69.25%, tr_best:  70.07%\n",
      "epoch-71  lr=['0.0001000'], tr/val_loss:  1.161029/  1.469339, val:  62.92%, val_best:  62.92%, tr:  69.87%, tr_best:  70.07%\n",
      "epoch-72  lr=['0.0001000'], tr/val_loss:  1.156914/  1.474918, val:  64.17%, val_best:  64.17%, tr:  67.93%, tr_best:  70.07%\n",
      "epoch-73  lr=['0.0001000'], tr/val_loss:  1.155185/  1.466457, val:  61.67%, val_best:  64.17%, tr:  69.46%, tr_best:  70.07%\n",
      "epoch-74  lr=['0.0001000'], tr/val_loss:  1.147075/  1.476183, val:  60.83%, val_best:  64.17%, tr:  70.07%, tr_best:  70.07%\n",
      "epoch-75  lr=['0.0001000'], tr/val_loss:  1.147706/  1.473466, val:  60.00%, val_best:  64.17%, tr:  70.28%, tr_best:  70.28%\n",
      "epoch-76  lr=['0.0001000'], tr/val_loss:  1.142400/  1.469923, val:  63.75%, val_best:  64.17%, tr:  70.07%, tr_best:  70.28%\n",
      "epoch-77  lr=['0.0001000'], tr/val_loss:  1.145256/  1.473269, val:  60.83%, val_best:  64.17%, tr:  71.30%, tr_best:  71.30%\n",
      "epoch-78  lr=['0.0001000'], tr/val_loss:  1.137693/  1.474349, val:  62.50%, val_best:  64.17%, tr:  70.68%, tr_best:  71.30%\n",
      "epoch-79  lr=['0.0001000'], tr/val_loss:  1.137738/  1.471267, val:  63.75%, val_best:  64.17%, tr:  72.52%, tr_best:  72.52%\n",
      "epoch-80  lr=['0.0001000'], tr/val_loss:  1.128538/  1.471211, val:  64.58%, val_best:  64.58%, tr:  71.09%, tr_best:  72.52%\n",
      "epoch-81  lr=['0.0001000'], tr/val_loss:  1.128519/  1.471791, val:  61.67%, val_best:  64.58%, tr:  72.83%, tr_best:  72.83%\n",
      "epoch-82  lr=['0.0001000'], tr/val_loss:  1.120410/  1.464406, val:  62.50%, val_best:  64.58%, tr:  73.95%, tr_best:  73.95%\n",
      "epoch-83  lr=['0.0001000'], tr/val_loss:  1.122236/  1.464249, val:  65.83%, val_best:  65.83%, tr:  73.75%, tr_best:  73.95%\n",
      "epoch-84  lr=['0.0001000'], tr/val_loss:  1.118438/  1.468242, val:  62.92%, val_best:  65.83%, tr:  73.54%, tr_best:  73.95%\n",
      "epoch-85  lr=['0.0001000'], tr/val_loss:  1.119879/  1.467838, val:  60.83%, val_best:  65.83%, tr:  71.91%, tr_best:  73.95%\n",
      "epoch-86  lr=['0.0001000'], tr/val_loss:  1.102337/  1.468865, val:  60.42%, val_best:  65.83%, tr:  72.52%, tr_best:  73.95%\n",
      "epoch-87  lr=['0.0001000'], tr/val_loss:  1.104501/  1.467722, val:  64.58%, val_best:  65.83%, tr:  75.38%, tr_best:  75.38%\n",
      "epoch-88  lr=['0.0001000'], tr/val_loss:  1.098423/  1.475282, val:  60.83%, val_best:  65.83%, tr:  74.26%, tr_best:  75.38%\n",
      "epoch-89  lr=['0.0001000'], tr/val_loss:  1.092018/  1.482834, val:  63.75%, val_best:  65.83%, tr:  72.42%, tr_best:  75.38%\n",
      "epoch-90  lr=['0.0001000'], tr/val_loss:  1.092569/  1.475079, val:  64.17%, val_best:  65.83%, tr:  73.65%, tr_best:  75.38%\n",
      "epoch-91  lr=['0.0001000'], tr/val_loss:  1.077821/  1.479140, val:  62.92%, val_best:  65.83%, tr:  74.77%, tr_best:  75.38%\n",
      "epoch-92  lr=['0.0001000'], tr/val_loss:  1.086606/  1.476905, val:  63.75%, val_best:  65.83%, tr:  73.54%, tr_best:  75.38%\n",
      "epoch-93  lr=['0.0001000'], tr/val_loss:  1.088363/  1.483124, val:  62.92%, val_best:  65.83%, tr:  76.40%, tr_best:  76.40%\n",
      "epoch-94  lr=['0.0001000'], tr/val_loss:  1.073517/  1.466642, val:  65.00%, val_best:  65.83%, tr:  75.89%, tr_best:  76.40%\n",
      "epoch-95  lr=['0.0001000'], tr/val_loss:  1.075022/  1.471238, val:  63.33%, val_best:  65.83%, tr:  74.77%, tr_best:  76.40%\n",
      "epoch-96  lr=['0.0001000'], tr/val_loss:  1.069606/  1.474976, val:  63.33%, val_best:  65.83%, tr:  76.10%, tr_best:  76.40%\n",
      "epoch-97  lr=['0.0001000'], tr/val_loss:  1.061367/  1.465693, val:  62.50%, val_best:  65.83%, tr:  75.69%, tr_best:  76.40%\n",
      "epoch-98  lr=['0.0001000'], tr/val_loss:  1.066643/  1.462039, val:  65.83%, val_best:  65.83%, tr:  75.08%, tr_best:  76.40%\n",
      "epoch-99  lr=['0.0001000'], tr/val_loss:  1.060613/  1.468572, val:  63.75%, val_best:  65.83%, tr:  75.69%, tr_best:  76.40%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3c5b1df5578642e89a485e19cd4953c3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.006 MB of 0.006 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>iter_acc</td><td>▁▂▁▁▂▁▂▄▂▄▅▄▄▅▆▅▆▅▇▅▅▅▅▅▆▆▆▆▆▅▆▆▆▅▆▆▅▇█▆</td></tr><tr><td>summary_val_acc</td><td>▁▁▁▁▁▂▃▄▅▅▅▆▆▇▇▆▇▇▇▇▇▇▇▇▇█▇███▇█████████</td></tr><tr><td>tr_acc</td><td>▁▁▁▁▁▁▂▃▄▅▆▆▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇█████████</td></tr><tr><td>tr_epoch_loss</td><td>██████▇▆▅▅▄▄▃▃▃▃▃▃▂▂▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_acc_best</td><td>▁▁▁▁▁▂▃▄▅▅▅▅▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇█████████████</td></tr><tr><td>val_acc_now</td><td>▁▁▁▁▁▂▃▄▅▅▅▆▆▇▇▆▇▇▇▇▇▇▇▇▇█▇███▇█████████</td></tr><tr><td>val_loss</td><td>██████▇▅▅▄▃▃▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>99</td></tr><tr><td>iter_acc</td><td>1.0</td></tr><tr><td>tr_acc</td><td>0.75689</td></tr><tr><td>tr_epoch_loss</td><td>1.06061</td></tr><tr><td>val_acc_best</td><td>0.65833</td></tr><tr><td>val_acc_now</td><td>0.6375</td></tr><tr><td>val_loss</td><td>1.46857</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">whole-sweep-258</strong> at: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/va9u7k62' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/va9u7k62</a><br/> View project at: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>/data2/bh_wandb/wandb/run-20250430_085642-va9u7k62/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require(\"core\")`! See https://wandb.me/wandb-core for more information."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: cu8ngqid with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBATCH: 16\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBN_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBPTT_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tDFA_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tIMAGE_SIZE: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tOTTT_input_trace_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tTIME: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tUDA_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \talpha_uda: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbias: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcfg: ['M', 'M', 200, 200]\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tchaching_on: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tconvTrue_fcFalse: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdata_path: /data2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tddp_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdenoise_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdvs_clipping: 5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdvs_duration: 100000\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepoch_num: 100\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \texclude_class: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \textra_train_dataset: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlast_lif: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.001\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_sg_width: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_decay: 0.5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_init: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_reset: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_threshold: 0.25\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmerge_polarities: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmy_seed: 42\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnet_print: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_workers: 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer_what: SGD\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tpin_memory: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tpre_trained: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tpre_trained_path: net_save/save_now_net_weights_{unique_name}.pth\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \trate_coding: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tscheduler_name: no\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsingle_step: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsurrogate: hard_sigmoid\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_conv_kernel_size: 3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_conv_padding: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_conv_stride: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_trace_const1: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_trace_const2: 0.5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \ttdBN_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \ttrace_on: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \twhich_data: DVS_GESTURE_TONIC\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.19.10 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.17.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/data2/bh_wandb/wandb/run-20250430_090314-cu8ngqid</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/cu8ngqid' target=\"_blank\">glamorous-sweep-260</a></strong> to <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/6pj3lh8j' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/6pj3lh8j</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/6pj3lh8j' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/6pj3lh8j</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/cu8ngqid' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/cu8ngqid</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'single_step' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'my_seed' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'TIME' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BATCH' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'IMAGE_SIZE' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'which_data' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'data_path' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'rate_coding' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_init' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_decay' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_threshold' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_reset' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_sg_width' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_conv_kernel_size' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_conv_stride' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_conv_padding' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_trace_const1' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_trace_const2' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'pre_trained' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'convTrue_fcFalse' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'cfg' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'net_print' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'pre_trained_path' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'learning_rate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'epoch_num' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'tdBN_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BN_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'surrogate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BPTT_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'optimizer_what' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'scheduler_name' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'ddp_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'dvs_clipping' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'dvs_duration' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'DFA_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'trace_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'OTTT_input_trace_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'exclude_class' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'merge_polarities' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'denoise_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'extra_train_dataset' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'num_workers' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'chaching_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'pin_memory' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'UDA_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'alpha_uda' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'bias' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'last_lif' was locked by 'sweep' (ignored update).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "param {'devices': '0', 'single_step': True, 'unique_name': 'main', 'my_seed': 42, 'TIME': 10, 'BATCH': 16, 'IMAGE_SIZE': 128, 'which_data': 'DVS_GESTURE_TONIC', 'data_path': '/data2', 'rate_coding': False, 'lif_layer_v_init': 0, 'lif_layer_v_decay': 0.5, 'lif_layer_v_threshold': 0.25, 'lif_layer_v_reset': 0, 'lif_layer_sg_width': 1, 'synapse_conv_kernel_size': 3, 'synapse_conv_stride': 1, 'synapse_conv_padding': 1, 'synapse_trace_const1': 1, 'synapse_trace_const2': 0.5, 'pre_trained': False, 'convTrue_fcFalse': False, 'cfg': ['M', 'M', 200, 200], 'net_print': True, 'pre_trained_path': 'net_save/save_now_net_weights_{unique_name}.pth', 'learning_rate': 0.001, 'epoch_num': 100, 'tdBN_on': False, 'BN_on': False, 'surrogate': 'hard_sigmoid', 'BPTT_on': False, 'optimizer_what': 'SGD', 'scheduler_name': 'no', 'ddp_on': False, 'dvs_clipping': 5, 'dvs_duration': 100000, 'DFA_on': False, 'trace_on': True, 'OTTT_input_trace_on': False, 'exclude_class': True, 'merge_polarities': False, 'denoise_on': False, 'extra_train_dataset': 0, 'num_workers': 2, 'chaching_on': True, 'pin_memory': True, 'UDA_on': False, 'alpha_uda': 1, 'bias': True, 'last_lif': False, 'current epoch': 0} \n",
      "\n",
      "dataset_hash = ffa516e60c3efd5e0208f72b4c36cb84\n",
      "cache path exists\n",
      "\n",
      "device ==> cuda\n",
      "\n",
      "DataParallel(\n",
      "  (module): REBORN_MY_SNN_FC(\n",
      "    (layers): REBORN_MY_Sequential(\n",
      "      (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (2): DimChanger_for_FC()\n",
      "      (3): SYNAPSE_FC(in_features=2048, out_features=200, TIME=10, bias=True, sstep=True)\n",
      "      (4): LIF_layer(v_init=0, v_decay=0.5, v_threshold=0.25, v_reset=0, sg_width=1, surrogate=hard_sigmoid, BPTT_on=False, trace_const1=1, trace_const2=0.5, TIME=10, sstep=True, trace_on=True)\n",
      "      (5): SYNAPSE_FC(in_features=200, out_features=200, TIME=10, bias=True, sstep=True)\n",
      "      (6): LIF_layer(v_init=0, v_decay=0.5, v_threshold=0.25, v_reset=0, sg_width=1, surrogate=hard_sigmoid, BPTT_on=False, trace_const1=1, trace_const2=0.5, TIME=10, sstep=True, trace_on=True)\n",
      "      (7): SYNAPSE_FC(in_features=200, out_features=10, TIME=10, bias=True, sstep=True)\n",
      "    )\n",
      "  )\n",
      ")\n",
      "\n",
      "========================================================\n",
      "Trainable parameters: 452,010\n",
      "========================================================\n",
      "\n",
      "epoch-0   lr=['0.0010000'], tr/val_loss:  2.229940/  2.118104, val:  25.83%, val_best:  25.83%, tr:  19.31%, tr_best:  19.31%\n",
      "epoch-1   lr=['0.0010000'], tr/val_loss:  1.927872/  1.838748, val:  48.33%, val_best:  48.33%, tr:  38.92%, tr_best:  38.92%\n",
      "epoch-2   lr=['0.0010000'], tr/val_loss:  1.645069/  1.657373, val:  48.33%, val_best:  48.33%, tr:  50.87%, tr_best:  50.87%\n",
      "epoch-3   lr=['0.0010000'], tr/val_loss:  1.466910/  1.558705, val:  54.58%, val_best:  54.58%, tr:  56.59%, tr_best:  56.59%\n",
      "epoch-4   lr=['0.0010000'], tr/val_loss:  1.369790/  1.520465, val:  54.58%, val_best:  54.58%, tr:  59.96%, tr_best:  59.96%\n",
      "epoch-5   lr=['0.0010000'], tr/val_loss:  1.296944/  1.467966, val:  57.50%, val_best:  57.50%, tr:  59.96%, tr_best:  59.96%\n",
      "epoch-6   lr=['0.0010000'], tr/val_loss:  1.243518/  1.434255, val:  57.92%, val_best:  57.92%, tr:  63.13%, tr_best:  63.13%\n",
      "epoch-7   lr=['0.0010000'], tr/val_loss:  1.202291/  1.440946, val:  58.75%, val_best:  58.75%, tr:  64.66%, tr_best:  64.66%\n",
      "epoch-8   lr=['0.0010000'], tr/val_loss:  1.155033/  1.396432, val:  64.17%, val_best:  64.17%, tr:  65.88%, tr_best:  65.88%\n",
      "epoch-9   lr=['0.0010000'], tr/val_loss:  1.127630/  1.385198, val:  61.67%, val_best:  64.17%, tr:  68.54%, tr_best:  68.54%\n",
      "epoch-10  lr=['0.0010000'], tr/val_loss:  1.102767/  1.402608, val:  61.25%, val_best:  64.17%, tr:  68.74%, tr_best:  68.74%\n",
      "epoch-11  lr=['0.0010000'], tr/val_loss:  1.067826/  1.369709, val:  62.50%, val_best:  64.17%, tr:  69.87%, tr_best:  69.87%\n",
      "epoch-12  lr=['0.0010000'], tr/val_loss:  1.054068/  1.374061, val:  64.17%, val_best:  64.17%, tr:  71.60%, tr_best:  71.60%\n",
      "epoch-13  lr=['0.0010000'], tr/val_loss:  1.037168/  1.375106, val:  62.92%, val_best:  64.17%, tr:  74.06%, tr_best:  74.06%\n",
      "epoch-14  lr=['0.0010000'], tr/val_loss:  0.985685/  1.410975, val:  59.58%, val_best:  64.17%, tr:  74.06%, tr_best:  74.06%\n",
      "epoch-15  lr=['0.0010000'], tr/val_loss:  0.978980/  1.375767, val:  70.42%, val_best:  70.42%, tr:  74.97%, tr_best:  74.97%\n",
      "epoch-16  lr=['0.0010000'], tr/val_loss:  0.972034/  1.375946, val:  66.25%, val_best:  70.42%, tr:  75.38%, tr_best:  75.38%\n",
      "epoch-17  lr=['0.0010000'], tr/val_loss:  0.933427/  1.342487, val:  70.00%, val_best:  70.42%, tr:  79.98%, tr_best:  79.98%\n",
      "epoch-18  lr=['0.0010000'], tr/val_loss:  0.903065/  1.453013, val:  64.17%, val_best:  70.42%, tr:  79.47%, tr_best:  79.98%\n",
      "epoch-19  lr=['0.0010000'], tr/val_loss:  0.910868/  1.435754, val:  65.00%, val_best:  70.42%, tr:  76.92%, tr_best:  79.98%\n",
      "epoch-20  lr=['0.0010000'], tr/val_loss:  0.875985/  1.435081, val:  68.75%, val_best:  70.42%, tr:  81.61%, tr_best:  81.61%\n",
      "epoch-21  lr=['0.0010000'], tr/val_loss:  0.866041/  1.422851, val:  70.00%, val_best:  70.42%, tr:  80.18%, tr_best:  81.61%\n",
      "epoch-22  lr=['0.0010000'], tr/val_loss:  0.873030/  1.412807, val:  67.08%, val_best:  70.42%, tr:  79.57%, tr_best:  81.61%\n",
      "epoch-23  lr=['0.0010000'], tr/val_loss:  0.837310/  1.424490, val:  70.00%, val_best:  70.42%, tr:  81.82%, tr_best:  81.82%\n",
      "epoch-24  lr=['0.0010000'], tr/val_loss:  0.820816/  1.490834, val:  66.67%, val_best:  70.42%, tr:  83.45%, tr_best:  83.45%\n",
      "epoch-25  lr=['0.0010000'], tr/val_loss:  0.792884/  1.500508, val:  71.67%, val_best:  71.67%, tr:  84.47%, tr_best:  84.47%\n",
      "epoch-26  lr=['0.0010000'], tr/val_loss:  0.787363/  1.483272, val:  76.25%, val_best:  76.25%, tr:  84.78%, tr_best:  84.78%\n",
      "epoch-27  lr=['0.0010000'], tr/val_loss:  0.762675/  1.582042, val:  68.75%, val_best:  76.25%, tr:  87.33%, tr_best:  87.33%\n",
      "epoch-28  lr=['0.0010000'], tr/val_loss:  0.770569/  1.543529, val:  72.08%, val_best:  76.25%, tr:  86.93%, tr_best:  87.33%\n",
      "epoch-29  lr=['0.0010000'], tr/val_loss:  0.735042/  1.645398, val:  62.92%, val_best:  76.25%, tr:  88.66%, tr_best:  88.66%\n",
      "epoch-30  lr=['0.0010000'], tr/val_loss:  0.733556/  1.654570, val:  66.67%, val_best:  76.25%, tr:  89.99%, tr_best:  89.99%\n",
      "epoch-31  lr=['0.0010000'], tr/val_loss:  0.743592/  1.686338, val:  65.00%, val_best:  76.25%, tr:  85.70%, tr_best:  89.99%\n",
      "epoch-32  lr=['0.0010000'], tr/val_loss:  0.720413/  1.745588, val:  67.50%, val_best:  76.25%, tr:  88.97%, tr_best:  89.99%\n",
      "epoch-33  lr=['0.0010000'], tr/val_loss:  0.706719/  1.767934, val:  69.17%, val_best:  76.25%, tr:  89.38%, tr_best:  89.99%\n",
      "epoch-34  lr=['0.0010000'], tr/val_loss:  0.686982/  1.811049, val:  63.75%, val_best:  76.25%, tr:  90.50%, tr_best:  90.50%\n",
      "epoch-35  lr=['0.0010000'], tr/val_loss:  0.700169/  1.941570, val:  62.92%, val_best:  76.25%, tr:  87.54%, tr_best:  90.50%\n",
      "epoch-36  lr=['0.0010000'], tr/val_loss:  0.652634/  1.840990, val:  68.33%, val_best:  76.25%, tr:  91.52%, tr_best:  91.52%\n",
      "epoch-37  lr=['0.0010000'], tr/val_loss:  0.648441/  1.917764, val:  67.92%, val_best:  76.25%, tr:  92.54%, tr_best:  92.54%\n",
      "epoch-38  lr=['0.0010000'], tr/val_loss:  0.650740/  1.952577, val:  67.92%, val_best:  76.25%, tr:  94.28%, tr_best:  94.28%\n",
      "epoch-39  lr=['0.0010000'], tr/val_loss:  0.647953/  2.037202, val:  65.42%, val_best:  76.25%, tr:  93.67%, tr_best:  94.28%\n",
      "epoch-40  lr=['0.0010000'], tr/val_loss:  0.629066/  2.064319, val:  64.17%, val_best:  76.25%, tr:  92.85%, tr_best:  94.28%\n",
      "epoch-41  lr=['0.0010000'], tr/val_loss:  0.625535/  2.108816, val:  62.50%, val_best:  76.25%, tr:  94.48%, tr_best:  94.48%\n",
      "epoch-42  lr=['0.0010000'], tr/val_loss:  0.600034/  2.112073, val:  66.67%, val_best:  76.25%, tr:  95.51%, tr_best:  95.51%\n",
      "epoch-43  lr=['0.0010000'], tr/val_loss:  0.604541/  2.162545, val:  63.75%, val_best:  76.25%, tr:  94.28%, tr_best:  95.51%\n",
      "epoch-44  lr=['0.0010000'], tr/val_loss:  0.586185/  2.167168, val:  69.17%, val_best:  76.25%, tr:  94.79%, tr_best:  95.51%\n",
      "epoch-45  lr=['0.0010000'], tr/val_loss:  0.561106/  2.324898, val:  65.42%, val_best:  76.25%, tr:  95.91%, tr_best:  95.91%\n",
      "epoch-46  lr=['0.0010000'], tr/val_loss:  0.557870/  2.351830, val:  66.67%, val_best:  76.25%, tr:  95.91%, tr_best:  95.91%\n",
      "epoch-47  lr=['0.0010000'], tr/val_loss:  0.542949/  2.408303, val:  65.00%, val_best:  76.25%, tr:  96.32%, tr_best:  96.32%\n",
      "epoch-48  lr=['0.0010000'], tr/val_loss:  0.550740/  2.341175, val:  67.92%, val_best:  76.25%, tr:  96.42%, tr_best:  96.42%\n",
      "epoch-49  lr=['0.0010000'], tr/val_loss:  0.543040/  2.505120, val:  69.17%, val_best:  76.25%, tr:  96.42%, tr_best:  96.42%\n",
      "epoch-50  lr=['0.0010000'], tr/val_loss:  0.528379/  2.494983, val:  66.25%, val_best:  76.25%, tr:  96.32%, tr_best:  96.42%\n",
      "epoch-51  lr=['0.0010000'], tr/val_loss:  0.533928/  2.579175, val:  66.25%, val_best:  76.25%, tr:  96.22%, tr_best:  96.42%\n",
      "epoch-52  lr=['0.0010000'], tr/val_loss:  0.491444/  2.656742, val:  60.42%, val_best:  76.25%, tr:  97.75%, tr_best:  97.75%\n",
      "epoch-53  lr=['0.0010000'], tr/val_loss:  0.491252/  2.806263, val:  62.92%, val_best:  76.25%, tr:  98.06%, tr_best:  98.06%\n",
      "epoch-54  lr=['0.0010000'], tr/val_loss:  0.497113/  2.662051, val:  67.50%, val_best:  76.25%, tr:  98.16%, tr_best:  98.16%\n",
      "epoch-55  lr=['0.0010000'], tr/val_loss:  0.480313/  2.696315, val:  64.17%, val_best:  76.25%, tr:  98.67%, tr_best:  98.67%\n",
      "epoch-56  lr=['0.0010000'], tr/val_loss:  0.470090/  2.803610, val:  62.92%, val_best:  76.25%, tr:  98.77%, tr_best:  98.77%\n",
      "epoch-57  lr=['0.0010000'], tr/val_loss:  0.483104/  2.833332, val:  67.08%, val_best:  76.25%, tr:  98.16%, tr_best:  98.77%\n",
      "epoch-58  lr=['0.0010000'], tr/val_loss:  0.460751/  2.932493, val:  65.83%, val_best:  76.25%, tr:  97.96%, tr_best:  98.77%\n",
      "epoch-59  lr=['0.0010000'], tr/val_loss:  0.467667/  2.936452, val:  68.33%, val_best:  76.25%, tr:  98.67%, tr_best:  98.77%\n",
      "epoch-60  lr=['0.0010000'], tr/val_loss:  0.458022/  2.943956, val:  68.75%, val_best:  76.25%, tr:  98.57%, tr_best:  98.77%\n",
      "epoch-61  lr=['0.0010000'], tr/val_loss:  0.447693/  3.068753, val:  63.33%, val_best:  76.25%, tr:  99.28%, tr_best:  99.28%\n",
      "epoch-62  lr=['0.0010000'], tr/val_loss:  0.439744/  3.100435, val:  64.58%, val_best:  76.25%, tr:  99.18%, tr_best:  99.28%\n",
      "epoch-63  lr=['0.0010000'], tr/val_loss:  0.425109/  3.128945, val:  64.58%, val_best:  76.25%, tr:  99.39%, tr_best:  99.39%\n",
      "epoch-64  lr=['0.0010000'], tr/val_loss:  0.441187/  3.335807, val:  61.67%, val_best:  76.25%, tr:  98.67%, tr_best:  99.39%\n",
      "epoch-65  lr=['0.0010000'], tr/val_loss:  0.418349/  3.299536, val:  63.33%, val_best:  76.25%, tr:  98.67%, tr_best:  99.39%\n",
      "epoch-66  lr=['0.0010000'], tr/val_loss:  0.412318/  3.312734, val:  62.92%, val_best:  76.25%, tr:  99.39%, tr_best:  99.39%\n",
      "epoch-67  lr=['0.0010000'], tr/val_loss:  0.410447/  3.468976, val:  60.42%, val_best:  76.25%, tr:  98.98%, tr_best:  99.39%\n",
      "epoch-68  lr=['0.0010000'], tr/val_loss:  0.424890/  3.393159, val:  63.33%, val_best:  76.25%, tr:  98.98%, tr_best:  99.39%\n",
      "epoch-69  lr=['0.0010000'], tr/val_loss:  0.401907/  3.492519, val:  63.33%, val_best:  76.25%, tr:  99.28%, tr_best:  99.39%\n",
      "epoch-70  lr=['0.0010000'], tr/val_loss:  0.379791/  3.463885, val:  66.67%, val_best:  76.25%, tr:  99.59%, tr_best:  99.59%\n",
      "epoch-71  lr=['0.0010000'], tr/val_loss:  0.400581/  3.518894, val:  62.92%, val_best:  76.25%, tr:  99.28%, tr_best:  99.59%\n",
      "epoch-72  lr=['0.0010000'], tr/val_loss:  0.388120/  3.757831, val:  60.42%, val_best:  76.25%, tr:  99.39%, tr_best:  99.59%\n",
      "epoch-73  lr=['0.0010000'], tr/val_loss:  0.399099/  3.800571, val:  60.00%, val_best:  76.25%, tr:  98.88%, tr_best:  99.59%\n",
      "epoch-74  lr=['0.0010000'], tr/val_loss:  0.404614/  3.699515, val:  61.25%, val_best:  76.25%, tr:  99.18%, tr_best:  99.59%\n",
      "epoch-75  lr=['0.0010000'], tr/val_loss:  0.377000/  3.676716, val:  62.92%, val_best:  76.25%, tr:  98.47%, tr_best:  99.59%\n",
      "epoch-76  lr=['0.0010000'], tr/val_loss:  0.378255/  3.802366, val:  61.67%, val_best:  76.25%, tr:  99.49%, tr_best:  99.59%\n",
      "epoch-77  lr=['0.0010000'], tr/val_loss:  0.363171/  3.948273, val:  60.42%, val_best:  76.25%, tr:  99.18%, tr_best:  99.59%\n",
      "epoch-78  lr=['0.0010000'], tr/val_loss:  0.374406/  3.938778, val:  62.08%, val_best:  76.25%, tr:  98.88%, tr_best:  99.59%\n",
      "epoch-79  lr=['0.0010000'], tr/val_loss:  0.343662/  3.971141, val:  62.92%, val_best:  76.25%, tr:  99.69%, tr_best:  99.69%\n",
      "epoch-80  lr=['0.0010000'], tr/val_loss:  0.326053/  4.136459, val:  60.42%, val_best:  76.25%, tr:  99.69%, tr_best:  99.69%\n",
      "epoch-81  lr=['0.0010000'], tr/val_loss:  0.327216/  4.070640, val:  62.08%, val_best:  76.25%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-82  lr=['0.0010000'], tr/val_loss:  0.318192/  4.127788, val:  62.50%, val_best:  76.25%, tr:  99.80%, tr_best: 100.00%\n",
      "epoch-83  lr=['0.0010000'], tr/val_loss:  0.351343/  4.356683, val:  59.58%, val_best:  76.25%, tr:  99.80%, tr_best: 100.00%\n",
      "epoch-84  lr=['0.0010000'], tr/val_loss:  0.316829/  4.245218, val:  61.25%, val_best:  76.25%, tr:  99.69%, tr_best: 100.00%\n",
      "epoch-85  lr=['0.0010000'], tr/val_loss:  0.303698/  4.348795, val:  61.67%, val_best:  76.25%, tr:  99.80%, tr_best: 100.00%\n",
      "epoch-86  lr=['0.0010000'], tr/val_loss:  0.316852/  4.251863, val:  64.17%, val_best:  76.25%, tr:  99.39%, tr_best: 100.00%\n",
      "epoch-87  lr=['0.0010000'], tr/val_loss:  0.301752/  4.310599, val:  60.83%, val_best:  76.25%, tr:  99.90%, tr_best: 100.00%\n",
      "epoch-88  lr=['0.0010000'], tr/val_loss:  0.293500/  4.343287, val:  65.42%, val_best:  76.25%, tr:  99.69%, tr_best: 100.00%\n",
      "epoch-89  lr=['0.0010000'], tr/val_loss:  0.287179/  4.476089, val:  63.33%, val_best:  76.25%, tr:  99.69%, tr_best: 100.00%\n",
      "epoch-90  lr=['0.0010000'], tr/val_loss:  0.291231/  4.500891, val:  65.42%, val_best:  76.25%, tr:  99.90%, tr_best: 100.00%\n",
      "epoch-91  lr=['0.0010000'], tr/val_loss:  0.282243/  4.623225, val:  61.67%, val_best:  76.25%, tr:  99.69%, tr_best: 100.00%\n",
      "epoch-92  lr=['0.0010000'], tr/val_loss:  0.256803/  4.604253, val:  61.67%, val_best:  76.25%, tr:  99.90%, tr_best: 100.00%\n",
      "epoch-93  lr=['0.0010000'], tr/val_loss:  0.301487/  4.628686, val:  60.83%, val_best:  76.25%, tr:  99.59%, tr_best: 100.00%\n",
      "epoch-94  lr=['0.0010000'], tr/val_loss:  0.277266/  4.741443, val:  62.50%, val_best:  76.25%, tr:  99.80%, tr_best: 100.00%\n",
      "epoch-95  lr=['0.0010000'], tr/val_loss:  0.282757/  4.913724, val:  60.83%, val_best:  76.25%, tr:  99.90%, tr_best: 100.00%\n",
      "epoch-96  lr=['0.0010000'], tr/val_loss:  0.282854/  4.720045, val:  64.17%, val_best:  76.25%, tr:  99.69%, tr_best: 100.00%\n",
      "epoch-97  lr=['0.0010000'], tr/val_loss:  0.253173/  4.936260, val:  60.83%, val_best:  76.25%, tr:  99.90%, tr_best: 100.00%\n",
      "epoch-98  lr=['0.0010000'], tr/val_loss:  0.259289/  5.074410, val:  57.92%, val_best:  76.25%, tr:  99.80%, tr_best: 100.00%\n",
      "epoch-99  lr=['0.0010000'], tr/val_loss:  0.286664/  5.011838, val:  63.75%, val_best:  76.25%, tr:  99.59%, tr_best: 100.00%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c078e41e1fad46468c9a019cb9b8fdaa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.006 MB of 0.006 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>iter_acc</td><td>▂▃▂▁▃▅▆▂▃▆▇█▆▆▆█▇███▆████████▇██████████</td></tr><tr><td>summary_val_acc</td><td>▁▄▅▆▆▆▆▇▆▇▇█▆▇▆▇▆▇▇▆▇▆▇▇▇▆▆▆▇▆▆▆▆▆▆▆▆▆▆▆</td></tr><tr><td>tr_acc</td><td>▁▄▅▅▅▆▆▆▆▆▇▇▇▇▇▇▇███████████████████████</td></tr><tr><td>tr_epoch_loss</td><td>█▆▅▄▄▄▄▃▃▃▃▃▃▃▃▂▂▂▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_acc_best</td><td>▁▄▅▆▆▆▆▇▇▇▇█████████████████████████████</td></tr><tr><td>val_acc_now</td><td>▁▄▅▆▆▆▆▇▆▇▇█▆▇▆▇▆▇▇▆▇▆▇▇▇▆▆▆▇▆▆▆▆▆▆▆▆▆▆▆</td></tr><tr><td>val_loss</td><td>▃▂▁▁▁▁▁▁▁▁▁▁▂▂▂▂▂▂▃▃▃▄▄▄▄▄▅▅▅▆▆▆▆▆▇▇▇▇██</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>99</td></tr><tr><td>iter_acc</td><td>1.0</td></tr><tr><td>tr_acc</td><td>0.99591</td></tr><tr><td>tr_epoch_loss</td><td>0.28666</td></tr><tr><td>val_acc_best</td><td>0.7625</td></tr><tr><td>val_acc_now</td><td>0.6375</td></tr><tr><td>val_loss</td><td>5.01184</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">glamorous-sweep-260</strong> at: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/cu8ngqid' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/cu8ngqid</a><br/> View project at: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>/data2/bh_wandb/wandb/run-20250430_090314-cu8ngqid/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require(\"core\")`! See https://wandb.me/wandb-core for more information."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: qtxv6byy with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBATCH: 16\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBN_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBPTT_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tDFA_on: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tIMAGE_SIZE: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tOTTT_input_trace_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tTIME: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tUDA_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \talpha_uda: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbias: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcfg: ['M', 'M', 200, 200]\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tchaching_on: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tconvTrue_fcFalse: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdata_path: /data2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tddp_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdenoise_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdvs_clipping: 5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdvs_duration: 100000\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepoch_num: 100\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \texclude_class: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \textra_train_dataset: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlast_lif: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.001\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_sg_width: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_decay: 0.5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_init: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_reset: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_threshold: 0.5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmerge_polarities: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmy_seed: 42\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnet_print: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_workers: 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer_what: SGD\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tpin_memory: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tpre_trained: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tpre_trained_path: net_save/save_now_net_weights_{unique_name}.pth\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \trate_coding: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tscheduler_name: no\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsingle_step: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsurrogate: hard_sigmoid\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_conv_kernel_size: 3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_conv_padding: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_conv_stride: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_trace_const1: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_trace_const2: 0.5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \ttdBN_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \ttrace_on: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \twhich_data: DVS_GESTURE_TONIC\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "48702863bc8741c88cd9b3cf63de1c2e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.011112988812641965, max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.17.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/data2/bh_wandb/wandb/run-20250430_090904-qtxv6byy</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/qtxv6byy' target=\"_blank\">noble-sweep-262</a></strong> to <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/6pj3lh8j' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/6pj3lh8j</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/6pj3lh8j' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/6pj3lh8j</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/qtxv6byy' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/qtxv6byy</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'single_step' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'my_seed' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'TIME' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BATCH' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'IMAGE_SIZE' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'which_data' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'data_path' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'rate_coding' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_init' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_decay' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_threshold' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_reset' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_sg_width' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_conv_kernel_size' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_conv_stride' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_conv_padding' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_trace_const1' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_trace_const2' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'pre_trained' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'convTrue_fcFalse' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'cfg' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'net_print' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'pre_trained_path' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'learning_rate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'epoch_num' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'tdBN_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BN_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'surrogate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BPTT_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'optimizer_what' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'scheduler_name' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'ddp_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'dvs_clipping' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'dvs_duration' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'DFA_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'trace_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'OTTT_input_trace_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'exclude_class' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'merge_polarities' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'denoise_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'extra_train_dataset' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'num_workers' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'chaching_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'pin_memory' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'UDA_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'alpha_uda' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'bias' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'last_lif' was locked by 'sweep' (ignored update).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "param {'devices': '0', 'single_step': True, 'unique_name': 'main', 'my_seed': 42, 'TIME': 10, 'BATCH': 16, 'IMAGE_SIZE': 128, 'which_data': 'DVS_GESTURE_TONIC', 'data_path': '/data2', 'rate_coding': False, 'lif_layer_v_init': 0, 'lif_layer_v_decay': 0.5, 'lif_layer_v_threshold': 0.5, 'lif_layer_v_reset': 0, 'lif_layer_sg_width': 1, 'synapse_conv_kernel_size': 3, 'synapse_conv_stride': 1, 'synapse_conv_padding': 1, 'synapse_trace_const1': 1, 'synapse_trace_const2': 0.5, 'pre_trained': False, 'convTrue_fcFalse': False, 'cfg': ['M', 'M', 200, 200], 'net_print': True, 'pre_trained_path': 'net_save/save_now_net_weights_{unique_name}.pth', 'learning_rate': 0.001, 'epoch_num': 100, 'tdBN_on': False, 'BN_on': False, 'surrogate': 'hard_sigmoid', 'BPTT_on': False, 'optimizer_what': 'SGD', 'scheduler_name': 'no', 'ddp_on': False, 'dvs_clipping': 5, 'dvs_duration': 100000, 'DFA_on': True, 'trace_on': True, 'OTTT_input_trace_on': False, 'exclude_class': True, 'merge_polarities': False, 'denoise_on': False, 'extra_train_dataset': 0, 'num_workers': 2, 'chaching_on': True, 'pin_memory': True, 'UDA_on': False, 'alpha_uda': 1, 'bias': True, 'last_lif': False, 'current epoch': 0} \n",
      "\n",
      "dataset_hash = ffa516e60c3efd5e0208f72b4c36cb84\n",
      "cache path exists\n",
      "\n",
      "device ==> cuda\n",
      "\n",
      "DataParallel(\n",
      "  (module): REBORN_MY_SNN_FC(\n",
      "    (layers): REBORN_MY_Sequential(\n",
      "      (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (2): DimChanger_for_FC()\n",
      "      (3): SYNAPSE_FC(in_features=2048, out_features=200, TIME=10, bias=True, sstep=True)\n",
      "      (4): LIF_layer(v_init=0, v_decay=0.5, v_threshold=0.5, v_reset=0, sg_width=1, surrogate=hard_sigmoid, BPTT_on=False, trace_const1=1, trace_const2=0.5, TIME=10, sstep=True, trace_on=True)\n",
      "      (5): Feedback_Receiver()\n",
      "      (6): SYNAPSE_FC(in_features=200, out_features=200, TIME=10, bias=True, sstep=True)\n",
      "      (7): LIF_layer(v_init=0, v_decay=0.5, v_threshold=0.5, v_reset=0, sg_width=1, surrogate=hard_sigmoid, BPTT_on=False, trace_const1=1, trace_const2=0.5, TIME=10, sstep=True, trace_on=True)\n",
      "      (8): Feedback_Receiver()\n",
      "      (9): SYNAPSE_FC(in_features=200, out_features=10, TIME=10, bias=True, sstep=True)\n",
      "      (DFA_top): Top_Gradient()\n",
      "    )\n",
      "  )\n",
      ")\n",
      "\n",
      "========================================================\n",
      "Trainable parameters: 452,010\n",
      "========================================================\n",
      "\n",
      "epoch-0   lr=['0.0010000'], tr/val_loss:  2.302801/  2.284564, val:  14.17%, val_best:  14.17%, tr:   9.40%, tr_best:   9.40%\n",
      "[module.layers.5] weight_fb parameter count: 2,000\n",
      "[module.layers.8] weight_fb parameter count: 2,000\n",
      "epoch-1   lr=['0.0010000'], tr/val_loss:  2.066060/  1.829384, val:  46.25%, val_best:  46.25%, tr:  26.56%, tr_best:  26.56%\n",
      "epoch-2   lr=['0.0010000'], tr/val_loss:  1.563532/  1.574583, val:  48.33%, val_best:  48.33%, tr:  50.36%, tr_best:  50.36%\n",
      "epoch-3   lr=['0.0010000'], tr/val_loss:  1.377160/  1.527985, val:  52.92%, val_best:  52.92%, tr:  58.84%, tr_best:  58.84%\n",
      "epoch-4   lr=['0.0010000'], tr/val_loss:  1.309563/  1.478362, val:  55.42%, val_best:  55.42%, tr:  60.37%, tr_best:  60.37%\n",
      "epoch-5   lr=['0.0010000'], tr/val_loss:  1.251835/  1.424491, val:  59.58%, val_best:  59.58%, tr:  60.27%, tr_best:  60.37%\n",
      "epoch-6   lr=['0.0010000'], tr/val_loss:  1.192548/  1.392709, val:  62.50%, val_best:  62.50%, tr:  64.56%, tr_best:  64.56%\n",
      "epoch-7   lr=['0.0010000'], tr/val_loss:  1.167372/  1.388060, val:  61.67%, val_best:  62.50%, tr:  63.94%, tr_best:  64.56%\n",
      "epoch-8   lr=['0.0010000'], tr/val_loss:  1.124402/  1.385908, val:  64.58%, val_best:  64.58%, tr:  65.27%, tr_best:  65.27%\n",
      "epoch-9   lr=['0.0010000'], tr/val_loss:  1.109459/  1.382073, val:  64.17%, val_best:  64.58%, tr:  69.05%, tr_best:  69.05%\n",
      "epoch-10  lr=['0.0010000'], tr/val_loss:  1.092512/  1.413750, val:  60.00%, val_best:  64.58%, tr:  67.21%, tr_best:  69.05%\n",
      "epoch-11  lr=['0.0010000'], tr/val_loss:  1.056610/  1.376295, val:  63.33%, val_best:  64.58%, tr:  70.07%, tr_best:  70.07%\n",
      "epoch-12  lr=['0.0010000'], tr/val_loss:  1.053051/  1.376730, val:  61.25%, val_best:  64.58%, tr:  71.50%, tr_best:  71.50%\n",
      "epoch-13  lr=['0.0010000'], tr/val_loss:  1.050623/  1.404810, val:  63.75%, val_best:  64.58%, tr:  72.01%, tr_best:  72.01%\n",
      "epoch-14  lr=['0.0010000'], tr/val_loss:  1.000400/  1.523773, val:  59.17%, val_best:  64.58%, tr:  72.93%, tr_best:  72.93%\n",
      "epoch-15  lr=['0.0010000'], tr/val_loss:  0.990078/  1.416633, val:  64.17%, val_best:  64.58%, tr:  76.20%, tr_best:  76.20%\n",
      "epoch-16  lr=['0.0010000'], tr/val_loss:  0.999519/  1.415075, val:  60.42%, val_best:  64.58%, tr:  73.03%, tr_best:  76.20%\n",
      "epoch-17  lr=['0.0010000'], tr/val_loss:  0.958782/  1.409094, val:  65.42%, val_best:  65.42%, tr:  77.22%, tr_best:  77.22%\n",
      "epoch-18  lr=['0.0010000'], tr/val_loss:  0.942028/  1.541635, val:  60.83%, val_best:  65.42%, tr:  75.59%, tr_best:  77.22%\n",
      "epoch-19  lr=['0.0010000'], tr/val_loss:  0.940917/  1.499634, val:  63.33%, val_best:  65.42%, tr:  76.00%, tr_best:  77.22%\n",
      "epoch-20  lr=['0.0010000'], tr/val_loss:  0.922179/  1.552639, val:  60.83%, val_best:  65.42%, tr:  79.98%, tr_best:  79.98%\n",
      "epoch-21  lr=['0.0010000'], tr/val_loss:  0.909742/  1.518625, val:  66.25%, val_best:  66.25%, tr:  81.10%, tr_best:  81.10%\n",
      "epoch-22  lr=['0.0010000'], tr/val_loss:  0.918319/  1.538721, val:  62.92%, val_best:  66.25%, tr:  78.96%, tr_best:  81.10%\n",
      "epoch-23  lr=['0.0010000'], tr/val_loss:  0.881237/  1.535864, val:  60.00%, val_best:  66.25%, tr:  82.94%, tr_best:  82.94%\n",
      "epoch-24  lr=['0.0010000'], tr/val_loss:  0.864145/  1.596977, val:  60.42%, val_best:  66.25%, tr:  84.27%, tr_best:  84.27%\n",
      "epoch-25  lr=['0.0010000'], tr/val_loss:  0.858807/  1.576494, val:  66.67%, val_best:  66.67%, tr:  85.50%, tr_best:  85.50%\n",
      "epoch-26  lr=['0.0010000'], tr/val_loss:  0.862254/  1.593858, val:  64.58%, val_best:  66.67%, tr:  85.60%, tr_best:  85.60%\n",
      "epoch-27  lr=['0.0010000'], tr/val_loss:  0.842549/  1.679253, val:  63.33%, val_best:  66.67%, tr:  86.72%, tr_best:  86.72%\n",
      "epoch-28  lr=['0.0010000'], tr/val_loss:  0.842744/  1.650445, val:  66.67%, val_best:  66.67%, tr:  87.64%, tr_best:  87.64%\n",
      "epoch-29  lr=['0.0010000'], tr/val_loss:  0.812293/  1.738028, val:  60.00%, val_best:  66.67%, tr:  88.66%, tr_best:  88.66%\n",
      "epoch-30  lr=['0.0010000'], tr/val_loss:  0.809101/  1.735972, val:  65.00%, val_best:  66.67%, tr:  89.79%, tr_best:  89.79%\n",
      "epoch-31  lr=['0.0010000'], tr/val_loss:  0.842492/  1.761177, val:  65.83%, val_best:  66.67%, tr:  86.21%, tr_best:  89.79%\n",
      "epoch-32  lr=['0.0010000'], tr/val_loss:  0.809665/  1.775782, val:  66.25%, val_best:  66.67%, tr:  89.17%, tr_best:  89.79%\n",
      "epoch-33  lr=['0.0010000'], tr/val_loss:  0.802738/  1.810049, val:  65.42%, val_best:  66.67%, tr:  89.99%, tr_best:  89.99%\n",
      "epoch-34  lr=['0.0010000'], tr/val_loss:  0.789427/  1.870005, val:  64.17%, val_best:  66.67%, tr:  91.42%, tr_best:  91.42%\n",
      "epoch-35  lr=['0.0010000'], tr/val_loss:  0.797356/  1.904050, val:  63.33%, val_best:  66.67%, tr:  89.27%, tr_best:  91.42%\n",
      "epoch-36  lr=['0.0010000'], tr/val_loss:  0.773251/  1.882745, val:  63.33%, val_best:  66.67%, tr:  92.24%, tr_best:  92.24%\n",
      "epoch-37  lr=['0.0010000'], tr/val_loss:  0.770342/  1.891537, val:  65.00%, val_best:  66.67%, tr:  92.34%, tr_best:  92.34%\n",
      "epoch-38  lr=['0.0010000'], tr/val_loss:  0.762552/  1.922123, val:  67.50%, val_best:  67.50%, tr:  92.95%, tr_best:  92.95%\n",
      "epoch-39  lr=['0.0010000'], tr/val_loss:  0.756860/  1.980651, val:  65.83%, val_best:  67.50%, tr:  92.85%, tr_best:  92.95%\n",
      "epoch-40  lr=['0.0010000'], tr/val_loss:  0.737025/  2.029433, val:  66.67%, val_best:  67.50%, tr:  92.75%, tr_best:  92.95%\n",
      "epoch-41  lr=['0.0010000'], tr/val_loss:  0.749700/  2.055583, val:  63.33%, val_best:  67.50%, tr:  94.38%, tr_best:  94.38%\n",
      "epoch-42  lr=['0.0010000'], tr/val_loss:  0.720124/  2.069899, val:  65.00%, val_best:  67.50%, tr:  94.89%, tr_best:  94.89%\n",
      "epoch-43  lr=['0.0010000'], tr/val_loss:  0.719912/  2.142943, val:  65.83%, val_best:  67.50%, tr:  94.79%, tr_best:  94.89%\n",
      "epoch-44  lr=['0.0010000'], tr/val_loss:  0.707053/  2.140191, val:  67.50%, val_best:  67.50%, tr:  94.59%, tr_best:  94.89%\n",
      "epoch-45  lr=['0.0010000'], tr/val_loss:  0.707208/  2.174128, val:  65.83%, val_best:  67.50%, tr:  95.61%, tr_best:  95.61%\n",
      "epoch-46  lr=['0.0010000'], tr/val_loss:  0.692739/  2.177892, val:  64.58%, val_best:  67.50%, tr:  96.12%, tr_best:  96.12%\n",
      "epoch-47  lr=['0.0010000'], tr/val_loss:  0.698938/  2.255687, val:  67.50%, val_best:  67.50%, tr:  96.83%, tr_best:  96.83%\n",
      "epoch-48  lr=['0.0010000'], tr/val_loss:  0.705974/  2.225448, val:  67.92%, val_best:  67.92%, tr:  95.71%, tr_best:  96.83%\n",
      "epoch-49  lr=['0.0010000'], tr/val_loss:  0.700951/  2.260986, val:  68.75%, val_best:  68.75%, tr:  96.22%, tr_best:  96.83%\n",
      "epoch-50  lr=['0.0010000'], tr/val_loss:  0.695283/  2.316585, val:  68.75%, val_best:  68.75%, tr:  97.04%, tr_best:  97.04%\n",
      "epoch-51  lr=['0.0010000'], tr/val_loss:  0.694572/  2.350719, val:  70.00%, val_best:  70.00%, tr:  96.42%, tr_best:  97.04%\n",
      "epoch-52  lr=['0.0010000'], tr/val_loss:  0.672128/  2.402938, val:  66.25%, val_best:  70.00%, tr:  97.14%, tr_best:  97.14%\n",
      "epoch-53  lr=['0.0010000'], tr/val_loss:  0.686557/  2.423370, val:  68.75%, val_best:  70.00%, tr:  96.83%, tr_best:  97.14%\n",
      "epoch-54  lr=['0.0010000'], tr/val_loss:  0.669325/  2.476629, val:  67.92%, val_best:  70.00%, tr:  97.14%, tr_best:  97.14%\n",
      "epoch-55  lr=['0.0010000'], tr/val_loss:  0.673865/  2.480316, val:  69.17%, val_best:  70.00%, tr:  97.24%, tr_best:  97.24%\n",
      "epoch-56  lr=['0.0010000'], tr/val_loss:  0.672411/  2.531370, val:  68.33%, val_best:  70.00%, tr:  97.24%, tr_best:  97.24%\n",
      "epoch-57  lr=['0.0010000'], tr/val_loss:  0.670662/  2.498407, val:  70.42%, val_best:  70.42%, tr:  97.55%, tr_best:  97.55%\n",
      "epoch-58  lr=['0.0010000'], tr/val_loss:  0.654622/  2.650820, val:  68.33%, val_best:  70.42%, tr:  97.65%, tr_best:  97.65%\n",
      "epoch-59  lr=['0.0010000'], tr/val_loss:  0.651994/  2.649876, val:  69.58%, val_best:  70.42%, tr:  97.75%, tr_best:  97.75%\n",
      "epoch-60  lr=['0.0010000'], tr/val_loss:  0.656776/  2.681524, val:  70.00%, val_best:  70.42%, tr:  97.96%, tr_best:  97.96%\n",
      "epoch-61  lr=['0.0010000'], tr/val_loss:  0.652432/  2.728782, val:  68.75%, val_best:  70.42%, tr:  97.96%, tr_best:  97.96%\n",
      "epoch-62  lr=['0.0010000'], tr/val_loss:  0.665156/  2.779841, val:  66.67%, val_best:  70.42%, tr:  97.85%, tr_best:  97.96%\n",
      "epoch-63  lr=['0.0010000'], tr/val_loss:  0.636155/  2.794334, val:  68.75%, val_best:  70.42%, tr:  97.85%, tr_best:  97.96%\n",
      "epoch-64  lr=['0.0010000'], tr/val_loss:  0.651492/  2.870145, val:  65.42%, val_best:  70.42%, tr:  97.75%, tr_best:  97.96%\n",
      "epoch-65  lr=['0.0010000'], tr/val_loss:  0.642489/  2.885282, val:  69.17%, val_best:  70.42%, tr:  97.55%, tr_best:  97.96%\n",
      "epoch-66  lr=['0.0010000'], tr/val_loss:  0.623443/  2.926335, val:  70.00%, val_best:  70.42%, tr:  98.16%, tr_best:  98.16%\n",
      "epoch-67  lr=['0.0010000'], tr/val_loss:  0.658681/  2.962411, val:  67.08%, val_best:  70.42%, tr:  98.57%, tr_best:  98.57%\n",
      "epoch-68  lr=['0.0010000'], tr/val_loss:  0.636749/  3.013072, val:  65.00%, val_best:  70.42%, tr:  98.06%, tr_best:  98.57%\n",
      "epoch-69  lr=['0.0010000'], tr/val_loss:  0.640370/  3.020235, val:  67.92%, val_best:  70.42%, tr:  98.37%, tr_best:  98.57%\n",
      "epoch-70  lr=['0.0010000'], tr/val_loss:  0.619816/  3.046269, val:  68.75%, val_best:  70.42%, tr:  98.06%, tr_best:  98.57%\n",
      "epoch-71  lr=['0.0010000'], tr/val_loss:  0.618293/  3.077544, val:  68.33%, val_best:  70.42%, tr:  98.57%, tr_best:  98.57%\n",
      "epoch-72  lr=['0.0010000'], tr/val_loss:  0.628061/  3.144683, val:  65.42%, val_best:  70.42%, tr:  98.67%, tr_best:  98.67%\n",
      "epoch-73  lr=['0.0010000'], tr/val_loss:  0.639076/  3.113719, val:  67.50%, val_best:  70.42%, tr:  98.16%, tr_best:  98.67%\n",
      "epoch-74  lr=['0.0010000'], tr/val_loss:  0.609438/  3.138774, val:  68.33%, val_best:  70.42%, tr:  98.37%, tr_best:  98.67%\n",
      "epoch-75  lr=['0.0010000'], tr/val_loss:  0.618427/  3.236826, val:  65.83%, val_best:  70.42%, tr:  98.57%, tr_best:  98.67%\n",
      "epoch-76  lr=['0.0010000'], tr/val_loss:  0.630455/  3.311949, val:  64.17%, val_best:  70.42%, tr:  98.37%, tr_best:  98.67%\n",
      "epoch-77  lr=['0.0010000'], tr/val_loss:  0.600376/  3.355717, val:  67.08%, val_best:  70.42%, tr:  98.67%, tr_best:  98.67%\n",
      "epoch-78  lr=['0.0010000'], tr/val_loss:  0.619047/  3.339892, val:  69.58%, val_best:  70.42%, tr:  98.98%, tr_best:  98.98%\n",
      "epoch-79  lr=['0.0010000'], tr/val_loss:  0.586459/  3.352066, val:  67.50%, val_best:  70.42%, tr:  99.18%, tr_best:  99.18%\n",
      "epoch-80  lr=['0.0010000'], tr/val_loss:  0.596651/  3.430934, val:  67.08%, val_best:  70.42%, tr:  98.88%, tr_best:  99.18%\n",
      "epoch-81  lr=['0.0010000'], tr/val_loss:  0.594515/  3.444839, val:  69.17%, val_best:  70.42%, tr:  98.67%, tr_best:  99.18%\n",
      "epoch-82  lr=['0.0010000'], tr/val_loss:  0.608785/  3.573705, val:  65.00%, val_best:  70.42%, tr:  98.88%, tr_best:  99.18%\n",
      "epoch-83  lr=['0.0010000'], tr/val_loss:  0.603090/  3.596771, val:  68.33%, val_best:  70.42%, tr:  99.08%, tr_best:  99.18%\n",
      "epoch-84  lr=['0.0010000'], tr/val_loss:  0.591193/  3.624691, val:  70.00%, val_best:  70.42%, tr:  99.39%, tr_best:  99.39%\n",
      "epoch-85  lr=['0.0010000'], tr/val_loss:  0.584158/  3.679123, val:  65.00%, val_best:  70.42%, tr:  99.18%, tr_best:  99.39%\n",
      "epoch-86  lr=['0.0010000'], tr/val_loss:  0.579165/  3.717563, val:  68.75%, val_best:  70.42%, tr:  98.67%, tr_best:  99.39%\n",
      "epoch-87  lr=['0.0010000'], tr/val_loss:  0.598659/  3.823455, val:  67.08%, val_best:  70.42%, tr:  98.98%, tr_best:  99.39%\n",
      "epoch-88  lr=['0.0010000'], tr/val_loss:  0.582427/  3.835217, val:  65.00%, val_best:  70.42%, tr:  99.18%, tr_best:  99.39%\n",
      "epoch-89  lr=['0.0010000'], tr/val_loss:  0.567094/  3.894794, val:  67.08%, val_best:  70.42%, tr:  99.28%, tr_best:  99.39%\n",
      "epoch-90  lr=['0.0010000'], tr/val_loss:  0.589734/  3.872932, val:  68.75%, val_best:  70.42%, tr:  99.08%, tr_best:  99.39%\n",
      "epoch-91  lr=['0.0010000'], tr/val_loss:  0.565884/  3.936031, val:  67.08%, val_best:  70.42%, tr:  98.98%, tr_best:  99.39%\n",
      "epoch-92  lr=['0.0010000'], tr/val_loss:  0.573307/  3.996939, val:  65.83%, val_best:  70.42%, tr:  99.39%, tr_best:  99.39%\n",
      "epoch-93  lr=['0.0010000'], tr/val_loss:  0.568557/  4.072213, val:  65.83%, val_best:  70.42%, tr:  99.49%, tr_best:  99.49%\n",
      "epoch-94  lr=['0.0010000'], tr/val_loss:  0.566732/  4.116649, val:  65.42%, val_best:  70.42%, tr:  99.39%, tr_best:  99.49%\n",
      "epoch-95  lr=['0.0010000'], tr/val_loss:  0.561214/  4.230402, val:  66.67%, val_best:  70.42%, tr:  99.49%, tr_best:  99.49%\n",
      "epoch-96  lr=['0.0010000'], tr/val_loss:  0.574944/  4.201910, val:  67.08%, val_best:  70.42%, tr:  99.18%, tr_best:  99.49%\n",
      "epoch-97  lr=['0.0010000'], tr/val_loss:  0.590673/  4.226595, val:  66.67%, val_best:  70.42%, tr:  99.28%, tr_best:  99.49%\n",
      "epoch-98  lr=['0.0010000'], tr/val_loss:  0.565770/  4.255224, val:  68.33%, val_best:  70.42%, tr:  99.49%, tr_best:  99.49%\n",
      "epoch-99  lr=['0.0010000'], tr/val_loss:  0.569314/  4.324138, val:  67.50%, val_best:  70.42%, tr:  99.18%, tr_best:  99.49%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2b5bddd25d9048c49ec3b6f86f2259a1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.006 MB of 0.006 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>iter_acc</td><td>▁▆▄▅▄▅▆▄▅▇██▇▇▇████▇█▇▇███▇██▇█▇▇██▇████</td></tr><tr><td>summary_val_acc</td><td>▁▅▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇███▇███████▇▇██▇███▇██</td></tr><tr><td>tr_acc</td><td>▁▄▅▅▆▆▆▆▆▇▇▇▇▇▇▇▇███████████████████████</td></tr><tr><td>tr_epoch_loss</td><td>█▅▄▃▃▃▃▃▃▂▂▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_acc_best</td><td>▁▅▆▇▇▇▇▇▇▇▇█████████████████████████████</td></tr><tr><td>val_acc_now</td><td>▁▅▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇███▇███████▇▇██▇███▇██</td></tr><tr><td>val_loss</td><td>▃▁▁▁▁▁▁▁▁▁▂▂▂▂▂▂▂▃▃▃▃▄▄▄▄▄▅▅▅▅▆▆▆▆▇▇▇▇██</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>99</td></tr><tr><td>iter_acc</td><td>1.0</td></tr><tr><td>tr_acc</td><td>0.99183</td></tr><tr><td>tr_epoch_loss</td><td>0.56931</td></tr><tr><td>val_acc_best</td><td>0.70417</td></tr><tr><td>val_acc_now</td><td>0.675</td></tr><tr><td>val_loss</td><td>4.32414</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">noble-sweep-262</strong> at: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/qtxv6byy' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/qtxv6byy</a><br/> View project at: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>/data2/bh_wandb/wandb/run-20250430_090904-qtxv6byy/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require(\"core\")`! See https://wandb.me/wandb-core for more information."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: vr8a4sr5 with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBATCH: 16\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBN_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBPTT_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tDFA_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tIMAGE_SIZE: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tOTTT_input_trace_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tTIME: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tUDA_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \talpha_uda: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbias: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcfg: ['M', 'M', 200, 200]\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tchaching_on: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tconvTrue_fcFalse: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdata_path: /data2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tddp_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdenoise_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdvs_clipping: 5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdvs_duration: 100000\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepoch_num: 100\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \texclude_class: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \textra_train_dataset: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlast_lif: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.001\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_sg_width: 4\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_decay: 0.5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_init: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_reset: 10000\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_threshold: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmerge_polarities: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmy_seed: 42\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnet_print: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_workers: 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer_what: SGD\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tpin_memory: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tpre_trained: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tpre_trained_path: net_save/save_now_net_weights_{unique_name}.pth\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \trate_coding: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tscheduler_name: no\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsingle_step: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsurrogate: hard_sigmoid\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_conv_kernel_size: 3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_conv_padding: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_conv_stride: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_trace_const1: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_trace_const2: 0.5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \ttdBN_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \ttrace_on: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \twhich_data: DVS_GESTURE_TONIC\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.19.10 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.17.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/data2/bh_wandb/wandb/run-20250430_091545-vr8a4sr5</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/vr8a4sr5' target=\"_blank\">vocal-sweep-264</a></strong> to <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/6pj3lh8j' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/6pj3lh8j</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/6pj3lh8j' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/6pj3lh8j</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/vr8a4sr5' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/vr8a4sr5</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'single_step' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'my_seed' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'TIME' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BATCH' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'IMAGE_SIZE' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'which_data' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'data_path' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'rate_coding' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_init' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_decay' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_threshold' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_reset' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_sg_width' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_conv_kernel_size' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_conv_stride' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_conv_padding' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_trace_const1' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_trace_const2' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'pre_trained' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'convTrue_fcFalse' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'cfg' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'net_print' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'pre_trained_path' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'learning_rate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'epoch_num' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'tdBN_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BN_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'surrogate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BPTT_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'optimizer_what' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'scheduler_name' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'ddp_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'dvs_clipping' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'dvs_duration' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'DFA_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'trace_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'OTTT_input_trace_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'exclude_class' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'merge_polarities' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'denoise_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'extra_train_dataset' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'num_workers' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'chaching_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'pin_memory' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'UDA_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'alpha_uda' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'bias' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'last_lif' was locked by 'sweep' (ignored update).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "param {'devices': '0', 'single_step': True, 'unique_name': 'main', 'my_seed': 42, 'TIME': 10, 'BATCH': 16, 'IMAGE_SIZE': 128, 'which_data': 'DVS_GESTURE_TONIC', 'data_path': '/data2', 'rate_coding': False, 'lif_layer_v_init': 0, 'lif_layer_v_decay': 0.5, 'lif_layer_v_threshold': 1, 'lif_layer_v_reset': 10000, 'lif_layer_sg_width': 4, 'synapse_conv_kernel_size': 3, 'synapse_conv_stride': 1, 'synapse_conv_padding': 1, 'synapse_trace_const1': 1, 'synapse_trace_const2': 0.5, 'pre_trained': False, 'convTrue_fcFalse': False, 'cfg': ['M', 'M', 200, 200], 'net_print': True, 'pre_trained_path': 'net_save/save_now_net_weights_{unique_name}.pth', 'learning_rate': 0.001, 'epoch_num': 100, 'tdBN_on': False, 'BN_on': False, 'surrogate': 'hard_sigmoid', 'BPTT_on': False, 'optimizer_what': 'SGD', 'scheduler_name': 'no', 'ddp_on': False, 'dvs_clipping': 5, 'dvs_duration': 100000, 'DFA_on': False, 'trace_on': True, 'OTTT_input_trace_on': False, 'exclude_class': True, 'merge_polarities': False, 'denoise_on': False, 'extra_train_dataset': 0, 'num_workers': 2, 'chaching_on': True, 'pin_memory': True, 'UDA_on': False, 'alpha_uda': 1, 'bias': True, 'last_lif': False, 'current epoch': 0} \n",
      "\n",
      "dataset_hash = ffa516e60c3efd5e0208f72b4c36cb84\n",
      "cache path exists\n",
      "\n",
      "device ==> cuda\n",
      "\n",
      "DataParallel(\n",
      "  (module): REBORN_MY_SNN_FC(\n",
      "    (layers): REBORN_MY_Sequential(\n",
      "      (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (2): DimChanger_for_FC()\n",
      "      (3): SYNAPSE_FC(in_features=2048, out_features=200, TIME=10, bias=True, sstep=True)\n",
      "      (4): LIF_layer(v_init=0, v_decay=0.5, v_threshold=1, v_reset=10000, sg_width=4, surrogate=hard_sigmoid, BPTT_on=False, trace_const1=1, trace_const2=0.5, TIME=10, sstep=True, trace_on=True)\n",
      "      (5): SYNAPSE_FC(in_features=200, out_features=200, TIME=10, bias=True, sstep=True)\n",
      "      (6): LIF_layer(v_init=0, v_decay=0.5, v_threshold=1, v_reset=10000, sg_width=4, surrogate=hard_sigmoid, BPTT_on=False, trace_const1=1, trace_const2=0.5, TIME=10, sstep=True, trace_on=True)\n",
      "      (7): SYNAPSE_FC(in_features=200, out_features=10, TIME=10, bias=True, sstep=True)\n",
      "    )\n",
      "  )\n",
      ")\n",
      "\n",
      "========================================================\n",
      "Trainable parameters: 452,010\n",
      "========================================================\n",
      "\n",
      "epoch-0   lr=['0.0010000'], tr/val_loss:  2.305365/  2.302841, val:  10.00%, val_best:  10.00%, tr:   8.17%, tr_best:   8.17%\n",
      "epoch-1   lr=['0.0010000'], tr/val_loss:  2.304994/  2.302639, val:  10.00%, val_best:  10.00%, tr:   7.66%, tr_best:   8.17%\n",
      "epoch-2   lr=['0.0010000'], tr/val_loss:  2.305079/  2.302667, val:  10.00%, val_best:  10.00%, tr:   8.99%, tr_best:   8.99%\n",
      "epoch-3   lr=['0.0010000'], tr/val_loss:  2.304731/  2.302708, val:  10.00%, val_best:  10.00%, tr:   8.38%, tr_best:   8.99%\n",
      "epoch-4   lr=['0.0010000'], tr/val_loss:  2.304833/  2.302682, val:  10.00%, val_best:  10.00%, tr:   7.87%, tr_best:   8.99%\n",
      "epoch-5   lr=['0.0010000'], tr/val_loss:  2.304569/  2.302663, val:  10.00%, val_best:  10.00%, tr:   7.87%, tr_best:   8.99%\n",
      "epoch-6   lr=['0.0010000'], tr/val_loss:  2.305086/  2.302687, val:  10.00%, val_best:  10.00%, tr:   9.70%, tr_best:   9.70%\n",
      "epoch-7   lr=['0.0010000'], tr/val_loss:  2.304632/  2.302694, val:  10.00%, val_best:  10.00%, tr:   7.46%, tr_best:   9.70%\n",
      "epoch-8   lr=['0.0010000'], tr/val_loss:  2.304545/  2.302613, val:  10.00%, val_best:  10.00%, tr:   8.17%, tr_best:   9.70%\n",
      "epoch-9   lr=['0.0010000'], tr/val_loss:  2.305080/  2.302782, val:  10.00%, val_best:  10.00%, tr:   9.19%, tr_best:   9.70%\n",
      "epoch-10  lr=['0.0010000'], tr/val_loss:  2.304688/  2.302772, val:  10.00%, val_best:  10.00%, tr:  10.01%, tr_best:  10.01%\n",
      "epoch-11  lr=['0.0010000'], tr/val_loss:  2.304834/  2.302622, val:  10.00%, val_best:  10.00%, tr:   8.17%, tr_best:  10.01%\n",
      "epoch-12  lr=['0.0010000'], tr/val_loss:  2.304284/  2.302666, val:  10.00%, val_best:  10.00%, tr:   9.50%, tr_best:  10.01%\n",
      "epoch-13  lr=['0.0010000'], tr/val_loss:  2.304813/  2.302634, val:  10.00%, val_best:  10.00%, tr:   9.09%, tr_best:  10.01%\n",
      "epoch-14  lr=['0.0010000'], tr/val_loss:  2.305231/  2.302722, val:  10.00%, val_best:  10.00%, tr:   8.78%, tr_best:  10.01%\n",
      "epoch-15  lr=['0.0010000'], tr/val_loss:  2.305301/  2.302723, val:  10.00%, val_best:  10.00%, tr:   8.38%, tr_best:  10.01%\n",
      "epoch-16  lr=['0.0010000'], tr/val_loss:  2.304772/  2.302634, val:  10.00%, val_best:  10.00%, tr:   8.27%, tr_best:  10.01%\n",
      "epoch-17  lr=['0.0010000'], tr/val_loss:  2.303716/  2.302659, val:  10.00%, val_best:  10.00%, tr:  10.01%, tr_best:  10.01%\n",
      "epoch-18  lr=['0.0010000'], tr/val_loss:  2.304624/  2.302669, val:  10.00%, val_best:  10.00%, tr:   9.30%, tr_best:  10.01%\n",
      "epoch-19  lr=['0.0010000'], tr/val_loss:  2.305880/  2.302768, val:  10.00%, val_best:  10.00%, tr:   8.48%, tr_best:  10.01%\n",
      "epoch-20  lr=['0.0010000'], tr/val_loss:  2.305089/  2.302728, val:  10.00%, val_best:  10.00%, tr:   9.60%, tr_best:  10.01%\n",
      "epoch-21  lr=['0.0010000'], tr/val_loss:  2.304662/  2.302646, val:  10.00%, val_best:  10.00%, tr:   9.40%, tr_best:  10.01%\n",
      "epoch-22  lr=['0.0010000'], tr/val_loss:  2.305019/  2.302714, val:  10.00%, val_best:  10.00%, tr:  10.32%, tr_best:  10.32%\n",
      "epoch-23  lr=['0.0010000'], tr/val_loss:  2.304242/  2.302678, val:  10.00%, val_best:  10.00%, tr:   8.68%, tr_best:  10.32%\n",
      "epoch-24  lr=['0.0010000'], tr/val_loss:  2.303980/  2.302631, val:  10.00%, val_best:  10.00%, tr:   7.66%, tr_best:  10.32%\n",
      "epoch-25  lr=['0.0010000'], tr/val_loss:  2.304494/  2.302676, val:  10.00%, val_best:  10.00%, tr:   8.17%, tr_best:  10.32%\n",
      "epoch-26  lr=['0.0010000'], tr/val_loss:  2.304318/  2.302692, val:  10.00%, val_best:  10.00%, tr:   8.38%, tr_best:  10.32%\n",
      "epoch-27  lr=['0.0010000'], tr/val_loss:  2.304585/  2.302743, val:  10.00%, val_best:  10.00%, tr:   7.97%, tr_best:  10.32%\n",
      "epoch-28  lr=['0.0010000'], tr/val_loss:  2.304604/  2.302687, val:  10.00%, val_best:  10.00%, tr:   7.46%, tr_best:  10.32%\n",
      "epoch-29  lr=['0.0010000'], tr/val_loss:  2.304065/  2.302622, val:  10.00%, val_best:  10.00%, tr:   9.70%, tr_best:  10.32%\n",
      "epoch-30  lr=['0.0010000'], tr/val_loss:  2.304437/  2.302634, val:  10.00%, val_best:  10.00%, tr:   7.87%, tr_best:  10.32%\n",
      "epoch-31  lr=['0.0010000'], tr/val_loss:  2.304662/  2.302706, val:  10.00%, val_best:  10.00%, tr:   7.25%, tr_best:  10.32%\n",
      "epoch-32  lr=['0.0010000'], tr/val_loss:  2.305145/  2.302731, val:  10.00%, val_best:  10.00%, tr:   7.87%, tr_best:  10.32%\n",
      "epoch-33  lr=['0.0010000'], tr/val_loss:  2.304735/  2.302727, val:  10.00%, val_best:  10.00%, tr:   8.58%, tr_best:  10.32%\n",
      "epoch-34  lr=['0.0010000'], tr/val_loss:  2.304953/  2.302632, val:  10.00%, val_best:  10.00%, tr:   8.78%, tr_best:  10.32%\n",
      "epoch-35  lr=['0.0010000'], tr/val_loss:  2.304517/  2.302745, val:  10.00%, val_best:  10.00%, tr:   9.40%, tr_best:  10.32%\n",
      "epoch-36  lr=['0.0010000'], tr/val_loss:  2.304946/  2.302701, val:  10.00%, val_best:  10.00%, tr:   8.68%, tr_best:  10.32%\n",
      "epoch-37  lr=['0.0010000'], tr/val_loss:  2.305197/  2.302687, val:  10.00%, val_best:  10.00%, tr:   8.89%, tr_best:  10.32%\n",
      "epoch-38  lr=['0.0010000'], tr/val_loss:  2.304106/  2.302715, val:  10.00%, val_best:  10.00%, tr:   8.99%, tr_best:  10.32%\n",
      "epoch-39  lr=['0.0010000'], tr/val_loss:  2.304535/  2.302683, val:  10.00%, val_best:  10.00%, tr:   9.40%, tr_best:  10.32%\n",
      "epoch-40  lr=['0.0010000'], tr/val_loss:  2.304653/  2.302674, val:  10.00%, val_best:  10.00%, tr:   8.99%, tr_best:  10.32%\n",
      "epoch-41  lr=['0.0010000'], tr/val_loss:  2.304348/  2.302677, val:  10.00%, val_best:  10.00%, tr:   9.60%, tr_best:  10.32%\n",
      "epoch-42  lr=['0.0010000'], tr/val_loss:  2.304514/  2.302729, val:  10.00%, val_best:  10.00%, tr:   9.19%, tr_best:  10.32%\n",
      "epoch-43  lr=['0.0010000'], tr/val_loss:  2.304611/  2.302673, val:  10.00%, val_best:  10.00%, tr:   8.89%, tr_best:  10.32%\n",
      "epoch-44  lr=['0.0010000'], tr/val_loss:  2.304545/  2.302760, val:  10.00%, val_best:  10.00%, tr:   8.17%, tr_best:  10.32%\n",
      "epoch-45  lr=['0.0010000'], tr/val_loss:  2.304274/  2.302822, val:  10.00%, val_best:  10.00%, tr:   9.30%, tr_best:  10.32%\n",
      "epoch-46  lr=['0.0010000'], tr/val_loss:  2.304114/  2.302626, val:  10.00%, val_best:  10.00%, tr:   9.09%, tr_best:  10.32%\n",
      "epoch-47  lr=['0.0010000'], tr/val_loss:  2.304720/  2.302717, val:  10.00%, val_best:  10.00%, tr:   8.48%, tr_best:  10.32%\n",
      "epoch-48  lr=['0.0010000'], tr/val_loss:  2.304052/  2.302806, val:  10.00%, val_best:  10.00%, tr:   9.81%, tr_best:  10.32%\n",
      "epoch-49  lr=['0.0010000'], tr/val_loss:  2.304631/  2.302734, val:  10.00%, val_best:  10.00%, tr:   9.60%, tr_best:  10.32%\n",
      "epoch-50  lr=['0.0010000'], tr/val_loss:  2.304856/  2.302790, val:  10.00%, val_best:  10.00%, tr:  10.11%, tr_best:  10.32%\n",
      "epoch-51  lr=['0.0010000'], tr/val_loss:  2.303980/  2.302723, val:  10.00%, val_best:  10.00%, tr:   8.38%, tr_best:  10.32%\n",
      "epoch-52  lr=['0.0010000'], tr/val_loss:  2.305447/  2.302761, val:  10.00%, val_best:  10.00%, tr:   7.87%, tr_best:  10.32%\n",
      "epoch-53  lr=['0.0010000'], tr/val_loss:  2.304740/  2.302716, val:  10.00%, val_best:  10.00%, tr:   8.48%, tr_best:  10.32%\n",
      "epoch-54  lr=['0.0010000'], tr/val_loss:  2.304604/  2.302668, val:  10.00%, val_best:  10.00%, tr:   9.40%, tr_best:  10.32%\n",
      "epoch-55  lr=['0.0010000'], tr/val_loss:  2.304554/  2.302632, val:  10.00%, val_best:  10.00%, tr:   7.35%, tr_best:  10.32%\n",
      "epoch-56  lr=['0.0010000'], tr/val_loss:  2.305324/  2.302709, val:  10.00%, val_best:  10.00%, tr:  10.01%, tr_best:  10.32%\n",
      "epoch-57  lr=['0.0010000'], tr/val_loss:  2.304349/  2.302676, val:  10.00%, val_best:  10.00%, tr:   8.07%, tr_best:  10.32%\n",
      "epoch-58  lr=['0.0010000'], tr/val_loss:  2.304797/  2.302742, val:  10.00%, val_best:  10.00%, tr:   9.40%, tr_best:  10.32%\n",
      "epoch-59  lr=['0.0010000'], tr/val_loss:  2.305519/  2.302842, val:  10.00%, val_best:  10.00%, tr:   9.50%, tr_best:  10.32%\n",
      "epoch-60  lr=['0.0010000'], tr/val_loss:  2.304214/  2.302650, val:  10.00%, val_best:  10.00%, tr:   7.87%, tr_best:  10.32%\n",
      "epoch-61  lr=['0.0010000'], tr/val_loss:  2.304307/  2.302675, val:  10.00%, val_best:  10.00%, tr:   9.09%, tr_best:  10.32%\n",
      "epoch-62  lr=['0.0010000'], tr/val_loss:  2.304764/  2.302663, val:  10.00%, val_best:  10.00%, tr:   8.99%, tr_best:  10.32%\n",
      "epoch-63  lr=['0.0010000'], tr/val_loss:  2.304623/  2.302703, val:  10.00%, val_best:  10.00%, tr:   9.30%, tr_best:  10.32%\n",
      "epoch-64  lr=['0.0010000'], tr/val_loss:  2.303885/  2.302848, val:  10.00%, val_best:  10.00%, tr:   9.09%, tr_best:  10.32%\n",
      "epoch-65  lr=['0.0010000'], tr/val_loss:  2.304417/  2.302755, val:  10.00%, val_best:  10.00%, tr:   9.30%, tr_best:  10.32%\n",
      "epoch-66  lr=['0.0010000'], tr/val_loss:  2.303841/  2.302698, val:  10.00%, val_best:  10.00%, tr:   9.09%, tr_best:  10.32%\n",
      "epoch-67  lr=['0.0010000'], tr/val_loss:  2.305081/  2.302692, val:  10.00%, val_best:  10.00%, tr:  10.01%, tr_best:  10.32%\n",
      "epoch-68  lr=['0.0010000'], tr/val_loss:  2.305073/  2.302701, val:  10.00%, val_best:  10.00%, tr:   9.30%, tr_best:  10.32%\n",
      "epoch-69  lr=['0.0010000'], tr/val_loss:  2.304717/  2.302645, val:  10.00%, val_best:  10.00%, tr:   8.99%, tr_best:  10.32%\n",
      "epoch-70  lr=['0.0010000'], tr/val_loss:  2.305171/  2.302620, val:  10.00%, val_best:  10.00%, tr:   8.38%, tr_best:  10.32%\n",
      "epoch-71  lr=['0.0010000'], tr/val_loss:  2.305242/  2.302688, val:  10.00%, val_best:  10.00%, tr:   8.48%, tr_best:  10.32%\n",
      "epoch-72  lr=['0.0010000'], tr/val_loss:  2.304678/  2.302624, val:  10.00%, val_best:  10.00%, tr:   8.58%, tr_best:  10.32%\n",
      "epoch-73  lr=['0.0010000'], tr/val_loss:  2.304676/  2.302652, val:  10.00%, val_best:  10.00%, tr:   8.48%, tr_best:  10.32%\n",
      "epoch-74  lr=['0.0010000'], tr/val_loss:  2.304883/  2.302660, val:  10.00%, val_best:  10.00%, tr:   9.30%, tr_best:  10.32%\n",
      "epoch-75  lr=['0.0010000'], tr/val_loss:  2.305337/  2.302700, val:  10.00%, val_best:  10.00%, tr:   9.19%, tr_best:  10.32%\n",
      "epoch-76  lr=['0.0010000'], tr/val_loss:  2.305019/  2.302656, val:  10.00%, val_best:  10.00%, tr:   8.17%, tr_best:  10.32%\n",
      "epoch-77  lr=['0.0010000'], tr/val_loss:  2.305215/  2.302638, val:  10.00%, val_best:  10.00%, tr:   8.89%, tr_best:  10.32%\n",
      "epoch-78  lr=['0.0010000'], tr/val_loss:  2.304676/  2.302660, val:  10.00%, val_best:  10.00%, tr:   9.09%, tr_best:  10.32%\n",
      "epoch-79  lr=['0.0010000'], tr/val_loss:  2.304999/  2.302665, val:  10.00%, val_best:  10.00%, tr:   9.81%, tr_best:  10.32%\n",
      "epoch-80  lr=['0.0010000'], tr/val_loss:  2.304617/  2.302732, val:  10.00%, val_best:  10.00%, tr:   7.35%, tr_best:  10.32%\n",
      "epoch-81  lr=['0.0010000'], tr/val_loss:  2.304430/  2.302707, val:  10.00%, val_best:  10.00%, tr:   7.66%, tr_best:  10.32%\n",
      "epoch-82  lr=['0.0010000'], tr/val_loss:  2.304436/  2.302796, val:  10.00%, val_best:  10.00%, tr:   9.30%, tr_best:  10.32%\n",
      "epoch-83  lr=['0.0010000'], tr/val_loss:  2.305023/  2.302669, val:  10.00%, val_best:  10.00%, tr:   7.66%, tr_best:  10.32%\n",
      "epoch-84  lr=['0.0010000'], tr/val_loss:  2.304577/  2.302758, val:  10.00%, val_best:  10.00%, tr:   8.89%, tr_best:  10.32%\n",
      "epoch-85  lr=['0.0010000'], tr/val_loss:  2.304359/  2.302626, val:  10.00%, val_best:  10.00%, tr:   8.07%, tr_best:  10.32%\n",
      "epoch-86  lr=['0.0010000'], tr/val_loss:  2.305443/  2.302771, val:  10.00%, val_best:  10.00%, tr:   8.17%, tr_best:  10.32%\n",
      "epoch-87  lr=['0.0010000'], tr/val_loss:  2.304418/  2.302737, val:  10.00%, val_best:  10.00%, tr:   8.78%, tr_best:  10.32%\n",
      "epoch-88  lr=['0.0010000'], tr/val_loss:  2.305364/  2.302662, val:  10.00%, val_best:  10.00%, tr:   8.68%, tr_best:  10.32%\n",
      "epoch-89  lr=['0.0010000'], tr/val_loss:  2.304665/  2.302694, val:  10.00%, val_best:  10.00%, tr:   8.89%, tr_best:  10.32%\n",
      "epoch-90  lr=['0.0010000'], tr/val_loss:  2.305019/  2.302693, val:  10.00%, val_best:  10.00%, tr:   8.38%, tr_best:  10.32%\n",
      "epoch-91  lr=['0.0010000'], tr/val_loss:  2.304266/  2.302669, val:  10.00%, val_best:  10.00%, tr:  10.21%, tr_best:  10.32%\n",
      "epoch-92  lr=['0.0010000'], tr/val_loss:  2.304705/  2.302684, val:  10.00%, val_best:  10.00%, tr:   9.40%, tr_best:  10.32%\n",
      "epoch-93  lr=['0.0010000'], tr/val_loss:  2.304860/  2.302634, val:  10.00%, val_best:  10.00%, tr:   8.68%, tr_best:  10.32%\n",
      "epoch-94  lr=['0.0010000'], tr/val_loss:  2.304419/  2.302675, val:  10.00%, val_best:  10.00%, tr:   8.89%, tr_best:  10.32%\n",
      "epoch-95  lr=['0.0010000'], tr/val_loss:  2.304308/  2.302676, val:  10.00%, val_best:  10.00%, tr:   8.17%, tr_best:  10.32%\n",
      "epoch-96  lr=['0.0010000'], tr/val_loss:  2.304734/  2.302685, val:  10.00%, val_best:  10.00%, tr:  10.11%, tr_best:  10.32%\n",
      "epoch-97  lr=['0.0010000'], tr/val_loss:  2.304735/  2.302724, val:  10.00%, val_best:  10.00%, tr:   9.09%, tr_best:  10.32%\n",
      "epoch-98  lr=['0.0010000'], tr/val_loss:  2.305681/  2.302760, val:  10.00%, val_best:  10.00%, tr:  10.11%, tr_best:  10.32%\n",
      "epoch-99  lr=['0.0010000'], tr/val_loss:  2.304706/  2.302780, val:  10.00%, val_best:  10.00%, tr:   9.50%, tr_best:  10.32%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "59762862c0f54ab3bedd1d01f3defd4e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.006 MB of 0.006 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>iter_acc</td><td>▃▆▁▃▃▃▃▃▃▃▃▁▃▆▃▆▆▃██▃▃▁▃▁▃▁▃▃▁▃▆▃▁▁▁█▃▁▃</td></tr><tr><td>summary_val_acc</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>tr_acc</td><td>▃▅▂▁▆▇▅█▄▆▂▄▇▂▆▅▆▆▃▄▇▂▆▃▇▅▆█▄▄▆▅▇▆▅▅▅▆▃▅</td></tr><tr><td>tr_epoch_loss</td><td>▆▅▅▄▅▃▆▁█▄▂▃▂▆▄▆▄▄▄▄▄▇▄▃▇▃▃▅▆▄▆▆▅▃▄▃▄▄▃▄</td></tr><tr><td>val_acc_best</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_acc_now</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_loss</td><td>█▂▃▃▆▂▄▂▆▂▁▃▁▅▅▃▃▄▅▄▅▅▃▃█▃▅▃▁▁▄▂▂▇▅▅▃▃▃▄</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>99</td></tr><tr><td>iter_acc</td><td>0.0</td></tr><tr><td>tr_acc</td><td>0.09499</td></tr><tr><td>tr_epoch_loss</td><td>2.30471</td></tr><tr><td>val_acc_best</td><td>0.1</td></tr><tr><td>val_acc_now</td><td>0.1</td></tr><tr><td>val_loss</td><td>2.30278</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">vocal-sweep-264</strong> at: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/vr8a4sr5' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/vr8a4sr5</a><br/> View project at: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>/data2/bh_wandb/wandb/run-20250430_091545-vr8a4sr5/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require(\"core\")`! See https://wandb.me/wandb-core for more information."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Sweep Agent: Waiting for job.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Job received.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: a1qdl35z with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBATCH: 16\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBN_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBPTT_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tDFA_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tIMAGE_SIZE: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tOTTT_input_trace_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tTIME: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tUDA_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \talpha_uda: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbias: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcfg: ['M', 'M', 200, 200]\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tchaching_on: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tconvTrue_fcFalse: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdata_path: /data2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tddp_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdenoise_on: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdvs_clipping: 5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdvs_duration: 100000\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepoch_num: 100\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \texclude_class: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \textra_train_dataset: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlast_lif: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.001\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_sg_width: 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_decay: 0.5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_init: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_reset: 10000\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_threshold: 0.25\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmerge_polarities: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmy_seed: 42\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnet_print: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_workers: 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer_what: SGD\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tpin_memory: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tpre_trained: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tpre_trained_path: net_save/save_now_net_weights_{unique_name}.pth\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \trate_coding: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tscheduler_name: no\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsingle_step: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsurrogate: hard_sigmoid\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_conv_kernel_size: 3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_conv_padding: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_conv_stride: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_trace_const1: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_trace_const2: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \ttdBN_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \ttrace_on: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \twhich_data: DVS_GESTURE_TONIC\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f3d0b96be28b461db5fa16e34da6ba1f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.011113278096955684, max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.19.10 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.17.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/data2/bh_wandb/wandb/run-20250430_092149-a1qdl35z</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/a1qdl35z' target=\"_blank\">bumbling-sweep-265</a></strong> to <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/6pj3lh8j' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/6pj3lh8j</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/6pj3lh8j' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/6pj3lh8j</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/a1qdl35z' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/a1qdl35z</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'single_step' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'my_seed' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'TIME' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BATCH' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'IMAGE_SIZE' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'which_data' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'data_path' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'rate_coding' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_init' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_decay' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_threshold' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_reset' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_sg_width' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_conv_kernel_size' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_conv_stride' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_conv_padding' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_trace_const1' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_trace_const2' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'pre_trained' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'convTrue_fcFalse' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'cfg' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'net_print' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'pre_trained_path' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'learning_rate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'epoch_num' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'tdBN_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BN_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'surrogate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BPTT_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'optimizer_what' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'scheduler_name' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'ddp_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'dvs_clipping' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'dvs_duration' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'DFA_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'trace_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'OTTT_input_trace_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'exclude_class' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'merge_polarities' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'denoise_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'extra_train_dataset' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'num_workers' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'chaching_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'pin_memory' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'UDA_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'alpha_uda' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'bias' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'last_lif' was locked by 'sweep' (ignored update).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "param {'devices': '0', 'single_step': True, 'unique_name': 'main', 'my_seed': 42, 'TIME': 10, 'BATCH': 16, 'IMAGE_SIZE': 128, 'which_data': 'DVS_GESTURE_TONIC', 'data_path': '/data2', 'rate_coding': False, 'lif_layer_v_init': 0, 'lif_layer_v_decay': 0.5, 'lif_layer_v_threshold': 0.25, 'lif_layer_v_reset': 10000, 'lif_layer_sg_width': 2, 'synapse_conv_kernel_size': 3, 'synapse_conv_stride': 1, 'synapse_conv_padding': 1, 'synapse_trace_const1': 1, 'synapse_trace_const2': 0, 'pre_trained': False, 'convTrue_fcFalse': False, 'cfg': ['M', 'M', 200, 200], 'net_print': True, 'pre_trained_path': 'net_save/save_now_net_weights_{unique_name}.pth', 'learning_rate': 0.001, 'epoch_num': 100, 'tdBN_on': False, 'BN_on': False, 'surrogate': 'hard_sigmoid', 'BPTT_on': False, 'optimizer_what': 'SGD', 'scheduler_name': 'no', 'ddp_on': False, 'dvs_clipping': 5, 'dvs_duration': 100000, 'DFA_on': False, 'trace_on': True, 'OTTT_input_trace_on': False, 'exclude_class': True, 'merge_polarities': False, 'denoise_on': True, 'extra_train_dataset': 0, 'num_workers': 2, 'chaching_on': True, 'pin_memory': True, 'UDA_on': False, 'alpha_uda': 1, 'bias': True, 'last_lif': False, 'current epoch': 0} \n",
      "\n",
      "dataset_hash = 63cc597115630ec173f3099200061e53\n",
      "cache path exists\n",
      "\n",
      "device ==> cuda\n",
      "\n",
      "DataParallel(\n",
      "  (module): REBORN_MY_SNN_FC(\n",
      "    (layers): REBORN_MY_Sequential(\n",
      "      (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (2): DimChanger_for_FC()\n",
      "      (3): SYNAPSE_FC(in_features=2048, out_features=200, TIME=10, bias=True, sstep=True)\n",
      "      (4): LIF_layer(v_init=0, v_decay=0.5, v_threshold=0.25, v_reset=10000, sg_width=2, surrogate=hard_sigmoid, BPTT_on=False, trace_const1=1, trace_const2=0, TIME=10, sstep=True, trace_on=True)\n",
      "      (5): SYNAPSE_FC(in_features=200, out_features=200, TIME=10, bias=True, sstep=True)\n",
      "      (6): LIF_layer(v_init=0, v_decay=0.5, v_threshold=0.25, v_reset=10000, sg_width=2, surrogate=hard_sigmoid, BPTT_on=False, trace_const1=1, trace_const2=0, TIME=10, sstep=True, trace_on=True)\n",
      "      (7): SYNAPSE_FC(in_features=200, out_features=10, TIME=10, bias=True, sstep=True)\n",
      "    )\n",
      "  )\n",
      ")\n",
      "\n",
      "========================================================\n",
      "Trainable parameters: 452,010\n",
      "========================================================\n",
      "\n",
      "epoch-0   lr=['0.0010000'], tr/val_loss:  2.274191/  2.218580, val:  25.00%, val_best:  25.00%, tr:  15.22%, tr_best:  15.22%\n",
      "epoch-1   lr=['0.0010000'], tr/val_loss:  2.075346/  1.972411, val:  47.50%, val_best:  47.50%, tr:  33.09%, tr_best:  33.09%\n",
      "epoch-2   lr=['0.0010000'], tr/val_loss:  1.756007/  1.739949, val:  51.67%, val_best:  51.67%, tr:  52.50%, tr_best:  52.50%\n",
      "epoch-3   lr=['0.0010000'], tr/val_loss:  1.552190/  1.630692, val:  53.33%, val_best:  53.33%, tr:  59.35%, tr_best:  59.35%\n",
      "epoch-4   lr=['0.0010000'], tr/val_loss:  1.445712/  1.578947, val:  55.83%, val_best:  55.83%, tr:  60.88%, tr_best:  60.88%\n",
      "epoch-5   lr=['0.0010000'], tr/val_loss:  1.355659/  1.513748, val:  59.17%, val_best:  59.17%, tr:  63.23%, tr_best:  63.23%\n",
      "epoch-6   lr=['0.0010000'], tr/val_loss:  1.298607/  1.495619, val:  59.58%, val_best:  59.58%, tr:  64.04%, tr_best:  64.04%\n",
      "epoch-7   lr=['0.0010000'], tr/val_loss:  1.254347/  1.449809, val:  58.75%, val_best:  59.58%, tr:  63.94%, tr_best:  64.04%\n",
      "epoch-8   lr=['0.0010000'], tr/val_loss:  1.208795/  1.409656, val:  62.08%, val_best:  62.08%, tr:  65.68%, tr_best:  65.68%\n",
      "epoch-9   lr=['0.0010000'], tr/val_loss:  1.177571/  1.412178, val:  60.00%, val_best:  62.08%, tr:  67.62%, tr_best:  67.62%\n",
      "epoch-10  lr=['0.0010000'], tr/val_loss:  1.147070/  1.396901, val:  56.25%, val_best:  62.08%, tr:  67.21%, tr_best:  67.62%\n",
      "epoch-11  lr=['0.0010000'], tr/val_loss:  1.112069/  1.354416, val:  62.92%, val_best:  62.92%, tr:  68.95%, tr_best:  68.95%\n",
      "epoch-12  lr=['0.0010000'], tr/val_loss:  1.096676/  1.344656, val:  59.58%, val_best:  62.92%, tr:  69.56%, tr_best:  69.56%\n",
      "epoch-13  lr=['0.0010000'], tr/val_loss:  1.077895/  1.319699, val:  62.08%, val_best:  62.92%, tr:  69.46%, tr_best:  69.56%\n",
      "epoch-14  lr=['0.0010000'], tr/val_loss:  1.031875/  1.362107, val:  56.67%, val_best:  62.92%, tr:  70.99%, tr_best:  70.99%\n",
      "epoch-15  lr=['0.0010000'], tr/val_loss:  1.028225/  1.320042, val:  64.17%, val_best:  64.17%, tr:  69.97%, tr_best:  70.99%\n",
      "epoch-16  lr=['0.0010000'], tr/val_loss:  1.010160/  1.293994, val:  63.75%, val_best:  64.17%, tr:  70.79%, tr_best:  70.99%\n",
      "epoch-17  lr=['0.0010000'], tr/val_loss:  0.976378/  1.284030, val:  65.83%, val_best:  65.83%, tr:  72.93%, tr_best:  72.93%\n",
      "epoch-18  lr=['0.0010000'], tr/val_loss:  0.960143/  1.313055, val:  60.00%, val_best:  65.83%, tr:  73.75%, tr_best:  73.75%\n",
      "epoch-19  lr=['0.0010000'], tr/val_loss:  0.959531/  1.308789, val:  60.83%, val_best:  65.83%, tr:  72.42%, tr_best:  73.75%\n",
      "epoch-20  lr=['0.0010000'], tr/val_loss:  0.928179/  1.284169, val:  63.33%, val_best:  65.83%, tr:  75.49%, tr_best:  75.49%\n",
      "epoch-21  lr=['0.0010000'], tr/val_loss:  0.916651/  1.262569, val:  65.83%, val_best:  65.83%, tr:  75.08%, tr_best:  75.49%\n",
      "epoch-22  lr=['0.0010000'], tr/val_loss:  0.915391/  1.279294, val:  63.33%, val_best:  65.83%, tr:  73.44%, tr_best:  75.49%\n",
      "epoch-23  lr=['0.0010000'], tr/val_loss:  0.883316/  1.271851, val:  65.42%, val_best:  65.83%, tr:  75.89%, tr_best:  75.89%\n",
      "epoch-24  lr=['0.0010000'], tr/val_loss:  0.863569/  1.277230, val:  63.33%, val_best:  65.83%, tr:  77.02%, tr_best:  77.02%\n",
      "epoch-25  lr=['0.0010000'], tr/val_loss:  0.852133/  1.254971, val:  67.92%, val_best:  67.92%, tr:  79.88%, tr_best:  79.88%\n",
      "epoch-26  lr=['0.0010000'], tr/val_loss:  0.845096/  1.252516, val:  65.42%, val_best:  67.92%, tr:  77.02%, tr_best:  79.88%\n",
      "epoch-27  lr=['0.0010000'], tr/val_loss:  0.827716/  1.291874, val:  64.17%, val_best:  67.92%, tr:  81.61%, tr_best:  81.61%\n",
      "epoch-28  lr=['0.0010000'], tr/val_loss:  0.820895/  1.234459, val:  65.83%, val_best:  67.92%, tr:  78.65%, tr_best:  81.61%\n",
      "epoch-29  lr=['0.0010000'], tr/val_loss:  0.811412/  1.277113, val:  62.08%, val_best:  67.92%, tr:  81.41%, tr_best:  81.61%\n",
      "epoch-30  lr=['0.0010000'], tr/val_loss:  0.793039/  1.266493, val:  64.17%, val_best:  67.92%, tr:  81.92%, tr_best:  81.92%\n",
      "epoch-31  lr=['0.0010000'], tr/val_loss:  0.798810/  1.303115, val:  62.50%, val_best:  67.92%, tr:  79.26%, tr_best:  81.92%\n",
      "epoch-32  lr=['0.0010000'], tr/val_loss:  0.782557/  1.282359, val:  65.83%, val_best:  67.92%, tr:  80.90%, tr_best:  81.92%\n",
      "epoch-33  lr=['0.0010000'], tr/val_loss:  0.772575/  1.269219, val:  68.75%, val_best:  68.75%, tr:  84.98%, tr_best:  84.98%\n",
      "epoch-34  lr=['0.0010000'], tr/val_loss:  0.757120/  1.289704, val:  65.83%, val_best:  68.75%, tr:  84.37%, tr_best:  84.98%\n",
      "epoch-35  lr=['0.0010000'], tr/val_loss:  0.760014/  1.307997, val:  66.67%, val_best:  68.75%, tr:  82.94%, tr_best:  84.98%\n",
      "epoch-36  lr=['0.0010000'], tr/val_loss:  0.734718/  1.261122, val:  70.00%, val_best:  70.00%, tr:  84.27%, tr_best:  84.98%\n",
      "epoch-37  lr=['0.0010000'], tr/val_loss:  0.738601/  1.288741, val:  72.08%, val_best:  72.08%, tr:  87.64%, tr_best:  87.64%\n",
      "epoch-38  lr=['0.0010000'], tr/val_loss:  0.721352/  1.292264, val:  70.00%, val_best:  72.08%, tr:  88.15%, tr_best:  88.15%\n",
      "epoch-39  lr=['0.0010000'], tr/val_loss:  0.710615/  1.291598, val:  68.33%, val_best:  72.08%, tr:  87.95%, tr_best:  88.15%\n",
      "epoch-40  lr=['0.0010000'], tr/val_loss:  0.707907/  1.281552, val:  69.17%, val_best:  72.08%, tr:  84.88%, tr_best:  88.15%\n",
      "epoch-41  lr=['0.0010000'], tr/val_loss:  0.687178/  1.335739, val:  67.08%, val_best:  72.08%, tr:  89.79%, tr_best:  89.79%\n",
      "epoch-42  lr=['0.0010000'], tr/val_loss:  0.676278/  1.304975, val:  67.08%, val_best:  72.08%, tr:  88.46%, tr_best:  89.79%\n",
      "epoch-43  lr=['0.0010000'], tr/val_loss:  0.663939/  1.310527, val:  70.00%, val_best:  72.08%, tr:  88.46%, tr_best:  89.79%\n",
      "epoch-44  lr=['0.0010000'], tr/val_loss:  0.658724/  1.326202, val:  69.58%, val_best:  72.08%, tr:  88.15%, tr_best:  89.79%\n",
      "epoch-45  lr=['0.0010000'], tr/val_loss:  0.642301/  1.310706, val:  70.42%, val_best:  72.08%, tr:  91.83%, tr_best:  91.83%\n",
      "epoch-46  lr=['0.0010000'], tr/val_loss:  0.641415/  1.337583, val:  65.83%, val_best:  72.08%, tr:  90.09%, tr_best:  91.83%\n",
      "epoch-47  lr=['0.0010000'], tr/val_loss:  0.628301/  1.370839, val:  70.00%, val_best:  72.08%, tr:  90.70%, tr_best:  91.83%\n",
      "epoch-48  lr=['0.0010000'], tr/val_loss:  0.629010/  1.324082, val:  69.17%, val_best:  72.08%, tr:  91.83%, tr_best:  91.83%\n",
      "epoch-49  lr=['0.0010000'], tr/val_loss:  0.620537/  1.319781, val:  75.00%, val_best:  75.00%, tr:  90.19%, tr_best:  91.83%\n",
      "epoch-50  lr=['0.0010000'], tr/val_loss:  0.615928/  1.352340, val:  74.17%, val_best:  75.00%, tr:  90.50%, tr_best:  91.83%\n",
      "epoch-51  lr=['0.0010000'], tr/val_loss:  0.603395/  1.377992, val:  70.42%, val_best:  75.00%, tr:  91.11%, tr_best:  91.83%\n",
      "epoch-52  lr=['0.0010000'], tr/val_loss:  0.590253/  1.438112, val:  63.33%, val_best:  75.00%, tr:  91.32%, tr_best:  91.83%\n",
      "epoch-53  lr=['0.0010000'], tr/val_loss:  0.592096/  1.405250, val:  70.00%, val_best:  75.00%, tr:  93.05%, tr_best:  93.05%\n",
      "epoch-54  lr=['0.0010000'], tr/val_loss:  0.580699/  1.383874, val:  71.25%, val_best:  75.00%, tr:  93.05%, tr_best:  93.05%\n",
      "epoch-55  lr=['0.0010000'], tr/val_loss:  0.567805/  1.391743, val:  71.25%, val_best:  75.00%, tr:  92.54%, tr_best:  93.05%\n",
      "epoch-56  lr=['0.0010000'], tr/val_loss:  0.564567/  1.474526, val:  65.42%, val_best:  75.00%, tr:  93.05%, tr_best:  93.05%\n",
      "epoch-57  lr=['0.0010000'], tr/val_loss:  0.577867/  1.390273, val:  68.75%, val_best:  75.00%, tr:  92.24%, tr_best:  93.05%\n",
      "epoch-58  lr=['0.0010000'], tr/val_loss:  0.547812/  1.455299, val:  65.42%, val_best:  75.00%, tr:  94.08%, tr_best:  94.08%\n",
      "epoch-59  lr=['0.0010000'], tr/val_loss:  0.553900/  1.433185, val:  75.42%, val_best:  75.42%, tr:  94.59%, tr_best:  94.59%\n",
      "epoch-60  lr=['0.0010000'], tr/val_loss:  0.539167/  1.435867, val:  70.00%, val_best:  75.42%, tr:  94.89%, tr_best:  94.89%\n",
      "epoch-61  lr=['0.0010000'], tr/val_loss:  0.528375/  1.467913, val:  66.25%, val_best:  75.42%, tr:  95.81%, tr_best:  95.81%\n",
      "epoch-62  lr=['0.0010000'], tr/val_loss:  0.525013/  1.456464, val:  71.67%, val_best:  75.42%, tr:  94.89%, tr_best:  95.81%\n",
      "epoch-63  lr=['0.0010000'], tr/val_loss:  0.515302/  1.425273, val:  70.83%, val_best:  75.42%, tr:  96.94%, tr_best:  96.94%\n",
      "epoch-64  lr=['0.0010000'], tr/val_loss:  0.517663/  1.497600, val:  69.17%, val_best:  75.42%, tr:  95.20%, tr_best:  96.94%\n",
      "epoch-65  lr=['0.0010000'], tr/val_loss:  0.509702/  1.484637, val:  72.50%, val_best:  75.42%, tr:  95.81%, tr_best:  96.94%\n",
      "epoch-66  lr=['0.0010000'], tr/val_loss:  0.500092/  1.494254, val:  69.58%, val_best:  75.42%, tr:  95.30%, tr_best:  96.94%\n",
      "epoch-67  lr=['0.0010000'], tr/val_loss:  0.501544/  1.501006, val:  70.42%, val_best:  75.42%, tr:  96.12%, tr_best:  96.94%\n",
      "epoch-68  lr=['0.0010000'], tr/val_loss:  0.490964/  1.502536, val:  68.75%, val_best:  75.42%, tr:  95.30%, tr_best:  96.94%\n",
      "epoch-69  lr=['0.0010000'], tr/val_loss:  0.490592/  1.530194, val:  66.25%, val_best:  75.42%, tr:  95.20%, tr_best:  96.94%\n",
      "epoch-70  lr=['0.0010000'], tr/val_loss:  0.479384/  1.517751, val:  72.08%, val_best:  75.42%, tr:  96.83%, tr_best:  96.94%\n",
      "epoch-71  lr=['0.0010000'], tr/val_loss:  0.480564/  1.547641, val:  66.67%, val_best:  75.42%, tr:  97.04%, tr_best:  97.04%\n",
      "epoch-72  lr=['0.0010000'], tr/val_loss:  0.473086/  1.558800, val:  69.17%, val_best:  75.42%, tr:  96.32%, tr_best:  97.04%\n",
      "epoch-73  lr=['0.0010000'], tr/val_loss:  0.480731/  1.543317, val:  73.33%, val_best:  75.42%, tr:  95.91%, tr_best:  97.04%\n",
      "epoch-74  lr=['0.0010000'], tr/val_loss:  0.461853/  1.534527, val:  72.50%, val_best:  75.42%, tr:  96.83%, tr_best:  97.04%\n",
      "epoch-75  lr=['0.0010000'], tr/val_loss:  0.455817/  1.571643, val:  65.83%, val_best:  75.42%, tr:  95.61%, tr_best:  97.04%\n",
      "epoch-76  lr=['0.0010000'], tr/val_loss:  0.447568/  1.577328, val:  66.67%, val_best:  75.42%, tr:  97.65%, tr_best:  97.65%\n",
      "epoch-77  lr=['0.0010000'], tr/val_loss:  0.461766/  1.571505, val:  71.25%, val_best:  75.42%, tr:  95.81%, tr_best:  97.65%\n",
      "epoch-78  lr=['0.0010000'], tr/val_loss:  0.452556/  1.546493, val:  74.17%, val_best:  75.42%, tr:  96.42%, tr_best:  97.65%\n",
      "epoch-79  lr=['0.0010000'], tr/val_loss:  0.439795/  1.534450, val:  74.17%, val_best:  75.42%, tr:  96.94%, tr_best:  97.65%\n",
      "epoch-80  lr=['0.0010000'], tr/val_loss:  0.426617/  1.551494, val:  75.00%, val_best:  75.42%, tr:  97.75%, tr_best:  97.75%\n",
      "epoch-81  lr=['0.0010000'], tr/val_loss:  0.429164/  1.578474, val:  74.58%, val_best:  75.42%, tr:  97.75%, tr_best:  97.75%\n",
      "epoch-82  lr=['0.0010000'], tr/val_loss:  0.424351/  1.598652, val:  71.67%, val_best:  75.42%, tr:  97.24%, tr_best:  97.75%\n",
      "epoch-83  lr=['0.0010000'], tr/val_loss:  0.421248/  1.653961, val:  72.50%, val_best:  75.42%, tr:  97.34%, tr_best:  97.75%\n",
      "epoch-84  lr=['0.0010000'], tr/val_loss:  0.417699/  1.599366, val:  70.83%, val_best:  75.42%, tr:  97.96%, tr_best:  97.96%\n",
      "epoch-85  lr=['0.0010000'], tr/val_loss:  0.406182/  1.632522, val:  73.33%, val_best:  75.42%, tr:  97.96%, tr_best:  97.96%\n",
      "epoch-86  lr=['0.0010000'], tr/val_loss:  0.406919/  1.666832, val:  72.92%, val_best:  75.42%, tr:  96.63%, tr_best:  97.96%\n",
      "epoch-87  lr=['0.0010000'], tr/val_loss:  0.403068/  1.639962, val:  73.33%, val_best:  75.42%, tr:  97.65%, tr_best:  97.96%\n",
      "epoch-88  lr=['0.0010000'], tr/val_loss:  0.388461/  1.656087, val:  72.08%, val_best:  75.42%, tr:  98.26%, tr_best:  98.26%\n",
      "epoch-89  lr=['0.0010000'], tr/val_loss:  0.377699/  1.681610, val:  72.92%, val_best:  75.42%, tr:  99.08%, tr_best:  99.08%\n",
      "epoch-90  lr=['0.0010000'], tr/val_loss:  0.388125/  1.643831, val:  74.58%, val_best:  75.42%, tr:  97.96%, tr_best:  99.08%\n",
      "epoch-91  lr=['0.0010000'], tr/val_loss:  0.372250/  1.668326, val:  75.83%, val_best:  75.83%, tr:  98.98%, tr_best:  99.08%\n",
      "epoch-92  lr=['0.0010000'], tr/val_loss:  0.367953/  1.707927, val:  72.92%, val_best:  75.83%, tr:  98.26%, tr_best:  99.08%\n",
      "epoch-93  lr=['0.0010000'], tr/val_loss:  0.368874/  1.667787, val:  72.08%, val_best:  75.83%, tr:  98.98%, tr_best:  99.08%\n",
      "epoch-94  lr=['0.0010000'], tr/val_loss:  0.365060/  1.681595, val:  74.58%, val_best:  75.83%, tr:  98.88%, tr_best:  99.08%\n",
      "epoch-95  lr=['0.0010000'], tr/val_loss:  0.361291/  1.740701, val:  74.17%, val_best:  75.83%, tr:  98.16%, tr_best:  99.08%\n",
      "epoch-96  lr=['0.0010000'], tr/val_loss:  0.361938/  1.779347, val:  67.92%, val_best:  75.83%, tr:  98.67%, tr_best:  99.08%\n",
      "epoch-97  lr=['0.0010000'], tr/val_loss:  0.371085/  1.662928, val:  73.33%, val_best:  75.83%, tr:  97.24%, tr_best:  99.08%\n",
      "epoch-98  lr=['0.0010000'], tr/val_loss:  0.343872/  1.729346, val:  71.67%, val_best:  75.83%, tr:  99.08%, tr_best:  99.08%\n",
      "epoch-99  lr=['0.0010000'], tr/val_loss:  0.356393/  1.748094, val:  71.67%, val_best:  75.83%, tr:  98.98%, tr_best:  99.08%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "41699f7bed974ce7b3c7457990f91c7a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.006 MB of 0.006 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>iter_acc</td><td>▁▅▃▄▂▅▅▂▃▆▇▇▅▆▅▇█▇▇▇▇▇▆▇███▇▇▇██▇███████</td></tr><tr><td>summary_val_acc</td><td>▁▅▅▆▆▆▅▇▆▇▆▇▆▇▇█▇▇▇▇█▆▇▇█▇█▇█▇▇▇█▇▇█████</td></tr><tr><td>tr_acc</td><td>▁▄▅▅▅▆▆▆▆▆▆▆▇▆▇▇▇▇▇▇▇▇▇▇████████████████</td></tr><tr><td>tr_epoch_loss</td><td>█▆▅▄▄▄▃▃▃▃▃▃▃▃▂▂▂▂▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_acc_best</td><td>▁▅▅▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇████████████████████</td></tr><tr><td>val_acc_now</td><td>▁▅▅▆▆▆▅▇▆▇▆▇▆▇▇█▇▇▇▇█▆▇▇█▇█▇█▇▇▇█▇▇█████</td></tr><tr><td>val_loss</td><td>█▅▃▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▂▂▁▂▂▂▂▃▃▃▃▃▃▃▃▄▄▄▄▄▅▄</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>99</td></tr><tr><td>iter_acc</td><td>1.0</td></tr><tr><td>tr_acc</td><td>0.98979</td></tr><tr><td>tr_epoch_loss</td><td>0.35639</td></tr><tr><td>val_acc_best</td><td>0.75833</td></tr><tr><td>val_acc_now</td><td>0.71667</td></tr><tr><td>val_loss</td><td>1.74809</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">bumbling-sweep-265</strong> at: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/a1qdl35z' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/a1qdl35z</a><br/> View project at: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>/data2/bh_wandb/wandb/run-20250430_092149-a1qdl35z/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require(\"core\")`! See https://wandb.me/wandb-core for more information."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: k5n09lze with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBATCH: 16\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBN_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBPTT_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tDFA_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tIMAGE_SIZE: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tOTTT_input_trace_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tTIME: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tUDA_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \talpha_uda: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbias: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcfg: ['M', 'M', 200, 200]\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tchaching_on: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tconvTrue_fcFalse: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdata_path: /data2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tddp_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdenoise_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdvs_clipping: 5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdvs_duration: 100000\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepoch_num: 100\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \texclude_class: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \textra_train_dataset: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlast_lif: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.001\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_sg_width: 4\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_decay: 0.5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_init: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_reset: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_threshold: 0.75\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmerge_polarities: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmy_seed: 42\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnet_print: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_workers: 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer_what: SGD\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tpin_memory: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tpre_trained: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tpre_trained_path: net_save/save_now_net_weights_{unique_name}.pth\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \trate_coding: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tscheduler_name: no\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsingle_step: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsurrogate: hard_sigmoid\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_conv_kernel_size: 3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_conv_padding: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_conv_stride: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_trace_const1: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_trace_const2: 0.5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \ttdBN_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \ttrace_on: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \twhich_data: DVS_GESTURE_TONIC\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b71047d7868d430ab79876c42b770fdb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.01111292839050293, max=1.0)…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.19.10 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.17.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/data2/bh_wandb/wandb/run-20250430_092754-k5n09lze</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/k5n09lze' target=\"_blank\">twilight-sweep-267</a></strong> to <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/6pj3lh8j' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/6pj3lh8j</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/6pj3lh8j' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/6pj3lh8j</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/k5n09lze' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/k5n09lze</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'single_step' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'my_seed' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'TIME' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BATCH' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'IMAGE_SIZE' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'which_data' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'data_path' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'rate_coding' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_init' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_decay' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_threshold' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_reset' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_sg_width' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_conv_kernel_size' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_conv_stride' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_conv_padding' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_trace_const1' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_trace_const2' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'pre_trained' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'convTrue_fcFalse' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'cfg' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'net_print' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'pre_trained_path' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'learning_rate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'epoch_num' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'tdBN_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BN_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'surrogate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BPTT_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'optimizer_what' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'scheduler_name' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'ddp_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'dvs_clipping' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'dvs_duration' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'DFA_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'trace_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'OTTT_input_trace_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'exclude_class' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'merge_polarities' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'denoise_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'extra_train_dataset' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'num_workers' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'chaching_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'pin_memory' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'UDA_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'alpha_uda' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'bias' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'last_lif' was locked by 'sweep' (ignored update).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "param {'devices': '0', 'single_step': True, 'unique_name': 'main', 'my_seed': 42, 'TIME': 10, 'BATCH': 16, 'IMAGE_SIZE': 128, 'which_data': 'DVS_GESTURE_TONIC', 'data_path': '/data2', 'rate_coding': False, 'lif_layer_v_init': 0, 'lif_layer_v_decay': 0.5, 'lif_layer_v_threshold': 0.75, 'lif_layer_v_reset': 0, 'lif_layer_sg_width': 4, 'synapse_conv_kernel_size': 3, 'synapse_conv_stride': 1, 'synapse_conv_padding': 1, 'synapse_trace_const1': 1, 'synapse_trace_const2': 0.5, 'pre_trained': False, 'convTrue_fcFalse': False, 'cfg': ['M', 'M', 200, 200], 'net_print': True, 'pre_trained_path': 'net_save/save_now_net_weights_{unique_name}.pth', 'learning_rate': 0.001, 'epoch_num': 100, 'tdBN_on': False, 'BN_on': False, 'surrogate': 'hard_sigmoid', 'BPTT_on': False, 'optimizer_what': 'SGD', 'scheduler_name': 'no', 'ddp_on': False, 'dvs_clipping': 5, 'dvs_duration': 100000, 'DFA_on': False, 'trace_on': True, 'OTTT_input_trace_on': False, 'exclude_class': True, 'merge_polarities': False, 'denoise_on': False, 'extra_train_dataset': 0, 'num_workers': 2, 'chaching_on': True, 'pin_memory': True, 'UDA_on': False, 'alpha_uda': 1, 'bias': True, 'last_lif': False, 'current epoch': 0} \n",
      "\n",
      "dataset_hash = ffa516e60c3efd5e0208f72b4c36cb84\n",
      "cache path exists\n",
      "\n",
      "device ==> cuda\n",
      "\n",
      "DataParallel(\n",
      "  (module): REBORN_MY_SNN_FC(\n",
      "    (layers): REBORN_MY_Sequential(\n",
      "      (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (2): DimChanger_for_FC()\n",
      "      (3): SYNAPSE_FC(in_features=2048, out_features=200, TIME=10, bias=True, sstep=True)\n",
      "      (4): LIF_layer(v_init=0, v_decay=0.5, v_threshold=0.75, v_reset=0, sg_width=4, surrogate=hard_sigmoid, BPTT_on=False, trace_const1=1, trace_const2=0.5, TIME=10, sstep=True, trace_on=True)\n",
      "      (5): SYNAPSE_FC(in_features=200, out_features=200, TIME=10, bias=True, sstep=True)\n",
      "      (6): LIF_layer(v_init=0, v_decay=0.5, v_threshold=0.75, v_reset=0, sg_width=4, surrogate=hard_sigmoid, BPTT_on=False, trace_const1=1, trace_const2=0.5, TIME=10, sstep=True, trace_on=True)\n",
      "      (7): SYNAPSE_FC(in_features=200, out_features=10, TIME=10, bias=True, sstep=True)\n",
      "    )\n",
      "  )\n",
      ")\n",
      "\n",
      "========================================================\n",
      "Trainable parameters: 452,010\n",
      "========================================================\n",
      "\n",
      "epoch-0   lr=['0.0010000'], tr/val_loss:  2.305365/  2.302841, val:  10.00%, val_best:  10.00%, tr:   8.17%, tr_best:   8.17%\n",
      "epoch-1   lr=['0.0010000'], tr/val_loss:  2.304994/  2.302639, val:  10.00%, val_best:  10.00%, tr:   7.66%, tr_best:   8.17%\n",
      "epoch-2   lr=['0.0010000'], tr/val_loss:  2.305079/  2.302667, val:  10.00%, val_best:  10.00%, tr:   8.99%, tr_best:   8.99%\n",
      "epoch-3   lr=['0.0010000'], tr/val_loss:  2.304731/  2.302708, val:  10.00%, val_best:  10.00%, tr:   8.38%, tr_best:   8.99%\n",
      "epoch-4   lr=['0.0010000'], tr/val_loss:  2.304833/  2.302682, val:  10.00%, val_best:  10.00%, tr:   7.87%, tr_best:   8.99%\n",
      "epoch-5   lr=['0.0010000'], tr/val_loss:  2.304569/  2.302663, val:  10.00%, val_best:  10.00%, tr:   7.87%, tr_best:   8.99%\n",
      "epoch-6   lr=['0.0010000'], tr/val_loss:  2.305086/  2.302687, val:  10.00%, val_best:  10.00%, tr:   9.70%, tr_best:   9.70%\n",
      "epoch-7   lr=['0.0010000'], tr/val_loss:  2.304632/  2.302694, val:  10.00%, val_best:  10.00%, tr:   7.46%, tr_best:   9.70%\n",
      "epoch-8   lr=['0.0010000'], tr/val_loss:  2.304545/  2.302613, val:  10.00%, val_best:  10.00%, tr:   8.17%, tr_best:   9.70%\n",
      "epoch-9   lr=['0.0010000'], tr/val_loss:  2.305080/  2.302782, val:  10.00%, val_best:  10.00%, tr:   9.19%, tr_best:   9.70%\n",
      "epoch-10  lr=['0.0010000'], tr/val_loss:  2.304688/  2.302772, val:  10.00%, val_best:  10.00%, tr:  10.01%, tr_best:  10.01%\n",
      "epoch-11  lr=['0.0010000'], tr/val_loss:  2.304834/  2.302622, val:  10.00%, val_best:  10.00%, tr:   8.17%, tr_best:  10.01%\n",
      "epoch-12  lr=['0.0010000'], tr/val_loss:  2.304284/  2.302666, val:  10.00%, val_best:  10.00%, tr:   9.50%, tr_best:  10.01%\n",
      "epoch-13  lr=['0.0010000'], tr/val_loss:  2.304813/  2.302634, val:  10.00%, val_best:  10.00%, tr:   9.09%, tr_best:  10.01%\n",
      "epoch-14  lr=['0.0010000'], tr/val_loss:  2.305231/  2.302722, val:  10.00%, val_best:  10.00%, tr:   8.78%, tr_best:  10.01%\n",
      "epoch-15  lr=['0.0010000'], tr/val_loss:  2.305301/  2.302723, val:  10.00%, val_best:  10.00%, tr:   8.38%, tr_best:  10.01%\n",
      "epoch-16  lr=['0.0010000'], tr/val_loss:  2.304772/  2.302634, val:  10.00%, val_best:  10.00%, tr:   8.27%, tr_best:  10.01%\n",
      "epoch-17  lr=['0.0010000'], tr/val_loss:  2.303716/  2.302659, val:  10.00%, val_best:  10.00%, tr:  10.01%, tr_best:  10.01%\n",
      "epoch-18  lr=['0.0010000'], tr/val_loss:  2.304624/  2.302669, val:  10.00%, val_best:  10.00%, tr:   9.30%, tr_best:  10.01%\n",
      "epoch-19  lr=['0.0010000'], tr/val_loss:  2.305880/  2.302768, val:  10.00%, val_best:  10.00%, tr:   8.48%, tr_best:  10.01%\n",
      "epoch-20  lr=['0.0010000'], tr/val_loss:  2.305082/  2.302727, val:  10.00%, val_best:  10.00%, tr:   9.60%, tr_best:  10.01%\n",
      "epoch-21  lr=['0.0010000'], tr/val_loss:  2.304254/  2.301517, val:  10.42%, val_best:  10.42%, tr:   9.91%, tr_best:  10.01%\n",
      "epoch-22  lr=['0.0010000'], tr/val_loss:  2.288673/  2.260418, val:  10.42%, val_best:  10.42%, tr:  13.18%, tr_best:  13.18%\n",
      "epoch-23  lr=['0.0010000'], tr/val_loss:  2.203691/  2.182794, val:  21.25%, val_best:  21.25%, tr:  18.69%, tr_best:  18.69%\n",
      "epoch-24  lr=['0.0010000'], tr/val_loss:  2.111111/  2.098608, val:  27.92%, val_best:  27.92%, tr:  25.03%, tr_best:  25.03%\n",
      "epoch-25  lr=['0.0010000'], tr/val_loss:  1.981219/  1.974401, val:  30.00%, val_best:  30.00%, tr:  28.29%, tr_best:  28.29%\n",
      "epoch-26  lr=['0.0010000'], tr/val_loss:  1.826150/  1.862731, val:  38.33%, val_best:  38.33%, tr:  34.83%, tr_best:  34.83%\n",
      "epoch-27  lr=['0.0010000'], tr/val_loss:  1.673866/  1.753483, val:  44.58%, val_best:  44.58%, tr:  43.82%, tr_best:  43.82%\n",
      "epoch-28  lr=['0.0010000'], tr/val_loss:  1.527385/  1.580629, val:  57.08%, val_best:  57.08%, tr:  55.26%, tr_best:  55.26%\n",
      "epoch-29  lr=['0.0010000'], tr/val_loss:  1.372502/  1.490708, val:  55.83%, val_best:  57.08%, tr:  55.77%, tr_best:  55.77%\n",
      "epoch-30  lr=['0.0010000'], tr/val_loss:  1.261319/  1.416897, val:  57.92%, val_best:  57.92%, tr:  60.57%, tr_best:  60.57%\n",
      "epoch-31  lr=['0.0010000'], tr/val_loss:  1.168113/  1.410117, val:  55.42%, val_best:  57.92%, tr:  63.43%, tr_best:  63.43%\n",
      "epoch-32  lr=['0.0010000'], tr/val_loss:  1.100346/  1.384131, val:  59.17%, val_best:  59.17%, tr:  65.47%, tr_best:  65.47%\n",
      "epoch-33  lr=['0.0010000'], tr/val_loss:  1.035397/  1.406119, val:  57.92%, val_best:  59.17%, tr:  68.03%, tr_best:  68.03%\n",
      "epoch-34  lr=['0.0010000'], tr/val_loss:  0.962865/  1.385560, val:  59.17%, val_best:  59.17%, tr:  68.85%, tr_best:  68.85%\n",
      "epoch-35  lr=['0.0010000'], tr/val_loss:  0.905129/  1.369740, val:  61.67%, val_best:  61.67%, tr:  70.07%, tr_best:  70.07%\n",
      "epoch-36  lr=['0.0010000'], tr/val_loss:  0.852197/  1.375322, val:  63.75%, val_best:  63.75%, tr:  74.57%, tr_best:  74.57%\n",
      "epoch-37  lr=['0.0010000'], tr/val_loss:  0.847282/  1.458853, val:  58.75%, val_best:  63.75%, tr:  73.34%, tr_best:  74.57%\n",
      "epoch-38  lr=['0.0010000'], tr/val_loss:  0.791986/  1.445415, val:  59.58%, val_best:  63.75%, tr:  76.71%, tr_best:  76.71%\n",
      "epoch-39  lr=['0.0010000'], tr/val_loss:  0.744918/  1.465026, val:  62.92%, val_best:  63.75%, tr:  75.89%, tr_best:  76.71%\n",
      "epoch-40  lr=['0.0010000'], tr/val_loss:  0.720116/  1.475227, val:  61.25%, val_best:  63.75%, tr:  77.43%, tr_best:  77.43%\n",
      "epoch-41  lr=['0.0010000'], tr/val_loss:  0.685382/  1.557409, val:  60.83%, val_best:  63.75%, tr:  78.96%, tr_best:  78.96%\n",
      "epoch-42  lr=['0.0010000'], tr/val_loss:  0.628516/  1.471498, val:  63.75%, val_best:  63.75%, tr:  81.82%, tr_best:  81.82%\n",
      "epoch-43  lr=['0.0010000'], tr/val_loss:  0.623087/  1.546668, val:  65.83%, val_best:  65.83%, tr:  81.41%, tr_best:  81.82%\n",
      "epoch-44  lr=['0.0010000'], tr/val_loss:  0.594505/  1.629656, val:  59.17%, val_best:  65.83%, tr:  81.82%, tr_best:  81.82%\n",
      "epoch-45  lr=['0.0010000'], tr/val_loss:  0.548538/  1.595229, val:  65.83%, val_best:  65.83%, tr:  84.27%, tr_best:  84.27%\n",
      "epoch-46  lr=['0.0010000'], tr/val_loss:  0.520244/  1.617166, val:  70.00%, val_best:  70.00%, tr:  84.37%, tr_best:  84.37%\n",
      "epoch-47  lr=['0.0010000'], tr/val_loss:  0.509828/  1.712841, val:  67.08%, val_best:  70.00%, tr:  86.93%, tr_best:  86.93%\n",
      "epoch-48  lr=['0.0010000'], tr/val_loss:  0.499363/  1.686048, val:  64.58%, val_best:  70.00%, tr:  88.05%, tr_best:  88.05%\n",
      "epoch-49  lr=['0.0010000'], tr/val_loss:  0.470483/  1.723797, val:  73.33%, val_best:  73.33%, tr:  89.79%, tr_best:  89.79%\n",
      "epoch-50  lr=['0.0010000'], tr/val_loss:  0.434213/  1.772505, val:  65.42%, val_best:  73.33%, tr:  91.93%, tr_best:  91.93%\n",
      "epoch-51  lr=['0.0010000'], tr/val_loss:  0.421624/  1.755268, val:  69.58%, val_best:  73.33%, tr:  90.91%, tr_best:  91.93%\n",
      "epoch-52  lr=['0.0010000'], tr/val_loss:  0.379255/  1.846967, val:  71.67%, val_best:  73.33%, tr:  93.26%, tr_best:  93.26%\n",
      "epoch-53  lr=['0.0010000'], tr/val_loss:  0.350949/  1.876170, val:  69.17%, val_best:  73.33%, tr:  95.61%, tr_best:  95.61%\n",
      "epoch-54  lr=['0.0010000'], tr/val_loss:  0.330818/  1.949607, val:  70.83%, val_best:  73.33%, tr:  96.32%, tr_best:  96.32%\n",
      "epoch-55  lr=['0.0010000'], tr/val_loss:  0.326976/  2.007905, val:  71.67%, val_best:  73.33%, tr:  95.20%, tr_best:  96.32%\n",
      "epoch-56  lr=['0.0010000'], tr/val_loss:  0.322913/  2.016722, val:  75.00%, val_best:  75.00%, tr:  97.55%, tr_best:  97.55%\n",
      "epoch-57  lr=['0.0010000'], tr/val_loss:  0.295511/  2.034192, val:  70.00%, val_best:  75.00%, tr:  96.32%, tr_best:  97.55%\n",
      "epoch-58  lr=['0.0010000'], tr/val_loss:  0.272474/  2.032138, val:  69.17%, val_best:  75.00%, tr:  97.04%, tr_best:  97.55%\n",
      "epoch-59  lr=['0.0010000'], tr/val_loss:  0.260154/  2.113172, val:  68.75%, val_best:  75.00%, tr:  98.47%, tr_best:  98.47%\n",
      "epoch-60  lr=['0.0010000'], tr/val_loss:  0.233469/  2.150723, val:  70.00%, val_best:  75.00%, tr:  98.77%, tr_best:  98.77%\n",
      "epoch-61  lr=['0.0010000'], tr/val_loss:  0.236894/  2.258943, val:  68.75%, val_best:  75.00%, tr:  99.59%, tr_best:  99.59%\n",
      "epoch-62  lr=['0.0010000'], tr/val_loss:  0.207488/  2.290641, val:  70.83%, val_best:  75.00%, tr:  99.69%, tr_best:  99.69%\n",
      "epoch-63  lr=['0.0010000'], tr/val_loss:  0.197155/  2.219427, val:  70.83%, val_best:  75.00%, tr:  99.59%, tr_best:  99.69%\n",
      "epoch-64  lr=['0.0010000'], tr/val_loss:  0.228095/  2.215579, val:  71.67%, val_best:  75.00%, tr:  98.06%, tr_best:  99.69%\n",
      "epoch-65  lr=['0.0010000'], tr/val_loss:  0.168089/  2.329436, val:  70.42%, val_best:  75.00%, tr:  99.80%, tr_best:  99.80%\n",
      "epoch-66  lr=['0.0010000'], tr/val_loss:  0.145179/  2.316641, val:  71.67%, val_best:  75.00%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-67  lr=['0.0010000'], tr/val_loss:  0.146658/  2.397222, val:  72.50%, val_best:  75.00%, tr:  99.80%, tr_best: 100.00%\n",
      "epoch-68  lr=['0.0010000'], tr/val_loss:  0.136890/  2.453565, val:  70.00%, val_best:  75.00%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-69  lr=['0.0010000'], tr/val_loss:  0.115327/  2.520828, val:  72.50%, val_best:  75.00%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-70  lr=['0.0010000'], tr/val_loss:  0.101343/  2.524369, val:  71.67%, val_best:  75.00%, tr:  99.90%, tr_best: 100.00%\n",
      "epoch-71  lr=['0.0010000'], tr/val_loss:  0.092939/  2.500799, val:  75.00%, val_best:  75.00%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-72  lr=['0.0010000'], tr/val_loss:  0.090610/  2.575087, val:  73.75%, val_best:  75.00%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-73  lr=['0.0010000'], tr/val_loss:  0.098331/  2.552742, val:  73.33%, val_best:  75.00%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-74  lr=['0.0010000'], tr/val_loss:  0.091592/  2.543524, val:  72.92%, val_best:  75.00%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-75  lr=['0.0010000'], tr/val_loss:  0.075275/  2.623063, val:  71.25%, val_best:  75.00%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-76  lr=['0.0010000'], tr/val_loss:  0.063562/  2.691905, val:  72.08%, val_best:  75.00%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-77  lr=['0.0010000'], tr/val_loss:  0.069125/  2.684309, val:  71.67%, val_best:  75.00%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-78  lr=['0.0010000'], tr/val_loss:  0.055323/  2.767101, val:  73.33%, val_best:  75.00%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-79  lr=['0.0010000'], tr/val_loss:  0.066768/  2.709724, val:  72.08%, val_best:  75.00%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-80  lr=['0.0010000'], tr/val_loss:  0.052304/  2.693866, val:  72.92%, val_best:  75.00%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-81  lr=['0.0010000'], tr/val_loss:  0.044177/  2.809050, val:  73.33%, val_best:  75.00%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-82  lr=['0.0010000'], tr/val_loss:  0.047482/  2.886943, val:  72.92%, val_best:  75.00%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-83  lr=['0.0010000'], tr/val_loss:  0.057937/  2.922480, val:  71.25%, val_best:  75.00%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-84  lr=['0.0010000'], tr/val_loss:  0.050336/  2.882087, val:  71.25%, val_best:  75.00%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-85  lr=['0.0010000'], tr/val_loss:  0.081126/  2.863017, val:  74.58%, val_best:  75.00%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-86  lr=['0.0010000'], tr/val_loss:  0.073970/  2.871922, val:  75.00%, val_best:  75.00%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-87  lr=['0.0010000'], tr/val_loss:  0.053747/  2.845538, val:  75.42%, val_best:  75.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-88  lr=['0.0010000'], tr/val_loss:  0.032694/  2.929825, val:  74.58%, val_best:  75.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-89  lr=['0.0010000'], tr/val_loss:  0.030289/  2.879163, val:  72.08%, val_best:  75.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-90  lr=['0.0010000'], tr/val_loss:  0.030561/  2.903164, val:  75.00%, val_best:  75.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-91  lr=['0.0010000'], tr/val_loss:  0.026602/  2.965892, val:  75.83%, val_best:  75.83%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-92  lr=['0.0010000'], tr/val_loss:  0.020696/  2.953660, val:  75.00%, val_best:  75.83%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-93  lr=['0.0010000'], tr/val_loss:  0.021481/  2.949029, val:  75.42%, val_best:  75.83%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-94  lr=['0.0010000'], tr/val_loss:  0.022689/  2.941777, val:  74.17%, val_best:  75.83%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-95  lr=['0.0010000'], tr/val_loss:  0.017259/  3.016999, val:  73.75%, val_best:  75.83%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-96  lr=['0.0010000'], tr/val_loss:  0.014881/  2.990945, val:  75.00%, val_best:  75.83%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-97  lr=['0.0010000'], tr/val_loss:  0.017263/  3.062665, val:  74.58%, val_best:  75.83%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-98  lr=['0.0010000'], tr/val_loss:  0.011898/  3.004778, val:  73.75%, val_best:  75.83%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-99  lr=['0.0010000'], tr/val_loss:  0.010760/  3.060306, val:  74.17%, val_best:  75.83%, tr: 100.00%, tr_best: 100.00%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c5cfd3e6a3574903b92144d180f7418d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.006 MB of 0.006 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>iter_acc</td><td>▁▂▁▁▁▁▁▁▁▂▄▅▅▅▅▆▇▆█▇████████████████████</td></tr><tr><td>summary_val_acc</td><td>▁▁▁▁▁▁▁▁▁▁▃▄▆▆▇▆▇▇▆▇███▇▇▇▇█████████████</td></tr><tr><td>tr_acc</td><td>▁▁▁▁▁▁▁▁▁▁▂▃▅▅▆▆▆▇▇▇▇▇██████████████████</td></tr><tr><td>tr_epoch_loss</td><td>██████████▇▇▅▄▄▄▃▃▃▃▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_acc_best</td><td>▁▁▁▁▁▁▁▁▁▁▃▄▆▆▆▇▇▇▇▇████████████████████</td></tr><tr><td>val_acc_now</td><td>▁▁▁▁▁▁▁▁▁▁▃▄▆▆▇▆▇▇▆▇███▇▇▇▇█████████████</td></tr><tr><td>val_loss</td><td>▅▅▅▅▅▅▅▅▅▅▄▃▂▁▁▁▁▁▂▂▂▃▃▄▄▅▅▅▆▆▆▆▇▇▇▇▇███</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>99</td></tr><tr><td>iter_acc</td><td>1.0</td></tr><tr><td>tr_acc</td><td>1.0</td></tr><tr><td>tr_epoch_loss</td><td>0.01076</td></tr><tr><td>val_acc_best</td><td>0.75833</td></tr><tr><td>val_acc_now</td><td>0.74167</td></tr><tr><td>val_loss</td><td>3.06031</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">twilight-sweep-267</strong> at: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/k5n09lze' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/k5n09lze</a><br/> View project at: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>/data2/bh_wandb/wandb/run-20250430_092754-k5n09lze/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require(\"core\")`! See https://wandb.me/wandb-core for more information."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: xdqwxepd with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBATCH: 16\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBN_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBPTT_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tDFA_on: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tIMAGE_SIZE: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tOTTT_input_trace_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tTIME: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tUDA_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \talpha_uda: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbias: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcfg: ['M', 'M', 200, 200]\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tchaching_on: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tconvTrue_fcFalse: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdata_path: /data2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tddp_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdenoise_on: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdvs_clipping: 5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdvs_duration: 100000\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepoch_num: 100\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \texclude_class: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \textra_train_dataset: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlast_lif: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.01\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_sg_width: 3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_decay: 0.5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_init: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_reset: 10000\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_threshold: 0.5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmerge_polarities: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmy_seed: 42\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnet_print: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_workers: 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer_what: SGD\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tpin_memory: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tpre_trained: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tpre_trained_path: net_save/save_now_net_weights_{unique_name}.pth\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \trate_coding: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tscheduler_name: no\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsingle_step: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsurrogate: hard_sigmoid\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_conv_kernel_size: 3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_conv_padding: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_conv_stride: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_trace_const1: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_trace_const2: 0.5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \ttdBN_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \ttrace_on: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \twhich_data: DVS_GESTURE_TONIC\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.19.10 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.17.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/data2/bh_wandb/wandb/run-20250430_093353-xdqwxepd</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/xdqwxepd' target=\"_blank\">unique-sweep-269</a></strong> to <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/6pj3lh8j' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/6pj3lh8j</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/6pj3lh8j' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/6pj3lh8j</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/xdqwxepd' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/xdqwxepd</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'single_step' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'my_seed' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'TIME' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BATCH' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'IMAGE_SIZE' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'which_data' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'data_path' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'rate_coding' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_init' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_decay' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_threshold' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_reset' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_sg_width' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_conv_kernel_size' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_conv_stride' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_conv_padding' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_trace_const1' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_trace_const2' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'pre_trained' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'convTrue_fcFalse' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'cfg' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'net_print' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'pre_trained_path' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'learning_rate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'epoch_num' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'tdBN_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BN_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'surrogate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BPTT_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'optimizer_what' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'scheduler_name' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'ddp_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'dvs_clipping' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'dvs_duration' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'DFA_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'trace_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'OTTT_input_trace_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'exclude_class' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'merge_polarities' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'denoise_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'extra_train_dataset' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'num_workers' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'chaching_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'pin_memory' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'UDA_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'alpha_uda' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'bias' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'last_lif' was locked by 'sweep' (ignored update).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "param {'devices': '0', 'single_step': True, 'unique_name': 'main', 'my_seed': 42, 'TIME': 10, 'BATCH': 16, 'IMAGE_SIZE': 128, 'which_data': 'DVS_GESTURE_TONIC', 'data_path': '/data2', 'rate_coding': False, 'lif_layer_v_init': 0, 'lif_layer_v_decay': 0.5, 'lif_layer_v_threshold': 0.5, 'lif_layer_v_reset': 10000, 'lif_layer_sg_width': 3, 'synapse_conv_kernel_size': 3, 'synapse_conv_stride': 1, 'synapse_conv_padding': 1, 'synapse_trace_const1': 1, 'synapse_trace_const2': 0.5, 'pre_trained': False, 'convTrue_fcFalse': False, 'cfg': ['M', 'M', 200, 200], 'net_print': True, 'pre_trained_path': 'net_save/save_now_net_weights_{unique_name}.pth', 'learning_rate': 0.01, 'epoch_num': 100, 'tdBN_on': False, 'BN_on': False, 'surrogate': 'hard_sigmoid', 'BPTT_on': False, 'optimizer_what': 'SGD', 'scheduler_name': 'no', 'ddp_on': False, 'dvs_clipping': 5, 'dvs_duration': 100000, 'DFA_on': True, 'trace_on': True, 'OTTT_input_trace_on': False, 'exclude_class': True, 'merge_polarities': False, 'denoise_on': True, 'extra_train_dataset': 0, 'num_workers': 2, 'chaching_on': True, 'pin_memory': True, 'UDA_on': False, 'alpha_uda': 1, 'bias': True, 'last_lif': False, 'current epoch': 0} \n",
      "\n",
      "dataset_hash = 63cc597115630ec173f3099200061e53\n",
      "cache path exists\n",
      "\n",
      "device ==> cuda\n",
      "\n",
      "DataParallel(\n",
      "  (module): REBORN_MY_SNN_FC(\n",
      "    (layers): REBORN_MY_Sequential(\n",
      "      (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (2): DimChanger_for_FC()\n",
      "      (3): SYNAPSE_FC(in_features=2048, out_features=200, TIME=10, bias=True, sstep=True)\n",
      "      (4): LIF_layer(v_init=0, v_decay=0.5, v_threshold=0.5, v_reset=10000, sg_width=3, surrogate=hard_sigmoid, BPTT_on=False, trace_const1=1, trace_const2=0.5, TIME=10, sstep=True, trace_on=True)\n",
      "      (5): Feedback_Receiver()\n",
      "      (6): SYNAPSE_FC(in_features=200, out_features=200, TIME=10, bias=True, sstep=True)\n",
      "      (7): LIF_layer(v_init=0, v_decay=0.5, v_threshold=0.5, v_reset=10000, sg_width=3, surrogate=hard_sigmoid, BPTT_on=False, trace_const1=1, trace_const2=0.5, TIME=10, sstep=True, trace_on=True)\n",
      "      (8): Feedback_Receiver()\n",
      "      (9): SYNAPSE_FC(in_features=200, out_features=10, TIME=10, bias=True, sstep=True)\n",
      "      (DFA_top): Top_Gradient()\n",
      "    )\n",
      "  )\n",
      ")\n",
      "\n",
      "========================================================\n",
      "Trainable parameters: 452,010\n",
      "========================================================\n",
      "\n",
      "epoch-0   lr=['0.0100000'], tr/val_loss:  2.648062/  4.935438, val:  32.92%, val_best:  32.92%, tr:  34.53%, tr_best:  34.53%\n",
      "[module.layers.5] weight_fb parameter count: 2,000\n",
      "[module.layers.8] weight_fb parameter count: 2,000\n",
      "epoch-1   lr=['0.0100000'], tr/val_loss:  3.960945/  5.212952, val:  47.08%, val_best:  47.08%, tr:  49.23%, tr_best:  49.23%\n",
      "epoch-2   lr=['0.0100000'], tr/val_loss:  4.936850/  6.058369, val:  40.42%, val_best:  47.08%, tr:  53.63%, tr_best:  53.63%\n",
      "epoch-3   lr=['0.0100000'], tr/val_loss:  4.378198/  5.843860, val:  47.92%, val_best:  47.92%, tr:  58.73%, tr_best:  58.73%\n",
      "epoch-4   lr=['0.0100000'], tr/val_loss:  4.357286/  3.430661, val:  62.92%, val_best:  62.92%, tr:  59.96%, tr_best:  59.96%\n",
      "epoch-5   lr=['0.0100000'], tr/val_loss:  3.349790/  5.949613, val:  50.42%, val_best:  62.92%, tr:  63.53%, tr_best:  63.53%\n",
      "epoch-6   lr=['0.0100000'], tr/val_loss:  2.795092/  5.125896, val:  57.08%, val_best:  62.92%, tr:  68.85%, tr_best:  68.85%\n",
      "epoch-7   lr=['0.0100000'], tr/val_loss:  2.313716/  5.959054, val:  44.17%, val_best:  62.92%, tr:  72.63%, tr_best:  72.63%\n",
      "epoch-8   lr=['0.0100000'], tr/val_loss:  2.367564/  3.875181, val:  63.33%, val_best:  63.33%, tr:  75.69%, tr_best:  75.69%\n",
      "epoch-9   lr=['0.0100000'], tr/val_loss:  2.021383/  5.324935, val:  59.17%, val_best:  63.33%, tr:  81.41%, tr_best:  81.41%\n",
      "epoch-10  lr=['0.0100000'], tr/val_loss:  1.947229/  4.686835, val:  61.67%, val_best:  63.33%, tr:  83.55%, tr_best:  83.55%\n",
      "epoch-11  lr=['0.0100000'], tr/val_loss:  1.539145/  5.549806, val:  58.33%, val_best:  63.33%, tr:  87.44%, tr_best:  87.44%\n",
      "epoch-12  lr=['0.0100000'], tr/val_loss:  2.121491/  4.761245, val:  69.58%, val_best:  69.58%, tr:  83.55%, tr_best:  87.44%\n",
      "epoch-13  lr=['0.0100000'], tr/val_loss:  1.599109/  6.208050, val:  60.83%, val_best:  69.58%, tr:  89.68%, tr_best:  89.68%\n",
      "epoch-14  lr=['0.0100000'], tr/val_loss:  1.689168/  6.215614, val:  63.75%, val_best:  69.58%, tr:  88.87%, tr_best:  89.68%\n",
      "epoch-15  lr=['0.0100000'], tr/val_loss:  1.372794/  6.581932, val:  66.67%, val_best:  69.58%, tr:  93.16%, tr_best:  93.16%\n",
      "epoch-16  lr=['0.0100000'], tr/val_loss:  1.261778/  6.771264, val:  65.00%, val_best:  69.58%, tr:  94.38%, tr_best:  94.38%\n",
      "epoch-17  lr=['0.0100000'], tr/val_loss:  1.103896/  5.651435, val:  76.25%, val_best:  76.25%, tr:  95.30%, tr_best:  95.30%\n",
      "epoch-18  lr=['0.0100000'], tr/val_loss:  0.808896/  6.630534, val:  67.92%, val_best:  76.25%, tr:  98.47%, tr_best:  98.47%\n",
      "epoch-19  lr=['0.0100000'], tr/val_loss:  0.839144/  6.331837, val:  71.67%, val_best:  76.25%, tr:  98.16%, tr_best:  98.47%\n",
      "epoch-20  lr=['0.0100000'], tr/val_loss:  0.740876/  7.119711, val:  67.92%, val_best:  76.25%, tr:  98.47%, tr_best:  98.47%\n",
      "epoch-21  lr=['0.0100000'], tr/val_loss:  0.733825/  6.765487, val:  69.58%, val_best:  76.25%, tr:  98.98%, tr_best:  98.98%\n",
      "epoch-22  lr=['0.0100000'], tr/val_loss:  0.552519/  6.533110, val:  76.67%, val_best:  76.67%, tr:  99.59%, tr_best:  99.59%\n",
      "epoch-23  lr=['0.0100000'], tr/val_loss:  0.450852/  6.774521, val:  72.08%, val_best:  76.67%, tr:  99.59%, tr_best:  99.59%\n",
      "epoch-24  lr=['0.0100000'], tr/val_loss:  0.390119/  6.932608, val:  73.75%, val_best:  76.67%, tr:  99.80%, tr_best:  99.80%\n",
      "epoch-25  lr=['0.0100000'], tr/val_loss:  0.514303/  7.136387, val:  75.42%, val_best:  76.67%, tr:  98.88%, tr_best:  99.80%\n",
      "epoch-26  lr=['0.0100000'], tr/val_loss:  0.439790/  7.264198, val:  73.75%, val_best:  76.67%, tr:  99.69%, tr_best:  99.80%\n",
      "epoch-27  lr=['0.0100000'], tr/val_loss:  0.386452/  7.739116, val:  75.83%, val_best:  76.67%, tr:  99.69%, tr_best:  99.80%\n",
      "epoch-28  lr=['0.0100000'], tr/val_loss:  0.298554/  7.396742, val:  75.42%, val_best:  76.67%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-29  lr=['0.0100000'], tr/val_loss:  0.251917/  7.965137, val:  75.00%, val_best:  76.67%, tr:  99.80%, tr_best: 100.00%\n",
      "epoch-30  lr=['0.0100000'], tr/val_loss:  0.230532/  7.767497, val:  75.83%, val_best:  76.67%, tr:  99.90%, tr_best: 100.00%\n",
      "epoch-31  lr=['0.0100000'], tr/val_loss:  0.248624/  8.232787, val:  75.42%, val_best:  76.67%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-32  lr=['0.0100000'], tr/val_loss:  0.258331/  8.167401, val:  74.58%, val_best:  76.67%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-33  lr=['0.0100000'], tr/val_loss:  0.259124/  8.426826, val:  73.75%, val_best:  76.67%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-34  lr=['0.0100000'], tr/val_loss:  0.207789/  8.611460, val:  75.42%, val_best:  76.67%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-35  lr=['0.0100000'], tr/val_loss:  0.206812/  8.568155, val:  79.17%, val_best:  79.17%, tr:  99.80%, tr_best: 100.00%\n",
      "epoch-36  lr=['0.0100000'], tr/val_loss:  0.173830/  8.336071, val:  78.75%, val_best:  79.17%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-37  lr=['0.0100000'], tr/val_loss:  0.184163/  9.101256, val:  76.25%, val_best:  79.17%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-38  lr=['0.0100000'], tr/val_loss:  0.164403/  9.056598, val:  75.00%, val_best:  79.17%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-39  lr=['0.0100000'], tr/val_loss:  0.170713/  8.948919, val:  77.08%, val_best:  79.17%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-40  lr=['0.0100000'], tr/val_loss:  0.128668/  9.569807, val:  73.75%, val_best:  79.17%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-41  lr=['0.0100000'], tr/val_loss:  0.117298/  9.618271, val:  73.75%, val_best:  79.17%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-42  lr=['0.0100000'], tr/val_loss:  0.087296/  9.193091, val:  78.75%, val_best:  79.17%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-43  lr=['0.0100000'], tr/val_loss:  0.108766/  9.634612, val:  78.33%, val_best:  79.17%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-44  lr=['0.0100000'], tr/val_loss:  0.095960/  9.405758, val:  77.08%, val_best:  79.17%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-45  lr=['0.0100000'], tr/val_loss:  0.109199/  9.226622, val:  77.92%, val_best:  79.17%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-46  lr=['0.0100000'], tr/val_loss:  0.102328/  9.243918, val:  77.08%, val_best:  79.17%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-47  lr=['0.0100000'], tr/val_loss:  0.102048/  9.572352, val:  76.25%, val_best:  79.17%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-48  lr=['0.0100000'], tr/val_loss:  0.097732/  9.660964, val:  78.33%, val_best:  79.17%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-49  lr=['0.0100000'], tr/val_loss:  0.092208/  9.562099, val:  77.92%, val_best:  79.17%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-50  lr=['0.0100000'], tr/val_loss:  0.102831/ 10.108727, val:  75.83%, val_best:  79.17%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-51  lr=['0.0100000'], tr/val_loss:  0.086680/ 10.050135, val:  76.25%, val_best:  79.17%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-52  lr=['0.0100000'], tr/val_loss:  0.089503/  9.876634, val:  77.08%, val_best:  79.17%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-53  lr=['0.0100000'], tr/val_loss:  0.076799/ 10.227845, val:  76.25%, val_best:  79.17%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-54  lr=['0.0100000'], tr/val_loss:  0.091615/ 10.085129, val:  76.25%, val_best:  79.17%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-55  lr=['0.0100000'], tr/val_loss:  0.078139/  9.927918, val:  76.67%, val_best:  79.17%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-56  lr=['0.0100000'], tr/val_loss:  0.065514/ 10.416179, val:  75.42%, val_best:  79.17%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-57  lr=['0.0100000'], tr/val_loss:  0.051524/ 10.234449, val:  77.92%, val_best:  79.17%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-58  lr=['0.0100000'], tr/val_loss:  0.049709/ 10.322612, val:  76.67%, val_best:  79.17%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-59  lr=['0.0100000'], tr/val_loss:  0.066644/ 10.482938, val:  77.08%, val_best:  79.17%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-60  lr=['0.0100000'], tr/val_loss:  0.050837/ 10.285621, val:  76.25%, val_best:  79.17%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-61  lr=['0.0100000'], tr/val_loss:  0.052625/ 10.280261, val:  76.67%, val_best:  79.17%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-62  lr=['0.0100000'], tr/val_loss:  0.056820/ 10.434179, val:  77.92%, val_best:  79.17%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-63  lr=['0.0100000'], tr/val_loss:  0.072016/ 10.575475, val:  75.00%, val_best:  79.17%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-64  lr=['0.0100000'], tr/val_loss:  0.049530/ 10.506165, val:  78.33%, val_best:  79.17%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-65  lr=['0.0100000'], tr/val_loss:  0.036696/ 10.595228, val:  76.67%, val_best:  79.17%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-66  lr=['0.0100000'], tr/val_loss:  0.075745/ 10.588161, val:  76.25%, val_best:  79.17%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-67  lr=['0.0100000'], tr/val_loss:  0.039611/ 10.622502, val:  79.58%, val_best:  79.58%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-68  lr=['0.0100000'], tr/val_loss:  0.047573/ 10.747025, val:  78.33%, val_best:  79.58%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-69  lr=['0.0100000'], tr/val_loss:  0.039665/ 10.623846, val:  79.17%, val_best:  79.58%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-70  lr=['0.0100000'], tr/val_loss:  0.057672/ 10.618272, val:  78.75%, val_best:  79.58%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-71  lr=['0.0100000'], tr/val_loss:  0.067825/ 10.933925, val:  77.50%, val_best:  79.58%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-72  lr=['0.0100000'], tr/val_loss:  0.098610/ 11.017079, val:  75.42%, val_best:  79.58%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-73  lr=['0.0100000'], tr/val_loss:  0.055480/ 10.912909, val:  77.50%, val_best:  79.58%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-74  lr=['0.0100000'], tr/val_loss:  0.041695/ 11.121871, val:  76.67%, val_best:  79.58%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-75  lr=['0.0100000'], tr/val_loss:  0.039789/ 10.788037, val:  77.92%, val_best:  79.58%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-76  lr=['0.0100000'], tr/val_loss:  0.035052/ 11.256669, val:  78.33%, val_best:  79.58%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-77  lr=['0.0100000'], tr/val_loss:  0.037636/ 10.898698, val:  77.92%, val_best:  79.58%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-78  lr=['0.0100000'], tr/val_loss:  0.031221/ 10.839951, val:  78.33%, val_best:  79.58%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-79  lr=['0.0100000'], tr/val_loss:  0.022864/ 10.753204, val:  80.42%, val_best:  80.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-80  lr=['0.0100000'], tr/val_loss:  0.032975/ 11.107567, val:  77.50%, val_best:  80.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-81  lr=['0.0100000'], tr/val_loss:  0.026244/ 11.216529, val:  77.92%, val_best:  80.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-82  lr=['0.0100000'], tr/val_loss:  0.032857/ 11.150466, val:  77.08%, val_best:  80.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-83  lr=['0.0100000'], tr/val_loss:  0.024448/ 11.171197, val:  78.33%, val_best:  80.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-84  lr=['0.0100000'], tr/val_loss:  0.034984/ 11.037858, val:  74.58%, val_best:  80.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-85  lr=['0.0100000'], tr/val_loss:  0.025107/ 11.091256, val:  76.67%, val_best:  80.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-86  lr=['0.0100000'], tr/val_loss:  0.030364/ 11.445452, val:  77.50%, val_best:  80.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-87  lr=['0.0100000'], tr/val_loss:  0.024280/ 11.411337, val:  79.58%, val_best:  80.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-88  lr=['0.0100000'], tr/val_loss:  0.010725/ 11.486571, val:  79.17%, val_best:  80.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-89  lr=['0.0100000'], tr/val_loss:  0.014039/ 11.342830, val:  79.17%, val_best:  80.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-90  lr=['0.0100000'], tr/val_loss:  0.017130/ 11.400306, val:  78.33%, val_best:  80.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-91  lr=['0.0100000'], tr/val_loss:  0.017728/ 11.530011, val:  77.08%, val_best:  80.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-92  lr=['0.0100000'], tr/val_loss:  0.015358/ 11.504789, val:  75.83%, val_best:  80.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-93  lr=['0.0100000'], tr/val_loss:  0.023274/ 11.665322, val:  76.25%, val_best:  80.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-94  lr=['0.0100000'], tr/val_loss:  0.024478/ 11.448070, val:  77.08%, val_best:  80.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-95  lr=['0.0100000'], tr/val_loss:  0.017264/ 11.592998, val:  76.67%, val_best:  80.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-96  lr=['0.0100000'], tr/val_loss:  0.014176/ 11.629991, val:  75.83%, val_best:  80.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-97  lr=['0.0100000'], tr/val_loss:  0.017076/ 11.668935, val:  76.25%, val_best:  80.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-98  lr=['0.0100000'], tr/val_loss:  0.021388/ 11.523643, val:  77.08%, val_best:  80.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-99  lr=['0.0100000'], tr/val_loss:  0.018635/ 11.635416, val:  77.08%, val_best:  80.42%, tr: 100.00%, tr_best: 100.00%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0d4ddab69f3d48aa94ac266ba02ebec4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.006 MB of 0.006 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>iter_acc</td><td>▁▅▅▅▆▇██████████████████████████████████</td></tr><tr><td>summary_val_acc</td><td>▁▂▅▃▅▆▆▇▇▆▇▇▇▇█▇███▇██▇██▇▇██▇████▇██▇▇▇</td></tr><tr><td>tr_acc</td><td>▁▃▄▅▆▆▇▇████████████████████████████████</td></tr><tr><td>tr_epoch_loss</td><td>▅█▇▄▄▄▃▃▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_acc_best</td><td>▁▃▅▅▅▆▆▇▇▇▇▇▇▇██████████████████████████</td></tr><tr><td>val_acc_now</td><td>▁▂▅▃▅▆▆▇▇▆▇▇▇▇█▇███▇██▇██▇▇██▇████▇██▇▇▇</td></tr><tr><td>val_loss</td><td>▂▃▁▃▃▂▃▃▃▄▄▄▅▅▅▆▆▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇█▇█████</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>99</td></tr><tr><td>iter_acc</td><td>1.0</td></tr><tr><td>tr_acc</td><td>1.0</td></tr><tr><td>tr_epoch_loss</td><td>0.01863</td></tr><tr><td>val_acc_best</td><td>0.80417</td></tr><tr><td>val_acc_now</td><td>0.77083</td></tr><tr><td>val_loss</td><td>11.63542</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">unique-sweep-269</strong> at: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/xdqwxepd' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/xdqwxepd</a><br/> View project at: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>/data2/bh_wandb/wandb/run-20250430_093353-xdqwxepd/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require(\"core\")`! See https://wandb.me/wandb-core for more information."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Sweep Agent: Waiting for job.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Job received.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 97a09qoe with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBATCH: 16\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBN_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBPTT_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tDFA_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tIMAGE_SIZE: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tOTTT_input_trace_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tTIME: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tUDA_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \talpha_uda: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbias: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcfg: ['M', 'M', 200, 200]\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tchaching_on: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tconvTrue_fcFalse: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdata_path: /data2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tddp_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdenoise_on: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdvs_clipping: 5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdvs_duration: 100000\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepoch_num: 100\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \texclude_class: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \textra_train_dataset: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlast_lif: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.001\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_sg_width: 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_decay: 0.5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_init: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_reset: 10000\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_threshold: 0.25\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmerge_polarities: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmy_seed: 42\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnet_print: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_workers: 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer_what: SGD\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tpin_memory: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tpre_trained: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tpre_trained_path: net_save/save_now_net_weights_{unique_name}.pth\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \trate_coding: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tscheduler_name: no\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsingle_step: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsurrogate: hard_sigmoid\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_conv_kernel_size: 3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_conv_padding: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_conv_stride: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_trace_const1: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_trace_const2: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \ttdBN_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \ttrace_on: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \twhich_data: DVS_GESTURE_TONIC\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aa72e81a8f634dbab45d693d48df4d2f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.011113726740909947, max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.19.10 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.17.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/data2/bh_wandb/wandb/run-20250430_094054-97a09qoe</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/97a09qoe' target=\"_blank\">distinctive-sweep-271</a></strong> to <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/6pj3lh8j' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/6pj3lh8j</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/6pj3lh8j' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/6pj3lh8j</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/97a09qoe' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/97a09qoe</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'single_step' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'my_seed' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'TIME' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BATCH' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'IMAGE_SIZE' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'which_data' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'data_path' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'rate_coding' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_init' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_decay' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_threshold' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_reset' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_sg_width' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_conv_kernel_size' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_conv_stride' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_conv_padding' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_trace_const1' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_trace_const2' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'pre_trained' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'convTrue_fcFalse' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'cfg' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'net_print' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'pre_trained_path' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'learning_rate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'epoch_num' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'tdBN_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BN_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'surrogate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BPTT_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'optimizer_what' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'scheduler_name' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'ddp_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'dvs_clipping' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'dvs_duration' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'DFA_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'trace_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'OTTT_input_trace_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'exclude_class' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'merge_polarities' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'denoise_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'extra_train_dataset' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'num_workers' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'chaching_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'pin_memory' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'UDA_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'alpha_uda' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'bias' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'last_lif' was locked by 'sweep' (ignored update).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "param {'devices': '0', 'single_step': True, 'unique_name': 'main', 'my_seed': 42, 'TIME': 10, 'BATCH': 16, 'IMAGE_SIZE': 128, 'which_data': 'DVS_GESTURE_TONIC', 'data_path': '/data2', 'rate_coding': False, 'lif_layer_v_init': 0, 'lif_layer_v_decay': 0.5, 'lif_layer_v_threshold': 0.25, 'lif_layer_v_reset': 10000, 'lif_layer_sg_width': 2, 'synapse_conv_kernel_size': 3, 'synapse_conv_stride': 1, 'synapse_conv_padding': 1, 'synapse_trace_const1': 1, 'synapse_trace_const2': 0, 'pre_trained': False, 'convTrue_fcFalse': False, 'cfg': ['M', 'M', 200, 200], 'net_print': True, 'pre_trained_path': 'net_save/save_now_net_weights_{unique_name}.pth', 'learning_rate': 0.001, 'epoch_num': 100, 'tdBN_on': False, 'BN_on': False, 'surrogate': 'hard_sigmoid', 'BPTT_on': False, 'optimizer_what': 'SGD', 'scheduler_name': 'no', 'ddp_on': False, 'dvs_clipping': 5, 'dvs_duration': 100000, 'DFA_on': False, 'trace_on': True, 'OTTT_input_trace_on': False, 'exclude_class': True, 'merge_polarities': False, 'denoise_on': True, 'extra_train_dataset': 0, 'num_workers': 2, 'chaching_on': True, 'pin_memory': True, 'UDA_on': False, 'alpha_uda': 1, 'bias': True, 'last_lif': False, 'current epoch': 0} \n",
      "\n",
      "dataset_hash = 63cc597115630ec173f3099200061e53\n",
      "cache path exists\n",
      "\n",
      "device ==> cuda\n",
      "\n",
      "DataParallel(\n",
      "  (module): REBORN_MY_SNN_FC(\n",
      "    (layers): REBORN_MY_Sequential(\n",
      "      (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (2): DimChanger_for_FC()\n",
      "      (3): SYNAPSE_FC(in_features=2048, out_features=200, TIME=10, bias=True, sstep=True)\n",
      "      (4): LIF_layer(v_init=0, v_decay=0.5, v_threshold=0.25, v_reset=10000, sg_width=2, surrogate=hard_sigmoid, BPTT_on=False, trace_const1=1, trace_const2=0, TIME=10, sstep=True, trace_on=True)\n",
      "      (5): SYNAPSE_FC(in_features=200, out_features=200, TIME=10, bias=True, sstep=True)\n",
      "      (6): LIF_layer(v_init=0, v_decay=0.5, v_threshold=0.25, v_reset=10000, sg_width=2, surrogate=hard_sigmoid, BPTT_on=False, trace_const1=1, trace_const2=0, TIME=10, sstep=True, trace_on=True)\n",
      "      (7): SYNAPSE_FC(in_features=200, out_features=10, TIME=10, bias=True, sstep=True)\n",
      "    )\n",
      "  )\n",
      ")\n",
      "\n",
      "========================================================\n",
      "Trainable parameters: 452,010\n",
      "========================================================\n",
      "\n",
      "epoch-0   lr=['0.0010000'], tr/val_loss:  2.274191/  2.218580, val:  25.00%, val_best:  25.00%, tr:  15.22%, tr_best:  15.22%\n",
      "epoch-1   lr=['0.0010000'], tr/val_loss:  2.075346/  1.972411, val:  47.50%, val_best:  47.50%, tr:  33.09%, tr_best:  33.09%\n",
      "epoch-2   lr=['0.0010000'], tr/val_loss:  1.756007/  1.739949, val:  51.67%, val_best:  51.67%, tr:  52.50%, tr_best:  52.50%\n",
      "epoch-3   lr=['0.0010000'], tr/val_loss:  1.552190/  1.630692, val:  53.33%, val_best:  53.33%, tr:  59.35%, tr_best:  59.35%\n",
      "epoch-4   lr=['0.0010000'], tr/val_loss:  1.445712/  1.578947, val:  55.83%, val_best:  55.83%, tr:  60.88%, tr_best:  60.88%\n",
      "epoch-5   lr=['0.0010000'], tr/val_loss:  1.355659/  1.513748, val:  59.17%, val_best:  59.17%, tr:  63.23%, tr_best:  63.23%\n",
      "epoch-6   lr=['0.0010000'], tr/val_loss:  1.298607/  1.495619, val:  59.58%, val_best:  59.58%, tr:  64.04%, tr_best:  64.04%\n",
      "epoch-7   lr=['0.0010000'], tr/val_loss:  1.254347/  1.449809, val:  58.75%, val_best:  59.58%, tr:  63.94%, tr_best:  64.04%\n",
      "epoch-8   lr=['0.0010000'], tr/val_loss:  1.208795/  1.409656, val:  62.08%, val_best:  62.08%, tr:  65.68%, tr_best:  65.68%\n",
      "epoch-9   lr=['0.0010000'], tr/val_loss:  1.177571/  1.412178, val:  60.00%, val_best:  62.08%, tr:  67.62%, tr_best:  67.62%\n",
      "epoch-10  lr=['0.0010000'], tr/val_loss:  1.147070/  1.396901, val:  56.25%, val_best:  62.08%, tr:  67.21%, tr_best:  67.62%\n",
      "epoch-11  lr=['0.0010000'], tr/val_loss:  1.112069/  1.354416, val:  62.92%, val_best:  62.92%, tr:  68.95%, tr_best:  68.95%\n",
      "epoch-12  lr=['0.0010000'], tr/val_loss:  1.096676/  1.344656, val:  59.58%, val_best:  62.92%, tr:  69.56%, tr_best:  69.56%\n",
      "epoch-13  lr=['0.0010000'], tr/val_loss:  1.077895/  1.319699, val:  62.08%, val_best:  62.92%, tr:  69.46%, tr_best:  69.56%\n",
      "epoch-14  lr=['0.0010000'], tr/val_loss:  1.031875/  1.362107, val:  56.67%, val_best:  62.92%, tr:  70.99%, tr_best:  70.99%\n",
      "epoch-15  lr=['0.0010000'], tr/val_loss:  1.028225/  1.320042, val:  64.17%, val_best:  64.17%, tr:  69.97%, tr_best:  70.99%\n",
      "epoch-16  lr=['0.0010000'], tr/val_loss:  1.010160/  1.293994, val:  63.75%, val_best:  64.17%, tr:  70.79%, tr_best:  70.99%\n",
      "epoch-17  lr=['0.0010000'], tr/val_loss:  0.976378/  1.284030, val:  65.83%, val_best:  65.83%, tr:  72.93%, tr_best:  72.93%\n",
      "epoch-18  lr=['0.0010000'], tr/val_loss:  0.960143/  1.313055, val:  60.00%, val_best:  65.83%, tr:  73.75%, tr_best:  73.75%\n",
      "epoch-19  lr=['0.0010000'], tr/val_loss:  0.959531/  1.308789, val:  60.83%, val_best:  65.83%, tr:  72.42%, tr_best:  73.75%\n",
      "epoch-20  lr=['0.0010000'], tr/val_loss:  0.928179/  1.284169, val:  63.33%, val_best:  65.83%, tr:  75.49%, tr_best:  75.49%\n",
      "epoch-21  lr=['0.0010000'], tr/val_loss:  0.916651/  1.262569, val:  65.83%, val_best:  65.83%, tr:  75.08%, tr_best:  75.49%\n",
      "epoch-22  lr=['0.0010000'], tr/val_loss:  0.915391/  1.279294, val:  63.33%, val_best:  65.83%, tr:  73.44%, tr_best:  75.49%\n",
      "epoch-23  lr=['0.0010000'], tr/val_loss:  0.883316/  1.271851, val:  65.42%, val_best:  65.83%, tr:  75.89%, tr_best:  75.89%\n",
      "epoch-24  lr=['0.0010000'], tr/val_loss:  0.863569/  1.277230, val:  63.33%, val_best:  65.83%, tr:  77.02%, tr_best:  77.02%\n",
      "epoch-25  lr=['0.0010000'], tr/val_loss:  0.852133/  1.254971, val:  67.92%, val_best:  67.92%, tr:  79.88%, tr_best:  79.88%\n",
      "epoch-26  lr=['0.0010000'], tr/val_loss:  0.845096/  1.252516, val:  65.42%, val_best:  67.92%, tr:  77.02%, tr_best:  79.88%\n",
      "epoch-27  lr=['0.0010000'], tr/val_loss:  0.827716/  1.291874, val:  64.17%, val_best:  67.92%, tr:  81.61%, tr_best:  81.61%\n",
      "epoch-28  lr=['0.0010000'], tr/val_loss:  0.820895/  1.234459, val:  65.83%, val_best:  67.92%, tr:  78.65%, tr_best:  81.61%\n",
      "epoch-29  lr=['0.0010000'], tr/val_loss:  0.811412/  1.277113, val:  62.08%, val_best:  67.92%, tr:  81.41%, tr_best:  81.61%\n",
      "epoch-30  lr=['0.0010000'], tr/val_loss:  0.793039/  1.266493, val:  64.17%, val_best:  67.92%, tr:  81.92%, tr_best:  81.92%\n",
      "epoch-31  lr=['0.0010000'], tr/val_loss:  0.798810/  1.303115, val:  62.50%, val_best:  67.92%, tr:  79.26%, tr_best:  81.92%\n",
      "epoch-32  lr=['0.0010000'], tr/val_loss:  0.782557/  1.282359, val:  65.83%, val_best:  67.92%, tr:  80.90%, tr_best:  81.92%\n",
      "epoch-33  lr=['0.0010000'], tr/val_loss:  0.772575/  1.269219, val:  68.75%, val_best:  68.75%, tr:  84.98%, tr_best:  84.98%\n",
      "epoch-34  lr=['0.0010000'], tr/val_loss:  0.757120/  1.289704, val:  65.83%, val_best:  68.75%, tr:  84.37%, tr_best:  84.98%\n",
      "epoch-35  lr=['0.0010000'], tr/val_loss:  0.760014/  1.307997, val:  66.67%, val_best:  68.75%, tr:  82.94%, tr_best:  84.98%\n",
      "epoch-36  lr=['0.0010000'], tr/val_loss:  0.734718/  1.261122, val:  70.00%, val_best:  70.00%, tr:  84.27%, tr_best:  84.98%\n",
      "epoch-37  lr=['0.0010000'], tr/val_loss:  0.738601/  1.288741, val:  72.08%, val_best:  72.08%, tr:  87.64%, tr_best:  87.64%\n",
      "epoch-38  lr=['0.0010000'], tr/val_loss:  0.721352/  1.292264, val:  70.00%, val_best:  72.08%, tr:  88.15%, tr_best:  88.15%\n",
      "epoch-39  lr=['0.0010000'], tr/val_loss:  0.710615/  1.291598, val:  68.33%, val_best:  72.08%, tr:  87.95%, tr_best:  88.15%\n",
      "epoch-40  lr=['0.0010000'], tr/val_loss:  0.707907/  1.281552, val:  69.17%, val_best:  72.08%, tr:  84.88%, tr_best:  88.15%\n",
      "epoch-41  lr=['0.0010000'], tr/val_loss:  0.687178/  1.335739, val:  67.08%, val_best:  72.08%, tr:  89.79%, tr_best:  89.79%\n",
      "epoch-42  lr=['0.0010000'], tr/val_loss:  0.676278/  1.304975, val:  67.08%, val_best:  72.08%, tr:  88.46%, tr_best:  89.79%\n",
      "epoch-43  lr=['0.0010000'], tr/val_loss:  0.663939/  1.310527, val:  70.00%, val_best:  72.08%, tr:  88.46%, tr_best:  89.79%\n",
      "epoch-44  lr=['0.0010000'], tr/val_loss:  0.658724/  1.326202, val:  69.58%, val_best:  72.08%, tr:  88.15%, tr_best:  89.79%\n",
      "epoch-45  lr=['0.0010000'], tr/val_loss:  0.642301/  1.310706, val:  70.42%, val_best:  72.08%, tr:  91.83%, tr_best:  91.83%\n",
      "epoch-46  lr=['0.0010000'], tr/val_loss:  0.641415/  1.337583, val:  65.83%, val_best:  72.08%, tr:  90.09%, tr_best:  91.83%\n",
      "epoch-47  lr=['0.0010000'], tr/val_loss:  0.628301/  1.370839, val:  70.00%, val_best:  72.08%, tr:  90.70%, tr_best:  91.83%\n",
      "epoch-48  lr=['0.0010000'], tr/val_loss:  0.629010/  1.324082, val:  69.17%, val_best:  72.08%, tr:  91.83%, tr_best:  91.83%\n",
      "epoch-49  lr=['0.0010000'], tr/val_loss:  0.620537/  1.319781, val:  75.00%, val_best:  75.00%, tr:  90.19%, tr_best:  91.83%\n",
      "epoch-50  lr=['0.0010000'], tr/val_loss:  0.615928/  1.352340, val:  74.17%, val_best:  75.00%, tr:  90.50%, tr_best:  91.83%\n",
      "epoch-51  lr=['0.0010000'], tr/val_loss:  0.603395/  1.377992, val:  70.42%, val_best:  75.00%, tr:  91.11%, tr_best:  91.83%\n",
      "epoch-52  lr=['0.0010000'], tr/val_loss:  0.590253/  1.438112, val:  63.33%, val_best:  75.00%, tr:  91.32%, tr_best:  91.83%\n",
      "epoch-53  lr=['0.0010000'], tr/val_loss:  0.592096/  1.405250, val:  70.00%, val_best:  75.00%, tr:  93.05%, tr_best:  93.05%\n",
      "epoch-54  lr=['0.0010000'], tr/val_loss:  0.580699/  1.383874, val:  71.25%, val_best:  75.00%, tr:  93.05%, tr_best:  93.05%\n",
      "epoch-55  lr=['0.0010000'], tr/val_loss:  0.567805/  1.391743, val:  71.25%, val_best:  75.00%, tr:  92.54%, tr_best:  93.05%\n",
      "epoch-56  lr=['0.0010000'], tr/val_loss:  0.564567/  1.474526, val:  65.42%, val_best:  75.00%, tr:  93.05%, tr_best:  93.05%\n",
      "epoch-57  lr=['0.0010000'], tr/val_loss:  0.577867/  1.390273, val:  68.75%, val_best:  75.00%, tr:  92.24%, tr_best:  93.05%\n",
      "epoch-58  lr=['0.0010000'], tr/val_loss:  0.547812/  1.455299, val:  65.42%, val_best:  75.00%, tr:  94.08%, tr_best:  94.08%\n",
      "epoch-59  lr=['0.0010000'], tr/val_loss:  0.553900/  1.433185, val:  75.42%, val_best:  75.42%, tr:  94.59%, tr_best:  94.59%\n",
      "epoch-60  lr=['0.0010000'], tr/val_loss:  0.539167/  1.435867, val:  70.00%, val_best:  75.42%, tr:  94.89%, tr_best:  94.89%\n",
      "epoch-61  lr=['0.0010000'], tr/val_loss:  0.528375/  1.467913, val:  66.25%, val_best:  75.42%, tr:  95.81%, tr_best:  95.81%\n",
      "epoch-62  lr=['0.0010000'], tr/val_loss:  0.525013/  1.456464, val:  71.67%, val_best:  75.42%, tr:  94.89%, tr_best:  95.81%\n",
      "epoch-63  lr=['0.0010000'], tr/val_loss:  0.515302/  1.425273, val:  70.83%, val_best:  75.42%, tr:  96.94%, tr_best:  96.94%\n",
      "epoch-64  lr=['0.0010000'], tr/val_loss:  0.517663/  1.497600, val:  69.17%, val_best:  75.42%, tr:  95.20%, tr_best:  96.94%\n",
      "epoch-65  lr=['0.0010000'], tr/val_loss:  0.509702/  1.484637, val:  72.50%, val_best:  75.42%, tr:  95.81%, tr_best:  96.94%\n",
      "epoch-66  lr=['0.0010000'], tr/val_loss:  0.500092/  1.494254, val:  69.58%, val_best:  75.42%, tr:  95.30%, tr_best:  96.94%\n",
      "epoch-67  lr=['0.0010000'], tr/val_loss:  0.501544/  1.501006, val:  70.42%, val_best:  75.42%, tr:  96.12%, tr_best:  96.94%\n",
      "epoch-68  lr=['0.0010000'], tr/val_loss:  0.490964/  1.502536, val:  68.75%, val_best:  75.42%, tr:  95.30%, tr_best:  96.94%\n",
      "epoch-69  lr=['0.0010000'], tr/val_loss:  0.490592/  1.530194, val:  66.25%, val_best:  75.42%, tr:  95.20%, tr_best:  96.94%\n",
      "epoch-70  lr=['0.0010000'], tr/val_loss:  0.479384/  1.517751, val:  72.08%, val_best:  75.42%, tr:  96.83%, tr_best:  96.94%\n",
      "epoch-71  lr=['0.0010000'], tr/val_loss:  0.480564/  1.547641, val:  66.67%, val_best:  75.42%, tr:  97.04%, tr_best:  97.04%\n",
      "epoch-72  lr=['0.0010000'], tr/val_loss:  0.473086/  1.558800, val:  69.17%, val_best:  75.42%, tr:  96.32%, tr_best:  97.04%\n",
      "epoch-73  lr=['0.0010000'], tr/val_loss:  0.480731/  1.543317, val:  73.33%, val_best:  75.42%, tr:  95.91%, tr_best:  97.04%\n",
      "epoch-74  lr=['0.0010000'], tr/val_loss:  0.461853/  1.534527, val:  72.50%, val_best:  75.42%, tr:  96.83%, tr_best:  97.04%\n",
      "epoch-75  lr=['0.0010000'], tr/val_loss:  0.455817/  1.571643, val:  65.83%, val_best:  75.42%, tr:  95.61%, tr_best:  97.04%\n",
      "epoch-76  lr=['0.0010000'], tr/val_loss:  0.447568/  1.577328, val:  66.67%, val_best:  75.42%, tr:  97.65%, tr_best:  97.65%\n",
      "epoch-77  lr=['0.0010000'], tr/val_loss:  0.461766/  1.571505, val:  71.25%, val_best:  75.42%, tr:  95.81%, tr_best:  97.65%\n",
      "epoch-78  lr=['0.0010000'], tr/val_loss:  0.452556/  1.546493, val:  74.17%, val_best:  75.42%, tr:  96.42%, tr_best:  97.65%\n",
      "epoch-79  lr=['0.0010000'], tr/val_loss:  0.439795/  1.534450, val:  74.17%, val_best:  75.42%, tr:  96.94%, tr_best:  97.65%\n",
      "epoch-80  lr=['0.0010000'], tr/val_loss:  0.426617/  1.551494, val:  75.00%, val_best:  75.42%, tr:  97.75%, tr_best:  97.75%\n",
      "epoch-81  lr=['0.0010000'], tr/val_loss:  0.429164/  1.578474, val:  74.58%, val_best:  75.42%, tr:  97.75%, tr_best:  97.75%\n",
      "epoch-82  lr=['0.0010000'], tr/val_loss:  0.424351/  1.598652, val:  71.67%, val_best:  75.42%, tr:  97.24%, tr_best:  97.75%\n",
      "epoch-83  lr=['0.0010000'], tr/val_loss:  0.421248/  1.653961, val:  72.50%, val_best:  75.42%, tr:  97.34%, tr_best:  97.75%\n",
      "epoch-84  lr=['0.0010000'], tr/val_loss:  0.417699/  1.599366, val:  70.83%, val_best:  75.42%, tr:  97.96%, tr_best:  97.96%\n",
      "epoch-85  lr=['0.0010000'], tr/val_loss:  0.406182/  1.632522, val:  73.33%, val_best:  75.42%, tr:  97.96%, tr_best:  97.96%\n",
      "epoch-86  lr=['0.0010000'], tr/val_loss:  0.406919/  1.666832, val:  72.92%, val_best:  75.42%, tr:  96.63%, tr_best:  97.96%\n",
      "epoch-87  lr=['0.0010000'], tr/val_loss:  0.403068/  1.639962, val:  73.33%, val_best:  75.42%, tr:  97.65%, tr_best:  97.96%\n",
      "epoch-88  lr=['0.0010000'], tr/val_loss:  0.388461/  1.656087, val:  72.08%, val_best:  75.42%, tr:  98.26%, tr_best:  98.26%\n",
      "epoch-89  lr=['0.0010000'], tr/val_loss:  0.377699/  1.681610, val:  72.92%, val_best:  75.42%, tr:  99.08%, tr_best:  99.08%\n",
      "epoch-90  lr=['0.0010000'], tr/val_loss:  0.388125/  1.643831, val:  74.58%, val_best:  75.42%, tr:  97.96%, tr_best:  99.08%\n",
      "epoch-91  lr=['0.0010000'], tr/val_loss:  0.372250/  1.668326, val:  75.83%, val_best:  75.83%, tr:  98.98%, tr_best:  99.08%\n",
      "epoch-92  lr=['0.0010000'], tr/val_loss:  0.367953/  1.707927, val:  72.92%, val_best:  75.83%, tr:  98.26%, tr_best:  99.08%\n",
      "epoch-93  lr=['0.0010000'], tr/val_loss:  0.368874/  1.667787, val:  72.08%, val_best:  75.83%, tr:  98.98%, tr_best:  99.08%\n",
      "epoch-94  lr=['0.0010000'], tr/val_loss:  0.365060/  1.681595, val:  74.58%, val_best:  75.83%, tr:  98.88%, tr_best:  99.08%\n",
      "epoch-95  lr=['0.0010000'], tr/val_loss:  0.361291/  1.740701, val:  74.17%, val_best:  75.83%, tr:  98.16%, tr_best:  99.08%\n",
      "epoch-96  lr=['0.0010000'], tr/val_loss:  0.361938/  1.779347, val:  67.92%, val_best:  75.83%, tr:  98.67%, tr_best:  99.08%\n",
      "epoch-97  lr=['0.0010000'], tr/val_loss:  0.371085/  1.662928, val:  73.33%, val_best:  75.83%, tr:  97.24%, tr_best:  99.08%\n",
      "epoch-98  lr=['0.0010000'], tr/val_loss:  0.343872/  1.729346, val:  71.67%, val_best:  75.83%, tr:  99.08%, tr_best:  99.08%\n",
      "epoch-99  lr=['0.0010000'], tr/val_loss:  0.356393/  1.748094, val:  71.67%, val_best:  75.83%, tr:  98.98%, tr_best:  99.08%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d5b96981065349018500b3169cdbe9a7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.006 MB of 0.006 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>iter_acc</td><td>▁▅▃▄▂▅▅▂▃▆▇▇▅▆▅▇█▇▇▇▇▇▆▇███▇▇▇██▇███████</td></tr><tr><td>summary_val_acc</td><td>▁▅▅▆▆▆▅▇▆▇▆▇▆▇▇█▇▇▇▇█▆▇▇█▇█▇█▇▇▇█▇▇█████</td></tr><tr><td>tr_acc</td><td>▁▄▅▅▅▆▆▆▆▆▆▆▇▆▇▇▇▇▇▇▇▇▇▇████████████████</td></tr><tr><td>tr_epoch_loss</td><td>█▆▅▄▄▄▃▃▃▃▃▃▃▃▂▂▂▂▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_acc_best</td><td>▁▅▅▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇████████████████████</td></tr><tr><td>val_acc_now</td><td>▁▅▅▆▆▆▅▇▆▇▆▇▆▇▇█▇▇▇▇█▆▇▇█▇█▇█▇▇▇█▇▇█████</td></tr><tr><td>val_loss</td><td>█▅▃▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▂▂▁▂▂▂▂▃▃▃▃▃▃▃▃▄▄▄▄▄▅▄</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>99</td></tr><tr><td>iter_acc</td><td>1.0</td></tr><tr><td>tr_acc</td><td>0.98979</td></tr><tr><td>tr_epoch_loss</td><td>0.35639</td></tr><tr><td>val_acc_best</td><td>0.75833</td></tr><tr><td>val_acc_now</td><td>0.71667</td></tr><tr><td>val_loss</td><td>1.74809</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">distinctive-sweep-271</strong> at: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/97a09qoe' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/97a09qoe</a><br/> View project at: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>/data2/bh_wandb/wandb/run-20250430_094054-97a09qoe/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require(\"core\")`! See https://wandb.me/wandb-core for more information."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 0nng3hyw with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBATCH: 16\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBN_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBPTT_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tDFA_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tIMAGE_SIZE: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tOTTT_input_trace_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tTIME: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tUDA_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \talpha_uda: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbias: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcfg: ['M', 'M', 200, 200]\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tchaching_on: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tconvTrue_fcFalse: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdata_path: /data2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tddp_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdenoise_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdvs_clipping: 5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdvs_duration: 100000\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepoch_num: 100\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \texclude_class: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \textra_train_dataset: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlast_lif: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_sg_width: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_decay: 0.5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_init: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_reset: 10000\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_threshold: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmerge_polarities: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmy_seed: 42\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnet_print: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_workers: 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer_what: SGD\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tpin_memory: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tpre_trained: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tpre_trained_path: net_save/save_now_net_weights_{unique_name}.pth\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \trate_coding: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tscheduler_name: no\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsingle_step: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsurrogate: hard_sigmoid\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_conv_kernel_size: 3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_conv_padding: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_conv_stride: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_trace_const1: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_trace_const2: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \ttdBN_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \ttrace_on: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \twhich_data: DVS_GESTURE_TONIC\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.19.10 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.17.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/data2/bh_wandb/wandb/run-20250430_094700-0nng3hyw</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/0nng3hyw' target=\"_blank\">vibrant-sweep-273</a></strong> to <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/6pj3lh8j' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/6pj3lh8j</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/6pj3lh8j' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/6pj3lh8j</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/0nng3hyw' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/0nng3hyw</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'single_step' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'my_seed' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'TIME' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BATCH' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'IMAGE_SIZE' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'which_data' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'data_path' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'rate_coding' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_init' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_decay' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_threshold' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_reset' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_sg_width' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_conv_kernel_size' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_conv_stride' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_conv_padding' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_trace_const1' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_trace_const2' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'pre_trained' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'convTrue_fcFalse' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'cfg' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'net_print' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'pre_trained_path' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'learning_rate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'epoch_num' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'tdBN_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BN_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'surrogate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BPTT_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'optimizer_what' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'scheduler_name' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'ddp_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'dvs_clipping' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'dvs_duration' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'DFA_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'trace_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'OTTT_input_trace_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'exclude_class' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'merge_polarities' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'denoise_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'extra_train_dataset' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'num_workers' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'chaching_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'pin_memory' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'UDA_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'alpha_uda' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'bias' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'last_lif' was locked by 'sweep' (ignored update).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "param {'devices': '0', 'single_step': True, 'unique_name': 'main', 'my_seed': 42, 'TIME': 10, 'BATCH': 16, 'IMAGE_SIZE': 128, 'which_data': 'DVS_GESTURE_TONIC', 'data_path': '/data2', 'rate_coding': False, 'lif_layer_v_init': 0, 'lif_layer_v_decay': 0.5, 'lif_layer_v_threshold': 1, 'lif_layer_v_reset': 10000, 'lif_layer_sg_width': 1, 'synapse_conv_kernel_size': 3, 'synapse_conv_stride': 1, 'synapse_conv_padding': 1, 'synapse_trace_const1': 1, 'synapse_trace_const2': 0, 'pre_trained': False, 'convTrue_fcFalse': False, 'cfg': ['M', 'M', 200, 200], 'net_print': True, 'pre_trained_path': 'net_save/save_now_net_weights_{unique_name}.pth', 'learning_rate': 0.1, 'epoch_num': 100, 'tdBN_on': False, 'BN_on': False, 'surrogate': 'hard_sigmoid', 'BPTT_on': False, 'optimizer_what': 'SGD', 'scheduler_name': 'no', 'ddp_on': False, 'dvs_clipping': 5, 'dvs_duration': 100000, 'DFA_on': False, 'trace_on': True, 'OTTT_input_trace_on': False, 'exclude_class': True, 'merge_polarities': False, 'denoise_on': False, 'extra_train_dataset': 0, 'num_workers': 2, 'chaching_on': True, 'pin_memory': True, 'UDA_on': False, 'alpha_uda': 1, 'bias': True, 'last_lif': False, 'current epoch': 0} \n",
      "\n",
      "dataset_hash = ffa516e60c3efd5e0208f72b4c36cb84\n",
      "cache path exists\n",
      "\n",
      "device ==> cuda\n",
      "\n",
      "DataParallel(\n",
      "  (module): REBORN_MY_SNN_FC(\n",
      "    (layers): REBORN_MY_Sequential(\n",
      "      (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (2): DimChanger_for_FC()\n",
      "      (3): SYNAPSE_FC(in_features=2048, out_features=200, TIME=10, bias=True, sstep=True)\n",
      "      (4): LIF_layer(v_init=0, v_decay=0.5, v_threshold=1, v_reset=10000, sg_width=1, surrogate=hard_sigmoid, BPTT_on=False, trace_const1=1, trace_const2=0, TIME=10, sstep=True, trace_on=True)\n",
      "      (5): SYNAPSE_FC(in_features=200, out_features=200, TIME=10, bias=True, sstep=True)\n",
      "      (6): LIF_layer(v_init=0, v_decay=0.5, v_threshold=1, v_reset=10000, sg_width=1, surrogate=hard_sigmoid, BPTT_on=False, trace_const1=1, trace_const2=0, TIME=10, sstep=True, trace_on=True)\n",
      "      (7): SYNAPSE_FC(in_features=200, out_features=10, TIME=10, bias=True, sstep=True)\n",
      "    )\n",
      "  )\n",
      ")\n",
      "\n",
      "========================================================\n",
      "Trainable parameters: 452,010\n",
      "========================================================\n",
      "\n",
      "epoch-0   lr=['0.1000000'], tr/val_loss:  2.285853/  2.053481, val:  42.08%, val_best:  42.08%, tr:  21.76%, tr_best:  21.76%\n",
      "epoch-1   lr=['0.1000000'], tr/val_loss:  1.709005/  1.680853, val:  47.92%, val_best:  47.92%, tr:  49.03%, tr_best:  49.03%\n",
      "epoch-2   lr=['0.1000000'], tr/val_loss:  1.458611/  1.724974, val:  50.42%, val_best:  50.42%, tr:  57.61%, tr_best:  57.61%\n",
      "epoch-3   lr=['0.1000000'], tr/val_loss:  1.226088/  1.636597, val:  51.67%, val_best:  51.67%, tr:  62.31%, tr_best:  62.31%\n",
      "epoch-4   lr=['0.1000000'], tr/val_loss:  1.243964/  1.653347, val:  61.67%, val_best:  61.67%, tr:  61.29%, tr_best:  62.31%\n",
      "epoch-5   lr=['0.1000000'], tr/val_loss:  1.013862/  1.657426, val:  53.75%, val_best:  61.67%, tr:  69.97%, tr_best:  69.97%\n",
      "epoch-6   lr=['0.1000000'], tr/val_loss:  0.987884/  1.547350, val:  62.50%, val_best:  62.50%, tr:  71.81%, tr_best:  71.81%\n",
      "epoch-7   lr=['0.1000000'], tr/val_loss:  0.911952/  1.773459, val:  62.50%, val_best:  62.50%, tr:  70.07%, tr_best:  71.81%\n",
      "epoch-8   lr=['0.1000000'], tr/val_loss:  0.867727/  1.682229, val:  60.42%, val_best:  62.50%, tr:  73.54%, tr_best:  73.54%\n",
      "epoch-9   lr=['0.1000000'], tr/val_loss:  0.823192/  1.764851, val:  57.50%, val_best:  62.50%, tr:  75.08%, tr_best:  75.08%\n",
      "epoch-10  lr=['0.1000000'], tr/val_loss:  0.693660/  1.717046, val:  61.25%, val_best:  62.50%, tr:  78.75%, tr_best:  78.75%\n",
      "epoch-11  lr=['0.1000000'], tr/val_loss:  0.683476/  1.572659, val:  67.50%, val_best:  67.50%, tr:  79.26%, tr_best:  79.26%\n",
      "epoch-12  lr=['0.1000000'], tr/val_loss:  0.568455/  1.585153, val:  73.33%, val_best:  73.33%, tr:  80.80%, tr_best:  80.80%\n",
      "epoch-13  lr=['0.1000000'], tr/val_loss:  0.612555/  1.726803, val:  62.92%, val_best:  73.33%, tr:  82.94%, tr_best:  82.94%\n",
      "epoch-14  lr=['0.1000000'], tr/val_loss:  0.498697/  2.186072, val:  62.92%, val_best:  73.33%, tr:  85.80%, tr_best:  85.80%\n",
      "epoch-15  lr=['0.1000000'], tr/val_loss:  0.434872/  2.158664, val:  60.00%, val_best:  73.33%, tr:  88.36%, tr_best:  88.36%\n",
      "epoch-16  lr=['0.1000000'], tr/val_loss:  0.387257/  2.359634, val:  67.50%, val_best:  73.33%, tr:  89.38%, tr_best:  89.38%\n",
      "epoch-17  lr=['0.1000000'], tr/val_loss:  0.427243/  1.947007, val:  67.92%, val_best:  73.33%, tr:  92.44%, tr_best:  92.44%\n",
      "epoch-18  lr=['0.1000000'], tr/val_loss:  0.399279/  2.301380, val:  64.58%, val_best:  73.33%, tr:  93.46%, tr_best:  93.46%\n",
      "epoch-19  lr=['0.1000000'], tr/val_loss:  0.278757/  2.081099, val:  75.00%, val_best:  75.00%, tr:  96.42%, tr_best:  96.42%\n",
      "epoch-20  lr=['0.1000000'], tr/val_loss:  0.318969/  2.248349, val:  72.92%, val_best:  75.00%, tr:  93.87%, tr_best:  96.42%\n",
      "epoch-21  lr=['0.1000000'], tr/val_loss:  0.218074/  2.311177, val:  66.25%, val_best:  75.00%, tr:  97.75%, tr_best:  97.75%\n",
      "epoch-22  lr=['0.1000000'], tr/val_loss:  0.154455/  2.411695, val:  71.67%, val_best:  75.00%, tr:  99.80%, tr_best:  99.80%\n",
      "epoch-23  lr=['0.1000000'], tr/val_loss:  0.274714/  2.689136, val:  64.17%, val_best:  75.00%, tr:  98.26%, tr_best:  99.80%\n",
      "epoch-24  lr=['0.1000000'], tr/val_loss:  0.196290/  2.261969, val:  76.67%, val_best:  76.67%, tr:  99.18%, tr_best:  99.80%\n",
      "epoch-25  lr=['0.1000000'], tr/val_loss:  0.152304/  2.336590, val:  76.67%, val_best:  76.67%, tr:  98.88%, tr_best:  99.80%\n",
      "epoch-26  lr=['0.1000000'], tr/val_loss:  0.129113/  2.406643, val:  75.00%, val_best:  76.67%, tr:  98.77%, tr_best:  99.80%\n",
      "epoch-27  lr=['0.1000000'], tr/val_loss:  0.094587/  2.458288, val:  79.17%, val_best:  79.17%, tr:  99.59%, tr_best:  99.80%\n",
      "epoch-28  lr=['0.1000000'], tr/val_loss:  0.043439/  2.509095, val:  79.17%, val_best:  79.17%, tr:  99.80%, tr_best:  99.80%\n",
      "epoch-29  lr=['0.1000000'], tr/val_loss:  0.023121/  2.642365, val:  80.00%, val_best:  80.00%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-30  lr=['0.1000000'], tr/val_loss:  0.017704/  2.702942, val:  80.83%, val_best:  80.83%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-31  lr=['0.1000000'], tr/val_loss:  0.012043/  2.661956, val:  78.75%, val_best:  80.83%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-32  lr=['0.1000000'], tr/val_loss:  0.007612/  2.754230, val:  78.33%, val_best:  80.83%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-33  lr=['0.1000000'], tr/val_loss:  0.031270/  2.698399, val:  80.00%, val_best:  80.83%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-34  lr=['0.1000000'], tr/val_loss:  0.023063/  2.694755, val:  80.42%, val_best:  80.83%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-35  lr=['0.1000000'], tr/val_loss:  0.010330/  2.819055, val:  81.25%, val_best:  81.25%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-36  lr=['0.1000000'], tr/val_loss:  0.007725/  2.810989, val:  78.33%, val_best:  81.25%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-37  lr=['0.1000000'], tr/val_loss:  0.008873/  2.872442, val:  80.00%, val_best:  81.25%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-38  lr=['0.1000000'], tr/val_loss:  0.007148/  2.844573, val:  80.83%, val_best:  81.25%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-39  lr=['0.1000000'], tr/val_loss:  0.004002/  2.945530, val:  78.75%, val_best:  81.25%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-40  lr=['0.1000000'], tr/val_loss:  0.006656/  2.811665, val:  81.67%, val_best:  81.67%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-41  lr=['0.1000000'], tr/val_loss:  0.003086/  2.887087, val:  79.58%, val_best:  81.67%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-42  lr=['0.1000000'], tr/val_loss:  0.002889/  2.980851, val:  77.92%, val_best:  81.67%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-43  lr=['0.1000000'], tr/val_loss:  0.002086/  3.055407, val:  80.42%, val_best:  81.67%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-44  lr=['0.1000000'], tr/val_loss:  0.004130/  3.043365, val:  77.92%, val_best:  81.67%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-45  lr=['0.1000000'], tr/val_loss:  0.004182/  2.988124, val:  79.58%, val_best:  81.67%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-46  lr=['0.1000000'], tr/val_loss:  0.007595/  3.083115, val:  78.75%, val_best:  81.67%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-47  lr=['0.1000000'], tr/val_loss:  0.013698/  3.048383, val:  76.67%, val_best:  81.67%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-48  lr=['0.1000000'], tr/val_loss:  0.009413/  3.062975, val:  77.08%, val_best:  81.67%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-49  lr=['0.1000000'], tr/val_loss:  0.010617/  3.112098, val:  75.83%, val_best:  81.67%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-50  lr=['0.1000000'], tr/val_loss:  0.017168/  3.231787, val:  76.67%, val_best:  81.67%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-51  lr=['0.1000000'], tr/val_loss:  0.037057/  3.186723, val:  73.75%, val_best:  81.67%, tr:  99.90%, tr_best: 100.00%\n",
      "epoch-52  lr=['0.1000000'], tr/val_loss:  0.020976/  3.206089, val:  77.92%, val_best:  81.67%, tr:  99.90%, tr_best: 100.00%\n",
      "epoch-53  lr=['0.1000000'], tr/val_loss:  0.061803/  3.378475, val:  75.00%, val_best:  81.67%, tr:  99.90%, tr_best: 100.00%\n",
      "epoch-54  lr=['0.1000000'], tr/val_loss:  0.034907/  2.924494, val:  77.08%, val_best:  81.67%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-55  lr=['0.1000000'], tr/val_loss:  0.017401/  2.955615, val:  81.25%, val_best:  81.67%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-56  lr=['0.1000000'], tr/val_loss:  0.010434/  3.061478, val:  79.58%, val_best:  81.67%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-57  lr=['0.1000000'], tr/val_loss:  0.007214/  3.017685, val:  78.33%, val_best:  81.67%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-58  lr=['0.1000000'], tr/val_loss:  0.006094/  3.124384, val:  77.92%, val_best:  81.67%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-59  lr=['0.1000000'], tr/val_loss:  0.004924/  3.158646, val:  77.50%, val_best:  81.67%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-60  lr=['0.1000000'], tr/val_loss:  0.002566/  3.297737, val:  75.83%, val_best:  81.67%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-61  lr=['0.1000000'], tr/val_loss:  0.001847/  3.177051, val:  80.00%, val_best:  81.67%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-62  lr=['0.1000000'], tr/val_loss:  0.000628/  3.173343, val:  79.17%, val_best:  81.67%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-63  lr=['0.1000000'], tr/val_loss:  0.000723/  3.179575, val:  79.17%, val_best:  81.67%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-64  lr=['0.1000000'], tr/val_loss:  0.000730/  3.154967, val:  80.00%, val_best:  81.67%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-65  lr=['0.1000000'], tr/val_loss:  0.000453/  3.202388, val:  79.58%, val_best:  81.67%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-66  lr=['0.1000000'], tr/val_loss:  0.000255/  3.201561, val:  80.42%, val_best:  81.67%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-67  lr=['0.1000000'], tr/val_loss:  0.000191/  3.210755, val:  80.00%, val_best:  81.67%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-68  lr=['0.1000000'], tr/val_loss:  0.000162/  3.208899, val:  80.00%, val_best:  81.67%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-69  lr=['0.1000000'], tr/val_loss:  0.000137/  3.201527, val:  80.00%, val_best:  81.67%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-70  lr=['0.1000000'], tr/val_loss:  0.000141/  3.198158, val:  80.00%, val_best:  81.67%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-71  lr=['0.1000000'], tr/val_loss:  0.000137/  3.201961, val:  80.00%, val_best:  81.67%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-72  lr=['0.1000000'], tr/val_loss:  0.000125/  3.197592, val:  79.58%, val_best:  81.67%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-73  lr=['0.1000000'], tr/val_loss:  0.000120/  3.224890, val:  80.00%, val_best:  81.67%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-74  lr=['0.1000000'], tr/val_loss:  0.000103/  3.241307, val:  80.00%, val_best:  81.67%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-75  lr=['0.1000000'], tr/val_loss:  0.000140/  3.252801, val:  79.58%, val_best:  81.67%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-76  lr=['0.1000000'], tr/val_loss:  0.000103/  3.245208, val:  79.17%, val_best:  81.67%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-77  lr=['0.1000000'], tr/val_loss:  0.000092/  3.250266, val:  79.17%, val_best:  81.67%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-78  lr=['0.1000000'], tr/val_loss:  0.000095/  3.249566, val:  79.17%, val_best:  81.67%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-79  lr=['0.1000000'], tr/val_loss:  0.000083/  3.250959, val:  79.58%, val_best:  81.67%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-80  lr=['0.1000000'], tr/val_loss:  0.000081/  3.254580, val:  79.58%, val_best:  81.67%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-81  lr=['0.1000000'], tr/val_loss:  0.000081/  3.260961, val:  79.58%, val_best:  81.67%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-82  lr=['0.1000000'], tr/val_loss:  0.000075/  3.266871, val:  80.00%, val_best:  81.67%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-83  lr=['0.1000000'], tr/val_loss:  0.000078/  3.275686, val:  79.58%, val_best:  81.67%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-84  lr=['0.1000000'], tr/val_loss:  0.000124/  3.282494, val:  80.00%, val_best:  81.67%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-85  lr=['0.1000000'], tr/val_loss:  0.000129/  3.263677, val:  80.83%, val_best:  81.67%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-86  lr=['0.1000000'], tr/val_loss:  0.000104/  3.259821, val:  80.83%, val_best:  81.67%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-87  lr=['0.1000000'], tr/val_loss:  0.000077/  3.263643, val:  80.83%, val_best:  81.67%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-88  lr=['0.1000000'], tr/val_loss:  0.000079/  3.260434, val:  80.83%, val_best:  81.67%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-89  lr=['0.1000000'], tr/val_loss:  0.000072/  3.269111, val:  80.83%, val_best:  81.67%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-90  lr=['0.1000000'], tr/val_loss:  0.000071/  3.279865, val:  81.25%, val_best:  81.67%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-91  lr=['0.1000000'], tr/val_loss:  0.000068/  3.289854, val:  81.25%, val_best:  81.67%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-92  lr=['0.1000000'], tr/val_loss:  0.000066/  3.290632, val:  80.42%, val_best:  81.67%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-93  lr=['0.1000000'], tr/val_loss:  0.000062/  3.282828, val:  80.83%, val_best:  81.67%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-94  lr=['0.1000000'], tr/val_loss:  0.000061/  3.294268, val:  80.83%, val_best:  81.67%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-95  lr=['0.1000000'], tr/val_loss:  0.000059/  3.292227, val:  80.42%, val_best:  81.67%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-96  lr=['0.1000000'], tr/val_loss:  0.000059/  3.304969, val:  80.42%, val_best:  81.67%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-97  lr=['0.1000000'], tr/val_loss:  0.000055/  3.313257, val:  80.42%, val_best:  81.67%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-98  lr=['0.1000000'], tr/val_loss:  0.000056/  3.305539, val:  80.00%, val_best:  81.67%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-99  lr=['0.1000000'], tr/val_loss:  0.000056/  3.316160, val:  80.42%, val_best:  81.67%, tr: 100.00%, tr_best: 100.00%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4dd157e5a0234929983b7f7a124f845c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.006 MB of 0.006 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>iter_acc</td><td>▁▅▆▅▄▇▇▇▅███████████████████████████████</td></tr><tr><td>summary_val_acc</td><td>▁▂▅▅▄▇▅▆▇▅▇▇█▇███▇▇▇▇▇▇▇▇███████████████</td></tr><tr><td>tr_acc</td><td>▁▄▅▅▆▆▇▇████████████████████████████████</td></tr><tr><td>tr_epoch_loss</td><td>█▅▅▄▄▃▃▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_acc_best</td><td>▁▂▄▅▅▇▇▇▇▇▇▇████████████████████████████</td></tr><tr><td>val_acc_now</td><td>▁▂▅▅▄▇▅▆▇▅▇▇█▇███▇▇▇▇▇▇▇▇███████████████</td></tr><tr><td>val_loss</td><td>▃▂▁▂▂▁▃▂▃▄▄▄▅▆▆▆▇▇▇▇▇█▆▇▇▇██████████████</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>99</td></tr><tr><td>iter_acc</td><td>1.0</td></tr><tr><td>tr_acc</td><td>1.0</td></tr><tr><td>tr_epoch_loss</td><td>6e-05</td></tr><tr><td>val_acc_best</td><td>0.81667</td></tr><tr><td>val_acc_now</td><td>0.80417</td></tr><tr><td>val_loss</td><td>3.31616</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">vibrant-sweep-273</strong> at: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/0nng3hyw' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/0nng3hyw</a><br/> View project at: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>/data2/bh_wandb/wandb/run-20250430_094700-0nng3hyw/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require(\"core\")`! See https://wandb.me/wandb-core for more information."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Sweep Agent: Waiting for job.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Job received.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: wawdq4p5 with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBATCH: 16\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBN_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBPTT_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tDFA_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tIMAGE_SIZE: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tOTTT_input_trace_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tTIME: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tUDA_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \talpha_uda: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbias: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcfg: ['M', 'M', 200, 200]\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tchaching_on: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tconvTrue_fcFalse: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdata_path: /data2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tddp_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdenoise_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdvs_clipping: 5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdvs_duration: 100000\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepoch_num: 100\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \texclude_class: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \textra_train_dataset: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlast_lif: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.001\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_sg_width: 3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_decay: 0.5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_init: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_reset: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_threshold: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmerge_polarities: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmy_seed: 42\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnet_print: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_workers: 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer_what: SGD\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tpin_memory: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tpre_trained: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tpre_trained_path: net_save/save_now_net_weights_{unique_name}.pth\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \trate_coding: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tscheduler_name: no\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsingle_step: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsurrogate: hard_sigmoid\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_conv_kernel_size: 3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_conv_padding: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_conv_stride: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_trace_const1: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_trace_const2: 0.5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \ttdBN_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \ttrace_on: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \twhich_data: DVS_GESTURE_TONIC\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: W&B API key is configured. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "056c9ad051f3435baf2e218550b97d29",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.011113333065683644, max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.17.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/data2/bh_wandb/wandb/run-20250430_095314-wawdq4p5</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/wawdq4p5' target=\"_blank\">pious-sweep-275</a></strong> to <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/6pj3lh8j' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/6pj3lh8j</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/6pj3lh8j' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/6pj3lh8j</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/wawdq4p5' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/wawdq4p5</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'single_step' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'my_seed' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'TIME' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BATCH' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'IMAGE_SIZE' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'which_data' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'data_path' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'rate_coding' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_init' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_decay' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_threshold' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_reset' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_sg_width' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_conv_kernel_size' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_conv_stride' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_conv_padding' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_trace_const1' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_trace_const2' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'pre_trained' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'convTrue_fcFalse' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'cfg' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'net_print' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'pre_trained_path' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'learning_rate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'epoch_num' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'tdBN_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BN_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'surrogate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BPTT_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'optimizer_what' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'scheduler_name' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'ddp_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'dvs_clipping' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'dvs_duration' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'DFA_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'trace_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'OTTT_input_trace_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'exclude_class' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'merge_polarities' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'denoise_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'extra_train_dataset' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'num_workers' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'chaching_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'pin_memory' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'UDA_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'alpha_uda' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'bias' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'last_lif' was locked by 'sweep' (ignored update).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "param {'devices': '0', 'single_step': True, 'unique_name': 'main', 'my_seed': 42, 'TIME': 10, 'BATCH': 16, 'IMAGE_SIZE': 128, 'which_data': 'DVS_GESTURE_TONIC', 'data_path': '/data2', 'rate_coding': False, 'lif_layer_v_init': 0, 'lif_layer_v_decay': 0.5, 'lif_layer_v_threshold': 1, 'lif_layer_v_reset': 0, 'lif_layer_sg_width': 3, 'synapse_conv_kernel_size': 3, 'synapse_conv_stride': 1, 'synapse_conv_padding': 1, 'synapse_trace_const1': 1, 'synapse_trace_const2': 0.5, 'pre_trained': False, 'convTrue_fcFalse': False, 'cfg': ['M', 'M', 200, 200], 'net_print': True, 'pre_trained_path': 'net_save/save_now_net_weights_{unique_name}.pth', 'learning_rate': 0.001, 'epoch_num': 100, 'tdBN_on': False, 'BN_on': False, 'surrogate': 'hard_sigmoid', 'BPTT_on': False, 'optimizer_what': 'SGD', 'scheduler_name': 'no', 'ddp_on': False, 'dvs_clipping': 5, 'dvs_duration': 100000, 'DFA_on': False, 'trace_on': True, 'OTTT_input_trace_on': False, 'exclude_class': True, 'merge_polarities': False, 'denoise_on': False, 'extra_train_dataset': 0, 'num_workers': 2, 'chaching_on': True, 'pin_memory': True, 'UDA_on': False, 'alpha_uda': 1, 'bias': True, 'last_lif': False, 'current epoch': 0} \n",
      "\n",
      "dataset_hash = ffa516e60c3efd5e0208f72b4c36cb84\n",
      "cache path exists\n",
      "\n",
      "device ==> cuda\n",
      "\n",
      "DataParallel(\n",
      "  (module): REBORN_MY_SNN_FC(\n",
      "    (layers): REBORN_MY_Sequential(\n",
      "      (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (2): DimChanger_for_FC()\n",
      "      (3): SYNAPSE_FC(in_features=2048, out_features=200, TIME=10, bias=True, sstep=True)\n",
      "      (4): LIF_layer(v_init=0, v_decay=0.5, v_threshold=1, v_reset=0, sg_width=3, surrogate=hard_sigmoid, BPTT_on=False, trace_const1=1, trace_const2=0.5, TIME=10, sstep=True, trace_on=True)\n",
      "      (5): SYNAPSE_FC(in_features=200, out_features=200, TIME=10, bias=True, sstep=True)\n",
      "      (6): LIF_layer(v_init=0, v_decay=0.5, v_threshold=1, v_reset=0, sg_width=3, surrogate=hard_sigmoid, BPTT_on=False, trace_const1=1, trace_const2=0.5, TIME=10, sstep=True, trace_on=True)\n",
      "      (7): SYNAPSE_FC(in_features=200, out_features=10, TIME=10, bias=True, sstep=True)\n",
      "    )\n",
      "  )\n",
      ")\n",
      "\n",
      "========================================================\n",
      "Trainable parameters: 452,010\n",
      "========================================================\n",
      "\n",
      "epoch-0   lr=['0.0010000'], tr/val_loss:  2.305365/  2.302841, val:  10.00%, val_best:  10.00%, tr:   8.17%, tr_best:   8.17%\n",
      "epoch-1   lr=['0.0010000'], tr/val_loss:  2.304994/  2.302639, val:  10.00%, val_best:  10.00%, tr:   7.66%, tr_best:   8.17%\n",
      "epoch-2   lr=['0.0010000'], tr/val_loss:  2.305079/  2.302667, val:  10.00%, val_best:  10.00%, tr:   8.99%, tr_best:   8.99%\n",
      "epoch-3   lr=['0.0010000'], tr/val_loss:  2.304731/  2.302708, val:  10.00%, val_best:  10.00%, tr:   8.38%, tr_best:   8.99%\n",
      "epoch-4   lr=['0.0010000'], tr/val_loss:  2.304833/  2.302682, val:  10.00%, val_best:  10.00%, tr:   7.87%, tr_best:   8.99%\n",
      "epoch-5   lr=['0.0010000'], tr/val_loss:  2.304569/  2.302663, val:  10.00%, val_best:  10.00%, tr:   7.87%, tr_best:   8.99%\n",
      "epoch-6   lr=['0.0010000'], tr/val_loss:  2.305086/  2.302687, val:  10.00%, val_best:  10.00%, tr:   9.70%, tr_best:   9.70%\n",
      "epoch-7   lr=['0.0010000'], tr/val_loss:  2.304632/  2.302694, val:  10.00%, val_best:  10.00%, tr:   7.46%, tr_best:   9.70%\n",
      "epoch-8   lr=['0.0010000'], tr/val_loss:  2.304545/  2.302613, val:  10.00%, val_best:  10.00%, tr:   8.17%, tr_best:   9.70%\n",
      "epoch-9   lr=['0.0010000'], tr/val_loss:  2.305080/  2.302782, val:  10.00%, val_best:  10.00%, tr:   9.19%, tr_best:   9.70%\n",
      "epoch-10  lr=['0.0010000'], tr/val_loss:  2.304688/  2.302772, val:  10.00%, val_best:  10.00%, tr:  10.01%, tr_best:  10.01%\n",
      "epoch-11  lr=['0.0010000'], tr/val_loss:  2.304834/  2.302622, val:  10.00%, val_best:  10.00%, tr:   8.17%, tr_best:  10.01%\n",
      "epoch-12  lr=['0.0010000'], tr/val_loss:  2.304284/  2.302666, val:  10.00%, val_best:  10.00%, tr:   9.50%, tr_best:  10.01%\n",
      "epoch-13  lr=['0.0010000'], tr/val_loss:  2.304813/  2.302634, val:  10.00%, val_best:  10.00%, tr:   9.09%, tr_best:  10.01%\n",
      "epoch-14  lr=['0.0010000'], tr/val_loss:  2.305231/  2.302722, val:  10.00%, val_best:  10.00%, tr:   8.78%, tr_best:  10.01%\n",
      "epoch-15  lr=['0.0010000'], tr/val_loss:  2.305301/  2.302723, val:  10.00%, val_best:  10.00%, tr:   8.38%, tr_best:  10.01%\n",
      "epoch-16  lr=['0.0010000'], tr/val_loss:  2.304772/  2.302634, val:  10.00%, val_best:  10.00%, tr:   8.27%, tr_best:  10.01%\n",
      "epoch-17  lr=['0.0010000'], tr/val_loss:  2.303716/  2.302659, val:  10.00%, val_best:  10.00%, tr:  10.01%, tr_best:  10.01%\n",
      "epoch-18  lr=['0.0010000'], tr/val_loss:  2.304624/  2.302669, val:  10.00%, val_best:  10.00%, tr:   9.30%, tr_best:  10.01%\n",
      "epoch-19  lr=['0.0010000'], tr/val_loss:  2.305880/  2.302768, val:  10.00%, val_best:  10.00%, tr:   8.48%, tr_best:  10.01%\n",
      "epoch-20  lr=['0.0010000'], tr/val_loss:  2.305089/  2.302728, val:  10.00%, val_best:  10.00%, tr:   9.60%, tr_best:  10.01%\n",
      "epoch-21  lr=['0.0010000'], tr/val_loss:  2.304662/  2.302646, val:  10.00%, val_best:  10.00%, tr:   9.40%, tr_best:  10.01%\n",
      "epoch-22  lr=['0.0010000'], tr/val_loss:  2.305019/  2.302714, val:  10.00%, val_best:  10.00%, tr:  10.32%, tr_best:  10.32%\n",
      "epoch-23  lr=['0.0010000'], tr/val_loss:  2.304242/  2.302678, val:  10.00%, val_best:  10.00%, tr:   8.68%, tr_best:  10.32%\n",
      "epoch-24  lr=['0.0010000'], tr/val_loss:  2.303980/  2.302631, val:  10.00%, val_best:  10.00%, tr:   7.66%, tr_best:  10.32%\n",
      "epoch-25  lr=['0.0010000'], tr/val_loss:  2.304494/  2.302676, val:  10.00%, val_best:  10.00%, tr:   8.17%, tr_best:  10.32%\n",
      "epoch-26  lr=['0.0010000'], tr/val_loss:  2.304318/  2.302692, val:  10.00%, val_best:  10.00%, tr:   8.38%, tr_best:  10.32%\n",
      "epoch-27  lr=['0.0010000'], tr/val_loss:  2.304585/  2.302743, val:  10.00%, val_best:  10.00%, tr:   7.97%, tr_best:  10.32%\n",
      "epoch-28  lr=['0.0010000'], tr/val_loss:  2.304604/  2.302687, val:  10.00%, val_best:  10.00%, tr:   7.46%, tr_best:  10.32%\n",
      "epoch-29  lr=['0.0010000'], tr/val_loss:  2.304065/  2.302622, val:  10.00%, val_best:  10.00%, tr:   9.70%, tr_best:  10.32%\n",
      "epoch-30  lr=['0.0010000'], tr/val_loss:  2.304437/  2.302634, val:  10.00%, val_best:  10.00%, tr:   7.87%, tr_best:  10.32%\n",
      "epoch-31  lr=['0.0010000'], tr/val_loss:  2.304662/  2.302706, val:  10.00%, val_best:  10.00%, tr:   7.25%, tr_best:  10.32%\n",
      "epoch-32  lr=['0.0010000'], tr/val_loss:  2.305145/  2.302731, val:  10.00%, val_best:  10.00%, tr:   7.87%, tr_best:  10.32%\n",
      "epoch-33  lr=['0.0010000'], tr/val_loss:  2.304735/  2.302727, val:  10.00%, val_best:  10.00%, tr:   8.58%, tr_best:  10.32%\n",
      "epoch-34  lr=['0.0010000'], tr/val_loss:  2.304953/  2.302632, val:  10.00%, val_best:  10.00%, tr:   8.78%, tr_best:  10.32%\n",
      "epoch-35  lr=['0.0010000'], tr/val_loss:  2.304517/  2.302745, val:  10.00%, val_best:  10.00%, tr:   9.40%, tr_best:  10.32%\n",
      "epoch-36  lr=['0.0010000'], tr/val_loss:  2.304946/  2.302701, val:  10.00%, val_best:  10.00%, tr:   8.68%, tr_best:  10.32%\n",
      "epoch-37  lr=['0.0010000'], tr/val_loss:  2.305197/  2.302687, val:  10.00%, val_best:  10.00%, tr:   8.89%, tr_best:  10.32%\n",
      "epoch-38  lr=['0.0010000'], tr/val_loss:  2.304106/  2.302715, val:  10.00%, val_best:  10.00%, tr:   8.99%, tr_best:  10.32%\n",
      "epoch-39  lr=['0.0010000'], tr/val_loss:  2.304535/  2.302683, val:  10.00%, val_best:  10.00%, tr:   9.40%, tr_best:  10.32%\n",
      "epoch-40  lr=['0.0010000'], tr/val_loss:  2.304653/  2.302674, val:  10.00%, val_best:  10.00%, tr:   8.99%, tr_best:  10.32%\n",
      "epoch-41  lr=['0.0010000'], tr/val_loss:  2.304348/  2.302677, val:  10.00%, val_best:  10.00%, tr:   9.60%, tr_best:  10.32%\n",
      "epoch-42  lr=['0.0010000'], tr/val_loss:  2.304514/  2.302729, val:  10.00%, val_best:  10.00%, tr:   9.19%, tr_best:  10.32%\n",
      "epoch-43  lr=['0.0010000'], tr/val_loss:  2.304611/  2.302673, val:  10.00%, val_best:  10.00%, tr:   8.89%, tr_best:  10.32%\n",
      "epoch-44  lr=['0.0010000'], tr/val_loss:  2.304545/  2.302760, val:  10.00%, val_best:  10.00%, tr:   8.17%, tr_best:  10.32%\n",
      "epoch-45  lr=['0.0010000'], tr/val_loss:  2.304274/  2.302822, val:  10.00%, val_best:  10.00%, tr:   9.30%, tr_best:  10.32%\n",
      "epoch-46  lr=['0.0010000'], tr/val_loss:  2.304114/  2.302626, val:  10.00%, val_best:  10.00%, tr:   9.09%, tr_best:  10.32%\n",
      "epoch-47  lr=['0.0010000'], tr/val_loss:  2.304720/  2.302717, val:  10.00%, val_best:  10.00%, tr:   8.48%, tr_best:  10.32%\n",
      "epoch-48  lr=['0.0010000'], tr/val_loss:  2.304052/  2.302806, val:  10.00%, val_best:  10.00%, tr:   9.81%, tr_best:  10.32%\n",
      "epoch-49  lr=['0.0010000'], tr/val_loss:  2.304631/  2.302734, val:  10.00%, val_best:  10.00%, tr:   9.60%, tr_best:  10.32%\n",
      "epoch-50  lr=['0.0010000'], tr/val_loss:  2.304856/  2.302790, val:  10.00%, val_best:  10.00%, tr:  10.11%, tr_best:  10.32%\n",
      "epoch-51  lr=['0.0010000'], tr/val_loss:  2.303980/  2.302723, val:  10.00%, val_best:  10.00%, tr:   8.38%, tr_best:  10.32%\n",
      "epoch-52  lr=['0.0010000'], tr/val_loss:  2.305447/  2.302761, val:  10.00%, val_best:  10.00%, tr:   7.87%, tr_best:  10.32%\n",
      "epoch-53  lr=['0.0010000'], tr/val_loss:  2.304740/  2.302716, val:  10.00%, val_best:  10.00%, tr:   8.48%, tr_best:  10.32%\n",
      "epoch-54  lr=['0.0010000'], tr/val_loss:  2.304604/  2.302668, val:  10.00%, val_best:  10.00%, tr:   9.40%, tr_best:  10.32%\n",
      "epoch-55  lr=['0.0010000'], tr/val_loss:  2.304554/  2.302632, val:  10.00%, val_best:  10.00%, tr:   7.35%, tr_best:  10.32%\n",
      "epoch-56  lr=['0.0010000'], tr/val_loss:  2.305324/  2.302709, val:  10.00%, val_best:  10.00%, tr:  10.01%, tr_best:  10.32%\n",
      "epoch-57  lr=['0.0010000'], tr/val_loss:  2.304349/  2.302676, val:  10.00%, val_best:  10.00%, tr:   8.07%, tr_best:  10.32%\n",
      "epoch-58  lr=['0.0010000'], tr/val_loss:  2.304797/  2.302742, val:  10.00%, val_best:  10.00%, tr:   9.40%, tr_best:  10.32%\n",
      "epoch-59  lr=['0.0010000'], tr/val_loss:  2.305519/  2.302842, val:  10.00%, val_best:  10.00%, tr:   9.50%, tr_best:  10.32%\n",
      "epoch-60  lr=['0.0010000'], tr/val_loss:  2.304214/  2.302650, val:  10.00%, val_best:  10.00%, tr:   7.87%, tr_best:  10.32%\n",
      "epoch-61  lr=['0.0010000'], tr/val_loss:  2.304307/  2.302675, val:  10.00%, val_best:  10.00%, tr:   9.09%, tr_best:  10.32%\n",
      "epoch-62  lr=['0.0010000'], tr/val_loss:  2.304764/  2.302663, val:  10.00%, val_best:  10.00%, tr:   8.99%, tr_best:  10.32%\n",
      "epoch-63  lr=['0.0010000'], tr/val_loss:  2.304623/  2.302703, val:  10.00%, val_best:  10.00%, tr:   9.30%, tr_best:  10.32%\n",
      "epoch-64  lr=['0.0010000'], tr/val_loss:  2.303885/  2.302848, val:  10.00%, val_best:  10.00%, tr:   9.09%, tr_best:  10.32%\n",
      "epoch-65  lr=['0.0010000'], tr/val_loss:  2.304417/  2.302755, val:  10.00%, val_best:  10.00%, tr:   9.30%, tr_best:  10.32%\n",
      "epoch-66  lr=['0.0010000'], tr/val_loss:  2.303841/  2.302698, val:  10.00%, val_best:  10.00%, tr:   9.09%, tr_best:  10.32%\n",
      "epoch-67  lr=['0.0010000'], tr/val_loss:  2.305081/  2.302692, val:  10.00%, val_best:  10.00%, tr:  10.01%, tr_best:  10.32%\n",
      "epoch-68  lr=['0.0010000'], tr/val_loss:  2.305073/  2.302701, val:  10.00%, val_best:  10.00%, tr:   9.30%, tr_best:  10.32%\n",
      "epoch-69  lr=['0.0010000'], tr/val_loss:  2.304717/  2.302645, val:  10.00%, val_best:  10.00%, tr:   8.99%, tr_best:  10.32%\n",
      "epoch-70  lr=['0.0010000'], tr/val_loss:  2.305171/  2.302620, val:  10.00%, val_best:  10.00%, tr:   8.38%, tr_best:  10.32%\n",
      "epoch-71  lr=['0.0010000'], tr/val_loss:  2.305242/  2.302688, val:  10.00%, val_best:  10.00%, tr:   8.48%, tr_best:  10.32%\n",
      "epoch-72  lr=['0.0010000'], tr/val_loss:  2.304678/  2.302624, val:  10.00%, val_best:  10.00%, tr:   8.58%, tr_best:  10.32%\n",
      "epoch-73  lr=['0.0010000'], tr/val_loss:  2.304676/  2.302652, val:  10.00%, val_best:  10.00%, tr:   8.48%, tr_best:  10.32%\n",
      "epoch-74  lr=['0.0010000'], tr/val_loss:  2.304883/  2.302660, val:  10.00%, val_best:  10.00%, tr:   9.30%, tr_best:  10.32%\n",
      "epoch-75  lr=['0.0010000'], tr/val_loss:  2.305337/  2.302700, val:  10.00%, val_best:  10.00%, tr:   9.19%, tr_best:  10.32%\n",
      "epoch-76  lr=['0.0010000'], tr/val_loss:  2.305019/  2.302656, val:  10.00%, val_best:  10.00%, tr:   8.17%, tr_best:  10.32%\n",
      "epoch-77  lr=['0.0010000'], tr/val_loss:  2.305215/  2.302638, val:  10.00%, val_best:  10.00%, tr:   8.89%, tr_best:  10.32%\n",
      "epoch-78  lr=['0.0010000'], tr/val_loss:  2.304676/  2.302660, val:  10.00%, val_best:  10.00%, tr:   9.09%, tr_best:  10.32%\n",
      "epoch-79  lr=['0.0010000'], tr/val_loss:  2.304999/  2.302665, val:  10.00%, val_best:  10.00%, tr:   9.81%, tr_best:  10.32%\n",
      "epoch-80  lr=['0.0010000'], tr/val_loss:  2.304617/  2.302732, val:  10.00%, val_best:  10.00%, tr:   7.35%, tr_best:  10.32%\n",
      "epoch-81  lr=['0.0010000'], tr/val_loss:  2.304430/  2.302707, val:  10.00%, val_best:  10.00%, tr:   7.66%, tr_best:  10.32%\n",
      "epoch-82  lr=['0.0010000'], tr/val_loss:  2.304436/  2.302796, val:  10.00%, val_best:  10.00%, tr:   9.30%, tr_best:  10.32%\n",
      "epoch-83  lr=['0.0010000'], tr/val_loss:  2.305023/  2.302669, val:  10.00%, val_best:  10.00%, tr:   7.66%, tr_best:  10.32%\n",
      "epoch-84  lr=['0.0010000'], tr/val_loss:  2.304577/  2.302758, val:  10.00%, val_best:  10.00%, tr:   8.89%, tr_best:  10.32%\n",
      "epoch-85  lr=['0.0010000'], tr/val_loss:  2.304359/  2.302626, val:  10.00%, val_best:  10.00%, tr:   8.07%, tr_best:  10.32%\n",
      "epoch-86  lr=['0.0010000'], tr/val_loss:  2.305443/  2.302771, val:  10.00%, val_best:  10.00%, tr:   8.17%, tr_best:  10.32%\n",
      "epoch-87  lr=['0.0010000'], tr/val_loss:  2.304418/  2.302737, val:  10.00%, val_best:  10.00%, tr:   8.78%, tr_best:  10.32%\n",
      "epoch-88  lr=['0.0010000'], tr/val_loss:  2.305364/  2.302662, val:  10.00%, val_best:  10.00%, tr:   8.68%, tr_best:  10.32%\n",
      "epoch-89  lr=['0.0010000'], tr/val_loss:  2.304665/  2.302694, val:  10.00%, val_best:  10.00%, tr:   8.89%, tr_best:  10.32%\n",
      "epoch-90  lr=['0.0010000'], tr/val_loss:  2.305019/  2.302693, val:  10.00%, val_best:  10.00%, tr:   8.38%, tr_best:  10.32%\n",
      "epoch-91  lr=['0.0010000'], tr/val_loss:  2.304266/  2.302669, val:  10.00%, val_best:  10.00%, tr:  10.21%, tr_best:  10.32%\n",
      "epoch-92  lr=['0.0010000'], tr/val_loss:  2.304705/  2.302684, val:  10.00%, val_best:  10.00%, tr:   9.40%, tr_best:  10.32%\n",
      "epoch-93  lr=['0.0010000'], tr/val_loss:  2.304860/  2.302634, val:  10.00%, val_best:  10.00%, tr:   8.68%, tr_best:  10.32%\n",
      "epoch-94  lr=['0.0010000'], tr/val_loss:  2.304419/  2.302675, val:  10.00%, val_best:  10.00%, tr:   8.89%, tr_best:  10.32%\n",
      "epoch-95  lr=['0.0010000'], tr/val_loss:  2.304308/  2.302676, val:  10.00%, val_best:  10.00%, tr:   8.17%, tr_best:  10.32%\n",
      "epoch-96  lr=['0.0010000'], tr/val_loss:  2.304734/  2.302685, val:  10.00%, val_best:  10.00%, tr:  10.11%, tr_best:  10.32%\n",
      "epoch-97  lr=['0.0010000'], tr/val_loss:  2.304735/  2.302724, val:  10.00%, val_best:  10.00%, tr:   9.09%, tr_best:  10.32%\n",
      "epoch-98  lr=['0.0010000'], tr/val_loss:  2.305681/  2.302760, val:  10.00%, val_best:  10.00%, tr:  10.11%, tr_best:  10.32%\n",
      "epoch-99  lr=['0.0010000'], tr/val_loss:  2.304706/  2.302780, val:  10.00%, val_best:  10.00%, tr:   9.50%, tr_best:  10.32%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "35d35ea0e768495b8af6cdd8df9a28fb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.006 MB of 0.006 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>iter_acc</td><td>▃▆▁▃▃▃▃▃▃▃▃▁▃▆▃▆▆▃██▃▃▁▃▁▃▁▃▃▁▃▆▃▁▁▁█▃▁▃</td></tr><tr><td>summary_val_acc</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>tr_acc</td><td>▃▅▂▁▆▇▅█▄▆▂▄▇▂▆▅▆▆▃▄▇▂▆▃▇▅▆█▄▄▆▅▇▆▅▅▅▆▃▅</td></tr><tr><td>tr_epoch_loss</td><td>▆▅▅▄▅▃▆▁█▄▂▃▂▆▄▆▄▄▄▄▄▇▄▃▇▃▃▅▆▄▆▆▅▃▄▃▄▄▃▄</td></tr><tr><td>val_acc_best</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_acc_now</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_loss</td><td>█▂▃▃▆▂▄▂▆▂▁▃▁▅▅▃▃▄▅▄▅▅▃▃█▃▅▃▁▁▄▂▂▇▅▅▃▃▃▄</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>99</td></tr><tr><td>iter_acc</td><td>0.0</td></tr><tr><td>tr_acc</td><td>0.09499</td></tr><tr><td>tr_epoch_loss</td><td>2.30471</td></tr><tr><td>val_acc_best</td><td>0.1</td></tr><tr><td>val_acc_now</td><td>0.1</td></tr><tr><td>val_loss</td><td>2.30278</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">pious-sweep-275</strong> at: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/wawdq4p5' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/wawdq4p5</a><br/> View project at: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>/data2/bh_wandb/wandb/run-20250430_095314-wawdq4p5/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require(\"core\")`! See https://wandb.me/wandb-core for more information."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 76d2u954 with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBATCH: 16\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBN_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBPTT_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tDFA_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tIMAGE_SIZE: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tOTTT_input_trace_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tTIME: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tUDA_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \talpha_uda: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbias: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcfg: ['M', 'M', 200, 200]\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tchaching_on: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tconvTrue_fcFalse: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdata_path: /data2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tddp_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdenoise_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdvs_clipping: 5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdvs_duration: 100000\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepoch_num: 100\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \texclude_class: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \textra_train_dataset: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlast_lif: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.001\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_sg_width: 3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_decay: 0.5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_init: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_reset: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_threshold: 0.75\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmerge_polarities: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmy_seed: 42\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnet_print: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_workers: 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer_what: SGD\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tpin_memory: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tpre_trained: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tpre_trained_path: net_save/save_now_net_weights_{unique_name}.pth\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \trate_coding: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tscheduler_name: no\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsingle_step: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsurrogate: hard_sigmoid\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_conv_kernel_size: 3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_conv_padding: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_conv_stride: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_trace_const1: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_trace_const2: 0.5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \ttdBN_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \ttrace_on: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \twhich_data: DVS_GESTURE_TONIC\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.19.10 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.17.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/data2/bh_wandb/wandb/run-20250430_095928-76d2u954</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/76d2u954' target=\"_blank\">stellar-sweep-277</a></strong> to <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/6pj3lh8j' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/6pj3lh8j</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/6pj3lh8j' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/6pj3lh8j</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/76d2u954' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/76d2u954</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'single_step' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'my_seed' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'TIME' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BATCH' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'IMAGE_SIZE' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'which_data' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'data_path' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'rate_coding' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_init' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_decay' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_threshold' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_reset' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_sg_width' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_conv_kernel_size' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_conv_stride' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_conv_padding' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_trace_const1' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_trace_const2' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'pre_trained' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'convTrue_fcFalse' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'cfg' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'net_print' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'pre_trained_path' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'learning_rate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'epoch_num' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'tdBN_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BN_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'surrogate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BPTT_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'optimizer_what' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'scheduler_name' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'ddp_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'dvs_clipping' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'dvs_duration' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'DFA_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'trace_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'OTTT_input_trace_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'exclude_class' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'merge_polarities' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'denoise_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'extra_train_dataset' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'num_workers' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'chaching_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'pin_memory' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'UDA_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'alpha_uda' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'bias' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'last_lif' was locked by 'sweep' (ignored update).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "param {'devices': '0', 'single_step': True, 'unique_name': 'main', 'my_seed': 42, 'TIME': 10, 'BATCH': 16, 'IMAGE_SIZE': 128, 'which_data': 'DVS_GESTURE_TONIC', 'data_path': '/data2', 'rate_coding': False, 'lif_layer_v_init': 0, 'lif_layer_v_decay': 0.5, 'lif_layer_v_threshold': 0.75, 'lif_layer_v_reset': 0, 'lif_layer_sg_width': 3, 'synapse_conv_kernel_size': 3, 'synapse_conv_stride': 1, 'synapse_conv_padding': 1, 'synapse_trace_const1': 1, 'synapse_trace_const2': 0.5, 'pre_trained': False, 'convTrue_fcFalse': False, 'cfg': ['M', 'M', 200, 200], 'net_print': True, 'pre_trained_path': 'net_save/save_now_net_weights_{unique_name}.pth', 'learning_rate': 0.001, 'epoch_num': 100, 'tdBN_on': False, 'BN_on': False, 'surrogate': 'hard_sigmoid', 'BPTT_on': False, 'optimizer_what': 'SGD', 'scheduler_name': 'no', 'ddp_on': False, 'dvs_clipping': 5, 'dvs_duration': 100000, 'DFA_on': False, 'trace_on': True, 'OTTT_input_trace_on': False, 'exclude_class': True, 'merge_polarities': False, 'denoise_on': False, 'extra_train_dataset': 0, 'num_workers': 2, 'chaching_on': True, 'pin_memory': True, 'UDA_on': False, 'alpha_uda': 1, 'bias': True, 'last_lif': False, 'current epoch': 0} \n",
      "\n",
      "dataset_hash = ffa516e60c3efd5e0208f72b4c36cb84\n",
      "cache path exists\n",
      "\n",
      "device ==> cuda\n",
      "\n",
      "DataParallel(\n",
      "  (module): REBORN_MY_SNN_FC(\n",
      "    (layers): REBORN_MY_Sequential(\n",
      "      (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (2): DimChanger_for_FC()\n",
      "      (3): SYNAPSE_FC(in_features=2048, out_features=200, TIME=10, bias=True, sstep=True)\n",
      "      (4): LIF_layer(v_init=0, v_decay=0.5, v_threshold=0.75, v_reset=0, sg_width=3, surrogate=hard_sigmoid, BPTT_on=False, trace_const1=1, trace_const2=0.5, TIME=10, sstep=True, trace_on=True)\n",
      "      (5): SYNAPSE_FC(in_features=200, out_features=200, TIME=10, bias=True, sstep=True)\n",
      "      (6): LIF_layer(v_init=0, v_decay=0.5, v_threshold=0.75, v_reset=0, sg_width=3, surrogate=hard_sigmoid, BPTT_on=False, trace_const1=1, trace_const2=0.5, TIME=10, sstep=True, trace_on=True)\n",
      "      (7): SYNAPSE_FC(in_features=200, out_features=10, TIME=10, bias=True, sstep=True)\n",
      "    )\n",
      "  )\n",
      ")\n",
      "\n",
      "========================================================\n",
      "Trainable parameters: 452,010\n",
      "========================================================\n",
      "\n",
      "epoch-0   lr=['0.0010000'], tr/val_loss:  2.305365/  2.302841, val:  10.00%, val_best:  10.00%, tr:   8.17%, tr_best:   8.17%\n",
      "epoch-1   lr=['0.0010000'], tr/val_loss:  2.304994/  2.302639, val:  10.00%, val_best:  10.00%, tr:   7.66%, tr_best:   8.17%\n",
      "epoch-2   lr=['0.0010000'], tr/val_loss:  2.305079/  2.302667, val:  10.00%, val_best:  10.00%, tr:   8.99%, tr_best:   8.99%\n",
      "epoch-3   lr=['0.0010000'], tr/val_loss:  2.304731/  2.302685, val:  10.00%, val_best:  10.00%, tr:   8.38%, tr_best:   8.99%\n",
      "epoch-4   lr=['0.0010000'], tr/val_loss:  2.303970/  2.300286, val:  12.92%, val_best:  12.92%, tr:   8.78%, tr_best:   8.99%\n",
      "epoch-5   lr=['0.0010000'], tr/val_loss:  2.266850/  2.223145, val:  21.67%, val_best:  21.67%, tr:  12.77%, tr_best:  12.77%\n",
      "epoch-6   lr=['0.0010000'], tr/val_loss:  2.151572/  2.110335, val:  31.25%, val_best:  31.25%, tr:  21.76%, tr_best:  21.76%\n",
      "epoch-7   lr=['0.0010000'], tr/val_loss:  1.939990/  1.885307, val:  39.17%, val_best:  39.17%, tr:  37.08%, tr_best:  37.08%\n",
      "epoch-8   lr=['0.0010000'], tr/val_loss:  1.646641/  1.652577, val:  47.92%, val_best:  47.92%, tr:  48.31%, tr_best:  48.31%\n",
      "epoch-9   lr=['0.0010000'], tr/val_loss:  1.453878/  1.513590, val:  52.50%, val_best:  52.50%, tr:  56.38%, tr_best:  56.38%\n",
      "epoch-10  lr=['0.0010000'], tr/val_loss:  1.321565/  1.472058, val:  53.33%, val_best:  53.33%, tr:  57.61%, tr_best:  57.61%\n",
      "epoch-11  lr=['0.0010000'], tr/val_loss:  1.219938/  1.402524, val:  56.67%, val_best:  56.67%, tr:  60.78%, tr_best:  60.78%\n",
      "epoch-12  lr=['0.0010000'], tr/val_loss:  1.167811/  1.399071, val:  60.00%, val_best:  60.00%, tr:  63.74%, tr_best:  63.74%\n",
      "epoch-13  lr=['0.0010000'], tr/val_loss:  1.113411/  1.390927, val:  62.08%, val_best:  62.08%, tr:  64.04%, tr_best:  64.04%\n",
      "epoch-14  lr=['0.0010000'], tr/val_loss:  1.028220/  1.467012, val:  59.58%, val_best:  62.08%, tr:  66.80%, tr_best:  66.80%\n",
      "epoch-15  lr=['0.0010000'], tr/val_loss:  0.993782/  1.445762, val:  60.83%, val_best:  62.08%, tr:  69.77%, tr_best:  69.77%\n",
      "epoch-16  lr=['0.0010000'], tr/val_loss:  0.973963/  1.380201, val:  61.25%, val_best:  62.08%, tr:  69.36%, tr_best:  69.77%\n",
      "epoch-17  lr=['0.0010000'], tr/val_loss:  0.898587/  1.433164, val:  62.92%, val_best:  62.92%, tr:  74.46%, tr_best:  74.46%\n",
      "epoch-18  lr=['0.0010000'], tr/val_loss:  0.859039/  1.482218, val:  59.58%, val_best:  62.92%, tr:  74.26%, tr_best:  74.46%\n",
      "epoch-19  lr=['0.0010000'], tr/val_loss:  0.836308/  1.482054, val:  61.25%, val_best:  62.92%, tr:  74.57%, tr_best:  74.57%\n",
      "epoch-20  lr=['0.0010000'], tr/val_loss:  0.780082/  1.534104, val:  63.75%, val_best:  63.75%, tr:  76.61%, tr_best:  76.61%\n",
      "epoch-21  lr=['0.0010000'], tr/val_loss:  0.747825/  1.508027, val:  64.58%, val_best:  64.58%, tr:  77.63%, tr_best:  77.63%\n",
      "epoch-22  lr=['0.0010000'], tr/val_loss:  0.752574/  1.504900, val:  65.42%, val_best:  65.42%, tr:  78.14%, tr_best:  78.14%\n",
      "epoch-23  lr=['0.0010000'], tr/val_loss:  0.695559/  1.570274, val:  70.42%, val_best:  70.42%, tr:  79.26%, tr_best:  79.26%\n",
      "epoch-24  lr=['0.0010000'], tr/val_loss:  0.660923/  1.634242, val:  63.33%, val_best:  70.42%, tr:  82.53%, tr_best:  82.53%\n",
      "epoch-25  lr=['0.0010000'], tr/val_loss:  0.633465/  1.582800, val:  68.33%, val_best:  70.42%, tr:  83.66%, tr_best:  83.66%\n",
      "epoch-26  lr=['0.0010000'], tr/val_loss:  0.621471/  1.697049, val:  70.83%, val_best:  70.83%, tr:  82.43%, tr_best:  83.66%\n",
      "epoch-27  lr=['0.0010000'], tr/val_loss:  0.590634/  1.838978, val:  67.50%, val_best:  70.83%, tr:  84.68%, tr_best:  84.68%\n",
      "epoch-28  lr=['0.0010000'], tr/val_loss:  0.587593/  1.715264, val:  67.50%, val_best:  70.83%, tr:  85.29%, tr_best:  85.29%\n",
      "epoch-29  lr=['0.0010000'], tr/val_loss:  0.545049/  1.886021, val:  63.33%, val_best:  70.83%, tr:  87.03%, tr_best:  87.03%\n",
      "epoch-30  lr=['0.0010000'], tr/val_loss:  0.526052/  1.863875, val:  67.50%, val_best:  70.83%, tr:  88.36%, tr_best:  88.36%\n",
      "epoch-31  lr=['0.0010000'], tr/val_loss:  0.524272/  1.978001, val:  68.75%, val_best:  70.83%, tr:  88.36%, tr_best:  88.36%\n",
      "epoch-32  lr=['0.0010000'], tr/val_loss:  0.512025/  1.984848, val:  67.08%, val_best:  70.83%, tr:  89.27%, tr_best:  89.27%\n",
      "epoch-33  lr=['0.0010000'], tr/val_loss:  0.469550/  1.889508, val:  67.92%, val_best:  70.83%, tr:  91.42%, tr_best:  91.42%\n",
      "epoch-34  lr=['0.0010000'], tr/val_loss:  0.466441/  2.122459, val:  60.42%, val_best:  70.83%, tr:  93.05%, tr_best:  93.05%\n",
      "epoch-35  lr=['0.0010000'], tr/val_loss:  0.455602/  2.137835, val:  66.67%, val_best:  70.83%, tr:  90.50%, tr_best:  93.05%\n",
      "epoch-36  lr=['0.0010000'], tr/val_loss:  0.396273/  2.043257, val:  73.33%, val_best:  73.33%, tr:  93.56%, tr_best:  93.56%\n",
      "epoch-37  lr=['0.0010000'], tr/val_loss:  0.379854/  2.190035, val:  64.17%, val_best:  73.33%, tr:  96.02%, tr_best:  96.02%\n",
      "epoch-38  lr=['0.0010000'], tr/val_loss:  0.387463/  2.202960, val:  67.92%, val_best:  73.33%, tr:  95.40%, tr_best:  96.02%\n",
      "epoch-39  lr=['0.0010000'], tr/val_loss:  0.361975/  2.260381, val:  68.75%, val_best:  73.33%, tr:  95.20%, tr_best:  96.02%\n",
      "epoch-40  lr=['0.0010000'], tr/val_loss:  0.335043/  2.234946, val:  74.58%, val_best:  74.58%, tr:  94.89%, tr_best:  96.02%\n",
      "epoch-41  lr=['0.0010000'], tr/val_loss:  0.291443/  2.452466, val:  68.75%, val_best:  74.58%, tr:  97.34%, tr_best:  97.34%\n",
      "epoch-42  lr=['0.0010000'], tr/val_loss:  0.288521/  2.363687, val:  69.58%, val_best:  74.58%, tr:  98.67%, tr_best:  98.67%\n",
      "epoch-43  lr=['0.0010000'], tr/val_loss:  0.280412/  2.506076, val:  67.08%, val_best:  74.58%, tr:  97.24%, tr_best:  98.67%\n",
      "epoch-44  lr=['0.0010000'], tr/val_loss:  0.276817/  2.513804, val:  66.25%, val_best:  74.58%, tr:  97.45%, tr_best:  98.67%\n",
      "epoch-45  lr=['0.0010000'], tr/val_loss:  0.262132/  2.513437, val:  72.50%, val_best:  74.58%, tr:  98.57%, tr_best:  98.67%\n",
      "epoch-46  lr=['0.0010000'], tr/val_loss:  0.245306/  2.633677, val:  75.00%, val_best:  75.00%, tr:  99.28%, tr_best:  99.28%\n",
      "epoch-47  lr=['0.0010000'], tr/val_loss:  0.220030/  2.642635, val:  72.50%, val_best:  75.00%, tr:  99.59%, tr_best:  99.59%\n",
      "epoch-48  lr=['0.0010000'], tr/val_loss:  0.246614/  2.623805, val:  73.33%, val_best:  75.00%, tr:  99.28%, tr_best:  99.59%\n",
      "epoch-49  lr=['0.0010000'], tr/val_loss:  0.204675/  2.713542, val:  72.92%, val_best:  75.00%, tr:  99.69%, tr_best:  99.69%\n",
      "epoch-50  lr=['0.0010000'], tr/val_loss:  0.172289/  2.761939, val:  73.75%, val_best:  75.00%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-51  lr=['0.0010000'], tr/val_loss:  0.169991/  2.814834, val:  70.83%, val_best:  75.00%, tr:  99.90%, tr_best: 100.00%\n",
      "epoch-52  lr=['0.0010000'], tr/val_loss:  0.140889/  2.832815, val:  74.58%, val_best:  75.00%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-53  lr=['0.0010000'], tr/val_loss:  0.134607/  2.971972, val:  71.25%, val_best:  75.00%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-54  lr=['0.0010000'], tr/val_loss:  0.141561/  2.934206, val:  73.33%, val_best:  75.00%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-55  lr=['0.0010000'], tr/val_loss:  0.143650/  3.019687, val:  73.33%, val_best:  75.00%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-56  lr=['0.0010000'], tr/val_loss:  0.118625/  3.055392, val:  75.00%, val_best:  75.00%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-57  lr=['0.0010000'], tr/val_loss:  0.111935/  3.100556, val:  75.00%, val_best:  75.00%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-58  lr=['0.0010000'], tr/val_loss:  0.105747/  3.122471, val:  76.25%, val_best:  76.25%, tr:  99.90%, tr_best: 100.00%\n",
      "epoch-59  lr=['0.0010000'], tr/val_loss:  0.089845/  3.271757, val:  75.83%, val_best:  76.25%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-60  lr=['0.0010000'], tr/val_loss:  0.080128/  3.283470, val:  75.83%, val_best:  76.25%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-61  lr=['0.0010000'], tr/val_loss:  0.089994/  3.294154, val:  74.17%, val_best:  76.25%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-62  lr=['0.0010000'], tr/val_loss:  0.088433/  3.335949, val:  75.83%, val_best:  76.25%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-63  lr=['0.0010000'], tr/val_loss:  0.063911/  3.378436, val:  74.17%, val_best:  76.25%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-64  lr=['0.0010000'], tr/val_loss:  0.066177/  3.379838, val:  75.00%, val_best:  76.25%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-65  lr=['0.0010000'], tr/val_loss:  0.060534/  3.362495, val:  77.50%, val_best:  77.50%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-66  lr=['0.0010000'], tr/val_loss:  0.057633/  3.524351, val:  74.17%, val_best:  77.50%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-67  lr=['0.0010000'], tr/val_loss:  0.060329/  3.568663, val:  74.58%, val_best:  77.50%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-68  lr=['0.0010000'], tr/val_loss:  0.064228/  3.483548, val:  76.25%, val_best:  77.50%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-69  lr=['0.0010000'], tr/val_loss:  0.051749/  3.559905, val:  73.33%, val_best:  77.50%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-70  lr=['0.0010000'], tr/val_loss:  0.041654/  3.470634, val:  75.00%, val_best:  77.50%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-71  lr=['0.0010000'], tr/val_loss:  0.041840/  3.610543, val:  75.42%, val_best:  77.50%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-72  lr=['0.0010000'], tr/val_loss:  0.047559/  3.623110, val:  75.00%, val_best:  77.50%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-73  lr=['0.0010000'], tr/val_loss:  0.045073/  3.525622, val:  74.58%, val_best:  77.50%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-74  lr=['0.0010000'], tr/val_loss:  0.042243/  3.644428, val:  74.58%, val_best:  77.50%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-75  lr=['0.0010000'], tr/val_loss:  0.042691/  3.596664, val:  77.08%, val_best:  77.50%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-76  lr=['0.0010000'], tr/val_loss:  0.033742/  3.734175, val:  75.42%, val_best:  77.50%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-77  lr=['0.0010000'], tr/val_loss:  0.028277/  3.663353, val:  77.08%, val_best:  77.50%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-78  lr=['0.0010000'], tr/val_loss:  0.039617/  3.776391, val:  77.92%, val_best:  77.92%, tr:  99.80%, tr_best: 100.00%\n",
      "epoch-79  lr=['0.0010000'], tr/val_loss:  0.035491/  3.819743, val:  76.67%, val_best:  77.92%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-80  lr=['0.0010000'], tr/val_loss:  0.040714/  3.702626, val:  75.83%, val_best:  77.92%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-81  lr=['0.0010000'], tr/val_loss:  0.027903/  3.781718, val:  75.83%, val_best:  77.92%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-82  lr=['0.0010000'], tr/val_loss:  0.038269/  3.810431, val:  76.25%, val_best:  77.92%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-83  lr=['0.0010000'], tr/val_loss:  0.028531/  3.812777, val:  78.33%, val_best:  78.33%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-84  lr=['0.0010000'], tr/val_loss:  0.034069/  3.873062, val:  78.33%, val_best:  78.33%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-85  lr=['0.0010000'], tr/val_loss:  0.029454/  3.902336, val:  76.67%, val_best:  78.33%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-86  lr=['0.0010000'], tr/val_loss:  0.038241/  3.903589, val:  75.42%, val_best:  78.33%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-87  lr=['0.0010000'], tr/val_loss:  0.032266/  3.766485, val:  77.92%, val_best:  78.33%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-88  lr=['0.0010000'], tr/val_loss:  0.038972/  3.898949, val:  78.33%, val_best:  78.33%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-89  lr=['0.0010000'], tr/val_loss:  0.031770/  3.947400, val:  73.33%, val_best:  78.33%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-90  lr=['0.0010000'], tr/val_loss:  0.050826/  3.902719, val:  75.83%, val_best:  78.33%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-91  lr=['0.0010000'], tr/val_loss:  0.028473/  3.885158, val:  77.08%, val_best:  78.33%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-92  lr=['0.0010000'], tr/val_loss:  0.021009/  3.888304, val:  79.17%, val_best:  79.17%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-93  lr=['0.0010000'], tr/val_loss:  0.016330/  3.910305, val:  78.75%, val_best:  79.17%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-94  lr=['0.0010000'], tr/val_loss:  0.013415/  4.048976, val:  76.67%, val_best:  79.17%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-95  lr=['0.0010000'], tr/val_loss:  0.014304/  4.021394, val:  79.17%, val_best:  79.17%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-96  lr=['0.0010000'], tr/val_loss:  0.012186/  4.021070, val:  78.33%, val_best:  79.17%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-97  lr=['0.0010000'], tr/val_loss:  0.010869/  4.033346, val:  78.33%, val_best:  79.17%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-98  lr=['0.0010000'], tr/val_loss:  0.006432/  4.049345, val:  77.08%, val_best:  79.17%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-99  lr=['0.0010000'], tr/val_loss:  0.010818/  4.045818, val:  79.17%, val_best:  79.17%, tr: 100.00%, tr_best: 100.00%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5a6c32eb7e24499285517735d5edd488",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.006 MB of 0.006 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: Network error (ConnectionError), entering retry loop.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>iter_acc</td><td>▁▂▁▄▅▆▇▄▅▇▇▇▇█▇██▇██████████████████████</td></tr><tr><td>summary_val_acc</td><td>▁▁▁▄▅▆▆▆▆▇▆▇▆▇▇▆▇▇▇▇▇█▇██▇██████████▇███</td></tr><tr><td>tr_acc</td><td>▁▁▁▃▅▅▅▆▆▆▇▇▇▇▇█████████████████████████</td></tr><tr><td>tr_epoch_loss</td><td>███▇▅▅▄▄▄▃▃▃▃▃▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_acc_best</td><td>▁▁▁▄▅▆▆▆▆▇▇▇▇▇▇▇▇███████████████████████</td></tr><tr><td>val_acc_now</td><td>▁▁▁▄▅▆▆▆▆▇▆▇▆▇▇▆▇▇▇▇▇█▇██▇██████████▇███</td></tr><tr><td>val_loss</td><td>▃▃▃▂▁▁▁▁▁▁▂▂▂▃▃▃▃▄▄▄▄▅▅▆▆▆▆▇▇▇▇▇▇▇█▇████</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>99</td></tr><tr><td>iter_acc</td><td>1.0</td></tr><tr><td>tr_acc</td><td>1.0</td></tr><tr><td>tr_epoch_loss</td><td>0.01082</td></tr><tr><td>val_acc_best</td><td>0.79167</td></tr><tr><td>val_acc_now</td><td>0.79167</td></tr><tr><td>val_loss</td><td>4.04582</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">stellar-sweep-277</strong> at: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/76d2u954' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/76d2u954</a><br/> View project at: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>/data2/bh_wandb/wandb/run-20250430_095928-76d2u954/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require(\"core\")`! See https://wandb.me/wandb-core for more information."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 13jc0dco with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBATCH: 16\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBN_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBPTT_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tDFA_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tIMAGE_SIZE: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tOTTT_input_trace_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tTIME: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tUDA_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \talpha_uda: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbias: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcfg: ['M', 'M', 200, 200]\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tchaching_on: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tconvTrue_fcFalse: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdata_path: /data2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tddp_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdenoise_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdvs_clipping: 5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdvs_duration: 100000\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepoch_num: 100\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \texclude_class: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \textra_train_dataset: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlast_lif: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_sg_width: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_decay: 0.5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_init: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_reset: 10000\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_threshold: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmerge_polarities: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmy_seed: 42\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnet_print: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_workers: 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer_what: SGD\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tpin_memory: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tpre_trained: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tpre_trained_path: net_save/save_now_net_weights_{unique_name}.pth\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \trate_coding: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tscheduler_name: no\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsingle_step: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsurrogate: hard_sigmoid\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_conv_kernel_size: 3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_conv_padding: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_conv_stride: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_trace_const1: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_trace_const2: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \ttdBN_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \ttrace_on: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \twhich_data: DVS_GESTURE_TONIC\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "44385d8f135848458c3d1e5faf0cf1f4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.011112775824343165, max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.19.10 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.17.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/data2/bh_wandb/wandb/run-20250430_100555-13jc0dco</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/13jc0dco' target=\"_blank\">fresh-sweep-279</a></strong> to <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/6pj3lh8j' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/6pj3lh8j</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/6pj3lh8j' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/6pj3lh8j</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/13jc0dco' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/13jc0dco</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'single_step' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'my_seed' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'TIME' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BATCH' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'IMAGE_SIZE' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'which_data' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'data_path' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'rate_coding' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_init' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_decay' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_threshold' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_reset' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_sg_width' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_conv_kernel_size' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_conv_stride' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_conv_padding' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_trace_const1' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_trace_const2' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'pre_trained' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'convTrue_fcFalse' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'cfg' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'net_print' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'pre_trained_path' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'learning_rate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'epoch_num' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'tdBN_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BN_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'surrogate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BPTT_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'optimizer_what' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'scheduler_name' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'ddp_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'dvs_clipping' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'dvs_duration' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'DFA_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'trace_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'OTTT_input_trace_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'exclude_class' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'merge_polarities' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'denoise_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'extra_train_dataset' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'num_workers' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'chaching_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'pin_memory' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'UDA_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'alpha_uda' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'bias' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'last_lif' was locked by 'sweep' (ignored update).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "param {'devices': '0', 'single_step': True, 'unique_name': 'main', 'my_seed': 42, 'TIME': 10, 'BATCH': 16, 'IMAGE_SIZE': 128, 'which_data': 'DVS_GESTURE_TONIC', 'data_path': '/data2', 'rate_coding': False, 'lif_layer_v_init': 0, 'lif_layer_v_decay': 0.5, 'lif_layer_v_threshold': 1, 'lif_layer_v_reset': 10000, 'lif_layer_sg_width': 1, 'synapse_conv_kernel_size': 3, 'synapse_conv_stride': 1, 'synapse_conv_padding': 1, 'synapse_trace_const1': 1, 'synapse_trace_const2': 0, 'pre_trained': False, 'convTrue_fcFalse': False, 'cfg': ['M', 'M', 200, 200], 'net_print': True, 'pre_trained_path': 'net_save/save_now_net_weights_{unique_name}.pth', 'learning_rate': 0.1, 'epoch_num': 100, 'tdBN_on': False, 'BN_on': False, 'surrogate': 'hard_sigmoid', 'BPTT_on': False, 'optimizer_what': 'SGD', 'scheduler_name': 'no', 'ddp_on': False, 'dvs_clipping': 5, 'dvs_duration': 100000, 'DFA_on': False, 'trace_on': True, 'OTTT_input_trace_on': False, 'exclude_class': True, 'merge_polarities': False, 'denoise_on': False, 'extra_train_dataset': 0, 'num_workers': 2, 'chaching_on': True, 'pin_memory': True, 'UDA_on': False, 'alpha_uda': 1, 'bias': True, 'last_lif': False, 'current epoch': 0} \n",
      "\n",
      "dataset_hash = ffa516e60c3efd5e0208f72b4c36cb84\n",
      "cache path exists\n",
      "\n",
      "device ==> cuda\n",
      "\n",
      "DataParallel(\n",
      "  (module): REBORN_MY_SNN_FC(\n",
      "    (layers): REBORN_MY_Sequential(\n",
      "      (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (2): DimChanger_for_FC()\n",
      "      (3): SYNAPSE_FC(in_features=2048, out_features=200, TIME=10, bias=True, sstep=True)\n",
      "      (4): LIF_layer(v_init=0, v_decay=0.5, v_threshold=1, v_reset=10000, sg_width=1, surrogate=hard_sigmoid, BPTT_on=False, trace_const1=1, trace_const2=0, TIME=10, sstep=True, trace_on=True)\n",
      "      (5): SYNAPSE_FC(in_features=200, out_features=200, TIME=10, bias=True, sstep=True)\n",
      "      (6): LIF_layer(v_init=0, v_decay=0.5, v_threshold=1, v_reset=10000, sg_width=1, surrogate=hard_sigmoid, BPTT_on=False, trace_const1=1, trace_const2=0, TIME=10, sstep=True, trace_on=True)\n",
      "      (7): SYNAPSE_FC(in_features=200, out_features=10, TIME=10, bias=True, sstep=True)\n",
      "    )\n",
      "  )\n",
      ")\n",
      "\n",
      "========================================================\n",
      "Trainable parameters: 452,010\n",
      "========================================================\n",
      "\n",
      "epoch-0   lr=['0.1000000'], tr/val_loss:  2.285853/  2.053481, val:  42.08%, val_best:  42.08%, tr:  21.76%, tr_best:  21.76%\n",
      "epoch-1   lr=['0.1000000'], tr/val_loss:  1.709005/  1.680853, val:  47.92%, val_best:  47.92%, tr:  49.03%, tr_best:  49.03%\n",
      "epoch-2   lr=['0.1000000'], tr/val_loss:  1.458611/  1.724974, val:  50.42%, val_best:  50.42%, tr:  57.61%, tr_best:  57.61%\n",
      "epoch-3   lr=['0.1000000'], tr/val_loss:  1.226088/  1.636597, val:  51.67%, val_best:  51.67%, tr:  62.31%, tr_best:  62.31%\n",
      "epoch-4   lr=['0.1000000'], tr/val_loss:  1.243964/  1.653347, val:  61.67%, val_best:  61.67%, tr:  61.29%, tr_best:  62.31%\n",
      "epoch-5   lr=['0.1000000'], tr/val_loss:  1.013862/  1.657426, val:  53.75%, val_best:  61.67%, tr:  69.97%, tr_best:  69.97%\n",
      "epoch-6   lr=['0.1000000'], tr/val_loss:  0.987884/  1.547350, val:  62.50%, val_best:  62.50%, tr:  71.81%, tr_best:  71.81%\n",
      "epoch-7   lr=['0.1000000'], tr/val_loss:  0.911952/  1.773459, val:  62.50%, val_best:  62.50%, tr:  70.07%, tr_best:  71.81%\n",
      "epoch-8   lr=['0.1000000'], tr/val_loss:  0.867727/  1.682229, val:  60.42%, val_best:  62.50%, tr:  73.54%, tr_best:  73.54%\n",
      "epoch-9   lr=['0.1000000'], tr/val_loss:  0.823192/  1.764851, val:  57.50%, val_best:  62.50%, tr:  75.08%, tr_best:  75.08%\n",
      "epoch-10  lr=['0.1000000'], tr/val_loss:  0.693660/  1.717046, val:  61.25%, val_best:  62.50%, tr:  78.75%, tr_best:  78.75%\n",
      "epoch-11  lr=['0.1000000'], tr/val_loss:  0.683476/  1.572659, val:  67.50%, val_best:  67.50%, tr:  79.26%, tr_best:  79.26%\n",
      "epoch-12  lr=['0.1000000'], tr/val_loss:  0.568455/  1.585153, val:  73.33%, val_best:  73.33%, tr:  80.80%, tr_best:  80.80%\n",
      "epoch-13  lr=['0.1000000'], tr/val_loss:  0.612555/  1.726803, val:  62.92%, val_best:  73.33%, tr:  82.94%, tr_best:  82.94%\n",
      "epoch-14  lr=['0.1000000'], tr/val_loss:  0.498697/  2.186072, val:  62.92%, val_best:  73.33%, tr:  85.80%, tr_best:  85.80%\n",
      "epoch-15  lr=['0.1000000'], tr/val_loss:  0.434872/  2.158664, val:  60.00%, val_best:  73.33%, tr:  88.36%, tr_best:  88.36%\n",
      "epoch-16  lr=['0.1000000'], tr/val_loss:  0.387257/  2.359634, val:  67.50%, val_best:  73.33%, tr:  89.38%, tr_best:  89.38%\n",
      "epoch-17  lr=['0.1000000'], tr/val_loss:  0.427243/  1.947007, val:  67.92%, val_best:  73.33%, tr:  92.44%, tr_best:  92.44%\n",
      "epoch-18  lr=['0.1000000'], tr/val_loss:  0.399279/  2.301380, val:  64.58%, val_best:  73.33%, tr:  93.46%, tr_best:  93.46%\n",
      "epoch-19  lr=['0.1000000'], tr/val_loss:  0.278757/  2.081099, val:  75.00%, val_best:  75.00%, tr:  96.42%, tr_best:  96.42%\n",
      "epoch-20  lr=['0.1000000'], tr/val_loss:  0.318969/  2.248349, val:  72.92%, val_best:  75.00%, tr:  93.87%, tr_best:  96.42%\n",
      "epoch-21  lr=['0.1000000'], tr/val_loss:  0.218074/  2.311177, val:  66.25%, val_best:  75.00%, tr:  97.75%, tr_best:  97.75%\n",
      "epoch-22  lr=['0.1000000'], tr/val_loss:  0.154455/  2.411695, val:  71.67%, val_best:  75.00%, tr:  99.80%, tr_best:  99.80%\n",
      "epoch-23  lr=['0.1000000'], tr/val_loss:  0.274714/  2.689136, val:  64.17%, val_best:  75.00%, tr:  98.26%, tr_best:  99.80%\n",
      "epoch-24  lr=['0.1000000'], tr/val_loss:  0.196290/  2.261969, val:  76.67%, val_best:  76.67%, tr:  99.18%, tr_best:  99.80%\n",
      "epoch-25  lr=['0.1000000'], tr/val_loss:  0.152304/  2.336590, val:  76.67%, val_best:  76.67%, tr:  98.88%, tr_best:  99.80%\n",
      "epoch-26  lr=['0.1000000'], tr/val_loss:  0.129113/  2.406643, val:  75.00%, val_best:  76.67%, tr:  98.77%, tr_best:  99.80%\n",
      "epoch-27  lr=['0.1000000'], tr/val_loss:  0.094587/  2.458288, val:  79.17%, val_best:  79.17%, tr:  99.59%, tr_best:  99.80%\n",
      "epoch-28  lr=['0.1000000'], tr/val_loss:  0.043439/  2.509095, val:  79.17%, val_best:  79.17%, tr:  99.80%, tr_best:  99.80%\n",
      "epoch-29  lr=['0.1000000'], tr/val_loss:  0.023121/  2.642365, val:  80.00%, val_best:  80.00%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-30  lr=['0.1000000'], tr/val_loss:  0.017704/  2.702942, val:  80.83%, val_best:  80.83%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-31  lr=['0.1000000'], tr/val_loss:  0.012043/  2.661956, val:  78.75%, val_best:  80.83%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-32  lr=['0.1000000'], tr/val_loss:  0.007612/  2.754230, val:  78.33%, val_best:  80.83%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-33  lr=['0.1000000'], tr/val_loss:  0.031270/  2.698399, val:  80.00%, val_best:  80.83%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-34  lr=['0.1000000'], tr/val_loss:  0.023063/  2.694755, val:  80.42%, val_best:  80.83%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-35  lr=['0.1000000'], tr/val_loss:  0.010330/  2.819055, val:  81.25%, val_best:  81.25%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-36  lr=['0.1000000'], tr/val_loss:  0.007725/  2.810989, val:  78.33%, val_best:  81.25%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-37  lr=['0.1000000'], tr/val_loss:  0.008873/  2.872442, val:  80.00%, val_best:  81.25%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-38  lr=['0.1000000'], tr/val_loss:  0.007148/  2.844573, val:  80.83%, val_best:  81.25%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-39  lr=['0.1000000'], tr/val_loss:  0.004002/  2.945530, val:  78.75%, val_best:  81.25%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-40  lr=['0.1000000'], tr/val_loss:  0.006656/  2.811665, val:  81.67%, val_best:  81.67%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-41  lr=['0.1000000'], tr/val_loss:  0.003086/  2.887087, val:  79.58%, val_best:  81.67%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-42  lr=['0.1000000'], tr/val_loss:  0.002889/  2.980851, val:  77.92%, val_best:  81.67%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-43  lr=['0.1000000'], tr/val_loss:  0.002086/  3.055407, val:  80.42%, val_best:  81.67%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-44  lr=['0.1000000'], tr/val_loss:  0.004130/  3.043365, val:  77.92%, val_best:  81.67%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-45  lr=['0.1000000'], tr/val_loss:  0.004182/  2.988124, val:  79.58%, val_best:  81.67%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-46  lr=['0.1000000'], tr/val_loss:  0.007595/  3.083115, val:  78.75%, val_best:  81.67%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-47  lr=['0.1000000'], tr/val_loss:  0.013698/  3.048383, val:  76.67%, val_best:  81.67%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-48  lr=['0.1000000'], tr/val_loss:  0.009413/  3.062975, val:  77.08%, val_best:  81.67%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-49  lr=['0.1000000'], tr/val_loss:  0.010617/  3.112098, val:  75.83%, val_best:  81.67%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-50  lr=['0.1000000'], tr/val_loss:  0.017168/  3.231787, val:  76.67%, val_best:  81.67%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-51  lr=['0.1000000'], tr/val_loss:  0.037057/  3.186723, val:  73.75%, val_best:  81.67%, tr:  99.90%, tr_best: 100.00%\n",
      "epoch-52  lr=['0.1000000'], tr/val_loss:  0.020976/  3.206089, val:  77.92%, val_best:  81.67%, tr:  99.90%, tr_best: 100.00%\n",
      "epoch-53  lr=['0.1000000'], tr/val_loss:  0.061803/  3.378475, val:  75.00%, val_best:  81.67%, tr:  99.90%, tr_best: 100.00%\n",
      "epoch-54  lr=['0.1000000'], tr/val_loss:  0.034907/  2.924494, val:  77.08%, val_best:  81.67%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-55  lr=['0.1000000'], tr/val_loss:  0.017401/  2.955615, val:  81.25%, val_best:  81.67%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-56  lr=['0.1000000'], tr/val_loss:  0.010434/  3.061478, val:  79.58%, val_best:  81.67%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-57  lr=['0.1000000'], tr/val_loss:  0.007214/  3.017685, val:  78.33%, val_best:  81.67%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-58  lr=['0.1000000'], tr/val_loss:  0.006094/  3.124384, val:  77.92%, val_best:  81.67%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-59  lr=['0.1000000'], tr/val_loss:  0.004924/  3.158646, val:  77.50%, val_best:  81.67%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-60  lr=['0.1000000'], tr/val_loss:  0.002566/  3.297737, val:  75.83%, val_best:  81.67%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-61  lr=['0.1000000'], tr/val_loss:  0.001847/  3.177051, val:  80.00%, val_best:  81.67%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-62  lr=['0.1000000'], tr/val_loss:  0.000628/  3.173343, val:  79.17%, val_best:  81.67%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-63  lr=['0.1000000'], tr/val_loss:  0.000723/  3.179575, val:  79.17%, val_best:  81.67%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-64  lr=['0.1000000'], tr/val_loss:  0.000730/  3.154967, val:  80.00%, val_best:  81.67%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-65  lr=['0.1000000'], tr/val_loss:  0.000453/  3.202388, val:  79.58%, val_best:  81.67%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-66  lr=['0.1000000'], tr/val_loss:  0.000255/  3.201561, val:  80.42%, val_best:  81.67%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-67  lr=['0.1000000'], tr/val_loss:  0.000191/  3.210755, val:  80.00%, val_best:  81.67%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-68  lr=['0.1000000'], tr/val_loss:  0.000162/  3.208899, val:  80.00%, val_best:  81.67%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-69  lr=['0.1000000'], tr/val_loss:  0.000137/  3.201527, val:  80.00%, val_best:  81.67%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-70  lr=['0.1000000'], tr/val_loss:  0.000141/  3.198158, val:  80.00%, val_best:  81.67%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-71  lr=['0.1000000'], tr/val_loss:  0.000137/  3.201961, val:  80.00%, val_best:  81.67%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-72  lr=['0.1000000'], tr/val_loss:  0.000125/  3.197592, val:  79.58%, val_best:  81.67%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-73  lr=['0.1000000'], tr/val_loss:  0.000120/  3.224890, val:  80.00%, val_best:  81.67%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-74  lr=['0.1000000'], tr/val_loss:  0.000103/  3.241307, val:  80.00%, val_best:  81.67%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-75  lr=['0.1000000'], tr/val_loss:  0.000140/  3.252801, val:  79.58%, val_best:  81.67%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-76  lr=['0.1000000'], tr/val_loss:  0.000103/  3.245208, val:  79.17%, val_best:  81.67%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-77  lr=['0.1000000'], tr/val_loss:  0.000092/  3.250266, val:  79.17%, val_best:  81.67%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-78  lr=['0.1000000'], tr/val_loss:  0.000095/  3.249566, val:  79.17%, val_best:  81.67%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-79  lr=['0.1000000'], tr/val_loss:  0.000083/  3.250959, val:  79.58%, val_best:  81.67%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-80  lr=['0.1000000'], tr/val_loss:  0.000081/  3.254580, val:  79.58%, val_best:  81.67%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-81  lr=['0.1000000'], tr/val_loss:  0.000081/  3.260961, val:  79.58%, val_best:  81.67%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-82  lr=['0.1000000'], tr/val_loss:  0.000075/  3.266871, val:  80.00%, val_best:  81.67%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-83  lr=['0.1000000'], tr/val_loss:  0.000078/  3.275686, val:  79.58%, val_best:  81.67%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-84  lr=['0.1000000'], tr/val_loss:  0.000124/  3.282494, val:  80.00%, val_best:  81.67%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-85  lr=['0.1000000'], tr/val_loss:  0.000129/  3.263677, val:  80.83%, val_best:  81.67%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-86  lr=['0.1000000'], tr/val_loss:  0.000104/  3.259821, val:  80.83%, val_best:  81.67%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-87  lr=['0.1000000'], tr/val_loss:  0.000077/  3.263643, val:  80.83%, val_best:  81.67%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-88  lr=['0.1000000'], tr/val_loss:  0.000079/  3.260434, val:  80.83%, val_best:  81.67%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-89  lr=['0.1000000'], tr/val_loss:  0.000072/  3.269111, val:  80.83%, val_best:  81.67%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-90  lr=['0.1000000'], tr/val_loss:  0.000071/  3.279865, val:  81.25%, val_best:  81.67%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-91  lr=['0.1000000'], tr/val_loss:  0.000068/  3.289854, val:  81.25%, val_best:  81.67%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-92  lr=['0.1000000'], tr/val_loss:  0.000066/  3.290632, val:  80.42%, val_best:  81.67%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-93  lr=['0.1000000'], tr/val_loss:  0.000062/  3.282828, val:  80.83%, val_best:  81.67%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-94  lr=['0.1000000'], tr/val_loss:  0.000061/  3.294268, val:  80.83%, val_best:  81.67%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-95  lr=['0.1000000'], tr/val_loss:  0.000059/  3.292227, val:  80.42%, val_best:  81.67%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-96  lr=['0.1000000'], tr/val_loss:  0.000059/  3.304969, val:  80.42%, val_best:  81.67%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-97  lr=['0.1000000'], tr/val_loss:  0.000055/  3.313257, val:  80.42%, val_best:  81.67%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-98  lr=['0.1000000'], tr/val_loss:  0.000056/  3.305539, val:  80.00%, val_best:  81.67%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-99  lr=['0.1000000'], tr/val_loss:  0.000056/  3.316160, val:  80.42%, val_best:  81.67%, tr: 100.00%, tr_best: 100.00%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b601a7692ac7452598d240d1486ad414",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.006 MB of 0.006 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>iter_acc</td><td>▁▅▆▅▄▇▇▇▅███████████████████████████████</td></tr><tr><td>summary_val_acc</td><td>▁▂▅▅▄▇▅▆▇▅▇▇█▇███▇▇▇▇▇▇▇▇███████████████</td></tr><tr><td>tr_acc</td><td>▁▄▅▅▆▆▇▇████████████████████████████████</td></tr><tr><td>tr_epoch_loss</td><td>█▅▅▄▄▃▃▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_acc_best</td><td>▁▂▄▅▅▇▇▇▇▇▇▇████████████████████████████</td></tr><tr><td>val_acc_now</td><td>▁▂▅▅▄▇▅▆▇▅▇▇█▇███▇▇▇▇▇▇▇▇███████████████</td></tr><tr><td>val_loss</td><td>▃▂▁▂▂▁▃▂▃▄▄▄▅▆▆▆▇▇▇▇▇█▆▇▇▇██████████████</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>99</td></tr><tr><td>iter_acc</td><td>1.0</td></tr><tr><td>tr_acc</td><td>1.0</td></tr><tr><td>tr_epoch_loss</td><td>6e-05</td></tr><tr><td>val_acc_best</td><td>0.81667</td></tr><tr><td>val_acc_now</td><td>0.80417</td></tr><tr><td>val_loss</td><td>3.31616</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">fresh-sweep-279</strong> at: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/13jc0dco' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/13jc0dco</a><br/> View project at: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>/data2/bh_wandb/wandb/run-20250430_100555-13jc0dco/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require(\"core\")`! See https://wandb.me/wandb-core for more information."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Sweep Agent: Waiting for job.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Job received.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 120gi0s5 with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBATCH: 16\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBN_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBPTT_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tDFA_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tIMAGE_SIZE: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tOTTT_input_trace_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tTIME: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tUDA_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \talpha_uda: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbias: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcfg: ['M', 'M', 200, 200]\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tchaching_on: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tconvTrue_fcFalse: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdata_path: /data2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tddp_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdenoise_on: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdvs_clipping: 5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdvs_duration: 100000\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepoch_num: 100\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \texclude_class: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \textra_train_dataset: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlast_lif: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.001\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_sg_width: 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_decay: 0.5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_init: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_reset: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_threshold: 0.5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmerge_polarities: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmy_seed: 42\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnet_print: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_workers: 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer_what: SGD\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tpin_memory: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tpre_trained: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tpre_trained_path: net_save/save_now_net_weights_{unique_name}.pth\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \trate_coding: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tscheduler_name: no\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsingle_step: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsurrogate: hard_sigmoid\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_conv_kernel_size: 3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_conv_padding: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_conv_stride: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_trace_const1: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_trace_const2: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \ttdBN_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \ttrace_on: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \twhich_data: DVS_GESTURE_TONIC\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b41ede694f8746dda5e12cecf42391a6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.011113242856744263, max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.19.10 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.17.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/data2/bh_wandb/wandb/run-20250430_101219-120gi0s5</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/120gi0s5' target=\"_blank\">worthy-sweep-281</a></strong> to <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/6pj3lh8j' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/6pj3lh8j</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/6pj3lh8j' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/6pj3lh8j</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/120gi0s5' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/120gi0s5</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'single_step' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'my_seed' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'TIME' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BATCH' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'IMAGE_SIZE' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'which_data' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'data_path' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'rate_coding' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_init' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_decay' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_threshold' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_reset' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_sg_width' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_conv_kernel_size' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_conv_stride' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_conv_padding' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_trace_const1' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_trace_const2' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'pre_trained' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'convTrue_fcFalse' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'cfg' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'net_print' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'pre_trained_path' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'learning_rate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'epoch_num' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'tdBN_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BN_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'surrogate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BPTT_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'optimizer_what' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'scheduler_name' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'ddp_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'dvs_clipping' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'dvs_duration' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'DFA_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'trace_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'OTTT_input_trace_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'exclude_class' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'merge_polarities' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'denoise_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'extra_train_dataset' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'num_workers' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'chaching_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'pin_memory' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'UDA_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'alpha_uda' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'bias' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'last_lif' was locked by 'sweep' (ignored update).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "param {'devices': '0', 'single_step': True, 'unique_name': 'main', 'my_seed': 42, 'TIME': 10, 'BATCH': 16, 'IMAGE_SIZE': 128, 'which_data': 'DVS_GESTURE_TONIC', 'data_path': '/data2', 'rate_coding': False, 'lif_layer_v_init': 0, 'lif_layer_v_decay': 0.5, 'lif_layer_v_threshold': 0.5, 'lif_layer_v_reset': 0, 'lif_layer_sg_width': 2, 'synapse_conv_kernel_size': 3, 'synapse_conv_stride': 1, 'synapse_conv_padding': 1, 'synapse_trace_const1': 1, 'synapse_trace_const2': 0, 'pre_trained': False, 'convTrue_fcFalse': False, 'cfg': ['M', 'M', 200, 200], 'net_print': True, 'pre_trained_path': 'net_save/save_now_net_weights_{unique_name}.pth', 'learning_rate': 0.001, 'epoch_num': 100, 'tdBN_on': False, 'BN_on': False, 'surrogate': 'hard_sigmoid', 'BPTT_on': False, 'optimizer_what': 'SGD', 'scheduler_name': 'no', 'ddp_on': False, 'dvs_clipping': 5, 'dvs_duration': 100000, 'DFA_on': False, 'trace_on': True, 'OTTT_input_trace_on': False, 'exclude_class': True, 'merge_polarities': False, 'denoise_on': True, 'extra_train_dataset': 0, 'num_workers': 2, 'chaching_on': True, 'pin_memory': True, 'UDA_on': False, 'alpha_uda': 1, 'bias': True, 'last_lif': False, 'current epoch': 0} \n",
      "\n",
      "dataset_hash = 63cc597115630ec173f3099200061e53\n",
      "cache path exists\n",
      "\n",
      "device ==> cuda\n",
      "\n",
      "DataParallel(\n",
      "  (module): REBORN_MY_SNN_FC(\n",
      "    (layers): REBORN_MY_Sequential(\n",
      "      (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (2): DimChanger_for_FC()\n",
      "      (3): SYNAPSE_FC(in_features=2048, out_features=200, TIME=10, bias=True, sstep=True)\n",
      "      (4): LIF_layer(v_init=0, v_decay=0.5, v_threshold=0.5, v_reset=0, sg_width=2, surrogate=hard_sigmoid, BPTT_on=False, trace_const1=1, trace_const2=0, TIME=10, sstep=True, trace_on=True)\n",
      "      (5): SYNAPSE_FC(in_features=200, out_features=200, TIME=10, bias=True, sstep=True)\n",
      "      (6): LIF_layer(v_init=0, v_decay=0.5, v_threshold=0.5, v_reset=0, sg_width=2, surrogate=hard_sigmoid, BPTT_on=False, trace_const1=1, trace_const2=0, TIME=10, sstep=True, trace_on=True)\n",
      "      (7): SYNAPSE_FC(in_features=200, out_features=10, TIME=10, bias=True, sstep=True)\n",
      "    )\n",
      "  )\n",
      ")\n",
      "\n",
      "========================================================\n",
      "Trainable parameters: 452,010\n",
      "========================================================\n",
      "\n",
      "epoch-0   lr=['0.0010000'], tr/val_loss:  2.305368/  2.302833, val:  10.00%, val_best:  10.00%, tr:   8.17%, tr_best:   8.17%\n",
      "epoch-1   lr=['0.0010000'], tr/val_loss:  2.304892/  2.302062, val:  10.83%, val_best:  10.83%, tr:   7.76%, tr_best:   8.17%\n",
      "epoch-2   lr=['0.0010000'], tr/val_loss:  2.300981/  2.294199, val:  18.33%, val_best:  18.33%, tr:  11.44%, tr_best:  11.44%\n",
      "epoch-3   lr=['0.0010000'], tr/val_loss:  2.258609/  2.238446, val:  23.75%, val_best:  23.75%, tr:  20.33%, tr_best:  20.33%\n",
      "epoch-4   lr=['0.0010000'], tr/val_loss:  2.144674/  2.110649, val:  35.83%, val_best:  35.83%, tr:  28.60%, tr_best:  28.60%\n",
      "epoch-5   lr=['0.0010000'], tr/val_loss:  1.912334/  1.878388, val:  46.25%, val_best:  46.25%, tr:  43.82%, tr_best:  43.82%\n",
      "epoch-6   lr=['0.0010000'], tr/val_loss:  1.677627/  1.719861, val:  47.08%, val_best:  47.08%, tr:  52.40%, tr_best:  52.40%\n",
      "epoch-7   lr=['0.0010000'], tr/val_loss:  1.521894/  1.620528, val:  49.58%, val_best:  49.58%, tr:  56.69%, tr_best:  56.69%\n",
      "epoch-8   lr=['0.0010000'], tr/val_loss:  1.418755/  1.555570, val:  51.67%, val_best:  51.67%, tr:  58.22%, tr_best:  58.22%\n",
      "epoch-9   lr=['0.0010000'], tr/val_loss:  1.348423/  1.508129, val:  52.92%, val_best:  52.92%, tr:  60.88%, tr_best:  60.88%\n",
      "epoch-10  lr=['0.0010000'], tr/val_loss:  1.288996/  1.459811, val:  55.00%, val_best:  55.00%, tr:  60.98%, tr_best:  60.98%\n",
      "epoch-11  lr=['0.0010000'], tr/val_loss:  1.237020/  1.421601, val:  55.83%, val_best:  55.83%, tr:  60.98%, tr_best:  60.98%\n",
      "epoch-12  lr=['0.0010000'], tr/val_loss:  1.207593/  1.393264, val:  56.25%, val_best:  56.25%, tr:  62.21%, tr_best:  62.21%\n",
      "epoch-13  lr=['0.0010000'], tr/val_loss:  1.170667/  1.370812, val:  60.42%, val_best:  60.42%, tr:  62.51%, tr_best:  62.51%\n",
      "epoch-14  lr=['0.0010000'], tr/val_loss:  1.118542/  1.374681, val:  57.92%, val_best:  60.42%, tr:  65.07%, tr_best:  65.07%\n",
      "epoch-15  lr=['0.0010000'], tr/val_loss:  1.107271/  1.342999, val:  60.83%, val_best:  60.83%, tr:  64.86%, tr_best:  65.07%\n",
      "epoch-16  lr=['0.0010000'], tr/val_loss:  1.077037/  1.324465, val:  58.75%, val_best:  60.83%, tr:  66.91%, tr_best:  66.91%\n",
      "epoch-17  lr=['0.0010000'], tr/val_loss:  1.047446/  1.299984, val:  65.83%, val_best:  65.83%, tr:  68.95%, tr_best:  68.95%\n",
      "epoch-18  lr=['0.0010000'], tr/val_loss:  1.030322/  1.308878, val:  60.00%, val_best:  65.83%, tr:  68.54%, tr_best:  68.95%\n",
      "epoch-19  lr=['0.0010000'], tr/val_loss:  1.012405/  1.305472, val:  61.67%, val_best:  65.83%, tr:  66.80%, tr_best:  68.95%\n",
      "epoch-20  lr=['0.0010000'], tr/val_loss:  0.983793/  1.285074, val:  59.58%, val_best:  65.83%, tr:  69.87%, tr_best:  69.87%\n",
      "epoch-21  lr=['0.0010000'], tr/val_loss:  0.962755/  1.278454, val:  60.42%, val_best:  65.83%, tr:  70.28%, tr_best:  70.28%\n",
      "epoch-22  lr=['0.0010000'], tr/val_loss:  0.956710/  1.284618, val:  61.25%, val_best:  65.83%, tr:  68.85%, tr_best:  70.28%\n",
      "epoch-23  lr=['0.0010000'], tr/val_loss:  0.932511/  1.268549, val:  60.83%, val_best:  65.83%, tr:  72.22%, tr_best:  72.22%\n",
      "epoch-24  lr=['0.0010000'], tr/val_loss:  0.911611/  1.253752, val:  59.58%, val_best:  65.83%, tr:  73.14%, tr_best:  73.14%\n",
      "epoch-25  lr=['0.0010000'], tr/val_loss:  0.899958/  1.243144, val:  63.33%, val_best:  65.83%, tr:  73.75%, tr_best:  73.75%\n",
      "epoch-26  lr=['0.0010000'], tr/val_loss:  0.885378/  1.235982, val:  62.50%, val_best:  65.83%, tr:  73.34%, tr_best:  73.75%\n",
      "epoch-27  lr=['0.0010000'], tr/val_loss:  0.868563/  1.265575, val:  64.58%, val_best:  65.83%, tr:  75.49%, tr_best:  75.49%\n",
      "epoch-28  lr=['0.0010000'], tr/val_loss:  0.864631/  1.238035, val:  62.92%, val_best:  65.83%, tr:  73.95%, tr_best:  75.49%\n",
      "epoch-29  lr=['0.0010000'], tr/val_loss:  0.842089/  1.251951, val:  61.25%, val_best:  65.83%, tr:  74.46%, tr_best:  75.49%\n",
      "epoch-30  lr=['0.0010000'], tr/val_loss:  0.833277/  1.244663, val:  60.83%, val_best:  65.83%, tr:  75.69%, tr_best:  75.69%\n",
      "epoch-31  lr=['0.0010000'], tr/val_loss:  0.828654/  1.265054, val:  64.17%, val_best:  65.83%, tr:  74.16%, tr_best:  75.69%\n",
      "epoch-32  lr=['0.0010000'], tr/val_loss:  0.816452/  1.272462, val:  60.83%, val_best:  65.83%, tr:  76.61%, tr_best:  76.61%\n",
      "epoch-33  lr=['0.0010000'], tr/val_loss:  0.803328/  1.259611, val:  61.67%, val_best:  65.83%, tr:  77.94%, tr_best:  77.94%\n",
      "epoch-34  lr=['0.0010000'], tr/val_loss:  0.789242/  1.243935, val:  62.50%, val_best:  65.83%, tr:  76.61%, tr_best:  77.94%\n",
      "epoch-35  lr=['0.0010000'], tr/val_loss:  0.778457/  1.268647, val:  63.33%, val_best:  65.83%, tr:  77.63%, tr_best:  77.94%\n",
      "epoch-36  lr=['0.0010000'], tr/val_loss:  0.761812/  1.259803, val:  62.92%, val_best:  65.83%, tr:  79.06%, tr_best:  79.06%\n",
      "epoch-37  lr=['0.0010000'], tr/val_loss:  0.758177/  1.243600, val:  66.67%, val_best:  66.67%, tr:  80.59%, tr_best:  80.59%\n",
      "epoch-38  lr=['0.0010000'], tr/val_loss:  0.751704/  1.236304, val:  68.75%, val_best:  68.75%, tr:  81.51%, tr_best:  81.51%\n",
      "epoch-39  lr=['0.0010000'], tr/val_loss:  0.737229/  1.225863, val:  66.67%, val_best:  68.75%, tr:  80.59%, tr_best:  81.51%\n",
      "epoch-40  lr=['0.0010000'], tr/val_loss:  0.722504/  1.238837, val:  68.75%, val_best:  68.75%, tr:  79.47%, tr_best:  81.51%\n",
      "epoch-41  lr=['0.0010000'], tr/val_loss:  0.719480/  1.260820, val:  66.25%, val_best:  68.75%, tr:  83.55%, tr_best:  83.55%\n",
      "epoch-42  lr=['0.0010000'], tr/val_loss:  0.704159/  1.241199, val:  64.17%, val_best:  68.75%, tr:  83.35%, tr_best:  83.55%\n",
      "epoch-43  lr=['0.0010000'], tr/val_loss:  0.698786/  1.245356, val:  68.33%, val_best:  68.75%, tr:  82.74%, tr_best:  83.55%\n",
      "epoch-44  lr=['0.0010000'], tr/val_loss:  0.697263/  1.229968, val:  69.58%, val_best:  69.58%, tr:  81.51%, tr_best:  83.55%\n",
      "epoch-45  lr=['0.0010000'], tr/val_loss:  0.678801/  1.256118, val:  67.50%, val_best:  69.58%, tr:  84.27%, tr_best:  84.27%\n",
      "epoch-46  lr=['0.0010000'], tr/val_loss:  0.671185/  1.272452, val:  67.92%, val_best:  69.58%, tr:  84.58%, tr_best:  84.58%\n",
      "epoch-47  lr=['0.0010000'], tr/val_loss:  0.669061/  1.276556, val:  69.58%, val_best:  69.58%, tr:  84.17%, tr_best:  84.58%\n",
      "epoch-48  lr=['0.0010000'], tr/val_loss:  0.662694/  1.254248, val:  70.42%, val_best:  70.42%, tr:  86.41%, tr_best:  86.41%\n",
      "epoch-49  lr=['0.0010000'], tr/val_loss:  0.654337/  1.256662, val:  69.17%, val_best:  70.42%, tr:  84.07%, tr_best:  86.41%\n",
      "epoch-50  lr=['0.0010000'], tr/val_loss:  0.643210/  1.262452, val:  70.42%, val_best:  70.42%, tr:  86.52%, tr_best:  86.52%\n",
      "epoch-51  lr=['0.0010000'], tr/val_loss:  0.635739/  1.282570, val:  71.67%, val_best:  71.67%, tr:  87.03%, tr_best:  87.03%\n",
      "epoch-52  lr=['0.0010000'], tr/val_loss:  0.623695/  1.296248, val:  66.25%, val_best:  71.67%, tr:  86.21%, tr_best:  87.03%\n",
      "epoch-53  lr=['0.0010000'], tr/val_loss:  0.617773/  1.271489, val:  71.25%, val_best:  71.67%, tr:  87.03%, tr_best:  87.03%\n",
      "epoch-54  lr=['0.0010000'], tr/val_loss:  0.611612/  1.283601, val:  69.17%, val_best:  71.67%, tr:  88.66%, tr_best:  88.66%\n",
      "epoch-55  lr=['0.0010000'], tr/val_loss:  0.600643/  1.299564, val:  68.75%, val_best:  71.67%, tr:  88.05%, tr_best:  88.66%\n",
      "epoch-56  lr=['0.0010000'], tr/val_loss:  0.590205/  1.329492, val:  70.00%, val_best:  71.67%, tr:  90.60%, tr_best:  90.60%\n",
      "epoch-57  lr=['0.0010000'], tr/val_loss:  0.595116/  1.298436, val:  70.42%, val_best:  71.67%, tr:  89.58%, tr_best:  90.60%\n",
      "epoch-58  lr=['0.0010000'], tr/val_loss:  0.575342/  1.342003, val:  70.42%, val_best:  71.67%, tr:  89.48%, tr_best:  90.60%\n",
      "epoch-59  lr=['0.0010000'], tr/val_loss:  0.572219/  1.363642, val:  72.08%, val_best:  72.08%, tr:  91.62%, tr_best:  91.62%\n",
      "epoch-60  lr=['0.0010000'], tr/val_loss:  0.565036/  1.327346, val:  70.00%, val_best:  72.08%, tr:  90.19%, tr_best:  91.62%\n",
      "epoch-61  lr=['0.0010000'], tr/val_loss:  0.562899/  1.345347, val:  71.67%, val_best:  72.08%, tr:  90.81%, tr_best:  91.62%\n",
      "epoch-62  lr=['0.0010000'], tr/val_loss:  0.556397/  1.323514, val:  74.17%, val_best:  74.17%, tr:  92.44%, tr_best:  92.44%\n",
      "epoch-63  lr=['0.0010000'], tr/val_loss:  0.547947/  1.333071, val:  73.33%, val_best:  74.17%, tr:  93.67%, tr_best:  93.67%\n",
      "epoch-64  lr=['0.0010000'], tr/val_loss:  0.541302/  1.389508, val:  71.25%, val_best:  74.17%, tr:  92.65%, tr_best:  93.67%\n",
      "epoch-65  lr=['0.0010000'], tr/val_loss:  0.539643/  1.361068, val:  72.08%, val_best:  74.17%, tr:  92.24%, tr_best:  93.67%\n",
      "epoch-66  lr=['0.0010000'], tr/val_loss:  0.534326/  1.365672, val:  72.50%, val_best:  74.17%, tr:  92.54%, tr_best:  93.67%\n",
      "epoch-67  lr=['0.0010000'], tr/val_loss:  0.528793/  1.367719, val:  73.75%, val_best:  74.17%, tr:  93.56%, tr_best:  93.67%\n",
      "epoch-68  lr=['0.0010000'], tr/val_loss:  0.520870/  1.370909, val:  71.25%, val_best:  74.17%, tr:  92.85%, tr_best:  93.67%\n",
      "epoch-69  lr=['0.0010000'], tr/val_loss:  0.512611/  1.381733, val:  70.42%, val_best:  74.17%, tr:  94.18%, tr_best:  94.18%\n",
      "epoch-70  lr=['0.0010000'], tr/val_loss:  0.505740/  1.402387, val:  72.92%, val_best:  74.17%, tr:  94.59%, tr_best:  94.59%\n",
      "epoch-71  lr=['0.0010000'], tr/val_loss:  0.504626/  1.415523, val:  68.75%, val_best:  74.17%, tr:  94.79%, tr_best:  94.79%\n",
      "epoch-72  lr=['0.0010000'], tr/val_loss:  0.491326/  1.446496, val:  69.58%, val_best:  74.17%, tr:  95.81%, tr_best:  95.81%\n",
      "epoch-73  lr=['0.0010000'], tr/val_loss:  0.495741/  1.450741, val:  70.00%, val_best:  74.17%, tr:  94.69%, tr_best:  95.81%\n",
      "epoch-74  lr=['0.0010000'], tr/val_loss:  0.491208/  1.420430, val:  70.42%, val_best:  74.17%, tr:  95.10%, tr_best:  95.81%\n",
      "epoch-75  lr=['0.0010000'], tr/val_loss:  0.487786/  1.463452, val:  67.92%, val_best:  74.17%, tr:  93.67%, tr_best:  95.81%\n",
      "epoch-76  lr=['0.0010000'], tr/val_loss:  0.461637/  1.478736, val:  70.00%, val_best:  74.17%, tr:  96.42%, tr_best:  96.42%\n",
      "epoch-77  lr=['0.0010000'], tr/val_loss:  0.475285/  1.465741, val:  70.42%, val_best:  74.17%, tr:  95.71%, tr_best:  96.42%\n",
      "epoch-78  lr=['0.0010000'], tr/val_loss:  0.466164/  1.470884, val:  71.67%, val_best:  74.17%, tr:  95.20%, tr_best:  96.42%\n",
      "epoch-79  lr=['0.0010000'], tr/val_loss:  0.453625/  1.449784, val:  71.67%, val_best:  74.17%, tr:  95.91%, tr_best:  96.42%\n",
      "epoch-80  lr=['0.0010000'], tr/val_loss:  0.443948/  1.483106, val:  70.00%, val_best:  74.17%, tr:  96.94%, tr_best:  96.94%\n",
      "epoch-81  lr=['0.0010000'], tr/val_loss:  0.451433/  1.480843, val:  70.83%, val_best:  74.17%, tr:  96.12%, tr_best:  96.94%\n",
      "epoch-82  lr=['0.0010000'], tr/val_loss:  0.434478/  1.501207, val:  70.00%, val_best:  74.17%, tr:  96.22%, tr_best:  96.94%\n",
      "epoch-83  lr=['0.0010000'], tr/val_loss:  0.426664/  1.508964, val:  72.08%, val_best:  74.17%, tr:  97.34%, tr_best:  97.34%\n",
      "epoch-84  lr=['0.0010000'], tr/val_loss:  0.421476/  1.501649, val:  72.92%, val_best:  74.17%, tr:  97.65%, tr_best:  97.65%\n",
      "epoch-85  lr=['0.0010000'], tr/val_loss:  0.422231/  1.529165, val:  72.08%, val_best:  74.17%, tr:  97.45%, tr_best:  97.65%\n",
      "epoch-86  lr=['0.0010000'], tr/val_loss:  0.414360/  1.515011, val:  73.33%, val_best:  74.17%, tr:  96.02%, tr_best:  97.65%\n",
      "epoch-87  lr=['0.0010000'], tr/val_loss:  0.410106/  1.549944, val:  72.92%, val_best:  74.17%, tr:  97.85%, tr_best:  97.85%\n",
      "epoch-88  lr=['0.0010000'], tr/val_loss:  0.395378/  1.550342, val:  72.08%, val_best:  74.17%, tr:  97.96%, tr_best:  97.96%\n",
      "epoch-89  lr=['0.0010000'], tr/val_loss:  0.390503/  1.554675, val:  72.50%, val_best:  74.17%, tr:  97.75%, tr_best:  97.96%\n",
      "epoch-90  lr=['0.0010000'], tr/val_loss:  0.397032/  1.516007, val:  72.92%, val_best:  74.17%, tr:  97.85%, tr_best:  97.96%\n",
      "epoch-91  lr=['0.0010000'], tr/val_loss:  0.388672/  1.565857, val:  75.00%, val_best:  75.00%, tr:  97.85%, tr_best:  97.96%\n",
      "epoch-92  lr=['0.0010000'], tr/val_loss:  0.390934/  1.567193, val:  73.33%, val_best:  75.00%, tr:  97.14%, tr_best:  97.96%\n",
      "epoch-93  lr=['0.0010000'], tr/val_loss:  0.386176/  1.549205, val:  70.83%, val_best:  75.00%, tr:  97.96%, tr_best:  97.96%\n",
      "epoch-94  lr=['0.0010000'], tr/val_loss:  0.382973/  1.580552, val:  73.75%, val_best:  75.00%, tr:  98.57%, tr_best:  98.57%\n",
      "epoch-95  lr=['0.0010000'], tr/val_loss:  0.377275/  1.607639, val:  71.25%, val_best:  75.00%, tr:  98.16%, tr_best:  98.57%\n",
      "epoch-96  lr=['0.0010000'], tr/val_loss:  0.379456/  1.620180, val:  70.42%, val_best:  75.00%, tr:  98.16%, tr_best:  98.57%\n",
      "epoch-97  lr=['0.0010000'], tr/val_loss:  0.381979/  1.568181, val:  72.08%, val_best:  75.00%, tr:  96.42%, tr_best:  98.57%\n",
      "epoch-98  lr=['0.0010000'], tr/val_loss:  0.358759/  1.604447, val:  69.58%, val_best:  75.00%, tr:  98.77%, tr_best:  98.77%\n",
      "epoch-99  lr=['0.0010000'], tr/val_loss:  0.375174/  1.589027, val:  72.50%, val_best:  75.00%, tr:  98.47%, tr_best:  98.77%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ccb0a9d022e8474d8e771532884e9de0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.006 MB of 0.006 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>iter_acc</td><td>▁▁▂▃▄▅▇▃▄▇▆▆▆▇▆▆█▇██▇▇▇▇███▇████▆███████</td></tr><tr><td>summary_val_acc</td><td>▁▂▄▅▆▆▆▇▇▇▆▇▇▇▇▇▇▇██▇▇▇███████▇█████████</td></tr><tr><td>tr_acc</td><td>▁▁▃▅▅▅▅▆▆▆▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇██████████████</td></tr><tr><td>tr_epoch_loss</td><td>██▇▅▅▄▄▃▃▃▃▃▃▃▂▂▂▂▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_acc_best</td><td>▁▂▄▅▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇████████████████████</td></tr><tr><td>val_acc_now</td><td>▁▂▄▅▆▆▆▇▇▇▆▇▇▇▇▇▇▇██▇▇▇███████▇█████████</td></tr><tr><td>val_loss</td><td>██▇▄▃▂▂▁▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▂▂▂▂▂▃▃▂▃▃▃▃▃▃▃</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>99</td></tr><tr><td>iter_acc</td><td>1.0</td></tr><tr><td>tr_acc</td><td>0.98468</td></tr><tr><td>tr_epoch_loss</td><td>0.37517</td></tr><tr><td>val_acc_best</td><td>0.75</td></tr><tr><td>val_acc_now</td><td>0.725</td></tr><tr><td>val_loss</td><td>1.58903</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">worthy-sweep-281</strong> at: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/120gi0s5' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/120gi0s5</a><br/> View project at: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>/data2/bh_wandb/wandb/run-20250430_101219-120gi0s5/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require(\"core\")`! See https://wandb.me/wandb-core for more information."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Sweep Agent: Waiting for job.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Job received.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: rqylwmww with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBATCH: 16\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBN_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBPTT_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tDFA_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tIMAGE_SIZE: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tOTTT_input_trace_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tTIME: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tUDA_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \talpha_uda: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbias: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcfg: ['M', 'M', 200, 200]\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tchaching_on: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tconvTrue_fcFalse: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdata_path: /data2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tddp_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdenoise_on: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdvs_clipping: 5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdvs_duration: 100000\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepoch_num: 100\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \texclude_class: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \textra_train_dataset: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlast_lif: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.01\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_sg_width: 4\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_decay: 0.5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_init: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_reset: 10000\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_threshold: 0.5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmerge_polarities: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmy_seed: 42\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnet_print: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_workers: 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer_what: SGD\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tpin_memory: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tpre_trained: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tpre_trained_path: net_save/save_now_net_weights_{unique_name}.pth\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \trate_coding: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tscheduler_name: no\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsingle_step: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsurrogate: hard_sigmoid\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_conv_kernel_size: 3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_conv_padding: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_conv_stride: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_trace_const1: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_trace_const2: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \ttdBN_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \ttrace_on: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \twhich_data: DVS_GESTURE_TONIC\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "87ac371556524e24af278392fd2f0df1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.01111298108783861, max=1.0)…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.17.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/data2/bh_wandb/wandb/run-20250430_101824-rqylwmww</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/rqylwmww' target=\"_blank\">bumbling-sweep-283</a></strong> to <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/6pj3lh8j' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/6pj3lh8j</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/6pj3lh8j' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/6pj3lh8j</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/rqylwmww' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/rqylwmww</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'single_step' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'my_seed' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'TIME' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BATCH' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'IMAGE_SIZE' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'which_data' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'data_path' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'rate_coding' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_init' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_decay' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_threshold' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_reset' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_sg_width' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_conv_kernel_size' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_conv_stride' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_conv_padding' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_trace_const1' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_trace_const2' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'pre_trained' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'convTrue_fcFalse' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'cfg' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'net_print' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'pre_trained_path' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'learning_rate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'epoch_num' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'tdBN_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BN_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'surrogate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BPTT_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'optimizer_what' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'scheduler_name' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'ddp_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'dvs_clipping' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'dvs_duration' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'DFA_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'trace_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'OTTT_input_trace_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'exclude_class' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'merge_polarities' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'denoise_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'extra_train_dataset' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'num_workers' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'chaching_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'pin_memory' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'UDA_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'alpha_uda' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'bias' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'last_lif' was locked by 'sweep' (ignored update).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "param {'devices': '0', 'single_step': True, 'unique_name': 'main', 'my_seed': 42, 'TIME': 10, 'BATCH': 16, 'IMAGE_SIZE': 128, 'which_data': 'DVS_GESTURE_TONIC', 'data_path': '/data2', 'rate_coding': False, 'lif_layer_v_init': 0, 'lif_layer_v_decay': 0.5, 'lif_layer_v_threshold': 0.5, 'lif_layer_v_reset': 10000, 'lif_layer_sg_width': 4, 'synapse_conv_kernel_size': 3, 'synapse_conv_stride': 1, 'synapse_conv_padding': 1, 'synapse_trace_const1': 1, 'synapse_trace_const2': 0, 'pre_trained': False, 'convTrue_fcFalse': False, 'cfg': ['M', 'M', 200, 200], 'net_print': True, 'pre_trained_path': 'net_save/save_now_net_weights_{unique_name}.pth', 'learning_rate': 0.01, 'epoch_num': 100, 'tdBN_on': False, 'BN_on': False, 'surrogate': 'hard_sigmoid', 'BPTT_on': False, 'optimizer_what': 'SGD', 'scheduler_name': 'no', 'ddp_on': False, 'dvs_clipping': 5, 'dvs_duration': 100000, 'DFA_on': False, 'trace_on': True, 'OTTT_input_trace_on': False, 'exclude_class': True, 'merge_polarities': False, 'denoise_on': True, 'extra_train_dataset': 0, 'num_workers': 2, 'chaching_on': True, 'pin_memory': True, 'UDA_on': False, 'alpha_uda': 1, 'bias': True, 'last_lif': False, 'current epoch': 0} \n",
      "\n",
      "dataset_hash = 63cc597115630ec173f3099200061e53\n",
      "cache path exists\n",
      "\n",
      "device ==> cuda\n",
      "\n",
      "DataParallel(\n",
      "  (module): REBORN_MY_SNN_FC(\n",
      "    (layers): REBORN_MY_Sequential(\n",
      "      (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (2): DimChanger_for_FC()\n",
      "      (3): SYNAPSE_FC(in_features=2048, out_features=200, TIME=10, bias=True, sstep=True)\n",
      "      (4): LIF_layer(v_init=0, v_decay=0.5, v_threshold=0.5, v_reset=10000, sg_width=4, surrogate=hard_sigmoid, BPTT_on=False, trace_const1=1, trace_const2=0, TIME=10, sstep=True, trace_on=True)\n",
      "      (5): SYNAPSE_FC(in_features=200, out_features=200, TIME=10, bias=True, sstep=True)\n",
      "      (6): LIF_layer(v_init=0, v_decay=0.5, v_threshold=0.5, v_reset=10000, sg_width=4, surrogate=hard_sigmoid, BPTT_on=False, trace_const1=1, trace_const2=0, TIME=10, sstep=True, trace_on=True)\n",
      "      (7): SYNAPSE_FC(in_features=200, out_features=10, TIME=10, bias=True, sstep=True)\n",
      "    )\n",
      "  )\n",
      ")\n",
      "\n",
      "========================================================\n",
      "Trainable parameters: 452,010\n",
      "========================================================\n",
      "\n",
      "epoch-0   lr=['0.0100000'], tr/val_loss:  2.143832/  1.725674, val:  47.50%, val_best:  47.50%, tr:  20.12%, tr_best:  20.12%\n",
      "epoch-1   lr=['0.0100000'], tr/val_loss:  1.445301/  1.483055, val:  55.83%, val_best:  55.83%, tr:  53.93%, tr_best:  53.93%\n",
      "epoch-2   lr=['0.0100000'], tr/val_loss:  1.227574/  1.479838, val:  53.33%, val_best:  55.83%, tr:  59.45%, tr_best:  59.45%\n",
      "epoch-3   lr=['0.0100000'], tr/val_loss:  1.050132/  1.487297, val:  53.75%, val_best:  55.83%, tr:  68.54%, tr_best:  68.54%\n",
      "epoch-4   lr=['0.0100000'], tr/val_loss:  0.977391/  1.298842, val:  64.58%, val_best:  64.58%, tr:  68.23%, tr_best:  68.54%\n",
      "epoch-5   lr=['0.0100000'], tr/val_loss:  0.898762/  1.396145, val:  58.75%, val_best:  64.58%, tr:  72.11%, tr_best:  72.11%\n",
      "epoch-6   lr=['0.0100000'], tr/val_loss:  0.824354/  1.269428, val:  66.67%, val_best:  66.67%, tr:  73.44%, tr_best:  73.44%\n",
      "epoch-7   lr=['0.0100000'], tr/val_loss:  0.761013/  1.316509, val:  66.67%, val_best:  66.67%, tr:  76.10%, tr_best:  76.10%\n",
      "epoch-8   lr=['0.0100000'], tr/val_loss:  0.666477/  1.310182, val:  69.58%, val_best:  69.58%, tr:  80.49%, tr_best:  80.49%\n",
      "epoch-9   lr=['0.0100000'], tr/val_loss:  0.627003/  1.364012, val:  67.08%, val_best:  69.58%, tr:  83.35%, tr_best:  83.35%\n",
      "epoch-10  lr=['0.0100000'], tr/val_loss:  0.578480/  1.411966, val:  68.75%, val_best:  69.58%, tr:  85.80%, tr_best:  85.80%\n",
      "epoch-11  lr=['0.0100000'], tr/val_loss:  0.548310/  1.480419, val:  66.25%, val_best:  69.58%, tr:  87.95%, tr_best:  87.95%\n",
      "epoch-12  lr=['0.0100000'], tr/val_loss:  0.442610/  1.377371, val:  72.08%, val_best:  72.08%, tr:  91.83%, tr_best:  91.83%\n",
      "epoch-13  lr=['0.0100000'], tr/val_loss:  0.404480/  1.432525, val:  76.67%, val_best:  76.67%, tr:  92.65%, tr_best:  92.65%\n",
      "epoch-14  lr=['0.0100000'], tr/val_loss:  0.326901/  1.710184, val:  72.08%, val_best:  76.67%, tr:  93.87%, tr_best:  93.87%\n",
      "epoch-15  lr=['0.0100000'], tr/val_loss:  0.354142/  1.654561, val:  73.33%, val_best:  76.67%, tr:  94.69%, tr_best:  94.69%\n",
      "epoch-16  lr=['0.0100000'], tr/val_loss:  0.280604/  1.737848, val:  71.25%, val_best:  76.67%, tr:  97.24%, tr_best:  97.24%\n",
      "epoch-17  lr=['0.0100000'], tr/val_loss:  0.247818/  1.668805, val:  78.75%, val_best:  78.75%, tr:  98.47%, tr_best:  98.47%\n",
      "epoch-18  lr=['0.0100000'], tr/val_loss:  0.173424/  1.783524, val:  74.58%, val_best:  78.75%, tr:  98.26%, tr_best:  98.47%\n",
      "epoch-19  lr=['0.0100000'], tr/val_loss:  0.148638/  1.933946, val:  75.00%, val_best:  78.75%, tr:  99.69%, tr_best:  99.69%\n",
      "epoch-20  lr=['0.0100000'], tr/val_loss:  0.170297/  1.860916, val:  77.92%, val_best:  78.75%, tr:  99.18%, tr_best:  99.69%\n",
      "epoch-21  lr=['0.0100000'], tr/val_loss:  0.116457/  1.952020, val:  75.83%, val_best:  78.75%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-22  lr=['0.0100000'], tr/val_loss:  0.088683/  1.996243, val:  79.17%, val_best:  79.17%, tr:  99.90%, tr_best: 100.00%\n",
      "epoch-23  lr=['0.0100000'], tr/val_loss:  0.081042/  1.971595, val:  80.00%, val_best:  80.00%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-24  lr=['0.0100000'], tr/val_loss:  0.057437/  2.074063, val:  78.33%, val_best:  80.00%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-25  lr=['0.0100000'], tr/val_loss:  0.047223/  2.117822, val:  80.42%, val_best:  80.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-26  lr=['0.0100000'], tr/val_loss:  0.043249/  2.162683, val:  75.42%, val_best:  80.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-27  lr=['0.0100000'], tr/val_loss:  0.029527/  2.170190, val:  77.50%, val_best:  80.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-28  lr=['0.0100000'], tr/val_loss:  0.020495/  2.173681, val:  80.42%, val_best:  80.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-29  lr=['0.0100000'], tr/val_loss:  0.017107/  2.231972, val:  79.58%, val_best:  80.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-30  lr=['0.0100000'], tr/val_loss:  0.024454/  2.276934, val:  77.08%, val_best:  80.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-31  lr=['0.0100000'], tr/val_loss:  0.018748/  2.311118, val:  79.58%, val_best:  80.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-32  lr=['0.0100000'], tr/val_loss:  0.025463/  2.321724, val:  79.58%, val_best:  80.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-33  lr=['0.0100000'], tr/val_loss:  0.034514/  2.353822, val:  75.83%, val_best:  80.42%, tr:  99.90%, tr_best: 100.00%\n",
      "epoch-34  lr=['0.0100000'], tr/val_loss:  0.036565/  2.472864, val:  77.08%, val_best:  80.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-35  lr=['0.0100000'], tr/val_loss:  0.037575/  2.371022, val:  76.25%, val_best:  80.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-36  lr=['0.0100000'], tr/val_loss:  0.040780/  2.385971, val:  80.00%, val_best:  80.42%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-37  lr=['0.0100000'], tr/val_loss:  0.021542/  2.311005, val:  80.83%, val_best:  80.83%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-38  lr=['0.0100000'], tr/val_loss:  0.017162/  2.459316, val:  77.92%, val_best:  80.83%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-39  lr=['0.0100000'], tr/val_loss:  0.014603/  2.457679, val:  79.17%, val_best:  80.83%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-40  lr=['0.0100000'], tr/val_loss:  0.010144/  2.366603, val:  81.67%, val_best:  81.67%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-41  lr=['0.0100000'], tr/val_loss:  0.010757/  2.426996, val:  79.17%, val_best:  81.67%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-42  lr=['0.0100000'], tr/val_loss:  0.008795/  2.494078, val:  78.33%, val_best:  81.67%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-43  lr=['0.0100000'], tr/val_loss:  0.007568/  2.476596, val:  81.25%, val_best:  81.67%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-44  lr=['0.0100000'], tr/val_loss:  0.006832/  2.518400, val:  79.58%, val_best:  81.67%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-45  lr=['0.0100000'], tr/val_loss:  0.005036/  2.540632, val:  76.67%, val_best:  81.67%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-46  lr=['0.0100000'], tr/val_loss:  0.003517/  2.586160, val:  79.58%, val_best:  81.67%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-47  lr=['0.0100000'], tr/val_loss:  0.003328/  2.566434, val:  80.00%, val_best:  81.67%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-48  lr=['0.0100000'], tr/val_loss:  0.002277/  2.525652, val:  81.25%, val_best:  81.67%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-49  lr=['0.0100000'], tr/val_loss:  0.002904/  2.548539, val:  79.58%, val_best:  81.67%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-50  lr=['0.0100000'], tr/val_loss:  0.002023/  2.597169, val:  78.33%, val_best:  81.67%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-51  lr=['0.0100000'], tr/val_loss:  0.001652/  2.548975, val:  80.42%, val_best:  81.67%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-52  lr=['0.0100000'], tr/val_loss:  0.001749/  2.567517, val:  79.17%, val_best:  81.67%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-53  lr=['0.0100000'], tr/val_loss:  0.001587/  2.592825, val:  79.58%, val_best:  81.67%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-54  lr=['0.0100000'], tr/val_loss:  0.001443/  2.595873, val:  79.17%, val_best:  81.67%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-55  lr=['0.0100000'], tr/val_loss:  0.001619/  2.591659, val:  79.17%, val_best:  81.67%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-56  lr=['0.0100000'], tr/val_loss:  0.001200/  2.602864, val:  80.83%, val_best:  81.67%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-57  lr=['0.0100000'], tr/val_loss:  0.001208/  2.617077, val:  79.17%, val_best:  81.67%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-58  lr=['0.0100000'], tr/val_loss:  0.001058/  2.621557, val:  80.00%, val_best:  81.67%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-59  lr=['0.0100000'], tr/val_loss:  0.000953/  2.621355, val:  80.00%, val_best:  81.67%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-60  lr=['0.0100000'], tr/val_loss:  0.000913/  2.636833, val:  79.58%, val_best:  81.67%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-61  lr=['0.0100000'], tr/val_loss:  0.001017/  2.638914, val:  79.17%, val_best:  81.67%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-62  lr=['0.0100000'], tr/val_loss:  0.000910/  2.658217, val:  79.58%, val_best:  81.67%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-63  lr=['0.0100000'], tr/val_loss:  0.000850/  2.648272, val:  78.75%, val_best:  81.67%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-64  lr=['0.0100000'], tr/val_loss:  0.000716/  2.659813, val:  80.00%, val_best:  81.67%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-65  lr=['0.0100000'], tr/val_loss:  0.000775/  2.650242, val:  78.75%, val_best:  81.67%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-66  lr=['0.0100000'], tr/val_loss:  0.000758/  2.660281, val:  78.75%, val_best:  81.67%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-67  lr=['0.0100000'], tr/val_loss:  0.001080/  2.676538, val:  78.75%, val_best:  81.67%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-68  lr=['0.0100000'], tr/val_loss:  0.000816/  2.667408, val:  79.58%, val_best:  81.67%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-69  lr=['0.0100000'], tr/val_loss:  0.000879/  2.685518, val:  78.33%, val_best:  81.67%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-70  lr=['0.0100000'], tr/val_loss:  0.000651/  2.683178, val:  78.75%, val_best:  81.67%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-71  lr=['0.0100000'], tr/val_loss:  0.000749/  2.683851, val:  78.75%, val_best:  81.67%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-72  lr=['0.0100000'], tr/val_loss:  0.000843/  2.703210, val:  78.75%, val_best:  81.67%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-73  lr=['0.0100000'], tr/val_loss:  0.000515/  2.691486, val:  78.75%, val_best:  81.67%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-74  lr=['0.0100000'], tr/val_loss:  0.000512/  2.690239, val:  79.58%, val_best:  81.67%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-75  lr=['0.0100000'], tr/val_loss:  0.000504/  2.714003, val:  79.17%, val_best:  81.67%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-76  lr=['0.0100000'], tr/val_loss:  0.000502/  2.718285, val:  79.17%, val_best:  81.67%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-77  lr=['0.0100000'], tr/val_loss:  0.000505/  2.719853, val:  79.17%, val_best:  81.67%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-78  lr=['0.0100000'], tr/val_loss:  0.000545/  2.719781, val:  77.08%, val_best:  81.67%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-79  lr=['0.0100000'], tr/val_loss:  0.000504/  2.728358, val:  78.33%, val_best:  81.67%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-80  lr=['0.0100000'], tr/val_loss:  0.000510/  2.729598, val:  78.33%, val_best:  81.67%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-81  lr=['0.0100000'], tr/val_loss:  0.000507/  2.750781, val:  77.92%, val_best:  81.67%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-82  lr=['0.0100000'], tr/val_loss:  0.000493/  2.756430, val:  78.33%, val_best:  81.67%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-83  lr=['0.0100000'], tr/val_loss:  0.000457/  2.745851, val:  77.92%, val_best:  81.67%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-84  lr=['0.0100000'], tr/val_loss:  0.000407/  2.746582, val:  77.08%, val_best:  81.67%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-85  lr=['0.0100000'], tr/val_loss:  0.000462/  2.741990, val:  77.92%, val_best:  81.67%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-86  lr=['0.0100000'], tr/val_loss:  0.000395/  2.759062, val:  77.08%, val_best:  81.67%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-87  lr=['0.0100000'], tr/val_loss:  0.000367/  2.760758, val:  77.50%, val_best:  81.67%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-88  lr=['0.0100000'], tr/val_loss:  0.000432/  2.758750, val:  77.50%, val_best:  81.67%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-89  lr=['0.0100000'], tr/val_loss:  0.000459/  2.780727, val:  77.50%, val_best:  81.67%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-90  lr=['0.0100000'], tr/val_loss:  0.000384/  2.767049, val:  77.08%, val_best:  81.67%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-91  lr=['0.0100000'], tr/val_loss:  0.000392/  2.763684, val:  77.50%, val_best:  81.67%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-92  lr=['0.0100000'], tr/val_loss:  0.000400/  2.776798, val:  77.92%, val_best:  81.67%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-93  lr=['0.0100000'], tr/val_loss:  0.000365/  2.785791, val:  77.92%, val_best:  81.67%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-94  lr=['0.0100000'], tr/val_loss:  0.000674/  2.764038, val:  78.75%, val_best:  81.67%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-95  lr=['0.0100000'], tr/val_loss:  0.000348/  2.775957, val:  78.75%, val_best:  81.67%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-96  lr=['0.0100000'], tr/val_loss:  0.000340/  2.776202, val:  77.92%, val_best:  81.67%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-97  lr=['0.0100000'], tr/val_loss:  0.000749/  2.782957, val:  77.92%, val_best:  81.67%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-98  lr=['0.0100000'], tr/val_loss:  0.000442/  2.785433, val:  77.92%, val_best:  81.67%, tr: 100.00%, tr_best: 100.00%\n",
      "epoch-99  lr=['0.0100000'], tr/val_loss:  0.001001/  2.777271, val:  77.50%, val_best:  81.67%, tr: 100.00%, tr_best: 100.00%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3aa933c053ab45c695f35cf64517af66",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.006 MB of 0.006 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>iter_acc</td><td>▁▇▅▆▇▆██▇███████████████████████████████</td></tr><tr><td>summary_val_acc</td><td>▁▂▅▅▅▆▆█▇▇▇▇██▇██▇██████████████▇▇▇▇▇▇█▇</td></tr><tr><td>tr_acc</td><td>▁▄▅▆▇▇▇█████████████████████████████████</td></tr><tr><td>tr_epoch_loss</td><td>█▅▄▃▃▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_acc_best</td><td>▁▃▄▅▆▆▇▇▇▇██████████████████████████████</td></tr><tr><td>val_acc_now</td><td>▁▂▅▅▅▆▆█▇▇▇▇██▇██▇██████████████▇▇▇▇▇▇█▇</td></tr><tr><td>val_loss</td><td>▃▂▁▁▁▁▃▃▄▄▅▅▅▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇████████████</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>99</td></tr><tr><td>iter_acc</td><td>1.0</td></tr><tr><td>tr_acc</td><td>1.0</td></tr><tr><td>tr_epoch_loss</td><td>0.001</td></tr><tr><td>val_acc_best</td><td>0.81667</td></tr><tr><td>val_acc_now</td><td>0.775</td></tr><tr><td>val_loss</td><td>2.77727</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">bumbling-sweep-283</strong> at: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/rqylwmww' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/rqylwmww</a><br/> View project at: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>/data2/bh_wandb/wandb/run-20250430_101824-rqylwmww/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require(\"core\")`! See https://wandb.me/wandb-core for more information."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: gst7th8o with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBATCH: 16\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBN_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBPTT_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tDFA_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tIMAGE_SIZE: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tOTTT_input_trace_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tTIME: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tUDA_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \talpha_uda: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbias: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcfg: ['M', 'M', 200, 200]\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tchaching_on: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tconvTrue_fcFalse: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdata_path: /data2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tddp_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdenoise_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdvs_clipping: 5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdvs_duration: 100000\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepoch_num: 100\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \texclude_class: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \textra_train_dataset: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlast_lif: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.001\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_sg_width: 3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_decay: 0.5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_init: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_reset: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_threshold: 0.5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmerge_polarities: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmy_seed: 42\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnet_print: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_workers: 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer_what: SGD\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tpin_memory: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tpre_trained: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tpre_trained_path: net_save/save_now_net_weights_{unique_name}.pth\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \trate_coding: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tscheduler_name: no\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsingle_step: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsurrogate: hard_sigmoid\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_conv_kernel_size: 3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_conv_padding: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_conv_stride: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_trace_const1: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_trace_const2: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \ttdBN_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \ttrace_on: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \twhich_data: DVS_GESTURE_TONIC\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c012cd24d30741f8a50de66c9b901d81",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.011113441176712513, max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.19.10 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.17.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/data2/bh_wandb/wandb/run-20250430_102436-gst7th8o</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/gst7th8o' target=\"_blank\">stellar-sweep-285</a></strong> to <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/6pj3lh8j' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/6pj3lh8j</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/6pj3lh8j' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/6pj3lh8j</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/gst7th8o' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/gst7th8o</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'single_step' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'my_seed' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'TIME' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BATCH' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'IMAGE_SIZE' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'which_data' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'data_path' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'rate_coding' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_init' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_decay' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_threshold' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_reset' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_sg_width' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_conv_kernel_size' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_conv_stride' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_conv_padding' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_trace_const1' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_trace_const2' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'pre_trained' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'convTrue_fcFalse' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'cfg' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'net_print' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'pre_trained_path' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'learning_rate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'epoch_num' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'tdBN_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BN_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'surrogate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BPTT_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'optimizer_what' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'scheduler_name' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'ddp_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'dvs_clipping' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'dvs_duration' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'DFA_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'trace_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'OTTT_input_trace_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'exclude_class' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'merge_polarities' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'denoise_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'extra_train_dataset' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'num_workers' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'chaching_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'pin_memory' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'UDA_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'alpha_uda' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'bias' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'last_lif' was locked by 'sweep' (ignored update).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "param {'devices': '0', 'single_step': True, 'unique_name': 'main', 'my_seed': 42, 'TIME': 10, 'BATCH': 16, 'IMAGE_SIZE': 128, 'which_data': 'DVS_GESTURE_TONIC', 'data_path': '/data2', 'rate_coding': False, 'lif_layer_v_init': 0, 'lif_layer_v_decay': 0.5, 'lif_layer_v_threshold': 0.5, 'lif_layer_v_reset': 0, 'lif_layer_sg_width': 3, 'synapse_conv_kernel_size': 3, 'synapse_conv_stride': 1, 'synapse_conv_padding': 1, 'synapse_trace_const1': 1, 'synapse_trace_const2': 0, 'pre_trained': False, 'convTrue_fcFalse': False, 'cfg': ['M', 'M', 200, 200], 'net_print': True, 'pre_trained_path': 'net_save/save_now_net_weights_{unique_name}.pth', 'learning_rate': 0.001, 'epoch_num': 100, 'tdBN_on': False, 'BN_on': False, 'surrogate': 'hard_sigmoid', 'BPTT_on': False, 'optimizer_what': 'SGD', 'scheduler_name': 'no', 'ddp_on': False, 'dvs_clipping': 5, 'dvs_duration': 100000, 'DFA_on': False, 'trace_on': True, 'OTTT_input_trace_on': False, 'exclude_class': True, 'merge_polarities': False, 'denoise_on': False, 'extra_train_dataset': 0, 'num_workers': 2, 'chaching_on': True, 'pin_memory': True, 'UDA_on': False, 'alpha_uda': 1, 'bias': True, 'last_lif': False, 'current epoch': 0} \n",
      "\n",
      "dataset_hash = ffa516e60c3efd5e0208f72b4c36cb84\n",
      "cache path exists\n",
      "\n",
      "device ==> cuda\n",
      "\n",
      "DataParallel(\n",
      "  (module): REBORN_MY_SNN_FC(\n",
      "    (layers): REBORN_MY_Sequential(\n",
      "      (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (2): DimChanger_for_FC()\n",
      "      (3): SYNAPSE_FC(in_features=2048, out_features=200, TIME=10, bias=True, sstep=True)\n",
      "      (4): LIF_layer(v_init=0, v_decay=0.5, v_threshold=0.5, v_reset=0, sg_width=3, surrogate=hard_sigmoid, BPTT_on=False, trace_const1=1, trace_const2=0, TIME=10, sstep=True, trace_on=True)\n",
      "      (5): SYNAPSE_FC(in_features=200, out_features=200, TIME=10, bias=True, sstep=True)\n",
      "      (6): LIF_layer(v_init=0, v_decay=0.5, v_threshold=0.5, v_reset=0, sg_width=3, surrogate=hard_sigmoid, BPTT_on=False, trace_const1=1, trace_const2=0, TIME=10, sstep=True, trace_on=True)\n",
      "      (7): SYNAPSE_FC(in_features=200, out_features=10, TIME=10, bias=True, sstep=True)\n",
      "    )\n",
      "  )\n",
      ")\n",
      "\n",
      "========================================================\n",
      "Trainable parameters: 452,010\n",
      "========================================================\n",
      "\n",
      "epoch-0   lr=['0.0010000'], tr/val_loss:  2.305171/  2.301856, val:  10.83%, val_best:  10.83%, tr:   8.48%, tr_best:   8.48%\n",
      "epoch-1   lr=['0.0010000'], tr/val_loss:  2.273171/  2.217931, val:  17.08%, val_best:  17.08%, tr:  13.79%, tr_best:  13.79%\n",
      "epoch-2   lr=['0.0010000'], tr/val_loss:  2.011832/  1.834919, val:  44.17%, val_best:  44.17%, tr:  31.26%, tr_best:  31.26%\n",
      "epoch-3   lr=['0.0010000'], tr/val_loss:  1.599105/  1.586483, val:  50.83%, val_best:  50.83%, tr:  53.01%, tr_best:  53.01%\n",
      "epoch-4   lr=['0.0010000'], tr/val_loss:  1.395335/  1.482376, val:  53.75%, val_best:  53.75%, tr:  57.00%, tr_best:  57.00%\n",
      "epoch-5   lr=['0.0010000'], tr/val_loss:  1.269064/  1.392176, val:  57.92%, val_best:  57.92%, tr:  59.14%, tr_best:  59.14%\n",
      "epoch-6   lr=['0.0010000'], tr/val_loss:  1.169317/  1.332928, val:  62.08%, val_best:  62.08%, tr:  63.23%, tr_best:  63.23%\n",
      "epoch-7   lr=['0.0010000'], tr/val_loss:  1.105657/  1.311026, val:  61.25%, val_best:  62.08%, tr:  64.56%, tr_best:  64.56%\n",
      "epoch-8   lr=['0.0010000'], tr/val_loss:  1.034860/  1.293237, val:  64.17%, val_best:  64.17%, tr:  67.72%, tr_best:  67.72%\n",
      "epoch-9   lr=['0.0010000'], tr/val_loss:  0.997533/  1.271757, val:  61.67%, val_best:  64.17%, tr:  70.99%, tr_best:  70.99%\n",
      "epoch-10  lr=['0.0010000'], tr/val_loss:  0.959854/  1.283736, val:  60.83%, val_best:  64.17%, tr:  69.77%, tr_best:  70.99%\n",
      "epoch-11  lr=['0.0010000'], tr/val_loss:  0.912564/  1.239861, val:  64.58%, val_best:  64.58%, tr:  70.48%, tr_best:  70.99%\n",
      "epoch-12  lr=['0.0010000'], tr/val_loss:  0.889166/  1.243932, val:  65.00%, val_best:  65.00%, tr:  73.95%, tr_best:  73.95%\n",
      "epoch-13  lr=['0.0010000'], tr/val_loss:  0.852452/  1.266854, val:  66.25%, val_best:  66.25%, tr:  75.38%, tr_best:  75.38%\n",
      "epoch-14  lr=['0.0010000'], tr/val_loss:  0.799891/  1.307784, val:  61.67%, val_best:  66.25%, tr:  75.79%, tr_best:  75.79%\n",
      "epoch-15  lr=['0.0010000'], tr/val_loss:  0.773346/  1.294973, val:  67.92%, val_best:  67.92%, tr:  79.06%, tr_best:  79.06%\n",
      "epoch-16  lr=['0.0010000'], tr/val_loss:  0.782060/  1.218565, val:  68.33%, val_best:  68.33%, tr:  76.51%, tr_best:  79.06%\n",
      "epoch-17  lr=['0.0010000'], tr/val_loss:  0.715583/  1.229110, val:  69.58%, val_best:  69.58%, tr:  81.72%, tr_best:  81.72%\n",
      "epoch-18  lr=['0.0010000'], tr/val_loss:  0.682788/  1.315310, val:  67.92%, val_best:  69.58%, tr:  82.64%, tr_best:  82.64%\n",
      "epoch-19  lr=['0.0010000'], tr/val_loss:  0.674120/  1.295060, val:  65.42%, val_best:  69.58%, tr:  80.80%, tr_best:  82.64%\n",
      "epoch-20  lr=['0.0010000'], tr/val_loss:  0.640092/  1.304640, val:  68.33%, val_best:  69.58%, tr:  86.11%, tr_best:  86.11%\n",
      "epoch-21  lr=['0.0010000'], tr/val_loss:  0.617748/  1.265836, val:  70.83%, val_best:  70.83%, tr:  84.98%, tr_best:  86.11%\n",
      "epoch-22  lr=['0.0010000'], tr/val_loss:  0.628923/  1.262777, val:  73.75%, val_best:  73.75%, tr:  83.96%, tr_best:  86.11%\n",
      "epoch-23  lr=['0.0010000'], tr/val_loss:  0.572397/  1.320007, val:  72.50%, val_best:  73.75%, tr:  87.64%, tr_best:  87.64%\n",
      "epoch-24  lr=['0.0010000'], tr/val_loss:  0.546860/  1.340460, val:  67.50%, val_best:  73.75%, tr:  90.70%, tr_best:  90.70%\n"
     ]
    }
   ],
   "source": [
    "# sweep 하는 코드, 위 셀 주석처리 해야 됨.\n",
    "\n",
    "# 이런 워닝 뜨는 거는 걍 너가 main 안에서  wandb.config.update(hyperparameters)할 때 물려서임. 어차피 근데 sweep에서 지정한 걸로 덮어짐 \n",
    "# wandb: WARNING Config item 'BATCH' was locked by 'sweep' (ignored update).\n",
    "\n",
    "unique_name_hyper = 'main'\n",
    "sweep_configuration = {\n",
    "    'method': 'bayes', # 'random', 'bayes'\n",
    "    'name': f'my_snn_sweep{datetime.datetime.now().strftime(\"%Y%m%d_%H%M%S\")}',\n",
    "    'metric': {'goal': 'maximize', 'name': 'val_acc_best'},\n",
    "    'parameters': \n",
    "    {\n",
    "        # \"devices\": {\"values\": [\"1\"]},\n",
    "        \"single_step\": {\"values\": [True]},\n",
    "        # \"unique_name\": {\"values\": [unique_name_hyper]},\n",
    "        \"my_seed\": {\"values\": [42]},\n",
    "        \"TIME\": {\"values\": [10]},\n",
    "        \"BATCH\": {\"values\": [16]},\n",
    "        \"IMAGE_SIZE\": {\"values\": [128]},\n",
    "        \"which_data\": {\"values\": ['DVS_GESTURE_TONIC']},\n",
    "        \"data_path\": {\"values\": ['/data2']},\n",
    "        \"rate_coding\": {\"values\": [False]},\n",
    "        \"lif_layer_v_init\": {\"values\": [0.0]},\n",
    "        \"lif_layer_v_decay\": {\"values\": [0.5]},\n",
    "        \"lif_layer_v_threshold\": {\"values\": [0.25, 0.5, 0.75, 1.0]},\n",
    "        \"lif_layer_v_reset\": {\"values\": [10000.0, 0.0]},\n",
    "        \"lif_layer_sg_width\": {\"values\": [1.0,2.0,3.0,4.0,5.0]},\n",
    "\n",
    "        \"synapse_conv_kernel_size\": {\"values\": [3]},\n",
    "        \"synapse_conv_stride\": {\"values\": [1]},\n",
    "        \"synapse_conv_padding\": {\"values\": [1]},\n",
    "\n",
    "        \"synapse_trace_const1\": {\"values\": [1]},\n",
    "        \"synapse_trace_const2\": {\"values\": [0, 0.5]},\n",
    "\n",
    "        \"pre_trained\": {\"values\": [False]},\n",
    "        \"convTrue_fcFalse\": {\"values\": [False]},\n",
    "\n",
    "        \"cfg\": {\"values\": [['M','M',200,200]]},\n",
    "\n",
    "        \"net_print\": {\"values\": [True]},\n",
    "\n",
    "        \"pre_trained_path\": {\"values\": [\"net_save/save_now_net_weights_{unique_name}.pth\"]},\n",
    "        \"learning_rate\": {\"values\": [0.001,0.01,0.1,0.0001]}, \n",
    "        \"epoch_num\": {\"values\": [100]}, \n",
    "        \"tdBN_on\": {\"values\": [False]},\n",
    "        \"BN_on\": {\"values\": [False]},\n",
    "\n",
    "        \"surrogate\": {\"values\": ['hard_sigmoid']},\n",
    "\n",
    "        \"BPTT_on\": {\"values\": [False]},\n",
    "\n",
    "        \"optimizer_what\": {\"values\": ['SGD']},\n",
    "        \"scheduler_name\": {\"values\": ['no']},\n",
    "\n",
    "        \"ddp_on\": {\"values\": [False]},\n",
    "\n",
    "        \"dvs_clipping\": {\"values\": [5]}, \n",
    "\n",
    "        \"dvs_duration\": {\"values\": [100_000]}, \n",
    "\n",
    "        \"DFA_on\": {\"values\": [True, False]},\n",
    "\n",
    "        \"trace_on\": {\"values\": [True]},\n",
    "        \"OTTT_input_trace_on\": {\"values\": [False]},\n",
    "\n",
    "        \"exclude_class\": {\"values\": [True]},\n",
    "\n",
    "        \"merge_polarities\": {\"values\": [False]},\n",
    "        \"denoise_on\": {\"values\": [True, False]},\n",
    "\n",
    "        \"extra_train_dataset\": {\"values\": [0]},\n",
    "\n",
    "        \"num_workers\": {\"values\": [2]},\n",
    "        \"chaching_on\": {\"values\": [True]},\n",
    "        \"pin_memory\": {\"values\": [True]},\n",
    "\n",
    "        \"UDA_on\": {\"values\": [False]},\n",
    "        \"alpha_uda\": {\"values\": [1.0]},\n",
    "\n",
    "        \"bias\": {\"values\": [True]},\n",
    "\n",
    "        \"last_lif\": {\"values\": [False]},\n",
    "     }\n",
    "}\n",
    "\n",
    "def hyper_iter():\n",
    "    ### my_snn control board ########################\n",
    "    wandb.init(save_code=False, dir='/data2/bh_wandb', tags=[\"sweep\"])\n",
    "\n",
    "    my_snn_system(  \n",
    "        devices  =  \"0\",\n",
    "        single_step  =  wandb.config.single_step,\n",
    "        unique_name  =  unique_name_hyper,\n",
    "        my_seed  =  wandb.config.my_seed,\n",
    "        TIME  =  wandb.config.TIME,\n",
    "        BATCH  =  wandb.config.BATCH,\n",
    "        IMAGE_SIZE  =  wandb.config.IMAGE_SIZE,\n",
    "        which_data  =  wandb.config.which_data,\n",
    "        data_path  =  wandb.config.data_path,\n",
    "        rate_coding  =  wandb.config.rate_coding,\n",
    "        lif_layer_v_init  =  wandb.config.lif_layer_v_init,\n",
    "        lif_layer_v_decay  =  wandb.config.lif_layer_v_decay,\n",
    "        lif_layer_v_threshold  =  wandb.config.lif_layer_v_threshold,\n",
    "        lif_layer_v_reset  =  wandb.config.lif_layer_v_reset,\n",
    "        lif_layer_sg_width  =  wandb.config.lif_layer_sg_width,\n",
    "        synapse_conv_kernel_size  =  wandb.config.synapse_conv_kernel_size,\n",
    "        synapse_conv_stride  =  wandb.config.synapse_conv_stride,\n",
    "        synapse_conv_padding  =  wandb.config.synapse_conv_padding,\n",
    "        synapse_trace_const1  =  wandb.config.synapse_trace_const1,\n",
    "        synapse_trace_const2  =  wandb.config.synapse_trace_const2,\n",
    "        pre_trained  =  wandb.config.pre_trained,\n",
    "        convTrue_fcFalse  =  wandb.config.convTrue_fcFalse,\n",
    "        cfg  =  wandb.config.cfg,\n",
    "        net_print  =  wandb.config.net_print,\n",
    "        pre_trained_path  =  wandb.config.pre_trained_path,\n",
    "        learning_rate  =  wandb.config.learning_rate,\n",
    "        epoch_num  =  wandb.config.epoch_num,\n",
    "        tdBN_on  =  wandb.config.tdBN_on,\n",
    "        BN_on  =  wandb.config.BN_on,\n",
    "        surrogate  =  wandb.config.surrogate,\n",
    "        BPTT_on  =  wandb.config.BPTT_on,\n",
    "        optimizer_what  =  wandb.config.optimizer_what,\n",
    "        scheduler_name  =  wandb.config.scheduler_name,\n",
    "        ddp_on  =  wandb.config.ddp_on,\n",
    "        dvs_clipping  =  wandb.config.dvs_clipping,\n",
    "        dvs_duration  =  wandb.config.dvs_duration,\n",
    "        DFA_on  =  wandb.config.DFA_on,\n",
    "        trace_on  =  wandb.config.trace_on,\n",
    "        OTTT_input_trace_on  =  wandb.config.OTTT_input_trace_on,\n",
    "        exclude_class  =  wandb.config.exclude_class,\n",
    "        merge_polarities  =  wandb.config.merge_polarities,\n",
    "        denoise_on  =  wandb.config.denoise_on,\n",
    "        extra_train_dataset  =  wandb.config.extra_train_dataset,\n",
    "        num_workers  =  wandb.config.num_workers,\n",
    "        chaching_on  =  wandb.config.chaching_on,\n",
    "        pin_memory  =  wandb.config.pin_memory,\n",
    "        UDA_on  =  wandb.config.UDA_on,\n",
    "        alpha_uda  =  wandb.config.alpha_uda,\n",
    "        bias  =  wandb.config.bias,\n",
    "        last_lif  =  wandb.config.last_lif,\n",
    "                        ) \n",
    "    # sigmoid와 BN이 있어야 잘된다.\n",
    "    # average pooling\n",
    "    # 이 낫다. \n",
    "    \n",
    "    # nda에서는 decay = 0.25, threshold = 0.5, width =1, surrogate = rectangle, batch = 256, tdBN = True\n",
    "    ## OTTT 에서는 decay = 0.5, threshold = 1.0, surrogate = sigmoid, batch = 128, BN = True\n",
    "\n",
    "# sweep_id = '6pj3lh8j'\n",
    "sweep_id = wandb.sweep(sweep=sweep_configuration, project=f'my_snn {unique_name_hyper}')\n",
    "wandb.agent(sweep_id, function=hyper_iter, count=10000, project=f'my_snn {unique_name_hyper}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wandb.finish() "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aedat2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
