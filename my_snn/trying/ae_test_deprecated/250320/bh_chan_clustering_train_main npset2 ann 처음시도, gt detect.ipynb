{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ssp.train.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch   \n",
    "import torch.nn as nn \n",
    "import torch.nn.functional as F   \n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import torch.optim as optim\n",
    "from scipy import io\n",
    "import itertools\n",
    "import math\n",
    "import datetime\n",
    "import wandb\n",
    "import pickle\n",
    "import json\n",
    "import time\n",
    "import sys\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import accuracy_score\n",
    "from scipy.optimize import linear_sum_assignment\n",
    "from snntorch import spikegen\n",
    "from sklearn.manifold import TSNE\n",
    "\n",
    "\n",
    "# my module import\n",
    "from modules import *\n",
    "\n",
    "# os.environ[\"CUBLAS_WORKSPACE_CONFIG\"] = \":4096:8\"\n",
    "\n",
    "# modules 폴더에 새모듈.py 만들면\n",
    "# modules/__init__py 파일에 form .새모듈 import * 하셈\n",
    "# 그리고 새모듈.py에서 from modules.새모듈 import * 하셈"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cluster_train_system( \n",
    "    gpu = '4',\n",
    "    Conv_net = True,\n",
    "    SAE_net = True,\n",
    "\n",
    "    # hyperparameter\n",
    "    dataset_num = 16,\n",
    "    spike_length = 50,\n",
    "    num_cluster = 4,  # 클러스터 수 설정 # 논문엔 4개라는데 여기서는 3개로 했네\n",
    "    training_cycle = 2400, # 그 초기 몇개까지만 cluster update할지\n",
    "\n",
    "\n",
    "    batch_size = 32,\n",
    "    max_epoch = 7000,\n",
    "    learning_rate = 0.001,\n",
    "    normalize_on = False, # True or False #이거 안 씀 # 이거 별로 안 좋은 normalize같음 # 쓸 거면 다른 거 써라.\n",
    "    need_bias = False,\n",
    "    # first_layer_no_train = False\n",
    "    lif_add_at_first = False,\n",
    "    my_seed = 42,\n",
    "\n",
    "    TIME = 10, # SAE일 때만 유효\n",
    "    v_decay = 0.5,\n",
    "    v_threshold = 0.5,\n",
    "    v_reset = 10000.0, # 10000이상 일 시 hard reset\n",
    "    BPTT_on = True,\n",
    "\n",
    "    SAE_hidden_nomean = True,\n",
    "    current_time = '20250101_210938_786',\n",
    "\n",
    "    optimizer = 'Adam',\n",
    "    coarse_com_mode = True,\n",
    "    coarse_com_config = (2.0, -2.0), # (max, min)\n",
    "\n",
    "    sae_l2_norm_bridge = True,\n",
    "    sae_lif_bridge = False,\n",
    "\n",
    "    accuracy_check_epoch_term = 5,\n",
    "    \n",
    "    lif_add_at_last = False,\n",
    "\n",
    "    two_channel_input = False,\n",
    "\n",
    "    lateral_feature_num = 4,\n",
    "\n",
    "    lc_adc_on = False, \n",
    "\n",
    "    converted_net_forward = False,\n",
    "\n",
    "    pretrained_net = None, \n",
    "\n",
    "    vth_mul_on = False,\n",
    "    batch_norm_on = False,\n",
    "\n",
    "    l2_norm_loss_weight = 0.0,\n",
    "\n",
    "    QCFS_neuron_on = False,\n",
    "\n",
    "    quantize_level_num = 0,\n",
    "\n",
    "    fusion_net = False, # True False\n",
    "    repeat_coding = False,\n",
    "    \n",
    "    sae_relu_on = False,\n",
    "\n",
    "    conv1d_scaling = False,\n",
    "\n",
    "    norm01 = True,\n",
    "\n",
    "    chan_loss_factor = 1.0,\n",
    "    ):\n",
    "    if coarse_com_mode == True:\n",
    "        assert coarse_com_config[0] > coarse_com_config[1], 'coarse_com_config[0] > coarse_com_config[1]이어야 함'\n",
    "        assert converted_net_forward == False\n",
    "        # assert SAE_net == True, 'coarse_com_mode는 SAE_net이 True일 때만 가능'\n",
    "    if two_channel_input == True:\n",
    "        assert Conv_net and coarse_com_mode, 'two_channel_input는 Conv_net이 True일 때만 가능'\n",
    "    if lc_adc_on == True:\n",
    "        assert coarse_com_mode and SAE_net, 'lc_adc_on은 coarse_com_mode와 SAE_net이 True일 때만 가능'\n",
    "    if converted_net_forward == True:\n",
    "        assert SAE_net == False, 'converted_net_forward는 SAE_net이 False일 때만 가능'\n",
    "    if conv1d_scaling:\n",
    "        assert Conv_net and coarse_com_mode and normalize_on\n",
    "    seed_assign(my_seed)\n",
    "    ## 함수 내 모든 로컬 변수 저장 ########################################################\n",
    "    hyperparameters = locals()\n",
    "    print(hyperparameters)\n",
    "    # JSON으로 저장\n",
    "    with open(f\"result_save/cluster_accuracy_history_{current_time}.json\", 'w') as f:\n",
    "        json.dump(hyperparameters, f, indent=4)\n",
    "    ######################################################################################\n",
    "\n",
    "    \n",
    "    wandb.config.update(hyperparameters)\n",
    "    wandb.run.name = f'{current_time}_SAE_net_{SAE_net}_v_threshold_{v_threshold}'\n",
    "\n",
    "    # data_path = [\"/data2/spike_sorting/neuropixels_choi/set1/20141202_all_es_merged_3125000_limit_autoencoder_data.pt\",]\n",
    "    # label_path = [\"/data2/spike_sorting/neuropixels_choi/set1/20141202_all_es_merged_3125000_limit_autoencoder_label.pt\"]\n",
    "    data_path = [\"/data2/spike_sorting/neuropixels_choi/set2/20150924_1_e_merged_3125000_limit_autoencoder_data.pt\",]\n",
    "    label_path = [\"/data2/spike_sorting/neuropixels_choi/set2/20150924_1_e_merged_3125000_limit_autoencoder_label.pt\"]\n",
    "    AE_train_data = data_path[0] #AE_train_path_gt_detect #AE_train_path_real_detect\n",
    "\n",
    "    os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\" \n",
    "    os.environ[\"CUDA_VISIBLE_DEVICES\"]= gpu\n",
    "\n",
    "\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "\n",
    "    if coarse_com_mode == True:\n",
    "        level_num = TIME\n",
    "        TIME = spike_length\n",
    "        spike_length = level_num\n",
    "        level_interval = (coarse_com_config[0] - coarse_com_config[1]) / (level_num-1)  # max - min\n",
    "        levels = [coarse_com_config[1] + level_interval * i for i in range(level_num)]\n",
    "        levels = torch.tensor(levels).to(torch.float32).to(device)\n",
    "        levels = levels.repeat(TIME,1) \n",
    "        # print('levels', levels, levels.shape) # TIME, level_num\n",
    "\n",
    "    n_sample = spike_length\n",
    "\n",
    "    class spikedataset(Dataset):\n",
    "        def __init__(self, path, transform = None):    \n",
    "            self.transform = transform\n",
    "            self.spike = torch.load(path)\n",
    "            \n",
    "        def __getitem__(self, index):\n",
    "            spike = self.spike[index]            \n",
    "            if self.transform is not None:\n",
    "                spike = self.transform(spike)\n",
    "            return spike\n",
    "        \n",
    "        def __len__(self):\n",
    "            return len(self.spike)\n",
    "\n",
    "    train_dataset = spikedataset(AE_train_data)\n",
    "    train_loader = DataLoader(dataset = train_dataset, batch_size = batch_size, shuffle = True)\n",
    "\n",
    "    # 모델 초기화\n",
    "    if SAE_net == False: # 여기서는 l2norm, lif bridge 둘 다 true면 l2norm먼저\n",
    "        assert two_channel_input == False\n",
    "\n",
    "        if Conv_net == True:\n",
    "            # input_channels = 2 if two_channel_input else 1\n",
    "            input_channels = TIME if coarse_com_mode else 1\n",
    "            if fusion_net == True:\n",
    "                assert False, '이거 맞음? 다시 확인'\n",
    "                net = FUSION_net_conv1(input_channels=input_channels, input_length=n_sample, encoder_ch = [32, 64, 96], fc_dim = lateral_feature_num, padding = 0, stride = 2, kernel_size = 3, \n",
    "                                    synapse_fc_trace_const1=1, \n",
    "                                    synapse_fc_trace_const2=v_decay, #안씀 \n",
    "                                    TIME=TIME, v_init=0.0, v_decay=v_decay, v_threshold=v_threshold, v_reset=v_reset, \n",
    "                                    sg_width=4.0, surrogate='sigmoid', BPTT_on=BPTT_on, need_bias=need_bias, lif_add_at_first=lif_add_at_first,\n",
    "                                    sae_l2_norm_bridge = sae_l2_norm_bridge, sae_lif_bridge = sae_lif_bridge, lif_add_at_last=lif_add_at_last, repeat_coding=repeat_coding).to(device)\n",
    "            else: \n",
    "                net = Autoencoder_conv1(input_channels=input_channels, input_length=n_sample, encoder_ch = [32, 64, 96], fc_dim = lateral_feature_num, padding = 0, stride = 2, kernel_size = 3, need_bias=need_bias, l2norm_bridge=sae_l2_norm_bridge, relu_bridge=sae_lif_bridge, activation_collector_on=False,\n",
    "                                        batch_norm_on=batch_norm_on, QCFS_neuron_on=QCFS_neuron_on).to(device)\n",
    "            net = torch.nn.DataParallel(net)\n",
    "            if converted_net_forward:\n",
    "                converted_net = SAE_converted_conv1(input_channels=input_channels, input_length=n_sample, encoder_ch = [32, 64, 96], fc_dim = lateral_feature_num, padding = 0, stride = 2, kernel_size = 3, \n",
    "                                    synapse_fc_trace_const1=1, \n",
    "                                    synapse_fc_trace_const2=v_decay, #안씀 \n",
    "                                    TIME=TIME, v_init=0.0, v_decay=v_decay, v_threshold=v_threshold, v_reset=v_reset, \n",
    "                                    sg_width=4.0, surrogate='sigmoid', BPTT_on=BPTT_on, need_bias=need_bias, lif_add_at_first=lif_add_at_first,\n",
    "                                    sae_l2_norm_bridge = sae_l2_norm_bridge, sae_lif_bridge = sae_lif_bridge, lif_add_at_last=lif_add_at_last,\n",
    "                                    vth_mul_on=vth_mul_on, batch_norm_on=batch_norm_on).to(device) # lif bridge는 무조건 들어가게 해놨음.\n",
    "                converted_net = torch.nn.DataParallel(converted_net)\n",
    "                print('converted_net', converted_net)\n",
    "        else:\n",
    "            n_sample = n_sample * TIME if coarse_com_mode else n_sample\n",
    "            net = Autoencoder_only_FC(encoder_ch=[400, lateral_feature_num], decoder_ch=[400,n_sample], n_sample=n_sample, need_bias=need_bias, l2norm_bridge=sae_l2_norm_bridge, relu_bridge=sae_lif_bridge, activation_collector_on=False,\n",
    "                                    batch_norm_on=batch_norm_on, QCFS_neuron_on=QCFS_neuron_on).to(device)\n",
    "            net = torch.nn.DataParallel(net)\n",
    "            if converted_net_forward:\n",
    "                converted_net = SAE_converted_fc(encoder_ch=[400, lateral_feature_num], \n",
    "                                    decoder_ch=[400, n_sample], \n",
    "                                    in_channels=n_sample, # in_channel 이 여기선 걍 lenght.\n",
    "                                    synapse_fc_trace_const1=1,\n",
    "                                    synapse_fc_trace_const2=v_decay,  #안씀 \n",
    "                                    TIME=TIME, v_init=0.0, v_decay=v_decay, v_threshold=v_threshold, v_reset=v_reset, \n",
    "                                    sg_width=4.0, surrogate='sigmoid', BPTT_on=BPTT_on, need_bias=need_bias, lif_add_at_first=lif_add_at_first,\n",
    "                                    sae_l2_norm_bridge = sae_l2_norm_bridge, sae_lif_bridge = sae_lif_bridge, lif_add_at_last=lif_add_at_last,\n",
    "                                    vth_mul_on=vth_mul_on, batch_norm_on=batch_norm_on).to(device) # lif bridge는 무조건 들어가게 해놨음.\n",
    "                converted_net = torch.nn.DataParallel(converted_net)\n",
    "                # print('converted_net', converted_net)\n",
    "    else:\n",
    "        if Conv_net == True: \n",
    "            input_channels = 1\n",
    "            input_channels = 2 if two_channel_input else 1\n",
    "            if fusion_net == True:  \n",
    "                assert coarse_com_mode == True\n",
    "                # net = SAE_FUSION2_net_conv1(input_channels=input_channels, input_length=n_sample, encoder_ch = [32, 64, 96], fc_dim = lateral_feature_num, padding = 0, stride = 2, kernel_size = 3, \n",
    "                #                     synapse_fc_trace_const1=1, \n",
    "                #                     synapse_fc_trace_const2=v_decay, #안씀 \n",
    "                #                     TIME=TIME, v_init=0.0, v_decay=v_decay, v_threshold=v_threshold, v_reset=v_reset, \n",
    "                #                     sg_width=4.0, surrogate='sigmoid', BPTT_on=BPTT_on, need_bias=need_bias, lif_add_at_first=lif_add_at_first,\n",
    "                #                     sae_l2_norm_bridge = sae_l2_norm_bridge, sae_lif_bridge = sae_lif_bridge, lif_add_at_last=lif_add_at_last, batch_norm_on=batch_norm_on, sae_relu_on=sae_relu_on).to(device)\n",
    "                # net = SAE_FUSION3_net_conv1(input_channels=input_channels, input_length=n_sample, encoder_ch = [32, 64, 96], fc_dim = lateral_feature_num, padding = 0, stride = 2, kernel_size = 3, \n",
    "                #                     synapse_fc_trace_const1=1, \n",
    "                #                     synapse_fc_trace_const2=v_decay, #안씀 \n",
    "                #                     TIME=TIME, v_init=0.0, v_decay=v_decay, v_threshold=v_threshold, v_reset=v_reset, \n",
    "                #                     sg_width=4.0, surrogate='sigmoid', BPTT_on=BPTT_on, need_bias=need_bias, lif_add_at_first=lif_add_at_first,\n",
    "                #                     sae_l2_norm_bridge = sae_l2_norm_bridge, sae_lif_bridge = sae_lif_bridge, lif_add_at_last=lif_add_at_last, batch_norm_on=batch_norm_on, sae_relu_on=sae_relu_on).to(device)\n",
    "                # net = SAE_FUSION4_net_conv1(input_channels=input_channels, input_length=n_sample, encoder_ch = [32, 64, 96], fc_dim = lateral_feature_num, padding = 0, stride = 2, kernel_size = 3, \n",
    "                #                     synapse_fc_trace_const1=1, \n",
    "                #                     synapse_fc_trace_const2=v_decay, #안씀 \n",
    "                #                     TIME=TIME, v_init=0.0, v_decay=v_decay, v_threshold=v_threshold, v_reset=v_reset, \n",
    "                #                     sg_width=4.0, surrogate='sigmoid', BPTT_on=BPTT_on, need_bias=need_bias, lif_add_at_first=lif_add_at_first,\n",
    "                #                     sae_l2_norm_bridge = sae_l2_norm_bridge, sae_lif_bridge = sae_lif_bridge, lif_add_at_last=lif_add_at_last, batch_norm_on=batch_norm_on, sae_relu_on=sae_relu_on).to(device)\n",
    "                net = SAE_FUSION5_net_conv1(input_channels=input_channels, input_length=n_sample, encoder_ch = [32, 64, 96], fc_dim = lateral_feature_num, padding = 0, stride = 2, kernel_size = 3, \n",
    "                                    synapse_fc_trace_const1=1, \n",
    "                                    synapse_fc_trace_const2=v_decay, #안씀 \n",
    "                                    TIME=TIME, v_init=0.0, v_decay=v_decay, v_threshold=v_threshold, v_reset=v_reset, \n",
    "                                    sg_width=4.0, surrogate='sigmoid', BPTT_on=BPTT_on, need_bias=need_bias, lif_add_at_first=lif_add_at_first,\n",
    "                                    sae_l2_norm_bridge = sae_l2_norm_bridge, sae_lif_bridge = sae_lif_bridge, lif_add_at_last=lif_add_at_last, batch_norm_on=batch_norm_on, sae_relu_on=sae_relu_on).to(device)\n",
    "                # net = SAE_FUSION6_net_conv1(input_channels=input_channels, input_length=n_sample, encoder_ch = [32, 64, 96], fc_dim = lateral_feature_num, padding = 0, stride = 2, kernel_size = 3, \n",
    "                #                     synapse_fc_trace_const1=1, \n",
    "                #                     synapse_fc_trace_const2=v_decay, #안씀 \n",
    "                #                     TIME=TIME, v_init=0.0, v_decay=v_decay, v_threshold=v_threshold, v_reset=v_reset, \n",
    "                #                     sg_width=4.0, surrogate='sigmoid', BPTT_on=BPTT_on, need_bias=need_bias, lif_add_at_first=lif_add_at_first,\n",
    "                #                     sae_l2_norm_bridge = sae_l2_norm_bridge, sae_lif_bridge = sae_lif_bridge, lif_add_at_last=lif_add_at_last, batch_norm_on=batch_norm_on, sae_relu_on=sae_relu_on).to(device)\n",
    "                # net = SAE_FUSION7_net_conv1(input_channels=input_channels, input_length=n_sample, encoder_ch = [32, 64, 96], fc_dim = lateral_feature_num, padding = 0, stride = 2, kernel_size = 3, \n",
    "                #                     synapse_fc_trace_const1=1, \n",
    "                #                     synapse_fc_trace_const2=v_decay, #안씀 \n",
    "                #                     TIME=TIME, v_init=0.0, v_decay=v_decay, v_threshold=v_threshold, v_reset=v_reset, \n",
    "                #                     sg_width=4.0, surrogate='sigmoid', BPTT_on=BPTT_on, need_bias=need_bias, lif_add_at_first=lif_add_at_first,\n",
    "                #                     sae_l2_norm_bridge = sae_l2_norm_bridge, sae_lif_bridge = sae_lif_bridge, lif_add_at_last=lif_add_at_last, batch_norm_on=batch_norm_on, sae_relu_on=sae_relu_on).to(device)\n",
    "            else:\n",
    "                net = SAE_conv1(input_channels=input_channels, input_length=n_sample, encoder_ch = [32, 64, 96], fc_dim = lateral_feature_num, padding = 0, stride = 2, kernel_size = 3, \n",
    "                                    synapse_fc_trace_const1=1, \n",
    "                                    synapse_fc_trace_const2=v_decay, #안씀 \n",
    "                                    TIME=TIME, v_init=0.0, v_decay=v_decay, v_threshold=v_threshold, v_reset=v_reset, \n",
    "                                    sg_width=4.0, surrogate='sigmoid', BPTT_on=BPTT_on, need_bias=need_bias, lif_add_at_first=lif_add_at_first,\n",
    "                                    sae_l2_norm_bridge = sae_l2_norm_bridge, sae_lif_bridge = sae_lif_bridge, lif_add_at_last=lif_add_at_last, batch_norm_on=batch_norm_on, sae_relu_on=sae_relu_on).to(device)\n",
    "            # net = SAE_conv1_DR(input_channels=input_channels, input_length=n_sample, encoder_ch = [32, 64, 96], fc_dim = lateral_feature_num, padding = 0, stride = 2, kernel_size = 3, \n",
    "            #                     synapse_fc_trace_const1=1, \n",
    "            #                     synapse_fc_trace_const2=v_decay, #안씀 \n",
    "            #                     TIME=TIME, v_init=0.0, v_decay=v_decay, v_threshold=v_threshold, v_reset=v_reset, \n",
    "            #                     sg_width=4.0, surrogate='sigmoid', BPTT_on=BPTT_on, need_bias=need_bias, lif_add_at_first=lif_add_at_first,\n",
    "            #                     sae_l2_norm_bridge = sae_l2_norm_bridge, sae_lif_bridge = sae_lif_bridge, lif_add_at_last=lif_add_at_last, batch_norm_on=batch_norm_on).to(device)\n",
    "            net = torch.nn.DataParallel(net)\n",
    "        else:\n",
    "            net = SAE_fc_only(encoder_ch=[400, lateral_feature_num], \n",
    "                                decoder_ch=[400, n_sample], \n",
    "                                in_channels=n_sample, # in_channel 이 여기선 걍 lenght.\n",
    "                                synapse_fc_trace_const1=1,\n",
    "                                synapse_fc_trace_const2=v_decay,  #안씀 \n",
    "                                TIME=TIME, v_init=0.0, v_decay=v_decay, v_threshold=v_threshold, v_reset=v_reset, \n",
    "                                sg_width=4.0, surrogate='sigmoid', BPTT_on=BPTT_on, need_bias=need_bias, lif_add_at_first=lif_add_at_first,\n",
    "                                sae_l2_norm_bridge = sae_l2_norm_bridge, sae_lif_bridge = sae_lif_bridge, lif_add_at_last=lif_add_at_last, batch_norm_on=batch_norm_on, sae_relu_on=sae_relu_on).to(device)\n",
    "            net = torch.nn.DataParallel(net)\n",
    "\n",
    "    # net = torch.load('/home/bhkim003/github_folder/ByeonghyeonKim/my_snn/net_save/save_now_net_AE_re_e7000.pth')\n",
    "    # net = torch.load('/home/bhkim003/github_folder/ByeonghyeonKim/my_snn/net_save/save_now_net_20250101_210938_786.pth')\n",
    "    # load했으면 torch.nn.DataParallel 하지마\n",
    "    # net.module.load_state_dict(torch.load('/home/bhkim003/github_folder/ByeonghyeonKim/my_snn/net_save/save_now_net_annbase_20250108_210641_941.pth'))\n",
    "    if pretrained_net != None:\n",
    "        ######################## 모델이 달라서 dict로 weight만 넣고싶을 때\n",
    "        # # 저장된 가중치 로드\n",
    "        saved_state_dict = torch.load(pretrained_net)\n",
    "        current_state_dict = net.module.state_dict()\n",
    "\n",
    "        # 함수 호출로 가중치 매핑\n",
    "        updated_state_dict = map_and_load_weights(saved_state_dict, current_state_dict)\n",
    "\n",
    "        # 업데이트된 state_dict를 네트워크에 로드\n",
    "        net.module.load_state_dict(updated_state_dict)\n",
    "        ######################## 모델이 달라서 dict로 weight만 넣고싶을 때\n",
    "\n",
    "        ############## 일반적일 때\n",
    "        # net.module.load_state_dict(torch.load(pretrained_net))\n",
    "        ############## 일반적일 때\n",
    "    \n",
    "        # pre_net = Autoencoder_conv1(input_channels=input_channels, input_length=n_sample, encoder_ch = [32, 64, 96], fc_dim = lateral_feature_num, padding = 0, stride = 2, kernel_size = 3, need_bias=need_bias, l2norm_bridge=sae_l2_norm_bridge, relu_bridge=sae_lif_bridge, activation_collector_on=False,\n",
    "        #                         batch_norm_on=batch_norm_on, QCFS_neuron_on=False).to(device)\n",
    "        # pre_net = torch.nn.DataParallel(net)\n",
    "        # pre_net.module.load_state_dict(torch.load(pretrained_net))\n",
    "        # copy_weights(pre_net.module.encoder , net.module.encoder )\n",
    "        # copy_weights(pre_net.module.decoder , net.module.decoder  )\n",
    "\n",
    "        \n",
    "\n",
    "\n",
    "\n",
    "    wandb.watch(net, log=\"all\", log_freq = 10)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    if SAE_net == True:\n",
    "        assert 'SAE' in net.module.__class__.__name__\n",
    "\n",
    "\n",
    "\n",
    "    net = net.to(device)\n",
    "    print(f\"Total number of encoder parameters: {sum(p.numel() for p in net.module.encoder.parameters())}\")\n",
    "    print(net)\n",
    "    print('Device:',device)\n",
    "\n",
    "    \n",
    "    if optimizer == 'Adam':\n",
    "        optimizer = optim.Adam(net.parameters(), lr=learning_rate)\n",
    "    elif optimizer == 'SGD':\n",
    "        optimizer = optim.SGD(net.parameters(), lr = learning_rate, momentum = 0.9)\n",
    "    else:\n",
    "        assert False, 'optimizer를 잘못 입력했습니다.'\n",
    "        \n",
    "    loss_history = []\n",
    "\n",
    "\n",
    "    print(f\"\\nStart Training, current_time = {current_time}\")\n",
    "\n",
    "    if SAE_net == True:\n",
    "        assert 'SAE' in net.module.__class__.__name__\n",
    "        \n",
    "    k_means_acc_best = 0\n",
    "    min_loss = 9999999\n",
    "    min_loss_normal = 9999999\n",
    "    min_loss_coarse = 9999999\n",
    "    for epoch in range(max_epoch):\n",
    "        print()\n",
    "        l2_loss_bin= 0\n",
    "        ae_train_start_time = time.time()\n",
    "        running_loss = 0.0\n",
    "        running_loss_normal = 0.0\n",
    "        running_loss_coarse = 0.0\n",
    "        iter = 0\n",
    "        net.train()\n",
    "        # if True or max_epoch != 1:\n",
    "        wrong_element_sum = 0\n",
    "        same_data_num = 0\n",
    "        total_data_num = 0\n",
    "        if max_epoch != 1:\n",
    "            for data in train_loader:\n",
    "                optimizer.zero_grad()\n",
    "                total_data_num += len(data)\n",
    "                data = data.to(device)\n",
    "                scaling = (level_num-3)/level_num if conv1d_scaling else 1.0\n",
    "                data = zero_to_one_normalize_features(data, level_num=quantize_level_num, coarse_com_config=coarse_com_config, scaling=scaling, norm01=norm01) if normalize_on else data\n",
    "                spike_backup = data\n",
    "                spike = data\n",
    "                spike = spike.to(device) # batch, feature\n",
    "                spike_for_fusion2_net = spike\n",
    "                if coarse_com_mode == True and 'SAE' in net.module.__class__.__name__:\n",
    "                    spike = spike.unsqueeze(2).repeat(1, 1, level_num) # spike_length == level_num # (batch, time, feature)로 변환 \n",
    "                    spike = (spike > levels).to(torch.float) \n",
    "\n",
    "                    spike = (spike == 0).cumsum(dim=-1).eq(1).to(torch.float) if lc_adc_on == True else spike\n",
    "\n",
    "                    # spike: batch, time, level_num\n",
    "                    # levels: time, level_num\n",
    "                    if Conv_net == True:\n",
    "                        spike = spike.unsqueeze(-2) # batch, time, in_channel, feature or batch in_channel,feature\n",
    "                        if two_channel_input == True:\n",
    "                            spike_backup = spike_backup.to(device)\n",
    "                            spike_backup = spike_backup.unsqueeze(2).repeat(1, 1, level_num) # spike_length == level_num # (batch, time, feature)로 변환 \n",
    "                            spike_backup = (spike_backup <= levels).to(torch.float) \n",
    "                            spike_backup = (spike_backup == 1).cumsum(dim=-1).eq(1).to(torch.float) if lc_adc_on == True else spike_backup\n",
    "                            spike_backup = spike_backup.unsqueeze(-2)\n",
    "                            spike = torch.cat((spike, spike_backup), dim=-2)\n",
    "                    assert spike.shape[0] == batch_size and spike.shape[1] == TIME\n",
    "                elif 'SAE' in net.module.__class__.__name__:\n",
    "                    spike = spike.unsqueeze(-1).repeat(1, 1, TIME).permute(0,2,1) # (batch, time, feature)로 변환\n",
    "                    if Conv_net == True:\n",
    "                        spike = spike.unsqueeze(-2) # batch, time, in_channel, feature or batch in_channel,feature\n",
    "                else:\n",
    "                    if Conv_net == True:\n",
    "                        if coarse_com_mode == False:\n",
    "                            spike = spike.unsqueeze(-2) #batch in_channel,feature\n",
    "                        else:\n",
    "                            spike = spike.unsqueeze(2).repeat(1, 1, level_num) # spike_length == level_num # (batch, time, feature)로 변환 \n",
    "                            spike = (spike > levels).to(torch.float) \n",
    "\n",
    "                            spike = (spike == 0).cumsum(dim=-1).eq(1).to(torch.float) if lc_adc_on == True else spike\n",
    "\n",
    "                    else:\n",
    "                        if coarse_com_mode == False:\n",
    "                            pass\n",
    "                        else:\n",
    "                            spike = spike.unsqueeze(2).repeat(1, 1, level_num) # spike_length == level_num # (batch, time, feature)로 변환 \n",
    "                            spike = (spike > levels).to(torch.float) \n",
    "\n",
    "                            spike = (spike == 0).cumsum(dim=-1).eq(1).to(torch.float) if lc_adc_on == True else spike\n",
    "\n",
    "                            # spike: batch, time, feature\n",
    "                            spike = spike.reshape(spike.shape[0], -1)\n",
    "\n",
    "                    \n",
    "\n",
    "\n",
    "                    # if fusion_net == True:\n",
    "                    #     spike = spikegen.rate(spike, num_steps=TIME).transpose(0, 1)\n",
    "\n",
    "                # spike_class = net(spike) # batch, time, feature\n",
    "                encoded_spike = net.module.encoder(spike)\n",
    "                spike_class = net.module.decoder(encoded_spike)\n",
    "                \n",
    "                # # 각 레이어의 weight와 bias의 비트 수 출력\n",
    "                # print(\"\\n=== Encoder & Decoder Weight/Bias Bit Size ===\")\n",
    "                # for name, param in net.module.named_parameters():\n",
    "                #     bit_size = param.element_size() * 8  # 바이트 크기에 8을 곱하여 비트 수 계산\n",
    "                #     print(f\"{name}: {bit_size} bits ({param.dtype})\")\n",
    "\n",
    "\n",
    "                # print('encoded_spike', spike_class)\n",
    "\n",
    "                # for i in range (2):\n",
    "                #     plot_spike(spike[i,:,0,:].cpu().numpy())\n",
    "                #     # plot_spike(spike[i,:,1,:].cpu().numpy())\n",
    "                #     plot_origin_spike(spike_class.squeeze()[i].cpu().detach().numpy(), min_max_y_on = True)\n",
    "                # assert False\n",
    "                        \n",
    "\n",
    "                loss = 0\n",
    "                loss_normal = torch.tensor(0.0)\n",
    "                loss_coarse = torch.tensor(0.0)\n",
    "                if coarse_com_mode == True and 'SAE' in net.module.__class__.__name__:\n",
    "                    criterion = nn.MSELoss().to(device)\n",
    "                    # loss1 = nn.MSELoss()(spike_class[..., 5:25], spike[..., 5:25])\n",
    "                    # loss2 = nn.MSELoss()(spike_class[..., 0:5], spike[..., 0:5])\n",
    "                    # loss3 = nn.MSELoss()(spike_class[..., 25:spike_length], spike[..., 25:spike_length])\n",
    "                    # loss = loss1 * chan_loss_factor*2.125 + (loss2 + loss3) *(1/chan_loss_factor)/ 4 \n",
    "\n",
    "                    # loss1 = nn.MSELoss()(spike_class[..., 5:25, :], spike[..., 5:25, :])\n",
    "                    # loss2 = nn.MSELoss()(spike_class[..., 0:5, :], spike[..., 0:5, :])\n",
    "                    # loss3 = nn.MSELoss()(spike_class[..., 25:spike_length, :], spike[..., 25:spike_length, :])\n",
    "                    # loss = loss1 * chan_loss_factor*2.125 + (loss2 + loss3) *(1/chan_loss_factor)/ 4 \n",
    "                    if fusion_net:\n",
    "                        # print('1', spike.shape) # batch, time, in_channel, feature [32, 50, 1, 50]\n",
    "                        \n",
    "                        # ### coarse에서 ann loss 만들기 ######\n",
    "                        # spike = spike.squeeze()\n",
    "                        # assert two_channel_input == False\n",
    "                        # zero_mask = (spike == 0)  # 0이 있는 위치\n",
    "                        # first_zero_idx = torch.where(zero_mask, torch.arange(spike.shape[-1]).to(device), spike.shape[-1]-1).min(dim=-1).values\n",
    "                        # spike = levels[0][first_zero_idx]\n",
    "                        # # plot_origin_spike(spike[0].cpu().detach().numpy())\n",
    "                        # ### coarse에서 ann loss 만들기 ######\n",
    "\n",
    "                        ### 그냥 원래 스파이크로 ann loss 만들기 ######\n",
    "                        spike = spike_for_fusion2_net\n",
    "                        ### 그냥 원래 스파이크로 ann loss 만들기 ######\n",
    "\n",
    "                        spike = spike.squeeze()\n",
    "                        spike_class = spike_class.squeeze()\n",
    "                        \n",
    "                        ### normal loss################\n",
    "                        # loss = criterion(spike_class, spike)\n",
    "                        ### normal loss################\n",
    "                        \n",
    "                        ### chan loss################\n",
    "                        loss1 = criterion(spike_class[..., 5:25], spike[..., 5:25])\n",
    "                        loss2 = criterion(spike_class[..., 0:5], spike[..., 0:5])\n",
    "                        loss3 = criterion(spike_class[..., 25:], spike[..., 25:])\n",
    "                        loss = loss1 * chan_loss_factor*2.125 + (loss2 + loss3) *(1/chan_loss_factor)/ 4 \n",
    "                        ### chan loss################\n",
    "\n",
    "\n",
    "                        # #########################################\n",
    "                        # # 손실 함수 정의 (예: MSELoss 사용)\n",
    "                        # criterion_joke = torch.nn.MSELoss(reduction='none')  # 개별 요소별 손실을 유지\n",
    "\n",
    "                        # # 손실 계산\n",
    "                        # loss1_joke = criterion_joke(spike_class[..., 5:25], spike[..., 5:25]).mean(dim=-1)  # (batch,)\n",
    "                        # loss2_joke = criterion_joke(spike_class[..., 0:5], spike[..., 0:5]).mean(dim=-1)    # (batch,)\n",
    "                        # loss3_joke = criterion_joke(spike_class[..., 25:], spike[..., 25:]).mean(dim=-1)    # (batch,)\n",
    "\n",
    "                        # # 주어진 가중치를 적용한 최종 손실\n",
    "                        # loss_joke = loss1_joke * chan_loss_factor*2.125 + (loss2_joke + loss3_joke) *(1/chan_loss_factor)/ 4 \n",
    "\n",
    "                        # # 가장 큰 손실을 갖는 샘플의 인덱스 찾기\n",
    "                        # max_loss_idx_joke = torch.argmax(loss_joke)\n",
    "\n",
    "                        # # 해당 샘플 선택\n",
    "                        # selected_sample_class = spike_class[max_loss_idx_joke]\n",
    "                        # selected_sample_spike = spike[max_loss_idx_joke]\n",
    "\n",
    "                        # # 선택한 샘플의 손실 값 출력\n",
    "                        # print(\"Index of max loss sample:\", max_loss_idx_joke.item())\n",
    "                        # print(\"Max loss value:\", loss_joke[max_loss_idx_joke].item())\n",
    "                        # mean_loss_joke = loss_joke.mean().item()\n",
    "                        # print(\"Mean loss across the batch:\", mean_loss_joke)\n",
    "\n",
    "                        # # 선택한 샘플을 시각화\n",
    "                        # plot_origin_spike(selected_sample_class.cpu().detach().numpy())\n",
    "                        # plot_origin_spike(selected_sample_spike.cpu().detach().numpy())\n",
    "                        # #########################################\n",
    "\n",
    "                        # coarse loss ######################################################\n",
    "                        loss_normal = criterion(spike_class, spike)\n",
    "                        level_num_in_loss = spike_length\n",
    "                        level_interval = (coarse_com_config[0] - coarse_com_config[1]) / (level_num_in_loss-1)  # max - min\n",
    "                        levels = [coarse_com_config[1] + level_interval * i for i in range(level_num_in_loss)]\n",
    "                        levels = torch.tensor(levels).to(torch.float).to(device)\n",
    "                        # print('coarse leves', levels)\n",
    "                        levels = levels.repeat(spike_length,1) \n",
    "\n",
    "                        spike = spike.squeeze()\n",
    "                        spike_class = spike_class.squeeze()\n",
    "                        # plot_origin_spike(spike_class[0].cpu().detach().numpy())\n",
    "                        spike = spike.unsqueeze(2).repeat(1, 1, level_num_in_loss) \n",
    "                        spike = (spike > levels).to(torch.float) \n",
    "                        spike_class = spike_class.unsqueeze(2).repeat(1, 1, level_num_in_loss) \n",
    "                        spike_class = (spike_class > levels).to(torch.float) \n",
    "                        # spike = spike[..., 0:-3, :]\n",
    "                        # spike_class = spike_class[..., 0:-3, :]\n",
    "                        loss_coarse = criterion(spike_class, spike)\n",
    "                        wrong_element_sum += torch.sum(torch.abs(spike - spike_class)).item() \n",
    "\n",
    "                        # plot_spike(spike_class[0].cpu().detach().numpy())\n",
    "                        # assert False\n",
    "                        # coarse loss ######################################################\n",
    "                    else:\n",
    "                        spike = spike.squeeze()\n",
    "                        spike_class = spike_class.squeeze()\n",
    "                        loss = criterion(spike_class, spike)\n",
    "\n",
    "                    for iii in range(spike.shape[0]):\n",
    "                        same_data_num = same_data_num + 1 if torch.eq(spike[iii], spike_class[iii]).all() else same_data_num\n",
    "                    wrong_element_sum += torch.sum(torch.abs(spike - spike_class)).item() \n",
    "\n",
    "                    # spike = spike.squeeze()\n",
    "                    # spike_class = spike_class.squeeze()\n",
    "                    # plot_spike(spike[0].cpu().detach().numpy())\n",
    "                    # plot_spike(spike_class[0].cpu().detach().numpy())\n",
    "                    # print('손실 절대값 합',np.sum(np.abs(spike[0].cpu().detach().numpy() - spike_class[0].cpu().detach().numpy())))\n",
    "                    # # assert False\n",
    "                elif 'SAE' in net.module.__class__.__name__:\n",
    "                    criterion = nn.MSELoss().to(device)\n",
    "                    loss1 = criterion(spike_class[..., 5:25], spike[..., 5:25])\n",
    "                    loss2 = criterion(spike_class[..., 0:5], spike[..., 0:5])\n",
    "                    loss3 = criterion(spike_class[..., 25:spike_length], spike[..., 25:spike_length])\n",
    "                    # loss = loss1 * 2.125 + (loss2 + loss3)/4 # chan_loss_factor = 1\n",
    "                    loss = loss1 * chan_loss_factor*2.125 + (loss2 + loss3) *(1/chan_loss_factor)/ 4 \n",
    "                    assert spike_length > 25, 'spike_length가 25보다 작음'\n",
    "                    # wrong_element_sum += torch.sum(torch.abs(spike - spike_class)).item() \n",
    "                else:\n",
    "                    criterion = nn.MSELoss().to(device)\n",
    "                    loss1 = criterion(spike_class[..., 5:25], spike[..., 5:25])\n",
    "                    loss2 = criterion(spike_class[..., 0:5], spike[..., 0:5])\n",
    "                    loss3 = criterion(spike_class[..., 25:spike_length], spike[..., 25:spike_length])\n",
    "                    loss = loss1 * chan_loss_factor*2.125 + (loss2 + loss3) *(1/chan_loss_factor)/ 4 \n",
    "                    assert spike_length > 25, 'spike_length가 25보다 작음'\n",
    "                    # wrong_element_sum += torch.sum(torch.abs(spike - spike_class)).item() \n",
    "\n",
    "\n",
    "                    if l2_norm_loss_weight > 0:\n",
    "                        assert len(encoded_spike.shape) == 2, 'time 성분 없는 걸로'\n",
    "                        l2_loss = l2_norm_loss(encoded_spike, target_norm=1.0)  # L2Norm Loss 계산, l2 1.0되게.\n",
    "                        loss = loss + l2_loss*l2_norm_loss_weight\n",
    "                        l2_loss_bin += l2_loss.item()\n",
    "\n",
    "                    # coarse loss ######################################################\n",
    "                    loss_normal = criterion(spike_class, spike)\n",
    "                    level_num_in_loss = quantize_level_num\n",
    "                    level_interval = (coarse_com_config[0] - coarse_com_config[1]) / (level_num_in_loss-1)  # max - min\n",
    "                    levels = [coarse_com_config[1] + level_interval * i for i in range(level_num_in_loss)]\n",
    "                    levels = torch.tensor(levels).to(torch.float).to(device)\n",
    "                    levels = levels.repeat(spike_length,1) \n",
    "\n",
    "                    spike = spike.squeeze()\n",
    "                    spike_class = spike_class.squeeze()\n",
    "                    spike = spike.squeeze()\n",
    "                    spike_class = spike_class.squeeze()\n",
    "\n",
    "                    # 차원이 1이면 0차원에 크기 1인 차원 추가\n",
    "                    if spike.ndimension() == 1:\n",
    "                        spike = spike.unsqueeze(0)\n",
    "\n",
    "                    if spike_class.ndimension() == 1:\n",
    "                        spike_class = spike_class.unsqueeze(0)\n",
    "                    # plot_origin_spike(spike_class[0].cpu().detach().numpy())\n",
    "                    spike = spike.unsqueeze(2).repeat(1, 1, level_num_in_loss) \n",
    "                    spike = (spike > levels).to(torch.float) \n",
    "                    spike_class = spike_class.unsqueeze(2).repeat(1, 1, level_num_in_loss) \n",
    "                    spike_class = (spike_class > levels).to(torch.float) \n",
    "                    # spike = spike[..., 0:-3, :]\n",
    "                    # spike_class = spike_class[..., 0:-3, :]\n",
    "                    loss_coarse = criterion(spike_class, spike)\n",
    "                    wrong_element_sum += torch.sum(torch.abs(spike - spike_class)).item() \n",
    "\n",
    "                    # plot_spike(spike_class[0].cpu().detach().numpy())\n",
    "                    # assert False\n",
    "                    # coarse loss ######################################################\n",
    "\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                running_loss += loss.item()\n",
    "                running_loss_normal += loss_normal.item()\n",
    "                running_loss_coarse += loss_coarse.item()\n",
    "                # print(f'\\nepoch-{epoch}, running_loss : {running_loss:.5f}, iter percent {iter/len(train_loader)*100:.2f}%')\n",
    "                iter += 1\n",
    "        else:\n",
    "            print('\\n\\n\\n max_epoch 1이면 Train 안함!!!!!!!!!!!!!!!!!!!!!')\n",
    "        if l2_norm_loss_weight > 0:\n",
    "            print('l2_loss_bin', l2_loss_bin/len(train_loader))\n",
    "        avg_loss = running_loss / len(train_loader)\n",
    "        assert not np.isnan(avg_loss), f\"Error: avg_loss is NaN! Running loss: {running_loss}, Length of train_loader: {len(train_loader)}\"\n",
    "        loss_history.append((epoch, avg_loss))\n",
    "        min_loss = min(min_loss, avg_loss)\n",
    "        min_loss_normal = min(min_loss_normal, running_loss_normal/len(train_loader))\n",
    "        min_loss_coarse = min(min_loss_coarse, running_loss_coarse/len(train_loader))\n",
    "        print(f'\\nepoch-{epoch} loss : {avg_loss:.8f}, loss_normal : {running_loss_normal/len(train_loader):.8f}, loss_coarse : {running_loss_coarse/len(train_loader):.8f}, min_loss : {min_loss:.8f}, min_loss_normal : {min_loss_normal:.8f}, min_loss_coarse : {min_loss_coarse:.8f}, wrong_element_sum : {wrong_element_sum:.8f}, same_data : {100*same_data_num/(total_data_num+1e-12):.2f}%')\n",
    "        print(f\"ae train 실행 시간: {time.time()-ae_train_start_time:.3f}초, 전체 시작 시간 {current_time}\")\n",
    "\n",
    "        # plot_activation_distribution(net)\n",
    "\n",
    "        if SAE_net == False and converted_net_forward == True:\n",
    "            source_encoder = net.module.encoder \n",
    "            target_encoder = converted_net.module.encoder  \n",
    "            copy_weights(source_encoder, target_encoder)\n",
    "\n",
    "        k_means_acc = 0\n",
    "        converted_k_means_acc = 0\n",
    "        if(epoch % accuracy_check_epoch_term == 0 or epoch == 1 or epoch == max_epoch-1): \n",
    "            accuracy_check_start_time = time.time()\n",
    "            print(f'\\nepoch-{epoch} accuracy check')\n",
    "            k_means_bin_origin_feature = []\n",
    "            k_means_bin = []\n",
    "            converted_k_means_bin = []\n",
    "            for ds in range(dataset_num):\n",
    "                # print('\\n', spike_tot[ds])\n",
    "\n",
    "                # spike = torch.tensor(torch.load(data_path[ds]))\n",
    "                spike = torch.load(data_path[ds])\n",
    "                label = torch.load(label_path[ds])\n",
    "                unit = label[:, 0].to(torch.int)\n",
    "                ch = label[:, 1].to(torch.int)\n",
    "                start = label[:, 2].to(torch.int)\n",
    "                end = label[:, 3].to(torch.int)\n",
    "                gt = label[:, 4].to(torch.int)\n",
    "                max_slope_index = label[:, 5].to(torch.int)\n",
    "                ch_winner_determinant = label[:, 6]\n",
    "                # unit, ch, start, end, gt, max_slope_index = map(int, label[i][:6])\n",
    "                # ch_winner_determinant = label[i][6]\n",
    "\n",
    "                label = unit\n",
    "\n",
    "                scaling = (level_num-3)/level_num if conv1d_scaling else 1.0\n",
    "                spike = zero_to_one_normalize_features(spike, level_num=quantize_level_num, coarse_com_config=coarse_com_config, scaling=scaling, norm01=norm01) if normalize_on else spike\n",
    "                \n",
    "                hidden_size = lateral_feature_num*TIME if 'SAE' in net.module.__class__.__name__ and SAE_hidden_nomean == True and fusion_net == False or 'SAE_FUSION5' in net.module.__class__.__name__ else lateral_feature_num\n",
    "                hidden_size = lateral_feature_num if '_DR' in net.module.__class__.__name__  else hidden_size\n",
    "\n",
    "                encoder_batch = 128\n",
    "                spike_hidden = np.zeros((len(spike), hidden_size))\n",
    "                converted_spike_hidden = np.zeros((len(spike), hidden_size))\n",
    "                net.eval()\n",
    "                with torch.no_grad():\n",
    "                    now_index = 0\n",
    "                    while (1):\n",
    "                        now_end_index = now_index+encoder_batch if now_index+encoder_batch < len(spike) else len(spike)\n",
    "                        spike_batch = spike[now_index:now_end_index] \n",
    "                        spike_torch = spike_batch\n",
    "                        spike_torch = spike_torch.float()\n",
    "                        spike_backup = spike_torch\n",
    "                        spike_torch = spike_torch.to(device)\n",
    "                        if coarse_com_mode == True and 'SAE' in net.module.__class__.__name__:\n",
    "                            spike_torch = spike_torch.unsqueeze(2).repeat(1, 1, level_num) # spike_length == level_num # (batch, time, feature)로 변환 \n",
    "                            spike_torch = (spike_torch > levels).to(torch.float) \n",
    "                            spike_torch = (spike_torch == 0).cumsum(dim=-1).eq(1).to(torch.float) if lc_adc_on == True else spike_torch\n",
    "                            if Conv_net == True:\n",
    "                                spike_torch = spike_torch.unsqueeze(-2) # batch, time, in_channel, feature or batch in_channel,feature\n",
    "                                if two_channel_input == True:\n",
    "                                    spike_backup = spike_backup.to(device)\n",
    "                                    spike_backup = spike_backup.unsqueeze(2).repeat(1, 1, level_num) # spike_length == level_num # (batch, time, feature)로 변환 \n",
    "                                    spike_backup = (spike_backup <= levels).to(torch.float) \n",
    "                                    spike_backup = (spike_backup == 1).cumsum(dim=-1).eq(1).to(torch.float) if lc_adc_on == True else spike_backup\n",
    "                                    spike_backup = spike_backup.unsqueeze(-2)\n",
    "                                    spike_torch = torch.cat((spike_torch, spike_backup), dim=-2)\n",
    "                        elif 'SAE' in net.module.__class__.__name__:\n",
    "                            spike_torch = spike_torch.unsqueeze(1).repeat(1, TIME, 1) # (batch, time, feature)로 변환\n",
    "                            if Conv_net == True:\n",
    "                                spike_torch = spike_torch.unsqueeze(-2) # batch, time, in_channel, feature or batch in_channel,feature\n",
    "                        else:\n",
    "                            # if Conv_net == True:\n",
    "                            #     spike_torch = spike_torch.unsqueeze(-2) #batch in_channel,feature\n",
    "                            if Conv_net == True:\n",
    "                                if coarse_com_mode == False:\n",
    "                                    spike_torch = spike_torch.unsqueeze(-2) #batch in_channel,feature\n",
    "                                else:\n",
    "                                    spike_torch = spike_torch.unsqueeze(2).repeat(1, 1, level_num) # spike_length == level_num # (batch, time, feature)로 변환 \n",
    "                                    spike_torch = (spike_torch > levels).to(torch.float) \n",
    "\n",
    "                                    spike_torch = (spike_torch == 0).cumsum(dim=-1).eq(1).to(torch.float) if lc_adc_on == True else spike_torch\n",
    "\n",
    "                            else:\n",
    "                                if coarse_com_mode == False:\n",
    "                                    pass\n",
    "                                else:\n",
    "                                    spike_torch = spike_torch.unsqueeze(2).repeat(1, 1, level_num) # spike_length == level_num # (batch, time, feature)로 변환 \n",
    "                                    spike_torch = (spike_torch > levels).to(torch.float) \n",
    "\n",
    "                                    spike_torch = (spike_torch == 0).cumsum(dim=-1).eq(1).to(torch.float) if lc_adc_on == True else spike_torch\n",
    "\n",
    "                                    # spike: batch, time, feature\n",
    "                                    spike_torch = spike_torch.reshape(spike_torch.shape[0], -1)\n",
    "                            if converted_net_forward == True:\n",
    "                                spike_torch_spikegen = spikegen.rate(spike_torch, num_steps=TIME).transpose(0, 1)\n",
    "                            # if fusion_net == True:\n",
    "                            #     spike_torch = spikegen.rate(spike_torch, num_steps=TIME).transpose(0, 1)\n",
    "                        ### forward #######################################################\n",
    "                        inner_inf = net.module.encoder(spike_torch)\n",
    "                        if SAE_net == False and converted_net_forward == True:\n",
    "                            converted_inner_inf = converted_net.module.encoder(spike_torch_spikegen)\n",
    "                        ### forward #######################################################\n",
    "                            \n",
    "                        if 'SAE' in net.module.__class__.__name__:\n",
    "                            if SAE_hidden_nomean == True:\n",
    "                                inner_inf = inner_inf.reshape(spike_batch.shape[0],-1)# 펼치기\n",
    "                            else:\n",
    "                                inner_inf = inner_inf.mean(dim=1)# Time 방향으로 평균\n",
    "                            # inner_inf = F.normalize(inner_inf, p=2, dim=1)\n",
    "                        spike_hidden[now_index:now_end_index] = inner_inf.cpu().detach().numpy()\n",
    "                        if SAE_net == False and converted_net_forward == True:\n",
    "                            converted_spike_hidden[now_index:now_end_index] = converted_inner_inf.cpu().detach().numpy()\n",
    "                        now_index += encoder_batch\n",
    "                        if (now_index >= len(spike)):\n",
    "                            break\n",
    "\n",
    "                origin_kmeans_accuracy = cluster_spikes_with_accuracy_torch(features= spike, true_labels=label, n_clusters=num_cluster, init_point=None)\n",
    "                kmeans_accuracy = cluster_spikes_with_accuracy_torch(features= torch.tensor(spike_hidden).to(device), true_labels=label, n_clusters=num_cluster, init_point=None)\n",
    "                \n",
    "                \n",
    "                # plot_tsne(spike_tot[ds], kmeans_accuracy, spike_hidden, label-1, n_components=2, perplexity=30, random_state=42)\n",
    "                \n",
    "                k_means_bin_origin_feature.append(origin_kmeans_accuracy)\n",
    "                k_means_bin.append(kmeans_accuracy)\n",
    "                if SAE_net == False and converted_net_forward == True:\n",
    "                    converted_kmeans_accuracy = cluster_spikes_with_accuracy_torch(features= torch.tensor(converted_spike_hidden).to(device), true_labels=label-1, n_clusters=num_cluster, init_point=None)\n",
    "                    converted_k_means_bin.append(converted_kmeans_accuracy)\n",
    "\n",
    "            print(f'k_means origin feature average accuracy : {100*sum(k_means_bin_origin_feature)/(len(k_means_bin_origin_feature)+1e-12):.8f}%, total {k_means_bin_origin_feature}')\n",
    "\n",
    "            if SAE_net == False and converted_net_forward == True:\n",
    "                converted_k_means_acc = 100*sum(converted_k_means_bin)/len(converted_k_means_bin)\n",
    "                print(f'converted_kmeans average accuracy : {converted_k_means_acc:.8f}%, total {converted_k_means_bin}')\n",
    "            k_means_acc = 100*sum(k_means_bin)/len(k_means_bin)\n",
    "            if k_means_acc > k_means_acc_best:\n",
    "                # torch.save(net, f\"net_save/save_now_net_{current_time}.pth\")\n",
    "                torch.save(net.module.state_dict(), f\"net_save/save_now_net_{current_time}.pth\")\n",
    "                print('save model')\n",
    "            \n",
    "            k_means_acc_best = max(k_means_acc_best, k_means_acc)\n",
    "            print(f'kmeans average accuracy best : {k_means_acc_best:.2f}%, kmeans average accuracy : {k_means_acc:.8f}%, total {k_means_bin}')\n",
    "            print(f\"accuracy_check 실행 시간: {time.time()-accuracy_check_start_time:.3f}초\")\n",
    "\n",
    "        wandb.log({\"avg_loss\": avg_loss})\n",
    "        wandb.log({\"k_means_acc\": k_means_acc})\n",
    "        wandb.log({\"k_means_acc_best\": k_means_acc_best})\n",
    "        wandb.log({\"converted_k_means_acc\": converted_k_means_acc})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Finishing last run (ID:8pzhlzkt) before initializing another..."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bff29212a17e4af18d7f5fb059ba1dcb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.006 MB of 0.006 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">vital-snowball-22</strong> at: <a href='https://wandb.ai/bhkim003-seoul-national-university/spike_sorting%20just%20run%20np/runs/8pzhlzkt' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/spike_sorting%20just%20run%20np/runs/8pzhlzkt</a><br/> View project at: <a href='https://wandb.ai/bhkim003-seoul-national-university/spike_sorting%20just%20run%20np' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/spike_sorting%20just%20run%20np</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20250320_221514-8pzhlzkt/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require(\"core\")`! See https://wandb.me/wandb-core for more information."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Successfully finished last run (ID:8pzhlzkt). Initializing new run:<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e8300362a7a24d00947c6479e70fefb4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.011113647702667448, max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.19.8 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.17.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/nfs/home/bhkim003/github_folder/ByeonghyeonKim/my_snn/wandb/run-20250320_221542-57w3b4tw</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/bhkim003-seoul-national-university/spike_sorting%20just%20run%20np/runs/57w3b4tw' target=\"_blank\">likely-sky-23</a></strong> to <a href='https://wandb.ai/bhkim003-seoul-national-university/spike_sorting%20just%20run%20np' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/bhkim003-seoul-national-university/spike_sorting%20just%20run%20np' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/spike_sorting%20just%20run%20np</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/bhkim003-seoul-national-university/spike_sorting%20just%20run%20np/runs/57w3b4tw' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/spike_sorting%20just%20run%20np/runs/57w3b4tw</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'gpu': '4', 'Conv_net': True, 'SAE_net': False, 'dataset_num': 1, 'spike_length': 50, 'num_cluster': 7, 'training_cycle': 1400, 'batch_size': 32, 'max_epoch': 10000, 'learning_rate': 0.001, 'normalize_on': True, 'need_bias': False, 'lif_add_at_first': False, 'my_seed': 42, 'TIME': 50, 'v_decay': 0.5, 'v_threshold': 0.25, 'v_reset': 0.0, 'BPTT_on': True, 'SAE_hidden_nomean': True, 'current_time': '20250320_221542_161', 'optimizer': 'Adam', 'coarse_com_mode': False, 'sae_l2_norm_bridge': True, 'sae_lif_bridge': False, 'accuracy_check_epoch_term': 1, 'lif_add_at_last': False, 'two_channel_input': False, 'lateral_feature_num': 4, 'lc_adc_on': False, 'converted_net_forward': False, 'pretrained_net': None, 'vth_mul_on': False, 'batch_norm_on': False, 'l2_norm_loss_weight': 0, 'QCFS_neuron_on': False, 'quantize_level_num': 50, 'fusion_net': False, 'repeat_coding': False, 'sae_relu_on': False, 'conv1d_scaling': False, 'norm01': True, 'chan_loss_factor': 1, 'coarse_com_config': (0.999, -0.0)}\n",
      "ae conv lenght [50, 24, 11, 5]\n",
      "Total number of encoder parameters: 26592\n",
      "DataParallel(\n",
      "  (module): Autoencoder_conv1(\n",
      "    (activation_function): ReLU()\n",
      "    (encoder): Sequential(\n",
      "      (0): Conv1d(1, 32, kernel_size=(3,), stride=(2,), bias=False)\n",
      "      (1): ReLU()\n",
      "      (2): Conv1d(32, 64, kernel_size=(3,), stride=(2,), bias=False)\n",
      "      (3): ReLU()\n",
      "      (4): Conv1d(64, 96, kernel_size=(3,), stride=(2,), bias=False)\n",
      "      (5): ReLU()\n",
      "      (6): SSBH_DimChanger_for_fc()\n",
      "      (7): Linear(in_features=480, out_features=4, bias=False)\n",
      "      (8): SSBH_L2NormLayer()\n",
      "    )\n",
      "    (decoder): Sequential(\n",
      "      (0): Linear(in_features=4, out_features=480, bias=False)\n",
      "      (1): ReLU()\n",
      "      (2): SSBH_DimChanger_for_conv1()\n",
      "      (3): ConvTranspose1d(96, 64, kernel_size=(3,), stride=(2,), bias=False)\n",
      "      (4): ReLU()\n",
      "      (5): ConvTranspose1d(64, 32, kernel_size=(3,), stride=(2,), output_padding=(1,), bias=False)\n",
      "      (6): ReLU()\n",
      "      (7): ConvTranspose1d(32, 1, kernel_size=(3,), stride=(2,), output_padding=(1,), bias=False)\n",
      "    )\n",
      "  )\n",
      ")\n",
      "Device: cuda\n",
      "\n",
      "Start Training, current_time = 20250320_221542_161\n",
      "\n",
      "\n",
      "epoch-0 loss : 0.20596857, loss_normal : 0.11436883, loss_coarse : 0.23082303, min_loss : 0.20596857, min_loss_normal : 0.11436883, min_loss_coarse : 0.23082303, wrong_element_sum : 1269152.00000000, same_data : 0.00%\n",
      "ae train 실행 시간: 0.494초, 전체 시작 시간 20250320_221542_161\n",
      "\n",
      "epoch-0 accuracy check\n",
      "k_means origin feature average accuracy : 73.73229785%, total [0.7373229785290086]\n",
      "save model\n",
      "kmeans average accuracy best : 54.91%, kmeans average accuracy : 54.91091823%, total [0.5491091822750114]\n",
      "accuracy_check 실행 시간: 7.745초\n",
      "\n",
      "\n",
      "epoch-1 loss : 0.03799739, loss_normal : 0.03961966, loss_coarse : 0.10406938, min_loss : 0.03799739, min_loss_normal : 0.03961966, min_loss_coarse : 0.10406938, wrong_element_sum : 570036.00000000, same_data : 0.00%\n",
      "ae train 실행 시간: 0.536초, 전체 시작 시간 20250320_221542_161\n",
      "\n",
      "epoch-1 accuracy check\n",
      "k_means origin feature average accuracy : 74.32617634%, total [0.7432617633622659]\n",
      "kmeans average accuracy best : 54.91%, kmeans average accuracy : 53.90589310%, total [0.53905893101873]\n",
      "accuracy_check 실행 시간: 7.715초\n",
      "\n",
      "\n",
      "epoch-2 loss : 0.03185992, loss_normal : 0.03793585, loss_coarse : 0.09794300, min_loss : 0.03185992, min_loss_normal : 0.03793585, min_loss_coarse : 0.09794300, wrong_element_sum : 536290.00000000, same_data : 0.00%\n",
      "ae train 실행 시간: 0.519초, 전체 시작 시간 20250320_221542_161\n",
      "\n",
      "epoch-2 accuracy check\n",
      "k_means origin feature average accuracy : 74.14344450%, total [0.7414344449520329]\n",
      "save model\n",
      "kmeans average accuracy best : 65.28%, kmeans average accuracy : 65.28095021%, total [0.6528095020557332]\n",
      "accuracy_check 실행 시간: 7.530초\n",
      "\n",
      "\n",
      "epoch-3 loss : 0.02706111, loss_normal : 0.03703252, loss_coarse : 0.09252296, min_loss : 0.02706111, min_loss_normal : 0.03703252, min_loss_coarse : 0.09252296, wrong_element_sum : 506842.00000000, same_data : 0.00%\n",
      "ae train 실행 시간: 0.503초, 전체 시작 시간 20250320_221542_161\n",
      "\n",
      "epoch-3 accuracy check\n",
      "k_means origin feature average accuracy : 73.82366377%, total [0.7382366377341252]\n",
      "kmeans average accuracy best : 65.28%, kmeans average accuracy : 63.13385107%, total [0.6313385107354956]\n",
      "accuracy_check 실행 시간: 7.460초\n",
      "\n",
      "\n",
      "epoch-4 loss : 0.02577201, loss_normal : 0.03662035, loss_coarse : 0.09036342, min_loss : 0.02577201, min_loss_normal : 0.03662035, min_loss_coarse : 0.09036342, wrong_element_sum : 494553.00000000, same_data : 0.00%\n",
      "ae train 실행 시간: 0.513초, 전체 시작 시간 20250320_221542_161\n",
      "\n",
      "epoch-4 accuracy check\n",
      "k_means origin feature average accuracy : 73.59524897%, total [0.735952489721334]\n",
      "save model\n",
      "kmeans average accuracy best : 65.42%, kmeans average accuracy : 65.41799909%, total [0.654179990863408]\n",
      "accuracy_check 실행 시간: 7.416초\n",
      "\n",
      "\n",
      "epoch-5 loss : 0.02518028, loss_normal : 0.03639660, loss_coarse : 0.08907228, min_loss : 0.02518028, min_loss_normal : 0.03639660, min_loss_coarse : 0.08907228, wrong_element_sum : 487632.00000000, same_data : 0.00%\n",
      "ae train 실행 시간: 0.505초, 전체 시작 시간 20250320_221542_161\n",
      "\n",
      "epoch-5 accuracy check\n",
      "k_means origin feature average accuracy : 74.73732298%, total [0.7473732297852901]\n",
      "kmeans average accuracy best : 65.42%, kmeans average accuracy : 60.71265418%, total [0.6071265417999087]\n",
      "accuracy_check 실행 시간: 8.121초\n",
      "\n",
      "\n",
      "epoch-6 loss : 0.02490156, loss_normal : 0.03628963, loss_coarse : 0.08841898, min_loss : 0.02490156, min_loss_normal : 0.03628963, min_loss_coarse : 0.08841898, wrong_element_sum : 483941.00000000, same_data : 0.00%\n",
      "ae train 실행 시간: 0.494초, 전체 시작 시간 20250320_221542_161\n",
      "\n",
      "epoch-6 accuracy check\n",
      "k_means origin feature average accuracy : 73.77798081%, total [0.737779808131567]\n",
      "kmeans average accuracy best : 65.42%, kmeans average accuracy : 61.39789858%, total [0.6139789858382824]\n",
      "accuracy_check 실행 시간: 7.623초\n",
      "\n",
      "\n",
      "epoch-7 loss : 0.02469568, loss_normal : 0.03616160, loss_coarse : 0.08795404, min_loss : 0.02469568, min_loss_normal : 0.03616160, min_loss_coarse : 0.08795404, wrong_element_sum : 481642.00000000, same_data : 0.00%\n",
      "ae train 실행 시간: 0.497초, 전체 시작 시간 20250320_221542_161\n",
      "\n",
      "epoch-7 accuracy check\n",
      "k_means origin feature average accuracy : 74.73732298%, total [0.7473732297852901]\n",
      "save model\n",
      "kmeans average accuracy best : 74.28%, kmeans average accuracy : 74.28049338%, total [0.7428049337597076]\n",
      "accuracy_check 실행 시간: 7.502초\n",
      "\n",
      "\n",
      "epoch-8 loss : 0.02439885, loss_normal : 0.03602510, loss_coarse : 0.08734580, min_loss : 0.02439885, min_loss_normal : 0.03602510, min_loss_coarse : 0.08734580, wrong_element_sum : 478039.00000000, same_data : 0.00%\n",
      "ae train 실행 시간: 0.501초, 전체 시작 시간 20250320_221542_161\n",
      "\n",
      "epoch-8 accuracy check\n",
      "k_means origin feature average accuracy : 73.54956601%, total [0.7354956601187757]\n",
      "kmeans average accuracy best : 74.28%, kmeans average accuracy : 61.80904523%, total [0.6180904522613065]\n",
      "accuracy_check 실행 시간: 7.927초\n",
      "\n",
      "\n",
      "epoch-9 loss : 0.02415380, loss_normal : 0.03588734, loss_coarse : 0.08677597, min_loss : 0.02415380, min_loss_normal : 0.03588734, min_loss_coarse : 0.08677597, wrong_element_sum : 474534.00000000, same_data : 0.00%\n",
      "ae train 실행 시간: 0.508초, 전체 시작 시간 20250320_221542_161\n",
      "\n",
      "epoch-9 accuracy check\n",
      "k_means origin feature average accuracy : 74.55459114%, total [0.7455459113750571]\n",
      "kmeans average accuracy best : 74.28%, kmeans average accuracy : 62.85975331%, total [0.6285975331201462]\n",
      "accuracy_check 실행 시간: 7.554초\n",
      "\n",
      "\n",
      "epoch-10 loss : 0.02421864, loss_normal : 0.03590996, loss_coarse : 0.08692735, min_loss : 0.02415380, min_loss_normal : 0.03588734, min_loss_coarse : 0.08677597, wrong_element_sum : 475431.00000000, same_data : 0.00%\n",
      "ae train 실행 시간: 0.506초, 전체 시작 시간 20250320_221542_161\n",
      "\n",
      "epoch-10 accuracy check\n",
      "k_means origin feature average accuracy : 74.23481042%, total [0.7423481041571494]\n",
      "kmeans average accuracy best : 74.28%, kmeans average accuracy : 69.52946551%, total [0.6952946550936501]\n",
      "accuracy_check 실행 시간: 7.564초\n",
      "\n",
      "\n",
      "epoch-11 loss : 0.02410056, loss_normal : 0.03585359, loss_coarse : 0.08656020, min_loss : 0.02410056, min_loss_normal : 0.03585359, min_loss_coarse : 0.08656020, wrong_element_sum : 473967.00000000, same_data : 0.00%\n",
      "ae train 실행 시간: 0.515초, 전체 시작 시간 20250320_221542_161\n",
      "\n",
      "epoch-11 accuracy check\n",
      "k_means origin feature average accuracy : 73.96071265%, total [0.7396071265417999]\n",
      "kmeans average accuracy best : 74.28%, kmeans average accuracy : 64.13887620%, total [0.6413887619917771]\n",
      "accuracy_check 실행 시간: 7.462초\n",
      "\n",
      "\n",
      "epoch-12 loss : 0.02379419, loss_normal : 0.03574368, loss_coarse : 0.08622659, min_loss : 0.02379419, min_loss_normal : 0.03574368, min_loss_coarse : 0.08622659, wrong_element_sum : 471858.00000000, same_data : 0.00%\n",
      "ae train 실행 시간: 0.509초, 전체 시작 시간 20250320_221542_161\n",
      "\n",
      "epoch-12 accuracy check\n",
      "k_means origin feature average accuracy : 74.18912746%, total [0.7418912745545911]\n",
      "kmeans average accuracy best : 74.28%, kmeans average accuracy : 72.31612608%, total [0.7231612608497031]\n",
      "accuracy_check 실행 시간: 7.506초\n",
      "\n",
      "\n",
      "epoch-13 loss : 0.02354149, loss_normal : 0.03561562, loss_coarse : 0.08550297, min_loss : 0.02354149, min_loss_normal : 0.03561562, min_loss_coarse : 0.08550297, wrong_element_sum : 468134.00000000, same_data : 0.00%\n",
      "ae train 실행 시간: 0.500초, 전체 시작 시간 20250320_221542_161\n",
      "\n",
      "epoch-13 accuracy check\n",
      "k_means origin feature average accuracy : 73.59524897%, total [0.735952489721334]\n",
      "kmeans average accuracy best : 74.28%, kmeans average accuracy : 73.82366377%, total [0.7382366377341252]\n",
      "accuracy_check 실행 시간: 7.527초\n",
      "\n",
      "\n",
      "epoch-14 loss : 0.02330146, loss_normal : 0.03554014, loss_coarse : 0.08509678, min_loss : 0.02330146, min_loss_normal : 0.03554014, min_loss_coarse : 0.08509678, wrong_element_sum : 465677.00000000, same_data : 0.00%\n",
      "ae train 실행 시간: 0.512초, 전체 시작 시간 20250320_221542_161\n",
      "\n",
      "epoch-14 accuracy check\n",
      "k_means origin feature average accuracy : 74.18912746%, total [0.7418912745545911]\n",
      "kmeans average accuracy best : 74.28%, kmeans average accuracy : 69.43809959%, total [0.6943809958885335]\n",
      "accuracy_check 실행 시간: 7.589초\n",
      "\n",
      "\n",
      "epoch-15 loss : 0.02332598, loss_normal : 0.03553620, loss_coarse : 0.08513559, min_loss : 0.02330146, min_loss_normal : 0.03553620, min_loss_coarse : 0.08509678, wrong_element_sum : 465881.00000000, same_data : 0.00%\n",
      "ae train 실행 시간: 0.509초, 전체 시작 시간 20250320_221542_161\n",
      "\n",
      "epoch-15 accuracy check\n",
      "k_means origin feature average accuracy : 73.73229785%, total [0.7373229785290086]\n",
      "kmeans average accuracy best : 74.28%, kmeans average accuracy : 68.02192782%, total [0.680219278209228]\n",
      "accuracy_check 실행 시간: 7.449초\n",
      "\n",
      "\n",
      "epoch-16 loss : 0.02332145, loss_normal : 0.03557305, loss_coarse : 0.08517073, min_loss : 0.02330146, min_loss_normal : 0.03553620, min_loss_coarse : 0.08509678, wrong_element_sum : 465752.00000000, same_data : 0.00%\n",
      "ae train 실행 시간: 0.514초, 전체 시작 시간 20250320_221542_161\n",
      "\n",
      "epoch-16 accuracy check\n",
      "k_means origin feature average accuracy : 73.91502969%, total [0.7391502969392416]\n",
      "kmeans average accuracy best : 74.28%, kmeans average accuracy : 66.83417085%, total [0.6683417085427136]\n",
      "accuracy_check 실행 시간: 7.613초\n",
      "\n",
      "\n",
      "epoch-17 loss : 0.02325372, loss_normal : 0.03554154, loss_coarse : 0.08501188, min_loss : 0.02325372, min_loss_normal : 0.03553620, min_loss_coarse : 0.08501188, wrong_element_sum : 465337.00000000, same_data : 0.00%\n",
      "ae train 실행 시간: 0.515초, 전체 시작 시간 20250320_221542_161\n",
      "\n",
      "epoch-17 accuracy check\n",
      "k_means origin feature average accuracy : 72.63590681%, total [0.7263590680676107]\n",
      "kmeans average accuracy best : 74.28%, kmeans average accuracy : 68.93558703%, total [0.6893558702603929]\n",
      "accuracy_check 실행 시간: 7.288초\n",
      "\n",
      "\n",
      "epoch-18 loss : 0.02330103, loss_normal : 0.03556607, loss_coarse : 0.08531404, min_loss : 0.02325372, min_loss_normal : 0.03553620, min_loss_coarse : 0.08501188, wrong_element_sum : 466926.00000000, same_data : 0.00%\n",
      "ae train 실행 시간: 0.505초, 전체 시작 시간 20250320_221542_161\n",
      "\n",
      "epoch-18 accuracy check\n",
      "k_means origin feature average accuracy : 74.23481042%, total [0.7423481041571494]\n",
      "kmeans average accuracy best : 74.28%, kmeans average accuracy : 64.36729100%, total [0.6436729100045683]\n",
      "accuracy_check 실행 시간: 7.324초\n",
      "\n",
      "\n",
      "epoch-19 loss : 0.02315014, loss_normal : 0.03549470, loss_coarse : 0.08522716, min_loss : 0.02315014, min_loss_normal : 0.03549470, min_loss_coarse : 0.08501188, wrong_element_sum : 467050.00000000, same_data : 0.00%\n",
      "ae train 실행 시간: 0.533초, 전체 시작 시간 20250320_221542_161\n",
      "\n",
      "epoch-19 accuracy check\n",
      "k_means origin feature average accuracy : 74.69164002%, total [0.7469164001827319]\n",
      "kmeans average accuracy best : 74.28%, kmeans average accuracy : 69.11831887%, total [0.6911831886706259]\n",
      "accuracy_check 실행 시간: 7.372초\n",
      "\n",
      "\n",
      "epoch-20 loss : 0.02275876, loss_normal : 0.03539378, loss_coarse : 0.08410205, min_loss : 0.02275876, min_loss_normal : 0.03539378, min_loss_coarse : 0.08410205, wrong_element_sum : 460265.00000000, same_data : 0.00%\n",
      "ae train 실행 시간: 0.510초, 전체 시작 시간 20250320_221542_161\n",
      "\n",
      "epoch-20 accuracy check\n",
      "k_means origin feature average accuracy : 74.18912746%, total [0.7418912745545911]\n",
      "kmeans average accuracy best : 74.28%, kmeans average accuracy : 70.80858840%, total [0.7080858839652809]\n",
      "accuracy_check 실행 시간: 7.444초\n",
      "\n",
      "\n",
      "epoch-21 loss : 0.02296274, loss_normal : 0.03542046, loss_coarse : 0.08464671, min_loss : 0.02275876, min_loss_normal : 0.03539378, min_loss_coarse : 0.08410205, wrong_element_sum : 463368.00000000, same_data : 0.00%\n",
      "ae train 실행 시간: 0.506초, 전체 시작 시간 20250320_221542_161\n",
      "\n",
      "epoch-21 accuracy check\n",
      "k_means origin feature average accuracy : 74.50890818%, total [0.7450890817724989]\n",
      "kmeans average accuracy best : 74.28%, kmeans average accuracy : 69.94061215%, total [0.6994061215166743]\n",
      "accuracy_check 실행 시간: 7.445초\n",
      "\n",
      "\n",
      "epoch-22 loss : 0.02281891, loss_normal : 0.03542873, loss_coarse : 0.08427978, min_loss : 0.02275876, min_loss_normal : 0.03539378, min_loss_coarse : 0.08410205, wrong_element_sum : 460052.00000000, same_data : 0.00%\n",
      "ae train 실행 시간: 0.496초, 전체 시작 시간 20250320_221542_161\n",
      "\n",
      "epoch-22 accuracy check\n",
      "k_means origin feature average accuracy : 74.18912746%, total [0.7418912745545911]\n",
      "kmeans average accuracy best : 74.28%, kmeans average accuracy : 72.68158977%, total [0.7268158976701691]\n",
      "accuracy_check 실행 시간: 7.445초\n",
      "\n",
      "\n",
      "epoch-23 loss : 0.02274850, loss_normal : 0.03538785, loss_coarse : 0.08422231, min_loss : 0.02274850, min_loss_normal : 0.03538785, min_loss_coarse : 0.08410205, wrong_element_sum : 460714.00000000, same_data : 0.00%\n",
      "ae train 실행 시간: 0.502초, 전체 시작 시간 20250320_221542_161\n",
      "\n",
      "epoch-23 accuracy check\n",
      "k_means origin feature average accuracy : 74.41754226%, total [0.7441754225673823]\n",
      "kmeans average accuracy best : 74.28%, kmeans average accuracy : 70.71722248%, total [0.7071722247601645]\n",
      "accuracy_check 실행 시간: 7.597초\n",
      "\n",
      "\n",
      "epoch-24 loss : 0.02283488, loss_normal : 0.03538087, loss_coarse : 0.08445780, min_loss : 0.02274850, min_loss_normal : 0.03538087, min_loss_coarse : 0.08410205, wrong_element_sum : 461840.00000000, same_data : 0.00%\n",
      "ae train 실행 시간: 0.504초, 전체 시작 시간 20250320_221542_161\n",
      "\n",
      "epoch-24 accuracy check\n",
      "k_means origin feature average accuracy : 74.28049338%, total [0.7428049337597076]\n",
      "kmeans average accuracy best : 74.28%, kmeans average accuracy : 70.35175879%, total [0.7035175879396985]\n",
      "accuracy_check 실행 시간: 7.563초\n",
      "\n",
      "\n",
      "epoch-25 loss : 0.02272985, loss_normal : 0.03538387, loss_coarse : 0.08415772, min_loss : 0.02272985, min_loss_normal : 0.03538087, min_loss_coarse : 0.08410205, wrong_element_sum : 460261.00000000, same_data : 0.00%\n",
      "ae train 실행 시간: 0.500초, 전체 시작 시간 20250320_221542_161\n",
      "\n",
      "epoch-25 accuracy check\n",
      "k_means origin feature average accuracy : 73.77798081%, total [0.737779808131567]\n",
      "kmeans average accuracy best : 74.28%, kmeans average accuracy : 69.62083143%, total [0.6962083142987665]\n",
      "accuracy_check 실행 시간: 7.641초\n",
      "\n",
      "\n",
      "epoch-26 loss : 0.02260962, loss_normal : 0.03526795, loss_coarse : 0.08382550, min_loss : 0.02260962, min_loss_normal : 0.03526795, min_loss_coarse : 0.08382550, wrong_element_sum : 458965.00000000, same_data : 0.00%\n",
      "ae train 실행 시간: 0.510초, 전체 시작 시간 20250320_221542_161\n",
      "\n",
      "epoch-26 accuracy check\n",
      "k_means origin feature average accuracy : 74.14344450%, total [0.7414344449520329]\n",
      "kmeans average accuracy best : 74.28%, kmeans average accuracy : 67.29100046%, total [0.672910004568296]\n",
      "accuracy_check 실행 시간: 7.545초\n",
      "\n",
      "\n",
      "epoch-27 loss : 0.02278700, loss_normal : 0.03532723, loss_coarse : 0.08442834, min_loss : 0.02260962, min_loss_normal : 0.03526795, min_loss_coarse : 0.08382550, wrong_element_sum : 461901.00000000, same_data : 0.00%\n",
      "ae train 실행 시간: 0.514초, 전체 시작 시간 20250320_221542_161\n",
      "\n",
      "epoch-27 accuracy check\n",
      "k_means origin feature average accuracy : 74.87437186%, total [0.7487437185929648]\n",
      "kmeans average accuracy best : 74.28%, kmeans average accuracy : 66.83417085%, total [0.6683417085427136]\n",
      "accuracy_check 실행 시간: 7.503초\n",
      "\n",
      "\n",
      "epoch-28 loss : 0.02271047, loss_normal : 0.03536336, loss_coarse : 0.08415456, min_loss : 0.02260962, min_loss_normal : 0.03526795, min_loss_coarse : 0.08382550, wrong_element_sum : 459466.00000000, same_data : 0.00%\n",
      "ae train 실행 시간: 0.505초, 전체 시작 시간 20250320_221542_161\n",
      "\n",
      "epoch-28 accuracy check\n",
      "k_means origin feature average accuracy : 72.17907720%, total [0.7217907720420284]\n",
      "kmeans average accuracy best : 74.28%, kmeans average accuracy : 69.57514847%, total [0.6957514846962083]\n",
      "accuracy_check 실행 시간: 7.382초\n",
      "\n",
      "\n",
      "epoch-29 loss : 0.02241691, loss_normal : 0.03521391, loss_coarse : 0.08365341, min_loss : 0.02241691, min_loss_normal : 0.03521391, min_loss_coarse : 0.08365341, wrong_element_sum : 458056.00000000, same_data : 0.00%\n",
      "ae train 실행 시간: 0.514초, 전체 시작 시간 20250320_221542_161\n",
      "\n",
      "epoch-29 accuracy check\n",
      "k_means origin feature average accuracy : 74.05207857%, total [0.7405207857469164]\n",
      "kmeans average accuracy best : 74.28%, kmeans average accuracy : 68.47875742%, total [0.6847875742348104]\n",
      "accuracy_check 실행 시간: 7.377초\n",
      "\n",
      "\n",
      "epoch-30 loss : 0.02234089, loss_normal : 0.03521367, loss_coarse : 0.08332025, min_loss : 0.02234089, min_loss_normal : 0.03521367, min_loss_coarse : 0.08332025, wrong_element_sum : 455834.00000000, same_data : 0.00%\n",
      "ae train 실행 시간: 0.386초, 전체 시작 시간 20250320_221542_161\n",
      "\n",
      "epoch-30 accuracy check\n",
      "k_means origin feature average accuracy : 74.23481042%, total [0.7423481041571494]\n",
      "kmeans average accuracy best : 74.28%, kmeans average accuracy : 67.61078118%, total [0.6761078117862037]\n",
      "accuracy_check 실행 시간: 7.523초\n",
      "\n",
      "\n",
      "epoch-31 loss : 0.02229583, loss_normal : 0.03517529, loss_coarse : 0.08318963, min_loss : 0.02229583, min_loss_normal : 0.03517529, min_loss_coarse : 0.08318963, wrong_element_sum : 455531.00000000, same_data : 0.00%\n",
      "ae train 실행 시간: 0.508초, 전체 시작 시간 20250320_221542_161\n",
      "\n",
      "epoch-31 accuracy check\n",
      "k_means origin feature average accuracy : 74.23481042%, total [0.7423481041571494]\n",
      "kmeans average accuracy best : 74.28%, kmeans average accuracy : 63.45363180%, total [0.6345363179534034]\n",
      "accuracy_check 실행 시간: 7.555초\n",
      "\n",
      "\n",
      "epoch-32 loss : 0.02222615, loss_normal : 0.03516483, loss_coarse : 0.08311091, min_loss : 0.02222615, min_loss_normal : 0.03516483, min_loss_coarse : 0.08311091, wrong_element_sum : 455133.00000000, same_data : 0.00%\n",
      "ae train 실행 시간: 0.496초, 전체 시작 시간 20250320_221542_161\n",
      "\n",
      "epoch-32 accuracy check\n",
      "k_means origin feature average accuracy : 74.37185930%, total [0.7437185929648241]\n",
      "kmeans average accuracy best : 74.28%, kmeans average accuracy : 63.04248515%, total [0.6304248515303792]\n",
      "accuracy_check 실행 시간: 7.645초\n",
      "\n",
      "\n",
      "epoch-33 loss : 0.02254810, loss_normal : 0.03525097, loss_coarse : 0.08393765, min_loss : 0.02222615, min_loss_normal : 0.03516483, min_loss_coarse : 0.08311091, wrong_element_sum : 459207.00000000, same_data : 0.00%\n",
      "ae train 실행 시간: 0.512초, 전체 시작 시간 20250320_221542_161\n",
      "\n",
      "epoch-33 accuracy check\n",
      "k_means origin feature average accuracy : 74.23481042%, total [0.7423481041571494]\n",
      "kmeans average accuracy best : 74.28%, kmeans average accuracy : 66.78848789%, total [0.6678848789401554]\n",
      "accuracy_check 실행 시간: 7.610초\n",
      "\n",
      "\n",
      "epoch-34 loss : 0.02232468, loss_normal : 0.03520425, loss_coarse : 0.08348279, min_loss : 0.02222615, min_loss_normal : 0.03516483, min_loss_coarse : 0.08311091, wrong_element_sum : 457006.00000000, same_data : 0.00%\n",
      "ae train 실행 시간: 0.499초, 전체 시작 시간 20250320_221542_161\n",
      "\n",
      "epoch-34 accuracy check\n",
      "k_means origin feature average accuracy : 70.99132024%, total [0.7099132023755139]\n",
      "kmeans average accuracy best : 74.28%, kmeans average accuracy : 73.96071265%, total [0.7396071265417999]\n",
      "accuracy_check 실행 시간: 7.748초\n",
      "\n",
      "\n",
      "epoch-35 loss : 0.02225112, loss_normal : 0.03517100, loss_coarse : 0.08333610, min_loss : 0.02222615, min_loss_normal : 0.03516483, min_loss_coarse : 0.08311091, wrong_element_sum : 455885.00000000, same_data : 0.00%\n",
      "ae train 실행 시간: 0.512초, 전체 시작 시간 20250320_221542_161\n",
      "\n",
      "epoch-35 accuracy check\n",
      "k_means origin feature average accuracy : 74.00639561%, total [0.7400639561443582]\n",
      "kmeans average accuracy best : 74.28%, kmeans average accuracy : 66.10324349%, total [0.6610324349017817]\n",
      "accuracy_check 실행 시간: 7.618초\n",
      "\n",
      "\n",
      "epoch-36 loss : 0.02212197, loss_normal : 0.03508853, loss_coarse : 0.08293113, min_loss : 0.02212197, min_loss_normal : 0.03508853, min_loss_coarse : 0.08293113, wrong_element_sum : 453879.00000000, same_data : 0.00%\n",
      "ae train 실행 시간: 0.509초, 전체 시작 시간 20250320_221542_161\n",
      "\n",
      "epoch-36 accuracy check\n",
      "k_means origin feature average accuracy : 74.09776153%, total [0.7409776153494746]\n",
      "kmeans average accuracy best : 74.28%, kmeans average accuracy : 68.34170854%, total [0.6834170854271356]\n",
      "accuracy_check 실행 시간: 7.591초\n",
      "\n",
      "\n",
      "epoch-37 loss : 0.02231571, loss_normal : 0.03515911, loss_coarse : 0.08342947, min_loss : 0.02212197, min_loss_normal : 0.03508853, min_loss_coarse : 0.08293113, wrong_element_sum : 456529.00000000, same_data : 0.00%\n",
      "ae train 실행 시간: 0.517초, 전체 시작 시간 20250320_221542_161\n",
      "\n",
      "epoch-37 accuracy check\n",
      "k_means origin feature average accuracy : 74.28049338%, total [0.7428049337597076]\n",
      "kmeans average accuracy best : 74.28%, kmeans average accuracy : 69.52946551%, total [0.6952946550936501]\n",
      "accuracy_check 실행 시간: 7.568초\n",
      "\n",
      "\n",
      "epoch-38 loss : 0.02260472, loss_normal : 0.03526965, loss_coarse : 0.08450674, min_loss : 0.02212197, min_loss_normal : 0.03508853, min_loss_coarse : 0.08293113, wrong_element_sum : 462268.00000000, same_data : 0.00%\n",
      "ae train 실행 시간: 0.500초, 전체 시작 시간 20250320_221542_161\n",
      "\n",
      "epoch-38 accuracy check\n",
      "k_means origin feature average accuracy : 73.64093193%, total [0.7364093193238922]\n",
      "kmeans average accuracy best : 74.28%, kmeans average accuracy : 66.46870717%, total [0.6646870717222476]\n",
      "accuracy_check 실행 시간: 7.709초\n",
      "\n",
      "\n",
      "epoch-39 loss : 0.02207287, loss_normal : 0.03510343, loss_coarse : 0.08280876, min_loss : 0.02207287, min_loss_normal : 0.03508853, min_loss_coarse : 0.08280876, wrong_element_sum : 452882.00000000, same_data : 0.00%\n",
      "ae train 실행 시간: 0.525초, 전체 시작 시간 20250320_221542_161\n",
      "\n",
      "epoch-39 accuracy check\n",
      "k_means origin feature average accuracy : 74.09776153%, total [0.7409776153494746]\n",
      "kmeans average accuracy best : 74.28%, kmeans average accuracy : 72.68158977%, total [0.7268158976701691]\n",
      "accuracy_check 실행 시간: 8.184초\n",
      "\n",
      "\n",
      "epoch-40 loss : 0.02192472, loss_normal : 0.03508165, loss_coarse : 0.08272052, min_loss : 0.02192472, min_loss_normal : 0.03508165, min_loss_coarse : 0.08272052, wrong_element_sum : 452924.00000000, same_data : 0.00%\n",
      "ae train 실행 시간: 0.517초, 전체 시작 시간 20250320_221542_161\n",
      "\n",
      "epoch-40 accuracy check\n",
      "k_means origin feature average accuracy : 72.59022385%, total [0.7259022384650525]\n",
      "kmeans average accuracy best : 74.28%, kmeans average accuracy : 64.13887620%, total [0.6413887619917771]\n",
      "accuracy_check 실행 시간: 7.758초\n",
      "\n",
      "\n",
      "epoch-41 loss : 0.02192943, loss_normal : 0.03502885, loss_coarse : 0.08262406, min_loss : 0.02192472, min_loss_normal : 0.03502885, min_loss_coarse : 0.08262406, wrong_element_sum : 451994.00000000, same_data : 0.00%\n",
      "ae train 실행 시간: 0.553초, 전체 시작 시간 20250320_221542_161\n",
      "\n",
      "epoch-41 accuracy check\n",
      "k_means origin feature average accuracy : 74.69164002%, total [0.7469164001827319]\n",
      "kmeans average accuracy best : 74.28%, kmeans average accuracy : 62.22019187%, total [0.6222019186843307]\n",
      "accuracy_check 실행 시간: 7.670초\n",
      "\n",
      "\n",
      "epoch-42 loss : 0.02205020, loss_normal : 0.03507481, loss_coarse : 0.08302616, min_loss : 0.02192472, min_loss_normal : 0.03502885, min_loss_coarse : 0.08262406, wrong_element_sum : 454386.00000000, same_data : 0.00%\n",
      "ae train 실행 시간: 0.518초, 전체 시작 시간 20250320_221542_161\n",
      "\n",
      "epoch-42 accuracy check\n",
      "k_means origin feature average accuracy : 74.46322522%, total [0.7446322521699407]\n",
      "kmeans average accuracy best : 74.28%, kmeans average accuracy : 66.14892645%, total [0.6614892645043399]\n",
      "accuracy_check 실행 시간: 7.819초\n",
      "\n",
      "\n",
      "epoch-43 loss : 0.02200529, loss_normal : 0.03508933, loss_coarse : 0.08299764, min_loss : 0.02192472, min_loss_normal : 0.03502885, min_loss_coarse : 0.08262406, wrong_element_sum : 454537.00000000, same_data : 0.00%\n",
      "ae train 실행 시간: 0.526초, 전체 시작 시간 20250320_221542_161\n",
      "\n",
      "epoch-43 accuracy check\n",
      "k_means origin feature average accuracy : 74.41754226%, total [0.7441754225673823]\n",
      "kmeans average accuracy best : 74.28%, kmeans average accuracy : 69.34673367%, total [0.6934673366834171]\n",
      "accuracy_check 실행 시간: 7.601초\n",
      "\n",
      "\n",
      "epoch-44 loss : 0.02197043, loss_normal : 0.03504479, loss_coarse : 0.08283346, min_loss : 0.02192472, min_loss_normal : 0.03502885, min_loss_coarse : 0.08262406, wrong_element_sum : 453505.00000000, same_data : 0.00%\n",
      "ae train 실행 시간: 0.524초, 전체 시작 시간 20250320_221542_161\n",
      "\n",
      "epoch-44 accuracy check\n",
      "k_means origin feature average accuracy : 74.28049338%, total [0.7428049337597076]\n",
      "kmeans average accuracy best : 74.28%, kmeans average accuracy : 70.89995432%, total [0.7089995431703975]\n",
      "accuracy_check 실행 시간: 7.650초\n",
      "\n",
      "\n",
      "epoch-45 loss : 0.02191130, loss_normal : 0.03504416, loss_coarse : 0.08259486, min_loss : 0.02191130, min_loss_normal : 0.03502885, min_loss_coarse : 0.08259486, wrong_element_sum : 452090.00000000, same_data : 0.00%\n",
      "ae train 실행 시간: 0.538초, 전체 시작 시간 20250320_221542_161\n",
      "\n",
      "epoch-45 accuracy check\n",
      "k_means origin feature average accuracy : 74.28049338%, total [0.7428049337597076]\n",
      "kmeans average accuracy best : 74.28%, kmeans average accuracy : 71.35678392%, total [0.7135678391959799]\n",
      "accuracy_check 실행 시간: 7.682초\n",
      "\n",
      "\n",
      "epoch-46 loss : 0.02199360, loss_normal : 0.03508282, loss_coarse : 0.08293676, min_loss : 0.02191130, min_loss_normal : 0.03502885, min_loss_coarse : 0.08259486, wrong_element_sum : 454179.00000000, same_data : 0.00%\n",
      "ae train 실행 시간: 0.546초, 전체 시작 시간 20250320_221542_161\n",
      "\n",
      "epoch-46 accuracy check\n",
      "k_means origin feature average accuracy : 74.23481042%, total [0.7423481041571494]\n",
      "kmeans average accuracy best : 74.28%, kmeans average accuracy : 64.68707172%, total [0.646870717222476]\n",
      "accuracy_check 실행 시간: 7.752초\n",
      "\n",
      "\n",
      "epoch-47 loss : 0.02204059, loss_normal : 0.03504796, loss_coarse : 0.08311625, min_loss : 0.02191130, min_loss_normal : 0.03502885, min_loss_coarse : 0.08259486, wrong_element_sum : 455066.00000000, same_data : 0.00%\n",
      "ae train 실행 시간: 0.531초, 전체 시작 시간 20250320_221542_161\n",
      "\n",
      "epoch-47 accuracy check\n",
      "k_means origin feature average accuracy : 74.14344450%, total [0.7414344449520329]\n",
      "kmeans average accuracy best : 74.28%, kmeans average accuracy : 60.66697122%, total [0.6066697121973504]\n",
      "accuracy_check 실행 시간: 7.758초\n",
      "\n",
      "\n",
      "epoch-48 loss : 0.02191601, loss_normal : 0.03501455, loss_coarse : 0.08297930, min_loss : 0.02191130, min_loss_normal : 0.03501455, min_loss_coarse : 0.08259486, wrong_element_sum : 454180.00000000, same_data : 0.00%\n",
      "ae train 실행 시간: 0.520초, 전체 시작 시간 20250320_221542_161\n",
      "\n",
      "epoch-48 accuracy check\n",
      "k_means origin feature average accuracy : 73.96071265%, total [0.7396071265417999]\n",
      "save model\n",
      "kmeans average accuracy best : 75.97%, kmeans average accuracy : 75.97076291%, total [0.7597076290543627]\n",
      "accuracy_check 실행 시간: 7.484초\n",
      "\n",
      "\n",
      "epoch-49 loss : 0.02173102, loss_normal : 0.03494130, loss_coarse : 0.08227065, min_loss : 0.02173102, min_loss_normal : 0.03494130, min_loss_coarse : 0.08227065, wrong_element_sum : 450448.00000000, same_data : 0.00%\n",
      "ae train 실행 시간: 0.523초, 전체 시작 시간 20250320_221542_161\n",
      "\n",
      "epoch-49 accuracy check\n",
      "k_means origin feature average accuracy : 74.18912746%, total [0.7418912745545911]\n",
      "kmeans average accuracy best : 75.97%, kmeans average accuracy : 70.48880767%, total [0.7048880767473732]\n",
      "accuracy_check 실행 시간: 7.658초\n",
      "\n",
      "\n",
      "epoch-50 loss : 0.02177831, loss_normal : 0.03500553, loss_coarse : 0.08242829, min_loss : 0.02173102, min_loss_normal : 0.03494130, min_loss_coarse : 0.08227065, wrong_element_sum : 451210.00000000, same_data : 0.00%\n",
      "ae train 실행 시간: 0.500초, 전체 시작 시간 20250320_221542_161\n",
      "\n",
      "epoch-50 accuracy check\n",
      "k_means origin feature average accuracy : 73.77798081%, total [0.737779808131567]\n",
      "save model\n",
      "kmeans average accuracy best : 76.75%, kmeans average accuracy : 76.74737323%, total [0.7674737322978529]\n",
      "accuracy_check 실행 시간: 7.667초\n",
      "\n",
      "\n",
      "epoch-51 loss : 0.02174840, loss_normal : 0.03495989, loss_coarse : 0.08255199, min_loss : 0.02173102, min_loss_normal : 0.03494130, min_loss_coarse : 0.08227065, wrong_element_sum : 452286.00000000, same_data : 0.00%\n",
      "ae train 실행 시간: 0.518초, 전체 시작 시간 20250320_221542_161\n",
      "\n",
      "epoch-51 accuracy check\n",
      "k_means origin feature average accuracy : 74.23481042%, total [0.7423481041571494]\n",
      "kmeans average accuracy best : 76.75%, kmeans average accuracy : 67.74783006%, total [0.6774783005938785]\n",
      "accuracy_check 실행 시간: 7.658초\n",
      "\n",
      "\n",
      "epoch-52 loss : 0.02169087, loss_normal : 0.03491728, loss_coarse : 0.08219717, min_loss : 0.02169087, min_loss_normal : 0.03491728, min_loss_coarse : 0.08219717, wrong_element_sum : 449810.00000000, same_data : 0.00%\n",
      "ae train 실행 시간: 0.517초, 전체 시작 시간 20250320_221542_161\n",
      "\n",
      "epoch-52 accuracy check\n",
      "k_means origin feature average accuracy : 73.96071265%, total [0.7396071265417999]\n",
      "kmeans average accuracy best : 76.75%, kmeans average accuracy : 70.44312471%, total [0.704431247144815]\n",
      "accuracy_check 실행 시간: 7.568초\n",
      "\n",
      "\n",
      "epoch-53 loss : 0.02161031, loss_normal : 0.03488653, loss_coarse : 0.08226990, min_loss : 0.02161031, min_loss_normal : 0.03488653, min_loss_coarse : 0.08219717, wrong_element_sum : 450419.00000000, same_data : 0.00%\n",
      "ae train 실행 시간: 0.510초, 전체 시작 시간 20250320_221542_161\n",
      "\n",
      "epoch-53 accuracy check\n",
      "k_means origin feature average accuracy : 75.28551850%, total [0.752855185015989]\n",
      "kmeans average accuracy best : 76.75%, kmeans average accuracy : 66.14892645%, total [0.6614892645043399]\n",
      "accuracy_check 실행 시간: 7.578초\n",
      "\n",
      "\n",
      "epoch-54 loss : 0.02165620, loss_normal : 0.03495188, loss_coarse : 0.08236487, min_loss : 0.02161031, min_loss_normal : 0.03488653, min_loss_coarse : 0.08219717, wrong_element_sum : 450287.00000000, same_data : 0.00%\n",
      "ae train 실행 시간: 0.509초, 전체 시작 시간 20250320_221542_161\n",
      "\n",
      "epoch-54 accuracy check\n",
      "k_means origin feature average accuracy : 74.23481042%, total [0.7423481041571494]\n",
      "kmeans average accuracy best : 76.75%, kmeans average accuracy : 75.69666514%, total [0.7569666514390132]\n",
      "accuracy_check 실행 시간: 7.637초\n",
      "\n",
      "\n",
      "epoch-55 loss : 0.02164590, loss_normal : 0.03492780, loss_coarse : 0.08218378, min_loss : 0.02161031, min_loss_normal : 0.03488653, min_loss_coarse : 0.08218378, wrong_element_sum : 449321.00000000, same_data : 0.00%\n",
      "ae train 실행 시간: 0.416초, 전체 시작 시간 20250320_221542_161\n",
      "\n",
      "epoch-55 accuracy check\n",
      "k_means origin feature average accuracy : 74.28049338%, total [0.7428049337597076]\n",
      "kmeans average accuracy best : 76.75%, kmeans average accuracy : 68.61580630%, total [0.6861580630424852]\n",
      "accuracy_check 실행 시간: 7.751초\n",
      "\n",
      "\n",
      "epoch-56 loss : 0.02161910, loss_normal : 0.03491690, loss_coarse : 0.08200291, min_loss : 0.02161031, min_loss_normal : 0.03488653, min_loss_coarse : 0.08200291, wrong_element_sum : 448403.00000000, same_data : 0.00%\n",
      "ae train 실행 시간: 0.530초, 전체 시작 시간 20250320_221542_161\n",
      "\n",
      "epoch-56 accuracy check\n",
      "k_means origin feature average accuracy : 74.55459114%, total [0.7455459113750571]\n",
      "kmeans average accuracy best : 76.75%, kmeans average accuracy : 62.72270443%, total [0.6272270443124714]\n",
      "accuracy_check 실행 시간: 7.696초\n",
      "\n",
      "\n",
      "epoch-57 loss : 0.02168877, loss_normal : 0.03492527, loss_coarse : 0.08237976, min_loss : 0.02161031, min_loss_normal : 0.03488653, min_loss_coarse : 0.08200291, wrong_element_sum : 451024.00000000, same_data : 0.00%\n",
      "ae train 실행 시간: 0.522초, 전체 시작 시간 20250320_221542_161\n",
      "\n",
      "epoch-57 accuracy check\n",
      "k_means origin feature average accuracy : 73.68661489%, total [0.7368661489264504]\n",
      "kmeans average accuracy best : 76.75%, kmeans average accuracy : 72.08771128%, total [0.7208771128369118]\n",
      "accuracy_check 실행 시간: 7.817초\n",
      "\n",
      "\n",
      "epoch-58 loss : 0.02148221, loss_normal : 0.03485599, loss_coarse : 0.08172381, min_loss : 0.02148221, min_loss_normal : 0.03485599, min_loss_coarse : 0.08172381, wrong_element_sum : 447124.00000000, same_data : 0.00%\n",
      "ae train 실행 시간: 0.535초, 전체 시작 시간 20250320_221542_161\n",
      "\n",
      "epoch-58 accuracy check\n",
      "k_means origin feature average accuracy : 74.55459114%, total [0.7455459113750571]\n",
      "kmeans average accuracy best : 76.75%, kmeans average accuracy : 65.69209685%, total [0.6569209684787575]\n",
      "accuracy_check 실행 시간: 7.790초\n",
      "\n",
      "\n",
      "epoch-59 loss : 0.02150837, loss_normal : 0.03483537, loss_coarse : 0.08192861, min_loss : 0.02148221, min_loss_normal : 0.03483537, min_loss_coarse : 0.08172381, wrong_element_sum : 448557.00000000, same_data : 0.00%\n",
      "ae train 실행 시간: 0.520초, 전체 시작 시간 20250320_221542_161\n",
      "\n",
      "epoch-59 accuracy check\n",
      "k_means origin feature average accuracy : 70.30607583%, total [0.7030607583371402]\n",
      "kmeans average accuracy best : 76.75%, kmeans average accuracy : 67.38236638%, total [0.6738236637734125]\n",
      "accuracy_check 실행 시간: 7.830초\n",
      "\n",
      "\n",
      "epoch-60 loss : 0.02153634, loss_normal : 0.03483914, loss_coarse : 0.08191037, min_loss : 0.02148221, min_loss_normal : 0.03483537, min_loss_coarse : 0.08172381, wrong_element_sum : 447917.00000000, same_data : 0.00%\n",
      "ae train 실행 시간: 0.515초, 전체 시작 시간 20250320_221542_161\n",
      "\n",
      "epoch-60 accuracy check\n",
      "k_means origin feature average accuracy : 74.18912746%, total [0.7418912745545911]\n",
      "kmeans average accuracy best : 76.75%, kmeans average accuracy : 71.72224760%, total [0.7172224760164458]\n",
      "accuracy_check 실행 시간: 8.023초\n",
      "\n",
      "\n",
      "epoch-61 loss : 0.02147117, loss_normal : 0.03482761, loss_coarse : 0.08180153, min_loss : 0.02147117, min_loss_normal : 0.03482761, min_loss_coarse : 0.08172381, wrong_element_sum : 448047.00000000, same_data : 0.00%\n",
      "ae train 실행 시간: 0.516초, 전체 시작 시간 20250320_221542_161\n",
      "\n",
      "epoch-61 accuracy check\n",
      "k_means origin feature average accuracy : 73.73229785%, total [0.7373229785290086]\n",
      "kmeans average accuracy best : 76.75%, kmeans average accuracy : 76.42759251%, total [0.7642759250799451]\n",
      "accuracy_check 실행 시간: 7.706초\n",
      "\n",
      "\n",
      "epoch-62 loss : 0.02136707, loss_normal : 0.03478626, loss_coarse : 0.08147252, min_loss : 0.02136707, min_loss_normal : 0.03478626, min_loss_coarse : 0.08147252, wrong_element_sum : 446035.00000000, same_data : 0.00%\n",
      "ae train 실행 시간: 0.400초, 전체 시작 시간 20250320_221542_161\n",
      "\n",
      "epoch-62 accuracy check\n",
      "k_means origin feature average accuracy : 74.37185930%, total [0.7437185929648241]\n",
      "kmeans average accuracy best : 76.75%, kmeans average accuracy : 75.23983554%, total [0.7523983554134308]\n",
      "accuracy_check 실행 시간: 7.764초\n",
      "\n",
      "\n",
      "epoch-63 loss : 0.02153045, loss_normal : 0.03485718, loss_coarse : 0.08204010, min_loss : 0.02136707, min_loss_normal : 0.03478626, min_loss_coarse : 0.08147252, wrong_element_sum : 449019.00000000, same_data : 0.00%\n",
      "ae train 실행 시간: 0.523초, 전체 시작 시간 20250320_221542_161\n",
      "\n",
      "epoch-63 accuracy check\n",
      "k_means origin feature average accuracy : 72.77295569%, total [0.7277295568752855]\n",
      "save model\n",
      "kmeans average accuracy best : 77.11%, kmeans average accuracy : 77.11283691%, total [0.7711283691183188]\n",
      "accuracy_check 실행 시간: 7.817초\n",
      "\n",
      "\n",
      "epoch-64 loss : 0.02138955, loss_normal : 0.03481525, loss_coarse : 0.08155272, min_loss : 0.02136707, min_loss_normal : 0.03478626, min_loss_coarse : 0.08147252, wrong_element_sum : 445440.00000000, same_data : 0.00%\n",
      "ae train 실행 시간: 0.514초, 전체 시작 시간 20250320_221542_161\n",
      "\n",
      "epoch-64 accuracy check\n",
      "k_means origin feature average accuracy : 73.68661489%, total [0.7368661489264504]\n",
      "kmeans average accuracy best : 77.11%, kmeans average accuracy : 72.31612608%, total [0.7231612608497031]\n",
      "accuracy_check 실행 시간: 7.895초\n",
      "\n",
      "\n",
      "epoch-65 loss : 0.02143423, loss_normal : 0.03479071, loss_coarse : 0.08171478, min_loss : 0.02136707, min_loss_normal : 0.03478626, min_loss_coarse : 0.08147252, wrong_element_sum : 447289.00000000, same_data : 0.00%\n",
      "ae train 실행 시간: 0.525초, 전체 시작 시간 20250320_221542_161\n",
      "\n",
      "epoch-65 accuracy check\n",
      "k_means origin feature average accuracy : 73.64093193%, total [0.7364093193238922]\n",
      "save model\n",
      "kmeans average accuracy best : 78.76%, kmeans average accuracy : 78.75742348%, total [0.7875742348104157]\n",
      "accuracy_check 실행 시간: 7.963초\n",
      "\n",
      "\n",
      "epoch-66 loss : 0.02135055, loss_normal : 0.03477799, loss_coarse : 0.08150127, min_loss : 0.02135055, min_loss_normal : 0.03477799, min_loss_coarse : 0.08147252, wrong_element_sum : 446068.00000000, same_data : 0.00%\n",
      "ae train 실행 시간: 0.565초, 전체 시작 시간 20250320_221542_161\n",
      "\n",
      "epoch-66 accuracy check\n",
      "k_means origin feature average accuracy : 74.32617634%, total [0.7432617633622659]\n",
      "kmeans average accuracy best : 78.76%, kmeans average accuracy : 77.02147099%, total [0.7702147099132024]\n",
      "accuracy_check 실행 시간: 9.585초\n",
      "\n",
      "\n",
      "epoch-67 loss : 0.02158163, loss_normal : 0.03485270, loss_coarse : 0.08245545, min_loss : 0.02135055, min_loss_normal : 0.03477799, min_loss_coarse : 0.08147252, wrong_element_sum : 451262.00000000, same_data : 0.00%\n",
      "ae train 실행 시간: 0.542초, 전체 시작 시간 20250320_221542_161\n",
      "\n",
      "epoch-67 accuracy check\n",
      "k_means origin feature average accuracy : 74.28049338%, total [0.7428049337597076]\n",
      "save model\n",
      "kmeans average accuracy best : 78.99%, kmeans average accuracy : 78.98583828%, total [0.789858382823207]\n",
      "accuracy_check 실행 시간: 8.083초\n",
      "\n",
      "\n",
      "epoch-68 loss : 0.02144562, loss_normal : 0.03483493, loss_coarse : 0.08194161, min_loss : 0.02135055, min_loss_normal : 0.03477799, min_loss_coarse : 0.08147252, wrong_element_sum : 448069.00000000, same_data : 0.00%\n",
      "ae train 실행 시간: 0.557초, 전체 시작 시간 20250320_221542_161\n",
      "\n",
      "epoch-68 accuracy check\n",
      "k_means origin feature average accuracy : 74.28049338%, total [0.7428049337597076]\n",
      "kmeans average accuracy best : 78.99%, kmeans average accuracy : 75.51393330%, total [0.7551393330287802]\n",
      "accuracy_check 실행 시간: 7.987초\n",
      "\n",
      "\n",
      "epoch-69 loss : 0.02134032, loss_normal : 0.03478079, loss_coarse : 0.08169622, min_loss : 0.02134032, min_loss_normal : 0.03477799, min_loss_coarse : 0.08147252, wrong_element_sum : 447606.00000000, same_data : 0.00%\n",
      "ae train 실행 시간: 0.513초, 전체 시작 시간 20250320_221542_161\n",
      "\n",
      "epoch-69 accuracy check\n",
      "k_means origin feature average accuracy : 74.05207857%, total [0.7405207857469164]\n",
      "kmeans average accuracy best : 78.99%, kmeans average accuracy : 70.94563728%, total [0.7094563727729557]\n",
      "accuracy_check 실행 시간: 7.708초\n",
      "\n",
      "\n",
      "epoch-70 loss : 0.02138139, loss_normal : 0.03477633, loss_coarse : 0.08178337, min_loss : 0.02134032, min_loss_normal : 0.03477633, min_loss_coarse : 0.08147252, wrong_element_sum : 447482.00000000, same_data : 0.00%\n",
      "ae train 실행 시간: 0.536초, 전체 시작 시간 20250320_221542_161\n",
      "\n",
      "epoch-70 accuracy check\n",
      "k_means origin feature average accuracy : 74.32617634%, total [0.7432617633622659]\n",
      "kmeans average accuracy best : 78.99%, kmeans average accuracy : 61.62631339%, total [0.6162631338510736]\n",
      "accuracy_check 실행 시간: 8.015초\n",
      "\n",
      "\n",
      "epoch-71 loss : 0.02133988, loss_normal : 0.03476513, loss_coarse : 0.08164852, min_loss : 0.02133988, min_loss_normal : 0.03476513, min_loss_coarse : 0.08147252, wrong_element_sum : 446856.00000000, same_data : 0.00%\n",
      "ae train 실행 시간: 0.518초, 전체 시작 시간 20250320_221542_161\n",
      "\n",
      "epoch-71 accuracy check\n",
      "k_means origin feature average accuracy : 74.78300594%, total [0.7478300593878483]\n",
      "kmeans average accuracy best : 78.99%, kmeans average accuracy : 77.98081316%, total [0.7798081315669255]\n",
      "accuracy_check 실행 시간: 7.761초\n",
      "\n",
      "\n",
      "epoch-72 loss : 0.02118913, loss_normal : 0.03468696, loss_coarse : 0.08131878, min_loss : 0.02118913, min_loss_normal : 0.03468696, min_loss_coarse : 0.08131878, wrong_element_sum : 445486.00000000, same_data : 0.00%\n",
      "ae train 실행 시간: 0.550초, 전체 시작 시간 20250320_221542_161\n",
      "\n",
      "epoch-72 accuracy check\n",
      "k_means origin feature average accuracy : 73.59524897%, total [0.735952489721334]\n",
      "kmeans average accuracy best : 78.99%, kmeans average accuracy : 71.76793056%, total [0.7176793056190041]\n",
      "accuracy_check 실행 시간: 8.317초\n",
      "\n",
      "\n",
      "epoch-73 loss : 0.02121725, loss_normal : 0.03472250, loss_coarse : 0.08143603, min_loss : 0.02118913, min_loss_normal : 0.03468696, min_loss_coarse : 0.08131878, wrong_element_sum : 445705.00000000, same_data : 0.00%\n",
      "ae train 실행 시간: 0.534초, 전체 시작 시간 20250320_221542_161\n",
      "\n",
      "epoch-73 accuracy check\n",
      "k_means origin feature average accuracy : 74.18912746%, total [0.7418912745545911]\n",
      "kmeans average accuracy best : 78.99%, kmeans average accuracy : 69.39241663%, total [0.6939241662859753]\n",
      "accuracy_check 실행 시간: 8.039초\n",
      "\n",
      "\n",
      "epoch-74 loss : 0.02121999, loss_normal : 0.03469799, loss_coarse : 0.08128783, min_loss : 0.02118913, min_loss_normal : 0.03468696, min_loss_coarse : 0.08128783, wrong_element_sum : 443763.00000000, same_data : 0.00%\n",
      "ae train 실행 시간: 0.548초, 전체 시작 시간 20250320_221542_161\n",
      "\n",
      "epoch-74 accuracy check\n",
      "k_means origin feature average accuracy : 73.77798081%, total [0.737779808131567]\n",
      "kmeans average accuracy best : 78.99%, kmeans average accuracy : 63.95614436%, total [0.6395614435815441]\n",
      "accuracy_check 실행 시간: 7.657초\n",
      "\n",
      "\n",
      "epoch-75 loss : 0.02122610, loss_normal : 0.03473286, loss_coarse : 0.08152132, min_loss : 0.02118913, min_loss_normal : 0.03468696, min_loss_coarse : 0.08128783, wrong_element_sum : 446281.00000000, same_data : 0.00%\n",
      "ae train 실행 시간: 0.516초, 전체 시작 시간 20250320_221542_161\n",
      "\n",
      "epoch-75 accuracy check\n",
      "k_means origin feature average accuracy : 74.05207857%, total [0.7405207857469164]\n",
      "kmeans average accuracy best : 78.99%, kmeans average accuracy : 78.75742348%, total [0.7875742348104157]\n",
      "accuracy_check 실행 시간: 7.706초\n",
      "\n",
      "\n",
      "epoch-76 loss : 0.02116503, loss_normal : 0.03470224, loss_coarse : 0.08138687, min_loss : 0.02116503, min_loss_normal : 0.03468696, min_loss_coarse : 0.08128783, wrong_element_sum : 445381.00000000, same_data : 0.00%\n",
      "ae train 실행 시간: 0.502초, 전체 시작 시간 20250320_221542_161\n",
      "\n",
      "epoch-76 accuracy check\n",
      "k_means origin feature average accuracy : 73.77798081%, total [0.737779808131567]\n",
      "kmeans average accuracy best : 78.99%, kmeans average accuracy : 68.29602558%, total [0.6829602558245774]\n",
      "accuracy_check 실행 시간: 7.828초\n",
      "\n",
      "\n",
      "epoch-77 loss : 0.02114825, loss_normal : 0.03470221, loss_coarse : 0.08120957, min_loss : 0.02114825, min_loss_normal : 0.03468696, min_loss_coarse : 0.08120957, wrong_element_sum : 444528.00000000, same_data : 0.00%\n",
      "ae train 실행 시간: 0.531초, 전체 시작 시간 20250320_221542_161\n",
      "\n",
      "epoch-77 accuracy check\n",
      "k_means origin feature average accuracy : 73.77798081%, total [0.737779808131567]\n",
      "kmeans average accuracy best : 78.99%, kmeans average accuracy : 62.49428963%, total [0.6249428962996803]\n",
      "accuracy_check 실행 시간: 7.771초\n",
      "\n",
      "\n",
      "epoch-78 loss : 0.02105648, loss_normal : 0.03466753, loss_coarse : 0.08097472, min_loss : 0.02105648, min_loss_normal : 0.03466753, min_loss_coarse : 0.08097472, wrong_element_sum : 442799.00000000, same_data : 0.00%\n",
      "ae train 실행 시간: 0.527초, 전체 시작 시간 20250320_221542_161\n",
      "\n",
      "epoch-78 accuracy check\n",
      "k_means origin feature average accuracy : 74.09776153%, total [0.7409776153494746]\n",
      "kmeans average accuracy best : 78.99%, kmeans average accuracy : 71.08268616%, total [0.7108268615806305]\n",
      "accuracy_check 실행 시간: 7.792초\n",
      "\n",
      "\n",
      "epoch-79 loss : 0.02098031, loss_normal : 0.03459447, loss_coarse : 0.08076098, min_loss : 0.02098031, min_loss_normal : 0.03459447, min_loss_coarse : 0.08076098, wrong_element_sum : 442138.00000000, same_data : 0.00%\n",
      "ae train 실행 시간: 0.505초, 전체 시작 시간 20250320_221542_161\n",
      "\n",
      "epoch-79 accuracy check\n",
      "k_means origin feature average accuracy : 73.73229785%, total [0.7373229785290086]\n",
      "kmeans average accuracy best : 78.99%, kmeans average accuracy : 78.30059388%, total [0.7830059387848333]\n",
      "accuracy_check 실행 시간: 7.767초\n",
      "\n",
      "\n",
      "epoch-80 loss : 0.02101627, loss_normal : 0.03465211, loss_coarse : 0.08096200, min_loss : 0.02098031, min_loss_normal : 0.03459447, min_loss_coarse : 0.08076098, wrong_element_sum : 442967.00000000, same_data : 0.00%\n",
      "ae train 실행 시간: 0.518초, 전체 시작 시간 20250320_221542_161\n",
      "\n",
      "epoch-80 accuracy check\n",
      "k_means origin feature average accuracy : 74.41754226%, total [0.7441754225673823]\n",
      "kmeans average accuracy best : 78.99%, kmeans average accuracy : 69.98629511%, total [0.6998629511192326]\n",
      "accuracy_check 실행 시간: 7.687초\n",
      "\n",
      "\n",
      "epoch-81 loss : 0.02117276, loss_normal : 0.03468907, loss_coarse : 0.08138127, min_loss : 0.02098031, min_loss_normal : 0.03459447, min_loss_coarse : 0.08076098, wrong_element_sum : 445296.00000000, same_data : 0.00%\n",
      "ae train 실행 시간: 0.536초, 전체 시작 시간 20250320_221542_161\n",
      "\n",
      "epoch-81 accuracy check\n",
      "k_means origin feature average accuracy : 73.96071265%, total [0.7396071265417999]\n",
      "kmeans average accuracy best : 78.99%, kmeans average accuracy : 78.20922796%, total [0.7820922795797167]\n",
      "accuracy_check 실행 시간: 7.812초\n",
      "\n",
      "\n",
      "epoch-82 loss : 0.02116902, loss_normal : 0.03468911, loss_coarse : 0.08106264, min_loss : 0.02098031, min_loss_normal : 0.03459447, min_loss_coarse : 0.08076098, wrong_element_sum : 443448.00000000, same_data : 0.00%\n",
      "ae train 실행 시간: 0.526초, 전체 시작 시간 20250320_221542_161\n",
      "\n",
      "epoch-82 accuracy check\n",
      "k_means origin feature average accuracy : 74.32617634%, total [0.7432617633622659]\n",
      "save model\n",
      "kmeans average accuracy best : 79.21%, kmeans average accuracy : 79.21425308%, total [0.7921425308359982]\n",
      "accuracy_check 실행 시간: 7.787초\n",
      "\n",
      "\n",
      "epoch-83 loss : 0.02109211, loss_normal : 0.03463910, loss_coarse : 0.08112351, min_loss : 0.02098031, min_loss_normal : 0.03459447, min_loss_coarse : 0.08076098, wrong_element_sum : 444031.00000000, same_data : 0.00%\n",
      "ae train 실행 시간: 0.515초, 전체 시작 시간 20250320_221542_161\n",
      "\n",
      "epoch-83 accuracy check\n",
      "k_means origin feature average accuracy : 74.23481042%, total [0.7423481041571494]\n",
      "kmeans average accuracy best : 79.21%, kmeans average accuracy : 79.16857012%, total [0.79168570123344]\n",
      "accuracy_check 실행 시간: 7.979초\n",
      "\n",
      "\n",
      "epoch-84 loss : 0.02097696, loss_normal : 0.03460644, loss_coarse : 0.08091499, min_loss : 0.02097696, min_loss_normal : 0.03459447, min_loss_coarse : 0.08076098, wrong_element_sum : 442937.00000000, same_data : 0.00%\n",
      "ae train 실행 시간: 0.524초, 전체 시작 시간 20250320_221542_161\n",
      "\n",
      "epoch-84 accuracy check\n",
      "k_means origin feature average accuracy : 73.96071265%, total [0.7396071265417999]\n",
      "kmeans average accuracy best : 79.21%, kmeans average accuracy : 78.20922796%, total [0.7820922795797167]\n",
      "accuracy_check 실행 시간: 7.932초\n",
      "\n",
      "\n",
      "epoch-85 loss : 0.02103705, loss_normal : 0.03464786, loss_coarse : 0.08103934, min_loss : 0.02097696, min_loss_normal : 0.03459447, min_loss_coarse : 0.08076098, wrong_element_sum : 442764.00000000, same_data : 0.00%\n",
      "ae train 실행 시간: 0.514초, 전체 시작 시간 20250320_221542_161\n",
      "\n",
      "epoch-85 accuracy check\n",
      "k_means origin feature average accuracy : 73.96071265%, total [0.7396071265417999]\n",
      "kmeans average accuracy best : 79.21%, kmeans average accuracy : 66.42302421%, total [0.6642302421196894]\n",
      "accuracy_check 실행 시간: 7.719초\n",
      "\n",
      "\n",
      "epoch-86 loss : 0.02096051, loss_normal : 0.03459543, loss_coarse : 0.08081003, min_loss : 0.02096051, min_loss_normal : 0.03459447, min_loss_coarse : 0.08076098, wrong_element_sum : 441602.00000000, same_data : 0.00%\n",
      "ae train 실행 시간: 0.521초, 전체 시작 시간 20250320_221542_161\n",
      "\n",
      "epoch-86 accuracy check\n",
      "k_means origin feature average accuracy : 74.55459114%, total [0.7455459113750571]\n",
      "save model\n",
      "kmeans average accuracy best : 79.85%, kmeans average accuracy : 79.85381453%, total [0.7985381452718137]\n",
      "accuracy_check 실행 시간: 7.900초\n",
      "\n",
      "\n",
      "epoch-87 loss : 0.02109270, loss_normal : 0.03462567, loss_coarse : 0.08116389, min_loss : 0.02096051, min_loss_normal : 0.03459447, min_loss_coarse : 0.08076098, wrong_element_sum : 443947.00000000, same_data : 0.00%\n",
      "ae train 실행 시간: 0.521초, 전체 시작 시간 20250320_221542_161\n",
      "\n",
      "epoch-87 accuracy check\n",
      "k_means origin feature average accuracy : 73.73229785%, total [0.7373229785290086]\n",
      "kmeans average accuracy best : 79.85%, kmeans average accuracy : 77.79808132%, total [0.7779808131566925]\n",
      "accuracy_check 실행 시간: 8.485초\n",
      "\n",
      "\n",
      "epoch-88 loss : 0.02102010, loss_normal : 0.03466238, loss_coarse : 0.08132033, min_loss : 0.02096051, min_loss_normal : 0.03459447, min_loss_coarse : 0.08076098, wrong_element_sum : 444660.00000000, same_data : 0.00%\n",
      "ae train 실행 시간: 0.535초, 전체 시작 시간 20250320_221542_161\n",
      "\n",
      "epoch-88 accuracy check\n",
      "k_means origin feature average accuracy : 74.32617634%, total [0.7432617633622659]\n",
      "kmeans average accuracy best : 79.85%, kmeans average accuracy : 77.84376428%, total [0.7784376427592508]\n",
      "accuracy_check 실행 시간: 8.303초\n",
      "\n",
      "\n",
      "epoch-89 loss : 0.02089232, loss_normal : 0.03458152, loss_coarse : 0.08065538, min_loss : 0.02089232, min_loss_normal : 0.03458152, min_loss_coarse : 0.08065538, wrong_element_sum : 441368.00000000, same_data : 0.00%\n",
      "ae train 실행 시간: 0.526초, 전체 시작 시간 20250320_221542_161\n",
      "\n",
      "epoch-89 accuracy check\n",
      "k_means origin feature average accuracy : 74.14344450%, total [0.7414344449520329]\n",
      "kmeans average accuracy best : 79.85%, kmeans average accuracy : 65.41799909%, total [0.654179990863408]\n",
      "accuracy_check 실행 시간: 8.072초\n",
      "\n",
      "\n",
      "epoch-90 loss : 0.02103440, loss_normal : 0.03463620, loss_coarse : 0.08116863, min_loss : 0.02089232, min_loss_normal : 0.03458152, min_loss_coarse : 0.08065538, wrong_element_sum : 444131.00000000, same_data : 0.00%\n",
      "ae train 실행 시간: 0.502초, 전체 시작 시간 20250320_221542_161\n",
      "\n",
      "epoch-90 accuracy check\n",
      "k_means origin feature average accuracy : 74.18912746%, total [0.7418912745545911]\n",
      "kmeans average accuracy best : 79.85%, kmeans average accuracy : 72.17907720%, total [0.7217907720420284]\n",
      "accuracy_check 실행 시간: 7.961초\n",
      "\n",
      "\n",
      "epoch-91 loss : 0.02088150, loss_normal : 0.03457572, loss_coarse : 0.08071604, min_loss : 0.02088150, min_loss_normal : 0.03457572, min_loss_coarse : 0.08065538, wrong_element_sum : 441982.00000000, same_data : 0.00%\n",
      "ae train 실행 시간: 0.526초, 전체 시작 시간 20250320_221542_161\n",
      "\n",
      "epoch-91 accuracy check\n",
      "k_means origin feature average accuracy : 74.18912746%, total [0.7418912745545911]\n",
      "kmeans average accuracy best : 79.85%, kmeans average accuracy : 78.66605756%, total [0.7866605756052992]\n",
      "accuracy_check 실행 시간: 8.039초\n",
      "\n",
      "\n",
      "epoch-92 loss : 0.02080181, loss_normal : 0.03452442, loss_coarse : 0.08042830, min_loss : 0.02080181, min_loss_normal : 0.03452442, min_loss_coarse : 0.08042830, wrong_element_sum : 440382.00000000, same_data : 0.00%\n",
      "ae train 실행 시간: 0.519초, 전체 시작 시간 20250320_221542_161\n",
      "\n",
      "epoch-92 accuracy check\n",
      "k_means origin feature average accuracy : 72.22476016%, total [0.7222476016445866]\n",
      "kmeans average accuracy best : 79.85%, kmeans average accuracy : 60.30150754%, total [0.6030150753768844]\n",
      "accuracy_check 실행 시간: 8.091초\n",
      "\n",
      "\n",
      "epoch-93 loss : 0.02082198, loss_normal : 0.03456285, loss_coarse : 0.08074830, min_loss : 0.02080181, min_loss_normal : 0.03452442, min_loss_coarse : 0.08042830, wrong_element_sum : 441403.00000000, same_data : 0.00%\n",
      "ae train 실행 시간: 0.519초, 전체 시작 시간 20250320_221542_161\n",
      "\n",
      "epoch-93 accuracy check\n",
      "k_means origin feature average accuracy : 74.23481042%, total [0.7423481041571494]\n",
      "kmeans average accuracy best : 79.85%, kmeans average accuracy : 79.57971677%, total [0.7957971676564641]\n",
      "accuracy_check 실행 시간: 7.999초\n",
      "\n",
      "\n",
      "epoch-94 loss : 0.02083864, loss_normal : 0.03455745, loss_coarse : 0.08076641, min_loss : 0.02080181, min_loss_normal : 0.03452442, min_loss_coarse : 0.08042830, wrong_element_sum : 441997.00000000, same_data : 0.00%\n",
      "ae train 실행 시간: 0.522초, 전체 시작 시간 20250320_221542_161\n",
      "\n",
      "epoch-94 accuracy check\n",
      "k_means origin feature average accuracy : 74.23481042%, total [0.7423481041571494]\n",
      "kmeans average accuracy best : 79.85%, kmeans average accuracy : 62.22019187%, total [0.6222019186843307]\n",
      "accuracy_check 실행 시간: 7.891초\n",
      "\n",
      "\n",
      "epoch-95 loss : 0.02064904, loss_normal : 0.03447342, loss_coarse : 0.08001607, min_loss : 0.02064904, min_loss_normal : 0.03447342, min_loss_coarse : 0.08001607, wrong_element_sum : 438238.00000000, same_data : 0.00%\n",
      "ae train 실행 시간: 0.529초, 전체 시작 시간 20250320_221542_161\n",
      "\n",
      "epoch-95 accuracy check\n",
      "k_means origin feature average accuracy : 71.81361352%, total [0.7181361352215624]\n",
      "kmeans average accuracy best : 79.85%, kmeans average accuracy : 73.00137049%, total [0.7300137048880767]\n",
      "accuracy_check 실행 시간: 8.078초\n",
      "\n",
      "\n",
      "epoch-96 loss : 0.02063501, loss_normal : 0.03446492, loss_coarse : 0.08019229, min_loss : 0.02063501, min_loss_normal : 0.03446492, min_loss_coarse : 0.08001607, wrong_element_sum : 439088.00000000, same_data : 0.00%\n",
      "ae train 실행 시간: 0.532초, 전체 시작 시간 20250320_221542_161\n",
      "\n",
      "epoch-96 accuracy check\n",
      "k_means origin feature average accuracy : 73.32115121%, total [0.7332115121059845]\n",
      "kmeans average accuracy best : 79.85%, kmeans average accuracy : 78.66605756%, total [0.7866605756052992]\n",
      "accuracy_check 실행 시간: 7.835초\n",
      "\n",
      "\n",
      "epoch-97 loss : 0.02078585, loss_normal : 0.03452704, loss_coarse : 0.08049982, min_loss : 0.02063501, min_loss_normal : 0.03446492, min_loss_coarse : 0.08001607, wrong_element_sum : 440312.00000000, same_data : 0.00%\n",
      "ae train 실행 시간: 0.517초, 전체 시작 시간 20250320_221542_161\n",
      "\n",
      "epoch-97 accuracy check\n",
      "k_means origin feature average accuracy : 72.17907720%, total [0.7217907720420284]\n",
      "kmeans average accuracy best : 79.85%, kmeans average accuracy : 69.57514847%, total [0.6957514846962083]\n",
      "accuracy_check 실행 시간: 8.052초\n",
      "\n",
      "\n",
      "epoch-98 loss : 0.02069714, loss_normal : 0.03448245, loss_coarse : 0.08028964, min_loss : 0.02063501, min_loss_normal : 0.03446492, min_loss_coarse : 0.08001607, wrong_element_sum : 439792.00000000, same_data : 0.00%\n",
      "ae train 실행 시간: 0.536초, 전체 시작 시간 20250320_221542_161\n",
      "\n",
      "epoch-98 accuracy check\n",
      "k_means origin feature average accuracy : 73.73229785%, total [0.7373229785290086]\n",
      "kmeans average accuracy best : 79.85%, kmeans average accuracy : 79.71676565%, total [0.7971676564641389]\n",
      "accuracy_check 실행 시간: 8.141초\n",
      "\n",
      "\n",
      "epoch-99 loss : 0.02071259, loss_normal : 0.03450734, loss_coarse : 0.08062670, min_loss : 0.02063501, min_loss_normal : 0.03446492, min_loss_coarse : 0.08001607, wrong_element_sum : 441730.00000000, same_data : 0.00%\n",
      "ae train 실행 시간: 0.528초, 전체 시작 시간 20250320_221542_161\n",
      "\n",
      "epoch-99 accuracy check\n",
      "k_means origin feature average accuracy : 74.18912746%, total [0.7418912745545911]\n",
      "kmeans average accuracy best : 79.85%, kmeans average accuracy : 78.25491092%, total [0.782549109182275]\n",
      "accuracy_check 실행 시간: 7.986초\n",
      "\n",
      "\n",
      "epoch-100 loss : 0.02064921, loss_normal : 0.03448341, loss_coarse : 0.08049074, min_loss : 0.02063501, min_loss_normal : 0.03446492, min_loss_coarse : 0.08001607, wrong_element_sum : 440411.00000000, same_data : 0.00%\n",
      "ae train 실행 시간: 0.518초, 전체 시작 시간 20250320_221542_161\n",
      "\n",
      "epoch-100 accuracy check\n",
      "k_means origin feature average accuracy : 74.55459114%, total [0.7455459113750571]\n",
      "save model\n",
      "kmeans average accuracy best : 80.17%, kmeans average accuracy : 80.17359525%, total [0.8017359524897213]\n",
      "accuracy_check 실행 시간: 9.103초\n",
      "\n",
      "\n",
      "epoch-101 loss : 0.02048520, loss_normal : 0.03437634, loss_coarse : 0.07977593, min_loss : 0.02048520, min_loss_normal : 0.03437634, min_loss_coarse : 0.07977593, wrong_element_sum : 436759.00000000, same_data : 0.00%\n",
      "ae train 실행 시간: 0.530초, 전체 시작 시간 20250320_221542_161\n",
      "\n",
      "epoch-101 accuracy check\n",
      "k_means origin feature average accuracy : 74.60027410%, total [0.7460027409776153]\n",
      "kmeans average accuracy best : 80.17%, kmeans average accuracy : 79.57971677%, total [0.7957971676564641]\n",
      "accuracy_check 실행 시간: 8.070초\n",
      "\n",
      "\n",
      "epoch-102 loss : 0.02058243, loss_normal : 0.03441908, loss_coarse : 0.08000992, min_loss : 0.02048520, min_loss_normal : 0.03437634, min_loss_coarse : 0.07977593, wrong_element_sum : 437637.00000000, same_data : 0.00%\n",
      "ae train 실행 시간: 0.533초, 전체 시작 시간 20250320_221542_161\n",
      "\n",
      "epoch-102 accuracy check\n",
      "k_means origin feature average accuracy : 76.93010507%, total [0.7693010507080859]\n",
      "kmeans average accuracy best : 80.17%, kmeans average accuracy : 72.13339424%, total [0.7213339424394701]\n",
      "accuracy_check 실행 시간: 8.019초\n",
      "\n",
      "\n",
      "epoch-103 loss : 0.02063872, loss_normal : 0.03444863, loss_coarse : 0.08029831, min_loss : 0.02048520, min_loss_normal : 0.03437634, min_loss_coarse : 0.07977593, wrong_element_sum : 439093.00000000, same_data : 0.00%\n",
      "ae train 실행 시간: 0.560초, 전체 시작 시간 20250320_221542_161\n",
      "\n",
      "epoch-103 accuracy check\n",
      "k_means origin feature average accuracy : 74.50890818%, total [0.7450890817724989]\n",
      "kmeans average accuracy best : 80.17%, kmeans average accuracy : 62.40292371%, total [0.6240292370945637]\n",
      "accuracy_check 실행 시간: 8.102초\n",
      "\n",
      "\n",
      "epoch-104 loss : 0.02064746, loss_normal : 0.03446268, loss_coarse : 0.08014990, min_loss : 0.02048520, min_loss_normal : 0.03437634, min_loss_coarse : 0.07977593, wrong_element_sum : 438759.00000000, same_data : 0.00%\n",
      "ae train 실행 시간: 0.548초, 전체 시작 시간 20250320_221542_161\n",
      "\n",
      "epoch-104 accuracy check\n",
      "k_means origin feature average accuracy : 74.05207857%, total [0.7405207857469164]\n",
      "kmeans average accuracy best : 80.17%, kmeans average accuracy : 79.76244861%, total [0.7976244860666971]\n",
      "accuracy_check 실행 시간: 7.884초\n",
      "\n",
      "\n",
      "epoch-105 loss : 0.02067858, loss_normal : 0.03451348, loss_coarse : 0.08057616, min_loss : 0.02048520, min_loss_normal : 0.03437634, min_loss_coarse : 0.07977593, wrong_element_sum : 440786.00000000, same_data : 0.00%\n",
      "ae train 실행 시간: 0.411초, 전체 시작 시간 20250320_221542_161\n",
      "\n",
      "epoch-105 accuracy check\n",
      "k_means origin feature average accuracy : 73.77798081%, total [0.737779808131567]\n",
      "kmeans average accuracy best : 80.17%, kmeans average accuracy : 63.13385107%, total [0.6313385107354956]\n",
      "accuracy_check 실행 시간: 8.735초\n",
      "\n",
      "\n",
      "epoch-106 loss : 0.02060171, loss_normal : 0.03442038, loss_coarse : 0.08014841, min_loss : 0.02048520, min_loss_normal : 0.03437634, min_loss_coarse : 0.07977593, wrong_element_sum : 438704.00000000, same_data : 0.00%\n",
      "ae train 실행 시간: 0.411초, 전체 시작 시간 20250320_221542_161\n",
      "\n",
      "epoch-106 accuracy check\n",
      "k_means origin feature average accuracy : 73.73229785%, total [0.7373229785290086]\n",
      "kmeans average accuracy best : 80.17%, kmeans average accuracy : 71.40246688%, total [0.7140246687985381]\n",
      "accuracy_check 실행 시간: 7.755초\n",
      "\n",
      "\n",
      "epoch-107 loss : 0.02061393, loss_normal : 0.03438524, loss_coarse : 0.08007981, min_loss : 0.02048520, min_loss_normal : 0.03437634, min_loss_coarse : 0.07977593, wrong_element_sum : 438375.00000000, same_data : 0.00%\n",
      "ae train 실행 시간: 0.515초, 전체 시작 시간 20250320_221542_161\n",
      "\n",
      "epoch-107 accuracy check\n",
      "k_means origin feature average accuracy : 74.32617634%, total [0.7432617633622659]\n",
      "kmeans average accuracy best : 80.17%, kmeans average accuracy : 76.65600731%, total [0.7665600730927364]\n",
      "accuracy_check 실행 시간: 7.614초\n",
      "\n",
      "\n",
      "epoch-108 loss : 0.02084311, loss_normal : 0.03453425, loss_coarse : 0.08071473, min_loss : 0.02048520, min_loss_normal : 0.03437634, min_loss_coarse : 0.07977593, wrong_element_sum : 441966.00000000, same_data : 0.00%\n",
      "ae train 실행 시간: 0.494초, 전체 시작 시간 20250320_221542_161\n",
      "\n",
      "epoch-108 accuracy check\n",
      "k_means origin feature average accuracy : 74.82868890%, total [0.7482868889904066]\n",
      "kmeans average accuracy best : 80.17%, kmeans average accuracy : 79.76244861%, total [0.7976244860666971]\n",
      "accuracy_check 실행 시간: 7.719초\n",
      "\n",
      "\n",
      "epoch-109 loss : 0.02074484, loss_normal : 0.03447159, loss_coarse : 0.08051308, min_loss : 0.02048520, min_loss_normal : 0.03437634, min_loss_coarse : 0.07977593, wrong_element_sum : 440926.00000000, same_data : 0.00%\n",
      "ae train 실행 시간: 0.499초, 전체 시작 시간 20250320_221542_161\n",
      "\n",
      "epoch-109 accuracy check\n",
      "k_means origin feature average accuracy : 74.73732298%, total [0.7473732297852901]\n",
      "kmeans average accuracy best : 80.17%, kmeans average accuracy : 79.89949749%, total [0.7989949748743719]\n",
      "accuracy_check 실행 시간: 7.521초\n",
      "\n",
      "\n",
      "epoch-110 loss : 0.02075213, loss_normal : 0.03444025, loss_coarse : 0.08079226, min_loss : 0.02048520, min_loss_normal : 0.03437634, min_loss_coarse : 0.07977593, wrong_element_sum : 441596.00000000, same_data : 0.00%\n",
      "ae train 실행 시간: 0.487초, 전체 시작 시간 20250320_221542_161\n",
      "\n",
      "epoch-110 accuracy check\n",
      "k_means origin feature average accuracy : 74.18912746%, total [0.7418912745545911]\n",
      "kmeans average accuracy best : 80.17%, kmeans average accuracy : 73.36683417%, total [0.7336683417085427]\n",
      "accuracy_check 실행 시간: 7.617초\n",
      "\n",
      "\n",
      "epoch-111 loss : 0.02049403, loss_normal : 0.03436934, loss_coarse : 0.07990160, min_loss : 0.02048520, min_loss_normal : 0.03436934, min_loss_coarse : 0.07977593, wrong_element_sum : 437441.00000000, same_data : 0.00%\n",
      "ae train 실행 시간: 0.507초, 전체 시작 시간 20250320_221542_161\n",
      "\n",
      "epoch-111 accuracy check\n",
      "k_means origin feature average accuracy : 74.32617634%, total [0.7432617633622659]\n",
      "kmeans average accuracy best : 80.17%, kmeans average accuracy : 79.89949749%, total [0.7989949748743719]\n",
      "accuracy_check 실행 시간: 7.653초\n",
      "\n",
      "\n",
      "epoch-112 loss : 0.02048190, loss_normal : 0.03439850, loss_coarse : 0.08003581, min_loss : 0.02048190, min_loss_normal : 0.03436934, min_loss_coarse : 0.07977593, wrong_element_sum : 437815.00000000, same_data : 0.00%\n",
      "ae train 실행 시간: 0.535초, 전체 시작 시간 20250320_221542_161\n",
      "\n",
      "epoch-112 accuracy check\n",
      "k_means origin feature average accuracy : 73.77798081%, total [0.737779808131567]\n",
      "kmeans average accuracy best : 80.17%, kmeans average accuracy : 78.39195980%, total [0.7839195979899497]\n",
      "accuracy_check 실행 시간: 7.672초\n",
      "\n",
      "\n",
      "epoch-113 loss : 0.02069249, loss_normal : 0.03441276, loss_coarse : 0.08064516, min_loss : 0.02048190, min_loss_normal : 0.03436934, min_loss_coarse : 0.07977593, wrong_element_sum : 441430.00000000, same_data : 0.00%\n",
      "ae train 실행 시간: 0.480초, 전체 시작 시간 20250320_221542_161\n",
      "\n",
      "epoch-113 accuracy check\n",
      "k_means origin feature average accuracy : 73.54956601%, total [0.7354956601187757]\n",
      "kmeans average accuracy best : 80.17%, kmeans average accuracy : 75.60529922%, total [0.7560529922338968]\n",
      "accuracy_check 실행 시간: 7.804초\n",
      "\n",
      "\n",
      "epoch-114 loss : 0.02059814, loss_normal : 0.03441460, loss_coarse : 0.08027943, min_loss : 0.02048190, min_loss_normal : 0.03436934, min_loss_coarse : 0.07977593, wrong_element_sum : 439531.00000000, same_data : 0.00%\n",
      "ae train 실행 시간: 0.521초, 전체 시작 시간 20250320_221542_161\n",
      "\n",
      "epoch-114 accuracy check\n",
      "k_means origin feature average accuracy : 74.05207857%, total [0.7405207857469164]\n",
      "kmeans average accuracy best : 80.17%, kmeans average accuracy : 79.53403381%, total [0.7953403380539059]\n",
      "accuracy_check 실행 시간: 7.841초\n",
      "\n",
      "\n",
      "epoch-115 loss : 0.02038638, loss_normal : 0.03434685, loss_coarse : 0.07962526, min_loss : 0.02038638, min_loss_normal : 0.03434685, min_loss_coarse : 0.07962526, wrong_element_sum : 435521.00000000, same_data : 0.00%\n",
      "ae train 실행 시간: 0.517초, 전체 시작 시간 20250320_221542_161\n",
      "\n",
      "epoch-115 accuracy check\n",
      "k_means origin feature average accuracy : 74.82868890%, total [0.7482868889904066]\n",
      "kmeans average accuracy best : 80.17%, kmeans average accuracy : 75.23983554%, total [0.7523983554134308]\n",
      "accuracy_check 실행 시간: 7.817초\n",
      "\n",
      "\n",
      "epoch-116 loss : 0.02045044, loss_normal : 0.03435727, loss_coarse : 0.07984579, min_loss : 0.02038638, min_loss_normal : 0.03434685, min_loss_coarse : 0.07962526, wrong_element_sum : 436959.00000000, same_data : 0.00%\n",
      "ae train 실행 시간: 0.503초, 전체 시작 시간 20250320_221542_161\n",
      "\n",
      "epoch-116 accuracy check\n",
      "k_means origin feature average accuracy : 74.18912746%, total [0.7418912745545911]\n",
      "kmeans average accuracy best : 80.17%, kmeans average accuracy : 71.58519872%, total [0.7158519872087711]\n",
      "accuracy_check 실행 시간: 7.936초\n",
      "\n",
      "\n",
      "epoch-117 loss : 0.02032049, loss_normal : 0.03431509, loss_coarse : 0.07943686, min_loss : 0.02032049, min_loss_normal : 0.03431509, min_loss_coarse : 0.07943686, wrong_element_sum : 434462.00000000, same_data : 0.00%\n",
      "ae train 실행 시간: 0.506초, 전체 시작 시간 20250320_221542_161\n",
      "\n",
      "epoch-117 accuracy check\n",
      "k_means origin feature average accuracy : 73.27546825%, total [0.7327546825034262]\n",
      "kmeans average accuracy best : 80.17%, kmeans average accuracy : 76.61032435%, total [0.7661032434901781]\n",
      "accuracy_check 실행 시간: 7.924초\n",
      "\n",
      "\n",
      "epoch-118 loss : 0.02039260, loss_normal : 0.03432869, loss_coarse : 0.07960253, min_loss : 0.02032049, min_loss_normal : 0.03431509, min_loss_coarse : 0.07943686, wrong_element_sum : 435340.00000000, same_data : 0.00%\n",
      "ae train 실행 시간: 0.529초, 전체 시작 시간 20250320_221542_161\n",
      "\n",
      "epoch-118 accuracy check\n",
      "k_means origin feature average accuracy : 74.28049338%, total [0.7428049337597076]\n",
      "kmeans average accuracy best : 80.17%, kmeans average accuracy : 79.94518045%, total [0.7994518044769301]\n",
      "accuracy_check 실행 시간: 7.752초\n",
      "\n",
      "\n",
      "epoch-119 loss : 0.02053292, loss_normal : 0.03436622, loss_coarse : 0.07987434, min_loss : 0.02032049, min_loss_normal : 0.03431509, min_loss_coarse : 0.07943686, wrong_element_sum : 437235.00000000, same_data : 0.00%\n",
      "ae train 실행 시간: 0.513초, 전체 시작 시간 20250320_221542_161\n",
      "\n",
      "epoch-119 accuracy check\n",
      "k_means origin feature average accuracy : 74.28049338%, total [0.7428049337597076]\n",
      "kmeans average accuracy best : 80.17%, kmeans average accuracy : 62.90543627%, total [0.6290543627227044]\n",
      "accuracy_check 실행 시간: 7.768초\n",
      "\n",
      "\n",
      "epoch-120 loss : 0.02049516, loss_normal : 0.03436035, loss_coarse : 0.07986644, min_loss : 0.02032049, min_loss_normal : 0.03431509, min_loss_coarse : 0.07943686, wrong_element_sum : 436883.00000000, same_data : 0.00%\n",
      "ae train 실행 시간: 0.506초, 전체 시작 시간 20250320_221542_161\n",
      "\n",
      "epoch-120 accuracy check\n",
      "k_means origin feature average accuracy : 70.62585656%, total [0.706258565555048]\n",
      "kmeans average accuracy best : 80.17%, kmeans average accuracy : 75.97076291%, total [0.7597076290543627]\n",
      "accuracy_check 실행 시간: 7.600초\n",
      "\n",
      "\n",
      "epoch-121 loss : 0.02045943, loss_normal : 0.03436307, loss_coarse : 0.08000854, min_loss : 0.02032049, min_loss_normal : 0.03431509, min_loss_coarse : 0.07943686, wrong_element_sum : 437834.00000000, same_data : 0.00%\n",
      "ae train 실행 시간: 0.518초, 전체 시작 시간 20250320_221542_161\n",
      "\n",
      "epoch-121 accuracy check\n",
      "k_means origin feature average accuracy : 74.14344450%, total [0.7414344449520329]\n",
      "kmeans average accuracy best : 80.17%, kmeans average accuracy : 74.82868890%, total [0.7482868889904066]\n",
      "accuracy_check 실행 시간: 7.711초\n",
      "\n",
      "\n",
      "epoch-122 loss : 0.02054596, loss_normal : 0.03442289, loss_coarse : 0.08048429, min_loss : 0.02032049, min_loss_normal : 0.03431509, min_loss_coarse : 0.07943686, wrong_element_sum : 440371.00000000, same_data : 0.00%\n",
      "ae train 실행 시간: 0.507초, 전체 시작 시간 20250320_221542_161\n",
      "\n",
      "epoch-122 accuracy check\n",
      "k_means origin feature average accuracy : 74.46322522%, total [0.7446322521699407]\n",
      "kmeans average accuracy best : 80.17%, kmeans average accuracy : 73.27546825%, total [0.7327546825034262]\n",
      "accuracy_check 실행 시간: 7.383초\n",
      "\n",
      "\n",
      "epoch-123 loss : 0.02031236, loss_normal : 0.03430467, loss_coarse : 0.07934176, min_loss : 0.02031236, min_loss_normal : 0.03430467, min_loss_coarse : 0.07934176, wrong_element_sum : 434149.00000000, same_data : 0.00%\n",
      "ae train 실행 시간: 0.517초, 전체 시작 시간 20250320_221542_161\n",
      "\n",
      "epoch-123 accuracy check\n",
      "k_means origin feature average accuracy : 74.23481042%, total [0.7423481041571494]\n",
      "kmeans average accuracy best : 80.17%, kmeans average accuracy : 62.58565555%, total [0.6258565555047967]\n",
      "accuracy_check 실행 시간: 7.470초\n",
      "\n",
      "\n",
      "epoch-124 loss : 0.02028839, loss_normal : 0.03430940, loss_coarse : 0.07947765, min_loss : 0.02028839, min_loss_normal : 0.03430467, min_loss_coarse : 0.07934176, wrong_element_sum : 434997.00000000, same_data : 0.00%\n",
      "ae train 실행 시간: 0.507초, 전체 시작 시간 20250320_221542_161\n",
      "\n",
      "epoch-124 accuracy check\n",
      "k_means origin feature average accuracy : 74.32617634%, total [0.7432617633622659]\n",
      "kmeans average accuracy best : 80.17%, kmeans average accuracy : 63.17953403%, total [0.631795340338054]\n",
      "accuracy_check 실행 시간: 7.494초\n",
      "\n",
      "\n",
      "epoch-125 loss : 0.02033453, loss_normal : 0.03429773, loss_coarse : 0.07987840, min_loss : 0.02028839, min_loss_normal : 0.03429773, min_loss_coarse : 0.07934176, wrong_element_sum : 437329.00000000, same_data : 0.00%\n",
      "ae train 실행 시간: 0.509초, 전체 시작 시간 20250320_221542_161\n",
      "\n",
      "epoch-125 accuracy check\n",
      "k_means origin feature average accuracy : 71.95066240%, total [0.719506624029237]\n",
      "kmeans average accuracy best : 80.17%, kmeans average accuracy : 79.89949749%, total [0.7989949748743719]\n",
      "accuracy_check 실행 시간: 7.374초\n",
      "\n",
      "\n",
      "epoch-126 loss : 0.02029462, loss_normal : 0.03428677, loss_coarse : 0.07944442, min_loss : 0.02028839, min_loss_normal : 0.03428677, min_loss_coarse : 0.07934176, wrong_element_sum : 435350.00000000, same_data : 0.00%\n",
      "ae train 실행 시간: 0.507초, 전체 시작 시간 20250320_221542_161\n",
      "\n",
      "epoch-126 accuracy check\n",
      "k_means origin feature average accuracy : 74.69164002%, total [0.7469164001827319]\n",
      "kmeans average accuracy best : 80.17%, kmeans average accuracy : 77.61534947%, total [0.7761534947464596]\n",
      "accuracy_check 실행 시간: 7.351초\n",
      "\n",
      "\n",
      "epoch-127 loss : 0.02033464, loss_normal : 0.03435561, loss_coarse : 0.07959447, min_loss : 0.02028839, min_loss_normal : 0.03428677, min_loss_coarse : 0.07934176, wrong_element_sum : 435142.00000000, same_data : 0.00%\n",
      "ae train 실행 시간: 0.532초, 전체 시작 시간 20250320_221542_161\n",
      "\n",
      "epoch-127 accuracy check\n",
      "k_means origin feature average accuracy : 74.05207857%, total [0.7405207857469164]\n",
      "kmeans average accuracy best : 80.17%, kmeans average accuracy : 77.70671540%, total [0.7770671539515761]\n",
      "accuracy_check 실행 시간: 7.775초\n",
      "\n",
      "\n",
      "epoch-128 loss : 0.02028413, loss_normal : 0.03424581, loss_coarse : 0.07932448, min_loss : 0.02028413, min_loss_normal : 0.03424581, min_loss_coarse : 0.07932448, wrong_element_sum : 434172.00000000, same_data : 0.00%\n",
      "ae train 실행 시간: 0.494초, 전체 시작 시간 20250320_221542_161\n",
      "\n",
      "epoch-128 accuracy check\n",
      "k_means origin feature average accuracy : 73.73229785%, total [0.7373229785290086]\n",
      "kmeans average accuracy best : 80.17%, kmeans average accuracy : 73.45820009%, total [0.7345820009136592]\n",
      "accuracy_check 실행 시간: 7.662초\n",
      "\n",
      "\n",
      "epoch-129 loss : 0.02020152, loss_normal : 0.03423382, loss_coarse : 0.07930396, min_loss : 0.02020152, min_loss_normal : 0.03423382, min_loss_coarse : 0.07930396, wrong_element_sum : 433990.00000000, same_data : 0.00%\n",
      "ae train 실행 시간: 0.526초, 전체 시작 시간 20250320_221542_161\n",
      "\n",
      "epoch-129 accuracy check\n",
      "k_means origin feature average accuracy : 71.58519872%, total [0.7158519872087711]\n",
      "kmeans average accuracy best : 80.17%, kmeans average accuracy : 79.89949749%, total [0.7989949748743719]\n",
      "accuracy_check 실행 시간: 7.519초\n",
      "\n",
      "\n",
      "epoch-130 loss : 0.02035750, loss_normal : 0.03429570, loss_coarse : 0.07954646, min_loss : 0.02020152, min_loss_normal : 0.03423382, min_loss_coarse : 0.07930396, wrong_element_sum : 435048.00000000, same_data : 0.00%\n",
      "ae train 실행 시간: 0.490초, 전체 시작 시간 20250320_221542_161\n",
      "\n",
      "epoch-130 accuracy check\n",
      "k_means origin feature average accuracy : 73.77798081%, total [0.737779808131567]\n",
      "kmeans average accuracy best : 80.17%, kmeans average accuracy : 77.79808132%, total [0.7779808131566925]\n",
      "accuracy_check 실행 시간: 7.488초\n",
      "\n",
      "\n",
      "epoch-131 loss : 0.02028076, loss_normal : 0.03426784, loss_coarse : 0.07942767, min_loss : 0.02020152, min_loss_normal : 0.03423382, min_loss_coarse : 0.07930396, wrong_element_sum : 434727.00000000, same_data : 0.00%\n",
      "ae train 실행 시간: 0.501초, 전체 시작 시간 20250320_221542_161\n",
      "\n",
      "epoch-131 accuracy check\n",
      "k_means origin feature average accuracy : 74.32617634%, total [0.7432617633622659]\n",
      "kmeans average accuracy best : 80.17%, kmeans average accuracy : 79.30561900%, total [0.7930561900411147]\n",
      "accuracy_check 실행 시간: 7.489초\n",
      "\n",
      "\n",
      "epoch-132 loss : 0.02047353, loss_normal : 0.03436767, loss_coarse : 0.08015586, min_loss : 0.02020152, min_loss_normal : 0.03423382, min_loss_coarse : 0.07930396, wrong_element_sum : 438542.00000000, same_data : 0.00%\n",
      "ae train 실행 시간: 0.514초, 전체 시작 시간 20250320_221542_161\n",
      "\n",
      "epoch-132 accuracy check\n",
      "k_means origin feature average accuracy : 74.18912746%, total [0.7418912745545911]\n",
      "kmeans average accuracy best : 80.17%, kmeans average accuracy : 78.57469164%, total [0.7857469164001827]\n",
      "accuracy_check 실행 시간: 7.449초\n",
      "\n",
      "\n",
      "epoch-133 loss : 0.02025404, loss_normal : 0.03422955, loss_coarse : 0.07927866, min_loss : 0.02020152, min_loss_normal : 0.03422955, min_loss_coarse : 0.07927866, wrong_element_sum : 434074.00000000, same_data : 0.00%\n",
      "ae train 실행 시간: 0.532초, 전체 시작 시간 20250320_221542_161\n",
      "\n",
      "epoch-133 accuracy check\n",
      "k_means origin feature average accuracy : 74.18912746%, total [0.7418912745545911]\n",
      "save model\n",
      "kmeans average accuracy best : 80.40%, kmeans average accuracy : 80.40201005%, total [0.8040201005025126]\n",
      "accuracy_check 실행 시간: 7.796초\n",
      "\n",
      "\n",
      "epoch-134 loss : 0.02022113, loss_normal : 0.03424371, loss_coarse : 0.07916774, min_loss : 0.02020152, min_loss_normal : 0.03422955, min_loss_coarse : 0.07916774, wrong_element_sum : 433355.00000000, same_data : 0.00%\n",
      "ae train 실행 시간: 0.491초, 전체 시작 시간 20250320_221542_161\n",
      "\n",
      "epoch-134 accuracy check\n",
      "k_means origin feature average accuracy : 73.68661489%, total [0.7368661489264504]\n",
      "kmeans average accuracy best : 80.40%, kmeans average accuracy : 72.27044312%, total [0.7227044312471448]\n",
      "accuracy_check 실행 시간: 7.696초\n",
      "\n",
      "\n",
      "epoch-135 loss : 0.02015808, loss_normal : 0.03420991, loss_coarse : 0.07915525, min_loss : 0.02015808, min_loss_normal : 0.03420991, min_loss_coarse : 0.07915525, wrong_element_sum : 433384.00000000, same_data : 0.00%\n",
      "ae train 실행 시간: 0.517초, 전체 시작 시간 20250320_221542_161\n",
      "\n",
      "epoch-135 accuracy check\n",
      "k_means origin feature average accuracy : 74.50890818%, total [0.7450890817724989]\n",
      "kmeans average accuracy best : 80.40%, kmeans average accuracy : 80.17359525%, total [0.8017359524897213]\n",
      "accuracy_check 실행 시간: 7.682초\n",
      "\n",
      "\n",
      "epoch-136 loss : 0.02014282, loss_normal : 0.03420539, loss_coarse : 0.07908130, min_loss : 0.02014282, min_loss_normal : 0.03420539, min_loss_coarse : 0.07908130, wrong_element_sum : 432492.00000000, same_data : 0.00%\n",
      "ae train 실행 시간: 0.514초, 전체 시작 시간 20250320_221542_161\n",
      "\n",
      "epoch-136 accuracy check\n",
      "k_means origin feature average accuracy : 74.87437186%, total [0.7487437185929648]\n",
      "kmeans average accuracy best : 80.40%, kmeans average accuracy : 79.89949749%, total [0.7989949748743719]\n",
      "accuracy_check 실행 시간: 7.856초\n",
      "\n",
      "\n",
      "epoch-137 loss : 0.02015241, loss_normal : 0.03420904, loss_coarse : 0.07912797, min_loss : 0.02014282, min_loss_normal : 0.03420539, min_loss_coarse : 0.07908130, wrong_element_sum : 433039.00000000, same_data : 0.00%\n",
      "ae train 실행 시간: 0.509초, 전체 시작 시간 20250320_221542_161\n",
      "\n",
      "epoch-137 accuracy check\n",
      "k_means origin feature average accuracy : 74.09776153%, total [0.7409776153494746]\n",
      "kmeans average accuracy best : 80.40%, kmeans average accuracy : 63.22521699%, total [0.6322521699406122]\n",
      "accuracy_check 실행 시간: 7.558초\n",
      "\n",
      "\n",
      "epoch-138 loss : 0.02008256, loss_normal : 0.03419232, loss_coarse : 0.07904566, min_loss : 0.02008256, min_loss_normal : 0.03419232, min_loss_coarse : 0.07904566, wrong_element_sum : 432440.00000000, same_data : 0.00%\n",
      "ae train 실행 시간: 0.509초, 전체 시작 시간 20250320_221542_161\n",
      "\n",
      "epoch-138 accuracy check\n",
      "k_means origin feature average accuracy : 74.46322522%, total [0.7446322521699407]\n",
      "kmeans average accuracy best : 80.40%, kmeans average accuracy : 79.25993604%, total [0.7925993604385564]\n",
      "accuracy_check 실행 시간: 7.659초\n",
      "\n",
      "\n",
      "epoch-139 loss : 0.02013979, loss_normal : 0.03423784, loss_coarse : 0.07917405, min_loss : 0.02008256, min_loss_normal : 0.03419232, min_loss_coarse : 0.07904566, wrong_element_sum : 433080.00000000, same_data : 0.00%\n",
      "ae train 실행 시간: 0.507초, 전체 시작 시간 20250320_221542_161\n",
      "\n",
      "epoch-139 accuracy check\n",
      "k_means origin feature average accuracy : 74.41754226%, total [0.7441754225673823]\n",
      "kmeans average accuracy best : 80.40%, kmeans average accuracy : 79.67108269%, total [0.7967108268615807]\n",
      "accuracy_check 실행 시간: 8.363초\n",
      "\n",
      "\n",
      "epoch-140 loss : 0.02013929, loss_normal : 0.03422886, loss_coarse : 0.07912386, min_loss : 0.02008256, min_loss_normal : 0.03419232, min_loss_coarse : 0.07904566, wrong_element_sum : 433104.00000000, same_data : 0.00%\n",
      "ae train 실행 시간: 0.500초, 전체 시작 시간 20250320_221542_161\n",
      "\n",
      "epoch-140 accuracy check\n",
      "k_means origin feature average accuracy : 74.14344450%, total [0.7414344449520329]\n",
      "kmeans average accuracy best : 80.40%, kmeans average accuracy : 77.20420283%, total [0.7720420283234354]\n",
      "accuracy_check 실행 시간: 7.722초\n",
      "\n",
      "\n",
      "epoch-141 loss : 0.02030577, loss_normal : 0.03425094, loss_coarse : 0.07948353, min_loss : 0.02008256, min_loss_normal : 0.03419232, min_loss_coarse : 0.07904566, wrong_element_sum : 435047.00000000, same_data : 0.00%\n",
      "ae train 실행 시간: 0.403초, 전체 시작 시간 20250320_221542_161\n",
      "\n",
      "epoch-141 accuracy check\n",
      "k_means origin feature average accuracy : 74.60027410%, total [0.7460027409776153]\n",
      "kmeans average accuracy best : 80.40%, kmeans average accuracy : 79.85381453%, total [0.7985381452718137]\n",
      "accuracy_check 실행 시간: 7.719초\n",
      "\n",
      "\n",
      "epoch-142 loss : 0.02018503, loss_normal : 0.03423598, loss_coarse : 0.07910107, min_loss : 0.02008256, min_loss_normal : 0.03419232, min_loss_coarse : 0.07904566, wrong_element_sum : 432911.00000000, same_data : 0.00%\n",
      "ae train 실행 시간: 0.516초, 전체 시작 시간 20250320_221542_161\n",
      "\n",
      "epoch-142 accuracy check\n",
      "k_means origin feature average accuracy : 74.28049338%, total [0.7428049337597076]\n",
      "kmeans average accuracy best : 80.40%, kmeans average accuracy : 80.03654637%, total [0.8003654636820466]\n",
      "accuracy_check 실행 시간: 7.533초\n",
      "\n",
      "\n",
      "epoch-143 loss : 0.02019149, loss_normal : 0.03423574, loss_coarse : 0.07937190, min_loss : 0.02008256, min_loss_normal : 0.03419232, min_loss_coarse : 0.07904566, wrong_element_sum : 434482.00000000, same_data : 0.00%\n",
      "ae train 실행 시간: 0.502초, 전체 시작 시간 20250320_221542_161\n",
      "\n",
      "epoch-143 accuracy check\n",
      "k_means origin feature average accuracy : 74.05207857%, total [0.7405207857469164]\n",
      "kmeans average accuracy best : 80.40%, kmeans average accuracy : 79.85381453%, total [0.7985381452718137]\n",
      "accuracy_check 실행 시간: 7.491초\n",
      "\n",
      "\n",
      "epoch-144 loss : 0.02011669, loss_normal : 0.03419189, loss_coarse : 0.07914143, min_loss : 0.02008256, min_loss_normal : 0.03419189, min_loss_coarse : 0.07904566, wrong_element_sum : 432935.00000000, same_data : 0.00%\n",
      "ae train 실행 시간: 0.525초, 전체 시작 시간 20250320_221542_161\n",
      "\n",
      "epoch-144 accuracy check\n",
      "k_means origin feature average accuracy : 73.64093193%, total [0.7364093193238922]\n",
      "kmeans average accuracy best : 80.40%, kmeans average accuracy : 63.49931476%, total [0.6349931475559616]\n",
      "accuracy_check 실행 시간: 7.522초\n",
      "\n",
      "\n",
      "epoch-145 loss : 0.02006909, loss_normal : 0.03422307, loss_coarse : 0.07893162, min_loss : 0.02006909, min_loss_normal : 0.03419189, min_loss_coarse : 0.07893162, wrong_element_sum : 431847.00000000, same_data : 0.00%\n",
      "ae train 실행 시간: 0.503초, 전체 시작 시간 20250320_221542_161\n",
      "\n",
      "epoch-145 accuracy check\n",
      "k_means origin feature average accuracy : 74.18912746%, total [0.7418912745545911]\n",
      "kmeans average accuracy best : 80.40%, kmeans average accuracy : 80.03654637%, total [0.8003654636820466]\n",
      "accuracy_check 실행 시간: 7.601초\n",
      "\n",
      "\n",
      "epoch-146 loss : 0.02008251, loss_normal : 0.03416897, loss_coarse : 0.07904001, min_loss : 0.02006909, min_loss_normal : 0.03416897, min_loss_coarse : 0.07893162, wrong_element_sum : 432305.00000000, same_data : 0.00%\n",
      "ae train 실행 시간: 0.505초, 전체 시작 시간 20250320_221542_161\n",
      "\n",
      "epoch-146 accuracy check\n",
      "k_means origin feature average accuracy : 74.41754226%, total [0.7441754225673823]\n",
      "kmeans average accuracy best : 80.40%, kmeans average accuracy : 73.91502969%, total [0.7391502969392416]\n",
      "accuracy_check 실행 시간: 7.603초\n",
      "\n",
      "\n",
      "epoch-147 loss : 0.02007483, loss_normal : 0.03417777, loss_coarse : 0.07898544, min_loss : 0.02006909, min_loss_normal : 0.03416897, min_loss_coarse : 0.07893162, wrong_element_sum : 432584.00000000, same_data : 0.00%\n",
      "ae train 실행 시간: 0.527초, 전체 시작 시간 20250320_221542_161\n",
      "\n",
      "epoch-147 accuracy check\n",
      "k_means origin feature average accuracy : 74.50890818%, total [0.7450890817724989]\n",
      "kmeans average accuracy best : 80.40%, kmeans average accuracy : 79.53403381%, total [0.7953403380539059]\n",
      "accuracy_check 실행 시간: 7.679초\n",
      "\n",
      "\n",
      "epoch-148 loss : 0.02006871, loss_normal : 0.03418325, loss_coarse : 0.07888726, min_loss : 0.02006871, min_loss_normal : 0.03416897, min_loss_coarse : 0.07888726, wrong_element_sum : 431551.00000000, same_data : 0.00%\n",
      "ae train 실행 시간: 0.518초, 전체 시작 시간 20250320_221542_161\n",
      "\n",
      "epoch-148 accuracy check\n",
      "k_means origin feature average accuracy : 74.23481042%, total [0.7423481041571494]\n",
      "save model\n",
      "kmeans average accuracy best : 80.58%, kmeans average accuracy : 80.58474189%, total [0.8058474189127456]\n",
      "accuracy_check 실행 시간: 7.535초\n",
      "\n",
      "\n",
      "epoch-149 loss : 0.02004608, loss_normal : 0.03413464, loss_coarse : 0.07871863, min_loss : 0.02004608, min_loss_normal : 0.03413464, min_loss_coarse : 0.07871863, wrong_element_sum : 431196.00000000, same_data : 0.00%\n",
      "ae train 실행 시간: 0.509초, 전체 시작 시간 20250320_221542_161\n",
      "\n",
      "epoch-149 accuracy check\n",
      "k_means origin feature average accuracy : 74.18912746%, total [0.7418912745545911]\n",
      "kmeans average accuracy best : 80.58%, kmeans average accuracy : 80.12791229%, total [0.8012791228871631]\n",
      "accuracy_check 실행 시간: 7.654초\n",
      "\n",
      "\n",
      "epoch-150 loss : 0.02014565, loss_normal : 0.03418900, loss_coarse : 0.07906386, min_loss : 0.02004608, min_loss_normal : 0.03413464, min_loss_coarse : 0.07871863, wrong_element_sum : 432368.00000000, same_data : 0.00%\n",
      "ae train 실행 시간: 0.461초, 전체 시작 시간 20250320_221542_161\n",
      "\n",
      "epoch-150 accuracy check\n",
      "k_means origin feature average accuracy : 74.18912746%, total [0.7418912745545911]\n",
      "kmeans average accuracy best : 80.58%, kmeans average accuracy : 79.99086341%, total [0.7999086340794883]\n",
      "accuracy_check 실행 시간: 9.983초\n",
      "\n",
      "\n",
      "epoch-151 loss : 0.02000193, loss_normal : 0.03413030, loss_coarse : 0.07868130, min_loss : 0.02000193, min_loss_normal : 0.03413030, min_loss_coarse : 0.07868130, wrong_element_sum : 430683.00000000, same_data : 0.00%\n",
      "ae train 실행 시간: 0.489초, 전체 시작 시간 20250320_221542_161\n",
      "\n",
      "epoch-151 accuracy check\n",
      "k_means origin feature average accuracy : 74.09776153%, total [0.7409776153494746]\n",
      "kmeans average accuracy best : 80.58%, kmeans average accuracy : 78.89447236%, total [0.7889447236180904]\n",
      "accuracy_check 실행 시간: 7.571초\n",
      "\n",
      "\n",
      "epoch-152 loss : 0.02000087, loss_normal : 0.03413663, loss_coarse : 0.07877696, min_loss : 0.02000087, min_loss_normal : 0.03413030, min_loss_coarse : 0.07868130, wrong_element_sum : 430815.00000000, same_data : 0.00%\n",
      "ae train 실행 시간: 0.509초, 전체 시작 시간 20250320_221542_161\n",
      "\n",
      "epoch-152 accuracy check\n",
      "k_means origin feature average accuracy : 73.82366377%, total [0.7382366377341252]\n",
      "kmeans average accuracy best : 80.58%, kmeans average accuracy : 73.68661489%, total [0.7368661489264504]\n",
      "accuracy_check 실행 시간: 7.624초\n",
      "\n",
      "\n",
      "epoch-153 loss : 0.01999240, loss_normal : 0.03415705, loss_coarse : 0.07868946, min_loss : 0.01999240, min_loss_normal : 0.03413030, min_loss_coarse : 0.07868130, wrong_element_sum : 430408.00000000, same_data : 0.00%\n",
      "ae train 실행 시간: 0.538초, 전체 시작 시간 20250320_221542_161\n",
      "\n",
      "epoch-153 accuracy check\n",
      "k_means origin feature average accuracy : 74.18912746%, total [0.7418912745545911]\n",
      "kmeans average accuracy best : 80.58%, kmeans average accuracy : 65.41799909%, total [0.654179990863408]\n",
      "accuracy_check 실행 시간: 7.600초\n",
      "\n",
      "\n",
      "epoch-154 loss : 0.02013558, loss_normal : 0.03417556, loss_coarse : 0.07922370, min_loss : 0.01999240, min_loss_normal : 0.03413030, min_loss_coarse : 0.07868130, wrong_element_sum : 433433.00000000, same_data : 0.00%\n",
      "ae train 실행 시간: 0.505초, 전체 시작 시간 20250320_221542_161\n",
      "\n",
      "epoch-154 accuracy check\n",
      "k_means origin feature average accuracy : 73.73229785%, total [0.7373229785290086]\n",
      "kmeans average accuracy best : 80.58%, kmeans average accuracy : 79.80813157%, total [0.7980813156692553]\n",
      "accuracy_check 실행 시간: 7.810초\n",
      "\n",
      "\n",
      "epoch-155 loss : 0.02010290, loss_normal : 0.03416952, loss_coarse : 0.07895818, min_loss : 0.01999240, min_loss_normal : 0.03413030, min_loss_coarse : 0.07868130, wrong_element_sum : 431998.00000000, same_data : 0.00%\n",
      "ae train 실행 시간: 0.519초, 전체 시작 시간 20250320_221542_161\n",
      "\n",
      "epoch-155 accuracy check\n",
      "k_means origin feature average accuracy : 73.73229785%, total [0.7373229785290086]\n",
      "kmeans average accuracy best : 80.58%, kmeans average accuracy : 73.68661489%, total [0.7368661489264504]\n",
      "accuracy_check 실행 시간: 7.596초\n",
      "\n",
      "\n",
      "epoch-156 loss : 0.02018022, loss_normal : 0.03418424, loss_coarse : 0.07915807, min_loss : 0.01999240, min_loss_normal : 0.03413030, min_loss_coarse : 0.07868130, wrong_element_sum : 433021.00000000, same_data : 0.00%\n",
      "ae train 실행 시간: 0.530초, 전체 시작 시간 20250320_221542_161\n",
      "\n",
      "epoch-156 accuracy check\n",
      "k_means origin feature average accuracy : 74.28049338%, total [0.7428049337597076]\n",
      "kmeans average accuracy best : 80.58%, kmeans average accuracy : 79.30561900%, total [0.7930561900411147]\n",
      "accuracy_check 실행 시간: 8.347초\n",
      "\n",
      "\n",
      "epoch-157 loss : 0.02004233, loss_normal : 0.03411892, loss_coarse : 0.07875435, min_loss : 0.01999240, min_loss_normal : 0.03411892, min_loss_coarse : 0.07868130, wrong_element_sum : 430962.00000000, same_data : 0.00%\n",
      "ae train 실행 시간: 0.498초, 전체 시작 시간 20250320_221542_161\n",
      "\n",
      "epoch-157 accuracy check\n",
      "k_means origin feature average accuracy : 70.16902695%, total [0.7016902695294656]\n",
      "kmeans average accuracy best : 80.58%, kmeans average accuracy : 79.67108269%, total [0.7967108268615807]\n",
      "accuracy_check 실행 시간: 7.626초\n",
      "\n",
      "\n",
      "epoch-158 loss : 0.01999229, loss_normal : 0.03411930, loss_coarse : 0.07866119, min_loss : 0.01999229, min_loss_normal : 0.03411892, min_loss_coarse : 0.07866119, wrong_element_sum : 430781.00000000, same_data : 0.00%\n",
      "ae train 실행 시간: 0.514초, 전체 시작 시간 20250320_221542_161\n",
      "\n",
      "epoch-158 accuracy check\n",
      "k_means origin feature average accuracy : 73.73229785%, total [0.7373229785290086]\n",
      "kmeans average accuracy best : 80.58%, kmeans average accuracy : 64.41297396%, total [0.6441297396071265]\n",
      "accuracy_check 실행 시간: 7.579초\n",
      "\n",
      "\n",
      "epoch-159 loss : 0.01995483, loss_normal : 0.03413034, loss_coarse : 0.07859307, min_loss : 0.01995483, min_loss_normal : 0.03411892, min_loss_coarse : 0.07859307, wrong_element_sum : 429892.00000000, same_data : 0.00%\n",
      "ae train 실행 시간: 0.516초, 전체 시작 시간 20250320_221542_161\n",
      "\n",
      "epoch-159 accuracy check\n",
      "k_means origin feature average accuracy : 74.28049338%, total [0.7428049337597076]\n",
      "kmeans average accuracy best : 80.58%, kmeans average accuracy : 79.30561900%, total [0.7930561900411147]\n",
      "accuracy_check 실행 시간: 7.783초\n",
      "\n",
      "\n",
      "epoch-160 loss : 0.01985892, loss_normal : 0.03408813, loss_coarse : 0.07843546, min_loss : 0.01985892, min_loss_normal : 0.03408813, min_loss_coarse : 0.07843546, wrong_element_sum : 429383.00000000, same_data : 0.00%\n",
      "ae train 실행 시간: 0.518초, 전체 시작 시간 20250320_221542_161\n",
      "\n",
      "epoch-160 accuracy check\n",
      "k_means origin feature average accuracy : 72.36180905%, total [0.7236180904522613]\n",
      "kmeans average accuracy best : 80.58%, kmeans average accuracy : 80.35632709%, total [0.8035632708999543]\n",
      "accuracy_check 실행 시간: 7.612초\n",
      "\n",
      "\n",
      "epoch-161 loss : 0.01993291, loss_normal : 0.03407898, loss_coarse : 0.07858987, min_loss : 0.01985892, min_loss_normal : 0.03407898, min_loss_coarse : 0.07843546, wrong_element_sum : 430247.00000000, same_data : 0.00%\n",
      "ae train 실행 시간: 0.500초, 전체 시작 시간 20250320_221542_161\n",
      "\n",
      "epoch-161 accuracy check\n",
      "k_means origin feature average accuracy : 72.04202832%, total [0.7204202832343536]\n",
      "kmeans average accuracy best : 80.58%, kmeans average accuracy : 76.70169027%, total [0.7670169026952947]\n",
      "accuracy_check 실행 시간: 7.671초\n",
      "\n",
      "\n",
      "epoch-162 loss : 0.01985952, loss_normal : 0.03405825, loss_coarse : 0.07838489, min_loss : 0.01985892, min_loss_normal : 0.03405825, min_loss_coarse : 0.07838489, wrong_element_sum : 429307.00000000, same_data : 0.00%\n",
      "ae train 실행 시간: 0.517초, 전체 시작 시간 20250320_221542_161\n",
      "\n",
      "epoch-162 accuracy check\n",
      "k_means origin feature average accuracy : 74.64595706%, total [0.7464595705801736]\n",
      "kmeans average accuracy best : 80.58%, kmeans average accuracy : 79.85381453%, total [0.7985381452718137]\n",
      "accuracy_check 실행 시간: 7.458초\n",
      "\n",
      "\n",
      "epoch-163 loss : 0.01982999, loss_normal : 0.03406030, loss_coarse : 0.07836558, min_loss : 0.01982999, min_loss_normal : 0.03405825, min_loss_coarse : 0.07836558, wrong_element_sum : 428588.00000000, same_data : 0.00%\n",
      "ae train 실행 시간: 0.509초, 전체 시작 시간 20250320_221542_161\n",
      "\n",
      "epoch-163 accuracy check\n",
      "k_means origin feature average accuracy : 73.64093193%, total [0.7364093193238922]\n",
      "kmeans average accuracy best : 80.58%, kmeans average accuracy : 79.80813157%, total [0.7980813156692553]\n",
      "accuracy_check 실행 시간: 7.967초\n",
      "\n",
      "\n",
      "epoch-164 loss : 0.02005722, loss_normal : 0.03417470, loss_coarse : 0.07908132, min_loss : 0.01982999, min_loss_normal : 0.03405825, min_loss_coarse : 0.07836558, wrong_element_sum : 432422.00000000, same_data : 0.00%\n",
      "ae train 실행 시간: 0.551초, 전체 시작 시간 20250320_221542_161\n",
      "\n",
      "epoch-164 accuracy check\n"
     ]
    }
   ],
   "source": [
    "\n",
    "gpu = '4'\n",
    "Conv_net = True # True False\n",
    "SAE_net = False # True False\n",
    "\n",
    "# hyperparameter\n",
    "dataset_num = 1\n",
    "spike_length = 50 # coarse_com_mode일 때는 time step이 됨.\n",
    "num_cluster = 7  # 클러스터 수 설정 # 논문엔 4개라는데 여기서는 3개로 했네\n",
    "training_cycle = 1400 #1400 2400 # 그 초기 몇개까지만 cluster update할지\n",
    "\n",
    "\n",
    "batch_size = 32\n",
    "max_epoch = 10000 # 10000 # 1\n",
    "learning_rate = 0.001\n",
    "normalize_on = True # True or False # 0부터1까지 normalize\n",
    "need_bias = False\n",
    "# first_layer_no_train = False\n",
    "lif_add_at_first = False\n",
    "my_seed = 42\n",
    "\n",
    "TIME = 50 # SAE일 때만 유효. coarse_com_mode일 때는 level_num이 됨. 즉 feature 개수.\n",
    "v_decay = 0.5 # -cor\n",
    "v_threshold = 0.25 # -cor\n",
    "v_reset = 0.0 # -cor # 10000이상 일 시 hard reset\n",
    "BPTT_on = True # +cor # True False\n",
    "\n",
    "SAE_hidden_nomean = True # True False\n",
    "\n",
    "current_time = datetime.datetime.now().strftime(\"%Y%m%d_%H%M%S\") + f\"_{str(int(datetime.datetime.now().microsecond / 1000)).zfill(3)}\"\n",
    "\n",
    "optimizer = 'Adam' #'Adam', 'SGD' # 둘다 준수함. loss 줄이는 거는 adam이 좋긴한데, cluster accuracy는 비슷함.\n",
    "\n",
    "coarse_com_mode = False # True False\n",
    "coarse_com_config = (0.999, -0.0) # (max, min) (0.999, -0.0) (1.0, -0.0) (2.0, -2.0) (3.0, -3.0)\n",
    "\n",
    "sae_l2_norm_bridge = True # True False\n",
    "sae_lif_bridge = False # True False\n",
    "\n",
    "accuracy_check_epoch_term = 1\n",
    "\n",
    "lif_add_at_last = False # True False\n",
    "\n",
    "two_channel_input = False # True False\n",
    "\n",
    "lateral_feature_num = 4\n",
    "\n",
    "lc_adc_on = False # True False\n",
    "\n",
    "converted_net_forward = False # True False\n",
    "\n",
    "pretrained_net = None\n",
    "# pretrained_net = '/home/bhkim003/github_folder/ByeonghyeonKim/my_snn/net_save/save_now_net_중요_20250110_203117_390.pth'\n",
    "# pretrained_net = '/home/bhkim003/github_folder/ByeonghyeonKim/my_snn/net_save/save_now_net_중요_20250113_134126_881_이거_94나오는거.pth'\n",
    "# pretrained_net = '/home/bhkim003/github_folder/ByeonghyeonKim/my_snn/net_save/save_now_net_20250205_184901_132.pth'\n",
    "# pretrained_net = '/home/bhkim003/github_folder/ByeonghyeonKim/my_snn/net_save/save_now_net_20250306_134219_133.pth'\n",
    "# pretrained_net = '/home/bhkim003/github_folder/ByeonghyeonKim/my_snn/net_save/save_now_net_20250304_130322_661.pth'\n",
    "\n",
    "vth_mul_on = False # True False\n",
    "batch_norm_on = False # True False\n",
    "\n",
    "l2_norm_loss_weight = 0 #0.0001 #0.1 #  0 # 0초과면 작동\n",
    "\n",
    "QCFS_neuron_on = False # True False\n",
    "\n",
    "quantize_level_num = 50 # 0이면 quantize 안함. 1이상이면 그 수만큼 quantize함. # normalize_on 켜져야됨. 음수면 0~1norm안하고 quant함\n",
    "\n",
    "fusion_net = False # True False # SAE_net False, Conv_net True로 해라. TIME 적절하게 설정해주고.\n",
    "repeat_coding = False # True False #fusion_net에서 쓰이는 거임 # True면 repeat, False면 rate coding.\n",
    "\n",
    "sae_relu_on = False # True False\n",
    "\n",
    "conv1d_scaling = False # True False # conv1d때매 norm하고 (level_num-3)/level_num 곱해줌 # Conv_net and coarse_com_mode and normalize_on\n",
    "\n",
    "norm01 = True # True False # normalize_on = True일 때 01norm하는지 아님 걍 quant만 하는지.\n",
    "\n",
    "chan_loss_factor = 1\n",
    "\n",
    "# multi_timestep_insert = (20,10) # (20,10) # None # (한번에 넣을 timestep,stride)\n",
    "\n",
    "wandb.init(project= f'spike_sorting just run np',save_code=False)\n",
    "\n",
    "\n",
    "cluster_train_system( \n",
    "    gpu = gpu,\n",
    "    Conv_net = Conv_net,\n",
    "    SAE_net = SAE_net,\n",
    "\n",
    "    # hyperparameter\n",
    "    dataset_num = dataset_num,\n",
    "    spike_length = spike_length,\n",
    "    num_cluster = num_cluster,  # 클러스터 수 설정 # 논문엔 4개라는데 여기서는 3개로 했네\n",
    "    training_cycle = training_cycle, # 그 초기 몇개까지만 cluster update할지\n",
    "\n",
    "\n",
    "    batch_size = batch_size,\n",
    "    max_epoch = max_epoch,\n",
    "    learning_rate = learning_rate,\n",
    "    normalize_on = normalize_on, # True or False #이거 안 씀 # 이거 별로 안 좋은 normalize같음 # 쓸 거면 다른 거 써라.\n",
    "    need_bias = need_bias,\n",
    "    # first_layer_no_train = False\n",
    "    lif_add_at_first = lif_add_at_first,\n",
    "    my_seed = my_seed,\n",
    "\n",
    "    TIME = TIME, # SAE일 때만 유효\n",
    "    v_decay = v_decay,\n",
    "    v_threshold = v_threshold,\n",
    "    v_reset = v_reset, # 10000이상 일 시 hard reset\n",
    "    BPTT_on = BPTT_on,\n",
    "\n",
    "    SAE_hidden_nomean = SAE_hidden_nomean,\n",
    "    \n",
    "    current_time = current_time,\n",
    "\n",
    "    optimizer = optimizer, #'Adam', 'SGD'\n",
    "\n",
    "    coarse_com_mode = coarse_com_mode,\n",
    "    coarse_com_config = coarse_com_config, # (max, min)\n",
    "\n",
    "    \n",
    "    sae_l2_norm_bridge = sae_l2_norm_bridge,\n",
    "    sae_lif_bridge = sae_lif_bridge,\n",
    "\n",
    "    accuracy_check_epoch_term = accuracy_check_epoch_term,\n",
    "    \n",
    "    lif_add_at_last = lif_add_at_last,\n",
    "\n",
    "    two_channel_input = two_channel_input,\n",
    "\n",
    "    lateral_feature_num = lateral_feature_num,\n",
    "\n",
    "    lc_adc_on = lc_adc_on, \n",
    "\n",
    "    converted_net_forward = converted_net_forward,\n",
    "\n",
    "    pretrained_net = pretrained_net,\n",
    "\n",
    "    vth_mul_on = vth_mul_on,\n",
    "    batch_norm_on = batch_norm_on,\n",
    "\n",
    "    l2_norm_loss_weight = l2_norm_loss_weight,\n",
    "    \n",
    "    QCFS_neuron_on = QCFS_neuron_on, # True False\n",
    "\n",
    "    quantize_level_num = quantize_level_num,\n",
    "\n",
    "    fusion_net = fusion_net, # True False\n",
    "    repeat_coding = repeat_coding,\n",
    "\n",
    "    sae_relu_on = sae_relu_on,\n",
    "\n",
    "    conv1d_scaling = conv1d_scaling,\n",
    "\n",
    "    norm01 = norm01,\n",
    "\n",
    "    chan_loss_factor = chan_loss_factor,\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Sweep code\n",
    "\n",
    "\n",
    "# from unittest import TextTestRunner\n",
    "\n",
    "\n",
    "# unique_name_hyper = 'cluster_train_system'\n",
    "# # run_name = 'spike_sorting'\n",
    "# sweep_start_time =  datetime.datetime.now().strftime(\"%Y%m%d_%H%M%S\") + f\"_{str(int(datetime.datetime.now().microsecond / 1000)).zfill(3)}\"\n",
    "# sweep_configuration = {\n",
    "#     'method': 'grid', # 'random', 'bayes', 'grid'\n",
    "#     'name': f'spike_sorting_{sweep_start_time}',\n",
    "#     'metric': {'goal': 'maximize', 'name': 'k_means_acc_best'},\n",
    "#     'parameters': \n",
    "#     {\n",
    "#         # \"gpu\": {\"values\": ['1']},  # 이건 sweep parameter아님. hyper_iter에서 직접 설정\n",
    "#         \"Conv_net\": {\"values\": [True]}, \n",
    "#         \"SAE_net\": {\"values\": [True]}, \n",
    "\n",
    "#         \"dataset_num\": {\"values\": [16]}, \n",
    "#         \"spike_length\": {\"values\": [50]},  \n",
    "#         \"num_cluster\": {\"values\": [4]}, \n",
    "#         \"training_cycle\": {\"values\": [1400]}, # [1400, 2400]\n",
    "\n",
    "#         \"batch_size\": {\"values\": [32]}, \n",
    "#         \"max_epoch\": {\"values\": [20]}, \n",
    "#         \"learning_rate\": {\"values\": [0.001, 0.0001]},\n",
    "#         \"normalize_on\": {\"values\": [True]},\n",
    "#         \"need_bias\": {\"values\": [False]}, # [True, False]\n",
    "\n",
    "#         \"lif_add_at_first\": {\"values\": [False]}, # [True, False]\n",
    "#         \"my_seed\": {\"values\": [42]}, \n",
    "\n",
    "#         \"TIME\": {\"values\": [50]}, #  [4,6,8,10]\n",
    "#         \"v_decay\": {\"values\": [0.5]}, # [0.25,0.50,0.75]\n",
    "#         \"v_threshold\": {\"values\": [0.25]}, # [0.25,0.50,0.75]\n",
    "#         \"v_reset\": {\"values\": [0.0]},  # [0.0, 10000.0]\n",
    "#         \"BPTT_on\": {\"values\": [True]},  # [True, False]\n",
    "\n",
    "#         \"SAE_hidden_nomean\": {\"values\": [True]}, # [True, False]\n",
    "\n",
    "#         # \"current_time\": {\"values\": [current_time]} #밑에서 직접설정됨.\n",
    "\n",
    "#         \"optimizer\": {\"values\": ['Adam']}, # ['Adam', 'SGD']\n",
    "\n",
    "#         \"coarse_com_mode\": {\"values\": [True]}, # [True, False]\n",
    "#         \"coarse_com_config\": {\"values\": [(0.999, -0.0)]}, # ['Adam', 'SGD']\n",
    "\n",
    "#         \"sae_l2_norm_bridge\": {\"values\": [True]}, # [True, False]\n",
    "#         \"sae_lif_bridge\": {\"values\": [False]}, # [False, True]\n",
    "        \n",
    "#         \"accuracy_check_epoch_term\": {\"values\": [1]}, \n",
    "\n",
    "#         \"lif_add_at_last\": {\"values\": [False]},# [True, False]\n",
    "\n",
    "#         \"two_channel_input\": {\"values\": [False]},# [True, False]\n",
    "\n",
    "#         \"lateral_feature_num\": {\"values\": [2, 4]},# [True, False]\n",
    "\n",
    "#         \"lc_adc_on\": {\"values\": [False]},# [True, False]\n",
    "        \n",
    "#         \"converted_net_forward\": {\"values\": [False]},# [True, False]\n",
    "\n",
    "#         \"pretrained_net\": {\"values\": [None]},# [None]\n",
    "\n",
    "#         \"vth_mul_on\": {\"values\": [False]},# [True, False]\n",
    "#         \"batch_norm_on\": {\"values\": [False]},# [True, False]\n",
    "\n",
    "#         \"l2_norm_loss_weight\": {\"values\": [0]},\n",
    "\n",
    "#         \"QCFS_neuron_on\": {\"values\": [False]},   # [True, False]\n",
    "\n",
    "#         \"quantize_level_num\": {\"values\": [0]}, \n",
    "\n",
    "#         \"fusion_net\": {\"values\": [True]}, \n",
    "#         \"repeat_coding\": {\"values\": [False]}, \n",
    "\n",
    "#         \"sae_relu_on\": {\"values\": [False]}, \n",
    "\n",
    "#         \"conv1d_scaling\": {\"values\": [False]}, \n",
    "\n",
    "#         \"norm01\": {\"values\": [True]}, \n",
    "\n",
    "#         \"chan_loss_factor\": {\"values\": [0.25,0.5,0.75,1.0,1.25,1.5,1.75,2.0,2.5,3.0,3.5]}, \n",
    "\n",
    "        \n",
    "#      }\n",
    "# }\n",
    "\n",
    "\n",
    "# def hyper_iter():\n",
    "#     ### my_snn control board ########################\n",
    "#     wandb.init(save_code = False)\n",
    "#     gpu  =  '2'\n",
    "#     Conv_net  =  wandb.config.Conv_net\n",
    "#     SAE_net  =  wandb.config.SAE_net\n",
    "\n",
    "#     dataset_num  =  wandb.config.dataset_num\n",
    "#     spike_length  =  wandb.config.spike_length\n",
    "#     num_cluster  =  wandb.config.num_cluster\n",
    "#     training_cycle  =  wandb.config.training_cycle\n",
    "\n",
    "#     batch_size  =  wandb.config.batch_size\n",
    "#     max_epoch  =  wandb.config.max_epoch\n",
    "#     learning_rate  =  wandb.config.learning_rate\n",
    "#     normalize_on  =  wandb.config.normalize_on\n",
    "#     need_bias  =  wandb.config.need_bias\n",
    "\n",
    "#     lif_add_at_first  =  wandb.config.lif_add_at_first\n",
    "#     my_seed  =  wandb.config.my_seed\n",
    "\n",
    "\n",
    "#     TIME  =  wandb.config.TIME\n",
    "#     v_decay  =  wandb.config.v_decay\n",
    "#     v_threshold  =  wandb.config.v_threshold\n",
    "#     v_reset  =  wandb.config.v_reset\n",
    "#     BPTT_on  =  wandb.config.BPTT_on\n",
    "\n",
    "#     SAE_hidden_nomean  =  wandb.config.SAE_hidden_nomean\n",
    "    \n",
    "#     current_time =  datetime.datetime.now().strftime(\"%Y%m%d_%H%M%S\") + f\"_{str(int(datetime.datetime.now().microsecond / 1000)).zfill(3)}\"\n",
    "\n",
    "#     optimizer  =  wandb.config.optimizer\n",
    "\n",
    "#     coarse_com_mode = wandb.config.coarse_com_mode\n",
    "#     coarse_com_config = wandb.config.coarse_com_config # (max, min)\n",
    "\n",
    "#     sae_l2_norm_bridge = wandb.config.sae_l2_norm_bridge\n",
    "#     sae_lif_bridge = wandb.config.sae_lif_bridge\n",
    "\n",
    "#     accuracy_check_epoch_term = wandb.config.accuracy_check_epoch_term\n",
    "\n",
    "#     lif_add_at_last = wandb.config.lif_add_at_last\n",
    "\n",
    "#     two_channel_input = wandb.config.two_channel_input\n",
    "\n",
    "#     lateral_feature_num = wandb.config.lateral_feature_num\n",
    "\n",
    "#     lc_adc_on = wandb.config.lc_adc_on\n",
    "\n",
    "#     converted_net_forward = wandb.config.converted_net_forward\n",
    "\n",
    "#     pretrained_net = wandb.config.pretrained_net\n",
    "\n",
    "#     vth_mul_on = wandb.config.vth_mul_on\n",
    "#     batch_norm_on = wandb.config.batch_norm_on\n",
    "\n",
    "#     l2_norm_loss_weight = wandb.config.l2_norm_loss_weight\n",
    "\n",
    "#     QCFS_neuron_on = wandb.config.QCFS_neuron_on\n",
    "\n",
    "#     quantize_level_num = wandb.config.quantize_level_num\n",
    "\n",
    "#     fusion_net = wandb.config.fusion_net\n",
    "#     repeat_coding = wandb.config.repeat_coding\n",
    "\n",
    "#     sae_relu_on = wandb.config.sae_relu_on\n",
    "\n",
    "#     conv1d_scaling = wandb.config.conv1d_scaling\n",
    "\n",
    "#     norm01 = wandb.config.norm01\n",
    "\n",
    "#     chan_loss_factor = wandb.config.chan_loss_factor\n",
    "\n",
    "#     cluster_train_system( \n",
    "#         gpu = gpu,\n",
    "#         Conv_net = Conv_net,\n",
    "#         SAE_net = SAE_net,\n",
    "\n",
    "#         # hyperparameter\n",
    "#         dataset_num = dataset_num,\n",
    "#         spike_length = spike_length,\n",
    "#         num_cluster = num_cluster,  # 클러스터 수 설정 # 논문엔 4개라는데 여기서는 3개로 했네\n",
    "#         training_cycle = training_cycle, # 그 초기 몇개까지만 cluster update할지\n",
    "\n",
    "\n",
    "#         batch_size = batch_size,\n",
    "#         max_epoch = max_epoch,\n",
    "#         learning_rate = learning_rate,\n",
    "#         normalize_on = normalize_on, # True or False #이거 안 씀 # 이거 별로 안 좋은 normalize같음 # 쓸 거면 다른 거 써라.\n",
    "#         need_bias = need_bias,\n",
    "#         # first_layer_no_train = False\n",
    "#         lif_add_at_first = lif_add_at_first,\n",
    "#         my_seed = my_seed,\n",
    "\n",
    "#         TIME = TIME, # SAE일 때만 유효\n",
    "#         v_decay = v_decay,\n",
    "#         v_threshold = v_threshold,\n",
    "#         v_reset = v_reset, # 10000이상 일 시 hard reset\n",
    "#         BPTT_on = BPTT_on,\n",
    "\n",
    "#         SAE_hidden_nomean = SAE_hidden_nomean,\n",
    "\n",
    "#         current_time = current_time,\n",
    "\n",
    "#         optimizer = optimizer, #'Adam', 'SGD'\n",
    "\n",
    "#         coarse_com_mode = coarse_com_mode,\n",
    "#         coarse_com_config = coarse_com_config, # (max, min)\n",
    "        \n",
    "#         sae_l2_norm_bridge = sae_l2_norm_bridge,\n",
    "#         sae_lif_bridge = sae_lif_bridge,\n",
    "\n",
    "#         accuracy_check_epoch_term = accuracy_check_epoch_term,\n",
    "\n",
    "#         lif_add_at_last = lif_add_at_last,\n",
    "        \n",
    "#         two_channel_input = two_channel_input,\n",
    "        \n",
    "#         lateral_feature_num = lateral_feature_num,\n",
    "\n",
    "#         lc_adc_on = lc_adc_on,\n",
    "\n",
    "#         converted_net_forward = converted_net_forward,\n",
    "\n",
    "#         pretrained_net = pretrained_net,\n",
    "\n",
    "#         vth_mul_on = vth_mul_on,\n",
    "#         batch_norm_on = batch_norm_on,\n",
    "\n",
    "#         l2_norm_loss_weight = l2_norm_loss_weight,\n",
    "\n",
    "#         QCFS_neuron_on = QCFS_neuron_on,\n",
    "\n",
    "#         quantize_level_num = quantize_level_num,\n",
    "\n",
    "#         fusion_net = fusion_net, \n",
    "#         repeat_coding = repeat_coding, \n",
    "\n",
    "#         sae_relu_on = sae_relu_on,\n",
    "\n",
    "#         conv1d_scaling = conv1d_scaling,\n",
    "\n",
    "#         norm01 = norm01,\n",
    "\n",
    "#         chan_loss_factor = chan_loss_factor,\n",
    "#         )\n",
    "    \n",
    "# # sweep_id = 'ygoj9jt4'\n",
    "# sweep_id = wandb.sweep(sweep=sweep_configuration, project=f'spike_sorting {unique_name_hyper} np')\n",
    "# wandb.agent(sweep_id, function=hyper_iter, count=100000, project=f'spike_sorting {unique_name_hyper}')\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wandb.finish() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import matplotlib.pyplot as plt\n",
    "# from matplotlib.ticker import MaxNLocator\n",
    "# import pickle\n",
    "# import json\n",
    "\n",
    "# # current_time = '20250102_225243_972'\n",
    "\n",
    "# with open(f\"result_save/cluster_accuracy_history_{current_time}.pkl\", \"rb\") as f:\n",
    "#     data = pickle.load(f)\n",
    "\n",
    "\n",
    "# # JSON으로 저장\n",
    "# with open(f\"result_save/cluster_accuracy_history_{current_time}.json\", 'r') as f:\n",
    "#     loaded_hyperparameters = json.load(f)\n",
    "\n",
    "# loss_history = data['loss_history']\n",
    "# mean_cluster_accuracy_during_training_cycle_all_dataset_history = data['mean_cluster_accuracy_during_training_cycle_all_dataset_history']\n",
    "# mean_cluster_accuracy_post_training_cycle_all_dataset_history = data['mean_cluster_accuracy_post_training_cycle_all_dataset_history']\n",
    "# mean_cluster_accuracy_total_all_dataset_history = data['mean_cluster_accuracy_total_all_dataset_history']\n",
    "# print(data)\n",
    "# max_acc = 0\n",
    "# for i in mean_cluster_accuracy_post_training_cycle_all_dataset_history:\n",
    "#     if i[1] > max_acc:\n",
    "#         max_acc = i[1]\n",
    "\n",
    "# # 설정 정보 제목 작성\n",
    "# title = (\n",
    "#     f\"Dataset Num: {loaded_hyperparameters['dataset_num']}, Conv {loaded_hyperparameters['Conv_net']}, SAE {loaded_hyperparameters['SAE_net']}, Current time {loaded_hyperparameters['current_time']}, Spike Length: {loaded_hyperparameters['spike_length']}, Num Cluster: {loaded_hyperparameters['num_cluster']}, \"\n",
    "#     f\"Training Cycle: {loaded_hyperparameters['training_cycle']}, Batch Size: {loaded_hyperparameters['batch_size']}, Max Epoch: {loaded_hyperparameters['max_epoch']}, \\n\"\n",
    "#     f\"Learning Rate: {loaded_hyperparameters['learning_rate']}, Input Normalize: {loaded_hyperparameters['normalize_on']}, Need Bias: {loaded_hyperparameters['need_bias']}, \"\n",
    "#     f\"LIF Add at First: {loaded_hyperparameters['lif_add_at_first']}, TIME: {loaded_hyperparameters['TIME']}, Seed: {loaded_hyperparameters['my_seed']}, Best ACC: {max_acc:.2f}%\"\n",
    "# )\n",
    "\n",
    "# # 데이터 리스트와 라벨 설정 (Loss 제외)\n",
    "# data_list = [\n",
    "#     (\"Mean Cluster Accuracy (During Training Cycle)\", mean_cluster_accuracy_during_training_cycle_all_dataset_history),\n",
    "#     (\"Mean Cluster Accuracy (Post Training Cycle)\", mean_cluster_accuracy_post_training_cycle_all_dataset_history),\n",
    "#     (\"Mean Cluster Accuracy (Total)\", mean_cluster_accuracy_total_all_dataset_history),\n",
    "# ]\n",
    "\n",
    "# # 플롯 생성\n",
    "# fig, ax1 = plt.subplots(figsize=(12, 8))\n",
    "\n",
    "# # 첫 번째 y축: Accuracy 관련 데이터\n",
    "# for label, data in data_list:\n",
    "#     epochs, values = zip(*data)  # epoch, value 분리\n",
    "#     ax1.plot(epochs, values, label=label)\n",
    "\n",
    "# ax1.set_xlabel(\"Epoch\")\n",
    "# ax1.set_ylabel(\"Clurstering Accuracy [%]\", color=\"blue\")\n",
    "# ax1.tick_params(axis=\"y\", labelcolor=\"blue\")\n",
    "# ax1.legend(loc=\"center right\")\n",
    "# ax1.grid(True)\n",
    "\n",
    "# # x축을 정수만 표시하도록 설정\n",
    "# ax1.xaxis.set_major_locator(MaxNLocator(integer=True))\n",
    "\n",
    "# # 두 번째 y축: Loss History\n",
    "# ax2 = ax1.twinx()\n",
    "# epochs, values = zip(*loss_history)\n",
    "# ax2.plot(epochs, values, label=\"AE Loss History\", color=\"red\", linestyle=\"--\")\n",
    "# ax2.set_ylabel(\"Loss\", color=\"red\")\n",
    "# ax2.tick_params(axis=\"y\", labelcolor=\"red\")\n",
    "# ax2.legend(loc=\"center left\")\n",
    "\n",
    "# # 제목 추가\n",
    "# plt.title(title, fontsize=10)\n",
    "# plt.tight_layout()\n",
    "# plt.savefig(f'net_save/{current_time}', dpi=300, bbox_inches=\"tight\")  # dpi=300은 고해상도로 저장, bbox_inches=\"tight\"는 여백 최소화\n",
    "# plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "\n",
    "def create_image_grid(image_paths, grid_size=(4, 4)):\n",
    "    \"\"\"\n",
    "    여러 개의 이미지를 4x4 그리드로 병합하여 저장하는 함수.\n",
    "\n",
    "    Parameters:\n",
    "        image_paths (list of str): 불러올 이미지 경로 리스트 (16개 필요).\n",
    "        grid_size (tuple): (rows, cols) 형태의 그리드 크기 (기본값: (4, 4)).\n",
    "        save_path (str): 저장할 파일 경로.\n",
    "\n",
    "    Returns:\n",
    "        None\n",
    "    \"\"\"\n",
    "    rows, cols = grid_size\n",
    "    assert len(image_paths) == rows * cols, f\"Need {rows * cols} images, but got {len(image_paths)}\"\n",
    "\n",
    "    # 이미지 불러오기\n",
    "    images = [Image.open(img_path) for img_path in image_paths]\n",
    "\n",
    "    # 모든 이미지 크기 맞추기 (첫 번째 이미지 기준)\n",
    "    img_width, img_height = images[0].size\n",
    "    new_image = Image.new(\"RGB\", (cols * img_width, rows * img_height))\n",
    "\n",
    "    # 이미지 붙이기\n",
    "    for i, img in enumerate(images):\n",
    "        x_offset = (i % cols) * img_width\n",
    "        y_offset = (i // cols) * img_height\n",
    "        new_image.paste(img, (x_offset, y_offset))\n",
    "\n",
    "    # 시각화\n",
    "    plt.figure(figsize=(32, 32))\n",
    "    plt.imshow(new_image)\n",
    "    plt.axis(\"off\")\n",
    "    plt.show()\n",
    "\n",
    "# 사용 예시\n",
    "    \n",
    "\n",
    "spike_tot = [\"BH_Spike_e1n005.npy\", \"BH_Spike_e1n010.npy\", \"BH_Spike_e1n015.npy\", \"BH_Spike_e1n020.npy\",\n",
    "            \"BH_Spike_e2n005.npy\", \"BH_Spike_e2n010.npy\", \"BH_Spike_e2n015.npy\", \"BH_Spike_e2n020.npy\",\n",
    "            \"BH_Spike_d1n005.npy\", \"BH_Spike_d1n010.npy\", \"BH_Spike_d1n015.npy\", \"BH_Spike_d1n020.npy\",\n",
    "            \"BH_Spike_d2n005.npy\", \"BH_Spike_d2n010.npy\", \"BH_Spike_d2n015.npy\", \"BH_Spike_d2n020.npy\"]\n",
    "image_paths = [f\"/home/bhkim003/github_folder/ByeonghyeonKim/my_snn/picture/{spike_tot[i]}.png\" for i in range(len(spike_tot))]  # 저장된 16개의 이미지\n",
    "create_image_grid(image_paths, grid_size=(4, 4))\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aedat2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
