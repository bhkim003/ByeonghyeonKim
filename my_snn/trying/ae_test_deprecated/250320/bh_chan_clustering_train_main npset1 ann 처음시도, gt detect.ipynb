{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ssp.train.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x600 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import torch   \n",
    "import torch.nn as nn \n",
    "import torch.nn.functional as F   \n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import torch.optim as optim\n",
    "from scipy import io\n",
    "import itertools\n",
    "import math\n",
    "import datetime\n",
    "import wandb\n",
    "import pickle\n",
    "import json\n",
    "import time\n",
    "import sys\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import accuracy_score\n",
    "from scipy.optimize import linear_sum_assignment\n",
    "from snntorch import spikegen\n",
    "from sklearn.manifold import TSNE\n",
    "\n",
    "\n",
    "# my module import\n",
    "from modules import *\n",
    "\n",
    "# os.environ[\"CUBLAS_WORKSPACE_CONFIG\"] = \":4096:8\"\n",
    "\n",
    "# modules 폴더에 새모듈.py 만들면\n",
    "# modules/__init__py 파일에 form .새모듈 import * 하셈\n",
    "# 그리고 새모듈.py에서 from modules.새모듈 import * 하셈"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cluster_train_system( \n",
    "    gpu = '4',\n",
    "    Conv_net = True,\n",
    "    SAE_net = True,\n",
    "\n",
    "    # hyperparameter\n",
    "    dataset_num = 16,\n",
    "    spike_length = 50,\n",
    "    num_cluster = 4,  # 클러스터 수 설정 # 논문엔 4개라는데 여기서는 3개로 했네\n",
    "    training_cycle = 2400, # 그 초기 몇개까지만 cluster update할지\n",
    "\n",
    "\n",
    "    batch_size = 32,\n",
    "    max_epoch = 7000,\n",
    "    learning_rate = 0.001,\n",
    "    normalize_on = False, # True or False #이거 안 씀 # 이거 별로 안 좋은 normalize같음 # 쓸 거면 다른 거 써라.\n",
    "    need_bias = False,\n",
    "    # first_layer_no_train = False\n",
    "    lif_add_at_first = False,\n",
    "    my_seed = 42,\n",
    "\n",
    "    TIME = 10, # SAE일 때만 유효\n",
    "    v_decay = 0.5,\n",
    "    v_threshold = 0.5,\n",
    "    v_reset = 10000.0, # 10000이상 일 시 hard reset\n",
    "    BPTT_on = True,\n",
    "\n",
    "    SAE_hidden_nomean = True,\n",
    "    current_time = '20250101_210938_786',\n",
    "\n",
    "    optimizer = 'Adam',\n",
    "    coarse_com_mode = True,\n",
    "    coarse_com_config = (2.0, -2.0), # (max, min)\n",
    "\n",
    "    sae_l2_norm_bridge = True,\n",
    "    sae_lif_bridge = False,\n",
    "\n",
    "    accuracy_check_epoch_term = 5,\n",
    "    \n",
    "    lif_add_at_last = False,\n",
    "\n",
    "    two_channel_input = False,\n",
    "\n",
    "    lateral_feature_num = 4,\n",
    "\n",
    "    lc_adc_on = False, \n",
    "\n",
    "    converted_net_forward = False,\n",
    "\n",
    "    pretrained_net = None, \n",
    "\n",
    "    vth_mul_on = False,\n",
    "    batch_norm_on = False,\n",
    "\n",
    "    l2_norm_loss_weight = 0.0,\n",
    "\n",
    "    QCFS_neuron_on = False,\n",
    "\n",
    "    quantize_level_num = 0,\n",
    "\n",
    "    fusion_net = False, # True False\n",
    "    repeat_coding = False,\n",
    "    \n",
    "    sae_relu_on = False,\n",
    "\n",
    "    conv1d_scaling = False,\n",
    "\n",
    "    norm01 = True,\n",
    "\n",
    "    chan_loss_factor = 1.0,\n",
    "    ):\n",
    "    if coarse_com_mode == True:\n",
    "        assert coarse_com_config[0] > coarse_com_config[1], 'coarse_com_config[0] > coarse_com_config[1]이어야 함'\n",
    "        assert converted_net_forward == False\n",
    "        # assert SAE_net == True, 'coarse_com_mode는 SAE_net이 True일 때만 가능'\n",
    "    if two_channel_input == True:\n",
    "        assert Conv_net and coarse_com_mode, 'two_channel_input는 Conv_net이 True일 때만 가능'\n",
    "    if lc_adc_on == True:\n",
    "        assert coarse_com_mode and SAE_net, 'lc_adc_on은 coarse_com_mode와 SAE_net이 True일 때만 가능'\n",
    "    if converted_net_forward == True:\n",
    "        assert SAE_net == False, 'converted_net_forward는 SAE_net이 False일 때만 가능'\n",
    "    if conv1d_scaling:\n",
    "        assert Conv_net and coarse_com_mode and normalize_on\n",
    "    seed_assign(my_seed)\n",
    "    ## 함수 내 모든 로컬 변수 저장 ########################################################\n",
    "    hyperparameters = locals()\n",
    "    print(hyperparameters)\n",
    "    # JSON으로 저장\n",
    "    with open(f\"result_save/cluster_accuracy_history_{current_time}.json\", 'w') as f:\n",
    "        json.dump(hyperparameters, f, indent=4)\n",
    "    ######################################################################################\n",
    "\n",
    "    \n",
    "    wandb.config.update(hyperparameters)\n",
    "    wandb.run.name = f'{current_time}_SAE_net_{SAE_net}_v_threshold_{v_threshold}'\n",
    "\n",
    "    data_path = [\"/data2/spike_sorting/neuropixels_choi/set1/20141202_all_es_merged_3125000_limit_autoencoder_data.pt\",]\n",
    "    label_path = [\"/data2/spike_sorting/neuropixels_choi/set1/20141202_all_es_merged_3125000_limit_autoencoder_label.pt\"]\n",
    "\n",
    "    AE_train_data = data_path[0] #AE_train_path_gt_detect #AE_train_path_real_detect\n",
    "\n",
    "    os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\" \n",
    "    os.environ[\"CUDA_VISIBLE_DEVICES\"]= gpu\n",
    "\n",
    "\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "\n",
    "    if coarse_com_mode == True:\n",
    "        level_num = TIME\n",
    "        TIME = spike_length\n",
    "        spike_length = level_num\n",
    "        level_interval = (coarse_com_config[0] - coarse_com_config[1]) / (level_num-1)  # max - min\n",
    "        levels = [coarse_com_config[1] + level_interval * i for i in range(level_num)]\n",
    "        levels = torch.tensor(levels).to(torch.float32).to(device)\n",
    "        levels = levels.repeat(TIME,1) \n",
    "        # print('levels', levels, levels.shape) # TIME, level_num\n",
    "\n",
    "    n_sample = spike_length\n",
    "\n",
    "    class spikedataset(Dataset):\n",
    "        def __init__(self, path, transform = None):    \n",
    "            self.transform = transform\n",
    "            self.spike = torch.load(path)\n",
    "            \n",
    "        def __getitem__(self, index):\n",
    "            spike = self.spike[index]            \n",
    "            if self.transform is not None:\n",
    "                spike = self.transform(spike)\n",
    "            return spike\n",
    "        \n",
    "        def __len__(self):\n",
    "            return len(self.spike)\n",
    "\n",
    "    train_dataset = spikedataset(AE_train_data)\n",
    "    train_loader = DataLoader(dataset = train_dataset, batch_size = batch_size, shuffle = True)\n",
    "\n",
    "    # 모델 초기화\n",
    "    if SAE_net == False: # 여기서는 l2norm, lif bridge 둘 다 true면 l2norm먼저\n",
    "        assert two_channel_input == False\n",
    "\n",
    "        if Conv_net == True:\n",
    "            # input_channels = 2 if two_channel_input else 1\n",
    "            input_channels = TIME if coarse_com_mode else 1\n",
    "            if fusion_net == True:\n",
    "                assert False, '이거 맞음? 다시 확인'\n",
    "                net = FUSION_net_conv1(input_channels=input_channels, input_length=n_sample, encoder_ch = [32, 64, 96], fc_dim = lateral_feature_num, padding = 0, stride = 2, kernel_size = 3, \n",
    "                                    synapse_fc_trace_const1=1, \n",
    "                                    synapse_fc_trace_const2=v_decay, #안씀 \n",
    "                                    TIME=TIME, v_init=0.0, v_decay=v_decay, v_threshold=v_threshold, v_reset=v_reset, \n",
    "                                    sg_width=4.0, surrogate='sigmoid', BPTT_on=BPTT_on, need_bias=need_bias, lif_add_at_first=lif_add_at_first,\n",
    "                                    sae_l2_norm_bridge = sae_l2_norm_bridge, sae_lif_bridge = sae_lif_bridge, lif_add_at_last=lif_add_at_last, repeat_coding=repeat_coding).to(device)\n",
    "            else: \n",
    "                net = Autoencoder_conv1(input_channels=input_channels, input_length=n_sample, encoder_ch = [32, 64, 96], fc_dim = lateral_feature_num, padding = 0, stride = 2, kernel_size = 3, need_bias=need_bias, l2norm_bridge=sae_l2_norm_bridge, relu_bridge=sae_lif_bridge, activation_collector_on=False,\n",
    "                                        batch_norm_on=batch_norm_on, QCFS_neuron_on=QCFS_neuron_on).to(device)\n",
    "            net = torch.nn.DataParallel(net)\n",
    "            if converted_net_forward:\n",
    "                converted_net = SAE_converted_conv1(input_channels=input_channels, input_length=n_sample, encoder_ch = [32, 64, 96], fc_dim = lateral_feature_num, padding = 0, stride = 2, kernel_size = 3, \n",
    "                                    synapse_fc_trace_const1=1, \n",
    "                                    synapse_fc_trace_const2=v_decay, #안씀 \n",
    "                                    TIME=TIME, v_init=0.0, v_decay=v_decay, v_threshold=v_threshold, v_reset=v_reset, \n",
    "                                    sg_width=4.0, surrogate='sigmoid', BPTT_on=BPTT_on, need_bias=need_bias, lif_add_at_first=lif_add_at_first,\n",
    "                                    sae_l2_norm_bridge = sae_l2_norm_bridge, sae_lif_bridge = sae_lif_bridge, lif_add_at_last=lif_add_at_last,\n",
    "                                    vth_mul_on=vth_mul_on, batch_norm_on=batch_norm_on).to(device) # lif bridge는 무조건 들어가게 해놨음.\n",
    "                converted_net = torch.nn.DataParallel(converted_net)\n",
    "                print('converted_net', converted_net)\n",
    "        else:\n",
    "            n_sample = n_sample * TIME if coarse_com_mode else n_sample\n",
    "            net = Autoencoder_only_FC(encoder_ch=[400, lateral_feature_num], decoder_ch=[400,n_sample], n_sample=n_sample, need_bias=need_bias, l2norm_bridge=sae_l2_norm_bridge, relu_bridge=sae_lif_bridge, activation_collector_on=False,\n",
    "                                    batch_norm_on=batch_norm_on, QCFS_neuron_on=QCFS_neuron_on).to(device)\n",
    "            net = torch.nn.DataParallel(net)\n",
    "            if converted_net_forward:\n",
    "                converted_net = SAE_converted_fc(encoder_ch=[400, lateral_feature_num], \n",
    "                                    decoder_ch=[400, n_sample], \n",
    "                                    in_channels=n_sample, # in_channel 이 여기선 걍 lenght.\n",
    "                                    synapse_fc_trace_const1=1,\n",
    "                                    synapse_fc_trace_const2=v_decay,  #안씀 \n",
    "                                    TIME=TIME, v_init=0.0, v_decay=v_decay, v_threshold=v_threshold, v_reset=v_reset, \n",
    "                                    sg_width=4.0, surrogate='sigmoid', BPTT_on=BPTT_on, need_bias=need_bias, lif_add_at_first=lif_add_at_first,\n",
    "                                    sae_l2_norm_bridge = sae_l2_norm_bridge, sae_lif_bridge = sae_lif_bridge, lif_add_at_last=lif_add_at_last,\n",
    "                                    vth_mul_on=vth_mul_on, batch_norm_on=batch_norm_on).to(device) # lif bridge는 무조건 들어가게 해놨음.\n",
    "                converted_net = torch.nn.DataParallel(converted_net)\n",
    "                # print('converted_net', converted_net)\n",
    "    else:\n",
    "        if Conv_net == True: \n",
    "            input_channels = 1\n",
    "            input_channels = 2 if two_channel_input else 1\n",
    "            if fusion_net == True:  \n",
    "                assert coarse_com_mode == True\n",
    "                # net = SAE_FUSION2_net_conv1(input_channels=input_channels, input_length=n_sample, encoder_ch = [32, 64, 96], fc_dim = lateral_feature_num, padding = 0, stride = 2, kernel_size = 3, \n",
    "                #                     synapse_fc_trace_const1=1, \n",
    "                #                     synapse_fc_trace_const2=v_decay, #안씀 \n",
    "                #                     TIME=TIME, v_init=0.0, v_decay=v_decay, v_threshold=v_threshold, v_reset=v_reset, \n",
    "                #                     sg_width=4.0, surrogate='sigmoid', BPTT_on=BPTT_on, need_bias=need_bias, lif_add_at_first=lif_add_at_first,\n",
    "                #                     sae_l2_norm_bridge = sae_l2_norm_bridge, sae_lif_bridge = sae_lif_bridge, lif_add_at_last=lif_add_at_last, batch_norm_on=batch_norm_on, sae_relu_on=sae_relu_on).to(device)\n",
    "                # net = SAE_FUSION3_net_conv1(input_channels=input_channels, input_length=n_sample, encoder_ch = [32, 64, 96], fc_dim = lateral_feature_num, padding = 0, stride = 2, kernel_size = 3, \n",
    "                #                     synapse_fc_trace_const1=1, \n",
    "                #                     synapse_fc_trace_const2=v_decay, #안씀 \n",
    "                #                     TIME=TIME, v_init=0.0, v_decay=v_decay, v_threshold=v_threshold, v_reset=v_reset, \n",
    "                #                     sg_width=4.0, surrogate='sigmoid', BPTT_on=BPTT_on, need_bias=need_bias, lif_add_at_first=lif_add_at_first,\n",
    "                #                     sae_l2_norm_bridge = sae_l2_norm_bridge, sae_lif_bridge = sae_lif_bridge, lif_add_at_last=lif_add_at_last, batch_norm_on=batch_norm_on, sae_relu_on=sae_relu_on).to(device)\n",
    "                # net = SAE_FUSION4_net_conv1(input_channels=input_channels, input_length=n_sample, encoder_ch = [32, 64, 96], fc_dim = lateral_feature_num, padding = 0, stride = 2, kernel_size = 3, \n",
    "                #                     synapse_fc_trace_const1=1, \n",
    "                #                     synapse_fc_trace_const2=v_decay, #안씀 \n",
    "                #                     TIME=TIME, v_init=0.0, v_decay=v_decay, v_threshold=v_threshold, v_reset=v_reset, \n",
    "                #                     sg_width=4.0, surrogate='sigmoid', BPTT_on=BPTT_on, need_bias=need_bias, lif_add_at_first=lif_add_at_first,\n",
    "                #                     sae_l2_norm_bridge = sae_l2_norm_bridge, sae_lif_bridge = sae_lif_bridge, lif_add_at_last=lif_add_at_last, batch_norm_on=batch_norm_on, sae_relu_on=sae_relu_on).to(device)\n",
    "                net = SAE_FUSION5_net_conv1(input_channels=input_channels, input_length=n_sample, encoder_ch = [32, 64, 96], fc_dim = lateral_feature_num, padding = 0, stride = 2, kernel_size = 3, \n",
    "                                    synapse_fc_trace_const1=1, \n",
    "                                    synapse_fc_trace_const2=v_decay, #안씀 \n",
    "                                    TIME=TIME, v_init=0.0, v_decay=v_decay, v_threshold=v_threshold, v_reset=v_reset, \n",
    "                                    sg_width=4.0, surrogate='sigmoid', BPTT_on=BPTT_on, need_bias=need_bias, lif_add_at_first=lif_add_at_first,\n",
    "                                    sae_l2_norm_bridge = sae_l2_norm_bridge, sae_lif_bridge = sae_lif_bridge, lif_add_at_last=lif_add_at_last, batch_norm_on=batch_norm_on, sae_relu_on=sae_relu_on).to(device)\n",
    "                # net = SAE_FUSION6_net_conv1(input_channels=input_channels, input_length=n_sample, encoder_ch = [32, 64, 96], fc_dim = lateral_feature_num, padding = 0, stride = 2, kernel_size = 3, \n",
    "                #                     synapse_fc_trace_const1=1, \n",
    "                #                     synapse_fc_trace_const2=v_decay, #안씀 \n",
    "                #                     TIME=TIME, v_init=0.0, v_decay=v_decay, v_threshold=v_threshold, v_reset=v_reset, \n",
    "                #                     sg_width=4.0, surrogate='sigmoid', BPTT_on=BPTT_on, need_bias=need_bias, lif_add_at_first=lif_add_at_first,\n",
    "                #                     sae_l2_norm_bridge = sae_l2_norm_bridge, sae_lif_bridge = sae_lif_bridge, lif_add_at_last=lif_add_at_last, batch_norm_on=batch_norm_on, sae_relu_on=sae_relu_on).to(device)\n",
    "                # net = SAE_FUSION7_net_conv1(input_channels=input_channels, input_length=n_sample, encoder_ch = [32, 64, 96], fc_dim = lateral_feature_num, padding = 0, stride = 2, kernel_size = 3, \n",
    "                #                     synapse_fc_trace_const1=1, \n",
    "                #                     synapse_fc_trace_const2=v_decay, #안씀 \n",
    "                #                     TIME=TIME, v_init=0.0, v_decay=v_decay, v_threshold=v_threshold, v_reset=v_reset, \n",
    "                #                     sg_width=4.0, surrogate='sigmoid', BPTT_on=BPTT_on, need_bias=need_bias, lif_add_at_first=lif_add_at_first,\n",
    "                #                     sae_l2_norm_bridge = sae_l2_norm_bridge, sae_lif_bridge = sae_lif_bridge, lif_add_at_last=lif_add_at_last, batch_norm_on=batch_norm_on, sae_relu_on=sae_relu_on).to(device)\n",
    "            else:\n",
    "                net = SAE_conv1(input_channels=input_channels, input_length=n_sample, encoder_ch = [32, 64, 96], fc_dim = lateral_feature_num, padding = 0, stride = 2, kernel_size = 3, \n",
    "                                    synapse_fc_trace_const1=1, \n",
    "                                    synapse_fc_trace_const2=v_decay, #안씀 \n",
    "                                    TIME=TIME, v_init=0.0, v_decay=v_decay, v_threshold=v_threshold, v_reset=v_reset, \n",
    "                                    sg_width=4.0, surrogate='sigmoid', BPTT_on=BPTT_on, need_bias=need_bias, lif_add_at_first=lif_add_at_first,\n",
    "                                    sae_l2_norm_bridge = sae_l2_norm_bridge, sae_lif_bridge = sae_lif_bridge, lif_add_at_last=lif_add_at_last, batch_norm_on=batch_norm_on, sae_relu_on=sae_relu_on).to(device)\n",
    "            # net = SAE_conv1_DR(input_channels=input_channels, input_length=n_sample, encoder_ch = [32, 64, 96], fc_dim = lateral_feature_num, padding = 0, stride = 2, kernel_size = 3, \n",
    "            #                     synapse_fc_trace_const1=1, \n",
    "            #                     synapse_fc_trace_const2=v_decay, #안씀 \n",
    "            #                     TIME=TIME, v_init=0.0, v_decay=v_decay, v_threshold=v_threshold, v_reset=v_reset, \n",
    "            #                     sg_width=4.0, surrogate='sigmoid', BPTT_on=BPTT_on, need_bias=need_bias, lif_add_at_first=lif_add_at_first,\n",
    "            #                     sae_l2_norm_bridge = sae_l2_norm_bridge, sae_lif_bridge = sae_lif_bridge, lif_add_at_last=lif_add_at_last, batch_norm_on=batch_norm_on).to(device)\n",
    "            net = torch.nn.DataParallel(net)\n",
    "        else:\n",
    "            net = SAE_fc_only(encoder_ch=[400, lateral_feature_num], \n",
    "                                decoder_ch=[400, n_sample], \n",
    "                                in_channels=n_sample, # in_channel 이 여기선 걍 lenght.\n",
    "                                synapse_fc_trace_const1=1,\n",
    "                                synapse_fc_trace_const2=v_decay,  #안씀 \n",
    "                                TIME=TIME, v_init=0.0, v_decay=v_decay, v_threshold=v_threshold, v_reset=v_reset, \n",
    "                                sg_width=4.0, surrogate='sigmoid', BPTT_on=BPTT_on, need_bias=need_bias, lif_add_at_first=lif_add_at_first,\n",
    "                                sae_l2_norm_bridge = sae_l2_norm_bridge, sae_lif_bridge = sae_lif_bridge, lif_add_at_last=lif_add_at_last, batch_norm_on=batch_norm_on, sae_relu_on=sae_relu_on).to(device)\n",
    "            net = torch.nn.DataParallel(net)\n",
    "\n",
    "    # net = torch.load('/home/bhkim003/github_folder/ByeonghyeonKim/my_snn/net_save/save_now_net_AE_re_e7000.pth')\n",
    "    # net = torch.load('/home/bhkim003/github_folder/ByeonghyeonKim/my_snn/net_save/save_now_net_20250101_210938_786.pth')\n",
    "    # load했으면 torch.nn.DataParallel 하지마\n",
    "    # net.module.load_state_dict(torch.load('/home/bhkim003/github_folder/ByeonghyeonKim/my_snn/net_save/save_now_net_annbase_20250108_210641_941.pth'))\n",
    "    if pretrained_net != None:\n",
    "        ######################## 모델이 달라서 dict로 weight만 넣고싶을 때\n",
    "        # # 저장된 가중치 로드\n",
    "        saved_state_dict = torch.load(pretrained_net)\n",
    "        current_state_dict = net.module.state_dict()\n",
    "\n",
    "        # 함수 호출로 가중치 매핑\n",
    "        updated_state_dict = map_and_load_weights(saved_state_dict, current_state_dict)\n",
    "\n",
    "        # 업데이트된 state_dict를 네트워크에 로드\n",
    "        net.module.load_state_dict(updated_state_dict)\n",
    "        ######################## 모델이 달라서 dict로 weight만 넣고싶을 때\n",
    "\n",
    "        ############## 일반적일 때\n",
    "        # net.module.load_state_dict(torch.load(pretrained_net))\n",
    "        ############## 일반적일 때\n",
    "    \n",
    "        # pre_net = Autoencoder_conv1(input_channels=input_channels, input_length=n_sample, encoder_ch = [32, 64, 96], fc_dim = lateral_feature_num, padding = 0, stride = 2, kernel_size = 3, need_bias=need_bias, l2norm_bridge=sae_l2_norm_bridge, relu_bridge=sae_lif_bridge, activation_collector_on=False,\n",
    "        #                         batch_norm_on=batch_norm_on, QCFS_neuron_on=False).to(device)\n",
    "        # pre_net = torch.nn.DataParallel(net)\n",
    "        # pre_net.module.load_state_dict(torch.load(pretrained_net))\n",
    "        # copy_weights(pre_net.module.encoder , net.module.encoder )\n",
    "        # copy_weights(pre_net.module.decoder , net.module.decoder  )\n",
    "\n",
    "        \n",
    "\n",
    "\n",
    "\n",
    "    wandb.watch(net, log=\"all\", log_freq = 10)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    if SAE_net == True:\n",
    "        assert 'SAE' in net.module.__class__.__name__\n",
    "\n",
    "\n",
    "\n",
    "    net = net.to(device)\n",
    "    print(f\"Total number of encoder parameters: {sum(p.numel() for p in net.module.encoder.parameters())}\")\n",
    "    print(net)\n",
    "    print('Device:',device)\n",
    "\n",
    "    \n",
    "    if optimizer == 'Adam':\n",
    "        optimizer = optim.Adam(net.parameters(), lr=learning_rate)\n",
    "    elif optimizer == 'SGD':\n",
    "        optimizer = optim.SGD(net.parameters(), lr = learning_rate, momentum = 0.9)\n",
    "    else:\n",
    "        assert False, 'optimizer를 잘못 입력했습니다.'\n",
    "        \n",
    "    loss_history = []\n",
    "\n",
    "\n",
    "    print(f\"\\nStart Training, current_time = {current_time}\")\n",
    "\n",
    "    if SAE_net == True:\n",
    "        assert 'SAE' in net.module.__class__.__name__\n",
    "        \n",
    "    k_means_acc_best = 0\n",
    "    min_loss = 9999999\n",
    "    min_loss_normal = 9999999\n",
    "    min_loss_coarse = 9999999\n",
    "    for epoch in range(max_epoch):\n",
    "        print()\n",
    "        l2_loss_bin= 0\n",
    "        ae_train_start_time = time.time()\n",
    "        running_loss = 0.0\n",
    "        running_loss_normal = 0.0\n",
    "        running_loss_coarse = 0.0\n",
    "        iter = 0\n",
    "        net.train()\n",
    "        # if True or max_epoch != 1:\n",
    "        wrong_element_sum = 0\n",
    "        same_data_num = 0\n",
    "        total_data_num = 0\n",
    "        if max_epoch != 1:\n",
    "            for data in train_loader:\n",
    "                optimizer.zero_grad()\n",
    "                total_data_num += len(data)\n",
    "                data = data.to(device)\n",
    "                scaling = (level_num-3)/level_num if conv1d_scaling else 1.0\n",
    "                data = zero_to_one_normalize_features(data, level_num=quantize_level_num, coarse_com_config=coarse_com_config, scaling=scaling, norm01=norm01) if normalize_on else data\n",
    "                spike_backup = data\n",
    "                spike = data\n",
    "                spike = spike.to(device) # batch, feature\n",
    "                spike_for_fusion2_net = spike\n",
    "                if coarse_com_mode == True and 'SAE' in net.module.__class__.__name__:\n",
    "                    spike = spike.unsqueeze(2).repeat(1, 1, level_num) # spike_length == level_num # (batch, time, feature)로 변환 \n",
    "                    spike = (spike > levels).to(torch.float) \n",
    "\n",
    "                    spike = (spike == 0).cumsum(dim=-1).eq(1).to(torch.float) if lc_adc_on == True else spike\n",
    "\n",
    "                    # spike: batch, time, level_num\n",
    "                    # levels: time, level_num\n",
    "                    if Conv_net == True:\n",
    "                        spike = spike.unsqueeze(-2) # batch, time, in_channel, feature or batch in_channel,feature\n",
    "                        if two_channel_input == True:\n",
    "                            spike_backup = spike_backup.to(device)\n",
    "                            spike_backup = spike_backup.unsqueeze(2).repeat(1, 1, level_num) # spike_length == level_num # (batch, time, feature)로 변환 \n",
    "                            spike_backup = (spike_backup <= levels).to(torch.float) \n",
    "                            spike_backup = (spike_backup == 1).cumsum(dim=-1).eq(1).to(torch.float) if lc_adc_on == True else spike_backup\n",
    "                            spike_backup = spike_backup.unsqueeze(-2)\n",
    "                            spike = torch.cat((spike, spike_backup), dim=-2)\n",
    "                    assert spike.shape[0] == batch_size and spike.shape[1] == TIME\n",
    "                elif 'SAE' in net.module.__class__.__name__:\n",
    "                    spike = spike.unsqueeze(-1).repeat(1, 1, TIME).permute(0,2,1) # (batch, time, feature)로 변환\n",
    "                    if Conv_net == True:\n",
    "                        spike = spike.unsqueeze(-2) # batch, time, in_channel, feature or batch in_channel,feature\n",
    "                else:\n",
    "                    if Conv_net == True:\n",
    "                        if coarse_com_mode == False:\n",
    "                            spike = spike.unsqueeze(-2) #batch in_channel,feature\n",
    "                        else:\n",
    "                            spike = spike.unsqueeze(2).repeat(1, 1, level_num) # spike_length == level_num # (batch, time, feature)로 변환 \n",
    "                            spike = (spike > levels).to(torch.float) \n",
    "\n",
    "                            spike = (spike == 0).cumsum(dim=-1).eq(1).to(torch.float) if lc_adc_on == True else spike\n",
    "\n",
    "                    else:\n",
    "                        if coarse_com_mode == False:\n",
    "                            pass\n",
    "                        else:\n",
    "                            spike = spike.unsqueeze(2).repeat(1, 1, level_num) # spike_length == level_num # (batch, time, feature)로 변환 \n",
    "                            spike = (spike > levels).to(torch.float) \n",
    "\n",
    "                            spike = (spike == 0).cumsum(dim=-1).eq(1).to(torch.float) if lc_adc_on == True else spike\n",
    "\n",
    "                            # spike: batch, time, feature\n",
    "                            spike = spike.reshape(spike.shape[0], -1)\n",
    "\n",
    "                    \n",
    "\n",
    "\n",
    "                    # if fusion_net == True:\n",
    "                    #     spike = spikegen.rate(spike, num_steps=TIME).transpose(0, 1)\n",
    "\n",
    "                # spike_class = net(spike) # batch, time, feature\n",
    "                encoded_spike = net.module.encoder(spike)\n",
    "                spike_class = net.module.decoder(encoded_spike)\n",
    "                \n",
    "                # # 각 레이어의 weight와 bias의 비트 수 출력\n",
    "                # print(\"\\n=== Encoder & Decoder Weight/Bias Bit Size ===\")\n",
    "                # for name, param in net.module.named_parameters():\n",
    "                #     bit_size = param.element_size() * 8  # 바이트 크기에 8을 곱하여 비트 수 계산\n",
    "                #     print(f\"{name}: {bit_size} bits ({param.dtype})\")\n",
    "\n",
    "\n",
    "                # print('encoded_spike', spike_class)\n",
    "\n",
    "                # for i in range (2):\n",
    "                #     plot_spike(spike[i,:,0,:].cpu().numpy())\n",
    "                #     # plot_spike(spike[i,:,1,:].cpu().numpy())\n",
    "                #     plot_origin_spike(spike_class.squeeze()[i].cpu().detach().numpy(), min_max_y_on = True)\n",
    "                # assert False\n",
    "                        \n",
    "\n",
    "                loss = 0\n",
    "                loss_normal = torch.tensor(0.0)\n",
    "                loss_coarse = torch.tensor(0.0)\n",
    "                if coarse_com_mode == True and 'SAE' in net.module.__class__.__name__:\n",
    "                    criterion = nn.MSELoss().to(device)\n",
    "                    # loss1 = nn.MSELoss()(spike_class[..., 5:25], spike[..., 5:25])\n",
    "                    # loss2 = nn.MSELoss()(spike_class[..., 0:5], spike[..., 0:5])\n",
    "                    # loss3 = nn.MSELoss()(spike_class[..., 25:spike_length], spike[..., 25:spike_length])\n",
    "                    # loss = loss1 * chan_loss_factor*2.125 + (loss2 + loss3) *(1/chan_loss_factor)/ 4 \n",
    "\n",
    "                    # loss1 = nn.MSELoss()(spike_class[..., 5:25, :], spike[..., 5:25, :])\n",
    "                    # loss2 = nn.MSELoss()(spike_class[..., 0:5, :], spike[..., 0:5, :])\n",
    "                    # loss3 = nn.MSELoss()(spike_class[..., 25:spike_length, :], spike[..., 25:spike_length, :])\n",
    "                    # loss = loss1 * chan_loss_factor*2.125 + (loss2 + loss3) *(1/chan_loss_factor)/ 4 \n",
    "                    if fusion_net:\n",
    "                        # print('1', spike.shape) # batch, time, in_channel, feature [32, 50, 1, 50]\n",
    "                        \n",
    "                        # ### coarse에서 ann loss 만들기 ######\n",
    "                        # spike = spike.squeeze()\n",
    "                        # assert two_channel_input == False\n",
    "                        # zero_mask = (spike == 0)  # 0이 있는 위치\n",
    "                        # first_zero_idx = torch.where(zero_mask, torch.arange(spike.shape[-1]).to(device), spike.shape[-1]-1).min(dim=-1).values\n",
    "                        # spike = levels[0][first_zero_idx]\n",
    "                        # # plot_origin_spike(spike[0].cpu().detach().numpy())\n",
    "                        # ### coarse에서 ann loss 만들기 ######\n",
    "\n",
    "                        ### 그냥 원래 스파이크로 ann loss 만들기 ######\n",
    "                        spike = spike_for_fusion2_net\n",
    "                        ### 그냥 원래 스파이크로 ann loss 만들기 ######\n",
    "\n",
    "                        spike = spike.squeeze()\n",
    "                        spike_class = spike_class.squeeze()\n",
    "                        \n",
    "                        ### normal loss################\n",
    "                        # loss = criterion(spike_class, spike)\n",
    "                        ### normal loss################\n",
    "                        \n",
    "                        ### chan loss################\n",
    "                        loss1 = criterion(spike_class[..., 5:25], spike[..., 5:25])\n",
    "                        loss2 = criterion(spike_class[..., 0:5], spike[..., 0:5])\n",
    "                        loss3 = criterion(spike_class[..., 25:], spike[..., 25:])\n",
    "                        loss = loss1 * chan_loss_factor*2.125 + (loss2 + loss3) *(1/chan_loss_factor)/ 4 \n",
    "                        ### chan loss################\n",
    "\n",
    "\n",
    "                        # #########################################\n",
    "                        # # 손실 함수 정의 (예: MSELoss 사용)\n",
    "                        # criterion_joke = torch.nn.MSELoss(reduction='none')  # 개별 요소별 손실을 유지\n",
    "\n",
    "                        # # 손실 계산\n",
    "                        # loss1_joke = criterion_joke(spike_class[..., 5:25], spike[..., 5:25]).mean(dim=-1)  # (batch,)\n",
    "                        # loss2_joke = criterion_joke(spike_class[..., 0:5], spike[..., 0:5]).mean(dim=-1)    # (batch,)\n",
    "                        # loss3_joke = criterion_joke(spike_class[..., 25:], spike[..., 25:]).mean(dim=-1)    # (batch,)\n",
    "\n",
    "                        # # 주어진 가중치를 적용한 최종 손실\n",
    "                        # loss_joke = loss1_joke * chan_loss_factor*2.125 + (loss2_joke + loss3_joke) *(1/chan_loss_factor)/ 4 \n",
    "\n",
    "                        # # 가장 큰 손실을 갖는 샘플의 인덱스 찾기\n",
    "                        # max_loss_idx_joke = torch.argmax(loss_joke)\n",
    "\n",
    "                        # # 해당 샘플 선택\n",
    "                        # selected_sample_class = spike_class[max_loss_idx_joke]\n",
    "                        # selected_sample_spike = spike[max_loss_idx_joke]\n",
    "\n",
    "                        # # 선택한 샘플의 손실 값 출력\n",
    "                        # print(\"Index of max loss sample:\", max_loss_idx_joke.item())\n",
    "                        # print(\"Max loss value:\", loss_joke[max_loss_idx_joke].item())\n",
    "                        # mean_loss_joke = loss_joke.mean().item()\n",
    "                        # print(\"Mean loss across the batch:\", mean_loss_joke)\n",
    "\n",
    "                        # # 선택한 샘플을 시각화\n",
    "                        # plot_origin_spike(selected_sample_class.cpu().detach().numpy())\n",
    "                        # plot_origin_spike(selected_sample_spike.cpu().detach().numpy())\n",
    "                        # #########################################\n",
    "\n",
    "                        # coarse loss ######################################################\n",
    "                        loss_normal = criterion(spike_class, spike)\n",
    "                        level_num_in_loss = spike_length\n",
    "                        level_interval = (coarse_com_config[0] - coarse_com_config[1]) / (level_num_in_loss-1)  # max - min\n",
    "                        levels = [coarse_com_config[1] + level_interval * i for i in range(level_num_in_loss)]\n",
    "                        levels = torch.tensor(levels).to(torch.float).to(device)\n",
    "                        # print('coarse leves', levels)\n",
    "                        levels = levels.repeat(spike_length,1) \n",
    "\n",
    "                        spike = spike.squeeze()\n",
    "                        spike_class = spike_class.squeeze()\n",
    "                        # plot_origin_spike(spike_class[0].cpu().detach().numpy())\n",
    "                        spike = spike.unsqueeze(2).repeat(1, 1, level_num_in_loss) \n",
    "                        spike = (spike > levels).to(torch.float) \n",
    "                        spike_class = spike_class.unsqueeze(2).repeat(1, 1, level_num_in_loss) \n",
    "                        spike_class = (spike_class > levels).to(torch.float) \n",
    "                        # spike = spike[..., 0:-3, :]\n",
    "                        # spike_class = spike_class[..., 0:-3, :]\n",
    "                        loss_coarse = criterion(spike_class, spike)\n",
    "                        wrong_element_sum += torch.sum(torch.abs(spike - spike_class)).item() \n",
    "\n",
    "                        # plot_spike(spike_class[0].cpu().detach().numpy())\n",
    "                        # assert False\n",
    "                        # coarse loss ######################################################\n",
    "                    else:\n",
    "                        spike = spike.squeeze()\n",
    "                        spike_class = spike_class.squeeze()\n",
    "                        loss = criterion(spike_class, spike)\n",
    "\n",
    "                    for iii in range(spike.shape[0]):\n",
    "                        same_data_num = same_data_num + 1 if torch.eq(spike[iii], spike_class[iii]).all() else same_data_num\n",
    "                    wrong_element_sum += torch.sum(torch.abs(spike - spike_class)).item() \n",
    "\n",
    "                    # spike = spike.squeeze()\n",
    "                    # spike_class = spike_class.squeeze()\n",
    "                    # plot_spike(spike[0].cpu().detach().numpy())\n",
    "                    # plot_spike(spike_class[0].cpu().detach().numpy())\n",
    "                    # print('손실 절대값 합',np.sum(np.abs(spike[0].cpu().detach().numpy() - spike_class[0].cpu().detach().numpy())))\n",
    "                    # # assert False\n",
    "                elif 'SAE' in net.module.__class__.__name__:\n",
    "                    criterion = nn.MSELoss().to(device)\n",
    "                    loss1 = criterion(spike_class[..., 5:25], spike[..., 5:25])\n",
    "                    loss2 = criterion(spike_class[..., 0:5], spike[..., 0:5])\n",
    "                    loss3 = criterion(spike_class[..., 25:spike_length], spike[..., 25:spike_length])\n",
    "                    # loss = loss1 * 2.125 + (loss2 + loss3)/4 # chan_loss_factor = 1\n",
    "                    loss = loss1 * chan_loss_factor*2.125 + (loss2 + loss3) *(1/chan_loss_factor)/ 4 \n",
    "                    assert spike_length > 25, 'spike_length가 25보다 작음'\n",
    "                    # wrong_element_sum += torch.sum(torch.abs(spike - spike_class)).item() \n",
    "                else:\n",
    "                    criterion = nn.MSELoss().to(device)\n",
    "                    loss1 = criterion(spike_class[..., 5:25], spike[..., 5:25])\n",
    "                    loss2 = criterion(spike_class[..., 0:5], spike[..., 0:5])\n",
    "                    loss3 = criterion(spike_class[..., 25:spike_length], spike[..., 25:spike_length])\n",
    "                    loss = loss1 * chan_loss_factor*2.125 + (loss2 + loss3) *(1/chan_loss_factor)/ 4 \n",
    "                    assert spike_length > 25, 'spike_length가 25보다 작음'\n",
    "                    # wrong_element_sum += torch.sum(torch.abs(spike - spike_class)).item() \n",
    "\n",
    "\n",
    "                    if l2_norm_loss_weight > 0:\n",
    "                        assert len(encoded_spike.shape) == 2, 'time 성분 없는 걸로'\n",
    "                        l2_loss = l2_norm_loss(encoded_spike, target_norm=1.0)  # L2Norm Loss 계산, l2 1.0되게.\n",
    "                        loss = loss + l2_loss*l2_norm_loss_weight\n",
    "                        l2_loss_bin += l2_loss.item()\n",
    "\n",
    "                    # coarse loss ######################################################\n",
    "                    loss_normal = criterion(spike_class, spike)\n",
    "                    level_num_in_loss = quantize_level_num\n",
    "                    level_interval = (coarse_com_config[0] - coarse_com_config[1]) / (level_num_in_loss-1)  # max - min\n",
    "                    levels = [coarse_com_config[1] + level_interval * i for i in range(level_num_in_loss)]\n",
    "                    levels = torch.tensor(levels).to(torch.float).to(device)\n",
    "                    levels = levels.repeat(spike_length,1) \n",
    "\n",
    "                    spike = spike.squeeze()\n",
    "                    spike_class = spike_class.squeeze()\n",
    "                    spike = spike.squeeze()\n",
    "                    spike_class = spike_class.squeeze()\n",
    "\n",
    "                    # 차원이 1이면 0차원에 크기 1인 차원 추가\n",
    "                    if spike.ndimension() == 1:\n",
    "                        spike = spike.unsqueeze(0)\n",
    "\n",
    "                    if spike_class.ndimension() == 1:\n",
    "                        spike_class = spike_class.unsqueeze(0)\n",
    "                    # plot_origin_spike(spike_class[0].cpu().detach().numpy())\n",
    "                    spike = spike.unsqueeze(2).repeat(1, 1, level_num_in_loss) \n",
    "                    spike = (spike > levels).to(torch.float) \n",
    "                    spike_class = spike_class.unsqueeze(2).repeat(1, 1, level_num_in_loss) \n",
    "                    spike_class = (spike_class > levels).to(torch.float) \n",
    "                    # spike = spike[..., 0:-3, :]\n",
    "                    # spike_class = spike_class[..., 0:-3, :]\n",
    "                    loss_coarse = criterion(spike_class, spike)\n",
    "                    wrong_element_sum += torch.sum(torch.abs(spike - spike_class)).item() \n",
    "\n",
    "                    # plot_spike(spike_class[0].cpu().detach().numpy())\n",
    "                    # assert False\n",
    "                    # coarse loss ######################################################\n",
    "\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                running_loss += loss.item()\n",
    "                running_loss_normal += loss_normal.item()\n",
    "                running_loss_coarse += loss_coarse.item()\n",
    "                # print(f'\\nepoch-{epoch}, running_loss : {running_loss:.5f}, iter percent {iter/len(train_loader)*100:.2f}%')\n",
    "                iter += 1\n",
    "        else:\n",
    "            print('\\n\\n\\n max_epoch 1이면 Train 안함!!!!!!!!!!!!!!!!!!!!!')\n",
    "        if l2_norm_loss_weight > 0:\n",
    "            print('l2_loss_bin', l2_loss_bin/len(train_loader))\n",
    "        avg_loss = running_loss / len(train_loader)\n",
    "        assert not np.isnan(avg_loss), f\"Error: avg_loss is NaN! Running loss: {running_loss}, Length of train_loader: {len(train_loader)}\"\n",
    "        loss_history.append((epoch, avg_loss))\n",
    "        min_loss = min(min_loss, avg_loss)\n",
    "        min_loss_normal = min(min_loss_normal, running_loss_normal/len(train_loader))\n",
    "        min_loss_coarse = min(min_loss_coarse, running_loss_coarse/len(train_loader))\n",
    "        print(f'\\nepoch-{epoch} loss : {avg_loss:.8f}, loss_normal : {running_loss_normal/len(train_loader):.8f}, loss_coarse : {running_loss_coarse/len(train_loader):.8f}, min_loss : {min_loss:.8f}, min_loss_normal : {min_loss_normal:.8f}, min_loss_coarse : {min_loss_coarse:.8f}, wrong_element_sum : {wrong_element_sum:.8f}, same_data : {100*same_data_num/(total_data_num+1e-12):.2f}%')\n",
    "        print(f\"ae train 실행 시간: {time.time()-ae_train_start_time:.3f}초, 전체 시작 시간 {current_time}\")\n",
    "\n",
    "        # plot_activation_distribution(net)\n",
    "\n",
    "        if SAE_net == False and converted_net_forward == True:\n",
    "            source_encoder = net.module.encoder \n",
    "            target_encoder = converted_net.module.encoder  \n",
    "            copy_weights(source_encoder, target_encoder)\n",
    "\n",
    "        k_means_acc = 0\n",
    "        converted_k_means_acc = 0\n",
    "        if(epoch % accuracy_check_epoch_term == 0 or epoch == 1 or epoch == max_epoch-1): \n",
    "            accuracy_check_start_time = time.time()\n",
    "            print(f'\\nepoch-{epoch} accuracy check')\n",
    "            k_means_bin_origin_feature = []\n",
    "            k_means_bin = []\n",
    "            converted_k_means_bin = []\n",
    "            for ds in range(dataset_num):\n",
    "                # print('\\n', spike_tot[ds])\n",
    "\n",
    "                # spike = torch.tensor(torch.load(data_path[ds]))\n",
    "                spike = torch.load(data_path[ds])\n",
    "                label = torch.load(label_path[ds])\n",
    "                unit = label[:, 0].to(torch.int)\n",
    "                ch = label[:, 1].to(torch.int)\n",
    "                start = label[:, 2].to(torch.int)\n",
    "                end = label[:, 3].to(torch.int)\n",
    "                gt = label[:, 4].to(torch.int)\n",
    "                max_slope_index = label[:, 5].to(torch.int)\n",
    "                ch_winner_determinant = label[:, 6]\n",
    "                # unit, ch, start, end, gt, max_slope_index = map(int, label[i][:6])\n",
    "                # ch_winner_determinant = label[i][6]\n",
    "\n",
    "                label = unit\n",
    "\n",
    "                scaling = (level_num-3)/level_num if conv1d_scaling else 1.0\n",
    "                spike = zero_to_one_normalize_features(spike, level_num=quantize_level_num, coarse_com_config=coarse_com_config, scaling=scaling, norm01=norm01) if normalize_on else spike\n",
    "                \n",
    "                hidden_size = lateral_feature_num*TIME if 'SAE' in net.module.__class__.__name__ and SAE_hidden_nomean == True and fusion_net == False or 'SAE_FUSION5' in net.module.__class__.__name__ else lateral_feature_num\n",
    "                hidden_size = lateral_feature_num if '_DR' in net.module.__class__.__name__  else hidden_size\n",
    "\n",
    "                encoder_batch = 128\n",
    "                spike_hidden = np.zeros((len(spike), hidden_size))\n",
    "                converted_spike_hidden = np.zeros((len(spike), hidden_size))\n",
    "                net.eval()\n",
    "                with torch.no_grad():\n",
    "                    now_index = 0\n",
    "                    while (1):\n",
    "                        now_end_index = now_index+encoder_batch if now_index+encoder_batch < len(spike) else len(spike)\n",
    "                        spike_batch = spike[now_index:now_end_index] \n",
    "                        spike_torch = spike_batch\n",
    "                        spike_torch = spike_torch.float()\n",
    "                        spike_backup = spike_torch\n",
    "                        spike_torch = spike_torch.to(device)\n",
    "                        if coarse_com_mode == True and 'SAE' in net.module.__class__.__name__:\n",
    "                            spike_torch = spike_torch.unsqueeze(2).repeat(1, 1, level_num) # spike_length == level_num # (batch, time, feature)로 변환 \n",
    "                            spike_torch = (spike_torch > levels).to(torch.float) \n",
    "                            spike_torch = (spike_torch == 0).cumsum(dim=-1).eq(1).to(torch.float) if lc_adc_on == True else spike_torch\n",
    "                            if Conv_net == True:\n",
    "                                spike_torch = spike_torch.unsqueeze(-2) # batch, time, in_channel, feature or batch in_channel,feature\n",
    "                                if two_channel_input == True:\n",
    "                                    spike_backup = spike_backup.to(device)\n",
    "                                    spike_backup = spike_backup.unsqueeze(2).repeat(1, 1, level_num) # spike_length == level_num # (batch, time, feature)로 변환 \n",
    "                                    spike_backup = (spike_backup <= levels).to(torch.float) \n",
    "                                    spike_backup = (spike_backup == 1).cumsum(dim=-1).eq(1).to(torch.float) if lc_adc_on == True else spike_backup\n",
    "                                    spike_backup = spike_backup.unsqueeze(-2)\n",
    "                                    spike_torch = torch.cat((spike_torch, spike_backup), dim=-2)\n",
    "                        elif 'SAE' in net.module.__class__.__name__:\n",
    "                            spike_torch = spike_torch.unsqueeze(1).repeat(1, TIME, 1) # (batch, time, feature)로 변환\n",
    "                            if Conv_net == True:\n",
    "                                spike_torch = spike_torch.unsqueeze(-2) # batch, time, in_channel, feature or batch in_channel,feature\n",
    "                        else:\n",
    "                            # if Conv_net == True:\n",
    "                            #     spike_torch = spike_torch.unsqueeze(-2) #batch in_channel,feature\n",
    "                            if Conv_net == True:\n",
    "                                if coarse_com_mode == False:\n",
    "                                    spike_torch = spike_torch.unsqueeze(-2) #batch in_channel,feature\n",
    "                                else:\n",
    "                                    spike_torch = spike_torch.unsqueeze(2).repeat(1, 1, level_num) # spike_length == level_num # (batch, time, feature)로 변환 \n",
    "                                    spike_torch = (spike_torch > levels).to(torch.float) \n",
    "\n",
    "                                    spike_torch = (spike_torch == 0).cumsum(dim=-1).eq(1).to(torch.float) if lc_adc_on == True else spike_torch\n",
    "\n",
    "                            else:\n",
    "                                if coarse_com_mode == False:\n",
    "                                    pass\n",
    "                                else:\n",
    "                                    spike_torch = spike_torch.unsqueeze(2).repeat(1, 1, level_num) # spike_length == level_num # (batch, time, feature)로 변환 \n",
    "                                    spike_torch = (spike_torch > levels).to(torch.float) \n",
    "\n",
    "                                    spike_torch = (spike_torch == 0).cumsum(dim=-1).eq(1).to(torch.float) if lc_adc_on == True else spike_torch\n",
    "\n",
    "                                    # spike: batch, time, feature\n",
    "                                    spike_torch = spike_torch.reshape(spike_torch.shape[0], -1)\n",
    "                            if converted_net_forward == True:\n",
    "                                spike_torch_spikegen = spikegen.rate(spike_torch, num_steps=TIME).transpose(0, 1)\n",
    "                            # if fusion_net == True:\n",
    "                            #     spike_torch = spikegen.rate(spike_torch, num_steps=TIME).transpose(0, 1)\n",
    "                        ### forward #######################################################\n",
    "                        inner_inf = net.module.encoder(spike_torch)\n",
    "                        if SAE_net == False and converted_net_forward == True:\n",
    "                            converted_inner_inf = converted_net.module.encoder(spike_torch_spikegen)\n",
    "                        ### forward #######################################################\n",
    "                            \n",
    "                        if 'SAE' in net.module.__class__.__name__:\n",
    "                            if SAE_hidden_nomean == True:\n",
    "                                inner_inf = inner_inf.reshape(spike_batch.shape[0],-1)# 펼치기\n",
    "                            else:\n",
    "                                inner_inf = inner_inf.mean(dim=1)# Time 방향으로 평균\n",
    "                            # inner_inf = F.normalize(inner_inf, p=2, dim=1)\n",
    "                        spike_hidden[now_index:now_end_index] = inner_inf.cpu().detach().numpy()\n",
    "                        if SAE_net == False and converted_net_forward == True:\n",
    "                            converted_spike_hidden[now_index:now_end_index] = converted_inner_inf.cpu().detach().numpy()\n",
    "                        now_index += encoder_batch\n",
    "                        if (now_index >= len(spike)):\n",
    "                            break\n",
    "\n",
    "                origin_kmeans_accuracy = cluster_spikes_with_accuracy_torch(features= spike, true_labels=label, n_clusters=num_cluster, init_point=None)\n",
    "                kmeans_accuracy = cluster_spikes_with_accuracy_torch(features= torch.tensor(spike_hidden).to(device), true_labels=label, n_clusters=num_cluster, init_point=None)\n",
    "                \n",
    "                \n",
    "                # plot_tsne(spike_tot[ds], kmeans_accuracy, spike_hidden, label-1, n_components=2, perplexity=30, random_state=42)\n",
    "                \n",
    "                k_means_bin_origin_feature.append(origin_kmeans_accuracy)\n",
    "                k_means_bin.append(kmeans_accuracy)\n",
    "                if SAE_net == False and converted_net_forward == True:\n",
    "                    converted_kmeans_accuracy = cluster_spikes_with_accuracy_torch(features= torch.tensor(converted_spike_hidden).to(device), true_labels=label-1, n_clusters=num_cluster, init_point=None)\n",
    "                    converted_k_means_bin.append(converted_kmeans_accuracy)\n",
    "\n",
    "            print(f'k_means origin feature average accuracy : {100*sum(k_means_bin_origin_feature)/(len(k_means_bin_origin_feature)+1e-12):.8f}%, total {k_means_bin_origin_feature}')\n",
    "\n",
    "            if SAE_net == False and converted_net_forward == True:\n",
    "                converted_k_means_acc = 100*sum(converted_k_means_bin)/len(converted_k_means_bin)\n",
    "                print(f'converted_kmeans average accuracy : {converted_k_means_acc:.8f}%, total {converted_k_means_bin}')\n",
    "            k_means_acc = 100*sum(k_means_bin)/len(k_means_bin)\n",
    "            if k_means_acc > k_means_acc_best:\n",
    "                # torch.save(net, f\"net_save/save_now_net_{current_time}.pth\")\n",
    "                torch.save(net.module.state_dict(), f\"net_save/save_now_net_{current_time}.pth\")\n",
    "                print('save model')\n",
    "            \n",
    "            k_means_acc_best = max(k_means_acc_best, k_means_acc)\n",
    "            print(f'kmeans average accuracy best : {k_means_acc_best:.2f}%, kmeans average accuracy : {k_means_acc:.8f}%, total {k_means_bin}')\n",
    "            print(f\"accuracy_check 실행 시간: {time.time()-accuracy_check_start_time:.3f}초\")\n",
    "\n",
    "        wandb.log({\"avg_loss\": avg_loss})\n",
    "        wandb.log({\"k_means_acc\": k_means_acc})\n",
    "        wandb.log({\"k_means_acc_best\": k_means_acc_best})\n",
    "        wandb.log({\"converted_k_means_acc\": converted_k_means_acc})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mbhkim003\u001b[0m (\u001b[33mbhkim003-seoul-national-university\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.19.8 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.17.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/nfs/home/bhkim003/github_folder/ByeonghyeonKim/my_snn/wandb/run-20250320_214859-oq9raniy</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/bhkim003-seoul-national-university/spike_sorting%20just%20run%20np/runs/oq9raniy' target=\"_blank\">hearty-dragon-19</a></strong> to <a href='https://wandb.ai/bhkim003-seoul-national-university/spike_sorting%20just%20run%20np' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/bhkim003-seoul-national-university/spike_sorting%20just%20run%20np' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/spike_sorting%20just%20run%20np</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/bhkim003-seoul-national-university/spike_sorting%20just%20run%20np/runs/oq9raniy' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/spike_sorting%20just%20run%20np/runs/oq9raniy</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'gpu': '5', 'Conv_net': True, 'SAE_net': False, 'dataset_num': 1, 'spike_length': 50, 'num_cluster': 7, 'training_cycle': 1400, 'batch_size': 32, 'max_epoch': 10000, 'learning_rate': 0.001, 'normalize_on': True, 'need_bias': False, 'lif_add_at_first': False, 'my_seed': 42, 'TIME': 50, 'v_decay': 0.5, 'v_threshold': 0.25, 'v_reset': 0.0, 'BPTT_on': True, 'SAE_hidden_nomean': True, 'current_time': '20250320_214857_580', 'optimizer': 'Adam', 'coarse_com_mode': False, 'sae_l2_norm_bridge': True, 'sae_lif_bridge': False, 'accuracy_check_epoch_term': 1, 'lif_add_at_last': False, 'two_channel_input': False, 'lateral_feature_num': 4, 'lc_adc_on': False, 'converted_net_forward': False, 'pretrained_net': None, 'vth_mul_on': False, 'batch_norm_on': False, 'l2_norm_loss_weight': 0, 'QCFS_neuron_on': False, 'quantize_level_num': 50, 'fusion_net': False, 'repeat_coding': False, 'sae_relu_on': False, 'conv1d_scaling': False, 'norm01': True, 'chan_loss_factor': 1, 'coarse_com_config': (0.999, -0.0)}\n",
      "ae conv lenght [50, 24, 11, 5]\n",
      "Total number of encoder parameters: 26592\n",
      "DataParallel(\n",
      "  (module): Autoencoder_conv1(\n",
      "    (activation_function): ReLU()\n",
      "    (encoder): Sequential(\n",
      "      (0): Conv1d(1, 32, kernel_size=(3,), stride=(2,), bias=False)\n",
      "      (1): ReLU()\n",
      "      (2): Conv1d(32, 64, kernel_size=(3,), stride=(2,), bias=False)\n",
      "      (3): ReLU()\n",
      "      (4): Conv1d(64, 96, kernel_size=(3,), stride=(2,), bias=False)\n",
      "      (5): ReLU()\n",
      "      (6): SSBH_DimChanger_for_fc()\n",
      "      (7): Linear(in_features=480, out_features=4, bias=False)\n",
      "      (8): SSBH_L2NormLayer()\n",
      "    )\n",
      "    (decoder): Sequential(\n",
      "      (0): Linear(in_features=4, out_features=480, bias=False)\n",
      "      (1): ReLU()\n",
      "      (2): SSBH_DimChanger_for_conv1()\n",
      "      (3): ConvTranspose1d(96, 64, kernel_size=(3,), stride=(2,), bias=False)\n",
      "      (4): ReLU()\n",
      "      (5): ConvTranspose1d(64, 32, kernel_size=(3,), stride=(2,), output_padding=(1,), bias=False)\n",
      "      (6): ReLU()\n",
      "      (7): ConvTranspose1d(32, 1, kernel_size=(3,), stride=(2,), output_padding=(1,), bias=False)\n",
      "    )\n",
      "  )\n",
      ")\n",
      "Device: cuda\n",
      "\n",
      "Start Training, current_time = 20250320_214857_580\n",
      "\n",
      "\n",
      "epoch-0 loss : 0.25093734, loss_normal : 0.14653667, loss_coarse : 0.26229631, min_loss : 0.25093734, min_loss_normal : 0.14653667, min_loss_coarse : 0.26229631, wrong_element_sum : 1269528.00000000, same_data : 0.00%\n",
      "ae train 실행 시간: 1.579초, 전체 시작 시간 20250320_214857_580\n",
      "\n",
      "epoch-0 accuracy check\n",
      "k_means origin feature average accuracy : 89.58875586%, total [0.8958875585632483]\n",
      "save model\n",
      "kmeans average accuracy best : 89.17%, kmeans average accuracy : 89.17230609%, total [0.8917230609057782]\n",
      "accuracy_check 실행 시간: 7.179초\n",
      "\n",
      "\n",
      "epoch-1 loss : 0.04018414, loss_normal : 0.04595131, loss_coarse : 0.10353565, min_loss : 0.04018414, min_loss_normal : 0.04595131, min_loss_coarse : 0.10353565, wrong_element_sum : 499240.00000000, same_data : 0.00%\n",
      "ae train 실행 시간: 0.446초, 전체 시작 시간 20250320_214857_580\n",
      "\n",
      "epoch-1 accuracy check\n",
      "k_means origin feature average accuracy : 89.58875586%, total [0.8958875585632483]\n",
      "save model\n",
      "kmeans average accuracy best : 96.15%, kmeans average accuracy : 96.14783967%, total [0.9614783966684018]\n",
      "accuracy_check 실행 시간: 7.104초\n",
      "\n",
      "\n",
      "epoch-2 loss : 0.02729608, loss_normal : 0.04254204, loss_coarse : 0.08500389, min_loss : 0.02729608, min_loss_normal : 0.04254204, min_loss_coarse : 0.08500389, wrong_element_sum : 409239.00000000, same_data : 0.00%\n",
      "ae train 실행 시간: 0.462초, 전체 시작 시간 20250320_214857_580\n",
      "\n",
      "epoch-2 accuracy check\n",
      "k_means origin feature average accuracy : 89.69286830%, total [0.8969286829776159]\n",
      "save model\n",
      "kmeans average accuracy best : 97.03%, kmeans average accuracy : 97.03279542%, total [0.9703279541905258]\n",
      "accuracy_check 실행 시간: 7.081초\n",
      "\n",
      "\n",
      "epoch-3 loss : 0.02416158, loss_normal : 0.04124204, loss_coarse : 0.07523217, min_loss : 0.02416158, min_loss_normal : 0.04124204, min_loss_coarse : 0.07523217, wrong_element_sum : 359693.00000000, same_data : 0.00%\n",
      "ae train 실행 시간: 0.468초, 전체 시작 시간 20250320_214857_580\n",
      "\n",
      "epoch-3 accuracy check\n",
      "k_means origin feature average accuracy : 89.58875586%, total [0.8958875585632483]\n",
      "kmeans average accuracy best : 97.03%, kmeans average accuracy : 90.62988027%, total [0.9062988027069234]\n",
      "accuracy_check 실행 시간: 7.017초\n",
      "\n",
      "\n",
      "epoch-4 loss : 0.02268383, loss_normal : 0.04073375, loss_coarse : 0.07080000, min_loss : 0.02268383, min_loss_normal : 0.04073375, min_loss_coarse : 0.07080000, wrong_element_sum : 338653.00000000, same_data : 0.00%\n",
      "ae train 실행 시간: 0.460초, 전체 시작 시간 20250320_214857_580\n",
      "\n",
      "epoch-4 accuracy check\n",
      "k_means origin feature average accuracy : 96.87662676%, total [0.9687662675689744]\n",
      "kmeans average accuracy best : 97.03%, kmeans average accuracy : 94.27381572%, total [0.9427381572097866]\n",
      "accuracy_check 실행 시간: 7.099초\n",
      "\n",
      "\n",
      "epoch-5 loss : 0.02208882, loss_normal : 0.04041738, loss_coarse : 0.06856086, min_loss : 0.02208882, min_loss_normal : 0.04041738, min_loss_coarse : 0.06856086, wrong_element_sum : 329462.00000000, same_data : 0.00%\n",
      "ae train 실행 시간: 0.477초, 전체 시작 시간 20250320_214857_580\n",
      "\n",
      "epoch-5 accuracy check\n",
      "k_means origin feature average accuracy : 89.74492452%, total [0.8974492451847996]\n",
      "kmeans average accuracy best : 97.03%, kmeans average accuracy : 91.41072358%, total [0.9141072358146799]\n",
      "accuracy_check 실행 시간: 8.144초\n",
      "\n",
      "\n",
      "epoch-6 loss : 0.02189273, loss_normal : 0.04051120, loss_coarse : 0.06786988, min_loss : 0.02189273, min_loss_normal : 0.04041738, min_loss_coarse : 0.06786988, wrong_element_sum : 325811.00000000, same_data : 0.00%\n",
      "ae train 실행 시간: 0.457초, 전체 시작 시간 20250320_214857_580\n",
      "\n",
      "epoch-6 accuracy check\n",
      "k_means origin feature average accuracy : 89.64081208%, total [0.8964081207704321]\n",
      "save model\n",
      "kmeans average accuracy best : 97.87%, kmeans average accuracy : 97.86569495%, total [0.9786569495054659]\n",
      "accuracy_check 실행 시간: 7.127초\n",
      "\n",
      "\n",
      "epoch-7 loss : 0.02170994, loss_normal : 0.04037387, loss_coarse : 0.06762377, min_loss : 0.02170994, min_loss_normal : 0.04037387, min_loss_coarse : 0.06762377, wrong_element_sum : 324796.00000000, same_data : 0.00%\n",
      "ae train 실행 시간: 0.472초, 전체 시작 시간 20250320_214857_580\n",
      "\n",
      "epoch-7 accuracy check\n",
      "k_means origin feature average accuracy : 96.87662676%, total [0.9687662675689744]\n",
      "kmeans average accuracy best : 97.87%, kmeans average accuracy : 97.34513274%, total [0.9734513274336283]\n",
      "accuracy_check 실행 시간: 7.081초\n",
      "\n",
      "\n",
      "epoch-8 loss : 0.02163285, loss_normal : 0.04038172, loss_coarse : 0.06720553, min_loss : 0.02163285, min_loss_normal : 0.04037387, min_loss_coarse : 0.06720553, wrong_element_sum : 322848.00000000, same_data : 0.00%\n",
      "ae train 실행 시간: 0.461초, 전체 시작 시간 20250320_214857_580\n",
      "\n",
      "epoch-8 accuracy check\n",
      "k_means origin feature average accuracy : 89.64081208%, total [0.8964081207704321]\n",
      "kmeans average accuracy best : 97.87%, kmeans average accuracy : 91.77511713%, total [0.9177511712649662]\n",
      "accuracy_check 실행 시간: 7.035초\n",
      "\n",
      "\n",
      "epoch-9 loss : 0.02141202, loss_normal : 0.04026601, loss_coarse : 0.06645901, min_loss : 0.02141202, min_loss_normal : 0.04026601, min_loss_coarse : 0.06645901, wrong_element_sum : 319484.00000000, same_data : 0.00%\n",
      "ae train 실행 시간: 0.478초, 전체 시작 시간 20250320_214857_580\n",
      "\n",
      "epoch-9 accuracy check\n",
      "k_means origin feature average accuracy : 90.99427382%, total [0.9099427381572098]\n",
      "kmeans average accuracy best : 97.87%, kmeans average accuracy : 91.87922957%, total [0.9187922956793336]\n",
      "accuracy_check 실행 시간: 7.094초\n",
      "\n",
      "\n",
      "epoch-10 loss : 0.02127628, loss_normal : 0.04011747, loss_coarse : 0.06644897, min_loss : 0.02127628, min_loss_normal : 0.04011747, min_loss_coarse : 0.06644897, wrong_element_sum : 319807.00000000, same_data : 0.00%\n",
      "ae train 실행 시간: 0.469초, 전체 시작 시간 20250320_214857_580\n",
      "\n",
      "epoch-10 accuracy check\n",
      "k_means origin feature average accuracy : 89.64081208%, total [0.8964081207704321]\n",
      "kmeans average accuracy best : 97.87%, kmeans average accuracy : 91.93128579%, total [0.9193128578865174]\n",
      "accuracy_check 실행 시간: 7.877초\n",
      "\n",
      "\n",
      "epoch-11 loss : 0.02125142, loss_normal : 0.04011462, loss_coarse : 0.06682418, min_loss : 0.02125142, min_loss_normal : 0.04011462, min_loss_coarse : 0.06644897, wrong_element_sum : 320522.00000000, same_data : 0.00%\n",
      "ae train 실행 시간: 0.500초, 전체 시작 시간 20250320_214857_580\n",
      "\n",
      "epoch-11 accuracy check\n",
      "k_means origin feature average accuracy : 89.74492452%, total [0.8974492451847996]\n",
      "kmeans average accuracy best : 97.87%, kmeans average accuracy : 97.81363873%, total [0.9781363872982821]\n",
      "accuracy_check 실행 시간: 9.384초\n",
      "\n",
      "\n",
      "epoch-12 loss : 0.02126445, loss_normal : 0.04027208, loss_coarse : 0.06636619, min_loss : 0.02125142, min_loss_normal : 0.04011462, min_loss_coarse : 0.06636619, wrong_element_sum : 318628.00000000, same_data : 0.00%\n",
      "ae train 실행 시간: 0.536초, 전체 시작 시간 20250320_214857_580\n",
      "\n",
      "epoch-12 accuracy check\n",
      "k_means origin feature average accuracy : 89.53669964%, total [0.8953669963560645]\n",
      "kmeans average accuracy best : 97.87%, kmeans average accuracy : 97.86569495%, total [0.9786569495054659]\n",
      "accuracy_check 실행 시간: 9.460초\n",
      "\n",
      "\n",
      "epoch-13 loss : 0.02115331, loss_normal : 0.04014572, loss_coarse : 0.06582090, min_loss : 0.02115331, min_loss_normal : 0.04011462, min_loss_coarse : 0.06582090, wrong_element_sum : 316711.00000000, same_data : 0.00%\n",
      "ae train 실행 시간: 0.546초, 전체 시작 시간 20250320_214857_580\n",
      "\n",
      "epoch-13 accuracy check\n",
      "k_means origin feature average accuracy : 90.99427382%, total [0.9099427381572098]\n",
      "kmeans average accuracy best : 97.87%, kmeans average accuracy : 97.65747007%, total [0.9765747006767309]\n",
      "accuracy_check 실행 시간: 9.388초\n",
      "\n",
      "\n",
      "epoch-14 loss : 0.02114385, loss_normal : 0.04019327, loss_coarse : 0.06625860, min_loss : 0.02114385, min_loss_normal : 0.04011462, min_loss_coarse : 0.06582090, wrong_element_sum : 318599.00000000, same_data : 0.00%\n",
      "ae train 실행 시간: 0.573초, 전체 시작 시간 20250320_214857_580\n",
      "\n",
      "epoch-14 accuracy check\n",
      "k_means origin feature average accuracy : 89.64081208%, total [0.8964081207704321]\n",
      "kmeans average accuracy best : 97.87%, kmeans average accuracy : 97.81363873%, total [0.9781363872982821]\n",
      "accuracy_check 실행 시간: 9.392초\n",
      "\n",
      "\n",
      "epoch-15 loss : 0.02094982, loss_normal : 0.03996305, loss_coarse : 0.06548811, min_loss : 0.02094982, min_loss_normal : 0.03996305, min_loss_coarse : 0.06548811, wrong_element_sum : 314746.00000000, same_data : 0.00%\n",
      "ae train 실행 시간: 0.529초, 전체 시작 시간 20250320_214857_580\n",
      "\n",
      "epoch-15 accuracy check\n",
      "k_means origin feature average accuracy : 89.74492452%, total [0.8974492451847996]\n",
      "save model\n",
      "kmeans average accuracy best : 98.07%, kmeans average accuracy : 98.07391983%, total [0.980739198334201]\n",
      "accuracy_check 실행 시간: 9.231초\n",
      "\n",
      "\n",
      "epoch-16 loss : 0.02106431, loss_normal : 0.04018576, loss_coarse : 0.06595738, min_loss : 0.02094982, min_loss_normal : 0.03996305, min_loss_coarse : 0.06548811, wrong_element_sum : 317129.00000000, same_data : 0.00%\n",
      "ae train 실행 시간: 0.532초, 전체 시작 시간 20250320_214857_580\n",
      "\n",
      "epoch-16 accuracy check\n",
      "k_means origin feature average accuracy : 89.64081208%, total [0.8964081207704321]\n",
      "kmeans average accuracy best : 98.07%, kmeans average accuracy : 91.72306091%, total [0.9172306090577824]\n",
      "accuracy_check 실행 시간: 9.310초\n",
      "\n",
      "\n",
      "epoch-17 loss : 0.02097188, loss_normal : 0.04002863, loss_coarse : 0.06573135, min_loss : 0.02094982, min_loss_normal : 0.03996305, min_loss_coarse : 0.06548811, wrong_element_sum : 315189.00000000, same_data : 0.00%\n",
      "ae train 실행 시간: 0.522초, 전체 시작 시간 20250320_214857_580\n",
      "\n",
      "epoch-17 accuracy check\n",
      "k_means origin feature average accuracy : 96.77251432%, total [0.967725143154607]\n",
      "kmeans average accuracy best : 98.07%, kmeans average accuracy : 97.76158251%, total [0.9776158250910983]\n",
      "accuracy_check 실행 시간: 9.304초\n",
      "\n",
      "\n",
      "epoch-18 loss : 0.02097881, loss_normal : 0.04010726, loss_coarse : 0.06581270, min_loss : 0.02094982, min_loss_normal : 0.03996305, min_loss_coarse : 0.06548811, wrong_element_sum : 316733.00000000, same_data : 0.00%\n",
      "ae train 실행 시간: 0.547초, 전체 시작 시간 20250320_214857_580\n",
      "\n",
      "epoch-18 accuracy check\n",
      "k_means origin feature average accuracy : 89.53669964%, total [0.8953669963560645]\n",
      "kmeans average accuracy best : 98.07%, kmeans average accuracy : 97.70952629%, total [0.9770952628839146]\n",
      "accuracy_check 실행 시간: 7.096초\n",
      "\n",
      "\n",
      "epoch-19 loss : 0.02085512, loss_normal : 0.03996382, loss_coarse : 0.06526721, min_loss : 0.02085512, min_loss_normal : 0.03996305, min_loss_coarse : 0.06526721, wrong_element_sum : 313730.00000000, same_data : 0.00%\n",
      "ae train 실행 시간: 0.467초, 전체 시작 시간 20250320_214857_580\n",
      "\n",
      "epoch-19 accuracy check\n",
      "k_means origin feature average accuracy : 96.98073920%, total [0.969807391983342]\n",
      "kmeans average accuracy best : 98.07%, kmeans average accuracy : 90.00520562%, total [0.9000520562207184]\n",
      "accuracy_check 실행 시간: 7.058초\n",
      "\n",
      "\n",
      "epoch-20 loss : 0.02090223, loss_normal : 0.03995886, loss_coarse : 0.06573483, min_loss : 0.02085512, min_loss_normal : 0.03995886, min_loss_coarse : 0.06526721, wrong_element_sum : 316260.00000000, same_data : 0.00%\n",
      "ae train 실행 시간: 0.463초, 전체 시작 시간 20250320_214857_580\n",
      "\n",
      "epoch-20 accuracy check\n",
      "k_means origin feature average accuracy : 96.77251432%, total [0.967725143154607]\n",
      "kmeans average accuracy best : 98.07%, kmeans average accuracy : 92.08745445%, total [0.9208745445080687]\n",
      "accuracy_check 실행 시간: 8.254초\n",
      "\n",
      "\n",
      "epoch-21 loss : 0.02087286, loss_normal : 0.04004928, loss_coarse : 0.06526947, min_loss : 0.02085512, min_loss_normal : 0.03995886, min_loss_coarse : 0.06526721, wrong_element_sum : 313741.00000000, same_data : 0.00%\n",
      "ae train 실행 시간: 0.532초, 전체 시작 시간 20250320_214857_580\n",
      "\n",
      "epoch-21 accuracy check\n",
      "k_means origin feature average accuracy : 89.64081208%, total [0.8964081207704321]\n",
      "kmeans average accuracy best : 98.07%, kmeans average accuracy : 90.05726184%, total [0.9005726184279021]\n",
      "accuracy_check 실행 시간: 7.149초\n",
      "\n",
      "\n",
      "epoch-22 loss : 0.02089119, loss_normal : 0.04009284, loss_coarse : 0.06510328, min_loss : 0.02085512, min_loss_normal : 0.03995886, min_loss_coarse : 0.06510328, wrong_element_sum : 312558.00000000, same_data : 0.00%\n",
      "ae train 실행 시간: 0.485초, 전체 시작 시간 20250320_214857_580\n",
      "\n",
      "epoch-22 accuracy check\n",
      "k_means origin feature average accuracy : 96.77251432%, total [0.967725143154607]\n",
      "kmeans average accuracy best : 98.07%, kmeans average accuracy : 97.96980739%, total [0.9796980739198334]\n",
      "accuracy_check 실행 시간: 7.052초\n",
      "\n",
      "\n",
      "epoch-23 loss : 0.02082655, loss_normal : 0.03997276, loss_coarse : 0.06548770, min_loss : 0.02082655, min_loss_normal : 0.03995886, min_loss_coarse : 0.06510328, wrong_element_sum : 313876.00000000, same_data : 0.00%\n",
      "ae train 실행 시간: 0.458초, 전체 시작 시간 20250320_214857_580\n",
      "\n",
      "epoch-23 accuracy check\n",
      "k_means origin feature average accuracy : 89.69286830%, total [0.8969286829776159]\n",
      "kmeans average accuracy best : 98.07%, kmeans average accuracy : 97.76158251%, total [0.9776158250910983]\n",
      "accuracy_check 실행 시간: 6.989초\n",
      "\n",
      "\n",
      "epoch-24 loss : 0.02084008, loss_normal : 0.03988555, loss_coarse : 0.06556455, min_loss : 0.02082655, min_loss_normal : 0.03988555, min_loss_coarse : 0.06510328, wrong_element_sum : 315491.00000000, same_data : 0.00%\n",
      "ae train 실행 시간: 0.471초, 전체 시작 시간 20250320_214857_580\n",
      "\n",
      "epoch-24 accuracy check\n",
      "k_means origin feature average accuracy : 96.87662676%, total [0.9687662675689744]\n",
      "kmeans average accuracy best : 98.07%, kmeans average accuracy : 97.55335763%, total [0.9755335762623634]\n",
      "accuracy_check 실행 시간: 7.741초\n",
      "\n",
      "\n",
      "epoch-25 loss : 0.02072866, loss_normal : 0.03986824, loss_coarse : 0.06524406, min_loss : 0.02072866, min_loss_normal : 0.03986824, min_loss_coarse : 0.06510328, wrong_element_sum : 313896.00000000, same_data : 0.00%\n",
      "ae train 실행 시간: 0.527초, 전체 시작 시간 20250320_214857_580\n",
      "\n",
      "epoch-25 accuracy check\n",
      "k_means origin feature average accuracy : 89.64081208%, total [0.8964081207704321]\n",
      "kmeans average accuracy best : 98.07%, kmeans average accuracy : 97.65747007%, total [0.9765747006767309]\n",
      "accuracy_check 실행 시간: 9.464초\n",
      "\n",
      "\n",
      "epoch-26 loss : 0.02080445, loss_normal : 0.04004823, loss_coarse : 0.06501516, min_loss : 0.02072866, min_loss_normal : 0.03986824, min_loss_coarse : 0.06501516, wrong_element_sum : 312283.00000000, same_data : 0.00%\n",
      "ae train 실행 시간: 0.556초, 전체 시작 시간 20250320_214857_580\n",
      "\n",
      "epoch-26 accuracy check\n",
      "k_means origin feature average accuracy : 96.72045809%, total [0.9672045809474232]\n",
      "kmeans average accuracy best : 98.07%, kmeans average accuracy : 97.65747007%, total [0.9765747006767309]\n",
      "accuracy_check 실행 시간: 7.917초\n",
      "\n",
      "\n",
      "epoch-27 loss : 0.02072354, loss_normal : 0.03996466, loss_coarse : 0.06474610, min_loss : 0.02072354, min_loss_normal : 0.03986824, min_loss_coarse : 0.06474610, wrong_element_sum : 311652.00000000, same_data : 0.00%\n",
      "ae train 실행 시간: 0.473초, 전체 시작 시간 20250320_214857_580\n",
      "\n",
      "epoch-27 accuracy check\n",
      "k_means origin feature average accuracy : 91.09838626%, total [0.9109838625715773]\n",
      "kmeans average accuracy best : 98.07%, kmeans average accuracy : 97.76158251%, total [0.9776158250910983]\n",
      "accuracy_check 실행 시간: 6.907초\n",
      "\n",
      "\n",
      "epoch-28 loss : 0.02072118, loss_normal : 0.03985584, loss_coarse : 0.06479979, min_loss : 0.02072118, min_loss_normal : 0.03985584, min_loss_coarse : 0.06474610, wrong_element_sum : 311294.00000000, same_data : 0.00%\n",
      "ae train 실행 시간: 0.462초, 전체 시작 시간 20250320_214857_580\n",
      "\n",
      "epoch-28 accuracy check\n",
      "k_means origin feature average accuracy : 89.64081208%, total [0.8964081207704321]\n",
      "kmeans average accuracy best : 98.07%, kmeans average accuracy : 89.95314940%, total [0.8995314940135346]\n",
      "accuracy_check 실행 시간: 6.826초\n",
      "\n",
      "\n",
      "epoch-29 loss : 0.02123932, loss_normal : 0.04009018, loss_coarse : 0.06794733, min_loss : 0.02072118, min_loss_normal : 0.03985584, min_loss_coarse : 0.06474610, wrong_element_sum : 325755.00000000, same_data : 0.00%\n",
      "ae train 실행 시간: 0.456초, 전체 시작 시간 20250320_214857_580\n",
      "\n",
      "epoch-29 accuracy check\n",
      "k_means origin feature average accuracy : 91.09838626%, total [0.9109838625715773]\n",
      "kmeans average accuracy best : 98.07%, kmeans average accuracy : 97.76158251%, total [0.9776158250910983]\n",
      "accuracy_check 실행 시간: 6.791초\n",
      "\n",
      "\n",
      "epoch-30 loss : 0.02086871, loss_normal : 0.04003272, loss_coarse : 0.06543094, min_loss : 0.02072118, min_loss_normal : 0.03985584, min_loss_coarse : 0.06474610, wrong_element_sum : 314808.00000000, same_data : 0.00%\n",
      "ae train 실행 시간: 0.475초, 전체 시작 시간 20250320_214857_580\n",
      "\n",
      "epoch-30 accuracy check\n",
      "k_means origin feature average accuracy : 89.58875586%, total [0.8958875585632483]\n",
      "kmeans average accuracy best : 98.07%, kmeans average accuracy : 97.76158251%, total [0.9776158250910983]\n",
      "accuracy_check 실행 시간: 7.093초\n",
      "\n",
      "\n",
      "epoch-31 loss : 0.02063015, loss_normal : 0.03978038, loss_coarse : 0.06461988, min_loss : 0.02063015, min_loss_normal : 0.03978038, min_loss_coarse : 0.06461988, wrong_element_sum : 310850.00000000, same_data : 0.00%\n",
      "ae train 실행 시간: 0.461초, 전체 시작 시간 20250320_214857_580\n",
      "\n",
      "epoch-31 accuracy check\n",
      "k_means origin feature average accuracy : 96.82457054%, total [0.9682457053617908]\n",
      "kmeans average accuracy best : 98.07%, kmeans average accuracy : 97.76158251%, total [0.9776158250910983]\n",
      "accuracy_check 실행 시간: 7.159초\n",
      "\n",
      "\n",
      "epoch-32 loss : 0.02130643, loss_normal : 0.04042881, loss_coarse : 0.06619549, min_loss : 0.02063015, min_loss_normal : 0.03978038, min_loss_coarse : 0.06461988, wrong_element_sum : 311068.00000000, same_data : 0.00%\n",
      "ae train 실행 시간: 0.490초, 전체 시작 시간 20250320_214857_580\n",
      "\n",
      "epoch-32 accuracy check\n",
      "k_means origin feature average accuracy : 89.58875586%, total [0.8958875585632483]\n",
      "kmeans average accuracy best : 98.07%, kmeans average accuracy : 90.00520562%, total [0.9000520562207184]\n",
      "accuracy_check 실행 시간: 7.146초\n",
      "\n",
      "\n",
      "epoch-33 loss : 0.02258834, loss_normal : 0.04050407, loss_coarse : 0.07202561, min_loss : 0.02063015, min_loss_normal : 0.03978038, min_loss_coarse : 0.06461988, wrong_element_sum : 347176.00000000, same_data : 0.00%\n",
      "ae train 실행 시간: 0.502초, 전체 시작 시간 20250320_214857_580\n",
      "\n",
      "epoch-33 accuracy check\n",
      "k_means origin feature average accuracy : 91.09838626%, total [0.9109838625715773]\n",
      "kmeans average accuracy best : 98.07%, kmeans average accuracy : 97.96980739%, total [0.9796980739198334]\n",
      "accuracy_check 실행 시간: 7.113초\n",
      "\n",
      "\n",
      "epoch-34 loss : 0.02092615, loss_normal : 0.03989583, loss_coarse : 0.06546885, min_loss : 0.02063015, min_loss_normal : 0.03978038, min_loss_coarse : 0.06461988, wrong_element_sum : 314931.00000000, same_data : 0.00%\n",
      "ae train 실행 시간: 0.451초, 전체 시작 시간 20250320_214857_580\n",
      "\n",
      "epoch-34 accuracy check\n",
      "k_means origin feature average accuracy : 91.09838626%, total [0.9109838625715773]\n",
      "kmeans average accuracy best : 98.07%, kmeans average accuracy : 97.44924518%, total [0.9744924518479958]\n",
      "accuracy_check 실행 시간: 6.910초\n",
      "\n",
      "\n",
      "epoch-35 loss : 0.02073498, loss_normal : 0.03983150, loss_coarse : 0.06506660, min_loss : 0.02063015, min_loss_normal : 0.03978038, min_loss_coarse : 0.06461988, wrong_element_sum : 312689.00000000, same_data : 0.00%\n",
      "ae train 실행 시간: 0.451초, 전체 시작 시간 20250320_214857_580\n",
      "\n",
      "epoch-35 accuracy check\n",
      "k_means origin feature average accuracy : 96.92868298%, total [0.9692868297761582]\n",
      "kmeans average accuracy best : 98.07%, kmeans average accuracy : 97.81363873%, total [0.9781363872982821]\n",
      "accuracy_check 실행 시간: 7.744초\n",
      "\n",
      "\n",
      "epoch-36 loss : 0.02074626, loss_normal : 0.03997535, loss_coarse : 0.06496188, min_loss : 0.02063015, min_loss_normal : 0.03978038, min_loss_coarse : 0.06461988, wrong_element_sum : 311961.00000000, same_data : 0.00%\n",
      "ae train 실행 시간: 0.482초, 전체 시작 시간 20250320_214857_580\n",
      "\n",
      "epoch-36 accuracy check\n",
      "k_means origin feature average accuracy : 91.15044248%, total [0.911504424778761]\n",
      "kmeans average accuracy best : 98.07%, kmeans average accuracy : 97.76158251%, total [0.9776158250910983]\n",
      "accuracy_check 실행 시간: 7.072초\n",
      "\n",
      "\n",
      "epoch-37 loss : 0.02071644, loss_normal : 0.03994159, loss_coarse : 0.06486844, min_loss : 0.02063015, min_loss_normal : 0.03978038, min_loss_coarse : 0.06461988, wrong_element_sum : 311350.00000000, same_data : 0.00%\n",
      "ae train 실행 시간: 0.448초, 전체 시작 시간 20250320_214857_580\n",
      "\n",
      "epoch-37 accuracy check\n",
      "k_means origin feature average accuracy : 96.82457054%, total [0.9682457053617908]\n",
      "kmeans average accuracy best : 98.07%, kmeans average accuracy : 97.81363873%, total [0.9781363872982821]\n",
      "accuracy_check 실행 시간: 7.031초\n",
      "\n",
      "\n",
      "epoch-38 loss : 0.02073999, loss_normal : 0.03997176, loss_coarse : 0.06491024, min_loss : 0.02063015, min_loss_normal : 0.03978038, min_loss_coarse : 0.06461988, wrong_element_sum : 311895.00000000, same_data : 0.00%\n",
      "ae train 실행 시간: 0.456초, 전체 시작 시간 20250320_214857_580\n",
      "\n",
      "epoch-38 accuracy check\n",
      "k_means origin feature average accuracy : 89.79698074%, total [0.8979698073919833]\n",
      "kmeans average accuracy best : 98.07%, kmeans average accuracy : 91.77511713%, total [0.9177511712649662]\n",
      "accuracy_check 실행 시간: 6.875초\n",
      "\n",
      "\n",
      "epoch-39 loss : 0.02071731, loss_normal : 0.03996554, loss_coarse : 0.06496065, min_loss : 0.02063015, min_loss_normal : 0.03978038, min_loss_coarse : 0.06461988, wrong_element_sum : 311862.00000000, same_data : 0.00%\n",
      "ae train 실행 시간: 0.457초, 전체 시작 시간 20250320_214857_580\n",
      "\n",
      "epoch-39 accuracy check\n",
      "k_means origin feature average accuracy : 89.58875586%, total [0.8958875585632483]\n",
      "kmeans average accuracy best : 98.07%, kmeans average accuracy : 97.65747007%, total [0.9765747006767309]\n",
      "accuracy_check 실행 시간: 6.842초\n",
      "\n",
      "\n",
      "epoch-40 loss : 0.02059867, loss_normal : 0.03986737, loss_coarse : 0.06436516, min_loss : 0.02059867, min_loss_normal : 0.03978038, min_loss_coarse : 0.06436516, wrong_element_sum : 309297.00000000, same_data : 0.00%\n",
      "ae train 실행 시간: 0.461초, 전체 시작 시간 20250320_214857_580\n",
      "\n",
      "epoch-40 accuracy check\n",
      "k_means origin feature average accuracy : 89.64081208%, total [0.8964081207704321]\n",
      "kmeans average accuracy best : 98.07%, kmeans average accuracy : 97.60541385%, total [0.9760541384695471]\n",
      "accuracy_check 실행 시간: 6.876초\n",
      "\n",
      "\n",
      "epoch-41 loss : 0.02057497, loss_normal : 0.03979583, loss_coarse : 0.06434754, min_loss : 0.02057497, min_loss_normal : 0.03978038, min_loss_coarse : 0.06434754, wrong_element_sum : 309428.00000000, same_data : 0.00%\n",
      "ae train 실행 시간: 0.445초, 전체 시작 시간 20250320_214857_580\n",
      "\n",
      "epoch-41 accuracy check\n",
      "k_means origin feature average accuracy : 96.98073920%, total [0.969807391983342]\n",
      "kmeans average accuracy best : 98.07%, kmeans average accuracy : 90.16137428%, total [0.9016137428422697]\n",
      "accuracy_check 실행 시간: 6.756초\n",
      "\n",
      "\n",
      "epoch-42 loss : 0.02054859, loss_normal : 0.03975316, loss_coarse : 0.06439385, min_loss : 0.02054859, min_loss_normal : 0.03975316, min_loss_coarse : 0.06434754, wrong_element_sum : 309871.00000000, same_data : 0.00%\n",
      "ae train 실행 시간: 0.452초, 전체 시작 시간 20250320_214857_580\n",
      "\n",
      "epoch-42 accuracy check\n",
      "k_means origin feature average accuracy : 91.09838626%, total [0.9109838625715773]\n",
      "kmeans average accuracy best : 98.07%, kmeans average accuracy : 91.61894846%, total [0.9161894846434149]\n",
      "accuracy_check 실행 시간: 6.836초\n",
      "\n",
      "\n",
      "epoch-43 loss : 0.02059322, loss_normal : 0.03985585, loss_coarse : 0.06448811, min_loss : 0.02054859, min_loss_normal : 0.03975316, min_loss_coarse : 0.06434754, wrong_element_sum : 310331.00000000, same_data : 0.00%\n",
      "ae train 실행 시간: 0.464초, 전체 시작 시간 20250320_214857_580\n",
      "\n",
      "epoch-43 accuracy check\n",
      "k_means origin feature average accuracy : 89.69286830%, total [0.8969286829776159]\n",
      "kmeans average accuracy best : 98.07%, kmeans average accuracy : 90.47371161%, total [0.9047371160853722]\n",
      "accuracy_check 실행 시간: 7.074초\n",
      "\n",
      "\n",
      "epoch-44 loss : 0.02062009, loss_normal : 0.03989751, loss_coarse : 0.06443565, min_loss : 0.02054859, min_loss_normal : 0.03975316, min_loss_coarse : 0.06434754, wrong_element_sum : 310292.00000000, same_data : 0.00%\n",
      "ae train 실행 시간: 0.478초, 전체 시작 시간 20250320_214857_580\n",
      "\n",
      "epoch-44 accuracy check\n",
      "k_means origin feature average accuracy : 89.64081208%, total [0.8964081207704321]\n",
      "kmeans average accuracy best : 98.07%, kmeans average accuracy : 91.72306091%, total [0.9172306090577824]\n",
      "accuracy_check 실행 시간: 6.957초\n",
      "\n",
      "\n",
      "epoch-45 loss : 0.02056320, loss_normal : 0.03988223, loss_coarse : 0.06430430, min_loss : 0.02054859, min_loss_normal : 0.03975316, min_loss_coarse : 0.06430430, wrong_element_sum : 308690.00000000, same_data : 0.00%\n",
      "ae train 실행 시간: 0.444초, 전체 시작 시간 20250320_214857_580\n",
      "\n",
      "epoch-45 accuracy check\n",
      "k_means origin feature average accuracy : 96.82457054%, total [0.9682457053617908]\n",
      "kmeans average accuracy best : 98.07%, kmeans average accuracy : 92.13951067%, total [0.9213951067152525]\n",
      "accuracy_check 실행 시간: 6.873초\n",
      "\n",
      "\n",
      "epoch-46 loss : 0.02054530, loss_normal : 0.03976006, loss_coarse : 0.06433996, min_loss : 0.02054530, min_loss_normal : 0.03975316, min_loss_coarse : 0.06430430, wrong_element_sum : 309577.00000000, same_data : 0.00%\n",
      "ae train 실행 시간: 0.440초, 전체 시작 시간 20250320_214857_580\n",
      "\n",
      "epoch-46 accuracy check\n",
      "k_means origin feature average accuracy : 89.64081208%, total [0.8964081207704321]\n",
      "kmeans average accuracy best : 98.07%, kmeans average accuracy : 97.44924518%, total [0.9744924518479958]\n",
      "accuracy_check 실행 시간: 6.943초\n",
      "\n",
      "\n",
      "epoch-47 loss : 0.02065763, loss_normal : 0.03994540, loss_coarse : 0.06502479, min_loss : 0.02054530, min_loss_normal : 0.03975316, min_loss_coarse : 0.06430430, wrong_element_sum : 311741.00000000, same_data : 0.00%\n",
      "ae train 실행 시간: 0.455초, 전체 시작 시간 20250320_214857_580\n",
      "\n",
      "epoch-47 accuracy check\n",
      "k_means origin feature average accuracy : 89.64081208%, total [0.8964081207704321]\n",
      "kmeans average accuracy best : 98.07%, kmeans average accuracy : 97.76158251%, total [0.9776158250910983]\n",
      "accuracy_check 실행 시간: 6.800초\n",
      "\n",
      "\n",
      "epoch-48 loss : 0.02072816, loss_normal : 0.03995907, loss_coarse : 0.06513463, min_loss : 0.02054530, min_loss_normal : 0.03975316, min_loss_coarse : 0.06430430, wrong_element_sum : 312928.00000000, same_data : 0.00%\n",
      "ae train 실행 시간: 0.453초, 전체 시작 시간 20250320_214857_580\n",
      "\n",
      "epoch-48 accuracy check\n",
      "k_means origin feature average accuracy : 89.64081208%, total [0.8964081207704321]\n",
      "kmeans average accuracy best : 98.07%, kmeans average accuracy : 97.55335763%, total [0.9755335762623634]\n",
      "accuracy_check 실행 시간: 6.931초\n",
      "\n",
      "\n",
      "epoch-49 loss : 0.02056158, loss_normal : 0.03985810, loss_coarse : 0.06418770, min_loss : 0.02054530, min_loss_normal : 0.03975316, min_loss_coarse : 0.06418770, wrong_element_sum : 308555.00000000, same_data : 0.00%\n",
      "ae train 실행 시간: 0.449초, 전체 시작 시간 20250320_214857_580\n",
      "\n",
      "epoch-49 accuracy check\n",
      "k_means origin feature average accuracy : 91.15044248%, total [0.911504424778761]\n",
      "kmeans average accuracy best : 98.07%, kmeans average accuracy : 97.55335763%, total [0.9755335762623634]\n",
      "accuracy_check 실행 시간: 6.817초\n",
      "\n",
      "\n",
      "epoch-50 loss : 0.02064041, loss_normal : 0.03992582, loss_coarse : 0.06475082, min_loss : 0.02054530, min_loss_normal : 0.03975316, min_loss_coarse : 0.06418770, wrong_element_sum : 311148.00000000, same_data : 0.00%\n",
      "ae train 실행 시간: 0.458초, 전체 시작 시간 20250320_214857_580\n",
      "\n",
      "epoch-50 accuracy check\n",
      "k_means origin feature average accuracy : 89.58875586%, total [0.8958875585632483]\n",
      "kmeans average accuracy best : 98.07%, kmeans average accuracy : 97.55335763%, total [0.9755335762623634]\n",
      "accuracy_check 실행 시간: 6.783초\n",
      "\n",
      "\n",
      "epoch-51 loss : 0.02090918, loss_normal : 0.03996078, loss_coarse : 0.06530840, min_loss : 0.02054530, min_loss_normal : 0.03975316, min_loss_coarse : 0.06418770, wrong_element_sum : 309932.00000000, same_data : 0.00%\n",
      "ae train 실행 시간: 0.447초, 전체 시작 시간 20250320_214857_580\n",
      "\n",
      "epoch-51 accuracy check\n",
      "k_means origin feature average accuracy : 89.69286830%, total [0.8969286829776159]\n",
      "kmeans average accuracy best : 98.07%, kmeans average accuracy : 97.65747007%, total [0.9765747006767309]\n",
      "accuracy_check 실행 시간: 7.009초\n",
      "\n",
      "\n",
      "epoch-52 loss : 0.02169118, loss_normal : 0.04022131, loss_coarse : 0.06855533, min_loss : 0.02054530, min_loss_normal : 0.03975316, min_loss_coarse : 0.06418770, wrong_element_sum : 330148.00000000, same_data : 0.00%\n",
      "ae train 실행 시간: 0.458초, 전체 시작 시간 20250320_214857_580\n",
      "\n",
      "epoch-52 accuracy check\n",
      "k_means origin feature average accuracy : 96.98073920%, total [0.969807391983342]\n",
      "kmeans average accuracy best : 98.07%, kmeans average accuracy : 97.86569495%, total [0.9786569495054659]\n",
      "accuracy_check 실행 시간: 6.758초\n",
      "\n",
      "\n",
      "epoch-53 loss : 0.02090932, loss_normal : 0.03997113, loss_coarse : 0.06548852, min_loss : 0.02054530, min_loss_normal : 0.03975316, min_loss_coarse : 0.06418770, wrong_element_sum : 314872.00000000, same_data : 0.00%\n",
      "ae train 실행 시간: 0.449초, 전체 시작 시간 20250320_214857_580\n",
      "\n",
      "epoch-53 accuracy check\n",
      "k_means origin feature average accuracy : 89.64081208%, total [0.8964081207704321]\n",
      "kmeans average accuracy best : 98.07%, kmeans average accuracy : 97.96980739%, total [0.9796980739198334]\n",
      "accuracy_check 실행 시간: 6.777초\n",
      "\n",
      "\n",
      "epoch-54 loss : 0.02061571, loss_normal : 0.03978592, loss_coarse : 0.06448217, min_loss : 0.02054530, min_loss_normal : 0.03975316, min_loss_coarse : 0.06418770, wrong_element_sum : 310240.00000000, same_data : 0.00%\n",
      "ae train 실행 시간: 0.464초, 전체 시작 시간 20250320_214857_580\n",
      "\n",
      "epoch-54 accuracy check\n",
      "k_means origin feature average accuracy : 89.69286830%, total [0.8969286829776159]\n",
      "kmeans average accuracy best : 98.07%, kmeans average accuracy : 79.90629880%, total [0.7990629880270692]\n",
      "accuracy_check 실행 시간: 6.826초\n",
      "\n",
      "\n",
      "epoch-55 loss : 0.02062275, loss_normal : 0.03989236, loss_coarse : 0.06436926, min_loss : 0.02054530, min_loss_normal : 0.03975316, min_loss_coarse : 0.06418770, wrong_element_sum : 309441.00000000, same_data : 0.00%\n",
      "ae train 실행 시간: 0.442초, 전체 시작 시간 20250320_214857_580\n",
      "\n",
      "epoch-55 accuracy check\n",
      "k_means origin feature average accuracy : 89.53669964%, total [0.8953669963560645]\n",
      "kmeans average accuracy best : 98.07%, kmeans average accuracy : 97.65747007%, total [0.9765747006767309]\n",
      "accuracy_check 실행 시간: 6.819초\n",
      "\n",
      "\n",
      "epoch-56 loss : 0.02059424, loss_normal : 0.03983383, loss_coarse : 0.06448750, min_loss : 0.02054530, min_loss_normal : 0.03975316, min_loss_coarse : 0.06418770, wrong_element_sum : 309925.00000000, same_data : 0.00%\n",
      "ae train 실행 시간: 0.459초, 전체 시작 시간 20250320_214857_580\n",
      "\n",
      "epoch-56 accuracy check\n",
      "k_means origin feature average accuracy : 89.53669964%, total [0.8953669963560645]\n",
      "kmeans average accuracy best : 98.07%, kmeans average accuracy : 97.70952629%, total [0.9770952628839146]\n",
      "accuracy_check 실행 시간: 6.898초\n",
      "\n",
      "\n",
      "epoch-57 loss : 0.02055524, loss_normal : 0.03983901, loss_coarse : 0.06418709, min_loss : 0.02054530, min_loss_normal : 0.03975316, min_loss_coarse : 0.06418709, wrong_element_sum : 308583.00000000, same_data : 0.00%\n",
      "ae train 실행 시간: 0.451초, 전체 시작 시간 20250320_214857_580\n",
      "\n",
      "epoch-57 accuracy check\n",
      "k_means origin feature average accuracy : 96.82457054%, total [0.9682457053617908]\n",
      "kmeans average accuracy best : 98.07%, kmeans average accuracy : 97.70952629%, total [0.9770952628839146]\n",
      "accuracy_check 실행 시간: 6.825초\n",
      "\n",
      "\n",
      "epoch-58 loss : 0.02050803, loss_normal : 0.03971866, loss_coarse : 0.06434344, min_loss : 0.02050803, min_loss_normal : 0.03971866, min_loss_coarse : 0.06418709, wrong_element_sum : 309098.00000000, same_data : 0.00%\n",
      "ae train 실행 시간: 0.466초, 전체 시작 시간 20250320_214857_580\n",
      "\n",
      "epoch-58 accuracy check\n",
      "k_means origin feature average accuracy : 89.69286830%, total [0.8969286829776159]\n",
      "kmeans average accuracy best : 98.07%, kmeans average accuracy : 97.60541385%, total [0.9760541384695471]\n",
      "accuracy_check 실행 시간: 6.925초\n",
      "\n",
      "\n",
      "epoch-59 loss : 0.02045815, loss_normal : 0.03965011, loss_coarse : 0.06413320, min_loss : 0.02045815, min_loss_normal : 0.03965011, min_loss_coarse : 0.06413320, wrong_element_sum : 308816.00000000, same_data : 0.00%\n",
      "ae train 실행 시간: 0.442초, 전체 시작 시간 20250320_214857_580\n",
      "\n",
      "epoch-59 accuracy check\n",
      "k_means origin feature average accuracy : 89.69286830%, total [0.8969286829776159]\n",
      "kmeans average accuracy best : 98.07%, kmeans average accuracy : 97.55335763%, total [0.9755335762623634]\n",
      "accuracy_check 실행 시간: 6.888초\n",
      "\n",
      "\n",
      "epoch-60 loss : 0.02051846, loss_normal : 0.03970087, loss_coarse : 0.06443975, min_loss : 0.02045815, min_loss_normal : 0.03965011, min_loss_coarse : 0.06413320, wrong_element_sum : 310095.00000000, same_data : 0.00%\n",
      "ae train 실행 시간: 0.459초, 전체 시작 시간 20250320_214857_580\n",
      "\n",
      "epoch-60 accuracy check\n",
      "k_means origin feature average accuracy : 94.79437793%, total [0.9479437792816241]\n",
      "kmeans average accuracy best : 98.07%, kmeans average accuracy : 97.60541385%, total [0.9760541384695471]\n",
      "accuracy_check 실행 시간: 6.893초\n",
      "\n",
      "\n",
      "epoch-61 loss : 0.02074312, loss_normal : 0.03989460, loss_coarse : 0.06554733, min_loss : 0.02045815, min_loss_normal : 0.03965011, min_loss_coarse : 0.06413320, wrong_element_sum : 315190.00000000, same_data : 0.00%\n",
      "ae train 실행 시간: 0.441초, 전체 시작 시간 20250320_214857_580\n",
      "\n",
      "epoch-61 accuracy check\n",
      "k_means origin feature average accuracy : 89.64081208%, total [0.8964081207704321]\n",
      "kmeans average accuracy best : 98.07%, kmeans average accuracy : 97.65747007%, total [0.9765747006767309]\n",
      "accuracy_check 실행 시간: 6.880초\n",
      "\n",
      "\n",
      "epoch-62 loss : 0.02047151, loss_normal : 0.03970087, loss_coarse : 0.06427151, min_loss : 0.02045815, min_loss_normal : 0.03965011, min_loss_coarse : 0.06413320, wrong_element_sum : 308499.00000000, same_data : 0.00%\n",
      "ae train 실행 시간: 0.461초, 전체 시작 시간 20250320_214857_580\n",
      "\n",
      "epoch-62 accuracy check\n",
      "k_means origin feature average accuracy : 89.58875586%, total [0.8958875585632483]\n",
      "kmeans average accuracy best : 98.07%, kmeans average accuracy : 97.44924518%, total [0.9744924518479958]\n",
      "accuracy_check 실행 시간: 6.897초\n",
      "\n",
      "\n",
      "epoch-63 loss : 0.02047689, loss_normal : 0.03968631, loss_coarse : 0.06417008, min_loss : 0.02045815, min_loss_normal : 0.03965011, min_loss_coarse : 0.06413320, wrong_element_sum : 308469.00000000, same_data : 0.00%\n",
      "ae train 실행 시간: 0.456초, 전체 시작 시간 20250320_214857_580\n",
      "\n",
      "epoch-63 accuracy check\n",
      "k_means origin feature average accuracy : 96.98073920%, total [0.969807391983342]\n",
      "kmeans average accuracy best : 98.07%, kmeans average accuracy : 97.70952629%, total [0.9770952628839146]\n",
      "accuracy_check 실행 시간: 6.787초\n",
      "\n",
      "\n",
      "epoch-64 loss : 0.02048797, loss_normal : 0.03978051, loss_coarse : 0.06409733, min_loss : 0.02045815, min_loss_normal : 0.03965011, min_loss_coarse : 0.06409733, wrong_element_sum : 307990.00000000, same_data : 0.00%\n",
      "ae train 실행 시간: 0.444초, 전체 시작 시간 20250320_214857_580\n",
      "\n",
      "epoch-64 accuracy check\n",
      "k_means origin feature average accuracy : 89.74492452%, total [0.8974492451847996]\n",
      "kmeans average accuracy best : 98.07%, kmeans average accuracy : 97.55335763%, total [0.9755335762623634]\n",
      "accuracy_check 실행 시간: 6.768초\n",
      "\n",
      "\n",
      "epoch-65 loss : 0.02047209, loss_normal : 0.03976640, loss_coarse : 0.06390061, min_loss : 0.02045815, min_loss_normal : 0.03965011, min_loss_coarse : 0.06390061, wrong_element_sum : 307464.00000000, same_data : 0.00%\n",
      "ae train 실행 시간: 0.454초, 전체 시작 시간 20250320_214857_580\n",
      "\n",
      "epoch-65 accuracy check\n",
      "k_means origin feature average accuracy : 89.79698074%, total [0.8979698073919833]\n",
      "kmeans average accuracy best : 98.07%, kmeans average accuracy : 97.91775117%, total [0.9791775117126497]\n",
      "accuracy_check 실행 시간: 6.859초\n",
      "\n",
      "\n",
      "epoch-66 loss : 0.02064103, loss_normal : 0.03987112, loss_coarse : 0.06527623, min_loss : 0.02045815, min_loss_normal : 0.03965011, min_loss_coarse : 0.06390061, wrong_element_sum : 313092.00000000, same_data : 0.00%\n",
      "ae train 실행 시간: 0.454초, 전체 시작 시간 20250320_214857_580\n",
      "\n",
      "epoch-66 accuracy check\n",
      "k_means origin feature average accuracy : 89.79698074%, total [0.8979698073919833]\n",
      "kmeans average accuracy best : 98.07%, kmeans average accuracy : 97.70952629%, total [0.9770952628839146]\n",
      "accuracy_check 실행 시간: 6.888초\n",
      "\n",
      "\n",
      "epoch-67 loss : 0.02055602, loss_normal : 0.03981504, loss_coarse : 0.06438012, min_loss : 0.02045815, min_loss_normal : 0.03965011, min_loss_coarse : 0.06390061, wrong_element_sum : 309308.00000000, same_data : 0.00%\n",
      "ae train 실행 시간: 0.447초, 전체 시작 시간 20250320_214857_580\n",
      "\n",
      "epoch-67 accuracy check\n",
      "k_means origin feature average accuracy : 96.72045809%, total [0.9672045809474232]\n",
      "kmeans average accuracy best : 98.07%, kmeans average accuracy : 97.60541385%, total [0.9760541384695471]\n",
      "accuracy_check 실행 시간: 6.840초\n",
      "\n",
      "\n",
      "epoch-68 loss : 0.02053838, loss_normal : 0.03978565, loss_coarse : 0.06460738, min_loss : 0.02045815, min_loss_normal : 0.03965011, min_loss_coarse : 0.06390061, wrong_element_sum : 310355.00000000, same_data : 0.00%\n",
      "ae train 실행 시간: 0.452초, 전체 시작 시간 20250320_214857_580\n",
      "\n",
      "epoch-68 accuracy check\n",
      "k_means origin feature average accuracy : 89.64081208%, total [0.8964081207704321]\n",
      "kmeans average accuracy best : 98.07%, kmeans average accuracy : 97.70952629%, total [0.9770952628839146]\n",
      "accuracy_check 실행 시간: 6.854초\n",
      "\n",
      "\n",
      "epoch-69 loss : 0.02047099, loss_normal : 0.03974764, loss_coarse : 0.06380123, min_loss : 0.02045815, min_loss_normal : 0.03965011, min_loss_coarse : 0.06380123, wrong_element_sum : 307010.00000000, same_data : 0.00%\n",
      "ae train 실행 시간: 0.488초, 전체 시작 시간 20250320_214857_580\n",
      "\n",
      "epoch-69 accuracy check\n",
      "k_means origin feature average accuracy : 89.64081208%, total [0.8964081207704321]\n",
      "kmeans average accuracy best : 98.07%, kmeans average accuracy : 97.76158251%, total [0.9776158250910983]\n",
      "accuracy_check 실행 시간: 7.218초\n",
      "\n",
      "\n",
      "epoch-70 loss : 0.02052795, loss_normal : 0.03980859, loss_coarse : 0.06448033, min_loss : 0.02045815, min_loss_normal : 0.03965011, min_loss_coarse : 0.06380123, wrong_element_sum : 309208.00000000, same_data : 0.00%\n",
      "ae train 실행 시간: 0.505초, 전체 시작 시간 20250320_214857_580\n",
      "\n",
      "epoch-70 accuracy check\n",
      "k_means origin feature average accuracy : 89.48464341%, total [0.8948464341488808]\n",
      "kmeans average accuracy best : 98.07%, kmeans average accuracy : 97.70952629%, total [0.9770952628839146]\n",
      "accuracy_check 실행 시간: 7.175초\n",
      "\n",
      "\n",
      "epoch-71 loss : 0.02059652, loss_normal : 0.03980793, loss_coarse : 0.06471188, min_loss : 0.02045815, min_loss_normal : 0.03965011, min_loss_coarse : 0.06380123, wrong_element_sum : 310555.00000000, same_data : 0.00%\n",
      "ae train 실행 시간: 0.503초, 전체 시작 시간 20250320_214857_580\n",
      "\n",
      "epoch-71 accuracy check\n",
      "k_means origin feature average accuracy : 89.53669964%, total [0.8953669963560645]\n",
      "kmeans average accuracy best : 98.07%, kmeans average accuracy : 91.46277980%, total [0.9146277980218636]\n",
      "accuracy_check 실행 시간: 7.304초\n",
      "\n",
      "\n",
      "epoch-72 loss : 0.02045379, loss_normal : 0.03975549, loss_coarse : 0.06376639, min_loss : 0.02045379, min_loss_normal : 0.03965011, min_loss_coarse : 0.06376639, wrong_element_sum : 306096.00000000, same_data : 0.00%\n",
      "ae train 실행 시간: 0.484초, 전체 시작 시간 20250320_214857_580\n",
      "\n",
      "epoch-72 accuracy check\n",
      "k_means origin feature average accuracy : 89.74492452%, total [0.8974492451847996]\n",
      "kmeans average accuracy best : 98.07%, kmeans average accuracy : 97.70952629%, total [0.9770952628839146]\n",
      "accuracy_check 실행 시간: 7.154초\n",
      "\n",
      "\n",
      "epoch-73 loss : 0.02050297, loss_normal : 0.03977238, loss_coarse : 0.06410779, min_loss : 0.02045379, min_loss_normal : 0.03965011, min_loss_coarse : 0.06376639, wrong_element_sum : 308134.00000000, same_data : 0.00%\n",
      "ae train 실행 시간: 0.449초, 전체 시작 시간 20250320_214857_580\n",
      "\n",
      "epoch-73 accuracy check\n",
      "k_means origin feature average accuracy : 96.87662676%, total [0.9687662675689744]\n",
      "kmeans average accuracy best : 98.07%, kmeans average accuracy : 97.81363873%, total [0.9781363872982821]\n",
      "accuracy_check 실행 시간: 6.844초\n",
      "\n",
      "\n",
      "epoch-74 loss : 0.02049275, loss_normal : 0.03974422, loss_coarse : 0.06416762, min_loss : 0.02045379, min_loss_normal : 0.03965011, min_loss_coarse : 0.06376639, wrong_element_sum : 308364.00000000, same_data : 0.00%\n",
      "ae train 실행 시간: 0.449초, 전체 시작 시간 20250320_214857_580\n",
      "\n",
      "epoch-74 accuracy check\n",
      "k_means origin feature average accuracy : 89.53669964%, total [0.8953669963560645]\n",
      "kmeans average accuracy best : 98.07%, kmeans average accuracy : 97.76158251%, total [0.9776158250910983]\n",
      "accuracy_check 실행 시간: 6.816초\n",
      "\n",
      "\n",
      "epoch-75 loss : 0.02038939, loss_normal : 0.03970714, loss_coarse : 0.06348320, min_loss : 0.02038939, min_loss_normal : 0.03965011, min_loss_coarse : 0.06348320, wrong_element_sum : 304993.00000000, same_data : 0.00%\n",
      "ae train 실행 시간: 0.448초, 전체 시작 시간 20250320_214857_580\n",
      "\n",
      "epoch-75 accuracy check\n",
      "k_means origin feature average accuracy : 89.69286830%, total [0.8969286829776159]\n",
      "kmeans average accuracy best : 98.07%, kmeans average accuracy : 97.55335763%, total [0.9755335762623634]\n",
      "accuracy_check 실행 시간: 6.828초\n",
      "\n",
      "\n",
      "epoch-76 loss : 0.02035995, loss_normal : 0.03956531, loss_coarse : 0.06374508, min_loss : 0.02035995, min_loss_normal : 0.03956531, min_loss_coarse : 0.06348320, wrong_element_sum : 306426.00000000, same_data : 0.00%\n",
      "ae train 실행 시간: 0.454초, 전체 시작 시간 20250320_214857_580\n",
      "\n",
      "epoch-76 accuracy check\n",
      "k_means origin feature average accuracy : 96.87662676%, total [0.9687662675689744]\n",
      "kmeans average accuracy best : 98.07%, kmeans average accuracy : 97.60541385%, total [0.9760541384695471]\n",
      "accuracy_check 실행 시간: 6.869초\n",
      "\n",
      "\n",
      "epoch-77 loss : 0.02047552, loss_normal : 0.03978797, loss_coarse : 0.06402746, min_loss : 0.02035995, min_loss_normal : 0.03956531, min_loss_coarse : 0.06348320, wrong_element_sum : 307153.00000000, same_data : 0.00%\n",
      "ae train 실행 시간: 0.468초, 전체 시작 시간 20250320_214857_580\n",
      "\n",
      "epoch-77 accuracy check\n",
      "k_means origin feature average accuracy : 91.09838626%, total [0.9109838625715773]\n",
      "kmeans average accuracy best : 98.07%, kmeans average accuracy : 97.55335763%, total [0.9755335762623634]\n",
      "accuracy_check 실행 시간: 6.875초\n",
      "\n",
      "\n",
      "epoch-78 loss : 0.02052677, loss_normal : 0.03977121, loss_coarse : 0.06429324, min_loss : 0.02035995, min_loss_normal : 0.03956531, min_loss_coarse : 0.06348320, wrong_element_sum : 308667.00000000, same_data : 0.00%\n",
      "ae train 실행 시간: 0.451초, 전체 시작 시간 20250320_214857_580\n",
      "\n",
      "epoch-78 accuracy check\n",
      "k_means origin feature average accuracy : 89.64081208%, total [0.8964081207704321]\n",
      "kmeans average accuracy best : 98.07%, kmeans average accuracy : 97.55335763%, total [0.9755335762623634]\n",
      "accuracy_check 실행 시간: 6.903초\n",
      "\n",
      "\n",
      "epoch-79 loss : 0.02043682, loss_normal : 0.03972340, loss_coarse : 0.06359570, min_loss : 0.02035995, min_loss_normal : 0.03956531, min_loss_coarse : 0.06348320, wrong_element_sum : 305852.00000000, same_data : 0.00%\n",
      "ae train 실행 시간: 0.452초, 전체 시작 시간 20250320_214857_580\n",
      "\n",
      "epoch-79 accuracy check\n",
      "k_means origin feature average accuracy : 89.74492452%, total [0.8974492451847996]\n",
      "kmeans average accuracy best : 98.07%, kmeans average accuracy : 90.10931806%, total [0.9010931806350859]\n",
      "accuracy_check 실행 시간: 6.961초\n",
      "\n",
      "\n",
      "epoch-80 loss : 0.02054999, loss_normal : 0.03977950, loss_coarse : 0.06456270, min_loss : 0.02035995, min_loss_normal : 0.03956531, min_loss_coarse : 0.06348320, wrong_element_sum : 309455.00000000, same_data : 0.00%\n",
      "ae train 실행 시간: 0.464초, 전체 시작 시간 20250320_214857_580\n",
      "\n",
      "epoch-80 accuracy check\n",
      "k_means origin feature average accuracy : 97.03279542%, total [0.9703279541905258]\n",
      "kmeans average accuracy best : 98.07%, kmeans average accuracy : 97.70952629%, total [0.9770952628839146]\n",
      "accuracy_check 실행 시간: 6.853초\n",
      "\n",
      "\n",
      "epoch-81 loss : 0.02049062, loss_normal : 0.03974395, loss_coarse : 0.06393361, min_loss : 0.02035995, min_loss_normal : 0.03956531, min_loss_coarse : 0.06348320, wrong_element_sum : 307160.00000000, same_data : 0.00%\n",
      "ae train 실행 시간: 0.450초, 전체 시작 시간 20250320_214857_580\n",
      "\n",
      "epoch-81 accuracy check\n",
      "k_means origin feature average accuracy : 96.98073920%, total [0.969807391983342]\n",
      "kmeans average accuracy best : 98.07%, kmeans average accuracy : 97.70952629%, total [0.9770952628839146]\n",
      "accuracy_check 실행 시간: 6.823초\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "gpu = '5'\n",
    "Conv_net = True # True False\n",
    "SAE_net = False # True False\n",
    "\n",
    "# hyperparameter\n",
    "dataset_num = 1\n",
    "spike_length = 50 # coarse_com_mode일 때는 time step이 됨.\n",
    "num_cluster = 7  # 클러스터 수 설정 # 논문엔 4개라는데 여기서는 3개로 했네\n",
    "training_cycle = 1400 #1400 2400 # 그 초기 몇개까지만 cluster update할지\n",
    "\n",
    "\n",
    "batch_size = 32\n",
    "max_epoch = 10000 # 10000 # 1\n",
    "learning_rate = 0.001\n",
    "normalize_on = True # True or False # 0부터1까지 normalize\n",
    "need_bias = False\n",
    "# first_layer_no_train = False\n",
    "lif_add_at_first = False\n",
    "my_seed = 42\n",
    "\n",
    "TIME = 50 # SAE일 때만 유효. coarse_com_mode일 때는 level_num이 됨. 즉 feature 개수.\n",
    "v_decay = 0.5 # -cor\n",
    "v_threshold = 0.25 # -cor\n",
    "v_reset = 0.0 # -cor # 10000이상 일 시 hard reset\n",
    "BPTT_on = True # +cor # True False\n",
    "\n",
    "SAE_hidden_nomean = True # True False\n",
    "\n",
    "current_time = datetime.datetime.now().strftime(\"%Y%m%d_%H%M%S\") + f\"_{str(int(datetime.datetime.now().microsecond / 1000)).zfill(3)}\"\n",
    "\n",
    "optimizer = 'Adam' #'Adam', 'SGD' # 둘다 준수함. loss 줄이는 거는 adam이 좋긴한데, cluster accuracy는 비슷함.\n",
    "\n",
    "coarse_com_mode = False # True False\n",
    "coarse_com_config = (0.999, -0.0) # (max, min) (0.999, -0.0) (1.0, -0.0) (2.0, -2.0) (3.0, -3.0)\n",
    "\n",
    "sae_l2_norm_bridge = True # True False\n",
    "sae_lif_bridge = False # True False\n",
    "\n",
    "accuracy_check_epoch_term = 1\n",
    "\n",
    "lif_add_at_last = False # True False\n",
    "\n",
    "two_channel_input = False # True False\n",
    "\n",
    "lateral_feature_num = 4\n",
    "\n",
    "lc_adc_on = False # True False\n",
    "\n",
    "converted_net_forward = False # True False\n",
    "\n",
    "pretrained_net = None\n",
    "# pretrained_net = '/home/bhkim003/github_folder/ByeonghyeonKim/my_snn/net_save/save_now_net_중요_20250110_203117_390.pth'\n",
    "# pretrained_net = '/home/bhkim003/github_folder/ByeonghyeonKim/my_snn/net_save/save_now_net_중요_20250113_134126_881_이거_94나오는거.pth'\n",
    "# pretrained_net = '/home/bhkim003/github_folder/ByeonghyeonKim/my_snn/net_save/save_now_net_20250205_184901_132.pth'\n",
    "# pretrained_net = '/home/bhkim003/github_folder/ByeonghyeonKim/my_snn/net_save/save_now_net_20250306_134219_133.pth'\n",
    "# pretrained_net = '/home/bhkim003/github_folder/ByeonghyeonKim/my_snn/net_save/save_now_net_20250304_130322_661.pth'\n",
    "\n",
    "vth_mul_on = False # True False\n",
    "batch_norm_on = False # True False\n",
    "\n",
    "l2_norm_loss_weight = 0 #0.0001 #0.1 #  0 # 0초과면 작동\n",
    "\n",
    "QCFS_neuron_on = False # True False\n",
    "\n",
    "quantize_level_num = 50 # 0이면 quantize 안함. 1이상이면 그 수만큼 quantize함. # normalize_on 켜져야됨. 음수면 0~1norm안하고 quant함\n",
    "\n",
    "fusion_net = False # True False # SAE_net False, Conv_net True로 해라. TIME 적절하게 설정해주고.\n",
    "repeat_coding = False # True False #fusion_net에서 쓰이는 거임 # True면 repeat, False면 rate coding.\n",
    "\n",
    "sae_relu_on = False # True False\n",
    "\n",
    "conv1d_scaling = False # True False # conv1d때매 norm하고 (level_num-3)/level_num 곱해줌 # Conv_net and coarse_com_mode and normalize_on\n",
    "\n",
    "norm01 = True # True False # normalize_on = True일 때 01norm하는지 아님 걍 quant만 하는지.\n",
    "\n",
    "chan_loss_factor = 1\n",
    "\n",
    "# multi_timestep_insert = (20,10) # (20,10) # None # (한번에 넣을 timestep,stride)\n",
    "\n",
    "wandb.init(project= f'spike_sorting just run np',save_code=False)\n",
    "\n",
    "\n",
    "cluster_train_system( \n",
    "    gpu = gpu,\n",
    "    Conv_net = Conv_net,\n",
    "    SAE_net = SAE_net,\n",
    "\n",
    "    # hyperparameter\n",
    "    dataset_num = dataset_num,\n",
    "    spike_length = spike_length,\n",
    "    num_cluster = num_cluster,  # 클러스터 수 설정 # 논문엔 4개라는데 여기서는 3개로 했네\n",
    "    training_cycle = training_cycle, # 그 초기 몇개까지만 cluster update할지\n",
    "\n",
    "\n",
    "    batch_size = batch_size,\n",
    "    max_epoch = max_epoch,\n",
    "    learning_rate = learning_rate,\n",
    "    normalize_on = normalize_on, # True or False #이거 안 씀 # 이거 별로 안 좋은 normalize같음 # 쓸 거면 다른 거 써라.\n",
    "    need_bias = need_bias,\n",
    "    # first_layer_no_train = False\n",
    "    lif_add_at_first = lif_add_at_first,\n",
    "    my_seed = my_seed,\n",
    "\n",
    "    TIME = TIME, # SAE일 때만 유효\n",
    "    v_decay = v_decay,\n",
    "    v_threshold = v_threshold,\n",
    "    v_reset = v_reset, # 10000이상 일 시 hard reset\n",
    "    BPTT_on = BPTT_on,\n",
    "\n",
    "    SAE_hidden_nomean = SAE_hidden_nomean,\n",
    "    \n",
    "    current_time = current_time,\n",
    "\n",
    "    optimizer = optimizer, #'Adam', 'SGD'\n",
    "\n",
    "    coarse_com_mode = coarse_com_mode,\n",
    "    coarse_com_config = coarse_com_config, # (max, min)\n",
    "\n",
    "    \n",
    "    sae_l2_norm_bridge = sae_l2_norm_bridge,\n",
    "    sae_lif_bridge = sae_lif_bridge,\n",
    "\n",
    "    accuracy_check_epoch_term = accuracy_check_epoch_term,\n",
    "    \n",
    "    lif_add_at_last = lif_add_at_last,\n",
    "\n",
    "    two_channel_input = two_channel_input,\n",
    "\n",
    "    lateral_feature_num = lateral_feature_num,\n",
    "\n",
    "    lc_adc_on = lc_adc_on, \n",
    "\n",
    "    converted_net_forward = converted_net_forward,\n",
    "\n",
    "    pretrained_net = pretrained_net,\n",
    "\n",
    "    vth_mul_on = vth_mul_on,\n",
    "    batch_norm_on = batch_norm_on,\n",
    "\n",
    "    l2_norm_loss_weight = l2_norm_loss_weight,\n",
    "    \n",
    "    QCFS_neuron_on = QCFS_neuron_on, # True False\n",
    "\n",
    "    quantize_level_num = quantize_level_num,\n",
    "\n",
    "    fusion_net = fusion_net, # True False\n",
    "    repeat_coding = repeat_coding,\n",
    "\n",
    "    sae_relu_on = sae_relu_on,\n",
    "\n",
    "    conv1d_scaling = conv1d_scaling,\n",
    "\n",
    "    norm01 = norm01,\n",
    "\n",
    "    chan_loss_factor = chan_loss_factor,\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Sweep code\n",
    "\n",
    "\n",
    "# from unittest import TextTestRunner\n",
    "\n",
    "\n",
    "# unique_name_hyper = 'cluster_train_system'\n",
    "# # run_name = 'spike_sorting'\n",
    "# sweep_start_time =  datetime.datetime.now().strftime(\"%Y%m%d_%H%M%S\") + f\"_{str(int(datetime.datetime.now().microsecond / 1000)).zfill(3)}\"\n",
    "# sweep_configuration = {\n",
    "#     'method': 'grid', # 'random', 'bayes', 'grid'\n",
    "#     'name': f'spike_sorting_{sweep_start_time}',\n",
    "#     'metric': {'goal': 'maximize', 'name': 'k_means_acc_best'},\n",
    "#     'parameters': \n",
    "#     {\n",
    "#         # \"gpu\": {\"values\": ['1']},  # 이건 sweep parameter아님. hyper_iter에서 직접 설정\n",
    "#         \"Conv_net\": {\"values\": [True]}, \n",
    "#         \"SAE_net\": {\"values\": [True]}, \n",
    "\n",
    "#         \"dataset_num\": {\"values\": [16]}, \n",
    "#         \"spike_length\": {\"values\": [50]},  \n",
    "#         \"num_cluster\": {\"values\": [4]}, \n",
    "#         \"training_cycle\": {\"values\": [1400]}, # [1400, 2400]\n",
    "\n",
    "#         \"batch_size\": {\"values\": [32]}, \n",
    "#         \"max_epoch\": {\"values\": [20]}, \n",
    "#         \"learning_rate\": {\"values\": [0.001, 0.0001]},\n",
    "#         \"normalize_on\": {\"values\": [True]},\n",
    "#         \"need_bias\": {\"values\": [False]}, # [True, False]\n",
    "\n",
    "#         \"lif_add_at_first\": {\"values\": [False]}, # [True, False]\n",
    "#         \"my_seed\": {\"values\": [42]}, \n",
    "\n",
    "#         \"TIME\": {\"values\": [50]}, #  [4,6,8,10]\n",
    "#         \"v_decay\": {\"values\": [0.5]}, # [0.25,0.50,0.75]\n",
    "#         \"v_threshold\": {\"values\": [0.25]}, # [0.25,0.50,0.75]\n",
    "#         \"v_reset\": {\"values\": [0.0]},  # [0.0, 10000.0]\n",
    "#         \"BPTT_on\": {\"values\": [True]},  # [True, False]\n",
    "\n",
    "#         \"SAE_hidden_nomean\": {\"values\": [True]}, # [True, False]\n",
    "\n",
    "#         # \"current_time\": {\"values\": [current_time]} #밑에서 직접설정됨.\n",
    "\n",
    "#         \"optimizer\": {\"values\": ['Adam']}, # ['Adam', 'SGD']\n",
    "\n",
    "#         \"coarse_com_mode\": {\"values\": [True]}, # [True, False]\n",
    "#         \"coarse_com_config\": {\"values\": [(0.999, -0.0)]}, # ['Adam', 'SGD']\n",
    "\n",
    "#         \"sae_l2_norm_bridge\": {\"values\": [True]}, # [True, False]\n",
    "#         \"sae_lif_bridge\": {\"values\": [False]}, # [False, True]\n",
    "        \n",
    "#         \"accuracy_check_epoch_term\": {\"values\": [1]}, \n",
    "\n",
    "#         \"lif_add_at_last\": {\"values\": [False]},# [True, False]\n",
    "\n",
    "#         \"two_channel_input\": {\"values\": [False]},# [True, False]\n",
    "\n",
    "#         \"lateral_feature_num\": {\"values\": [2, 4]},# [True, False]\n",
    "\n",
    "#         \"lc_adc_on\": {\"values\": [False]},# [True, False]\n",
    "        \n",
    "#         \"converted_net_forward\": {\"values\": [False]},# [True, False]\n",
    "\n",
    "#         \"pretrained_net\": {\"values\": [None]},# [None]\n",
    "\n",
    "#         \"vth_mul_on\": {\"values\": [False]},# [True, False]\n",
    "#         \"batch_norm_on\": {\"values\": [False]},# [True, False]\n",
    "\n",
    "#         \"l2_norm_loss_weight\": {\"values\": [0]},\n",
    "\n",
    "#         \"QCFS_neuron_on\": {\"values\": [False]},   # [True, False]\n",
    "\n",
    "#         \"quantize_level_num\": {\"values\": [0]}, \n",
    "\n",
    "#         \"fusion_net\": {\"values\": [True]}, \n",
    "#         \"repeat_coding\": {\"values\": [False]}, \n",
    "\n",
    "#         \"sae_relu_on\": {\"values\": [False]}, \n",
    "\n",
    "#         \"conv1d_scaling\": {\"values\": [False]}, \n",
    "\n",
    "#         \"norm01\": {\"values\": [True]}, \n",
    "\n",
    "#         \"chan_loss_factor\": {\"values\": [0.25,0.5,0.75,1.0,1.25,1.5,1.75,2.0,2.5,3.0,3.5]}, \n",
    "\n",
    "        \n",
    "#      }\n",
    "# }\n",
    "\n",
    "\n",
    "# def hyper_iter():\n",
    "#     ### my_snn control board ########################\n",
    "#     wandb.init(save_code = False)\n",
    "#     gpu  =  '2'\n",
    "#     Conv_net  =  wandb.config.Conv_net\n",
    "#     SAE_net  =  wandb.config.SAE_net\n",
    "\n",
    "#     dataset_num  =  wandb.config.dataset_num\n",
    "#     spike_length  =  wandb.config.spike_length\n",
    "#     num_cluster  =  wandb.config.num_cluster\n",
    "#     training_cycle  =  wandb.config.training_cycle\n",
    "\n",
    "#     batch_size  =  wandb.config.batch_size\n",
    "#     max_epoch  =  wandb.config.max_epoch\n",
    "#     learning_rate  =  wandb.config.learning_rate\n",
    "#     normalize_on  =  wandb.config.normalize_on\n",
    "#     need_bias  =  wandb.config.need_bias\n",
    "\n",
    "#     lif_add_at_first  =  wandb.config.lif_add_at_first\n",
    "#     my_seed  =  wandb.config.my_seed\n",
    "\n",
    "\n",
    "#     TIME  =  wandb.config.TIME\n",
    "#     v_decay  =  wandb.config.v_decay\n",
    "#     v_threshold  =  wandb.config.v_threshold\n",
    "#     v_reset  =  wandb.config.v_reset\n",
    "#     BPTT_on  =  wandb.config.BPTT_on\n",
    "\n",
    "#     SAE_hidden_nomean  =  wandb.config.SAE_hidden_nomean\n",
    "    \n",
    "#     current_time =  datetime.datetime.now().strftime(\"%Y%m%d_%H%M%S\") + f\"_{str(int(datetime.datetime.now().microsecond / 1000)).zfill(3)}\"\n",
    "\n",
    "#     optimizer  =  wandb.config.optimizer\n",
    "\n",
    "#     coarse_com_mode = wandb.config.coarse_com_mode\n",
    "#     coarse_com_config = wandb.config.coarse_com_config # (max, min)\n",
    "\n",
    "#     sae_l2_norm_bridge = wandb.config.sae_l2_norm_bridge\n",
    "#     sae_lif_bridge = wandb.config.sae_lif_bridge\n",
    "\n",
    "#     accuracy_check_epoch_term = wandb.config.accuracy_check_epoch_term\n",
    "\n",
    "#     lif_add_at_last = wandb.config.lif_add_at_last\n",
    "\n",
    "#     two_channel_input = wandb.config.two_channel_input\n",
    "\n",
    "#     lateral_feature_num = wandb.config.lateral_feature_num\n",
    "\n",
    "#     lc_adc_on = wandb.config.lc_adc_on\n",
    "\n",
    "#     converted_net_forward = wandb.config.converted_net_forward\n",
    "\n",
    "#     pretrained_net = wandb.config.pretrained_net\n",
    "\n",
    "#     vth_mul_on = wandb.config.vth_mul_on\n",
    "#     batch_norm_on = wandb.config.batch_norm_on\n",
    "\n",
    "#     l2_norm_loss_weight = wandb.config.l2_norm_loss_weight\n",
    "\n",
    "#     QCFS_neuron_on = wandb.config.QCFS_neuron_on\n",
    "\n",
    "#     quantize_level_num = wandb.config.quantize_level_num\n",
    "\n",
    "#     fusion_net = wandb.config.fusion_net\n",
    "#     repeat_coding = wandb.config.repeat_coding\n",
    "\n",
    "#     sae_relu_on = wandb.config.sae_relu_on\n",
    "\n",
    "#     conv1d_scaling = wandb.config.conv1d_scaling\n",
    "\n",
    "#     norm01 = wandb.config.norm01\n",
    "\n",
    "#     chan_loss_factor = wandb.config.chan_loss_factor\n",
    "\n",
    "#     cluster_train_system( \n",
    "#         gpu = gpu,\n",
    "#         Conv_net = Conv_net,\n",
    "#         SAE_net = SAE_net,\n",
    "\n",
    "#         # hyperparameter\n",
    "#         dataset_num = dataset_num,\n",
    "#         spike_length = spike_length,\n",
    "#         num_cluster = num_cluster,  # 클러스터 수 설정 # 논문엔 4개라는데 여기서는 3개로 했네\n",
    "#         training_cycle = training_cycle, # 그 초기 몇개까지만 cluster update할지\n",
    "\n",
    "\n",
    "#         batch_size = batch_size,\n",
    "#         max_epoch = max_epoch,\n",
    "#         learning_rate = learning_rate,\n",
    "#         normalize_on = normalize_on, # True or False #이거 안 씀 # 이거 별로 안 좋은 normalize같음 # 쓸 거면 다른 거 써라.\n",
    "#         need_bias = need_bias,\n",
    "#         # first_layer_no_train = False\n",
    "#         lif_add_at_first = lif_add_at_first,\n",
    "#         my_seed = my_seed,\n",
    "\n",
    "#         TIME = TIME, # SAE일 때만 유효\n",
    "#         v_decay = v_decay,\n",
    "#         v_threshold = v_threshold,\n",
    "#         v_reset = v_reset, # 10000이상 일 시 hard reset\n",
    "#         BPTT_on = BPTT_on,\n",
    "\n",
    "#         SAE_hidden_nomean = SAE_hidden_nomean,\n",
    "\n",
    "#         current_time = current_time,\n",
    "\n",
    "#         optimizer = optimizer, #'Adam', 'SGD'\n",
    "\n",
    "#         coarse_com_mode = coarse_com_mode,\n",
    "#         coarse_com_config = coarse_com_config, # (max, min)\n",
    "        \n",
    "#         sae_l2_norm_bridge = sae_l2_norm_bridge,\n",
    "#         sae_lif_bridge = sae_lif_bridge,\n",
    "\n",
    "#         accuracy_check_epoch_term = accuracy_check_epoch_term,\n",
    "\n",
    "#         lif_add_at_last = lif_add_at_last,\n",
    "        \n",
    "#         two_channel_input = two_channel_input,\n",
    "        \n",
    "#         lateral_feature_num = lateral_feature_num,\n",
    "\n",
    "#         lc_adc_on = lc_adc_on,\n",
    "\n",
    "#         converted_net_forward = converted_net_forward,\n",
    "\n",
    "#         pretrained_net = pretrained_net,\n",
    "\n",
    "#         vth_mul_on = vth_mul_on,\n",
    "#         batch_norm_on = batch_norm_on,\n",
    "\n",
    "#         l2_norm_loss_weight = l2_norm_loss_weight,\n",
    "\n",
    "#         QCFS_neuron_on = QCFS_neuron_on,\n",
    "\n",
    "#         quantize_level_num = quantize_level_num,\n",
    "\n",
    "#         fusion_net = fusion_net, \n",
    "#         repeat_coding = repeat_coding, \n",
    "\n",
    "#         sae_relu_on = sae_relu_on,\n",
    "\n",
    "#         conv1d_scaling = conv1d_scaling,\n",
    "\n",
    "#         norm01 = norm01,\n",
    "\n",
    "#         chan_loss_factor = chan_loss_factor,\n",
    "#         )\n",
    "    \n",
    "# # sweep_id = 'ygoj9jt4'\n",
    "# sweep_id = wandb.sweep(sweep=sweep_configuration, project=f'spike_sorting {unique_name_hyper} np')\n",
    "# wandb.agent(sweep_id, function=hyper_iter, count=100000, project=f'spike_sorting {unique_name_hyper}')\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wandb.finish() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import matplotlib.pyplot as plt\n",
    "# from matplotlib.ticker import MaxNLocator\n",
    "# import pickle\n",
    "# import json\n",
    "\n",
    "# # current_time = '20250102_225243_972'\n",
    "\n",
    "# with open(f\"result_save/cluster_accuracy_history_{current_time}.pkl\", \"rb\") as f:\n",
    "#     data = pickle.load(f)\n",
    "\n",
    "\n",
    "# # JSON으로 저장\n",
    "# with open(f\"result_save/cluster_accuracy_history_{current_time}.json\", 'r') as f:\n",
    "#     loaded_hyperparameters = json.load(f)\n",
    "\n",
    "# loss_history = data['loss_history']\n",
    "# mean_cluster_accuracy_during_training_cycle_all_dataset_history = data['mean_cluster_accuracy_during_training_cycle_all_dataset_history']\n",
    "# mean_cluster_accuracy_post_training_cycle_all_dataset_history = data['mean_cluster_accuracy_post_training_cycle_all_dataset_history']\n",
    "# mean_cluster_accuracy_total_all_dataset_history = data['mean_cluster_accuracy_total_all_dataset_history']\n",
    "# print(data)\n",
    "# max_acc = 0\n",
    "# for i in mean_cluster_accuracy_post_training_cycle_all_dataset_history:\n",
    "#     if i[1] > max_acc:\n",
    "#         max_acc = i[1]\n",
    "\n",
    "# # 설정 정보 제목 작성\n",
    "# title = (\n",
    "#     f\"Dataset Num: {loaded_hyperparameters['dataset_num']}, Conv {loaded_hyperparameters['Conv_net']}, SAE {loaded_hyperparameters['SAE_net']}, Current time {loaded_hyperparameters['current_time']}, Spike Length: {loaded_hyperparameters['spike_length']}, Num Cluster: {loaded_hyperparameters['num_cluster']}, \"\n",
    "#     f\"Training Cycle: {loaded_hyperparameters['training_cycle']}, Batch Size: {loaded_hyperparameters['batch_size']}, Max Epoch: {loaded_hyperparameters['max_epoch']}, \\n\"\n",
    "#     f\"Learning Rate: {loaded_hyperparameters['learning_rate']}, Input Normalize: {loaded_hyperparameters['normalize_on']}, Need Bias: {loaded_hyperparameters['need_bias']}, \"\n",
    "#     f\"LIF Add at First: {loaded_hyperparameters['lif_add_at_first']}, TIME: {loaded_hyperparameters['TIME']}, Seed: {loaded_hyperparameters['my_seed']}, Best ACC: {max_acc:.2f}%\"\n",
    "# )\n",
    "\n",
    "# # 데이터 리스트와 라벨 설정 (Loss 제외)\n",
    "# data_list = [\n",
    "#     (\"Mean Cluster Accuracy (During Training Cycle)\", mean_cluster_accuracy_during_training_cycle_all_dataset_history),\n",
    "#     (\"Mean Cluster Accuracy (Post Training Cycle)\", mean_cluster_accuracy_post_training_cycle_all_dataset_history),\n",
    "#     (\"Mean Cluster Accuracy (Total)\", mean_cluster_accuracy_total_all_dataset_history),\n",
    "# ]\n",
    "\n",
    "# # 플롯 생성\n",
    "# fig, ax1 = plt.subplots(figsize=(12, 8))\n",
    "\n",
    "# # 첫 번째 y축: Accuracy 관련 데이터\n",
    "# for label, data in data_list:\n",
    "#     epochs, values = zip(*data)  # epoch, value 분리\n",
    "#     ax1.plot(epochs, values, label=label)\n",
    "\n",
    "# ax1.set_xlabel(\"Epoch\")\n",
    "# ax1.set_ylabel(\"Clurstering Accuracy [%]\", color=\"blue\")\n",
    "# ax1.tick_params(axis=\"y\", labelcolor=\"blue\")\n",
    "# ax1.legend(loc=\"center right\")\n",
    "# ax1.grid(True)\n",
    "\n",
    "# # x축을 정수만 표시하도록 설정\n",
    "# ax1.xaxis.set_major_locator(MaxNLocator(integer=True))\n",
    "\n",
    "# # 두 번째 y축: Loss History\n",
    "# ax2 = ax1.twinx()\n",
    "# epochs, values = zip(*loss_history)\n",
    "# ax2.plot(epochs, values, label=\"AE Loss History\", color=\"red\", linestyle=\"--\")\n",
    "# ax2.set_ylabel(\"Loss\", color=\"red\")\n",
    "# ax2.tick_params(axis=\"y\", labelcolor=\"red\")\n",
    "# ax2.legend(loc=\"center left\")\n",
    "\n",
    "# # 제목 추가\n",
    "# plt.title(title, fontsize=10)\n",
    "# plt.tight_layout()\n",
    "# plt.savefig(f'net_save/{current_time}', dpi=300, bbox_inches=\"tight\")  # dpi=300은 고해상도로 저장, bbox_inches=\"tight\"는 여백 최소화\n",
    "# plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "\n",
    "def create_image_grid(image_paths, grid_size=(4, 4)):\n",
    "    \"\"\"\n",
    "    여러 개의 이미지를 4x4 그리드로 병합하여 저장하는 함수.\n",
    "\n",
    "    Parameters:\n",
    "        image_paths (list of str): 불러올 이미지 경로 리스트 (16개 필요).\n",
    "        grid_size (tuple): (rows, cols) 형태의 그리드 크기 (기본값: (4, 4)).\n",
    "        save_path (str): 저장할 파일 경로.\n",
    "\n",
    "    Returns:\n",
    "        None\n",
    "    \"\"\"\n",
    "    rows, cols = grid_size\n",
    "    assert len(image_paths) == rows * cols, f\"Need {rows * cols} images, but got {len(image_paths)}\"\n",
    "\n",
    "    # 이미지 불러오기\n",
    "    images = [Image.open(img_path) for img_path in image_paths]\n",
    "\n",
    "    # 모든 이미지 크기 맞추기 (첫 번째 이미지 기준)\n",
    "    img_width, img_height = images[0].size\n",
    "    new_image = Image.new(\"RGB\", (cols * img_width, rows * img_height))\n",
    "\n",
    "    # 이미지 붙이기\n",
    "    for i, img in enumerate(images):\n",
    "        x_offset = (i % cols) * img_width\n",
    "        y_offset = (i // cols) * img_height\n",
    "        new_image.paste(img, (x_offset, y_offset))\n",
    "\n",
    "    # 시각화\n",
    "    plt.figure(figsize=(32, 32))\n",
    "    plt.imshow(new_image)\n",
    "    plt.axis(\"off\")\n",
    "    plt.show()\n",
    "\n",
    "# 사용 예시\n",
    "    \n",
    "\n",
    "spike_tot = [\"BH_Spike_e1n005.npy\", \"BH_Spike_e1n010.npy\", \"BH_Spike_e1n015.npy\", \"BH_Spike_e1n020.npy\",\n",
    "            \"BH_Spike_e2n005.npy\", \"BH_Spike_e2n010.npy\", \"BH_Spike_e2n015.npy\", \"BH_Spike_e2n020.npy\",\n",
    "            \"BH_Spike_d1n005.npy\", \"BH_Spike_d1n010.npy\", \"BH_Spike_d1n015.npy\", \"BH_Spike_d1n020.npy\",\n",
    "            \"BH_Spike_d2n005.npy\", \"BH_Spike_d2n010.npy\", \"BH_Spike_d2n015.npy\", \"BH_Spike_d2n020.npy\"]\n",
    "image_paths = [f\"/home/bhkim003/github_folder/ByeonghyeonKim/my_snn/picture/{spike_tot[i]}.png\" for i in range(len(spike_tot))]  # 저장된 16개의 이미지\n",
    "create_image_grid(image_paths, grid_size=(4, 4))\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aedat2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
