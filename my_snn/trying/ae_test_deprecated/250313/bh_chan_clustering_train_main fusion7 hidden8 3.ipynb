{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ssp.train.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x600 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import torch   \n",
    "import torch.nn as nn \n",
    "import torch.nn.functional as F   \n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import torch.optim as optim\n",
    "from scipy import io\n",
    "import itertools\n",
    "import math\n",
    "import datetime\n",
    "import wandb\n",
    "import pickle\n",
    "import json\n",
    "import time\n",
    "import sys\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import accuracy_score\n",
    "from scipy.optimize import linear_sum_assignment\n",
    "from snntorch import spikegen\n",
    "\n",
    "\n",
    "# my module import\n",
    "from modules import *\n",
    "\n",
    "# modules 폴더에 새모듈.py 만들면\n",
    "# modules/__init__py 파일에 form .새모듈 import * 하셈\n",
    "# 그리고 새모듈.py에서 from modules.새모듈 import * 하셈"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cluster_train_system( \n",
    "    gpu = '4',\n",
    "    Conv_net = True,\n",
    "    SAE_net = True,\n",
    "\n",
    "    # hyperparameter\n",
    "    dataset_num = 16,\n",
    "    spike_length = 50,\n",
    "    num_cluster = 4,  # 클러스터 수 설정 # 논문엔 4개라는데 여기서는 3개로 했네\n",
    "    training_cycle = 2400, # 그 초기 몇개까지만 cluster update할지\n",
    "\n",
    "\n",
    "    batch_size = 32,\n",
    "    max_epoch = 7000,\n",
    "    learning_rate = 0.001,\n",
    "    normalize_on = False, # True or False #이거 안 씀 # 이거 별로 안 좋은 normalize같음 # 쓸 거면 다른 거 써라.\n",
    "    need_bias = False,\n",
    "    # first_layer_no_train = False\n",
    "    lif_add_at_first = False,\n",
    "    my_seed = 42,\n",
    "\n",
    "    TIME = 10, # SAE일 때만 유효\n",
    "    v_decay = 0.5,\n",
    "    v_threshold = 0.5,\n",
    "    v_reset = 10000.0, # 10000이상 일 시 hard reset\n",
    "    BPTT_on = True,\n",
    "\n",
    "    SAE_hidden_nomean = True,\n",
    "    current_time = '20250101_210938_786',\n",
    "\n",
    "    optimizer = 'Adam',\n",
    "    coarse_com_mode = True,\n",
    "    coarse_com_config = (2.0, -2.0), # (max, min)\n",
    "\n",
    "    sae_l2_norm_bridge = True,\n",
    "    sae_lif_bridge = False,\n",
    "\n",
    "    accuracy_check_epoch_term = 5,\n",
    "    \n",
    "    lif_add_at_last = False,\n",
    "\n",
    "    two_channel_input = False,\n",
    "\n",
    "    lateral_feature_num = 4,\n",
    "\n",
    "    lc_adc_on = False, \n",
    "\n",
    "    converted_net_forward = False,\n",
    "\n",
    "    pretrained_net = None, \n",
    "\n",
    "    vth_mul_on = False,\n",
    "    batch_norm_on = False,\n",
    "\n",
    "    l2_norm_loss_weight = 0.0,\n",
    "\n",
    "    QCFS_neuron_on = False,\n",
    "\n",
    "    quantize_level_num = 0,\n",
    "\n",
    "    fusion_net = False, # True False\n",
    "    repeat_coding = False,\n",
    "    \n",
    "    sae_relu_on = False,\n",
    "\n",
    "    conv1d_scaling = False,\n",
    "\n",
    "    norm01 = True,\n",
    "    ):\n",
    "    if coarse_com_mode == True:\n",
    "        assert coarse_com_config[0] > coarse_com_config[1], 'coarse_com_config[0] > coarse_com_config[1]이어야 함'\n",
    "        assert converted_net_forward == False\n",
    "        # assert SAE_net == True, 'coarse_com_mode는 SAE_net이 True일 때만 가능'\n",
    "    if two_channel_input == True:\n",
    "        assert Conv_net and coarse_com_mode, 'two_channel_input는 Conv_net이 True일 때만 가능'\n",
    "    if lc_adc_on == True:\n",
    "        assert coarse_com_mode and SAE_net, 'lc_adc_on은 coarse_com_mode와 SAE_net이 True일 때만 가능'\n",
    "    if converted_net_forward == True:\n",
    "        assert SAE_net == False, 'converted_net_forward는 SAE_net이 False일 때만 가능'\n",
    "    if conv1d_scaling:\n",
    "        assert Conv_net and coarse_com_mode and normalize_on\n",
    "    seed_assign(my_seed)\n",
    "    ## 함수 내 모든 로컬 변수 저장 ########################################################\n",
    "    hyperparameters = locals()\n",
    "    print(hyperparameters)\n",
    "    # JSON으로 저장\n",
    "    with open(f\"result_save/cluster_accuracy_history_{current_time}.json\", 'w') as f:\n",
    "        json.dump(hyperparameters, f, indent=4)\n",
    "    ######################################################################################\n",
    "\n",
    "    \n",
    "    wandb.config.update(hyperparameters)\n",
    "    wandb.run.name = f'{current_time}_SAE_net_{SAE_net}_v_threshold_{v_threshold}'\n",
    "    wandb.define_metric(\"best_mean_cluster_accuracy_post_training_cycle_all_dataset2\", summary=\"max\")\n",
    "\n",
    "\n",
    "    my_path_ground_BH = '/data2/spike_sorting/quiroga/BH/'\n",
    "\n",
    "\n",
    "    filename = [\"C_Easy1_noise005.mat\", \"C_Easy1_noise01.mat\", \"C_Easy1_noise015.mat\", \"C_Easy1_noise02.mat\",\n",
    "                \"C_Easy2_noise005.mat\", \"C_Easy2_noise01.mat\", \"C_Easy2_noise015.mat\", \"C_Easy2_noise02.mat\",\n",
    "                \"C_Difficult1_noise005.mat\", \"C_Difficult1_noise01.mat\", \"C_Difficult1_noise015.mat\", \"C_Difficult1_noise02.mat\",\n",
    "                \"C_Difficult2_noise005.mat\", \"C_Difficult2_noise01.mat\", \"C_Difficult2_noise015.mat\", \"C_Difficult2_noise02.mat\"]\n",
    "\n",
    "\n",
    "    spike_tot = [\"BH_Spike_e1n005.npy\", \"BH_Spike_e1n010.npy\", \"BH_Spike_e1n015.npy\", \"BH_Spike_e1n020.npy\",\n",
    "                \"BH_Spike_e2n005.npy\", \"BH_Spike_e2n010.npy\", \"BH_Spike_e2n015.npy\", \"BH_Spike_e2n020.npy\",\n",
    "                \"BH_Spike_d1n005.npy\", \"BH_Spike_d1n010.npy\", \"BH_Spike_d1n015.npy\", \"BH_Spike_d1n020.npy\",\n",
    "                \"BH_Spike_d2n005.npy\", \"BH_Spike_d2n010.npy\", \"BH_Spike_d2n015.npy\", \"BH_Spike_d2n020.npy\"]\n",
    "\n",
    "    label_tot = [\"BH_Label_e1n005.npy\", \"BH_Label_e1n010.npy\", \"BH_Label_e1n015.npy\", \"BH_Label_e1n020.npy\",\n",
    "                \"BH_Label_e2n005.npy\", \"BH_Label_e2n010.npy\", \"BH_Label_e2n015.npy\", \"BH_Label_e2n020.npy\",\n",
    "                \"BH_Label_d1n005.npy\", \"BH_Label_d1n010.npy\", \"BH_Label_d1n015.npy\", \"BH_Label_d1n020.npy\",\n",
    "                \"BH_Label_d2n005.npy\", \"BH_Label_d2n010.npy\", \"BH_Label_d2n015.npy\", \"BH_Label_d2n020.npy\"]\n",
    "\n",
    "    template =  [\"BH_Spike_TEMPLATE_e1n005.npy\", \"BH_Spike_TEMPLATE_e1n010.npy\", \"BH_Spike_TEMPLATE_e1n015.npy\", \"BH_Spike_TEMPLATE_e1n020.npy\",\n",
    "                \"BH_Spike_TEMPLATE_e2n005.npy\", \"BH_Spike_TEMPLATE_e2n010.npy\", \"BH_Spike_TEMPLATE_e2n015.npy\", \"BH_Spike_TEMPLATE_e2n020.npy\",\n",
    "                \"BH_Spike_TEMPLATE_d1n005.npy\", \"BH_Spike_TEMPLATE_d1n010.npy\", \"BH_Spike_TEMPLATE_d1n015.npy\", \"BH_Spike_TEMPLATE_d1n020.npy\",\n",
    "                \"BH_Spike_TEMPLATE_d2n005.npy\", \"BH_Spike_TEMPLATE_d2n010.npy\", \"BH_Spike_TEMPLATE_d2n015.npy\", \"BH_Spike_TEMPLATE_d2n020.npy\"]\n",
    "\n",
    "    AE_train_path_gt_detect = 'BH_quiroga_training_dataset_gt_detect.pt' \n",
    "    AE_test_path_gt_detect = 'BH_quiroga_test_dataset_gt_detect.pt'\n",
    "\n",
    "    AE_train_path_real_detect = 'BH_quiroga_training_dataset_real_detect.pt'\n",
    "    AE_test_path_real_detect = 'BH_quiroga_test_dataset_real_detect.pt'\n",
    "\n",
    "    AE_train_data = AE_train_path_real_detect #AE_train_path_gt_detect #AE_train_path_real_detect\n",
    "    AE_test_data = AE_test_path_real_detect #AE_test_path_gt_detect  #AE_test_path_real_detect\n",
    "\n",
    "    # thr_tot = np.array([0.5, 0.5, 0.55, 0.7, 0.5, 0.5, 0.55, 0.7, 0.5, 0.5, 0.55, 0.7, 0.5, 0.5, 0.55, 0.7])\n",
    "    cos_thr = np.array([0.95, 0.95, 0.95, 0.95, 0.95, 0.95, 0.95, 0.85, 0.95, 0.9, 0.8, 0.95, 0.95, 0.95, 0.95, 0.8])\n",
    "    # tem=10\n",
    "    # cos_thr = np.array([tem, tem, tem, tem, tem, tem, tem, tem, tem, tem, tem, tem, tem, tem, tem, tem, ])\n",
    "\n",
    "    print('cos_thr', cos_thr)\n",
    "    \n",
    "    os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\" \n",
    "    os.environ[\"CUDA_VISIBLE_DEVICES\"]= gpu\n",
    "\n",
    "\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "\n",
    "    if coarse_com_mode == True:\n",
    "        level_num = TIME\n",
    "        TIME = spike_length\n",
    "        spike_length = level_num\n",
    "        level_interval = (coarse_com_config[0] - coarse_com_config[1]) / (level_num-1)  # max - min\n",
    "        levels = [coarse_com_config[1] + level_interval * i for i in range(level_num)]\n",
    "        levels = torch.tensor(levels).to(torch.float).to(device)\n",
    "        levels = levels.repeat(TIME,1) \n",
    "        # print('levels', levels, levels.shape) # TIME, level_num\n",
    "\n",
    "    n_sample = spike_length\n",
    "\n",
    "    class spikedataset(Dataset):\n",
    "        def __init__(self, path, transform = None):    \n",
    "            self.transform = transform\n",
    "            self.spike = torch.load(path)\n",
    "            \n",
    "        def __getitem__(self, index):\n",
    "            spike = self.spike[index]            \n",
    "            if self.transform is not None:\n",
    "                spike = self.transform(spike)\n",
    "            return spike\n",
    "        \n",
    "        def __len__(self):\n",
    "            return len(self.spike)\n",
    "\n",
    "    train_dataset = spikedataset(my_path_ground_BH + AE_train_data)\n",
    "    train_loader = DataLoader(dataset = train_dataset, batch_size = batch_size, shuffle = True)\n",
    "\n",
    "    test_dataset = spikedataset(my_path_ground_BH + AE_test_data)\n",
    "    test_loader = DataLoader(dataset = test_dataset, batch_size = batch_size, shuffle = False)\n",
    "\n",
    "\n",
    "    # vth_mul_on = True # True False\n",
    "    # batch_norm_on = True # True False\n",
    "\n",
    "\n",
    "    # 모델 초기화\n",
    "    if SAE_net == False: # 여기서는 l2norm, lif bridge 둘 다 true면 l2norm먼저\n",
    "        assert two_channel_input == False\n",
    "\n",
    "        if Conv_net == True:\n",
    "            # input_channels = 2 if two_channel_input else 1\n",
    "            input_channels = TIME if coarse_com_mode else 1\n",
    "            if fusion_net == True:\n",
    "                assert False, '이거 맞음? 다시 확인'\n",
    "                net = FUSION_net_conv1(input_channels=input_channels, input_length=n_sample, encoder_ch = [32, 64, 96], fc_dim = lateral_feature_num, padding = 0, stride = 2, kernel_size = 3, \n",
    "                                    synapse_fc_trace_const1=1, \n",
    "                                    synapse_fc_trace_const2=v_decay, #안씀 \n",
    "                                    TIME=TIME, v_init=0.0, v_decay=v_decay, v_threshold=v_threshold, v_reset=v_reset, \n",
    "                                    sg_width=4.0, surrogate='sigmoid', BPTT_on=BPTT_on, need_bias=need_bias, lif_add_at_first=lif_add_at_first,\n",
    "                                    sae_l2_norm_bridge = sae_l2_norm_bridge, sae_lif_bridge = sae_lif_bridge, lif_add_at_last=lif_add_at_last, repeat_coding=repeat_coding).to(device)\n",
    "            else: \n",
    "                net = Autoencoder_conv1(input_channels=input_channels, input_length=n_sample, encoder_ch = [32, 64, 96], fc_dim = lateral_feature_num, padding = 0, stride = 2, kernel_size = 3, need_bias=need_bias, l2norm_bridge=sae_l2_norm_bridge, relu_bridge=sae_lif_bridge, activation_collector_on=False,\n",
    "                                        batch_norm_on=batch_norm_on, QCFS_neuron_on=QCFS_neuron_on).to(device)\n",
    "            net = torch.nn.DataParallel(net)\n",
    "            if converted_net_forward:\n",
    "                converted_net = SAE_converted_conv1(input_channels=input_channels, input_length=n_sample, encoder_ch = [32, 64, 96], fc_dim = lateral_feature_num, padding = 0, stride = 2, kernel_size = 3, \n",
    "                                    synapse_fc_trace_const1=1, \n",
    "                                    synapse_fc_trace_const2=v_decay, #안씀 \n",
    "                                    TIME=TIME, v_init=0.0, v_decay=v_decay, v_threshold=v_threshold, v_reset=v_reset, \n",
    "                                    sg_width=4.0, surrogate='sigmoid', BPTT_on=BPTT_on, need_bias=need_bias, lif_add_at_first=lif_add_at_first,\n",
    "                                    sae_l2_norm_bridge = sae_l2_norm_bridge, sae_lif_bridge = sae_lif_bridge, lif_add_at_last=lif_add_at_last,\n",
    "                                    vth_mul_on=vth_mul_on, batch_norm_on=batch_norm_on).to(device) # lif bridge는 무조건 들어가게 해놨음.\n",
    "                converted_net = torch.nn.DataParallel(converted_net)\n",
    "                print('converted_net', converted_net)\n",
    "        else:\n",
    "            n_sample = n_sample * TIME if coarse_com_mode else n_sample\n",
    "            net = Autoencoder_only_FC(encoder_ch=[400, lateral_feature_num], decoder_ch=[400,n_sample], n_sample=n_sample, need_bias=need_bias, l2norm_bridge=sae_l2_norm_bridge, relu_bridge=sae_lif_bridge, activation_collector_on=False,\n",
    "                                    batch_norm_on=batch_norm_on, QCFS_neuron_on=QCFS_neuron_on).to(device)\n",
    "            net = torch.nn.DataParallel(net)\n",
    "            if converted_net_forward:\n",
    "                converted_net = SAE_converted_fc(encoder_ch=[400, lateral_feature_num], \n",
    "                                    decoder_ch=[400, n_sample], \n",
    "                                    in_channels=n_sample, # in_channel 이 여기선 걍 lenght.\n",
    "                                    synapse_fc_trace_const1=1,\n",
    "                                    synapse_fc_trace_const2=v_decay,  #안씀 \n",
    "                                    TIME=TIME, v_init=0.0, v_decay=v_decay, v_threshold=v_threshold, v_reset=v_reset, \n",
    "                                    sg_width=4.0, surrogate='sigmoid', BPTT_on=BPTT_on, need_bias=need_bias, lif_add_at_first=lif_add_at_first,\n",
    "                                    sae_l2_norm_bridge = sae_l2_norm_bridge, sae_lif_bridge = sae_lif_bridge, lif_add_at_last=lif_add_at_last,\n",
    "                                    vth_mul_on=vth_mul_on, batch_norm_on=batch_norm_on).to(device) # lif bridge는 무조건 들어가게 해놨음.\n",
    "                converted_net = torch.nn.DataParallel(converted_net)\n",
    "                # print('converted_net', converted_net)\n",
    "    else:\n",
    "        if Conv_net == True: \n",
    "            input_channels = 1\n",
    "            input_channels = 2 if two_channel_input else 1\n",
    "            if fusion_net == True:  \n",
    "                assert coarse_com_mode == True\n",
    "                # net = SAE_FUSION2_net_conv1(input_channels=input_channels, input_length=n_sample, encoder_ch = [32, 64, 96], fc_dim = lateral_feature_num, padding = 0, stride = 2, kernel_size = 3, \n",
    "                #                     synapse_fc_trace_const1=1, \n",
    "                #                     synapse_fc_trace_const2=v_decay, #안씀 \n",
    "                #                     TIME=TIME, v_init=0.0, v_decay=v_decay, v_threshold=v_threshold, v_reset=v_reset, \n",
    "                #                     sg_width=4.0, surrogate='sigmoid', BPTT_on=BPTT_on, need_bias=need_bias, lif_add_at_first=lif_add_at_first,\n",
    "                #                     sae_l2_norm_bridge = sae_l2_norm_bridge, sae_lif_bridge = sae_lif_bridge, lif_add_at_last=lif_add_at_last, batch_norm_on=batch_norm_on, sae_relu_on=sae_relu_on).to(device)\n",
    "                # net = SAE_FUSION3_net_conv1(input_channels=input_channels, input_length=n_sample, encoder_ch = [32, 64, 96], fc_dim = lateral_feature_num, padding = 0, stride = 2, kernel_size = 3, \n",
    "                #                     synapse_fc_trace_const1=1, \n",
    "                #                     synapse_fc_trace_const2=v_decay, #안씀 \n",
    "                #                     TIME=TIME, v_init=0.0, v_decay=v_decay, v_threshold=v_threshold, v_reset=v_reset, \n",
    "                #                     sg_width=4.0, surrogate='sigmoid', BPTT_on=BPTT_on, need_bias=need_bias, lif_add_at_first=lif_add_at_first,\n",
    "                #                     sae_l2_norm_bridge = sae_l2_norm_bridge, sae_lif_bridge = sae_lif_bridge, lif_add_at_last=lif_add_at_last, batch_norm_on=batch_norm_on, sae_relu_on=sae_relu_on).to(device)\n",
    "                # net = SAE_FUSION4_net_conv1(input_channels=input_channels, input_length=n_sample, encoder_ch = [32, 64, 96], fc_dim = lateral_feature_num, padding = 0, stride = 2, kernel_size = 3, \n",
    "                #                     synapse_fc_trace_const1=1, \n",
    "                #                     synapse_fc_trace_const2=v_decay, #안씀 \n",
    "                #                     TIME=TIME, v_init=0.0, v_decay=v_decay, v_threshold=v_threshold, v_reset=v_reset, \n",
    "                #                     sg_width=4.0, surrogate='sigmoid', BPTT_on=BPTT_on, need_bias=need_bias, lif_add_at_first=lif_add_at_first,\n",
    "                #                     sae_l2_norm_bridge = sae_l2_norm_bridge, sae_lif_bridge = sae_lif_bridge, lif_add_at_last=lif_add_at_last, batch_norm_on=batch_norm_on, sae_relu_on=sae_relu_on).to(device)\n",
    "                # net = SAE_FUSION5_net_conv1(input_channels=input_channels, input_length=n_sample, encoder_ch = [32, 64, 96], fc_dim = lateral_feature_num, padding = 0, stride = 2, kernel_size = 3, \n",
    "                #                     synapse_fc_trace_const1=1, \n",
    "                #                     synapse_fc_trace_const2=v_decay, #안씀 \n",
    "                #                     TIME=TIME, v_init=0.0, v_decay=v_decay, v_threshold=v_threshold, v_reset=v_reset, \n",
    "                #                     sg_width=4.0, surrogate='sigmoid', BPTT_on=BPTT_on, need_bias=need_bias, lif_add_at_first=lif_add_at_first,\n",
    "                #                     sae_l2_norm_bridge = sae_l2_norm_bridge, sae_lif_bridge = sae_lif_bridge, lif_add_at_last=lif_add_at_last, batch_norm_on=batch_norm_on, sae_relu_on=sae_relu_on).to(device)\n",
    "                # net = SAE_FUSION6_net_conv1(input_channels=input_channels, input_length=n_sample, encoder_ch = [32, 64, 96], fc_dim = lateral_feature_num, padding = 0, stride = 2, kernel_size = 3, \n",
    "                #                     synapse_fc_trace_const1=1, \n",
    "                #                     synapse_fc_trace_const2=v_decay, #안씀 \n",
    "                #                     TIME=TIME, v_init=0.0, v_decay=v_decay, v_threshold=v_threshold, v_reset=v_reset, \n",
    "                #                     sg_width=4.0, surrogate='sigmoid', BPTT_on=BPTT_on, need_bias=need_bias, lif_add_at_first=lif_add_at_first,\n",
    "                #                     sae_l2_norm_bridge = sae_l2_norm_bridge, sae_lif_bridge = sae_lif_bridge, lif_add_at_last=lif_add_at_last, batch_norm_on=batch_norm_on, sae_relu_on=sae_relu_on).to(device)\n",
    "                net = SAE_FUSION7_net_conv1(input_channels=input_channels, input_length=n_sample, encoder_ch = [32, 64, 96], fc_dim = lateral_feature_num, padding = 0, stride = 2, kernel_size = 3, \n",
    "                                    synapse_fc_trace_const1=1, \n",
    "                                    synapse_fc_trace_const2=v_decay, #안씀 \n",
    "                                    TIME=TIME, v_init=0.0, v_decay=v_decay, v_threshold=v_threshold, v_reset=v_reset, \n",
    "                                    sg_width=4.0, surrogate='sigmoid', BPTT_on=BPTT_on, need_bias=need_bias, lif_add_at_first=lif_add_at_first,\n",
    "                                    sae_l2_norm_bridge = sae_l2_norm_bridge, sae_lif_bridge = sae_lif_bridge, lif_add_at_last=lif_add_at_last, batch_norm_on=batch_norm_on, sae_relu_on=sae_relu_on).to(device)\n",
    "            else:\n",
    "                net = SAE_conv1(input_channels=input_channels, input_length=n_sample, encoder_ch = [32, 64, 96], fc_dim = lateral_feature_num, padding = 0, stride = 2, kernel_size = 3, \n",
    "                                    synapse_fc_trace_const1=1, \n",
    "                                    synapse_fc_trace_const2=v_decay, #안씀 \n",
    "                                    TIME=TIME, v_init=0.0, v_decay=v_decay, v_threshold=v_threshold, v_reset=v_reset, \n",
    "                                    sg_width=4.0, surrogate='sigmoid', BPTT_on=BPTT_on, need_bias=need_bias, lif_add_at_first=lif_add_at_first,\n",
    "                                    sae_l2_norm_bridge = sae_l2_norm_bridge, sae_lif_bridge = sae_lif_bridge, lif_add_at_last=lif_add_at_last, batch_norm_on=batch_norm_on, sae_relu_on=sae_relu_on).to(device)\n",
    "            # net = SAE_conv1_DR(input_channels=input_channels, input_length=n_sample, encoder_ch = [32, 64, 96], fc_dim = lateral_feature_num, padding = 0, stride = 2, kernel_size = 3, \n",
    "            #                     synapse_fc_trace_const1=1, \n",
    "            #                     synapse_fc_trace_const2=v_decay, #안씀 \n",
    "            #                     TIME=TIME, v_init=0.0, v_decay=v_decay, v_threshold=v_threshold, v_reset=v_reset, \n",
    "            #                     sg_width=4.0, surrogate='sigmoid', BPTT_on=BPTT_on, need_bias=need_bias, lif_add_at_first=lif_add_at_first,\n",
    "            #                     sae_l2_norm_bridge = sae_l2_norm_bridge, sae_lif_bridge = sae_lif_bridge, lif_add_at_last=lif_add_at_last, batch_norm_on=batch_norm_on).to(device)\n",
    "            net = torch.nn.DataParallel(net)\n",
    "        else:\n",
    "            net = SAE_fc_only(encoder_ch=[400, lateral_feature_num], \n",
    "                                decoder_ch=[400, n_sample], \n",
    "                                in_channels=n_sample, # in_channel 이 여기선 걍 lenght.\n",
    "                                synapse_fc_trace_const1=1,\n",
    "                                synapse_fc_trace_const2=v_decay,  #안씀 \n",
    "                                TIME=TIME, v_init=0.0, v_decay=v_decay, v_threshold=v_threshold, v_reset=v_reset, \n",
    "                                sg_width=4.0, surrogate='sigmoid', BPTT_on=BPTT_on, need_bias=need_bias, lif_add_at_first=lif_add_at_first,\n",
    "                                sae_l2_norm_bridge = sae_l2_norm_bridge, sae_lif_bridge = sae_lif_bridge, lif_add_at_last=lif_add_at_last, batch_norm_on=batch_norm_on, sae_relu_on=sae_relu_on).to(device)\n",
    "            net = torch.nn.DataParallel(net)\n",
    "\n",
    "    # net = torch.load('/home/bhkim003/github_folder/ByeonghyeonKim/my_snn/net_save/save_now_net_AE_re_e7000.pth')\n",
    "    # net = torch.load('/home/bhkim003/github_folder/ByeonghyeonKim/my_snn/net_save/save_now_net_20250101_210938_786.pth')\n",
    "    # load했으면 torch.nn.DataParallel 하지마\n",
    "    # net.module.load_state_dict(torch.load('/home/bhkim003/github_folder/ByeonghyeonKim/my_snn/net_save/save_now_net_annbase_20250108_210641_941.pth'))\n",
    "    if pretrained_net != None:\n",
    "        ######################## 모델이 달라서 dict로 weight만 넣고싶을 때\n",
    "        # # 저장된 가중치 로드\n",
    "        saved_state_dict = torch.load(pretrained_net)\n",
    "        current_state_dict = net.module.state_dict()\n",
    "\n",
    "        # 함수 호출로 가중치 매핑\n",
    "        updated_state_dict = map_and_load_weights(saved_state_dict, current_state_dict)\n",
    "\n",
    "        # 업데이트된 state_dict를 네트워크에 로드\n",
    "        net.module.load_state_dict(updated_state_dict)\n",
    "        ######################## 모델이 달라서 dict로 weight만 넣고싶을 때\n",
    "\n",
    "        ############## 일반적일 때\n",
    "        # net.module.load_state_dict(torch.load(pretrained_net))\n",
    "        ############## 일반적일 때\n",
    "    \n",
    "        # pre_net = Autoencoder_conv1(input_channels=input_channels, input_length=n_sample, encoder_ch = [32, 64, 96], fc_dim = lateral_feature_num, padding = 0, stride = 2, kernel_size = 3, need_bias=need_bias, l2norm_bridge=sae_l2_norm_bridge, relu_bridge=sae_lif_bridge, activation_collector_on=False,\n",
    "        #                         batch_norm_on=batch_norm_on, QCFS_neuron_on=False).to(device)\n",
    "        # pre_net = torch.nn.DataParallel(net)\n",
    "        # pre_net.module.load_state_dict(torch.load(pretrained_net))\n",
    "        # copy_weights(pre_net.module.encoder , net.module.encoder )\n",
    "        # copy_weights(pre_net.module.decoder , net.module.decoder  )\n",
    "\n",
    "        \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    wandb.watch(net, log=\"all\", log_freq = 10)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    if SAE_net == True:\n",
    "        assert 'SAE' in net.module.__class__.__name__\n",
    "\n",
    "\n",
    "\n",
    "    net = net.to(device)\n",
    "    print(f\"Total number of encoder parameters: {sum(p.numel() for p in net.module.encoder.parameters())}\")\n",
    "    print(net)\n",
    "    print('Device:',device)\n",
    "\n",
    "    \n",
    "    if optimizer == 'Adam':\n",
    "        optimizer = optim.Adam(net.parameters(), lr=learning_rate)\n",
    "    elif optimizer == 'SGD':\n",
    "        optimizer = optim.SGD(net.parameters(), lr = learning_rate, momentum = 0.9)\n",
    "    else:\n",
    "        assert False, 'optimizer를 잘못 입력했습니다.'\n",
    "        \n",
    "    loss_history = []\n",
    "    mean_cluster_accuracy_during_training_cycle_all_dataset_history = []\n",
    "    mean_cluster_accuracy_post_training_cycle_all_dataset_history = []\n",
    "    mean_cluster_accuracy_total_all_dataset_history = []\n",
    "\n",
    "    tau = np.zeros(num_cluster)\n",
    "\n",
    "    print(f\"\\nStart Training, current_time = {current_time}\")\n",
    "    mean_cluster_accuracy_post_training_cycle_all_dataset = 0\n",
    "    best_mean_cluster_accuracy_post_training_cycle_all_dataset = 0\n",
    "\n",
    "    if SAE_net == True:\n",
    "        assert 'SAE' in net.module.__class__.__name__\n",
    "        \n",
    "    k_means_acc_best = 0\n",
    "    min_loss = 9999999\n",
    "    min_loss_normal = 9999999\n",
    "    min_loss_coarse = 9999999\n",
    "    for epoch in range(max_epoch):\n",
    "        print()\n",
    "        l2_loss_bin= 0\n",
    "        ae_train_start_time = time.time()\n",
    "        running_loss = 0.0\n",
    "        running_loss_normal = 0.0\n",
    "        running_loss_coarse = 0.0\n",
    "        iter = 0\n",
    "        net.train()\n",
    "        # if True or max_epoch != 1:\n",
    "        wrong_element_sum = 0\n",
    "        same_data_num = 0\n",
    "        total_data_num = 0\n",
    "        if max_epoch != 1:\n",
    "            for data in train_loader:\n",
    "                optimizer.zero_grad()\n",
    "                total_data_num += len(data)\n",
    "                data = data.to(device)\n",
    "                scaling = (level_num-3)/level_num if conv1d_scaling else 1.0\n",
    "                data = zero_to_one_normalize_features(data, level_num=quantize_level_num, coarse_com_config=coarse_com_config, scaling=scaling, norm01=norm01) if normalize_on else data\n",
    "                # plot_origin_spike(data[0].cpu().detach().numpy(), min_max_y_on = True)\n",
    "                # plot_origin_spike(data[1].cpu().detach().numpy(), min_max_y_on = True)\n",
    "                spike_backup = data\n",
    "                spike = data\n",
    "                spike = spike.to(device) # batch, feature\n",
    "                spike_for_fusion2_net = spike\n",
    "                if coarse_com_mode == True and 'SAE' in net.module.__class__.__name__:\n",
    "                    # print(spike[0])\n",
    "                    spike = spike.unsqueeze(2).repeat(1, 1, level_num) # spike_length == level_num # (batch, time, feature)로 변환 \n",
    "                    spike = (spike > levels).to(torch.float) \n",
    "\n",
    "                    spike = (spike == 0).cumsum(dim=-1).eq(1).to(torch.float) if lc_adc_on == True else spike\n",
    "\n",
    "                    # spike: batch, time, level_num\n",
    "                    # levels: time, level_num\n",
    "                    if Conv_net == True:\n",
    "                        spike = spike.unsqueeze(-2) # batch, time, in_channel, feature or batch in_channel,feature\n",
    "                        if two_channel_input == True:\n",
    "                            spike_backup = spike_backup.to(device)\n",
    "                            spike_backup = spike_backup.unsqueeze(2).repeat(1, 1, level_num) # spike_length == level_num # (batch, time, feature)로 변환 \n",
    "                            spike_backup = (spike_backup <= levels).to(torch.float) \n",
    "                            spike_backup = (spike_backup == 1).cumsum(dim=-1).eq(1).to(torch.float) if lc_adc_on == True else spike_backup\n",
    "                            spike_backup = spike_backup.unsqueeze(-2)\n",
    "                            spike = torch.cat((spike, spike_backup), dim=-2)\n",
    "                    assert spike.shape[0] == batch_size and spike.shape[1] == TIME\n",
    "                elif 'SAE' in net.module.__class__.__name__:\n",
    "                    spike = spike.unsqueeze(-1).repeat(1, 1, TIME).permute(0,2,1) # (batch, time, feature)로 변환\n",
    "                    if Conv_net == True:\n",
    "                        spike = spike.unsqueeze(-2) # batch, time, in_channel, feature or batch in_channel,feature\n",
    "                else:\n",
    "                    if Conv_net == True:\n",
    "                        if coarse_com_mode == False:\n",
    "                            spike = spike.unsqueeze(-2) #batch in_channel,feature\n",
    "                        else:\n",
    "                            spike = spike.unsqueeze(2).repeat(1, 1, level_num) # spike_length == level_num # (batch, time, feature)로 변환 \n",
    "                            spike = (spike > levels).to(torch.float) \n",
    "\n",
    "                            spike = (spike == 0).cumsum(dim=-1).eq(1).to(torch.float) if lc_adc_on == True else spike\n",
    "\n",
    "                    else:\n",
    "                        if coarse_com_mode == False:\n",
    "                            pass\n",
    "                        else:\n",
    "                            spike = spike.unsqueeze(2).repeat(1, 1, level_num) # spike_length == level_num # (batch, time, feature)로 변환 \n",
    "                            spike = (spike > levels).to(torch.float) \n",
    "\n",
    "                            spike = (spike == 0).cumsum(dim=-1).eq(1).to(torch.float) if lc_adc_on == True else spike\n",
    "\n",
    "                            # spike: batch, time, feature\n",
    "                            spike = spike.reshape(spike.shape[0], -1)\n",
    "\n",
    "                    \n",
    "\n",
    "\n",
    "                    # if fusion_net == True:\n",
    "                    #     spike = spikegen.rate(spike, num_steps=TIME).transpose(0, 1)\n",
    "\n",
    "                # spike_class = net(spike) # batch, time, feature\n",
    "                encoded_spike = net.module.encoder(spike)\n",
    "                spike_class = net.module.decoder(encoded_spike)\n",
    "\n",
    "                # for i in range (2):\n",
    "                #     plot_spike(spike[i,:,0,:].cpu().numpy())\n",
    "                #     # plot_spike(spike[i,:,1,:].cpu().numpy())\n",
    "                #     plot_origin_spike(spike_class.squeeze()[i].cpu().detach().numpy(), min_max_y_on = True)\n",
    "                # assert False\n",
    "                        \n",
    "\n",
    "                loss = 0\n",
    "                loss_normal = torch.tensor(0.0)\n",
    "                loss_coarse = torch.tensor(0.0)\n",
    "                if coarse_com_mode == True and 'SAE' in net.module.__class__.__name__:\n",
    "                    criterion = nn.MSELoss().to(device)\n",
    "                    # loss1 = nn.MSELoss()(spike_class[..., 5:25], spike[..., 5:25])\n",
    "                    # loss2 = nn.MSELoss()(spike_class[..., 0:5], spike[..., 0:5])\n",
    "                    # loss3 = nn.MSELoss()(spike_class[..., 25:spike_length], spike[..., 25:spike_length])\n",
    "                    # loss = loss1 * 2.125 + (loss2 + loss3)/4\n",
    "\n",
    "                    # loss1 = nn.MSELoss()(spike_class[..., 5:25, :], spike[..., 5:25, :])\n",
    "                    # loss2 = nn.MSELoss()(spike_class[..., 0:5, :], spike[..., 0:5, :])\n",
    "                    # loss3 = nn.MSELoss()(spike_class[..., 25:spike_length, :], spike[..., 25:spike_length, :])\n",
    "                    # loss = loss1 * 2.125 + (loss2 + loss3)/4\n",
    "                    if fusion_net:\n",
    "                        # print('1', spike.shape) # batch, time, in_channel, feature [32, 50, 1, 50]\n",
    "                        \n",
    "                        # ### coarse에서 ann loss 만들기 ######\n",
    "                        # spike = spike.squeeze()\n",
    "                        # assert two_channel_input == False\n",
    "                        # zero_mask = (spike == 0)  # 0이 있는 위치\n",
    "                        # first_zero_idx = torch.where(zero_mask, torch.arange(spike.shape[-1]).to(device), spike.shape[-1]-1).min(dim=-1).values\n",
    "                        # spike = levels[0][first_zero_idx]\n",
    "                        # # plot_origin_spike(spike[0].cpu().detach().numpy())\n",
    "                        # ### coarse에서 ann loss 만들기 ######\n",
    "\n",
    "                        ### 그냥 원래 스파이크로 ann loss 만들기 ######\n",
    "                        spike = spike_for_fusion2_net\n",
    "                        ### 그냥 원래 스파이크로 ann loss 만들기 ######\n",
    "\n",
    "                        spike = spike.squeeze()\n",
    "                        spike_class = spike_class.squeeze()\n",
    "                        \n",
    "                        ### normal loss################\n",
    "                        # loss = criterion(spike_class, spike)\n",
    "                        ### normal loss################\n",
    "                        \n",
    "                        ### chan loss################\n",
    "                        loss1 = criterion(spike_class[..., 5:25], spike[..., 5:25])\n",
    "                        loss2 = criterion(spike_class[..., 0:5], spike[..., 0:5])\n",
    "                        loss3 = criterion(spike_class[..., 25:], spike[..., 25:])\n",
    "                        loss = loss1 * 2.125 + (loss2 + loss3)/4\n",
    "                        ### chan loss################\n",
    "\n",
    "\n",
    "                        # #########################################\n",
    "                        # # 손실 함수 정의 (예: MSELoss 사용)\n",
    "                        # criterion_joke = torch.nn.MSELoss(reduction='none')  # 개별 요소별 손실을 유지\n",
    "\n",
    "                        # # 손실 계산\n",
    "                        # loss1_joke = criterion_joke(spike_class[..., 5:25], spike[..., 5:25]).mean(dim=-1)  # (batch,)\n",
    "                        # loss2_joke = criterion_joke(spike_class[..., 0:5], spike[..., 0:5]).mean(dim=-1)    # (batch,)\n",
    "                        # loss3_joke = criterion_joke(spike_class[..., 25:], spike[..., 25:]).mean(dim=-1)    # (batch,)\n",
    "\n",
    "                        # # 주어진 가중치를 적용한 최종 손실\n",
    "                        # loss_joke = loss1_joke * 2.125 + (loss2_joke + loss3_joke) / 4  # (batch,)\n",
    "\n",
    "                        # # 가장 큰 손실을 갖는 샘플의 인덱스 찾기\n",
    "                        # max_loss_idx_joke = torch.argmax(loss_joke)\n",
    "\n",
    "                        # # 해당 샘플 선택\n",
    "                        # selected_sample_class = spike_class[max_loss_idx_joke]\n",
    "                        # selected_sample_spike = spike[max_loss_idx_joke]\n",
    "\n",
    "                        # # 선택한 샘플의 손실 값 출력\n",
    "                        # print(\"Index of max loss sample:\", max_loss_idx_joke.item())\n",
    "                        # print(\"Max loss value:\", loss_joke[max_loss_idx_joke].item())\n",
    "                        # mean_loss_joke = loss_joke.mean().item()\n",
    "                        # print(\"Mean loss across the batch:\", mean_loss_joke)\n",
    "\n",
    "                        # # 선택한 샘플을 시각화\n",
    "                        # plot_origin_spike(selected_sample_class.cpu().detach().numpy())\n",
    "                        # plot_origin_spike(selected_sample_spike.cpu().detach().numpy())\n",
    "                        # #########################################\n",
    "\n",
    "                        # coarse loss ######################################################\n",
    "                        loss_normal = criterion(spike_class, spike)\n",
    "                        level_num_in_loss = spike_length\n",
    "                        level_interval = (coarse_com_config[0] - coarse_com_config[1]) / (level_num_in_loss-1)  # max - min\n",
    "                        levels = [coarse_com_config[1] + level_interval * i for i in range(level_num_in_loss)]\n",
    "                        levels = torch.tensor(levels).to(torch.float).to(device)\n",
    "                        # print('coarse leves', levels)\n",
    "                        levels = levels.repeat(spike_length,1) \n",
    "\n",
    "                        spike = spike.squeeze()\n",
    "                        spike_class = spike_class.squeeze()\n",
    "                        # plot_origin_spike(spike_class[0].cpu().detach().numpy())\n",
    "                        spike = spike.unsqueeze(2).repeat(1, 1, level_num_in_loss) \n",
    "                        spike = (spike > levels).to(torch.float) \n",
    "                        spike_class = spike_class.unsqueeze(2).repeat(1, 1, level_num_in_loss) \n",
    "                        spike_class = (spike_class > levels).to(torch.float) \n",
    "                        # spike = spike[..., 0:-3, :]\n",
    "                        # spike_class = spike_class[..., 0:-3, :]\n",
    "                        loss_coarse = criterion(spike_class, spike)\n",
    "                        wrong_element_sum += torch.sum(torch.abs(spike - spike_class)).item() \n",
    "\n",
    "                        # plot_spike(spike_class[0].cpu().detach().numpy())\n",
    "                        # assert False\n",
    "                        # coarse loss ######################################################\n",
    "                    else:\n",
    "                        spike = spike.squeeze()\n",
    "                        spike_class = spike_class.squeeze()\n",
    "                        loss = criterion(spike_class, spike)\n",
    "\n",
    "                    for iii in range(spike.shape[0]):\n",
    "                        same_data_num = same_data_num + 1 if torch.eq(spike[iii], spike_class[iii]).all() else same_data_num\n",
    "                    wrong_element_sum += torch.sum(torch.abs(spike - spike_class)).item() \n",
    "\n",
    "                    # spike = spike.squeeze()\n",
    "                    # spike_class = spike_class.squeeze()\n",
    "                    # plot_spike(spike[0].cpu().detach().numpy())\n",
    "                    # plot_spike(spike_class[0].cpu().detach().numpy())\n",
    "                    # print('손실 절대값 합',np.sum(np.abs(spike[0].cpu().detach().numpy() - spike_class[0].cpu().detach().numpy())))\n",
    "                    # # assert False\n",
    "                elif 'SAE' in net.module.__class__.__name__:\n",
    "                    criterion = nn.MSELoss().to(device)\n",
    "                    loss1 = criterion(spike_class[..., 5:25], spike[..., 5:25])\n",
    "                    loss2 = criterion(spike_class[..., 0:5], spike[..., 0:5])\n",
    "                    loss3 = criterion(spike_class[..., 25:spike_length], spike[..., 25:spike_length])\n",
    "                    loss = loss1 * 2.125 + (loss2 + loss3)/4\n",
    "                    assert spike_length > 25, 'spike_length가 25보다 작음'\n",
    "                    # wrong_element_sum += torch.sum(torch.abs(spike - spike_class)).item() \n",
    "                else:\n",
    "                    criterion = nn.MSELoss().to(device)\n",
    "                    loss1 = criterion(spike_class[..., 5:25], spike[..., 5:25])\n",
    "                    loss2 = criterion(spike_class[..., 0:5], spike[..., 0:5])\n",
    "                    loss3 = criterion(spike_class[..., 25:spike_length], spike[..., 25:spike_length])\n",
    "                    loss = loss1 * 2.125 + (loss2 + loss3)/4\n",
    "                    assert spike_length > 25, 'spike_length가 25보다 작음'\n",
    "                    # wrong_element_sum += torch.sum(torch.abs(spike - spike_class)).item() \n",
    "\n",
    "\n",
    "                    if l2_norm_loss_weight > 0:\n",
    "                        assert len(encoded_spike.shape) == 2, 'time 성분 없는 걸로'\n",
    "                        l2_loss = l2_norm_loss(encoded_spike, target_norm=1.0)  # L2Norm Loss 계산, l2 1.0되게.\n",
    "                        loss = loss + l2_loss*l2_norm_loss_weight\n",
    "                        l2_loss_bin += l2_loss.item()\n",
    "\n",
    "                    # coarse loss ######################################################\n",
    "                    loss_normal = criterion(spike_class, spike)\n",
    "                    level_num_in_loss = quantize_level_num\n",
    "                    level_interval = (coarse_com_config[0] - coarse_com_config[1]) / (level_num_in_loss-1)  # max - min\n",
    "                    levels = [coarse_com_config[1] + level_interval * i for i in range(level_num_in_loss)]\n",
    "                    levels = torch.tensor(levels).to(torch.float).to(device)\n",
    "                    levels = levels.repeat(spike_length,1) \n",
    "\n",
    "                    spike = spike.squeeze()\n",
    "                    spike_class = spike_class.squeeze()\n",
    "                    # plot_origin_spike(spike_class[0].cpu().detach().numpy())\n",
    "                    spike = spike.unsqueeze(2).repeat(1, 1, level_num_in_loss) \n",
    "                    spike = (spike > levels).to(torch.float) \n",
    "                    spike_class = spike_class.unsqueeze(2).repeat(1, 1, level_num_in_loss) \n",
    "                    spike_class = (spike_class > levels).to(torch.float) \n",
    "                    # spike = spike[..., 0:-3, :]\n",
    "                    # spike_class = spike_class[..., 0:-3, :]\n",
    "                    loss_coarse = criterion(spike_class, spike)\n",
    "                    wrong_element_sum += torch.sum(torch.abs(spike - spike_class)).item() \n",
    "\n",
    "                    # plot_spike(spike_class[0].cpu().detach().numpy())\n",
    "                    # assert False\n",
    "                    # coarse loss ######################################################\n",
    "\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                running_loss += loss.item()\n",
    "                running_loss_normal += loss_normal.item()\n",
    "                running_loss_coarse += loss_coarse.item()\n",
    "                # print(f'\\nepoch-{epoch}, running_loss : {running_loss:.5f}, iter percent {iter/len(train_loader)*100:.2f}%')\n",
    "                iter += 1\n",
    "        else:\n",
    "            print('\\n\\n\\n max_epoch 1이면 Train 안함!!!!!!!!!!!!!!!!!!!!!')\n",
    "        if l2_norm_loss_weight > 0:\n",
    "            print('l2_loss_bin', l2_loss_bin/len(train_loader))\n",
    "        avg_loss = running_loss / len(train_loader)\n",
    "        assert not np.isnan(avg_loss), f\"Error: avg_loss is NaN! Running loss: {running_loss}, Length of train_loader: {len(train_loader)}\"\n",
    "        loss_history.append((epoch, avg_loss))\n",
    "        min_loss = min(min_loss, avg_loss)\n",
    "        min_loss_normal = min(min_loss_normal, running_loss_normal/len(train_loader))\n",
    "        min_loss_coarse = min(min_loss_coarse, running_loss_coarse/len(train_loader))\n",
    "        print(f'\\nepoch-{epoch} loss : {avg_loss:.8f}, loss_normal : {running_loss_normal/len(train_loader):.8f}, loss_coarse : {running_loss_coarse/len(train_loader):.8f}, min_loss : {min_loss:.8f}, min_loss_normal : {min_loss_normal:.8f}, min_loss_coarse : {min_loss_coarse:.8f}, wrong_element_sum : {wrong_element_sum:.8f}, same_data : {100*same_data_num/(total_data_num+1e-12):.2f}%')\n",
    "        print(f\"ae train 실행 시간: {time.time()-ae_train_start_time:.3f}초, 전체 시작 시간 {current_time}\")\n",
    "\n",
    "        # plot_activation_distribution(net)\n",
    "\n",
    "        if SAE_net == False and converted_net_forward == True:\n",
    "            source_encoder = net.module.encoder \n",
    "            target_encoder = converted_net.module.encoder  \n",
    "            copy_weights(source_encoder, target_encoder)\n",
    "\n",
    "        cluster_accuracy_during_training_cycle_all_dataset = np.zeros(dataset_num)\n",
    "        cluster_accuracy_post_training_cycle_all_dataset = np.zeros(dataset_num)\n",
    "        cluster_accuracy_total_all_dataset = np.zeros(dataset_num)    \n",
    "\n",
    "        k_means_acc = 0\n",
    "        converted_k_means_acc = 0\n",
    "        if(epoch % accuracy_check_epoch_term == 0 or epoch == 1 or epoch == max_epoch-1): \n",
    "            accuracy_check_start_time = time.time()\n",
    "            print(f'\\nepoch-{epoch} accuracy check')\n",
    "            k_means_bin_origin_feature = []\n",
    "            k_means_bin = []\n",
    "            converted_k_means_bin = []\n",
    "            for ds in range(dataset_num):\n",
    "                # print('\\n', spike_tot[ds])\n",
    "\n",
    "                spike_template = np.load(my_path_ground_BH + template[ds])\n",
    "                spike = np.load(my_path_ground_BH + spike_tot[ds])\n",
    "                label = np.load(my_path_ground_BH + label_tot[ds])\n",
    "                spike_template = torch.from_numpy(spike_template).to(device)\n",
    "                spike = torch.from_numpy(spike).to(device)\n",
    "                scaling = (level_num-3)/level_num if conv1d_scaling else 1.0\n",
    "                spike_template = zero_to_one_normalize_features(spike_template, level_num=quantize_level_num, coarse_com_config=coarse_com_config, scaling=scaling, norm01=norm01) if normalize_on else spike_template\n",
    "                spike = zero_to_one_normalize_features(spike, level_num=quantize_level_num, coarse_com_config=coarse_com_config, scaling=scaling, norm01=norm01) if normalize_on else spike\n",
    "                \n",
    "                hidden_size = lateral_feature_num*TIME if 'SAE' in net.module.__class__.__name__ and SAE_hidden_nomean == True and fusion_net == False or 'SAE_FUSION5' in net.module.__class__.__name__ else lateral_feature_num\n",
    "                hidden_size = lateral_feature_num if '_DR' in net.module.__class__.__name__  else hidden_size\n",
    "\n",
    "                Cluster = np.zeros((num_cluster, hidden_size))\n",
    "                assert Cluster.shape[-1] == hidden_size, '이거 hidden dim 4 아니게 할 거면 잘 바꿔라'\n",
    "                \n",
    "\n",
    "\n",
    "                net.eval()\n",
    "                with torch.no_grad():\n",
    "                    spike_torch = spike_template.float()\n",
    "                    spike_torch = spike_torch[:num_cluster]\n",
    "                    spike_backup = spike_torch\n",
    "                    spike_torch = spike_torch.to(device)\n",
    "                    if coarse_com_mode == True and 'SAE' in net.module.__class__.__name__:\n",
    "                        spike_torch = spike_torch.unsqueeze(2).repeat(1, 1, level_num) # spike_length == level_num # (batch, time, feature)로 변환 \n",
    "                        spike_torch = (spike_torch > levels).to(torch.float) \n",
    "                        spike_torch = (spike_torch == 0).cumsum(dim=-1).eq(1).to(torch.float) if lc_adc_on == True else spike_torch\n",
    "                        if Conv_net == True:\n",
    "                            spike_torch = spike_torch.unsqueeze(-2) # batch, time, in_channel, feature or batch in_channel,feature\n",
    "                            if two_channel_input == True:\n",
    "                                spike_backup = spike_backup.to(device)\n",
    "                                spike_backup = spike_backup.unsqueeze(2).repeat(1, 1, level_num) # spike_length == level_num # (batch, time, feature)로 변환 \n",
    "                                spike_backup = (spike_backup <= levels).to(torch.float) \n",
    "                                spike_backup = (spike_backup == 1).cumsum(dim=-1).eq(1).to(torch.float) if lc_adc_on == True else spike_backup\n",
    "                                spike_backup = spike_backup.unsqueeze(-2) # batch, time, in_channel, feature\n",
    "                                spike_torch = torch.cat((spike_torch, spike_backup), dim=-2)\n",
    "                    elif 'SAE' in net.module.__class__.__name__:\n",
    "                        spike_torch = spike_torch.unsqueeze(1).repeat(1, TIME, 1) # (batch, time, feature)로 변환\n",
    "                        if Conv_net == True:\n",
    "                            spike_torch = spike_torch.unsqueeze(-2) # batch, time, in_channel, feature or batch in_channel,feature\n",
    "                    else:\n",
    "                        # if Conv_net == True:\n",
    "                        #     spike_torch = spike_torch.unsqueeze(-2) #batch in_channel,feature\n",
    "                        if Conv_net == True:\n",
    "                            if coarse_com_mode == False:\n",
    "                                spike_torch = spike_torch.unsqueeze(-2) #batch in_channel,feature\n",
    "                            else:\n",
    "                                spike_torch = spike_torch.unsqueeze(2).repeat(1, 1, level_num) # spike_length == level_num # (batch, time, feature)로 변환 \n",
    "                                spike_torch = (spike_torch > levels).to(torch.float) \n",
    "\n",
    "                                spike_torch = (spike_torch == 0).cumsum(dim=-1).eq(1).to(torch.float) if lc_adc_on == True else spike_torch\n",
    "\n",
    "                        else:\n",
    "                            if coarse_com_mode == False:\n",
    "                                pass\n",
    "                            else:\n",
    "                                spike_torch = spike_torch.unsqueeze(2).repeat(1, 1, level_num) # spike_length == level_num # (batch, time, feature)로 변환 \n",
    "                                spike_torch = (spike_torch > levels).to(torch.float) \n",
    "\n",
    "                                spike_torch = (spike_torch == 0).cumsum(dim=-1).eq(1).to(torch.float) if lc_adc_on == True else spike_torch\n",
    "\n",
    "                                # spike: batch, time, feature\n",
    "                                spike_torch = spike_torch.reshape(spike_torch.shape[0], -1)\n",
    "\n",
    "                        if converted_net_forward == True:\n",
    "                            spike_torch_spikegen = spikegen.rate(spike_torch, num_steps=TIME).transpose(0, 1)\n",
    "                        # if fusion_net == True:\n",
    "                        #     spike_torch = spikegen.rate(spike_torch, num_steps=TIME).transpose(0, 1)\n",
    "                    ### forward #######################################################\n",
    "                    inner_inf = net.module.encoder(spike_torch)\n",
    "                    if SAE_net == False and converted_net_forward == True:\n",
    "                        converted_inner_inf = converted_net.module.encoder(spike_torch_spikegen)\n",
    "                    ### forward #######################################################\n",
    "\n",
    "                    # if ds % 4 == 0:\n",
    "                    #     for i in range(4):\n",
    "                    #         decoded = net.module.decoder(inner_inf).squeeze()\n",
    "                    #         plot_spike(spike_torch[i,:,:].cpu().numpy())\n",
    "                    #         plot_spike(inner_inf[i,:].cpu().numpy())\n",
    "                    #         # plot_origin_spike(net.module.decoder(inner_inf)[i,:].cpu().numpy())\n",
    "                    #         plot_origin_spike(decoded[i].cpu().numpy(), min_max_y_on = True)\n",
    "                        \n",
    "                    # if 'SAE' in net.module.__class__.__name__:\n",
    "                    #     tensors = [inner_inf[0][i] for i in range(TIME)] \n",
    "                    #     all_equal = all(torch.equal(tensors[0], t) for t in tensors)\n",
    "                    #     print(all_equal, inner_inf)\n",
    "\n",
    "                    if 'SAE' in net.module.__class__.__name__:\n",
    "                        if SAE_hidden_nomean == True:\n",
    "                            inner_inf = inner_inf.reshape(inner_inf.shape[0],-1)# time*feature 펼치기\n",
    "                        else:\n",
    "                            inner_inf = inner_inf.mean(dim=1)# Time 방향으로 평균\n",
    "                        # inner_inf = F.normalize(inner_inf, p=2, dim=1)\n",
    "                    Cluster = inner_inf.cpu().detach().numpy()\n",
    "\n",
    "                encoder_batch = 128\n",
    "                spike_hidden = np.zeros((len(spike), hidden_size))\n",
    "                converted_spike_hidden = np.zeros((len(spike), hidden_size))\n",
    "                net.eval()\n",
    "                with torch.no_grad():\n",
    "                    now_index = 0\n",
    "                    while (1):\n",
    "                        now_end_index = now_index+encoder_batch if now_index+encoder_batch < len(spike) else len(spike)\n",
    "                        spike_batch = spike[now_index:now_end_index] \n",
    "                        spike_torch = spike_batch\n",
    "                        spike_torch = spike_torch.float()\n",
    "                        spike_backup = spike_torch\n",
    "                        spike_torch = spike_torch.to(device)\n",
    "                        if coarse_com_mode == True and 'SAE' in net.module.__class__.__name__:\n",
    "                            spike_torch = spike_torch.unsqueeze(2).repeat(1, 1, level_num) # spike_length == level_num # (batch, time, feature)로 변환 \n",
    "                            spike_torch = (spike_torch > levels).to(torch.float) \n",
    "                            spike_torch = (spike_torch == 0).cumsum(dim=-1).eq(1).to(torch.float) if lc_adc_on == True else spike_torch\n",
    "                            if Conv_net == True:\n",
    "                                spike_torch = spike_torch.unsqueeze(-2) # batch, time, in_channel, feature or batch in_channel,feature\n",
    "                                if two_channel_input == True:\n",
    "                                    spike_backup = spike_backup.to(device)\n",
    "                                    spike_backup = spike_backup.unsqueeze(2).repeat(1, 1, level_num) # spike_length == level_num # (batch, time, feature)로 변환 \n",
    "                                    spike_backup = (spike_backup <= levels).to(torch.float) \n",
    "                                    spike_backup = (spike_backup == 1).cumsum(dim=-1).eq(1).to(torch.float) if lc_adc_on == True else spike_backup\n",
    "                                    spike_backup = spike_backup.unsqueeze(-2)\n",
    "                                    spike_torch = torch.cat((spike_torch, spike_backup), dim=-2)\n",
    "                        elif 'SAE' in net.module.__class__.__name__:\n",
    "                            spike_torch = spike_torch.unsqueeze(1).repeat(1, TIME, 1) # (batch, time, feature)로 변환\n",
    "                            if Conv_net == True:\n",
    "                                spike_torch = spike_torch.unsqueeze(-2) # batch, time, in_channel, feature or batch in_channel,feature\n",
    "                        else:\n",
    "                            # if Conv_net == True:\n",
    "                            #     spike_torch = spike_torch.unsqueeze(-2) #batch in_channel,feature\n",
    "                            if Conv_net == True:\n",
    "                                if coarse_com_mode == False:\n",
    "                                    spike_torch = spike_torch.unsqueeze(-2) #batch in_channel,feature\n",
    "                                else:\n",
    "                                    spike_torch = spike_torch.unsqueeze(2).repeat(1, 1, level_num) # spike_length == level_num # (batch, time, feature)로 변환 \n",
    "                                    spike_torch = (spike_torch > levels).to(torch.float) \n",
    "\n",
    "                                    spike_torch = (spike_torch == 0).cumsum(dim=-1).eq(1).to(torch.float) if lc_adc_on == True else spike_torch\n",
    "\n",
    "                            else:\n",
    "                                if coarse_com_mode == False:\n",
    "                                    pass\n",
    "                                else:\n",
    "                                    spike_torch = spike_torch.unsqueeze(2).repeat(1, 1, level_num) # spike_length == level_num # (batch, time, feature)로 변환 \n",
    "                                    spike_torch = (spike_torch > levels).to(torch.float) \n",
    "\n",
    "                                    spike_torch = (spike_torch == 0).cumsum(dim=-1).eq(1).to(torch.float) if lc_adc_on == True else spike_torch\n",
    "\n",
    "                                    # spike: batch, time, feature\n",
    "                                    spike_torch = spike_torch.reshape(spike_torch.shape[0], -1)\n",
    "                            if converted_net_forward == True:\n",
    "                                spike_torch_spikegen = spikegen.rate(spike_torch, num_steps=TIME).transpose(0, 1)\n",
    "                            # if fusion_net == True:\n",
    "                            #     spike_torch = spikegen.rate(spike_torch, num_steps=TIME).transpose(0, 1)\n",
    "                        ### forward #######################################################\n",
    "                        inner_inf = net.module.encoder(spike_torch)\n",
    "                        if SAE_net == False and converted_net_forward == True:\n",
    "                            converted_inner_inf = converted_net.module.encoder(spike_torch_spikegen)\n",
    "                        ### forward #######################################################\n",
    "                            \n",
    "                        if 'SAE' in net.module.__class__.__name__:\n",
    "                            if SAE_hidden_nomean == True:\n",
    "                                inner_inf = inner_inf.reshape(spike_batch.shape[0],-1)# 펼치기\n",
    "                            else:\n",
    "                                inner_inf = inner_inf.mean(dim=1)# Time 방향으로 평균\n",
    "                            # inner_inf = F.normalize(inner_inf, p=2, dim=1)\n",
    "                        spike_hidden[now_index:now_end_index] = inner_inf.cpu().detach().numpy()\n",
    "                        if SAE_net == False and converted_net_forward == True:\n",
    "                            converted_spike_hidden[now_index:now_end_index] = converted_inner_inf.cpu().detach().numpy()\n",
    "                        now_index += encoder_batch\n",
    "                        if (now_index >= len(spike)):\n",
    "                            break\n",
    "                    \n",
    "                spike_id = np.zeros(len(spike))\n",
    "                distance_sm = np.zeros(num_cluster)\n",
    "                tau = np.zeros(num_cluster)\n",
    "                \n",
    "                plot_tau = []\n",
    "                plot_denominator = []\n",
    "                plot_m = []\n",
    "                plot_max_tau = []\n",
    "                for spike_index in range(len(spike)): \n",
    "                    for q in range(num_cluster):\n",
    "                        tau[q] = np.dot(spike_hidden[spike_index, :], Cluster[q, :]) # 이거 l2norm 거쳐서 나온 거니까 분모 1임.\n",
    "                        denominator =  np.linalg.norm(spike_hidden[spike_index, :])*np.linalg.norm(Cluster[q, :]) + 1e-12\n",
    "                        plot_denominator.append(denominator)\n",
    "                        if 'SAE' in net.module.__class__.__name__: # AE 때는 l2norm거쳐서 나와서 괜찮음\n",
    "                            tau[q] = tau[q] / denominator\n",
    "\n",
    "                        plot_tau.append(tau[q])\n",
    "\n",
    "                    # for i in range(num_cluster): # l2 distance\n",
    "                    #     distance_sm[i] = np.sum(np.power(np.abs(Cluster[i] - spike_hidden[spike_index, :]), 2))\n",
    "                    distance_sm = np.sum(np.power(np.abs(Cluster - spike_hidden[spike_index, :]), 2), axis=1)\n",
    "\n",
    "                    m = np.argmin(distance_sm)\n",
    "                    plot_m.append(m)\n",
    "                    spike_id[spike_index] = m + 1\n",
    "                    # print(spike_tot[ds], spike_index,np.max(tau))\n",
    "                    plot_max_tau.append(np.max(tau))\n",
    "                    if(np.max(tau) >= cos_thr[ds] and spike_index < training_cycle): # 원래 1400 아니냐?\n",
    "                        Cluster[m] = (Cluster[m] * 15 + spike_hidden[spike_index, :])/16\n",
    "\n",
    "\n",
    "                \n",
    "                origin_kmeans_accuracy = cluster_spikes_with_accuracy_torch(features= spike, true_labels=label-1, n_clusters=3, init_point=None)\n",
    "                kmeans_accuracy = cluster_spikes_with_accuracy_torch(features= torch.tensor(spike_hidden).to(device), true_labels=label-1, n_clusters=3, init_point=None)\n",
    "                \n",
    "                # print('temporoal k')\n",
    "                # result = evaluate_clustering_accuracy(spike_hidden.reshape(spike_hidden.shape[0], TIME, -1), label-1, n_clusters=3)\n",
    "                # print('원래', kmeans_accuracy)\n",
    "                # print(result)\n",
    "\n",
    "                k_means_bin_origin_feature.append(origin_kmeans_accuracy)\n",
    "                k_means_bin.append(kmeans_accuracy)\n",
    "                if SAE_net == False and converted_net_forward == True:\n",
    "                    converted_kmeans_accuracy = cluster_spikes_with_accuracy_torch(features= torch.tensor(converted_spike_hidden).to(device), true_labels=label-1, n_clusters=3, init_point=None)\n",
    "                    converted_k_means_bin.append(converted_kmeans_accuracy)\n",
    "                # sklearn kmeans인데 cpu많이먹어서 버림.\n",
    "                # origin_kmeans_accuracy = cluster_spikes_with_accuracy(features= spike.cpu().detach().numpy(), true_labels=label-1, n_clusters=3, init_point=None)\n",
    "                # kmeans_accuracy = cluster_spikes_with_accuracy(features= spike_hidden, true_labels=label-1, n_clusters=3, init_point=None)\n",
    "                # k_means_bin_origin_feature.append(origin_kmeans_accuracy)\n",
    "                # k_means_bin.append(kmeans_accuracy)\n",
    "                # if SAE_net == False and converted_net_forward == True:\n",
    "                #     converted_kmeans_accuracy = cluster_spikes_with_accuracy(features= converted_spike_hidden, true_labels=label-1, n_clusters=3, init_point=None)\n",
    "                #     converted_k_means_bin.append(converted_kmeans_accuracy)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "                # print('Cluster',Cluster)\n",
    "                # print('spike_id', spike_id)\n",
    "\n",
    "                # spike id 분포 확인하기\n",
    "                # unique_elements, counts = np.unique(spike_id, return_counts=True)\n",
    "                # print(\"Unique elements:\", unique_elements)\n",
    "                # print(\"Counts:\", counts)\n",
    "\n",
    "                cluster_accuracy_during_training_cycle = np.zeros(math.factorial(num_cluster))\n",
    "                cluster_accuracy_post_training_cycle = np.zeros(math.factorial(num_cluster))\n",
    "                cluster_accuracy_total = np.zeros(math.factorial(num_cluster))\n",
    "                \n",
    "                label_converter_ground = list(range(1, num_cluster + 1)) # [1, 2, 3, 4] 생성\n",
    "                label_converter_permutations = list(itertools.permutations(label_converter_ground)) # 모든 순열 구하기\n",
    "                perm_i = 0\n",
    "                perm_start_time = time.time() \n",
    "                for perm in label_converter_permutations:\n",
    "                    label_converter = list(perm)\n",
    "                    # print(label_converter)\n",
    "                    correct_during_training_cycle = 0\n",
    "                    correct_post_training_cycle = 0\n",
    "\n",
    "                    assert len(spike_id) == len(label), 'spike_id랑 label 길이 같아야 됨.'\n",
    "                    for i in range(len(spike_id)):\n",
    "                        if(label_converter[int(spike_id[i]-1)] == label[i]):\n",
    "                            if i < training_cycle:\n",
    "                                correct_during_training_cycle += 1\n",
    "                            else:\n",
    "                                correct_post_training_cycle += 1\n",
    "\n",
    "                    cluster_accuracy_during_training_cycle[perm_i] = correct_during_training_cycle/training_cycle\n",
    "                    cluster_accuracy_post_training_cycle[perm_i] = correct_post_training_cycle/(len(spike_id)-training_cycle)\n",
    "                    cluster_accuracy_total[perm_i] = (correct_during_training_cycle+correct_post_training_cycle)/(len(spike_id))\n",
    "                    perm_i += 1\n",
    "                # print(f\"perm 실행 시간: {time.time()-perm_start_time:.3f}초\")\n",
    "                \n",
    "                cluster_accuracy_during_training_cycle_all_dataset[ds] = np.max(cluster_accuracy_during_training_cycle)\n",
    "                cluster_accuracy_post_training_cycle_all_dataset[ds] = cluster_accuracy_post_training_cycle[np.argmax(cluster_accuracy_during_training_cycle)]\n",
    "                cluster_accuracy_total_all_dataset[ds] = cluster_accuracy_total[np.argmax(cluster_accuracy_during_training_cycle)]\n",
    "                # plot_distributions(ds, plot_tau, plot_denominator, plot_m, plot_max_tau, cos_thr[ds],\n",
    "                #                    cluster_accuracy_during_training_cycle_all_dataset[ds], cluster_accuracy_post_training_cycle_all_dataset[ds], cluster_accuracy_total_all_dataset[ds])\n",
    "            print(f'k_means origin feature average accuracy : {100*sum(k_means_bin_origin_feature)/(len(k_means_bin_origin_feature)+1e-12):.8f}%, total {k_means_bin_origin_feature}')\n",
    "            \n",
    "            mean_cluster_accuracy_during_training_cycle_all_dataset = np.mean(cluster_accuracy_during_training_cycle_all_dataset)\n",
    "            mean_cluster_accuracy_post_training_cycle_all_dataset = np.mean(cluster_accuracy_post_training_cycle_all_dataset)\n",
    "            mean_cluster_accuracy_total_all_dataset = np.mean(cluster_accuracy_total_all_dataset)\n",
    "            \n",
    "            if SAE_net == False and converted_net_forward == True:\n",
    "                converted_k_means_acc = 100*sum(converted_k_means_bin)/len(converted_k_means_bin)\n",
    "                print(f'converted_kmeans average accuracy : {converted_k_means_acc:.8f}%, total {converted_k_means_bin}')\n",
    "            k_means_acc = 100*sum(k_means_bin)/len(k_means_bin)\n",
    "            if k_means_acc > k_means_acc_best:\n",
    "                # torch.save(net, f\"net_save/save_now_net_{current_time}.pth\")\n",
    "                torch.save(net.module.state_dict(), f\"net_save/save_now_net_{current_time}.pth\")\n",
    "                print('save model')\n",
    "                best_mean_cluster_accuracy_post_training_cycle_all_dataset = mean_cluster_accuracy_post_training_cycle_all_dataset\n",
    "            \n",
    "            k_means_acc_best = max(k_means_acc_best, k_means_acc)\n",
    "            print(f'kmeans average accuracy best : {k_means_acc_best:.2f}%, kmeans average accuracy : {k_means_acc:.8f}%, total {k_means_bin}')\n",
    "            print(f'cluster_accuracy_post_training_cycle_all_dataset : {cluster_accuracy_post_training_cycle_all_dataset}')\n",
    "\n",
    "            \n",
    "            mean_cluster_accuracy_during_training_cycle_all_dataset_history.append((epoch, mean_cluster_accuracy_during_training_cycle_all_dataset*100))\n",
    "            mean_cluster_accuracy_post_training_cycle_all_dataset_history.append((epoch, mean_cluster_accuracy_post_training_cycle_all_dataset*100))\n",
    "            mean_cluster_accuracy_total_all_dataset_history.append((epoch, mean_cluster_accuracy_total_all_dataset*100))\n",
    "            print(f\"mean_cluster_accuracy_during_training_cycle : {mean_cluster_accuracy_during_training_cycle_all_dataset*100:.2f}%, post_traincycle_acc : {mean_cluster_accuracy_post_training_cycle_all_dataset*100:.2f}%, total_acc : {mean_cluster_accuracy_total_all_dataset*100:.8f}%\")\n",
    "\n",
    "            # kmeans accuracy기준으로 좋은 거 저장할 거임\n",
    "            # if mean_cluster_accuracy_post_training_cycle_all_dataset > best_mean_cluster_accuracy_post_training_cycle_all_dataset:\n",
    "            #     # torch.save(net, f\"net_save/save_now_net_{current_time}.pth\")\n",
    "            #     torch.save(net.module.state_dict(), f\"net_save/save_now_net_{current_time}.pth\")\n",
    "            #     print('save model')\n",
    "            #     best_mean_cluster_accuracy_post_training_cycle_all_dataset = mean_cluster_accuracy_post_training_cycle_all_dataset\n",
    "            print(f\"best_mean_cluster_accuracy_post_training_cycle_all_dataset : {best_mean_cluster_accuracy_post_training_cycle_all_dataset*100:.2f}%\")\n",
    "            print(f\"accuracy_check 실행 시간: {time.time()-accuracy_check_start_time:.3f}초\")\n",
    "\n",
    "        wandb.log({\"avg_loss\": avg_loss})\n",
    "        wandb.log({\"mean_cluster_accuracy_post_training_cycle_all_dataset\": mean_cluster_accuracy_post_training_cycle_all_dataset})\n",
    "        wandb.log({\"best_mean_cluster_accuracy_post_training_cycle_all_dataset\": best_mean_cluster_accuracy_post_training_cycle_all_dataset})\n",
    "        wandb.log({\"best_mean_cluster_accuracy_post_training_cycle_all_dataset2\": best_mean_cluster_accuracy_post_training_cycle_all_dataset})\n",
    "        wandb.log({\"k_means_acc\": k_means_acc})\n",
    "        wandb.log({\"k_means_acc_best\": k_means_acc_best})\n",
    "        wandb.log({\"converted_k_means_acc\": converted_k_means_acc})\n",
    "\n",
    "\n",
    "        # 저장\n",
    "        with open(f\"result_save/cluster_accuracy_history_{current_time}.pkl\", \"wb\") as f:\n",
    "            pickle.dump({\n",
    "                \"loss_history\": loss_history,\n",
    "                \"mean_cluster_accuracy_during_training_cycle_all_dataset_history\": mean_cluster_accuracy_during_training_cycle_all_dataset_history,\n",
    "                \"mean_cluster_accuracy_post_training_cycle_all_dataset_history\": mean_cluster_accuracy_post_training_cycle_all_dataset_history,\n",
    "                \"mean_cluster_accuracy_total_all_dataset_history\": mean_cluster_accuracy_total_all_dataset_history,\n",
    "            }, f)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mbhkim003\u001b[0m (\u001b[33mbhkim003-seoul-national-university\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.19.8 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.17.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/nfs/home/bhkim003/github_folder/ByeonghyeonKim/my_snn/wandb/run-20250314_000326-s2i7pngp</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/bhkim003-seoul-national-university/spike_sorting%20just%20run/runs/s2i7pngp' target=\"_blank\">dashing-star-1485</a></strong> to <a href='https://wandb.ai/bhkim003-seoul-national-university/spike_sorting%20just%20run' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/bhkim003-seoul-national-university/spike_sorting%20just%20run' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/spike_sorting%20just%20run</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/bhkim003-seoul-national-university/spike_sorting%20just%20run/runs/s2i7pngp' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/spike_sorting%20just%20run/runs/s2i7pngp</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'gpu': '3', 'Conv_net': True, 'SAE_net': True, 'dataset_num': 16, 'spike_length': 50, 'num_cluster': 4, 'training_cycle': 1400, 'batch_size': 32, 'max_epoch': 10000, 'learning_rate': 0.001, 'normalize_on': True, 'need_bias': False, 'lif_add_at_first': False, 'my_seed': 42, 'TIME': 50, 'v_decay': 0.5, 'v_threshold': 0.25, 'v_reset': 0.0, 'BPTT_on': True, 'SAE_hidden_nomean': True, 'current_time': '20250314_000324_593', 'optimizer': 'Adam', 'coarse_com_mode': True, 'sae_l2_norm_bridge': True, 'sae_lif_bridge': False, 'accuracy_check_epoch_term': 1, 'lif_add_at_last': False, 'two_channel_input': False, 'lateral_feature_num': 8, 'lc_adc_on': False, 'converted_net_forward': False, 'pretrained_net': None, 'vth_mul_on': False, 'batch_norm_on': False, 'l2_norm_loss_weight': 0, 'QCFS_neuron_on': False, 'quantize_level_num': 0, 'fusion_net': True, 'repeat_coding': False, 'sae_relu_on': False, 'conv1d_scaling': False, 'norm01': True, 'coarse_com_config': (0.999, -0.0)}\n",
      "cos_thr [0.95 0.95 0.95 0.95 0.95 0.95 0.95 0.85 0.95 0.9  0.8  0.95 0.95 0.95\n",
      " 0.95 0.8 ]\n",
      "conv length [50, 24, 11, 5]\n",
      "Total number of encoder parameters: 31712\n",
      "DataParallel(\n",
      "  (module): SAE_FUSION7_net_conv1(\n",
      "    (activation_function): LIF_layer()\n",
      "    (encoder): Sequential(\n",
      "      (0): SSBH_DimChanger_one_two()\n",
      "      (1): SSBH_DimChanger_for_one_two_coupling()\n",
      "      (2): Conv1d(1, 32, kernel_size=(3,), stride=(2,), bias=False)\n",
      "      (3): SSBH_DimChanger_for_one_two_decoupling()\n",
      "      (4): LIF_layer()\n",
      "      (5): SSBH_DimChanger_for_one_two_coupling()\n",
      "      (6): Conv1d(32, 64, kernel_size=(3,), stride=(2,), bias=False)\n",
      "      (7): SSBH_DimChanger_for_one_two_decoupling()\n",
      "      (8): LIF_layer()\n",
      "      (9): SSBH_DimChanger_for_one_two_coupling()\n",
      "      (10): Conv1d(64, 96, kernel_size=(3,), stride=(2,), bias=False)\n",
      "      (11): SSBH_DimChanger_for_one_two_decoupling()\n",
      "      (12): LIF_layer()\n",
      "      (13): SSBH_DimChanger_for_one_two_coupling()\n",
      "      (14): SSBH_DimChanger_for_fc()\n",
      "      (15): Linear(in_features=480, out_features=8, bias=False)\n",
      "      (16): SSBH_DimChanger_for_one_two_decoupling()\n",
      "      (17): LIF_layer()\n",
      "      (18): SSBH_DimChanger_one_two()\n",
      "      (19): SSBH_DimChanger_for_two_three_coupling()\n",
      "      (20): Linear(in_features=400, out_features=8, bias=False)\n",
      "      (21): SSBH_L2NormLayer()\n",
      "    )\n",
      "    (decoder): Sequential(\n",
      "      (0): Linear(in_features=8, out_features=480, bias=False)\n",
      "      (1): ReLU()\n",
      "      (2): SSBH_DimChanger_for_conv1()\n",
      "      (3): ConvTranspose1d(96, 64, kernel_size=(3,), stride=(2,), bias=False)\n",
      "      (4): ReLU()\n",
      "      (5): ConvTranspose1d(64, 32, kernel_size=(3,), stride=(2,), output_padding=(1,), bias=False)\n",
      "      (6): ReLU()\n",
      "      (7): ConvTranspose1d(32, 1, kernel_size=(3,), stride=(2,), output_padding=(1,), bias=False)\n",
      "    )\n",
      "  )\n",
      ")\n",
      "Device: cuda\n",
      "\n",
      "Start Training, current_time = 20250314_000324_593\n",
      "\n",
      "\n",
      "epoch-0 loss : 0.02378105, loss_normal : 0.01632804, loss_coarse : 0.07116727, min_loss : 0.02378105, min_loss_normal : 0.01632804, min_loss_coarse : 0.07116727, wrong_element_sum : 13664116.00000000, same_data : 0.00%\n",
      "ae train 실행 시간: 117.998초, 전체 시작 시간 20250314_000324_593\n",
      "\n",
      "epoch-0 accuracy check\n",
      "k_means origin feature average accuracy : 82.25492108%, total [0.9746727376209448, 0.9733106189664963, 0.9700891573195284, 0.9530800230282096, 0.943108504398827, 0.9150568181818182, 0.801817648783348, 0.6625070901871809, 0.9488619568430388, 0.822215777262181, 0.5866935483870968, 0.5005858230814294, 0.9429250891795482, 0.8922588099364529, 0.673546511627907, 0.6000572573718866]\n",
      "save model\n",
      "kmeans average accuracy best : 88.97%, kmeans average accuracy : 88.97421748%, total [0.9758110415480934, 0.9772856331629756, 0.9741156169111302, 0.9617156016119747, 0.9565982404692082, 0.9451704545454546, 0.9029610085019056, 0.817356778218945, 0.9470883830919302, 0.8831206496519721, 0.7828341013824884, 0.6915641476274165, 0.9509512485136742, 0.9208549971114962, 0.825, 0.7234468937875751]\n",
      "cluster_accuracy_post_training_cycle_all_dataset : [0.97776727 0.97832234 0.97544535 0.96576663 0.95671642 0.94528302\n",
      " 0.91546494 0.81608655 0.9329299  0.89013672 0.76254826 0.66037736\n",
      " 0.950611   0.9199806  0.83235294 0.74534161]\n",
      "mean_cluster_accuracy_during_training_cycle : 87.90%, post_traincycle_acc : 88.91%, total_acc : 88.49620197%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 88.91%\n",
      "accuracy_check 실행 시간: 28.755초\n",
      "\n",
      "\n",
      "epoch-1 loss : 0.00800774, loss_normal : 0.01072597, loss_coarse : 0.04983849, min_loss : 0.00800774, min_loss_normal : 0.01072597, min_loss_coarse : 0.04983849, wrong_element_sum : 9568990.00000000, same_data : 0.00%\n",
      "ae train 실행 시간: 118.760초, 전체 시작 시간 20250314_000324_593\n",
      "\n",
      "epoch-1 accuracy check\n",
      "k_means origin feature average accuracy : 82.26042087%, total [0.9746727376209448, 0.9733106189664963, 0.9700891573195284, 0.9530800230282096, 0.943108504398827, 0.9150568181818182, 0.801817648783348, 0.6625070901871809, 0.9488619568430388, 0.822215777262181, 0.5872695852534562, 0.5005858230814294, 0.9429250891795482, 0.8922588099364529, 0.6747093023255814, 0.5991983967935872]\n",
      "save model\n",
      "kmeans average accuracy best : 90.36%, kmeans average accuracy : 90.35778485%, total [0.9755264655663062, 0.9775695627484384, 0.9744032211676733, 0.9637305699481865, 0.9580645161290322, 0.9511363636363637, 0.9170331281149223, 0.8369256948383438, 0.963641738102276, 0.9103828306264501, 0.8205645161290323, 0.7226127709431751, 0.955410225921522, 0.9191218948584633, 0.8424418604651163, 0.7686802175780132]\n",
      "cluster_accuracy_post_training_cycle_all_dataset : [0.97871334 0.97879359 0.97544535 0.96576663 0.96119403 0.94716981\n",
      " 0.91994033 0.83866416 0.95763994 0.92138672 0.79247104 0.7388282\n",
      " 0.95315682 0.91561591 0.85       0.77305303]\n",
      "mean_cluster_accuracy_during_training_cycle : 89.51%, post_traincycle_acc : 90.42%, total_acc : 90.04919290%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 90.42%\n",
      "accuracy_check 실행 시간: 22.791초\n",
      "\n",
      "\n",
      "epoch-2 loss : 0.00748884, loss_normal : 0.01058220, loss_coarse : 0.04828534, min_loss : 0.00748884, min_loss_normal : 0.01058220, min_loss_coarse : 0.04828534, wrong_element_sum : 9270786.00000000, same_data : 0.00%\n",
      "ae train 실행 시간: 113.191초, 전체 시작 시간 20250314_000324_593\n",
      "\n",
      "epoch-2 accuracy check\n",
      "k_means origin feature average accuracy : 82.25682366%, total [0.9746727376209448, 0.9733106189664963, 0.9700891573195284, 0.9530800230282096, 0.943108504398827, 0.915340909090909, 0.801817648783348, 0.6622234826999432, 0.9488619568430388, 0.822215777262181, 0.5866935483870968, 0.5005858230814294, 0.9429250891795482, 0.8922588099364529, 0.6747093023255814, 0.5991983967935872]\n",
      "save model\n",
      "kmeans average accuracy best : 90.74%, kmeans average accuracy : 90.73732075%, total [0.9755264655663062, 0.9778534923339012, 0.9744032211676733, 0.9625791594703512, 0.9574780058651027, 0.9528409090909091, 0.9211374963353856, 0.8423142370958593, 0.9645285249778304, 0.91792343387471, 0.8173963133640553, 0.7483889865260691, 0.950653983353151, 0.9269208549971115, 0.8433139534883721, 0.7847122817062697]\n",
      "cluster_accuracy_post_training_cycle_all_dataset : [0.97918638 0.97832234 0.97544535 0.96576663 0.96069652 0.94811321\n",
      " 0.92640477 0.83725306 0.9591528  0.92333984 0.80405405 0.71151936\n",
      " 0.95366599 0.92774006 0.85196078 0.79980889]\n",
      "mean_cluster_accuracy_during_training_cycle : 90.14%, post_traincycle_acc : 90.64%, total_acc : 90.43819896%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 90.64%\n",
      "accuracy_check 실행 시간: 22.625초\n",
      "\n",
      "\n",
      "epoch-3 loss : 0.00732426, loss_normal : 0.01052352, loss_coarse : 0.04772117, min_loss : 0.00732426, min_loss_normal : 0.01052352, min_loss_coarse : 0.04772117, wrong_element_sum : 9162464.00000000, same_data : 0.00%\n",
      "ae train 실행 시간: 116.643초, 전체 시작 시간 20250314_000324_593\n",
      "\n",
      "epoch-3 accuracy check\n",
      "k_means origin feature average accuracy : 82.24960240%, total [0.9746727376209448, 0.9733106189664963, 0.9700891573195284, 0.9530800230282096, 0.943108504398827, 0.915340909090909, 0.801817648783348, 0.6622234826999432, 0.9488619568430388, 0.822215777262181, 0.5866935483870968, 0.5005858230814294, 0.9429250891795482, 0.8911034084344309, 0.6747093023255814, 0.5991983967935872]\n",
      "kmeans average accuracy best : 90.74%, kmeans average accuracy : 90.54297335%, total [0.9758110415480934, 0.9772856331629756, 0.9741156169111302, 0.9637305699481865, 0.9580645161290322, 0.953125, 0.9132219290530637, 0.8287010777084515, 0.9606857818504286, 0.9089327146171694, 0.8142281105990783, 0.7475102519039251, 0.9571938168846611, 0.9309647602541883, 0.852906976744186, 0.770397938734612]\n",
      "cluster_accuracy_post_training_cycle_all_dataset : [0.97776727 0.97785108 0.97544535 0.96624879 0.96169154 0.94858491\n",
      " 0.91596221 0.82502352 0.95461422 0.92041016 0.7953668  0.74180735\n",
      " 0.95723014 0.93113482 0.85980392 0.78738653]\n",
      "mean_cluster_accuracy_during_training_cycle : 89.59%, post_traincycle_acc : 90.60%, total_acc : 90.19105879%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 90.64%\n",
      "accuracy_check 실행 시간: 22.507초\n",
      "\n",
      "\n",
      "epoch-4 loss : 0.00715215, loss_normal : 0.01045393, loss_coarse : 0.04709529, min_loss : 0.00715215, min_loss_normal : 0.01045393, min_loss_coarse : 0.04709529, wrong_element_sum : 9042296.00000000, same_data : 0.00%\n",
      "ae train 실행 시간: 117.319초, 전체 시작 시간 20250314_000324_593\n",
      "\n",
      "epoch-4 accuracy check\n",
      "k_means origin feature average accuracy : 82.25671829%, total [0.9746727376209448, 0.9733106189664963, 0.9700891573195284, 0.9530800230282096, 0.943108504398827, 0.915340909090909, 0.801817648783348, 0.6625070901871809, 0.9488619568430388, 0.822215777262181, 0.5872695852534562, 0.5005858230814294, 0.9429250891795482, 0.8922588099364529, 0.673546511627907, 0.5994846836530203]\n",
      "save model\n",
      "kmeans average accuracy best : 91.13%, kmeans average accuracy : 91.12953293%, total [0.9758110415480934, 0.9775695627484384, 0.9744032211676733, 0.9645941278065631, 0.9595307917888563, 0.95625, 0.9240691879214307, 0.845150311968236, 0.9612769731007981, 0.9080626450116009, 0.8381336405529954, 0.7598125366139425, 0.9509512485136742, 0.9329867128827267, 0.8654069767441861, 0.7867162897223018]\n",
      "cluster_accuracy_post_training_cycle_all_dataset : [0.9782403  0.97737983 0.97544535 0.96673095 0.96218905 0.95235849\n",
      " 0.92541024 0.84242709 0.94452849 0.92138672 0.8030888  0.77308838\n",
      " 0.95213849 0.92725509 0.86862745 0.8079312 ]\n",
      "mean_cluster_accuracy_during_training_cycle : 90.53%, post_traincycle_acc : 91.11%, total_acc : 90.87437320%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 91.11%\n",
      "accuracy_check 실행 시간: 22.585초\n",
      "\n",
      "\n",
      "epoch-5 loss : 0.00709279, loss_normal : 0.01043022, loss_coarse : 0.04687075, min_loss : 0.00709279, min_loss_normal : 0.01043022, min_loss_coarse : 0.04687075, wrong_element_sum : 8999184.00000000, same_data : 0.00%\n",
      "ae train 실행 시간: 119.202초, 전체 시작 시간 20250314_000324_593\n",
      "\n",
      "epoch-5 accuracy check\n",
      "k_means origin feature average accuracy : 82.26400538%, total [0.9746727376209448, 0.9733106189664963, 0.9700891573195284, 0.9530800230282096, 0.943108504398827, 0.9150568181818182, 0.801817648783348, 0.6625070901871809, 0.9488619568430388, 0.822215777262181, 0.5866935483870968, 0.5005858230814294, 0.9429250891795482, 0.8922588099364529, 0.675, 0.6000572573718866]\n",
      "kmeans average accuracy best : 91.13%, kmeans average accuracy : 90.73035707%, total [0.9760956175298805, 0.9772856331629756, 0.9744032211676733, 0.9640184225676454, 0.9601173020527859, 0.9568181818181818, 0.9223101729698036, 0.8454339194554736, 0.9627549512267218, 0.9187935034802784, 0.8375576036866359, 0.7642062097246631, 0.9500594530321046, 0.9182553437319468, 0.8395348837209302, 0.7492127111365589]\n",
      "cluster_accuracy_post_training_cycle_all_dataset : [0.97918638 0.97785108 0.97496389 0.96624879 0.9641791  0.95330189\n",
      " 0.92441571 0.84336783 0.94553707 0.93408203 0.79874517 0.76266137\n",
      " 0.95162933 0.90979631 0.85441176 0.76397516]\n",
      "mean_cluster_accuracy_during_training_cycle : 90.24%, post_traincycle_acc : 90.65%, total_acc : 90.48489296%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 91.11%\n",
      "accuracy_check 실행 시간: 22.436초\n",
      "\n",
      "\n",
      "epoch-6 loss : 0.00695364, loss_normal : 0.01037981, loss_coarse : 0.04636941, min_loss : 0.00695364, min_loss_normal : 0.01037981, min_loss_coarse : 0.04636941, wrong_element_sum : 8902926.00000000, same_data : 0.00%\n",
      "ae train 실행 시간: 119.148초, 전체 시작 시간 20250314_000324_593\n",
      "\n",
      "epoch-6 accuracy check\n",
      "k_means origin feature average accuracy : 82.25678715%, total [0.9746727376209448, 0.9733106189664963, 0.9700891573195284, 0.9530800230282096, 0.943108504398827, 0.9150568181818182, 0.801817648783348, 0.6625070901871809, 0.9488619568430388, 0.822215777262181, 0.5872695852534562, 0.5005858230814294, 0.9429250891795482, 0.8922588099364529, 0.6741279069767442, 0.5991983967935872]\n",
      "save model\n",
      "kmeans average accuracy best : 91.25%, kmeans average accuracy : 91.24809834%, total [0.9760956175298805, 0.9778534923339012, 0.9746908254242163, 0.9643062751871042, 0.9612903225806452, 0.9585227272727272, 0.931691586045148, 0.8621667612024957, 0.9663020987289388, 0.9185034802784223, 0.8398617511520737, 0.760398359695372, 0.9512485136741974, 0.9196995956094743, 0.8540697674418605, 0.7829945605496708]\n",
      "cluster_accuracy_post_training_cycle_all_dataset : [0.97918638 0.97832234 0.97544535 0.96673095 0.96567164 0.95424528\n",
      " 0.93038289 0.85606773 0.95612708 0.9296875  0.79971042 0.77060576\n",
      " 0.95112016 0.92192047 0.85784314 0.79694219]\n",
      "mean_cluster_accuracy_during_training_cycle : 90.46%, post_traincycle_acc : 91.19%, total_acc : 90.89063022%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 91.19%\n",
      "accuracy_check 실행 시간: 22.166초\n",
      "\n",
      "\n",
      "epoch-7 loss : 0.00692751, loss_normal : 0.01035689, loss_coarse : 0.04625586, min_loss : 0.00692751, min_loss_normal : 0.01035689, min_loss_coarse : 0.04625586, wrong_element_sum : 8881126.00000000, same_data : 0.00%\n",
      "ae train 실행 시간: 104.609초, 전체 시작 시간 20250314_000324_593\n",
      "\n",
      "epoch-7 accuracy check\n",
      "k_means origin feature average accuracy : 82.26033061%, total [0.9746727376209448, 0.9733106189664963, 0.9700891573195284, 0.9530800230282096, 0.943108504398827, 0.9150568181818182, 0.801817648783348, 0.6625070901871809, 0.9488619568430388, 0.822215777262181, 0.5866935483870968, 0.5005858230814294, 0.942627824019025, 0.8922588099364529, 0.6747093023255814, 0.6000572573718866]\n",
      "kmeans average accuracy best : 91.25%, kmeans average accuracy : 91.21455100%, total [0.9758110415480934, 0.9778534923339012, 0.9744032211676733, 0.9637305699481865, 0.9615835777126099, 0.9559659090909091, 0.9243623570800352, 0.8562110039705049, 0.9645285249778304, 0.921983758700696, 0.8430299539170507, 0.7691857059168131, 0.9509512485136742, 0.9240323512420566, 0.8494186046511628, 0.7812768393930719]\n",
      "cluster_accuracy_post_training_cycle_all_dataset : [0.97871334 0.97785108 0.97496389 0.96721311 0.9641791  0.9504717\n",
      " 0.93038289 0.85136406 0.95511851 0.9296875  0.80743243 0.74677259\n",
      " 0.94450102 0.9228904  0.85735294 0.79025323]\n",
      "mean_cluster_accuracy_during_training_cycle : 90.17%, post_traincycle_acc : 90.93%, total_acc : 90.61924823%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 91.19%\n",
      "accuracy_check 실행 시간: 22.041초\n",
      "\n",
      "\n",
      "epoch-8 loss : 0.00689962, loss_normal : 0.01034276, loss_coarse : 0.04615080, min_loss : 0.00689962, min_loss_normal : 0.01034276, min_loss_coarse : 0.04615080, wrong_element_sum : 8860954.00000000, same_data : 0.00%\n",
      "ae train 실행 시간: 108.561초, 전체 시작 시간 20250314_000324_593\n",
      "\n",
      "epoch-8 accuracy check\n",
      "k_means origin feature average accuracy : 82.25674876%, total [0.9746727376209448, 0.9733106189664963, 0.9700891573195284, 0.9530800230282096, 0.943108504398827, 0.9150568181818182, 0.801817648783348, 0.6622234826999432, 0.9488619568430388, 0.822215777262181, 0.5872695852534562, 0.5005858230814294, 0.9429250891795482, 0.8922588099364529, 0.673546511627907, 0.6000572573718866]\n",
      "save model\n",
      "kmeans average accuracy best : 91.40%, kmeans average accuracy : 91.39756883%, total [0.9763801935116676, 0.9778534923339012, 0.9741156169111302, 0.9640184225676454, 0.9615835777126099, 0.9590909090909091, 0.931691586045148, 0.8635847986386841, 0.9606857818504286, 0.9187935034802784, 0.8387096774193549, 0.7697715289982425, 0.9536266349583828, 0.9283651068746389, 0.8523255813953489, 0.7930146006298311]\n",
      "cluster_accuracy_post_training_cycle_all_dataset : [0.97965941 0.97832234 0.97544535 0.96576663 0.9641791  0.95518868\n",
      " 0.93436101 0.8565381  0.94957136 0.92871094 0.80019305 0.78699106\n",
      " 0.95519348 0.92774006 0.86078431 0.80888677]\n",
      "mean_cluster_accuracy_during_training_cycle : 90.75%, post_traincycle_acc : 91.42%, total_acc : 91.14576306%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 91.42%\n",
      "accuracy_check 실행 시간: 21.835초\n",
      "\n",
      "\n",
      "epoch-9 loss : 0.00681234, loss_normal : 0.01031458, loss_coarse : 0.04583822, min_loss : 0.00681234, min_loss_normal : 0.01031458, min_loss_coarse : 0.04583822, wrong_element_sum : 8800938.00000000, same_data : 0.00%\n",
      "ae train 실행 시간: 107.657초, 전체 시작 시간 20250314_000324_593\n",
      "\n",
      "epoch-9 accuracy check\n",
      "k_means origin feature average accuracy : 82.24062348%, total [0.9746727376209448, 0.9733106189664963, 0.9700891573195284, 0.9530800230282096, 0.943108504398827, 0.9150568181818182, 0.801817648783348, 0.6622234826999432, 0.9488619568430388, 0.822215777262181, 0.5866935483870968, 0.5005858230814294, 0.9429250891795482, 0.8922588099364529, 0.673546511627907, 0.5980532493558546]\n",
      "save model\n",
      "kmeans average accuracy best : 91.72%, kmeans average accuracy : 91.72095243%, total [0.9758110415480934, 0.9778534923339012, 0.9741156169111302, 0.9631548647092688, 0.9615835777126099, 0.9585227272727272, 0.9264145411902668, 0.8567782189449802, 0.9698492462311558, 0.933584686774942, 0.8623271889400922, 0.7832454598711189, 0.9568965517241379, 0.9347198151357596, 0.8537790697674419, 0.7867162897223018]\n",
      "cluster_accuracy_post_training_cycle_all_dataset : [0.97871334 0.97832234 0.97544535 0.96673095 0.96517413 0.95518868\n",
      " 0.93137742 0.8494826  0.95259708 0.94189453 0.81805019 0.7999007\n",
      " 0.95773931 0.92240543 0.86813725 0.79503106]\n",
      "mean_cluster_accuracy_during_training_cycle : 91.18%, post_traincycle_acc : 91.60%, total_acc : 91.42712759%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 91.60%\n",
      "accuracy_check 실행 시간: 21.564초\n",
      "\n",
      "\n",
      "epoch-10 loss : 0.00677171, loss_normal : 0.01029671, loss_coarse : 0.04571980, min_loss : 0.00677171, min_loss_normal : 0.01029671, min_loss_coarse : 0.04571980, wrong_element_sum : 8778202.00000000, same_data : 0.00%\n",
      "ae train 실행 시간: 113.752초, 전체 시작 시간 20250314_000324_593\n",
      "\n",
      "epoch-10 accuracy check\n",
      "k_means origin feature average accuracy : 82.25490563%, total [0.9746727376209448, 0.9733106189664963, 0.9700891573195284, 0.9530800230282096, 0.943108504398827, 0.9150568181818182, 0.8015244796247435, 0.6625070901871809, 0.9488619568430388, 0.822215777262181, 0.5866935483870968, 0.5005858230814294, 0.9429250891795482, 0.8922588099364529, 0.6738372093023256, 0.6000572573718866]\n",
      "save model\n",
      "kmeans average accuracy best : 91.90%, kmeans average accuracy : 91.90451771%, total [0.9766647694934547, 0.9778534923339012, 0.9744032211676733, 0.9637305699481865, 0.9612903225806452, 0.9590909090909091, 0.9363822925828202, 0.8627339761769711, 0.967188885604493, 0.935614849187935, 0.8744239631336406, 0.7937902753368483, 0.9527348394768134, 0.9263431542461005, 0.8523255813953489, 0.7901517320354996]\n",
      "cluster_accuracy_post_training_cycle_all_dataset : [0.98013245 0.97832234 0.97496389 0.96624879 0.9641791  0.95518868\n",
      " 0.9373446  0.85700847 0.95965709 0.94042969 0.82722008 0.57199603\n",
      " 0.95417515 0.9228904  0.85784314 0.80172002]\n",
      "mean_cluster_accuracy_during_training_cycle : 90.02%, post_traincycle_acc : 90.31%, total_acc : 90.19007427%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 90.31%\n",
      "accuracy_check 실행 시간: 21.873초\n",
      "\n",
      "\n",
      "epoch-11 loss : 0.00671969, loss_normal : 0.01027353, loss_coarse : 0.04547278, min_loss : 0.00671969, min_loss_normal : 0.01027353, min_loss_coarse : 0.04547278, wrong_element_sum : 8730774.00000000, same_data : 0.00%\n",
      "ae train 실행 시간: 113.284초, 전체 시작 시간 20250314_000324_593\n",
      "\n",
      "epoch-11 accuracy check\n",
      "k_means origin feature average accuracy : 82.25683739%, total [0.9746727376209448, 0.9733106189664963, 0.9700891573195284, 0.9530800230282096, 0.943108504398827, 0.9150568181818182, 0.801817648783348, 0.6622234826999432, 0.9488619568430388, 0.822215777262181, 0.5866935483870968, 0.5005858230814294, 0.9429250891795482, 0.8922588099364529, 0.6747093023255814, 0.5994846836530203]\n",
      "save model\n",
      "kmeans average accuracy best : 91.94%, kmeans average accuracy : 91.94362771%, total [0.9755264655663062, 0.978137421919364, 0.9741156169111302, 0.9628670120898101, 0.9615835777126099, 0.9582386363636364, 0.9278803869832893, 0.8573454339194555, 0.9674844812296778, 0.9306844547563805, 0.861463133640553, 0.7902753368482718, 0.9604637336504162, 0.9367417677642981, 0.8665697674418604, 0.8016032064128257]\n",
      "cluster_accuracy_post_training_cycle_all_dataset : [0.9782403  0.97785108 0.97544535 0.96480231 0.96467662 0.95235849\n",
      " 0.93088016 0.8508937  0.96217852 0.93408203 0.82528958 0.79940417\n",
      " 0.9607943  0.93501455 0.87205882 0.8050645 ]\n",
      "mean_cluster_accuracy_during_training_cycle : 91.38%, post_traincycle_acc : 91.81%, total_acc : 91.62819783%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 91.81%\n",
      "accuracy_check 실행 시간: 24.171초\n",
      "\n",
      "\n",
      "epoch-12 loss : 0.00672006, loss_normal : 0.01027461, loss_coarse : 0.04548649, min_loss : 0.00671969, min_loss_normal : 0.01027353, min_loss_coarse : 0.04547278, wrong_element_sum : 8733406.00000000, same_data : 0.00%\n",
      "ae train 실행 시간: 118.880초, 전체 시작 시간 20250314_000324_593\n",
      "\n",
      "epoch-12 accuracy check\n",
      "k_means origin feature average accuracy : 82.25134010%, total [0.9746727376209448, 0.9733106189664963, 0.9700891573195284, 0.9530800230282096, 0.943108504398827, 0.9150568181818182, 0.801817648783348, 0.6622234826999432, 0.9488619568430388, 0.8216357308584686, 0.5866935483870968, 0.5005858230814294, 0.9429250891795482, 0.8922588099364529, 0.6738372093023256, 0.6000572573718866]\n",
      "kmeans average accuracy best : 91.94%, kmeans average accuracy : 91.61987218%, total [0.9763801935116676, 0.9772856331629756, 0.9744032211676733, 0.9631548647092688, 0.9624633431085043, 0.9565340909090909, 0.9252418645558487, 0.8516732841747022, 0.9665976943541236, 0.923723897911833, 0.8502304147465438, 0.7809021675454013, 0.9568965517241379, 0.9332755632582322, 0.8648255813953488, 0.7955911823647295]\n",
      "cluster_accuracy_post_training_cycle_all_dataset : [0.98013245 0.97785108 0.97496389 0.96480231 0.96567164 0.95330189\n",
      " 0.92342118 0.84336783 0.93847705 0.92773438 0.81177606 0.78351539\n",
      " 0.95824847 0.93064985 0.87892157 0.80267559]\n",
      "mean_cluster_accuracy_during_training_cycle : 91.15%, post_traincycle_acc : 91.35%, total_acc : 91.26634597%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 91.81%\n",
      "accuracy_check 실행 시간: 24.243초\n",
      "\n",
      "\n",
      "epoch-13 loss : 0.00668569, loss_normal : 0.01026237, loss_coarse : 0.04535238, min_loss : 0.00668569, min_loss_normal : 0.01026237, min_loss_coarse : 0.04535238, wrong_element_sum : 8707658.00000000, same_data : 0.00%\n",
      "ae train 실행 시간: 121.779초, 전체 시작 시간 20250314_000324_593\n",
      "\n",
      "epoch-13 accuracy check\n",
      "k_means origin feature average accuracy : 82.24959751%, total [0.9746727376209448, 0.9733106189664963, 0.9700891573195284, 0.9530800230282096, 0.943108504398827, 0.9150568181818182, 0.801817648783348, 0.6622234826999432, 0.9488619568430388, 0.822215777262181, 0.5866935483870968, 0.5005858230814294, 0.9429250891795482, 0.8922588099364529, 0.6738372093023256, 0.5991983967935872]\n",
      "kmeans average accuracy best : 91.94%, kmeans average accuracy : 91.85610523%, total [0.9763801935116676, 0.9775695627484384, 0.9738280126545873, 0.9628670120898101, 0.9621700879765396, 0.9559659090909091, 0.9284667253004983, 0.8567782189449802, 0.9674844812296778, 0.9309744779582366, 0.8525345622119815, 0.7832454598711189, 0.9563020214030915, 0.9341421143847487, 0.8715116279069768, 0.8067563698826223]\n",
      "cluster_accuracy_post_training_cycle_all_dataset : [0.97965941 0.97832234 0.97496389 0.96528447 0.96567164 0.95330189\n",
      " 0.92690204 0.85418627 0.95713565 0.93652344 0.82480695 0.78748759\n",
      " 0.95824847 0.92919496 0.86764706 0.82226469]\n",
      "mean_cluster_accuracy_during_training_cycle : 91.26%, post_traincycle_acc : 91.76%, total_acc : 91.55881072%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 91.81%\n",
      "accuracy_check 실행 시간: 24.583초\n",
      "\n",
      "\n",
      "epoch-14 loss : 0.00668479, loss_normal : 0.01025892, loss_coarse : 0.04538446, min_loss : 0.00668479, min_loss_normal : 0.01025892, min_loss_coarse : 0.04535238, wrong_element_sum : 8713816.00000000, same_data : 0.00%\n",
      "ae train 실행 시간: 122.055초, 전체 시작 시간 20250314_000324_593\n",
      "\n",
      "epoch-14 accuracy check\n",
      "k_means origin feature average accuracy : 82.25504809%, total [0.9746727376209448, 0.9733106189664963, 0.9700891573195284, 0.9530800230282096, 0.943108504398827, 0.9150568181818182, 0.801817648783348, 0.6622234826999432, 0.9488619568430388, 0.822215777262181, 0.5866935483870968, 0.5005858230814294, 0.9429250891795482, 0.8922588099364529, 0.6747093023255814, 0.5991983967935872]\n",
      "kmeans average accuracy best : 91.94%, kmeans average accuracy : 91.73583221%, total [0.9760956175298805, 0.978137421919364, 0.9744032211676733, 0.9637305699481865, 0.9618768328445748, 0.9582386363636364, 0.9275872178246849, 0.8579126488939308, 0.966006503103754, 0.9306844547563805, 0.8476382488479263, 0.7776801405975395, 0.9568965517241379, 0.9332755632582322, 0.8645348837209302, 0.8030346407099914]\n",
      "cluster_accuracy_post_training_cycle_all_dataset : [0.97871334 0.97832234 0.97496389 0.96528447 0.96616915 0.95377358\n",
      " 0.93336648 0.85042333 0.95713565 0.9375     0.81177606 0.78003972\n",
      " 0.95875764 0.93161979 0.88676471 0.82274247]\n",
      "mean_cluster_accuracy_during_training_cycle : 91.03%, post_traincycle_acc : 91.80%, total_acc : 91.48430253%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 91.81%\n",
      "accuracy_check 실행 시간: 24.482초\n",
      "\n",
      "\n",
      "epoch-15 loss : 0.00659980, loss_normal : 0.01022758, loss_coarse : 0.04508730, min_loss : 0.00659980, min_loss_normal : 0.01022758, min_loss_coarse : 0.04508730, wrong_element_sum : 8656762.00000000, same_data : 0.00%\n",
      "ae train 실행 시간: 119.327초, 전체 시작 시간 20250314_000324_593\n",
      "\n",
      "epoch-15 accuracy check\n",
      "k_means origin feature average accuracy : 82.24778065%, total [0.9746727376209448, 0.9733106189664963, 0.9700891573195284, 0.9530800230282096, 0.943108504398827, 0.9150568181818182, 0.801817648783348, 0.6622234826999432, 0.9488619568430388, 0.822215777262181, 0.5866935483870968, 0.5005858230814294, 0.9429250891795482, 0.8922588099364529, 0.673546511627907, 0.5991983967935872]\n",
      "save model\n",
      "kmeans average accuracy best : 91.94%, kmeans average accuracy : 91.94420310%, total [0.9758110415480934, 0.9775695627484384, 0.9735404083980443, 0.9637305699481865, 0.9627565982404692, 0.9576704545454545, 0.9308120785693345, 0.8641520136131594, 0.968371268105232, 0.9330046403712297, 0.8505184331797235, 0.7785588752196837, 0.9571938168846611, 0.9376083188908145, 0.876453488372093, 0.8033209275694245]\n",
      "cluster_accuracy_post_training_cycle_all_dataset : [0.97871334 0.97879359 0.97544535 0.96576663 0.96567164 0.95424528\n",
      " 0.93436101 0.855127   0.95562279 0.94189453 0.81032819 0.5774578\n",
      " 0.9592668  0.92822502 0.89313725 0.81748686]\n",
      "mean_cluster_accuracy_during_training_cycle : 90.12%, post_traincycle_acc : 90.57%, total_acc : 90.38602896%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 90.57%\n",
      "accuracy_check 실행 시간: 24.403초\n",
      "\n",
      "\n",
      "epoch-16 loss : 0.00660682, loss_normal : 0.01022744, loss_coarse : 0.04511127, min_loss : 0.00659980, min_loss_normal : 0.01022744, min_loss_coarse : 0.04508730, wrong_element_sum : 8661364.00000000, same_data : 0.00%\n",
      "ae train 실행 시간: 120.747초, 전체 시작 시간 20250314_000324_593\n",
      "\n",
      "epoch-16 accuracy check\n",
      "k_means origin feature average accuracy : 82.26218852%, total [0.9746727376209448, 0.9733106189664963, 0.9700891573195284, 0.9530800230282096, 0.943108504398827, 0.9150568181818182, 0.801817648783348, 0.6625070901871809, 0.9488619568430388, 0.822215777262181, 0.5866935483870968, 0.5005858230814294, 0.9429250891795482, 0.8922588099364529, 0.6747093023255814, 0.6000572573718866]\n",
      "kmeans average accuracy best : 91.94%, kmeans average accuracy : 91.59300956%, total [0.9760956175298805, 0.9775695627484384, 0.9741156169111302, 0.9631548647092688, 0.9621700879765396, 0.9576704545454545, 0.9308120785693345, 0.8613159387407827, 0.9642329293526456, 0.9202436194895591, 0.8320852534562212, 0.7700644405389573, 0.9574910820451843, 0.9355863662622761, 0.8726744186046511, 0.7995991983967936]\n",
      "cluster_accuracy_post_training_cycle_all_dataset : [0.97918638 0.97785108 0.97496389 0.96528447 0.96467662 0.95330189\n",
      " 0.93137742 0.85606773 0.94957136 0.92675781 0.80646718 0.76266137\n",
      " 0.95977597 0.93258972 0.89264706 0.80984233]\n",
      "mean_cluster_accuracy_during_training_cycle : 91.24%, post_traincycle_acc : 91.52%, total_acc : 91.40420894%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 90.57%\n",
      "accuracy_check 실행 시간: 24.174초\n",
      "\n",
      "\n",
      "epoch-17 loss : 0.00654691, loss_normal : 0.01020599, loss_coarse : 0.04489074, min_loss : 0.00654691, min_loss_normal : 0.01020599, min_loss_coarse : 0.04489074, wrong_element_sum : 8619022.00000000, same_data : 0.00%\n",
      "ae train 실행 시간: 117.993초, 전체 시작 시간 20250314_000324_593\n",
      "\n",
      "epoch-17 accuracy check\n",
      "k_means origin feature average accuracy : 82.25503135%, total [0.9746727376209448, 0.9733106189664963, 0.9700891573195284, 0.9530800230282096, 0.943108504398827, 0.9150568181818182, 0.801817648783348, 0.6625070901871809, 0.9488619568430388, 0.822215777262181, 0.5866935483870968, 0.5005858230814294, 0.9429250891795482, 0.8922588099364529, 0.6747093023255814, 0.598912109934154]\n",
      "kmeans average accuracy best : 91.94%, kmeans average accuracy : 91.90406185%, total [0.9760956175298805, 0.9778534923339012, 0.9744032211676733, 0.9631548647092688, 0.9615835777126099, 0.9579545454545455, 0.9261213720316622, 0.8598979013045944, 0.9701448418563405, 0.9327146171693735, 0.851094470046083, 0.7782659636789689, 0.9631391200951248, 0.9367417677642981, 0.8767441860465116, 0.7987403378184942]\n",
      "cluster_accuracy_post_training_cycle_all_dataset : [0.97918638 0.97832234 0.97544535 0.96624879 0.96467662 0.95283019\n",
      " 0.92938836 0.85465663 0.95965709 0.94189453 0.8219112  0.78450844\n",
      " 0.96130346 0.93016489 0.8872549  0.81892021]\n",
      "mean_cluster_accuracy_during_training_cycle : 91.17%, post_traincycle_acc : 91.91%, total_acc : 91.61281363%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 90.57%\n",
      "accuracy_check 실행 시간: 24.335초\n",
      "\n",
      "\n",
      "epoch-18 loss : 0.00651285, loss_normal : 0.01018982, loss_coarse : 0.04471784, min_loss : 0.00651285, min_loss_normal : 0.01018982, min_loss_coarse : 0.04471784, wrong_element_sum : 8585826.00000000, same_data : 0.00%\n",
      "ae train 실행 시간: 124.474초, 전체 시작 시간 20250314_000324_593\n",
      "\n",
      "epoch-18 accuracy check\n",
      "k_means origin feature average accuracy : 82.26572279%, total [0.9746727376209448, 0.9733106189664963, 0.9700891573195284, 0.9530800230282096, 0.943108504398827, 0.9150568181818182, 0.801817648783348, 0.6622234826999432, 0.9488619568430388, 0.822215777262181, 0.5872695852534562, 0.5005858230814294, 0.9429250891795482, 0.8922588099364529, 0.6738372093023256, 0.6012024048096193]\n",
      "save model\n",
      "kmeans average accuracy best : 91.98%, kmeans average accuracy : 91.97864266%, total [0.9758110415480934, 0.9764338444065872, 0.9744032211676733, 0.9631548647092688, 0.9615835777126099, 0.9559659090909091, 0.9290530636177075, 0.8564946114577425, 0.968371268105232, 0.9399651972157773, 0.861463133640553, 0.789103690685413, 0.9563020214030915, 0.9361640670132871, 0.8752906976744186, 0.7970226166618952]\n",
      "cluster_accuracy_post_training_cycle_all_dataset : [0.97871334 0.97737983 0.97496389 0.96624879 0.96567164 0.95141509\n",
      " 0.93187469 0.8537159  0.9515885  0.94677734 0.81611969 0.79195631\n",
      " 0.95519348 0.92870999 0.88970588 0.80363115]\n",
      "mean_cluster_accuracy_during_training_cycle : 91.16%, post_traincycle_acc : 91.77%, total_acc : 91.52299378%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 91.77%\n",
      "accuracy_check 실행 시간: 23.960초\n",
      "\n",
      "\n",
      "epoch-19 loss : 0.00653736, loss_normal : 0.01019484, loss_coarse : 0.04486321, min_loss : 0.00651285, min_loss_normal : 0.01018982, min_loss_coarse : 0.04471784, wrong_element_sum : 8613736.00000000, same_data : 0.00%\n",
      "ae train 실행 시간: 119.614초, 전체 시작 시간 20250314_000324_593\n",
      "\n",
      "epoch-19 accuracy check\n",
      "k_means origin feature average accuracy : 82.25142280%, total [0.9746727376209448, 0.9733106189664963, 0.9700891573195284, 0.9530800230282096, 0.943108504398827, 0.9150568181818182, 0.801817648783348, 0.6622234826999432, 0.9488619568430388, 0.8216357308584686, 0.5866935483870968, 0.5005858230814294, 0.9429250891795482, 0.8922588099364529, 0.6747093023255814, 0.5991983967935872]\n",
      "kmeans average accuracy best : 91.98%, kmeans average accuracy : 91.77933960%, total [0.9760956175298805, 0.9772856331629756, 0.9746908254242163, 0.9631548647092688, 0.9615835777126099, 0.9548295454545455, 0.9234828496042217, 0.8508224617129893, 0.9689624593556015, 0.9303944315545244, 0.8568548387096774, 0.7797305213825425, 0.9577883472057075, 0.9355863662622761, 0.873546511627907, 0.7998854852562267]\n",
      "cluster_accuracy_post_training_cycle_all_dataset : [0.97918638 0.97832234 0.97496389 0.96432015 0.96616915 0.95188679\n",
      " 0.92789657 0.85277516 0.96520424 0.94140625 0.8238417  0.79642502\n",
      " 0.95977597 0.93549952 0.86715686 0.80888677]\n",
      "mean_cluster_accuracy_during_training_cycle : 91.12%, post_traincycle_acc : 91.84%, total_acc : 91.54564952%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 91.77%\n",
      "accuracy_check 실행 시간: 24.317초\n",
      "\n",
      "\n",
      "epoch-20 loss : 0.00651234, loss_normal : 0.01018082, loss_coarse : 0.04470293, min_loss : 0.00651234, min_loss_normal : 0.01018082, min_loss_coarse : 0.04470293, wrong_element_sum : 8582962.00000000, same_data : 0.00%\n",
      "ae train 실행 시간: 125.133초, 전체 시작 시간 20250314_000324_593\n",
      "\n",
      "epoch-20 accuracy check\n",
      "k_means origin feature average accuracy : 82.25138088%, total [0.9746727376209448, 0.9733106189664963, 0.9700891573195284, 0.9530800230282096, 0.943108504398827, 0.9150568181818182, 0.801817648783348, 0.6622234826999432, 0.9488619568430388, 0.822215777262181, 0.5872695852534562, 0.5005858230814294, 0.9429250891795482, 0.8922588099364529, 0.673546511627907, 0.5991983967935872]\n",
      "kmeans average accuracy best : 91.98%, kmeans average accuracy : 91.57826192%, total [0.9758110415480934, 0.978137421919364, 0.9746908254242163, 0.9643062751871042, 0.9621700879765396, 0.9571022727272728, 0.9284667253004983, 0.8550765740215541, 0.9654153118533846, 0.9234338747099768, 0.8303571428571429, 0.7691857059168131, 0.9616527942925089, 0.9381860196418256, 0.8712209302325581, 0.7973089035213283]\n",
      "cluster_accuracy_post_training_cycle_all_dataset : [0.97871334 0.97832234 0.97496389 0.96673095 0.96517413 0.95235849\n",
      " 0.93187469 0.85559737 0.95057993 0.93066406 0.81370656 0.74428997\n",
      " 0.96232179 0.93598448 0.87745098 0.81748686]\n",
      "mean_cluster_accuracy_during_training_cycle : 90.93%, post_traincycle_acc : 91.48%, total_acc : 91.25561362%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 91.77%\n",
      "accuracy_check 실행 시간: 31.778초\n",
      "\n",
      "\n",
      "epoch-21 loss : 0.00652819, loss_normal : 0.01018066, loss_coarse : 0.04473821, min_loss : 0.00651234, min_loss_normal : 0.01018066, min_loss_coarse : 0.04470293, wrong_element_sum : 8589736.00000000, same_data : 0.00%\n",
      "ae train 실행 시간: 122.392초, 전체 시작 시간 20250314_000324_593\n",
      "\n",
      "epoch-21 accuracy check\n",
      "k_means origin feature average accuracy : 82.25673794%, total [0.9746727376209448, 0.9733106189664963, 0.9700891573195284, 0.9530800230282096, 0.943108504398827, 0.9150568181818182, 0.801817648783348, 0.6625070901871809, 0.9488619568430388, 0.822215777262181, 0.5866935483870968, 0.5005858230814294, 0.9429250891795482, 0.8922588099364529, 0.6738372093023256, 0.6000572573718866]\n",
      "kmeans average accuracy best : 91.98%, kmeans average accuracy : 91.43095785%, total [0.9763801935116676, 0.978137421919364, 0.9746908254242163, 0.966321243523316, 0.9615835777126099, 0.9579545454545455, 0.9313984168865436, 0.8564946114577425, 0.9663020987289388, 0.9216937354988399, 0.8286290322580645, 0.7662565905096661, 0.9568965517241379, 0.9303870595031773, 0.8642441860465117, 0.7915831663326653]\n",
      "cluster_accuracy_post_training_cycle_all_dataset : [0.97965941 0.97832234 0.97496389 0.96769527 0.96567164 0.95424528\n",
      " 0.93684734 0.85559737 0.94503278 0.93066406 0.79971042 0.72591857\n",
      " 0.95672098 0.92677013 0.8754902  0.80363115]\n",
      "mean_cluster_accuracy_during_training_cycle : 90.13%, post_traincycle_acc : 91.11%, total_acc : 90.70574663%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 91.77%\n",
      "accuracy_check 실행 시간: 24.357초\n",
      "\n",
      "\n",
      "epoch-22 loss : 0.00661368, loss_normal : 0.01020082, loss_coarse : 0.04507619, min_loss : 0.00651234, min_loss_normal : 0.01018066, min_loss_coarse : 0.04470293, wrong_element_sum : 8654628.00000000, same_data : 0.00%\n",
      "ae train 실행 시간: 116.599초, 전체 시작 시간 20250314_000324_593\n",
      "\n",
      "epoch-22 accuracy check\n",
      "k_means origin feature average accuracy : 82.24952324%, total [0.9746727376209448, 0.9733106189664963, 0.9700891573195284, 0.9530800230282096, 0.943108504398827, 0.9150568181818182, 0.801817648783348, 0.6622234826999432, 0.9488619568430388, 0.8216357308584686, 0.5866935483870968, 0.5005858230814294, 0.9429250891795482, 0.8922588099364529, 0.673546511627907, 0.6000572573718866]\n",
      "kmeans average accuracy best : 91.98%, kmeans average accuracy : 90.98907380%, total [0.9760956175298805, 0.9778534923339012, 0.9738280126545873, 0.9645941278065631, 0.9612903225806452, 0.9536931818181819, 0.9129287598944591, 0.8304027226318775, 0.9665976943541236, 0.9205336426914154, 0.8225806451612904, 0.7586408904510837, 0.9571938168846611, 0.9335644136337378, 0.8688953488372093, 0.779559118236473]\n",
      "cluster_accuracy_post_training_cycle_all_dataset : [0.97871334 0.97785108 0.97448243 0.96624879 0.96517413 0.94764151\n",
      " 0.92093486 0.82737535 0.95663137 0.93603516 0.79391892 0.77110228\n",
      " 0.95824847 0.93210475 0.86519608 0.7993311 ]\n",
      "mean_cluster_accuracy_during_training_cycle : 90.07%, post_traincycle_acc : 91.07%, total_acc : 90.66105631%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 91.77%\n",
      "accuracy_check 실행 시간: 24.428초\n",
      "\n",
      "\n",
      "epoch-23 loss : 0.00649720, loss_normal : 0.01016161, loss_coarse : 0.04461678, min_loss : 0.00649720, min_loss_normal : 0.01016161, min_loss_coarse : 0.04461678, wrong_element_sum : 8566422.00000000, same_data : 0.00%\n",
      "ae train 실행 시간: 120.773초, 전체 시작 시간 20250314_000324_593\n",
      "\n",
      "epoch-23 accuracy check\n",
      "k_means origin feature average accuracy : 82.26583306%, total [0.9746727376209448, 0.9733106189664963, 0.9700891573195284, 0.9530800230282096, 0.943108504398827, 0.9150568181818182, 0.801817648783348, 0.6622234826999432, 0.9488619568430388, 0.822215777262181, 0.5872695852534562, 0.5005858230814294, 0.9429250891795482, 0.8922588099364529, 0.675, 0.6000572573718866]\n",
      "kmeans average accuracy best : 91.98%, kmeans average accuracy : 91.61300871%, total [0.9758110415480934, 0.9784213515048268, 0.9744032211676733, 0.9651698330454808, 0.9621700879765396, 0.9565340909090909, 0.9328642626795661, 0.8584798638684061, 0.9692580549807863, 0.9321345707656613, 0.8384216589861752, 0.7770943175161101, 0.9545184304399524, 0.9318313113807047, 0.8648255813953488, 0.7861437160034355]\n",
      "cluster_accuracy_post_training_cycle_all_dataset : [0.97918638 0.97879359 0.97544535 0.96769527 0.96666667 0.95330189\n",
      " 0.93187469 0.86312324 0.95461422 0.93603516 0.81225869 0.78848064\n",
      " 0.95621181 0.93258972 0.86960784 0.80267559]\n",
      "mean_cluster_accuracy_during_training_cycle : 91.04%, post_traincycle_acc : 91.68%, total_acc : 91.41858295%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 91.77%\n",
      "accuracy_check 실행 시간: 24.090초\n",
      "\n",
      "\n",
      "epoch-24 loss : 0.00653238, loss_normal : 0.01017003, loss_coarse : 0.04479560, min_loss : 0.00649720, min_loss_normal : 0.01016161, min_loss_coarse : 0.04461678, wrong_element_sum : 8600756.00000000, same_data : 0.00%\n",
      "ae train 실행 시간: 120.634초, 전체 시작 시간 20250314_000324_593\n",
      "\n",
      "epoch-24 accuracy check\n",
      "k_means origin feature average accuracy : 82.25131622%, total [0.9746727376209448, 0.9733106189664963, 0.9700891573195284, 0.9530800230282096, 0.943108504398827, 0.9150568181818182, 0.8015244796247435, 0.6622234826999432, 0.9488619568430388, 0.822215777262181, 0.5866935483870968, 0.5005858230814294, 0.9429250891795482, 0.8922588099364529, 0.673546511627907, 0.6000572573718866]\n",
      "kmeans average accuracy best : 91.98%, kmeans average accuracy : 91.07178705%, total [0.9758110415480934, 0.978137421919364, 0.9746908254242163, 0.9643062751871042, 0.9621700879765396, 0.9539772727272727, 0.9190853122251539, 0.845150311968236, 0.9565474430978421, 0.9031322505800464, 0.8139400921658986, 0.7589338019917985, 0.9557074910820452, 0.9367417677642981, 0.8741279069767441, 0.7990266246779273]\n",
      "cluster_accuracy_post_training_cycle_all_dataset : [0.97871334 0.97832234 0.97544535 0.96576663 0.96616915 0.95\n",
      " 0.9273993  0.84995296 0.94604135 0.91699219 0.79054054 0.66236346\n",
      " 0.95875764 0.93404462 0.88088235 0.81987578]\n",
      "mean_cluster_accuracy_during_training_cycle : 89.75%, post_traincycle_acc : 90.63%, total_acc : 90.27068146%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 91.77%\n",
      "accuracy_check 실행 시간: 24.221초\n",
      "\n",
      "\n",
      "epoch-25 loss : 0.00652002, loss_normal : 0.01016050, loss_coarse : 0.04470148, min_loss : 0.00649720, min_loss_normal : 0.01016050, min_loss_coarse : 0.04461678, wrong_element_sum : 8582684.00000000, same_data : 0.00%\n",
      "ae train 실행 시간: 122.375초, 전체 시작 시간 20250314_000324_593\n",
      "\n",
      "epoch-25 accuracy check\n",
      "k_means origin feature average accuracy : 82.26213178%, total [0.9746727376209448, 0.9733106189664963, 0.9700891573195284, 0.9530800230282096, 0.943108504398827, 0.915340909090909, 0.8015244796247435, 0.6625070901871809, 0.9488619568430388, 0.822215777262181, 0.5866935483870968, 0.5005858230814294, 0.9429250891795482, 0.8922588099364529, 0.6747093023255814, 0.6000572573718866]\n",
      "kmeans average accuracy best : 91.98%, kmeans average accuracy : 91.36303657%, total [0.9760956175298805, 0.9778534923339012, 0.9744032211676733, 0.9648819804260219, 0.9604105571847508, 0.95625, 0.9205511580181764, 0.8474191718661372, 0.9680756724800473, 0.9205336426914154, 0.8375576036866359, 0.7729935559461043, 0.9557074910820452, 0.9280762564991335, 0.8654069767441861, 0.7918694531920984]\n",
      "cluster_accuracy_post_training_cycle_all_dataset : [0.97871334 0.97785108 0.97496389 0.96624879 0.96616915 0.95\n",
      " 0.91944306 0.84524929 0.94351992 0.93896484 0.80984556 0.78649454\n",
      " 0.95672098 0.92677013 0.85882353 0.81127568]\n",
      "mean_cluster_accuracy_during_training_cycle : 90.48%, post_traincycle_acc : 91.32%, total_acc : 90.97545512%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 91.77%\n",
      "accuracy_check 실행 시간: 24.258초\n",
      "\n",
      "\n",
      "epoch-26 loss : 0.00650650, loss_normal : 0.01015995, loss_coarse : 0.04469694, min_loss : 0.00649720, min_loss_normal : 0.01015995, min_loss_coarse : 0.04461678, wrong_element_sum : 8581812.00000000, same_data : 0.00%\n",
      "ae train 실행 시간: 119.619초, 전체 시작 시간 20250314_000324_593\n",
      "\n",
      "epoch-26 accuracy check\n",
      "k_means origin feature average accuracy : 82.24420206%, total [0.9746727376209448, 0.9733106189664963, 0.9700891573195284, 0.9530800230282096, 0.943108504398827, 0.9150568181818182, 0.801817648783348, 0.6622234826999432, 0.9488619568430388, 0.822215777262181, 0.5866935483870968, 0.5005858230814294, 0.9429250891795482, 0.8922588099364529, 0.673546511627907, 0.5986258230747209]\n",
      "kmeans average accuracy best : 91.98%, kmeans average accuracy : 91.44919319%, total [0.9766647694934547, 0.9775695627484384, 0.9746908254242163, 0.9634427173287277, 0.9621700879765396, 0.9545454545454546, 0.9220170038111991, 0.8508224617129893, 0.9654153118533846, 0.9208236658932715, 0.8378456221198156, 0.7823667252489748, 0.9512485136741974, 0.9283651068746389, 0.8668604651162791, 0.7970226166618952]\n",
      "cluster_accuracy_post_training_cycle_all_dataset : [0.97965941 0.97785108 0.97496389 0.96576663 0.96517413 0.95\n",
      " 0.92391845 0.84430856 0.94251135 0.93603516 0.81081081 0.76961271\n",
      " 0.95519348 0.91901067 0.87009804 0.81844243]\n",
      "mean_cluster_accuracy_during_training_cycle : 90.79%, post_traincycle_acc : 91.27%, total_acc : 91.07555747%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 91.77%\n",
      "accuracy_check 실행 시간: 24.278초\n",
      "\n",
      "\n",
      "epoch-27 loss : 0.00647956, loss_normal : 0.01014718, loss_coarse : 0.04460944, min_loss : 0.00647956, min_loss_normal : 0.01014718, min_loss_coarse : 0.04460944, wrong_element_sum : 8565012.00000000, same_data : 0.00%\n",
      "ae train 실행 시간: 118.064초, 전체 시작 시간 20250314_000324_593\n",
      "\n",
      "epoch-27 accuracy check\n",
      "k_means origin feature average accuracy : 82.25131622%, total [0.9746727376209448, 0.9733106189664963, 0.9700891573195284, 0.9530800230282096, 0.943108504398827, 0.9150568181818182, 0.8015244796247435, 0.6622234826999432, 0.9488619568430388, 0.822215777262181, 0.5866935483870968, 0.5005858230814294, 0.9429250891795482, 0.8922588099364529, 0.673546511627907, 0.6000572573718866]\n",
      "kmeans average accuracy best : 91.98%, kmeans average accuracy : 91.70882858%, total [0.9760956175298805, 0.9778534923339012, 0.9746908254242163, 0.9631548647092688, 0.9621700879765396, 0.9568181818181818, 0.9264145411902668, 0.8615995462280204, 0.964824120603015, 0.9240139211136891, 0.8436059907834101, 0.7835383714118336, 0.9560047562425684, 0.9326978625072213, 0.8691860465116279, 0.8007443458345262]\n",
      "cluster_accuracy_post_training_cycle_all_dataset : [0.97871334 0.97785108 0.97496389 0.96480231 0.96616915 0.95188679\n",
      " 0.93038289 0.84242709 0.94301563 0.93798828 0.81467181 0.78599801\n",
      " 0.95723014 0.93113482 0.86127451 0.81462016]\n",
      "mean_cluster_accuracy_during_training_cycle : 90.94%, post_traincycle_acc : 91.46%, total_acc : 91.24604132%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 91.77%\n",
      "accuracy_check 실행 시간: 30.497초\n",
      "\n",
      "\n",
      "epoch-28 loss : 0.00646042, loss_normal : 0.01013890, loss_coarse : 0.04451417, min_loss : 0.00646042, min_loss_normal : 0.01013890, min_loss_coarse : 0.04451417, wrong_element_sum : 8546720.00000000, same_data : 0.00%\n",
      "ae train 실행 시간: 121.801초, 전체 시작 시간 20250314_000324_593\n",
      "\n",
      "epoch-28 accuracy check\n",
      "k_means origin feature average accuracy : 82.26578875%, total [0.9746727376209448, 0.9733106189664963, 0.9700891573195284, 0.9530800230282096, 0.943108504398827, 0.9150568181818182, 0.801817648783348, 0.6625070901871809, 0.9488619568430388, 0.822215777262181, 0.5872695852534562, 0.5005858230814294, 0.9429250891795482, 0.8922588099364529, 0.6747093023255814, 0.6000572573718866]\n",
      "kmeans average accuracy best : 91.98%, kmeans average accuracy : 91.78631937%, total [0.9760956175298805, 0.9778534923339012, 0.9746908254242163, 0.9645941278065631, 0.9612903225806452, 0.9582386363636364, 0.929932571093521, 0.8556437889960294, 0.969553650605971, 0.9274941995359629, 0.8421658986175116, 0.7855887521968365, 0.9542211652794292, 0.9338532640092432, 0.8747093023255814, 0.7998854852562267]\n",
      "cluster_accuracy_post_training_cycle_all_dataset : [0.97871334 0.97879359 0.97544535 0.96624879 0.96467662 0.95283019\n",
      " 0.93038289 0.84383819 0.94301563 0.93945312 0.80984556 0.78599801\n",
      " 0.95621181 0.93355965 0.88627451 0.80410893]\n",
      "mean_cluster_accuracy_during_training_cycle : 91.12%, post_traincycle_acc : 91.56%, total_acc : 91.37711262%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 91.77%\n",
      "accuracy_check 실행 시간: 24.261초\n",
      "\n",
      "\n",
      "epoch-29 loss : 0.00643205, loss_normal : 0.01012403, loss_coarse : 0.04439636, min_loss : 0.00643205, min_loss_normal : 0.01012403, min_loss_coarse : 0.04439636, wrong_element_sum : 8524102.00000000, same_data : 0.00%\n",
      "ae train 실행 시간: 122.439초, 전체 시작 시간 20250314_000324_593\n",
      "\n",
      "epoch-29 accuracy check\n",
      "k_means origin feature average accuracy : 82.24955320%, total [0.9746727376209448, 0.9733106189664963, 0.9700891573195284, 0.9530800230282096, 0.943108504398827, 0.9150568181818182, 0.801817648783348, 0.6625070901871809, 0.9488619568430388, 0.822215777262181, 0.5866935483870968, 0.5005858230814294, 0.9429250891795482, 0.8922588099364529, 0.673546511627907, 0.5991983967935872]\n",
      "kmeans average accuracy best : 91.98%, kmeans average accuracy : 91.48532744%, total [0.9760956175298805, 0.9778534923339012, 0.9749784296807593, 0.9645941278065631, 0.9612903225806452, 0.9571022727272728, 0.9249486953972442, 0.8547929665343165, 0.9639373337274608, 0.9243039443155452, 0.8294930875576036, 0.7668424135910955, 0.960166468489893, 0.939052570768342, 0.8691860465116279, 0.7930146006298311]\n",
      "cluster_accuracy_post_training_cycle_all_dataset : [0.98013245 0.97832234 0.97544535 0.96721311 0.96467662 0.95188679\n",
      " 0.9273993  0.85418627 0.93998991 0.93115234 0.80984556 0.75571003\n",
      " 0.96283096 0.93549952 0.87156863 0.80028667]\n",
      "mean_cluster_accuracy_during_training_cycle : 90.64%, post_traincycle_acc : 91.29%, total_acc : 91.02363441%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 91.77%\n",
      "accuracy_check 실행 시간: 24.326초\n",
      "\n",
      "\n",
      "epoch-30 loss : 0.00638913, loss_normal : 0.01011128, loss_coarse : 0.04415997, min_loss : 0.00638913, min_loss_normal : 0.01011128, min_loss_coarse : 0.04415997, wrong_element_sum : 8478714.00000000, same_data : 0.00%\n",
      "ae train 실행 시간: 123.148초, 전체 시작 시간 20250314_000324_593\n",
      "\n",
      "epoch-30 accuracy check\n",
      "k_means origin feature average accuracy : 82.23519786%, total [0.9746727376209448, 0.9733106189664963, 0.9700891573195284, 0.9530800230282096, 0.943108504398827, 0.9150568181818182, 0.801817648783348, 0.6625070901871809, 0.9488619568430388, 0.822215777262181, 0.5866935483870968, 0.5005858230814294, 0.9429250891795482, 0.89052570768342, 0.6741279069767442, 0.5980532493558546]\n",
      "kmeans average accuracy best : 91.98%, kmeans average accuracy : 91.51732579%, total [0.9763801935116676, 0.978137421919364, 0.9746908254242163, 0.9648819804260219, 0.9621700879765396, 0.9571022727272728, 0.9275872178246849, 0.8590470788428815, 0.968371268105232, 0.9245939675174014, 0.8338133640552995, 0.7747510251903925, 0.955410225921522, 0.9283651068746389, 0.8593023255813953, 0.7981677640996279]\n",
      "cluster_accuracy_post_training_cycle_all_dataset : [0.97965941 0.97879359 0.97496389 0.96769527 0.96467662 0.95283019\n",
      " 0.93038289 0.85606773 0.95410993 0.93359375 0.81611969 0.74627607\n",
      " 0.95773931 0.92822502 0.87843137 0.79837554]\n",
      "mean_cluster_accuracy_during_training_cycle : 90.79%, post_traincycle_acc : 91.36%, total_acc : 91.12839311%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 91.77%\n",
      "accuracy_check 실행 시간: 24.319초\n",
      "\n",
      "\n",
      "epoch-31 loss : 0.00638494, loss_normal : 0.01010608, loss_coarse : 0.04422210, min_loss : 0.00638494, min_loss_normal : 0.01010608, min_loss_coarse : 0.04415997, wrong_element_sum : 8490644.00000000, same_data : 0.00%\n",
      "ae train 실행 시간: 123.713초, 전체 시작 시간 20250314_000324_593\n",
      "\n",
      "epoch-31 accuracy check\n",
      "k_means origin feature average accuracy : 82.26219154%, total [0.9746727376209448, 0.9733106189664963, 0.9700891573195284, 0.9530800230282096, 0.943108504398827, 0.915340909090909, 0.801817648783348, 0.6622234826999432, 0.9488619568430388, 0.822215777262181, 0.5866935483870968, 0.5005858230814294, 0.9429250891795482, 0.8922588099364529, 0.6747093023255814, 0.6000572573718866]\n",
      "kmeans average accuracy best : 91.98%, kmeans average accuracy : 91.46802714%, total [0.9763801935116676, 0.978137421919364, 0.9749784296807593, 0.9648819804260219, 0.9615835777126099, 0.9553977272727273, 0.9234828496042217, 0.8428814520703346, 0.9668932899793083, 0.9196635730858469, 0.8352534562211982, 0.7677211482132396, 0.9568965517241379, 0.9381860196418256, 0.8718023255813954, 0.8007443458345262]\n",
      "cluster_accuracy_post_training_cycle_all_dataset : [0.97965941 0.97832234 0.97496389 0.96721311 0.96467662 0.95\n",
      " 0.92938836 0.85324553 0.9404942  0.93261719 0.80936293 0.77308838\n",
      " 0.9592668  0.93549952 0.875      0.80697563]\n",
      "mean_cluster_accuracy_during_training_cycle : 90.92%, post_traincycle_acc : 91.44%, total_acc : 91.22393153%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 91.77%\n",
      "accuracy_check 실행 시간: 24.593초\n",
      "\n",
      "\n",
      "epoch-32 loss : 0.00638096, loss_normal : 0.01010470, loss_coarse : 0.04419447, min_loss : 0.00638096, min_loss_normal : 0.01010470, min_loss_coarse : 0.04415997, wrong_element_sum : 8485338.00000000, same_data : 0.00%\n",
      "ae train 실행 시간: 115.111초, 전체 시작 시간 20250314_000324_593\n",
      "\n",
      "epoch-32 accuracy check\n",
      "k_means origin feature average accuracy : 82.25133588%, total [0.9746727376209448, 0.9733106189664963, 0.9700891573195284, 0.9530800230282096, 0.943108504398827, 0.9150568181818182, 0.801817648783348, 0.6622234826999432, 0.9488619568430388, 0.8219257540603249, 0.5866935483870968, 0.5005858230814294, 0.9429250891795482, 0.8922588099364529, 0.673546511627907, 0.6000572573718866]\n",
      "kmeans average accuracy best : 91.98%, kmeans average accuracy : 91.62684122%, total [0.9760956175298805, 0.978137421919364, 0.9752660339373023, 0.9654576856649395, 0.9618768328445748, 0.9565340909090909, 0.9281735561418939, 0.8550765740215541, 0.9698492462311558, 0.9248839907192575, 0.836405529953917, 0.7803163444639719, 0.9557074910820452, 0.9286539572501444, 0.8648255813953488, 0.8030346407099914]\n",
      "cluster_accuracy_post_training_cycle_all_dataset : [0.97918638 0.97832234 0.97544535 0.96721311 0.96517413 0.95141509\n",
      " 0.9288911  0.855127   0.95461422 0.93896484 0.81274131 0.72194638\n",
      " 0.95570265 0.93113482 0.8754902  0.78881988]\n",
      "mean_cluster_accuracy_during_training_cycle : 90.32%, post_traincycle_acc : 91.13%, total_acc : 90.79560227%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 91.77%\n",
      "accuracy_check 실행 시간: 25.918초\n",
      "\n",
      "\n",
      "epoch-33 loss : 0.00634813, loss_normal : 0.01008635, loss_coarse : 0.04399897, min_loss : 0.00634813, min_loss_normal : 0.01008635, min_loss_coarse : 0.04399897, wrong_element_sum : 8447802.00000000, same_data : 0.00%\n",
      "ae train 실행 시간: 125.948초, 전체 시작 시간 20250314_000324_593\n",
      "\n",
      "epoch-33 accuracy check\n",
      "k_means origin feature average accuracy : 82.25318692%, total [0.9746727376209448, 0.9733106189664963, 0.9700891573195284, 0.9530800230282096, 0.943108504398827, 0.9150568181818182, 0.801817648783348, 0.6625070901871809, 0.9488619568430388, 0.822215777262181, 0.5866935483870968, 0.5005858230814294, 0.9429250891795482, 0.8922588099364529, 0.6741279069767442, 0.5991983967935872]\n",
      "kmeans average accuracy best : 91.98%, kmeans average accuracy : 91.52981549%, total [0.9760956175298805, 0.9775695627484384, 0.9749784296807593, 0.9657455382843984, 0.9615835777126099, 0.9565340909090909, 0.9293462327763119, 0.8559273964832672, 0.9621637599763524, 0.9127030162412993, 0.8317972350230415, 0.773286467486819, 0.9568965517241379, 0.9332755632582322, 0.873546511627907, 0.8033209275694245]\n",
      "cluster_accuracy_post_training_cycle_all_dataset : [0.97918638 0.97785108 0.97496389 0.96673095 0.96467662 0.95188679\n",
      " 0.92690204 0.85042333 0.93797277 0.93066406 0.79826255 0.76911619\n",
      " 0.95875764 0.92967992 0.87745098 0.80554228]\n",
      "mean_cluster_accuracy_during_training_cycle : 90.84%, post_traincycle_acc : 91.25%, total_acc : 91.08338017%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 91.77%\n",
      "accuracy_check 실행 시간: 24.217초\n",
      "\n",
      "\n",
      "epoch-34 loss : 0.00635175, loss_normal : 0.01009306, loss_coarse : 0.04405913, min_loss : 0.00634813, min_loss_normal : 0.01008635, min_loss_coarse : 0.04399897, wrong_element_sum : 8459354.00000000, same_data : 0.00%\n",
      "ae train 실행 시간: 110.484초, 전체 시작 시간 20250314_000324_593\n",
      "\n",
      "epoch-34 accuracy check\n",
      "k_means origin feature average accuracy : 82.25135763%, total [0.9746727376209448, 0.9733106189664963, 0.9700891573195284, 0.9530800230282096, 0.943108504398827, 0.915340909090909, 0.8015244796247435, 0.6622234826999432, 0.9488619568430388, 0.822215777262181, 0.5866935483870968, 0.5005858230814294, 0.9429250891795482, 0.8922588099364529, 0.6741279069767442, 0.5991983967935872]\n",
      "kmeans average accuracy best : 91.98%, kmeans average accuracy : 91.36681136%, total [0.9763801935116676, 0.978137421919364, 0.9746908254242163, 0.9643062751871042, 0.9612903225806452, 0.9565340909090909, 0.9220170038111991, 0.8499716392512763, 0.963641738102276, 0.9231438515081206, 0.8335253456221198, 0.7642062097246631, 0.9557074910820452, 0.9318313113807047, 0.8665697674418604, 0.7967363298024621]\n",
      "cluster_accuracy_post_training_cycle_all_dataset : [0.97965941 0.97832234 0.97496389 0.96721311 0.96467662 0.95188679\n",
      " 0.92789657 0.84524929 0.93898134 0.93115234 0.80984556 0.76415094\n",
      " 0.95723014 0.92774006 0.86421569 0.8079312 ]\n",
      "mean_cluster_accuracy_during_training_cycle : 90.58%, post_traincycle_acc : 91.19%, total_acc : 90.94481966%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 91.77%\n",
      "accuracy_check 실행 시간: 22.024초\n",
      "\n",
      "\n",
      "epoch-35 loss : 0.00635117, loss_normal : 0.01008708, loss_coarse : 0.04404092, min_loss : 0.00634813, min_loss_normal : 0.01008635, min_loss_coarse : 0.04399897, wrong_element_sum : 8455856.00000000, same_data : 0.00%\n",
      "ae train 실행 시간: 115.444초, 전체 시작 시간 20250314_000324_593\n",
      "\n",
      "epoch-35 accuracy check\n",
      "k_means origin feature average accuracy : 82.24953775%, total [0.9746727376209448, 0.9733106189664963, 0.9700891573195284, 0.9530800230282096, 0.943108504398827, 0.9150568181818182, 0.8015244796247435, 0.6625070901871809, 0.9488619568430388, 0.822215777262181, 0.5866935483870968, 0.5005858230814294, 0.9429250891795482, 0.8922588099364529, 0.6738372093023256, 0.5991983967935872]\n",
      "kmeans average accuracy best : 91.98%, kmeans average accuracy : 91.60798847%, total [0.9758110415480934, 0.978137421919364, 0.9746908254242163, 0.9651698330454808, 0.9618768328445748, 0.9571022727272728, 0.9293462327763119, 0.8587634713556438, 0.9698492462311558, 0.9211136890951276, 0.8369815668202765, 0.7741652021089631, 0.9563020214030915, 0.9257654534950895, 0.8680232558139535, 0.8041797881477241]\n",
      "cluster_accuracy_post_training_cycle_all_dataset : [0.97871334 0.97832234 0.97496389 0.96721311 0.96467662 0.95141509\n",
      " 0.93187469 0.84854186 0.92788704 0.93505859 0.81660232 0.78450844\n",
      " 0.95977597 0.9243453  0.87205882 0.81557573]\n",
      "mean_cluster_accuracy_during_training_cycle : 90.78%, post_traincycle_acc : 91.45%, total_acc : 91.17346352%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 91.77%\n",
      "accuracy_check 실행 시간: 22.209초\n",
      "\n",
      "\n",
      "epoch-36 loss : 0.00632703, loss_normal : 0.01008147, loss_coarse : 0.04394862, min_loss : 0.00632703, min_loss_normal : 0.01008147, min_loss_coarse : 0.04394862, wrong_element_sum : 8438136.00000000, same_data : 0.00%\n",
      "ae train 실행 시간: 113.593초, 전체 시작 시간 20250314_000324_593\n",
      "\n",
      "epoch-36 accuracy check\n",
      "k_means origin feature average accuracy : 82.26218852%, total [0.9746727376209448, 0.9733106189664963, 0.9700891573195284, 0.9530800230282096, 0.943108504398827, 0.9150568181818182, 0.801817648783348, 0.6625070901871809, 0.9488619568430388, 0.822215777262181, 0.5866935483870968, 0.5005858230814294, 0.9429250891795482, 0.8922588099364529, 0.6747093023255814, 0.6000572573718866]\n",
      "kmeans average accuracy best : 91.98%, kmeans average accuracy : 91.54715965%, total [0.9760956175298805, 0.9778534923339012, 0.9749784296807593, 0.9657455382843984, 0.9612903225806452, 0.9565340909090909, 0.9264145411902668, 0.8579126488939308, 0.9668932899793083, 0.9231438515081206, 0.8349654377880185, 0.7727006444053895, 0.953923900118906, 0.9274985557481225, 0.8656976744186047, 0.8058975093043229]\n",
      "cluster_accuracy_post_training_cycle_all_dataset : [0.97918638 0.97832234 0.97544535 0.96769527 0.96268657 0.95188679\n",
      " 0.93137742 0.84901223 0.95511851 0.93554688 0.81660232 0.7775571\n",
      " 0.95570265 0.92774006 0.87696078 0.80076445]\n",
      "mean_cluster_accuracy_during_training_cycle : 90.98%, post_traincycle_acc : 91.51%, total_acc : 91.29335492%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 91.77%\n",
      "accuracy_check 실행 시간: 22.087초\n",
      "\n",
      "\n",
      "epoch-37 loss : 0.00632484, loss_normal : 0.01007424, loss_coarse : 0.04393786, min_loss : 0.00632484, min_loss_normal : 0.01007424, min_loss_coarse : 0.04393786, wrong_element_sum : 8436070.00000000, same_data : 0.00%\n",
      "ae train 실행 시간: 114.171초, 전체 시작 시간 20250314_000324_593\n",
      "\n",
      "epoch-37 accuracy check\n",
      "k_means origin feature average accuracy : 82.25674876%, total [0.9746727376209448, 0.9733106189664963, 0.9700891573195284, 0.9530800230282096, 0.943108504398827, 0.9150568181818182, 0.801817648783348, 0.6622234826999432, 0.9488619568430388, 0.822215777262181, 0.5872695852534562, 0.5005858230814294, 0.9429250891795482, 0.8922588099364529, 0.673546511627907, 0.6000572573718866]\n",
      "kmeans average accuracy best : 91.98%, kmeans average accuracy : 91.40756001%, total [0.9763801935116676, 0.978137421919364, 0.9746908254242163, 0.9645941278065631, 0.9612903225806452, 0.9553977272727273, 0.9231896804456171, 0.8496880317640386, 0.9668932899793083, 0.9193735498839907, 0.8248847926267281, 0.7653778558875219, 0.9574910820451843, 0.9341421143847487, 0.8709302325581395, 0.8027483538505582]\n",
      "cluster_accuracy_post_training_cycle_all_dataset : [0.97776727 0.97832234 0.97448243 0.96721311 0.96467662 0.9509434\n",
      " 0.92391845 0.84901223 0.94503278 0.93359375 0.80357143 0.76464747\n",
      " 0.95519348 0.93016489 0.87058824 0.80697563]\n",
      "mean_cluster_accuracy_during_training_cycle : 90.69%, post_traincycle_acc : 91.23%, total_acc : 91.00756204%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 91.77%\n",
      "accuracy_check 실행 시간: 22.523초\n",
      "\n",
      "\n",
      "epoch-38 loss : 0.00631907, loss_normal : 0.01006756, loss_coarse : 0.04390496, min_loss : 0.00631907, min_loss_normal : 0.01006756, min_loss_coarse : 0.04390496, wrong_element_sum : 8429752.00000000, same_data : 0.00%\n",
      "ae train 실행 시간: 115.937초, 전체 시작 시간 20250314_000324_593\n",
      "\n",
      "epoch-38 accuracy check\n",
      "k_means origin feature average accuracy : 82.24244034%, total [0.9746727376209448, 0.9733106189664963, 0.9700891573195284, 0.9530800230282096, 0.943108504398827, 0.9150568181818182, 0.801817648783348, 0.6622234826999432, 0.9488619568430388, 0.822215777262181, 0.5866935483870968, 0.5005858230814294, 0.9429250891795482, 0.8922588099364529, 0.6738372093023256, 0.5980532493558546]\n",
      "kmeans average accuracy best : 91.98%, kmeans average accuracy : 91.74196586%, total [0.9760956175298805, 0.9778534923339012, 0.9746908254242163, 0.9654576856649395, 0.9612903225806452, 0.9559659090909091, 0.9243623570800352, 0.8511060692002269, 0.9642329293526456, 0.9187935034802784, 0.8355414746543779, 0.7694786174575279, 0.9610582639714625, 0.9445407279029463, 0.8863372093023256, 0.8119095333524191]\n",
      "cluster_accuracy_post_training_cycle_all_dataset : [0.97871334 0.97737983 0.97496389 0.96914176 0.96517413 0.95188679\n",
      " 0.92640477 0.84289746 0.93746848 0.93505859 0.80453668 0.79195631\n",
      " 0.96181263 0.93840931 0.88284314 0.82417582]\n",
      "mean_cluster_accuracy_during_training_cycle : 91.09%, post_traincycle_acc : 91.64%, total_acc : 91.41767937%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 91.77%\n",
      "accuracy_check 실행 시간: 29.205초\n",
      "\n",
      "\n",
      "epoch-39 loss : 0.00632127, loss_normal : 0.01006732, loss_coarse : 0.04390396, min_loss : 0.00631907, min_loss_normal : 0.01006732, min_loss_coarse : 0.04390396, wrong_element_sum : 8429560.00000000, same_data : 0.00%\n",
      "ae train 실행 시간: 107.239초, 전체 시작 시간 20250314_000324_593\n",
      "\n",
      "epoch-39 accuracy check\n",
      "k_means origin feature average accuracy : 82.25503437%, total [0.9746727376209448, 0.9733106189664963, 0.9700891573195284, 0.9530800230282096, 0.943108504398827, 0.915340909090909, 0.801817648783348, 0.6622234826999432, 0.9488619568430388, 0.822215777262181, 0.5866935483870968, 0.5005858230814294, 0.9429250891795482, 0.8922588099364529, 0.6747093023255814, 0.598912109934154]\n",
      "kmeans average accuracy best : 91.98%, kmeans average accuracy : 91.56266531%, total [0.9760956175298805, 0.9775695627484384, 0.9744032211676733, 0.9648819804260219, 0.9609970674486803, 0.9579545454545455, 0.9267077103488713, 0.861883153715258, 0.9677800768548626, 0.9211136890951276, 0.8294930875576036, 0.7615700058582309, 0.9551129607609988, 0.9332755632582322, 0.8752906976744186, 0.8058975093043229]\n",
      "cluster_accuracy_post_training_cycle_all_dataset : [0.97918638 0.97832234 0.97496389 0.96769527 0.9641791  0.95235849\n",
      " 0.93386375 0.86030103 0.95410993 0.93164062 0.81129344 0.77855015\n",
      " 0.95672098 0.93646945 0.87647059 0.82035356]\n",
      "mean_cluster_accuracy_during_training_cycle : 91.13%, post_traincycle_acc : 91.73%, total_acc : 91.48544815%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 91.77%\n",
      "accuracy_check 실행 시간: 22.598초\n",
      "\n",
      "\n",
      "epoch-40 loss : 0.00630084, loss_normal : 0.01006363, loss_coarse : 0.04383104, min_loss : 0.00630084, min_loss_normal : 0.01006363, min_loss_coarse : 0.04383104, wrong_element_sum : 8415560.00000000, same_data : 0.00%\n",
      "ae train 실행 시간: 112.706초, 전체 시작 시간 20250314_000324_593\n",
      "\n",
      "epoch-40 accuracy check\n",
      "k_means origin feature average accuracy : 82.24426563%, total [0.9746727376209448, 0.9733106189664963, 0.9700891573195284, 0.9530800230282096, 0.943108504398827, 0.9150568181818182, 0.801817648783348, 0.6622234826999432, 0.9488619568430388, 0.8216357308584686, 0.5866935483870968, 0.5005858230814294, 0.9429250891795482, 0.8922588099364529, 0.6747093023255814, 0.5980532493558546]\n",
      "kmeans average accuracy best : 91.98%, kmeans average accuracy : 91.63644849%, total [0.9763801935116676, 0.9778534923339012, 0.9744032211676733, 0.9648819804260219, 0.9618768328445748, 0.9556818181818182, 0.9270008795074758, 0.8550765740215541, 0.9674844812296778, 0.9251740139211136, 0.8309331797235023, 0.7724077328646749, 0.9533293697978596, 0.9312536106296938, 0.8776162790697675, 0.8104780990552534]\n",
      "cluster_accuracy_post_training_cycle_all_dataset : [0.97918638 0.97785108 0.97496389 0.96817743 0.96467662 0.95\n",
      " 0.93485828 0.8537159  0.94906707 0.93554688 0.80598456 0.77159881\n",
      " 0.95519348 0.92870999 0.88676471 0.81557573]\n",
      "mean_cluster_accuracy_during_training_cycle : 90.69%, post_traincycle_acc : 91.57%, total_acc : 91.21317822%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 91.77%\n",
      "accuracy_check 실행 시간: 21.848초\n",
      "\n",
      "\n",
      "epoch-41 loss : 0.00628512, loss_normal : 0.01004972, loss_coarse : 0.04374099, min_loss : 0.00628512, min_loss_normal : 0.01004972, min_loss_coarse : 0.04374099, wrong_element_sum : 8398270.00000000, same_data : 0.00%\n",
      "ae train 실행 시간: 112.722초, 전체 시작 시간 20250314_000324_593\n",
      "\n",
      "epoch-41 accuracy check\n",
      "k_means origin feature average accuracy : 82.24421591%, total [0.9746727376209448, 0.9733106189664963, 0.9700891573195284, 0.9530800230282096, 0.943108504398827, 0.915340909090909, 0.801817648783348, 0.6622234826999432, 0.9488619568430388, 0.822215777262181, 0.5866935483870968, 0.5005858230814294, 0.9429250891795482, 0.8922588099364529, 0.6738372093023256, 0.5980532493558546]\n",
      "kmeans average accuracy best : 91.98%, kmeans average accuracy : 91.49165809%, total [0.9763801935116676, 0.9778534923339012, 0.9744032211676733, 0.9648819804260219, 0.9615835777126099, 0.9556818181818182, 0.9267077103488713, 0.8542257515598412, 0.9654153118533846, 0.9214037122969838, 0.8315092165898618, 0.7691857059168131, 0.9536266349583828, 0.9280762564991335, 0.8738372093023256, 0.8038935012882908]\n",
      "cluster_accuracy_post_training_cycle_all_dataset : [0.97918638 0.97832234 0.97448243 0.96673095 0.96368159 0.95188679\n",
      " 0.93535554 0.855127   0.93948563 0.9375     0.79247104 0.76464747\n",
      " 0.95366599 0.92725509 0.87254902 0.8079312 ]\n",
      "mean_cluster_accuracy_during_training_cycle : 90.67%, post_traincycle_acc : 91.25%, total_acc : 91.01256429%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 91.77%\n",
      "accuracy_check 실행 시간: 29.046초\n",
      "\n",
      "\n",
      "epoch-42 loss : 0.00627111, loss_normal : 0.01004040, loss_coarse : 0.04361955, min_loss : 0.00627111, min_loss_normal : 0.01004040, min_loss_coarse : 0.04361955, wrong_element_sum : 8374954.00000000, same_data : 0.00%\n",
      "ae train 실행 시간: 114.200초, 전체 시작 시간 20250314_000324_593\n",
      "\n",
      "epoch-42 accuracy check\n",
      "k_means origin feature average accuracy : 82.25310748%, total [0.9746727376209448, 0.9733106189664963, 0.9700891573195284, 0.9530800230282096, 0.943108504398827, 0.9150568181818182, 0.801817648783348, 0.6622234826999432, 0.9488619568430388, 0.822215777262181, 0.5866935483870968, 0.5005858230814294, 0.942627824019025, 0.8922588099364529, 0.6738372093023256, 0.6000572573718866]\n",
      "kmeans average accuracy best : 91.98%, kmeans average accuracy : 91.42746510%, total [0.9763801935116676, 0.9778534923339012, 0.9749784296807593, 0.9651698330454808, 0.9609970674486803, 0.9556818181818182, 0.9220170038111991, 0.8513896766874646, 0.9657109074785694, 0.9173433874709976, 0.826036866359447, 0.7633274751025191, 0.960166468489893, 0.9338532640092432, 0.8767441860465116, 0.8007443458345262]\n",
      "cluster_accuracy_post_training_cycle_all_dataset : [0.97965941 0.97832234 0.97496389 0.96721311 0.96368159 0.95\n",
      " 0.92491298 0.8508937  0.93545134 0.9296875  0.7992278  0.74528302\n",
      " 0.96130346 0.93695441 0.875      0.81414238]\n",
      "mean_cluster_accuracy_during_training_cycle : 90.09%, post_traincycle_acc : 91.17%, total_acc : 90.72759235%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 91.77%\n",
      "accuracy_check 실행 시간: 22.025초\n",
      "\n",
      "\n",
      "epoch-43 loss : 0.00627356, loss_normal : 0.01004533, loss_coarse : 0.04368130, min_loss : 0.00627111, min_loss_normal : 0.01004040, min_loss_coarse : 0.04361955, wrong_element_sum : 8386810.00000000, same_data : 0.00%\n",
      "ae train 실행 시간: 108.968초, 전체 시작 시간 20250314_000324_593\n",
      "\n",
      "epoch-43 accuracy check\n",
      "k_means origin feature average accuracy : 82.24959751%, total [0.9746727376209448, 0.9733106189664963, 0.9700891573195284, 0.9530800230282096, 0.943108504398827, 0.9150568181818182, 0.801817648783348, 0.6622234826999432, 0.9488619568430388, 0.822215777262181, 0.5866935483870968, 0.5005858230814294, 0.9429250891795482, 0.8922588099364529, 0.6738372093023256, 0.5991983967935872]\n",
      "kmeans average accuracy best : 91.98%, kmeans average accuracy : 91.61559431%, total [0.9763801935116676, 0.978137421919364, 0.9752660339373023, 0.9648819804260219, 0.9609970674486803, 0.9568181818181818, 0.9249486953972442, 0.8536585365853658, 0.967188885604493, 0.9251740139211136, 0.831221198156682, 0.7706502636203867, 0.9592746730083235, 0.9404968226458694, 0.8715116279069768, 0.8018894932722588]\n",
      "cluster_accuracy_post_training_cycle_all_dataset : [0.9782403  0.97879359 0.97544535 0.96624879 0.96467662 0.95377358\n",
      " 0.9273993  0.85700847 0.95259708 0.93652344 0.7953668  0.7795432\n",
      " 0.96028513 0.93792435 0.87745098 0.81509795]\n",
      "mean_cluster_accuracy_during_training_cycle : 91.05%, post_traincycle_acc : 91.60%, total_acc : 91.37745103%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 91.77%\n",
      "accuracy_check 실행 시간: 21.738초\n",
      "\n",
      "\n",
      "epoch-44 loss : 0.00627507, loss_normal : 0.01004204, loss_coarse : 0.04366757, min_loss : 0.00627111, min_loss_normal : 0.01004040, min_loss_coarse : 0.04361955, wrong_element_sum : 8384174.00000000, same_data : 0.00%\n",
      "ae train 실행 시간: 111.892초, 전체 시작 시간 20250314_000324_593\n",
      "\n",
      "epoch-44 accuracy check\n",
      "k_means origin feature average accuracy : 82.25135924%, total [0.9746727376209448, 0.9733106189664963, 0.9700891573195284, 0.9530800230282096, 0.943108504398827, 0.9150568181818182, 0.801817648783348, 0.6622234826999432, 0.9488619568430388, 0.822215777262181, 0.5866935483870968, 0.5005858230814294, 0.9429250891795482, 0.8922588099364529, 0.673546511627907, 0.5997709705124534]\n",
      "kmeans average accuracy best : 91.98%, kmeans average accuracy : 91.74025607%, total [0.9763801935116676, 0.978137421919364, 0.9746908254242163, 0.9651698330454808, 0.9609970674486803, 0.95625, 0.9258282028730578, 0.8567782189449802, 0.9645285249778304, 0.923723897911833, 0.831221198156682, 0.781195079086116, 0.9592746730083235, 0.9350086655112652, 0.8787790697674419, 0.8104780990552534]\n",
      "cluster_accuracy_post_training_cycle_all_dataset : [0.97965941 0.97832234 0.97544535 0.96721311 0.96567164 0.95188679\n",
      " 0.9288911  0.84995296 0.95108422 0.93554688 0.81322394 0.78649454\n",
      " 0.9607943  0.93598448 0.87843137 0.83134257]\n",
      "mean_cluster_accuracy_during_training_cycle : 91.14%, post_traincycle_acc : 91.81%, total_acc : 91.53739314%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 91.77%\n",
      "accuracy_check 실행 시간: 22.008초\n",
      "\n",
      "\n",
      "epoch-45 loss : 0.00625334, loss_normal : 0.01003460, loss_coarse : 0.04357519, min_loss : 0.00625334, min_loss_normal : 0.01003460, min_loss_coarse : 0.04357519, wrong_element_sum : 8366436.00000000, same_data : 0.00%\n",
      "ae train 실행 시간: 114.589초, 전체 시작 시간 20250314_000324_593\n",
      "\n",
      "epoch-45 accuracy check\n",
      "k_means origin feature average accuracy : 82.24955320%, total [0.9746727376209448, 0.9733106189664963, 0.9700891573195284, 0.9530800230282096, 0.943108504398827, 0.9150568181818182, 0.801817648783348, 0.6625070901871809, 0.9488619568430388, 0.822215777262181, 0.5866935483870968, 0.5005858230814294, 0.9429250891795482, 0.8922588099364529, 0.673546511627907, 0.5991983967935872]\n",
      "kmeans average accuracy best : 91.98%, kmeans average accuracy : 91.37263517%, total [0.9763801935116676, 0.978137421919364, 0.9752660339373023, 0.9657455382843984, 0.9604105571847508, 0.9551136363636363, 0.9240691879214307, 0.8485536018150879, 0.9606857818504286, 0.9118329466357309, 0.8171082949308756, 0.7630345635618043, 0.9613555291319857, 0.939630271519353, 0.8729651162790698, 0.8093329516175207]\n",
      "cluster_accuracy_post_training_cycle_all_dataset : [0.97965941 0.97785108 0.97448243 0.96817743 0.96318408 0.95188679\n",
      " 0.92391845 0.8508937  0.92486132 0.92138672 0.80164093 0.74875869\n",
      " 0.96232179 0.93598448 0.86764706 0.81892021]\n",
      "mean_cluster_accuracy_during_training_cycle : 90.41%, post_traincycle_acc : 91.07%, total_acc : 90.80368666%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 91.77%\n",
      "accuracy_check 실행 시간: 26.103초\n",
      "\n",
      "\n",
      "epoch-46 loss : 0.00623773, loss_normal : 0.01002349, loss_coarse : 0.04351545, min_loss : 0.00623773, min_loss_normal : 0.01002349, min_loss_coarse : 0.04351545, wrong_element_sum : 8354966.00000000, same_data : 0.00%\n",
      "ae train 실행 시간: 116.854초, 전체 시작 시간 20250314_000324_593\n",
      "\n",
      "epoch-46 accuracy check\n",
      "k_means origin feature average accuracy : 82.26036864%, total [0.9746727376209448, 0.9733106189664963, 0.9700891573195284, 0.9530800230282096, 0.943108504398827, 0.9150568181818182, 0.801817648783348, 0.6622234826999432, 0.9488619568430388, 0.822215777262181, 0.5872695852534562, 0.5002929115407148, 0.9429250891795482, 0.8922588099364529, 0.6744186046511628, 0.6000572573718866]\n",
      "kmeans average accuracy best : 91.98%, kmeans average accuracy : 91.70162033%, total [0.9763801935116676, 0.978137421919364, 0.9749784296807593, 0.9654576856649395, 0.9607038123167155, 0.9585227272727272, 0.9296394019349165, 0.8615995462280204, 0.9674844812296778, 0.9222737819025522, 0.8274769585253456, 0.7729935559461043, 0.9589774078478003, 0.9341421143847487, 0.8761627906976744, 0.8073289436014887]\n",
      "cluster_accuracy_post_training_cycle_all_dataset : [0.97965941 0.97879359 0.97496389 0.96865959 0.9641791  0.95377358\n",
      " 0.93137742 0.8621825  0.93998991 0.93066406 0.8030888  0.77457795\n",
      " 0.9592668  0.93695441 0.87696078 0.81223125]\n",
      "mean_cluster_accuracy_during_training_cycle : 90.88%, post_traincycle_acc : 91.55%, total_acc : 91.27298490%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 91.77%\n",
      "accuracy_check 실행 시간: 28.981초\n",
      "\n",
      "\n",
      "epoch-47 loss : 0.00624632, loss_normal : 0.01002996, loss_coarse : 0.04356256, min_loss : 0.00623773, min_loss_normal : 0.01002349, min_loss_coarse : 0.04351545, wrong_element_sum : 8364012.00000000, same_data : 0.00%\n",
      "ae train 실행 시간: 104.699초, 전체 시작 시간 20250314_000324_593\n",
      "\n",
      "epoch-47 accuracy check\n",
      "k_means origin feature average accuracy : 82.25858366%, total [0.9746727376209448, 0.9733106189664963, 0.9700891573195284, 0.9530800230282096, 0.943108504398827, 0.9150568181818182, 0.8015244796247435, 0.6622234826999432, 0.9488619568430388, 0.822215777262181, 0.5866935483870968, 0.5005858230814294, 0.9429250891795482, 0.8922588099364529, 0.6747093023255814, 0.6000572573718866]\n",
      "kmeans average accuracy best : 91.98%, kmeans average accuracy : 91.73740544%, total [0.9763801935116676, 0.9778534923339012, 0.9746908254242163, 0.9648819804260219, 0.9615835777126099, 0.9573863636363636, 0.9261213720316622, 0.8522404991491775, 0.969553650605971, 0.9234338747099768, 0.8338133640552995, 0.7703573520796719, 0.9607609988109393, 0.9451184286539572, 0.8781976744186046, 0.8056112224448898]\n",
      "cluster_accuracy_post_training_cycle_all_dataset : [0.97918638 0.97785108 0.97448243 0.96721311 0.96467662 0.95330189\n",
      " 0.93137742 0.8480715  0.95763994 0.93701172 0.80405405 0.78450844\n",
      " 0.96130346 0.94471387 0.87990196 0.81032011]\n",
      "mean_cluster_accuracy_during_training_cycle : 91.13%, post_traincycle_acc : 91.72%, total_acc : 91.47916904%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 91.77%\n",
      "accuracy_check 실행 시간: 22.018초\n",
      "\n",
      "\n",
      "epoch-48 loss : 0.00622725, loss_normal : 0.01002102, loss_coarse : 0.04346239, min_loss : 0.00622725, min_loss_normal : 0.01002102, min_loss_coarse : 0.04346239, wrong_element_sum : 8344780.00000000, same_data : 0.00%\n",
      "ae train 실행 시간: 113.929초, 전체 시작 시간 20250314_000324_593\n",
      "\n",
      "epoch-48 accuracy check\n",
      "k_means origin feature average accuracy : 82.25673331%, total [0.9746727376209448, 0.9733106189664963, 0.9700891573195284, 0.9530800230282096, 0.943108504398827, 0.9150568181818182, 0.8015244796247435, 0.6622234826999432, 0.9488619568430388, 0.822215777262181, 0.5872695852534562, 0.5005858230814294, 0.9429250891795482, 0.8922588099364529, 0.6738372093023256, 0.6000572573718866]\n",
      "kmeans average accuracy best : 91.98%, kmeans average accuracy : 91.58823323%, total [0.9766647694934547, 0.978137421919364, 0.9744032211676733, 0.9648819804260219, 0.9607038123167155, 0.9559659090909091, 0.9237760187628261, 0.8496880317640386, 0.9645285249778304, 0.9234338747099768, 0.8300691244239631, 0.7694786174575279, 0.9592746730083235, 0.9399191218948585, 0.8752906976744186, 0.807901517320355]\n",
      "cluster_accuracy_post_training_cycle_all_dataset : [0.97918638 0.97879359 0.97496389 0.96721311 0.96467662 0.95\n",
      " 0.92541024 0.84524929 0.94150277 0.93652344 0.80791506 0.76315789\n",
      " 0.96130346 0.93889428 0.87745098 0.81414238]\n",
      "mean_cluster_accuracy_during_training_cycle : 90.92%, post_traincycle_acc : 91.41%, total_acc : 91.21202576%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 91.77%\n",
      "accuracy_check 실행 시간: 21.999초\n",
      "\n",
      "\n",
      "epoch-49 loss : 0.00621305, loss_normal : 0.01001388, loss_coarse : 0.04341918, min_loss : 0.00621305, min_loss_normal : 0.01001388, min_loss_coarse : 0.04341918, wrong_element_sum : 8336482.00000000, same_data : 0.00%\n",
      "ae train 실행 시간: 115.847초, 전체 시작 시간 20250314_000324_593\n",
      "\n",
      "epoch-49 accuracy check\n",
      "k_means origin feature average accuracy : 82.24778065%, total [0.9746727376209448, 0.9733106189664963, 0.9700891573195284, 0.9530800230282096, 0.943108504398827, 0.9150568181818182, 0.801817648783348, 0.6622234826999432, 0.9488619568430388, 0.822215777262181, 0.5866935483870968, 0.5005858230814294, 0.9429250891795482, 0.8922588099364529, 0.673546511627907, 0.5991983967935872]\n",
      "kmeans average accuracy best : 91.98%, kmeans average accuracy : 91.64945720%, total [0.9763801935116676, 0.9778534923339012, 0.9744032211676733, 0.9648819804260219, 0.9609970674486803, 0.95625, 0.9275872178246849, 0.8564946114577425, 0.9689624593556015, 0.9234338747099768, 0.8243087557603687, 0.7665495020503807, 0.9589774078478003, 0.9419410745233969, 0.8741279069767441, 0.8107643859146865]\n",
      "cluster_accuracy_post_training_cycle_all_dataset : [0.97918638 0.97832234 0.97448243 0.96721311 0.96517413 0.95141509\n",
      " 0.92938836 0.8579492  0.94856278 0.93164062 0.80357143 0.76911619\n",
      " 0.95977597 0.93792435 0.86421569 0.81748686]\n",
      "mean_cluster_accuracy_during_training_cycle : 91.21%, post_traincycle_acc : 91.47%, total_acc : 91.36581181%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 91.77%\n",
      "accuracy_check 실행 시간: 21.903초\n",
      "\n",
      "\n",
      "epoch-50 loss : 0.00622666, loss_normal : 0.01001902, loss_coarse : 0.04347046, min_loss : 0.00621305, min_loss_normal : 0.01001388, min_loss_coarse : 0.04341918, wrong_element_sum : 8346328.00000000, same_data : 0.00%\n",
      "ae train 실행 시간: 118.809초, 전체 시작 시간 20250314_000324_593\n",
      "\n",
      "epoch-50 accuracy check\n",
      "k_means origin feature average accuracy : 82.26578875%, total [0.9746727376209448, 0.9733106189664963, 0.9700891573195284, 0.9530800230282096, 0.943108504398827, 0.9150568181818182, 0.801817648783348, 0.6625070901871809, 0.9488619568430388, 0.822215777262181, 0.5872695852534562, 0.5005858230814294, 0.9429250891795482, 0.8922588099364529, 0.6747093023255814, 0.6000572573718866]\n",
      "kmeans average accuracy best : 91.98%, kmeans average accuracy : 91.59803775%, total [0.9763801935116676, 0.9778534923339012, 0.9749784296807593, 0.9645941278065631, 0.9615835777126099, 0.9573863636363636, 0.9313984168865436, 0.8573454339194555, 0.967188885604493, 0.9274941995359629, 0.834389400921659, 0.7753368482718219, 0.955410225921522, 0.9350086655112652, 0.8691860465116279, 0.7901517320354996]\n",
      "cluster_accuracy_post_training_cycle_all_dataset : [0.97965941 0.97832234 0.97496389 0.96721311 0.96368159 0.95235849\n",
      " 0.93336648 0.85183443 0.95511851 0.93896484 0.80646718 0.78103277\n",
      " 0.9592668  0.93355965 0.86764706 0.77353082]\n",
      "mean_cluster_accuracy_during_training_cycle : 90.93%, post_traincycle_acc : 91.36%, total_acc : 91.18035109%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 91.77%\n",
      "accuracy_check 실행 시간: 21.969초\n",
      "\n",
      "\n",
      "epoch-51 loss : 0.00621291, loss_normal : 0.01000720, loss_coarse : 0.04340551, min_loss : 0.00621291, min_loss_normal : 0.01000720, min_loss_coarse : 0.04340551, wrong_element_sum : 8333858.00000000, same_data : 0.00%\n",
      "ae train 실행 시간: 115.965초, 전체 시작 시간 20250314_000324_593\n",
      "\n",
      "epoch-51 accuracy check\n",
      "k_means origin feature average accuracy : 82.24773733%, total [0.9746727376209448, 0.9733106189664963, 0.9700891573195284, 0.9530800230282096, 0.943108504398827, 0.915340909090909, 0.8015244796247435, 0.6625070901871809, 0.9488619568430388, 0.822215777262181, 0.5866935483870968, 0.5005858230814294, 0.9429250891795482, 0.8908145580589255, 0.6747093023255814, 0.5991983967935872]\n",
      "kmeans average accuracy best : 91.98%, kmeans average accuracy : 91.53728729%, total [0.9760956175298805, 0.9775695627484384, 0.9746908254242163, 0.9660333909038572, 0.9618768328445748, 0.9565340909090909, 0.9255350337144532, 0.8491208167895632, 0.9621637599763524, 0.9153132250580046, 0.8303571428571429, 0.7653778558875219, 0.9592746730083235, 0.938474870017331, 0.8793604651162791, 0.8081878041797882]\n",
      "cluster_accuracy_post_training_cycle_all_dataset : [0.97918638 0.97832234 0.97496389 0.96865959 0.9641791  0.95188679\n",
      " 0.9273993  0.8494826  0.95108422 0.9296875  0.80550193 0.73237339\n",
      " 0.96028513 0.93210475 0.88627451 0.80984233]\n",
      "mean_cluster_accuracy_during_training_cycle : 90.77%, post_traincycle_acc : 91.26%, total_acc : 91.06002761%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 91.77%\n",
      "accuracy_check 실행 시간: 21.920초\n",
      "\n",
      "\n",
      "epoch-52 loss : 0.00621682, loss_normal : 0.01000956, loss_coarse : 0.04343284, min_loss : 0.00621291, min_loss_normal : 0.01000720, min_loss_coarse : 0.04340551, wrong_element_sum : 8339106.00000000, same_data : 0.00%\n",
      "ae train 실행 시간: 109.577초, 전체 시작 시간 20250314_000324_593\n",
      "\n",
      "epoch-52 accuracy check\n",
      "k_means origin feature average accuracy : 82.25508056%, total [0.9746727376209448, 0.9733106189664963, 0.9700891573195284, 0.9530800230282096, 0.943108504398827, 0.9150568181818182, 0.801817648783348, 0.6625070901871809, 0.9488619568430388, 0.822215777262181, 0.5872695852534562, 0.5005858230814294, 0.9429250891795482, 0.8922588099364529, 0.675, 0.5980532493558546]\n",
      "kmeans average accuracy best : 91.98%, kmeans average accuracy : 91.46895352%, total [0.9763801935116676, 0.9778534923339012, 0.9749784296807593, 0.9654576856649395, 0.9609970674486803, 0.9551136363636363, 0.9234828496042217, 0.8477027793533749, 0.9615725687259828, 0.9156032482598608, 0.8300691244239631, 0.7738722905682484, 0.9574910820451843, 0.9376083188908145, 0.8723837209302325, 0.8044660750071572]\n",
      "cluster_accuracy_post_training_cycle_all_dataset : [0.97918638 0.97832234 0.97496389 0.96721311 0.96368159 0.95188679\n",
      " 0.93187469 0.85136406 0.9480585  0.92578125 0.80743243 0.76365442\n",
      " 0.95977597 0.92919496 0.87058824 0.81318681]\n",
      "mean_cluster_accuracy_during_training_cycle : 90.62%, post_traincycle_acc : 91.35%, total_acc : 91.05291034%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 91.77%\n",
      "accuracy_check 실행 시간: 22.072초\n",
      "\n",
      "\n",
      "epoch-53 loss : 0.00620876, loss_normal : 0.01000996, loss_coarse : 0.04339017, min_loss : 0.00620876, min_loss_normal : 0.01000720, min_loss_coarse : 0.04339017, wrong_element_sum : 8330912.00000000, same_data : 0.00%\n",
      "ae train 실행 시간: 115.626초, 전체 시작 시간 20250314_000324_593\n",
      "\n",
      "epoch-53 accuracy check\n",
      "k_means origin feature average accuracy : 82.25863750%, total [0.9746727376209448, 0.9733106189664963, 0.9700891573195284, 0.9530800230282096, 0.943108504398827, 0.9150568181818182, 0.801817648783348, 0.6625070901871809, 0.9488619568430388, 0.822215777262181, 0.5866935483870968, 0.5005858230814294, 0.9429250891795482, 0.8922588099364529, 0.675, 0.5991983967935872]\n",
      "kmeans average accuracy best : 91.98%, kmeans average accuracy : 91.81252613%, total [0.9763801935116676, 0.978137421919364, 0.9746908254242163, 0.9651698330454808, 0.9615835777126099, 0.9582386363636364, 0.9313984168865436, 0.8610323312535451, 0.967188885604493, 0.9260440835266821, 0.8355414746543779, 0.7776801405975395, 0.9592746730083235, 0.9367417677642981, 0.8752906976744186, 0.8056112224448898]\n",
      "cluster_accuracy_post_training_cycle_all_dataset : [0.97965941 0.97879359 0.97496389 0.96817743 0.96517413 0.95330189\n",
      " 0.9373446  0.8664158  0.9480585  0.93652344 0.81853282 0.76911619\n",
      " 0.96130346 0.93307468 0.88235294 0.81939799]\n",
      "mean_cluster_accuracy_during_training_cycle : 90.88%, post_traincycle_acc : 91.83%, total_acc : 91.44309314%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 91.77%\n",
      "accuracy_check 실행 시간: 22.070초\n",
      "\n",
      "\n",
      "epoch-54 loss : 0.00620637, loss_normal : 0.01000802, loss_coarse : 0.04336903, min_loss : 0.00620637, min_loss_normal : 0.01000720, min_loss_coarse : 0.04336903, wrong_element_sum : 8326854.00000000, same_data : 0.00%\n",
      "ae train 실행 시간: 114.134초, 전체 시작 시간 20250314_000324_593\n",
      "\n",
      "epoch-54 accuracy check\n",
      "k_means origin feature average accuracy : 82.25487505%, total [0.9746727376209448, 0.9733106189664963, 0.9700891573195284, 0.9530800230282096, 0.943108504398827, 0.9150568181818182, 0.8015244796247435, 0.6622234826999432, 0.9488619568430388, 0.822215777262181, 0.5872695852534562, 0.5002929115407148, 0.9429250891795482, 0.8922588099364529, 0.673546511627907, 0.6003435442313197]\n",
      "kmeans average accuracy best : 91.98%, kmeans average accuracy : 91.67336485%, total [0.9763801935116676, 0.978137421919364, 0.9746908254242163, 0.9651698330454808, 0.9604105571847508, 0.9559659090909091, 0.9228965112870126, 0.8539421440726035, 0.9657109074785694, 0.9263341067285383, 0.8346774193548387, 0.7715289982425307, 0.9607609988109393, 0.9442518775274408, 0.8744186046511628, 0.8024620669911251]\n",
      "cluster_accuracy_post_training_cycle_all_dataset : [0.97965941 0.97832234 0.97496389 0.96721311 0.96318408 0.95283019\n",
      " 0.92839383 0.8523048  0.9515885  0.93798828 0.81322394 0.7775571\n",
      " 0.96181263 0.93792435 0.87892157 0.81414238]\n",
      "mean_cluster_accuracy_during_training_cycle : 91.02%, post_traincycle_acc : 91.69%, total_acc : 91.41709209%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 91.77%\n",
      "accuracy_check 실행 시간: 22.005초\n",
      "\n",
      "\n",
      "epoch-55 loss : 0.00621634, loss_normal : 0.01000726, loss_coarse : 0.04342883, min_loss : 0.00620637, min_loss_normal : 0.01000720, min_loss_coarse : 0.04336903, wrong_element_sum : 8338336.00000000, same_data : 0.00%\n",
      "ae train 실행 시간: 114.745초, 전체 시작 시간 20250314_000324_593\n",
      "\n",
      "epoch-55 accuracy check\n",
      "k_means origin feature average accuracy : 82.26041597%, total [0.9746727376209448, 0.9733106189664963, 0.9700891573195284, 0.9530800230282096, 0.943108504398827, 0.9150568181818182, 0.801817648783348, 0.6622234826999432, 0.9488619568430388, 0.822215777262181, 0.5866935483870968, 0.5005858230814294, 0.9429250891795482, 0.8922588099364529, 0.6747093023255814, 0.6000572573718866]\n",
      "kmeans average accuracy best : 91.98%, kmeans average accuracy : 91.70247818%, total [0.9763801935116676, 0.9784213515048268, 0.9746908254242163, 0.9657455382843984, 0.9607038123167155, 0.9553977272727273, 0.9272940486660803, 0.8539421440726035, 0.9651197162281998, 0.9208236658932715, 0.8378456221198156, 0.7750439367311072, 0.9616527942925089, 0.9422299248989023, 0.8703488372093023, 0.8067563698826223]\n",
      "cluster_accuracy_post_training_cycle_all_dataset : [0.97965941 0.97879359 0.97496389 0.96865959 0.96368159 0.95141509\n",
      " 0.93386375 0.855127   0.95108422 0.93554688 0.81515444 0.77408143\n",
      " 0.96435845 0.93501455 0.8754902  0.80936455]\n",
      "mean_cluster_accuracy_during_training_cycle : 90.94%, post_traincycle_acc : 91.66%, total_acc : 91.36720141%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 91.77%\n",
      "accuracy_check 실행 시간: 21.620초\n",
      "\n",
      "\n",
      "epoch-56 loss : 0.00619051, loss_normal : 0.00999788, loss_coarse : 0.04331632, min_loss : 0.00619051, min_loss_normal : 0.00999788, min_loss_coarse : 0.04331632, wrong_element_sum : 8316734.00000000, same_data : 0.00%\n",
      "ae train 실행 시간: 116.362초, 전체 시작 시간 20250314_000324_593\n",
      "\n",
      "epoch-56 accuracy check\n",
      "k_means origin feature average accuracy : 82.25678225%, total [0.9746727376209448, 0.9733106189664963, 0.9700891573195284, 0.9530800230282096, 0.943108504398827, 0.9150568181818182, 0.801817648783348, 0.6622234826999432, 0.9488619568430388, 0.822215777262181, 0.5866935483870968, 0.5005858230814294, 0.9429250891795482, 0.8922588099364529, 0.6741279069767442, 0.6000572573718866]\n",
      "kmeans average accuracy best : 91.98%, kmeans average accuracy : 91.66008812%, total [0.9763801935116676, 0.978137421919364, 0.9752660339373023, 0.9645941278065631, 0.9607038123167155, 0.9559659090909091, 0.9275872178246849, 0.8539421440726035, 0.9630505468519066, 0.9248839907192575, 0.8323732718894009, 0.7709431751611013, 0.9577883472057075, 0.9355863662622761, 0.8796511627906977, 0.8087603778986544]\n",
      "cluster_accuracy_post_training_cycle_all_dataset : [0.97918638 0.97832234 0.97496389 0.96673095 0.9641791  0.95141509\n",
      " 0.93286922 0.85841957 0.95007564 0.93359375 0.81901544 0.7795432\n",
      " 0.96028513 0.93355965 0.88137255 0.82417582]\n",
      "mean_cluster_accuracy_during_training_cycle : 91.21%, post_traincycle_acc : 91.80%, total_acc : 91.55707157%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 91.77%\n",
      "accuracy_check 실행 시간: 22.418초\n",
      "\n",
      "\n",
      "epoch-57 loss : 0.00620011, loss_normal : 0.00999999, loss_coarse : 0.04334813, min_loss : 0.00619051, min_loss_normal : 0.00999788, min_loss_coarse : 0.04331632, wrong_element_sum : 8322842.00000000, same_data : 0.00%\n",
      "ae train 실행 시간: 116.013초, 전체 시작 시간 20250314_000324_593\n",
      "\n",
      "epoch-57 accuracy check\n",
      "k_means origin feature average accuracy : 82.25496539%, total [0.9746727376209448, 0.9733106189664963, 0.9700891573195284, 0.9530800230282096, 0.943108504398827, 0.9150568181818182, 0.801817648783348, 0.6622234826999432, 0.9488619568430388, 0.822215777262181, 0.5866935483870968, 0.5005858230814294, 0.9429250891795482, 0.8922588099364529, 0.6738372093023256, 0.6000572573718866]\n",
      "kmeans average accuracy best : 91.98%, kmeans average accuracy : 91.86030959%, total [0.9763801935116676, 0.9775695627484384, 0.9749784296807593, 0.9648819804260219, 0.9615835777126099, 0.95625, 0.9296394019349165, 0.8570618264322178, 0.966006503103754, 0.925754060324826, 0.8384216589861752, 0.7765084944346807, 0.9563020214030915, 0.938474870017331, 0.8781976744186046, 0.8196392785571143]\n",
      "cluster_accuracy_post_training_cycle_all_dataset : [0.97918638 0.97785108 0.97496389 0.96721311 0.9641791  0.95141509\n",
      " 0.92988563 0.85465663 0.95108422 0.94042969 0.81129344 0.7775571\n",
      " 0.95875764 0.93307468 0.8877451  0.8332537 ]\n",
      "mean_cluster_accuracy_during_training_cycle : 91.09%, post_traincycle_acc : 91.83%, total_acc : 91.52968480%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 91.77%\n",
      "accuracy_check 실행 시간: 22.515초\n",
      "\n",
      "\n",
      "epoch-58 loss : 0.00617636, loss_normal : 0.00998787, loss_coarse : 0.04323542, min_loss : 0.00617636, min_loss_normal : 0.00998787, min_loss_coarse : 0.04323542, wrong_element_sum : 8301200.00000000, same_data : 0.00%\n",
      "ae train 실행 시간: 112.407초, 전체 시작 시간 20250314_000324_593\n",
      "\n",
      "epoch-58 accuracy check\n",
      "k_means origin feature average accuracy : 82.26578875%, total [0.9746727376209448, 0.9733106189664963, 0.9700891573195284, 0.9530800230282096, 0.943108504398827, 0.9150568181818182, 0.801817648783348, 0.6625070901871809, 0.9488619568430388, 0.822215777262181, 0.5872695852534562, 0.5005858230814294, 0.9429250891795482, 0.8922588099364529, 0.6747093023255814, 0.6000572573718866]\n",
      "kmeans average accuracy best : 91.98%, kmeans average accuracy : 91.43676606%, total [0.9763801935116676, 0.978137421919364, 0.9746908254242163, 0.9651698330454808, 0.9609970674486803, 0.9548295454545455, 0.9220170038111991, 0.8519568916619399, 0.9645285249778304, 0.9182134570765661, 0.8251728110599078, 0.7680140597539543, 0.960166468489893, 0.939052570768342, 0.8726744186046511, 0.7978814772401946]\n",
      "cluster_accuracy_post_training_cycle_all_dataset : [0.97918638 0.97879359 0.97496389 0.96673095 0.96318408 0.95188679\n",
      " 0.93088016 0.8480715  0.94402421 0.93408203 0.80212355 0.74329692\n",
      " 0.96283096 0.93210475 0.87598039 0.80888677]\n",
      "mean_cluster_accuracy_during_training_cycle : 90.44%, post_traincycle_acc : 91.23%, total_acc : 90.90937232%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 91.77%\n",
      "accuracy_check 실행 시간: 21.797초\n",
      "\n",
      "\n",
      "epoch-59 loss : 0.00617200, loss_normal : 0.00998793, loss_coarse : 0.04320110, min_loss : 0.00617200, min_loss_normal : 0.00998787, min_loss_coarse : 0.04320110, wrong_element_sum : 8294612.00000000, same_data : 0.00%\n",
      "ae train 실행 시간: 120.569초, 전체 시작 시간 20250314_000324_593\n",
      "\n",
      "epoch-59 accuracy check\n",
      "k_means origin feature average accuracy : 82.59314664%, total [0.9746727376209448, 0.9733106189664963, 0.9700891573195284, 0.9530800230282096, 0.943108504398827, 0.9150568181818182, 0.801817648783348, 0.6625070901871809, 0.9488619568430388, 0.822215777262181, 0.5872695852534562, 0.5005858230814294, 0.9429250891795482, 0.8922588099364529, 0.6738372093023256, 0.6533066132264529]\n",
      "kmeans average accuracy best : 91.98%, kmeans average accuracy : 91.58203662%, total [0.9763801935116676, 0.978137421919364, 0.9749784296807593, 0.9654576856649395, 0.9612903225806452, 0.9553977272727273, 0.9228965112870126, 0.8536585365853658, 0.9654153118533846, 0.9234338747099768, 0.8306451612903226, 0.7697715289982425, 0.9586801426872771, 0.9332755632582322, 0.8715116279069768, 0.8121958202118523]\n",
      "cluster_accuracy_post_training_cycle_all_dataset : [0.97965941 0.97832234 0.97496389 0.96769527 0.96467662 0.95235849\n",
      " 0.92988563 0.85747883 0.94856278 0.93310547 0.81370656 0.77805362\n",
      " 0.96181263 0.93210475 0.88284314 0.79980889]\n",
      "mean_cluster_accuracy_during_training_cycle : 90.98%, post_traincycle_acc : 91.59%, total_acc : 91.34482958%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 91.77%\n",
      "accuracy_check 실행 시간: 23.193초\n",
      "\n",
      "\n",
      "epoch-60 loss : 0.00618622, loss_normal : 0.00999325, loss_coarse : 0.04329476, min_loss : 0.00617200, min_loss_normal : 0.00998787, min_loss_coarse : 0.04320110, wrong_element_sum : 8312594.00000000, same_data : 0.00%\n",
      "ae train 실행 시간: 116.345초, 전체 시작 시간 20250314_000324_593\n",
      "\n",
      "epoch-60 accuracy check\n",
      "k_means origin feature average accuracy : 82.26218852%, total [0.9746727376209448, 0.9733106189664963, 0.9700891573195284, 0.9530800230282096, 0.943108504398827, 0.9150568181818182, 0.801817648783348, 0.6625070901871809, 0.9488619568430388, 0.822215777262181, 0.5866935483870968, 0.5005858230814294, 0.9429250891795482, 0.8922588099364529, 0.6747093023255814, 0.6000572573718866]\n",
      "kmeans average accuracy best : 91.98%, kmeans average accuracy : 91.57633624%, total [0.9763801935116676, 0.978137421919364, 0.9746908254242163, 0.9666090961427749, 0.9604105571847508, 0.9553977272727273, 0.92143066549399, 0.846001134429949, 0.9651197162281998, 0.9266241299303944, 0.8323732718894009, 0.7718219097832455, 0.960166468489893, 0.9433853264009243, 0.8700581395348838, 0.8036072144288577]\n",
      "cluster_accuracy_post_training_cycle_all_dataset : [0.97918638 0.97879359 0.97496389 0.96721311 0.96467662 0.9504717\n",
      " 0.92541024 0.85465663 0.9515885  0.94091797 0.80743243 0.74677259\n",
      " 0.96130346 0.93986421 0.88431373 0.81557573]\n",
      "mean_cluster_accuracy_during_training_cycle : 90.78%, post_traincycle_acc : 91.52%, total_acc : 91.21869844%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 91.77%\n",
      "accuracy_check 실행 시간: 24.828초\n",
      "\n",
      "\n",
      "epoch-61 loss : 0.00618584, loss_normal : 0.00999220, loss_coarse : 0.04328643, min_loss : 0.00617200, min_loss_normal : 0.00998787, min_loss_coarse : 0.04320110, wrong_element_sum : 8310994.00000000, same_data : 0.00%\n",
      "ae train 실행 시간: 115.306초, 전체 시작 시간 20250314_000324_593\n",
      "\n",
      "epoch-61 accuracy check\n",
      "k_means origin feature average accuracy : 82.25501460%, total [0.9746727376209448, 0.9733106189664963, 0.9700891573195284, 0.9530800230282096, 0.943108504398827, 0.9150568181818182, 0.801817648783348, 0.6622234826999432, 0.9488619568430388, 0.822215777262181, 0.5872695852534562, 0.5005858230814294, 0.9429250891795482, 0.8922588099364529, 0.6741279069767442, 0.5991983967935872]\n",
      "kmeans average accuracy best : 91.98%, kmeans average accuracy : 91.51306005%, total [0.9763801935116676, 0.9778534923339012, 0.9741156169111302, 0.9657455382843984, 0.9615835777126099, 0.9556818181818182, 0.9249486953972442, 0.8502552467385139, 0.9600945906000591, 0.9138631090487239, 0.824020737327189, 0.7636203866432337, 0.9592746730083235, 0.9459849797804737, 0.8776162790697675, 0.8110506727741197]\n",
      "cluster_accuracy_post_training_cycle_all_dataset : [0.97965941 0.97785108 0.97496389 0.96769527 0.96567164 0.95141509\n",
      " 0.93237195 0.8523048  0.93444276 0.9296875  0.79681467 0.75620655\n",
      " 0.96130346 0.93986421 0.89166667 0.83420927]\n",
      "mean_cluster_accuracy_during_training_cycle : 90.79%, post_traincycle_acc : 91.54%, total_acc : 91.23412462%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 91.77%\n",
      "accuracy_check 실행 시간: 25.578초\n",
      "\n",
      "\n",
      "epoch-62 loss : 0.00618734, loss_normal : 0.00999190, loss_coarse : 0.04329556, min_loss : 0.00617200, min_loss_normal : 0.00998787, min_loss_coarse : 0.04320110, wrong_element_sum : 8312748.00000000, same_data : 0.00%\n",
      "ae train 실행 시간: 117.302초, 전체 시작 시간 20250314_000324_593\n",
      "\n",
      "epoch-62 accuracy check\n",
      "k_means origin feature average accuracy : 82.26034409%, total [0.9746727376209448, 0.9733106189664963, 0.9700891573195284, 0.9530800230282096, 0.943108504398827, 0.9150568181818182, 0.801817648783348, 0.6625070901871809, 0.9488619568430388, 0.822215777262181, 0.5866935483870968, 0.5005858230814294, 0.9429250891795482, 0.8922588099364529, 0.6741279069767442, 0.6003435442313197]\n",
      "kmeans average accuracy best : 91.98%, kmeans average accuracy : 91.82445521%, total [0.9763801935116676, 0.9778534923339012, 0.9749784296807593, 0.9648819804260219, 0.9612903225806452, 0.9556818181818182, 0.9349164467897977, 0.8630175836642088, 0.966006503103754, 0.9283642691415314, 0.8384216589861752, 0.7729935559461043, 0.9580856123662307, 0.9358752166377816, 0.873546511627907, 0.8096192384769539]\n",
      "cluster_accuracy_post_training_cycle_all_dataset : [0.97965941 0.97832234 0.97496389 0.96673095 0.96517413 0.95\n",
      " 0.93436101 0.86030103 0.93393848 0.94287109 0.80694981 0.79294935\n",
      " 0.96130346 0.93404462 0.87401961 0.82083134]\n",
      "mean_cluster_accuracy_during_training_cycle : 91.06%, post_traincycle_acc : 91.73%, total_acc : 91.45605331%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 91.77%\n",
      "accuracy_check 실행 시간: 24.217초\n",
      "\n",
      "\n",
      "epoch-63 loss : 0.00617166, loss_normal : 0.00997779, loss_coarse : 0.04315556, min_loss : 0.00617166, min_loss_normal : 0.00997779, min_loss_coarse : 0.04315556, wrong_element_sum : 8285868.00000000, same_data : 0.00%\n",
      "ae train 실행 시간: 113.998초, 전체 시작 시간 20250314_000324_593\n",
      "\n",
      "epoch-63 accuracy check\n",
      "k_means origin feature average accuracy : 82.25492108%, total [0.9746727376209448, 0.9733106189664963, 0.9700891573195284, 0.9530800230282096, 0.943108504398827, 0.9150568181818182, 0.801817648783348, 0.6625070901871809, 0.9488619568430388, 0.822215777262181, 0.5866935483870968, 0.5005858230814294, 0.9429250891795482, 0.8922588099364529, 0.673546511627907, 0.6000572573718866]\n",
      "kmeans average accuracy best : 91.98%, kmeans average accuracy : 91.65441084%, total [0.9763801935116676, 0.9778534923339012, 0.9746908254242163, 0.9657455382843984, 0.9615835777126099, 0.9571022727272728, 0.9255350337144532, 0.8570618264322178, 0.9645285249778304, 0.9214037122969838, 0.8297811059907834, 0.7674282366725249, 0.9607609988109393, 0.9393414211438474, 0.8770348837209302, 0.8084740910392213]\n",
      "cluster_accuracy_post_training_cycle_all_dataset : [0.97871334 0.97879359 0.97496389 0.96817743 0.96517413 0.95141509\n",
      " 0.93386375 0.85606773 0.94755421 0.93212891 0.7992278  0.76861966\n",
      " 0.96283096 0.93404462 0.87941176 0.81748686]\n",
      "mean_cluster_accuracy_during_training_cycle : 90.91%, post_traincycle_acc : 91.55%, total_acc : 91.28890765%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 91.77%\n",
      "accuracy_check 실행 시간: 23.503초\n",
      "\n",
      "\n",
      "epoch-64 loss : 0.00618880, loss_normal : 0.00998485, loss_coarse : 0.04326089, min_loss : 0.00617166, min_loss_normal : 0.00997779, min_loss_coarse : 0.04315556, wrong_element_sum : 8306092.00000000, same_data : 0.00%\n",
      "ae train 실행 시간: 115.560초, 전체 시작 시간 20250314_000324_593\n",
      "\n",
      "epoch-64 accuracy check\n",
      "k_means origin feature average accuracy : 82.25675468%, total [0.9746727376209448, 0.9733106189664963, 0.9700891573195284, 0.9530800230282096, 0.943108504398827, 0.9150568181818182, 0.801817648783348, 0.6622234826999432, 0.9488619568430388, 0.822215777262181, 0.5866935483870968, 0.5005858230814294, 0.9429250891795482, 0.8922588099364529, 0.6738372093023256, 0.6003435442313197]\n",
      "kmeans average accuracy best : 91.98%, kmeans average accuracy : 91.67251298%, total [0.9763801935116676, 0.9778534923339012, 0.9744032211676733, 0.9648819804260219, 0.9612903225806452, 0.9565340909090909, 0.9308120785693345, 0.8581962563811685, 0.9665976943541236, 0.9243039443155452, 0.8375576036866359, 0.7785588752196837, 0.9518430439952438, 0.9326978625072213, 0.8715116279069768, 0.8041797881477241]\n",
      "cluster_accuracy_post_training_cycle_all_dataset : [0.97965941 0.97832234 0.97496389 0.96769527 0.96467662 0.95283019\n",
      " 0.93088016 0.86171214 0.95108422 0.9375     0.81467181 0.76514399\n",
      " 0.95570265 0.92531523 0.88872549 0.80315337]\n",
      "mean_cluster_accuracy_during_training_cycle : 90.86%, post_traincycle_acc : 91.58%, total_acc : 91.28158504%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 91.77%\n",
      "accuracy_check 실행 시간: 23.866초\n",
      "\n",
      "\n",
      "epoch-65 loss : 0.00616690, loss_normal : 0.00997840, loss_coarse : 0.04316805, min_loss : 0.00616690, min_loss_normal : 0.00997779, min_loss_coarse : 0.04315556, wrong_element_sum : 8288266.00000000, same_data : 0.00%\n",
      "ae train 실행 시간: 116.407초, 전체 시작 시간 20250314_000324_593\n",
      "\n",
      "epoch-65 accuracy check\n",
      "k_means origin feature average accuracy : 82.25492108%, total [0.9746727376209448, 0.9733106189664963, 0.9700891573195284, 0.9530800230282096, 0.943108504398827, 0.9150568181818182, 0.801817648783348, 0.6625070901871809, 0.9488619568430388, 0.822215777262181, 0.5866935483870968, 0.5005858230814294, 0.9429250891795482, 0.8922588099364529, 0.673546511627907, 0.6000572573718866]\n",
      "kmeans average accuracy best : 91.98%, kmeans average accuracy : 91.60765861%, total [0.9760956175298805, 0.9778534923339012, 0.9746908254242163, 0.9654576856649395, 0.9609970674486803, 0.9553977272727273, 0.9313984168865436, 0.8576290414066932, 0.9654153118533846, 0.9245939675174014, 0.8352534562211982, 0.7644991212653779, 0.9580856123662307, 0.93789716926632, 0.8709302325581395, 0.8010306326939594]\n",
      "cluster_accuracy_post_training_cycle_all_dataset : [0.97871334 0.97832234 0.97496389 0.96721311 0.96467662 0.95188679\n",
      " 0.93485828 0.8579492  0.93797277 0.94189453 0.81370656 0.76415094\n",
      " 0.9607943  0.93792435 0.87058824 0.79885332]\n",
      "mean_cluster_accuracy_during_training_cycle : 91.07%, post_traincycle_acc : 91.47%, total_acc : 91.30392137%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 91.77%\n",
      "accuracy_check 실행 시간: 25.623초\n",
      "\n",
      "\n",
      "epoch-66 loss : 0.00616954, loss_normal : 0.00998076, loss_coarse : 0.04321023, min_loss : 0.00616690, min_loss_normal : 0.00997779, min_loss_coarse : 0.04315556, wrong_element_sum : 8296364.00000000, same_data : 0.00%\n",
      "ae train 실행 시간: 116.686초, 전체 시작 시간 20250314_000324_593\n",
      "\n",
      "epoch-66 accuracy check\n",
      "k_means origin feature average accuracy : 82.24244034%, total [0.9746727376209448, 0.9733106189664963, 0.9700891573195284, 0.9530800230282096, 0.943108504398827, 0.9150568181818182, 0.801817648783348, 0.6622234826999432, 0.9488619568430388, 0.822215777262181, 0.5866935483870968, 0.5005858230814294, 0.9429250891795482, 0.8922588099364529, 0.6738372093023256, 0.5980532493558546]\n",
      "kmeans average accuracy best : 91.98%, kmeans average accuracy : 91.51011898%, total [0.9763801935116676, 0.9778534923339012, 0.9744032211676733, 0.9654576856649395, 0.9609970674486803, 0.9553977272727273, 0.9275872178246849, 0.8533749290981282, 0.9624593556015371, 0.9211136890951276, 0.8338133640552995, 0.7685998828353837, 0.9583828775267539, 0.9335644136337378, 0.8700581395348838, 0.802175780131692]\n",
      "cluster_accuracy_post_training_cycle_all_dataset : [0.97965941 0.97785108 0.97448243 0.96721311 0.96517413 0.95141509\n",
      " 0.93286922 0.85559737 0.93746848 0.9375     0.8030888  0.76713009\n",
      " 0.9592668  0.92774006 0.88284314 0.81127568]\n",
      "mean_cluster_accuracy_during_training_cycle : 90.88%, post_traincycle_acc : 91.44%, total_acc : 91.21165358%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 91.77%\n",
      "accuracy_check 실행 시간: 25.805초\n",
      "\n",
      "\n",
      "epoch-67 loss : 0.00616122, loss_normal : 0.00997237, loss_coarse : 0.04314201, min_loss : 0.00616122, min_loss_normal : 0.00997237, min_loss_coarse : 0.04314201, wrong_element_sum : 8283266.00000000, same_data : 0.00%\n",
      "ae train 실행 시간: 119.985초, 전체 시작 시간 20250314_000324_593\n",
      "\n",
      "epoch-67 accuracy check\n",
      "k_means origin feature average accuracy : 82.26215503%, total [0.9746727376209448, 0.9733106189664963, 0.9700891573195284, 0.9530800230282096, 0.943108504398827, 0.9150568181818182, 0.801817648783348, 0.6625070901871809, 0.9488619568430388, 0.822215777262181, 0.5872695852534562, 0.5005858230814294, 0.9429250891795482, 0.8922588099364529, 0.6741279069767442, 0.6000572573718866]\n",
      "kmeans average accuracy best : 91.98%, kmeans average accuracy : 91.57072046%, total [0.9760956175298805, 0.9775695627484384, 0.9746908254242163, 0.9651698330454808, 0.9609970674486803, 0.9559659090909091, 0.9246555262386397, 0.8545093590470788, 0.9668932899793083, 0.9243039443155452, 0.8289170506912442, 0.7633274751025191, 0.9565992865636147, 0.9347198151357596, 0.8744186046511628, 0.8124821070712854]\n",
      "cluster_accuracy_post_training_cycle_all_dataset : [0.97965941 0.97785108 0.97448243 0.96624879 0.96467662 0.9509434\n",
      " 0.92839383 0.8466604  0.94906707 0.93359375 0.80646718 0.73088381\n",
      " 0.9592668  0.93307468 0.87156863 0.82465361]\n",
      "mean_cluster_accuracy_during_training_cycle : 90.68%, post_traincycle_acc : 91.23%, total_acc : 91.00752614%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 91.77%\n",
      "accuracy_check 실행 시간: 25.442초\n",
      "\n",
      "\n",
      "epoch-68 loss : 0.00614342, loss_normal : 0.00996805, loss_coarse : 0.04309663, min_loss : 0.00614342, min_loss_normal : 0.00996805, min_loss_coarse : 0.04309663, wrong_element_sum : 8274554.00000000, same_data : 0.00%\n",
      "ae train 실행 시간: 115.175초, 전체 시작 시간 20250314_000324_593\n",
      "\n",
      "epoch-68 accuracy check\n",
      "k_means origin feature average accuracy : 82.24598845%, total [0.9746727376209448, 0.9733106189664963, 0.9700891573195284, 0.9530800230282096, 0.943108504398827, 0.915340909090909, 0.801817648783348, 0.6625070901871809, 0.9488619568430388, 0.822215777262181, 0.5866935483870968, 0.5005858230814294, 0.9429250891795482, 0.8922588099364529, 0.6738372093023256, 0.5980532493558546]\n",
      "kmeans average accuracy best : 91.98%, kmeans average accuracy : 91.52363788%, total [0.9763801935116676, 0.9778534923339012, 0.9741156169111302, 0.9645941278065631, 0.9618768328445748, 0.9545454545454546, 0.9261213720316622, 0.8513896766874646, 0.966006503103754, 0.9182134570765661, 0.831221198156682, 0.7715289982425307, 0.9565992865636147, 0.9347198151357596, 0.8755813953488372, 0.8030346407099914]\n",
      "cluster_accuracy_post_training_cycle_all_dataset : [0.97871334 0.97832234 0.97496389 0.96721311 0.96616915 0.95141509\n",
      " 0.92839383 0.85183443 0.93091276 0.93701172 0.80453668 0.78401192\n",
      " 0.95824847 0.93258972 0.87647059 0.82274247]\n",
      "mean_cluster_accuracy_during_training_cycle : 91.00%, post_traincycle_acc : 91.52%, total_acc : 91.31040017%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 91.77%\n",
      "accuracy_check 실행 시간: 25.900초\n",
      "\n",
      "\n",
      "epoch-69 loss : 0.00615038, loss_normal : 0.00996976, loss_coarse : 0.04312077, min_loss : 0.00614342, min_loss_normal : 0.00996805, min_loss_coarse : 0.04309663, wrong_element_sum : 8279188.00000000, same_data : 0.00%\n",
      "ae train 실행 시간: 117.407초, 전체 시작 시간 20250314_000324_593\n",
      "\n",
      "epoch-69 accuracy check\n",
      "k_means origin feature average accuracy : 82.26401620%, total [0.9746727376209448, 0.9733106189664963, 0.9700891573195284, 0.9530800230282096, 0.943108504398827, 0.9150568181818182, 0.801817648783348, 0.6622234826999432, 0.9488619568430388, 0.822215777262181, 0.5872695852534562, 0.5005858230814294, 0.9429250891795482, 0.8922588099364529, 0.6747093023255814, 0.6000572573718866]\n",
      "kmeans average accuracy best : 91.98%, kmeans average accuracy : 91.56971592%, total [0.9763801935116676, 0.9778534923339012, 0.9744032211676733, 0.966321243523316, 0.9609970674486803, 0.9553977272727273, 0.9231896804456171, 0.8553601815087918, 0.9627549512267218, 0.921983758700696, 0.8315092165898618, 0.7744581136496778, 0.9589774078478003, 0.9300982091276718, 0.875, 0.8064700830231892]\n",
      "cluster_accuracy_post_training_cycle_all_dataset : [0.97965941 0.97785108 0.97448243 0.96769527 0.96616915 0.95188679\n",
      " 0.92640477 0.85183443 0.94503278 0.9375     0.81081081 0.77805362\n",
      " 0.96130346 0.92919496 0.8877451  0.81175346]\n",
      "mean_cluster_accuracy_during_training_cycle : 91.03%, post_traincycle_acc : 91.61%, total_acc : 91.37237647%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 91.77%\n",
      "accuracy_check 실행 시간: 27.548초\n",
      "\n",
      "\n",
      "epoch-70 loss : 0.00614248, loss_normal : 0.00996143, loss_coarse : 0.04307414, min_loss : 0.00614248, min_loss_normal : 0.00996143, min_loss_coarse : 0.04307414, wrong_element_sum : 8270236.00000000, same_data : 0.00%\n",
      "ae train 실행 시간: 119.245초, 전체 시작 시간 20250314_000324_593\n",
      "\n",
      "epoch-70 accuracy check\n",
      "k_means origin feature average accuracy : 82.26032272%, total [0.9746727376209448, 0.9733106189664963, 0.9700891573195284, 0.9530800230282096, 0.943108504398827, 0.9150568181818182, 0.8015244796247435, 0.6625070901871809, 0.9488619568430388, 0.822215777262181, 0.5872695852534562, 0.5005858230814294, 0.9429250891795482, 0.8922588099364529, 0.6741279069767442, 0.6000572573718866]\n",
      "kmeans average accuracy best : 91.98%, kmeans average accuracy : 91.46780363%, total [0.9763801935116676, 0.9775695627484384, 0.9746908254242163, 0.9654576856649395, 0.9612903225806452, 0.9559659090909091, 0.92143066549399, 0.8499716392512763, 0.968371268105232, 0.9240139211136891, 0.8306451612903226, 0.7712360867018161, 0.9571938168846611, 0.9350086655112652, 0.8683139534883721, 0.7973089035213283]\n",
      "cluster_accuracy_post_training_cycle_all_dataset : [0.97871334 0.97785108 0.97496389 0.96673095 0.96517413 0.9509434\n",
      " 0.92292392 0.85418627 0.95562279 0.93701172 0.80067568 0.71797418\n",
      " 0.96028513 0.92870999 0.88284314 0.8107979 ]\n",
      "mean_cluster_accuracy_during_training_cycle : 90.52%, post_traincycle_acc : 91.16%, total_acc : 90.89778660%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 91.77%\n",
      "accuracy_check 실행 시간: 26.243초\n",
      "\n",
      "\n",
      "epoch-71 loss : 0.00614560, loss_normal : 0.00996763, loss_coarse : 0.04311034, min_loss : 0.00614248, min_loss_normal : 0.00996143, min_loss_coarse : 0.04307414, wrong_element_sum : 8277186.00000000, same_data : 0.00%\n",
      "ae train 실행 시간: 116.960초, 전체 시작 시간 20250314_000324_593\n",
      "\n",
      "epoch-71 accuracy check\n",
      "k_means origin feature average accuracy : 82.25673794%, total [0.9746727376209448, 0.9733106189664963, 0.9700891573195284, 0.9530800230282096, 0.943108504398827, 0.9150568181818182, 0.801817648783348, 0.6625070901871809, 0.9488619568430388, 0.822215777262181, 0.5866935483870968, 0.5005858230814294, 0.9429250891795482, 0.8922588099364529, 0.6738372093023256, 0.6000572573718866]\n",
      "kmeans average accuracy best : 91.98%, kmeans average accuracy : 91.53202674%, total [0.9766647694934547, 0.9775695627484384, 0.9744032211676733, 0.9651698330454808, 0.9615835777126099, 0.9556818181818182, 0.9240691879214307, 0.8502552467385139, 0.9651197162281998, 0.9187935034802784, 0.8283410138248848, 0.7677211482132396, 0.9580856123662307, 0.9358752166377816, 0.8767441860465116, 0.8090466647580876]\n",
      "cluster_accuracy_post_training_cycle_all_dataset : [0.97918638 0.97832234 0.97496389 0.96673095 0.96467662 0.95283019\n",
      " 0.93187469 0.8466604  0.94150277 0.93164062 0.81274131 0.77010924\n",
      " 0.95875764 0.93598448 0.88284314 0.82274247]\n",
      "mean_cluster_accuracy_during_training_cycle : 90.70%, post_traincycle_acc : 91.57%, total_acc : 91.21691880%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 91.77%\n",
      "accuracy_check 실행 시간: 25.918초\n",
      "\n",
      "\n",
      "epoch-72 loss : 0.00612790, loss_normal : 0.00996299, loss_coarse : 0.04303891, min_loss : 0.00612790, min_loss_normal : 0.00996143, min_loss_coarse : 0.04303891, wrong_element_sum : 8263470.00000000, same_data : 0.00%\n",
      "ae train 실행 시간: 118.192초, 전체 시작 시간 20250314_000324_593\n",
      "\n",
      "epoch-72 accuracy check\n",
      "k_means origin feature average accuracy : 82.24417940%, total [0.9746727376209448, 0.9733106189664963, 0.9700891573195284, 0.9530800230282096, 0.943108504398827, 0.9150568181818182, 0.801817648783348, 0.6625070901871809, 0.9488619568430388, 0.822215777262181, 0.5872695852534562, 0.5005858230814294, 0.9429250891795482, 0.8922588099364529, 0.6732558139534883, 0.5980532493558546]\n",
      "kmeans average accuracy best : 91.98%, kmeans average accuracy : 91.62011307%, total [0.9760956175298805, 0.978137421919364, 0.9738280126545873, 0.9651698330454808, 0.9609970674486803, 0.9568181818181818, 0.9211374963353856, 0.8530913216108905, 0.9642329293526456, 0.9289443155452436, 0.8283410138248848, 0.7697715289982425, 0.9613555291319857, 0.9355863662622761, 0.8715116279069768, 0.8141998282278844]\n",
      "cluster_accuracy_post_training_cycle_all_dataset : [0.97918638 0.97832234 0.97496389 0.96673095 0.96467662 0.95188679\n",
      " 0.93187469 0.84995296 0.94654564 0.94042969 0.81274131 0.76514399\n",
      " 0.96283096 0.93307468 0.8872549  0.82560917]\n",
      "mean_cluster_accuracy_during_training_cycle : 91.08%, post_traincycle_acc : 91.70%, total_acc : 91.44362569%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 91.77%\n",
      "accuracy_check 실행 시간: 25.359초\n",
      "\n",
      "\n",
      "epoch-73 loss : 0.00614318, loss_normal : 0.00996824, loss_coarse : 0.04312556, min_loss : 0.00612790, min_loss_normal : 0.00996143, min_loss_coarse : 0.04303891, wrong_element_sum : 8280108.00000000, same_data : 0.00%\n",
      "ae train 실행 시간: 116.244초, 전체 시작 시간 20250314_000324_593\n",
      "\n",
      "epoch-73 accuracy check\n",
      "k_means origin feature average accuracy : 82.25856562%, total [0.9746727376209448, 0.9733106189664963, 0.9700891573195284, 0.9530800230282096, 0.943108504398827, 0.9150568181818182, 0.801817648783348, 0.6622234826999432, 0.9488619568430388, 0.822215777262181, 0.5872695852534562, 0.5005858230814294, 0.9429250891795482, 0.8922588099364529, 0.6738372093023256, 0.6000572573718866]\n",
      "kmeans average accuracy best : 91.98%, kmeans average accuracy : 91.62252179%, total [0.9760956175298805, 0.978137421919364, 0.9741156169111302, 0.9648819804260219, 0.9609970674486803, 0.9559659090909091, 0.9255350337144532, 0.8522404991491775, 0.9645285249778304, 0.925754060324826, 0.8335253456221198, 0.768306971294669, 0.9589774078478003, 0.9422299248989023, 0.8744186046511628, 0.8038935012882908]\n",
      "cluster_accuracy_post_training_cycle_all_dataset : [0.97918638 0.97879359 0.97400096 0.96721311 0.96517413 0.95141509\n",
      " 0.93038289 0.8565381  0.93242562 0.93798828 0.8011583  0.76067527\n",
      " 0.96130346 0.93792435 0.88823529 0.82799809]\n",
      "mean_cluster_accuracy_during_training_cycle : 90.94%, post_traincycle_acc : 91.57%, total_acc : 91.31235047%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 91.77%\n",
      "accuracy_check 실행 시간: 24.765초\n",
      "\n",
      "\n",
      "epoch-74 loss : 0.00613580, loss_normal : 0.00996093, loss_coarse : 0.04307374, min_loss : 0.00612790, min_loss_normal : 0.00996093, min_loss_coarse : 0.04303891, wrong_element_sum : 8270158.00000000, same_data : 0.00%\n",
      "ae train 실행 시간: 117.938초, 전체 시작 시간 20250314_000324_593\n",
      "\n",
      "epoch-74 accuracy check\n",
      "k_means origin feature average accuracy : 82.24955320%, total [0.9746727376209448, 0.9733106189664963, 0.9700891573195284, 0.9530800230282096, 0.943108504398827, 0.9150568181818182, 0.801817648783348, 0.6625070901871809, 0.9488619568430388, 0.822215777262181, 0.5866935483870968, 0.5005858230814294, 0.9429250891795482, 0.8922588099364529, 0.673546511627907, 0.5991983967935872]\n",
      "kmeans average accuracy best : 91.98%, kmeans average accuracy : 91.81811260%, total [0.9763801935116676, 0.978137421919364, 0.9749784296807593, 0.9648819804260219, 0.9609970674486803, 0.9556818181818182, 0.9258282028730578, 0.8519568916619399, 0.9674844812296778, 0.9280742459396751, 0.836405529953917, 0.773286467486819, 0.9598692033293698, 0.9428076256499134, 0.8790697674418605, 0.8150586888061838]\n",
      "cluster_accuracy_post_training_cycle_all_dataset : [0.97918638 0.97879359 0.97496389 0.96721311 0.96517413 0.95141509\n",
      " 0.93088016 0.85183443 0.9404942  0.93554688 0.82046332 0.76762661\n",
      " 0.95977597 0.93501455 0.88137255 0.82035356]\n",
      "mean_cluster_accuracy_during_training_cycle : 90.92%, post_traincycle_acc : 91.63%, total_acc : 91.33970975%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 91.77%\n",
      "accuracy_check 실행 시간: 25.797초\n",
      "\n",
      "\n",
      "epoch-75 loss : 0.00614940, loss_normal : 0.00996304, loss_coarse : 0.04310209, min_loss : 0.00612790, min_loss_normal : 0.00996093, min_loss_coarse : 0.04303891, wrong_element_sum : 8275602.00000000, same_data : 0.00%\n",
      "ae train 실행 시간: 114.976초, 전체 시작 시간 20250314_000324_593\n",
      "\n",
      "epoch-75 accuracy check\n",
      "k_means origin feature average accuracy : 82.26035621%, total [0.9746727376209448, 0.9733106189664963, 0.9700891573195284, 0.9530800230282096, 0.943108504398827, 0.9150568181818182, 0.8015244796247435, 0.6625070901871809, 0.9488619568430388, 0.822215777262181, 0.5866935483870968, 0.5005858230814294, 0.9429250891795482, 0.8922588099364529, 0.6747093023255814, 0.6000572573718866]\n",
      "kmeans average accuracy best : 91.98%, kmeans average accuracy : 91.70157729%, total [0.9760956175298805, 0.9778534923339012, 0.9741156169111302, 0.9640184225676454, 0.9621700879765396, 0.9559659090909091, 0.9272940486660803, 0.8570618264322178, 0.9668932899793083, 0.9280742459396751, 0.8317972350230415, 0.7662565905096661, 0.9577883472057075, 0.9393414211438474, 0.877906976744186, 0.8096192384769539]\n",
      "cluster_accuracy_post_training_cycle_all_dataset : [0.97871334 0.97785108 0.97496389 0.96576663 0.9641791  0.95188679\n",
      " 0.93088016 0.8565381  0.94906707 0.93652344 0.81805019 0.76713009\n",
      " 0.9592668  0.93743938 0.87843137 0.81653129]\n",
      "mean_cluster_accuracy_during_training_cycle : 91.06%, post_traincycle_acc : 91.65%, total_acc : 91.40811046%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 91.77%\n",
      "accuracy_check 실행 시간: 29.354초\n",
      "\n",
      "\n",
      "epoch-76 loss : 0.00613318, loss_normal : 0.00995677, loss_coarse : 0.04305913, min_loss : 0.00612790, min_loss_normal : 0.00995677, min_loss_coarse : 0.04303891, wrong_element_sum : 8267354.00000000, same_data : 0.00%\n",
      "ae train 실행 시간: 120.196초, 전체 시작 시간 20250314_000324_593\n",
      "\n",
      "epoch-76 accuracy check\n",
      "k_means origin feature average accuracy : 82.25674876%, total [0.9746727376209448, 0.9733106189664963, 0.9700891573195284, 0.9530800230282096, 0.943108504398827, 0.9150568181818182, 0.801817648783348, 0.6622234826999432, 0.9488619568430388, 0.822215777262181, 0.5872695852534562, 0.5005858230814294, 0.9429250891795482, 0.8922588099364529, 0.673546511627907, 0.6000572573718866]\n",
      "kmeans average accuracy best : 91.98%, kmeans average accuracy : 91.64085644%, total [0.9763801935116676, 0.978137421919364, 0.9746908254242163, 0.9648819804260219, 0.9612903225806452, 0.9559659090909091, 0.9267077103488713, 0.8499716392512763, 0.966006503103754, 0.9251740139211136, 0.8251728110599078, 0.7639132981839485, 0.9604637336504162, 0.9430964760254188, 0.8784883720930232, 0.8121958202118523]\n",
      "cluster_accuracy_post_training_cycle_all_dataset : [0.97918638 0.97879359 0.97496389 0.96624879 0.9641791  0.95235849\n",
      " 0.92789657 0.84760113 0.95007564 0.93505859 0.80936293 0.75670308\n",
      " 0.96232179 0.93549952 0.87990196 0.81939799]\n",
      "mean_cluster_accuracy_during_training_cycle : 90.76%, post_traincycle_acc : 91.50%, total_acc : 91.19571258%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 91.77%\n",
      "accuracy_check 실행 시간: 27.068초\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "gpu = '3'\n",
    "Conv_net = True # True False\n",
    "SAE_net = True # True False\n",
    "\n",
    "# hyperparameter\n",
    "dataset_num = 16\n",
    "spike_length = 50 # coarse_com_mode일 때는 time step이 됨.\n",
    "num_cluster = 4  # 클러스터 수 설정 # 논문엔 4개라는데 여기서는 3개로 했네\n",
    "training_cycle = 1400 #1400 2400 # 그 초기 몇개까지만 cluster update할지\n",
    "\n",
    "\n",
    "batch_size = 32\n",
    "max_epoch = 10000\n",
    "learning_rate = 0.001\n",
    "normalize_on = True # True or False # 0부터1까지 normalize\n",
    "need_bias = False\n",
    "# first_layer_no_train = False\n",
    "lif_add_at_first = False\n",
    "my_seed = 42\n",
    "\n",
    "TIME = 50 # SAE일 때만 유효. coarse_com_mode일 때는 level_num이 됨. 즉 feature 개수.\n",
    "v_decay = 0.5 # -cor\n",
    "v_threshold = 0.25 # -cor\n",
    "v_reset = 0.0 # -cor # 10000이상 일 시 hard reset\n",
    "BPTT_on = True # +cor # True False\n",
    "\n",
    "SAE_hidden_nomean = True # True False\n",
    "\n",
    "current_time = datetime.datetime.now().strftime(\"%Y%m%d_%H%M%S\") + f\"_{str(int(datetime.datetime.now().microsecond / 1000)).zfill(3)}\"\n",
    "\n",
    "optimizer = 'Adam' #'Adam', 'SGD' # 둘다 준수함. loss 줄이는 거는 adam이 좋긴한데, cluster accuracy는 비슷함.\n",
    "\n",
    "coarse_com_mode = True # True False\n",
    "coarse_com_config = (0.999, -0.0) # (max, min) (0.999, -0.0) (1.0, -0.0) (2.0, -2.0) (3.0, -3.0)\n",
    "\n",
    "sae_l2_norm_bridge = True # True False\n",
    "sae_lif_bridge = False # True False\n",
    "\n",
    "accuracy_check_epoch_term = 1\n",
    "\n",
    "lif_add_at_last = False # True False\n",
    "\n",
    "two_channel_input = False # True False\n",
    "\n",
    "lateral_feature_num = 8\n",
    "\n",
    "lc_adc_on = False # True False\n",
    "\n",
    "converted_net_forward = False # True False\n",
    "\n",
    "pretrained_net = None\n",
    "# pretrained_net = '/home/bhkim003/github_folder/ByeonghyeonKim/my_snn/net_save/save_now_net_중요_20250110_203117_390.pth'\n",
    "# pretrained_net = '/home/bhkim003/github_folder/ByeonghyeonKim/my_snn/net_save/save_now_net_중요_20250113_134126_881_이거_94나오는거.pth'\n",
    "# pretrained_net =  '/home/bhkim003/github_folder/ByeonghyeonKim/my_snn/net_save/save_now_net_20250205_184901_132.pth'\n",
    "# pretrained_net =  '/home/bhkim003/github_folder/ByeonghyeonKim/my_snn/net_save/save_now_net_20250306_134219_133.pth'\n",
    "\n",
    "vth_mul_on = False # True False\n",
    "batch_norm_on = False # True False\n",
    "\n",
    "l2_norm_loss_weight = 0 #0.0001 #0.1 #  0 # 0초과면 작동\n",
    "\n",
    "QCFS_neuron_on = False # True False\n",
    "\n",
    "quantize_level_num = 0 # 0이면 quantize 안함. 1이상이면 그 수만큼 quantize함. # normalize_on 켜져야됨. 음수면 0~1norm안하고 quant함\n",
    "\n",
    "fusion_net = True # True False # SAE_net False, Conv_net True로 해라. TIME 적절하게 설정해주고.\n",
    "repeat_coding = False # True False #fusion_net에서 쓰이는 거임 # True면 repeat, False면 rate coding.\n",
    "\n",
    "sae_relu_on = False # True False\n",
    "\n",
    "conv1d_scaling = False # True False # conv1d때매 norm하고 (level_num-3)/level_num 곱해줌 # Conv_net and coarse_com_mode and normalize_on\n",
    "\n",
    "norm01 = True # True False # normalize_on = True일 때 01norm하는지 아님 걍 quant만 하는지.\n",
    "\n",
    "wandb.init(project= f'spike_sorting just run',save_code=False)\n",
    "\n",
    "\n",
    "cluster_train_system( \n",
    "    gpu = gpu,\n",
    "    Conv_net = Conv_net,\n",
    "    SAE_net = SAE_net,\n",
    "\n",
    "    # hyperparameter\n",
    "    dataset_num = dataset_num,\n",
    "    spike_length = spike_length,\n",
    "    num_cluster = num_cluster,  # 클러스터 수 설정 # 논문엔 4개라는데 여기서는 3개로 했네\n",
    "    training_cycle = training_cycle, # 그 초기 몇개까지만 cluster update할지\n",
    "\n",
    "\n",
    "    batch_size = batch_size,\n",
    "    max_epoch = max_epoch,\n",
    "    learning_rate = learning_rate,\n",
    "    normalize_on = normalize_on, # True or False #이거 안 씀 # 이거 별로 안 좋은 normalize같음 # 쓸 거면 다른 거 써라.\n",
    "    need_bias = need_bias,\n",
    "    # first_layer_no_train = False\n",
    "    lif_add_at_first = lif_add_at_first,\n",
    "    my_seed = my_seed,\n",
    "\n",
    "    TIME = TIME, # SAE일 때만 유효\n",
    "    v_decay = v_decay,\n",
    "    v_threshold = v_threshold,\n",
    "    v_reset = v_reset, # 10000이상 일 시 hard reset\n",
    "    BPTT_on = BPTT_on,\n",
    "\n",
    "    SAE_hidden_nomean = SAE_hidden_nomean,\n",
    "    \n",
    "    current_time = current_time,\n",
    "\n",
    "    optimizer = optimizer, #'Adam', 'SGD'\n",
    "\n",
    "    coarse_com_mode = coarse_com_mode,\n",
    "    coarse_com_config = coarse_com_config, # (max, min)\n",
    "\n",
    "    \n",
    "    sae_l2_norm_bridge = sae_l2_norm_bridge,\n",
    "    sae_lif_bridge = sae_lif_bridge,\n",
    "\n",
    "    accuracy_check_epoch_term = accuracy_check_epoch_term,\n",
    "    \n",
    "    lif_add_at_last = lif_add_at_last,\n",
    "\n",
    "    two_channel_input = two_channel_input,\n",
    "\n",
    "    lateral_feature_num = lateral_feature_num,\n",
    "\n",
    "    lc_adc_on = lc_adc_on, \n",
    "\n",
    "    converted_net_forward = converted_net_forward,\n",
    "\n",
    "    pretrained_net = pretrained_net,\n",
    "\n",
    "    vth_mul_on = vth_mul_on,\n",
    "    batch_norm_on = batch_norm_on,\n",
    "\n",
    "    l2_norm_loss_weight = l2_norm_loss_weight,\n",
    "    \n",
    "    QCFS_neuron_on = QCFS_neuron_on, # True False\n",
    "\n",
    "    quantize_level_num = quantize_level_num,\n",
    "\n",
    "    fusion_net = fusion_net, # True False\n",
    "    repeat_coding = repeat_coding,\n",
    "\n",
    "    sae_relu_on = sae_relu_on,\n",
    "\n",
    "    conv1d_scaling = conv1d_scaling,\n",
    "\n",
    "    norm01 = norm01,\n",
    "\n",
    "    )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Sweep code\n",
    "\n",
    "\n",
    "# from unittest import TextTestRunner\n",
    "\n",
    "\n",
    "# unique_name_hyper = 'cluster_train_system'\n",
    "# # run_name = 'spike_sorting'\n",
    "# sweep_start_time =  datetime.datetime.now().strftime(\"%Y%m%d_%H%M%S\") + f\"_{str(int(datetime.datetime.now().microsecond / 1000)).zfill(3)}\"\n",
    "# sweep_configuration = {\n",
    "#     'method': 'bayes', # 'random', 'bayes'\n",
    "#     'name': f'spike_sorting_{sweep_start_time}',\n",
    "#     'metric': {'goal': 'maximize', 'name': 'k_means_acc_best'},\n",
    "#     'parameters': \n",
    "#     {\n",
    "#         # \"gpu\": {\"values\": ['1']},  # 이건 sweep parameter아님. hyper_iter에서 직접 설정\n",
    "#         \"Conv_net\": {\"values\": [True]}, \n",
    "#         \"SAE_net\": {\"values\": [True]}, \n",
    "\n",
    "#         \"dataset_num\": {\"values\": [16]}, \n",
    "#         \"spike_length\": {\"values\": [50]},  \n",
    "#         \"num_cluster\": {\"values\": [4]}, \n",
    "#         \"training_cycle\": {\"values\": [1400]}, # [1400, 2400]\n",
    "\n",
    "#         \"batch_size\": {\"values\": [32]}, \n",
    "#         \"max_epoch\": {\"values\": [20]}, \n",
    "#         \"learning_rate\": {\"values\": [0.001, 0.0001]},\n",
    "#         \"normalize_on\": {\"values\": [True]},\n",
    "#         \"need_bias\": {\"values\": [False]}, # [True, False]\n",
    "\n",
    "#         \"lif_add_at_first\": {\"values\": [False]}, # [True, False]\n",
    "#         \"my_seed\": {\"values\": [42]}, \n",
    "\n",
    "#         \"TIME\": {\"values\": [50]}, #  [4,6,8,10]\n",
    "#         \"v_decay\": {\"values\": [0.125, 0.25,0.50,0.75,1.0]}, # [0.25,0.50,0.75]\n",
    "#         \"v_threshold\": {\"values\": [0.125, 0.25, 0.50, 0.75, 0.875, 1.0]}, # [0.25,0.50,0.75]\n",
    "#         \"v_reset\": {\"values\": [0.0, 10000.0]},  # [0.0, 10000.0]\n",
    "#         \"BPTT_on\": {\"values\": [True, False]},  # [True, False]\n",
    "\n",
    "#         \"SAE_hidden_nomean\": {\"values\": [True]}, # [True, False]\n",
    "\n",
    "#         # \"current_time\": {\"values\": [current_time]} #밑에서 직접설정됨.\n",
    "\n",
    "#         \"optimizer\": {\"values\": ['Adam', 'SGD']}, # ['Adam', 'SGD']\n",
    "\n",
    "#         \"coarse_com_mode\": {\"values\": [True]}, # [True, False]\n",
    "#         \"coarse_com_config\": {\"values\": [(0.999, -0.0)]}, # ['Adam', 'SGD']\n",
    "\n",
    "#         \"sae_l2_norm_bridge\": {\"values\": [True]}, # [True, False]\n",
    "#         \"sae_lif_bridge\": {\"values\": [False]}, # [False, True]\n",
    "        \n",
    "#         \"accuracy_check_epoch_term\": {\"values\": [1]}, \n",
    "\n",
    "#         \"lif_add_at_last\": {\"values\": [False]},# [True, False]\n",
    "\n",
    "#         \"two_channel_input\": {\"values\": [False]},# [True, False]\n",
    "\n",
    "#         \"lateral_feature_num\": {\"values\": [4]},# [True, False]\n",
    "\n",
    "#         \"lc_adc_on\": {\"values\": [False]},# [True, False]\n",
    "        \n",
    "#         \"converted_net_forward\": {\"values\": [False]},# [True, False]\n",
    "\n",
    "#         \"pretrained_net\": {\"values\": [None]},# [None]\n",
    "\n",
    "#         \"vth_mul_on\": {\"values\": [False]},# [True, False]\n",
    "#         \"batch_norm_on\": {\"values\": [False]},# [True, False]\n",
    "\n",
    "#         \"l2_norm_loss_weight\": {\"values\": [0]},\n",
    "\n",
    "#         \"QCFS_neuron_on\": {\"values\": [False]},   # [True, False]\n",
    "\n",
    "#         \"quantize_level_num\": {\"values\": [0]}, \n",
    "\n",
    "#         \"fusion_net\": {\"values\": [True]}, \n",
    "#         \"repeat_coding\": {\"values\": [False]}, \n",
    "\n",
    "#         \"sae_relu_on\": {\"values\": [False]}, \n",
    "\n",
    "#         \"conv1d_scaling\": {\"values\": [False]}, \n",
    "\n",
    "#         \"norm01\": {\"values\": [True]}, \n",
    "#      }\n",
    "# }\n",
    "\n",
    "\n",
    "# def hyper_iter():\n",
    "#     ### my_snn control board ########################\n",
    "#     wandb.init(save_code = False)\n",
    "#     gpu  =  '2'\n",
    "#     Conv_net  =  wandb.config.Conv_net\n",
    "#     SAE_net  =  wandb.config.SAE_net\n",
    "\n",
    "#     dataset_num  =  wandb.config.dataset_num\n",
    "#     spike_length  =  wandb.config.spike_length\n",
    "#     num_cluster  =  wandb.config.num_cluster\n",
    "#     training_cycle  =  wandb.config.training_cycle\n",
    "\n",
    "#     batch_size  =  wandb.config.batch_size\n",
    "#     max_epoch  =  wandb.config.max_epoch\n",
    "#     learning_rate  =  wandb.config.learning_rate\n",
    "#     normalize_on  =  wandb.config.normalize_on\n",
    "#     need_bias  =  wandb.config.need_bias\n",
    "\n",
    "#     lif_add_at_first  =  wandb.config.lif_add_at_first\n",
    "#     my_seed  =  wandb.config.my_seed\n",
    "\n",
    "\n",
    "#     TIME  =  wandb.config.TIME\n",
    "#     v_decay  =  wandb.config.v_decay\n",
    "#     v_threshold  =  wandb.config.v_threshold\n",
    "#     v_reset  =  wandb.config.v_reset\n",
    "#     BPTT_on  =  wandb.config.BPTT_on\n",
    "\n",
    "#     SAE_hidden_nomean  =  wandb.config.SAE_hidden_nomean\n",
    "    \n",
    "#     current_time =  datetime.datetime.now().strftime(\"%Y%m%d_%H%M%S\") + f\"_{str(int(datetime.datetime.now().microsecond / 1000)).zfill(3)}\"\n",
    "\n",
    "#     optimizer  =  wandb.config.optimizer\n",
    "\n",
    "#     coarse_com_mode = wandb.config.coarse_com_mode\n",
    "#     coarse_com_config = wandb.config.coarse_com_config # (max, min)\n",
    "\n",
    "#     sae_l2_norm_bridge = wandb.config.sae_l2_norm_bridge\n",
    "#     sae_lif_bridge = wandb.config.sae_lif_bridge\n",
    "\n",
    "#     accuracy_check_epoch_term = wandb.config.accuracy_check_epoch_term\n",
    "\n",
    "#     lif_add_at_last = wandb.config.lif_add_at_last\n",
    "\n",
    "#     two_channel_input = wandb.config.two_channel_input\n",
    "\n",
    "#     lateral_feature_num = wandb.config.lateral_feature_num\n",
    "\n",
    "#     lc_adc_on = wandb.config.lc_adc_on\n",
    "\n",
    "#     converted_net_forward = wandb.config.converted_net_forward\n",
    "\n",
    "#     pretrained_net = wandb.config.pretrained_net\n",
    "\n",
    "#     vth_mul_on = wandb.config.vth_mul_on\n",
    "#     batch_norm_on = wandb.config.batch_norm_on\n",
    "\n",
    "#     l2_norm_loss_weight = wandb.config.l2_norm_loss_weight\n",
    "\n",
    "#     QCFS_neuron_on = wandb.config.QCFS_neuron_on\n",
    "\n",
    "#     quantize_level_num = wandb.config.quantize_level_num\n",
    "\n",
    "#     fusion_net = wandb.config.fusion_net\n",
    "#     repeat_coding = wandb.config.repeat_coding\n",
    "\n",
    "#     sae_relu_on = wandb.config.sae_relu_on\n",
    "\n",
    "#     conv1d_scaling = wandb.config.conv1d_scaling\n",
    "\n",
    "#     norm01 = wandb.config.norm01\n",
    "\n",
    "#     cluster_train_system( \n",
    "#         gpu = gpu,\n",
    "#         Conv_net = Conv_net,\n",
    "#         SAE_net = SAE_net,\n",
    "\n",
    "#         # hyperparameter\n",
    "#         dataset_num = dataset_num,\n",
    "#         spike_length = spike_length,\n",
    "#         num_cluster = num_cluster,  # 클러스터 수 설정 # 논문엔 4개라는데 여기서는 3개로 했네\n",
    "#         training_cycle = training_cycle, # 그 초기 몇개까지만 cluster update할지\n",
    "\n",
    "\n",
    "#         batch_size = batch_size,\n",
    "#         max_epoch = max_epoch,\n",
    "#         learning_rate = learning_rate,\n",
    "#         normalize_on = normalize_on, # True or False #이거 안 씀 # 이거 별로 안 좋은 normalize같음 # 쓸 거면 다른 거 써라.\n",
    "#         need_bias = need_bias,\n",
    "#         # first_layer_no_train = False\n",
    "#         lif_add_at_first = lif_add_at_first,\n",
    "#         my_seed = my_seed,\n",
    "\n",
    "#         TIME = TIME, # SAE일 때만 유효\n",
    "#         v_decay = v_decay,\n",
    "#         v_threshold = v_threshold,\n",
    "#         v_reset = v_reset, # 10000이상 일 시 hard reset\n",
    "#         BPTT_on = BPTT_on,\n",
    "\n",
    "#         SAE_hidden_nomean = SAE_hidden_nomean,\n",
    "\n",
    "#         current_time = current_time,\n",
    "\n",
    "#         optimizer = optimizer, #'Adam', 'SGD'\n",
    "\n",
    "#         coarse_com_mode = coarse_com_mode,\n",
    "#         coarse_com_config = coarse_com_config, # (max, min)\n",
    "        \n",
    "#         sae_l2_norm_bridge = sae_l2_norm_bridge,\n",
    "#         sae_lif_bridge = sae_lif_bridge,\n",
    "\n",
    "#         accuracy_check_epoch_term = accuracy_check_epoch_term,\n",
    "\n",
    "#         lif_add_at_last = lif_add_at_last,\n",
    "        \n",
    "#         two_channel_input = two_channel_input,\n",
    "        \n",
    "#         lateral_feature_num = lateral_feature_num,\n",
    "\n",
    "#         lc_adc_on = lc_adc_on,\n",
    "\n",
    "#         converted_net_forward = converted_net_forward,\n",
    "\n",
    "#         pretrained_net = pretrained_net,\n",
    "\n",
    "#         vth_mul_on = vth_mul_on,\n",
    "#         batch_norm_on = batch_norm_on,\n",
    "\n",
    "#         l2_norm_loss_weight = l2_norm_loss_weight,\n",
    "\n",
    "#         QCFS_neuron_on = QCFS_neuron_on,\n",
    "\n",
    "#         quantize_level_num = quantize_level_num,\n",
    "\n",
    "#         fusion_net = fusion_net, \n",
    "#         repeat_coding = repeat_coding, \n",
    "\n",
    "#         sae_relu_on = sae_relu_on,\n",
    "\n",
    "#         conv1d_scaling = conv1d_scaling,\n",
    "\n",
    "#         norm01 = norm01,\n",
    "#         )\n",
    "    \n",
    "# # sweep_id = 'ygoj9jt4'\n",
    "# sweep_id = wandb.sweep(sweep=sweep_configuration, project=f'spike_sorting {unique_name_hyper}')\n",
    "# wandb.agent(sweep_id, function=hyper_iter, count=100000, project=f'spike_sorting {unique_name_hyper}')\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wandb.finish() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import matplotlib.pyplot as plt\n",
    "# from matplotlib.ticker import MaxNLocator\n",
    "# import pickle\n",
    "# import json\n",
    "\n",
    "# # current_time = '20250102_225243_972'\n",
    "\n",
    "# with open(f\"result_save/cluster_accuracy_history_{current_time}.pkl\", \"rb\") as f:\n",
    "#     data = pickle.load(f)\n",
    "\n",
    "\n",
    "# # JSON으로 저장\n",
    "# with open(f\"result_save/cluster_accuracy_history_{current_time}.json\", 'r') as f:\n",
    "#     loaded_hyperparameters = json.load(f)\n",
    "\n",
    "# loss_history = data['loss_history']\n",
    "# mean_cluster_accuracy_during_training_cycle_all_dataset_history = data['mean_cluster_accuracy_during_training_cycle_all_dataset_history']\n",
    "# mean_cluster_accuracy_post_training_cycle_all_dataset_history = data['mean_cluster_accuracy_post_training_cycle_all_dataset_history']\n",
    "# mean_cluster_accuracy_total_all_dataset_history = data['mean_cluster_accuracy_total_all_dataset_history']\n",
    "# print(data)\n",
    "# max_acc = 0\n",
    "# for i in mean_cluster_accuracy_post_training_cycle_all_dataset_history:\n",
    "#     if i[1] > max_acc:\n",
    "#         max_acc = i[1]\n",
    "\n",
    "# # 설정 정보 제목 작성\n",
    "# title = (\n",
    "#     f\"Dataset Num: {loaded_hyperparameters['dataset_num']}, Conv {loaded_hyperparameters['Conv_net']}, SAE {loaded_hyperparameters['SAE_net']}, Current time {loaded_hyperparameters['current_time']}, Spike Length: {loaded_hyperparameters['spike_length']}, Num Cluster: {loaded_hyperparameters['num_cluster']}, \"\n",
    "#     f\"Training Cycle: {loaded_hyperparameters['training_cycle']}, Batch Size: {loaded_hyperparameters['batch_size']}, Max Epoch: {loaded_hyperparameters['max_epoch']}, \\n\"\n",
    "#     f\"Learning Rate: {loaded_hyperparameters['learning_rate']}, Input Normalize: {loaded_hyperparameters['normalize_on']}, Need Bias: {loaded_hyperparameters['need_bias']}, \"\n",
    "#     f\"LIF Add at First: {loaded_hyperparameters['lif_add_at_first']}, TIME: {loaded_hyperparameters['TIME']}, Seed: {loaded_hyperparameters['my_seed']}, Best ACC: {max_acc:.2f}%\"\n",
    "# )\n",
    "\n",
    "# # 데이터 리스트와 라벨 설정 (Loss 제외)\n",
    "# data_list = [\n",
    "#     (\"Mean Cluster Accuracy (During Training Cycle)\", mean_cluster_accuracy_during_training_cycle_all_dataset_history),\n",
    "#     (\"Mean Cluster Accuracy (Post Training Cycle)\", mean_cluster_accuracy_post_training_cycle_all_dataset_history),\n",
    "#     (\"Mean Cluster Accuracy (Total)\", mean_cluster_accuracy_total_all_dataset_history),\n",
    "# ]\n",
    "\n",
    "# # 플롯 생성\n",
    "# fig, ax1 = plt.subplots(figsize=(12, 8))\n",
    "\n",
    "# # 첫 번째 y축: Accuracy 관련 데이터\n",
    "# for label, data in data_list:\n",
    "#     epochs, values = zip(*data)  # epoch, value 분리\n",
    "#     ax1.plot(epochs, values, label=label)\n",
    "\n",
    "# ax1.set_xlabel(\"Epoch\")\n",
    "# ax1.set_ylabel(\"Clurstering Accuracy [%]\", color=\"blue\")\n",
    "# ax1.tick_params(axis=\"y\", labelcolor=\"blue\")\n",
    "# ax1.legend(loc=\"center right\")\n",
    "# ax1.grid(True)\n",
    "\n",
    "# # x축을 정수만 표시하도록 설정\n",
    "# ax1.xaxis.set_major_locator(MaxNLocator(integer=True))\n",
    "\n",
    "# # 두 번째 y축: Loss History\n",
    "# ax2 = ax1.twinx()\n",
    "# epochs, values = zip(*loss_history)\n",
    "# ax2.plot(epochs, values, label=\"AE Loss History\", color=\"red\", linestyle=\"--\")\n",
    "# ax2.set_ylabel(\"Loss\", color=\"red\")\n",
    "# ax2.tick_params(axis=\"y\", labelcolor=\"red\")\n",
    "# ax2.legend(loc=\"center left\")\n",
    "\n",
    "# # 제목 추가\n",
    "# plt.title(title, fontsize=10)\n",
    "# plt.tight_layout()\n",
    "# plt.savefig(f'net_save/{current_time}', dpi=300, bbox_inches=\"tight\")  # dpi=300은 고해상도로 저장, bbox_inches=\"tight\"는 여백 최소화\n",
    "# plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# 데이터셋\n",
    "filename_for_plot = [\n",
    "    \"Easy1_noise05\", \"Easy1_noise10\", \"Easy1_noise15\", \"Easy1_noise20\",\n",
    "    \"Easy2_noise05\", \"Easy2_noise10\", \"Easy2_noise15\", \"Easy2_noise20\",\n",
    "    \"Difficult1_noise05\", \"Difficult1_noise10\", \"Difficult1_noise15\", \"Difficult1_noise20\",\n",
    "    \"Difficult2_noise05\", \"Difficult2_noise10\", \"Difficult2_noise15\", \"Difficult2_noise20\"\n",
    "]\n",
    "\n",
    "# Accuracy 데이터\n",
    "ANN_conv_accracy_set= [0.97935368, 0.97682709, 0.97028784, 0.96461825, 0.97524752, 0.95803571\n",
    ", 0.95746785, 0.92628774, 0.965412,  0.97805344, 0.94869403, 0.92110454\n",
    ", 0.96784232, 0.97551789, 0.91538462, 0.84446478]\n",
    "SNN_fc_accuracy_set = [0.97114475, 0.97643732, 0.84400578, 0.78977821, 0.96616915, 0.92830189\n",
    ", 0.86176032, 0.31984948, 0.80635401, 0.88769531, 0.61003861, 0.60377358\n",
    ", 0.9592668,  0.92870999, 0.78333333, 0.67271859]\n",
    "SNN_conv_accuracy_set = [0.97445601, 0.97737983, 0.97063072, 0.95998071, 0.96268657, 0.90566038\n",
    ", 0.82545997, 0.68391345, 0.96116994, 0.92138672, 0.80694981, 0.49602781\n",
    ", 0.83604888, 0.70611057, 0.69313725, 0.5819398 ]\n",
    "\n",
    "# 평균 계산\n",
    "average_ANN_conv = np.mean(ANN_conv_accracy_set)\n",
    "average_SNN_fc = np.mean(SNN_fc_accuracy_set)\n",
    "average_SNN_conv = np.mean(SNN_conv_accuracy_set)\n",
    "\n",
    "# 데이터 준비\n",
    "accuracies = np.array([ANN_conv_accracy_set, SNN_fc_accuracy_set, SNN_conv_accuracy_set])\n",
    "averages = np.array([average_ANN_conv, average_SNN_fc, average_SNN_conv])\n",
    "\n",
    "# 시각화\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "\n",
    "# 각 모델의 정확도 플롯\n",
    "ax.plot(accuracies[0], label='ANN Conv', marker='o', linestyle='-', color='blue')\n",
    "ax.plot(accuracies[1], label='SNN FC', marker='o', linestyle='-', color='green')\n",
    "ax.plot(accuracies[2], label='SNN Conv', marker='o', linestyle='-', color='red')\n",
    "\n",
    "# 평균값 플롯\n",
    "ax.axhline(y=average_ANN_conv, color='blue', linestyle='--', label=f'Average ANN Conv: {average_ANN_conv:.3f}')\n",
    "ax.axhline(y=average_SNN_fc, color='green', linestyle='--', label=f'Average SNN FC: {average_SNN_fc:.3f}')\n",
    "ax.axhline(y=average_SNN_conv, color='red', linestyle='--', label=f'Average SNN Conv: {average_SNN_conv:.3f}')\n",
    "\n",
    "# 레이블 추가\n",
    "ax.set_xticks(np.arange(len(filename_for_plot)))\n",
    "ax.set_xticklabels(filename_for_plot, rotation=45, ha='right')\n",
    "ax.set_ylabel('Accuracy')\n",
    "ax.set_title('Accuracy Comparison of Models on Datasets')\n",
    "ax.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import matplotlib.pyplot as plt\n",
    "import os  # 파일 경로 처리를 위한 모듈\n",
    "\n",
    "# CSV 파일 경로\n",
    "# csv_file_path = \"/home/bhkim003/github_folder/ByeonghyeonKim/my_snn/ae_test_deprecated/250115/sweep0_vth_mul.csv\" # vth_mul해서 sweep 돌린거\n",
    "csv_file_path = \"/home/bhkim003/github_folder/ByeonghyeonKim/my_snn/ae_test_deprecated/250115/sweep1.csv\"  #vth_mul안한거\n",
    "\n",
    "# 결과를 저장할 리스트\n",
    "tuple_list = []\n",
    "\n",
    "# CSV 파일 읽기\n",
    "with open(csv_file_path, 'r') as file:\n",
    "    reader = csv.DictReader(file)\n",
    "    for row in reader:\n",
    "        try:\n",
    "            # v_threshold, TIME, v_reset, converted_k_means_acc 값을 가져와 튜플로 변환\n",
    "            v_threshold = float(row[\"v_threshold\"])\n",
    "            time = int(row[\"TIME\"])\n",
    "            v_reset = int(row[\"v_reset\"])\n",
    "            converted_k_means_acc = float(row[\"converted_k_means_acc\"]) if row[\"converted_k_means_acc\"] else None\n",
    "\n",
    "            # 튜플 형태로 추가 (값이 None일 경우 처리할 수도 있음)\n",
    "            tuple_list.append((v_threshold, time, v_reset, converted_k_means_acc))\n",
    "        except ValueError as e:\n",
    "            print(f\"Error processing row {row}: {e}\")\n",
    "\n",
    "# 데이터를 TIME 기준으로 정렬\n",
    "tuple_list.sort(key=lambda x: x[1])  # TIME을 기준으로 오름차순 정렬\n",
    "\n",
    "# reset 방식에 따라 데이터를 나누기\n",
    "soft_reset = [t for t in tuple_list if t[2] == 0]\n",
    "hard_reset = [t for t in tuple_list if t[2] == 10000]\n",
    "\n",
    "# reset 방식과 v_threshold에 따라 색상 설정\n",
    "def plot_data(data, label_prefix, marker):\n",
    "    for v_threshold in [1.0]:  # v_threshold 기준으로 제한\n",
    "        filtered_data = [(t[1], t[3]) for t in data if t[0] == v_threshold]\n",
    "        if filtered_data:  # 해당 v_threshold 데이터가 있을 경우만 플롯\n",
    "            times, accuracies = zip(*filtered_data)  # x축(TIME), y축(converted_k_means_acc)\n",
    "            \n",
    "            plt.plot(\n",
    "                times,\n",
    "                accuracies,\n",
    "                marker,\n",
    "                label=f\"{label_prefix}, v_threshold={v_threshold}\",\n",
    "                linestyle=\"--\",\n",
    "            )\n",
    "            # 각 점에 accuracy 표시\n",
    "            for time, acc in filtered_data:\n",
    "                if acc == None:\n",
    "                    continue\n",
    "                plt.text(time, acc, f\"{acc:.2f}\", fontsize=8, ha=\"right\")\n",
    "\n",
    "# 그래프 초기화\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "# soft_reset (v_reset=0) 데이터 플롯\n",
    "plot_data(soft_reset, \"Soft Reset\", \"o\")\n",
    "\n",
    "# hard_reset (v_reset=10000) 데이터 플롯\n",
    "plot_data(hard_reset, \"Hard Reset\", \"x\")\n",
    "\n",
    "# baseline accuracy 가로선 추가\n",
    "baseline_accuracy = 94.43\n",
    "plt.axhline(y=baseline_accuracy, color=\"red\", linestyle=\"-\", label=f\"Baseline Accuracy ({baseline_accuracy}%)\")\n",
    "# baseline 텍스트 추가\n",
    "plt.text(\n",
    "    2000,  # x축 위치 (그래프 오른쪽 끝)\n",
    "    baseline_accuracy + 0.4,  # y축 위치 (baseline 위 약간)\n",
    "    f\"ANN Baseline ({baseline_accuracy}%)\",\n",
    "    color=\"red\",\n",
    "    fontsize=10,\n",
    "    ha=\"center\",\n",
    ")\n",
    "\n",
    "# CSV 파일 이름 가져오기\n",
    "csv_file_name = os.path.basename(csv_file_path)\n",
    "\n",
    "# 그래프 세부 설정\n",
    "plt.title(f\"Converted SNN K-Means Accuracy vs TIME STEP - {csv_file_name}\")\n",
    "plt.xlabel(\"TIME STEP\")\n",
    "plt.ylabel(\"Converted K-Means Accuracy [%]\")\n",
    "plt.legend(loc=\"lower right\")  # 범례를 오른쪽 아래로 이동\n",
    "plt.grid(True)\n",
    "\n",
    "# 그래프 출력\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aedat2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
