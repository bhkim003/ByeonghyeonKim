{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ssp.train.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x600 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import torch   \n",
    "import torch.nn as nn \n",
    "import torch.nn.functional as F   \n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import torch.optim as optim\n",
    "from scipy import io\n",
    "import itertools\n",
    "import math\n",
    "import datetime\n",
    "import wandb\n",
    "import pickle\n",
    "import json\n",
    "import time\n",
    "import sys\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import accuracy_score\n",
    "from scipy.optimize import linear_sum_assignment\n",
    "from snntorch import spikegen\n",
    "\n",
    "\n",
    "# my module import\n",
    "from modules import *\n",
    "\n",
    "# modules 폴더에 새모듈.py 만들면\n",
    "# modules/__init__py 파일에 form .새모듈 import * 하셈\n",
    "# 그리고 새모듈.py에서 from modules.새모듈 import * 하셈"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cluster_train_system( \n",
    "    gpu = '4',\n",
    "    Conv_net = True,\n",
    "    SAE_net = True,\n",
    "\n",
    "    # hyperparameter\n",
    "    dataset_num = 16,\n",
    "    spike_length = 50,\n",
    "    num_cluster = 4,  # 클러스터 수 설정 # 논문엔 4개라는데 여기서는 3개로 했네\n",
    "    training_cycle = 2400, # 그 초기 몇개까지만 cluster update할지\n",
    "\n",
    "\n",
    "    batch_size = 32,\n",
    "    max_epoch = 7000,\n",
    "    learning_rate = 0.001,\n",
    "    normalize_on = False, # True or False #이거 안 씀 # 이거 별로 안 좋은 normalize같음 # 쓸 거면 다른 거 써라.\n",
    "    need_bias = False,\n",
    "    # first_layer_no_train = False\n",
    "    lif_add_at_first = False,\n",
    "    my_seed = 42,\n",
    "\n",
    "    TIME = 10, # SAE일 때만 유효\n",
    "    v_decay = 0.5,\n",
    "    v_threshold = 0.5,\n",
    "    v_reset = 10000.0, # 10000이상 일 시 hard reset\n",
    "    BPTT_on = True,\n",
    "\n",
    "    SAE_hidden_nomean = True,\n",
    "    current_time = '20250101_210938_786',\n",
    "\n",
    "    optimizer = 'Adam',\n",
    "    coarse_com_mode = True,\n",
    "    coarse_com_config = (2.0, -2.0), # (max, min)\n",
    "\n",
    "    sae_l2_norm_bridge = True,\n",
    "    sae_lif_bridge = False,\n",
    "\n",
    "    accuracy_check_epoch_term = 5,\n",
    "    \n",
    "    lif_add_at_last = False,\n",
    "\n",
    "    two_channel_input = False,\n",
    "\n",
    "    lateral_feature_num = 4,\n",
    "\n",
    "    lc_adc_on = False, \n",
    "\n",
    "    converted_net_forward = False,\n",
    "\n",
    "    pretrained_net = None, \n",
    "\n",
    "    vth_mul_on = False,\n",
    "    batch_norm_on = False,\n",
    "\n",
    "    l2_norm_loss_weight = 0.0,\n",
    "\n",
    "    QCFS_neuron_on = False,\n",
    "\n",
    "    quantize_level_num = 0,\n",
    "\n",
    "    fusion_net = False, # True False\n",
    "    repeat_coding = False,\n",
    "    \n",
    "    sae_relu_on = False,\n",
    "\n",
    "    conv1d_scaling = False,\n",
    "\n",
    "    norm01 = True,\n",
    "    ):\n",
    "    if coarse_com_mode == True:\n",
    "        assert coarse_com_config[0] > coarse_com_config[1], 'coarse_com_config[0] > coarse_com_config[1]이어야 함'\n",
    "        assert converted_net_forward == False\n",
    "        # assert SAE_net == True, 'coarse_com_mode는 SAE_net이 True일 때만 가능'\n",
    "    if two_channel_input == True:\n",
    "        assert Conv_net and coarse_com_mode, 'two_channel_input는 Conv_net이 True일 때만 가능'\n",
    "    if lc_adc_on == True:\n",
    "        assert coarse_com_mode and SAE_net, 'lc_adc_on은 coarse_com_mode와 SAE_net이 True일 때만 가능'\n",
    "    if converted_net_forward == True:\n",
    "        assert SAE_net == False, 'converted_net_forward는 SAE_net이 False일 때만 가능'\n",
    "    if conv1d_scaling:\n",
    "        assert Conv_net and coarse_com_mode and normalize_on\n",
    "    seed_assign(my_seed)\n",
    "    ## 함수 내 모든 로컬 변수 저장 ########################################################\n",
    "    hyperparameters = locals()\n",
    "    print(hyperparameters)\n",
    "    # JSON으로 저장\n",
    "    with open(f\"result_save/cluster_accuracy_history_{current_time}.json\", 'w') as f:\n",
    "        json.dump(hyperparameters, f, indent=4)\n",
    "    ######################################################################################\n",
    "\n",
    "    \n",
    "    wandb.config.update(hyperparameters)\n",
    "    wandb.run.name = f'{current_time}_SAE_net_{SAE_net}_v_threshold_{v_threshold}'\n",
    "    wandb.define_metric(\"best_mean_cluster_accuracy_post_training_cycle_all_dataset2\", summary=\"max\")\n",
    "\n",
    "\n",
    "    my_path_ground_BH = '/data2/spike_sorting/quiroga/BH/'\n",
    "\n",
    "\n",
    "    filename = [\"C_Easy1_noise005.mat\", \"C_Easy1_noise01.mat\", \"C_Easy1_noise015.mat\", \"C_Easy1_noise02.mat\",\n",
    "                \"C_Easy2_noise005.mat\", \"C_Easy2_noise01.mat\", \"C_Easy2_noise015.mat\", \"C_Easy2_noise02.mat\",\n",
    "                \"C_Difficult1_noise005.mat\", \"C_Difficult1_noise01.mat\", \"C_Difficult1_noise015.mat\", \"C_Difficult1_noise02.mat\",\n",
    "                \"C_Difficult2_noise005.mat\", \"C_Difficult2_noise01.mat\", \"C_Difficult2_noise015.mat\", \"C_Difficult2_noise02.mat\"]\n",
    "\n",
    "\n",
    "    spike_tot = [\"BH_Spike_e1n005.npy\", \"BH_Spike_e1n010.npy\", \"BH_Spike_e1n015.npy\", \"BH_Spike_e1n020.npy\",\n",
    "                \"BH_Spike_e2n005.npy\", \"BH_Spike_e2n010.npy\", \"BH_Spike_e2n015.npy\", \"BH_Spike_e2n020.npy\",\n",
    "                \"BH_Spike_d1n005.npy\", \"BH_Spike_d1n010.npy\", \"BH_Spike_d1n015.npy\", \"BH_Spike_d1n020.npy\",\n",
    "                \"BH_Spike_d2n005.npy\", \"BH_Spike_d2n010.npy\", \"BH_Spike_d2n015.npy\", \"BH_Spike_d2n020.npy\"]\n",
    "\n",
    "    label_tot = [\"BH_Label_e1n005.npy\", \"BH_Label_e1n010.npy\", \"BH_Label_e1n015.npy\", \"BH_Label_e1n020.npy\",\n",
    "                \"BH_Label_e2n005.npy\", \"BH_Label_e2n010.npy\", \"BH_Label_e2n015.npy\", \"BH_Label_e2n020.npy\",\n",
    "                \"BH_Label_d1n005.npy\", \"BH_Label_d1n010.npy\", \"BH_Label_d1n015.npy\", \"BH_Label_d1n020.npy\",\n",
    "                \"BH_Label_d2n005.npy\", \"BH_Label_d2n010.npy\", \"BH_Label_d2n015.npy\", \"BH_Label_d2n020.npy\"]\n",
    "\n",
    "    template =  [\"BH_Spike_TEMPLATE_e1n005.npy\", \"BH_Spike_TEMPLATE_e1n010.npy\", \"BH_Spike_TEMPLATE_e1n015.npy\", \"BH_Spike_TEMPLATE_e1n020.npy\",\n",
    "                \"BH_Spike_TEMPLATE_e2n005.npy\", \"BH_Spike_TEMPLATE_e2n010.npy\", \"BH_Spike_TEMPLATE_e2n015.npy\", \"BH_Spike_TEMPLATE_e2n020.npy\",\n",
    "                \"BH_Spike_TEMPLATE_d1n005.npy\", \"BH_Spike_TEMPLATE_d1n010.npy\", \"BH_Spike_TEMPLATE_d1n015.npy\", \"BH_Spike_TEMPLATE_d1n020.npy\",\n",
    "                \"BH_Spike_TEMPLATE_d2n005.npy\", \"BH_Spike_TEMPLATE_d2n010.npy\", \"BH_Spike_TEMPLATE_d2n015.npy\", \"BH_Spike_TEMPLATE_d2n020.npy\"]\n",
    "\n",
    "    AE_train_path_gt_detect = 'BH_quiroga_training_dataset_gt_detect.pt' \n",
    "    AE_test_path_gt_detect = 'BH_quiroga_test_dataset_gt_detect.pt'\n",
    "\n",
    "    AE_train_path_real_detect = 'BH_quiroga_training_dataset_real_detect.pt'\n",
    "    AE_test_path_real_detect = 'BH_quiroga_test_dataset_real_detect.pt'\n",
    "\n",
    "    AE_train_data = AE_train_path_real_detect #AE_train_path_gt_detect #AE_train_path_real_detect\n",
    "    AE_test_data = AE_test_path_real_detect #AE_test_path_gt_detect  #AE_test_path_real_detect\n",
    "\n",
    "    # thr_tot = np.array([0.5, 0.5, 0.55, 0.7, 0.5, 0.5, 0.55, 0.7, 0.5, 0.5, 0.55, 0.7, 0.5, 0.5, 0.55, 0.7])\n",
    "    cos_thr = np.array([0.95, 0.95, 0.95, 0.95, 0.95, 0.95, 0.95, 0.85, 0.95, 0.9, 0.8, 0.95, 0.95, 0.95, 0.95, 0.8])\n",
    "    # tem=10\n",
    "    # cos_thr = np.array([tem, tem, tem, tem, tem, tem, tem, tem, tem, tem, tem, tem, tem, tem, tem, tem, ])\n",
    "\n",
    "    print('cos_thr', cos_thr)\n",
    "    \n",
    "    os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\" \n",
    "    os.environ[\"CUDA_VISIBLE_DEVICES\"]= gpu\n",
    "\n",
    "\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "\n",
    "    if coarse_com_mode == True:\n",
    "        level_num = TIME\n",
    "        TIME = spike_length\n",
    "        spike_length = level_num\n",
    "        level_interval = (coarse_com_config[0] - coarse_com_config[1]) / (level_num-1)  # max - min\n",
    "        levels = [coarse_com_config[1] + level_interval * i for i in range(level_num)]\n",
    "        levels = torch.tensor(levels).to(torch.float).to(device)\n",
    "        levels = levels.repeat(TIME,1) \n",
    "        # print('levels', levels, levels.shape) # TIME, level_num\n",
    "\n",
    "    n_sample = spike_length\n",
    "\n",
    "    class spikedataset(Dataset):\n",
    "        def __init__(self, path, transform = None):    \n",
    "            self.transform = transform\n",
    "            self.spike = torch.load(path)\n",
    "            \n",
    "        def __getitem__(self, index):\n",
    "            spike = self.spike[index]            \n",
    "            if self.transform is not None:\n",
    "                spike = self.transform(spike)\n",
    "            return spike\n",
    "        \n",
    "        def __len__(self):\n",
    "            return len(self.spike)\n",
    "\n",
    "    train_dataset = spikedataset(my_path_ground_BH + AE_train_data)\n",
    "    train_loader = DataLoader(dataset = train_dataset, batch_size = batch_size, shuffle = True)\n",
    "\n",
    "    test_dataset = spikedataset(my_path_ground_BH + AE_test_data)\n",
    "    test_loader = DataLoader(dataset = test_dataset, batch_size = batch_size, shuffle = False)\n",
    "\n",
    "\n",
    "    # vth_mul_on = True # True False\n",
    "    # batch_norm_on = True # True False\n",
    "\n",
    "\n",
    "    # 모델 초기화\n",
    "    if SAE_net == False: # 여기서는 l2norm, lif bridge 둘 다 true면 l2norm먼저\n",
    "        assert two_channel_input == False\n",
    "\n",
    "        if Conv_net == True:\n",
    "            # input_channels = 2 if two_channel_input else 1\n",
    "            input_channels = TIME if coarse_com_mode else 1\n",
    "            if fusion_net == True:\n",
    "                assert False, '이거 맞음? 다시 확인'\n",
    "                net = FUSION_net_conv1(input_channels=input_channels, input_length=n_sample, encoder_ch = [32, 64, 96], fc_dim = lateral_feature_num, padding = 0, stride = 2, kernel_size = 3, \n",
    "                                    synapse_fc_trace_const1=1, \n",
    "                                    synapse_fc_trace_const2=v_decay, #안씀 \n",
    "                                    TIME=TIME, v_init=0.0, v_decay=v_decay, v_threshold=v_threshold, v_reset=v_reset, \n",
    "                                    sg_width=4.0, surrogate='sigmoid', BPTT_on=BPTT_on, need_bias=need_bias, lif_add_at_first=lif_add_at_first,\n",
    "                                    sae_l2_norm_bridge = sae_l2_norm_bridge, sae_lif_bridge = sae_lif_bridge, lif_add_at_last=lif_add_at_last, repeat_coding=repeat_coding).to(device)\n",
    "            else: \n",
    "                net = Autoencoder_conv1(input_channels=input_channels, input_length=n_sample, encoder_ch = [32, 64, 96], fc_dim = lateral_feature_num, padding = 0, stride = 2, kernel_size = 3, need_bias=need_bias, l2norm_bridge=sae_l2_norm_bridge, relu_bridge=sae_lif_bridge, activation_collector_on=False,\n",
    "                                        batch_norm_on=batch_norm_on, QCFS_neuron_on=QCFS_neuron_on).to(device)\n",
    "            net = torch.nn.DataParallel(net)\n",
    "            if converted_net_forward:\n",
    "                converted_net = SAE_converted_conv1(input_channels=input_channels, input_length=n_sample, encoder_ch = [32, 64, 96], fc_dim = lateral_feature_num, padding = 0, stride = 2, kernel_size = 3, \n",
    "                                    synapse_fc_trace_const1=1, \n",
    "                                    synapse_fc_trace_const2=v_decay, #안씀 \n",
    "                                    TIME=TIME, v_init=0.0, v_decay=v_decay, v_threshold=v_threshold, v_reset=v_reset, \n",
    "                                    sg_width=4.0, surrogate='sigmoid', BPTT_on=BPTT_on, need_bias=need_bias, lif_add_at_first=lif_add_at_first,\n",
    "                                    sae_l2_norm_bridge = sae_l2_norm_bridge, sae_lif_bridge = sae_lif_bridge, lif_add_at_last=lif_add_at_last,\n",
    "                                    vth_mul_on=vth_mul_on, batch_norm_on=batch_norm_on).to(device) # lif bridge는 무조건 들어가게 해놨음.\n",
    "                converted_net = torch.nn.DataParallel(converted_net)\n",
    "                print('converted_net', converted_net)\n",
    "        else:\n",
    "            n_sample = n_sample * TIME if coarse_com_mode else n_sample\n",
    "            net = Autoencoder_only_FC(encoder_ch=[400, lateral_feature_num], decoder_ch=[400,n_sample], n_sample=n_sample, need_bias=need_bias, l2norm_bridge=sae_l2_norm_bridge, relu_bridge=sae_lif_bridge, activation_collector_on=False,\n",
    "                                    batch_norm_on=batch_norm_on, QCFS_neuron_on=QCFS_neuron_on).to(device)\n",
    "            net = torch.nn.DataParallel(net)\n",
    "            if converted_net_forward:\n",
    "                converted_net = SAE_converted_fc(encoder_ch=[400, lateral_feature_num], \n",
    "                                    decoder_ch=[400, n_sample], \n",
    "                                    in_channels=n_sample, # in_channel 이 여기선 걍 lenght.\n",
    "                                    synapse_fc_trace_const1=1,\n",
    "                                    synapse_fc_trace_const2=v_decay,  #안씀 \n",
    "                                    TIME=TIME, v_init=0.0, v_decay=v_decay, v_threshold=v_threshold, v_reset=v_reset, \n",
    "                                    sg_width=4.0, surrogate='sigmoid', BPTT_on=BPTT_on, need_bias=need_bias, lif_add_at_first=lif_add_at_first,\n",
    "                                    sae_l2_norm_bridge = sae_l2_norm_bridge, sae_lif_bridge = sae_lif_bridge, lif_add_at_last=lif_add_at_last,\n",
    "                                    vth_mul_on=vth_mul_on, batch_norm_on=batch_norm_on).to(device) # lif bridge는 무조건 들어가게 해놨음.\n",
    "                converted_net = torch.nn.DataParallel(converted_net)\n",
    "                # print('converted_net', converted_net)\n",
    "    else:\n",
    "        if Conv_net == True: \n",
    "            input_channels = 1\n",
    "            input_channels = 2 if two_channel_input else 1\n",
    "            if fusion_net == True:  \n",
    "                assert coarse_com_mode == True\n",
    "                # net = SAE_FUSION2_net_conv1(input_channels=input_channels, input_length=n_sample, encoder_ch = [32, 64, 96], fc_dim = lateral_feature_num, padding = 0, stride = 2, kernel_size = 3, \n",
    "                #                     synapse_fc_trace_const1=1, \n",
    "                #                     synapse_fc_trace_const2=v_decay, #안씀 \n",
    "                #                     TIME=TIME, v_init=0.0, v_decay=v_decay, v_threshold=v_threshold, v_reset=v_reset, \n",
    "                #                     sg_width=4.0, surrogate='sigmoid', BPTT_on=BPTT_on, need_bias=need_bias, lif_add_at_first=lif_add_at_first,\n",
    "                #                     sae_l2_norm_bridge = sae_l2_norm_bridge, sae_lif_bridge = sae_lif_bridge, lif_add_at_last=lif_add_at_last, batch_norm_on=batch_norm_on, sae_relu_on=sae_relu_on).to(device)\n",
    "                # net = SAE_FUSION3_net_conv1(input_channels=input_channels, input_length=n_sample, encoder_ch = [32, 64, 96], fc_dim = lateral_feature_num, padding = 0, stride = 2, kernel_size = 3, \n",
    "                #                     synapse_fc_trace_const1=1, \n",
    "                #                     synapse_fc_trace_const2=v_decay, #안씀 \n",
    "                #                     TIME=TIME, v_init=0.0, v_decay=v_decay, v_threshold=v_threshold, v_reset=v_reset, \n",
    "                #                     sg_width=4.0, surrogate='sigmoid', BPTT_on=BPTT_on, need_bias=need_bias, lif_add_at_first=lif_add_at_first,\n",
    "                #                     sae_l2_norm_bridge = sae_l2_norm_bridge, sae_lif_bridge = sae_lif_bridge, lif_add_at_last=lif_add_at_last, batch_norm_on=batch_norm_on, sae_relu_on=sae_relu_on).to(device)\n",
    "                # net = SAE_FUSION4_net_conv1(input_channels=input_channels, input_length=n_sample, encoder_ch = [32, 64, 96], fc_dim = lateral_feature_num, padding = 0, stride = 2, kernel_size = 3, \n",
    "                #                     synapse_fc_trace_const1=1, \n",
    "                #                     synapse_fc_trace_const2=v_decay, #안씀 \n",
    "                #                     TIME=TIME, v_init=0.0, v_decay=v_decay, v_threshold=v_threshold, v_reset=v_reset, \n",
    "                #                     sg_width=4.0, surrogate='sigmoid', BPTT_on=BPTT_on, need_bias=need_bias, lif_add_at_first=lif_add_at_first,\n",
    "                #                     sae_l2_norm_bridge = sae_l2_norm_bridge, sae_lif_bridge = sae_lif_bridge, lif_add_at_last=lif_add_at_last, batch_norm_on=batch_norm_on, sae_relu_on=sae_relu_on).to(device)\n",
    "                # net = SAE_FUSION5_net_conv1(input_channels=input_channels, input_length=n_sample, encoder_ch = [32, 64, 96], fc_dim = lateral_feature_num, padding = 0, stride = 2, kernel_size = 3, \n",
    "                #                     synapse_fc_trace_const1=1, \n",
    "                #                     synapse_fc_trace_const2=v_decay, #안씀 \n",
    "                #                     TIME=TIME, v_init=0.0, v_decay=v_decay, v_threshold=v_threshold, v_reset=v_reset, \n",
    "                #                     sg_width=4.0, surrogate='sigmoid', BPTT_on=BPTT_on, need_bias=need_bias, lif_add_at_first=lif_add_at_first,\n",
    "                #                     sae_l2_norm_bridge = sae_l2_norm_bridge, sae_lif_bridge = sae_lif_bridge, lif_add_at_last=lif_add_at_last, batch_norm_on=batch_norm_on, sae_relu_on=sae_relu_on).to(device)\n",
    "                # net = SAE_FUSION6_net_conv1(input_channels=input_channels, input_length=n_sample, encoder_ch = [32, 64, 96], fc_dim = lateral_feature_num, padding = 0, stride = 2, kernel_size = 3, \n",
    "                #                     synapse_fc_trace_const1=1, \n",
    "                #                     synapse_fc_trace_const2=v_decay, #안씀 \n",
    "                #                     TIME=TIME, v_init=0.0, v_decay=v_decay, v_threshold=v_threshold, v_reset=v_reset, \n",
    "                #                     sg_width=4.0, surrogate='sigmoid', BPTT_on=BPTT_on, need_bias=need_bias, lif_add_at_first=lif_add_at_first,\n",
    "                #                     sae_l2_norm_bridge = sae_l2_norm_bridge, sae_lif_bridge = sae_lif_bridge, lif_add_at_last=lif_add_at_last, batch_norm_on=batch_norm_on, sae_relu_on=sae_relu_on).to(device)\n",
    "                net = SAE_FUSION7_net_conv1(input_channels=input_channels, input_length=n_sample, encoder_ch = [32, 64, 96], fc_dim = lateral_feature_num, padding = 0, stride = 2, kernel_size = 3, \n",
    "                                    synapse_fc_trace_const1=1, \n",
    "                                    synapse_fc_trace_const2=v_decay, #안씀 \n",
    "                                    TIME=TIME, v_init=0.0, v_decay=v_decay, v_threshold=v_threshold, v_reset=v_reset, \n",
    "                                    sg_width=4.0, surrogate='sigmoid', BPTT_on=BPTT_on, need_bias=need_bias, lif_add_at_first=lif_add_at_first,\n",
    "                                    sae_l2_norm_bridge = sae_l2_norm_bridge, sae_lif_bridge = sae_lif_bridge, lif_add_at_last=lif_add_at_last, batch_norm_on=batch_norm_on, sae_relu_on=sae_relu_on).to(device)\n",
    "            else:\n",
    "                net = SAE_conv1(input_channels=input_channels, input_length=n_sample, encoder_ch = [32, 64, 96], fc_dim = lateral_feature_num, padding = 0, stride = 2, kernel_size = 3, \n",
    "                                    synapse_fc_trace_const1=1, \n",
    "                                    synapse_fc_trace_const2=v_decay, #안씀 \n",
    "                                    TIME=TIME, v_init=0.0, v_decay=v_decay, v_threshold=v_threshold, v_reset=v_reset, \n",
    "                                    sg_width=4.0, surrogate='sigmoid', BPTT_on=BPTT_on, need_bias=need_bias, lif_add_at_first=lif_add_at_first,\n",
    "                                    sae_l2_norm_bridge = sae_l2_norm_bridge, sae_lif_bridge = sae_lif_bridge, lif_add_at_last=lif_add_at_last, batch_norm_on=batch_norm_on, sae_relu_on=sae_relu_on).to(device)\n",
    "            # net = SAE_conv1_DR(input_channels=input_channels, input_length=n_sample, encoder_ch = [32, 64, 96], fc_dim = lateral_feature_num, padding = 0, stride = 2, kernel_size = 3, \n",
    "            #                     synapse_fc_trace_const1=1, \n",
    "            #                     synapse_fc_trace_const2=v_decay, #안씀 \n",
    "            #                     TIME=TIME, v_init=0.0, v_decay=v_decay, v_threshold=v_threshold, v_reset=v_reset, \n",
    "            #                     sg_width=4.0, surrogate='sigmoid', BPTT_on=BPTT_on, need_bias=need_bias, lif_add_at_first=lif_add_at_first,\n",
    "            #                     sae_l2_norm_bridge = sae_l2_norm_bridge, sae_lif_bridge = sae_lif_bridge, lif_add_at_last=lif_add_at_last, batch_norm_on=batch_norm_on).to(device)\n",
    "            net = torch.nn.DataParallel(net)\n",
    "        else:\n",
    "            net = SAE_fc_only(encoder_ch=[400, lateral_feature_num], \n",
    "                                decoder_ch=[400, n_sample], \n",
    "                                in_channels=n_sample, # in_channel 이 여기선 걍 lenght.\n",
    "                                synapse_fc_trace_const1=1,\n",
    "                                synapse_fc_trace_const2=v_decay,  #안씀 \n",
    "                                TIME=TIME, v_init=0.0, v_decay=v_decay, v_threshold=v_threshold, v_reset=v_reset, \n",
    "                                sg_width=4.0, surrogate='sigmoid', BPTT_on=BPTT_on, need_bias=need_bias, lif_add_at_first=lif_add_at_first,\n",
    "                                sae_l2_norm_bridge = sae_l2_norm_bridge, sae_lif_bridge = sae_lif_bridge, lif_add_at_last=lif_add_at_last, batch_norm_on=batch_norm_on, sae_relu_on=sae_relu_on).to(device)\n",
    "            net = torch.nn.DataParallel(net)\n",
    "\n",
    "    # net = torch.load('/home/bhkim003/github_folder/ByeonghyeonKim/my_snn/net_save/save_now_net_AE_re_e7000.pth')\n",
    "    # net = torch.load('/home/bhkim003/github_folder/ByeonghyeonKim/my_snn/net_save/save_now_net_20250101_210938_786.pth')\n",
    "    # load했으면 torch.nn.DataParallel 하지마\n",
    "    # net.module.load_state_dict(torch.load('/home/bhkim003/github_folder/ByeonghyeonKim/my_snn/net_save/save_now_net_annbase_20250108_210641_941.pth'))\n",
    "    if pretrained_net != None:\n",
    "        ######################## 모델이 달라서 dict로 weight만 넣고싶을 때\n",
    "        # # 저장된 가중치 로드\n",
    "        saved_state_dict = torch.load(pretrained_net)\n",
    "        current_state_dict = net.module.state_dict()\n",
    "\n",
    "        # 함수 호출로 가중치 매핑\n",
    "        updated_state_dict = map_and_load_weights(saved_state_dict, current_state_dict)\n",
    "\n",
    "        # 업데이트된 state_dict를 네트워크에 로드\n",
    "        net.module.load_state_dict(updated_state_dict)\n",
    "        ######################## 모델이 달라서 dict로 weight만 넣고싶을 때\n",
    "\n",
    "        ############## 일반적일 때\n",
    "        # net.module.load_state_dict(torch.load(pretrained_net))\n",
    "        ############## 일반적일 때\n",
    "    \n",
    "        # pre_net = Autoencoder_conv1(input_channels=input_channels, input_length=n_sample, encoder_ch = [32, 64, 96], fc_dim = lateral_feature_num, padding = 0, stride = 2, kernel_size = 3, need_bias=need_bias, l2norm_bridge=sae_l2_norm_bridge, relu_bridge=sae_lif_bridge, activation_collector_on=False,\n",
    "        #                         batch_norm_on=batch_norm_on, QCFS_neuron_on=False).to(device)\n",
    "        # pre_net = torch.nn.DataParallel(net)\n",
    "        # pre_net.module.load_state_dict(torch.load(pretrained_net))\n",
    "        # copy_weights(pre_net.module.encoder , net.module.encoder )\n",
    "        # copy_weights(pre_net.module.decoder , net.module.decoder  )\n",
    "\n",
    "        \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    wandb.watch(net, log=\"all\", log_freq = 10)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    if SAE_net == True:\n",
    "        assert 'SAE' in net.module.__class__.__name__\n",
    "\n",
    "\n",
    "\n",
    "    net = net.to(device)\n",
    "    print(f\"Total number of encoder parameters: {sum(p.numel() for p in net.module.encoder.parameters())}\")\n",
    "    print(net)\n",
    "    print('Device:',device)\n",
    "\n",
    "    \n",
    "    if optimizer == 'Adam':\n",
    "        optimizer = optim.Adam(net.parameters(), lr=learning_rate)\n",
    "    elif optimizer == 'SGD':\n",
    "        optimizer = optim.SGD(net.parameters(), lr = learning_rate, momentum = 0.9)\n",
    "    else:\n",
    "        assert False, 'optimizer를 잘못 입력했습니다.'\n",
    "        \n",
    "    loss_history = []\n",
    "    mean_cluster_accuracy_during_training_cycle_all_dataset_history = []\n",
    "    mean_cluster_accuracy_post_training_cycle_all_dataset_history = []\n",
    "    mean_cluster_accuracy_total_all_dataset_history = []\n",
    "\n",
    "    tau = np.zeros(num_cluster)\n",
    "\n",
    "    print(f\"\\nStart Training, current_time = {current_time}\")\n",
    "    mean_cluster_accuracy_post_training_cycle_all_dataset = 0\n",
    "    best_mean_cluster_accuracy_post_training_cycle_all_dataset = 0\n",
    "\n",
    "    if SAE_net == True:\n",
    "        assert 'SAE' in net.module.__class__.__name__\n",
    "        \n",
    "    k_means_acc_best = 0\n",
    "    min_loss = 9999999\n",
    "    min_loss_normal = 9999999\n",
    "    min_loss_coarse = 9999999\n",
    "    for epoch in range(max_epoch):\n",
    "        print()\n",
    "        l2_loss_bin= 0\n",
    "        ae_train_start_time = time.time()\n",
    "        running_loss = 0.0\n",
    "        running_loss_normal = 0.0\n",
    "        running_loss_coarse = 0.0\n",
    "        iter = 0\n",
    "        net.train()\n",
    "        # if True or max_epoch != 1:\n",
    "        wrong_element_sum = 0\n",
    "        same_data_num = 0\n",
    "        total_data_num = 0\n",
    "        if max_epoch != 1:\n",
    "            for data in train_loader:\n",
    "                optimizer.zero_grad()\n",
    "                total_data_num += len(data)\n",
    "                data = data.to(device)\n",
    "                scaling = (level_num-3)/level_num if conv1d_scaling else 1.0\n",
    "                data = zero_to_one_normalize_features(data, level_num=quantize_level_num, coarse_com_config=coarse_com_config, scaling=scaling, norm01=norm01) if normalize_on else data\n",
    "                # plot_origin_spike(data[0].cpu().detach().numpy(), min_max_y_on = True)\n",
    "                # plot_origin_spike(data[1].cpu().detach().numpy(), min_max_y_on = True)\n",
    "                spike_backup = data\n",
    "                spike = data\n",
    "                spike = spike.to(device) # batch, feature\n",
    "                spike_for_fusion2_net = spike\n",
    "                if coarse_com_mode == True and 'SAE' in net.module.__class__.__name__:\n",
    "                    # print(spike[0])\n",
    "                    spike = spike.unsqueeze(2).repeat(1, 1, level_num) # spike_length == level_num # (batch, time, feature)로 변환 \n",
    "                    spike = (spike > levels).to(torch.float) \n",
    "\n",
    "                    spike = (spike == 0).cumsum(dim=-1).eq(1).to(torch.float) if lc_adc_on == True else spike\n",
    "\n",
    "                    # spike: batch, time, level_num\n",
    "                    # levels: time, level_num\n",
    "                    if Conv_net == True:\n",
    "                        spike = spike.unsqueeze(-2) # batch, time, in_channel, feature or batch in_channel,feature\n",
    "                        if two_channel_input == True:\n",
    "                            spike_backup = spike_backup.to(device)\n",
    "                            spike_backup = spike_backup.unsqueeze(2).repeat(1, 1, level_num) # spike_length == level_num # (batch, time, feature)로 변환 \n",
    "                            spike_backup = (spike_backup <= levels).to(torch.float) \n",
    "                            spike_backup = (spike_backup == 1).cumsum(dim=-1).eq(1).to(torch.float) if lc_adc_on == True else spike_backup\n",
    "                            spike_backup = spike_backup.unsqueeze(-2)\n",
    "                            spike = torch.cat((spike, spike_backup), dim=-2)\n",
    "                    assert spike.shape[0] == batch_size and spike.shape[1] == TIME\n",
    "                elif 'SAE' in net.module.__class__.__name__:\n",
    "                    spike = spike.unsqueeze(-1).repeat(1, 1, TIME).permute(0,2,1) # (batch, time, feature)로 변환\n",
    "                    if Conv_net == True:\n",
    "                        spike = spike.unsqueeze(-2) # batch, time, in_channel, feature or batch in_channel,feature\n",
    "                else:\n",
    "                    if Conv_net == True:\n",
    "                        if coarse_com_mode == False:\n",
    "                            spike = spike.unsqueeze(-2) #batch in_channel,feature\n",
    "                        else:\n",
    "                            spike = spike.unsqueeze(2).repeat(1, 1, level_num) # spike_length == level_num # (batch, time, feature)로 변환 \n",
    "                            spike = (spike > levels).to(torch.float) \n",
    "\n",
    "                            spike = (spike == 0).cumsum(dim=-1).eq(1).to(torch.float) if lc_adc_on == True else spike\n",
    "\n",
    "                    else:\n",
    "                        if coarse_com_mode == False:\n",
    "                            pass\n",
    "                        else:\n",
    "                            spike = spike.unsqueeze(2).repeat(1, 1, level_num) # spike_length == level_num # (batch, time, feature)로 변환 \n",
    "                            spike = (spike > levels).to(torch.float) \n",
    "\n",
    "                            spike = (spike == 0).cumsum(dim=-1).eq(1).to(torch.float) if lc_adc_on == True else spike\n",
    "\n",
    "                            # spike: batch, time, feature\n",
    "                            spike = spike.reshape(spike.shape[0], -1)\n",
    "\n",
    "                    \n",
    "\n",
    "\n",
    "                    # if fusion_net == True:\n",
    "                    #     spike = spikegen.rate(spike, num_steps=TIME).transpose(0, 1)\n",
    "\n",
    "                # spike_class = net(spike) # batch, time, feature\n",
    "                encoded_spike = net.module.encoder(spike)\n",
    "                spike_class = net.module.decoder(encoded_spike)\n",
    "\n",
    "                # for i in range (2):\n",
    "                #     plot_spike(spike[i,:,0,:].cpu().numpy())\n",
    "                #     # plot_spike(spike[i,:,1,:].cpu().numpy())\n",
    "                #     plot_origin_spike(spike_class.squeeze()[i].cpu().detach().numpy(), min_max_y_on = True)\n",
    "                # assert False\n",
    "                        \n",
    "\n",
    "                loss = 0\n",
    "                loss_normal = torch.tensor(0.0)\n",
    "                loss_coarse = torch.tensor(0.0)\n",
    "                if coarse_com_mode == True and 'SAE' in net.module.__class__.__name__:\n",
    "                    criterion = nn.MSELoss().to(device)\n",
    "                    # loss1 = nn.MSELoss()(spike_class[..., 5:25], spike[..., 5:25])\n",
    "                    # loss2 = nn.MSELoss()(spike_class[..., 0:5], spike[..., 0:5])\n",
    "                    # loss3 = nn.MSELoss()(spike_class[..., 25:spike_length], spike[..., 25:spike_length])\n",
    "                    # loss = loss1 * 2.125 + (loss2 + loss3)/4\n",
    "\n",
    "                    # loss1 = nn.MSELoss()(spike_class[..., 5:25, :], spike[..., 5:25, :])\n",
    "                    # loss2 = nn.MSELoss()(spike_class[..., 0:5, :], spike[..., 0:5, :])\n",
    "                    # loss3 = nn.MSELoss()(spike_class[..., 25:spike_length, :], spike[..., 25:spike_length, :])\n",
    "                    # loss = loss1 * 2.125 + (loss2 + loss3)/4\n",
    "                    if fusion_net:\n",
    "                        # print('1', spike.shape) # batch, time, in_channel, feature [32, 50, 1, 50]\n",
    "                        \n",
    "                        # ### coarse에서 ann loss 만들기 ######\n",
    "                        # spike = spike.squeeze()\n",
    "                        # assert two_channel_input == False\n",
    "                        # zero_mask = (spike == 0)  # 0이 있는 위치\n",
    "                        # first_zero_idx = torch.where(zero_mask, torch.arange(spike.shape[-1]).to(device), spike.shape[-1]-1).min(dim=-1).values\n",
    "                        # spike = levels[0][first_zero_idx]\n",
    "                        # # plot_origin_spike(spike[0].cpu().detach().numpy())\n",
    "                        # ### coarse에서 ann loss 만들기 ######\n",
    "\n",
    "                        ### 그냥 원래 스파이크로 ann loss 만들기 ######\n",
    "                        spike = spike_for_fusion2_net\n",
    "                        ### 그냥 원래 스파이크로 ann loss 만들기 ######\n",
    "\n",
    "                        spike = spike.squeeze()\n",
    "                        spike_class = spike_class.squeeze()\n",
    "                        \n",
    "                        ### normal loss################\n",
    "                        # loss = criterion(spike_class, spike)\n",
    "                        ### normal loss################\n",
    "                        \n",
    "                        ### chan loss################\n",
    "                        loss1 = criterion(spike_class[..., 5:25], spike[..., 5:25])\n",
    "                        loss2 = criterion(spike_class[..., 0:5], spike[..., 0:5])\n",
    "                        loss3 = criterion(spike_class[..., 25:], spike[..., 25:])\n",
    "                        loss = loss1 * 2.125 + (loss2 + loss3)/4\n",
    "                        ### chan loss################\n",
    "\n",
    "\n",
    "                        # #########################################\n",
    "                        # # 손실 함수 정의 (예: MSELoss 사용)\n",
    "                        # criterion_joke = torch.nn.MSELoss(reduction='none')  # 개별 요소별 손실을 유지\n",
    "\n",
    "                        # # 손실 계산\n",
    "                        # loss1_joke = criterion_joke(spike_class[..., 5:25], spike[..., 5:25]).mean(dim=-1)  # (batch,)\n",
    "                        # loss2_joke = criterion_joke(spike_class[..., 0:5], spike[..., 0:5]).mean(dim=-1)    # (batch,)\n",
    "                        # loss3_joke = criterion_joke(spike_class[..., 25:], spike[..., 25:]).mean(dim=-1)    # (batch,)\n",
    "\n",
    "                        # # 주어진 가중치를 적용한 최종 손실\n",
    "                        # loss_joke = loss1_joke * 2.125 + (loss2_joke + loss3_joke) / 4  # (batch,)\n",
    "\n",
    "                        # # 가장 큰 손실을 갖는 샘플의 인덱스 찾기\n",
    "                        # max_loss_idx_joke = torch.argmax(loss_joke)\n",
    "\n",
    "                        # # 해당 샘플 선택\n",
    "                        # selected_sample_class = spike_class[max_loss_idx_joke]\n",
    "                        # selected_sample_spike = spike[max_loss_idx_joke]\n",
    "\n",
    "                        # # 선택한 샘플의 손실 값 출력\n",
    "                        # print(\"Index of max loss sample:\", max_loss_idx_joke.item())\n",
    "                        # print(\"Max loss value:\", loss_joke[max_loss_idx_joke].item())\n",
    "                        # mean_loss_joke = loss_joke.mean().item()\n",
    "                        # print(\"Mean loss across the batch:\", mean_loss_joke)\n",
    "\n",
    "                        # # 선택한 샘플을 시각화\n",
    "                        # plot_origin_spike(selected_sample_class.cpu().detach().numpy())\n",
    "                        # plot_origin_spike(selected_sample_spike.cpu().detach().numpy())\n",
    "                        # #########################################\n",
    "\n",
    "                        # coarse loss ######################################################\n",
    "                        loss_normal = criterion(spike_class, spike)\n",
    "                        level_num_in_loss = spike_length\n",
    "                        level_interval = (coarse_com_config[0] - coarse_com_config[1]) / (level_num_in_loss-1)  # max - min\n",
    "                        levels = [coarse_com_config[1] + level_interval * i for i in range(level_num_in_loss)]\n",
    "                        levels = torch.tensor(levels).to(torch.float).to(device)\n",
    "                        # print('coarse leves', levels)\n",
    "                        levels = levels.repeat(spike_length,1) \n",
    "\n",
    "                        spike = spike.squeeze()\n",
    "                        spike_class = spike_class.squeeze()\n",
    "                        # plot_origin_spike(spike_class[0].cpu().detach().numpy())\n",
    "                        spike = spike.unsqueeze(2).repeat(1, 1, level_num_in_loss) \n",
    "                        spike = (spike > levels).to(torch.float) \n",
    "                        spike_class = spike_class.unsqueeze(2).repeat(1, 1, level_num_in_loss) \n",
    "                        spike_class = (spike_class > levels).to(torch.float) \n",
    "                        # spike = spike[..., 0:-3, :]\n",
    "                        # spike_class = spike_class[..., 0:-3, :]\n",
    "                        loss_coarse = criterion(spike_class, spike)\n",
    "                        wrong_element_sum += torch.sum(torch.abs(spike - spike_class)).item() \n",
    "\n",
    "                        # plot_spike(spike_class[0].cpu().detach().numpy())\n",
    "                        # assert False\n",
    "                        # coarse loss ######################################################\n",
    "                    else:\n",
    "                        spike = spike.squeeze()\n",
    "                        spike_class = spike_class.squeeze()\n",
    "                        loss = criterion(spike_class, spike)\n",
    "\n",
    "                    for iii in range(spike.shape[0]):\n",
    "                        same_data_num = same_data_num + 1 if torch.eq(spike[iii], spike_class[iii]).all() else same_data_num\n",
    "                    wrong_element_sum += torch.sum(torch.abs(spike - spike_class)).item() \n",
    "\n",
    "                    # spike = spike.squeeze()\n",
    "                    # spike_class = spike_class.squeeze()\n",
    "                    # plot_spike(spike[0].cpu().detach().numpy())\n",
    "                    # plot_spike(spike_class[0].cpu().detach().numpy())\n",
    "                    # print('손실 절대값 합',np.sum(np.abs(spike[0].cpu().detach().numpy() - spike_class[0].cpu().detach().numpy())))\n",
    "                    # # assert False\n",
    "                elif 'SAE' in net.module.__class__.__name__:\n",
    "                    criterion = nn.MSELoss().to(device)\n",
    "                    loss1 = criterion(spike_class[..., 5:25], spike[..., 5:25])\n",
    "                    loss2 = criterion(spike_class[..., 0:5], spike[..., 0:5])\n",
    "                    loss3 = criterion(spike_class[..., 25:spike_length], spike[..., 25:spike_length])\n",
    "                    loss = loss1 * 2.125 + (loss2 + loss3)/4\n",
    "                    assert spike_length > 25, 'spike_length가 25보다 작음'\n",
    "                    # wrong_element_sum += torch.sum(torch.abs(spike - spike_class)).item() \n",
    "                else:\n",
    "                    criterion = nn.MSELoss().to(device)\n",
    "                    loss1 = criterion(spike_class[..., 5:25], spike[..., 5:25])\n",
    "                    loss2 = criterion(spike_class[..., 0:5], spike[..., 0:5])\n",
    "                    loss3 = criterion(spike_class[..., 25:spike_length], spike[..., 25:spike_length])\n",
    "                    loss = loss1 * 2.125 + (loss2 + loss3)/4\n",
    "                    assert spike_length > 25, 'spike_length가 25보다 작음'\n",
    "                    # wrong_element_sum += torch.sum(torch.abs(spike - spike_class)).item() \n",
    "\n",
    "\n",
    "                    if l2_norm_loss_weight > 0:\n",
    "                        assert len(encoded_spike.shape) == 2, 'time 성분 없는 걸로'\n",
    "                        l2_loss = l2_norm_loss(encoded_spike, target_norm=1.0)  # L2Norm Loss 계산, l2 1.0되게.\n",
    "                        loss = loss + l2_loss*l2_norm_loss_weight\n",
    "                        l2_loss_bin += l2_loss.item()\n",
    "\n",
    "                    # coarse loss ######################################################\n",
    "                    loss_normal = criterion(spike_class, spike)\n",
    "                    level_num_in_loss = quantize_level_num\n",
    "                    level_interval = (coarse_com_config[0] - coarse_com_config[1]) / (level_num_in_loss-1)  # max - min\n",
    "                    levels = [coarse_com_config[1] + level_interval * i for i in range(level_num_in_loss)]\n",
    "                    levels = torch.tensor(levels).to(torch.float).to(device)\n",
    "                    levels = levels.repeat(spike_length,1) \n",
    "\n",
    "                    spike = spike.squeeze()\n",
    "                    spike_class = spike_class.squeeze()\n",
    "                    # plot_origin_spike(spike_class[0].cpu().detach().numpy())\n",
    "                    spike = spike.unsqueeze(2).repeat(1, 1, level_num_in_loss) \n",
    "                    spike = (spike > levels).to(torch.float) \n",
    "                    spike_class = spike_class.unsqueeze(2).repeat(1, 1, level_num_in_loss) \n",
    "                    spike_class = (spike_class > levels).to(torch.float) \n",
    "                    # spike = spike[..., 0:-3, :]\n",
    "                    # spike_class = spike_class[..., 0:-3, :]\n",
    "                    loss_coarse = criterion(spike_class, spike)\n",
    "                    wrong_element_sum += torch.sum(torch.abs(spike - spike_class)).item() \n",
    "\n",
    "                    # plot_spike(spike_class[0].cpu().detach().numpy())\n",
    "                    # assert False\n",
    "                    # coarse loss ######################################################\n",
    "\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                running_loss += loss.item()\n",
    "                running_loss_normal += loss_normal.item()\n",
    "                running_loss_coarse += loss_coarse.item()\n",
    "                # print(f'\\nepoch-{epoch}, running_loss : {running_loss:.5f}, iter percent {iter/len(train_loader)*100:.2f}%')\n",
    "                iter += 1\n",
    "        else:\n",
    "            print('\\n\\n\\n max_epoch 1이면 Train 안함!!!!!!!!!!!!!!!!!!!!!')\n",
    "        if l2_norm_loss_weight > 0:\n",
    "            print('l2_loss_bin', l2_loss_bin/len(train_loader))\n",
    "        avg_loss = running_loss / len(train_loader)\n",
    "        assert not np.isnan(avg_loss), f\"Error: avg_loss is NaN! Running loss: {running_loss}, Length of train_loader: {len(train_loader)}\"\n",
    "        loss_history.append((epoch, avg_loss))\n",
    "        min_loss = min(min_loss, avg_loss)\n",
    "        min_loss_normal = min(min_loss_normal, running_loss_normal/len(train_loader))\n",
    "        min_loss_coarse = min(min_loss_coarse, running_loss_coarse/len(train_loader))\n",
    "        print(f'\\nepoch-{epoch} loss : {avg_loss:.8f}, loss_normal : {running_loss_normal/len(train_loader):.8f}, loss_coarse : {running_loss_coarse/len(train_loader):.8f}, min_loss : {min_loss:.8f}, min_loss_normal : {min_loss_normal:.8f}, min_loss_coarse : {min_loss_coarse:.8f}, wrong_element_sum : {wrong_element_sum:.8f}, same_data : {100*same_data_num/(total_data_num+1e-12):.2f}%')\n",
    "        print(f\"ae train 실행 시간: {time.time()-ae_train_start_time:.3f}초, 전체 시작 시간 {current_time}\")\n",
    "\n",
    "        # plot_activation_distribution(net)\n",
    "\n",
    "        if SAE_net == False and converted_net_forward == True:\n",
    "            source_encoder = net.module.encoder \n",
    "            target_encoder = converted_net.module.encoder  \n",
    "            copy_weights(source_encoder, target_encoder)\n",
    "\n",
    "        cluster_accuracy_during_training_cycle_all_dataset = np.zeros(dataset_num)\n",
    "        cluster_accuracy_post_training_cycle_all_dataset = np.zeros(dataset_num)\n",
    "        cluster_accuracy_total_all_dataset = np.zeros(dataset_num)    \n",
    "\n",
    "        k_means_acc = 0\n",
    "        converted_k_means_acc = 0\n",
    "        if(epoch % accuracy_check_epoch_term == 0 or epoch == 1 or epoch == max_epoch-1): \n",
    "            accuracy_check_start_time = time.time()\n",
    "            print(f'\\nepoch-{epoch} accuracy check')\n",
    "            k_means_bin_origin_feature = []\n",
    "            k_means_bin = []\n",
    "            converted_k_means_bin = []\n",
    "            for ds in range(dataset_num):\n",
    "                # print('\\n', spike_tot[ds])\n",
    "\n",
    "                spike_template = np.load(my_path_ground_BH + template[ds])\n",
    "                spike = np.load(my_path_ground_BH + spike_tot[ds])\n",
    "                label = np.load(my_path_ground_BH + label_tot[ds])\n",
    "                spike_template = torch.from_numpy(spike_template).to(device)\n",
    "                spike = torch.from_numpy(spike).to(device)\n",
    "                scaling = (level_num-3)/level_num if conv1d_scaling else 1.0\n",
    "                spike_template = zero_to_one_normalize_features(spike_template, level_num=quantize_level_num, coarse_com_config=coarse_com_config, scaling=scaling, norm01=norm01) if normalize_on else spike_template\n",
    "                spike = zero_to_one_normalize_features(spike, level_num=quantize_level_num, coarse_com_config=coarse_com_config, scaling=scaling, norm01=norm01) if normalize_on else spike\n",
    "                \n",
    "                hidden_size = lateral_feature_num*TIME if 'SAE' in net.module.__class__.__name__ and SAE_hidden_nomean == True and fusion_net == False or 'SAE_FUSION5' in net.module.__class__.__name__ else lateral_feature_num\n",
    "                hidden_size = lateral_feature_num if '_DR' in net.module.__class__.__name__  else hidden_size\n",
    "\n",
    "                Cluster = np.zeros((num_cluster, hidden_size))\n",
    "                assert Cluster.shape[-1] == hidden_size, '이거 hidden dim 4 아니게 할 거면 잘 바꿔라'\n",
    "                \n",
    "\n",
    "\n",
    "                net.eval()\n",
    "                with torch.no_grad():\n",
    "                    spike_torch = spike_template.float()\n",
    "                    spike_torch = spike_torch[:num_cluster]\n",
    "                    spike_backup = spike_torch\n",
    "                    spike_torch = spike_torch.to(device)\n",
    "                    if coarse_com_mode == True and 'SAE' in net.module.__class__.__name__:\n",
    "                        spike_torch = spike_torch.unsqueeze(2).repeat(1, 1, level_num) # spike_length == level_num # (batch, time, feature)로 변환 \n",
    "                        spike_torch = (spike_torch > levels).to(torch.float) \n",
    "                        spike_torch = (spike_torch == 0).cumsum(dim=-1).eq(1).to(torch.float) if lc_adc_on == True else spike_torch\n",
    "                        if Conv_net == True:\n",
    "                            spike_torch = spike_torch.unsqueeze(-2) # batch, time, in_channel, feature or batch in_channel,feature\n",
    "                            if two_channel_input == True:\n",
    "                                spike_backup = spike_backup.to(device)\n",
    "                                spike_backup = spike_backup.unsqueeze(2).repeat(1, 1, level_num) # spike_length == level_num # (batch, time, feature)로 변환 \n",
    "                                spike_backup = (spike_backup <= levels).to(torch.float) \n",
    "                                spike_backup = (spike_backup == 1).cumsum(dim=-1).eq(1).to(torch.float) if lc_adc_on == True else spike_backup\n",
    "                                spike_backup = spike_backup.unsqueeze(-2) # batch, time, in_channel, feature\n",
    "                                spike_torch = torch.cat((spike_torch, spike_backup), dim=-2)\n",
    "                    elif 'SAE' in net.module.__class__.__name__:\n",
    "                        spike_torch = spike_torch.unsqueeze(1).repeat(1, TIME, 1) # (batch, time, feature)로 변환\n",
    "                        if Conv_net == True:\n",
    "                            spike_torch = spike_torch.unsqueeze(-2) # batch, time, in_channel, feature or batch in_channel,feature\n",
    "                    else:\n",
    "                        # if Conv_net == True:\n",
    "                        #     spike_torch = spike_torch.unsqueeze(-2) #batch in_channel,feature\n",
    "                        if Conv_net == True:\n",
    "                            if coarse_com_mode == False:\n",
    "                                spike_torch = spike_torch.unsqueeze(-2) #batch in_channel,feature\n",
    "                            else:\n",
    "                                spike_torch = spike_torch.unsqueeze(2).repeat(1, 1, level_num) # spike_length == level_num # (batch, time, feature)로 변환 \n",
    "                                spike_torch = (spike_torch > levels).to(torch.float) \n",
    "\n",
    "                                spike_torch = (spike_torch == 0).cumsum(dim=-1).eq(1).to(torch.float) if lc_adc_on == True else spike_torch\n",
    "\n",
    "                        else:\n",
    "                            if coarse_com_mode == False:\n",
    "                                pass\n",
    "                            else:\n",
    "                                spike_torch = spike_torch.unsqueeze(2).repeat(1, 1, level_num) # spike_length == level_num # (batch, time, feature)로 변환 \n",
    "                                spike_torch = (spike_torch > levels).to(torch.float) \n",
    "\n",
    "                                spike_torch = (spike_torch == 0).cumsum(dim=-1).eq(1).to(torch.float) if lc_adc_on == True else spike_torch\n",
    "\n",
    "                                # spike: batch, time, feature\n",
    "                                spike_torch = spike_torch.reshape(spike_torch.shape[0], -1)\n",
    "\n",
    "                        if converted_net_forward == True:\n",
    "                            spike_torch_spikegen = spikegen.rate(spike_torch, num_steps=TIME).transpose(0, 1)\n",
    "                        # if fusion_net == True:\n",
    "                        #     spike_torch = spikegen.rate(spike_torch, num_steps=TIME).transpose(0, 1)\n",
    "                    ### forward #######################################################\n",
    "                    inner_inf = net.module.encoder(spike_torch)\n",
    "                    if SAE_net == False and converted_net_forward == True:\n",
    "                        converted_inner_inf = converted_net.module.encoder(spike_torch_spikegen)\n",
    "                    ### forward #######################################################\n",
    "\n",
    "                    # if ds % 4 == 0:\n",
    "                    #     for i in range(4):\n",
    "                    #         decoded = net.module.decoder(inner_inf).squeeze()\n",
    "                    #         plot_spike(spike_torch[i,:,:].cpu().numpy())\n",
    "                    #         plot_spike(inner_inf[i,:].cpu().numpy())\n",
    "                    #         # plot_origin_spike(net.module.decoder(inner_inf)[i,:].cpu().numpy())\n",
    "                    #         plot_origin_spike(decoded[i].cpu().numpy(), min_max_y_on = True)\n",
    "                        \n",
    "                    # if 'SAE' in net.module.__class__.__name__:\n",
    "                    #     tensors = [inner_inf[0][i] for i in range(TIME)] \n",
    "                    #     all_equal = all(torch.equal(tensors[0], t) for t in tensors)\n",
    "                    #     print(all_equal, inner_inf)\n",
    "\n",
    "                    if 'SAE' in net.module.__class__.__name__:\n",
    "                        if SAE_hidden_nomean == True:\n",
    "                            inner_inf = inner_inf.reshape(inner_inf.shape[0],-1)# time*feature 펼치기\n",
    "                        else:\n",
    "                            inner_inf = inner_inf.mean(dim=1)# Time 방향으로 평균\n",
    "                        # inner_inf = F.normalize(inner_inf, p=2, dim=1)\n",
    "                    Cluster = inner_inf.cpu().detach().numpy()\n",
    "\n",
    "                encoder_batch = 128\n",
    "                spike_hidden = np.zeros((len(spike), hidden_size))\n",
    "                converted_spike_hidden = np.zeros((len(spike), hidden_size))\n",
    "                net.eval()\n",
    "                with torch.no_grad():\n",
    "                    now_index = 0\n",
    "                    while (1):\n",
    "                        now_end_index = now_index+encoder_batch if now_index+encoder_batch < len(spike) else len(spike)\n",
    "                        spike_batch = spike[now_index:now_end_index] \n",
    "                        spike_torch = spike_batch\n",
    "                        spike_torch = spike_torch.float()\n",
    "                        spike_backup = spike_torch\n",
    "                        spike_torch = spike_torch.to(device)\n",
    "                        if coarse_com_mode == True and 'SAE' in net.module.__class__.__name__:\n",
    "                            spike_torch = spike_torch.unsqueeze(2).repeat(1, 1, level_num) # spike_length == level_num # (batch, time, feature)로 변환 \n",
    "                            spike_torch = (spike_torch > levels).to(torch.float) \n",
    "                            spike_torch = (spike_torch == 0).cumsum(dim=-1).eq(1).to(torch.float) if lc_adc_on == True else spike_torch\n",
    "                            if Conv_net == True:\n",
    "                                spike_torch = spike_torch.unsqueeze(-2) # batch, time, in_channel, feature or batch in_channel,feature\n",
    "                                if two_channel_input == True:\n",
    "                                    spike_backup = spike_backup.to(device)\n",
    "                                    spike_backup = spike_backup.unsqueeze(2).repeat(1, 1, level_num) # spike_length == level_num # (batch, time, feature)로 변환 \n",
    "                                    spike_backup = (spike_backup <= levels).to(torch.float) \n",
    "                                    spike_backup = (spike_backup == 1).cumsum(dim=-1).eq(1).to(torch.float) if lc_adc_on == True else spike_backup\n",
    "                                    spike_backup = spike_backup.unsqueeze(-2)\n",
    "                                    spike_torch = torch.cat((spike_torch, spike_backup), dim=-2)\n",
    "                        elif 'SAE' in net.module.__class__.__name__:\n",
    "                            spike_torch = spike_torch.unsqueeze(1).repeat(1, TIME, 1) # (batch, time, feature)로 변환\n",
    "                            if Conv_net == True:\n",
    "                                spike_torch = spike_torch.unsqueeze(-2) # batch, time, in_channel, feature or batch in_channel,feature\n",
    "                        else:\n",
    "                            # if Conv_net == True:\n",
    "                            #     spike_torch = spike_torch.unsqueeze(-2) #batch in_channel,feature\n",
    "                            if Conv_net == True:\n",
    "                                if coarse_com_mode == False:\n",
    "                                    spike_torch = spike_torch.unsqueeze(-2) #batch in_channel,feature\n",
    "                                else:\n",
    "                                    spike_torch = spike_torch.unsqueeze(2).repeat(1, 1, level_num) # spike_length == level_num # (batch, time, feature)로 변환 \n",
    "                                    spike_torch = (spike_torch > levels).to(torch.float) \n",
    "\n",
    "                                    spike_torch = (spike_torch == 0).cumsum(dim=-1).eq(1).to(torch.float) if lc_adc_on == True else spike_torch\n",
    "\n",
    "                            else:\n",
    "                                if coarse_com_mode == False:\n",
    "                                    pass\n",
    "                                else:\n",
    "                                    spike_torch = spike_torch.unsqueeze(2).repeat(1, 1, level_num) # spike_length == level_num # (batch, time, feature)로 변환 \n",
    "                                    spike_torch = (spike_torch > levels).to(torch.float) \n",
    "\n",
    "                                    spike_torch = (spike_torch == 0).cumsum(dim=-1).eq(1).to(torch.float) if lc_adc_on == True else spike_torch\n",
    "\n",
    "                                    # spike: batch, time, feature\n",
    "                                    spike_torch = spike_torch.reshape(spike_torch.shape[0], -1)\n",
    "                            if converted_net_forward == True:\n",
    "                                spike_torch_spikegen = spikegen.rate(spike_torch, num_steps=TIME).transpose(0, 1)\n",
    "                            # if fusion_net == True:\n",
    "                            #     spike_torch = spikegen.rate(spike_torch, num_steps=TIME).transpose(0, 1)\n",
    "                        ### forward #######################################################\n",
    "                        inner_inf = net.module.encoder(spike_torch)\n",
    "                        if SAE_net == False and converted_net_forward == True:\n",
    "                            converted_inner_inf = converted_net.module.encoder(spike_torch_spikegen)\n",
    "                        ### forward #######################################################\n",
    "                            \n",
    "                        if 'SAE' in net.module.__class__.__name__:\n",
    "                            if SAE_hidden_nomean == True:\n",
    "                                inner_inf = inner_inf.reshape(spike_batch.shape[0],-1)# 펼치기\n",
    "                            else:\n",
    "                                inner_inf = inner_inf.mean(dim=1)# Time 방향으로 평균\n",
    "                            # inner_inf = F.normalize(inner_inf, p=2, dim=1)\n",
    "                        spike_hidden[now_index:now_end_index] = inner_inf.cpu().detach().numpy()\n",
    "                        if SAE_net == False and converted_net_forward == True:\n",
    "                            converted_spike_hidden[now_index:now_end_index] = converted_inner_inf.cpu().detach().numpy()\n",
    "                        now_index += encoder_batch\n",
    "                        if (now_index >= len(spike)):\n",
    "                            break\n",
    "                    \n",
    "                spike_id = np.zeros(len(spike))\n",
    "                distance_sm = np.zeros(num_cluster)\n",
    "                tau = np.zeros(num_cluster)\n",
    "                \n",
    "                plot_tau = []\n",
    "                plot_denominator = []\n",
    "                plot_m = []\n",
    "                plot_max_tau = []\n",
    "                for spike_index in range(len(spike)): \n",
    "                    for q in range(num_cluster):\n",
    "                        tau[q] = np.dot(spike_hidden[spike_index, :], Cluster[q, :]) # 이거 l2norm 거쳐서 나온 거니까 분모 1임.\n",
    "                        denominator =  np.linalg.norm(spike_hidden[spike_index, :])*np.linalg.norm(Cluster[q, :]) + 1e-12\n",
    "                        plot_denominator.append(denominator)\n",
    "                        if 'SAE' in net.module.__class__.__name__: # AE 때는 l2norm거쳐서 나와서 괜찮음\n",
    "                            tau[q] = tau[q] / denominator\n",
    "\n",
    "                        plot_tau.append(tau[q])\n",
    "\n",
    "                    # for i in range(num_cluster): # l2 distance\n",
    "                    #     distance_sm[i] = np.sum(np.power(np.abs(Cluster[i] - spike_hidden[spike_index, :]), 2))\n",
    "                    distance_sm = np.sum(np.power(np.abs(Cluster - spike_hidden[spike_index, :]), 2), axis=1)\n",
    "\n",
    "                    m = np.argmin(distance_sm)\n",
    "                    plot_m.append(m)\n",
    "                    spike_id[spike_index] = m + 1\n",
    "                    # print(spike_tot[ds], spike_index,np.max(tau))\n",
    "                    plot_max_tau.append(np.max(tau))\n",
    "                    if(np.max(tau) >= cos_thr[ds] and spike_index < training_cycle): # 원래 1400 아니냐?\n",
    "                        Cluster[m] = (Cluster[m] * 15 + spike_hidden[spike_index, :])/16\n",
    "\n",
    "\n",
    "                \n",
    "                origin_kmeans_accuracy = cluster_spikes_with_accuracy_torch(features= spike, true_labels=label-1, n_clusters=3, init_point=None)\n",
    "                kmeans_accuracy = cluster_spikes_with_accuracy_torch(features= torch.tensor(spike_hidden).to(device), true_labels=label-1, n_clusters=3, init_point=None)\n",
    "                \n",
    "                # print('temporoal k')\n",
    "                # result = evaluate_clustering_accuracy(spike_hidden.reshape(spike_hidden.shape[0], TIME, -1), label-1, n_clusters=3)\n",
    "                # print('원래', kmeans_accuracy)\n",
    "                # print(result)\n",
    "\n",
    "                k_means_bin_origin_feature.append(origin_kmeans_accuracy)\n",
    "                k_means_bin.append(kmeans_accuracy)\n",
    "                if SAE_net == False and converted_net_forward == True:\n",
    "                    converted_kmeans_accuracy = cluster_spikes_with_accuracy_torch(features= torch.tensor(converted_spike_hidden).to(device), true_labels=label-1, n_clusters=3, init_point=None)\n",
    "                    converted_k_means_bin.append(converted_kmeans_accuracy)\n",
    "                # sklearn kmeans인데 cpu많이먹어서 버림.\n",
    "                # origin_kmeans_accuracy = cluster_spikes_with_accuracy(features= spike.cpu().detach().numpy(), true_labels=label-1, n_clusters=3, init_point=None)\n",
    "                # kmeans_accuracy = cluster_spikes_with_accuracy(features= spike_hidden, true_labels=label-1, n_clusters=3, init_point=None)\n",
    "                # k_means_bin_origin_feature.append(origin_kmeans_accuracy)\n",
    "                # k_means_bin.append(kmeans_accuracy)\n",
    "                # if SAE_net == False and converted_net_forward == True:\n",
    "                #     converted_kmeans_accuracy = cluster_spikes_with_accuracy(features= converted_spike_hidden, true_labels=label-1, n_clusters=3, init_point=None)\n",
    "                #     converted_k_means_bin.append(converted_kmeans_accuracy)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "                # print('Cluster',Cluster)\n",
    "                # print('spike_id', spike_id)\n",
    "\n",
    "                # spike id 분포 확인하기\n",
    "                # unique_elements, counts = np.unique(spike_id, return_counts=True)\n",
    "                # print(\"Unique elements:\", unique_elements)\n",
    "                # print(\"Counts:\", counts)\n",
    "\n",
    "                cluster_accuracy_during_training_cycle = np.zeros(math.factorial(num_cluster))\n",
    "                cluster_accuracy_post_training_cycle = np.zeros(math.factorial(num_cluster))\n",
    "                cluster_accuracy_total = np.zeros(math.factorial(num_cluster))\n",
    "                \n",
    "                label_converter_ground = list(range(1, num_cluster + 1)) # [1, 2, 3, 4] 생성\n",
    "                label_converter_permutations = list(itertools.permutations(label_converter_ground)) # 모든 순열 구하기\n",
    "                perm_i = 0\n",
    "                perm_start_time = time.time() \n",
    "                for perm in label_converter_permutations:\n",
    "                    label_converter = list(perm)\n",
    "                    # print(label_converter)\n",
    "                    correct_during_training_cycle = 0\n",
    "                    correct_post_training_cycle = 0\n",
    "\n",
    "                    assert len(spike_id) == len(label), 'spike_id랑 label 길이 같아야 됨.'\n",
    "                    for i in range(len(spike_id)):\n",
    "                        if(label_converter[int(spike_id[i]-1)] == label[i]):\n",
    "                            if i < training_cycle:\n",
    "                                correct_during_training_cycle += 1\n",
    "                            else:\n",
    "                                correct_post_training_cycle += 1\n",
    "\n",
    "                    cluster_accuracy_during_training_cycle[perm_i] = correct_during_training_cycle/training_cycle\n",
    "                    cluster_accuracy_post_training_cycle[perm_i] = correct_post_training_cycle/(len(spike_id)-training_cycle)\n",
    "                    cluster_accuracy_total[perm_i] = (correct_during_training_cycle+correct_post_training_cycle)/(len(spike_id))\n",
    "                    perm_i += 1\n",
    "                # print(f\"perm 실행 시간: {time.time()-perm_start_time:.3f}초\")\n",
    "                \n",
    "                cluster_accuracy_during_training_cycle_all_dataset[ds] = np.max(cluster_accuracy_during_training_cycle)\n",
    "                cluster_accuracy_post_training_cycle_all_dataset[ds] = cluster_accuracy_post_training_cycle[np.argmax(cluster_accuracy_during_training_cycle)]\n",
    "                cluster_accuracy_total_all_dataset[ds] = cluster_accuracy_total[np.argmax(cluster_accuracy_during_training_cycle)]\n",
    "                # plot_distributions(ds, plot_tau, plot_denominator, plot_m, plot_max_tau, cos_thr[ds],\n",
    "                #                    cluster_accuracy_during_training_cycle_all_dataset[ds], cluster_accuracy_post_training_cycle_all_dataset[ds], cluster_accuracy_total_all_dataset[ds])\n",
    "            print(f'k_means origin feature average accuracy : {100*sum(k_means_bin_origin_feature)/(len(k_means_bin_origin_feature)+1e-12):.8f}%, total {k_means_bin_origin_feature}')\n",
    "            \n",
    "            mean_cluster_accuracy_during_training_cycle_all_dataset = np.mean(cluster_accuracy_during_training_cycle_all_dataset)\n",
    "            mean_cluster_accuracy_post_training_cycle_all_dataset = np.mean(cluster_accuracy_post_training_cycle_all_dataset)\n",
    "            mean_cluster_accuracy_total_all_dataset = np.mean(cluster_accuracy_total_all_dataset)\n",
    "            \n",
    "            if SAE_net == False and converted_net_forward == True:\n",
    "                converted_k_means_acc = 100*sum(converted_k_means_bin)/len(converted_k_means_bin)\n",
    "                print(f'converted_kmeans average accuracy : {converted_k_means_acc:.8f}%, total {converted_k_means_bin}')\n",
    "            k_means_acc = 100*sum(k_means_bin)/len(k_means_bin)\n",
    "            if k_means_acc > k_means_acc_best:\n",
    "                # torch.save(net, f\"net_save/save_now_net_{current_time}.pth\")\n",
    "                torch.save(net.module.state_dict(), f\"net_save/save_now_net_{current_time}.pth\")\n",
    "                print('save model')\n",
    "                best_mean_cluster_accuracy_post_training_cycle_all_dataset = mean_cluster_accuracy_post_training_cycle_all_dataset\n",
    "            \n",
    "            k_means_acc_best = max(k_means_acc_best, k_means_acc)\n",
    "            print(f'kmeans average accuracy best : {k_means_acc_best:.2f}%, kmeans average accuracy : {k_means_acc:.8f}%, total {k_means_bin}')\n",
    "            print(f'cluster_accuracy_post_training_cycle_all_dataset : {cluster_accuracy_post_training_cycle_all_dataset}')\n",
    "\n",
    "            \n",
    "            mean_cluster_accuracy_during_training_cycle_all_dataset_history.append((epoch, mean_cluster_accuracy_during_training_cycle_all_dataset*100))\n",
    "            mean_cluster_accuracy_post_training_cycle_all_dataset_history.append((epoch, mean_cluster_accuracy_post_training_cycle_all_dataset*100))\n",
    "            mean_cluster_accuracy_total_all_dataset_history.append((epoch, mean_cluster_accuracy_total_all_dataset*100))\n",
    "            print(f\"mean_cluster_accuracy_during_training_cycle : {mean_cluster_accuracy_during_training_cycle_all_dataset*100:.2f}%, post_traincycle_acc : {mean_cluster_accuracy_post_training_cycle_all_dataset*100:.2f}%, total_acc : {mean_cluster_accuracy_total_all_dataset*100:.8f}%\")\n",
    "\n",
    "            # kmeans accuracy기준으로 좋은 거 저장할 거임\n",
    "            # if mean_cluster_accuracy_post_training_cycle_all_dataset > best_mean_cluster_accuracy_post_training_cycle_all_dataset:\n",
    "            #     # torch.save(net, f\"net_save/save_now_net_{current_time}.pth\")\n",
    "            #     torch.save(net.module.state_dict(), f\"net_save/save_now_net_{current_time}.pth\")\n",
    "            #     print('save model')\n",
    "            #     best_mean_cluster_accuracy_post_training_cycle_all_dataset = mean_cluster_accuracy_post_training_cycle_all_dataset\n",
    "            print(f\"best_mean_cluster_accuracy_post_training_cycle_all_dataset : {best_mean_cluster_accuracy_post_training_cycle_all_dataset*100:.2f}%\")\n",
    "            print(f\"accuracy_check 실행 시간: {time.time()-accuracy_check_start_time:.3f}초\")\n",
    "\n",
    "        wandb.log({\"avg_loss\": avg_loss})\n",
    "        wandb.log({\"mean_cluster_accuracy_post_training_cycle_all_dataset\": mean_cluster_accuracy_post_training_cycle_all_dataset})\n",
    "        wandb.log({\"best_mean_cluster_accuracy_post_training_cycle_all_dataset\": best_mean_cluster_accuracy_post_training_cycle_all_dataset})\n",
    "        wandb.log({\"best_mean_cluster_accuracy_post_training_cycle_all_dataset2\": best_mean_cluster_accuracy_post_training_cycle_all_dataset})\n",
    "        wandb.log({\"k_means_acc\": k_means_acc})\n",
    "        wandb.log({\"k_means_acc_best\": k_means_acc_best})\n",
    "        wandb.log({\"converted_k_means_acc\": converted_k_means_acc})\n",
    "\n",
    "\n",
    "        # 저장\n",
    "        with open(f\"result_save/cluster_accuracy_history_{current_time}.pkl\", \"wb\") as f:\n",
    "            pickle.dump({\n",
    "                \"loss_history\": loss_history,\n",
    "                \"mean_cluster_accuracy_during_training_cycle_all_dataset_history\": mean_cluster_accuracy_during_training_cycle_all_dataset_history,\n",
    "                \"mean_cluster_accuracy_post_training_cycle_all_dataset_history\": mean_cluster_accuracy_post_training_cycle_all_dataset_history,\n",
    "                \"mean_cluster_accuracy_total_all_dataset_history\": mean_cluster_accuracy_total_all_dataset_history,\n",
    "            }, f)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mbhkim003\u001b[0m (\u001b[33mbhkim003-seoul-national-university\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.19.8 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.17.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/nfs/home/bhkim003/github_folder/ByeonghyeonKim/my_snn/wandb/run-20250314_000222-9g8k42oy</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/bhkim003-seoul-national-university/spike_sorting%20just%20run/runs/9g8k42oy' target=\"_blank\">quiet-haze-1482</a></strong> to <a href='https://wandb.ai/bhkim003-seoul-national-university/spike_sorting%20just%20run' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/bhkim003-seoul-national-university/spike_sorting%20just%20run' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/spike_sorting%20just%20run</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/bhkim003-seoul-national-university/spike_sorting%20just%20run/runs/9g8k42oy' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/spike_sorting%20just%20run/runs/9g8k42oy</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'gpu': '1', 'Conv_net': True, 'SAE_net': True, 'dataset_num': 16, 'spike_length': 50, 'num_cluster': 4, 'training_cycle': 1400, 'batch_size': 32, 'max_epoch': 10000, 'learning_rate': 0.001, 'normalize_on': True, 'need_bias': False, 'lif_add_at_first': False, 'my_seed': 42, 'TIME': 50, 'v_decay': 0.5, 'v_threshold': 0.25, 'v_reset': 0.0, 'BPTT_on': True, 'SAE_hidden_nomean': True, 'current_time': '20250314_000221_115', 'optimizer': 'Adam', 'coarse_com_mode': True, 'sae_l2_norm_bridge': True, 'sae_lif_bridge': False, 'accuracy_check_epoch_term': 1, 'lif_add_at_last': False, 'two_channel_input': False, 'lateral_feature_num': 5, 'lc_adc_on': False, 'converted_net_forward': False, 'pretrained_net': None, 'vth_mul_on': False, 'batch_norm_on': False, 'l2_norm_loss_weight': 0, 'QCFS_neuron_on': False, 'quantize_level_num': 0, 'fusion_net': True, 'repeat_coding': False, 'sae_relu_on': False, 'conv1d_scaling': False, 'norm01': True, 'coarse_com_config': (0.999, -0.0)}\n",
      "cos_thr [0.95 0.95 0.95 0.95 0.95 0.95 0.95 0.85 0.95 0.9  0.8  0.95 0.95 0.95\n",
      " 0.95 0.8 ]\n",
      "conv length [50, 24, 11, 5]\n",
      "Total number of encoder parameters: 28322\n",
      "DataParallel(\n",
      "  (module): SAE_FUSION7_net_conv1(\n",
      "    (activation_function): LIF_layer()\n",
      "    (encoder): Sequential(\n",
      "      (0): SSBH_DimChanger_one_two()\n",
      "      (1): SSBH_DimChanger_for_one_two_coupling()\n",
      "      (2): Conv1d(1, 32, kernel_size=(3,), stride=(2,), bias=False)\n",
      "      (3): SSBH_DimChanger_for_one_two_decoupling()\n",
      "      (4): LIF_layer()\n",
      "      (5): SSBH_DimChanger_for_one_two_coupling()\n",
      "      (6): Conv1d(32, 64, kernel_size=(3,), stride=(2,), bias=False)\n",
      "      (7): SSBH_DimChanger_for_one_two_decoupling()\n",
      "      (8): LIF_layer()\n",
      "      (9): SSBH_DimChanger_for_one_two_coupling()\n",
      "      (10): Conv1d(64, 96, kernel_size=(3,), stride=(2,), bias=False)\n",
      "      (11): SSBH_DimChanger_for_one_two_decoupling()\n",
      "      (12): LIF_layer()\n",
      "      (13): SSBH_DimChanger_for_one_two_coupling()\n",
      "      (14): SSBH_DimChanger_for_fc()\n",
      "      (15): Linear(in_features=480, out_features=5, bias=False)\n",
      "      (16): SSBH_DimChanger_for_one_two_decoupling()\n",
      "      (17): LIF_layer()\n",
      "      (18): SSBH_DimChanger_one_two()\n",
      "      (19): SSBH_DimChanger_for_two_three_coupling()\n",
      "      (20): Linear(in_features=250, out_features=5, bias=False)\n",
      "      (21): SSBH_L2NormLayer()\n",
      "    )\n",
      "    (decoder): Sequential(\n",
      "      (0): Linear(in_features=5, out_features=480, bias=False)\n",
      "      (1): ReLU()\n",
      "      (2): SSBH_DimChanger_for_conv1()\n",
      "      (3): ConvTranspose1d(96, 64, kernel_size=(3,), stride=(2,), bias=False)\n",
      "      (4): ReLU()\n",
      "      (5): ConvTranspose1d(64, 32, kernel_size=(3,), stride=(2,), output_padding=(1,), bias=False)\n",
      "      (6): ReLU()\n",
      "      (7): ConvTranspose1d(32, 1, kernel_size=(3,), stride=(2,), output_padding=(1,), bias=False)\n",
      "    )\n",
      "  )\n",
      ")\n",
      "Device: cuda\n",
      "\n",
      "Start Training, current_time = 20250314_000221_115\n",
      "\n",
      "\n",
      "epoch-0 loss : 0.02310294, loss_normal : 0.01739275, loss_coarse : 0.07801990, min_loss : 0.02310294, min_loss_normal : 0.01739275, min_loss_coarse : 0.07801990, wrong_element_sum : 14979822.00000000, same_data : 0.00%\n",
      "ae train 실행 시간: 129.524초, 전체 시작 시간 20250314_000221_115\n",
      "\n",
      "epoch-0 accuracy check\n",
      "k_means origin feature average accuracy : 82.25492410%, total [0.9746727376209448, 0.9733106189664963, 0.9700891573195284, 0.9530800230282096, 0.943108504398827, 0.915340909090909, 0.801817648783348, 0.6622234826999432, 0.9488619568430388, 0.822215777262181, 0.5866935483870968, 0.5005858230814294, 0.9429250891795482, 0.8922588099364529, 0.673546511627907, 0.6000572573718866]\n",
      "save model\n",
      "kmeans average accuracy best : 88.94%, kmeans average accuracy : 88.94349823%, total [0.9752418895845191, 0.9772856331629756, 0.9735404083980443, 0.9605641911341393, 0.9604105571847508, 0.9522727272727273, 0.9088243916739959, 0.8247305728871243, 0.9470883830919302, 0.8790603248259861, 0.785426267281106, 0.7114821323960164, 0.9473840665873959, 0.9043905257076834, 0.8063953488372093, 0.7168622960206127]\n",
      "cluster_accuracy_post_training_cycle_all_dataset : [0.97729423 0.97690858 0.97496389 0.96335583 0.96368159 0.94858491\n",
      " 0.91546494 0.81890875 0.92284418 0.88232422 0.77027027 0.71698113\n",
      " 0.950611   0.90300679 0.81323529 0.72336359]\n",
      "mean_cluster_accuracy_during_training_cycle : 88.52%, post_traincycle_acc : 88.89%, total_acc : 88.73527504%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 88.89%\n",
      "accuracy_check 실행 시간: 24.304초\n",
      "\n",
      "\n",
      "epoch-1 loss : 0.01100380, loss_normal : 0.01376130, loss_coarse : 0.06497250, min_loss : 0.01100380, min_loss_normal : 0.01376130, min_loss_coarse : 0.06497250, wrong_element_sum : 12474720.00000000, same_data : 0.00%\n",
      "ae train 실행 시간: 127.971초, 전체 시작 시간 20250314_000221_115\n",
      "\n",
      "epoch-1 accuracy check\n",
      "k_means origin feature average accuracy : 82.26583306%, total [0.9746727376209448, 0.9733106189664963, 0.9700891573195284, 0.9530800230282096, 0.943108504398827, 0.9150568181818182, 0.801817648783348, 0.6622234826999432, 0.9488619568430388, 0.822215777262181, 0.5872695852534562, 0.5005858230814294, 0.9429250891795482, 0.8922588099364529, 0.675, 0.6000572573718866]\n",
      "save model\n",
      "kmeans average accuracy best : 90.32%, kmeans average accuracy : 90.32312826%, total [0.9760956175298805, 0.978137421919364, 0.9744032211676733, 0.9634427173287277, 0.9636363636363636, 0.9534090909090909, 0.9267077103488713, 0.8488372093023255, 0.9606857818504286, 0.9060324825986079, 0.8165322580645161, 0.7454598711189221, 0.9456004756242569, 0.9139225880993646, 0.8252906976744186, 0.7535070140280561]\n",
      "cluster_accuracy_post_training_cycle_all_dataset : [0.9782403  0.97785108 0.97544535 0.96624879 0.96666667 0.94811321\n",
      " 0.92789657 0.82314205 0.94906707 0.90722656 0.78571429 0.57894737\n",
      " 0.94297352 0.91028128 0.82598039 0.75967511]\n",
      "mean_cluster_accuracy_during_training_cycle : 88.89%, post_traincycle_acc : 88.90%, total_acc : 88.89390251%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 88.90%\n",
      "accuracy_check 실행 시간: 30.580초\n",
      "\n",
      "\n",
      "epoch-2 loss : 0.01053955, loss_normal : 0.01355219, loss_coarse : 0.06355165, min_loss : 0.01053955, min_loss_normal : 0.01355219, min_loss_coarse : 0.06355165, wrong_element_sum : 12201918.00000000, same_data : 0.00%\n",
      "ae train 실행 시간: 128.670초, 전체 시작 시간 20250314_000221_115\n",
      "\n",
      "epoch-2 accuracy check\n",
      "k_means origin feature average accuracy : 82.25492108%, total [0.9746727376209448, 0.9733106189664963, 0.9700891573195284, 0.9530800230282096, 0.943108504398827, 0.9150568181818182, 0.801817648783348, 0.6625070901871809, 0.9488619568430388, 0.822215777262181, 0.5866935483870968, 0.5005858230814294, 0.9429250891795482, 0.8922588099364529, 0.673546511627907, 0.6000572573718866]\n",
      "save model\n",
      "kmeans average accuracy best : 90.52%, kmeans average accuracy : 90.51646032%, total [0.9760956175298805, 0.9775695627484384, 0.9741156169111302, 0.9625791594703512, 0.9621700879765396, 0.9556818181818182, 0.9199648197009674, 0.8377765173000568, 0.9615725687259828, 0.9086426914153132, 0.8297811059907834, 0.7642062097246631, 0.9456004756242569, 0.9130560369728481, 0.8343023255813954, 0.7595190380761523]\n",
      "cluster_accuracy_post_training_cycle_all_dataset : [0.97729423 0.97690858 0.97496389 0.96576663 0.9641791  0.95235849\n",
      " 0.92242665 0.81702728 0.94251135 0.91162109 0.79440154 0.7408143\n",
      " 0.95162933 0.91076625 0.84019608 0.75633063]\n",
      "mean_cluster_accuracy_during_training_cycle : 89.20%, post_traincycle_acc : 89.99%, total_acc : 89.66611731%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 89.99%\n",
      "accuracy_check 실행 시간: 24.396초\n",
      "\n",
      "\n",
      "epoch-3 loss : 0.01025013, loss_normal : 0.01341773, loss_coarse : 0.06266400, min_loss : 0.01025013, min_loss_normal : 0.01341773, min_loss_coarse : 0.06266400, wrong_element_sum : 12031488.00000000, same_data : 0.00%\n",
      "ae train 실행 시간: 129.068초, 전체 시작 시간 20250314_000221_115\n",
      "\n",
      "epoch-3 accuracy check\n",
      "k_means origin feature average accuracy : 82.25135030%, total [0.9746727376209448, 0.9733106189664963, 0.9700891573195284, 0.9530800230282096, 0.943108504398827, 0.9150568181818182, 0.801817648783348, 0.6625070901871809, 0.9488619568430388, 0.822215777262181, 0.5872695852534562, 0.5002929115407148, 0.9429250891795482, 0.8922588099364529, 0.6738372093023256, 0.598912109934154]\n",
      "save model\n",
      "kmeans average accuracy best : 90.85%, kmeans average accuracy : 90.84577443%, total [0.9766647694934547, 0.9778534923339012, 0.9744032211676733, 0.9651698330454808, 0.963049853372434, 0.9551136363636363, 0.9217238346525946, 0.8471355643788996, 0.9624593556015371, 0.9135730858468677, 0.8384216589861752, 0.7656707674282367, 0.9524375743162902, 0.9196995956094743, 0.8415697674418605, 0.7603778986544517]\n",
      "cluster_accuracy_post_training_cycle_all_dataset : [0.97918638 0.97785108 0.97544535 0.96865959 0.96368159 0.94858491\n",
      " 0.92391845 0.84007526 0.94200706 0.91894531 0.80694981 0.69662363\n",
      " 0.95417515 0.91707081 0.84852941 0.76015289]\n",
      "mean_cluster_accuracy_during_training_cycle : 89.66%, post_traincycle_acc : 90.14%, total_acc : 89.94149054%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 90.14%\n",
      "accuracy_check 실행 시간: 25.077초\n",
      "\n",
      "\n",
      "epoch-4 loss : 0.01008173, loss_normal : 0.01330654, loss_coarse : 0.06201612, min_loss : 0.01008173, min_loss_normal : 0.01330654, min_loss_coarse : 0.06201612, wrong_element_sum : 11907096.00000000, same_data : 0.00%\n",
      "ae train 실행 시간: 130.041초, 전체 시작 시간 20250314_000221_115\n",
      "\n",
      "epoch-4 accuracy check\n",
      "k_means origin feature average accuracy : 82.25487806%, total [0.9746727376209448, 0.9733106189664963, 0.9700891573195284, 0.9530800230282096, 0.943108504398827, 0.9150568181818182, 0.8015244796247435, 0.6625070901871809, 0.9488619568430388, 0.822215777262181, 0.5866935483870968, 0.5005858230814294, 0.9429250891795482, 0.8922588099364529, 0.673546511627907, 0.6003435442313197]\n",
      "save model\n",
      "kmeans average accuracy best : 91.16%, kmeans average accuracy : 91.15551828%, total [0.9758110415480934, 0.9778534923339012, 0.9744032211676733, 0.9666090961427749, 0.9648093841642229, 0.95625, 0.9237760187628261, 0.8528077141236529, 0.9630505468519066, 0.9167633410672854, 0.8358294930875576, 0.7729935559461043, 0.9488703923900119, 0.9237435008665511, 0.8523255813953489, 0.7789865445176066]\n",
      "cluster_accuracy_post_training_cycle_all_dataset : [0.9782403  0.97737983 0.97544535 0.96769527 0.96616915 0.95188679\n",
      " 0.92491298 0.84713076 0.9480585  0.91894531 0.82046332 0.76017875\n",
      " 0.95417515 0.92483026 0.85784314 0.78881988]\n",
      "mean_cluster_accuracy_during_training_cycle : 90.09%, post_traincycle_acc : 91.01%, total_acc : 90.63691974%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 91.01%\n",
      "accuracy_check 실행 시간: 24.801초\n",
      "\n",
      "\n",
      "epoch-5 loss : 0.00993848, loss_normal : 0.01320366, loss_coarse : 0.06144599, min_loss : 0.00993848, min_loss_normal : 0.01320366, min_loss_coarse : 0.06144599, wrong_element_sum : 11797630.00000000, same_data : 0.00%\n",
      "ae train 실행 시간: 122.631초, 전체 시작 시간 20250314_000221_115\n",
      "\n",
      "epoch-5 accuracy check\n",
      "k_means origin feature average accuracy : 82.25667516%, total [0.9746727376209448, 0.9733106189664963, 0.9700891573195284, 0.9530800230282096, 0.943108504398827, 0.9150568181818182, 0.8015244796247435, 0.6625070901871809, 0.9488619568430388, 0.822215777262181, 0.5872695852534562, 0.5002929115407148, 0.9429250891795482, 0.8922588099364529, 0.6738372093023256, 0.6000572573718866]\n",
      "save model\n",
      "kmeans average accuracy best : 91.37%, kmeans average accuracy : 91.37426529%, total [0.9766647694934547, 0.978137421919364, 0.9746908254242163, 0.9654576856649395, 0.9651026392961877, 0.9573863636363636, 0.9237760187628261, 0.8576290414066932, 0.9668932899793083, 0.9263341067285383, 0.853110599078341, 0.7876391329818395, 0.952140309155767, 0.9269208549971115, 0.8441860465116279, 0.7638133409676496]\n",
      "cluster_accuracy_post_training_cycle_all_dataset : [0.97871334 0.97785108 0.97544535 0.96721311 0.96567164 0.95424528\n",
      " 0.9288911  0.84148636 0.96016137 0.92578125 0.81998069 0.77507448\n",
      " 0.95570265 0.92192047 0.85588235 0.77878643]\n",
      "mean_cluster_accuracy_during_training_cycle : 90.51%, post_traincycle_acc : 91.14%, total_acc : 90.88266576%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 91.14%\n",
      "accuracy_check 실행 시간: 24.821초\n",
      "\n",
      "\n",
      "epoch-6 loss : 0.00986348, loss_normal : 0.01315702, loss_coarse : 0.06109726, min_loss : 0.00986348, min_loss_normal : 0.01315702, min_loss_coarse : 0.06109726, wrong_element_sum : 11730674.00000000, same_data : 0.00%\n",
      "ae train 실행 시간: 132.280초, 전체 시작 시간 20250314_000221_115\n",
      "\n",
      "epoch-6 accuracy check\n",
      "k_means origin feature average accuracy : 82.25141437%, total [0.9746727376209448, 0.9733106189664963, 0.9700891573195284, 0.9530800230282096, 0.943108504398827, 0.9150568181818182, 0.801817648783348, 0.6622234826999432, 0.9488619568430388, 0.822215777262181, 0.5866935483870968, 0.5005858230814294, 0.9429250891795482, 0.8922588099364529, 0.6741279069767442, 0.5991983967935872]\n",
      "kmeans average accuracy best : 91.37%, kmeans average accuracy : 90.99477283%, total [0.9766647694934547, 0.978137421919364, 0.9746908254242163, 0.9651698330454808, 0.963049853372434, 0.9565340909090909, 0.9211374963353856, 0.8462847419171866, 0.966006503103754, 0.919953596287703, 0.8464861751152074, 0.776215582893966, 0.9500594530321046, 0.9214326978625073, 0.8398255813953488, 0.7575150300601202]\n",
      "cluster_accuracy_post_training_cycle_all_dataset : [0.97918638 0.97737983 0.97544535 0.96865959 0.96517413 0.9490566\n",
      " 0.92441571 0.83960489 0.96016137 0.92089844 0.81805019 0.775571\n",
      " 0.95417515 0.92240543 0.84411765 0.77830865]\n",
      "mean_cluster_accuracy_during_training_cycle : 90.26%, post_traincycle_acc : 90.95%, total_acc : 90.67137046%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 91.14%\n",
      "accuracy_check 실행 시간: 24.464초\n",
      "\n",
      "\n",
      "epoch-7 loss : 0.00976787, loss_normal : 0.01308296, loss_coarse : 0.06074364, min_loss : 0.00976787, min_loss_normal : 0.01308296, min_loss_coarse : 0.06074364, wrong_element_sum : 11662780.00000000, same_data : 0.00%\n",
      "ae train 실행 시간: 126.173초, 전체 시작 시간 20250314_000221_115\n",
      "\n",
      "epoch-7 accuracy check\n",
      "k_means origin feature average accuracy : 82.25852131%, total [0.9746727376209448, 0.9733106189664963, 0.9700891573195284, 0.9530800230282096, 0.943108504398827, 0.9150568181818182, 0.801817648783348, 0.6625070901871809, 0.9488619568430388, 0.822215777262181, 0.5872695852534562, 0.5005858230814294, 0.9429250891795482, 0.8922588099364529, 0.673546511627907, 0.6000572573718866]\n",
      "kmeans average accuracy best : 91.37%, kmeans average accuracy : 91.27648302%, total [0.9763801935116676, 0.9784213515048268, 0.9749784296807593, 0.966321243523316, 0.9653958944281525, 0.9576704545454545, 0.9249486953972442, 0.8576290414066932, 0.9657109074785694, 0.9167633410672854, 0.8536866359447005, 0.7932044522554189, 0.9497621878715814, 0.9246100519930676, 0.8386627906976745, 0.7600916117950186]\n",
      "cluster_accuracy_post_training_cycle_all_dataset : [0.97776727 0.97690858 0.97544535 0.96817743 0.96766169 0.95377358\n",
      " 0.92391845 0.8480715  0.95814423 0.92089844 0.81853282 0.70258193\n",
      " 0.950611   0.92240543 0.84901961 0.77448638]\n",
      "mean_cluster_accuracy_during_training_cycle : 89.48%, post_traincycle_acc : 90.55%, total_acc : 90.11406931%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 91.14%\n",
      "accuracy_check 실행 시간: 24.248초\n",
      "\n",
      "\n",
      "epoch-8 loss : 0.00973373, loss_normal : 0.01306647, loss_coarse : 0.06062435, min_loss : 0.00973373, min_loss_normal : 0.01306647, min_loss_coarse : 0.06062435, wrong_element_sum : 11639876.00000000, same_data : 0.00%\n",
      "ae train 실행 시간: 127.158초, 전체 시작 시간 20250314_000221_115\n",
      "\n",
      "epoch-8 accuracy check\n",
      "k_means origin feature average accuracy : 82.25850888%, total [0.9746727376209448, 0.9733106189664963, 0.9700891573195284, 0.9530800230282096, 0.943108504398827, 0.915340909090909, 0.8015244796247435, 0.6622234826999432, 0.9488619568430388, 0.822215777262181, 0.5872695852534562, 0.5005858230814294, 0.9429250891795482, 0.8922588099364529, 0.6738372093023256, 0.6000572573718866]\n",
      "kmeans average accuracy best : 91.37%, kmeans average accuracy : 91.09838881%, total [0.9763801935116676, 0.978137421919364, 0.9746908254242163, 0.966321243523316, 0.9639296187683285, 0.9588068181818182, 0.929932571093521, 0.8545093590470788, 0.9645285249778304, 0.9069025522041764, 0.8407258064516129, 0.7864674868189807, 0.9533293697978596, 0.9243212016175621, 0.8392441860465116, 0.7575150300601202]\n",
      "cluster_accuracy_post_training_cycle_all_dataset : [0.97776727 0.97832234 0.97544535 0.96817743 0.96616915 0.95471698\n",
      " 0.92590751 0.85183443 0.94452849 0.91943359 0.81370656 0.70307845\n",
      " 0.95366599 0.9199806  0.84852941 0.78929766]\n",
      "mean_cluster_accuracy_during_training_cycle : 89.65%, post_traincycle_acc : 90.57%, total_acc : 90.19385350%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 91.14%\n",
      "accuracy_check 실행 시간: 24.126초\n",
      "\n",
      "\n",
      "epoch-9 loss : 0.00965457, loss_normal : 0.01301342, loss_coarse : 0.06026726, min_loss : 0.00965457, min_loss_normal : 0.01301342, min_loss_coarse : 0.06026726, wrong_element_sum : 11571314.00000000, same_data : 0.00%\n",
      "ae train 실행 시간: 121.248초, 전체 시작 시간 20250314_000221_115\n",
      "\n",
      "epoch-9 accuracy check\n",
      "k_means origin feature average accuracy : 82.25682366%, total [0.9746727376209448, 0.9733106189664963, 0.9700891573195284, 0.9530800230282096, 0.943108504398827, 0.915340909090909, 0.801817648783348, 0.6622234826999432, 0.9488619568430388, 0.822215777262181, 0.5866935483870968, 0.5005858230814294, 0.9429250891795482, 0.8922588099364529, 0.6747093023255814, 0.5991983967935872]\n",
      "save model\n",
      "kmeans average accuracy best : 91.41%, kmeans average accuracy : 91.40584970%, total [0.9763801935116676, 0.9784213515048268, 0.9741156169111302, 0.9657455382843984, 0.9653958944281525, 0.9610795454545454, 0.931691586045148, 0.8621667612024957, 0.9677800768548626, 0.9234338747099768, 0.8548387096774194, 0.7914469830111306, 0.9518430439952438, 0.9248989023685731, 0.8447674418604652, 0.7509304322931577]\n",
      "cluster_accuracy_post_training_cycle_all_dataset : [0.97682119 0.97832234 0.97496389 0.96769527 0.96616915 0.95707547\n",
      " 0.93386375 0.855127   0.96469995 0.93115234 0.81322394 0.58639523\n",
      " 0.95570265 0.92046557 0.85343137 0.78069756]\n",
      "mean_cluster_accuracy_during_training_cycle : 90.01%, post_traincycle_acc : 90.10%, total_acc : 90.06463513%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 90.10%\n",
      "accuracy_check 실행 시간: 24.219초\n",
      "\n",
      "\n",
      "epoch-10 loss : 0.00962867, loss_normal : 0.01299615, loss_coarse : 0.06018572, min_loss : 0.00962867, min_loss_normal : 0.01299615, min_loss_coarse : 0.06018572, wrong_element_sum : 11555658.00000000, same_data : 0.00%\n",
      "ae train 실행 시간: 125.083초, 전체 시작 시간 20250314_000221_115\n",
      "\n",
      "epoch-10 accuracy check\n",
      "k_means origin feature average accuracy : 82.24062348%, total [0.9746727376209448, 0.9733106189664963, 0.9700891573195284, 0.9530800230282096, 0.943108504398827, 0.9150568181818182, 0.801817648783348, 0.6622234826999432, 0.9488619568430388, 0.822215777262181, 0.5866935483870968, 0.5005858230814294, 0.9429250891795482, 0.8922588099364529, 0.673546511627907, 0.5980532493558546]\n",
      "kmeans average accuracy best : 91.41%, kmeans average accuracy : 91.31402685%, total [0.9766647694934547, 0.978137421919364, 0.9744032211676733, 0.9666090961427749, 0.9648093841642229, 0.9585227272727272, 0.9255350337144532, 0.8593306863301191, 0.9674844812296778, 0.9216937354988399, 0.8441820276497696, 0.7870533099004101, 0.9563020214030915, 0.92894280762565, 0.8453488372093023, 0.755224735184655]\n",
      "cluster_accuracy_post_training_cycle_all_dataset : [0.9782403  0.97737983 0.97448243 0.96865959 0.96666667 0.95141509\n",
      " 0.92590751 0.85042333 0.94452849 0.92626953 0.80743243 0.56007944\n",
      " 0.96028513 0.93113482 0.85392157 0.77209747]\n",
      "mean_cluster_accuracy_during_training_cycle : 89.03%, post_traincycle_acc : 89.68%, total_acc : 89.41607649%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 90.10%\n",
      "accuracy_check 실행 시간: 25.830초\n",
      "\n",
      "\n",
      "epoch-11 loss : 0.00962682, loss_normal : 0.01296903, loss_coarse : 0.06011773, min_loss : 0.00962682, min_loss_normal : 0.01296903, min_loss_coarse : 0.06011773, wrong_element_sum : 11542604.00000000, same_data : 0.00%\n",
      "ae train 실행 시간: 127.970초, 전체 시작 시간 20250314_000221_115\n",
      "\n",
      "epoch-11 accuracy check\n",
      "k_means origin feature average accuracy : 82.24421591%, total [0.9746727376209448, 0.9733106189664963, 0.9700891573195284, 0.9530800230282096, 0.943108504398827, 0.915340909090909, 0.801817648783348, 0.6622234826999432, 0.9488619568430388, 0.822215777262181, 0.5866935483870968, 0.5005858230814294, 0.9429250891795482, 0.8922588099364529, 0.6738372093023256, 0.5980532493558546]\n",
      "kmeans average accuracy best : 91.41%, kmeans average accuracy : 91.19396942%, total [0.9763801935116676, 0.9778534923339012, 0.9741156169111302, 0.966321243523316, 0.9665689149560117, 0.9602272727272727, 0.9281735561418939, 0.8598979013045944, 0.9665976943541236, 0.9193735498839907, 0.8516705069124424, 0.7955477445811365, 0.9515457788347206, 0.9176776429809359, 0.8252906976744186, 0.7537933008874893]\n",
      "cluster_accuracy_post_training_cycle_all_dataset : [0.97776727 0.97785108 0.97544535 0.96769527 0.96666667 0.95471698\n",
      " 0.9288911  0.85183443 0.95360565 0.92431641 0.81418919 0.76961271\n",
      " 0.95417515 0.91755577 0.85686275 0.76588629]\n",
      "mean_cluster_accuracy_during_training_cycle : 90.12%, post_traincycle_acc : 90.98%, total_acc : 90.63125494%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 90.10%\n",
      "accuracy_check 실행 시간: 23.317초\n",
      "\n",
      "\n",
      "epoch-12 loss : 0.00958501, loss_normal : 0.01295135, loss_coarse : 0.05995628, min_loss : 0.00958501, min_loss_normal : 0.01295135, min_loss_coarse : 0.05995628, wrong_element_sum : 11511606.00000000, same_data : 0.00%\n",
      "ae train 실행 시간: 126.972초, 전체 시작 시간 20250314_000221_115\n",
      "\n",
      "epoch-12 accuracy check\n",
      "k_means origin feature average accuracy : 82.25672249%, total [0.9746727376209448, 0.9733106189664963, 0.9700891573195284, 0.9530800230282096, 0.943108504398827, 0.9150568181818182, 0.8015244796247435, 0.6625070901871809, 0.9488619568430388, 0.822215777262181, 0.5866935483870968, 0.5005858230814294, 0.9429250891795482, 0.8922588099364529, 0.6741279069767442, 0.6000572573718866]\n",
      "kmeans average accuracy best : 91.41%, kmeans average accuracy : 91.00679081%, total [0.9766647694934547, 0.9775695627484384, 0.9744032211676733, 0.9666090961427749, 0.9633431085043989, 0.95625, 0.9246555262386397, 0.8508224617129893, 0.9677800768548626, 0.9254640371229699, 0.8600230414746544, 0.7946690099589924, 0.952140309155767, 0.9162333911034084, 0.825, 0.7294589178356713]\n",
      "cluster_accuracy_post_training_cycle_all_dataset : [0.97871334 0.97737983 0.97544535 0.96914176 0.96517413 0.95188679\n",
      " 0.92590751 0.84571966 0.96167423 0.93310547 0.82094595 0.65839126\n",
      " 0.95213849 0.91270611 0.83186275 0.74629718]\n",
      "mean_cluster_accuracy_during_training_cycle : 89.40%, post_traincycle_acc : 90.04%, total_acc : 89.77950319%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 90.10%\n",
      "accuracy_check 실행 시간: 24.080초\n",
      "\n",
      "\n",
      "epoch-13 loss : 0.00961728, loss_normal : 0.01294702, loss_coarse : 0.06001813, min_loss : 0.00958501, min_loss_normal : 0.01294702, min_loss_coarse : 0.05995628, wrong_element_sum : 11523482.00000000, same_data : 0.00%\n",
      "ae train 실행 시간: 123.243초, 전체 시작 시간 20250314_000221_115\n",
      "\n",
      "epoch-13 accuracy check\n",
      "k_means origin feature average accuracy : 82.25504809%, total [0.9746727376209448, 0.9733106189664963, 0.9700891573195284, 0.9530800230282096, 0.943108504398827, 0.9150568181818182, 0.801817648783348, 0.6622234826999432, 0.9488619568430388, 0.822215777262181, 0.5866935483870968, 0.5005858230814294, 0.9429250891795482, 0.8922588099364529, 0.6747093023255814, 0.5991983967935872]\n",
      "kmeans average accuracy best : 91.41%, kmeans average accuracy : 90.97633190%, total [0.9766647694934547, 0.978137421919364, 0.9744032211676733, 0.9666090961427749, 0.9653958944281525, 0.959375, 0.9355027851070068, 0.8701077708451503, 0.9713272243570795, 0.9269141531322506, 0.8536866359447005, 0.7873462214411248, 0.9328180737217598, 0.902946273830156, 0.8215116279069767, 0.7334669338677354]\n",
      "cluster_accuracy_post_training_cycle_all_dataset : [0.97871334 0.97785108 0.97544535 0.96962392 0.96766169 0.95613208\n",
      " 0.93436101 0.8621825  0.9515885  0.9296875  0.81708494 0.68321748\n",
      " 0.93177189 0.90882638 0.83039216 0.76015289]\n",
      "mean_cluster_accuracy_during_training_cycle : 89.60%, post_traincycle_acc : 90.22%, total_acc : 89.96456689%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 90.10%\n",
      "accuracy_check 실행 시간: 23.479초\n",
      "\n",
      "\n",
      "epoch-14 loss : 0.00967376, loss_normal : 0.01294476, loss_coarse : 0.06014009, min_loss : 0.00958501, min_loss_normal : 0.01294476, min_loss_coarse : 0.05995628, wrong_element_sum : 11546898.00000000, same_data : 0.00%\n",
      "ae train 실행 시간: 126.165초, 전체 시작 시간 20250314_000221_115\n",
      "\n",
      "epoch-14 accuracy check\n",
      "k_means origin feature average accuracy : 82.25493782%, total [0.9746727376209448, 0.9733106189664963, 0.9700891573195284, 0.9530800230282096, 0.943108504398827, 0.9150568181818182, 0.801817648783348, 0.6625070901871809, 0.9488619568430388, 0.822215777262181, 0.586405529953917, 0.5005858230814294, 0.9429250891795482, 0.8922588099364529, 0.6738372093023256, 0.6000572573718866]\n",
      "save model\n",
      "kmeans average accuracy best : 91.48%, kmeans average accuracy : 91.47603742%, total [0.9766647694934547, 0.9784213515048268, 0.9746908254242163, 0.9668969487622338, 0.9651026392961877, 0.9582386363636364, 0.9343301084725887, 0.8766307430516166, 0.9665976943541236, 0.9234338747099768, 0.8525345622119815, 0.7911540714704159, 0.9524375743162902, 0.927787406123628, 0.8343023255813954, 0.7569424563412539]\n",
      "cluster_accuracy_post_training_cycle_all_dataset : [0.97918638 0.97785108 0.97544535 0.96914176 0.96616915 0.95471698\n",
      " 0.93485828 0.86829727 0.9515885  0.91992188 0.80550193 0.57000993\n",
      " 0.95621181 0.92919496 0.86372549 0.75919732]\n",
      "mean_cluster_accuracy_during_training_cycle : 89.79%, post_traincycle_acc : 89.88%, total_acc : 89.84616136%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 89.88%\n",
      "accuracy_check 실행 시간: 23.729초\n",
      "\n",
      "\n",
      "epoch-15 loss : 0.00960896, loss_normal : 0.01291160, loss_coarse : 0.05986713, min_loss : 0.00958501, min_loss_normal : 0.01291160, min_loss_coarse : 0.05986713, wrong_element_sum : 11494490.00000000, same_data : 0.00%\n",
      "ae train 실행 시간: 127.766초, 전체 시작 시간 20250314_000221_115\n",
      "\n",
      "epoch-15 accuracy check\n",
      "k_means origin feature average accuracy : 82.25492108%, total [0.9746727376209448, 0.9733106189664963, 0.9700891573195284, 0.9530800230282096, 0.943108504398827, 0.9150568181818182, 0.801817648783348, 0.6625070901871809, 0.9488619568430388, 0.822215777262181, 0.5866935483870968, 0.5005858230814294, 0.9429250891795482, 0.8922588099364529, 0.673546511627907, 0.6000572573718866]\n",
      "kmeans average accuracy best : 91.48%, kmeans average accuracy : 91.02150968%, total [0.9769493454752419, 0.978137421919364, 0.9741156169111302, 0.966321243523316, 0.963049853372434, 0.9565340909090909, 0.9264145411902668, 0.8556437889960294, 0.9689624593556015, 0.9222737819025522, 0.8525345622119815, 0.7876391329818395, 0.9563020214030915, 0.9237435008665511, 0.8299418604651163, 0.724878328084741]\n",
      "cluster_accuracy_post_training_cycle_all_dataset : [0.97918638 0.97879359 0.97544535 0.96865959 0.96567164 0.95283019\n",
      " 0.93137742 0.8466604  0.95713565 0.92089844 0.8257722  0.7408143\n",
      " 0.95875764 0.92531523 0.84460784 0.75824176]\n",
      "mean_cluster_accuracy_during_training_cycle : 89.11%, post_traincycle_acc : 90.81%, total_acc : 90.11680296%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 89.88%\n",
      "accuracy_check 실행 시간: 24.263초\n",
      "\n",
      "\n",
      "epoch-16 loss : 0.00956994, loss_normal : 0.01288519, loss_coarse : 0.05973124, min_loss : 0.00956994, min_loss_normal : 0.01288519, min_loss_coarse : 0.05973124, wrong_element_sum : 11468398.00000000, same_data : 0.00%\n",
      "ae train 실행 시간: 125.557초, 전체 시작 시간 20250314_000221_115\n",
      "\n",
      "epoch-16 accuracy check\n",
      "k_means origin feature average accuracy : 82.25673794%, total [0.9746727376209448, 0.9733106189664963, 0.9700891573195284, 0.9530800230282096, 0.943108504398827, 0.9150568181818182, 0.801817648783348, 0.6625070901871809, 0.9488619568430388, 0.822215777262181, 0.5866935483870968, 0.5005858230814294, 0.9429250891795482, 0.8922588099364529, 0.6738372093023256, 0.6000572573718866]\n",
      "kmeans average accuracy best : 91.48%, kmeans average accuracy : 90.89458386%, total [0.9766647694934547, 0.9778534923339012, 0.9744032211676733, 0.966321243523316, 0.9636363636363636, 0.9590909090909091, 0.9281735561418939, 0.8584798638684061, 0.964824120603015, 0.9138631090487239, 0.8467741935483871, 0.7929115407147042, 0.9512485136741974, 0.9179664933564413, 0.8183139534883721, 0.732608073289436]\n",
      "cluster_accuracy_post_training_cycle_all_dataset : [0.9782403  0.97785108 0.97544535 0.96769527 0.96517413 0.95377358\n",
      " 0.9288911  0.84995296 0.92889561 0.90869141 0.82142857 0.52730884\n",
      " 0.95315682 0.9228904  0.82745098 0.75680841]\n",
      "mean_cluster_accuracy_during_training_cycle : 89.33%, post_traincycle_acc : 89.02%, total_acc : 89.14936091%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 89.88%\n",
      "accuracy_check 실행 시간: 24.532초\n",
      "\n",
      "\n",
      "epoch-17 loss : 0.00950959, loss_normal : 0.01284911, loss_coarse : 0.05953687, min_loss : 0.00950959, min_loss_normal : 0.01284911, min_loss_coarse : 0.05953687, wrong_element_sum : 11431080.00000000, same_data : 0.00%\n",
      "ae train 실행 시간: 130.092초, 전체 시작 시간 20250314_000221_115\n",
      "\n",
      "epoch-17 accuracy check\n",
      "k_means origin feature average accuracy : 82.25125667%, total [0.9746727376209448, 0.9733106189664963, 0.9700891573195284, 0.9530800230282096, 0.943108504398827, 0.9150568181818182, 0.801817648783348, 0.6622234826999432, 0.9488619568430388, 0.822215777262181, 0.5872695852534562, 0.4997070884592853, 0.9429250891795482, 0.8922588099364529, 0.673546511627907, 0.6000572573718866]\n",
      "kmeans average accuracy best : 91.48%, kmeans average accuracy : 90.84630194%, total [0.9763801935116676, 0.9778534923339012, 0.9744032211676733, 0.9666090961427749, 0.9651026392961877, 0.9588068181818182, 0.929932571093521, 0.8533749290981282, 0.9704404374815253, 0.9187935034802784, 0.8565668202764977, 0.8005272407732865, 0.9485731272294887, 0.9145002888503755, 0.8063953488372093, 0.7171485828800458]\n",
      "cluster_accuracy_post_training_cycle_all_dataset : [0.97918638 0.97737983 0.97544535 0.96914176 0.96766169 0.95283019\n",
      " 0.92839383 0.84619003 0.96167423 0.91943359 0.8238417  0.71896723\n",
      " 0.95162933 0.90688652 0.83235294 0.71046345]\n",
      "mean_cluster_accuracy_during_training_cycle : 89.55%, post_traincycle_acc : 90.13%, total_acc : 89.89483398%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 89.88%\n",
      "accuracy_check 실행 시간: 24.418초\n",
      "\n",
      "\n",
      "epoch-18 loss : 0.00950178, loss_normal : 0.01284456, loss_coarse : 0.05953218, min_loss : 0.00950178, min_loss_normal : 0.01284456, min_loss_coarse : 0.05953218, wrong_element_sum : 11430178.00000000, same_data : 0.00%\n",
      "ae train 실행 시간: 123.233초, 전체 시작 시간 20250314_000221_115\n",
      "\n",
      "epoch-18 accuracy check\n",
      "k_means origin feature average accuracy : 82.24966347%, total [0.9746727376209448, 0.9733106189664963, 0.9700891573195284, 0.9530800230282096, 0.943108504398827, 0.9150568181818182, 0.801817648783348, 0.6625070901871809, 0.9488619568430388, 0.822215777262181, 0.5866935483870968, 0.5005858230814294, 0.9429250891795482, 0.8922588099364529, 0.6747093023255814, 0.5980532493558546]\n",
      "kmeans average accuracy best : 91.48%, kmeans average accuracy : 91.19943102%, total [0.9766647694934547, 0.9775695627484384, 0.9744032211676733, 0.9648819804260219, 0.9651026392961877, 0.9585227272727272, 0.9284667253004983, 0.8468519568916619, 0.9654153118533846, 0.9176334106728539, 0.8389976958525346, 0.7847100175746925, 0.9548156956004756, 0.9355863662622761, 0.8450581395348837, 0.7572287432006871]\n",
      "cluster_accuracy_post_training_cycle_all_dataset : [0.97965941 0.97785108 0.97544535 0.96865959 0.96567164 0.95471698\n",
      " 0.93386375 0.84242709 0.9591528  0.91748047 0.81660232 0.6266137\n",
      " 0.95621181 0.92919496 0.85539216 0.76875299]\n",
      "mean_cluster_accuracy_during_training_cycle : 89.95%, post_traincycle_acc : 90.17%, total_acc : 90.08168397%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 89.88%\n",
      "accuracy_check 실행 시간: 24.556초\n",
      "\n",
      "\n",
      "epoch-19 loss : 0.00948159, loss_normal : 0.01282370, loss_coarse : 0.05940382, min_loss : 0.00948159, min_loss_normal : 0.01282370, min_loss_coarse : 0.05940382, wrong_element_sum : 11405534.00000000, same_data : 0.00%\n",
      "ae train 실행 시간: 128.607초, 전체 시작 시간 20250314_000221_115\n",
      "\n",
      "epoch-19 accuracy check\n",
      "k_means origin feature average accuracy : 82.25498703%, total [0.9746727376209448, 0.9733106189664963, 0.9700891573195284, 0.9530800230282096, 0.943108504398827, 0.9150568181818182, 0.801817648783348, 0.6622234826999432, 0.9488619568430388, 0.822215777262181, 0.5872695852534562, 0.5005858230814294, 0.9429250891795482, 0.8922588099364529, 0.6738372093023256, 0.5994846836530203]\n",
      "kmeans average accuracy best : 91.48%, kmeans average accuracy : 91.40693398%, total [0.9766647694934547, 0.9772856331629756, 0.9746908254242163, 0.9668969487622338, 0.9671554252199414, 0.9599431818181818, 0.9349164467897977, 0.8593306863301191, 0.9710316287318947, 0.9283642691415314, 0.8580069124423964, 0.8063854715875806, 0.9503567181926278, 0.9237435008665511, 0.8337209302325581, 0.7366160893215001]\n",
      "cluster_accuracy_post_training_cycle_all_dataset : [0.97918638 0.97832234 0.97544535 0.96817743 0.96766169 0.95801887\n",
      " 0.93386375 0.84760113 0.9591528  0.93457031 0.83108108 0.79245283\n",
      " 0.94755601 0.92337536 0.85343137 0.76206402]\n",
      "mean_cluster_accuracy_during_training_cycle : 90.66%, post_traincycle_acc : 91.32%, total_acc : 91.05371007%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 89.88%\n",
      "accuracy_check 실행 시간: 24.625초\n",
      "\n",
      "\n",
      "epoch-20 loss : 0.00951003, loss_normal : 0.01283638, loss_coarse : 0.05950296, min_loss : 0.00948159, min_loss_normal : 0.01282370, min_loss_coarse : 0.05940382, wrong_element_sum : 11424568.00000000, same_data : 0.00%\n",
      "ae train 실행 시간: 126.513초, 전체 시작 시간 20250314_000221_115\n",
      "\n",
      "epoch-20 accuracy check\n",
      "k_means origin feature average accuracy : 82.25497029%, total [0.9746727376209448, 0.9733106189664963, 0.9700891573195284, 0.9530800230282096, 0.943108504398827, 0.9150568181818182, 0.801817648783348, 0.6625070901871809, 0.9488619568430388, 0.822215777262181, 0.5872695852534562, 0.5005858230814294, 0.9429250891795482, 0.8922588099364529, 0.6738372093023256, 0.5991983967935872]\n",
      "kmeans average accuracy best : 91.48%, kmeans average accuracy : 91.05153921%, total [0.9766647694934547, 0.9778534923339012, 0.9749784296807593, 0.9657455382843984, 0.9639296187683285, 0.9576704545454545, 0.9290530636177075, 0.8562110039705049, 0.9733963937333727, 0.9344547563805105, 0.8594470046082949, 0.809900410076157, 0.941141498216409, 0.9090121317157712, 0.811046511627907, 0.7277411966790724]\n",
      "cluster_accuracy_post_training_cycle_all_dataset : [0.97965941 0.97690858 0.97544535 0.96865959 0.96616915 0.95330189\n",
      " 0.92789657 0.85277516 0.9667171  0.94335938 0.83108108 0.77457795\n",
      " 0.94093686 0.9214355  0.83529412 0.75059723]\n",
      "mean_cluster_accuracy_during_training_cycle : 89.73%, post_traincycle_acc : 91.03%, total_acc : 90.49661713%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 89.88%\n",
      "accuracy_check 실행 시간: 24.682초\n",
      "\n",
      "\n",
      "epoch-21 loss : 0.00946701, loss_normal : 0.01281364, loss_coarse : 0.05939495, min_loss : 0.00946701, min_loss_normal : 0.01281364, min_loss_coarse : 0.05939495, wrong_element_sum : 11403830.00000000, same_data : 0.00%\n",
      "ae train 실행 시간: 126.889초, 전체 시작 시간 20250314_000221_115\n",
      "\n",
      "epoch-21 accuracy check\n",
      "k_means origin feature average accuracy : 82.26035621%, total [0.9746727376209448, 0.9733106189664963, 0.9700891573195284, 0.9530800230282096, 0.943108504398827, 0.9150568181818182, 0.8015244796247435, 0.6625070901871809, 0.9488619568430388, 0.822215777262181, 0.5866935483870968, 0.5005858230814294, 0.9429250891795482, 0.8922588099364529, 0.6747093023255814, 0.6000572573718866]\n",
      "kmeans average accuracy best : 91.48%, kmeans average accuracy : 91.02904681%, total [0.9769493454752419, 0.9778534923339012, 0.9749784296807593, 0.9651698330454808, 0.9648093841642229, 0.9602272727272727, 0.9290530636177075, 0.8533749290981282, 0.9716228199822643, 0.9243039443155452, 0.8487903225806451, 0.7929115407147042, 0.9461950059453033, 0.9156556903523975, 0.8244186046511628, 0.7383338104780991]\n",
      "cluster_accuracy_post_training_cycle_all_dataset : [0.97965941 0.97832234 0.97544535 0.96817743 0.96666667 0.95801887\n",
      " 0.93187469 0.84619003 0.9591528  0.92480469 0.82335907 0.74329692\n",
      " 0.94857434 0.91270611 0.83921569 0.76970855]\n",
      "mean_cluster_accuracy_during_training_cycle : 89.76%, post_traincycle_acc : 90.78%, total_acc : 90.36515229%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 89.88%\n",
      "accuracy_check 실행 시간: 24.127초\n",
      "\n",
      "\n",
      "epoch-22 loss : 0.00948308, loss_normal : 0.01281376, loss_coarse : 0.05943196, min_loss : 0.00946701, min_loss_normal : 0.01281364, min_loss_coarse : 0.05939495, wrong_element_sum : 11410936.00000000, same_data : 0.00%\n",
      "ae train 실행 시간: 123.648초, 전체 시작 시간 20250314_000221_115\n",
      "\n",
      "epoch-22 accuracy check\n",
      "k_means origin feature average accuracy : 82.25134249%, total [0.9746727376209448, 0.9733106189664963, 0.9700891573195284, 0.9530800230282096, 0.943108504398827, 0.9150568181818182, 0.801817648783348, 0.6625070901871809, 0.9488619568430388, 0.822215777262181, 0.5866935483870968, 0.5005858230814294, 0.9429250891795482, 0.8922588099364529, 0.673546511627907, 0.5994846836530203]\n",
      "kmeans average accuracy best : 91.48%, kmeans average accuracy : 91.19586793%, total [0.9766647694934547, 0.9772856331629756, 0.9749784296807593, 0.9666090961427749, 0.9636363636363636, 0.9568181818181818, 0.9293462327763119, 0.8576290414066932, 0.9713272243570795, 0.9292343387470998, 0.8603110599078341, 0.8031634446397188, 0.9441141498216409, 0.9194107452339688, 0.8284883720930233, 0.7323217864300029]\n",
      "cluster_accuracy_post_training_cycle_all_dataset : [0.97871334 0.97737983 0.97544535 0.96817743 0.96517413 0.95471698\n",
      " 0.93386375 0.85418627 0.95965709 0.93603516 0.83204633 0.73982125\n",
      " 0.94551935 0.91513094 0.84852941 0.7343526 ]\n",
      "mean_cluster_accuracy_during_training_cycle : 90.47%, post_traincycle_acc : 90.74%, total_acc : 90.63228853%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 89.88%\n",
      "accuracy_check 실행 시간: 23.603초\n",
      "\n",
      "\n",
      "epoch-23 loss : 0.00947618, loss_normal : 0.01279764, loss_coarse : 0.05933634, min_loss : 0.00946701, min_loss_normal : 0.01279764, min_loss_coarse : 0.05933634, wrong_element_sum : 11392578.00000000, same_data : 0.00%\n",
      "ae train 실행 시간: 119.332초, 전체 시작 시간 20250314_000221_115\n",
      "\n",
      "epoch-23 accuracy check\n",
      "k_means origin feature average accuracy : 82.25314853%, total [0.9746727376209448, 0.9733106189664963, 0.9700891573195284, 0.9530800230282096, 0.943108504398827, 0.9150568181818182, 0.801817648783348, 0.6622234826999432, 0.9488619568430388, 0.822215777262181, 0.5866935483870968, 0.5005858230814294, 0.9429250891795482, 0.8922588099364529, 0.673546511627907, 0.6000572573718866]\n",
      "kmeans average accuracy best : 91.48%, kmeans average accuracy : 90.59621956%, total [0.9763801935116676, 0.9778534923339012, 0.9749784296807593, 0.9660333909038572, 0.9656891495601173, 0.95625, 0.9302257402521255, 0.8482699943278502, 0.9651197162281998, 0.9263341067285383, 0.8421658986175116, 0.7847100175746925, 0.9479785969084423, 0.9110340843443097, 0.8046511627906977, 0.7177211565989121]\n",
      "cluster_accuracy_post_training_cycle_all_dataset : [0.97965941 0.97832234 0.97544535 0.96865959 0.96716418 0.95471698\n",
      " 0.9288911  0.84007526 0.95410993 0.92675781 0.82094595 0.54419067\n",
      " 0.95264766 0.91367604 0.83039216 0.73530817]\n",
      "mean_cluster_accuracy_during_training_cycle : 88.84%, post_traincycle_acc : 89.19%, total_acc : 89.04957820%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 89.88%\n",
      "accuracy_check 실행 시간: 22.900초\n",
      "\n",
      "\n",
      "epoch-24 loss : 0.00943685, loss_normal : 0.01278798, loss_coarse : 0.05929659, min_loss : 0.00943685, min_loss_normal : 0.01278798, min_loss_coarse : 0.05929659, wrong_element_sum : 11384946.00000000, same_data : 0.00%\n",
      "ae train 실행 시간: 125.634초, 전체 시작 시간 20250314_000221_115\n",
      "\n",
      "epoch-24 accuracy check\n",
      "k_means origin feature average accuracy : 82.24956994%, total [0.9746727376209448, 0.9733106189664963, 0.9700891573195284, 0.9530800230282096, 0.943108504398827, 0.9150568181818182, 0.801817648783348, 0.6622234826999432, 0.9488619568430388, 0.822215777262181, 0.5866935483870968, 0.5005858230814294, 0.9429250891795482, 0.8922588099364529, 0.673546511627907, 0.5994846836530203]\n",
      "kmeans average accuracy best : 91.48%, kmeans average accuracy : 91.41349994%, total [0.9766647694934547, 0.9775695627484384, 0.9752660339373023, 0.9666090961427749, 0.9648093841642229, 0.959659090909091, 0.929932571093521, 0.8630175836642088, 0.9733963937333727, 0.9312645011600929, 0.8554147465437788, 0.8040421792618629, 0.9497621878715814, 0.9240323512420566, 0.8395348837209302, 0.7351846550243344]\n",
      "cluster_accuracy_post_training_cycle_all_dataset : [0.97918638 0.97737983 0.97496389 0.96865959 0.96567164 0.95518868\n",
      " 0.93436101 0.855127   0.96520424 0.93017578 0.83783784 0.56752731\n",
      " 0.95162933 0.92628516 0.84509804 0.77018634]\n",
      "mean_cluster_accuracy_during_training_cycle : 89.50%, post_traincycle_acc : 90.03%, total_acc : 89.81376815%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 89.88%\n",
      "accuracy_check 실행 시간: 23.437초\n",
      "\n",
      "\n",
      "epoch-25 loss : 0.00942372, loss_normal : 0.01277731, loss_coarse : 0.05924633, min_loss : 0.00942372, min_loss_normal : 0.01277731, min_loss_coarse : 0.05924633, wrong_element_sum : 11375296.00000000, same_data : 0.00%\n",
      "ae train 실행 시간: 122.165초, 전체 시작 시간 20250314_000221_115\n",
      "\n",
      "epoch-25 accuracy check\n",
      "k_means origin feature average accuracy : 82.24414230%, total [0.9746727376209448, 0.9733106189664963, 0.9700891573195284, 0.9530800230282096, 0.943108504398827, 0.9150568181818182, 0.8015244796247435, 0.6625070901871809, 0.9488619568430388, 0.822215777262181, 0.5866935483870968, 0.5005858230814294, 0.9429250891795482, 0.8922588099364529, 0.673546511627907, 0.5986258230747209]\n",
      "kmeans average accuracy best : 91.48%, kmeans average accuracy : 90.95397163%, total [0.9763801935116676, 0.9778534923339012, 0.9752660339373023, 0.9654576856649395, 0.9648093841642229, 0.9556818181818182, 0.9302257402521255, 0.8545093590470788, 0.9674844812296778, 0.9332946635730859, 0.8626152073732719, 0.7973052138254247, 0.9527348394768134, 0.915944540727903, 0.8130813953488372, 0.709991411394217]\n",
      "cluster_accuracy_post_training_cycle_all_dataset : [0.97871334 0.97737983 0.97496389 0.96769527 0.96517413 0.95471698\n",
      " 0.93336648 0.85465663 0.96318709 0.93164062 0.84314672 0.73088381\n",
      " 0.95213849 0.91416101 0.84264706 0.75585284]\n",
      "mean_cluster_accuracy_during_training_cycle : 89.75%, post_traincycle_acc : 90.88%, total_acc : 90.41655301%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 89.88%\n",
      "accuracy_check 실행 시간: 24.196초\n",
      "\n",
      "\n",
      "epoch-26 loss : 0.00946907, loss_normal : 0.01278269, loss_coarse : 0.05932524, min_loss : 0.00942372, min_loss_normal : 0.01277731, min_loss_coarse : 0.05924633, wrong_element_sum : 11390446.00000000, same_data : 0.00%\n",
      "ae train 실행 시간: 120.455초, 전체 시작 시간 20250314_000221_115\n",
      "\n",
      "epoch-26 accuracy check\n",
      "k_means origin feature average accuracy : 82.24958206%, total [0.9746727376209448, 0.9733106189664963, 0.9700891573195284, 0.9530800230282096, 0.943108504398827, 0.9150568181818182, 0.8015244796247435, 0.6622234826999432, 0.9488619568430388, 0.822215777262181, 0.5866935483870968, 0.5005858230814294, 0.9429250891795482, 0.8922588099364529, 0.6741279069767442, 0.5991983967935872]\n",
      "kmeans average accuracy best : 91.48%, kmeans average accuracy : 91.10347588%, total [0.9763801935116676, 0.9775695627484384, 0.9749784296807593, 0.9666090961427749, 0.964516129032258, 0.9579545454545455, 0.9322779243623571, 0.861883153715258, 0.9609813774756134, 0.9196635730858469, 0.8467741935483871, 0.7905682483889865, 0.9536266349583828, 0.9312536106296938, 0.8375, 0.7240194675064414]\n",
      "cluster_accuracy_post_training_cycle_all_dataset : [0.97918638 0.97737983 0.97544535 0.96914176 0.96616915 0.95424528\n",
      " 0.93535554 0.85418627 0.95057993 0.90917969 0.83397683 0.56653426\n",
      " 0.95570265 0.92677013 0.84313725 0.75346393]\n",
      "mean_cluster_accuracy_during_training_cycle : 89.56%, post_traincycle_acc : 89.69%, total_acc : 89.63855905%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 89.88%\n",
      "accuracy_check 실행 시간: 24.812초\n",
      "\n",
      "\n",
      "epoch-27 loss : 0.00946971, loss_normal : 0.01277812, loss_coarse : 0.05933748, min_loss : 0.00942372, min_loss_normal : 0.01277731, min_loss_coarse : 0.05924633, wrong_element_sum : 11392796.00000000, same_data : 0.00%\n",
      "ae train 실행 시간: 127.493초, 전체 시작 시간 20250314_000221_115\n",
      "\n",
      "epoch-27 accuracy check\n",
      "k_means origin feature average accuracy : 82.26042087%, total [0.9746727376209448, 0.9733106189664963, 0.9700891573195284, 0.9530800230282096, 0.943108504398827, 0.9150568181818182, 0.801817648783348, 0.6625070901871809, 0.9488619568430388, 0.822215777262181, 0.5872695852534562, 0.5005858230814294, 0.9429250891795482, 0.8922588099364529, 0.6747093023255814, 0.5991983967935872]\n",
      "kmeans average accuracy best : 91.48%, kmeans average accuracy : 90.75403634%, total [0.9766647694934547, 0.978137421919364, 0.9746908254242163, 0.9660333909038572, 0.9624633431085043, 0.959375, 0.9313984168865436, 0.8533749290981282, 0.9704404374815253, 0.9295243619489559, 0.8485023041474654, 0.7888107791446983, 0.9524375743162902, 0.91421143847487, 0.8005813953488372, 0.7139994274262811]\n",
      "cluster_accuracy_post_training_cycle_all_dataset : [0.97918638 0.97785108 0.97544535 0.96865959 0.96567164 0.95566038\n",
      " 0.93485828 0.83960489 0.96923853 0.92919922 0.8277027  0.46077458\n",
      " 0.95417515 0.90834142 0.8254902  0.75059723]\n",
      "mean_cluster_accuracy_during_training_cycle : 88.96%, post_traincycle_acc : 88.89%, total_acc : 88.92244155%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 89.88%\n",
      "accuracy_check 실행 시간: 24.456초\n",
      "\n",
      "\n",
      "epoch-28 loss : 0.00944595, loss_normal : 0.01276477, loss_coarse : 0.05927176, min_loss : 0.00942372, min_loss_normal : 0.01276477, min_loss_coarse : 0.05924633, wrong_element_sum : 11380178.00000000, same_data : 0.00%\n",
      "ae train 실행 시간: 127.625초, 전체 시작 시간 20250314_000221_115\n",
      "\n",
      "epoch-28 accuracy check\n",
      "k_means origin feature average accuracy : 82.25670206%, total [0.9746727376209448, 0.9733106189664963, 0.9700891573195284, 0.9530800230282096, 0.943108504398827, 0.9150568181818182, 0.801817648783348, 0.6622234826999432, 0.9488619568430388, 0.8216357308584686, 0.5872695852534562, 0.5005858230814294, 0.9429250891795482, 0.8922588099364529, 0.673546511627907, 0.600629831090753]\n",
      "kmeans average accuracy best : 91.48%, kmeans average accuracy : 91.01815392%, total [0.9766647694934547, 0.978137421919364, 0.9744032211676733, 0.966321243523316, 0.9648093841642229, 0.9573863636363636, 0.9308120785693345, 0.8545093590470788, 0.9677800768548626, 0.9283642691415314, 0.8591589861751152, 0.7958406561218512, 0.9450059453032105, 0.91421143847487, 0.8188953488372093, 0.7306040652734039]\n",
      "cluster_accuracy_post_training_cycle_all_dataset : [0.97918638 0.97785108 0.97496389 0.96769527 0.96517413 0.95283019\n",
      " 0.93535554 0.8593603  0.9591528  0.93212891 0.82915058 0.70854022\n",
      " 0.94959267 0.91513094 0.82107843 0.73817487]\n",
      "mean_cluster_accuracy_during_training_cycle : 89.80%, post_traincycle_acc : 90.41%, total_acc : 90.16024949%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 89.88%\n",
      "accuracy_check 실행 시간: 24.471초\n",
      "\n",
      "\n",
      "epoch-29 loss : 0.00942492, loss_normal : 0.01276136, loss_coarse : 0.05919725, min_loss : 0.00942372, min_loss_normal : 0.01276136, min_loss_coarse : 0.05919725, wrong_element_sum : 11365872.00000000, same_data : 0.00%\n",
      "ae train 실행 시간: 127.464초, 전체 시작 시간 20250314_000221_115\n",
      "\n",
      "epoch-29 accuracy check\n",
      "k_means origin feature average accuracy : 82.26216225%, total [0.9746727376209448, 0.9733106189664963, 0.9700891573195284, 0.9530800230282096, 0.943108504398827, 0.9150568181818182, 0.8015244796247435, 0.6622234826999432, 0.9488619568430388, 0.822215777262181, 0.5866935483870968, 0.5005858230814294, 0.9429250891795482, 0.8922588099364529, 0.6747093023255814, 0.600629831090753]\n",
      "kmeans average accuracy best : 91.48%, kmeans average accuracy : 90.88208674%, total [0.9769493454752419, 0.9778534923339012, 0.9749784296807593, 0.9657455382843984, 0.9636363636363636, 0.95625, 0.9296394019349165, 0.8511060692002269, 0.9665976943541236, 0.9274941995359629, 0.8580069124423964, 0.7996485061511424, 0.9530321046373365, 0.9196995956094743, 0.8130813953488372, 0.7074148296593187]\n",
      "cluster_accuracy_post_training_cycle_all_dataset : [0.97965941 0.97785108 0.97496389 0.96817743 0.96517413 0.95283019\n",
      " 0.93386375 0.855127   0.96066566 0.92529297 0.83542471 0.69116187\n",
      " 0.95570265 0.91464597 0.84313725 0.74438605]\n",
      "mean_cluster_accuracy_during_training_cycle : 89.32%, post_traincycle_acc : 90.49%, total_acc : 90.01205784%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 89.88%\n",
      "accuracy_check 실행 시간: 24.485초\n",
      "\n",
      "\n",
      "epoch-30 loss : 0.00941119, loss_normal : 0.01275133, loss_coarse : 0.05914189, min_loss : 0.00941119, min_loss_normal : 0.01275133, min_loss_coarse : 0.05914189, wrong_element_sum : 11355244.00000000, same_data : 0.00%\n",
      "ae train 실행 시간: 128.468초, 전체 시작 시간 20250314_000221_115\n",
      "\n",
      "epoch-30 accuracy check\n",
      "k_means origin feature average accuracy : 82.26041597%, total [0.9746727376209448, 0.9733106189664963, 0.9700891573195284, 0.9530800230282096, 0.943108504398827, 0.9150568181818182, 0.801817648783348, 0.6622234826999432, 0.9488619568430388, 0.822215777262181, 0.5866935483870968, 0.5005858230814294, 0.9429250891795482, 0.8922588099364529, 0.6747093023255814, 0.6000572573718866]\n",
      "kmeans average accuracy best : 91.48%, kmeans average accuracy : 90.43594958%, total [0.9769493454752419, 0.9784213515048268, 0.9746908254242163, 0.9694876223373633, 0.9642228739002933, 0.95625, 0.9313984168865436, 0.8505388542257516, 0.9677800768548626, 0.9228538283062645, 0.8444700460829493, 0.789103690685413, 0.9482758620689655, 0.9032351242056614, 0.788953488372093, 0.7031205267678213]\n",
      "cluster_accuracy_post_training_cycle_all_dataset : [0.97965941 0.97832234 0.97496389 0.96962392 0.96567164 0.95424528\n",
      " 0.93137742 0.85277516 0.95814423 0.92333984 0.81515444 0.51191658\n",
      " 0.94399185 0.90591659 0.81715686 0.72718586]\n",
      "mean_cluster_accuracy_during_training_cycle : 89.00%, post_traincycle_acc : 88.81%, total_acc : 88.88772091%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 89.88%\n",
      "accuracy_check 실행 시간: 24.583초\n",
      "\n",
      "\n",
      "epoch-31 loss : 0.00940975, loss_normal : 0.01273763, loss_coarse : 0.05913530, min_loss : 0.00940975, min_loss_normal : 0.01273763, min_loss_coarse : 0.05913530, wrong_element_sum : 11353978.00000000, same_data : 0.00%\n",
      "ae train 실행 시간: 131.005초, 전체 시작 시간 20250314_000221_115\n",
      "\n",
      "epoch-31 accuracy check\n",
      "k_means origin feature average accuracy : 82.25319774%, total [0.9746727376209448, 0.9733106189664963, 0.9700891573195284, 0.9530800230282096, 0.943108504398827, 0.9150568181818182, 0.801817648783348, 0.6622234826999432, 0.9488619568430388, 0.822215777262181, 0.5872695852534562, 0.5005858230814294, 0.9429250891795482, 0.8922588099364529, 0.6738372093023256, 0.5991983967935872]\n",
      "kmeans average accuracy best : 91.48%, kmeans average accuracy : 90.83657002%, total [0.9769493454752419, 0.9778534923339012, 0.9749784296807593, 0.9645941278065631, 0.9653958944281525, 0.959659090909091, 0.931691586045148, 0.861883153715258, 0.947383978717115, 0.921983758700696, 0.8508064516129032, 0.7975981253661394, 0.9476813317479191, 0.9119006354708261, 0.8191860465116279, 0.7243057543658746]\n",
      "cluster_accuracy_post_training_cycle_all_dataset : [0.97918638 0.97785108 0.97496389 0.96673095 0.96766169 0.95566038\n",
      " 0.93635007 0.85324553 0.92788704 0.92578125 0.83156371 0.74180735\n",
      " 0.9490835  0.90979631 0.83676471 0.70998567]\n",
      "mean_cluster_accuracy_during_training_cycle : 89.21%, post_traincycle_acc : 90.28%, total_acc : 89.83860545%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 89.88%\n",
      "accuracy_check 실행 시간: 24.367초\n",
      "\n",
      "\n",
      "epoch-32 loss : 0.00938564, loss_normal : 0.01274503, loss_coarse : 0.05909125, min_loss : 0.00938564, min_loss_normal : 0.01273763, min_loss_coarse : 0.05909125, wrong_element_sum : 11345520.00000000, same_data : 0.00%\n",
      "ae train 실행 시간: 124.718초, 전체 시작 시간 20250314_000221_115\n",
      "\n",
      "epoch-32 accuracy check\n",
      "k_means origin feature average accuracy : 82.26218852%, total [0.9746727376209448, 0.9733106189664963, 0.9700891573195284, 0.9530800230282096, 0.943108504398827, 0.9150568181818182, 0.801817648783348, 0.6625070901871809, 0.9488619568430388, 0.822215777262181, 0.5866935483870968, 0.5005858230814294, 0.9429250891795482, 0.8922588099364529, 0.6747093023255814, 0.6000572573718866]\n",
      "kmeans average accuracy best : 91.48%, kmeans average accuracy : 90.86646749%, total [0.9769493454752419, 0.9778534923339012, 0.9746908254242163, 0.9657455382843984, 0.9656891495601173, 0.9545454545454546, 0.931105247727939, 0.8519568916619399, 0.9686668637304168, 0.929814385150812, 0.8536866359447005, 0.8031634446397188, 0.9497621878715814, 0.9145002888503755, 0.8136627906976744, 0.7068422559404524]\n",
      "cluster_accuracy_post_training_cycle_all_dataset : [0.97965941 0.97785108 0.97496389 0.96721311 0.96666667 0.9504717\n",
      " 0.92491298 0.8494826  0.96369138 0.93115234 0.8238417  0.61171797\n",
      " 0.94857434 0.91610087 0.82892157 0.73960822]\n",
      "mean_cluster_accuracy_during_training_cycle : 89.21%, post_traincycle_acc : 89.72%, total_acc : 89.51050194%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 89.88%\n",
      "accuracy_check 실행 시간: 29.991초\n",
      "\n",
      "\n",
      "epoch-33 loss : 0.00937494, loss_normal : 0.01273842, loss_coarse : 0.05904974, min_loss : 0.00937494, min_loss_normal : 0.01273763, min_loss_coarse : 0.05904974, wrong_element_sum : 11337550.00000000, same_data : 0.00%\n",
      "ae train 실행 시간: 132.941초, 전체 시작 시간 20250314_000221_115\n",
      "\n",
      "epoch-33 accuracy check\n",
      "k_means origin feature average accuracy : 82.25852131%, total [0.9746727376209448, 0.9733106189664963, 0.9700891573195284, 0.9530800230282096, 0.943108504398827, 0.9150568181818182, 0.801817648783348, 0.6625070901871809, 0.9488619568430388, 0.822215777262181, 0.5872695852534562, 0.5005858230814294, 0.9429250891795482, 0.8922588099364529, 0.673546511627907, 0.6000572573718866]\n",
      "kmeans average accuracy best : 91.48%, kmeans average accuracy : 90.96475494%, total [0.9766647694934547, 0.9778534923339012, 0.9749784296807593, 0.9666090961427749, 0.964516129032258, 0.9582386363636364, 0.9313984168865436, 0.8579126488939308, 0.967188885604493, 0.9243039443155452, 0.8585829493087558, 0.7981839484475688, 0.9512485136741974, 0.915944540727903, 0.8087209302325581, 0.7220154594904094]\n",
      "cluster_accuracy_post_training_cycle_all_dataset : [0.97871334 0.97832234 0.97496389 0.96865959 0.96666667 0.95518868\n",
      " 0.92541024 0.86171214 0.95814423 0.92285156 0.83735521 0.7060576\n",
      " 0.95366599 0.91610087 0.83382353 0.74677496]\n",
      "mean_cluster_accuracy_during_training_cycle : 89.42%, post_traincycle_acc : 90.53%, total_acc : 90.07263844%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 89.88%\n",
      "accuracy_check 실행 시간: 23.651초\n",
      "\n",
      "\n",
      "epoch-34 loss : 0.00938967, loss_normal : 0.01273978, loss_coarse : 0.05913294, min_loss : 0.00937494, min_loss_normal : 0.01273763, min_loss_coarse : 0.05904974, wrong_element_sum : 11353524.00000000, same_data : 0.00%\n",
      "ae train 실행 시간: 124.484초, 전체 시작 시간 20250314_000221_115\n",
      "\n",
      "epoch-34 accuracy check\n",
      "k_means origin feature average accuracy : 82.24418371%, total [0.9746727376209448, 0.9733106189664963, 0.9700891573195284, 0.9530800230282096, 0.943108504398827, 0.915340909090909, 0.8015244796247435, 0.6625070901871809, 0.9488619568430388, 0.822215777262181, 0.5866935483870968, 0.5005858230814294, 0.9429250891795482, 0.8922588099364529, 0.6741279069767442, 0.5977669624964214]\n",
      "kmeans average accuracy best : 91.48%, kmeans average accuracy : 91.04758459%, total [0.9769493454752419, 0.978137421919364, 0.9749784296807593, 0.9640184225676454, 0.9659824046920821, 0.9585227272727272, 0.9313984168865436, 0.8630175836642088, 0.9736919893585575, 0.931554524361949, 0.8551267281105991, 0.7981839484475688, 0.9503567181926278, 0.9179664933564413, 0.8180232558139535, 0.7097051245347838]\n",
      "cluster_accuracy_post_training_cycle_all_dataset : [0.97918638 0.97832234 0.97448243 0.96721311 0.96716418 0.95566038\n",
      " 0.93684734 0.8635936  0.96722138 0.92382812 0.81949807 0.57298908\n",
      " 0.95264766 0.91513094 0.8495098  0.73960822]\n",
      "mean_cluster_accuracy_during_training_cycle : 89.54%, post_traincycle_acc : 89.77%, total_acc : 89.67534892%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 89.88%\n",
      "accuracy_check 실행 시간: 22.638초\n",
      "\n",
      "\n",
      "epoch-35 loss : 0.00936273, loss_normal : 0.01271451, loss_coarse : 0.05898760, min_loss : 0.00936273, min_loss_normal : 0.01271451, min_loss_coarse : 0.05898760, wrong_element_sum : 11325620.00000000, same_data : 0.00%\n",
      "ae train 실행 시간: 126.624초, 전체 시작 시간 20250314_000221_115\n",
      "\n",
      "epoch-35 accuracy check\n",
      "k_means origin feature average accuracy : 82.24056372%, total [0.9746727376209448, 0.9733106189664963, 0.9700891573195284, 0.9530800230282096, 0.943108504398827, 0.9150568181818182, 0.8015244796247435, 0.6625070901871809, 0.9488619568430388, 0.822215777262181, 0.5866935483870968, 0.5005858230814294, 0.9429250891795482, 0.8922588099364529, 0.673546511627907, 0.5980532493558546]\n",
      "kmeans average accuracy best : 91.48%, kmeans average accuracy : 90.70356914%, total [0.9766647694934547, 0.978137421919364, 0.9744032211676733, 0.9657455382843984, 0.9648093841642229, 0.959659090909091, 0.9325710935209616, 0.8539421440726035, 0.9674844812296778, 0.9245939675174014, 0.8467741935483871, 0.7855887521968365, 0.9509512485136742, 0.91421143847487, 0.8113372093023256, 0.7056971085027197]\n",
      "cluster_accuracy_post_training_cycle_all_dataset : [0.97871334 0.97785108 0.97496389 0.96865959 0.96716418 0.95518868\n",
      " 0.9373446  0.85183443 0.95612708 0.92773438 0.83108108 0.52234359\n",
      " 0.95213849 0.91076625 0.82107843 0.72097468]\n",
      "mean_cluster_accuracy_during_training_cycle : 89.13%, post_traincycle_acc : 89.09%, total_acc : 89.10478617%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 89.88%\n",
      "accuracy_check 실행 시간: 23.302초\n",
      "\n",
      "\n",
      "epoch-36 loss : 0.00936154, loss_normal : 0.01272090, loss_coarse : 0.05896501, min_loss : 0.00936154, min_loss_normal : 0.01271451, min_loss_coarse : 0.05896501, wrong_element_sum : 11321282.00000000, same_data : 0.00%\n",
      "ae train 실행 시간: 128.157초, 전체 시작 시간 20250314_000221_115\n",
      "\n",
      "epoch-36 accuracy check\n",
      "k_means origin feature average accuracy : 82.24413350%, total [0.9746727376209448, 0.9733106189664963, 0.9700891573195284, 0.9530800230282096, 0.943108504398827, 0.9150568181818182, 0.801817648783348, 0.6622234826999432, 0.9488619568430388, 0.822215777262181, 0.5866935483870968, 0.5005858230814294, 0.9429250891795482, 0.89052570768342, 0.6738372093023256, 0.6000572573718866]\n",
      "kmeans average accuracy best : 91.48%, kmeans average accuracy : 90.77774508%, total [0.9766647694934547, 0.978137421919364, 0.9752660339373023, 0.9657455382843984, 0.9653958944281525, 0.9588068181818182, 0.9287598944591029, 0.8593306863301191, 0.9642329293526456, 0.9106728538283063, 0.8467741935483871, 0.7981839484475688, 0.9470868014268727, 0.9145002888503755, 0.8177325581395349, 0.7171485828800458]\n",
      "cluster_accuracy_post_training_cycle_all_dataset : [0.97918638 0.97832234 0.97496389 0.96865959 0.96616915 0.95518868\n",
      " 0.93088016 0.85559737 0.94604135 0.90478516 0.82722008 0.44736842\n",
      " 0.94704684 0.91610087 0.83431373 0.74534161]\n",
      "mean_cluster_accuracy_during_training_cycle : 89.38%, post_traincycle_acc : 88.61%, total_acc : 88.92544331%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 89.88%\n",
      "accuracy_check 실행 시간: 23.840초\n",
      "\n",
      "\n",
      "epoch-37 loss : 0.00937898, loss_normal : 0.01272030, loss_coarse : 0.05904608, min_loss : 0.00936154, min_loss_normal : 0.01271451, min_loss_coarse : 0.05896501, wrong_element_sum : 11336848.00000000, same_data : 0.00%\n",
      "ae train 실행 시간: 126.177초, 전체 시작 시간 20250314_000221_115\n",
      "\n",
      "epoch-37 accuracy check\n",
      "k_means origin feature average accuracy : 82.26034660%, total [0.9746727376209448, 0.9733106189664963, 0.9700891573195284, 0.9530800230282096, 0.943108504398827, 0.9150568181818182, 0.801817648783348, 0.6625070901871809, 0.9488619568430388, 0.8216357308584686, 0.5872695852534562, 0.5005858230814294, 0.9429250891795482, 0.8922588099364529, 0.6744186046511628, 0.6000572573718866]\n",
      "kmeans average accuracy best : 91.48%, kmeans average accuracy : 91.21457193%, total [0.9769493454752419, 0.9778534923339012, 0.9744032211676733, 0.9634427173287277, 0.9642228739002933, 0.9585227272727272, 0.9308120785693345, 0.8633011911514464, 0.969553650605971, 0.9318445475638051, 0.8594470046082949, 0.8040421792618629, 0.9485731272294887, 0.9173887926054304, 0.8308139534883721, 0.723160606928142]\n",
      "cluster_accuracy_post_training_cycle_all_dataset : [0.97918638 0.97832234 0.97496389 0.96817743 0.96716418 0.95188679\n",
      " 0.93237195 0.85747883 0.96167423 0.9296875  0.8257722  0.6876862\n",
      " 0.95366599 0.92046557 0.84852941 0.69804109]\n",
      "mean_cluster_accuracy_during_training_cycle : 89.72%, post_traincycle_acc : 90.22%, total_acc : 90.01161965%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 89.88%\n",
      "accuracy_check 실행 시간: 24.236초\n",
      "\n",
      "\n",
      "epoch-38 loss : 0.00934051, loss_normal : 0.01270044, loss_coarse : 0.05893252, min_loss : 0.00934051, min_loss_normal : 0.01270044, min_loss_coarse : 0.05893252, wrong_element_sum : 11315044.00000000, same_data : 0.00%\n",
      "ae train 실행 시간: 128.129초, 전체 시작 시간 20250314_000221_115\n",
      "\n",
      "epoch-38 accuracy check\n",
      "k_means origin feature average accuracy : 82.24607406%, total [0.9746727376209448, 0.9733106189664963, 0.9700891573195284, 0.9530800230282096, 0.943108504398827, 0.9150568181818182, 0.801817648783348, 0.6622234826999432, 0.9488619568430388, 0.822215777262181, 0.5866935483870968, 0.5005858230814294, 0.9429250891795482, 0.8922588099364529, 0.6744186046511628, 0.5980532493558546]\n",
      "kmeans average accuracy best : 91.48%, kmeans average accuracy : 90.91255053%, total [0.9769493454752419, 0.9778534923339012, 0.9744032211676733, 0.9651698330454808, 0.9639296187683285, 0.9582386363636364, 0.9272940486660803, 0.8550765740215541, 0.967188885604493, 0.9228538283062645, 0.8536866359447005, 0.8081429408318688, 0.9467895362663495, 0.9121894858463316, 0.8130813953488372, 0.723160606928142]\n",
      "cluster_accuracy_post_training_cycle_all_dataset : [0.97965941 0.97832234 0.97496389 0.96769527 0.96666667 0.95471698\n",
      " 0.92839383 0.84901223 0.96520424 0.92529297 0.82480695 0.73733863\n",
      " 0.94653768 0.91222114 0.82892157 0.74534161]\n",
      "mean_cluster_accuracy_during_training_cycle : 89.77%, post_traincycle_acc : 90.53%, total_acc : 90.21870502%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 89.88%\n",
      "accuracy_check 실행 시간: 24.005초\n",
      "\n",
      "\n",
      "epoch-39 loss : 0.00934413, loss_normal : 0.01270040, loss_coarse : 0.05891249, min_loss : 0.00934051, min_loss_normal : 0.01270040, min_loss_coarse : 0.05891249, wrong_element_sum : 11311198.00000000, same_data : 0.00%\n",
      "ae train 실행 시간: 92.786초, 전체 시작 시간 20250314_000221_115\n",
      "\n",
      "epoch-39 accuracy check\n",
      "k_means origin feature average accuracy : 82.25672249%, total [0.9746727376209448, 0.9733106189664963, 0.9700891573195284, 0.9530800230282096, 0.943108504398827, 0.9150568181818182, 0.8015244796247435, 0.6625070901871809, 0.9488619568430388, 0.822215777262181, 0.5866935483870968, 0.5005858230814294, 0.9429250891795482, 0.8922588099364529, 0.6741279069767442, 0.6000572573718866]\n",
      "kmeans average accuracy best : 91.48%, kmeans average accuracy : 91.00961866%, total [0.9766647694934547, 0.978137421919364, 0.9749784296807593, 0.9643062751871042, 0.964516129032258, 0.9590909090909091, 0.9343301084725887, 0.8650028360748724, 0.9665976943541236, 0.9245939675174014, 0.8554147465437788, 0.7987697715289982, 0.9497621878715814, 0.913633737723859, 0.8177325581395349, 0.7180074434583452]\n",
      "cluster_accuracy_post_training_cycle_all_dataset : [0.97918638 0.97832234 0.97496389 0.96721311 0.96616915 0.95660377\n",
      " 0.93635007 0.8537159  0.95562279 0.92041016 0.83494208 0.7775571\n",
      " 0.95315682 0.91755577 0.82990196 0.73865265]\n",
      "mean_cluster_accuracy_during_training_cycle : 89.85%, post_traincycle_acc : 90.88%, total_acc : 90.45483296%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 89.88%\n",
      "accuracy_check 실행 시간: 23.778초\n",
      "\n",
      "\n",
      "epoch-40 loss : 0.00935626, loss_normal : 0.01270174, loss_coarse : 0.05895370, min_loss : 0.00934051, min_loss_normal : 0.01270040, min_loss_coarse : 0.05891249, wrong_element_sum : 11319110.00000000, same_data : 0.00%\n",
      "ae train 실행 시간: 122.517초, 전체 시작 시간 20250314_000221_115\n",
      "\n",
      "epoch-40 accuracy check\n",
      "k_means origin feature average accuracy : 82.25497029%, total [0.9746727376209448, 0.9733106189664963, 0.9700891573195284, 0.9530800230282096, 0.943108504398827, 0.9150568181818182, 0.801817648783348, 0.6625070901871809, 0.9488619568430388, 0.822215777262181, 0.5872695852534562, 0.5005858230814294, 0.9429250891795482, 0.8922588099364529, 0.6738372093023256, 0.5991983967935872]\n",
      "kmeans average accuracy best : 91.48%, kmeans average accuracy : 90.60151190%, total [0.9769493454752419, 0.978137421919364, 0.9746908254242163, 0.9643062751871042, 0.9633431085043989, 0.9579545454545455, 0.9328642626795661, 0.8593306863301191, 0.9677800768548626, 0.9263341067285383, 0.8450460829493087, 0.7923257176332748, 0.9456004756242569, 0.9046793760831889, 0.8037790697674418, 0.7031205267678213]\n",
      "cluster_accuracy_post_training_cycle_all_dataset : [0.97918638 0.97832234 0.97544535 0.96769527 0.96517413 0.95566038\n",
      " 0.93784187 0.85324553 0.96116994 0.92675781 0.83156371 0.59433962\n",
      " 0.94602851 0.90543162 0.82352941 0.72479694]\n",
      "mean_cluster_accuracy_during_training_cycle : 89.03%, post_traincycle_acc : 89.54%, total_acc : 89.33154611%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 89.88%\n",
      "accuracy_check 실행 시간: 23.363초\n",
      "\n",
      "\n",
      "epoch-41 loss : 0.00936055, loss_normal : 0.01270577, loss_coarse : 0.05899313, min_loss : 0.00934051, min_loss_normal : 0.01270040, min_loss_coarse : 0.05891249, wrong_element_sum : 11326682.00000000, same_data : 0.00%\n",
      "ae train 실행 시간: 94.339초, 전체 시작 시간 20250314_000221_115\n",
      "\n",
      "epoch-41 accuracy check\n",
      "k_means origin feature average accuracy : 82.24959751%, total [0.9746727376209448, 0.9733106189664963, 0.9700891573195284, 0.9530800230282096, 0.943108504398827, 0.9150568181818182, 0.801817648783348, 0.6622234826999432, 0.9488619568430388, 0.822215777262181, 0.5866935483870968, 0.5005858230814294, 0.9429250891795482, 0.8922588099364529, 0.6738372093023256, 0.5991983967935872]\n",
      "kmeans average accuracy best : 91.48%, kmeans average accuracy : 90.85369610%, total [0.9769493454752419, 0.9775695627484384, 0.9746908254242163, 0.9643062751871042, 0.9639296187683285, 0.9582386363636364, 0.9331574318381706, 0.8562110039705049, 0.9663020987289388, 0.9272041763341067, 0.8548387096774194, 0.7973052138254247, 0.9515457788347206, 0.914789139225881, 0.8075581395348838, 0.711995419410249]\n",
      "cluster_accuracy_post_training_cycle_all_dataset : [0.97918638 0.97832234 0.97496389 0.96865959 0.96567164 0.95377358\n",
      " 0.93336648 0.85465663 0.95763994 0.92578125 0.82528958 0.70158888\n",
      " 0.95112016 0.91416101 0.84656863 0.74773053]\n",
      "mean_cluster_accuracy_during_training_cycle : 89.17%, post_traincycle_acc : 90.49%, total_acc : 89.94959351%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 89.88%\n",
      "accuracy_check 실행 시간: 23.126초\n",
      "\n",
      "\n",
      "epoch-42 loss : 0.00933552, loss_normal : 0.01270417, loss_coarse : 0.05894477, min_loss : 0.00933552, min_loss_normal : 0.01270040, min_loss_coarse : 0.05891249, wrong_element_sum : 11317396.00000000, same_data : 0.00%\n",
      "ae train 실행 시간: 125.139초, 전체 시작 시간 20250314_000221_115\n",
      "\n",
      "epoch-42 accuracy check\n",
      "k_means origin feature average accuracy : 82.26029687%, total [0.9746727376209448, 0.9733106189664963, 0.9700891573195284, 0.9530800230282096, 0.943108504398827, 0.915340909090909, 0.801817648783348, 0.6625070901871809, 0.9488619568430388, 0.822215777262181, 0.5872695852534562, 0.5005858230814294, 0.9429250891795482, 0.8922588099364529, 0.673546511627907, 0.6000572573718866]\n",
      "kmeans average accuracy best : 91.48%, kmeans average accuracy : 91.15783713%, total [0.9769493454752419, 0.9784213515048268, 0.9749784296807593, 0.9660333909038572, 0.9653958944281525, 0.9602272727272727, 0.9352096159484022, 0.8613159387407827, 0.971918415607449, 0.9289443155452436, 0.8545506912442397, 0.7975981253661394, 0.9542211652794292, 0.9165222414789139, 0.8223837209302326, 0.7205840251932436]\n",
      "cluster_accuracy_post_training_cycle_all_dataset : [0.97871334 0.97785108 0.97544535 0.96865959 0.9681592  0.95660377\n",
      " 0.93386375 0.855127   0.96167423 0.93115234 0.83204633 0.55412115\n",
      " 0.95315682 0.91949564 0.83088235 0.74151935]\n",
      "mean_cluster_accuracy_during_training_cycle : 89.28%, post_traincycle_acc : 89.62%, total_acc : 89.48043735%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 89.88%\n",
      "accuracy_check 실행 시간: 23.425초\n",
      "\n",
      "\n",
      "epoch-43 loss : 0.00934330, loss_normal : 0.01270927, loss_coarse : 0.05901682, min_loss : 0.00933552, min_loss_normal : 0.01270040, min_loss_coarse : 0.05891249, wrong_element_sum : 11331230.00000000, same_data : 0.00%\n",
      "ae train 실행 시간: 123.147초, 전체 시작 시간 20250314_000221_115\n",
      "\n",
      "epoch-43 accuracy check\n",
      "k_means origin feature average accuracy : 82.24966649%, total [0.9746727376209448, 0.9733106189664963, 0.9700891573195284, 0.9530800230282096, 0.943108504398827, 0.915340909090909, 0.801817648783348, 0.6622234826999432, 0.9488619568430388, 0.822215777262181, 0.5866935483870968, 0.5005858230814294, 0.9429250891795482, 0.8922588099364529, 0.6747093023255814, 0.5980532493558546]\n",
      "kmeans average accuracy best : 91.48%, kmeans average accuracy : 91.21942195%, total [0.9766647694934547, 0.978137421919364, 0.9749784296807593, 0.9660333909038572, 0.9639296187683285, 0.959659090909091, 0.9302257402521255, 0.8584798638684061, 0.9704404374815253, 0.9240139211136891, 0.8626152073732719, 0.8057996485061512, 0.9512485136741974, 0.9196995956094743, 0.8351744186046511, 0.7180074434583452]\n",
      "cluster_accuracy_post_training_cycle_all_dataset : [0.97871334 0.97785108 0.97496389 0.96817743 0.96716418 0.95660377\n",
      " 0.93585281 0.8537159  0.95209279 0.93652344 0.83542471 0.65590864\n",
      " 0.95213849 0.92192047 0.85539216 0.75776398]\n",
      "mean_cluster_accuracy_during_training_cycle : 89.91%, post_traincycle_acc : 90.50%, total_acc : 90.26138694%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 89.88%\n",
      "accuracy_check 실행 시간: 23.426초\n",
      "\n",
      "\n",
      "epoch-44 loss : 0.00931718, loss_normal : 0.01269189, loss_coarse : 0.05892772, min_loss : 0.00931718, min_loss_normal : 0.01269189, min_loss_coarse : 0.05891249, wrong_element_sum : 11314122.00000000, same_data : 0.00%\n",
      "ae train 실행 시간: 124.865초, 전체 시작 시간 20250314_000221_115\n",
      "\n",
      "epoch-44 accuracy check\n",
      "k_means origin feature average accuracy : 82.24778065%, total [0.9746727376209448, 0.9733106189664963, 0.9700891573195284, 0.9530800230282096, 0.943108504398827, 0.9150568181818182, 0.801817648783348, 0.6622234826999432, 0.9488619568430388, 0.822215777262181, 0.5866935483870968, 0.5005858230814294, 0.9429250891795482, 0.8922588099364529, 0.673546511627907, 0.5991983967935872]\n",
      "kmeans average accuracy best : 91.48%, kmeans average accuracy : 90.66516187%, total [0.9766647694934547, 0.9784213515048268, 0.9749784296807593, 0.9654576856649395, 0.9642228739002933, 0.95625, 0.9334506009967751, 0.8607487237663074, 0.9689624593556015, 0.9330046403712297, 0.8542626728110599, 0.7996485061511424, 0.9402497027348394, 0.9084344309647603, 0.8, 0.6916690523904953]\n",
      "cluster_accuracy_post_training_cycle_all_dataset : [0.97871334 0.97832234 0.97544535 0.96769527 0.96567164 0.95471698\n",
      " 0.93038289 0.84195673 0.96016137 0.93701172 0.83252896 0.56951341\n",
      " 0.93584521 0.91173618 0.82647059 0.72431916]\n",
      "mean_cluster_accuracy_during_training_cycle : 88.96%, post_traincycle_acc : 89.32%, total_acc : 89.17014634%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 89.88%\n",
      "accuracy_check 실행 시간: 23.598초\n",
      "\n",
      "\n",
      "epoch-45 loss : 0.00930468, loss_normal : 0.01268988, loss_coarse : 0.05886367, min_loss : 0.00930468, min_loss_normal : 0.01268988, min_loss_coarse : 0.05886367, wrong_element_sum : 11301824.00000000, same_data : 0.00%\n",
      "ae train 실행 시간: 128.334초, 전체 시작 시간 20250314_000221_115\n",
      "\n",
      "epoch-45 accuracy check\n",
      "k_means origin feature average accuracy : 82.25315935%, total [0.9746727376209448, 0.9733106189664963, 0.9700891573195284, 0.9530800230282096, 0.943108504398827, 0.9150568181818182, 0.801817648783348, 0.6625070901871809, 0.9488619568430388, 0.822215777262181, 0.5866935483870968, 0.5005858230814294, 0.9429250891795482, 0.8922588099364529, 0.6738372093023256, 0.5994846836530203]\n",
      "kmeans average accuracy best : 91.48%, kmeans average accuracy : 90.91035323%, total [0.9769493454752419, 0.978137421919364, 0.9746908254242163, 0.9648819804260219, 0.9651026392961877, 0.959659090909091, 0.9340369393139841, 0.8633011911514464, 0.9674844812296778, 0.931554524361949, 0.8608870967741935, 0.8040421792618629, 0.9500594530321046, 0.913633737723859, 0.8078488372093023, 0.6933867735470942]\n",
      "cluster_accuracy_post_training_cycle_all_dataset : [0.97871334 0.97785108 0.97448243 0.96817743 0.96716418 0.95849057\n",
      " 0.93485828 0.855127   0.95562279 0.93408203 0.82722008 0.72194638\n",
      " 0.94959267 0.90591659 0.83284314 0.7061634 ]\n",
      "mean_cluster_accuracy_during_training_cycle : 89.51%, post_traincycle_acc : 90.30%, total_acc : 89.97756856%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 89.88%\n",
      "accuracy_check 실행 시간: 23.828초\n",
      "\n",
      "\n",
      "epoch-46 loss : 0.00928923, loss_normal : 0.01267712, loss_coarse : 0.05876970, min_loss : 0.00928923, min_loss_normal : 0.01267712, min_loss_coarse : 0.05876970, wrong_element_sum : 11283782.00000000, same_data : 0.00%\n",
      "ae train 실행 시간: 123.434초, 전체 시작 시간 20250314_000221_115\n",
      "\n",
      "epoch-46 accuracy check\n",
      "k_means origin feature average accuracy : 82.26939000%, total [0.9746727376209448, 0.9733106189664963, 0.9700891573195284, 0.9530800230282096, 0.943108504398827, 0.9150568181818182, 0.801817648783348, 0.6622234826999432, 0.9488619568430388, 0.822215777262181, 0.5866935483870968, 0.5005858230814294, 0.9429250891795482, 0.8922588099364529, 0.675, 0.6012024048096193]\n",
      "kmeans average accuracy best : 91.48%, kmeans average accuracy : 91.12491408%, total [0.9766647694934547, 0.9784213515048268, 0.9749784296807593, 0.9666090961427749, 0.9639296187683285, 0.9605113636363637, 0.9328642626795661, 0.8675553034600113, 0.97073603310671, 0.9350348027842227, 0.8629032258064516, 0.7984768599882835, 0.9491676575505351, 0.91421143847487, 0.8119186046511628, 0.7160034354423132]\n",
      "cluster_accuracy_post_training_cycle_all_dataset : [0.97918638 0.97832234 0.97544535 0.96914176 0.96616915 0.95896226\n",
      " 0.93386375 0.85606773 0.96469995 0.93066406 0.84025097 0.56256207\n",
      " 0.95112016 0.91949564 0.82745098 0.72240803]\n",
      "mean_cluster_accuracy_during_training_cycle : 89.29%, post_traincycle_acc : 89.60%, total_acc : 89.47263523%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 89.88%\n",
      "accuracy_check 실행 시간: 24.202초\n",
      "\n",
      "\n",
      "epoch-47 loss : 0.00931646, loss_normal : 0.01268335, loss_coarse : 0.05884507, min_loss : 0.00928923, min_loss_normal : 0.01267712, min_loss_coarse : 0.05876970, wrong_element_sum : 11298254.00000000, same_data : 0.00%\n",
      "ae train 실행 시간: 127.509초, 전체 시작 시간 20250314_000221_115\n",
      "\n",
      "epoch-47 accuracy check\n",
      "k_means origin feature average accuracy : 82.26031652%, total [0.9746727376209448, 0.9733106189664963, 0.9700891573195284, 0.9530800230282096, 0.943108504398827, 0.9150568181818182, 0.801817648783348, 0.6625070901871809, 0.9488619568430388, 0.822215777262181, 0.5866935483870968, 0.5005858230814294, 0.9429250891795482, 0.8922588099364529, 0.6738372093023256, 0.600629831090753]\n",
      "kmeans average accuracy best : 91.48%, kmeans average accuracy : 90.88722725%, total [0.9769493454752419, 0.978137421919364, 0.9752660339373023, 0.9668969487622338, 0.9648093841642229, 0.9599431818181818, 0.9369686309000294, 0.8701077708451503, 0.97073603310671, 0.9243039443155452, 0.8585829493087558, 0.804920913884007, 0.9467895362663495, 0.9116117850953206, 0.7979651162790697, 0.6979673632980247]\n",
      "cluster_accuracy_post_training_cycle_all_dataset : [0.97965941 0.97832234 0.97496389 0.96914176 0.96666667 0.95613208\n",
      " 0.93187469 0.86406397 0.95562279 0.92089844 0.83252896 0.58142999\n",
      " 0.94857434 0.91949564 0.83529412 0.7147635 ]\n",
      "mean_cluster_accuracy_during_training_cycle : 88.91%, post_traincycle_acc : 89.56%, total_acc : 89.29210443%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 89.88%\n",
      "accuracy_check 실행 시간: 24.126초\n",
      "\n",
      "\n",
      "epoch-48 loss : 0.00932675, loss_normal : 0.01268652, loss_coarse : 0.05890837, min_loss : 0.00928923, min_loss_normal : 0.01267712, min_loss_coarse : 0.05876970, wrong_element_sum : 11310408.00000000, same_data : 0.00%\n",
      "ae train 실행 시간: 125.459초, 전체 시작 시간 20250314_000221_115\n",
      "\n",
      "epoch-48 accuracy check\n",
      "k_means origin feature average accuracy : 82.24244034%, total [0.9746727376209448, 0.9733106189664963, 0.9700891573195284, 0.9530800230282096, 0.943108504398827, 0.9150568181818182, 0.801817648783348, 0.6622234826999432, 0.9488619568430388, 0.822215777262181, 0.5866935483870968, 0.5005858230814294, 0.9429250891795482, 0.8922588099364529, 0.6738372093023256, 0.5980532493558546]\n",
      "kmeans average accuracy best : 91.48%, kmeans average accuracy : 90.94269309%, total [0.9769493454752419, 0.9778534923339012, 0.9746908254242163, 0.9666090961427749, 0.9648093841642229, 0.959375, 0.931105247727939, 0.8627339761769711, 0.9739875849837423, 0.9318445475638051, 0.8605990783410138, 0.8002343292325718, 0.9470868014268727, 0.9052570768341999, 0.8171511627906977, 0.7005439450329229]\n",
      "cluster_accuracy_post_training_cycle_all_dataset : [0.97965941 0.97832234 0.97544535 0.96817743 0.96666667 0.95613208\n",
      " 0.92541024 0.8523048  0.96822995 0.92480469 0.83204633 0.78500497\n",
      " 0.95112016 0.90785645 0.82107843 0.72431916]\n",
      "mean_cluster_accuracy_during_training_cycle : 89.64%, post_traincycle_acc : 90.73%, total_acc : 90.28333412%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 89.88%\n",
      "accuracy_check 실행 시간: 24.275초\n",
      "\n",
      "\n",
      "epoch-49 loss : 0.00929247, loss_normal : 0.01267660, loss_coarse : 0.05882349, min_loss : 0.00928923, min_loss_normal : 0.01267660, min_loss_coarse : 0.05876970, wrong_element_sum : 11294110.00000000, same_data : 0.00%\n",
      "ae train 실행 시간: 128.074초, 전체 시작 시간 20250314_000221_115\n",
      "\n",
      "epoch-49 accuracy check\n",
      "k_means origin feature average accuracy : 82.26033817%, total [0.9746727376209448, 0.9733106189664963, 0.9700891573195284, 0.9530800230282096, 0.943108504398827, 0.9150568181818182, 0.801817648783348, 0.6625070901871809, 0.9488619568430388, 0.822215777262181, 0.5872695852534562, 0.5005858230814294, 0.9429250891795482, 0.8922588099364529, 0.6738372093023256, 0.6000572573718866]\n",
      "kmeans average accuracy best : 91.48%, kmeans average accuracy : 91.42246904%, total [0.9769493454752419, 0.9778534923339012, 0.9746908254242163, 0.9674726540011515, 0.9642228739002933, 0.9613636363636363, 0.9343301084725887, 0.870391378332388, 0.968371268105232, 0.9274941995359629, 0.8646313364055299, 0.8084358523725835, 0.9488703923900119, 0.9121894858463316, 0.833139534883721, 0.7371886630403665]\n",
      "cluster_accuracy_post_training_cycle_all_dataset : [0.97965941 0.97832234 0.97544535 0.96865959 0.96517413 0.95801887\n",
      " 0.93336648 0.8508937  0.95612708 0.92333984 0.82915058 0.79195631\n",
      " 0.95112016 0.91270611 0.85098039 0.73960822]\n",
      "mean_cluster_accuracy_during_training_cycle : 90.50%, post_traincycle_acc : 91.03%, total_acc : 90.81053592%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 89.88%\n",
      "accuracy_check 실행 시간: 24.206초\n",
      "\n",
      "\n",
      "epoch-50 loss : 0.00928109, loss_normal : 0.01266900, loss_coarse : 0.05878521, min_loss : 0.00928109, min_loss_normal : 0.01266900, min_loss_coarse : 0.05876970, wrong_element_sum : 11286760.00000000, same_data : 0.00%\n",
      "ae train 실행 시간: 127.426초, 전체 시작 시간 20250314_000221_115\n",
      "\n",
      "epoch-50 accuracy check\n",
      "k_means origin feature average accuracy : 82.26029687%, total [0.9746727376209448, 0.9733106189664963, 0.9700891573195284, 0.9530800230282096, 0.943108504398827, 0.915340909090909, 0.801817648783348, 0.6625070901871809, 0.9488619568430388, 0.822215777262181, 0.5872695852534562, 0.5005858230814294, 0.9429250891795482, 0.8922588099364529, 0.673546511627907, 0.6000572573718866]\n",
      "kmeans average accuracy best : 91.48%, kmeans average accuracy : 91.19999166%, total [0.9769493454752419, 0.9778534923339012, 0.9752660339373023, 0.9657455382843984, 0.9633431085043989, 0.9607954545454546, 0.931105247727939, 0.8621667612024957, 0.971918415607449, 0.9295243619489559, 0.8640552995391705, 0.8060925600468658, 0.950653983353151, 0.9139225880993646, 0.8174418604651162, 0.7251646149441741]\n",
      "cluster_accuracy_post_training_cycle_all_dataset : [0.98013245 0.97832234 0.97544535 0.96769527 0.96616915 0.95849057\n",
      " 0.92789657 0.85700847 0.96419566 0.93164062 0.83638996 0.65342602\n",
      " 0.95468432 0.90737148 0.83186275 0.7458194 ]\n",
      "mean_cluster_accuracy_during_training_cycle : 89.28%, post_traincycle_acc : 90.23%, total_acc : 89.83998600%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 89.88%\n",
      "accuracy_check 실행 시간: 24.301초\n",
      "\n",
      "\n",
      "epoch-51 loss : 0.00931431, loss_normal : 0.01267528, loss_coarse : 0.05887967, min_loss : 0.00928109, min_loss_normal : 0.01266900, min_loss_coarse : 0.05876970, wrong_element_sum : 11304896.00000000, same_data : 0.00%\n",
      "ae train 실행 시간: 128.225초, 전체 시작 시간 20250314_000221_115\n",
      "\n",
      "epoch-51 accuracy check\n",
      "k_means origin feature average accuracy : 82.25686495%, total [0.9746727376209448, 0.9733106189664963, 0.9700891573195284, 0.9530800230282096, 0.943108504398827, 0.9150568181818182, 0.801817648783348, 0.6622234826999432, 0.9488619568430388, 0.822215777262181, 0.5866935483870968, 0.5005858230814294, 0.9429250891795482, 0.8922588099364529, 0.675, 0.5991983967935872]\n",
      "kmeans average accuracy best : 91.48%, kmeans average accuracy : 91.03188197%, total [0.9769493454752419, 0.9784213515048268, 0.9746908254242163, 0.966321243523316, 0.9636363636363636, 0.9607954545454546, 0.9296394019349165, 0.8641520136131594, 0.9713272243570795, 0.9214037122969838, 0.8559907834101382, 0.7978910369068541, 0.9456004756242569, 0.9084344309647603, 0.8229651162790698, 0.726882336100773]\n",
      "cluster_accuracy_post_training_cycle_all_dataset : [0.97918638 0.97879359 0.97544535 0.96769527 0.96567164 0.95566038\n",
      " 0.9288911  0.8565381  0.94452849 0.92675781 0.82625483 0.68470705\n",
      " 0.94297352 0.90300679 0.83382353 0.75728619]\n",
      "mean_cluster_accuracy_during_training_cycle : 89.35%, post_traincycle_acc : 90.17%, total_acc : 89.83462039%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 89.88%\n",
      "accuracy_check 실행 시간: 24.192초\n",
      "\n",
      "\n",
      "epoch-52 loss : 0.00930220, loss_normal : 0.01266418, loss_coarse : 0.05881126, min_loss : 0.00928109, min_loss_normal : 0.01266418, min_loss_coarse : 0.05876970, wrong_element_sum : 11291762.00000000, same_data : 0.00%\n",
      "ae train 실행 시간: 129.248초, 전체 시작 시간 20250314_000221_115\n",
      "\n",
      "epoch-52 accuracy check\n",
      "k_means origin feature average accuracy : 82.25307821%, total [0.9746727376209448, 0.9733106189664963, 0.9700891573195284, 0.9530800230282096, 0.943108504398827, 0.9150568181818182, 0.801817648783348, 0.6622234826999432, 0.9488619568430388, 0.8219257540603249, 0.5872695852534562, 0.5005858230814294, 0.942627824019025, 0.8922588099364529, 0.673546511627907, 0.6000572573718866]\n",
      "kmeans average accuracy best : 91.48%, kmeans average accuracy : 91.10302343%, total [0.9769493454752419, 0.978137421919364, 0.9752660339373023, 0.9660333909038572, 0.9639296187683285, 0.9582386363636364, 0.9302257402521255, 0.8601815087918321, 0.9692580549807863, 0.9243039443155452, 0.8574308755760369, 0.7975981253661394, 0.9473840665873959, 0.9093009820912767, 0.8287790697674419, 0.7334669338677354]\n",
      "cluster_accuracy_post_training_cycle_all_dataset : [0.97965941 0.97879359 0.97496389 0.96865959 0.96616915 0.95613208\n",
      " 0.92590751 0.84195673 0.95310136 0.93017578 0.82673745 0.72790467\n",
      " 0.9490835  0.91222114 0.82598039 0.75680841]\n",
      "mean_cluster_accuracy_during_training_cycle : 89.92%, post_traincycle_acc : 90.46%, total_acc : 90.23830777%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 89.88%\n",
      "accuracy_check 실행 시간: 24.221초\n",
      "\n",
      "\n",
      "epoch-53 loss : 0.00928572, loss_normal : 0.01266724, loss_coarse : 0.05881895, min_loss : 0.00928109, min_loss_normal : 0.01266418, min_loss_coarse : 0.05876970, wrong_element_sum : 11293238.00000000, same_data : 0.00%\n",
      "ae train 실행 시간: 127.411초, 전체 시작 시간 20250314_000221_115\n",
      "\n",
      "epoch-53 accuracy check\n",
      "k_means origin feature average accuracy : 82.25317017%, total [0.9746727376209448, 0.9733106189664963, 0.9700891573195284, 0.9530800230282096, 0.943108504398827, 0.9150568181818182, 0.801817648783348, 0.6622234826999432, 0.9488619568430388, 0.822215777262181, 0.5872695852534562, 0.5005858230814294, 0.9429250891795482, 0.8922588099364529, 0.673546511627907, 0.5994846836530203]\n",
      "kmeans average accuracy best : 91.48%, kmeans average accuracy : 91.28039505%, total [0.9769493454752419, 0.978137421919364, 0.9752660339373023, 0.9668969487622338, 0.9639296187683285, 0.9599431818181818, 0.9369686309000294, 0.8706749858196257, 0.9701448418563405, 0.9266241299303944, 0.8577188940092166, 0.8002343292325718, 0.942627824019025, 0.913633737723859, 0.8290697674418605, 0.7360435156026338]\n",
      "cluster_accuracy_post_training_cycle_all_dataset : [0.97965941 0.97879359 0.97544535 0.96817743 0.96467662 0.95707547\n",
      " 0.93784187 0.85606773 0.95461422 0.93505859 0.82528958 0.57199603\n",
      " 0.94348269 0.91416101 0.83284314 0.7486861 ]\n",
      "mean_cluster_accuracy_during_training_cycle : 89.23%, post_traincycle_acc : 89.65%, total_acc : 89.47726086%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 89.88%\n",
      "accuracy_check 실행 시간: 29.316초\n",
      "\n",
      "\n",
      "epoch-54 loss : 0.00929351, loss_normal : 0.01267052, loss_coarse : 0.05886135, min_loss : 0.00928109, min_loss_normal : 0.01266418, min_loss_coarse : 0.05876970, wrong_element_sum : 11301380.00000000, same_data : 0.00%\n",
      "ae train 실행 시간: 126.279초, 전체 시작 시간 20250314_000221_115\n",
      "\n",
      "epoch-54 accuracy check\n",
      "k_means origin feature average accuracy : 82.25684228%, total [0.9746727376209448, 0.9733106189664963, 0.9700891573195284, 0.9530800230282096, 0.943108504398827, 0.9150568181818182, 0.801817648783348, 0.6625070901871809, 0.9488619568430388, 0.822215777262181, 0.5872695852534562, 0.5005858230814294, 0.9429250891795482, 0.8922588099364529, 0.6747093023255814, 0.5986258230747209]\n",
      "kmeans average accuracy best : 91.48%, kmeans average accuracy : 91.28614319%, total [0.9769493454752419, 0.978137421919364, 0.9749784296807593, 0.966321243523316, 0.9642228739002933, 0.9585227272727272, 0.9331574318381706, 0.8635847986386841, 0.9716228199822643, 0.9347447795823666, 0.8588709677419355, 0.8087287639132982, 0.9509512485136742, 0.9173887926054304, 0.8258720930232558, 0.7217291726309762]\n",
      "cluster_accuracy_post_training_cycle_all_dataset : [0.97918638 0.97832234 0.97544535 0.96721311 0.96716418 0.95471698\n",
      " 0.92938836 0.84619003 0.96570852 0.93115234 0.82722008 0.77904667\n",
      " 0.950611   0.92240543 0.84117647 0.71094123]\n",
      "mean_cluster_accuracy_during_training_cycle : 89.83%, post_traincycle_acc : 90.79%, total_acc : 90.39510193%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 89.88%\n",
      "accuracy_check 실행 시간: 23.922초\n",
      "\n",
      "\n",
      "epoch-55 loss : 0.00927931, loss_normal : 0.01267134, loss_coarse : 0.05880754, min_loss : 0.00927931, min_loss_normal : 0.01266418, min_loss_coarse : 0.05876970, wrong_element_sum : 11291048.00000000, same_data : 0.00%\n",
      "ae train 실행 시간: 126.240초, 전체 시작 시간 20250314_000221_115\n",
      "\n",
      "epoch-55 accuracy check\n",
      "k_means origin feature average accuracy : 82.25148033%, total [0.9746727376209448, 0.9733106189664963, 0.9700891573195284, 0.9530800230282096, 0.943108504398827, 0.9150568181818182, 0.801817648783348, 0.6625070901871809, 0.9488619568430388, 0.822215777262181, 0.5866935483870968, 0.5005858230814294, 0.9429250891795482, 0.8922588099364529, 0.675, 0.5980532493558546]\n",
      "kmeans average accuracy best : 91.48%, kmeans average accuracy : 91.19887593%, total [0.9766647694934547, 0.9778534923339012, 0.9752660339373023, 0.9657455382843984, 0.9639296187683285, 0.9585227272727272, 0.9343301084725887, 0.8627339761769711, 0.9680756724800473, 0.9266241299303944, 0.8580069124423964, 0.804920913884007, 0.9494649227110583, 0.915944540727903, 0.8340116279069767, 0.7197251646149442]\n",
      "cluster_accuracy_post_training_cycle_all_dataset : [0.97918638 0.97832234 0.97544535 0.96769527 0.96517413 0.95235849\n",
      " 0.9288911  0.85418627 0.95360565 0.92675781 0.81949807 0.55858987\n",
      " 0.95162933 0.92192047 0.84019608 0.75250836]\n",
      "mean_cluster_accuracy_during_training_cycle : 89.50%, post_traincycle_acc : 89.54%, total_acc : 89.52359618%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 89.88%\n",
      "accuracy_check 실행 시간: 24.072초\n",
      "\n",
      "\n",
      "epoch-56 loss : 0.00925781, loss_normal : 0.01265250, loss_coarse : 0.05870056, min_loss : 0.00925781, min_loss_normal : 0.01265250, min_loss_coarse : 0.05870056, wrong_element_sum : 11270508.00000000, same_data : 0.00%\n",
      "ae train 실행 시간: 127.564초, 전체 시작 시간 20250314_000221_115\n",
      "\n",
      "epoch-56 accuracy check\n",
      "k_means origin feature average accuracy : 82.25673794%, total [0.9746727376209448, 0.9733106189664963, 0.9700891573195284, 0.9530800230282096, 0.943108504398827, 0.9150568181818182, 0.801817648783348, 0.6625070901871809, 0.9488619568430388, 0.822215777262181, 0.5866935483870968, 0.5005858230814294, 0.9429250891795482, 0.8922588099364529, 0.6738372093023256, 0.6000572573718866]\n",
      "save model\n",
      "kmeans average accuracy best : 91.81%, kmeans average accuracy : 91.80830626%, total [0.9769493454752419, 0.978137421919364, 0.9749784296807593, 0.966321243523316, 0.9653958944281525, 0.9590909090909091, 0.9343301084725887, 0.8769143505388542, 0.973100798108188, 0.9367749419953596, 0.8729838709677419, 0.8072642062097246, 0.9557074910820452, 0.9280762564991335, 0.8392441860465116, 0.7440595476667621]\n",
      "cluster_accuracy_post_training_cycle_all_dataset : [0.97965941 0.97879359 0.97496389 0.96817743 0.96716418 0.95613208\n",
      " 0.93237195 0.855127   0.96822995 0.94042969 0.84749035 0.71400199\n",
      " 0.95417515 0.92337536 0.84362745 0.75346393]\n",
      "mean_cluster_accuracy_during_training_cycle : 90.89%, post_traincycle_acc : 90.98%, total_acc : 90.94506223%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 90.98%\n",
      "accuracy_check 실행 시간: 24.805초\n",
      "\n",
      "\n",
      "epoch-57 loss : 0.00926091, loss_normal : 0.01264723, loss_coarse : 0.05872320, min_loss : 0.00925781, min_loss_normal : 0.01264723, min_loss_coarse : 0.05870056, wrong_element_sum : 11274854.00000000, same_data : 0.00%\n",
      "ae train 실행 시간: 126.056초, 전체 시작 시간 20250314_000221_115\n",
      "\n",
      "epoch-57 accuracy check\n",
      "k_means origin feature average accuracy : 82.25855190%, total [0.9746727376209448, 0.9733106189664963, 0.9700891573195284, 0.9530800230282096, 0.943108504398827, 0.915340909090909, 0.801817648783348, 0.6622234826999432, 0.9488619568430388, 0.822215777262181, 0.5872695852534562, 0.5005858230814294, 0.9429250891795482, 0.8922588099364529, 0.6738372093023256, 0.5997709705124534]\n",
      "kmeans average accuracy best : 91.81%, kmeans average accuracy : 91.37910273%, total [0.9769493454752419, 0.978137421919364, 0.9752660339373023, 0.9654576856649395, 0.9636363636363636, 0.9602272727272727, 0.9319847552037526, 0.8698241633579127, 0.9689624593556015, 0.9312645011600929, 0.861463133640553, 0.8093145869947276, 0.9456004756242569, 0.9173887926054304, 0.8334302325581395, 0.7317492127111366]\n",
      "cluster_accuracy_post_training_cycle_all_dataset : [0.97918638 0.97832234 0.97544535 0.96721311 0.96567164 0.95660377\n",
      " 0.93038289 0.82925682 0.95965709 0.93066406 0.83638996 0.68123138\n",
      " 0.94551935 0.91464597 0.84607843 0.73817487]\n",
      "mean_cluster_accuracy_during_training_cycle : 89.33%, post_traincycle_acc : 90.22%, total_acc : 89.85272341%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 90.98%\n",
      "accuracy_check 실행 시간: 24.158초\n",
      "\n",
      "\n",
      "epoch-58 loss : 0.00925608, loss_normal : 0.01264420, loss_coarse : 0.05870783, min_loss : 0.00925608, min_loss_normal : 0.01264420, min_loss_coarse : 0.05870056, wrong_element_sum : 11271904.00000000, same_data : 0.00%\n",
      "ae train 실행 시간: 127.921초, 전체 시작 시간 20250314_000221_115\n",
      "\n",
      "epoch-58 accuracy check\n",
      "k_means origin feature average accuracy : 82.25313970%, total [0.9746727376209448, 0.9733106189664963, 0.9700891573195284, 0.9530800230282096, 0.943108504398827, 0.915340909090909, 0.801817648783348, 0.6625070901871809, 0.9488619568430388, 0.822215777262181, 0.5872695852534562, 0.5005858230814294, 0.9429250891795482, 0.8922588099364529, 0.673546511627907, 0.598912109934154]\n",
      "kmeans average accuracy best : 91.81%, kmeans average accuracy : 90.81759878%, total [0.9769493454752419, 0.9784213515048268, 0.9749784296807593, 0.9657455382843984, 0.9648093841642229, 0.9599431818181818, 0.9287598944591029, 0.8564946114577425, 0.9698492462311558, 0.9248839907192575, 0.8600230414746544, 0.7943760984182777, 0.9456004756242569, 0.9121894858463316, 0.8046511627906977, 0.7131405668479817]\n",
      "cluster_accuracy_post_training_cycle_all_dataset : [0.97965941 0.97832234 0.97544535 0.96769527 0.96616915 0.95660377\n",
      " 0.92988563 0.83160865 0.95965709 0.92773438 0.8296332  0.77904667\n",
      " 0.94755601 0.91416101 0.81960784 0.71141902]\n",
      "mean_cluster_accuracy_during_training_cycle : 89.77%, post_traincycle_acc : 90.46%, total_acc : 90.17838653%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 90.98%\n",
      "accuracy_check 실행 시간: 25.140초\n",
      "\n",
      "\n",
      "epoch-59 loss : 0.00925070, loss_normal : 0.01263802, loss_coarse : 0.05863434, min_loss : 0.00925070, min_loss_normal : 0.01263802, min_loss_coarse : 0.05863434, wrong_element_sum : 11257794.00000000, same_data : 0.00%\n",
      "ae train 실행 시간: 128.129초, 전체 시작 시간 20250314_000221_115\n",
      "\n",
      "epoch-59 accuracy check\n",
      "k_means origin feature average accuracy : 82.24774477%, total [0.9746727376209448, 0.9733106189664963, 0.9700891573195284, 0.9530800230282096, 0.943108504398827, 0.9150568181818182, 0.801817648783348, 0.6625070901871809, 0.9488619568430388, 0.8216357308584686, 0.5866935483870968, 0.5005858230814294, 0.9429250891795482, 0.8922588099364529, 0.6738372093023256, 0.5991983967935872]\n",
      "kmeans average accuracy best : 91.81%, kmeans average accuracy : 91.41388096%, total [0.9766647694934547, 0.978137421919364, 0.9752660339373023, 0.9677605066206102, 0.9627565982404692, 0.9571022727272728, 0.9296394019349165, 0.8613159387407827, 0.9728052024830033, 0.9330046403712297, 0.8626152073732719, 0.8025776215582894, 0.9530321046373365, 0.9237435008665511, 0.836046511627907, 0.7337532207271686]\n",
      "cluster_accuracy_post_training_cycle_all_dataset : [0.97871334 0.97785108 0.97544535 0.96817743 0.96517413 0.95518868\n",
      " 0.93038289 0.83631232 0.95511851 0.93896484 0.82915058 0.78351539\n",
      " 0.95519348 0.92677013 0.8495098  0.76254181]\n",
      "mean_cluster_accuracy_during_training_cycle : 90.42%, post_traincycle_acc : 91.18%, total_acc : 90.86755341%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 90.98%\n",
      "accuracy_check 실행 시간: 28.174초\n",
      "\n",
      "\n",
      "epoch-60 loss : 0.00927718, loss_normal : 0.01264860, loss_coarse : 0.05877674, min_loss : 0.00925070, min_loss_normal : 0.01263802, min_loss_coarse : 0.05863434, wrong_element_sum : 11285134.00000000, same_data : 0.00%\n",
      "ae train 실행 시간: 133.115초, 전체 시작 시간 20250314_000221_115\n",
      "\n",
      "epoch-60 accuracy check\n",
      "k_means origin feature average accuracy : 82.25492108%, total [0.9746727376209448, 0.9733106189664963, 0.9700891573195284, 0.9530800230282096, 0.943108504398827, 0.9150568181818182, 0.801817648783348, 0.6625070901871809, 0.9488619568430388, 0.822215777262181, 0.5866935483870968, 0.5005858230814294, 0.9429250891795482, 0.8922588099364529, 0.673546511627907, 0.6000572573718866]\n",
      "kmeans average accuracy best : 91.81%, kmeans average accuracy : 91.05187506%, total [0.9766647694934547, 0.978137421919364, 0.9749784296807593, 0.9668969487622338, 0.964516129032258, 0.9590909090909091, 0.9322779243623571, 0.8624503686897335, 0.969553650605971, 0.9208236658932715, 0.8482142857142857, 0.794083186877563, 0.9560047562425684, 0.9145002888503755, 0.8212209302325582, 0.7288863441168051]\n",
      "cluster_accuracy_post_training_cycle_all_dataset : [0.97965941 0.97832234 0.97544535 0.96817743 0.96716418 0.95518868\n",
      " 0.93286922 0.85841957 0.9591528  0.92578125 0.8238417  0.5590864\n",
      " 0.95773931 0.91561591 0.84117647 0.73913043]\n",
      "mean_cluster_accuracy_during_training_cycle : 88.88%, post_traincycle_acc : 89.60%, total_acc : 89.30554266%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 90.98%\n",
      "accuracy_check 실행 시간: 27.904초\n",
      "\n",
      "\n",
      "epoch-61 loss : 0.00926467, loss_normal : 0.01263804, loss_coarse : 0.05869932, min_loss : 0.00925070, min_loss_normal : 0.01263802, min_loss_coarse : 0.05863434, wrong_element_sum : 11270270.00000000, same_data : 0.00%\n",
      "ae train 실행 시간: 127.903초, 전체 시작 시간 20250314_000221_115\n",
      "\n",
      "epoch-61 accuracy check\n",
      "k_means origin feature average accuracy : 82.26397781%, total [0.9746727376209448, 0.9733106189664963, 0.9700891573195284, 0.9530800230282096, 0.943108504398827, 0.9150568181818182, 0.801817648783348, 0.6625070901871809, 0.9488619568430388, 0.822215777262181, 0.5866935483870968, 0.5005858230814294, 0.9429250891795482, 0.8922588099364529, 0.6747093023255814, 0.6003435442313197]\n",
      "kmeans average accuracy best : 91.81%, kmeans average accuracy : 91.07473327%, total [0.9769493454752419, 0.9784213515048268, 0.9752660339373023, 0.9677605066206102, 0.9636363636363636, 0.9571022727272728, 0.9281735561418939, 0.8635847986386841, 0.9698492462311558, 0.9309744779582366, 0.8580069124423964, 0.799941417691857, 0.9497621878715814, 0.9113229347198152, 0.8194767441860465, 0.7217291726309762]\n",
      "cluster_accuracy_post_training_cycle_all_dataset : [0.97871334 0.97879359 0.97544535 0.96769527 0.96616915 0.95518868\n",
      " 0.93137742 0.84477893 0.94654564 0.93359375 0.8238417  0.78401192\n",
      " 0.95162933 0.9185257  0.83578431 0.73483039]\n",
      "mean_cluster_accuracy_during_training_cycle : 90.06%, post_traincycle_acc : 90.79%, total_acc : 90.49201408%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 90.98%\n",
      "accuracy_check 실행 시간: 26.245초\n",
      "\n",
      "\n",
      "epoch-62 loss : 0.00923906, loss_normal : 0.01262883, loss_coarse : 0.05866576, min_loss : 0.00923906, min_loss_normal : 0.01262883, min_loss_coarse : 0.05863434, wrong_element_sum : 11263826.00000000, same_data : 0.00%\n",
      "ae train 실행 시간: 129.004초, 전체 시작 시간 20250314_000221_115\n",
      "\n",
      "epoch-62 accuracy check\n",
      "k_means origin feature average accuracy : 82.26392107%, total [0.9746727376209448, 0.9733106189664963, 0.9700891573195284, 0.9530800230282096, 0.943108504398827, 0.915340909090909, 0.8015244796247435, 0.6625070901871809, 0.9488619568430388, 0.822215777262181, 0.5866935483870968, 0.5005858230814294, 0.9429250891795482, 0.8922588099364529, 0.6747093023255814, 0.6003435442313197]\n",
      "kmeans average accuracy best : 91.81%, kmeans average accuracy : 91.23237339%, total [0.9766647694934547, 0.978137421919364, 0.9752660339373023, 0.9677605066206102, 0.9651026392961877, 0.9576704545454545, 0.9308120785693345, 0.8587634713556438, 0.9692580549807863, 0.9301044083526682, 0.8608870967741935, 0.8040421792618629, 0.9479785969084423, 0.9133448873483535, 0.8287790697674419, 0.732608073289436]\n",
      "cluster_accuracy_post_training_cycle_all_dataset : [0.97918638 0.97832234 0.97496389 0.96769527 0.96716418 0.95518868\n",
      " 0.92789657 0.84854186 0.96016137 0.93408203 0.82673745 0.69563059\n",
      " 0.94959267 0.91416101 0.82794118 0.75680841]\n",
      "mean_cluster_accuracy_during_training_cycle : 89.80%, post_traincycle_acc : 90.40%, total_acc : 90.15562024%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 90.98%\n",
      "accuracy_check 실행 시간: 27.386초\n",
      "\n",
      "\n",
      "epoch-63 loss : 0.00925173, loss_normal : 0.01264228, loss_coarse : 0.05871893, min_loss : 0.00923906, min_loss_normal : 0.01262883, min_loss_coarse : 0.05863434, wrong_element_sum : 11274034.00000000, same_data : 0.00%\n",
      "ae train 실행 시간: 131.233초, 전체 시작 시간 20250314_000221_115\n",
      "\n",
      "epoch-63 accuracy check\n",
      "k_means origin feature average accuracy : 82.25855480%, total [0.9746727376209448, 0.9733106189664963, 0.9700891573195284, 0.9530800230282096, 0.943108504398827, 0.9150568181818182, 0.801817648783348, 0.6625070901871809, 0.9488619568430388, 0.822215777262181, 0.5866935483870968, 0.5005858230814294, 0.9429250891795482, 0.8922588099364529, 0.6741279069767442, 0.6000572573718866]\n",
      "kmeans average accuracy best : 91.81%, kmeans average accuracy : 91.35052288%, total [0.9766647694934547, 0.978137421919364, 0.9749784296807593, 0.9674726540011515, 0.9642228739002933, 0.9602272727272727, 0.9340369393139841, 0.8689733408961997, 0.967188885604493, 0.9266241299303944, 0.8545506912442397, 0.7943760984182777, 0.9568965517241379, 0.9243212016175621, 0.8296511627906977, 0.7377612367592328]\n",
      "cluster_accuracy_post_training_cycle_all_dataset : [0.97918638 0.97879359 0.97544535 0.96817743 0.96666667 0.95801887\n",
      " 0.93635007 0.85136406 0.96016137 0.93017578 0.81660232 0.76713009\n",
      " 0.95824847 0.92628516 0.84117647 0.75298614]\n",
      "mean_cluster_accuracy_during_training_cycle : 89.63%, post_traincycle_acc : 91.04%, total_acc : 90.46516627%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 90.98%\n",
      "accuracy_check 실행 시간: 28.203초\n",
      "\n",
      "\n",
      "epoch-64 loss : 0.00923914, loss_normal : 0.01263527, loss_coarse : 0.05868558, min_loss : 0.00923906, min_loss_normal : 0.01262883, min_loss_coarse : 0.05863434, wrong_element_sum : 11267632.00000000, same_data : 0.00%\n",
      "ae train 실행 시간: 127.061초, 전체 시작 시간 20250314_000221_115\n",
      "\n",
      "epoch-64 accuracy check\n",
      "k_means origin feature average accuracy : 82.25673794%, total [0.9746727376209448, 0.9733106189664963, 0.9700891573195284, 0.9530800230282096, 0.943108504398827, 0.9150568181818182, 0.801817648783348, 0.6625070901871809, 0.9488619568430388, 0.822215777262181, 0.5866935483870968, 0.5005858230814294, 0.9429250891795482, 0.8922588099364529, 0.6738372093023256, 0.6000572573718866]\n",
      "kmeans average accuracy best : 91.81%, kmeans average accuracy : 91.45384249%, total [0.9769493454752419, 0.978137421919364, 0.9749784296807593, 0.966321243523316, 0.9648093841642229, 0.959659090909091, 0.9343301084725887, 0.8681225184344866, 0.9739875849837423, 0.9379350348027842, 0.875, 0.8181019332161688, 0.9476813317479191, 0.9170999422299249, 0.8203488372093023, 0.7191525908960779]\n",
      "cluster_accuracy_post_training_cycle_all_dataset : [0.97965941 0.97832234 0.97544535 0.96817743 0.96517413 0.95660377\n",
      " 0.92839383 0.83396049 0.96974281 0.94335938 0.85183398 0.43048659\n",
      " 0.95162933 0.9185257  0.83823529 0.72814142]\n",
      "mean_cluster_accuracy_during_training_cycle : 89.31%, post_traincycle_acc : 88.86%, total_acc : 89.04468028%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 90.98%\n",
      "accuracy_check 실행 시간: 30.285초\n",
      "\n",
      "\n",
      "epoch-65 loss : 0.00924980, loss_normal : 0.01263048, loss_coarse : 0.05867544, min_loss : 0.00923906, min_loss_normal : 0.01262883, min_loss_coarse : 0.05863434, wrong_element_sum : 11265684.00000000, same_data : 0.00%\n",
      "ae train 실행 시간: 127.449초, 전체 시작 시간 20250314_000221_115\n",
      "\n",
      "epoch-65 accuracy check\n",
      "k_means origin feature average accuracy : 82.18734789%, total [0.9746727376209448, 0.9733106189664963, 0.9700891573195284, 0.9530800230282096, 0.943108504398827, 0.9150568181818182, 0.801817648783348, 0.6622234826999432, 0.9488619568430388, 0.822215777262181, 0.5872695852534562, 0.4906268306971295, 0.9429250891795482, 0.8922588099364529, 0.673546511627907, 0.598912109934154]\n",
      "kmeans average accuracy best : 91.81%, kmeans average accuracy : 90.85917185%, total [0.9766647694934547, 0.9784213515048268, 0.9752660339373023, 0.9660333909038572, 0.9633431085043989, 0.9599431818181818, 0.9357959542656112, 0.8621667612024957, 0.9725096068578185, 0.9417053364269141, 0.8617511520737328, 0.8084358523725835, 0.9470868014268727, 0.9020797227036396, 0.7834302325581395, 0.7028342399083882]\n",
      "cluster_accuracy_post_training_cycle_all_dataset : [0.97965941 0.97926484 0.97544535 0.96721311 0.9641791  0.95660377\n",
      " 0.93833913 0.8607714  0.96822995 0.94140625 0.83976834 0.65888779\n",
      " 0.94755601 0.91319108 0.81764706 0.7090301 ]\n",
      "mean_cluster_accuracy_during_training_cycle : 89.33%, post_traincycle_acc : 90.11%, total_acc : 89.79076775%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 90.98%\n",
      "accuracy_check 실행 시간: 27.843초\n",
      "\n",
      "\n",
      "epoch-66 loss : 0.00920924, loss_normal : 0.01261481, loss_coarse : 0.05856609, min_loss : 0.00920924, min_loss_normal : 0.01261481, min_loss_coarse : 0.05856609, wrong_element_sum : 11244690.00000000, same_data : 0.00%\n",
      "ae train 실행 시간: 127.754초, 전체 시작 시간 20250314_000221_115\n",
      "\n",
      "epoch-66 accuracy check\n",
      "k_means origin feature average accuracy : 82.26041597%, total [0.9746727376209448, 0.9733106189664963, 0.9700891573195284, 0.9530800230282096, 0.943108504398827, 0.9150568181818182, 0.801817648783348, 0.6622234826999432, 0.9488619568430388, 0.822215777262181, 0.5866935483870968, 0.5005858230814294, 0.9429250891795482, 0.8922588099364529, 0.6747093023255814, 0.6000572573718866]\n",
      "kmeans average accuracy best : 91.81%, kmeans average accuracy : 91.27334863%, total [0.9766647694934547, 0.978137421919364, 0.9752660339373023, 0.9668969487622338, 0.9636363636363636, 0.9585227272727272, 0.931105247727939, 0.8579126488939308, 0.9692580549807863, 0.929814385150812, 0.856278801843318, 0.8060925600468658, 0.9524375743162902, 0.9196995956094743, 0.8322674418604651, 0.7297452046951045]\n",
      "cluster_accuracy_post_training_cycle_all_dataset : [0.97871334 0.97785108 0.97496389 0.96817743 0.96616915 0.95518868\n",
      " 0.92938836 0.81702728 0.96469995 0.92529297 0.83108108 0.68272095\n",
      " 0.95366599 0.91561591 0.84117647 0.7682752 ]\n",
      "mean_cluster_accuracy_during_training_cycle : 89.07%, post_traincycle_acc : 90.31%, total_acc : 89.80342357%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 90.98%\n",
      "accuracy_check 실행 시간: 28.770초\n",
      "\n",
      "\n",
      "epoch-67 loss : 0.00920010, loss_normal : 0.01260722, loss_coarse : 0.05853547, min_loss : 0.00920010, min_loss_normal : 0.01260722, min_loss_coarse : 0.05853547, wrong_element_sum : 11238810.00000000, same_data : 0.00%\n",
      "ae train 실행 시간: 129.631초, 전체 시작 시간 20250314_000221_115\n",
      "\n",
      "epoch-67 accuracy check\n",
      "k_means origin feature average accuracy : 82.23879117%, total [0.9746727376209448, 0.9733106189664963, 0.9700891573195284, 0.9530800230282096, 0.943108504398827, 0.9150568181818182, 0.8015244796247435, 0.6622234826999432, 0.9488619568430388, 0.822215777262181, 0.5866935483870968, 0.5005858230814294, 0.9429250891795482, 0.8922588099364529, 0.673546511627907, 0.5980532493558546]\n",
      "kmeans average accuracy best : 91.81%, kmeans average accuracy : 91.43598443%, total [0.9766647694934547, 0.9784213515048268, 0.9749784296807593, 0.9666090961427749, 0.9651026392961877, 0.9585227272727272, 0.9293462327763119, 0.867838910947249, 0.9665976943541236, 0.9228538283062645, 0.8574308755760369, 0.8014059753954306, 0.952140309155767, 0.9228769497400346, 0.8351744186046511, 0.7537933008874893]\n",
      "cluster_accuracy_post_training_cycle_all_dataset : [0.97965941 0.97879359 0.97544535 0.96817743 0.96616915 0.95566038\n",
      " 0.92043759 0.85277516 0.95864851 0.92773438 0.8257722  0.65640516\n",
      " 0.95315682 0.92386033 0.84803922 0.77544195]\n",
      "mean_cluster_accuracy_during_training_cycle : 89.79%, post_traincycle_acc : 90.41%, total_acc : 90.15802931%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 90.98%\n",
      "accuracy_check 실행 시간: 29.325초\n",
      "\n",
      "\n",
      "epoch-68 loss : 0.00922294, loss_normal : 0.01260561, loss_coarse : 0.05861968, min_loss : 0.00920010, min_loss_normal : 0.01260561, min_loss_coarse : 0.05853547, wrong_element_sum : 11254978.00000000, same_data : 0.00%\n",
      "ae train 실행 시간: 128.936초, 전체 시작 시간 20250314_000221_115\n",
      "\n",
      "epoch-68 accuracy check\n",
      "k_means origin feature average accuracy : 82.24421289%, total [0.9746727376209448, 0.9733106189664963, 0.9700891573195284, 0.9530800230282096, 0.943108504398827, 0.9150568181818182, 0.801817648783348, 0.6625070901871809, 0.9488619568430388, 0.822215777262181, 0.5866935483870968, 0.5005858230814294, 0.9429250891795482, 0.8922588099364529, 0.6738372093023256, 0.5980532493558546]\n",
      "kmeans average accuracy best : 91.81%, kmeans average accuracy : 90.97836464%, total [0.9766647694934547, 0.978137421919364, 0.9752660339373023, 0.9657455382843984, 0.9648093841642229, 0.959659090909091, 0.9349164467897977, 0.8641520136131594, 0.9698492462311558, 0.929814385150812, 0.847926267281106, 0.7952548330404218, 0.9515457788347206, 0.9165222414789139, 0.8165697674418605, 0.7097051245347838]\n",
      "cluster_accuracy_post_training_cycle_all_dataset : [0.9782403  0.97737983 0.97544535 0.96914176 0.96666667 0.95471698\n",
      " 0.93635007 0.84995296 0.96772567 0.93115234 0.82722008 0.47368421\n",
      " 0.95570265 0.92192047 0.83970588 0.73865265]\n",
      "mean_cluster_accuracy_during_training_cycle : 89.06%, post_traincycle_acc : 89.15%, total_acc : 89.11294569%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 90.98%\n",
      "accuracy_check 실행 시간: 30.172초\n",
      "\n",
      "\n",
      "epoch-69 loss : 0.00919373, loss_normal : 0.01259595, loss_coarse : 0.05847809, min_loss : 0.00919373, min_loss_normal : 0.01259595, min_loss_coarse : 0.05847809, wrong_element_sum : 11227794.00000000, same_data : 0.00%\n",
      "ae train 실행 시간: 131.371초, 전체 시작 시간 20250314_000221_115\n",
      "\n",
      "epoch-69 accuracy check\n",
      "k_means origin feature average accuracy : 82.26037166%, total [0.9746727376209448, 0.9733106189664963, 0.9700891573195284, 0.9530800230282096, 0.943108504398827, 0.9150568181818182, 0.801817648783348, 0.6625070901871809, 0.9488619568430388, 0.822215777262181, 0.5866935483870968, 0.5005858230814294, 0.9429250891795482, 0.8922588099364529, 0.6744186046511628, 0.6000572573718866]\n",
      "kmeans average accuracy best : 91.81%, kmeans average accuracy : 91.52472506%, total [0.9766647694934547, 0.9784213515048268, 0.9749784296807593, 0.9666090961427749, 0.9656891495601173, 0.9582386363636364, 0.9331574318381706, 0.866988088485536, 0.9710316287318947, 0.927784222737819, 0.8582949308755761, 0.8052138254247218, 0.9533293697978596, 0.9248989023685731, 0.8343023255813954, 0.7483538505582594]\n",
      "cluster_accuracy_post_training_cycle_all_dataset : [0.97776727 0.97832234 0.97448243 0.96914176 0.96716418 0.95518868\n",
      " 0.92988563 0.84854186 0.96873424 0.93017578 0.83638996 0.74627607\n",
      " 0.95315682 0.92628516 0.8372549  0.7682752 ]\n",
      "mean_cluster_accuracy_during_training_cycle : 90.08%, post_traincycle_acc : 91.04%, total_acc : 90.65176074%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 90.98%\n",
      "accuracy_check 실행 시간: 28.929초\n",
      "\n",
      "\n",
      "epoch-70 loss : 0.00919021, loss_normal : 0.01260861, loss_coarse : 0.05852649, min_loss : 0.00919021, min_loss_normal : 0.01259595, min_loss_coarse : 0.05847809, wrong_element_sum : 11237086.00000000, same_data : 0.00%\n",
      "ae train 실행 시간: 128.084초, 전체 시작 시간 20250314_000221_115\n",
      "\n",
      "epoch-70 accuracy check\n",
      "k_means origin feature average accuracy : 82.25675297%, total [0.9746727376209448, 0.9733106189664963, 0.9700891573195284, 0.9530800230282096, 0.943108504398827, 0.9150568181818182, 0.8015244796247435, 0.6622234826999432, 0.9488619568430388, 0.822215777262181, 0.5866935483870968, 0.5002929115407148, 0.9429250891795482, 0.8922588099364529, 0.6747093023255814, 0.6000572573718866]\n",
      "kmeans average accuracy best : 91.81%, kmeans average accuracy : 91.05553482%, total [0.9763801935116676, 0.9775695627484384, 0.9749784296807593, 0.9657455382843984, 0.9636363636363636, 0.9579545454545455, 0.9290530636177075, 0.8528077141236529, 0.9689624593556015, 0.9272041763341067, 0.8513824884792627, 0.7955477445811365, 0.9545184304399524, 0.9225880993645291, 0.8319767441860465, 0.7185800171772115]\n",
      "cluster_accuracy_post_training_cycle_all_dataset : [0.97729423 0.97690858 0.97496389 0.96721311 0.96666667 0.95471698\n",
      " 0.93336648 0.84336783 0.96469995 0.92480469 0.81611969 0.76415094\n",
      " 0.95468432 0.92192047 0.82352941 0.74916388]\n",
      "mean_cluster_accuracy_during_training_cycle : 90.23%, post_traincycle_acc : 90.71%, total_acc : 90.51246405%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 90.98%\n",
      "accuracy_check 실행 시간: 29.664초\n",
      "\n",
      "\n",
      "epoch-71 loss : 0.00920575, loss_normal : 0.01259410, loss_coarse : 0.05849152, min_loss : 0.00919021, min_loss_normal : 0.01259410, min_loss_coarse : 0.05847809, wrong_element_sum : 11230372.00000000, same_data : 0.00%\n",
      "ae train 실행 시간: 131.911초, 전체 시작 시간 20250314_000221_115\n",
      "\n",
      "epoch-71 accuracy check\n",
      "k_means origin feature average accuracy : 82.25858366%, total [0.9746727376209448, 0.9733106189664963, 0.9700891573195284, 0.9530800230282096, 0.943108504398827, 0.9150568181818182, 0.8015244796247435, 0.6622234826999432, 0.9488619568430388, 0.822215777262181, 0.5866935483870968, 0.5005858230814294, 0.9429250891795482, 0.8922588099364529, 0.6747093023255814, 0.6000572573718866]\n",
      "kmeans average accuracy best : 91.81%, kmeans average accuracy : 91.15287096%, total [0.9766647694934547, 0.9784213515048268, 0.9749784296807593, 0.9674726540011515, 0.963049853372434, 0.9599431818181818, 0.9340369393139841, 0.8644356211003971, 0.9642329293526456, 0.9292343387470998, 0.8476382488479263, 0.7864674868189807, 0.9530321046373365, 0.9205661467359908, 0.8311046511627908, 0.7331806470083023]\n",
      "cluster_accuracy_post_training_cycle_all_dataset : [0.97918638 0.97832234 0.97544535 0.96817743 0.96567164 0.95660377\n",
      " 0.93585281 0.8480715  0.95360565 0.92480469 0.81467181 0.64101291\n",
      " 0.95773931 0.92046557 0.83529412 0.75107501]\n",
      "mean_cluster_accuracy_during_training_cycle : 89.46%, post_traincycle_acc : 90.04%, total_acc : 89.80043917%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 90.98%\n",
      "accuracy_check 실행 시간: 29.536초\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "gpu = '1'\n",
    "Conv_net = True # True False\n",
    "SAE_net = True # True False\n",
    "\n",
    "# hyperparameter\n",
    "dataset_num = 16\n",
    "spike_length = 50 # coarse_com_mode일 때는 time step이 됨.\n",
    "num_cluster = 4  # 클러스터 수 설정 # 논문엔 4개라는데 여기서는 3개로 했네\n",
    "training_cycle = 1400 #1400 2400 # 그 초기 몇개까지만 cluster update할지\n",
    "\n",
    "\n",
    "batch_size = 32\n",
    "max_epoch = 10000\n",
    "learning_rate = 0.001\n",
    "normalize_on = True # True or False # 0부터1까지 normalize\n",
    "need_bias = False\n",
    "# first_layer_no_train = False\n",
    "lif_add_at_first = False\n",
    "my_seed = 42\n",
    "\n",
    "TIME = 50 # SAE일 때만 유효. coarse_com_mode일 때는 level_num이 됨. 즉 feature 개수.\n",
    "v_decay = 0.5 # -cor\n",
    "v_threshold = 0.25 # -cor\n",
    "v_reset = 0.0 # -cor # 10000이상 일 시 hard reset\n",
    "BPTT_on = True # +cor # True False\n",
    "\n",
    "SAE_hidden_nomean = True # True False\n",
    "\n",
    "current_time = datetime.datetime.now().strftime(\"%Y%m%d_%H%M%S\") + f\"_{str(int(datetime.datetime.now().microsecond / 1000)).zfill(3)}\"\n",
    "\n",
    "optimizer = 'Adam' #'Adam', 'SGD' # 둘다 준수함. loss 줄이는 거는 adam이 좋긴한데, cluster accuracy는 비슷함.\n",
    "\n",
    "coarse_com_mode = True # True False\n",
    "coarse_com_config = (0.999, -0.0) # (max, min) (0.999, -0.0) (1.0, -0.0) (2.0, -2.0) (3.0, -3.0)\n",
    "\n",
    "sae_l2_norm_bridge = True # True False\n",
    "sae_lif_bridge = False # True False\n",
    "\n",
    "accuracy_check_epoch_term = 1\n",
    "\n",
    "lif_add_at_last = False # True False\n",
    "\n",
    "two_channel_input = False # True False\n",
    "\n",
    "lateral_feature_num = 5\n",
    "\n",
    "lc_adc_on = False # True False\n",
    "\n",
    "converted_net_forward = False # True False\n",
    "\n",
    "pretrained_net = None\n",
    "# pretrained_net = '/home/bhkim003/github_folder/ByeonghyeonKim/my_snn/net_save/save_now_net_중요_20250110_203117_390.pth'\n",
    "# pretrained_net = '/home/bhkim003/github_folder/ByeonghyeonKim/my_snn/net_save/save_now_net_중요_20250113_134126_881_이거_94나오는거.pth'\n",
    "# pretrained_net =  '/home/bhkim003/github_folder/ByeonghyeonKim/my_snn/net_save/save_now_net_20250205_184901_132.pth'\n",
    "# pretrained_net =  '/home/bhkim003/github_folder/ByeonghyeonKim/my_snn/net_save/save_now_net_20250306_134219_133.pth'\n",
    "\n",
    "vth_mul_on = False # True False\n",
    "batch_norm_on = False # True False\n",
    "\n",
    "l2_norm_loss_weight = 0 #0.0001 #0.1 #  0 # 0초과면 작동\n",
    "\n",
    "QCFS_neuron_on = False # True False\n",
    "\n",
    "quantize_level_num = 0 # 0이면 quantize 안함. 1이상이면 그 수만큼 quantize함. # normalize_on 켜져야됨. 음수면 0~1norm안하고 quant함\n",
    "\n",
    "fusion_net = True # True False # SAE_net False, Conv_net True로 해라. TIME 적절하게 설정해주고.\n",
    "repeat_coding = False # True False #fusion_net에서 쓰이는 거임 # True면 repeat, False면 rate coding.\n",
    "\n",
    "sae_relu_on = False # True False\n",
    "\n",
    "conv1d_scaling = False # True False # conv1d때매 norm하고 (level_num-3)/level_num 곱해줌 # Conv_net and coarse_com_mode and normalize_on\n",
    "\n",
    "norm01 = True # True False # normalize_on = True일 때 01norm하는지 아님 걍 quant만 하는지.\n",
    "\n",
    "wandb.init(project= f'spike_sorting just run',save_code=False)\n",
    "\n",
    "\n",
    "cluster_train_system( \n",
    "    gpu = gpu,\n",
    "    Conv_net = Conv_net,\n",
    "    SAE_net = SAE_net,\n",
    "\n",
    "    # hyperparameter\n",
    "    dataset_num = dataset_num,\n",
    "    spike_length = spike_length,\n",
    "    num_cluster = num_cluster,  # 클러스터 수 설정 # 논문엔 4개라는데 여기서는 3개로 했네\n",
    "    training_cycle = training_cycle, # 그 초기 몇개까지만 cluster update할지\n",
    "\n",
    "\n",
    "    batch_size = batch_size,\n",
    "    max_epoch = max_epoch,\n",
    "    learning_rate = learning_rate,\n",
    "    normalize_on = normalize_on, # True or False #이거 안 씀 # 이거 별로 안 좋은 normalize같음 # 쓸 거면 다른 거 써라.\n",
    "    need_bias = need_bias,\n",
    "    # first_layer_no_train = False\n",
    "    lif_add_at_first = lif_add_at_first,\n",
    "    my_seed = my_seed,\n",
    "\n",
    "    TIME = TIME, # SAE일 때만 유효\n",
    "    v_decay = v_decay,\n",
    "    v_threshold = v_threshold,\n",
    "    v_reset = v_reset, # 10000이상 일 시 hard reset\n",
    "    BPTT_on = BPTT_on,\n",
    "\n",
    "    SAE_hidden_nomean = SAE_hidden_nomean,\n",
    "    \n",
    "    current_time = current_time,\n",
    "\n",
    "    optimizer = optimizer, #'Adam', 'SGD'\n",
    "\n",
    "    coarse_com_mode = coarse_com_mode,\n",
    "    coarse_com_config = coarse_com_config, # (max, min)\n",
    "\n",
    "    \n",
    "    sae_l2_norm_bridge = sae_l2_norm_bridge,\n",
    "    sae_lif_bridge = sae_lif_bridge,\n",
    "\n",
    "    accuracy_check_epoch_term = accuracy_check_epoch_term,\n",
    "    \n",
    "    lif_add_at_last = lif_add_at_last,\n",
    "\n",
    "    two_channel_input = two_channel_input,\n",
    "\n",
    "    lateral_feature_num = lateral_feature_num,\n",
    "\n",
    "    lc_adc_on = lc_adc_on, \n",
    "\n",
    "    converted_net_forward = converted_net_forward,\n",
    "\n",
    "    pretrained_net = pretrained_net,\n",
    "\n",
    "    vth_mul_on = vth_mul_on,\n",
    "    batch_norm_on = batch_norm_on,\n",
    "\n",
    "    l2_norm_loss_weight = l2_norm_loss_weight,\n",
    "    \n",
    "    QCFS_neuron_on = QCFS_neuron_on, # True False\n",
    "\n",
    "    quantize_level_num = quantize_level_num,\n",
    "\n",
    "    fusion_net = fusion_net, # True False\n",
    "    repeat_coding = repeat_coding,\n",
    "\n",
    "    sae_relu_on = sae_relu_on,\n",
    "\n",
    "    conv1d_scaling = conv1d_scaling,\n",
    "\n",
    "    norm01 = norm01,\n",
    "\n",
    "    )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Sweep code\n",
    "\n",
    "\n",
    "# from unittest import TextTestRunner\n",
    "\n",
    "\n",
    "# unique_name_hyper = 'cluster_train_system'\n",
    "# # run_name = 'spike_sorting'\n",
    "# sweep_start_time =  datetime.datetime.now().strftime(\"%Y%m%d_%H%M%S\") + f\"_{str(int(datetime.datetime.now().microsecond / 1000)).zfill(3)}\"\n",
    "# sweep_configuration = {\n",
    "#     'method': 'bayes', # 'random', 'bayes'\n",
    "#     'name': f'spike_sorting_{sweep_start_time}',\n",
    "#     'metric': {'goal': 'maximize', 'name': 'k_means_acc_best'},\n",
    "#     'parameters': \n",
    "#     {\n",
    "#         # \"gpu\": {\"values\": ['1']},  # 이건 sweep parameter아님. hyper_iter에서 직접 설정\n",
    "#         \"Conv_net\": {\"values\": [True]}, \n",
    "#         \"SAE_net\": {\"values\": [True]}, \n",
    "\n",
    "#         \"dataset_num\": {\"values\": [16]}, \n",
    "#         \"spike_length\": {\"values\": [50]},  \n",
    "#         \"num_cluster\": {\"values\": [4]}, \n",
    "#         \"training_cycle\": {\"values\": [1400]}, # [1400, 2400]\n",
    "\n",
    "#         \"batch_size\": {\"values\": [32]}, \n",
    "#         \"max_epoch\": {\"values\": [20]}, \n",
    "#         \"learning_rate\": {\"values\": [0.001, 0.0001]},\n",
    "#         \"normalize_on\": {\"values\": [True]},\n",
    "#         \"need_bias\": {\"values\": [False]}, # [True, False]\n",
    "\n",
    "#         \"lif_add_at_first\": {\"values\": [False]}, # [True, False]\n",
    "#         \"my_seed\": {\"values\": [42]}, \n",
    "\n",
    "#         \"TIME\": {\"values\": [50]}, #  [4,6,8,10]\n",
    "#         \"v_decay\": {\"values\": [0.125, 0.25,0.50,0.75,1.0]}, # [0.25,0.50,0.75]\n",
    "#         \"v_threshold\": {\"values\": [0.125, 0.25, 0.50, 0.75, 0.875, 1.0]}, # [0.25,0.50,0.75]\n",
    "#         \"v_reset\": {\"values\": [0.0, 10000.0]},  # [0.0, 10000.0]\n",
    "#         \"BPTT_on\": {\"values\": [True, False]},  # [True, False]\n",
    "\n",
    "#         \"SAE_hidden_nomean\": {\"values\": [True]}, # [True, False]\n",
    "\n",
    "#         # \"current_time\": {\"values\": [current_time]} #밑에서 직접설정됨.\n",
    "\n",
    "#         \"optimizer\": {\"values\": ['Adam', 'SGD']}, # ['Adam', 'SGD']\n",
    "\n",
    "#         \"coarse_com_mode\": {\"values\": [True]}, # [True, False]\n",
    "#         \"coarse_com_config\": {\"values\": [(0.999, -0.0)]}, # ['Adam', 'SGD']\n",
    "\n",
    "#         \"sae_l2_norm_bridge\": {\"values\": [True]}, # [True, False]\n",
    "#         \"sae_lif_bridge\": {\"values\": [False]}, # [False, True]\n",
    "        \n",
    "#         \"accuracy_check_epoch_term\": {\"values\": [1]}, \n",
    "\n",
    "#         \"lif_add_at_last\": {\"values\": [False]},# [True, False]\n",
    "\n",
    "#         \"two_channel_input\": {\"values\": [False]},# [True, False]\n",
    "\n",
    "#         \"lateral_feature_num\": {\"values\": [4]},# [True, False]\n",
    "\n",
    "#         \"lc_adc_on\": {\"values\": [False]},# [True, False]\n",
    "        \n",
    "#         \"converted_net_forward\": {\"values\": [False]},# [True, False]\n",
    "\n",
    "#         \"pretrained_net\": {\"values\": [None]},# [None]\n",
    "\n",
    "#         \"vth_mul_on\": {\"values\": [False]},# [True, False]\n",
    "#         \"batch_norm_on\": {\"values\": [False]},# [True, False]\n",
    "\n",
    "#         \"l2_norm_loss_weight\": {\"values\": [0]},\n",
    "\n",
    "#         \"QCFS_neuron_on\": {\"values\": [False]},   # [True, False]\n",
    "\n",
    "#         \"quantize_level_num\": {\"values\": [0]}, \n",
    "\n",
    "#         \"fusion_net\": {\"values\": [True]}, \n",
    "#         \"repeat_coding\": {\"values\": [False]}, \n",
    "\n",
    "#         \"sae_relu_on\": {\"values\": [False]}, \n",
    "\n",
    "#         \"conv1d_scaling\": {\"values\": [False]}, \n",
    "\n",
    "#         \"norm01\": {\"values\": [True]}, \n",
    "#      }\n",
    "# }\n",
    "\n",
    "\n",
    "# def hyper_iter():\n",
    "#     ### my_snn control board ########################\n",
    "#     wandb.init(save_code = False)\n",
    "#     gpu  =  '2'\n",
    "#     Conv_net  =  wandb.config.Conv_net\n",
    "#     SAE_net  =  wandb.config.SAE_net\n",
    "\n",
    "#     dataset_num  =  wandb.config.dataset_num\n",
    "#     spike_length  =  wandb.config.spike_length\n",
    "#     num_cluster  =  wandb.config.num_cluster\n",
    "#     training_cycle  =  wandb.config.training_cycle\n",
    "\n",
    "#     batch_size  =  wandb.config.batch_size\n",
    "#     max_epoch  =  wandb.config.max_epoch\n",
    "#     learning_rate  =  wandb.config.learning_rate\n",
    "#     normalize_on  =  wandb.config.normalize_on\n",
    "#     need_bias  =  wandb.config.need_bias\n",
    "\n",
    "#     lif_add_at_first  =  wandb.config.lif_add_at_first\n",
    "#     my_seed  =  wandb.config.my_seed\n",
    "\n",
    "\n",
    "#     TIME  =  wandb.config.TIME\n",
    "#     v_decay  =  wandb.config.v_decay\n",
    "#     v_threshold  =  wandb.config.v_threshold\n",
    "#     v_reset  =  wandb.config.v_reset\n",
    "#     BPTT_on  =  wandb.config.BPTT_on\n",
    "\n",
    "#     SAE_hidden_nomean  =  wandb.config.SAE_hidden_nomean\n",
    "    \n",
    "#     current_time =  datetime.datetime.now().strftime(\"%Y%m%d_%H%M%S\") + f\"_{str(int(datetime.datetime.now().microsecond / 1000)).zfill(3)}\"\n",
    "\n",
    "#     optimizer  =  wandb.config.optimizer\n",
    "\n",
    "#     coarse_com_mode = wandb.config.coarse_com_mode\n",
    "#     coarse_com_config = wandb.config.coarse_com_config # (max, min)\n",
    "\n",
    "#     sae_l2_norm_bridge = wandb.config.sae_l2_norm_bridge\n",
    "#     sae_lif_bridge = wandb.config.sae_lif_bridge\n",
    "\n",
    "#     accuracy_check_epoch_term = wandb.config.accuracy_check_epoch_term\n",
    "\n",
    "#     lif_add_at_last = wandb.config.lif_add_at_last\n",
    "\n",
    "#     two_channel_input = wandb.config.two_channel_input\n",
    "\n",
    "#     lateral_feature_num = wandb.config.lateral_feature_num\n",
    "\n",
    "#     lc_adc_on = wandb.config.lc_adc_on\n",
    "\n",
    "#     converted_net_forward = wandb.config.converted_net_forward\n",
    "\n",
    "#     pretrained_net = wandb.config.pretrained_net\n",
    "\n",
    "#     vth_mul_on = wandb.config.vth_mul_on\n",
    "#     batch_norm_on = wandb.config.batch_norm_on\n",
    "\n",
    "#     l2_norm_loss_weight = wandb.config.l2_norm_loss_weight\n",
    "\n",
    "#     QCFS_neuron_on = wandb.config.QCFS_neuron_on\n",
    "\n",
    "#     quantize_level_num = wandb.config.quantize_level_num\n",
    "\n",
    "#     fusion_net = wandb.config.fusion_net\n",
    "#     repeat_coding = wandb.config.repeat_coding\n",
    "\n",
    "#     sae_relu_on = wandb.config.sae_relu_on\n",
    "\n",
    "#     conv1d_scaling = wandb.config.conv1d_scaling\n",
    "\n",
    "#     norm01 = wandb.config.norm01\n",
    "\n",
    "#     cluster_train_system( \n",
    "#         gpu = gpu,\n",
    "#         Conv_net = Conv_net,\n",
    "#         SAE_net = SAE_net,\n",
    "\n",
    "#         # hyperparameter\n",
    "#         dataset_num = dataset_num,\n",
    "#         spike_length = spike_length,\n",
    "#         num_cluster = num_cluster,  # 클러스터 수 설정 # 논문엔 4개라는데 여기서는 3개로 했네\n",
    "#         training_cycle = training_cycle, # 그 초기 몇개까지만 cluster update할지\n",
    "\n",
    "\n",
    "#         batch_size = batch_size,\n",
    "#         max_epoch = max_epoch,\n",
    "#         learning_rate = learning_rate,\n",
    "#         normalize_on = normalize_on, # True or False #이거 안 씀 # 이거 별로 안 좋은 normalize같음 # 쓸 거면 다른 거 써라.\n",
    "#         need_bias = need_bias,\n",
    "#         # first_layer_no_train = False\n",
    "#         lif_add_at_first = lif_add_at_first,\n",
    "#         my_seed = my_seed,\n",
    "\n",
    "#         TIME = TIME, # SAE일 때만 유효\n",
    "#         v_decay = v_decay,\n",
    "#         v_threshold = v_threshold,\n",
    "#         v_reset = v_reset, # 10000이상 일 시 hard reset\n",
    "#         BPTT_on = BPTT_on,\n",
    "\n",
    "#         SAE_hidden_nomean = SAE_hidden_nomean,\n",
    "\n",
    "#         current_time = current_time,\n",
    "\n",
    "#         optimizer = optimizer, #'Adam', 'SGD'\n",
    "\n",
    "#         coarse_com_mode = coarse_com_mode,\n",
    "#         coarse_com_config = coarse_com_config, # (max, min)\n",
    "        \n",
    "#         sae_l2_norm_bridge = sae_l2_norm_bridge,\n",
    "#         sae_lif_bridge = sae_lif_bridge,\n",
    "\n",
    "#         accuracy_check_epoch_term = accuracy_check_epoch_term,\n",
    "\n",
    "#         lif_add_at_last = lif_add_at_last,\n",
    "        \n",
    "#         two_channel_input = two_channel_input,\n",
    "        \n",
    "#         lateral_feature_num = lateral_feature_num,\n",
    "\n",
    "#         lc_adc_on = lc_adc_on,\n",
    "\n",
    "#         converted_net_forward = converted_net_forward,\n",
    "\n",
    "#         pretrained_net = pretrained_net,\n",
    "\n",
    "#         vth_mul_on = vth_mul_on,\n",
    "#         batch_norm_on = batch_norm_on,\n",
    "\n",
    "#         l2_norm_loss_weight = l2_norm_loss_weight,\n",
    "\n",
    "#         QCFS_neuron_on = QCFS_neuron_on,\n",
    "\n",
    "#         quantize_level_num = quantize_level_num,\n",
    "\n",
    "#         fusion_net = fusion_net, \n",
    "#         repeat_coding = repeat_coding, \n",
    "\n",
    "#         sae_relu_on = sae_relu_on,\n",
    "\n",
    "#         conv1d_scaling = conv1d_scaling,\n",
    "\n",
    "#         norm01 = norm01,\n",
    "#         )\n",
    "    \n",
    "# # sweep_id = 'ygoj9jt4'\n",
    "# sweep_id = wandb.sweep(sweep=sweep_configuration, project=f'spike_sorting {unique_name_hyper}')\n",
    "# wandb.agent(sweep_id, function=hyper_iter, count=100000, project=f'spike_sorting {unique_name_hyper}')\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wandb.finish() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import matplotlib.pyplot as plt\n",
    "# from matplotlib.ticker import MaxNLocator\n",
    "# import pickle\n",
    "# import json\n",
    "\n",
    "# # current_time = '20250102_225243_972'\n",
    "\n",
    "# with open(f\"result_save/cluster_accuracy_history_{current_time}.pkl\", \"rb\") as f:\n",
    "#     data = pickle.load(f)\n",
    "\n",
    "\n",
    "# # JSON으로 저장\n",
    "# with open(f\"result_save/cluster_accuracy_history_{current_time}.json\", 'r') as f:\n",
    "#     loaded_hyperparameters = json.load(f)\n",
    "\n",
    "# loss_history = data['loss_history']\n",
    "# mean_cluster_accuracy_during_training_cycle_all_dataset_history = data['mean_cluster_accuracy_during_training_cycle_all_dataset_history']\n",
    "# mean_cluster_accuracy_post_training_cycle_all_dataset_history = data['mean_cluster_accuracy_post_training_cycle_all_dataset_history']\n",
    "# mean_cluster_accuracy_total_all_dataset_history = data['mean_cluster_accuracy_total_all_dataset_history']\n",
    "# print(data)\n",
    "# max_acc = 0\n",
    "# for i in mean_cluster_accuracy_post_training_cycle_all_dataset_history:\n",
    "#     if i[1] > max_acc:\n",
    "#         max_acc = i[1]\n",
    "\n",
    "# # 설정 정보 제목 작성\n",
    "# title = (\n",
    "#     f\"Dataset Num: {loaded_hyperparameters['dataset_num']}, Conv {loaded_hyperparameters['Conv_net']}, SAE {loaded_hyperparameters['SAE_net']}, Current time {loaded_hyperparameters['current_time']}, Spike Length: {loaded_hyperparameters['spike_length']}, Num Cluster: {loaded_hyperparameters['num_cluster']}, \"\n",
    "#     f\"Training Cycle: {loaded_hyperparameters['training_cycle']}, Batch Size: {loaded_hyperparameters['batch_size']}, Max Epoch: {loaded_hyperparameters['max_epoch']}, \\n\"\n",
    "#     f\"Learning Rate: {loaded_hyperparameters['learning_rate']}, Input Normalize: {loaded_hyperparameters['normalize_on']}, Need Bias: {loaded_hyperparameters['need_bias']}, \"\n",
    "#     f\"LIF Add at First: {loaded_hyperparameters['lif_add_at_first']}, TIME: {loaded_hyperparameters['TIME']}, Seed: {loaded_hyperparameters['my_seed']}, Best ACC: {max_acc:.2f}%\"\n",
    "# )\n",
    "\n",
    "# # 데이터 리스트와 라벨 설정 (Loss 제외)\n",
    "# data_list = [\n",
    "#     (\"Mean Cluster Accuracy (During Training Cycle)\", mean_cluster_accuracy_during_training_cycle_all_dataset_history),\n",
    "#     (\"Mean Cluster Accuracy (Post Training Cycle)\", mean_cluster_accuracy_post_training_cycle_all_dataset_history),\n",
    "#     (\"Mean Cluster Accuracy (Total)\", mean_cluster_accuracy_total_all_dataset_history),\n",
    "# ]\n",
    "\n",
    "# # 플롯 생성\n",
    "# fig, ax1 = plt.subplots(figsize=(12, 8))\n",
    "\n",
    "# # 첫 번째 y축: Accuracy 관련 데이터\n",
    "# for label, data in data_list:\n",
    "#     epochs, values = zip(*data)  # epoch, value 분리\n",
    "#     ax1.plot(epochs, values, label=label)\n",
    "\n",
    "# ax1.set_xlabel(\"Epoch\")\n",
    "# ax1.set_ylabel(\"Clurstering Accuracy [%]\", color=\"blue\")\n",
    "# ax1.tick_params(axis=\"y\", labelcolor=\"blue\")\n",
    "# ax1.legend(loc=\"center right\")\n",
    "# ax1.grid(True)\n",
    "\n",
    "# # x축을 정수만 표시하도록 설정\n",
    "# ax1.xaxis.set_major_locator(MaxNLocator(integer=True))\n",
    "\n",
    "# # 두 번째 y축: Loss History\n",
    "# ax2 = ax1.twinx()\n",
    "# epochs, values = zip(*loss_history)\n",
    "# ax2.plot(epochs, values, label=\"AE Loss History\", color=\"red\", linestyle=\"--\")\n",
    "# ax2.set_ylabel(\"Loss\", color=\"red\")\n",
    "# ax2.tick_params(axis=\"y\", labelcolor=\"red\")\n",
    "# ax2.legend(loc=\"center left\")\n",
    "\n",
    "# # 제목 추가\n",
    "# plt.title(title, fontsize=10)\n",
    "# plt.tight_layout()\n",
    "# plt.savefig(f'net_save/{current_time}', dpi=300, bbox_inches=\"tight\")  # dpi=300은 고해상도로 저장, bbox_inches=\"tight\"는 여백 최소화\n",
    "# plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# 데이터셋\n",
    "filename_for_plot = [\n",
    "    \"Easy1_noise05\", \"Easy1_noise10\", \"Easy1_noise15\", \"Easy1_noise20\",\n",
    "    \"Easy2_noise05\", \"Easy2_noise10\", \"Easy2_noise15\", \"Easy2_noise20\",\n",
    "    \"Difficult1_noise05\", \"Difficult1_noise10\", \"Difficult1_noise15\", \"Difficult1_noise20\",\n",
    "    \"Difficult2_noise05\", \"Difficult2_noise10\", \"Difficult2_noise15\", \"Difficult2_noise20\"\n",
    "]\n",
    "\n",
    "# Accuracy 데이터\n",
    "ANN_conv_accracy_set= [0.97935368, 0.97682709, 0.97028784, 0.96461825, 0.97524752, 0.95803571\n",
    ", 0.95746785, 0.92628774, 0.965412,  0.97805344, 0.94869403, 0.92110454\n",
    ", 0.96784232, 0.97551789, 0.91538462, 0.84446478]\n",
    "SNN_fc_accuracy_set = [0.97114475, 0.97643732, 0.84400578, 0.78977821, 0.96616915, 0.92830189\n",
    ", 0.86176032, 0.31984948, 0.80635401, 0.88769531, 0.61003861, 0.60377358\n",
    ", 0.9592668,  0.92870999, 0.78333333, 0.67271859]\n",
    "SNN_conv_accuracy_set = [0.97445601, 0.97737983, 0.97063072, 0.95998071, 0.96268657, 0.90566038\n",
    ", 0.82545997, 0.68391345, 0.96116994, 0.92138672, 0.80694981, 0.49602781\n",
    ", 0.83604888, 0.70611057, 0.69313725, 0.5819398 ]\n",
    "\n",
    "# 평균 계산\n",
    "average_ANN_conv = np.mean(ANN_conv_accracy_set)\n",
    "average_SNN_fc = np.mean(SNN_fc_accuracy_set)\n",
    "average_SNN_conv = np.mean(SNN_conv_accuracy_set)\n",
    "\n",
    "# 데이터 준비\n",
    "accuracies = np.array([ANN_conv_accracy_set, SNN_fc_accuracy_set, SNN_conv_accuracy_set])\n",
    "averages = np.array([average_ANN_conv, average_SNN_fc, average_SNN_conv])\n",
    "\n",
    "# 시각화\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "\n",
    "# 각 모델의 정확도 플롯\n",
    "ax.plot(accuracies[0], label='ANN Conv', marker='o', linestyle='-', color='blue')\n",
    "ax.plot(accuracies[1], label='SNN FC', marker='o', linestyle='-', color='green')\n",
    "ax.plot(accuracies[2], label='SNN Conv', marker='o', linestyle='-', color='red')\n",
    "\n",
    "# 평균값 플롯\n",
    "ax.axhline(y=average_ANN_conv, color='blue', linestyle='--', label=f'Average ANN Conv: {average_ANN_conv:.3f}')\n",
    "ax.axhline(y=average_SNN_fc, color='green', linestyle='--', label=f'Average SNN FC: {average_SNN_fc:.3f}')\n",
    "ax.axhline(y=average_SNN_conv, color='red', linestyle='--', label=f'Average SNN Conv: {average_SNN_conv:.3f}')\n",
    "\n",
    "# 레이블 추가\n",
    "ax.set_xticks(np.arange(len(filename_for_plot)))\n",
    "ax.set_xticklabels(filename_for_plot, rotation=45, ha='right')\n",
    "ax.set_ylabel('Accuracy')\n",
    "ax.set_title('Accuracy Comparison of Models on Datasets')\n",
    "ax.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import matplotlib.pyplot as plt\n",
    "import os  # 파일 경로 처리를 위한 모듈\n",
    "\n",
    "# CSV 파일 경로\n",
    "# csv_file_path = \"/home/bhkim003/github_folder/ByeonghyeonKim/my_snn/ae_test_deprecated/250115/sweep0_vth_mul.csv\" # vth_mul해서 sweep 돌린거\n",
    "csv_file_path = \"/home/bhkim003/github_folder/ByeonghyeonKim/my_snn/ae_test_deprecated/250115/sweep1.csv\"  #vth_mul안한거\n",
    "\n",
    "# 결과를 저장할 리스트\n",
    "tuple_list = []\n",
    "\n",
    "# CSV 파일 읽기\n",
    "with open(csv_file_path, 'r') as file:\n",
    "    reader = csv.DictReader(file)\n",
    "    for row in reader:\n",
    "        try:\n",
    "            # v_threshold, TIME, v_reset, converted_k_means_acc 값을 가져와 튜플로 변환\n",
    "            v_threshold = float(row[\"v_threshold\"])\n",
    "            time = int(row[\"TIME\"])\n",
    "            v_reset = int(row[\"v_reset\"])\n",
    "            converted_k_means_acc = float(row[\"converted_k_means_acc\"]) if row[\"converted_k_means_acc\"] else None\n",
    "\n",
    "            # 튜플 형태로 추가 (값이 None일 경우 처리할 수도 있음)\n",
    "            tuple_list.append((v_threshold, time, v_reset, converted_k_means_acc))\n",
    "        except ValueError as e:\n",
    "            print(f\"Error processing row {row}: {e}\")\n",
    "\n",
    "# 데이터를 TIME 기준으로 정렬\n",
    "tuple_list.sort(key=lambda x: x[1])  # TIME을 기준으로 오름차순 정렬\n",
    "\n",
    "# reset 방식에 따라 데이터를 나누기\n",
    "soft_reset = [t for t in tuple_list if t[2] == 0]\n",
    "hard_reset = [t for t in tuple_list if t[2] == 10000]\n",
    "\n",
    "# reset 방식과 v_threshold에 따라 색상 설정\n",
    "def plot_data(data, label_prefix, marker):\n",
    "    for v_threshold in [1.0]:  # v_threshold 기준으로 제한\n",
    "        filtered_data = [(t[1], t[3]) for t in data if t[0] == v_threshold]\n",
    "        if filtered_data:  # 해당 v_threshold 데이터가 있을 경우만 플롯\n",
    "            times, accuracies = zip(*filtered_data)  # x축(TIME), y축(converted_k_means_acc)\n",
    "            \n",
    "            plt.plot(\n",
    "                times,\n",
    "                accuracies,\n",
    "                marker,\n",
    "                label=f\"{label_prefix}, v_threshold={v_threshold}\",\n",
    "                linestyle=\"--\",\n",
    "            )\n",
    "            # 각 점에 accuracy 표시\n",
    "            for time, acc in filtered_data:\n",
    "                if acc == None:\n",
    "                    continue\n",
    "                plt.text(time, acc, f\"{acc:.2f}\", fontsize=8, ha=\"right\")\n",
    "\n",
    "# 그래프 초기화\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "# soft_reset (v_reset=0) 데이터 플롯\n",
    "plot_data(soft_reset, \"Soft Reset\", \"o\")\n",
    "\n",
    "# hard_reset (v_reset=10000) 데이터 플롯\n",
    "plot_data(hard_reset, \"Hard Reset\", \"x\")\n",
    "\n",
    "# baseline accuracy 가로선 추가\n",
    "baseline_accuracy = 94.43\n",
    "plt.axhline(y=baseline_accuracy, color=\"red\", linestyle=\"-\", label=f\"Baseline Accuracy ({baseline_accuracy}%)\")\n",
    "# baseline 텍스트 추가\n",
    "plt.text(\n",
    "    2000,  # x축 위치 (그래프 오른쪽 끝)\n",
    "    baseline_accuracy + 0.4,  # y축 위치 (baseline 위 약간)\n",
    "    f\"ANN Baseline ({baseline_accuracy}%)\",\n",
    "    color=\"red\",\n",
    "    fontsize=10,\n",
    "    ha=\"center\",\n",
    ")\n",
    "\n",
    "# CSV 파일 이름 가져오기\n",
    "csv_file_name = os.path.basename(csv_file_path)\n",
    "\n",
    "# 그래프 세부 설정\n",
    "plt.title(f\"Converted SNN K-Means Accuracy vs TIME STEP - {csv_file_name}\")\n",
    "plt.xlabel(\"TIME STEP\")\n",
    "plt.ylabel(\"Converted K-Means Accuracy [%]\")\n",
    "plt.legend(loc=\"lower right\")  # 범례를 오른쪽 아래로 이동\n",
    "plt.grid(True)\n",
    "\n",
    "# 그래프 출력\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aedat2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
