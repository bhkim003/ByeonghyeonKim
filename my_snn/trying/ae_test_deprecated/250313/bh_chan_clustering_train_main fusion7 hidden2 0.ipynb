{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ssp.train.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x600 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import torch   \n",
    "import torch.nn as nn \n",
    "import torch.nn.functional as F   \n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import torch.optim as optim\n",
    "from scipy import io\n",
    "import itertools\n",
    "import math\n",
    "import datetime\n",
    "import wandb\n",
    "import pickle\n",
    "import json\n",
    "import time\n",
    "import sys\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import accuracy_score\n",
    "from scipy.optimize import linear_sum_assignment\n",
    "from snntorch import spikegen\n",
    "\n",
    "\n",
    "# my module import\n",
    "from modules import *\n",
    "\n",
    "# modules 폴더에 새모듈.py 만들면\n",
    "# modules/__init__py 파일에 form .새모듈 import * 하셈\n",
    "# 그리고 새모듈.py에서 from modules.새모듈 import * 하셈"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cluster_train_system( \n",
    "    gpu = '4',\n",
    "    Conv_net = True,\n",
    "    SAE_net = True,\n",
    "\n",
    "    # hyperparameter\n",
    "    dataset_num = 16,\n",
    "    spike_length = 50,\n",
    "    num_cluster = 4,  # 클러스터 수 설정 # 논문엔 4개라는데 여기서는 3개로 했네\n",
    "    training_cycle = 2400, # 그 초기 몇개까지만 cluster update할지\n",
    "\n",
    "\n",
    "    batch_size = 32,\n",
    "    max_epoch = 7000,\n",
    "    learning_rate = 0.001,\n",
    "    normalize_on = False, # True or False #이거 안 씀 # 이거 별로 안 좋은 normalize같음 # 쓸 거면 다른 거 써라.\n",
    "    need_bias = False,\n",
    "    # first_layer_no_train = False\n",
    "    lif_add_at_first = False,\n",
    "    my_seed = 42,\n",
    "\n",
    "    TIME = 10, # SAE일 때만 유효\n",
    "    v_decay = 0.5,\n",
    "    v_threshold = 0.5,\n",
    "    v_reset = 10000.0, # 10000이상 일 시 hard reset\n",
    "    BPTT_on = True,\n",
    "\n",
    "    SAE_hidden_nomean = True,\n",
    "    current_time = '20250101_210938_786',\n",
    "\n",
    "    optimizer = 'Adam',\n",
    "    coarse_com_mode = True,\n",
    "    coarse_com_config = (2.0, -2.0), # (max, min)\n",
    "\n",
    "    sae_l2_norm_bridge = True,\n",
    "    sae_lif_bridge = False,\n",
    "\n",
    "    accuracy_check_epoch_term = 5,\n",
    "    \n",
    "    lif_add_at_last = False,\n",
    "\n",
    "    two_channel_input = False,\n",
    "\n",
    "    lateral_feature_num = 4,\n",
    "\n",
    "    lc_adc_on = False, \n",
    "\n",
    "    converted_net_forward = False,\n",
    "\n",
    "    pretrained_net = None, \n",
    "\n",
    "    vth_mul_on = False,\n",
    "    batch_norm_on = False,\n",
    "\n",
    "    l2_norm_loss_weight = 0.0,\n",
    "\n",
    "    QCFS_neuron_on = False,\n",
    "\n",
    "    quantize_level_num = 0,\n",
    "\n",
    "    fusion_net = False, # True False\n",
    "    repeat_coding = False,\n",
    "    \n",
    "    sae_relu_on = False,\n",
    "\n",
    "    conv1d_scaling = False,\n",
    "\n",
    "    norm01 = True,\n",
    "    ):\n",
    "    if coarse_com_mode == True:\n",
    "        assert coarse_com_config[0] > coarse_com_config[1], 'coarse_com_config[0] > coarse_com_config[1]이어야 함'\n",
    "        assert converted_net_forward == False\n",
    "        # assert SAE_net == True, 'coarse_com_mode는 SAE_net이 True일 때만 가능'\n",
    "    if two_channel_input == True:\n",
    "        assert Conv_net and coarse_com_mode, 'two_channel_input는 Conv_net이 True일 때만 가능'\n",
    "    if lc_adc_on == True:\n",
    "        assert coarse_com_mode and SAE_net, 'lc_adc_on은 coarse_com_mode와 SAE_net이 True일 때만 가능'\n",
    "    if converted_net_forward == True:\n",
    "        assert SAE_net == False, 'converted_net_forward는 SAE_net이 False일 때만 가능'\n",
    "    if conv1d_scaling:\n",
    "        assert Conv_net and coarse_com_mode and normalize_on\n",
    "    seed_assign(my_seed)\n",
    "    ## 함수 내 모든 로컬 변수 저장 ########################################################\n",
    "    hyperparameters = locals()\n",
    "    print(hyperparameters)\n",
    "    # JSON으로 저장\n",
    "    with open(f\"result_save/cluster_accuracy_history_{current_time}.json\", 'w') as f:\n",
    "        json.dump(hyperparameters, f, indent=4)\n",
    "    ######################################################################################\n",
    "\n",
    "    \n",
    "    wandb.config.update(hyperparameters)\n",
    "    wandb.run.name = f'{current_time}_SAE_net_{SAE_net}_v_threshold_{v_threshold}'\n",
    "    wandb.define_metric(\"best_mean_cluster_accuracy_post_training_cycle_all_dataset2\", summary=\"max\")\n",
    "\n",
    "\n",
    "    my_path_ground_BH = '/data2/spike_sorting/quiroga/BH/'\n",
    "\n",
    "\n",
    "    filename = [\"C_Easy1_noise005.mat\", \"C_Easy1_noise01.mat\", \"C_Easy1_noise015.mat\", \"C_Easy1_noise02.mat\",\n",
    "                \"C_Easy2_noise005.mat\", \"C_Easy2_noise01.mat\", \"C_Easy2_noise015.mat\", \"C_Easy2_noise02.mat\",\n",
    "                \"C_Difficult1_noise005.mat\", \"C_Difficult1_noise01.mat\", \"C_Difficult1_noise015.mat\", \"C_Difficult1_noise02.mat\",\n",
    "                \"C_Difficult2_noise005.mat\", \"C_Difficult2_noise01.mat\", \"C_Difficult2_noise015.mat\", \"C_Difficult2_noise02.mat\"]\n",
    "\n",
    "\n",
    "    spike_tot = [\"BH_Spike_e1n005.npy\", \"BH_Spike_e1n010.npy\", \"BH_Spike_e1n015.npy\", \"BH_Spike_e1n020.npy\",\n",
    "                \"BH_Spike_e2n005.npy\", \"BH_Spike_e2n010.npy\", \"BH_Spike_e2n015.npy\", \"BH_Spike_e2n020.npy\",\n",
    "                \"BH_Spike_d1n005.npy\", \"BH_Spike_d1n010.npy\", \"BH_Spike_d1n015.npy\", \"BH_Spike_d1n020.npy\",\n",
    "                \"BH_Spike_d2n005.npy\", \"BH_Spike_d2n010.npy\", \"BH_Spike_d2n015.npy\", \"BH_Spike_d2n020.npy\"]\n",
    "\n",
    "    label_tot = [\"BH_Label_e1n005.npy\", \"BH_Label_e1n010.npy\", \"BH_Label_e1n015.npy\", \"BH_Label_e1n020.npy\",\n",
    "                \"BH_Label_e2n005.npy\", \"BH_Label_e2n010.npy\", \"BH_Label_e2n015.npy\", \"BH_Label_e2n020.npy\",\n",
    "                \"BH_Label_d1n005.npy\", \"BH_Label_d1n010.npy\", \"BH_Label_d1n015.npy\", \"BH_Label_d1n020.npy\",\n",
    "                \"BH_Label_d2n005.npy\", \"BH_Label_d2n010.npy\", \"BH_Label_d2n015.npy\", \"BH_Label_d2n020.npy\"]\n",
    "\n",
    "    template =  [\"BH_Spike_TEMPLATE_e1n005.npy\", \"BH_Spike_TEMPLATE_e1n010.npy\", \"BH_Spike_TEMPLATE_e1n015.npy\", \"BH_Spike_TEMPLATE_e1n020.npy\",\n",
    "                \"BH_Spike_TEMPLATE_e2n005.npy\", \"BH_Spike_TEMPLATE_e2n010.npy\", \"BH_Spike_TEMPLATE_e2n015.npy\", \"BH_Spike_TEMPLATE_e2n020.npy\",\n",
    "                \"BH_Spike_TEMPLATE_d1n005.npy\", \"BH_Spike_TEMPLATE_d1n010.npy\", \"BH_Spike_TEMPLATE_d1n015.npy\", \"BH_Spike_TEMPLATE_d1n020.npy\",\n",
    "                \"BH_Spike_TEMPLATE_d2n005.npy\", \"BH_Spike_TEMPLATE_d2n010.npy\", \"BH_Spike_TEMPLATE_d2n015.npy\", \"BH_Spike_TEMPLATE_d2n020.npy\"]\n",
    "\n",
    "    AE_train_path_gt_detect = 'BH_quiroga_training_dataset_gt_detect.pt' \n",
    "    AE_test_path_gt_detect = 'BH_quiroga_test_dataset_gt_detect.pt'\n",
    "\n",
    "    AE_train_path_real_detect = 'BH_quiroga_training_dataset_real_detect.pt'\n",
    "    AE_test_path_real_detect = 'BH_quiroga_test_dataset_real_detect.pt'\n",
    "\n",
    "    AE_train_data = AE_train_path_real_detect #AE_train_path_gt_detect #AE_train_path_real_detect\n",
    "    AE_test_data = AE_test_path_real_detect #AE_test_path_gt_detect  #AE_test_path_real_detect\n",
    "\n",
    "    # thr_tot = np.array([0.5, 0.5, 0.55, 0.7, 0.5, 0.5, 0.55, 0.7, 0.5, 0.5, 0.55, 0.7, 0.5, 0.5, 0.55, 0.7])\n",
    "    cos_thr = np.array([0.95, 0.95, 0.95, 0.95, 0.95, 0.95, 0.95, 0.85, 0.95, 0.9, 0.8, 0.95, 0.95, 0.95, 0.95, 0.8])\n",
    "    # tem=10\n",
    "    # cos_thr = np.array([tem, tem, tem, tem, tem, tem, tem, tem, tem, tem, tem, tem, tem, tem, tem, tem, ])\n",
    "\n",
    "    print('cos_thr', cos_thr)\n",
    "    \n",
    "    os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\" \n",
    "    os.environ[\"CUDA_VISIBLE_DEVICES\"]= gpu\n",
    "\n",
    "\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "\n",
    "    if coarse_com_mode == True:\n",
    "        level_num = TIME\n",
    "        TIME = spike_length\n",
    "        spike_length = level_num\n",
    "        level_interval = (coarse_com_config[0] - coarse_com_config[1]) / (level_num-1)  # max - min\n",
    "        levels = [coarse_com_config[1] + level_interval * i for i in range(level_num)]\n",
    "        levels = torch.tensor(levels).to(torch.float).to(device)\n",
    "        levels = levels.repeat(TIME,1) \n",
    "        # print('levels', levels, levels.shape) # TIME, level_num\n",
    "\n",
    "    n_sample = spike_length\n",
    "\n",
    "    class spikedataset(Dataset):\n",
    "        def __init__(self, path, transform = None):    \n",
    "            self.transform = transform\n",
    "            self.spike = torch.load(path)\n",
    "            \n",
    "        def __getitem__(self, index):\n",
    "            spike = self.spike[index]            \n",
    "            if self.transform is not None:\n",
    "                spike = self.transform(spike)\n",
    "            return spike\n",
    "        \n",
    "        def __len__(self):\n",
    "            return len(self.spike)\n",
    "\n",
    "    train_dataset = spikedataset(my_path_ground_BH + AE_train_data)\n",
    "    train_loader = DataLoader(dataset = train_dataset, batch_size = batch_size, shuffle = True)\n",
    "\n",
    "    test_dataset = spikedataset(my_path_ground_BH + AE_test_data)\n",
    "    test_loader = DataLoader(dataset = test_dataset, batch_size = batch_size, shuffle = False)\n",
    "\n",
    "\n",
    "    # vth_mul_on = True # True False\n",
    "    # batch_norm_on = True # True False\n",
    "\n",
    "\n",
    "    # 모델 초기화\n",
    "    if SAE_net == False: # 여기서는 l2norm, lif bridge 둘 다 true면 l2norm먼저\n",
    "        assert two_channel_input == False\n",
    "\n",
    "        if Conv_net == True:\n",
    "            # input_channels = 2 if two_channel_input else 1\n",
    "            input_channels = TIME if coarse_com_mode else 1\n",
    "            if fusion_net == True:\n",
    "                assert False, '이거 맞음? 다시 확인'\n",
    "                net = FUSION_net_conv1(input_channels=input_channels, input_length=n_sample, encoder_ch = [32, 64, 96], fc_dim = lateral_feature_num, padding = 0, stride = 2, kernel_size = 3, \n",
    "                                    synapse_fc_trace_const1=1, \n",
    "                                    synapse_fc_trace_const2=v_decay, #안씀 \n",
    "                                    TIME=TIME, v_init=0.0, v_decay=v_decay, v_threshold=v_threshold, v_reset=v_reset, \n",
    "                                    sg_width=4.0, surrogate='sigmoid', BPTT_on=BPTT_on, need_bias=need_bias, lif_add_at_first=lif_add_at_first,\n",
    "                                    sae_l2_norm_bridge = sae_l2_norm_bridge, sae_lif_bridge = sae_lif_bridge, lif_add_at_last=lif_add_at_last, repeat_coding=repeat_coding).to(device)\n",
    "            else: \n",
    "                net = Autoencoder_conv1(input_channels=input_channels, input_length=n_sample, encoder_ch = [32, 64, 96], fc_dim = lateral_feature_num, padding = 0, stride = 2, kernel_size = 3, need_bias=need_bias, l2norm_bridge=sae_l2_norm_bridge, relu_bridge=sae_lif_bridge, activation_collector_on=False,\n",
    "                                        batch_norm_on=batch_norm_on, QCFS_neuron_on=QCFS_neuron_on).to(device)\n",
    "            net = torch.nn.DataParallel(net)\n",
    "            if converted_net_forward:\n",
    "                converted_net = SAE_converted_conv1(input_channels=input_channels, input_length=n_sample, encoder_ch = [32, 64, 96], fc_dim = lateral_feature_num, padding = 0, stride = 2, kernel_size = 3, \n",
    "                                    synapse_fc_trace_const1=1, \n",
    "                                    synapse_fc_trace_const2=v_decay, #안씀 \n",
    "                                    TIME=TIME, v_init=0.0, v_decay=v_decay, v_threshold=v_threshold, v_reset=v_reset, \n",
    "                                    sg_width=4.0, surrogate='sigmoid', BPTT_on=BPTT_on, need_bias=need_bias, lif_add_at_first=lif_add_at_first,\n",
    "                                    sae_l2_norm_bridge = sae_l2_norm_bridge, sae_lif_bridge = sae_lif_bridge, lif_add_at_last=lif_add_at_last,\n",
    "                                    vth_mul_on=vth_mul_on, batch_norm_on=batch_norm_on).to(device) # lif bridge는 무조건 들어가게 해놨음.\n",
    "                converted_net = torch.nn.DataParallel(converted_net)\n",
    "                print('converted_net', converted_net)\n",
    "        else:\n",
    "            n_sample = n_sample * TIME if coarse_com_mode else n_sample\n",
    "            net = Autoencoder_only_FC(encoder_ch=[400, lateral_feature_num], decoder_ch=[400,n_sample], n_sample=n_sample, need_bias=need_bias, l2norm_bridge=sae_l2_norm_bridge, relu_bridge=sae_lif_bridge, activation_collector_on=False,\n",
    "                                    batch_norm_on=batch_norm_on, QCFS_neuron_on=QCFS_neuron_on).to(device)\n",
    "            net = torch.nn.DataParallel(net)\n",
    "            if converted_net_forward:\n",
    "                converted_net = SAE_converted_fc(encoder_ch=[400, lateral_feature_num], \n",
    "                                    decoder_ch=[400, n_sample], \n",
    "                                    in_channels=n_sample, # in_channel 이 여기선 걍 lenght.\n",
    "                                    synapse_fc_trace_const1=1,\n",
    "                                    synapse_fc_trace_const2=v_decay,  #안씀 \n",
    "                                    TIME=TIME, v_init=0.0, v_decay=v_decay, v_threshold=v_threshold, v_reset=v_reset, \n",
    "                                    sg_width=4.0, surrogate='sigmoid', BPTT_on=BPTT_on, need_bias=need_bias, lif_add_at_first=lif_add_at_first,\n",
    "                                    sae_l2_norm_bridge = sae_l2_norm_bridge, sae_lif_bridge = sae_lif_bridge, lif_add_at_last=lif_add_at_last,\n",
    "                                    vth_mul_on=vth_mul_on, batch_norm_on=batch_norm_on).to(device) # lif bridge는 무조건 들어가게 해놨음.\n",
    "                converted_net = torch.nn.DataParallel(converted_net)\n",
    "                # print('converted_net', converted_net)\n",
    "    else:\n",
    "        if Conv_net == True: \n",
    "            input_channels = 1\n",
    "            input_channels = 2 if two_channel_input else 1\n",
    "            if fusion_net == True:  \n",
    "                assert coarse_com_mode == True\n",
    "                # net = SAE_FUSION2_net_conv1(input_channels=input_channels, input_length=n_sample, encoder_ch = [32, 64, 96], fc_dim = lateral_feature_num, padding = 0, stride = 2, kernel_size = 3, \n",
    "                #                     synapse_fc_trace_const1=1, \n",
    "                #                     synapse_fc_trace_const2=v_decay, #안씀 \n",
    "                #                     TIME=TIME, v_init=0.0, v_decay=v_decay, v_threshold=v_threshold, v_reset=v_reset, \n",
    "                #                     sg_width=4.0, surrogate='sigmoid', BPTT_on=BPTT_on, need_bias=need_bias, lif_add_at_first=lif_add_at_first,\n",
    "                #                     sae_l2_norm_bridge = sae_l2_norm_bridge, sae_lif_bridge = sae_lif_bridge, lif_add_at_last=lif_add_at_last, batch_norm_on=batch_norm_on, sae_relu_on=sae_relu_on).to(device)\n",
    "                # net = SAE_FUSION3_net_conv1(input_channels=input_channels, input_length=n_sample, encoder_ch = [32, 64, 96], fc_dim = lateral_feature_num, padding = 0, stride = 2, kernel_size = 3, \n",
    "                #                     synapse_fc_trace_const1=1, \n",
    "                #                     synapse_fc_trace_const2=v_decay, #안씀 \n",
    "                #                     TIME=TIME, v_init=0.0, v_decay=v_decay, v_threshold=v_threshold, v_reset=v_reset, \n",
    "                #                     sg_width=4.0, surrogate='sigmoid', BPTT_on=BPTT_on, need_bias=need_bias, lif_add_at_first=lif_add_at_first,\n",
    "                #                     sae_l2_norm_bridge = sae_l2_norm_bridge, sae_lif_bridge = sae_lif_bridge, lif_add_at_last=lif_add_at_last, batch_norm_on=batch_norm_on, sae_relu_on=sae_relu_on).to(device)\n",
    "                # net = SAE_FUSION4_net_conv1(input_channels=input_channels, input_length=n_sample, encoder_ch = [32, 64, 96], fc_dim = lateral_feature_num, padding = 0, stride = 2, kernel_size = 3, \n",
    "                #                     synapse_fc_trace_const1=1, \n",
    "                #                     synapse_fc_trace_const2=v_decay, #안씀 \n",
    "                #                     TIME=TIME, v_init=0.0, v_decay=v_decay, v_threshold=v_threshold, v_reset=v_reset, \n",
    "                #                     sg_width=4.0, surrogate='sigmoid', BPTT_on=BPTT_on, need_bias=need_bias, lif_add_at_first=lif_add_at_first,\n",
    "                #                     sae_l2_norm_bridge = sae_l2_norm_bridge, sae_lif_bridge = sae_lif_bridge, lif_add_at_last=lif_add_at_last, batch_norm_on=batch_norm_on, sae_relu_on=sae_relu_on).to(device)\n",
    "                # net = SAE_FUSION5_net_conv1(input_channels=input_channels, input_length=n_sample, encoder_ch = [32, 64, 96], fc_dim = lateral_feature_num, padding = 0, stride = 2, kernel_size = 3, \n",
    "                #                     synapse_fc_trace_const1=1, \n",
    "                #                     synapse_fc_trace_const2=v_decay, #안씀 \n",
    "                #                     TIME=TIME, v_init=0.0, v_decay=v_decay, v_threshold=v_threshold, v_reset=v_reset, \n",
    "                #                     sg_width=4.0, surrogate='sigmoid', BPTT_on=BPTT_on, need_bias=need_bias, lif_add_at_first=lif_add_at_first,\n",
    "                #                     sae_l2_norm_bridge = sae_l2_norm_bridge, sae_lif_bridge = sae_lif_bridge, lif_add_at_last=lif_add_at_last, batch_norm_on=batch_norm_on, sae_relu_on=sae_relu_on).to(device)\n",
    "                # net = SAE_FUSION6_net_conv1(input_channels=input_channels, input_length=n_sample, encoder_ch = [32, 64, 96], fc_dim = lateral_feature_num, padding = 0, stride = 2, kernel_size = 3, \n",
    "                #                     synapse_fc_trace_const1=1, \n",
    "                #                     synapse_fc_trace_const2=v_decay, #안씀 \n",
    "                #                     TIME=TIME, v_init=0.0, v_decay=v_decay, v_threshold=v_threshold, v_reset=v_reset, \n",
    "                #                     sg_width=4.0, surrogate='sigmoid', BPTT_on=BPTT_on, need_bias=need_bias, lif_add_at_first=lif_add_at_first,\n",
    "                #                     sae_l2_norm_bridge = sae_l2_norm_bridge, sae_lif_bridge = sae_lif_bridge, lif_add_at_last=lif_add_at_last, batch_norm_on=batch_norm_on, sae_relu_on=sae_relu_on).to(device)\n",
    "                net = SAE_FUSION7_net_conv1(input_channels=input_channels, input_length=n_sample, encoder_ch = [32, 64, 96], fc_dim = lateral_feature_num, padding = 0, stride = 2, kernel_size = 3, \n",
    "                                    synapse_fc_trace_const1=1, \n",
    "                                    synapse_fc_trace_const2=v_decay, #안씀 \n",
    "                                    TIME=TIME, v_init=0.0, v_decay=v_decay, v_threshold=v_threshold, v_reset=v_reset, \n",
    "                                    sg_width=4.0, surrogate='sigmoid', BPTT_on=BPTT_on, need_bias=need_bias, lif_add_at_first=lif_add_at_first,\n",
    "                                    sae_l2_norm_bridge = sae_l2_norm_bridge, sae_lif_bridge = sae_lif_bridge, lif_add_at_last=lif_add_at_last, batch_norm_on=batch_norm_on, sae_relu_on=sae_relu_on).to(device)\n",
    "            else:\n",
    "                net = SAE_conv1(input_channels=input_channels, input_length=n_sample, encoder_ch = [32, 64, 96], fc_dim = lateral_feature_num, padding = 0, stride = 2, kernel_size = 3, \n",
    "                                    synapse_fc_trace_const1=1, \n",
    "                                    synapse_fc_trace_const2=v_decay, #안씀 \n",
    "                                    TIME=TIME, v_init=0.0, v_decay=v_decay, v_threshold=v_threshold, v_reset=v_reset, \n",
    "                                    sg_width=4.0, surrogate='sigmoid', BPTT_on=BPTT_on, need_bias=need_bias, lif_add_at_first=lif_add_at_first,\n",
    "                                    sae_l2_norm_bridge = sae_l2_norm_bridge, sae_lif_bridge = sae_lif_bridge, lif_add_at_last=lif_add_at_last, batch_norm_on=batch_norm_on, sae_relu_on=sae_relu_on).to(device)\n",
    "            # net = SAE_conv1_DR(input_channels=input_channels, input_length=n_sample, encoder_ch = [32, 64, 96], fc_dim = lateral_feature_num, padding = 0, stride = 2, kernel_size = 3, \n",
    "            #                     synapse_fc_trace_const1=1, \n",
    "            #                     synapse_fc_trace_const2=v_decay, #안씀 \n",
    "            #                     TIME=TIME, v_init=0.0, v_decay=v_decay, v_threshold=v_threshold, v_reset=v_reset, \n",
    "            #                     sg_width=4.0, surrogate='sigmoid', BPTT_on=BPTT_on, need_bias=need_bias, lif_add_at_first=lif_add_at_first,\n",
    "            #                     sae_l2_norm_bridge = sae_l2_norm_bridge, sae_lif_bridge = sae_lif_bridge, lif_add_at_last=lif_add_at_last, batch_norm_on=batch_norm_on).to(device)\n",
    "            net = torch.nn.DataParallel(net)\n",
    "        else:\n",
    "            net = SAE_fc_only(encoder_ch=[400, lateral_feature_num], \n",
    "                                decoder_ch=[400, n_sample], \n",
    "                                in_channels=n_sample, # in_channel 이 여기선 걍 lenght.\n",
    "                                synapse_fc_trace_const1=1,\n",
    "                                synapse_fc_trace_const2=v_decay,  #안씀 \n",
    "                                TIME=TIME, v_init=0.0, v_decay=v_decay, v_threshold=v_threshold, v_reset=v_reset, \n",
    "                                sg_width=4.0, surrogate='sigmoid', BPTT_on=BPTT_on, need_bias=need_bias, lif_add_at_first=lif_add_at_first,\n",
    "                                sae_l2_norm_bridge = sae_l2_norm_bridge, sae_lif_bridge = sae_lif_bridge, lif_add_at_last=lif_add_at_last, batch_norm_on=batch_norm_on, sae_relu_on=sae_relu_on).to(device)\n",
    "            net = torch.nn.DataParallel(net)\n",
    "\n",
    "    # net = torch.load('/home/bhkim003/github_folder/ByeonghyeonKim/my_snn/net_save/save_now_net_AE_re_e7000.pth')\n",
    "    # net = torch.load('/home/bhkim003/github_folder/ByeonghyeonKim/my_snn/net_save/save_now_net_20250101_210938_786.pth')\n",
    "    # load했으면 torch.nn.DataParallel 하지마\n",
    "    # net.module.load_state_dict(torch.load('/home/bhkim003/github_folder/ByeonghyeonKim/my_snn/net_save/save_now_net_annbase_20250108_210641_941.pth'))\n",
    "    if pretrained_net != None:\n",
    "        ######################## 모델이 달라서 dict로 weight만 넣고싶을 때\n",
    "        # # 저장된 가중치 로드\n",
    "        saved_state_dict = torch.load(pretrained_net)\n",
    "        current_state_dict = net.module.state_dict()\n",
    "\n",
    "        # 함수 호출로 가중치 매핑\n",
    "        updated_state_dict = map_and_load_weights(saved_state_dict, current_state_dict)\n",
    "\n",
    "        # 업데이트된 state_dict를 네트워크에 로드\n",
    "        net.module.load_state_dict(updated_state_dict)\n",
    "        ######################## 모델이 달라서 dict로 weight만 넣고싶을 때\n",
    "\n",
    "        ############## 일반적일 때\n",
    "        # net.module.load_state_dict(torch.load(pretrained_net))\n",
    "        ############## 일반적일 때\n",
    "    \n",
    "        # pre_net = Autoencoder_conv1(input_channels=input_channels, input_length=n_sample, encoder_ch = [32, 64, 96], fc_dim = lateral_feature_num, padding = 0, stride = 2, kernel_size = 3, need_bias=need_bias, l2norm_bridge=sae_l2_norm_bridge, relu_bridge=sae_lif_bridge, activation_collector_on=False,\n",
    "        #                         batch_norm_on=batch_norm_on, QCFS_neuron_on=False).to(device)\n",
    "        # pre_net = torch.nn.DataParallel(net)\n",
    "        # pre_net.module.load_state_dict(torch.load(pretrained_net))\n",
    "        # copy_weights(pre_net.module.encoder , net.module.encoder )\n",
    "        # copy_weights(pre_net.module.decoder , net.module.decoder  )\n",
    "\n",
    "        \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    wandb.watch(net, log=\"all\", log_freq = 10)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    if SAE_net == True:\n",
    "        assert 'SAE' in net.module.__class__.__name__\n",
    "\n",
    "\n",
    "\n",
    "    net = net.to(device)\n",
    "    print(f\"Total number of encoder parameters: {sum(p.numel() for p in net.module.encoder.parameters())}\")\n",
    "    print(net)\n",
    "    print('Device:',device)\n",
    "\n",
    "    \n",
    "    if optimizer == 'Adam':\n",
    "        optimizer = optim.Adam(net.parameters(), lr=learning_rate)\n",
    "    elif optimizer == 'SGD':\n",
    "        optimizer = optim.SGD(net.parameters(), lr = learning_rate, momentum = 0.9)\n",
    "    else:\n",
    "        assert False, 'optimizer를 잘못 입력했습니다.'\n",
    "        \n",
    "    loss_history = []\n",
    "    mean_cluster_accuracy_during_training_cycle_all_dataset_history = []\n",
    "    mean_cluster_accuracy_post_training_cycle_all_dataset_history = []\n",
    "    mean_cluster_accuracy_total_all_dataset_history = []\n",
    "\n",
    "    tau = np.zeros(num_cluster)\n",
    "\n",
    "    print(f\"\\nStart Training, current_time = {current_time}\")\n",
    "    mean_cluster_accuracy_post_training_cycle_all_dataset = 0\n",
    "    best_mean_cluster_accuracy_post_training_cycle_all_dataset = 0\n",
    "\n",
    "    if SAE_net == True:\n",
    "        assert 'SAE' in net.module.__class__.__name__\n",
    "        \n",
    "    k_means_acc_best = 0\n",
    "    min_loss = 9999999\n",
    "    min_loss_normal = 9999999\n",
    "    min_loss_coarse = 9999999\n",
    "    for epoch in range(max_epoch):\n",
    "        print()\n",
    "        l2_loss_bin= 0\n",
    "        ae_train_start_time = time.time()\n",
    "        running_loss = 0.0\n",
    "        running_loss_normal = 0.0\n",
    "        running_loss_coarse = 0.0\n",
    "        iter = 0\n",
    "        net.train()\n",
    "        # if True or max_epoch != 1:\n",
    "        wrong_element_sum = 0\n",
    "        same_data_num = 0\n",
    "        total_data_num = 0\n",
    "        if max_epoch != 1:\n",
    "            for data in train_loader:\n",
    "                optimizer.zero_grad()\n",
    "                total_data_num += len(data)\n",
    "                data = data.to(device)\n",
    "                scaling = (level_num-3)/level_num if conv1d_scaling else 1.0\n",
    "                data = zero_to_one_normalize_features(data, level_num=quantize_level_num, coarse_com_config=coarse_com_config, scaling=scaling, norm01=norm01) if normalize_on else data\n",
    "                # plot_origin_spike(data[0].cpu().detach().numpy(), min_max_y_on = True)\n",
    "                # plot_origin_spike(data[1].cpu().detach().numpy(), min_max_y_on = True)\n",
    "                spike_backup = data\n",
    "                spike = data\n",
    "                spike = spike.to(device) # batch, feature\n",
    "                spike_for_fusion2_net = spike\n",
    "                if coarse_com_mode == True and 'SAE' in net.module.__class__.__name__:\n",
    "                    # print(spike[0])\n",
    "                    spike = spike.unsqueeze(2).repeat(1, 1, level_num) # spike_length == level_num # (batch, time, feature)로 변환 \n",
    "                    spike = (spike > levels).to(torch.float) \n",
    "\n",
    "                    spike = (spike == 0).cumsum(dim=-1).eq(1).to(torch.float) if lc_adc_on == True else spike\n",
    "\n",
    "                    # spike: batch, time, level_num\n",
    "                    # levels: time, level_num\n",
    "                    if Conv_net == True:\n",
    "                        spike = spike.unsqueeze(-2) # batch, time, in_channel, feature or batch in_channel,feature\n",
    "                        if two_channel_input == True:\n",
    "                            spike_backup = spike_backup.to(device)\n",
    "                            spike_backup = spike_backup.unsqueeze(2).repeat(1, 1, level_num) # spike_length == level_num # (batch, time, feature)로 변환 \n",
    "                            spike_backup = (spike_backup <= levels).to(torch.float) \n",
    "                            spike_backup = (spike_backup == 1).cumsum(dim=-1).eq(1).to(torch.float) if lc_adc_on == True else spike_backup\n",
    "                            spike_backup = spike_backup.unsqueeze(-2)\n",
    "                            spike = torch.cat((spike, spike_backup), dim=-2)\n",
    "                    assert spike.shape[0] == batch_size and spike.shape[1] == TIME\n",
    "                elif 'SAE' in net.module.__class__.__name__:\n",
    "                    spike = spike.unsqueeze(-1).repeat(1, 1, TIME).permute(0,2,1) # (batch, time, feature)로 변환\n",
    "                    if Conv_net == True:\n",
    "                        spike = spike.unsqueeze(-2) # batch, time, in_channel, feature or batch in_channel,feature\n",
    "                else:\n",
    "                    if Conv_net == True:\n",
    "                        if coarse_com_mode == False:\n",
    "                            spike = spike.unsqueeze(-2) #batch in_channel,feature\n",
    "                        else:\n",
    "                            spike = spike.unsqueeze(2).repeat(1, 1, level_num) # spike_length == level_num # (batch, time, feature)로 변환 \n",
    "                            spike = (spike > levels).to(torch.float) \n",
    "\n",
    "                            spike = (spike == 0).cumsum(dim=-1).eq(1).to(torch.float) if lc_adc_on == True else spike\n",
    "\n",
    "                    else:\n",
    "                        if coarse_com_mode == False:\n",
    "                            pass\n",
    "                        else:\n",
    "                            spike = spike.unsqueeze(2).repeat(1, 1, level_num) # spike_length == level_num # (batch, time, feature)로 변환 \n",
    "                            spike = (spike > levels).to(torch.float) \n",
    "\n",
    "                            spike = (spike == 0).cumsum(dim=-1).eq(1).to(torch.float) if lc_adc_on == True else spike\n",
    "\n",
    "                            # spike: batch, time, feature\n",
    "                            spike = spike.reshape(spike.shape[0], -1)\n",
    "\n",
    "                    \n",
    "\n",
    "\n",
    "                    # if fusion_net == True:\n",
    "                    #     spike = spikegen.rate(spike, num_steps=TIME).transpose(0, 1)\n",
    "\n",
    "                # spike_class = net(spike) # batch, time, feature\n",
    "                encoded_spike = net.module.encoder(spike)\n",
    "                spike_class = net.module.decoder(encoded_spike)\n",
    "\n",
    "                # for i in range (2):\n",
    "                #     plot_spike(spike[i,:,0,:].cpu().numpy())\n",
    "                #     # plot_spike(spike[i,:,1,:].cpu().numpy())\n",
    "                #     plot_origin_spike(spike_class.squeeze()[i].cpu().detach().numpy(), min_max_y_on = True)\n",
    "                # assert False\n",
    "                        \n",
    "\n",
    "                loss = 0\n",
    "                loss_normal = torch.tensor(0.0)\n",
    "                loss_coarse = torch.tensor(0.0)\n",
    "                if coarse_com_mode == True and 'SAE' in net.module.__class__.__name__:\n",
    "                    criterion = nn.MSELoss().to(device)\n",
    "                    # loss1 = nn.MSELoss()(spike_class[..., 5:25], spike[..., 5:25])\n",
    "                    # loss2 = nn.MSELoss()(spike_class[..., 0:5], spike[..., 0:5])\n",
    "                    # loss3 = nn.MSELoss()(spike_class[..., 25:spike_length], spike[..., 25:spike_length])\n",
    "                    # loss = loss1 * 2.125 + (loss2 + loss3)/4\n",
    "\n",
    "                    # loss1 = nn.MSELoss()(spike_class[..., 5:25, :], spike[..., 5:25, :])\n",
    "                    # loss2 = nn.MSELoss()(spike_class[..., 0:5, :], spike[..., 0:5, :])\n",
    "                    # loss3 = nn.MSELoss()(spike_class[..., 25:spike_length, :], spike[..., 25:spike_length, :])\n",
    "                    # loss = loss1 * 2.125 + (loss2 + loss3)/4\n",
    "                    if fusion_net:\n",
    "                        # print('1', spike.shape) # batch, time, in_channel, feature [32, 50, 1, 50]\n",
    "                        \n",
    "                        # ### coarse에서 ann loss 만들기 ######\n",
    "                        # spike = spike.squeeze()\n",
    "                        # assert two_channel_input == False\n",
    "                        # zero_mask = (spike == 0)  # 0이 있는 위치\n",
    "                        # first_zero_idx = torch.where(zero_mask, torch.arange(spike.shape[-1]).to(device), spike.shape[-1]-1).min(dim=-1).values\n",
    "                        # spike = levels[0][first_zero_idx]\n",
    "                        # # plot_origin_spike(spike[0].cpu().detach().numpy())\n",
    "                        # ### coarse에서 ann loss 만들기 ######\n",
    "\n",
    "                        ### 그냥 원래 스파이크로 ann loss 만들기 ######\n",
    "                        spike = spike_for_fusion2_net\n",
    "                        ### 그냥 원래 스파이크로 ann loss 만들기 ######\n",
    "\n",
    "                        spike = spike.squeeze()\n",
    "                        spike_class = spike_class.squeeze()\n",
    "                        \n",
    "                        ### normal loss################\n",
    "                        # loss = criterion(spike_class, spike)\n",
    "                        ### normal loss################\n",
    "                        \n",
    "                        ### chan loss################\n",
    "                        loss1 = criterion(spike_class[..., 5:25], spike[..., 5:25])\n",
    "                        loss2 = criterion(spike_class[..., 0:5], spike[..., 0:5])\n",
    "                        loss3 = criterion(spike_class[..., 25:], spike[..., 25:])\n",
    "                        loss = loss1 * 2.125 + (loss2 + loss3)/4\n",
    "                        ### chan loss################\n",
    "\n",
    "\n",
    "                        # #########################################\n",
    "                        # # 손실 함수 정의 (예: MSELoss 사용)\n",
    "                        # criterion_joke = torch.nn.MSELoss(reduction='none')  # 개별 요소별 손실을 유지\n",
    "\n",
    "                        # # 손실 계산\n",
    "                        # loss1_joke = criterion_joke(spike_class[..., 5:25], spike[..., 5:25]).mean(dim=-1)  # (batch,)\n",
    "                        # loss2_joke = criterion_joke(spike_class[..., 0:5], spike[..., 0:5]).mean(dim=-1)    # (batch,)\n",
    "                        # loss3_joke = criterion_joke(spike_class[..., 25:], spike[..., 25:]).mean(dim=-1)    # (batch,)\n",
    "\n",
    "                        # # 주어진 가중치를 적용한 최종 손실\n",
    "                        # loss_joke = loss1_joke * 2.125 + (loss2_joke + loss3_joke) / 4  # (batch,)\n",
    "\n",
    "                        # # 가장 큰 손실을 갖는 샘플의 인덱스 찾기\n",
    "                        # max_loss_idx_joke = torch.argmax(loss_joke)\n",
    "\n",
    "                        # # 해당 샘플 선택\n",
    "                        # selected_sample_class = spike_class[max_loss_idx_joke]\n",
    "                        # selected_sample_spike = spike[max_loss_idx_joke]\n",
    "\n",
    "                        # # 선택한 샘플의 손실 값 출력\n",
    "                        # print(\"Index of max loss sample:\", max_loss_idx_joke.item())\n",
    "                        # print(\"Max loss value:\", loss_joke[max_loss_idx_joke].item())\n",
    "                        # mean_loss_joke = loss_joke.mean().item()\n",
    "                        # print(\"Mean loss across the batch:\", mean_loss_joke)\n",
    "\n",
    "                        # # 선택한 샘플을 시각화\n",
    "                        # plot_origin_spike(selected_sample_class.cpu().detach().numpy())\n",
    "                        # plot_origin_spike(selected_sample_spike.cpu().detach().numpy())\n",
    "                        # #########################################\n",
    "\n",
    "                        # coarse loss ######################################################\n",
    "                        loss_normal = criterion(spike_class, spike)\n",
    "                        level_num_in_loss = spike_length\n",
    "                        level_interval = (coarse_com_config[0] - coarse_com_config[1]) / (level_num_in_loss-1)  # max - min\n",
    "                        levels = [coarse_com_config[1] + level_interval * i for i in range(level_num_in_loss)]\n",
    "                        levels = torch.tensor(levels).to(torch.float).to(device)\n",
    "                        # print('coarse leves', levels)\n",
    "                        levels = levels.repeat(spike_length,1) \n",
    "\n",
    "                        spike = spike.squeeze()\n",
    "                        spike_class = spike_class.squeeze()\n",
    "                        # plot_origin_spike(spike_class[0].cpu().detach().numpy())\n",
    "                        spike = spike.unsqueeze(2).repeat(1, 1, level_num_in_loss) \n",
    "                        spike = (spike > levels).to(torch.float) \n",
    "                        spike_class = spike_class.unsqueeze(2).repeat(1, 1, level_num_in_loss) \n",
    "                        spike_class = (spike_class > levels).to(torch.float) \n",
    "                        # spike = spike[..., 0:-3, :]\n",
    "                        # spike_class = spike_class[..., 0:-3, :]\n",
    "                        loss_coarse = criterion(spike_class, spike)\n",
    "                        wrong_element_sum += torch.sum(torch.abs(spike - spike_class)).item() \n",
    "\n",
    "                        # plot_spike(spike_class[0].cpu().detach().numpy())\n",
    "                        # assert False\n",
    "                        # coarse loss ######################################################\n",
    "                    else:\n",
    "                        spike = spike.squeeze()\n",
    "                        spike_class = spike_class.squeeze()\n",
    "                        loss = criterion(spike_class, spike)\n",
    "\n",
    "                    for iii in range(spike.shape[0]):\n",
    "                        same_data_num = same_data_num + 1 if torch.eq(spike[iii], spike_class[iii]).all() else same_data_num\n",
    "                    wrong_element_sum += torch.sum(torch.abs(spike - spike_class)).item() \n",
    "\n",
    "                    # spike = spike.squeeze()\n",
    "                    # spike_class = spike_class.squeeze()\n",
    "                    # plot_spike(spike[0].cpu().detach().numpy())\n",
    "                    # plot_spike(spike_class[0].cpu().detach().numpy())\n",
    "                    # print('손실 절대값 합',np.sum(np.abs(spike[0].cpu().detach().numpy() - spike_class[0].cpu().detach().numpy())))\n",
    "                    # # assert False\n",
    "                elif 'SAE' in net.module.__class__.__name__:\n",
    "                    criterion = nn.MSELoss().to(device)\n",
    "                    loss1 = criterion(spike_class[..., 5:25], spike[..., 5:25])\n",
    "                    loss2 = criterion(spike_class[..., 0:5], spike[..., 0:5])\n",
    "                    loss3 = criterion(spike_class[..., 25:spike_length], spike[..., 25:spike_length])\n",
    "                    loss = loss1 * 2.125 + (loss2 + loss3)/4\n",
    "                    assert spike_length > 25, 'spike_length가 25보다 작음'\n",
    "                    # wrong_element_sum += torch.sum(torch.abs(spike - spike_class)).item() \n",
    "                else:\n",
    "                    criterion = nn.MSELoss().to(device)\n",
    "                    loss1 = criterion(spike_class[..., 5:25], spike[..., 5:25])\n",
    "                    loss2 = criterion(spike_class[..., 0:5], spike[..., 0:5])\n",
    "                    loss3 = criterion(spike_class[..., 25:spike_length], spike[..., 25:spike_length])\n",
    "                    loss = loss1 * 2.125 + (loss2 + loss3)/4\n",
    "                    assert spike_length > 25, 'spike_length가 25보다 작음'\n",
    "                    # wrong_element_sum += torch.sum(torch.abs(spike - spike_class)).item() \n",
    "\n",
    "\n",
    "                    if l2_norm_loss_weight > 0:\n",
    "                        assert len(encoded_spike.shape) == 2, 'time 성분 없는 걸로'\n",
    "                        l2_loss = l2_norm_loss(encoded_spike, target_norm=1.0)  # L2Norm Loss 계산, l2 1.0되게.\n",
    "                        loss = loss + l2_loss*l2_norm_loss_weight\n",
    "                        l2_loss_bin += l2_loss.item()\n",
    "\n",
    "                    # coarse loss ######################################################\n",
    "                    loss_normal = criterion(spike_class, spike)\n",
    "                    level_num_in_loss = quantize_level_num\n",
    "                    level_interval = (coarse_com_config[0] - coarse_com_config[1]) / (level_num_in_loss-1)  # max - min\n",
    "                    levels = [coarse_com_config[1] + level_interval * i for i in range(level_num_in_loss)]\n",
    "                    levels = torch.tensor(levels).to(torch.float).to(device)\n",
    "                    levels = levels.repeat(spike_length,1) \n",
    "\n",
    "                    spike = spike.squeeze()\n",
    "                    spike_class = spike_class.squeeze()\n",
    "                    # plot_origin_spike(spike_class[0].cpu().detach().numpy())\n",
    "                    spike = spike.unsqueeze(2).repeat(1, 1, level_num_in_loss) \n",
    "                    spike = (spike > levels).to(torch.float) \n",
    "                    spike_class = spike_class.unsqueeze(2).repeat(1, 1, level_num_in_loss) \n",
    "                    spike_class = (spike_class > levels).to(torch.float) \n",
    "                    # spike = spike[..., 0:-3, :]\n",
    "                    # spike_class = spike_class[..., 0:-3, :]\n",
    "                    loss_coarse = criterion(spike_class, spike)\n",
    "                    wrong_element_sum += torch.sum(torch.abs(spike - spike_class)).item() \n",
    "\n",
    "                    # plot_spike(spike_class[0].cpu().detach().numpy())\n",
    "                    # assert False\n",
    "                    # coarse loss ######################################################\n",
    "\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                running_loss += loss.item()\n",
    "                running_loss_normal += loss_normal.item()\n",
    "                running_loss_coarse += loss_coarse.item()\n",
    "                # print(f'\\nepoch-{epoch}, running_loss : {running_loss:.5f}, iter percent {iter/len(train_loader)*100:.2f}%')\n",
    "                iter += 1\n",
    "        else:\n",
    "            print('\\n\\n\\n max_epoch 1이면 Train 안함!!!!!!!!!!!!!!!!!!!!!')\n",
    "        if l2_norm_loss_weight > 0:\n",
    "            print('l2_loss_bin', l2_loss_bin/len(train_loader))\n",
    "        avg_loss = running_loss / len(train_loader)\n",
    "        assert not np.isnan(avg_loss), f\"Error: avg_loss is NaN! Running loss: {running_loss}, Length of train_loader: {len(train_loader)}\"\n",
    "        loss_history.append((epoch, avg_loss))\n",
    "        min_loss = min(min_loss, avg_loss)\n",
    "        min_loss_normal = min(min_loss_normal, running_loss_normal/len(train_loader))\n",
    "        min_loss_coarse = min(min_loss_coarse, running_loss_coarse/len(train_loader))\n",
    "        print(f'\\nepoch-{epoch} loss : {avg_loss:.8f}, loss_normal : {running_loss_normal/len(train_loader):.8f}, loss_coarse : {running_loss_coarse/len(train_loader):.8f}, min_loss : {min_loss:.8f}, min_loss_normal : {min_loss_normal:.8f}, min_loss_coarse : {min_loss_coarse:.8f}, wrong_element_sum : {wrong_element_sum:.8f}, same_data : {100*same_data_num/(total_data_num+1e-12):.2f}%')\n",
    "        print(f\"ae train 실행 시간: {time.time()-ae_train_start_time:.3f}초, 전체 시작 시간 {current_time}\")\n",
    "\n",
    "        # plot_activation_distribution(net)\n",
    "\n",
    "        if SAE_net == False and converted_net_forward == True:\n",
    "            source_encoder = net.module.encoder \n",
    "            target_encoder = converted_net.module.encoder  \n",
    "            copy_weights(source_encoder, target_encoder)\n",
    "\n",
    "        cluster_accuracy_during_training_cycle_all_dataset = np.zeros(dataset_num)\n",
    "        cluster_accuracy_post_training_cycle_all_dataset = np.zeros(dataset_num)\n",
    "        cluster_accuracy_total_all_dataset = np.zeros(dataset_num)    \n",
    "\n",
    "        k_means_acc = 0\n",
    "        converted_k_means_acc = 0\n",
    "        if(epoch % accuracy_check_epoch_term == 0 or epoch == 1 or epoch == max_epoch-1): \n",
    "            accuracy_check_start_time = time.time()\n",
    "            print(f'\\nepoch-{epoch} accuracy check')\n",
    "            k_means_bin_origin_feature = []\n",
    "            k_means_bin = []\n",
    "            converted_k_means_bin = []\n",
    "            for ds in range(dataset_num):\n",
    "                # print('\\n', spike_tot[ds])\n",
    "\n",
    "                spike_template = np.load(my_path_ground_BH + template[ds])\n",
    "                spike = np.load(my_path_ground_BH + spike_tot[ds])\n",
    "                label = np.load(my_path_ground_BH + label_tot[ds])\n",
    "                spike_template = torch.from_numpy(spike_template).to(device)\n",
    "                spike = torch.from_numpy(spike).to(device)\n",
    "                scaling = (level_num-3)/level_num if conv1d_scaling else 1.0\n",
    "                spike_template = zero_to_one_normalize_features(spike_template, level_num=quantize_level_num, coarse_com_config=coarse_com_config, scaling=scaling, norm01=norm01) if normalize_on else spike_template\n",
    "                spike = zero_to_one_normalize_features(spike, level_num=quantize_level_num, coarse_com_config=coarse_com_config, scaling=scaling, norm01=norm01) if normalize_on else spike\n",
    "                \n",
    "                hidden_size = lateral_feature_num*TIME if 'SAE' in net.module.__class__.__name__ and SAE_hidden_nomean == True and fusion_net == False or 'SAE_FUSION5' in net.module.__class__.__name__ else lateral_feature_num\n",
    "                hidden_size = lateral_feature_num if '_DR' in net.module.__class__.__name__  else hidden_size\n",
    "\n",
    "                Cluster = np.zeros((num_cluster, hidden_size))\n",
    "                assert Cluster.shape[-1] == hidden_size, '이거 hidden dim 4 아니게 할 거면 잘 바꿔라'\n",
    "                \n",
    "\n",
    "\n",
    "                net.eval()\n",
    "                with torch.no_grad():\n",
    "                    spike_torch = spike_template.float()\n",
    "                    spike_torch = spike_torch[:num_cluster]\n",
    "                    spike_backup = spike_torch\n",
    "                    spike_torch = spike_torch.to(device)\n",
    "                    if coarse_com_mode == True and 'SAE' in net.module.__class__.__name__:\n",
    "                        spike_torch = spike_torch.unsqueeze(2).repeat(1, 1, level_num) # spike_length == level_num # (batch, time, feature)로 변환 \n",
    "                        spike_torch = (spike_torch > levels).to(torch.float) \n",
    "                        spike_torch = (spike_torch == 0).cumsum(dim=-1).eq(1).to(torch.float) if lc_adc_on == True else spike_torch\n",
    "                        if Conv_net == True:\n",
    "                            spike_torch = spike_torch.unsqueeze(-2) # batch, time, in_channel, feature or batch in_channel,feature\n",
    "                            if two_channel_input == True:\n",
    "                                spike_backup = spike_backup.to(device)\n",
    "                                spike_backup = spike_backup.unsqueeze(2).repeat(1, 1, level_num) # spike_length == level_num # (batch, time, feature)로 변환 \n",
    "                                spike_backup = (spike_backup <= levels).to(torch.float) \n",
    "                                spike_backup = (spike_backup == 1).cumsum(dim=-1).eq(1).to(torch.float) if lc_adc_on == True else spike_backup\n",
    "                                spike_backup = spike_backup.unsqueeze(-2) # batch, time, in_channel, feature\n",
    "                                spike_torch = torch.cat((spike_torch, spike_backup), dim=-2)\n",
    "                    elif 'SAE' in net.module.__class__.__name__:\n",
    "                        spike_torch = spike_torch.unsqueeze(1).repeat(1, TIME, 1) # (batch, time, feature)로 변환\n",
    "                        if Conv_net == True:\n",
    "                            spike_torch = spike_torch.unsqueeze(-2) # batch, time, in_channel, feature or batch in_channel,feature\n",
    "                    else:\n",
    "                        # if Conv_net == True:\n",
    "                        #     spike_torch = spike_torch.unsqueeze(-2) #batch in_channel,feature\n",
    "                        if Conv_net == True:\n",
    "                            if coarse_com_mode == False:\n",
    "                                spike_torch = spike_torch.unsqueeze(-2) #batch in_channel,feature\n",
    "                            else:\n",
    "                                spike_torch = spike_torch.unsqueeze(2).repeat(1, 1, level_num) # spike_length == level_num # (batch, time, feature)로 변환 \n",
    "                                spike_torch = (spike_torch > levels).to(torch.float) \n",
    "\n",
    "                                spike_torch = (spike_torch == 0).cumsum(dim=-1).eq(1).to(torch.float) if lc_adc_on == True else spike_torch\n",
    "\n",
    "                        else:\n",
    "                            if coarse_com_mode == False:\n",
    "                                pass\n",
    "                            else:\n",
    "                                spike_torch = spike_torch.unsqueeze(2).repeat(1, 1, level_num) # spike_length == level_num # (batch, time, feature)로 변환 \n",
    "                                spike_torch = (spike_torch > levels).to(torch.float) \n",
    "\n",
    "                                spike_torch = (spike_torch == 0).cumsum(dim=-1).eq(1).to(torch.float) if lc_adc_on == True else spike_torch\n",
    "\n",
    "                                # spike: batch, time, feature\n",
    "                                spike_torch = spike_torch.reshape(spike_torch.shape[0], -1)\n",
    "\n",
    "                        if converted_net_forward == True:\n",
    "                            spike_torch_spikegen = spikegen.rate(spike_torch, num_steps=TIME).transpose(0, 1)\n",
    "                        # if fusion_net == True:\n",
    "                        #     spike_torch = spikegen.rate(spike_torch, num_steps=TIME).transpose(0, 1)\n",
    "                    ### forward #######################################################\n",
    "                    inner_inf = net.module.encoder(spike_torch)\n",
    "                    if SAE_net == False and converted_net_forward == True:\n",
    "                        converted_inner_inf = converted_net.module.encoder(spike_torch_spikegen)\n",
    "                    ### forward #######################################################\n",
    "\n",
    "                    # if ds % 4 == 0:\n",
    "                    #     for i in range(4):\n",
    "                    #         decoded = net.module.decoder(inner_inf).squeeze()\n",
    "                    #         plot_spike(spike_torch[i,:,:].cpu().numpy())\n",
    "                    #         plot_spike(inner_inf[i,:].cpu().numpy())\n",
    "                    #         # plot_origin_spike(net.module.decoder(inner_inf)[i,:].cpu().numpy())\n",
    "                    #         plot_origin_spike(decoded[i].cpu().numpy(), min_max_y_on = True)\n",
    "                        \n",
    "                    # if 'SAE' in net.module.__class__.__name__:\n",
    "                    #     tensors = [inner_inf[0][i] for i in range(TIME)] \n",
    "                    #     all_equal = all(torch.equal(tensors[0], t) for t in tensors)\n",
    "                    #     print(all_equal, inner_inf)\n",
    "\n",
    "                    if 'SAE' in net.module.__class__.__name__:\n",
    "                        if SAE_hidden_nomean == True:\n",
    "                            inner_inf = inner_inf.reshape(inner_inf.shape[0],-1)# time*feature 펼치기\n",
    "                        else:\n",
    "                            inner_inf = inner_inf.mean(dim=1)# Time 방향으로 평균\n",
    "                        # inner_inf = F.normalize(inner_inf, p=2, dim=1)\n",
    "                    Cluster = inner_inf.cpu().detach().numpy()\n",
    "\n",
    "                encoder_batch = 128\n",
    "                spike_hidden = np.zeros((len(spike), hidden_size))\n",
    "                converted_spike_hidden = np.zeros((len(spike), hidden_size))\n",
    "                net.eval()\n",
    "                with torch.no_grad():\n",
    "                    now_index = 0\n",
    "                    while (1):\n",
    "                        now_end_index = now_index+encoder_batch if now_index+encoder_batch < len(spike) else len(spike)\n",
    "                        spike_batch = spike[now_index:now_end_index] \n",
    "                        spike_torch = spike_batch\n",
    "                        spike_torch = spike_torch.float()\n",
    "                        spike_backup = spike_torch\n",
    "                        spike_torch = spike_torch.to(device)\n",
    "                        if coarse_com_mode == True and 'SAE' in net.module.__class__.__name__:\n",
    "                            spike_torch = spike_torch.unsqueeze(2).repeat(1, 1, level_num) # spike_length == level_num # (batch, time, feature)로 변환 \n",
    "                            spike_torch = (spike_torch > levels).to(torch.float) \n",
    "                            spike_torch = (spike_torch == 0).cumsum(dim=-1).eq(1).to(torch.float) if lc_adc_on == True else spike_torch\n",
    "                            if Conv_net == True:\n",
    "                                spike_torch = spike_torch.unsqueeze(-2) # batch, time, in_channel, feature or batch in_channel,feature\n",
    "                                if two_channel_input == True:\n",
    "                                    spike_backup = spike_backup.to(device)\n",
    "                                    spike_backup = spike_backup.unsqueeze(2).repeat(1, 1, level_num) # spike_length == level_num # (batch, time, feature)로 변환 \n",
    "                                    spike_backup = (spike_backup <= levels).to(torch.float) \n",
    "                                    spike_backup = (spike_backup == 1).cumsum(dim=-1).eq(1).to(torch.float) if lc_adc_on == True else spike_backup\n",
    "                                    spike_backup = spike_backup.unsqueeze(-2)\n",
    "                                    spike_torch = torch.cat((spike_torch, spike_backup), dim=-2)\n",
    "                        elif 'SAE' in net.module.__class__.__name__:\n",
    "                            spike_torch = spike_torch.unsqueeze(1).repeat(1, TIME, 1) # (batch, time, feature)로 변환\n",
    "                            if Conv_net == True:\n",
    "                                spike_torch = spike_torch.unsqueeze(-2) # batch, time, in_channel, feature or batch in_channel,feature\n",
    "                        else:\n",
    "                            # if Conv_net == True:\n",
    "                            #     spike_torch = spike_torch.unsqueeze(-2) #batch in_channel,feature\n",
    "                            if Conv_net == True:\n",
    "                                if coarse_com_mode == False:\n",
    "                                    spike_torch = spike_torch.unsqueeze(-2) #batch in_channel,feature\n",
    "                                else:\n",
    "                                    spike_torch = spike_torch.unsqueeze(2).repeat(1, 1, level_num) # spike_length == level_num # (batch, time, feature)로 변환 \n",
    "                                    spike_torch = (spike_torch > levels).to(torch.float) \n",
    "\n",
    "                                    spike_torch = (spike_torch == 0).cumsum(dim=-1).eq(1).to(torch.float) if lc_adc_on == True else spike_torch\n",
    "\n",
    "                            else:\n",
    "                                if coarse_com_mode == False:\n",
    "                                    pass\n",
    "                                else:\n",
    "                                    spike_torch = spike_torch.unsqueeze(2).repeat(1, 1, level_num) # spike_length == level_num # (batch, time, feature)로 변환 \n",
    "                                    spike_torch = (spike_torch > levels).to(torch.float) \n",
    "\n",
    "                                    spike_torch = (spike_torch == 0).cumsum(dim=-1).eq(1).to(torch.float) if lc_adc_on == True else spike_torch\n",
    "\n",
    "                                    # spike: batch, time, feature\n",
    "                                    spike_torch = spike_torch.reshape(spike_torch.shape[0], -1)\n",
    "                            if converted_net_forward == True:\n",
    "                                spike_torch_spikegen = spikegen.rate(spike_torch, num_steps=TIME).transpose(0, 1)\n",
    "                            # if fusion_net == True:\n",
    "                            #     spike_torch = spikegen.rate(spike_torch, num_steps=TIME).transpose(0, 1)\n",
    "                        ### forward #######################################################\n",
    "                        inner_inf = net.module.encoder(spike_torch)\n",
    "                        if SAE_net == False and converted_net_forward == True:\n",
    "                            converted_inner_inf = converted_net.module.encoder(spike_torch_spikegen)\n",
    "                        ### forward #######################################################\n",
    "                            \n",
    "                        if 'SAE' in net.module.__class__.__name__:\n",
    "                            if SAE_hidden_nomean == True:\n",
    "                                inner_inf = inner_inf.reshape(spike_batch.shape[0],-1)# 펼치기\n",
    "                            else:\n",
    "                                inner_inf = inner_inf.mean(dim=1)# Time 방향으로 평균\n",
    "                            # inner_inf = F.normalize(inner_inf, p=2, dim=1)\n",
    "                        spike_hidden[now_index:now_end_index] = inner_inf.cpu().detach().numpy()\n",
    "                        if SAE_net == False and converted_net_forward == True:\n",
    "                            converted_spike_hidden[now_index:now_end_index] = converted_inner_inf.cpu().detach().numpy()\n",
    "                        now_index += encoder_batch\n",
    "                        if (now_index >= len(spike)):\n",
    "                            break\n",
    "                    \n",
    "                spike_id = np.zeros(len(spike))\n",
    "                distance_sm = np.zeros(num_cluster)\n",
    "                tau = np.zeros(num_cluster)\n",
    "                \n",
    "                plot_tau = []\n",
    "                plot_denominator = []\n",
    "                plot_m = []\n",
    "                plot_max_tau = []\n",
    "                for spike_index in range(len(spike)): \n",
    "                    for q in range(num_cluster):\n",
    "                        tau[q] = np.dot(spike_hidden[spike_index, :], Cluster[q, :]) # 이거 l2norm 거쳐서 나온 거니까 분모 1임.\n",
    "                        denominator =  np.linalg.norm(spike_hidden[spike_index, :])*np.linalg.norm(Cluster[q, :]) + 1e-12\n",
    "                        plot_denominator.append(denominator)\n",
    "                        if 'SAE' in net.module.__class__.__name__: # AE 때는 l2norm거쳐서 나와서 괜찮음\n",
    "                            tau[q] = tau[q] / denominator\n",
    "\n",
    "                        plot_tau.append(tau[q])\n",
    "\n",
    "                    # for i in range(num_cluster): # l2 distance\n",
    "                    #     distance_sm[i] = np.sum(np.power(np.abs(Cluster[i] - spike_hidden[spike_index, :]), 2))\n",
    "                    distance_sm = np.sum(np.power(np.abs(Cluster - spike_hidden[spike_index, :]), 2), axis=1)\n",
    "\n",
    "                    m = np.argmin(distance_sm)\n",
    "                    plot_m.append(m)\n",
    "                    spike_id[spike_index] = m + 1\n",
    "                    # print(spike_tot[ds], spike_index,np.max(tau))\n",
    "                    plot_max_tau.append(np.max(tau))\n",
    "                    if(np.max(tau) >= cos_thr[ds] and spike_index < training_cycle): # 원래 1400 아니냐?\n",
    "                        Cluster[m] = (Cluster[m] * 15 + spike_hidden[spike_index, :])/16\n",
    "\n",
    "\n",
    "                \n",
    "                origin_kmeans_accuracy = cluster_spikes_with_accuracy_torch(features= spike, true_labels=label-1, n_clusters=3, init_point=None)\n",
    "                kmeans_accuracy = cluster_spikes_with_accuracy_torch(features= torch.tensor(spike_hidden).to(device), true_labels=label-1, n_clusters=3, init_point=None)\n",
    "                \n",
    "                # print('temporoal k')\n",
    "                # result = evaluate_clustering_accuracy(spike_hidden.reshape(spike_hidden.shape[0], TIME, -1), label-1, n_clusters=3)\n",
    "                # print('원래', kmeans_accuracy)\n",
    "                # print(result)\n",
    "\n",
    "                k_means_bin_origin_feature.append(origin_kmeans_accuracy)\n",
    "                k_means_bin.append(kmeans_accuracy)\n",
    "                if SAE_net == False and converted_net_forward == True:\n",
    "                    converted_kmeans_accuracy = cluster_spikes_with_accuracy_torch(features= torch.tensor(converted_spike_hidden).to(device), true_labels=label-1, n_clusters=3, init_point=None)\n",
    "                    converted_k_means_bin.append(converted_kmeans_accuracy)\n",
    "                # sklearn kmeans인데 cpu많이먹어서 버림.\n",
    "                # origin_kmeans_accuracy = cluster_spikes_with_accuracy(features= spike.cpu().detach().numpy(), true_labels=label-1, n_clusters=3, init_point=None)\n",
    "                # kmeans_accuracy = cluster_spikes_with_accuracy(features= spike_hidden, true_labels=label-1, n_clusters=3, init_point=None)\n",
    "                # k_means_bin_origin_feature.append(origin_kmeans_accuracy)\n",
    "                # k_means_bin.append(kmeans_accuracy)\n",
    "                # if SAE_net == False and converted_net_forward == True:\n",
    "                #     converted_kmeans_accuracy = cluster_spikes_with_accuracy(features= converted_spike_hidden, true_labels=label-1, n_clusters=3, init_point=None)\n",
    "                #     converted_k_means_bin.append(converted_kmeans_accuracy)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "                # print('Cluster',Cluster)\n",
    "                # print('spike_id', spike_id)\n",
    "\n",
    "                # spike id 분포 확인하기\n",
    "                # unique_elements, counts = np.unique(spike_id, return_counts=True)\n",
    "                # print(\"Unique elements:\", unique_elements)\n",
    "                # print(\"Counts:\", counts)\n",
    "\n",
    "                cluster_accuracy_during_training_cycle = np.zeros(math.factorial(num_cluster))\n",
    "                cluster_accuracy_post_training_cycle = np.zeros(math.factorial(num_cluster))\n",
    "                cluster_accuracy_total = np.zeros(math.factorial(num_cluster))\n",
    "                \n",
    "                label_converter_ground = list(range(1, num_cluster + 1)) # [1, 2, 3, 4] 생성\n",
    "                label_converter_permutations = list(itertools.permutations(label_converter_ground)) # 모든 순열 구하기\n",
    "                perm_i = 0\n",
    "                perm_start_time = time.time() \n",
    "                for perm in label_converter_permutations:\n",
    "                    label_converter = list(perm)\n",
    "                    # print(label_converter)\n",
    "                    correct_during_training_cycle = 0\n",
    "                    correct_post_training_cycle = 0\n",
    "\n",
    "                    assert len(spike_id) == len(label), 'spike_id랑 label 길이 같아야 됨.'\n",
    "                    for i in range(len(spike_id)):\n",
    "                        if(label_converter[int(spike_id[i]-1)] == label[i]):\n",
    "                            if i < training_cycle:\n",
    "                                correct_during_training_cycle += 1\n",
    "                            else:\n",
    "                                correct_post_training_cycle += 1\n",
    "\n",
    "                    cluster_accuracy_during_training_cycle[perm_i] = correct_during_training_cycle/training_cycle\n",
    "                    cluster_accuracy_post_training_cycle[perm_i] = correct_post_training_cycle/(len(spike_id)-training_cycle)\n",
    "                    cluster_accuracy_total[perm_i] = (correct_during_training_cycle+correct_post_training_cycle)/(len(spike_id))\n",
    "                    perm_i += 1\n",
    "                # print(f\"perm 실행 시간: {time.time()-perm_start_time:.3f}초\")\n",
    "                \n",
    "                cluster_accuracy_during_training_cycle_all_dataset[ds] = np.max(cluster_accuracy_during_training_cycle)\n",
    "                cluster_accuracy_post_training_cycle_all_dataset[ds] = cluster_accuracy_post_training_cycle[np.argmax(cluster_accuracy_during_training_cycle)]\n",
    "                cluster_accuracy_total_all_dataset[ds] = cluster_accuracy_total[np.argmax(cluster_accuracy_during_training_cycle)]\n",
    "                # plot_distributions(ds, plot_tau, plot_denominator, plot_m, plot_max_tau, cos_thr[ds],\n",
    "                #                    cluster_accuracy_during_training_cycle_all_dataset[ds], cluster_accuracy_post_training_cycle_all_dataset[ds], cluster_accuracy_total_all_dataset[ds])\n",
    "            print(f'k_means origin feature average accuracy : {100*sum(k_means_bin_origin_feature)/(len(k_means_bin_origin_feature)+1e-12):.8f}%, total {k_means_bin_origin_feature}')\n",
    "            \n",
    "            mean_cluster_accuracy_during_training_cycle_all_dataset = np.mean(cluster_accuracy_during_training_cycle_all_dataset)\n",
    "            mean_cluster_accuracy_post_training_cycle_all_dataset = np.mean(cluster_accuracy_post_training_cycle_all_dataset)\n",
    "            mean_cluster_accuracy_total_all_dataset = np.mean(cluster_accuracy_total_all_dataset)\n",
    "            \n",
    "            if SAE_net == False and converted_net_forward == True:\n",
    "                converted_k_means_acc = 100*sum(converted_k_means_bin)/len(converted_k_means_bin)\n",
    "                print(f'converted_kmeans average accuracy : {converted_k_means_acc:.8f}%, total {converted_k_means_bin}')\n",
    "            k_means_acc = 100*sum(k_means_bin)/len(k_means_bin)\n",
    "            if k_means_acc > k_means_acc_best:\n",
    "                # torch.save(net, f\"net_save/save_now_net_{current_time}.pth\")\n",
    "                torch.save(net.module.state_dict(), f\"net_save/save_now_net_{current_time}.pth\")\n",
    "                print('save model')\n",
    "                best_mean_cluster_accuracy_post_training_cycle_all_dataset = mean_cluster_accuracy_post_training_cycle_all_dataset\n",
    "            \n",
    "            k_means_acc_best = max(k_means_acc_best, k_means_acc)\n",
    "            print(f'kmeans average accuracy best : {k_means_acc_best:.2f}%, kmeans average accuracy : {k_means_acc:.8f}%, total {k_means_bin}')\n",
    "            print(f'cluster_accuracy_post_training_cycle_all_dataset : {cluster_accuracy_post_training_cycle_all_dataset}')\n",
    "\n",
    "            \n",
    "            mean_cluster_accuracy_during_training_cycle_all_dataset_history.append((epoch, mean_cluster_accuracy_during_training_cycle_all_dataset*100))\n",
    "            mean_cluster_accuracy_post_training_cycle_all_dataset_history.append((epoch, mean_cluster_accuracy_post_training_cycle_all_dataset*100))\n",
    "            mean_cluster_accuracy_total_all_dataset_history.append((epoch, mean_cluster_accuracy_total_all_dataset*100))\n",
    "            print(f\"mean_cluster_accuracy_during_training_cycle : {mean_cluster_accuracy_during_training_cycle_all_dataset*100:.2f}%, post_traincycle_acc : {mean_cluster_accuracy_post_training_cycle_all_dataset*100:.2f}%, total_acc : {mean_cluster_accuracy_total_all_dataset*100:.8f}%\")\n",
    "\n",
    "            # kmeans accuracy기준으로 좋은 거 저장할 거임\n",
    "            # if mean_cluster_accuracy_post_training_cycle_all_dataset > best_mean_cluster_accuracy_post_training_cycle_all_dataset:\n",
    "            #     # torch.save(net, f\"net_save/save_now_net_{current_time}.pth\")\n",
    "            #     torch.save(net.module.state_dict(), f\"net_save/save_now_net_{current_time}.pth\")\n",
    "            #     print('save model')\n",
    "            #     best_mean_cluster_accuracy_post_training_cycle_all_dataset = mean_cluster_accuracy_post_training_cycle_all_dataset\n",
    "            print(f\"best_mean_cluster_accuracy_post_training_cycle_all_dataset : {best_mean_cluster_accuracy_post_training_cycle_all_dataset*100:.2f}%\")\n",
    "            print(f\"accuracy_check 실행 시간: {time.time()-accuracy_check_start_time:.3f}초\")\n",
    "\n",
    "        wandb.log({\"avg_loss\": avg_loss})\n",
    "        wandb.log({\"mean_cluster_accuracy_post_training_cycle_all_dataset\": mean_cluster_accuracy_post_training_cycle_all_dataset})\n",
    "        wandb.log({\"best_mean_cluster_accuracy_post_training_cycle_all_dataset\": best_mean_cluster_accuracy_post_training_cycle_all_dataset})\n",
    "        wandb.log({\"best_mean_cluster_accuracy_post_training_cycle_all_dataset2\": best_mean_cluster_accuracy_post_training_cycle_all_dataset})\n",
    "        wandb.log({\"k_means_acc\": k_means_acc})\n",
    "        wandb.log({\"k_means_acc_best\": k_means_acc_best})\n",
    "        wandb.log({\"converted_k_means_acc\": converted_k_means_acc})\n",
    "\n",
    "\n",
    "        # 저장\n",
    "        with open(f\"result_save/cluster_accuracy_history_{current_time}.pkl\", \"wb\") as f:\n",
    "            pickle.dump({\n",
    "                \"loss_history\": loss_history,\n",
    "                \"mean_cluster_accuracy_during_training_cycle_all_dataset_history\": mean_cluster_accuracy_during_training_cycle_all_dataset_history,\n",
    "                \"mean_cluster_accuracy_post_training_cycle_all_dataset_history\": mean_cluster_accuracy_post_training_cycle_all_dataset_history,\n",
    "                \"mean_cluster_accuracy_total_all_dataset_history\": mean_cluster_accuracy_total_all_dataset_history,\n",
    "            }, f)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mbhkim003\u001b[0m (\u001b[33mbhkim003-seoul-national-university\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.19.8 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.17.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/nfs/home/bhkim003/github_folder/ByeonghyeonKim/my_snn/wandb/run-20250313_235816-a2gmdkcg</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/bhkim003-seoul-national-university/spike_sorting%20just%20run/runs/a2gmdkcg' target=\"_blank\">rural-pyramid-1479</a></strong> to <a href='https://wandb.ai/bhkim003-seoul-national-university/spike_sorting%20just%20run' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/bhkim003-seoul-national-university/spike_sorting%20just%20run' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/spike_sorting%20just%20run</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/bhkim003-seoul-national-university/spike_sorting%20just%20run/runs/a2gmdkcg' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/spike_sorting%20just%20run/runs/a2gmdkcg</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'gpu': '0', 'Conv_net': True, 'SAE_net': True, 'dataset_num': 16, 'spike_length': 50, 'num_cluster': 4, 'training_cycle': 1400, 'batch_size': 32, 'max_epoch': 10000, 'learning_rate': 0.001, 'normalize_on': True, 'need_bias': False, 'lif_add_at_first': False, 'my_seed': 42, 'TIME': 50, 'v_decay': 0.5, 'v_threshold': 0.25, 'v_reset': 0.0, 'BPTT_on': True, 'SAE_hidden_nomean': True, 'current_time': '20250313_235813_378', 'optimizer': 'Adam', 'coarse_com_mode': True, 'sae_l2_norm_bridge': True, 'sae_lif_bridge': False, 'accuracy_check_epoch_term': 1, 'lif_add_at_last': False, 'two_channel_input': False, 'lateral_feature_num': 2, 'lc_adc_on': False, 'converted_net_forward': False, 'pretrained_net': None, 'vth_mul_on': False, 'batch_norm_on': False, 'l2_norm_loss_weight': 0, 'QCFS_neuron_on': False, 'quantize_level_num': 0, 'fusion_net': True, 'repeat_coding': False, 'sae_relu_on': False, 'conv1d_scaling': False, 'norm01': True, 'coarse_com_config': (0.999, -0.0)}\n",
      "cos_thr [0.95 0.95 0.95 0.95 0.95 0.95 0.95 0.85 0.95 0.9  0.8  0.95 0.95 0.95\n",
      " 0.95 0.8 ]\n",
      "conv length [50, 24, 11, 5]\n",
      "Total number of encoder parameters: 25832\n",
      "DataParallel(\n",
      "  (module): SAE_FUSION7_net_conv1(\n",
      "    (activation_function): LIF_layer()\n",
      "    (encoder): Sequential(\n",
      "      (0): SSBH_DimChanger_one_two()\n",
      "      (1): SSBH_DimChanger_for_one_two_coupling()\n",
      "      (2): Conv1d(1, 32, kernel_size=(3,), stride=(2,), bias=False)\n",
      "      (3): SSBH_DimChanger_for_one_two_decoupling()\n",
      "      (4): LIF_layer()\n",
      "      (5): SSBH_DimChanger_for_one_two_coupling()\n",
      "      (6): Conv1d(32, 64, kernel_size=(3,), stride=(2,), bias=False)\n",
      "      (7): SSBH_DimChanger_for_one_two_decoupling()\n",
      "      (8): LIF_layer()\n",
      "      (9): SSBH_DimChanger_for_one_two_coupling()\n",
      "      (10): Conv1d(64, 96, kernel_size=(3,), stride=(2,), bias=False)\n",
      "      (11): SSBH_DimChanger_for_one_two_decoupling()\n",
      "      (12): LIF_layer()\n",
      "      (13): SSBH_DimChanger_for_one_two_coupling()\n",
      "      (14): SSBH_DimChanger_for_fc()\n",
      "      (15): Linear(in_features=480, out_features=2, bias=False)\n",
      "      (16): SSBH_DimChanger_for_one_two_decoupling()\n",
      "      (17): LIF_layer()\n",
      "      (18): SSBH_DimChanger_one_two()\n",
      "      (19): SSBH_DimChanger_for_two_three_coupling()\n",
      "      (20): Linear(in_features=100, out_features=2, bias=False)\n",
      "      (21): SSBH_L2NormLayer()\n",
      "    )\n",
      "    (decoder): Sequential(\n",
      "      (0): Linear(in_features=2, out_features=480, bias=False)\n",
      "      (1): ReLU()\n",
      "      (2): SSBH_DimChanger_for_conv1()\n",
      "      (3): ConvTranspose1d(96, 64, kernel_size=(3,), stride=(2,), bias=False)\n",
      "      (4): ReLU()\n",
      "      (5): ConvTranspose1d(64, 32, kernel_size=(3,), stride=(2,), output_padding=(1,), bias=False)\n",
      "      (6): ReLU()\n",
      "      (7): ConvTranspose1d(32, 1, kernel_size=(3,), stride=(2,), output_padding=(1,), bias=False)\n",
      "    )\n",
      "  )\n",
      ")\n",
      "Device: cuda\n",
      "\n",
      "Start Training, current_time = 20250313_235813_378\n",
      "\n",
      "\n",
      "epoch-0 loss : 0.04681985, loss_normal : 0.02496568, loss_coarse : 0.10834452, min_loss : 0.04681985, min_loss_normal : 0.02496568, min_loss_coarse : 0.10834452, wrong_element_sum : 20802148.00000000, same_data : 0.00%\n",
      "ae train 실행 시간: 125.116초, 전체 시작 시간 20250313_235813_378\n",
      "\n",
      "epoch-0 accuracy check\n",
      "k_means origin feature average accuracy : 82.24239603%, total [0.9746727376209448, 0.9733106189664963, 0.9700891573195284, 0.9530800230282096, 0.943108504398827, 0.9150568181818182, 0.801817648783348, 0.6625070901871809, 0.9488619568430388, 0.822215777262181, 0.5866935483870968, 0.5005858230814294, 0.9429250891795482, 0.8922588099364529, 0.673546511627907, 0.5980532493558546]\n",
      "save model\n",
      "kmeans average accuracy best : 78.19%, kmeans average accuracy : 78.19198760%, total [0.9649971542401822, 0.9696195343554799, 0.9485188380788036, 0.9251583189407023, 0.8826979472140762, 0.7832386363636363, 0.703312811492231, 0.6049347702779353, 0.6686373041678983, 0.7491299303944315, 0.6057027649769585, 0.6104276508494435, 0.9039833531510107, 0.8393991912189486, 0.7340116279069767, 0.6169481820784426]\n",
      "cluster_accuracy_post_training_cycle_all_dataset : [0.96452223 0.96842601 0.94222436 0.92622951 0.8800995  0.78160377\n",
      " 0.68970661 0.58560677 0.70196672 0.77001953 0.71283784 0.65342602\n",
      " 0.90733198 0.83462658 0.73480392 0.62541806]\n",
      "mean_cluster_accuracy_during_training_cycle : 80.11%, post_traincycle_acc : 79.24%, total_acc : 79.59283638%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 79.24%\n",
      "accuracy_check 실행 시간: 20.146초\n",
      "\n",
      "\n",
      "epoch-1 loss : 0.03321301, loss_normal : 0.02129156, loss_coarse : 0.09808054, min_loss : 0.03321301, min_loss_normal : 0.02129156, min_loss_coarse : 0.09808054, wrong_element_sum : 18831464.00000000, same_data : 0.00%\n",
      "ae train 실행 시간: 122.102초, 전체 시작 시간 20250313_235813_378\n",
      "\n",
      "epoch-1 accuracy check\n",
      "k_means origin feature average accuracy : 82.24789092%, total [0.9746727376209448, 0.9733106189664963, 0.9700891573195284, 0.9530800230282096, 0.943108504398827, 0.9150568181818182, 0.801817648783348, 0.6622234826999432, 0.9488619568430388, 0.822215777262181, 0.5866935483870968, 0.5005858230814294, 0.9429250891795482, 0.8922588099364529, 0.6747093023255814, 0.5980532493558546]\n",
      "kmeans average accuracy best : 78.19%, kmeans average accuracy : 77.81638043%, total [0.9621513944223108, 0.9653605905735377, 0.9344262295081968, 0.9078871617731722, 0.9249266862170088, 0.8139204545454546, 0.6470243330401642, 0.5811117413499717, 0.8187998817617499, 0.8140951276102089, 0.6235599078341014, 0.6206795547744581, 0.843935790725327, 0.7527440785673022, 0.6662790697674419, 0.5737188663040367]\n",
      "cluster_accuracy_post_training_cycle_all_dataset : [0.96357616 0.96512724 0.93259509 0.91176471 0.92686567 0.78820755\n",
      " 0.68572849 0.58701787 0.81442259 0.82275391 0.73214286 0.69364449\n",
      " 0.83655804 0.76188167 0.66078431 0.59436216]\n",
      "mean_cluster_accuracy_during_training_cycle : 79.49%, post_traincycle_acc : 79.23%, total_acc : 79.33531573%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 79.24%\n",
      "accuracy_check 실행 시간: 24.137초\n",
      "\n",
      "\n",
      "epoch-2 loss : 0.05025003, loss_normal : 0.02685737, loss_coarse : 0.10887900, min_loss : 0.03321301, min_loss_normal : 0.02129156, min_loss_coarse : 0.09808054, wrong_element_sum : 20904768.00000000, same_data : 0.00%\n",
      "ae train 실행 시간: 129.805초, 전체 시작 시간 20250313_235813_378\n",
      "\n",
      "epoch-2 accuracy check\n",
      "k_means origin feature average accuracy : 82.26041597%, total [0.9746727376209448, 0.9733106189664963, 0.9700891573195284, 0.9530800230282096, 0.943108504398827, 0.9150568181818182, 0.801817648783348, 0.6622234826999432, 0.9488619568430388, 0.822215777262181, 0.5866935483870968, 0.5005858230814294, 0.9429250891795482, 0.8922588099364529, 0.6747093023255814, 0.6000572573718866]\n",
      "kmeans average accuracy best : 78.19%, kmeans average accuracy : 70.03119243%, total [0.9476380193511668, 0.8957978421351505, 0.8389416163359218, 0.8068508923431204, 0.8624633431085044, 0.6877840909090909, 0.603635297566696, 0.5740215541690301, 0.6104049660065031, 0.5748259860788864, 0.5452188940092166, 0.45899238429994144, 0.6982758620689655, 0.7423454650491046, 0.6938953488372093, 0.6638992270254795]\n",
      "cluster_accuracy_post_training_cycle_all_dataset : [0.94654683 0.89585297 0.83822821 0.80713597 0.86218905 0.68490566\n",
      " 0.59870711 0.49952963 0.50731215 0.52880859 0.50579151 0.47368421\n",
      " 0.74490835 0.75266731 0.6745098  0.6383182 ]\n",
      "mean_cluster_accuracy_during_training_cycle : 68.24%, post_traincycle_acc : 68.49%, total_acc : 68.38712593%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 79.24%\n",
      "accuracy_check 실행 시간: 41.920초\n",
      "\n",
      "\n",
      "epoch-3 loss : 0.03983959, loss_normal : 0.02307161, loss_coarse : 0.10198506, min_loss : 0.03321301, min_loss_normal : 0.02129156, min_loss_coarse : 0.09808054, wrong_element_sum : 19581132.00000000, same_data : 0.00%\n",
      "ae train 실행 시간: 126.416초, 전체 시작 시간 20250313_235813_378\n",
      "\n",
      "epoch-3 accuracy check\n",
      "k_means origin feature average accuracy : 82.25137006%, total [0.9746727376209448, 0.9733106189664963, 0.9700891573195284, 0.9530800230282096, 0.943108504398827, 0.9150568181818182, 0.801817648783348, 0.6625070901871809, 0.9488619568430388, 0.822215777262181, 0.5866935483870968, 0.5005858230814294, 0.9429250891795482, 0.8922588099364529, 0.6738372093023256, 0.5991983967935872]\n",
      "kmeans average accuracy best : 78.19%, kmeans average accuracy : 75.84691241%, total [0.9718269778030734, 0.9733106189664963, 0.9531205061834915, 0.9277489925158319, 0.8052785923753666, 0.6539772727272727, 0.5452946350043976, 0.5195689166193987, 0.7431274017144546, 0.7398491879350348, 0.7211981566820277, 0.6496777973052138, 0.8323424494649228, 0.7671865973425765, 0.6918604651162791, 0.640137417692528]\n",
      "cluster_accuracy_post_training_cycle_all_dataset : [0.97398297 0.97313855 0.95137217 0.92815815 0.78208955 0.52358491\n",
      " 0.61014421 0.56632173 0.74785678 0.72900391 0.68146718 0.66484608\n",
      " 0.83553971 0.77546072 0.68823529 0.63975155]\n",
      "mean_cluster_accuracy_during_training_cycle : 75.51%, post_traincycle_acc : 75.44%, total_acc : 75.46545579%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 79.24%\n",
      "accuracy_check 실행 시간: 27.174초\n",
      "\n",
      "\n",
      "epoch-4 loss : 0.03023734, loss_normal : 0.02025351, loss_coarse : 0.09420995, min_loss : 0.03023734, min_loss_normal : 0.02025351, min_loss_coarse : 0.09420995, wrong_element_sum : 18088310.00000000, same_data : 0.00%\n",
      "ae train 실행 시간: 131.521초, 전체 시작 시간 20250313_235813_378\n",
      "\n",
      "epoch-4 accuracy check\n",
      "k_means origin feature average accuracy : 82.26393060%, total [0.9746727376209448, 0.9733106189664963, 0.9700891573195284, 0.9530800230282096, 0.943108504398827, 0.915340909090909, 0.801817648783348, 0.6625070901871809, 0.9488619568430388, 0.822215777262181, 0.5872695852534562, 0.5005858230814294, 0.9429250891795482, 0.8922588099364529, 0.6741279069767442, 0.6000572573718866]\n",
      "kmeans average accuracy best : 78.19%, kmeans average accuracy : 75.78829392%, total [0.9726807057484348, 0.9733106189664963, 0.9568593615185504, 0.9358088658606794, 0.8480938416422288, 0.7463068181818182, 0.6678393433010847, 0.5048213272830403, 0.646763227904227, 0.6479118329466357, 0.6013824884792627, 0.5972466315172817, 0.8626634958382877, 0.8145580589254766, 0.7194767441860465, 0.6304036644718007]\n",
      "cluster_accuracy_post_training_cycle_all_dataset : [0.97445601 0.9726673  0.95859413 0.94021215 0.84427861 0.70424528\n",
      " 0.61810045 0.59313264 0.67876954 0.69580078 0.67567568 0.53078451\n",
      " 0.87576375 0.82201746 0.70931373 0.61777353]\n",
      "mean_cluster_accuracy_during_training_cycle : 76.71%, post_traincycle_acc : 76.32%, total_acc : 76.47903671%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 79.24%\n",
      "accuracy_check 실행 시간: 25.774초\n",
      "\n",
      "\n",
      "epoch-5 loss : 0.03051316, loss_normal : 0.02045305, loss_coarse : 0.09461880, min_loss : 0.03023734, min_loss_normal : 0.02025351, min_loss_coarse : 0.09420995, wrong_element_sum : 18166810.00000000, same_data : 0.00%\n",
      "ae train 실행 시간: 127.357초, 전체 시작 시간 20250313_235813_378\n",
      "\n",
      "epoch-5 accuracy check\n",
      "k_means origin feature average accuracy : 82.25313033%, total [0.9746727376209448, 0.9733106189664963, 0.9700891573195284, 0.9530800230282096, 0.943108504398827, 0.915340909090909, 0.801817648783348, 0.6622234826999432, 0.9488619568430388, 0.822215777262181, 0.5866935483870968, 0.5005858230814294, 0.9429250891795482, 0.891681109185442, 0.6738372093023256, 0.6000572573718866]\n",
      "kmeans average accuracy best : 78.19%, kmeans average accuracy : 72.94483365%, total [0.9695503699487763, 0.9662123793299262, 0.9378774805867127, 0.9084628670120898, 0.8161290322580645, 0.7164772727272727, 0.6326590442685429, 0.5836642087351106, 0.671297664794561, 0.6917053364269141, 0.6304723502304147, 0.6101347393087287, 0.7080856123662307, 0.6874638937030618, 0.6122093023255814, 0.5287718293730318]\n",
      "cluster_accuracy_post_training_cycle_all_dataset : [0.9692526  0.96559849 0.93452094 0.90983607 0.76766169 0.65377358\n",
      " 0.56887121 0.53809972 0.79878971 0.67626953 0.63030888 0.6102284\n",
      " 0.68737271 0.68816683 0.61323529 0.51457238]\n",
      "mean_cluster_accuracy_during_training_cycle : 72.71%, post_traincycle_acc : 72.04%, total_acc : 72.30933903%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 79.24%\n",
      "accuracy_check 실행 시간: 31.410초\n",
      "\n",
      "\n",
      "epoch-6 loss : 0.03355402, loss_normal : 0.02145715, loss_coarse : 0.09797640, min_loss : 0.03023734, min_loss_normal : 0.02025351, min_loss_coarse : 0.09420995, wrong_element_sum : 18811470.00000000, same_data : 0.00%\n",
      "ae train 실행 시간: 129.850초, 전체 시작 시간 20250313_235813_378\n",
      "\n",
      "epoch-6 accuracy check\n",
      "k_means origin feature average accuracy : 82.25495209%, total [0.9746727376209448, 0.9733106189664963, 0.9700891573195284, 0.9530800230282096, 0.943108504398827, 0.915340909090909, 0.801817648783348, 0.6625070901871809, 0.9488619568430388, 0.822215777262181, 0.5872695852534562, 0.5005858230814294, 0.9429250891795482, 0.891681109185442, 0.6741279069767442, 0.5991983967935872]\n",
      "kmeans average accuracy best : 78.19%, kmeans average accuracy : 74.94030614%, total [0.9704040978941377, 0.9681998864281658, 0.9358642507909117, 0.9136442141623489, 0.8888563049853373, 0.7846590909090909, 0.5901495162708883, 0.5473624503686897, 0.645580845403488, 0.6447215777262181, 0.5938940092165899, 0.5814294083186877, 0.8531510107015458, 0.7645869439630272, 0.6915697674418605, 0.6163756083595763]\n",
      "cluster_accuracy_post_training_cycle_all_dataset : [0.97256386 0.96889727 0.9364468  0.92092575 0.80945274 0.68490566\n",
      " 0.58279463 0.61241769 0.54362078 0.68457031 0.58301158 0.54667329\n",
      " 0.8604888  0.79388943 0.70147059 0.59770664]\n",
      "mean_cluster_accuracy_during_training_cycle : 74.55%, post_traincycle_acc : 73.75%, total_acc : 74.07824609%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 79.24%\n",
      "accuracy_check 실행 시간: 26.513초\n",
      "\n",
      "\n",
      "epoch-7 loss : 0.03002502, loss_normal : 0.02036876, loss_coarse : 0.09396045, min_loss : 0.03002502, min_loss_normal : 0.02025351, min_loss_coarse : 0.09396045, wrong_element_sum : 18040406.00000000, same_data : 0.00%\n",
      "ae train 실행 시간: 129.792초, 전체 시작 시간 20250313_235813_378\n",
      "\n",
      "epoch-7 accuracy check\n",
      "k_means origin feature average accuracy : 82.26223283%, total [0.9746727376209448, 0.9733106189664963, 0.9700891573195284, 0.9530800230282096, 0.943108504398827, 0.9150568181818182, 0.801817648783348, 0.6622234826999432, 0.9488619568430388, 0.822215777262181, 0.5866935483870968, 0.5005858230814294, 0.9429250891795482, 0.8922588099364529, 0.675, 0.6000572573718866]\n",
      "kmeans average accuracy best : 78.19%, kmeans average accuracy : 76.52309235%, total [0.9695503699487763, 0.9681998864281658, 0.9565717572620075, 0.9320667818077144, 0.8727272727272727, 0.7522727272727273, 0.6772207563764292, 0.5927396483267158, 0.8492462311557789, 0.7842227378190255, 0.7160138248847926, 0.643526654950205, 0.7615933412604042, 0.6819757365684576, 0.5959302325581395, 0.4898368164901231]\n",
      "cluster_accuracy_post_training_cycle_all_dataset : [0.96972564 0.96889727 0.95137217 0.92864031 0.86069652 0.75330189\n",
      " 0.66633516 0.58325494 0.85022693 0.78027344 0.7027027  0.62413108\n",
      " 0.72810591 0.68234724 0.58627451 0.51361682]\n",
      "mean_cluster_accuracy_during_training_cycle : 75.81%, post_traincycle_acc : 75.94%, total_acc : 75.88328458%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 79.24%\n",
      "accuracy_check 실행 시간: 23.810초\n",
      "\n",
      "\n",
      "epoch-8 loss : 0.05304980, loss_normal : 0.02783915, loss_coarse : 0.10878403, min_loss : 0.03002502, min_loss_normal : 0.02025351, min_loss_coarse : 0.09396045, wrong_element_sum : 20886534.00000000, same_data : 0.00%\n",
      "ae train 실행 시간: 128.296초, 전체 시작 시간 20250313_235813_378\n",
      "\n",
      "epoch-8 accuracy check\n",
      "k_means origin feature average accuracy : 82.26220526%, total [0.9746727376209448, 0.9733106189664963, 0.9700891573195284, 0.9530800230282096, 0.943108504398827, 0.9150568181818182, 0.801817648783348, 0.6622234826999432, 0.9488619568430388, 0.822215777262181, 0.5866935483870968, 0.5005858230814294, 0.9429250891795482, 0.8922588099364529, 0.6747093023255814, 0.6003435442313197]\n",
      "kmeans average accuracy best : 78.19%, kmeans average accuracy : 64.05408929%, total [0.7017643710870802, 0.7524134014764339, 0.7612884670693126, 0.7461139896373057, 0.9093841642228739, 0.7639204545454545, 0.6303136909997068, 0.5762904140669314, 0.6828258941767662, 0.5252320185614849, 0.478110599078341, 0.4771528998242531, 0.6816290130796671, 0.5932986712882726, 0.5174418604651163, 0.45147437732608076]\n",
      "cluster_accuracy_post_training_cycle_all_dataset : [0.64806055 0.65268615 0.66008666 0.73818708 0.88109453 0.66462264\n",
      " 0.67926405 0.51881468 0.69591528 0.58740234 0.52171815 0.45332671\n",
      " 0.61252546 0.60911736 0.48382353 0.41184902]\n",
      "mean_cluster_accuracy_during_training_cycle : 60.96%, post_traincycle_acc : 61.37%, total_acc : 61.19792546%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 79.24%\n",
      "accuracy_check 실행 시간: 50.349초\n",
      "\n",
      "\n",
      "epoch-9 loss : 0.05954953, loss_normal : 0.03012576, loss_coarse : 0.11390056, min_loss : 0.03002502, min_loss_normal : 0.02025351, min_loss_coarse : 0.09396045, wrong_element_sum : 21868908.00000000, same_data : 0.00%\n",
      "ae train 실행 시간: 121.174초, 전체 시작 시간 20250313_235813_378\n",
      "\n",
      "epoch-9 accuracy check\n",
      "k_means origin feature average accuracy : 82.26038248%, total [0.9746727376209448, 0.9733106189664963, 0.9700891573195284, 0.9530800230282096, 0.943108504398827, 0.9150568181818182, 0.801817648783348, 0.6622234826999432, 0.9488619568430388, 0.822215777262181, 0.5872695852534562, 0.5005858230814294, 0.9429250891795482, 0.8922588099364529, 0.6741279069767442, 0.6000572573718866]\n",
      "kmeans average accuracy best : 78.19%, kmeans average accuracy : 76.98286777%, total [0.9669891861126921, 0.9673480976717774, 0.9424791486914006, 0.9162348877374784, 0.8765395894428153, 0.734375, 0.6394019349164468, 0.555587067498582, 0.8037245048773278, 0.8123549883990719, 0.6103110599078341, 0.5723491505565319, 0.8127229488703924, 0.7738301559792028, 0.7020348837209303, 0.6309762381906671]\n",
      "cluster_accuracy_post_training_cycle_all_dataset : [0.96783349 0.96465598 0.93885412 0.92140791 0.87960199 0.73113208\n",
      " 0.59025361 0.48918156 0.80635401 0.81494141 0.61727799 0.63157895\n",
      " 0.80804481 0.78273521 0.70245098 0.63784042]\n",
      "mean_cluster_accuracy_during_training_cycle : 76.24%, post_traincycle_acc : 76.78%, total_acc : 76.55375372%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 79.24%\n",
      "accuracy_check 실행 시간: 46.543초\n",
      "\n",
      "\n",
      "epoch-10 loss : 0.03682169, loss_normal : 0.02244271, loss_coarse : 0.09886808, min_loss : 0.03002502, min_loss_normal : 0.02025351, min_loss_coarse : 0.09396045, wrong_element_sum : 18982672.00000000, same_data : 0.00%\n",
      "ae train 실행 시간: 122.618초, 전체 시작 시간 20250313_235813_378\n",
      "\n",
      "epoch-10 accuracy check\n",
      "k_means origin feature average accuracy : 82.25315343%, total [0.9746727376209448, 0.9733106189664963, 0.9700891573195284, 0.9530800230282096, 0.943108504398827, 0.9150568181818182, 0.801817648783348, 0.6625070901871809, 0.9488619568430388, 0.822215777262181, 0.5872695852534562, 0.5005858230814294, 0.9429250891795482, 0.8922588099364529, 0.673546511627907, 0.5991983967935872]\n",
      "kmeans average accuracy best : 78.19%, kmeans average accuracy : 72.31288539%, total [0.9632896983494593, 0.9673480976717774, 0.9442047742306586, 0.9153713298791019, 0.7187683284457478, 0.680965909090909, 0.6004104368220463, 0.5195689166193987, 0.7788944723618091, 0.7427494199535963, 0.567684331797235, 0.5755711775043937, 0.8156956004756243, 0.6637781629116117, 0.5915697674418605, 0.5241912396221013]\n",
      "cluster_accuracy_post_training_cycle_all_dataset : [0.93235572 0.89773798 0.85941261 0.81002893 0.71343284 0.51179245\n",
      " 0.60566882 0.48118532 0.67523954 0.71875    0.65395753 0.58093347\n",
      " 0.82739308 0.67846751 0.58431373 0.52221691]\n",
      "mean_cluster_accuracy_during_training_cycle : 69.39%, post_traincycle_acc : 69.08%, total_acc : 69.19664324%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 79.24%\n",
      "accuracy_check 실행 시간: 30.991초\n",
      "\n",
      "\n",
      "epoch-11 loss : 0.03019685, loss_normal : 0.02030832, loss_coarse : 0.09457798, min_loss : 0.03002502, min_loss_normal : 0.02025351, min_loss_coarse : 0.09396045, wrong_element_sum : 18158972.00000000, same_data : 0.00%\n",
      "ae train 실행 시간: 124.904초, 전체 시작 시간 20250313_235813_378\n",
      "\n",
      "epoch-11 accuracy check\n",
      "k_means origin feature average accuracy : 82.59856590%, total [0.9746727376209448, 0.9733106189664963, 0.9700891573195284, 0.9530800230282096, 0.943108504398827, 0.9150568181818182, 0.801817648783348, 0.6622234826999432, 0.9488619568430388, 0.822215777262181, 0.5872695852534562, 0.5005858230814294, 0.9429250891795482, 0.8913922588099364, 0.6747093023255814, 0.6544517606641855]\n",
      "kmeans average accuracy best : 78.19%, kmeans average accuracy : 77.18127468%, total [0.9701195219123506, 0.9667802385008518, 0.9364394593039977, 0.9124928036845136, 0.7914956011730205, 0.7411931818181818, 0.6640281442392261, 0.5394214407260352, 0.7623411173514631, 0.7682714617169374, 0.7206221198156681, 0.5969537199765671, 0.8284780023781213, 0.7764298093587522, 0.7200581395348837, 0.6538791869453192]\n",
      "cluster_accuracy_post_training_cycle_all_dataset : [0.97161779 0.966541   0.93355802 0.91755063 0.77313433 0.67122642\n",
      " 0.58478369 0.57290687 0.76752395 0.77783203 0.67181467 0.61618669\n",
      " 0.83095723 0.78467507 0.72303922 0.63975155]\n",
      "mean_cluster_accuracy_during_training_cycle : 76.46%, post_traincycle_acc : 76.27%, total_acc : 76.34689897%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 79.24%\n",
      "accuracy_check 실행 시간: 45.180초\n",
      "\n",
      "\n",
      "epoch-12 loss : 0.03399647, loss_normal : 0.02153425, loss_coarse : 0.09828906, min_loss : 0.03002502, min_loss_normal : 0.02025351, min_loss_coarse : 0.09396045, wrong_element_sum : 18871500.00000000, same_data : 0.00%\n",
      "ae train 실행 시간: 128.414초, 전체 시작 시간 20250313_235813_378\n",
      "\n",
      "epoch-12 accuracy check\n",
      "k_means origin feature average accuracy : 82.24780822%, total [0.9746727376209448, 0.9733106189664963, 0.9700891573195284, 0.9530800230282096, 0.943108504398827, 0.9150568181818182, 0.801817648783348, 0.6622234826999432, 0.9488619568430388, 0.822215777262181, 0.5866935483870968, 0.5005858230814294, 0.9429250891795482, 0.8922588099364529, 0.6738372093023256, 0.598912109934154]\n",
      "kmeans average accuracy best : 78.19%, kmeans average accuracy : 68.89645462%, total [0.9721115537848606, 0.9724588302101079, 0.9442047742306586, 0.9162348877374784, 0.7592375366568915, 0.5818181818181818, 0.475520375256523, 0.4628474191718661, 0.6429204847768253, 0.6084686774941995, 0.5665322580645161, 0.5325131810193322, 0.7877526753864447, 0.5927209705372617, 0.6011627906976744, 0.6069281419982823]\n",
      "cluster_accuracy_post_training_cycle_all_dataset : [0.96877956 0.966541   0.9364468  0.92285439 0.75870647 0.53632075\n",
      " 0.46046743 0.45672625 0.56933938 0.61083984 0.57239382 0.5347567\n",
      " 0.78564155 0.7371484  0.66911765 0.57859532]\n",
      "mean_cluster_accuracy_during_training_cycle : 69.43%, post_traincycle_acc : 69.15%, total_acc : 69.26862181%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 79.24%\n",
      "accuracy_check 실행 시간: 34.797초\n",
      "\n",
      "\n",
      "epoch-13 loss : 0.03249002, loss_normal : 0.02126063, loss_coarse : 0.09767929, min_loss : 0.03002502, min_loss_normal : 0.02025351, min_loss_coarse : 0.09396045, wrong_element_sum : 18754424.00000000, same_data : 0.00%\n",
      "ae train 실행 시간: 125.340초, 전체 시작 시간 20250313_235813_378\n",
      "\n",
      "epoch-13 accuracy check\n",
      "k_means origin feature average accuracy : 82.24772089%, total [0.9746727376209448, 0.9733106189664963, 0.9700891573195284, 0.9530800230282096, 0.943108504398827, 0.9150568181818182, 0.8015244796247435, 0.6625070901871809, 0.9488619568430388, 0.822215777262181, 0.5866935483870968, 0.5005858230814294, 0.9429250891795482, 0.8922588099364529, 0.673546511627907, 0.5991983967935872]\n",
      "kmeans average accuracy best : 78.19%, kmeans average accuracy : 75.85511912%, total [0.9664200341491178, 0.9605337876206701, 0.9157319528329019, 0.8886010362694301, 0.9026392961876832, 0.7664772727272727, 0.5971855760773966, 0.5473624503686897, 0.6715932604197458, 0.6644431554524362, 0.6431451612903226, 0.5761570005858231, 0.8483947681331748, 0.7862507221259387, 0.7316860465116279, 0.6701975379330088]\n",
      "cluster_accuracy_post_training_cycle_all_dataset : [0.96736045 0.96182846 0.91285508 0.89633558 0.74427861 0.66367925\n",
      " 0.55246146 0.55832549 0.66565809 0.67138672 0.57432432 0.58291956\n",
      " 0.84623218 0.79097963 0.72303922 0.62494028]\n",
      "mean_cluster_accuracy_during_training_cycle : 74.48%, post_traincycle_acc : 73.35%, total_acc : 73.81067358%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 79.24%\n",
      "accuracy_check 실행 시간: 35.057초\n",
      "\n",
      "\n",
      "epoch-14 loss : 0.06033228, loss_normal : 0.02989739, loss_coarse : 0.11338164, min_loss : 0.03002502, min_loss_normal : 0.02025351, min_loss_coarse : 0.09396045, wrong_element_sum : 21769276.00000000, same_data : 0.00%\n",
      "ae train 실행 시간: 128.469초, 전체 시작 시간 20250313_235813_378\n",
      "\n",
      "epoch-14 accuracy check\n",
      "k_means origin feature average accuracy : 82.25314853%, total [0.9746727376209448, 0.9733106189664963, 0.9700891573195284, 0.9530800230282096, 0.943108504398827, 0.9150568181818182, 0.801817648783348, 0.6622234826999432, 0.9488619568430388, 0.822215777262181, 0.5866935483870968, 0.5005858230814294, 0.9429250891795482, 0.8922588099364529, 0.673546511627907, 0.6000572573718866]\n",
      "kmeans average accuracy best : 78.19%, kmeans average accuracy : 34.22488434%, total [0.3392145702902675, 0.35122089721749006, 0.34167385677308026, 0.34484743811168683, 0.34222873900293255, 0.34488636363636366, 0.346232776311932, 0.3369256948383437, 0.3414129470883831, 0.3375870069605568, 0.33755760368663595, 0.3453427065026362, 0.3373959571938169, 0.34286539572501445, 0.3444767441860465, 0.34211279702261665]\n",
      "cluster_accuracy_post_training_cycle_all_dataset : [0.33491012 0.35815269 0.33654309 0.32111861 0.33930348 0.3254717\n",
      " 0.32521134 0.3565381  0.34140192 0.33349609 0.33252896 0.3326713\n",
      " 0.33604888 0.33947624 0.33970588 0.35260392]\n",
      "mean_cluster_accuracy_during_training_cycle : 34.68%, post_traincycle_acc : 33.78%, total_acc : 34.14636178%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 79.24%\n",
      "accuracy_check 실행 시간: 156.253초\n",
      "\n",
      "\n",
      "epoch-15 loss : 0.06415066, loss_normal : 0.03124518, loss_coarse : 0.12749530, min_loss : 0.03002502, min_loss_normal : 0.02025351, min_loss_coarse : 0.09396045, wrong_element_sum : 24479098.00000000, same_data : 0.00%\n",
      "ae train 실행 시간: 127.292초, 전체 시작 시간 20250313_235813_378\n",
      "\n",
      "epoch-15 accuracy check\n",
      "k_means origin feature average accuracy : 82.25129579%, total [0.9746727376209448, 0.9733106189664963, 0.9700891573195284, 0.9530800230282096, 0.943108504398827, 0.9150568181818182, 0.801817648783348, 0.6625070901871809, 0.9488619568430388, 0.8216357308584686, 0.5866935483870968, 0.5005858230814294, 0.9429250891795482, 0.8922588099364529, 0.673546511627907, 0.6000572573718866]\n",
      "kmeans average accuracy best : 78.19%, kmeans average accuracy : 70.80608335%, total [0.954183266932271, 0.9588302101078933, 0.9269485188380788, 0.8972366148531952, 0.7346041055718475, 0.6417613636363636, 0.5857519788918206, 0.5337492909812819, 0.5767070647354419, 0.5812064965197216, 0.5941820276497696, 0.526654950205038, 0.8041022592152199, 0.7403235124205662, 0.6726744186046512, 0.6000572573718866]\n",
      "cluster_accuracy_post_training_cycle_all_dataset : [0.95506149 0.95852969 0.92826192 0.8924783  0.73532338 0.53396226\n",
      " 0.54400796 0.53057385 0.58799798 0.59326172 0.59700772 0.58738828\n",
      " 0.7892057  0.72938894 0.64754902 0.61204013]\n",
      "mean_cluster_accuracy_during_training_cycle : 70.15%, post_traincycle_acc : 70.14%, total_acc : 70.13939805%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 79.24%\n",
      "accuracy_check 실행 시간: 39.292초\n",
      "\n",
      "\n",
      "epoch-16 loss : 0.04062830, loss_normal : 0.02271892, loss_coarse : 0.10425503, min_loss : 0.03002502, min_loss_normal : 0.02025351, min_loss_coarse : 0.09396045, wrong_element_sum : 20016966.00000000, same_data : 0.00%\n",
      "ae train 실행 시간: 124.401초, 전체 시작 시간 20250313_235813_378\n",
      "\n",
      "epoch-16 accuracy check\n",
      "k_means origin feature average accuracy : 82.24226135%, total [0.9746727376209448, 0.9733106189664963, 0.9700891573195284, 0.9530800230282096, 0.943108504398827, 0.9150568181818182, 0.801817648783348, 0.6622234826999432, 0.9488619568430388, 0.822215777262181, 0.5866935483870968, 0.5, 0.942627824019025, 0.8922588099364529, 0.673546511627907, 0.5991983967935872]\n",
      "kmeans average accuracy best : 78.19%, kmeans average accuracy : 75.54344369%, total [0.9678429140580534, 0.9639409426462238, 0.9370146678170836, 0.9127806563039723, 0.8548387096774194, 0.7232954545454545, 0.6065669891527411, 0.5714690867838911, 0.733372746083358, 0.7610208816705336, 0.6851958525345622, 0.5489162272993556, 0.7690249702734839, 0.7400346620450606, 0.6895348837209302, 0.6221013455482394]\n",
      "cluster_accuracy_post_training_cycle_all_dataset : [0.9692526  0.96559849 0.92826192 0.91610415 0.8159204  0.53962264\n",
      " 0.53853804 0.47977422 0.69994957 0.64355469 0.53088803 0.61618669\n",
      " 0.77596741 0.74733269 0.69166667 0.6043956 ]\n",
      "mean_cluster_accuracy_during_training_cycle : 72.96%, post_traincycle_acc : 71.64%, total_acc : 72.16125486%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 79.24%\n",
      "accuracy_check 실행 시간: 33.432초\n",
      "\n",
      "\n",
      "epoch-17 loss : 0.03749279, loss_normal : 0.02165918, loss_coarse : 0.10024842, min_loss : 0.03002502, min_loss_normal : 0.02025351, min_loss_coarse : 0.09396045, wrong_element_sum : 19247698.00000000, same_data : 0.00%\n",
      "ae train 실행 시간: 126.865초, 전체 시작 시간 20250313_235813_378\n",
      "\n",
      "epoch-17 accuracy check\n",
      "k_means origin feature average accuracy : 82.26569387%, total [0.9746727376209448, 0.9733106189664963, 0.9700891573195284, 0.9530800230282096, 0.943108504398827, 0.9150568181818182, 0.8015244796247435, 0.6622234826999432, 0.9488619568430388, 0.822215777262181, 0.5872695852534562, 0.5005858230814294, 0.942627824019025, 0.8922588099364529, 0.6747093023255814, 0.6009161179501861]\n",
      "kmeans average accuracy best : 78.19%, kmeans average accuracy : 73.94070359%, total [0.9664200341491178, 0.967915956842703, 0.9453551912568307, 0.9211283822682786, 0.8331378299120235, 0.66875, 0.6250366461448256, 0.5822461712989223, 0.6961276973100798, 0.6818445475638051, 0.6419930875576036, 0.5685413005272407, 0.7360285374554102, 0.7134604274985558, 0.6578488372093023, 0.6246779272831378]\n",
      "cluster_accuracy_post_training_cycle_all_dataset : [0.96830653 0.96795476 0.94511314 0.92092575 0.56318408 0.59056604\n",
      " 0.46195922 0.51034807 0.69389813 0.68212891 0.56756757 0.63207547\n",
      " 0.7398167  0.71580989 0.6627451  0.55900621]\n",
      "mean_cluster_accuracy_during_training_cycle : 70.43%, post_traincycle_acc : 69.88%, total_acc : 70.11001589%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 79.24%\n",
      "accuracy_check 실행 시간: 29.673초\n",
      "\n",
      "\n",
      "epoch-18 loss : 0.03639387, loss_normal : 0.02147696, loss_coarse : 0.09935741, min_loss : 0.03002502, min_loss_normal : 0.02025351, min_loss_coarse : 0.09396045, wrong_element_sum : 19076624.00000000, same_data : 0.00%\n",
      "ae train 실행 시간: 123.898초, 전체 시작 시간 20250313_235813_378\n",
      "\n",
      "epoch-18 accuracy check\n",
      "k_means origin feature average accuracy : 82.25668041%, total [0.9746727376209448, 0.9733106189664963, 0.9700891573195284, 0.9530800230282096, 0.943108504398827, 0.9150568181818182, 0.801817648783348, 0.6622234826999432, 0.9488619568430388, 0.8216357308584686, 0.5866935483870968, 0.5005858230814294, 0.9429250891795482, 0.8922588099364529, 0.673546511627907, 0.6012024048096193]\n",
      "kmeans average accuracy best : 78.19%, kmeans average accuracy : 70.43387151%, total [0.9686966420034149, 0.9676320272572402, 0.9361518550474547, 0.915083477259643, 0.6920821114369502, 0.6431818181818182, 0.5189094107299912, 0.5099262620533183, 0.5935560153709725, 0.6107888631090487, 0.6215437788018433, 0.5887521968365553, 0.8005350772889417, 0.6481802426343154, 0.6343023255813953, 0.6200973375322073]\n",
      "cluster_accuracy_post_training_cycle_all_dataset : [0.97019868 0.96748351 0.93596533 0.91706847 0.69402985 0.58726415\n",
      " 0.50969667 0.50658514 0.5874937  0.60205078 0.61872587 0.60178749\n",
      " 0.80600815 0.65518914 0.64117647 0.60009556]\n",
      "mean_cluster_accuracy_during_training_cycle : 70.54%, post_traincycle_acc : 70.01%, total_acc : 70.21978913%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 79.24%\n",
      "accuracy_check 실행 시간: 32.358초\n",
      "\n",
      "\n",
      "epoch-19 loss : 0.04249698, loss_normal : 0.02473097, loss_coarse : 0.10876856, min_loss : 0.03002502, min_loss_normal : 0.02025351, min_loss_coarse : 0.09396045, wrong_element_sum : 20883564.00000000, same_data : 0.00%\n",
      "ae train 실행 시간: 124.378초, 전체 시작 시간 20250313_235813_378\n",
      "\n",
      "epoch-19 accuracy check\n",
      "k_means origin feature average accuracy : 82.25849806%, total [0.9746727376209448, 0.9733106189664963, 0.9700891573195284, 0.9530800230282096, 0.943108504398827, 0.915340909090909, 0.8015244796247435, 0.6625070901871809, 0.9488619568430388, 0.822215777262181, 0.5866935483870968, 0.5005858230814294, 0.9429250891795482, 0.8922588099364529, 0.6741279069767442, 0.6000572573718866]\n",
      "kmeans average accuracy best : 78.19%, kmeans average accuracy : 75.21760721%, total [0.9573136027319294, 0.9551391254968767, 0.9188955996548749, 0.8940702360391479, 0.7480938416422287, 0.6678977272727272, 0.5957197302843741, 0.5391378332387975, 0.7874667454921667, 0.7842227378190255, 0.7537442396313364, 0.6775043936731108, 0.7794292508917955, 0.7215482380127094, 0.6686046511627907, 0.5860292012596622]\n",
      "cluster_accuracy_post_training_cycle_all_dataset : [0.95742668 0.95711593 0.91911411 0.90067502 0.760199   0.66132075\n",
      " 0.58677275 0.52587018 0.78618255 0.79785156 0.62403475 0.64945382\n",
      " 0.49898167 0.57419981 0.43480392 0.43908266]\n",
      "mean_cluster_accuracy_during_training_cycle : 72.19%, post_traincycle_acc : 69.21%, total_acc : 70.42442827%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 79.24%\n",
      "accuracy_check 실행 시간: 42.938초\n",
      "\n",
      "\n",
      "epoch-20 loss : 0.03789781, loss_normal : 0.02218415, loss_coarse : 0.10158677, min_loss : 0.03002502, min_loss_normal : 0.02025351, min_loss_coarse : 0.09396045, wrong_element_sum : 19504660.00000000, same_data : 0.00%\n",
      "ae train 실행 시간: 127.815초, 전체 시작 시간 20250313_235813_378\n",
      "\n",
      "epoch-20 accuracy check\n",
      "k_means origin feature average accuracy : 82.25492529%, total [0.9746727376209448, 0.9733106189664963, 0.9700891573195284, 0.9530800230282096, 0.943108504398827, 0.9150568181818182, 0.801817648783348, 0.6625070901871809, 0.9488619568430388, 0.8219257540603249, 0.5866935483870968, 0.5005858230814294, 0.9429250891795482, 0.8922588099364529, 0.6738372093023256, 0.6000572573718866]\n",
      "kmeans average accuracy best : 78.19%, kmeans average accuracy : 75.05018569%, total [0.9615822424587365, 0.9639409426462238, 0.9367270635605407, 0.9127806563039723, 0.6759530791788856, 0.740909090909091, 0.5713866901201994, 0.5365853658536586, 0.7647058823529411, 0.7647911832946636, 0.7741935483870968, 0.6649091974223784, 0.7838882282996433, 0.7538994800693241, 0.6944767441860465, 0.5073003149155454]\n",
      "cluster_accuracy_post_training_cycle_all_dataset : [0.96357616 0.96512724 0.93452094 0.91947927 0.68109453 0.61509434\n",
      " 0.55693685 0.46989652 0.76348966 0.76464844 0.65057915 0.66285998\n",
      " 0.78105906 0.7657614  0.43970588 0.43191591]\n",
      "mean_cluster_accuracy_during_training_cycle : 73.38%, post_traincycle_acc : 71.04%, total_acc : 71.98277469%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 79.24%\n",
      "accuracy_check 실행 시간: 49.057초\n",
      "\n",
      "\n",
      "epoch-21 loss : 0.03587753, loss_normal : 0.02153250, loss_coarse : 0.09929631, min_loss : 0.03002502, min_loss_normal : 0.02025351, min_loss_coarse : 0.09396045, wrong_element_sum : 19064892.00000000, same_data : 0.00%\n",
      "ae train 실행 시간: 128.125초, 전체 시작 시간 20250313_235813_378\n",
      "\n",
      "epoch-21 accuracy check\n",
      "k_means origin feature average accuracy : 82.26398863%, total [0.9746727376209448, 0.9733106189664963, 0.9700891573195284, 0.9530800230282096, 0.943108504398827, 0.9150568181818182, 0.801817648783348, 0.6625070901871809, 0.9488619568430388, 0.822215777262181, 0.5869815668202765, 0.5005858230814294, 0.9429250891795482, 0.8922588099364529, 0.6747093023255814, 0.6000572573718866]\n",
      "kmeans average accuracy best : 78.19%, kmeans average accuracy : 75.60847274%, total [0.9678429140580534, 0.9681998864281658, 0.9393155018694277, 0.9127806563039723, 0.7604105571847507, 0.70625, 0.5702140134857813, 0.5779920589903573, 0.7265740467041087, 0.7465197215777262, 0.7151497695852534, 0.6209724663151728, 0.8733650416171225, 0.8087810514153668, 0.6799418604651163, 0.5230460921843687]\n",
      "cluster_accuracy_post_training_cycle_all_dataset : [0.97019868 0.96842601 0.94029851 0.91851495 0.71094527 0.73584906\n",
      " 0.57981104 0.45108184 0.65859808 0.72851562 0.60472973 0.63455809\n",
      " 0.77494908 0.64161009 0.44754902 0.45341615]\n",
      "mean_cluster_accuracy_during_training_cycle : 72.45%, post_traincycle_acc : 70.12%, total_acc : 71.06008650%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 79.24%\n",
      "accuracy_check 실행 시간: 44.639초\n",
      "\n",
      "\n",
      "epoch-22 loss : 0.03454018, loss_normal : 0.02133247, loss_coarse : 0.09874985, min_loss : 0.03002502, min_loss_normal : 0.02025351, min_loss_coarse : 0.09396045, wrong_element_sum : 18959972.00000000, same_data : 0.00%\n",
      "ae train 실행 시간: 121.752초, 전체 시작 시간 20250313_235813_378\n",
      "\n",
      "epoch-22 accuracy check\n",
      "k_means origin feature average accuracy : 82.25492108%, total [0.9746727376209448, 0.9733106189664963, 0.9700891573195284, 0.9530800230282096, 0.943108504398827, 0.9150568181818182, 0.801817648783348, 0.6625070901871809, 0.9488619568430388, 0.822215777262181, 0.5866935483870968, 0.5005858230814294, 0.9429250891795482, 0.8922588099364529, 0.673546511627907, 0.6000572573718866]\n",
      "kmeans average accuracy best : 78.19%, kmeans average accuracy : 76.87890659%, total [0.9649971542401822, 0.965076660988075, 0.9424791486914006, 0.9173862982153138, 0.7703812316715543, 0.6542613636363637, 0.5816476106713574, 0.581678956324447, 0.8368312148980195, 0.8198955916473318, 0.6949884792626728, 0.715875805506737, 0.8763376932223543, 0.8116695551704217, 0.6744186046511628, 0.4926996850844546]\n",
      "cluster_accuracy_post_training_cycle_all_dataset : [0.96641438 0.96465598 0.94222436 0.92092575 0.76965174 0.65518868\n",
      " 0.5420189  0.4943556  0.83459405 0.67138672 0.69401544 0.71251241\n",
      " 0.88136456 0.72744908 0.62009804 0.43143813]\n",
      "mean_cluster_accuracy_during_training_cycle : 75.21%, post_traincycle_acc : 73.93%, total_acc : 74.44178428%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 79.24%\n",
      "accuracy_check 실행 시간: 35.646초\n",
      "\n",
      "\n",
      "epoch-23 loss : 0.03313501, loss_normal : 0.02107220, loss_coarse : 0.09774345, min_loss : 0.03002502, min_loss_normal : 0.02025351, min_loss_coarse : 0.09396045, wrong_element_sum : 18766742.00000000, same_data : 0.00%\n",
      "ae train 실행 시간: 123.767초, 전체 시작 시간 20250313_235813_378\n",
      "\n",
      "epoch-23 accuracy check\n",
      "k_means origin feature average accuracy : 82.26748452%, total [0.9746727376209448, 0.9733106189664963, 0.9700891573195284, 0.9530800230282096, 0.943108504398827, 0.915340909090909, 0.801817648783348, 0.6622234826999432, 0.9488619568430388, 0.822215777262181, 0.5872695852534562, 0.5002929115407148, 0.9429250891795482, 0.8922588099364529, 0.6741279069767442, 0.6012024048096193]\n",
      "kmeans average accuracy best : 78.19%, kmeans average accuracy : 76.07586143%, total [0.9686966420034149, 0.966496308915389, 0.9344262295081968, 0.9107656879677605, 0.83841642228739, 0.7661931818181819, 0.5549692172383466, 0.5802609188882587, 0.7780076854862548, 0.7665313225058005, 0.7188940092165899, 0.6110134739308729, 0.821640903686088, 0.7732524552281917, 0.6741279069767442, 0.508445462353278]\n",
      "cluster_accuracy_post_training_cycle_all_dataset : [0.97067171 0.96606975 0.93452094 0.91272903 0.84726368 0.68584906\n",
      " 0.53605172 0.48071496 0.7771054  0.77734375 0.60907336 0.62164846\n",
      " 0.81415479 0.78031038 0.59411765 0.52747253]\n",
      "mean_cluster_accuracy_during_training_cycle : 75.33%, post_traincycle_acc : 73.97%, total_acc : 74.51623710%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 79.24%\n",
      "accuracy_check 실행 시간: 24.304초\n",
      "\n",
      "\n",
      "epoch-24 loss : 0.03272229, loss_normal : 0.02098843, loss_coarse : 0.09740113, min_loss : 0.03002502, min_loss_normal : 0.02025351, min_loss_coarse : 0.09396045, wrong_element_sum : 18701018.00000000, same_data : 0.00%\n",
      "ae train 실행 시간: 129.138초, 전체 시작 시간 20250313_235813_378\n",
      "\n",
      "epoch-24 accuracy check\n",
      "k_means origin feature average accuracy : 82.58773747%, total [0.9746727376209448, 0.9733106189664963, 0.9700891573195284, 0.9530800230282096, 0.943108504398827, 0.915340909090909, 0.801817648783348, 0.6625070901871809, 0.9488619568430388, 0.822215777262181, 0.5872695852534562, 0.5005858230814294, 0.9429250891795482, 0.8922588099364529, 0.673546511627907, 0.6524477526481535]\n",
      "save model\n",
      "kmeans average accuracy best : 78.64%, kmeans average accuracy : 78.63562965%, total [0.9684120660216278, 0.9656445201590006, 0.9257981018119068, 0.9055843408175014, 0.8536656891495601, 0.790625, 0.703312811492231, 0.6284741917186614, 0.739284658587053, 0.7250580046403712, 0.6644585253456221, 0.5975395430579965, 0.8793103448275862, 0.8004043905257077, 0.7436046511627907, 0.6905239049527626]\n",
      "cluster_accuracy_post_training_cycle_all_dataset : [0.97019868 0.96701225 0.92970631 0.90983607 0.87910448 0.56556604\n",
      " 0.55643958 0.5809031  0.71507816 0.72363281 0.57046332 0.59682224\n",
      " 0.88594705 0.80455868 0.72843137 0.66889632]\n",
      "mean_cluster_accuracy_during_training_cycle : 77.27%, post_traincycle_acc : 75.33%, total_acc : 76.10532699%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 75.33%\n",
      "accuracy_check 실행 시간: 26.970초\n",
      "\n",
      "\n",
      "epoch-25 loss : 0.03307076, loss_normal : 0.02108988, loss_coarse : 0.09746538, min_loss : 0.03002502, min_loss_normal : 0.02025351, min_loss_coarse : 0.09396045, wrong_element_sum : 18713354.00000000, same_data : 0.00%\n",
      "ae train 실행 시간: 125.032초, 전체 시작 시간 20250313_235813_378\n",
      "\n",
      "epoch-25 accuracy check\n",
      "k_means origin feature average accuracy : 82.26029687%, total [0.9746727376209448, 0.9733106189664963, 0.9700891573195284, 0.9530800230282096, 0.943108504398827, 0.915340909090909, 0.801817648783348, 0.6625070901871809, 0.9488619568430388, 0.822215777262181, 0.5872695852534562, 0.5005858230814294, 0.9429250891795482, 0.8922588099364529, 0.673546511627907, 0.6000572573718866]\n",
      "kmeans average accuracy best : 78.64%, kmeans average accuracy : 70.52563339%, total [0.9678429140580534, 0.9625212947189097, 0.9197584124245038, 0.8995394358088659, 0.669208211143695, 0.5838068181818182, 0.5013192612137203, 0.49120816789563243, 0.653857522908661, 0.6412412993039444, 0.6379608294930875, 0.6048623315758641, 0.745243757431629, 0.719526285384171, 0.6738372093023256, 0.6123675923275121]\n",
      "cluster_accuracy_post_training_cycle_all_dataset : [0.9692526  0.96418473 0.91670679 0.90597878 0.67761194 0.55\n",
      " 0.50522128 0.46660395 0.65002521 0.64111328 0.62644788 0.60178749\n",
      " 0.73167006 0.73035887 0.60882353 0.60965122]\n",
      "mean_cluster_accuracy_during_training_cycle : 70.18%, post_traincycle_acc : 69.72%, total_acc : 69.90613832%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 75.33%\n",
      "accuracy_check 실행 시간: 34.038초\n",
      "\n",
      "\n",
      "epoch-26 loss : 0.03460075, loss_normal : 0.02157324, loss_coarse : 0.09899979, min_loss : 0.03002502, min_loss_normal : 0.02025351, min_loss_coarse : 0.09396045, wrong_element_sum : 19007960.00000000, same_data : 0.00%\n",
      "ae train 실행 시간: 128.861초, 전체 시작 시간 20250313_235813_378\n",
      "\n",
      "epoch-26 accuracy check\n",
      "k_means origin feature average accuracy : 82.25308877%, total [0.9746727376209448, 0.9733106189664963, 0.9700891573195284, 0.9530800230282096, 0.943108504398827, 0.9150568181818182, 0.8015244796247435, 0.6625070901871809, 0.9488619568430388, 0.822215777262181, 0.5866935483870968, 0.5005858230814294, 0.9429250891795482, 0.8922588099364529, 0.673546511627907, 0.6000572573718866]\n",
      "save model\n",
      "kmeans average accuracy best : 78.79%, kmeans average accuracy : 78.78984976%, total [0.9678429140580534, 0.9721749006246451, 0.9626114466494105, 0.9507772020725389, 0.8117302052785924, 0.7772727272727272, 0.7091761946643214, 0.6429381735677822, 0.8492462311557789, 0.7737819025522041, 0.7263824884792627, 0.6233157586408905, 0.8504756242568371, 0.7527440785673022, 0.6607558139534884, 0.5751503006012024]\n",
      "cluster_accuracy_post_training_cycle_all_dataset : [0.96972564 0.9726673  0.96437169 0.95467695 0.81343284 0.77735849\n",
      " 0.71854799 0.62041392 0.84871407 0.75341797 0.66071429 0.60129096\n",
      " 0.85743381 0.75315228 0.66764706 0.47396082]\n",
      "mean_cluster_accuracy_during_training_cycle : 77.37%, post_traincycle_acc : 77.55%, total_acc : 77.47509084%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 77.55%\n",
      "accuracy_check 실행 시간: 32.154초\n",
      "\n",
      "\n",
      "epoch-27 loss : 0.03348703, loss_normal : 0.02095699, loss_coarse : 0.09686054, min_loss : 0.03002502, min_loss_normal : 0.02025351, min_loss_coarse : 0.09396045, wrong_element_sum : 18597224.00000000, same_data : 0.00%\n",
      "ae train 실행 시간: 119.583초, 전체 시작 시간 20250313_235813_378\n",
      "\n",
      "epoch-27 accuracy check\n",
      "k_means origin feature average accuracy : 82.24230604%, total [0.9746727376209448, 0.9733106189664963, 0.9700891573195284, 0.9530800230282096, 0.943108504398827, 0.9150568181818182, 0.8015244796247435, 0.6625070901871809, 0.9488619568430388, 0.822215777262181, 0.5872695852534562, 0.5005858230814294, 0.942627824019025, 0.8922588099364529, 0.673546511627907, 0.5980532493558546]\n",
      "kmeans average accuracy best : 78.79%, kmeans average accuracy : 77.12962619%, total [0.9706886738759248, 0.9716070414537195, 0.9476560253091746, 0.9251583189407023, 0.8126099706744868, 0.7011363636363637, 0.6168279097038991, 0.5606920022688598, 0.7123854566952409, 0.7308584686774942, 0.7024769585253456, 0.6461628588166374, 0.8370986920332937, 0.7946273830155979, 0.7313953488372092, 0.6793587174348698]\n",
      "cluster_accuracy_post_training_cycle_all_dataset : [0.9730369  0.9726673  0.94559461 0.92767599 0.82288557 0.69622642\n",
      " 0.56389856 0.52916275 0.71205245 0.609375   0.64430502 0.64597815\n",
      " 0.84266802 0.80504365 0.72303922 0.6779742 ]\n",
      "mean_cluster_accuracy_during_training_cycle : 76.13%, post_traincycle_acc : 75.57%, total_acc : 75.79889682%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 77.55%\n",
      "accuracy_check 실행 시간: 43.677초\n",
      "\n",
      "\n",
      "epoch-28 loss : 0.03448297, loss_normal : 0.02142406, loss_coarse : 0.09846257, min_loss : 0.03002502, min_loss_normal : 0.02025351, min_loss_coarse : 0.09396045, wrong_element_sum : 18904814.00000000, same_data : 0.00%\n",
      "ae train 실행 시간: 123.610초, 전체 시작 시간 20250313_235813_378\n",
      "\n",
      "epoch-28 accuracy check\n",
      "k_means origin feature average accuracy : 82.24789092%, total [0.9746727376209448, 0.9733106189664963, 0.9700891573195284, 0.9530800230282096, 0.943108504398827, 0.9150568181818182, 0.801817648783348, 0.6622234826999432, 0.9488619568430388, 0.822215777262181, 0.5866935483870968, 0.5005858230814294, 0.9429250891795482, 0.8922588099364529, 0.6747093023255814, 0.5980532493558546]\n",
      "kmeans average accuracy best : 78.79%, kmeans average accuracy : 70.02586987%, total [0.9672737620944792, 0.9721749006246451, 0.9605982168536095, 0.9525043177892919, 0.6988269794721408, 0.653125, 0.6191732629727352, 0.5927396483267158, 0.7490393142181496, 0.7195475638051044, 0.6782834101382489, 0.5380785002929115, 0.5112960760998811, 0.524841132293472, 0.5238372093023256, 0.5427998854852563]\n",
      "cluster_accuracy_post_training_cycle_all_dataset : [0.96877956 0.9726673  0.96340876 0.95371263 0.72487562 0.5509434\n",
      " 0.63848831 0.59548448 0.75794251 0.72998047 0.69015444 0.66484608\n",
      " 0.55040733 0.53443259 0.52107843 0.53559484]\n",
      "mean_cluster_accuracy_during_training_cycle : 70.21%, post_traincycle_acc : 70.95%, total_acc : 70.65362846%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 77.55%\n",
      "accuracy_check 실행 시간: 32.578초\n",
      "\n",
      "\n",
      "epoch-29 loss : 0.03238039, loss_normal : 0.02091903, loss_coarse : 0.09673099, min_loss : 0.03002502, min_loss_normal : 0.02025351, min_loss_coarse : 0.09396045, wrong_element_sum : 18572350.00000000, same_data : 0.00%\n",
      "ae train 실행 시간: 126.354초, 전체 시작 시간 20250313_235813_378\n",
      "\n",
      "epoch-29 accuracy check\n",
      "k_means origin feature average accuracy : 82.24420826%, total [0.9746727376209448, 0.9733106189664963, 0.9700891573195284, 0.9530800230282096, 0.943108504398827, 0.9150568181818182, 0.8015244796247435, 0.6622234826999432, 0.9488619568430388, 0.822215777262181, 0.5872695852534562, 0.5005858230814294, 0.9429250891795482, 0.8922588099364529, 0.6738372093023256, 0.5980532493558546]\n",
      "kmeans average accuracy best : 78.79%, kmeans average accuracy : 77.11694681%, total [0.9712578258394992, 0.9701873935264055, 0.9459303997699166, 0.9265975820379966, 0.6510263929618768, 0.6338068181818182, 0.5872178246848432, 0.5686330119115145, 0.7853975761158735, 0.7879930394431555, 0.7548963133640553, 0.6490919742237844, 0.8593935790725327, 0.8110918544194108, 0.7473837209302325, 0.6888061837961638]\n",
      "cluster_accuracy_post_training_cycle_all_dataset : [0.97256386 0.97125353 0.94366875 0.93105111 0.74179104 0.68349057\n",
      " 0.63550472 0.52587018 0.78920827 0.79785156 0.63079151 0.65491559\n",
      " 0.85794297 0.77303589 0.73431373 0.68896321]\n",
      "mean_cluster_accuracy_during_training_cycle : 77.18%, post_traincycle_acc : 77.08%, total_acc : 77.11668166%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 77.55%\n",
      "accuracy_check 실행 시간: 28.091초\n",
      "\n",
      "\n",
      "epoch-30 loss : 0.03147478, loss_normal : 0.02069262, loss_coarse : 0.09569217, min_loss : 0.03002502, min_loss_normal : 0.02025351, min_loss_coarse : 0.09396045, wrong_element_sum : 18372898.00000000, same_data : 0.00%\n",
      "ae train 실행 시간: 122.012초, 전체 시작 시간 20250313_235813_378\n",
      "\n",
      "epoch-30 accuracy check\n",
      "k_means origin feature average accuracy : 82.25318692%, total [0.9746727376209448, 0.9733106189664963, 0.9700891573195284, 0.9530800230282096, 0.943108504398827, 0.9150568181818182, 0.801817648783348, 0.6625070901871809, 0.9488619568430388, 0.822215777262181, 0.5866935483870968, 0.5005858230814294, 0.9429250891795482, 0.8922588099364529, 0.6741279069767442, 0.5991983967935872]\n",
      "kmeans average accuracy best : 78.79%, kmeans average accuracy : 77.18358950%, total [0.9701195219123506, 0.9724588302101079, 0.9565717572620075, 0.93811168681635, 0.6876832844574781, 0.6036931818181818, 0.5587804163002053, 0.5598411798071469, 0.8199822642624889, 0.7940835266821346, 0.7430875576036866, 0.6200937316930287, 0.8683115338882283, 0.8203350664355864, 0.7494186046511628, 0.6868021757801317]\n",
      "cluster_accuracy_post_training_cycle_all_dataset : [0.97161779 0.9736098  0.95570534 0.94310511 0.66517413 0.49386792\n",
      " 0.51566385 0.50517404 0.80937973 0.80273438 0.71766409 0.65491559\n",
      " 0.77545825 0.78516004 0.74362745 0.66125179]\n",
      "mean_cluster_accuracy_during_training_cycle : 74.66%, post_traincycle_acc : 74.84%, total_acc : 74.76253671%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 77.55%\n",
      "accuracy_check 실행 시간: 30.119초\n",
      "\n",
      "\n",
      "epoch-31 loss : 0.03127405, loss_normal : 0.02060627, loss_coarse : 0.09512527, min_loss : 0.03002502, min_loss_normal : 0.02025351, min_loss_coarse : 0.09396045, wrong_element_sum : 18264052.00000000, same_data : 0.00%\n",
      "ae train 실행 시간: 102.624초, 전체 시작 시간 20250313_235813_378\n",
      "\n",
      "epoch-31 accuracy check\n",
      "k_means origin feature average accuracy : 82.26034398%, total [0.9746727376209448, 0.9733106189664963, 0.9700891573195284, 0.9530800230282096, 0.943108504398827, 0.9150568181818182, 0.801817648783348, 0.6625070901871809, 0.9488619568430388, 0.822215777262181, 0.5866935483870968, 0.5, 0.9429250891795482, 0.8922588099364529, 0.675, 0.6000572573718866]\n",
      "kmeans average accuracy best : 78.79%, kmeans average accuracy : 71.08412043%, total [0.9704040978941377, 0.9670641680863146, 0.9355766465343687, 0.9162348877374784, 0.6466275659824047, 0.6125, 0.5696276751685723, 0.5450935904707884, 0.542713567839196, 0.564385150812065, 0.567684331797235, 0.5398359695371998, 0.8492865636147443, 0.7819179664933564, 0.7023255813953488, 0.6621815058688806]\n",
      "cluster_accuracy_post_training_cycle_all_dataset : [0.94560076 0.94580584 0.89841117 0.8852459  0.56368159 0.60471698\n",
      " 0.53555445 0.53057385 0.5577408  0.56835938 0.50048263 0.54170804\n",
      " 0.85132383 0.7929195  0.69803922 0.66364071]\n",
      "mean_cluster_accuracy_during_training_cycle : 70.00%, post_traincycle_acc : 69.27%, total_acc : 69.57194721%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 77.55%\n",
      "accuracy_check 실행 시간: 30.487초\n",
      "\n",
      "\n",
      "epoch-32 loss : 0.03117319, loss_normal : 0.02049813, loss_coarse : 0.09471486, min_loss : 0.03002502, min_loss_normal : 0.02025351, min_loss_coarse : 0.09396045, wrong_element_sum : 18185254.00000000, same_data : 0.00%\n",
      "ae train 실행 시간: 121.218초, 전체 시작 시간 20250313_235813_378\n",
      "\n",
      "epoch-32 accuracy check\n",
      "k_means origin feature average accuracy : 82.26030531%, total [0.9746727376209448, 0.9733106189664963, 0.9700891573195284, 0.9530800230282096, 0.943108504398827, 0.915340909090909, 0.801817648783348, 0.6625070901871809, 0.9488619568430388, 0.8216357308584686, 0.5872695852534562, 0.5005858230814294, 0.9429250891795482, 0.8922588099364529, 0.6741279069767442, 0.6000572573718866]\n",
      "kmeans average accuracy best : 78.79%, kmeans average accuracy : 72.32884316%, total [0.9721115537848606, 0.9747302668938104, 0.9649122807017544, 0.9548071387449626, 0.5829912023460411, 0.5096590909090909, 0.4995602462620932, 0.5348837209302325, 0.7354419154596512, 0.6888051044083526, 0.6782834101382489, 0.5843585237258347, 0.8834720570749108, 0.8099364529173888, 0.6401162790697674, 0.5585456627540796]\n",
      "cluster_accuracy_post_training_cycle_all_dataset : [0.97350993 0.97502356 0.96533462 0.95515911 0.59651741 0.49386792\n",
      " 0.50472402 0.50799624 0.72163389 0.70019531 0.6988417  0.65392254\n",
      " 0.87270876 0.81959263 0.69215686 0.54706163]\n",
      "mean_cluster_accuracy_during_training_cycle : 73.01%, post_traincycle_acc : 72.99%, total_acc : 72.99986669%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 77.55%\n",
      "accuracy_check 실행 시간: 28.250초\n",
      "\n",
      "\n",
      "epoch-33 loss : 0.03158562, loss_normal : 0.02065162, loss_coarse : 0.09525566, min_loss : 0.03002502, min_loss_normal : 0.02025351, min_loss_coarse : 0.09396045, wrong_element_sum : 18289088.00000000, same_data : 0.00%\n",
      "ae train 실행 시간: 123.412초, 전체 시작 시간 20250313_235813_378\n",
      "\n",
      "epoch-33 accuracy check\n",
      "k_means origin feature average accuracy : 82.23672699%, total [0.9746727376209448, 0.9733106189664963, 0.9700891573195284, 0.9530800230282096, 0.943108504398827, 0.9150568181818182, 0.7991791263559074, 0.6622234826999432, 0.9488619568430388, 0.822215777262181, 0.5866935483870968, 0.5005858230814294, 0.942627824019025, 0.8922588099364529, 0.675, 0.598912109934154]\n",
      "kmeans average accuracy best : 78.79%, kmeans average accuracy : 70.15639971%, total [0.9698349459305634, 0.9710391822827938, 0.9649122807017544, 0.9556706966033391, 0.5920821114369501, 0.5511363636363636, 0.5021987686895338, 0.524390243902439, 0.8270765592669228, 0.6525522041763341, 0.5728686635944701, 0.6189220855301699, 0.6685493460166468, 0.6504910456383594, 0.625, 0.5782994560549671]\n",
      "cluster_accuracy_post_training_cycle_all_dataset : [0.97114475 0.97125353 0.96533462 0.95323047 0.59800995 0.48207547\n",
      " 0.50671308 0.44073377 0.77962683 0.66943359 0.66891892 0.58440914\n",
      " 0.86558045 0.83802134 0.62009804 0.57142857]\n",
      "mean_cluster_accuracy_during_training_cycle : 72.79%, post_traincycle_acc : 71.79%, total_acc : 72.19260166%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 77.55%\n",
      "accuracy_check 실행 시간: 26.124초\n",
      "\n",
      "\n",
      "epoch-34 loss : 0.03082096, loss_normal : 0.02050140, loss_coarse : 0.09498895, min_loss : 0.03002502, min_loss_normal : 0.02025351, min_loss_coarse : 0.09396045, wrong_element_sum : 18237878.00000000, same_data : 0.00%\n",
      "ae train 실행 시간: 126.280초, 전체 시작 시간 20250313_235813_378\n",
      "\n",
      "epoch-34 accuracy check\n",
      "k_means origin feature average accuracy : 82.26579177%, total [0.9746727376209448, 0.9733106189664963, 0.9700891573195284, 0.9530800230282096, 0.943108504398827, 0.915340909090909, 0.801817648783348, 0.6622234826999432, 0.9488619568430388, 0.822215777262181, 0.5872695852534562, 0.5005858230814294, 0.9429250891795482, 0.8922588099364529, 0.6747093023255814, 0.6000572573718866]\n",
      "kmeans average accuracy best : 78.79%, kmeans average accuracy : 66.97330765%, total [0.9706886738759248, 0.9713231118682567, 0.9666379062410123, 0.9571099597006333, 0.5363636363636364, 0.5232954545454546, 0.5227206097918499, 0.6174134997163925, 0.6367129766479456, 0.6354408352668214, 0.5714285714285714, 0.6080843585237259, 0.7208680142687277, 0.4846909300982091, 0.49767441860465117, 0.495276266819353]\n",
      "cluster_accuracy_post_training_cycle_all_dataset : [0.97114475 0.97078228 0.96533462 0.95612343 0.8318408  0.43254717\n",
      " 0.6414719  0.40122295 0.7730711  0.62158203 0.65685328 0.63455809\n",
      " 0.71639511 0.68671193 0.50441176 0.4605829 ]\n",
      "mean_cluster_accuracy_during_training_cycle : 72.78%, post_traincycle_acc : 70.15%, total_acc : 71.21543248%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 77.55%\n",
      "accuracy_check 실행 시간: 32.945초\n",
      "\n",
      "\n",
      "epoch-35 loss : 0.11921514, loss_normal : 0.04715709, loss_coarse : 0.16382129, min_loss : 0.03002502, min_loss_normal : 0.02025351, min_loss_coarse : 0.09396045, wrong_element_sum : 31453688.00000000, same_data : 0.00%\n",
      "ae train 실행 시간: 112.988초, 전체 시작 시간 20250313_235813_378\n",
      "\n",
      "epoch-35 accuracy check\n",
      "k_means origin feature average accuracy : 82.25491645%, total [0.9746727376209448, 0.9733106189664963, 0.9700891573195284, 0.9530800230282096, 0.943108504398827, 0.9150568181818182, 0.8015244796247435, 0.6622234826999432, 0.9488619568430388, 0.822215777262181, 0.5872695852534562, 0.5005858230814294, 0.9429250891795482, 0.8922588099364529, 0.673546511627907, 0.6000572573718866]\n",
      "kmeans average accuracy best : 78.79%, kmeans average accuracy : 34.22488434%, total [0.3392145702902675, 0.35122089721749006, 0.34167385677308026, 0.34484743811168683, 0.34222873900293255, 0.34488636363636366, 0.346232776311932, 0.3369256948383437, 0.3414129470883831, 0.3375870069605568, 0.33755760368663595, 0.3453427065026362, 0.3373959571938169, 0.34286539572501445, 0.3444767441860465, 0.34211279702261665]\n",
      "cluster_accuracy_post_training_cycle_all_dataset : [0.33491012 0.36050895 0.35146846 0.32594021 0.33930348 0.3254717\n",
      " 0.32521134 0.3565381  0.3419062  0.32080078 0.33349421 0.3326713\n",
      " 0.33757637 0.33899127 0.33970588 0.35260392]\n",
      "mean_cluster_accuracy_during_training_cycle : 34.60%, post_traincycle_acc : 33.86%, total_acc : 34.15835831%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 77.55%\n",
      "accuracy_check 실행 시간: 158.172초\n",
      "\n",
      "\n",
      "epoch-36 loss : 0.13533414, loss_normal : 0.05192709, loss_coarse : 0.17685014, min_loss : 0.03002502, min_loss_normal : 0.02025351, min_loss_coarse : 0.09396045, wrong_element_sum : 33955228.00000000, same_data : 0.00%\n",
      "ae train 실행 시간: 123.073초, 전체 시작 시간 20250313_235813_378\n",
      "\n",
      "epoch-36 accuracy check\n",
      "k_means origin feature average accuracy : 82.60574950%, total [0.9746727376209448, 0.9733106189664963, 0.9700891573195284, 0.9530800230282096, 0.943108504398827, 0.9150568181818182, 0.801817648783348, 0.6622234826999432, 0.9488619568430388, 0.822215777262181, 0.5866935483870968, 0.5005858230814294, 0.9429250891795482, 0.8922588099364529, 0.6747093023255814, 0.655310621242485]\n",
      "kmeans average accuracy best : 78.79%, kmeans average accuracy : 34.22488434%, total [0.3392145702902675, 0.35122089721749006, 0.34167385677308026, 0.34484743811168683, 0.34222873900293255, 0.34488636363636366, 0.346232776311932, 0.3369256948383437, 0.3414129470883831, 0.3375870069605568, 0.33755760368663595, 0.3453427065026362, 0.3373959571938169, 0.34286539572501445, 0.3444767441860465, 0.34211279702261665]\n",
      "cluster_accuracy_post_training_cycle_all_dataset : [0.33491012 0.36050895 0.35146846 0.32594021 0.33930348 0.3254717\n",
      " 0.32521134 0.3565381  0.3419062  0.32080078 0.33349421 0.3326713\n",
      " 0.33757637 0.33899127 0.33970588 0.35260392]\n",
      "mean_cluster_accuracy_during_training_cycle : 34.60%, post_traincycle_acc : 33.86%, total_acc : 34.15835831%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 77.55%\n",
      "accuracy_check 실행 시간: 157.970초\n",
      "\n",
      "\n",
      "epoch-37 loss : 0.12006304, loss_normal : 0.04791884, loss_coarse : 0.16741749, min_loss : 0.03002502, min_loss_normal : 0.02025351, min_loss_coarse : 0.09396045, wrong_element_sum : 32144158.00000000, same_data : 0.00%\n",
      "ae train 실행 시간: 121.441초, 전체 시작 시간 20250313_235813_378\n",
      "\n",
      "epoch-37 accuracy check\n",
      "k_means origin feature average accuracy : 82.24592791%, total [0.9746727376209448, 0.9733106189664963, 0.9700891573195284, 0.9530800230282096, 0.943108504398827, 0.9150568181818182, 0.801817648783348, 0.6625070901871809, 0.9488619568430388, 0.8216357308584686, 0.5866935483870968, 0.5005858230814294, 0.9429250891795482, 0.8922588099364529, 0.673546511627907, 0.5991983967935872]\n",
      "kmeans average accuracy best : 78.79%, kmeans average accuracy : 69.98934335%, total [0.8955606146841206, 0.8952299829642248, 0.8656888121944205, 0.8537708693149108, 0.7126099706744868, 0.5991477272727272, 0.5379654060392847, 0.4895065229722065, 0.6976056754360035, 0.6850348027842227, 0.6535138248847926, 0.6487990626830697, 0.7589179548156956, 0.6932409012131716, 0.6127906976744186, 0.598912109934154]\n",
      "cluster_accuracy_post_training_cycle_all_dataset : [0.88694418 0.90150801 0.86567164 0.85776278 0.70099502 0.58396226\n",
      " 0.52610641 0.4261524  0.70095814 0.69824219 0.51351351 0.66087388\n",
      " 0.65682281 0.65276431 0.53431373 0.58862876]\n",
      "mean_cluster_accuracy_during_training_cycle : 67.65%, post_traincycle_acc : 67.22%, total_acc : 67.39268311%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 77.55%\n",
      "accuracy_check 실행 시간: 55.637초\n",
      "\n",
      "\n",
      "epoch-38 loss : 0.04419595, loss_normal : 0.02432039, loss_coarse : 0.10845002, min_loss : 0.03002502, min_loss_normal : 0.02025351, min_loss_coarse : 0.09396045, wrong_element_sum : 20822404.00000000, same_data : 0.00%\n",
      "ae train 실행 시간: 122.411초, 전체 시작 시간 20250313_235813_378\n",
      "\n",
      "epoch-38 accuracy check\n",
      "k_means origin feature average accuracy : 82.24955320%, total [0.9746727376209448, 0.9733106189664963, 0.9700891573195284, 0.9530800230282096, 0.943108504398827, 0.9150568181818182, 0.801817648783348, 0.6625070901871809, 0.9488619568430388, 0.822215777262181, 0.5866935483870968, 0.5005858230814294, 0.9429250891795482, 0.8922588099364529, 0.673546511627907, 0.5991983967935872]\n",
      "kmeans average accuracy best : 78.79%, kmeans average accuracy : 74.23700439%, total [0.9675583380762663, 0.9659284497444633, 0.9373022720736267, 0.9093264248704663, 0.7501466275659824, 0.6667613636363636, 0.5965992377601876, 0.5238230289279637, 0.6905113804315696, 0.6780742459396751, 0.6728110599078341, 0.6508494434680726, 0.7990487514863258, 0.7590987868284229, 0.6813953488372093, 0.6286859433152018]\n",
      "cluster_accuracy_post_training_cycle_all_dataset : [0.96877956 0.966541   0.93355802 0.90549662 0.79303483 0.66415094\n",
      " 0.59671805 0.47412982 0.69541099 0.67822266 0.67181467 0.61618669\n",
      " 0.71334012 0.63336566 0.5872549  0.53607262]\n",
      "mean_cluster_accuracy_during_training_cycle : 71.46%, post_traincycle_acc : 71.46%, total_acc : 71.45780602%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 77.55%\n",
      "accuracy_check 실행 시간: 39.042초\n",
      "\n",
      "\n",
      "epoch-39 loss : 0.04032587, loss_normal : 0.02304043, loss_coarse : 0.10446462, min_loss : 0.03002502, min_loss_normal : 0.02025351, min_loss_coarse : 0.09396045, wrong_element_sum : 20057208.00000000, same_data : 0.00%\n",
      "ae train 실행 시간: 125.361초, 전체 시작 시간 20250313_235813_378\n",
      "\n",
      "epoch-39 accuracy check\n",
      "k_means origin feature average accuracy : 82.24241528%, total [0.9746727376209448, 0.9733106189664963, 0.9700891573195284, 0.9530800230282096, 0.943108504398827, 0.9150568181818182, 0.801817648783348, 0.6622234826999432, 0.9488619568430388, 0.8216357308584686, 0.5872695852534562, 0.5005858230814294, 0.9429250891795482, 0.8922588099364529, 0.6738372093023256, 0.5980532493558546]\n",
      "kmeans average accuracy best : 78.79%, kmeans average accuracy : 74.24423881%, total [0.9655663062037564, 0.9687677455990914, 0.9522576934138626, 0.9271732872769142, 0.7554252199413489, 0.6417613636363636, 0.5769569041336852, 0.5425411230856495, 0.6911025716819391, 0.6861948955916474, 0.6725230414746544, 0.6309314586994728, 0.8243162901307967, 0.7299248989023686, 0.6703488372093023, 0.6432865731462926]\n",
      "cluster_accuracy_post_training_cycle_all_dataset : [0.96688742 0.96795476 0.95185364 0.92719383 0.69353234 0.56698113\n",
      " 0.5305818  0.48871119 0.70146243 0.68603516 0.64044402 0.60278054\n",
      " 0.82077393 0.73326867 0.67941176 0.49307215]\n",
      "mean_cluster_accuracy_during_training_cycle : 72.29%, post_traincycle_acc : 71.57%, total_acc : 71.85431547%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 77.55%\n",
      "accuracy_check 실행 시간: 27.872초\n",
      "\n",
      "\n",
      "epoch-40 loss : 0.03934271, loss_normal : 0.02280926, loss_coarse : 0.10381052, min_loss : 0.03002502, min_loss_normal : 0.02025351, min_loss_coarse : 0.09396045, wrong_element_sum : 19931620.00000000, same_data : 0.00%\n",
      "ae train 실행 시간: 126.003초, 전체 시작 시간 20250313_235813_378\n",
      "\n",
      "epoch-40 accuracy check\n",
      "k_means origin feature average accuracy : 82.26219154%, total [0.9746727376209448, 0.9733106189664963, 0.9700891573195284, 0.9530800230282096, 0.943108504398827, 0.915340909090909, 0.801817648783348, 0.6622234826999432, 0.9488619568430388, 0.822215777262181, 0.5866935483870968, 0.5005858230814294, 0.9429250891795482, 0.8922588099364529, 0.6747093023255814, 0.6000572573718866]\n",
      "kmeans average accuracy best : 78.79%, kmeans average accuracy : 76.26370544%, total [0.9618668184405236, 0.9619534355479841, 0.9404659188955996, 0.9156591824985607, 0.8516129032258064, 0.7525568181818182, 0.6484901788331867, 0.5317640385706183, 0.7112030741945019, 0.7096867749419954, 0.701036866359447, 0.666373755125952, 0.807372175980975, 0.7313691507798961, 0.6898255813953489, 0.6209561981105067]\n",
      "cluster_accuracy_post_training_cycle_all_dataset : [0.96310312 0.9604147  0.94463168 0.92140791 0.85820896 0.75518868\n",
      " 0.60865241 0.53857008 0.70852244 0.71777344 0.70028958 0.66832175\n",
      " 0.67311609 0.59408341 0.57303922 0.52173913]\n",
      "mean_cluster_accuracy_during_training_cycle : 73.77%, post_traincycle_acc : 73.17%, total_acc : 73.41651345%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 77.55%\n",
      "accuracy_check 실행 시간: 37.783초\n",
      "\n",
      "\n",
      "epoch-41 loss : 0.03760696, loss_normal : 0.02216726, loss_coarse : 0.10183663, min_loss : 0.03002502, min_loss_normal : 0.02025351, min_loss_coarse : 0.09396045, wrong_element_sum : 19552634.00000000, same_data : 0.00%\n",
      "ae train 실행 시간: 126.053초, 전체 시작 시간 20250313_235813_378\n",
      "\n",
      "epoch-41 accuracy check\n",
      "k_means origin feature average accuracy : 82.26223283%, total [0.9746727376209448, 0.9733106189664963, 0.9700891573195284, 0.9530800230282096, 0.943108504398827, 0.9150568181818182, 0.801817648783348, 0.6622234826999432, 0.9488619568430388, 0.822215777262181, 0.5866935483870968, 0.5005858230814294, 0.9429250891795482, 0.8922588099364529, 0.675, 0.6000572573718866]\n",
      "kmeans average accuracy best : 78.79%, kmeans average accuracy : 77.05595274%, total [0.9698349459305634, 0.9704713231118682, 0.9574345700316365, 0.9343696027633851, 0.7686217008797654, 0.6571022727272727, 0.6309000293169159, 0.5629608621667612, 0.7620455217262785, 0.7607308584686775, 0.7211981566820277, 0.6959578207381371, 0.8561236623067776, 0.7741190063547082, 0.6912790697674419, 0.61580303464071]\n",
      "cluster_accuracy_post_training_cycle_all_dataset : [0.96972564 0.97125353 0.96003852 0.93442623 0.79054726 0.69150943\n",
      " 0.61810045 0.49670743 0.76399395 0.76416016 0.71766409 0.67229394\n",
      " 0.84114053 0.75412221 0.69705882 0.60009556]\n",
      "mean_cluster_accuracy_during_training_cycle : 76.42%, post_traincycle_acc : 76.52%, total_acc : 76.47378561%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 77.55%\n",
      "accuracy_check 실행 시간: 29.661초\n",
      "\n",
      "\n",
      "epoch-42 loss : 0.03705936, loss_normal : 0.02197163, loss_coarse : 0.10130397, min_loss : 0.03002502, min_loss_normal : 0.02025351, min_loss_coarse : 0.09396045, wrong_element_sum : 19450362.00000000, same_data : 0.00%\n",
      "ae train 실행 시간: 123.121초, 전체 시작 시간 20250313_235813_378\n",
      "\n",
      "epoch-42 accuracy check\n",
      "k_means origin feature average accuracy : 82.25318100%, total [0.9746727376209448, 0.9733106189664963, 0.9700891573195284, 0.9530800230282096, 0.943108504398827, 0.9150568181818182, 0.801817648783348, 0.6625070901871809, 0.9488619568430388, 0.822215777262181, 0.5872695852534562, 0.5005858230814294, 0.9429250891795482, 0.8922588099364529, 0.6738372093023256, 0.598912109934154]\n",
      "kmeans average accuracy best : 78.79%, kmeans average accuracy : 75.62995230%, total [0.9689812179852021, 0.9724588302101079, 0.9585849870578085, 0.9317789291882557, 0.7826979472140763, 0.6892045454545455, 0.6358839050131926, 0.5743051616562678, 0.7709133904818208, 0.7737819025522041, 0.6699308755760369, 0.6933216168717048, 0.7672413793103449, 0.7059503177354131, 0.6360465116279069, 0.5697108502719725]\n",
      "cluster_accuracy_post_training_cycle_all_dataset : [0.97019868 0.97172479 0.96100144 0.93539055 0.74427861 0.6504717\n",
      " 0.64644455 0.54562559 0.76399395 0.77148438 0.6476834  0.65590864\n",
      " 0.76832994 0.71047527 0.64215686 0.56903966]\n",
      "mean_cluster_accuracy_during_training_cycle : 75.15%, post_traincycle_acc : 74.71%, total_acc : 74.88869946%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 77.55%\n",
      "accuracy_check 실행 시간: 36.372초\n",
      "\n",
      "\n",
      "epoch-43 loss : 0.03517216, loss_normal : 0.02138385, loss_coarse : 0.09897130, min_loss : 0.03002502, min_loss_normal : 0.02025351, min_loss_coarse : 0.09396045, wrong_element_sum : 19002490.00000000, same_data : 0.00%\n",
      "ae train 실행 시간: 123.272초, 전체 시작 시간 20250313_235813_378\n",
      "\n",
      "epoch-43 accuracy check\n",
      "k_means origin feature average accuracy : 82.24231664%, total [0.9746727376209448, 0.9733106189664963, 0.9700891573195284, 0.9530800230282096, 0.943108504398827, 0.9150568181818182, 0.801817648783348, 0.6622234826999432, 0.9488619568430388, 0.822215777262181, 0.5866935483870968, 0.5005858230814294, 0.9429250891795482, 0.89052570768342, 0.673546511627907, 0.6000572573718866]\n",
      "kmeans average accuracy best : 78.79%, kmeans average accuracy : 77.40407483%, total [0.9667046101309049, 0.9704713231118682, 0.9442047742306586, 0.918825561312608, 0.8428152492668621, 0.7184659090909091, 0.6226912928759895, 0.5635280771412365, 0.859592078037245, 0.8245359628770301, 0.6751152073732719, 0.726713532513181, 0.8043995243757431, 0.7255921432697863, 0.640406976744186, 0.5805897509304323]\n",
      "cluster_accuracy_post_training_cycle_all_dataset : [0.96877956 0.9726673  0.94318729 0.93394407 0.67014925 0.63113208\n",
      " 0.61362506 0.54609595 0.8587998  0.82568359 0.67519305 0.65839126\n",
      " 0.81059063 0.72987391 0.64656863 0.5733397 ]\n",
      "mean_cluster_accuracy_during_training_cycle : 76.39%, post_traincycle_acc : 75.36%, total_acc : 75.77645589%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 77.55%\n",
      "accuracy_check 실행 시간: 33.271초\n",
      "\n",
      "\n",
      "epoch-44 loss : 0.03465804, loss_normal : 0.02129027, loss_coarse : 0.09865421, min_loss : 0.03002502, min_loss_normal : 0.02025351, min_loss_coarse : 0.09396045, wrong_element_sum : 18941608.00000000, same_data : 0.00%\n",
      "ae train 실행 시간: 123.251초, 전체 시작 시간 20250313_235813_378\n",
      "\n",
      "epoch-44 accuracy check\n",
      "k_means origin feature average accuracy : 82.26041597%, total [0.9746727376209448, 0.9733106189664963, 0.9700891573195284, 0.9530800230282096, 0.943108504398827, 0.9150568181818182, 0.801817648783348, 0.6622234826999432, 0.9488619568430388, 0.822215777262181, 0.5866935483870968, 0.5005858230814294, 0.9429250891795482, 0.8922588099364529, 0.6747093023255814, 0.6000572573718866]\n",
      "kmeans average accuracy best : 78.79%, kmeans average accuracy : 77.52933404%, total [0.9692657939669892, 0.9662123793299262, 0.9462180040264596, 0.9176741508347726, 0.750733137829912, 0.6900568181818182, 0.6490765171503958, 0.5720363017583664, 0.8891516405557198, 0.8503480278422274, 0.7632488479262672, 0.6763327475102519, 0.8504756242568371, 0.7475447718082033, 0.5651162790697675, 0.6012024048096193]\n",
      "cluster_accuracy_post_training_cycle_all_dataset : [0.96877956 0.96936852 0.95089071 0.92333655 0.75970149 0.69481132\n",
      " 0.62655395 0.52069614 0.81593545 0.79589844 0.60328185 0.62065541\n",
      " 0.86761711 0.77449079 0.6004902  0.49976111]\n",
      "mean_cluster_accuracy_during_training_cycle : 75.88%, post_traincycle_acc : 74.95%, total_acc : 75.32605179%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 77.55%\n",
      "accuracy_check 실행 시간: 27.797초\n",
      "\n",
      "\n",
      "epoch-45 loss : 0.03443275, loss_normal : 0.02118278, loss_coarse : 0.09832886, min_loss : 0.03002502, min_loss_normal : 0.02025351, min_loss_coarse : 0.09396045, wrong_element_sum : 18879142.00000000, same_data : 0.00%\n",
      "ae train 실행 시간: 123.636초, 전체 시작 시간 20250313_235813_378\n",
      "\n",
      "epoch-45 accuracy check\n",
      "k_means origin feature average accuracy : 82.24775559%, total [0.9746727376209448, 0.9733106189664963, 0.9700891573195284, 0.9530800230282096, 0.943108504398827, 0.9150568181818182, 0.801817648783348, 0.6622234826999432, 0.9488619568430388, 0.8216357308584686, 0.5872695852534562, 0.5005858230814294, 0.9429250891795482, 0.8922588099364529, 0.673546511627907, 0.5991983967935872]\n",
      "kmeans average accuracy best : 78.79%, kmeans average accuracy : 78.16135278%, total [0.9658508821855435, 0.9721749006246451, 0.9548461317227495, 0.9251583189407023, 0.7407624633431085, 0.6823863636363636, 0.6267956610964527, 0.5618264322178106, 0.8477682530298551, 0.8111948955916474, 0.7430875576036866, 0.6862917398945518, 0.8989298454221165, 0.7876949740034662, 0.6898255813953489, 0.6112224448897795]\n",
      "cluster_accuracy_post_training_cycle_all_dataset : [0.96641438 0.97172479 0.9523351  0.92237223 0.7        0.72688679\n",
      " 0.60268523 0.55174036 0.85476551 0.81152344 0.64527027 0.60724926\n",
      " 0.90631365 0.80213385 0.69705882 0.61251792]\n",
      "mean_cluster_accuracy_during_training_cycle : 77.25%, post_traincycle_acc : 77.07%, total_acc : 77.14530549%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 77.55%\n",
      "accuracy_check 실행 시간: 31.713초\n",
      "\n",
      "\n",
      "epoch-46 loss : 0.03346410, loss_normal : 0.02089740, loss_coarse : 0.09727406, min_loss : 0.03002502, min_loss_normal : 0.02025351, min_loss_coarse : 0.09396045, wrong_element_sum : 18676620.00000000, same_data : 0.00%\n",
      "ae train 실행 시간: 124.054초, 전체 시작 시간 20250313_235813_378\n",
      "\n",
      "epoch-46 accuracy check\n",
      "k_means origin feature average accuracy : 82.24422963%, total [0.9746727376209448, 0.9733106189664963, 0.9700891573195284, 0.9530800230282096, 0.943108504398827, 0.9150568181818182, 0.801817648783348, 0.6622234826999432, 0.9488619568430388, 0.822215777262181, 0.5866935483870968, 0.5005858230814294, 0.9429250891795482, 0.8922588099364529, 0.6738372093023256, 0.5983395362152877]\n",
      "save model\n",
      "kmeans average accuracy best : 79.57%, kmeans average accuracy : 79.57187800%, total [0.9686966420034149, 0.9718909710391823, 0.9548461317227495, 0.9326424870466321, 0.7255131964809384, 0.6789772727272727, 0.6361770741717971, 0.5870674985819626, 0.9012710611882944, 0.8604988399071926, 0.7842741935483871, 0.710896309314587, 0.8959571938168847, 0.8018486424032352, 0.6991279069767442, 0.6218150586888062]\n",
      "cluster_accuracy_post_training_cycle_all_dataset : [0.96972564 0.97078228 0.95426095 0.93249759 0.7159204  0.67028302\n",
      " 0.61859771 0.57619944 0.89460414 0.85742188 0.68918919 0.6693148\n",
      " 0.901222   0.8128031  0.70588235 0.61634018]\n",
      "mean_cluster_accuracy_during_training_cycle : 78.36%, post_traincycle_acc : 78.47%, total_acc : 78.42355843%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 78.47%\n",
      "accuracy_check 실행 시간: 37.151초\n",
      "\n",
      "\n",
      "epoch-47 loss : 0.03345402, loss_normal : 0.02093233, loss_coarse : 0.09713779, min_loss : 0.03002502, min_loss_normal : 0.02025351, min_loss_coarse : 0.09396045, wrong_element_sum : 18650456.00000000, same_data : 0.00%\n",
      "ae train 실행 시간: 124.396초, 전체 시작 시간 20250313_235813_378\n",
      "\n",
      "epoch-47 accuracy check\n",
      "k_means origin feature average accuracy : 82.25321579%, total [0.9746727376209448, 0.9733106189664963, 0.9700891573195284, 0.9530800230282096, 0.943108504398827, 0.9150568181818182, 0.8015244796247435, 0.6622234826999432, 0.9488619568430388, 0.822215777262181, 0.5866935483870968, 0.5005858230814294, 0.9429250891795482, 0.8922588099364529, 0.6747093023255814, 0.5991983967935872]\n",
      "kmeans average accuracy best : 79.57%, kmeans average accuracy : 78.65198453%, total [0.9675583380762663, 0.9724588302101079, 0.9490940465918896, 0.9231433506044905, 0.8096774193548387, 0.6644886363636363, 0.6473175021987687, 0.5768576290414067, 0.9228495418267809, 0.8744199535962877, 0.7096774193548387, 0.7067955477445811, 0.85820451843044, 0.7452339688041595, 0.6622093023255814, 0.5943315201832235]\n",
      "cluster_accuracy_post_training_cycle_all_dataset : [0.96736045 0.97172479 0.94944632 0.92622951 0.67462687 0.66839623\n",
      " 0.65241174 0.56585136 0.84467978 0.80517578 0.75434363 0.68867925\n",
      " 0.86303462 0.75848691 0.66617647 0.58576206]\n",
      "mean_cluster_accuracy_during_training_cycle : 76.67%, post_traincycle_acc : 77.14%, total_acc : 76.94560189%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 78.47%\n",
      "accuracy_check 실행 시간: 30.654초\n",
      "\n",
      "\n",
      "epoch-48 loss : 0.03337655, loss_normal : 0.02098199, loss_coarse : 0.09733432, min_loss : 0.03002502, min_loss_normal : 0.02025351, min_loss_coarse : 0.09396045, wrong_element_sum : 18688190.00000000, same_data : 0.00%\n",
      "ae train 실행 시간: 121.188초, 전체 시작 시간 20250313_235813_378\n",
      "\n",
      "epoch-48 accuracy check\n",
      "k_means origin feature average accuracy : 82.26393060%, total [0.9746727376209448, 0.9733106189664963, 0.9700891573195284, 0.9530800230282096, 0.943108504398827, 0.915340909090909, 0.801817648783348, 0.6625070901871809, 0.9488619568430388, 0.822215777262181, 0.5872695852534562, 0.5005858230814294, 0.9429250891795482, 0.8922588099364529, 0.6741279069767442, 0.6000572573718866]\n",
      "kmeans average accuracy best : 79.57%, kmeans average accuracy : 76.44957954%, total [0.9689812179852021, 0.9724588302101079, 0.9502444636180616, 0.92573402417962, 0.749266862170088, 0.6482954545454546, 0.6112576956904133, 0.5680657969370392, 0.8329884717706177, 0.8181554524361949, 0.7407834101382489, 0.6338605741066198, 0.8379904875148633, 0.7411900635470826, 0.6543604651162791, 0.5782994560549671]\n",
      "cluster_accuracy_post_training_cycle_all_dataset : [0.97067171 0.97313855 0.94896485 0.93297975 0.60348259 0.62122642\n",
      " 0.61213327 0.55738476 0.82450832 0.79492188 0.65202703 0.632572\n",
      " 0.8401222  0.74636275 0.65833333 0.5762064 ]\n",
      "mean_cluster_accuracy_during_training_cycle : 75.13%, post_traincycle_acc : 74.66%, total_acc : 74.84625863%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 78.47%\n",
      "accuracy_check 실행 시간: 26.118초\n",
      "\n",
      "\n",
      "epoch-49 loss : 0.03394905, loss_normal : 0.02118322, loss_coarse : 0.09789879, min_loss : 0.03002502, min_loss_normal : 0.02025351, min_loss_coarse : 0.09396045, wrong_element_sum : 18796568.00000000, same_data : 0.00%\n",
      "ae train 실행 시간: 119.536초, 전체 시작 시간 20250313_235813_378\n",
      "\n",
      "epoch-49 accuracy check\n",
      "k_means origin feature average accuracy : 82.26209499%, total [0.9746727376209448, 0.9733106189664963, 0.9700891573195284, 0.9530800230282096, 0.943108504398827, 0.9150568181818182, 0.801817648783348, 0.6622234826999432, 0.9488619568430388, 0.822215777262181, 0.5866935483870968, 0.5005858230814294, 0.9429250891795482, 0.8922588099364529, 0.673546511627907, 0.6014886916690524]\n",
      "kmeans average accuracy best : 79.57%, kmeans average accuracy : 76.55795058%, total [0.9672737620944792, 0.9710391822827938, 0.9539833189531205, 0.9251583189407023, 0.7607038123167156, 0.6571022727272727, 0.6136030489592494, 0.5689166193987522, 0.8909252143068283, 0.8291763341067285, 0.7367511520737328, 0.679261862917399, 0.7645659928656362, 0.6848642403235125, 0.6055232558139535, 0.6404237045519611]\n",
      "cluster_accuracy_post_training_cycle_all_dataset : [0.96783349 0.97219604 0.95474242 0.92237223 0.7641791  0.60990566\n",
      " 0.59522626 0.54468485 0.81442259 0.79492188 0.65540541 0.63803376\n",
      " 0.8604888  0.7929195  0.61421569 0.63879599]\n",
      "mean_cluster_accuracy_during_training_cycle : 76.20%, post_traincycle_acc : 75.88%, total_acc : 76.00463086%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 78.47%\n",
      "accuracy_check 실행 시간: 32.797초\n",
      "\n",
      "\n",
      "epoch-50 loss : 0.03277906, loss_normal : 0.02090859, loss_coarse : 0.09693130, min_loss : 0.03002502, min_loss_normal : 0.02025351, min_loss_coarse : 0.09396045, wrong_element_sum : 18610810.00000000, same_data : 0.00%\n",
      "ae train 실행 시간: 123.913초, 전체 시작 시간 20250313_235813_378\n",
      "\n",
      "epoch-50 accuracy check\n",
      "k_means origin feature average accuracy : 82.24418532%, total [0.9746727376209448, 0.9733106189664963, 0.9700891573195284, 0.9530800230282096, 0.943108504398827, 0.9150568181818182, 0.801817648783348, 0.6625070901871809, 0.9488619568430388, 0.822215777262181, 0.5866935483870968, 0.5005858230814294, 0.9429250891795482, 0.8922588099364529, 0.673546511627907, 0.5983395362152877]\n",
      "kmeans average accuracy best : 79.57%, kmeans average accuracy : 76.69957284%, total [0.9684120660216278, 0.9718909710391823, 0.9559965487489215, 0.9309153713298791, 0.7378299120234604, 0.6769886363636364, 0.6226912928759895, 0.5442427680090755, 0.8146615430091635, 0.7801624129930395, 0.7445276497695853, 0.6953719976567077, 0.7824019024970273, 0.7056614673599075, 0.7026162790697674, 0.6375608359576296]\n",
      "cluster_accuracy_post_training_cycle_all_dataset : [0.96877956 0.96182846 0.94366875 0.91417551 0.73532338 0.67783019\n",
      " 0.64594729 0.53998119 0.80635401 0.77294922 0.73310811 0.68619662\n",
      " 0.78615071 0.76721629 0.62254902 0.54132824]\n",
      "mean_cluster_accuracy_during_training_cycle : 75.17%, post_traincycle_acc : 75.65%, total_acc : 75.44840557%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 78.47%\n",
      "accuracy_check 실행 시간: 30.403초\n",
      "\n",
      "\n",
      "epoch-51 loss : 0.03154816, loss_normal : 0.02052974, loss_coarse : 0.09544181, min_loss : 0.03002502, min_loss_normal : 0.02025351, min_loss_coarse : 0.09396045, wrong_element_sum : 18324828.00000000, same_data : 0.00%\n",
      "ae train 실행 시간: 124.745초, 전체 시작 시간 20250313_235813_378\n",
      "\n",
      "epoch-51 accuracy check\n",
      "k_means origin feature average accuracy : 82.26223283%, total [0.9746727376209448, 0.9733106189664963, 0.9700891573195284, 0.9530800230282096, 0.943108504398827, 0.9150568181818182, 0.801817648783348, 0.6622234826999432, 0.9488619568430388, 0.822215777262181, 0.5866935483870968, 0.5005858230814294, 0.9429250891795482, 0.8922588099364529, 0.675, 0.6000572573718866]\n",
      "kmeans average accuracy best : 79.57%, kmeans average accuracy : 76.86161901%, total [0.9695503699487763, 0.9721749006246451, 0.9568593615185504, 0.9326424870466321, 0.6592375366568914, 0.6659090909090909, 0.624743476986221, 0.5748723766307431, 0.8566361217853976, 0.8152552204176334, 0.7606566820276498, 0.7026947861745753, 0.8543400713436385, 0.7417677642980935, 0.6479651162790697, 0.5625536787861437]\n",
      "cluster_accuracy_post_training_cycle_all_dataset : [0.97067171 0.96512724 0.94752046 0.91851495 0.63283582 0.63301887\n",
      " 0.62555942 0.56161806 0.82955119 0.80175781 0.76013514 0.6817279\n",
      " 0.85641548 0.75169738 0.65539216 0.55566173]\n",
      "mean_cluster_accuracy_during_training_cycle : 75.96%, post_traincycle_acc : 75.92%, total_acc : 75.93552481%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 78.47%\n",
      "accuracy_check 실행 시간: 32.764초\n",
      "\n",
      "\n",
      "epoch-52 loss : 0.03135650, loss_normal : 0.02051332, loss_coarse : 0.09525027, min_loss : 0.03002502, min_loss_normal : 0.02025351, min_loss_coarse : 0.09396045, wrong_element_sum : 18288052.00000000, same_data : 0.00%\n",
      "ae train 실행 시간: 126.110초, 전체 시작 시간 20250313_235813_378\n",
      "\n",
      "epoch-52 accuracy check\n",
      "k_means origin feature average accuracy : 82.25860993%, total [0.9746727376209448, 0.9733106189664963, 0.9700891573195284, 0.9530800230282096, 0.943108504398827, 0.9150568181818182, 0.801817648783348, 0.6625070901871809, 0.9488619568430388, 0.822215777262181, 0.5866935483870968, 0.5005858230814294, 0.9429250891795482, 0.8922588099364529, 0.6747093023255814, 0.5994846836530203]\n",
      "kmeans average accuracy best : 79.57%, kmeans average accuracy : 64.43463378%, total [0.78628343767786, 0.7385008517887564, 0.7382801265458728, 0.717328727691422, 0.7187683284457478, 0.6761363636363636, 0.6162415713866901, 0.5692002268859898, 0.5702039609813775, 0.5809164733178654, 0.6143433179723502, 0.6060339777387229, 0.6516052318668252, 0.6175621028307337, 0.5796511627906977, 0.5284855425135986]\n",
      "cluster_accuracy_post_training_cycle_all_dataset : [0.74692526 0.73656927 0.71545498 0.69527483 0.72189055 0.67924528\n",
      " 0.61412233 0.54891816 0.57589511 0.58642578 0.61583012 0.61122145\n",
      " 0.66344196 0.51309408 0.43137255 0.42140468]\n",
      "mean_cluster_accuracy_during_training_cycle : 61.30%, post_traincycle_acc : 61.73%, total_acc : 61.55641075%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 78.47%\n",
      "accuracy_check 실행 시간: 53.594초\n",
      "\n",
      "\n",
      "epoch-53 loss : 0.03627748, loss_normal : 0.02202526, loss_coarse : 0.10063702, min_loss : 0.03002502, min_loss_normal : 0.02025351, min_loss_coarse : 0.09396045, wrong_element_sum : 19322308.00000000, same_data : 0.00%\n",
      "ae train 실행 시간: 125.465초, 전체 시작 시간 20250313_235813_378\n",
      "\n",
      "epoch-53 accuracy check\n",
      "k_means origin feature average accuracy : 82.26034119%, total [0.9746727376209448, 0.9733106189664963, 0.9700891573195284, 0.9530800230282096, 0.943108504398827, 0.915340909090909, 0.801817648783348, 0.6622234826999432, 0.9488619568430388, 0.822215777262181, 0.5872695852534562, 0.5005858230814294, 0.9429250891795482, 0.8922588099364529, 0.6738372093023256, 0.6000572573718866]\n",
      "kmeans average accuracy best : 79.57%, kmeans average accuracy : 76.97305458%, total [0.9632896983494593, 0.9622373651334469, 0.9309749784296808, 0.9052964881980426, 0.7812316715542522, 0.75625, 0.6953972442099091, 0.49886557005104937, 0.7561336092225835, 0.7137470997679815, 0.6526497695852534, 0.6224370240187463, 0.8451248513674198, 0.8128249566724437, 0.7427325581395349, 0.6764958488405383]\n",
      "cluster_accuracy_post_training_cycle_all_dataset : [0.96546831 0.95852969 0.92007703 0.90646095 0.78109453 0.72169811\n",
      " 0.54748881 0.59031044 0.75895108 0.71777344 0.55888031 0.62164846\n",
      " 0.84164969 0.82347236 0.74411765 0.66507406]\n",
      "mean_cluster_accuracy_during_training_cycle : 75.93%, post_traincycle_acc : 75.77%, total_acc : 75.83105270%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 78.47%\n",
      "accuracy_check 실행 시간: 39.005초\n",
      "\n",
      "\n",
      "epoch-54 loss : 0.03231581, loss_normal : 0.02084792, loss_coarse : 0.09649562, min_loss : 0.03002502, min_loss_normal : 0.02025351, min_loss_coarse : 0.09396045, wrong_element_sum : 18527160.00000000, same_data : 0.00%\n",
      "ae train 실행 시간: 125.118초, 전체 시작 시간 20250313_235813_378\n",
      "\n",
      "epoch-54 accuracy check\n",
      "k_means origin feature average accuracy : 82.24232846%, total [0.9746727376209448, 0.9733106189664963, 0.9700891573195284, 0.9530800230282096, 0.943108504398827, 0.915340909090909, 0.8015244796247435, 0.6625070901871809, 0.9488619568430388, 0.822215777262181, 0.586405529953917, 0.5005858230814294, 0.9429250891795482, 0.8922588099364529, 0.673546511627907, 0.5983395362152877]\n",
      "kmeans average accuracy best : 79.57%, kmeans average accuracy : 77.63153277%, total [0.9692657939669892, 0.9701873935264055, 0.9548461317227495, 0.9202648244099021, 0.6510263929618768, 0.6625, 0.6341248900615655, 0.5734543391945547, 0.9101389299438368, 0.8401972157772621, 0.7741935483870968, 0.6063268892794376, 0.8897146254458977, 0.7801848642403235, 0.6825581395348838, 0.6020612653879187]\n",
      "cluster_accuracy_post_training_cycle_all_dataset : [0.96783349 0.96465598 0.94415022 0.91080039 0.65771144 0.66415094\n",
      " 0.63749378 0.55503293 0.90216843 0.83056641 0.77027027 0.69761668\n",
      " 0.89714868 0.79388943 0.68676471 0.59961777]\n",
      "mean_cluster_accuracy_during_training_cycle : 78.08%, post_traincycle_acc : 78.00%, total_acc : 78.03191796%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 78.47%\n",
      "accuracy_check 실행 시간: 38.322초\n",
      "\n",
      "\n",
      "epoch-55 loss : 0.03230689, loss_normal : 0.02095795, loss_coarse : 0.09623013, min_loss : 0.03002502, min_loss_normal : 0.02025351, min_loss_coarse : 0.09396045, wrong_element_sum : 18476186.00000000, same_data : 0.00%\n",
      "ae train 실행 시간: 126.525초, 전체 시작 시간 20250313_235813_378\n",
      "\n",
      "epoch-55 accuracy check\n",
      "k_means origin feature average accuracy : 82.24959751%, total [0.9746727376209448, 0.9733106189664963, 0.9700891573195284, 0.9530800230282096, 0.943108504398827, 0.9150568181818182, 0.801817648783348, 0.6622234826999432, 0.9488619568430388, 0.822215777262181, 0.5866935483870968, 0.5005858230814294, 0.9429250891795482, 0.8922588099364529, 0.6738372093023256, 0.5991983967935872]\n",
      "kmeans average accuracy best : 79.57%, kmeans average accuracy : 74.24756673%, total [0.9661354581673307, 0.967915956842703, 0.9490940465918896, 0.9260218767990789, 0.6733137829912024, 0.6789772727272727, 0.6523013778950454, 0.5706182643221781, 0.6355305941472066, 0.613399071925754, 0.5823732718894009, 0.5697129466900996, 0.8460166468489893, 0.8128249566724437, 0.7502906976744186, 0.6850844546235327]\n",
      "cluster_accuracy_post_training_cycle_all_dataset : [0.96830653 0.96606975 0.94511314 0.92526519 0.67661692 0.67264151\n",
      " 0.65589259 0.55126999 0.62228946 0.61035156 0.52509653 0.52581927\n",
      " 0.85081466 0.48254122 0.75294118 0.67606307]\n",
      "mean_cluster_accuracy_during_training_cycle : 72.40%, post_traincycle_acc : 71.29%, total_acc : 71.74065210%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 78.47%\n",
      "accuracy_check 실행 시간: 37.444초\n",
      "\n",
      "\n",
      "epoch-56 loss : 0.03523646, loss_normal : 0.02131364, loss_coarse : 0.09802033, min_loss : 0.03002502, min_loss_normal : 0.02025351, min_loss_coarse : 0.09396045, wrong_element_sum : 18819904.00000000, same_data : 0.00%\n",
      "ae train 실행 시간: 128.600초, 전체 시작 시간 20250313_235813_378\n",
      "\n",
      "epoch-56 accuracy check\n",
      "k_means origin feature average accuracy : 82.26218852%, total [0.9746727376209448, 0.9733106189664963, 0.9700891573195284, 0.9530800230282096, 0.943108504398827, 0.9150568181818182, 0.801817648783348, 0.6625070901871809, 0.9488619568430388, 0.822215777262181, 0.5866935483870968, 0.5005858230814294, 0.9429250891795482, 0.8922588099364529, 0.6747093023255814, 0.6000572573718866]\n",
      "kmeans average accuracy best : 79.57%, kmeans average accuracy : 70.86825059%, total [0.9652817302219693, 0.965076660988075, 0.9436295657175726, 0.9179620034542314, 0.7020527859237536, 0.6411931818181819, 0.5930812078569334, 0.5433919455473625, 0.649127992905705, 0.6583526682134571, 0.6483294930875576, 0.5550673696543644, 0.7455410225921522, 0.6582900057770075, 0.6005813953488373, 0.5519610649871171]\n",
      "cluster_accuracy_post_training_cycle_all_dataset : [0.96594134 0.96559849 0.94463168 0.91803279 0.71144279 0.64198113\n",
      " 0.56837394 0.50329257 0.64750378 0.65478516 0.59555985 0.59880834\n",
      " 0.75254582 0.78419011 0.60294118 0.52795031]\n",
      "mean_cluster_accuracy_during_training_cycle : 71.13%, post_traincycle_acc : 71.15%, total_acc : 71.13655488%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 78.47%\n",
      "accuracy_check 실행 시간: 33.761초\n",
      "\n",
      "\n",
      "epoch-57 loss : 0.03140101, loss_normal : 0.02041159, loss_coarse : 0.09508016, min_loss : 0.03002502, min_loss_normal : 0.02025351, min_loss_coarse : 0.09396045, wrong_element_sum : 18255392.00000000, same_data : 0.00%\n",
      "ae train 실행 시간: 127.219초, 전체 시작 시간 20250313_235813_378\n",
      "\n",
      "epoch-57 accuracy check\n",
      "k_means origin feature average accuracy : 82.25141437%, total [0.9746727376209448, 0.9733106189664963, 0.9700891573195284, 0.9530800230282096, 0.943108504398827, 0.9150568181818182, 0.801817648783348, 0.6622234826999432, 0.9488619568430388, 0.822215777262181, 0.5866935483870968, 0.5005858230814294, 0.9429250891795482, 0.8922588099364529, 0.6741279069767442, 0.5991983967935872]\n",
      "kmeans average accuracy best : 79.57%, kmeans average accuracy : 77.41568579%, total [0.9678429140580534, 0.9676320272572402, 0.9433419614610297, 0.9156591824985607, 0.729325513196481, 0.6704545454545454, 0.6455584872471416, 0.5904707884288145, 0.9042270174401419, 0.843677494199536, 0.7629608294930875, 0.6318101933216169, 0.8480975029726516, 0.7328134026574235, 0.6529069767441861, 0.5797308903521329]\n",
      "cluster_accuracy_post_training_cycle_all_dataset : [0.96830653 0.96606975 0.94077997 0.91224687 0.63432836 0.66933962\n",
      " 0.65887618 0.5710254  0.89006556 0.82421875 0.70608108 0.67328699\n",
      " 0.85081466 0.78806984 0.65637255 0.57142857]\n",
      "mean_cluster_accuracy_during_training_cycle : 76.54%, post_traincycle_acc : 76.76%, total_acc : 76.66535825%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 78.47%\n",
      "accuracy_check 실행 시간: 38.318초\n",
      "\n",
      "\n",
      "epoch-58 loss : 0.03627328, loss_normal : 0.02282086, loss_coarse : 0.10200274, min_loss : 0.03002502, min_loss_normal : 0.02025351, min_loss_coarse : 0.09396045, wrong_element_sum : 19584526.00000000, same_data : 0.00%\n",
      "ae train 실행 시간: 128.601초, 전체 시작 시간 20250313_235813_378\n",
      "\n",
      "epoch-58 accuracy check\n",
      "k_means origin feature average accuracy : 82.24774477%, total [0.9746727376209448, 0.9733106189664963, 0.9700891573195284, 0.9530800230282096, 0.943108504398827, 0.9150568181818182, 0.801817648783348, 0.6625070901871809, 0.9488619568430388, 0.8216357308584686, 0.5866935483870968, 0.5005858230814294, 0.9429250891795482, 0.8922588099364529, 0.6738372093023256, 0.5991983967935872]\n",
      "kmeans average accuracy best : 79.57%, kmeans average accuracy : 74.67431746%, total [0.9652817302219693, 0.9653605905735377, 0.9421915444348576, 0.9156591824985607, 0.6665689149560118, 0.6900568181818182, 0.66168279097039, 0.5901871809415768, 0.6745492166715933, 0.660092807424594, 0.6091589861751152, 0.5905096660808435, 0.8305588585017836, 0.7980935875216638, 0.7183139534883721, 0.6696249642141425]\n",
      "cluster_accuracy_post_training_cycle_all_dataset : [0.96688742 0.96465598 0.93789119 0.91562199 0.67462687 0.68679245\n",
      " 0.65837892 0.58419567 0.66515381 0.65673828 0.51303089 0.58341609\n",
      " 0.83299389 0.61687682 0.53823529 0.66985189]\n",
      "mean_cluster_accuracy_during_training_cycle : 71.43%, post_traincycle_acc : 71.66%, total_acc : 71.56539742%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 78.47%\n",
      "accuracy_check 실행 시간: 33.967초\n",
      "\n",
      "\n",
      "epoch-59 loss : 0.03462949, loss_normal : 0.02112586, loss_coarse : 0.09793978, min_loss : 0.03002502, min_loss_normal : 0.02025351, min_loss_coarse : 0.09396045, wrong_element_sum : 18804438.00000000, same_data : 0.00%\n",
      "ae train 실행 시간: 131.080초, 전체 시작 시간 20250313_235813_378\n",
      "\n",
      "epoch-59 accuracy check\n",
      "k_means origin feature average accuracy : 82.25486595%, total [0.9746727376209448, 0.9733106189664963, 0.9700891573195284, 0.9530800230282096, 0.943108504398827, 0.915340909090909, 0.801817648783348, 0.6625070901871809, 0.9488619568430388, 0.822215777262181, 0.5866935483870968, 0.5002929115407148, 0.9429250891795482, 0.8922588099364529, 0.673546511627907, 0.6000572573718866]\n",
      "kmeans average accuracy best : 79.57%, kmeans average accuracy : 72.62775179%, total [0.9649971542401822, 0.9670641680863146, 0.9531205061834915, 0.927461139896373, 0.6850439882697947, 0.6607954545454545, 0.6259161536206391, 0.5720363017583664, 0.6710020691693763, 0.6136890951276102, 0.559331797235023, 0.5673696543643819, 0.7856718192627824, 0.7221259387637204, 0.7063953488372093, 0.638419696535929]\n",
      "cluster_accuracy_post_training_cycle_all_dataset : [0.96594134 0.96512724 0.94992778 0.91803279 0.6840796  0.5995283\n",
      " 0.57583292 0.51222954 0.66464952 0.65673828 0.56708494 0.59483615\n",
      " 0.74796334 0.714355   0.61323529 0.54562828]\n",
      "mean_cluster_accuracy_during_training_cycle : 69.87%, post_traincycle_acc : 70.47%, total_acc : 70.22821683%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 78.47%\n",
      "accuracy_check 실행 시간: 35.345초\n",
      "\n",
      "\n",
      "epoch-60 loss : 0.03495951, loss_normal : 0.02128651, loss_coarse : 0.09822790, min_loss : 0.03002502, min_loss_normal : 0.02025351, min_loss_coarse : 0.09396045, wrong_element_sum : 18859758.00000000, same_data : 0.00%\n",
      "ae train 실행 시간: 125.767초, 전체 시작 시간 20250313_235813_378\n",
      "\n",
      "epoch-60 accuracy check\n",
      "k_means origin feature average accuracy : 82.25683448%, total [0.9746727376209448, 0.9733106189664963, 0.9700891573195284, 0.9530800230282096, 0.943108504398827, 0.915340909090909, 0.801817648783348, 0.6625070901871809, 0.9488619568430388, 0.822215777262181, 0.5866935483870968, 0.5005858230814294, 0.9429250891795482, 0.8922588099364529, 0.675, 0.5986258230747209]\n",
      "kmeans average accuracy best : 79.57%, kmeans average accuracy : 74.47245949%, total [0.9624359704040979, 0.9645088018171494, 0.9554213402358355, 0.9289004029936673, 0.7343108504398826, 0.7014204545454545, 0.6352975666959836, 0.5348837209302325, 0.8028377180017736, 0.675754060324826, 0.606278801843318, 0.5884592852958407, 0.7711058263971462, 0.7082611207394569, 0.690406976744186, 0.655310621242485]\n",
      "cluster_accuracy_post_training_cycle_all_dataset : [0.96452223 0.96418473 0.95281656 0.92767599 0.66368159 0.65141509\n",
      " 0.63799105 0.55973659 0.79324256 0.67675781 0.60810811 0.6082423\n",
      " 0.76120163 0.69495635 0.61519608 0.54897277]\n",
      "mean_cluster_accuracy_during_training_cycle : 72.65%, post_traincycle_acc : 72.68%, total_acc : 72.66463257%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 78.47%\n",
      "accuracy_check 실행 시간: 43.917초\n",
      "\n",
      "\n",
      "epoch-61 loss : 0.03454767, loss_normal : 0.02129856, loss_coarse : 0.09825421, min_loss : 0.03002502, min_loss_normal : 0.02025351, min_loss_coarse : 0.09396045, wrong_element_sum : 18864808.00000000, same_data : 0.00%\n",
      "ae train 실행 시간: 128.471초, 전체 시작 시간 20250313_235813_378\n",
      "\n",
      "epoch-61 accuracy check\n",
      "k_means origin feature average accuracy : 82.25682064%, total [0.9746727376209448, 0.9733106189664963, 0.9700891573195284, 0.9530800230282096, 0.943108504398827, 0.9150568181818182, 0.801817648783348, 0.6625070901871809, 0.9488619568430388, 0.822215777262181, 0.5866935483870968, 0.5005858230814294, 0.9429250891795482, 0.8922588099364529, 0.6747093023255814, 0.5991983967935872]\n",
      "kmeans average accuracy best : 79.57%, kmeans average accuracy : 71.51799836%, total [0.9635742743312464, 0.9630891538898353, 0.9341386252516537, 0.9052964881980426, 0.6662756598240469, 0.5755681818181818, 0.5420697742597479, 0.5709018718094158, 0.76027194797517, 0.6830046403712297, 0.5748847926267281, 0.5140597539543058, 0.8204518430439952, 0.7215482380127094, 0.6296511627906977, 0.6180933295161752]\n",
      "cluster_accuracy_post_training_cycle_all_dataset : [0.9640492  0.96135721 0.92729899 0.90067502 0.63432836 0.57075472\n",
      " 0.50621581 0.48306679 0.74533535 0.68457031 0.56515444 0.52333664\n",
      " 0.81619145 0.73035887 0.62696078 0.5226947 ]\n",
      "mean_cluster_accuracy_during_training_cycle : 70.60%, post_traincycle_acc : 69.76%, total_acc : 70.10534704%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 78.47%\n",
      "accuracy_check 실행 시간: 47.599초\n",
      "\n",
      "\n",
      "epoch-62 loss : 0.03761875, loss_normal : 0.02212504, loss_coarse : 0.10017910, min_loss : 0.03002502, min_loss_normal : 0.02025351, min_loss_coarse : 0.09396045, wrong_element_sum : 19234388.00000000, same_data : 0.00%\n",
      "ae train 실행 시간: 130.341초, 전체 시작 시간 20250313_235813_378\n",
      "\n",
      "epoch-62 accuracy check\n",
      "k_means origin feature average accuracy : 82.26032074%, total [0.9746727376209448, 0.9733106189664963, 0.9700891573195284, 0.9530800230282096, 0.943108504398827, 0.915340909090909, 0.801817648783348, 0.6625070901871809, 0.9488619568430388, 0.8219257540603249, 0.5866935483870968, 0.5002929115407148, 0.9429250891795482, 0.8922588099364529, 0.6747093023255814, 0.6000572573718866]\n",
      "kmeans average accuracy best : 79.57%, kmeans average accuracy : 71.94308029%, total [0.9456459874786568, 0.9440658716638274, 0.909692263445499, 0.874496257915947, 0.7724340175953079, 0.74375, 0.682204632072706, 0.6080544526375496, 0.785988767366243, 0.6061484918793504, 0.5311059907834101, 0.47685998828353837, 0.7470273483947681, 0.6871750433275563, 0.6316860465116279, 0.5645576868021758]\n",
      "cluster_accuracy_post_training_cycle_all_dataset : [0.94701987 0.94297832 0.91622532 0.87126326 0.77711443 0.74103774\n",
      " 0.68771755 0.47507056 0.71306102 0.56787109 0.47586873 0.46871897\n",
      " 0.83401222 0.78952473 0.64019608 0.55996178]\n",
      "mean_cluster_accuracy_during_training_cycle : 70.98%, post_traincycle_acc : 71.30%, total_acc : 71.16225231%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 78.47%\n",
      "accuracy_check 실행 시간: 41.823초\n",
      "\n",
      "\n",
      "epoch-63 loss : 0.03111613, loss_normal : 0.02072112, loss_coarse : 0.09587329, min_loss : 0.03002502, min_loss_normal : 0.02025351, min_loss_coarse : 0.09396045, wrong_element_sum : 18407672.00000000, same_data : 0.00%\n",
      "ae train 실행 시간: 129.033초, 전체 시작 시간 20250313_235813_378\n",
      "\n",
      "epoch-63 accuracy check\n",
      "k_means origin feature average accuracy : 82.25504809%, total [0.9746727376209448, 0.9733106189664963, 0.9700891573195284, 0.9530800230282096, 0.943108504398827, 0.9150568181818182, 0.801817648783348, 0.6622234826999432, 0.9488619568430388, 0.822215777262181, 0.5866935483870968, 0.5005858230814294, 0.9429250891795482, 0.8922588099364529, 0.6747093023255814, 0.5991983967935872]\n",
      "save model\n",
      "kmeans average accuracy best : 79.75%, kmeans average accuracy : 79.75324751%, total [0.9644280022766079, 0.9662123793299262, 0.9462180040264596, 0.9182498560736903, 0.770674486803519, 0.7213068181818182, 0.6775139255350338, 0.6055019852524106, 0.8699379249187112, 0.8158352668213457, 0.7056451612903226, 0.6578793204452256, 0.9236028537455411, 0.8281340265742345, 0.7377906976744186, 0.651588892069854]\n",
      "cluster_accuracy_post_training_cycle_all_dataset : [0.96641438 0.96606975 0.94270583 0.91513983 0.77960199 0.7259434\n",
      " 0.67777225 0.58984008 0.86283409 0.72607422 0.68436293 0.63654419\n",
      " 0.92820774 0.8399612  0.74607843 0.65647396]\n",
      "mean_cluster_accuracy_during_training_cycle : 79.20%, post_traincycle_acc : 79.03%, total_acc : 79.09542964%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 79.03%\n",
      "accuracy_check 실행 시간: 37.751초\n",
      "\n",
      "\n",
      "epoch-64 loss : 0.03287900, loss_normal : 0.02147369, loss_coarse : 0.09801499, min_loss : 0.03002502, min_loss_normal : 0.02025351, min_loss_coarse : 0.09396045, wrong_element_sum : 18818878.00000000, same_data : 0.00%\n",
      "ae train 실행 시간: 127.699초, 전체 시작 시간 20250313_235813_378\n",
      "\n",
      "epoch-64 accuracy check\n",
      "k_means origin feature average accuracy : 82.25682064%, total [0.9746727376209448, 0.9733106189664963, 0.9700891573195284, 0.9530800230282096, 0.943108504398827, 0.9150568181818182, 0.801817648783348, 0.6625070901871809, 0.9488619568430388, 0.822215777262181, 0.5866935483870968, 0.5005858230814294, 0.9429250891795482, 0.8922588099364529, 0.6747093023255814, 0.5991983967935872]\n",
      "kmeans average accuracy best : 79.75%, kmeans average accuracy : 73.21847927%, total [0.9658508821855435, 0.9662123793299262, 0.9456427955133736, 0.918825561312608, 0.786217008797654, 0.5914772727272727, 0.5620052770448549, 0.577424844015882, 0.5900088678687555, 0.6017981438515081, 0.5861175115207373, 0.637668424135911, 0.8094530321046374, 0.7856730213749278, 0.7226744186046512, 0.6679072430575437]\n",
      "cluster_accuracy_post_training_cycle_all_dataset : [0.96594134 0.96606975 0.94366875 0.91706847 0.81293532 0.59481132\n",
      " 0.48881154 0.52022578 0.58850227 0.61230469 0.58783784 0.56305859\n",
      " 0.80142566 0.79194956 0.72696078 0.65981844]\n",
      "mean_cluster_accuracy_during_training_cycle : 72.25%, post_traincycle_acc : 72.13%, total_acc : 72.18650702%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 79.03%\n",
      "accuracy_check 실행 시간: 41.999초\n",
      "\n",
      "\n",
      "epoch-65 loss : 0.03738221, loss_normal : 0.02264667, loss_coarse : 0.10201401, min_loss : 0.03002502, min_loss_normal : 0.02025351, min_loss_coarse : 0.09396045, wrong_element_sum : 19586690.00000000, same_data : 0.00%\n",
      "ae train 실행 시간: 127.253초, 전체 시작 시간 20250313_235813_378\n",
      "\n",
      "epoch-65 accuracy check\n",
      "k_means origin feature average accuracy : 82.24966347%, total [0.9746727376209448, 0.9733106189664963, 0.9700891573195284, 0.9530800230282096, 0.943108504398827, 0.9150568181818182, 0.801817648783348, 0.6625070901871809, 0.9488619568430388, 0.822215777262181, 0.5866935483870968, 0.5005858230814294, 0.9429250891795482, 0.8922588099364529, 0.6747093023255814, 0.5980532493558546]\n",
      "kmeans average accuracy best : 79.75%, kmeans average accuracy : 73.07211596%, total [0.9635742743312464, 0.9673480976717774, 0.9525452976704055, 0.9254461715601612, 0.5709677419354838, 0.5681818181818182, 0.6414541190266784, 0.5958593306863301, 0.677209577298256, 0.6577726218097448, 0.6353686635944701, 0.5550673696543644, 0.8739595719381689, 0.7862507221259387, 0.6909883720930232, 0.6295448038935013]\n",
      "cluster_accuracy_post_training_cycle_all_dataset : [0.96452223 0.966541   0.94944632 0.92333655 0.55074627 0.53773585\n",
      " 0.50721034 0.45625588 0.67977811 0.60546875 0.65781853 0.54965243\n",
      " 0.88187373 0.80649855 0.68578431 0.62302914]\n",
      "mean_cluster_accuracy_during_training_cycle : 72.48%, post_traincycle_acc : 70.91%, total_acc : 71.55038487%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 79.03%\n",
      "accuracy_check 실행 시간: 41.035초\n",
      "\n",
      "\n",
      "epoch-66 loss : 0.03612632, loss_normal : 0.02247997, loss_coarse : 0.10156686, min_loss : 0.03002502, min_loss_normal : 0.02025351, min_loss_coarse : 0.09396045, wrong_element_sum : 19500838.00000000, same_data : 0.00%\n",
      "ae train 실행 시간: 130.166초, 전체 시작 시간 20250313_235813_378\n",
      "\n",
      "epoch-66 accuracy check\n",
      "k_means origin feature average accuracy : 82.25317267%, total [0.9746727376209448, 0.9733106189664963, 0.9700891573195284, 0.9530800230282096, 0.943108504398827, 0.9150568181818182, 0.8015244796247435, 0.6622234826999432, 0.9488619568430388, 0.8219257540603249, 0.5872695852534562, 0.5002929115407148, 0.9429250891795482, 0.8922588099364529, 0.6747093023255814, 0.5991983967935872]\n",
      "kmeans average accuracy best : 79.75%, kmeans average accuracy : 72.36170585%, total [0.9524758110415481, 0.9534355479840999, 0.9214840379637619, 0.8983880253310305, 0.6381231671554253, 0.5772727272727273, 0.545001465845793, 0.5382870107770845, 0.6955365060597103, 0.6763341067285383, 0.6575460829493087, 0.6033977738722905, 0.8644470868014269, 0.7348353552859619, 0.6854651162790698, 0.6358431148010306]\n",
      "cluster_accuracy_post_training_cycle_all_dataset : [0.9512772  0.95805844 0.91766972 0.90260366 0.64179104 0.5509434\n",
      " 0.51367479 0.50235183 0.6913767  0.50146484 0.64816602 0.59533267\n",
      " 0.74338086 0.74151309 0.69166667 0.63115146]\n",
      "mean_cluster_accuracy_during_training_cycle : 70.99%, post_traincycle_acc : 69.89%, total_acc : 70.33456174%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 79.03%\n",
      "accuracy_check 실행 시간: 52.250초\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "gpu = '0'\n",
    "Conv_net = True # True False\n",
    "SAE_net = True # True False\n",
    "\n",
    "# hyperparameter\n",
    "dataset_num = 16\n",
    "spike_length = 50 # coarse_com_mode일 때는 time step이 됨.\n",
    "num_cluster = 4  # 클러스터 수 설정 # 논문엔 4개라는데 여기서는 3개로 했네\n",
    "training_cycle = 1400 #1400 2400 # 그 초기 몇개까지만 cluster update할지\n",
    "\n",
    "\n",
    "batch_size = 32\n",
    "max_epoch = 10000\n",
    "learning_rate = 0.001\n",
    "normalize_on = True # True or False # 0부터1까지 normalize\n",
    "need_bias = False\n",
    "# first_layer_no_train = False\n",
    "lif_add_at_first = False\n",
    "my_seed = 42\n",
    "\n",
    "TIME = 50 # SAE일 때만 유효. coarse_com_mode일 때는 level_num이 됨. 즉 feature 개수.\n",
    "v_decay = 0.5 # -cor\n",
    "v_threshold = 0.25 # -cor\n",
    "v_reset = 0.0 # -cor # 10000이상 일 시 hard reset\n",
    "BPTT_on = True # +cor # True False\n",
    "\n",
    "SAE_hidden_nomean = True # True False\n",
    "\n",
    "current_time = datetime.datetime.now().strftime(\"%Y%m%d_%H%M%S\") + f\"_{str(int(datetime.datetime.now().microsecond / 1000)).zfill(3)}\"\n",
    "\n",
    "optimizer = 'Adam' #'Adam', 'SGD' # 둘다 준수함. loss 줄이는 거는 adam이 좋긴한데, cluster accuracy는 비슷함.\n",
    "\n",
    "coarse_com_mode = True # True False\n",
    "coarse_com_config = (0.999, -0.0) # (max, min) (0.999, -0.0) (1.0, -0.0) (2.0, -2.0) (3.0, -3.0)\n",
    "\n",
    "sae_l2_norm_bridge = True # True False\n",
    "sae_lif_bridge = False # True False\n",
    "\n",
    "accuracy_check_epoch_term = 1\n",
    "\n",
    "lif_add_at_last = False # True False\n",
    "\n",
    "two_channel_input = False # True False\n",
    "\n",
    "lateral_feature_num = 2\n",
    "\n",
    "lc_adc_on = False # True False\n",
    "\n",
    "converted_net_forward = False # True False\n",
    "\n",
    "pretrained_net = None\n",
    "# pretrained_net = '/home/bhkim003/github_folder/ByeonghyeonKim/my_snn/net_save/save_now_net_중요_20250110_203117_390.pth'\n",
    "# pretrained_net = '/home/bhkim003/github_folder/ByeonghyeonKim/my_snn/net_save/save_now_net_중요_20250113_134126_881_이거_94나오는거.pth'\n",
    "# pretrained_net =  '/home/bhkim003/github_folder/ByeonghyeonKim/my_snn/net_save/save_now_net_20250205_184901_132.pth'\n",
    "# pretrained_net =  '/home/bhkim003/github_folder/ByeonghyeonKim/my_snn/net_save/save_now_net_20250306_134219_133.pth'\n",
    "\n",
    "vth_mul_on = False # True False\n",
    "batch_norm_on = False # True False\n",
    "\n",
    "l2_norm_loss_weight = 0 #0.0001 #0.1 #  0 # 0초과면 작동\n",
    "\n",
    "QCFS_neuron_on = False # True False\n",
    "\n",
    "quantize_level_num = 0 # 0이면 quantize 안함. 1이상이면 그 수만큼 quantize함. # normalize_on 켜져야됨. 음수면 0~1norm안하고 quant함\n",
    "\n",
    "fusion_net = True # True False # SAE_net False, Conv_net True로 해라. TIME 적절하게 설정해주고.\n",
    "repeat_coding = False # True False #fusion_net에서 쓰이는 거임 # True면 repeat, False면 rate coding.\n",
    "\n",
    "sae_relu_on = False # True False\n",
    "\n",
    "conv1d_scaling = False # True False # conv1d때매 norm하고 (level_num-3)/level_num 곱해줌 # Conv_net and coarse_com_mode and normalize_on\n",
    "\n",
    "norm01 = True # True False # normalize_on = True일 때 01norm하는지 아님 걍 quant만 하는지.\n",
    "\n",
    "wandb.init(project= f'spike_sorting just run',save_code=False)\n",
    "\n",
    "\n",
    "cluster_train_system( \n",
    "    gpu = gpu,\n",
    "    Conv_net = Conv_net,\n",
    "    SAE_net = SAE_net,\n",
    "\n",
    "    # hyperparameter\n",
    "    dataset_num = dataset_num,\n",
    "    spike_length = spike_length,\n",
    "    num_cluster = num_cluster,  # 클러스터 수 설정 # 논문엔 4개라는데 여기서는 3개로 했네\n",
    "    training_cycle = training_cycle, # 그 초기 몇개까지만 cluster update할지\n",
    "\n",
    "\n",
    "    batch_size = batch_size,\n",
    "    max_epoch = max_epoch,\n",
    "    learning_rate = learning_rate,\n",
    "    normalize_on = normalize_on, # True or False #이거 안 씀 # 이거 별로 안 좋은 normalize같음 # 쓸 거면 다른 거 써라.\n",
    "    need_bias = need_bias,\n",
    "    # first_layer_no_train = False\n",
    "    lif_add_at_first = lif_add_at_first,\n",
    "    my_seed = my_seed,\n",
    "\n",
    "    TIME = TIME, # SAE일 때만 유효\n",
    "    v_decay = v_decay,\n",
    "    v_threshold = v_threshold,\n",
    "    v_reset = v_reset, # 10000이상 일 시 hard reset\n",
    "    BPTT_on = BPTT_on,\n",
    "\n",
    "    SAE_hidden_nomean = SAE_hidden_nomean,\n",
    "    \n",
    "    current_time = current_time,\n",
    "\n",
    "    optimizer = optimizer, #'Adam', 'SGD'\n",
    "\n",
    "    coarse_com_mode = coarse_com_mode,\n",
    "    coarse_com_config = coarse_com_config, # (max, min)\n",
    "\n",
    "    \n",
    "    sae_l2_norm_bridge = sae_l2_norm_bridge,\n",
    "    sae_lif_bridge = sae_lif_bridge,\n",
    "\n",
    "    accuracy_check_epoch_term = accuracy_check_epoch_term,\n",
    "    \n",
    "    lif_add_at_last = lif_add_at_last,\n",
    "\n",
    "    two_channel_input = two_channel_input,\n",
    "\n",
    "    lateral_feature_num = lateral_feature_num,\n",
    "\n",
    "    lc_adc_on = lc_adc_on, \n",
    "\n",
    "    converted_net_forward = converted_net_forward,\n",
    "\n",
    "    pretrained_net = pretrained_net,\n",
    "\n",
    "    vth_mul_on = vth_mul_on,\n",
    "    batch_norm_on = batch_norm_on,\n",
    "\n",
    "    l2_norm_loss_weight = l2_norm_loss_weight,\n",
    "    \n",
    "    QCFS_neuron_on = QCFS_neuron_on, # True False\n",
    "\n",
    "    quantize_level_num = quantize_level_num,\n",
    "\n",
    "    fusion_net = fusion_net, # True False\n",
    "    repeat_coding = repeat_coding,\n",
    "\n",
    "    sae_relu_on = sae_relu_on,\n",
    "\n",
    "    conv1d_scaling = conv1d_scaling,\n",
    "\n",
    "    norm01 = norm01,\n",
    "\n",
    "    )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Sweep code\n",
    "\n",
    "\n",
    "# from unittest import TextTestRunner\n",
    "\n",
    "\n",
    "# unique_name_hyper = 'cluster_train_system'\n",
    "# # run_name = 'spike_sorting'\n",
    "# sweep_start_time =  datetime.datetime.now().strftime(\"%Y%m%d_%H%M%S\") + f\"_{str(int(datetime.datetime.now().microsecond / 1000)).zfill(3)}\"\n",
    "# sweep_configuration = {\n",
    "#     'method': 'bayes', # 'random', 'bayes'\n",
    "#     'name': f'spike_sorting_{sweep_start_time}',\n",
    "#     'metric': {'goal': 'maximize', 'name': 'k_means_acc_best'},\n",
    "#     'parameters': \n",
    "#     {\n",
    "#         # \"gpu\": {\"values\": ['1']},  # 이건 sweep parameter아님. hyper_iter에서 직접 설정\n",
    "#         \"Conv_net\": {\"values\": [True]}, \n",
    "#         \"SAE_net\": {\"values\": [True]}, \n",
    "\n",
    "#         \"dataset_num\": {\"values\": [16]}, \n",
    "#         \"spike_length\": {\"values\": [50]},  \n",
    "#         \"num_cluster\": {\"values\": [4]}, \n",
    "#         \"training_cycle\": {\"values\": [1400]}, # [1400, 2400]\n",
    "\n",
    "#         \"batch_size\": {\"values\": [32]}, \n",
    "#         \"max_epoch\": {\"values\": [20]}, \n",
    "#         \"learning_rate\": {\"values\": [0.001, 0.0001]},\n",
    "#         \"normalize_on\": {\"values\": [True]},\n",
    "#         \"need_bias\": {\"values\": [False]}, # [True, False]\n",
    "\n",
    "#         \"lif_add_at_first\": {\"values\": [False]}, # [True, False]\n",
    "#         \"my_seed\": {\"values\": [42]}, \n",
    "\n",
    "#         \"TIME\": {\"values\": [50]}, #  [4,6,8,10]\n",
    "#         \"v_decay\": {\"values\": [0.125, 0.25,0.50,0.75,1.0]}, # [0.25,0.50,0.75]\n",
    "#         \"v_threshold\": {\"values\": [0.125, 0.25, 0.50, 0.75, 0.875, 1.0]}, # [0.25,0.50,0.75]\n",
    "#         \"v_reset\": {\"values\": [0.0, 10000.0]},  # [0.0, 10000.0]\n",
    "#         \"BPTT_on\": {\"values\": [True, False]},  # [True, False]\n",
    "\n",
    "#         \"SAE_hidden_nomean\": {\"values\": [True]}, # [True, False]\n",
    "\n",
    "#         # \"current_time\": {\"values\": [current_time]} #밑에서 직접설정됨.\n",
    "\n",
    "#         \"optimizer\": {\"values\": ['Adam', 'SGD']}, # ['Adam', 'SGD']\n",
    "\n",
    "#         \"coarse_com_mode\": {\"values\": [True]}, # [True, False]\n",
    "#         \"coarse_com_config\": {\"values\": [(0.999, -0.0)]}, # ['Adam', 'SGD']\n",
    "\n",
    "#         \"sae_l2_norm_bridge\": {\"values\": [True]}, # [True, False]\n",
    "#         \"sae_lif_bridge\": {\"values\": [False]}, # [False, True]\n",
    "        \n",
    "#         \"accuracy_check_epoch_term\": {\"values\": [1]}, \n",
    "\n",
    "#         \"lif_add_at_last\": {\"values\": [False]},# [True, False]\n",
    "\n",
    "#         \"two_channel_input\": {\"values\": [False]},# [True, False]\n",
    "\n",
    "#         \"lateral_feature_num\": {\"values\": [4]},# [True, False]\n",
    "\n",
    "#         \"lc_adc_on\": {\"values\": [False]},# [True, False]\n",
    "        \n",
    "#         \"converted_net_forward\": {\"values\": [False]},# [True, False]\n",
    "\n",
    "#         \"pretrained_net\": {\"values\": [None]},# [None]\n",
    "\n",
    "#         \"vth_mul_on\": {\"values\": [False]},# [True, False]\n",
    "#         \"batch_norm_on\": {\"values\": [False]},# [True, False]\n",
    "\n",
    "#         \"l2_norm_loss_weight\": {\"values\": [0]},\n",
    "\n",
    "#         \"QCFS_neuron_on\": {\"values\": [False]},   # [True, False]\n",
    "\n",
    "#         \"quantize_level_num\": {\"values\": [0]}, \n",
    "\n",
    "#         \"fusion_net\": {\"values\": [True]}, \n",
    "#         \"repeat_coding\": {\"values\": [False]}, \n",
    "\n",
    "#         \"sae_relu_on\": {\"values\": [False]}, \n",
    "\n",
    "#         \"conv1d_scaling\": {\"values\": [False]}, \n",
    "\n",
    "#         \"norm01\": {\"values\": [True]}, \n",
    "#      }\n",
    "# }\n",
    "\n",
    "\n",
    "# def hyper_iter():\n",
    "#     ### my_snn control board ########################\n",
    "#     wandb.init(save_code = False)\n",
    "#     gpu  =  '2'\n",
    "#     Conv_net  =  wandb.config.Conv_net\n",
    "#     SAE_net  =  wandb.config.SAE_net\n",
    "\n",
    "#     dataset_num  =  wandb.config.dataset_num\n",
    "#     spike_length  =  wandb.config.spike_length\n",
    "#     num_cluster  =  wandb.config.num_cluster\n",
    "#     training_cycle  =  wandb.config.training_cycle\n",
    "\n",
    "#     batch_size  =  wandb.config.batch_size\n",
    "#     max_epoch  =  wandb.config.max_epoch\n",
    "#     learning_rate  =  wandb.config.learning_rate\n",
    "#     normalize_on  =  wandb.config.normalize_on\n",
    "#     need_bias  =  wandb.config.need_bias\n",
    "\n",
    "#     lif_add_at_first  =  wandb.config.lif_add_at_first\n",
    "#     my_seed  =  wandb.config.my_seed\n",
    "\n",
    "\n",
    "#     TIME  =  wandb.config.TIME\n",
    "#     v_decay  =  wandb.config.v_decay\n",
    "#     v_threshold  =  wandb.config.v_threshold\n",
    "#     v_reset  =  wandb.config.v_reset\n",
    "#     BPTT_on  =  wandb.config.BPTT_on\n",
    "\n",
    "#     SAE_hidden_nomean  =  wandb.config.SAE_hidden_nomean\n",
    "    \n",
    "#     current_time =  datetime.datetime.now().strftime(\"%Y%m%d_%H%M%S\") + f\"_{str(int(datetime.datetime.now().microsecond / 1000)).zfill(3)}\"\n",
    "\n",
    "#     optimizer  =  wandb.config.optimizer\n",
    "\n",
    "#     coarse_com_mode = wandb.config.coarse_com_mode\n",
    "#     coarse_com_config = wandb.config.coarse_com_config # (max, min)\n",
    "\n",
    "#     sae_l2_norm_bridge = wandb.config.sae_l2_norm_bridge\n",
    "#     sae_lif_bridge = wandb.config.sae_lif_bridge\n",
    "\n",
    "#     accuracy_check_epoch_term = wandb.config.accuracy_check_epoch_term\n",
    "\n",
    "#     lif_add_at_last = wandb.config.lif_add_at_last\n",
    "\n",
    "#     two_channel_input = wandb.config.two_channel_input\n",
    "\n",
    "#     lateral_feature_num = wandb.config.lateral_feature_num\n",
    "\n",
    "#     lc_adc_on = wandb.config.lc_adc_on\n",
    "\n",
    "#     converted_net_forward = wandb.config.converted_net_forward\n",
    "\n",
    "#     pretrained_net = wandb.config.pretrained_net\n",
    "\n",
    "#     vth_mul_on = wandb.config.vth_mul_on\n",
    "#     batch_norm_on = wandb.config.batch_norm_on\n",
    "\n",
    "#     l2_norm_loss_weight = wandb.config.l2_norm_loss_weight\n",
    "\n",
    "#     QCFS_neuron_on = wandb.config.QCFS_neuron_on\n",
    "\n",
    "#     quantize_level_num = wandb.config.quantize_level_num\n",
    "\n",
    "#     fusion_net = wandb.config.fusion_net\n",
    "#     repeat_coding = wandb.config.repeat_coding\n",
    "\n",
    "#     sae_relu_on = wandb.config.sae_relu_on\n",
    "\n",
    "#     conv1d_scaling = wandb.config.conv1d_scaling\n",
    "\n",
    "#     norm01 = wandb.config.norm01\n",
    "\n",
    "#     cluster_train_system( \n",
    "#         gpu = gpu,\n",
    "#         Conv_net = Conv_net,\n",
    "#         SAE_net = SAE_net,\n",
    "\n",
    "#         # hyperparameter\n",
    "#         dataset_num = dataset_num,\n",
    "#         spike_length = spike_length,\n",
    "#         num_cluster = num_cluster,  # 클러스터 수 설정 # 논문엔 4개라는데 여기서는 3개로 했네\n",
    "#         training_cycle = training_cycle, # 그 초기 몇개까지만 cluster update할지\n",
    "\n",
    "\n",
    "#         batch_size = batch_size,\n",
    "#         max_epoch = max_epoch,\n",
    "#         learning_rate = learning_rate,\n",
    "#         normalize_on = normalize_on, # True or False #이거 안 씀 # 이거 별로 안 좋은 normalize같음 # 쓸 거면 다른 거 써라.\n",
    "#         need_bias = need_bias,\n",
    "#         # first_layer_no_train = False\n",
    "#         lif_add_at_first = lif_add_at_first,\n",
    "#         my_seed = my_seed,\n",
    "\n",
    "#         TIME = TIME, # SAE일 때만 유효\n",
    "#         v_decay = v_decay,\n",
    "#         v_threshold = v_threshold,\n",
    "#         v_reset = v_reset, # 10000이상 일 시 hard reset\n",
    "#         BPTT_on = BPTT_on,\n",
    "\n",
    "#         SAE_hidden_nomean = SAE_hidden_nomean,\n",
    "\n",
    "#         current_time = current_time,\n",
    "\n",
    "#         optimizer = optimizer, #'Adam', 'SGD'\n",
    "\n",
    "#         coarse_com_mode = coarse_com_mode,\n",
    "#         coarse_com_config = coarse_com_config, # (max, min)\n",
    "        \n",
    "#         sae_l2_norm_bridge = sae_l2_norm_bridge,\n",
    "#         sae_lif_bridge = sae_lif_bridge,\n",
    "\n",
    "#         accuracy_check_epoch_term = accuracy_check_epoch_term,\n",
    "\n",
    "#         lif_add_at_last = lif_add_at_last,\n",
    "        \n",
    "#         two_channel_input = two_channel_input,\n",
    "        \n",
    "#         lateral_feature_num = lateral_feature_num,\n",
    "\n",
    "#         lc_adc_on = lc_adc_on,\n",
    "\n",
    "#         converted_net_forward = converted_net_forward,\n",
    "\n",
    "#         pretrained_net = pretrained_net,\n",
    "\n",
    "#         vth_mul_on = vth_mul_on,\n",
    "#         batch_norm_on = batch_norm_on,\n",
    "\n",
    "#         l2_norm_loss_weight = l2_norm_loss_weight,\n",
    "\n",
    "#         QCFS_neuron_on = QCFS_neuron_on,\n",
    "\n",
    "#         quantize_level_num = quantize_level_num,\n",
    "\n",
    "#         fusion_net = fusion_net, \n",
    "#         repeat_coding = repeat_coding, \n",
    "\n",
    "#         sae_relu_on = sae_relu_on,\n",
    "\n",
    "#         conv1d_scaling = conv1d_scaling,\n",
    "\n",
    "#         norm01 = norm01,\n",
    "#         )\n",
    "    \n",
    "# # sweep_id = 'ygoj9jt4'\n",
    "# sweep_id = wandb.sweep(sweep=sweep_configuration, project=f'spike_sorting {unique_name_hyper}')\n",
    "# wandb.agent(sweep_id, function=hyper_iter, count=100000, project=f'spike_sorting {unique_name_hyper}')\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wandb.finish() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import matplotlib.pyplot as plt\n",
    "# from matplotlib.ticker import MaxNLocator\n",
    "# import pickle\n",
    "# import json\n",
    "\n",
    "# # current_time = '20250102_225243_972'\n",
    "\n",
    "# with open(f\"result_save/cluster_accuracy_history_{current_time}.pkl\", \"rb\") as f:\n",
    "#     data = pickle.load(f)\n",
    "\n",
    "\n",
    "# # JSON으로 저장\n",
    "# with open(f\"result_save/cluster_accuracy_history_{current_time}.json\", 'r') as f:\n",
    "#     loaded_hyperparameters = json.load(f)\n",
    "\n",
    "# loss_history = data['loss_history']\n",
    "# mean_cluster_accuracy_during_training_cycle_all_dataset_history = data['mean_cluster_accuracy_during_training_cycle_all_dataset_history']\n",
    "# mean_cluster_accuracy_post_training_cycle_all_dataset_history = data['mean_cluster_accuracy_post_training_cycle_all_dataset_history']\n",
    "# mean_cluster_accuracy_total_all_dataset_history = data['mean_cluster_accuracy_total_all_dataset_history']\n",
    "# print(data)\n",
    "# max_acc = 0\n",
    "# for i in mean_cluster_accuracy_post_training_cycle_all_dataset_history:\n",
    "#     if i[1] > max_acc:\n",
    "#         max_acc = i[1]\n",
    "\n",
    "# # 설정 정보 제목 작성\n",
    "# title = (\n",
    "#     f\"Dataset Num: {loaded_hyperparameters['dataset_num']}, Conv {loaded_hyperparameters['Conv_net']}, SAE {loaded_hyperparameters['SAE_net']}, Current time {loaded_hyperparameters['current_time']}, Spike Length: {loaded_hyperparameters['spike_length']}, Num Cluster: {loaded_hyperparameters['num_cluster']}, \"\n",
    "#     f\"Training Cycle: {loaded_hyperparameters['training_cycle']}, Batch Size: {loaded_hyperparameters['batch_size']}, Max Epoch: {loaded_hyperparameters['max_epoch']}, \\n\"\n",
    "#     f\"Learning Rate: {loaded_hyperparameters['learning_rate']}, Input Normalize: {loaded_hyperparameters['normalize_on']}, Need Bias: {loaded_hyperparameters['need_bias']}, \"\n",
    "#     f\"LIF Add at First: {loaded_hyperparameters['lif_add_at_first']}, TIME: {loaded_hyperparameters['TIME']}, Seed: {loaded_hyperparameters['my_seed']}, Best ACC: {max_acc:.2f}%\"\n",
    "# )\n",
    "\n",
    "# # 데이터 리스트와 라벨 설정 (Loss 제외)\n",
    "# data_list = [\n",
    "#     (\"Mean Cluster Accuracy (During Training Cycle)\", mean_cluster_accuracy_during_training_cycle_all_dataset_history),\n",
    "#     (\"Mean Cluster Accuracy (Post Training Cycle)\", mean_cluster_accuracy_post_training_cycle_all_dataset_history),\n",
    "#     (\"Mean Cluster Accuracy (Total)\", mean_cluster_accuracy_total_all_dataset_history),\n",
    "# ]\n",
    "\n",
    "# # 플롯 생성\n",
    "# fig, ax1 = plt.subplots(figsize=(12, 8))\n",
    "\n",
    "# # 첫 번째 y축: Accuracy 관련 데이터\n",
    "# for label, data in data_list:\n",
    "#     epochs, values = zip(*data)  # epoch, value 분리\n",
    "#     ax1.plot(epochs, values, label=label)\n",
    "\n",
    "# ax1.set_xlabel(\"Epoch\")\n",
    "# ax1.set_ylabel(\"Clurstering Accuracy [%]\", color=\"blue\")\n",
    "# ax1.tick_params(axis=\"y\", labelcolor=\"blue\")\n",
    "# ax1.legend(loc=\"center right\")\n",
    "# ax1.grid(True)\n",
    "\n",
    "# # x축을 정수만 표시하도록 설정\n",
    "# ax1.xaxis.set_major_locator(MaxNLocator(integer=True))\n",
    "\n",
    "# # 두 번째 y축: Loss History\n",
    "# ax2 = ax1.twinx()\n",
    "# epochs, values = zip(*loss_history)\n",
    "# ax2.plot(epochs, values, label=\"AE Loss History\", color=\"red\", linestyle=\"--\")\n",
    "# ax2.set_ylabel(\"Loss\", color=\"red\")\n",
    "# ax2.tick_params(axis=\"y\", labelcolor=\"red\")\n",
    "# ax2.legend(loc=\"center left\")\n",
    "\n",
    "# # 제목 추가\n",
    "# plt.title(title, fontsize=10)\n",
    "# plt.tight_layout()\n",
    "# plt.savefig(f'net_save/{current_time}', dpi=300, bbox_inches=\"tight\")  # dpi=300은 고해상도로 저장, bbox_inches=\"tight\"는 여백 최소화\n",
    "# plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# 데이터셋\n",
    "filename_for_plot = [\n",
    "    \"Easy1_noise05\", \"Easy1_noise10\", \"Easy1_noise15\", \"Easy1_noise20\",\n",
    "    \"Easy2_noise05\", \"Easy2_noise10\", \"Easy2_noise15\", \"Easy2_noise20\",\n",
    "    \"Difficult1_noise05\", \"Difficult1_noise10\", \"Difficult1_noise15\", \"Difficult1_noise20\",\n",
    "    \"Difficult2_noise05\", \"Difficult2_noise10\", \"Difficult2_noise15\", \"Difficult2_noise20\"\n",
    "]\n",
    "\n",
    "# Accuracy 데이터\n",
    "ANN_conv_accracy_set= [0.97935368, 0.97682709, 0.97028784, 0.96461825, 0.97524752, 0.95803571\n",
    ", 0.95746785, 0.92628774, 0.965412,  0.97805344, 0.94869403, 0.92110454\n",
    ", 0.96784232, 0.97551789, 0.91538462, 0.84446478]\n",
    "SNN_fc_accuracy_set = [0.97114475, 0.97643732, 0.84400578, 0.78977821, 0.96616915, 0.92830189\n",
    ", 0.86176032, 0.31984948, 0.80635401, 0.88769531, 0.61003861, 0.60377358\n",
    ", 0.9592668,  0.92870999, 0.78333333, 0.67271859]\n",
    "SNN_conv_accuracy_set = [0.97445601, 0.97737983, 0.97063072, 0.95998071, 0.96268657, 0.90566038\n",
    ", 0.82545997, 0.68391345, 0.96116994, 0.92138672, 0.80694981, 0.49602781\n",
    ", 0.83604888, 0.70611057, 0.69313725, 0.5819398 ]\n",
    "\n",
    "# 평균 계산\n",
    "average_ANN_conv = np.mean(ANN_conv_accracy_set)\n",
    "average_SNN_fc = np.mean(SNN_fc_accuracy_set)\n",
    "average_SNN_conv = np.mean(SNN_conv_accuracy_set)\n",
    "\n",
    "# 데이터 준비\n",
    "accuracies = np.array([ANN_conv_accracy_set, SNN_fc_accuracy_set, SNN_conv_accuracy_set])\n",
    "averages = np.array([average_ANN_conv, average_SNN_fc, average_SNN_conv])\n",
    "\n",
    "# 시각화\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "\n",
    "# 각 모델의 정확도 플롯\n",
    "ax.plot(accuracies[0], label='ANN Conv', marker='o', linestyle='-', color='blue')\n",
    "ax.plot(accuracies[1], label='SNN FC', marker='o', linestyle='-', color='green')\n",
    "ax.plot(accuracies[2], label='SNN Conv', marker='o', linestyle='-', color='red')\n",
    "\n",
    "# 평균값 플롯\n",
    "ax.axhline(y=average_ANN_conv, color='blue', linestyle='--', label=f'Average ANN Conv: {average_ANN_conv:.3f}')\n",
    "ax.axhline(y=average_SNN_fc, color='green', linestyle='--', label=f'Average SNN FC: {average_SNN_fc:.3f}')\n",
    "ax.axhline(y=average_SNN_conv, color='red', linestyle='--', label=f'Average SNN Conv: {average_SNN_conv:.3f}')\n",
    "\n",
    "# 레이블 추가\n",
    "ax.set_xticks(np.arange(len(filename_for_plot)))\n",
    "ax.set_xticklabels(filename_for_plot, rotation=45, ha='right')\n",
    "ax.set_ylabel('Accuracy')\n",
    "ax.set_title('Accuracy Comparison of Models on Datasets')\n",
    "ax.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import matplotlib.pyplot as plt\n",
    "import os  # 파일 경로 처리를 위한 모듈\n",
    "\n",
    "# CSV 파일 경로\n",
    "# csv_file_path = \"/home/bhkim003/github_folder/ByeonghyeonKim/my_snn/ae_test_deprecated/250115/sweep0_vth_mul.csv\" # vth_mul해서 sweep 돌린거\n",
    "csv_file_path = \"/home/bhkim003/github_folder/ByeonghyeonKim/my_snn/ae_test_deprecated/250115/sweep1.csv\"  #vth_mul안한거\n",
    "\n",
    "# 결과를 저장할 리스트\n",
    "tuple_list = []\n",
    "\n",
    "# CSV 파일 읽기\n",
    "with open(csv_file_path, 'r') as file:\n",
    "    reader = csv.DictReader(file)\n",
    "    for row in reader:\n",
    "        try:\n",
    "            # v_threshold, TIME, v_reset, converted_k_means_acc 값을 가져와 튜플로 변환\n",
    "            v_threshold = float(row[\"v_threshold\"])\n",
    "            time = int(row[\"TIME\"])\n",
    "            v_reset = int(row[\"v_reset\"])\n",
    "            converted_k_means_acc = float(row[\"converted_k_means_acc\"]) if row[\"converted_k_means_acc\"] else None\n",
    "\n",
    "            # 튜플 형태로 추가 (값이 None일 경우 처리할 수도 있음)\n",
    "            tuple_list.append((v_threshold, time, v_reset, converted_k_means_acc))\n",
    "        except ValueError as e:\n",
    "            print(f\"Error processing row {row}: {e}\")\n",
    "\n",
    "# 데이터를 TIME 기준으로 정렬\n",
    "tuple_list.sort(key=lambda x: x[1])  # TIME을 기준으로 오름차순 정렬\n",
    "\n",
    "# reset 방식에 따라 데이터를 나누기\n",
    "soft_reset = [t for t in tuple_list if t[2] == 0]\n",
    "hard_reset = [t for t in tuple_list if t[2] == 10000]\n",
    "\n",
    "# reset 방식과 v_threshold에 따라 색상 설정\n",
    "def plot_data(data, label_prefix, marker):\n",
    "    for v_threshold in [1.0]:  # v_threshold 기준으로 제한\n",
    "        filtered_data = [(t[1], t[3]) for t in data if t[0] == v_threshold]\n",
    "        if filtered_data:  # 해당 v_threshold 데이터가 있을 경우만 플롯\n",
    "            times, accuracies = zip(*filtered_data)  # x축(TIME), y축(converted_k_means_acc)\n",
    "            \n",
    "            plt.plot(\n",
    "                times,\n",
    "                accuracies,\n",
    "                marker,\n",
    "                label=f\"{label_prefix}, v_threshold={v_threshold}\",\n",
    "                linestyle=\"--\",\n",
    "            )\n",
    "            # 각 점에 accuracy 표시\n",
    "            for time, acc in filtered_data:\n",
    "                if acc == None:\n",
    "                    continue\n",
    "                plt.text(time, acc, f\"{acc:.2f}\", fontsize=8, ha=\"right\")\n",
    "\n",
    "# 그래프 초기화\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "# soft_reset (v_reset=0) 데이터 플롯\n",
    "plot_data(soft_reset, \"Soft Reset\", \"o\")\n",
    "\n",
    "# hard_reset (v_reset=10000) 데이터 플롯\n",
    "plot_data(hard_reset, \"Hard Reset\", \"x\")\n",
    "\n",
    "# baseline accuracy 가로선 추가\n",
    "baseline_accuracy = 94.43\n",
    "plt.axhline(y=baseline_accuracy, color=\"red\", linestyle=\"-\", label=f\"Baseline Accuracy ({baseline_accuracy}%)\")\n",
    "# baseline 텍스트 추가\n",
    "plt.text(\n",
    "    2000,  # x축 위치 (그래프 오른쪽 끝)\n",
    "    baseline_accuracy + 0.4,  # y축 위치 (baseline 위 약간)\n",
    "    f\"ANN Baseline ({baseline_accuracy}%)\",\n",
    "    color=\"red\",\n",
    "    fontsize=10,\n",
    "    ha=\"center\",\n",
    ")\n",
    "\n",
    "# CSV 파일 이름 가져오기\n",
    "csv_file_name = os.path.basename(csv_file_path)\n",
    "\n",
    "# 그래프 세부 설정\n",
    "plt.title(f\"Converted SNN K-Means Accuracy vs TIME STEP - {csv_file_name}\")\n",
    "plt.xlabel(\"TIME STEP\")\n",
    "plt.ylabel(\"Converted K-Means Accuracy [%]\")\n",
    "plt.legend(loc=\"lower right\")  # 범례를 오른쪽 아래로 이동\n",
    "plt.grid(True)\n",
    "\n",
    "# 그래프 출력\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aedat2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
