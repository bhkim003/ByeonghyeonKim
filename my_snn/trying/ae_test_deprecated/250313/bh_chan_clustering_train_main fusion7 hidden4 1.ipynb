{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ssp.train.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x600 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import torch   \n",
    "import torch.nn as nn \n",
    "import torch.nn.functional as F   \n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import torch.optim as optim\n",
    "from scipy import io\n",
    "import itertools\n",
    "import math\n",
    "import datetime\n",
    "import wandb\n",
    "import pickle\n",
    "import json\n",
    "import time\n",
    "import sys\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import accuracy_score\n",
    "from scipy.optimize import linear_sum_assignment\n",
    "from snntorch import spikegen\n",
    "\n",
    "\n",
    "# my module import\n",
    "from modules import *\n",
    "\n",
    "# modules 폴더에 새모듈.py 만들면\n",
    "# modules/__init__py 파일에 form .새모듈 import * 하셈\n",
    "# 그리고 새모듈.py에서 from modules.새모듈 import * 하셈"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cluster_train_system( \n",
    "    gpu = '4',\n",
    "    Conv_net = True,\n",
    "    SAE_net = True,\n",
    "\n",
    "    # hyperparameter\n",
    "    dataset_num = 16,\n",
    "    spike_length = 50,\n",
    "    num_cluster = 4,  # 클러스터 수 설정 # 논문엔 4개라는데 여기서는 3개로 했네\n",
    "    training_cycle = 2400, # 그 초기 몇개까지만 cluster update할지\n",
    "\n",
    "\n",
    "    batch_size = 32,\n",
    "    max_epoch = 7000,\n",
    "    learning_rate = 0.001,\n",
    "    normalize_on = False, # True or False #이거 안 씀 # 이거 별로 안 좋은 normalize같음 # 쓸 거면 다른 거 써라.\n",
    "    need_bias = False,\n",
    "    # first_layer_no_train = False\n",
    "    lif_add_at_first = False,\n",
    "    my_seed = 42,\n",
    "\n",
    "    TIME = 10, # SAE일 때만 유효\n",
    "    v_decay = 0.5,\n",
    "    v_threshold = 0.5,\n",
    "    v_reset = 10000.0, # 10000이상 일 시 hard reset\n",
    "    BPTT_on = True,\n",
    "\n",
    "    SAE_hidden_nomean = True,\n",
    "    current_time = '20250101_210938_786',\n",
    "\n",
    "    optimizer = 'Adam',\n",
    "    coarse_com_mode = True,\n",
    "    coarse_com_config = (2.0, -2.0), # (max, min)\n",
    "\n",
    "    sae_l2_norm_bridge = True,\n",
    "    sae_lif_bridge = False,\n",
    "\n",
    "    accuracy_check_epoch_term = 5,\n",
    "    \n",
    "    lif_add_at_last = False,\n",
    "\n",
    "    two_channel_input = False,\n",
    "\n",
    "    lateral_feature_num = 4,\n",
    "\n",
    "    lc_adc_on = False, \n",
    "\n",
    "    converted_net_forward = False,\n",
    "\n",
    "    pretrained_net = None, \n",
    "\n",
    "    vth_mul_on = False,\n",
    "    batch_norm_on = False,\n",
    "\n",
    "    l2_norm_loss_weight = 0.0,\n",
    "\n",
    "    QCFS_neuron_on = False,\n",
    "\n",
    "    quantize_level_num = 0,\n",
    "\n",
    "    fusion_net = False, # True False\n",
    "    repeat_coding = False,\n",
    "    \n",
    "    sae_relu_on = False,\n",
    "\n",
    "    conv1d_scaling = False,\n",
    "\n",
    "    norm01 = True,\n",
    "    ):\n",
    "    if coarse_com_mode == True:\n",
    "        assert coarse_com_config[0] > coarse_com_config[1], 'coarse_com_config[0] > coarse_com_config[1]이어야 함'\n",
    "        assert converted_net_forward == False\n",
    "        # assert SAE_net == True, 'coarse_com_mode는 SAE_net이 True일 때만 가능'\n",
    "    if two_channel_input == True:\n",
    "        assert Conv_net and coarse_com_mode, 'two_channel_input는 Conv_net이 True일 때만 가능'\n",
    "    if lc_adc_on == True:\n",
    "        assert coarse_com_mode and SAE_net, 'lc_adc_on은 coarse_com_mode와 SAE_net이 True일 때만 가능'\n",
    "    if converted_net_forward == True:\n",
    "        assert SAE_net == False, 'converted_net_forward는 SAE_net이 False일 때만 가능'\n",
    "    if conv1d_scaling:\n",
    "        assert Conv_net and coarse_com_mode and normalize_on\n",
    "    seed_assign(my_seed)\n",
    "    ## 함수 내 모든 로컬 변수 저장 ########################################################\n",
    "    hyperparameters = locals()\n",
    "    print(hyperparameters)\n",
    "    # JSON으로 저장\n",
    "    with open(f\"result_save/cluster_accuracy_history_{current_time}.json\", 'w') as f:\n",
    "        json.dump(hyperparameters, f, indent=4)\n",
    "    ######################################################################################\n",
    "\n",
    "    \n",
    "    wandb.config.update(hyperparameters)\n",
    "    wandb.run.name = f'{current_time}_SAE_net_{SAE_net}_v_threshold_{v_threshold}'\n",
    "    wandb.define_metric(\"best_mean_cluster_accuracy_post_training_cycle_all_dataset2\", summary=\"max\")\n",
    "\n",
    "\n",
    "    my_path_ground_BH = '/data2/spike_sorting/quiroga/BH/'\n",
    "\n",
    "\n",
    "    filename = [\"C_Easy1_noise005.mat\", \"C_Easy1_noise01.mat\", \"C_Easy1_noise015.mat\", \"C_Easy1_noise02.mat\",\n",
    "                \"C_Easy2_noise005.mat\", \"C_Easy2_noise01.mat\", \"C_Easy2_noise015.mat\", \"C_Easy2_noise02.mat\",\n",
    "                \"C_Difficult1_noise005.mat\", \"C_Difficult1_noise01.mat\", \"C_Difficult1_noise015.mat\", \"C_Difficult1_noise02.mat\",\n",
    "                \"C_Difficult2_noise005.mat\", \"C_Difficult2_noise01.mat\", \"C_Difficult2_noise015.mat\", \"C_Difficult2_noise02.mat\"]\n",
    "\n",
    "\n",
    "    spike_tot = [\"BH_Spike_e1n005.npy\", \"BH_Spike_e1n010.npy\", \"BH_Spike_e1n015.npy\", \"BH_Spike_e1n020.npy\",\n",
    "                \"BH_Spike_e2n005.npy\", \"BH_Spike_e2n010.npy\", \"BH_Spike_e2n015.npy\", \"BH_Spike_e2n020.npy\",\n",
    "                \"BH_Spike_d1n005.npy\", \"BH_Spike_d1n010.npy\", \"BH_Spike_d1n015.npy\", \"BH_Spike_d1n020.npy\",\n",
    "                \"BH_Spike_d2n005.npy\", \"BH_Spike_d2n010.npy\", \"BH_Spike_d2n015.npy\", \"BH_Spike_d2n020.npy\"]\n",
    "\n",
    "    label_tot = [\"BH_Label_e1n005.npy\", \"BH_Label_e1n010.npy\", \"BH_Label_e1n015.npy\", \"BH_Label_e1n020.npy\",\n",
    "                \"BH_Label_e2n005.npy\", \"BH_Label_e2n010.npy\", \"BH_Label_e2n015.npy\", \"BH_Label_e2n020.npy\",\n",
    "                \"BH_Label_d1n005.npy\", \"BH_Label_d1n010.npy\", \"BH_Label_d1n015.npy\", \"BH_Label_d1n020.npy\",\n",
    "                \"BH_Label_d2n005.npy\", \"BH_Label_d2n010.npy\", \"BH_Label_d2n015.npy\", \"BH_Label_d2n020.npy\"]\n",
    "\n",
    "    template =  [\"BH_Spike_TEMPLATE_e1n005.npy\", \"BH_Spike_TEMPLATE_e1n010.npy\", \"BH_Spike_TEMPLATE_e1n015.npy\", \"BH_Spike_TEMPLATE_e1n020.npy\",\n",
    "                \"BH_Spike_TEMPLATE_e2n005.npy\", \"BH_Spike_TEMPLATE_e2n010.npy\", \"BH_Spike_TEMPLATE_e2n015.npy\", \"BH_Spike_TEMPLATE_e2n020.npy\",\n",
    "                \"BH_Spike_TEMPLATE_d1n005.npy\", \"BH_Spike_TEMPLATE_d1n010.npy\", \"BH_Spike_TEMPLATE_d1n015.npy\", \"BH_Spike_TEMPLATE_d1n020.npy\",\n",
    "                \"BH_Spike_TEMPLATE_d2n005.npy\", \"BH_Spike_TEMPLATE_d2n010.npy\", \"BH_Spike_TEMPLATE_d2n015.npy\", \"BH_Spike_TEMPLATE_d2n020.npy\"]\n",
    "\n",
    "    AE_train_path_gt_detect = 'BH_quiroga_training_dataset_gt_detect.pt' \n",
    "    AE_test_path_gt_detect = 'BH_quiroga_test_dataset_gt_detect.pt'\n",
    "\n",
    "    AE_train_path_real_detect = 'BH_quiroga_training_dataset_real_detect.pt'\n",
    "    AE_test_path_real_detect = 'BH_quiroga_test_dataset_real_detect.pt'\n",
    "\n",
    "    AE_train_data = AE_train_path_real_detect #AE_train_path_gt_detect #AE_train_path_real_detect\n",
    "    AE_test_data = AE_test_path_real_detect #AE_test_path_gt_detect  #AE_test_path_real_detect\n",
    "\n",
    "    # thr_tot = np.array([0.5, 0.5, 0.55, 0.7, 0.5, 0.5, 0.55, 0.7, 0.5, 0.5, 0.55, 0.7, 0.5, 0.5, 0.55, 0.7])\n",
    "    cos_thr = np.array([0.95, 0.95, 0.95, 0.95, 0.95, 0.95, 0.95, 0.85, 0.95, 0.9, 0.8, 0.95, 0.95, 0.95, 0.95, 0.8])\n",
    "    # tem=10\n",
    "    # cos_thr = np.array([tem, tem, tem, tem, tem, tem, tem, tem, tem, tem, tem, tem, tem, tem, tem, tem, ])\n",
    "\n",
    "    print('cos_thr', cos_thr)\n",
    "    \n",
    "    os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\" \n",
    "    os.environ[\"CUDA_VISIBLE_DEVICES\"]= gpu\n",
    "\n",
    "\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "\n",
    "    if coarse_com_mode == True:\n",
    "        level_num = TIME\n",
    "        TIME = spike_length\n",
    "        spike_length = level_num\n",
    "        level_interval = (coarse_com_config[0] - coarse_com_config[1]) / (level_num-1)  # max - min\n",
    "        levels = [coarse_com_config[1] + level_interval * i for i in range(level_num)]\n",
    "        levels = torch.tensor(levels).to(torch.float).to(device)\n",
    "        levels = levels.repeat(TIME,1) \n",
    "        # print('levels', levels, levels.shape) # TIME, level_num\n",
    "\n",
    "    n_sample = spike_length\n",
    "\n",
    "    class spikedataset(Dataset):\n",
    "        def __init__(self, path, transform = None):    \n",
    "            self.transform = transform\n",
    "            self.spike = torch.load(path)\n",
    "            \n",
    "        def __getitem__(self, index):\n",
    "            spike = self.spike[index]            \n",
    "            if self.transform is not None:\n",
    "                spike = self.transform(spike)\n",
    "            return spike\n",
    "        \n",
    "        def __len__(self):\n",
    "            return len(self.spike)\n",
    "\n",
    "    train_dataset = spikedataset(my_path_ground_BH + AE_train_data)\n",
    "    train_loader = DataLoader(dataset = train_dataset, batch_size = batch_size, shuffle = True)\n",
    "\n",
    "    test_dataset = spikedataset(my_path_ground_BH + AE_test_data)\n",
    "    test_loader = DataLoader(dataset = test_dataset, batch_size = batch_size, shuffle = False)\n",
    "\n",
    "\n",
    "    # vth_mul_on = True # True False\n",
    "    # batch_norm_on = True # True False\n",
    "\n",
    "\n",
    "    # 모델 초기화\n",
    "    if SAE_net == False: # 여기서는 l2norm, lif bridge 둘 다 true면 l2norm먼저\n",
    "        assert two_channel_input == False\n",
    "\n",
    "        if Conv_net == True:\n",
    "            # input_channels = 2 if two_channel_input else 1\n",
    "            input_channels = TIME if coarse_com_mode else 1\n",
    "            if fusion_net == True:\n",
    "                assert False, '이거 맞음? 다시 확인'\n",
    "                net = FUSION_net_conv1(input_channels=input_channels, input_length=n_sample, encoder_ch = [32, 64, 96], fc_dim = lateral_feature_num, padding = 0, stride = 2, kernel_size = 3, \n",
    "                                    synapse_fc_trace_const1=1, \n",
    "                                    synapse_fc_trace_const2=v_decay, #안씀 \n",
    "                                    TIME=TIME, v_init=0.0, v_decay=v_decay, v_threshold=v_threshold, v_reset=v_reset, \n",
    "                                    sg_width=4.0, surrogate='sigmoid', BPTT_on=BPTT_on, need_bias=need_bias, lif_add_at_first=lif_add_at_first,\n",
    "                                    sae_l2_norm_bridge = sae_l2_norm_bridge, sae_lif_bridge = sae_lif_bridge, lif_add_at_last=lif_add_at_last, repeat_coding=repeat_coding).to(device)\n",
    "            else: \n",
    "                net = Autoencoder_conv1(input_channels=input_channels, input_length=n_sample, encoder_ch = [32, 64, 96], fc_dim = lateral_feature_num, padding = 0, stride = 2, kernel_size = 3, need_bias=need_bias, l2norm_bridge=sae_l2_norm_bridge, relu_bridge=sae_lif_bridge, activation_collector_on=False,\n",
    "                                        batch_norm_on=batch_norm_on, QCFS_neuron_on=QCFS_neuron_on).to(device)\n",
    "            net = torch.nn.DataParallel(net)\n",
    "            if converted_net_forward:\n",
    "                converted_net = SAE_converted_conv1(input_channels=input_channels, input_length=n_sample, encoder_ch = [32, 64, 96], fc_dim = lateral_feature_num, padding = 0, stride = 2, kernel_size = 3, \n",
    "                                    synapse_fc_trace_const1=1, \n",
    "                                    synapse_fc_trace_const2=v_decay, #안씀 \n",
    "                                    TIME=TIME, v_init=0.0, v_decay=v_decay, v_threshold=v_threshold, v_reset=v_reset, \n",
    "                                    sg_width=4.0, surrogate='sigmoid', BPTT_on=BPTT_on, need_bias=need_bias, lif_add_at_first=lif_add_at_first,\n",
    "                                    sae_l2_norm_bridge = sae_l2_norm_bridge, sae_lif_bridge = sae_lif_bridge, lif_add_at_last=lif_add_at_last,\n",
    "                                    vth_mul_on=vth_mul_on, batch_norm_on=batch_norm_on).to(device) # lif bridge는 무조건 들어가게 해놨음.\n",
    "                converted_net = torch.nn.DataParallel(converted_net)\n",
    "                print('converted_net', converted_net)\n",
    "        else:\n",
    "            n_sample = n_sample * TIME if coarse_com_mode else n_sample\n",
    "            net = Autoencoder_only_FC(encoder_ch=[400, lateral_feature_num], decoder_ch=[400,n_sample], n_sample=n_sample, need_bias=need_bias, l2norm_bridge=sae_l2_norm_bridge, relu_bridge=sae_lif_bridge, activation_collector_on=False,\n",
    "                                    batch_norm_on=batch_norm_on, QCFS_neuron_on=QCFS_neuron_on).to(device)\n",
    "            net = torch.nn.DataParallel(net)\n",
    "            if converted_net_forward:\n",
    "                converted_net = SAE_converted_fc(encoder_ch=[400, lateral_feature_num], \n",
    "                                    decoder_ch=[400, n_sample], \n",
    "                                    in_channels=n_sample, # in_channel 이 여기선 걍 lenght.\n",
    "                                    synapse_fc_trace_const1=1,\n",
    "                                    synapse_fc_trace_const2=v_decay,  #안씀 \n",
    "                                    TIME=TIME, v_init=0.0, v_decay=v_decay, v_threshold=v_threshold, v_reset=v_reset, \n",
    "                                    sg_width=4.0, surrogate='sigmoid', BPTT_on=BPTT_on, need_bias=need_bias, lif_add_at_first=lif_add_at_first,\n",
    "                                    sae_l2_norm_bridge = sae_l2_norm_bridge, sae_lif_bridge = sae_lif_bridge, lif_add_at_last=lif_add_at_last,\n",
    "                                    vth_mul_on=vth_mul_on, batch_norm_on=batch_norm_on).to(device) # lif bridge는 무조건 들어가게 해놨음.\n",
    "                converted_net = torch.nn.DataParallel(converted_net)\n",
    "                # print('converted_net', converted_net)\n",
    "    else:\n",
    "        if Conv_net == True: \n",
    "            input_channels = 1\n",
    "            input_channels = 2 if two_channel_input else 1\n",
    "            if fusion_net == True:  \n",
    "                assert coarse_com_mode == True\n",
    "                # net = SAE_FUSION2_net_conv1(input_channels=input_channels, input_length=n_sample, encoder_ch = [32, 64, 96], fc_dim = lateral_feature_num, padding = 0, stride = 2, kernel_size = 3, \n",
    "                #                     synapse_fc_trace_const1=1, \n",
    "                #                     synapse_fc_trace_const2=v_decay, #안씀 \n",
    "                #                     TIME=TIME, v_init=0.0, v_decay=v_decay, v_threshold=v_threshold, v_reset=v_reset, \n",
    "                #                     sg_width=4.0, surrogate='sigmoid', BPTT_on=BPTT_on, need_bias=need_bias, lif_add_at_first=lif_add_at_first,\n",
    "                #                     sae_l2_norm_bridge = sae_l2_norm_bridge, sae_lif_bridge = sae_lif_bridge, lif_add_at_last=lif_add_at_last, batch_norm_on=batch_norm_on, sae_relu_on=sae_relu_on).to(device)\n",
    "                # net = SAE_FUSION3_net_conv1(input_channels=input_channels, input_length=n_sample, encoder_ch = [32, 64, 96], fc_dim = lateral_feature_num, padding = 0, stride = 2, kernel_size = 3, \n",
    "                #                     synapse_fc_trace_const1=1, \n",
    "                #                     synapse_fc_trace_const2=v_decay, #안씀 \n",
    "                #                     TIME=TIME, v_init=0.0, v_decay=v_decay, v_threshold=v_threshold, v_reset=v_reset, \n",
    "                #                     sg_width=4.0, surrogate='sigmoid', BPTT_on=BPTT_on, need_bias=need_bias, lif_add_at_first=lif_add_at_first,\n",
    "                #                     sae_l2_norm_bridge = sae_l2_norm_bridge, sae_lif_bridge = sae_lif_bridge, lif_add_at_last=lif_add_at_last, batch_norm_on=batch_norm_on, sae_relu_on=sae_relu_on).to(device)\n",
    "                # net = SAE_FUSION4_net_conv1(input_channels=input_channels, input_length=n_sample, encoder_ch = [32, 64, 96], fc_dim = lateral_feature_num, padding = 0, stride = 2, kernel_size = 3, \n",
    "                #                     synapse_fc_trace_const1=1, \n",
    "                #                     synapse_fc_trace_const2=v_decay, #안씀 \n",
    "                #                     TIME=TIME, v_init=0.0, v_decay=v_decay, v_threshold=v_threshold, v_reset=v_reset, \n",
    "                #                     sg_width=4.0, surrogate='sigmoid', BPTT_on=BPTT_on, need_bias=need_bias, lif_add_at_first=lif_add_at_first,\n",
    "                #                     sae_l2_norm_bridge = sae_l2_norm_bridge, sae_lif_bridge = sae_lif_bridge, lif_add_at_last=lif_add_at_last, batch_norm_on=batch_norm_on, sae_relu_on=sae_relu_on).to(device)\n",
    "                # net = SAE_FUSION5_net_conv1(input_channels=input_channels, input_length=n_sample, encoder_ch = [32, 64, 96], fc_dim = lateral_feature_num, padding = 0, stride = 2, kernel_size = 3, \n",
    "                #                     synapse_fc_trace_const1=1, \n",
    "                #                     synapse_fc_trace_const2=v_decay, #안씀 \n",
    "                #                     TIME=TIME, v_init=0.0, v_decay=v_decay, v_threshold=v_threshold, v_reset=v_reset, \n",
    "                #                     sg_width=4.0, surrogate='sigmoid', BPTT_on=BPTT_on, need_bias=need_bias, lif_add_at_first=lif_add_at_first,\n",
    "                #                     sae_l2_norm_bridge = sae_l2_norm_bridge, sae_lif_bridge = sae_lif_bridge, lif_add_at_last=lif_add_at_last, batch_norm_on=batch_norm_on, sae_relu_on=sae_relu_on).to(device)\n",
    "                # net = SAE_FUSION6_net_conv1(input_channels=input_channels, input_length=n_sample, encoder_ch = [32, 64, 96], fc_dim = lateral_feature_num, padding = 0, stride = 2, kernel_size = 3, \n",
    "                #                     synapse_fc_trace_const1=1, \n",
    "                #                     synapse_fc_trace_const2=v_decay, #안씀 \n",
    "                #                     TIME=TIME, v_init=0.0, v_decay=v_decay, v_threshold=v_threshold, v_reset=v_reset, \n",
    "                #                     sg_width=4.0, surrogate='sigmoid', BPTT_on=BPTT_on, need_bias=need_bias, lif_add_at_first=lif_add_at_first,\n",
    "                #                     sae_l2_norm_bridge = sae_l2_norm_bridge, sae_lif_bridge = sae_lif_bridge, lif_add_at_last=lif_add_at_last, batch_norm_on=batch_norm_on, sae_relu_on=sae_relu_on).to(device)\n",
    "                net = SAE_FUSION7_net_conv1(input_channels=input_channels, input_length=n_sample, encoder_ch = [32, 64, 96], fc_dim = lateral_feature_num, padding = 0, stride = 2, kernel_size = 3, \n",
    "                                    synapse_fc_trace_const1=1, \n",
    "                                    synapse_fc_trace_const2=v_decay, #안씀 \n",
    "                                    TIME=TIME, v_init=0.0, v_decay=v_decay, v_threshold=v_threshold, v_reset=v_reset, \n",
    "                                    sg_width=4.0, surrogate='sigmoid', BPTT_on=BPTT_on, need_bias=need_bias, lif_add_at_first=lif_add_at_first,\n",
    "                                    sae_l2_norm_bridge = sae_l2_norm_bridge, sae_lif_bridge = sae_lif_bridge, lif_add_at_last=lif_add_at_last, batch_norm_on=batch_norm_on, sae_relu_on=sae_relu_on).to(device)\n",
    "            else:\n",
    "                net = SAE_conv1(input_channels=input_channels, input_length=n_sample, encoder_ch = [32, 64, 96], fc_dim = lateral_feature_num, padding = 0, stride = 2, kernel_size = 3, \n",
    "                                    synapse_fc_trace_const1=1, \n",
    "                                    synapse_fc_trace_const2=v_decay, #안씀 \n",
    "                                    TIME=TIME, v_init=0.0, v_decay=v_decay, v_threshold=v_threshold, v_reset=v_reset, \n",
    "                                    sg_width=4.0, surrogate='sigmoid', BPTT_on=BPTT_on, need_bias=need_bias, lif_add_at_first=lif_add_at_first,\n",
    "                                    sae_l2_norm_bridge = sae_l2_norm_bridge, sae_lif_bridge = sae_lif_bridge, lif_add_at_last=lif_add_at_last, batch_norm_on=batch_norm_on, sae_relu_on=sae_relu_on).to(device)\n",
    "            # net = SAE_conv1_DR(input_channels=input_channels, input_length=n_sample, encoder_ch = [32, 64, 96], fc_dim = lateral_feature_num, padding = 0, stride = 2, kernel_size = 3, \n",
    "            #                     synapse_fc_trace_const1=1, \n",
    "            #                     synapse_fc_trace_const2=v_decay, #안씀 \n",
    "            #                     TIME=TIME, v_init=0.0, v_decay=v_decay, v_threshold=v_threshold, v_reset=v_reset, \n",
    "            #                     sg_width=4.0, surrogate='sigmoid', BPTT_on=BPTT_on, need_bias=need_bias, lif_add_at_first=lif_add_at_first,\n",
    "            #                     sae_l2_norm_bridge = sae_l2_norm_bridge, sae_lif_bridge = sae_lif_bridge, lif_add_at_last=lif_add_at_last, batch_norm_on=batch_norm_on).to(device)\n",
    "            net = torch.nn.DataParallel(net)\n",
    "        else:\n",
    "            net = SAE_fc_only(encoder_ch=[400, lateral_feature_num], \n",
    "                                decoder_ch=[400, n_sample], \n",
    "                                in_channels=n_sample, # in_channel 이 여기선 걍 lenght.\n",
    "                                synapse_fc_trace_const1=1,\n",
    "                                synapse_fc_trace_const2=v_decay,  #안씀 \n",
    "                                TIME=TIME, v_init=0.0, v_decay=v_decay, v_threshold=v_threshold, v_reset=v_reset, \n",
    "                                sg_width=4.0, surrogate='sigmoid', BPTT_on=BPTT_on, need_bias=need_bias, lif_add_at_first=lif_add_at_first,\n",
    "                                sae_l2_norm_bridge = sae_l2_norm_bridge, sae_lif_bridge = sae_lif_bridge, lif_add_at_last=lif_add_at_last, batch_norm_on=batch_norm_on, sae_relu_on=sae_relu_on).to(device)\n",
    "            net = torch.nn.DataParallel(net)\n",
    "\n",
    "    # net = torch.load('/home/bhkim003/github_folder/ByeonghyeonKim/my_snn/net_save/save_now_net_AE_re_e7000.pth')\n",
    "    # net = torch.load('/home/bhkim003/github_folder/ByeonghyeonKim/my_snn/net_save/save_now_net_20250101_210938_786.pth')\n",
    "    # load했으면 torch.nn.DataParallel 하지마\n",
    "    # net.module.load_state_dict(torch.load('/home/bhkim003/github_folder/ByeonghyeonKim/my_snn/net_save/save_now_net_annbase_20250108_210641_941.pth'))\n",
    "    if pretrained_net != None:\n",
    "        ######################## 모델이 달라서 dict로 weight만 넣고싶을 때\n",
    "        # # 저장된 가중치 로드\n",
    "        saved_state_dict = torch.load(pretrained_net)\n",
    "        current_state_dict = net.module.state_dict()\n",
    "\n",
    "        # 함수 호출로 가중치 매핑\n",
    "        updated_state_dict = map_and_load_weights(saved_state_dict, current_state_dict)\n",
    "\n",
    "        # 업데이트된 state_dict를 네트워크에 로드\n",
    "        net.module.load_state_dict(updated_state_dict)\n",
    "        ######################## 모델이 달라서 dict로 weight만 넣고싶을 때\n",
    "\n",
    "        ############## 일반적일 때\n",
    "        # net.module.load_state_dict(torch.load(pretrained_net))\n",
    "        ############## 일반적일 때\n",
    "    \n",
    "        # pre_net = Autoencoder_conv1(input_channels=input_channels, input_length=n_sample, encoder_ch = [32, 64, 96], fc_dim = lateral_feature_num, padding = 0, stride = 2, kernel_size = 3, need_bias=need_bias, l2norm_bridge=sae_l2_norm_bridge, relu_bridge=sae_lif_bridge, activation_collector_on=False,\n",
    "        #                         batch_norm_on=batch_norm_on, QCFS_neuron_on=False).to(device)\n",
    "        # pre_net = torch.nn.DataParallel(net)\n",
    "        # pre_net.module.load_state_dict(torch.load(pretrained_net))\n",
    "        # copy_weights(pre_net.module.encoder , net.module.encoder )\n",
    "        # copy_weights(pre_net.module.decoder , net.module.decoder  )\n",
    "\n",
    "        \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    wandb.watch(net, log=\"all\", log_freq = 10)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    if SAE_net == True:\n",
    "        assert 'SAE' in net.module.__class__.__name__\n",
    "\n",
    "\n",
    "\n",
    "    net = net.to(device)\n",
    "    print(f\"Total number of encoder parameters: {sum(p.numel() for p in net.module.encoder.parameters())}\")\n",
    "    print(net)\n",
    "    print('Device:',device)\n",
    "\n",
    "    \n",
    "    if optimizer == 'Adam':\n",
    "        optimizer = optim.Adam(net.parameters(), lr=learning_rate)\n",
    "    elif optimizer == 'SGD':\n",
    "        optimizer = optim.SGD(net.parameters(), lr = learning_rate, momentum = 0.9)\n",
    "    else:\n",
    "        assert False, 'optimizer를 잘못 입력했습니다.'\n",
    "        \n",
    "    loss_history = []\n",
    "    mean_cluster_accuracy_during_training_cycle_all_dataset_history = []\n",
    "    mean_cluster_accuracy_post_training_cycle_all_dataset_history = []\n",
    "    mean_cluster_accuracy_total_all_dataset_history = []\n",
    "\n",
    "    tau = np.zeros(num_cluster)\n",
    "\n",
    "    print(f\"\\nStart Training, current_time = {current_time}\")\n",
    "    mean_cluster_accuracy_post_training_cycle_all_dataset = 0\n",
    "    best_mean_cluster_accuracy_post_training_cycle_all_dataset = 0\n",
    "\n",
    "    if SAE_net == True:\n",
    "        assert 'SAE' in net.module.__class__.__name__\n",
    "        \n",
    "    k_means_acc_best = 0\n",
    "    min_loss = 9999999\n",
    "    min_loss_normal = 9999999\n",
    "    min_loss_coarse = 9999999\n",
    "    for epoch in range(max_epoch):\n",
    "        print()\n",
    "        l2_loss_bin= 0\n",
    "        ae_train_start_time = time.time()\n",
    "        running_loss = 0.0\n",
    "        running_loss_normal = 0.0\n",
    "        running_loss_coarse = 0.0\n",
    "        iter = 0\n",
    "        net.train()\n",
    "        # if True or max_epoch != 1:\n",
    "        wrong_element_sum = 0\n",
    "        same_data_num = 0\n",
    "        total_data_num = 0\n",
    "        if max_epoch != 1:\n",
    "            for data in train_loader:\n",
    "                optimizer.zero_grad()\n",
    "                total_data_num += len(data)\n",
    "                data = data.to(device)\n",
    "                scaling = (level_num-3)/level_num if conv1d_scaling else 1.0\n",
    "                data = zero_to_one_normalize_features(data, level_num=quantize_level_num, coarse_com_config=coarse_com_config, scaling=scaling, norm01=norm01) if normalize_on else data\n",
    "                # plot_origin_spike(data[0].cpu().detach().numpy(), min_max_y_on = True)\n",
    "                # plot_origin_spike(data[1].cpu().detach().numpy(), min_max_y_on = True)\n",
    "                spike_backup = data\n",
    "                spike = data\n",
    "                spike = spike.to(device) # batch, feature\n",
    "                spike_for_fusion2_net = spike\n",
    "                if coarse_com_mode == True and 'SAE' in net.module.__class__.__name__:\n",
    "                    # print(spike[0])\n",
    "                    spike = spike.unsqueeze(2).repeat(1, 1, level_num) # spike_length == level_num # (batch, time, feature)로 변환 \n",
    "                    spike = (spike > levels).to(torch.float) \n",
    "\n",
    "                    spike = (spike == 0).cumsum(dim=-1).eq(1).to(torch.float) if lc_adc_on == True else spike\n",
    "\n",
    "                    # spike: batch, time, level_num\n",
    "                    # levels: time, level_num\n",
    "                    if Conv_net == True:\n",
    "                        spike = spike.unsqueeze(-2) # batch, time, in_channel, feature or batch in_channel,feature\n",
    "                        if two_channel_input == True:\n",
    "                            spike_backup = spike_backup.to(device)\n",
    "                            spike_backup = spike_backup.unsqueeze(2).repeat(1, 1, level_num) # spike_length == level_num # (batch, time, feature)로 변환 \n",
    "                            spike_backup = (spike_backup <= levels).to(torch.float) \n",
    "                            spike_backup = (spike_backup == 1).cumsum(dim=-1).eq(1).to(torch.float) if lc_adc_on == True else spike_backup\n",
    "                            spike_backup = spike_backup.unsqueeze(-2)\n",
    "                            spike = torch.cat((spike, spike_backup), dim=-2)\n",
    "                    assert spike.shape[0] == batch_size and spike.shape[1] == TIME\n",
    "                elif 'SAE' in net.module.__class__.__name__:\n",
    "                    spike = spike.unsqueeze(-1).repeat(1, 1, TIME).permute(0,2,1) # (batch, time, feature)로 변환\n",
    "                    if Conv_net == True:\n",
    "                        spike = spike.unsqueeze(-2) # batch, time, in_channel, feature or batch in_channel,feature\n",
    "                else:\n",
    "                    if Conv_net == True:\n",
    "                        if coarse_com_mode == False:\n",
    "                            spike = spike.unsqueeze(-2) #batch in_channel,feature\n",
    "                        else:\n",
    "                            spike = spike.unsqueeze(2).repeat(1, 1, level_num) # spike_length == level_num # (batch, time, feature)로 변환 \n",
    "                            spike = (spike > levels).to(torch.float) \n",
    "\n",
    "                            spike = (spike == 0).cumsum(dim=-1).eq(1).to(torch.float) if lc_adc_on == True else spike\n",
    "\n",
    "                    else:\n",
    "                        if coarse_com_mode == False:\n",
    "                            pass\n",
    "                        else:\n",
    "                            spike = spike.unsqueeze(2).repeat(1, 1, level_num) # spike_length == level_num # (batch, time, feature)로 변환 \n",
    "                            spike = (spike > levels).to(torch.float) \n",
    "\n",
    "                            spike = (spike == 0).cumsum(dim=-1).eq(1).to(torch.float) if lc_adc_on == True else spike\n",
    "\n",
    "                            # spike: batch, time, feature\n",
    "                            spike = spike.reshape(spike.shape[0], -1)\n",
    "\n",
    "                    \n",
    "\n",
    "\n",
    "                    # if fusion_net == True:\n",
    "                    #     spike = spikegen.rate(spike, num_steps=TIME).transpose(0, 1)\n",
    "\n",
    "                # spike_class = net(spike) # batch, time, feature\n",
    "                encoded_spike = net.module.encoder(spike)\n",
    "                spike_class = net.module.decoder(encoded_spike)\n",
    "\n",
    "                # for i in range (2):\n",
    "                #     plot_spike(spike[i,:,0,:].cpu().numpy())\n",
    "                #     # plot_spike(spike[i,:,1,:].cpu().numpy())\n",
    "                #     plot_origin_spike(spike_class.squeeze()[i].cpu().detach().numpy(), min_max_y_on = True)\n",
    "                # assert False\n",
    "                        \n",
    "\n",
    "                loss = 0\n",
    "                loss_normal = torch.tensor(0.0)\n",
    "                loss_coarse = torch.tensor(0.0)\n",
    "                if coarse_com_mode == True and 'SAE' in net.module.__class__.__name__:\n",
    "                    criterion = nn.MSELoss().to(device)\n",
    "                    # loss1 = nn.MSELoss()(spike_class[..., 5:25], spike[..., 5:25])\n",
    "                    # loss2 = nn.MSELoss()(spike_class[..., 0:5], spike[..., 0:5])\n",
    "                    # loss3 = nn.MSELoss()(spike_class[..., 25:spike_length], spike[..., 25:spike_length])\n",
    "                    # loss = loss1 * 2.125 + (loss2 + loss3)/4\n",
    "\n",
    "                    # loss1 = nn.MSELoss()(spike_class[..., 5:25, :], spike[..., 5:25, :])\n",
    "                    # loss2 = nn.MSELoss()(spike_class[..., 0:5, :], spike[..., 0:5, :])\n",
    "                    # loss3 = nn.MSELoss()(spike_class[..., 25:spike_length, :], spike[..., 25:spike_length, :])\n",
    "                    # loss = loss1 * 2.125 + (loss2 + loss3)/4\n",
    "                    if fusion_net:\n",
    "                        # print('1', spike.shape) # batch, time, in_channel, feature [32, 50, 1, 50]\n",
    "                        \n",
    "                        # ### coarse에서 ann loss 만들기 ######\n",
    "                        # spike = spike.squeeze()\n",
    "                        # assert two_channel_input == False\n",
    "                        # zero_mask = (spike == 0)  # 0이 있는 위치\n",
    "                        # first_zero_idx = torch.where(zero_mask, torch.arange(spike.shape[-1]).to(device), spike.shape[-1]-1).min(dim=-1).values\n",
    "                        # spike = levels[0][first_zero_idx]\n",
    "                        # # plot_origin_spike(spike[0].cpu().detach().numpy())\n",
    "                        # ### coarse에서 ann loss 만들기 ######\n",
    "\n",
    "                        ### 그냥 원래 스파이크로 ann loss 만들기 ######\n",
    "                        spike = spike_for_fusion2_net\n",
    "                        ### 그냥 원래 스파이크로 ann loss 만들기 ######\n",
    "\n",
    "                        spike = spike.squeeze()\n",
    "                        spike_class = spike_class.squeeze()\n",
    "                        \n",
    "                        ### normal loss################\n",
    "                        # loss = criterion(spike_class, spike)\n",
    "                        ### normal loss################\n",
    "                        \n",
    "                        ### chan loss################\n",
    "                        loss1 = criterion(spike_class[..., 5:25], spike[..., 5:25])\n",
    "                        loss2 = criterion(spike_class[..., 0:5], spike[..., 0:5])\n",
    "                        loss3 = criterion(spike_class[..., 25:], spike[..., 25:])\n",
    "                        loss = loss1 * 2.125 + (loss2 + loss3)/4\n",
    "                        ### chan loss################\n",
    "\n",
    "\n",
    "                        # #########################################\n",
    "                        # # 손실 함수 정의 (예: MSELoss 사용)\n",
    "                        # criterion_joke = torch.nn.MSELoss(reduction='none')  # 개별 요소별 손실을 유지\n",
    "\n",
    "                        # # 손실 계산\n",
    "                        # loss1_joke = criterion_joke(spike_class[..., 5:25], spike[..., 5:25]).mean(dim=-1)  # (batch,)\n",
    "                        # loss2_joke = criterion_joke(spike_class[..., 0:5], spike[..., 0:5]).mean(dim=-1)    # (batch,)\n",
    "                        # loss3_joke = criterion_joke(spike_class[..., 25:], spike[..., 25:]).mean(dim=-1)    # (batch,)\n",
    "\n",
    "                        # # 주어진 가중치를 적용한 최종 손실\n",
    "                        # loss_joke = loss1_joke * 2.125 + (loss2_joke + loss3_joke) / 4  # (batch,)\n",
    "\n",
    "                        # # 가장 큰 손실을 갖는 샘플의 인덱스 찾기\n",
    "                        # max_loss_idx_joke = torch.argmax(loss_joke)\n",
    "\n",
    "                        # # 해당 샘플 선택\n",
    "                        # selected_sample_class = spike_class[max_loss_idx_joke]\n",
    "                        # selected_sample_spike = spike[max_loss_idx_joke]\n",
    "\n",
    "                        # # 선택한 샘플의 손실 값 출력\n",
    "                        # print(\"Index of max loss sample:\", max_loss_idx_joke.item())\n",
    "                        # print(\"Max loss value:\", loss_joke[max_loss_idx_joke].item())\n",
    "                        # mean_loss_joke = loss_joke.mean().item()\n",
    "                        # print(\"Mean loss across the batch:\", mean_loss_joke)\n",
    "\n",
    "                        # # 선택한 샘플을 시각화\n",
    "                        # plot_origin_spike(selected_sample_class.cpu().detach().numpy())\n",
    "                        # plot_origin_spike(selected_sample_spike.cpu().detach().numpy())\n",
    "                        # #########################################\n",
    "\n",
    "                        # coarse loss ######################################################\n",
    "                        loss_normal = criterion(spike_class, spike)\n",
    "                        level_num_in_loss = spike_length\n",
    "                        level_interval = (coarse_com_config[0] - coarse_com_config[1]) / (level_num_in_loss-1)  # max - min\n",
    "                        levels = [coarse_com_config[1] + level_interval * i for i in range(level_num_in_loss)]\n",
    "                        levels = torch.tensor(levels).to(torch.float).to(device)\n",
    "                        # print('coarse leves', levels)\n",
    "                        levels = levels.repeat(spike_length,1) \n",
    "\n",
    "                        spike = spike.squeeze()\n",
    "                        spike_class = spike_class.squeeze()\n",
    "                        # plot_origin_spike(spike_class[0].cpu().detach().numpy())\n",
    "                        spike = spike.unsqueeze(2).repeat(1, 1, level_num_in_loss) \n",
    "                        spike = (spike > levels).to(torch.float) \n",
    "                        spike_class = spike_class.unsqueeze(2).repeat(1, 1, level_num_in_loss) \n",
    "                        spike_class = (spike_class > levels).to(torch.float) \n",
    "                        # spike = spike[..., 0:-3, :]\n",
    "                        # spike_class = spike_class[..., 0:-3, :]\n",
    "                        loss_coarse = criterion(spike_class, spike)\n",
    "                        wrong_element_sum += torch.sum(torch.abs(spike - spike_class)).item() \n",
    "\n",
    "                        # plot_spike(spike_class[0].cpu().detach().numpy())\n",
    "                        # assert False\n",
    "                        # coarse loss ######################################################\n",
    "                    else:\n",
    "                        spike = spike.squeeze()\n",
    "                        spike_class = spike_class.squeeze()\n",
    "                        loss = criterion(spike_class, spike)\n",
    "\n",
    "                    for iii in range(spike.shape[0]):\n",
    "                        same_data_num = same_data_num + 1 if torch.eq(spike[iii], spike_class[iii]).all() else same_data_num\n",
    "                    wrong_element_sum += torch.sum(torch.abs(spike - spike_class)).item() \n",
    "\n",
    "                    # spike = spike.squeeze()\n",
    "                    # spike_class = spike_class.squeeze()\n",
    "                    # plot_spike(spike[0].cpu().detach().numpy())\n",
    "                    # plot_spike(spike_class[0].cpu().detach().numpy())\n",
    "                    # print('손실 절대값 합',np.sum(np.abs(spike[0].cpu().detach().numpy() - spike_class[0].cpu().detach().numpy())))\n",
    "                    # # assert False\n",
    "                elif 'SAE' in net.module.__class__.__name__:\n",
    "                    criterion = nn.MSELoss().to(device)\n",
    "                    loss1 = criterion(spike_class[..., 5:25], spike[..., 5:25])\n",
    "                    loss2 = criterion(spike_class[..., 0:5], spike[..., 0:5])\n",
    "                    loss3 = criterion(spike_class[..., 25:spike_length], spike[..., 25:spike_length])\n",
    "                    loss = loss1 * 2.125 + (loss2 + loss3)/4\n",
    "                    assert spike_length > 25, 'spike_length가 25보다 작음'\n",
    "                    # wrong_element_sum += torch.sum(torch.abs(spike - spike_class)).item() \n",
    "                else:\n",
    "                    criterion = nn.MSELoss().to(device)\n",
    "                    loss1 = criterion(spike_class[..., 5:25], spike[..., 5:25])\n",
    "                    loss2 = criterion(spike_class[..., 0:5], spike[..., 0:5])\n",
    "                    loss3 = criterion(spike_class[..., 25:spike_length], spike[..., 25:spike_length])\n",
    "                    loss = loss1 * 2.125 + (loss2 + loss3)/4\n",
    "                    assert spike_length > 25, 'spike_length가 25보다 작음'\n",
    "                    # wrong_element_sum += torch.sum(torch.abs(spike - spike_class)).item() \n",
    "\n",
    "\n",
    "                    if l2_norm_loss_weight > 0:\n",
    "                        assert len(encoded_spike.shape) == 2, 'time 성분 없는 걸로'\n",
    "                        l2_loss = l2_norm_loss(encoded_spike, target_norm=1.0)  # L2Norm Loss 계산, l2 1.0되게.\n",
    "                        loss = loss + l2_loss*l2_norm_loss_weight\n",
    "                        l2_loss_bin += l2_loss.item()\n",
    "\n",
    "                    # coarse loss ######################################################\n",
    "                    loss_normal = criterion(spike_class, spike)\n",
    "                    level_num_in_loss = quantize_level_num\n",
    "                    level_interval = (coarse_com_config[0] - coarse_com_config[1]) / (level_num_in_loss-1)  # max - min\n",
    "                    levels = [coarse_com_config[1] + level_interval * i for i in range(level_num_in_loss)]\n",
    "                    levels = torch.tensor(levels).to(torch.float).to(device)\n",
    "                    levels = levels.repeat(spike_length,1) \n",
    "\n",
    "                    spike = spike.squeeze()\n",
    "                    spike_class = spike_class.squeeze()\n",
    "                    # plot_origin_spike(spike_class[0].cpu().detach().numpy())\n",
    "                    spike = spike.unsqueeze(2).repeat(1, 1, level_num_in_loss) \n",
    "                    spike = (spike > levels).to(torch.float) \n",
    "                    spike_class = spike_class.unsqueeze(2).repeat(1, 1, level_num_in_loss) \n",
    "                    spike_class = (spike_class > levels).to(torch.float) \n",
    "                    # spike = spike[..., 0:-3, :]\n",
    "                    # spike_class = spike_class[..., 0:-3, :]\n",
    "                    loss_coarse = criterion(spike_class, spike)\n",
    "                    wrong_element_sum += torch.sum(torch.abs(spike - spike_class)).item() \n",
    "\n",
    "                    # plot_spike(spike_class[0].cpu().detach().numpy())\n",
    "                    # assert False\n",
    "                    # coarse loss ######################################################\n",
    "\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                running_loss += loss.item()\n",
    "                running_loss_normal += loss_normal.item()\n",
    "                running_loss_coarse += loss_coarse.item()\n",
    "                # print(f'\\nepoch-{epoch}, running_loss : {running_loss:.5f}, iter percent {iter/len(train_loader)*100:.2f}%')\n",
    "                iter += 1\n",
    "        else:\n",
    "            print('\\n\\n\\n max_epoch 1이면 Train 안함!!!!!!!!!!!!!!!!!!!!!')\n",
    "        if l2_norm_loss_weight > 0:\n",
    "            print('l2_loss_bin', l2_loss_bin/len(train_loader))\n",
    "        avg_loss = running_loss / len(train_loader)\n",
    "        assert not np.isnan(avg_loss), f\"Error: avg_loss is NaN! Running loss: {running_loss}, Length of train_loader: {len(train_loader)}\"\n",
    "        loss_history.append((epoch, avg_loss))\n",
    "        min_loss = min(min_loss, avg_loss)\n",
    "        min_loss_normal = min(min_loss_normal, running_loss_normal/len(train_loader))\n",
    "        min_loss_coarse = min(min_loss_coarse, running_loss_coarse/len(train_loader))\n",
    "        print(f'\\nepoch-{epoch} loss : {avg_loss:.8f}, loss_normal : {running_loss_normal/len(train_loader):.8f}, loss_coarse : {running_loss_coarse/len(train_loader):.8f}, min_loss : {min_loss:.8f}, min_loss_normal : {min_loss_normal:.8f}, min_loss_coarse : {min_loss_coarse:.8f}, wrong_element_sum : {wrong_element_sum:.8f}, same_data : {100*same_data_num/(total_data_num+1e-12):.2f}%')\n",
    "        print(f\"ae train 실행 시간: {time.time()-ae_train_start_time:.3f}초, 전체 시작 시간 {current_time}\")\n",
    "\n",
    "        # plot_activation_distribution(net)\n",
    "\n",
    "        if SAE_net == False and converted_net_forward == True:\n",
    "            source_encoder = net.module.encoder \n",
    "            target_encoder = converted_net.module.encoder  \n",
    "            copy_weights(source_encoder, target_encoder)\n",
    "\n",
    "        cluster_accuracy_during_training_cycle_all_dataset = np.zeros(dataset_num)\n",
    "        cluster_accuracy_post_training_cycle_all_dataset = np.zeros(dataset_num)\n",
    "        cluster_accuracy_total_all_dataset = np.zeros(dataset_num)    \n",
    "\n",
    "        k_means_acc = 0\n",
    "        converted_k_means_acc = 0\n",
    "        if(epoch % accuracy_check_epoch_term == 0 or epoch == 1 or epoch == max_epoch-1): \n",
    "            accuracy_check_start_time = time.time()\n",
    "            print(f'\\nepoch-{epoch} accuracy check')\n",
    "            k_means_bin_origin_feature = []\n",
    "            k_means_bin = []\n",
    "            converted_k_means_bin = []\n",
    "            for ds in range(dataset_num):\n",
    "                # print('\\n', spike_tot[ds])\n",
    "\n",
    "                spike_template = np.load(my_path_ground_BH + template[ds])\n",
    "                spike = np.load(my_path_ground_BH + spike_tot[ds])\n",
    "                label = np.load(my_path_ground_BH + label_tot[ds])\n",
    "                spike_template = torch.from_numpy(spike_template).to(device)\n",
    "                spike = torch.from_numpy(spike).to(device)\n",
    "                scaling = (level_num-3)/level_num if conv1d_scaling else 1.0\n",
    "                spike_template = zero_to_one_normalize_features(spike_template, level_num=quantize_level_num, coarse_com_config=coarse_com_config, scaling=scaling, norm01=norm01) if normalize_on else spike_template\n",
    "                spike = zero_to_one_normalize_features(spike, level_num=quantize_level_num, coarse_com_config=coarse_com_config, scaling=scaling, norm01=norm01) if normalize_on else spike\n",
    "                \n",
    "                hidden_size = lateral_feature_num*TIME if 'SAE' in net.module.__class__.__name__ and SAE_hidden_nomean == True and fusion_net == False or 'SAE_FUSION5' in net.module.__class__.__name__ else lateral_feature_num\n",
    "                hidden_size = lateral_feature_num if '_DR' in net.module.__class__.__name__  else hidden_size\n",
    "\n",
    "                Cluster = np.zeros((num_cluster, hidden_size))\n",
    "                assert Cluster.shape[-1] == hidden_size, '이거 hidden dim 4 아니게 할 거면 잘 바꿔라'\n",
    "                \n",
    "\n",
    "\n",
    "                net.eval()\n",
    "                with torch.no_grad():\n",
    "                    spike_torch = spike_template.float()\n",
    "                    spike_torch = spike_torch[:num_cluster]\n",
    "                    spike_backup = spike_torch\n",
    "                    spike_torch = spike_torch.to(device)\n",
    "                    if coarse_com_mode == True and 'SAE' in net.module.__class__.__name__:\n",
    "                        spike_torch = spike_torch.unsqueeze(2).repeat(1, 1, level_num) # spike_length == level_num # (batch, time, feature)로 변환 \n",
    "                        spike_torch = (spike_torch > levels).to(torch.float) \n",
    "                        spike_torch = (spike_torch == 0).cumsum(dim=-1).eq(1).to(torch.float) if lc_adc_on == True else spike_torch\n",
    "                        if Conv_net == True:\n",
    "                            spike_torch = spike_torch.unsqueeze(-2) # batch, time, in_channel, feature or batch in_channel,feature\n",
    "                            if two_channel_input == True:\n",
    "                                spike_backup = spike_backup.to(device)\n",
    "                                spike_backup = spike_backup.unsqueeze(2).repeat(1, 1, level_num) # spike_length == level_num # (batch, time, feature)로 변환 \n",
    "                                spike_backup = (spike_backup <= levels).to(torch.float) \n",
    "                                spike_backup = (spike_backup == 1).cumsum(dim=-1).eq(1).to(torch.float) if lc_adc_on == True else spike_backup\n",
    "                                spike_backup = spike_backup.unsqueeze(-2) # batch, time, in_channel, feature\n",
    "                                spike_torch = torch.cat((spike_torch, spike_backup), dim=-2)\n",
    "                    elif 'SAE' in net.module.__class__.__name__:\n",
    "                        spike_torch = spike_torch.unsqueeze(1).repeat(1, TIME, 1) # (batch, time, feature)로 변환\n",
    "                        if Conv_net == True:\n",
    "                            spike_torch = spike_torch.unsqueeze(-2) # batch, time, in_channel, feature or batch in_channel,feature\n",
    "                    else:\n",
    "                        # if Conv_net == True:\n",
    "                        #     spike_torch = spike_torch.unsqueeze(-2) #batch in_channel,feature\n",
    "                        if Conv_net == True:\n",
    "                            if coarse_com_mode == False:\n",
    "                                spike_torch = spike_torch.unsqueeze(-2) #batch in_channel,feature\n",
    "                            else:\n",
    "                                spike_torch = spike_torch.unsqueeze(2).repeat(1, 1, level_num) # spike_length == level_num # (batch, time, feature)로 변환 \n",
    "                                spike_torch = (spike_torch > levels).to(torch.float) \n",
    "\n",
    "                                spike_torch = (spike_torch == 0).cumsum(dim=-1).eq(1).to(torch.float) if lc_adc_on == True else spike_torch\n",
    "\n",
    "                        else:\n",
    "                            if coarse_com_mode == False:\n",
    "                                pass\n",
    "                            else:\n",
    "                                spike_torch = spike_torch.unsqueeze(2).repeat(1, 1, level_num) # spike_length == level_num # (batch, time, feature)로 변환 \n",
    "                                spike_torch = (spike_torch > levels).to(torch.float) \n",
    "\n",
    "                                spike_torch = (spike_torch == 0).cumsum(dim=-1).eq(1).to(torch.float) if lc_adc_on == True else spike_torch\n",
    "\n",
    "                                # spike: batch, time, feature\n",
    "                                spike_torch = spike_torch.reshape(spike_torch.shape[0], -1)\n",
    "\n",
    "                        if converted_net_forward == True:\n",
    "                            spike_torch_spikegen = spikegen.rate(spike_torch, num_steps=TIME).transpose(0, 1)\n",
    "                        # if fusion_net == True:\n",
    "                        #     spike_torch = spikegen.rate(spike_torch, num_steps=TIME).transpose(0, 1)\n",
    "                    ### forward #######################################################\n",
    "                    inner_inf = net.module.encoder(spike_torch)\n",
    "                    if SAE_net == False and converted_net_forward == True:\n",
    "                        converted_inner_inf = converted_net.module.encoder(spike_torch_spikegen)\n",
    "                    ### forward #######################################################\n",
    "\n",
    "                    # if ds % 4 == 0:\n",
    "                    #     for i in range(4):\n",
    "                    #         decoded = net.module.decoder(inner_inf).squeeze()\n",
    "                    #         plot_spike(spike_torch[i,:,:].cpu().numpy())\n",
    "                    #         plot_spike(inner_inf[i,:].cpu().numpy())\n",
    "                    #         # plot_origin_spike(net.module.decoder(inner_inf)[i,:].cpu().numpy())\n",
    "                    #         plot_origin_spike(decoded[i].cpu().numpy(), min_max_y_on = True)\n",
    "                        \n",
    "                    # if 'SAE' in net.module.__class__.__name__:\n",
    "                    #     tensors = [inner_inf[0][i] for i in range(TIME)] \n",
    "                    #     all_equal = all(torch.equal(tensors[0], t) for t in tensors)\n",
    "                    #     print(all_equal, inner_inf)\n",
    "\n",
    "                    if 'SAE' in net.module.__class__.__name__:\n",
    "                        if SAE_hidden_nomean == True:\n",
    "                            inner_inf = inner_inf.reshape(inner_inf.shape[0],-1)# time*feature 펼치기\n",
    "                        else:\n",
    "                            inner_inf = inner_inf.mean(dim=1)# Time 방향으로 평균\n",
    "                        # inner_inf = F.normalize(inner_inf, p=2, dim=1)\n",
    "                    Cluster = inner_inf.cpu().detach().numpy()\n",
    "\n",
    "                encoder_batch = 128\n",
    "                spike_hidden = np.zeros((len(spike), hidden_size))\n",
    "                converted_spike_hidden = np.zeros((len(spike), hidden_size))\n",
    "                net.eval()\n",
    "                with torch.no_grad():\n",
    "                    now_index = 0\n",
    "                    while (1):\n",
    "                        now_end_index = now_index+encoder_batch if now_index+encoder_batch < len(spike) else len(spike)\n",
    "                        spike_batch = spike[now_index:now_end_index] \n",
    "                        spike_torch = spike_batch\n",
    "                        spike_torch = spike_torch.float()\n",
    "                        spike_backup = spike_torch\n",
    "                        spike_torch = spike_torch.to(device)\n",
    "                        if coarse_com_mode == True and 'SAE' in net.module.__class__.__name__:\n",
    "                            spike_torch = spike_torch.unsqueeze(2).repeat(1, 1, level_num) # spike_length == level_num # (batch, time, feature)로 변환 \n",
    "                            spike_torch = (spike_torch > levels).to(torch.float) \n",
    "                            spike_torch = (spike_torch == 0).cumsum(dim=-1).eq(1).to(torch.float) if lc_adc_on == True else spike_torch\n",
    "                            if Conv_net == True:\n",
    "                                spike_torch = spike_torch.unsqueeze(-2) # batch, time, in_channel, feature or batch in_channel,feature\n",
    "                                if two_channel_input == True:\n",
    "                                    spike_backup = spike_backup.to(device)\n",
    "                                    spike_backup = spike_backup.unsqueeze(2).repeat(1, 1, level_num) # spike_length == level_num # (batch, time, feature)로 변환 \n",
    "                                    spike_backup = (spike_backup <= levels).to(torch.float) \n",
    "                                    spike_backup = (spike_backup == 1).cumsum(dim=-1).eq(1).to(torch.float) if lc_adc_on == True else spike_backup\n",
    "                                    spike_backup = spike_backup.unsqueeze(-2)\n",
    "                                    spike_torch = torch.cat((spike_torch, spike_backup), dim=-2)\n",
    "                        elif 'SAE' in net.module.__class__.__name__:\n",
    "                            spike_torch = spike_torch.unsqueeze(1).repeat(1, TIME, 1) # (batch, time, feature)로 변환\n",
    "                            if Conv_net == True:\n",
    "                                spike_torch = spike_torch.unsqueeze(-2) # batch, time, in_channel, feature or batch in_channel,feature\n",
    "                        else:\n",
    "                            # if Conv_net == True:\n",
    "                            #     spike_torch = spike_torch.unsqueeze(-2) #batch in_channel,feature\n",
    "                            if Conv_net == True:\n",
    "                                if coarse_com_mode == False:\n",
    "                                    spike_torch = spike_torch.unsqueeze(-2) #batch in_channel,feature\n",
    "                                else:\n",
    "                                    spike_torch = spike_torch.unsqueeze(2).repeat(1, 1, level_num) # spike_length == level_num # (batch, time, feature)로 변환 \n",
    "                                    spike_torch = (spike_torch > levels).to(torch.float) \n",
    "\n",
    "                                    spike_torch = (spike_torch == 0).cumsum(dim=-1).eq(1).to(torch.float) if lc_adc_on == True else spike_torch\n",
    "\n",
    "                            else:\n",
    "                                if coarse_com_mode == False:\n",
    "                                    pass\n",
    "                                else:\n",
    "                                    spike_torch = spike_torch.unsqueeze(2).repeat(1, 1, level_num) # spike_length == level_num # (batch, time, feature)로 변환 \n",
    "                                    spike_torch = (spike_torch > levels).to(torch.float) \n",
    "\n",
    "                                    spike_torch = (spike_torch == 0).cumsum(dim=-1).eq(1).to(torch.float) if lc_adc_on == True else spike_torch\n",
    "\n",
    "                                    # spike: batch, time, feature\n",
    "                                    spike_torch = spike_torch.reshape(spike_torch.shape[0], -1)\n",
    "                            if converted_net_forward == True:\n",
    "                                spike_torch_spikegen = spikegen.rate(spike_torch, num_steps=TIME).transpose(0, 1)\n",
    "                            # if fusion_net == True:\n",
    "                            #     spike_torch = spikegen.rate(spike_torch, num_steps=TIME).transpose(0, 1)\n",
    "                        ### forward #######################################################\n",
    "                        inner_inf = net.module.encoder(spike_torch)\n",
    "                        if SAE_net == False and converted_net_forward == True:\n",
    "                            converted_inner_inf = converted_net.module.encoder(spike_torch_spikegen)\n",
    "                        ### forward #######################################################\n",
    "                            \n",
    "                        if 'SAE' in net.module.__class__.__name__:\n",
    "                            if SAE_hidden_nomean == True:\n",
    "                                inner_inf = inner_inf.reshape(spike_batch.shape[0],-1)# 펼치기\n",
    "                            else:\n",
    "                                inner_inf = inner_inf.mean(dim=1)# Time 방향으로 평균\n",
    "                            # inner_inf = F.normalize(inner_inf, p=2, dim=1)\n",
    "                        spike_hidden[now_index:now_end_index] = inner_inf.cpu().detach().numpy()\n",
    "                        if SAE_net == False and converted_net_forward == True:\n",
    "                            converted_spike_hidden[now_index:now_end_index] = converted_inner_inf.cpu().detach().numpy()\n",
    "                        now_index += encoder_batch\n",
    "                        if (now_index >= len(spike)):\n",
    "                            break\n",
    "                    \n",
    "                spike_id = np.zeros(len(spike))\n",
    "                distance_sm = np.zeros(num_cluster)\n",
    "                tau = np.zeros(num_cluster)\n",
    "                \n",
    "                plot_tau = []\n",
    "                plot_denominator = []\n",
    "                plot_m = []\n",
    "                plot_max_tau = []\n",
    "                for spike_index in range(len(spike)): \n",
    "                    for q in range(num_cluster):\n",
    "                        tau[q] = np.dot(spike_hidden[spike_index, :], Cluster[q, :]) # 이거 l2norm 거쳐서 나온 거니까 분모 1임.\n",
    "                        denominator =  np.linalg.norm(spike_hidden[spike_index, :])*np.linalg.norm(Cluster[q, :]) + 1e-12\n",
    "                        plot_denominator.append(denominator)\n",
    "                        if 'SAE' in net.module.__class__.__name__: # AE 때는 l2norm거쳐서 나와서 괜찮음\n",
    "                            tau[q] = tau[q] / denominator\n",
    "\n",
    "                        plot_tau.append(tau[q])\n",
    "\n",
    "                    # for i in range(num_cluster): # l2 distance\n",
    "                    #     distance_sm[i] = np.sum(np.power(np.abs(Cluster[i] - spike_hidden[spike_index, :]), 2))\n",
    "                    distance_sm = np.sum(np.power(np.abs(Cluster - spike_hidden[spike_index, :]), 2), axis=1)\n",
    "\n",
    "                    m = np.argmin(distance_sm)\n",
    "                    plot_m.append(m)\n",
    "                    spike_id[spike_index] = m + 1\n",
    "                    # print(spike_tot[ds], spike_index,np.max(tau))\n",
    "                    plot_max_tau.append(np.max(tau))\n",
    "                    if(np.max(tau) >= cos_thr[ds] and spike_index < training_cycle): # 원래 1400 아니냐?\n",
    "                        Cluster[m] = (Cluster[m] * 15 + spike_hidden[spike_index, :])/16\n",
    "\n",
    "\n",
    "                \n",
    "                origin_kmeans_accuracy = cluster_spikes_with_accuracy_torch(features= spike, true_labels=label-1, n_clusters=3, init_point=None)\n",
    "                kmeans_accuracy = cluster_spikes_with_accuracy_torch(features= torch.tensor(spike_hidden).to(device), true_labels=label-1, n_clusters=3, init_point=None)\n",
    "                \n",
    "                # print('temporoal k')\n",
    "                # result = evaluate_clustering_accuracy(spike_hidden.reshape(spike_hidden.shape[0], TIME, -1), label-1, n_clusters=3)\n",
    "                # print('원래', kmeans_accuracy)\n",
    "                # print(result)\n",
    "\n",
    "                k_means_bin_origin_feature.append(origin_kmeans_accuracy)\n",
    "                k_means_bin.append(kmeans_accuracy)\n",
    "                if SAE_net == False and converted_net_forward == True:\n",
    "                    converted_kmeans_accuracy = cluster_spikes_with_accuracy_torch(features= torch.tensor(converted_spike_hidden).to(device), true_labels=label-1, n_clusters=3, init_point=None)\n",
    "                    converted_k_means_bin.append(converted_kmeans_accuracy)\n",
    "                # sklearn kmeans인데 cpu많이먹어서 버림.\n",
    "                # origin_kmeans_accuracy = cluster_spikes_with_accuracy(features= spike.cpu().detach().numpy(), true_labels=label-1, n_clusters=3, init_point=None)\n",
    "                # kmeans_accuracy = cluster_spikes_with_accuracy(features= spike_hidden, true_labels=label-1, n_clusters=3, init_point=None)\n",
    "                # k_means_bin_origin_feature.append(origin_kmeans_accuracy)\n",
    "                # k_means_bin.append(kmeans_accuracy)\n",
    "                # if SAE_net == False and converted_net_forward == True:\n",
    "                #     converted_kmeans_accuracy = cluster_spikes_with_accuracy(features= converted_spike_hidden, true_labels=label-1, n_clusters=3, init_point=None)\n",
    "                #     converted_k_means_bin.append(converted_kmeans_accuracy)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "                # print('Cluster',Cluster)\n",
    "                # print('spike_id', spike_id)\n",
    "\n",
    "                # spike id 분포 확인하기\n",
    "                # unique_elements, counts = np.unique(spike_id, return_counts=True)\n",
    "                # print(\"Unique elements:\", unique_elements)\n",
    "                # print(\"Counts:\", counts)\n",
    "\n",
    "                cluster_accuracy_during_training_cycle = np.zeros(math.factorial(num_cluster))\n",
    "                cluster_accuracy_post_training_cycle = np.zeros(math.factorial(num_cluster))\n",
    "                cluster_accuracy_total = np.zeros(math.factorial(num_cluster))\n",
    "                \n",
    "                label_converter_ground = list(range(1, num_cluster + 1)) # [1, 2, 3, 4] 생성\n",
    "                label_converter_permutations = list(itertools.permutations(label_converter_ground)) # 모든 순열 구하기\n",
    "                perm_i = 0\n",
    "                perm_start_time = time.time() \n",
    "                for perm in label_converter_permutations:\n",
    "                    label_converter = list(perm)\n",
    "                    # print(label_converter)\n",
    "                    correct_during_training_cycle = 0\n",
    "                    correct_post_training_cycle = 0\n",
    "\n",
    "                    assert len(spike_id) == len(label), 'spike_id랑 label 길이 같아야 됨.'\n",
    "                    for i in range(len(spike_id)):\n",
    "                        if(label_converter[int(spike_id[i]-1)] == label[i]):\n",
    "                            if i < training_cycle:\n",
    "                                correct_during_training_cycle += 1\n",
    "                            else:\n",
    "                                correct_post_training_cycle += 1\n",
    "\n",
    "                    cluster_accuracy_during_training_cycle[perm_i] = correct_during_training_cycle/training_cycle\n",
    "                    cluster_accuracy_post_training_cycle[perm_i] = correct_post_training_cycle/(len(spike_id)-training_cycle)\n",
    "                    cluster_accuracy_total[perm_i] = (correct_during_training_cycle+correct_post_training_cycle)/(len(spike_id))\n",
    "                    perm_i += 1\n",
    "                # print(f\"perm 실행 시간: {time.time()-perm_start_time:.3f}초\")\n",
    "                \n",
    "                cluster_accuracy_during_training_cycle_all_dataset[ds] = np.max(cluster_accuracy_during_training_cycle)\n",
    "                cluster_accuracy_post_training_cycle_all_dataset[ds] = cluster_accuracy_post_training_cycle[np.argmax(cluster_accuracy_during_training_cycle)]\n",
    "                cluster_accuracy_total_all_dataset[ds] = cluster_accuracy_total[np.argmax(cluster_accuracy_during_training_cycle)]\n",
    "                # plot_distributions(ds, plot_tau, plot_denominator, plot_m, plot_max_tau, cos_thr[ds],\n",
    "                #                    cluster_accuracy_during_training_cycle_all_dataset[ds], cluster_accuracy_post_training_cycle_all_dataset[ds], cluster_accuracy_total_all_dataset[ds])\n",
    "            print(f'k_means origin feature average accuracy : {100*sum(k_means_bin_origin_feature)/(len(k_means_bin_origin_feature)+1e-12):.8f}%, total {k_means_bin_origin_feature}')\n",
    "            \n",
    "            mean_cluster_accuracy_during_training_cycle_all_dataset = np.mean(cluster_accuracy_during_training_cycle_all_dataset)\n",
    "            mean_cluster_accuracy_post_training_cycle_all_dataset = np.mean(cluster_accuracy_post_training_cycle_all_dataset)\n",
    "            mean_cluster_accuracy_total_all_dataset = np.mean(cluster_accuracy_total_all_dataset)\n",
    "            \n",
    "            if SAE_net == False and converted_net_forward == True:\n",
    "                converted_k_means_acc = 100*sum(converted_k_means_bin)/len(converted_k_means_bin)\n",
    "                print(f'converted_kmeans average accuracy : {converted_k_means_acc:.8f}%, total {converted_k_means_bin}')\n",
    "            k_means_acc = 100*sum(k_means_bin)/len(k_means_bin)\n",
    "            if k_means_acc > k_means_acc_best:\n",
    "                # torch.save(net, f\"net_save/save_now_net_{current_time}.pth\")\n",
    "                torch.save(net.module.state_dict(), f\"net_save/save_now_net_{current_time}.pth\")\n",
    "                print('save model')\n",
    "                best_mean_cluster_accuracy_post_training_cycle_all_dataset = mean_cluster_accuracy_post_training_cycle_all_dataset\n",
    "            \n",
    "            k_means_acc_best = max(k_means_acc_best, k_means_acc)\n",
    "            print(f'kmeans average accuracy best : {k_means_acc_best:.2f}%, kmeans average accuracy : {k_means_acc:.8f}%, total {k_means_bin}')\n",
    "            print(f'cluster_accuracy_post_training_cycle_all_dataset : {cluster_accuracy_post_training_cycle_all_dataset}')\n",
    "\n",
    "            \n",
    "            mean_cluster_accuracy_during_training_cycle_all_dataset_history.append((epoch, mean_cluster_accuracy_during_training_cycle_all_dataset*100))\n",
    "            mean_cluster_accuracy_post_training_cycle_all_dataset_history.append((epoch, mean_cluster_accuracy_post_training_cycle_all_dataset*100))\n",
    "            mean_cluster_accuracy_total_all_dataset_history.append((epoch, mean_cluster_accuracy_total_all_dataset*100))\n",
    "            print(f\"mean_cluster_accuracy_during_training_cycle : {mean_cluster_accuracy_during_training_cycle_all_dataset*100:.2f}%, post_traincycle_acc : {mean_cluster_accuracy_post_training_cycle_all_dataset*100:.2f}%, total_acc : {mean_cluster_accuracy_total_all_dataset*100:.8f}%\")\n",
    "\n",
    "            # kmeans accuracy기준으로 좋은 거 저장할 거임\n",
    "            # if mean_cluster_accuracy_post_training_cycle_all_dataset > best_mean_cluster_accuracy_post_training_cycle_all_dataset:\n",
    "            #     # torch.save(net, f\"net_save/save_now_net_{current_time}.pth\")\n",
    "            #     torch.save(net.module.state_dict(), f\"net_save/save_now_net_{current_time}.pth\")\n",
    "            #     print('save model')\n",
    "            #     best_mean_cluster_accuracy_post_training_cycle_all_dataset = mean_cluster_accuracy_post_training_cycle_all_dataset\n",
    "            print(f\"best_mean_cluster_accuracy_post_training_cycle_all_dataset : {best_mean_cluster_accuracy_post_training_cycle_all_dataset*100:.2f}%\")\n",
    "            print(f\"accuracy_check 실행 시간: {time.time()-accuracy_check_start_time:.3f}초\")\n",
    "\n",
    "        wandb.log({\"avg_loss\": avg_loss})\n",
    "        wandb.log({\"mean_cluster_accuracy_post_training_cycle_all_dataset\": mean_cluster_accuracy_post_training_cycle_all_dataset})\n",
    "        wandb.log({\"best_mean_cluster_accuracy_post_training_cycle_all_dataset\": best_mean_cluster_accuracy_post_training_cycle_all_dataset})\n",
    "        wandb.log({\"best_mean_cluster_accuracy_post_training_cycle_all_dataset2\": best_mean_cluster_accuracy_post_training_cycle_all_dataset})\n",
    "        wandb.log({\"k_means_acc\": k_means_acc})\n",
    "        wandb.log({\"k_means_acc_best\": k_means_acc_best})\n",
    "        wandb.log({\"converted_k_means_acc\": converted_k_means_acc})\n",
    "\n",
    "\n",
    "        # 저장\n",
    "        with open(f\"result_save/cluster_accuracy_history_{current_time}.pkl\", \"wb\") as f:\n",
    "            pickle.dump({\n",
    "                \"loss_history\": loss_history,\n",
    "                \"mean_cluster_accuracy_during_training_cycle_all_dataset_history\": mean_cluster_accuracy_during_training_cycle_all_dataset_history,\n",
    "                \"mean_cluster_accuracy_post_training_cycle_all_dataset_history\": mean_cluster_accuracy_post_training_cycle_all_dataset_history,\n",
    "                \"mean_cluster_accuracy_total_all_dataset_history\": mean_cluster_accuracy_total_all_dataset_history,\n",
    "            }, f)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mbhkim003\u001b[0m (\u001b[33mbhkim003-seoul-national-university\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.19.8 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.17.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/nfs/home/bhkim003/github_folder/ByeonghyeonKim/my_snn/wandb/run-20250314_000025-s7ppz5y1</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/bhkim003-seoul-national-university/spike_sorting%20just%20run/runs/s7ppz5y1' target=\"_blank\">divine-sunset-1480</a></strong> to <a href='https://wandb.ai/bhkim003-seoul-national-university/spike_sorting%20just%20run' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/bhkim003-seoul-national-university/spike_sorting%20just%20run' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/spike_sorting%20just%20run</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/bhkim003-seoul-national-university/spike_sorting%20just%20run/runs/s7ppz5y1' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/spike_sorting%20just%20run/runs/s7ppz5y1</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'gpu': '1', 'Conv_net': True, 'SAE_net': True, 'dataset_num': 16, 'spike_length': 50, 'num_cluster': 4, 'training_cycle': 1400, 'batch_size': 32, 'max_epoch': 10000, 'learning_rate': 0.001, 'normalize_on': True, 'need_bias': False, 'lif_add_at_first': False, 'my_seed': 42, 'TIME': 50, 'v_decay': 0.5, 'v_threshold': 0.25, 'v_reset': 0.0, 'BPTT_on': True, 'SAE_hidden_nomean': True, 'current_time': '20250314_000023_260', 'optimizer': 'Adam', 'coarse_com_mode': True, 'sae_l2_norm_bridge': True, 'sae_lif_bridge': False, 'accuracy_check_epoch_term': 1, 'lif_add_at_last': False, 'two_channel_input': False, 'lateral_feature_num': 4, 'lc_adc_on': False, 'converted_net_forward': False, 'pretrained_net': None, 'vth_mul_on': False, 'batch_norm_on': False, 'l2_norm_loss_weight': 0, 'QCFS_neuron_on': False, 'quantize_level_num': 0, 'fusion_net': True, 'repeat_coding': False, 'sae_relu_on': False, 'conv1d_scaling': False, 'norm01': True, 'coarse_com_config': (0.999, -0.0)}\n",
      "cos_thr [0.95 0.95 0.95 0.95 0.95 0.95 0.95 0.85 0.95 0.9  0.8  0.95 0.95 0.95\n",
      " 0.95 0.8 ]\n",
      "conv length [50, 24, 11, 5]\n",
      "Total number of encoder parameters: 27392\n",
      "DataParallel(\n",
      "  (module): SAE_FUSION7_net_conv1(\n",
      "    (activation_function): LIF_layer()\n",
      "    (encoder): Sequential(\n",
      "      (0): SSBH_DimChanger_one_two()\n",
      "      (1): SSBH_DimChanger_for_one_two_coupling()\n",
      "      (2): Conv1d(1, 32, kernel_size=(3,), stride=(2,), bias=False)\n",
      "      (3): SSBH_DimChanger_for_one_two_decoupling()\n",
      "      (4): LIF_layer()\n",
      "      (5): SSBH_DimChanger_for_one_two_coupling()\n",
      "      (6): Conv1d(32, 64, kernel_size=(3,), stride=(2,), bias=False)\n",
      "      (7): SSBH_DimChanger_for_one_two_decoupling()\n",
      "      (8): LIF_layer()\n",
      "      (9): SSBH_DimChanger_for_one_two_coupling()\n",
      "      (10): Conv1d(64, 96, kernel_size=(3,), stride=(2,), bias=False)\n",
      "      (11): SSBH_DimChanger_for_one_two_decoupling()\n",
      "      (12): LIF_layer()\n",
      "      (13): SSBH_DimChanger_for_one_two_coupling()\n",
      "      (14): SSBH_DimChanger_for_fc()\n",
      "      (15): Linear(in_features=480, out_features=4, bias=False)\n",
      "      (16): SSBH_DimChanger_for_one_two_decoupling()\n",
      "      (17): LIF_layer()\n",
      "      (18): SSBH_DimChanger_one_two()\n",
      "      (19): SSBH_DimChanger_for_two_three_coupling()\n",
      "      (20): Linear(in_features=200, out_features=4, bias=False)\n",
      "      (21): SSBH_L2NormLayer()\n",
      "    )\n",
      "    (decoder): Sequential(\n",
      "      (0): Linear(in_features=4, out_features=480, bias=False)\n",
      "      (1): ReLU()\n",
      "      (2): SSBH_DimChanger_for_conv1()\n",
      "      (3): ConvTranspose1d(96, 64, kernel_size=(3,), stride=(2,), bias=False)\n",
      "      (4): ReLU()\n",
      "      (5): ConvTranspose1d(64, 32, kernel_size=(3,), stride=(2,), output_padding=(1,), bias=False)\n",
      "      (6): ReLU()\n",
      "      (7): ConvTranspose1d(32, 1, kernel_size=(3,), stride=(2,), output_padding=(1,), bias=False)\n",
      "    )\n",
      "  )\n",
      ")\n",
      "Device: cuda\n",
      "\n",
      "Start Training, current_time = 20250314_000023_260\n",
      "\n",
      "\n",
      "epoch-0 loss : 0.02465363, loss_normal : 0.01797634, loss_coarse : 0.08324617, min_loss : 0.02465363, min_loss_normal : 0.01797634, min_loss_coarse : 0.08324617, wrong_element_sum : 15983266.00000000, same_data : 0.00%\n",
      "ae train 실행 시간: 120.156초, 전체 시작 시간 20250314_000023_260\n",
      "\n",
      "epoch-0 accuracy check\n",
      "k_means origin feature average accuracy : 82.25676103%, total [0.9746727376209448, 0.9733106189664963, 0.9700891573195284, 0.9530800230282096, 0.943108504398827, 0.9150568181818182, 0.801817648783348, 0.6625070901871809, 0.9488619568430388, 0.822215777262181, 0.5866935483870968, 0.5005858230814294, 0.9429250891795482, 0.891681109185442, 0.6744186046511628, 0.6000572573718866]\n",
      "save model\n",
      "kmeans average accuracy best : 86.04%, kmeans average accuracy : 86.03872519%, total [0.9726807057484348, 0.9735945485519591, 0.9712395743457003, 0.9548071387449626, 0.956891495601173, 0.9417613636363636, 0.8877162122544708, 0.7833238797504254, 0.942654448714159, 0.859338747099768, 0.7381912442396313, 0.6681312243702402, 0.8941736028537456, 0.8145580589254766, 0.7380813953488372, 0.6690523904952763]\n",
      "cluster_accuracy_post_training_cycle_all_dataset : [0.97398297 0.97502356 0.97159364 0.95901639 0.95820896 0.93113208\n",
      " 0.88662357 0.78645343 0.94150277 0.84619141 0.75530888 0.66385303\n",
      " 0.89613035 0.82104753 0.75784314 0.66698519]\n",
      "mean_cluster_accuracy_during_training_cycle : 85.87%, post_traincycle_acc : 86.19%, total_acc : 86.06027238%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 86.19%\n",
      "accuracy_check 실행 시간: 23.326초\n",
      "\n",
      "\n",
      "epoch-1 loss : 0.01430087, loss_normal : 0.01534748, loss_coarse : 0.07303487, min_loss : 0.01430087, min_loss_normal : 0.01534748, min_loss_coarse : 0.07303487, wrong_element_sum : 14022696.00000000, same_data : 0.00%\n",
      "ae train 실행 시간: 117.400초, 전체 시작 시간 20250314_000023_260\n",
      "\n",
      "epoch-1 accuracy check\n",
      "k_means origin feature average accuracy : 82.25682064%, total [0.9746727376209448, 0.9733106189664963, 0.9700891573195284, 0.9530800230282096, 0.943108504398827, 0.9150568181818182, 0.801817648783348, 0.6625070901871809, 0.9488619568430388, 0.822215777262181, 0.5866935483870968, 0.5005858230814294, 0.9429250891795482, 0.8922588099364529, 0.6747093023255814, 0.5991983967935872]\n",
      "save model\n",
      "kmeans average accuracy best : 87.58%, kmeans average accuracy : 87.57807204%, total [0.9715424018212863, 0.9741624077228848, 0.9709519700891573, 0.9559585492227979, 0.9580645161290322, 0.9460227272727273, 0.9020815010260921, 0.8244469653998866, 0.9432456399645285, 0.8642691415313225, 0.7690092165898618, 0.6862917398945518, 0.9268727705112961, 0.8587521663778163, 0.766860465116279, 0.6939593472659605]\n",
      "cluster_accuracy_post_training_cycle_all_dataset : [0.9730369  0.9736098  0.97111218 0.95853423 0.95721393 0.94056604\n",
      " 0.89706614 0.81232361 0.93898134 0.87353516 0.72490347 0.67229394\n",
      " 0.9287169  0.85935984 0.77696078 0.68752986]\n",
      "mean_cluster_accuracy_during_training_cycle : 87.31%, post_traincycle_acc : 87.16%, total_acc : 87.22253503%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 87.16%\n",
      "accuracy_check 실행 시간: 24.662초\n",
      "\n",
      "\n",
      "epoch-2 loss : 0.01352879, loss_normal : 0.01521768, loss_coarse : 0.07185183, min_loss : 0.01352879, min_loss_normal : 0.01521768, min_loss_coarse : 0.07185183, wrong_element_sum : 13795552.00000000, same_data : 0.00%\n",
      "ae train 실행 시간: 121.303초, 전체 시작 시간 20250314_000023_260\n",
      "\n",
      "epoch-2 accuracy check\n",
      "k_means origin feature average accuracy : 82.27480709%, total [0.9746727376209448, 0.9733106189664963, 0.9700891573195284, 0.9530800230282096, 0.943108504398827, 0.9150568181818182, 0.801817648783348, 0.6622234826999432, 0.9488619568430388, 0.822215777262181, 0.5872695852534562, 0.5005858230814294, 0.9429250891795482, 0.8922588099364529, 0.6752906976744186, 0.6012024048096193]\n",
      "save model\n",
      "kmeans average accuracy best : 88.15%, kmeans average accuracy : 88.15390372%, total [0.9723961297666477, 0.9724588302101079, 0.9700891573195284, 0.9550949913644214, 0.9595307917888563, 0.9488636363636364, 0.9088243916739959, 0.8372093023255814, 0.9553650605971031, 0.865139211136891, 0.7517281105990783, 0.6971294669009959, 0.9357907253269917, 0.8804159445407279, 0.7848837209302325, 0.7097051245347838]\n",
      "cluster_accuracy_post_training_cycle_all_dataset : [0.97350993 0.9726673  0.97063072 0.95756991 0.960199   0.94669811\n",
      " 0.90949776 0.82126058 0.95259708 0.89453125 0.74324324 0.66087388\n",
      " 0.93584521 0.88797284 0.79656863 0.70234114]\n",
      "mean_cluster_accuracy_during_training_cycle : 87.25%, post_traincycle_acc : 88.04%, total_acc : 87.71670238%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 88.04%\n",
      "accuracy_check 실행 시간: 23.029초\n",
      "\n",
      "\n",
      "epoch-3 loss : 0.01320364, loss_normal : 0.01515634, loss_coarse : 0.07132282, min_loss : 0.01320364, min_loss_normal : 0.01515634, min_loss_coarse : 0.07132282, wrong_element_sum : 13693982.00000000, same_data : 0.00%\n",
      "ae train 실행 시간: 115.992초, 전체 시작 시간 20250314_000023_260\n",
      "\n",
      "epoch-3 accuracy check\n",
      "k_means origin feature average accuracy : 82.26037166%, total [0.9746727376209448, 0.9733106189664963, 0.9700891573195284, 0.9530800230282096, 0.943108504398827, 0.9150568181818182, 0.801817648783348, 0.6625070901871809, 0.9488619568430388, 0.822215777262181, 0.5866935483870968, 0.5005858230814294, 0.9429250891795482, 0.8922588099364529, 0.6744186046511628, 0.6000572573718866]\n",
      "save model\n",
      "kmeans average accuracy best : 88.56%, kmeans average accuracy : 88.56099009%, total [0.9726807057484348, 0.9735945485519591, 0.9718147828587863, 0.9571099597006333, 0.9580645161290322, 0.9454545454545454, 0.9132219290530637, 0.8428814520703346, 0.9580254212237659, 0.8831206496519721, 0.7730414746543779, 0.7088459285295841, 0.9325208085612366, 0.8723281340265743, 0.7950581395348837, 0.711995419410249]\n",
      "cluster_accuracy_post_training_cycle_all_dataset : [0.97398297 0.97408106 0.97303804 0.95901639 0.95920398 0.94103774\n",
      " 0.91347588 0.83584196 0.95410993 0.84960938 0.75289575 0.67576961\n",
      " 0.93177189 0.87342386 0.80539216 0.71428571]\n",
      "mean_cluster_accuracy_during_training_cycle : 88.25%, post_traincycle_acc : 88.04%, total_acc : 88.12698081%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 88.04%\n",
      "accuracy_check 실행 시간: 23.583초\n",
      "\n",
      "\n",
      "epoch-4 loss : 0.01288955, loss_normal : 0.01508432, loss_coarse : 0.07075187, min_loss : 0.01288955, min_loss_normal : 0.01508432, min_loss_coarse : 0.07075187, wrong_element_sum : 13584360.00000000, same_data : 0.00%\n",
      "ae train 실행 시간: 117.537초, 전체 시작 시간 20250314_000023_260\n",
      "\n",
      "epoch-4 accuracy check\n",
      "k_means origin feature average accuracy : 82.25314853%, total [0.9746727376209448, 0.9733106189664963, 0.9700891573195284, 0.9530800230282096, 0.943108504398827, 0.9150568181818182, 0.801817648783348, 0.6622234826999432, 0.9488619568430388, 0.822215777262181, 0.5866935483870968, 0.5005858230814294, 0.9429250891795482, 0.8922588099364529, 0.673546511627907, 0.6000572573718866]\n",
      "save model\n",
      "kmeans average accuracy best : 88.79%, kmeans average accuracy : 88.78816454%, total [0.9712578258394992, 0.9735945485519591, 0.9706643658326143, 0.9565342544617156, 0.9624633431085043, 0.953125, 0.9167399589563178, 0.8440158820192853, 0.9618681643511676, 0.8845707656612529, 0.7788018433179723, 0.7026947861745753, 0.9348989298454221, 0.8778162911611785, 0.7941860465116279, 0.7228743200687089]\n",
      "cluster_accuracy_post_training_cycle_all_dataset : [0.97209082 0.9736098  0.97063072 0.95998071 0.96218905 0.95\n",
      " 0.91496768 0.83207902 0.95562279 0.89404297 0.77992278 0.69563059\n",
      " 0.93584521 0.87972842 0.79852941 0.7147635 ]\n",
      "mean_cluster_accuracy_during_training_cycle : 88.77%, post_traincycle_acc : 88.69%, total_acc : 88.72009251%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 88.69%\n",
      "accuracy_check 실행 시간: 22.730초\n",
      "\n",
      "\n",
      "epoch-5 loss : 0.01269991, loss_normal : 0.01503260, loss_coarse : 0.07034594, min_loss : 0.01269991, min_loss_normal : 0.01503260, min_loss_coarse : 0.07034594, wrong_element_sum : 13506420.00000000, same_data : 0.00%\n",
      "ae train 실행 시간: 116.794초, 전체 시작 시간 20250314_000023_260\n",
      "\n",
      "epoch-5 accuracy check\n",
      "k_means origin feature average accuracy : 82.26384617%, total [0.9746727376209448, 0.9733106189664963, 0.9700891573195284, 0.9530800230282096, 0.943108504398827, 0.9150568181818182, 0.8015244796247435, 0.6625070901871809, 0.9488619568430388, 0.822215777262181, 0.5872695852534562, 0.5005858230814294, 0.9429250891795482, 0.8922588099364529, 0.673546511627907, 0.6012024048096193]\n",
      "kmeans average accuracy best : 88.79%, kmeans average accuracy : 88.64348228%, total [0.9732498577120091, 0.9738784781374219, 0.9709519700891573, 0.9579735175590098, 0.9589442815249267, 0.9502840909090909, 0.9143946056874817, 0.8508224617129893, 0.9595033993496896, 0.8781902552204176, 0.7595046082949308, 0.695079086115993, 0.9441141498216409, 0.8853264009243212, 0.7927325581395349, 0.7180074434583452]\n",
      "cluster_accuracy_post_training_cycle_all_dataset : [0.97587512 0.9726673  0.97207511 0.95949855 0.95970149 0.94433962\n",
      " 0.91695674 0.82878645 0.94553707 0.88085938 0.75627413 0.68321748\n",
      " 0.94755601 0.88312318 0.80588235 0.72001911]\n",
      "mean_cluster_accuracy_during_training_cycle : 88.33%, post_traincycle_acc : 88.45%, total_acc : 88.40413068%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 88.69%\n",
      "accuracy_check 실행 시간: 23.843초\n",
      "\n",
      "\n",
      "epoch-6 loss : 0.01250803, loss_normal : 0.01496456, loss_coarse : 0.06979994, min_loss : 0.01250803, min_loss_normal : 0.01496456, min_loss_coarse : 0.06979994, wrong_element_sum : 13401588.00000000, same_data : 0.00%\n",
      "ae train 실행 시간: 116.845초, 전체 시작 시간 20250314_000023_260\n",
      "\n",
      "epoch-6 accuracy check\n",
      "k_means origin feature average accuracy : 82.24774477%, total [0.9746727376209448, 0.9733106189664963, 0.9700891573195284, 0.9530800230282096, 0.943108504398827, 0.9150568181818182, 0.801817648783348, 0.6625070901871809, 0.9488619568430388, 0.8216357308584686, 0.5866935483870968, 0.5005858230814294, 0.9429250891795482, 0.8922588099364529, 0.6738372093023256, 0.5991983967935872]\n",
      "save model\n",
      "kmeans average accuracy best : 88.80%, kmeans average accuracy : 88.79535638%, total [0.9735344336937962, 0.9750141964792731, 0.9712395743457003, 0.9582613701784686, 0.9607038123167155, 0.9517045454545454, 0.9149809440046907, 0.8477027793533749, 0.9586166124741354, 0.8822505800464037, 0.7753456221198156, 0.7006444053895724, 0.9408442330558858, 0.8902368573079145, 0.7938953488372092, 0.7122817062696822]\n",
      "cluster_accuracy_post_training_cycle_all_dataset : [0.97587512 0.97455231 0.97255657 0.96094503 0.96218905 0.94669811\n",
      " 0.91994033 0.83772342 0.95663137 0.89697266 0.77799228 0.68619662\n",
      " 0.94093686 0.89330747 0.80833333 0.71524128]\n",
      "mean_cluster_accuracy_during_training_cycle : 88.75%, post_traincycle_acc : 88.91%, total_acc : 88.84711764%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 88.91%\n",
      "accuracy_check 실행 시간: 22.813초\n",
      "\n",
      "\n",
      "epoch-7 loss : 0.01240852, loss_normal : 0.01494998, loss_coarse : 0.06966379, min_loss : 0.01240852, min_loss_normal : 0.01494998, min_loss_coarse : 0.06966379, wrong_element_sum : 13375448.00000000, same_data : 0.00%\n",
      "ae train 실행 시간: 118.836초, 전체 시작 시간 20250314_000023_260\n",
      "\n",
      "epoch-7 accuracy check\n",
      "k_means origin feature average accuracy : 82.25137308%, total [0.9746727376209448, 0.9733106189664963, 0.9700891573195284, 0.9530800230282096, 0.943108504398827, 0.915340909090909, 0.801817648783348, 0.6622234826999432, 0.9488619568430388, 0.822215777262181, 0.5866935483870968, 0.5005858230814294, 0.9429250891795482, 0.8922588099364529, 0.6738372093023256, 0.5991983967935872]\n",
      "save model\n",
      "kmeans average accuracy best : 89.26%, kmeans average accuracy : 89.26431221%, total [0.9735344336937962, 0.975298126064736, 0.9721023871153293, 0.9585492227979274, 0.9612903225806452, 0.9534090909090909, 0.9155672823218998, 0.8528077141236529, 0.966006503103754, 0.8958816705336426, 0.7874423963133641, 0.7129466900995899, 0.9494649227110583, 0.8922588099364529, 0.8008720930232558, 0.7148582880045806]\n",
      "cluster_accuracy_post_training_cycle_all_dataset : [0.97682119 0.97549482 0.97207511 0.96142719 0.96318408 0.94669811\n",
      " 0.92043759 0.83537159 0.96217852 0.90478516 0.78861004 0.69811321\n",
      " 0.95010183 0.8971872  0.8122549  0.71428571]\n",
      "mean_cluster_accuracy_during_training_cycle : 89.11%, post_traincycle_acc : 89.24%, total_acc : 89.18909520%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 89.24%\n",
      "accuracy_check 실행 시간: 24.269초\n",
      "\n",
      "\n",
      "epoch-8 loss : 0.01234519, loss_normal : 0.01491507, loss_coarse : 0.06947733, min_loss : 0.01234519, min_loss_normal : 0.01491507, min_loss_coarse : 0.06947733, wrong_element_sum : 13339648.00000000, same_data : 0.00%\n",
      "ae train 실행 시간: 117.936초, 전체 시작 시간 20250314_000023_260\n",
      "\n",
      "epoch-8 accuracy check\n",
      "k_means origin feature average accuracy : 82.26041597%, total [0.9746727376209448, 0.9733106189664963, 0.9700891573195284, 0.9530800230282096, 0.943108504398827, 0.9150568181818182, 0.801817648783348, 0.6622234826999432, 0.9488619568430388, 0.822215777262181, 0.5866935483870968, 0.5005858230814294, 0.9429250891795482, 0.8922588099364529, 0.6747093023255814, 0.6000572573718866]\n",
      "kmeans average accuracy best : 89.26%, kmeans average accuracy : 88.82840288%, total [0.9723961297666477, 0.9735945485519591, 0.9709519700891573, 0.957685664939551, 0.9580645161290322, 0.9477272727272728, 0.9108765757842275, 0.8397617697107204, 0.9583210168489507, 0.8732598607888631, 0.7655529953917051, 0.6953719976567077, 0.9515457788347206, 0.8968804159445407, 0.8142441860465116, 0.7263097623819067]\n",
      "cluster_accuracy_post_training_cycle_all_dataset : [0.97398297 0.9736098  0.97303804 0.95998071 0.960199   0.94056604\n",
      " 0.90949776 0.82831609 0.95057993 0.89257812 0.76978764 0.69910626\n",
      " 0.95010183 0.90446169 0.82303922 0.72575251]\n",
      "mean_cluster_accuracy_during_training_cycle : 88.56%, post_traincycle_acc : 88.97%, total_acc : 88.80175045%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 89.24%\n",
      "accuracy_check 실행 시간: 24.296초\n",
      "\n",
      "\n",
      "epoch-9 loss : 0.01226272, loss_normal : 0.01489646, loss_coarse : 0.06934409, min_loss : 0.01226272, min_loss_normal : 0.01489646, min_loss_coarse : 0.06934409, wrong_element_sum : 13314066.00000000, same_data : 0.00%\n",
      "ae train 실행 시간: 121.248초, 전체 시작 시간 20250314_000023_260\n",
      "\n",
      "epoch-9 accuracy check\n",
      "k_means origin feature average accuracy : 82.24780532%, total [0.9746727376209448, 0.9733106189664963, 0.9700891573195284, 0.9530800230282096, 0.943108504398827, 0.915340909090909, 0.801817648783348, 0.6625070901871809, 0.9488619568430388, 0.822215777262181, 0.5866935483870968, 0.5005858230814294, 0.9429250891795482, 0.8922588099364529, 0.6741279069767442, 0.5980532493558546]\n",
      "kmeans average accuracy best : 89.26%, kmeans average accuracy : 89.00197624%, total [0.9738190096755834, 0.9755820556501987, 0.9726775956284153, 0.957685664939551, 0.9609970674486803, 0.9508522727272727, 0.9170331281149223, 0.8437322745320477, 0.9633461424770914, 0.8947215777262181, 0.7661290322580645, 0.7114821323960164, 0.942627824019025, 0.8821490467937608, 0.8017441860465117, 0.7257371886630404]\n",
      "cluster_accuracy_post_training_cycle_all_dataset : [0.97587512 0.97596607 0.9735195  0.96046287 0.96368159 0.94575472\n",
      " 0.9189458  0.83160865 0.95310136 0.90185547 0.77171815 0.69414101\n",
      " 0.94551935 0.89524733 0.81862745 0.72718586]\n",
      "mean_cluster_accuracy_during_training_cycle : 88.35%, post_traincycle_acc : 89.08%, total_acc : 88.78472070%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 89.24%\n",
      "accuracy_check 실행 시간: 23.697초\n",
      "\n",
      "\n",
      "epoch-10 loss : 0.01217231, loss_normal : 0.01486564, loss_coarse : 0.06912281, min_loss : 0.01217231, min_loss_normal : 0.01486564, min_loss_coarse : 0.06912281, wrong_element_sum : 13271580.00000000, same_data : 0.00%\n",
      "ae train 실행 시간: 117.424초, 전체 시작 시간 20250314_000023_260\n",
      "\n",
      "epoch-10 accuracy check\n",
      "k_means origin feature average accuracy : 82.24590034%, total [0.9746727376209448, 0.9733106189664963, 0.9700891573195284, 0.9530800230282096, 0.943108504398827, 0.9150568181818182, 0.801817648783348, 0.6625070901871809, 0.9488619568430388, 0.8216357308584686, 0.5866935483870968, 0.5005858230814294, 0.9429250891795482, 0.8922588099364529, 0.6732558139534883, 0.5994846836530203]\n",
      "kmeans average accuracy best : 89.26%, kmeans average accuracy : 88.87010075%, total [0.9741035856573705, 0.9750141964792731, 0.9723899913718723, 0.9582613701784686, 0.9598240469208211, 0.9514204545454545, 0.9161536206391088, 0.8448667044809983, 0.9559562518474727, 0.8805104408352669, 0.7655529953917051, 0.7032806092560047, 0.9458977407847801, 0.8859041016753322, 0.8031976744186047, 0.726882336100773]\n",
      "cluster_accuracy_post_training_cycle_all_dataset : [0.97682119 0.97502356 0.97303804 0.96046287 0.96069652 0.94481132\n",
      " 0.92192939 0.83349012 0.94755421 0.88671875 0.7726834  0.70456802\n",
      " 0.94551935 0.89621726 0.81127451 0.72384138]\n",
      "mean_cluster_accuracy_during_training_cycle : 88.76%, post_traincycle_acc : 88.97%, total_acc : 88.88125520%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 89.24%\n",
      "accuracy_check 실행 시간: 23.233초\n",
      "\n",
      "\n",
      "epoch-11 loss : 0.01215190, loss_normal : 0.01484792, loss_coarse : 0.06902130, min_loss : 0.01215190, min_loss_normal : 0.01484792, min_loss_coarse : 0.06902130, wrong_element_sum : 13252090.00000000, same_data : 0.00%\n",
      "ae train 실행 시간: 117.490초, 전체 시작 시간 20250314_000023_260\n",
      "\n",
      "epoch-11 accuracy check\n",
      "k_means origin feature average accuracy : 82.25673794%, total [0.9746727376209448, 0.9733106189664963, 0.9700891573195284, 0.9530800230282096, 0.943108504398827, 0.9150568181818182, 0.801817648783348, 0.6625070901871809, 0.9488619568430388, 0.822215777262181, 0.5866935483870968, 0.5005858230814294, 0.9429250891795482, 0.8922588099364529, 0.6738372093023256, 0.6000572573718866]\n",
      "kmeans average accuracy best : 89.26%, kmeans average accuracy : 89.05382222%, total [0.9726807057484348, 0.9764338444065872, 0.9718147828587863, 0.9588370754173863, 0.9601173020527859, 0.9511363636363637, 0.9117560832600411, 0.8224617129892229, 0.9615725687259828, 0.898491879350348, 0.7900345622119815, 0.7176332747510252, 0.9369797859690844, 0.8908145580589255, 0.8069767441860465, 0.7208703120526768]\n",
      "cluster_accuracy_post_training_cycle_all_dataset : [0.97445601 0.97596607 0.97303804 0.96094503 0.96318408 0.94150943\n",
      " 0.90949776 0.81138288 0.95814423 0.90039062 0.7953668  0.71499503\n",
      " 0.93940937 0.88991271 0.81764706 0.71810798]\n",
      "mean_cluster_accuracy_during_training_cycle : 89.00%, post_traincycle_acc : 89.02%, total_acc : 89.01233289%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 89.24%\n",
      "accuracy_check 실행 시간: 23.886초\n",
      "\n",
      "\n",
      "epoch-12 loss : 0.01212589, loss_normal : 0.01485110, loss_coarse : 0.06901053, min_loss : 0.01212589, min_loss_normal : 0.01484792, min_loss_coarse : 0.06901053, wrong_element_sum : 13250022.00000000, same_data : 0.00%\n",
      "ae train 실행 시간: 88.399초, 전체 시작 시간 20250314_000023_260\n",
      "\n",
      "epoch-12 accuracy check\n",
      "k_means origin feature average accuracy : 82.24949203%, total [0.9746727376209448, 0.9733106189664963, 0.9700891573195284, 0.9530800230282096, 0.943108504398827, 0.9150568181818182, 0.801817648783348, 0.6625070901871809, 0.9488619568430388, 0.822215777262181, 0.5872695852534562, 0.5, 0.9429250891795482, 0.8922588099364529, 0.673546511627907, 0.5991983967935872]\n",
      "kmeans average accuracy best : 89.26%, kmeans average accuracy : 89.21045710%, total [0.9718269778030734, 0.9741624077228848, 0.9721023871153293, 0.9571099597006333, 0.9583577712609971, 0.9494318181818182, 0.9120492524186455, 0.8397617697107204, 0.9606857818504286, 0.8938515081206496, 0.7819700460829493, 0.7132396016403046, 0.9545184304399524, 0.9046793760831889, 0.8119186046511628, 0.7180074434583452]\n",
      "cluster_accuracy_post_training_cycle_all_dataset : [0.97445601 0.97408106 0.97303804 0.96094503 0.960199   0.94009434\n",
      " 0.91347588 0.82361242 0.9515885  0.90332031 0.78426641 0.71201589\n",
      " 0.95417515 0.90785645 0.81617647 0.7147635 ]\n",
      "mean_cluster_accuracy_during_training_cycle : 88.78%, post_traincycle_acc : 89.15%, total_acc : 88.99996674%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 89.24%\n",
      "accuracy_check 실행 시간: 22.869초\n",
      "\n",
      "\n",
      "epoch-13 loss : 0.01209091, loss_normal : 0.01482570, loss_coarse : 0.06885428, min_loss : 0.01209091, min_loss_normal : 0.01482570, min_loss_coarse : 0.06885428, wrong_element_sum : 13220022.00000000, same_data : 0.00%\n",
      "ae train 실행 시간: 116.003초, 전체 시작 시간 20250314_000023_260\n",
      "\n",
      "epoch-13 accuracy check\n",
      "k_means origin feature average accuracy : 82.25318692%, total [0.9746727376209448, 0.9733106189664963, 0.9700891573195284, 0.9530800230282096, 0.943108504398827, 0.9150568181818182, 0.801817648783348, 0.6625070901871809, 0.9488619568430388, 0.822215777262181, 0.5866935483870968, 0.5005858230814294, 0.9429250891795482, 0.8922588099364529, 0.6741279069767442, 0.5991983967935872]\n",
      "kmeans average accuracy best : 89.26%, kmeans average accuracy : 89.18580196%, total [0.9732498577120091, 0.9755820556501987, 0.9712395743457003, 0.9579735175590098, 0.9592375366568915, 0.9522727272727273, 0.9082380533567869, 0.8321043675553035, 0.9624593556015371, 0.8929814385150812, 0.7848502304147466, 0.7149970708845929, 0.9494649227110583, 0.8948584633160023, 0.811046511627907, 0.7291726309762382]\n",
      "cluster_accuracy_post_training_cycle_all_dataset : [0.97540208 0.97455231 0.97255657 0.96046287 0.95970149 0.94339623\n",
      " 0.91148682 0.80009407 0.95612708 0.8984375  0.78330116 0.71797418\n",
      " 0.950611   0.90106693 0.8254902  0.72479694]\n",
      "mean_cluster_accuracy_during_training_cycle : 88.90%, post_traincycle_acc : 89.10%, total_acc : 89.01428330%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 89.24%\n",
      "accuracy_check 실행 시간: 23.519초\n",
      "\n",
      "\n",
      "epoch-14 loss : 0.01210990, loss_normal : 0.01484291, loss_coarse : 0.06894250, min_loss : 0.01209091, min_loss_normal : 0.01482570, min_loss_coarse : 0.06885428, wrong_element_sum : 13236960.00000000, same_data : 0.00%\n",
      "ae train 실행 시간: 120.457초, 전체 시작 시간 20250314_000023_260\n",
      "\n",
      "epoch-14 accuracy check\n",
      "k_means origin feature average accuracy : 82.23127444%, total [0.9746727376209448, 0.9733106189664963, 0.9700891573195284, 0.9530800230282096, 0.943108504398827, 0.9150568181818182, 0.7988859571973028, 0.6622234826999432, 0.9488619568430388, 0.822215777262181, 0.5866935483870968, 0.5005858230814294, 0.9429250891795482, 0.8922588099364529, 0.6738372093023256, 0.5991983967935872]\n",
      "save model\n",
      "kmeans average accuracy best : 89.52%, kmeans average accuracy : 89.52336294%, total [0.9732498577120091, 0.9747302668938104, 0.9712395743457003, 0.9573978123200921, 0.9601173020527859, 0.95, 0.9129287598944591, 0.8383437322745321, 0.9663020987289388, 0.906322505800464, 0.7929147465437788, 0.7243702401874634, 0.9402497027348394, 0.8983246678220682, 0.8200581395348837, 0.7371886630403665]\n",
      "cluster_accuracy_post_training_cycle_all_dataset : [0.97350993 0.97502356 0.97207511 0.96094503 0.96069652 0.94009434\n",
      " 0.9090005  0.81702728 0.96217852 0.91943359 0.7953668  0.71300894\n",
      " 0.93940937 0.90106693 0.81862745 0.73530817]\n",
      "mean_cluster_accuracy_during_training_cycle : 89.23%, post_traincycle_acc : 89.33%, total_acc : 89.28746273%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 89.33%\n",
      "accuracy_check 실행 시간: 23.908초\n",
      "\n",
      "\n",
      "epoch-15 loss : 0.01202782, loss_normal : 0.01480565, loss_coarse : 0.06867782, min_loss : 0.01202782, min_loss_normal : 0.01480565, min_loss_coarse : 0.06867782, wrong_element_sum : 13186142.00000000, same_data : 0.00%\n",
      "ae train 실행 시간: 116.562초, 전체 시작 시간 20250314_000023_260\n",
      "\n",
      "epoch-15 accuracy check\n",
      "k_means origin feature average accuracy : 82.25497029%, total [0.9746727376209448, 0.9733106189664963, 0.9700891573195284, 0.9530800230282096, 0.943108504398827, 0.9150568181818182, 0.801817648783348, 0.6625070901871809, 0.9488619568430388, 0.822215777262181, 0.5872695852534562, 0.5005858230814294, 0.9429250891795482, 0.8922588099364529, 0.6738372093023256, 0.5991983967935872]\n",
      "kmeans average accuracy best : 89.52%, kmeans average accuracy : 89.28946158%, total [0.9732498577120091, 0.9755820556501987, 0.9715271786022434, 0.9573978123200921, 0.9609970674486803, 0.9519886363636364, 0.9164467897977133, 0.8366420873511061, 0.9630505468519066, 0.8947215777262181, 0.7920506912442397, 0.7185120093731693, 0.942627824019025, 0.8850375505488157, 0.8087209302325581, 0.7377612367592328]\n",
      "cluster_accuracy_post_training_cycle_all_dataset : [0.97492904 0.97596607 0.9735195  0.96046287 0.9641791  0.94575472\n",
      " 0.91695674 0.82031985 0.95965709 0.90722656 0.78281853 0.70804369\n",
      " 0.94501018 0.89670223 0.81127451 0.73817487]\n",
      "mean_cluster_accuracy_during_training_cycle : 89.09%, post_traincycle_acc : 89.26%, total_acc : 89.18778418%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 89.33%\n",
      "accuracy_check 실행 시간: 22.950초\n",
      "\n",
      "\n",
      "epoch-16 loss : 0.01203171, loss_normal : 0.01480420, loss_coarse : 0.06874624, min_loss : 0.01202782, min_loss_normal : 0.01480420, min_loss_coarse : 0.06867782, wrong_element_sum : 13199278.00000000, same_data : 0.00%\n",
      "ae train 실행 시간: 120.185초, 전체 시작 시간 20250314_000023_260\n",
      "\n",
      "epoch-16 accuracy check\n",
      "k_means origin feature average accuracy : 82.24778908%, total [0.9746727376209448, 0.9733106189664963, 0.9700891573195284, 0.9530800230282096, 0.943108504398827, 0.9150568181818182, 0.801817648783348, 0.6622234826999432, 0.9488619568430388, 0.8216357308584686, 0.5866935483870968, 0.5005858230814294, 0.9429250891795482, 0.8922588099364529, 0.6741279069767442, 0.5991983967935872]\n",
      "kmeans average accuracy best : 89.52%, kmeans average accuracy : 88.93219143%, total [0.9726807057484348, 0.9741624077228848, 0.9700891573195284, 0.9573978123200921, 0.9589442815249267, 0.946875, 0.9076517150395779, 0.815655133295519, 0.9615725687259828, 0.8929814385150812, 0.7868663594470046, 0.7135325131810193, 0.9438168846611177, 0.889370306181398, 0.8052325581395349, 0.7323217864300029]\n",
      "cluster_accuracy_post_training_cycle_all_dataset : [0.97445601 0.97408106 0.97111218 0.96046287 0.960199   0.93443396\n",
      " 0.90203879 0.81138288 0.95612708 0.90429688 0.78137066 0.63853029\n",
      " 0.94246436 0.89379243 0.81470588 0.73005256]\n",
      "mean_cluster_accuracy_during_training_cycle : 88.19%, post_traincycle_acc : 88.43%, total_acc : 88.33454163%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 89.33%\n",
      "accuracy_check 실행 시간: 22.652초\n",
      "\n",
      "\n",
      "epoch-17 loss : 0.01200461, loss_normal : 0.01478202, loss_coarse : 0.06861294, min_loss : 0.01200461, min_loss_normal : 0.01478202, min_loss_coarse : 0.06861294, wrong_element_sum : 13173684.00000000, same_data : 0.00%\n",
      "ae train 실행 시간: 118.221초, 전체 시작 시간 20250314_000023_260\n",
      "\n",
      "epoch-17 accuracy check\n",
      "k_means origin feature average accuracy : 82.26042087%, total [0.9746727376209448, 0.9733106189664963, 0.9700891573195284, 0.9530800230282096, 0.943108504398827, 0.9150568181818182, 0.801817648783348, 0.6625070901871809, 0.9488619568430388, 0.822215777262181, 0.5872695852534562, 0.5005858230814294, 0.9429250891795482, 0.8922588099364529, 0.6747093023255814, 0.5991983967935872]\n",
      "kmeans average accuracy best : 89.52%, kmeans average accuracy : 88.97427928%, total [0.9735344336937962, 0.9750141964792731, 0.9721023871153293, 0.9579735175590098, 0.9609970674486803, 0.9471590909090909, 0.9135150982116681, 0.8196256381168463, 0.9580254212237659, 0.8883410672853829, 0.7816820276497696, 0.7190978324545987, 0.9432223543400713, 0.892836510687464, 0.8098837209302325, 0.7228743200687089]\n",
      "cluster_accuracy_post_training_cycle_all_dataset : [0.97587512 0.97643732 0.97303804 0.95901639 0.96119403 0.94103774\n",
      " 0.91198409 0.80338664 0.95360565 0.90185547 0.77992278 0.63952334\n",
      " 0.94297352 0.90252182 0.81421569 0.72909699]\n",
      "mean_cluster_accuracy_during_training_cycle : 88.29%, post_traincycle_acc : 88.54%, total_acc : 88.43442573%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 89.33%\n",
      "accuracy_check 실행 시간: 23.881초\n",
      "\n",
      "\n",
      "epoch-18 loss : 0.01198146, loss_normal : 0.01477599, loss_coarse : 0.06854828, min_loss : 0.01198146, min_loss_normal : 0.01477599, min_loss_coarse : 0.06854828, wrong_element_sum : 13161270.00000000, same_data : 0.00%\n",
      "ae train 실행 시간: 119.744초, 전체 시작 시간 20250314_000023_260\n",
      "\n",
      "epoch-18 accuracy check\n",
      "k_means origin feature average accuracy : 82.26401620%, total [0.9746727376209448, 0.9733106189664963, 0.9700891573195284, 0.9530800230282096, 0.943108504398827, 0.9150568181818182, 0.801817648783348, 0.6622234826999432, 0.9488619568430388, 0.822215777262181, 0.5872695852534562, 0.5005858230814294, 0.9429250891795482, 0.8922588099364529, 0.6747093023255814, 0.6000572573718866]\n",
      "kmeans average accuracy best : 89.52%, kmeans average accuracy : 88.99614372%, total [0.9732498577120091, 0.9750141964792731, 0.9706643658326143, 0.9565342544617156, 0.9607038123167155, 0.9497159090909091, 0.9135150982116681, 0.8349404424276801, 0.9583210168489507, 0.8863109048723898, 0.7764976958525346, 0.7035735207967194, 0.9542211652794292, 0.8945696129404969, 0.8058139534883721, 0.7257371886630404]\n",
      "cluster_accuracy_post_training_cycle_all_dataset : [0.97587512 0.97455231 0.97111218 0.95949855 0.96169154 0.94433962\n",
      " 0.91695674 0.81608655 0.94906707 0.90087891 0.78233591 0.7040715\n",
      " 0.95519348 0.90252182 0.81862745 0.72909699]\n",
      "mean_cluster_accuracy_during_training_cycle : 88.94%, post_traincycle_acc : 89.14%, total_acc : 89.05560778%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 89.33%\n",
      "accuracy_check 실행 시간: 22.991초\n",
      "\n",
      "\n",
      "epoch-19 loss : 0.01197190, loss_normal : 0.01477485, loss_coarse : 0.06851353, min_loss : 0.01197190, min_loss_normal : 0.01477485, min_loss_coarse : 0.06851353, wrong_element_sum : 13154598.00000000, same_data : 0.00%\n",
      "ae train 실행 시간: 115.402초, 전체 시작 시간 20250314_000023_260\n",
      "\n",
      "epoch-19 accuracy check\n",
      "k_means origin feature average accuracy : 82.24966347%, total [0.9746727376209448, 0.9733106189664963, 0.9700891573195284, 0.9530800230282096, 0.943108504398827, 0.9150568181818182, 0.801817648783348, 0.6625070901871809, 0.9488619568430388, 0.822215777262181, 0.5866935483870968, 0.5005858230814294, 0.9429250891795482, 0.8922588099364529, 0.6747093023255814, 0.5980532493558546]\n",
      "kmeans average accuracy best : 89.52%, kmeans average accuracy : 89.03229068%, total [0.972965281730222, 0.9755820556501987, 0.9700891573195284, 0.9579735175590098, 0.9592375366568915, 0.9454545454545454, 0.9073585458809733, 0.8153715258082813, 0.9642329293526456, 0.8973317865429234, 0.7799539170506913, 0.7132396016403046, 0.9441141498216409, 0.8954361640670133, 0.8125, 0.734325794446035]\n",
      "cluster_accuracy_post_training_cycle_all_dataset : [0.97492904 0.97690858 0.97207511 0.96094503 0.96119403 0.93726415\n",
      " 0.91248135 0.81420508 0.96066566 0.90429688 0.78523166 0.65640516\n",
      " 0.94399185 0.90640155 0.81617647 0.72957477]\n",
      "mean_cluster_accuracy_during_training_cycle : 88.46%, post_traincycle_acc : 88.83%, total_acc : 88.68005136%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 89.33%\n",
      "accuracy_check 실행 시간: 23.953초\n",
      "\n",
      "\n",
      "epoch-20 loss : 0.01194032, loss_normal : 0.01475575, loss_coarse : 0.06842485, min_loss : 0.01194032, min_loss_normal : 0.01475575, min_loss_coarse : 0.06842485, wrong_element_sum : 13137572.00000000, same_data : 0.00%\n",
      "ae train 실행 시간: 118.505초, 전체 시작 시간 20250314_000023_260\n",
      "\n",
      "epoch-20 accuracy check\n",
      "k_means origin feature average accuracy : 82.24598845%, total [0.9746727376209448, 0.9733106189664963, 0.9700891573195284, 0.9530800230282096, 0.943108504398827, 0.915340909090909, 0.801817648783348, 0.6625070901871809, 0.9488619568430388, 0.822215777262181, 0.5866935483870968, 0.5005858230814294, 0.9429250891795482, 0.8922588099364529, 0.6738372093023256, 0.5980532493558546]\n",
      "kmeans average accuracy best : 89.52%, kmeans average accuracy : 88.96866938%, total [0.9738190096755834, 0.9764338444065872, 0.9721023871153293, 0.9579735175590098, 0.9592375366568915, 0.9446022727272727, 0.9032541776605101, 0.8133862733976177, 0.9559562518474727, 0.8892111368909513, 0.7773617511520737, 0.7144112478031635, 0.9479785969084423, 0.901213171577123, 0.8174418604651162, 0.7306040652734039]\n",
      "cluster_accuracy_post_training_cycle_all_dataset : [0.97587512 0.97596607 0.97255657 0.95949855 0.960199   0.93584906\n",
      " 0.90004973 0.80950141 0.94957136 0.90478516 0.76689189 0.63207547\n",
      " 0.9490835  0.90252182 0.8254902  0.72670807]\n",
      "mean_cluster_accuracy_during_training_cycle : 87.98%, post_traincycle_acc : 88.42%, total_acc : 88.23797537%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 89.33%\n",
      "accuracy_check 실행 시간: 24.166초\n",
      "\n",
      "\n",
      "epoch-21 loss : 0.01193696, loss_normal : 0.01476368, loss_coarse : 0.06842432, min_loss : 0.01193696, min_loss_normal : 0.01475575, min_loss_coarse : 0.06842432, wrong_element_sum : 13137470.00000000, same_data : 0.00%\n",
      "ae train 실행 시간: 113.666초, 전체 시작 시간 20250314_000023_260\n",
      "\n",
      "epoch-21 accuracy check\n",
      "k_means origin feature average accuracy : 82.25862668%, total [0.9746727376209448, 0.9733106189664963, 0.9700891573195284, 0.9530800230282096, 0.943108504398827, 0.9150568181818182, 0.801817648783348, 0.6622234826999432, 0.9488619568430388, 0.822215777262181, 0.5866935483870968, 0.5005858230814294, 0.9429250891795482, 0.8922588099364529, 0.6747093023255814, 0.5997709705124534]\n",
      "kmeans average accuracy best : 89.52%, kmeans average accuracy : 89.14601913%, total [0.9741035856573705, 0.975298126064736, 0.9706643658326143, 0.9573978123200921, 0.9598240469208211, 0.9457386363636363, 0.909410729991205, 0.8204764605785593, 0.9624593556015371, 0.9011020881670534, 0.7923387096774194, 0.7170474516695958, 0.952140309155767, 0.8983246678220682, 0.8101744186046511, 0.7168622960206127]\n",
      "cluster_accuracy_post_training_cycle_all_dataset : [0.97634816 0.97596607 0.97255657 0.96142719 0.96069652 0.94056604\n",
      " 0.9075087  0.79868297 0.95713565 0.90478516 0.78957529 0.71598808\n",
      " 0.95366599 0.90834142 0.81764706 0.72384138]\n",
      "mean_cluster_accuracy_during_training_cycle : 88.82%, post_traincycle_acc : 89.15%, total_acc : 89.01553285%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 89.33%\n",
      "accuracy_check 실행 시간: 23.879초\n",
      "\n",
      "\n",
      "epoch-22 loss : 0.01193093, loss_normal : 0.01476010, loss_coarse : 0.06843958, min_loss : 0.01193093, min_loss_normal : 0.01475575, min_loss_coarse : 0.06842432, wrong_element_sum : 13140400.00000000, same_data : 0.00%\n",
      "ae train 실행 시간: 88.343초, 전체 시작 시간 20250314_000023_260\n",
      "\n",
      "epoch-22 accuracy check\n",
      "k_means origin feature average accuracy : 82.26032735%, total [0.9746727376209448, 0.9733106189664963, 0.9700891573195284, 0.9530800230282096, 0.943108504398827, 0.915340909090909, 0.801817648783348, 0.6622234826999432, 0.9488619568430388, 0.822215777262181, 0.5872695852534562, 0.5002929115407148, 0.9429250891795482, 0.8922588099364529, 0.6741279069767442, 0.6000572573718866]\n",
      "kmeans average accuracy best : 89.52%, kmeans average accuracy : 88.93993070%, total [0.9732498577120091, 0.9744463373083475, 0.9703767615760713, 0.9556706966033391, 0.9601173020527859, 0.9505681818181818, 0.9117560832600411, 0.8204764605785593, 0.9618681643511676, 0.8857308584686775, 0.7825460829493087, 0.7135325131810193, 0.9497621878715814, 0.8913922588099364, 0.8005813953488372, 0.7283137703979388]\n",
      "cluster_accuracy_post_training_cycle_all_dataset : [0.97587512 0.97596607 0.97159364 0.95853423 0.96119403 0.94716981\n",
      " 0.91148682 0.81749765 0.95663137 0.89306641 0.77799228 0.71102284\n",
      " 0.94857434 0.8986421  0.80294118 0.73005256]\n",
      "mean_cluster_accuracy_during_training_cycle : 88.66%, post_traincycle_acc : 88.99%, total_acc : 88.85506454%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 89.33%\n",
      "accuracy_check 실행 시간: 22.804초\n",
      "\n",
      "\n",
      "epoch-23 loss : 0.01189915, loss_normal : 0.01474832, loss_coarse : 0.06834629, min_loss : 0.01189915, min_loss_normal : 0.01474832, min_loss_coarse : 0.06834629, wrong_element_sum : 13122488.00000000, same_data : 0.00%\n",
      "ae train 실행 시간: 117.396초, 전체 시작 시간 20250314_000023_260\n",
      "\n",
      "epoch-23 accuracy check\n",
      "k_means origin feature average accuracy : 82.24780230%, total [0.9746727376209448, 0.9733106189664963, 0.9700891573195284, 0.9530800230282096, 0.943108504398827, 0.9150568181818182, 0.801817648783348, 0.6622234826999432, 0.9488619568430388, 0.822215777262181, 0.5872695852534562, 0.5005858230814294, 0.9429250891795482, 0.8922588099364529, 0.673546511627907, 0.5986258230747209]\n",
      "kmeans average accuracy best : 89.52%, kmeans average accuracy : 89.12938277%, total [0.9741035856573705, 0.9750141964792731, 0.9718147828587863, 0.957685664939551, 0.9612903225806452, 0.9457386363636363, 0.9114629141014365, 0.8102665910380034, 0.9627549512267218, 0.8976218097447796, 0.7816820276497696, 0.7120679554774458, 0.9473840665873959, 0.8977469670710572, 0.8180232558139535, 0.7360435156026338]\n",
      "cluster_accuracy_post_training_cycle_all_dataset : [0.97682119 0.97502356 0.97255657 0.95901639 0.96169154 0.93915094\n",
      " 0.91546494 0.80950141 0.95612708 0.90283203 0.78185328 0.70357498\n",
      " 0.94602851 0.90349176 0.81960784 0.74056378]\n",
      "mean_cluster_accuracy_during_training_cycle : 89.04%, post_traincycle_acc : 89.15%, total_acc : 89.10135731%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 89.33%\n",
      "accuracy_check 실행 시간: 24.252초\n",
      "\n",
      "\n",
      "epoch-24 loss : 0.01187457, loss_normal : 0.01472964, loss_coarse : 0.06827964, min_loss : 0.01187457, min_loss_normal : 0.01472964, min_loss_coarse : 0.06827964, wrong_element_sum : 13109692.00000000, same_data : 0.00%\n",
      "ae train 실행 시간: 118.578초, 전체 시작 시간 20250314_000023_260\n",
      "\n",
      "epoch-24 accuracy check\n",
      "k_means origin feature average accuracy : 82.25129052%, total [0.9746727376209448, 0.9733106189664963, 0.9700891573195284, 0.9530800230282096, 0.943108504398827, 0.9150568181818182, 0.8015244796247435, 0.6625070901871809, 0.9488619568430388, 0.822215777262181, 0.5866935483870968, 0.5005858230814294, 0.9429250891795482, 0.8911034084344309, 0.6741279069767442, 0.6003435442313197]\n",
      "kmeans average accuracy best : 89.52%, kmeans average accuracy : 89.33952621%, total [0.9732498577120091, 0.975298126064736, 0.9712395743457003, 0.9579735175590098, 0.9595307917888563, 0.9477272727272728, 0.9058927000879508, 0.8184912081678957, 0.9630505468519066, 0.9013921113689095, 0.7923387096774194, 0.7190978324545987, 0.9503567181926278, 0.901790872328134, 0.8156976744186046, 0.7411966790724306]\n",
      "cluster_accuracy_post_training_cycle_all_dataset : [0.97540208 0.97502356 0.97207511 0.96142719 0.96218905 0.93679245\n",
      " 0.90154152 0.81279398 0.95562279 0.90332031 0.79874517 0.69761668\n",
      " 0.95213849 0.90252182 0.8122549  0.72670807]\n",
      "mean_cluster_accuracy_during_training_cycle : 89.13%, post_traincycle_acc : 89.04%, total_acc : 89.07667938%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 89.33%\n",
      "accuracy_check 실행 시간: 22.785초\n",
      "\n",
      "\n",
      "epoch-25 loss : 0.01189517, loss_normal : 0.01473734, loss_coarse : 0.06833504, min_loss : 0.01187457, min_loss_normal : 0.01472964, min_loss_coarse : 0.06827964, wrong_element_sum : 13120328.00000000, same_data : 0.00%\n",
      "ae train 실행 시간: 114.938초, 전체 시작 시간 20250314_000023_260\n",
      "\n",
      "epoch-25 accuracy check\n",
      "k_means origin feature average accuracy : 82.24239929%, total [0.9746727376209448, 0.9733106189664963, 0.9700891573195284, 0.9530800230282096, 0.943108504398827, 0.9150568181818182, 0.801817648783348, 0.6622234826999432, 0.9488619568430388, 0.822215777262181, 0.5866935483870968, 0.5005858230814294, 0.942627824019025, 0.8922588099364529, 0.6741279069767442, 0.5980532493558546]\n",
      "kmeans average accuracy best : 89.52%, kmeans average accuracy : 88.60885059%, total [0.9735344336937962, 0.9761499148211243, 0.9709519700891573, 0.9573978123200921, 0.9601173020527859, 0.9443181818181818, 0.9032541776605101, 0.816505955757232, 0.9633461424770914, 0.8793503480278422, 0.7641129032258065, 0.7053309900410076, 0.9458977407847801, 0.89052570768342, 0.8017441860465117, 0.724878328084741]\n",
      "cluster_accuracy_post_training_cycle_all_dataset : [0.97587512 0.97502356 0.97255657 0.95949855 0.96119403 0.93443396\n",
      " 0.90502238 0.81138288 0.95310136 0.89697266 0.76447876 0.69960278\n",
      " 0.94755601 0.90058196 0.82401961 0.72336359]\n",
      "mean_cluster_accuracy_during_training_cycle : 88.21%, post_traincycle_acc : 88.78%, total_acc : 88.54393190%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 89.33%\n",
      "accuracy_check 실행 시간: 23.738초\n",
      "\n",
      "\n",
      "epoch-26 loss : 0.01188483, loss_normal : 0.01472788, loss_coarse : 0.06829357, min_loss : 0.01187457, min_loss_normal : 0.01472788, min_loss_coarse : 0.06827964, wrong_element_sum : 13112366.00000000, same_data : 0.00%\n",
      "ae train 실행 시간: 108.238초, 전체 시작 시간 20250314_000023_260\n",
      "\n",
      "epoch-26 accuracy check\n",
      "k_means origin feature average accuracy : 82.24062348%, total [0.9746727376209448, 0.9733106189664963, 0.9700891573195284, 0.9530800230282096, 0.943108504398827, 0.9150568181818182, 0.801817648783348, 0.6622234826999432, 0.9488619568430388, 0.822215777262181, 0.5866935483870968, 0.5005858230814294, 0.9429250891795482, 0.8922588099364529, 0.673546511627907, 0.5980532493558546]\n",
      "kmeans average accuracy best : 89.52%, kmeans average accuracy : 89.31182237%, total [0.9735344336937962, 0.975298126064736, 0.9706643658326143, 0.9582613701784686, 0.9612903225806452, 0.9494318181818182, 0.9193784813837584, 0.8366420873511061, 0.9642329293526456, 0.9034222737819025, 0.7929147465437788, 0.7179261862917399, 0.9402497027348394, 0.8856152512998267, 0.8078488372093023, 0.7331806470083023]\n",
      "cluster_accuracy_post_training_cycle_all_dataset : [0.97587512 0.97643732 0.97111218 0.96142719 0.96218905 0.93962264\n",
      " 0.91447041 0.82361242 0.96066566 0.90087891 0.79198842 0.69860973\n",
      " 0.9404277  0.89088264 0.81176471 0.73053034]\n",
      "mean_cluster_accuracy_during_training_cycle : 88.98%, post_traincycle_acc : 89.07%, total_acc : 89.03065344%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 89.33%\n",
      "accuracy_check 실행 시간: 24.370초\n",
      "\n",
      "\n",
      "epoch-27 loss : 0.01183051, loss_normal : 0.01471992, loss_coarse : 0.06819331, min_loss : 0.01183051, min_loss_normal : 0.01471992, min_loss_coarse : 0.06819331, wrong_element_sum : 13093116.00000000, same_data : 0.00%\n",
      "ae train 실행 시간: 115.920초, 전체 시작 시간 20250314_000023_260\n",
      "\n",
      "epoch-27 accuracy check\n",
      "k_means origin feature average accuracy : 82.26398299%, total [0.9746727376209448, 0.9733106189664963, 0.9700891573195284, 0.9530800230282096, 0.943108504398827, 0.9150568181818182, 0.8015244796247435, 0.6622234826999432, 0.9488619568430388, 0.822215777262181, 0.5889976958525346, 0.5005858230814294, 0.9429250891795482, 0.8922588099364529, 0.6741279069767442, 0.5991983967935872]\n",
      "kmeans average accuracy best : 89.52%, kmeans average accuracy : 89.19798174%, total [0.9743881616391576, 0.9758659852356616, 0.9712395743457003, 0.9579735175590098, 0.9618768328445748, 0.9511363636363637, 0.9079448841981823, 0.8057288712422008, 0.9612769731007981, 0.8932714617169374, 0.7848502304147466, 0.7208553016988869, 0.9494649227110583, 0.901213171577123, 0.8148255813953489, 0.7397652447752648]\n",
      "cluster_accuracy_post_training_cycle_all_dataset : [0.97634816 0.97643732 0.97255657 0.95998071 0.96169154 0.94386792\n",
      " 0.90502238 0.81749765 0.95864851 0.91210938 0.77895753 0.64200596\n",
      " 0.95010183 0.90882638 0.82647059 0.7343526 ]\n",
      "mean_cluster_accuracy_during_training_cycle : 88.58%, post_traincycle_acc : 88.91%, total_acc : 88.77054176%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 89.33%\n",
      "accuracy_check 실행 시간: 23.357초\n",
      "\n",
      "\n",
      "epoch-28 loss : 0.01182226, loss_normal : 0.01471479, loss_coarse : 0.06815302, min_loss : 0.01182226, min_loss_normal : 0.01471479, min_loss_coarse : 0.06815302, wrong_element_sum : 13085380.00000000, same_data : 0.00%\n",
      "ae train 실행 시간: 112.312초, 전체 시작 시간 20250314_000023_260\n",
      "\n",
      "epoch-28 accuracy check\n",
      "k_means origin feature average accuracy : 82.25314853%, total [0.9746727376209448, 0.9733106189664963, 0.9700891573195284, 0.9530800230282096, 0.943108504398827, 0.9150568181818182, 0.801817648783348, 0.6622234826999432, 0.9488619568430388, 0.822215777262181, 0.5866935483870968, 0.5005858230814294, 0.9429250891795482, 0.8922588099364529, 0.673546511627907, 0.6000572573718866]\n",
      "kmeans average accuracy best : 89.52%, kmeans average accuracy : 88.51500810%, total [0.9743881616391576, 0.9750141964792731, 0.9712395743457003, 0.9573978123200921, 0.9592375366568915, 0.9463068181818182, 0.9091175608326004, 0.8255813953488372, 0.9547738693467337, 0.8747099767981439, 0.7655529953917051, 0.6971294669009959, 0.9423305588585018, 0.8890814558058926, 0.797093023255814, 0.7234468937875751]\n",
      "cluster_accuracy_post_training_cycle_all_dataset : [0.97682119 0.97455231 0.97111218 0.95901639 0.95970149 0.93820755\n",
      " 0.90303332 0.79868297 0.9480585  0.89453125 0.73696911 0.71052632\n",
      " 0.94348269 0.89815713 0.81470588 0.71858576]\n",
      "mean_cluster_accuracy_during_training_cycle : 87.98%, post_traincycle_acc : 88.41%, total_acc : 88.23504575%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 89.33%\n",
      "accuracy_check 실행 시간: 23.177초\n",
      "\n",
      "\n",
      "epoch-29 loss : 0.01181731, loss_normal : 0.01470954, loss_coarse : 0.06815145, min_loss : 0.01181731, min_loss_normal : 0.01470954, min_loss_coarse : 0.06815145, wrong_element_sum : 13085078.00000000, same_data : 0.00%\n",
      "ae train 실행 시간: 109.893초, 전체 시작 시간 20250314_000023_260\n",
      "\n",
      "epoch-29 accuracy check\n",
      "k_means origin feature average accuracy : 82.25684228%, total [0.9746727376209448, 0.9733106189664963, 0.9700891573195284, 0.9530800230282096, 0.943108504398827, 0.9150568181818182, 0.801817648783348, 0.6625070901871809, 0.9488619568430388, 0.822215777262181, 0.5872695852534562, 0.5005858230814294, 0.9429250891795482, 0.8922588099364529, 0.6747093023255814, 0.5986258230747209]\n",
      "kmeans average accuracy best : 89.52%, kmeans average accuracy : 89.09077883%, total [0.9738190096755834, 0.9750141964792731, 0.9715271786022434, 0.957685664939551, 0.9598240469208211, 0.9463068181818182, 0.9055995309293462, 0.8218944980147476, 0.9621637599763524, 0.8834106728538283, 0.7767857142857143, 0.7065026362038664, 0.9515457788347206, 0.9041016753321779, 0.8168604651162791, 0.7414829659318637]\n",
      "cluster_accuracy_post_training_cycle_all_dataset : [0.97587512 0.97549482 0.97255657 0.95998071 0.960199   0.93160377\n",
      " 0.90601691 0.80620884 0.95511851 0.90039062 0.77799228 0.69563059\n",
      " 0.95570265 0.90252182 0.82254902 0.74438605]\n",
      "mean_cluster_accuracy_during_training_cycle : 88.75%, post_traincycle_acc : 89.01%, total_acc : 88.90340347%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 89.33%\n",
      "accuracy_check 실행 시간: 23.790초\n",
      "\n",
      "\n",
      "epoch-30 loss : 0.01182610, loss_normal : 0.01470440, loss_coarse : 0.06813993, min_loss : 0.01181731, min_loss_normal : 0.01470440, min_loss_coarse : 0.06813993, wrong_element_sum : 13082866.00000000, same_data : 0.00%\n",
      "ae train 실행 시간: 108.012초, 전체 시작 시간 20250314_000023_260\n",
      "\n",
      "epoch-30 accuracy check\n",
      "k_means origin feature average accuracy : 82.24057036%, total [0.9746727376209448, 0.9733106189664963, 0.9700891573195284, 0.9530800230282096, 0.943108504398827, 0.9150568181818182, 0.801817648783348, 0.6622234826999432, 0.9488619568430388, 0.8216357308584686, 0.5866935483870968, 0.5005858230814294, 0.942627824019025, 0.8913922588099364, 0.6747093023255814, 0.5986258230747209]\n",
      "kmeans average accuracy best : 89.52%, kmeans average accuracy : 89.14029049%, total [0.9735344336937962, 0.975298126064736, 0.9700891573195284, 0.9571099597006333, 0.9612903225806452, 0.9477272727272728, 0.9017883318674875, 0.8057288712422008, 0.9589122080993201, 0.8973317865429234, 0.7816820276497696, 0.713825424721734, 0.9518430439952438, 0.9055459272097054, 0.8238372093023256, 0.7369023761809333]\n",
      "cluster_accuracy_post_training_cycle_all_dataset : [0.97587512 0.97643732 0.97063072 0.95998071 0.96218905 0.93207547\n",
      " 0.90353058 0.80197554 0.95461422 0.90087891 0.78281853 0.70456802\n",
      " 0.95315682 0.90494665 0.82990196 0.7343526 ]\n",
      "mean_cluster_accuracy_during_training_cycle : 88.78%, post_traincycle_acc : 89.05%, total_acc : 88.93630498%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 89.33%\n",
      "accuracy_check 실행 시간: 23.303초\n",
      "\n",
      "\n",
      "epoch-31 loss : 0.01178721, loss_normal : 0.01467958, loss_coarse : 0.06803038, min_loss : 0.01178721, min_loss_normal : 0.01467958, min_loss_coarse : 0.06803038, wrong_element_sum : 13061834.00000000, same_data : 0.00%\n",
      "ae train 실행 시간: 119.380초, 전체 시작 시간 20250314_000023_260\n",
      "\n",
      "epoch-31 accuracy check\n",
      "k_means origin feature average accuracy : 82.23881505%, total [0.9746727376209448, 0.9733106189664963, 0.9700891573195284, 0.9530800230282096, 0.943108504398827, 0.9150568181818182, 0.801817648783348, 0.6622234826999432, 0.9488619568430388, 0.8216357308584686, 0.5866935483870968, 0.5005858230814294, 0.9429250891795482, 0.8922588099364529, 0.6738372093023256, 0.5980532493558546]\n",
      "kmeans average accuracy best : 89.52%, kmeans average accuracy : 88.77099402%, total [0.9746727376209448, 0.9761499148211243, 0.9723899913718723, 0.957685664939551, 0.9592375366568915, 0.9480113636363636, 0.9064790384051598, 0.7994895065229722, 0.9603901862252439, 0.8871809744779582, 0.7793778801843319, 0.7106033977738723, 0.9429250891795482, 0.892836510687464, 0.8113372093023256, 0.7245920412253077]\n",
      "cluster_accuracy_post_training_cycle_all_dataset : [0.97682119 0.97643732 0.97303804 0.95949855 0.95920398 0.94292453\n",
      " 0.91098956 0.80338664 0.95007564 0.88476562 0.76737452 0.70307845\n",
      " 0.94602851 0.90009699 0.81617647 0.71428571]\n",
      "mean_cluster_accuracy_during_training_cycle : 88.39%, post_traincycle_acc : 88.65%, total_acc : 88.54324524%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 89.33%\n",
      "accuracy_check 실행 시간: 24.368초\n",
      "\n",
      "\n",
      "epoch-32 loss : 0.01178837, loss_normal : 0.01468285, loss_coarse : 0.06811749, min_loss : 0.01178721, min_loss_normal : 0.01467958, min_loss_coarse : 0.06803038, wrong_element_sum : 13078558.00000000, same_data : 0.00%\n",
      "ae train 실행 시간: 121.304초, 전체 시작 시간 20250314_000023_260\n",
      "\n",
      "epoch-32 accuracy check\n",
      "k_means origin feature average accuracy : 82.25503135%, total [0.9746727376209448, 0.9733106189664963, 0.9700891573195284, 0.9530800230282096, 0.943108504398827, 0.9150568181818182, 0.801817648783348, 0.6625070901871809, 0.9488619568430388, 0.822215777262181, 0.5866935483870968, 0.5005858230814294, 0.9429250891795482, 0.8922588099364529, 0.6747093023255814, 0.598912109934154]\n",
      "kmeans average accuracy best : 89.52%, kmeans average accuracy : 89.12980726%, total [0.9741035856573705, 0.9747302668938104, 0.9709519700891573, 0.957685664939551, 0.9607038123167155, 0.9448863636363637, 0.8944591029023746, 0.787861599546228, 0.9642329293526456, 0.9019721577726219, 0.7940668202764977, 0.7261277094317516, 0.9536266349583828, 0.9093009820912767, 0.8186046511627907, 0.7274549098196392]\n",
      "cluster_accuracy_post_training_cycle_all_dataset : [0.97634816 0.97596607 0.97159364 0.95901639 0.96268657 0.93396226\n",
      " 0.90203879 0.7953904  0.96066566 0.91308594 0.79343629 0.71350546\n",
      " 0.95417515 0.91028128 0.81862745 0.72240803]\n",
      "mean_cluster_accuracy_during_training_cycle : 88.92%, post_traincycle_acc : 89.14%, total_acc : 89.04908492%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 89.33%\n",
      "accuracy_check 실행 시간: 24.483초\n",
      "\n",
      "\n",
      "epoch-33 loss : 0.01174741, loss_normal : 0.01467958, loss_coarse : 0.06796604, min_loss : 0.01174741, min_loss_normal : 0.01467958, min_loss_coarse : 0.06796604, wrong_element_sum : 13049480.00000000, same_data : 0.00%\n",
      "ae train 실행 시간: 116.601초, 전체 시작 시간 20250314_000023_260\n",
      "\n",
      "epoch-33 accuracy check\n",
      "k_means origin feature average accuracy : 82.25137006%, total [0.9746727376209448, 0.9733106189664963, 0.9700891573195284, 0.9530800230282096, 0.943108504398827, 0.9150568181818182, 0.801817648783348, 0.6625070901871809, 0.9488619568430388, 0.822215777262181, 0.5866935483870968, 0.5005858230814294, 0.9429250891795482, 0.8922588099364529, 0.6738372093023256, 0.5991983967935872]\n",
      "kmeans average accuracy best : 89.52%, kmeans average accuracy : 89.21070366%, total [0.9735344336937962, 0.975298126064736, 0.9706643658326143, 0.9573978123200921, 0.9589442815249267, 0.9434659090909091, 0.8950454412195837, 0.7941009642654566, 0.9600945906000591, 0.8903712296983759, 0.7894585253456221, 0.7167545401288811, 0.9560047562425684, 0.9176776429809359, 0.8325581395348837, 0.7423418265101632]\n",
      "cluster_accuracy_post_training_cycle_all_dataset : [0.97587512 0.97643732 0.97111218 0.95853423 0.960199   0.93490566\n",
      " 0.89557434 0.78786453 0.95209279 0.90332031 0.78233591 0.70655412\n",
      " 0.95570265 0.91076625 0.83039216 0.74773053]\n",
      "mean_cluster_accuracy_during_training_cycle : 88.33%, post_traincycle_acc : 89.06%, total_acc : 88.75743149%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 89.33%\n",
      "accuracy_check 실행 시간: 24.159초\n",
      "\n",
      "\n",
      "epoch-34 loss : 0.01176574, loss_normal : 0.01467433, loss_coarse : 0.06798660, min_loss : 0.01174741, min_loss_normal : 0.01467433, min_loss_coarse : 0.06796604, wrong_element_sum : 13053428.00000000, same_data : 0.00%\n",
      "ae train 실행 시간: 120.153초, 전체 시작 시간 20250314_000023_260\n",
      "\n",
      "epoch-34 accuracy check\n",
      "k_means origin feature average accuracy : 82.26390131%, total [0.9746727376209448, 0.9733106189664963, 0.9700891573195284, 0.9530800230282096, 0.943108504398827, 0.9150568181818182, 0.8015244796247435, 0.6625070901871809, 0.9488619568430388, 0.822215777262181, 0.5872695852534562, 0.5005858230814294, 0.9429250891795482, 0.8922588099364529, 0.6741279069767442, 0.600629831090753]\n",
      "kmeans average accuracy best : 89.52%, kmeans average accuracy : 88.95717042%, total [0.9735344336937962, 0.975298126064736, 0.9703767615760713, 0.957685664939551, 0.9589442815249267, 0.9423295454545455, 0.9082380533567869, 0.8085649461145774, 0.9577298255985811, 0.8825406032482599, 0.7756336405529954, 0.7082601054481547, 0.9500594530321046, 0.9061236279607163, 0.8206395348837209, 0.7371886630403665]\n",
      "cluster_accuracy_post_training_cycle_all_dataset : [0.97587512 0.97502356 0.97207511 0.95901639 0.960199   0.93679245\n",
      " 0.90850323 0.81185325 0.94957136 0.89306641 0.7746139  0.69612711\n",
      " 0.94602851 0.90882638 0.82352941 0.73674152]\n",
      "mean_cluster_accuracy_during_training_cycle : 88.65%, post_traincycle_acc : 88.92%, total_acc : 88.81136139%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 89.33%\n",
      "accuracy_check 실행 시간: 22.764초\n",
      "\n",
      "\n",
      "epoch-35 loss : 0.01176379, loss_normal : 0.01467331, loss_coarse : 0.06799043, min_loss : 0.01174741, min_loss_normal : 0.01467331, min_loss_coarse : 0.06796604, wrong_element_sum : 13054162.00000000, same_data : 0.00%\n",
      "ae train 실행 시간: 116.104초, 전체 시작 시간 20250314_000023_260\n",
      "\n",
      "epoch-35 accuracy check\n",
      "k_means origin feature average accuracy : 82.25141437%, total [0.9746727376209448, 0.9733106189664963, 0.9700891573195284, 0.9530800230282096, 0.943108504398827, 0.9150568181818182, 0.801817648783348, 0.6622234826999432, 0.9488619568430388, 0.822215777262181, 0.5866935483870968, 0.5005858230814294, 0.9429250891795482, 0.8922588099364529, 0.6741279069767442, 0.5991983967935872]\n",
      "kmeans average accuracy best : 89.52%, kmeans average accuracy : 89.09532919%, total [0.9743881616391576, 0.97671777399205, 0.9723899913718723, 0.957685664939551, 0.9595307917888563, 0.944034090909091, 0.9041336851363236, 0.816505955757232, 0.9618681643511676, 0.8909512761020881, 0.7877304147465438, 0.7179261862917399, 0.9488703923900119, 0.901213171577123, 0.8072674418604651, 0.7340395075866017]\n",
      "cluster_accuracy_post_training_cycle_all_dataset : [0.97682119 0.97737983 0.97207511 0.95998071 0.96119403 0.93301887\n",
      " 0.90651417 0.80620884 0.95410993 0.8984375  0.75434363 0.71201589\n",
      " 0.95112016 0.90349176 0.81421569 0.740086  ]\n",
      "mean_cluster_accuracy_during_training_cycle : 88.71%, post_traincycle_acc : 88.88%, total_acc : 88.81122061%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 89.33%\n",
      "accuracy_check 실행 시간: 24.225초\n",
      "\n",
      "\n",
      "epoch-36 loss : 0.01177926, loss_normal : 0.01468230, loss_coarse : 0.06803701, min_loss : 0.01174741, min_loss_normal : 0.01467331, min_loss_coarse : 0.06796604, wrong_element_sum : 13063106.00000000, same_data : 0.00%\n",
      "ae train 실행 시간: 100.080초, 전체 시작 시간 20250314_000023_260\n",
      "\n",
      "epoch-36 accuracy check\n",
      "k_means origin feature average accuracy : 82.26934569%, total [0.9746727376209448, 0.9733106189664963, 0.9700891573195284, 0.9530800230282096, 0.943108504398827, 0.9150568181818182, 0.801817648783348, 0.6625070901871809, 0.9488619568430388, 0.822215777262181, 0.5866935483870968, 0.5005858230814294, 0.9429250891795482, 0.8922588099364529, 0.6747093023255814, 0.6012024048096193]\n",
      "kmeans average accuracy best : 89.52%, kmeans average accuracy : 88.64174968%, total [0.9746727376209448, 0.9764338444065872, 0.9726775956284153, 0.9573978123200921, 0.9589442815249267, 0.9383522727272727, 0.9047200234535326, 0.8238797504254113, 0.9544782737215489, 0.872969837587007, 0.7641129032258065, 0.70298769771529, 0.9482758620689655, 0.8937030618139804, 0.811046511627907, 0.7280274835385055]\n",
      "cluster_accuracy_post_training_cycle_all_dataset : [0.97729423 0.97690858 0.97303804 0.95901639 0.96119403 0.93018868\n",
      " 0.90154152 0.80056444 0.9404942  0.88574219 0.74855212 0.63654419\n",
      " 0.94857434 0.90009699 0.82156863 0.72814142]\n",
      "mean_cluster_accuracy_during_training_cycle : 87.87%, post_traincycle_acc : 88.06%, total_acc : 87.97991402%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 89.33%\n",
      "accuracy_check 실행 시간: 23.086초\n",
      "\n",
      "\n",
      "epoch-37 loss : 0.01174508, loss_normal : 0.01465311, loss_coarse : 0.06789759, min_loss : 0.01174508, min_loss_normal : 0.01465311, min_loss_coarse : 0.06789759, wrong_element_sum : 13036338.00000000, same_data : 0.00%\n",
      "ae train 실행 시간: 120.537초, 전체 시작 시간 20250314_000023_260\n",
      "\n",
      "epoch-37 accuracy check\n",
      "k_means origin feature average accuracy : 82.24597222%, total [0.9746727376209448, 0.9733106189664963, 0.9700891573195284, 0.9530800230282096, 0.943108504398827, 0.9150568181818182, 0.801817648783348, 0.6622234826999432, 0.9488619568430388, 0.8216357308584686, 0.5866935483870968, 0.5005858230814294, 0.9429250891795482, 0.8922588099364529, 0.6738372093023256, 0.5991983967935872]\n",
      "kmeans average accuracy best : 89.52%, kmeans average accuracy : 89.27268553%, total [0.9732498577120091, 0.9755820556501987, 0.9709519700891573, 0.9568221070811744, 0.9592375366568915, 0.9394886363636363, 0.9050131926121372, 0.815655133295519, 0.9633461424770914, 0.9071925754060325, 0.7943548387096774, 0.7214411247803163, 0.9473840665873959, 0.9067013287117274, 0.8188953488372093, 0.7283137703979388]\n",
      "cluster_accuracy_post_training_cycle_all_dataset : [0.97540208 0.97643732 0.97207511 0.95949855 0.960199   0.92735849\n",
      " 0.90601691 0.81185325 0.95612708 0.91162109 0.78667954 0.70059583\n",
      " 0.94653768 0.90979631 0.82205882 0.72479694]\n",
      "mean_cluster_accuracy_during_training_cycle : 89.01%, post_traincycle_acc : 89.04%, total_acc : 89.02934865%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 89.33%\n",
      "accuracy_check 실행 시간: 24.248초\n",
      "\n",
      "\n",
      "epoch-38 loss : 0.01174926, loss_normal : 0.01465626, loss_coarse : 0.06791069, min_loss : 0.01174508, min_loss_normal : 0.01465311, min_loss_coarse : 0.06789759, wrong_element_sum : 13038852.00000000, same_data : 0.00%\n",
      "ae train 실행 시간: 121.344초, 전체 시작 시간 20250314_000023_260\n",
      "\n",
      "epoch-38 accuracy check\n",
      "k_means origin feature average accuracy : 82.25489340%, total [0.9746727376209448, 0.9733106189664963, 0.9700891573195284, 0.9530800230282096, 0.943108504398827, 0.9150568181818182, 0.801817648783348, 0.6625070901871809, 0.9488619568430388, 0.822215777262181, 0.5866935483870968, 0.5, 0.9429250891795482, 0.8922588099364529, 0.6741279069767442, 0.6000572573718866]\n",
      "kmeans average accuracy best : 89.52%, kmeans average accuracy : 89.30925495%, total [0.9735344336937962, 0.9764338444065872, 0.9718147828587863, 0.9585492227979274, 0.9601173020527859, 0.9474431818181818, 0.9149809440046907, 0.8218944980147476, 0.9612769731007981, 0.8950116009280742, 0.7845622119815668, 0.7170474516695958, 0.9518430439952438, 0.8991912189485847, 0.8177325581395349, 0.7380475236186659]\n",
      "cluster_accuracy_post_training_cycle_all_dataset : [0.97587512 0.97690858 0.97303804 0.95998071 0.96169154 0.93490566\n",
      " 0.91397315 0.80809031 0.95663137 0.90722656 0.79102317 0.69563059\n",
      " 0.95315682 0.8986421  0.82254902 0.7458194 ]\n",
      "mean_cluster_accuracy_during_training_cycle : 89.03%, post_traincycle_acc : 89.22%, total_acc : 89.14104846%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 89.33%\n",
      "accuracy_check 실행 시간: 23.990초\n",
      "\n",
      "\n",
      "epoch-39 loss : 0.01178380, loss_normal : 0.01467383, loss_coarse : 0.06800245, min_loss : 0.01174508, min_loss_normal : 0.01465311, min_loss_coarse : 0.06789759, wrong_element_sum : 13056470.00000000, same_data : 0.00%\n",
      "ae train 실행 시간: 121.355초, 전체 시작 시간 20250314_000023_260\n",
      "\n",
      "epoch-39 accuracy check\n",
      "k_means origin feature average accuracy : 82.25850586%, total [0.9746727376209448, 0.9733106189664963, 0.9700891573195284, 0.9530800230282096, 0.943108504398827, 0.9150568181818182, 0.8015244796247435, 0.6625070901871809, 0.9488619568430388, 0.822215777262181, 0.5872695852534562, 0.5005858230814294, 0.9429250891795482, 0.8922588099364529, 0.6738372093023256, 0.6000572573718866]\n",
      "kmeans average accuracy best : 89.52%, kmeans average accuracy : 89.34113178%, total [0.972965281730222, 0.9755820556501987, 0.9700891573195284, 0.9571099597006333, 0.9592375366568915, 0.946590909090909, 0.9088243916739959, 0.8207600680657969, 0.9633461424770914, 0.8955916473317865, 0.7880184331797235, 0.7208553016988869, 0.9467895362663495, 0.902368573079145, 0.8229651162790698, 0.7434869739478958]\n",
      "cluster_accuracy_post_training_cycle_all_dataset : [0.97587512 0.97643732 0.97255657 0.95998071 0.96069652 0.93773585\n",
      " 0.90949776 0.81655691 0.95713565 0.89941406 0.78764479 0.7000993\n",
      " 0.94704684 0.89670223 0.81666667 0.74534161]\n",
      "mean_cluster_accuracy_during_training_cycle : 88.79%, post_traincycle_acc : 89.12%, total_acc : 88.98656722%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 89.33%\n",
      "accuracy_check 실행 시간: 23.763초\n",
      "\n",
      "\n",
      "epoch-40 loss : 0.01175270, loss_normal : 0.01466180, loss_coarse : 0.06792886, min_loss : 0.01174508, min_loss_normal : 0.01465311, min_loss_coarse : 0.06789759, wrong_element_sum : 13042342.00000000, same_data : 0.00%\n",
      "ae train 실행 시간: 119.998초, 전체 시작 시간 20250314_000023_260\n",
      "\n",
      "epoch-40 accuracy check\n",
      "k_means origin feature average accuracy : 82.25492108%, total [0.9746727376209448, 0.9733106189664963, 0.9700891573195284, 0.9530800230282096, 0.943108504398827, 0.9150568181818182, 0.801817648783348, 0.6625070901871809, 0.9488619568430388, 0.822215777262181, 0.5866935483870968, 0.5005858230814294, 0.9429250891795482, 0.8922588099364529, 0.673546511627907, 0.6000572573718866]\n",
      "save model\n",
      "kmeans average accuracy best : 89.68%, kmeans average accuracy : 89.68160812%, total [0.9735344336937962, 0.975298126064736, 0.9712395743457003, 0.9571099597006333, 0.9604105571847508, 0.9491477272727272, 0.9117560832600411, 0.8272830402722632, 0.9663020987289388, 0.9028422273781903, 0.8004032258064516, 0.7252489748096075, 0.953923900118906, 0.9041016753321779, 0.8226744186046512, 0.7477812768393931]\n",
      "cluster_accuracy_post_training_cycle_all_dataset : [0.97634816 0.97549482 0.97207511 0.96046287 0.96218905 0.93537736\n",
      " 0.91297862 0.79350894 0.96217852 0.91162109 0.79198842 0.72591857\n",
      " 0.95621181 0.90349176 0.8245098  0.75203058]\n",
      "mean_cluster_accuracy_during_training_cycle : 89.33%, post_traincycle_acc : 89.48%, total_acc : 89.41523457%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 89.48%\n",
      "accuracy_check 실행 시간: 22.109초\n",
      "\n",
      "\n",
      "epoch-41 loss : 0.01176855, loss_normal : 0.01465992, loss_coarse : 0.06796080, min_loss : 0.01174508, min_loss_normal : 0.01465311, min_loss_coarse : 0.06789759, wrong_element_sum : 13048474.00000000, same_data : 0.00%\n",
      "ae train 실행 시간: 116.581초, 전체 시작 시간 20250314_000023_260\n",
      "\n",
      "epoch-41 accuracy check\n",
      "k_means origin feature average accuracy : 82.25138088%, total [0.9746727376209448, 0.9733106189664963, 0.9700891573195284, 0.9530800230282096, 0.943108504398827, 0.9150568181818182, 0.801817648783348, 0.6622234826999432, 0.9488619568430388, 0.822215777262181, 0.5872695852534562, 0.5005858230814294, 0.9429250891795482, 0.8922588099364529, 0.673546511627907, 0.5991983967935872]\n",
      "kmeans average accuracy best : 89.68%, kmeans average accuracy : 89.00165945%, total [0.9738190096755834, 0.9750141964792731, 0.9718147828587863, 0.9573978123200921, 0.9583577712609971, 0.9397727272727273, 0.9076517150395779, 0.8114010209869541, 0.9600945906000591, 0.8961716937354989, 0.7796658986175116, 0.7091388400702988, 0.9438168846611177, 0.8948584633160023, 0.8223837209302326, 0.7389063841969653]\n",
      "cluster_accuracy_post_training_cycle_all_dataset : [0.97587512 0.97502356 0.97255657 0.95949855 0.95970149 0.93066038\n",
      " 0.90004973 0.81984948 0.95864851 0.89746094 0.79102317 0.69960278\n",
      " 0.94653768 0.89961203 0.82745098 0.74343048]\n",
      "mean_cluster_accuracy_during_training_cycle : 88.59%, post_traincycle_acc : 89.11%, total_acc : 88.89823348%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 89.48%\n",
      "accuracy_check 실행 시간: 23.391초\n",
      "\n",
      "\n",
      "epoch-42 loss : 0.01172854, loss_normal : 0.01463623, loss_coarse : 0.06786776, min_loss : 0.01172854, min_loss_normal : 0.01463623, min_loss_coarse : 0.06786776, wrong_element_sum : 13030610.00000000, same_data : 0.00%\n",
      "ae train 실행 시간: 113.334초, 전체 시작 시간 20250314_000023_260\n",
      "\n",
      "epoch-42 accuracy check\n",
      "k_means origin feature average accuracy : 82.24421419%, total [0.9746727376209448, 0.9733106189664963, 0.9700891573195284, 0.9530800230282096, 0.943108504398827, 0.9150568181818182, 0.8015244796247435, 0.6622234826999432, 0.9488619568430388, 0.822215777262181, 0.5866935483870968, 0.5005858230814294, 0.9429250891795482, 0.8922588099364529, 0.6741279069767442, 0.5983395362152877]\n",
      "kmeans average accuracy best : 89.68%, kmeans average accuracy : 89.38664304%, total [0.9743881616391576, 0.9761499148211243, 0.9715271786022434, 0.9573978123200921, 0.9598240469208211, 0.9426136363636364, 0.910583406625623, 0.8267158252977879, 0.9624593556015371, 0.9071925754060325, 0.7946428571428571, 0.7281780902167545, 0.9432223543400713, 0.9020797227036396, 0.8168604651162791, 0.7280274835385055]\n",
      "cluster_accuracy_post_training_cycle_all_dataset : [0.97682119 0.97643732 0.97207511 0.95949855 0.960199   0.93160377\n",
      " 0.9090005  0.82220132 0.95562279 0.91455078 0.78764479 0.70953327\n",
      " 0.94195519 0.90446169 0.81715686 0.72479694]\n",
      "mean_cluster_accuracy_during_training_cycle : 89.09%, post_traincycle_acc : 89.15%, total_acc : 89.12315286%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 89.48%\n",
      "accuracy_check 실행 시간: 23.001초\n",
      "\n",
      "\n",
      "epoch-43 loss : 0.01172935, loss_normal : 0.01464408, loss_coarse : 0.06787475, min_loss : 0.01172854, min_loss_normal : 0.01463623, min_loss_coarse : 0.06786776, wrong_element_sum : 13031952.00000000, same_data : 0.00%\n",
      "ae train 실행 시간: 118.804초, 전체 시작 시간 20250314_000023_260\n",
      "\n",
      "epoch-43 accuracy check\n",
      "k_means origin feature average accuracy : 82.25666896%, total [0.9746727376209448, 0.9733106189664963, 0.9700891573195284, 0.9530800230282096, 0.943108504398827, 0.9150568181818182, 0.801817648783348, 0.6625070901871809, 0.9488619568430388, 0.822215777262181, 0.5866935483870968, 0.5002929115407148, 0.9429250891795482, 0.8922588099364529, 0.673546511627907, 0.600629831090753]\n",
      "kmeans average accuracy best : 89.68%, kmeans average accuracy : 88.83509230%, total [0.9738190096755834, 0.975298126064736, 0.9715271786022434, 0.9573978123200921, 0.9583577712609971, 0.9383522727272727, 0.9035473468191146, 0.8204764605785593, 0.9538870824711795, 0.8845707656612529, 0.7698732718894009, 0.7103104862331576, 0.9473840665873959, 0.8951473136915078, 0.8104651162790698, 0.7432006870884627]\n",
      "cluster_accuracy_post_training_cycle_all_dataset : [0.97587512 0.97549482 0.97255657 0.95853423 0.95920398 0.92783019\n",
      " 0.90154152 0.80056444 0.94402421 0.88769531 0.77750965 0.69364449\n",
      " 0.95112016 0.90543162 0.82058824 0.74820831]\n",
      "mean_cluster_accuracy_during_training_cycle : 88.42%, post_traincycle_acc : 88.75%, total_acc : 88.61102013%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 89.48%\n",
      "accuracy_check 실행 시간: 23.188초\n",
      "\n",
      "\n",
      "epoch-44 loss : 0.01175916, loss_normal : 0.01463962, loss_coarse : 0.06793526, min_loss : 0.01172854, min_loss_normal : 0.01463623, min_loss_coarse : 0.06786776, wrong_element_sum : 13043570.00000000, same_data : 0.00%\n",
      "ae train 실행 시간: 119.943초, 전체 시작 시간 20250314_000023_260\n",
      "\n",
      "epoch-44 accuracy check\n",
      "k_means origin feature average accuracy : 82.26938118%, total [0.9746727376209448, 0.9733106189664963, 0.9700891573195284, 0.9530800230282096, 0.943108504398827, 0.915340909090909, 0.801817648783348, 0.6625070901871809, 0.9488619568430388, 0.822215777262181, 0.5872695852534562, 0.5005858230814294, 0.9429250891795482, 0.8922588099364529, 0.675, 0.6000572573718866]\n",
      "kmeans average accuracy best : 89.68%, kmeans average accuracy : 88.97581394%, total [0.9735344336937962, 0.9750141964792731, 0.9712395743457003, 0.9559585492227979, 0.9580645161290322, 0.9363636363636364, 0.8962181178540017, 0.7972206466250709, 0.9630505468519066, 0.9028422273781903, 0.7983870967741935, 0.7211482132396017, 0.9414387633769322, 0.8925476603119584, 0.811046511627907, 0.74205553965073]\n",
      "cluster_accuracy_post_training_cycle_all_dataset : [0.97587512 0.97455231 0.97255657 0.95708775 0.96069652 0.93018868\n",
      " 0.8975634  0.76763876 0.9591528  0.90722656 0.76833977 0.69563059\n",
      " 0.9389002  0.90252182 0.81078431 0.74629718]\n",
      "mean_cluster_accuracy_during_training_cycle : 88.33%, post_traincycle_acc : 88.53%, total_acc : 88.44523320%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 89.48%\n",
      "accuracy_check 실행 시간: 22.994초\n",
      "\n",
      "\n",
      "epoch-45 loss : 0.01171191, loss_normal : 0.01463095, loss_coarse : 0.06784091, min_loss : 0.01171191, min_loss_normal : 0.01463095, min_loss_coarse : 0.06784091, wrong_element_sum : 13025456.00000000, same_data : 0.00%\n",
      "ae train 실행 시간: 119.151초, 전체 시작 시간 20250314_000023_260\n",
      "\n",
      "epoch-45 accuracy check\n",
      "k_means origin feature average accuracy : 82.25326370%, total [0.9746727376209448, 0.9733106189664963, 0.9700891573195284, 0.9530800230282096, 0.943108504398827, 0.9150568181818182, 0.801817648783348, 0.6625070901871809, 0.9488619568430388, 0.822215777262181, 0.5872695852534562, 0.5005858230814294, 0.9429250891795482, 0.8922588099364529, 0.6747093023255814, 0.5980532493558546]\n",
      "kmeans average accuracy best : 89.68%, kmeans average accuracy : 89.09963698%, total [0.9752418895845191, 0.9747302668938104, 0.9715271786022434, 0.9568221070811744, 0.9589442815249267, 0.9454545454545454, 0.9132219290530637, 0.8125354509359047, 0.9544782737215489, 0.8857308584686775, 0.782258064516129, 0.7164616285881664, 0.9512485136741974, 0.9000577700751011, 0.8188953488372093, 0.7383338104780991]\n",
      "cluster_accuracy_post_training_cycle_all_dataset : [0.97729423 0.97502356 0.97303804 0.95756991 0.96069652 0.93962264\n",
      " 0.90949776 0.80338664 0.94251135 0.89306641 0.76882239 0.70357498\n",
      " 0.950611   0.90591659 0.82401961 0.74247492]\n",
      "mean_cluster_accuracy_during_training_cycle : 88.70%, post_traincycle_acc : 88.92%, total_acc : 88.82703898%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 89.48%\n",
      "accuracy_check 실행 시간: 23.673초\n",
      "\n",
      "\n",
      "epoch-46 loss : 0.01173824, loss_normal : 0.01463247, loss_coarse : 0.06788485, min_loss : 0.01171191, min_loss_normal : 0.01463095, min_loss_coarse : 0.06784091, wrong_element_sum : 13033892.00000000, same_data : 0.00%\n",
      "ae train 실행 시간: 118.746초, 전체 시작 시간 20250314_000023_260\n",
      "\n",
      "epoch-46 accuracy check\n",
      "k_means origin feature average accuracy : 82.26041597%, total [0.9746727376209448, 0.9733106189664963, 0.9700891573195284, 0.9530800230282096, 0.943108504398827, 0.9150568181818182, 0.801817648783348, 0.6622234826999432, 0.9488619568430388, 0.822215777262181, 0.5866935483870968, 0.5005858230814294, 0.9429250891795482, 0.8922588099364529, 0.6747093023255814, 0.6000572573718866]\n",
      "kmeans average accuracy best : 89.68%, kmeans average accuracy : 89.07495842%, total [0.9738190096755834, 0.975298126064736, 0.9712395743457003, 0.9579735175590098, 0.9592375366568915, 0.9446022727272727, 0.9067722075637643, 0.8281338627339762, 0.9606857818504286, 0.8941415313225058, 0.7865783410138248, 0.7208553016988869, 0.9414387633769322, 0.8882149046793761, 0.8058139534883721, 0.7371886630403665]\n",
      "cluster_accuracy_post_training_cycle_all_dataset : [0.97587512 0.97502356 0.97255657 0.95756991 0.96218905 0.93584906\n",
      " 0.90701144 0.81232361 0.95713565 0.89355469 0.78137066 0.70506455\n",
      " 0.94246436 0.88797284 0.81323529 0.73244147]\n",
      "mean_cluster_accuracy_during_training_cycle : 88.84%, post_traincycle_acc : 88.82%, total_acc : 88.82733826%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 89.48%\n",
      "accuracy_check 실행 시간: 22.530초\n",
      "\n",
      "\n",
      "epoch-47 loss : 0.01172527, loss_normal : 0.01463409, loss_coarse : 0.06784887, min_loss : 0.01171191, min_loss_normal : 0.01463095, min_loss_coarse : 0.06784091, wrong_element_sum : 13026984.00000000, same_data : 0.00%\n",
      "ae train 실행 시간: 118.047초, 전체 시작 시간 20250314_000023_260\n",
      "\n",
      "epoch-47 accuracy check\n",
      "k_means origin feature average accuracy : 82.24789092%, total [0.9746727376209448, 0.9733106189664963, 0.9700891573195284, 0.9530800230282096, 0.943108504398827, 0.9150568181818182, 0.801817648783348, 0.6622234826999432, 0.9488619568430388, 0.822215777262181, 0.5866935483870968, 0.5005858230814294, 0.9429250891795482, 0.8922588099364529, 0.6747093023255814, 0.5980532493558546]\n",
      "kmeans average accuracy best : 89.68%, kmeans average accuracy : 89.14453562%, total [0.9738190096755834, 0.9758659852356616, 0.9718147828587863, 0.9573978123200921, 0.9586510263929618, 0.9460227272727273, 0.9102902374670184, 0.8196256381168463, 0.9642329293526456, 0.906322505800464, 0.7894585253456221, 0.7220269478617457, 0.9476813317479191, 0.879838243789717, 0.8017441860465117, 0.7383338104780991]\n",
      "cluster_accuracy_post_training_cycle_all_dataset : [0.97587512 0.97690858 0.9735195  0.95949855 0.960199   0.93679245\n",
      " 0.90999503 0.80997178 0.95713565 0.90673828 0.7784749  0.71598808\n",
      " 0.94857434 0.89379243 0.80882353 0.74390827]\n",
      "mean_cluster_accuracy_during_training_cycle : 88.73%, post_traincycle_acc : 89.10%, total_acc : 88.94783974%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 89.48%\n",
      "accuracy_check 실행 시간: 24.129초\n",
      "\n",
      "\n",
      "epoch-48 loss : 0.01169373, loss_normal : 0.01462160, loss_coarse : 0.06778231, min_loss : 0.01169373, min_loss_normal : 0.01462160, min_loss_coarse : 0.06778231, wrong_element_sum : 13014204.00000000, same_data : 0.00%\n",
      "ae train 실행 시간: 117.652초, 전체 시작 시간 20250314_000023_260\n",
      "\n",
      "epoch-48 accuracy check\n",
      "k_means origin feature average accuracy : 82.24398570%, total [0.9746727376209448, 0.9733106189664963, 0.9700891573195284, 0.9530800230282096, 0.943108504398827, 0.915340909090909, 0.8006449721489299, 0.6625070901871809, 0.9488619568430388, 0.822215777262181, 0.5866935483870968, 0.5002929115407148, 0.9429250891795482, 0.8922588099364529, 0.6738372093023256, 0.5991983967935872]\n",
      "kmeans average accuracy best : 89.68%, kmeans average accuracy : 89.21524136%, total [0.9738190096755834, 0.9755820556501987, 0.9715271786022434, 0.9579735175590098, 0.9595307917888563, 0.9414772727272728, 0.9082380533567869, 0.8167895632444696, 0.9633461424770914, 0.8895011600928074, 0.7839861751152074, 0.7111892208553017, 0.9524375743162902, 0.8989023685730791, 0.8206395348837209, 0.749498997995992]\n",
      "cluster_accuracy_post_training_cycle_all_dataset : [0.97634816 0.97502356 0.97303804 0.95998071 0.95970149 0.93066038\n",
      " 0.91198409 0.80197554 0.96016137 0.90185547 0.77557915 0.70705065\n",
      " 0.95570265 0.90494665 0.81764706 0.75537506]\n",
      "mean_cluster_accuracy_during_training_cycle : 88.78%, post_traincycle_acc : 89.17%, total_acc : 89.00714443%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 89.48%\n",
      "accuracy_check 실행 시간: 22.704초\n",
      "\n",
      "\n",
      "epoch-49 loss : 0.01170738, loss_normal : 0.01463966, loss_coarse : 0.06781919, min_loss : 0.01169373, min_loss_normal : 0.01462160, min_loss_coarse : 0.06778231, wrong_element_sum : 13021284.00000000, same_data : 0.00%\n",
      "ae train 실행 시간: 120.956초, 전체 시작 시간 20250314_000023_260\n",
      "\n",
      "epoch-49 accuracy check\n",
      "k_means origin feature average accuracy : 82.25318431%, total [0.9746727376209448, 0.9733106189664963, 0.9700891573195284, 0.9530800230282096, 0.943108504398827, 0.9150568181818182, 0.801817648783348, 0.6622234826999432, 0.9488619568430388, 0.822215777262181, 0.5872695852534562, 0.5005858230814294, 0.9429250891795482, 0.89052570768342, 0.6747093023255814, 0.6000572573718866]\n",
      "kmeans average accuracy best : 89.68%, kmeans average accuracy : 89.28313349%, total [0.9743881616391576, 0.9744463373083475, 0.9709519700891573, 0.9559585492227979, 0.9592375366568915, 0.9454545454545454, 0.9055995309293462, 0.8071469086783891, 0.9609813774756134, 0.9040023201856149, 0.7952188940092166, 0.7123608670181605, 0.9527348394768134, 0.9046793760831889, 0.8218023255813953, 0.7403378184941312]\n",
      "cluster_accuracy_post_training_cycle_all_dataset : [0.97587512 0.97455231 0.97159364 0.95901639 0.96069652 0.93443396\n",
      " 0.90253605 0.79350894 0.9515885  0.91064453 0.79247104 0.71251241\n",
      " 0.95315682 0.90446169 0.82205882 0.73626374]\n",
      "mean_cluster_accuracy_during_training_cycle : 89.17%, post_traincycle_acc : 89.10%, total_acc : 89.12602007%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 89.48%\n",
      "accuracy_check 실행 시간: 23.640초\n",
      "\n",
      "\n",
      "epoch-50 loss : 0.01169120, loss_normal : 0.01461564, loss_coarse : 0.06776227, min_loss : 0.01169120, min_loss_normal : 0.01461564, min_loss_coarse : 0.06776227, wrong_element_sum : 13010356.00000000, same_data : 0.00%\n",
      "ae train 실행 시간: 120.612초, 전체 시작 시간 20250314_000023_260\n",
      "\n",
      "epoch-50 accuracy check\n",
      "k_means origin feature average accuracy : 82.25855610%, total [0.9746727376209448, 0.9733106189664963, 0.9700891573195284, 0.9530800230282096, 0.943108504398827, 0.9150568181818182, 0.8015244796247435, 0.6625070901871809, 0.9488619568430388, 0.822215777262181, 0.586405529953917, 0.5005858230814294, 0.9429250891795482, 0.8922588099364529, 0.6747093023255814, 0.6000572573718866]\n",
      "kmeans average accuracy best : 89.68%, kmeans average accuracy : 89.59166125%, total [0.9735344336937962, 0.9758659852356616, 0.9703767615760713, 0.9568221070811744, 0.9586510263929618, 0.9457386363636363, 0.9135150982116681, 0.8323879750425411, 0.9618681643511676, 0.9037122969837587, 0.7952188940092166, 0.7179261862917399, 0.9470868014268727, 0.9061236279607163, 0.8188953488372093, 0.7569424563412539]\n",
      "cluster_accuracy_post_training_cycle_all_dataset : [0.97540208 0.97596607 0.97207511 0.95949855 0.95970149 0.93773585\n",
      " 0.917454   0.80809031 0.9515885  0.90478516 0.79777992 0.70158888\n",
      " 0.94704684 0.90155189 0.82696078 0.75489728]\n",
      "mean_cluster_accuracy_during_training_cycle : 89.21%, post_traincycle_acc : 89.33%, total_acc : 89.27884364%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 89.48%\n",
      "accuracy_check 실행 시간: 23.770초\n",
      "\n",
      "\n",
      "epoch-51 loss : 0.01174657, loss_normal : 0.01463611, loss_coarse : 0.06789310, min_loss : 0.01169120, min_loss_normal : 0.01461564, min_loss_coarse : 0.06776227, wrong_element_sum : 13035476.00000000, same_data : 0.00%\n",
      "ae train 실행 시간: 116.952초, 전체 시작 시간 20250314_000023_260\n",
      "\n",
      "epoch-51 accuracy check\n",
      "k_means origin feature average accuracy : 82.26753726%, total [0.9746727376209448, 0.9733106189664963, 0.9700891573195284, 0.9530800230282096, 0.943108504398827, 0.9150568181818182, 0.801817648783348, 0.6625070901871809, 0.9488619568430388, 0.8216357308584686, 0.5866935483870968, 0.5005858230814294, 0.9429250891795482, 0.8922588099364529, 0.675, 0.6012024048096193]\n",
      "kmeans average accuracy best : 89.68%, kmeans average accuracy : 88.65907016%, total [0.9738190096755834, 0.9758659852356616, 0.9709519700891573, 0.957685664939551, 0.956891495601173, 0.9397727272727273, 0.9050131926121372, 0.8082813386273398, 0.9586166124741354, 0.8854408352668214, 0.7741935483870968, 0.7062097246631517, 0.9322235434007135, 0.8908145580589255, 0.8113372093023256, 0.7383338104780991]\n",
      "cluster_accuracy_post_training_cycle_all_dataset : [0.97634816 0.97737983 0.97159364 0.95998071 0.95920398 0.93396226\n",
      " 0.90651417 0.79162747 0.95713565 0.90429688 0.746139   0.71549156\n",
      " 0.93431772 0.90155189 0.81078431 0.7372193 ]\n",
      "mean_cluster_accuracy_during_training_cycle : 88.27%, post_traincycle_acc : 88.65%, total_acc : 88.49305695%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 89.48%\n",
      "accuracy_check 실행 시간: 24.176초\n",
      "\n",
      "\n",
      "epoch-52 loss : 0.01170283, loss_normal : 0.01462877, loss_coarse : 0.06783091, min_loss : 0.01169120, min_loss_normal : 0.01461564, min_loss_coarse : 0.06776227, wrong_element_sum : 13023536.00000000, same_data : 0.00%\n",
      "ae train 실행 시간: 113.298초, 전체 시작 시간 20250314_000023_260\n",
      "\n",
      "epoch-52 accuracy check\n",
      "k_means origin feature average accuracy : 82.24597591%, total [0.9746727376209448, 0.9733106189664963, 0.9700891573195284, 0.9530800230282096, 0.943108504398827, 0.9150568181818182, 0.8015244796247435, 0.6622234826999432, 0.9488619568430388, 0.822215777262181, 0.5866935483870968, 0.5005858230814294, 0.9429250891795482, 0.8922588099364529, 0.6738372093023256, 0.598912109934154]\n",
      "kmeans average accuracy best : 89.68%, kmeans average accuracy : 89.06627648%, total [0.9738190096755834, 0.9755820556501987, 0.9721023871153293, 0.9579735175590098, 0.9583577712609971, 0.9403409090909091, 0.9061858692465553, 0.819909245604084, 0.9535914868459947, 0.8758700696055685, 0.7756336405529954, 0.7085530169888694, 0.9500594530321046, 0.9090121317157712, 0.8232558139534883, 0.7503578585742915]\n",
      "cluster_accuracy_post_training_cycle_all_dataset : [0.97634816 0.97643732 0.97207511 0.95949855 0.960199   0.92877358\n",
      " 0.88811537 0.80761994 0.94503278 0.90234375 0.7784749  0.66434955\n",
      " 0.95162933 0.91561591 0.825      0.75107501]\n",
      "mean_cluster_accuracy_during_training_cycle : 88.42%, post_traincycle_acc : 88.77%, total_acc : 88.62417698%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 89.48%\n",
      "accuracy_check 실행 시간: 23.502초\n",
      "\n",
      "\n",
      "epoch-53 loss : 0.01169400, loss_normal : 0.01461094, loss_coarse : 0.06779337, min_loss : 0.01169120, min_loss_normal : 0.01461094, min_loss_coarse : 0.06776227, wrong_element_sum : 13016328.00000000, same_data : 0.00%\n",
      "ae train 실행 시간: 115.008초, 전체 시작 시간 20250314_000023_260\n",
      "\n",
      "epoch-53 accuracy check\n",
      "k_means origin feature average accuracy : 82.26203825%, total [0.9746727376209448, 0.9733106189664963, 0.9700891573195284, 0.9530800230282096, 0.943108504398827, 0.915340909090909, 0.8015244796247435, 0.6622234826999432, 0.9488619568430388, 0.822215777262181, 0.5866935483870968, 0.5005858230814294, 0.9429250891795482, 0.8922588099364529, 0.673546511627907, 0.6014886916690524]\n",
      "kmeans average accuracy best : 89.68%, kmeans average accuracy : 89.44481216%, total [0.9741035856573705, 0.9750141964792731, 0.9718147828587863, 0.9582613701784686, 0.9592375366568915, 0.9491477272727272, 0.9164467897977133, 0.8366420873511061, 0.9609813774756134, 0.8938515081206496, 0.7805299539170507, 0.7211482132396017, 0.9432223543400713, 0.9015020219526285, 0.8197674418604651, 0.749498997995992]\n",
      "cluster_accuracy_post_training_cycle_all_dataset : [0.97587512 0.97596607 0.97255657 0.96094503 0.96069652 0.94198113\n",
      " 0.91596221 0.80714958 0.95410993 0.90332031 0.76303089 0.71747766\n",
      " 0.94348269 0.90009699 0.81617647 0.75107501]\n",
      "mean_cluster_accuracy_during_training_cycle : 88.96%, post_traincycle_acc : 89.12%, total_acc : 89.05679826%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 89.48%\n",
      "accuracy_check 실행 시간: 24.090초\n",
      "\n",
      "\n",
      "epoch-54 loss : 0.01167941, loss_normal : 0.01459971, loss_coarse : 0.06770576, min_loss : 0.01167941, min_loss_normal : 0.01459971, min_loss_coarse : 0.06770576, wrong_element_sum : 12999506.00000000, same_data : 0.00%\n",
      "ae train 실행 시간: 118.860초, 전체 시작 시간 20250314_000023_260\n",
      "\n",
      "epoch-54 accuracy check\n",
      "k_means origin feature average accuracy : 82.26042087%, total [0.9746727376209448, 0.9733106189664963, 0.9700891573195284, 0.9530800230282096, 0.943108504398827, 0.9150568181818182, 0.801817648783348, 0.6625070901871809, 0.9488619568430388, 0.822215777262181, 0.5872695852534562, 0.5005858230814294, 0.9429250891795482, 0.8922588099364529, 0.6747093023255814, 0.5991983967935872]\n",
      "kmeans average accuracy best : 89.68%, kmeans average accuracy : 89.09973320%, total [0.9741035856573705, 0.9758659852356616, 0.9715271786022434, 0.9568221070811744, 0.9574780058651027, 0.9380681818181819, 0.9012019935502785, 0.8071469086783891, 0.9556606562222879, 0.884860788863109, 0.7831221198156681, 0.7097246631517282, 0.9551129607609988, 0.9127671865973426, 0.825, 0.7474949899799599]\n",
      "cluster_accuracy_post_training_cycle_all_dataset : [0.97634816 0.97596607 0.97207511 0.95901639 0.95870647 0.92924528\n",
      " 0.90154152 0.80997178 0.94957136 0.89355469 0.77702703 0.71598808\n",
      " 0.95570265 0.91804074 0.83431373 0.75203058]\n",
      "mean_cluster_accuracy_during_training_cycle : 88.25%, post_traincycle_acc : 89.24%, total_acc : 88.83585942%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 89.48%\n",
      "accuracy_check 실행 시간: 22.856초\n",
      "\n",
      "\n",
      "epoch-55 loss : 0.01169799, loss_normal : 0.01461608, loss_coarse : 0.06777060, min_loss : 0.01167941, min_loss_normal : 0.01459971, min_loss_coarse : 0.06770576, wrong_element_sum : 13011956.00000000, same_data : 0.00%\n",
      "ae train 실행 시간: 90.011초, 전체 시작 시간 20250314_000023_260\n",
      "\n",
      "epoch-55 accuracy check\n",
      "k_means origin feature average accuracy : 82.25859911%, total [0.9746727376209448, 0.9733106189664963, 0.9700891573195284, 0.9530800230282096, 0.943108504398827, 0.9150568181818182, 0.801817648783348, 0.6622234826999432, 0.9488619568430388, 0.822215777262181, 0.5866935483870968, 0.5005858230814294, 0.9429250891795482, 0.8922588099364529, 0.6744186046511628, 0.6000572573718866]\n",
      "kmeans average accuracy best : 89.68%, kmeans average accuracy : 89.09297757%, total [0.9738190096755834, 0.9750141964792731, 0.9715271786022434, 0.957685664939551, 0.9595307917888563, 0.9414772727272728, 0.9076517150395779, 0.8187748156551333, 0.9583210168489507, 0.8970417633410673, 0.7816820276497696, 0.7164616285881664, 0.9444114149821641, 0.8951473136915078, 0.8162790697674419, 0.740051531634698]\n",
      "cluster_accuracy_post_training_cycle_all_dataset : [0.97587512 0.97596607 0.97303804 0.95949855 0.96069652 0.93301887\n",
      " 0.90850323 0.81138288 0.94856278 0.90380859 0.75965251 0.7040715\n",
      " 0.94450102 0.89524733 0.81813725 0.73626374]\n",
      "mean_cluster_accuracy_during_training_cycle : 88.55%, post_traincycle_acc : 88.80%, total_acc : 88.69847191%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 89.48%\n",
      "accuracy_check 실행 시간: 24.296초\n",
      "\n",
      "\n",
      "epoch-56 loss : 0.01168106, loss_normal : 0.01460137, loss_coarse : 0.06774514, min_loss : 0.01167941, min_loss_normal : 0.01459971, min_loss_coarse : 0.06770576, wrong_element_sum : 13007068.00000000, same_data : 0.00%\n",
      "ae train 실행 시간: 117.581초, 전체 시작 시간 20250314_000023_260\n",
      "\n",
      "epoch-56 accuracy check\n",
      "k_means origin feature average accuracy : 82.25314853%, total [0.9746727376209448, 0.9733106189664963, 0.9700891573195284, 0.9530800230282096, 0.943108504398827, 0.9150568181818182, 0.801817648783348, 0.6622234826999432, 0.9488619568430388, 0.822215777262181, 0.5866935483870968, 0.5005858230814294, 0.9429250891795482, 0.8922588099364529, 0.673546511627907, 0.6000572573718866]\n",
      "kmeans average accuracy best : 89.68%, kmeans average accuracy : 89.03603723%, total [0.9732498577120091, 0.9750141964792731, 0.9718147828587863, 0.9571099597006333, 0.9589442815249267, 0.94375, 0.9123424215772501, 0.8213272830402722, 0.9595033993496896, 0.8889211136890951, 0.7785138248847926, 0.7167545401288811, 0.9503567181926278, 0.8937030618139804, 0.8075581395348838, 0.7369023761809333]\n",
      "cluster_accuracy_post_training_cycle_all_dataset : [0.97587512 0.97455231 0.97255657 0.95853423 0.96119403 0.93018868\n",
      " 0.90502238 0.80856068 0.94150277 0.90478516 0.75337838 0.7040715\n",
      " 0.9490835  0.90737148 0.80833333 0.7372193 ]\n",
      "mean_cluster_accuracy_during_training_cycle : 88.51%, post_traincycle_acc : 88.70%, total_acc : 88.62301047%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 89.48%\n",
      "accuracy_check 실행 시간: 24.215초\n",
      "\n",
      "\n",
      "epoch-57 loss : 0.01166939, loss_normal : 0.01460716, loss_coarse : 0.06774052, min_loss : 0.01166939, min_loss_normal : 0.01459971, min_loss_coarse : 0.06770576, wrong_element_sum : 13006180.00000000, same_data : 0.00%\n",
      "ae train 실행 시간: 118.912초, 전체 시작 시간 20250314_000023_260\n",
      "\n",
      "epoch-57 accuracy check\n",
      "k_means origin feature average accuracy : 82.25856562%, total [0.9746727376209448, 0.9733106189664963, 0.9700891573195284, 0.9530800230282096, 0.943108504398827, 0.9150568181818182, 0.801817648783348, 0.6622234826999432, 0.9488619568430388, 0.822215777262181, 0.5872695852534562, 0.5005858230814294, 0.9429250891795482, 0.8922588099364529, 0.6738372093023256, 0.6000572573718866]\n",
      "kmeans average accuracy best : 89.68%, kmeans average accuracy : 89.40495124%, total [0.9735344336937962, 0.9755820556501987, 0.9721023871153293, 0.9579735175590098, 0.9598240469208211, 0.9525568181818181, 0.9199648197009674, 0.846001134429949, 0.9603901862252439, 0.8921113689095128, 0.7825460829493087, 0.7196836555360281, 0.9438168846611177, 0.8913922588099364, 0.8055232558139535, 0.7517892928714572]\n",
      "cluster_accuracy_post_training_cycle_all_dataset : [0.97587512 0.97596607 0.9735195  0.95998071 0.96119403 0.94764151\n",
      " 0.92043759 0.82831609 0.95562279 0.88964844 0.77557915 0.69761668\n",
      " 0.94450102 0.89379243 0.81421569 0.74916388]\n",
      "mean_cluster_accuracy_during_training_cycle : 89.13%, post_traincycle_acc : 89.14%, total_acc : 89.13915081%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 89.48%\n",
      "accuracy_check 실행 시간: 23.896초\n",
      "\n",
      "\n",
      "epoch-58 loss : 0.01168610, loss_normal : 0.01459950, loss_coarse : 0.06771401, min_loss : 0.01166939, min_loss_normal : 0.01459950, min_loss_coarse : 0.06770576, wrong_element_sum : 13001090.00000000, same_data : 0.00%\n",
      "ae train 실행 시간: 114.470초, 전체 시작 시간 20250314_000023_260\n",
      "\n",
      "epoch-58 accuracy check\n",
      "k_means origin feature average accuracy : 82.24604057%, total [0.9746727376209448, 0.9733106189664963, 0.9700891573195284, 0.9530800230282096, 0.943108504398827, 0.9150568181818182, 0.801817648783348, 0.6622234826999432, 0.9488619568430388, 0.822215777262181, 0.5872695852534562, 0.5005858230814294, 0.9429250891795482, 0.8922588099364529, 0.6738372093023256, 0.5980532493558546]\n",
      "kmeans average accuracy best : 89.68%, kmeans average accuracy : 89.22841873%, total [0.9735344336937962, 0.975298126064736, 0.9723899913718723, 0.9579735175590098, 0.9595307917888563, 0.946590909090909, 0.9155672823218998, 0.816505955757232, 0.9589122080993201, 0.8982018561484919, 0.788594470046083, 0.7190978324545987, 0.9500594530321046, 0.8971692663200462, 0.8130813953488372, 0.7340395075866017]\n",
      "cluster_accuracy_post_training_cycle_all_dataset : [0.97587512 0.97502356 0.9735195  0.96142719 0.96119403 0.93867925\n",
      " 0.90800597 0.81232361 0.95057993 0.90185547 0.79150579 0.59682224\n",
      " 0.95010183 0.90009699 0.81960784 0.73865265]\n",
      "mean_cluster_accuracy_during_training_cycle : 88.46%, post_traincycle_acc : 88.47%, total_acc : 88.46477810%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 89.48%\n",
      "accuracy_check 실행 시간: 22.496초\n",
      "\n",
      "\n",
      "epoch-59 loss : 0.01166698, loss_normal : 0.01459651, loss_coarse : 0.06768386, min_loss : 0.01166698, min_loss_normal : 0.01459651, min_loss_coarse : 0.06768386, wrong_element_sum : 12995302.00000000, same_data : 0.00%\n",
      "ae train 실행 시간: 112.537초, 전체 시작 시간 20250314_000023_260\n",
      "\n",
      "epoch-59 accuracy check\n",
      "k_means origin feature average accuracy : 82.25490563%, total [0.9746727376209448, 0.9733106189664963, 0.9700891573195284, 0.9530800230282096, 0.943108504398827, 0.9150568181818182, 0.8015244796247435, 0.6625070901871809, 0.9488619568430388, 0.822215777262181, 0.5866935483870968, 0.5005858230814294, 0.9429250891795482, 0.8922588099364529, 0.6738372093023256, 0.6000572573718866]\n",
      "kmeans average accuracy best : 89.68%, kmeans average accuracy : 89.35201925%, total [0.9735344336937962, 0.9755820556501987, 0.9721023871153293, 0.957685664939551, 0.9589442815249267, 0.9414772727272728, 0.9055995309293462, 0.814804310833806, 0.9600945906000591, 0.8993619489559165, 0.7851382488479263, 0.723784417106034, 0.952140309155767, 0.9067013287117274, 0.8267441860465117, 0.7426281133695963]\n",
      "cluster_accuracy_post_training_cycle_all_dataset : [0.97540208 0.97643732 0.9735195  0.95901639 0.95970149 0.92924528\n",
      " 0.90800597 0.7953904  0.95410993 0.89648438 0.78571429 0.71350546\n",
      " 0.95366599 0.90785645 0.82990196 0.73626374]\n",
      "mean_cluster_accuracy_during_training_cycle : 88.87%, post_traincycle_acc : 89.09%, total_acc : 88.99564729%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 89.48%\n",
      "accuracy_check 실행 시간: 23.464초\n",
      "\n",
      "\n",
      "epoch-60 loss : 0.01163507, loss_normal : 0.01456111, loss_coarse : 0.06753691, min_loss : 0.01163507, min_loss_normal : 0.01456111, min_loss_coarse : 0.06753691, wrong_element_sum : 12967088.00000000, same_data : 0.00%\n",
      "ae train 실행 시간: 121.355초, 전체 시작 시간 20250314_000023_260\n",
      "\n",
      "epoch-60 accuracy check\n",
      "k_means origin feature average accuracy : 82.25674586%, total [0.9746727376209448, 0.9733106189664963, 0.9700891573195284, 0.9530800230282096, 0.943108504398827, 0.915340909090909, 0.801817648783348, 0.6625070901871809, 0.9488619568430388, 0.822215777262181, 0.5872695852534562, 0.5005858230814294, 0.9429250891795482, 0.8922588099364529, 0.6738372093023256, 0.5991983967935872]\n",
      "kmeans average accuracy best : 89.68%, kmeans average accuracy : 89.27249510%, total [0.9735344336937962, 0.9738784781374219, 0.9703767615760713, 0.9568221070811744, 0.9604105571847508, 0.9454545454545454, 0.911169744942832, 0.8150879183210437, 0.9580254212237659, 0.896461716937355, 0.7897465437788018, 0.7129466900995899, 0.9494649227110583, 0.9026574234546505, 0.8206395348837209, 0.7469224162610936]\n",
      "cluster_accuracy_post_training_cycle_all_dataset : [0.97540208 0.9736098  0.97207511 0.95998071 0.96169154 0.93679245\n",
      " 0.91795127 0.79444967 0.95259708 0.89111328 0.79198842 0.71052632\n",
      " 0.94755601 0.8957323  0.82892157 0.75346393]\n",
      "mean_cluster_accuracy_during_training_cycle : 88.97%, post_traincycle_acc : 89.15%, total_acc : 89.07190404%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 89.48%\n",
      "accuracy_check 실행 시간: 22.802초\n",
      "\n",
      "\n",
      "epoch-61 loss : 0.01167560, loss_normal : 0.01458942, loss_coarse : 0.06770718, min_loss : 0.01163507, min_loss_normal : 0.01456111, min_loss_coarse : 0.06753691, wrong_element_sum : 12999778.00000000, same_data : 0.00%\n",
      "ae train 실행 시간: 118.389초, 전체 시작 시간 20250314_000023_260\n",
      "\n",
      "epoch-61 accuracy check\n",
      "k_means origin feature average accuracy : 82.25132112%, total [0.9746727376209448, 0.9733106189664963, 0.9700891573195284, 0.9530800230282096, 0.943108504398827, 0.9150568181818182, 0.8015244796247435, 0.6625070901871809, 0.9488619568430388, 0.822215777262181, 0.5872695852534562, 0.5005858230814294, 0.9429250891795482, 0.8922588099364529, 0.673546511627907, 0.5991983967935872]\n",
      "kmeans average accuracy best : 89.68%, kmeans average accuracy : 88.84594292%, total [0.9726807057484348, 0.9744463373083475, 0.9709519700891573, 0.9562464018422567, 0.9577712609970674, 0.9329545454545455, 0.8874230430958663, 0.7861599546228021, 0.9580254212237659, 0.8903712296983759, 0.7776497695852534, 0.7129466900995899, 0.9509512485136742, 0.9121894858463316, 0.8305232558139535, 0.7440595476667621]\n",
      "cluster_accuracy_post_training_cycle_all_dataset : [0.97445601 0.97502356 0.97207511 0.95901639 0.95920398 0.92688679\n",
      " 0.89507708 0.78222013 0.94704992 0.89111328 0.75675676 0.70556107\n",
      " 0.95366599 0.91222114 0.81911765 0.740086  ]\n",
      "mean_cluster_accuracy_during_training_cycle : 88.52%, post_traincycle_acc : 88.56%, total_acc : 88.54144099%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 89.48%\n",
      "accuracy_check 실행 시간: 25.084초\n",
      "\n",
      "\n",
      "epoch-62 loss : 0.01164585, loss_normal : 0.01457180, loss_coarse : 0.06759161, min_loss : 0.01163507, min_loss_normal : 0.01456111, min_loss_coarse : 0.06753691, wrong_element_sum : 12977590.00000000, same_data : 0.00%\n",
      "ae train 실행 시간: 122.181초, 전체 시작 시간 20250314_000023_260\n",
      "\n",
      "epoch-62 accuracy check\n",
      "k_means origin feature average accuracy : 82.26219934%, total [0.9746727376209448, 0.9733106189664963, 0.9700891573195284, 0.9530800230282096, 0.943108504398827, 0.9150568181818182, 0.801817648783348, 0.6622234826999432, 0.9488619568430388, 0.822215777262181, 0.5872695852534562, 0.5005858230814294, 0.9429250891795482, 0.8922588099364529, 0.6744186046511628, 0.6000572573718866]\n",
      "kmeans average accuracy best : 89.68%, kmeans average accuracy : 89.13662853%, total [0.9738190096755834, 0.975298126064736, 0.9715271786022434, 0.9565342544617156, 0.9598240469208211, 0.9451704545454546, 0.9070653767223688, 0.8043108338060124, 0.9618681643511676, 0.9011020881670534, 0.7926267281105991, 0.7226127709431751, 0.9441141498216409, 0.8948584633160023, 0.8130813953488372, 0.7380475236186659]\n",
      "cluster_accuracy_post_training_cycle_all_dataset : [0.97587512 0.97549482 0.97303804 0.95901639 0.96069652 0.93537736\n",
      " 0.91297862 0.7939793  0.95814423 0.8984375  0.77557915 0.72194638\n",
      " 0.94501018 0.90397672 0.8122549  0.7429527 ]\n",
      "mean_cluster_accuracy_during_training_cycle : 88.94%, post_traincycle_acc : 89.03%, total_acc : 88.99083670%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 89.48%\n",
      "accuracy_check 실행 시간: 23.835초\n",
      "\n",
      "\n",
      "epoch-63 loss : 0.01160954, loss_normal : 0.01457014, loss_coarse : 0.06750321, min_loss : 0.01160954, min_loss_normal : 0.01456111, min_loss_coarse : 0.06750321, wrong_element_sum : 12960616.00000000, same_data : 0.00%\n",
      "ae train 실행 시간: 120.715초, 전체 시작 시간 20250314_000023_260\n",
      "\n",
      "epoch-63 accuracy check\n",
      "k_means origin feature average accuracy : 82.26218852%, total [0.9746727376209448, 0.9733106189664963, 0.9700891573195284, 0.9530800230282096, 0.943108504398827, 0.9150568181818182, 0.801817648783348, 0.6625070901871809, 0.9488619568430388, 0.822215777262181, 0.5866935483870968, 0.5005858230814294, 0.9429250891795482, 0.8922588099364529, 0.6747093023255814, 0.6000572573718866]\n",
      "kmeans average accuracy best : 89.68%, kmeans average accuracy : 89.18002739%, total [0.9738190096755834, 0.975298126064736, 0.9712395743457003, 0.9573978123200921, 0.9595307917888563, 0.9491477272727272, 0.9097038991498094, 0.8099829835507657, 0.9580254212237659, 0.8961716937354989, 0.7920506912442397, 0.7103104862331576, 0.941141498216409, 0.9009243212016176, 0.8162790697674419, 0.7477812768393931]\n",
      "cluster_accuracy_post_training_cycle_all_dataset : [0.97587512 0.97549482 0.97255657 0.95756991 0.96069652 0.93726415\n",
      " 0.91347588 0.7953904  0.96016137 0.89404297 0.79295367 0.70258193\n",
      " 0.94144603 0.90543162 0.81715686 0.75489728]\n",
      "mean_cluster_accuracy_during_training_cycle : 88.74%, post_traincycle_acc : 89.11%, total_acc : 88.95519660%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 89.48%\n",
      "accuracy_check 실행 시간: 24.669초\n",
      "\n",
      "\n",
      "epoch-64 loss : 0.01169213, loss_normal : 0.01459953, loss_coarse : 0.06772094, min_loss : 0.01160954, min_loss_normal : 0.01456111, min_loss_coarse : 0.06750321, wrong_element_sum : 13002420.00000000, same_data : 0.00%\n",
      "ae train 실행 시간: 123.320초, 전체 시작 시간 20250314_000023_260\n",
      "\n",
      "epoch-64 accuracy check\n",
      "k_means origin feature average accuracy : 82.26578875%, total [0.9746727376209448, 0.9733106189664963, 0.9700891573195284, 0.9530800230282096, 0.943108504398827, 0.9150568181818182, 0.801817648783348, 0.6625070901871809, 0.9488619568430388, 0.822215777262181, 0.5872695852534562, 0.5005858230814294, 0.9429250891795482, 0.8922588099364529, 0.6747093023255814, 0.6000572573718866]\n",
      "kmeans average accuracy best : 89.68%, kmeans average accuracy : 89.15090850%, total [0.9732498577120091, 0.975298126064736, 0.9712395743457003, 0.9573978123200921, 0.9621700879765396, 0.9451704545454546, 0.9026678393433011, 0.8054452637549632, 0.9586166124741354, 0.892691415313225, 0.7894585253456221, 0.7223198594024605, 0.9497621878715814, 0.8991912189485847, 0.815406976744186, 0.7440595476667621]\n",
      "cluster_accuracy_post_training_cycle_all_dataset : [0.97492904 0.97596607 0.97207511 0.95998071 0.96268657 0.94056604\n",
      " 0.90502238 0.7953904  0.95360565 0.90136719 0.79440154 0.70456802\n",
      " 0.950611   0.90785645 0.81568627 0.74343048]\n",
      "mean_cluster_accuracy_during_training_cycle : 88.94%, post_traincycle_acc : 89.11%, total_acc : 89.04185703%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 89.48%\n",
      "accuracy_check 실행 시간: 23.081초\n",
      "\n",
      "\n",
      "epoch-65 loss : 0.01167524, loss_normal : 0.01459181, loss_coarse : 0.06766660, min_loss : 0.01160954, min_loss_normal : 0.01456111, min_loss_coarse : 0.06750321, wrong_element_sum : 12991988.00000000, same_data : 0.00%\n",
      "ae train 실행 시간: 123.421초, 전체 시작 시간 20250314_000023_260\n",
      "\n",
      "epoch-65 accuracy check\n",
      "k_means origin feature average accuracy : 82.25852723%, total [0.9746727376209448, 0.9733106189664963, 0.9700891573195284, 0.9530800230282096, 0.943108504398827, 0.9150568181818182, 0.801817648783348, 0.6625070901871809, 0.9488619568430388, 0.822215777262181, 0.5866935483870968, 0.5005858230814294, 0.9429250891795482, 0.8922588099364529, 0.6738372093023256, 0.6003435442313197]\n",
      "kmeans average accuracy best : 89.68%, kmeans average accuracy : 89.01653941%, total [0.9738190096755834, 0.9758659852356616, 0.9712395743457003, 0.9571099597006333, 0.9589442815249267, 0.9417613636363636, 0.9050131926121372, 0.8085649461145774, 0.9547738693467337, 0.8845707656612529, 0.7727534562211982, 0.7097246631517282, 0.952140309155767, 0.9107452339688041, 0.8247093023255814, 0.7409103922129974]\n",
      "cluster_accuracy_post_training_cycle_all_dataset : [0.97634816 0.97643732 0.9735195  0.95853423 0.96169154 0.93349057\n",
      " 0.90999503 0.78504233 0.95310136 0.87548828 0.77027027 0.69960278\n",
      " 0.95621181 0.91610087 0.82990196 0.74820831]\n",
      "mean_cluster_accuracy_during_training_cycle : 88.58%, post_traincycle_acc : 88.90%, total_acc : 88.76920632%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 89.48%\n",
      "accuracy_check 실행 시간: 25.251초\n",
      "\n",
      "\n",
      "epoch-66 loss : 0.01163893, loss_normal : 0.01458082, loss_coarse : 0.06762399, min_loss : 0.01160954, min_loss_normal : 0.01456111, min_loss_coarse : 0.06750321, wrong_element_sum : 12983806.00000000, same_data : 0.00%\n",
      "ae train 실행 시간: 122.410초, 전체 시작 시간 20250314_000023_260\n",
      "\n",
      "epoch-66 accuracy check\n",
      "k_means origin feature average accuracy : 82.25503135%, total [0.9746727376209448, 0.9733106189664963, 0.9700891573195284, 0.9530800230282096, 0.943108504398827, 0.9150568181818182, 0.801817648783348, 0.6625070901871809, 0.9488619568430388, 0.822215777262181, 0.5866935483870968, 0.5005858230814294, 0.9429250891795482, 0.8922588099364529, 0.6747093023255814, 0.598912109934154]\n",
      "kmeans average accuracy best : 89.68%, kmeans average accuracy : 88.64636513%, total [0.972965281730222, 0.9741624077228848, 0.9700891573195284, 0.9568221070811744, 0.9580645161290322, 0.9403409090909091, 0.8982703019642334, 0.8077141236528644, 0.9606857818504286, 0.8903712296983759, 0.7808179723502304, 0.7141183362624487, 0.9447086801426873, 0.8887926054303871, 0.8029069767441861, 0.7225880332092757]\n",
      "cluster_accuracy_post_training_cycle_all_dataset : [0.97445601 0.97549482 0.97111218 0.95756991 0.95920398 0.92688679\n",
      " 0.90054699 0.80150517 0.95259708 0.88867188 0.77316602 0.70258193\n",
      " 0.9490835  0.89815713 0.80098039 0.72957477]\n",
      "mean_cluster_accuracy_during_training_cycle : 88.13%, post_traincycle_acc : 88.51%, total_acc : 88.35583954%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 89.48%\n",
      "accuracy_check 실행 시간: 25.964초\n",
      "\n",
      "\n",
      "epoch-67 loss : 0.01165911, loss_normal : 0.01458371, loss_coarse : 0.06760339, min_loss : 0.01160954, min_loss_normal : 0.01456111, min_loss_coarse : 0.06750321, wrong_element_sum : 12979852.00000000, same_data : 0.00%\n",
      "ae train 실행 시간: 121.195초, 전체 시작 시간 20250314_000023_260\n",
      "\n",
      "epoch-67 accuracy check\n",
      "k_means origin feature average accuracy : 82.26037166%, total [0.9746727376209448, 0.9733106189664963, 0.9700891573195284, 0.9530800230282096, 0.943108504398827, 0.9150568181818182, 0.801817648783348, 0.6625070901871809, 0.9488619568430388, 0.822215777262181, 0.5866935483870968, 0.5005858230814294, 0.9429250891795482, 0.8922588099364529, 0.6744186046511628, 0.6000572573718866]\n",
      "kmeans average accuracy best : 89.68%, kmeans average accuracy : 89.04293631%, total [0.9743881616391576, 0.975298126064736, 0.9723899913718723, 0.9573978123200921, 0.9577712609970674, 0.9434659090909091, 0.9085312225153914, 0.8267158252977879, 0.9541826780963641, 0.890661252900232, 0.780241935483871, 0.718804920913884, 0.9464922711058263, 0.8951473136915078, 0.8116279069767441, 0.7337532207271686]\n",
      "cluster_accuracy_post_training_cycle_all_dataset : [0.97587512 0.97502356 0.97400096 0.95949855 0.95920398 0.93443396\n",
      " 0.90452511 0.80385701 0.95209279 0.89208984 0.78088803 0.68073486\n",
      " 0.94348269 0.8986421  0.81470588 0.73817487]\n",
      "mean_cluster_accuracy_during_training_cycle : 88.56%, post_traincycle_acc : 88.67%, total_acc : 88.62375133%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 89.48%\n",
      "accuracy_check 실행 시간: 26.707초\n",
      "\n",
      "\n",
      "epoch-68 loss : 0.01164667, loss_normal : 0.01458949, loss_coarse : 0.06763819, min_loss : 0.01160954, min_loss_normal : 0.01456111, min_loss_coarse : 0.06750321, wrong_element_sum : 12986532.00000000, same_data : 0.00%\n",
      "ae train 실행 시간: 121.858초, 전체 시작 시간 20250314_000023_260\n",
      "\n",
      "epoch-68 accuracy check\n",
      "k_means origin feature average accuracy : 82.25860993%, total [0.9746727376209448, 0.9733106189664963, 0.9700891573195284, 0.9530800230282096, 0.943108504398827, 0.9150568181818182, 0.801817648783348, 0.6625070901871809, 0.9488619568430388, 0.822215777262181, 0.5866935483870968, 0.5005858230814294, 0.9429250891795482, 0.8922588099364529, 0.6747093023255814, 0.5994846836530203]\n",
      "kmeans average accuracy best : 89.68%, kmeans average accuracy : 89.62282444%, total [0.9735344336937962, 0.9741624077228848, 0.9709519700891573, 0.9573978123200921, 0.9586510263929618, 0.9403409090909091, 0.9012019935502785, 0.8048780487804879, 0.9633461424770914, 0.9074825986078886, 0.804147465437788, 0.7343292325717633, 0.953923900118906, 0.9107452339688041, 0.8276162790697674, 0.7569424563412539]\n",
      "cluster_accuracy_post_training_cycle_all_dataset : [0.97587512 0.97549482 0.97255657 0.96046287 0.96069652 0.93160377\n",
      " 0.89308802 0.80197554 0.95663137 0.91455078 0.79874517 0.55412115\n",
      " 0.95672098 0.91610087 0.82745098 0.75537506]\n",
      "mean_cluster_accuracy_during_training_cycle : 87.75%, post_traincycle_acc : 88.45%, total_acc : 88.16172815%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 89.48%\n",
      "accuracy_check 실행 시간: 27.772초\n",
      "\n",
      "\n",
      "epoch-69 loss : 0.01162612, loss_normal : 0.01455967, loss_coarse : 0.06757502, min_loss : 0.01160954, min_loss_normal : 0.01455967, min_loss_coarse : 0.06750321, wrong_element_sum : 12974404.00000000, same_data : 0.00%\n",
      "ae train 실행 시간: 124.257초, 전체 시작 시간 20250314_000023_260\n",
      "\n",
      "epoch-69 accuracy check\n",
      "k_means origin feature average accuracy : 82.25680519%, total [0.9746727376209448, 0.9733106189664963, 0.9700891573195284, 0.9530800230282096, 0.943108504398827, 0.9150568181818182, 0.8015244796247435, 0.6625070901871809, 0.9488619568430388, 0.822215777262181, 0.5866935483870968, 0.5005858230814294, 0.9429250891795482, 0.8922588099364529, 0.675, 0.5991983967935872]\n",
      "kmeans average accuracy best : 89.68%, kmeans average accuracy : 89.28252029%, total [0.9735344336937962, 0.9747302668938104, 0.9721023871153293, 0.9565342544617156, 0.9592375366568915, 0.9463068181818182, 0.9120492524186455, 0.8074305161656268, 0.9592078037245049, 0.9016821345707656, 0.7880184331797235, 0.723784417106034, 0.9527348394768134, 0.9049682264586943, 0.815406976744186, 0.7374749498997996]\n",
      "cluster_accuracy_post_training_cycle_all_dataset : [0.97540208 0.97502356 0.97303804 0.96190935 0.960199   0.93443396\n",
      " 0.91098956 0.82173095 0.95511851 0.90625    0.77316602 0.69712016\n",
      " 0.95468432 0.91076625 0.82990196 0.73817487]\n",
      "mean_cluster_accuracy_during_training_cycle : 88.98%, post_traincycle_acc : 89.24%, total_acc : 89.13144698%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 89.48%\n",
      "accuracy_check 실행 시간: 29.355초\n",
      "\n",
      "\n",
      "epoch-70 loss : 0.01164269, loss_normal : 0.01456220, loss_coarse : 0.06760320, min_loss : 0.01160954, min_loss_normal : 0.01455967, min_loss_coarse : 0.06750321, wrong_element_sum : 12979814.00000000, same_data : 0.00%\n",
      "ae train 실행 시간: 121.967초, 전체 시작 시간 20250314_000023_260\n",
      "\n",
      "epoch-70 accuracy check\n",
      "k_means origin feature average accuracy : 82.25685903%, total [0.9746727376209448, 0.9733106189664963, 0.9700891573195284, 0.9530800230282096, 0.943108504398827, 0.9150568181818182, 0.801817648783348, 0.6622234826999432, 0.9488619568430388, 0.822215777262181, 0.5872695852534562, 0.5005858230814294, 0.9429250891795482, 0.8922588099364529, 0.6747093023255814, 0.598912109934154]\n",
      "kmeans average accuracy best : 89.68%, kmeans average accuracy : 88.75220900%, total [0.9735344336937962, 0.9747302668938104, 0.9715271786022434, 0.9582613701784686, 0.9583577712609971, 0.9380681818181819, 0.9058927000879508, 0.8162223482699943, 0.9562518474726575, 0.8758700696055685, 0.7641129032258065, 0.7100175746924429, 0.9509512485136742, 0.8948584633160023, 0.8127906976744186, 0.7389063841969653]\n",
      "cluster_accuracy_post_training_cycle_all_dataset : [0.97587512 0.97596607 0.97255657 0.96142719 0.960199   0.93113208\n",
      " 0.90452511 0.79303857 0.95410993 0.88378906 0.76013514 0.70307845\n",
      " 0.95468432 0.90058196 0.82843137 0.74534161]\n",
      "mean_cluster_accuracy_during_training_cycle : 88.54%, post_traincycle_acc : 88.78%, total_acc : 88.68126233%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 89.48%\n",
      "accuracy_check 실행 시간: 26.271초\n",
      "\n",
      "\n",
      "epoch-71 loss : 0.01165294, loss_normal : 0.01456583, loss_coarse : 0.06758857, min_loss : 0.01160954, min_loss_normal : 0.01455967, min_loss_coarse : 0.06750321, wrong_element_sum : 12977006.00000000, same_data : 0.00%\n",
      "ae train 실행 시간: 123.020초, 전체 시작 시간 20250314_000023_260\n",
      "\n",
      "epoch-71 accuracy check\n",
      "k_means origin feature average accuracy : 82.26395644%, total [0.9746727376209448, 0.9733106189664963, 0.9700891573195284, 0.9530800230282096, 0.943108504398827, 0.9150568181818182, 0.8015244796247435, 0.6625070901871809, 0.9488619568430388, 0.822215777262181, 0.5872695852534562, 0.5005858230814294, 0.9429250891795482, 0.8922588099364529, 0.6747093023255814, 0.6000572573718866]\n",
      "kmeans average accuracy best : 89.68%, kmeans average accuracy : 88.78888800%, total [0.9738190096755834, 0.975298126064736, 0.9712395743457003, 0.9571099597006333, 0.9583577712609971, 0.9426136363636364, 0.9055995309293462, 0.8034600113442995, 0.9562518474726575, 0.888631090487239, 0.7750576036866359, 0.7044522554188635, 0.9509512485136742, 0.902368573079145, 0.8066860465116279, 0.734325794446035]\n",
      "cluster_accuracy_post_training_cycle_all_dataset : [0.97587512 0.97502356 0.97207511 0.95998071 0.95920398 0.93396226\n",
      " 0.8990552  0.78504233 0.95259708 0.90185547 0.76785714 0.63952334\n",
      " 0.95112016 0.91173618 0.82156863 0.73244147]\n",
      "mean_cluster_accuracy_during_training_cycle : 88.12%, post_traincycle_acc : 88.37%, total_acc : 88.26635661%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 89.48%\n",
      "accuracy_check 실행 시간: 28.015초\n",
      "\n",
      "\n",
      "epoch-72 loss : 0.01184439, loss_normal : 0.01462478, loss_coarse : 0.06797591, min_loss : 0.01160954, min_loss_normal : 0.01455967, min_loss_coarse : 0.06750321, wrong_element_sum : 13051376.00000000, same_data : 0.00%\n",
      "ae train 실행 시간: 123.993초, 전체 시작 시간 20250314_000023_260\n",
      "\n",
      "epoch-72 accuracy check\n",
      "k_means origin feature average accuracy : 82.25308877%, total [0.9746727376209448, 0.9733106189664963, 0.9700891573195284, 0.9530800230282096, 0.943108504398827, 0.9150568181818182, 0.8015244796247435, 0.6625070901871809, 0.9488619568430388, 0.822215777262181, 0.5866935483870968, 0.5005858230814294, 0.9429250891795482, 0.8922588099364529, 0.673546511627907, 0.6000572573718866]\n",
      "kmeans average accuracy best : 89.68%, kmeans average accuracy : 88.37959001%, total [0.9735344336937962, 0.975298126064736, 0.9706643658326143, 0.9568221070811744, 0.9583577712609971, 0.9434659090909091, 0.8985634711228379, 0.7983550765740216, 0.9541826780963641, 0.8773201856148491, 0.7626728110599078, 0.69302870533099, 0.9497621878715814, 0.8931253610629694, 0.8072674418604651, 0.7283137703979388]\n",
      "cluster_accuracy_post_training_cycle_all_dataset : [0.97587512 0.97596607 0.97255657 0.95853423 0.96218905 0.93254717\n",
      " 0.89408255 0.77516463 0.94906707 0.88525391 0.74517375 0.70357498\n",
      " 0.950611   0.8971872  0.81519608 0.73291925]\n",
      "mean_cluster_accuracy_during_training_cycle : 88.25%, post_traincycle_acc : 88.29%, total_acc : 88.26796098%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 89.48%\n",
      "accuracy_check 실행 시간: 27.422초\n",
      "\n",
      "\n",
      "epoch-73 loss : 0.01179510, loss_normal : 0.01459171, loss_coarse : 0.06782283, min_loss : 0.01160954, min_loss_normal : 0.01455967, min_loss_coarse : 0.06750321, wrong_element_sum : 13021984.00000000, same_data : 0.00%\n",
      "ae train 실행 시간: 121.651초, 전체 시작 시간 20250314_000023_260\n",
      "\n",
      "epoch-73 accuracy check\n",
      "k_means origin feature average accuracy : 82.24605861%, total [0.9746727376209448, 0.9733106189664963, 0.9700891573195284, 0.9530800230282096, 0.943108504398827, 0.9150568181818182, 0.8015244796247435, 0.6622234826999432, 0.9488619568430388, 0.822215777262181, 0.5866935483870968, 0.5005858230814294, 0.9429250891795482, 0.8922588099364529, 0.6747093023255814, 0.5980532493558546]\n",
      "kmeans average accuracy best : 89.68%, kmeans average accuracy : 88.89567043%, total [0.9732498577120091, 0.975298126064736, 0.9715271786022434, 0.9562464018422567, 0.9609970674486803, 0.9434659090909091, 0.8976839636470243, 0.7989222915484969, 0.9574342299733964, 0.8970417633410673, 0.7796658986175116, 0.7111892208553017, 0.9503567181926278, 0.8983246678220682, 0.8075581395348838, 0.7443458345261953]\n",
      "cluster_accuracy_post_training_cycle_all_dataset : [0.97587512 0.97502356 0.97255657 0.95901639 0.96119403 0.93679245\n",
      " 0.8876181  0.78880527 0.9515885  0.90527344 0.76978764 0.71400199\n",
      " 0.950611   0.90300679 0.82058824 0.75059723]\n",
      "mean_cluster_accuracy_during_training_cycle : 88.88%, post_traincycle_acc : 88.89%, total_acc : 88.88252239%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 89.48%\n",
      "accuracy_check 실행 시간: 29.172초\n",
      "\n",
      "\n",
      "epoch-74 loss : 0.01171959, loss_normal : 0.01456348, loss_coarse : 0.06763968, min_loss : 0.01160954, min_loss_normal : 0.01455967, min_loss_coarse : 0.06750321, wrong_element_sum : 12986818.00000000, same_data : 0.00%\n",
      "ae train 실행 시간: 121.373초, 전체 시작 시간 20250314_000023_260\n",
      "\n",
      "epoch-74 accuracy check\n",
      "k_means origin feature average accuracy : 82.25129579%, total [0.9746727376209448, 0.9733106189664963, 0.9700891573195284, 0.9530800230282096, 0.943108504398827, 0.9150568181818182, 0.801817648783348, 0.6625070901871809, 0.9488619568430388, 0.8216357308584686, 0.5866935483870968, 0.5005858230814294, 0.9429250891795482, 0.8922588099364529, 0.673546511627907, 0.6000572573718866]\n",
      "kmeans average accuracy best : 89.68%, kmeans average accuracy : 88.60507504%, total [0.9738190096755834, 0.9750141964792731, 0.9718147828587863, 0.9571099597006333, 0.9607038123167155, 0.9423295454545455, 0.9017883318674875, 0.8060124787294385, 0.9559562518474727, 0.8805104408352669, 0.7724654377880185, 0.70298769771529, 0.9432223543400713, 0.892836510687464, 0.8125, 0.7277411966790724]\n",
      "cluster_accuracy_post_training_cycle_all_dataset : [0.97587512 0.97455231 0.97303804 0.95805207 0.96268657 0.92830189\n",
      " 0.90303332 0.80150517 0.9480585  0.89550781 0.77413127 0.65888779\n",
      " 0.94297352 0.89961203 0.80833333 0.73578595]\n",
      "mean_cluster_accuracy_during_training_cycle : 87.83%, post_traincycle_acc : 88.38%, total_acc : 88.15360987%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 89.48%\n",
      "accuracy_check 실행 시간: 27.960초\n",
      "\n",
      "\n",
      "epoch-75 loss : 0.01169360, loss_normal : 0.01456152, loss_coarse : 0.06761448, min_loss : 0.01160954, min_loss_normal : 0.01455967, min_loss_coarse : 0.06750321, wrong_element_sum : 12981980.00000000, same_data : 0.00%\n",
      "ae train 실행 시간: 123.830초, 전체 시작 시간 20250314_000023_260\n",
      "\n",
      "epoch-75 accuracy check\n",
      "k_means origin feature average accuracy : 82.26042087%, total [0.9746727376209448, 0.9733106189664963, 0.9700891573195284, 0.9530800230282096, 0.943108504398827, 0.9150568181818182, 0.801817648783348, 0.6625070901871809, 0.9488619568430388, 0.822215777262181, 0.5872695852534562, 0.5005858230814294, 0.9429250891795482, 0.8922588099364529, 0.6747093023255814, 0.5991983967935872]\n",
      "kmeans average accuracy best : 89.68%, kmeans average accuracy : 89.18559057%, total [0.9738190096755834, 0.975298126064736, 0.9712395743457003, 0.9573978123200921, 0.9615835777126099, 0.9423295454545455, 0.899736147757256, 0.8153715258082813, 0.9600945906000591, 0.898491879350348, 0.7911866359447005, 0.7173403632103105, 0.9488703923900119, 0.8971692663200462, 0.8162790697674419, 0.7434869739478958]\n",
      "cluster_accuracy_post_training_cycle_all_dataset : [0.97587512 0.97596607 0.97207511 0.96094503 0.96069652 0.93773585\n",
      " 0.89457981 0.79209784 0.95763994 0.90722656 0.77220077 0.70059583\n",
      " 0.9490835  0.89476237 0.82254902 0.74438605]\n",
      "mean_cluster_accuracy_during_training_cycle : 88.51%, post_traincycle_acc : 88.87%, total_acc : 88.72192839%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 89.48%\n",
      "accuracy_check 실행 시간: 27.297초\n",
      "\n",
      "\n",
      "epoch-76 loss : 0.01161973, loss_normal : 0.01454845, loss_coarse : 0.06746781, min_loss : 0.01160954, min_loss_normal : 0.01454845, min_loss_coarse : 0.06746781, wrong_element_sum : 12953820.00000000, same_data : 0.00%\n",
      "ae train 실행 시간: 121.161초, 전체 시작 시간 20250314_000023_260\n",
      "\n",
      "epoch-76 accuracy check\n",
      "k_means origin feature average accuracy : 82.25308877%, total [0.9746727376209448, 0.9733106189664963, 0.9700891573195284, 0.9530800230282096, 0.943108504398827, 0.9150568181818182, 0.8015244796247435, 0.6625070901871809, 0.9488619568430388, 0.822215777262181, 0.5866935483870968, 0.5005858230814294, 0.9429250891795482, 0.8922588099364529, 0.673546511627907, 0.6000572573718866]\n",
      "kmeans average accuracy best : 89.68%, kmeans average accuracy : 88.78246347%, total [0.9738190096755834, 0.9747302668938104, 0.9721023871153293, 0.9562464018422567, 0.9595307917888563, 0.9448863636363637, 0.9047200234535326, 0.8091321610890527, 0.9562518474726575, 0.8842807424593968, 0.780241935483871, 0.7073813708260105, 0.9488703923900119, 0.8945696129404969, 0.8063953488372093, 0.7320354995705697]\n",
      "cluster_accuracy_post_training_cycle_all_dataset : [0.97634816 0.97549482 0.97303804 0.95853423 0.96119403 0.93490566\n",
      " 0.89955246 0.7841016  0.95310136 0.89208984 0.76447876 0.69165839\n",
      " 0.94704684 0.90203686 0.81029412 0.73960822]\n",
      "mean_cluster_accuracy_during_training_cycle : 88.41%, post_traincycle_acc : 88.52%, total_acc : 88.47427640%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 89.48%\n",
      "accuracy_check 실행 시간: 30.090초\n",
      "\n",
      "\n",
      "epoch-77 loss : 0.01163772, loss_normal : 0.01454254, loss_coarse : 0.06751908, min_loss : 0.01160954, min_loss_normal : 0.01454254, min_loss_coarse : 0.06746781, wrong_element_sum : 12963664.00000000, same_data : 0.00%\n",
      "ae train 실행 시간: 126.688초, 전체 시작 시간 20250314_000023_260\n",
      "\n",
      "epoch-77 accuracy check\n",
      "k_means origin feature average accuracy : 82.25852131%, total [0.9746727376209448, 0.9733106189664963, 0.9700891573195284, 0.9530800230282096, 0.943108504398827, 0.9150568181818182, 0.801817648783348, 0.6625070901871809, 0.9488619568430388, 0.822215777262181, 0.5872695852534562, 0.5005858230814294, 0.9429250891795482, 0.8922588099364529, 0.673546511627907, 0.6000572573718866]\n",
      "kmeans average accuracy best : 89.68%, kmeans average accuracy : 88.62142153%, total [0.9735344336937962, 0.975298126064736, 0.9721023871153293, 0.9582613701784686, 0.9601173020527859, 0.9457386363636363, 0.8970976253298153, 0.793817356778219, 0.9512267218445167, 0.8851508120649652, 0.7741935483870968, 0.7100175746924429, 0.9450059453032105, 0.8913922588099364, 0.8081395348837209, 0.7383338104780991]\n",
      "cluster_accuracy_post_training_cycle_all_dataset : [0.97587512 0.97596607 0.97303804 0.96046287 0.96169154 0.93726415\n",
      " 0.90004973 0.78033866 0.94553707 0.89746094 0.76110039 0.57696127\n",
      " 0.94450102 0.89670223 0.8127451  0.74343048]\n",
      "mean_cluster_accuracy_during_training_cycle : 88.10%, post_traincycle_acc : 87.77%, total_acc : 87.90336894%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 89.48%\n",
      "accuracy_check 실행 시간: 28.524초\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "gpu = '1'\n",
    "Conv_net = True # True False\n",
    "SAE_net = True # True False\n",
    "\n",
    "# hyperparameter\n",
    "dataset_num = 16\n",
    "spike_length = 50 # coarse_com_mode일 때는 time step이 됨.\n",
    "num_cluster = 4  # 클러스터 수 설정 # 논문엔 4개라는데 여기서는 3개로 했네\n",
    "training_cycle = 1400 #1400 2400 # 그 초기 몇개까지만 cluster update할지\n",
    "\n",
    "\n",
    "batch_size = 32\n",
    "max_epoch = 10000\n",
    "learning_rate = 0.001\n",
    "normalize_on = True # True or False # 0부터1까지 normalize\n",
    "need_bias = False\n",
    "# first_layer_no_train = False\n",
    "lif_add_at_first = False\n",
    "my_seed = 42\n",
    "\n",
    "TIME = 50 # SAE일 때만 유효. coarse_com_mode일 때는 level_num이 됨. 즉 feature 개수.\n",
    "v_decay = 0.5 # -cor\n",
    "v_threshold = 0.25 # -cor\n",
    "v_reset = 0.0 # -cor # 10000이상 일 시 hard reset\n",
    "BPTT_on = True # +cor # True False\n",
    "\n",
    "SAE_hidden_nomean = True # True False\n",
    "\n",
    "current_time = datetime.datetime.now().strftime(\"%Y%m%d_%H%M%S\") + f\"_{str(int(datetime.datetime.now().microsecond / 1000)).zfill(3)}\"\n",
    "\n",
    "optimizer = 'Adam' #'Adam', 'SGD' # 둘다 준수함. loss 줄이는 거는 adam이 좋긴한데, cluster accuracy는 비슷함.\n",
    "\n",
    "coarse_com_mode = True # True False\n",
    "coarse_com_config = (0.999, -0.0) # (max, min) (0.999, -0.0) (1.0, -0.0) (2.0, -2.0) (3.0, -3.0)\n",
    "\n",
    "sae_l2_norm_bridge = True # True False\n",
    "sae_lif_bridge = False # True False\n",
    "\n",
    "accuracy_check_epoch_term = 1\n",
    "\n",
    "lif_add_at_last = False # True False\n",
    "\n",
    "two_channel_input = False # True False\n",
    "\n",
    "lateral_feature_num = 4\n",
    "\n",
    "lc_adc_on = False # True False\n",
    "\n",
    "converted_net_forward = False # True False\n",
    "\n",
    "pretrained_net = None\n",
    "# pretrained_net = '/home/bhkim003/github_folder/ByeonghyeonKim/my_snn/net_save/save_now_net_중요_20250110_203117_390.pth'\n",
    "# pretrained_net = '/home/bhkim003/github_folder/ByeonghyeonKim/my_snn/net_save/save_now_net_중요_20250113_134126_881_이거_94나오는거.pth'\n",
    "# pretrained_net =  '/home/bhkim003/github_folder/ByeonghyeonKim/my_snn/net_save/save_now_net_20250205_184901_132.pth'\n",
    "# pretrained_net =  '/home/bhkim003/github_folder/ByeonghyeonKim/my_snn/net_save/save_now_net_20250306_134219_133.pth'\n",
    "\n",
    "vth_mul_on = False # True False\n",
    "batch_norm_on = False # True False\n",
    "\n",
    "l2_norm_loss_weight = 0 #0.0001 #0.1 #  0 # 0초과면 작동\n",
    "\n",
    "QCFS_neuron_on = False # True False\n",
    "\n",
    "quantize_level_num = 0 # 0이면 quantize 안함. 1이상이면 그 수만큼 quantize함. # normalize_on 켜져야됨. 음수면 0~1norm안하고 quant함\n",
    "\n",
    "fusion_net = True # True False # SAE_net False, Conv_net True로 해라. TIME 적절하게 설정해주고.\n",
    "repeat_coding = False # True False #fusion_net에서 쓰이는 거임 # True면 repeat, False면 rate coding.\n",
    "\n",
    "sae_relu_on = False # True False\n",
    "\n",
    "conv1d_scaling = False # True False # conv1d때매 norm하고 (level_num-3)/level_num 곱해줌 # Conv_net and coarse_com_mode and normalize_on\n",
    "\n",
    "norm01 = True # True False # normalize_on = True일 때 01norm하는지 아님 걍 quant만 하는지.\n",
    "\n",
    "wandb.init(project= f'spike_sorting just run',save_code=False)\n",
    "\n",
    "\n",
    "cluster_train_system( \n",
    "    gpu = gpu,\n",
    "    Conv_net = Conv_net,\n",
    "    SAE_net = SAE_net,\n",
    "\n",
    "    # hyperparameter\n",
    "    dataset_num = dataset_num,\n",
    "    spike_length = spike_length,\n",
    "    num_cluster = num_cluster,  # 클러스터 수 설정 # 논문엔 4개라는데 여기서는 3개로 했네\n",
    "    training_cycle = training_cycle, # 그 초기 몇개까지만 cluster update할지\n",
    "\n",
    "\n",
    "    batch_size = batch_size,\n",
    "    max_epoch = max_epoch,\n",
    "    learning_rate = learning_rate,\n",
    "    normalize_on = normalize_on, # True or False #이거 안 씀 # 이거 별로 안 좋은 normalize같음 # 쓸 거면 다른 거 써라.\n",
    "    need_bias = need_bias,\n",
    "    # first_layer_no_train = False\n",
    "    lif_add_at_first = lif_add_at_first,\n",
    "    my_seed = my_seed,\n",
    "\n",
    "    TIME = TIME, # SAE일 때만 유효\n",
    "    v_decay = v_decay,\n",
    "    v_threshold = v_threshold,\n",
    "    v_reset = v_reset, # 10000이상 일 시 hard reset\n",
    "    BPTT_on = BPTT_on,\n",
    "\n",
    "    SAE_hidden_nomean = SAE_hidden_nomean,\n",
    "    \n",
    "    current_time = current_time,\n",
    "\n",
    "    optimizer = optimizer, #'Adam', 'SGD'\n",
    "\n",
    "    coarse_com_mode = coarse_com_mode,\n",
    "    coarse_com_config = coarse_com_config, # (max, min)\n",
    "\n",
    "    \n",
    "    sae_l2_norm_bridge = sae_l2_norm_bridge,\n",
    "    sae_lif_bridge = sae_lif_bridge,\n",
    "\n",
    "    accuracy_check_epoch_term = accuracy_check_epoch_term,\n",
    "    \n",
    "    lif_add_at_last = lif_add_at_last,\n",
    "\n",
    "    two_channel_input = two_channel_input,\n",
    "\n",
    "    lateral_feature_num = lateral_feature_num,\n",
    "\n",
    "    lc_adc_on = lc_adc_on, \n",
    "\n",
    "    converted_net_forward = converted_net_forward,\n",
    "\n",
    "    pretrained_net = pretrained_net,\n",
    "\n",
    "    vth_mul_on = vth_mul_on,\n",
    "    batch_norm_on = batch_norm_on,\n",
    "\n",
    "    l2_norm_loss_weight = l2_norm_loss_weight,\n",
    "    \n",
    "    QCFS_neuron_on = QCFS_neuron_on, # True False\n",
    "\n",
    "    quantize_level_num = quantize_level_num,\n",
    "\n",
    "    fusion_net = fusion_net, # True False\n",
    "    repeat_coding = repeat_coding,\n",
    "\n",
    "    sae_relu_on = sae_relu_on,\n",
    "\n",
    "    conv1d_scaling = conv1d_scaling,\n",
    "\n",
    "    norm01 = norm01,\n",
    "\n",
    "    )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Sweep code\n",
    "\n",
    "\n",
    "# from unittest import TextTestRunner\n",
    "\n",
    "\n",
    "# unique_name_hyper = 'cluster_train_system'\n",
    "# # run_name = 'spike_sorting'\n",
    "# sweep_start_time =  datetime.datetime.now().strftime(\"%Y%m%d_%H%M%S\") + f\"_{str(int(datetime.datetime.now().microsecond / 1000)).zfill(3)}\"\n",
    "# sweep_configuration = {\n",
    "#     'method': 'bayes', # 'random', 'bayes'\n",
    "#     'name': f'spike_sorting_{sweep_start_time}',\n",
    "#     'metric': {'goal': 'maximize', 'name': 'k_means_acc_best'},\n",
    "#     'parameters': \n",
    "#     {\n",
    "#         # \"gpu\": {\"values\": ['1']},  # 이건 sweep parameter아님. hyper_iter에서 직접 설정\n",
    "#         \"Conv_net\": {\"values\": [True]}, \n",
    "#         \"SAE_net\": {\"values\": [True]}, \n",
    "\n",
    "#         \"dataset_num\": {\"values\": [16]}, \n",
    "#         \"spike_length\": {\"values\": [50]},  \n",
    "#         \"num_cluster\": {\"values\": [4]}, \n",
    "#         \"training_cycle\": {\"values\": [1400]}, # [1400, 2400]\n",
    "\n",
    "#         \"batch_size\": {\"values\": [32]}, \n",
    "#         \"max_epoch\": {\"values\": [20]}, \n",
    "#         \"learning_rate\": {\"values\": [0.001, 0.0001]},\n",
    "#         \"normalize_on\": {\"values\": [True]},\n",
    "#         \"need_bias\": {\"values\": [False]}, # [True, False]\n",
    "\n",
    "#         \"lif_add_at_first\": {\"values\": [False]}, # [True, False]\n",
    "#         \"my_seed\": {\"values\": [42]}, \n",
    "\n",
    "#         \"TIME\": {\"values\": [50]}, #  [4,6,8,10]\n",
    "#         \"v_decay\": {\"values\": [0.125, 0.25,0.50,0.75,1.0]}, # [0.25,0.50,0.75]\n",
    "#         \"v_threshold\": {\"values\": [0.125, 0.25, 0.50, 0.75, 0.875, 1.0]}, # [0.25,0.50,0.75]\n",
    "#         \"v_reset\": {\"values\": [0.0, 10000.0]},  # [0.0, 10000.0]\n",
    "#         \"BPTT_on\": {\"values\": [True, False]},  # [True, False]\n",
    "\n",
    "#         \"SAE_hidden_nomean\": {\"values\": [True]}, # [True, False]\n",
    "\n",
    "#         # \"current_time\": {\"values\": [current_time]} #밑에서 직접설정됨.\n",
    "\n",
    "#         \"optimizer\": {\"values\": ['Adam', 'SGD']}, # ['Adam', 'SGD']\n",
    "\n",
    "#         \"coarse_com_mode\": {\"values\": [True]}, # [True, False]\n",
    "#         \"coarse_com_config\": {\"values\": [(0.999, -0.0)]}, # ['Adam', 'SGD']\n",
    "\n",
    "#         \"sae_l2_norm_bridge\": {\"values\": [True]}, # [True, False]\n",
    "#         \"sae_lif_bridge\": {\"values\": [False]}, # [False, True]\n",
    "        \n",
    "#         \"accuracy_check_epoch_term\": {\"values\": [1]}, \n",
    "\n",
    "#         \"lif_add_at_last\": {\"values\": [False]},# [True, False]\n",
    "\n",
    "#         \"two_channel_input\": {\"values\": [False]},# [True, False]\n",
    "\n",
    "#         \"lateral_feature_num\": {\"values\": [4]},# [True, False]\n",
    "\n",
    "#         \"lc_adc_on\": {\"values\": [False]},# [True, False]\n",
    "        \n",
    "#         \"converted_net_forward\": {\"values\": [False]},# [True, False]\n",
    "\n",
    "#         \"pretrained_net\": {\"values\": [None]},# [None]\n",
    "\n",
    "#         \"vth_mul_on\": {\"values\": [False]},# [True, False]\n",
    "#         \"batch_norm_on\": {\"values\": [False]},# [True, False]\n",
    "\n",
    "#         \"l2_norm_loss_weight\": {\"values\": [0]},\n",
    "\n",
    "#         \"QCFS_neuron_on\": {\"values\": [False]},   # [True, False]\n",
    "\n",
    "#         \"quantize_level_num\": {\"values\": [0]}, \n",
    "\n",
    "#         \"fusion_net\": {\"values\": [True]}, \n",
    "#         \"repeat_coding\": {\"values\": [False]}, \n",
    "\n",
    "#         \"sae_relu_on\": {\"values\": [False]}, \n",
    "\n",
    "#         \"conv1d_scaling\": {\"values\": [False]}, \n",
    "\n",
    "#         \"norm01\": {\"values\": [True]}, \n",
    "#      }\n",
    "# }\n",
    "\n",
    "\n",
    "# def hyper_iter():\n",
    "#     ### my_snn control board ########################\n",
    "#     wandb.init(save_code = False)\n",
    "#     gpu  =  '2'\n",
    "#     Conv_net  =  wandb.config.Conv_net\n",
    "#     SAE_net  =  wandb.config.SAE_net\n",
    "\n",
    "#     dataset_num  =  wandb.config.dataset_num\n",
    "#     spike_length  =  wandb.config.spike_length\n",
    "#     num_cluster  =  wandb.config.num_cluster\n",
    "#     training_cycle  =  wandb.config.training_cycle\n",
    "\n",
    "#     batch_size  =  wandb.config.batch_size\n",
    "#     max_epoch  =  wandb.config.max_epoch\n",
    "#     learning_rate  =  wandb.config.learning_rate\n",
    "#     normalize_on  =  wandb.config.normalize_on\n",
    "#     need_bias  =  wandb.config.need_bias\n",
    "\n",
    "#     lif_add_at_first  =  wandb.config.lif_add_at_first\n",
    "#     my_seed  =  wandb.config.my_seed\n",
    "\n",
    "\n",
    "#     TIME  =  wandb.config.TIME\n",
    "#     v_decay  =  wandb.config.v_decay\n",
    "#     v_threshold  =  wandb.config.v_threshold\n",
    "#     v_reset  =  wandb.config.v_reset\n",
    "#     BPTT_on  =  wandb.config.BPTT_on\n",
    "\n",
    "#     SAE_hidden_nomean  =  wandb.config.SAE_hidden_nomean\n",
    "    \n",
    "#     current_time =  datetime.datetime.now().strftime(\"%Y%m%d_%H%M%S\") + f\"_{str(int(datetime.datetime.now().microsecond / 1000)).zfill(3)}\"\n",
    "\n",
    "#     optimizer  =  wandb.config.optimizer\n",
    "\n",
    "#     coarse_com_mode = wandb.config.coarse_com_mode\n",
    "#     coarse_com_config = wandb.config.coarse_com_config # (max, min)\n",
    "\n",
    "#     sae_l2_norm_bridge = wandb.config.sae_l2_norm_bridge\n",
    "#     sae_lif_bridge = wandb.config.sae_lif_bridge\n",
    "\n",
    "#     accuracy_check_epoch_term = wandb.config.accuracy_check_epoch_term\n",
    "\n",
    "#     lif_add_at_last = wandb.config.lif_add_at_last\n",
    "\n",
    "#     two_channel_input = wandb.config.two_channel_input\n",
    "\n",
    "#     lateral_feature_num = wandb.config.lateral_feature_num\n",
    "\n",
    "#     lc_adc_on = wandb.config.lc_adc_on\n",
    "\n",
    "#     converted_net_forward = wandb.config.converted_net_forward\n",
    "\n",
    "#     pretrained_net = wandb.config.pretrained_net\n",
    "\n",
    "#     vth_mul_on = wandb.config.vth_mul_on\n",
    "#     batch_norm_on = wandb.config.batch_norm_on\n",
    "\n",
    "#     l2_norm_loss_weight = wandb.config.l2_norm_loss_weight\n",
    "\n",
    "#     QCFS_neuron_on = wandb.config.QCFS_neuron_on\n",
    "\n",
    "#     quantize_level_num = wandb.config.quantize_level_num\n",
    "\n",
    "#     fusion_net = wandb.config.fusion_net\n",
    "#     repeat_coding = wandb.config.repeat_coding\n",
    "\n",
    "#     sae_relu_on = wandb.config.sae_relu_on\n",
    "\n",
    "#     conv1d_scaling = wandb.config.conv1d_scaling\n",
    "\n",
    "#     norm01 = wandb.config.norm01\n",
    "\n",
    "#     cluster_train_system( \n",
    "#         gpu = gpu,\n",
    "#         Conv_net = Conv_net,\n",
    "#         SAE_net = SAE_net,\n",
    "\n",
    "#         # hyperparameter\n",
    "#         dataset_num = dataset_num,\n",
    "#         spike_length = spike_length,\n",
    "#         num_cluster = num_cluster,  # 클러스터 수 설정 # 논문엔 4개라는데 여기서는 3개로 했네\n",
    "#         training_cycle = training_cycle, # 그 초기 몇개까지만 cluster update할지\n",
    "\n",
    "\n",
    "#         batch_size = batch_size,\n",
    "#         max_epoch = max_epoch,\n",
    "#         learning_rate = learning_rate,\n",
    "#         normalize_on = normalize_on, # True or False #이거 안 씀 # 이거 별로 안 좋은 normalize같음 # 쓸 거면 다른 거 써라.\n",
    "#         need_bias = need_bias,\n",
    "#         # first_layer_no_train = False\n",
    "#         lif_add_at_first = lif_add_at_first,\n",
    "#         my_seed = my_seed,\n",
    "\n",
    "#         TIME = TIME, # SAE일 때만 유효\n",
    "#         v_decay = v_decay,\n",
    "#         v_threshold = v_threshold,\n",
    "#         v_reset = v_reset, # 10000이상 일 시 hard reset\n",
    "#         BPTT_on = BPTT_on,\n",
    "\n",
    "#         SAE_hidden_nomean = SAE_hidden_nomean,\n",
    "\n",
    "#         current_time = current_time,\n",
    "\n",
    "#         optimizer = optimizer, #'Adam', 'SGD'\n",
    "\n",
    "#         coarse_com_mode = coarse_com_mode,\n",
    "#         coarse_com_config = coarse_com_config, # (max, min)\n",
    "        \n",
    "#         sae_l2_norm_bridge = sae_l2_norm_bridge,\n",
    "#         sae_lif_bridge = sae_lif_bridge,\n",
    "\n",
    "#         accuracy_check_epoch_term = accuracy_check_epoch_term,\n",
    "\n",
    "#         lif_add_at_last = lif_add_at_last,\n",
    "        \n",
    "#         two_channel_input = two_channel_input,\n",
    "        \n",
    "#         lateral_feature_num = lateral_feature_num,\n",
    "\n",
    "#         lc_adc_on = lc_adc_on,\n",
    "\n",
    "#         converted_net_forward = converted_net_forward,\n",
    "\n",
    "#         pretrained_net = pretrained_net,\n",
    "\n",
    "#         vth_mul_on = vth_mul_on,\n",
    "#         batch_norm_on = batch_norm_on,\n",
    "\n",
    "#         l2_norm_loss_weight = l2_norm_loss_weight,\n",
    "\n",
    "#         QCFS_neuron_on = QCFS_neuron_on,\n",
    "\n",
    "#         quantize_level_num = quantize_level_num,\n",
    "\n",
    "#         fusion_net = fusion_net, \n",
    "#         repeat_coding = repeat_coding, \n",
    "\n",
    "#         sae_relu_on = sae_relu_on,\n",
    "\n",
    "#         conv1d_scaling = conv1d_scaling,\n",
    "\n",
    "#         norm01 = norm01,\n",
    "#         )\n",
    "    \n",
    "# # sweep_id = 'ygoj9jt4'\n",
    "# sweep_id = wandb.sweep(sweep=sweep_configuration, project=f'spike_sorting {unique_name_hyper}')\n",
    "# wandb.agent(sweep_id, function=hyper_iter, count=100000, project=f'spike_sorting {unique_name_hyper}')\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wandb.finish() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import matplotlib.pyplot as plt\n",
    "# from matplotlib.ticker import MaxNLocator\n",
    "# import pickle\n",
    "# import json\n",
    "\n",
    "# # current_time = '20250102_225243_972'\n",
    "\n",
    "# with open(f\"result_save/cluster_accuracy_history_{current_time}.pkl\", \"rb\") as f:\n",
    "#     data = pickle.load(f)\n",
    "\n",
    "\n",
    "# # JSON으로 저장\n",
    "# with open(f\"result_save/cluster_accuracy_history_{current_time}.json\", 'r') as f:\n",
    "#     loaded_hyperparameters = json.load(f)\n",
    "\n",
    "# loss_history = data['loss_history']\n",
    "# mean_cluster_accuracy_during_training_cycle_all_dataset_history = data['mean_cluster_accuracy_during_training_cycle_all_dataset_history']\n",
    "# mean_cluster_accuracy_post_training_cycle_all_dataset_history = data['mean_cluster_accuracy_post_training_cycle_all_dataset_history']\n",
    "# mean_cluster_accuracy_total_all_dataset_history = data['mean_cluster_accuracy_total_all_dataset_history']\n",
    "# print(data)\n",
    "# max_acc = 0\n",
    "# for i in mean_cluster_accuracy_post_training_cycle_all_dataset_history:\n",
    "#     if i[1] > max_acc:\n",
    "#         max_acc = i[1]\n",
    "\n",
    "# # 설정 정보 제목 작성\n",
    "# title = (\n",
    "#     f\"Dataset Num: {loaded_hyperparameters['dataset_num']}, Conv {loaded_hyperparameters['Conv_net']}, SAE {loaded_hyperparameters['SAE_net']}, Current time {loaded_hyperparameters['current_time']}, Spike Length: {loaded_hyperparameters['spike_length']}, Num Cluster: {loaded_hyperparameters['num_cluster']}, \"\n",
    "#     f\"Training Cycle: {loaded_hyperparameters['training_cycle']}, Batch Size: {loaded_hyperparameters['batch_size']}, Max Epoch: {loaded_hyperparameters['max_epoch']}, \\n\"\n",
    "#     f\"Learning Rate: {loaded_hyperparameters['learning_rate']}, Input Normalize: {loaded_hyperparameters['normalize_on']}, Need Bias: {loaded_hyperparameters['need_bias']}, \"\n",
    "#     f\"LIF Add at First: {loaded_hyperparameters['lif_add_at_first']}, TIME: {loaded_hyperparameters['TIME']}, Seed: {loaded_hyperparameters['my_seed']}, Best ACC: {max_acc:.2f}%\"\n",
    "# )\n",
    "\n",
    "# # 데이터 리스트와 라벨 설정 (Loss 제외)\n",
    "# data_list = [\n",
    "#     (\"Mean Cluster Accuracy (During Training Cycle)\", mean_cluster_accuracy_during_training_cycle_all_dataset_history),\n",
    "#     (\"Mean Cluster Accuracy (Post Training Cycle)\", mean_cluster_accuracy_post_training_cycle_all_dataset_history),\n",
    "#     (\"Mean Cluster Accuracy (Total)\", mean_cluster_accuracy_total_all_dataset_history),\n",
    "# ]\n",
    "\n",
    "# # 플롯 생성\n",
    "# fig, ax1 = plt.subplots(figsize=(12, 8))\n",
    "\n",
    "# # 첫 번째 y축: Accuracy 관련 데이터\n",
    "# for label, data in data_list:\n",
    "#     epochs, values = zip(*data)  # epoch, value 분리\n",
    "#     ax1.plot(epochs, values, label=label)\n",
    "\n",
    "# ax1.set_xlabel(\"Epoch\")\n",
    "# ax1.set_ylabel(\"Clurstering Accuracy [%]\", color=\"blue\")\n",
    "# ax1.tick_params(axis=\"y\", labelcolor=\"blue\")\n",
    "# ax1.legend(loc=\"center right\")\n",
    "# ax1.grid(True)\n",
    "\n",
    "# # x축을 정수만 표시하도록 설정\n",
    "# ax1.xaxis.set_major_locator(MaxNLocator(integer=True))\n",
    "\n",
    "# # 두 번째 y축: Loss History\n",
    "# ax2 = ax1.twinx()\n",
    "# epochs, values = zip(*loss_history)\n",
    "# ax2.plot(epochs, values, label=\"AE Loss History\", color=\"red\", linestyle=\"--\")\n",
    "# ax2.set_ylabel(\"Loss\", color=\"red\")\n",
    "# ax2.tick_params(axis=\"y\", labelcolor=\"red\")\n",
    "# ax2.legend(loc=\"center left\")\n",
    "\n",
    "# # 제목 추가\n",
    "# plt.title(title, fontsize=10)\n",
    "# plt.tight_layout()\n",
    "# plt.savefig(f'net_save/{current_time}', dpi=300, bbox_inches=\"tight\")  # dpi=300은 고해상도로 저장, bbox_inches=\"tight\"는 여백 최소화\n",
    "# plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# 데이터셋\n",
    "filename_for_plot = [\n",
    "    \"Easy1_noise05\", \"Easy1_noise10\", \"Easy1_noise15\", \"Easy1_noise20\",\n",
    "    \"Easy2_noise05\", \"Easy2_noise10\", \"Easy2_noise15\", \"Easy2_noise20\",\n",
    "    \"Difficult1_noise05\", \"Difficult1_noise10\", \"Difficult1_noise15\", \"Difficult1_noise20\",\n",
    "    \"Difficult2_noise05\", \"Difficult2_noise10\", \"Difficult2_noise15\", \"Difficult2_noise20\"\n",
    "]\n",
    "\n",
    "# Accuracy 데이터\n",
    "ANN_conv_accracy_set= [0.97935368, 0.97682709, 0.97028784, 0.96461825, 0.97524752, 0.95803571\n",
    ", 0.95746785, 0.92628774, 0.965412,  0.97805344, 0.94869403, 0.92110454\n",
    ", 0.96784232, 0.97551789, 0.91538462, 0.84446478]\n",
    "SNN_fc_accuracy_set = [0.97114475, 0.97643732, 0.84400578, 0.78977821, 0.96616915, 0.92830189\n",
    ", 0.86176032, 0.31984948, 0.80635401, 0.88769531, 0.61003861, 0.60377358\n",
    ", 0.9592668,  0.92870999, 0.78333333, 0.67271859]\n",
    "SNN_conv_accuracy_set = [0.97445601, 0.97737983, 0.97063072, 0.95998071, 0.96268657, 0.90566038\n",
    ", 0.82545997, 0.68391345, 0.96116994, 0.92138672, 0.80694981, 0.49602781\n",
    ", 0.83604888, 0.70611057, 0.69313725, 0.5819398 ]\n",
    "\n",
    "# 평균 계산\n",
    "average_ANN_conv = np.mean(ANN_conv_accracy_set)\n",
    "average_SNN_fc = np.mean(SNN_fc_accuracy_set)\n",
    "average_SNN_conv = np.mean(SNN_conv_accuracy_set)\n",
    "\n",
    "# 데이터 준비\n",
    "accuracies = np.array([ANN_conv_accracy_set, SNN_fc_accuracy_set, SNN_conv_accuracy_set])\n",
    "averages = np.array([average_ANN_conv, average_SNN_fc, average_SNN_conv])\n",
    "\n",
    "# 시각화\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "\n",
    "# 각 모델의 정확도 플롯\n",
    "ax.plot(accuracies[0], label='ANN Conv', marker='o', linestyle='-', color='blue')\n",
    "ax.plot(accuracies[1], label='SNN FC', marker='o', linestyle='-', color='green')\n",
    "ax.plot(accuracies[2], label='SNN Conv', marker='o', linestyle='-', color='red')\n",
    "\n",
    "# 평균값 플롯\n",
    "ax.axhline(y=average_ANN_conv, color='blue', linestyle='--', label=f'Average ANN Conv: {average_ANN_conv:.3f}')\n",
    "ax.axhline(y=average_SNN_fc, color='green', linestyle='--', label=f'Average SNN FC: {average_SNN_fc:.3f}')\n",
    "ax.axhline(y=average_SNN_conv, color='red', linestyle='--', label=f'Average SNN Conv: {average_SNN_conv:.3f}')\n",
    "\n",
    "# 레이블 추가\n",
    "ax.set_xticks(np.arange(len(filename_for_plot)))\n",
    "ax.set_xticklabels(filename_for_plot, rotation=45, ha='right')\n",
    "ax.set_ylabel('Accuracy')\n",
    "ax.set_title('Accuracy Comparison of Models on Datasets')\n",
    "ax.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import matplotlib.pyplot as plt\n",
    "import os  # 파일 경로 처리를 위한 모듈\n",
    "\n",
    "# CSV 파일 경로\n",
    "# csv_file_path = \"/home/bhkim003/github_folder/ByeonghyeonKim/my_snn/ae_test_deprecated/250115/sweep0_vth_mul.csv\" # vth_mul해서 sweep 돌린거\n",
    "csv_file_path = \"/home/bhkim003/github_folder/ByeonghyeonKim/my_snn/ae_test_deprecated/250115/sweep1.csv\"  #vth_mul안한거\n",
    "\n",
    "# 결과를 저장할 리스트\n",
    "tuple_list = []\n",
    "\n",
    "# CSV 파일 읽기\n",
    "with open(csv_file_path, 'r') as file:\n",
    "    reader = csv.DictReader(file)\n",
    "    for row in reader:\n",
    "        try:\n",
    "            # v_threshold, TIME, v_reset, converted_k_means_acc 값을 가져와 튜플로 변환\n",
    "            v_threshold = float(row[\"v_threshold\"])\n",
    "            time = int(row[\"TIME\"])\n",
    "            v_reset = int(row[\"v_reset\"])\n",
    "            converted_k_means_acc = float(row[\"converted_k_means_acc\"]) if row[\"converted_k_means_acc\"] else None\n",
    "\n",
    "            # 튜플 형태로 추가 (값이 None일 경우 처리할 수도 있음)\n",
    "            tuple_list.append((v_threshold, time, v_reset, converted_k_means_acc))\n",
    "        except ValueError as e:\n",
    "            print(f\"Error processing row {row}: {e}\")\n",
    "\n",
    "# 데이터를 TIME 기준으로 정렬\n",
    "tuple_list.sort(key=lambda x: x[1])  # TIME을 기준으로 오름차순 정렬\n",
    "\n",
    "# reset 방식에 따라 데이터를 나누기\n",
    "soft_reset = [t for t in tuple_list if t[2] == 0]\n",
    "hard_reset = [t for t in tuple_list if t[2] == 10000]\n",
    "\n",
    "# reset 방식과 v_threshold에 따라 색상 설정\n",
    "def plot_data(data, label_prefix, marker):\n",
    "    for v_threshold in [1.0]:  # v_threshold 기준으로 제한\n",
    "        filtered_data = [(t[1], t[3]) for t in data if t[0] == v_threshold]\n",
    "        if filtered_data:  # 해당 v_threshold 데이터가 있을 경우만 플롯\n",
    "            times, accuracies = zip(*filtered_data)  # x축(TIME), y축(converted_k_means_acc)\n",
    "            \n",
    "            plt.plot(\n",
    "                times,\n",
    "                accuracies,\n",
    "                marker,\n",
    "                label=f\"{label_prefix}, v_threshold={v_threshold}\",\n",
    "                linestyle=\"--\",\n",
    "            )\n",
    "            # 각 점에 accuracy 표시\n",
    "            for time, acc in filtered_data:\n",
    "                if acc == None:\n",
    "                    continue\n",
    "                plt.text(time, acc, f\"{acc:.2f}\", fontsize=8, ha=\"right\")\n",
    "\n",
    "# 그래프 초기화\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "# soft_reset (v_reset=0) 데이터 플롯\n",
    "plot_data(soft_reset, \"Soft Reset\", \"o\")\n",
    "\n",
    "# hard_reset (v_reset=10000) 데이터 플롯\n",
    "plot_data(hard_reset, \"Hard Reset\", \"x\")\n",
    "\n",
    "# baseline accuracy 가로선 추가\n",
    "baseline_accuracy = 94.43\n",
    "plt.axhline(y=baseline_accuracy, color=\"red\", linestyle=\"-\", label=f\"Baseline Accuracy ({baseline_accuracy}%)\")\n",
    "# baseline 텍스트 추가\n",
    "plt.text(\n",
    "    2000,  # x축 위치 (그래프 오른쪽 끝)\n",
    "    baseline_accuracy + 0.4,  # y축 위치 (baseline 위 약간)\n",
    "    f\"ANN Baseline ({baseline_accuracy}%)\",\n",
    "    color=\"red\",\n",
    "    fontsize=10,\n",
    "    ha=\"center\",\n",
    ")\n",
    "\n",
    "# CSV 파일 이름 가져오기\n",
    "csv_file_name = os.path.basename(csv_file_path)\n",
    "\n",
    "# 그래프 세부 설정\n",
    "plt.title(f\"Converted SNN K-Means Accuracy vs TIME STEP - {csv_file_name}\")\n",
    "plt.xlabel(\"TIME STEP\")\n",
    "plt.ylabel(\"Converted K-Means Accuracy [%]\")\n",
    "plt.legend(loc=\"lower right\")  # 범례를 오른쪽 아래로 이동\n",
    "plt.grid(True)\n",
    "\n",
    "# 그래프 출력\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aedat2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
