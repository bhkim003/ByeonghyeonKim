{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ssp.train.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x600 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import torch   \n",
    "import torch.nn as nn \n",
    "import torch.nn.functional as F   \n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import torch.optim as optim\n",
    "from scipy import io\n",
    "import itertools\n",
    "import math\n",
    "import datetime\n",
    "import wandb\n",
    "import pickle\n",
    "import json\n",
    "import time\n",
    "import sys\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import accuracy_score\n",
    "from scipy.optimize import linear_sum_assignment\n",
    "from snntorch import spikegen\n",
    "\n",
    "\n",
    "# my module import\n",
    "from modules import *\n",
    "\n",
    "# modules 폴더에 새모듈.py 만들면\n",
    "# modules/__init__py 파일에 form .새모듈 import * 하셈\n",
    "# 그리고 새모듈.py에서 from modules.새모듈 import * 하셈"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cluster_train_system( \n",
    "    gpu = '4',\n",
    "    Conv_net = True,\n",
    "    SAE_net = True,\n",
    "\n",
    "    # hyperparameter\n",
    "    dataset_num = 16,\n",
    "    spike_length = 50,\n",
    "    num_cluster = 4,  # 클러스터 수 설정 # 논문엔 4개라는데 여기서는 3개로 했네\n",
    "    training_cycle = 2400, # 그 초기 몇개까지만 cluster update할지\n",
    "\n",
    "\n",
    "    batch_size = 32,\n",
    "    max_epoch = 7000,\n",
    "    learning_rate = 0.001,\n",
    "    normalize_on = False, # True or False #이거 안 씀 # 이거 별로 안 좋은 normalize같음 # 쓸 거면 다른 거 써라.\n",
    "    need_bias = False,\n",
    "    # first_layer_no_train = False\n",
    "    lif_add_at_first = False,\n",
    "    my_seed = 42,\n",
    "\n",
    "    TIME = 10, # SAE일 때만 유효\n",
    "    v_decay = 0.5,\n",
    "    v_threshold = 0.5,\n",
    "    v_reset = 10000.0, # 10000이상 일 시 hard reset\n",
    "    BPTT_on = True,\n",
    "\n",
    "    SAE_hidden_nomean = True,\n",
    "    current_time = '20250101_210938_786',\n",
    "\n",
    "    optimizer = 'Adam',\n",
    "    coarse_com_mode = True,\n",
    "    coarse_com_config = (2.0, -2.0), # (max, min)\n",
    "\n",
    "    sae_l2_norm_bridge = True,\n",
    "    sae_lif_bridge = False,\n",
    "\n",
    "    accuracy_check_epoch_term = 5,\n",
    "    \n",
    "    lif_add_at_last = False,\n",
    "\n",
    "    two_channel_input = False,\n",
    "\n",
    "    lateral_feature_num = 4,\n",
    "\n",
    "    lc_adc_on = False, \n",
    "\n",
    "    converted_net_forward = False,\n",
    "\n",
    "    pretrained_net = None, \n",
    "\n",
    "    vth_mul_on = False,\n",
    "    batch_norm_on = False,\n",
    "\n",
    "    l2_norm_loss_weight = 0.0,\n",
    "\n",
    "    QCFS_neuron_on = False,\n",
    "\n",
    "    quantize_level_num = 0,\n",
    "\n",
    "    fusion_net = False, # True False\n",
    "    repeat_coding = False,\n",
    "    \n",
    "    sae_relu_on = False,\n",
    "\n",
    "    conv1d_scaling = False,\n",
    "\n",
    "    norm01 = True,\n",
    "    ):\n",
    "    if coarse_com_mode == True:\n",
    "        assert coarse_com_config[0] > coarse_com_config[1], 'coarse_com_config[0] > coarse_com_config[1]이어야 함'\n",
    "        assert converted_net_forward == False\n",
    "        # assert SAE_net == True, 'coarse_com_mode는 SAE_net이 True일 때만 가능'\n",
    "    if two_channel_input == True:\n",
    "        assert Conv_net and coarse_com_mode, 'two_channel_input는 Conv_net이 True일 때만 가능'\n",
    "    if lc_adc_on == True:\n",
    "        assert coarse_com_mode and SAE_net, 'lc_adc_on은 coarse_com_mode와 SAE_net이 True일 때만 가능'\n",
    "    if converted_net_forward == True:\n",
    "        assert SAE_net == False, 'converted_net_forward는 SAE_net이 False일 때만 가능'\n",
    "    if conv1d_scaling:\n",
    "        assert Conv_net and coarse_com_mode and normalize_on\n",
    "    seed_assign(my_seed)\n",
    "    ## 함수 내 모든 로컬 변수 저장 ########################################################\n",
    "    hyperparameters = locals()\n",
    "    print(hyperparameters)\n",
    "    # JSON으로 저장\n",
    "    with open(f\"result_save/cluster_accuracy_history_{current_time}.json\", 'w') as f:\n",
    "        json.dump(hyperparameters, f, indent=4)\n",
    "    ######################################################################################\n",
    "\n",
    "    \n",
    "    wandb.config.update(hyperparameters)\n",
    "    wandb.run.name = f'{current_time}_SAE_net_{SAE_net}_v_threshold_{v_threshold}'\n",
    "    wandb.define_metric(\"best_mean_cluster_accuracy_post_training_cycle_all_dataset2\", summary=\"max\")\n",
    "\n",
    "\n",
    "    my_path_ground_BH = '/data2/spike_sorting/quiroga/BH/'\n",
    "\n",
    "\n",
    "    filename = [\"C_Easy1_noise005.mat\", \"C_Easy1_noise01.mat\", \"C_Easy1_noise015.mat\", \"C_Easy1_noise02.mat\",\n",
    "                \"C_Easy2_noise005.mat\", \"C_Easy2_noise01.mat\", \"C_Easy2_noise015.mat\", \"C_Easy2_noise02.mat\",\n",
    "                \"C_Difficult1_noise005.mat\", \"C_Difficult1_noise01.mat\", \"C_Difficult1_noise015.mat\", \"C_Difficult1_noise02.mat\",\n",
    "                \"C_Difficult2_noise005.mat\", \"C_Difficult2_noise01.mat\", \"C_Difficult2_noise015.mat\", \"C_Difficult2_noise02.mat\"]\n",
    "\n",
    "\n",
    "    spike_tot = [\"BH_Spike_e1n005.npy\", \"BH_Spike_e1n010.npy\", \"BH_Spike_e1n015.npy\", \"BH_Spike_e1n020.npy\",\n",
    "                \"BH_Spike_e2n005.npy\", \"BH_Spike_e2n010.npy\", \"BH_Spike_e2n015.npy\", \"BH_Spike_e2n020.npy\",\n",
    "                \"BH_Spike_d1n005.npy\", \"BH_Spike_d1n010.npy\", \"BH_Spike_d1n015.npy\", \"BH_Spike_d1n020.npy\",\n",
    "                \"BH_Spike_d2n005.npy\", \"BH_Spike_d2n010.npy\", \"BH_Spike_d2n015.npy\", \"BH_Spike_d2n020.npy\"]\n",
    "\n",
    "    label_tot = [\"BH_Label_e1n005.npy\", \"BH_Label_e1n010.npy\", \"BH_Label_e1n015.npy\", \"BH_Label_e1n020.npy\",\n",
    "                \"BH_Label_e2n005.npy\", \"BH_Label_e2n010.npy\", \"BH_Label_e2n015.npy\", \"BH_Label_e2n020.npy\",\n",
    "                \"BH_Label_d1n005.npy\", \"BH_Label_d1n010.npy\", \"BH_Label_d1n015.npy\", \"BH_Label_d1n020.npy\",\n",
    "                \"BH_Label_d2n005.npy\", \"BH_Label_d2n010.npy\", \"BH_Label_d2n015.npy\", \"BH_Label_d2n020.npy\"]\n",
    "\n",
    "    template =  [\"BH_Spike_TEMPLATE_e1n005.npy\", \"BH_Spike_TEMPLATE_e1n010.npy\", \"BH_Spike_TEMPLATE_e1n015.npy\", \"BH_Spike_TEMPLATE_e1n020.npy\",\n",
    "                \"BH_Spike_TEMPLATE_e2n005.npy\", \"BH_Spike_TEMPLATE_e2n010.npy\", \"BH_Spike_TEMPLATE_e2n015.npy\", \"BH_Spike_TEMPLATE_e2n020.npy\",\n",
    "                \"BH_Spike_TEMPLATE_d1n005.npy\", \"BH_Spike_TEMPLATE_d1n010.npy\", \"BH_Spike_TEMPLATE_d1n015.npy\", \"BH_Spike_TEMPLATE_d1n020.npy\",\n",
    "                \"BH_Spike_TEMPLATE_d2n005.npy\", \"BH_Spike_TEMPLATE_d2n010.npy\", \"BH_Spike_TEMPLATE_d2n015.npy\", \"BH_Spike_TEMPLATE_d2n020.npy\"]\n",
    "\n",
    "    AE_train_path_gt_detect = 'BH_quiroga_training_dataset_gt_detect.pt' \n",
    "    AE_test_path_gt_detect = 'BH_quiroga_test_dataset_gt_detect.pt'\n",
    "\n",
    "    AE_train_path_real_detect = 'BH_quiroga_training_dataset_real_detect.pt'\n",
    "    AE_test_path_real_detect = 'BH_quiroga_test_dataset_real_detect.pt'\n",
    "\n",
    "    AE_train_data = AE_train_path_real_detect #AE_train_path_gt_detect #AE_train_path_real_detect\n",
    "    AE_test_data = AE_test_path_real_detect #AE_test_path_gt_detect  #AE_test_path_real_detect\n",
    "\n",
    "    # thr_tot = np.array([0.5, 0.5, 0.55, 0.7, 0.5, 0.5, 0.55, 0.7, 0.5, 0.5, 0.55, 0.7, 0.5, 0.5, 0.55, 0.7])\n",
    "    cos_thr = np.array([0.95, 0.95, 0.95, 0.95, 0.95, 0.95, 0.95, 0.85, 0.95, 0.9, 0.8, 0.95, 0.95, 0.95, 0.95, 0.8])\n",
    "    # tem=10\n",
    "    # cos_thr = np.array([tem, tem, tem, tem, tem, tem, tem, tem, tem, tem, tem, tem, tem, tem, tem, tem, ])\n",
    "\n",
    "    print('cos_thr', cos_thr)\n",
    "    \n",
    "    os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\" \n",
    "    os.environ[\"CUDA_VISIBLE_DEVICES\"]= gpu\n",
    "\n",
    "\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "\n",
    "    if coarse_com_mode == True:\n",
    "        level_num = TIME\n",
    "        TIME = spike_length\n",
    "        spike_length = level_num\n",
    "        level_interval = (coarse_com_config[0] - coarse_com_config[1]) / (level_num-1)  # max - min\n",
    "        levels = [coarse_com_config[1] + level_interval * i for i in range(level_num)]\n",
    "        levels = torch.tensor(levels).to(torch.float).to(device)\n",
    "        levels = levels.repeat(TIME,1) \n",
    "        # print('levels', levels, levels.shape) # TIME, level_num\n",
    "\n",
    "    n_sample = spike_length\n",
    "\n",
    "    class spikedataset(Dataset):\n",
    "        def __init__(self, path, transform = None):    \n",
    "            self.transform = transform\n",
    "            self.spike = torch.load(path)\n",
    "            \n",
    "        def __getitem__(self, index):\n",
    "            spike = self.spike[index]            \n",
    "            if self.transform is not None:\n",
    "                spike = self.transform(spike)\n",
    "            return spike\n",
    "        \n",
    "        def __len__(self):\n",
    "            return len(self.spike)\n",
    "\n",
    "    train_dataset = spikedataset(my_path_ground_BH + AE_train_data)\n",
    "    train_loader = DataLoader(dataset = train_dataset, batch_size = batch_size, shuffle = True)\n",
    "\n",
    "    test_dataset = spikedataset(my_path_ground_BH + AE_test_data)\n",
    "    test_loader = DataLoader(dataset = test_dataset, batch_size = batch_size, shuffle = False)\n",
    "\n",
    "\n",
    "    # vth_mul_on = True # True False\n",
    "    # batch_norm_on = True # True False\n",
    "\n",
    "\n",
    "    # 모델 초기화\n",
    "    if SAE_net == False: # 여기서는 l2norm, lif bridge 둘 다 true면 l2norm먼저\n",
    "        assert two_channel_input == False\n",
    "\n",
    "        if Conv_net == True:\n",
    "            # input_channels = 2 if two_channel_input else 1\n",
    "            input_channels = TIME if coarse_com_mode else 1\n",
    "            if fusion_net == True:\n",
    "                assert False, '이거 맞음? 다시 확인'\n",
    "                net = FUSION_net_conv1(input_channels=input_channels, input_length=n_sample, encoder_ch = [32, 64, 96], fc_dim = lateral_feature_num, padding = 0, stride = 2, kernel_size = 3, \n",
    "                                    synapse_fc_trace_const1=1, \n",
    "                                    synapse_fc_trace_const2=v_decay, #안씀 \n",
    "                                    TIME=TIME, v_init=0.0, v_decay=v_decay, v_threshold=v_threshold, v_reset=v_reset, \n",
    "                                    sg_width=4.0, surrogate='sigmoid', BPTT_on=BPTT_on, need_bias=need_bias, lif_add_at_first=lif_add_at_first,\n",
    "                                    sae_l2_norm_bridge = sae_l2_norm_bridge, sae_lif_bridge = sae_lif_bridge, lif_add_at_last=lif_add_at_last, repeat_coding=repeat_coding).to(device)\n",
    "            else: \n",
    "                net = Autoencoder_conv1(input_channels=input_channels, input_length=n_sample, encoder_ch = [32, 64, 96], fc_dim = lateral_feature_num, padding = 0, stride = 2, kernel_size = 3, need_bias=need_bias, l2norm_bridge=sae_l2_norm_bridge, relu_bridge=sae_lif_bridge, activation_collector_on=False,\n",
    "                                        batch_norm_on=batch_norm_on, QCFS_neuron_on=QCFS_neuron_on).to(device)\n",
    "            net = torch.nn.DataParallel(net)\n",
    "            if converted_net_forward:\n",
    "                converted_net = SAE_converted_conv1(input_channels=input_channels, input_length=n_sample, encoder_ch = [32, 64, 96], fc_dim = lateral_feature_num, padding = 0, stride = 2, kernel_size = 3, \n",
    "                                    synapse_fc_trace_const1=1, \n",
    "                                    synapse_fc_trace_const2=v_decay, #안씀 \n",
    "                                    TIME=TIME, v_init=0.0, v_decay=v_decay, v_threshold=v_threshold, v_reset=v_reset, \n",
    "                                    sg_width=4.0, surrogate='sigmoid', BPTT_on=BPTT_on, need_bias=need_bias, lif_add_at_first=lif_add_at_first,\n",
    "                                    sae_l2_norm_bridge = sae_l2_norm_bridge, sae_lif_bridge = sae_lif_bridge, lif_add_at_last=lif_add_at_last,\n",
    "                                    vth_mul_on=vth_mul_on, batch_norm_on=batch_norm_on).to(device) # lif bridge는 무조건 들어가게 해놨음.\n",
    "                converted_net = torch.nn.DataParallel(converted_net)\n",
    "                print('converted_net', converted_net)\n",
    "        else:\n",
    "            n_sample = n_sample * TIME if coarse_com_mode else n_sample\n",
    "            net = Autoencoder_only_FC(encoder_ch=[400, lateral_feature_num], decoder_ch=[400,n_sample], n_sample=n_sample, need_bias=need_bias, l2norm_bridge=sae_l2_norm_bridge, relu_bridge=sae_lif_bridge, activation_collector_on=False,\n",
    "                                    batch_norm_on=batch_norm_on, QCFS_neuron_on=QCFS_neuron_on).to(device)\n",
    "            net = torch.nn.DataParallel(net)\n",
    "            if converted_net_forward:\n",
    "                converted_net = SAE_converted_fc(encoder_ch=[400, lateral_feature_num], \n",
    "                                    decoder_ch=[400, n_sample], \n",
    "                                    in_channels=n_sample, # in_channel 이 여기선 걍 lenght.\n",
    "                                    synapse_fc_trace_const1=1,\n",
    "                                    synapse_fc_trace_const2=v_decay,  #안씀 \n",
    "                                    TIME=TIME, v_init=0.0, v_decay=v_decay, v_threshold=v_threshold, v_reset=v_reset, \n",
    "                                    sg_width=4.0, surrogate='sigmoid', BPTT_on=BPTT_on, need_bias=need_bias, lif_add_at_first=lif_add_at_first,\n",
    "                                    sae_l2_norm_bridge = sae_l2_norm_bridge, sae_lif_bridge = sae_lif_bridge, lif_add_at_last=lif_add_at_last,\n",
    "                                    vth_mul_on=vth_mul_on, batch_norm_on=batch_norm_on).to(device) # lif bridge는 무조건 들어가게 해놨음.\n",
    "                converted_net = torch.nn.DataParallel(converted_net)\n",
    "                # print('converted_net', converted_net)\n",
    "    else:\n",
    "        if Conv_net == True: \n",
    "            input_channels = 1\n",
    "            input_channels = 2 if two_channel_input else 1\n",
    "            if fusion_net == True:  \n",
    "                assert coarse_com_mode == True\n",
    "                # net = SAE_FUSION2_net_conv1(input_channels=input_channels, input_length=n_sample, encoder_ch = [32, 64, 96], fc_dim = lateral_feature_num, padding = 0, stride = 2, kernel_size = 3, \n",
    "                #                     synapse_fc_trace_const1=1, \n",
    "                #                     synapse_fc_trace_const2=v_decay, #안씀 \n",
    "                #                     TIME=TIME, v_init=0.0, v_decay=v_decay, v_threshold=v_threshold, v_reset=v_reset, \n",
    "                #                     sg_width=4.0, surrogate='sigmoid', BPTT_on=BPTT_on, need_bias=need_bias, lif_add_at_first=lif_add_at_first,\n",
    "                #                     sae_l2_norm_bridge = sae_l2_norm_bridge, sae_lif_bridge = sae_lif_bridge, lif_add_at_last=lif_add_at_last, batch_norm_on=batch_norm_on, sae_relu_on=sae_relu_on).to(device)\n",
    "                # net = SAE_FUSION3_net_conv1(input_channels=input_channels, input_length=n_sample, encoder_ch = [32, 64, 96], fc_dim = lateral_feature_num, padding = 0, stride = 2, kernel_size = 3, \n",
    "                #                     synapse_fc_trace_const1=1, \n",
    "                #                     synapse_fc_trace_const2=v_decay, #안씀 \n",
    "                #                     TIME=TIME, v_init=0.0, v_decay=v_decay, v_threshold=v_threshold, v_reset=v_reset, \n",
    "                #                     sg_width=4.0, surrogate='sigmoid', BPTT_on=BPTT_on, need_bias=need_bias, lif_add_at_first=lif_add_at_first,\n",
    "                #                     sae_l2_norm_bridge = sae_l2_norm_bridge, sae_lif_bridge = sae_lif_bridge, lif_add_at_last=lif_add_at_last, batch_norm_on=batch_norm_on, sae_relu_on=sae_relu_on).to(device)\n",
    "                # net = SAE_FUSION4_net_conv1(input_channels=input_channels, input_length=n_sample, encoder_ch = [32, 64, 96], fc_dim = lateral_feature_num, padding = 0, stride = 2, kernel_size = 3, \n",
    "                #                     synapse_fc_trace_const1=1, \n",
    "                #                     synapse_fc_trace_const2=v_decay, #안씀 \n",
    "                #                     TIME=TIME, v_init=0.0, v_decay=v_decay, v_threshold=v_threshold, v_reset=v_reset, \n",
    "                #                     sg_width=4.0, surrogate='sigmoid', BPTT_on=BPTT_on, need_bias=need_bias, lif_add_at_first=lif_add_at_first,\n",
    "                #                     sae_l2_norm_bridge = sae_l2_norm_bridge, sae_lif_bridge = sae_lif_bridge, lif_add_at_last=lif_add_at_last, batch_norm_on=batch_norm_on, sae_relu_on=sae_relu_on).to(device)\n",
    "                # net = SAE_FUSION5_net_conv1(input_channels=input_channels, input_length=n_sample, encoder_ch = [32, 64, 96], fc_dim = lateral_feature_num, padding = 0, stride = 2, kernel_size = 3, \n",
    "                #                     synapse_fc_trace_const1=1, \n",
    "                #                     synapse_fc_trace_const2=v_decay, #안씀 \n",
    "                #                     TIME=TIME, v_init=0.0, v_decay=v_decay, v_threshold=v_threshold, v_reset=v_reset, \n",
    "                #                     sg_width=4.0, surrogate='sigmoid', BPTT_on=BPTT_on, need_bias=need_bias, lif_add_at_first=lif_add_at_first,\n",
    "                #                     sae_l2_norm_bridge = sae_l2_norm_bridge, sae_lif_bridge = sae_lif_bridge, lif_add_at_last=lif_add_at_last, batch_norm_on=batch_norm_on, sae_relu_on=sae_relu_on).to(device)\n",
    "                net = SAE_FUSION6_net_conv1(input_channels=input_channels, input_length=n_sample, encoder_ch = [32, 64, 96], fc_dim = lateral_feature_num, padding = 0, stride = 2, kernel_size = 3, \n",
    "                                    synapse_fc_trace_const1=1, \n",
    "                                    synapse_fc_trace_const2=v_decay, #안씀 \n",
    "                                    TIME=TIME, v_init=0.0, v_decay=v_decay, v_threshold=v_threshold, v_reset=v_reset, \n",
    "                                    sg_width=4.0, surrogate='sigmoid', BPTT_on=BPTT_on, need_bias=need_bias, lif_add_at_first=lif_add_at_first,\n",
    "                                    sae_l2_norm_bridge = sae_l2_norm_bridge, sae_lif_bridge = sae_lif_bridge, lif_add_at_last=lif_add_at_last, batch_norm_on=batch_norm_on, sae_relu_on=sae_relu_on).to(device)\n",
    "            else:\n",
    "                net = SAE_conv1(input_channels=input_channels, input_length=n_sample, encoder_ch = [32, 64, 96], fc_dim = lateral_feature_num, padding = 0, stride = 2, kernel_size = 3, \n",
    "                                    synapse_fc_trace_const1=1, \n",
    "                                    synapse_fc_trace_const2=v_decay, #안씀 \n",
    "                                    TIME=TIME, v_init=0.0, v_decay=v_decay, v_threshold=v_threshold, v_reset=v_reset, \n",
    "                                    sg_width=4.0, surrogate='sigmoid', BPTT_on=BPTT_on, need_bias=need_bias, lif_add_at_first=lif_add_at_first,\n",
    "                                    sae_l2_norm_bridge = sae_l2_norm_bridge, sae_lif_bridge = sae_lif_bridge, lif_add_at_last=lif_add_at_last, batch_norm_on=batch_norm_on, sae_relu_on=sae_relu_on).to(device)\n",
    "            # net = SAE_conv1_DR(input_channels=input_channels, input_length=n_sample, encoder_ch = [32, 64, 96], fc_dim = lateral_feature_num, padding = 0, stride = 2, kernel_size = 3, \n",
    "            #                     synapse_fc_trace_const1=1, \n",
    "            #                     synapse_fc_trace_const2=v_decay, #안씀 \n",
    "            #                     TIME=TIME, v_init=0.0, v_decay=v_decay, v_threshold=v_threshold, v_reset=v_reset, \n",
    "            #                     sg_width=4.0, surrogate='sigmoid', BPTT_on=BPTT_on, need_bias=need_bias, lif_add_at_first=lif_add_at_first,\n",
    "            #                     sae_l2_norm_bridge = sae_l2_norm_bridge, sae_lif_bridge = sae_lif_bridge, lif_add_at_last=lif_add_at_last, batch_norm_on=batch_norm_on).to(device)\n",
    "            net = torch.nn.DataParallel(net)\n",
    "        else:\n",
    "            net = SAE_fc_only(encoder_ch=[400, lateral_feature_num], \n",
    "                                decoder_ch=[400, n_sample], \n",
    "                                in_channels=n_sample, # in_channel 이 여기선 걍 lenght.\n",
    "                                synapse_fc_trace_const1=1,\n",
    "                                synapse_fc_trace_const2=v_decay,  #안씀 \n",
    "                                TIME=TIME, v_init=0.0, v_decay=v_decay, v_threshold=v_threshold, v_reset=v_reset, \n",
    "                                sg_width=4.0, surrogate='sigmoid', BPTT_on=BPTT_on, need_bias=need_bias, lif_add_at_first=lif_add_at_first,\n",
    "                                sae_l2_norm_bridge = sae_l2_norm_bridge, sae_lif_bridge = sae_lif_bridge, lif_add_at_last=lif_add_at_last, batch_norm_on=batch_norm_on, sae_relu_on=sae_relu_on).to(device)\n",
    "            net = torch.nn.DataParallel(net)\n",
    "\n",
    "    # net = torch.load('/home/bhkim003/github_folder/ByeonghyeonKim/my_snn/net_save/save_now_net_AE_re_e7000.pth')\n",
    "    # net = torch.load('/home/bhkim003/github_folder/ByeonghyeonKim/my_snn/net_save/save_now_net_20250101_210938_786.pth')\n",
    "    # load했으면 torch.nn.DataParallel 하지마\n",
    "    # net.module.load_state_dict(torch.load('/home/bhkim003/github_folder/ByeonghyeonKim/my_snn/net_save/save_now_net_annbase_20250108_210641_941.pth'))\n",
    "    if pretrained_net != None:\n",
    "        ######################## 모델이 달라서 dict로 weight만 넣고싶을 때\n",
    "        # # 저장된 가중치 로드\n",
    "        saved_state_dict = torch.load(pretrained_net)\n",
    "        current_state_dict = net.module.state_dict()\n",
    "\n",
    "        # 함수 호출로 가중치 매핑\n",
    "        updated_state_dict = map_and_load_weights(saved_state_dict, current_state_dict)\n",
    "\n",
    "        # 업데이트된 state_dict를 네트워크에 로드\n",
    "        net.module.load_state_dict(updated_state_dict)\n",
    "        ######################## 모델이 달라서 dict로 weight만 넣고싶을 때\n",
    "\n",
    "        ############## 일반적일 때\n",
    "        # net.module.load_state_dict(torch.load(pretrained_net))\n",
    "        ############## 일반적일 때\n",
    "    \n",
    "        # pre_net = Autoencoder_conv1(input_channels=input_channels, input_length=n_sample, encoder_ch = [32, 64, 96], fc_dim = lateral_feature_num, padding = 0, stride = 2, kernel_size = 3, need_bias=need_bias, l2norm_bridge=sae_l2_norm_bridge, relu_bridge=sae_lif_bridge, activation_collector_on=False,\n",
    "        #                         batch_norm_on=batch_norm_on, QCFS_neuron_on=False).to(device)\n",
    "        # pre_net = torch.nn.DataParallel(net)\n",
    "        # pre_net.module.load_state_dict(torch.load(pretrained_net))\n",
    "        # copy_weights(pre_net.module.encoder , net.module.encoder )\n",
    "        # copy_weights(pre_net.module.decoder , net.module.decoder  )\n",
    "\n",
    "        \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    wandb.watch(net, log=\"all\", log_freq = 10)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    if SAE_net == True:\n",
    "        assert 'SAE' in net.module.__class__.__name__\n",
    "\n",
    "\n",
    "\n",
    "    net = net.to(device)\n",
    "    print(f\"Total number of encoder parameters: {sum(p.numel() for p in net.module.encoder.parameters())}\")\n",
    "    print(net)\n",
    "    print('Device:',device)\n",
    "\n",
    "    \n",
    "    if optimizer == 'Adam':\n",
    "        optimizer = optim.Adam(net.parameters(), lr=learning_rate)\n",
    "    elif optimizer == 'SGD':\n",
    "        optimizer = optim.SGD(net.parameters(), lr = learning_rate, momentum = 0.9)\n",
    "    else:\n",
    "        assert False, 'optimizer를 잘못 입력했습니다.'\n",
    "        \n",
    "    loss_history = []\n",
    "    mean_cluster_accuracy_during_training_cycle_all_dataset_history = []\n",
    "    mean_cluster_accuracy_post_training_cycle_all_dataset_history = []\n",
    "    mean_cluster_accuracy_total_all_dataset_history = []\n",
    "\n",
    "    tau = np.zeros(num_cluster)\n",
    "\n",
    "    print(f\"\\nStart Training, current_time = {current_time}\")\n",
    "    mean_cluster_accuracy_post_training_cycle_all_dataset = 0\n",
    "    best_mean_cluster_accuracy_post_training_cycle_all_dataset = 0\n",
    "\n",
    "    if SAE_net == True:\n",
    "        assert 'SAE' in net.module.__class__.__name__\n",
    "        \n",
    "    k_means_acc_best = 0\n",
    "    min_loss = 9999999\n",
    "    min_loss_normal = 9999999\n",
    "    min_loss_coarse = 9999999\n",
    "    for epoch in range(max_epoch):\n",
    "        print()\n",
    "        l2_loss_bin= 0\n",
    "        ae_train_start_time = time.time()\n",
    "        running_loss = 0.0\n",
    "        running_loss_normal = 0.0\n",
    "        running_loss_coarse = 0.0\n",
    "        iter = 0\n",
    "        net.train()\n",
    "        # if True or max_epoch != 1:\n",
    "        wrong_element_sum = 0\n",
    "        same_data_num = 0\n",
    "        total_data_num = 0\n",
    "        if max_epoch != 1:\n",
    "            for data in train_loader:\n",
    "                optimizer.zero_grad()\n",
    "                total_data_num += len(data)\n",
    "                data = data.to(device)\n",
    "                scaling = (level_num-3)/level_num if conv1d_scaling else 1.0\n",
    "                data = zero_to_one_normalize_features(data, level_num=quantize_level_num, coarse_com_config=coarse_com_config, scaling=scaling, norm01=norm01) if normalize_on else data\n",
    "                # plot_origin_spike(data[0].cpu().detach().numpy(), min_max_y_on = True)\n",
    "                # plot_origin_spike(data[1].cpu().detach().numpy(), min_max_y_on = True)\n",
    "                spike_backup = data\n",
    "                spike = data\n",
    "                spike = spike.to(device) # batch, feature\n",
    "                spike_for_fusion2_net = spike\n",
    "                if coarse_com_mode == True and 'SAE' in net.module.__class__.__name__:\n",
    "                    # print(spike[0])\n",
    "                    spike = spike.unsqueeze(2).repeat(1, 1, level_num) # spike_length == level_num # (batch, time, feature)로 변환 \n",
    "                    spike = (spike > levels).to(torch.float) \n",
    "\n",
    "                    spike = (spike == 0).cumsum(dim=-1).eq(1).to(torch.float) if lc_adc_on == True else spike\n",
    "\n",
    "                    # spike: batch, time, level_num\n",
    "                    # levels: time, level_num\n",
    "                    if Conv_net == True:\n",
    "                        spike = spike.unsqueeze(-2) # batch, time, in_channel, feature or batch in_channel,feature\n",
    "                        if two_channel_input == True:\n",
    "                            spike_backup = spike_backup.to(device)\n",
    "                            spike_backup = spike_backup.unsqueeze(2).repeat(1, 1, level_num) # spike_length == level_num # (batch, time, feature)로 변환 \n",
    "                            spike_backup = (spike_backup <= levels).to(torch.float) \n",
    "                            spike_backup = (spike_backup == 1).cumsum(dim=-1).eq(1).to(torch.float) if lc_adc_on == True else spike_backup\n",
    "                            spike_backup = spike_backup.unsqueeze(-2)\n",
    "                            spike = torch.cat((spike, spike_backup), dim=-2)\n",
    "                    assert spike.shape[0] == batch_size and spike.shape[1] == TIME\n",
    "                elif 'SAE' in net.module.__class__.__name__:\n",
    "                    spike = spike.unsqueeze(-1).repeat(1, 1, TIME).permute(0,2,1) # (batch, time, feature)로 변환\n",
    "                    if Conv_net == True:\n",
    "                        spike = spike.unsqueeze(-2) # batch, time, in_channel, feature or batch in_channel,feature\n",
    "                else:\n",
    "                    if Conv_net == True:\n",
    "                        if coarse_com_mode == False:\n",
    "                            spike = spike.unsqueeze(-2) #batch in_channel,feature\n",
    "                        else:\n",
    "                            spike = spike.unsqueeze(2).repeat(1, 1, level_num) # spike_length == level_num # (batch, time, feature)로 변환 \n",
    "                            spike = (spike > levels).to(torch.float) \n",
    "\n",
    "                            spike = (spike == 0).cumsum(dim=-1).eq(1).to(torch.float) if lc_adc_on == True else spike\n",
    "\n",
    "                    else:\n",
    "                        if coarse_com_mode == False:\n",
    "                            pass\n",
    "                        else:\n",
    "                            spike = spike.unsqueeze(2).repeat(1, 1, level_num) # spike_length == level_num # (batch, time, feature)로 변환 \n",
    "                            spike = (spike > levels).to(torch.float) \n",
    "\n",
    "                            spike = (spike == 0).cumsum(dim=-1).eq(1).to(torch.float) if lc_adc_on == True else spike\n",
    "\n",
    "                            # spike: batch, time, feature\n",
    "                            spike = spike.reshape(spike.shape[0], -1)\n",
    "\n",
    "                    \n",
    "\n",
    "\n",
    "                    # if fusion_net == True:\n",
    "                    #     spike = spikegen.rate(spike, num_steps=TIME).transpose(0, 1)\n",
    "\n",
    "                # spike_class = net(spike) # batch, time, feature\n",
    "                encoded_spike = net.module.encoder(spike)\n",
    "                spike_class = net.module.decoder(encoded_spike)\n",
    "\n",
    "                # for i in range (2):\n",
    "                #     plot_spike(spike[i,:,0,:].cpu().numpy())\n",
    "                #     # plot_spike(spike[i,:,1,:].cpu().numpy())\n",
    "                #     plot_origin_spike(spike_class.squeeze()[i].cpu().detach().numpy(), min_max_y_on = True)\n",
    "                # assert False\n",
    "                        \n",
    "\n",
    "                loss = 0\n",
    "                loss_normal = torch.tensor(0.0)\n",
    "                loss_coarse = torch.tensor(0.0)\n",
    "                if coarse_com_mode == True and 'SAE' in net.module.__class__.__name__:\n",
    "                    criterion = nn.MSELoss().to(device)\n",
    "                    # loss1 = nn.MSELoss()(spike_class[..., 5:25], spike[..., 5:25])\n",
    "                    # loss2 = nn.MSELoss()(spike_class[..., 0:5], spike[..., 0:5])\n",
    "                    # loss3 = nn.MSELoss()(spike_class[..., 25:spike_length], spike[..., 25:spike_length])\n",
    "                    # loss = loss1 * 2.125 + (loss2 + loss3)/4\n",
    "\n",
    "                    # loss1 = nn.MSELoss()(spike_class[..., 5:25, :], spike[..., 5:25, :])\n",
    "                    # loss2 = nn.MSELoss()(spike_class[..., 0:5, :], spike[..., 0:5, :])\n",
    "                    # loss3 = nn.MSELoss()(spike_class[..., 25:spike_length, :], spike[..., 25:spike_length, :])\n",
    "                    # loss = loss1 * 2.125 + (loss2 + loss3)/4\n",
    "                    if fusion_net:\n",
    "                        # print('1', spike.shape) # batch, time, in_channel, feature [32, 50, 1, 50]\n",
    "                        \n",
    "                        # ### coarse에서 ann loss 만들기 ######\n",
    "                        # spike = spike.squeeze()\n",
    "                        # assert two_channel_input == False\n",
    "                        # zero_mask = (spike == 0)  # 0이 있는 위치\n",
    "                        # first_zero_idx = torch.where(zero_mask, torch.arange(spike.shape[-1]).to(device), spike.shape[-1]-1).min(dim=-1).values\n",
    "                        # spike = levels[0][first_zero_idx]\n",
    "                        # # plot_origin_spike(spike[0].cpu().detach().numpy())\n",
    "                        # ### coarse에서 ann loss 만들기 ######\n",
    "\n",
    "                        ### 그냥 원래 스파이크로 ann loss 만들기 ######\n",
    "                        spike = spike_for_fusion2_net\n",
    "                        ### 그냥 원래 스파이크로 ann loss 만들기 ######\n",
    "\n",
    "                        spike = spike.squeeze()\n",
    "                        spike_class = spike_class.squeeze()\n",
    "                        \n",
    "                        ### normal loss################\n",
    "                        # loss = criterion(spike_class, spike)\n",
    "                        ### normal loss################\n",
    "                        \n",
    "                        ### chan loss################\n",
    "                        loss1 = criterion(spike_class[..., 5:25], spike[..., 5:25])\n",
    "                        loss2 = criterion(spike_class[..., 0:5], spike[..., 0:5])\n",
    "                        loss3 = criterion(spike_class[..., 25:], spike[..., 25:])\n",
    "                        loss = loss1 * 2.125 + (loss2 + loss3)/4\n",
    "                        ### chan loss################\n",
    "\n",
    "\n",
    "                        # #########################################\n",
    "                        # # 손실 함수 정의 (예: MSELoss 사용)\n",
    "                        # criterion_joke = torch.nn.MSELoss(reduction='none')  # 개별 요소별 손실을 유지\n",
    "\n",
    "                        # # 손실 계산\n",
    "                        # loss1_joke = criterion_joke(spike_class[..., 5:25], spike[..., 5:25]).mean(dim=-1)  # (batch,)\n",
    "                        # loss2_joke = criterion_joke(spike_class[..., 0:5], spike[..., 0:5]).mean(dim=-1)    # (batch,)\n",
    "                        # loss3_joke = criterion_joke(spike_class[..., 25:], spike[..., 25:]).mean(dim=-1)    # (batch,)\n",
    "\n",
    "                        # # 주어진 가중치를 적용한 최종 손실\n",
    "                        # loss_joke = loss1_joke * 2.125 + (loss2_joke + loss3_joke) / 4  # (batch,)\n",
    "\n",
    "                        # # 가장 큰 손실을 갖는 샘플의 인덱스 찾기\n",
    "                        # max_loss_idx_joke = torch.argmax(loss_joke)\n",
    "\n",
    "                        # # 해당 샘플 선택\n",
    "                        # selected_sample_class = spike_class[max_loss_idx_joke]\n",
    "                        # selected_sample_spike = spike[max_loss_idx_joke]\n",
    "\n",
    "                        # # 선택한 샘플의 손실 값 출력\n",
    "                        # print(\"Index of max loss sample:\", max_loss_idx_joke.item())\n",
    "                        # print(\"Max loss value:\", loss_joke[max_loss_idx_joke].item())\n",
    "                        # mean_loss_joke = loss_joke.mean().item()\n",
    "                        # print(\"Mean loss across the batch:\", mean_loss_joke)\n",
    "\n",
    "                        # # 선택한 샘플을 시각화\n",
    "                        # plot_origin_spike(selected_sample_class.cpu().detach().numpy())\n",
    "                        # plot_origin_spike(selected_sample_spike.cpu().detach().numpy())\n",
    "                        # #########################################\n",
    "\n",
    "                        # coarse loss ######################################################\n",
    "                        loss_normal = criterion(spike_class, spike)\n",
    "                        level_num_in_loss = spike_length\n",
    "                        level_interval = (coarse_com_config[0] - coarse_com_config[1]) / (level_num_in_loss-1)  # max - min\n",
    "                        levels = [coarse_com_config[1] + level_interval * i for i in range(level_num_in_loss)]\n",
    "                        levels = torch.tensor(levels).to(torch.float).to(device)\n",
    "                        # print('coarse leves', levels)\n",
    "                        levels = levels.repeat(spike_length,1) \n",
    "\n",
    "                        spike = spike.squeeze()\n",
    "                        spike_class = spike_class.squeeze()\n",
    "                        # plot_origin_spike(spike_class[0].cpu().detach().numpy())\n",
    "                        spike = spike.unsqueeze(2).repeat(1, 1, level_num_in_loss) \n",
    "                        spike = (spike > levels).to(torch.float) \n",
    "                        spike_class = spike_class.unsqueeze(2).repeat(1, 1, level_num_in_loss) \n",
    "                        spike_class = (spike_class > levels).to(torch.float) \n",
    "                        # spike = spike[..., 0:-3, :]\n",
    "                        # spike_class = spike_class[..., 0:-3, :]\n",
    "                        loss_coarse = criterion(spike_class, spike)\n",
    "                        wrong_element_sum += torch.sum(torch.abs(spike - spike_class)).item() \n",
    "\n",
    "                        # plot_spike(spike_class[0].cpu().detach().numpy())\n",
    "                        # assert False\n",
    "                        # coarse loss ######################################################\n",
    "                    else:\n",
    "                        spike = spike.squeeze()\n",
    "                        spike_class = spike_class.squeeze()\n",
    "                        loss = criterion(spike_class, spike)\n",
    "\n",
    "                    for iii in range(spike.shape[0]):\n",
    "                        same_data_num = same_data_num + 1 if torch.eq(spike[iii], spike_class[iii]).all() else same_data_num\n",
    "                    wrong_element_sum += torch.sum(torch.abs(spike - spike_class)).item() \n",
    "\n",
    "                    # spike = spike.squeeze()\n",
    "                    # spike_class = spike_class.squeeze()\n",
    "                    # plot_spike(spike[0].cpu().detach().numpy())\n",
    "                    # plot_spike(spike_class[0].cpu().detach().numpy())\n",
    "                    # print('손실 절대값 합',np.sum(np.abs(spike[0].cpu().detach().numpy() - spike_class[0].cpu().detach().numpy())))\n",
    "                    # # assert False\n",
    "                elif 'SAE' in net.module.__class__.__name__:\n",
    "                    criterion = nn.MSELoss().to(device)\n",
    "                    loss1 = criterion(spike_class[..., 5:25], spike[..., 5:25])\n",
    "                    loss2 = criterion(spike_class[..., 0:5], spike[..., 0:5])\n",
    "                    loss3 = criterion(spike_class[..., 25:spike_length], spike[..., 25:spike_length])\n",
    "                    loss = loss1 * 2.125 + (loss2 + loss3)/4\n",
    "                    assert spike_length > 25, 'spike_length가 25보다 작음'\n",
    "                    # wrong_element_sum += torch.sum(torch.abs(spike - spike_class)).item() \n",
    "                else:\n",
    "                    criterion = nn.MSELoss().to(device)\n",
    "                    loss1 = criterion(spike_class[..., 5:25], spike[..., 5:25])\n",
    "                    loss2 = criterion(spike_class[..., 0:5], spike[..., 0:5])\n",
    "                    loss3 = criterion(spike_class[..., 25:spike_length], spike[..., 25:spike_length])\n",
    "                    loss = loss1 * 2.125 + (loss2 + loss3)/4\n",
    "                    assert spike_length > 25, 'spike_length가 25보다 작음'\n",
    "                    # wrong_element_sum += torch.sum(torch.abs(spike - spike_class)).item() \n",
    "\n",
    "\n",
    "                    if l2_norm_loss_weight > 0:\n",
    "                        assert len(encoded_spike.shape) == 2, 'time 성분 없는 걸로'\n",
    "                        l2_loss = l2_norm_loss(encoded_spike, target_norm=1.0)  # L2Norm Loss 계산, l2 1.0되게.\n",
    "                        loss = loss + l2_loss*l2_norm_loss_weight\n",
    "                        l2_loss_bin += l2_loss.item()\n",
    "\n",
    "                    # coarse loss ######################################################\n",
    "                    loss_normal = criterion(spike_class, spike)\n",
    "                    level_num_in_loss = quantize_level_num\n",
    "                    level_interval = (coarse_com_config[0] - coarse_com_config[1]) / (level_num_in_loss-1)  # max - min\n",
    "                    levels = [coarse_com_config[1] + level_interval * i for i in range(level_num_in_loss)]\n",
    "                    levels = torch.tensor(levels).to(torch.float).to(device)\n",
    "                    levels = levels.repeat(spike_length,1) \n",
    "\n",
    "                    spike = spike.squeeze()\n",
    "                    spike_class = spike_class.squeeze()\n",
    "                    # plot_origin_spike(spike_class[0].cpu().detach().numpy())\n",
    "                    spike = spike.unsqueeze(2).repeat(1, 1, level_num_in_loss) \n",
    "                    spike = (spike > levels).to(torch.float) \n",
    "                    spike_class = spike_class.unsqueeze(2).repeat(1, 1, level_num_in_loss) \n",
    "                    spike_class = (spike_class > levels).to(torch.float) \n",
    "                    # spike = spike[..., 0:-3, :]\n",
    "                    # spike_class = spike_class[..., 0:-3, :]\n",
    "                    loss_coarse = criterion(spike_class, spike)\n",
    "                    wrong_element_sum += torch.sum(torch.abs(spike - spike_class)).item() \n",
    "\n",
    "                    # plot_spike(spike_class[0].cpu().detach().numpy())\n",
    "                    # assert False\n",
    "                    # coarse loss ######################################################\n",
    "\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                running_loss += loss.item()\n",
    "                running_loss_normal += loss_normal.item()\n",
    "                running_loss_coarse += loss_coarse.item()\n",
    "                # print(f'\\nepoch-{epoch}, running_loss : {running_loss:.5f}, iter percent {iter/len(train_loader)*100:.2f}%')\n",
    "                iter += 1\n",
    "        else:\n",
    "            print('\\n\\n\\n max_epoch 1이면 Train 안함!!!!!!!!!!!!!!!!!!!!!')\n",
    "        if l2_norm_loss_weight > 0:\n",
    "            print('l2_loss_bin', l2_loss_bin/len(train_loader))\n",
    "        avg_loss = running_loss / len(train_loader)\n",
    "        assert not np.isnan(avg_loss), f\"Error: avg_loss is NaN! Running loss: {running_loss}, Length of train_loader: {len(train_loader)}\"\n",
    "        loss_history.append((epoch, avg_loss))\n",
    "        min_loss = min(min_loss, avg_loss)\n",
    "        min_loss_normal = min(min_loss_normal, running_loss_normal/len(train_loader))\n",
    "        min_loss_coarse = min(min_loss_coarse, running_loss_coarse/len(train_loader))\n",
    "        print(f'\\nepoch-{epoch} loss : {avg_loss:.8f}, loss_normal : {running_loss_normal/len(train_loader):.8f}, loss_coarse : {running_loss_coarse/len(train_loader):.8f}, min_loss : {min_loss:.8f}, min_loss_normal : {min_loss_normal:.8f}, min_loss_coarse : {min_loss_coarse:.8f}, wrong_element_sum : {wrong_element_sum:.8f}, same_data : {100*same_data_num/(total_data_num+1e-12):.2f}%')\n",
    "        print(f\"ae train 실행 시간: {time.time()-ae_train_start_time:.3f}초, 전체 시작 시간 {current_time}\")\n",
    "\n",
    "        # plot_activation_distribution(net)\n",
    "\n",
    "        if SAE_net == False and converted_net_forward == True:\n",
    "            source_encoder = net.module.encoder \n",
    "            target_encoder = converted_net.module.encoder  \n",
    "            copy_weights(source_encoder, target_encoder)\n",
    "\n",
    "        cluster_accuracy_during_training_cycle_all_dataset = np.zeros(dataset_num)\n",
    "        cluster_accuracy_post_training_cycle_all_dataset = np.zeros(dataset_num)\n",
    "        cluster_accuracy_total_all_dataset = np.zeros(dataset_num)    \n",
    "\n",
    "        k_means_acc = 0\n",
    "        converted_k_means_acc = 0\n",
    "        if(epoch % accuracy_check_epoch_term == 0 or epoch == 1 or epoch == max_epoch-1): \n",
    "            accuracy_check_start_time = time.time()\n",
    "            print(f'\\nepoch-{epoch} accuracy check')\n",
    "            k_means_bin_origin_feature = []\n",
    "            k_means_bin = []\n",
    "            converted_k_means_bin = []\n",
    "            for ds in range(dataset_num):\n",
    "                # print('\\n', spike_tot[ds])\n",
    "\n",
    "                spike_template = np.load(my_path_ground_BH + template[ds])\n",
    "                spike = np.load(my_path_ground_BH + spike_tot[ds])\n",
    "                label = np.load(my_path_ground_BH + label_tot[ds])\n",
    "                spike_template = torch.from_numpy(spike_template).to(device)\n",
    "                spike = torch.from_numpy(spike).to(device)\n",
    "                scaling = (level_num-3)/level_num if conv1d_scaling else 1.0\n",
    "                spike_template = zero_to_one_normalize_features(spike_template, level_num=quantize_level_num, coarse_com_config=coarse_com_config, scaling=scaling, norm01=norm01) if normalize_on else spike_template\n",
    "                spike = zero_to_one_normalize_features(spike, level_num=quantize_level_num, coarse_com_config=coarse_com_config, scaling=scaling, norm01=norm01) if normalize_on else spike\n",
    "                \n",
    "                hidden_size = lateral_feature_num*TIME if 'SAE' in net.module.__class__.__name__ and SAE_hidden_nomean == True and fusion_net == False or 'SAE_FUSION5' in net.module.__class__.__name__ else lateral_feature_num\n",
    "                hidden_size = lateral_feature_num if '_DR' in net.module.__class__.__name__  else hidden_size\n",
    "\n",
    "                Cluster = np.zeros((num_cluster, hidden_size))\n",
    "                assert Cluster.shape[-1] == hidden_size, '이거 hidden dim 4 아니게 할 거면 잘 바꿔라'\n",
    "                \n",
    "\n",
    "\n",
    "                net.eval()\n",
    "                with torch.no_grad():\n",
    "                    spike_torch = spike_template.float()\n",
    "                    spike_torch = spike_torch[:num_cluster]\n",
    "                    spike_backup = spike_torch\n",
    "                    spike_torch = spike_torch.to(device)\n",
    "                    if coarse_com_mode == True and 'SAE' in net.module.__class__.__name__:\n",
    "                        spike_torch = spike_torch.unsqueeze(2).repeat(1, 1, level_num) # spike_length == level_num # (batch, time, feature)로 변환 \n",
    "                        spike_torch = (spike_torch > levels).to(torch.float) \n",
    "                        spike_torch = (spike_torch == 0).cumsum(dim=-1).eq(1).to(torch.float) if lc_adc_on == True else spike_torch\n",
    "                        if Conv_net == True:\n",
    "                            spike_torch = spike_torch.unsqueeze(-2) # batch, time, in_channel, feature or batch in_channel,feature\n",
    "                            if two_channel_input == True:\n",
    "                                spike_backup = spike_backup.to(device)\n",
    "                                spike_backup = spike_backup.unsqueeze(2).repeat(1, 1, level_num) # spike_length == level_num # (batch, time, feature)로 변환 \n",
    "                                spike_backup = (spike_backup <= levels).to(torch.float) \n",
    "                                spike_backup = (spike_backup == 1).cumsum(dim=-1).eq(1).to(torch.float) if lc_adc_on == True else spike_backup\n",
    "                                spike_backup = spike_backup.unsqueeze(-2) # batch, time, in_channel, feature\n",
    "                                spike_torch = torch.cat((spike_torch, spike_backup), dim=-2)\n",
    "                    elif 'SAE' in net.module.__class__.__name__:\n",
    "                        spike_torch = spike_torch.unsqueeze(1).repeat(1, TIME, 1) # (batch, time, feature)로 변환\n",
    "                        if Conv_net == True:\n",
    "                            spike_torch = spike_torch.unsqueeze(-2) # batch, time, in_channel, feature or batch in_channel,feature\n",
    "                    else:\n",
    "                        # if Conv_net == True:\n",
    "                        #     spike_torch = spike_torch.unsqueeze(-2) #batch in_channel,feature\n",
    "                        if Conv_net == True:\n",
    "                            if coarse_com_mode == False:\n",
    "                                spike_torch = spike_torch.unsqueeze(-2) #batch in_channel,feature\n",
    "                            else:\n",
    "                                spike_torch = spike_torch.unsqueeze(2).repeat(1, 1, level_num) # spike_length == level_num # (batch, time, feature)로 변환 \n",
    "                                spike_torch = (spike_torch > levels).to(torch.float) \n",
    "\n",
    "                                spike_torch = (spike_torch == 0).cumsum(dim=-1).eq(1).to(torch.float) if lc_adc_on == True else spike_torch\n",
    "\n",
    "                        else:\n",
    "                            if coarse_com_mode == False:\n",
    "                                pass\n",
    "                            else:\n",
    "                                spike_torch = spike_torch.unsqueeze(2).repeat(1, 1, level_num) # spike_length == level_num # (batch, time, feature)로 변환 \n",
    "                                spike_torch = (spike_torch > levels).to(torch.float) \n",
    "\n",
    "                                spike_torch = (spike_torch == 0).cumsum(dim=-1).eq(1).to(torch.float) if lc_adc_on == True else spike_torch\n",
    "\n",
    "                                # spike: batch, time, feature\n",
    "                                spike_torch = spike_torch.reshape(spike_torch.shape[0], -1)\n",
    "\n",
    "                        if converted_net_forward == True:\n",
    "                            spike_torch_spikegen = spikegen.rate(spike_torch, num_steps=TIME).transpose(0, 1)\n",
    "                        # if fusion_net == True:\n",
    "                        #     spike_torch = spikegen.rate(spike_torch, num_steps=TIME).transpose(0, 1)\n",
    "                    ### forward #######################################################\n",
    "                    inner_inf = net.module.encoder(spike_torch)\n",
    "                    if SAE_net == False and converted_net_forward == True:\n",
    "                        converted_inner_inf = converted_net.module.encoder(spike_torch_spikegen)\n",
    "                    ### forward #######################################################\n",
    "\n",
    "                    # if ds % 4 == 0:\n",
    "                    #     for i in range(4):\n",
    "                    #         decoded = net.module.decoder(inner_inf).squeeze()\n",
    "                    #         plot_spike(spike_torch[i,:,:].cpu().numpy())\n",
    "                    #         plot_spike(inner_inf[i,:].cpu().numpy())\n",
    "                    #         # plot_origin_spike(net.module.decoder(inner_inf)[i,:].cpu().numpy())\n",
    "                    #         plot_origin_spike(decoded[i].cpu().numpy(), min_max_y_on = True)\n",
    "                        \n",
    "                    # if 'SAE' in net.module.__class__.__name__:\n",
    "                    #     tensors = [inner_inf[0][i] for i in range(TIME)] \n",
    "                    #     all_equal = all(torch.equal(tensors[0], t) for t in tensors)\n",
    "                    #     print(all_equal, inner_inf)\n",
    "\n",
    "                    if 'SAE' in net.module.__class__.__name__:\n",
    "                        if SAE_hidden_nomean == True:\n",
    "                            inner_inf = inner_inf.reshape(inner_inf.shape[0],-1)# time*feature 펼치기\n",
    "                        else:\n",
    "                            inner_inf = inner_inf.mean(dim=1)# Time 방향으로 평균\n",
    "                        # inner_inf = F.normalize(inner_inf, p=2, dim=1)\n",
    "                    Cluster = inner_inf.cpu().detach().numpy()\n",
    "\n",
    "                encoder_batch = 128\n",
    "                spike_hidden = np.zeros((len(spike), hidden_size))\n",
    "                converted_spike_hidden = np.zeros((len(spike), hidden_size))\n",
    "                net.eval()\n",
    "                with torch.no_grad():\n",
    "                    now_index = 0\n",
    "                    while (1):\n",
    "                        now_end_index = now_index+encoder_batch if now_index+encoder_batch < len(spike) else len(spike)\n",
    "                        spike_batch = spike[now_index:now_end_index] \n",
    "                        spike_torch = spike_batch\n",
    "                        spike_torch = spike_torch.float()\n",
    "                        spike_backup = spike_torch\n",
    "                        spike_torch = spike_torch.to(device)\n",
    "                        if coarse_com_mode == True and 'SAE' in net.module.__class__.__name__:\n",
    "                            spike_torch = spike_torch.unsqueeze(2).repeat(1, 1, level_num) # spike_length == level_num # (batch, time, feature)로 변환 \n",
    "                            spike_torch = (spike_torch > levels).to(torch.float) \n",
    "                            spike_torch = (spike_torch == 0).cumsum(dim=-1).eq(1).to(torch.float) if lc_adc_on == True else spike_torch\n",
    "                            if Conv_net == True:\n",
    "                                spike_torch = spike_torch.unsqueeze(-2) # batch, time, in_channel, feature or batch in_channel,feature\n",
    "                                if two_channel_input == True:\n",
    "                                    spike_backup = spike_backup.to(device)\n",
    "                                    spike_backup = spike_backup.unsqueeze(2).repeat(1, 1, level_num) # spike_length == level_num # (batch, time, feature)로 변환 \n",
    "                                    spike_backup = (spike_backup <= levels).to(torch.float) \n",
    "                                    spike_backup = (spike_backup == 1).cumsum(dim=-1).eq(1).to(torch.float) if lc_adc_on == True else spike_backup\n",
    "                                    spike_backup = spike_backup.unsqueeze(-2)\n",
    "                                    spike_torch = torch.cat((spike_torch, spike_backup), dim=-2)\n",
    "                        elif 'SAE' in net.module.__class__.__name__:\n",
    "                            spike_torch = spike_torch.unsqueeze(1).repeat(1, TIME, 1) # (batch, time, feature)로 변환\n",
    "                            if Conv_net == True:\n",
    "                                spike_torch = spike_torch.unsqueeze(-2) # batch, time, in_channel, feature or batch in_channel,feature\n",
    "                        else:\n",
    "                            # if Conv_net == True:\n",
    "                            #     spike_torch = spike_torch.unsqueeze(-2) #batch in_channel,feature\n",
    "                            if Conv_net == True:\n",
    "                                if coarse_com_mode == False:\n",
    "                                    spike_torch = spike_torch.unsqueeze(-2) #batch in_channel,feature\n",
    "                                else:\n",
    "                                    spike_torch = spike_torch.unsqueeze(2).repeat(1, 1, level_num) # spike_length == level_num # (batch, time, feature)로 변환 \n",
    "                                    spike_torch = (spike_torch > levels).to(torch.float) \n",
    "\n",
    "                                    spike_torch = (spike_torch == 0).cumsum(dim=-1).eq(1).to(torch.float) if lc_adc_on == True else spike_torch\n",
    "\n",
    "                            else:\n",
    "                                if coarse_com_mode == False:\n",
    "                                    pass\n",
    "                                else:\n",
    "                                    spike_torch = spike_torch.unsqueeze(2).repeat(1, 1, level_num) # spike_length == level_num # (batch, time, feature)로 변환 \n",
    "                                    spike_torch = (spike_torch > levels).to(torch.float) \n",
    "\n",
    "                                    spike_torch = (spike_torch == 0).cumsum(dim=-1).eq(1).to(torch.float) if lc_adc_on == True else spike_torch\n",
    "\n",
    "                                    # spike: batch, time, feature\n",
    "                                    spike_torch = spike_torch.reshape(spike_torch.shape[0], -1)\n",
    "                            if converted_net_forward == True:\n",
    "                                spike_torch_spikegen = spikegen.rate(spike_torch, num_steps=TIME).transpose(0, 1)\n",
    "                            # if fusion_net == True:\n",
    "                            #     spike_torch = spikegen.rate(spike_torch, num_steps=TIME).transpose(0, 1)\n",
    "                        ### forward #######################################################\n",
    "                        inner_inf = net.module.encoder(spike_torch)\n",
    "                        if SAE_net == False and converted_net_forward == True:\n",
    "                            converted_inner_inf = converted_net.module.encoder(spike_torch_spikegen)\n",
    "                        ### forward #######################################################\n",
    "                            \n",
    "                        if 'SAE' in net.module.__class__.__name__:\n",
    "                            if SAE_hidden_nomean == True:\n",
    "                                inner_inf = inner_inf.reshape(spike_batch.shape[0],-1)# 펼치기\n",
    "                            else:\n",
    "                                inner_inf = inner_inf.mean(dim=1)# Time 방향으로 평균\n",
    "                            # inner_inf = F.normalize(inner_inf, p=2, dim=1)\n",
    "                        spike_hidden[now_index:now_end_index] = inner_inf.cpu().detach().numpy()\n",
    "                        if SAE_net == False and converted_net_forward == True:\n",
    "                            converted_spike_hidden[now_index:now_end_index] = converted_inner_inf.cpu().detach().numpy()\n",
    "                        now_index += encoder_batch\n",
    "                        if (now_index >= len(spike)):\n",
    "                            break\n",
    "                    \n",
    "                spike_id = np.zeros(len(spike))\n",
    "                distance_sm = np.zeros(num_cluster)\n",
    "                tau = np.zeros(num_cluster)\n",
    "                \n",
    "                plot_tau = []\n",
    "                plot_denominator = []\n",
    "                plot_m = []\n",
    "                plot_max_tau = []\n",
    "                for spike_index in range(len(spike)): \n",
    "                    for q in range(num_cluster):\n",
    "                        tau[q] = np.dot(spike_hidden[spike_index, :], Cluster[q, :]) # 이거 l2norm 거쳐서 나온 거니까 분모 1임.\n",
    "                        denominator =  np.linalg.norm(spike_hidden[spike_index, :])*np.linalg.norm(Cluster[q, :]) + 1e-12\n",
    "                        plot_denominator.append(denominator)\n",
    "                        if 'SAE' in net.module.__class__.__name__: # AE 때는 l2norm거쳐서 나와서 괜찮음\n",
    "                            tau[q] = tau[q] / denominator\n",
    "\n",
    "                        plot_tau.append(tau[q])\n",
    "\n",
    "                    # for i in range(num_cluster): # l2 distance\n",
    "                    #     distance_sm[i] = np.sum(np.power(np.abs(Cluster[i] - spike_hidden[spike_index, :]), 2))\n",
    "                    distance_sm = np.sum(np.power(np.abs(Cluster - spike_hidden[spike_index, :]), 2), axis=1)\n",
    "\n",
    "                    m = np.argmin(distance_sm)\n",
    "                    plot_m.append(m)\n",
    "                    spike_id[spike_index] = m + 1\n",
    "                    # print(spike_tot[ds], spike_index,np.max(tau))\n",
    "                    plot_max_tau.append(np.max(tau))\n",
    "                    if(np.max(tau) >= cos_thr[ds] and spike_index < training_cycle): # 원래 1400 아니냐?\n",
    "                        Cluster[m] = (Cluster[m] * 15 + spike_hidden[spike_index, :])/16\n",
    "\n",
    "\n",
    "                \n",
    "                origin_kmeans_accuracy = cluster_spikes_with_accuracy_torch(features= spike, true_labels=label-1, n_clusters=3, init_point=None)\n",
    "                kmeans_accuracy = cluster_spikes_with_accuracy_torch(features= torch.tensor(spike_hidden).to(device), true_labels=label-1, n_clusters=3, init_point=None)\n",
    "                \n",
    "                # print('temporoal k')\n",
    "                # result = evaluate_clustering_accuracy(spike_hidden.reshape(spike_hidden.shape[0], TIME, -1), label-1, n_clusters=3)\n",
    "                # print('원래', kmeans_accuracy)\n",
    "                # print(result)\n",
    "\n",
    "                k_means_bin_origin_feature.append(origin_kmeans_accuracy)\n",
    "                k_means_bin.append(kmeans_accuracy)\n",
    "                if SAE_net == False and converted_net_forward == True:\n",
    "                    converted_kmeans_accuracy = cluster_spikes_with_accuracy_torch(features= torch.tensor(converted_spike_hidden).to(device), true_labels=label-1, n_clusters=3, init_point=None)\n",
    "                    converted_k_means_bin.append(converted_kmeans_accuracy)\n",
    "                # sklearn kmeans인데 cpu많이먹어서 버림.\n",
    "                # origin_kmeans_accuracy = cluster_spikes_with_accuracy(features= spike.cpu().detach().numpy(), true_labels=label-1, n_clusters=3, init_point=None)\n",
    "                # kmeans_accuracy = cluster_spikes_with_accuracy(features= spike_hidden, true_labels=label-1, n_clusters=3, init_point=None)\n",
    "                # k_means_bin_origin_feature.append(origin_kmeans_accuracy)\n",
    "                # k_means_bin.append(kmeans_accuracy)\n",
    "                # if SAE_net == False and converted_net_forward == True:\n",
    "                #     converted_kmeans_accuracy = cluster_spikes_with_accuracy(features= converted_spike_hidden, true_labels=label-1, n_clusters=3, init_point=None)\n",
    "                #     converted_k_means_bin.append(converted_kmeans_accuracy)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "                # print('Cluster',Cluster)\n",
    "                # print('spike_id', spike_id)\n",
    "\n",
    "                # spike id 분포 확인하기\n",
    "                # unique_elements, counts = np.unique(spike_id, return_counts=True)\n",
    "                # print(\"Unique elements:\", unique_elements)\n",
    "                # print(\"Counts:\", counts)\n",
    "\n",
    "                cluster_accuracy_during_training_cycle = np.zeros(math.factorial(num_cluster))\n",
    "                cluster_accuracy_post_training_cycle = np.zeros(math.factorial(num_cluster))\n",
    "                cluster_accuracy_total = np.zeros(math.factorial(num_cluster))\n",
    "                \n",
    "                label_converter_ground = list(range(1, num_cluster + 1)) # [1, 2, 3, 4] 생성\n",
    "                label_converter_permutations = list(itertools.permutations(label_converter_ground)) # 모든 순열 구하기\n",
    "                perm_i = 0\n",
    "                perm_start_time = time.time() \n",
    "                for perm in label_converter_permutations:\n",
    "                    label_converter = list(perm)\n",
    "                    # print(label_converter)\n",
    "                    correct_during_training_cycle = 0\n",
    "                    correct_post_training_cycle = 0\n",
    "\n",
    "                    assert len(spike_id) == len(label), 'spike_id랑 label 길이 같아야 됨.'\n",
    "                    for i in range(len(spike_id)):\n",
    "                        if(label_converter[int(spike_id[i]-1)] == label[i]):\n",
    "                            if i < training_cycle:\n",
    "                                correct_during_training_cycle += 1\n",
    "                            else:\n",
    "                                correct_post_training_cycle += 1\n",
    "\n",
    "                    cluster_accuracy_during_training_cycle[perm_i] = correct_during_training_cycle/training_cycle\n",
    "                    cluster_accuracy_post_training_cycle[perm_i] = correct_post_training_cycle/(len(spike_id)-training_cycle)\n",
    "                    cluster_accuracy_total[perm_i] = (correct_during_training_cycle+correct_post_training_cycle)/(len(spike_id))\n",
    "                    perm_i += 1\n",
    "                # print(f\"perm 실행 시간: {time.time()-perm_start_time:.3f}초\")\n",
    "                \n",
    "                cluster_accuracy_during_training_cycle_all_dataset[ds] = np.max(cluster_accuracy_during_training_cycle)\n",
    "                cluster_accuracy_post_training_cycle_all_dataset[ds] = cluster_accuracy_post_training_cycle[np.argmax(cluster_accuracy_during_training_cycle)]\n",
    "                cluster_accuracy_total_all_dataset[ds] = cluster_accuracy_total[np.argmax(cluster_accuracy_during_training_cycle)]\n",
    "                # plot_distributions(ds, plot_tau, plot_denominator, plot_m, plot_max_tau, cos_thr[ds],\n",
    "                #                    cluster_accuracy_during_training_cycle_all_dataset[ds], cluster_accuracy_post_training_cycle_all_dataset[ds], cluster_accuracy_total_all_dataset[ds])\n",
    "            print(f'k_means origin feature average accuracy : {100*sum(k_means_bin_origin_feature)/(len(k_means_bin_origin_feature)+1e-12):.8f}%, total {k_means_bin_origin_feature}')\n",
    "            \n",
    "            mean_cluster_accuracy_during_training_cycle_all_dataset = np.mean(cluster_accuracy_during_training_cycle_all_dataset)\n",
    "            mean_cluster_accuracy_post_training_cycle_all_dataset = np.mean(cluster_accuracy_post_training_cycle_all_dataset)\n",
    "            mean_cluster_accuracy_total_all_dataset = np.mean(cluster_accuracy_total_all_dataset)\n",
    "            \n",
    "            if SAE_net == False and converted_net_forward == True:\n",
    "                converted_k_means_acc = 100*sum(converted_k_means_bin)/len(converted_k_means_bin)\n",
    "                print(f'converted_kmeans average accuracy : {converted_k_means_acc:.8f}%, total {converted_k_means_bin}')\n",
    "            k_means_acc = 100*sum(k_means_bin)/len(k_means_bin)\n",
    "            if k_means_acc > k_means_acc_best:\n",
    "                # torch.save(net, f\"net_save/save_now_net_{current_time}.pth\")\n",
    "                torch.save(net.module.state_dict(), f\"net_save/save_now_net_{current_time}.pth\")\n",
    "                print('save model')\n",
    "                best_mean_cluster_accuracy_post_training_cycle_all_dataset = mean_cluster_accuracy_post_training_cycle_all_dataset\n",
    "            \n",
    "            k_means_acc_best = max(k_means_acc_best, k_means_acc)\n",
    "            print(f'kmeans average accuracy best : {k_means_acc_best:.2f}%, kmeans average accuracy : {k_means_acc:.8f}%, total {k_means_bin}')\n",
    "            print(f'cluster_accuracy_post_training_cycle_all_dataset : {cluster_accuracy_post_training_cycle_all_dataset}')\n",
    "\n",
    "            \n",
    "            mean_cluster_accuracy_during_training_cycle_all_dataset_history.append((epoch, mean_cluster_accuracy_during_training_cycle_all_dataset*100))\n",
    "            mean_cluster_accuracy_post_training_cycle_all_dataset_history.append((epoch, mean_cluster_accuracy_post_training_cycle_all_dataset*100))\n",
    "            mean_cluster_accuracy_total_all_dataset_history.append((epoch, mean_cluster_accuracy_total_all_dataset*100))\n",
    "            print(f\"mean_cluster_accuracy_during_training_cycle : {mean_cluster_accuracy_during_training_cycle_all_dataset*100:.2f}%, post_traincycle_acc : {mean_cluster_accuracy_post_training_cycle_all_dataset*100:.2f}%, total_acc : {mean_cluster_accuracy_total_all_dataset*100:.8f}%\")\n",
    "\n",
    "            # kmeans accuracy기준으로 좋은 거 저장할 거임\n",
    "            # if mean_cluster_accuracy_post_training_cycle_all_dataset > best_mean_cluster_accuracy_post_training_cycle_all_dataset:\n",
    "            #     # torch.save(net, f\"net_save/save_now_net_{current_time}.pth\")\n",
    "            #     torch.save(net.module.state_dict(), f\"net_save/save_now_net_{current_time}.pth\")\n",
    "            #     print('save model')\n",
    "            #     best_mean_cluster_accuracy_post_training_cycle_all_dataset = mean_cluster_accuracy_post_training_cycle_all_dataset\n",
    "            print(f\"best_mean_cluster_accuracy_post_training_cycle_all_dataset : {best_mean_cluster_accuracy_post_training_cycle_all_dataset*100:.2f}%\")\n",
    "            print(f\"accuracy_check 실행 시간: {time.time()-accuracy_check_start_time:.3f}초\")\n",
    "\n",
    "        wandb.log({\"avg_loss\": avg_loss})\n",
    "        wandb.log({\"mean_cluster_accuracy_post_training_cycle_all_dataset\": mean_cluster_accuracy_post_training_cycle_all_dataset})\n",
    "        wandb.log({\"best_mean_cluster_accuracy_post_training_cycle_all_dataset\": best_mean_cluster_accuracy_post_training_cycle_all_dataset})\n",
    "        wandb.log({\"best_mean_cluster_accuracy_post_training_cycle_all_dataset2\": best_mean_cluster_accuracy_post_training_cycle_all_dataset})\n",
    "        wandb.log({\"k_means_acc\": k_means_acc})\n",
    "        wandb.log({\"k_means_acc_best\": k_means_acc_best})\n",
    "        wandb.log({\"converted_k_means_acc\": converted_k_means_acc})\n",
    "\n",
    "\n",
    "        # 저장\n",
    "        with open(f\"result_save/cluster_accuracy_history_{current_time}.pkl\", \"wb\") as f:\n",
    "            pickle.dump({\n",
    "                \"loss_history\": loss_history,\n",
    "                \"mean_cluster_accuracy_during_training_cycle_all_dataset_history\": mean_cluster_accuracy_during_training_cycle_all_dataset_history,\n",
    "                \"mean_cluster_accuracy_post_training_cycle_all_dataset_history\": mean_cluster_accuracy_post_training_cycle_all_dataset_history,\n",
    "                \"mean_cluster_accuracy_total_all_dataset_history\": mean_cluster_accuracy_total_all_dataset_history,\n",
    "            }, f)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mbhkim003\u001b[0m (\u001b[33mbhkim003-seoul-national-university\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.19.8 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.17.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/nfs/home/bhkim003/github_folder/ByeonghyeonKim/my_snn/wandb/run-20250312_165253-x42wsdmc</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/bhkim003-seoul-national-university/spike_sorting%20just%20run/runs/x42wsdmc' target=\"_blank\">expert-sea-1435</a></strong> to <a href='https://wandb.ai/bhkim003-seoul-national-university/spike_sorting%20just%20run' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/bhkim003-seoul-national-university/spike_sorting%20just%20run' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/spike_sorting%20just%20run</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/bhkim003-seoul-national-university/spike_sorting%20just%20run/runs/x42wsdmc' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/spike_sorting%20just%20run/runs/x42wsdmc</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'gpu': '2', 'Conv_net': True, 'SAE_net': True, 'dataset_num': 16, 'spike_length': 50, 'num_cluster': 4, 'training_cycle': 1400, 'batch_size': 32, 'max_epoch': 10000, 'learning_rate': 0.001, 'normalize_on': True, 'need_bias': False, 'lif_add_at_first': False, 'my_seed': 42, 'TIME': 50, 'v_decay': 0.5, 'v_threshold': 0.25, 'v_reset': 0.0, 'BPTT_on': True, 'SAE_hidden_nomean': True, 'current_time': '20250312_165249_979', 'optimizer': 'Adam', 'coarse_com_mode': True, 'sae_l2_norm_bridge': True, 'sae_lif_bridge': False, 'accuracy_check_epoch_term': 1, 'lif_add_at_last': False, 'two_channel_input': False, 'lateral_feature_num': 3, 'lc_adc_on': False, 'converted_net_forward': False, 'pretrained_net': None, 'vth_mul_on': False, 'batch_norm_on': False, 'l2_norm_loss_weight': 0, 'QCFS_neuron_on': False, 'quantize_level_num': 0, 'fusion_net': True, 'repeat_coding': False, 'sae_relu_on': False, 'conv1d_scaling': False, 'norm01': True, 'coarse_com_config': (0.999, -0.0)}\n",
      "cos_thr [0.95 0.95 0.95 0.95 0.95 0.95 0.95 0.85 0.95 0.9  0.8  0.95 0.95 0.95\n",
      " 0.95 0.8 ]\n",
      "conv length [50, 24, 11, 5]\n",
      "Total number of encoder parameters: 26262\n",
      "DataParallel(\n",
      "  (module): SAE_FUSION6_net_conv1(\n",
      "    (activation_function): LIF_layer()\n",
      "    (encoder): Sequential(\n",
      "      (0): SSBH_DimChanger_one_two()\n",
      "      (1): SSBH_DimChanger_for_one_two_coupling()\n",
      "      (2): Conv1d(1, 32, kernel_size=(3,), stride=(2,), bias=False)\n",
      "      (3): SSBH_DimChanger_for_one_two_decoupling()\n",
      "      (4): LIF_layer()\n",
      "      (5): SSBH_DimChanger_for_one_two_coupling()\n",
      "      (6): Conv1d(32, 64, kernel_size=(3,), stride=(2,), bias=False)\n",
      "      (7): SSBH_DimChanger_for_one_two_decoupling()\n",
      "      (8): LIF_layer()\n",
      "      (9): SSBH_DimChanger_for_one_two_coupling()\n",
      "      (10): Conv1d(64, 96, kernel_size=(3,), stride=(2,), bias=False)\n",
      "      (11): SSBH_DimChanger_for_one_two_decoupling()\n",
      "      (12): LIF_layer()\n",
      "      (13): SSBH_DimChanger_for_one_two_coupling()\n",
      "      (14): SSBH_DimChanger_for_fc()\n",
      "      (15): Linear(in_features=480, out_features=3, bias=False)\n",
      "      (16): SSBH_DimChanger_for_one_two_decoupling()\n",
      "      (17): LIF_layer()\n",
      "      (18): SSBH_DimChanger_one_two()\n",
      "      (19): SSBH_MultiLinearLayer(\n",
      "        (linears): ModuleList(\n",
      "          (0): Linear(in_features=50, out_features=1, bias=False)\n",
      "          (1): Linear(in_features=50, out_features=1, bias=False)\n",
      "          (2): Linear(in_features=50, out_features=1, bias=False)\n",
      "        )\n",
      "      )\n",
      "      (20): SSBH_L2NormLayer()\n",
      "    )\n",
      "    (decoder): Sequential(\n",
      "      (0): Linear(in_features=3, out_features=480, bias=False)\n",
      "      (1): ReLU()\n",
      "      (2): SSBH_DimChanger_for_conv1()\n",
      "      (3): ConvTranspose1d(96, 64, kernel_size=(3,), stride=(2,), bias=False)\n",
      "      (4): ReLU()\n",
      "      (5): ConvTranspose1d(64, 32, kernel_size=(3,), stride=(2,), output_padding=(1,), bias=False)\n",
      "      (6): ReLU()\n",
      "      (7): ConvTranspose1d(32, 1, kernel_size=(3,), stride=(2,), output_padding=(1,), bias=False)\n",
      "    )\n",
      "  )\n",
      ")\n",
      "Device: cuda\n",
      "\n",
      "Start Training, current_time = 20250312_165249_979\n",
      "\n",
      "\n",
      "epoch-0 loss : 0.05106879, loss_normal : 0.02624696, loss_coarse : 0.10927076, min_loss : 0.05106879, min_loss_normal : 0.02624696, min_loss_coarse : 0.10927076, wrong_element_sum : 20979986.00000000, same_data : 0.00%\n",
      "ae train 실행 시간: 120.660초, 전체 시작 시간 20250312_165249_979\n",
      "\n",
      "epoch-0 accuracy check\n",
      "k_means origin feature average accuracy : 82.24418027%, total [0.9746727376209448, 0.9733106189664963, 0.9700891573195284, 0.9530800230282096, 0.943108504398827, 0.9150568181818182, 0.801817648783348, 0.6625070901871809, 0.9488619568430388, 0.8216357308584686, 0.5866935483870968, 0.5005858230814294, 0.942627824019025, 0.8922588099364529, 0.6747093023255814, 0.5980532493558546]\n",
      "save model\n",
      "kmeans average accuracy best : 79.19%, kmeans average accuracy : 79.19146909%, total [0.9715424018212863, 0.9727427597955707, 0.9686511360368133, 0.9533678756476683, 0.9483870967741935, 0.8627840909090909, 0.7490472002345353, 0.632161089052751, 0.7901271061188294, 0.6969257540603249, 0.6347926267281107, 0.5913884007029877, 0.8418549346016647, 0.7533217793183131, 0.6843023255813954, 0.6192384769539078]\n",
      "cluster_accuracy_post_training_cycle_all_dataset : [0.97398297 0.9736098  0.96918633 0.95419479 0.94925373 0.85849057\n",
      " 0.7339632  0.58560677 0.79425113 0.70556641 0.61341699 0.50397219\n",
      " 0.84775967 0.75897187 0.67941176 0.59675108]\n",
      "mean_cluster_accuracy_during_training_cycle : 77.66%, post_traincycle_acc : 78.11%, total_acc : 77.92643049%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 78.11%\n",
      "accuracy_check 실행 시간: 31.502초\n",
      "\n",
      "\n",
      "epoch-1 loss : 0.02543979, loss_normal : 0.01834876, loss_coarse : 0.08747912, min_loss : 0.02543979, min_loss_normal : 0.01834876, min_loss_coarse : 0.08747912, wrong_element_sum : 16795992.00000000, same_data : 0.00%\n",
      "ae train 실행 시간: 120.733초, 전체 시작 시간 20250312_165249_979\n",
      "\n",
      "epoch-1 accuracy check\n",
      "k_means origin feature average accuracy : 82.25682366%, total [0.9746727376209448, 0.9733106189664963, 0.9700891573195284, 0.9530800230282096, 0.943108504398827, 0.915340909090909, 0.801817648783348, 0.6622234826999432, 0.9488619568430388, 0.822215777262181, 0.5866935483870968, 0.5005858230814294, 0.9429250891795482, 0.8922588099364529, 0.6747093023255814, 0.5991983967935872]\n",
      "kmeans average accuracy best : 79.19%, kmeans average accuracy : 78.94844063%, total [0.9692657939669892, 0.9699034639409426, 0.9634742594190394, 0.941565918249856, 0.9090909090909091, 0.8042613636363637, 0.6437994722955145, 0.5955757231990925, 0.7963346142477091, 0.7784222737819025, 0.7044930875576036, 0.6432337434094904, 0.8766349583828775, 0.7781629116117851, 0.6709302325581395, 0.5866017749785285]\n",
      "cluster_accuracy_post_training_cycle_all_dataset : [0.97209082 0.97172479 0.96437169 0.94165863 0.9039801  0.80707547\n",
      " 0.65987071 0.58043274 0.80383258 0.73925781 0.70801158 0.64548163\n",
      " 0.8808554  0.79243453 0.66519608 0.6043956 ]\n",
      "mean_cluster_accuracy_during_training_cycle : 77.54%, post_traincycle_acc : 79.00%, total_acc : 78.40966098%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 78.11%\n",
      "accuracy_check 실행 시간: 30.817초\n",
      "\n",
      "\n",
      "epoch-2 loss : 0.02349405, loss_normal : 0.01807250, loss_coarse : 0.08602670, min_loss : 0.02349405, min_loss_normal : 0.01807250, min_loss_coarse : 0.08602670, wrong_element_sum : 16517126.00000000, same_data : 0.00%\n",
      "ae train 실행 시간: 111.794초, 전체 시작 시간 20250312_165249_979\n",
      "\n",
      "epoch-2 accuracy check\n",
      "k_means origin feature average accuracy : 82.26033817%, total [0.9746727376209448, 0.9733106189664963, 0.9700891573195284, 0.9530800230282096, 0.943108504398827, 0.9150568181818182, 0.801817648783348, 0.6625070901871809, 0.9488619568430388, 0.822215777262181, 0.5872695852534562, 0.5005858230814294, 0.9429250891795482, 0.8922588099364529, 0.6738372093023256, 0.6000572573718866]\n",
      "save model\n",
      "kmeans average accuracy best : 82.17%, kmeans average accuracy : 82.17359606%, total [0.9706886738759248, 0.9738784781374219, 0.9683635317802703, 0.9562464018422567, 0.956891495601173, 0.9167613636363636, 0.7742597478745236, 0.6395348837209303, 0.8796925805498078, 0.7868329466357309, 0.6875, 0.6531927357937902, 0.89179548156956, 0.8073367995378394, 0.6944767441860465, 0.5903235041511594]\n",
      "cluster_accuracy_post_training_cycle_all_dataset : [0.97161779 0.97455231 0.97014925 0.95853423 0.95522388 0.92358491\n",
      " 0.77125808 0.50893697 0.86838124 0.78759766 0.66747104 0.64746773\n",
      " 0.89154786 0.75848691 0.6872549  0.58289537]\n",
      "mean_cluster_accuracy_during_training_cycle : 81.77%, post_traincycle_acc : 80.78%, total_acc : 81.17817581%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 80.78%\n",
      "accuracy_check 실행 시간: 24.693초\n",
      "\n",
      "\n",
      "epoch-3 loss : 0.02261675, loss_normal : 0.01800987, loss_coarse : 0.08549813, min_loss : 0.02261675, min_loss_normal : 0.01800987, min_loss_coarse : 0.08549813, wrong_element_sum : 16415642.00000000, same_data : 0.00%\n",
      "ae train 실행 시간: 121.022초, 전체 시작 시간 20250312_165249_979\n",
      "\n",
      "epoch-3 accuracy check\n",
      "k_means origin feature average accuracy : 82.26401620%, total [0.9746727376209448, 0.9733106189664963, 0.9700891573195284, 0.9530800230282096, 0.943108504398827, 0.9150568181818182, 0.801817648783348, 0.6622234826999432, 0.9488619568430388, 0.822215777262181, 0.5872695852534562, 0.5005858230814294, 0.9429250891795482, 0.8922588099364529, 0.6747093023255814, 0.6000572573718866]\n",
      "save model\n",
      "kmeans average accuracy best : 84.52%, kmeans average accuracy : 84.52204273%, total [0.9712578258394992, 0.9750141964792731, 0.9695139488064424, 0.957685664939551, 0.9565982404692082, 0.9198863636363637, 0.830841395485195, 0.7733976176971072, 0.9054093999408809, 0.8567285382830626, 0.7525921658986175, 0.6652021089630932, 0.8953626634958383, 0.7836510687463893, 0.701453488372093, 0.6089321500143143]\n",
      "cluster_accuracy_post_training_cycle_all_dataset : [0.97209082 0.97596607 0.97207511 0.95949855 0.95671642 0.91839623\n",
      " 0.83988066 0.64675447 0.90015129 0.83496094 0.73552124 0.69314796\n",
      " 0.89714868 0.78419011 0.70784314 0.60869565]\n",
      "mean_cluster_accuracy_during_training_cycle : 84.05%, post_traincycle_acc : 83.77%, total_acc : 83.87910607%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 83.77%\n",
      "accuracy_check 실행 시간: 31.985초\n",
      "\n",
      "\n",
      "epoch-4 loss : 0.02199596, loss_normal : 0.01794925, loss_coarse : 0.08495112, min_loss : 0.02199596, min_loss_normal : 0.01794925, min_loss_coarse : 0.08495112, wrong_element_sum : 16310616.00000000, same_data : 0.00%\n",
      "ae train 실행 시간: 121.345초, 전체 시작 시간 20250312_165249_979\n",
      "\n",
      "epoch-4 accuracy check\n",
      "k_means origin feature average accuracy : 82.25680519%, total [0.9746727376209448, 0.9733106189664963, 0.9700891573195284, 0.9530800230282096, 0.943108504398827, 0.9150568181818182, 0.8015244796247435, 0.6625070901871809, 0.9488619568430388, 0.822215777262181, 0.5866935483870968, 0.5005858230814294, 0.9429250891795482, 0.8922588099364529, 0.675, 0.5991983967935872]\n",
      "kmeans average accuracy best : 84.52%, kmeans average accuracy : 83.83783236%, total [0.9735344336937962, 0.975298126064736, 0.9700891573195284, 0.9602763385146805, 0.9586510263929618, 0.928125, 0.8748167692758722, 0.8006239364719229, 0.8941767661838604, 0.7534802784222738, 0.6797235023041475, 0.650556531927358, 0.8974435196195006, 0.8110918544194108, 0.7090116279069767, 0.5771543086172345]\n",
      "cluster_accuracy_post_training_cycle_all_dataset : [0.97587512 0.97596607 0.97207511 0.96287367 0.95920398 0.91698113\n",
      " 0.85181502 0.5639699  0.79576399 0.74511719 0.66361004 0.66434955\n",
      " 0.90173116 0.79243453 0.61862745 0.56330626]\n",
      "mean_cluster_accuracy_during_training_cycle : 82.08%, post_traincycle_acc : 80.77%, total_acc : 81.29538109%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 83.77%\n",
      "accuracy_check 실행 시간: 32.455초\n",
      "\n",
      "\n",
      "epoch-5 loss : 0.02179450, loss_normal : 0.01795110, loss_coarse : 0.08481911, min_loss : 0.02179450, min_loss_normal : 0.01794925, min_loss_coarse : 0.08481911, wrong_element_sum : 16285270.00000000, same_data : 0.00%\n",
      "ae train 실행 시간: 120.639초, 전체 시작 시간 20250312_165249_979\n",
      "\n",
      "epoch-5 accuracy check\n",
      "k_means origin feature average accuracy : 82.25503135%, total [0.9746727376209448, 0.9733106189664963, 0.9700891573195284, 0.9530800230282096, 0.943108504398827, 0.9150568181818182, 0.801817648783348, 0.6625070901871809, 0.9488619568430388, 0.822215777262181, 0.5866935483870968, 0.5005858230814294, 0.9429250891795482, 0.8922588099364529, 0.6747093023255814, 0.598912109934154]\n",
      "kmeans average accuracy best : 84.52%, kmeans average accuracy : 82.35125988%, total [0.9715424018212863, 0.9733106189664963, 0.9709519700891573, 0.9562464018422567, 0.9586510263929618, 0.9215909090909091, 0.8135444151275286, 0.7439024390243902, 0.8261897723913686, 0.7781322505800464, 0.6941244239631337, 0.6022261277094317, 0.9075505350772889, 0.829000577700751, 0.6552325581395348, 0.5740051531634698]\n",
      "cluster_accuracy_post_training_cycle_all_dataset : [0.97256386 0.97313855 0.97255657 0.95901639 0.95721393 0.92264151\n",
      " 0.82943809 0.63029163 0.81240545 0.76318359 0.67905405 0.60873883\n",
      " 0.8589613  0.78661494 0.63088235 0.56617296]\n",
      "mean_cluster_accuracy_during_training_cycle : 81.99%, post_traincycle_acc : 80.77%, total_acc : 81.25647375%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 83.77%\n",
      "accuracy_check 실행 시간: 34.448초\n",
      "\n",
      "\n",
      "epoch-6 loss : 0.02139691, loss_normal : 0.01785193, loss_coarse : 0.08420143, min_loss : 0.02139691, min_loss_normal : 0.01785193, min_loss_coarse : 0.08420143, wrong_element_sum : 16166674.00000000, same_data : 0.00%\n",
      "ae train 실행 시간: 123.944초, 전체 시작 시간 20250312_165249_979\n",
      "\n",
      "epoch-6 accuracy check\n",
      "k_means origin feature average accuracy : 82.25308877%, total [0.9746727376209448, 0.9733106189664963, 0.9700891573195284, 0.9530800230282096, 0.943108504398827, 0.9150568181818182, 0.8015244796247435, 0.6625070901871809, 0.9488619568430388, 0.822215777262181, 0.5866935483870968, 0.5005858230814294, 0.9429250891795482, 0.8922588099364529, 0.673546511627907, 0.6000572573718866]\n",
      "kmeans average accuracy best : 84.52%, kmeans average accuracy : 82.73356450%, total [0.9704040978941377, 0.9727427597955707, 0.9680759275237274, 0.9562464018422567, 0.9595307917888563, 0.9261363636363636, 0.8440340076223981, 0.7107203630175837, 0.8918120011823825, 0.8227958236658933, 0.695852534562212, 0.6080843585237259, 0.9007134363852557, 0.8032928942807626, 0.6188953488372093, 0.5880332092756942]\n",
      "cluster_accuracy_post_training_cycle_all_dataset : [0.9692526  0.97219604 0.97111218 0.95853423 0.95970149 0.93962264\n",
      " 0.85877673 0.63875823 0.88048411 0.77832031 0.71428571 0.64051639\n",
      " 0.901222   0.7657614  0.61127451 0.58146202]\n",
      "mean_cluster_accuracy_during_training_cycle : 83.22%, post_traincycle_acc : 82.13%, total_acc : 82.56760763%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 83.77%\n",
      "accuracy_check 실행 시간: 29.674초\n",
      "\n",
      "\n",
      "epoch-7 loss : 0.02124648, loss_normal : 0.01781025, loss_coarse : 0.08401541, min_loss : 0.02124648, min_loss_normal : 0.01781025, min_loss_coarse : 0.08401541, wrong_element_sum : 16130960.00000000, same_data : 0.00%\n",
      "ae train 실행 시간: 121.555초, 전체 시작 시간 20250312_165249_979\n",
      "\n",
      "epoch-7 accuracy check\n",
      "k_means origin feature average accuracy : 82.25319774%, total [0.9746727376209448, 0.9733106189664963, 0.9700891573195284, 0.9530800230282096, 0.943108504398827, 0.9150568181818182, 0.801817648783348, 0.6622234826999432, 0.9488619568430388, 0.822215777262181, 0.5872695852534562, 0.5005858230814294, 0.9429250891795482, 0.8922588099364529, 0.6738372093023256, 0.5991983967935872]\n",
      "kmeans average accuracy best : 84.52%, kmeans average accuracy : 82.51599413%, total [0.9741035856573705, 0.9750141964792731, 0.9698015530629853, 0.9588370754173863, 0.9627565982404692, 0.9372159090909091, 0.8669012019935503, 0.7447532614861032, 0.8536801655335501, 0.7819025522041764, 0.655241935483871, 0.6080843585237259, 0.8721759809750297, 0.7429231658001155, 0.6979651162790698, 0.6012024048096193]\n",
      "cluster_accuracy_post_training_cycle_all_dataset : [0.97682119 0.97643732 0.97111218 0.96239151 0.96218905 0.93915094\n",
      " 0.87319741 0.63170273 0.84417549 0.71044922 0.61679537 0.62413108\n",
      " 0.88543788 0.75654704 0.65       0.57095079]\n",
      "mean_cluster_accuracy_during_training_cycle : 82.28%, post_traincycle_acc : 80.95%, total_acc : 81.47795288%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 83.77%\n",
      "accuracy_check 실행 시간: 30.980초\n",
      "\n",
      "\n",
      "epoch-8 loss : 0.02112663, loss_normal : 0.01779934, loss_coarse : 0.08390626, min_loss : 0.02112663, min_loss_normal : 0.01779934, min_loss_coarse : 0.08390626, wrong_element_sum : 16110002.00000000, same_data : 0.00%\n",
      "ae train 실행 시간: 121.906초, 전체 시작 시간 20250312_165249_979\n",
      "\n",
      "epoch-8 accuracy check\n",
      "k_means origin feature average accuracy : 82.24239603%, total [0.9746727376209448, 0.9733106189664963, 0.9700891573195284, 0.9530800230282096, 0.943108504398827, 0.9150568181818182, 0.801817648783348, 0.6625070901871809, 0.9488619568430388, 0.822215777262181, 0.5866935483870968, 0.5005858230814294, 0.9429250891795482, 0.8922588099364529, 0.673546511627907, 0.5980532493558546]\n",
      "kmeans average accuracy best : 84.52%, kmeans average accuracy : 82.96990980%, total [0.9732498577120091, 0.9738784781374219, 0.9700891573195284, 0.9565342544617156, 0.9592375366568915, 0.8954545454545455, 0.8194077982996189, 0.7291548496880318, 0.888856044930535, 0.8294663573085846, 0.7344470046082949, 0.6748681898066784, 0.8665279429250892, 0.7602541883304448, 0.6688953488372092, 0.5748640137417692]\n",
      "cluster_accuracy_post_training_cycle_all_dataset : [0.97445601 0.97549482 0.97159364 0.95853423 0.95671642 0.90943396\n",
      " 0.83540527 0.69520226 0.87140696 0.78369141 0.7046332  0.68321748\n",
      " 0.87474542 0.77352085 0.68333333 0.57381749]\n",
      "mean_cluster_accuracy_during_training_cycle : 82.08%, post_traincycle_acc : 82.66%, total_acc : 82.41877070%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 83.77%\n",
      "accuracy_check 실행 시간: 32.450초\n",
      "\n",
      "\n",
      "epoch-9 loss : 0.02119634, loss_normal : 0.01783869, loss_coarse : 0.08408227, min_loss : 0.02112663, min_loss_normal : 0.01779934, min_loss_coarse : 0.08390626, wrong_element_sum : 16143796.00000000, same_data : 0.00%\n",
      "ae train 실행 시간: 120.246초, 전체 시작 시간 20250312_165249_979\n",
      "\n",
      "epoch-9 accuracy check\n",
      "k_means origin feature average accuracy : 82.24970778%, total [0.9746727376209448, 0.9733106189664963, 0.9700891573195284, 0.9530800230282096, 0.943108504398827, 0.9150568181818182, 0.801817648783348, 0.6622234826999432, 0.9488619568430388, 0.822215777262181, 0.5866935483870968, 0.5005858230814294, 0.9429250891795482, 0.8922588099364529, 0.675, 0.5980532493558546]\n",
      "kmeans average accuracy best : 84.52%, kmeans average accuracy : 81.76058950%, total [0.9704040978941377, 0.9707552526973311, 0.9677883232671843, 0.9565342544617156, 0.9369501466275659, 0.8414772727272727, 0.78246848431545, 0.6925694838343732, 0.893585574933491, 0.7810324825986079, 0.6765552995391705, 0.59900410076157, 0.9102259215219977, 0.7891392258809936, 0.6985465116279069, 0.6146578872029774]\n",
      "cluster_accuracy_post_training_cycle_all_dataset : [0.9730369  0.97078228 0.97063072 0.95756991 0.93383085 0.85566038\n",
      " 0.78717056 0.58372531 0.87493696 0.75732422 0.66119691 0.62015889\n",
      " 0.89511202 0.7643065  0.59509804 0.60487339]\n",
      "mean_cluster_accuracy_during_training_cycle : 81.12%, post_traincycle_acc : 80.03%, total_acc : 80.47266084%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 83.77%\n",
      "accuracy_check 실행 시간: 31.465초\n",
      "\n",
      "\n",
      "epoch-10 loss : 0.02178484, loss_normal : 0.01797436, loss_coarse : 0.08453248, min_loss : 0.02112663, min_loss_normal : 0.01779934, min_loss_coarse : 0.08390626, wrong_element_sum : 16230236.00000000, same_data : 0.00%\n",
      "ae train 실행 시간: 110.051초, 전체 시작 시간 20250312_165249_979\n",
      "\n",
      "epoch-10 accuracy check\n",
      "k_means origin feature average accuracy : 82.25318692%, total [0.9746727376209448, 0.9733106189664963, 0.9700891573195284, 0.9530800230282096, 0.943108504398827, 0.9150568181818182, 0.801817648783348, 0.6625070901871809, 0.9488619568430388, 0.822215777262181, 0.5866935483870968, 0.5005858230814294, 0.9429250891795482, 0.8922588099364529, 0.6741279069767442, 0.5991983967935872]\n",
      "kmeans average accuracy best : 84.52%, kmeans average accuracy : 82.86037565%, total [0.9721115537848606, 0.9744463373083475, 0.9683635317802703, 0.9571099597006333, 0.9219941348973607, 0.809375, 0.7546174142480211, 0.7081678956324446, 0.9337865799586166, 0.8755800464037123, 0.763536866359447, 0.7129466900995899, 0.8900118906064209, 0.766897746967071, 0.6747093023255814, 0.5740051531634698]\n",
      "cluster_accuracy_post_training_cycle_all_dataset : [0.97540208 0.97502356 0.97111218 0.95949855 0.9318408  0.86226415\n",
      " 0.80109398 0.62511759 0.93393848 0.85400391 0.74469112 0.69612711\n",
      " 0.84775967 0.75897187 0.67107843 0.60678452]\n",
      "mean_cluster_accuracy_during_training_cycle : 82.43%, post_traincycle_acc : 82.59%, total_acc : 82.52587241%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 83.77%\n",
      "accuracy_check 실행 시간: 30.887초\n",
      "\n",
      "\n",
      "epoch-11 loss : 0.02071973, loss_normal : 0.01767706, loss_coarse : 0.08321310, min_loss : 0.02071973, min_loss_normal : 0.01767706, min_loss_coarse : 0.08321310, wrong_element_sum : 15976916.00000000, same_data : 0.00%\n",
      "ae train 실행 시간: 119.392초, 전체 시작 시간 20250312_165249_979\n",
      "\n",
      "epoch-11 accuracy check\n",
      "k_means origin feature average accuracy : 82.26578875%, total [0.9746727376209448, 0.9733106189664963, 0.9700891573195284, 0.9530800230282096, 0.943108504398827, 0.9150568181818182, 0.801817648783348, 0.6625070901871809, 0.9488619568430388, 0.822215777262181, 0.5872695852534562, 0.5005858230814294, 0.9429250891795482, 0.8922588099364529, 0.6747093023255814, 0.6000572573718866]\n",
      "kmeans average accuracy best : 84.52%, kmeans average accuracy : 81.67372488%, total [0.9738190096755834, 0.9741624077228848, 0.9698015530629853, 0.957685664939551, 0.9126099706744868, 0.8278409090909091, 0.7423043095866315, 0.664208735110607, 0.9015666568134791, 0.796983758700696, 0.7174539170506913, 0.6250732278851787, 0.9191438763376932, 0.7943385326400925, 0.6938953488372093, 0.5969081019181219]\n",
      "cluster_accuracy_post_training_cycle_all_dataset : [0.97540208 0.97408106 0.97063072 0.96142719 0.92039801 0.82641509\n",
      " 0.76628543 0.6476952  0.89561271 0.77880859 0.66071429 0.64945382\n",
      " 0.88136456 0.76236663 0.68137255 0.61156235]\n",
      "mean_cluster_accuracy_during_training_cycle : 81.20%, post_traincycle_acc : 81.02%, total_acc : 81.09218745%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 83.77%\n",
      "accuracy_check 실행 시간: 33.282초\n",
      "\n",
      "\n",
      "epoch-12 loss : 0.02059635, loss_normal : 0.01767500, loss_coarse : 0.08309588, min_loss : 0.02059635, min_loss_normal : 0.01767500, min_loss_coarse : 0.08309588, wrong_element_sum : 15954410.00000000, same_data : 0.00%\n",
      "ae train 실행 시간: 118.801초, 전체 시작 시간 20250312_165249_979\n",
      "\n",
      "epoch-12 accuracy check\n",
      "k_means origin feature average accuracy : 82.26215503%, total [0.9746727376209448, 0.9733106189664963, 0.9700891573195284, 0.9530800230282096, 0.943108504398827, 0.9150568181818182, 0.801817648783348, 0.6625070901871809, 0.9488619568430388, 0.822215777262181, 0.5872695852534562, 0.5005858230814294, 0.9429250891795482, 0.8922588099364529, 0.6741279069767442, 0.6000572573718866]\n",
      "kmeans average accuracy best : 84.52%, kmeans average accuracy : 82.50557554%, total [0.9706886738759248, 0.9716070414537195, 0.9675007190106414, 0.9568221070811744, 0.9551319648093841, 0.9119318181818182, 0.8185282908238053, 0.7007941009642654, 0.8926987880579368, 0.8109048723897911, 0.7079493087557603, 0.6268306971294669, 0.901307966706302, 0.7619872905834778, 0.6793604651162791, 0.5668479816776409]\n",
      "cluster_accuracy_post_training_cycle_all_dataset : [0.97067171 0.9726673  0.96918633 0.95949855 0.95024876 0.93396226\n",
      " 0.79612133 0.70084666 0.84619264 0.78466797 0.69015444 0.58142999\n",
      " 0.87169043 0.76333657 0.6872549  0.56043956]\n",
      "mean_cluster_accuracy_during_training_cycle : 81.44%, post_traincycle_acc : 81.49%, total_acc : 81.47096351%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 83.77%\n",
      "accuracy_check 실행 시간: 30.661초\n",
      "\n",
      "\n",
      "epoch-13 loss : 0.02057802, loss_normal : 0.01769055, loss_coarse : 0.08306920, min_loss : 0.02057802, min_loss_normal : 0.01767500, min_loss_coarse : 0.08306920, wrong_element_sum : 15949286.00000000, same_data : 0.00%\n",
      "ae train 실행 시간: 120.640초, 전체 시작 시간 20250312_165249_979\n",
      "\n",
      "epoch-13 accuracy check\n",
      "k_means origin feature average accuracy : 82.26756432%, total [0.9746727376209448, 0.9733106189664963, 0.9700891573195284, 0.9530800230282096, 0.943108504398827, 0.915340909090909, 0.801817648783348, 0.6625070901871809, 0.9488619568430388, 0.822215777262181, 0.5872695852534562, 0.5005858230814294, 0.9429250891795482, 0.8922588099364529, 0.6747093023255814, 0.6000572573718866]\n",
      "kmeans average accuracy best : 84.52%, kmeans average accuracy : 82.46985254%, total [0.9718269778030734, 0.9724588302101079, 0.9695139488064424, 0.9571099597006333, 0.9580645161290322, 0.899715909090909, 0.7886250366461448, 0.6920022688598979, 0.9402896837126811, 0.8767401392111369, 0.7381912442396313, 0.4774458113649678, 0.901307966706302, 0.7839399191218949, 0.6779069767441861, 0.5900372172917263]\n",
      "cluster_accuracy_post_training_cycle_all_dataset : [0.97398297 0.97313855 0.97159364 0.95949855 0.960199   0.92122642\n",
      " 0.79860766 0.68203198 0.94251135 0.78564453 0.69449807 0.37040715\n",
      " 0.85488798 0.75751697 0.59509804 0.60200669]\n",
      "mean_cluster_accuracy_during_training_cycle : 82.27%, post_traincycle_acc : 80.27%, total_acc : 81.08501041%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 83.77%\n",
      "accuracy_check 실행 시간: 30.837초\n",
      "\n",
      "\n",
      "epoch-14 loss : 0.02093080, loss_normal : 0.01776952, loss_coarse : 0.08340575, min_loss : 0.02057802, min_loss_normal : 0.01767500, min_loss_coarse : 0.08306920, wrong_element_sum : 16013904.00000000, same_data : 0.00%\n",
      "ae train 실행 시간: 119.086초, 전체 시작 시간 20250312_165249_979\n",
      "\n",
      "epoch-14 accuracy check\n",
      "k_means origin feature average accuracy : 82.26934569%, total [0.9746727376209448, 0.9733106189664963, 0.9700891573195284, 0.9530800230282096, 0.943108504398827, 0.9150568181818182, 0.801817648783348, 0.6625070901871809, 0.9488619568430388, 0.822215777262181, 0.5866935483870968, 0.5005858230814294, 0.9429250891795482, 0.8922588099364529, 0.6747093023255814, 0.6012024048096193]\n",
      "kmeans average accuracy best : 84.52%, kmeans average accuracy : 83.53590678%, total [0.9726807057484348, 0.9735945485519591, 0.9692263445498993, 0.9588370754173863, 0.9636363636363636, 0.9446022727272727, 0.8595719730284375, 0.7515598411798071, 0.9036358261897723, 0.830046403712297, 0.6970046082949308, 0.622729935559461, 0.9224137931034483, 0.7414789139225881, 0.6747093023255814, 0.580017177211566]\n",
      "cluster_accuracy_post_training_cycle_all_dataset : [0.97350993 0.9736098  0.97111218 0.96142719 0.96517413 0.94716981\n",
      " 0.86573844 0.73894638 0.88703984 0.80761719 0.68918919 0.5531281\n",
      " 0.78665988 0.72793404 0.61568627 0.56903966]\n",
      "mean_cluster_accuracy_during_training_cycle : 82.34%, post_traincycle_acc : 81.46%, total_acc : 81.81396787%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 83.77%\n",
      "accuracy_check 실행 시간: 24.378초\n",
      "\n",
      "\n",
      "epoch-15 loss : 0.02092643, loss_normal : 0.01772669, loss_coarse : 0.08331730, min_loss : 0.02057802, min_loss_normal : 0.01767500, min_loss_coarse : 0.08306920, wrong_element_sum : 15996922.00000000, same_data : 0.00%\n",
      "ae train 실행 시간: 115.162초, 전체 시작 시간 20250312_165249_979\n",
      "\n",
      "epoch-15 accuracy check\n",
      "k_means origin feature average accuracy : 82.24776520%, total [0.9746727376209448, 0.9733106189664963, 0.9700891573195284, 0.9530800230282096, 0.943108504398827, 0.9150568181818182, 0.8015244796247435, 0.6622234826999432, 0.9488619568430388, 0.822215777262181, 0.5866935483870968, 0.5005858230814294, 0.9429250891795482, 0.8922588099364529, 0.6738372093023256, 0.5991983967935872]\n",
      "kmeans average accuracy best : 84.52%, kmeans average accuracy : 80.89920395%, total [0.9712578258394992, 0.9718909710391823, 0.9683635317802703, 0.9568221070811744, 0.9457478005865103, 0.8556818181818182, 0.7358545880973322, 0.6670448099829835, 0.9006798699379249, 0.8459976798143851, 0.6785714285714286, 0.5243116578793204, 0.8944708680142688, 0.7862507221259387, 0.6520348837209302, 0.5888920698539937]\n",
      "cluster_accuracy_post_training_cycle_all_dataset : [0.97209082 0.97219604 0.97014925 0.95901639 0.94378109 0.90235849\n",
      " 0.73794132 0.65475071 0.89309128 0.80566406 0.54247104 0.61519364\n",
      " 0.89460285 0.79534433 0.65735294 0.56569517]\n",
      "mean_cluster_accuracy_during_training_cycle : 80.42%, post_traincycle_acc : 80.51%, total_acc : 80.47708146%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 83.77%\n",
      "accuracy_check 실행 시간: 30.102초\n",
      "\n",
      "\n",
      "epoch-16 loss : 0.02115157, loss_normal : 0.01783708, loss_coarse : 0.08367147, min_loss : 0.02057802, min_loss_normal : 0.01767500, min_loss_coarse : 0.08306920, wrong_element_sum : 16064922.00000000, same_data : 0.00%\n",
      "ae train 실행 시간: 123.803초, 전체 시작 시간 20250312_165249_979\n",
      "\n",
      "epoch-16 accuracy check\n",
      "k_means origin feature average accuracy : 82.25864832%, total [0.9746727376209448, 0.9733106189664963, 0.9700891573195284, 0.9530800230282096, 0.943108504398827, 0.9150568181818182, 0.801817648783348, 0.6622234826999432, 0.9488619568430388, 0.822215777262181, 0.5872695852534562, 0.5005858230814294, 0.9429250891795482, 0.8922588099364529, 0.6747093023255814, 0.5991983967935872]\n",
      "kmeans average accuracy best : 84.52%, kmeans average accuracy : 82.69306555%, total [0.970973249857712, 0.9718909710391823, 0.9677883232671843, 0.9565342544617156, 0.9363636363636364, 0.9085227272727273, 0.8355321020228672, 0.7538287010777085, 0.9125036949453148, 0.8407772621809745, 0.7456797235023042, 0.5052724077328646, 0.8900118906064209, 0.7593876372039283, 0.6877906976744186, 0.5880332092756942]\n",
      "cluster_accuracy_post_training_cycle_all_dataset : [0.97209082 0.97219604 0.96966779 0.95901639 0.94577114 0.92028302\n",
      " 0.83988066 0.72107244 0.88048411 0.81201172 0.55598456 0.49950348\n",
      " 0.87881874 0.7129001  0.61764706 0.56378404]\n",
      "mean_cluster_accuracy_during_training_cycle : 80.22%, post_traincycle_acc : 80.13%, total_acc : 80.16664981%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 83.77%\n",
      "accuracy_check 실행 시간: 33.332초\n",
      "\n",
      "\n",
      "epoch-17 loss : 0.02069102, loss_normal : 0.01772522, loss_coarse : 0.08319439, min_loss : 0.02057802, min_loss_normal : 0.01767500, min_loss_coarse : 0.08306920, wrong_element_sum : 15973324.00000000, same_data : 0.00%\n",
      "ae train 실행 시간: 121.632초, 전체 시작 시간 20250312_165249_979\n",
      "\n",
      "epoch-17 accuracy check\n",
      "k_means origin feature average accuracy : 82.26219154%, total [0.9746727376209448, 0.9733106189664963, 0.9700891573195284, 0.9530800230282096, 0.943108504398827, 0.915340909090909, 0.801817648783348, 0.6622234826999432, 0.9488619568430388, 0.822215777262181, 0.5866935483870968, 0.5005858230814294, 0.9429250891795482, 0.8922588099364529, 0.6747093023255814, 0.6000572573718866]\n",
      "kmeans average accuracy best : 84.52%, kmeans average accuracy : 82.21041436%, total [0.9695503699487763, 0.9704713231118682, 0.9672131147540983, 0.9550949913644214, 0.9460410557184751, 0.8678977272727273, 0.7842274992670771, 0.7243335224049915, 0.9423588530889743, 0.8254060324825986, 0.7520161290322581, 0.5597539543057997, 0.9007134363852557, 0.7671865973425765, 0.6293604651162791, 0.5920412253077584]\n",
      "cluster_accuracy_post_training_cycle_all_dataset : [0.97019868 0.97125353 0.9682234  0.95612343 0.94577114 0.89009434\n",
      " 0.81452014 0.73424271 0.88905698 0.78710938 0.68388031 0.59980139\n",
      " 0.86252546 0.61396702 0.55245098 0.58671763]\n",
      "mean_cluster_accuracy_during_training_cycle : 80.84%, post_traincycle_acc : 80.16%, total_acc : 80.43569361%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 83.77%\n",
      "accuracy_check 실행 시간: 32.107초\n",
      "\n",
      "\n",
      "epoch-18 loss : 0.02072717, loss_normal : 0.01774346, loss_coarse : 0.08324751, min_loss : 0.02057802, min_loss_normal : 0.01767500, min_loss_coarse : 0.08306920, wrong_element_sum : 15983522.00000000, same_data : 0.00%\n",
      "ae train 실행 시간: 121.645초, 전체 시작 시간 20250312_165249_979\n",
      "\n",
      "epoch-18 accuracy check\n",
      "k_means origin feature average accuracy : 82.25679017%, total [0.9746727376209448, 0.9733106189664963, 0.9700891573195284, 0.9530800230282096, 0.943108504398827, 0.915340909090909, 0.801817648783348, 0.6622234826999432, 0.9488619568430388, 0.822215777262181, 0.5872695852534562, 0.5005858230814294, 0.9429250891795482, 0.8922588099364529, 0.6741279069767442, 0.5991983967935872]\n",
      "kmeans average accuracy best : 84.52%, kmeans average accuracy : 81.18540578%, total [0.9721115537848606, 0.9727427597955707, 0.9698015530629853, 0.9579735175590098, 0.9170087976539589, 0.8838068181818182, 0.7666373497508062, 0.7257515598411798, 0.8850133018031333, 0.8030742459396751, 0.6270161290322581, 0.5005858230814294, 0.9129013079667063, 0.8186019641825535, 0.6659883720930233, 0.6106498711709133]\n",
      "cluster_accuracy_post_training_cycle_all_dataset : [0.97350993 0.97408106 0.97207511 0.95998071 0.91144279 0.91650943\n",
      " 0.81153655 0.61571025 0.85678265 0.74316406 0.628861   0.57050645\n",
      " 0.91344196 0.75606208 0.64852941 0.59149546]\n",
      "mean_cluster_accuracy_during_training_cycle : 81.18%, post_traincycle_acc : 80.27%, total_acc : 80.63685135%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 83.77%\n",
      "accuracy_check 실행 시간: 28.793초\n",
      "\n",
      "\n",
      "epoch-19 loss : 0.02054289, loss_normal : 0.01768400, loss_coarse : 0.08286517, min_loss : 0.02054289, min_loss_normal : 0.01767500, min_loss_coarse : 0.08286517, wrong_element_sum : 15910114.00000000, same_data : 0.00%\n",
      "ae train 실행 시간: 117.361초, 전체 시작 시간 20250312_165249_979\n",
      "\n",
      "epoch-19 accuracy check\n",
      "k_means origin feature average accuracy : 82.26756432%, total [0.9746727376209448, 0.9733106189664963, 0.9700891573195284, 0.9530800230282096, 0.943108504398827, 0.915340909090909, 0.801817648783348, 0.6625070901871809, 0.9488619568430388, 0.822215777262181, 0.5872695852534562, 0.5005858230814294, 0.9429250891795482, 0.8922588099364529, 0.6747093023255814, 0.6000572573718866]\n",
      "kmeans average accuracy best : 84.52%, kmeans average accuracy : 83.81569634%, total [0.9718269778030734, 0.9724588302101079, 0.9698015530629853, 0.9588370754173863, 0.9609970674486803, 0.934375, 0.8449135150982117, 0.7422007941009643, 0.914572864321608, 0.8297563805104409, 0.7269585253456221, 0.6417691857059168, 0.9316290130796671, 0.729636048526863, 0.6747093023255814, 0.6060692814199828]\n",
      "cluster_accuracy_post_training_cycle_all_dataset : [0.9730369  0.9736098  0.97207511 0.96190935 0.96318408 0.93773585\n",
      " 0.86474391 0.76152399 0.90771558 0.81347656 0.71862934 0.65590864\n",
      " 0.94093686 0.72744908 0.63382353 0.59818442]\n",
      "mean_cluster_accuracy_during_training_cycle : 83.54%, post_traincycle_acc : 83.77%, total_acc : 83.67771981%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 83.77%\n",
      "accuracy_check 실행 시간: 31.935초\n",
      "\n",
      "\n",
      "epoch-20 loss : 0.02031592, loss_normal : 0.01753699, loss_coarse : 0.08227602, min_loss : 0.02031592, min_loss_normal : 0.01753699, min_loss_coarse : 0.08227602, wrong_element_sum : 15796996.00000000, same_data : 0.00%\n",
      "ae train 실행 시간: 127.764초, 전체 시작 시간 20250312_165249_979\n",
      "\n",
      "epoch-20 accuracy check\n",
      "k_means origin feature average accuracy : 82.24948714%, total [0.9746727376209448, 0.9733106189664963, 0.9700891573195284, 0.9530800230282096, 0.943108504398827, 0.9150568181818182, 0.801817648783348, 0.6622234826999432, 0.9488619568430388, 0.822215777262181, 0.5866935483870968, 0.5, 0.9429250891795482, 0.8922588099364529, 0.673546511627907, 0.6000572573718866]\n",
      "kmeans average accuracy best : 84.52%, kmeans average accuracy : 81.83832972%, total [0.9718269778030734, 0.9716070414537195, 0.9698015530629853, 0.9579735175590098, 0.9580645161290322, 0.9210227272727273, 0.842274992670771, 0.7053318207600681, 0.8323972805202483, 0.7740719257540604, 0.7142857142857143, 0.6385471587580551, 0.8810939357907254, 0.7111496244945118, 0.6543604651162791, 0.5903235041511594]\n",
      "cluster_accuracy_post_training_cycle_all_dataset : [0.97445601 0.97125353 0.97303804 0.96094503 0.95970149 0.93254717\n",
      " 0.84435604 0.67262465 0.81139687 0.76025391 0.68001931 0.36295929\n",
      " 0.8401222  0.71871969 0.64215686 0.58576206]\n",
      "mean_cluster_accuracy_during_training_cycle : 81.29%, post_traincycle_acc : 79.31%, total_acc : 80.11854410%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 83.77%\n",
      "accuracy_check 실행 시간: 28.956초\n",
      "\n",
      "\n",
      "epoch-21 loss : 0.01987838, loss_normal : 0.01730079, loss_coarse : 0.08128216, min_loss : 0.01987838, min_loss_normal : 0.01730079, min_loss_coarse : 0.08128216, wrong_element_sum : 15606176.00000000, same_data : 0.00%\n",
      "ae train 실행 시간: 122.853초, 전체 시작 시간 20250312_165249_979\n",
      "\n",
      "epoch-21 accuracy check\n",
      "k_means origin feature average accuracy : 82.26392268%, total [0.9746727376209448, 0.9733106189664963, 0.9700891573195284, 0.9530800230282096, 0.943108504398827, 0.9150568181818182, 0.801817648783348, 0.6625070901871809, 0.9488619568430388, 0.822215777262181, 0.5866935483870968, 0.5005858230814294, 0.9429250891795482, 0.8922588099364529, 0.6741279069767442, 0.6009161179501861]\n",
      "kmeans average accuracy best : 84.52%, kmeans average accuracy : 82.19174977%, total [0.9695503699487763, 0.9716070414537195, 0.9695139488064424, 0.9568221070811744, 0.9601173020527859, 0.9298295454545454, 0.8469656992084432, 0.7473057288712422, 0.8977239136860774, 0.8019141531322506, 0.6949884792626728, 0.5840656121851201, 0.9307372175980975, 0.7102830733679953, 0.6252906976744186, 0.5539650730031491]\n",
      "cluster_accuracy_post_training_cycle_all_dataset : [0.97114475 0.97219604 0.97207511 0.95805207 0.96169154 0.93820755\n",
      " 0.87468921 0.74788335 0.89309128 0.78759766 0.65926641 0.6122145\n",
      " 0.93228106 0.71241513 0.62156863 0.55613951]\n",
      "mean_cluster_accuracy_during_training_cycle : 81.82%, post_traincycle_acc : 82.32%, total_acc : 82.11032335%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 83.77%\n",
      "accuracy_check 실행 시간: 37.833초\n",
      "\n",
      "\n",
      "epoch-22 loss : 0.02006992, loss_normal : 0.01738245, loss_coarse : 0.08160584, min_loss : 0.01987838, min_loss_normal : 0.01730079, min_loss_coarse : 0.08128216, wrong_element_sum : 15668322.00000000, same_data : 0.00%\n",
      "ae train 실행 시간: 124.930초, 전체 시작 시간 20250312_165249_979\n",
      "\n",
      "epoch-22 accuracy check\n",
      "k_means origin feature average accuracy : 82.27836893%, total [0.9746727376209448, 0.9733106189664963, 0.9700891573195284, 0.9530800230282096, 0.943108504398827, 0.9150568181818182, 0.801817648783348, 0.6625070901871809, 0.9488619568430388, 0.822215777262181, 0.5872695852534562, 0.5005858230814294, 0.9429250891795482, 0.8922588099364529, 0.6752906976744186, 0.6014886916690524]\n",
      "kmeans average accuracy best : 84.52%, kmeans average accuracy : 82.53491756%, total [0.9746727376209448, 0.975298126064736, 0.9709519700891573, 0.9597006332757628, 0.9275659824046921, 0.9261363636363636, 0.8545880973321607, 0.7220646625070902, 0.8507242092817027, 0.7937935034802784, 0.7332949308755761, 0.6256590509666081, 0.9120095124851367, 0.7169266320046216, 0.6578488372093023, 0.6043515602633839]\n",
      "cluster_accuracy_post_training_cycle_all_dataset : [0.97729423 0.97690858 0.97303804 0.96287367 0.93880597 0.94009434\n",
      " 0.85479861 0.48777046 0.83913263 0.78515625 0.69980695 0.46921549\n",
      " 0.89460285 0.67895247 0.62598039 0.58432871]\n",
      "mean_cluster_accuracy_during_training_cycle : 81.44%, post_traincycle_acc : 79.30%, total_acc : 80.16012406%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 83.77%\n",
      "accuracy_check 실행 시간: 30.699초\n",
      "\n",
      "\n",
      "epoch-23 loss : 0.02004818, loss_normal : 0.01732338, loss_coarse : 0.08144876, min_loss : 0.01987838, min_loss_normal : 0.01730079, min_loss_coarse : 0.08128216, wrong_element_sum : 15638162.00000000, same_data : 0.00%\n",
      "ae train 실행 시간: 119.994초, 전체 시작 시간 20250312_165249_979\n",
      "\n",
      "epoch-23 accuracy check\n",
      "k_means origin feature average accuracy : 82.24783277%, total [0.9746727376209448, 0.9733106189664963, 0.9700891573195284, 0.9530800230282096, 0.943108504398827, 0.9150568181818182, 0.801817648783348, 0.6625070901871809, 0.9488619568430388, 0.822215777262181, 0.5866935483870968, 0.5002929115407148, 0.9429250891795482, 0.8922588099364529, 0.6747093023255814, 0.5980532493558546]\n",
      "kmeans average accuracy best : 84.52%, kmeans average accuracy : 82.72141242%, total [0.9692657939669892, 0.9718909710391823, 0.9689387402933564, 0.957685664939551, 0.9565982404692082, 0.9258522727272728, 0.7947815889768396, 0.7220646625070902, 0.8755542417972214, 0.7810324825986079, 0.706221198156682, 0.6013473930872877, 0.920332936979786, 0.792316580011554, 0.686046511627907, 0.6054967077011165]\n",
      "cluster_accuracy_post_training_cycle_all_dataset : [0.97067171 0.97219604 0.97111218 0.95949855 0.960199   0.93726415\n",
      " 0.84485331 0.4915334  0.87090267 0.75195312 0.68291506 0.64150943\n",
      " 0.91802444 0.73617847 0.67205882 0.57286192]\n",
      "mean_cluster_accuracy_during_training_cycle : 81.95%, post_traincycle_acc : 80.96%, total_acc : 81.34711758%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 83.77%\n",
      "accuracy_check 실행 시간: 23.998초\n",
      "\n",
      "\n",
      "epoch-24 loss : 0.01972169, loss_normal : 0.01724797, loss_coarse : 0.08112645, min_loss : 0.01972169, min_loss_normal : 0.01724797, min_loss_coarse : 0.08112645, wrong_element_sum : 15576278.00000000, same_data : 0.00%\n",
      "ae train 실행 시간: 124.006초, 전체 시작 시간 20250312_165249_979\n",
      "\n",
      "epoch-24 accuracy check\n",
      "k_means origin feature average accuracy : 82.26396409%, total [0.9746727376209448, 0.9733106189664963, 0.9700891573195284, 0.9530800230282096, 0.943108504398827, 0.915340909090909, 0.801817648783348, 0.6625070901871809, 0.9488619568430388, 0.822215777262181, 0.5866935483870968, 0.5005858230814294, 0.9429250891795482, 0.8922588099364529, 0.6747093023255814, 0.6000572573718866]\n",
      "save model\n",
      "kmeans average accuracy best : 85.05%, kmeans average accuracy : 85.04594164%, total [0.972965281730222, 0.9727427597955707, 0.9712395743457003, 0.9597006332757628, 0.963049853372434, 0.9454545454545454, 0.8809733216065669, 0.7722631877481565, 0.9068873780668046, 0.8155452436194895, 0.7597926267281107, 0.666373755125952, 0.929845422116528, 0.806470248411323, 0.6825581395348838, 0.6014886916690524]\n",
      "cluster_accuracy_post_training_cycle_all_dataset : [0.97398297 0.9736098  0.97303804 0.96383799 0.96318408 0.94764151\n",
      " 0.87518647 0.77328316 0.83459405 0.77636719 0.70125483 0.53128103\n",
      " 0.91293279 0.79388943 0.67009804 0.58528428]\n",
      "mean_cluster_accuracy_during_training_cycle : 83.50%, post_traincycle_acc : 82.81%, total_acc : 83.08793729%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 82.81%\n",
      "accuracy_check 실행 시간: 32.892초\n",
      "\n",
      "\n",
      "epoch-25 loss : 0.01948852, loss_normal : 0.01713383, loss_coarse : 0.08057765, min_loss : 0.01948852, min_loss_normal : 0.01713383, min_loss_coarse : 0.08057765, wrong_element_sum : 15470910.00000000, same_data : 0.00%\n",
      "ae train 실행 시간: 124.533초, 전체 시작 시간 20250312_165249_979\n",
      "\n",
      "epoch-25 accuracy check\n",
      "k_means origin feature average accuracy : 82.24954857%, total [0.9746727376209448, 0.9733106189664963, 0.9700891573195284, 0.9530800230282096, 0.943108504398827, 0.9150568181818182, 0.8015244796247435, 0.6622234826999432, 0.9488619568430388, 0.822215777262181, 0.5872695852534562, 0.5005858230814294, 0.9429250891795482, 0.8922588099364529, 0.673546511627907, 0.5991983967935872]\n",
      "kmeans average accuracy best : 85.05%, kmeans average accuracy : 83.24814132%, total [0.9718269778030734, 0.9718909710391823, 0.9680759275237274, 0.9608520437535981, 0.9627565982404692, 0.9536931818181819, 0.9076517150395779, 0.8034600113442995, 0.8811705586757316, 0.7795823665893271, 0.7085253456221198, 0.6649091974223784, 0.8356123662306778, 0.7267475447718083, 0.6369186046511628, 0.5860292012596622]\n",
      "cluster_accuracy_post_training_cycle_all_dataset : [0.97209082 0.97219604 0.97014925 0.96432015 0.96467662 0.95424528\n",
      " 0.90253605 0.79162747 0.80736258 0.76220703 0.64720077 0.54468719\n",
      " 0.84164969 0.73666343 0.5245098  0.50645007]\n",
      "mean_cluster_accuracy_during_training_cycle : 80.47%, post_traincycle_acc : 80.39%, total_acc : 80.42106026%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 82.81%\n",
      "accuracy_check 실행 시간: 29.342초\n",
      "\n",
      "\n",
      "epoch-26 loss : 0.02031462, loss_normal : 0.01738048, loss_coarse : 0.08162040, min_loss : 0.01948852, min_loss_normal : 0.01713383, min_loss_coarse : 0.08057765, wrong_element_sum : 15671118.00000000, same_data : 0.00%\n",
      "ae train 실행 시간: 123.258초, 전체 시작 시간 20250312_165249_979\n",
      "\n",
      "epoch-26 accuracy check\n",
      "k_means origin feature average accuracy : 82.58599539%, total [0.9746727376209448, 0.9733106189664963, 0.9700891573195284, 0.9530800230282096, 0.943108504398827, 0.9150568181818182, 0.801817648783348, 0.6625070901871809, 0.9488619568430388, 0.822215777262181, 0.5866935483870968, 0.5005858230814294, 0.9429250891795482, 0.8922588099364529, 0.6741279069767442, 0.6524477526481535]\n",
      "kmeans average accuracy best : 85.05%, kmeans average accuracy : 82.26431058%, total [0.9723961297666477, 0.9718909710391823, 0.9703767615760713, 0.9645941278065631, 0.9607038123167155, 0.9443181818181818, 0.8862503664614483, 0.6032331253545093, 0.9237363287023352, 0.8636890951276102, 0.7171658986175116, 0.59900410076157, 0.869500594530321, 0.7154823801270942, 0.6305232558139535, 0.5694245634125393]\n",
      "cluster_accuracy_post_training_cycle_all_dataset : [0.97492904 0.97219604 0.97255657 0.96480231 0.96169154 0.90566038\n",
      " 0.90154152 0.48212606 0.91124559 0.75927734 0.73166023 0.68718967\n",
      " 0.83553971 0.68913676 0.62598039 0.56378404]\n",
      "mean_cluster_accuracy_during_training_cycle : 80.94%, post_traincycle_acc : 80.87%, total_acc : 80.89165348%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 82.81%\n",
      "accuracy_check 실행 시간: 31.328초\n",
      "\n",
      "\n",
      "epoch-27 loss : 0.01952708, loss_normal : 0.01717377, loss_coarse : 0.08076319, min_loss : 0.01948852, min_loss_normal : 0.01713383, min_loss_coarse : 0.08057765, wrong_element_sum : 15506532.00000000, same_data : 0.00%\n",
      "ae train 실행 시간: 121.731초, 전체 시작 시간 20250312_165249_979\n",
      "\n",
      "epoch-27 accuracy check\n",
      "k_means origin feature average accuracy : 82.25496539%, total [0.9746727376209448, 0.9733106189664963, 0.9700891573195284, 0.9530800230282096, 0.943108504398827, 0.9150568181818182, 0.801817648783348, 0.6622234826999432, 0.9488619568430388, 0.822215777262181, 0.5866935483870968, 0.5005858230814294, 0.9429250891795482, 0.8922588099364529, 0.6738372093023256, 0.6000572573718866]\n",
      "kmeans average accuracy best : 85.05%, kmeans average accuracy : 84.13205144%, total [0.9689812179852021, 0.9716070414537195, 0.9695139488064424, 0.9608520437535981, 0.9618768328445748, 0.9394886363636363, 0.8683670477865728, 0.7799205899035735, 0.86550399054094, 0.820185614849188, 0.7243663594470046, 0.6549502050380785, 0.9274673008323424, 0.7819179664933564, 0.6715116279069767, 0.5946178070426568]\n",
      "cluster_accuracy_post_training_cycle_all_dataset : [0.97067171 0.97219604 0.97255657 0.96142719 0.96666667 0.9495283\n",
      " 0.86126305 0.79727187 0.8587998  0.80419922 0.70366795 0.45580933\n",
      " 0.9302444  0.78128031 0.65441176 0.55757286]\n",
      "mean_cluster_accuracy_during_training_cycle : 82.71%, post_traincycle_acc : 82.48%, total_acc : 82.57519147%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 82.81%\n",
      "accuracy_check 실행 시간: 25.912초\n",
      "\n",
      "\n",
      "epoch-28 loss : 0.01929412, loss_normal : 0.01709493, loss_coarse : 0.08048404, min_loss : 0.01929412, min_loss_normal : 0.01709493, min_loss_coarse : 0.08048404, wrong_element_sum : 15452936.00000000, same_data : 0.00%\n",
      "ae train 실행 시간: 122.515초, 전체 시작 시간 20250312_165249_979\n",
      "\n",
      "epoch-28 accuracy check\n",
      "k_means origin feature average accuracy : 82.23879117%, total [0.9746727376209448, 0.9733106189664963, 0.9700891573195284, 0.9530800230282096, 0.943108504398827, 0.9150568181818182, 0.8015244796247435, 0.6622234826999432, 0.9488619568430388, 0.822215777262181, 0.5866935483870968, 0.5005858230814294, 0.9429250891795482, 0.8922588099364529, 0.673546511627907, 0.5980532493558546]\n",
      "kmeans average accuracy best : 85.05%, kmeans average accuracy : 83.38926220%, total [0.9692657939669892, 0.9713231118682567, 0.9677883232671843, 0.9608520437535981, 0.9607038123167155, 0.9426136363636364, 0.8868367047786573, 0.7370958593306863, 0.8587052911616908, 0.7897331786542924, 0.7019009216589862, 0.6461628588166374, 0.917360285374554, 0.755054881571346, 0.6822674418604651, 0.5946178070426568]\n",
      "cluster_accuracy_post_training_cycle_all_dataset : [0.97114475 0.97219604 0.97159364 0.96335583 0.96567164 0.94716981\n",
      " 0.87916459 0.45625588 0.86283409 0.77197266 0.6703668  0.54121152\n",
      " 0.9098778  0.76188167 0.68382353 0.56187291]\n",
      "mean_cluster_accuracy_during_training_cycle : 82.36%, post_traincycle_acc : 80.56%, total_acc : 81.27556038%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 82.81%\n",
      "accuracy_check 실행 시간: 35.201초\n",
      "\n",
      "\n",
      "epoch-29 loss : 0.01956004, loss_normal : 0.01714030, loss_coarse : 0.08076794, min_loss : 0.01929412, min_loss_normal : 0.01709493, min_loss_coarse : 0.08048404, wrong_element_sum : 15507444.00000000, same_data : 0.00%\n",
      "ae train 실행 시간: 128.069초, 전체 시작 시간 20250312_165249_979\n",
      "\n",
      "epoch-29 accuracy check\n"
     ]
    }
   ],
   "source": [
    "\n",
    "gpu = '2'\n",
    "Conv_net = True # True False\n",
    "SAE_net = True # True False\n",
    "\n",
    "# hyperparameter\n",
    "dataset_num = 16\n",
    "spike_length = 50 # coarse_com_mode일 때는 time step이 됨.\n",
    "num_cluster = 4  # 클러스터 수 설정 # 논문엔 4개라는데 여기서는 3개로 했네\n",
    "training_cycle = 1400 #1400 2400 # 그 초기 몇개까지만 cluster update할지\n",
    "\n",
    "\n",
    "batch_size = 32\n",
    "max_epoch = 10000\n",
    "learning_rate = 0.001\n",
    "normalize_on = True # True or False # 0부터1까지 normalize\n",
    "need_bias = False\n",
    "# first_layer_no_train = False\n",
    "lif_add_at_first = False\n",
    "my_seed = 42\n",
    "\n",
    "TIME = 50 # SAE일 때만 유효. coarse_com_mode일 때는 level_num이 됨. 즉 feature 개수.\n",
    "v_decay = 0.5 # -cor\n",
    "v_threshold = 0.25 # -cor\n",
    "v_reset = 0.0 # -cor # 10000이상 일 시 hard reset\n",
    "BPTT_on = True # +cor # True False\n",
    "\n",
    "SAE_hidden_nomean = True # True False\n",
    "\n",
    "current_time = datetime.datetime.now().strftime(\"%Y%m%d_%H%M%S\") + f\"_{str(int(datetime.datetime.now().microsecond / 1000)).zfill(3)}\"\n",
    "\n",
    "optimizer = 'Adam' #'Adam', 'SGD' # 둘다 준수함. loss 줄이는 거는 adam이 좋긴한데, cluster accuracy는 비슷함.\n",
    "\n",
    "coarse_com_mode = True # True False\n",
    "coarse_com_config = (0.999, -0.0) # (max, min) (0.999, -0.0) (1.0, -0.0) (2.0, -2.0) (3.0, -3.0)\n",
    "\n",
    "sae_l2_norm_bridge = True # True False\n",
    "sae_lif_bridge = False # True False\n",
    "\n",
    "accuracy_check_epoch_term = 1\n",
    "\n",
    "lif_add_at_last = False # True False\n",
    "\n",
    "two_channel_input = False # True False\n",
    "\n",
    "lateral_feature_num = 3\n",
    "\n",
    "lc_adc_on = False # True False\n",
    "\n",
    "converted_net_forward = False # True False\n",
    "\n",
    "pretrained_net = None\n",
    "# pretrained_net = '/home/bhkim003/github_folder/ByeonghyeonKim/my_snn/net_save/save_now_net_중요_20250110_203117_390.pth'\n",
    "# pretrained_net = '/home/bhkim003/github_folder/ByeonghyeonKim/my_snn/net_save/save_now_net_중요_20250113_134126_881_이거_94나오는거.pth'\n",
    "# pretrained_net =  '/home/bhkim003/github_folder/ByeonghyeonKim/my_snn/net_save/save_now_net_20250205_184901_132.pth'\n",
    "# pretrained_net =  '/home/bhkim003/github_folder/ByeonghyeonKim/my_snn/net_save/save_now_net_20250306_134219_133.pth'\n",
    "\n",
    "vth_mul_on = False # True False\n",
    "batch_norm_on = False # True False\n",
    "\n",
    "l2_norm_loss_weight = 0 #0.0001 #0.1 #  0 # 0초과면 작동\n",
    "\n",
    "QCFS_neuron_on = False # True False\n",
    "\n",
    "quantize_level_num = 0 # 0이면 quantize 안함. 1이상이면 그 수만큼 quantize함. # normalize_on 켜져야됨. 음수면 0~1norm안하고 quant함\n",
    "\n",
    "fusion_net = True # True False # SAE_net False, Conv_net True로 해라. TIME 적절하게 설정해주고.\n",
    "repeat_coding = False # True False #fusion_net에서 쓰이는 거임 # True면 repeat, False면 rate coding.\n",
    "\n",
    "sae_relu_on = False # True False\n",
    "\n",
    "conv1d_scaling = False # True False # conv1d때매 norm하고 (level_num-3)/level_num 곱해줌 # Conv_net and coarse_com_mode and normalize_on\n",
    "\n",
    "norm01 = True # True False # normalize_on = True일 때 01norm하는지 아님 걍 quant만 하는지.\n",
    "\n",
    "wandb.init(project= f'spike_sorting just run',save_code=False)\n",
    "\n",
    "\n",
    "cluster_train_system( \n",
    "    gpu = gpu,\n",
    "    Conv_net = Conv_net,\n",
    "    SAE_net = SAE_net,\n",
    "\n",
    "    # hyperparameter\n",
    "    dataset_num = dataset_num,\n",
    "    spike_length = spike_length,\n",
    "    num_cluster = num_cluster,  # 클러스터 수 설정 # 논문엔 4개라는데 여기서는 3개로 했네\n",
    "    training_cycle = training_cycle, # 그 초기 몇개까지만 cluster update할지\n",
    "\n",
    "\n",
    "    batch_size = batch_size,\n",
    "    max_epoch = max_epoch,\n",
    "    learning_rate = learning_rate,\n",
    "    normalize_on = normalize_on, # True or False #이거 안 씀 # 이거 별로 안 좋은 normalize같음 # 쓸 거면 다른 거 써라.\n",
    "    need_bias = need_bias,\n",
    "    # first_layer_no_train = False\n",
    "    lif_add_at_first = lif_add_at_first,\n",
    "    my_seed = my_seed,\n",
    "\n",
    "    TIME = TIME, # SAE일 때만 유효\n",
    "    v_decay = v_decay,\n",
    "    v_threshold = v_threshold,\n",
    "    v_reset = v_reset, # 10000이상 일 시 hard reset\n",
    "    BPTT_on = BPTT_on,\n",
    "\n",
    "    SAE_hidden_nomean = SAE_hidden_nomean,\n",
    "    \n",
    "    current_time = current_time,\n",
    "\n",
    "    optimizer = optimizer, #'Adam', 'SGD'\n",
    "\n",
    "    coarse_com_mode = coarse_com_mode,\n",
    "    coarse_com_config = coarse_com_config, # (max, min)\n",
    "\n",
    "    \n",
    "    sae_l2_norm_bridge = sae_l2_norm_bridge,\n",
    "    sae_lif_bridge = sae_lif_bridge,\n",
    "\n",
    "    accuracy_check_epoch_term = accuracy_check_epoch_term,\n",
    "    \n",
    "    lif_add_at_last = lif_add_at_last,\n",
    "\n",
    "    two_channel_input = two_channel_input,\n",
    "\n",
    "    lateral_feature_num = lateral_feature_num,\n",
    "\n",
    "    lc_adc_on = lc_adc_on, \n",
    "\n",
    "    converted_net_forward = converted_net_forward,\n",
    "\n",
    "    pretrained_net = pretrained_net,\n",
    "\n",
    "    vth_mul_on = vth_mul_on,\n",
    "    batch_norm_on = batch_norm_on,\n",
    "\n",
    "    l2_norm_loss_weight = l2_norm_loss_weight,\n",
    "    \n",
    "    QCFS_neuron_on = QCFS_neuron_on, # True False\n",
    "\n",
    "    quantize_level_num = quantize_level_num,\n",
    "\n",
    "    fusion_net = fusion_net, # True False\n",
    "    repeat_coding = repeat_coding,\n",
    "\n",
    "    sae_relu_on = sae_relu_on,\n",
    "\n",
    "    conv1d_scaling = conv1d_scaling,\n",
    "\n",
    "    norm01 = norm01,\n",
    "\n",
    "    )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Sweep code\n",
    "\n",
    "\n",
    "# from unittest import TextTestRunner\n",
    "\n",
    "\n",
    "# unique_name_hyper = 'cluster_train_system'\n",
    "# # run_name = 'spike_sorting'\n",
    "# sweep_start_time =  datetime.datetime.now().strftime(\"%Y%m%d_%H%M%S\") + f\"_{str(int(datetime.datetime.now().microsecond / 1000)).zfill(3)}\"\n",
    "# sweep_configuration = {\n",
    "#     'method': 'bayes', # 'random', 'bayes'\n",
    "#     'name': f'spike_sorting_{sweep_start_time}',\n",
    "#     'metric': {'goal': 'maximize', 'name': 'k_means_acc_best'},\n",
    "#     'parameters': \n",
    "#     {\n",
    "#         # \"gpu\": {\"values\": ['1']},  # 이건 sweep parameter아님. hyper_iter에서 직접 설정\n",
    "#         \"Conv_net\": {\"values\": [True]}, \n",
    "#         \"SAE_net\": {\"values\": [True]}, \n",
    "\n",
    "#         \"dataset_num\": {\"values\": [16]}, \n",
    "#         \"spike_length\": {\"values\": [50]},  \n",
    "#         \"num_cluster\": {\"values\": [4]}, \n",
    "#         \"training_cycle\": {\"values\": [1400]}, # [1400, 2400]\n",
    "\n",
    "#         \"batch_size\": {\"values\": [32]}, \n",
    "#         \"max_epoch\": {\"values\": [20]}, \n",
    "#         \"learning_rate\": {\"values\": [0.001, 0.0001]},\n",
    "#         \"normalize_on\": {\"values\": [True]},\n",
    "#         \"need_bias\": {\"values\": [False]}, # [True, False]\n",
    "\n",
    "#         \"lif_add_at_first\": {\"values\": [False]}, # [True, False]\n",
    "#         \"my_seed\": {\"values\": [42]}, \n",
    "\n",
    "#         \"TIME\": {\"values\": [50]}, #  [4,6,8,10]\n",
    "#         \"v_decay\": {\"values\": [0.125, 0.25,0.50,0.75,1.0]}, # [0.25,0.50,0.75]\n",
    "#         \"v_threshold\": {\"values\": [0.125, 0.25, 0.50, 0.75, 0.875, 1.0]}, # [0.25,0.50,0.75]\n",
    "#         \"v_reset\": {\"values\": [0.0, 10000.0]},  # [0.0, 10000.0]\n",
    "#         \"BPTT_on\": {\"values\": [True, False]},  # [True, False]\n",
    "\n",
    "#         \"SAE_hidden_nomean\": {\"values\": [True]}, # [True, False]\n",
    "\n",
    "#         # \"current_time\": {\"values\": [current_time]} #밑에서 직접설정됨.\n",
    "\n",
    "#         \"optimizer\": {\"values\": ['Adam', 'SGD']}, # ['Adam', 'SGD']\n",
    "\n",
    "#         \"coarse_com_mode\": {\"values\": [True]}, # [True, False]\n",
    "#         \"coarse_com_config\": {\"values\": [(0.999, -0.0)]}, # ['Adam', 'SGD']\n",
    "\n",
    "#         \"sae_l2_norm_bridge\": {\"values\": [True]}, # [True, False]\n",
    "#         \"sae_lif_bridge\": {\"values\": [False]}, # [False, True]\n",
    "        \n",
    "#         \"accuracy_check_epoch_term\": {\"values\": [1]}, \n",
    "\n",
    "#         \"lif_add_at_last\": {\"values\": [False]},# [True, False]\n",
    "\n",
    "#         \"two_channel_input\": {\"values\": [False]},# [True, False]\n",
    "\n",
    "#         \"lateral_feature_num\": {\"values\": [4]},# [True, False]\n",
    "\n",
    "#         \"lc_adc_on\": {\"values\": [False]},# [True, False]\n",
    "        \n",
    "#         \"converted_net_forward\": {\"values\": [False]},# [True, False]\n",
    "\n",
    "#         \"pretrained_net\": {\"values\": [None]},# [None]\n",
    "\n",
    "#         \"vth_mul_on\": {\"values\": [False]},# [True, False]\n",
    "#         \"batch_norm_on\": {\"values\": [False]},# [True, False]\n",
    "\n",
    "#         \"l2_norm_loss_weight\": {\"values\": [0]},\n",
    "\n",
    "#         \"QCFS_neuron_on\": {\"values\": [False]},   # [True, False]\n",
    "\n",
    "#         \"quantize_level_num\": {\"values\": [0]}, \n",
    "\n",
    "#         \"fusion_net\": {\"values\": [True]}, \n",
    "#         \"repeat_coding\": {\"values\": [False]}, \n",
    "\n",
    "#         \"sae_relu_on\": {\"values\": [False]}, \n",
    "\n",
    "#         \"conv1d_scaling\": {\"values\": [False]}, \n",
    "\n",
    "#         \"norm01\": {\"values\": [True]}, \n",
    "#      }\n",
    "# }\n",
    "\n",
    "\n",
    "# def hyper_iter():\n",
    "#     ### my_snn control board ########################\n",
    "#     wandb.init(save_code = False)\n",
    "#     gpu  =  '2'\n",
    "#     Conv_net  =  wandb.config.Conv_net\n",
    "#     SAE_net  =  wandb.config.SAE_net\n",
    "\n",
    "#     dataset_num  =  wandb.config.dataset_num\n",
    "#     spike_length  =  wandb.config.spike_length\n",
    "#     num_cluster  =  wandb.config.num_cluster\n",
    "#     training_cycle  =  wandb.config.training_cycle\n",
    "\n",
    "#     batch_size  =  wandb.config.batch_size\n",
    "#     max_epoch  =  wandb.config.max_epoch\n",
    "#     learning_rate  =  wandb.config.learning_rate\n",
    "#     normalize_on  =  wandb.config.normalize_on\n",
    "#     need_bias  =  wandb.config.need_bias\n",
    "\n",
    "#     lif_add_at_first  =  wandb.config.lif_add_at_first\n",
    "#     my_seed  =  wandb.config.my_seed\n",
    "\n",
    "\n",
    "#     TIME  =  wandb.config.TIME\n",
    "#     v_decay  =  wandb.config.v_decay\n",
    "#     v_threshold  =  wandb.config.v_threshold\n",
    "#     v_reset  =  wandb.config.v_reset\n",
    "#     BPTT_on  =  wandb.config.BPTT_on\n",
    "\n",
    "#     SAE_hidden_nomean  =  wandb.config.SAE_hidden_nomean\n",
    "    \n",
    "#     current_time =  datetime.datetime.now().strftime(\"%Y%m%d_%H%M%S\") + f\"_{str(int(datetime.datetime.now().microsecond / 1000)).zfill(3)}\"\n",
    "\n",
    "#     optimizer  =  wandb.config.optimizer\n",
    "\n",
    "#     coarse_com_mode = wandb.config.coarse_com_mode\n",
    "#     coarse_com_config = wandb.config.coarse_com_config # (max, min)\n",
    "\n",
    "#     sae_l2_norm_bridge = wandb.config.sae_l2_norm_bridge\n",
    "#     sae_lif_bridge = wandb.config.sae_lif_bridge\n",
    "\n",
    "#     accuracy_check_epoch_term = wandb.config.accuracy_check_epoch_term\n",
    "\n",
    "#     lif_add_at_last = wandb.config.lif_add_at_last\n",
    "\n",
    "#     two_channel_input = wandb.config.two_channel_input\n",
    "\n",
    "#     lateral_feature_num = wandb.config.lateral_feature_num\n",
    "\n",
    "#     lc_adc_on = wandb.config.lc_adc_on\n",
    "\n",
    "#     converted_net_forward = wandb.config.converted_net_forward\n",
    "\n",
    "#     pretrained_net = wandb.config.pretrained_net\n",
    "\n",
    "#     vth_mul_on = wandb.config.vth_mul_on\n",
    "#     batch_norm_on = wandb.config.batch_norm_on\n",
    "\n",
    "#     l2_norm_loss_weight = wandb.config.l2_norm_loss_weight\n",
    "\n",
    "#     QCFS_neuron_on = wandb.config.QCFS_neuron_on\n",
    "\n",
    "#     quantize_level_num = wandb.config.quantize_level_num\n",
    "\n",
    "#     fusion_net = wandb.config.fusion_net\n",
    "#     repeat_coding = wandb.config.repeat_coding\n",
    "\n",
    "#     sae_relu_on = wandb.config.sae_relu_on\n",
    "\n",
    "#     conv1d_scaling = wandb.config.conv1d_scaling\n",
    "\n",
    "#     norm01 = wandb.config.norm01\n",
    "\n",
    "#     cluster_train_system( \n",
    "#         gpu = gpu,\n",
    "#         Conv_net = Conv_net,\n",
    "#         SAE_net = SAE_net,\n",
    "\n",
    "#         # hyperparameter\n",
    "#         dataset_num = dataset_num,\n",
    "#         spike_length = spike_length,\n",
    "#         num_cluster = num_cluster,  # 클러스터 수 설정 # 논문엔 4개라는데 여기서는 3개로 했네\n",
    "#         training_cycle = training_cycle, # 그 초기 몇개까지만 cluster update할지\n",
    "\n",
    "\n",
    "#         batch_size = batch_size,\n",
    "#         max_epoch = max_epoch,\n",
    "#         learning_rate = learning_rate,\n",
    "#         normalize_on = normalize_on, # True or False #이거 안 씀 # 이거 별로 안 좋은 normalize같음 # 쓸 거면 다른 거 써라.\n",
    "#         need_bias = need_bias,\n",
    "#         # first_layer_no_train = False\n",
    "#         lif_add_at_first = lif_add_at_first,\n",
    "#         my_seed = my_seed,\n",
    "\n",
    "#         TIME = TIME, # SAE일 때만 유효\n",
    "#         v_decay = v_decay,\n",
    "#         v_threshold = v_threshold,\n",
    "#         v_reset = v_reset, # 10000이상 일 시 hard reset\n",
    "#         BPTT_on = BPTT_on,\n",
    "\n",
    "#         SAE_hidden_nomean = SAE_hidden_nomean,\n",
    "\n",
    "#         current_time = current_time,\n",
    "\n",
    "#         optimizer = optimizer, #'Adam', 'SGD'\n",
    "\n",
    "#         coarse_com_mode = coarse_com_mode,\n",
    "#         coarse_com_config = coarse_com_config, # (max, min)\n",
    "        \n",
    "#         sae_l2_norm_bridge = sae_l2_norm_bridge,\n",
    "#         sae_lif_bridge = sae_lif_bridge,\n",
    "\n",
    "#         accuracy_check_epoch_term = accuracy_check_epoch_term,\n",
    "\n",
    "#         lif_add_at_last = lif_add_at_last,\n",
    "        \n",
    "#         two_channel_input = two_channel_input,\n",
    "        \n",
    "#         lateral_feature_num = lateral_feature_num,\n",
    "\n",
    "#         lc_adc_on = lc_adc_on,\n",
    "\n",
    "#         converted_net_forward = converted_net_forward,\n",
    "\n",
    "#         pretrained_net = pretrained_net,\n",
    "\n",
    "#         vth_mul_on = vth_mul_on,\n",
    "#         batch_norm_on = batch_norm_on,\n",
    "\n",
    "#         l2_norm_loss_weight = l2_norm_loss_weight,\n",
    "\n",
    "#         QCFS_neuron_on = QCFS_neuron_on,\n",
    "\n",
    "#         quantize_level_num = quantize_level_num,\n",
    "\n",
    "#         fusion_net = fusion_net, \n",
    "#         repeat_coding = repeat_coding, \n",
    "\n",
    "#         sae_relu_on = sae_relu_on,\n",
    "\n",
    "#         conv1d_scaling = conv1d_scaling,\n",
    "\n",
    "#         norm01 = norm01,\n",
    "#         )\n",
    "    \n",
    "# # sweep_id = 'ygoj9jt4'\n",
    "# sweep_id = wandb.sweep(sweep=sweep_configuration, project=f'spike_sorting {unique_name_hyper}')\n",
    "# wandb.agent(sweep_id, function=hyper_iter, count=100000, project=f'spike_sorting {unique_name_hyper}')\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wandb.finish() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import matplotlib.pyplot as plt\n",
    "# from matplotlib.ticker import MaxNLocator\n",
    "# import pickle\n",
    "# import json\n",
    "\n",
    "# # current_time = '20250102_225243_972'\n",
    "\n",
    "# with open(f\"result_save/cluster_accuracy_history_{current_time}.pkl\", \"rb\") as f:\n",
    "#     data = pickle.load(f)\n",
    "\n",
    "\n",
    "# # JSON으로 저장\n",
    "# with open(f\"result_save/cluster_accuracy_history_{current_time}.json\", 'r') as f:\n",
    "#     loaded_hyperparameters = json.load(f)\n",
    "\n",
    "# loss_history = data['loss_history']\n",
    "# mean_cluster_accuracy_during_training_cycle_all_dataset_history = data['mean_cluster_accuracy_during_training_cycle_all_dataset_history']\n",
    "# mean_cluster_accuracy_post_training_cycle_all_dataset_history = data['mean_cluster_accuracy_post_training_cycle_all_dataset_history']\n",
    "# mean_cluster_accuracy_total_all_dataset_history = data['mean_cluster_accuracy_total_all_dataset_history']\n",
    "# print(data)\n",
    "# max_acc = 0\n",
    "# for i in mean_cluster_accuracy_post_training_cycle_all_dataset_history:\n",
    "#     if i[1] > max_acc:\n",
    "#         max_acc = i[1]\n",
    "\n",
    "# # 설정 정보 제목 작성\n",
    "# title = (\n",
    "#     f\"Dataset Num: {loaded_hyperparameters['dataset_num']}, Conv {loaded_hyperparameters['Conv_net']}, SAE {loaded_hyperparameters['SAE_net']}, Current time {loaded_hyperparameters['current_time']}, Spike Length: {loaded_hyperparameters['spike_length']}, Num Cluster: {loaded_hyperparameters['num_cluster']}, \"\n",
    "#     f\"Training Cycle: {loaded_hyperparameters['training_cycle']}, Batch Size: {loaded_hyperparameters['batch_size']}, Max Epoch: {loaded_hyperparameters['max_epoch']}, \\n\"\n",
    "#     f\"Learning Rate: {loaded_hyperparameters['learning_rate']}, Input Normalize: {loaded_hyperparameters['normalize_on']}, Need Bias: {loaded_hyperparameters['need_bias']}, \"\n",
    "#     f\"LIF Add at First: {loaded_hyperparameters['lif_add_at_first']}, TIME: {loaded_hyperparameters['TIME']}, Seed: {loaded_hyperparameters['my_seed']}, Best ACC: {max_acc:.2f}%\"\n",
    "# )\n",
    "\n",
    "# # 데이터 리스트와 라벨 설정 (Loss 제외)\n",
    "# data_list = [\n",
    "#     (\"Mean Cluster Accuracy (During Training Cycle)\", mean_cluster_accuracy_during_training_cycle_all_dataset_history),\n",
    "#     (\"Mean Cluster Accuracy (Post Training Cycle)\", mean_cluster_accuracy_post_training_cycle_all_dataset_history),\n",
    "#     (\"Mean Cluster Accuracy (Total)\", mean_cluster_accuracy_total_all_dataset_history),\n",
    "# ]\n",
    "\n",
    "# # 플롯 생성\n",
    "# fig, ax1 = plt.subplots(figsize=(12, 8))\n",
    "\n",
    "# # 첫 번째 y축: Accuracy 관련 데이터\n",
    "# for label, data in data_list:\n",
    "#     epochs, values = zip(*data)  # epoch, value 분리\n",
    "#     ax1.plot(epochs, values, label=label)\n",
    "\n",
    "# ax1.set_xlabel(\"Epoch\")\n",
    "# ax1.set_ylabel(\"Clurstering Accuracy [%]\", color=\"blue\")\n",
    "# ax1.tick_params(axis=\"y\", labelcolor=\"blue\")\n",
    "# ax1.legend(loc=\"center right\")\n",
    "# ax1.grid(True)\n",
    "\n",
    "# # x축을 정수만 표시하도록 설정\n",
    "# ax1.xaxis.set_major_locator(MaxNLocator(integer=True))\n",
    "\n",
    "# # 두 번째 y축: Loss History\n",
    "# ax2 = ax1.twinx()\n",
    "# epochs, values = zip(*loss_history)\n",
    "# ax2.plot(epochs, values, label=\"AE Loss History\", color=\"red\", linestyle=\"--\")\n",
    "# ax2.set_ylabel(\"Loss\", color=\"red\")\n",
    "# ax2.tick_params(axis=\"y\", labelcolor=\"red\")\n",
    "# ax2.legend(loc=\"center left\")\n",
    "\n",
    "# # 제목 추가\n",
    "# plt.title(title, fontsize=10)\n",
    "# plt.tight_layout()\n",
    "# plt.savefig(f'net_save/{current_time}', dpi=300, bbox_inches=\"tight\")  # dpi=300은 고해상도로 저장, bbox_inches=\"tight\"는 여백 최소화\n",
    "# plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# 데이터셋\n",
    "filename_for_plot = [\n",
    "    \"Easy1_noise05\", \"Easy1_noise10\", \"Easy1_noise15\", \"Easy1_noise20\",\n",
    "    \"Easy2_noise05\", \"Easy2_noise10\", \"Easy2_noise15\", \"Easy2_noise20\",\n",
    "    \"Difficult1_noise05\", \"Difficult1_noise10\", \"Difficult1_noise15\", \"Difficult1_noise20\",\n",
    "    \"Difficult2_noise05\", \"Difficult2_noise10\", \"Difficult2_noise15\", \"Difficult2_noise20\"\n",
    "]\n",
    "\n",
    "# Accuracy 데이터\n",
    "ANN_conv_accracy_set= [0.97935368, 0.97682709, 0.97028784, 0.96461825, 0.97524752, 0.95803571\n",
    ", 0.95746785, 0.92628774, 0.965412,  0.97805344, 0.94869403, 0.92110454\n",
    ", 0.96784232, 0.97551789, 0.91538462, 0.84446478]\n",
    "SNN_fc_accuracy_set = [0.97114475, 0.97643732, 0.84400578, 0.78977821, 0.96616915, 0.92830189\n",
    ", 0.86176032, 0.31984948, 0.80635401, 0.88769531, 0.61003861, 0.60377358\n",
    ", 0.9592668,  0.92870999, 0.78333333, 0.67271859]\n",
    "SNN_conv_accuracy_set = [0.97445601, 0.97737983, 0.97063072, 0.95998071, 0.96268657, 0.90566038\n",
    ", 0.82545997, 0.68391345, 0.96116994, 0.92138672, 0.80694981, 0.49602781\n",
    ", 0.83604888, 0.70611057, 0.69313725, 0.5819398 ]\n",
    "\n",
    "# 평균 계산\n",
    "average_ANN_conv = np.mean(ANN_conv_accracy_set)\n",
    "average_SNN_fc = np.mean(SNN_fc_accuracy_set)\n",
    "average_SNN_conv = np.mean(SNN_conv_accuracy_set)\n",
    "\n",
    "# 데이터 준비\n",
    "accuracies = np.array([ANN_conv_accracy_set, SNN_fc_accuracy_set, SNN_conv_accuracy_set])\n",
    "averages = np.array([average_ANN_conv, average_SNN_fc, average_SNN_conv])\n",
    "\n",
    "# 시각화\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "\n",
    "# 각 모델의 정확도 플롯\n",
    "ax.plot(accuracies[0], label='ANN Conv', marker='o', linestyle='-', color='blue')\n",
    "ax.plot(accuracies[1], label='SNN FC', marker='o', linestyle='-', color='green')\n",
    "ax.plot(accuracies[2], label='SNN Conv', marker='o', linestyle='-', color='red')\n",
    "\n",
    "# 평균값 플롯\n",
    "ax.axhline(y=average_ANN_conv, color='blue', linestyle='--', label=f'Average ANN Conv: {average_ANN_conv:.3f}')\n",
    "ax.axhline(y=average_SNN_fc, color='green', linestyle='--', label=f'Average SNN FC: {average_SNN_fc:.3f}')\n",
    "ax.axhline(y=average_SNN_conv, color='red', linestyle='--', label=f'Average SNN Conv: {average_SNN_conv:.3f}')\n",
    "\n",
    "# 레이블 추가\n",
    "ax.set_xticks(np.arange(len(filename_for_plot)))\n",
    "ax.set_xticklabels(filename_for_plot, rotation=45, ha='right')\n",
    "ax.set_ylabel('Accuracy')\n",
    "ax.set_title('Accuracy Comparison of Models on Datasets')\n",
    "ax.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import matplotlib.pyplot as plt\n",
    "import os  # 파일 경로 처리를 위한 모듈\n",
    "\n",
    "# CSV 파일 경로\n",
    "# csv_file_path = \"/home/bhkim003/github_folder/ByeonghyeonKim/my_snn/ae_test_deprecated/250115/sweep0_vth_mul.csv\" # vth_mul해서 sweep 돌린거\n",
    "csv_file_path = \"/home/bhkim003/github_folder/ByeonghyeonKim/my_snn/ae_test_deprecated/250115/sweep1.csv\"  #vth_mul안한거\n",
    "\n",
    "# 결과를 저장할 리스트\n",
    "tuple_list = []\n",
    "\n",
    "# CSV 파일 읽기\n",
    "with open(csv_file_path, 'r') as file:\n",
    "    reader = csv.DictReader(file)\n",
    "    for row in reader:\n",
    "        try:\n",
    "            # v_threshold, TIME, v_reset, converted_k_means_acc 값을 가져와 튜플로 변환\n",
    "            v_threshold = float(row[\"v_threshold\"])\n",
    "            time = int(row[\"TIME\"])\n",
    "            v_reset = int(row[\"v_reset\"])\n",
    "            converted_k_means_acc = float(row[\"converted_k_means_acc\"]) if row[\"converted_k_means_acc\"] else None\n",
    "\n",
    "            # 튜플 형태로 추가 (값이 None일 경우 처리할 수도 있음)\n",
    "            tuple_list.append((v_threshold, time, v_reset, converted_k_means_acc))\n",
    "        except ValueError as e:\n",
    "            print(f\"Error processing row {row}: {e}\")\n",
    "\n",
    "# 데이터를 TIME 기준으로 정렬\n",
    "tuple_list.sort(key=lambda x: x[1])  # TIME을 기준으로 오름차순 정렬\n",
    "\n",
    "# reset 방식에 따라 데이터를 나누기\n",
    "soft_reset = [t for t in tuple_list if t[2] == 0]\n",
    "hard_reset = [t for t in tuple_list if t[2] == 10000]\n",
    "\n",
    "# reset 방식과 v_threshold에 따라 색상 설정\n",
    "def plot_data(data, label_prefix, marker):\n",
    "    for v_threshold in [1.0]:  # v_threshold 기준으로 제한\n",
    "        filtered_data = [(t[1], t[3]) for t in data if t[0] == v_threshold]\n",
    "        if filtered_data:  # 해당 v_threshold 데이터가 있을 경우만 플롯\n",
    "            times, accuracies = zip(*filtered_data)  # x축(TIME), y축(converted_k_means_acc)\n",
    "            \n",
    "            plt.plot(\n",
    "                times,\n",
    "                accuracies,\n",
    "                marker,\n",
    "                label=f\"{label_prefix}, v_threshold={v_threshold}\",\n",
    "                linestyle=\"--\",\n",
    "            )\n",
    "            # 각 점에 accuracy 표시\n",
    "            for time, acc in filtered_data:\n",
    "                if acc == None:\n",
    "                    continue\n",
    "                plt.text(time, acc, f\"{acc:.2f}\", fontsize=8, ha=\"right\")\n",
    "\n",
    "# 그래프 초기화\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "# soft_reset (v_reset=0) 데이터 플롯\n",
    "plot_data(soft_reset, \"Soft Reset\", \"o\")\n",
    "\n",
    "# hard_reset (v_reset=10000) 데이터 플롯\n",
    "plot_data(hard_reset, \"Hard Reset\", \"x\")\n",
    "\n",
    "# baseline accuracy 가로선 추가\n",
    "baseline_accuracy = 94.43\n",
    "plt.axhline(y=baseline_accuracy, color=\"red\", linestyle=\"-\", label=f\"Baseline Accuracy ({baseline_accuracy}%)\")\n",
    "# baseline 텍스트 추가\n",
    "plt.text(\n",
    "    2000,  # x축 위치 (그래프 오른쪽 끝)\n",
    "    baseline_accuracy + 0.4,  # y축 위치 (baseline 위 약간)\n",
    "    f\"ANN Baseline ({baseline_accuracy}%)\",\n",
    "    color=\"red\",\n",
    "    fontsize=10,\n",
    "    ha=\"center\",\n",
    ")\n",
    "\n",
    "# CSV 파일 이름 가져오기\n",
    "csv_file_name = os.path.basename(csv_file_path)\n",
    "\n",
    "# 그래프 세부 설정\n",
    "plt.title(f\"Converted SNN K-Means Accuracy vs TIME STEP - {csv_file_name}\")\n",
    "plt.xlabel(\"TIME STEP\")\n",
    "plt.ylabel(\"Converted K-Means Accuracy [%]\")\n",
    "plt.legend(loc=\"lower right\")  # 범례를 오른쪽 아래로 이동\n",
    "plt.grid(True)\n",
    "\n",
    "# 그래프 출력\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aedat2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
