{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ssp.train.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x600 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import torch   \n",
    "import torch.nn as nn \n",
    "import torch.nn.functional as F   \n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import torch.optim as optim\n",
    "from scipy import io\n",
    "import itertools\n",
    "import math\n",
    "import datetime\n",
    "import wandb\n",
    "import pickle\n",
    "import json\n",
    "import time\n",
    "import sys\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import accuracy_score\n",
    "from scipy.optimize import linear_sum_assignment\n",
    "from snntorch import spikegen\n",
    "\n",
    "\n",
    "# my module import\n",
    "from modules import *\n",
    "\n",
    "# modules 폴더에 새모듈.py 만들면\n",
    "# modules/__init__py 파일에 form .새모듈 import * 하셈\n",
    "# 그리고 새모듈.py에서 from modules.새모듈 import * 하셈"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cluster_train_system( \n",
    "    gpu = '4',\n",
    "    Conv_net = True,\n",
    "    SAE_net = True,\n",
    "\n",
    "    # hyperparameter\n",
    "    dataset_num = 16,\n",
    "    spike_length = 50,\n",
    "    num_cluster = 4,  # 클러스터 수 설정 # 논문엔 4개라는데 여기서는 3개로 했네\n",
    "    training_cycle = 2400, # 그 초기 몇개까지만 cluster update할지\n",
    "\n",
    "\n",
    "    batch_size = 32,\n",
    "    max_epoch = 7000,\n",
    "    learning_rate = 0.001,\n",
    "    normalize_on = False, # True or False #이거 안 씀 # 이거 별로 안 좋은 normalize같음 # 쓸 거면 다른 거 써라.\n",
    "    need_bias = False,\n",
    "    # first_layer_no_train = False\n",
    "    lif_add_at_first = False,\n",
    "    my_seed = 42,\n",
    "\n",
    "    TIME = 10, # SAE일 때만 유효\n",
    "    v_decay = 0.5,\n",
    "    v_threshold = 0.5,\n",
    "    v_reset = 10000.0, # 10000이상 일 시 hard reset\n",
    "    BPTT_on = True,\n",
    "\n",
    "    SAE_hidden_nomean = True,\n",
    "    current_time = '20250101_210938_786',\n",
    "\n",
    "    optimizer = 'Adam',\n",
    "    coarse_com_mode = True,\n",
    "    coarse_com_config = (2.0, -2.0), # (max, min)\n",
    "\n",
    "    sae_l2_norm_bridge = True,\n",
    "    sae_lif_bridge = False,\n",
    "\n",
    "    accuracy_check_epoch_term = 5,\n",
    "    \n",
    "    lif_add_at_last = False,\n",
    "\n",
    "    two_channel_input = False,\n",
    "\n",
    "    lateral_feature_num = 4,\n",
    "\n",
    "    lc_adc_on = False, \n",
    "\n",
    "    converted_net_forward = False,\n",
    "\n",
    "    pretrained_net = None, \n",
    "\n",
    "    vth_mul_on = False,\n",
    "    batch_norm_on = False,\n",
    "\n",
    "    l2_norm_loss_weight = 0.0,\n",
    "\n",
    "    QCFS_neuron_on = False,\n",
    "    ):\n",
    "    if coarse_com_mode == True:\n",
    "        assert coarse_com_config[0] > coarse_com_config[1], 'coarse_com_config[0] > coarse_com_config[1]이어야 함'\n",
    "        assert SAE_net == True, 'coarse_com_mode는 SAE_net이 True일 때만 가능'\n",
    "    if two_channel_input == True:\n",
    "        assert Conv_net and coarse_com_mode, 'two_channel_input는 Conv_net이 True일 때만 가능'\n",
    "    if lc_adc_on == True:\n",
    "        assert coarse_com_mode and SAE_net, 'lc_adc_on은 coarse_com_mode와 SAE_net이 True일 때만 가능'\n",
    "    if converted_net_forward == True:\n",
    "        assert SAE_net == False, 'converted_net_forward는 SAE_net이 False일 때만 가능'\n",
    "    seed_assign(my_seed)\n",
    "    ## 함수 내 모든 로컬 변수 저장 ########################################################\n",
    "    hyperparameters = locals()\n",
    "    print(hyperparameters)\n",
    "    # JSON으로 저장\n",
    "    with open(f\"result_save/cluster_accuracy_history_{current_time}.json\", 'w') as f:\n",
    "        json.dump(hyperparameters, f, indent=4)\n",
    "    ######################################################################################\n",
    "\n",
    "    \n",
    "    wandb.config.update(hyperparameters)\n",
    "    wandb.run.name = f'{current_time}_SAE_net_{SAE_net}_v_threshold_{v_threshold}'\n",
    "    wandb.define_metric(\"best_mean_cluster_accuracy_post_training_cycle_all_dataset2\", summary=\"max\")\n",
    "\n",
    "\n",
    "    my_path_ground_BH = '/data2/spike_sorting/quiroga/BH/'\n",
    "\n",
    "\n",
    "    filename = [\"C_Easy1_noise005.mat\", \"C_Easy1_noise01.mat\", \"C_Easy1_noise015.mat\", \"C_Easy1_noise02.mat\",\n",
    "                \"C_Easy2_noise005.mat\", \"C_Easy2_noise01.mat\", \"C_Easy2_noise015.mat\", \"C_Easy2_noise02.mat\",\n",
    "                \"C_Difficult1_noise005.mat\", \"C_Difficult1_noise01.mat\", \"C_Difficult1_noise015.mat\", \"C_Difficult1_noise02.mat\",\n",
    "                \"C_Difficult2_noise005.mat\", \"C_Difficult2_noise01.mat\", \"C_Difficult2_noise015.mat\", \"C_Difficult2_noise02.mat\"]\n",
    "\n",
    "\n",
    "    spike_tot = [\"BH_Spike_e1n005.npy\", \"BH_Spike_e1n010.npy\", \"BH_Spike_e1n015.npy\", \"BH_Spike_e1n020.npy\",\n",
    "                \"BH_Spike_e2n005.npy\", \"BH_Spike_e2n010.npy\", \"BH_Spike_e2n015.npy\", \"BH_Spike_e2n020.npy\",\n",
    "                \"BH_Spike_d1n005.npy\", \"BH_Spike_d1n010.npy\", \"BH_Spike_d1n015.npy\", \"BH_Spike_d1n020.npy\",\n",
    "                \"BH_Spike_d2n005.npy\", \"BH_Spike_d2n010.npy\", \"BH_Spike_d2n015.npy\", \"BH_Spike_d2n020.npy\"]\n",
    "\n",
    "    label_tot = [\"BH_Label_e1n005.npy\", \"BH_Label_e1n010.npy\", \"BH_Label_e1n015.npy\", \"BH_Label_e1n020.npy\",\n",
    "                \"BH_Label_e2n005.npy\", \"BH_Label_e2n010.npy\", \"BH_Label_e2n015.npy\", \"BH_Label_e2n020.npy\",\n",
    "                \"BH_Label_d1n005.npy\", \"BH_Label_d1n010.npy\", \"BH_Label_d1n015.npy\", \"BH_Label_d1n020.npy\",\n",
    "                \"BH_Label_d2n005.npy\", \"BH_Label_d2n010.npy\", \"BH_Label_d2n015.npy\", \"BH_Label_d2n020.npy\"]\n",
    "\n",
    "    template =  [\"BH_Spike_TEMPLATE_e1n005.npy\", \"BH_Spike_TEMPLATE_e1n010.npy\", \"BH_Spike_TEMPLATE_e1n015.npy\", \"BH_Spike_TEMPLATE_e1n020.npy\",\n",
    "                \"BH_Spike_TEMPLATE_e2n005.npy\", \"BH_Spike_TEMPLATE_e2n010.npy\", \"BH_Spike_TEMPLATE_e2n015.npy\", \"BH_Spike_TEMPLATE_e2n020.npy\",\n",
    "                \"BH_Spike_TEMPLATE_d1n005.npy\", \"BH_Spike_TEMPLATE_d1n010.npy\", \"BH_Spike_TEMPLATE_d1n015.npy\", \"BH_Spike_TEMPLATE_d1n020.npy\",\n",
    "                \"BH_Spike_TEMPLATE_d2n005.npy\", \"BH_Spike_TEMPLATE_d2n010.npy\", \"BH_Spike_TEMPLATE_d2n015.npy\", \"BH_Spike_TEMPLATE_d2n020.npy\"]\n",
    "\n",
    "    AE_train_path_gt_detect = 'BH_quiroga_training_dataset_gt_detect.pt' \n",
    "    AE_test_path_gt_detect = 'BH_quiroga_test_dataset_gt_detect.pt'\n",
    "\n",
    "    AE_train_path_real_detect = 'BH_quiroga_training_dataset_real_detect.pt'\n",
    "    AE_test_path_real_detect = 'BH_quiroga_test_dataset_real_detect.pt'\n",
    "\n",
    "    AE_train_data = AE_train_path_real_detect #AE_train_path_gt_detect #AE_train_path_real_detect\n",
    "    AE_test_data = AE_test_path_real_detect #AE_test_path_gt_detect  #AE_test_path_real_detect\n",
    "\n",
    "    # thr_tot = np.array([0.5, 0.5, 0.55, 0.7, 0.5, 0.5, 0.55, 0.7, 0.5, 0.5, 0.55, 0.7, 0.5, 0.5, 0.55, 0.7])\n",
    "    cos_thr = np.array([0.95, 0.95, 0.95, 0.95, 0.95, 0.95, 0.95, 0.85, 0.95, 0.9, 0.8, 0.95, 0.95, 0.95, 0.95, 0.8])\n",
    "    # tem=10\n",
    "    # cos_thr = np.array([tem, tem, tem, tem, tem, tem, tem, tem, tem, tem, tem, tem, tem, tem, tem, tem, ])\n",
    "\n",
    "    print('cos_thr', cos_thr)\n",
    "    \n",
    "    os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\" \n",
    "    os.environ[\"CUDA_VISIBLE_DEVICES\"]= gpu\n",
    "\n",
    "\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "\n",
    "    if coarse_com_mode == True:\n",
    "        level_num = TIME\n",
    "        TIME = spike_length\n",
    "        spike_length = level_num\n",
    "        level_interval = (coarse_com_config[0] - coarse_com_config[1]) / (level_num-1)  # max - min\n",
    "        levels = [coarse_com_config[1] + level_interval * i for i in range(level_num)]\n",
    "        levels = torch.tensor(levels).to(torch.float).to(device)\n",
    "        levels = levels.repeat(TIME,1) \n",
    "        # print('levels', levels, levels.shape) # TIME, level_num\n",
    "\n",
    "    n_sample = spike_length\n",
    "\n",
    "    class spikedataset(Dataset):\n",
    "        def __init__(self, path, transform = None):    \n",
    "            self.transform = transform\n",
    "            self.spike = torch.load(path)\n",
    "            \n",
    "        def __getitem__(self, index):\n",
    "            spike = self.spike[index]            \n",
    "            if self.transform is not None:\n",
    "                spike = self.transform(spike)\n",
    "            return spike\n",
    "        \n",
    "        def __len__(self):\n",
    "            return len(self.spike)\n",
    "\n",
    "    train_dataset = spikedataset(my_path_ground_BH + AE_train_data)\n",
    "    train_loader = DataLoader(dataset = train_dataset, batch_size = batch_size, shuffle = True)\n",
    "\n",
    "    test_dataset = spikedataset(my_path_ground_BH + AE_test_data)\n",
    "    test_loader = DataLoader(dataset = test_dataset, batch_size = batch_size, shuffle = False)\n",
    "\n",
    "\n",
    "    # vth_mul_on = True # True False\n",
    "    # batch_norm_on = True # True False\n",
    "\n",
    "\n",
    "    # 모델 초기화\n",
    "    if SAE_net == False: # 여기서는 l2norm, lif bridge 둘 다 true면 l2norm먼저\n",
    "        if Conv_net == True:\n",
    "            input_channels = 2 if two_channel_input else 1\n",
    "            net = Autoencoder_conv1(input_channels=input_channels, input_length=n_sample, encoder_ch = [32, 64, 96], fc_dim = lateral_feature_num, padding = 0, stride = 2, kernel_size = 3, need_bias=need_bias, l2norm_bridge=sae_l2_norm_bridge, relu_bridge=sae_lif_bridge, activation_collector_on=False,\n",
    "                                    batch_norm_on=batch_norm_on, QCFS_neuron_on=QCFS_neuron_on).to(device)\n",
    "            net = torch.nn.DataParallel(net)\n",
    "            if converted_net_forward:\n",
    "                converted_net = SAE_converted_conv1(input_channels=input_channels, input_length=n_sample, encoder_ch = [32, 64, 96], fc_dim = lateral_feature_num, padding = 0, stride = 2, kernel_size = 3, \n",
    "                                    synapse_fc_trace_const1=1, \n",
    "                                    synapse_fc_trace_const2=v_decay, #안씀 \n",
    "                                    TIME=TIME, v_init=0.0, v_decay=v_decay, v_threshold=v_threshold, v_reset=v_reset, \n",
    "                                    sg_width=4.0, surrogate='sigmoid', BPTT_on=BPTT_on, need_bias=need_bias, lif_add_at_first=lif_add_at_first,\n",
    "                                    sae_l2_norm_bridge = sae_l2_norm_bridge, sae_lif_bridge = sae_lif_bridge, lif_add_at_last=lif_add_at_last,\n",
    "                                    vth_mul_on=vth_mul_on, batch_norm_on=batch_norm_on).to(device) # lif bridge는 무조건 들어가게 해놨음.\n",
    "                converted_net = torch.nn.DataParallel(converted_net)\n",
    "                print('converted_net', converted_net)\n",
    "        else:\n",
    "            net = Autoencoder_only_FC(encoder_ch=[400, lateral_feature_num], decoder_ch=[400,n_sample], n_sample=n_sample, need_bias=need_bias, l2norm_bridge=sae_l2_norm_bridge, relu_bridge=sae_lif_bridge, activation_collector_on=False,\n",
    "                                    batch_norm_on=batch_norm_on, QCFS_neuron_on=QCFS_neuron_on).to(device)\n",
    "            net = torch.nn.DataParallel(net)\n",
    "            if converted_net_forward:\n",
    "                converted_net = SAE_converted_fc(encoder_ch=[400, lateral_feature_num], \n",
    "                                    decoder_ch=[400, n_sample], \n",
    "                                    in_channels=n_sample, # in_channel 이 여기선 걍 lenght.\n",
    "                                    synapse_fc_trace_const1=1,\n",
    "                                    synapse_fc_trace_const2=v_decay,  #안씀 \n",
    "                                    TIME=TIME, v_init=0.0, v_decay=v_decay, v_threshold=v_threshold, v_reset=v_reset, \n",
    "                                    sg_width=4.0, surrogate='sigmoid', BPTT_on=BPTT_on, need_bias=need_bias, lif_add_at_first=lif_add_at_first,\n",
    "                                    sae_l2_norm_bridge = sae_l2_norm_bridge, sae_lif_bridge = sae_lif_bridge, lif_add_at_last=lif_add_at_last,\n",
    "                                    vth_mul_on=vth_mul_on, batch_norm_on=batch_norm_on).to(device) # lif bridge는 무조건 들어가게 해놨음.\n",
    "                converted_net = torch.nn.DataParallel(converted_net)\n",
    "                # print('converted_net', converted_net)\n",
    "    else: # 여기서는 l2norm, lif bridge 둘 다 true면 lif또는 relu먼저\n",
    "        if Conv_net == True: \n",
    "            input_channels = 2 if two_channel_input else 1\n",
    "            net = SAE_conv1(input_channels=input_channels, input_length=n_sample, encoder_ch = [32, 64, 96], fc_dim = lateral_feature_num, padding = 0, stride = 2, kernel_size = 3, \n",
    "                                synapse_fc_trace_const1=1, \n",
    "                                synapse_fc_trace_const2=v_decay, #안씀 \n",
    "                                TIME=TIME, v_init=0.0, v_decay=v_decay, v_threshold=v_threshold, v_reset=v_reset, \n",
    "                                sg_width=4.0, surrogate='sigmoid', BPTT_on=BPTT_on, need_bias=need_bias, lif_add_at_first=lif_add_at_first,\n",
    "                                sae_l2_norm_bridge = sae_l2_norm_bridge, sae_lif_bridge = sae_lif_bridge, lif_add_at_last=lif_add_at_last).to(device)\n",
    "            net = torch.nn.DataParallel(net)\n",
    "        else:\n",
    "            net = SAE_fc_only(encoder_ch=[400, lateral_feature_num], \n",
    "                                decoder_ch=[400, n_sample], \n",
    "                                in_channels=n_sample, # in_channel 이 여기선 걍 lenght.\n",
    "                                synapse_fc_trace_const1=1,\n",
    "                                synapse_fc_trace_const2=v_decay,  #안씀 \n",
    "                                TIME=TIME, v_init=0.0, v_decay=v_decay, v_threshold=v_threshold, v_reset=v_reset, \n",
    "                                sg_width=4.0, surrogate='sigmoid', BPTT_on=BPTT_on, need_bias=need_bias, lif_add_at_first=lif_add_at_first,\n",
    "                                sae_l2_norm_bridge = sae_l2_norm_bridge, sae_lif_bridge = sae_lif_bridge, lif_add_at_last=lif_add_at_last).to(device)\n",
    "            net = torch.nn.DataParallel(net)\n",
    "\n",
    "    # net = torch.load('/home/bhkim003/github_folder/ByeonghyeonKim/my_snn/net_save/save_now_net_AE_re_e7000.pth')\n",
    "    # net = torch.load('/home/bhkim003/github_folder/ByeonghyeonKim/my_snn/net_save/save_now_net_20250101_210938_786.pth')\n",
    "    # load했으면 torch.nn.DataParallel 하지마\n",
    "    # net.module.load_state_dict(torch.load('/home/bhkim003/github_folder/ByeonghyeonKim/my_snn/net_save/save_now_net_annbase_20250108_210641_941.pth'))\n",
    "    if pretrained_net != None:\n",
    "        ######################## 모델이 달라서 dict로 weight만 넣고싶을 때\n",
    "        # # 저장된 가중치 로드\n",
    "        saved_state_dict = torch.load(pretrained_net)\n",
    "        current_state_dict = net.module.state_dict()\n",
    "\n",
    "        # 함수 호출로 가중치 매핑\n",
    "        updated_state_dict = map_and_load_weights(saved_state_dict, current_state_dict)\n",
    "\n",
    "        # 업데이트된 state_dict를 네트워크에 로드\n",
    "        net.module.load_state_dict(updated_state_dict)\n",
    "        ######################## 모델이 달라서 dict로 weight만 넣고싶을 때\n",
    "\n",
    "        ############## 일반적일 때\n",
    "        # net.module.load_state_dict(torch.load(pretrained_net))\n",
    "        ############## 일반적일 때\n",
    "    \n",
    "        # pre_net = Autoencoder_conv1(input_channels=input_channels, input_length=n_sample, encoder_ch = [32, 64, 96], fc_dim = lateral_feature_num, padding = 0, stride = 2, kernel_size = 3, need_bias=need_bias, l2norm_bridge=sae_l2_norm_bridge, relu_bridge=sae_lif_bridge, activation_collector_on=False,\n",
    "        #                         batch_norm_on=batch_norm_on, QCFS_neuron_on=False).to(device)\n",
    "        # pre_net = torch.nn.DataParallel(net)\n",
    "        # pre_net.module.load_state_dict(torch.load(pretrained_net))\n",
    "        # copy_weights(pre_net.module.encoder , net.module.encoder )\n",
    "        # copy_weights(pre_net.module.decoder , net.module.decoder  )\n",
    "\n",
    "        \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    wandb.watch(net, log=\"all\", log_freq = 10)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    if SAE_net == True:\n",
    "        assert 'SAE' in net.module.__class__.__name__\n",
    "\n",
    "\n",
    "\n",
    "    net = net.to(device)\n",
    "    print(f\"Total number of encoder parameters: {sum(p.numel() for p in net.module.encoder.parameters())}\")\n",
    "    print(net)\n",
    "    print('Device:',device)\n",
    "\n",
    "    \n",
    "    if optimizer == 'Adam':\n",
    "        optimizer = optim.Adam(net.parameters(), lr=learning_rate)\n",
    "    elif optimizer == 'SGD':\n",
    "        optimizer = optim.SGD(net.parameters(), lr = learning_rate, momentum = 0.9)\n",
    "    else:\n",
    "        assert False, 'optimizer를 잘못 입력했습니다.'\n",
    "        \n",
    "    loss_history = []\n",
    "    mean_cluster_accuracy_during_training_cycle_all_dataset_history = []\n",
    "    mean_cluster_accuracy_post_training_cycle_all_dataset_history = []\n",
    "    mean_cluster_accuracy_total_all_dataset_history = []\n",
    "\n",
    "    tau = np.zeros(num_cluster)\n",
    "\n",
    "    print(f\"\\nStart Training, current_time = {current_time}\")\n",
    "    mean_cluster_accuracy_post_training_cycle_all_dataset = 0\n",
    "    best_mean_cluster_accuracy_post_training_cycle_all_dataset = 0\n",
    "\n",
    "    if SAE_net == True:\n",
    "        assert 'SAE' in net.module.__class__.__name__\n",
    "        \n",
    "    k_means_acc_best = 0\n",
    "    for epoch in range(max_epoch):\n",
    "        print()\n",
    "        l2_loss_bin= 0\n",
    "        ae_train_start_time = time.time()\n",
    "        running_loss = 0.0\n",
    "        iter = 0\n",
    "        net.train()\n",
    "        # if True or max_epoch != 1:\n",
    "        if max_epoch != 1:\n",
    "            for data in train_loader:\n",
    "                optimizer.zero_grad()\n",
    "                data = data.to(device)\n",
    "                data = zero_to_one_normalize_features(data) if normalize_on else data\n",
    "                spike_backup = data\n",
    "                spike = data\n",
    "                spike = spike.to(device) # batch, feature\n",
    "                if coarse_com_mode == True and 'SAE' in net.module.__class__.__name__:\n",
    "                    spike = spike.unsqueeze(2).repeat(1, 1, level_num) # spike_length == level_num # (batch, time, feature)로 변환 \n",
    "                    spike = (spike > levels).to(torch.float) \n",
    "\n",
    "                    spike = (spike == 0).cumsum(dim=-1).eq(1).to(torch.float) if lc_adc_on == True else spike\n",
    "\n",
    "                    # spike: batch, time, level_num\n",
    "                    # levels: time, level_num\n",
    "                    if Conv_net == True:\n",
    "                        spike = spike.unsqueeze(-2) # batch, time, in_channel, feature or batch in_channel,feature\n",
    "                        if two_channel_input == True:\n",
    "                            spike_backup = spike_backup.to(device)\n",
    "                            spike_backup = spike_backup.unsqueeze(2).repeat(1, 1, level_num) # spike_length == level_num # (batch, time, feature)로 변환 \n",
    "                            spike_backup = (spike_backup <= levels).to(torch.float) \n",
    "                            spike_backup = (spike_backup == 1).cumsum(dim=-1).eq(1).to(torch.float) if lc_adc_on == True else spike_backup\n",
    "                            spike_backup = spike_backup.unsqueeze(-2)\n",
    "                            spike = torch.cat((spike, spike_backup), dim=-2)\n",
    "                    assert spike.shape[0] == batch_size and spike.shape[1] == TIME\n",
    "                elif 'SAE' in net.module.__class__.__name__:\n",
    "                    spike = spike.unsqueeze(-1).repeat(1, 1, TIME).permute(0,2,1) # (batch, time, feature)로 변환\n",
    "                    if Conv_net == True:\n",
    "                        spike = spike.unsqueeze(-2) # batch, time, in_channel, feature or batch in_channel,feature\n",
    "                else:\n",
    "                    if Conv_net == True:\n",
    "                        spike = spike.unsqueeze(-2) #batch in_channel,feature\n",
    "\n",
    "                # for i in range (3):\n",
    "                #     plot_spike(spike[i,:,0,:].cpu().numpy())\n",
    "                #     plot_spike(spike[i,:,1,:].cpu().numpy())\n",
    "                # assert False\n",
    "                        \n",
    "                # spike_class = net(spike) # batch, time, feature\n",
    "                encoded_spike = net.module.encoder(spike)\n",
    "                spike_class = net.module.decoder(encoded_spike)\n",
    "\n",
    "                if coarse_com_mode == True and 'SAE' in net.module.__class__.__name__:\n",
    "                    criterion = nn.MSELoss().to(device)\n",
    "                    # loss1 = nn.MSELoss()(spike_class[..., 5:25], spike[..., 5:25])\n",
    "                    # loss2 = nn.MSELoss()(spike_class[..., 0:5], spike[..., 0:5])\n",
    "                    # loss3 = nn.MSELoss()(spike_class[..., 25:spike_length], spike[..., 25:spike_length])\n",
    "                    # loss = loss1 * 2.125 + (loss2 + loss3)/4\n",
    "\n",
    "                    # loss1 = nn.MSELoss()(spike_class[..., 5:25, :], spike[..., 5:25, :])\n",
    "                    # loss2 = nn.MSELoss()(spike_class[..., 0:5, :], spike[..., 0:5, :])\n",
    "                    # loss3 = nn.MSELoss()(spike_class[..., 25:spike_length, :], spike[..., 25:spike_length, :])\n",
    "                    # loss = loss1 * 2.125 + (loss2 + loss3)/4\n",
    "\n",
    "                    loss = criterion(spike_class, spike)\n",
    "                elif 'SAE' in net.module.__class__.__name__:\n",
    "                    criterion = nn.MSELoss().to(device)\n",
    "                    loss1 = criterion(spike_class[..., 5:25], spike[..., 5:25])\n",
    "                    loss2 = criterion(spike_class[..., 0:5], spike[..., 0:5])\n",
    "                    loss3 = criterion(spike_class[..., 25:spike_length], spike[..., 25:spike_length])\n",
    "                    loss = loss1 * 2.125 + (loss2 + loss3)/4\n",
    "                    assert spike_length > 25, 'spike_length가 25보다 작음'\n",
    "                else:\n",
    "\n",
    "                    criterion = nn.MSELoss().to(device)\n",
    "                    loss1 = criterion(spike_class[..., 5:25], spike[..., 5:25])\n",
    "                    loss2 = criterion(spike_class[..., 0:5], spike[..., 0:5])\n",
    "                    loss3 = criterion(spike_class[..., 25:spike_length], spike[..., 25:spike_length])\n",
    "                    loss = loss1 * 2.125 + (loss2 + loss3)/4\n",
    "                    assert spike_length > 25, 'spike_length가 25보다 작음'\n",
    "\n",
    "                    if l2_norm_loss_weight > 0:\n",
    "                        assert len(encoded_spike.shape) == 2, 'time 성분 없는 걸로'\n",
    "                        l2_loss = l2_norm_loss(encoded_spike, target_norm=1.0)  # L2Norm Loss 계산, l2 1.0되게.\n",
    "                        loss = loss + l2_loss*l2_norm_loss_weight\n",
    "                        l2_loss_bin += l2_loss.item()\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                running_loss += loss.item()\n",
    "                # print(f'\\nepoch-{epoch}, running_loss : {running_loss:.5f}, iter percent {iter/len(train_loader)*100:.2f}%')\n",
    "                iter += 1\n",
    "        else:\n",
    "            print('\\n\\n\\n max_epoch 1이면 Train 안함!!!!!!!!!!!!!!!!!!!!!')\n",
    "        if l2_norm_loss_weight > 0:\n",
    "            print('l2_loss_bin', l2_loss_bin/len(train_loader))\n",
    "        avg_loss = running_loss / len(train_loader)\n",
    "        assert not np.isnan(avg_loss), f\"Error: avg_loss is NaN! Running loss: {running_loss}, Length of train_loader: {len(train_loader)}\"\n",
    "        loss_history.append((epoch, avg_loss))\n",
    "        print(f'\\nepoch-{epoch} loss : {avg_loss:.5f}')\n",
    "        print(f\"ae train 실행 시간: {time.time()-ae_train_start_time:.3f}초, 전체 시작 시간 {current_time}\")\n",
    "\n",
    "        # plot_activation_distribution(net)\n",
    "\n",
    "        if SAE_net == False and converted_net_forward == True:\n",
    "            source_encoder = net.module.encoder \n",
    "            target_encoder = converted_net.module.encoder  \n",
    "            copy_weights(source_encoder, target_encoder)\n",
    "\n",
    "        cluster_accuracy_during_training_cycle_all_dataset = np.zeros(dataset_num)\n",
    "        cluster_accuracy_post_training_cycle_all_dataset = np.zeros(dataset_num)\n",
    "        cluster_accuracy_total_all_dataset = np.zeros(dataset_num)    \n",
    "\n",
    "        k_means_acc = 0\n",
    "        converted_k_means_acc = 0\n",
    "        if(epoch % accuracy_check_epoch_term == 0 or epoch == 1 or epoch == max_epoch-1): \n",
    "            accuracy_check_start_time = time.time()\n",
    "            print(f'\\nepoch-{epoch} accuracy check')\n",
    "            k_means_bin_origin_feature = []\n",
    "            k_means_bin = []\n",
    "            converted_k_means_bin = []\n",
    "            for ds in range(dataset_num):\n",
    "                # print('\\n', spike_tot[ds])\n",
    "\n",
    "                spike_template = np.load(my_path_ground_BH + template[ds])\n",
    "                spike = np.load(my_path_ground_BH + spike_tot[ds])\n",
    "                label = np.load(my_path_ground_BH + label_tot[ds])\n",
    "                spike_template = torch.from_numpy(spike_template).to(device)\n",
    "                spike = torch.from_numpy(spike).to(device)\n",
    "                spike_template = zero_to_one_normalize_features(spike_template) if normalize_on else spike_template\n",
    "                spike = zero_to_one_normalize_features(spike) if normalize_on else spike\n",
    "                \n",
    "                hidden_size = lateral_feature_num*TIME if 'SAE' in net.module.__class__.__name__ and SAE_hidden_nomean == True else lateral_feature_num\n",
    "\n",
    "                Cluster = np.zeros((num_cluster, hidden_size))\n",
    "                assert Cluster.shape[-1] == hidden_size, '이거 hidden dim 4 아니게 할 거면 잘 바꿔라'\n",
    "                \n",
    "\n",
    "\n",
    "                net.eval()\n",
    "                with torch.no_grad():\n",
    "                    spike_torch = spike_template.float()\n",
    "                    spike_torch = spike_torch[:num_cluster]\n",
    "                    spike_backup = spike_torch\n",
    "                    spike_torch = spike_torch.to(device)\n",
    "                    if coarse_com_mode == True and 'SAE' in net.module.__class__.__name__:\n",
    "                        spike_torch = spike_torch.unsqueeze(2).repeat(1, 1, level_num) # spike_length == level_num # (batch, time, feature)로 변환 \n",
    "                        spike_torch = (spike_torch > levels).to(torch.float) \n",
    "                        spike_torch = (spike_torch == 0).cumsum(dim=-1).eq(1).to(torch.float) if lc_adc_on == True else spike_torch\n",
    "                        if Conv_net == True:\n",
    "                            spike_torch = spike_torch.unsqueeze(-2) # batch, time, in_channel, feature or batch in_channel,feature\n",
    "                            if two_channel_input == True:\n",
    "                                spike_backup = spike_backup.to(device)\n",
    "                                spike_backup = spike_backup.unsqueeze(2).repeat(1, 1, level_num) # spike_length == level_num # (batch, time, feature)로 변환 \n",
    "                                spike_backup = (spike_backup <= levels).to(torch.float) \n",
    "                                spike_backup = (spike_backup == 1).cumsum(dim=-1).eq(1).to(torch.float) if lc_adc_on == True else spike_backup\n",
    "                                spike_backup = spike_backup.unsqueeze(-2) # batch, time, in_channel, feature\n",
    "                                spike_torch = torch.cat((spike_torch, spike_backup), dim=-2)\n",
    "                    elif 'SAE' in net.module.__class__.__name__:\n",
    "                        spike_torch = spike_torch.unsqueeze(1).repeat(1, TIME, 1) # (batch, time, feature)로 변환\n",
    "                        if Conv_net == True:\n",
    "                            spike_torch = spike_torch.unsqueeze(-2) # batch, time, in_channel, feature or batch in_channel,feature\n",
    "                    else:\n",
    "                        if Conv_net == True:\n",
    "                            spike_torch = spike_torch.unsqueeze(-2) #batch in_channel,feature\n",
    "                        if converted_net_forward == True:\n",
    "                            spike_torch_spikegen = spikegen.rate(spike_torch, num_steps=TIME).transpose(0, 1)\n",
    "                    ### forward #######################################################\n",
    "                    inner_inf = net.module.encoder(spike_torch)\n",
    "                    if SAE_net == False and converted_net_forward == True:\n",
    "                        converted_inner_inf = converted_net.module.encoder(spike_torch_spikegen)\n",
    "                    ### forward #######################################################\n",
    "\n",
    "                    # for i in range(3):\n",
    "                    #     plot_spike(spike_torch[i,:,:].cpu().numpy())\n",
    "                    #     plot_spike(inner_inf[i,:].cpu().numpy())\n",
    "                    #     plot_spike(net.module.decoder(inner_inf)[i,:,:].cpu().numpy())\n",
    "                        \n",
    "                    # if 'SAE' in net.module.__class__.__name__:\n",
    "                    #     tensors = [inner_inf[0][i] for i in range(TIME)] \n",
    "                    #     all_equal = all(torch.equal(tensors[0], t) for t in tensors)\n",
    "                    #     print(all_equal, inner_inf)\n",
    "\n",
    "                    if 'SAE' in net.module.__class__.__name__:\n",
    "                        if SAE_hidden_nomean == True:\n",
    "                            inner_inf = inner_inf.reshape(inner_inf.shape[0],-1)# time*feature 펼치기\n",
    "                        else:\n",
    "                            inner_inf = inner_inf.mean(dim=1)# Time 방향으로 평균\n",
    "\n",
    "                    Cluster = inner_inf.cpu().detach().numpy()\n",
    "\n",
    "                encoder_batch = 128\n",
    "                spike_hidden = np.zeros((len(spike), hidden_size))\n",
    "                converted_spike_hidden = np.zeros((len(spike), hidden_size))\n",
    "                net.eval()\n",
    "                with torch.no_grad():\n",
    "                    now_index = 0\n",
    "                    while (1):\n",
    "                        now_end_index = now_index+encoder_batch if now_index+encoder_batch < len(spike) else len(spike)\n",
    "                        spike_batch = spike[now_index:now_end_index] \n",
    "                        spike_torch = spike_batch\n",
    "                        spike_torch = spike_torch.float()\n",
    "                        spike_backup = spike_torch\n",
    "                        spike_torch = spike_torch.to(device)\n",
    "                        if coarse_com_mode == True and 'SAE' in net.module.__class__.__name__:\n",
    "                            spike_torch = spike_torch.unsqueeze(2).repeat(1, 1, level_num) # spike_length == level_num # (batch, time, feature)로 변환 \n",
    "                            spike_torch = (spike_torch > levels).to(torch.float) \n",
    "                            spike_torch = (spike_torch == 0).cumsum(dim=-1).eq(1).to(torch.float) if lc_adc_on == True else spike_torch\n",
    "                            if Conv_net == True:\n",
    "                                spike_torch = spike_torch.unsqueeze(-2) # batch, time, in_channel, feature or batch in_channel,feature\n",
    "                                if two_channel_input == True:\n",
    "                                    spike_backup = spike_backup.to(device)\n",
    "                                    spike_backup = spike_backup.unsqueeze(2).repeat(1, 1, level_num) # spike_length == level_num # (batch, time, feature)로 변환 \n",
    "                                    spike_backup = (spike_backup <= levels).to(torch.float) \n",
    "                                    spike_backup = (spike_backup == 1).cumsum(dim=-1).eq(1).to(torch.float) if lc_adc_on == True else spike_backup\n",
    "                                    spike_backup = spike_backup.unsqueeze(-2)\n",
    "                                    spike_torch = torch.cat((spike_torch, spike_backup), dim=-2)\n",
    "                        elif 'SAE' in net.module.__class__.__name__:\n",
    "                            spike_torch = spike_torch.unsqueeze(1).repeat(1, TIME, 1) # (batch, time, feature)로 변환\n",
    "                            if Conv_net == True:\n",
    "                                spike_torch = spike_torch.unsqueeze(-2) # batch, time, in_channel, feature or batch in_channel,feature\n",
    "                        else:\n",
    "                            if Conv_net == True:\n",
    "                                spike_torch = spike_torch.unsqueeze(-2) #batch in_channel,feature\n",
    "                            if converted_net_forward == True:\n",
    "                                spike_torch_spikegen = spikegen.rate(spike_torch, num_steps=TIME).transpose(0, 1)\n",
    "                                \n",
    "                        ### forward #######################################################\n",
    "                        inner_inf = net.module.encoder(spike_torch)\n",
    "                        if SAE_net == False and converted_net_forward == True:\n",
    "                            converted_inner_inf = converted_net.module.encoder(spike_torch_spikegen)\n",
    "                        ### forward #######################################################\n",
    "                            \n",
    "                        if 'SAE' in net.module.__class__.__name__:\n",
    "                            if SAE_hidden_nomean == True:\n",
    "                                inner_inf = inner_inf.reshape(spike_batch.shape[0],-1)# 펼치기\n",
    "                            else:\n",
    "                                inner_inf = inner_inf.mean(dim=1)# Time 방향으로 평균\n",
    "                        spike_hidden[now_index:now_end_index] = inner_inf.cpu().detach().numpy()\n",
    "                        if SAE_net == False and converted_net_forward == True:\n",
    "                            converted_spike_hidden[now_index:now_end_index] = converted_inner_inf.cpu().detach().numpy()\n",
    "                        now_index += encoder_batch\n",
    "                        if (now_index >= len(spike)):\n",
    "                            break\n",
    "                    \n",
    "                spike_id = np.zeros(len(spike))\n",
    "                distance_sm = np.zeros(num_cluster)\n",
    "                tau = np.zeros(num_cluster)\n",
    "                \n",
    "                plot_tau = []\n",
    "                plot_denominator = []\n",
    "                plot_m = []\n",
    "                plot_max_tau = []\n",
    "                for spike_index in range(len(spike)): \n",
    "                    for q in range(num_cluster):\n",
    "                        tau[q] = np.dot(spike_hidden[spike_index, :], Cluster[q, :]) # 이거 l2norm 거쳐서 나온 거니까 분모 1임.\n",
    "                        denominator =  np.linalg.norm(spike_hidden[spike_index, :])*np.linalg.norm(Cluster[q, :]) + 1e-12\n",
    "                        plot_denominator.append(denominator)\n",
    "                        if 'SAE' in net.module.__class__.__name__: # AE 때는 l2norm거쳐서 나와서 괜찮음\n",
    "                            tau[q] = tau[q] / denominator\n",
    "\n",
    "                        plot_tau.append(tau[q])\n",
    "\n",
    "                    # for i in range(num_cluster): # l2 distance\n",
    "                    #     distance_sm[i] = np.sum(np.power(np.abs(Cluster[i] - spike_hidden[spike_index, :]), 2))\n",
    "                    distance_sm = np.sum(np.power(np.abs(Cluster - spike_hidden[spike_index, :]), 2), axis=1)\n",
    "\n",
    "                    m = np.argmin(distance_sm)\n",
    "                    plot_m.append(m)\n",
    "                    spike_id[spike_index] = m + 1\n",
    "                    # print(spike_tot[ds], spike_index,np.max(tau))\n",
    "                    plot_max_tau.append(np.max(tau))\n",
    "                    if(np.max(tau) >= cos_thr[ds] and spike_index < training_cycle): # 원래 1400 아니냐?\n",
    "                        Cluster[m] = (Cluster[m] * 15 + spike_hidden[spike_index, :])/16\n",
    "\n",
    "\n",
    "                \n",
    "                origin_kmeans_accuracy = cluster_spikes_with_accuracy_torch(features= spike, true_labels=label-1, n_clusters=3, init_point=None)\n",
    "                kmeans_accuracy = cluster_spikes_with_accuracy_torch(features= torch.tensor(spike_hidden).to(device), true_labels=label-1, n_clusters=3, init_point=None)\n",
    "                k_means_bin_origin_feature.append(origin_kmeans_accuracy)\n",
    "                k_means_bin.append(kmeans_accuracy)\n",
    "                if SAE_net == False and converted_net_forward == True:\n",
    "                    converted_kmeans_accuracy = cluster_spikes_with_accuracy_torch(features= torch.tensor(converted_spike_hidden).to(device), true_labels=label-1, n_clusters=3, init_point=None)\n",
    "                    converted_k_means_bin.append(converted_kmeans_accuracy)\n",
    "                # sklearn kmeans인데 cpu많이먹어서 버림.\n",
    "                # origin_kmeans_accuracy = cluster_spikes_with_accuracy(features= spike.cpu().detach().numpy(), true_labels=label-1, n_clusters=3, init_point=None)\n",
    "                # kmeans_accuracy = cluster_spikes_with_accuracy(features= spike_hidden, true_labels=label-1, n_clusters=3, init_point=None)\n",
    "                # k_means_bin_origin_feature.append(origin_kmeans_accuracy)\n",
    "                # k_means_bin.append(kmeans_accuracy)\n",
    "                # if SAE_net == False and converted_net_forward == True:\n",
    "                #     converted_kmeans_accuracy = cluster_spikes_with_accuracy(features= converted_spike_hidden, true_labels=label-1, n_clusters=3, init_point=None)\n",
    "                #     converted_k_means_bin.append(converted_kmeans_accuracy)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "                # print('Cluster',Cluster)\n",
    "                # print('spike_id', spike_id)\n",
    "\n",
    "                # spike id 분포 확인하기\n",
    "                # unique_elements, counts = np.unique(spike_id, return_counts=True)\n",
    "                # print(\"Unique elements:\", unique_elements)\n",
    "                # print(\"Counts:\", counts)\n",
    "\n",
    "                cluster_accuracy_during_training_cycle = np.zeros(math.factorial(num_cluster))\n",
    "                cluster_accuracy_post_training_cycle = np.zeros(math.factorial(num_cluster))\n",
    "                cluster_accuracy_total = np.zeros(math.factorial(num_cluster))\n",
    "                \n",
    "                label_converter_ground = list(range(1, num_cluster + 1)) # [1, 2, 3, 4] 생성\n",
    "                label_converter_permutations = list(itertools.permutations(label_converter_ground)) # 모든 순열 구하기\n",
    "                perm_i = 0\n",
    "                perm_start_time = time.time() \n",
    "                for perm in label_converter_permutations:\n",
    "                    label_converter = list(perm)\n",
    "                    # print(label_converter)\n",
    "                    correct_during_training_cycle = 0\n",
    "                    correct_post_training_cycle = 0\n",
    "\n",
    "                    assert len(spike_id) == len(label), 'spike_id랑 label 길이 같아야 됨.'\n",
    "                    for i in range(len(spike_id)):\n",
    "                        if(label_converter[int(spike_id[i]-1)] == label[i]):\n",
    "                            if i < training_cycle:\n",
    "                                correct_during_training_cycle += 1\n",
    "                            else:\n",
    "                                correct_post_training_cycle += 1\n",
    "\n",
    "                    cluster_accuracy_during_training_cycle[perm_i] = correct_during_training_cycle/training_cycle\n",
    "                    cluster_accuracy_post_training_cycle[perm_i] = correct_post_training_cycle/(len(spike_id)-training_cycle)\n",
    "                    cluster_accuracy_total[perm_i] = (correct_during_training_cycle+correct_post_training_cycle)/(len(spike_id))\n",
    "                    perm_i += 1\n",
    "                # print(f\"perm 실행 시간: {time.time()-perm_start_time:.3f}초\")\n",
    "                \n",
    "                cluster_accuracy_during_training_cycle_all_dataset[ds] = np.max(cluster_accuracy_during_training_cycle)\n",
    "                cluster_accuracy_post_training_cycle_all_dataset[ds] = cluster_accuracy_post_training_cycle[np.argmax(cluster_accuracy_during_training_cycle)]\n",
    "                cluster_accuracy_total_all_dataset[ds] = cluster_accuracy_total[np.argmax(cluster_accuracy_during_training_cycle)]\n",
    "                # plot_distributions(ds, plot_tau, plot_denominator, plot_m, plot_max_tau, cos_thr[ds],\n",
    "                #                    cluster_accuracy_during_training_cycle_all_dataset[ds], cluster_accuracy_post_training_cycle_all_dataset[ds], cluster_accuracy_total_all_dataset[ds])\n",
    "            print(f'k_means origin feature average accuracy : {100*sum(k_means_bin_origin_feature)/(len(k_means_bin_origin_feature)+1e-12):.8f}%, total {k_means_bin_origin_feature}')\n",
    "            \n",
    "            mean_cluster_accuracy_during_training_cycle_all_dataset = np.mean(cluster_accuracy_during_training_cycle_all_dataset)\n",
    "            mean_cluster_accuracy_post_training_cycle_all_dataset = np.mean(cluster_accuracy_post_training_cycle_all_dataset)\n",
    "            mean_cluster_accuracy_total_all_dataset = np.mean(cluster_accuracy_total_all_dataset)\n",
    "            \n",
    "            if SAE_net == False and converted_net_forward == True:\n",
    "                converted_k_means_acc = 100*sum(converted_k_means_bin)/len(converted_k_means_bin)\n",
    "                print(f'converted_kmeans average accuracy : {converted_k_means_acc:.8f}%, total {converted_k_means_bin}')\n",
    "            k_means_acc = 100*sum(k_means_bin)/len(k_means_bin)\n",
    "            if k_means_acc > k_means_acc_best:\n",
    "                # torch.save(net, f\"net_save/save_now_net_{current_time}.pth\")\n",
    "                torch.save(net.module.state_dict(), f\"net_save/save_now_net_{current_time}.pth\")\n",
    "                print('save model')\n",
    "                best_mean_cluster_accuracy_post_training_cycle_all_dataset = mean_cluster_accuracy_post_training_cycle_all_dataset\n",
    "            \n",
    "            k_means_acc_best = max(k_means_acc_best, k_means_acc)\n",
    "            print(f'kmeans average accuracy best : {k_means_acc_best:.2f}%, kmeans average accuracy : {k_means_acc:.8f}%, total {k_means_bin}')\n",
    "            print(f'cluster_accuracy_post_training_cycle_all_dataset : {cluster_accuracy_post_training_cycle_all_dataset}')\n",
    "\n",
    "            \n",
    "            mean_cluster_accuracy_during_training_cycle_all_dataset_history.append((epoch, mean_cluster_accuracy_during_training_cycle_all_dataset*100))\n",
    "            mean_cluster_accuracy_post_training_cycle_all_dataset_history.append((epoch, mean_cluster_accuracy_post_training_cycle_all_dataset*100))\n",
    "            mean_cluster_accuracy_total_all_dataset_history.append((epoch, mean_cluster_accuracy_total_all_dataset*100))\n",
    "            print(f\"mean_cluster_accuracy_during_training_cycle : {mean_cluster_accuracy_during_training_cycle_all_dataset*100:.2f}%, post_traincycle_acc : {mean_cluster_accuracy_post_training_cycle_all_dataset*100:.2f}%, total_acc : {mean_cluster_accuracy_total_all_dataset*100:.8f}%\")\n",
    "\n",
    "            # kmeans accuracy기준으로 좋은 거 저장할 거임\n",
    "            # if mean_cluster_accuracy_post_training_cycle_all_dataset > best_mean_cluster_accuracy_post_training_cycle_all_dataset:\n",
    "            #     # torch.save(net, f\"net_save/save_now_net_{current_time}.pth\")\n",
    "            #     torch.save(net.module.state_dict(), f\"net_save/save_now_net_{current_time}.pth\")\n",
    "            #     print('save model')\n",
    "            #     best_mean_cluster_accuracy_post_training_cycle_all_dataset = mean_cluster_accuracy_post_training_cycle_all_dataset\n",
    "            print(f\"best_mean_cluster_accuracy_post_training_cycle_all_dataset : {best_mean_cluster_accuracy_post_training_cycle_all_dataset*100:.2f}%\")\n",
    "            print(f\"accuracy_check 실행 시간: {time.time()-accuracy_check_start_time:.3f}초\")\n",
    "\n",
    "        wandb.log({\"avg_loss\": avg_loss})\n",
    "        wandb.log({\"mean_cluster_accuracy_post_training_cycle_all_dataset\": mean_cluster_accuracy_post_training_cycle_all_dataset})\n",
    "        wandb.log({\"best_mean_cluster_accuracy_post_training_cycle_all_dataset\": best_mean_cluster_accuracy_post_training_cycle_all_dataset})\n",
    "        wandb.log({\"best_mean_cluster_accuracy_post_training_cycle_all_dataset2\": best_mean_cluster_accuracy_post_training_cycle_all_dataset})\n",
    "        wandb.log({\"k_means_acc\": k_means_acc})\n",
    "        wandb.log({\"k_means_acc_best\": k_means_acc_best})\n",
    "        wandb.log({\"converted_k_means_acc\": converted_k_means_acc})\n",
    "\n",
    "\n",
    "        # 저장\n",
    "        with open(f\"result_save/cluster_accuracy_history_{current_time}.pkl\", \"wb\") as f:\n",
    "            pickle.dump({\n",
    "                \"loss_history\": loss_history,\n",
    "                \"mean_cluster_accuracy_during_training_cycle_all_dataset_history\": mean_cluster_accuracy_during_training_cycle_all_dataset_history,\n",
    "                \"mean_cluster_accuracy_post_training_cycle_all_dataset_history\": mean_cluster_accuracy_post_training_cycle_all_dataset_history,\n",
    "                \"mean_cluster_accuracy_total_all_dataset_history\": mean_cluster_accuracy_total_all_dataset_history,\n",
    "            }, f)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mbhkim003\u001b[0m (\u001b[33mbhkim003-seoul-national-university\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.19.5 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.17.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/nfs/home/bhkim003/github_folder/ByeonghyeonKim/my_snn/wandb/run-20250130_234105-0op7tryj</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/bhkim003-seoul-national-university/spike_sorting%20just%20run/runs/0op7tryj' target=\"_blank\">lively-cherry-828</a></strong> to <a href='https://wandb.ai/bhkim003-seoul-national-university/spike_sorting%20just%20run' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/bhkim003-seoul-national-university/spike_sorting%20just%20run' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/spike_sorting%20just%20run</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/bhkim003-seoul-national-university/spike_sorting%20just%20run/runs/0op7tryj' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/spike_sorting%20just%20run/runs/0op7tryj</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'gpu': '1', 'Conv_net': True, 'SAE_net': True, 'dataset_num': 16, 'spike_length': 50, 'num_cluster': 4, 'training_cycle': 2400, 'batch_size': 32, 'max_epoch': 7000, 'learning_rate': 0.001, 'normalize_on': True, 'need_bias': False, 'lif_add_at_first': False, 'my_seed': 42, 'TIME': 2000, 'v_decay': 0.25, 'v_threshold': 0.5, 'v_reset': 10000.0, 'BPTT_on': False, 'SAE_hidden_nomean': True, 'current_time': '20250130_234103_699', 'optimizer': 'Adam', 'coarse_com_mode': True, 'sae_l2_norm_bridge': True, 'sae_lif_bridge': True, 'accuracy_check_epoch_term': 1, 'lif_add_at_last': False, 'two_channel_input': False, 'lateral_feature_num': 4, 'lc_adc_on': False, 'converted_net_forward': False, 'pretrained_net': None, 'vth_mul_on': False, 'batch_norm_on': False, 'l2_norm_loss_weight': 0, 'QCFS_neuron_on': False, 'coarse_com_config': (1.0, -0.0)}\n",
      "cos_thr [0.95 0.95 0.95 0.95 0.95 0.95 0.95 0.85 0.95 0.9  0.8  0.95 0.95 0.95\n",
      " 0.95 0.8 ]\n",
      "conv length [2000, 999, 499, 249]\n",
      "Total number of encoder parameters: 120288\n",
      "DataParallel(\n",
      "  (module): SAE_conv1(\n",
      "    (encoder): Sequential(\n",
      "      (0): SSBH_DimChanger_one_two()\n",
      "      (1): SSBH_DimChanger_for_one_two_coupling()\n",
      "      (2): Conv1d(1, 32, kernel_size=(3,), stride=(2,), bias=False)\n",
      "      (3): SSBH_DimChanger_for_one_two_decoupling()\n",
      "      (4): LIF_layer()\n",
      "      (5): SSBH_DimChanger_for_one_two_coupling()\n",
      "      (6): Conv1d(32, 64, kernel_size=(3,), stride=(2,), bias=False)\n",
      "      (7): SSBH_DimChanger_for_one_two_decoupling()\n",
      "      (8): LIF_layer()\n",
      "      (9): SSBH_DimChanger_for_one_two_coupling()\n",
      "      (10): Conv1d(64, 96, kernel_size=(3,), stride=(2,), bias=False)\n",
      "      (11): SSBH_DimChanger_for_one_two_decoupling()\n",
      "      (12): LIF_layer()\n",
      "      (13): SSBH_DimChanger_for_one_two_coupling()\n",
      "      (14): SSBH_DimChanger_for_fc()\n",
      "      (15): Linear(in_features=23904, out_features=4, bias=False)\n",
      "      (16): SSBH_DimChanger_for_one_two_decoupling()\n",
      "      (17): LIF_layer()\n",
      "      (18): SSBH_DimChanger_for_one_two_coupling()\n",
      "      (19): SSBH_L2NormLayer()\n",
      "      (20): SSBH_DimChanger_for_one_two_decoupling()\n",
      "      (21): SSBH_DimChanger_one_two()\n",
      "    )\n",
      "    (decoder): Sequential(\n",
      "      (0): SSBH_DimChanger_one_two()\n",
      "      (1): SSBH_DimChanger_for_one_two_coupling()\n",
      "      (2): Linear(in_features=4, out_features=23904, bias=False)\n",
      "      (3): SSBH_DimChanger_for_one_two_decoupling()\n",
      "      (4): LIF_layer()\n",
      "      (5): SSBH_DimChanger_for_one_two_coupling()\n",
      "      (6): SSBH_DimChanger_for_conv1()\n",
      "      (7): SSBH_DimChanger_for_one_two_decoupling()\n",
      "      (8): SSBH_DimChanger_for_one_two_coupling()\n",
      "      (9): ConvTranspose1d(96, 64, kernel_size=(3,), stride=(2,), bias=False)\n",
      "      (10): SSBH_DimChanger_for_one_two_decoupling()\n",
      "      (11): LIF_layer()\n",
      "      (12): SSBH_DimChanger_for_one_two_coupling()\n",
      "      (13): ConvTranspose1d(64, 32, kernel_size=(3,), stride=(2,), bias=False)\n",
      "      (14): SSBH_DimChanger_for_one_two_decoupling()\n",
      "      (15): LIF_layer()\n",
      "      (16): SSBH_DimChanger_for_one_two_coupling()\n",
      "      (17): ConvTranspose1d(32, 1, kernel_size=(3,), stride=(2,), output_padding=(1,), bias=False)\n",
      "      (18): SSBH_DimChanger_for_one_two_decoupling()\n",
      "      (19): SSBH_DimChanger_one_two()\n",
      "    )\n",
      "  )\n",
      ")\n",
      "Device: cuda\n",
      "\n",
      "Start Training, current_time = 20250130_234103_699\n",
      "\n",
      "\n",
      "epoch-0 loss : 0.09980\n",
      "ae train 실행 시간: 913.618초, 전체 시작 시간 20250130_234103_699\n",
      "\n",
      "epoch-0 accuracy check\n",
      "k_means origin feature average accuracy : 82.26041597%, total [0.9746727376209448, 0.9733106189664963, 0.9700891573195284, 0.9530800230282096, 0.943108504398827, 0.9150568181818182, 0.801817648783348, 0.6622234826999432, 0.9488619568430388, 0.822215777262181, 0.5866935483870968, 0.5005858230814294, 0.9429250891795482, 0.8922588099364529, 0.6747093023255814, 0.6000572573718866]\n",
      "save model\n",
      "kmeans average accuracy best : 78.68%, kmeans average accuracy : 78.67803637%, total [0.9667046101309049, 0.9690516751845543, 0.9646246764452114, 0.9525043177892919, 0.9331378299120234, 0.8275568181818181, 0.7379067722075637, 0.6480431083380601, 0.918120011823825, 0.738399071925754, 0.5941820276497696, 0.5225541886350322, 0.8980380499405469, 0.743212016175621, 0.6293604651162791, 0.5450901803607214]\n",
      "cluster_accuracy_post_training_cycle_all_dataset : [0.96319569 0.97326203 0.96471681 0.94599628 0.94950495 0.84375\n",
      " 0.84965381 0.62877442 0.90233978 0.70133588 0.56716418 0.44773176\n",
      " 0.90975104 0.73446328 0.53557692 0.43275389]\n",
      "mean_cluster_accuracy_during_training_cycle : 77.82%, post_traincycle_acc : 77.19%, total_acc : 77.62300048%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 77.19%\n",
      "accuracy_check 실행 시간: 62.590초\n",
      "\n",
      "\n",
      "epoch-1 loss : 0.04935\n",
      "ae train 실행 시간: 913.030초, 전체 시작 시간 20250130_234103_699\n",
      "\n",
      "epoch-1 accuracy check\n",
      "k_means origin feature average accuracy : 82.24953947%, total [0.9746727376209448, 0.9733106189664963, 0.9700891573195284, 0.9530800230282096, 0.943108504398827, 0.915340909090909, 0.801817648783348, 0.6625070901871809, 0.9488619568430388, 0.822215777262181, 0.5866935483870968, 0.5005858230814294, 0.9429250891795482, 0.8922588099364529, 0.673546511627907, 0.598912109934154]\n",
      "save model\n",
      "kmeans average accuracy best : 79.03%, kmeans average accuracy : 79.02834020%, total [0.9649971542401822, 0.9690516751845543, 0.9637618636755824, 0.9510650546919976, 0.9378299120234604, 0.8911931818181819, 0.7355614189387276, 0.6525808281338628, 0.9175288205734555, 0.7267981438515081, 0.597926267281106, 0.5222612770943175, 0.8906064209274673, 0.7359907567879839, 0.6136627906976744, 0.5737188663040367]\n",
      "cluster_accuracy_post_training_cycle_all_dataset : [0.96140036 0.97237077 0.96471681 0.94599628 0.95940594 0.88214286\n",
      " 0.85756677 0.65097691 0.89725331 0.71374046 0.58022388 0.44280079\n",
      " 0.90041494 0.7354049  0.49326923 0.44007319]\n",
      "mean_cluster_accuracy_during_training_cycle : 77.14%, post_traincycle_acc : 77.49%, total_acc : 77.24977346%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 77.49%\n",
      "accuracy_check 실행 시간: 64.912초\n",
      "\n",
      "\n",
      "epoch-2 loss : 0.04853\n",
      "ae train 실행 시간: 913.523초, 전체 시작 시간 20250130_234103_699\n",
      "\n",
      "epoch-2 accuracy check\n",
      "k_means origin feature average accuracy : 82.24589019%, total [0.9746727376209448, 0.9733106189664963, 0.9700891573195284, 0.9530800230282096, 0.943108504398827, 0.9150568181818182, 0.8015244796247435, 0.6625070901871809, 0.9488619568430388, 0.822215777262181, 0.5866935483870968, 0.5002929115407148, 0.9429250891795482, 0.8922588099364529, 0.673546511627907, 0.5991983967935872]\n",
      "save model\n",
      "kmeans average accuracy best : 79.49%, kmeans average accuracy : 79.49024890%, total [0.9649971542401822, 0.9699034639409426, 0.9646246764452114, 0.9510650546919976, 0.9419354838709677, 0.8900568181818181, 0.7381999413661683, 0.6554169030062393, 0.9255099024534437, 0.7273781902552204, 0.6057027649769585, 0.525776215582894, 0.9054696789536266, 0.7475447718082033, 0.6334302325581396, 0.5714285714285714]\n",
      "cluster_accuracy_post_training_cycle_all_dataset : [0.96319569 0.97326203 0.9637883  0.94878957 0.96138614 0.88928571\n",
      " 0.86646884 0.63232682 0.90539166 0.72996183 0.56809701 0.4566075\n",
      " 0.91078838 0.75329567 0.54903846 0.36413541]\n",
      "mean_cluster_accuracy_during_training_cycle : 78.05%, post_traincycle_acc : 77.72%, total_acc : 77.94637640%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 77.72%\n",
      "accuracy_check 실행 시간: 64.046초\n",
      "\n",
      "\n",
      "epoch-3 loss : 0.04776\n",
      "ae train 실행 시간: 913.792초, 전체 시작 시간 20250130_234103_699\n",
      "\n",
      "epoch-3 accuracy check\n",
      "k_means origin feature average accuracy : 82.25855480%, total [0.9746727376209448, 0.9733106189664963, 0.9700891573195284, 0.9530800230282096, 0.943108504398827, 0.9150568181818182, 0.801817648783348, 0.6625070901871809, 0.9488619568430388, 0.822215777262181, 0.5866935483870968, 0.5005858230814294, 0.9429250891795482, 0.8922588099364529, 0.6741279069767442, 0.6000572573718866]\n",
      "kmeans average accuracy best : 79.49%, kmeans average accuracy : 78.16114195%, total [0.9695503699487763, 0.9684838160136287, 0.9637618636755824, 0.9473229706390328, 0.9038123167155425, 0.8025568181818182, 0.7338024039871005, 0.6554169030062393, 0.8805793674253621, 0.703016241299304, 0.5950460829493087, 0.552431165787932, 0.8882282996432818, 0.7270363951473137, 0.6241279069767441, 0.5906097910105926]\n",
      "cluster_accuracy_post_training_cycle_all_dataset : [0.97037702 0.97237077 0.96564531 0.94972067 0.92376238 0.79732143\n",
      " 0.72205737 0.65452931 0.87792472 0.73187023 0.57929104 0.4112426\n",
      " 0.8973029  0.72410546 0.40288462 0.55077768]\n",
      "mean_cluster_accuracy_during_training_cycle : 75.39%, post_traincycle_acc : 75.82%, total_acc : 75.53142786%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 77.72%\n",
      "accuracy_check 실행 시간: 62.389초\n",
      "\n",
      "\n",
      "epoch-4 loss : 0.04946\n",
      "ae train 실행 시간: 913.695초, 전체 시작 시간 20250130_234103_699\n",
      "\n",
      "epoch-4 accuracy check\n",
      "k_means origin feature average accuracy : 82.25858366%, total [0.9746727376209448, 0.9733106189664963, 0.9700891573195284, 0.9530800230282096, 0.943108504398827, 0.9150568181818182, 0.8015244796247435, 0.6622234826999432, 0.9488619568430388, 0.822215777262181, 0.5866935483870968, 0.5005858230814294, 0.9429250891795482, 0.8922588099364529, 0.6747093023255814, 0.6000572573718866]\n",
      "kmeans average accuracy best : 79.49%, kmeans average accuracy : 78.84251215%, total [0.9669891861126921, 0.9701873935264055, 0.9631866551624964, 0.9530800230282096, 0.9469208211143695, 0.8980113636363637, 0.7338024039871005, 0.6446398184912082, 0.9278746674549216, 0.7169373549883991, 0.613479262672811, 0.5222612770943175, 0.8564209274673008, 0.7264586943963027, 0.6360465116279069, 0.5385055825937589]\n",
      "cluster_accuracy_post_training_cycle_all_dataset : [0.96319569 0.97504456 0.9628598  0.94692737 0.96336634 0.90446429\n",
      " 0.85459941 0.63676732 0.90233978 0.70229008 0.57369403 0.45759369\n",
      " 0.88278008 0.62617702 0.54903846 0.46020128]\n",
      "mean_cluster_accuracy_during_training_cycle : 78.05%, post_traincycle_acc : 77.26%, total_acc : 77.80775777%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 77.72%\n",
      "accuracy_check 실행 시간: 63.866초\n",
      "\n",
      "\n",
      "epoch-5 loss : 0.04892\n",
      "ae train 실행 시간: 916.403초, 전체 시작 시간 20250130_234103_699\n",
      "\n",
      "epoch-5 accuracy check\n",
      "k_means origin feature average accuracy : 82.25674876%, total [0.9746727376209448, 0.9733106189664963, 0.9700891573195284, 0.9530800230282096, 0.943108504398827, 0.9150568181818182, 0.801817648783348, 0.6622234826999432, 0.9488619568430388, 0.822215777262181, 0.5872695852534562, 0.5005858230814294, 0.9429250891795482, 0.8922588099364529, 0.673546511627907, 0.6000572573718866]\n",
      "kmeans average accuracy best : 79.49%, kmeans average accuracy : 78.94827537%, total [0.9684120660216278, 0.9696195343554799, 0.9628990509059534, 0.952216465169833, 0.9310850439882697, 0.8301136363636363, 0.7455291703312812, 0.6610890527509926, 0.916937629323086, 0.718677494199536, 0.5780529953917051, 0.5454012888107791, 0.9093341260404281, 0.729636048526863, 0.6232558139534884, 0.58946464357286]\n",
      "cluster_accuracy_post_training_cycle_all_dataset : [0.96768402 0.9741533  0.96564531 0.94692737 0.94554455 0.83214286\n",
      " 0.74085064 0.64564831 0.90539166 0.73187023 0.58955224 0.42899408\n",
      " 0.92012448 0.71845574 0.40384615 0.50960659]\n",
      "mean_cluster_accuracy_during_training_cycle : 76.55%, post_traincycle_acc : 76.42%, total_acc : 76.51673489%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 77.72%\n",
      "accuracy_check 실행 시간: 62.426초\n",
      "\n",
      "\n",
      "epoch-6 loss : 0.04837\n",
      "ae train 실행 시간: 913.974초, 전체 시작 시간 20250130_234103_699\n",
      "\n",
      "epoch-6 accuracy check\n",
      "k_means origin feature average accuracy : 82.26756432%, total [0.9746727376209448, 0.9733106189664963, 0.9700891573195284, 0.9530800230282096, 0.943108504398827, 0.915340909090909, 0.801817648783348, 0.6625070901871809, 0.9488619568430388, 0.822215777262181, 0.5872695852534562, 0.5005858230814294, 0.9429250891795482, 0.8922588099364529, 0.6747093023255814, 0.6000572573718866]\n",
      "save model\n",
      "kmeans average accuracy best : 81.18%, kmeans average accuracy : 81.17567850%, total [0.9649971542401822, 0.9707552526973311, 0.9626114466494105, 0.9548071387449626, 0.9504398826979472, 0.9394886363636363, 0.8874230430958663, 0.7827566647759501, 0.9358557493349099, 0.7236078886310905, 0.6129032258064516, 0.5260691271236086, 0.8596908442330559, 0.7287694974003466, 0.65, 0.5379330088748926]\n",
      "cluster_accuracy_post_training_cycle_all_dataset : [0.96319569 0.9714795  0.96471681 0.95437616 0.96831683 0.93660714\n",
      " 0.83877349 0.61456483 0.90030519 0.71755725 0.57276119 0.3964497\n",
      " 0.8620332  0.59698682 0.56826923 0.3494968 ]\n",
      "mean_cluster_accuracy_during_training_cycle : 77.34%, post_traincycle_acc : 76.10%, total_acc : 76.96515866%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 76.10%\n",
      "accuracy_check 실행 시간: 62.588초\n",
      "\n",
      "\n",
      "epoch-7 loss : 0.04809\n",
      "ae train 실행 시간: 914.369초, 전체 시작 시간 20250130_234103_699\n",
      "\n",
      "epoch-7 accuracy check\n",
      "k_means origin feature average accuracy : 82.26388919%, total [0.9746727376209448, 0.9733106189664963, 0.9700891573195284, 0.9530800230282096, 0.943108504398827, 0.9150568181818182, 0.801817648783348, 0.6625070901871809, 0.9488619568430388, 0.822215777262181, 0.5872695852534562, 0.5005858230814294, 0.9429250891795482, 0.8922588099364529, 0.673546511627907, 0.6009161179501861]\n",
      "kmeans average accuracy best : 81.18%, kmeans average accuracy : 80.26322118%, total [0.9635742743312464, 0.969335604770017, 0.9608858211101524, 0.9548071387449626, 0.9571847507331378, 0.9477272727272728, 0.9041336851363236, 0.8150879183210437, 0.9213715637008573, 0.6653132250580046, 0.6077188940092166, 0.5228471001757469, 0.8350178359096314, 0.7154823801270942, 0.6223837209302325, 0.47924420269109647]\n",
      "cluster_accuracy_post_training_cycle_all_dataset : [0.95691203 0.97326203 0.96100279 0.94878957 0.97029703 0.94017857\n",
      " 0.87636004 0.82326821 0.90946083 0.66221374 0.59981343 0.52071006\n",
      " 0.84128631 0.56214689 0.51826923 0.39341263]\n",
      "mean_cluster_accuracy_during_training_cycle : 77.82%, post_traincycle_acc : 77.86%, total_acc : 77.82318612%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 76.10%\n",
      "accuracy_check 실행 시간: 62.818초\n",
      "\n",
      "\n",
      "epoch-8 loss : 0.04879\n",
      "ae train 실행 시간: 914.470초, 전체 시작 시간 20250130_234103_699\n",
      "\n",
      "epoch-8 accuracy check\n",
      "k_means origin feature average accuracy : 82.26219154%, total [0.9746727376209448, 0.9733106189664963, 0.9700891573195284, 0.9530800230282096, 0.943108504398827, 0.915340909090909, 0.801817648783348, 0.6622234826999432, 0.9488619568430388, 0.822215777262181, 0.5866935483870968, 0.5005858230814294, 0.9429250891795482, 0.8922588099364529, 0.6747093023255814, 0.6000572573718866]\n",
      "kmeans average accuracy best : 81.18%, kmeans average accuracy : 80.44795319%, total [0.9638588503130335, 0.9690516751845543, 0.9597354040839804, 0.953943580886586, 0.9571847507331378, 0.9463068181818182, 0.9000293169158604, 0.809699376063528, 0.9266922849541827, 0.6687935034802784, 0.6137672811059908, 0.5298769771528998, 0.8379904875148633, 0.7250144425187752, 0.627906976744186, 0.48182078442599485]\n",
      "cluster_accuracy_post_training_cycle_all_dataset : [0.96409336 0.97237077 0.96100279 0.94878957 0.97029703 0.94196429\n",
      " 0.80217606 0.82415631 0.90437436 0.67080153 0.60634328 0.54536489\n",
      " 0.8620332  0.59416196 0.49134615 0.36870997]\n",
      "mean_cluster_accuracy_during_training_cycle : 77.23%, post_traincycle_acc : 77.67%, total_acc : 77.35880642%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 76.10%\n",
      "accuracy_check 실행 시간: 63.163초\n",
      "\n",
      "\n",
      "epoch-9 loss : 0.04762\n",
      "ae train 실행 시간: 913.734초, 전체 시작 시간 20250130_234103_699\n",
      "\n",
      "epoch-9 accuracy check\n",
      "k_means origin feature average accuracy : 82.25319774%, total [0.9746727376209448, 0.9733106189664963, 0.9700891573195284, 0.9530800230282096, 0.943108504398827, 0.9150568181818182, 0.801817648783348, 0.6622234826999432, 0.9488619568430388, 0.822215777262181, 0.5872695852534562, 0.5005858230814294, 0.9429250891795482, 0.8922588099364529, 0.6738372093023256, 0.5991983967935872]\n",
      "kmeans average accuracy best : 81.18%, kmeans average accuracy : 79.48900118%, total [0.9692657939669892, 0.9699034639409426, 0.9646246764452114, 0.948762233736327, 0.9387096774193548, 0.8403409090909091, 0.751685722661976, 0.659103800340329, 0.9349689624593556, 0.7308584686774942, 0.6005184331797235, 0.5216754540128881, 0.906064209274673, 0.7504332755632582, 0.641860465116279, 0.58946464357286]\n",
      "cluster_accuracy_post_training_cycle_all_dataset : [0.96858169 0.97504456 0.96471681 0.94413408 0.95148515 0.86517857\n",
      " 0.75667656 0.6660746  0.90946083 0.66603053 0.47574627 0.46449704\n",
      " 0.93153527 0.69585687 0.54230769 0.42177493]\n",
      "mean_cluster_accuracy_during_training_cycle : 77.61%, post_traincycle_acc : 76.24%, total_acc : 77.19101127%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 76.10%\n",
      "accuracy_check 실행 시간: 63.693초\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "gpu = '1'\n",
    "Conv_net = True # True False\n",
    "SAE_net = True # True False\n",
    "\n",
    "# hyperparameter\n",
    "dataset_num = 16\n",
    "spike_length = 50 # coarse_com_mode일 때는 time step이 됨.\n",
    "num_cluster = 4  # 클러스터 수 설정 # 논문엔 4개라는데 여기서는 3개로 했네\n",
    "training_cycle = 2400 #1400 2400 # 그 초기 몇개까지만 cluster update할지\n",
    "\n",
    "\n",
    "batch_size = 32\n",
    "max_epoch = 7000\n",
    "learning_rate = 0.001\n",
    "normalize_on = True # True or False # 0부터1까지 normalize\n",
    "need_bias = False\n",
    "# first_layer_no_train = False\n",
    "lif_add_at_first = False\n",
    "my_seed = 42\n",
    "\n",
    "TIME = 2000 # SAE일 때만 유효. coarse_com_mode일 때는 level_num이 됨. 즉 feature 개수.\n",
    "v_decay = 0.25 # -cor\n",
    "v_threshold = 0.5 # -cor\n",
    "v_reset = 10000.0 # -cor # 10000이상 일 시 hard reset\n",
    "BPTT_on = False # +cor # True False\n",
    "\n",
    "SAE_hidden_nomean = True # True False\n",
    "\n",
    "current_time = datetime.datetime.now().strftime(\"%Y%m%d_%H%M%S\") + f\"_{str(int(datetime.datetime.now().microsecond / 1000)).zfill(3)}\"\n",
    "\n",
    "optimizer = 'Adam' #'Adam', 'SGD' # 둘다 준수함. loss 줄이는 거는 adam이 좋긴한데, cluster accuracy는 비슷함.\n",
    "\n",
    "coarse_com_mode = True\n",
    "coarse_com_config = (1.0, -0.0) # (max, min) (2.0, -2.0) (3.0, -3.0)\n",
    "\n",
    "sae_l2_norm_bridge = True # True False\n",
    "sae_lif_bridge = True # False True\n",
    "\n",
    "accuracy_check_epoch_term = 1\n",
    "\n",
    "lif_add_at_last = False # True False\n",
    "\n",
    "two_channel_input = False # True False\n",
    "\n",
    "lateral_feature_num = 4\n",
    "\n",
    "lc_adc_on = False # True False\n",
    "\n",
    "converted_net_forward = False # True False\n",
    "\n",
    "pretrained_net = None\n",
    "# pretrained_net = '/home/bhkim003/github_folder/ByeonghyeonKim/my_snn/net_save/save_now_net_중요_20250110_203117_390.pth'\n",
    "# pretrained_net = '/home/bhkim003/github_folder/ByeonghyeonKim/my_snn/net_save/save_now_net_중요_20250113_134126_881_이거_94나오는거.pth'\n",
    "# pretrained_net = '/home/bhkim003/github_folder/ByeonghyeonKim/my_snn/net_save/save_now_net_중요_20250115_200335_029_무한열차95.12.pth'\n",
    "# pretrained_net = '/home/bhkim003/github_folder/ByeonghyeonKim/my_snn/net_save/save_now_net_중요_20250115_200335_029_무한열차95.23.pth'\n",
    "\n",
    "vth_mul_on = False # True False\n",
    "batch_norm_on = False # True False\n",
    "\n",
    "l2_norm_loss_weight = 0 #0.0001 #0.1 #  0 # 0초과면 작동\n",
    "\n",
    "QCFS_neuron_on = False # True False\n",
    "\n",
    "wandb.init(project= f'spike_sorting just run',save_code=False)\n",
    "\n",
    "\n",
    "cluster_train_system( \n",
    "    gpu = gpu,\n",
    "    Conv_net = Conv_net,\n",
    "    SAE_net = SAE_net,\n",
    "\n",
    "    # hyperparameter\n",
    "    dataset_num = dataset_num,\n",
    "    spike_length = spike_length,\n",
    "    num_cluster = num_cluster,  # 클러스터 수 설정 # 논문엔 4개라는데 여기서는 3개로 했네\n",
    "    training_cycle = training_cycle, # 그 초기 몇개까지만 cluster update할지\n",
    "\n",
    "\n",
    "    batch_size = batch_size,\n",
    "    max_epoch = max_epoch,\n",
    "    learning_rate = learning_rate,\n",
    "    normalize_on = normalize_on, # True or False #이거 안 씀 # 이거 별로 안 좋은 normalize같음 # 쓸 거면 다른 거 써라.\n",
    "    need_bias = need_bias,\n",
    "    # first_layer_no_train = False\n",
    "    lif_add_at_first = lif_add_at_first,\n",
    "    my_seed = my_seed,\n",
    "\n",
    "    TIME = TIME, # SAE일 때만 유효\n",
    "    v_decay = v_decay,\n",
    "    v_threshold = v_threshold,\n",
    "    v_reset = v_reset, # 10000이상 일 시 hard reset\n",
    "    BPTT_on = BPTT_on,\n",
    "\n",
    "    SAE_hidden_nomean = SAE_hidden_nomean,\n",
    "    \n",
    "    current_time = current_time,\n",
    "\n",
    "    optimizer = optimizer, #'Adam', 'SGD'\n",
    "\n",
    "    coarse_com_mode = coarse_com_mode,\n",
    "    coarse_com_config = coarse_com_config, # (max, min)\n",
    "\n",
    "    \n",
    "    sae_l2_norm_bridge = sae_l2_norm_bridge,\n",
    "    sae_lif_bridge = sae_lif_bridge,\n",
    "\n",
    "    accuracy_check_epoch_term = accuracy_check_epoch_term,\n",
    "    \n",
    "    lif_add_at_last = lif_add_at_last,\n",
    "\n",
    "    two_channel_input = two_channel_input,\n",
    "\n",
    "    lateral_feature_num = lateral_feature_num,\n",
    "\n",
    "    lc_adc_on = lc_adc_on, \n",
    "\n",
    "    converted_net_forward = converted_net_forward,\n",
    "\n",
    "    pretrained_net = pretrained_net,\n",
    "\n",
    "    vth_mul_on = vth_mul_on,\n",
    "    batch_norm_on = batch_norm_on,\n",
    "\n",
    "    l2_norm_loss_weight = l2_norm_loss_weight,\n",
    "    \n",
    "    QCFS_neuron_on = QCFS_neuron_on # True False\n",
    "\n",
    "    )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Sweep code\n",
    "\n",
    "\n",
    "# from unittest import TextTestRunner\n",
    "\n",
    "\n",
    "# unique_name_hyper = 'cluster_train_system'\n",
    "# # run_name = 'spike_sorting'\n",
    "# sweep_start_time =  datetime.datetime.now().strftime(\"%Y%m%d_%H%M%S\") + f\"_{str(int(datetime.datetime.now().microsecond / 1000)).zfill(3)}\"\n",
    "# sweep_configuration = {\n",
    "#     'method': 'bayes', # 'random', 'bayes'\n",
    "#     'name': f'spike_sorting_{sweep_start_time}',\n",
    "#     'metric': {'goal': 'maximize', 'name': 'k_means_acc_best'},\n",
    "#     'parameters': \n",
    "#     {\n",
    "#         # \"gpu\": {\"values\": ['1']},  # 이건 sweep parameter아님. hyper_iter에서 직접 설정\n",
    "#         \"Conv_net\": {\"values\": [True]}, \n",
    "#         \"SAE_net\": {\"values\": [False]}, \n",
    "\n",
    "#         \"dataset_num\": {\"values\": [16]}, \n",
    "#         \"spike_length\": {\"values\": [50]},  \n",
    "#         \"num_cluster\": {\"values\": [4]}, \n",
    "#         \"training_cycle\": {\"values\": [2400]}, # [1400, 2400]\n",
    "\n",
    "#         \"batch_size\": {\"values\": [32]}, \n",
    "#         \"max_epoch\": {\"values\": [1]}, \n",
    "#         \"learning_rate\": {\"values\": [0.001, 0.0001]},\n",
    "#         \"normalize_on\": {\"values\": [True]},\n",
    "#         \"need_bias\": {\"values\": [False]}, # [True, False]\n",
    "\n",
    "#         \"lif_add_at_first\": {\"values\": [False]}, # [True, False]\n",
    "#         \"my_seed\": {\"values\": [42]}, \n",
    "\n",
    "#         \"TIME\": {\"values\": [10, 50, 100, 250, 500, 750, 1000, 1500, 2000, 2500]}, #  [4,6,8,10]\n",
    "#         \"v_decay\": {\"values\": [1.0]}, # [0.25,0.50,0.75]\n",
    "#         \"v_threshold\": {\"values\": [0.125, 0.25, 0.50, 0.75, 0.875, 1.0]}, # [0.25,0.50,0.75]\n",
    "#         \"v_reset\": {\"values\": [0.0, 10000.0]},  # [0.0, 10000.0]\n",
    "#         \"BPTT_on\": {\"values\": [True, False]},  # [True, False]\n",
    "\n",
    "#         \"SAE_hidden_nomean\": {\"values\": [True]}, # [True, False]\n",
    "\n",
    "#         # \"current_time\": {\"values\": [current_time]} #밑에서 직접설정됨.\n",
    "\n",
    "#         \"optimizer\": {\"values\": ['Adam', 'SGD']}, # ['Adam', 'SGD']\n",
    "\n",
    "#         \"coarse_com_mode\": {\"values\": [False]}, # [True, False]\n",
    "#         \"coarse_com_config\": {\"values\": [(2.0, -2.0)]}, # ['Adam', 'SGD']\n",
    "\n",
    "#         \"sae_l2_norm_bridge\": {\"values\": [True]}, # [True, False]\n",
    "#         \"sae_lif_bridge\": {\"values\": [True]}, # [False, True]\n",
    "        \n",
    "#         \"accuracy_check_epoch_term\": {\"values\": [1]}, \n",
    "\n",
    "#         \"lif_add_at_last\": {\"values\": [False]},# [True, False]\n",
    "\n",
    "#         \"two_channel_input\": {\"values\": [False]},# [True, False]\n",
    "\n",
    "#         \"lateral_feature_num\": {\"values\": [4]},# [True, False]\n",
    "\n",
    "#         \"lc_adc_on\": {\"values\": [False]},# [True, False]\n",
    "        \n",
    "#         \"converted_net_forward\": {\"values\": [True]},# [True, False]\n",
    "\n",
    "#         \"pretrained_net\": {\"values\": ['/home/bhkim003/github_folder/ByeonghyeonKim/my_snn/net_save/save_now_net_중요_20250110_203117_390.pth']},# [None]\n",
    "\n",
    "#         \"vth_mul_on\": {\"values\": [True]},# [True, False]\n",
    "#         \"batch_norm_on\": {\"values\": [True]},# [True, False]\n",
    "\n",
    "#         \"l2_norm_loss_weight\": {\"values\": [0.1]},\n",
    "\n",
    "#         \"QCFS_neuron_on\": {\"values\": [True]},   # [True, False]\n",
    "\n",
    "\n",
    "#      }\n",
    "# }\n",
    "\n",
    "\n",
    "# def hyper_iter():\n",
    "#     ### my_snn control board ########################\n",
    "#     wandb.init(save_code = False)\n",
    "#     gpu  =  '2'\n",
    "#     Conv_net  =  wandb.config.Conv_net\n",
    "#     SAE_net  =  wandb.config.SAE_net\n",
    "\n",
    "#     dataset_num  =  wandb.config.dataset_num\n",
    "#     spike_length  =  wandb.config.spike_length\n",
    "#     num_cluster  =  wandb.config.num_cluster\n",
    "#     training_cycle  =  wandb.config.training_cycle\n",
    "\n",
    "#     batch_size  =  wandb.config.batch_size\n",
    "#     max_epoch  =  wandb.config.max_epoch\n",
    "#     learning_rate  =  wandb.config.learning_rate\n",
    "#     normalize_on  =  wandb.config.normalize_on\n",
    "#     need_bias  =  wandb.config.need_bias\n",
    "\n",
    "#     lif_add_at_first  =  wandb.config.lif_add_at_first\n",
    "#     my_seed  =  wandb.config.my_seed\n",
    "\n",
    "\n",
    "#     TIME  =  wandb.config.TIME\n",
    "#     v_decay  =  wandb.config.v_decay\n",
    "#     v_threshold  =  wandb.config.v_threshold\n",
    "#     v_reset  =  wandb.config.v_reset\n",
    "#     BPTT_on  =  wandb.config.BPTT_on\n",
    "\n",
    "#     SAE_hidden_nomean  =  wandb.config.SAE_hidden_nomean\n",
    "    \n",
    "#     current_time =  datetime.datetime.now().strftime(\"%Y%m%d_%H%M%S\") + f\"_{str(int(datetime.datetime.now().microsecond / 1000)).zfill(3)}\"\n",
    "\n",
    "#     optimizer  =  wandb.config.optimizer\n",
    "\n",
    "#     coarse_com_mode = wandb.config.coarse_com_mode\n",
    "#     coarse_com_config = wandb.config.coarse_com_config # (max, min)\n",
    "\n",
    "#     sae_l2_norm_bridge = wandb.config.sae_l2_norm_bridge\n",
    "#     sae_lif_bridge = wandb.config.sae_lif_bridge\n",
    "\n",
    "#     accuracy_check_epoch_term = wandb.config.accuracy_check_epoch_term\n",
    "\n",
    "#     lif_add_at_last = wandb.config.lif_add_at_last\n",
    "\n",
    "#     two_channel_input = wandb.config.two_channel_input\n",
    "\n",
    "#     lateral_feature_num = wandb.config.lateral_feature_num\n",
    "\n",
    "#     lc_adc_on = wandb.config.lc_adc_on\n",
    "\n",
    "#     converted_net_forward = wandb.config.converted_net_forward\n",
    "\n",
    "#     pretrained_net = wandb.config.pretrained_net\n",
    "\n",
    "#     vth_mul_on = wandb.config.vth_mul_on\n",
    "#     batch_norm_on = wandb.config.batch_norm_on\n",
    "\n",
    "#     l2_norm_loss_weight = wandb.config.l2_norm_loss_weight\n",
    "\n",
    "#     QCFS_neuron_on = wandb.config.QCFS_neuron_on\n",
    "\n",
    "    \n",
    "\n",
    "#     cluster_train_system( \n",
    "#         gpu = gpu,\n",
    "#         Conv_net = Conv_net,\n",
    "#         SAE_net = SAE_net,\n",
    "\n",
    "#         # hyperparameter\n",
    "#         dataset_num = dataset_num,\n",
    "#         spike_length = spike_length,\n",
    "#         num_cluster = num_cluster,  # 클러스터 수 설정 # 논문엔 4개라는데 여기서는 3개로 했네\n",
    "#         training_cycle = training_cycle, # 그 초기 몇개까지만 cluster update할지\n",
    "\n",
    "\n",
    "#         batch_size = batch_size,\n",
    "#         max_epoch = max_epoch,\n",
    "#         learning_rate = learning_rate,\n",
    "#         normalize_on = normalize_on, # True or False #이거 안 씀 # 이거 별로 안 좋은 normalize같음 # 쓸 거면 다른 거 써라.\n",
    "#         need_bias = need_bias,\n",
    "#         # first_layer_no_train = False\n",
    "#         lif_add_at_first = lif_add_at_first,\n",
    "#         my_seed = my_seed,\n",
    "\n",
    "#         TIME = TIME, # SAE일 때만 유효\n",
    "#         v_decay = v_decay,\n",
    "#         v_threshold = v_threshold,\n",
    "#         v_reset = v_reset, # 10000이상 일 시 hard reset\n",
    "#         BPTT_on = BPTT_on,\n",
    "\n",
    "#         SAE_hidden_nomean = SAE_hidden_nomean,\n",
    "\n",
    "#         current_time = current_time,\n",
    "\n",
    "#         optimizer = optimizer, #'Adam', 'SGD'\n",
    "\n",
    "#         coarse_com_mode = coarse_com_mode,\n",
    "#         coarse_com_config = coarse_com_config, # (max, min)\n",
    "        \n",
    "#         sae_l2_norm_bridge = sae_l2_norm_bridge,\n",
    "#         sae_lif_bridge = sae_lif_bridge,\n",
    "\n",
    "#         accuracy_check_epoch_term = accuracy_check_epoch_term,\n",
    "\n",
    "#         lif_add_at_last = lif_add_at_last,\n",
    "        \n",
    "#         two_channel_input = two_channel_input,\n",
    "        \n",
    "#         lateral_feature_num = lateral_feature_num,\n",
    "\n",
    "#         lc_adc_on = lc_adc_on,\n",
    "\n",
    "#         converted_net_forward = converted_net_forward,\n",
    "\n",
    "#         pretrained_net = pretrained_net,\n",
    "\n",
    "#         vth_mul_on = vth_mul_on,\n",
    "#         batch_norm_on = batch_norm_on,\n",
    "\n",
    "#         l2_norm_loss_weight = l2_norm_loss_weight,\n",
    "\n",
    "#         QCFS_neuron_on = QCFS_neuron_on,\n",
    "\n",
    "#         )\n",
    "    \n",
    "# # sweep_id = 'ygoj9jt4'\n",
    "# sweep_id = wandb.sweep(sweep=sweep_configuration, project=f'spike_sorting {unique_name_hyper}')\n",
    "# wandb.agent(sweep_id, function=hyper_iter, count=100000, project=f'spike_sorting {unique_name_hyper}')\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wandb.finish() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import matplotlib.pyplot as plt\n",
    "# from matplotlib.ticker import MaxNLocator\n",
    "# import pickle\n",
    "# import json\n",
    "\n",
    "# # current_time = '20250102_225243_972'\n",
    "\n",
    "# with open(f\"result_save/cluster_accuracy_history_{current_time}.pkl\", \"rb\") as f:\n",
    "#     data = pickle.load(f)\n",
    "\n",
    "\n",
    "# # JSON으로 저장\n",
    "# with open(f\"result_save/cluster_accuracy_history_{current_time}.json\", 'r') as f:\n",
    "#     loaded_hyperparameters = json.load(f)\n",
    "\n",
    "# loss_history = data['loss_history']\n",
    "# mean_cluster_accuracy_during_training_cycle_all_dataset_history = data['mean_cluster_accuracy_during_training_cycle_all_dataset_history']\n",
    "# mean_cluster_accuracy_post_training_cycle_all_dataset_history = data['mean_cluster_accuracy_post_training_cycle_all_dataset_history']\n",
    "# mean_cluster_accuracy_total_all_dataset_history = data['mean_cluster_accuracy_total_all_dataset_history']\n",
    "# print(data)\n",
    "# max_acc = 0\n",
    "# for i in mean_cluster_accuracy_post_training_cycle_all_dataset_history:\n",
    "#     if i[1] > max_acc:\n",
    "#         max_acc = i[1]\n",
    "\n",
    "# # 설정 정보 제목 작성\n",
    "# title = (\n",
    "#     f\"Dataset Num: {loaded_hyperparameters['dataset_num']}, Conv {loaded_hyperparameters['Conv_net']}, SAE {loaded_hyperparameters['SAE_net']}, Current time {loaded_hyperparameters['current_time']}, Spike Length: {loaded_hyperparameters['spike_length']}, Num Cluster: {loaded_hyperparameters['num_cluster']}, \"\n",
    "#     f\"Training Cycle: {loaded_hyperparameters['training_cycle']}, Batch Size: {loaded_hyperparameters['batch_size']}, Max Epoch: {loaded_hyperparameters['max_epoch']}, \\n\"\n",
    "#     f\"Learning Rate: {loaded_hyperparameters['learning_rate']}, Input Normalize: {loaded_hyperparameters['normalize_on']}, Need Bias: {loaded_hyperparameters['need_bias']}, \"\n",
    "#     f\"LIF Add at First: {loaded_hyperparameters['lif_add_at_first']}, TIME: {loaded_hyperparameters['TIME']}, Seed: {loaded_hyperparameters['my_seed']}, Best ACC: {max_acc:.2f}%\"\n",
    "# )\n",
    "\n",
    "# # 데이터 리스트와 라벨 설정 (Loss 제외)\n",
    "# data_list = [\n",
    "#     (\"Mean Cluster Accuracy (During Training Cycle)\", mean_cluster_accuracy_during_training_cycle_all_dataset_history),\n",
    "#     (\"Mean Cluster Accuracy (Post Training Cycle)\", mean_cluster_accuracy_post_training_cycle_all_dataset_history),\n",
    "#     (\"Mean Cluster Accuracy (Total)\", mean_cluster_accuracy_total_all_dataset_history),\n",
    "# ]\n",
    "\n",
    "# # 플롯 생성\n",
    "# fig, ax1 = plt.subplots(figsize=(12, 8))\n",
    "\n",
    "# # 첫 번째 y축: Accuracy 관련 데이터\n",
    "# for label, data in data_list:\n",
    "#     epochs, values = zip(*data)  # epoch, value 분리\n",
    "#     ax1.plot(epochs, values, label=label)\n",
    "\n",
    "# ax1.set_xlabel(\"Epoch\")\n",
    "# ax1.set_ylabel(\"Clurstering Accuracy [%]\", color=\"blue\")\n",
    "# ax1.tick_params(axis=\"y\", labelcolor=\"blue\")\n",
    "# ax1.legend(loc=\"center right\")\n",
    "# ax1.grid(True)\n",
    "\n",
    "# # x축을 정수만 표시하도록 설정\n",
    "# ax1.xaxis.set_major_locator(MaxNLocator(integer=True))\n",
    "\n",
    "# # 두 번째 y축: Loss History\n",
    "# ax2 = ax1.twinx()\n",
    "# epochs, values = zip(*loss_history)\n",
    "# ax2.plot(epochs, values, label=\"AE Loss History\", color=\"red\", linestyle=\"--\")\n",
    "# ax2.set_ylabel(\"Loss\", color=\"red\")\n",
    "# ax2.tick_params(axis=\"y\", labelcolor=\"red\")\n",
    "# ax2.legend(loc=\"center left\")\n",
    "\n",
    "# # 제목 추가\n",
    "# plt.title(title, fontsize=10)\n",
    "# plt.tight_layout()\n",
    "# plt.savefig(f'net_save/{current_time}', dpi=300, bbox_inches=\"tight\")  # dpi=300은 고해상도로 저장, bbox_inches=\"tight\"는 여백 최소화\n",
    "# plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# 데이터셋\n",
    "filename_for_plot = [\n",
    "    \"Easy1_noise05\", \"Easy1_noise10\", \"Easy1_noise15\", \"Easy1_noise20\",\n",
    "    \"Easy2_noise05\", \"Easy2_noise10\", \"Easy2_noise15\", \"Easy2_noise20\",\n",
    "    \"Difficult1_noise05\", \"Difficult1_noise10\", \"Difficult1_noise15\", \"Difficult1_noise20\",\n",
    "    \"Difficult2_noise05\", \"Difficult2_noise10\", \"Difficult2_noise15\", \"Difficult2_noise20\"\n",
    "]\n",
    "\n",
    "# Accuracy 데이터\n",
    "ANN_conv_accracy_set= [0.97935368, 0.97682709, 0.97028784, 0.96461825, 0.97524752, 0.95803571\n",
    ", 0.95746785, 0.92628774, 0.965412,  0.97805344, 0.94869403, 0.92110454\n",
    ", 0.96784232, 0.97551789, 0.91538462, 0.84446478]\n",
    "SNN_fc_accuracy_set = [0.97114475, 0.97643732, 0.84400578, 0.78977821, 0.96616915, 0.92830189\n",
    ", 0.86176032, 0.31984948, 0.80635401, 0.88769531, 0.61003861, 0.60377358\n",
    ", 0.9592668,  0.92870999, 0.78333333, 0.67271859]\n",
    "SNN_conv_accuracy_set = [0.97445601, 0.97737983, 0.97063072, 0.95998071, 0.96268657, 0.90566038\n",
    ", 0.82545997, 0.68391345, 0.96116994, 0.92138672, 0.80694981, 0.49602781\n",
    ", 0.83604888, 0.70611057, 0.69313725, 0.5819398 ]\n",
    "\n",
    "# 평균 계산\n",
    "average_ANN_conv = np.mean(ANN_conv_accracy_set)\n",
    "average_SNN_fc = np.mean(SNN_fc_accuracy_set)\n",
    "average_SNN_conv = np.mean(SNN_conv_accuracy_set)\n",
    "\n",
    "# 데이터 준비\n",
    "accuracies = np.array([ANN_conv_accracy_set, SNN_fc_accuracy_set, SNN_conv_accuracy_set])\n",
    "averages = np.array([average_ANN_conv, average_SNN_fc, average_SNN_conv])\n",
    "\n",
    "# 시각화\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "\n",
    "# 각 모델의 정확도 플롯\n",
    "ax.plot(accuracies[0], label='ANN Conv', marker='o', linestyle='-', color='blue')\n",
    "ax.plot(accuracies[1], label='SNN FC', marker='o', linestyle='-', color='green')\n",
    "ax.plot(accuracies[2], label='SNN Conv', marker='o', linestyle='-', color='red')\n",
    "\n",
    "# 평균값 플롯\n",
    "ax.axhline(y=average_ANN_conv, color='blue', linestyle='--', label=f'Average ANN Conv: {average_ANN_conv:.3f}')\n",
    "ax.axhline(y=average_SNN_fc, color='green', linestyle='--', label=f'Average SNN FC: {average_SNN_fc:.3f}')\n",
    "ax.axhline(y=average_SNN_conv, color='red', linestyle='--', label=f'Average SNN Conv: {average_SNN_conv:.3f}')\n",
    "\n",
    "# 레이블 추가\n",
    "ax.set_xticks(np.arange(len(filename_for_plot)))\n",
    "ax.set_xticklabels(filename_for_plot, rotation=45, ha='right')\n",
    "ax.set_ylabel('Accuracy')\n",
    "ax.set_title('Accuracy Comparison of Models on Datasets')\n",
    "ax.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import matplotlib.pyplot as plt\n",
    "import os  # 파일 경로 처리를 위한 모듈\n",
    "\n",
    "# CSV 파일 경로\n",
    "# csv_file_path = \"/home/bhkim003/github_folder/ByeonghyeonKim/my_snn/ae_test_deprecated/250115/sweep0_vth_mul.csv\" # vth_mul해서 sweep 돌린거\n",
    "csv_file_path = \"/home/bhkim003/github_folder/ByeonghyeonKim/my_snn/ae_test_deprecated/250115/sweep1.csv\"  #vth_mul안한거\n",
    "\n",
    "# 결과를 저장할 리스트\n",
    "tuple_list = []\n",
    "\n",
    "# CSV 파일 읽기\n",
    "with open(csv_file_path, 'r') as file:\n",
    "    reader = csv.DictReader(file)\n",
    "    for row in reader:\n",
    "        try:\n",
    "            # v_threshold, TIME, v_reset, converted_k_means_acc 값을 가져와 튜플로 변환\n",
    "            v_threshold = float(row[\"v_threshold\"])\n",
    "            time = int(row[\"TIME\"])\n",
    "            v_reset = int(row[\"v_reset\"])\n",
    "            converted_k_means_acc = float(row[\"converted_k_means_acc\"]) if row[\"converted_k_means_acc\"] else None\n",
    "\n",
    "            # 튜플 형태로 추가 (값이 None일 경우 처리할 수도 있음)\n",
    "            tuple_list.append((v_threshold, time, v_reset, converted_k_means_acc))\n",
    "        except ValueError as e:\n",
    "            print(f\"Error processing row {row}: {e}\")\n",
    "\n",
    "# 데이터를 TIME 기준으로 정렬\n",
    "tuple_list.sort(key=lambda x: x[1])  # TIME을 기준으로 오름차순 정렬\n",
    "\n",
    "# reset 방식에 따라 데이터를 나누기\n",
    "soft_reset = [t for t in tuple_list if t[2] == 0]\n",
    "hard_reset = [t for t in tuple_list if t[2] == 10000]\n",
    "\n",
    "# reset 방식과 v_threshold에 따라 색상 설정\n",
    "def plot_data(data, label_prefix, marker):\n",
    "    for v_threshold in [1.0]:  # v_threshold 기준으로 제한\n",
    "        filtered_data = [(t[1], t[3]) for t in data if t[0] == v_threshold]\n",
    "        if filtered_data:  # 해당 v_threshold 데이터가 있을 경우만 플롯\n",
    "            times, accuracies = zip(*filtered_data)  # x축(TIME), y축(converted_k_means_acc)\n",
    "            \n",
    "            plt.plot(\n",
    "                times,\n",
    "                accuracies,\n",
    "                marker,\n",
    "                label=f\"{label_prefix}, v_threshold={v_threshold}\",\n",
    "                linestyle=\"--\",\n",
    "            )\n",
    "            # 각 점에 accuracy 표시\n",
    "            for time, acc in filtered_data:\n",
    "                if acc == None:\n",
    "                    continue\n",
    "                plt.text(time, acc, f\"{acc:.2f}\", fontsize=8, ha=\"right\")\n",
    "\n",
    "# 그래프 초기화\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "# soft_reset (v_reset=0) 데이터 플롯\n",
    "plot_data(soft_reset, \"Soft Reset\", \"o\")\n",
    "\n",
    "# hard_reset (v_reset=10000) 데이터 플롯\n",
    "plot_data(hard_reset, \"Hard Reset\", \"x\")\n",
    "\n",
    "# baseline accuracy 가로선 추가\n",
    "baseline_accuracy = 94.43\n",
    "plt.axhline(y=baseline_accuracy, color=\"red\", linestyle=\"-\", label=f\"Baseline Accuracy ({baseline_accuracy}%)\")\n",
    "# baseline 텍스트 추가\n",
    "plt.text(\n",
    "    2000,  # x축 위치 (그래프 오른쪽 끝)\n",
    "    baseline_accuracy + 0.4,  # y축 위치 (baseline 위 약간)\n",
    "    f\"ANN Baseline ({baseline_accuracy}%)\",\n",
    "    color=\"red\",\n",
    "    fontsize=10,\n",
    "    ha=\"center\",\n",
    ")\n",
    "\n",
    "# CSV 파일 이름 가져오기\n",
    "csv_file_name = os.path.basename(csv_file_path)\n",
    "\n",
    "# 그래프 세부 설정\n",
    "plt.title(f\"Converted SNN K-Means Accuracy vs TIME STEP - {csv_file_name}\")\n",
    "plt.xlabel(\"TIME STEP\")\n",
    "plt.ylabel(\"Converted K-Means Accuracy [%]\")\n",
    "plt.legend(loc=\"lower right\")  # 범례를 오른쪽 아래로 이동\n",
    "plt.grid(True)\n",
    "\n",
    "# 그래프 출력\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aedat2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
