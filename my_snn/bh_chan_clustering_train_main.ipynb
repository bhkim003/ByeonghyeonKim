{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ssp.train.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x600 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import torch   \n",
    "import torch.nn as nn \n",
    "import torch.nn.functional as F   \n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import torch.optim as optim\n",
    "from scipy import io\n",
    "import itertools\n",
    "import math\n",
    "import datetime\n",
    "import wandb\n",
    "import pickle\n",
    "import json\n",
    "import time\n",
    "import sys\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import accuracy_score\n",
    "from scipy.optimize import linear_sum_assignment\n",
    "from snntorch import spikegen\n",
    "\n",
    "\n",
    "# my module import\n",
    "from modules import *\n",
    "\n",
    "# modules 폴더에 새모듈.py 만들면\n",
    "# modules/__init__py 파일에 form .새모듈 import * 하셈\n",
    "# 그리고 새모듈.py에서 from modules.새모듈 import * 하셈"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cluster_train_system( \n",
    "    gpu = '4',\n",
    "    Conv_net = True,\n",
    "    SAE_net = True,\n",
    "\n",
    "    # hyperparameter\n",
    "    dataset_num = 16,\n",
    "    spike_length = 50,\n",
    "    num_cluster = 4,  # 클러스터 수 설정 # 논문엔 4개라는데 여기서는 3개로 했네\n",
    "    training_cycle = 2400, # 그 초기 몇개까지만 cluster update할지\n",
    "\n",
    "\n",
    "    batch_size = 32,\n",
    "    max_epoch = 7000,\n",
    "    learning_rate = 0.001,\n",
    "    normalize_on = False, # True or False #이거 안 씀 # 이거 별로 안 좋은 normalize같음 # 쓸 거면 다른 거 써라.\n",
    "    need_bias = False,\n",
    "    # first_layer_no_train = False\n",
    "    lif_add_at_first = False,\n",
    "    my_seed = 42,\n",
    "\n",
    "    TIME = 10, # SAE일 때만 유효\n",
    "    v_decay = 0.5,\n",
    "    v_threshold = 0.5,\n",
    "    v_reset = 10000.0, # 10000이상 일 시 hard reset\n",
    "    BPTT_on = True,\n",
    "\n",
    "    SAE_hidden_nomean = True,\n",
    "    current_time = '20250101_210938_786',\n",
    "\n",
    "    optimizer = 'Adam',\n",
    "    coarse_com_mode = True,\n",
    "    coarse_com_config = (2.0, -2.0), # (max, min)\n",
    "\n",
    "    sae_l2_norm_bridge = True,\n",
    "    sae_lif_bridge = False,\n",
    "\n",
    "    accuracy_check_epoch_term = 5,\n",
    "    \n",
    "    lif_add_at_last = False,\n",
    "\n",
    "    two_channel_input = False,\n",
    "\n",
    "    lateral_feature_num = 4,\n",
    "\n",
    "    lc_adc_on = False, \n",
    "\n",
    "    converted_net_forward = False,\n",
    "\n",
    "    pretrained_net = None, \n",
    "\n",
    "    vth_mul_on = False,\n",
    "    batch_norm_on = False,\n",
    "\n",
    "    l2_norm_loss_weight = 0.0,\n",
    "\n",
    "    QCFS_neuron_on = False,\n",
    "    ):\n",
    "    if coarse_com_mode == True:\n",
    "        assert coarse_com_config[0] > coarse_com_config[1], 'coarse_com_config[0] > coarse_com_config[1]이어야 함'\n",
    "        assert SAE_net == True, 'coarse_com_mode는 SAE_net이 True일 때만 가능'\n",
    "    if two_channel_input == True:\n",
    "        assert Conv_net and coarse_com_mode, 'two_channel_input는 Conv_net이 True일 때만 가능'\n",
    "    if lc_adc_on == True:\n",
    "        assert coarse_com_mode and SAE_net, 'lc_adc_on은 coarse_com_mode와 SAE_net이 True일 때만 가능'\n",
    "    if converted_net_forward == True:\n",
    "        assert SAE_net == False, 'converted_net_forward는 SAE_net이 False일 때만 가능'\n",
    "    seed_assign(my_seed)\n",
    "    ## 함수 내 모든 로컬 변수 저장 ########################################################\n",
    "    hyperparameters = locals()\n",
    "    print(hyperparameters)\n",
    "    # JSON으로 저장\n",
    "    with open(f\"result_save/cluster_accuracy_history_{current_time}.json\", 'w') as f:\n",
    "        json.dump(hyperparameters, f, indent=4)\n",
    "    ######################################################################################\n",
    "\n",
    "    \n",
    "    wandb.config.update(hyperparameters)\n",
    "    wandb.run.name = f'{current_time}_SAE_net_{SAE_net}_v_threshold_{v_threshold}'\n",
    "    wandb.define_metric(\"best_mean_cluster_accuracy_post_training_cycle_all_dataset2\", summary=\"max\")\n",
    "\n",
    "\n",
    "    my_path_ground_BH = '/data2/spike_sorting/quiroga/BH/'\n",
    "\n",
    "\n",
    "    filename = [\"C_Easy1_noise005.mat\", \"C_Easy1_noise01.mat\", \"C_Easy1_noise015.mat\", \"C_Easy1_noise02.mat\",\n",
    "                \"C_Easy2_noise005.mat\", \"C_Easy2_noise01.mat\", \"C_Easy2_noise015.mat\", \"C_Easy2_noise02.mat\",\n",
    "                \"C_Difficult1_noise005.mat\", \"C_Difficult1_noise01.mat\", \"C_Difficult1_noise015.mat\", \"C_Difficult1_noise02.mat\",\n",
    "                \"C_Difficult2_noise005.mat\", \"C_Difficult2_noise01.mat\", \"C_Difficult2_noise015.mat\", \"C_Difficult2_noise02.mat\"]\n",
    "\n",
    "\n",
    "    spike_tot = [\"BH_Spike_e1n005.npy\", \"BH_Spike_e1n010.npy\", \"BH_Spike_e1n015.npy\", \"BH_Spike_e1n020.npy\",\n",
    "                \"BH_Spike_e2n005.npy\", \"BH_Spike_e2n010.npy\", \"BH_Spike_e2n015.npy\", \"BH_Spike_e2n020.npy\",\n",
    "                \"BH_Spike_d1n005.npy\", \"BH_Spike_d1n010.npy\", \"BH_Spike_d1n015.npy\", \"BH_Spike_d1n020.npy\",\n",
    "                \"BH_Spike_d2n005.npy\", \"BH_Spike_d2n010.npy\", \"BH_Spike_d2n015.npy\", \"BH_Spike_d2n020.npy\"]\n",
    "\n",
    "    label_tot = [\"BH_Label_e1n005.npy\", \"BH_Label_e1n010.npy\", \"BH_Label_e1n015.npy\", \"BH_Label_e1n020.npy\",\n",
    "                \"BH_Label_e2n005.npy\", \"BH_Label_e2n010.npy\", \"BH_Label_e2n015.npy\", \"BH_Label_e2n020.npy\",\n",
    "                \"BH_Label_d1n005.npy\", \"BH_Label_d1n010.npy\", \"BH_Label_d1n015.npy\", \"BH_Label_d1n020.npy\",\n",
    "                \"BH_Label_d2n005.npy\", \"BH_Label_d2n010.npy\", \"BH_Label_d2n015.npy\", \"BH_Label_d2n020.npy\"]\n",
    "\n",
    "    template =  [\"BH_Spike_TEMPLATE_e1n005.npy\", \"BH_Spike_TEMPLATE_e1n010.npy\", \"BH_Spike_TEMPLATE_e1n015.npy\", \"BH_Spike_TEMPLATE_e1n020.npy\",\n",
    "                \"BH_Spike_TEMPLATE_e2n005.npy\", \"BH_Spike_TEMPLATE_e2n010.npy\", \"BH_Spike_TEMPLATE_e2n015.npy\", \"BH_Spike_TEMPLATE_e2n020.npy\",\n",
    "                \"BH_Spike_TEMPLATE_d1n005.npy\", \"BH_Spike_TEMPLATE_d1n010.npy\", \"BH_Spike_TEMPLATE_d1n015.npy\", \"BH_Spike_TEMPLATE_d1n020.npy\",\n",
    "                \"BH_Spike_TEMPLATE_d2n005.npy\", \"BH_Spike_TEMPLATE_d2n010.npy\", \"BH_Spike_TEMPLATE_d2n015.npy\", \"BH_Spike_TEMPLATE_d2n020.npy\"]\n",
    "\n",
    "    AE_train_path_gt_detect = 'BH_quiroga_training_dataset_gt_detect.pt' \n",
    "    AE_test_path_gt_detect = 'BH_quiroga_test_dataset_gt_detect.pt'\n",
    "\n",
    "    AE_train_path_real_detect = 'BH_quiroga_training_dataset_real_detect.pt'\n",
    "    AE_test_path_real_detect = 'BH_quiroga_test_dataset_real_detect.pt'\n",
    "\n",
    "    AE_train_data = AE_train_path_real_detect #AE_train_path_gt_detect #AE_train_path_real_detect\n",
    "    AE_test_data = AE_test_path_real_detect #AE_test_path_gt_detect  #AE_test_path_real_detect\n",
    "\n",
    "    # thr_tot = np.array([0.5, 0.5, 0.55, 0.7, 0.5, 0.5, 0.55, 0.7, 0.5, 0.5, 0.55, 0.7, 0.5, 0.5, 0.55, 0.7])\n",
    "    cos_thr = np.array([0.95, 0.95, 0.95, 0.95, 0.95, 0.95, 0.95, 0.85, 0.95, 0.9, 0.8, 0.95, 0.95, 0.95, 0.95, 0.8])\n",
    "    # tem=10\n",
    "    # cos_thr = np.array([tem, tem, tem, tem, tem, tem, tem, tem, tem, tem, tem, tem, tem, tem, tem, tem, ])\n",
    "\n",
    "    print('cos_thr', cos_thr)\n",
    "    \n",
    "    os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\" \n",
    "    os.environ[\"CUDA_VISIBLE_DEVICES\"]= gpu\n",
    "\n",
    "\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "\n",
    "    if coarse_com_mode == True:\n",
    "        level_num = TIME\n",
    "        TIME = spike_length\n",
    "        spike_length = level_num\n",
    "        level_interval = (coarse_com_config[0] - coarse_com_config[1]) / (level_num-1)  # max - min\n",
    "        levels = [coarse_com_config[1] + level_interval * i for i in range(level_num)]\n",
    "        levels = torch.tensor(levels).to(torch.float).to(device)\n",
    "        levels = levels.repeat(TIME,1) \n",
    "        # print('levels', levels, levels.shape) # TIME, level_num\n",
    "\n",
    "    n_sample = spike_length\n",
    "\n",
    "    class spikedataset(Dataset):\n",
    "        def __init__(self, path, transform = None):    \n",
    "            self.transform = transform\n",
    "            self.spike = torch.load(path)\n",
    "            \n",
    "        def __getitem__(self, index):\n",
    "            spike = self.spike[index]            \n",
    "            if self.transform is not None:\n",
    "                spike = self.transform(spike)\n",
    "            return spike\n",
    "        \n",
    "        def __len__(self):\n",
    "            return len(self.spike)\n",
    "\n",
    "    train_dataset = spikedataset(my_path_ground_BH + AE_train_data)\n",
    "    train_loader = DataLoader(dataset = train_dataset, batch_size = batch_size, shuffle = True)\n",
    "\n",
    "    test_dataset = spikedataset(my_path_ground_BH + AE_test_data)\n",
    "    test_loader = DataLoader(dataset = test_dataset, batch_size = batch_size, shuffle = False)\n",
    "\n",
    "\n",
    "    # vth_mul_on = True # True False\n",
    "    # batch_norm_on = True # True False\n",
    "\n",
    "\n",
    "    # 모델 초기화\n",
    "    if SAE_net == False: # 여기서는 l2norm, lif bridge 둘 다 true면 l2norm먼저\n",
    "        if Conv_net == True:\n",
    "            input_channels = 2 if two_channel_input else 1\n",
    "            net = Autoencoder_conv1(input_channels=input_channels, input_length=n_sample, encoder_ch = [32, 64, 96], fc_dim = lateral_feature_num, padding = 0, stride = 2, kernel_size = 3, need_bias=need_bias, l2norm_bridge=sae_l2_norm_bridge, relu_bridge=sae_lif_bridge, activation_collector_on=False,\n",
    "                                    batch_norm_on=batch_norm_on, QCFS_neuron_on=QCFS_neuron_on).to(device)\n",
    "            net = torch.nn.DataParallel(net)\n",
    "            if converted_net_forward:\n",
    "                converted_net = SAE_converted_conv1(input_channels=input_channels, input_length=n_sample, encoder_ch = [32, 64, 96], fc_dim = lateral_feature_num, padding = 0, stride = 2, kernel_size = 3, \n",
    "                                    synapse_fc_trace_const1=1, \n",
    "                                    synapse_fc_trace_const2=v_decay, #안씀 \n",
    "                                    TIME=TIME, v_init=0.0, v_decay=v_decay, v_threshold=v_threshold, v_reset=v_reset, \n",
    "                                    sg_width=4.0, surrogate='sigmoid', BPTT_on=BPTT_on, need_bias=need_bias, lif_add_at_first=lif_add_at_first,\n",
    "                                    sae_l2_norm_bridge = sae_l2_norm_bridge, sae_lif_bridge = sae_lif_bridge, lif_add_at_last=lif_add_at_last,\n",
    "                                    vth_mul_on=vth_mul_on, batch_norm_on=batch_norm_on).to(device) # lif bridge는 무조건 들어가게 해놨음.\n",
    "                converted_net = torch.nn.DataParallel(converted_net)\n",
    "                print('converted_net', converted_net)\n",
    "        else:\n",
    "            net = Autoencoder_only_FC(encoder_ch=[400, lateral_feature_num], decoder_ch=[400,n_sample], n_sample=n_sample, need_bias=need_bias, l2norm_bridge=sae_l2_norm_bridge, relu_bridge=sae_lif_bridge, activation_collector_on=False,\n",
    "                                    batch_norm_on=batch_norm_on, QCFS_neuron_on=QCFS_neuron_on).to(device)\n",
    "            net = torch.nn.DataParallel(net)\n",
    "            if converted_net_forward:\n",
    "                converted_net = SAE_converted_fc(encoder_ch=[400, lateral_feature_num], \n",
    "                                    decoder_ch=[400, n_sample], \n",
    "                                    in_channels=n_sample, # in_channel 이 여기선 걍 lenght.\n",
    "                                    synapse_fc_trace_const1=1,\n",
    "                                    synapse_fc_trace_const2=v_decay,  #안씀 \n",
    "                                    TIME=TIME, v_init=0.0, v_decay=v_decay, v_threshold=v_threshold, v_reset=v_reset, \n",
    "                                    sg_width=4.0, surrogate='sigmoid', BPTT_on=BPTT_on, need_bias=need_bias, lif_add_at_first=lif_add_at_first,\n",
    "                                    sae_l2_norm_bridge = sae_l2_norm_bridge, sae_lif_bridge = sae_lif_bridge, lif_add_at_last=lif_add_at_last,\n",
    "                                    vth_mul_on=vth_mul_on, batch_norm_on=batch_norm_on).to(device) # lif bridge는 무조건 들어가게 해놨음.\n",
    "                converted_net = torch.nn.DataParallel(converted_net)\n",
    "                # print('converted_net', converted_net)\n",
    "    else: # 여기서는 l2norm, lif bridge 둘 다 true면 lif또는 relu먼저\n",
    "        if Conv_net == True: \n",
    "            input_channels = 2 if two_channel_input else 1\n",
    "            net = SAE_conv1(input_channels=input_channels, input_length=n_sample, encoder_ch = [32, 64, 96], fc_dim = lateral_feature_num, padding = 0, stride = 2, kernel_size = 3, \n",
    "                                synapse_fc_trace_const1=1, \n",
    "                                synapse_fc_trace_const2=v_decay, #안씀 \n",
    "                                TIME=TIME, v_init=0.0, v_decay=v_decay, v_threshold=v_threshold, v_reset=v_reset, \n",
    "                                sg_width=4.0, surrogate='sigmoid', BPTT_on=BPTT_on, need_bias=need_bias, lif_add_at_first=lif_add_at_first,\n",
    "                                sae_l2_norm_bridge = sae_l2_norm_bridge, sae_lif_bridge = sae_lif_bridge, lif_add_at_last=lif_add_at_last).to(device)\n",
    "            net = torch.nn.DataParallel(net)\n",
    "        else:\n",
    "            net = SAE_fc_only(encoder_ch=[400, lateral_feature_num], \n",
    "                                decoder_ch=[400, n_sample], \n",
    "                                in_channels=n_sample, # in_channel 이 여기선 걍 lenght.\n",
    "                                synapse_fc_trace_const1=1,\n",
    "                                synapse_fc_trace_const2=v_decay,  #안씀 \n",
    "                                TIME=TIME, v_init=0.0, v_decay=v_decay, v_threshold=v_threshold, v_reset=v_reset, \n",
    "                                sg_width=4.0, surrogate='sigmoid', BPTT_on=BPTT_on, need_bias=need_bias, lif_add_at_first=lif_add_at_first,\n",
    "                                sae_l2_norm_bridge = sae_l2_norm_bridge, sae_lif_bridge = sae_lif_bridge, lif_add_at_last=lif_add_at_last).to(device)\n",
    "            net = torch.nn.DataParallel(net)\n",
    "\n",
    "    # net = torch.load('/home/bhkim003/github_folder/ByeonghyeonKim/my_snn/net_save/save_now_net_AE_re_e7000.pth')\n",
    "    # net = torch.load('/home/bhkim003/github_folder/ByeonghyeonKim/my_snn/net_save/save_now_net_20250101_210938_786.pth')\n",
    "    # load했으면 torch.nn.DataParallel 하지마\n",
    "    # net.module.load_state_dict(torch.load('/home/bhkim003/github_folder/ByeonghyeonKim/my_snn/net_save/save_now_net_annbase_20250108_210641_941.pth'))\n",
    "    if pretrained_net != None:\n",
    "        ######################## 모델이 달라서 dict로 weight만 넣고싶을 때\n",
    "        # # 저장된 가중치 로드\n",
    "        saved_state_dict = torch.load(pretrained_net)\n",
    "        current_state_dict = net.module.state_dict()\n",
    "\n",
    "        # 함수 호출로 가중치 매핑\n",
    "        updated_state_dict = map_and_load_weights(saved_state_dict, current_state_dict)\n",
    "\n",
    "        # 업데이트된 state_dict를 네트워크에 로드\n",
    "        net.module.load_state_dict(updated_state_dict)\n",
    "        ######################## 모델이 달라서 dict로 weight만 넣고싶을 때\n",
    "\n",
    "        ############## 일반적일 때\n",
    "        # net.module.load_state_dict(torch.load(pretrained_net))\n",
    "        ############## 일반적일 때\n",
    "    \n",
    "        # pre_net = Autoencoder_conv1(input_channels=input_channels, input_length=n_sample, encoder_ch = [32, 64, 96], fc_dim = lateral_feature_num, padding = 0, stride = 2, kernel_size = 3, need_bias=need_bias, l2norm_bridge=sae_l2_norm_bridge, relu_bridge=sae_lif_bridge, activation_collector_on=False,\n",
    "        #                         batch_norm_on=batch_norm_on, QCFS_neuron_on=False).to(device)\n",
    "        # pre_net = torch.nn.DataParallel(net)\n",
    "        # pre_net.module.load_state_dict(torch.load(pretrained_net))\n",
    "        # copy_weights(pre_net.module.encoder , net.module.encoder )\n",
    "        # copy_weights(pre_net.module.decoder , net.module.decoder  )\n",
    "\n",
    "        \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    wandb.watch(net, log=\"all\", log_freq = 10)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    if SAE_net == True:\n",
    "        assert 'SAE' in net.module.__class__.__name__\n",
    "\n",
    "\n",
    "\n",
    "    net = net.to(device)\n",
    "    print(f\"Total number of encoder parameters: {sum(p.numel() for p in net.module.encoder.parameters())}\")\n",
    "    print(net)\n",
    "    print('Device:',device)\n",
    "\n",
    "    \n",
    "    if optimizer == 'Adam':\n",
    "        optimizer = optim.Adam(net.parameters(), lr=learning_rate)\n",
    "    elif optimizer == 'SGD':\n",
    "        optimizer = optim.SGD(net.parameters(), lr = learning_rate, momentum = 0.9)\n",
    "    else:\n",
    "        assert False, 'optimizer를 잘못 입력했습니다.'\n",
    "        \n",
    "    loss_history = []\n",
    "    mean_cluster_accuracy_during_training_cycle_all_dataset_history = []\n",
    "    mean_cluster_accuracy_post_training_cycle_all_dataset_history = []\n",
    "    mean_cluster_accuracy_total_all_dataset_history = []\n",
    "\n",
    "    tau = np.zeros(num_cluster)\n",
    "\n",
    "    print(f\"\\nStart Training, current_time = {current_time}\")\n",
    "    mean_cluster_accuracy_post_training_cycle_all_dataset = 0\n",
    "    best_mean_cluster_accuracy_post_training_cycle_all_dataset = 0\n",
    "\n",
    "    if SAE_net == True:\n",
    "        assert 'SAE' in net.module.__class__.__name__\n",
    "        \n",
    "    k_means_acc_best = 0\n",
    "    for epoch in range(max_epoch):\n",
    "        print()\n",
    "        l2_loss_bin= 0\n",
    "        ae_train_start_time = time.time()\n",
    "        running_loss = 0.0\n",
    "        iter = 0\n",
    "        net.train()\n",
    "        # if True or max_epoch != 1:\n",
    "        if max_epoch != 1:\n",
    "            for data in train_loader:\n",
    "                optimizer.zero_grad()\n",
    "                data = data.to(device)\n",
    "                data = zero_to_one_normalize_features(data) if normalize_on else data\n",
    "                spike_backup = data\n",
    "                spike = data\n",
    "                spike = spike.to(device) # batch, feature\n",
    "                if coarse_com_mode == True and 'SAE' in net.module.__class__.__name__:\n",
    "                    spike = spike.unsqueeze(2).repeat(1, 1, level_num) # spike_length == level_num # (batch, time, feature)로 변환 \n",
    "                    spike = (spike > levels).to(torch.float) \n",
    "\n",
    "                    spike = (spike == 0).cumsum(dim=-1).eq(1).to(torch.float) if lc_adc_on == True else spike\n",
    "\n",
    "                    # spike: batch, time, level_num\n",
    "                    # levels: time, level_num\n",
    "                    if Conv_net == True:\n",
    "                        spike = spike.unsqueeze(-2) # batch, time, in_channel, feature or batch in_channel,feature\n",
    "                        if two_channel_input == True:\n",
    "                            spike_backup = spike_backup.to(device)\n",
    "                            spike_backup = spike_backup.unsqueeze(2).repeat(1, 1, level_num) # spike_length == level_num # (batch, time, feature)로 변환 \n",
    "                            spike_backup = (spike_backup <= levels).to(torch.float) \n",
    "                            spike_backup = (spike_backup == 1).cumsum(dim=-1).eq(1).to(torch.float) if lc_adc_on == True else spike_backup\n",
    "                            spike_backup = spike_backup.unsqueeze(-2)\n",
    "                            spike = torch.cat((spike, spike_backup), dim=-2)\n",
    "                    assert spike.shape[0] == batch_size and spike.shape[1] == TIME\n",
    "                elif 'SAE' in net.module.__class__.__name__:\n",
    "                    spike = spike.unsqueeze(-1).repeat(1, 1, TIME).permute(0,2,1) # (batch, time, feature)로 변환\n",
    "                    if Conv_net == True:\n",
    "                        spike = spike.unsqueeze(-2) # batch, time, in_channel, feature or batch in_channel,feature\n",
    "                else:\n",
    "                    if Conv_net == True:\n",
    "                        spike = spike.unsqueeze(-2) #batch in_channel,feature\n",
    "\n",
    "                # for i in range (3):\n",
    "                #     plot_spike(spike[i,:,0,:].cpu().numpy())\n",
    "                #     plot_spike(spike[i,:,1,:].cpu().numpy())\n",
    "                # assert False\n",
    "                        \n",
    "                # spike_class = net(spike) # batch, time, feature\n",
    "                encoded_spike = net.module.encoder(spike)\n",
    "                spike_class = net.module.decoder(encoded_spike)\n",
    "\n",
    "                if coarse_com_mode == True and 'SAE' in net.module.__class__.__name__:\n",
    "                    criterion = nn.MSELoss().to(device)\n",
    "                    # loss1 = nn.MSELoss()(spike_class[..., 5:25], spike[..., 5:25])\n",
    "                    # loss2 = nn.MSELoss()(spike_class[..., 0:5], spike[..., 0:5])\n",
    "                    # loss3 = nn.MSELoss()(spike_class[..., 25:spike_length], spike[..., 25:spike_length])\n",
    "                    # loss = loss1 * 2.125 + (loss2 + loss3)/4\n",
    "\n",
    "                    # loss1 = nn.MSELoss()(spike_class[..., 5:25, :], spike[..., 5:25, :])\n",
    "                    # loss2 = nn.MSELoss()(spike_class[..., 0:5, :], spike[..., 0:5, :])\n",
    "                    # loss3 = nn.MSELoss()(spike_class[..., 25:spike_length, :], spike[..., 25:spike_length, :])\n",
    "                    # loss = loss1 * 2.125 + (loss2 + loss3)/4\n",
    "\n",
    "                    loss = criterion(spike_class, spike)\n",
    "                elif 'SAE' in net.module.__class__.__name__:\n",
    "                    criterion = nn.MSELoss().to(device)\n",
    "                    loss1 = criterion(spike_class[..., 5:25], spike[..., 5:25])\n",
    "                    loss2 = criterion(spike_class[..., 0:5], spike[..., 0:5])\n",
    "                    loss3 = criterion(spike_class[..., 25:spike_length], spike[..., 25:spike_length])\n",
    "                    loss = loss1 * 2.125 + (loss2 + loss3)/4\n",
    "                    assert spike_length > 25, 'spike_length가 25보다 작음'\n",
    "                else:\n",
    "\n",
    "                    criterion = nn.MSELoss().to(device)\n",
    "                    loss1 = criterion(spike_class[..., 5:25], spike[..., 5:25])\n",
    "                    loss2 = criterion(spike_class[..., 0:5], spike[..., 0:5])\n",
    "                    loss3 = criterion(spike_class[..., 25:spike_length], spike[..., 25:spike_length])\n",
    "                    loss = loss1 * 2.125 + (loss2 + loss3)/4\n",
    "                    assert spike_length > 25, 'spike_length가 25보다 작음'\n",
    "\n",
    "                    if l2_norm_loss_weight > 0:\n",
    "                        assert len(encoded_spike.shape) == 2, 'time 성분 없는 걸로'\n",
    "                        l2_loss = l2_norm_loss(encoded_spike, target_norm=1.0)  # L2Norm Loss 계산, l2 1.0되게.\n",
    "                        loss = loss + l2_loss*l2_norm_loss_weight\n",
    "                        l2_loss_bin += l2_loss.item()\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                running_loss += loss.item()\n",
    "                # print(f'\\nepoch-{epoch}, running_loss : {running_loss:.5f}, iter percent {iter/len(train_loader)*100:.2f}%')\n",
    "                iter += 1\n",
    "        else:\n",
    "            print('\\n\\n\\n max_epoch 1이면 Train 안함!!!!!!!!!!!!!!!!!!!!!')\n",
    "        if l2_norm_loss_weight > 0:\n",
    "            print('l2_loss_bin', l2_loss_bin/len(train_loader))\n",
    "        avg_loss = running_loss / len(train_loader)\n",
    "        assert not np.isnan(avg_loss), f\"Error: avg_loss is NaN! Running loss: {running_loss}, Length of train_loader: {len(train_loader)}\"\n",
    "        loss_history.append((epoch, avg_loss))\n",
    "        print(f'\\nepoch-{epoch} loss : {avg_loss:.5f}')\n",
    "        print(f\"ae train 실행 시간: {time.time()-ae_train_start_time:.3f}초, 전체 시작 시간 {current_time}\")\n",
    "\n",
    "        # plot_activation_distribution(net)\n",
    "\n",
    "        if SAE_net == False and converted_net_forward == True:\n",
    "            source_encoder = net.module.encoder \n",
    "            target_encoder = converted_net.module.encoder  \n",
    "            copy_weights(source_encoder, target_encoder)\n",
    "\n",
    "        cluster_accuracy_during_training_cycle_all_dataset = np.zeros(dataset_num)\n",
    "        cluster_accuracy_post_training_cycle_all_dataset = np.zeros(dataset_num)\n",
    "        cluster_accuracy_total_all_dataset = np.zeros(dataset_num)    \n",
    "\n",
    "        k_means_acc = 0\n",
    "        converted_k_means_acc = 0\n",
    "        if(epoch % accuracy_check_epoch_term == 0 or epoch == 1 or epoch == max_epoch-1): \n",
    "            accuracy_check_start_time = time.time()\n",
    "            print(f'\\nepoch-{epoch} accuracy check')\n",
    "            k_means_bin_origin_feature = []\n",
    "            k_means_bin = []\n",
    "            converted_k_means_bin = []\n",
    "            for ds in range(dataset_num):\n",
    "                # print('\\n', spike_tot[ds])\n",
    "\n",
    "                spike_template = np.load(my_path_ground_BH + template[ds])\n",
    "                spike = np.load(my_path_ground_BH + spike_tot[ds])\n",
    "                label = np.load(my_path_ground_BH + label_tot[ds])\n",
    "                spike_template = torch.from_numpy(spike_template).to(device)\n",
    "                spike = torch.from_numpy(spike).to(device)\n",
    "                spike_template = zero_to_one_normalize_features(spike_template) if normalize_on else spike_template\n",
    "                spike = zero_to_one_normalize_features(spike) if normalize_on else spike\n",
    "                \n",
    "                hidden_size = lateral_feature_num*TIME if 'SAE' in net.module.__class__.__name__ and SAE_hidden_nomean == True else lateral_feature_num\n",
    "\n",
    "                Cluster = np.zeros((num_cluster, hidden_size))\n",
    "                assert Cluster.shape[-1] == hidden_size, '이거 hidden dim 4 아니게 할 거면 잘 바꿔라'\n",
    "                \n",
    "\n",
    "\n",
    "                net.eval()\n",
    "                with torch.no_grad():\n",
    "                    spike_torch = spike_template.float()\n",
    "                    spike_torch = spike_torch[:num_cluster]\n",
    "                    spike_backup = spike_torch\n",
    "                    spike_torch = spike_torch.to(device)\n",
    "                    if coarse_com_mode == True and 'SAE' in net.module.__class__.__name__:\n",
    "                        spike_torch = spike_torch.unsqueeze(2).repeat(1, 1, level_num) # spike_length == level_num # (batch, time, feature)로 변환 \n",
    "                        spike_torch = (spike_torch > levels).to(torch.float) \n",
    "                        spike_torch = (spike_torch == 0).cumsum(dim=-1).eq(1).to(torch.float) if lc_adc_on == True else spike_torch\n",
    "                        if Conv_net == True:\n",
    "                            spike_torch = spike_torch.unsqueeze(-2) # batch, time, in_channel, feature or batch in_channel,feature\n",
    "                            if two_channel_input == True:\n",
    "                                spike_backup = spike_backup.to(device)\n",
    "                                spike_backup = spike_backup.unsqueeze(2).repeat(1, 1, level_num) # spike_length == level_num # (batch, time, feature)로 변환 \n",
    "                                spike_backup = (spike_backup <= levels).to(torch.float) \n",
    "                                spike_backup = (spike_backup == 1).cumsum(dim=-1).eq(1).to(torch.float) if lc_adc_on == True else spike_backup\n",
    "                                spike_backup = spike_backup.unsqueeze(-2) # batch, time, in_channel, feature\n",
    "                                spike_torch = torch.cat((spike_torch, spike_backup), dim=-2)\n",
    "                    elif 'SAE' in net.module.__class__.__name__:\n",
    "                        spike_torch = spike_torch.unsqueeze(1).repeat(1, TIME, 1) # (batch, time, feature)로 변환\n",
    "                        if Conv_net == True:\n",
    "                            spike_torch = spike_torch.unsqueeze(-2) # batch, time, in_channel, feature or batch in_channel,feature\n",
    "                    else:\n",
    "                        if Conv_net == True:\n",
    "                            spike_torch = spike_torch.unsqueeze(-2) #batch in_channel,feature\n",
    "                        if converted_net_forward == True:\n",
    "                            spike_torch_spikegen = spikegen.rate(spike_torch, num_steps=TIME).transpose(0, 1)\n",
    "                    ### forward #######################################################\n",
    "                    inner_inf = net.module.encoder(spike_torch)\n",
    "                    if SAE_net == False and converted_net_forward == True:\n",
    "                        converted_inner_inf = converted_net.module.encoder(spike_torch_spikegen)\n",
    "                    ### forward #######################################################\n",
    "\n",
    "                    # for i in range(3):\n",
    "                    #     plot_spike(spike_torch[i,:,:].cpu().numpy())\n",
    "                    #     plot_spike(inner_inf[i,:].cpu().numpy())\n",
    "                    #     plot_spike(net.module.decoder(inner_inf)[i,:,:].cpu().numpy())\n",
    "                        \n",
    "                    # if 'SAE' in net.module.__class__.__name__:\n",
    "                    #     tensors = [inner_inf[0][i] for i in range(TIME)] \n",
    "                    #     all_equal = all(torch.equal(tensors[0], t) for t in tensors)\n",
    "                    #     print(all_equal, inner_inf)\n",
    "\n",
    "                    if 'SAE' in net.module.__class__.__name__:\n",
    "                        if SAE_hidden_nomean == True:\n",
    "                            inner_inf = inner_inf.reshape(inner_inf.shape[0],-1)# time*feature 펼치기\n",
    "                        else:\n",
    "                            inner_inf = inner_inf.mean(dim=1)# Time 방향으로 평균\n",
    "\n",
    "                    Cluster = inner_inf.cpu().detach().numpy()\n",
    "\n",
    "                encoder_batch = 128\n",
    "                spike_hidden = np.zeros((len(spike), hidden_size))\n",
    "                converted_spike_hidden = np.zeros((len(spike), hidden_size))\n",
    "                net.eval()\n",
    "                with torch.no_grad():\n",
    "                    now_index = 0\n",
    "                    while (1):\n",
    "                        now_end_index = now_index+encoder_batch if now_index+encoder_batch < len(spike) else len(spike)\n",
    "                        spike_batch = spike[now_index:now_end_index] \n",
    "                        spike_torch = spike_batch\n",
    "                        spike_torch = spike_torch.float()\n",
    "                        spike_backup = spike_torch\n",
    "                        spike_torch = spike_torch.to(device)\n",
    "                        if coarse_com_mode == True and 'SAE' in net.module.__class__.__name__:\n",
    "                            spike_torch = spike_torch.unsqueeze(2).repeat(1, 1, level_num) # spike_length == level_num # (batch, time, feature)로 변환 \n",
    "                            spike_torch = (spike_torch > levels).to(torch.float) \n",
    "                            spike_torch = (spike_torch == 0).cumsum(dim=-1).eq(1).to(torch.float) if lc_adc_on == True else spike_torch\n",
    "                            if Conv_net == True:\n",
    "                                spike_torch = spike_torch.unsqueeze(-2) # batch, time, in_channel, feature or batch in_channel,feature\n",
    "                                if two_channel_input == True:\n",
    "                                    spike_backup = spike_backup.to(device)\n",
    "                                    spike_backup = spike_backup.unsqueeze(2).repeat(1, 1, level_num) # spike_length == level_num # (batch, time, feature)로 변환 \n",
    "                                    spike_backup = (spike_backup <= levels).to(torch.float) \n",
    "                                    spike_backup = (spike_backup == 1).cumsum(dim=-1).eq(1).to(torch.float) if lc_adc_on == True else spike_backup\n",
    "                                    spike_backup = spike_backup.unsqueeze(-2)\n",
    "                                    spike_torch = torch.cat((spike_torch, spike_backup), dim=-2)\n",
    "                        elif 'SAE' in net.module.__class__.__name__:\n",
    "                            spike_torch = spike_torch.unsqueeze(1).repeat(1, TIME, 1) # (batch, time, feature)로 변환\n",
    "                            if Conv_net == True:\n",
    "                                spike_torch = spike_torch.unsqueeze(-2) # batch, time, in_channel, feature or batch in_channel,feature\n",
    "                        else:\n",
    "                            if Conv_net == True:\n",
    "                                spike_torch = spike_torch.unsqueeze(-2) #batch in_channel,feature\n",
    "                            if converted_net_forward == True:\n",
    "                                spike_torch_spikegen = spikegen.rate(spike_torch, num_steps=TIME).transpose(0, 1)\n",
    "                                \n",
    "                        ### forward #######################################################\n",
    "                        inner_inf = net.module.encoder(spike_torch)\n",
    "                        if SAE_net == False and converted_net_forward == True:\n",
    "                            converted_inner_inf = converted_net.module.encoder(spike_torch_spikegen)\n",
    "                        ### forward #######################################################\n",
    "                            \n",
    "                        if 'SAE' in net.module.__class__.__name__:\n",
    "                            if SAE_hidden_nomean == True:\n",
    "                                inner_inf = inner_inf.reshape(spike_batch.shape[0],-1)# 펼치기\n",
    "                            else:\n",
    "                                inner_inf = inner_inf.mean(dim=1)# Time 방향으로 평균\n",
    "                        spike_hidden[now_index:now_end_index] = inner_inf.cpu().detach().numpy()\n",
    "                        if SAE_net == False and converted_net_forward == True:\n",
    "                            converted_spike_hidden[now_index:now_end_index] = converted_inner_inf.cpu().detach().numpy()\n",
    "                        now_index += encoder_batch\n",
    "                        if (now_index >= len(spike)):\n",
    "                            break\n",
    "                    \n",
    "                spike_id = np.zeros(len(spike))\n",
    "                distance_sm = np.zeros(num_cluster)\n",
    "                tau = np.zeros(num_cluster)\n",
    "                \n",
    "                plot_tau = []\n",
    "                plot_denominator = []\n",
    "                plot_m = []\n",
    "                plot_max_tau = []\n",
    "                for spike_index in range(len(spike)): \n",
    "                    for q in range(num_cluster):\n",
    "                        tau[q] = np.dot(spike_hidden[spike_index, :], Cluster[q, :]) # 이거 l2norm 거쳐서 나온 거니까 분모 1임.\n",
    "                        denominator =  np.linalg.norm(spike_hidden[spike_index, :])*np.linalg.norm(Cluster[q, :]) + 1e-12\n",
    "                        plot_denominator.append(denominator)\n",
    "                        if 'SAE' in net.module.__class__.__name__: # AE 때는 l2norm거쳐서 나와서 괜찮음\n",
    "                            tau[q] = tau[q] / denominator\n",
    "\n",
    "                        plot_tau.append(tau[q])\n",
    "\n",
    "                    # for i in range(num_cluster): # l2 distance\n",
    "                    #     distance_sm[i] = np.sum(np.power(np.abs(Cluster[i] - spike_hidden[spike_index, :]), 2))\n",
    "                    distance_sm = np.sum(np.power(np.abs(Cluster - spike_hidden[spike_index, :]), 2), axis=1)\n",
    "\n",
    "                    m = np.argmin(distance_sm)\n",
    "                    plot_m.append(m)\n",
    "                    spike_id[spike_index] = m + 1\n",
    "                    # print(spike_tot[ds], spike_index,np.max(tau))\n",
    "                    plot_max_tau.append(np.max(tau))\n",
    "                    if(np.max(tau) >= cos_thr[ds] and spike_index < training_cycle): # 원래 1400 아니냐?\n",
    "                        Cluster[m] = (Cluster[m] * 15 + spike_hidden[spike_index, :])/16\n",
    "\n",
    "\n",
    "                \n",
    "                origin_kmeans_accuracy = cluster_spikes_with_accuracy_torch(features= spike, true_labels=label-1, n_clusters=3, init_point=None)\n",
    "                kmeans_accuracy = cluster_spikes_with_accuracy_torch(features= torch.tensor(spike_hidden).to(device), true_labels=label-1, n_clusters=3, init_point=None)\n",
    "                k_means_bin_origin_feature.append(origin_kmeans_accuracy)\n",
    "                k_means_bin.append(kmeans_accuracy)\n",
    "                if SAE_net == False and converted_net_forward == True:\n",
    "                    converted_kmeans_accuracy = cluster_spikes_with_accuracy_torch(features= torch.tensor(converted_spike_hidden).to(device), true_labels=label-1, n_clusters=3, init_point=None)\n",
    "                    converted_k_means_bin.append(converted_kmeans_accuracy)\n",
    "                # sklearn kmeans인데 cpu많이먹어서 버림.\n",
    "                # origin_kmeans_accuracy = cluster_spikes_with_accuracy(features= spike.cpu().detach().numpy(), true_labels=label-1, n_clusters=3, init_point=None)\n",
    "                # kmeans_accuracy = cluster_spikes_with_accuracy(features= spike_hidden, true_labels=label-1, n_clusters=3, init_point=None)\n",
    "                # k_means_bin_origin_feature.append(origin_kmeans_accuracy)\n",
    "                # k_means_bin.append(kmeans_accuracy)\n",
    "                # if SAE_net == False and converted_net_forward == True:\n",
    "                #     converted_kmeans_accuracy = cluster_spikes_with_accuracy(features= converted_spike_hidden, true_labels=label-1, n_clusters=3, init_point=None)\n",
    "                #     converted_k_means_bin.append(converted_kmeans_accuracy)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "                # print('Cluster',Cluster)\n",
    "                # print('spike_id', spike_id)\n",
    "\n",
    "                # spike id 분포 확인하기\n",
    "                # unique_elements, counts = np.unique(spike_id, return_counts=True)\n",
    "                # print(\"Unique elements:\", unique_elements)\n",
    "                # print(\"Counts:\", counts)\n",
    "\n",
    "                cluster_accuracy_during_training_cycle = np.zeros(math.factorial(num_cluster))\n",
    "                cluster_accuracy_post_training_cycle = np.zeros(math.factorial(num_cluster))\n",
    "                cluster_accuracy_total = np.zeros(math.factorial(num_cluster))\n",
    "                \n",
    "                label_converter_ground = list(range(1, num_cluster + 1)) # [1, 2, 3, 4] 생성\n",
    "                label_converter_permutations = list(itertools.permutations(label_converter_ground)) # 모든 순열 구하기\n",
    "                perm_i = 0\n",
    "                perm_start_time = time.time() \n",
    "                for perm in label_converter_permutations:\n",
    "                    label_converter = list(perm)\n",
    "                    # print(label_converter)\n",
    "                    correct_during_training_cycle = 0\n",
    "                    correct_post_training_cycle = 0\n",
    "\n",
    "                    assert len(spike_id) == len(label), 'spike_id랑 label 길이 같아야 됨.'\n",
    "                    for i in range(len(spike_id)):\n",
    "                        if(label_converter[int(spike_id[i]-1)] == label[i]):\n",
    "                            if i < training_cycle:\n",
    "                                correct_during_training_cycle += 1\n",
    "                            else:\n",
    "                                correct_post_training_cycle += 1\n",
    "\n",
    "                    cluster_accuracy_during_training_cycle[perm_i] = correct_during_training_cycle/training_cycle\n",
    "                    cluster_accuracy_post_training_cycle[perm_i] = correct_post_training_cycle/(len(spike_id)-training_cycle)\n",
    "                    cluster_accuracy_total[perm_i] = (correct_during_training_cycle+correct_post_training_cycle)/(len(spike_id))\n",
    "                    perm_i += 1\n",
    "                # print(f\"perm 실행 시간: {time.time()-perm_start_time:.3f}초\")\n",
    "                \n",
    "                cluster_accuracy_during_training_cycle_all_dataset[ds] = np.max(cluster_accuracy_during_training_cycle)\n",
    "                cluster_accuracy_post_training_cycle_all_dataset[ds] = cluster_accuracy_post_training_cycle[np.argmax(cluster_accuracy_during_training_cycle)]\n",
    "                cluster_accuracy_total_all_dataset[ds] = cluster_accuracy_total[np.argmax(cluster_accuracy_during_training_cycle)]\n",
    "                # plot_distributions(ds, plot_tau, plot_denominator, plot_m, plot_max_tau, cos_thr[ds],\n",
    "                #                    cluster_accuracy_during_training_cycle_all_dataset[ds], cluster_accuracy_post_training_cycle_all_dataset[ds], cluster_accuracy_total_all_dataset[ds])\n",
    "            print(f'k_means origin feature average accuracy : {100*sum(k_means_bin_origin_feature)/(len(k_means_bin_origin_feature)+1e-12):.8f}%, total {k_means_bin_origin_feature}')\n",
    "            if SAE_net == False and converted_net_forward == True:\n",
    "                converted_k_means_acc = 100*sum(converted_k_means_bin)/len(converted_k_means_bin)\n",
    "                print(f'converted_kmeans average accuracy : {converted_k_means_acc:.8f}%, total {converted_k_means_bin}')\n",
    "            k_means_acc = 100*sum(k_means_bin)/len(k_means_bin)\n",
    "            if k_means_acc > k_means_acc_best:\n",
    "                # torch.save(net, f\"net_save/save_now_net_{current_time}.pth\")\n",
    "                torch.save(net.module.state_dict(), f\"net_save/save_now_net_{current_time}.pth\")\n",
    "                print('save model')\n",
    "                best_mean_cluster_accuracy_post_training_cycle_all_dataset = mean_cluster_accuracy_post_training_cycle_all_dataset\n",
    "            \n",
    "            k_means_acc_best = max(k_means_acc_best, k_means_acc)\n",
    "            print(f'kmeans average accuracy best : {k_means_acc_best:.2f}%, kmeans average accuracy : {k_means_acc:.8f}%, total {k_means_bin}')\n",
    "            print(f'cluster_accuracy_post_training_cycle_all_dataset : {cluster_accuracy_post_training_cycle_all_dataset}')\n",
    "\n",
    "\n",
    "            mean_cluster_accuracy_during_training_cycle_all_dataset = np.mean(cluster_accuracy_during_training_cycle_all_dataset)\n",
    "            mean_cluster_accuracy_post_training_cycle_all_dataset = np.mean(cluster_accuracy_post_training_cycle_all_dataset)\n",
    "            mean_cluster_accuracy_total_all_dataset = np.mean(cluster_accuracy_total_all_dataset)\n",
    "            \n",
    "            mean_cluster_accuracy_during_training_cycle_all_dataset_history.append((epoch, mean_cluster_accuracy_during_training_cycle_all_dataset*100))\n",
    "            mean_cluster_accuracy_post_training_cycle_all_dataset_history.append((epoch, mean_cluster_accuracy_post_training_cycle_all_dataset*100))\n",
    "            mean_cluster_accuracy_total_all_dataset_history.append((epoch, mean_cluster_accuracy_total_all_dataset*100))\n",
    "            print(f\"mean_cluster_accuracy_during_training_cycle : {mean_cluster_accuracy_during_training_cycle_all_dataset*100:.2f}%, post_traincycle_acc : {mean_cluster_accuracy_post_training_cycle_all_dataset*100:.2f}%, total_acc : {mean_cluster_accuracy_total_all_dataset*100:.8f}%\")\n",
    "\n",
    "            # kmeans accuracy기준으로 좋은 거 저장할 거임\n",
    "            # if mean_cluster_accuracy_post_training_cycle_all_dataset > best_mean_cluster_accuracy_post_training_cycle_all_dataset:\n",
    "            #     # torch.save(net, f\"net_save/save_now_net_{current_time}.pth\")\n",
    "            #     torch.save(net.module.state_dict(), f\"net_save/save_now_net_{current_time}.pth\")\n",
    "            #     print('save model')\n",
    "            #     best_mean_cluster_accuracy_post_training_cycle_all_dataset = mean_cluster_accuracy_post_training_cycle_all_dataset\n",
    "            print(f\"best_mean_cluster_accuracy_post_training_cycle_all_dataset : {best_mean_cluster_accuracy_post_training_cycle_all_dataset*100:.2f}%\")\n",
    "            print(f\"accuracy_check 실행 시간: {time.time()-accuracy_check_start_time:.3f}초\")\n",
    "\n",
    "        wandb.log({\"avg_loss\": avg_loss})\n",
    "        wandb.log({\"mean_cluster_accuracy_post_training_cycle_all_dataset\": mean_cluster_accuracy_post_training_cycle_all_dataset})\n",
    "        wandb.log({\"best_mean_cluster_accuracy_post_training_cycle_all_dataset\": best_mean_cluster_accuracy_post_training_cycle_all_dataset})\n",
    "        wandb.log({\"best_mean_cluster_accuracy_post_training_cycle_all_dataset2\": best_mean_cluster_accuracy_post_training_cycle_all_dataset})\n",
    "        wandb.log({\"k_means_acc\": k_means_acc})\n",
    "        wandb.log({\"k_means_acc_best\": k_means_acc_best})\n",
    "        wandb.log({\"converted_k_means_acc\": converted_k_means_acc})\n",
    "\n",
    "\n",
    "        # 저장\n",
    "        with open(f\"result_save/cluster_accuracy_history_{current_time}.pkl\", \"wb\") as f:\n",
    "            pickle.dump({\n",
    "                \"loss_history\": loss_history,\n",
    "                \"mean_cluster_accuracy_during_training_cycle_all_dataset_history\": mean_cluster_accuracy_during_training_cycle_all_dataset_history,\n",
    "                \"mean_cluster_accuracy_post_training_cycle_all_dataset_history\": mean_cluster_accuracy_post_training_cycle_all_dataset_history,\n",
    "                \"mean_cluster_accuracy_total_all_dataset_history\": mean_cluster_accuracy_total_all_dataset_history,\n",
    "            }, f)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mbhkim003\u001b[0m (\u001b[33mbhkim003-seoul-national-university\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.19.4 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.17.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/nfs/home/bhkim003/github_folder/ByeonghyeonKim/my_snn/wandb/run-20250123_143345-3og0j15m</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/bhkim003-seoul-national-university/spike_sorting%20just%20run/runs/3og0j15m' target=\"_blank\">playful-bush-789</a></strong> to <a href='https://wandb.ai/bhkim003-seoul-national-university/spike_sorting%20just%20run' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/bhkim003-seoul-national-university/spike_sorting%20just%20run' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/spike_sorting%20just%20run</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/bhkim003-seoul-national-university/spike_sorting%20just%20run/runs/3og0j15m' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/spike_sorting%20just%20run/runs/3og0j15m</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'gpu': '0', 'Conv_net': True, 'SAE_net': True, 'dataset_num': 16, 'spike_length': 50, 'num_cluster': 4, 'training_cycle': 2400, 'batch_size': 32, 'max_epoch': 7000, 'learning_rate': 0.001, 'normalize_on': True, 'need_bias': False, 'lif_add_at_first': False, 'my_seed': 42, 'TIME': 50, 'v_decay': 0.25, 'v_threshold': 0.5, 'v_reset': 10000.0, 'BPTT_on': False, 'SAE_hidden_nomean': True, 'current_time': '20250123_143343_030', 'optimizer': 'Adam', 'coarse_com_mode': True, 'sae_l2_norm_bridge': True, 'sae_lif_bridge': True, 'accuracy_check_epoch_term': 1, 'lif_add_at_last': False, 'two_channel_input': False, 'lateral_feature_num': 4, 'lc_adc_on': False, 'converted_net_forward': False, 'pretrained_net': None, 'vth_mul_on': False, 'batch_norm_on': False, 'l2_norm_loss_weight': 0, 'QCFS_neuron_on': False, 'coarse_com_config': (1.0, -0.0)}\n",
      "cos_thr [0.95 0.95 0.95 0.95 0.95 0.95 0.95 0.85 0.95 0.9  0.8  0.95 0.95 0.95\n",
      " 0.95 0.8 ]\n",
      "conv length [50, 24, 11, 5]\n",
      "Total number of encoder parameters: 26592\n",
      "DataParallel(\n",
      "  (module): SAE_conv1(\n",
      "    (encoder): Sequential(\n",
      "      (0): SSBH_DimChanger_one_two()\n",
      "      (1): SSBH_DimChanger_for_one_two_coupling()\n",
      "      (2): Conv1d(1, 32, kernel_size=(3,), stride=(2,), bias=False)\n",
      "      (3): SSBH_DimChanger_for_one_two_decoupling()\n",
      "      (4): LIF_layer()\n",
      "      (5): SSBH_DimChanger_for_one_two_coupling()\n",
      "      (6): Conv1d(32, 64, kernel_size=(3,), stride=(2,), bias=False)\n",
      "      (7): SSBH_DimChanger_for_one_two_decoupling()\n",
      "      (8): LIF_layer()\n",
      "      (9): SSBH_DimChanger_for_one_two_coupling()\n",
      "      (10): Conv1d(64, 96, kernel_size=(3,), stride=(2,), bias=False)\n",
      "      (11): SSBH_DimChanger_for_one_two_decoupling()\n",
      "      (12): LIF_layer()\n",
      "      (13): SSBH_DimChanger_for_one_two_coupling()\n",
      "      (14): SSBH_DimChanger_for_fc()\n",
      "      (15): Linear(in_features=480, out_features=4, bias=False)\n",
      "      (16): SSBH_DimChanger_for_one_two_decoupling()\n",
      "      (17): LIF_layer()\n",
      "      (18): SSBH_DimChanger_for_one_two_coupling()\n",
      "      (19): SSBH_L2NormLayer()\n",
      "      (20): SSBH_DimChanger_for_one_two_decoupling()\n",
      "      (21): SSBH_DimChanger_one_two()\n",
      "    )\n",
      "    (decoder): Sequential(\n",
      "      (0): SSBH_DimChanger_one_two()\n",
      "      (1): SSBH_DimChanger_for_one_two_coupling()\n",
      "      (2): Linear(in_features=4, out_features=480, bias=False)\n",
      "      (3): SSBH_DimChanger_for_one_two_decoupling()\n",
      "      (4): LIF_layer()\n",
      "      (5): SSBH_DimChanger_for_one_two_coupling()\n",
      "      (6): SSBH_DimChanger_for_conv1()\n",
      "      (7): SSBH_DimChanger_for_one_two_decoupling()\n",
      "      (8): SSBH_DimChanger_for_one_two_coupling()\n",
      "      (9): ConvTranspose1d(96, 64, kernel_size=(3,), stride=(2,), bias=False)\n",
      "      (10): SSBH_DimChanger_for_one_two_decoupling()\n",
      "      (11): LIF_layer()\n",
      "      (12): SSBH_DimChanger_for_one_two_coupling()\n",
      "      (13): ConvTranspose1d(64, 32, kernel_size=(3,), stride=(2,), output_padding=(1,), bias=False)\n",
      "      (14): SSBH_DimChanger_for_one_two_decoupling()\n",
      "      (15): LIF_layer()\n",
      "      (16): SSBH_DimChanger_for_one_two_coupling()\n",
      "      (17): ConvTranspose1d(32, 1, kernel_size=(3,), stride=(2,), output_padding=(1,), bias=False)\n",
      "      (18): SSBH_DimChanger_for_one_two_decoupling()\n",
      "      (19): SSBH_DimChanger_one_two()\n",
      "    )\n",
      "  )\n",
      ")\n",
      "Device: cuda\n",
      "\n",
      "Start Training, current_time = 20250123_143343_030\n",
      "\n",
      "\n",
      "epoch-0 loss : 0.07112\n",
      "ae train 실행 시간: 167.192초, 전체 시작 시간 20250123_143343_030\n",
      "\n",
      "epoch-0 accuracy check\n",
      "k_means origin feature average accuracy : 82.25492108%, total [0.9746727376209448, 0.9733106189664963, 0.9700891573195284, 0.9530800230282096, 0.943108504398827, 0.9150568181818182, 0.801817648783348, 0.6625070901871809, 0.9488619568430388, 0.822215777262181, 0.5866935483870968, 0.5005858230814294, 0.9429250891795482, 0.8922588099364529, 0.673546511627907, 0.6000572573718866]\n",
      "save model\n",
      "kmeans average accuracy best : 79.84%, kmeans average accuracy : 79.83660312%, total [0.9590210586226523, 0.9630891538898353, 0.9565717572620075, 0.9476108232584917, 0.9524926686217009, 0.9366477272727273, 0.8844913515098212, 0.6942711287577992, 0.8761454330475908, 0.6574825986078886, 0.5794930875576036, 0.4897480960749854, 0.8775267538644471, 0.7527440785673022, 0.6622093023255814, 0.5843114801030632]\n",
      "cluster_accuracy_post_training_cycle_all_dataset : [0.95960503 0.942959   0.92107707 0.87337058 0.94752475 0.80803571\n",
      " 0.78635015 0.81527531 0.88504578 0.64885496 0.57369403 0.40828402\n",
      " 0.86721992 0.70903955 0.575      0.40622141]\n",
      "mean_cluster_accuracy_during_training_cycle : 74.93%, post_traincycle_acc : 75.80%, total_acc : 75.20973601%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 0.00%\n",
      "accuracy_check 실행 시간: 34.395초\n",
      "\n",
      "\n",
      "epoch-1 loss : 0.02659\n",
      "ae train 실행 시간: 166.165초, 전체 시작 시간 20250123_143343_030\n",
      "\n",
      "epoch-1 accuracy check\n",
      "k_means origin feature average accuracy : 82.25860333%, total [0.9746727376209448, 0.9733106189664963, 0.9700891573195284, 0.9530800230282096, 0.943108504398827, 0.9150568181818182, 0.801817648783348, 0.6622234826999432, 0.9488619568430388, 0.8219257540603249, 0.5866935483870968, 0.5005858230814294, 0.9429250891795482, 0.8922588099364529, 0.6747093023255814, 0.6000572573718866]\n",
      "kmeans average accuracy best : 79.84%, kmeans average accuracy : 78.00484250%, total [0.9604439385315879, 0.9633730834752982, 0.9588725913143514, 0.9430051813471503, 0.9428152492668622, 0.8517045454545454, 0.7179712694224567, 0.6486103233125354, 0.9012710611882944, 0.656322505800464, 0.5460829493087558, 0.5055653192735794, 0.8793103448275862, 0.7541883304448296, 0.6712209302325581, 0.580017177211566]\n",
      "cluster_accuracy_post_training_cycle_all_dataset : [0.96050269 0.95098039 0.94057567 0.91527002 0.93663366 0.76071429\n",
      " 0.6834817  0.67584369 0.88809766 0.64408397 0.52238806 0.39940828\n",
      " 0.8620332  0.71374765 0.61634615 0.56084172]\n",
      "mean_cluster_accuracy_during_training_cycle : 73.98%, post_traincycle_acc : 75.19%, total_acc : 74.36609563%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 0.00%\n",
      "accuracy_check 실행 시간: 33.789초\n",
      "\n",
      "\n",
      "epoch-2 loss : 0.02663\n",
      "ae train 실행 시간: 167.033초, 전체 시작 시간 20250123_143343_030\n",
      "\n",
      "epoch-2 accuracy check\n",
      "k_means origin feature average accuracy : 82.25855480%, total [0.9746727376209448, 0.9733106189664963, 0.9700891573195284, 0.9530800230282096, 0.943108504398827, 0.9150568181818182, 0.801817648783348, 0.6625070901871809, 0.9488619568430388, 0.822215777262181, 0.5866935483870968, 0.5005858230814294, 0.9429250891795482, 0.8922588099364529, 0.6741279069767442, 0.6000572573718866]\n",
      "kmeans average accuracy best : 79.84%, kmeans average accuracy : 78.51487030%, total [0.9612976664769494, 0.9636570130607609, 0.9614610296232384, 0.9447322970639033, 0.9457478005865103, 0.8761363636363636, 0.7288185282908238, 0.6469086783891095, 0.9136860774460538, 0.6763341067285383, 0.5492511520737328, 0.5149384885764499, 0.866230677764566, 0.7533217793183131, 0.6732558139534883, 0.5866017749785285]\n",
      "cluster_accuracy_post_training_cycle_all_dataset : [0.95870736 0.95276292 0.93779016 0.91620112 0.95247525 0.74375\n",
      " 0.63996044 0.6714032  0.86876907 0.66603053 0.54757463 0.39940828\n",
      " 0.843361   0.69585687 0.61730769 0.4967978 ]\n",
      "mean_cluster_accuracy_during_training_cycle : 73.68%, post_traincycle_acc : 74.43%, total_acc : 73.92361747%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 0.00%\n",
      "accuracy_check 실행 시간: 33.646초\n",
      "\n",
      "\n",
      "epoch-3 loss : 0.02575\n",
      "ae train 실행 시간: 166.164초, 전체 시작 시간 20250123_143343_030\n",
      "\n",
      "epoch-3 accuracy check\n",
      "k_means origin feature average accuracy : 82.26764992%, total [0.9746727376209448, 0.9733106189664963, 0.9700891573195284, 0.9530800230282096, 0.943108504398827, 0.9150568181818182, 0.801817648783348, 0.6622234826999432, 0.9488619568430388, 0.822215777262181, 0.5872695852534562, 0.5005858230814294, 0.9429250891795482, 0.8922588099364529, 0.6752906976744186, 0.6000572573718866]\n",
      "kmeans average accuracy best : 79.84%, kmeans average accuracy : 78.20675465%, total [0.960728514513375, 0.9636570130607609, 0.9611734253666955, 0.945308002302821, 0.9469208211143695, 0.9076704545454546, 0.7543242450894166, 0.653998865570051, 0.8569317174105823, 0.662122969837587, 0.5581797235023042, 0.49502050380785, 0.856718192627824, 0.7440785673021375, 0.6630813953488373, 0.5831663326653307]\n",
      "cluster_accuracy_post_training_cycle_all_dataset : [0.95780969 0.95989305 0.93779016 0.91340782 0.94554455 0.75089286\n",
      " 0.61721068 0.68650089 0.86571719 0.64408397 0.58022388 0.37672584\n",
      " 0.85165975 0.68361582 0.61346154 0.52333028]\n",
      "mean_cluster_accuracy_during_training_cycle : 72.67%, post_traincycle_acc : 74.42%, total_acc : 73.21703432%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 0.00%\n",
      "accuracy_check 실행 시간: 34.481초\n",
      "\n",
      "\n",
      "epoch-4 loss : 0.02533\n",
      "ae train 실행 시간: 167.126초, 전체 시작 시간 20250123_143343_030\n",
      "\n",
      "epoch-4 accuracy check\n",
      "k_means origin feature average accuracy : 82.25498833%, total [0.9746727376209448, 0.9733106189664963, 0.9700891573195284, 0.9530800230282096, 0.943108504398827, 0.9150568181818182, 0.8015244796247435, 0.6625070901871809, 0.9488619568430388, 0.822215777262181, 0.5866935483870968, 0.5005858230814294, 0.9429250891795482, 0.8922588099364529, 0.6747093023255814, 0.5991983967935872]\n",
      "kmeans average accuracy best : 79.84%, kmeans average accuracy : 77.85055592%, total [0.9612976664769494, 0.965076660988075, 0.9626114466494105, 0.9447322970639033, 0.9475073313782991, 0.9142045454545454, 0.752858399296394, 0.6596710153148043, 0.8279633461424771, 0.6574825986078886, 0.557315668202765, 0.4853544229642648, 0.8489892984542212, 0.7409012131715771, 0.6569767441860465, 0.5731462925851704]\n",
      "cluster_accuracy_post_training_cycle_all_dataset : [0.95691203 0.95721925 0.92293408 0.89478585 0.90990099 0.7\n",
      " 0.60138477 0.68206039 0.86876907 0.64122137 0.50932836 0.35108481\n",
      " 0.79149378 0.64124294 0.61442308 0.51509607]\n",
      "mean_cluster_accuracy_during_training_cycle : 71.69%, post_traincycle_acc : 72.24%, total_acc : 71.87786771%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 0.00%\n",
      "accuracy_check 실행 시간: 34.240초\n",
      "\n",
      "\n",
      "epoch-5 loss : 0.02233\n",
      "ae train 실행 시간: 167.010초, 전체 시작 시간 20250123_143343_030\n",
      "\n",
      "epoch-5 accuracy check\n",
      "k_means origin feature average accuracy : 82.24959751%, total [0.9746727376209448, 0.9733106189664963, 0.9700891573195284, 0.9530800230282096, 0.943108504398827, 0.9150568181818182, 0.801817648783348, 0.6622234826999432, 0.9488619568430388, 0.822215777262181, 0.5866935483870968, 0.5005858230814294, 0.9429250891795482, 0.8922588099364529, 0.6738372093023256, 0.5991983967935872]\n",
      "kmeans average accuracy best : 79.84%, kmeans average accuracy : 77.65049835%, total [0.9601593625498008, 0.9639409426462238, 0.9554213402358355, 0.9427173287276914, 0.9504398826979472, 0.9176136363636364, 0.724420990911756, 0.6579693703913784, 0.8211646467632279, 0.6122389791183295, 0.5167050691244239, 0.5064440538957234, 0.8721759809750297, 0.7599653379549394, 0.672093023255814, 0.5906097910105926]\n",
      "cluster_accuracy_post_training_cycle_all_dataset : [0.96409336 0.95900178 0.91457753 0.90502793 0.93861386 0.76607143\n",
      " 0.66073195 0.42717584 0.86571719 0.63358779 0.49347015 0.38362919\n",
      " 0.83921162 0.69397363 0.60480769 0.47483989]\n",
      "mean_cluster_accuracy_during_training_cycle : 72.13%, post_traincycle_acc : 72.03%, total_acc : 72.09611306%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 0.00%\n",
      "accuracy_check 실행 시간: 31.804초\n",
      "\n",
      "\n",
      "epoch-6 loss : 0.01932\n",
      "ae train 실행 시간: 167.816초, 전체 시작 시간 20250123_143343_030\n",
      "\n",
      "epoch-6 accuracy check\n",
      "k_means origin feature average accuracy : 82.25504809%, total [0.9746727376209448, 0.9733106189664963, 0.9700891573195284, 0.9530800230282096, 0.943108504398827, 0.9150568181818182, 0.801817648783348, 0.6622234826999432, 0.9488619568430388, 0.822215777262181, 0.5866935483870968, 0.5005858230814294, 0.9429250891795482, 0.8922588099364529, 0.6747093023255814, 0.5991983967935872]\n",
      "kmeans average accuracy best : 79.84%, kmeans average accuracy : 79.09201812%, total [0.9601593625498008, 0.9630891538898353, 0.9539833189531205, 0.9418537708693149, 0.950733137829912, 0.9079545454545455, 0.7736734095573146, 0.6559841179807147, 0.8921075968075672, 0.6702436194895591, 0.5766129032258065, 0.502050380785003, 0.8891200951248514, 0.7683419988445985, 0.6625, 0.5863154881190953]\n",
      "cluster_accuracy_post_training_cycle_all_dataset : [0.96229803 0.95900178 0.91922006 0.90037244 0.96534653 0.82142857\n",
      " 0.78041543 0.70870337 0.89013225 0.65648855 0.57835821 0.40532544\n",
      " 0.8879668  0.69020716 0.60384615 0.41628545]\n",
      "mean_cluster_accuracy_during_training_cycle : 74.01%, post_traincycle_acc : 75.91%, total_acc : 74.61221900%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 0.00%\n",
      "accuracy_check 실행 시간: 34.186초\n",
      "\n",
      "\n",
      "epoch-7 loss : 0.03039\n",
      "ae train 실행 시간: 166.427초, 전체 시작 시간 20250123_143343_030\n",
      "\n",
      "epoch-7 accuracy check\n",
      "k_means origin feature average accuracy : 82.25149115%, total [0.9746727376209448, 0.9733106189664963, 0.9700891573195284, 0.9530800230282096, 0.943108504398827, 0.9150568181818182, 0.801817648783348, 0.6622234826999432, 0.9488619568430388, 0.822215777262181, 0.5872695852534562, 0.5005858230814294, 0.9429250891795482, 0.8922588099364529, 0.6747093023255814, 0.5980532493558546]\n",
      "save model\n",
      "kmeans average accuracy best : 80.49%, kmeans average accuracy : 80.48978991%, total [0.9624359704040979, 0.9588302101078933, 0.9289617486338798, 0.9021301093839954, 0.9565982404692082, 0.9369318181818181, 0.8642626795661097, 0.7158252977878616, 0.9399940880874963, 0.630800464037123, 0.5339861751152074, 0.45606326889279436, 0.9405469678953626, 0.7960716348931254, 0.7125, 0.6424277125679931]\n",
      "cluster_accuracy_post_training_cycle_all_dataset : [0.96588869 0.95276292 0.88672238 0.89664804 0.96831683 0.93392857\n",
      " 0.79327399 0.36678508 0.91251272 0.67175573 0.49533582 0.40335306\n",
      " 0.93049793 0.7306968  0.70865385 0.58279963]\n",
      "mean_cluster_accuracy_during_training_cycle : 76.29%, post_traincycle_acc : 76.25%, total_acc : 76.26824713%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 75.91%\n",
      "accuracy_check 실행 시간: 34.814초\n",
      "\n",
      "\n",
      "epoch-8 loss : 0.02938\n",
      "ae train 실행 시간: 166.949초, 전체 시작 시간 20250123_143343_030\n",
      "\n",
      "epoch-8 accuracy check\n",
      "k_means origin feature average accuracy : 82.25851350%, total [0.9746727376209448, 0.9733106189664963, 0.9700891573195284, 0.9530800230282096, 0.943108504398827, 0.915340909090909, 0.801817648783348, 0.6625070901871809, 0.9488619568430388, 0.822215777262181, 0.5866935483870968, 0.5005858230814294, 0.9429250891795482, 0.8922588099364529, 0.6738372093023256, 0.6000572573718866]\n",
      "kmeans average accuracy best : 80.49%, kmeans average accuracy : 80.05748278%, total [0.960728514513375, 0.9551391254968767, 0.9177451826287029, 0.8837075417386299, 0.9557184750733138, 0.9428977272727272, 0.8669012019935503, 0.7087351106069201, 0.9402896837126811, 0.6447215777262181, 0.5357142857142857, 0.4132981839484476, 0.937871581450654, 0.792316580011554, 0.7069767441860465, 0.6464357286000573]\n",
      "cluster_accuracy_post_training_cycle_all_dataset : [0.96499102 0.93672014 0.88486537 0.88919926 0.96732673 0.92321429\n",
      " 0.76063304 0.44671403 0.90742625 0.65458015 0.46455224 0.39546351\n",
      " 0.91908714 0.53766478 0.70576923 0.57182068]\n",
      "mean_cluster_accuracy_during_training_cycle : 75.77%, post_traincycle_acc : 74.56%, total_acc : 75.38873017%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 75.91%\n",
      "accuracy_check 실행 시간: 34.648초\n",
      "\n",
      "\n",
      "epoch-9 loss : 0.03177\n",
      "ae train 실행 시간: 165.899초, 전체 시작 시간 20250123_143343_030\n",
      "\n",
      "epoch-9 accuracy check\n",
      "k_means origin feature average accuracy : 82.25495484%, total [0.9746727376209448, 0.9733106189664963, 0.9700891573195284, 0.9530800230282096, 0.943108504398827, 0.9150568181818182, 0.8015244796247435, 0.6625070901871809, 0.9488619568430388, 0.822215777262181, 0.5872695852534562, 0.5005858230814294, 0.9429250891795482, 0.8922588099364529, 0.6741279069767442, 0.5991983967935872]\n",
      "kmeans average accuracy best : 80.49%, kmeans average accuracy : 79.17323962%, total [0.9595902105862265, 0.9605337876206701, 0.9344262295081968, 0.904720782959125, 0.9524926686217009, 0.9289772727272727, 0.8496042216358839, 0.6466250709018718, 0.9340821755838014, 0.6038283062645011, 0.5057603686635944, 0.45430579964850615, 0.9334126040428062, 0.7772963604852686, 0.7351744186046512, 0.5868880618379616]\n",
      "cluster_accuracy_post_training_cycle_all_dataset : [0.96140036 0.95098039 0.91736305 0.89199255 0.96237624 0.8625\n",
      " 0.6834817  0.46447602 0.90946083 0.6879771  0.5        0.40433925\n",
      " 0.77697095 0.7212806  0.68269231 0.5663312 ]\n",
      "mean_cluster_accuracy_during_training_cycle : 73.50%, post_traincycle_acc : 74.65%, total_acc : 73.86501740%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 75.91%\n",
      "accuracy_check 실행 시간: 34.757초\n",
      "\n",
      "\n",
      "epoch-10 loss : 0.03366\n",
      "ae train 실행 시간: 166.595초, 전체 시작 시간 20250123_143343_030\n",
      "\n",
      "epoch-10 accuracy check\n",
      "k_means origin feature average accuracy : 82.24225975%, total [0.9746727376209448, 0.9733106189664963, 0.9700891573195284, 0.9530800230282096, 0.943108504398827, 0.9150568181818182, 0.8006449721489299, 0.6625070901871809, 0.9488619568430388, 0.822215777262181, 0.5872695852534562, 0.5005858230814294, 0.9429250891795482, 0.89052570768342, 0.6747093023255814, 0.5991983967935872]\n",
      "kmeans average accuracy best : 80.49%, kmeans average accuracy : 77.70449552%, total [0.9538986909504837, 0.957694491766042, 0.9335634167385677, 0.9078871617731722, 0.9510263929618769, 0.8900568181818181, 0.693638229258282, 0.6236528644356211, 0.9263966893289979, 0.6589327146171694, 0.5178571428571429, 0.46543643819566494, 0.9066587395957194, 0.782206816868862, 0.6697674418604651, 0.5940452333237904]\n",
      "cluster_accuracy_post_training_cycle_all_dataset : [0.95421903 0.94919786 0.90436397 0.88175047 0.96534653 0.9\n",
      " 0.743818   0.64831261 0.91353001 0.87118321 0.46735075 0.42800789\n",
      " 0.88900415 0.65442561 0.5875     0.51418115]\n",
      "mean_cluster_accuracy_during_training_cycle : 75.28%, post_traincycle_acc : 76.70%, total_acc : 75.72283451%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 75.91%\n",
      "accuracy_check 실행 시간: 34.288초\n",
      "\n",
      "\n",
      "epoch-11 loss : 0.03353\n",
      "ae train 실행 시간: 167.452초, 전체 시작 시간 20250123_143343_030\n",
      "\n",
      "epoch-11 accuracy check\n",
      "k_means origin feature average accuracy : 82.26578875%, total [0.9746727376209448, 0.9733106189664963, 0.9700891573195284, 0.9530800230282096, 0.943108504398827, 0.9150568181818182, 0.801817648783348, 0.6625070901871809, 0.9488619568430388, 0.822215777262181, 0.5872695852534562, 0.5005858230814294, 0.9429250891795482, 0.8922588099364529, 0.6747093023255814, 0.6000572573718866]\n",
      "kmeans average accuracy best : 80.49%, kmeans average accuracy : 76.55572322%, total [0.9530449630051223, 0.9574105621805792, 0.9329882082254818, 0.9110535405872193, 0.9469208211143695, 0.7710227272727272, 0.7024333040164175, 0.6219512195121951, 0.9207803724504877, 0.6299303944315545, 0.5299539170506913, 0.4777387229056825, 0.896551724137931, 0.7738301559792028, 0.6604651162790698, 0.5628399656455769]\n",
      "cluster_accuracy_post_training_cycle_all_dataset : [0.94883303 0.93761141 0.89322191 0.8594041  0.95148515 0.78839286\n",
      " 0.71810089 0.65186501 0.9145473  0.85496183 0.48507463 0.43491124\n",
      " 0.89004149 0.66478343 0.55673077 0.48307411]\n",
      "mean_cluster_accuracy_during_training_cycle : 74.61%, post_traincycle_acc : 75.21%, total_acc : 74.79028722%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 75.91%\n",
      "accuracy_check 실행 시간: 34.510초\n",
      "\n",
      "\n",
      "epoch-12 loss : 0.03245\n",
      "ae train 실행 시간: 166.361초, 전체 시작 시간 20250123_143343_030\n",
      "\n",
      "epoch-12 accuracy check\n",
      "k_means origin feature average accuracy : 82.24955320%, total [0.9746727376209448, 0.9733106189664963, 0.9700891573195284, 0.9530800230282096, 0.943108504398827, 0.9150568181818182, 0.801817648783348, 0.6625070901871809, 0.9488619568430388, 0.822215777262181, 0.5866935483870968, 0.5005858230814294, 0.9429250891795482, 0.8922588099364529, 0.673546511627907, 0.5991983967935872]\n",
      "kmeans average accuracy best : 80.49%, kmeans average accuracy : 78.21171691%, total [0.9530449630051223, 0.9554230550823396, 0.9249352890422778, 0.9001151410477836, 0.9516129032258065, 0.9360795454545454, 0.8056288478452067, 0.6020986954055587, 0.91220809932013, 0.6690835266821346, 0.591589861751152, 0.429701230228471, 0.8831747919143876, 0.7683419988445985, 0.6662790697674419, 0.5645576868021758]\n",
      "cluster_accuracy_post_training_cycle_all_dataset : [0.94883303 0.95187166 0.89972145 0.87337058 0.96435644 0.89375\n",
      " 0.71513353 0.63676732 0.91149542 0.6860687  0.49906716 0.40532544\n",
      " 0.86929461 0.67608286 0.58269231 0.43732845]\n",
      "mean_cluster_accuracy_during_training_cycle : 74.33%, post_traincycle_acc : 74.69%, total_acc : 74.45213391%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 75.91%\n",
      "accuracy_check 실행 시간: 31.486초\n",
      "\n",
      "\n",
      "epoch-13 loss : 0.03098\n",
      "ae train 실행 시간: 166.749초, 전체 시작 시간 20250123_143343_030\n",
      "\n",
      "epoch-13 accuracy check\n",
      "k_means origin feature average accuracy : 82.25856323%, total [0.9746727376209448, 0.9733106189664963, 0.9700891573195284, 0.9530800230282096, 0.943108504398827, 0.9150568181818182, 0.801817648783348, 0.6625070901871809, 0.9488619568430388, 0.8216357308584686, 0.5866935483870968, 0.5005858230814294, 0.9429250891795482, 0.8922588099364529, 0.6747093023255814, 0.6000572573718866]\n",
      "kmeans average accuracy best : 80.49%, kmeans average accuracy : 76.13315277%, total [0.9519066590779738, 0.9494605337876206, 0.9197584124245038, 0.8848589522164652, 0.9527859237536657, 0.9369318181818181, 0.6470243330401642, 0.6049347702779353, 0.9107301211942064, 0.6078886310904872, 0.46889400921658986, 0.4182776801405975, 0.9126040428061831, 0.7720970537261699, 0.6665697674418605, 0.5765817348983682]\n",
      "cluster_accuracy_post_training_cycle_all_dataset : [0.9551167  0.91622103 0.89507892 0.79702048 0.94851485 0.76428571\n",
      " 0.74579624 0.43960924 0.88809766 0.66793893 0.46455224 0.39151874\n",
      " 0.88692946 0.73163842 0.57692308 0.57456542]\n",
      "mean_cluster_accuracy_during_training_cycle : 73.15%, post_traincycle_acc : 72.77%, total_acc : 73.02724777%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 75.91%\n",
      "accuracy_check 실행 시간: 34.518초\n",
      "\n",
      "\n",
      "epoch-14 loss : 0.04526\n",
      "ae train 실행 시간: 166.199초, 전체 시작 시간 20250123_143343_030\n",
      "\n",
      "epoch-14 accuracy check\n",
      "k_means origin feature average accuracy : 82.26401620%, total [0.9746727376209448, 0.9733106189664963, 0.9700891573195284, 0.9530800230282096, 0.943108504398827, 0.9150568181818182, 0.801817648783348, 0.6622234826999432, 0.9488619568430388, 0.822215777262181, 0.5872695852534562, 0.5005858230814294, 0.9429250891795482, 0.8922588099364529, 0.6747093023255814, 0.6000572573718866]\n",
      "save model\n",
      "kmeans average accuracy best : 80.77%, kmeans average accuracy : 80.76709041%, total [0.9669891861126921, 0.966496308915389, 0.9571469657750935, 0.931203223949338, 0.9536656891495601, 0.9213068181818181, 0.8255643506303136, 0.7214974475326149, 0.9293526455808454, 0.8416473317865429, 0.613479262672811, 0.5166959578207382, 0.7922116527942925, 0.7605430387059503, 0.6546511627906977, 0.5702834239908389]\n",
      "cluster_accuracy_post_training_cycle_all_dataset : [0.96588869 0.94474153 0.93779016 0.90595903 0.96534653 0.89821429\n",
      " 0.8140455  0.75932504 0.90640895 0.79580153 0.61100746 0.56410256\n",
      " 0.7873444  0.76741996 0.66057692 0.52516011]\n",
      "mean_cluster_accuracy_during_training_cycle : 79.29%, post_traincycle_acc : 80.06%, total_acc : 79.52675716%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 72.77%\n",
      "accuracy_check 실행 시간: 34.110초\n",
      "\n",
      "\n",
      "epoch-15 loss : 0.04261\n",
      "ae train 실행 시간: 166.070초, 전체 시작 시간 20250123_143343_030\n",
      "\n",
      "epoch-15 accuracy check\n",
      "k_means origin feature average accuracy : 82.24594995%, total [0.9746727376209448, 0.9733106189664963, 0.9700891573195284, 0.9530800230282096, 0.943108504398827, 0.9150568181818182, 0.801817648783348, 0.6622234826999432, 0.9488619568430388, 0.822215777262181, 0.5866935483870968, 0.5002929115407148, 0.9429250891795482, 0.8922588099364529, 0.673546511627907, 0.5991983967935872]\n",
      "save model\n",
      "kmeans average accuracy best : 81.72%, kmeans average accuracy : 81.72422570%, total [0.9595902105862265, 0.9628052243043725, 0.9539833189531205, 0.939838802533103, 0.952199413489736, 0.9244318181818182, 0.850776898270302, 0.7300056721497448, 0.9423588530889743, 0.8288863109048724, 0.6152073732718893, 0.520796719390744, 0.9236028537455411, 0.7590987868284229, 0.6517441860465116, 0.5605496707701116]\n",
      "cluster_accuracy_post_training_cycle_all_dataset : [0.96768402 0.96434938 0.94800371 0.87895717 0.96534653 0.91428571\n",
      " 0.81008902 0.75577265 0.92777213 0.82824427 0.62126866 0.43096647\n",
      " 0.92634855 0.41713748 0.66730769 0.39066789]\n",
      "mean_cluster_accuracy_during_training_cycle : 75.51%, post_traincycle_acc : 77.59%, total_acc : 76.16272225%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 80.06%\n",
      "accuracy_check 실행 시간: 34.254초\n",
      "\n",
      "\n",
      "epoch-16 loss : 0.03890\n",
      "ae train 실행 시간: 165.494초, 전체 시작 시간 20250123_143343_030\n",
      "\n",
      "epoch-16 accuracy check\n",
      "k_means origin feature average accuracy : 82.26218852%, total [0.9746727376209448, 0.9733106189664963, 0.9700891573195284, 0.9530800230282096, 0.943108504398827, 0.9150568181818182, 0.801817648783348, 0.6625070901871809, 0.9488619568430388, 0.822215777262181, 0.5866935483870968, 0.5005858230814294, 0.9429250891795482, 0.8922588099364529, 0.6747093023255814, 0.6000572573718866]\n",
      "kmeans average accuracy best : 81.72%, kmeans average accuracy : 80.79702448%, total [0.9604439385315879, 0.9616695059625213, 0.9542709232096636, 0.9401266551525619, 0.9489736070381232, 0.9096590909090909, 0.8284960422163589, 0.6522972206466251, 0.9435412355897133, 0.8042343387470998, 0.6048387096774194, 0.5102519039250146, 0.9360879904875149, 0.7663200462160601, 0.6537790697674418, 0.5525336387059834]\n",
      "cluster_accuracy_post_training_cycle_all_dataset : [0.96858169 0.96434938 0.93314763 0.88733706 0.95940594 0.91517857\n",
      " 0.80316518 0.65097691 0.92370295 0.8139313  0.61753731 0.42011834\n",
      " 0.94190871 0.42090395 0.64903846 0.38975297]\n",
      "mean_cluster_accuracy_during_training_cycle : 75.73%, post_traincycle_acc : 76.62%, total_acc : 76.00729412%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 80.06%\n",
      "accuracy_check 실행 시간: 33.366초\n",
      "\n",
      "\n",
      "epoch-17 loss : 0.03819\n",
      "ae train 실행 시간: 166.810초, 전체 시작 시간 20250123_143343_030\n",
      "\n",
      "epoch-17 accuracy check\n",
      "k_means origin feature average accuracy : 82.26582224%, total [0.9746727376209448, 0.9733106189664963, 0.9700891573195284, 0.9530800230282096, 0.943108504398827, 0.9150568181818182, 0.801817648783348, 0.6625070901871809, 0.9488619568430388, 0.822215777262181, 0.5866935483870968, 0.5005858230814294, 0.9429250891795482, 0.8922588099364529, 0.6752906976744186, 0.6000572573718866]\n",
      "save model\n",
      "kmeans average accuracy best : 81.78%, kmeans average accuracy : 81.77665780%, total [0.9621513944223108, 0.9630891538898353, 0.9545585274662065, 0.9349453080023028, 0.9492668621700879, 0.9164772727272728, 0.8408091468777484, 0.6534316505955757, 0.9476795743422998, 0.8329466357308585, 0.6172235023041475, 0.5814294083186877, 0.9322235434007135, 0.7787406123627961, 0.6601744186046512, 0.5591182364729459]\n",
      "cluster_accuracy_post_training_cycle_all_dataset : [0.96319569 0.96345811 0.94243268 0.90037244 0.96237624 0.91428571\n",
      " 0.76261128 0.72912966 0.92472024 0.85114504 0.63432836 0.41518738\n",
      " 0.88278008 0.42937853 0.61442308 0.50411711]\n",
      "mean_cluster_accuracy_during_training_cycle : 76.19%, post_traincycle_acc : 77.46%, total_acc : 76.58564875%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 76.62%\n",
      "accuracy_check 실행 시간: 34.139초\n",
      "\n",
      "\n",
      "epoch-18 loss : 0.03806\n",
      "ae train 실행 시간: 166.636초, 전체 시작 시간 20250123_143343_030\n",
      "\n",
      "epoch-18 accuracy check\n",
      "k_means origin feature average accuracy : 82.25315343%, total [0.9746727376209448, 0.9733106189664963, 0.9700891573195284, 0.9530800230282096, 0.943108504398827, 0.9150568181818182, 0.801817648783348, 0.6625070901871809, 0.9488619568430388, 0.822215777262181, 0.5872695852534562, 0.5005858230814294, 0.9429250891795482, 0.8922588099364529, 0.673546511627907, 0.5991983967935872]\n",
      "kmeans average accuracy best : 81.78%, kmeans average accuracy : 81.47474387%, total [0.9593056346044394, 0.9628052243043725, 0.9542709232096636, 0.9412780656303973, 0.9519061583577713, 0.925, 0.8481383758428613, 0.7288712422007941, 0.9447236180904522, 0.7703016241299304, 0.628168202764977, 0.5284124194493263, 0.9158739595719382, 0.7651646447140381, 0.6529069767441861, 0.5588319496135128]\n",
      "cluster_accuracy_post_training_cycle_all_dataset : [0.96140036 0.96345811 0.9275766  0.89013035 0.96435644 0.92232143\n",
      " 0.77645895 0.72557726 0.93082401 0.73568702 0.63619403 0.36489152\n",
      " 0.87759336 0.43879473 0.61442308 0.49313815]\n",
      "mean_cluster_accuracy_during_training_cycle : 75.22%, post_traincycle_acc : 76.39%, total_acc : 75.59274393%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 76.62%\n",
      "accuracy_check 실행 시간: 34.397초\n",
      "\n",
      "\n",
      "epoch-19 loss : 0.03800\n",
      "ae train 실행 시간: 167.246초, 전체 시작 시간 20250123_143343_030\n",
      "\n",
      "epoch-19 accuracy check\n",
      "k_means origin feature average accuracy : 82.26034409%, total [0.9746727376209448, 0.9733106189664963, 0.9700891573195284, 0.9530800230282096, 0.943108504398827, 0.9150568181818182, 0.801817648783348, 0.6625070901871809, 0.9488619568430388, 0.822215777262181, 0.5866935483870968, 0.5005858230814294, 0.9429250891795482, 0.8922588099364529, 0.6741279069767442, 0.6003435442313197]\n",
      "kmeans average accuracy best : 81.78%, kmeans average accuracy : 81.45889358%, total [0.9612976664769494, 0.9622373651334469, 0.9519700891573195, 0.9286125503742084, 0.950733137829912, 0.9224431818181819, 0.8472588683670478, 0.6508791832104368, 0.9459060005911912, 0.8694895591647331, 0.6152073732718893, 0.5222612770943175, 0.9239001189060642, 0.7634315424610052, 0.6558139534883721, 0.5619811050672774]\n",
      "cluster_accuracy_post_training_cycle_all_dataset : [0.96140036 0.96256684 0.9275766  0.90782123 0.96534653 0.91339286\n",
      " 0.82987141 0.64209591 0.92777213 0.73759542 0.62406716 0.35996055\n",
      " 0.82987552 0.44915254 0.62692308 0.53247941]\n",
      "mean_cluster_accuracy_during_training_cycle : 75.03%, post_traincycle_acc : 76.24%, total_acc : 75.41603898%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 76.62%\n",
      "accuracy_check 실행 시간: 31.426초\n",
      "\n",
      "\n",
      "epoch-20 loss : 0.03797\n",
      "ae train 실행 시간: 165.853초, 전체 시작 시간 20250123_143343_030\n",
      "\n",
      "epoch-20 accuracy check\n",
      "k_means origin feature average accuracy : 82.24958206%, total [0.9746727376209448, 0.9733106189664963, 0.9700891573195284, 0.9530800230282096, 0.943108504398827, 0.9150568181818182, 0.8015244796247435, 0.6622234826999432, 0.9488619568430388, 0.822215777262181, 0.5866935483870968, 0.5005858230814294, 0.9429250891795482, 0.8922588099364529, 0.6741279069767442, 0.5991983967935872]\n",
      "kmeans average accuracy best : 81.78%, kmeans average accuracy : 81.74502356%, total [0.9615822424587365, 0.9628052243043725, 0.9551337359792925, 0.9409902130109384, 0.9501466275659824, 0.9136363636363637, 0.8396364702433304, 0.6559841179807147, 0.9429500443393438, 0.8439675174013921, 0.6195276497695853, 0.5172817809021676, 0.9444114149821641, 0.8001155401502021, 0.6604651162790698, 0.570569710850272]\n",
      "cluster_accuracy_post_training_cycle_all_dataset : [0.96768402 0.96524064 0.94057567 0.89851024 0.96435644 0.90892857\n",
      " 0.8239367  0.73978686 0.9318413  0.80725191 0.62406716 0.39349112\n",
      " 0.93879668 0.44444444 0.65384615 0.54345837]\n",
      "mean_cluster_accuracy_during_training_cycle : 76.88%, post_traincycle_acc : 78.41%, total_acc : 77.35962442%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 76.62%\n",
      "accuracy_check 실행 시간: 34.042초\n",
      "\n",
      "\n",
      "epoch-21 loss : 0.03790\n",
      "ae train 실행 시간: 166.220초, 전체 시작 시간 20250123_143343_030\n",
      "\n",
      "epoch-21 accuracy check\n",
      "k_means origin feature average accuracy : 82.25141437%, total [0.9746727376209448, 0.9733106189664963, 0.9700891573195284, 0.9530800230282096, 0.943108504398827, 0.9150568181818182, 0.801817648783348, 0.6622234826999432, 0.9488619568430388, 0.822215777262181, 0.5866935483870968, 0.5005858230814294, 0.9429250891795482, 0.8922588099364529, 0.6741279069767442, 0.5991983967935872]\n",
      "kmeans average accuracy best : 81.78%, kmeans average accuracy : 81.25762525%, total [0.9630051223676722, 0.9639409426462238, 0.9513948806442335, 0.939838802533103, 0.9486803519061584, 0.9105113636363636, 0.8270301964233363, 0.6474758933635848, 0.9432456399645285, 0.8309164733178654, 0.619815668202765, 0.5164030462800234, 0.9271700356718192, 0.7885615251299827, 0.6555232558139535, 0.5677068422559405]\n",
      "cluster_accuracy_post_training_cycle_all_dataset : [0.96319569 0.96524064 0.92293408 0.88268156 0.96336634 0.89910714\n",
      " 0.75469832 0.65186501 0.8982706  0.84828244 0.45615672 0.39349112\n",
      " 0.71991701 0.40301318 0.61057692 0.39249771]\n",
      "mean_cluster_accuracy_during_training_cycle : 73.25%, post_traincycle_acc : 73.28%, total_acc : 73.24912539%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 76.62%\n",
      "accuracy_check 실행 시간: 34.135초\n",
      "\n",
      "\n",
      "epoch-22 loss : 0.03827\n",
      "ae train 실행 시간: 166.987초, 전체 시작 시간 20250123_143343_030\n",
      "\n",
      "epoch-22 accuracy check\n",
      "k_means origin feature average accuracy : 82.24602975%, total [0.9746727376209448, 0.9733106189664963, 0.9700891573195284, 0.9530800230282096, 0.943108504398827, 0.9150568181818182, 0.801817648783348, 0.6625070901871809, 0.9488619568430388, 0.822215777262181, 0.5866935483870968, 0.5005858230814294, 0.9429250891795482, 0.8922588099364529, 0.6741279069767442, 0.5980532493558546]\n",
      "kmeans average accuracy best : 81.78%, kmeans average accuracy : 81.38719446%, total [0.9632896983494593, 0.9630891538898353, 0.9542709232096636, 0.9383995394358089, 0.9492668621700879, 0.9178977272727272, 0.8270301964233363, 0.6497447532614861, 0.943836831214898, 0.8538283062645011, 0.6336405529953917, 0.5234329232571764, 0.9042806183115338, 0.7720970537261699, 0.6578488372093023, 0.5699971371314057]\n",
      "cluster_accuracy_post_training_cycle_all_dataset : [0.96140036 0.96434938 0.92386258 0.89851024 0.96336634 0.91785714\n",
      " 0.78635015 0.65364121 0.91251272 0.88167939 0.62313433 0.39151874\n",
      " 0.81016598 0.40583804 0.61153846 0.54620311]\n",
      "mean_cluster_accuracy_during_training_cycle : 74.63%, post_traincycle_acc : 76.57%, total_acc : 75.23158148%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 76.62%\n",
      "accuracy_check 실행 시간: 33.828초\n",
      "\n",
      "\n",
      "epoch-23 loss : 0.03837\n",
      "ae train 실행 시간: 166.280초, 전체 시작 시간 20250123_143343_030\n",
      "\n",
      "epoch-23 accuracy check\n",
      "k_means origin feature average accuracy : 82.25134249%, total [0.9746727376209448, 0.9733106189664963, 0.9700891573195284, 0.9530800230282096, 0.943108504398827, 0.9150568181818182, 0.801817648783348, 0.6625070901871809, 0.9488619568430388, 0.822215777262181, 0.5866935483870968, 0.5005858230814294, 0.9429250891795482, 0.8922588099364529, 0.673546511627907, 0.5994846836530203]\n",
      "kmeans average accuracy best : 81.78%, kmeans average accuracy : 81.20794193%, total [0.962720546385885, 0.9633730834752982, 0.9551337359792925, 0.9392630972941853, 0.9486803519061584, 0.9159090909090909, 0.8270301964233363, 0.6497447532614861, 0.943836831214898, 0.824245939675174, 0.6353686635944701, 0.5246045694200352, 0.9129013079667063, 0.7689196995956095, 0.6572674418604652, 0.5642713999427427]\n",
      "cluster_accuracy_post_training_cycle_all_dataset : [0.96140036 0.96256684 0.92014856 0.89199255 0.96336634 0.90892857\n",
      " 0.7537092  0.65008881 0.90132248 0.86164122 0.63619403 0.40236686\n",
      " 0.80082988 0.44350282 0.58653846 0.53064959]\n",
      "mean_cluster_accuracy_during_training_cycle : 74.45%, post_traincycle_acc : 76.10%, total_acc : 74.96470034%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 76.62%\n",
      "accuracy_check 실행 시간: 33.262초\n",
      "\n",
      "\n",
      "epoch-24 loss : 0.03804\n",
      "ae train 실행 시간: 166.826초, 전체 시작 시간 20250123_143343_030\n",
      "\n",
      "epoch-24 accuracy check\n",
      "k_means origin feature average accuracy : 82.25853805%, total [0.9746727376209448, 0.9733106189664963, 0.9700891573195284, 0.9530800230282096, 0.943108504398827, 0.9150568181818182, 0.801817648783348, 0.6622234826999432, 0.9488619568430388, 0.822215777262181, 0.5872695852534562, 0.5005858230814294, 0.9429250891795482, 0.8922588099364529, 0.673546511627907, 0.6003435442313197]\n",
      "kmeans average accuracy best : 81.78%, kmeans average accuracy : 81.32067241%, total [0.9630051223676722, 0.9625212947189097, 0.9539833189531205, 0.9372481289579735, 0.9498533724340176, 0.9147727272727273, 0.8279097038991499, 0.6426545660805445, 0.9414720662134201, 0.8375870069605569, 0.6345046082949308, 0.5202108963093146, 0.914090368608799, 0.7744078567302137, 0.6630813953488373, 0.5740051531634698]\n",
      "cluster_accuracy_post_training_cycle_all_dataset : [0.96050269 0.96434938 0.92386258 0.90409683 0.96237624 0.9125\n",
      " 0.78536103 0.30106572 0.91963377 0.85782443 0.63246269 0.41715976\n",
      " 0.83921162 0.45009416 0.6        0.51875572]\n",
      "mean_cluster_accuracy_during_training_cycle : 74.67%, post_traincycle_acc : 74.68%, total_acc : 74.65571538%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 76.62%\n",
      "accuracy_check 실행 시간: 34.789초\n",
      "\n",
      "\n",
      "epoch-25 loss : 0.03802\n",
      "ae train 실행 시간: 166.389초, 전체 시작 시간 20250123_143343_030\n",
      "\n",
      "epoch-25 accuracy check\n",
      "k_means origin feature average accuracy : 82.25313308%, total [0.9746727376209448, 0.9733106189664963, 0.9700891573195284, 0.9530800230282096, 0.943108504398827, 0.9150568181818182, 0.8015244796247435, 0.6622234826999432, 0.9488619568430388, 0.822215777262181, 0.5866935483870968, 0.5005858230814294, 0.9429250891795482, 0.8922588099364529, 0.6738372093023256, 0.6000572573718866]\n",
      "kmeans average accuracy best : 81.78%, kmeans average accuracy : 81.22745895%, total [0.9630051223676722, 0.9630891538898353, 0.9528329019269485, 0.932930339666091, 0.9492668621700879, 0.9210227272727273, 0.8279097038991499, 0.6457742484401588, 0.9373337274608335, 0.8283062645011601, 0.6414170506912442, 0.5240187463386058, 0.9054696789536266, 0.7700751010976314, 0.6633720930232558, 0.570569710850272]\n",
      "cluster_accuracy_post_training_cycle_all_dataset : [0.96140036 0.96256684 0.92014856 0.89385475 0.96237624 0.91696429\n",
      " 0.77744807 0.30284192 0.90640895 0.8769084  0.62406716 0.40631164\n",
      " 0.83506224 0.48022599 0.60288462 0.52516011]\n",
      "mean_cluster_accuracy_during_training_cycle : 74.82%, post_traincycle_acc : 74.72%, total_acc : 74.77193537%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 76.62%\n",
      "accuracy_check 실행 시간: 33.721초\n",
      "\n",
      "\n",
      "epoch-26 loss : 0.03900\n",
      "ae train 실행 시간: 165.807초, 전체 시작 시간 20250123_143343_030\n",
      "\n",
      "epoch-26 accuracy check\n",
      "k_means origin feature average accuracy : 82.25678225%, total [0.9746727376209448, 0.9733106189664963, 0.9700891573195284, 0.9530800230282096, 0.943108504398827, 0.9150568181818182, 0.801817648783348, 0.6622234826999432, 0.9488619568430388, 0.822215777262181, 0.5866935483870968, 0.5005858230814294, 0.9429250891795482, 0.8922588099364529, 0.6741279069767442, 0.6000572573718866]\n",
      "kmeans average accuracy best : 81.78%, kmeans average accuracy : 81.00690871%, total [0.9644280022766079, 0.9630891538898353, 0.9516824849007766, 0.9300518134715026, 0.9489736070381232, 0.912784090909091, 0.8182351216652008, 0.6418037436188315, 0.9394028968371269, 0.830046403712297, 0.6336405529953917, 0.5222612770943175, 0.9019024970273484, 0.770363951473137, 0.6587209302325582, 0.5737188663040367]\n",
      "cluster_accuracy_post_training_cycle_all_dataset : [0.96499102 0.96167558 0.91457753 0.89292365 0.96237624 0.9125\n",
      " 0.77546983 0.64653641 0.91353001 0.86354962 0.62593284 0.37968442\n",
      " 0.81327801 0.43314501 0.60769231 0.52790485]\n",
      "mean_cluster_accuracy_during_training_cycle : 73.48%, post_traincycle_acc : 76.22%, total_acc : 74.33614387%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 76.62%\n",
      "accuracy_check 실행 시간: 33.360초\n",
      "\n",
      "\n",
      "epoch-27 loss : 0.03940\n",
      "ae train 실행 시간: 166.462초, 전체 시작 시간 20250123_143343_030\n",
      "\n",
      "epoch-27 accuracy check\n",
      "k_means origin feature average accuracy : 82.24964802%, total [0.9746727376209448, 0.9733106189664963, 0.9700891573195284, 0.9530800230282096, 0.943108504398827, 0.9150568181818182, 0.8015244796247435, 0.6625070901871809, 0.9488619568430388, 0.822215777262181, 0.5866935483870968, 0.5005858230814294, 0.9429250891795482, 0.8922588099364529, 0.675, 0.5980532493558546]\n",
      "kmeans average accuracy best : 81.78%, kmeans average accuracy : 80.89230559%, total [0.9649971542401822, 0.9619534355479841, 0.9508196721311475, 0.9335060449050087, 0.9483870967741935, 0.9147727272727273, 0.8264438581061272, 0.6511627906976745, 0.9388117055867573, 0.8198955916473318, 0.6304723502304147, 0.5161101347393088, 0.8923900118906064, 0.7637203928365107, 0.661046511627907, 0.5682794159748068]\n",
      "cluster_accuracy_post_training_cycle_all_dataset : [0.96588869 0.96256684 0.92293408 0.90782123 0.96336634 0.91160714\n",
      " 0.78041543 0.70959147 0.90437436 0.87118321 0.62686567 0.41814596\n",
      " 0.82883817 0.44067797 0.62019231 0.51143641]\n",
      "mean_cluster_accuracy_during_training_cycle : 75.38%, post_traincycle_acc : 77.16%, total_acc : 75.93259487%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 76.62%\n",
      "accuracy_check 실행 시간: 33.589초\n",
      "\n",
      "\n",
      "epoch-28 loss : 0.03829\n",
      "ae train 실행 시간: 167.416초, 전체 시작 시간 20250123_143343_030\n",
      "\n",
      "epoch-28 accuracy check\n",
      "k_means origin feature average accuracy : 82.24959580%, total [0.9746727376209448, 0.9733106189664963, 0.9700891573195284, 0.9530800230282096, 0.943108504398827, 0.9150568181818182, 0.8015244796247435, 0.6622234826999432, 0.9488619568430388, 0.822215777262181, 0.5866935483870968, 0.5002929115407148, 0.9429250891795482, 0.8922588099364529, 0.6747093023255814, 0.598912109934154]\n",
      "kmeans average accuracy best : 81.78%, kmeans average accuracy : 80.14117377%, total [0.9612976664769494, 0.9642248722316865, 0.9531205061834915, 0.934657455382844, 0.9475073313782991, 0.9184659090909091, 0.8261506889475227, 0.6358479863868406, 0.9385161099615725, 0.7386890951276102, 0.6350806451612904, 0.5313415348564734, 0.8686087990487514, 0.7475447718082033, 0.6569767441860465, 0.5645576868021758]\n",
      "cluster_accuracy_post_training_cycle_all_dataset : [0.96050269 0.95811052 0.92479109 0.87709497 0.96534653 0.72678571\n",
      " 0.77151335 0.61634103 0.90437436 0.78625954 0.50559701 0.382643\n",
      " 0.83609959 0.65254237 0.58269231 0.48398902]\n",
      "mean_cluster_accuracy_during_training_cycle : 73.99%, post_traincycle_acc : 74.59%, total_acc : 74.17549183%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 76.62%\n",
      "accuracy_check 실행 시간: 34.060초\n",
      "\n",
      "\n",
      "epoch-29 loss : 0.03723\n",
      "ae train 실행 시간: 166.537초, 전체 시작 시간 20250123_143343_030\n",
      "\n",
      "epoch-29 accuracy check\n",
      "k_means origin feature average accuracy : 82.25859319%, total [0.9746727376209448, 0.9733106189664963, 0.9700891573195284, 0.9530800230282096, 0.943108504398827, 0.9150568181818182, 0.801817648783348, 0.6622234826999432, 0.9488619568430388, 0.822215777262181, 0.5872695852534562, 0.5005858230814294, 0.9429250891795482, 0.8922588099364529, 0.6741279069767442, 0.5997709705124534]\n",
      "kmeans average accuracy best : 81.78%, kmeans average accuracy : 79.09407828%, total [0.9610130904951623, 0.9622373651334469, 0.9508196721311475, 0.9360967184801382, 0.9469208211143695, 0.9028409090909091, 0.7217824684843155, 0.632161089052751, 0.9394028968371269, 0.7250580046403712, 0.6347926267281107, 0.5216754540128881, 0.8724732461355529, 0.7484113229347198, 0.6488372093023256, 0.5505296306899513]\n",
      "cluster_accuracy_post_training_cycle_all_dataset : [0.95780969 0.96078431 0.92014856 0.90037244 0.95148515 0.91964286\n",
      " 0.76557864 0.62255773 0.85656155 0.6278626  0.51026119 0.38560158\n",
      " 0.87136929 0.65536723 0.59038462 0.4547118 ]\n",
      "mean_cluster_accuracy_during_training_cycle : 73.63%, post_traincycle_acc : 74.69%, total_acc : 73.95966395%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 76.62%\n",
      "accuracy_check 실행 시간: 34.245초\n",
      "\n",
      "\n",
      "epoch-30 loss : 0.03753\n",
      "ae train 실행 시간: 167.286초, 전체 시작 시간 20250123_143343_030\n",
      "\n",
      "epoch-30 accuracy check\n",
      "k_means origin feature average accuracy : 82.26218389%, total [0.9746727376209448, 0.9733106189664963, 0.9700891573195284, 0.9530800230282096, 0.943108504398827, 0.9150568181818182, 0.8015244796247435, 0.6622234826999432, 0.9488619568430388, 0.822215777262181, 0.5872695852534562, 0.5005858230814294, 0.9429250891795482, 0.8922588099364529, 0.6747093023255814, 0.6000572573718866]\n",
      "kmeans average accuracy best : 81.78%, kmeans average accuracy : 79.48573662%, total [0.9624359704040979, 0.9639409426462238, 0.9513948806442335, 0.9286125503742084, 0.9504398826979472, 0.9252840909090909, 0.8161829375549692, 0.6440726035167328, 0.9352645580845403, 0.673723897911833, 0.6088709677419355, 0.5117164616285882, 0.8715814506539834, 0.7489890236857308, 0.6537790697674418, 0.5714285714285714]\n",
      "cluster_accuracy_post_training_cycle_all_dataset : [0.95870736 0.96078431 0.9090065  0.89385475 0.93168317 0.91071429\n",
      " 0.72997033 0.6722913  0.68056968 0.61164122 0.50186567 0.33234714\n",
      " 0.79979253 0.62806026 0.58942308 0.53705398]\n",
      "mean_cluster_accuracy_during_training_cycle : 71.41%, post_traincycle_acc : 72.80%, total_acc : 71.85884789%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 76.62%\n",
      "accuracy_check 실행 시간: 33.632초\n",
      "\n",
      "\n",
      "epoch-31 loss : 0.03663\n",
      "ae train 실행 시간: 166.801초, 전체 시작 시간 20250123_143343_030\n",
      "\n",
      "epoch-31 accuracy check\n",
      "k_means origin feature average accuracy : 82.26219154%, total [0.9746727376209448, 0.9733106189664963, 0.9700891573195284, 0.9530800230282096, 0.943108504398827, 0.915340909090909, 0.801817648783348, 0.6622234826999432, 0.9488619568430388, 0.822215777262181, 0.5866935483870968, 0.5005858230814294, 0.9429250891795482, 0.8922588099364529, 0.6747093023255814, 0.6000572573718866]\n",
      "kmeans average accuracy best : 81.78%, kmeans average accuracy : 79.91821750%, total [0.9638588503130335, 0.9633730834752982, 0.9522576934138626, 0.9358088658606794, 0.9483870967741935, 0.9071022727272727, 0.7455291703312812, 0.6491775382870107, 0.9467927874667454, 0.7613109048723898, 0.6275921658986175, 0.5199179847685999, 0.8840665873959572, 0.7582322357019065, 0.6549418604651163, 0.5685657028342399]\n",
      "cluster_accuracy_post_training_cycle_all_dataset : [0.96050269 0.96345811 0.92479109 0.90223464 0.96435644 0.92142857\n",
      " 0.77052423 0.62699822 0.90844354 0.84160305 0.50746269 0.33727811\n",
      " 0.70435685 0.63559322 0.60384615 0.46752059]\n",
      "mean_cluster_accuracy_during_training_cycle : 73.79%, post_traincycle_acc : 75.25%, total_acc : 74.24275406%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 76.62%\n",
      "accuracy_check 실행 시간: 34.023초\n",
      "\n",
      "\n",
      "epoch-32 loss : 0.03757\n",
      "ae train 실행 시간: 165.946초, 전체 시작 시간 20250123_143343_030\n",
      "\n",
      "epoch-32 accuracy check\n",
      "k_means origin feature average accuracy : 82.25857997%, total [0.9746727376209448, 0.9733106189664963, 0.9700891573195284, 0.9530800230282096, 0.943108504398827, 0.9150568181818182, 0.801817648783348, 0.6622234826999432, 0.9488619568430388, 0.8216357308584686, 0.5866935483870968, 0.5005858230814294, 0.9429250891795482, 0.8922588099364529, 0.6747093023255814, 0.6003435442313197]\n",
      "kmeans average accuracy best : 81.78%, kmeans average accuracy : 80.06657746%, total [0.960728514513375, 0.9633730834752982, 0.9525452976704055, 0.9366724237190558, 0.944574780058651, 0.8596590909090909, 0.7381999413661683, 0.6420873511060692, 0.9388117055867573, 0.8187354988399071, 0.618663594470046, 0.513766842413591, 0.9191438763376932, 0.7749855574812248, 0.6578488372093023, 0.5708559977097051]\n",
      "cluster_accuracy_post_training_cycle_all_dataset : [0.95960503 0.96702317 0.92571959 0.90316574 0.96336634 0.90089286\n",
      " 0.70128586 0.64387211 0.8982706  0.84923664 0.50652985 0.38658777\n",
      " 0.66493776 0.62241055 0.60480769 0.5105215 ]\n",
      "mean_cluster_accuracy_during_training_cycle : 73.46%, post_traincycle_acc : 75.05%, total_acc : 73.96210731%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 76.62%\n",
      "accuracy_check 실행 시간: 34.350초\n",
      "\n",
      "\n",
      "epoch-33 loss : 0.03585\n",
      "ae train 실행 시간: 166.847초, 전체 시작 시간 20250123_143343_030\n",
      "\n",
      "epoch-33 accuracy check\n",
      "k_means origin feature average accuracy : 82.24778065%, total [0.9746727376209448, 0.9733106189664963, 0.9700891573195284, 0.9530800230282096, 0.943108504398827, 0.9150568181818182, 0.801817648783348, 0.6622234826999432, 0.9488619568430388, 0.822215777262181, 0.5866935483870968, 0.5005858230814294, 0.9429250891795482, 0.8922588099364529, 0.673546511627907, 0.5991983967935872]\n",
      "kmeans average accuracy best : 81.78%, kmeans average accuracy : 79.41164840%, total [0.9618668184405236, 0.9639409426462238, 0.9539833189531205, 0.9366724237190558, 0.9480938416422288, 0.8923295454545455, 0.7402521254763998, 0.6392512762336926, 0.9355601537097251, 0.7415893271461717, 0.6226958525345622, 0.5166959578207382, 0.8873365041617123, 0.7461005199306759, 0.6546511627906977, 0.5648439736616089]\n",
      "cluster_accuracy_post_training_cycle_all_dataset : [0.96140036 0.96256684 0.89879294 0.90689013 0.95841584 0.91428571\n",
      " 0.77546983 0.64653641 0.79450661 0.6221374  0.51679104 0.36587771\n",
      " 0.73651452 0.65913371 0.58846154 0.48032937]\n",
      "mean_cluster_accuracy_during_training_cycle : 73.79%, post_traincycle_acc : 73.68%, total_acc : 73.77259207%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 76.62%\n",
      "accuracy_check 실행 시간: 33.833초\n",
      "\n",
      "\n",
      "epoch-34 loss : 0.03578\n",
      "ae train 실행 시간: 165.394초, 전체 시작 시간 20250123_143343_030\n",
      "\n",
      "epoch-34 accuracy check\n",
      "k_means origin feature average accuracy : 82.24599626%, total [0.9746727376209448, 0.9733106189664963, 0.9700891573195284, 0.9530800230282096, 0.943108504398827, 0.9150568181818182, 0.801817648783348, 0.6625070901871809, 0.9488619568430388, 0.822215777262181, 0.5872695852534562, 0.5005858230814294, 0.9429250891795482, 0.8922588099364529, 0.673546511627907, 0.5980532493558546]\n",
      "kmeans average accuracy best : 81.78%, kmeans average accuracy : 78.97635598%, total [0.9612976664769494, 0.9630891538898353, 0.9516824849007766, 0.9355210132412205, 0.9469208211143695, 0.8730113636363637, 0.7370272647317502, 0.6418037436188315, 0.9405852793378658, 0.7201276102088167, 0.5953341013824884, 0.515817223198594, 0.8858501783590963, 0.7469670710571924, 0.6526162790697675, 0.5685657028342399]\n",
      "cluster_accuracy_post_training_cycle_all_dataset : [0.95601436 0.96524064 0.9275766  0.91247672 0.95841584 0.86428571\n",
      " 0.68051434 0.64209591 0.90233978 0.79580153 0.50932836 0.37376726\n",
      " 0.72821577 0.67419962 0.6125     0.50594694]\n",
      "mean_cluster_accuracy_during_training_cycle : 73.42%, post_traincycle_acc : 75.05%, total_acc : 73.92701628%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 76.62%\n",
      "accuracy_check 실행 시간: 33.960초\n",
      "\n",
      "\n",
      "epoch-35 loss : 0.03198\n",
      "ae train 실행 시간: 166.426초, 전체 시작 시간 20250123_143343_030\n",
      "\n",
      "epoch-35 accuracy check\n",
      "k_means origin feature average accuracy : 82.24237097%, total [0.9746727376209448, 0.9733106189664963, 0.9700891573195284, 0.9530800230282096, 0.943108504398827, 0.9150568181818182, 0.801817648783348, 0.6625070901871809, 0.9488619568430388, 0.8216357308584686, 0.5872695852534562, 0.5005858230814294, 0.9429250891795482, 0.8922588099364529, 0.673546511627907, 0.5980532493558546]\n",
      "kmeans average accuracy best : 81.78%, kmeans average accuracy : 77.62271519%, total [0.9612976664769494, 0.9622373651334469, 0.9499568593615185, 0.9337938975244675, 0.943108504398827, 0.8676136363636363, 0.7288185282908238, 0.627906976744186, 0.8841265149275791, 0.6525522041763341, 0.595910138248848, 0.5120093731693028, 0.8531510107015458, 0.7423454650491046, 0.6488372093023256, 0.5559690810191812]\n",
      "cluster_accuracy_post_training_cycle_all_dataset : [0.95960503 0.96345811 0.93500464 0.90130354 0.91782178 0.77053571\n",
      " 0.62908012 0.64564831 0.8311292  0.67557252 0.58675373 0.38067061\n",
      " 0.86410788 0.63559322 0.60096154 0.5242452 ]\n",
      "mean_cluster_accuracy_during_training_cycle : 73.28%, post_traincycle_acc : 73.88%, total_acc : 73.47239152%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 76.62%\n",
      "accuracy_check 실행 시간: 33.617초\n",
      "\n",
      "\n",
      "epoch-36 loss : 0.02910\n",
      "ae train 실행 시간: 165.997초, 전체 시작 시간 20250123_143343_030\n",
      "\n",
      "epoch-36 accuracy check\n",
      "k_means origin feature average accuracy : 82.24947330%, total [0.9746727376209448, 0.9733106189664963, 0.9700891573195284, 0.9530800230282096, 0.943108504398827, 0.9150568181818182, 0.801817648783348, 0.6622234826999432, 0.9488619568430388, 0.822215777262181, 0.5866935483870968, 0.4997070884592853, 0.9429250891795482, 0.8922588099364529, 0.6738372093023256, 0.6000572573718866]\n",
      "kmeans average accuracy best : 81.78%, kmeans average accuracy : 77.54434104%, total [0.9593056346044394, 0.9611016467915957, 0.9502444636180616, 0.9337938975244675, 0.9410557184750733, 0.8900568181818181, 0.7261800058633832, 0.6318774815655134, 0.8604788649127993, 0.6534222737819025, 0.5924539170506913, 0.5295840656121851, 0.845422116527943, 0.7357019064124783, 0.6430232558139535, 0.5533924992842828]\n",
      "cluster_accuracy_post_training_cycle_all_dataset : [0.9551167  0.96524064 0.93036212 0.90037244 0.89306931 0.73303571\n",
      " 0.58456973 0.65452931 0.85147508 0.68129771 0.57369403 0.3816568\n",
      " 0.85788382 0.64500942 0.55961538 0.53430924]\n",
      "mean_cluster_accuracy_during_training_cycle : 71.96%, post_traincycle_acc : 73.13%, total_acc : 72.33107099%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 76.62%\n",
      "accuracy_check 실행 시간: 33.964초\n",
      "\n",
      "\n",
      "epoch-37 loss : 0.02811\n",
      "ae train 실행 시간: 166.402초, 전체 시작 시간 20250123_143343_030\n",
      "\n",
      "epoch-37 accuracy check\n",
      "k_means origin feature average accuracy : 82.26398401%, total [0.9746727376209448, 0.9733106189664963, 0.9700891573195284, 0.9530800230282096, 0.943108504398827, 0.9150568181818182, 0.8015244796247435, 0.6625070901871809, 0.9488619568430388, 0.822215777262181, 0.5872695852534562, 0.5005858230814294, 0.9429250891795482, 0.8922588099364529, 0.675, 0.5997709705124534]\n",
      "kmeans average accuracy best : 81.78%, kmeans average accuracy : 76.98987794%, total [0.9598747865680136, 0.9625212947189097, 0.9490940465918896, 0.931203223949338, 0.9404692082111437, 0.90625, 0.7279390208150103, 0.6145774248440159, 0.8353532367720957, 0.6499419953596288, 0.5832373271889401, 0.5260691271236086, 0.8415576694411415, 0.7261698440207972, 0.627906976744186, 0.5362152877182937]\n",
      "cluster_accuracy_post_training_cycle_all_dataset : [0.95601436 0.96256684 0.92943361 0.90130354 0.91584158 0.67857143\n",
      " 0.55093966 0.6616341  0.85859613 0.64980916 0.56623134 0.38658777\n",
      " 0.84439834 0.6393597  0.55576923 0.29460201]\n",
      "mean_cluster_accuracy_during_training_cycle : 71.18%, post_traincycle_acc : 70.95%, total_acc : 71.11311430%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 76.62%\n",
      "accuracy_check 실행 시간: 32.752초\n",
      "\n",
      "\n",
      "epoch-38 loss : 0.02815\n",
      "ae train 실행 시간: 166.103초, 전체 시작 시간 20250123_143343_030\n",
      "\n",
      "epoch-38 accuracy check\n",
      "k_means origin feature average accuracy : 82.24966347%, total [0.9746727376209448, 0.9733106189664963, 0.9700891573195284, 0.9530800230282096, 0.943108504398827, 0.9150568181818182, 0.801817648783348, 0.6625070901871809, 0.9488619568430388, 0.822215777262181, 0.5866935483870968, 0.5005858230814294, 0.9429250891795482, 0.8922588099364529, 0.6747093023255814, 0.5980532493558546]\n",
      "kmeans average accuracy best : 81.78%, kmeans average accuracy : 76.60875448%, total [0.9553215708594195, 0.9616695059625213, 0.9516824849007766, 0.936384571099597, 0.9419354838709677, 0.9170454545454545, 0.7015537965406039, 0.6176971072036301, 0.8250073898906296, 0.6429814385150812, 0.5766129032258065, 0.5123022847100176, 0.845422116527943, 0.7227036395147314, 0.6177325581395349, 0.5313484111079302]\n",
      "cluster_accuracy_post_training_cycle_all_dataset : [0.95332136 0.95989305 0.93686165 0.91154562 0.8970297  0.69553571\n",
      " 0.6181998  0.6651865  0.84231943 0.62881679 0.55876866 0.39053254\n",
      " 0.8526971  0.62429379 0.55769231 0.46294602]\n",
      "mean_cluster_accuracy_during_training_cycle : 71.71%, post_traincycle_acc : 72.22%, total_acc : 71.87488685%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 76.62%\n",
      "accuracy_check 실행 시간: 33.179초\n",
      "\n",
      "\n",
      "epoch-39 loss : 0.02666\n",
      "ae train 실행 시간: 166.570초, 전체 시작 시간 20250123_143343_030\n",
      "\n",
      "epoch-39 accuracy check\n",
      "k_means origin feature average accuracy : 82.24960241%, total [0.9746727376209448, 0.9733106189664963, 0.9700891573195284, 0.9530800230282096, 0.943108504398827, 0.9150568181818182, 0.801817648783348, 0.6625070901871809, 0.9488619568430388, 0.822215777262181, 0.5872695852534562, 0.5005858230814294, 0.9429250891795482, 0.8922588099364529, 0.6738372093023256, 0.5983395362152877]\n",
      "kmeans average accuracy best : 81.78%, kmeans average accuracy : 77.33753791%, total [0.962720546385885, 0.9645088018171494, 0.9557089444923785, 0.93811168681635, 0.9392961876832845, 0.8943181818181818, 0.7349750806215186, 0.6310266591038003, 0.8501330180313331, 0.6453016241299304, 0.5823732718894009, 0.5041007615700058, 0.8418549346016647, 0.7357019064124783, 0.6453488372093024, 0.5485256226739192]\n",
      "cluster_accuracy_post_training_cycle_all_dataset : [0.96050269 0.96613191 0.94150418 0.90782123 0.91881188 0.73571429\n",
      " 0.5578635  0.6651865  0.82400814 0.64122137 0.57742537 0.38362919\n",
      " 0.85995851 0.64595104 0.61346154 0.5315645 ]\n",
      "mean_cluster_accuracy_during_training_cycle : 72.80%, post_traincycle_acc : 73.32%, total_acc : 72.97413085%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 76.62%\n",
      "accuracy_check 실행 시간: 32.843초\n",
      "\n",
      "\n",
      "epoch-40 loss : 0.02613\n",
      "ae train 실행 시간: 166.887초, 전체 시작 시간 20250123_143343_030\n",
      "\n",
      "epoch-40 accuracy check\n",
      "k_means origin feature average accuracy : 82.25854398%, total [0.9746727376209448, 0.9733106189664963, 0.9700891573195284, 0.9530800230282096, 0.943108504398827, 0.9150568181818182, 0.801817648783348, 0.6622234826999432, 0.9488619568430388, 0.822215777262181, 0.5866935483870968, 0.5005858230814294, 0.9429250891795482, 0.8922588099364529, 0.6738372093023256, 0.600629831090753]\n",
      "kmeans average accuracy best : 81.78%, kmeans average accuracy : 77.14953681%, total [0.9621513944223108, 0.9642248722316865, 0.9528329019269485, 0.9366724237190558, 0.9351906158357771, 0.8838068181818182, 0.7162122544708297, 0.6327283040272264, 0.8474726574046704, 0.6487819025522041, 0.5797811059907834, 0.5043936731107206, 0.8478002378121284, 0.7313691507798961, 0.648546511627907, 0.5519610649871171]\n",
      "cluster_accuracy_post_training_cycle_all_dataset : [0.95691203 0.96345811 0.93314763 0.90223464 0.9049505  0.75089286\n",
      " 0.62710188 0.65808171 0.80264496 0.62977099 0.58302239 0.38560158\n",
      " 0.84128631 0.63841808 0.60192308 0.53247941]\n",
      "mean_cluster_accuracy_during_training_cycle : 72.52%, post_traincycle_acc : 73.20%, total_acc : 72.74803311%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 76.62%\n",
      "accuracy_check 실행 시간: 34.008초\n",
      "\n",
      "\n",
      "epoch-41 loss : 0.02933\n",
      "ae train 실행 시간: 166.897초, 전체 시작 시간 20250123_143343_030\n",
      "\n",
      "epoch-41 accuracy check\n",
      "k_means origin feature average accuracy : 82.26402702%, total [0.9746727376209448, 0.9733106189664963, 0.9700891573195284, 0.9530800230282096, 0.943108504398827, 0.9150568181818182, 0.801817648783348, 0.6625070901871809, 0.9488619568430388, 0.822215777262181, 0.5872695852534562, 0.5005858230814294, 0.9429250891795482, 0.8922588099364529, 0.675, 0.5994846836530203]\n",
      "kmeans average accuracy best : 81.78%, kmeans average accuracy : 76.50331612%, total [0.9618668184405236, 0.9628052243043725, 0.9476560253091746, 0.9303396660909614, 0.9366568914956012, 0.8409090909090909, 0.7065376722368807, 0.6205331820760068, 0.858409695536506, 0.650522041763341, 0.5737327188940092, 0.4847685998828354, 0.8504756242568371, 0.7290583477758521, 0.6340116279069767, 0.5522473518465503]\n",
      "cluster_accuracy_post_training_cycle_all_dataset : [0.95870736 0.96167558 0.92850511 0.88919926 0.91683168 0.775\n",
      " 0.6181998  0.65719361 0.86571719 0.6259542  0.57462687 0.39250493\n",
      " 0.84543568 0.65065913 0.59711538 0.51875572]\n",
      "mean_cluster_accuracy_during_training_cycle : 73.30%, post_traincycle_acc : 73.60%, total_acc : 73.40217331%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 76.62%\n",
      "accuracy_check 실행 시간: 34.570초\n",
      "\n",
      "\n",
      "epoch-42 loss : 0.02814\n",
      "ae train 실행 시간: 166.073초, 전체 시작 시간 20250123_143343_030\n",
      "\n",
      "epoch-42 accuracy check\n",
      "k_means origin feature average accuracy : 82.25855480%, total [0.9746727376209448, 0.9733106189664963, 0.9700891573195284, 0.9530800230282096, 0.943108504398827, 0.9150568181818182, 0.801817648783348, 0.6625070901871809, 0.9488619568430388, 0.822215777262181, 0.5866935483870968, 0.5005858230814294, 0.9429250891795482, 0.8922588099364529, 0.6741279069767442, 0.6000572573718866]\n",
      "kmeans average accuracy best : 81.78%, kmeans average accuracy : 75.60483517%, total [0.9567444507683551, 0.956274843838728, 0.9433419614610297, 0.9349453080023028, 0.944574780058651, 0.8607954545454546, 0.6742890647903841, 0.6174134997163925, 0.7969258054980787, 0.6424013921113689, 0.5743087557603687, 0.4947275922671353, 0.829667063020214, 0.7169266320046216, 0.6218023255813954, 0.5316346979673633]\n",
      "cluster_accuracy_post_training_cycle_all_dataset : [0.95332136 0.95811052 0.91457753 0.89757914 0.9        0.77678571\n",
      " 0.56577646 0.65630551 0.86775178 0.64885496 0.55317164 0.39053254\n",
      " 0.83506224 0.62806026 0.62307692 0.37968893]\n",
      "mean_cluster_accuracy_during_training_cycle : 71.75%, post_traincycle_acc : 72.18%, total_acc : 71.89431360%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 76.62%\n",
      "accuracy_check 실행 시간: 34.292초\n",
      "\n",
      "\n",
      "epoch-43 loss : 0.02632\n",
      "ae train 실행 시간: 167.789초, 전체 시작 시간 20250123_143343_030\n",
      "\n",
      "epoch-43 accuracy check\n",
      "k_means origin feature average accuracy : 82.26211374%, total [0.9746727376209448, 0.9733106189664963, 0.9700891573195284, 0.9530800230282096, 0.943108504398827, 0.915340909090909, 0.801817648783348, 0.6625070901871809, 0.9488619568430388, 0.822215777262181, 0.5872695852534562, 0.5005858230814294, 0.9429250891795482, 0.8922588099364529, 0.6738372093023256, 0.6000572573718866]\n",
      "kmeans average accuracy best : 81.78%, kmeans average accuracy : 76.34247408%, total [0.9547524188958452, 0.9568427030096536, 0.9450675870002876, 0.9340817501439264, 0.9404692082111437, 0.8394886363636364, 0.7021401348578129, 0.6270561542824731, 0.8471770617794857, 0.6447215777262181, 0.5817972350230415, 0.497070884592853, 0.8451248513674198, 0.7273252455228192, 0.6354651162790698, 0.5362152877182937]\n",
      "cluster_accuracy_post_training_cycle_all_dataset : [0.95062837 0.95632799 0.92850511 0.90689013 0.90594059 0.75446429\n",
      " 0.60929773 0.67939609 0.83418108 0.66412214 0.56623134 0.38954635\n",
      " 0.82572614 0.6299435  0.63461538 0.51235133]\n",
      "mean_cluster_accuracy_during_training_cycle : 72.40%, post_traincycle_acc : 73.43%, total_acc : 72.73025717%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 76.62%\n",
      "accuracy_check 실행 시간: 34.285초\n",
      "\n",
      "\n",
      "epoch-44 loss : 0.02587\n",
      "ae train 실행 시간: 167.346초, 전체 시작 시간 20250123_143343_030\n",
      "\n",
      "epoch-44 accuracy check\n",
      "k_means origin feature average accuracy : 82.26041597%, total [0.9746727376209448, 0.9733106189664963, 0.9700891573195284, 0.9530800230282096, 0.943108504398827, 0.9150568181818182, 0.801817648783348, 0.6622234826999432, 0.9488619568430388, 0.822215777262181, 0.5866935483870968, 0.5005858230814294, 0.9429250891795482, 0.8922588099364529, 0.6747093023255814, 0.6000572573718866]\n",
      "kmeans average accuracy best : 81.78%, kmeans average accuracy : 76.37287193%, total [0.9533295389869095, 0.9568427030096536, 0.9433419614610297, 0.9332181922855498, 0.9390029325513196, 0.8292613636363636, 0.7021401348578129, 0.6259217243335224, 0.8566361217853976, 0.6458816705336426, 0.5792050691244239, 0.5002929115407148, 0.8483947681331748, 0.7264586943963027, 0.6377906976744186, 0.5419410249069567]\n",
      "cluster_accuracy_post_training_cycle_all_dataset : [0.9497307  0.95721925 0.90064995 0.90409683 0.90990099 0.77321429\n",
      " 0.64589515 0.67584369 0.84944049 0.64408397 0.55690299 0.39151874\n",
      " 0.843361   0.64218456 0.64807692 0.36596523]\n",
      "mean_cluster_accuracy_during_training_cycle : 72.88%, post_traincycle_acc : 72.86%, total_acc : 72.88553231%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 76.62%\n",
      "accuracy_check 실행 시간: 33.110초\n",
      "\n",
      "\n",
      "epoch-45 loss : 0.02656\n",
      "ae train 실행 시간: 166.671초, 전체 시작 시간 20250123_143343_030\n",
      "\n",
      "epoch-45 accuracy check\n",
      "k_means origin feature average accuracy : 82.25318692%, total [0.9746727376209448, 0.9733106189664963, 0.9700891573195284, 0.9530800230282096, 0.943108504398827, 0.9150568181818182, 0.801817648783348, 0.6625070901871809, 0.9488619568430388, 0.822215777262181, 0.5866935483870968, 0.5005858230814294, 0.9429250891795482, 0.8922588099364529, 0.6741279069767442, 0.5991983967935872]\n",
      "kmeans average accuracy best : 81.78%, kmeans average accuracy : 76.19438988%, total [0.9487763232783153, 0.9522998296422487, 0.9278113316077078, 0.8978123200921129, 0.9480938416422288, 0.8619318181818182, 0.6886543535620053, 0.6108905275099262, 0.8737806680461129, 0.6496519721577726, 0.5826612903225806, 0.5014645577035736, 0.8507728894173603, 0.7299248989023686, 0.6386627906976744, 0.5279129687947324]\n",
      "cluster_accuracy_post_training_cycle_all_dataset : [0.94883303 0.9483066  0.88115135 0.89385475 0.92178218 0.79107143\n",
      " 0.61127596 0.73445826 0.87894201 0.65362595 0.58395522 0.3678501\n",
      " 0.85373444 0.63370998 0.62980769 0.34217749]\n",
      "mean_cluster_accuracy_during_training_cycle : 72.65%, post_traincycle_acc : 72.97%, total_acc : 72.76007571%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 76.62%\n",
      "accuracy_check 실행 시간: 33.362초\n",
      "\n",
      "\n",
      "epoch-46 loss : 0.02804\n",
      "ae train 실행 시간: 167.016초, 전체 시작 시간 20250123_143343_030\n",
      "\n",
      "epoch-46 accuracy check\n",
      "k_means origin feature average accuracy : 82.24590825%, total [0.9746727376209448, 0.9733106189664963, 0.9700891573195284, 0.9530800230282096, 0.943108504398827, 0.9150568181818182, 0.8015244796247435, 0.6625070901871809, 0.9488619568430388, 0.8219257540603249, 0.5866935483870968, 0.5005858230814294, 0.9429250891795482, 0.8922588099364529, 0.673546511627907, 0.5991983967935872]\n",
      "kmeans average accuracy best : 81.78%, kmeans average accuracy : 77.09760218%, total [0.9516220830961867, 0.9542873367404884, 0.9347138337647397, 0.9081750143926309, 0.9469208211143695, 0.8670454545454546, 0.7302843740838464, 0.6349971639251276, 0.857227313035767, 0.6519721577726219, 0.5717165898617511, 0.4991212653778559, 0.8635552913198573, 0.7429231658001155, 0.6630813953488373, 0.5579730890352133]\n",
      "cluster_accuracy_post_training_cycle_all_dataset : [0.95601436 0.95276292 0.91364903 0.89199255 0.90990099 0.74017857\n",
      " 0.61424332 0.69271758 0.84842319 0.65648855 0.53078358 0.40729783\n",
      " 0.84958506 0.6920904  0.66826923 0.54894785]\n",
      "mean_cluster_accuracy_during_training_cycle : 73.61%, post_traincycle_acc : 74.21%, total_acc : 73.80274071%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 76.62%\n",
      "accuracy_check 실행 시간: 33.837초\n",
      "\n",
      "\n",
      "epoch-47 loss : 0.02250\n",
      "ae train 실행 시간: 166.581초, 전체 시작 시간 20250123_143343_030\n",
      "\n",
      "epoch-47 accuracy check\n",
      "k_means origin feature average accuracy : 82.26042087%, total [0.9746727376209448, 0.9733106189664963, 0.9700891573195284, 0.9530800230282096, 0.943108504398827, 0.9150568181818182, 0.801817648783348, 0.6625070901871809, 0.9488619568430388, 0.822215777262181, 0.5872695852534562, 0.5005858230814294, 0.9429250891795482, 0.8922588099364529, 0.6747093023255814, 0.5991983967935872]\n",
      "kmeans average accuracy best : 81.78%, kmeans average accuracy : 76.67431175%, total [0.9544678429140581, 0.9540034071550255, 0.9347138337647397, 0.9061600460564191, 0.943108504398827, 0.8556818181818182, 0.7296980357666374, 0.6310266591038003, 0.8560449305350281, 0.6409512761020881, 0.5567396313364056, 0.4923842999414177, 0.8570154577883472, 0.7383015597920277, 0.6613372093023255, 0.5562553678786144]\n",
      "cluster_accuracy_post_training_cycle_all_dataset : [0.9524237  0.95098039 0.90157846 0.84543762 0.91287129 0.78571429\n",
      " 0.62116716 0.68206039 0.86266531 0.66698473 0.53264925 0.3964497\n",
      " 0.84958506 0.66854991 0.69519231 0.31838975]\n",
      "mean_cluster_accuracy_during_training_cycle : 73.00%, post_traincycle_acc : 72.77%, total_acc : 72.93886710%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 76.62%\n",
      "accuracy_check 실행 시간: 34.077초\n",
      "\n",
      "\n",
      "epoch-48 loss : 0.02228\n",
      "ae train 실행 시간: 166.765초, 전체 시작 시간 20250123_143343_030\n",
      "\n",
      "epoch-48 accuracy check\n",
      "k_means origin feature average accuracy : 82.24777182%, total [0.9746727376209448, 0.9733106189664963, 0.9700891573195284, 0.9530800230282096, 0.943108504398827, 0.915340909090909, 0.801817648783348, 0.6625070901871809, 0.9488619568430388, 0.822215777262181, 0.5872695852534562, 0.5005858230814294, 0.9429250891795482, 0.8922588099364529, 0.673546511627907, 0.5980532493558546]\n",
      "kmeans average accuracy best : 81.78%, kmeans average accuracy : 76.43458896%, total [0.9536141149686966, 0.9542873367404884, 0.9303997699165948, 0.9101899827288429, 0.9457478005865103, 0.853125, 0.7235414834359425, 0.6324446965399887, 0.8507242092817027, 0.6368909512761021, 0.5313940092165899, 0.4917984768599883, 0.8558263971462544, 0.7403235124205662, 0.6558139534883721, 0.5634125393644431]\n",
      "cluster_accuracy_post_training_cycle_all_dataset : [0.95062837 0.93582888 0.90250696 0.84078212 0.90693069 0.77857143\n",
      " 0.64589515 0.67850799 0.85045778 0.66698473 0.50932836 0.37179487\n",
      " 0.85062241 0.66666667 0.66634615 0.38517841]\n",
      "mean_cluster_accuracy_during_training_cycle : 72.73%, post_traincycle_acc : 72.54%, total_acc : 72.68386106%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 76.62%\n",
      "accuracy_check 실행 시간: 34.075초\n",
      "\n",
      "\n",
      "epoch-49 loss : 0.02192\n",
      "ae train 실행 시간: 166.676초, 전체 시작 시간 20250123_143343_030\n",
      "\n",
      "epoch-49 accuracy check\n",
      "k_means origin feature average accuracy : 82.26218852%, total [0.9746727376209448, 0.9733106189664963, 0.9700891573195284, 0.9530800230282096, 0.943108504398827, 0.9150568181818182, 0.801817648783348, 0.6625070901871809, 0.9488619568430388, 0.822215777262181, 0.5866935483870968, 0.5005858230814294, 0.9429250891795482, 0.8922588099364529, 0.6747093023255814, 0.6000572573718866]\n",
      "kmeans average accuracy best : 81.78%, kmeans average accuracy : 76.69866486%, total [0.9553215708594195, 0.9545712663259511, 0.9350014380212827, 0.911629245826137, 0.9460410557184751, 0.8701704545454545, 0.7285253591322193, 0.6341463414634146, 0.8459946792787467, 0.640661252900232, 0.5601958525345622, 0.49502050380785, 0.848692033293698, 0.7371461582900057, 0.6581395348837209, 0.5505296306899513]\n",
      "cluster_accuracy_post_training_cycle_all_dataset : [0.9524237  0.94474153 0.90436397 0.8594041  0.91584158 0.79107143\n",
      " 0.63402572 0.68472469 0.8809766  0.67461832 0.56343284 0.382643\n",
      " 0.86721992 0.66949153 0.64038462 0.37328454]\n",
      "mean_cluster_accuracy_during_training_cycle : 73.05%, post_traincycle_acc : 73.37%, total_acc : 73.16013777%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 76.62%\n",
      "accuracy_check 실행 시간: 34.737초\n",
      "\n",
      "\n",
      "epoch-50 loss : 0.02248\n",
      "ae train 실행 시간: 167.823초, 전체 시작 시간 20250123_143343_030\n",
      "\n",
      "epoch-50 accuracy check\n",
      "k_means origin feature average accuracy : 82.24421289%, total [0.9746727376209448, 0.9733106189664963, 0.9700891573195284, 0.9530800230282096, 0.943108504398827, 0.9150568181818182, 0.801817648783348, 0.6625070901871809, 0.9488619568430388, 0.822215777262181, 0.5866935483870968, 0.5005858230814294, 0.9429250891795482, 0.8922588099364529, 0.6738372093023256, 0.5980532493558546]\n",
      "kmeans average accuracy best : 81.78%, kmeans average accuracy : 76.40807623%, total [0.9536141149686966, 0.9571266325951164, 0.9367270635605407, 0.9139320667818077, 0.9451612903225807, 0.8818181818181818, 0.7338024039871005, 0.6253545093590471, 0.8170263080106415, 0.6421113689095128, 0.5697004608294931, 0.4915055653192736, 0.8466111771700356, 0.7293471981513576, 0.6380813953488372, 0.5433724592041226]\n",
      "cluster_accuracy_post_training_cycle_all_dataset : [0.95062837 0.94741533 0.90529248 0.8575419  0.8960396  0.76339286\n",
      " 0.60237389 0.69271758 0.86063072 0.64312977 0.56063433 0.37968442\n",
      " 0.83921162 0.66666667 0.66923077 0.3568161 ]\n",
      "mean_cluster_accuracy_during_training_cycle : 72.52%, post_traincycle_acc : 72.45%, total_acc : 72.51214524%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 76.62%\n",
      "accuracy_check 실행 시간: 33.852초\n",
      "\n",
      "\n",
      "epoch-51 loss : 0.02296\n",
      "ae train 실행 시간: 168.081초, 전체 시작 시간 20250123_143343_030\n",
      "\n",
      "epoch-51 accuracy check\n",
      "k_means origin feature average accuracy : 82.26207825%, total [0.9746727376209448, 0.9733106189664963, 0.9700891573195284, 0.9530800230282096, 0.943108504398827, 0.9150568181818182, 0.801817648783348, 0.6625070901871809, 0.9488619568430388, 0.822215777262181, 0.5866935483870968, 0.5005858230814294, 0.9429250891795482, 0.8922588099364529, 0.673546511627907, 0.6012024048096193]\n",
      "kmeans average accuracy best : 81.78%, kmeans average accuracy : 78.22608232%, total [0.9533295389869095, 0.9559909142532652, 0.9381650848432557, 0.9081750143926309, 0.944574780058651, 0.8704545454545455, 0.7194371152154794, 0.6364152013613159, 0.9355601537097251, 0.6809744779582366, 0.5619239631336406, 0.5295840656121851, 0.8912009512485137, 0.7648757943385326, 0.6549418604651163, 0.570569710850272]\n",
      "cluster_accuracy_post_training_cycle_all_dataset : [0.9524237  0.94117647 0.91179201 0.88175047 0.94257426 0.82678571\n",
      " 0.70128586 0.6687389  0.91047813 0.77385496 0.53451493 0.38362919\n",
      " 0.90352697 0.66290019 0.59615385 0.28087832]\n",
      "mean_cluster_accuracy_during_training_cycle : 75.23%, post_traincycle_acc : 74.20%, total_acc : 74.91151774%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 76.62%\n",
      "accuracy_check 실행 시간: 32.780초\n",
      "\n",
      "\n",
      "epoch-52 loss : 0.02363\n",
      "ae train 실행 시간: 166.090초, 전체 시작 시간 20250123_143343_030\n",
      "\n",
      "epoch-52 accuracy check\n",
      "k_means origin feature average accuracy : 82.25137006%, total [0.9746727376209448, 0.9733106189664963, 0.9700891573195284, 0.9530800230282096, 0.943108504398827, 0.9150568181818182, 0.801817648783348, 0.6625070901871809, 0.9488619568430388, 0.822215777262181, 0.5866935483870968, 0.5005858230814294, 0.9429250891795482, 0.8922588099364529, 0.6738372093023256, 0.5991983967935872]\n",
      "kmeans average accuracy best : 81.78%, kmeans average accuracy : 77.93358545%, total [0.9553215708594195, 0.9582623509369677, 0.9398907103825137, 0.9208405296488198, 0.9454545454545454, 0.8534090909090909, 0.7167985927880387, 0.633011911514464, 0.9261010937038132, 0.6728538283062645, 0.5613479262672811, 0.525776215582894, 0.8843638525564804, 0.7530329289428076, 0.6531976744186047, 0.5697108502719725]\n",
      "cluster_accuracy_post_training_cycle_all_dataset : [0.9524237  0.94741533 0.93500464 0.89478585 0.93564356 0.8\n",
      " 0.67062315 0.6705151  0.8982706  0.72232824 0.58675373 0.38560158\n",
      " 0.85477178 0.64030132 0.59326923 0.50960659]\n",
      "mean_cluster_accuracy_during_training_cycle : 74.61%, post_traincycle_acc : 74.98%, total_acc : 74.73439296%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 76.62%\n",
      "accuracy_check 실행 시간: 33.582초\n",
      "\n",
      "\n",
      "epoch-53 loss : 0.02514\n",
      "ae train 실행 시간: 166.575초, 전체 시작 시간 20250123_143343_030\n",
      "\n",
      "epoch-53 accuracy check\n",
      "k_means origin feature average accuracy : 82.25149115%, total [0.9746727376209448, 0.9733106189664963, 0.9700891573195284, 0.9530800230282096, 0.943108504398827, 0.9150568181818182, 0.801817648783348, 0.6622234826999432, 0.9488619568430388, 0.822215777262181, 0.5872695852534562, 0.5005858230814294, 0.9429250891795482, 0.8922588099364529, 0.6747093023255814, 0.5980532493558546]\n",
      "kmeans average accuracy best : 81.78%, kmeans average accuracy : 78.09267828%, total [0.9581673306772909, 0.9613855763770585, 0.9453551912568307, 0.9248704663212435, 0.9357771260997068, 0.819034090909091, 0.7085898563471122, 0.627906976744186, 0.8906296186816435, 0.6888051044083526, 0.586405529953917, 0.510837727006444, 0.8900118906064209, 0.7440785673021375, 0.7223837209302325, 0.5805897509304323]\n",
      "cluster_accuracy_post_training_cycle_all_dataset : [0.95960503 0.95365419 0.91922006 0.89385475 0.94851485 0.74017857\n",
      " 0.66369931 0.62699822 0.89623601 0.69751908 0.57649254 0.40631164\n",
      " 0.843361   0.70527307 0.58942308 0.56084172]\n",
      "mean_cluster_accuracy_during_training_cycle : 73.78%, post_traincycle_acc : 74.88%, total_acc : 74.12700011%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 76.62%\n",
      "accuracy_check 실행 시간: 33.728초\n",
      "\n",
      "\n",
      "epoch-54 loss : 0.02502\n",
      "ae train 실행 시간: 166.660초, 전체 시작 시간 20250123_143343_030\n",
      "\n",
      "epoch-54 accuracy check\n",
      "k_means origin feature average accuracy : 82.26031652%, total [0.9746727376209448, 0.9733106189664963, 0.9700891573195284, 0.9530800230282096, 0.943108504398827, 0.9150568181818182, 0.801817648783348, 0.6625070901871809, 0.9488619568430388, 0.822215777262181, 0.5866935483870968, 0.5005858230814294, 0.9429250891795482, 0.8922588099364529, 0.6738372093023256, 0.600629831090753]\n",
      "kmeans average accuracy best : 81.78%, kmeans average accuracy : 78.91129702%, total [0.9601593625498008, 0.9639409426462238, 0.9528329019269485, 0.931203223949338, 0.9442815249266863, 0.8676136363636363, 0.7294048666080328, 0.6395348837209303, 0.9027490393142181, 0.7178074245939675, 0.5780529953917051, 0.5096660808435852, 0.8816884661117717, 0.7590987868284229, 0.7017441860465117, 0.5860292012596622]\n",
      "cluster_accuracy_post_training_cycle_all_dataset : [0.96140036 0.95454545 0.93036212 0.90875233 0.95148515 0.79642857\n",
      " 0.67260138 0.65452931 0.89114954 0.76240458 0.61847015 0.39250493\n",
      " 0.83713693 0.6299435  0.57596154 0.55535224]\n",
      "mean_cluster_accuracy_during_training_cycle : 73.15%, post_traincycle_acc : 75.58%, total_acc : 73.91357599%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 76.62%\n",
      "accuracy_check 실행 시간: 34.068초\n",
      "\n",
      "\n",
      "epoch-55 loss : 0.02440\n",
      "ae train 실행 시간: 166.351초, 전체 시작 시간 20250123_143343_030\n",
      "\n",
      "epoch-55 accuracy check\n",
      "k_means origin feature average accuracy : 82.26041597%, total [0.9746727376209448, 0.9733106189664963, 0.9700891573195284, 0.9530800230282096, 0.943108504398827, 0.9150568181818182, 0.801817648783348, 0.6622234826999432, 0.9488619568430388, 0.822215777262181, 0.5866935483870968, 0.5005858230814294, 0.9429250891795482, 0.8922588099364529, 0.6747093023255814, 0.6000572573718866]\n",
      "kmeans average accuracy best : 81.78%, kmeans average accuracy : 78.76471351%, total [0.9601593625498008, 0.9633730834752982, 0.9554213402358355, 0.9375359815774323, 0.9448680351906158, 0.8670454545454546, 0.73116388155966, 0.6454906409529212, 0.8897428318060893, 0.718677494199536, 0.5809331797235023, 0.5125951962507322, 0.8721759809750297, 0.7576545349508954, 0.6688953488372092, 0.5966218150586888]\n",
      "cluster_accuracy_post_training_cycle_all_dataset : [0.96229803 0.95811052 0.92943361 0.90502793 0.95346535 0.73303571\n",
      " 0.6933729  0.6625222  0.90335707 0.73759542 0.5988806  0.40335306\n",
      " 0.82365145 0.67137476 0.56442308 0.55169259]\n",
      "mean_cluster_accuracy_during_training_cycle : 73.90%, post_traincycle_acc : 75.32%, total_acc : 74.34177264%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 76.62%\n",
      "accuracy_check 실행 시간: 33.894초\n",
      "\n",
      "\n",
      "epoch-56 loss : 0.02422\n",
      "ae train 실행 시간: 167.338초, 전체 시작 시간 20250123_143343_030\n",
      "\n",
      "epoch-56 accuracy check\n",
      "k_means origin feature average accuracy : 82.25489481%, total [0.9746727376209448, 0.9733106189664963, 0.9700891573195284, 0.9530800230282096, 0.943108504398827, 0.9150568181818182, 0.8015244796247435, 0.6622234826999432, 0.9488619568430388, 0.822215777262181, 0.5866935483870968, 0.5005858230814294, 0.9429250891795482, 0.8922588099364529, 0.673546511627907, 0.600629831090753]\n",
      "kmeans average accuracy best : 81.78%, kmeans average accuracy : 78.96361441%, total [0.960728514513375, 0.9628052243043725, 0.9582973828012654, 0.9383995394358089, 0.9442815249266863, 0.8772727272727273, 0.7469950161243037, 0.6537152580828134, 0.8932899793083062, 0.6998259860788864, 0.5878456221198156, 0.5184534270650264, 0.8730677764565993, 0.7498555748122473, 0.6758720930232558, 0.5934726596049241]\n",
      "cluster_accuracy_post_training_cycle_all_dataset : [0.95870736 0.95543672 0.93779016 0.92458101 0.94653465 0.72321429\n",
      " 0.69732938 0.68561279 0.85757884 0.79389313 0.58675373 0.41913215\n",
      " 0.84232365 0.65630885 0.56634615 0.55169259]\n",
      "mean_cluster_accuracy_during_training_cycle : 73.41%, post_traincycle_acc : 75.65%, total_acc : 74.10693629%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 76.62%\n",
      "accuracy_check 실행 시간: 33.942초\n",
      "\n",
      "\n",
      "epoch-57 loss : 0.02422\n",
      "ae train 실행 시간: 166.508초, 전체 시작 시간 20250123_143343_030\n",
      "\n",
      "epoch-57 accuracy check\n",
      "k_means origin feature average accuracy : 82.26574734%, total [0.9746727376209448, 0.9733106189664963, 0.9700891573195284, 0.9530800230282096, 0.943108504398827, 0.9150568181818182, 0.801817648783348, 0.6625070901871809, 0.9488619568430388, 0.822215777262181, 0.5872695852534562, 0.5002929115407148, 0.9429250891795482, 0.8922588099364529, 0.6747093023255814, 0.6003435442313197]\n",
      "kmeans average accuracy best : 81.78%, kmeans average accuracy : 78.31179770%, total [0.9610130904951623, 0.9633730834752982, 0.9559965487489215, 0.939838802533103, 0.9448680351906158, 0.8667613636363637, 0.7285253591322193, 0.6452070334656835, 0.8791013892994384, 0.673723897911833, 0.5633640552995391, 0.5143526654950205, 0.8745541022592153, 0.756210283073368, 0.6726744186046512, 0.5903235041511594]\n",
      "cluster_accuracy_post_training_cycle_all_dataset : [0.96319569 0.95811052 0.94150418 0.92458101 0.95445545 0.73571429\n",
      " 0.6785361  0.669627   0.90844354 0.79389313 0.55223881 0.40631164\n",
      " 0.85788382 0.69868173 0.59615385 0.5315645 ]\n",
      "mean_cluster_accuracy_during_training_cycle : 75.16%, post_traincycle_acc : 76.07%, total_acc : 75.44241652%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 76.62%\n",
      "accuracy_check 실행 시간: 34.240초\n",
      "\n",
      "\n",
      "epoch-58 loss : 0.02381\n",
      "ae train 실행 시간: 167.460초, 전체 시작 시간 20250123_143343_030\n",
      "\n",
      "epoch-58 accuracy check\n",
      "k_means origin feature average accuracy : 82.26578875%, total [0.9746727376209448, 0.9733106189664963, 0.9700891573195284, 0.9530800230282096, 0.943108504398827, 0.9150568181818182, 0.801817648783348, 0.6625070901871809, 0.9488619568430388, 0.822215777262181, 0.5872695852534562, 0.5005858230814294, 0.9429250891795482, 0.8922588099364529, 0.6747093023255814, 0.6000572573718866]\n",
      "kmeans average accuracy best : 81.78%, kmeans average accuracy : 78.46492225%, total [0.9598747865680136, 0.9630891538898353, 0.9539833189531205, 0.9343696027633851, 0.9410557184750733, 0.8252840909090909, 0.7144532395192026, 0.6418037436188315, 0.9042270174401419, 0.673723897911833, 0.5590437788018433, 0.5161101347393088, 0.882282996432818, 0.7631426920854997, 0.7273255813953489, 0.5946178070426568]\n",
      "cluster_accuracy_post_training_cycle_all_dataset : [0.95870736 0.95632799 0.93964717 0.90968343 0.95049505 0.78571429\n",
      " 0.73491592 0.6678508  0.89013225 0.75954198 0.53544776 0.40039448\n",
      " 0.86721992 0.70056497 0.59519231 0.56816102]\n",
      "mean_cluster_accuracy_during_training_cycle : 75.61%, post_traincycle_acc : 76.37%, total_acc : 75.85052020%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 76.62%\n",
      "accuracy_check 실행 시간: 32.736초\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "gpu = '0'\n",
    "Conv_net = True # True False\n",
    "SAE_net = True # True False\n",
    "\n",
    "# hyperparameter\n",
    "dataset_num = 16\n",
    "spike_length = 50 # coarse_com_mode일 때는 time step이 됨.\n",
    "num_cluster = 4  # 클러스터 수 설정 # 논문엔 4개라는데 여기서는 3개로 했네\n",
    "training_cycle = 2400 #1400 2400 # 그 초기 몇개까지만 cluster update할지\n",
    "\n",
    "\n",
    "batch_size = 32\n",
    "max_epoch = 7000\n",
    "learning_rate = 0.001\n",
    "normalize_on = True # True or False # 0부터1까지 normalize\n",
    "need_bias = False\n",
    "# first_layer_no_train = False\n",
    "lif_add_at_first = False\n",
    "my_seed = 42\n",
    "\n",
    "TIME = 50 # SAE일 때만 유효. coarse_com_mode일 때는 level_num이 됨. 즉 feature 개수.\n",
    "v_decay = 0.25 # -cor\n",
    "v_threshold = 0.5 # -cor\n",
    "v_reset = 10000.0 # -cor # 10000이상 일 시 hard reset\n",
    "BPTT_on = False # +cor # True False\n",
    "\n",
    "SAE_hidden_nomean = True # True False\n",
    "\n",
    "current_time = datetime.datetime.now().strftime(\"%Y%m%d_%H%M%S\") + f\"_{str(int(datetime.datetime.now().microsecond / 1000)).zfill(3)}\"\n",
    "\n",
    "optimizer = 'Adam' #'Adam', 'SGD' # 둘다 준수함. loss 줄이는 거는 adam이 좋긴한데, cluster accuracy는 비슷함.\n",
    "\n",
    "coarse_com_mode = True\n",
    "coarse_com_config = (1.0, -0.0) # (max, min) (2.0, -2.0) (3.0, -3.0)\n",
    "\n",
    "sae_l2_norm_bridge = True # True False\n",
    "sae_lif_bridge = True # False True\n",
    "\n",
    "accuracy_check_epoch_term = 1\n",
    "\n",
    "lif_add_at_last = False # True False\n",
    "\n",
    "two_channel_input = False # True False\n",
    "\n",
    "lateral_feature_num = 4\n",
    "\n",
    "lc_adc_on = False # True False\n",
    "\n",
    "converted_net_forward = False # True False\n",
    "\n",
    "pretrained_net = None\n",
    "# pretrained_net = '/home/bhkim003/github_folder/ByeonghyeonKim/my_snn/net_save/save_now_net_중요_20250110_203117_390.pth'\n",
    "# pretrained_net = '/home/bhkim003/github_folder/ByeonghyeonKim/my_snn/net_save/save_now_net_중요_20250113_134126_881_이거_94나오는거.pth'\n",
    "# pretrained_net = '/home/bhkim003/github_folder/ByeonghyeonKim/my_snn/net_save/save_now_net_중요_20250115_200335_029_무한열차95.12.pth'\n",
    "# pretrained_net = '/home/bhkim003/github_folder/ByeonghyeonKim/my_snn/net_save/save_now_net_중요_20250115_200335_029_무한열차95.23.pth'\n",
    "\n",
    "vth_mul_on = False # True False\n",
    "batch_norm_on = False # True False\n",
    "\n",
    "l2_norm_loss_weight = 0 #0.0001 #0.1 #  0 # 0초과면 작동\n",
    "\n",
    "QCFS_neuron_on = False # True False\n",
    "\n",
    "wandb.init(project= f'spike_sorting just run',save_code=False)\n",
    "\n",
    "\n",
    "cluster_train_system( \n",
    "    gpu = gpu,\n",
    "    Conv_net = Conv_net,\n",
    "    SAE_net = SAE_net,\n",
    "\n",
    "    # hyperparameter\n",
    "    dataset_num = dataset_num,\n",
    "    spike_length = spike_length,\n",
    "    num_cluster = num_cluster,  # 클러스터 수 설정 # 논문엔 4개라는데 여기서는 3개로 했네\n",
    "    training_cycle = training_cycle, # 그 초기 몇개까지만 cluster update할지\n",
    "\n",
    "\n",
    "    batch_size = batch_size,\n",
    "    max_epoch = max_epoch,\n",
    "    learning_rate = learning_rate,\n",
    "    normalize_on = normalize_on, # True or False #이거 안 씀 # 이거 별로 안 좋은 normalize같음 # 쓸 거면 다른 거 써라.\n",
    "    need_bias = need_bias,\n",
    "    # first_layer_no_train = False\n",
    "    lif_add_at_first = lif_add_at_first,\n",
    "    my_seed = my_seed,\n",
    "\n",
    "    TIME = TIME, # SAE일 때만 유효\n",
    "    v_decay = v_decay,\n",
    "    v_threshold = v_threshold,\n",
    "    v_reset = v_reset, # 10000이상 일 시 hard reset\n",
    "    BPTT_on = BPTT_on,\n",
    "\n",
    "    SAE_hidden_nomean = SAE_hidden_nomean,\n",
    "    \n",
    "    current_time = current_time,\n",
    "\n",
    "    optimizer = optimizer, #'Adam', 'SGD'\n",
    "\n",
    "    coarse_com_mode = coarse_com_mode,\n",
    "    coarse_com_config = coarse_com_config, # (max, min)\n",
    "\n",
    "    \n",
    "    sae_l2_norm_bridge = sae_l2_norm_bridge,\n",
    "    sae_lif_bridge = sae_lif_bridge,\n",
    "\n",
    "    accuracy_check_epoch_term = accuracy_check_epoch_term,\n",
    "    \n",
    "    lif_add_at_last = lif_add_at_last,\n",
    "\n",
    "    two_channel_input = two_channel_input,\n",
    "\n",
    "    lateral_feature_num = lateral_feature_num,\n",
    "\n",
    "    lc_adc_on = lc_adc_on, \n",
    "\n",
    "    converted_net_forward = converted_net_forward,\n",
    "\n",
    "    pretrained_net = pretrained_net,\n",
    "\n",
    "    vth_mul_on = vth_mul_on,\n",
    "    batch_norm_on = batch_norm_on,\n",
    "\n",
    "    l2_norm_loss_weight = l2_norm_loss_weight,\n",
    "    \n",
    "    QCFS_neuron_on = QCFS_neuron_on # True False\n",
    "\n",
    "    )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Sweep code\n",
    "\n",
    "\n",
    "# from unittest import TextTestRunner\n",
    "\n",
    "\n",
    "# unique_name_hyper = 'cluster_train_system'\n",
    "# # run_name = 'spike_sorting'\n",
    "# sweep_start_time =  datetime.datetime.now().strftime(\"%Y%m%d_%H%M%S\") + f\"_{str(int(datetime.datetime.now().microsecond / 1000)).zfill(3)}\"\n",
    "# sweep_configuration = {\n",
    "#     'method': 'bayes', # 'random', 'bayes'\n",
    "#     'name': f'spike_sorting_{sweep_start_time}',\n",
    "#     'metric': {'goal': 'maximize', 'name': 'k_means_acc_best'},\n",
    "#     'parameters': \n",
    "#     {\n",
    "#         # \"gpu\": {\"values\": ['1']},  # 이건 sweep parameter아님. hyper_iter에서 직접 설정\n",
    "#         \"Conv_net\": {\"values\": [True]}, \n",
    "#         \"SAE_net\": {\"values\": [False]}, \n",
    "\n",
    "#         \"dataset_num\": {\"values\": [16]}, \n",
    "#         \"spike_length\": {\"values\": [50]},  \n",
    "#         \"num_cluster\": {\"values\": [4]}, \n",
    "#         \"training_cycle\": {\"values\": [2400]}, # [1400, 2400]\n",
    "\n",
    "#         \"batch_size\": {\"values\": [32]}, \n",
    "#         \"max_epoch\": {\"values\": [1]}, \n",
    "#         \"learning_rate\": {\"values\": [0.001, 0.0001]},\n",
    "#         \"normalize_on\": {\"values\": [True]},\n",
    "#         \"need_bias\": {\"values\": [False]}, # [True, False]\n",
    "\n",
    "#         \"lif_add_at_first\": {\"values\": [False]}, # [True, False]\n",
    "#         \"my_seed\": {\"values\": [42]}, \n",
    "\n",
    "#         \"TIME\": {\"values\": [10, 50, 100, 250, 500, 750, 1000, 1500, 2000, 2500]}, #  [4,6,8,10]\n",
    "#         \"v_decay\": {\"values\": [1.0]}, # [0.25,0.50,0.75]\n",
    "#         \"v_threshold\": {\"values\": [0.125, 0.25, 0.50, 0.75, 0.875, 1.0]}, # [0.25,0.50,0.75]\n",
    "#         \"v_reset\": {\"values\": [0.0, 10000.0]},  # [0.0, 10000.0]\n",
    "#         \"BPTT_on\": {\"values\": [True, False]},  # [True, False]\n",
    "\n",
    "#         \"SAE_hidden_nomean\": {\"values\": [True]}, # [True, False]\n",
    "\n",
    "#         # \"current_time\": {\"values\": [current_time]} #밑에서 직접설정됨.\n",
    "\n",
    "#         \"optimizer\": {\"values\": ['Adam', 'SGD']}, # ['Adam', 'SGD']\n",
    "\n",
    "#         \"coarse_com_mode\": {\"values\": [False]}, # [True, False]\n",
    "#         \"coarse_com_config\": {\"values\": [(2.0, -2.0)]}, # ['Adam', 'SGD']\n",
    "\n",
    "#         \"sae_l2_norm_bridge\": {\"values\": [True]}, # [True, False]\n",
    "#         \"sae_lif_bridge\": {\"values\": [True]}, # [False, True]\n",
    "        \n",
    "#         \"accuracy_check_epoch_term\": {\"values\": [1]}, \n",
    "\n",
    "#         \"lif_add_at_last\": {\"values\": [False]},# [True, False]\n",
    "\n",
    "#         \"two_channel_input\": {\"values\": [False]},# [True, False]\n",
    "\n",
    "#         \"lateral_feature_num\": {\"values\": [4]},# [True, False]\n",
    "\n",
    "#         \"lc_adc_on\": {\"values\": [False]},# [True, False]\n",
    "        \n",
    "#         \"converted_net_forward\": {\"values\": [True]},# [True, False]\n",
    "\n",
    "#         \"pretrained_net\": {\"values\": ['/home/bhkim003/github_folder/ByeonghyeonKim/my_snn/net_save/save_now_net_중요_20250110_203117_390.pth']},# [None]\n",
    "\n",
    "#         \"vth_mul_on\": {\"values\": [True]},# [True, False]\n",
    "#         \"batch_norm_on\": {\"values\": [True]},# [True, False]\n",
    "\n",
    "#         \"l2_norm_loss_weight\": {\"values\": [0.1]},\n",
    "\n",
    "#         \"QCFS_neuron_on\": {\"values\": [True]},   # [True, False]\n",
    "\n",
    "\n",
    "#      }\n",
    "# }\n",
    "\n",
    "\n",
    "# def hyper_iter():\n",
    "#     ### my_snn control board ########################\n",
    "#     wandb.init(save_code = False)\n",
    "#     gpu  =  '2'\n",
    "#     Conv_net  =  wandb.config.Conv_net\n",
    "#     SAE_net  =  wandb.config.SAE_net\n",
    "\n",
    "#     dataset_num  =  wandb.config.dataset_num\n",
    "#     spike_length  =  wandb.config.spike_length\n",
    "#     num_cluster  =  wandb.config.num_cluster\n",
    "#     training_cycle  =  wandb.config.training_cycle\n",
    "\n",
    "#     batch_size  =  wandb.config.batch_size\n",
    "#     max_epoch  =  wandb.config.max_epoch\n",
    "#     learning_rate  =  wandb.config.learning_rate\n",
    "#     normalize_on  =  wandb.config.normalize_on\n",
    "#     need_bias  =  wandb.config.need_bias\n",
    "\n",
    "#     lif_add_at_first  =  wandb.config.lif_add_at_first\n",
    "#     my_seed  =  wandb.config.my_seed\n",
    "\n",
    "\n",
    "#     TIME  =  wandb.config.TIME\n",
    "#     v_decay  =  wandb.config.v_decay\n",
    "#     v_threshold  =  wandb.config.v_threshold\n",
    "#     v_reset  =  wandb.config.v_reset\n",
    "#     BPTT_on  =  wandb.config.BPTT_on\n",
    "\n",
    "#     SAE_hidden_nomean  =  wandb.config.SAE_hidden_nomean\n",
    "    \n",
    "#     current_time =  datetime.datetime.now().strftime(\"%Y%m%d_%H%M%S\") + f\"_{str(int(datetime.datetime.now().microsecond / 1000)).zfill(3)}\"\n",
    "\n",
    "#     optimizer  =  wandb.config.optimizer\n",
    "\n",
    "#     coarse_com_mode = wandb.config.coarse_com_mode\n",
    "#     coarse_com_config = wandb.config.coarse_com_config # (max, min)\n",
    "\n",
    "#     sae_l2_norm_bridge = wandb.config.sae_l2_norm_bridge\n",
    "#     sae_lif_bridge = wandb.config.sae_lif_bridge\n",
    "\n",
    "#     accuracy_check_epoch_term = wandb.config.accuracy_check_epoch_term\n",
    "\n",
    "#     lif_add_at_last = wandb.config.lif_add_at_last\n",
    "\n",
    "#     two_channel_input = wandb.config.two_channel_input\n",
    "\n",
    "#     lateral_feature_num = wandb.config.lateral_feature_num\n",
    "\n",
    "#     lc_adc_on = wandb.config.lc_adc_on\n",
    "\n",
    "#     converted_net_forward = wandb.config.converted_net_forward\n",
    "\n",
    "#     pretrained_net = wandb.config.pretrained_net\n",
    "\n",
    "#     vth_mul_on = wandb.config.vth_mul_on\n",
    "#     batch_norm_on = wandb.config.batch_norm_on\n",
    "\n",
    "#     l2_norm_loss_weight = wandb.config.l2_norm_loss_weight\n",
    "\n",
    "#     QCFS_neuron_on = wandb.config.QCFS_neuron_on\n",
    "\n",
    "    \n",
    "\n",
    "#     cluster_train_system( \n",
    "#         gpu = gpu,\n",
    "#         Conv_net = Conv_net,\n",
    "#         SAE_net = SAE_net,\n",
    "\n",
    "#         # hyperparameter\n",
    "#         dataset_num = dataset_num,\n",
    "#         spike_length = spike_length,\n",
    "#         num_cluster = num_cluster,  # 클러스터 수 설정 # 논문엔 4개라는데 여기서는 3개로 했네\n",
    "#         training_cycle = training_cycle, # 그 초기 몇개까지만 cluster update할지\n",
    "\n",
    "\n",
    "#         batch_size = batch_size,\n",
    "#         max_epoch = max_epoch,\n",
    "#         learning_rate = learning_rate,\n",
    "#         normalize_on = normalize_on, # True or False #이거 안 씀 # 이거 별로 안 좋은 normalize같음 # 쓸 거면 다른 거 써라.\n",
    "#         need_bias = need_bias,\n",
    "#         # first_layer_no_train = False\n",
    "#         lif_add_at_first = lif_add_at_first,\n",
    "#         my_seed = my_seed,\n",
    "\n",
    "#         TIME = TIME, # SAE일 때만 유효\n",
    "#         v_decay = v_decay,\n",
    "#         v_threshold = v_threshold,\n",
    "#         v_reset = v_reset, # 10000이상 일 시 hard reset\n",
    "#         BPTT_on = BPTT_on,\n",
    "\n",
    "#         SAE_hidden_nomean = SAE_hidden_nomean,\n",
    "\n",
    "#         current_time = current_time,\n",
    "\n",
    "#         optimizer = optimizer, #'Adam', 'SGD'\n",
    "\n",
    "#         coarse_com_mode = coarse_com_mode,\n",
    "#         coarse_com_config = coarse_com_config, # (max, min)\n",
    "        \n",
    "#         sae_l2_norm_bridge = sae_l2_norm_bridge,\n",
    "#         sae_lif_bridge = sae_lif_bridge,\n",
    "\n",
    "#         accuracy_check_epoch_term = accuracy_check_epoch_term,\n",
    "\n",
    "#         lif_add_at_last = lif_add_at_last,\n",
    "        \n",
    "#         two_channel_input = two_channel_input,\n",
    "        \n",
    "#         lateral_feature_num = lateral_feature_num,\n",
    "\n",
    "#         lc_adc_on = lc_adc_on,\n",
    "\n",
    "#         converted_net_forward = converted_net_forward,\n",
    "\n",
    "#         pretrained_net = pretrained_net,\n",
    "\n",
    "#         vth_mul_on = vth_mul_on,\n",
    "#         batch_norm_on = batch_norm_on,\n",
    "\n",
    "#         l2_norm_loss_weight = l2_norm_loss_weight,\n",
    "\n",
    "#         QCFS_neuron_on = QCFS_neuron_on,\n",
    "\n",
    "#         )\n",
    "    \n",
    "# # sweep_id = 'ygoj9jt4'\n",
    "# sweep_id = wandb.sweep(sweep=sweep_configuration, project=f'spike_sorting {unique_name_hyper}')\n",
    "# wandb.agent(sweep_id, function=hyper_iter, count=100000, project=f'spike_sorting {unique_name_hyper}')\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wandb.finish() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import matplotlib.pyplot as plt\n",
    "# from matplotlib.ticker import MaxNLocator\n",
    "# import pickle\n",
    "# import json\n",
    "\n",
    "# # current_time = '20250102_225243_972'\n",
    "\n",
    "# with open(f\"result_save/cluster_accuracy_history_{current_time}.pkl\", \"rb\") as f:\n",
    "#     data = pickle.load(f)\n",
    "\n",
    "\n",
    "# # JSON으로 저장\n",
    "# with open(f\"result_save/cluster_accuracy_history_{current_time}.json\", 'r') as f:\n",
    "#     loaded_hyperparameters = json.load(f)\n",
    "\n",
    "# loss_history = data['loss_history']\n",
    "# mean_cluster_accuracy_during_training_cycle_all_dataset_history = data['mean_cluster_accuracy_during_training_cycle_all_dataset_history']\n",
    "# mean_cluster_accuracy_post_training_cycle_all_dataset_history = data['mean_cluster_accuracy_post_training_cycle_all_dataset_history']\n",
    "# mean_cluster_accuracy_total_all_dataset_history = data['mean_cluster_accuracy_total_all_dataset_history']\n",
    "# print(data)\n",
    "# max_acc = 0\n",
    "# for i in mean_cluster_accuracy_post_training_cycle_all_dataset_history:\n",
    "#     if i[1] > max_acc:\n",
    "#         max_acc = i[1]\n",
    "\n",
    "# # 설정 정보 제목 작성\n",
    "# title = (\n",
    "#     f\"Dataset Num: {loaded_hyperparameters['dataset_num']}, Conv {loaded_hyperparameters['Conv_net']}, SAE {loaded_hyperparameters['SAE_net']}, Current time {loaded_hyperparameters['current_time']}, Spike Length: {loaded_hyperparameters['spike_length']}, Num Cluster: {loaded_hyperparameters['num_cluster']}, \"\n",
    "#     f\"Training Cycle: {loaded_hyperparameters['training_cycle']}, Batch Size: {loaded_hyperparameters['batch_size']}, Max Epoch: {loaded_hyperparameters['max_epoch']}, \\n\"\n",
    "#     f\"Learning Rate: {loaded_hyperparameters['learning_rate']}, Input Normalize: {loaded_hyperparameters['normalize_on']}, Need Bias: {loaded_hyperparameters['need_bias']}, \"\n",
    "#     f\"LIF Add at First: {loaded_hyperparameters['lif_add_at_first']}, TIME: {loaded_hyperparameters['TIME']}, Seed: {loaded_hyperparameters['my_seed']}, Best ACC: {max_acc:.2f}%\"\n",
    "# )\n",
    "\n",
    "# # 데이터 리스트와 라벨 설정 (Loss 제외)\n",
    "# data_list = [\n",
    "#     (\"Mean Cluster Accuracy (During Training Cycle)\", mean_cluster_accuracy_during_training_cycle_all_dataset_history),\n",
    "#     (\"Mean Cluster Accuracy (Post Training Cycle)\", mean_cluster_accuracy_post_training_cycle_all_dataset_history),\n",
    "#     (\"Mean Cluster Accuracy (Total)\", mean_cluster_accuracy_total_all_dataset_history),\n",
    "# ]\n",
    "\n",
    "# # 플롯 생성\n",
    "# fig, ax1 = plt.subplots(figsize=(12, 8))\n",
    "\n",
    "# # 첫 번째 y축: Accuracy 관련 데이터\n",
    "# for label, data in data_list:\n",
    "#     epochs, values = zip(*data)  # epoch, value 분리\n",
    "#     ax1.plot(epochs, values, label=label)\n",
    "\n",
    "# ax1.set_xlabel(\"Epoch\")\n",
    "# ax1.set_ylabel(\"Clurstering Accuracy [%]\", color=\"blue\")\n",
    "# ax1.tick_params(axis=\"y\", labelcolor=\"blue\")\n",
    "# ax1.legend(loc=\"center right\")\n",
    "# ax1.grid(True)\n",
    "\n",
    "# # x축을 정수만 표시하도록 설정\n",
    "# ax1.xaxis.set_major_locator(MaxNLocator(integer=True))\n",
    "\n",
    "# # 두 번째 y축: Loss History\n",
    "# ax2 = ax1.twinx()\n",
    "# epochs, values = zip(*loss_history)\n",
    "# ax2.plot(epochs, values, label=\"AE Loss History\", color=\"red\", linestyle=\"--\")\n",
    "# ax2.set_ylabel(\"Loss\", color=\"red\")\n",
    "# ax2.tick_params(axis=\"y\", labelcolor=\"red\")\n",
    "# ax2.legend(loc=\"center left\")\n",
    "\n",
    "# # 제목 추가\n",
    "# plt.title(title, fontsize=10)\n",
    "# plt.tight_layout()\n",
    "# plt.savefig(f'net_save/{current_time}', dpi=300, bbox_inches=\"tight\")  # dpi=300은 고해상도로 저장, bbox_inches=\"tight\"는 여백 최소화\n",
    "# plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# 데이터셋\n",
    "filename_for_plot = [\n",
    "    \"Easy1_noise05\", \"Easy1_noise10\", \"Easy1_noise15\", \"Easy1_noise20\",\n",
    "    \"Easy2_noise05\", \"Easy2_noise10\", \"Easy2_noise15\", \"Easy2_noise20\",\n",
    "    \"Difficult1_noise05\", \"Difficult1_noise10\", \"Difficult1_noise15\", \"Difficult1_noise20\",\n",
    "    \"Difficult2_noise05\", \"Difficult2_noise10\", \"Difficult2_noise15\", \"Difficult2_noise20\"\n",
    "]\n",
    "\n",
    "# Accuracy 데이터\n",
    "ANN_conv_accracy_set= [0.97935368, 0.97682709, 0.97028784, 0.96461825, 0.97524752, 0.95803571\n",
    ", 0.95746785, 0.92628774, 0.965412,  0.97805344, 0.94869403, 0.92110454\n",
    ", 0.96784232, 0.97551789, 0.91538462, 0.84446478]\n",
    "SNN_fc_accuracy_set = [0.97114475, 0.97643732, 0.84400578, 0.78977821, 0.96616915, 0.92830189\n",
    ", 0.86176032, 0.31984948, 0.80635401, 0.88769531, 0.61003861, 0.60377358\n",
    ", 0.9592668,  0.92870999, 0.78333333, 0.67271859]\n",
    "SNN_conv_accuracy_set = [0.97445601, 0.97737983, 0.97063072, 0.95998071, 0.96268657, 0.90566038\n",
    ", 0.82545997, 0.68391345, 0.96116994, 0.92138672, 0.80694981, 0.49602781\n",
    ", 0.83604888, 0.70611057, 0.69313725, 0.5819398 ]\n",
    "\n",
    "# 평균 계산\n",
    "average_ANN_conv = np.mean(ANN_conv_accracy_set)\n",
    "average_SNN_fc = np.mean(SNN_fc_accuracy_set)\n",
    "average_SNN_conv = np.mean(SNN_conv_accuracy_set)\n",
    "\n",
    "# 데이터 준비\n",
    "accuracies = np.array([ANN_conv_accracy_set, SNN_fc_accuracy_set, SNN_conv_accuracy_set])\n",
    "averages = np.array([average_ANN_conv, average_SNN_fc, average_SNN_conv])\n",
    "\n",
    "# 시각화\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "\n",
    "# 각 모델의 정확도 플롯\n",
    "ax.plot(accuracies[0], label='ANN Conv', marker='o', linestyle='-', color='blue')\n",
    "ax.plot(accuracies[1], label='SNN FC', marker='o', linestyle='-', color='green')\n",
    "ax.plot(accuracies[2], label='SNN Conv', marker='o', linestyle='-', color='red')\n",
    "\n",
    "# 평균값 플롯\n",
    "ax.axhline(y=average_ANN_conv, color='blue', linestyle='--', label=f'Average ANN Conv: {average_ANN_conv:.3f}')\n",
    "ax.axhline(y=average_SNN_fc, color='green', linestyle='--', label=f'Average SNN FC: {average_SNN_fc:.3f}')\n",
    "ax.axhline(y=average_SNN_conv, color='red', linestyle='--', label=f'Average SNN Conv: {average_SNN_conv:.3f}')\n",
    "\n",
    "# 레이블 추가\n",
    "ax.set_xticks(np.arange(len(filename_for_plot)))\n",
    "ax.set_xticklabels(filename_for_plot, rotation=45, ha='right')\n",
    "ax.set_ylabel('Accuracy')\n",
    "ax.set_title('Accuracy Comparison of Models on Datasets')\n",
    "ax.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import matplotlib.pyplot as plt\n",
    "import os  # 파일 경로 처리를 위한 모듈\n",
    "\n",
    "# CSV 파일 경로\n",
    "# csv_file_path = \"/home/bhkim003/github_folder/ByeonghyeonKim/my_snn/ae_test_deprecated/250115/sweep0_vth_mul.csv\" # vth_mul해서 sweep 돌린거\n",
    "csv_file_path = \"/home/bhkim003/github_folder/ByeonghyeonKim/my_snn/ae_test_deprecated/250115/sweep1.csv\"  #vth_mul안한거\n",
    "\n",
    "# 결과를 저장할 리스트\n",
    "tuple_list = []\n",
    "\n",
    "# CSV 파일 읽기\n",
    "with open(csv_file_path, 'r') as file:\n",
    "    reader = csv.DictReader(file)\n",
    "    for row in reader:\n",
    "        try:\n",
    "            # v_threshold, TIME, v_reset, converted_k_means_acc 값을 가져와 튜플로 변환\n",
    "            v_threshold = float(row[\"v_threshold\"])\n",
    "            time = int(row[\"TIME\"])\n",
    "            v_reset = int(row[\"v_reset\"])\n",
    "            converted_k_means_acc = float(row[\"converted_k_means_acc\"]) if row[\"converted_k_means_acc\"] else None\n",
    "\n",
    "            # 튜플 형태로 추가 (값이 None일 경우 처리할 수도 있음)\n",
    "            tuple_list.append((v_threshold, time, v_reset, converted_k_means_acc))\n",
    "        except ValueError as e:\n",
    "            print(f\"Error processing row {row}: {e}\")\n",
    "\n",
    "# 데이터를 TIME 기준으로 정렬\n",
    "tuple_list.sort(key=lambda x: x[1])  # TIME을 기준으로 오름차순 정렬\n",
    "\n",
    "# reset 방식에 따라 데이터를 나누기\n",
    "soft_reset = [t for t in tuple_list if t[2] == 0]\n",
    "hard_reset = [t for t in tuple_list if t[2] == 10000]\n",
    "\n",
    "# reset 방식과 v_threshold에 따라 색상 설정\n",
    "def plot_data(data, label_prefix, marker):\n",
    "    for v_threshold in [1.0]:  # v_threshold 기준으로 제한\n",
    "        filtered_data = [(t[1], t[3]) for t in data if t[0] == v_threshold]\n",
    "        if filtered_data:  # 해당 v_threshold 데이터가 있을 경우만 플롯\n",
    "            times, accuracies = zip(*filtered_data)  # x축(TIME), y축(converted_k_means_acc)\n",
    "            \n",
    "            plt.plot(\n",
    "                times,\n",
    "                accuracies,\n",
    "                marker,\n",
    "                label=f\"{label_prefix}, v_threshold={v_threshold}\",\n",
    "                linestyle=\"--\",\n",
    "            )\n",
    "            # 각 점에 accuracy 표시\n",
    "            for time, acc in filtered_data:\n",
    "                if acc == None:\n",
    "                    continue\n",
    "                plt.text(time, acc, f\"{acc:.2f}\", fontsize=8, ha=\"right\")\n",
    "\n",
    "# 그래프 초기화\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "# soft_reset (v_reset=0) 데이터 플롯\n",
    "plot_data(soft_reset, \"Soft Reset\", \"o\")\n",
    "\n",
    "# hard_reset (v_reset=10000) 데이터 플롯\n",
    "plot_data(hard_reset, \"Hard Reset\", \"x\")\n",
    "\n",
    "# baseline accuracy 가로선 추가\n",
    "baseline_accuracy = 94.43\n",
    "plt.axhline(y=baseline_accuracy, color=\"red\", linestyle=\"-\", label=f\"Baseline Accuracy ({baseline_accuracy}%)\")\n",
    "# baseline 텍스트 추가\n",
    "plt.text(\n",
    "    2000,  # x축 위치 (그래프 오른쪽 끝)\n",
    "    baseline_accuracy + 0.4,  # y축 위치 (baseline 위 약간)\n",
    "    f\"ANN Baseline ({baseline_accuracy}%)\",\n",
    "    color=\"red\",\n",
    "    fontsize=10,\n",
    "    ha=\"center\",\n",
    ")\n",
    "\n",
    "# CSV 파일 이름 가져오기\n",
    "csv_file_name = os.path.basename(csv_file_path)\n",
    "\n",
    "# 그래프 세부 설정\n",
    "plt.title(f\"Converted SNN K-Means Accuracy vs TIME STEP - {csv_file_name}\")\n",
    "plt.xlabel(\"TIME STEP\")\n",
    "plt.ylabel(\"Converted K-Means Accuracy [%]\")\n",
    "plt.legend(loc=\"lower right\")  # 범례를 오른쪽 아래로 이동\n",
    "plt.grid(True)\n",
    "\n",
    "# 그래프 출력\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aedat2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
