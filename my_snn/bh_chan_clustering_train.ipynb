{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ssp.train.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x600 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import torch \n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import torch.optim as optim\n",
    "from scipy import io\n",
    "import itertools\n",
    "import math\n",
    "import datetime\n",
    "\n",
    "# my module import\n",
    "from modules import *\n",
    "\n",
    "# modules 폴더에 새모듈.py 만들면\n",
    "# modules/__init__py 파일에 form .새모듈 import * 하셈\n",
    "# 그리고 새모듈.py에서 from modules.새모듈 import * 하셈"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_path_ground_BH = '/data2/spike_sorting/quiroga/BH/'\n",
    "\n",
    "\n",
    "filename = [\"C_Easy1_noise005.mat\", \"C_Easy1_noise01.mat\", \"C_Easy1_noise015.mat\", \"C_Easy1_noise02.mat\",\n",
    "            \"C_Easy2_noise005.mat\", \"C_Easy2_noise01.mat\", \"C_Easy2_noise015.mat\", \"C_Easy2_noise02.mat\",\n",
    "            \"C_Difficult1_noise005.mat\", \"C_Difficult1_noise01.mat\", \"C_Difficult1_noise015.mat\", \"C_Difficult1_noise02.mat\",\n",
    "            \"C_Difficult2_noise005.mat\", \"C_Difficult2_noise01.mat\", \"C_Difficult2_noise015.mat\", \"C_Difficult2_noise02.mat\"]\n",
    "\n",
    "\n",
    "spike_tot = [\"BH_Spike_e1n005.npy\", \"BH_Spike_e1n010.npy\", \"BH_Spike_e1n015.npy\", \"BH_Spike_e1n020.npy\",\n",
    "            \"BH_Spike_e2n005.npy\", \"BH_Spike_e2n010.npy\", \"BH_Spike_e2n015.npy\", \"BH_Spike_e2n020.npy\",\n",
    "            \"BH_Spike_d1n005.npy\", \"BH_Spike_d1n010.npy\", \"BH_Spike_d1n015.npy\", \"BH_Spike_d1n020.npy\",\n",
    "            \"BH_Spike_d2n005.npy\", \"BH_Spike_d2n010.npy\", \"BH_Spike_d2n015.npy\", \"BH_Spike_d2n020.npy\"]\n",
    "\n",
    "label_tot = [\"BH_Label_e1n005.npy\", \"BH_Label_e1n010.npy\", \"BH_Label_e1n015.npy\", \"BH_Label_e1n020.npy\",\n",
    "            \"BH_Label_e2n005.npy\", \"BH_Label_e2n010.npy\", \"BH_Label_e2n015.npy\", \"BH_Label_e2n020.npy\",\n",
    "            \"BH_Label_d1n005.npy\", \"BH_Label_d1n010.npy\", \"BH_Label_d1n015.npy\", \"BH_Label_d1n020.npy\",\n",
    "            \"BH_Label_d2n005.npy\", \"BH_Label_d2n010.npy\", \"BH_Label_d2n015.npy\", \"BH_Label_d2n020.npy\"]\n",
    "\n",
    "template =  [\"BH_Spike_TEMPLATE_e1n005.npy\", \"BH_Spike_TEMPLATE_e1n010.npy\", \"BH_Spike_TEMPLATE_e1n015.npy\", \"BH_Spike_TEMPLATE_e1n020.npy\",\n",
    "             \"BH_Spike_TEMPLATE_e2n005.npy\", \"BH_Spike_TEMPLATE_e2n010.npy\", \"BH_Spike_TEMPLATE_e2n015.npy\", \"BH_Spike_TEMPLATE_e2n020.npy\",\n",
    "             \"BH_Spike_TEMPLATE_d1n005.npy\", \"BH_Spike_TEMPLATE_d1n010.npy\", \"BH_Spike_TEMPLATE_d1n015.npy\", \"BH_Spike_TEMPLATE_d1n020.npy\",\n",
    "             \"BH_Spike_TEMPLATE_d2n005.npy\", \"BH_Spike_TEMPLATE_d2n010.npy\", \"BH_Spike_TEMPLATE_d2n015.npy\", \"BH_Spike_TEMPLATE_d2n020.npy\"]\n",
    "\n",
    "AE_train_path_gt_detect = 'BH_quiroga_training_dataset_gt_detect.pt' \n",
    "AE_test_path_gt_detect = 'BH_quiroga_test_dataset_gt_detect.pt'\n",
    "\n",
    "AE_train_path_real_detect = 'BH_quiroga_training_dataset_real_detect.pt'\n",
    "AE_test_path_real_detect = 'BH_quiroga_test_dataset_real_detect.pt'\n",
    "\n",
    "\n",
    "\n",
    "# thr_tot = np.array([0.5, 0.5, 0.55, 0.7, 0.5, 0.5, 0.55, 0.7, 0.5, 0.5, 0.55, 0.7, 0.5, 0.5, 0.55, 0.7])\n",
    "cos_thr = np.array([0.95, 0.95, 0.95, 0.95, 0.95, 0.95, 0.95, 0.85, 0.95, 0.9, 0.8, 0.95, 0.95, 0.95, 0.95, 0.8])\n",
    "\n",
    "Conv_net = True\n",
    "SAE_net = True\n",
    "\n",
    "# hyperparameter\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\" \n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]= '3'\n",
    "dataset_num = 16\n",
    "spike_length = 50\n",
    "n_sample = spike_length\n",
    "num_cluster = 4  # 클러스터 수 설정 # 논문엔 4개라는데 여기서는 3개로 했네\n",
    "training_cycle = 2400 # 그 초기 몇개까지만 cluster update할지\n",
    "AE_train_data = AE_train_path_real_detect #AE_train_path_gt_detect #AE_train_path_real_detect\n",
    "AE_test_data = AE_test_path_real_detect #AE_test_path_gt_detect  #AE_test_path_real_detect\n",
    "\n",
    "\n",
    "batch_size = 32\n",
    "max_epoch = 7000\n",
    "learning_rate = 0.001\n",
    "normalize_on = False # True or False # 이거 별로 안 좋은 normalize같음 # 쓸 거면 다른 거 써라.\n",
    "need_bias = False\n",
    "# first_layer_no_train = False\n",
    "lif_add_at_first = False\n",
    "TIME = 10 # SAE일 때만 유효\n",
    "my_seed = 42\n",
    "\n",
    "\n",
    "seed_assign(my_seed)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "class spikedataset(Dataset):\n",
    "    def __init__(self, path, transform = None):    \n",
    "        self.transform = transform\n",
    "        self.spike = torch.load(path)\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        spike = self.spike[index]            \n",
    "        if self.transform is not None:\n",
    "            spike = self.transform(spike)\n",
    "        return spike\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.spike)\n",
    "\n",
    "train_dataset = spikedataset(my_path_ground_BH + AE_train_data)\n",
    "train_loader = DataLoader(dataset = train_dataset, batch_size = batch_size, shuffle = True)\n",
    "\n",
    "test_dataset = spikedataset(my_path_ground_BH + AE_test_data)\n",
    "test_loader = DataLoader(dataset = test_dataset, batch_size = batch_size, shuffle = False)\n",
    "\n",
    "\n",
    "class AE(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(AE, self).__init__()\n",
    "\n",
    "        # encoder\n",
    "        self.conv1 = nn.Conv1d(1, 32, 3, stride = 2, bias = False) # 24\n",
    "        self.conv2 = nn.Conv1d(32, 64, 3, stride = 2, bias = False) # 11\n",
    "        self.conv3 = nn.Conv1d(64, 96, 3, stride = 2, bias = False) # 4 # 병현: 여기 5인데?\n",
    "        self.fc1 = nn.Linear(96 * 5, 4, bias = False)\n",
    "        \n",
    "        # decoder\n",
    "        self.fc4 = nn.Linear(4, 5 * 96, bias = False)\n",
    "        self.deconv3 = nn.ConvTranspose1d(96, 64, 3, stride = 2, bias = False) #6 + 2 + 1= 9\n",
    "        self.deconv1 = nn.ConvTranspose1d(64, 32, 3, stride = 2, output_padding=1, bias = False) #16(9-1)*stride + 4(kernel-1) + 1 = 21\n",
    "        self.deconv2 = nn.ConvTranspose1d(32, 1, 3, stride = 2, output_padding=1, bias = False) #40 + 4 + 1 = 45\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        # encoder\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = F.relu(self.conv3(x))\n",
    "        x = x.view(-1, 96 * 5)\n",
    "        mid = self.fc1(x)\n",
    "        norm = torch.sqrt(torch.sum(torch.pow(mid, 2), dim = 1))\n",
    "        h = (mid.t()/(norm + 1e-12)).t()\n",
    "\n",
    "        # decoder\n",
    "        z = F.relu(self.fc4(h))\n",
    "        z = z.view(-1, 96, 5)\n",
    "        z = F.relu(self.deconv3(z))\n",
    "        z = F.relu(self.deconv1(z))\n",
    "        z = self.deconv2(z)\n",
    "\n",
    "        return h, z\n",
    "    \n",
    "\n",
    "\n",
    "# net = AE()\n",
    "# net = torch.nn.DataParallel(net)\n",
    "    \n",
    "# 모델 초기화\n",
    "if SAE_net == False:\n",
    "    if Conv_net == True:\n",
    "        net = Autoencoder_conv1(input_channels=1, input_length=n_sample, encoder_ch = [32, 64, 96], fc_dim = 4, padding = 0, stride = 2, kernel_size = 3, need_bias=need_bias)\n",
    "        net = torch.nn.DataParallel(net)\n",
    "    else:\n",
    "        net = Autoencoder_only_FC(encoder_ch=[96, 64, 32, 4], decoder_ch=[32,64,96,n_sample], n_sample=n_sample, need_bias=need_bias)\n",
    "        net = torch.nn.DataParallel(net)\n",
    "else:\n",
    "    if Conv_net == True: \n",
    "        net = SAE_conv1(input_channels=1, input_length=n_sample, encoder_ch = [32, 64, 96], fc_dim = 4, padding = 0, stride = 2, kernel_size = 3, \n",
    "                            synapse_fc_trace_const1=1, \n",
    "                            synapse_fc_trace_const2=0.5, #안씀 \n",
    "                            TIME=TIME, v_init=0.0, v_decay=0.5, v_threshold=0.75, v_reset=10000.0, \n",
    "                            sg_width=4.0, surrogate='sigmoid', BPTT_on=True, need_bias=need_bias, lif_add_at_first=lif_add_at_first)\n",
    "        net = torch.nn.DataParallel(net)\n",
    "    else:\n",
    "        net = SAE_fc_only(encoder_ch=[96, 64, 32, 4], \n",
    "                            decoder_ch=[32,64,96,n_sample], \n",
    "                            in_channels=n_sample, # in_channel 이 여기선 걍 lenght.\n",
    "                            synapse_fc_trace_const1=1,\n",
    "                            synapse_fc_trace_const2=0.5,  #안씀 \n",
    "                            TIME=TIME, v_init=0.0, v_decay=0.5, v_threshold=0.75, v_reset=10000.0, \n",
    "                            sg_width=4.0, surrogate='sigmoid', BPTT_on=True, need_bias=need_bias, lif_add_at_first=lif_add_at_first)\n",
    "        net = torch.nn.DataParallel(net)\n",
    "\n",
    "# net = torch.load('/home/bhkim003/github_folder/ByeonghyeonKim/my_snn/net_save/save_now_net_20241231_210505_671.pth')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataParallel(\n",
      "  (module): SAE_conv1(\n",
      "    (encoder): Sequential(\n",
      "      (0): SSBH_DimChanger_one_two()\n",
      "      (1): SSBH_DimChanger_for_unsuqeeze()\n",
      "      (2): SSBH_DimChanger_for_one_two_coupling()\n",
      "      (3): Conv1d(1, 32, kernel_size=(3,), stride=(2,), bias=False)\n",
      "      (4): SSBH_DimChanger_for_one_two_decoupling()\n",
      "      (5): LIF_layer()\n",
      "      (6): SSBH_DimChanger_for_one_two_coupling()\n",
      "      (7): Conv1d(32, 64, kernel_size=(3,), stride=(2,), bias=False)\n",
      "      (8): SSBH_DimChanger_for_one_two_decoupling()\n",
      "      (9): LIF_layer()\n",
      "      (10): SSBH_DimChanger_for_one_two_coupling()\n",
      "      (11): Conv1d(64, 96, kernel_size=(3,), stride=(2,), bias=False)\n",
      "      (12): SSBH_DimChanger_for_one_two_decoupling()\n",
      "      (13): LIF_layer()\n",
      "      (14): SSBH_DimChanger_for_one_two_coupling()\n",
      "      (15): SSBH_DimChanger_for_fc()\n",
      "      (16): Linear(in_features=480, out_features=4, bias=False)\n",
      "      (17): SSBH_L2NormLayer()\n",
      "      (18): SSBH_DimChanger_for_one_two_decoupling()\n",
      "      (19): SSBH_DimChanger_one_two()\n",
      "    )\n",
      "    (decoder): Sequential(\n",
      "      (0): SSBH_DimChanger_one_two()\n",
      "      (1): SSBH_DimChanger_for_one_two_coupling()\n",
      "      (2): Linear(in_features=4, out_features=480, bias=False)\n",
      "      (3): SSBH_DimChanger_for_one_two_decoupling()\n",
      "      (4): LIF_layer()\n",
      "      (5): SSBH_DimChanger_for_one_two_coupling()\n",
      "      (6): SSBH_DimChanger_for_conv1()\n",
      "      (7): SSBH_DimChanger_for_one_two_decoupling()\n",
      "      (8): SSBH_DimChanger_for_one_two_coupling()\n",
      "      (9): ConvTranspose1d(96, 64, kernel_size=(3,), stride=(2,), bias=False)\n",
      "      (10): SSBH_DimChanger_for_one_two_decoupling()\n",
      "      (11): LIF_layer()\n",
      "      (12): SSBH_DimChanger_for_one_two_coupling()\n",
      "      (13): ConvTranspose1d(64, 32, kernel_size=(3,), stride=(2,), output_padding=(1,), bias=False)\n",
      "      (14): SSBH_DimChanger_for_one_two_decoupling()\n",
      "      (15): LIF_layer()\n",
      "      (16): SSBH_DimChanger_for_one_two_coupling()\n",
      "      (17): ConvTranspose1d(32, 1, kernel_size=(3,), stride=(2,), output_padding=(1,), bias=False)\n",
      "      (18): SSBH_DimChanger_for_one_two_decoupling()\n",
      "      (19): SSBH_DimChanger_for_suqeeze()\n",
      "      (20): SSBH_DimChanger_one_two()\n",
      "    )\n",
      "  )\n",
      ")\n",
      "Device: cuda\n",
      "\n",
      "Start Training, current_time = 20250101_150337_682\n",
      "\n",
      "epoch-0 loss : 0.58012\n",
      "\n",
      "epoch-1 loss : 0.51236\n",
      "\n",
      "epoch-2 loss : 0.46988\n",
      "\n",
      "epoch-3 loss : 0.40455\n",
      "\n",
      "epoch-4 loss : 0.39277\n",
      "\n",
      "epoch-5 loss : 0.38767\n",
      "\n",
      "epoch-6 loss : 0.38342\n",
      "\n",
      "epoch-7 loss : 0.37925\n",
      "\n",
      "epoch-8 loss : 0.37600\n",
      "\n",
      "epoch-9 loss : 0.37974\n",
      "\n",
      "epoch-10 accuracy check\n",
      "cluster_accuracy_post_training_cycle_all_dataset [0.35816876 0.35561497 0.35004643 0.34729981 0.39306931 0.35535714\n",
      " 0.34124629 0.3365897  0.33265514 0.32729008 0.34235075 0.31360947\n",
      " 0.33609959 0.33709981 0.38269231 0.36047575]\n",
      "mean_cluster_accuracy_during_training_cycle : 35.09%, post_traincycle_acc : 34.81%, total_acc : 35.01%\n",
      "save model\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 34.81%\n",
      "\n",
      "epoch-10 loss : 0.38063\n",
      "\n",
      "epoch-11 loss : 0.37493\n",
      "\n",
      "epoch-12 loss : 0.37565\n",
      "\n",
      "epoch-13 loss : 0.37320\n",
      "\n",
      "epoch-14 loss : 0.37116\n",
      "\n",
      "epoch-15 loss : 0.37033\n",
      "\n",
      "epoch-16 loss : 0.36879\n",
      "\n",
      "epoch-17 loss : 0.37007\n",
      "\n",
      "epoch-18 loss : 0.36952\n",
      "\n",
      "epoch-19 loss : 0.36756\n",
      "\n",
      "epoch-20 loss : 0.36482\n",
      "\n",
      "epoch-21 loss : 0.36285\n",
      "\n",
      "epoch-22 loss : 0.36237\n",
      "\n",
      "epoch-23 loss : 0.36248\n",
      "\n",
      "epoch-24 loss : 0.36267\n",
      "\n",
      "epoch-25 loss : 0.36327\n",
      "\n",
      "epoch-26 loss : 0.36458\n",
      "\n",
      "epoch-27 loss : 0.36455\n",
      "\n",
      "epoch-28 loss : 0.36459\n",
      "\n",
      "epoch-29 loss : 0.36317\n",
      "\n",
      "epoch-30 loss : 0.36220\n",
      "\n",
      "epoch-31 loss : 0.36254\n",
      "\n",
      "epoch-32 loss : 0.36202\n",
      "\n",
      "epoch-33 loss : 0.36154\n",
      "\n",
      "epoch-34 loss : 0.36140\n",
      "\n",
      "epoch-35 loss : 0.36174\n"
     ]
    }
   ],
   "source": [
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "\n",
    "net = net.to(device)\n",
    "print(net)\n",
    "print('Device:',device)\n",
    "\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.SGD(net.parameters(), lr = learning_rate, momentum = 0.9)\n",
    "# optimizer = optim.Adam(net.parameters(), lr=learning_rate)\n",
    "\n",
    "loss_history = []\n",
    "mean_cluster_accuracy_during_training_cycle_all_dataset_history = []\n",
    "mean_cluster_accuracy_post_training_cycle_all_dataset_history = []\n",
    "mean_cluster_accuracy_total_all_dataset_history = []\n",
    "\n",
    "tau = np.zeros(num_cluster)\n",
    "\n",
    "current_time = datetime.datetime.now().strftime(\"%Y%m%d_%H%M%S\") + f\"_{str(int(datetime.datetime.now().microsecond / 1000)).zfill(3)}\"\n",
    "print(f\"\\nStart Training, current_time = {current_time}\")\n",
    "best_mean_cluster_accuracy_post_training_cycle_all_dataset = 0\n",
    "for epoch in range(max_epoch):\n",
    "    cluster_accuracy_during_training_cycle_all_dataset = np.zeros(dataset_num)\n",
    "    cluster_accuracy_post_training_cycle_all_dataset = np.zeros(dataset_num)\n",
    "    cluster_accuracy_total_all_dataset = np.zeros(dataset_num)    \n",
    "    \n",
    "    if(epoch % 50 == 10): \n",
    "        print(f'\\nepoch-{epoch} accuracy check')\n",
    "        for ds in range(dataset_num):\n",
    "            # print('\\n', spike_tot[ds])\n",
    "\n",
    "            spike_template = np.load(my_path_ground_BH + template[ds])\n",
    "            spike = np.load(my_path_ground_BH + spike_tot[ds])\n",
    "            label = np.load(my_path_ground_BH + label_tot[ds])\n",
    "            \n",
    "            Cluster = np.zeros((num_cluster, 4))\n",
    "            assert Cluster.shape[-1] == 4, '이거 hidden dim 4 아니게 할 거면 잘 바꿔라'\n",
    "            \n",
    "            net.eval()\n",
    "            with torch.no_grad():\n",
    "                for i in range(num_cluster):\n",
    "                    spike_torch = torch.from_numpy(spike_template[i, :])\n",
    "                    spike_torch = spike_torch.float().to(device)\n",
    "                    if 'SAE' in net.module.__class__.__name__:\n",
    "                        spike_torch = spike_torch.unsqueeze(-1).repeat(1, 1, TIME).permute(0,2,1) # (batch, time, feature)로 변환\n",
    "                    else:\n",
    "                        spike_torch = spike_torch.unsqueeze(0)\n",
    "                    inner_inf = net.module.encoder(spike_torch)\n",
    "                    # if 'SAE' in net.module.__class__.__name__:\n",
    "                    #     tensors = [inner_inf[0][i] for i in range(TIME)] \n",
    "                    #     all_equal = all(torch.equal(tensors[0], t) for t in tensors)\n",
    "                    #     print(all_equal, inner_inf)\n",
    "\n",
    "                        \n",
    "\n",
    "                    if 'SAE' in net.module.__class__.__name__:\n",
    "                        inner_inf = inner_inf.mean(dim=1)# Time 방향으로 평균\n",
    "                    Cluster[i, :] = inner_inf.cpu().detach().numpy()\n",
    "\n",
    "            spike_hidden = np.zeros((len(spike), 4))\n",
    "            net.eval()\n",
    "            with torch.no_grad():\n",
    "                for i in range(len(spike)):\n",
    "                    spike_torch = torch.from_numpy(spike[i, :])\n",
    "                    spike_torch = spike_torch.float().to(device)\n",
    "                    if 'SAE' in net.module.__class__.__name__:\n",
    "                        spike_torch = spike_torch.unsqueeze(-1).repeat(1, 1, TIME).permute(0,2,1) # (batch, time, feature)로 변환\n",
    "                    else:\n",
    "                        spike_torch = spike_torch.unsqueeze(0)\n",
    "                    inner_inf = net.module.encoder(spike_torch)\n",
    "                    if 'SAE' in net.module.__class__.__name__:\n",
    "                        inner_inf = inner_inf.mean(dim=1)# Time 방향으로 평균\n",
    "                    spike_hidden[i, :] = inner_inf.cpu().detach().numpy()\n",
    "                \n",
    "            spike_id = np.zeros(len(spike))\n",
    "\n",
    "\n",
    "            distance_sm = np.zeros(num_cluster)\n",
    "            tau = np.zeros(num_cluster)\n",
    "            \n",
    "            for spike_index in range(len(spike)): \n",
    "                for q in range(num_cluster):\n",
    "                    tau[q] = np.dot(spike_hidden[spike_index, :], Cluster[q, :]) / (np.linalg.norm(spike_hidden[spike_index, :])) # 이거 l2norm 거쳐서 나온 거니까 분모 1임.\n",
    "                    denominator =  np.linalg.norm(spike_hidden[spike_index, :]) + np.linalg.norm(Cluster[q, :]) + 1e-12\n",
    "                    tau[q] = tau[q] / denominator\n",
    "                    # print(np.linalg.norm(spike_hidden[spike_index, :]))\n",
    "                    # print(np.linalg.norm(Cluster[q, :]))\n",
    "                # tau = np.dot(Cluster, spike_hidden[spike_index, :]) # 이거 l2norm 거쳐서 나온 거니까 분모 1임.\n",
    "\n",
    "                for i in range(num_cluster): # l2 distance\n",
    "                    distance_sm[i] = np.sum(np.power(np.abs(Cluster[i] - spike_hidden[spike_index, :]), 2))\n",
    "\n",
    "                m = np.argmin(distance_sm)\n",
    "                spike_id[spike_index] = m + 1\n",
    "                if(np.max(tau) >= cos_thr[ds] and spike_index < training_cycle): # 원래 1400 아니냐?\n",
    "                    Cluster[m] = (Cluster[m] * 15 + spike_hidden[spike_index, :])/16\n",
    "                            \n",
    "            # spike id 분포 확인하기\n",
    "            # unique_elements, counts = np.unique(spike_id, return_counts=True)\n",
    "            # print(\"Unique elements:\", unique_elements)\n",
    "            # print(\"Counts:\", counts)\n",
    "\n",
    "            cluster_accuracy_during_training_cycle = np.zeros(math.factorial(num_cluster))\n",
    "            cluster_accuracy_post_training_cycle = np.zeros(math.factorial(num_cluster))\n",
    "            cluster_accuracy_total = np.zeros(math.factorial(num_cluster))\n",
    "            \n",
    "            label_converter_ground = list(range(1, num_cluster + 1)) # [1, 2, 3, 4] 생성\n",
    "            label_converter_permutations = list(itertools.permutations(label_converter_ground)) # 모든 순열 구하기\n",
    "            perm_i = 0\n",
    "            for perm in label_converter_permutations:\n",
    "                label_converter = list(perm)\n",
    "                # print(label_converter)\n",
    "                correct_during_training_cycle = 0\n",
    "                correct_post_training_cycle = 0\n",
    "\n",
    "                assert len(spike_id) == len(label), 'spike_id랑 label 길이 같아야 됨.'\n",
    "                for i in range(len(spike_id)):\n",
    "                    if(label_converter[int(spike_id[i]-1)] == label[i]):\n",
    "                        if i < training_cycle:\n",
    "                            correct_during_training_cycle += 1\n",
    "                        else:\n",
    "                            correct_post_training_cycle += 1\n",
    "\n",
    "                cluster_accuracy_during_training_cycle[perm_i] = correct_during_training_cycle/training_cycle\n",
    "                cluster_accuracy_post_training_cycle[perm_i] = correct_post_training_cycle/(len(spike_id)-training_cycle)\n",
    "                cluster_accuracy_total[perm_i] = (correct_during_training_cycle+correct_post_training_cycle)/(len(spike_id))\n",
    "                perm_i += 1\n",
    "\n",
    "            cluster_accuracy_during_training_cycle_all_dataset[ds] = np.max(cluster_accuracy_during_training_cycle)\n",
    "            cluster_accuracy_post_training_cycle_all_dataset[ds] = cluster_accuracy_post_training_cycle[np.argmax(cluster_accuracy_during_training_cycle)]\n",
    "            cluster_accuracy_total_all_dataset[ds] = cluster_accuracy_total[np.argmax(cluster_accuracy_during_training_cycle)]\n",
    "\n",
    "        print('cluster_accuracy_post_training_cycle_all_dataset', cluster_accuracy_post_training_cycle_all_dataset)\n",
    "\n",
    "        mean_cluster_accuracy_during_training_cycle_all_dataset = np.mean(cluster_accuracy_during_training_cycle_all_dataset)\n",
    "        mean_cluster_accuracy_post_training_cycle_all_dataset = np.mean(cluster_accuracy_post_training_cycle_all_dataset)\n",
    "        mean_cluster_accuracy_total_all_dataset = np.mean(cluster_accuracy_total_all_dataset)\n",
    "        \n",
    "        mean_cluster_accuracy_during_training_cycle_all_dataset_history.append((epoch, mean_cluster_accuracy_during_training_cycle_all_dataset*100))\n",
    "        mean_cluster_accuracy_post_training_cycle_all_dataset_history.append((epoch, mean_cluster_accuracy_post_training_cycle_all_dataset*100))\n",
    "        mean_cluster_accuracy_total_all_dataset_history.append((epoch, mean_cluster_accuracy_total_all_dataset*100))\n",
    "        print(f\"mean_cluster_accuracy_during_training_cycle : {mean_cluster_accuracy_during_training_cycle_all_dataset*100:.2f}%, post_traincycle_acc : {mean_cluster_accuracy_post_training_cycle_all_dataset*100:.2f}%, total_acc : {mean_cluster_accuracy_total_all_dataset*100:.2f}%\")\n",
    "\n",
    "        if mean_cluster_accuracy_post_training_cycle_all_dataset > best_mean_cluster_accuracy_post_training_cycle_all_dataset:\n",
    "            torch.save(net, f\"net_save/save_now_net_{current_time}.pth\")\n",
    "            print('save model')\n",
    "            best_mean_cluster_accuracy_post_training_cycle_all_dataset = mean_cluster_accuracy_post_training_cycle_all_dataset\n",
    "        print(f\"best_mean_cluster_accuracy_post_training_cycle_all_dataset : {best_mean_cluster_accuracy_post_training_cycle_all_dataset*100:.2f}%\")\n",
    "\n",
    "\n",
    "    running_loss = 0.0\n",
    "    net.train()\n",
    "    for data in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        spike = data\n",
    "        spike = spike.to(device)\n",
    "        if 'SAE' in net.module.__class__.__name__:\n",
    "            spike = spike.unsqueeze(-1).repeat(1, 1, TIME).permute(0,2,1) # (batch, time, feature)로 변환\n",
    "        spike_class = net(spike)\n",
    "\n",
    "        # if 'SAE' in net.module.__class__.__name__:\n",
    "        #     spike = spike.mean(dim=1)# Time 방향으로 평균\n",
    "        #     spike_class = spike_class.mean(dim=1)# Time 방향으로 평균\n",
    "\n",
    "        if 'SAE' in net.module.__class__.__name__:\n",
    "            loss1 = criterion(spike_class[:, :, 5:25], spike[:, :, 5:25])\n",
    "            loss2 = criterion(spike_class[:, :, 0:5], spike[:, :, 0:5])\n",
    "            loss3 = criterion(spike_class[:, :, 25:spike_length], spike[:, :, 25:spike_length])\n",
    "        else:\n",
    "            loss1 = criterion(spike_class[:, 5:25], spike[:, 5:25])\n",
    "            loss2 = criterion(spike_class[:, 0:5], spike[:, 0:5])\n",
    "            loss3 = criterion(spike_class[:, 25:spike_length], spike[:, 25:spike_length])\n",
    "\n",
    "        loss = loss1 * 2.125 + (loss2 + loss3)/4\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "    avg_loss = running_loss / len(train_loader)\n",
    "    loss_history.append((epoch, avg_loss))\n",
    "    print(f'\\nepoch-{epoch} loss : {avg_loss:.5f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.ticker import MaxNLocator\n",
    "\n",
    "# 설정 정보 제목 작성\n",
    "title = (\n",
    "    f\"Dataset Num: {dataset_num}, Conv {Conv_net}, SAE {SAE_net}, Current time {current_time}, Spike Length: {spike_length}, Num Cluster: {num_cluster}, \"\n",
    "    f\"Training Cycle: {training_cycle}, Batch Size: {batch_size}, Max Epoch: {max_epoch}, \\n\"\n",
    "    f\"Learning Rate: {learning_rate}, Input Normalize: {normalize_on}, Need Bias: {need_bias}, \"\n",
    "    f\"LIF Add at First: {lif_add_at_first}, TIME: {TIME}, Seed: {my_seed}, Data: {AE_train_data}, Best ACC: {best_mean_cluster_accuracy_post_training_cycle_all_dataset*100:.2f}%\"\n",
    ")\n",
    "\n",
    "# 데이터 리스트와 라벨 설정 (Loss 제외)\n",
    "data_list = [\n",
    "    (\"Mean Cluster Accuracy (During Training Cycle)\", mean_cluster_accuracy_during_training_cycle_all_dataset_history),\n",
    "    (\"Mean Cluster Accuracy (Post Training Cycle)\", mean_cluster_accuracy_post_training_cycle_all_dataset_history),\n",
    "    (\"Mean Cluster Accuracy (Total)\", mean_cluster_accuracy_total_all_dataset_history),\n",
    "]\n",
    "\n",
    "# 플롯 생성\n",
    "fig, ax1 = plt.subplots(figsize=(12, 8))\n",
    "\n",
    "# 첫 번째 y축: Accuracy 관련 데이터\n",
    "for label, data in data_list:\n",
    "    epochs, values = zip(*data)  # epoch, value 분리\n",
    "    ax1.plot(epochs, values, label=label)\n",
    "\n",
    "ax1.set_xlabel(\"Epoch\")\n",
    "ax1.set_ylabel(\"Clurstering Accuracy [%]\", color=\"blue\")\n",
    "ax1.tick_params(axis=\"y\", labelcolor=\"blue\")\n",
    "ax1.legend(loc=\"center right\")\n",
    "ax1.grid(True)\n",
    "\n",
    "# x축을 정수만 표시하도록 설정\n",
    "ax1.xaxis.set_major_locator(MaxNLocator(integer=True))\n",
    "\n",
    "# 두 번째 y축: Loss History\n",
    "ax2 = ax1.twinx()\n",
    "epochs, values = zip(*loss_history)\n",
    "ax2.plot(epochs, values, label=\"AE Loss History\", color=\"red\", linestyle=\"--\")\n",
    "ax2.set_ylabel(\"Loss\", color=\"red\")\n",
    "ax2.tick_params(axis=\"y\", labelcolor=\"red\")\n",
    "ax2.legend(loc=\"center left\")\n",
    "\n",
    "# 제목 추가\n",
    "plt.title(title, fontsize=10)\n",
    "plt.tight_layout()\n",
    "plt.savefig(f'net_save/{current_time}', dpi=300, bbox_inches=\"tight\")  # dpi=300은 고해상도로 저장, bbox_inches=\"tight\"는 여백 최소화\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aedat2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
