{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ssp.train.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x600 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import torch \n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import torch.optim as optim\n",
    "from scipy import io\n",
    "import itertools\n",
    "import math\n",
    "import datetime\n",
    "\n",
    "# my module import\n",
    "from modules import *\n",
    "\n",
    "# modules 폴더에 새모듈.py 만들면\n",
    "# modules/__init__py 파일에 form .새모듈 import * 하셈\n",
    "# 그리고 새모듈.py에서 from modules.새모듈 import * 하셈"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_path_ground_BH = '/data2/spike_sorting/quiroga/BH/'\n",
    "\n",
    "\n",
    "filename = [\"C_Easy1_noise005.mat\", \"C_Easy1_noise01.mat\", \"C_Easy1_noise015.mat\", \"C_Easy1_noise02.mat\",\n",
    "            \"C_Easy2_noise005.mat\", \"C_Easy2_noise01.mat\", \"C_Easy2_noise015.mat\", \"C_Easy2_noise02.mat\",\n",
    "            \"C_Difficult1_noise005.mat\", \"C_Difficult1_noise01.mat\", \"C_Difficult1_noise015.mat\", \"C_Difficult1_noise02.mat\",\n",
    "            \"C_Difficult2_noise005.mat\", \"C_Difficult2_noise01.mat\", \"C_Difficult2_noise015.mat\", \"C_Difficult2_noise02.mat\"]\n",
    "\n",
    "\n",
    "spike_tot = [\"BH_Spike_e1n005.npy\", \"BH_Spike_e1n010.npy\", \"BH_Spike_e1n015.npy\", \"BH_Spike_e1n020.npy\",\n",
    "            \"BH_Spike_e2n005.npy\", \"BH_Spike_e2n010.npy\", \"BH_Spike_e2n015.npy\", \"BH_Spike_e2n020.npy\",\n",
    "            \"BH_Spike_d1n005.npy\", \"BH_Spike_d1n010.npy\", \"BH_Spike_d1n015.npy\", \"BH_Spike_d1n020.npy\",\n",
    "            \"BH_Spike_d2n005.npy\", \"BH_Spike_d2n010.npy\", \"BH_Spike_d2n015.npy\", \"BH_Spike_d2n020.npy\"]\n",
    "\n",
    "label_tot = [\"BH_Label_e1n005.npy\", \"BH_Label_e1n010.npy\", \"BH_Label_e1n015.npy\", \"BH_Label_e1n020.npy\",\n",
    "            \"BH_Label_e2n005.npy\", \"BH_Label_e2n010.npy\", \"BH_Label_e2n015.npy\", \"BH_Label_e2n020.npy\",\n",
    "            \"BH_Label_d1n005.npy\", \"BH_Label_d1n010.npy\", \"BH_Label_d1n015.npy\", \"BH_Label_d1n020.npy\",\n",
    "            \"BH_Label_d2n005.npy\", \"BH_Label_d2n010.npy\", \"BH_Label_d2n015.npy\", \"BH_Label_d2n020.npy\"]\n",
    "\n",
    "template =  [\"BH_Spike_TEMPLATE_e1n005.npy\", \"BH_Spike_TEMPLATE_e1n010.npy\", \"BH_Spike_TEMPLATE_e1n015.npy\", \"BH_Spike_TEMPLATE_e1n020.npy\",\n",
    "             \"BH_Spike_TEMPLATE_e2n005.npy\", \"BH_Spike_TEMPLATE_e2n010.npy\", \"BH_Spike_TEMPLATE_e2n015.npy\", \"BH_Spike_TEMPLATE_e2n020.npy\",\n",
    "             \"BH_Spike_TEMPLATE_d1n005.npy\", \"BH_Spike_TEMPLATE_d1n010.npy\", \"BH_Spike_TEMPLATE_d1n015.npy\", \"BH_Spike_TEMPLATE_d1n020.npy\",\n",
    "             \"BH_Spike_TEMPLATE_d2n005.npy\", \"BH_Spike_TEMPLATE_d2n010.npy\", \"BH_Spike_TEMPLATE_d2n015.npy\", \"BH_Spike_TEMPLATE_d2n020.npy\"]\n",
    "\n",
    "AE_train_path_gt_detect = 'BH_quiroga_training_dataset_gt_detect.pt' \n",
    "AE_test_path_gt_detect = 'BH_quiroga_test_dataset_gt_detect.pt'\n",
    "\n",
    "AE_train_path_real_detect = 'BH_quiroga_training_dataset_real_detect.pt'\n",
    "AE_test_path_real_detect = 'BH_quiroga_test_dataset_real_detect.pt'\n",
    "\n",
    "\n",
    "\n",
    "# thr_tot = np.array([0.5, 0.5, 0.55, 0.7, 0.5, 0.5, 0.55, 0.7, 0.5, 0.5, 0.55, 0.7, 0.5, 0.5, 0.55, 0.7])\n",
    "cos_thr = np.array([0.95, 0.95, 0.95, 0.95, 0.95, 0.95, 0.95, 0.85, 0.95, 0.9, 0.8, 0.95, 0.95, 0.95, 0.95, 0.8])\n",
    "\n",
    "Conv_net = True\n",
    "SAE_net = True\n",
    "\n",
    "# hyperparameter\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\" \n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]= '3'\n",
    "dataset_num = 16\n",
    "spike_length = 50\n",
    "n_sample = spike_length\n",
    "num_cluster = 4  # 클러스터 수 설정 # 논문엔 4개라는데 여기서는 3개로 했네\n",
    "training_cycle = 2400 # 그 초기 몇개까지만 cluster update할지\n",
    "AE_train_data = AE_train_path_real_detect #AE_train_path_gt_detect #AE_train_path_real_detect\n",
    "AE_test_data = AE_test_path_real_detect #AE_test_path_gt_detect  #AE_test_path_real_detect\n",
    "\n",
    "\n",
    "batch_size = 32\n",
    "max_epoch = 7000\n",
    "learning_rate = 0.001\n",
    "normalize_on = False # True or False # 이거 별로 안 좋은 normalize같음 # 쓸 거면 다른 거 써라.\n",
    "need_bias = False\n",
    "# first_layer_no_train = False\n",
    "lif_add_at_first = False\n",
    "my_seed = 42\n",
    "\n",
    "TIME = 10 # SAE일 때만 유효\n",
    "v_decay = 0.5\n",
    "v_threshold = 0.5\n",
    "v_reset = 10000.0 # 10000이상 일 시 hard reset\n",
    "BPTT_on = True\n",
    "\n",
    "SAE_hidden_nomean = True\n",
    "\n",
    "seed_assign(my_seed)\n",
    "\n",
    "class spikedataset(Dataset):\n",
    "    def __init__(self, path, transform = None):    \n",
    "        self.transform = transform\n",
    "        self.spike = torch.load(path)\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        spike = self.spike[index]            \n",
    "        if self.transform is not None:\n",
    "            spike = self.transform(spike)\n",
    "        return spike\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.spike)\n",
    "\n",
    "train_dataset = spikedataset(my_path_ground_BH + AE_train_data)\n",
    "train_loader = DataLoader(dataset = train_dataset, batch_size = batch_size, shuffle = True)\n",
    "\n",
    "test_dataset = spikedataset(my_path_ground_BH + AE_test_data)\n",
    "test_loader = DataLoader(dataset = test_dataset, batch_size = batch_size, shuffle = False)\n",
    "\n",
    "\n",
    "\n",
    "# 모델 초기화\n",
    "if SAE_net == False:\n",
    "    if Conv_net == True:\n",
    "        net = Autoencoder_conv1(input_channels=1, input_length=n_sample, encoder_ch = [32, 64, 96], fc_dim = 4, padding = 0, stride = 2, kernel_size = 3, need_bias=need_bias)\n",
    "        net = torch.nn.DataParallel(net)\n",
    "    else:\n",
    "        net = Autoencoder_only_FC(encoder_ch=[96, 64, 32, 4], decoder_ch=[32,64,96,n_sample], n_sample=n_sample, need_bias=need_bias)\n",
    "        net = torch.nn.DataParallel(net)\n",
    "else:\n",
    "    if Conv_net == True: \n",
    "        net = SAE_conv1(input_channels=1, input_length=n_sample, encoder_ch = [32, 64, 96], fc_dim = 4, padding = 0, stride = 2, kernel_size = 3, \n",
    "                            synapse_fc_trace_const1=1, \n",
    "                            synapse_fc_trace_const2=v_decay, #안씀 \n",
    "                            TIME=TIME, v_init=0.0, v_decay=v_decay, v_threshold=v_threshold, v_reset=v_reset, \n",
    "                            sg_width=4.0, surrogate='sigmoid', BPTT_on=BPTT_on, need_bias=need_bias, lif_add_at_first=lif_add_at_first)\n",
    "        net = torch.nn.DataParallel(net)\n",
    "    else:\n",
    "        net = SAE_fc_only(encoder_ch=[96, 64, 32, 4], \n",
    "                            decoder_ch=[32,64,96,n_sample], \n",
    "                            in_channels=n_sample, # in_channel 이 여기선 걍 lenght.\n",
    "                            synapse_fc_trace_const1=1,\n",
    "                            synapse_fc_trace_const2=v_decay,  #안씀 \n",
    "                            TIME=TIME, v_init=0.0, v_decay=v_decay, v_threshold=v_threshold, v_reset=v_reset, \n",
    "                            sg_width=4.0, surrogate='sigmoid', BPTT_on=BPTT_on, need_bias=need_bias, lif_add_at_first=lif_add_at_first)\n",
    "        net = torch.nn.DataParallel(net)\n",
    "\n",
    "# net = torch.load('/home/bhkim003/github_folder/ByeonghyeonKim/my_snn/net_save/save_now_net_AE_re_e7000.pth')\n",
    "# net = torch.load('/home/bhkim003/github_folder/ByeonghyeonKim/my_snn/net_save/save_now_net_20250101_210938_786.pth')\n",
    "# load했으면 torch.nn.DataParallel 하지마"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataParallel(\n",
      "  (module): SAE_conv1(\n",
      "    (encoder): Sequential(\n",
      "      (0): SSBH_DimChanger_one_two()\n",
      "      (1): SSBH_DimChanger_for_unsuqeeze()\n",
      "      (2): SSBH_DimChanger_for_one_two_coupling()\n",
      "      (3): Conv1d(1, 32, kernel_size=(3,), stride=(2,), bias=False)\n",
      "      (4): SSBH_DimChanger_for_one_two_decoupling()\n",
      "      (5): LIF_layer()\n",
      "      (6): SSBH_DimChanger_for_one_two_coupling()\n",
      "      (7): Conv1d(32, 64, kernel_size=(3,), stride=(2,), bias=False)\n",
      "      (8): SSBH_DimChanger_for_one_two_decoupling()\n",
      "      (9): LIF_layer()\n",
      "      (10): SSBH_DimChanger_for_one_two_coupling()\n",
      "      (11): Conv1d(64, 96, kernel_size=(3,), stride=(2,), bias=False)\n",
      "      (12): SSBH_DimChanger_for_one_two_decoupling()\n",
      "      (13): LIF_layer()\n",
      "      (14): SSBH_DimChanger_for_one_two_coupling()\n",
      "      (15): SSBH_DimChanger_for_fc()\n",
      "      (16): Linear(in_features=480, out_features=4, bias=False)\n",
      "      (17): SSBH_L2NormLayer()\n",
      "      (18): SSBH_DimChanger_for_one_two_decoupling()\n",
      "      (19): SSBH_DimChanger_one_two()\n",
      "    )\n",
      "    (decoder): Sequential(\n",
      "      (0): SSBH_DimChanger_one_two()\n",
      "      (1): SSBH_DimChanger_for_one_two_coupling()\n",
      "      (2): Linear(in_features=4, out_features=480, bias=False)\n",
      "      (3): SSBH_DimChanger_for_one_two_decoupling()\n",
      "      (4): LIF_layer()\n",
      "      (5): SSBH_DimChanger_for_one_two_coupling()\n",
      "      (6): SSBH_DimChanger_for_conv1()\n",
      "      (7): SSBH_DimChanger_for_one_two_decoupling()\n",
      "      (8): SSBH_DimChanger_for_one_two_coupling()\n",
      "      (9): ConvTranspose1d(96, 64, kernel_size=(3,), stride=(2,), bias=False)\n",
      "      (10): SSBH_DimChanger_for_one_two_decoupling()\n",
      "      (11): LIF_layer()\n",
      "      (12): SSBH_DimChanger_for_one_two_coupling()\n",
      "      (13): ConvTranspose1d(64, 32, kernel_size=(3,), stride=(2,), output_padding=(1,), bias=False)\n",
      "      (14): SSBH_DimChanger_for_one_two_decoupling()\n",
      "      (15): LIF_layer()\n",
      "      (16): SSBH_DimChanger_for_one_two_coupling()\n",
      "      (17): ConvTranspose1d(32, 1, kernel_size=(3,), stride=(2,), output_padding=(1,), bias=False)\n",
      "      (18): SSBH_DimChanger_for_one_two_decoupling()\n",
      "      (19): SSBH_DimChanger_for_suqeeze()\n",
      "      (20): SSBH_DimChanger_one_two()\n",
      "    )\n",
      "  )\n",
      ")\n",
      "Device: cuda\n",
      "\n",
      "Start Training, current_time = 20250101_221644_793\n",
      "\n",
      "epoch-0 accuracy check\n"
     ]
    }
   ],
   "source": [
    "if SAE_net == True:\n",
    "    assert 'SAE' in net.module.__class__.__name__\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "\n",
    "net = net.to(device)\n",
    "print(net)\n",
    "print('Device:',device)\n",
    "\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.SGD(net.parameters(), lr = learning_rate, momentum = 0.9)\n",
    "# optimizer = optim.Adam(net.parameters(), lr=learning_rate)\n",
    "\n",
    "loss_history = []\n",
    "mean_cluster_accuracy_during_training_cycle_all_dataset_history = []\n",
    "mean_cluster_accuracy_post_training_cycle_all_dataset_history = []\n",
    "mean_cluster_accuracy_total_all_dataset_history = []\n",
    "\n",
    "tau = np.zeros(num_cluster)\n",
    "\n",
    "current_time = datetime.datetime.now().strftime(\"%Y%m%d_%H%M%S\") + f\"_{str(int(datetime.datetime.now().microsecond / 1000)).zfill(3)}\"\n",
    "print(f\"\\nStart Training, current_time = {current_time}\")\n",
    "best_mean_cluster_accuracy_post_training_cycle_all_dataset = 0\n",
    "for epoch in range(max_epoch):\n",
    "    cluster_accuracy_during_training_cycle_all_dataset = np.zeros(dataset_num)\n",
    "    cluster_accuracy_post_training_cycle_all_dataset = np.zeros(dataset_num)\n",
    "    cluster_accuracy_total_all_dataset = np.zeros(dataset_num)    \n",
    "    \n",
    "    if(epoch % 50 == 0): \n",
    "        print(f'\\nepoch-{epoch} accuracy check')\n",
    "        for ds in range(dataset_num):\n",
    "            # print('\\n', spike_tot[ds])\n",
    "\n",
    "            spike_template = np.load(my_path_ground_BH + template[ds])\n",
    "            spike = np.load(my_path_ground_BH + spike_tot[ds])\n",
    "            label = np.load(my_path_ground_BH + label_tot[ds])\n",
    "            \n",
    "            hidden_size = 4*TIME if 'SAE' in net.module.__class__.__name__ and SAE_hidden_nomean == True else 4\n",
    "\n",
    "            Cluster = np.zeros((num_cluster, hidden_size))\n",
    "            assert Cluster.shape[-1] == hidden_size, '이거 hidden dim 4 아니게 할 거면 잘 바꿔라'\n",
    "            \n",
    "            net.eval()\n",
    "            with torch.no_grad():\n",
    "                for i in range(num_cluster):\n",
    "                    spike_torch = torch.from_numpy(spike_template[i, :])\n",
    "                    spike_torch = spike_torch.float().to(device)\n",
    "                    if 'SAE' in net.module.__class__.__name__:\n",
    "                        spike_torch = spike_torch.unsqueeze(-1).repeat(1, 1, TIME).permute(0,2,1) # (batch, time, feature)로 변환\n",
    "                    else:\n",
    "                        spike_torch = spike_torch.unsqueeze(0)\n",
    "                    inner_inf = net.module.encoder(spike_torch)\n",
    "                    # if 'SAE' in net.module.__class__.__name__:\n",
    "                    #     tensors = [inner_inf[0][i] for i in range(TIME)] \n",
    "                    #     all_equal = all(torch.equal(tensors[0], t) for t in tensors)\n",
    "                    #     print(all_equal, inner_inf)\n",
    "\n",
    "                    if 'SAE' in net.module.__class__.__name__:\n",
    "                        if SAE_hidden_nomean == True:\n",
    "                            inner_inf = inner_inf.view(1,-1)# 펼치기\n",
    "                        else:\n",
    "                            inner_inf = inner_inf.mean(dim=1)# Time 방향으로 평균\n",
    "                    Cluster[i, :] = inner_inf.cpu().detach().numpy()\n",
    "\n",
    "            spike_hidden = np.zeros((len(spike), hidden_size))\n",
    "            net.eval()\n",
    "            with torch.no_grad():\n",
    "                for i in range(len(spike)):\n",
    "                    spike_torch = torch.from_numpy(spike[i, :])\n",
    "                    spike_torch = spike_torch.float().to(device)\n",
    "                    if 'SAE' in net.module.__class__.__name__:\n",
    "                        spike_torch = spike_torch.unsqueeze(-1).repeat(1, 1, TIME).permute(0,2,1) # (batch, time, feature)로 변환\n",
    "                    else:\n",
    "                        spike_torch = spike_torch.unsqueeze(0)\n",
    "                    inner_inf = net.module.encoder(spike_torch)\n",
    "                    if 'SAE' in net.module.__class__.__name__:\n",
    "                        if SAE_hidden_nomean == True:\n",
    "                            inner_inf = inner_inf.view(1,-1)# 펼치기\n",
    "                        else:\n",
    "                            inner_inf = inner_inf.mean(dim=1)# Time 방향으로 평균\n",
    "                    spike_hidden[i, :] = inner_inf.cpu().detach().numpy()\n",
    "                \n",
    "            spike_id = np.zeros(len(spike))\n",
    "\n",
    "\n",
    "            distance_sm = np.zeros(num_cluster)\n",
    "            tau = np.zeros(num_cluster)\n",
    "            \n",
    "            for spike_index in range(len(spike)): \n",
    "                for q in range(num_cluster):\n",
    "                    tau[q] = np.dot(spike_hidden[spike_index, :], Cluster[q, :]) # 이거 l2norm 거쳐서 나온 거니까 분모 1임.\n",
    "                    if 'SAE' in net.module.__class__.__name__: # AE 때는 l2norm거쳐서 나와서 괜찮음\n",
    "                        denominator =  np.linalg.norm(spike_hidden[spike_index, :])*np.linalg.norm(Cluster[q, :]) + 1e-12\n",
    "                        tau[q] = tau[q] / denominator\n",
    "                    # print(np.linalg.norm(spike_hidden[spike_index, :]))\n",
    "                    # print(np.linalg.norm(Cluster[q, :]))\n",
    "                # tau = np.dot(Cluster, spike_hidden[spike_index, :]) # 이거 l2norm 거쳐서 나온 거니까 분모 1임.\n",
    "\n",
    "                for i in range(num_cluster): # l2 distance\n",
    "                    distance_sm[i] = np.sum(np.power(np.abs(Cluster[i] - spike_hidden[spike_index, :]), 2))\n",
    "\n",
    "                m = np.argmin(distance_sm)\n",
    "                spike_id[spike_index] = m + 1\n",
    "                # print(spike_tot[ds], spike_index,np.max(tau))\n",
    "                if(np.max(tau) >= cos_thr[ds] and spike_index < training_cycle): # 원래 1400 아니냐?\n",
    "                    Cluster[m] = (Cluster[m] * 15 + spike_hidden[spike_index, :])/16\n",
    "                            \n",
    "            # spike id 분포 확인하기\n",
    "            # unique_elements, counts = np.unique(spike_id, return_counts=True)\n",
    "            # print(\"Unique elements:\", unique_elements)\n",
    "            # print(\"Counts:\", counts)\n",
    "\n",
    "            cluster_accuracy_during_training_cycle = np.zeros(math.factorial(num_cluster))\n",
    "            cluster_accuracy_post_training_cycle = np.zeros(math.factorial(num_cluster))\n",
    "            cluster_accuracy_total = np.zeros(math.factorial(num_cluster))\n",
    "            \n",
    "            label_converter_ground = list(range(1, num_cluster + 1)) # [1, 2, 3, 4] 생성\n",
    "            label_converter_permutations = list(itertools.permutations(label_converter_ground)) # 모든 순열 구하기\n",
    "            perm_i = 0\n",
    "            for perm in label_converter_permutations:\n",
    "                label_converter = list(perm)\n",
    "                # print(label_converter)\n",
    "                correct_during_training_cycle = 0\n",
    "                correct_post_training_cycle = 0\n",
    "\n",
    "                assert len(spike_id) == len(label), 'spike_id랑 label 길이 같아야 됨.'\n",
    "                for i in range(len(spike_id)):\n",
    "                    if(label_converter[int(spike_id[i]-1)] == label[i]):\n",
    "                        if i < training_cycle:\n",
    "                            correct_during_training_cycle += 1\n",
    "                        else:\n",
    "                            correct_post_training_cycle += 1\n",
    "\n",
    "                cluster_accuracy_during_training_cycle[perm_i] = correct_during_training_cycle/training_cycle\n",
    "                cluster_accuracy_post_training_cycle[perm_i] = correct_post_training_cycle/(len(spike_id)-training_cycle)\n",
    "                cluster_accuracy_total[perm_i] = (correct_during_training_cycle+correct_post_training_cycle)/(len(spike_id))\n",
    "                perm_i += 1\n",
    "\n",
    "            cluster_accuracy_during_training_cycle_all_dataset[ds] = np.max(cluster_accuracy_during_training_cycle)\n",
    "            cluster_accuracy_post_training_cycle_all_dataset[ds] = cluster_accuracy_post_training_cycle[np.argmax(cluster_accuracy_during_training_cycle)]\n",
    "            cluster_accuracy_total_all_dataset[ds] = cluster_accuracy_total[np.argmax(cluster_accuracy_during_training_cycle)]\n",
    "\n",
    "        print('cluster_accuracy_post_training_cycle_all_dataset', cluster_accuracy_post_training_cycle_all_dataset)\n",
    "\n",
    "        mean_cluster_accuracy_during_training_cycle_all_dataset = np.mean(cluster_accuracy_during_training_cycle_all_dataset)\n",
    "        mean_cluster_accuracy_post_training_cycle_all_dataset = np.mean(cluster_accuracy_post_training_cycle_all_dataset)\n",
    "        mean_cluster_accuracy_total_all_dataset = np.mean(cluster_accuracy_total_all_dataset)\n",
    "        \n",
    "        mean_cluster_accuracy_during_training_cycle_all_dataset_history.append((epoch, mean_cluster_accuracy_during_training_cycle_all_dataset*100))\n",
    "        mean_cluster_accuracy_post_training_cycle_all_dataset_history.append((epoch, mean_cluster_accuracy_post_training_cycle_all_dataset*100))\n",
    "        mean_cluster_accuracy_total_all_dataset_history.append((epoch, mean_cluster_accuracy_total_all_dataset*100))\n",
    "        print(f\"mean_cluster_accuracy_during_training_cycle : {mean_cluster_accuracy_during_training_cycle_all_dataset*100:.2f}%, post_traincycle_acc : {mean_cluster_accuracy_post_training_cycle_all_dataset*100:.2f}%, total_acc : {mean_cluster_accuracy_total_all_dataset*100:.2f}%\")\n",
    "\n",
    "        if mean_cluster_accuracy_post_training_cycle_all_dataset > best_mean_cluster_accuracy_post_training_cycle_all_dataset:\n",
    "            torch.save(net, f\"net_save/save_now_net_{current_time}.pth\")\n",
    "            print('save model')\n",
    "            best_mean_cluster_accuracy_post_training_cycle_all_dataset = mean_cluster_accuracy_post_training_cycle_all_dataset\n",
    "        print(f\"best_mean_cluster_accuracy_post_training_cycle_all_dataset : {best_mean_cluster_accuracy_post_training_cycle_all_dataset*100:.2f}%\")\n",
    "\n",
    "\n",
    "    running_loss = 0.0\n",
    "    net.train()\n",
    "    for data in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        spike = data\n",
    "        spike = spike.to(device)\n",
    "        if 'SAE' in net.module.__class__.__name__:\n",
    "            spike = spike.unsqueeze(-1).repeat(1, 1, TIME).permute(0,2,1) # (batch, time, feature)로 변환\n",
    "        spike_class = net(spike)\n",
    "\n",
    "        # if 'SAE' in net.module.__class__.__name__:\n",
    "        #     spike = spike.mean(dim=1)# Time 방향으로 평균\n",
    "        #     spike_class = spike_class.mean(dim=1)# Time 방향으로 평균\n",
    "\n",
    "        if 'SAE' in net.module.__class__.__name__:\n",
    "            loss1 = criterion(spike_class[:, :, 5:25], spike[:, :, 5:25])\n",
    "            loss2 = criterion(spike_class[:, :, 0:5], spike[:, :, 0:5])\n",
    "            loss3 = criterion(spike_class[:, :, 25:spike_length], spike[:, :, 25:spike_length])\n",
    "        else:\n",
    "            loss1 = criterion(spike_class[:, 5:25], spike[:, 5:25])\n",
    "            loss2 = criterion(spike_class[:, 0:5], spike[:, 0:5])\n",
    "            loss3 = criterion(spike_class[:, 25:spike_length], spike[:, 25:spike_length])\n",
    "\n",
    "        loss = loss1 * 2.125 + (loss2 + loss3)/4\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "    avg_loss = running_loss / len(train_loader)\n",
    "    loss_history.append((epoch, avg_loss))\n",
    "    print(f'\\nepoch-{epoch} loss : {avg_loss:.5f}')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.ticker import MaxNLocator\n",
    "\n",
    "# 설정 정보 제목 작성\n",
    "title = (\n",
    "    f\"Dataset Num: {dataset_num}, Conv {Conv_net}, SAE {SAE_net}, Current time {current_time}, Spike Length: {spike_length}, Num Cluster: {num_cluster}, \"\n",
    "    f\"Training Cycle: {training_cycle}, Batch Size: {batch_size}, Max Epoch: {max_epoch}, \\n\"\n",
    "    f\"Learning Rate: {learning_rate}, Input Normalize: {normalize_on}, Need Bias: {need_bias}, \"\n",
    "    f\"LIF Add at First: {lif_add_at_first}, TIME: {TIME}, Seed: {my_seed}, Data: {AE_train_data}, Best ACC: {best_mean_cluster_accuracy_post_training_cycle_all_dataset*100:.2f}%\"\n",
    ")\n",
    "\n",
    "# 데이터 리스트와 라벨 설정 (Loss 제외)\n",
    "data_list = [\n",
    "    (\"Mean Cluster Accuracy (During Training Cycle)\", mean_cluster_accuracy_during_training_cycle_all_dataset_history),\n",
    "    (\"Mean Cluster Accuracy (Post Training Cycle)\", mean_cluster_accuracy_post_training_cycle_all_dataset_history),\n",
    "    (\"Mean Cluster Accuracy (Total)\", mean_cluster_accuracy_total_all_dataset_history),\n",
    "]\n",
    "\n",
    "# 플롯 생성\n",
    "fig, ax1 = plt.subplots(figsize=(12, 8))\n",
    "\n",
    "# 첫 번째 y축: Accuracy 관련 데이터\n",
    "for label, data in data_list:\n",
    "    epochs, values = zip(*data)  # epoch, value 분리\n",
    "    ax1.plot(epochs, values, label=label)\n",
    "\n",
    "ax1.set_xlabel(\"Epoch\")\n",
    "ax1.set_ylabel(\"Clurstering Accuracy [%]\", color=\"blue\")\n",
    "ax1.tick_params(axis=\"y\", labelcolor=\"blue\")\n",
    "ax1.legend(loc=\"center right\")\n",
    "ax1.grid(True)\n",
    "\n",
    "# x축을 정수만 표시하도록 설정\n",
    "ax1.xaxis.set_major_locator(MaxNLocator(integer=True))\n",
    "\n",
    "# 두 번째 y축: Loss History\n",
    "ax2 = ax1.twinx()\n",
    "epochs, values = zip(*loss_history)\n",
    "ax2.plot(epochs, values, label=\"AE Loss History\", color=\"red\", linestyle=\"--\")\n",
    "ax2.set_ylabel(\"Loss\", color=\"red\")\n",
    "ax2.tick_params(axis=\"y\", labelcolor=\"red\")\n",
    "ax2.legend(loc=\"center left\")\n",
    "\n",
    "# 제목 추가\n",
    "plt.title(title, fontsize=10)\n",
    "plt.tight_layout()\n",
    "plt.savefig(f'net_save/{current_time}', dpi=300, bbox_inches=\"tight\")  # dpi=300은 고해상도로 저장, bbox_inches=\"tight\"는 여백 최소화\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aedat2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
