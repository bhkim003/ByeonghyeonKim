{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copyright (c) 2024 Byeonghyeon Kim \n",
    "# github site: https://github.com/bhkim003/ByeonghyeonKim\n",
    "# email: bhkim003@snu.ac.kr\n",
    " \n",
    "# Permission is hereby granted, free of charge, to any person obtaining a copy of\n",
    "# this software and associated documentation files (the \"Software\"), to deal in\n",
    "# the Software without restriction, including without limitation the rights to\n",
    "# use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of\n",
    "# the Software, and to permit persons to whom the Software is furnished to do so,\n",
    "# subject to the following conditions:\n",
    " \n",
    "# The above copyright notice and this permission notice shall be included in all\n",
    "# copies or substantial portions of the Software.\n",
    " \n",
    "# THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\n",
    "# IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS\n",
    "# FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR\n",
    "# COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER\n",
    "# IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN\n",
    "# CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_19721/3914466541.py:46: DeprecationWarning: The module snntorch.spikevision is deprecated. For loading neuromorphic datasets, we recommend using the Tonic project: https://github.com/neuromorphs/tonic\n",
      "  from snntorch.spikevision import spikedata\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "import argparse\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.optim as optim\n",
    "import torch.optim.lr_scheduler as lr_scheduler\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "import torchvision\n",
    "import torchvision.datasets\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import time\n",
    "\n",
    "from snntorch import spikegen\n",
    "import matplotlib.pyplot as plt\n",
    "import snntorch.spikeplot as splt\n",
    "from IPython.display import HTML\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "from apex.parallel import DistributedDataParallel as DDP\n",
    "\n",
    "import random\n",
    "import datetime\n",
    "\n",
    "import json\n",
    "\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "''' 레퍼런스\n",
    "https://spikingjelly.readthedocs.io/zh-cn/0.0.0.0.4/spikingjelly.datasets.html#module-spikingjelly.datasets\n",
    "https://github.com/GorkaAbad/Sneaky-Spikes/blob/main/datasets.py\n",
    "https://github.com/GorkaAbad/Sneaky-Spikes/blob/main/how_to.md\n",
    "https://github.com/nmi-lab/torchneuromorphic\n",
    "https://snntorch.readthedocs.io/en/latest/snntorch.spikevision.spikedata.html#shd\n",
    "'''\n",
    "\n",
    "import snntorch\n",
    "from snntorch.spikevision import spikedata\n",
    "\n",
    "from spikingjelly.datasets.dvs128_gesture import DVS128Gesture\n",
    "from spikingjelly.datasets.cifar10_dvs import CIFAR10DVS\n",
    "from spikingjelly.datasets.n_mnist import NMNIST\n",
    "# from spikingjelly.datasets.es_imagenet import ESImageNet\n",
    "from spikingjelly.datasets import split_to_train_test_set\n",
    "from spikingjelly.datasets.n_caltech101 import NCaltech101\n",
    "from spikingjelly.datasets import pad_sequence_collate, padded_sequence_mask\n",
    "\n",
    "import torchneuromorphic\n",
    "\n",
    "import wandb\n",
    "\n",
    "from torchviz import make_dot\n",
    "import graphviz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x600 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# my module import\n",
    "from modules import *\n",
    "\n",
    "# modules 폴더에 새모듈.py 만들면\n",
    "# modules/__init__py 파일에 form .새모듈 import * 하셈\n",
    "# 그리고 새모듈.py에서 from modules.새모듈 import * 하셈\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_snn_system(devices = \"0,1,2,3\",\n",
    "                    single_step = False, # True # False\n",
    "                    unique_name = 'main',\n",
    "                    my_seed = 42,\n",
    "                    TIME = 10,\n",
    "                    BATCH = 256,\n",
    "                    IMAGE_SIZE = 32,\n",
    "                    which_data = 'CIFAR10',\n",
    "                    # CLASS_NUM = 10,\n",
    "                    data_path = '/data2',\n",
    "                    rate_coding = True,\n",
    "    \n",
    "                    lif_layer_v_init = 0.0,\n",
    "                    lif_layer_v_decay = 0.6,\n",
    "                    lif_layer_v_threshold = 1.2,\n",
    "                    lif_layer_v_reset = 0.0,\n",
    "                    lif_layer_sg_width = 1,\n",
    "\n",
    "                    # synapse_conv_in_channels = IMAGE_PIXEL_CHANNEL,\n",
    "                    synapse_conv_kernel_size = 3,\n",
    "                    synapse_conv_stride = 1,\n",
    "                    synapse_conv_padding = 1,\n",
    "                    synapse_conv_trace_const1 = 1,\n",
    "                    synapse_conv_trace_const2 = 0.6,\n",
    "\n",
    "                    # synapse_fc_out_features = CLASS_NUM,\n",
    "                    synapse_fc_trace_const1 = 1,\n",
    "                    synapse_fc_trace_const2 = 0.6,\n",
    "\n",
    "                    pre_trained = False,\n",
    "                    convTrue_fcFalse = True,\n",
    "                    cfg = [64, 64],\n",
    "                    net_print = False, # True # False\n",
    "                    weight_count_print = False, # True # False\n",
    "                    pre_trained_path = \"net_save/save_now_net.pth\",\n",
    "                    learning_rate = 0.0001,\n",
    "                    epoch_num = 200,\n",
    "                    verbose_interval = 100, #숫자 크게 하면 꺼짐\n",
    "                    validation_interval = 10, #숫자 크게 하면 꺼짐\n",
    "                    tdBN_on = False,\n",
    "                    BN_on = False,\n",
    "\n",
    "                    surrogate = 'sigmoid',\n",
    "\n",
    "                    gradient_verbose = False,\n",
    "\n",
    "                    BPTT_on = False,\n",
    "\n",
    "                    optimizer_what = 'SGD', # 'SGD' 'Adam', 'RMSprop'\n",
    "                    scheduler_name = 'no',\n",
    "                    \n",
    "                    ddp_on = True,\n",
    "\n",
    "                    nda_net = False,\n",
    "                    \n",
    "                    domain_il_epoch = 0, # over 0, then domain il mode on\n",
    "\n",
    "                    dvs_clipping = 1, \n",
    "                    dvs_duration = 10005,\n",
    "\n",
    "                    OTTT_sWS_on = True, # True # False\n",
    "\n",
    "                    DFA_on = False, # True # False\n",
    "                    OTTT_input_trace_on = False, # True # False\n",
    "                 \n",
    "                    e_transport_swap = 5, # 1 이상이면 해당 숫자 에포크만큼 val_acc_best가 변화가 없으면 e_transport scheme (BP vs DFA) swap\n",
    "                    e_transport_swap_tr = 0, # 1 이상이면 해당 숫자 에포크만큼 val_acc_best가 변화가 없으면 e_transport scheme (BP vs DFA) swap\n",
    "                    e_transport_swap_coin = 0, # swap할 수 있는 coin 개수\n",
    "\n",
    "                    drop_rate = 0.5, \n",
    "\n",
    "                    exclude_class = True, # True # False # gesture에서 10번째 클래스 제외\n",
    "\n",
    "                    merge_polarities = True, # True # False # tonic dvs dataset 에서 polarities 합치기\n",
    "                  ):\n",
    "    ## hyperparameter check #############################################################\n",
    "    if OTTT_sWS_on == True:\n",
    "        assert BPTT_on == False and tdBN_on == False and BN_on == False\n",
    "        if convTrue_fcFalse == False:\n",
    "            assert single_step == True\n",
    "    if single_step == True:\n",
    "        assert BPTT_on == False and tdBN_on == False \n",
    "    if tdBN_on == True:\n",
    "        assert BPTT_on == True\n",
    "    if pre_trained == True:\n",
    "        print('\\n\\n')\n",
    "        print(\"Caution! pre_trained is True\\n\\n\"*3)    \n",
    "    if DFA_on == True:\n",
    "        assert single_step == True and BPTT_on == False and any(isinstance(item, list) for item in cfg) == False\n",
    "    if OTTT_input_trace_on == True:\n",
    "        assert BPTT_on == False and single_step == True\n",
    "    ######################################################################################\n",
    "\n",
    "\n",
    "    ## 함수 내 모든 로컬 변수 저장 ########################################################\n",
    "    hyperparameters = locals()\n",
    "    hyperparameters['current epoch'] = 0\n",
    "    ######################################################################################\n",
    "    \n",
    "    args_gpu = None\n",
    "    ## DDP settting ######################################################################\n",
    "    if (ddp_on == True):\n",
    "        parser = argparse.ArgumentParser(description='my_snn CIFAR10 Training')\n",
    "\n",
    "        # # local_rank는 command line에서 따로 줄 필요는 없지만, 선언은 필요\n",
    "        parser.add_argument(\"--local_rank\", default=0, type=int)\n",
    "\n",
    "        args = parser.parse_args() # 이거 적어줘야됨. parser argument선언하고\n",
    "\n",
    "        args.gpu = args.local_rank\n",
    "        args_gpu = args.gpu\n",
    "        torch.cuda.set_device(args.gpu)\n",
    "        torch.distributed.init_process_group(backend=\"nccl\", init_method=\"env://\")\n",
    "        args.world_size = torch.distributed.get_world_size()\n",
    "    #######################################################################################\n",
    "\n",
    "\n",
    "    ## wandb 세팅 ###################################################################\n",
    "    current_time = datetime.datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "    if (ddp_on == True and torch.distributed.get_rank() != 0):\n",
    "        wandb.finish()\n",
    "    if (ddp_on == False or torch.distributed.get_rank() == 0):\n",
    "        wandb.config.update(hyperparameters)\n",
    "        wandb.run.name = f'lr_{learning_rate}_{unique_name}_{which_data}_tstep{TIME}'\n",
    "        wandb.define_metric(\"summary_val_acc\", summary=\"max\")\n",
    "        wandb.run.log_code(\".\", \n",
    "                           include_fn=lambda path: path.endswith(\".py\") or path.endswith(\".ipynb\"),\n",
    "                           exclude_fn=lambda path: 'logs/' in path or 'net_save/' in path or 'result_save/' in path or 'trying/' in path or 'wandb/' in path or 'private/' in path\n",
    "                           )\n",
    "    ###################################################################################\n",
    "\n",
    "\n",
    "\n",
    "    ## gpu setting ##################################################################################################################\n",
    "    os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\" \n",
    "    os.environ[\"CUDA_VISIBLE_DEVICES\"]= devices\n",
    "    ###################################################################################################################################\n",
    "\n",
    "\n",
    "    ## seed setting ##################################################################################################################\n",
    "    seed_assign(my_seed)\n",
    "    ###################################################################################################################################\n",
    "    \n",
    "\n",
    "    ## data_loader 가져오기 ##################################################################################################################\n",
    "    # data loader, pixel channel, class num\n",
    "    train_loader, test_loader, synapse_conv_in_channels, CLASS_NUM = data_loader(\n",
    "            which_data,\n",
    "            data_path, \n",
    "            rate_coding, \n",
    "            BATCH, \n",
    "            IMAGE_SIZE,\n",
    "            ddp_on,\n",
    "            TIME,\n",
    "            dvs_clipping,\n",
    "            dvs_duration,\n",
    "            exclude_class,\n",
    "            merge_polarities)\n",
    "    synapse_fc_out_features = CLASS_NUM\n",
    "    ###########################################################################################################################################\n",
    "\n",
    "    \n",
    "    ## parameter number calculator (안 중요함) ##################################################################################################################\n",
    "    params_num = 0\n",
    "    img_size = IMAGE_SIZE \n",
    "    bias_param = 1 # 1 or 0\n",
    "    classifier_making = False\n",
    "    if (convTrue_fcFalse == True):\n",
    "        past_kernel = synapse_conv_in_channels\n",
    "        for kernel in cfg:\n",
    "            if (classifier_making == False):\n",
    "                if (type(kernel) == list):\n",
    "                    for residual_kernel in kernel:\n",
    "                        if (residual_kernel >= 10000 and residual_kernel < 20000): # separable\n",
    "                            residual_kernel -= 10000\n",
    "                            params_num += (synapse_conv_kernel_size**2 + bias_param) * past_kernel\n",
    "                            params_num += (1**2 * past_kernel + bias_param) * residual_kernel\n",
    "                            past_kernel = residual_kernel  \n",
    "                        elif (residual_kernel >= 20000 and residual_kernel < 30000): # depthwise\n",
    "                            residual_kernel -= 20000\n",
    "                            # 'past_kernel' should be same with 'kernel'\n",
    "                            params_num += (synapse_conv_kernel_size**2 + bias_param) * past_kernel\n",
    "                            past_kernel = residual_kernel  \n",
    "                        else:\n",
    "                            params_num += residual_kernel * ((synapse_conv_kernel_size**2) * past_kernel + bias_param)\n",
    "                            past_kernel = residual_kernel\n",
    "                elif (kernel == 'P' or kernel == 'M'):\n",
    "                    img_size = img_size // 2\n",
    "                elif (kernel == 'D'):\n",
    "                    img_size = 1\n",
    "                elif (kernel == 'L'):\n",
    "                    classifier_making = True\n",
    "                    past_kernel = past_kernel * (img_size**2)\n",
    "                else:\n",
    "                    if (kernel >= 10000 and kernel < 20000): # separable\n",
    "                        kernel -= 10000\n",
    "                        params_num += (synapse_conv_kernel_size**2 + bias_param) * past_kernel\n",
    "                        params_num += (1**2 * past_kernel + bias_param) * kernel\n",
    "                        past_kernel = kernel  \n",
    "                    elif (kernel >= 20000 and kernel < 30000): # depthwise\n",
    "                        kernel -= 20000\n",
    "                        # 'past_kernel' should be same with 'kernel'\n",
    "                        params_num += (synapse_conv_kernel_size**2 + bias_param) * past_kernel\n",
    "                        past_kernel = kernel  \n",
    "                    else:\n",
    "                        params_num += kernel * (synapse_conv_kernel_size**2 * past_kernel + bias_param)\n",
    "                        past_kernel = kernel    \n",
    "            else: # classifier making\n",
    "                params_num += (past_kernel + bias_param) * kernel\n",
    "                past_kernel = kernel\n",
    "        \n",
    "        \n",
    "        if classifier_making == False:\n",
    "            past_kernel = past_kernel*img_size*img_size\n",
    "\n",
    "        params_num += (past_kernel + bias_param) * synapse_fc_out_features\n",
    "    else:\n",
    "        past_in_channel = synapse_conv_in_channels*img_size*img_size\n",
    "        for in_channel in cfg:\n",
    "            if (type(in_channel) == list):\n",
    "                for residual_in_channel in in_channel:\n",
    "                    params_num += (past_in_channel + bias_param) * residual_in_channel\n",
    "                    past_in_channel = residual_in_channel\n",
    "            elif (in_channel == 'P' or in_channel == 'M'):\n",
    "                img_size = img_size // 2\n",
    "                past_in_channel = synapse_conv_in_channels*img_size*img_size\n",
    "            else:\n",
    "                params_num += (past_in_channel + bias_param) * in_channel\n",
    "                past_in_channel = in_channel\n",
    "        params_num += (past_in_channel + bias_param) * synapse_fc_out_features\n",
    "    ###########################################################################################################################################\n",
    "\n",
    "\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "    ### network setting #######################################################################################################################\n",
    "    if (convTrue_fcFalse == False):\n",
    "        if (single_step == False):\n",
    "            net = MY_SNN_FC(cfg, synapse_conv_in_channels, IMAGE_SIZE, synapse_fc_out_features,\n",
    "                        synapse_fc_trace_const1, synapse_fc_trace_const2, \n",
    "                        lif_layer_v_init, lif_layer_v_decay, \n",
    "                        lif_layer_v_threshold, lif_layer_v_reset,\n",
    "                        lif_layer_sg_width,\n",
    "                        tdBN_on,\n",
    "                        BN_on, TIME,\n",
    "                        surrogate,\n",
    "                        BPTT_on,\n",
    "                        DFA_on,\n",
    "                        drop_rate).to(device)\n",
    "        else:\n",
    "            net = MY_SNN_FC_sstep(cfg, synapse_conv_in_channels, IMAGE_SIZE, synapse_fc_out_features,\n",
    "                        synapse_fc_trace_const1, synapse_fc_trace_const2, \n",
    "                        lif_layer_v_init, lif_layer_v_decay, \n",
    "                        lif_layer_v_threshold, lif_layer_v_reset,\n",
    "                        lif_layer_sg_width,\n",
    "                        tdBN_on,\n",
    "                        BN_on, TIME,\n",
    "                        surrogate,\n",
    "                        BPTT_on,\n",
    "                        DFA_on,\n",
    "                        OTTT_sWS_on,\n",
    "                        drop_rate).to(device)\n",
    "    else:\n",
    "        if (single_step == False):\n",
    "            net = MY_SNN_CONV(cfg, synapse_conv_in_channels, IMAGE_SIZE,\n",
    "                        synapse_conv_kernel_size, synapse_conv_stride, \n",
    "                        synapse_conv_padding, synapse_conv_trace_const1, \n",
    "                        synapse_conv_trace_const2, \n",
    "                        lif_layer_v_init, lif_layer_v_decay, \n",
    "                        lif_layer_v_threshold, lif_layer_v_reset,\n",
    "                        lif_layer_sg_width,\n",
    "                        synapse_fc_out_features, synapse_fc_trace_const1, synapse_fc_trace_const2,\n",
    "                        tdBN_on,\n",
    "                        BN_on, TIME,\n",
    "                        surrogate,\n",
    "                        BPTT_on,\n",
    "                        OTTT_sWS_on,\n",
    "                        DFA_on,\n",
    "                        drop_rate).to(device)\n",
    "        else:\n",
    "            net = MY_SNN_CONV_sstep(cfg, synapse_conv_in_channels, IMAGE_SIZE,\n",
    "                        synapse_conv_kernel_size, synapse_conv_stride, \n",
    "                        synapse_conv_padding, synapse_conv_trace_const1, \n",
    "                        synapse_conv_trace_const2, \n",
    "                        lif_layer_v_init, lif_layer_v_decay, \n",
    "                        lif_layer_v_threshold, lif_layer_v_reset,\n",
    "                        lif_layer_sg_width,\n",
    "                        synapse_fc_out_features, synapse_fc_trace_const1, synapse_fc_trace_const2,\n",
    "                        tdBN_on,\n",
    "                        BN_on, TIME,\n",
    "                        surrogate,\n",
    "                        BPTT_on,\n",
    "                        OTTT_sWS_on,\n",
    "                        DFA_on,\n",
    "                        drop_rate).to(device)\n",
    "    if (nda_net == True):\n",
    "        net = VGG(cfg = cfg, num_classes=10, batch_norm = tdBN_on, in_c = synapse_conv_in_channels, \n",
    "                    lif_layer_v_threshold=lif_layer_v_threshold, lif_layer_v_decay=lif_layer_v_decay, lif_layer_sg_width=lif_layer_sg_width)\n",
    "        net.T = TIME\n",
    "    if ddp_on == False:\n",
    "        net = torch.nn.DataParallel(net) \n",
    "    \n",
    "    if pre_trained == True:\n",
    "        net.load_state_dict(torch.load(pre_trained_path))\n",
    "    \n",
    "    if ddp_on == True:\n",
    "        device = args.gpu\n",
    "        net = net.to(args.gpu)\n",
    "        net = DDP(net, delay_allreduce=True)\n",
    "\n",
    "    net = net.to(device)\n",
    "    if (net_print == True):\n",
    "        if ddp_on == False or torch.distributed.get_rank() == 0:\n",
    "            print(net)    \n",
    "    ####################################################################################################################################\n",
    "    \n",
    "\n",
    "    ## wandb logging ###########################################\n",
    "    if ddp_on == False or torch.distributed.get_rank() == 0:\n",
    "        wandb.watch(net, log=\"all\", log_freq = 10) #gradient, parameter logging해줌\n",
    "    ############################################################\n",
    "\n",
    "    ## param num and memory estimation except BN with MY own calculation some lines above ##########################################\n",
    "    if ddp_on == False or torch.distributed.get_rank() == 0:\n",
    "        real_param_num = sum(p.numel() for p in net.parameters() if p.requires_grad)\n",
    "        if (weight_count_print == True):\n",
    "            for name, param in net.named_parameters():\n",
    "                if param.requires_grad:\n",
    "                    print(f'Layer: {name} | Number of parameters: {param.numel()}')\n",
    "        # Batch norm 있으면 아래 두 개 서로 다를 수 있음.\n",
    "        # assert real_param_num == params_num, f'parameter number is not same. real_param_num: {real_param_num}, params_num: {params_num}'    \n",
    "        print('='*50)\n",
    "        print(f\"My Num of PARAMS: {params_num:,}, system's param_num : {real_param_num:,}\")\n",
    "        memory = params_num / 8 / 1024 / 1024 # MB\n",
    "        precision = 32\n",
    "        memory = memory * precision \n",
    "        print(f\"Memory: {memory:.2f}MiB at {precision}-bit\")\n",
    "        print('='*50)\n",
    "    ##############################################################################################################################\n",
    "\n",
    "\n",
    "\n",
    "    ## criterion ########################################## # loss 구해주는 친구\n",
    "    criterion = nn.CrossEntropyLoss().to(device)\n",
    "    if (OTTT_sWS_on == True):\n",
    "        # criterion = nn.CrossEntropyLoss().to(device)\n",
    "        criterion = lambda y_t, target_t: ((1 - 0.05) * F.cross_entropy(y_t, target_t) + 0.05 * F.mse_loss(y_t, F.one_hot(target_t, CLASS_NUM).float())) / TIME \n",
    "        if which_data == 'DVS_GESTURE':\n",
    "            criterion = lambda y_t, target_t: ((1 - 0.001) * F.cross_entropy(y_t, target_t) + 0.001 * F.mse_loss(y_t, F.one_hot(target_t, CLASS_NUM).float())) / TIME \n",
    "    ####################################################\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "    ## optimizer, scheduler ########################################################################\n",
    "    if(optimizer_what == 'SGD'):\n",
    "        # optimizer = optim.SGD(net.parameters(), lr=learning_rate, momentum=0.9)\n",
    "        optimizer = optim.SGD(net.parameters(), lr=learning_rate, momentum=0.9, weight_decay=0)\n",
    "    elif(optimizer_what == 'Adam'):\n",
    "        optimizer = torch.optim.Adam(net.parameters(), lr=learning_rate)\n",
    "        # optimizer = torch.optim.Adam(net.parameters(), lr=0.00001)\n",
    "        # optimizer = torch.optim.Adam(net.parameters(), lr=learning_rate/256 * BATCH, weight_decay=1e-4)\n",
    "        # optimizer = optim.Adam(net.parameters(), lr=learning_rate, weight_decay=0, betas=(0.9, 0.999))\n",
    "    elif(optimizer_what == 'RMSprop'):\n",
    "        pass\n",
    "\n",
    "\n",
    "    if (scheduler_name == 'StepLR'):\n",
    "        scheduler = lr_scheduler.StepLR(optimizer, step_size=10, gamma=0.1)\n",
    "    elif (scheduler_name == 'ExponentialLR'):\n",
    "        scheduler = lr_scheduler.ExponentialLR(optimizer, gamma=0.95)\n",
    "    elif (scheduler_name == 'ReduceLROnPlateau'):\n",
    "        scheduler = lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.1, patience=10)\n",
    "    elif (scheduler_name == 'CosineAnnealingLR'):\n",
    "        # scheduler = lr_scheduler.CosineAnnealingLR(optimizer, eta_min=0, T_max=50)\n",
    "        scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, eta_min=0, T_max=epoch_num)\n",
    "    elif (scheduler_name == 'OneCycleLR'):\n",
    "        scheduler = lr_scheduler.OneCycleLR(optimizer, max_lr=0.1, steps_per_epoch=len(train_loader), epochs=epoch_num)\n",
    "    else:\n",
    "        pass # 'no' scheduler\n",
    "    ## optimizer, scheduler ########################################################################\n",
    "\n",
    "\n",
    "    tr_acc = 0\n",
    "    tr_correct = 0\n",
    "    tr_total = 0\n",
    "    tr_acc_best = 0\n",
    "    tr_epoch_loss_temp = 0\n",
    "    tr_epoch_loss= 0\n",
    "    val_acc_best = 0\n",
    "    val_acc_now = 0\n",
    "    val_loss = 0\n",
    "    elapsed_time_val = 0\n",
    "    no_val_best_growth_count = 0\n",
    "    no_tr_best_growth_count = 0\n",
    "    iter_acc_array = np.array([])\n",
    "    tr_acc_array = np.array([])\n",
    "    val_acc_now_array = np.array([])\n",
    "    DFA_current = DFA_on\n",
    "    DFA_toggle = False\n",
    "    DFA_flag = 1.0 if DFA_current == True else 0.0\n",
    "    DFA_BP_toggle_trial = 0\n",
    "    iter_of_val = False\n",
    "    #======== EPOCH START ==========================================================================================\n",
    "    for epoch in range(epoch_num):\n",
    "        if (e_transport_swap > 0 or e_transport_swap_tr > 0):\n",
    "            assert not (e_transport_swap > 0 and e_transport_swap_tr > 0)\n",
    "            if e_transport_swap > 0 and no_val_best_growth_count == e_transport_swap:\n",
    "                if DFA_BP_toggle_trial < e_transport_swap_coin:\n",
    "                    net = BP_DFA_SWAP(net, convTrue_fcFalse, single_step, ddp_on, args_gpu)\n",
    "                    no_val_best_growth_count = 0\n",
    "                    DFA_current = not DFA_current\n",
    "                    DFA_toggle = True\n",
    "                    DFA_BP_toggle_trial = DFA_BP_toggle_trial + 1\n",
    "            if e_transport_swap_tr > 0 and no_tr_best_growth_count == e_transport_swap_tr:\n",
    "                if DFA_BP_toggle_trial < e_transport_swap_coin:\n",
    "                    net = BP_DFA_SWAP(net, convTrue_fcFalse, single_step, ddp_on, args_gpu)\n",
    "                    no_tr_best_growth_count = 0\n",
    "                    DFA_current = not DFA_current\n",
    "                    DFA_toggle = True\n",
    "                    DFA_BP_toggle_trial = DFA_BP_toggle_trial + 1\n",
    "\n",
    "        if ddp_on == False or torch.distributed.get_rank() == 0:\n",
    "            # print('EPOCH', epoch)\n",
    "            pass\n",
    "        epoch_start_time = time.time()\n",
    "\n",
    "        # if (domain_il_epoch>0 and which_data == 'PMNIST'):\n",
    "        #     k = epoch // domain_il_epoch\n",
    "        #     xtrain=data[k]['train']['x']\n",
    "        #     ytrain=data[k]['train']['y']\n",
    "        #     xtest =data[k]['test']['x']\n",
    "        #     ytest =data[k]['test']['y']\n",
    "\n",
    "        \n",
    "        ####### iterator : input_loading & tqdm을 통한 progress_bar 생성###################\n",
    "        iterator = enumerate(train_loader, 0)\n",
    "        if ddp_on == False or torch.distributed.get_rank() == 0:  \n",
    "            iterator = tqdm(iterator, total=len(train_loader), desc='train', dynamic_ncols=True, position=0, leave=True)\n",
    "        ##################################################################################   \n",
    "        \n",
    "        #### validation_interval이 batch size보다 작을 시 validation_interval을 batch size로 맞춰줌#############\n",
    "        validation_interval2 = validation_interval\n",
    "        if (validation_interval > len(train_loader)):\n",
    "            validation_interval2 = len(train_loader)\n",
    "        ##################################################################################################\n",
    "\n",
    "\n",
    "        ###### ITERATION START ##########################################################################################################\n",
    "        for i, data in iterator:\n",
    "            iter_one_train_time_start = time.time()\n",
    "            net.train() # train 모드로 바꿔줘야함\n",
    "\n",
    "            ### data loading & semi-pre-processing ################################################################################\n",
    "            if len(data) == 2:\n",
    "                inputs, labels = data\n",
    "                # 처리 로직 작성\n",
    "            elif len(data) == 3:\n",
    "                inputs, labels, x_len = data\n",
    "                # print('x_len',x_len)\n",
    "                # mask = padded_sequence_mask(x_len)\n",
    "                # max_time_step = x_len.max()\n",
    "                # min_time_step = x_len.min()\n",
    "            ## batch 크기 ######################################\n",
    "            real_batch = labels.size(0)\n",
    "            ###########################################################\n",
    "\n",
    "            ###########################################################################################################################        \n",
    "            if (which_data == 'n_tidigits'):\n",
    "                inputs = inputs.permute(0, 1, 3, 2, 4)\n",
    "                labels = labels[:, 0, :]\n",
    "                labels = torch.argmax(labels, dim=1)\n",
    "            elif (which_data == 'heidelberg'):\n",
    "                inputs = inputs.view(5, 1000, 1, 700, 1)\n",
    "                print(\"\\n\\n\\n경고!!!! heidelberg 이거 타임스텝이랑 채널 잘 바꿔줘라!!!\\n\\n\\n\\n\")\n",
    "            # print('inputs',inputs.size(),'\\nlabels',labels.size())\n",
    "            # print(labels)\n",
    "                \n",
    "            if (which_data == 'DVS_CIFAR10' or which_data == 'DVS_GESTURE' or which_data == 'DVS_GESTURE_TONIC' or which_data == 'DVS_CIFAR10_2' or which_data == 'NMNIST' or which_data == 'NMNIST_TONIC' or which_data == 'N_CALTECH101' or which_data == 'n_tidigits' or which_data == 'heidelberg'):\n",
    "                inputs = inputs.permute(1, 0, 2, 3, 4)\n",
    "            elif rate_coding == True :\n",
    "                inputs = spikegen.rate(inputs, num_steps=TIME)\n",
    "            else :\n",
    "                inputs = inputs.repeat(TIME, 1, 1, 1, 1)\n",
    "            # inputs: [Time, Batch, Channel, Height, Width]  \n",
    "            ####################################################################################################################### \n",
    "                \n",
    "            \n",
    "            # # dvs 데이터 시각화 코드 (확인 필요할 시 써라)\n",
    "            # ##############################################################################################\n",
    "            # dvs_visualization(inputs, labels, TIME, BATCH, my_seed)\n",
    "            # #####################################################################################################\n",
    "\n",
    "            ## to (device) #######################################\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "            ###########################################################\n",
    "\n",
    "\n",
    "            ## gradient 초기화 #######################################\n",
    "            optimizer.zero_grad()\n",
    "            ###########################################################\n",
    "            \n",
    "            ## DVS gesture에서 other label자리 매꾸기 ###############\n",
    "            if (which_data == 'DVS_GESTURE'):\n",
    "                labels[labels>2] -= 1\n",
    "            #######################################################\n",
    "\n",
    "            if single_step == False:\n",
    "                # net에 넣어줄때는 batch가 젤 앞 차원으로 와야함. # dataparallel때매##############################\n",
    "                # inputs: [Time, Batch, Channel, Height, Width]   \n",
    "                inputs = inputs.permute(1, 0, 2, 3, 4) # net에 넣어줄때는 batch가 젤 앞 차원으로 와야함. # dataparallel때매\n",
    "                # inputs: [Batch, Time, Channel, Height, Width] \n",
    "                #################################################################################################\n",
    "            else:\n",
    "                labels = labels.repeat(TIME, 1)\n",
    "                ## first input도 ottt trace 적용하기 위한 코드 (validation 시에는 필요X) ##########################\n",
    "                if OTTT_input_trace_on == True:\n",
    "                    spike = inputs\n",
    "                    trace = torch.full_like(spike, fill_value = 0.0, dtype = torch.float, requires_grad=False)\n",
    "                    inputs = []\n",
    "                    for t in range(TIME):\n",
    "                        trace[t] = trace[t-1]*synapse_conv_trace_const2 + spike[t]*synapse_conv_trace_const1\n",
    "                        inputs += [[spike[t], trace[t]]]\n",
    "                ##################################################################################################\n",
    "                        \n",
    "            if merge_polarities == True:\n",
    "                inputs = inputs[:,:,0,:,:]\n",
    "\n",
    "            if single_step == False:\n",
    "                ### input --> net --> output #####################################################\n",
    "                outputs = net(inputs)\n",
    "                ##################################################################################\n",
    "                ## loss, backward ##########################################\n",
    "                loss = criterion(outputs, labels)\n",
    "                loss.backward()\n",
    "                ############################################################\n",
    "                ## weight 업데이트!! ##################################\n",
    "                optimizer.step()\n",
    "                ################################################################\n",
    "            else:\n",
    "                outputs_all = []\n",
    "                loss = 0.0\n",
    "                for t in range(TIME):\n",
    "                    ### input[t] --> net --> output_one_time #########################################\n",
    "                    outputs_one_time = net(inputs[t])\n",
    "                    ##################################################################################\n",
    "                    one_time_loss = criterion(outputs_one_time, labels[t].contiguous())\n",
    "                    one_time_loss.backward() # one_time backward\n",
    "                    loss += one_time_loss.data\n",
    "                    outputs_all.append(outputs_one_time.detach())\n",
    "                optimizer.step() # full step time update\n",
    "                outputs_all = torch.stack(outputs_all, dim=1)\n",
    "                outputs = outputs_all.mean(1) # ottt꺼 쓸때\n",
    "                labels = labels[0]\n",
    "                loss /= TIME\n",
    "            tr_epoch_loss_temp += loss.data/len(train_loader)\n",
    "\n",
    "            ## net 그림 출력해보기 #################################################################\n",
    "            # print('시각화')\n",
    "            # make_dot(outputs, params=dict(list(net.named_parameters()))).render(\"net_torchviz\", format=\"png\")\n",
    "            # return 0\n",
    "            ##################################################################################\n",
    "\n",
    "            #### batch 어긋남 방지 ###############################################\n",
    "            assert real_batch == outputs.size(0), f'batch size is not same. real_batch: {real_batch}, outputs.size(0): {outputs.size(0)}'\n",
    "            #######################################################################\n",
    "            \n",
    "\n",
    "            ####### training accruacy save for print ###############################\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total = real_batch\n",
    "            correct = (predicted == labels).sum().item()\n",
    "            iter_acc = correct / total\n",
    "            tr_total += total\n",
    "            tr_correct += correct\n",
    "            if i % verbose_interval == verbose_interval-1:\n",
    "                if ddp_on == False or torch.distributed.get_rank() == 0:\n",
    "                    print(f'{epoch}-{i} training acc: {100 * iter_acc:.2f}%, lr={[f\"{lr}\" for lr in (param_group[\"lr\"] for param_group in optimizer.param_groups)]}, val_acc: {100 * val_acc_now:.2f}%')\n",
    "            iter_acc_string = f'epoch-{epoch:<3} iter_acc:{100 * iter_acc:7.2f}%, lr={[f\"{lr:9.7f}\" for lr in (param_group[\"lr\"] for param_group in optimizer.param_groups)]}'\n",
    "            iter_acc_string2 = f'epoch-{epoch:<3} lr={[f\"{lr:9.7f}\" for lr in (param_group[\"lr\"] for param_group in optimizer.param_groups)]}'\n",
    "            ################################################################\n",
    "            \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "            iter_one_train_time_end = time.time()\n",
    "            elapsed_time = iter_one_train_time_end - iter_one_train_time_start  # 실행 시간 계산\n",
    "\n",
    "            if (i % verbose_interval == verbose_interval-1):\n",
    "                if ddp_on == False or torch.distributed.get_rank() == 0:\n",
    "                    print(f\"iter_one_train_time: {elapsed_time} seconds, last one_val_time: {elapsed_time_val} seconds\\n\")\n",
    "\n",
    "            ##### validation ##################################################################################################################################\n",
    "            if i % validation_interval2 == validation_interval2-1:\n",
    "                iter_one_val_time_start = time.time()\n",
    "                tr_acc = tr_correct/tr_total\n",
    "                tr_correct = 0\n",
    "                tr_total = 0\n",
    "                val_loss = 0\n",
    "                correct = 0\n",
    "                total = 0\n",
    "                with torch.no_grad():\n",
    "                    net.eval() # eval 모드로 바꿔줘야함 \n",
    "                    for data in test_loader:\n",
    "                        ## data loading & semi-pre-processing ##########################################################\n",
    "                        if len(data) == 2:\n",
    "                            inputs, labels = data\n",
    "                            # 처리 로직 작성\n",
    "                        elif len(data) == 3:\n",
    "                            inputs, labels, x_len = data\n",
    "                            # print('x_len',x_len)\n",
    "                            # mask = padded_sequence_mask(x_len)\n",
    "                            # max_time_step = x_len.max()\n",
    "                            # min_time_step = x_len.min()\n",
    "                            # B, T, *spatial_dims = inputs.shape\n",
    "\n",
    "                        if (which_data == 'DVS_CIFAR10' or which_data == 'DVS_GESTURE' or which_data == 'DVS_GESTURE_TONIC' or which_data == 'DVS_CIFAR10_2' or which_data == 'NMNIST' or which_data == 'NMNIST_TONIC' or which_data == 'N_CALTECH101' or which_data == 'n_tidigits' or which_data == 'heidelberg'):\n",
    "                            inputs = inputs.permute(1, 0, 2, 3, 4)\n",
    "                        elif rate_coding == True :\n",
    "                            inputs = spikegen.rate(inputs, num_steps=TIME)\n",
    "                        else :\n",
    "                            inputs = inputs.repeat(TIME, 1, 1, 1, 1)\n",
    "                        # inputs: [Time, Batch, Channel, Height, Width]  \n",
    "                        ###################################################################################################\n",
    "\n",
    "                        inputs = inputs.to(device)\n",
    "                        labels = labels.to(device)\n",
    "                        real_batch = labels.size(0)\n",
    "                        \n",
    "                        ## DVS gesture에서 other label자리 매꾸기 ###############\n",
    "                        if (which_data == 'DVS_GESTURE'):\n",
    "                            labels[labels>2] -= 1\n",
    "                        #######################################################\n",
    "                        \n",
    "                        if merge_polarities == True:\n",
    "                            inputs = inputs[:,:,0,:,:]\n",
    "\n",
    "                        ## network 연산 시작 ############################################################################################################\n",
    "                        if single_step == False:\n",
    "                            outputs = net(inputs.permute(1, 0, 2, 3, 4)) #inputs: [Batch, Time, Channel, Height, Width]  \n",
    "                            val_loss += criterion(outputs, labels)/len(test_loader)\n",
    "                        else:\n",
    "                            outputs_all = []\n",
    "                            for t in range(TIME):\n",
    "                                outputs = net(inputs[t])\n",
    "                                val_loss_temp = criterion(outputs, labels)\n",
    "                                outputs_all.append(outputs.detach())\n",
    "                                val_loss += (val_loss_temp.data/TIME)/len(test_loader)\n",
    "                            outputs_all = torch.stack(outputs_all, dim=1)\n",
    "                            outputs = outputs_all.mean(1)\n",
    "                        #################################################################################################################################\n",
    "\n",
    "                        _, predicted = torch.max(outputs.data, 1)\n",
    "                        total += real_batch\n",
    "                        assert real_batch == outputs.size(0), f'batch size is not same. real_batch: {real_batch}, outputs.size(0): {outputs.size(0)}'\n",
    "                        correct += (predicted == labels).sum().item()\n",
    "\n",
    "                    val_acc_now = correct / total\n",
    "                    # print(f'{epoch}-{i} validation acc: {100 * val_acc_now:.2f}%, lr={[f\"{lr:.10f}\" for lr in (param_group[\"lr\"] for param_group in optimizer.param_groups)]}')\n",
    "\n",
    "                iter_one_val_time_end = time.time()\n",
    "                elapsed_time_val = iter_one_val_time_end - iter_one_val_time_start  # 실행 시간 계산\n",
    "                # print(f\"iter_one_val_time: {elapsed_time_val} seconds\")\n",
    "\n",
    "                # network save\n",
    "                if val_acc_best < val_acc_now:\n",
    "                    val_acc_best = val_acc_now\n",
    "                    if ddp_on == False or torch.distributed.get_rank() == 0:\n",
    "                        # wandb 키면 state_dict아닌거는 저장 안됨\n",
    "                        torch.save(net.state_dict(), f\"net_save/save_now_net_weights_{unique_name}.pth\")\n",
    "                        # torch.save(net, f\"net_save/save_now_net_{unique_name}.pth\")\n",
    "                        # torch.save(net.module.state_dict(), f\"net_save/save_now_net_weights2_{unique_name}.pth\")\n",
    "                        # torch.save(net.module, f\"net_save/save_now_net2_{unique_name}.pth\")\n",
    "                    no_val_best_growth_count = 0\n",
    "                else:\n",
    "                    no_val_best_growth_count = no_val_best_growth_count + 1\n",
    "\n",
    "                if tr_acc_best < tr_acc:\n",
    "                    tr_acc_best = tr_acc\n",
    "                    no_tr_best_growth_count = 0\n",
    "                else:\n",
    "                    no_tr_best_growth_count = no_tr_best_growth_count + 1\n",
    "\n",
    "                tr_epoch_loss = tr_epoch_loss_temp\n",
    "                tr_epoch_loss_temp = 0\n",
    "\n",
    "                if DFA_toggle == True:\n",
    "                    DFA_flag = 1.0 - DFA_flag\n",
    "                    DFA_toggle = False\n",
    "\n",
    "                iter_of_val = True\n",
    "            ####################################################################################################################################################\n",
    "            \n",
    "            ## progress bar update ############################################################################################################\n",
    "            if ddp_on == False or torch.distributed.get_rank() == 0:\n",
    "                if iter_of_val == False:\n",
    "                    iterator.set_description(f\"{iter_acc_string}, iter_loss:{loss:10.6f}, val_best:{100 * val_acc_best:7.2f}%\")  \n",
    "                else:\n",
    "                    iterator.set_description(f\"{iter_acc_string2}, tr/val_loss:{tr_epoch_loss:10.6f}/{val_loss:10.6f}, tr:{100 * tr_acc:7.2f}%, val:{100 * val_acc_now:7.2f}%, val_best:{100 * val_acc_best:7.2f}%\")  \n",
    "                    iter_of_val = False\n",
    "            ####################################################################################################################################\n",
    "            \n",
    "            ## wandb logging ############################################################################################################\n",
    "            if ddp_on == False or torch.distributed.get_rank() == 0:\n",
    "                wandb.log({\"iter_acc\": iter_acc})\n",
    "                wandb.log({\"tr_acc\": tr_acc})\n",
    "                wandb.log({\"val_acc_now\": val_acc_now})\n",
    "                wandb.log({\"val_acc_best\": val_acc_best})\n",
    "                wandb.log({\"summary_val_acc\": val_acc_now})\n",
    "                wandb.log({\"epoch\": epoch})\n",
    "                wandb.log({\"DFA_flag\": DFA_flag}) # DFA mode 바뀌자 마자 바뀌는 게 아니고 validation 한번 했을 때 바뀜.\n",
    "                wandb.log({\"val_loss\": val_loss}) \n",
    "                wandb.log({\"tr_epoch_loss\": tr_epoch_loss}) \n",
    "            ####################################################################################################################################\n",
    "            \n",
    "            \n",
    "            ## accuray 로컬에 저장 하기 위한 코드 #####################################################################################\n",
    "            iter_acc_array = np.append(iter_acc_array, iter_acc)\n",
    "            tr_acc_array = np.append(tr_acc_array, tr_acc)\n",
    "            val_acc_now_array = np.append(val_acc_now_array, val_acc_now)\n",
    "            base_name = f'{current_time}'\n",
    "            ####################################################################################################################\n",
    "            \n",
    "            iter_acc_file_name_time = f'result_save/{base_name}_iter_acc_array_{unique_name}.npy'\n",
    "            tr_acc_file_name_time = f'result_save/{base_name}_tr_acc_array_{unique_name}.npy'\n",
    "            val_acc_file_name_time = f'result_save/{base_name}_val_acc_now_array_{unique_name}.npy'\n",
    "            hyperparameters_file_name_time = f'result_save/{base_name}_hyperparameters_{unique_name}.json'\n",
    "\n",
    "            hyperparameters['current epoch'] = epoch\n",
    "\n",
    "            ### accuracy 세이브: 덮어쓰기 하기 싫으면 주석 풀어서 사용 (시간마다 새로 쓰기) 비추천 ########################\n",
    "            # if ddp_on == False or torch.distributed.get_rank() == 0:\n",
    "            #     np.save(iter_acc_file_name_time, iter_acc_array)\n",
    "            #     np.save(tr_acc_file_name_time, iter_acc_array)\n",
    "            #     np.save(val_acc_file_name_time, val_acc_now_array)\n",
    "            #     with open(hyperparameters_file_name_time, 'w') as f:\n",
    "            #         json.dump(hyperparameters, f, indent=4)\n",
    "            #########################################################################################################\n",
    "\n",
    "            ## accuracy 세이브 ###########################################################################################\n",
    "            if ddp_on == False or torch.distributed.get_rank() == 0:\n",
    "                np.save(f'result_save/iter_acc_array_{unique_name}.npy', iter_acc_array)\n",
    "                np.save(f'result_save/tr_acc_array_{unique_name}.npy', tr_acc_array)\n",
    "                np.save(f'result_save/val_acc_now_array_{unique_name}.npy', val_acc_now_array)\n",
    "                with open(f'result_save/hyperparameters_{unique_name}.json', 'w') as f:\n",
    "                    json.dump(hyperparameters, f, indent=4)\n",
    "            ##########################################################################################################\n",
    "        ###### ITERATION END ##########################################################################################################\n",
    "                \n",
    "\n",
    "        ## scheduler update #############################################################################\n",
    "        if (scheduler_name != 'no'):\n",
    "            if (scheduler_name == 'ReduceLROnPlateau'):\n",
    "                scheduler.step(val_loss)\n",
    "            else:\n",
    "                scheduler.step()\n",
    "        #################################################################################################\n",
    "        \n",
    "        # 실행 시간 계산\n",
    "        epoch_time_end = time.time()\n",
    "        # print(f\"epoch_time: {epoch_time_end - epoch_start_time} seconds\\n\") \n",
    "    #======== EPOCH END ==========================================================================================\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ### my_snn control board (Gesture) ########################\n",
    "# decay = 0.25 # 0.875 0.25 0.125 0.75 0.5\n",
    "# # nda 0.25 # ottt 0.5\n",
    "# const2 = False # trace 할거면 True, 안할거면 False\n",
    "\n",
    "# unique_name = 'main' ## 이거 설정하면 새로운 경로에 모두 save\n",
    "# run_name = 'main' ## 이거 설정하면 새로운 경로에 모두 save\n",
    "\n",
    "# if const2 == True:\n",
    "#     const2 = decay\n",
    "# else:\n",
    "#     const2 = 0.0\n",
    "\n",
    "# wandb.init(project= f'my_snn {unique_name}',save_code=True)\n",
    "\n",
    "# my_snn_system(  devices = \"2\",\n",
    "#                 single_step = True, # True # False\n",
    "#                 unique_name = run_name,\n",
    "#                 my_seed = 42,\n",
    "#                 TIME = 10 , # dvscifar 10 # ottt 6 or 10 # nda 10  # 제작하는 dvs에서 TIME넘거나 적으면 자르거나 PADDING함\n",
    "#                 BATCH = 16, # batch norm 할거면 2이상으로 해야함   # nda 256   #  ottt 128\n",
    "#                 IMAGE_SIZE = 128, # dvscifar 48 # MNIST 28 # CIFAR10 32 # PMNIST 28 #NMNIST 34 # GESTURE 128\n",
    "#                 # dvsgesture 128, dvs_cifar2 128, nmnist 34, n_caltech101 180,240, n_tidigits 64, heidelberg 700, \n",
    "#                 #pmnist는 28로 해야 됨. 나머지는 바꿔도 돌아는 감.\n",
    "\n",
    "#                 # DVS_CIFAR10 할거면 time 10으로 해라\n",
    "#                 which_data = 'DVS_GESTURE_TONIC',\n",
    "# # 'CIFAR100' 'CIFAR10' 'MNIST' 'FASHION_MNIST' 'DVS_CIFAR10' 'PMNIST'아직\n",
    "# # 'DVS_GESTURE', 'DVS_GESTURE_TONIC','DVS_CIFAR10_2','NMNIST','NMNIST_TONIC','N_CALTECH101','n_tidigits','heidelberg'\n",
    "#                 # CLASS_NUM = 10,\n",
    "#                 data_path = '/data2', # YOU NEED TO CHANGE THIS\n",
    "#                 rate_coding = False, # True # False\n",
    "#                 lif_layer_v_init = 0.0,\n",
    "#                 lif_layer_v_decay = decay,\n",
    "#                 lif_layer_v_threshold = 0.5,  # 10000이상으로 하면 NDA LIF 씀. #nda 0.5  #ottt 1.0\n",
    "#                 lif_layer_v_reset = 0, # 10000이상은 hardreset (내 LIF쓰기는 함 ㅇㅇ)\n",
    "#                 lif_layer_sg_width = 2.570969004857107, # sigmoid류에서는 alpha값 4.0, rectangle류에서는 width값 0.5\n",
    "\n",
    "#                 # synapse_conv_in_channels = IMAGE_PIXEL_CHANNEL,\n",
    "#                 synapse_conv_kernel_size = 3,\n",
    "#                 synapse_conv_stride = 1,\n",
    "#                 synapse_conv_padding = 1,\n",
    "#                 synapse_conv_trace_const1 = 1, # 현재 trace구할 때 현재 spike에 곱해지는 상수. 걍 1로 두셈.\n",
    "#                 synapse_conv_trace_const2 = const2, # 현재 trace구할 때 직전 trace에 곱해지는 상수. lif_layer_v_decay와 같게 할 것을 추천\n",
    "\n",
    "#                 # synapse_fc_out_features = CLASS_NUM,\n",
    "#                 synapse_fc_trace_const1 = 1, # 현재 trace구할 때 현재 spike에 곱해지는 상수. 걍 1로 두셈.\n",
    "#                 synapse_fc_trace_const2 = const2, # 현재 trace구할 때 직전 trace에 곱해지는 상수. lif_layer_v_decay와 같게 할 것을 추천\n",
    "\n",
    "#                 pre_trained = False, # True # False\n",
    "#                 convTrue_fcFalse = False, # True # False\n",
    "\n",
    "#                 # 'P' for average pooling, 'D' for (1,1) aver pooling, 'M' for maxpooling, 'L' for linear classifier, [  ] for residual block\n",
    "#                 # conv에서 10000 이상은 depth-wise separable (BPTT만 지원), 20000이상은 depth-wise (BPTT만 지원)\n",
    "#                 # cfg = [64, 64],\n",
    "#                 # cfg = [64, 124, 64, 124],\n",
    "#                 # cfg = ['M','M',512], \n",
    "#                 # cfg = [512], \n",
    "#                 # cfg = ['M', 'M', 64, 128, 'P', 128, 'P'], \n",
    "#                 # cfg = ['M','M',512],\n",
    "#                 # cfg = ['M','M',200,200],\n",
    "#                 cfg = ['M','M',200,200,200],\n",
    "#                 # cfg = ['M','M',1024,512,256,128,64],\n",
    "#                 # cfg = [200,200],\n",
    "#                 # cfg = [12], #fc\n",
    "#                 # cfg = [12, 'M', 48, 'M', 12], \n",
    "#                 # cfg = [64,[64,64],64], # 끝에 linear classifier 하나 자동으로 붙습니다\n",
    "#                 # cfg = [64, 128, 'P', 256, 256, 'P', 512, 512, 'P', 512, 512, 'D'], #ottt\n",
    "#                 # cfg = [64, 128, 'P', 256, 256, 'P', 512, 512, 'P', 512, 512], \n",
    "#                 # cfg = [64, 128, 'M', 256, 256, 'M', 512, 512, 'M', 512, 512], \n",
    "#                 # cfg = [64, 'P', 128, 'P', 256, 256, 'P', 512, 512, 512, 512, 'D'], # nda\n",
    "#                 # cfg = [64, 'P', 128, 'P', 256, 256, 'P', 512, 512, 512, 512], # nda 128pixel\n",
    "#                 # cfg = [64, 'P', 128, 'P', 256, 256, 'P', 512, 512, 512, 512, 'L', 4096, 4096],\n",
    "#                 # cfg = [20001,10001], # depthwise, separable\n",
    "#                 # cfg = [64,20064,10001], # vanilla conv, depthwise, separable\n",
    "#                 # cfg = [8, 'P', 8, 'P', 8, 'P', 8,'P', 8, 'P'],\n",
    "#                 # cfg = [],        \n",
    "                \n",
    "#                 net_print = True, # True # False # True로 하길 추천\n",
    "#                 weight_count_print = False, # True # False\n",
    "                \n",
    "#                 pre_trained_path = f\"net_save/save_now_net_weights_{unique_name}.pth\",\n",
    "#                 learning_rate = 0.001, #0.1 bptt, #0.01 ottt, # default 0.001  # ottt 0.1 # nda 0.001 # 0.00936191669529645\n",
    "#                 epoch_num = 60,\n",
    "#                 verbose_interval = 999999999, #이거 걍 건들지마셈 #숫자 크게 하면 꺼짐 #걍 중간중간 iter에서 끊어서 출력\n",
    "#                 validation_interval =  999999999,#999999999, #이거 걍 건들지마셈 #숫자 크게 하면 에포크 마지막 iter 때 val 함\n",
    "\n",
    "#                 tdBN_on = False,  # True # False\n",
    "#                 BN_on = False,  # True # False\n",
    "                \n",
    "#                 surrogate = 'hard_sigmoid', # 'sigmoid' 'rectangle' 'rough_rectangle' 'hard_sigmoid'\n",
    "                \n",
    "#                 gradient_verbose = False,  # True # False  # weight gradient 각 layer마다 띄워줌\n",
    "\n",
    "#                 BPTT_on = False,  # True # False # True이면 BPTT, False이면 OTTT  # depthwise, separable은 BPTT만 가능\n",
    "#                 optimizer_what = 'SGD', # 'SGD' 'Adam', 'RMSprop'\n",
    "#                 scheduler_name = 'CosineAnnealingLR', # 'no' 'StepLR' 'ExponentialLR' 'ReduceLROnPlateau' 'CosineAnnealingLR' 'OneCycleLR'\n",
    "                \n",
    "#                 ddp_on = False,   # True # False \n",
    "#                 # 지원 DATASET: cifar10, mnist\n",
    "\n",
    "#                 nda_net = False,   # True # False\n",
    "\n",
    "#                 domain_il_epoch = 0, # over 0, then domain il mode on # pmnist 쓸거면 HLOP 코드보고 더 디벨롭하셈. 지금 개발 hold함.\n",
    "                \n",
    "#                 dvs_clipping = 2, # 숫자만큼 크면 spike 아니면 걍 0\n",
    "#                 # gesture, cifar-dvs2, nmnist, ncaltech101\n",
    "\n",
    "#                 dvs_duration = 100_000, # 0 아니면 time sampling # dvs number sampling OR time sampling # gesture, cifar-dvs2, nmnist, ncaltech101\n",
    "#                 # 있는 데이터들 #gesture 100_000 25_000 10_000 1_000 1_000_000 #nmnist 10000 #nmnist_tonic 10_000 25_000\n",
    "#                 # 한 숫자가 1us인듯 (spikingjelly코드에서)\n",
    "#                 # 한 장에 50 timestep만 생산함. 싫으면 my_snn/trying/spikingjelly_dvsgesture의__init__.py 를 참고해봐\n",
    "\n",
    "#                 OTTT_sWS_on = False, # True # False # BPTT끄고, CONV에만 적용됨.\n",
    "\n",
    "#                 DFA_on = False, # True # False # residual은 dfa지원안함.\n",
    "#                 OTTT_input_trace_on = False, # True # False # 맨 처음 input에 trace 적용\n",
    "                 \n",
    "#                 e_transport_swap = 0, # 1 이상이면 해당 숫자 에포크만큼 val_acc_best가 변화가 없으면 e_transport scheme (BP vs DFA) swap\n",
    "#                 e_transport_swap_tr = 0, # 1 이상이면 해당 숫자 에포크만큼 tr_acc_best가 변화가 없으면 e_transport scheme (BP vs DFA) swap\n",
    "#                 e_transport_swap_coin = 1, # swap할 수 있는 coin 개수\n",
    "\n",
    "#                 drop_rate = 0.0, # drop_rate만큼 0으로 만듦. ex) 0.2면 activation의 20%를 0으로 만듦.\n",
    "\n",
    "#                 exclude_class = True, # True # False # gesture에서 10번째 클래스 제외\n",
    "\n",
    "#                 merge_polarities = False, # True # False # tonic dvs dataset 에서 polarities 합치기\n",
    "#                 ) \n",
    "# # sigmoid와 BN이 있어야 잘된다.\n",
    "# # average pooling  \n",
    "# # 이 낫다. \n",
    " \n",
    "# # nda에서는 decay = 0.25, threshold = 0.5, width =1, surrogate = rectangle, batch = 256, tdBN = True\n",
    "# ## OTTT 에서는 decay = 0.5, threshold = 1.0, surrogate = sigmoid, batch = 128, BN = True\n",
    "\n",
    "\n",
    "# # DDP 실행 코드\n",
    "# '''\n",
    "# ddp_on 키고, gpu 개수 만큼 batch size 나눠줘\n",
    "# CUDA_VISIBLE_DEVICES=0,1,2,3,4,5 python -m torch.distributed.launch --nproc_per_node=6 main_ddp.py\n",
    "# CUDA_VISIBLE_DEVICES=1,2,3 python -m torch.distributed.launch --nproc_per_node=3 main_ddp.py\n",
    "# CUDA_VISIBLE_DEVICES=0,1,2,3 python -m torch.distributed.launch --nproc_per_node=4 main_ddp.py\n",
    "# '''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ### my_snn control board (NMNIST) ########################\n",
    "# decay = 0.25 # 0.875 0.25 0.125 0.75 0.5\n",
    "# # nda 0.25 # ottt 0.5\n",
    "# const2 = False # trace 할거면 True, 안할거면 False\n",
    "\n",
    "# unique_name = 'main' ## 이거 설정하면 새로운 경로에 모두 save\n",
    "# run_name = 'main' ## 이거 설정하면 새로운 경로에 모두 save\n",
    "\n",
    "# if const2 == True:\n",
    "#     const2 = decay\n",
    "# else:\n",
    "#     const2 = 0.0\n",
    "\n",
    "# wandb.init(project= f'my_snn {unique_name}',save_code=True)\n",
    "\n",
    "# my_snn_system(  devices = \"4\",\n",
    "#                 single_step = True, # True # False\n",
    "#                 unique_name = run_name,\n",
    "#                 my_seed = 42,\n",
    "#                 TIME = 10 , # dvscifar 10 # ottt 6 or 10 # nda 10  # 제작하는 dvs에서 TIME넘거나 적으면 자르거나 PADDING함\n",
    "#                 BATCH = 128, # batch norm 할거면 2이상으로 해야함   # nda 256   #  ottt 128\n",
    "#                 IMAGE_SIZE = 34, # dvscifar 48 # MNIST 28 # CIFAR10 32 # PMNIST 28 #NMNIST 34 # GESTURE 128\n",
    "#                 # dvsgesture 128, dvs_cifar2 128, nmnist 34, n_caltech101 180,240, n_tidigits 64, heidelberg 700, \n",
    "#                 #pmnist는 28로 해야 됨. 나머지는 바꿔도 돌아는 감.\n",
    "\n",
    "#                 # DVS_CIFAR10 할거면 time 10으로 해라\n",
    "#                 which_data = 'NMNIST_TONIC',\n",
    "# # 'CIFAR100' 'CIFAR10' 'MNIST' 'FASHION_MNIST' 'DVS_CIFAR10' 'PMNIST'아직\n",
    "# # 'DVS_GESTURE', 'DVS_GESTURE_TONIC','DVS_CIFAR10_2','NMNIST','NMNIST_TONIC','N_CALTECH101','n_tidigits','heidelberg'\n",
    "#                 # CLASS_NUM = 10,\n",
    "#                 data_path = '/data2', # YOU NEED TO CHANGE THIS\n",
    "#                 rate_coding = False, # True # False\n",
    "#                 lif_layer_v_init = 0.0,\n",
    "#                 lif_layer_v_decay = decay,\n",
    "#                 lif_layer_v_threshold = 1.0,  # 10000이상으로 하면 NDA LIF 씀. #nda 0.5  #ottt 1.0\n",
    "#                 lif_layer_v_reset = 0, # 10000이상은 hardreset (내 LIF쓰기는 함 ㅇㅇ)\n",
    "#                 lif_layer_sg_width = 0.5, # # surrogate sigmoid 쓸 때는 의미없음\n",
    "\n",
    "#                 # synapse_conv_in_channels = IMAGE_PIXEL_CHANNEL,\n",
    "#                 synapse_conv_kernel_size = 3,\n",
    "#                 synapse_conv_stride = 1,\n",
    "#                 synapse_conv_padding = 1,\n",
    "#                 synapse_conv_trace_const1 = 1, # 현재 trace구할 때 현재 spike에 곱해지는 상수. 걍 1로 두셈.\n",
    "#                 synapse_conv_trace_const2 = const2, # 현재 trace구할 때 직전 trace에 곱해지는 상수. lif_layer_v_decay와 같게 할 것을 추천\n",
    "\n",
    "#                 # synapse_fc_out_features = CLASS_NUM,\n",
    "#                 synapse_fc_trace_const1 = 1, # 현재 trace구할 때 현재 spike에 곱해지는 상수. 걍 1로 두셈.\n",
    "#                 synapse_fc_trace_const2 = const2, # 현재 trace구할 때 직전 trace에 곱해지는 상수. lif_layer_v_decay와 같게 할 것을 추천\n",
    "\n",
    "#                 pre_trained = False, # True # False\n",
    "#                 convTrue_fcFalse = False, # True # False\n",
    "\n",
    "#                 # 'P' for average pooling, 'D' for (1,1) aver pooling, 'M' for maxpooling, 'L' for linear classifier, [  ] for residual block\n",
    "#                 # conv에서 10000 이상은 depth-wise separable (BPTT만 지원), 20000이상은 depth-wise (BPTT만 지원)\n",
    "#                 # cfg = [64, 64],\n",
    "#                 # cfg = [64, 124, 64, 124],\n",
    "#                 # cfg = ['M','M',512], \n",
    "#                 # cfg = [512], \n",
    "#                 # cfg = ['M', 'M', 64, 128, 'P', 128, 'P'], \n",
    "#                 # cfg = ['M','M',512],\n",
    "#                 # cfg = ['M','M',200,200],\n",
    "#                 # cfg = ['M','M',1024,512,256,128,64],\n",
    "#                 cfg = [200,200],\n",
    "#                 # cfg = [12], #fc\n",
    "#                 # cfg = [12, 'M', 48, 'M', 12], \n",
    "#                 # cfg = [64,[64,64],64], # 끝에 linear classifier 하나 자동으로 붙습니다\n",
    "#                 # cfg = [64, 128, 'P', 256, 256, 'P', 512, 512, 'P', 512, 512, 'D'], #ottt\n",
    "#                 # cfg = [64, 128, 'P', 256, 256, 'P', 512, 512, 'P', 512, 512], \n",
    "#                 # cfg = [64, 128, 'M', 256, 256, 'M', 512, 512, 'M', 512, 512], \n",
    "#                 # cfg = [64, 'P', 128, 'P', 256, 256, 'P', 512, 512, 512, 512, 'D'], # nda\n",
    "#                 # cfg = [64, 'P', 128, 'P', 256, 256, 'P', 512, 512, 512, 512], # nda 128pixel\n",
    "#                 # cfg = [64, 'P', 128, 'P', 256, 256, 'P', 512, 512, 512, 512, 'L', 4096, 4096],\n",
    "#                 # cfg = [20001,10001], # depthwise, separable\n",
    "#                 # cfg = [64,20064,10001], # vanilla conv, depthwise, separable\n",
    "#                 # cfg = [8, 'P', 8, 'P', 8, 'P', 8,'P', 8, 'P'],\n",
    "#                 # cfg = [],        \n",
    "                \n",
    "#                 net_print = True, # True # False # True로 하길 추천\n",
    "#                 weight_count_print = False, # True # False\n",
    "                \n",
    "#                 pre_trained_path = f\"net_save/save_now_net_weights_{unique_name}.pth\",\n",
    "#                 learning_rate = 0.009, # 0.001, # default 0.001  # ottt 0.1 # nda 0.001 \n",
    "#                 epoch_num = 300,\n",
    "#                 verbose_interval = 999999999, #이거 걍 건들지마셈 #숫자 크게 하면 꺼짐 #걍 중간중간 iter에서 끊어서 출력\n",
    "#                 validation_interval =  999999999,#999999999, #이거 걍 건들지마셈 #숫자 크게 하면 에포크 마지막 iter 때 val 함\n",
    "\n",
    "#                 tdBN_on = False,  # True # False\n",
    "#                 BN_on = False,  # True # False\n",
    "                \n",
    "#                 surrogate = 'hard_sigmoid', # 'rectangle' 'sigmoid' 'rough_rectangle' 'hard_sigmoid'\n",
    "                \n",
    "#                 gradient_verbose = False,  # True # False  # weight gradient 각 layer마다 띄워줌\n",
    "\n",
    "#                 BPTT_on = False,  # True # False # True이면 BPTT, False이면 OTTT  # depthwise, separable은 BPTT만 가능\n",
    "#                 optimizer_what = 'SGD', # 'SGD' 'Adam', 'RMSprop'\n",
    "#                 scheduler_name = 'CosineAnnealingLR', # 'no' 'StepLR' 'ExponentialLR' 'ReduceLROnPlateau' 'CosineAnnealingLR' 'OneCycleLR'\n",
    "                \n",
    "#                 ddp_on = False,   # True # False \n",
    "#                 # 지원 DATASET: cifar10, mnist\n",
    "\n",
    "#                 nda_net = False,   # True # False\n",
    "\n",
    "#                 domain_il_epoch = 0, # over 0, then domain il mode on # pmnist 쓸거면 HLOP 코드보고 더 디벨롭하셈. 지금 개발 hold함.\n",
    "                \n",
    "#                 dvs_clipping = 1, # 숫자만큼 크면 spike 아니면 걍 0\n",
    "#                 # gesture, cifar-dvs2, nmnist, ncaltech101\n",
    "\n",
    "#                 dvs_duration = 10_000, # 0 아니면 time sampling # dvs number sampling OR time sampling # gesture, cifar-dvs2, nmnist, ncaltech101\n",
    "#                 # 있는 데이터들 #gesture 100_000 25_000 10_000 1_000 1_000_000 #nmnist 10000 #nmnist_tonic 10_000 25_000\n",
    "#                 # 한 숫자가 1us인듯 (spikingjelly코드에서)\n",
    "#                 # 한 장에 50 timestep만 생산함. 싫으면 my_snn/trying/spikingjelly_dvsgesture의__init__.py 를 참고해봐\n",
    "\n",
    "#                 OTTT_sWS_on = False, # True # False # BPTT끄고, CONV에만 적용됨.\n",
    "\n",
    "#                 DFA_on = True, # True # False # residual은 dfa지원안함.\n",
    "#                 OTTT_input_trace_on = False, # True # False # 맨 처음 input에 trace 적용\n",
    "                 \n",
    "#                 e_transport_swap = 5, # 1 이상이면 해당 숫자 에포크만큼 val_acc_best가 변화가 없으면 e_transport scheme (BP vs DFA) swap\n",
    "#                 e_transport_swap_tr = 0, # 1 이상이면 해당 숫자 에포크만큼 tr_acc_best가 변화가 없으면 e_transport scheme (BP vs DFA) swap\n",
    "#                 e_transport_swap_coin = 1, # swap할 수 있는 coin 개수\n",
    "                \n",
    "#                 drop_rate = 0.0, # drop_rate만큼 0으로 만듦. ex) 0.2면 activation의 20%를 0으로 만듦.\n",
    "\n",
    "#                 exclude_class = True, # True # False # gesture에서 10번째 클래스 제외\n",
    "\n",
    "#                 merge_polarities = False, # True # False # tonic dvs dataset 에서 polarities 합치기\n",
    "#                 ) \n",
    "# # sigmoid와 BN이 있어야 잘된다.\n",
    "# # average pooling  \n",
    "# # 이 낫다. \n",
    " \n",
    "# # nda에서는 decay = 0.25, threshold = 0.5, width =1, surrogate = rectangle, batch = 256, tdBN = True\n",
    "# ## OTTT 에서는 decay = 0.5, threshold = 1.0, surrogate = sigmoid, batch = 128, BN = True\n",
    "\n",
    "\n",
    "# # DDP 실행 코드\n",
    "# '''\n",
    "# ddp_on 키고, gpu 개수 만큼 batch size 나눠줘\n",
    "# CUDA_VISIBLE_DEVICES=0,1,2,3,4,5 python -m torch.distributed.launch --nproc_per_node=6 main_ddp.py\n",
    "# CUDA_VISIBLE_DEVICES=1,2,3 python -m torch.distributed.launch --nproc_per_node=3 main_ddp.py\n",
    "# CUDA_VISIBLE_DEVICES=0,1,2,3 python -m torch.distributed.launch --nproc_per_node=4 main_ddp.py\n",
    "# '''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: o23ycpm6 with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBATCH: 16\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tDFA_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tIMAGE_SIZE: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tOTTT_input_trace_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tOTTT_sWS_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tTIME: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcfg: ['M', 'M', 200, 200]\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tconst2: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdecay: 0.25\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdrop_rate: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdvs_clipping: 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdvs_duration: 100000\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \te_transport_swap: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \te_transport_swap_coin: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \te_transport_swap_tr: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepoch_num: 60\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \texclude_class: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.01\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_sg_width: 2.570969004857107\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_reset: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_threshold: 1.094869666474513\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmerge_polarities: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tscheduler_name: CosineAnnealingLR\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsurrogate: hard_sigmoid\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \twhich_data: DVS_GESTURE_TONIC\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mbhkim003\u001b[0m (\u001b[33mbhkim003-seoul-national-university\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7708c4d0ee384d1eb611e8f7e76e660f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.011112712189141246, max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.17.7 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.17.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/nfs/home/bhkim003/github_folder/ByeonghyeonKim/my_snn/wandb/run-20240822_170632-o23ycpm6</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/o23ycpm6' target=\"_blank\">swift-sweep-3</a></strong> to <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/yxynyr6h' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/yxynyr6h</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/yxynyr6h' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/yxynyr6h</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/o23ycpm6' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/o23ycpm6</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BATCH' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'IMAGE_SIZE' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'which_data' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_threshold' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_reset' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_sg_width' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'cfg' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'learning_rate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'epoch_num' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'surrogate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'scheduler_name' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'dvs_clipping' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'dvs_duration' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'OTTT_sWS_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'DFA_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'OTTT_input_trace_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'e_transport_swap' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'e_transport_swap_tr' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'e_transport_swap_coin' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'drop_rate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'exclude_class' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'merge_polarities' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'TIME' was locked by 'sweep' (ignored update).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset_hash = 2bbd58b4e0d3c1e9ad501fad8a43feed\n",
      "cache path exists\n",
      "\n",
      "we will exclude the 'other' class. dvsgestrue 10 classes' indices exist. \n",
      "\n",
      "DataParallel(\n",
      "  (module): MY_SNN_FC_sstep(\n",
      "    (layers): MY_Sequential(\n",
      "      (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (2): DimChanger_for_FC_sstep()\n",
      "      (3): SYNAPSE_FC_trace_sstep()\n",
      "      (4): LIF_layer_trace_sstep()\n",
      "      (5): SYNAPSE_FC_trace_sstep()\n",
      "      (6): LIF_layer_trace_sstep()\n",
      "      (7): SYNAPSE_FC_trace_sstep()\n",
      "    )\n",
      "  )\n",
      ")\n",
      "==================================================\n",
      "My Num of PARAMS: 452,010, system's param_num : 452,010\n",
      "Memory: 1.72MiB at 32-bit\n",
      "==================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch-0   lr=['0.0100000'], tr/val_loss:  2.197065/  1.644941, tr:  17.57%, val:  41.25%, val_best:  41.25%: 100%|██████████| 62/62 [00:23<00:00,  2.63it/s]\n",
      "epoch-1   lr=['0.0099931'], tr/val_loss:  1.318826/  1.348763, tr:  54.55%, val:  53.33%, val_best:  53.33%: 100%|██████████| 62/62 [00:42<00:00,  1.45it/s]\n",
      "epoch-2   lr=['0.0099726'], tr/val_loss:  1.102448/  1.232747, tr:  63.64%, val:  60.83%, val_best:  60.83%: 100%|██████████| 62/62 [00:20<00:00,  3.02it/s]\n",
      "epoch-3   lr=['0.0099384'], tr/val_loss:  0.978218/  1.153138, tr:  67.72%, val:  62.50%, val_best:  62.50%: 100%|██████████| 62/62 [00:21<00:00,  2.85it/s]\n",
      "epoch-4   lr=['0.0098907'], tr/val_loss:  0.928283/  1.283194, tr:  68.13%, val:  56.67%, val_best:  62.50%: 100%|██████████| 62/62 [00:20<00:00,  2.97it/s]\n",
      "epoch-5   lr=['0.0098296'], tr/val_loss:  0.871296/  1.262501, tr:  67.42%, val:  65.42%, val_best:  65.42%: 100%|██████████| 62/62 [00:21<00:00,  2.87it/s]\n",
      "epoch-6   lr=['0.0097553'], tr/val_loss:  0.785576/  1.267414, tr:  70.38%, val:  60.42%, val_best:  65.42%: 100%|██████████| 62/62 [00:17<00:00,  3.48it/s]\n",
      "epoch-7   lr=['0.0096679'], tr/val_loss:  0.747285/  1.294394, tr:  72.83%, val:  58.75%, val_best:  65.42%: 100%|██████████| 62/62 [00:18<00:00,  3.41it/s]\n",
      "epoch-8   lr=['0.0095677'], tr/val_loss:  0.743513/  1.086263, tr:  72.63%, val:  69.17%, val_best:  69.17%: 100%|██████████| 62/62 [00:18<00:00,  3.44it/s]\n",
      "epoch-9   lr=['0.0094550'], tr/val_loss:  0.570860/  1.240653, tr:  78.35%, val:  67.92%, val_best:  69.17%: 100%|██████████| 62/62 [00:23<00:00,  2.68it/s]\n",
      "epoch-10  lr=['0.0093301'], tr/val_loss:  0.561555/  1.264592, tr:  79.47%, val:  66.67%, val_best:  69.17%: 100%|██████████| 62/62 [00:20<00:00,  3.08it/s]\n",
      "epoch-11  lr=['0.0091934'], tr/val_loss:  0.524061/  1.347424, tr:  79.78%, val:  67.50%, val_best:  69.17%: 100%|██████████| 62/62 [00:22<00:00,  2.78it/s]\n",
      "epoch-12  lr=['0.0090451'], tr/val_loss:  0.509898/  1.190273, tr:  82.94%, val:  70.83%, val_best:  70.83%: 100%|██████████| 62/62 [00:20<00:00,  3.07it/s]\n",
      "epoch-13  lr=['0.0088857'], tr/val_loss:  0.460390/  1.183507, tr:  85.09%, val:  68.33%, val_best:  70.83%: 100%|██████████| 62/62 [00:22<00:00,  2.79it/s]\n",
      "epoch-14  lr=['0.0087157'], tr/val_loss:  0.354726/  1.186702, tr:  89.58%, val:  76.25%, val_best:  76.25%: 100%|██████████| 62/62 [00:21<00:00,  2.89it/s]\n",
      "epoch-15  lr=['0.0085355'], tr/val_loss:  0.365923/  1.324382, tr:  90.19%, val:  73.75%, val_best:  76.25%: 100%|██████████| 62/62 [00:19<00:00,  3.21it/s]\n",
      "epoch-16  lr=['0.0083457'], tr/val_loss:  0.311172/  1.485789, tr:  92.54%, val:  75.00%, val_best:  76.25%: 100%|██████████| 62/62 [00:17<00:00,  3.49it/s]\n",
      "epoch-17  lr=['0.0081466'], tr/val_loss:  0.306221/  1.303205, tr:  93.56%, val:  77.92%, val_best:  77.92%: 100%|██████████| 62/62 [00:19<00:00,  3.13it/s]\n",
      "epoch-18  lr=['0.0079389'], tr/val_loss:  0.292379/  1.328406, tr:  93.77%, val:  75.00%, val_best:  77.92%: 100%|██████████| 62/62 [00:22<00:00,  2.75it/s]\n",
      "epoch-19  lr=['0.0077232'], tr/val_loss:  0.214212/  1.383984, tr:  96.22%, val:  80.00%, val_best:  80.00%: 100%|██████████| 62/62 [00:23<00:00,  2.60it/s]\n",
      "epoch-20  lr=['0.0075000'], tr/val_loss:  0.169265/  1.344182, tr:  98.16%, val:  75.83%, val_best:  80.00%: 100%|██████████| 62/62 [00:21<00:00,  2.92it/s]\n",
      "epoch-21  lr=['0.0072700'], tr/val_loss:  0.139140/  1.535376, tr:  99.59%, val:  72.92%, val_best:  80.00%: 100%|██████████| 62/62 [00:22<00:00,  2.81it/s]\n",
      "epoch-22  lr=['0.0070337'], tr/val_loss:  0.137997/  1.403625, tr:  97.96%, val:  76.25%, val_best:  80.00%: 100%|██████████| 62/62 [00:20<00:00,  3.00it/s]\n",
      "epoch-23  lr=['0.0067918'], tr/val_loss:  0.088977/  1.478644, tr:  99.69%, val:  74.58%, val_best:  80.00%: 100%|██████████| 62/62 [00:21<00:00,  2.86it/s]\n",
      "epoch-24  lr=['0.0065451'], tr/val_loss:  0.090420/  1.484924, tr:  99.59%, val:  79.58%, val_best:  80.00%: 100%|██████████| 62/62 [00:21<00:00,  2.91it/s]\n",
      "epoch-25  lr=['0.0062941'], tr/val_loss:  0.073514/  1.444595, tr:  99.69%, val:  78.33%, val_best:  80.00%: 100%|██████████| 62/62 [00:21<00:00,  2.88it/s]\n",
      "epoch-26  lr=['0.0060396'], tr/val_loss:  0.043408/  1.530136, tr: 100.00%, val:  79.17%, val_best:  80.00%: 100%|██████████| 62/62 [00:20<00:00,  3.09it/s]\n",
      "epoch-27  lr=['0.0057822'], tr/val_loss:  0.031512/  1.582517, tr: 100.00%, val:  77.92%, val_best:  80.00%: 100%|██████████| 62/62 [00:22<00:00,  2.79it/s]\n",
      "epoch-28  lr=['0.0055226'], tr/val_loss:  0.020300/  1.551647, tr: 100.00%, val:  81.25%, val_best:  81.25%: 100%|██████████| 62/62 [00:20<00:00,  3.00it/s]\n",
      "epoch-29  lr=['0.0052617'], tr/val_loss:  0.013282/  1.542423, tr: 100.00%, val:  82.50%, val_best:  82.50%: 100%|██████████| 62/62 [00:18<00:00,  3.33it/s]\n",
      "epoch-30  lr=['0.0050000'], tr/val_loss:  0.010208/  1.588260, tr: 100.00%, val:  82.50%, val_best:  82.50%: 100%|██████████| 62/62 [00:20<00:00,  3.04it/s]\n",
      "epoch-31  lr=['0.0047383'], tr/val_loss:  0.007766/  1.554587, tr: 100.00%, val:  82.08%, val_best:  82.50%: 100%|██████████| 62/62 [00:20<00:00,  3.04it/s]\n",
      "epoch-32  lr=['0.0044774'], tr/val_loss:  0.006972/  1.615507, tr: 100.00%, val:  83.33%, val_best:  83.33%: 100%|██████████| 62/62 [00:16<00:00,  3.76it/s]\n",
      "epoch-33  lr=['0.0042178'], tr/val_loss:  0.005235/  1.646346, tr: 100.00%, val:  80.83%, val_best:  83.33%: 100%|██████████| 62/62 [00:21<00:00,  2.89it/s]\n",
      "epoch-34  lr=['0.0039604'], tr/val_loss:  0.004050/  1.632433, tr: 100.00%, val:  82.50%, val_best:  83.33%: 100%|██████████| 62/62 [00:21<00:00,  2.85it/s]\n",
      "epoch-35  lr=['0.0037059'], tr/val_loss:  0.003409/  1.631384, tr: 100.00%, val:  82.50%, val_best:  83.33%: 100%|██████████| 62/62 [00:18<00:00,  3.32it/s]\n",
      "epoch-36  lr=['0.0034549'], tr/val_loss:  0.003110/  1.640810, tr: 100.00%, val:  82.50%, val_best:  83.33%: 100%|██████████| 62/62 [00:18<00:00,  3.34it/s]\n",
      "epoch-37  lr=['0.0032082'], tr/val_loss:  0.002907/  1.645134, tr: 100.00%, val:  81.25%, val_best:  83.33%: 100%|██████████| 62/62 [00:17<00:00,  3.56it/s]\n",
      "epoch-38  lr=['0.0029663'], tr/val_loss:  0.002758/  1.646548, tr: 100.00%, val:  82.08%, val_best:  83.33%: 100%|██████████| 62/62 [00:18<00:00,  3.27it/s]\n",
      "epoch-39  lr=['0.0027300'], tr/val_loss:  0.002617/  1.654310, tr: 100.00%, val:  82.92%, val_best:  83.33%: 100%|██████████| 62/62 [00:24<00:00,  2.51it/s]\n",
      "epoch-40  lr=['0.0025000'], tr/val_loss:  0.002500/  1.653106, tr: 100.00%, val:  82.50%, val_best:  83.33%: 100%|██████████| 62/62 [00:19<00:00,  3.19it/s]\n",
      "epoch-41  lr=['0.0022768'], tr/val_loss:  0.002314/  1.660906, tr: 100.00%, val:  82.92%, val_best:  83.33%: 100%|██████████| 62/62 [00:07<00:00,  8.09it/s]\n",
      "epoch-42  lr=['0.0020611'], tr/val_loss:  0.002193/  1.666398, tr: 100.00%, val:  82.08%, val_best:  83.33%: 100%|██████████| 62/62 [00:07<00:00,  8.38it/s]\n",
      "epoch-43  lr=['0.0018534'], tr/val_loss:  0.002112/  1.677971, tr: 100.00%, val:  82.08%, val_best:  83.33%: 100%|██████████| 62/62 [00:11<00:00,  5.59it/s]\n",
      "epoch-44  lr=['0.0016543'], tr/val_loss:  0.002035/  1.679546, tr: 100.00%, val:  82.92%, val_best:  83.33%: 100%|██████████| 62/62 [00:22<00:00,  2.77it/s]\n",
      "epoch-45  lr=['0.0014645'], tr/val_loss:  0.001977/  1.680220, tr: 100.00%, val:  82.50%, val_best:  83.33%: 100%|██████████| 62/62 [00:18<00:00,  3.42it/s]\n",
      "epoch-46  lr=['0.0012843'], tr/val_loss:  0.001914/  1.682925, tr: 100.00%, val:  81.67%, val_best:  83.33%: 100%|██████████| 62/62 [00:23<00:00,  2.68it/s]\n",
      "epoch-47  lr=['0.0011143'], tr/val_loss:  0.001878/  1.677695, tr: 100.00%, val:  81.67%, val_best:  83.33%: 100%|██████████| 62/62 [00:23<00:00,  2.67it/s]\n",
      "epoch-48  lr=['0.0009549'], tr/val_loss:  0.001899/  1.674971, tr: 100.00%, val:  81.67%, val_best:  83.33%: 100%|██████████| 62/62 [00:19<00:00,  3.15it/s]\n",
      "epoch-49  lr=['0.0008066'], tr/val_loss:  0.001851/  1.681707, tr: 100.00%, val:  81.67%, val_best:  83.33%: 100%|██████████| 62/62 [00:21<00:00,  2.90it/s]\n",
      "epoch-50  lr=['0.0006699'], tr/val_loss:  0.001886/  1.680349, tr: 100.00%, val:  81.67%, val_best:  83.33%: 100%|██████████| 62/62 [00:21<00:00,  2.87it/s]\n",
      "epoch-51  lr=['0.0005450'], tr/val_loss:  0.001821/  1.684829, tr: 100.00%, val:  81.67%, val_best:  83.33%: 100%|██████████| 62/62 [00:22<00:00,  2.72it/s]\n",
      "epoch-52  lr=['0.0004323'], tr/val_loss:  0.001786/  1.682928, tr: 100.00%, val:  81.67%, val_best:  83.33%: 100%|██████████| 62/62 [00:19<00:00,  3.11it/s]\n",
      "epoch-53  lr=['0.0003321'], tr/val_loss:  0.001806/  1.683708, tr: 100.00%, val:  81.67%, val_best:  83.33%: 100%|██████████| 62/62 [00:21<00:00,  2.92it/s]\n",
      "epoch-54  lr=['0.0002447'], tr/val_loss:  0.001778/  1.683163, tr: 100.00%, val:  82.08%, val_best:  83.33%: 100%|██████████| 62/62 [00:12<00:00,  4.95it/s]\n",
      "epoch-55  lr=['0.0001704'], tr/val_loss:  0.001768/  1.684339, tr: 100.00%, val:  82.08%, val_best:  83.33%: 100%|██████████| 62/62 [00:06<00:00,  9.50it/s]\n",
      "epoch-56  lr=['0.0001093'], tr/val_loss:  0.001747/  1.684556, tr: 100.00%, val:  82.08%, val_best:  83.33%: 100%|██████████| 62/62 [00:05<00:00, 11.53it/s]\n",
      "epoch-57  lr=['0.0000616'], tr/val_loss:  0.001771/  1.685208, tr: 100.00%, val:  82.08%, val_best:  83.33%: 100%|██████████| 62/62 [00:05<00:00, 11.86it/s]\n",
      "epoch-58  lr=['0.0000274'], tr/val_loss:  0.001749/  1.682326, tr: 100.00%, val:  82.08%, val_best:  83.33%: 100%|██████████| 62/62 [00:05<00:00, 11.66it/s]\n",
      "epoch-59  lr=['0.0000069'], tr/val_loss:  0.001758/  1.682332, tr: 100.00%, val:  82.08%, val_best:  83.33%: 100%|██████████| 62/62 [00:05<00:00, 11.33it/s]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f4e29c5e73074529b158b417e60b8359",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='4.497 MB of 4.497 MB uploaded (2.568 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "W&B sync reduced upload amount by 55.4%"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>DFA_flag</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>epoch</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇████</td></tr><tr><td>iter_acc</td><td>▁▅▆▅▇▅▆▇▆▇█▇████████████████████████████</td></tr><tr><td>summary_val_acc</td><td>▁▄▆▆▆▆▇▇▇▇▇▇██▇▇▇███████████████████████</td></tr><tr><td>tr_acc</td><td>▁▂▅▆▆▆▆▆▇▇▇▇████████████████████████████</td></tr><tr><td>tr_epoch_loss</td><td>▁█▅▄▄▄▃▃▃▃▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_acc_best</td><td>▁▄▆▆▆▆▇▇▇▇▇▇████████████████████████████</td></tr><tr><td>val_acc_now</td><td>▁▄▆▆▆▆▇▇▇▇▇▇██▇▇▇███████████████████████</td></tr><tr><td>val_loss</td><td>▁█▆▆▆▆▆▆▇▆▆▇▆▇▇▇▇▇▇▇▇▇██████████████████</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>DFA_flag</td><td>0.0</td></tr><tr><td>epoch</td><td>59</td></tr><tr><td>iter_acc</td><td>1.0</td></tr><tr><td>tr_acc</td><td>1.0</td></tr><tr><td>tr_epoch_loss</td><td>0.00176</td></tr><tr><td>val_acc_best</td><td>0.83333</td></tr><tr><td>val_acc_now</td><td>0.82083</td></tr><tr><td>val_loss</td><td>1.68233</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">swift-sweep-3</strong> at: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/o23ycpm6' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/o23ycpm6</a><br/> View project at: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main</a><br/>Synced 7 W&B file(s), 0 media file(s), 15 artifact file(s) and 1 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20240822_170632-o23ycpm6/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require(\"core\")`! See https://wandb.me/wandb-core for more information."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: n1vwlhg8 with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBATCH: 16\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tDFA_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tIMAGE_SIZE: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tOTTT_input_trace_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tOTTT_sWS_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tTIME: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcfg: ['M', 'M', 200, 200]\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tconst2: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdecay: 0.25\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdrop_rate: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdvs_clipping: 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdvs_duration: 100000\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \te_transport_swap: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \te_transport_swap_coin: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \te_transport_swap_tr: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepoch_num: 60\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \texclude_class: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.01\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_sg_width: 2.570969004857107\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_reset: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_threshold: 0.2540730746004104\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmerge_polarities: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tscheduler_name: CosineAnnealingLR\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsurrogate: hard_sigmoid\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \twhich_data: DVS_GESTURE_TONIC\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.17.7 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.17.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/nfs/home/bhkim003/github_folder/ByeonghyeonKim/my_snn/wandb/run-20240822_172620-n1vwlhg8</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/n1vwlhg8' target=\"_blank\">youthful-sweep-7</a></strong> to <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/yxynyr6h' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/yxynyr6h</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/yxynyr6h' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/yxynyr6h</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/n1vwlhg8' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/n1vwlhg8</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BATCH' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'IMAGE_SIZE' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'which_data' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_threshold' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_reset' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_sg_width' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'cfg' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'learning_rate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'epoch_num' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'surrogate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'scheduler_name' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'dvs_clipping' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'dvs_duration' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'OTTT_sWS_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'DFA_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'OTTT_input_trace_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'e_transport_swap' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'e_transport_swap_tr' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'e_transport_swap_coin' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'drop_rate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'exclude_class' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'merge_polarities' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'TIME' was locked by 'sweep' (ignored update).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset_hash = 2bbd58b4e0d3c1e9ad501fad8a43feed\n",
      "cache path exists\n",
      "\n",
      "we will exclude the 'other' class. dvsgestrue 10 classes' indices exist. \n",
      "\n",
      "DataParallel(\n",
      "  (module): MY_SNN_FC_sstep(\n",
      "    (layers): MY_Sequential(\n",
      "      (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (2): DimChanger_for_FC_sstep()\n",
      "      (3): SYNAPSE_FC_trace_sstep()\n",
      "      (4): LIF_layer_trace_sstep()\n",
      "      (5): SYNAPSE_FC_trace_sstep()\n",
      "      (6): LIF_layer_trace_sstep()\n",
      "      (7): SYNAPSE_FC_trace_sstep()\n",
      "    )\n",
      "  )\n",
      ")\n",
      "==================================================\n",
      "My Num of PARAMS: 452,010, system's param_num : 452,010\n",
      "Memory: 1.72MiB at 32-bit\n",
      "==================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch-0   lr=['0.0100000'], tr/val_loss:  1.496346/  1.338449, tr:  48.52%, val:  50.00%, val_best:  50.00%: 100%|██████████| 62/62 [00:06<00:00,  9.58it/s]\n",
      "epoch-1   lr=['0.0099931'], tr/val_loss:  1.085263/  1.351882, tr:  60.16%, val:  51.67%, val_best:  51.67%: 100%|██████████| 62/62 [00:07<00:00,  8.69it/s]\n",
      "epoch-2   lr=['0.0099726'], tr/val_loss:  0.946589/  1.276514, tr:  63.74%, val:  60.00%, val_best:  60.00%: 100%|██████████| 62/62 [00:06<00:00,  9.80it/s]\n",
      "epoch-3   lr=['0.0099384'], tr/val_loss:  0.844138/  1.087919, tr:  69.77%, val:  64.58%, val_best:  64.58%: 100%|██████████| 62/62 [00:06<00:00,  9.90it/s]\n",
      "epoch-4   lr=['0.0098907'], tr/val_loss:  0.776171/  1.164571, tr:  70.38%, val:  60.83%, val_best:  64.58%: 100%|██████████| 62/62 [00:06<00:00,  9.39it/s]\n",
      "epoch-5   lr=['0.0098296'], tr/val_loss:  0.790628/  1.362115, tr:  70.38%, val:  60.83%, val_best:  64.58%: 100%|██████████| 62/62 [00:05<00:00, 10.99it/s]\n",
      "epoch-6   lr=['0.0097553'], tr/val_loss:  0.665211/  1.194820, tr:  73.14%, val:  62.50%, val_best:  64.58%: 100%|██████████| 62/62 [00:06<00:00, 10.16it/s]\n",
      "epoch-7   lr=['0.0096679'], tr/val_loss:  0.614381/  1.424164, tr:  76.40%, val:  55.83%, val_best:  64.58%: 100%|██████████| 62/62 [00:06<00:00,  9.76it/s]\n",
      "epoch-8   lr=['0.0095677'], tr/val_loss:  0.600320/  1.121499, tr:  76.10%, val:  67.50%, val_best:  67.50%: 100%|██████████| 62/62 [00:06<00:00,  9.34it/s]\n",
      "epoch-9   lr=['0.0094550'], tr/val_loss:  0.457316/  1.307911, tr:  82.33%, val:  63.33%, val_best:  67.50%: 100%|██████████| 62/62 [00:05<00:00, 10.80it/s]\n",
      "epoch-10  lr=['0.0093301'], tr/val_loss:  0.465602/  1.075095, tr:  81.31%, val:  68.33%, val_best:  68.33%: 100%|██████████| 62/62 [00:05<00:00, 10.44it/s]\n",
      "epoch-11  lr=['0.0091934'], tr/val_loss:  0.415555/  1.409744, tr:  82.23%, val:  63.75%, val_best:  68.33%: 100%|██████████| 62/62 [00:06<00:00,  9.98it/s]\n",
      "epoch-12  lr=['0.0090451'], tr/val_loss:  0.451184/  1.214797, tr:  84.88%, val:  71.25%, val_best:  71.25%: 100%|██████████| 62/62 [00:06<00:00,  9.46it/s]\n",
      "epoch-13  lr=['0.0088857'], tr/val_loss:  0.400978/  1.217104, tr:  86.62%, val:  70.42%, val_best:  71.25%: 100%|██████████| 62/62 [00:06<00:00,  9.92it/s]\n",
      "epoch-14  lr=['0.0087157'], tr/val_loss:  0.331093/  1.295567, tr:  91.62%, val:  70.83%, val_best:  71.25%: 100%|██████████| 62/62 [00:06<00:00,  9.79it/s]\n",
      "epoch-15  lr=['0.0085355'], tr/val_loss:  0.330143/  1.208592, tr:  91.73%, val:  75.00%, val_best:  75.00%: 100%|██████████| 62/62 [00:06<00:00,  9.16it/s]\n",
      "epoch-16  lr=['0.0083457'], tr/val_loss:  0.253316/  1.332908, tr:  94.89%, val:  71.67%, val_best:  75.00%: 100%|██████████| 62/62 [00:06<00:00,  9.85it/s]\n",
      "epoch-17  lr=['0.0081466'], tr/val_loss:  0.235037/  1.243366, tr:  94.99%, val:  72.08%, val_best:  75.00%: 100%|██████████| 62/62 [00:06<00:00, 10.02it/s]\n",
      "epoch-18  lr=['0.0079389'], tr/val_loss:  0.241972/  1.345083, tr:  93.87%, val:  75.42%, val_best:  75.42%: 100%|██████████| 62/62 [00:05<00:00, 10.77it/s]\n",
      "epoch-19  lr=['0.0077232'], tr/val_loss:  0.177595/  1.285919, tr:  97.45%, val:  77.50%, val_best:  77.50%: 100%|██████████| 62/62 [00:07<00:00,  8.54it/s]\n",
      "epoch-20  lr=['0.0075000'], tr/val_loss:  0.136487/  1.360480, tr:  99.18%, val:  77.08%, val_best:  77.50%: 100%|██████████| 62/62 [00:05<00:00, 11.17it/s]\n",
      "epoch-21  lr=['0.0072700'], tr/val_loss:  0.079245/  1.417095, tr:  99.90%, val:  76.67%, val_best:  77.50%: 100%|██████████| 62/62 [00:06<00:00,  9.65it/s]\n",
      "epoch-22  lr=['0.0070337'], tr/val_loss:  0.082108/  1.398305, tr:  98.98%, val:  78.33%, val_best:  78.33%: 100%|██████████| 62/62 [00:06<00:00,  9.20it/s]\n",
      "epoch-23  lr=['0.0067918'], tr/val_loss:  0.052081/  1.437621, tr:  99.90%, val:  79.58%, val_best:  79.58%: 100%|██████████| 62/62 [00:06<00:00,  9.17it/s]\n",
      "epoch-24  lr=['0.0065451'], tr/val_loss:  0.034267/  1.457561, tr: 100.00%, val:  80.00%, val_best:  80.00%: 100%|██████████| 62/62 [00:06<00:00, 10.18it/s]\n",
      "epoch-25  lr=['0.0062941'], tr/val_loss:  0.034990/  1.468438, tr: 100.00%, val:  80.00%, val_best:  80.00%: 100%|██████████| 62/62 [00:05<00:00, 11.09it/s]\n",
      "epoch-26  lr=['0.0060396'], tr/val_loss:  0.019083/  1.487478, tr: 100.00%, val:  82.08%, val_best:  82.08%: 100%|██████████| 62/62 [00:06<00:00, 10.23it/s]\n",
      "epoch-27  lr=['0.0057822'], tr/val_loss:  0.011437/  1.484091, tr: 100.00%, val:  81.67%, val_best:  82.08%: 100%|██████████| 62/62 [00:06<00:00,  9.33it/s]\n",
      "epoch-28  lr=['0.0055226'], tr/val_loss:  0.007315/  1.479604, tr: 100.00%, val:  83.75%, val_best:  83.75%: 100%|██████████| 62/62 [00:05<00:00, 11.00it/s]\n",
      "epoch-29  lr=['0.0052617'], tr/val_loss:  0.005209/  1.497185, tr: 100.00%, val:  82.92%, val_best:  83.75%: 100%|██████████| 62/62 [00:06<00:00,  9.74it/s]\n",
      "epoch-30  lr=['0.0050000'], tr/val_loss:  0.004047/  1.483191, tr: 100.00%, val:  82.92%, val_best:  83.75%: 100%|██████████| 62/62 [00:06<00:00,  9.93it/s]\n",
      "epoch-31  lr=['0.0047383'], tr/val_loss:  0.003281/  1.488750, tr: 100.00%, val:  83.33%, val_best:  83.75%: 100%|██████████| 62/62 [00:07<00:00,  8.57it/s]\n",
      "epoch-32  lr=['0.0044774'], tr/val_loss:  0.002864/  1.492199, tr: 100.00%, val:  82.08%, val_best:  83.75%: 100%|██████████| 62/62 [00:05<00:00, 11.44it/s]\n",
      "epoch-33  lr=['0.0042178'], tr/val_loss:  0.002419/  1.503011, tr: 100.00%, val:  82.08%, val_best:  83.75%: 100%|██████████| 62/62 [00:06<00:00, 10.21it/s]\n",
      "epoch-34  lr=['0.0039604'], tr/val_loss:  0.002207/  1.516455, tr: 100.00%, val:  82.50%, val_best:  83.75%: 100%|██████████| 62/62 [00:06<00:00,  9.60it/s]\n",
      "epoch-35  lr=['0.0037059'], tr/val_loss:  0.002039/  1.511991, tr: 100.00%, val:  82.08%, val_best:  83.75%: 100%|██████████| 62/62 [00:06<00:00,  9.92it/s]\n",
      "epoch-36  lr=['0.0034549'], tr/val_loss:  0.001886/  1.520748, tr: 100.00%, val:  81.67%, val_best:  83.75%: 100%|██████████| 62/62 [00:05<00:00, 11.10it/s]\n",
      "epoch-37  lr=['0.0032082'], tr/val_loss:  0.001753/  1.519950, tr: 100.00%, val:  82.50%, val_best:  83.75%: 100%|██████████| 62/62 [00:05<00:00, 10.64it/s]\n",
      "epoch-38  lr=['0.0029663'], tr/val_loss:  0.001682/  1.534716, tr: 100.00%, val:  82.50%, val_best:  83.75%: 100%|██████████| 62/62 [00:05<00:00, 11.12it/s]\n",
      "epoch-39  lr=['0.0027300'], tr/val_loss:  0.001569/  1.538481, tr: 100.00%, val:  82.50%, val_best:  83.75%: 100%|██████████| 62/62 [00:05<00:00, 11.04it/s]\n",
      "epoch-40  lr=['0.0025000'], tr/val_loss:  0.001556/  1.539009, tr: 100.00%, val:  81.25%, val_best:  83.75%: 100%|██████████| 62/62 [00:06<00:00,  9.77it/s]\n",
      "epoch-41  lr=['0.0022768'], tr/val_loss:  0.001525/  1.536749, tr: 100.00%, val:  82.08%, val_best:  83.75%: 100%|██████████| 62/62 [00:06<00:00,  9.42it/s]\n",
      "epoch-42  lr=['0.0020611'], tr/val_loss:  0.001439/  1.538463, tr: 100.00%, val:  81.67%, val_best:  83.75%: 100%|██████████| 62/62 [00:05<00:00, 10.41it/s]\n",
      "epoch-43  lr=['0.0018534'], tr/val_loss:  0.001455/  1.548025, tr: 100.00%, val:  81.25%, val_best:  83.75%: 100%|██████████| 62/62 [00:06<00:00,  9.65it/s]\n",
      "epoch-44  lr=['0.0016543'], tr/val_loss:  0.001382/  1.536089, tr: 100.00%, val:  82.50%, val_best:  83.75%: 100%|██████████| 62/62 [00:06<00:00, 10.09it/s]\n",
      "epoch-45  lr=['0.0014645'], tr/val_loss:  0.001365/  1.546525, tr: 100.00%, val:  82.08%, val_best:  83.75%: 100%|██████████| 62/62 [00:06<00:00, 10.28it/s]\n",
      "epoch-46  lr=['0.0012843'], tr/val_loss:  0.001340/  1.548877, tr: 100.00%, val:  81.67%, val_best:  83.75%: 100%|██████████| 62/62 [00:06<00:00,  9.95it/s]\n",
      "epoch-47  lr=['0.0011143'], tr/val_loss:  0.001310/  1.554725, tr: 100.00%, val:  82.08%, val_best:  83.75%: 100%|██████████| 62/62 [00:06<00:00,  9.23it/s]\n",
      "epoch-48  lr=['0.0009549'], tr/val_loss:  0.001321/  1.555930, tr: 100.00%, val:  82.08%, val_best:  83.75%: 100%|██████████| 62/62 [00:05<00:00, 10.62it/s]\n",
      "epoch-49  lr=['0.0008066'], tr/val_loss:  0.001291/  1.554323, tr: 100.00%, val:  82.08%, val_best:  83.75%: 100%|██████████| 62/62 [00:06<00:00,  9.85it/s]\n",
      "epoch-50  lr=['0.0006699'], tr/val_loss:  0.001305/  1.555876, tr: 100.00%, val:  82.08%, val_best:  83.75%: 100%|██████████| 62/62 [00:06<00:00,  8.99it/s]\n",
      "epoch-51  lr=['0.0005450'], tr/val_loss:  0.001284/  1.557242, tr: 100.00%, val:  82.08%, val_best:  83.75%: 100%|██████████| 62/62 [00:05<00:00, 10.77it/s]\n",
      "epoch-52  lr=['0.0004323'], tr/val_loss:  0.001265/  1.557585, tr: 100.00%, val:  82.50%, val_best:  83.75%: 100%|██████████| 62/62 [00:06<00:00,  9.97it/s]\n",
      "epoch-53  lr=['0.0003321'], tr/val_loss:  0.001261/  1.557022, tr: 100.00%, val:  82.50%, val_best:  83.75%: 100%|██████████| 62/62 [00:05<00:00, 10.50it/s]\n",
      "epoch-54  lr=['0.0002447'], tr/val_loss:  0.001265/  1.559098, tr: 100.00%, val:  82.50%, val_best:  83.75%: 100%|██████████| 62/62 [00:06<00:00,  9.42it/s]\n",
      "epoch-55  lr=['0.0001704'], tr/val_loss:  0.001243/  1.559066, tr: 100.00%, val:  82.50%, val_best:  83.75%: 100%|██████████| 62/62 [00:05<00:00, 12.17it/s]\n",
      "epoch-56  lr=['0.0001093'], tr/val_loss:  0.001231/  1.560819, tr: 100.00%, val:  82.50%, val_best:  83.75%: 100%|██████████| 62/62 [00:05<00:00, 11.51it/s]\n",
      "epoch-57  lr=['0.0000616'], tr/val_loss:  0.001283/  1.559656, tr: 100.00%, val:  82.50%, val_best:  83.75%: 100%|██████████| 62/62 [00:05<00:00, 11.41it/s]\n",
      "epoch-58  lr=['0.0000274'], tr/val_loss:  0.001230/  1.560117, tr: 100.00%, val:  82.50%, val_best:  83.75%: 100%|██████████| 62/62 [00:05<00:00, 11.33it/s]\n",
      "epoch-59  lr=['0.0000069'], tr/val_loss:  0.001237/  1.560108, tr: 100.00%, val:  82.50%, val_best:  83.75%: 100%|██████████| 62/62 [00:05<00:00, 11.38it/s]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cda62d0e520a4343b8cc18481dd08c74",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='1.930 MB of 1.930 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>DFA_flag</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>epoch</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇████</td></tr><tr><td>iter_acc</td><td>▁▁▁▁▂▄▇▂▄▁▇█▇███████████████████████████</td></tr><tr><td>summary_val_acc</td><td>▁▅▆▆▆▆▇▆▆▇▇▇▇▇▇█████████████████████████</td></tr><tr><td>tr_acc</td><td>▁▄▅▆▆▆▆▇▇▇▇█████████████████████████████</td></tr><tr><td>tr_epoch_loss</td><td>▁█▅▅▅▄▄▃▃▃▃▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_acc_best</td><td>▁▅▆▆▆▆▇▇▇▇▇▇▇▇▇█████████████████████████</td></tr><tr><td>val_acc_now</td><td>▁▅▆▆▆▆▇▆▆▇▇▇▇▇▇█████████████████████████</td></tr><tr><td>val_loss</td><td>▁▇▇▆▇▆▆▇▇▆▇▇▇▇▇▇▇███████████████████████</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>DFA_flag</td><td>0.0</td></tr><tr><td>epoch</td><td>59</td></tr><tr><td>iter_acc</td><td>1.0</td></tr><tr><td>tr_acc</td><td>1.0</td></tr><tr><td>tr_epoch_loss</td><td>0.00124</td></tr><tr><td>val_acc_best</td><td>0.8375</td></tr><tr><td>val_acc_now</td><td>0.825</td></tr><tr><td>val_loss</td><td>1.56011</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">youthful-sweep-7</strong> at: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/n1vwlhg8' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/n1vwlhg8</a><br/> View project at: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main</a><br/>Synced 7 W&B file(s), 0 media file(s), 0 artifact file(s) and 1 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20240822_172620-n1vwlhg8/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require(\"core\")`! See https://wandb.me/wandb-core for more information."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: tp4d0x1z with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBATCH: 16\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tDFA_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tIMAGE_SIZE: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tOTTT_input_trace_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tOTTT_sWS_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tTIME: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcfg: ['M', 'M', 200, 200]\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tconst2: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdecay: 0.25\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdrop_rate: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdvs_clipping: 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdvs_duration: 100000\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \te_transport_swap: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \te_transport_swap_coin: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \te_transport_swap_tr: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepoch_num: 60\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \texclude_class: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.01\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_sg_width: 2.570969004857107\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_reset: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_threshold: 0.2994179019971077\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmerge_polarities: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tscheduler_name: CosineAnnealingLR\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsurrogate: hard_sigmoid\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \twhich_data: DVS_GESTURE_TONIC\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.17.7 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.17.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/nfs/home/bhkim003/github_folder/ByeonghyeonKim/my_snn/wandb/run-20240822_173302-tp4d0x1z</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/tp4d0x1z' target=\"_blank\">soft-sweep-10</a></strong> to <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/yxynyr6h' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/yxynyr6h</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/yxynyr6h' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/yxynyr6h</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/tp4d0x1z' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/tp4d0x1z</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BATCH' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'IMAGE_SIZE' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'which_data' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_threshold' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_reset' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_sg_width' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'cfg' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'learning_rate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'epoch_num' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'surrogate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'scheduler_name' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'dvs_clipping' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'dvs_duration' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'OTTT_sWS_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'DFA_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'OTTT_input_trace_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'e_transport_swap' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'e_transport_swap_tr' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'e_transport_swap_coin' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'drop_rate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'exclude_class' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'merge_polarities' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'TIME' was locked by 'sweep' (ignored update).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset_hash = 2bbd58b4e0d3c1e9ad501fad8a43feed\n",
      "cache path exists\n",
      "\n",
      "we will exclude the 'other' class. dvsgestrue 10 classes' indices exist. \n",
      "\n",
      "DataParallel(\n",
      "  (module): MY_SNN_FC_sstep(\n",
      "    (layers): MY_Sequential(\n",
      "      (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (2): DimChanger_for_FC_sstep()\n",
      "      (3): SYNAPSE_FC_trace_sstep()\n",
      "      (4): LIF_layer_trace_sstep()\n",
      "      (5): SYNAPSE_FC_trace_sstep()\n",
      "      (6): LIF_layer_trace_sstep()\n",
      "      (7): SYNAPSE_FC_trace_sstep()\n",
      "    )\n",
      "  )\n",
      ")\n",
      "==================================================\n",
      "My Num of PARAMS: 452,010, system's param_num : 452,010\n",
      "Memory: 1.72MiB at 32-bit\n",
      "==================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch-0   lr=['0.0100000'], tr/val_loss:  1.494565/  1.319992, tr:  49.34%, val:  50.83%, val_best:  50.83%: 100%|██████████| 62/62 [00:06<00:00,  9.70it/s]\n",
      "epoch-1   lr=['0.0099931'], tr/val_loss:  1.089510/  1.366718, tr:  59.55%, val:  50.00%, val_best:  50.83%: 100%|██████████| 62/62 [00:06<00:00, 10.16it/s]\n",
      "epoch-2   lr=['0.0099726'], tr/val_loss:  0.918355/  1.247588, tr:  65.88%, val:  58.75%, val_best:  58.75%: 100%|██████████| 62/62 [00:06<00:00,  9.37it/s]\n",
      "epoch-3   lr=['0.0099384'], tr/val_loss:  0.798837/  1.181212, tr:  69.46%, val:  60.42%, val_best:  60.42%: 100%|██████████| 62/62 [00:06<00:00,  9.40it/s]\n",
      "epoch-4   lr=['0.0098907'], tr/val_loss:  0.768910/  1.165668, tr:  71.50%, val:  63.75%, val_best:  63.75%: 100%|██████████| 62/62 [00:16<00:00,  3.68it/s]\n",
      "epoch-5   lr=['0.0098296'], tr/val_loss:  0.703286/  1.386308, tr:  72.63%, val:  57.50%, val_best:  63.75%: 100%|██████████| 62/62 [00:11<00:00,  5.58it/s]\n",
      "epoch-6   lr=['0.0097553'], tr/val_loss:  0.716833/  1.223683, tr:  72.73%, val:  63.33%, val_best:  63.75%: 100%|██████████| 62/62 [00:07<00:00,  8.08it/s]\n",
      "epoch-7   lr=['0.0096679'], tr/val_loss:  0.647445/  1.299349, tr:  76.71%, val:  59.58%, val_best:  63.75%: 100%|██████████| 62/62 [00:14<00:00,  4.41it/s]\n",
      "epoch-8   lr=['0.0095677'], tr/val_loss:  0.599347/  1.155264, tr:  76.00%, val:  67.08%, val_best:  67.08%: 100%|██████████| 62/62 [00:06<00:00, 10.07it/s]\n",
      "epoch-9   lr=['0.0094550'], tr/val_loss:  0.469896/  1.285156, tr:  81.51%, val:  71.67%, val_best:  71.67%: 100%|██████████| 62/62 [00:10<00:00,  6.09it/s]\n",
      "epoch-10  lr=['0.0093301'], tr/val_loss:  0.482472/  1.116986, tr:  83.45%, val:  72.08%, val_best:  72.08%: 100%|██████████| 62/62 [00:11<00:00,  5.58it/s]\n",
      "epoch-11  lr=['0.0091934'], tr/val_loss:  0.435108/  1.310437, tr:  84.07%, val:  67.50%, val_best:  72.08%: 100%|██████████| 62/62 [00:06<00:00,  9.77it/s]\n",
      "epoch-12  lr=['0.0090451'], tr/val_loss:  0.430958/  1.223550, tr:  86.01%, val:  73.75%, val_best:  73.75%: 100%|██████████| 62/62 [00:11<00:00,  5.40it/s]\n",
      "epoch-13  lr=['0.0088857'], tr/val_loss:  0.374627/  1.220425, tr:  88.76%, val:  71.67%, val_best:  73.75%: 100%|██████████| 62/62 [00:08<00:00,  7.27it/s]\n",
      "epoch-14  lr=['0.0087157'], tr/val_loss:  0.326371/  1.198647, tr:  92.34%, val:  75.00%, val_best:  75.00%: 100%|██████████| 62/62 [00:05<00:00, 11.40it/s]\n",
      "epoch-15  lr=['0.0085355'], tr/val_loss:  0.286000/  1.362449, tr:  94.08%, val:  73.75%, val_best:  75.00%: 100%|██████████| 62/62 [00:06<00:00,  9.93it/s]\n",
      "epoch-16  lr=['0.0083457'], tr/val_loss:  0.249455/  1.364297, tr:  95.20%, val:  73.75%, val_best:  75.00%: 100%|██████████| 62/62 [00:06<00:00,  9.00it/s]\n",
      "epoch-17  lr=['0.0081466'], tr/val_loss:  0.190826/  1.312289, tr:  97.14%, val:  75.00%, val_best:  75.00%: 100%|██████████| 62/62 [00:06<00:00,  9.41it/s]\n",
      "epoch-18  lr=['0.0079389'], tr/val_loss:  0.182090/  1.364650, tr:  97.96%, val:  76.25%, val_best:  76.25%: 100%|██████████| 62/62 [00:05<00:00, 11.02it/s]\n",
      "epoch-19  lr=['0.0077232'], tr/val_loss:  0.130736/  1.393520, tr:  98.88%, val:  75.42%, val_best:  76.25%: 100%|██████████| 62/62 [00:06<00:00,  9.67it/s]\n",
      "epoch-20  lr=['0.0075000'], tr/val_loss:  0.086348/  1.523537, tr:  99.69%, val:  74.58%, val_best:  76.25%: 100%|██████████| 62/62 [00:06<00:00, 10.33it/s]\n",
      "epoch-21  lr=['0.0072700'], tr/val_loss:  0.070686/  1.473164, tr: 100.00%, val:  77.08%, val_best:  77.08%: 100%|██████████| 62/62 [00:06<00:00, 10.29it/s]\n",
      "epoch-22  lr=['0.0070337'], tr/val_loss:  0.056732/  1.517090, tr:  99.80%, val:  78.33%, val_best:  78.33%: 100%|██████████| 62/62 [00:06<00:00,  9.71it/s]\n",
      "epoch-23  lr=['0.0067918'], tr/val_loss:  0.039756/  1.586878, tr:  99.90%, val:  77.50%, val_best:  78.33%: 100%|██████████| 62/62 [00:05<00:00, 10.77it/s]\n",
      "epoch-24  lr=['0.0065451'], tr/val_loss:  0.021238/  1.604869, tr: 100.00%, val:  76.25%, val_best:  78.33%: 100%|██████████| 62/62 [00:06<00:00,  9.99it/s]\n",
      "epoch-25  lr=['0.0062941'], tr/val_loss:  0.018435/  1.577655, tr: 100.00%, val:  79.17%, val_best:  79.17%: 100%|██████████| 62/62 [00:06<00:00,  9.51it/s]\n",
      "epoch-26  lr=['0.0060396'], tr/val_loss:  0.009553/  1.593008, tr: 100.00%, val:  78.33%, val_best:  79.17%: 100%|██████████| 62/62 [00:05<00:00, 10.75it/s]\n",
      "epoch-27  lr=['0.0057822'], tr/val_loss:  0.006158/  1.595665, tr: 100.00%, val:  79.58%, val_best:  79.58%: 100%|██████████| 62/62 [00:06<00:00, 10.26it/s]\n",
      "epoch-28  lr=['0.0055226'], tr/val_loss:  0.004771/  1.629804, tr: 100.00%, val:  79.17%, val_best:  79.58%: 100%|██████████| 62/62 [00:06<00:00, 10.16it/s]\n",
      "epoch-29  lr=['0.0052617'], tr/val_loss:  0.003790/  1.637599, tr: 100.00%, val:  80.00%, val_best:  80.00%: 100%|██████████| 62/62 [00:05<00:00, 11.11it/s]\n",
      "epoch-30  lr=['0.0050000'], tr/val_loss:  0.002977/  1.629135, tr: 100.00%, val:  79.17%, val_best:  80.00%: 100%|██████████| 62/62 [00:06<00:00,  9.85it/s]\n",
      "epoch-31  lr=['0.0047383'], tr/val_loss:  0.002677/  1.627915, tr: 100.00%, val:  79.17%, val_best:  80.00%: 100%|██████████| 62/62 [00:05<00:00, 10.65it/s]\n",
      "epoch-32  lr=['0.0044774'], tr/val_loss:  0.002470/  1.631675, tr: 100.00%, val:  79.58%, val_best:  80.00%: 100%|██████████| 62/62 [00:05<00:00, 10.59it/s]\n",
      "epoch-33  lr=['0.0042178'], tr/val_loss:  0.002251/  1.640858, tr: 100.00%, val:  79.58%, val_best:  80.00%: 100%|██████████| 62/62 [00:06<00:00,  9.94it/s]\n",
      "epoch-34  lr=['0.0039604'], tr/val_loss:  0.002042/  1.654209, tr: 100.00%, val:  79.58%, val_best:  80.00%: 100%|██████████| 62/62 [00:05<00:00, 12.33it/s]\n",
      "epoch-35  lr=['0.0037059'], tr/val_loss:  0.001904/  1.663835, tr: 100.00%, val:  78.75%, val_best:  80.00%: 100%|██████████| 62/62 [00:05<00:00, 11.38it/s]\n",
      "epoch-36  lr=['0.0034549'], tr/val_loss:  0.001879/  1.672992, tr: 100.00%, val:  80.42%, val_best:  80.42%: 100%|██████████| 62/62 [00:05<00:00, 12.06it/s]\n",
      "epoch-37  lr=['0.0032082'], tr/val_loss:  0.001789/  1.686238, tr: 100.00%, val:  79.58%, val_best:  80.42%: 100%|██████████| 62/62 [00:05<00:00, 11.29it/s]\n",
      "epoch-38  lr=['0.0029663'], tr/val_loss:  0.001652/  1.697463, tr: 100.00%, val:  79.58%, val_best:  80.42%: 100%|██████████| 62/62 [00:05<00:00, 10.61it/s]\n",
      "epoch-39  lr=['0.0027300'], tr/val_loss:  0.001621/  1.701296, tr: 100.00%, val:  80.00%, val_best:  80.42%: 100%|██████████| 62/62 [00:06<00:00,  9.36it/s]\n",
      "epoch-40  lr=['0.0025000'], tr/val_loss:  0.001598/  1.700492, tr: 100.00%, val:  80.00%, val_best:  80.42%: 100%|██████████| 62/62 [00:06<00:00,  9.76it/s]\n",
      "epoch-41  lr=['0.0022768'], tr/val_loss:  0.001563/  1.706057, tr: 100.00%, val:  80.00%, val_best:  80.42%: 100%|██████████| 62/62 [00:06<00:00,  9.88it/s]\n",
      "epoch-42  lr=['0.0020611'], tr/val_loss:  0.001455/  1.700842, tr: 100.00%, val:  80.00%, val_best:  80.42%: 100%|██████████| 62/62 [00:05<00:00, 10.34it/s]\n",
      "epoch-43  lr=['0.0018534'], tr/val_loss:  0.001445/  1.704665, tr: 100.00%, val:  79.58%, val_best:  80.42%: 100%|██████████| 62/62 [00:05<00:00, 10.91it/s]\n",
      "epoch-44  lr=['0.0016543'], tr/val_loss:  0.001404/  1.701995, tr: 100.00%, val:  79.58%, val_best:  80.42%: 100%|██████████| 62/62 [00:06<00:00, 10.19it/s]\n",
      "epoch-45  lr=['0.0014645'], tr/val_loss:  0.001393/  1.698310, tr: 100.00%, val:  80.00%, val_best:  80.42%: 100%|██████████| 62/62 [00:06<00:00,  9.57it/s]\n",
      "epoch-46  lr=['0.0012843'], tr/val_loss:  0.001345/  1.694718, tr: 100.00%, val:  79.17%, val_best:  80.42%: 100%|██████████| 62/62 [00:05<00:00, 10.36it/s]\n",
      "epoch-47  lr=['0.0011143'], tr/val_loss:  0.001358/  1.692717, tr: 100.00%, val:  79.17%, val_best:  80.42%: 100%|██████████| 62/62 [00:06<00:00, 10.00it/s]\n",
      "epoch-48  lr=['0.0009549'], tr/val_loss:  0.001343/  1.685966, tr: 100.00%, val:  79.17%, val_best:  80.42%: 100%|██████████| 62/62 [00:06<00:00, 10.12it/s]\n",
      "epoch-49  lr=['0.0008066'], tr/val_loss:  0.001286/  1.686939, tr: 100.00%, val:  79.17%, val_best:  80.42%: 100%|██████████| 62/62 [00:06<00:00, 10.11it/s]\n",
      "epoch-50  lr=['0.0006699'], tr/val_loss:  0.001341/  1.690285, tr: 100.00%, val:  79.58%, val_best:  80.42%: 100%|██████████| 62/62 [00:06<00:00,  9.09it/s]\n",
      "epoch-51  lr=['0.0005450'], tr/val_loss:  0.001279/  1.694174, tr: 100.00%, val:  80.00%, val_best:  80.42%: 100%|██████████| 62/62 [00:06<00:00,  8.99it/s]\n",
      "epoch-52  lr=['0.0004323'], tr/val_loss:  0.001284/  1.695675, tr: 100.00%, val:  80.00%, val_best:  80.42%: 100%|██████████| 62/62 [00:05<00:00, 10.65it/s]\n",
      "epoch-53  lr=['0.0003321'], tr/val_loss:  0.001273/  1.695926, tr: 100.00%, val:  80.00%, val_best:  80.42%: 100%|██████████| 62/62 [00:06<00:00,  8.95it/s]\n",
      "epoch-54  lr=['0.0002447'], tr/val_loss:  0.001304/  1.697426, tr: 100.00%, val:  80.00%, val_best:  80.42%: 100%|██████████| 62/62 [00:05<00:00, 11.65it/s]\n",
      "epoch-55  lr=['0.0001704'], tr/val_loss:  0.001249/  1.696921, tr: 100.00%, val:  80.00%, val_best:  80.42%: 100%|██████████| 62/62 [00:05<00:00, 11.38it/s]\n",
      "epoch-56  lr=['0.0001093'], tr/val_loss:  0.001269/  1.696965, tr: 100.00%, val:  80.00%, val_best:  80.42%: 100%|██████████| 62/62 [00:05<00:00, 11.00it/s]\n",
      "epoch-57  lr=['0.0000616'], tr/val_loss:  0.001286/  1.696400, tr: 100.00%, val:  80.00%, val_best:  80.42%: 100%|██████████| 62/62 [00:05<00:00, 12.00it/s]\n",
      "epoch-58  lr=['0.0000274'], tr/val_loss:  0.001255/  1.696475, tr: 100.00%, val:  80.00%, val_best:  80.42%: 100%|██████████| 62/62 [00:05<00:00, 10.74it/s]\n",
      "epoch-59  lr=['0.0000069'], tr/val_loss:  0.001274/  1.696480, tr: 100.00%, val:  80.00%, val_best:  80.42%: 100%|██████████| 62/62 [00:05<00:00, 10.81it/s]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "84f1dda5c5264aefb34eb43e859af479",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='1.937 MB of 1.937 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>DFA_flag</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>epoch</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇████</td></tr><tr><td>iter_acc</td><td>▂▁▄▆▃▅▅▅▅▅██▇███████████████████████████</td></tr><tr><td>summary_val_acc</td><td>▁▅▆▆▆▇▇▇▇▇█▇████████████████████████████</td></tr><tr><td>tr_acc</td><td>▁▄▆▆▆▆▆▇▇▇▇█████████████████████████████</td></tr><tr><td>tr_epoch_loss</td><td>▁█▅▅▄▄▄▃▃▃▃▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_acc_best</td><td>▁▅▆▆▇▇▇▇▇▇██████████████████████████████</td></tr><tr><td>val_acc_now</td><td>▁▅▆▆▆▇▇▇▇▇█▇████████████████████████████</td></tr><tr><td>val_loss</td><td>▁▆▆▆▇▆▆▆▆▆▆▇▆▇▇▇█▇██████████████████████</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>DFA_flag</td><td>0.0</td></tr><tr><td>epoch</td><td>59</td></tr><tr><td>iter_acc</td><td>1.0</td></tr><tr><td>tr_acc</td><td>1.0</td></tr><tr><td>tr_epoch_loss</td><td>0.00127</td></tr><tr><td>val_acc_best</td><td>0.80417</td></tr><tr><td>val_acc_now</td><td>0.8</td></tr><tr><td>val_loss</td><td>1.69648</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">soft-sweep-10</strong> at: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/tp4d0x1z' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/tp4d0x1z</a><br/> View project at: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main</a><br/>Synced 7 W&B file(s), 0 media file(s), 0 artifact file(s) and 1 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20240822_173302-tp4d0x1z/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require(\"core\")`! See https://wandb.me/wandb-core for more information."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: cazlsdep with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBATCH: 16\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tDFA_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tIMAGE_SIZE: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tOTTT_input_trace_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tOTTT_sWS_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tTIME: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcfg: ['M', 'M', 200, 200]\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tconst2: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdecay: 0.25\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdrop_rate: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdvs_clipping: 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdvs_duration: 100000\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \te_transport_swap: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \te_transport_swap_coin: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \te_transport_swap_tr: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepoch_num: 60\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \texclude_class: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.01\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_sg_width: 2.570969004857107\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_reset: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_threshold: 1.8949402746835924\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmerge_polarities: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tscheduler_name: CosineAnnealingLR\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsurrogate: hard_sigmoid\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \twhich_data: DVS_GESTURE_TONIC\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.17.7 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.17.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/nfs/home/bhkim003/github_folder/ByeonghyeonKim/my_snn/wandb/run-20240822_174019-cazlsdep</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/cazlsdep' target=\"_blank\">icy-sweep-13</a></strong> to <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/yxynyr6h' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/yxynyr6h</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/yxynyr6h' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/yxynyr6h</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/cazlsdep' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/cazlsdep</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BATCH' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'IMAGE_SIZE' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'which_data' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_threshold' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_reset' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_sg_width' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'cfg' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'learning_rate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'epoch_num' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'surrogate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'scheduler_name' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'dvs_clipping' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'dvs_duration' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'OTTT_sWS_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'DFA_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'OTTT_input_trace_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'e_transport_swap' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'e_transport_swap_tr' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'e_transport_swap_coin' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'drop_rate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'exclude_class' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'merge_polarities' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'TIME' was locked by 'sweep' (ignored update).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset_hash = 2bbd58b4e0d3c1e9ad501fad8a43feed\n",
      "cache path exists\n",
      "\n",
      "we will exclude the 'other' class. dvsgestrue 10 classes' indices exist. \n",
      "\n",
      "DataParallel(\n",
      "  (module): MY_SNN_FC_sstep(\n",
      "    (layers): MY_Sequential(\n",
      "      (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (2): DimChanger_for_FC_sstep()\n",
      "      (3): SYNAPSE_FC_trace_sstep()\n",
      "      (4): LIF_layer_trace_sstep()\n",
      "      (5): SYNAPSE_FC_trace_sstep()\n",
      "      (6): LIF_layer_trace_sstep()\n",
      "      (7): SYNAPSE_FC_trace_sstep()\n",
      "    )\n",
      "  )\n",
      ")\n",
      "==================================================\n",
      "My Num of PARAMS: 452,010, system's param_num : 452,010\n",
      "Memory: 1.72MiB at 32-bit\n",
      "==================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch-0   lr=['0.0100000'], tr/val_loss:  2.317507/  2.316367, tr:   9.70%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:05<00:00, 10.39it/s]\n",
      "epoch-1   lr=['0.0099931'], tr/val_loss:  2.316254/  2.314931, tr:  10.21%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:05<00:00, 10.36it/s]\n",
      "epoch-2   lr=['0.0099726'], tr/val_loss:  2.315321/  2.315877, tr:   9.81%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:05<00:00, 10.61it/s]\n",
      "epoch-3   lr=['0.0099384'], tr/val_loss:  2.319123/  2.321801, tr:  10.42%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:05<00:00, 11.40it/s]\n",
      "epoch-4   lr=['0.0098907'], tr/val_loss:  2.328817/  2.310750, tr:   7.66%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:06<00:00, 10.08it/s]\n",
      "epoch-5   lr=['0.0098296'], tr/val_loss:  2.318780/  2.313111, tr:   8.58%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:05<00:00, 10.41it/s]\n",
      "epoch-6   lr=['0.0097553'], tr/val_loss:  2.326567/  2.312034, tr:   8.89%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:05<00:00, 10.65it/s]\n",
      "epoch-7   lr=['0.0096679'], tr/val_loss:  2.319906/  2.308871, tr:   8.89%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:06<00:00, 10.25it/s]\n",
      "epoch-8   lr=['0.0095677'], tr/val_loss:  2.315703/  2.318316, tr:   9.09%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:05<00:00, 11.30it/s]\n",
      "epoch-9   lr=['0.0094550'], tr/val_loss:  2.315776/  2.321137, tr:   9.81%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:05<00:00, 10.60it/s]\n",
      "epoch-10  lr=['0.0093301'], tr/val_loss:  2.319218/  2.310921, tr:   9.40%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:05<00:00, 10.57it/s]\n",
      "epoch-11  lr=['0.0091934'], tr/val_loss:  2.320658/  2.318817, tr:   9.60%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:07<00:00,  8.12it/s]\n",
      "epoch-12  lr=['0.0090451'], tr/val_loss:  2.323760/  2.306959, tr:   9.70%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:06<00:00,  9.86it/s]\n",
      "epoch-13  lr=['0.0088857'], tr/val_loss:  2.312257/  2.313825, tr:   8.78%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:06<00:00,  9.94it/s]\n",
      "epoch-14  lr=['0.0087157'], tr/val_loss:  2.321870/  2.310401, tr:   9.70%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:06<00:00,  9.70it/s]\n",
      "epoch-15  lr=['0.0085355'], tr/val_loss:  2.318407/  2.313874, tr:   9.60%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:06<00:00,  9.99it/s]\n",
      "epoch-16  lr=['0.0083457'], tr/val_loss:  2.317499/  2.312321, tr:  10.11%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:06<00:00,  9.84it/s]\n",
      "epoch-17  lr=['0.0081466'], tr/val_loss:  2.318669/  2.307941, tr:   8.89%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:06<00:00, 10.26it/s]\n",
      "epoch-18  lr=['0.0079389'], tr/val_loss:  2.325135/  2.306585, tr:   7.46%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:05<00:00, 10.38it/s]\n",
      "epoch-19  lr=['0.0077232'], tr/val_loss:  2.314244/  2.310251, tr:  10.01%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:05<00:00, 10.53it/s]\n",
      "epoch-20  lr=['0.0075000'], tr/val_loss:  2.312182/  2.307967, tr:   9.91%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:06<00:00, 10.04it/s]\n",
      "epoch-21  lr=['0.0072700'], tr/val_loss:  2.318818/  2.307295, tr:   9.30%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:05<00:00, 10.48it/s]\n",
      "epoch-22  lr=['0.0070337'], tr/val_loss:  2.313441/  2.307399, tr:   9.91%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:06<00:00,  9.94it/s]\n",
      "epoch-23  lr=['0.0067918'], tr/val_loss:  2.314248/  2.309416, tr:   7.76%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:05<00:00, 10.39it/s]\n",
      "epoch-24  lr=['0.0065451'], tr/val_loss:  2.318841/  2.305136, tr:   9.09%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:06<00:00,  9.92it/s]\n",
      "epoch-25  lr=['0.0062941'], tr/val_loss:  2.316903/  2.306750, tr:   7.97%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:06<00:00,  9.53it/s]\n",
      "epoch-26  lr=['0.0060396'], tr/val_loss:  2.311055/  2.305107, tr:   8.99%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:06<00:00, 10.17it/s]\n",
      "epoch-27  lr=['0.0057822'], tr/val_loss:  2.313828/  2.306802, tr:   8.58%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:06<00:00, 10.23it/s]\n",
      "epoch-28  lr=['0.0055226'], tr/val_loss:  2.315332/  2.308450, tr:   8.68%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:06<00:00,  8.94it/s]\n",
      "epoch-29  lr=['0.0052617'], tr/val_loss:  2.315842/  2.306032, tr:   7.15%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:05<00:00, 10.42it/s]\n",
      "epoch-30  lr=['0.0050000'], tr/val_loss:  2.312570/  2.303939, tr:   8.89%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:05<00:00, 10.39it/s]\n",
      "epoch-31  lr=['0.0047383'], tr/val_loss:  2.309263/  2.303903, tr:   9.09%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:06<00:00,  9.22it/s]\n",
      "epoch-32  lr=['0.0044774'], tr/val_loss:  2.311847/  2.302894, tr:   8.38%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:06<00:00,  9.55it/s]\n",
      "epoch-33  lr=['0.0042178'], tr/val_loss:  2.308722/  2.303530, tr:   9.50%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:06<00:00,  9.46it/s]\n",
      "epoch-34  lr=['0.0039604'], tr/val_loss:  2.313000/  2.304187, tr:   8.48%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:05<00:00, 11.80it/s]\n",
      "epoch-35  lr=['0.0037059'], tr/val_loss:  2.309877/  2.303538, tr:   9.09%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:05<00:00, 10.97it/s]\n",
      "epoch-36  lr=['0.0034549'], tr/val_loss:  2.309406/  2.303601, tr:   8.99%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:05<00:00, 11.03it/s]\n",
      "epoch-37  lr=['0.0032082'], tr/val_loss:  2.309686/  2.303400, tr:   7.66%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:05<00:00, 11.27it/s]\n",
      "epoch-38  lr=['0.0029663'], tr/val_loss:  2.308588/  2.303166, tr:   9.09%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:06<00:00,  8.92it/s]\n",
      "epoch-39  lr=['0.0027300'], tr/val_loss:  2.308727/  2.302884, tr:   8.89%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:05<00:00, 10.65it/s]\n",
      "epoch-40  lr=['0.0025000'], tr/val_loss:  2.308749/  2.302732, tr:   9.40%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:05<00:00, 10.73it/s]\n",
      "epoch-41  lr=['0.0022768'], tr/val_loss:  2.306803/  2.302942, tr:   9.19%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:06<00:00,  9.90it/s]\n",
      "epoch-42  lr=['0.0020611'], tr/val_loss:  2.306347/  2.302762, tr:   8.68%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:06<00:00,  9.59it/s]\n",
      "epoch-43  lr=['0.0018534'], tr/val_loss:  2.305991/  2.302857, tr:   8.99%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:06<00:00,  9.59it/s]\n",
      "epoch-44  lr=['0.0016543'], tr/val_loss:  2.305293/  2.302853, tr:  10.01%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:06<00:00, 10.25it/s]\n",
      "epoch-45  lr=['0.0014645'], tr/val_loss:  2.306396/  2.302847, tr:   8.48%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:07<00:00,  8.73it/s]\n",
      "epoch-46  lr=['0.0012843'], tr/val_loss:  2.305307/  2.302670, tr:  10.01%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:06<00:00,  9.60it/s]\n",
      "epoch-47  lr=['0.0011143'], tr/val_loss:  2.305197/  2.302644, tr:   9.30%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:06<00:00,  9.65it/s]\n",
      "epoch-48  lr=['0.0009549'], tr/val_loss:  2.304637/  2.302745, tr:   8.78%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:07<00:00,  8.67it/s]\n",
      "epoch-49  lr=['0.0008066'], tr/val_loss:  2.304113/  2.302645, tr:   8.89%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:06<00:00, 10.19it/s]\n",
      "epoch-50  lr=['0.0006699'], tr/val_loss:  2.304358/  2.302700, tr:   8.68%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:06<00:00, 10.20it/s]\n",
      "epoch-51  lr=['0.0005450'], tr/val_loss:  2.303610/  2.302717, tr:   9.81%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:06<00:00,  9.13it/s]\n",
      "epoch-52  lr=['0.0004323'], tr/val_loss:  2.303667/  2.302626, tr:   9.30%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:05<00:00, 10.63it/s]\n",
      "epoch-53  lr=['0.0003321'], tr/val_loss:  2.303300/  2.302634, tr:   9.19%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:05<00:00, 11.52it/s]\n",
      "epoch-54  lr=['0.0002447'], tr/val_loss:  2.303030/  2.302622, tr:   8.38%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:05<00:00, 11.87it/s]\n",
      "epoch-55  lr=['0.0001704'], tr/val_loss:  2.303107/  2.302625, tr:  10.01%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:05<00:00, 12.02it/s]\n",
      "epoch-56  lr=['0.0001093'], tr/val_loss:  2.302886/  2.302609, tr:  10.01%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:05<00:00, 12.22it/s]\n",
      "epoch-57  lr=['0.0000616'], tr/val_loss:  2.302670/  2.302610, tr:  10.01%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:05<00:00, 10.63it/s]\n",
      "epoch-58  lr=['0.0000274'], tr/val_loss:  2.302685/  2.302609, tr:  10.01%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:05<00:00, 10.62it/s]\n",
      "epoch-59  lr=['0.0000069'], tr/val_loss:  2.302528/  2.302609, tr:  10.01%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:06<00:00,  9.17it/s]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ba4cadbffbc54d49939873673606e2fe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='1.937 MB of 1.937 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>DFA_flag</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>epoch</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇████</td></tr><tr><td>iter_acc</td><td>▁█▅▅▃▁▅█▆▃▆▅▃▃▁▃▃▃▁▁▁▁▆▅▁▃▁▅▃▅▃▅▃▃▅▅▁▃▅█</td></tr><tr><td>summary_val_acc</td><td>▁███████████████████████████████████████</td></tr><tr><td>tr_acc</td><td>▁███▇▇▇█▇███▇███▆▆▇▇▆▇▇▇▇▆▇▇▇▇██▇▇█▇▇███</td></tr><tr><td>tr_epoch_loss</td><td>▁███████████████████████████████████████</td></tr><tr><td>val_acc_best</td><td>▁███████████████████████████████████████</td></tr><tr><td>val_acc_now</td><td>▁███████████████████████████████████████</td></tr><tr><td>val_loss</td><td>▁███████████████████████████████████████</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>DFA_flag</td><td>0.0</td></tr><tr><td>epoch</td><td>59</td></tr><tr><td>iter_acc</td><td>0.33333</td></tr><tr><td>tr_acc</td><td>0.1001</td></tr><tr><td>tr_epoch_loss</td><td>2.30253</td></tr><tr><td>val_acc_best</td><td>0.1</td></tr><tr><td>val_acc_now</td><td>0.1</td></tr><tr><td>val_loss</td><td>2.30261</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">icy-sweep-13</strong> at: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/cazlsdep' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/cazlsdep</a><br/> View project at: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main</a><br/>Synced 7 W&B file(s), 0 media file(s), 0 artifact file(s) and 1 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20240822_174019-cazlsdep/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require(\"core\")`! See https://wandb.me/wandb-core for more information."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: r3d9drh1 with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBATCH: 16\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tDFA_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tIMAGE_SIZE: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tOTTT_input_trace_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tOTTT_sWS_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tTIME: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcfg: ['M', 'M', 200, 200]\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tconst2: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdecay: 0.25\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdrop_rate: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdvs_clipping: 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdvs_duration: 100000\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \te_transport_swap: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \te_transport_swap_coin: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \te_transport_swap_tr: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepoch_num: 60\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \texclude_class: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.01\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_sg_width: 2.570969004857107\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_reset: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_threshold: 1.3971604051378217\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmerge_polarities: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tscheduler_name: CosineAnnealingLR\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsurrogate: hard_sigmoid\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \twhich_data: DVS_GESTURE_TONIC\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.17.7 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.17.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/nfs/home/bhkim003/github_folder/ByeonghyeonKim/my_snn/wandb/run-20240822_174658-r3d9drh1</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/r3d9drh1' target=\"_blank\">lyric-sweep-16</a></strong> to <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/yxynyr6h' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/yxynyr6h</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/yxynyr6h' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/yxynyr6h</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/r3d9drh1' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/r3d9drh1</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BATCH' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'IMAGE_SIZE' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'which_data' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_threshold' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_reset' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_sg_width' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'cfg' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'learning_rate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'epoch_num' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'surrogate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'scheduler_name' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'dvs_clipping' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'dvs_duration' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'OTTT_sWS_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'DFA_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'OTTT_input_trace_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'e_transport_swap' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'e_transport_swap_tr' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'e_transport_swap_coin' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'drop_rate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'exclude_class' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'merge_polarities' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'TIME' was locked by 'sweep' (ignored update).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset_hash = 2bbd58b4e0d3c1e9ad501fad8a43feed\n",
      "cache path exists\n",
      "\n",
      "we will exclude the 'other' class. dvsgestrue 10 classes' indices exist. \n",
      "\n",
      "DataParallel(\n",
      "  (module): MY_SNN_FC_sstep(\n",
      "    (layers): MY_Sequential(\n",
      "      (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (2): DimChanger_for_FC_sstep()\n",
      "      (3): SYNAPSE_FC_trace_sstep()\n",
      "      (4): LIF_layer_trace_sstep()\n",
      "      (5): SYNAPSE_FC_trace_sstep()\n",
      "      (6): LIF_layer_trace_sstep()\n",
      "      (7): SYNAPSE_FC_trace_sstep()\n",
      "    )\n",
      "  )\n",
      ")\n",
      "==================================================\n",
      "My Num of PARAMS: 452,010, system's param_num : 452,010\n",
      "Memory: 1.72MiB at 32-bit\n",
      "==================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch-0   lr=['0.0100000'], tr/val_loss:  2.317507/  2.316367, tr:   9.70%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:06<00:00, 10.16it/s]\n",
      "epoch-1   lr=['0.0099931'], tr/val_loss:  2.316254/  2.314931, tr:  10.21%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:05<00:00, 10.87it/s]\n",
      "epoch-2   lr=['0.0099726'], tr/val_loss:  2.315321/  2.315877, tr:   9.81%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:06<00:00,  9.57it/s]\n",
      "epoch-3   lr=['0.0099384'], tr/val_loss:  2.319123/  2.321801, tr:  10.42%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:05<00:00, 10.45it/s]\n",
      "epoch-4   lr=['0.0098907'], tr/val_loss:  2.328817/  2.310750, tr:   7.66%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:05<00:00, 11.35it/s]\n",
      "epoch-5   lr=['0.0098296'], tr/val_loss:  2.318780/  2.313111, tr:   8.58%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:06<00:00, 10.12it/s]\n",
      "epoch-6   lr=['0.0097553'], tr/val_loss:  2.326567/  2.312034, tr:   8.89%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:06<00:00, 10.07it/s]\n",
      "epoch-7   lr=['0.0096679'], tr/val_loss:  2.319906/  2.308871, tr:   8.89%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:06<00:00, 10.12it/s]\n",
      "epoch-8   lr=['0.0095677'], tr/val_loss:  2.315703/  2.318316, tr:   9.09%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:06<00:00,  9.22it/s]\n",
      "epoch-9   lr=['0.0094550'], tr/val_loss:  2.315776/  2.321137, tr:   9.81%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:05<00:00, 10.47it/s]\n",
      "epoch-10  lr=['0.0093301'], tr/val_loss:  2.319218/  2.310921, tr:   9.40%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:06<00:00,  9.93it/s]\n",
      "epoch-11  lr=['0.0091934'], tr/val_loss:  2.320658/  2.318817, tr:   9.60%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:06<00:00,  9.21it/s]\n",
      "epoch-12  lr=['0.0090451'], tr/val_loss:  2.323760/  2.306959, tr:   9.70%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:05<00:00, 11.22it/s]\n",
      "epoch-13  lr=['0.0088857'], tr/val_loss:  2.312243/  2.313826, tr:   8.78%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:06<00:00, 10.30it/s]\n",
      "epoch-14  lr=['0.0087157'], tr/val_loss:  2.321856/  2.310401, tr:   9.70%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:06<00:00,  9.93it/s]\n",
      "epoch-15  lr=['0.0085355'], tr/val_loss:  2.318392/  2.313874, tr:   9.60%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:06<00:00, 10.24it/s]\n",
      "epoch-16  lr=['0.0083457'], tr/val_loss:  2.317484/  2.312322, tr:  10.11%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:05<00:00, 10.34it/s]\n",
      "epoch-17  lr=['0.0081466'], tr/val_loss:  2.318630/  2.307940, tr:   8.89%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:06<00:00,  9.77it/s]\n",
      "epoch-18  lr=['0.0079389'], tr/val_loss:  2.325032/  2.306468, tr:   7.46%, val:  10.42%, val_best:  10.42%: 100%|██████████| 62/62 [00:06<00:00,  8.90it/s]\n",
      "epoch-19  lr=['0.0077232'], tr/val_loss:  2.302925/  2.209508, tr:  10.62%, val:  24.17%, val_best:  24.17%: 100%|██████████| 62/62 [00:06<00:00,  9.40it/s]\n",
      "epoch-20  lr=['0.0075000'], tr/val_loss:  1.746508/  1.446250, tr:  38.20%, val:  49.58%, val_best:  49.58%: 100%|██████████| 62/62 [00:06<00:00,  9.08it/s]\n",
      "epoch-21  lr=['0.0072700'], tr/val_loss:  1.257445/  1.263204, tr:  57.51%, val:  59.17%, val_best:  59.17%: 100%|██████████| 62/62 [00:05<00:00, 11.11it/s]\n",
      "epoch-22  lr=['0.0070337'], tr/val_loss:  1.087828/  1.231014, tr:  62.51%, val:  58.75%, val_best:  59.17%: 100%|██████████| 62/62 [00:06<00:00,  9.87it/s]\n",
      "epoch-23  lr=['0.0067918'], tr/val_loss:  0.987573/  1.225760, tr:  66.39%, val:  67.08%, val_best:  67.08%: 100%|██████████| 62/62 [00:05<00:00, 10.94it/s]\n",
      "epoch-24  lr=['0.0065451'], tr/val_loss:  0.872322/  1.378110, tr:  70.89%, val:  56.67%, val_best:  67.08%: 100%|██████████| 62/62 [00:07<00:00,  8.84it/s]\n",
      "epoch-25  lr=['0.0062941'], tr/val_loss:  0.775280/  1.172647, tr:  72.93%, val:  64.17%, val_best:  67.08%: 100%|██████████| 62/62 [00:06<00:00,  9.51it/s]\n",
      "epoch-26  lr=['0.0060396'], tr/val_loss:  0.738793/  1.091548, tr:  72.93%, val:  65.00%, val_best:  67.08%: 100%|██████████| 62/62 [00:05<00:00, 10.40it/s]\n",
      "epoch-27  lr=['0.0057822'], tr/val_loss:  0.640145/  1.196303, tr:  75.59%, val:  67.50%, val_best:  67.50%: 100%|██████████| 62/62 [00:06<00:00,  9.18it/s]\n",
      "epoch-28  lr=['0.0055226'], tr/val_loss:  0.587901/  1.065685, tr:  80.08%, val:  67.50%, val_best:  67.50%: 100%|██████████| 62/62 [00:05<00:00, 10.94it/s]\n",
      "epoch-29  lr=['0.0052617'], tr/val_loss:  0.524370/  1.196763, tr:  80.69%, val:  67.92%, val_best:  67.92%: 100%|██████████| 62/62 [00:06<00:00,  9.62it/s]\n",
      "epoch-30  lr=['0.0050000'], tr/val_loss:  0.481537/  1.189490, tr:  81.21%, val:  68.75%, val_best:  68.75%: 100%|██████████| 62/62 [00:06<00:00,  9.47it/s]\n",
      "epoch-31  lr=['0.0047383'], tr/val_loss:  0.440502/  1.184263, tr:  83.45%, val:  67.92%, val_best:  68.75%: 100%|██████████| 62/62 [00:05<00:00, 10.85it/s]\n",
      "epoch-32  lr=['0.0044774'], tr/val_loss:  0.438512/  1.214578, tr:  82.33%, val:  66.67%, val_best:  68.75%: 100%|██████████| 62/62 [00:06<00:00,  9.85it/s]\n",
      "epoch-33  lr=['0.0042178'], tr/val_loss:  0.347871/  1.196543, tr:  91.73%, val:  75.00%, val_best:  75.00%: 100%|██████████| 62/62 [00:05<00:00, 11.58it/s]\n",
      "epoch-34  lr=['0.0039604'], tr/val_loss:  0.301813/  1.238014, tr:  92.54%, val:  72.08%, val_best:  75.00%: 100%|██████████| 62/62 [00:05<00:00, 11.62it/s]\n",
      "epoch-35  lr=['0.0037059'], tr/val_loss:  0.259209/  1.234416, tr:  93.97%, val:  76.67%, val_best:  76.67%: 100%|██████████| 62/62 [00:05<00:00, 11.36it/s]\n",
      "epoch-36  lr=['0.0034549'], tr/val_loss:  0.222577/  1.312066, tr:  97.55%, val:  75.00%, val_best:  76.67%: 100%|██████████| 62/62 [00:05<00:00, 10.74it/s]\n",
      "epoch-37  lr=['0.0032082'], tr/val_loss:  0.210772/  1.306105, tr:  97.34%, val:  75.83%, val_best:  76.67%: 100%|██████████| 62/62 [00:06<00:00,  9.88it/s]\n",
      "epoch-38  lr=['0.0029663'], tr/val_loss:  0.175578/  1.351550, tr:  96.94%, val:  77.92%, val_best:  77.92%: 100%|██████████| 62/62 [00:07<00:00,  8.46it/s]\n",
      "epoch-39  lr=['0.0027300'], tr/val_loss:  0.151431/  1.380385, tr:  99.28%, val:  75.42%, val_best:  77.92%: 100%|██████████| 62/62 [00:06<00:00, 10.27it/s]\n",
      "epoch-40  lr=['0.0025000'], tr/val_loss:  0.124137/  1.390934, tr:  99.80%, val:  75.00%, val_best:  77.92%: 100%|██████████| 62/62 [00:06<00:00,  9.03it/s]\n",
      "epoch-41  lr=['0.0022768'], tr/val_loss:  0.101820/  1.391829, tr:  99.59%, val:  78.33%, val_best:  78.33%: 100%|██████████| 62/62 [00:06<00:00,  9.93it/s]\n",
      "epoch-42  lr=['0.0020611'], tr/val_loss:  0.081143/  1.405733, tr: 100.00%, val:  80.42%, val_best:  80.42%: 100%|██████████| 62/62 [00:06<00:00,  9.04it/s]\n",
      "epoch-43  lr=['0.0018534'], tr/val_loss:  0.071014/  1.421288, tr: 100.00%, val:  79.58%, val_best:  80.42%: 100%|██████████| 62/62 [00:05<00:00, 11.17it/s]\n",
      "epoch-44  lr=['0.0016543'], tr/val_loss:  0.058655/  1.457551, tr: 100.00%, val:  80.00%, val_best:  80.42%: 100%|██████████| 62/62 [00:06<00:00, 10.21it/s]\n",
      "epoch-45  lr=['0.0014645'], tr/val_loss:  0.051009/  1.482949, tr: 100.00%, val:  77.50%, val_best:  80.42%: 100%|██████████| 62/62 [00:06<00:00,  9.38it/s]\n",
      "epoch-46  lr=['0.0012843'], tr/val_loss:  0.041989/  1.470272, tr: 100.00%, val:  80.83%, val_best:  80.83%: 100%|██████████| 62/62 [00:06<00:00, 10.18it/s]\n",
      "epoch-47  lr=['0.0011143'], tr/val_loss:  0.039290/  1.478703, tr: 100.00%, val:  82.92%, val_best:  82.92%: 100%|██████████| 62/62 [00:07<00:00,  8.17it/s]\n",
      "epoch-48  lr=['0.0009549'], tr/val_loss:  0.035829/  1.493108, tr: 100.00%, val:  79.58%, val_best:  82.92%: 100%|██████████| 62/62 [00:06<00:00, 10.13it/s]\n",
      "epoch-49  lr=['0.0008066'], tr/val_loss:  0.030816/  1.507583, tr: 100.00%, val:  80.83%, val_best:  82.92%: 100%|██████████| 62/62 [00:07<00:00,  8.14it/s]\n",
      "epoch-50  lr=['0.0006699'], tr/val_loss:  0.030853/  1.500396, tr: 100.00%, val:  80.42%, val_best:  82.92%: 100%|██████████| 62/62 [00:06<00:00,  9.73it/s]\n",
      "epoch-51  lr=['0.0005450'], tr/val_loss:  0.027052/  1.505222, tr: 100.00%, val:  80.00%, val_best:  82.92%: 100%|██████████| 62/62 [00:06<00:00,  9.12it/s]\n",
      "epoch-52  lr=['0.0004323'], tr/val_loss:  0.027613/  1.521328, tr: 100.00%, val:  80.83%, val_best:  82.92%: 100%|██████████| 62/62 [00:06<00:00, 10.13it/s]\n",
      "epoch-53  lr=['0.0003321'], tr/val_loss:  0.024947/  1.515455, tr: 100.00%, val:  81.25%, val_best:  82.92%: 100%|██████████| 62/62 [00:06<00:00,  9.41it/s]\n",
      "epoch-54  lr=['0.0002447'], tr/val_loss:  0.024290/  1.516456, tr: 100.00%, val:  80.42%, val_best:  82.92%: 100%|██████████| 62/62 [00:05<00:00, 11.23it/s]\n",
      "epoch-55  lr=['0.0001704'], tr/val_loss:  0.022337/  1.514032, tr: 100.00%, val:  80.83%, val_best:  82.92%: 100%|██████████| 62/62 [00:05<00:00, 10.82it/s]\n",
      "epoch-56  lr=['0.0001093'], tr/val_loss:  0.022063/  1.522397, tr: 100.00%, val:  80.83%, val_best:  82.92%: 100%|██████████| 62/62 [00:05<00:00, 10.41it/s]\n",
      "epoch-57  lr=['0.0000616'], tr/val_loss:  0.021828/  1.521360, tr: 100.00%, val:  80.83%, val_best:  82.92%: 100%|██████████| 62/62 [00:06<00:00,  9.50it/s]\n",
      "epoch-58  lr=['0.0000274'], tr/val_loss:  0.021440/  1.521503, tr: 100.00%, val:  80.42%, val_best:  82.92%: 100%|██████████| 62/62 [00:06<00:00,  9.54it/s]\n",
      "epoch-59  lr=['0.0000069'], tr/val_loss:  0.021665/  1.521327, tr: 100.00%, val:  80.42%, val_best:  82.92%: 100%|██████████| 62/62 [00:06<00:00,  9.26it/s]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a86fc0bdab2a42298891940f04ec15a2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='1.937 MB of 1.937 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>DFA_flag</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>epoch</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇████</td></tr><tr><td>iter_acc</td><td>▁▃▂▂▁▁▂▃▂▁▂▂▁▂▅▅▆▆▆▇▇█▇██▇██████████████</td></tr><tr><td>summary_val_acc</td><td>▁▂▂▂▂▂▂▂▂▂▂▂▂▃▅▆▇▇▇▇▇▇▇▇███▇████████████</td></tr><tr><td>tr_acc</td><td>▁▂▂▂▂▂▂▂▂▂▂▂▂▂▄▅▆▆▆▇▇▇▇▇████████████████</td></tr><tr><td>tr_epoch_loss</td><td>▁█████████████▆▄▄▃▃▃▃▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_acc_best</td><td>▁▂▂▂▂▂▂▂▂▂▂▂▂▃▅▆▇▇▇▇▇▇▇▇▇▇██████████████</td></tr><tr><td>val_acc_now</td><td>▁▂▂▂▂▂▂▂▂▂▂▂▂▃▅▆▇▇▇▇▇▇▇▇███▇████████████</td></tr><tr><td>val_loss</td><td>▁█████████████▅▅▅▅▄▄▅▅▅▅▅▅▅▅▅▅▅▅▆▆▆▆▆▆▆▆</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>DFA_flag</td><td>0.0</td></tr><tr><td>epoch</td><td>59</td></tr><tr><td>iter_acc</td><td>1.0</td></tr><tr><td>tr_acc</td><td>1.0</td></tr><tr><td>tr_epoch_loss</td><td>0.02166</td></tr><tr><td>val_acc_best</td><td>0.82917</td></tr><tr><td>val_acc_now</td><td>0.80417</td></tr><tr><td>val_loss</td><td>1.52133</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">lyric-sweep-16</strong> at: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/r3d9drh1' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/r3d9drh1</a><br/> View project at: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main</a><br/>Synced 7 W&B file(s), 0 media file(s), 0 artifact file(s) and 1 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20240822_174658-r3d9drh1/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require(\"core\")`! See https://wandb.me/wandb-core for more information."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Sweep Agent: Waiting for job.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Job received.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: vf5q7j9k with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBATCH: 16\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tDFA_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tIMAGE_SIZE: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tOTTT_input_trace_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tOTTT_sWS_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tTIME: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcfg: ['M', 'M', 200, 200]\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tconst2: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdecay: 0.25\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdrop_rate: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdvs_clipping: 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdvs_duration: 100000\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \te_transport_swap: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \te_transport_swap_coin: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \te_transport_swap_tr: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepoch_num: 60\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \texclude_class: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.01\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_sg_width: 2.570969004857107\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_reset: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_threshold: 2.985029943687466\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmerge_polarities: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tscheduler_name: CosineAnnealingLR\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsurrogate: hard_sigmoid\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \twhich_data: DVS_GESTURE_TONIC\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.17.7 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.17.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/nfs/home/bhkim003/github_folder/ByeonghyeonKim/my_snn/wandb/run-20240822_175353-vf5q7j9k</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/vf5q7j9k' target=\"_blank\">electric-sweep-19</a></strong> to <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/yxynyr6h' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/yxynyr6h</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/yxynyr6h' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/yxynyr6h</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/vf5q7j9k' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/vf5q7j9k</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BATCH' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'IMAGE_SIZE' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'which_data' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_threshold' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_reset' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_sg_width' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'cfg' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'learning_rate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'epoch_num' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'surrogate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'scheduler_name' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'dvs_clipping' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'dvs_duration' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'OTTT_sWS_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'DFA_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'OTTT_input_trace_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'e_transport_swap' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'e_transport_swap_tr' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'e_transport_swap_coin' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'drop_rate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'exclude_class' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'merge_polarities' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'TIME' was locked by 'sweep' (ignored update).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset_hash = 2bbd58b4e0d3c1e9ad501fad8a43feed\n",
      "cache path exists\n",
      "\n",
      "we will exclude the 'other' class. dvsgestrue 10 classes' indices exist. \n",
      "\n",
      "DataParallel(\n",
      "  (module): MY_SNN_FC_sstep(\n",
      "    (layers): MY_Sequential(\n",
      "      (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (2): DimChanger_for_FC_sstep()\n",
      "      (3): SYNAPSE_FC_trace_sstep()\n",
      "      (4): LIF_layer_trace_sstep()\n",
      "      (5): SYNAPSE_FC_trace_sstep()\n",
      "      (6): LIF_layer_trace_sstep()\n",
      "      (7): SYNAPSE_FC_trace_sstep()\n",
      "    )\n",
      "  )\n",
      ")\n",
      "==================================================\n",
      "My Num of PARAMS: 452,010, system's param_num : 452,010\n",
      "Memory: 1.72MiB at 32-bit\n",
      "==================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch-0   lr=['0.0100000'], tr/val_loss:  2.317507/  2.316367, tr:   9.70%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:08<00:00,  7.50it/s]\n",
      "epoch-1   lr=['0.0099931'], tr/val_loss:  2.316254/  2.314931, tr:  10.21%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:06<00:00,  9.21it/s]\n",
      "epoch-2   lr=['0.0099726'], tr/val_loss:  2.315321/  2.315877, tr:   9.81%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:06<00:00, 10.11it/s]\n",
      "epoch-3   lr=['0.0099384'], tr/val_loss:  2.319123/  2.321801, tr:  10.42%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:06<00:00,  9.39it/s]\n",
      "epoch-4   lr=['0.0098907'], tr/val_loss:  2.328817/  2.310750, tr:   7.66%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:06<00:00,  9.99it/s]\n",
      "epoch-5   lr=['0.0098296'], tr/val_loss:  2.318780/  2.313111, tr:   8.58%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:06<00:00,  9.38it/s]\n",
      "epoch-6   lr=['0.0097553'], tr/val_loss:  2.326567/  2.312034, tr:   8.89%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:06<00:00, 10.30it/s]\n",
      "epoch-7   lr=['0.0096679'], tr/val_loss:  2.319906/  2.308871, tr:   8.89%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:06<00:00, 10.05it/s]\n",
      "epoch-8   lr=['0.0095677'], tr/val_loss:  2.315703/  2.318316, tr:   9.09%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:05<00:00, 10.71it/s]\n",
      "epoch-9   lr=['0.0094550'], tr/val_loss:  2.315776/  2.321137, tr:   9.81%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:06<00:00,  9.52it/s]\n",
      "epoch-10  lr=['0.0093301'], tr/val_loss:  2.319218/  2.310921, tr:   9.40%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:06<00:00, 10.01it/s]\n",
      "epoch-11  lr=['0.0091934'], tr/val_loss:  2.320658/  2.318817, tr:   9.60%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:06<00:00, 10.15it/s]\n",
      "epoch-12  lr=['0.0090451'], tr/val_loss:  2.323760/  2.306959, tr:   9.70%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:05<00:00, 10.37it/s]\n",
      "epoch-13  lr=['0.0088857'], tr/val_loss:  2.312257/  2.313825, tr:   8.78%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:06<00:00, 10.20it/s]\n",
      "epoch-14  lr=['0.0087157'], tr/val_loss:  2.321870/  2.310401, tr:   9.70%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:06<00:00,  9.21it/s]\n",
      "epoch-15  lr=['0.0085355'], tr/val_loss:  2.318407/  2.313874, tr:   9.60%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:05<00:00, 10.69it/s]\n",
      "epoch-16  lr=['0.0083457'], tr/val_loss:  2.317499/  2.312321, tr:  10.11%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:06<00:00,  8.94it/s]\n",
      "epoch-17  lr=['0.0081466'], tr/val_loss:  2.318669/  2.307941, tr:   8.89%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:06<00:00, 10.19it/s]\n",
      "epoch-18  lr=['0.0079389'], tr/val_loss:  2.325135/  2.306585, tr:   7.46%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:06<00:00,  9.57it/s]\n",
      "epoch-19  lr=['0.0077232'], tr/val_loss:  2.314244/  2.310251, tr:  10.01%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:06<00:00, 10.21it/s]\n",
      "epoch-20  lr=['0.0075000'], tr/val_loss:  2.312182/  2.307967, tr:   9.91%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:07<00:00,  8.65it/s]\n",
      "epoch-21  lr=['0.0072700'], tr/val_loss:  2.318818/  2.307295, tr:   9.30%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:06<00:00,  9.98it/s]\n",
      "epoch-22  lr=['0.0070337'], tr/val_loss:  2.313441/  2.307399, tr:   9.91%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:06<00:00,  9.48it/s]\n",
      "epoch-23  lr=['0.0067918'], tr/val_loss:  2.314248/  2.309416, tr:   7.76%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:05<00:00, 10.43it/s]\n",
      "epoch-24  lr=['0.0065451'], tr/val_loss:  2.318841/  2.305136, tr:   9.09%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:06<00:00,  9.13it/s]\n",
      "epoch-25  lr=['0.0062941'], tr/val_loss:  2.316903/  2.306750, tr:   7.97%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:06<00:00, 10.31it/s]\n",
      "epoch-26  lr=['0.0060396'], tr/val_loss:  2.311055/  2.305107, tr:   8.99%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:06<00:00,  9.39it/s]\n",
      "epoch-27  lr=['0.0057822'], tr/val_loss:  2.313828/  2.306802, tr:   8.58%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:06<00:00,  9.75it/s]\n",
      "epoch-28  lr=['0.0055226'], tr/val_loss:  2.315332/  2.308450, tr:   8.68%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:06<00:00,  9.78it/s]\n",
      "epoch-29  lr=['0.0052617'], tr/val_loss:  2.315842/  2.306032, tr:   7.15%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:06<00:00,  9.62it/s]\n",
      "epoch-30  lr=['0.0050000'], tr/val_loss:  2.312570/  2.303939, tr:   8.89%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:05<00:00, 10.84it/s]\n",
      "epoch-31  lr=['0.0047383'], tr/val_loss:  2.309263/  2.303903, tr:   9.09%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:07<00:00,  8.62it/s]\n",
      "epoch-32  lr=['0.0044774'], tr/val_loss:  2.311847/  2.302894, tr:   8.38%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:05<00:00, 11.84it/s]\n",
      "epoch-33  lr=['0.0042178'], tr/val_loss:  2.308722/  2.303530, tr:   9.50%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:05<00:00, 11.47it/s]\n",
      "epoch-34  lr=['0.0039604'], tr/val_loss:  2.313000/  2.304187, tr:   8.48%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:05<00:00, 11.22it/s]\n",
      "epoch-35  lr=['0.0037059'], tr/val_loss:  2.309877/  2.303538, tr:   9.09%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:04<00:00, 12.59it/s]\n",
      "epoch-36  lr=['0.0034549'], tr/val_loss:  2.309406/  2.303601, tr:   8.99%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:05<00:00, 10.84it/s]\n",
      "epoch-37  lr=['0.0032082'], tr/val_loss:  2.309686/  2.303400, tr:   7.66%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:05<00:00, 12.29it/s]\n",
      "epoch-38  lr=['0.0029663'], tr/val_loss:  2.308588/  2.303166, tr:   9.09%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:06<00:00,  9.22it/s]\n",
      "epoch-39  lr=['0.0027300'], tr/val_loss:  2.308727/  2.302884, tr:   8.89%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:06<00:00, 10.09it/s]\n",
      "epoch-40  lr=['0.0025000'], tr/val_loss:  2.308749/  2.302732, tr:   9.40%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:06<00:00,  9.03it/s]\n",
      "epoch-41  lr=['0.0022768'], tr/val_loss:  2.306803/  2.302942, tr:   9.19%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:05<00:00, 11.04it/s]\n",
      "epoch-42  lr=['0.0020611'], tr/val_loss:  2.306347/  2.302762, tr:   8.68%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:06<00:00, 10.00it/s]\n",
      "epoch-43  lr=['0.0018534'], tr/val_loss:  2.305991/  2.302857, tr:   8.99%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:06<00:00,  9.24it/s]\n",
      "epoch-44  lr=['0.0016543'], tr/val_loss:  2.305293/  2.302853, tr:  10.01%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:05<00:00, 10.67it/s]\n",
      "epoch-45  lr=['0.0014645'], tr/val_loss:  2.306396/  2.302847, tr:   8.48%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:07<00:00,  8.30it/s]\n",
      "epoch-46  lr=['0.0012843'], tr/val_loss:  2.305307/  2.302670, tr:  10.01%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:05<00:00, 10.92it/s]\n",
      "epoch-47  lr=['0.0011143'], tr/val_loss:  2.305197/  2.302644, tr:   9.30%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:06<00:00,  8.97it/s]\n",
      "epoch-48  lr=['0.0009549'], tr/val_loss:  2.304637/  2.302745, tr:   8.78%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:06<00:00,  9.60it/s]\n",
      "epoch-49  lr=['0.0008066'], tr/val_loss:  2.304113/  2.302645, tr:   8.89%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:06<00:00,  8.99it/s]\n",
      "epoch-50  lr=['0.0006699'], tr/val_loss:  2.304358/  2.302700, tr:   8.68%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:06<00:00, 10.08it/s]\n",
      "epoch-51  lr=['0.0005450'], tr/val_loss:  2.303610/  2.302717, tr:   9.81%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:06<00:00,  9.02it/s]\n",
      "epoch-52  lr=['0.0004323'], tr/val_loss:  2.303667/  2.302626, tr:   9.30%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:06<00:00,  9.80it/s]\n",
      "epoch-53  lr=['0.0003321'], tr/val_loss:  2.303300/  2.302634, tr:   9.19%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:06<00:00, 10.28it/s]\n",
      "epoch-54  lr=['0.0002447'], tr/val_loss:  2.303030/  2.302622, tr:   8.38%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:05<00:00, 11.44it/s]\n",
      "epoch-55  lr=['0.0001704'], tr/val_loss:  2.303107/  2.302625, tr:  10.01%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:06<00:00, 10.12it/s]\n",
      "epoch-56  lr=['0.0001093'], tr/val_loss:  2.302886/  2.302609, tr:  10.01%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:06<00:00,  9.44it/s]\n",
      "epoch-57  lr=['0.0000616'], tr/val_loss:  2.302670/  2.302610, tr:  10.01%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:06<00:00,  9.37it/s]\n",
      "epoch-58  lr=['0.0000274'], tr/val_loss:  2.302685/  2.302609, tr:  10.01%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:05<00:00, 10.84it/s]\n",
      "epoch-59  lr=['0.0000069'], tr/val_loss:  2.302528/  2.302609, tr:  10.01%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:07<00:00,  8.43it/s]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8459d68c86474553b7e57f75ba55f850",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='1.937 MB of 1.937 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>DFA_flag</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>epoch</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇████</td></tr><tr><td>iter_acc</td><td>▁█▅▅▃▁▅█▆▃▆▅▃▃▁▃▃▃▁▁▁▁▆▅▁▃▁▅▃▅▃▅▃▃▅▅▁▃▅█</td></tr><tr><td>summary_val_acc</td><td>▁███████████████████████████████████████</td></tr><tr><td>tr_acc</td><td>▁███▇▇▇█▇███▇███▆▆▇▇▆▇▇▇▇▆▇▇▇▇██▇▇█▇▇███</td></tr><tr><td>tr_epoch_loss</td><td>▁███████████████████████████████████████</td></tr><tr><td>val_acc_best</td><td>▁███████████████████████████████████████</td></tr><tr><td>val_acc_now</td><td>▁███████████████████████████████████████</td></tr><tr><td>val_loss</td><td>▁███████████████████████████████████████</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>DFA_flag</td><td>0.0</td></tr><tr><td>epoch</td><td>59</td></tr><tr><td>iter_acc</td><td>0.33333</td></tr><tr><td>tr_acc</td><td>0.1001</td></tr><tr><td>tr_epoch_loss</td><td>2.30253</td></tr><tr><td>val_acc_best</td><td>0.1</td></tr><tr><td>val_acc_now</td><td>0.1</td></tr><tr><td>val_loss</td><td>2.30261</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">electric-sweep-19</strong> at: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/vf5q7j9k' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/vf5q7j9k</a><br/> View project at: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main</a><br/>Synced 7 W&B file(s), 0 media file(s), 0 artifact file(s) and 1 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20240822_175353-vf5q7j9k/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require(\"core\")`! See https://wandb.me/wandb-core for more information."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: uzf3es7x with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBATCH: 16\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tDFA_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tIMAGE_SIZE: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tOTTT_input_trace_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tOTTT_sWS_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tTIME: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcfg: ['M', 'M', 200, 200]\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tconst2: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdecay: 0.25\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdrop_rate: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdvs_clipping: 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdvs_duration: 100000\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \te_transport_swap: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \te_transport_swap_coin: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \te_transport_swap_tr: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepoch_num: 60\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \texclude_class: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.01\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_sg_width: 2.570969004857107\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_reset: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_threshold: 1.4096788633026152\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmerge_polarities: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tscheduler_name: CosineAnnealingLR\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsurrogate: hard_sigmoid\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \twhich_data: DVS_GESTURE_TONIC\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.17.7 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.17.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/nfs/home/bhkim003/github_folder/ByeonghyeonKim/my_snn/wandb/run-20240822_180041-uzf3es7x</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/uzf3es7x' target=\"_blank\">fine-sweep-22</a></strong> to <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/yxynyr6h' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/yxynyr6h</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/yxynyr6h' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/yxynyr6h</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/uzf3es7x' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/uzf3es7x</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BATCH' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'IMAGE_SIZE' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'which_data' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_threshold' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_reset' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_sg_width' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'cfg' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'learning_rate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'epoch_num' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'surrogate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'scheduler_name' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'dvs_clipping' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'dvs_duration' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'OTTT_sWS_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'DFA_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'OTTT_input_trace_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'e_transport_swap' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'e_transport_swap_tr' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'e_transport_swap_coin' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'drop_rate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'exclude_class' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'merge_polarities' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'TIME' was locked by 'sweep' (ignored update).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset_hash = 2bbd58b4e0d3c1e9ad501fad8a43feed\n",
      "cache path exists\n",
      "\n",
      "we will exclude the 'other' class. dvsgestrue 10 classes' indices exist. \n",
      "\n",
      "DataParallel(\n",
      "  (module): MY_SNN_FC_sstep(\n",
      "    (layers): MY_Sequential(\n",
      "      (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (2): DimChanger_for_FC_sstep()\n",
      "      (3): SYNAPSE_FC_trace_sstep()\n",
      "      (4): LIF_layer_trace_sstep()\n",
      "      (5): SYNAPSE_FC_trace_sstep()\n",
      "      (6): LIF_layer_trace_sstep()\n",
      "      (7): SYNAPSE_FC_trace_sstep()\n",
      "    )\n",
      "  )\n",
      ")\n",
      "==================================================\n",
      "My Num of PARAMS: 452,010, system's param_num : 452,010\n",
      "Memory: 1.72MiB at 32-bit\n",
      "==================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch-0   lr=['0.0100000'], tr/val_loss:  2.317507/  2.316367, tr:   9.70%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:07<00:00,  7.83it/s]\n",
      "epoch-1   lr=['0.0099931'], tr/val_loss:  2.316254/  2.314931, tr:  10.21%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:05<00:00, 10.39it/s]\n",
      "epoch-2   lr=['0.0099726'], tr/val_loss:  2.315321/  2.315877, tr:   9.81%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:06<00:00,  9.95it/s]\n",
      "epoch-3   lr=['0.0099384'], tr/val_loss:  2.319123/  2.321801, tr:  10.42%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:06<00:00,  8.86it/s]\n",
      "epoch-4   lr=['0.0098907'], tr/val_loss:  2.328817/  2.310750, tr:   7.66%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:06<00:00,  9.81it/s]\n",
      "epoch-5   lr=['0.0098296'], tr/val_loss:  2.318780/  2.313111, tr:   8.58%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:05<00:00, 10.56it/s]\n",
      "epoch-6   lr=['0.0097553'], tr/val_loss:  2.326567/  2.312034, tr:   8.89%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:06<00:00, 10.00it/s]\n",
      "epoch-7   lr=['0.0096679'], tr/val_loss:  2.319906/  2.308871, tr:   8.89%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:06<00:00,  9.19it/s]\n",
      "epoch-8   lr=['0.0095677'], tr/val_loss:  2.315703/  2.318316, tr:   9.09%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:06<00:00,  9.59it/s]\n",
      "epoch-9   lr=['0.0094550'], tr/val_loss:  2.315776/  2.321137, tr:   9.81%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:06<00:00,  9.18it/s]\n",
      "epoch-10  lr=['0.0093301'], tr/val_loss:  2.319218/  2.310921, tr:   9.40%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:06<00:00,  9.25it/s]\n",
      "epoch-11  lr=['0.0091934'], tr/val_loss:  2.320658/  2.318817, tr:   9.60%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:05<00:00, 11.86it/s]\n",
      "epoch-12  lr=['0.0090451'], tr/val_loss:  2.323760/  2.306959, tr:   9.70%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:06<00:00,  9.41it/s]\n",
      "epoch-13  lr=['0.0088857'], tr/val_loss:  2.312257/  2.313825, tr:   8.78%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:06<00:00,  9.36it/s]\n",
      "epoch-14  lr=['0.0087157'], tr/val_loss:  2.321870/  2.310401, tr:   9.70%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:05<00:00, 10.44it/s]\n",
      "epoch-15  lr=['0.0085355'], tr/val_loss:  2.318393/  2.313874, tr:   9.60%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:06<00:00,  9.57it/s]\n",
      "epoch-16  lr=['0.0083457'], tr/val_loss:  2.317485/  2.312322, tr:  10.11%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:06<00:00,  8.99it/s]\n",
      "epoch-17  lr=['0.0081466'], tr/val_loss:  2.318655/  2.307941, tr:   8.89%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:06<00:00,  9.24it/s]\n",
      "epoch-18  lr=['0.0079389'], tr/val_loss:  2.325106/  2.306584, tr:   7.46%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:05<00:00, 10.52it/s]\n",
      "epoch-19  lr=['0.0077232'], tr/val_loss:  2.314133/  2.310154, tr:  10.01%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:06<00:00, 10.21it/s]\n",
      "epoch-20  lr=['0.0075000'], tr/val_loss:  2.311513/  2.304215, tr:  10.11%, val:  10.42%, val_best:  10.42%: 100%|██████████| 62/62 [00:05<00:00, 11.69it/s]\n",
      "epoch-21  lr=['0.0072700'], tr/val_loss:  2.178650/  2.028589, tr:  15.02%, val:  22.92%, val_best:  22.92%: 100%|██████████| 62/62 [00:05<00:00, 10.46it/s]\n",
      "epoch-22  lr=['0.0070337'], tr/val_loss:  1.860689/  1.755402, tr:  26.76%, val:  31.25%, val_best:  31.25%: 100%|██████████| 62/62 [00:05<00:00, 12.08it/s]\n",
      "epoch-23  lr=['0.0067918'], tr/val_loss:  1.501644/  1.401278, tr:  50.87%, val:  62.92%, val_best:  62.92%: 100%|██████████| 62/62 [00:05<00:00, 11.94it/s]\n",
      "epoch-24  lr=['0.0065451'], tr/val_loss:  1.183283/  1.430165, tr:  61.80%, val:  52.92%, val_best:  62.92%: 100%|██████████| 62/62 [00:05<00:00, 11.01it/s]\n",
      "epoch-25  lr=['0.0062941'], tr/val_loss:  0.988589/  1.194514, tr:  66.60%, val:  58.75%, val_best:  62.92%: 100%|██████████| 62/62 [00:05<00:00, 11.21it/s]\n",
      "epoch-26  lr=['0.0060396'], tr/val_loss:  0.891257/  1.140084, tr:  68.13%, val:  62.50%, val_best:  62.92%: 100%|██████████| 62/62 [00:05<00:00, 11.03it/s]\n",
      "epoch-27  lr=['0.0057822'], tr/val_loss:  0.806472/  1.170068, tr:  71.20%, val:  65.42%, val_best:  65.42%: 100%|██████████| 62/62 [00:05<00:00, 10.45it/s]\n",
      "epoch-28  lr=['0.0055226'], tr/val_loss:  0.754585/  1.075443, tr:  74.26%, val:  65.42%, val_best:  65.42%: 100%|██████████| 62/62 [00:05<00:00, 11.75it/s]\n",
      "epoch-29  lr=['0.0052617'], tr/val_loss:  0.654687/  1.110986, tr:  76.51%, val:  67.92%, val_best:  67.92%: 100%|██████████| 62/62 [00:05<00:00, 10.93it/s]\n",
      "epoch-30  lr=['0.0050000'], tr/val_loss:  0.594793/  1.100114, tr:  77.02%, val:  67.50%, val_best:  67.92%: 100%|██████████| 62/62 [00:05<00:00, 11.54it/s]\n",
      "epoch-31  lr=['0.0047383'], tr/val_loss:  0.550998/  1.158354, tr:  78.75%, val:  66.25%, val_best:  67.92%: 100%|██████████| 62/62 [00:05<00:00, 10.76it/s]\n",
      "epoch-32  lr=['0.0044774'], tr/val_loss:  0.523277/  1.138543, tr:  79.88%, val:  66.67%, val_best:  67.92%: 100%|██████████| 62/62 [00:05<00:00, 11.87it/s]\n",
      "epoch-33  lr=['0.0042178'], tr/val_loss:  0.468113/  1.180047, tr:  82.84%, val:  70.83%, val_best:  70.83%: 100%|██████████| 62/62 [00:06<00:00, 10.25it/s]\n",
      "epoch-34  lr=['0.0039604'], tr/val_loss:  0.420175/  1.135792, tr:  85.19%, val:  73.33%, val_best:  73.33%: 100%|██████████| 62/62 [00:05<00:00, 11.24it/s]\n",
      "epoch-35  lr=['0.0037059'], tr/val_loss:  0.368320/  1.162439, tr:  86.52%, val:  72.92%, val_best:  73.33%: 100%|██████████| 62/62 [00:06<00:00,  9.77it/s]\n",
      "epoch-36  lr=['0.0034549'], tr/val_loss:  0.323889/  1.208642, tr:  92.34%, val:  72.08%, val_best:  73.33%: 100%|██████████| 62/62 [00:05<00:00, 11.55it/s]\n",
      "epoch-37  lr=['0.0032082'], tr/val_loss:  0.310544/  1.274225, tr:  89.27%, val:  68.33%, val_best:  73.33%: 100%|██████████| 62/62 [00:04<00:00, 12.57it/s]\n",
      "epoch-38  lr=['0.0029663'], tr/val_loss:  0.257147/  1.243131, tr:  93.77%, val:  75.42%, val_best:  75.42%: 100%|██████████| 62/62 [00:06<00:00, 10.30it/s]\n",
      "epoch-39  lr=['0.0027300'], tr/val_loss:  0.229423/  1.250725, tr:  94.59%, val:  72.08%, val_best:  75.42%: 100%|██████████| 62/62 [00:05<00:00, 11.47it/s]\n",
      "epoch-40  lr=['0.0025000'], tr/val_loss:  0.207551/  1.235126, tr:  96.53%, val:  75.83%, val_best:  75.83%: 100%|██████████| 62/62 [00:05<00:00, 10.43it/s]\n",
      "epoch-41  lr=['0.0022768'], tr/val_loss:  0.181669/  1.244536, tr:  98.47%, val:  78.75%, val_best:  78.75%: 100%|██████████| 62/62 [00:05<00:00, 11.42it/s]\n",
      "epoch-42  lr=['0.0020611'], tr/val_loss:  0.148274/  1.298104, tr:  99.18%, val:  77.50%, val_best:  78.75%: 100%|██████████| 62/62 [00:05<00:00, 11.97it/s]\n",
      "epoch-43  lr=['0.0018534'], tr/val_loss:  0.128658/  1.305907, tr:  99.80%, val:  80.83%, val_best:  80.83%: 100%|██████████| 62/62 [00:06<00:00, 10.25it/s]\n",
      "epoch-44  lr=['0.0016543'], tr/val_loss:  0.113534/  1.305667, tr:  99.90%, val:  78.75%, val_best:  80.83%: 100%|██████████| 62/62 [00:05<00:00, 11.41it/s]\n",
      "epoch-45  lr=['0.0014645'], tr/val_loss:  0.099864/  1.346553, tr:  99.90%, val:  77.50%, val_best:  80.83%: 100%|██████████| 62/62 [00:05<00:00, 11.77it/s]\n",
      "epoch-46  lr=['0.0012843'], tr/val_loss:  0.088640/  1.350849, tr: 100.00%, val:  79.58%, val_best:  80.83%: 100%|██████████| 62/62 [00:05<00:00, 10.88it/s]\n",
      "epoch-47  lr=['0.0011143'], tr/val_loss:  0.080860/  1.326722, tr: 100.00%, val:  78.75%, val_best:  80.83%: 100%|██████████| 62/62 [00:05<00:00, 11.73it/s]\n",
      "epoch-48  lr=['0.0009549'], tr/val_loss:  0.072971/  1.357426, tr: 100.00%, val:  80.42%, val_best:  80.83%: 100%|██████████| 62/62 [00:05<00:00, 11.29it/s]\n",
      "epoch-49  lr=['0.0008066'], tr/val_loss:  0.064691/  1.367014, tr: 100.00%, val:  81.25%, val_best:  81.25%: 100%|██████████| 62/62 [00:05<00:00, 11.01it/s]\n",
      "epoch-50  lr=['0.0006699'], tr/val_loss:  0.059715/  1.367979, tr: 100.00%, val:  79.58%, val_best:  81.25%: 100%|██████████| 62/62 [00:05<00:00, 11.20it/s]\n",
      "epoch-51  lr=['0.0005450'], tr/val_loss:  0.054894/  1.372947, tr: 100.00%, val:  81.67%, val_best:  81.67%: 100%|██████████| 62/62 [00:05<00:00, 10.93it/s]\n",
      "epoch-52  lr=['0.0004323'], tr/val_loss:  0.052877/  1.380050, tr: 100.00%, val:  79.17%, val_best:  81.67%: 100%|██████████| 62/62 [00:05<00:00, 11.03it/s]\n",
      "epoch-53  lr=['0.0003321'], tr/val_loss:  0.048907/  1.379308, tr: 100.00%, val:  79.58%, val_best:  81.67%: 100%|██████████| 62/62 [00:06<00:00,  9.31it/s]\n",
      "epoch-54  lr=['0.0002447'], tr/val_loss:  0.048660/  1.389234, tr: 100.00%, val:  80.83%, val_best:  81.67%: 100%|██████████| 62/62 [00:06<00:00,  9.70it/s]\n",
      "epoch-55  lr=['0.0001704'], tr/val_loss:  0.045941/  1.393094, tr: 100.00%, val:  80.42%, val_best:  81.67%: 100%|██████████| 62/62 [00:06<00:00,  9.48it/s]\n",
      "epoch-56  lr=['0.0001093'], tr/val_loss:  0.045176/  1.388131, tr: 100.00%, val:  81.67%, val_best:  81.67%: 100%|██████████| 62/62 [00:06<00:00,  9.71it/s]\n",
      "epoch-57  lr=['0.0000616'], tr/val_loss:  0.043944/  1.387171, tr: 100.00%, val:  80.83%, val_best:  81.67%: 100%|██████████| 62/62 [00:05<00:00, 10.42it/s]\n",
      "epoch-58  lr=['0.0000274'], tr/val_loss:  0.043725/  1.390087, tr: 100.00%, val:  80.42%, val_best:  81.67%: 100%|██████████| 62/62 [00:06<00:00,  9.82it/s]\n",
      "epoch-59  lr=['0.0000069'], tr/val_loss:  0.044358/  1.388989, tr: 100.00%, val:  80.42%, val_best:  81.67%: 100%|██████████| 62/62 [00:06<00:00, 10.05it/s]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f28927e962e24fce8249647480bcbf99",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='1.937 MB of 1.937 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>DFA_flag</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>epoch</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇████</td></tr><tr><td>iter_acc</td><td>▁▃▂▂▁▁▂▃▂▁▂▂▁▁▁▄▄▆▆▇▇█▆▇█▇▇█████████████</td></tr><tr><td>summary_val_acc</td><td>▁▂▂▂▂▂▂▂▂▂▂▂▂▂▂▄▆▆▆▇▇▇▇▇▇▇▇▇████████████</td></tr><tr><td>tr_acc</td><td>▁▂▂▂▂▂▂▂▂▂▂▂▂▂▂▃▅▆▆▆▆▇▇▇▇▇██████████████</td></tr><tr><td>tr_epoch_loss</td><td>▁██████████████▇▆▄▄▃▃▃▃▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_acc_best</td><td>▁▂▂▂▂▂▂▂▂▂▂▂▂▂▂▄▆▆▆▇▇▇▇▇▇▇▇▇████████████</td></tr><tr><td>val_acc_now</td><td>▁▂▂▂▂▂▂▂▂▂▂▂▂▂▂▄▆▆▆▇▇▇▇▇▇▇▇▇████████████</td></tr><tr><td>val_loss</td><td>▁██████████████▆▅▅▄▄▄▄▄▄▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>DFA_flag</td><td>0.0</td></tr><tr><td>epoch</td><td>59</td></tr><tr><td>iter_acc</td><td>1.0</td></tr><tr><td>tr_acc</td><td>1.0</td></tr><tr><td>tr_epoch_loss</td><td>0.04436</td></tr><tr><td>val_acc_best</td><td>0.81667</td></tr><tr><td>val_acc_now</td><td>0.80417</td></tr><tr><td>val_loss</td><td>1.38899</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">fine-sweep-22</strong> at: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/uzf3es7x' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/uzf3es7x</a><br/> View project at: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main</a><br/>Synced 7 W&B file(s), 0 media file(s), 0 artifact file(s) and 1 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20240822_180041-uzf3es7x/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require(\"core\")`! See https://wandb.me/wandb-core for more information."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: m354r73d with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBATCH: 16\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tDFA_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tIMAGE_SIZE: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tOTTT_input_trace_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tOTTT_sWS_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tTIME: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcfg: ['M', 'M', 200, 200]\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tconst2: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdecay: 0.25\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdrop_rate: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdvs_clipping: 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdvs_duration: 100000\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \te_transport_swap: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \te_transport_swap_coin: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \te_transport_swap_tr: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepoch_num: 60\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \texclude_class: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.01\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_sg_width: 2.570969004857107\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_reset: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_threshold: 0.24110063691509345\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmerge_polarities: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tscheduler_name: CosineAnnealingLR\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsurrogate: hard_sigmoid\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \twhich_data: DVS_GESTURE_TONIC\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.17.7 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.17.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/nfs/home/bhkim003/github_folder/ByeonghyeonKim/my_snn/wandb/run-20240822_180709-m354r73d</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/m354r73d' target=\"_blank\">glowing-sweep-25</a></strong> to <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/yxynyr6h' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/yxynyr6h</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/yxynyr6h' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/yxynyr6h</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/m354r73d' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/m354r73d</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BATCH' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'IMAGE_SIZE' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'which_data' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_threshold' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_reset' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_sg_width' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'cfg' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'learning_rate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'epoch_num' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'surrogate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'scheduler_name' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'dvs_clipping' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'dvs_duration' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'OTTT_sWS_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'DFA_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'OTTT_input_trace_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'e_transport_swap' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'e_transport_swap_tr' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'e_transport_swap_coin' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'drop_rate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'exclude_class' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'merge_polarities' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'TIME' was locked by 'sweep' (ignored update).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset_hash = 2bbd58b4e0d3c1e9ad501fad8a43feed\n",
      "cache path exists\n",
      "\n",
      "we will exclude the 'other' class. dvsgestrue 10 classes' indices exist. \n",
      "\n",
      "DataParallel(\n",
      "  (module): MY_SNN_FC_sstep(\n",
      "    (layers): MY_Sequential(\n",
      "      (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (2): DimChanger_for_FC_sstep()\n",
      "      (3): SYNAPSE_FC_trace_sstep()\n",
      "      (4): LIF_layer_trace_sstep()\n",
      "      (5): SYNAPSE_FC_trace_sstep()\n",
      "      (6): LIF_layer_trace_sstep()\n",
      "      (7): SYNAPSE_FC_trace_sstep()\n",
      "    )\n",
      "  )\n",
      ")\n",
      "==================================================\n",
      "My Num of PARAMS: 452,010, system's param_num : 452,010\n",
      "Memory: 1.72MiB at 32-bit\n",
      "==================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch-0   lr=['0.0100000'], tr/val_loss:  1.513070/  1.273857, tr:  46.88%, val:  52.92%, val_best:  52.92%: 100%|██████████| 62/62 [00:06<00:00,  9.12it/s]\n",
      "epoch-1   lr=['0.0099931'], tr/val_loss:  1.098531/  1.401295, tr:  60.06%, val:  52.50%, val_best:  52.92%: 100%|██████████| 62/62 [00:06<00:00,  9.45it/s]\n",
      "epoch-2   lr=['0.0099726'], tr/val_loss:  0.949454/  1.281100, tr:  65.07%, val:  57.08%, val_best:  57.08%: 100%|██████████| 62/62 [00:05<00:00, 10.97it/s]\n",
      "epoch-3   lr=['0.0099384'], tr/val_loss:  0.852661/  1.075174, tr:  68.64%, val:  61.25%, val_best:  61.25%: 100%|██████████| 62/62 [00:06<00:00,  9.21it/s]\n",
      "epoch-4   lr=['0.0098907'], tr/val_loss:  0.787058/  1.259361, tr:  70.28%, val:  58.33%, val_best:  61.25%: 100%|██████████| 62/62 [00:06<00:00, 10.13it/s]\n",
      "epoch-5   lr=['0.0098296'], tr/val_loss:  0.765967/  1.243000, tr:  71.09%, val:  63.75%, val_best:  63.75%: 100%|██████████| 62/62 [00:06<00:00,  9.67it/s]\n",
      "epoch-6   lr=['0.0097553'], tr/val_loss:  0.648502/  1.183155, tr:  73.65%, val:  60.42%, val_best:  63.75%: 100%|██████████| 62/62 [00:05<00:00, 11.12it/s]\n",
      "epoch-7   lr=['0.0096679'], tr/val_loss:  0.640836/  1.338750, tr:  76.92%, val:  60.00%, val_best:  63.75%: 100%|██████████| 62/62 [00:06<00:00,  9.64it/s]\n",
      "epoch-8   lr=['0.0095677'], tr/val_loss:  0.595924/  1.195553, tr:  76.61%, val:  65.00%, val_best:  65.00%: 100%|██████████| 62/62 [00:06<00:00,  9.50it/s]\n",
      "epoch-9   lr=['0.0094550'], tr/val_loss:  0.460717/  1.414750, tr:  81.41%, val:  63.75%, val_best:  65.00%: 100%|██████████| 62/62 [00:05<00:00, 10.92it/s]\n",
      "epoch-10  lr=['0.0093301'], tr/val_loss:  0.472460/  1.289514, tr:  82.74%, val:  65.00%, val_best:  65.00%: 100%|██████████| 62/62 [00:06<00:00,  8.99it/s]\n",
      "epoch-11  lr=['0.0091934'], tr/val_loss:  0.429625/  1.539227, tr:  82.74%, val:  62.50%, val_best:  65.00%: 100%|██████████| 62/62 [00:06<00:00,  9.91it/s]\n",
      "epoch-12  lr=['0.0090451'], tr/val_loss:  0.458613/  1.212674, tr:  84.88%, val:  72.92%, val_best:  72.92%: 100%|██████████| 62/62 [00:06<00:00,  9.95it/s]\n",
      "epoch-13  lr=['0.0088857'], tr/val_loss:  0.378682/  1.280887, tr:  89.48%, val:  71.25%, val_best:  72.92%: 100%|██████████| 62/62 [00:06<00:00, 10.16it/s]\n",
      "epoch-14  lr=['0.0087157'], tr/val_loss:  0.301661/  1.305125, tr:  92.85%, val:  72.92%, val_best:  72.92%: 100%|██████████| 62/62 [00:06<00:00,  9.99it/s]\n",
      "epoch-15  lr=['0.0085355'], tr/val_loss:  0.302383/  1.391810, tr:  93.56%, val:  71.25%, val_best:  72.92%: 100%|██████████| 62/62 [00:06<00:00,  9.39it/s]\n",
      "epoch-16  lr=['0.0083457'], tr/val_loss:  0.282898/  1.582311, tr:  94.48%, val:  67.92%, val_best:  72.92%: 100%|██████████| 62/62 [00:06<00:00,  9.34it/s]\n",
      "epoch-17  lr=['0.0081466'], tr/val_loss:  0.292489/  1.440301, tr:  94.28%, val:  72.08%, val_best:  72.92%: 100%|██████████| 62/62 [00:06<00:00,  9.29it/s]\n",
      "epoch-18  lr=['0.0079389'], tr/val_loss:  0.250852/  1.332750, tr:  94.08%, val:  77.92%, val_best:  77.92%: 100%|██████████| 62/62 [00:06<00:00,  9.19it/s]\n",
      "epoch-19  lr=['0.0077232'], tr/val_loss:  0.165045/  1.482211, tr:  98.57%, val:  75.83%, val_best:  77.92%: 100%|██████████| 62/62 [00:06<00:00,  9.61it/s]\n",
      "epoch-20  lr=['0.0075000'], tr/val_loss:  0.139456/  1.581568, tr:  98.98%, val:  69.58%, val_best:  77.92%: 100%|██████████| 62/62 [00:06<00:00,  9.55it/s]\n",
      "epoch-21  lr=['0.0072700'], tr/val_loss:  0.114921/  1.479245, tr:  99.69%, val:  77.92%, val_best:  77.92%: 100%|██████████| 62/62 [00:06<00:00,  9.03it/s]\n",
      "epoch-22  lr=['0.0070337'], tr/val_loss:  0.078699/  1.501279, tr:  99.28%, val:  78.75%, val_best:  78.75%: 100%|██████████| 62/62 [00:06<00:00,  9.36it/s]\n",
      "epoch-23  lr=['0.0067918'], tr/val_loss:  0.051762/  1.526013, tr: 100.00%, val:  80.83%, val_best:  80.83%: 100%|██████████| 62/62 [00:06<00:00,  9.55it/s]\n",
      "epoch-24  lr=['0.0065451'], tr/val_loss:  0.042992/  1.634456, tr: 100.00%, val:  77.50%, val_best:  80.83%: 100%|██████████| 62/62 [00:06<00:00,  9.02it/s]\n",
      "epoch-25  lr=['0.0062941'], tr/val_loss:  0.024976/  1.699092, tr: 100.00%, val:  80.42%, val_best:  80.83%: 100%|██████████| 62/62 [00:06<00:00,  9.81it/s]\n",
      "epoch-26  lr=['0.0060396'], tr/val_loss:  0.012829/  1.646761, tr: 100.00%, val:  81.25%, val_best:  81.25%: 100%|██████████| 62/62 [00:06<00:00,  9.01it/s]\n",
      "epoch-27  lr=['0.0057822'], tr/val_loss:  0.010325/  1.664151, tr: 100.00%, val:  80.00%, val_best:  81.25%: 100%|██████████| 62/62 [00:07<00:00,  8.73it/s]\n",
      "epoch-28  lr=['0.0055226'], tr/val_loss:  0.008228/  1.658919, tr: 100.00%, val:  81.25%, val_best:  81.25%: 100%|██████████| 62/62 [00:05<00:00, 11.06it/s]\n",
      "epoch-29  lr=['0.0052617'], tr/val_loss:  0.005193/  1.689633, tr: 100.00%, val:  80.42%, val_best:  81.25%: 100%|██████████| 62/62 [00:05<00:00, 10.37it/s]\n",
      "epoch-30  lr=['0.0050000'], tr/val_loss:  0.003893/  1.700736, tr: 100.00%, val:  80.00%, val_best:  81.25%: 100%|██████████| 62/62 [00:06<00:00,  9.72it/s]\n",
      "epoch-31  lr=['0.0047383'], tr/val_loss:  0.003098/  1.698928, tr: 100.00%, val:  80.00%, val_best:  81.25%: 100%|██████████| 62/62 [00:05<00:00, 10.44it/s]\n",
      "epoch-32  lr=['0.0044774'], tr/val_loss:  0.002706/  1.688647, tr: 100.00%, val:  80.42%, val_best:  81.25%: 100%|██████████| 62/62 [00:07<00:00,  8.31it/s]\n",
      "epoch-33  lr=['0.0042178'], tr/val_loss:  0.002329/  1.714344, tr: 100.00%, val:  79.17%, val_best:  81.25%: 100%|██████████| 62/62 [00:06<00:00, 10.00it/s]\n",
      "epoch-34  lr=['0.0039604'], tr/val_loss:  0.002136/  1.723124, tr: 100.00%, val:  78.75%, val_best:  81.25%: 100%|██████████| 62/62 [00:05<00:00, 10.69it/s]\n",
      "epoch-35  lr=['0.0037059'], tr/val_loss:  0.002058/  1.734913, tr: 100.00%, val:  78.75%, val_best:  81.25%: 100%|██████████| 62/62 [00:05<00:00, 11.39it/s]\n",
      "epoch-36  lr=['0.0034549'], tr/val_loss:  0.002004/  1.745618, tr: 100.00%, val:  78.75%, val_best:  81.25%: 100%|██████████| 62/62 [00:05<00:00, 10.82it/s]\n",
      "epoch-37  lr=['0.0032082'], tr/val_loss:  0.001828/  1.757879, tr: 100.00%, val:  79.17%, val_best:  81.25%: 100%|██████████| 62/62 [00:05<00:00, 10.47it/s]\n",
      "epoch-38  lr=['0.0029663'], tr/val_loss:  0.001746/  1.757749, tr: 100.00%, val:  79.17%, val_best:  81.25%: 100%|██████████| 62/62 [00:06<00:00,  9.26it/s]\n",
      "epoch-39  lr=['0.0027300'], tr/val_loss:  0.001741/  1.756317, tr: 100.00%, val:  79.58%, val_best:  81.25%: 100%|██████████| 62/62 [00:06<00:00,  9.43it/s]\n",
      "epoch-40  lr=['0.0025000'], tr/val_loss:  0.001655/  1.749628, tr: 100.00%, val:  79.17%, val_best:  81.25%: 100%|██████████| 62/62 [00:06<00:00,  8.88it/s]\n",
      "epoch-41  lr=['0.0022768'], tr/val_loss:  0.001608/  1.754777, tr: 100.00%, val:  78.75%, val_best:  81.25%: 100%|██████████| 62/62 [00:05<00:00, 10.43it/s]\n",
      "epoch-42  lr=['0.0020611'], tr/val_loss:  0.001556/  1.762727, tr: 100.00%, val:  78.33%, val_best:  81.25%: 100%|██████████| 62/62 [00:06<00:00, 10.17it/s]\n",
      "epoch-43  lr=['0.0018534'], tr/val_loss:  0.001560/  1.764825, tr: 100.00%, val:  78.33%, val_best:  81.25%: 100%|██████████| 62/62 [00:06<00:00, 10.08it/s]\n",
      "epoch-44  lr=['0.0016543'], tr/val_loss:  0.001496/  1.767018, tr: 100.00%, val:  78.75%, val_best:  81.25%: 100%|██████████| 62/62 [00:06<00:00, 10.26it/s]\n",
      "epoch-45  lr=['0.0014645'], tr/val_loss:  0.001495/  1.768321, tr: 100.00%, val:  78.75%, val_best:  81.25%: 100%|██████████| 62/62 [00:06<00:00,  9.22it/s]\n",
      "epoch-46  lr=['0.0012843'], tr/val_loss:  0.001458/  1.764862, tr: 100.00%, val:  79.17%, val_best:  81.25%: 100%|██████████| 62/62 [00:05<00:00, 10.71it/s]\n",
      "epoch-47  lr=['0.0011143'], tr/val_loss:  0.001439/  1.772805, tr: 100.00%, val:  79.17%, val_best:  81.25%: 100%|██████████| 62/62 [00:06<00:00,  9.29it/s]\n",
      "epoch-48  lr=['0.0009549'], tr/val_loss:  0.001448/  1.773257, tr: 100.00%, val:  80.00%, val_best:  81.25%: 100%|██████████| 62/62 [00:05<00:00, 11.27it/s]\n",
      "epoch-49  lr=['0.0008066'], tr/val_loss:  0.001420/  1.777174, tr: 100.00%, val:  80.42%, val_best:  81.25%: 100%|██████████| 62/62 [00:05<00:00, 11.27it/s]\n",
      "epoch-50  lr=['0.0006699'], tr/val_loss:  0.001415/  1.777116, tr: 100.00%, val:  80.42%, val_best:  81.25%: 100%|██████████| 62/62 [00:05<00:00, 11.59it/s]\n",
      "epoch-51  lr=['0.0005450'], tr/val_loss:  0.001384/  1.770609, tr: 100.00%, val:  80.00%, val_best:  81.25%: 100%|██████████| 62/62 [00:04<00:00, 12.52it/s]\n",
      "epoch-52  lr=['0.0004323'], tr/val_loss:  0.001384/  1.774309, tr: 100.00%, val:  80.00%, val_best:  81.25%: 100%|██████████| 62/62 [00:07<00:00,  7.83it/s]\n",
      "epoch-53  lr=['0.0003321'], tr/val_loss:  0.001361/  1.773987, tr: 100.00%, val:  80.00%, val_best:  81.25%: 100%|██████████| 62/62 [00:07<00:00,  8.81it/s]\n",
      "epoch-54  lr=['0.0002447'], tr/val_loss:  0.001362/  1.771894, tr: 100.00%, val:  80.00%, val_best:  81.25%: 100%|██████████| 62/62 [00:06<00:00, 10.27it/s]\n",
      "epoch-55  lr=['0.0001704'], tr/val_loss:  0.001349/  1.771998, tr: 100.00%, val:  80.00%, val_best:  81.25%: 100%|██████████| 62/62 [00:06<00:00, 10.09it/s]\n",
      "epoch-56  lr=['0.0001093'], tr/val_loss:  0.001357/  1.770685, tr: 100.00%, val:  80.00%, val_best:  81.25%: 100%|██████████| 62/62 [00:06<00:00,  9.68it/s]\n",
      "epoch-57  lr=['0.0000616'], tr/val_loss:  0.001371/  1.771294, tr: 100.00%, val:  80.00%, val_best:  81.25%: 100%|██████████| 62/62 [00:05<00:00, 10.48it/s]\n",
      "epoch-58  lr=['0.0000274'], tr/val_loss:  0.001353/  1.771221, tr: 100.00%, val:  80.00%, val_best:  81.25%: 100%|██████████| 62/62 [00:06<00:00,  9.61it/s]\n",
      "epoch-59  lr=['0.0000069'], tr/val_loss:  0.001352/  1.771016, tr: 100.00%, val:  80.00%, val_best:  81.25%: 100%|██████████| 62/62 [00:06<00:00,  9.38it/s]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4d7eb2fd66434eee8b3bb1a79f5b337f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='1.937 MB of 1.937 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>DFA_flag</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>epoch</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇████</td></tr><tr><td>iter_acc</td><td>▁▁▃▁▃▆▃▆▅▅█▇▇███████████████████████████</td></tr><tr><td>summary_val_acc</td><td>▁▆▆▆▆▆▇▆▆▇▇▇▇█▇█████████████████████████</td></tr><tr><td>tr_acc</td><td>▁▄▆▆▆▆▆▇▇▇▇█████████████████████████████</td></tr><tr><td>tr_epoch_loss</td><td>▁█▅▅▅▄▄▃▃▃▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_acc_best</td><td>▁▆▆▆▆▆▇▇▇▇▇▇▇███████████████████████████</td></tr><tr><td>val_acc_now</td><td>▁▆▆▆▆▆▇▆▆▇▇▇▇█▇█████████████████████████</td></tr><tr><td>val_loss</td><td>▁▆▆▅▆▆▆▇▇▆▆▇▇▇▇▇▇█▇█████████████████████</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>DFA_flag</td><td>0.0</td></tr><tr><td>epoch</td><td>59</td></tr><tr><td>iter_acc</td><td>1.0</td></tr><tr><td>tr_acc</td><td>1.0</td></tr><tr><td>tr_epoch_loss</td><td>0.00135</td></tr><tr><td>val_acc_best</td><td>0.8125</td></tr><tr><td>val_acc_now</td><td>0.8</td></tr><tr><td>val_loss</td><td>1.77102</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">glowing-sweep-25</strong> at: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/m354r73d' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/m354r73d</a><br/> View project at: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main</a><br/>Synced 7 W&B file(s), 0 media file(s), 0 artifact file(s) and 1 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20240822_180709-m354r73d/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require(\"core\")`! See https://wandb.me/wandb-core for more information."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: k91tdsre with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBATCH: 16\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tDFA_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tIMAGE_SIZE: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tOTTT_input_trace_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tOTTT_sWS_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tTIME: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcfg: ['M', 'M', 200, 200]\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tconst2: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdecay: 0.25\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdrop_rate: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdvs_clipping: 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdvs_duration: 100000\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \te_transport_swap: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \te_transport_swap_coin: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \te_transport_swap_tr: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepoch_num: 60\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \texclude_class: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.01\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_sg_width: 2.570969004857107\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_reset: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_threshold: 1.6037822049215975\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmerge_polarities: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tscheduler_name: CosineAnnealingLR\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsurrogate: hard_sigmoid\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \twhich_data: DVS_GESTURE_TONIC\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "489c0191df2f45e78dec63866c7d38ad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.011114948377427127, max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.17.7 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.17.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/nfs/home/bhkim003/github_folder/ByeonghyeonKim/my_snn/wandb/run-20240822_181401-k91tdsre</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/k91tdsre' target=\"_blank\">sweet-sweep-28</a></strong> to <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/yxynyr6h' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/yxynyr6h</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/yxynyr6h' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/yxynyr6h</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/k91tdsre' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/k91tdsre</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BATCH' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'IMAGE_SIZE' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'which_data' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_threshold' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_reset' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_sg_width' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'cfg' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'learning_rate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'epoch_num' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'surrogate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'scheduler_name' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'dvs_clipping' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'dvs_duration' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'OTTT_sWS_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'DFA_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'OTTT_input_trace_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'e_transport_swap' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'e_transport_swap_tr' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'e_transport_swap_coin' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'drop_rate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'exclude_class' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'merge_polarities' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'TIME' was locked by 'sweep' (ignored update).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset_hash = 2bbd58b4e0d3c1e9ad501fad8a43feed\n",
      "cache path exists\n",
      "\n",
      "we will exclude the 'other' class. dvsgestrue 10 classes' indices exist. \n",
      "\n",
      "DataParallel(\n",
      "  (module): MY_SNN_FC_sstep(\n",
      "    (layers): MY_Sequential(\n",
      "      (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (2): DimChanger_for_FC_sstep()\n",
      "      (3): SYNAPSE_FC_trace_sstep()\n",
      "      (4): LIF_layer_trace_sstep()\n",
      "      (5): SYNAPSE_FC_trace_sstep()\n",
      "      (6): LIF_layer_trace_sstep()\n",
      "      (7): SYNAPSE_FC_trace_sstep()\n",
      "    )\n",
      "  )\n",
      ")\n",
      "==================================================\n",
      "My Num of PARAMS: 452,010, system's param_num : 452,010\n",
      "Memory: 1.72MiB at 32-bit\n",
      "==================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch-0   lr=['0.0100000'], tr/val_loss:  2.317507/  2.316367, tr:   9.70%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:06<00:00,  9.64it/s]\n",
      "epoch-1   lr=['0.0099931'], tr/val_loss:  2.316254/  2.314931, tr:  10.21%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:06<00:00, 10.29it/s]\n",
      "epoch-2   lr=['0.0099726'], tr/val_loss:  2.315321/  2.315877, tr:   9.81%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:07<00:00,  8.84it/s]\n",
      "epoch-3   lr=['0.0099384'], tr/val_loss:  2.319123/  2.321801, tr:  10.42%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:06<00:00, 10.02it/s]\n",
      "epoch-4   lr=['0.0098907'], tr/val_loss:  2.328817/  2.310750, tr:   7.66%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:06<00:00,  9.91it/s]\n",
      "epoch-5   lr=['0.0098296'], tr/val_loss:  2.318780/  2.313111, tr:   8.58%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:05<00:00, 11.28it/s]\n",
      "epoch-6   lr=['0.0097553'], tr/val_loss:  2.326567/  2.312034, tr:   8.89%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:05<00:00, 10.66it/s]\n",
      "epoch-7   lr=['0.0096679'], tr/val_loss:  2.319906/  2.308871, tr:   8.89%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:05<00:00, 11.79it/s]\n",
      "epoch-8   lr=['0.0095677'], tr/val_loss:  2.315703/  2.318316, tr:   9.09%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:05<00:00, 10.61it/s]\n",
      "epoch-9   lr=['0.0094550'], tr/val_loss:  2.315776/  2.321137, tr:   9.81%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:06<00:00, 10.00it/s]\n",
      "epoch-10  lr=['0.0093301'], tr/val_loss:  2.319218/  2.310921, tr:   9.40%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:06<00:00,  9.31it/s]\n",
      "epoch-11  lr=['0.0091934'], tr/val_loss:  2.320658/  2.318817, tr:   9.60%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:06<00:00,  9.75it/s]\n",
      "epoch-12  lr=['0.0090451'], tr/val_loss:  2.323760/  2.306959, tr:   9.70%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:06<00:00,  9.76it/s]\n",
      "epoch-13  lr=['0.0088857'], tr/val_loss:  2.312257/  2.313825, tr:   8.78%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:05<00:00, 11.01it/s]\n",
      "epoch-14  lr=['0.0087157'], tr/val_loss:  2.321870/  2.310401, tr:   9.70%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:05<00:00, 11.20it/s]\n",
      "epoch-15  lr=['0.0085355'], tr/val_loss:  2.318407/  2.313874, tr:   9.60%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:06<00:00,  9.04it/s]\n",
      "epoch-16  lr=['0.0083457'], tr/val_loss:  2.317499/  2.312321, tr:  10.11%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:05<00:00, 10.99it/s]\n",
      "epoch-17  lr=['0.0081466'], tr/val_loss:  2.318669/  2.307941, tr:   8.89%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:05<00:00, 11.21it/s]\n",
      "epoch-18  lr=['0.0079389'], tr/val_loss:  2.325135/  2.306585, tr:   7.46%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:06<00:00,  9.14it/s]\n",
      "epoch-19  lr=['0.0077232'], tr/val_loss:  2.314244/  2.310251, tr:  10.01%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:05<00:00, 11.03it/s]\n",
      "epoch-20  lr=['0.0075000'], tr/val_loss:  2.312182/  2.307967, tr:   9.91%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:05<00:00, 11.00it/s]\n",
      "epoch-21  lr=['0.0072700'], tr/val_loss:  2.318818/  2.307295, tr:   9.30%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:05<00:00, 10.44it/s]\n",
      "epoch-22  lr=['0.0070337'], tr/val_loss:  2.313441/  2.307399, tr:   9.91%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:05<00:00, 11.35it/s]\n",
      "epoch-23  lr=['0.0067918'], tr/val_loss:  2.314248/  2.309416, tr:   7.76%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:06<00:00, 10.13it/s]\n",
      "epoch-24  lr=['0.0065451'], tr/val_loss:  2.318841/  2.305136, tr:   9.09%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:05<00:00, 11.22it/s]\n",
      "epoch-25  lr=['0.0062941'], tr/val_loss:  2.316903/  2.306750, tr:   7.97%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:06<00:00, 10.28it/s]\n",
      "epoch-26  lr=['0.0060396'], tr/val_loss:  2.311055/  2.305107, tr:   8.99%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:06<00:00,  9.65it/s]\n",
      "epoch-27  lr=['0.0057822'], tr/val_loss:  2.313828/  2.306802, tr:   8.58%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:05<00:00, 10.92it/s]\n",
      "epoch-28  lr=['0.0055226'], tr/val_loss:  2.315332/  2.308450, tr:   8.68%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:05<00:00, 11.23it/s]\n",
      "epoch-29  lr=['0.0052617'], tr/val_loss:  2.315842/  2.306032, tr:   7.15%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:06<00:00,  9.96it/s]\n",
      "epoch-30  lr=['0.0050000'], tr/val_loss:  2.312570/  2.303939, tr:   8.89%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:06<00:00, 10.07it/s]\n",
      "epoch-31  lr=['0.0047383'], tr/val_loss:  2.309263/  2.303903, tr:   9.09%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:06<00:00,  9.20it/s]\n",
      "epoch-32  lr=['0.0044774'], tr/val_loss:  2.311847/  2.302894, tr:   8.38%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:07<00:00,  8.83it/s]\n",
      "epoch-33  lr=['0.0042178'], tr/val_loss:  2.308722/  2.303530, tr:   9.50%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:06<00:00, 10.21it/s]\n",
      "epoch-34  lr=['0.0039604'], tr/val_loss:  2.313000/  2.304187, tr:   8.48%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:05<00:00, 10.78it/s]\n",
      "epoch-35  lr=['0.0037059'], tr/val_loss:  2.309877/  2.303538, tr:   9.09%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:05<00:00, 10.88it/s]\n",
      "epoch-36  lr=['0.0034549'], tr/val_loss:  2.309406/  2.303601, tr:   8.99%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:05<00:00, 11.77it/s]\n",
      "epoch-37  lr=['0.0032082'], tr/val_loss:  2.309686/  2.303400, tr:   7.66%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:05<00:00, 11.43it/s]\n",
      "epoch-38  lr=['0.0029663'], tr/val_loss:  2.308588/  2.303166, tr:   9.09%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:05<00:00, 11.12it/s]\n",
      "epoch-39  lr=['0.0027300'], tr/val_loss:  2.308727/  2.302884, tr:   8.89%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:06<00:00, 10.00it/s]\n",
      "epoch-40  lr=['0.0025000'], tr/val_loss:  2.308749/  2.302732, tr:   9.40%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:07<00:00,  8.50it/s]\n",
      "epoch-41  lr=['0.0022768'], tr/val_loss:  2.306803/  2.302942, tr:   9.19%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:06<00:00,  9.63it/s]\n",
      "epoch-42  lr=['0.0020611'], tr/val_loss:  2.306347/  2.302762, tr:   8.68%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:05<00:00, 10.57it/s]\n",
      "epoch-43  lr=['0.0018534'], tr/val_loss:  2.305991/  2.302857, tr:   8.99%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:05<00:00, 10.77it/s]\n",
      "epoch-44  lr=['0.0016543'], tr/val_loss:  2.305293/  2.302853, tr:  10.01%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:06<00:00,  9.65it/s]\n",
      "epoch-45  lr=['0.0014645'], tr/val_loss:  2.306396/  2.302847, tr:   8.48%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:05<00:00, 10.47it/s]\n",
      "epoch-46  lr=['0.0012843'], tr/val_loss:  2.305307/  2.302670, tr:  10.01%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:06<00:00,  9.27it/s]\n",
      "epoch-47  lr=['0.0011143'], tr/val_loss:  2.305197/  2.302644, tr:   9.30%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:05<00:00, 10.47it/s]\n",
      "epoch-48  lr=['0.0009549'], tr/val_loss:  2.304637/  2.302745, tr:   8.78%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:13<00:00,  4.47it/s]\n",
      "epoch-49  lr=['0.0008066'], tr/val_loss:  2.304113/  2.302645, tr:   8.89%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:13<00:00,  4.46it/s]\n",
      "epoch-50  lr=['0.0006699'], tr/val_loss:  2.304358/  2.302700, tr:   8.68%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:05<00:00, 10.52it/s]\n",
      "epoch-51  lr=['0.0005450'], tr/val_loss:  2.303610/  2.302717, tr:   9.81%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:06<00:00,  9.55it/s]\n",
      "epoch-52  lr=['0.0004323'], tr/val_loss:  2.303667/  2.302626, tr:   9.30%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:09<00:00,  6.32it/s]\n",
      "epoch-53  lr=['0.0003321'], tr/val_loss:  2.303300/  2.302634, tr:   9.19%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:15<00:00,  4.09it/s]\n",
      "epoch-54  lr=['0.0002447'], tr/val_loss:  2.303030/  2.302622, tr:   8.38%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:08<00:00,  6.89it/s]\n",
      "epoch-55  lr=['0.0001704'], tr/val_loss:  2.303107/  2.302625, tr:  10.01%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:05<00:00, 10.77it/s]\n",
      "epoch-56  lr=['0.0001093'], tr/val_loss:  2.302886/  2.302609, tr:  10.01%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:06<00:00, 10.10it/s]\n",
      "epoch-57  lr=['0.0000616'], tr/val_loss:  2.302670/  2.302610, tr:  10.01%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:08<00:00,  6.93it/s]\n",
      "epoch-58  lr=['0.0000274'], tr/val_loss:  2.302685/  2.302609, tr:  10.01%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:15<00:00,  3.93it/s]\n",
      "epoch-59  lr=['0.0000069'], tr/val_loss:  2.302528/  2.302609, tr:  10.01%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:15<00:00,  4.10it/s]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7b18fc3bfb03483287a3fadec8e6aaeb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='1.937 MB of 1.937 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>DFA_flag</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>epoch</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇████</td></tr><tr><td>iter_acc</td><td>▁█▅▅▃▁▅█▆▃▆▅▃▃▁▃▃▃▁▁▁▁▆▅▁▃▁▅▃▅▃▅▃▃▅▅▁▃▅█</td></tr><tr><td>summary_val_acc</td><td>▁███████████████████████████████████████</td></tr><tr><td>tr_acc</td><td>▁███▇▇▇█▇███▇███▆▆▇▇▆▇▇▇▇▆▇▇▇▇██▇▇█▇▇███</td></tr><tr><td>tr_epoch_loss</td><td>▁███████████████████████████████████████</td></tr><tr><td>val_acc_best</td><td>▁███████████████████████████████████████</td></tr><tr><td>val_acc_now</td><td>▁███████████████████████████████████████</td></tr><tr><td>val_loss</td><td>▁███████████████████████████████████████</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>DFA_flag</td><td>0.0</td></tr><tr><td>epoch</td><td>59</td></tr><tr><td>iter_acc</td><td>0.33333</td></tr><tr><td>tr_acc</td><td>0.1001</td></tr><tr><td>tr_epoch_loss</td><td>2.30253</td></tr><tr><td>val_acc_best</td><td>0.1</td></tr><tr><td>val_acc_now</td><td>0.1</td></tr><tr><td>val_loss</td><td>2.30261</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">sweet-sweep-28</strong> at: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/k91tdsre' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/k91tdsre</a><br/> View project at: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main</a><br/>Synced 7 W&B file(s), 0 media file(s), 0 artifact file(s) and 1 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20240822_181401-k91tdsre/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require(\"core\")`! See https://wandb.me/wandb-core for more information."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 3gp46ewh with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBATCH: 16\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tDFA_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tIMAGE_SIZE: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tOTTT_input_trace_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tOTTT_sWS_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tTIME: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcfg: ['M', 'M', 200, 200]\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tconst2: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdecay: 0.25\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdrop_rate: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdvs_clipping: 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdvs_duration: 100000\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \te_transport_swap: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \te_transport_swap_coin: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \te_transport_swap_tr: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepoch_num: 60\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \texclude_class: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.01\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_sg_width: 2.570969004857107\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_reset: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_threshold: 0.3973343381043325\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmerge_polarities: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tscheduler_name: CosineAnnealingLR\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsurrogate: hard_sigmoid\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \twhich_data: DVS_GESTURE_TONIC\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.17.7 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.17.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/nfs/home/bhkim003/github_folder/ByeonghyeonKim/my_snn/wandb/run-20240822_182129-3gp46ewh</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/3gp46ewh' target=\"_blank\">grateful-sweep-31</a></strong> to <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/yxynyr6h' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/yxynyr6h</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/yxynyr6h' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/yxynyr6h</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/3gp46ewh' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/3gp46ewh</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BATCH' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'IMAGE_SIZE' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'which_data' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_threshold' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_reset' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_sg_width' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'cfg' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'learning_rate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'epoch_num' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'surrogate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'scheduler_name' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'dvs_clipping' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'dvs_duration' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'OTTT_sWS_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'DFA_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'OTTT_input_trace_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'e_transport_swap' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'e_transport_swap_tr' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'e_transport_swap_coin' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'drop_rate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'exclude_class' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'merge_polarities' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'TIME' was locked by 'sweep' (ignored update).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset_hash = 2bbd58b4e0d3c1e9ad501fad8a43feed\n",
      "cache path exists\n",
      "\n",
      "we will exclude the 'other' class. dvsgestrue 10 classes' indices exist. \n",
      "\n",
      "DataParallel(\n",
      "  (module): MY_SNN_FC_sstep(\n",
      "    (layers): MY_Sequential(\n",
      "      (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (2): DimChanger_for_FC_sstep()\n",
      "      (3): SYNAPSE_FC_trace_sstep()\n",
      "      (4): LIF_layer_trace_sstep()\n",
      "      (5): SYNAPSE_FC_trace_sstep()\n",
      "      (6): LIF_layer_trace_sstep()\n",
      "      (7): SYNAPSE_FC_trace_sstep()\n",
      "    )\n",
      "  )\n",
      ")\n",
      "==================================================\n",
      "My Num of PARAMS: 452,010, system's param_num : 452,010\n",
      "Memory: 1.72MiB at 32-bit\n",
      "==================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch-0   lr=['0.0100000'], tr/val_loss:  1.513602/  1.299559, tr:  47.80%, val:  54.58%, val_best:  54.58%: 100%|██████████| 62/62 [00:14<00:00,  4.29it/s]\n",
      "epoch-1   lr=['0.0099931'], tr/val_loss:  1.060527/  1.275925, tr:  60.98%, val:  53.75%, val_best:  54.58%: 100%|██████████| 62/62 [00:18<00:00,  3.31it/s]\n",
      "epoch-2   lr=['0.0099726'], tr/val_loss:  0.917085/  1.258073, tr:  65.37%, val:  58.33%, val_best:  58.33%: 100%|██████████| 62/62 [00:10<00:00,  6.04it/s]\n",
      "epoch-3   lr=['0.0099384'], tr/val_loss:  0.838985/  1.086981, tr:  69.15%, val:  63.75%, val_best:  63.75%: 100%|██████████| 62/62 [00:08<00:00,  7.55it/s]\n",
      "epoch-4   lr=['0.0098907'], tr/val_loss:  0.772283/  1.299563, tr:  71.60%, val:  58.33%, val_best:  63.75%: 100%|██████████| 62/62 [00:07<00:00,  8.50it/s]\n",
      "epoch-5   lr=['0.0098296'], tr/val_loss:  0.738884/  1.222141, tr:  71.60%, val:  64.58%, val_best:  64.58%: 100%|██████████| 62/62 [00:07<00:00,  8.01it/s]\n",
      "epoch-6   lr=['0.0097553'], tr/val_loss:  0.662183/  1.142085, tr:  75.69%, val:  62.92%, val_best:  64.58%: 100%|██████████| 62/62 [00:15<00:00,  3.92it/s]\n",
      "epoch-7   lr=['0.0096679'], tr/val_loss:  0.624486/  1.261799, tr:  77.12%, val:  62.08%, val_best:  64.58%: 100%|██████████| 62/62 [00:16<00:00,  3.86it/s]\n",
      "epoch-8   lr=['0.0095677'], tr/val_loss:  0.624924/  1.117092, tr:  76.71%, val:  64.58%, val_best:  64.58%: 100%|██████████| 62/62 [00:13<00:00,  4.52it/s]\n",
      "epoch-9   lr=['0.0094550'], tr/val_loss:  0.472145/  1.300446, tr:  83.96%, val:  67.50%, val_best:  67.50%: 100%|██████████| 62/62 [00:15<00:00,  3.99it/s]\n",
      "epoch-10  lr=['0.0093301'], tr/val_loss:  0.471703/  1.277156, tr:  84.37%, val:  63.75%, val_best:  67.50%: 100%|██████████| 62/62 [00:16<00:00,  3.75it/s]\n",
      "epoch-11  lr=['0.0091934'], tr/val_loss:  0.446901/  1.402014, tr:  83.76%, val:  67.50%, val_best:  67.50%: 100%|██████████| 62/62 [00:13<00:00,  4.70it/s]\n",
      "epoch-12  lr=['0.0090451'], tr/val_loss:  0.428873/  1.292156, tr:  88.05%, val:  74.17%, val_best:  74.17%: 100%|██████████| 62/62 [00:16<00:00,  3.76it/s]\n",
      "epoch-13  lr=['0.0088857'], tr/val_loss:  0.352747/  1.304237, tr:  93.05%, val:  73.33%, val_best:  74.17%: 100%|██████████| 62/62 [00:15<00:00,  3.91it/s]\n",
      "epoch-14  lr=['0.0087157'], tr/val_loss:  0.285561/  1.320582, tr:  94.48%, val:  74.17%, val_best:  74.17%: 100%|██████████| 62/62 [00:18<00:00,  3.43it/s]\n",
      "epoch-15  lr=['0.0085355'], tr/val_loss:  0.309750/  1.274299, tr:  92.65%, val:  72.92%, val_best:  74.17%: 100%|██████████| 62/62 [00:15<00:00,  3.89it/s]\n",
      "epoch-16  lr=['0.0083457'], tr/val_loss:  0.245471/  1.397278, tr:  96.02%, val:  73.33%, val_best:  74.17%: 100%|██████████| 62/62 [00:16<00:00,  3.67it/s]\n",
      "epoch-17  lr=['0.0081466'], tr/val_loss:  0.220860/  1.412892, tr:  96.94%, val:  73.75%, val_best:  74.17%: 100%|██████████| 62/62 [00:13<00:00,  4.61it/s]\n",
      "epoch-18  lr=['0.0079389'], tr/val_loss:  0.177900/  1.419043, tr:  98.06%, val:  78.33%, val_best:  78.33%: 100%|██████████| 62/62 [00:20<00:00,  2.97it/s]\n",
      "epoch-19  lr=['0.0077232'], tr/val_loss:  0.146262/  1.611642, tr:  98.88%, val:  74.58%, val_best:  78.33%: 100%|██████████| 62/62 [00:18<00:00,  3.39it/s]\n",
      "epoch-20  lr=['0.0075000'], tr/val_loss:  0.110741/  1.447674, tr:  99.90%, val:  80.00%, val_best:  80.00%: 100%|██████████| 62/62 [00:14<00:00,  4.37it/s]\n",
      "epoch-21  lr=['0.0072700'], tr/val_loss:  0.073424/  1.510206, tr:  99.80%, val:  80.83%, val_best:  80.83%: 100%|██████████| 62/62 [00:13<00:00,  4.52it/s]\n",
      "epoch-22  lr=['0.0070337'], tr/val_loss:  0.057554/  1.533402, tr:  99.80%, val:  80.83%, val_best:  80.83%: 100%|██████████| 62/62 [00:16<00:00,  3.67it/s]\n",
      "epoch-23  lr=['0.0067918'], tr/val_loss:  0.037118/  1.633219, tr: 100.00%, val:  76.67%, val_best:  80.83%: 100%|██████████| 62/62 [00:18<00:00,  3.38it/s]\n",
      "epoch-24  lr=['0.0065451'], tr/val_loss:  0.023343/  1.688028, tr: 100.00%, val:  80.42%, val_best:  80.83%: 100%|██████████| 62/62 [00:15<00:00,  3.99it/s]\n",
      "epoch-25  lr=['0.0062941'], tr/val_loss:  0.018907/  1.655216, tr: 100.00%, val:  81.25%, val_best:  81.25%: 100%|██████████| 62/62 [00:15<00:00,  4.11it/s]\n",
      "epoch-26  lr=['0.0060396'], tr/val_loss:  0.012081/  1.712613, tr: 100.00%, val:  79.17%, val_best:  81.25%: 100%|██████████| 62/62 [00:15<00:00,  3.88it/s]\n",
      "epoch-27  lr=['0.0057822'], tr/val_loss:  0.008228/  1.677441, tr: 100.00%, val:  81.25%, val_best:  81.25%: 100%|██████████| 62/62 [00:19<00:00,  3.25it/s]\n",
      "epoch-28  lr=['0.0055226'], tr/val_loss:  0.005117/  1.664693, tr: 100.00%, val:  82.50%, val_best:  82.50%: 100%|██████████| 62/62 [00:14<00:00,  4.32it/s]\n",
      "epoch-29  lr=['0.0052617'], tr/val_loss:  0.003693/  1.723661, tr: 100.00%, val:  81.25%, val_best:  82.50%: 100%|██████████| 62/62 [00:16<00:00,  3.85it/s]\n",
      "epoch-30  lr=['0.0050000'], tr/val_loss:  0.002772/  1.738612, tr: 100.00%, val:  81.25%, val_best:  82.50%: 100%|██████████| 62/62 [00:17<00:00,  3.45it/s]\n",
      "epoch-31  lr=['0.0047383'], tr/val_loss:  0.002518/  1.740473, tr: 100.00%, val:  80.83%, val_best:  82.50%: 100%|██████████| 62/62 [00:18<00:00,  3.30it/s]\n",
      "epoch-32  lr=['0.0044774'], tr/val_loss:  0.002196/  1.747347, tr: 100.00%, val:  81.25%, val_best:  82.50%: 100%|██████████| 62/62 [00:21<00:00,  2.87it/s]\n",
      "epoch-33  lr=['0.0042178'], tr/val_loss:  0.002002/  1.761021, tr: 100.00%, val:  81.25%, val_best:  82.50%: 100%|██████████| 62/62 [00:15<00:00,  3.93it/s]\n",
      "epoch-34  lr=['0.0039604'], tr/val_loss:  0.001783/  1.773819, tr: 100.00%, val:  81.25%, val_best:  82.50%: 100%|██████████| 62/62 [00:19<00:00,  3.14it/s]\n",
      "epoch-35  lr=['0.0037059'], tr/val_loss:  0.001759/  1.778564, tr: 100.00%, val:  81.25%, val_best:  82.50%: 100%|██████████| 62/62 [00:21<00:00,  2.82it/s]\n",
      "epoch-36  lr=['0.0034549'], tr/val_loss:  0.001676/  1.781062, tr: 100.00%, val:  81.25%, val_best:  82.50%: 100%|██████████| 62/62 [00:10<00:00,  6.12it/s]\n",
      "epoch-37  lr=['0.0032082'], tr/val_loss:  0.001630/  1.773809, tr: 100.00%, val:  81.25%, val_best:  82.50%: 100%|██████████| 62/62 [00:06<00:00, 10.21it/s]\n",
      "epoch-38  lr=['0.0029663'], tr/val_loss:  0.001509/  1.788450, tr: 100.00%, val:  81.25%, val_best:  82.50%: 100%|██████████| 62/62 [00:11<00:00,  5.54it/s]\n",
      "epoch-39  lr=['0.0027300'], tr/val_loss:  0.001447/  1.805675, tr: 100.00%, val:  81.25%, val_best:  82.50%: 100%|██████████| 62/62 [00:07<00:00,  8.47it/s]\n",
      "epoch-40  lr=['0.0025000'], tr/val_loss:  0.001385/  1.806793, tr: 100.00%, val:  81.25%, val_best:  82.50%: 100%|██████████| 62/62 [00:14<00:00,  4.25it/s]\n",
      "epoch-41  lr=['0.0022768'], tr/val_loss:  0.001334/  1.803936, tr: 100.00%, val:  81.25%, val_best:  82.50%: 100%|██████████| 62/62 [00:14<00:00,  4.15it/s]\n",
      "epoch-42  lr=['0.0020611'], tr/val_loss:  0.001285/  1.824966, tr: 100.00%, val:  81.25%, val_best:  82.50%: 100%|██████████| 62/62 [00:24<00:00,  2.53it/s]\n",
      "epoch-43  lr=['0.0018534'], tr/val_loss:  0.001307/  1.816369, tr: 100.00%, val:  81.25%, val_best:  82.50%: 100%|██████████| 62/62 [00:15<00:00,  4.01it/s]\n",
      "epoch-44  lr=['0.0016543'], tr/val_loss:  0.001243/  1.819884, tr: 100.00%, val:  81.25%, val_best:  82.50%: 100%|██████████| 62/62 [00:14<00:00,  4.34it/s]\n",
      "epoch-45  lr=['0.0014645'], tr/val_loss:  0.001231/  1.821090, tr: 100.00%, val:  81.25%, val_best:  82.50%: 100%|██████████| 62/62 [00:16<00:00,  3.82it/s]\n",
      "epoch-46  lr=['0.0012843'], tr/val_loss:  0.001237/  1.821711, tr: 100.00%, val:  80.83%, val_best:  82.50%: 100%|██████████| 62/62 [00:23<00:00,  2.68it/s]\n",
      "epoch-47  lr=['0.0011143'], tr/val_loss:  0.001185/  1.828871, tr: 100.00%, val:  80.83%, val_best:  82.50%: 100%|██████████| 62/62 [00:20<00:00,  3.01it/s]\n",
      "epoch-48  lr=['0.0009549'], tr/val_loss:  0.001175/  1.830872, tr: 100.00%, val:  81.25%, val_best:  82.50%: 100%|██████████| 62/62 [00:07<00:00,  8.68it/s]\n",
      "epoch-49  lr=['0.0008066'], tr/val_loss:  0.001152/  1.835033, tr: 100.00%, val:  81.25%, val_best:  82.50%: 100%|██████████| 62/62 [00:05<00:00, 12.19it/s]\n",
      "epoch-50  lr=['0.0006699'], tr/val_loss:  0.001170/  1.835846, tr: 100.00%, val:  81.67%, val_best:  82.50%: 100%|██████████| 62/62 [00:05<00:00, 12.11it/s]\n",
      "epoch-51  lr=['0.0005450'], tr/val_loss:  0.001121/  1.837324, tr: 100.00%, val:  81.25%, val_best:  82.50%: 100%|██████████| 62/62 [00:10<00:00,  5.75it/s]\n",
      "epoch-52  lr=['0.0004323'], tr/val_loss:  0.001124/  1.835230, tr: 100.00%, val:  81.25%, val_best:  82.50%: 100%|██████████| 62/62 [00:05<00:00, 11.27it/s]\n",
      "epoch-53  lr=['0.0003321'], tr/val_loss:  0.001097/  1.834445, tr: 100.00%, val:  81.25%, val_best:  82.50%: 100%|██████████| 62/62 [00:06<00:00,  9.22it/s]\n",
      "epoch-54  lr=['0.0002447'], tr/val_loss:  0.001136/  1.838961, tr: 100.00%, val:  81.25%, val_best:  82.50%: 100%|██████████| 62/62 [00:05<00:00, 10.50it/s]\n",
      "epoch-55  lr=['0.0001704'], tr/val_loss:  0.001103/  1.839328, tr: 100.00%, val:  81.25%, val_best:  82.50%: 100%|██████████| 62/62 [00:06<00:00,  9.57it/s]\n",
      "epoch-56  lr=['0.0001093'], tr/val_loss:  0.001110/  1.838518, tr: 100.00%, val:  81.25%, val_best:  82.50%: 100%|██████████| 62/62 [00:08<00:00,  7.39it/s]\n",
      "epoch-57  lr=['0.0000616'], tr/val_loss:  0.001104/  1.838177, tr: 100.00%, val:  81.25%, val_best:  82.50%: 100%|██████████| 62/62 [00:06<00:00,  9.98it/s]\n",
      "epoch-58  lr=['0.0000274'], tr/val_loss:  0.001113/  1.838769, tr: 100.00%, val:  81.25%, val_best:  82.50%: 100%|██████████| 62/62 [00:05<00:00, 10.47it/s]\n",
      "epoch-59  lr=['0.0000069'], tr/val_loss:  0.001105/  1.838773, tr: 100.00%, val:  81.25%, val_best:  82.50%: 100%|██████████| 62/62 [00:08<00:00,  7.19it/s]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eb782295ada347ef98a5d12e0966937b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='1.938 MB of 1.938 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>DFA_flag</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>epoch</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇████</td></tr><tr><td>iter_acc</td><td>▁▁▃▅▅▅▅▆▆▇▆█████████████████████████████</td></tr><tr><td>summary_val_acc</td><td>▁▆▆▆▆▆▆▇▇▇▇▇▇▇██████████████████████████</td></tr><tr><td>tr_acc</td><td>▁▄▆▆▆▆▆▇▇▇██████████████████████████████</td></tr><tr><td>tr_epoch_loss</td><td>▁█▅▅▄▄▄▃▃▃▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_acc_best</td><td>▁▆▆▆▆▆▆▇▇▇▇▇▇███████████████████████████</td></tr><tr><td>val_acc_now</td><td>▁▆▆▆▆▆▆▇▇▇▇▇▇▇██████████████████████████</td></tr><tr><td>val_loss</td><td>▁▆▆▅▆▅▅▆▆▆▆▆▆▇▇▇▇▇█▇████████████████████</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>DFA_flag</td><td>0.0</td></tr><tr><td>epoch</td><td>59</td></tr><tr><td>iter_acc</td><td>1.0</td></tr><tr><td>tr_acc</td><td>1.0</td></tr><tr><td>tr_epoch_loss</td><td>0.0011</td></tr><tr><td>val_acc_best</td><td>0.825</td></tr><tr><td>val_acc_now</td><td>0.8125</td></tr><tr><td>val_loss</td><td>1.83877</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">grateful-sweep-31</strong> at: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/3gp46ewh' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/3gp46ewh</a><br/> View project at: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main</a><br/>Synced 7 W&B file(s), 0 media file(s), 0 artifact file(s) and 1 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20240822_182129-3gp46ewh/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require(\"core\")`! See https://wandb.me/wandb-core for more information."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: gdk7o9dx with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBATCH: 16\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tDFA_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tIMAGE_SIZE: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tOTTT_input_trace_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tOTTT_sWS_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tTIME: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcfg: ['M', 'M', 200, 200]\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tconst2: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdecay: 0.25\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdrop_rate: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdvs_clipping: 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdvs_duration: 100000\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \te_transport_swap: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \te_transport_swap_coin: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \te_transport_swap_tr: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepoch_num: 60\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \texclude_class: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.01\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_sg_width: 2.570969004857107\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_reset: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_threshold: 1.4041240817126717\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmerge_polarities: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tscheduler_name: CosineAnnealingLR\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsurrogate: hard_sigmoid\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \twhich_data: DVS_GESTURE_TONIC\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.17.7 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.17.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/nfs/home/bhkim003/github_folder/ByeonghyeonKim/my_snn/wandb/run-20240822_183552-gdk7o9dx</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/gdk7o9dx' target=\"_blank\">wobbly-sweep-34</a></strong> to <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/yxynyr6h' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/yxynyr6h</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/yxynyr6h' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/yxynyr6h</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/gdk7o9dx' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/gdk7o9dx</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BATCH' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'IMAGE_SIZE' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'which_data' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_threshold' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_reset' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_sg_width' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'cfg' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'learning_rate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'epoch_num' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'surrogate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'scheduler_name' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'dvs_clipping' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'dvs_duration' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'OTTT_sWS_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'DFA_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'OTTT_input_trace_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'e_transport_swap' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'e_transport_swap_tr' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'e_transport_swap_coin' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'drop_rate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'exclude_class' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'merge_polarities' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'TIME' was locked by 'sweep' (ignored update).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset_hash = 2bbd58b4e0d3c1e9ad501fad8a43feed\n",
      "cache path exists\n",
      "\n",
      "we will exclude the 'other' class. dvsgestrue 10 classes' indices exist. \n",
      "\n",
      "DataParallel(\n",
      "  (module): MY_SNN_FC_sstep(\n",
      "    (layers): MY_Sequential(\n",
      "      (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (2): DimChanger_for_FC_sstep()\n",
      "      (3): SYNAPSE_FC_trace_sstep()\n",
      "      (4): LIF_layer_trace_sstep()\n",
      "      (5): SYNAPSE_FC_trace_sstep()\n",
      "      (6): LIF_layer_trace_sstep()\n",
      "      (7): SYNAPSE_FC_trace_sstep()\n",
      "    )\n",
      "  )\n",
      ")\n",
      "==================================================\n",
      "My Num of PARAMS: 452,010, system's param_num : 452,010\n",
      "Memory: 1.72MiB at 32-bit\n",
      "==================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch-0   lr=['0.0100000'], tr/val_loss:  2.317507/  2.316367, tr:   9.70%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:08<00:00,  6.95it/s]\n",
      "epoch-1   lr=['0.0099931'], tr/val_loss:  2.316254/  2.314931, tr:  10.21%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:05<00:00, 10.41it/s]\n",
      "epoch-2   lr=['0.0099726'], tr/val_loss:  2.315321/  2.315877, tr:   9.81%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:06<00:00,  9.97it/s]\n",
      "epoch-3   lr=['0.0099384'], tr/val_loss:  2.319123/  2.321801, tr:  10.42%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:06<00:00,  9.36it/s]\n",
      "epoch-4   lr=['0.0098907'], tr/val_loss:  2.328817/  2.310750, tr:   7.66%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:05<00:00, 10.64it/s]\n",
      "epoch-5   lr=['0.0098296'], tr/val_loss:  2.318780/  2.313111, tr:   8.58%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:14<00:00,  4.38it/s]\n",
      "epoch-6   lr=['0.0097553'], tr/val_loss:  2.326567/  2.312034, tr:   8.89%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:06<00:00,  8.95it/s]\n",
      "epoch-7   lr=['0.0096679'], tr/val_loss:  2.319906/  2.308871, tr:   8.89%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:05<00:00, 10.73it/s]\n",
      "epoch-8   lr=['0.0095677'], tr/val_loss:  2.315703/  2.318316, tr:   9.09%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:06<00:00,  9.57it/s]\n",
      "epoch-9   lr=['0.0094550'], tr/val_loss:  2.315776/  2.321137, tr:   9.81%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:05<00:00, 10.68it/s]\n",
      "epoch-10  lr=['0.0093301'], tr/val_loss:  2.319218/  2.310921, tr:   9.40%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:07<00:00,  8.80it/s]\n",
      "epoch-11  lr=['0.0091934'], tr/val_loss:  2.320658/  2.318817, tr:   9.60%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:06<00:00,  9.35it/s]\n",
      "epoch-12  lr=['0.0090451'], tr/val_loss:  2.323760/  2.306959, tr:   9.70%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:09<00:00,  6.26it/s]\n",
      "epoch-13  lr=['0.0088857'], tr/val_loss:  2.312243/  2.313826, tr:   8.78%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:07<00:00,  7.94it/s]\n",
      "epoch-14  lr=['0.0087157'], tr/val_loss:  2.321871/  2.310400, tr:   9.70%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:05<00:00, 11.72it/s]\n",
      "epoch-15  lr=['0.0085355'], tr/val_loss:  2.318393/  2.313874, tr:   9.60%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:06<00:00, 10.12it/s]\n",
      "epoch-16  lr=['0.0083457'], tr/val_loss:  2.317484/  2.312322, tr:  10.11%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:06<00:00, 10.06it/s]\n",
      "epoch-17  lr=['0.0081466'], tr/val_loss:  2.318655/  2.307941, tr:   8.89%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:06<00:00,  9.52it/s]\n",
      "epoch-18  lr=['0.0079389'], tr/val_loss:  2.325070/  2.306539, tr:   7.46%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:06<00:00,  9.36it/s]\n",
      "epoch-19  lr=['0.0077232'], tr/val_loss:  2.314097/  2.309390, tr:  10.01%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:06<00:00,  9.96it/s]\n",
      "epoch-20  lr=['0.0075000'], tr/val_loss:  2.250417/  2.107679, tr:  14.30%, val:  19.17%, val_best:  19.17%: 100%|██████████| 62/62 [00:07<00:00,  8.78it/s]\n",
      "epoch-21  lr=['0.0072700'], tr/val_loss:  1.900053/  1.767158, tr:  25.64%, val:  32.08%, val_best:  32.08%: 100%|██████████| 62/62 [00:11<00:00,  5.51it/s]\n",
      "epoch-22  lr=['0.0070337'], tr/val_loss:  1.521224/  1.445060, tr:  47.09%, val:  57.08%, val_best:  57.08%: 100%|██████████| 62/62 [00:05<00:00, 10.61it/s]\n",
      "epoch-23  lr=['0.0067918'], tr/val_loss:  1.209996/  1.322130, tr:  61.08%, val:  62.08%, val_best:  62.08%: 100%|██████████| 62/62 [00:06<00:00,  9.85it/s]\n",
      "epoch-24  lr=['0.0065451'], tr/val_loss:  1.063146/  1.313070, tr:  66.19%, val:  57.92%, val_best:  62.08%: 100%|██████████| 62/62 [00:05<00:00, 10.49it/s]\n",
      "epoch-25  lr=['0.0062941'], tr/val_loss:  0.909728/  1.131763, tr:  70.07%, val:  63.33%, val_best:  63.33%: 100%|██████████| 62/62 [00:08<00:00,  7.03it/s]\n",
      "epoch-26  lr=['0.0060396'], tr/val_loss:  0.816765/  1.105127, tr:  70.79%, val:  66.25%, val_best:  66.25%: 100%|██████████| 62/62 [00:06<00:00,  9.22it/s]\n",
      "epoch-27  lr=['0.0057822'], tr/val_loss:  0.763297/  1.191526, tr:  72.01%, val:  67.08%, val_best:  67.08%: 100%|██████████| 62/62 [00:09<00:00,  6.44it/s]\n",
      "epoch-28  lr=['0.0055226'], tr/val_loss:  0.665387/  1.006289, tr:  77.94%, val:  70.83%, val_best:  70.83%: 100%|██████████| 62/62 [00:13<00:00,  4.56it/s]\n",
      "epoch-29  lr=['0.0052617'], tr/val_loss:  0.601940/  1.115775, tr:  77.73%, val:  66.67%, val_best:  70.83%: 100%|██████████| 62/62 [00:05<00:00, 10.82it/s]\n",
      "epoch-30  lr=['0.0050000'], tr/val_loss:  0.534030/  1.110411, tr:  79.26%, val:  69.17%, val_best:  70.83%: 100%|██████████| 62/62 [00:08<00:00,  7.17it/s]\n",
      "epoch-31  lr=['0.0047383'], tr/val_loss:  0.489570/  1.211716, tr:  80.69%, val:  70.83%, val_best:  70.83%: 100%|██████████| 62/62 [00:06<00:00,  9.28it/s]\n",
      "epoch-32  lr=['0.0044774'], tr/val_loss:  0.477714/  1.136420, tr:  81.92%, val:  69.58%, val_best:  70.83%: 100%|██████████| 62/62 [00:08<00:00,  7.66it/s]\n",
      "epoch-33  lr=['0.0042178'], tr/val_loss:  0.422011/  1.158547, tr:  86.11%, val:  70.83%, val_best:  70.83%: 100%|██████████| 62/62 [00:06<00:00,  9.08it/s]\n",
      "epoch-34  lr=['0.0039604'], tr/val_loss:  0.371678/  1.202507, tr:  87.44%, val:  71.25%, val_best:  71.25%: 100%|██████████| 62/62 [00:07<00:00,  8.72it/s]\n",
      "epoch-35  lr=['0.0037059'], tr/val_loss:  0.339151/  1.215635, tr:  87.95%, val:  72.50%, val_best:  72.50%: 100%|██████████| 62/62 [00:06<00:00,  9.90it/s]\n",
      "epoch-36  lr=['0.0034549'], tr/val_loss:  0.292755/  1.282574, tr:  94.18%, val:  71.67%, val_best:  72.50%: 100%|██████████| 62/62 [00:09<00:00,  6.87it/s]\n",
      "epoch-37  lr=['0.0032082'], tr/val_loss:  0.290224/  1.323372, tr:  90.09%, val:  69.58%, val_best:  72.50%: 100%|██████████| 62/62 [00:06<00:00, 10.15it/s]\n",
      "epoch-38  lr=['0.0029663'], tr/val_loss:  0.230647/  1.288676, tr:  93.16%, val:  74.58%, val_best:  74.58%: 100%|██████████| 62/62 [00:05<00:00, 11.61it/s]\n",
      "epoch-39  lr=['0.0027300'], tr/val_loss:  0.209388/  1.350466, tr:  93.87%, val:  68.75%, val_best:  74.58%: 100%|██████████| 62/62 [00:05<00:00, 11.03it/s]\n",
      "epoch-40  lr=['0.0025000'], tr/val_loss:  0.177611/  1.321188, tr:  97.14%, val:  75.83%, val_best:  75.83%: 100%|██████████| 62/62 [00:05<00:00, 12.21it/s]\n",
      "epoch-41  lr=['0.0022768'], tr/val_loss:  0.158271/  1.322739, tr:  98.37%, val:  77.92%, val_best:  77.92%: 100%|██████████| 62/62 [00:10<00:00,  5.79it/s]\n",
      "epoch-42  lr=['0.0020611'], tr/val_loss:  0.130762/  1.364713, tr:  99.08%, val:  78.33%, val_best:  78.33%: 100%|██████████| 62/62 [00:07<00:00,  8.77it/s]\n",
      "epoch-43  lr=['0.0018534'], tr/val_loss:  0.114755/  1.380387, tr:  99.59%, val:  78.33%, val_best:  78.33%: 100%|██████████| 62/62 [00:05<00:00, 10.58it/s]\n",
      "epoch-44  lr=['0.0016543'], tr/val_loss:  0.103446/  1.426544, tr:  99.90%, val:  79.17%, val_best:  79.17%: 100%|██████████| 62/62 [00:11<00:00,  5.21it/s]\n",
      "epoch-45  lr=['0.0014645'], tr/val_loss:  0.093186/  1.420830, tr:  99.80%, val:  77.92%, val_best:  79.17%: 100%|██████████| 62/62 [00:06<00:00,  9.33it/s]\n",
      "epoch-46  lr=['0.0012843'], tr/val_loss:  0.079308/  1.448624, tr: 100.00%, val:  79.17%, val_best:  79.17%: 100%|██████████| 62/62 [00:06<00:00, 10.03it/s]\n",
      "epoch-47  lr=['0.0011143'], tr/val_loss:  0.071866/  1.461227, tr: 100.00%, val:  77.08%, val_best:  79.17%: 100%|██████████| 62/62 [00:06<00:00,  9.98it/s]\n",
      "epoch-48  lr=['0.0009549'], tr/val_loss:  0.065842/  1.461017, tr:  99.90%, val:  79.17%, val_best:  79.17%: 100%|██████████| 62/62 [00:10<00:00,  6.05it/s]\n",
      "epoch-49  lr=['0.0008066'], tr/val_loss:  0.058544/  1.469395, tr: 100.00%, val:  78.33%, val_best:  79.17%: 100%|██████████| 62/62 [00:09<00:00,  6.27it/s]\n",
      "epoch-50  lr=['0.0006699'], tr/val_loss:  0.053162/  1.477974, tr: 100.00%, val:  77.08%, val_best:  79.17%: 100%|██████████| 62/62 [00:06<00:00, 10.02it/s]\n",
      "epoch-51  lr=['0.0005450'], tr/val_loss:  0.049765/  1.479279, tr: 100.00%, val:  78.33%, val_best:  79.17%: 100%|██████████| 62/62 [00:05<00:00, 11.79it/s]\n",
      "epoch-52  lr=['0.0004323'], tr/val_loss:  0.048549/  1.495615, tr: 100.00%, val:  77.92%, val_best:  79.17%: 100%|██████████| 62/62 [00:06<00:00,  9.10it/s]\n",
      "epoch-53  lr=['0.0003321'], tr/val_loss:  0.045195/  1.487074, tr: 100.00%, val:  79.17%, val_best:  79.17%: 100%|██████████| 62/62 [00:06<00:00,  8.94it/s]\n",
      "epoch-54  lr=['0.0002447'], tr/val_loss:  0.042834/  1.502726, tr: 100.00%, val:  77.50%, val_best:  79.17%: 100%|██████████| 62/62 [00:05<00:00, 10.80it/s]\n",
      "epoch-55  lr=['0.0001704'], tr/val_loss:  0.040761/  1.500047, tr: 100.00%, val:  78.75%, val_best:  79.17%: 100%|██████████| 62/62 [00:06<00:00,  9.96it/s]\n",
      "epoch-56  lr=['0.0001093'], tr/val_loss:  0.040744/  1.504746, tr: 100.00%, val:  78.75%, val_best:  79.17%: 100%|██████████| 62/62 [00:05<00:00, 11.44it/s]\n",
      "epoch-57  lr=['0.0000616'], tr/val_loss:  0.039748/  1.503849, tr: 100.00%, val:  78.75%, val_best:  79.17%: 100%|██████████| 62/62 [00:10<00:00,  5.79it/s]\n",
      "epoch-58  lr=['0.0000274'], tr/val_loss:  0.039564/  1.503600, tr: 100.00%, val:  78.75%, val_best:  79.17%: 100%|██████████| 62/62 [00:06<00:00,  9.99it/s]\n",
      "epoch-59  lr=['0.0000069'], tr/val_loss:  0.040978/  1.503910, tr: 100.00%, val:  78.75%, val_best:  79.17%: 100%|██████████| 62/62 [00:06<00:00,  9.74it/s]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ec37050d7d7646278fefdb014dcf9b8e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='1.934 MB of 1.934 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>DFA_flag</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>epoch</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇████</td></tr><tr><td>iter_acc</td><td>▁▃▂▂▁▁▂▃▂▁▂▂▁▂▂▅▅▆▇▇▇▆▆▇█▆▇█████████████</td></tr><tr><td>summary_val_acc</td><td>▁▂▂▂▂▂▂▂▂▂▂▂▂▂▃▆▆▇▇▇▇▇▇▇▇▇██████████████</td></tr><tr><td>tr_acc</td><td>▁▂▂▂▂▂▂▂▂▂▂▂▂▂▂▄▅▆▆▆▆▇▇▇▇▇██████████████</td></tr><tr><td>tr_epoch_loss</td><td>▁██████████████▆▅▄▃▃▃▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_acc_best</td><td>▁▂▂▂▂▂▂▂▂▂▂▂▂▂▃▆▆▇▇▇▇▇▇▇▇▇██████████████</td></tr><tr><td>val_acc_now</td><td>▁▂▂▂▂▂▂▂▂▂▂▂▂▂▃▆▆▇▇▇▇▇▇▇▇▇██████████████</td></tr><tr><td>val_loss</td><td>▁█████████████▇▅▅▄▄▄▄▅▄▅▅▅▅▅▅▅▅▅▅▅▅▆▆▆▆▆</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>DFA_flag</td><td>0.0</td></tr><tr><td>epoch</td><td>59</td></tr><tr><td>iter_acc</td><td>1.0</td></tr><tr><td>tr_acc</td><td>1.0</td></tr><tr><td>tr_epoch_loss</td><td>0.04098</td></tr><tr><td>val_acc_best</td><td>0.79167</td></tr><tr><td>val_acc_now</td><td>0.7875</td></tr><tr><td>val_loss</td><td>1.50391</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">wobbly-sweep-34</strong> at: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/gdk7o9dx' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/gdk7o9dx</a><br/> View project at: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main</a><br/>Synced 7 W&B file(s), 0 media file(s), 0 artifact file(s) and 1 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20240822_183552-gdk7o9dx/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require(\"core\")`! See https://wandb.me/wandb-core for more information."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: fip0arhy with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBATCH: 16\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tDFA_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tIMAGE_SIZE: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tOTTT_input_trace_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tOTTT_sWS_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tTIME: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcfg: ['M', 'M', 200, 200]\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tconst2: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdecay: 0.25\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdrop_rate: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdvs_clipping: 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdvs_duration: 100000\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \te_transport_swap: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \te_transport_swap_coin: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \te_transport_swap_tr: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepoch_num: 60\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \texclude_class: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.01\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_sg_width: 2.570969004857107\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_reset: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_threshold: 0.33530321430319066\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmerge_polarities: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tscheduler_name: CosineAnnealingLR\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsurrogate: hard_sigmoid\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \twhich_data: DVS_GESTURE_TONIC\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.17.7 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.17.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/nfs/home/bhkim003/github_folder/ByeonghyeonKim/my_snn/wandb/run-20240822_184345-fip0arhy</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/fip0arhy' target=\"_blank\">lyric-sweep-37</a></strong> to <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/yxynyr6h' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/yxynyr6h</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/yxynyr6h' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/yxynyr6h</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/fip0arhy' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/fip0arhy</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BATCH' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'IMAGE_SIZE' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'which_data' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_threshold' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_reset' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_sg_width' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'cfg' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'learning_rate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'epoch_num' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'surrogate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'scheduler_name' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'dvs_clipping' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'dvs_duration' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'OTTT_sWS_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'DFA_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'OTTT_input_trace_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'e_transport_swap' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'e_transport_swap_tr' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'e_transport_swap_coin' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'drop_rate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'exclude_class' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'merge_polarities' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'TIME' was locked by 'sweep' (ignored update).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset_hash = 2bbd58b4e0d3c1e9ad501fad8a43feed\n",
      "cache path exists\n",
      "\n",
      "we will exclude the 'other' class. dvsgestrue 10 classes' indices exist. \n",
      "\n",
      "DataParallel(\n",
      "  (module): MY_SNN_FC_sstep(\n",
      "    (layers): MY_Sequential(\n",
      "      (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (2): DimChanger_for_FC_sstep()\n",
      "      (3): SYNAPSE_FC_trace_sstep()\n",
      "      (4): LIF_layer_trace_sstep()\n",
      "      (5): SYNAPSE_FC_trace_sstep()\n",
      "      (6): LIF_layer_trace_sstep()\n",
      "      (7): SYNAPSE_FC_trace_sstep()\n",
      "    )\n",
      "  )\n",
      ")\n",
      "==================================================\n",
      "My Num of PARAMS: 452,010, system's param_num : 452,010\n",
      "Memory: 1.72MiB at 32-bit\n",
      "==================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch-0   lr=['0.0100000'], tr/val_loss:  1.496389/  1.323576, tr:  48.11%, val:  48.33%, val_best:  48.33%: 100%|██████████| 62/62 [00:05<00:00, 10.82it/s]\n",
      "epoch-1   lr=['0.0099931'], tr/val_loss:  1.083903/  1.436457, tr:  60.57%, val:  50.00%, val_best:  50.00%: 100%|██████████| 62/62 [00:06<00:00,  9.89it/s]\n",
      "epoch-2   lr=['0.0099726'], tr/val_loss:  0.918255/  1.304698, tr:  66.29%, val:  58.75%, val_best:  58.75%: 100%|██████████| 62/62 [00:05<00:00, 10.40it/s]\n",
      "epoch-3   lr=['0.0099384'], tr/val_loss:  0.835219/  1.204142, tr:  71.20%, val:  62.50%, val_best:  62.50%: 100%|██████████| 62/62 [00:06<00:00, 10.01it/s]\n",
      "epoch-4   lr=['0.0098907'], tr/val_loss:  0.800857/  1.236836, tr:  69.15%, val:  60.83%, val_best:  62.50%: 100%|██████████| 62/62 [00:05<00:00, 10.47it/s]\n",
      "epoch-5   lr=['0.0098296'], tr/val_loss:  0.786908/  1.440273, tr:  69.77%, val:  58.33%, val_best:  62.50%: 100%|██████████| 62/62 [00:06<00:00,  9.47it/s]\n",
      "epoch-6   lr=['0.0097553'], tr/val_loss:  0.711478/  1.158784, tr:  71.91%, val:  66.25%, val_best:  66.25%: 100%|██████████| 62/62 [00:06<00:00,  9.91it/s]\n",
      "epoch-7   lr=['0.0096679'], tr/val_loss:  0.654089/  1.473018, tr:  75.38%, val:  56.25%, val_best:  66.25%: 100%|██████████| 62/62 [00:05<00:00, 11.40it/s]\n",
      "epoch-8   lr=['0.0095677'], tr/val_loss:  0.642779/  1.180688, tr:  74.26%, val:  66.67%, val_best:  66.67%: 100%|██████████| 62/62 [00:05<00:00, 10.38it/s]\n",
      "epoch-9   lr=['0.0094550'], tr/val_loss:  0.472586/  1.312254, tr:  82.94%, val:  67.92%, val_best:  67.92%: 100%|██████████| 62/62 [00:06<00:00, 10.08it/s]\n",
      "epoch-10  lr=['0.0093301'], tr/val_loss:  0.469879/  1.300905, tr:  85.29%, val:  64.17%, val_best:  67.92%: 100%|██████████| 62/62 [00:06<00:00, 10.16it/s]\n",
      "epoch-11  lr=['0.0091934'], tr/val_loss:  0.443401/  1.432872, tr:  83.55%, val:  66.25%, val_best:  67.92%: 100%|██████████| 62/62 [00:05<00:00, 10.59it/s]\n",
      "epoch-12  lr=['0.0090451'], tr/val_loss:  0.414257/  1.190843, tr:  88.76%, val:  75.83%, val_best:  75.83%: 100%|██████████| 62/62 [00:05<00:00, 10.67it/s]\n",
      "epoch-13  lr=['0.0088857'], tr/val_loss:  0.347480/  1.280520, tr:  92.34%, val:  72.50%, val_best:  75.83%: 100%|██████████| 62/62 [00:05<00:00, 10.80it/s]\n",
      "epoch-14  lr=['0.0087157'], tr/val_loss:  0.280368/  1.289897, tr:  94.48%, val:  75.42%, val_best:  75.83%: 100%|██████████| 62/62 [00:05<00:00, 11.57it/s]\n",
      "epoch-15  lr=['0.0085355'], tr/val_loss:  0.253038/  1.301632, tr:  96.22%, val:  78.33%, val_best:  78.33%: 100%|██████████| 62/62 [00:06<00:00, 10.15it/s]\n",
      "epoch-16  lr=['0.0083457'], tr/val_loss:  0.237700/  1.515313, tr:  96.73%, val:  71.67%, val_best:  78.33%: 100%|██████████| 62/62 [00:06<00:00,  9.63it/s]\n",
      "epoch-17  lr=['0.0081466'], tr/val_loss:  0.249104/  1.421895, tr:  95.91%, val:  70.83%, val_best:  78.33%: 100%|██████████| 62/62 [00:06<00:00,  9.79it/s]\n",
      "epoch-18  lr=['0.0079389'], tr/val_loss:  0.192207/  1.385341, tr:  97.85%, val:  77.08%, val_best:  78.33%: 100%|██████████| 62/62 [00:06<00:00,  9.51it/s]\n",
      "epoch-19  lr=['0.0077232'], tr/val_loss:  0.132287/  1.432511, tr:  98.77%, val:  75.83%, val_best:  78.33%: 100%|██████████| 62/62 [00:06<00:00, 10.02it/s]\n",
      "epoch-20  lr=['0.0075000'], tr/val_loss:  0.096136/  1.498084, tr: 100.00%, val:  77.50%, val_best:  78.33%: 100%|██████████| 62/62 [00:05<00:00, 10.58it/s]\n",
      "epoch-21  lr=['0.0072700'], tr/val_loss:  0.069210/  1.606017, tr:  99.80%, val:  76.25%, val_best:  78.33%: 100%|██████████| 62/62 [00:06<00:00,  9.82it/s]\n",
      "epoch-22  lr=['0.0070337'], tr/val_loss:  0.057639/  1.572932, tr: 100.00%, val:  75.00%, val_best:  78.33%: 100%|██████████| 62/62 [00:06<00:00, 10.16it/s]\n",
      "epoch-23  lr=['0.0067918'], tr/val_loss:  0.054770/  1.641331, tr:  99.90%, val:  75.00%, val_best:  78.33%: 100%|██████████| 62/62 [00:06<00:00,  9.26it/s]\n",
      "epoch-24  lr=['0.0065451'], tr/val_loss:  0.021890/  1.598266, tr: 100.00%, val:  76.67%, val_best:  78.33%: 100%|██████████| 62/62 [00:05<00:00, 10.65it/s]\n",
      "epoch-25  lr=['0.0062941'], tr/val_loss:  0.018210/  1.608194, tr: 100.00%, val:  77.92%, val_best:  78.33%: 100%|██████████| 62/62 [00:07<00:00,  7.76it/s]\n",
      "epoch-26  lr=['0.0060396'], tr/val_loss:  0.008545/  1.651132, tr: 100.00%, val:  77.92%, val_best:  78.33%: 100%|██████████| 62/62 [00:08<00:00,  7.20it/s]\n",
      "epoch-27  lr=['0.0057822'], tr/val_loss:  0.005772/  1.664341, tr: 100.00%, val:  75.83%, val_best:  78.33%: 100%|██████████| 62/62 [00:06<00:00,  9.70it/s]\n",
      "epoch-28  lr=['0.0055226'], tr/val_loss:  0.004272/  1.707111, tr: 100.00%, val:  76.67%, val_best:  78.33%: 100%|██████████| 62/62 [00:06<00:00, 10.22it/s]\n",
      "epoch-29  lr=['0.0052617'], tr/val_loss:  0.003450/  1.715462, tr: 100.00%, val:  75.83%, val_best:  78.33%: 100%|██████████| 62/62 [00:06<00:00, 10.02it/s]\n",
      "epoch-30  lr=['0.0050000'], tr/val_loss:  0.002920/  1.718781, tr: 100.00%, val:  77.50%, val_best:  78.33%: 100%|██████████| 62/62 [00:05<00:00, 10.48it/s]\n",
      "epoch-31  lr=['0.0047383'], tr/val_loss:  0.002471/  1.732957, tr: 100.00%, val:  77.50%, val_best:  78.33%: 100%|██████████| 62/62 [00:05<00:00, 11.32it/s]\n",
      "epoch-32  lr=['0.0044774'], tr/val_loss:  0.002157/  1.744028, tr: 100.00%, val:  77.92%, val_best:  78.33%: 100%|██████████| 62/62 [00:05<00:00, 10.51it/s]\n",
      "epoch-33  lr=['0.0042178'], tr/val_loss:  0.002061/  1.764196, tr: 100.00%, val:  75.83%, val_best:  78.33%: 100%|██████████| 62/62 [00:05<00:00, 10.91it/s]\n",
      "epoch-34  lr=['0.0039604'], tr/val_loss:  0.001845/  1.766787, tr: 100.00%, val:  75.83%, val_best:  78.33%: 100%|██████████| 62/62 [00:05<00:00, 11.03it/s]\n",
      "epoch-35  lr=['0.0037059'], tr/val_loss:  0.001726/  1.769719, tr: 100.00%, val:  75.83%, val_best:  78.33%: 100%|██████████| 62/62 [00:07<00:00,  8.74it/s]\n",
      "epoch-36  lr=['0.0034549'], tr/val_loss:  0.001546/  1.773217, tr: 100.00%, val:  76.25%, val_best:  78.33%: 100%|██████████| 62/62 [00:05<00:00, 10.76it/s]\n",
      "epoch-37  lr=['0.0032082'], tr/val_loss:  0.001457/  1.772476, tr: 100.00%, val:  75.83%, val_best:  78.33%: 100%|██████████| 62/62 [00:05<00:00, 11.31it/s]\n",
      "epoch-38  lr=['0.0029663'], tr/val_loss:  0.001434/  1.775213, tr: 100.00%, val:  75.83%, val_best:  78.33%: 100%|██████████| 62/62 [00:05<00:00, 12.16it/s]\n",
      "epoch-39  lr=['0.0027300'], tr/val_loss:  0.001362/  1.780796, tr: 100.00%, val:  75.83%, val_best:  78.33%: 100%|██████████| 62/62 [00:05<00:00, 11.92it/s]\n",
      "epoch-40  lr=['0.0025000'], tr/val_loss:  0.001351/  1.778436, tr: 100.00%, val:  76.25%, val_best:  78.33%: 100%|██████████| 62/62 [00:05<00:00, 12.18it/s]\n",
      "epoch-41  lr=['0.0022768'], tr/val_loss:  0.001306/  1.781046, tr: 100.00%, val:  77.08%, val_best:  78.33%: 100%|██████████| 62/62 [00:05<00:00, 12.27it/s]\n",
      "epoch-42  lr=['0.0020611'], tr/val_loss:  0.001270/  1.786353, tr: 100.00%, val:  76.25%, val_best:  78.33%: 100%|██████████| 62/62 [00:05<00:00, 10.36it/s]\n",
      "epoch-43  lr=['0.0018534'], tr/val_loss:  0.001250/  1.788711, tr: 100.00%, val:  75.83%, val_best:  78.33%: 100%|██████████| 62/62 [00:05<00:00, 11.05it/s]\n",
      "epoch-44  lr=['0.0016543'], tr/val_loss:  0.001219/  1.792915, tr: 100.00%, val:  75.42%, val_best:  78.33%: 100%|██████████| 62/62 [00:05<00:00, 10.81it/s]\n",
      "epoch-45  lr=['0.0014645'], tr/val_loss:  0.001203/  1.797964, tr: 100.00%, val:  75.42%, val_best:  78.33%: 100%|██████████| 62/62 [00:05<00:00, 11.14it/s]\n",
      "epoch-46  lr=['0.0012843'], tr/val_loss:  0.001194/  1.803762, tr: 100.00%, val:  75.42%, val_best:  78.33%: 100%|██████████| 62/62 [00:06<00:00,  8.91it/s]\n",
      "epoch-47  lr=['0.0011143'], tr/val_loss:  0.001166/  1.800615, tr: 100.00%, val:  75.42%, val_best:  78.33%: 100%|██████████| 62/62 [00:05<00:00, 10.76it/s]\n",
      "epoch-48  lr=['0.0009549'], tr/val_loss:  0.001180/  1.801534, tr: 100.00%, val:  75.42%, val_best:  78.33%: 100%|██████████| 62/62 [00:05<00:00, 10.60it/s]\n",
      "epoch-49  lr=['0.0008066'], tr/val_loss:  0.001115/  1.800211, tr: 100.00%, val:  75.83%, val_best:  78.33%: 100%|██████████| 62/62 [00:05<00:00, 10.86it/s]\n",
      "epoch-50  lr=['0.0006699'], tr/val_loss:  0.001120/  1.801146, tr: 100.00%, val:  75.83%, val_best:  78.33%: 100%|██████████| 62/62 [00:05<00:00, 10.62it/s]\n",
      "epoch-51  lr=['0.0005450'], tr/val_loss:  0.001109/  1.802068, tr: 100.00%, val:  75.83%, val_best:  78.33%: 100%|██████████| 62/62 [00:05<00:00, 10.83it/s]\n",
      "epoch-52  lr=['0.0004323'], tr/val_loss:  0.001115/  1.803449, tr: 100.00%, val:  75.83%, val_best:  78.33%: 100%|██████████| 62/62 [00:06<00:00,  9.67it/s]\n",
      "epoch-53  lr=['0.0003321'], tr/val_loss:  0.001108/  1.805761, tr: 100.00%, val:  75.83%, val_best:  78.33%: 100%|██████████| 62/62 [00:05<00:00, 11.28it/s]\n",
      "epoch-54  lr=['0.0002447'], tr/val_loss:  0.001122/  1.804594, tr: 100.00%, val:  75.83%, val_best:  78.33%: 100%|██████████| 62/62 [00:05<00:00, 10.54it/s]\n",
      "epoch-55  lr=['0.0001704'], tr/val_loss:  0.001090/  1.805561, tr: 100.00%, val:  75.83%, val_best:  78.33%: 100%|██████████| 62/62 [00:06<00:00,  9.01it/s]\n",
      "epoch-56  lr=['0.0001093'], tr/val_loss:  0.001091/  1.805107, tr: 100.00%, val:  75.83%, val_best:  78.33%: 100%|██████████| 62/62 [00:05<00:00, 10.44it/s]\n",
      "epoch-57  lr=['0.0000616'], tr/val_loss:  0.001092/  1.804975, tr: 100.00%, val:  75.83%, val_best:  78.33%: 100%|██████████| 62/62 [00:05<00:00, 10.68it/s]\n",
      "epoch-58  lr=['0.0000274'], tr/val_loss:  0.001090/  1.805134, tr: 100.00%, val:  75.83%, val_best:  78.33%: 100%|██████████| 62/62 [00:05<00:00, 10.55it/s]\n",
      "epoch-59  lr=['0.0000069'], tr/val_loss:  0.001081/  1.805139, tr: 100.00%, val:  75.83%, val_best:  78.33%: 100%|██████████| 62/62 [00:05<00:00, 11.42it/s]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "045fe4d6955c487983eba881fdc64c83",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='5.721 MB of 5.721 MB uploaded (2.160 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "W&B sync reduced upload amount by 36.9%"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>DFA_flag</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>epoch</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇████</td></tr><tr><td>iter_acc</td><td>▁▅▄▂▅▂▆▅▇▇██▇███████████████████████████</td></tr><tr><td>summary_val_acc</td><td>▁▅▆▇▆▇▇▇▇██▇▇███████████████████████████</td></tr><tr><td>tr_acc</td><td>▁▄▆▆▆▆▆▇▇▇██████████████████████████████</td></tr><tr><td>tr_epoch_loss</td><td>▁█▅▅▅▄▄▃▃▃▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_acc_best</td><td>▁▅▆▇▇▇▇▇▇███████████████████████████████</td></tr><tr><td>val_acc_now</td><td>▁▅▆▇▆▇▇▇▇██▇▇███████████████████████████</td></tr><tr><td>val_loss</td><td>▁▆▆▆▇▅▆▆▇▆▆▇▇▇▇▇▇▇▇█████████████████████</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>DFA_flag</td><td>0.0</td></tr><tr><td>epoch</td><td>59</td></tr><tr><td>iter_acc</td><td>1.0</td></tr><tr><td>tr_acc</td><td>1.0</td></tr><tr><td>tr_epoch_loss</td><td>0.00108</td></tr><tr><td>val_acc_best</td><td>0.78333</td></tr><tr><td>val_acc_now</td><td>0.75833</td></tr><tr><td>val_loss</td><td>1.80514</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">lyric-sweep-37</strong> at: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/fip0arhy' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/fip0arhy</a><br/> View project at: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main</a><br/>Synced 7 W&B file(s), 0 media file(s), 14 artifact file(s) and 1 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20240822_184345-fip0arhy/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require(\"core\")`! See https://wandb.me/wandb-core for more information."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 1px1yu0v with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBATCH: 16\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tDFA_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tIMAGE_SIZE: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tOTTT_input_trace_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tOTTT_sWS_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tTIME: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcfg: ['M', 'M', 200, 200]\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tconst2: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdecay: 0.25\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdrop_rate: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdvs_clipping: 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdvs_duration: 100000\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \te_transport_swap: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \te_transport_swap_coin: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \te_transport_swap_tr: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepoch_num: 60\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \texclude_class: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.01\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_sg_width: 2.570969004857107\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_reset: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_threshold: 0.46096324461292826\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmerge_polarities: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tscheduler_name: CosineAnnealingLR\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsurrogate: hard_sigmoid\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \twhich_data: DVS_GESTURE_TONIC\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.17.7 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.17.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/nfs/home/bhkim003/github_folder/ByeonghyeonKim/my_snn/wandb/run-20240822_185018-1px1yu0v</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/1px1yu0v' target=\"_blank\">earthy-sweep-39</a></strong> to <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/yxynyr6h' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/yxynyr6h</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/yxynyr6h' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/yxynyr6h</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/1px1yu0v' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/1px1yu0v</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BATCH' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'IMAGE_SIZE' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'which_data' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_threshold' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_reset' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_sg_width' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'cfg' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'learning_rate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'epoch_num' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'surrogate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'scheduler_name' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'dvs_clipping' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'dvs_duration' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'OTTT_sWS_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'DFA_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'OTTT_input_trace_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'e_transport_swap' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'e_transport_swap_tr' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'e_transport_swap_coin' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'drop_rate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'exclude_class' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'merge_polarities' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'TIME' was locked by 'sweep' (ignored update).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset_hash = 2bbd58b4e0d3c1e9ad501fad8a43feed\n",
      "cache path exists\n",
      "\n",
      "we will exclude the 'other' class. dvsgestrue 10 classes' indices exist. \n",
      "\n",
      "DataParallel(\n",
      "  (module): MY_SNN_FC_sstep(\n",
      "    (layers): MY_Sequential(\n",
      "      (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (2): DimChanger_for_FC_sstep()\n",
      "      (3): SYNAPSE_FC_trace_sstep()\n",
      "      (4): LIF_layer_trace_sstep()\n",
      "      (5): SYNAPSE_FC_trace_sstep()\n",
      "      (6): LIF_layer_trace_sstep()\n",
      "      (7): SYNAPSE_FC_trace_sstep()\n",
      "    )\n",
      "  )\n",
      ")\n",
      "==================================================\n",
      "My Num of PARAMS: 452,010, system's param_num : 452,010\n",
      "Memory: 1.72MiB at 32-bit\n",
      "==================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch-0   lr=['0.0100000'], tr/val_loss:  1.518525/  1.333384, tr:  47.29%, val:  50.00%, val_best:  50.00%: 100%|██████████| 62/62 [00:05<00:00, 11.81it/s]\n",
      "epoch-1   lr=['0.0099931'], tr/val_loss:  1.101721/  1.295802, tr:  59.35%, val:  55.42%, val_best:  55.42%: 100%|██████████| 62/62 [00:06<00:00, 10.28it/s]\n",
      "epoch-2   lr=['0.0099726'], tr/val_loss:  0.961175/  1.244892, tr:  64.96%, val:  58.33%, val_best:  58.33%: 100%|██████████| 62/62 [00:05<00:00, 11.51it/s]\n",
      "epoch-3   lr=['0.0099384'], tr/val_loss:  0.868223/  1.214903, tr:  67.82%, val:  57.08%, val_best:  58.33%: 100%|██████████| 62/62 [00:05<00:00, 11.55it/s]\n",
      "epoch-4   lr=['0.0098907'], tr/val_loss:  0.787432/  1.260732, tr:  71.20%, val:  60.00%, val_best:  60.00%: 100%|██████████| 62/62 [00:05<00:00, 12.05it/s]\n",
      "epoch-5   lr=['0.0098296'], tr/val_loss:  0.759187/  1.313418, tr:  72.73%, val:  62.08%, val_best:  62.08%: 100%|██████████| 62/62 [00:05<00:00, 11.95it/s]\n",
      "epoch-6   lr=['0.0097553'], tr/val_loss:  0.700054/  1.145026, tr:  72.93%, val:  63.33%, val_best:  63.33%: 100%|██████████| 62/62 [00:05<00:00, 11.73it/s]\n",
      "epoch-7   lr=['0.0096679'], tr/val_loss:  0.645243/  1.262344, tr:  74.77%, val:  60.83%, val_best:  63.33%: 100%|██████████| 62/62 [00:05<00:00, 12.01it/s]\n",
      "epoch-8   lr=['0.0095677'], tr/val_loss:  0.610732/  1.131724, tr:  77.43%, val:  71.25%, val_best:  71.25%: 100%|██████████| 62/62 [00:05<00:00, 11.98it/s]\n",
      "epoch-9   lr=['0.0094550'], tr/val_loss:  0.481868/  1.211673, tr:  82.23%, val:  66.25%, val_best:  71.25%: 100%|██████████| 62/62 [00:05<00:00, 11.89it/s]\n",
      "epoch-10  lr=['0.0093301'], tr/val_loss:  0.444567/  1.187067, tr:  86.72%, val:  69.17%, val_best:  71.25%: 100%|██████████| 62/62 [00:05<00:00, 12.00it/s]\n",
      "epoch-11  lr=['0.0091934'], tr/val_loss:  0.405076/  1.324035, tr:  86.01%, val:  66.67%, val_best:  71.25%: 100%|██████████| 62/62 [00:05<00:00, 12.32it/s]\n",
      "epoch-12  lr=['0.0090451'], tr/val_loss:  0.393595/  1.197400, tr:  90.70%, val:  75.00%, val_best:  75.00%: 100%|██████████| 62/62 [00:05<00:00, 11.76it/s]\n",
      "epoch-13  lr=['0.0088857'], tr/val_loss:  0.365327/  1.375246, tr:  90.60%, val:  67.92%, val_best:  75.00%: 100%|██████████| 62/62 [00:05<00:00, 10.52it/s]\n",
      "epoch-14  lr=['0.0087157'], tr/val_loss:  0.299551/  1.384765, tr:  93.77%, val:  72.08%, val_best:  75.00%: 100%|██████████| 62/62 [00:05<00:00, 11.79it/s]\n",
      "epoch-15  lr=['0.0085355'], tr/val_loss:  0.255886/  1.360957, tr:  95.20%, val:  72.08%, val_best:  75.00%: 100%|██████████| 62/62 [00:05<00:00, 11.85it/s]\n",
      "epoch-16  lr=['0.0083457'], tr/val_loss:  0.216158/  1.414222, tr:  97.14%, val:  72.92%, val_best:  75.00%: 100%|██████████| 62/62 [00:05<00:00, 12.08it/s]\n",
      "epoch-17  lr=['0.0081466'], tr/val_loss:  0.200560/  1.286222, tr:  96.94%, val:  76.67%, val_best:  76.67%: 100%|██████████| 62/62 [00:05<00:00, 11.77it/s]\n",
      "epoch-18  lr=['0.0079389'], tr/val_loss:  0.164604/  1.378965, tr:  97.75%, val:  78.33%, val_best:  78.33%: 100%|██████████| 62/62 [00:05<00:00, 12.26it/s]\n",
      "epoch-19  lr=['0.0077232'], tr/val_loss:  0.144120/  1.465331, tr:  98.67%, val:  75.83%, val_best:  78.33%: 100%|██████████| 62/62 [00:05<00:00, 11.46it/s]\n",
      "epoch-20  lr=['0.0075000'], tr/val_loss:  0.081220/  1.467916, tr:  99.90%, val:  74.17%, val_best:  78.33%: 100%|██████████| 62/62 [00:05<00:00, 11.95it/s]\n",
      "epoch-21  lr=['0.0072700'], tr/val_loss:  0.052099/  1.602575, tr: 100.00%, val:  74.58%, val_best:  78.33%: 100%|██████████| 62/62 [00:05<00:00, 12.01it/s]\n",
      "epoch-22  lr=['0.0070337'], tr/val_loss:  0.078309/  1.485913, tr:  99.49%, val:  81.25%, val_best:  81.25%: 100%|██████████| 62/62 [00:06<00:00, 10.26it/s]\n",
      "epoch-23  lr=['0.0067918'], tr/val_loss:  0.063418/  1.511265, tr:  99.90%, val:  76.67%, val_best:  81.25%: 100%|██████████| 62/62 [00:05<00:00, 11.69it/s]\n",
      "epoch-24  lr=['0.0065451'], tr/val_loss:  0.040865/  1.619877, tr: 100.00%, val:  76.67%, val_best:  81.25%: 100%|██████████| 62/62 [00:05<00:00, 10.34it/s]\n",
      "epoch-25  lr=['0.0062941'], tr/val_loss:  0.026923/  1.599340, tr:  99.90%, val:  77.08%, val_best:  81.25%: 100%|██████████| 62/62 [00:05<00:00, 11.47it/s]\n",
      "epoch-26  lr=['0.0060396'], tr/val_loss:  0.012087/  1.551408, tr: 100.00%, val:  79.17%, val_best:  81.25%: 100%|██████████| 62/62 [00:05<00:00, 12.19it/s]\n",
      "epoch-27  lr=['0.0057822'], tr/val_loss:  0.007519/  1.625879, tr: 100.00%, val:  81.25%, val_best:  81.25%: 100%|██████████| 62/62 [00:05<00:00, 11.67it/s]\n",
      "epoch-28  lr=['0.0055226'], tr/val_loss:  0.004601/  1.577092, tr: 100.00%, val:  81.67%, val_best:  81.67%: 100%|██████████| 62/62 [00:05<00:00, 11.88it/s]\n",
      "epoch-29  lr=['0.0052617'], tr/val_loss:  0.003664/  1.631225, tr: 100.00%, val:  80.83%, val_best:  81.67%: 100%|██████████| 62/62 [00:05<00:00, 11.98it/s]\n",
      "epoch-30  lr=['0.0050000'], tr/val_loss:  0.003511/  1.630459, tr: 100.00%, val:  80.00%, val_best:  81.67%: 100%|██████████| 62/62 [00:05<00:00, 11.91it/s]\n",
      "epoch-31  lr=['0.0047383'], tr/val_loss:  0.003469/  1.604973, tr: 100.00%, val:  81.25%, val_best:  81.67%: 100%|██████████| 62/62 [00:05<00:00, 11.90it/s]\n",
      "epoch-32  lr=['0.0044774'], tr/val_loss:  0.002383/  1.623312, tr: 100.00%, val:  80.83%, val_best:  81.67%: 100%|██████████| 62/62 [00:05<00:00, 12.06it/s]\n",
      "epoch-33  lr=['0.0042178'], tr/val_loss:  0.001938/  1.649562, tr: 100.00%, val:  79.58%, val_best:  81.67%: 100%|██████████| 62/62 [00:05<00:00, 11.83it/s]\n",
      "epoch-34  lr=['0.0039604'], tr/val_loss:  0.001723/  1.655607, tr: 100.00%, val:  79.17%, val_best:  81.67%: 100%|██████████| 62/62 [00:05<00:00, 10.96it/s]\n",
      "epoch-35  lr=['0.0037059'], tr/val_loss:  0.001600/  1.658012, tr: 100.00%, val:  80.00%, val_best:  81.67%: 100%|██████████| 62/62 [00:05<00:00, 11.80it/s]\n",
      "epoch-36  lr=['0.0034549'], tr/val_loss:  0.001477/  1.669852, tr: 100.00%, val:  79.17%, val_best:  81.67%: 100%|██████████| 62/62 [00:05<00:00, 11.50it/s]\n",
      "epoch-37  lr=['0.0032082'], tr/val_loss:  0.001400/  1.665224, tr: 100.00%, val:  80.00%, val_best:  81.67%: 100%|██████████| 62/62 [00:05<00:00, 11.71it/s]\n",
      "epoch-38  lr=['0.0029663'], tr/val_loss:  0.001384/  1.682687, tr: 100.00%, val:  79.58%, val_best:  81.67%: 100%|██████████| 62/62 [00:05<00:00, 11.35it/s]\n",
      "epoch-39  lr=['0.0027300'], tr/val_loss:  0.001397/  1.681926, tr: 100.00%, val:  80.00%, val_best:  81.67%: 100%|██████████| 62/62 [00:05<00:00, 11.80it/s]\n",
      "epoch-40  lr=['0.0025000'], tr/val_loss:  0.001300/  1.695091, tr: 100.00%, val:  78.75%, val_best:  81.67%: 100%|██████████| 62/62 [00:04<00:00, 13.07it/s]\n",
      "epoch-41  lr=['0.0022768'], tr/val_loss:  0.001263/  1.688778, tr: 100.00%, val:  79.58%, val_best:  81.67%: 100%|██████████| 62/62 [00:05<00:00, 12.32it/s]\n",
      "epoch-42  lr=['0.0020611'], tr/val_loss:  0.001206/  1.702457, tr: 100.00%, val:  79.58%, val_best:  81.67%: 100%|██████████| 62/62 [00:05<00:00, 12.11it/s]\n",
      "epoch-43  lr=['0.0018534'], tr/val_loss:  0.001180/  1.697886, tr: 100.00%, val:  79.58%, val_best:  81.67%: 100%|██████████| 62/62 [00:04<00:00, 12.59it/s]\n",
      "epoch-44  lr=['0.0016543'], tr/val_loss:  0.001162/  1.694767, tr: 100.00%, val:  79.58%, val_best:  81.67%: 100%|██████████| 62/62 [00:04<00:00, 12.68it/s]\n",
      "epoch-45  lr=['0.0014645'], tr/val_loss:  0.001163/  1.697999, tr: 100.00%, val:  80.00%, val_best:  81.67%: 100%|██████████| 62/62 [00:05<00:00, 12.03it/s]\n",
      "epoch-46  lr=['0.0012843'], tr/val_loss:  0.001144/  1.697829, tr: 100.00%, val:  80.00%, val_best:  81.67%: 100%|██████████| 62/62 [00:06<00:00,  9.70it/s]\n",
      "epoch-47  lr=['0.0011143'], tr/val_loss:  0.001134/  1.695352, tr: 100.00%, val:  80.00%, val_best:  81.67%: 100%|██████████| 62/62 [00:05<00:00, 11.95it/s]\n",
      "epoch-48  lr=['0.0009549'], tr/val_loss:  0.001154/  1.692169, tr: 100.00%, val:  80.00%, val_best:  81.67%: 100%|██████████| 62/62 [00:05<00:00, 11.43it/s]\n",
      "epoch-49  lr=['0.0008066'], tr/val_loss:  0.001079/  1.699607, tr: 100.00%, val:  80.00%, val_best:  81.67%: 100%|██████████| 62/62 [00:05<00:00, 11.91it/s]\n",
      "epoch-50  lr=['0.0006699'], tr/val_loss:  0.001073/  1.696678, tr: 100.00%, val:  80.00%, val_best:  81.67%: 100%|██████████| 62/62 [00:05<00:00, 12.17it/s]\n",
      "epoch-51  lr=['0.0005450'], tr/val_loss:  0.001060/  1.700806, tr: 100.00%, val:  80.00%, val_best:  81.67%: 100%|██████████| 62/62 [00:05<00:00, 11.76it/s]\n",
      "epoch-52  lr=['0.0004323'], tr/val_loss:  0.001043/  1.701099, tr: 100.00%, val:  79.58%, val_best:  81.67%: 100%|██████████| 62/62 [00:05<00:00, 12.13it/s]\n",
      "epoch-53  lr=['0.0003321'], tr/val_loss:  0.001045/  1.700558, tr: 100.00%, val:  79.58%, val_best:  81.67%: 100%|██████████| 62/62 [00:05<00:00, 11.45it/s]\n",
      "epoch-54  lr=['0.0002447'], tr/val_loss:  0.001038/  1.704493, tr: 100.00%, val:  79.58%, val_best:  81.67%: 100%|██████████| 62/62 [00:05<00:00, 11.38it/s]\n",
      "epoch-55  lr=['0.0001704'], tr/val_loss:  0.001019/  1.701495, tr: 100.00%, val:  79.58%, val_best:  81.67%: 100%|██████████| 62/62 [00:05<00:00, 11.80it/s]\n",
      "epoch-56  lr=['0.0001093'], tr/val_loss:  0.001023/  1.700369, tr: 100.00%, val:  79.58%, val_best:  81.67%: 100%|██████████| 62/62 [00:05<00:00, 10.97it/s]\n",
      "epoch-57  lr=['0.0000616'], tr/val_loss:  0.001016/  1.700481, tr: 100.00%, val:  79.58%, val_best:  81.67%: 100%|██████████| 62/62 [00:05<00:00, 11.38it/s]\n",
      "epoch-58  lr=['0.0000274'], tr/val_loss:  0.001016/  1.700961, tr: 100.00%, val:  79.58%, val_best:  81.67%: 100%|██████████| 62/62 [00:05<00:00, 11.34it/s]\n",
      "epoch-59  lr=['0.0000069'], tr/val_loss:  0.001015/  1.700967, tr: 100.00%, val:  79.58%, val_best:  81.67%: 100%|██████████| 62/62 [00:05<00:00, 11.51it/s]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5a5435a83be347b08d36da6869e5ea4d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='3.438 MB of 3.438 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>DFA_flag</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>epoch</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇████</td></tr><tr><td>iter_acc</td><td>▁▃▂▆▃▂▅▆▇███▇███████████████████████████</td></tr><tr><td>summary_val_acc</td><td>▁▅▆▆▆▆▇▇▇▇▇▇█▇▇█████████████████████████</td></tr><tr><td>tr_acc</td><td>▁▄▆▆▆▆▆▇▇▇██████████████████████████████</td></tr><tr><td>tr_epoch_loss</td><td>▁█▅▅▄▄▄▃▃▃▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_acc_best</td><td>▁▅▆▆▆▆▇▇▇▇▇▇████████████████████████████</td></tr><tr><td>val_acc_now</td><td>▁▅▆▆▆▆▇▇▇▇▇▇█▇▇█████████████████████████</td></tr><tr><td>val_loss</td><td>▁▆▆▆▆▆▆▆▆▆▇▇▆▇▇▇▇█▇▇████████████████████</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>DFA_flag</td><td>0.0</td></tr><tr><td>epoch</td><td>59</td></tr><tr><td>iter_acc</td><td>1.0</td></tr><tr><td>tr_acc</td><td>1.0</td></tr><tr><td>tr_epoch_loss</td><td>0.00101</td></tr><tr><td>val_acc_best</td><td>0.81667</td></tr><tr><td>val_acc_now</td><td>0.79583</td></tr><tr><td>val_loss</td><td>1.70097</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">earthy-sweep-39</strong> at: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/1px1yu0v' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/1px1yu0v</a><br/> View project at: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main</a><br/>Synced 7 W&B file(s), 0 media file(s), 0 artifact file(s) and 1 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20240822_185018-1px1yu0v/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require(\"core\")`! See https://wandb.me/wandb-core for more information."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 90ijqzhv with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBATCH: 16\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tDFA_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tIMAGE_SIZE: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tOTTT_input_trace_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tOTTT_sWS_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tTIME: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcfg: ['M', 'M', 200, 200]\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tconst2: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdecay: 0.25\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdrop_rate: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdvs_clipping: 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdvs_duration: 100000\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \te_transport_swap: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \te_transport_swap_coin: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \te_transport_swap_tr: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepoch_num: 60\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \texclude_class: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.01\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_sg_width: 2.570969004857107\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_reset: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_threshold: 1.601410716906922\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmerge_polarities: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tscheduler_name: CosineAnnealingLR\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsurrogate: hard_sigmoid\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \twhich_data: DVS_GESTURE_TONIC\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.17.7 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.17.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/nfs/home/bhkim003/github_folder/ByeonghyeonKim/my_snn/wandb/run-20240822_185610-90ijqzhv</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/90ijqzhv' target=\"_blank\">driven-sweep-41</a></strong> to <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/yxynyr6h' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/yxynyr6h</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/yxynyr6h' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/yxynyr6h</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/90ijqzhv' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/90ijqzhv</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BATCH' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'IMAGE_SIZE' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'which_data' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_threshold' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_reset' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_sg_width' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'cfg' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'learning_rate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'epoch_num' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'surrogate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'scheduler_name' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'dvs_clipping' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'dvs_duration' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'OTTT_sWS_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'DFA_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'OTTT_input_trace_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'e_transport_swap' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'e_transport_swap_tr' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'e_transport_swap_coin' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'drop_rate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'exclude_class' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'merge_polarities' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'TIME' was locked by 'sweep' (ignored update).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset_hash = 2bbd58b4e0d3c1e9ad501fad8a43feed\n",
      "cache path exists\n",
      "\n",
      "we will exclude the 'other' class. dvsgestrue 10 classes' indices exist. \n",
      "\n",
      "DataParallel(\n",
      "  (module): MY_SNN_FC_sstep(\n",
      "    (layers): MY_Sequential(\n",
      "      (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (2): DimChanger_for_FC_sstep()\n",
      "      (3): SYNAPSE_FC_trace_sstep()\n",
      "      (4): LIF_layer_trace_sstep()\n",
      "      (5): SYNAPSE_FC_trace_sstep()\n",
      "      (6): LIF_layer_trace_sstep()\n",
      "      (7): SYNAPSE_FC_trace_sstep()\n",
      "    )\n",
      "  )\n",
      ")\n",
      "==================================================\n",
      "My Num of PARAMS: 452,010, system's param_num : 452,010\n",
      "Memory: 1.72MiB at 32-bit\n",
      "==================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch-0   lr=['0.0100000'], tr/val_loss:  2.317507/  2.316367, tr:   9.70%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:05<00:00, 12.37it/s]\n",
      "epoch-1   lr=['0.0099931'], tr/val_loss:  2.316254/  2.314931, tr:  10.21%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:04<00:00, 12.41it/s]\n",
      "epoch-2   lr=['0.0099726'], tr/val_loss:  2.315321/  2.315877, tr:   9.81%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:05<00:00, 11.86it/s]\n",
      "epoch-3   lr=['0.0099384'], tr/val_loss:  2.319123/  2.321801, tr:  10.42%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:05<00:00, 12.05it/s]\n",
      "epoch-4   lr=['0.0098907'], tr/val_loss:  2.328817/  2.310750, tr:   7.66%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:05<00:00, 10.48it/s]\n",
      "epoch-5   lr=['0.0098296'], tr/val_loss:  2.318780/  2.313111, tr:   8.58%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:05<00:00, 12.17it/s]\n",
      "epoch-6   lr=['0.0097553'], tr/val_loss:  2.326567/  2.312034, tr:   8.89%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:05<00:00, 11.93it/s]\n",
      "epoch-7   lr=['0.0096679'], tr/val_loss:  2.319906/  2.308871, tr:   8.89%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:04<00:00, 12.64it/s]\n",
      "epoch-8   lr=['0.0095677'], tr/val_loss:  2.315703/  2.318316, tr:   9.09%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:04<00:00, 12.82it/s]\n",
      "epoch-9   lr=['0.0094550'], tr/val_loss:  2.315776/  2.321137, tr:   9.81%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:05<00:00, 11.56it/s]\n",
      "epoch-10  lr=['0.0093301'], tr/val_loss:  2.319218/  2.310921, tr:   9.40%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:06<00:00, 10.31it/s]\n",
      "epoch-11  lr=['0.0091934'], tr/val_loss:  2.320658/  2.318817, tr:   9.60%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:05<00:00, 10.97it/s]\n",
      "epoch-12  lr=['0.0090451'], tr/val_loss:  2.323760/  2.306959, tr:   9.70%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:06<00:00, 10.03it/s]\n",
      "epoch-13  lr=['0.0088857'], tr/val_loss:  2.312257/  2.313825, tr:   8.78%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:05<00:00, 10.35it/s]\n",
      "epoch-14  lr=['0.0087157'], tr/val_loss:  2.321870/  2.310401, tr:   9.70%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:06<00:00,  9.63it/s]\n",
      "epoch-15  lr=['0.0085355'], tr/val_loss:  2.318407/  2.313874, tr:   9.60%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:05<00:00, 10.43it/s]\n",
      "epoch-16  lr=['0.0083457'], tr/val_loss:  2.317499/  2.312321, tr:  10.11%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:05<00:00, 11.02it/s]\n",
      "epoch-17  lr=['0.0081466'], tr/val_loss:  2.318669/  2.307941, tr:   8.89%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:05<00:00, 10.84it/s]\n",
      "epoch-18  lr=['0.0079389'], tr/val_loss:  2.325135/  2.306585, tr:   7.46%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:06<00:00,  9.64it/s]\n",
      "epoch-19  lr=['0.0077232'], tr/val_loss:  2.314244/  2.310251, tr:  10.01%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:05<00:00, 10.71it/s]\n",
      "epoch-20  lr=['0.0075000'], tr/val_loss:  2.312182/  2.307967, tr:   9.91%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:05<00:00, 11.20it/s]\n",
      "epoch-21  lr=['0.0072700'], tr/val_loss:  2.318818/  2.307295, tr:   9.30%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:06<00:00, 10.00it/s]\n",
      "epoch-22  lr=['0.0070337'], tr/val_loss:  2.313441/  2.307399, tr:   9.91%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:05<00:00, 10.39it/s]\n",
      "epoch-23  lr=['0.0067918'], tr/val_loss:  2.314248/  2.309416, tr:   7.76%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:06<00:00,  9.91it/s]\n",
      "epoch-24  lr=['0.0065451'], tr/val_loss:  2.318841/  2.305136, tr:   9.09%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:05<00:00, 10.44it/s]\n",
      "epoch-25  lr=['0.0062941'], tr/val_loss:  2.316903/  2.306750, tr:   7.97%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:06<00:00, 10.22it/s]\n",
      "epoch-26  lr=['0.0060396'], tr/val_loss:  2.311055/  2.305107, tr:   8.99%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:05<00:00, 10.75it/s]\n",
      "epoch-27  lr=['0.0057822'], tr/val_loss:  2.313828/  2.306802, tr:   8.58%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:05<00:00, 10.55it/s]\n",
      "epoch-28  lr=['0.0055226'], tr/val_loss:  2.315332/  2.308450, tr:   8.68%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:05<00:00, 10.52it/s]\n",
      "epoch-29  lr=['0.0052617'], tr/val_loss:  2.315842/  2.306032, tr:   7.15%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:06<00:00,  9.74it/s]\n",
      "epoch-30  lr=['0.0050000'], tr/val_loss:  2.312570/  2.303939, tr:   8.89%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:05<00:00, 10.70it/s]\n",
      "epoch-31  lr=['0.0047383'], tr/val_loss:  2.309263/  2.303903, tr:   9.09%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:05<00:00, 11.11it/s]\n",
      "epoch-32  lr=['0.0044774'], tr/val_loss:  2.311847/  2.302894, tr:   8.38%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:05<00:00, 10.49it/s]\n",
      "epoch-33  lr=['0.0042178'], tr/val_loss:  2.308722/  2.303530, tr:   9.50%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:06<00:00, 10.13it/s]\n",
      "epoch-34  lr=['0.0039604'], tr/val_loss:  2.313000/  2.304187, tr:   8.48%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:06<00:00, 10.01it/s]\n",
      "epoch-35  lr=['0.0037059'], tr/val_loss:  2.309877/  2.303538, tr:   9.09%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:06<00:00, 10.19it/s]\n",
      "epoch-36  lr=['0.0034549'], tr/val_loss:  2.309406/  2.303601, tr:   8.99%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:06<00:00, 10.32it/s]\n",
      "epoch-37  lr=['0.0032082'], tr/val_loss:  2.309686/  2.303400, tr:   7.66%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:06<00:00, 10.30it/s]\n",
      "epoch-38  lr=['0.0029663'], tr/val_loss:  2.308588/  2.303166, tr:   9.09%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:06<00:00,  9.39it/s]\n",
      "epoch-39  lr=['0.0027300'], tr/val_loss:  2.308727/  2.302884, tr:   8.89%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:05<00:00, 10.34it/s]\n",
      "epoch-40  lr=['0.0025000'], tr/val_loss:  2.308749/  2.302732, tr:   9.40%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:05<00:00, 10.36it/s]\n",
      "epoch-41  lr=['0.0022768'], tr/val_loss:  2.306803/  2.302942, tr:   9.19%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:04<00:00, 12.41it/s]\n",
      "epoch-42  lr=['0.0020611'], tr/val_loss:  2.306347/  2.302762, tr:   8.68%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:05<00:00, 11.50it/s]\n",
      "epoch-43  lr=['0.0018534'], tr/val_loss:  2.305991/  2.302857, tr:   8.99%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:05<00:00, 11.51it/s]\n",
      "epoch-44  lr=['0.0016543'], tr/val_loss:  2.305293/  2.302853, tr:  10.01%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:04<00:00, 12.53it/s]\n",
      "epoch-45  lr=['0.0014645'], tr/val_loss:  2.306396/  2.302847, tr:   8.48%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:06<00:00, 10.10it/s]\n",
      "epoch-46  lr=['0.0012843'], tr/val_loss:  2.305307/  2.302670, tr:  10.01%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:05<00:00, 11.50it/s]\n",
      "epoch-47  lr=['0.0011143'], tr/val_loss:  2.305197/  2.302644, tr:   9.30%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:05<00:00, 10.94it/s]\n",
      "epoch-48  lr=['0.0009549'], tr/val_loss:  2.304637/  2.302745, tr:   8.78%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:05<00:00, 10.81it/s]\n",
      "epoch-49  lr=['0.0008066'], tr/val_loss:  2.304113/  2.302645, tr:   8.89%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:06<00:00,  9.16it/s]\n",
      "epoch-50  lr=['0.0006699'], tr/val_loss:  2.304358/  2.302700, tr:   8.68%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:05<00:00, 10.56it/s]\n",
      "epoch-51  lr=['0.0005450'], tr/val_loss:  2.303610/  2.302717, tr:   9.81%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:05<00:00, 10.55it/s]\n",
      "epoch-52  lr=['0.0004323'], tr/val_loss:  2.303667/  2.302626, tr:   9.30%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:05<00:00, 10.91it/s]\n",
      "epoch-53  lr=['0.0003321'], tr/val_loss:  2.303300/  2.302634, tr:   9.19%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:06<00:00, 10.32it/s]\n",
      "epoch-54  lr=['0.0002447'], tr/val_loss:  2.303030/  2.302622, tr:   8.38%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:05<00:00, 10.45it/s]\n",
      "epoch-55  lr=['0.0001704'], tr/val_loss:  2.303107/  2.302625, tr:  10.01%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:05<00:00, 11.26it/s]\n",
      "epoch-56  lr=['0.0001093'], tr/val_loss:  2.302886/  2.302609, tr:  10.01%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:05<00:00, 11.28it/s]\n",
      "epoch-57  lr=['0.0000616'], tr/val_loss:  2.302670/  2.302610, tr:  10.01%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:05<00:00, 10.65it/s]\n",
      "epoch-58  lr=['0.0000274'], tr/val_loss:  2.302685/  2.302609, tr:  10.01%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:05<00:00, 10.90it/s]\n",
      "epoch-59  lr=['0.0000069'], tr/val_loss:  2.302528/  2.302609, tr:  10.01%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:06<00:00,  9.17it/s]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d8f37fef72be4f0d8cdc8c071bde9aad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='3.438 MB of 3.438 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>DFA_flag</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>epoch</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇████</td></tr><tr><td>iter_acc</td><td>▁█▅▅▃▁▅█▆▃▆▅▃▃▁▃▃▃▁▁▁▁▆▅▁▃▁▅▃▅▃▅▃▃▅▅▁▃▅█</td></tr><tr><td>summary_val_acc</td><td>▁███████████████████████████████████████</td></tr><tr><td>tr_acc</td><td>▁███▇▇▇█▇███▇███▆▆▇▇▆▇▇▇▇▆▇▇▇▇██▇▇█▇▇███</td></tr><tr><td>tr_epoch_loss</td><td>▁███████████████████████████████████████</td></tr><tr><td>val_acc_best</td><td>▁███████████████████████████████████████</td></tr><tr><td>val_acc_now</td><td>▁███████████████████████████████████████</td></tr><tr><td>val_loss</td><td>▁███████████████████████████████████████</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>DFA_flag</td><td>0.0</td></tr><tr><td>epoch</td><td>59</td></tr><tr><td>iter_acc</td><td>0.33333</td></tr><tr><td>tr_acc</td><td>0.1001</td></tr><tr><td>tr_epoch_loss</td><td>2.30253</td></tr><tr><td>val_acc_best</td><td>0.1</td></tr><tr><td>val_acc_now</td><td>0.1</td></tr><tr><td>val_loss</td><td>2.30261</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">driven-sweep-41</strong> at: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/90ijqzhv' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/90ijqzhv</a><br/> View project at: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main</a><br/>Synced 7 W&B file(s), 0 media file(s), 0 artifact file(s) and 1 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20240822_185610-90ijqzhv/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require(\"core\")`! See https://wandb.me/wandb-core for more information."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: qhvtkazs with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBATCH: 16\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tDFA_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tIMAGE_SIZE: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tOTTT_input_trace_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tOTTT_sWS_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tTIME: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcfg: ['M', 'M', 200, 200]\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tconst2: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdecay: 0.25\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdrop_rate: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdvs_clipping: 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdvs_duration: 100000\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \te_transport_swap: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \te_transport_swap_coin: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \te_transport_swap_tr: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepoch_num: 60\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \texclude_class: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.01\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_sg_width: 2.570969004857107\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_reset: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_threshold: 1.3000333386699947\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmerge_polarities: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tscheduler_name: CosineAnnealingLR\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsurrogate: hard_sigmoid\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \twhich_data: DVS_GESTURE_TONIC\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.17.7 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.17.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/nfs/home/bhkim003/github_folder/ByeonghyeonKim/my_snn/wandb/run-20240822_190228-qhvtkazs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/qhvtkazs' target=\"_blank\">fresh-sweep-43</a></strong> to <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/yxynyr6h' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/yxynyr6h</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/yxynyr6h' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/yxynyr6h</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/qhvtkazs' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/qhvtkazs</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BATCH' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'IMAGE_SIZE' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'which_data' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_threshold' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_reset' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_sg_width' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'cfg' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'learning_rate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'epoch_num' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'surrogate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'scheduler_name' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'dvs_clipping' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'dvs_duration' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'OTTT_sWS_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'DFA_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'OTTT_input_trace_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'e_transport_swap' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'e_transport_swap_tr' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'e_transport_swap_coin' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'drop_rate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'exclude_class' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'merge_polarities' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'TIME' was locked by 'sweep' (ignored update).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset_hash = 2bbd58b4e0d3c1e9ad501fad8a43feed\n",
      "cache path exists\n",
      "\n",
      "we will exclude the 'other' class. dvsgestrue 10 classes' indices exist. \n",
      "\n",
      "DataParallel(\n",
      "  (module): MY_SNN_FC_sstep(\n",
      "    (layers): MY_Sequential(\n",
      "      (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (2): DimChanger_for_FC_sstep()\n",
      "      (3): SYNAPSE_FC_trace_sstep()\n",
      "      (4): LIF_layer_trace_sstep()\n",
      "      (5): SYNAPSE_FC_trace_sstep()\n",
      "      (6): LIF_layer_trace_sstep()\n",
      "      (7): SYNAPSE_FC_trace_sstep()\n",
      "    )\n",
      "  )\n",
      ")\n",
      "==================================================\n",
      "My Num of PARAMS: 452,010, system's param_num : 452,010\n",
      "Memory: 1.72MiB at 32-bit\n",
      "==================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch-0   lr=['0.0100000'], tr/val_loss:  2.317507/  2.316367, tr:   9.70%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:06<00:00,  9.45it/s]\n",
      "epoch-1   lr=['0.0099931'], tr/val_loss:  2.316254/  2.314931, tr:  10.21%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:05<00:00, 11.69it/s]\n",
      "epoch-2   lr=['0.0099726'], tr/val_loss:  2.315321/  2.315877, tr:   9.81%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:06<00:00, 10.13it/s]\n",
      "epoch-3   lr=['0.0099384'], tr/val_loss:  2.319123/  2.321801, tr:  10.42%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:05<00:00, 11.18it/s]\n",
      "epoch-4   lr=['0.0098907'], tr/val_loss:  2.328800/  2.310752, tr:   7.66%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:05<00:00, 10.93it/s]\n",
      "epoch-5   lr=['0.0098296'], tr/val_loss:  2.176152/  1.809030, tr:  17.57%, val:  43.75%, val_best:  43.75%: 100%|██████████| 62/62 [00:06<00:00,  9.38it/s]\n",
      "epoch-6   lr=['0.0097553'], tr/val_loss:  1.409292/  1.406217, tr:  51.38%, val:  54.58%, val_best:  54.58%: 100%|██████████| 62/62 [00:05<00:00, 10.60it/s]\n",
      "epoch-7   lr=['0.0096679'], tr/val_loss:  1.137688/  1.385989, tr:  60.98%, val:  51.25%, val_best:  54.58%: 100%|██████████| 62/62 [00:05<00:00, 12.14it/s]\n",
      "epoch-8   lr=['0.0095677'], tr/val_loss:  1.109750/  1.208541, tr:  61.59%, val:  64.17%, val_best:  64.17%: 100%|██████████| 62/62 [00:05<00:00, 11.66it/s]\n",
      "epoch-9   lr=['0.0094550'], tr/val_loss:  0.894294/  1.279968, tr:  69.25%, val:  63.75%, val_best:  64.17%: 100%|██████████| 62/62 [00:05<00:00, 12.03it/s]\n",
      "epoch-10  lr=['0.0093301'], tr/val_loss:  0.859956/  1.192103, tr:  70.38%, val:  62.50%, val_best:  64.17%: 100%|██████████| 62/62 [00:05<00:00, 11.45it/s]\n",
      "epoch-11  lr=['0.0091934'], tr/val_loss:  0.778066/  1.302156, tr:  72.52%, val:  59.58%, val_best:  64.17%: 100%|██████████| 62/62 [00:05<00:00, 11.71it/s]\n",
      "epoch-12  lr=['0.0090451'], tr/val_loss:  0.763842/  1.160090, tr:  72.93%, val:  64.17%, val_best:  64.17%: 100%|██████████| 62/62 [00:05<00:00, 11.94it/s]\n",
      "epoch-13  lr=['0.0088857'], tr/val_loss:  0.679588/  1.234821, tr:  76.71%, val:  62.50%, val_best:  64.17%: 100%|██████████| 62/62 [00:05<00:00, 12.04it/s]\n",
      "epoch-14  lr=['0.0087157'], tr/val_loss:  0.606687/  1.201488, tr:  77.02%, val:  67.50%, val_best:  67.50%: 100%|██████████| 62/62 [00:05<00:00, 12.12it/s]\n",
      "epoch-15  lr=['0.0085355'], tr/val_loss:  0.597984/  1.207413, tr:  79.47%, val:  65.00%, val_best:  67.50%: 100%|██████████| 62/62 [00:05<00:00, 12.01it/s]\n",
      "epoch-16  lr=['0.0083457'], tr/val_loss:  0.563055/  1.445920, tr:  79.88%, val:  63.33%, val_best:  67.50%: 100%|██████████| 62/62 [00:05<00:00, 10.52it/s]\n",
      "epoch-17  lr=['0.0081466'], tr/val_loss:  0.606548/  1.185908, tr:  77.22%, val:  65.00%, val_best:  67.50%: 100%|██████████| 62/62 [00:05<00:00, 12.18it/s]\n",
      "epoch-18  lr=['0.0079389'], tr/val_loss:  0.501027/  1.160934, tr:  81.51%, val:  72.50%, val_best:  72.50%: 100%|██████████| 62/62 [00:05<00:00, 11.99it/s]\n",
      "epoch-19  lr=['0.0077232'], tr/val_loss:  0.448456/  1.279694, tr:  86.72%, val:  68.33%, val_best:  72.50%: 100%|██████████| 62/62 [00:05<00:00, 11.67it/s]\n",
      "epoch-20  lr=['0.0075000'], tr/val_loss:  0.393643/  1.355468, tr:  89.38%, val:  68.33%, val_best:  72.50%: 100%|██████████| 62/62 [00:05<00:00, 12.33it/s]\n",
      "epoch-21  lr=['0.0072700'], tr/val_loss:  0.382071/  1.557021, tr:  89.99%, val:  67.08%, val_best:  72.50%: 100%|██████████| 62/62 [00:05<00:00, 12.17it/s]\n",
      "epoch-22  lr=['0.0070337'], tr/val_loss:  0.346061/  1.332915, tr:  91.42%, val:  76.67%, val_best:  76.67%: 100%|██████████| 62/62 [00:05<00:00, 12.22it/s]\n",
      "epoch-23  lr=['0.0067918'], tr/val_loss:  0.308888/  1.291695, tr:  93.36%, val:  76.67%, val_best:  76.67%: 100%|██████████| 62/62 [00:04<00:00, 12.52it/s]\n",
      "epoch-24  lr=['0.0065451'], tr/val_loss:  0.259313/  1.389082, tr:  94.79%, val:  73.75%, val_best:  76.67%: 100%|██████████| 62/62 [00:05<00:00, 12.07it/s]\n",
      "epoch-25  lr=['0.0062941'], tr/val_loss:  0.186129/  1.413704, tr:  97.24%, val:  74.17%, val_best:  76.67%: 100%|██████████| 62/62 [00:05<00:00, 12.38it/s]\n",
      "epoch-26  lr=['0.0060396'], tr/val_loss:  0.152446/  1.417848, tr:  98.47%, val:  74.17%, val_best:  76.67%: 100%|██████████| 62/62 [00:05<00:00, 12.09it/s]\n",
      "epoch-27  lr=['0.0057822'], tr/val_loss:  0.128878/  1.484692, tr:  99.80%, val:  77.92%, val_best:  77.92%: 100%|██████████| 62/62 [00:05<00:00, 11.86it/s]\n",
      "epoch-28  lr=['0.0055226'], tr/val_loss:  0.121619/  1.459353, tr:  99.39%, val:  77.08%, val_best:  77.92%: 100%|██████████| 62/62 [00:05<00:00, 11.95it/s]\n",
      "epoch-29  lr=['0.0052617'], tr/val_loss:  0.086240/  1.445516, tr:  99.90%, val:  80.00%, val_best:  80.00%: 100%|██████████| 62/62 [00:05<00:00, 12.07it/s]\n",
      "epoch-30  lr=['0.0050000'], tr/val_loss:  0.073199/  1.540756, tr: 100.00%, val:  77.92%, val_best:  80.00%: 100%|██████████| 62/62 [00:05<00:00, 11.99it/s]\n",
      "epoch-31  lr=['0.0047383'], tr/val_loss:  0.054423/  1.551152, tr: 100.00%, val:  77.92%, val_best:  80.00%: 100%|██████████| 62/62 [00:05<00:00, 11.96it/s]\n",
      "epoch-32  lr=['0.0044774'], tr/val_loss:  0.048353/  1.582714, tr:  99.90%, val:  80.00%, val_best:  80.00%: 100%|██████████| 62/62 [00:05<00:00, 12.05it/s]\n",
      "epoch-33  lr=['0.0042178'], tr/val_loss:  0.025889/  1.597087, tr: 100.00%, val:  80.83%, val_best:  80.83%: 100%|██████████| 62/62 [00:04<00:00, 12.51it/s]\n",
      "epoch-34  lr=['0.0039604'], tr/val_loss:  0.020339/  1.564820, tr: 100.00%, val:  80.00%, val_best:  80.83%: 100%|██████████| 62/62 [00:05<00:00, 11.78it/s]\n",
      "epoch-35  lr=['0.0037059'], tr/val_loss:  0.015055/  1.616213, tr: 100.00%, val:  80.42%, val_best:  80.83%: 100%|██████████| 62/62 [00:05<00:00, 11.71it/s]\n",
      "epoch-36  lr=['0.0034549'], tr/val_loss:  0.012267/  1.666985, tr: 100.00%, val:  80.83%, val_best:  80.83%: 100%|██████████| 62/62 [00:05<00:00, 11.93it/s]\n",
      "epoch-37  lr=['0.0032082'], tr/val_loss:  0.010210/  1.664783, tr: 100.00%, val:  80.42%, val_best:  80.83%: 100%|██████████| 62/62 [00:05<00:00, 12.07it/s]\n",
      "epoch-38  lr=['0.0029663'], tr/val_loss:  0.008035/  1.680194, tr: 100.00%, val:  80.00%, val_best:  80.83%: 100%|██████████| 62/62 [00:05<00:00, 10.97it/s]\n",
      "epoch-39  lr=['0.0027300'], tr/val_loss:  0.007050/  1.705964, tr: 100.00%, val:  79.58%, val_best:  80.83%: 100%|██████████| 62/62 [00:05<00:00, 12.26it/s]\n",
      "epoch-40  lr=['0.0025000'], tr/val_loss:  0.006756/  1.704306, tr: 100.00%, val:  80.42%, val_best:  80.83%: 100%|██████████| 62/62 [00:05<00:00, 12.36it/s]\n",
      "epoch-41  lr=['0.0022768'], tr/val_loss:  0.005892/  1.721359, tr: 100.00%, val:  80.83%, val_best:  80.83%: 100%|██████████| 62/62 [00:05<00:00, 12.36it/s]\n",
      "epoch-42  lr=['0.0020611'], tr/val_loss:  0.005252/  1.718657, tr: 100.00%, val:  80.42%, val_best:  80.83%: 100%|██████████| 62/62 [00:05<00:00, 12.19it/s]\n",
      "epoch-43  lr=['0.0018534'], tr/val_loss:  0.005319/  1.715271, tr: 100.00%, val:  80.83%, val_best:  80.83%: 100%|██████████| 62/62 [00:04<00:00, 12.51it/s]\n",
      "epoch-44  lr=['0.0016543'], tr/val_loss:  0.004836/  1.703798, tr: 100.00%, val:  80.42%, val_best:  80.83%: 100%|██████████| 62/62 [00:05<00:00, 11.27it/s]\n",
      "epoch-45  lr=['0.0014645'], tr/val_loss:  0.004705/  1.704628, tr: 100.00%, val:  80.42%, val_best:  80.83%: 100%|██████████| 62/62 [00:04<00:00, 12.61it/s]\n",
      "epoch-46  lr=['0.0012843'], tr/val_loss:  0.004486/  1.711646, tr: 100.00%, val:  80.42%, val_best:  80.83%: 100%|██████████| 62/62 [00:04<00:00, 12.74it/s]\n",
      "epoch-47  lr=['0.0011143'], tr/val_loss:  0.004340/  1.723119, tr: 100.00%, val:  80.00%, val_best:  80.83%: 100%|██████████| 62/62 [00:05<00:00, 12.10it/s]\n",
      "epoch-48  lr=['0.0009549'], tr/val_loss:  0.004550/  1.726461, tr: 100.00%, val:  80.00%, val_best:  80.83%: 100%|██████████| 62/62 [00:05<00:00, 11.83it/s]\n",
      "epoch-49  lr=['0.0008066'], tr/val_loss:  0.004341/  1.735429, tr: 100.00%, val:  80.00%, val_best:  80.83%: 100%|██████████| 62/62 [00:05<00:00, 11.89it/s]\n",
      "epoch-50  lr=['0.0006699'], tr/val_loss:  0.004005/  1.737188, tr: 100.00%, val:  80.42%, val_best:  80.83%: 100%|██████████| 62/62 [00:05<00:00, 11.47it/s]\n",
      "epoch-51  lr=['0.0005450'], tr/val_loss:  0.003896/  1.733276, tr: 100.00%, val:  80.83%, val_best:  80.83%: 100%|██████████| 62/62 [00:06<00:00,  9.63it/s]\n",
      "epoch-52  lr=['0.0004323'], tr/val_loss:  0.003927/  1.736894, tr: 100.00%, val:  80.42%, val_best:  80.83%: 100%|██████████| 62/62 [00:05<00:00, 10.92it/s]\n",
      "epoch-53  lr=['0.0003321'], tr/val_loss:  0.003993/  1.734737, tr: 100.00%, val:  80.42%, val_best:  80.83%: 100%|██████████| 62/62 [00:05<00:00, 10.87it/s]\n",
      "epoch-54  lr=['0.0002447'], tr/val_loss:  0.003835/  1.733592, tr: 100.00%, val:  80.83%, val_best:  80.83%: 100%|██████████| 62/62 [00:05<00:00, 11.45it/s]\n",
      "epoch-55  lr=['0.0001704'], tr/val_loss:  0.003742/  1.735323, tr: 100.00%, val:  80.83%, val_best:  80.83%: 100%|██████████| 62/62 [00:06<00:00, 10.23it/s]\n",
      "epoch-56  lr=['0.0001093'], tr/val_loss:  0.003691/  1.734043, tr: 100.00%, val:  80.83%, val_best:  80.83%: 100%|██████████| 62/62 [00:06<00:00,  9.52it/s]\n",
      "epoch-57  lr=['0.0000616'], tr/val_loss:  0.003673/  1.733452, tr: 100.00%, val:  80.42%, val_best:  80.83%: 100%|██████████| 62/62 [00:05<00:00, 10.67it/s]\n",
      "epoch-58  lr=['0.0000274'], tr/val_loss:  0.003620/  1.733594, tr: 100.00%, val:  80.42%, val_best:  80.83%: 100%|██████████| 62/62 [00:05<00:00, 10.56it/s]\n",
      "epoch-59  lr=['0.0000069'], tr/val_loss:  0.003646/  1.734482, tr: 100.00%, val:  80.83%, val_best:  80.83%: 100%|██████████| 62/62 [00:06<00:00, 10.05it/s]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "afcab52b66f94864ba26d41657a318f8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='3.438 MB of 3.438 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>DFA_flag</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>epoch</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇████</td></tr><tr><td>iter_acc</td><td>▁▃▂▂▄▅▅▅▇▇▇▅█▇▇█▇███████████████████████</td></tr><tr><td>summary_val_acc</td><td>▁▂▂▂▅▆▇▇▆▇▇▆▇▇▇██▇▇█████████████████████</td></tr><tr><td>tr_acc</td><td>▁▂▂▂▂▅▅▆▆▆▆▇▆▇▇▇████████████████████████</td></tr><tr><td>tr_epoch_loss</td><td>▁████▅▄▄▃▃▃▃▃▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_acc_best</td><td>▁▂▂▂▅▆▇▇▇▇▇▇▇▇▇█████████████████████████</td></tr><tr><td>val_acc_now</td><td>▁▂▂▂▅▆▇▇▆▇▇▆▇▇▇██▇▇█████████████████████</td></tr><tr><td>val_loss</td><td>▁███▆▅▅▅▅▄▅▅▅▅▅▅▅▅▅▅▅▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>DFA_flag</td><td>0.0</td></tr><tr><td>epoch</td><td>59</td></tr><tr><td>iter_acc</td><td>1.0</td></tr><tr><td>tr_acc</td><td>1.0</td></tr><tr><td>tr_epoch_loss</td><td>0.00365</td></tr><tr><td>val_acc_best</td><td>0.80833</td></tr><tr><td>val_acc_now</td><td>0.80833</td></tr><tr><td>val_loss</td><td>1.73448</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">fresh-sweep-43</strong> at: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/qhvtkazs' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/qhvtkazs</a><br/> View project at: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main</a><br/>Synced 7 W&B file(s), 0 media file(s), 0 artifact file(s) and 1 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20240822_190228-qhvtkazs/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require(\"core\")`! See https://wandb.me/wandb-core for more information."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 1uz4h8wf with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBATCH: 16\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tDFA_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tIMAGE_SIZE: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tOTTT_input_trace_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tOTTT_sWS_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tTIME: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcfg: ['M', 'M', 200, 200]\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tconst2: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdecay: 0.25\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdrop_rate: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdvs_clipping: 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdvs_duration: 100000\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \te_transport_swap: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \te_transport_swap_coin: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \te_transport_swap_tr: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepoch_num: 60\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \texclude_class: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.01\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_sg_width: 2.570969004857107\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_reset: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_threshold: 2.31642379263955\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmerge_polarities: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tscheduler_name: CosineAnnealingLR\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsurrogate: hard_sigmoid\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \twhich_data: DVS_GESTURE_TONIC\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.17.7 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.17.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/nfs/home/bhkim003/github_folder/ByeonghyeonKim/my_snn/wandb/run-20240822_190826-1uz4h8wf</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/1uz4h8wf' target=\"_blank\">super-sweep-45</a></strong> to <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/yxynyr6h' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/yxynyr6h</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/yxynyr6h' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/yxynyr6h</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/1uz4h8wf' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/1uz4h8wf</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BATCH' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'IMAGE_SIZE' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'which_data' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_threshold' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_reset' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_sg_width' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'cfg' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'learning_rate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'epoch_num' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'surrogate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'scheduler_name' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'dvs_clipping' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'dvs_duration' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'OTTT_sWS_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'DFA_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'OTTT_input_trace_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'e_transport_swap' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'e_transport_swap_tr' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'e_transport_swap_coin' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'drop_rate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'exclude_class' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'merge_polarities' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'TIME' was locked by 'sweep' (ignored update).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset_hash = 2bbd58b4e0d3c1e9ad501fad8a43feed\n",
      "cache path exists\n",
      "\n",
      "we will exclude the 'other' class. dvsgestrue 10 classes' indices exist. \n",
      "\n",
      "DataParallel(\n",
      "  (module): MY_SNN_FC_sstep(\n",
      "    (layers): MY_Sequential(\n",
      "      (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (2): DimChanger_for_FC_sstep()\n",
      "      (3): SYNAPSE_FC_trace_sstep()\n",
      "      (4): LIF_layer_trace_sstep()\n",
      "      (5): SYNAPSE_FC_trace_sstep()\n",
      "      (6): LIF_layer_trace_sstep()\n",
      "      (7): SYNAPSE_FC_trace_sstep()\n",
      "    )\n",
      "  )\n",
      ")\n",
      "==================================================\n",
      "My Num of PARAMS: 452,010, system's param_num : 452,010\n",
      "Memory: 1.72MiB at 32-bit\n",
      "==================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch-0   lr=['0.0100000'], tr/val_loss:  2.317507/  2.316367, tr:   9.70%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:06<00:00, 10.20it/s]\n",
      "epoch-1   lr=['0.0099931'], tr/val_loss:  2.316254/  2.314931, tr:  10.21%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:05<00:00, 10.97it/s]\n",
      "epoch-2   lr=['0.0099726'], tr/val_loss:  2.315321/  2.315877, tr:   9.81%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:05<00:00, 10.82it/s]\n",
      "epoch-3   lr=['0.0099384'], tr/val_loss:  2.319123/  2.321801, tr:  10.42%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:05<00:00, 10.92it/s]\n",
      "epoch-4   lr=['0.0098907'], tr/val_loss:  2.328817/  2.310750, tr:   7.66%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:05<00:00, 11.35it/s]\n",
      "epoch-5   lr=['0.0098296'], tr/val_loss:  2.318780/  2.313111, tr:   8.58%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:05<00:00, 10.95it/s]\n",
      "epoch-6   lr=['0.0097553'], tr/val_loss:  2.326567/  2.312034, tr:   8.89%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:05<00:00, 11.51it/s]\n",
      "epoch-7   lr=['0.0096679'], tr/val_loss:  2.319906/  2.308871, tr:   8.89%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:05<00:00, 10.43it/s]\n",
      "epoch-8   lr=['0.0095677'], tr/val_loss:  2.315703/  2.318316, tr:   9.09%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:05<00:00, 11.07it/s]\n",
      "epoch-9   lr=['0.0094550'], tr/val_loss:  2.315776/  2.321137, tr:   9.81%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:05<00:00, 11.05it/s]\n",
      "epoch-10  lr=['0.0093301'], tr/val_loss:  2.319218/  2.310921, tr:   9.40%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:05<00:00, 10.39it/s]\n",
      "epoch-11  lr=['0.0091934'], tr/val_loss:  2.320658/  2.318817, tr:   9.60%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:05<00:00, 10.53it/s]\n",
      "epoch-12  lr=['0.0090451'], tr/val_loss:  2.323760/  2.306959, tr:   9.70%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:05<00:00, 10.64it/s]\n",
      "epoch-13  lr=['0.0088857'], tr/val_loss:  2.312257/  2.313825, tr:   8.78%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:05<00:00, 10.97it/s]\n",
      "epoch-14  lr=['0.0087157'], tr/val_loss:  2.321870/  2.310401, tr:   9.70%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:05<00:00, 10.97it/s]\n",
      "epoch-15  lr=['0.0085355'], tr/val_loss:  2.318407/  2.313874, tr:   9.60%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:06<00:00, 10.21it/s]\n",
      "epoch-16  lr=['0.0083457'], tr/val_loss:  2.317499/  2.312321, tr:  10.11%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:05<00:00, 10.55it/s]\n",
      "epoch-17  lr=['0.0081466'], tr/val_loss:  2.318669/  2.307941, tr:   8.89%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:06<00:00, 10.26it/s]\n",
      "epoch-18  lr=['0.0079389'], tr/val_loss:  2.325135/  2.306585, tr:   7.46%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:06<00:00, 10.03it/s]\n",
      "epoch-19  lr=['0.0077232'], tr/val_loss:  2.314244/  2.310251, tr:  10.01%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:05<00:00, 10.48it/s]\n",
      "epoch-20  lr=['0.0075000'], tr/val_loss:  2.312182/  2.307967, tr:   9.91%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:06<00:00,  9.12it/s]\n",
      "epoch-21  lr=['0.0072700'], tr/val_loss:  2.318818/  2.307295, tr:   9.30%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:05<00:00, 10.36it/s]\n",
      "epoch-22  lr=['0.0070337'], tr/val_loss:  2.313441/  2.307399, tr:   9.91%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:05<00:00, 10.77it/s]\n",
      "epoch-23  lr=['0.0067918'], tr/val_loss:  2.314248/  2.309416, tr:   7.76%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:06<00:00, 10.14it/s]\n",
      "epoch-24  lr=['0.0065451'], tr/val_loss:  2.318841/  2.305136, tr:   9.09%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:05<00:00, 10.92it/s]\n",
      "epoch-25  lr=['0.0062941'], tr/val_loss:  2.316903/  2.306750, tr:   7.97%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:06<00:00,  9.59it/s]\n",
      "epoch-26  lr=['0.0060396'], tr/val_loss:  2.311055/  2.305107, tr:   8.99%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:05<00:00, 10.59it/s]\n",
      "epoch-27  lr=['0.0057822'], tr/val_loss:  2.313828/  2.306802, tr:   8.58%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:05<00:00, 10.45it/s]\n",
      "epoch-28  lr=['0.0055226'], tr/val_loss:  2.315332/  2.308450, tr:   8.68%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:05<00:00, 11.34it/s]\n",
      "epoch-29  lr=['0.0052617'], tr/val_loss:  2.315842/  2.306032, tr:   7.15%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:06<00:00, 10.05it/s]\n",
      "epoch-30  lr=['0.0050000'], tr/val_loss:  2.312570/  2.303939, tr:   8.89%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:05<00:00, 10.72it/s]\n",
      "epoch-31  lr=['0.0047383'], tr/val_loss:  2.309263/  2.303903, tr:   9.09%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:05<00:00, 10.63it/s]\n",
      "epoch-32  lr=['0.0044774'], tr/val_loss:  2.311847/  2.302894, tr:   8.38%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:05<00:00, 10.68it/s]\n",
      "epoch-33  lr=['0.0042178'], tr/val_loss:  2.308722/  2.303530, tr:   9.50%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:06<00:00, 10.25it/s]\n",
      "epoch-34  lr=['0.0039604'], tr/val_loss:  2.313000/  2.304187, tr:   8.48%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:07<00:00,  8.78it/s]\n",
      "epoch-35  lr=['0.0037059'], tr/val_loss:  2.309877/  2.303538, tr:   9.09%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:05<00:00, 11.11it/s]\n",
      "epoch-36  lr=['0.0034549'], tr/val_loss:  2.309406/  2.303601, tr:   8.99%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:05<00:00, 10.39it/s]\n",
      "epoch-37  lr=['0.0032082'], tr/val_loss:  2.309686/  2.303400, tr:   7.66%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:06<00:00,  9.97it/s]\n",
      "epoch-38  lr=['0.0029663'], tr/val_loss:  2.308588/  2.303166, tr:   9.09%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:05<00:00, 10.88it/s]\n",
      "epoch-39  lr=['0.0027300'], tr/val_loss:  2.308727/  2.302884, tr:   8.89%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:05<00:00, 10.78it/s]\n",
      "epoch-40  lr=['0.0025000'], tr/val_loss:  2.308749/  2.302732, tr:   9.40%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:05<00:00, 10.99it/s]\n",
      "epoch-41  lr=['0.0022768'], tr/val_loss:  2.306803/  2.302942, tr:   9.19%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:05<00:00, 10.51it/s]\n",
      "epoch-42  lr=['0.0020611'], tr/val_loss:  2.306347/  2.302762, tr:   8.68%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:06<00:00, 10.21it/s]\n",
      "epoch-43  lr=['0.0018534'], tr/val_loss:  2.305991/  2.302857, tr:   8.99%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:05<00:00, 11.61it/s]\n",
      "epoch-44  lr=['0.0016543'], tr/val_loss:  2.305293/  2.302853, tr:  10.01%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:05<00:00, 11.33it/s]\n",
      "epoch-45  lr=['0.0014645'], tr/val_loss:  2.306396/  2.302847, tr:   8.48%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:05<00:00, 11.46it/s]\n",
      "epoch-46  lr=['0.0012843'], tr/val_loss:  2.305307/  2.302670, tr:  10.01%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:05<00:00, 11.88it/s]\n",
      "epoch-47  lr=['0.0011143'], tr/val_loss:  2.305197/  2.302644, tr:   9.30%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:05<00:00, 11.78it/s]\n",
      "epoch-48  lr=['0.0009549'], tr/val_loss:  2.304637/  2.302745, tr:   8.78%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:04<00:00, 12.51it/s]\n",
      "epoch-49  lr=['0.0008066'], tr/val_loss:  2.304113/  2.302645, tr:   8.89%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:06<00:00, 10.06it/s]\n",
      "epoch-50  lr=['0.0006699'], tr/val_loss:  2.304358/  2.302700, tr:   8.68%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:06<00:00, 10.09it/s]\n",
      "epoch-51  lr=['0.0005450'], tr/val_loss:  2.303610/  2.302717, tr:   9.81%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:05<00:00, 10.79it/s]\n",
      "epoch-52  lr=['0.0004323'], tr/val_loss:  2.303667/  2.302626, tr:   9.30%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:06<00:00,  9.84it/s]\n",
      "epoch-53  lr=['0.0003321'], tr/val_loss:  2.303300/  2.302634, tr:   9.19%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:05<00:00, 11.15it/s]\n",
      "epoch-54  lr=['0.0002447'], tr/val_loss:  2.303030/  2.302622, tr:   8.38%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:05<00:00, 10.84it/s]\n",
      "epoch-55  lr=['0.0001704'], tr/val_loss:  2.303107/  2.302625, tr:  10.01%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:06<00:00,  9.07it/s]\n",
      "epoch-56  lr=['0.0001093'], tr/val_loss:  2.302886/  2.302609, tr:  10.01%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:05<00:00, 10.92it/s]\n",
      "epoch-57  lr=['0.0000616'], tr/val_loss:  2.302670/  2.302610, tr:  10.01%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:05<00:00, 11.42it/s]\n",
      "epoch-58  lr=['0.0000274'], tr/val_loss:  2.302685/  2.302609, tr:  10.01%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:05<00:00, 11.47it/s]\n",
      "epoch-59  lr=['0.0000069'], tr/val_loss:  2.302528/  2.302609, tr:  10.01%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:05<00:00, 11.13it/s]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "edeb4e4911674053a146f25dc5deff78",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='3.438 MB of 3.438 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>DFA_flag</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>epoch</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇████</td></tr><tr><td>iter_acc</td><td>▁█▅▅▃▁▅█▆▃▆▅▃▃▁▃▃▃▁▁▁▁▆▅▁▃▁▅▃▅▃▅▃▃▅▅▁▃▅█</td></tr><tr><td>summary_val_acc</td><td>▁███████████████████████████████████████</td></tr><tr><td>tr_acc</td><td>▁███▇▇▇█▇███▇███▆▆▇▇▆▇▇▇▇▆▇▇▇▇██▇▇█▇▇███</td></tr><tr><td>tr_epoch_loss</td><td>▁███████████████████████████████████████</td></tr><tr><td>val_acc_best</td><td>▁███████████████████████████████████████</td></tr><tr><td>val_acc_now</td><td>▁███████████████████████████████████████</td></tr><tr><td>val_loss</td><td>▁███████████████████████████████████████</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>DFA_flag</td><td>0.0</td></tr><tr><td>epoch</td><td>59</td></tr><tr><td>iter_acc</td><td>0.33333</td></tr><tr><td>tr_acc</td><td>0.1001</td></tr><tr><td>tr_epoch_loss</td><td>2.30253</td></tr><tr><td>val_acc_best</td><td>0.1</td></tr><tr><td>val_acc_now</td><td>0.1</td></tr><tr><td>val_loss</td><td>2.30261</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">super-sweep-45</strong> at: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/1uz4h8wf' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/1uz4h8wf</a><br/> View project at: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main</a><br/>Synced 7 W&B file(s), 0 media file(s), 0 artifact file(s) and 1 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20240822_190826-1uz4h8wf/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require(\"core\")`! See https://wandb.me/wandb-core for more information."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 706j4pyu with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBATCH: 16\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tDFA_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tIMAGE_SIZE: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tOTTT_input_trace_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tOTTT_sWS_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tTIME: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcfg: ['M', 'M', 200, 200]\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tconst2: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdecay: 0.25\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdrop_rate: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdvs_clipping: 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdvs_duration: 100000\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \te_transport_swap: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \te_transport_swap_coin: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \te_transport_swap_tr: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepoch_num: 60\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \texclude_class: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.01\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_sg_width: 2.570969004857107\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_reset: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_threshold: 2.6956236931655813\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmerge_polarities: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tscheduler_name: CosineAnnealingLR\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsurrogate: hard_sigmoid\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \twhich_data: DVS_GESTURE_TONIC\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.17.7 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.17.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/nfs/home/bhkim003/github_folder/ByeonghyeonKim/my_snn/wandb/run-20240822_191456-706j4pyu</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/706j4pyu' target=\"_blank\">ethereal-sweep-47</a></strong> to <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/yxynyr6h' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/yxynyr6h</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/yxynyr6h' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/yxynyr6h</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/706j4pyu' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/706j4pyu</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BATCH' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'IMAGE_SIZE' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'which_data' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_threshold' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_reset' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_sg_width' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'cfg' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'learning_rate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'epoch_num' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'surrogate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'scheduler_name' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'dvs_clipping' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'dvs_duration' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'OTTT_sWS_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'DFA_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'OTTT_input_trace_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'e_transport_swap' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'e_transport_swap_tr' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'e_transport_swap_coin' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'drop_rate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'exclude_class' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'merge_polarities' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'TIME' was locked by 'sweep' (ignored update).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset_hash = 2bbd58b4e0d3c1e9ad501fad8a43feed\n",
      "cache path exists\n",
      "\n",
      "we will exclude the 'other' class. dvsgestrue 10 classes' indices exist. \n",
      "\n",
      "DataParallel(\n",
      "  (module): MY_SNN_FC_sstep(\n",
      "    (layers): MY_Sequential(\n",
      "      (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (2): DimChanger_for_FC_sstep()\n",
      "      (3): SYNAPSE_FC_trace_sstep()\n",
      "      (4): LIF_layer_trace_sstep()\n",
      "      (5): SYNAPSE_FC_trace_sstep()\n",
      "      (6): LIF_layer_trace_sstep()\n",
      "      (7): SYNAPSE_FC_trace_sstep()\n",
      "    )\n",
      "  )\n",
      ")\n",
      "==================================================\n",
      "My Num of PARAMS: 452,010, system's param_num : 452,010\n",
      "Memory: 1.72MiB at 32-bit\n",
      "==================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch-0   lr=['0.0100000'], tr/val_loss:  2.317507/  2.316367, tr:   9.70%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:06<00:00,  9.80it/s]\n",
      "epoch-1   lr=['0.0099931'], tr/val_loss:  2.316254/  2.314931, tr:  10.21%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:07<00:00,  8.62it/s]\n",
      "epoch-2   lr=['0.0099726'], tr/val_loss:  2.315321/  2.315877, tr:   9.81%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:05<00:00, 10.75it/s]\n",
      "epoch-3   lr=['0.0099384'], tr/val_loss:  2.319123/  2.321801, tr:  10.42%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:06<00:00,  9.34it/s]\n",
      "epoch-4   lr=['0.0098907'], tr/val_loss:  2.328817/  2.310750, tr:   7.66%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:05<00:00, 10.73it/s]\n",
      "epoch-5   lr=['0.0098296'], tr/val_loss:  2.318780/  2.313111, tr:   8.58%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:06<00:00,  9.65it/s]\n",
      "epoch-6   lr=['0.0097553'], tr/val_loss:  2.326567/  2.312034, tr:   8.89%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:05<00:00, 11.00it/s]\n",
      "epoch-7   lr=['0.0096679'], tr/val_loss:  2.319906/  2.308871, tr:   8.89%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:06<00:00, 10.11it/s]\n",
      "epoch-8   lr=['0.0095677'], tr/val_loss:  2.315703/  2.318316, tr:   9.09%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:05<00:00, 10.57it/s]\n",
      "epoch-9   lr=['0.0094550'], tr/val_loss:  2.315776/  2.321137, tr:   9.81%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:05<00:00, 10.65it/s]\n",
      "epoch-10  lr=['0.0093301'], tr/val_loss:  2.319218/  2.310921, tr:   9.40%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:06<00:00, 10.14it/s]\n",
      "epoch-11  lr=['0.0091934'], tr/val_loss:  2.320658/  2.318817, tr:   9.60%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:05<00:00, 10.91it/s]\n",
      "epoch-12  lr=['0.0090451'], tr/val_loss:  2.323760/  2.306959, tr:   9.70%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:06<00:00, 10.24it/s]\n",
      "epoch-13  lr=['0.0088857'], tr/val_loss:  2.312257/  2.313825, tr:   8.78%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:07<00:00,  8.02it/s]\n",
      "epoch-14  lr=['0.0087157'], tr/val_loss:  2.321870/  2.310401, tr:   9.70%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:05<00:00, 11.39it/s]\n",
      "epoch-15  lr=['0.0085355'], tr/val_loss:  2.318407/  2.313874, tr:   9.60%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:06<00:00,  9.97it/s]\n",
      "epoch-16  lr=['0.0083457'], tr/val_loss:  2.317499/  2.312321, tr:  10.11%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:05<00:00, 11.09it/s]\n",
      "epoch-17  lr=['0.0081466'], tr/val_loss:  2.318669/  2.307941, tr:   8.89%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:06<00:00, 10.18it/s]\n",
      "epoch-18  lr=['0.0079389'], tr/val_loss:  2.325135/  2.306585, tr:   7.46%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:06<00:00,  9.91it/s]\n",
      "epoch-19  lr=['0.0077232'], tr/val_loss:  2.314244/  2.310251, tr:  10.01%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:06<00:00, 10.25it/s]\n",
      "epoch-20  lr=['0.0075000'], tr/val_loss:  2.312182/  2.307967, tr:   9.91%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:06<00:00,  9.54it/s]\n",
      "epoch-21  lr=['0.0072700'], tr/val_loss:  2.318818/  2.307295, tr:   9.30%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:05<00:00, 10.58it/s]\n",
      "epoch-22  lr=['0.0070337'], tr/val_loss:  2.313441/  2.307399, tr:   9.91%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:05<00:00, 10.44it/s]\n",
      "epoch-23  lr=['0.0067918'], tr/val_loss:  2.314248/  2.309416, tr:   7.76%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:05<00:00, 10.48it/s]\n",
      "epoch-24  lr=['0.0065451'], tr/val_loss:  2.318841/  2.305136, tr:   9.09%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:05<00:00, 10.65it/s]\n",
      "epoch-25  lr=['0.0062941'], tr/val_loss:  2.316903/  2.306750, tr:   7.97%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:06<00:00, 10.23it/s]\n",
      "epoch-26  lr=['0.0060396'], tr/val_loss:  2.311055/  2.305107, tr:   8.99%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:05<00:00, 11.10it/s]\n",
      "epoch-27  lr=['0.0057822'], tr/val_loss:  2.313828/  2.306802, tr:   8.58%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:05<00:00, 10.60it/s]\n",
      "epoch-28  lr=['0.0055226'], tr/val_loss:  2.315332/  2.308450, tr:   8.68%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:05<00:00, 11.15it/s]\n",
      "epoch-29  lr=['0.0052617'], tr/val_loss:  2.315842/  2.306032, tr:   7.15%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:06<00:00, 10.28it/s]\n",
      "epoch-30  lr=['0.0050000'], tr/val_loss:  2.312570/  2.303939, tr:   8.89%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:07<00:00,  8.78it/s]\n",
      "epoch-31  lr=['0.0047383'], tr/val_loss:  2.309263/  2.303903, tr:   9.09%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:05<00:00, 10.87it/s]\n",
      "epoch-32  lr=['0.0044774'], tr/val_loss:  2.311847/  2.302894, tr:   8.38%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:05<00:00, 10.45it/s]\n",
      "epoch-33  lr=['0.0042178'], tr/val_loss:  2.308722/  2.303530, tr:   9.50%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:06<00:00,  9.83it/s]\n",
      "epoch-34  lr=['0.0039604'], tr/val_loss:  2.313000/  2.304187, tr:   8.48%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:05<00:00, 11.01it/s]\n",
      "epoch-35  lr=['0.0037059'], tr/val_loss:  2.309877/  2.303538, tr:   9.09%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:05<00:00, 11.08it/s]\n",
      "epoch-36  lr=['0.0034549'], tr/val_loss:  2.309406/  2.303601, tr:   8.99%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:05<00:00, 10.63it/s]\n",
      "epoch-37  lr=['0.0032082'], tr/val_loss:  2.309686/  2.303400, tr:   7.66%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:06<00:00,  9.73it/s]\n",
      "epoch-38  lr=['0.0029663'], tr/val_loss:  2.308588/  2.303166, tr:   9.09%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:05<00:00, 11.02it/s]\n",
      "epoch-39  lr=['0.0027300'], tr/val_loss:  2.308727/  2.302884, tr:   8.89%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:06<00:00,  9.77it/s]\n",
      "epoch-40  lr=['0.0025000'], tr/val_loss:  2.308749/  2.302732, tr:   9.40%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:05<00:00, 11.59it/s]\n",
      "epoch-41  lr=['0.0022768'], tr/val_loss:  2.306803/  2.302942, tr:   9.19%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:05<00:00, 11.22it/s]\n",
      "epoch-42  lr=['0.0020611'], tr/val_loss:  2.306347/  2.302762, tr:   8.68%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:06<00:00,  9.86it/s]\n",
      "epoch-43  lr=['0.0018534'], tr/val_loss:  2.305991/  2.302857, tr:   8.99%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:05<00:00, 11.27it/s]\n",
      "epoch-44  lr=['0.0016543'], tr/val_loss:  2.305293/  2.302853, tr:  10.01%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:05<00:00, 11.93it/s]\n",
      "epoch-45  lr=['0.0014645'], tr/val_loss:  2.306396/  2.302847, tr:   8.48%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:05<00:00, 11.71it/s]\n",
      "epoch-46  lr=['0.0012843'], tr/val_loss:  2.305307/  2.302670, tr:  10.01%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:04<00:00, 12.76it/s]\n",
      "epoch-47  lr=['0.0011143'], tr/val_loss:  2.305197/  2.302644, tr:   9.30%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:06<00:00, 10.21it/s]\n",
      "epoch-48  lr=['0.0009549'], tr/val_loss:  2.304637/  2.302745, tr:   8.78%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:05<00:00, 10.50it/s]\n",
      "epoch-49  lr=['0.0008066'], tr/val_loss:  2.304113/  2.302645, tr:   8.89%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:05<00:00, 10.46it/s]\n",
      "epoch-50  lr=['0.0006699'], tr/val_loss:  2.304358/  2.302700, tr:   8.68%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:07<00:00,  8.62it/s]\n",
      "epoch-51  lr=['0.0005450'], tr/val_loss:  2.303610/  2.302717, tr:   9.81%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:05<00:00, 11.20it/s]\n",
      "epoch-52  lr=['0.0004323'], tr/val_loss:  2.303667/  2.302626, tr:   9.30%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:06<00:00, 10.27it/s]\n",
      "epoch-53  lr=['0.0003321'], tr/val_loss:  2.303300/  2.302634, tr:   9.19%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:05<00:00, 11.20it/s]\n",
      "epoch-54  lr=['0.0002447'], tr/val_loss:  2.303030/  2.302622, tr:   8.38%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:06<00:00, 10.22it/s]\n",
      "epoch-55  lr=['0.0001704'], tr/val_loss:  2.303107/  2.302625, tr:  10.01%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:05<00:00, 11.02it/s]\n",
      "epoch-56  lr=['0.0001093'], tr/val_loss:  2.302886/  2.302609, tr:  10.01%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:05<00:00, 10.47it/s]\n",
      "epoch-57  lr=['0.0000616'], tr/val_loss:  2.302670/  2.302610, tr:  10.01%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:05<00:00, 11.01it/s]\n",
      "epoch-58  lr=['0.0000274'], tr/val_loss:  2.302685/  2.302609, tr:  10.01%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:06<00:00, 10.01it/s]\n",
      "epoch-59  lr=['0.0000069'], tr/val_loss:  2.302528/  2.302609, tr:  10.01%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:06<00:00,  9.06it/s]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7e09c6c445084de3866ce0a9f5718688",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='3.438 MB of 3.438 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>DFA_flag</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>epoch</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇████</td></tr><tr><td>iter_acc</td><td>▁█▅▅▃▁▅█▆▃▆▅▃▃▁▃▃▃▁▁▁▁▆▅▁▃▁▅▃▅▃▅▃▃▅▅▁▃▅█</td></tr><tr><td>summary_val_acc</td><td>▁███████████████████████████████████████</td></tr><tr><td>tr_acc</td><td>▁███▇▇▇█▇███▇███▆▆▇▇▆▇▇▇▇▆▇▇▇▇██▇▇█▇▇███</td></tr><tr><td>tr_epoch_loss</td><td>▁███████████████████████████████████████</td></tr><tr><td>val_acc_best</td><td>▁███████████████████████████████████████</td></tr><tr><td>val_acc_now</td><td>▁███████████████████████████████████████</td></tr><tr><td>val_loss</td><td>▁███████████████████████████████████████</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>DFA_flag</td><td>0.0</td></tr><tr><td>epoch</td><td>59</td></tr><tr><td>iter_acc</td><td>0.33333</td></tr><tr><td>tr_acc</td><td>0.1001</td></tr><tr><td>tr_epoch_loss</td><td>2.30253</td></tr><tr><td>val_acc_best</td><td>0.1</td></tr><tr><td>val_acc_now</td><td>0.1</td></tr><tr><td>val_loss</td><td>2.30261</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">ethereal-sweep-47</strong> at: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/706j4pyu' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/706j4pyu</a><br/> View project at: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main</a><br/>Synced 7 W&B file(s), 0 media file(s), 0 artifact file(s) and 1 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20240822_191456-706j4pyu/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require(\"core\")`! See https://wandb.me/wandb-core for more information."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: lbrlpq21 with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBATCH: 16\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tDFA_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tIMAGE_SIZE: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tOTTT_input_trace_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tOTTT_sWS_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tTIME: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcfg: ['M', 'M', 200, 200]\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tconst2: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdecay: 0.25\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdrop_rate: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdvs_clipping: 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdvs_duration: 100000\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \te_transport_swap: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \te_transport_swap_coin: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \te_transport_swap_tr: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepoch_num: 60\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \texclude_class: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.01\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_sg_width: 2.570969004857107\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_reset: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_threshold: 0.7101114381428459\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmerge_polarities: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tscheduler_name: CosineAnnealingLR\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsurrogate: hard_sigmoid\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \twhich_data: DVS_GESTURE_TONIC\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.17.7 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.17.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/nfs/home/bhkim003/github_folder/ByeonghyeonKim/my_snn/wandb/run-20240822_192128-lbrlpq21</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/lbrlpq21' target=\"_blank\">vivid-sweep-49</a></strong> to <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/yxynyr6h' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/yxynyr6h</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/yxynyr6h' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/yxynyr6h</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/lbrlpq21' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/lbrlpq21</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BATCH' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'IMAGE_SIZE' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'which_data' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_threshold' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_reset' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_sg_width' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'cfg' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'learning_rate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'epoch_num' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'surrogate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'scheduler_name' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'dvs_clipping' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'dvs_duration' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'OTTT_sWS_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'DFA_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'OTTT_input_trace_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'e_transport_swap' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'e_transport_swap_tr' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'e_transport_swap_coin' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'drop_rate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'exclude_class' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'merge_polarities' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'TIME' was locked by 'sweep' (ignored update).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset_hash = 2bbd58b4e0d3c1e9ad501fad8a43feed\n",
      "cache path exists\n",
      "\n",
      "we will exclude the 'other' class. dvsgestrue 10 classes' indices exist. \n",
      "\n",
      "DataParallel(\n",
      "  (module): MY_SNN_FC_sstep(\n",
      "    (layers): MY_Sequential(\n",
      "      (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (2): DimChanger_for_FC_sstep()\n",
      "      (3): SYNAPSE_FC_trace_sstep()\n",
      "      (4): LIF_layer_trace_sstep()\n",
      "      (5): SYNAPSE_FC_trace_sstep()\n",
      "      (6): LIF_layer_trace_sstep()\n",
      "      (7): SYNAPSE_FC_trace_sstep()\n",
      "    )\n",
      "  )\n",
      ")\n",
      "==================================================\n",
      "My Num of PARAMS: 452,010, system's param_num : 452,010\n",
      "Memory: 1.72MiB at 32-bit\n",
      "==================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch-0   lr=['0.0100000'], tr/val_loss:  1.617635/  1.283337, tr:  45.56%, val:  53.33%, val_best:  53.33%: 100%|██████████| 62/62 [00:05<00:00, 10.57it/s]\n",
      "epoch-1   lr=['0.0099931'], tr/val_loss:  1.138460/  1.293224, tr:  58.43%, val:  55.00%, val_best:  55.00%: 100%|██████████| 62/62 [00:06<00:00,  9.75it/s]\n",
      "epoch-2   lr=['0.0099726'], tr/val_loss:  0.980375/  1.285108, tr:  63.74%, val:  57.08%, val_best:  57.08%: 100%|██████████| 62/62 [00:06<00:00,  9.53it/s]\n",
      "epoch-3   lr=['0.0099384'], tr/val_loss:  0.879542/  1.084308, tr:  68.34%, val:  62.92%, val_best:  62.92%: 100%|██████████| 62/62 [00:05<00:00, 10.49it/s]\n",
      "epoch-4   lr=['0.0098907'], tr/val_loss:  0.807730/  1.111017, tr:  72.01%, val:  64.17%, val_best:  64.17%: 100%|██████████| 62/62 [00:05<00:00, 10.40it/s]\n",
      "epoch-5   lr=['0.0098296'], tr/val_loss:  0.756195/  1.299381, tr:  71.20%, val:  61.25%, val_best:  64.17%: 100%|██████████| 62/62 [00:07<00:00,  8.76it/s]\n",
      "epoch-6   lr=['0.0097553'], tr/val_loss:  0.719218/  1.219887, tr:  72.22%, val:  60.00%, val_best:  64.17%: 100%|██████████| 62/62 [00:05<00:00, 10.98it/s]\n",
      "epoch-7   lr=['0.0096679'], tr/val_loss:  0.668682/  1.308550, tr:  75.28%, val:  55.42%, val_best:  64.17%: 100%|██████████| 62/62 [00:06<00:00, 10.08it/s]\n",
      "epoch-8   lr=['0.0095677'], tr/val_loss:  0.630273/  1.112824, tr:  75.18%, val:  68.75%, val_best:  68.75%: 100%|██████████| 62/62 [00:06<00:00, 10.29it/s]\n",
      "epoch-9   lr=['0.0094550'], tr/val_loss:  0.476402/  1.288555, tr:  82.43%, val:  67.92%, val_best:  68.75%: 100%|██████████| 62/62 [00:05<00:00, 10.75it/s]\n",
      "epoch-10  lr=['0.0093301'], tr/val_loss:  0.504455/  1.226606, tr:  83.76%, val:  68.75%, val_best:  68.75%: 100%|██████████| 62/62 [00:05<00:00, 10.87it/s]\n",
      "epoch-11  lr=['0.0091934'], tr/val_loss:  0.450188/  1.314204, tr:  84.88%, val:  69.17%, val_best:  69.17%: 100%|██████████| 62/62 [00:06<00:00,  9.74it/s]\n",
      "epoch-12  lr=['0.0090451'], tr/val_loss:  0.492085/  1.082755, tr:  85.90%, val:  73.33%, val_best:  73.33%: 100%|██████████| 62/62 [00:06<00:00, 10.06it/s]\n",
      "epoch-13  lr=['0.0088857'], tr/val_loss:  0.407515/  1.198969, tr:  88.76%, val:  75.83%, val_best:  75.83%: 100%|██████████| 62/62 [00:05<00:00, 10.59it/s]\n",
      "epoch-14  lr=['0.0087157'], tr/val_loss:  0.360955/  1.245905, tr:  91.52%, val:  73.33%, val_best:  75.83%: 100%|██████████| 62/62 [00:06<00:00,  8.86it/s]\n",
      "epoch-15  lr=['0.0085355'], tr/val_loss:  0.290451/  1.295403, tr:  94.59%, val:  77.92%, val_best:  77.92%: 100%|██████████| 62/62 [00:11<00:00,  5.40it/s]\n",
      "epoch-16  lr=['0.0083457'], tr/val_loss:  0.286656/  1.380378, tr:  93.46%, val:  74.58%, val_best:  77.92%: 100%|██████████| 62/62 [00:07<00:00,  7.90it/s]\n",
      "epoch-17  lr=['0.0081466'], tr/val_loss:  0.264814/  1.254694, tr:  94.28%, val:  74.17%, val_best:  77.92%: 100%|██████████| 62/62 [00:08<00:00,  7.71it/s]\n",
      "epoch-18  lr=['0.0079389'], tr/val_loss:  0.217911/  1.317094, tr:  97.04%, val:  76.25%, val_best:  77.92%: 100%|██████████| 62/62 [00:07<00:00,  8.03it/s]\n",
      "epoch-19  lr=['0.0077232'], tr/val_loss:  0.210805/  1.253161, tr:  96.63%, val:  78.75%, val_best:  78.75%: 100%|██████████| 62/62 [00:07<00:00,  7.98it/s]\n",
      "epoch-20  lr=['0.0075000'], tr/val_loss:  0.173751/  1.365716, tr:  98.37%, val:  77.50%, val_best:  78.75%: 100%|██████████| 62/62 [00:08<00:00,  7.19it/s]\n",
      "epoch-21  lr=['0.0072700'], tr/val_loss:  0.121006/  1.422105, tr:  99.80%, val:  76.25%, val_best:  78.75%: 100%|██████████| 62/62 [00:06<00:00, 10.30it/s]\n",
      "epoch-22  lr=['0.0070337'], tr/val_loss:  0.104716/  1.324134, tr:  99.08%, val:  81.67%, val_best:  81.67%: 100%|██████████| 62/62 [00:06<00:00, 10.25it/s]\n",
      "epoch-23  lr=['0.0067918'], tr/val_loss:  0.063812/  1.423787, tr:  99.90%, val:  79.17%, val_best:  81.67%: 100%|██████████| 62/62 [00:05<00:00, 11.25it/s]\n",
      "epoch-24  lr=['0.0065451'], tr/val_loss:  0.042538/  1.553405, tr: 100.00%, val:  77.08%, val_best:  81.67%: 100%|██████████| 62/62 [00:05<00:00, 10.60it/s]\n",
      "epoch-25  lr=['0.0062941'], tr/val_loss:  0.033279/  1.528066, tr:  99.90%, val:  79.58%, val_best:  81.67%: 100%|██████████| 62/62 [00:06<00:00, 10.29it/s]\n",
      "epoch-26  lr=['0.0060396'], tr/val_loss:  0.017904/  1.534172, tr: 100.00%, val:  79.17%, val_best:  81.67%: 100%|██████████| 62/62 [00:05<00:00, 10.55it/s]\n",
      "epoch-27  lr=['0.0057822'], tr/val_loss:  0.012555/  1.560069, tr: 100.00%, val:  78.33%, val_best:  81.67%: 100%|██████████| 62/62 [00:05<00:00, 10.60it/s]\n",
      "epoch-28  lr=['0.0055226'], tr/val_loss:  0.009480/  1.604496, tr: 100.00%, val:  79.17%, val_best:  81.67%: 100%|██████████| 62/62 [00:05<00:00, 10.72it/s]\n",
      "epoch-29  lr=['0.0052617'], tr/val_loss:  0.007898/  1.607047, tr: 100.00%, val:  78.33%, val_best:  81.67%: 100%|██████████| 62/62 [00:05<00:00, 10.47it/s]\n",
      "epoch-30  lr=['0.0050000'], tr/val_loss:  0.006608/  1.606595, tr: 100.00%, val:  78.75%, val_best:  81.67%: 100%|██████████| 62/62 [00:05<00:00, 11.09it/s]\n",
      "epoch-31  lr=['0.0047383'], tr/val_loss:  0.004857/  1.625702, tr: 100.00%, val:  78.75%, val_best:  81.67%: 100%|██████████| 62/62 [00:06<00:00, 10.32it/s]\n",
      "epoch-32  lr=['0.0044774'], tr/val_loss:  0.003990/  1.642285, tr: 100.00%, val:  79.58%, val_best:  81.67%: 100%|██████████| 62/62 [00:05<00:00, 10.54it/s]\n",
      "epoch-33  lr=['0.0042178'], tr/val_loss:  0.003694/  1.654824, tr: 100.00%, val:  79.17%, val_best:  81.67%: 100%|██████████| 62/62 [00:05<00:00, 10.77it/s]\n",
      "epoch-34  lr=['0.0039604'], tr/val_loss:  0.002882/  1.655420, tr: 100.00%, val:  79.17%, val_best:  81.67%: 100%|██████████| 62/62 [00:06<00:00, 10.16it/s]\n",
      "epoch-35  lr=['0.0037059'], tr/val_loss:  0.002757/  1.653713, tr: 100.00%, val:  79.17%, val_best:  81.67%: 100%|██████████| 62/62 [00:05<00:00, 10.44it/s]\n",
      "epoch-36  lr=['0.0034549'], tr/val_loss:  0.002593/  1.664744, tr: 100.00%, val:  80.00%, val_best:  81.67%: 100%|██████████| 62/62 [00:06<00:00, 10.07it/s]\n",
      "epoch-37  lr=['0.0032082'], tr/val_loss:  0.002392/  1.672438, tr: 100.00%, val:  80.00%, val_best:  81.67%: 100%|██████████| 62/62 [00:06<00:00,  9.19it/s]\n",
      "epoch-38  lr=['0.0029663'], tr/val_loss:  0.002158/  1.680010, tr: 100.00%, val:  80.00%, val_best:  81.67%: 100%|██████████| 62/62 [00:05<00:00, 10.42it/s]\n",
      "epoch-39  lr=['0.0027300'], tr/val_loss:  0.002063/  1.684843, tr: 100.00%, val:  78.33%, val_best:  81.67%: 100%|██████████| 62/62 [00:05<00:00, 10.44it/s]\n",
      "epoch-40  lr=['0.0025000'], tr/val_loss:  0.001959/  1.691820, tr: 100.00%, val:  77.92%, val_best:  81.67%: 100%|██████████| 62/62 [00:06<00:00, 10.02it/s]\n",
      "epoch-41  lr=['0.0022768'], tr/val_loss:  0.001904/  1.699514, tr: 100.00%, val:  77.92%, val_best:  81.67%: 100%|██████████| 62/62 [00:06<00:00,  9.87it/s]\n",
      "epoch-42  lr=['0.0020611'], tr/val_loss:  0.001803/  1.700210, tr: 100.00%, val:  79.17%, val_best:  81.67%: 100%|██████████| 62/62 [00:06<00:00,  9.69it/s]\n",
      "epoch-43  lr=['0.0018534'], tr/val_loss:  0.001795/  1.693416, tr: 100.00%, val:  79.58%, val_best:  81.67%: 100%|██████████| 62/62 [00:04<00:00, 12.42it/s]\n",
      "epoch-44  lr=['0.0016543'], tr/val_loss:  0.001746/  1.696285, tr: 100.00%, val:  79.58%, val_best:  81.67%: 100%|██████████| 62/62 [00:05<00:00, 11.81it/s]\n",
      "epoch-45  lr=['0.0014645'], tr/val_loss:  0.001738/  1.700422, tr: 100.00%, val:  79.58%, val_best:  81.67%: 100%|██████████| 62/62 [00:05<00:00, 11.44it/s]\n",
      "epoch-46  lr=['0.0012843'], tr/val_loss:  0.001690/  1.703760, tr: 100.00%, val:  79.58%, val_best:  81.67%: 100%|██████████| 62/62 [00:05<00:00, 11.42it/s]\n",
      "epoch-47  lr=['0.0011143'], tr/val_loss:  0.001674/  1.706107, tr: 100.00%, val:  79.17%, val_best:  81.67%: 100%|██████████| 62/62 [00:05<00:00, 12.25it/s]\n",
      "epoch-48  lr=['0.0009549'], tr/val_loss:  0.001660/  1.709825, tr: 100.00%, val:  79.17%, val_best:  81.67%: 100%|██████████| 62/62 [00:06<00:00, 10.10it/s]\n",
      "epoch-49  lr=['0.0008066'], tr/val_loss:  0.001616/  1.714869, tr: 100.00%, val:  78.75%, val_best:  81.67%: 100%|██████████| 62/62 [00:06<00:00,  9.97it/s]\n",
      "epoch-50  lr=['0.0006699'], tr/val_loss:  0.001659/  1.717054, tr: 100.00%, val:  78.33%, val_best:  81.67%: 100%|██████████| 62/62 [00:05<00:00, 10.44it/s]\n",
      "epoch-51  lr=['0.0005450'], tr/val_loss:  0.001613/  1.718085, tr: 100.00%, val:  78.33%, val_best:  81.67%: 100%|██████████| 62/62 [00:05<00:00, 10.86it/s]\n",
      "epoch-52  lr=['0.0004323'], tr/val_loss:  0.001578/  1.720106, tr: 100.00%, val:  78.33%, val_best:  81.67%: 100%|██████████| 62/62 [00:05<00:00, 10.36it/s]\n",
      "epoch-53  lr=['0.0003321'], tr/val_loss:  0.001589/  1.717935, tr: 100.00%, val:  78.33%, val_best:  81.67%: 100%|██████████| 62/62 [00:05<00:00, 10.44it/s]\n",
      "epoch-54  lr=['0.0002447'], tr/val_loss:  0.001590/  1.718470, tr: 100.00%, val:  78.33%, val_best:  81.67%: 100%|██████████| 62/62 [00:06<00:00, 10.10it/s]\n",
      "epoch-55  lr=['0.0001704'], tr/val_loss:  0.001543/  1.717996, tr: 100.00%, val:  78.33%, val_best:  81.67%: 100%|██████████| 62/62 [00:05<00:00, 10.52it/s]\n",
      "epoch-56  lr=['0.0001093'], tr/val_loss:  0.001570/  1.718269, tr: 100.00%, val:  78.33%, val_best:  81.67%: 100%|██████████| 62/62 [00:05<00:00, 10.54it/s]\n",
      "epoch-57  lr=['0.0000616'], tr/val_loss:  0.001572/  1.722237, tr: 100.00%, val:  77.92%, val_best:  81.67%: 100%|██████████| 62/62 [00:05<00:00, 10.99it/s]\n",
      "epoch-58  lr=['0.0000274'], tr/val_loss:  0.001562/  1.722006, tr: 100.00%, val:  77.92%, val_best:  81.67%: 100%|██████████| 62/62 [00:05<00:00, 10.52it/s]\n",
      "epoch-59  lr=['0.0000069'], tr/val_loss:  0.001541/  1.721961, tr: 100.00%, val:  77.92%, val_best:  81.67%: 100%|██████████| 62/62 [00:05<00:00, 11.72it/s]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6500d51b5bc54c3290d13cd527e77039",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='3.438 MB of 3.438 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>DFA_flag</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>epoch</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇████</td></tr><tr><td>iter_acc</td><td>▁▃▃▃▆▇▅▆▆▇█▇▇███████████████████████████</td></tr><tr><td>summary_val_acc</td><td>▁▆▆▆▆▆▇▇▇▇▇▇▇███████████████████████████</td></tr><tr><td>tr_acc</td><td>▁▄▅▆▆▆▆▇▇▇▇█████████████████████████████</td></tr><tr><td>tr_epoch_loss</td><td>▁█▅▅▄▄▄▃▃▃▃▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_acc_best</td><td>▁▆▆▆▆▆▇▇▇▇▇█████████████████████████████</td></tr><tr><td>val_acc_now</td><td>▁▆▆▆▆▆▇▇▇▇▇▇▇███████████████████████████</td></tr><tr><td>val_loss</td><td>▁▆▆▅▆▆▆▆▆▅▆▇▆▆▇▆▇▇▇█████████████████████</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>DFA_flag</td><td>0.0</td></tr><tr><td>epoch</td><td>59</td></tr><tr><td>iter_acc</td><td>1.0</td></tr><tr><td>tr_acc</td><td>1.0</td></tr><tr><td>tr_epoch_loss</td><td>0.00154</td></tr><tr><td>val_acc_best</td><td>0.81667</td></tr><tr><td>val_acc_now</td><td>0.77917</td></tr><tr><td>val_loss</td><td>1.72196</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">vivid-sweep-49</strong> at: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/lbrlpq21' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/lbrlpq21</a><br/> View project at: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main</a><br/>Synced 7 W&B file(s), 0 media file(s), 0 artifact file(s) and 1 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20240822_192128-lbrlpq21/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require(\"core\")`! See https://wandb.me/wandb-core for more information."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Sweep Agent: Waiting for job.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Job received.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: q33zj3ix with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBATCH: 16\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tDFA_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tIMAGE_SIZE: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tOTTT_input_trace_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tOTTT_sWS_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tTIME: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcfg: ['M', 'M', 200, 200]\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tconst2: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdecay: 0.25\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdrop_rate: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdvs_clipping: 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdvs_duration: 100000\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \te_transport_swap: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \te_transport_swap_coin: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \te_transport_swap_tr: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepoch_num: 60\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \texclude_class: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.01\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_sg_width: 2.570969004857107\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_reset: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_threshold: 2.443168163641599\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmerge_polarities: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tscheduler_name: CosineAnnealingLR\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsurrogate: hard_sigmoid\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \twhich_data: DVS_GESTURE_TONIC\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.17.7 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.17.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/nfs/home/bhkim003/github_folder/ByeonghyeonKim/my_snn/wandb/run-20240822_192819-q33zj3ix</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/q33zj3ix' target=\"_blank\">rose-sweep-51</a></strong> to <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/yxynyr6h' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/yxynyr6h</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/yxynyr6h' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/yxynyr6h</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/q33zj3ix' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/q33zj3ix</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BATCH' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'IMAGE_SIZE' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'which_data' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_threshold' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_reset' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_sg_width' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'cfg' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'learning_rate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'epoch_num' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'surrogate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'scheduler_name' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'dvs_clipping' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'dvs_duration' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'OTTT_sWS_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'DFA_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'OTTT_input_trace_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'e_transport_swap' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'e_transport_swap_tr' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'e_transport_swap_coin' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'drop_rate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'exclude_class' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'merge_polarities' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'TIME' was locked by 'sweep' (ignored update).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset_hash = 2bbd58b4e0d3c1e9ad501fad8a43feed\n",
      "cache path exists\n",
      "\n",
      "we will exclude the 'other' class. dvsgestrue 10 classes' indices exist. \n",
      "\n",
      "DataParallel(\n",
      "  (module): MY_SNN_FC_sstep(\n",
      "    (layers): MY_Sequential(\n",
      "      (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (2): DimChanger_for_FC_sstep()\n",
      "      (3): SYNAPSE_FC_trace_sstep()\n",
      "      (4): LIF_layer_trace_sstep()\n",
      "      (5): SYNAPSE_FC_trace_sstep()\n",
      "      (6): LIF_layer_trace_sstep()\n",
      "      (7): SYNAPSE_FC_trace_sstep()\n",
      "    )\n",
      "  )\n",
      ")\n",
      "==================================================\n",
      "My Num of PARAMS: 452,010, system's param_num : 452,010\n",
      "Memory: 1.72MiB at 32-bit\n",
      "==================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch-0   lr=['0.0100000'], tr/val_loss:  2.317507/  2.316367, tr:   9.70%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:04<00:00, 12.53it/s]\n",
      "epoch-1   lr=['0.0099931'], tr/val_loss:  2.316254/  2.314931, tr:  10.21%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:05<00:00, 12.28it/s]\n",
      "epoch-2   lr=['0.0099726'], tr/val_loss:  2.315321/  2.315877, tr:   9.81%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:05<00:00, 11.61it/s]\n",
      "epoch-3   lr=['0.0099384'], tr/val_loss:  2.319123/  2.321801, tr:  10.42%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:05<00:00, 12.27it/s]\n",
      "epoch-4   lr=['0.0098907'], tr/val_loss:  2.328817/  2.310750, tr:   7.66%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:04<00:00, 12.68it/s]\n",
      "epoch-5   lr=['0.0098296'], tr/val_loss:  2.318780/  2.313111, tr:   8.58%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:04<00:00, 12.43it/s]\n",
      "epoch-6   lr=['0.0097553'], tr/val_loss:  2.326567/  2.312034, tr:   8.89%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:05<00:00, 12.15it/s]\n",
      "epoch-7   lr=['0.0096679'], tr/val_loss:  2.319906/  2.308871, tr:   8.89%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:05<00:00, 12.15it/s]\n",
      "epoch-8   lr=['0.0095677'], tr/val_loss:  2.315703/  2.318316, tr:   9.09%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:04<00:00, 12.64it/s]\n",
      "epoch-9   lr=['0.0094550'], tr/val_loss:  2.315776/  2.321137, tr:   9.81%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:05<00:00, 12.34it/s]\n",
      "epoch-10  lr=['0.0093301'], tr/val_loss:  2.319218/  2.310921, tr:   9.40%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:05<00:00, 11.85it/s]\n",
      "epoch-11  lr=['0.0091934'], tr/val_loss:  2.320658/  2.318817, tr:   9.60%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:04<00:00, 12.44it/s]\n",
      "epoch-12  lr=['0.0090451'], tr/val_loss:  2.323760/  2.306959, tr:   9.70%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:04<00:00, 12.73it/s]\n",
      "epoch-13  lr=['0.0088857'], tr/val_loss:  2.312257/  2.313825, tr:   8.78%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:04<00:00, 12.47it/s]\n",
      "epoch-14  lr=['0.0087157'], tr/val_loss:  2.321870/  2.310401, tr:   9.70%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:04<00:00, 12.43it/s]\n",
      "epoch-15  lr=['0.0085355'], tr/val_loss:  2.318407/  2.313874, tr:   9.60%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:05<00:00, 12.12it/s]\n",
      "epoch-16  lr=['0.0083457'], tr/val_loss:  2.317499/  2.312321, tr:  10.11%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:05<00:00, 12.36it/s]\n",
      "epoch-17  lr=['0.0081466'], tr/val_loss:  2.318669/  2.307941, tr:   8.89%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:05<00:00, 12.39it/s]\n",
      "epoch-18  lr=['0.0079389'], tr/val_loss:  2.325135/  2.306585, tr:   7.46%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:04<00:00, 12.63it/s]\n",
      "epoch-19  lr=['0.0077232'], tr/val_loss:  2.314244/  2.310251, tr:  10.01%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:04<00:00, 12.78it/s]\n",
      "epoch-20  lr=['0.0075000'], tr/val_loss:  2.312182/  2.307967, tr:   9.91%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:05<00:00, 12.29it/s]\n",
      "epoch-21  lr=['0.0072700'], tr/val_loss:  2.318818/  2.307295, tr:   9.30%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:05<00:00, 12.32it/s]\n",
      "epoch-22  lr=['0.0070337'], tr/val_loss:  2.313441/  2.307399, tr:   9.91%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:04<00:00, 12.46it/s]\n",
      "epoch-23  lr=['0.0067918'], tr/val_loss:  2.314248/  2.309416, tr:   7.76%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:05<00:00, 12.32it/s]\n",
      "epoch-24  lr=['0.0065451'], tr/val_loss:  2.318841/  2.305136, tr:   9.09%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:05<00:00, 12.40it/s]\n",
      "epoch-25  lr=['0.0062941'], tr/val_loss:  2.316903/  2.306750, tr:   7.97%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:05<00:00, 12.35it/s]\n",
      "epoch-26  lr=['0.0060396'], tr/val_loss:  2.311055/  2.305107, tr:   8.99%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:04<00:00, 12.41it/s]\n",
      "epoch-27  lr=['0.0057822'], tr/val_loss:  2.313828/  2.306802, tr:   8.58%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:05<00:00, 12.24it/s]\n",
      "epoch-28  lr=['0.0055226'], tr/val_loss:  2.315332/  2.308450, tr:   8.68%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:05<00:00, 12.13it/s]\n",
      "epoch-29  lr=['0.0052617'], tr/val_loss:  2.315842/  2.306032, tr:   7.15%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:05<00:00, 11.93it/s]\n",
      "epoch-30  lr=['0.0050000'], tr/val_loss:  2.312570/  2.303939, tr:   8.89%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:05<00:00, 11.66it/s]\n",
      "epoch-31  lr=['0.0047383'], tr/val_loss:  2.309263/  2.303903, tr:   9.09%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:05<00:00, 12.18it/s]\n",
      "epoch-32  lr=['0.0044774'], tr/val_loss:  2.311847/  2.302894, tr:   8.38%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:05<00:00, 12.00it/s]\n",
      "epoch-33  lr=['0.0042178'], tr/val_loss:  2.308722/  2.303530, tr:   9.50%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:05<00:00, 11.57it/s]\n",
      "epoch-34  lr=['0.0039604'], tr/val_loss:  2.313000/  2.304187, tr:   8.48%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:05<00:00, 12.10it/s]\n",
      "epoch-35  lr=['0.0037059'], tr/val_loss:  2.309877/  2.303538, tr:   9.09%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:05<00:00, 12.35it/s]\n",
      "epoch-36  lr=['0.0034549'], tr/val_loss:  2.309406/  2.303601, tr:   8.99%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:04<00:00, 12.50it/s]\n",
      "epoch-37  lr=['0.0032082'], tr/val_loss:  2.309686/  2.303400, tr:   7.66%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:05<00:00, 12.14it/s]\n",
      "epoch-38  lr=['0.0029663'], tr/val_loss:  2.308588/  2.303166, tr:   9.09%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:05<00:00, 11.89it/s]\n",
      "epoch-39  lr=['0.0027300'], tr/val_loss:  2.308727/  2.302884, tr:   8.89%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:05<00:00, 11.86it/s]\n",
      "epoch-40  lr=['0.0025000'], tr/val_loss:  2.308749/  2.302732, tr:   9.40%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:05<00:00, 11.89it/s]\n",
      "epoch-41  lr=['0.0022768'], tr/val_loss:  2.306803/  2.302942, tr:   9.19%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:05<00:00, 12.30it/s]\n",
      "epoch-42  lr=['0.0020611'], tr/val_loss:  2.306347/  2.302762, tr:   8.68%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:04<00:00, 12.86it/s]\n",
      "epoch-43  lr=['0.0018534'], tr/val_loss:  2.305991/  2.302857, tr:   8.99%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:04<00:00, 12.63it/s]\n",
      "epoch-44  lr=['0.0016543'], tr/val_loss:  2.305293/  2.302853, tr:  10.01%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:04<00:00, 12.64it/s]\n",
      "epoch-45  lr=['0.0014645'], tr/val_loss:  2.306396/  2.302847, tr:   8.48%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:04<00:00, 13.36it/s]\n",
      "epoch-46  lr=['0.0012843'], tr/val_loss:  2.305307/  2.302670, tr:  10.01%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:04<00:00, 13.49it/s]\n",
      "epoch-47  lr=['0.0011143'], tr/val_loss:  2.305197/  2.302644, tr:   9.30%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:05<00:00, 12.35it/s]\n",
      "epoch-48  lr=['0.0009549'], tr/val_loss:  2.304637/  2.302745, tr:   8.78%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:05<00:00, 12.32it/s]\n",
      "epoch-49  lr=['0.0008066'], tr/val_loss:  2.304113/  2.302645, tr:   8.89%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:04<00:00, 12.41it/s]\n",
      "epoch-50  lr=['0.0006699'], tr/val_loss:  2.304358/  2.302700, tr:   8.68%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:05<00:00, 12.26it/s]\n",
      "epoch-51  lr=['0.0005450'], tr/val_loss:  2.303610/  2.302717, tr:   9.81%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:05<00:00, 12.04it/s]\n",
      "epoch-52  lr=['0.0004323'], tr/val_loss:  2.303667/  2.302626, tr:   9.30%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:05<00:00, 12.13it/s]\n",
      "epoch-53  lr=['0.0003321'], tr/val_loss:  2.303300/  2.302634, tr:   9.19%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:04<00:00, 12.44it/s]\n",
      "epoch-54  lr=['0.0002447'], tr/val_loss:  2.303030/  2.302622, tr:   8.38%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:04<00:00, 12.54it/s]\n",
      "epoch-55  lr=['0.0001704'], tr/val_loss:  2.303107/  2.302625, tr:  10.01%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:05<00:00, 11.97it/s]\n",
      "epoch-56  lr=['0.0001093'], tr/val_loss:  2.302886/  2.302609, tr:  10.01%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:05<00:00, 12.24it/s]\n",
      "epoch-57  lr=['0.0000616'], tr/val_loss:  2.302670/  2.302610, tr:  10.01%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:04<00:00, 12.74it/s]\n",
      "epoch-58  lr=['0.0000274'], tr/val_loss:  2.302685/  2.302609, tr:  10.01%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:05<00:00, 11.99it/s]\n",
      "epoch-59  lr=['0.0000069'], tr/val_loss:  2.302528/  2.302609, tr:  10.01%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:05<00:00, 12.21it/s]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b1a78e2ec7964188a1842ebb065f53d0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='3.438 MB of 3.438 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>DFA_flag</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>epoch</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇████</td></tr><tr><td>iter_acc</td><td>▁█▅▅▃▁▅█▆▃▆▅▃▃▁▃▃▃▁▁▁▁▆▅▁▃▁▅▃▅▃▅▃▃▅▅▁▃▅█</td></tr><tr><td>summary_val_acc</td><td>▁███████████████████████████████████████</td></tr><tr><td>tr_acc</td><td>▁███▇▇▇█▇███▇███▆▆▇▇▆▇▇▇▇▆▇▇▇▇██▇▇█▇▇███</td></tr><tr><td>tr_epoch_loss</td><td>▁███████████████████████████████████████</td></tr><tr><td>val_acc_best</td><td>▁███████████████████████████████████████</td></tr><tr><td>val_acc_now</td><td>▁███████████████████████████████████████</td></tr><tr><td>val_loss</td><td>▁███████████████████████████████████████</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>DFA_flag</td><td>0.0</td></tr><tr><td>epoch</td><td>59</td></tr><tr><td>iter_acc</td><td>0.33333</td></tr><tr><td>tr_acc</td><td>0.1001</td></tr><tr><td>tr_epoch_loss</td><td>2.30253</td></tr><tr><td>val_acc_best</td><td>0.1</td></tr><tr><td>val_acc_now</td><td>0.1</td></tr><tr><td>val_loss</td><td>2.30261</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">rose-sweep-51</strong> at: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/q33zj3ix' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/q33zj3ix</a><br/> View project at: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main</a><br/>Synced 7 W&B file(s), 0 media file(s), 0 artifact file(s) and 1 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20240822_192819-q33zj3ix/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require(\"core\")`! See https://wandb.me/wandb-core for more information."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: ssgqv38d with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBATCH: 16\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tDFA_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tIMAGE_SIZE: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tOTTT_input_trace_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tOTTT_sWS_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tTIME: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcfg: ['M', 'M', 200, 200]\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tconst2: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdecay: 0.25\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdrop_rate: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdvs_clipping: 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdvs_duration: 100000\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \te_transport_swap: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \te_transport_swap_coin: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \te_transport_swap_tr: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepoch_num: 60\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \texclude_class: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.01\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_sg_width: 2.570969004857107\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_reset: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_threshold: 1.085270539946095\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmerge_polarities: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tscheduler_name: CosineAnnealingLR\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsurrogate: hard_sigmoid\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \twhich_data: DVS_GESTURE_TONIC\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.17.7 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.17.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/nfs/home/bhkim003/github_folder/ByeonghyeonKim/my_snn/wandb/run-20240822_193358-ssgqv38d</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/ssgqv38d' target=\"_blank\">whole-sweep-53</a></strong> to <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/yxynyr6h' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/yxynyr6h</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/yxynyr6h' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/yxynyr6h</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/ssgqv38d' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/ssgqv38d</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BATCH' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'IMAGE_SIZE' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'which_data' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_threshold' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_reset' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_sg_width' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'cfg' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'learning_rate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'epoch_num' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'surrogate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'scheduler_name' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'dvs_clipping' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'dvs_duration' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'OTTT_sWS_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'DFA_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'OTTT_input_trace_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'e_transport_swap' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'e_transport_swap_tr' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'e_transport_swap_coin' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'drop_rate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'exclude_class' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'merge_polarities' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'TIME' was locked by 'sweep' (ignored update).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset_hash = 2bbd58b4e0d3c1e9ad501fad8a43feed\n",
      "cache path exists\n",
      "\n",
      "we will exclude the 'other' class. dvsgestrue 10 classes' indices exist. \n",
      "\n",
      "DataParallel(\n",
      "  (module): MY_SNN_FC_sstep(\n",
      "    (layers): MY_Sequential(\n",
      "      (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (2): DimChanger_for_FC_sstep()\n",
      "      (3): SYNAPSE_FC_trace_sstep()\n",
      "      (4): LIF_layer_trace_sstep()\n",
      "      (5): SYNAPSE_FC_trace_sstep()\n",
      "      (6): LIF_layer_trace_sstep()\n",
      "      (7): SYNAPSE_FC_trace_sstep()\n",
      "    )\n",
      "  )\n",
      ")\n",
      "==================================================\n",
      "My Num of PARAMS: 452,010, system's param_num : 452,010\n",
      "Memory: 1.72MiB at 32-bit\n",
      "==================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch-0   lr=['0.0100000'], tr/val_loss:  2.146781/  1.547706, tr:  19.92%, val:  47.92%, val_best:  47.92%: 100%|██████████| 62/62 [00:04<00:00, 12.89it/s]\n",
      "epoch-1   lr=['0.0099931'], tr/val_loss:  1.295569/  1.378941, tr:  55.26%, val:  52.50%, val_best:  52.50%: 100%|██████████| 62/62 [00:05<00:00, 11.65it/s]\n",
      "epoch-2   lr=['0.0099726'], tr/val_loss:  1.070215/  1.439821, tr:  64.04%, val:  53.75%, val_best:  53.75%: 100%|██████████| 62/62 [00:05<00:00, 11.87it/s]\n",
      "epoch-3   lr=['0.0099384'], tr/val_loss:  0.952569/  1.116736, tr:  66.70%, val:  64.58%, val_best:  64.58%: 100%|██████████| 62/62 [00:05<00:00, 12.03it/s]\n",
      "epoch-4   lr=['0.0098907'], tr/val_loss:  0.900050/  1.140277, tr:  68.44%, val:  62.50%, val_best:  64.58%: 100%|██████████| 62/62 [00:05<00:00, 12.36it/s]\n",
      "epoch-5   lr=['0.0098296'], tr/val_loss:  0.827519/  1.308333, tr:  69.87%, val:  63.33%, val_best:  64.58%: 100%|██████████| 62/62 [00:05<00:00, 12.24it/s]\n",
      "epoch-6   lr=['0.0097553'], tr/val_loss:  0.786615/  1.265463, tr:  70.28%, val:  57.92%, val_best:  64.58%: 100%|██████████| 62/62 [00:05<00:00, 12.36it/s]\n",
      "epoch-7   lr=['0.0096679'], tr/val_loss:  0.713021/  1.321671, tr:  73.54%, val:  56.67%, val_best:  64.58%: 100%|██████████| 62/62 [00:05<00:00, 11.81it/s]\n",
      "epoch-8   lr=['0.0095677'], tr/val_loss:  0.708457/  1.168797, tr:  75.38%, val:  62.92%, val_best:  64.58%: 100%|██████████| 62/62 [00:05<00:00, 12.13it/s]\n",
      "epoch-9   lr=['0.0094550'], tr/val_loss:  0.533905/  1.241641, tr:  80.39%, val:  74.58%, val_best:  74.58%: 100%|██████████| 62/62 [00:05<00:00, 12.13it/s]\n",
      "epoch-10  lr=['0.0093301'], tr/val_loss:  0.507800/  1.216974, tr:  83.66%, val:  65.00%, val_best:  74.58%: 100%|██████████| 62/62 [00:05<00:00, 12.11it/s]\n",
      "epoch-11  lr=['0.0091934'], tr/val_loss:  0.482033/  1.441607, tr:  82.94%, val:  58.75%, val_best:  74.58%: 100%|██████████| 62/62 [00:05<00:00, 12.02it/s]\n",
      "epoch-12  lr=['0.0090451'], tr/val_loss:  0.499401/  1.296428, tr:  83.86%, val:  70.00%, val_best:  74.58%: 100%|██████████| 62/62 [00:05<00:00, 12.23it/s]\n",
      "epoch-13  lr=['0.0088857'], tr/val_loss:  0.444789/  1.194312, tr:  86.52%, val:  68.75%, val_best:  74.58%: 100%|██████████| 62/62 [00:05<00:00, 11.79it/s]\n",
      "epoch-14  lr=['0.0087157'], tr/val_loss:  0.344285/  1.261775, tr:  91.52%, val:  76.67%, val_best:  76.67%: 100%|██████████| 62/62 [00:05<00:00, 11.63it/s]\n",
      "epoch-15  lr=['0.0085355'], tr/val_loss:  0.345676/  1.319580, tr:  92.85%, val:  74.58%, val_best:  76.67%: 100%|██████████| 62/62 [00:05<00:00, 12.35it/s]\n",
      "epoch-16  lr=['0.0083457'], tr/val_loss:  0.345681/  1.410211, tr:  92.54%, val:  77.08%, val_best:  77.08%: 100%|██████████| 62/62 [00:05<00:00, 11.97it/s]\n",
      "epoch-17  lr=['0.0081466'], tr/val_loss:  0.334942/  1.301818, tr:  93.26%, val:  73.33%, val_best:  77.08%: 100%|██████████| 62/62 [00:05<00:00, 12.03it/s]\n",
      "epoch-18  lr=['0.0079389'], tr/val_loss:  0.288095/  1.267974, tr:  93.77%, val:  75.42%, val_best:  77.08%: 100%|██████████| 62/62 [00:05<00:00, 11.93it/s]\n",
      "epoch-19  lr=['0.0077232'], tr/val_loss:  0.252054/  1.322631, tr:  97.04%, val:  80.42%, val_best:  80.42%: 100%|██████████| 62/62 [00:05<00:00, 11.92it/s]\n",
      "epoch-20  lr=['0.0075000'], tr/val_loss:  0.184202/  1.325879, tr:  98.37%, val:  79.17%, val_best:  80.42%: 100%|██████████| 62/62 [00:05<00:00, 11.99it/s]\n",
      "epoch-21  lr=['0.0072700'], tr/val_loss:  0.134424/  1.510904, tr:  99.69%, val:  73.75%, val_best:  80.42%: 100%|██████████| 62/62 [00:05<00:00, 12.17it/s]\n",
      "epoch-22  lr=['0.0070337'], tr/val_loss:  0.123156/  1.464118, tr:  98.47%, val:  75.83%, val_best:  80.42%: 100%|██████████| 62/62 [00:05<00:00, 11.95it/s]\n",
      "epoch-23  lr=['0.0067918'], tr/val_loss:  0.093457/  1.432297, tr:  99.80%, val:  79.17%, val_best:  80.42%: 100%|██████████| 62/62 [00:05<00:00, 12.01it/s]\n",
      "epoch-24  lr=['0.0065451'], tr/val_loss:  0.096131/  1.494316, tr:  99.18%, val:  80.00%, val_best:  80.42%: 100%|██████████| 62/62 [00:05<00:00, 12.25it/s]\n",
      "epoch-25  lr=['0.0062941'], tr/val_loss:  0.054401/  1.513846, tr: 100.00%, val:  80.00%, val_best:  80.42%: 100%|██████████| 62/62 [00:05<00:00, 11.73it/s]\n",
      "epoch-26  lr=['0.0060396'], tr/val_loss:  0.036685/  1.476649, tr: 100.00%, val:  82.08%, val_best:  82.08%: 100%|██████████| 62/62 [00:04<00:00, 12.51it/s]\n",
      "epoch-27  lr=['0.0057822'], tr/val_loss:  0.020717/  1.505056, tr: 100.00%, val:  82.50%, val_best:  82.50%: 100%|██████████| 62/62 [00:05<00:00, 12.28it/s]\n",
      "epoch-28  lr=['0.0055226'], tr/val_loss:  0.013462/  1.568385, tr: 100.00%, val:  83.33%, val_best:  83.33%: 100%|██████████| 62/62 [00:04<00:00, 12.53it/s]\n",
      "epoch-29  lr=['0.0052617'], tr/val_loss:  0.010547/  1.542640, tr: 100.00%, val:  84.17%, val_best:  84.17%: 100%|██████████| 62/62 [00:05<00:00, 11.97it/s]\n",
      "epoch-30  lr=['0.0050000'], tr/val_loss:  0.009150/  1.566815, tr: 100.00%, val:  85.00%, val_best:  85.00%: 100%|██████████| 62/62 [00:05<00:00, 11.79it/s]\n",
      "epoch-31  lr=['0.0047383'], tr/val_loss:  0.008097/  1.561250, tr: 100.00%, val:  85.42%, val_best:  85.42%: 100%|██████████| 62/62 [00:05<00:00, 12.06it/s]\n",
      "epoch-32  lr=['0.0044774'], tr/val_loss:  0.006105/  1.597683, tr: 100.00%, val:  85.42%, val_best:  85.42%: 100%|██████████| 62/62 [00:05<00:00, 12.24it/s]\n",
      "epoch-33  lr=['0.0042178'], tr/val_loss:  0.004598/  1.602283, tr: 100.00%, val:  84.58%, val_best:  85.42%: 100%|██████████| 62/62 [00:04<00:00, 12.68it/s]\n",
      "epoch-34  lr=['0.0039604'], tr/val_loss:  0.003986/  1.622449, tr: 100.00%, val:  84.17%, val_best:  85.42%: 100%|██████████| 62/62 [00:05<00:00, 12.04it/s]\n",
      "epoch-35  lr=['0.0037059'], tr/val_loss:  0.003826/  1.627247, tr: 100.00%, val:  84.58%, val_best:  85.42%: 100%|██████████| 62/62 [00:05<00:00, 11.09it/s]\n",
      "epoch-36  lr=['0.0034549'], tr/val_loss:  0.003219/  1.625410, tr: 100.00%, val:  84.58%, val_best:  85.42%: 100%|██████████| 62/62 [00:04<00:00, 12.53it/s]\n",
      "epoch-37  lr=['0.0032082'], tr/val_loss:  0.003155/  1.642808, tr: 100.00%, val:  84.17%, val_best:  85.42%: 100%|██████████| 62/62 [00:05<00:00, 12.19it/s]\n",
      "epoch-38  lr=['0.0029663'], tr/val_loss:  0.002898/  1.665433, tr: 100.00%, val:  84.17%, val_best:  85.42%: 100%|██████████| 62/62 [00:05<00:00, 12.07it/s]\n",
      "epoch-39  lr=['0.0027300'], tr/val_loss:  0.002692/  1.652662, tr: 100.00%, val:  85.00%, val_best:  85.42%: 100%|██████████| 62/62 [00:04<00:00, 12.40it/s]\n",
      "epoch-40  lr=['0.0025000'], tr/val_loss:  0.002496/  1.646952, tr: 100.00%, val:  85.83%, val_best:  85.83%: 100%|██████████| 62/62 [00:06<00:00,  9.62it/s]\n",
      "epoch-41  lr=['0.0022768'], tr/val_loss:  0.002371/  1.648862, tr: 100.00%, val:  85.42%, val_best:  85.83%: 100%|██████████| 62/62 [00:05<00:00, 12.00it/s]\n",
      "epoch-42  lr=['0.0020611'], tr/val_loss:  0.002293/  1.652956, tr: 100.00%, val:  84.17%, val_best:  85.83%: 100%|██████████| 62/62 [00:04<00:00, 12.60it/s]\n",
      "epoch-43  lr=['0.0018534'], tr/val_loss:  0.002195/  1.663701, tr: 100.00%, val:  84.17%, val_best:  85.83%: 100%|██████████| 62/62 [00:04<00:00, 13.31it/s]\n",
      "epoch-44  lr=['0.0016543'], tr/val_loss:  0.002174/  1.656567, tr: 100.00%, val:  84.58%, val_best:  85.83%: 100%|██████████| 62/62 [00:05<00:00, 12.06it/s]\n",
      "epoch-45  lr=['0.0014645'], tr/val_loss:  0.002111/  1.659692, tr: 100.00%, val:  85.00%, val_best:  85.83%: 100%|██████████| 62/62 [00:05<00:00, 12.27it/s]\n",
      "epoch-46  lr=['0.0012843'], tr/val_loss:  0.002078/  1.656229, tr: 100.00%, val:  85.00%, val_best:  85.83%: 100%|██████████| 62/62 [00:04<00:00, 12.92it/s]\n",
      "epoch-47  lr=['0.0011143'], tr/val_loss:  0.002019/  1.654625, tr: 100.00%, val:  85.00%, val_best:  85.83%: 100%|██████████| 62/62 [00:05<00:00, 11.89it/s]\n",
      "epoch-48  lr=['0.0009549'], tr/val_loss:  0.002054/  1.662171, tr: 100.00%, val:  85.00%, val_best:  85.83%: 100%|██████████| 62/62 [00:05<00:00, 11.49it/s]\n",
      "epoch-49  lr=['0.0008066'], tr/val_loss:  0.001970/  1.663095, tr: 100.00%, val:  85.00%, val_best:  85.83%: 100%|██████████| 62/62 [00:05<00:00, 12.39it/s]\n",
      "epoch-50  lr=['0.0006699'], tr/val_loss:  0.001974/  1.664966, tr: 100.00%, val:  85.00%, val_best:  85.83%: 100%|██████████| 62/62 [00:05<00:00, 12.20it/s]\n",
      "epoch-51  lr=['0.0005450'], tr/val_loss:  0.001958/  1.668143, tr: 100.00%, val:  85.00%, val_best:  85.83%: 100%|██████████| 62/62 [00:05<00:00, 11.78it/s]\n",
      "epoch-52  lr=['0.0004323'], tr/val_loss:  0.001913/  1.667287, tr: 100.00%, val:  85.00%, val_best:  85.83%: 100%|██████████| 62/62 [00:05<00:00, 12.06it/s]\n",
      "epoch-53  lr=['0.0003321'], tr/val_loss:  0.001916/  1.669303, tr: 100.00%, val:  85.00%, val_best:  85.83%: 100%|██████████| 62/62 [00:05<00:00, 11.97it/s]\n",
      "epoch-54  lr=['0.0002447'], tr/val_loss:  0.001959/  1.667479, tr: 100.00%, val:  85.00%, val_best:  85.83%: 100%|██████████| 62/62 [00:05<00:00, 11.96it/s]\n",
      "epoch-55  lr=['0.0001704'], tr/val_loss:  0.001895/  1.669550, tr: 100.00%, val:  85.00%, val_best:  85.83%: 100%|██████████| 62/62 [00:04<00:00, 12.42it/s]\n",
      "epoch-56  lr=['0.0001093'], tr/val_loss:  0.001913/  1.671963, tr: 100.00%, val:  85.00%, val_best:  85.83%: 100%|██████████| 62/62 [00:05<00:00, 12.22it/s]\n",
      "epoch-57  lr=['0.0000616'], tr/val_loss:  0.001896/  1.671736, tr: 100.00%, val:  85.00%, val_best:  85.83%: 100%|██████████| 62/62 [00:05<00:00, 12.30it/s]\n",
      "epoch-58  lr=['0.0000274'], tr/val_loss:  0.001899/  1.671694, tr: 100.00%, val:  85.00%, val_best:  85.83%: 100%|██████████| 62/62 [00:05<00:00, 12.20it/s]\n",
      "epoch-59  lr=['0.0000069'], tr/val_loss:  0.001895/  1.671598, tr: 100.00%, val:  85.00%, val_best:  85.83%: 100%|██████████| 62/62 [00:05<00:00, 12.08it/s]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ed8f485019614859a0ed5a77a862ded7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='3.438 MB of 3.438 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>DFA_flag</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>epoch</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇████</td></tr><tr><td>iter_acc</td><td>▁▅▆▆▆▆▆▇▇▇▇█████████████████████████████</td></tr><tr><td>summary_val_acc</td><td>▁▅▅▆▆▆▆▇▆▇▇▇▇█▇▇▇███████████████████████</td></tr><tr><td>tr_acc</td><td>▁▂▅▆▆▆▆▇▇▇▇▇████████████████████████████</td></tr><tr><td>tr_epoch_loss</td><td>▁█▄▄▄▄▃▃▃▃▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_acc_best</td><td>▁▅▅▆▆▆▆▇▇▇▇▇▇███████████████████████████</td></tr><tr><td>val_acc_now</td><td>▁▅▅▆▆▆▆▇▆▇▇▇▇█▇▇▇███████████████████████</td></tr><tr><td>val_loss</td><td>▁▇▇▆▆▆▆▆▇▆▆▇▆▇▇▇▇▇▇█▇███████████████████</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>DFA_flag</td><td>0.0</td></tr><tr><td>epoch</td><td>59</td></tr><tr><td>iter_acc</td><td>1.0</td></tr><tr><td>tr_acc</td><td>1.0</td></tr><tr><td>tr_epoch_loss</td><td>0.00189</td></tr><tr><td>val_acc_best</td><td>0.85833</td></tr><tr><td>val_acc_now</td><td>0.85</td></tr><tr><td>val_loss</td><td>1.6716</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">whole-sweep-53</strong> at: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/ssgqv38d' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/ssgqv38d</a><br/> View project at: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main</a><br/>Synced 7 W&B file(s), 0 media file(s), 0 artifact file(s) and 1 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20240822_193358-ssgqv38d/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require(\"core\")`! See https://wandb.me/wandb-core for more information."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 9qpzcx77 with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBATCH: 16\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tDFA_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tIMAGE_SIZE: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tOTTT_input_trace_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tOTTT_sWS_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tTIME: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcfg: ['M', 'M', 200, 200]\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tconst2: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdecay: 0.25\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdrop_rate: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdvs_clipping: 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdvs_duration: 100000\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \te_transport_swap: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \te_transport_swap_coin: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \te_transport_swap_tr: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepoch_num: 60\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \texclude_class: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.01\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_sg_width: 2.570969004857107\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_reset: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_threshold: 2.99140135943297\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmerge_polarities: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tscheduler_name: CosineAnnealingLR\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsurrogate: hard_sigmoid\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \twhich_data: DVS_GESTURE_TONIC\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.17.7 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.17.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/nfs/home/bhkim003/github_folder/ByeonghyeonKim/my_snn/wandb/run-20240822_193939-9qpzcx77</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/9qpzcx77' target=\"_blank\">jumping-sweep-55</a></strong> to <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/yxynyr6h' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/yxynyr6h</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/yxynyr6h' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/yxynyr6h</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/9qpzcx77' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/9qpzcx77</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BATCH' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'IMAGE_SIZE' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'which_data' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_threshold' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_reset' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_sg_width' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'cfg' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'learning_rate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'epoch_num' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'surrogate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'scheduler_name' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'dvs_clipping' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'dvs_duration' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'OTTT_sWS_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'DFA_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'OTTT_input_trace_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'e_transport_swap' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'e_transport_swap_tr' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'e_transport_swap_coin' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'drop_rate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'exclude_class' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'merge_polarities' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'TIME' was locked by 'sweep' (ignored update).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset_hash = 2bbd58b4e0d3c1e9ad501fad8a43feed\n",
      "cache path exists\n",
      "\n",
      "we will exclude the 'other' class. dvsgestrue 10 classes' indices exist. \n",
      "\n",
      "DataParallel(\n",
      "  (module): MY_SNN_FC_sstep(\n",
      "    (layers): MY_Sequential(\n",
      "      (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (2): DimChanger_for_FC_sstep()\n",
      "      (3): SYNAPSE_FC_trace_sstep()\n",
      "      (4): LIF_layer_trace_sstep()\n",
      "      (5): SYNAPSE_FC_trace_sstep()\n",
      "      (6): LIF_layer_trace_sstep()\n",
      "      (7): SYNAPSE_FC_trace_sstep()\n",
      "    )\n",
      "  )\n",
      ")\n",
      "==================================================\n",
      "My Num of PARAMS: 452,010, system's param_num : 452,010\n",
      "Memory: 1.72MiB at 32-bit\n",
      "==================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch-0   lr=['0.0100000'], tr/val_loss:  2.317507/  2.316367, tr:   9.70%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:04<00:00, 12.82it/s]\n",
      "epoch-1   lr=['0.0099931'], tr/val_loss:  2.316254/  2.314931, tr:  10.21%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:04<00:00, 12.42it/s]\n",
      "epoch-2   lr=['0.0099726'], tr/val_loss:  2.315321/  2.315877, tr:   9.81%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:05<00:00, 12.15it/s]\n",
      "epoch-3   lr=['0.0099384'], tr/val_loss:  2.319123/  2.321801, tr:  10.42%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:04<00:00, 12.44it/s]\n",
      "epoch-4   lr=['0.0098907'], tr/val_loss:  2.328817/  2.310750, tr:   7.66%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:05<00:00, 12.15it/s]\n",
      "epoch-5   lr=['0.0098296'], tr/val_loss:  2.318780/  2.313111, tr:   8.58%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:05<00:00, 12.18it/s]\n",
      "epoch-6   lr=['0.0097553'], tr/val_loss:  2.326567/  2.312034, tr:   8.89%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:05<00:00, 12.11it/s]\n",
      "epoch-7   lr=['0.0096679'], tr/val_loss:  2.319906/  2.308871, tr:   8.89%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:05<00:00, 12.14it/s]\n",
      "epoch-8   lr=['0.0095677'], tr/val_loss:  2.315703/  2.318316, tr:   9.09%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:05<00:00, 12.09it/s]\n",
      "epoch-9   lr=['0.0094550'], tr/val_loss:  2.315776/  2.321137, tr:   9.81%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:05<00:00, 12.40it/s]\n",
      "epoch-10  lr=['0.0093301'], tr/val_loss:  2.319218/  2.310921, tr:   9.40%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:05<00:00, 12.12it/s]\n",
      "epoch-11  lr=['0.0091934'], tr/val_loss:  2.320658/  2.318817, tr:   9.60%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:05<00:00, 12.06it/s]\n",
      "epoch-12  lr=['0.0090451'], tr/val_loss:  2.323760/  2.306959, tr:   9.70%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:05<00:00, 12.25it/s]\n",
      "epoch-13  lr=['0.0088857'], tr/val_loss:  2.312257/  2.313825, tr:   8.78%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:04<00:00, 12.45it/s]\n",
      "epoch-14  lr=['0.0087157'], tr/val_loss:  2.321870/  2.310401, tr:   9.70%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:05<00:00, 12.23it/s]\n",
      "epoch-15  lr=['0.0085355'], tr/val_loss:  2.318407/  2.313874, tr:   9.60%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:04<00:00, 12.65it/s]\n",
      "epoch-16  lr=['0.0083457'], tr/val_loss:  2.317499/  2.312321, tr:  10.11%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:05<00:00, 12.27it/s]\n",
      "epoch-17  lr=['0.0081466'], tr/val_loss:  2.318669/  2.307941, tr:   8.89%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:05<00:00, 12.18it/s]\n",
      "epoch-18  lr=['0.0079389'], tr/val_loss:  2.325135/  2.306585, tr:   7.46%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:05<00:00, 12.18it/s]\n",
      "epoch-19  lr=['0.0077232'], tr/val_loss:  2.314244/  2.310251, tr:  10.01%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:05<00:00, 12.20it/s]\n",
      "epoch-20  lr=['0.0075000'], tr/val_loss:  2.312182/  2.307967, tr:   9.91%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:04<00:00, 12.61it/s]\n",
      "epoch-21  lr=['0.0072700'], tr/val_loss:  2.318818/  2.307295, tr:   9.30%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:04<00:00, 12.50it/s]\n",
      "epoch-22  lr=['0.0070337'], tr/val_loss:  2.313441/  2.307399, tr:   9.91%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:05<00:00, 12.37it/s]\n",
      "epoch-23  lr=['0.0067918'], tr/val_loss:  2.314248/  2.309416, tr:   7.76%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:04<00:00, 12.51it/s]\n",
      "epoch-24  lr=['0.0065451'], tr/val_loss:  2.318841/  2.305136, tr:   9.09%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:05<00:00, 12.32it/s]\n",
      "epoch-25  lr=['0.0062941'], tr/val_loss:  2.316903/  2.306750, tr:   7.97%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:04<00:00, 12.91it/s]\n",
      "epoch-26  lr=['0.0060396'], tr/val_loss:  2.311055/  2.305107, tr:   8.99%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:05<00:00, 12.36it/s]\n",
      "epoch-27  lr=['0.0057822'], tr/val_loss:  2.313828/  2.306802, tr:   8.58%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:05<00:00, 12.21it/s]\n",
      "epoch-28  lr=['0.0055226'], tr/val_loss:  2.315332/  2.308450, tr:   8.68%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:05<00:00, 11.94it/s]\n",
      "epoch-29  lr=['0.0052617'], tr/val_loss:  2.315842/  2.306032, tr:   7.15%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:05<00:00, 11.87it/s]\n",
      "epoch-30  lr=['0.0050000'], tr/val_loss:  2.312570/  2.303939, tr:   8.89%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:05<00:00, 11.91it/s]\n",
      "epoch-31  lr=['0.0047383'], tr/val_loss:  2.309263/  2.303903, tr:   9.09%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:05<00:00, 12.12it/s]\n",
      "epoch-32  lr=['0.0044774'], tr/val_loss:  2.311847/  2.302894, tr:   8.38%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:04<00:00, 12.57it/s]\n",
      "epoch-33  lr=['0.0042178'], tr/val_loss:  2.308722/  2.303530, tr:   9.50%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:05<00:00, 12.11it/s]\n",
      "epoch-34  lr=['0.0039604'], tr/val_loss:  2.313000/  2.304187, tr:   8.48%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:05<00:00, 12.19it/s]\n",
      "epoch-35  lr=['0.0037059'], tr/val_loss:  2.309877/  2.303538, tr:   9.09%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:05<00:00, 12.13it/s]\n",
      "epoch-36  lr=['0.0034549'], tr/val_loss:  2.309406/  2.303601, tr:   8.99%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:05<00:00, 12.27it/s]\n",
      "epoch-37  lr=['0.0032082'], tr/val_loss:  2.309686/  2.303400, tr:   7.66%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:05<00:00, 12.40it/s]\n",
      "epoch-38  lr=['0.0029663'], tr/val_loss:  2.308588/  2.303166, tr:   9.09%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:05<00:00, 12.33it/s]\n",
      "epoch-39  lr=['0.0027300'], tr/val_loss:  2.308727/  2.302884, tr:   8.89%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:05<00:00, 12.07it/s]\n",
      "epoch-40  lr=['0.0025000'], tr/val_loss:  2.308749/  2.302732, tr:   9.40%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:05<00:00, 12.27it/s]\n",
      "epoch-41  lr=['0.0022768'], tr/val_loss:  2.306803/  2.302942, tr:   9.19%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:04<00:00, 12.57it/s]\n",
      "epoch-42  lr=['0.0020611'], tr/val_loss:  2.306347/  2.302762, tr:   8.68%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:05<00:00, 12.37it/s]\n",
      "epoch-43  lr=['0.0018534'], tr/val_loss:  2.305991/  2.302857, tr:   8.99%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:04<00:00, 12.76it/s]\n",
      "epoch-44  lr=['0.0016543'], tr/val_loss:  2.305293/  2.302853, tr:  10.01%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:04<00:00, 12.85it/s]\n",
      "epoch-45  lr=['0.0014645'], tr/val_loss:  2.306396/  2.302847, tr:   8.48%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:05<00:00, 12.33it/s]\n",
      "epoch-46  lr=['0.0012843'], tr/val_loss:  2.305307/  2.302670, tr:  10.01%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:05<00:00, 12.14it/s]\n",
      "epoch-47  lr=['0.0011143'], tr/val_loss:  2.305197/  2.302644, tr:   9.30%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:04<00:00, 12.79it/s]\n",
      "epoch-48  lr=['0.0009549'], tr/val_loss:  2.304637/  2.302745, tr:   8.78%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:04<00:00, 12.48it/s]\n",
      "epoch-49  lr=['0.0008066'], tr/val_loss:  2.304113/  2.302645, tr:   8.89%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:04<00:00, 12.73it/s]\n",
      "epoch-50  lr=['0.0006699'], tr/val_loss:  2.304358/  2.302700, tr:   8.68%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:05<00:00, 12.13it/s]\n",
      "epoch-51  lr=['0.0005450'], tr/val_loss:  2.303610/  2.302717, tr:   9.81%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:05<00:00, 11.80it/s]\n",
      "epoch-52  lr=['0.0004323'], tr/val_loss:  2.303667/  2.302626, tr:   9.30%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:05<00:00, 11.56it/s]\n",
      "epoch-53  lr=['0.0003321'], tr/val_loss:  2.303300/  2.302634, tr:   9.19%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:05<00:00, 12.15it/s]\n",
      "epoch-54  lr=['0.0002447'], tr/val_loss:  2.303030/  2.302622, tr:   8.38%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:05<00:00, 12.15it/s]\n",
      "epoch-55  lr=['0.0001704'], tr/val_loss:  2.303107/  2.302625, tr:  10.01%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:05<00:00, 12.09it/s]\n",
      "epoch-56  lr=['0.0001093'], tr/val_loss:  2.302886/  2.302609, tr:  10.01%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:05<00:00, 12.37it/s]\n",
      "epoch-57  lr=['0.0000616'], tr/val_loss:  2.302670/  2.302610, tr:  10.01%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:05<00:00, 12.37it/s]\n",
      "epoch-58  lr=['0.0000274'], tr/val_loss:  2.302685/  2.302609, tr:  10.01%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:05<00:00, 12.09it/s]\n",
      "epoch-59  lr=['0.0000069'], tr/val_loss:  2.302528/  2.302609, tr:  10.01%, val:  10.00%, val_best:  10.00%: 100%|██████████| 62/62 [00:05<00:00, 12.09it/s]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fab23f86ab534ff0819f8ed0f8e00710",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='3.438 MB of 3.438 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>DFA_flag</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>epoch</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇████</td></tr><tr><td>iter_acc</td><td>▁█▅▅▃▁▅█▆▃▆▅▃▃▁▃▃▃▁▁▁▁▆▅▁▃▁▅▃▅▃▅▃▃▅▅▁▃▅█</td></tr><tr><td>summary_val_acc</td><td>▁███████████████████████████████████████</td></tr><tr><td>tr_acc</td><td>▁███▇▇▇█▇███▇███▆▆▇▇▆▇▇▇▇▆▇▇▇▇██▇▇█▇▇███</td></tr><tr><td>tr_epoch_loss</td><td>▁███████████████████████████████████████</td></tr><tr><td>val_acc_best</td><td>▁███████████████████████████████████████</td></tr><tr><td>val_acc_now</td><td>▁███████████████████████████████████████</td></tr><tr><td>val_loss</td><td>▁███████████████████████████████████████</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>DFA_flag</td><td>0.0</td></tr><tr><td>epoch</td><td>59</td></tr><tr><td>iter_acc</td><td>0.33333</td></tr><tr><td>tr_acc</td><td>0.1001</td></tr><tr><td>tr_epoch_loss</td><td>2.30253</td></tr><tr><td>val_acc_best</td><td>0.1</td></tr><tr><td>val_acc_now</td><td>0.1</td></tr><tr><td>val_loss</td><td>2.30261</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">jumping-sweep-55</strong> at: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/9qpzcx77' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/9qpzcx77</a><br/> View project at: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main</a><br/>Synced 7 W&B file(s), 0 media file(s), 0 artifact file(s) and 1 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20240822_193939-9qpzcx77/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require(\"core\")`! See https://wandb.me/wandb-core for more information."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Sweep Agent: Waiting for job.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Job received.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 913uhrvh with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBATCH: 16\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tDFA_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tIMAGE_SIZE: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tOTTT_input_trace_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tOTTT_sWS_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tTIME: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcfg: ['M', 'M', 200, 200]\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tconst2: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdecay: 0.25\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdrop_rate: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdvs_clipping: 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdvs_duration: 100000\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \te_transport_swap: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \te_transport_swap_coin: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \te_transport_swap_tr: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepoch_num: 60\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \texclude_class: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.01\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_sg_width: 2.570969004857107\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_reset: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_threshold: 0.25187520203834646\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmerge_polarities: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tscheduler_name: CosineAnnealingLR\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsurrogate: hard_sigmoid\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \twhich_data: DVS_GESTURE_TONIC\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.17.7 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.17.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/nfs/home/bhkim003/github_folder/ByeonghyeonKim/my_snn/wandb/run-20240822_194518-913uhrvh</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/913uhrvh' target=\"_blank\">pious-sweep-57</a></strong> to <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/yxynyr6h' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/yxynyr6h</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/yxynyr6h' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/yxynyr6h</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/913uhrvh' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/913uhrvh</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BATCH' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'IMAGE_SIZE' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'which_data' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_threshold' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_reset' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_sg_width' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'cfg' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'learning_rate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'epoch_num' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'surrogate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'scheduler_name' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'dvs_clipping' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'dvs_duration' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'OTTT_sWS_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'DFA_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'OTTT_input_trace_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'e_transport_swap' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'e_transport_swap_tr' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'e_transport_swap_coin' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'drop_rate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'exclude_class' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'merge_polarities' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'TIME' was locked by 'sweep' (ignored update).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset_hash = 2bbd58b4e0d3c1e9ad501fad8a43feed\n",
      "cache path exists\n",
      "\n",
      "we will exclude the 'other' class. dvsgestrue 10 classes' indices exist. \n",
      "\n",
      "DataParallel(\n",
      "  (module): MY_SNN_FC_sstep(\n",
      "    (layers): MY_Sequential(\n",
      "      (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (2): DimChanger_for_FC_sstep()\n",
      "      (3): SYNAPSE_FC_trace_sstep()\n",
      "      (4): LIF_layer_trace_sstep()\n",
      "      (5): SYNAPSE_FC_trace_sstep()\n",
      "      (6): LIF_layer_trace_sstep()\n",
      "      (7): SYNAPSE_FC_trace_sstep()\n",
      "    )\n",
      "  )\n",
      ")\n",
      "==================================================\n",
      "My Num of PARAMS: 452,010, system's param_num : 452,010\n",
      "Memory: 1.72MiB at 32-bit\n",
      "==================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch-0   lr=['0.0100000'], tr/val_loss:  1.510107/  1.275678, tr:  46.88%, val:  50.83%, val_best:  50.83%: 100%|██████████| 62/62 [00:05<00:00, 12.02it/s]\n",
      "epoch-1   lr=['0.0099931'], tr/val_loss:  1.110804/  1.421435, tr:  58.53%, val:  50.83%, val_best:  50.83%: 100%|██████████| 62/62 [00:05<00:00, 11.72it/s]\n",
      "epoch-2   lr=['0.0099726'], tr/val_loss:  0.941573/  1.216820, tr:  65.07%, val:  57.92%, val_best:  57.92%: 100%|██████████| 62/62 [00:05<00:00, 11.94it/s]\n",
      "epoch-3   lr=['0.0099384'], tr/val_loss:  0.849932/  1.238878, tr:  69.05%, val:  60.00%, val_best:  60.00%: 100%|██████████| 62/62 [00:05<00:00, 12.25it/s]\n",
      "epoch-4   lr=['0.0098907'], tr/val_loss:  0.820104/  1.207919, tr:  68.54%, val:  63.33%, val_best:  63.33%: 100%|██████████| 62/62 [00:05<00:00, 12.28it/s]\n",
      "epoch-5   lr=['0.0098296'], tr/val_loss:  0.752299/  1.297150, tr:  70.48%, val:  62.50%, val_best:  63.33%: 100%|██████████| 62/62 [00:05<00:00, 12.19it/s]\n",
      "epoch-6   lr=['0.0097553'], tr/val_loss:  0.666808/  1.182302, tr:  72.83%, val:  60.00%, val_best:  63.33%: 100%|██████████| 62/62 [00:05<00:00, 12.24it/s]\n",
      "epoch-7   lr=['0.0096679'], tr/val_loss:  0.592437/  1.258465, tr:  75.69%, val:  62.92%, val_best:  63.33%: 100%|██████████| 62/62 [00:05<00:00, 12.07it/s]\n",
      "epoch-8   lr=['0.0095677'], tr/val_loss:  0.615847/  1.116804, tr:  75.79%, val:  65.83%, val_best:  65.83%: 100%|██████████| 62/62 [00:05<00:00, 11.90it/s]\n",
      "epoch-9   lr=['0.0094550'], tr/val_loss:  0.443285/  1.255430, tr:  82.64%, val:  63.33%, val_best:  65.83%: 100%|██████████| 62/62 [00:05<00:00, 12.32it/s]\n",
      "epoch-10  lr=['0.0093301'], tr/val_loss:  0.462346/  1.110697, tr:  83.25%, val:  65.83%, val_best:  65.83%: 100%|██████████| 62/62 [00:05<00:00, 11.44it/s]\n",
      "epoch-11  lr=['0.0091934'], tr/val_loss:  0.440698/  1.174210, tr:  82.53%, val:  66.25%, val_best:  66.25%: 100%|██████████| 62/62 [00:05<00:00, 11.66it/s]\n",
      "epoch-12  lr=['0.0090451'], tr/val_loss:  0.401958/  1.253511, tr:  86.62%, val:  73.75%, val_best:  73.75%: 100%|██████████| 62/62 [00:05<00:00, 11.89it/s]\n",
      "epoch-13  lr=['0.0088857'], tr/val_loss:  0.358942/  1.417104, tr:  89.89%, val:  68.75%, val_best:  73.75%: 100%|██████████| 62/62 [00:05<00:00, 11.85it/s]\n",
      "epoch-14  lr=['0.0087157'], tr/val_loss:  0.320594/  1.351359, tr:  92.75%, val:  72.92%, val_best:  73.75%: 100%|██████████| 62/62 [00:05<00:00, 12.28it/s]\n",
      "epoch-15  lr=['0.0085355'], tr/val_loss:  0.295054/  1.387163, tr:  92.13%, val:  70.42%, val_best:  73.75%: 100%|██████████| 62/62 [00:05<00:00, 12.18it/s]\n",
      "epoch-16  lr=['0.0083457'], tr/val_loss:  0.214733/  1.604192, tr:  96.32%, val:  69.17%, val_best:  73.75%: 100%|██████████| 62/62 [00:05<00:00, 12.01it/s]\n",
      "epoch-17  lr=['0.0081466'], tr/val_loss:  0.251574/  1.324913, tr:  95.30%, val:  72.92%, val_best:  73.75%: 100%|██████████| 62/62 [00:05<00:00, 11.61it/s]\n",
      "epoch-18  lr=['0.0079389'], tr/val_loss:  0.191206/  1.457062, tr:  97.45%, val:  74.17%, val_best:  74.17%: 100%|██████████| 62/62 [00:05<00:00, 11.61it/s]\n",
      "epoch-19  lr=['0.0077232'], tr/val_loss:  0.132096/  1.451566, tr:  98.57%, val:  76.25%, val_best:  76.25%: 100%|██████████| 62/62 [00:05<00:00, 11.98it/s]\n",
      "epoch-20  lr=['0.0075000'], tr/val_loss:  0.103612/  1.436940, tr:  99.80%, val:  79.58%, val_best:  79.58%: 100%|██████████| 62/62 [00:05<00:00, 11.77it/s]\n",
      "epoch-21  lr=['0.0072700'], tr/val_loss:  0.068689/  1.609070, tr: 100.00%, val:  76.25%, val_best:  79.58%: 100%|██████████| 62/62 [00:05<00:00, 11.48it/s]\n",
      "epoch-22  lr=['0.0070337'], tr/val_loss:  0.125483/  1.518638, tr:  98.06%, val:  76.67%, val_best:  79.58%: 100%|██████████| 62/62 [00:05<00:00, 12.26it/s]\n",
      "epoch-23  lr=['0.0067918'], tr/val_loss:  0.047259/  1.576845, tr:  99.90%, val:  78.75%, val_best:  79.58%: 100%|██████████| 62/62 [00:05<00:00, 11.70it/s]\n",
      "epoch-24  lr=['0.0065451'], tr/val_loss:  0.033660/  1.639394, tr:  99.90%, val:  77.92%, val_best:  79.58%: 100%|██████████| 62/62 [00:05<00:00, 12.25it/s]\n",
      "epoch-25  lr=['0.0062941'], tr/val_loss:  0.018744/  1.597340, tr: 100.00%, val:  78.33%, val_best:  79.58%: 100%|██████████| 62/62 [00:05<00:00, 11.88it/s]\n",
      "epoch-26  lr=['0.0060396'], tr/val_loss:  0.010760/  1.685212, tr: 100.00%, val:  76.67%, val_best:  79.58%: 100%|██████████| 62/62 [00:05<00:00, 12.05it/s]\n",
      "epoch-27  lr=['0.0057822'], tr/val_loss:  0.006340/  1.679848, tr: 100.00%, val:  79.17%, val_best:  79.58%: 100%|██████████| 62/62 [00:05<00:00, 11.93it/s]\n",
      "epoch-28  lr=['0.0055226'], tr/val_loss:  0.005018/  1.680013, tr: 100.00%, val:  78.75%, val_best:  79.58%: 100%|██████████| 62/62 [00:05<00:00, 11.89it/s]\n",
      "epoch-29  lr=['0.0052617'], tr/val_loss:  0.003802/  1.694827, tr: 100.00%, val:  79.17%, val_best:  79.58%: 100%|██████████| 62/62 [00:05<00:00, 11.54it/s]\n",
      "epoch-30  lr=['0.0050000'], tr/val_loss:  0.002907/  1.703333, tr: 100.00%, val:  81.25%, val_best:  81.25%: 100%|██████████| 62/62 [00:05<00:00, 11.80it/s]\n",
      "epoch-31  lr=['0.0047383'], tr/val_loss:  0.002519/  1.729841, tr: 100.00%, val:  78.75%, val_best:  81.25%: 100%|██████████| 62/62 [00:05<00:00, 12.07it/s]\n",
      "epoch-32  lr=['0.0044774'], tr/val_loss:  0.002209/  1.736645, tr: 100.00%, val:  78.75%, val_best:  81.25%: 100%|██████████| 62/62 [00:04<00:00, 12.55it/s]\n",
      "epoch-33  lr=['0.0042178'], tr/val_loss:  0.001935/  1.751118, tr: 100.00%, val:  79.17%, val_best:  81.25%: 100%|██████████| 62/62 [00:05<00:00, 12.00it/s]\n",
      "epoch-34  lr=['0.0039604'], tr/val_loss:  0.001773/  1.750302, tr: 100.00%, val:  79.17%, val_best:  81.25%: 100%|██████████| 62/62 [00:05<00:00, 12.10it/s]\n",
      "epoch-35  lr=['0.0037059'], tr/val_loss:  0.001699/  1.749856, tr: 100.00%, val:  79.58%, val_best:  81.25%: 100%|██████████| 62/62 [00:05<00:00, 11.93it/s]\n",
      "epoch-36  lr=['0.0034549'], tr/val_loss:  0.001691/  1.749914, tr: 100.00%, val:  79.17%, val_best:  81.25%: 100%|██████████| 62/62 [00:05<00:00, 11.93it/s]\n",
      "epoch-37  lr=['0.0032082'], tr/val_loss:  0.001527/  1.752845, tr: 100.00%, val:  79.58%, val_best:  81.25%: 100%|██████████| 62/62 [00:05<00:00, 12.08it/s]\n",
      "epoch-38  lr=['0.0029663'], tr/val_loss:  0.001475/  1.751683, tr: 100.00%, val:  80.00%, val_best:  81.25%: 100%|██████████| 62/62 [00:05<00:00, 11.78it/s]\n",
      "epoch-39  lr=['0.0027300'], tr/val_loss:  0.001430/  1.748755, tr: 100.00%, val:  80.42%, val_best:  81.25%: 100%|██████████| 62/62 [00:05<00:00, 11.92it/s]\n",
      "epoch-40  lr=['0.0025000'], tr/val_loss:  0.001395/  1.756461, tr: 100.00%, val:  79.17%, val_best:  81.25%: 100%|██████████| 62/62 [00:05<00:00, 12.05it/s]\n",
      "epoch-41  lr=['0.0022768'], tr/val_loss:  0.001421/  1.770756, tr: 100.00%, val:  79.17%, val_best:  81.25%: 100%|██████████| 62/62 [00:05<00:00, 11.92it/s]\n",
      "epoch-42  lr=['0.0020611'], tr/val_loss:  0.001285/  1.775803, tr: 100.00%, val:  78.75%, val_best:  81.25%: 100%|██████████| 62/62 [00:05<00:00, 11.90it/s]\n",
      "epoch-43  lr=['0.0018534'], tr/val_loss:  0.001299/  1.779238, tr: 100.00%, val:  79.58%, val_best:  81.25%: 100%|██████████| 62/62 [00:05<00:00, 11.92it/s]\n",
      "epoch-44  lr=['0.0016543'], tr/val_loss:  0.001248/  1.772783, tr: 100.00%, val:  79.58%, val_best:  81.25%: 100%|██████████| 62/62 [00:05<00:00, 12.23it/s]\n",
      "epoch-45  lr=['0.0014645'], tr/val_loss:  0.001237/  1.776591, tr: 100.00%, val:  79.17%, val_best:  81.25%: 100%|██████████| 62/62 [00:05<00:00, 12.22it/s]\n",
      "epoch-46  lr=['0.0012843'], tr/val_loss:  0.001219/  1.781229, tr: 100.00%, val:  79.17%, val_best:  81.25%: 100%|██████████| 62/62 [00:05<00:00, 12.35it/s]\n",
      "epoch-47  lr=['0.0011143'], tr/val_loss:  0.001190/  1.784198, tr: 100.00%, val:  78.75%, val_best:  81.25%: 100%|██████████| 62/62 [00:04<00:00, 13.36it/s]\n",
      "epoch-48  lr=['0.0009549'], tr/val_loss:  0.001216/  1.786174, tr: 100.00%, val:  79.17%, val_best:  81.25%: 100%|██████████| 62/62 [00:04<00:00, 12.61it/s]\n",
      "epoch-49  lr=['0.0008066'], tr/val_loss:  0.001191/  1.791145, tr: 100.00%, val:  79.58%, val_best:  81.25%: 100%|██████████| 62/62 [00:05<00:00, 12.39it/s]\n",
      "epoch-50  lr=['0.0006699'], tr/val_loss:  0.001181/  1.792842, tr: 100.00%, val:  79.58%, val_best:  81.25%: 100%|██████████| 62/62 [00:04<00:00, 12.40it/s]\n",
      "epoch-51  lr=['0.0005450'], tr/val_loss:  0.001143/  1.795220, tr: 100.00%, val:  79.58%, val_best:  81.25%: 100%|██████████| 62/62 [00:04<00:00, 12.49it/s]\n",
      "epoch-52  lr=['0.0004323'], tr/val_loss:  0.001164/  1.793511, tr: 100.00%, val:  80.00%, val_best:  81.25%: 100%|██████████| 62/62 [00:05<00:00, 12.08it/s]\n",
      "epoch-53  lr=['0.0003321'], tr/val_loss:  0.001146/  1.795679, tr: 100.00%, val:  79.58%, val_best:  81.25%: 100%|██████████| 62/62 [00:05<00:00, 11.74it/s]\n",
      "epoch-54  lr=['0.0002447'], tr/val_loss:  0.001146/  1.797094, tr: 100.00%, val:  79.58%, val_best:  81.25%: 100%|██████████| 62/62 [00:04<00:00, 12.47it/s]\n",
      "epoch-55  lr=['0.0001704'], tr/val_loss:  0.001140/  1.797256, tr: 100.00%, val:  80.00%, val_best:  81.25%: 100%|██████████| 62/62 [00:05<00:00, 12.01it/s]\n",
      "epoch-56  lr=['0.0001093'], tr/val_loss:  0.001132/  1.797256, tr: 100.00%, val:  80.00%, val_best:  81.25%: 100%|██████████| 62/62 [00:05<00:00, 12.12it/s]\n",
      "epoch-57  lr=['0.0000616'], tr/val_loss:  0.001135/  1.797256, tr: 100.00%, val:  80.00%, val_best:  81.25%: 100%|██████████| 62/62 [00:05<00:00, 12.38it/s]\n",
      "epoch-58  lr=['0.0000274'], tr/val_loss:  0.001122/  1.797276, tr: 100.00%, val:  80.00%, val_best:  81.25%: 100%|██████████| 62/62 [00:05<00:00, 11.81it/s]\n",
      "epoch-59  lr=['0.0000069'], tr/val_loss:  0.001138/  1.797281, tr: 100.00%, val:  80.00%, val_best:  81.25%: 100%|██████████| 62/62 [00:05<00:00, 11.98it/s]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "376631653252426487db935e51da3967",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='3.438 MB of 3.438 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>DFA_flag</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>epoch</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇████</td></tr><tr><td>iter_acc</td><td>▂▃▄▂▆▁▆▆▇▆▆▇▇███████████████████████████</td></tr><tr><td>summary_val_acc</td><td>▁▅▆▆▆▆▇▇▇▇▇▇▇███████████████████████████</td></tr><tr><td>tr_acc</td><td>▁▄▆▆▆▆▆▇▇▇▇█████████████████████████████</td></tr><tr><td>tr_epoch_loss</td><td>▁█▅▅▄▄▄▃▃▃▂▂▂▂▁▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_acc_best</td><td>▁▅▆▆▆▆▇▇▇▇▇▇▇███████████████████████████</td></tr><tr><td>val_acc_now</td><td>▁▅▆▆▆▆▇▇▇▇▇▇▇███████████████████████████</td></tr><tr><td>val_loss</td><td>▁▆▆▆▆▆▅▆▆▆▆▇▆▇▇▇▇▇██████████████████████</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>DFA_flag</td><td>0.0</td></tr><tr><td>epoch</td><td>59</td></tr><tr><td>iter_acc</td><td>1.0</td></tr><tr><td>tr_acc</td><td>1.0</td></tr><tr><td>tr_epoch_loss</td><td>0.00114</td></tr><tr><td>val_acc_best</td><td>0.8125</td></tr><tr><td>val_acc_now</td><td>0.8</td></tr><tr><td>val_loss</td><td>1.79728</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">pious-sweep-57</strong> at: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/913uhrvh' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/913uhrvh</a><br/> View project at: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main</a><br/>Synced 7 W&B file(s), 0 media file(s), 0 artifact file(s) and 1 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20240822_194518-913uhrvh/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require(\"core\")`! See https://wandb.me/wandb-core for more information."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: vqqxmh6i with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBATCH: 16\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tDFA_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tIMAGE_SIZE: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tOTTT_input_trace_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tOTTT_sWS_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tTIME: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcfg: ['M', 'M', 200, 200]\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tconst2: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdecay: 0.25\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdrop_rate: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdvs_clipping: 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdvs_duration: 100000\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \te_transport_swap: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \te_transport_swap_coin: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \te_transport_swap_tr: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepoch_num: 60\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \texclude_class: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.01\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_sg_width: 2.570969004857107\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_reset: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_threshold: 0.6234618070033706\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmerge_polarities: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tscheduler_name: CosineAnnealingLR\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsurrogate: hard_sigmoid\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \twhich_data: DVS_GESTURE_TONIC\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.17.7 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.17.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/nfs/home/bhkim003/github_folder/ByeonghyeonKim/my_snn/wandb/run-20240822_195059-vqqxmh6i</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/vqqxmh6i' target=\"_blank\">earthy-sweep-59</a></strong> to <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/yxynyr6h' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/yxynyr6h</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/yxynyr6h' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/yxynyr6h</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/vqqxmh6i' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/vqqxmh6i</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BATCH' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'IMAGE_SIZE' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'which_data' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_threshold' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_reset' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_sg_width' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'cfg' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'learning_rate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'epoch_num' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'surrogate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'scheduler_name' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'dvs_clipping' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'dvs_duration' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'OTTT_sWS_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'DFA_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'OTTT_input_trace_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'e_transport_swap' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'e_transport_swap_tr' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'e_transport_swap_coin' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'drop_rate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'exclude_class' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'merge_polarities' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'TIME' was locked by 'sweep' (ignored update).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset_hash = 2bbd58b4e0d3c1e9ad501fad8a43feed\n",
      "cache path exists\n",
      "\n",
      "we will exclude the 'other' class. dvsgestrue 10 classes' indices exist. \n",
      "\n",
      "DataParallel(\n",
      "  (module): MY_SNN_FC_sstep(\n",
      "    (layers): MY_Sequential(\n",
      "      (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (2): DimChanger_for_FC_sstep()\n",
      "      (3): SYNAPSE_FC_trace_sstep()\n",
      "      (4): LIF_layer_trace_sstep()\n",
      "      (5): SYNAPSE_FC_trace_sstep()\n",
      "      (6): LIF_layer_trace_sstep()\n",
      "      (7): SYNAPSE_FC_trace_sstep()\n",
      "    )\n",
      "  )\n",
      ")\n",
      "==================================================\n",
      "My Num of PARAMS: 452,010, system's param_num : 452,010\n",
      "Memory: 1.72MiB at 32-bit\n",
      "==================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch-0   lr=['0.0100000'], tr/val_loss:  1.585900/  1.296007, tr:  46.48%, val:  53.33%, val_best:  53.33%: 100%|██████████| 62/62 [00:05<00:00, 12.09it/s]\n",
      "epoch-1   lr=['0.0099931'], tr/val_loss:  1.124131/  1.345087, tr:  58.73%, val:  50.83%, val_best:  53.33%: 100%|██████████| 62/62 [00:04<00:00, 12.40it/s]\n",
      "epoch-2   lr=['0.0099726'], tr/val_loss:  0.994587/  1.269991, tr:  64.86%, val:  62.08%, val_best:  62.08%: 100%|██████████| 62/62 [00:05<00:00, 12.16it/s]\n",
      "epoch-3   lr=['0.0099384'], tr/val_loss:  0.860519/  1.111105, tr:  69.46%, val:  61.25%, val_best:  62.08%: 100%|██████████| 62/62 [00:05<00:00, 11.73it/s]\n",
      "epoch-4   lr=['0.0098907'], tr/val_loss:  0.800412/  1.239920, tr:  70.79%, val:  58.75%, val_best:  62.08%: 100%|██████████| 62/62 [00:05<00:00, 11.92it/s]\n",
      "epoch-5   lr=['0.0098296'], tr/val_loss:  0.773623/  1.300372, tr:  70.48%, val:  62.50%, val_best:  62.50%: 100%|██████████| 62/62 [00:05<00:00, 12.21it/s]\n",
      "epoch-6   lr=['0.0097553'], tr/val_loss:  0.671666/  1.219095, tr:  74.77%, val:  61.25%, val_best:  62.50%: 100%|██████████| 62/62 [00:06<00:00,  9.92it/s]\n",
      "epoch-7   lr=['0.0096679'], tr/val_loss:  0.667289/  1.302055, tr:  75.49%, val:  60.00%, val_best:  62.50%: 100%|██████████| 62/62 [00:15<00:00,  3.92it/s]\n",
      "epoch-8   lr=['0.0095677'], tr/val_loss:  0.632400/  1.217200, tr:  76.10%, val:  64.58%, val_best:  64.58%: 100%|██████████| 62/62 [00:05<00:00, 10.64it/s]\n",
      "epoch-9   lr=['0.0094550'], tr/val_loss:  0.498590/  1.394292, tr:  83.04%, val:  61.67%, val_best:  64.58%: 100%|██████████| 62/62 [00:06<00:00, 10.05it/s]\n",
      "epoch-10  lr=['0.0093301'], tr/val_loss:  0.489132/  1.230533, tr:  84.37%, val:  66.67%, val_best:  66.67%: 100%|██████████| 62/62 [00:06<00:00,  9.82it/s]\n",
      "epoch-11  lr=['0.0091934'], tr/val_loss:  0.434752/  1.305974, tr:  84.27%, val:  68.75%, val_best:  68.75%: 100%|██████████| 62/62 [00:05<00:00, 10.94it/s]\n",
      "epoch-12  lr=['0.0090451'], tr/val_loss:  0.464480/  1.173945, tr:  86.31%, val:  73.75%, val_best:  73.75%: 100%|██████████| 62/62 [00:05<00:00, 11.03it/s]\n",
      "epoch-13  lr=['0.0088857'], tr/val_loss:  0.405900/  1.352050, tr:  86.01%, val:  63.33%, val_best:  73.75%: 100%|██████████| 62/62 [00:06<00:00,  9.89it/s]\n",
      "epoch-14  lr=['0.0087157'], tr/val_loss:  0.331177/  1.234182, tr:  90.70%, val:  73.75%, val_best:  73.75%: 100%|██████████| 62/62 [00:05<00:00, 10.54it/s]\n",
      "epoch-15  lr=['0.0085355'], tr/val_loss:  0.325266/  1.388311, tr:  93.05%, val:  72.92%, val_best:  73.75%: 100%|██████████| 62/62 [00:05<00:00, 10.61it/s]\n",
      "epoch-16  lr=['0.0083457'], tr/val_loss:  0.284097/  1.334642, tr:  93.67%, val:  72.50%, val_best:  73.75%: 100%|██████████| 62/62 [00:05<00:00, 10.56it/s]\n",
      "epoch-17  lr=['0.0081466'], tr/val_loss:  0.256158/  1.399422, tr:  95.71%, val:  72.50%, val_best:  73.75%: 100%|██████████| 62/62 [00:06<00:00, 10.16it/s]\n",
      "epoch-18  lr=['0.0079389'], tr/val_loss:  0.199946/  1.335374, tr:  97.75%, val:  75.83%, val_best:  75.83%: 100%|██████████| 62/62 [00:05<00:00, 10.45it/s]\n",
      "epoch-19  lr=['0.0077232'], tr/val_loss:  0.165979/  1.388747, tr:  98.16%, val:  78.75%, val_best:  78.75%: 100%|██████████| 62/62 [00:05<00:00, 10.46it/s]\n",
      "epoch-20  lr=['0.0075000'], tr/val_loss:  0.125198/  1.426587, tr:  99.39%, val:  75.83%, val_best:  78.75%: 100%|██████████| 62/62 [00:05<00:00, 10.56it/s]\n",
      "epoch-21  lr=['0.0072700'], tr/val_loss:  0.085003/  1.386533, tr:  99.90%, val:  80.42%, val_best:  80.42%: 100%|██████████| 62/62 [00:05<00:00, 10.61it/s]\n",
      "epoch-22  lr=['0.0070337'], tr/val_loss:  0.077557/  1.485902, tr:  99.69%, val:  78.33%, val_best:  80.42%: 100%|██████████| 62/62 [00:06<00:00, 10.05it/s]\n",
      "epoch-23  lr=['0.0067918'], tr/val_loss:  0.048713/  1.476112, tr: 100.00%, val:  79.17%, val_best:  80.42%: 100%|██████████| 62/62 [00:06<00:00,  9.83it/s]\n",
      "epoch-24  lr=['0.0065451'], tr/val_loss:  0.031485/  1.498809, tr: 100.00%, val:  83.33%, val_best:  83.33%: 100%|██████████| 62/62 [00:05<00:00, 10.96it/s]\n",
      "epoch-25  lr=['0.0062941'], tr/val_loss:  0.020344/  1.521682, tr: 100.00%, val:  81.25%, val_best:  83.33%: 100%|██████████| 62/62 [00:05<00:00, 11.04it/s]\n",
      "epoch-26  lr=['0.0060396'], tr/val_loss:  0.010536/  1.497186, tr: 100.00%, val:  81.67%, val_best:  83.33%: 100%|██████████| 62/62 [00:05<00:00, 10.81it/s]\n",
      "epoch-27  lr=['0.0057822'], tr/val_loss:  0.007372/  1.514359, tr: 100.00%, val:  81.25%, val_best:  83.33%: 100%|██████████| 62/62 [00:05<00:00, 11.23it/s]\n",
      "epoch-28  lr=['0.0055226'], tr/val_loss:  0.005527/  1.542991, tr: 100.00%, val:  82.92%, val_best:  83.33%: 100%|██████████| 62/62 [00:05<00:00, 10.42it/s]\n",
      "epoch-29  lr=['0.0052617'], tr/val_loss:  0.004603/  1.559563, tr: 100.00%, val:  81.25%, val_best:  83.33%: 100%|██████████| 62/62 [00:05<00:00, 10.93it/s]\n",
      "epoch-30  lr=['0.0050000'], tr/val_loss:  0.003772/  1.554624, tr: 100.00%, val:  81.25%, val_best:  83.33%: 100%|██████████| 62/62 [00:05<00:00, 11.28it/s]\n",
      "epoch-31  lr=['0.0047383'], tr/val_loss:  0.003363/  1.580129, tr: 100.00%, val:  82.08%, val_best:  83.33%: 100%|██████████| 62/62 [00:06<00:00, 10.02it/s]\n",
      "epoch-32  lr=['0.0044774'], tr/val_loss:  0.002744/  1.586607, tr: 100.00%, val:  82.50%, val_best:  83.33%: 100%|██████████| 62/62 [00:05<00:00, 10.52it/s]\n",
      "epoch-33  lr=['0.0042178'], tr/val_loss:  0.002544/  1.588936, tr: 100.00%, val:  81.67%, val_best:  83.33%: 100%|██████████| 62/62 [00:05<00:00, 10.52it/s]\n",
      "epoch-34  lr=['0.0039604'], tr/val_loss:  0.002498/  1.596318, tr: 100.00%, val:  82.08%, val_best:  83.33%: 100%|██████████| 62/62 [00:06<00:00,  9.79it/s]\n",
      "epoch-35  lr=['0.0037059'], tr/val_loss:  0.002385/  1.609273, tr: 100.00%, val:  81.25%, val_best:  83.33%: 100%|██████████| 62/62 [00:06<00:00, 10.15it/s]\n",
      "epoch-36  lr=['0.0034549'], tr/val_loss:  0.002151/  1.605886, tr: 100.00%, val:  82.50%, val_best:  83.33%: 100%|██████████| 62/62 [00:06<00:00,  9.54it/s]\n",
      "epoch-37  lr=['0.0032082'], tr/val_loss:  0.002055/  1.605156, tr: 100.00%, val:  80.42%, val_best:  83.33%: 100%|██████████| 62/62 [00:06<00:00,  9.27it/s]\n",
      "epoch-38  lr=['0.0029663'], tr/val_loss:  0.001991/  1.618996, tr: 100.00%, val:  81.67%, val_best:  83.33%: 100%|██████████| 62/62 [00:05<00:00, 10.90it/s]\n",
      "epoch-39  lr=['0.0027300'], tr/val_loss:  0.001884/  1.620516, tr: 100.00%, val:  82.08%, val_best:  83.33%: 100%|██████████| 62/62 [00:05<00:00, 10.93it/s]\n",
      "epoch-40  lr=['0.0025000'], tr/val_loss:  0.001828/  1.624648, tr: 100.00%, val:  82.50%, val_best:  83.33%: 100%|██████████| 62/62 [00:05<00:00, 11.06it/s]\n",
      "epoch-41  lr=['0.0022768'], tr/val_loss:  0.001828/  1.629853, tr: 100.00%, val:  81.67%, val_best:  83.33%: 100%|██████████| 62/62 [00:05<00:00, 10.60it/s]\n",
      "epoch-42  lr=['0.0020611'], tr/val_loss:  0.001756/  1.627987, tr: 100.00%, val:  81.67%, val_best:  83.33%: 100%|██████████| 62/62 [00:05<00:00, 10.36it/s]\n",
      "epoch-43  lr=['0.0018534'], tr/val_loss:  0.001712/  1.630715, tr: 100.00%, val:  82.50%, val_best:  83.33%: 100%|██████████| 62/62 [00:05<00:00, 10.84it/s]\n",
      "epoch-44  lr=['0.0016543'], tr/val_loss:  0.001620/  1.627560, tr: 100.00%, val:  82.50%, val_best:  83.33%: 100%|██████████| 62/62 [00:05<00:00, 10.62it/s]\n",
      "epoch-45  lr=['0.0014645'], tr/val_loss:  0.001585/  1.633474, tr: 100.00%, val:  82.08%, val_best:  83.33%: 100%|██████████| 62/62 [00:05<00:00, 12.11it/s]\n",
      "epoch-46  lr=['0.0012843'], tr/val_loss:  0.001568/  1.632805, tr: 100.00%, val:  82.92%, val_best:  83.33%: 100%|██████████| 62/62 [00:05<00:00, 12.10it/s]\n",
      "epoch-47  lr=['0.0011143'], tr/val_loss:  0.001561/  1.633630, tr: 100.00%, val:  82.92%, val_best:  83.33%: 100%|██████████| 62/62 [00:05<00:00, 11.28it/s]\n",
      "epoch-48  lr=['0.0009549'], tr/val_loss:  0.001561/  1.640280, tr: 100.00%, val:  81.25%, val_best:  83.33%: 100%|██████████| 62/62 [00:05<00:00, 11.77it/s]\n",
      "epoch-49  lr=['0.0008066'], tr/val_loss:  0.001509/  1.637672, tr: 100.00%, val:  81.25%, val_best:  83.33%: 100%|██████████| 62/62 [00:07<00:00,  8.69it/s]\n",
      "epoch-50  lr=['0.0006699'], tr/val_loss:  0.001511/  1.637201, tr: 100.00%, val:  81.25%, val_best:  83.33%: 100%|██████████| 62/62 [00:06<00:00,  9.18it/s]\n",
      "epoch-51  lr=['0.0005450'], tr/val_loss:  0.001503/  1.640363, tr: 100.00%, val:  81.25%, val_best:  83.33%: 100%|██████████| 62/62 [00:06<00:00, 10.09it/s]\n",
      "epoch-52  lr=['0.0004323'], tr/val_loss:  0.001493/  1.641707, tr: 100.00%, val:  81.25%, val_best:  83.33%: 100%|██████████| 62/62 [00:06<00:00,  9.70it/s]\n",
      "epoch-53  lr=['0.0003321'], tr/val_loss:  0.001489/  1.641709, tr: 100.00%, val:  81.67%, val_best:  83.33%: 100%|██████████| 62/62 [00:16<00:00,  3.75it/s]\n",
      "epoch-54  lr=['0.0002447'], tr/val_loss:  0.001509/  1.644958, tr: 100.00%, val:  81.67%, val_best:  83.33%: 100%|██████████| 62/62 [00:29<00:00,  2.08it/s]\n",
      "epoch-55  lr=['0.0001704'], tr/val_loss:  0.001451/  1.645873, tr: 100.00%, val:  81.67%, val_best:  83.33%: 100%|██████████| 62/62 [00:17<00:00,  3.60it/s]\n",
      "epoch-56  lr=['0.0001093'], tr/val_loss:  0.001453/  1.646474, tr: 100.00%, val:  81.67%, val_best:  83.33%: 100%|██████████| 62/62 [00:12<00:00,  4.79it/s]\n",
      "epoch-57  lr=['0.0000616'], tr/val_loss:  0.001503/  1.646912, tr: 100.00%, val:  81.67%, val_best:  83.33%: 100%|██████████| 62/62 [00:05<00:00, 10.54it/s]\n",
      "epoch-58  lr=['0.0000274'], tr/val_loss:  0.001448/  1.646632, tr: 100.00%, val:  81.67%, val_best:  83.33%: 100%|██████████| 62/62 [00:05<00:00, 10.52it/s]\n",
      "epoch-59  lr=['0.0000069'], tr/val_loss:  0.001440/  1.646638, tr: 100.00%, val:  81.67%, val_best:  83.33%: 100%|██████████| 62/62 [00:06<00:00,  9.36it/s]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "99519783370e4567bfccf8ff9f192cb4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='3.438 MB of 3.438 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>DFA_flag</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>epoch</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇████</td></tr><tr><td>iter_acc</td><td>▁▂▃▂▅▅▅▆▆▆█▆████████████████████████████</td></tr><tr><td>summary_val_acc</td><td>▁▆▆▆▆▆▆▆▇▇▇▇▇█▇█████████████████████████</td></tr><tr><td>tr_acc</td><td>▁▄▆▆▆▆▆▇▇▇▇█████████████████████████████</td></tr><tr><td>tr_epoch_loss</td><td>▁█▅▅▄▄▄▃▃▃▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_acc_best</td><td>▁▅▆▆▆▆▆▆▇▇▇▇▇███████████████████████████</td></tr><tr><td>val_acc_now</td><td>▁▆▆▆▆▆▆▆▇▇▇▇▇█▇█████████████████████████</td></tr><tr><td>val_loss</td><td>▁▇▆▆▇▆▆▇▇▆▆▇▇▇▇▇▇▇▇█████████████████████</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>DFA_flag</td><td>0.0</td></tr><tr><td>epoch</td><td>59</td></tr><tr><td>iter_acc</td><td>1.0</td></tr><tr><td>tr_acc</td><td>1.0</td></tr><tr><td>tr_epoch_loss</td><td>0.00144</td></tr><tr><td>val_acc_best</td><td>0.83333</td></tr><tr><td>val_acc_now</td><td>0.81667</td></tr><tr><td>val_loss</td><td>1.64664</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">earthy-sweep-59</strong> at: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/vqqxmh6i' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/vqqxmh6i</a><br/> View project at: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main</a><br/>Synced 7 W&B file(s), 0 media file(s), 0 artifact file(s) and 1 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20240822_195059-vqqxmh6i/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require(\"core\")`! See https://wandb.me/wandb-core for more information."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: nvc2tklo with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBATCH: 16\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tDFA_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tIMAGE_SIZE: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tOTTT_input_trace_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tOTTT_sWS_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tTIME: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcfg: ['M', 'M', 200, 200]\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tconst2: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdecay: 0.25\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdrop_rate: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdvs_clipping: 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdvs_duration: 100000\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \te_transport_swap: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \te_transport_swap_coin: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \te_transport_swap_tr: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepoch_num: 60\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \texclude_class: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.01\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_sg_width: 2.570969004857107\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_reset: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_threshold: 0.9801302995430662\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmerge_polarities: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tscheduler_name: CosineAnnealingLR\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsurrogate: hard_sigmoid\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \twhich_data: DVS_GESTURE_TONIC\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.17.7 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.17.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/nfs/home/bhkim003/github_folder/ByeonghyeonKim/my_snn/wandb/run-20240822_195825-nvc2tklo</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/nvc2tklo' target=\"_blank\">resilient-sweep-62</a></strong> to <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/yxynyr6h' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/yxynyr6h</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/yxynyr6h' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/sweeps/yxynyr6h</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/nvc2tklo' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/nvc2tklo</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BATCH' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'IMAGE_SIZE' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'which_data' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_threshold' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_reset' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_sg_width' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'cfg' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'learning_rate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'epoch_num' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'surrogate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'scheduler_name' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'dvs_clipping' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'dvs_duration' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'OTTT_sWS_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'DFA_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'OTTT_input_trace_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'e_transport_swap' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'e_transport_swap_tr' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'e_transport_swap_coin' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'drop_rate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'exclude_class' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'merge_polarities' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'TIME' was locked by 'sweep' (ignored update).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset_hash = 2bbd58b4e0d3c1e9ad501fad8a43feed\n",
      "cache path exists\n",
      "\n",
      "we will exclude the 'other' class. dvsgestrue 10 classes' indices exist. \n",
      "\n",
      "DataParallel(\n",
      "  (module): MY_SNN_FC_sstep(\n",
      "    (layers): MY_Sequential(\n",
      "      (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (2): DimChanger_for_FC_sstep()\n",
      "      (3): SYNAPSE_FC_trace_sstep()\n",
      "      (4): LIF_layer_trace_sstep()\n",
      "      (5): SYNAPSE_FC_trace_sstep()\n",
      "      (6): LIF_layer_trace_sstep()\n",
      "      (7): SYNAPSE_FC_trace_sstep()\n",
      "    )\n",
      "  )\n",
      ")\n",
      "==================================================\n",
      "My Num of PARAMS: 452,010, system's param_num : 452,010\n",
      "Memory: 1.72MiB at 32-bit\n",
      "==================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch-0   lr=['0.0100000'], tr/val_loss:  1.818799/  1.394293, tr:  34.42%, val:  49.17%, val_best:  49.17%: 100%|██████████| 62/62 [00:18<00:00,  3.29it/s]\n",
      "epoch-1   lr=['0.0099931'], tr/val_loss:  1.184430/  1.452350, tr:  58.12%, val:  56.25%, val_best:  56.25%: 100%|██████████| 62/62 [00:17<00:00,  3.46it/s]\n",
      "epoch-2   lr=['0.0099726'], tr/val_loss:  1.052833/  1.277143, tr:  63.94%, val:  60.00%, val_best:  60.00%: 100%|██████████| 62/62 [00:17<00:00,  3.58it/s]\n",
      "epoch-3   lr=['0.0099384'], tr/val_loss:  1.017712/  1.158783, tr:  63.53%, val:  61.25%, val_best:  61.25%: 100%|██████████| 62/62 [00:17<00:00,  3.50it/s]\n",
      "epoch-4   lr=['0.0098907'], tr/val_loss:  0.935259/  1.167035, tr:  68.13%, val:  62.08%, val_best:  62.08%: 100%|██████████| 62/62 [00:16<00:00,  3.69it/s]\n",
      "epoch-5   lr=['0.0098296'], tr/val_loss:  0.848289/  1.261413, tr:  68.34%, val:  58.75%, val_best:  62.08%: 100%|██████████| 62/62 [00:21<00:00,  2.92it/s]\n",
      "epoch-6   lr=['0.0097553'], tr/val_loss:  0.776797/  1.274571, tr:  70.07%, val:  60.42%, val_best:  62.08%: 100%|██████████| 62/62 [00:20<00:00,  3.09it/s]\n",
      "epoch-7   lr=['0.0096679'], tr/val_loss:  0.728645/  1.347090, tr:  73.03%, val:  55.83%, val_best:  62.08%: 100%|██████████| 62/62 [00:16<00:00,  3.72it/s]\n",
      "epoch-8   lr=['0.0095677'], tr/val_loss:  0.723853/  1.234833, tr:  73.03%, val:  63.75%, val_best:  63.75%: 100%|██████████| 62/62 [00:20<00:00,  3.05it/s]\n",
      "epoch-9   lr=['0.0094550'], tr/val_loss:  0.545523/  1.282946, tr:  77.94%, val:  66.67%, val_best:  66.67%: 100%|██████████| 62/62 [00:18<00:00,  3.27it/s]\n",
      "epoch-10  lr=['0.0093301'], tr/val_loss:  0.553857/  1.289669, tr:  79.26%, val:  66.67%, val_best:  66.67%: 100%|██████████| 62/62 [00:20<00:00,  3.05it/s]\n",
      "epoch-11  lr=['0.0091934'], tr/val_loss:  0.498913/  1.267100, tr:  81.00%, val:  63.75%, val_best:  66.67%: 100%|██████████| 62/62 [00:18<00:00,  3.33it/s]\n",
      "epoch-12  lr=['0.0090451'], tr/val_loss:  0.467048/  1.245869, tr:  83.66%, val:  72.92%, val_best:  72.92%: 100%|██████████| 62/62 [00:16<00:00,  3.79it/s]\n",
      "epoch-13  lr=['0.0088857'], tr/val_loss:  0.413328/  1.308568, tr:  84.27%, val:  66.25%, val_best:  72.92%: 100%|██████████| 62/62 [00:14<00:00,  4.24it/s]\n",
      "epoch-14  lr=['0.0087157'], tr/val_loss:  0.377657/  1.242995, tr:  85.70%, val:  70.00%, val_best:  72.92%: 100%|██████████| 62/62 [00:20<00:00,  2.99it/s]\n",
      "epoch-15  lr=['0.0085355'], tr/val_loss:  0.353882/  1.320918, tr:  90.50%, val:  69.17%, val_best:  72.92%: 100%|██████████| 62/62 [00:20<00:00,  3.04it/s]\n",
      "epoch-16  lr=['0.0083457'], tr/val_loss:  0.330770/  1.368807, tr:  90.91%, val:  75.42%, val_best:  75.42%: 100%|██████████| 62/62 [00:18<00:00,  3.35it/s]\n",
      "epoch-17  lr=['0.0081466'], tr/val_loss:  0.321589/  1.242295, tr:  93.26%, val:  71.25%, val_best:  75.42%: 100%|██████████| 62/62 [00:15<00:00,  4.10it/s]\n",
      "epoch-18  lr=['0.0079389'], tr/val_loss:  0.294011/  1.322363, tr:  92.65%, val:  72.92%, val_best:  75.42%: 100%|██████████| 62/62 [00:20<00:00,  3.08it/s]\n",
      "epoch-19  lr=['0.0077232'], tr/val_loss:  0.302600/  1.327281, tr:  94.99%, val:  76.25%, val_best:  76.25%: 100%|██████████| 62/62 [00:14<00:00,  4.31it/s]\n",
      "epoch-20  lr=['0.0075000'], tr/val_loss:  0.228705/  1.389388, tr:  97.24%, val:  75.83%, val_best:  76.25%: 100%|██████████| 62/62 [00:15<00:00,  3.94it/s]\n",
      "epoch-21  lr=['0.0072700'], tr/val_loss:  0.156963/  1.529309, tr:  99.08%, val:  71.67%, val_best:  76.25%: 100%|██████████| 62/62 [00:19<00:00,  3.15it/s]\n",
      "epoch-22  lr=['0.0070337'], tr/val_loss:  0.144774/  1.296562, tr:  97.75%, val:  81.25%, val_best:  81.25%: 100%|██████████| 62/62 [00:18<00:00,  3.43it/s]\n",
      "epoch-23  lr=['0.0067918'], tr/val_loss:  0.147188/  1.403891, tr:  97.55%, val:  76.25%, val_best:  81.25%: 100%|██████████| 62/62 [00:17<00:00,  3.55it/s]\n",
      "epoch-24  lr=['0.0065451'], tr/val_loss:  0.079138/  1.524681, tr: 100.00%, val:  76.25%, val_best:  81.25%: 100%|██████████| 62/62 [00:16<00:00,  3.69it/s]\n",
      "epoch-25  lr=['0.0062941'], tr/val_loss:  0.056584/  1.482784, tr: 100.00%, val:  77.92%, val_best:  81.25%: 100%|██████████| 62/62 [00:18<00:00,  3.37it/s]\n",
      "epoch-26  lr=['0.0060396'], tr/val_loss:  0.032377/  1.486377, tr: 100.00%, val:  80.42%, val_best:  81.25%: 100%|██████████| 62/62 [00:16<00:00,  3.74it/s]\n",
      "epoch-27  lr=['0.0057822'], tr/val_loss:  0.023830/  1.525643, tr: 100.00%, val:  78.75%, val_best:  81.25%: 100%|██████████| 62/62 [00:20<00:00,  3.08it/s]\n",
      "epoch-28  lr=['0.0055226'], tr/val_loss:  0.013668/  1.527866, tr: 100.00%, val:  81.67%, val_best:  81.67%: 100%|██████████| 62/62 [00:18<00:00,  3.36it/s]\n",
      "epoch-29  lr=['0.0052617'], tr/val_loss:  0.009876/  1.547803, tr: 100.00%, val:  80.00%, val_best:  81.67%: 100%|██████████| 62/62 [00:17<00:00,  3.47it/s]\n",
      "epoch-30  lr=['0.0050000'], tr/val_loss:  0.008419/  1.585096, tr: 100.00%, val:  82.08%, val_best:  82.08%: 100%|██████████| 62/62 [00:16<00:00,  3.74it/s]\n",
      "epoch-31  lr=['0.0047383'], tr/val_loss:  0.005663/  1.605282, tr: 100.00%, val:  80.42%, val_best:  82.08%: 100%|██████████| 62/62 [00:16<00:00,  3.87it/s]\n",
      "epoch-32  lr=['0.0044774'], tr/val_loss:  0.004607/  1.595733, tr: 100.00%, val:  80.83%, val_best:  82.08%: 100%|██████████| 62/62 [00:12<00:00,  4.82it/s]\n",
      "epoch-33  lr=['0.0042178'], tr/val_loss:  0.003894/  1.594565, tr: 100.00%, val:  80.83%, val_best:  82.08%: 100%|██████████| 62/62 [00:05<00:00, 11.30it/s]\n",
      "epoch-34  lr=['0.0039604'], tr/val_loss:  0.003371/  1.622274, tr: 100.00%, val:  81.25%, val_best:  82.08%: 100%|██████████| 62/62 [00:06<00:00, 10.32it/s]\n",
      "epoch-35  iter_acc: 100.00%, lr=['0.0037059'], iter_loss:  0.003481, val_best:  82.08%:   8%|▊         | 5/62 [00:00<00:05, 11.20it/s]"
     ]
    }
   ],
   "source": [
    "# sweep 하는 코드, 위 셀 주석처리 해야 됨.\n",
    "\n",
    "# 이런 워닝 뜨는 거는 걍 너가 main 안에서  wandb.config.update(hyperparameters)할 때 물려서임. 어차피 근데 sweep에서 지정한 걸로 덮어짐 \n",
    "# wandb: WARNING Config item 'BATCH' was locked by 'sweep' (ignored update).\n",
    "\n",
    "unique_name_hyper = 'main'\n",
    "run_name = 'main'\n",
    "sweep_configuration = {\n",
    "    'method': 'bayes',\n",
    "    'name': f'my_snn_sweep{datetime.datetime.now().strftime(\"%Y%m%d_%H%M%S\")}',\n",
    "    'metric': {'goal': 'maximize', 'name': 'val_acc_best'},\n",
    "    'parameters': \n",
    "    {\n",
    "        \"learning_rate\": {\"values\": [0.01]}, #0.00936191669529645\n",
    "        \"BATCH\": {\"values\": [16]},\n",
    "        \"decay\": {\"values\": [0.25]},\n",
    "        \"IMAGE_SIZE\": {\"values\": [128]},\n",
    "        \"TIME\": {\"values\": [10]},\n",
    "        \"epoch_num\": {\"values\": [60]},\n",
    "        \"dvs_duration\": {\"values\": [100_000]},\n",
    "        \"dvs_clipping\": {\"values\": [2]},\n",
    "        \"which_data\": {\"values\": ['DVS_GESTURE_TONIC']},\n",
    "        \"OTTT_sWS_on\": {\"values\": [False]},\n",
    "        \"const2\": {\"values\": [False]},\n",
    "        \"surrogate\": {\"values\": ['hard_sigmoid']},\n",
    "        \"DFA_on\": {\"values\": [False]},\n",
    "        \"OTTT_input_trace_on\": {\"values\": [False]},\n",
    "        \"cfg\": {\"values\": [['M','M',200,200]]},\n",
    "        \"e_transport_swap\": {\"values\": [0]},\n",
    "        \"e_transport_swap_tr\": {\"values\": [0]},\n",
    "        \"drop_rate\": {\"values\": [0.0]}, # \"drop_rate\": {\"values\": [0.25,0.5,0.75]}, #\"drop_rate\": {\"min\": 0.25, \"max\": 0.75},\n",
    "        \"exclude_class\": {\"values\": [True]},\n",
    "        \"merge_polarities\": {\"values\": [False]},\n",
    "        \"lif_layer_v_reset\": {\"values\": [0]},\n",
    "        \"lif_layer_sg_width\": {\"values\": [2.570969004857107]},\n",
    "        \"e_transport_swap_coin\": {\"values\": [1]},\n",
    "        \"lif_layer_v_threshold\": {\"min\": 0.0, \"max\": 3.0},\n",
    "        \"scheduler_name\": {\"values\": ['CosineAnnealingLR']},  # 'no' 'StepLR' 'ExponentialLR' 'ReduceLROnPlateau' 'CosineAnnealingLR' 'OneCycleLR'\n",
    "     }\n",
    "}\n",
    "\n",
    "def hyper_iter():\n",
    "    ### my_snn control board ########################\n",
    "    unique_name = unique_name_hyper ## 이거 설정하면 새로운 경로에 모두 save\n",
    "    \n",
    "    wandb.init(save_code = True)\n",
    "    learning_rate  =  wandb.config.learning_rate\n",
    "    BATCH  =  wandb.config.BATCH\n",
    "    decay  =  wandb.config.decay\n",
    "    IMAGE_SIZE  =  wandb.config.IMAGE_SIZE\n",
    "    TIME  =  wandb.config.TIME\n",
    "    epoch_num  =  wandb.config.epoch_num \n",
    "    dvs_duration  =  wandb.config.dvs_duration\n",
    "    dvs_clipping  =  wandb.config.dvs_clipping\n",
    "    which_data  =  wandb.config.which_data\n",
    "    OTTT_sWS_on  =  wandb.config.OTTT_sWS_on\n",
    "    const2  =  wandb.config.const2\n",
    "    surrogate  =  wandb.config.surrogate\n",
    "    DFA_on  =  wandb.config.DFA_on\n",
    "    OTTT_input_trace_on  =  wandb.config.OTTT_input_trace_on\n",
    "    cfg  =  wandb.config.cfg\n",
    "    e_transport_swap  =  wandb.config.e_transport_swap\n",
    "    e_transport_swap_tr  =  wandb.config.e_transport_swap_tr\n",
    "    drop_rate  =  wandb.config.drop_rate\n",
    "    exclude_class  =  wandb.config.exclude_class\n",
    "    merge_polarities  =  wandb.config.merge_polarities\n",
    "    lif_layer_v_reset  =  wandb.config.lif_layer_v_reset\n",
    "    lif_layer_sg_width  =  wandb.config.lif_layer_sg_width\n",
    "    e_transport_swap_coin  =  wandb.config.e_transport_swap_coin\n",
    "    lif_layer_v_threshold  =  wandb.config.lif_layer_v_threshold\n",
    "    scheduler_name  =  wandb.config.scheduler_name\n",
    "    if const2 == True:\n",
    "        const2 = decay\n",
    "    else:\n",
    "        const2 = 0.0\n",
    "\n",
    "    my_snn_system(  devices = \"3\",\n",
    "                single_step = True, # True # False\n",
    "                unique_name = run_name,\n",
    "                my_seed = 42,\n",
    "                TIME = TIME , # dvscifar 10 # ottt 6 or 10 # nda 10  # 제작하는 dvs에서 TIME넘거나 적으면 자르거나 PADDING함\n",
    "                BATCH = BATCH, # batch norm 할거면 2이상으로 해야함   # nda 256   #  ottt 128\n",
    "                IMAGE_SIZE = IMAGE_SIZE, # dvscifar 48 # MNIST 28 # CIFAR10 32 # PMNIST 28 #NMNIST 34 # GESTURE 128\n",
    "                # dvsgesture 128, dvs_cifar2 128, nmnist 34, n_caltech101 180,240, n_tidigits 64, heidelberg 700, \n",
    "                #pmnist는 28로 해야 됨. 나머지는 바꿔도 돌아는 감.\n",
    "\n",
    "                # DVS_CIFAR10 할거면 time 10으로 해라\n",
    "                which_data = which_data,\n",
    "# 'CIFAR100' 'CIFAR10' 'MNIST' 'FASHION_MNIST' 'DVS_CIFAR10' 'PMNIST'아직\n",
    "# 'DVS_GESTURE', 'DVS_GESTURE_TONIC','DVS_CIFAR10_2','NMNIST','NMNIST_TONIC','N_CALTECH101','n_tidigits','heidelberg'\n",
    "                # CLASS_NUM = 10,\n",
    "                data_path = '/data2', # YOU NEED TO CHANGE THIS\n",
    "                rate_coding = False, # True # False\n",
    "                lif_layer_v_init = 0.0,\n",
    "                lif_layer_v_decay = decay,\n",
    "                lif_layer_v_threshold = lif_layer_v_threshold,  # 10000이상으로 하면 NDA LIF 씀. #nda 0.5  #ottt 1.0\n",
    "                lif_layer_v_reset = lif_layer_v_reset, # 10000이상은 hardreset (내 LIF쓰기는 함 ㅇㅇ)\n",
    "                lif_layer_sg_width = lif_layer_sg_width, # # surrogate sigmoid 쓸 때는 의미없음\n",
    "\n",
    "                # synapse_conv_in_channels = IMAGE_PIXEL_CHANNEL,\n",
    "                synapse_conv_kernel_size = 3,\n",
    "                synapse_conv_stride = 1,\n",
    "                synapse_conv_padding = 1,\n",
    "                synapse_conv_trace_const1 = 1, # 현재 trace구할 때 현재 spike에 곱해지는 상수. 걍 1로 두셈.\n",
    "                synapse_conv_trace_const2 = const2, # 현재 trace구할 때 직전 trace에 곱해지는 상수. lif_layer_v_decay와 같게 할 것을 추천\n",
    "\n",
    "                # synapse_fc_out_features = CLASS_NUM,\n",
    "                synapse_fc_trace_const1 = 1, # 현재 trace구할 때 현재 spike에 곱해지는 상수. 걍 1로 두셈.\n",
    "                synapse_fc_trace_const2 = const2, # 현재 trace구할 때 직전 trace에 곱해지는 상수. lif_layer_v_decay와 같게 할 것을 추천\n",
    "\n",
    "                pre_trained = False, # True # False\n",
    "                convTrue_fcFalse = False, # True # False\n",
    "\n",
    "                # 'P' for average pooling, 'D' for (1,1) aver pooling, 'M' for maxpooling, 'L' for linear classifier, [  ] for residual block\n",
    "                # conv에서 10000 이상은 depth-wise separable (BPTT만 지원), 20000이상은 depth-wise (BPTT만 지원)\n",
    "                # cfg = [64, 64],\n",
    "                # cfg = [64, 124, 64, 124],\n",
    "                # cfg = ['M','M',512], \n",
    "                # cfg = [512], \n",
    "                # cfg = ['M', 'M', 64, 128, 'P', 128, 'P'], \n",
    "                # cfg = ['M','M',200,200],\n",
    "                # cfg = [200,200],\n",
    "                cfg = cfg,\n",
    "                # cfg = [12], #fc\n",
    "                # cfg = [12, 'M', 48, 'M', 12], \n",
    "                # cfg = [64,[64,64],64], # 끝에 linear classifier 하나 자동으로 붙습니다\n",
    "                # cfg = [64, 128, 'P', 256, 256, 'P', 512, 512, 'P', 512, 512, 'D'], #ottt\n",
    "                # cfg = [64, 128, 'P', 256, 256, 'P', 512, 512, 'P', 512, 512], \n",
    "                # cfg = [64, 128, 'M', 256, 256, 'M', 512, 512, 'M', 512, 512], \n",
    "                # cfg = [64, 'P', 128, 'P', 256, 256, 'P', 512, 512, 512, 512, 'D'], # nda\n",
    "                # cfg = [64, 'P', 128, 'P', 256, 256, 'P', 512, 512, 512, 512], # nda 128pixel\n",
    "                # cfg = [64, 'P', 128, 'P', 256, 256, 'P', 512, 512, 512, 512, 'L', 4096, 4096],\n",
    "                # cfg = [20001,10001], # depthwise, separable\n",
    "                # cfg = [64,20064,10001], # vanilla conv, depthwise, separable\n",
    "                # cfg = [8, 'P', 8, 'P', 8, 'P', 8,'P', 8, 'P'],\n",
    "                # cfg = [], \n",
    "                \n",
    "                net_print = True, # True # False # True로 하길 추천\n",
    "                weight_count_print = False, # True # False\n",
    "                \n",
    "                pre_trained_path = f\"net_save/save_now_net_weights_{unique_name}.pth\",\n",
    "                learning_rate = learning_rate, # default 0.001  # ottt 0.1 # nda 0.001 \n",
    "                epoch_num = epoch_num,\n",
    "                verbose_interval = 999999999, #숫자 크게 하면 꺼짐 #걍 중간중간 iter에서 끊어서 출력\n",
    "                validation_interval =  999999999,#999999999, #숫자 크게 하면 에포크 마지막 iter 때 val 함\n",
    "\n",
    "                tdBN_on = False,  # True # False\n",
    "                BN_on = False,  # True # False\n",
    "                \n",
    "                surrogate = surrogate, # 'rectangle' 'sigmoid' 'rough_rectangle'\n",
    "                \n",
    "                gradient_verbose = False,  # True # False  # weight gradient 각 layer마다 띄워줌\n",
    "\n",
    "                BPTT_on = False,  # True # False # True이면 BPTT, False이면 OTTT  # depthwise, separable은 BPTT만 가능\n",
    "                optimizer_what = 'SGD', # 'SGD' 'Adam', 'RMSprop'\n",
    "                scheduler_name = scheduler_name, # 'no' 'StepLR' 'ExponentialLR' 'ReduceLROnPlateau' 'CosineAnnealingLR' 'OneCycleLR'\n",
    "                \n",
    "                ddp_on = False,   # True # False \n",
    "                # 지원 DATASET: cifar10, mnist\n",
    "\n",
    "                nda_net = False,   # True # False\n",
    "\n",
    "                domain_il_epoch = 0, # over 0, then domain il mode on # pmnist 쓸거면 HLOP 코드보고 더 디벨롭하셈. 지금 개발 hold함.\n",
    "                \n",
    "                dvs_clipping = dvs_clipping, # 숫자만큼 크면 spike 아니면 걍 0\n",
    "                # gesture, cifar-dvs2, nmnist, ncaltech101\n",
    "\n",
    "                dvs_duration = dvs_duration, # 0 아니면 time sampling # dvs number sampling OR time sampling # gesture, cifar-dvs2, nmnist, ncaltech101\n",
    "                # 있는 데이터들 #gesture 100_000 25_000 10_000 1_000 1_000_000 #nmnist 10000 #nmnist_tonic 10_000 25_000\n",
    "                # 한 숫자가 1us인듯 (spikingjelly코드에서)\n",
    "                # 한 장에 50 timestep만 생산함. 싫으면 my_snn/trying/spikingjelly_dvsgesture의__init__.py 를 참고해봐\n",
    "\n",
    "                OTTT_sWS_on = OTTT_sWS_on, # True # False # BPTT끄고, CONV에만 적용됨.\n",
    "\n",
    "                DFA_on = DFA_on, # True # False # residual은 dfa지원안함.\n",
    "                OTTT_input_trace_on = OTTT_input_trace_on, # True # False # 맨 처음 input에 trace 적용\n",
    "                 \n",
    "                e_transport_swap = e_transport_swap, # 1 이상이면 해당 숫자 에포크만큼 val_acc_best가 변화가 없으면 e_transport scheme (BP vs DFA) swap\n",
    "                e_transport_swap_tr = e_transport_swap_tr, # 1 이상이면 해당 숫자 에포크만큼 tr_acc_best가 변화가 없으면 e_transport scheme (BP vs DFA) swap\n",
    "                e_transport_swap_coin = e_transport_swap_coin, # swap할 수 있는 coin 개수\n",
    "                    \n",
    "                drop_rate = drop_rate,\n",
    "\n",
    "                exclude_class = exclude_class, # True # False # gesture에서 10번째 클래스 제외\n",
    "\n",
    "                merge_polarities = merge_polarities, # True # False # tonic dvs dataset 에서 polarities 합치기\n",
    "                    ) \n",
    "    # sigmoid와 BN이 있어야 잘된다.\n",
    "    # average pooling\n",
    "    # 이 낫다. \n",
    "    \n",
    "    # nda에서는 decay = 0.25, threshold = 0.5, width =1, surrogate = rectangle, batch = 256, tdBN = True\n",
    "    ## OTTT 에서는 decay = 0.5, threshold = 1.0, surrogate = sigmoid, batch = 128, BN = True\n",
    "\n",
    "sweep_id = 'yxynyr6h'\n",
    "wandb.agent(sweep_id, function=hyper_iter, count=10000, project=f'my_snn {unique_name_hyper}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "# import matplotlib.pyplot as plt\n",
    "# import json\n",
    "# run_name = 'main_FINAL_TEST'\n",
    "\n",
    "# unique_name = run_name\n",
    "# def pad_array_to_match_length(array1, array2):\n",
    "#     if len(array1) > len(array2):\n",
    "#         padded_array2 = np.pad(array2, (0, len(array1) - len(array2)), 'constant')\n",
    "#         return array1, padded_array2\n",
    "#     elif len(array2) > len(array1):\n",
    "#         padded_array1 = np.pad(array1, (0, len(array2) - len(array1)), 'constant')\n",
    "#         return padded_array1, array2\n",
    "#     else:\n",
    "#         return array1, array2\n",
    "# def load_hyperparameters(filename=f'result_save/hyperparameters_{unique_name}.json'):\n",
    "#     with open(filename, 'r') as f:\n",
    "#         return json.load(f)\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# current_time = '20240628_110116'\n",
    "# base_name = f'{current_time}'\n",
    "# iter_acc_file_name = f'result_save/{base_name}_iter_acc_array_{unique_name}.npy'\n",
    "# val_acc_file_name = f'result_save/{base_name}_val_acc_now_array_{unique_name}.npy'\n",
    "# hyperparameters_file_name = f'result_save/{base_name}_hyperparameters_{unique_name}.json'\n",
    "\n",
    "# ### if you want to just see most recent train and val acc###########################\n",
    "# iter_acc_file_name = f'result_save/iter_acc_array_{unique_name}.npy'\n",
    "# tr_acc_file_name = f'result_save/tr_acc_array_{unique_name}.npy'\n",
    "# val_acc_file_name = f'result_save/val_acc_now_array_{unique_name}.npy'\n",
    "# hyperparameters_file_name = f'result_save/hyperparameters_{unique_name}.json'\n",
    "\n",
    "# loaded_iter_acc_array = np.load(iter_acc_file_name)*100\n",
    "# loaded_tr_acc_array = np.load(tr_acc_file_name)*100\n",
    "# loaded_val_acc_array = np.load(val_acc_file_name)*100\n",
    "# hyperparameters = load_hyperparameters(hyperparameters_file_name)\n",
    "\n",
    "# loaded_iter_acc_array, loaded_val_acc_array = pad_array_to_match_length(loaded_iter_acc_array, loaded_val_acc_array)\n",
    "# loaded_iter_acc_array, loaded_tr_acc_array = pad_array_to_match_length(loaded_iter_acc_array, loaded_tr_acc_array)\n",
    "# loaded_val_acc_array, loaded_tr_acc_array = pad_array_to_match_length(loaded_val_acc_array, loaded_tr_acc_array)\n",
    "\n",
    "# top_iter_acc = np.max(loaded_iter_acc_array)\n",
    "# top_tr_acc = np.max(loaded_tr_acc_array)\n",
    "# top_val_acc = np.max(loaded_val_acc_array)\n",
    "\n",
    "# which_data = hyperparameters['which_data']\n",
    "# BPTT_on = hyperparameters['BPTT_on']\n",
    "# current_epoch = hyperparameters['current epoch']\n",
    "# surrogate = hyperparameters['surrogate']\n",
    "# cfg = hyperparameters['cfg']\n",
    "# tdBN_on = hyperparameters['tdBN_on']\n",
    "# BN_on = hyperparameters['BN_on']\n",
    "\n",
    "\n",
    "# iterations = np.arange(len(loaded_iter_acc_array))\n",
    "\n",
    "# # 그래프 그리기\n",
    "# plt.figure(figsize=(10, 5))\n",
    "# plt.plot(iterations, loaded_iter_acc_array, label='Iter Accuracy', color='g', alpha=0.2)\n",
    "# plt.plot(iterations, loaded_tr_acc_array, label='Training Accuracy', color='b')\n",
    "# plt.plot(iterations, loaded_val_acc_array, label='Validation Accuracy', color='r')\n",
    "\n",
    "# # # 텍스트 추가\n",
    "# # plt.text(0.05, 0.95, f'Top Training Accuracy: {100*top_iter_acc:.2f}%', transform=plt.gca().transAxes, fontsize=12, verticalalignment='top', horizontalalignment='left', color='blue')\n",
    "# # plt.text(0.05, 0.90, f'Top Validation Accuracy: {100*top_val_acc:.2f}%', transform=plt.gca().transAxes, fontsize=12, verticalalignment='top', horizontalalignment='left', color='red')\n",
    "# # 텍스트 추가\n",
    "# plt.text(0.5, 0.10, f'Top Training Accuracy: {top_tr_acc:.2f}%', transform=plt.gca().transAxes, fontsize=12, verticalalignment='top', horizontalalignment='center', color='blue')\n",
    "# plt.text(0.5, 0.05, f'Top Validation Accuracy: {top_val_acc:.2f}%', transform=plt.gca().transAxes, fontsize=12, verticalalignment='top', horizontalalignment='center', color='red')\n",
    "\n",
    "# plt.xlabel('Iterations')\n",
    "# plt.ylabel('Accuracy [%]')\n",
    "\n",
    "# # 그래프 제목에 하이퍼파라미터 정보 추가\n",
    "# title = f'Training and Validation Accuracy over Iterations\\n\\nData: {which_data}, BPTT: {\"On\" if BPTT_on else \"Off\"}, Current Epoch: {current_epoch}, Surrogate: {surrogate},\\nCFG: {cfg}, tdBN: {\"On\" if tdBN_on else \"Off\"}, BN: {\"On\" if BN_on else \"Off\"}'\n",
    "\n",
    "# plt.title(title)\n",
    "\n",
    "# plt.legend(loc='lower right')\n",
    "# plt.xlim(0)  # x축을 0부터 시작\n",
    "# plt.grid(True)\n",
    "# plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nfs",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
