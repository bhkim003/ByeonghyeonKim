{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ssp.train.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x600 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import torch   \n",
    "import torch.nn as nn \n",
    "import torch.nn.functional as F   \n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import torch.optim as optim\n",
    "from scipy import io\n",
    "import itertools\n",
    "import math\n",
    "import datetime\n",
    "import wandb\n",
    "import pickle\n",
    "import json\n",
    "import time\n",
    "\n",
    "# my module import\n",
    "from modules import *\n",
    "\n",
    "# modules 폴더에 새모듈.py 만들면\n",
    "# modules/__init__py 파일에 form .새모듈 import * 하셈\n",
    "# 그리고 새모듈.py에서 from modules.새모듈 import * 하셈"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cluster_train_system( \n",
    "    gpu = 3,\n",
    "    Conv_net = True,\n",
    "    SAE_net = True,\n",
    "\n",
    "    # hyperparameter\n",
    "    dataset_num = 16,\n",
    "    spike_length = 50,\n",
    "    num_cluster = 4,  # 클러스터 수 설정 # 논문엔 4개라는데 여기서는 3개로 했네\n",
    "    training_cycle = 2400, # 그 초기 몇개까지만 cluster update할지\n",
    "\n",
    "\n",
    "    batch_size = 32,\n",
    "    max_epoch = 7000,\n",
    "    learning_rate = 0.001,\n",
    "    normalize_on = False, # True or False #이거 안 씀 # 이거 별로 안 좋은 normalize같음 # 쓸 거면 다른 거 써라.\n",
    "    need_bias = False,\n",
    "    # first_layer_no_train = False\n",
    "    lif_add_at_first = False,\n",
    "    my_seed = 42,\n",
    "\n",
    "    TIME = 10, # SAE일 때만 유효\n",
    "    v_decay = 0.5,\n",
    "    v_threshold = 0.5,\n",
    "    v_reset = 10000.0, # 10000이상 일 시 hard reset\n",
    "    BPTT_on = True,\n",
    "\n",
    "    SAE_hidden_nomean = True,\n",
    "    current_time = '20250101_210938_786',\n",
    "\n",
    "    optimizer = 'Adam',\n",
    "    coarse_com_mode = True,\n",
    "    coarse_com_config = (2.0, -2.0), # (max, min)\n",
    "\n",
    "    sae_l2_norm_bridge = True,\n",
    "    sae_lif_bridge = False,\n",
    "\n",
    "    accuracy_check_epoch_term = 5,\n",
    "    \n",
    "    lif_add_at_last = False,\n",
    "\n",
    "    two_channel_input = False,\n",
    "    ):\n",
    "    if coarse_com_mode == True:\n",
    "        assert coarse_com_config[0] > coarse_com_config[1], 'coarse_com_config[0] > coarse_com_config[1]이어야 함'\n",
    "        assert SAE_net == True, 'coarse_com_mode는 SAE_net이 True일 때만 가능'\n",
    "\n",
    "    if two_channel_input == True:\n",
    "        assert Conv_net and coarse_com_mode, 'two_channel_input는 Conv_net이 True일 때만 가능'\n",
    "\n",
    "    seed_assign(my_seed)\n",
    "    ## 함수 내 모든 로컬 변수 저장 ########################################################\n",
    "    hyperparameters = locals()\n",
    "    print(hyperparameters)\n",
    "    # JSON으로 저장\n",
    "    with open(f\"result_save/cluster_accuracy_history_{current_time}.json\", 'w') as f:\n",
    "        json.dump(hyperparameters, f, indent=4)\n",
    "    ######################################################################################\n",
    "\n",
    "    \n",
    "    wandb.config.update(hyperparameters)\n",
    "    wandb.run.name = f'{current_time}_SAE_net_{SAE_net}_v_threshold_{v_threshold}'\n",
    "    wandb.define_metric(\"best_mean_cluster_accuracy_post_training_cycle_all_dataset2\", summary=\"max\")\n",
    "\n",
    "\n",
    "    my_path_ground_BH = '/data2/spike_sorting/quiroga/BH/'\n",
    "\n",
    "\n",
    "    filename = [\"C_Easy1_noise005.mat\", \"C_Easy1_noise01.mat\", \"C_Easy1_noise015.mat\", \"C_Easy1_noise02.mat\",\n",
    "                \"C_Easy2_noise005.mat\", \"C_Easy2_noise01.mat\", \"C_Easy2_noise015.mat\", \"C_Easy2_noise02.mat\",\n",
    "                \"C_Difficult1_noise005.mat\", \"C_Difficult1_noise01.mat\", \"C_Difficult1_noise015.mat\", \"C_Difficult1_noise02.mat\",\n",
    "                \"C_Difficult2_noise005.mat\", \"C_Difficult2_noise01.mat\", \"C_Difficult2_noise015.mat\", \"C_Difficult2_noise02.mat\"]\n",
    "\n",
    "\n",
    "    spike_tot = [\"BH_Spike_e1n005.npy\", \"BH_Spike_e1n010.npy\", \"BH_Spike_e1n015.npy\", \"BH_Spike_e1n020.npy\",\n",
    "                \"BH_Spike_e2n005.npy\", \"BH_Spike_e2n010.npy\", \"BH_Spike_e2n015.npy\", \"BH_Spike_e2n020.npy\",\n",
    "                \"BH_Spike_d1n005.npy\", \"BH_Spike_d1n010.npy\", \"BH_Spike_d1n015.npy\", \"BH_Spike_d1n020.npy\",\n",
    "                \"BH_Spike_d2n005.npy\", \"BH_Spike_d2n010.npy\", \"BH_Spike_d2n015.npy\", \"BH_Spike_d2n020.npy\"]\n",
    "\n",
    "    label_tot = [\"BH_Label_e1n005.npy\", \"BH_Label_e1n010.npy\", \"BH_Label_e1n015.npy\", \"BH_Label_e1n020.npy\",\n",
    "                \"BH_Label_e2n005.npy\", \"BH_Label_e2n010.npy\", \"BH_Label_e2n015.npy\", \"BH_Label_e2n020.npy\",\n",
    "                \"BH_Label_d1n005.npy\", \"BH_Label_d1n010.npy\", \"BH_Label_d1n015.npy\", \"BH_Label_d1n020.npy\",\n",
    "                \"BH_Label_d2n005.npy\", \"BH_Label_d2n010.npy\", \"BH_Label_d2n015.npy\", \"BH_Label_d2n020.npy\"]\n",
    "\n",
    "    template =  [\"BH_Spike_TEMPLATE_e1n005.npy\", \"BH_Spike_TEMPLATE_e1n010.npy\", \"BH_Spike_TEMPLATE_e1n015.npy\", \"BH_Spike_TEMPLATE_e1n020.npy\",\n",
    "                \"BH_Spike_TEMPLATE_e2n005.npy\", \"BH_Spike_TEMPLATE_e2n010.npy\", \"BH_Spike_TEMPLATE_e2n015.npy\", \"BH_Spike_TEMPLATE_e2n020.npy\",\n",
    "                \"BH_Spike_TEMPLATE_d1n005.npy\", \"BH_Spike_TEMPLATE_d1n010.npy\", \"BH_Spike_TEMPLATE_d1n015.npy\", \"BH_Spike_TEMPLATE_d1n020.npy\",\n",
    "                \"BH_Spike_TEMPLATE_d2n005.npy\", \"BH_Spike_TEMPLATE_d2n010.npy\", \"BH_Spike_TEMPLATE_d2n015.npy\", \"BH_Spike_TEMPLATE_d2n020.npy\"]\n",
    "\n",
    "    AE_train_path_gt_detect = 'BH_quiroga_training_dataset_gt_detect.pt' \n",
    "    AE_test_path_gt_detect = 'BH_quiroga_test_dataset_gt_detect.pt'\n",
    "\n",
    "    AE_train_path_real_detect = 'BH_quiroga_training_dataset_real_detect.pt'\n",
    "    AE_test_path_real_detect = 'BH_quiroga_test_dataset_real_detect.pt'\n",
    "\n",
    "    AE_train_data = AE_train_path_real_detect #AE_train_path_gt_detect #AE_train_path_real_detect\n",
    "    AE_test_data = AE_test_path_real_detect #AE_test_path_gt_detect  #AE_test_path_real_detect\n",
    "\n",
    "    # thr_tot = np.array([0.5, 0.5, 0.55, 0.7, 0.5, 0.5, 0.55, 0.7, 0.5, 0.5, 0.55, 0.7, 0.5, 0.5, 0.55, 0.7])\n",
    "    cos_thr = np.array([0.95, 0.95, 0.95, 0.95, 0.95, 0.95, 0.95, 0.85, 0.95, 0.9, 0.8, 0.95, 0.95, 0.95, 0.95, 0.8])\n",
    "    # tem_cos_thr = 0.8\n",
    "    # cos_thr = np.array([tem_cos_thr, tem_cos_thr, tem_cos_thr, tem_cos_thr, tem_cos_thr, tem_cos_thr, tem_cos_thr, tem_cos_thr, tem_cos_thr, tem_cos_thr, tem_cos_thr, tem_cos_thr, tem_cos_thr, tem_cos_thr, tem_cos_thr, tem_cos_thr])\n",
    "\n",
    "\n",
    "    os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\" \n",
    "    os.environ[\"CUDA_VISIBLE_DEVICES\"]= f'{gpu}'\n",
    "\n",
    "\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "\n",
    "    if coarse_com_mode == True:\n",
    "        level_num = TIME\n",
    "        TIME = spike_length\n",
    "        spike_length = level_num\n",
    "        level_interval = (coarse_com_config[0] - coarse_com_config[1]) / (level_num-1)  # max - min\n",
    "        levels = [coarse_com_config[1] + level_interval * i for i in range(level_num)]\n",
    "        levels = torch.tensor(levels).to(torch.float).to(device)\n",
    "        levels = levels.repeat(TIME,1) \n",
    "        # print('levels', levels, levels.shape) # TIME, level_num\n",
    "\n",
    "    n_sample = spike_length\n",
    "\n",
    "    class spikedataset(Dataset):\n",
    "        def __init__(self, path, transform = None):    \n",
    "            self.transform = transform\n",
    "            self.spike = torch.load(path)\n",
    "            \n",
    "        def __getitem__(self, index):\n",
    "            spike = self.spike[index]            \n",
    "            if self.transform is not None:\n",
    "                spike = self.transform(spike)\n",
    "            return spike\n",
    "        \n",
    "        def __len__(self):\n",
    "            return len(self.spike)\n",
    "\n",
    "    train_dataset = spikedataset(my_path_ground_BH + AE_train_data)\n",
    "    train_loader = DataLoader(dataset = train_dataset, batch_size = batch_size, shuffle = True)\n",
    "\n",
    "    test_dataset = spikedataset(my_path_ground_BH + AE_test_data)\n",
    "    test_loader = DataLoader(dataset = test_dataset, batch_size = batch_size, shuffle = False)\n",
    "\n",
    "\n",
    "\n",
    "    # 모델 초기화\n",
    "    if SAE_net == False:\n",
    "        if Conv_net == True:\n",
    "            input_channels = 2 if two_channel_input else 1\n",
    "            net = Autoencoder_conv1(input_channels=input_channels, input_length=n_sample, encoder_ch = [32, 64, 96], fc_dim = 4, padding = 0, stride = 2, kernel_size = 3, need_bias=need_bias)\n",
    "            net = torch.nn.DataParallel(net)\n",
    "        else:\n",
    "            net = Autoencoder_only_FC(encoder_ch=[96, 64, 32, 4], decoder_ch=[32,64,96,n_sample], n_sample=n_sample, need_bias=need_bias)\n",
    "            net = torch.nn.DataParallel(net)\n",
    "    else:\n",
    "        if Conv_net == True: \n",
    "            input_channels = 2 if two_channel_input else 1\n",
    "            net = SAE_conv1(input_channels=input_channels, input_length=n_sample, encoder_ch = [32, 64, 96], fc_dim = 4, padding = 0, stride = 2, kernel_size = 3, \n",
    "                                synapse_fc_trace_const1=1, \n",
    "                                synapse_fc_trace_const2=v_decay, #안씀 \n",
    "                                TIME=TIME, v_init=0.0, v_decay=v_decay, v_threshold=v_threshold, v_reset=v_reset, \n",
    "                                sg_width=4.0, surrogate='sigmoid', BPTT_on=BPTT_on, need_bias=need_bias, lif_add_at_first=lif_add_at_first,\n",
    "                                sae_l2_norm_bridge = sae_l2_norm_bridge, sae_lif_bridge = sae_lif_bridge, lif_add_at_last=lif_add_at_last)\n",
    "            net = torch.nn.DataParallel(net)\n",
    "        else:\n",
    "            net = SAE_fc_only(encoder_ch=[96, 64, 32, 4], \n",
    "                                decoder_ch=[32,64,96,n_sample], \n",
    "                                in_channels=n_sample, # in_channel 이 여기선 걍 lenght.\n",
    "                                synapse_fc_trace_const1=1,\n",
    "                                synapse_fc_trace_const2=v_decay,  #안씀 \n",
    "                                TIME=TIME, v_init=0.0, v_decay=v_decay, v_threshold=v_threshold, v_reset=v_reset, \n",
    "                                sg_width=4.0, surrogate='sigmoid', BPTT_on=BPTT_on, need_bias=need_bias, lif_add_at_first=lif_add_at_first,\n",
    "                                sae_l2_norm_bridge = sae_l2_norm_bridge, sae_lif_bridge = sae_lif_bridge, lif_add_at_last=lif_add_at_last)\n",
    "            net = torch.nn.DataParallel(net)\n",
    "\n",
    "    # net = torch.load('/home/bhkim003/github_folder/ByeonghyeonKim/my_snn/net_save/save_now_net_AE_re_e7000.pth')\n",
    "    # net = torch.load('/home/bhkim003/github_folder/ByeonghyeonKim/my_snn/net_save/save_now_net_20250101_210938_786.pth')\n",
    "    # load했으면 torch.nn.DataParallel 하지마\n",
    "    # net.module.load_state_dict(torch.load('/home/bhkim003/github_folder/ByeonghyeonKim/my_snn/net_save/save_now_net_20250108_131059_668.pth'))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    wandb.watch(net, log=\"all\", log_freq = 10)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    if SAE_net == True:\n",
    "        assert 'SAE' in net.module.__class__.__name__\n",
    "\n",
    "\n",
    "\n",
    "    net = net.to(device)\n",
    "    print(net)\n",
    "    print('Device:',device)\n",
    "\n",
    "    \n",
    "    if optimizer == 'Adam':\n",
    "        optimizer = optim.Adam(net.parameters(), lr=learning_rate)\n",
    "    elif optimizer == 'SGD':\n",
    "        optimizer = optim.SGD(net.parameters(), lr = learning_rate, momentum = 0.9)\n",
    "    else:\n",
    "        assert False, 'optimizer를 잘못 입력했습니다.'\n",
    "        \n",
    "    loss_history = []\n",
    "    mean_cluster_accuracy_during_training_cycle_all_dataset_history = []\n",
    "    mean_cluster_accuracy_post_training_cycle_all_dataset_history = []\n",
    "    mean_cluster_accuracy_total_all_dataset_history = []\n",
    "\n",
    "    tau = np.zeros(num_cluster)\n",
    "\n",
    "    print(f\"\\nStart Training, current_time = {current_time}\")\n",
    "    mean_cluster_accuracy_post_training_cycle_all_dataset = 0\n",
    "    best_mean_cluster_accuracy_post_training_cycle_all_dataset = 0\n",
    "\n",
    "    if SAE_net == True:\n",
    "        assert 'SAE' in net.module.__class__.__name__\n",
    "    \n",
    "    for epoch in range(max_epoch):\n",
    "\n",
    "        ae_train_start_time = time.time()\n",
    "        running_loss = 0.0\n",
    "        iter = 0\n",
    "        net.train()\n",
    "        for data in train_loader:\n",
    "            optimizer.zero_grad()\n",
    "            spike_backup = data\n",
    "            spike = data\n",
    "            spike = spike.to(device) # batch, feature\n",
    "            if coarse_com_mode == True and 'SAE' in net.module.__class__.__name__:\n",
    "                spike = spike.unsqueeze(2).repeat(1, 1, level_num) # spike_length == level_num # (batch, time, feature)로 변환 \n",
    "                spike = (spike > levels).to(torch.float) \n",
    "                # spike: batch, time, level_num\n",
    "                # levels: time, level_num\n",
    "                if Conv_net == True:\n",
    "                    spike = spike.unsqueeze(-2) # batch, time, in_channel, feature or batch in_channel,feature\n",
    "                    if two_channel_input == True:\n",
    "                        spike_backup = spike_backup.to(device)\n",
    "                        spike_backup = spike_backup.unsqueeze(2).repeat(1, 1, level_num) # spike_length == level_num # (batch, time, feature)로 변환 \n",
    "                        spike_backup = (spike_backup <= levels).to(torch.float) \n",
    "                        spike_backup = spike_backup.unsqueeze(-2)\n",
    "                        spike = torch.cat((spike, spike_backup), dim=-2)\n",
    "                assert spike.shape[0] == batch_size and spike.shape[1] == TIME\n",
    "            elif 'SAE' in net.module.__class__.__name__:\n",
    "                spike = spike.unsqueeze(-1).repeat(1, 1, TIME).permute(0,2,1) # (batch, time, feature)로 변환\n",
    "                if Conv_net == True:\n",
    "                    spike = spike.unsqueeze(-2) # batch, time, in_channel, feature or batch in_channel,feature\n",
    "            else:\n",
    "                if Conv_net == True:\n",
    "                    spike = spike.unsqueeze(-2) #batch in_channel,feature\n",
    "\n",
    "            spike_class = net(spike) # batch, time, feature\n",
    "\n",
    "            if coarse_com_mode == True and 'SAE' in net.module.__class__.__name__:\n",
    "                # loss1 = nn.MSELoss()(spike_class[..., 5:25], spike[..., 5:25])\n",
    "                # loss2 = nn.MSELoss()(spike_class[..., 0:5], spike[..., 0:5])\n",
    "                # loss3 = nn.MSELoss()(spike_class[..., 25:spike_length], spike[..., 25:spike_length])\n",
    "                # loss = loss1 * 2.125 + (loss2 + loss3)/4\n",
    "\n",
    "                # loss1 = nn.MSELoss()(spike_class[..., 5:25, :], spike[..., 5:25, :])\n",
    "                # loss2 = nn.MSELoss()(spike_class[..., 0:5, :], spike[..., 0:5, :])\n",
    "                # loss3 = nn.MSELoss()(spike_class[..., 25:spike_length, :], spike[..., 25:spike_length, :])\n",
    "                # loss = loss1 * 2.125 + (loss2 + loss3)/4\n",
    "\n",
    "                loss = nn.MSELoss()(spike_class, spike)\n",
    "            elif 'SAE' in net.module.__class__.__name__:\n",
    "                loss1 = nn.MSELoss()(spike_class[..., 5:25], spike[..., 5:25])\n",
    "                loss2 = nn.MSELoss()(spike_class[..., 0:5], spike[..., 0:5])\n",
    "                loss3 = nn.MSELoss()(spike_class[..., 25:spike_length], spike[..., 25:spike_length])\n",
    "                loss = loss1 * 2.125 + (loss2 + loss3)/4\n",
    "                assert spike_length > 25, 'spike_length가 25보다 작음'\n",
    "            else:\n",
    "                loss1 = nn.MSELoss()(spike_class[..., 5:25], spike[..., 5:25])\n",
    "                loss2 = nn.MSELoss()(spike_class[..., 0:5], spike[..., 0:5])\n",
    "                loss3 = nn.MSELoss()(spike_class[..., 25:spike_length], spike[..., 25:spike_length])\n",
    "                loss = loss1 * 2.125 + (loss2 + loss3)/4\n",
    "                assert spike_length > 25, 'spike_length가 25보다 작음'\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_loss += loss.item()\n",
    "            # print(f'\\nepoch-{epoch}, running_loss : {running_loss:.5f}, iter percent {iter/len(train_loader)*100:.2f}%')\n",
    "            iter += 1\n",
    "        avg_loss = running_loss / len(train_loader)\n",
    "        assert not np.isnan(avg_loss), f\"Error: avg_loss is NaN! Running loss: {running_loss}, Length of train_loader: {len(train_loader)}\"\n",
    "        loss_history.append((epoch, avg_loss))\n",
    "        print(f'\\nepoch-{epoch} loss : {avg_loss:.5f}')\n",
    "        print(f\"ae train 실행 시간: {time.time()-ae_train_start_time:.3f}초\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        cluster_accuracy_during_training_cycle_all_dataset = np.zeros(dataset_num)\n",
    "        cluster_accuracy_post_training_cycle_all_dataset = np.zeros(dataset_num)\n",
    "        cluster_accuracy_total_all_dataset = np.zeros(dataset_num)    \n",
    "\n",
    "        if(epoch % accuracy_check_epoch_term == 0 or epoch == 1 or epoch == max_epoch-1): \n",
    "            accuracy_check_start_time = time.time()\n",
    "            print(f'\\nepoch-{epoch} accuracy check')\n",
    "            for ds in range(dataset_num):\n",
    "                # print('\\n', spike_tot[ds])\n",
    "\n",
    "                spike_template = np.load(my_path_ground_BH + template[ds])\n",
    "                spike = np.load(my_path_ground_BH + spike_tot[ds])\n",
    "                label = np.load(my_path_ground_BH + label_tot[ds])\n",
    "                \n",
    "                hidden_size = 4*TIME if 'SAE' in net.module.__class__.__name__ and SAE_hidden_nomean == True else 4\n",
    "\n",
    "                Cluster = np.zeros((num_cluster, hidden_size))\n",
    "                assert Cluster.shape[-1] == hidden_size, '이거 hidden dim 4 아니게 할 거면 잘 바꿔라'\n",
    "                \n",
    "                net.eval()\n",
    "                with torch.no_grad():\n",
    "                    spike_torch = torch.from_numpy(spike_template).float()\n",
    "                    spike_backup = spike_torch\n",
    "                    spike_torch = spike_torch.to(device)\n",
    "                    if coarse_com_mode == True and 'SAE' in net.module.__class__.__name__:\n",
    "                        spike_torch = spike_torch.unsqueeze(2).repeat(1, 1, level_num) # spike_length == level_num # (batch, time, feature)로 변환 \n",
    "                        spike_torch = (spike_torch > levels).to(torch.float) \n",
    "                        if Conv_net == True:\n",
    "                            spike_torch = spike_torch.unsqueeze(-2) # batch, time, in_channel, feature or batch in_channel,feature\n",
    "                            if two_channel_input == True:\n",
    "                                spike_backup = spike_backup.to(device)\n",
    "                                spike_backup = spike_backup.unsqueeze(2).repeat(1, 1, level_num) # spike_length == level_num # (batch, time, feature)로 변환 \n",
    "                                spike_backup = (spike_backup <= levels).to(torch.float) \n",
    "                                spike_backup = spike_backup.unsqueeze(-2) # batch, time, in_channel, feature\n",
    "                                spike_torch = torch.cat((spike_torch, spike_backup), dim=-2)\n",
    "                    elif 'SAE' in net.module.__class__.__name__:\n",
    "                        spike_torch = spike_torch.unsqueeze(1).repeat(1, TIME, 1) # (batch, time, feature)로 변환\n",
    "                        if Conv_net == True:\n",
    "                            spike_torch = spike_torch.unsqueeze(-2) # batch, time, in_channel, feature or batch in_channel,feature\n",
    "                    else:\n",
    "                        if Conv_net == True:\n",
    "                            spike_torch = spike_torch.unsqueeze(-2) #batch in_channel,feature\n",
    "                    inner_inf = net.module.encoder(spike_torch)\n",
    "\n",
    "                    # if 'SAE' in net.module.__class__.__name__:\n",
    "                    #     tensors = [inner_inf[0][i] for i in range(TIME)] \n",
    "                    #     all_equal = all(torch.equal(tensors[0], t) for t in tensors)\n",
    "                    #     print(all_equal, inner_inf)\n",
    "\n",
    "                    if 'SAE' in net.module.__class__.__name__:\n",
    "                        if SAE_hidden_nomean == True:\n",
    "                            inner_inf = inner_inf.reshape(spike_template.shape[0],-1)# time*feature 펼치기\n",
    "                        else:\n",
    "                            inner_inf = inner_inf.mean(dim=1)# Time 방향으로 평균\n",
    "\n",
    "                    Cluster = inner_inf.cpu().detach().numpy()\n",
    "\n",
    "                encoder_batch = 128\n",
    "                spike_hidden = np.zeros((len(spike), hidden_size))\n",
    "                net.eval()\n",
    "                with torch.no_grad():\n",
    "                    now_index = 0\n",
    "                    while (1):\n",
    "                        now_end_index = now_index+encoder_batch if now_index+encoder_batch < len(spike) else len(spike)\n",
    "                        spike_batch = spike[now_index:now_end_index] \n",
    "                        spike_torch = torch.from_numpy(spike_batch)\n",
    "                        spike_torch = spike_torch.float()\n",
    "                        spike_backup = spike_torch\n",
    "                        spike_torch = spike_torch.to(device)\n",
    "                        if coarse_com_mode == True and 'SAE' in net.module.__class__.__name__:\n",
    "                            spike_torch = spike_torch.unsqueeze(2).repeat(1, 1, level_num) # spike_length == level_num # (batch, time, feature)로 변환 \n",
    "                            spike_torch = (spike_torch > levels).to(torch.float) \n",
    "                            if Conv_net == True:\n",
    "                                spike_torch = spike_torch.unsqueeze(-2) # batch, time, in_channel, feature or batch in_channel,feature\n",
    "                                if two_channel_input == True:\n",
    "                                    spike_backup = spike_backup.to(device)\n",
    "                                    spike_backup = spike_backup.unsqueeze(2).repeat(1, 1, level_num) # spike_length == level_num # (batch, time, feature)로 변환 \n",
    "                                    spike_backup = (spike_backup <= levels).to(torch.float) \n",
    "                                    spike_backup = spike_backup.unsqueeze(-2)\n",
    "                                    spike_torch = torch.cat((spike_torch, spike_backup), dim=-2)\n",
    "                        elif 'SAE' in net.module.__class__.__name__:\n",
    "                            spike_torch = spike_torch.unsqueeze(1).repeat(1, TIME, 1) # (batch, time, feature)로 변환\n",
    "                            if Conv_net == True:\n",
    "                                spike_torch = spike_torch.unsqueeze(-2) # batch, time, in_channel, feature or batch in_channel,feature\n",
    "                        else:\n",
    "                            if Conv_net == True:\n",
    "                                spike_torch = spike_torch.unsqueeze(-2) #batch in_channel,feature\n",
    "                                \n",
    "                        inner_inf = net.module.encoder(spike_torch)\n",
    "                        if 'SAE' in net.module.__class__.__name__:\n",
    "                            if SAE_hidden_nomean == True:\n",
    "                                inner_inf = inner_inf.reshape(spike_batch.shape[0],-1)# 펼치기\n",
    "                            else:\n",
    "                                inner_inf = inner_inf.mean(dim=1)# Time 방향으로 평균\n",
    "                        spike_hidden[now_index:now_end_index] = inner_inf.cpu().detach().numpy()\n",
    "                        now_index += encoder_batch\n",
    "                        if (now_index >= len(spike)):\n",
    "                            break\n",
    "                    \n",
    "                spike_id = np.zeros(len(spike))\n",
    "                distance_sm = np.zeros(num_cluster)\n",
    "                tau = np.zeros(num_cluster)\n",
    "\n",
    "                # tau와 denominator 값을 저장할 리스트\n",
    "                plot_tau = []\n",
    "                plot_denominator = []\n",
    "                plot_m = []\n",
    "                plot_max_tau = []\n",
    "                for spike_index in range(len(spike)): \n",
    "                    for q in range(num_cluster):\n",
    "                        tau[q] = np.dot(spike_hidden[spike_index, :], Cluster[q, :]) # 이거 l2norm 거쳐서 나온 거니까 분모 1임.\n",
    "                        denominator =  np.linalg.norm(spike_hidden[spike_index, :])*np.linalg.norm(Cluster[q, :]) + 1e-12\n",
    "                        plot_denominator.append(denominator)\n",
    "                        if 'SAE' in net.module.__class__.__name__: # AE 때는 l2norm거쳐서 나와서 괜찮음\n",
    "                            tau[q] = tau[q] / denominator\n",
    "\n",
    "                        plot_tau.append(tau[q])\n",
    "\n",
    "                    # for i in range(num_cluster): # l2 distance\n",
    "                    #     distance_sm[i] = np.sum(np.power(np.abs(Cluster[i] - spike_hidden[spike_index, :]), 2))\n",
    "                    distance_sm = np.sum(np.power(np.abs(Cluster - spike_hidden[spike_index, :]), 2), axis=1)\n",
    "\n",
    "                    m = np.argmin(distance_sm)\n",
    "                    plot_m.append(m)\n",
    "                    spike_id[spike_index] = m + 1\n",
    "                    # print(spike_tot[ds], spike_index,np.max(tau))\n",
    "                    plot_max_tau.append(np.max(tau))\n",
    "                    if(np.max(tau) >= cos_thr[ds] and spike_index < training_cycle): # 원래 1400 아니냐?\n",
    "                        Cluster[m] = (Cluster[m] * 15 + spike_hidden[spike_index, :])/16\n",
    "\n",
    "                \n",
    "                # print('Cluster',Cluster)\n",
    "                # print('spike_id', spike_id)\n",
    "\n",
    "                # spike id 분포 확인하기\n",
    "                # unique_elements, counts = np.unique(spike_id, return_counts=True)\n",
    "                # print(\"Unique elements:\", unique_elements)\n",
    "                # print(\"Counts:\", counts)\n",
    "\n",
    "                cluster_accuracy_during_training_cycle = np.zeros(math.factorial(num_cluster))\n",
    "                cluster_accuracy_post_training_cycle = np.zeros(math.factorial(num_cluster))\n",
    "                cluster_accuracy_total = np.zeros(math.factorial(num_cluster))\n",
    "                \n",
    "                label_converter_ground = list(range(1, num_cluster + 1)) # [1, 2, 3, 4] 생성\n",
    "                label_converter_permutations = list(itertools.permutations(label_converter_ground)) # 모든 순열 구하기\n",
    "                perm_i = 0\n",
    "                perm_start_time = time.time()\n",
    "                for perm in label_converter_permutations:\n",
    "                    label_converter = list(perm)\n",
    "                    # print(label_converter)\n",
    "                    correct_during_training_cycle = 0\n",
    "                    correct_post_training_cycle = 0\n",
    "\n",
    "                    assert len(spike_id) == len(label), 'spike_id랑 label 길이 같아야 됨.'\n",
    "                    for i in range(len(spike_id)):\n",
    "                        if(label_converter[int(spike_id[i]-1)] == label[i]):\n",
    "                            if i < training_cycle:\n",
    "                                correct_during_training_cycle += 1\n",
    "                            else:\n",
    "                                correct_post_training_cycle += 1\n",
    "\n",
    "                    cluster_accuracy_during_training_cycle[perm_i] = correct_during_training_cycle/training_cycle\n",
    "                    cluster_accuracy_post_training_cycle[perm_i] = correct_post_training_cycle/(len(spike_id)-training_cycle)\n",
    "                    cluster_accuracy_total[perm_i] = (correct_during_training_cycle+correct_post_training_cycle)/(len(spike_id))\n",
    "                    perm_i += 1\n",
    "                # print(f\"perm 실행 시간: {time.time()-perm_start_time:.3f}초\")\n",
    "                \n",
    "                cluster_accuracy_during_training_cycle_all_dataset[ds] = np.max(cluster_accuracy_during_training_cycle)\n",
    "                cluster_accuracy_post_training_cycle_all_dataset[ds] = cluster_accuracy_post_training_cycle[np.argmax(cluster_accuracy_during_training_cycle)]\n",
    "                cluster_accuracy_total_all_dataset[ds] = cluster_accuracy_total[np.argmax(cluster_accuracy_during_training_cycle)]\n",
    "                # plot_distributions(ds, plot_tau, plot_denominator, plot_m, plot_max_tau, cos_thr[ds],\n",
    "                #                    cluster_accuracy_during_training_cycle_all_dataset[ds], cluster_accuracy_post_training_cycle_all_dataset[ds], cluster_accuracy_total_all_dataset[ds])\n",
    "\n",
    "\n",
    "            print('cluster_accuracy_post_training_cycle_all_dataset', cluster_accuracy_post_training_cycle_all_dataset)\n",
    "\n",
    "            mean_cluster_accuracy_during_training_cycle_all_dataset = np.mean(cluster_accuracy_during_training_cycle_all_dataset)\n",
    "            mean_cluster_accuracy_post_training_cycle_all_dataset = np.mean(cluster_accuracy_post_training_cycle_all_dataset)\n",
    "            mean_cluster_accuracy_total_all_dataset = np.mean(cluster_accuracy_total_all_dataset)\n",
    "            \n",
    "            mean_cluster_accuracy_during_training_cycle_all_dataset_history.append((epoch, mean_cluster_accuracy_during_training_cycle_all_dataset*100))\n",
    "            mean_cluster_accuracy_post_training_cycle_all_dataset_history.append((epoch, mean_cluster_accuracy_post_training_cycle_all_dataset*100))\n",
    "            mean_cluster_accuracy_total_all_dataset_history.append((epoch, mean_cluster_accuracy_total_all_dataset*100))\n",
    "            print(f\"mean_cluster_accuracy_during_training_cycle : {mean_cluster_accuracy_during_training_cycle_all_dataset*100:.2f}%, post_traincycle_acc : {mean_cluster_accuracy_post_training_cycle_all_dataset*100:.2f}%, total_acc : {mean_cluster_accuracy_total_all_dataset*100:.2f}%\")\n",
    "\n",
    "            if mean_cluster_accuracy_post_training_cycle_all_dataset > best_mean_cluster_accuracy_post_training_cycle_all_dataset:\n",
    "                # torch.save(net, f\"net_save/save_now_net_{current_time}.pth\")\n",
    "                torch.save(net.module.state_dict(), f\"net_save/save_now_net_{current_time}.pth\")\n",
    "                print('save model')\n",
    "                best_mean_cluster_accuracy_post_training_cycle_all_dataset = mean_cluster_accuracy_post_training_cycle_all_dataset\n",
    "            print(f\"best_mean_cluster_accuracy_post_training_cycle_all_dataset : {best_mean_cluster_accuracy_post_training_cycle_all_dataset*100:.2f}%\")\n",
    "            print(f\"accuracy_check 실행 시간: {time.time()-accuracy_check_start_time:.3f}초\")\n",
    "\n",
    "        wandb.log({\"avg_loss\": avg_loss})\n",
    "        wandb.log({\"mean_cluster_accuracy_post_training_cycle_all_dataset\": mean_cluster_accuracy_post_training_cycle_all_dataset})\n",
    "        wandb.log({\"best_mean_cluster_accuracy_post_training_cycle_all_dataset\": best_mean_cluster_accuracy_post_training_cycle_all_dataset})\n",
    "        wandb.log({\"best_mean_cluster_accuracy_post_training_cycle_all_dataset2\": best_mean_cluster_accuracy_post_training_cycle_all_dataset})\n",
    "\n",
    "\n",
    "        # 저장\n",
    "        with open(f\"result_save/cluster_accuracy_history_{current_time}.pkl\", \"wb\") as f:\n",
    "            pickle.dump({\n",
    "                \"loss_history\": loss_history,\n",
    "                \"mean_cluster_accuracy_during_training_cycle_all_dataset_history\": mean_cluster_accuracy_during_training_cycle_all_dataset_history,\n",
    "                \"mean_cluster_accuracy_post_training_cycle_all_dataset_history\": mean_cluster_accuracy_post_training_cycle_all_dataset_history,\n",
    "                \"mean_cluster_accuracy_total_all_dataset_history\": mean_cluster_accuracy_total_all_dataset_history,\n",
    "            }, f)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mbhkim003\u001b[0m (\u001b[33mbhkim003-seoul-national-university\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.19.2 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.17.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/nfs/home/bhkim003/github_folder/ByeonghyeonKim/my_snn/wandb/run-20250108_145643-wkmu8kz3</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/bhkim003-seoul-national-university/spike_sorting%20just%20run/runs/wkmu8kz3' target=\"_blank\">woven-sea-258</a></strong> to <a href='https://wandb.ai/bhkim003-seoul-national-university/spike_sorting%20just%20run' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/bhkim003-seoul-national-university/spike_sorting%20just%20run' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/spike_sorting%20just%20run</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/bhkim003-seoul-national-university/spike_sorting%20just%20run/runs/wkmu8kz3' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/spike_sorting%20just%20run/runs/wkmu8kz3</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'gpu': 2, 'Conv_net': True, 'SAE_net': True, 'dataset_num': 16, 'spike_length': 50, 'num_cluster': 4, 'training_cycle': 2400, 'batch_size': 48, 'max_epoch': 7000, 'learning_rate': 0.0001, 'normalize_on': False, 'need_bias': False, 'lif_add_at_first': False, 'my_seed': 42, 'TIME': 50, 'v_decay': 0.25, 'v_threshold': 0.5, 'v_reset': 10000.0, 'BPTT_on': False, 'SAE_hidden_nomean': True, 'current_time': '20250108_145641_959', 'optimizer': 'Adam', 'coarse_com_mode': True, 'sae_l2_norm_bridge': False, 'sae_lif_bridge': True, 'accuracy_check_epoch_term': 1, 'lif_add_at_last': True, 'two_channel_input': True, 'coarse_com_config': (3.0, -3.0)}\n",
      "conv length [5, 11, 24, 50]\n",
      "DataParallel(\n",
      "  (module): SAE_conv1(\n",
      "    (encoder): Sequential(\n",
      "      (0): SSBH_DimChanger_one_two()\n",
      "      (1): SSBH_DimChanger_for_one_two_coupling()\n",
      "      (2): Conv1d(2, 32, kernel_size=(3,), stride=(2,), bias=False)\n",
      "      (3): SSBH_DimChanger_for_one_two_decoupling()\n",
      "      (4): LIF_layer()\n",
      "      (5): SSBH_DimChanger_for_one_two_coupling()\n",
      "      (6): Conv1d(32, 64, kernel_size=(3,), stride=(2,), bias=False)\n",
      "      (7): SSBH_DimChanger_for_one_two_decoupling()\n",
      "      (8): LIF_layer()\n",
      "      (9): SSBH_DimChanger_for_one_two_coupling()\n",
      "      (10): Conv1d(64, 96, kernel_size=(3,), stride=(2,), bias=False)\n",
      "      (11): SSBH_DimChanger_for_one_two_decoupling()\n",
      "      (12): LIF_layer()\n",
      "      (13): SSBH_DimChanger_for_one_two_coupling()\n",
      "      (14): SSBH_DimChanger_for_fc()\n",
      "      (15): Linear(in_features=480, out_features=4, bias=False)\n",
      "      (16): SSBH_DimChanger_for_one_two_decoupling()\n",
      "      (17): LIF_layer()\n",
      "      (18): SSBH_DimChanger_one_two()\n",
      "    )\n",
      "    (decoder): Sequential(\n",
      "      (0): SSBH_DimChanger_one_two()\n",
      "      (1): SSBH_DimChanger_for_one_two_coupling()\n",
      "      (2): Linear(in_features=4, out_features=480, bias=False)\n",
      "      (3): SSBH_DimChanger_for_one_two_decoupling()\n",
      "      (4): LIF_layer()\n",
      "      (5): SSBH_DimChanger_for_one_two_coupling()\n",
      "      (6): SSBH_DimChanger_for_conv1()\n",
      "      (7): SSBH_DimChanger_for_one_two_decoupling()\n",
      "      (8): SSBH_DimChanger_for_one_two_coupling()\n",
      "      (9): ConvTranspose1d(96, 64, kernel_size=(3,), stride=(2,), bias=False)\n",
      "      (10): SSBH_DimChanger_for_one_two_decoupling()\n",
      "      (11): LIF_layer()\n",
      "      (12): SSBH_DimChanger_for_one_two_coupling()\n",
      "      (13): ConvTranspose1d(64, 32, kernel_size=(3,), stride=(2,), output_padding=(1,), bias=False)\n",
      "      (14): SSBH_DimChanger_for_one_two_decoupling()\n",
      "      (15): LIF_layer()\n",
      "      (16): SSBH_DimChanger_for_one_two_coupling()\n",
      "      (17): ConvTranspose1d(32, 2, kernel_size=(3,), stride=(2,), output_padding=(1,), bias=False)\n",
      "      (18): SSBH_DimChanger_for_one_two_decoupling()\n",
      "      (19): LIF_layer()\n",
      "      (20): SSBH_DimChanger_one_two()\n",
      "    )\n",
      "  )\n",
      ")\n",
      "Device: cuda\n",
      "\n",
      "Start Training, current_time = 20250108_145641_959\n",
      "\n",
      "epoch-0 loss : 0.17668\n",
      "ae train 실행 시간: 137.994초\n",
      "\n",
      "epoch-0 accuracy check\n",
      "cluster_accuracy_post_training_cycle_all_dataset [0.97307002 0.97771836 0.80872795 0.82402235 0.96435644 0.9125\n",
      " 0.79228487 0.54973357 0.94710071 0.86259542 0.51399254 0.39349112\n",
      " 0.75829876 0.75706215 0.46442308 0.44281793]\n",
      "mean_cluster_accuracy_during_training_cycle : 76.35%, post_traincycle_acc : 74.64%, total_acc : 75.82%\n",
      "save model\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 74.64%\n",
      "accuracy_check 실행 시간: 22.709초\n",
      "\n",
      "epoch-1 loss : 0.05615\n",
      "ae train 실행 시간: 136.733초\n",
      "\n",
      "epoch-1 accuracy check\n",
      "cluster_accuracy_post_training_cycle_all_dataset [0.97486535 0.97593583 0.96657382 0.94878957 0.97623762 0.92321429\n",
      " 0.82195846 0.63587922 0.9491353  0.90744275 0.56529851 0.50591716\n",
      " 0.94813278 0.87758945 0.71923077 0.39249771]\n",
      "mean_cluster_accuracy_during_training_cycle : 80.34%, post_traincycle_acc : 81.80%, total_acc : 80.79%\n",
      "save model\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 81.80%\n",
      "accuracy_check 실행 시간: 22.454초\n",
      "\n",
      "epoch-2 loss : 0.04836\n",
      "ae train 실행 시간: 136.169초\n",
      "\n",
      "epoch-2 accuracy check\n",
      "cluster_accuracy_post_training_cycle_all_dataset [0.89138241 0.97771836 0.96657382 0.89851024 0.97524752 0.925\n",
      " 0.77448071 0.61989343 0.93997965 0.89694656 0.58208955 0.47337278\n",
      " 0.94813278 0.913371   0.41153846 0.45562672]\n",
      "mean_cluster_accuracy_during_training_cycle : 78.53%, post_traincycle_acc : 79.06%, total_acc : 78.68%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 81.80%\n",
      "accuracy_check 실행 시간: 21.735초\n",
      "\n",
      "epoch-3 loss : 0.04549\n",
      "ae train 실행 시간: 136.799초\n",
      "\n",
      "epoch-3 accuracy check\n",
      "cluster_accuracy_post_training_cycle_all_dataset [0.97486535 0.97058824 0.93686165 0.82681564 0.97326733 0.83125\n",
      " 0.78437191 0.53285968 0.92370295 0.79866412 0.49626866 0.49901381\n",
      " 0.94605809 0.61958569 0.50288462 0.49039341]\n",
      "mean_cluster_accuracy_during_training_cycle : 75.80%, post_traincycle_acc : 75.67%, total_acc : 75.76%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 81.80%\n",
      "accuracy_check 실행 시간: 23.077초\n",
      "\n",
      "epoch-4 loss : 0.04372\n",
      "ae train 실행 시간: 137.582초\n",
      "\n",
      "epoch-4 accuracy check\n",
      "cluster_accuracy_post_training_cycle_all_dataset [0.97396768 0.97326203 0.94893222 0.89664804 0.97722772 0.88125\n",
      " 0.79228487 0.61900533 0.93692777 0.90458015 0.60447761 0.52859961\n",
      " 0.95228216 0.75612053 0.54903846 0.47301006]\n",
      "mean_cluster_accuracy_during_training_cycle : 78.96%, post_traincycle_acc : 79.80%, total_acc : 79.22%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 81.80%\n",
      "accuracy_check 실행 시간: 21.996초\n",
      "\n",
      "epoch-5 loss : 0.04311\n",
      "ae train 실행 시간: 136.145초\n",
      "\n",
      "epoch-5 accuracy check\n",
      "cluster_accuracy_post_training_cycle_all_dataset [0.97486535 0.97326203 0.95636026 0.90409683 0.91287129 0.83571429\n",
      " 0.81008902 0.64476021 0.94811801 0.91889313 0.5755597  0.47731755\n",
      " 0.9533195  0.73917137 0.52596154 0.47758463]\n",
      "mean_cluster_accuracy_during_training_cycle : 78.57%, post_traincycle_acc : 78.92%, total_acc : 78.68%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 81.80%\n",
      "accuracy_check 실행 시간: 22.681초\n",
      "\n",
      "epoch-6 loss : 0.04410\n",
      "ae train 실행 시간: 137.439초\n",
      "\n",
      "epoch-6 accuracy check\n",
      "cluster_accuracy_post_training_cycle_all_dataset [0.97396768 0.96167558 0.95543175 0.84916201 0.97524752 0.86696429\n",
      " 0.79030663 0.62522202 0.89318413 0.89790076 0.58022388 0.50197239\n",
      " 0.85580913 0.78531073 0.54230769 0.46020128]\n",
      "mean_cluster_accuracy_during_training_cycle : 76.69%, post_traincycle_acc : 78.22%, total_acc : 77.16%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 81.80%\n",
      "accuracy_check 실행 시간: 22.477초\n",
      "\n",
      "epoch-7 loss : 0.04287\n",
      "ae train 실행 시간: 135.683초\n",
      "\n",
      "epoch-7 accuracy check\n",
      "cluster_accuracy_post_training_cycle_all_dataset [0.97396768 0.9688057  0.95264624 0.858473   0.97425743 0.87410714\n",
      " 0.76854599 0.53197158 0.95015259 0.90839695 0.57742537 0.48422091\n",
      " 0.9533195  0.76741996 0.54519231 0.57639524]\n",
      "mean_cluster_accuracy_during_training_cycle : 77.62%, post_traincycle_acc : 79.16%, total_acc : 78.10%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 81.80%\n",
      "accuracy_check 실행 시간: 22.036초\n",
      "\n",
      "epoch-8 loss : 0.04189\n",
      "ae train 실행 시간: 137.856초\n",
      "\n",
      "epoch-8 accuracy check\n",
      "cluster_accuracy_post_training_cycle_all_dataset [0.97307002 0.96969697 0.95078923 0.83147114 0.97029703 0.89375\n",
      " 0.76755687 0.42984014 0.90437436 0.68034351 0.58302239 0.49704142\n",
      " 0.95435685 0.7259887  0.57596154 0.46386093]\n",
      "mean_cluster_accuracy_during_training_cycle : 76.18%, post_traincycle_acc : 76.07%, total_acc : 76.14%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 81.80%\n",
      "accuracy_check 실행 시간: 22.326초\n",
      "\n",
      "epoch-9 loss : 0.04093\n",
      "ae train 실행 시간: 137.588초\n",
      "\n",
      "epoch-9 accuracy check\n",
      "cluster_accuracy_post_training_cycle_all_dataset [0.97396768 0.96791444 0.94986072 0.83519553 0.97227723 0.85892857\n",
      " 0.74183976 0.45648313 0.93489318 0.6240458  0.45708955 0.49112426\n",
      " 0.95435685 0.86252354 0.56442308 0.47209515]\n",
      "mean_cluster_accuracy_during_training_cycle : 76.71%, post_traincycle_acc : 75.73%, total_acc : 76.41%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 81.80%\n",
      "accuracy_check 실행 시간: 22.333초\n",
      "\n",
      "epoch-10 loss : 0.04031\n",
      "ae train 실행 시간: 143.780초\n",
      "\n",
      "epoch-10 accuracy check\n",
      "cluster_accuracy_post_training_cycle_all_dataset [0.97486535 0.9688057  0.95264624 0.87337058 0.97425743 0.86160714\n",
      " 0.7388724  0.44493783 0.91658189 0.6240458  0.5886194  0.50394477\n",
      " 0.95435685 0.80131827 0.57211538 0.54437328]\n",
      "mean_cluster_accuracy_during_training_cycle : 77.49%, post_traincycle_acc : 76.84%, total_acc : 77.28%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 81.80%\n",
      "accuracy_check 실행 시간: 22.892초\n",
      "\n",
      "epoch-11 loss : 0.04042\n",
      "ae train 실행 시간: 137.388초\n",
      "\n",
      "epoch-11 accuracy check\n",
      "cluster_accuracy_post_training_cycle_all_dataset [0.97217235 0.9688057  0.95264624 0.89013035 0.97326733 0.82589286\n",
      " 0.69238378 0.43161634 0.93896236 0.90839695 0.5858209  0.47830375\n",
      " 0.95539419 0.81826742 0.575      0.2863678 ]\n",
      "mean_cluster_accuracy_during_training_cycle : 77.26%, post_traincycle_acc : 76.58%, total_acc : 77.03%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 81.80%\n",
      "accuracy_check 실행 시간: 22.131초\n",
      "\n",
      "epoch-12 loss : 0.03969\n",
      "ae train 실행 시간: 138.393초\n",
      "\n",
      "epoch-12 accuracy check\n",
      "cluster_accuracy_post_training_cycle_all_dataset [0.97396768 0.95900178 0.95821727 0.88826816 0.95049505 0.83571429\n",
      " 0.72502473 0.56216696 0.85554425 0.71946565 0.59514925 0.49013807\n",
      " 0.84854772 0.72881356 0.475      0.51509607]\n",
      "mean_cluster_accuracy_during_training_cycle : 74.85%, post_traincycle_acc : 75.50%, total_acc : 75.05%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 81.80%\n",
      "accuracy_check 실행 시간: 22.461초\n",
      "\n",
      "epoch-13 loss : 0.03719\n",
      "ae train 실행 시간: 137.059초\n",
      "\n",
      "epoch-13 accuracy check\n",
      "cluster_accuracy_post_training_cycle_all_dataset [0.97217235 0.95098039 0.94057567 0.86685289 0.95544554 0.84285714\n",
      " 0.76458952 0.58436945 0.82197355 0.73759542 0.57742537 0.53155819\n",
      " 0.87966805 0.70809793 0.48942308 0.50503202]\n",
      "mean_cluster_accuracy_during_training_cycle : 75.21%, post_traincycle_acc : 75.80%, total_acc : 75.39%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 81.80%\n",
      "accuracy_check 실행 시간: 22.304초\n",
      "\n",
      "epoch-14 loss : 0.03675\n",
      "ae train 실행 시간: 138.290초\n",
      "\n",
      "epoch-14 accuracy check\n",
      "cluster_accuracy_post_training_cycle_all_dataset [0.97127469 0.94652406 0.9452182  0.8575419  0.95346535 0.81071429\n",
      " 0.70722057 0.56394316 0.81892167 0.68320611 0.56996269 0.50690335\n",
      " 0.86618257 0.69491525 0.49615385 0.52058554]\n",
      "mean_cluster_accuracy_during_training_cycle : 74.00%, post_traincycle_acc : 74.45%, total_acc : 74.14%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 81.80%\n",
      "accuracy_check 실행 시간: 22.065초\n",
      "\n",
      "epoch-15 loss : 0.03730\n",
      "ae train 실행 시간: 136.126초\n",
      "\n",
      "epoch-15 accuracy check\n",
      "cluster_accuracy_post_training_cycle_all_dataset [0.97037702 0.94474153 0.93964717 0.84916201 0.88019802 0.75267857\n",
      " 0.70524233 0.54973357 0.82400814 0.61545802 0.5755597  0.49112426\n",
      " 0.86929461 0.71845574 0.53076923 0.50686185]\n",
      "mean_cluster_accuracy_during_training_cycle : 73.47%, post_traincycle_acc : 73.27%, total_acc : 73.40%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 81.80%\n",
      "accuracy_check 실행 시간: 22.236초\n",
      "\n",
      "epoch-16 loss : 0.03871\n",
      "ae train 실행 시간: 137.455초\n",
      "\n",
      "epoch-16 accuracy check\n",
      "cluster_accuracy_post_training_cycle_all_dataset [0.97307002 0.96969697 0.95078923 0.90502793 0.9039604  0.81517857\n",
      " 0.76953511 0.59857904 0.91251272 0.63072519 0.59048507 0.50493097\n",
      " 0.8879668  0.72975518 0.51826923 0.4473925 ]\n",
      "mean_cluster_accuracy_during_training_cycle : 76.45%, post_traincycle_acc : 75.67%, total_acc : 76.22%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 81.80%\n",
      "accuracy_check 실행 시간: 22.514초\n",
      "\n",
      "epoch-17 loss : 0.03809\n",
      "ae train 실행 시간: 136.980초\n",
      "\n",
      "epoch-17 accuracy check\n",
      "cluster_accuracy_post_training_cycle_all_dataset [0.97037702 0.94919786 0.94428969 0.86499069 0.92277228 0.81875\n",
      " 0.72106825 0.55417407 0.83316378 0.63931298 0.55130597 0.51084813\n",
      " 0.88589212 0.73163842 0.46634615 0.50594694]\n",
      "mean_cluster_accuracy_during_training_cycle : 74.82%, post_traincycle_acc : 74.19%, total_acc : 74.62%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 81.80%\n",
      "accuracy_check 실행 시간: 22.341초\n",
      "\n",
      "epoch-18 loss : 0.03724\n",
      "ae train 실행 시간: 138.357초\n",
      "\n",
      "epoch-18 accuracy check\n",
      "cluster_accuracy_post_training_cycle_all_dataset [0.97127469 0.94741533 0.93593315 0.86685289 0.93267327 0.79553571\n",
      " 0.67260138 0.39609236 0.82706002 0.61450382 0.5261194  0.50197239\n",
      " 0.8879668  0.73258004 0.48557692 0.50503202]\n",
      "mean_cluster_accuracy_during_training_cycle : 73.61%, post_traincycle_acc : 72.49%, total_acc : 73.26%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 81.80%\n",
      "accuracy_check 실행 시간: 24.089초\n",
      "\n",
      "epoch-19 loss : 0.03699\n",
      "ae train 실행 시간: 137.334초\n",
      "\n",
      "epoch-19 accuracy check\n",
      "cluster_accuracy_post_training_cycle_all_dataset [0.96947935 0.93939394 0.94336119 0.84823091 0.93960396 0.83035714\n",
      " 0.72205737 0.58703375 0.82807731 0.63835878 0.58022388 0.49013807\n",
      " 0.88174274 0.73446328 0.47788462 0.49862763]\n",
      "mean_cluster_accuracy_during_training_cycle : 74.32%, post_traincycle_acc : 74.43%, total_acc : 74.35%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 81.80%\n",
      "accuracy_check 실행 시간: 22.236초\n",
      "\n",
      "epoch-20 loss : 0.03585\n",
      "ae train 실행 시간: 137.782초\n",
      "\n",
      "epoch-20 accuracy check\n",
      "cluster_accuracy_post_training_cycle_all_dataset [0.96858169 0.9483066  0.94057567 0.87243948 0.94158416 0.82857143\n",
      " 0.70623145 0.57460036 0.82909461 0.64503817 0.58768657 0.49112426\n",
      " 0.8620332  0.74011299 0.50288462 0.54345837]\n",
      "mean_cluster_accuracy_during_training_cycle : 74.52%, post_traincycle_acc : 74.89%, total_acc : 74.64%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 81.80%\n",
      "accuracy_check 실행 시간: 22.524초\n",
      "\n",
      "epoch-21 loss : 0.03618\n",
      "ae train 실행 시간: 136.448초\n",
      "\n",
      "epoch-21 accuracy check\n",
      "cluster_accuracy_post_training_cycle_all_dataset [0.97037702 0.942959   0.93686165 0.86685289 0.95247525 0.85267857\n",
      " 0.73689416 0.57815275 0.8311292  0.68225191 0.5858209  0.48619329\n",
      " 0.86929461 0.70998117 0.4875     0.50228728]\n",
      "mean_cluster_accuracy_during_training_cycle : 74.76%, post_traincycle_acc : 74.95%, total_acc : 74.82%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 81.80%\n",
      "accuracy_check 실행 시간: 22.223초\n",
      "\n",
      "epoch-22 loss : 0.03524\n",
      "ae train 실행 시간: 138.766초\n",
      "\n",
      "epoch-22 accuracy check\n",
      "cluster_accuracy_post_training_cycle_all_dataset [0.96947935 0.93761141 0.93779016 0.87337058 0.93762376 0.83303571\n",
      " 0.72997033 0.57992895 0.82807731 0.67557252 0.57462687 0.47633136\n",
      " 0.84958506 0.69962335 0.47403846 0.46569076]\n",
      "mean_cluster_accuracy_during_training_cycle : 74.39%, post_traincycle_acc : 74.01%, total_acc : 74.27%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 81.80%\n",
      "accuracy_check 실행 시간: 22.276초\n",
      "\n",
      "epoch-23 loss : 0.03527\n",
      "ae train 실행 시간: 135.480초\n",
      "\n",
      "epoch-23 accuracy check\n",
      "cluster_accuracy_post_training_cycle_all_dataset [0.96858169 0.94741533 0.93129062 0.87430168 0.94059406 0.83035714\n",
      " 0.73095945 0.58348135 0.83723296 0.64217557 0.60820896 0.50295858\n",
      " 0.87136929 0.73634652 0.49903846 0.48215919]\n",
      "mean_cluster_accuracy_during_training_cycle : 74.63%, post_traincycle_acc : 74.92%, total_acc : 74.72%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 81.80%\n",
      "accuracy_check 실행 시간: 22.195초\n",
      "\n",
      "epoch-24 loss : 0.03523\n",
      "ae train 실행 시간: 137.320초\n",
      "\n",
      "epoch-24 accuracy check\n",
      "cluster_accuracy_post_training_cycle_all_dataset [0.96947935 0.95008913 0.93500464 0.87616387 0.93762376 0.81964286\n",
      " 0.68545994 0.41563055 0.83214649 0.67366412 0.56716418 0.50887574\n",
      " 0.85684647 0.70433145 0.48846154 0.48581885]\n",
      "mean_cluster_accuracy_during_training_cycle : 74.28%, post_traincycle_acc : 73.17%, total_acc : 73.92%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 81.80%\n",
      "accuracy_check 실행 시간: 22.257초\n",
      "\n",
      "epoch-25 loss : 0.03564\n",
      "ae train 실행 시간: 139.170초\n",
      "\n",
      "epoch-25 accuracy check\n",
      "cluster_accuracy_post_training_cycle_all_dataset [0.96768402 0.93672014 0.93686165 0.86592179 0.93861386 0.80357143\n",
      " 0.69930762 0.37211368 0.83418108 0.66030534 0.58955224 0.50098619\n",
      " 0.85580913 0.70998117 0.47884615 0.47666972]\n",
      "mean_cluster_accuracy_during_training_cycle : 73.47%, post_traincycle_acc : 72.67%, total_acc : 73.22%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 81.80%\n",
      "accuracy_check 실행 시간: 22.540초\n",
      "\n",
      "epoch-26 loss : 0.03511\n",
      "ae train 실행 시간: 138.577초\n",
      "\n",
      "epoch-26 accuracy check\n",
      "cluster_accuracy_post_training_cycle_all_dataset [0.96858169 0.93493761 0.92850511 0.85288641 0.92772277 0.81607143\n",
      " 0.6735905  0.56749556 0.82604273 0.65076336 0.5988806  0.46942801\n",
      " 0.86618257 0.69114878 0.47788462 0.47666972]\n",
      "mean_cluster_accuracy_during_training_cycle : 73.29%, post_traincycle_acc : 73.29%, total_acc : 73.29%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 81.80%\n",
      "accuracy_check 실행 시간: 22.395초\n",
      "\n",
      "epoch-27 loss : 0.03526\n",
      "ae train 실행 시간: 138.336초\n",
      "\n",
      "epoch-27 accuracy check\n",
      "cluster_accuracy_post_training_cycle_all_dataset [0.97217235 0.94117647 0.94150418 0.8594041  0.91584158 0.81428571\n",
      " 0.70326409 0.54440497 0.8311292  0.66889313 0.59421642 0.47830375\n",
      " 0.84958506 0.70338983 0.51346154 0.55352242]\n",
      "mean_cluster_accuracy_during_training_cycle : 74.34%, post_traincycle_acc : 74.28%, total_acc : 74.32%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 81.80%\n",
      "accuracy_check 실행 시간: 22.788초\n",
      "\n",
      "epoch-28 loss : 0.03523\n",
      "ae train 실행 시간: 134.867초\n",
      "\n",
      "epoch-28 accuracy check\n",
      "cluster_accuracy_post_training_cycle_all_dataset [0.96768402 0.92869875 0.93871866 0.84916201 0.91386139 0.79642857\n",
      " 0.67952522 0.57726465 0.82604273 0.65458015 0.5625     0.51282051\n",
      " 0.8526971  0.7165725  0.52403846 0.47849954]\n",
      "mean_cluster_accuracy_during_training_cycle : 74.26%, post_traincycle_acc : 73.62%, total_acc : 74.06%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 81.80%\n",
      "accuracy_check 실행 시간: 22.420초\n",
      "\n",
      "epoch-29 loss : 0.03506\n",
      "ae train 실행 시간: 136.312초\n",
      "\n",
      "epoch-29 accuracy check\n",
      "cluster_accuracy_post_training_cycle_all_dataset [0.96588869 0.92780749 0.93779016 0.87057728 0.92673267 0.76517857\n",
      " 0.66172107 0.40852575 0.8301119  0.66125954 0.55876866 0.49013807\n",
      " 0.85788382 0.72033898 0.51442308 0.55718207]\n",
      "mean_cluster_accuracy_during_training_cycle : 73.00%, post_traincycle_acc : 72.84%, total_acc : 72.95%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 81.80%\n",
      "accuracy_check 실행 시간: 22.581초\n",
      "\n",
      "epoch-30 loss : 0.03519\n",
      "ae train 실행 시간: 139.357초\n",
      "\n",
      "epoch-30 accuracy check\n",
      "cluster_accuracy_post_training_cycle_all_dataset [0.97037702 0.93493761 0.93686165 0.84729981 0.93168317 0.82232143\n",
      " 0.65281899 0.57015986 0.83214649 0.625      0.56436567 0.49704142\n",
      " 0.86514523 0.70244821 0.48461538 0.46752059]\n",
      "mean_cluster_accuracy_during_training_cycle : 73.21%, post_traincycle_acc : 73.15%, total_acc : 73.20%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 81.80%\n",
      "accuracy_check 실행 시간: 22.563초\n",
      "\n",
      "epoch-31 loss : 0.03465\n",
      "ae train 실행 시간: 139.754초\n",
      "\n",
      "epoch-31 accuracy check\n",
      "cluster_accuracy_post_training_cycle_all_dataset [0.97037702 0.93493761 0.93593315 0.85009311 0.95445545 0.85357143\n",
      " 0.71315529 0.58081705 0.8474059  0.67175573 0.59328358 0.47830375\n",
      " 0.84854772 0.74105461 0.48846154 0.49313815]\n",
      "mean_cluster_accuracy_during_training_cycle : 74.35%, post_traincycle_acc : 74.72%, total_acc : 74.46%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 81.80%\n",
      "accuracy_check 실행 시간: 23.306초\n",
      "\n",
      "epoch-32 loss : 0.03397\n",
      "ae train 실행 시간: 144.626초\n",
      "\n",
      "epoch-32 accuracy check\n",
      "cluster_accuracy_post_training_cycle_all_dataset [0.97037702 0.92691622 0.93500464 0.84171322 0.91089109 0.81339286\n",
      " 0.68249258 0.56483126 0.8301119  0.63549618 0.57276119 0.48027613\n",
      " 0.8526971  0.72316384 0.47211538 0.41171089]\n",
      "mean_cluster_accuracy_during_training_cycle : 72.90%, post_traincycle_acc : 72.65%, total_acc : 72.83%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 81.80%\n",
      "accuracy_check 실행 시간: 25.289초\n",
      "\n",
      "epoch-33 loss : 0.03386\n",
      "ae train 실행 시간: 140.646초\n",
      "\n",
      "epoch-33 accuracy check\n",
      "cluster_accuracy_post_training_cycle_all_dataset [0.97307002 0.92335116 0.93221913 0.83240223 0.91188119 0.81964286\n",
      " 0.66963403 0.45381883 0.83214649 0.61927481 0.61007463 0.45364892\n",
      " 0.86514523 0.69020716 0.47788462 0.39432754]\n",
      "mean_cluster_accuracy_during_training_cycle : 72.11%, post_traincycle_acc : 71.62%, total_acc : 71.96%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 81.80%\n",
      "accuracy_check 실행 시간: 24.897초\n",
      "\n",
      "epoch-34 loss : 0.03374\n",
      "ae train 실행 시간: 138.980초\n",
      "\n",
      "epoch-34 accuracy check\n",
      "cluster_accuracy_post_training_cycle_all_dataset [0.96947935 0.91265597 0.93129062 0.81471136 0.91386139 0.76964286\n",
      " 0.63996044 0.56660746 0.82909461 0.61545802 0.58302239 0.46449704\n",
      " 0.85788382 0.69585687 0.47884615 0.50228728]\n",
      "mean_cluster_accuracy_during_training_cycle : 71.99%, post_traincycle_acc : 72.16%, total_acc : 72.04%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 81.80%\n",
      "accuracy_check 실행 시간: 22.790초\n",
      "\n",
      "epoch-35 loss : 0.03391\n",
      "ae train 실행 시간: 140.322초\n",
      "\n",
      "epoch-35 accuracy check\n",
      "cluster_accuracy_post_training_cycle_all_dataset [0.96947935 0.91532977 0.93036212 0.83891993 0.86237624 0.78839286\n",
      " 0.67457962 0.36412078 0.83621567 0.56774809 0.61660448 0.45759369\n",
      " 0.83713693 0.7212806  0.5        0.52881976]\n",
      "mean_cluster_accuracy_during_training_cycle : 71.29%, post_traincycle_acc : 71.31%, total_acc : 71.29%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 81.80%\n",
      "accuracy_check 실행 시간: 22.509초\n",
      "\n",
      "epoch-36 loss : 0.03406\n",
      "ae train 실행 시간: 138.305초\n",
      "\n",
      "epoch-36 accuracy check\n",
      "cluster_accuracy_post_training_cycle_all_dataset [0.97127469 0.90106952 0.8913649  0.83333333 0.93960396 0.81428571\n",
      " 0.68150346 0.54085258 0.80874873 0.63549618 0.57742537 0.46548323\n",
      " 0.85165975 0.69397363 0.44423077 0.38700823]\n",
      "mean_cluster_accuracy_during_training_cycle : 71.80%, post_traincycle_acc : 71.48%, total_acc : 71.70%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 81.80%\n",
      "accuracy_check 실행 시간: 22.623초\n",
      "\n",
      "epoch-37 loss : 0.03424\n",
      "ae train 실행 시간: 139.734초\n",
      "\n",
      "epoch-37 accuracy check\n",
      "cluster_accuracy_post_training_cycle_all_dataset [0.96768402 0.93582888 0.93593315 0.85195531 0.89207921 0.7625\n",
      " 0.67556874 0.37211368 0.82807731 0.61832061 0.56902985 0.4566075\n",
      " 0.83713693 0.67890772 0.49230769 0.46203111]\n",
      "mean_cluster_accuracy_during_training_cycle : 71.42%, post_traincycle_acc : 70.85%, total_acc : 71.24%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 81.80%\n",
      "accuracy_check 실행 시간: 22.272초\n",
      "\n",
      "epoch-38 loss : 0.03414\n",
      "ae train 실행 시간: 138.092초\n",
      "\n",
      "epoch-38 accuracy check\n",
      "cluster_accuracy_post_training_cycle_all_dataset [0.95332136 0.88680927 0.84679666 0.79702048 0.88514851 0.76785714\n",
      " 0.65776459 0.55683837 0.79247202 0.58110687 0.56156716 0.44674556\n",
      " 0.81742739 0.67231638 0.46538462 0.34400732]\n",
      "mean_cluster_accuracy_during_training_cycle : 68.73%, post_traincycle_acc : 68.95%, total_acc : 68.80%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 81.80%\n",
      "accuracy_check 실행 시간: 22.859초\n",
      "\n",
      "epoch-39 loss : 0.03374\n",
      "ae train 실행 시간: 135.930초\n",
      "\n",
      "epoch-39 accuracy check\n",
      "cluster_accuracy_post_training_cycle_all_dataset [0.94793537 0.87522282 0.84772516 0.78957169 0.87326733 0.72589286\n",
      " 0.59643917 0.54973357 0.79145473 0.57251908 0.55410448 0.45463511\n",
      " 0.80705394 0.63841808 0.44423077 0.34858188]\n",
      "mean_cluster_accuracy_during_training_cycle : 67.02%, post_traincycle_acc : 67.60%, total_acc : 67.21%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 81.80%\n",
      "accuracy_check 실행 시간: 21.947초\n",
      "\n",
      "epoch-40 loss : 0.03430\n",
      "ae train 실행 시간: 137.348초\n",
      "\n",
      "epoch-40 accuracy check\n",
      "cluster_accuracy_post_training_cycle_all_dataset [0.95152603 0.89037433 0.85701021 0.80167598 0.88118812 0.77053571\n",
      " 0.63996044 0.56039076 0.80671414 0.57824427 0.59608209 0.46252465\n",
      " 0.82780083 0.66007533 0.46057692 0.34583715]\n",
      "mean_cluster_accuracy_during_training_cycle : 68.46%, post_traincycle_acc : 69.32%, total_acc : 68.73%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 81.80%\n",
      "accuracy_check 실행 시간: 22.283초\n",
      "\n",
      "epoch-41 loss : 0.03454\n",
      "ae train 실행 시간: 137.270초\n",
      "\n",
      "epoch-41 accuracy check\n",
      "cluster_accuracy_post_training_cycle_all_dataset [0.95062837 0.88324421 0.84029712 0.78119181 0.8950495  0.77767857\n",
      " 0.63204748 0.56927176 0.79857579 0.60209924 0.55130597 0.45069034\n",
      " 0.82676349 0.66760829 0.46442308 0.34400732]\n",
      "mean_cluster_accuracy_during_training_cycle : 68.51%, post_traincycle_acc : 68.97%, total_acc : 68.66%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 81.80%\n",
      "accuracy_check 실행 시간: 22.374초\n",
      "\n",
      "epoch-42 loss : 0.03385\n",
      "ae train 실행 시간: 138.061초\n",
      "\n",
      "epoch-42 accuracy check\n",
      "cluster_accuracy_post_training_cycle_all_dataset [0.95062837 0.88057041 0.81522748 0.79329609 0.9039604  0.77053571\n",
      " 0.6132542  0.52664298 0.80366226 0.58587786 0.56156716 0.4704142\n",
      " 0.82572614 0.6826742  0.47019231 0.34766697]\n",
      "mean_cluster_accuracy_during_training_cycle : 68.30%, post_traincycle_acc : 68.76%, total_acc : 68.45%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 81.80%\n",
      "accuracy_check 실행 시간: 22.815초\n",
      "\n",
      "epoch-43 loss : 0.03413\n",
      "ae train 실행 시간: 137.464초\n",
      "\n",
      "epoch-43 accuracy check\n",
      "cluster_accuracy_post_training_cycle_all_dataset [0.94524237 0.88146168 0.83751161 0.80353818 0.88811881 0.77767857\n",
      " 0.62908012 0.56127886 0.79348932 0.58015267 0.55690299 0.46252465\n",
      " 0.82053942 0.66195857 0.45961538 0.34217749]\n",
      "mean_cluster_accuracy_during_training_cycle : 68.35%, post_traincycle_acc : 68.76%, total_acc : 68.48%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 81.80%\n",
      "accuracy_check 실행 시간: 22.409초\n",
      "\n",
      "epoch-44 loss : 0.03398\n",
      "ae train 실행 시간: 137.880초\n",
      "\n",
      "epoch-44 accuracy check\n",
      "cluster_accuracy_post_training_cycle_all_dataset [0.9551167  0.88770053 0.85329619 0.78212291 0.88316832 0.74375\n",
      " 0.62611276 0.58348135 0.80467955 0.59160305 0.57835821 0.45463511\n",
      " 0.82157676 0.67890772 0.47596154 0.34400732]\n",
      "mean_cluster_accuracy_during_training_cycle : 68.34%, post_traincycle_acc : 69.15%, total_acc : 68.59%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 81.80%\n",
      "accuracy_check 실행 시간: 22.483초\n",
      "\n",
      "epoch-45 loss : 0.03384\n",
      "ae train 실행 시간: 136.925초\n",
      "\n",
      "epoch-45 accuracy check\n",
      "cluster_accuracy_post_training_cycle_all_dataset [0.95152603 0.89661319 0.84029712 0.7839851  0.88217822 0.73035714\n",
      " 0.6231454  0.55861456 0.79348932 0.59351145 0.55410448 0.46646943\n",
      " 0.82676349 0.66007533 0.46538462 0.33851784]\n",
      "mean_cluster_accuracy_during_training_cycle : 68.06%, post_traincycle_acc : 68.53%, total_acc : 68.21%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 81.80%\n",
      "accuracy_check 실행 시간: 22.407초\n",
      "\n",
      "epoch-46 loss : 0.03428\n",
      "ae train 실행 시간: 137.549초\n",
      "\n",
      "epoch-46 accuracy check\n",
      "cluster_accuracy_post_training_cycle_all_dataset [0.95152603 0.87611408 0.84308264 0.78212291 0.88217822 0.775\n",
      " 0.61523244 0.55417407 0.80671414 0.58778626 0.57742537 0.46745562\n",
      " 0.81327801 0.64030132 0.43846154 0.34400732]\n",
      "mean_cluster_accuracy_during_training_cycle : 68.24%, post_traincycle_acc : 68.47%, total_acc : 68.32%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 81.80%\n",
      "accuracy_check 실행 시간: 22.124초\n",
      "\n",
      "epoch-47 loss : 0.03509\n",
      "ae train 실행 시간: 138.590초\n",
      "\n",
      "epoch-47 accuracy check\n",
      "cluster_accuracy_post_training_cycle_all_dataset [0.95421903 0.90285205 0.81337047 0.80167598 0.90792079 0.78928571\n",
      " 0.64787339 0.56927176 0.81790437 0.58587786 0.57276119 0.44871795\n",
      " 0.81742739 0.69774011 0.49903846 0.35407136]\n",
      "mean_cluster_accuracy_during_training_cycle : 69.15%, post_traincycle_acc : 69.88%, total_acc : 69.37%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 81.80%\n",
      "accuracy_check 실행 시간: 22.489초\n",
      "\n",
      "epoch-48 loss : 0.03485\n",
      "ae train 실행 시간: 137.534초\n",
      "\n",
      "epoch-48 accuracy check\n",
      "cluster_accuracy_post_training_cycle_all_dataset [0.9497307  0.89661319 0.84958217 0.783054   0.87920792 0.73660714\n",
      " 0.62710188 0.54706927 0.79450661 0.57729008 0.5625     0.47238659\n",
      " 0.8246888  0.66290019 0.46153846 0.34858188]\n",
      "mean_cluster_accuracy_during_training_cycle : 67.75%, post_traincycle_acc : 68.58%, total_acc : 68.01%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 81.80%\n",
      "accuracy_check 실행 시간: 22.314초\n",
      "\n",
      "epoch-49 loss : 0.03372\n",
      "ae train 실행 시간: 138.167초\n",
      "\n",
      "epoch-49 accuracy check\n",
      "cluster_accuracy_post_training_cycle_all_dataset [0.9524237  0.90641711 0.85329619 0.78957169 0.8950495  0.77410714\n",
      " 0.64490603 0.54795737 0.80162767 0.58492366 0.54384328 0.47633136\n",
      " 0.82261411 0.69020716 0.45480769 0.34309241]\n",
      "mean_cluster_accuracy_during_training_cycle : 68.87%, post_traincycle_acc : 69.26%, total_acc : 68.99%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 81.80%\n",
      "accuracy_check 실행 시간: 22.641초\n",
      "\n",
      "epoch-50 loss : 0.03393\n",
      "ae train 실행 시간: 139.264초\n",
      "\n",
      "epoch-50 accuracy check\n",
      "cluster_accuracy_post_training_cycle_all_dataset [0.9551167  0.89661319 0.84122563 0.7858473  0.8980198  0.76696429\n",
      " 0.628091   0.54706927 0.79348932 0.58778626 0.5625     0.47633136\n",
      " 0.81431535 0.65819209 0.45192308 0.34034767]\n",
      "mean_cluster_accuracy_during_training_cycle : 68.30%, post_traincycle_acc : 68.77%, total_acc : 68.45%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 81.80%\n",
      "accuracy_check 실행 시간: 22.466초\n",
      "\n",
      "epoch-51 loss : 0.03365\n",
      "ae train 실행 시간: 137.901초\n",
      "\n",
      "epoch-51 accuracy check\n",
      "cluster_accuracy_post_training_cycle_all_dataset [0.95152603 0.89483066 0.83379759 0.79050279 0.9009901  0.77857143\n",
      " 0.66271019 0.55683837 0.79552391 0.59351145 0.54104478 0.48027613\n",
      " 0.84128631 0.66666667 0.45480769 0.35773102]\n",
      "mean_cluster_accuracy_during_training_cycle : 68.99%, post_traincycle_acc : 69.38%, total_acc : 69.11%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 81.80%\n",
      "accuracy_check 실행 시간: 22.203초\n",
      "\n",
      "epoch-52 loss : 0.03339\n",
      "ae train 실행 시간: 140.973초\n",
      "\n",
      "epoch-52 accuracy check\n",
      "cluster_accuracy_post_training_cycle_all_dataset [0.95691203 0.89037433 0.83101207 0.80260708 0.8990099  0.77767857\n",
      " 0.63996044 0.54618117 0.80366226 0.59351145 0.55410448 0.47928994\n",
      " 0.81120332 0.66384181 0.46634615 0.35224154]\n",
      "mean_cluster_accuracy_during_training_cycle : 68.95%, post_traincycle_acc : 69.17%, total_acc : 69.02%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 81.80%\n",
      "accuracy_check 실행 시간: 22.014초\n",
      "\n",
      "epoch-53 loss : 0.03377\n",
      "ae train 실행 시간: 138.638초\n",
      "\n",
      "epoch-53 accuracy check\n",
      "cluster_accuracy_post_training_cycle_all_dataset [0.96409336 0.9144385  0.90157846 0.85195531 0.92772277 0.80714286\n",
      " 0.68447082 0.58436945 0.8301119  0.66030534 0.54291045 0.47731755\n",
      " 0.84854772 0.68079096 0.50480769 0.34766697]\n",
      "mean_cluster_accuracy_during_training_cycle : 71.88%, post_traincycle_acc : 72.05%, total_acc : 71.93%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 81.80%\n",
      "accuracy_check 실행 시간: 22.657초\n",
      "\n",
      "epoch-54 loss : 0.03371\n",
      "ae train 실행 시간: 137.073초\n",
      "\n",
      "epoch-54 accuracy check\n",
      "cluster_accuracy_post_training_cycle_all_dataset [0.97037702 0.93315508 0.94057567 0.8547486  0.95445545 0.84196429\n",
      " 0.70919881 0.41119005 0.82400814 0.63740458 0.62033582 0.46646943\n",
      " 0.86929461 0.72316384 0.48557692 0.52698994]\n",
      "mean_cluster_accuracy_during_training_cycle : 73.30%, post_traincycle_acc : 73.56%, total_acc : 73.37%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 81.80%\n",
      "accuracy_check 실행 시간: 22.645초\n",
      "\n",
      "epoch-55 loss : 0.03362\n",
      "ae train 실행 시간: 138.580초\n",
      "\n",
      "epoch-55 accuracy check\n",
      "cluster_accuracy_post_training_cycle_all_dataset [0.96947935 0.93582888 0.93314763 0.87243948 0.95346535 0.85267857\n",
      " 0.73095945 0.57637655 0.83316378 0.65267176 0.58955224 0.4852071\n",
      " 0.88485477 0.74858757 0.48653846 0.48490393]\n",
      "mean_cluster_accuracy_during_training_cycle : 74.35%, post_traincycle_acc : 74.94%, total_acc : 74.53%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 81.80%\n",
      "accuracy_check 실행 시간: 21.963초\n",
      "\n",
      "epoch-56 loss : 0.03357\n",
      "ae train 실행 시간: 138.024초\n",
      "\n",
      "epoch-56 accuracy check\n",
      "cluster_accuracy_post_training_cycle_all_dataset [0.97127469 0.942959   0.93129062 0.84543762 0.94752475 0.81785714\n",
      " 0.70722057 0.51687389 0.83316378 0.53435115 0.57742537 0.49309665\n",
      " 0.86825726 0.74011299 0.47980769 0.50686185]\n",
      "mean_cluster_accuracy_during_training_cycle : 73.05%, post_traincycle_acc : 73.21%, total_acc : 73.10%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 81.80%\n",
      "accuracy_check 실행 시간: 22.515초\n",
      "\n",
      "epoch-57 loss : 0.03319\n",
      "ae train 실행 시간: 137.899초\n",
      "\n",
      "epoch-57 accuracy check\n",
      "cluster_accuracy_post_training_cycle_all_dataset [0.96947935 0.93939394 0.93779016 0.8566108  0.94554455 0.82321429\n",
      " 0.71018793 0.58348135 0.82909461 0.60591603 0.59701493 0.49408284\n",
      " 0.87344398 0.72222222 0.48076923 0.46203111]\n",
      "mean_cluster_accuracy_during_training_cycle : 74.45%, post_traincycle_acc : 73.94%, total_acc : 74.29%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 81.80%\n",
      "accuracy_check 실행 시간: 22.091초\n",
      "\n",
      "epoch-58 loss : 0.03338\n",
      "ae train 실행 시간: 138.107초\n",
      "\n",
      "epoch-58 accuracy check\n",
      "cluster_accuracy_post_training_cycle_all_dataset [0.97037702 0.93582888 0.93036212 0.8575419  0.96237624 0.83035714\n",
      " 0.72403561 0.36678508 0.83519837 0.64980916 0.58955224 0.48915187\n",
      " 0.8879668  0.72881356 0.45288462 0.47209515]\n",
      "mean_cluster_accuracy_during_training_cycle : 73.03%, post_traincycle_acc : 73.02%, total_acc : 73.02%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 81.80%\n",
      "accuracy_check 실행 시간: 22.612초\n",
      "\n",
      "epoch-59 loss : 0.03346\n",
      "ae train 실행 시간: 137.357초\n",
      "\n",
      "epoch-59 accuracy check\n",
      "cluster_accuracy_post_training_cycle_all_dataset [0.97127469 0.9456328  0.9275766  0.83985102 0.96138614 0.85714286\n",
      " 0.743818   0.56483126 0.82909461 0.66412214 0.59141791 0.51282051\n",
      " 0.86721992 0.72787194 0.47403846 0.50503202]\n",
      "mean_cluster_accuracy_during_training_cycle : 74.33%, post_traincycle_acc : 74.89%, total_acc : 74.50%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 81.80%\n",
      "accuracy_check 실행 시간: 22.420초\n",
      "\n",
      "epoch-60 loss : 0.03335\n",
      "ae train 실행 시간: 138.952초\n",
      "\n",
      "epoch-60 accuracy check\n",
      "cluster_accuracy_post_training_cycle_all_dataset [0.96947935 0.92959002 0.9275766  0.84078212 0.95445545 0.83482143\n",
      " 0.73194857 0.55772647 0.82604273 0.64026718 0.60261194 0.49112426\n",
      " 0.87136929 0.72975518 0.48461538 0.48673376]\n",
      "mean_cluster_accuracy_during_training_cycle : 74.28%, post_traincycle_acc : 74.24%, total_acc : 74.26%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 81.80%\n",
      "accuracy_check 실행 시간: 22.336초\n",
      "\n",
      "epoch-61 loss : 0.03326\n",
      "ae train 실행 시간: 139.417초\n",
      "\n",
      "epoch-61 accuracy check\n",
      "cluster_accuracy_post_training_cycle_all_dataset [0.97037702 0.9456328  0.93314763 0.8547486  0.95544554 0.8375\n",
      " 0.72304649 0.57460036 0.82807731 0.68225191 0.59981343 0.49704142\n",
      " 0.88278008 0.70433145 0.47019231 0.4967978 ]\n",
      "mean_cluster_accuracy_during_training_cycle : 74.53%, post_traincycle_acc : 74.72%, total_acc : 74.58%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 81.80%\n",
      "accuracy_check 실행 시간: 22.463초\n",
      "\n",
      "epoch-62 loss : 0.03373\n",
      "ae train 실행 시간: 138.981초\n",
      "\n",
      "epoch-62 accuracy check\n",
      "cluster_accuracy_post_training_cycle_all_dataset [0.96947935 0.94474153 0.93964717 0.86685289 0.95445545 0.85982143\n",
      " 0.69930762 0.59680284 0.83214649 0.66316794 0.56716418 0.49605523\n",
      " 0.89626556 0.71751412 0.48173077 0.36047575]\n",
      "mean_cluster_accuracy_during_training_cycle : 74.42%, post_traincycle_acc : 74.04%, total_acc : 74.30%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 81.80%\n",
      "accuracy_check 실행 시간: 22.555초\n",
      "\n",
      "epoch-63 loss : 0.03490\n",
      "ae train 실행 시간: 139.569초\n",
      "\n",
      "epoch-63 accuracy check\n",
      "cluster_accuracy_post_training_cycle_all_dataset [0.97217235 0.96613191 0.93314763 0.87057728 0.96435644 0.88035714\n",
      " 0.74480712 0.58436945 0.83926755 0.8148855  0.61007463 0.49211045\n",
      " 0.92427386 0.70338983 0.52980769 0.55718207]\n",
      "mean_cluster_accuracy_during_training_cycle : 76.58%, post_traincycle_acc : 77.42%, total_acc : 76.83%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 81.80%\n",
      "accuracy_check 실행 시간: 22.737초\n",
      "\n",
      "epoch-64 loss : 0.03522\n",
      "ae train 실행 시간: 138.810초\n",
      "\n",
      "epoch-64 accuracy check\n",
      "cluster_accuracy_post_training_cycle_all_dataset [0.97127469 0.95098039 0.93779016 0.87057728 0.94554455 0.84196429\n",
      " 0.71612265 0.5062167  0.85961343 0.74045802 0.63432836 0.49309665\n",
      " 0.89315353 0.71186441 0.48653846 0.52241537]\n",
      "mean_cluster_accuracy_during_training_cycle : 75.20%, post_traincycle_acc : 75.51%, total_acc : 75.29%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 81.80%\n",
      "accuracy_check 실행 시간: 23.168초\n",
      "\n",
      "epoch-65 loss : 0.03530\n",
      "ae train 실행 시간: 138.332초\n",
      "\n",
      "epoch-65 accuracy check\n",
      "cluster_accuracy_post_training_cycle_all_dataset [0.97217235 0.95811052 0.9452182  0.87616387 0.92475248 0.79196429\n",
      " 0.69238378 0.55328597 0.85045778 0.66125954 0.58022388 0.50493097\n",
      " 0.87448133 0.74011299 0.4875     0.49496798]\n",
      "mean_cluster_accuracy_during_training_cycle : 74.45%, post_traincycle_acc : 74.42%, total_acc : 74.44%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 81.80%\n",
      "accuracy_check 실행 시간: 22.592초\n",
      "\n",
      "epoch-66 loss : 0.03533\n",
      "ae train 실행 시간: 139.447초\n",
      "\n",
      "epoch-66 accuracy check\n",
      "cluster_accuracy_post_training_cycle_all_dataset [0.96858169 0.95187166 0.94057567 0.87709497 0.96039604 0.81964286\n",
      " 0.75469832 0.56394316 0.83723296 0.6898855  0.59514925 0.49704142\n",
      " 0.86825726 0.67043315 0.46826923 0.50228728]\n",
      "mean_cluster_accuracy_during_training_cycle : 74.74%, post_traincycle_acc : 74.78%, total_acc : 74.75%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 81.80%\n",
      "accuracy_check 실행 시간: 23.039초\n",
      "\n",
      "epoch-67 loss : 0.03480\n",
      "ae train 실행 시간: 139.307초\n",
      "\n",
      "epoch-67 accuracy check\n",
      "cluster_accuracy_post_training_cycle_all_dataset [0.96947935 0.92424242 0.92107707 0.84078212 0.9029703  0.80357143\n",
      " 0.67457962 0.39609236 0.80874873 0.64599237 0.60074627 0.48816568\n",
      " 0.83921162 0.72033898 0.46538462 0.51235133]\n",
      "mean_cluster_accuracy_during_training_cycle : 72.29%, post_traincycle_acc : 71.96%, total_acc : 72.19%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 81.80%\n",
      "accuracy_check 실행 시간: 22.701초\n",
      "\n",
      "epoch-68 loss : 0.03457\n",
      "ae train 실행 시간: 139.753초\n",
      "\n",
      "epoch-68 accuracy check\n",
      "cluster_accuracy_post_training_cycle_all_dataset [0.97217235 0.95008913 0.93593315 0.84357542 0.96732673 0.82410714\n",
      " 0.70722057 0.55772647 0.82604273 0.69083969 0.57182836 0.51282051\n",
      " 0.87136929 0.71186441 0.47788462 0.4894785 ]\n",
      "mean_cluster_accuracy_during_training_cycle : 73.34%, post_traincycle_acc : 74.44%, total_acc : 73.68%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 81.80%\n",
      "accuracy_check 실행 시간: 22.893초\n",
      "\n",
      "epoch-69 loss : 0.03492\n",
      "ae train 실행 시간: 137.295초\n",
      "\n",
      "epoch-69 accuracy check\n",
      "cluster_accuracy_post_training_cycle_all_dataset [0.96319569 0.95098039 0.9266481  0.86778399 0.95940594 0.79107143\n",
      " 0.71216617 0.55772647 0.85961343 0.69370229 0.58675373 0.50197239\n",
      " 0.87033195 0.75047081 0.49038462 0.42360476]\n",
      "mean_cluster_accuracy_during_training_cycle : 74.85%, post_traincycle_acc : 74.41%, total_acc : 74.71%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 81.80%\n",
      "accuracy_check 실행 시간: 22.579초\n",
      "\n",
      "epoch-70 loss : 0.03438\n",
      "ae train 실행 시간: 138.445초\n",
      "\n",
      "epoch-70 accuracy check\n",
      "cluster_accuracy_post_training_cycle_all_dataset [0.95691203 0.95365419 0.93593315 0.8603352  0.96039604 0.82232143\n",
      " 0.72403561 0.56305506 0.8474059  0.67748092 0.59794776 0.49408284\n",
      " 0.85684647 0.75329567 0.4875     0.3989021 ]\n",
      "mean_cluster_accuracy_during_training_cycle : 74.90%, post_traincycle_acc : 74.31%, total_acc : 74.72%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 81.80%\n",
      "accuracy_check 실행 시간: 22.697초\n",
      "\n",
      "epoch-71 loss : 0.03468\n",
      "ae train 실행 시간: 139.397초\n",
      "\n",
      "epoch-71 accuracy check\n",
      "cluster_accuracy_post_training_cycle_all_dataset [0.96947935 0.93850267 0.92571959 0.86219739 0.95346535 0.81875\n",
      " 0.72403561 0.59325044 0.86571719 0.65267176 0.58675373 0.50098619\n",
      " 0.84543568 0.75141243 0.49326923 0.47026532]\n",
      "mean_cluster_accuracy_during_training_cycle : 74.96%, post_traincycle_acc : 74.70%, total_acc : 74.88%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 81.80%\n",
      "accuracy_check 실행 시간: 22.742초\n",
      "\n",
      "epoch-72 loss : 0.03448\n",
      "ae train 실행 시간: 139.287초\n",
      "\n",
      "epoch-72 accuracy check\n",
      "cluster_accuracy_post_training_cycle_all_dataset [0.97127469 0.93493761 0.91829155 0.86499069 0.95445545 0.82321429\n",
      " 0.73689416 0.56216696 0.84231943 0.6851145  0.58768657 0.46844181\n",
      " 0.83609959 0.72787194 0.48557692 0.47026532]\n",
      "mean_cluster_accuracy_during_training_cycle : 74.45%, post_traincycle_acc : 74.19%, total_acc : 74.37%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 81.80%\n",
      "accuracy_check 실행 시간: 22.997초\n",
      "\n",
      "epoch-73 loss : 0.03451\n",
      "ae train 실행 시간: 138.307초\n",
      "\n",
      "epoch-73 accuracy check\n",
      "cluster_accuracy_post_training_cycle_all_dataset [0.97307002 0.95543672 0.93500464 0.89013035 0.96831683 0.84375\n",
      " 0.7586548  0.56127886 0.8646999  0.75763359 0.61100746 0.52366864\n",
      " 0.87966805 0.74387947 0.52884615 0.46111619]\n",
      "mean_cluster_accuracy_during_training_cycle : 75.64%, post_traincycle_acc : 76.60%, total_acc : 75.93%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 81.80%\n",
      "accuracy_check 실행 시간: 22.893초\n",
      "\n",
      "epoch-74 loss : 0.03429\n",
      "ae train 실행 시간: 138.818초\n",
      "\n",
      "epoch-74 accuracy check\n",
      "cluster_accuracy_post_training_cycle_all_dataset [0.97037702 0.93493761 0.92293408 0.86871508 0.95049505 0.81696429\n",
      " 0.74183976 0.56660746 0.8636826  0.71660305 0.59794776 0.49605523\n",
      " 0.87551867 0.73822976 0.45480769 0.49496798]\n",
      "mean_cluster_accuracy_during_training_cycle : 75.02%, post_traincycle_acc : 75.07%, total_acc : 75.03%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 81.80%\n",
      "accuracy_check 실행 시간: 22.534초\n",
      "\n",
      "epoch-75 loss : 0.03400\n",
      "ae train 실행 시간: 138.713초\n",
      "\n",
      "epoch-75 accuracy check\n",
      "cluster_accuracy_post_training_cycle_all_dataset [0.96947935 0.94741533 0.91272052 0.85009311 0.96336634 0.84196429\n",
      " 0.73689416 0.56927176 0.85656155 0.73187023 0.62873134 0.48126233\n",
      " 0.87655602 0.7212806  0.48076923 0.22049405]\n",
      "mean_cluster_accuracy_during_training_cycle : 74.12%, post_traincycle_acc : 73.68%, total_acc : 73.97%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 81.80%\n",
      "accuracy_check 실행 시간: 22.618초\n",
      "\n",
      "epoch-76 loss : 0.03368\n",
      "ae train 실행 시간: 139.263초\n",
      "\n",
      "epoch-76 accuracy check\n",
      "cluster_accuracy_post_training_cycle_all_dataset [0.96678636 0.93137255 0.91922006 0.84729981 0.95346535 0.82053571\n",
      " 0.70524233 0.63854352 0.81485249 0.58778626 0.60261194 0.47731755\n",
      " 0.87033195 0.72410546 0.46153846 0.46477585]\n",
      "mean_cluster_accuracy_during_training_cycle : 72.63%, post_traincycle_acc : 73.66%, total_acc : 72.96%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 81.80%\n",
      "accuracy_check 실행 시간: 22.665초\n",
      "\n",
      "epoch-77 loss : 0.03462\n",
      "ae train 실행 시간: 137.567초\n",
      "\n",
      "epoch-77 accuracy check\n",
      "cluster_accuracy_post_training_cycle_all_dataset [0.97127469 0.95721925 0.94243268 0.86685289 0.95148515 0.85625\n",
      " 0.73986152 0.56571936 0.86571719 0.76812977 0.58115672 0.48619329\n",
      " 0.84232365 0.71939736 0.49038462 0.47301006]\n",
      "mean_cluster_accuracy_during_training_cycle : 75.14%, post_traincycle_acc : 75.48%, total_acc : 75.24%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 81.80%\n",
      "accuracy_check 실행 시간: 22.853초\n",
      "\n",
      "epoch-78 loss : 0.03425\n",
      "ae train 실행 시간: 140.611초\n",
      "\n",
      "epoch-78 accuracy check\n",
      "cluster_accuracy_post_training_cycle_all_dataset [0.96588869 0.95721925 0.93593315 0.86871508 0.93861386 0.84464286\n",
      " 0.76162216 0.55150977 0.85656155 0.6889313  0.58488806 0.51282051\n",
      " 0.83609959 0.76836158 0.48365385 0.43732845]\n",
      "mean_cluster_accuracy_during_training_cycle : 75.17%, post_traincycle_acc : 74.95%, total_acc : 75.11%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 81.80%\n",
      "accuracy_check 실행 시간: 22.657초\n",
      "\n",
      "epoch-79 loss : 0.03416\n",
      "ae train 실행 시간: 139.438초\n",
      "\n",
      "epoch-79 accuracy check\n",
      "cluster_accuracy_post_training_cycle_all_dataset [0.96858169 0.95811052 0.95264624 0.89664804 0.94356436 0.85089286\n",
      " 0.75667656 0.56571936 0.87080366 0.73473282 0.55783582 0.49211045\n",
      " 0.87966805 0.73163842 0.48846154 0.4473925 ]\n",
      "mean_cluster_accuracy_during_training_cycle : 75.99%, post_traincycle_acc : 75.60%, total_acc : 75.87%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 81.80%\n",
      "accuracy_check 실행 시간: 23.236초\n",
      "\n",
      "epoch-80 loss : 0.03423\n",
      "ae train 실행 시간: 138.322초\n",
      "\n",
      "epoch-80 accuracy check\n",
      "cluster_accuracy_post_training_cycle_all_dataset [0.97127469 0.96434938 0.92850511 0.87709497 0.94950495 0.82767857\n",
      " 0.73194857 0.42717584 0.83825025 0.70324427 0.56902985 0.48422091\n",
      " 0.88381743 0.76647834 0.46923077 0.46111619]\n",
      "mean_cluster_accuracy_during_training_cycle : 74.60%, post_traincycle_acc : 74.08%, total_acc : 74.44%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 81.80%\n",
      "accuracy_check 실행 시간: 22.510초\n",
      "\n",
      "epoch-81 loss : 0.03325\n",
      "ae train 실행 시간: 138.338초\n",
      "\n",
      "epoch-81 accuracy check\n",
      "cluster_accuracy_post_training_cycle_all_dataset [0.97037702 0.92959002 0.92850511 0.86405959 0.95643564 0.82946429\n",
      " 0.72799209 0.55772647 0.81688708 0.5601145  0.60820896 0.49112426\n",
      " 0.86618257 0.74670433 0.47211538 0.56450137]\n",
      "mean_cluster_accuracy_during_training_cycle : 73.89%, post_traincycle_acc : 74.31%, total_acc : 74.02%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 81.80%\n",
      "accuracy_check 실행 시간: 22.564초\n",
      "\n",
      "epoch-82 loss : 0.03307\n",
      "ae train 실행 시간: 139.098초\n",
      "\n",
      "epoch-82 accuracy check\n",
      "cluster_accuracy_post_training_cycle_all_dataset [0.97127469 0.9402852  0.93129062 0.84264432 0.95742574 0.85446429\n",
      " 0.73590504 0.58170515 0.82604273 0.63263359 0.59794776 0.49112426\n",
      " 0.85995851 0.73917137 0.46057692 0.46660567]\n",
      "mean_cluster_accuracy_during_training_cycle : 74.25%, post_traincycle_acc : 74.31%, total_acc : 74.26%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 81.80%\n",
      "accuracy_check 실행 시간: 22.376초\n",
      "\n",
      "epoch-83 loss : 0.03320\n",
      "ae train 실행 시간: 138.814초\n",
      "\n",
      "epoch-83 accuracy check\n",
      "cluster_accuracy_post_training_cycle_all_dataset [0.97217235 0.93315508 0.92850511 0.858473   0.95544554 0.83303571\n",
      " 0.70722057 0.57548845 0.82197355 0.58015267 0.59048507 0.49013807\n",
      " 0.87136929 0.72316384 0.46442308 0.49130833]\n",
      "mean_cluster_accuracy_during_training_cycle : 73.73%, post_traincycle_acc : 73.73%, total_acc : 73.73%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 81.80%\n",
      "accuracy_check 실행 시간: 23.081초\n",
      "\n",
      "epoch-84 loss : 0.03306\n",
      "ae train 실행 시간: 139.783초\n",
      "\n",
      "epoch-84 accuracy check\n",
      "cluster_accuracy_post_training_cycle_all_dataset [0.96858169 0.91265597 0.92107707 0.83426443 0.94851485 0.82767857\n",
      " 0.73986152 0.56927176 0.82095626 0.55916031 0.55223881 0.47928994\n",
      " 0.87551867 0.73446328 0.46730769 0.46660567]\n",
      "mean_cluster_accuracy_during_training_cycle : 72.90%, post_traincycle_acc : 72.98%, total_acc : 72.93%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 81.80%\n",
      "accuracy_check 실행 시간: 22.543초\n",
      "\n",
      "epoch-85 loss : 0.03299\n",
      "ae train 실행 시간: 139.108초\n",
      "\n",
      "epoch-85 accuracy check\n",
      "cluster_accuracy_post_training_cycle_all_dataset [0.96947935 0.92869875 0.92479109 0.83985102 0.95643564 0.84553571\n",
      " 0.72502473 0.68383659 0.82400814 0.64694656 0.57835821 0.47928994\n",
      " 0.86929461 0.73446328 0.46442308 0.51875572]\n",
      "mean_cluster_accuracy_during_training_cycle : 73.60%, post_traincycle_acc : 74.93%, total_acc : 74.02%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 81.80%\n",
      "accuracy_check 실행 시간: 22.364초\n",
      "\n",
      "epoch-86 loss : 0.03324\n",
      "ae train 실행 시간: 138.895초\n",
      "\n",
      "epoch-86 accuracy check\n",
      "cluster_accuracy_post_training_cycle_all_dataset [0.96947935 0.92424242 0.93407614 0.8594041  0.95940594 0.85178571\n",
      " 0.7487636  0.70159858 0.81688708 0.6240458  0.57276119 0.50197239\n",
      " 0.88278008 0.73163842 0.47403846 0.49862763]\n",
      "mean_cluster_accuracy_during_training_cycle : 73.90%, post_traincycle_acc : 75.32%, total_acc : 74.35%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 81.80%\n",
      "accuracy_check 실행 시간: 22.748초\n",
      "\n",
      "epoch-87 loss : 0.03327\n",
      "ae train 실행 시간: 137.978초\n",
      "\n",
      "epoch-87 accuracy check\n",
      "cluster_accuracy_post_training_cycle_all_dataset [0.97127469 0.9197861  0.92850511 0.84916201 0.95544554 0.85\n",
      " 0.743818   0.6749556  0.82400814 0.68225191 0.56343284 0.45463511\n",
      " 0.89211618 0.72033898 0.48173077 0.46111619]\n",
      "mean_cluster_accuracy_during_training_cycle : 73.78%, post_traincycle_acc : 74.83%, total_acc : 74.11%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 81.80%\n",
      "accuracy_check 실행 시간: 22.301초\n",
      "\n",
      "epoch-88 loss : 0.03345\n",
      "ae train 실행 시간: 137.283초\n",
      "\n",
      "epoch-88 accuracy check\n",
      "cluster_accuracy_post_training_cycle_all_dataset [0.97127469 0.92691622 0.92943361 0.85009311 0.95643564 0.84464286\n",
      " 0.73986152 0.56305506 0.81180061 0.64026718 0.5858209  0.47238659\n",
      " 0.88692946 0.70998117 0.48269231 0.43915828]\n",
      "mean_cluster_accuracy_during_training_cycle : 73.23%, post_traincycle_acc : 73.82%, total_acc : 73.41%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 81.80%\n",
      "accuracy_check 실행 시간: 22.452초\n",
      "\n",
      "epoch-89 loss : 0.03338\n",
      "ae train 실행 시간: 138.393초\n",
      "\n",
      "epoch-89 accuracy check\n",
      "cluster_accuracy_post_training_cycle_all_dataset [0.96858169 0.93493761 0.92850511 0.86126629 0.94752475 0.82946429\n",
      " 0.72403561 0.54618117 0.81078332 0.61164122 0.58115672 0.50098619\n",
      " 0.87240664 0.7259887  0.47884615 0.48581885]\n",
      "mean_cluster_accuracy_during_training_cycle : 73.77%, post_traincycle_acc : 73.80%, total_acc : 73.78%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 81.80%\n",
      "accuracy_check 실행 시간: 22.386초\n",
      "\n",
      "epoch-90 loss : 0.03372\n",
      "ae train 실행 시간: 138.395초\n",
      "\n",
      "epoch-90 accuracy check\n",
      "cluster_accuracy_post_training_cycle_all_dataset [0.97307002 0.92513369 0.93036212 0.84636872 0.95742574 0.82946429\n",
      " 0.73689416 0.56749556 0.81485249 0.61164122 0.60820896 0.46646943\n",
      " 0.86825726 0.72316384 0.46826923 0.39615737]\n",
      "mean_cluster_accuracy_during_training_cycle : 72.80%, post_traincycle_acc : 73.27%, total_acc : 72.95%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 81.80%\n",
      "accuracy_check 실행 시간: 22.571초\n",
      "\n",
      "epoch-91 loss : 0.03366\n",
      "ae train 실행 시간: 135.974초\n",
      "\n",
      "epoch-91 accuracy check\n",
      "cluster_accuracy_post_training_cycle_all_dataset [0.97037702 0.93137255 0.92943361 0.83985102 0.94950495 0.85625\n",
      " 0.71810089 0.54618117 0.82095626 0.69179389 0.59141791 0.48717949\n",
      " 0.88070539 0.72033898 0.44615385 0.45928637]\n",
      "mean_cluster_accuracy_during_training_cycle : 73.54%, post_traincycle_acc : 73.99%, total_acc : 73.68%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 81.80%\n",
      "accuracy_check 실행 시간: 22.700초\n",
      "\n",
      "epoch-92 loss : 0.03329\n",
      "ae train 실행 시간: 138.384초\n",
      "\n",
      "epoch-92 accuracy check\n",
      "cluster_accuracy_post_training_cycle_all_dataset [0.97217235 0.93404635 0.9266481  0.81284916 0.95544554 0.84464286\n",
      " 0.71018793 0.54973357 0.82400814 0.6240458  0.59235075 0.46449704\n",
      " 0.84854772 0.69585687 0.44903846 0.37694419]\n",
      "mean_cluster_accuracy_during_training_cycle : 72.40%, post_traincycle_acc : 72.38%, total_acc : 72.39%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 81.80%\n",
      "accuracy_check 실행 시간: 22.751초\n",
      "\n",
      "epoch-93 loss : 0.03435\n",
      "ae train 실행 시간: 138.564초\n",
      "\n",
      "epoch-93 accuracy check\n",
      "cluster_accuracy_post_training_cycle_all_dataset [0.97307002 0.93582888 0.93314763 0.79981378 0.95148515 0.84732143\n",
      " 0.72997033 0.63143872 0.83621567 0.66316794 0.59328358 0.47830375\n",
      " 0.84958506 0.74576271 0.51826923 0.40805124]\n",
      "mean_cluster_accuracy_during_training_cycle : 73.45%, post_traincycle_acc : 74.34%, total_acc : 73.73%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 81.80%\n",
      "accuracy_check 실행 시간: 22.736초\n",
      "\n",
      "epoch-94 loss : 0.03414\n",
      "ae train 실행 시간: 140.488초\n",
      "\n",
      "epoch-94 accuracy check\n",
      "cluster_accuracy_post_training_cycle_all_dataset [0.97217235 0.942959   0.9266481  0.81471136 0.95049505 0.84642857\n",
      " 0.73491592 0.51154529 0.82197355 0.59446565 0.60820896 0.47337278\n",
      " 0.87448133 0.72410546 0.50769231 0.45928637]\n",
      "mean_cluster_accuracy_during_training_cycle : 72.71%, post_traincycle_acc : 73.52%, total_acc : 72.96%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 81.80%\n",
      "accuracy_check 실행 시간: 23.043초\n",
      "\n",
      "epoch-95 loss : 0.03344\n",
      "ae train 실행 시간: 139.788초\n",
      "\n",
      "epoch-95 accuracy check\n",
      "cluster_accuracy_post_training_cycle_all_dataset [0.97396768 0.95365419 0.94150418 0.83612663 0.95841584 0.84285714\n",
      " 0.76656775 0.55328597 0.84435402 0.68129771 0.60914179 0.47928994\n",
      " 0.86099585 0.6826742  0.48942308 0.4336688 ]\n",
      "mean_cluster_accuracy_during_training_cycle : 74.08%, post_traincycle_acc : 74.42%, total_acc : 74.18%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 81.80%\n",
      "accuracy_check 실행 시간: 22.919초\n",
      "\n",
      "epoch-96 loss : 0.03387\n",
      "ae train 실행 시간: 138.348초\n",
      "\n",
      "epoch-96 accuracy check\n",
      "cluster_accuracy_post_training_cycle_all_dataset [0.97396768 0.94385027 0.93221913 0.80819367 0.95544554 0.83035714\n",
      " 0.73590504 0.69094139 0.84028484 0.58015267 0.57649254 0.46055227\n",
      " 0.83921162 0.70244821 0.48557692 0.44830741]\n",
      "mean_cluster_accuracy_during_training_cycle : 72.36%, post_traincycle_acc : 73.77%, total_acc : 72.81%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 81.80%\n",
      "accuracy_check 실행 시간: 22.713초\n",
      "\n",
      "epoch-97 loss : 0.03365\n",
      "ae train 실행 시간: 137.342초\n",
      "\n",
      "epoch-97 accuracy check\n",
      "cluster_accuracy_post_training_cycle_all_dataset [0.97217235 0.94206774 0.93686165 0.79888268 0.96237624 0.83303571\n",
      " 0.73095945 0.69182948 0.83825025 0.59637405 0.59328358 0.45956607\n",
      " 0.84958506 0.68926554 0.50769231 0.3147301 ]\n",
      "mean_cluster_accuracy_during_training_cycle : 72.86%, post_traincycle_acc : 73.23%, total_acc : 72.98%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 81.80%\n",
      "accuracy_check 실행 시간: 22.340초\n",
      "\n",
      "epoch-98 loss : 0.03389\n",
      "ae train 실행 시간: 139.529초\n",
      "\n",
      "epoch-98 accuracy check\n",
      "cluster_accuracy_post_training_cycle_all_dataset [0.97396768 0.95098039 0.92571959 0.78957169 0.95445545 0.85089286\n",
      " 0.75766568 0.70071048 0.84028484 0.61641221 0.58395522 0.42406312\n",
      " 0.86307054 0.70338983 0.49134615 0.36870997]\n",
      "mean_cluster_accuracy_during_training_cycle : 73.22%, post_traincycle_acc : 73.72%, total_acc : 73.38%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 81.80%\n",
      "accuracy_check 실행 시간: 22.391초\n",
      "\n",
      "epoch-99 loss : 0.03363\n",
      "ae train 실행 시간: 139.657초\n",
      "\n",
      "epoch-99 accuracy check\n",
      "cluster_accuracy_post_training_cycle_all_dataset [0.97396768 0.95098039 0.92386258 0.81284916 0.95841584 0.83392857\n",
      " 0.74579624 0.6722913  0.82604273 0.58778626 0.60634328 0.43984221\n",
      " 0.86099585 0.70527307 0.48269231 0.3494968 ]\n",
      "mean_cluster_accuracy_during_training_cycle : 72.90%, post_traincycle_acc : 73.32%, total_acc : 73.03%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 81.80%\n",
      "accuracy_check 실행 시간: 22.272초\n",
      "\n",
      "epoch-100 loss : 0.03372\n",
      "ae train 실행 시간: 138.373초\n",
      "\n",
      "epoch-100 accuracy check\n",
      "cluster_accuracy_post_training_cycle_all_dataset [0.97307002 0.9483066  0.93500464 0.80074488 0.96336634 0.85\n",
      " 0.75173096 0.57904085 0.84638861 0.62881679 0.58675373 0.44970414\n",
      " 0.8879668  0.70903955 0.50288462 0.31838975]\n",
      "mean_cluster_accuracy_during_training_cycle : 73.15%, post_traincycle_acc : 73.32%, total_acc : 73.20%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 81.80%\n",
      "accuracy_check 실행 시간: 22.717초\n",
      "\n",
      "epoch-101 loss : 0.03371\n",
      "ae train 실행 시간: 140.739초\n",
      "\n",
      "epoch-101 accuracy check\n",
      "cluster_accuracy_post_training_cycle_all_dataset [0.97307002 0.95008913 0.93407614 0.82122905 0.96039604 0.85982143\n",
      " 0.73986152 0.69005329 0.84537131 0.63645038 0.5988806  0.43491124\n",
      " 0.85062241 0.69679849 0.48461538 0.46203111]\n",
      "mean_cluster_accuracy_during_training_cycle : 73.40%, post_traincycle_acc : 74.61%, total_acc : 73.79%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 81.80%\n",
      "accuracy_check 실행 시간: 22.839초\n",
      "\n",
      "epoch-102 loss : 0.03373\n",
      "ae train 실행 시간: 139.446초\n",
      "\n",
      "epoch-102 accuracy check\n",
      "cluster_accuracy_post_training_cycle_all_dataset [0.97396768 0.9456328  0.93129062 0.80726257 0.95643564 0.84285714\n",
      " 0.74183976 0.53996448 0.82706002 0.64980916 0.59701493 0.43491124\n",
      " 0.87344398 0.69774011 0.49615385 0.50503202]\n",
      "mean_cluster_accuracy_during_training_cycle : 73.18%, post_traincycle_acc : 73.88%, total_acc : 73.40%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 81.80%\n",
      "accuracy_check 실행 시간: 22.833초\n",
      "\n",
      "epoch-103 loss : 0.03408\n",
      "ae train 실행 시간: 139.689초\n",
      "\n",
      "epoch-103 accuracy check\n",
      "cluster_accuracy_post_training_cycle_all_dataset [0.97307002 0.94652406 0.93407614 0.81098696 0.95247525 0.83571429\n",
      " 0.74282888 0.56483126 0.83723296 0.65935115 0.59608209 0.45069034\n",
      " 0.85995851 0.71845574 0.52019231 0.33668801]\n",
      "mean_cluster_accuracy_during_training_cycle : 73.22%, post_traincycle_acc : 73.37%, total_acc : 73.26%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 81.80%\n",
      "accuracy_check 실행 시간: 22.603초\n",
      "\n",
      "epoch-104 loss : 0.03375\n",
      "ae train 실행 시간: 139.060초\n",
      "\n",
      "epoch-104 accuracy check\n",
      "cluster_accuracy_post_training_cycle_all_dataset [0.97217235 0.92602496 0.92293408 0.7886406  0.96039604 0.81964286\n",
      " 0.7388724  0.71047957 0.84231943 0.63358779 0.59981343 0.46449704\n",
      " 0.8526971  0.6920904  0.47980769 0.38792315]\n",
      "mean_cluster_accuracy_during_training_cycle : 72.19%, post_traincycle_acc : 73.70%, total_acc : 72.66%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 81.80%\n",
      "accuracy_check 실행 시간: 22.964초\n",
      "\n",
      "epoch-105 loss : 0.03362\n",
      "ae train 실행 시간: 137.615초\n",
      "\n",
      "epoch-105 accuracy check\n",
      "cluster_accuracy_post_training_cycle_all_dataset [0.97037702 0.94919786 0.93500464 0.80633147 0.95247525 0.80357143\n",
      " 0.72997033 0.42984014 0.83519837 0.60973282 0.59421642 0.45069034\n",
      " 0.8620332  0.7354049  0.50769231 0.37877402]\n",
      "mean_cluster_accuracy_during_training_cycle : 72.51%, post_traincycle_acc : 72.19%, total_acc : 72.40%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 81.80%\n",
      "accuracy_check 실행 시간: 22.457초\n",
      "\n",
      "epoch-106 loss : 0.03349\n",
      "ae train 실행 시간: 139.721초\n",
      "\n",
      "epoch-106 accuracy check\n",
      "cluster_accuracy_post_training_cycle_all_dataset [0.97217235 0.93048128 0.92386258 0.79329609 0.94950495 0.82946429\n",
      " 0.74480712 0.57726465 0.81892167 0.62022901 0.6016791  0.44970414\n",
      " 0.85580913 0.72410546 0.50769231 0.3147301 ]\n",
      "mean_cluster_accuracy_during_training_cycle : 72.28%, post_traincycle_acc : 72.59%, total_acc : 72.38%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 81.80%\n",
      "accuracy_check 실행 시간: 22.975초\n",
      "\n",
      "epoch-107 loss : 0.03358\n",
      "ae train 실행 시간: 139.685초\n",
      "\n",
      "epoch-107 accuracy check\n",
      "cluster_accuracy_post_training_cycle_all_dataset [0.97127469 0.93850267 0.9275766  0.79702048 0.95247525 0.83214286\n",
      " 0.74579624 0.65808171 0.83214649 0.61164122 0.59514925 0.45857988\n",
      " 0.86514523 0.68361582 0.51346154 0.31747484]\n",
      "mean_cluster_accuracy_during_training_cycle : 72.40%, post_traincycle_acc : 73.13%, total_acc : 72.63%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 81.80%\n",
      "accuracy_check 실행 시간: 22.753초\n",
      "\n",
      "epoch-108 loss : 0.03341\n",
      "ae train 실행 시간: 139.453초\n",
      "\n",
      "epoch-108 accuracy check\n",
      "cluster_accuracy_post_training_cycle_all_dataset [0.97127469 0.94117647 0.92386258 0.79515829 0.95049505 0.83303571\n",
      " 0.73194857 0.67761989 0.82604273 0.51145038 0.59981343 0.46351085\n",
      " 0.87344398 0.70056497 0.52307692 0.46935041]\n",
      "mean_cluster_accuracy_during_training_cycle : 72.45%, post_traincycle_acc : 73.70%, total_acc : 72.84%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 81.80%\n",
      "accuracy_check 실행 시간: 23.099초\n",
      "\n",
      "epoch-109 loss : 0.03329\n",
      "ae train 실행 시간: 140.574초\n",
      "\n",
      "epoch-109 accuracy check\n",
      "cluster_accuracy_post_training_cycle_all_dataset [0.97217235 0.942959   0.91550604 0.79050279 0.95346535 0.86607143\n",
      " 0.75667656 0.52309059 0.82807731 0.59637405 0.60354478 0.4566075\n",
      " 0.85788382 0.70621469 0.51346154 0.44373285]\n",
      "mean_cluster_accuracy_during_training_cycle : 73.15%, post_traincycle_acc : 73.29%, total_acc : 73.19%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 81.80%\n",
      "accuracy_check 실행 시간: 22.853초\n",
      "\n",
      "epoch-110 loss : 0.03330\n",
      "ae train 실행 시간: 140.852초\n",
      "\n",
      "epoch-110 accuracy check\n",
      "cluster_accuracy_post_training_cycle_all_dataset [0.97396768 0.93850267 0.92014856 0.7858473  0.96039604 0.86428571\n",
      " 0.73293769 0.71403197 0.83418108 0.52767176 0.59701493 0.43589744\n",
      " 0.86618257 0.72222222 0.51153846 0.35773102]\n",
      "mean_cluster_accuracy_during_training_cycle : 72.73%, post_traincycle_acc : 73.39%, total_acc : 72.95%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 81.80%\n",
      "accuracy_check 실행 시간: 22.561초\n",
      "\n",
      "epoch-111 loss : 0.03452\n",
      "ae train 실행 시간: 138.821초\n",
      "\n",
      "epoch-111 accuracy check\n",
      "cluster_accuracy_post_training_cycle_all_dataset [0.97217235 0.95454545 0.92850511 0.82402235 0.95445545 0.84642857\n",
      " 0.74777448 0.56838366 0.84130214 0.62881679 0.60447761 0.46548323\n",
      " 0.84647303 0.69303202 0.47980769 0.49588289]\n",
      "mean_cluster_accuracy_during_training_cycle : 72.64%, post_traincycle_acc : 74.07%, total_acc : 73.09%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 81.80%\n",
      "accuracy_check 실행 시간: 22.985초\n",
      "\n",
      "epoch-112 loss : 0.03401\n",
      "ae train 실행 시간: 140.086초\n",
      "\n",
      "epoch-112 accuracy check\n",
      "cluster_accuracy_post_training_cycle_all_dataset [0.97307002 0.94117647 0.93686165 0.82029795 0.95049505 0.84464286\n",
      " 0.7586548  0.53285968 0.8311292  0.63645038 0.60074627 0.46646943\n",
      " 0.85580913 0.69774011 0.49423077 0.38151876]\n",
      "mean_cluster_accuracy_during_training_cycle : 72.85%, post_traincycle_acc : 73.26%, total_acc : 72.98%\n",
      "best_mean_cluster_accuracy_post_training_cycle_all_dataset : 81.80%\n",
      "accuracy_check 실행 시간: 22.417초\n"
     ]
    }
   ],
   "source": [
    "\n",
    "gpu = 2\n",
    "Conv_net = True\n",
    "SAE_net = True\n",
    "\n",
    "# hyperparameter\n",
    "dataset_num = 16\n",
    "spike_length = 50 # coarse_com_mode일 때는 time step이 됨.\n",
    "num_cluster = 4  # 클러스터 수 설정 # 논문엔 4개라는데 여기서는 3개로 했네\n",
    "training_cycle = 2400 #1400 2400 # 그 초기 몇개까지만 cluster update할지\n",
    "\n",
    "\n",
    "batch_size = 48\n",
    "max_epoch = 7000\n",
    "learning_rate = 0.0001\n",
    "normalize_on = False # True or False #이거 안 씀 # 이거 별로 안 좋은 normalize같음 # 쓸 거면 다른 거 써라.\n",
    "need_bias = False\n",
    "# first_layer_no_train = False\n",
    "lif_add_at_first = False\n",
    "my_seed = 42\n",
    "\n",
    "TIME = 50 # SAE일 때만 유효. coarse_com_mode일 때는 level_num이 됨. 즉 feature 개수.\n",
    "v_decay = 0.25 # -cor\n",
    "v_threshold = 0.5 # -cor\n",
    "v_reset = 10000.0 # -cor # 10000이상 일 시 hard reset\n",
    "BPTT_on = False # +cor\n",
    "\n",
    "SAE_hidden_nomean = True # True False\n",
    "\n",
    "current_time = datetime.datetime.now().strftime(\"%Y%m%d_%H%M%S\") + f\"_{str(int(datetime.datetime.now().microsecond / 1000)).zfill(3)}\"\n",
    "\n",
    "optimizer = 'Adam' #'Adam', 'SGD' # 둘다 준수함. loss 줄이는 거는 adam이 좋긴한데, cluster accuracy는 비슷함.\n",
    "\n",
    "coarse_com_mode = True\n",
    "coarse_com_config = (3.0, -3.0) # (max, min) (2.0, -2.0) (3.0, -3.0)\n",
    "\n",
    "sae_l2_norm_bridge = False # True False\n",
    "sae_lif_bridge = True # False True\n",
    "\n",
    "accuracy_check_epoch_term = 1\n",
    "    \n",
    "lif_add_at_last = True # True False\n",
    "\n",
    "two_channel_input = True # True False\n",
    "\n",
    "wandb.init(project= f'spike_sorting just run',save_code=False)\n",
    "\n",
    "\n",
    "cluster_train_system( \n",
    "    gpu = gpu,\n",
    "    Conv_net = Conv_net,\n",
    "    SAE_net = SAE_net,\n",
    "\n",
    "    # hyperparameter\n",
    "    dataset_num = dataset_num,\n",
    "    spike_length = spike_length,\n",
    "    num_cluster = num_cluster,  # 클러스터 수 설정 # 논문엔 4개라는데 여기서는 3개로 했네\n",
    "    training_cycle = training_cycle, # 그 초기 몇개까지만 cluster update할지\n",
    "\n",
    "\n",
    "    batch_size = batch_size,\n",
    "    max_epoch = max_epoch,\n",
    "    learning_rate = learning_rate,\n",
    "    normalize_on = normalize_on, # True or False #이거 안 씀 # 이거 별로 안 좋은 normalize같음 # 쓸 거면 다른 거 써라.\n",
    "    need_bias = need_bias,\n",
    "    # first_layer_no_train = False\n",
    "    lif_add_at_first = lif_add_at_first,\n",
    "    my_seed = my_seed,\n",
    "\n",
    "    TIME = TIME, # SAE일 때만 유효\n",
    "    v_decay = v_decay,\n",
    "    v_threshold = v_threshold,\n",
    "    v_reset = v_reset, # 10000이상 일 시 hard reset\n",
    "    BPTT_on = BPTT_on,\n",
    "\n",
    "    SAE_hidden_nomean = SAE_hidden_nomean,\n",
    "    \n",
    "    current_time = current_time,\n",
    "\n",
    "    optimizer = optimizer, #'Adam', 'SGD'\n",
    "\n",
    "    coarse_com_mode = coarse_com_mode,\n",
    "    coarse_com_config = coarse_com_config, # (max, min)\n",
    "\n",
    "    \n",
    "    sae_l2_norm_bridge = sae_l2_norm_bridge,\n",
    "    sae_lif_bridge = sae_lif_bridge,\n",
    "\n",
    "    accuracy_check_epoch_term = accuracy_check_epoch_term,\n",
    "    \n",
    "    lif_add_at_last = lif_add_at_last,\n",
    "\n",
    "    two_channel_input = two_channel_input,\n",
    "    )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Sweep code\n",
    "\n",
    "\n",
    "# from unittest import TextTestRunner\n",
    "\n",
    "\n",
    "# unique_name_hyper = 'cluster_train_system'\n",
    "# # run_name = 'spike_sorting'\n",
    "# sweep_start_time =  datetime.datetime.now().strftime(\"%Y%m%d_%H%M%S\") + f\"_{str(int(datetime.datetime.now().microsecond / 1000)).zfill(3)}\"\n",
    "# sweep_configuration = {\n",
    "#     'method': 'bayes', # 'random', 'bayes'\n",
    "#     'name': f'spike_sorting_{sweep_start_time}',\n",
    "#     'metric': {'goal': 'maximize', 'name': 'best_mean_cluster_accuracy_post_training_cycle_all_dataset'},\n",
    "#     'parameters': \n",
    "#     {\n",
    "#         # \"gpu\": {\"values\": [1]},  # 이건 sweep parameter아님. hyper_iter에서 직접 설정\n",
    "#         \"Conv_net\": {\"values\": [True]}, \n",
    "#         \"SAE_net\": {\"values\": [True]}, \n",
    "\n",
    "#         \"dataset_num\": {\"values\": [16]}, \n",
    "#         \"spike_length\": {\"values\": [50]},  \n",
    "#         \"num_cluster\": {\"values\": [4]}, \n",
    "#         \"training_cycle\": {\"values\": [1400, 2400]}, # [1400, 2400]\n",
    "\n",
    "#         \"batch_size\": {\"values\": [16,32,48]}, \n",
    "#         \"max_epoch\": {\"values\": [1]}, \n",
    "#         \"learning_rate\": {\"values\": [0.001]},\n",
    "#         \"normalize_on\": {\"values\": [False]},\n",
    "#         \"need_bias\": {\"values\": [False]}, \n",
    "\n",
    "#         \"lif_add_at_first\": {\"values\": [False]}, # [True, False]\n",
    "#         \"my_seed\": {\"values\": [42]}, \n",
    "\n",
    "#         \"TIME\": {\"values\": [50,40,30,20]}, #  [4,6,8,10]\n",
    "#         \"v_decay\": {\"values\": [0.25,0.50,0.75,0.875]}, # [0.25,0.50,0.75]\n",
    "#         \"v_threshold\": {\"values\": [0.25,0.50,0.75,1.0]}, # [0.25,0.50,0.75]\n",
    "#         \"v_reset\": {\"values\": [0.0, 10000.0]},  # [0.0, 10000.0]\n",
    "#         \"BPTT_on\": {\"values\": [True, False]},  # [True, False]\n",
    "\n",
    "#         \"SAE_hidden_nomean\": {\"values\": [True, False]}, # [True, False]\n",
    "\n",
    "#         # \"current_time\": {\"values\": [current_time]} #밑에서 직접설정됨.\n",
    "\n",
    "#         \"optimizer\": {\"values\": ['Adam', 'SGD']}, # ['Adam', 'SGD']\n",
    "\n",
    "#         \"coarse_com_mode\": {\"values\": [True]}, # ['Adam', 'SGD']\n",
    "#         \"coarse_com_config\": {\"values\": [(2.0, -2.0), (3.0, -3.0)]}, # ['Adam', 'SGD']\n",
    "\n",
    "#         \"sae_l2_norm_bridge\": {\"values\": [False]}, # [True, False]\n",
    "#         \"sae_lif_bridge\": {\"values\": [True]}, # [False, True]\n",
    "        \n",
    "#         \"accuracy_check_epoch_term\": {\"values\": [5]}, \n",
    "\n",
    "#         \"lif_add_at_last\": {\"values\": [True, False]},# [True, False]\n",
    "\n",
    "#         \"two_channel_input\": {\"values\": [True, False]},# [True, False]\n",
    "#      }\n",
    "# }\n",
    "\n",
    "\n",
    "# def hyper_iter():\n",
    "#     ### my_snn control board ########################\n",
    "#     wandb.init(save_code = False)\n",
    "#     gpu  =  3\n",
    "#     Conv_net  =  wandb.config.Conv_net\n",
    "#     SAE_net  =  wandb.config.SAE_net\n",
    "\n",
    "#     dataset_num  =  wandb.config.dataset_num\n",
    "#     spike_length  =  wandb.config.spike_length\n",
    "#     num_cluster  =  wandb.config.num_cluster\n",
    "#     training_cycle  =  wandb.config.training_cycle\n",
    "\n",
    "#     batch_size  =  wandb.config.batch_size\n",
    "#     max_epoch  =  wandb.config.max_epoch\n",
    "#     learning_rate  =  wandb.config.learning_rate\n",
    "#     normalize_on  =  wandb.config.normalize_on\n",
    "#     need_bias  =  wandb.config.need_bias\n",
    "\n",
    "#     lif_add_at_first  =  wandb.config.lif_add_at_first\n",
    "#     my_seed  =  wandb.config.my_seed\n",
    "\n",
    "\n",
    "#     TIME  =  wandb.config.TIME\n",
    "#     v_decay  =  wandb.config.v_decay\n",
    "#     v_threshold  =  wandb.config.v_threshold\n",
    "#     v_reset  =  wandb.config.v_reset\n",
    "#     BPTT_on  =  wandb.config.BPTT_on\n",
    "\n",
    "#     SAE_hidden_nomean  =  wandb.config.SAE_hidden_nomean\n",
    "    \n",
    "#     current_time =  datetime.datetime.now().strftime(\"%Y%m%d_%H%M%S\") + f\"_{str(int(datetime.datetime.now().microsecond / 1000)).zfill(3)}\"\n",
    "\n",
    "#     optimizer  =  wandb.config.optimizer\n",
    "\n",
    "#     coarse_com_mode = wandb.config.coarse_com_mode\n",
    "#     coarse_com_config = wandb.config.coarse_com_config # (max, min)\n",
    "\n",
    "#     sae_l2_norm_bridge = wandb.config.sae_l2_norm_bridge\n",
    "#     sae_lif_bridge = wandb.config.sae_lif_bridge\n",
    "\n",
    "#     accuracy_check_epoch_term = wandb.config.accuracy_check_epoch_term\n",
    "\n",
    "#     lif_add_at_last = wandb.config.lif_add_at_last\n",
    "\n",
    "#     two_channel_input = wandb.config.two_channel_input\n",
    "\n",
    "#     cluster_train_system( \n",
    "#         gpu = gpu,\n",
    "#         Conv_net = Conv_net,\n",
    "#         SAE_net = SAE_net,\n",
    "\n",
    "#         # hyperparameter\n",
    "#         dataset_num = dataset_num,\n",
    "#         spike_length = spike_length,\n",
    "#         num_cluster = num_cluster,  # 클러스터 수 설정 # 논문엔 4개라는데 여기서는 3개로 했네\n",
    "#         training_cycle = training_cycle, # 그 초기 몇개까지만 cluster update할지\n",
    "\n",
    "\n",
    "#         batch_size = batch_size,\n",
    "#         max_epoch = max_epoch,\n",
    "#         learning_rate = learning_rate,\n",
    "#         normalize_on = normalize_on, # True or False #이거 안 씀 # 이거 별로 안 좋은 normalize같음 # 쓸 거면 다른 거 써라.\n",
    "#         need_bias = need_bias,\n",
    "#         # first_layer_no_train = False\n",
    "#         lif_add_at_first = lif_add_at_first,\n",
    "#         my_seed = my_seed,\n",
    "\n",
    "#         TIME = TIME, # SAE일 때만 유효\n",
    "#         v_decay = v_decay,\n",
    "#         v_threshold = v_threshold,\n",
    "#         v_reset = v_reset, # 10000이상 일 시 hard reset\n",
    "#         BPTT_on = BPTT_on,\n",
    "\n",
    "#         SAE_hidden_nomean = SAE_hidden_nomean,\n",
    "\n",
    "#         current_time = current_time,\n",
    "\n",
    "#         optimizer = optimizer, #'Adam', 'SGD'\n",
    "\n",
    "#         coarse_com_mode = coarse_com_mode,\n",
    "#         coarse_com_config = coarse_com_config, # (max, min)\n",
    "        \n",
    "#         sae_l2_norm_bridge = sae_l2_norm_bridge,\n",
    "#         sae_lif_bridge = sae_lif_bridge,\n",
    "\n",
    "#         accuracy_check_epoch_term = accuracy_check_epoch_term,\n",
    "\n",
    "#         lif_add_at_last = lif_add_at_last,\n",
    "        \n",
    "#         two_channel_input = two_channel_input,\n",
    "#         )\n",
    "    \n",
    "# # sweep_id = 'ygoj9jt4'\n",
    "# sweep_id = wandb.sweep(sweep=sweep_configuration, project=f'spike_sorting {unique_name_hyper}')\n",
    "# wandb.agent(sweep_id, function=hyper_iter, count=100000, project=f'spike_sorting {unique_name_hyper}')\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wandb.finish() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.ticker import MaxNLocator\n",
    "import pickle\n",
    "import json\n",
    "\n",
    "# current_time = '20250102_225243_972'\n",
    "\n",
    "with open(f\"result_save/cluster_accuracy_history_{current_time}.pkl\", \"rb\") as f:\n",
    "    data = pickle.load(f)\n",
    "\n",
    "\n",
    "# JSON으로 저장\n",
    "with open(f\"result_save/cluster_accuracy_history_{current_time}.json\", 'r') as f:\n",
    "    loaded_hyperparameters = json.load(f)\n",
    "\n",
    "loss_history = data['loss_history']\n",
    "mean_cluster_accuracy_during_training_cycle_all_dataset_history = data['mean_cluster_accuracy_during_training_cycle_all_dataset_history']\n",
    "mean_cluster_accuracy_post_training_cycle_all_dataset_history = data['mean_cluster_accuracy_post_training_cycle_all_dataset_history']\n",
    "mean_cluster_accuracy_total_all_dataset_history = data['mean_cluster_accuracy_total_all_dataset_history']\n",
    "print(data)\n",
    "max_acc = 0\n",
    "for i in mean_cluster_accuracy_post_training_cycle_all_dataset_history:\n",
    "    if i[1] > max_acc:\n",
    "        max_acc = i[1]\n",
    "\n",
    "# 설정 정보 제목 작성\n",
    "title = (\n",
    "    f\"Dataset Num: {loaded_hyperparameters['dataset_num']}, Conv {loaded_hyperparameters['Conv_net']}, SAE {loaded_hyperparameters['SAE_net']}, Current time {loaded_hyperparameters['current_time']}, Spike Length: {loaded_hyperparameters['spike_length']}, Num Cluster: {loaded_hyperparameters['num_cluster']}, \"\n",
    "    f\"Training Cycle: {loaded_hyperparameters['training_cycle']}, Batch Size: {loaded_hyperparameters['batch_size']}, Max Epoch: {loaded_hyperparameters['max_epoch']}, \\n\"\n",
    "    f\"Learning Rate: {loaded_hyperparameters['learning_rate']}, Input Normalize: {loaded_hyperparameters['normalize_on']}, Need Bias: {loaded_hyperparameters['need_bias']}, \"\n",
    "    f\"LIF Add at First: {loaded_hyperparameters['lif_add_at_first']}, TIME: {loaded_hyperparameters['TIME']}, Seed: {loaded_hyperparameters['my_seed']}, Best ACC: {max_acc:.2f}%\"\n",
    ")\n",
    "\n",
    "# 데이터 리스트와 라벨 설정 (Loss 제외)\n",
    "data_list = [\n",
    "    (\"Mean Cluster Accuracy (During Training Cycle)\", mean_cluster_accuracy_during_training_cycle_all_dataset_history),\n",
    "    (\"Mean Cluster Accuracy (Post Training Cycle)\", mean_cluster_accuracy_post_training_cycle_all_dataset_history),\n",
    "    (\"Mean Cluster Accuracy (Total)\", mean_cluster_accuracy_total_all_dataset_history),\n",
    "]\n",
    "\n",
    "# 플롯 생성\n",
    "fig, ax1 = plt.subplots(figsize=(12, 8))\n",
    "\n",
    "# 첫 번째 y축: Accuracy 관련 데이터\n",
    "for label, data in data_list:\n",
    "    epochs, values = zip(*data)  # epoch, value 분리\n",
    "    ax1.plot(epochs, values, label=label)\n",
    "\n",
    "ax1.set_xlabel(\"Epoch\")\n",
    "ax1.set_ylabel(\"Clurstering Accuracy [%]\", color=\"blue\")\n",
    "ax1.tick_params(axis=\"y\", labelcolor=\"blue\")\n",
    "ax1.legend(loc=\"center right\")\n",
    "ax1.grid(True)\n",
    "\n",
    "# x축을 정수만 표시하도록 설정\n",
    "ax1.xaxis.set_major_locator(MaxNLocator(integer=True))\n",
    "\n",
    "# 두 번째 y축: Loss History\n",
    "ax2 = ax1.twinx()\n",
    "epochs, values = zip(*loss_history)\n",
    "ax2.plot(epochs, values, label=\"AE Loss History\", color=\"red\", linestyle=\"--\")\n",
    "ax2.set_ylabel(\"Loss\", color=\"red\")\n",
    "ax2.tick_params(axis=\"y\", labelcolor=\"red\")\n",
    "ax2.legend(loc=\"center left\")\n",
    "\n",
    "# 제목 추가\n",
    "plt.title(title, fontsize=10)\n",
    "plt.tight_layout()\n",
    "plt.savefig(f'net_save/{current_time}', dpi=300, bbox_inches=\"tight\")  # dpi=300은 고해상도로 저장, bbox_inches=\"tight\"는 여백 최소화\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aedat2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
