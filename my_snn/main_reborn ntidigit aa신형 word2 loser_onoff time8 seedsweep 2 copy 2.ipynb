{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_38521/4213678604.py:46: DeprecationWarning: The module snntorch.spikevision is deprecated. For loading neuromorphic datasets, we recommend using the Tonic project: https://github.com/neuromorphs/tonic\n",
      "  from snntorch.spikevision import spikedata\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os \n",
    "import argparse\n",
    "import torch\n",
    "import torch.nn as nn \n",
    "import torch.nn.functional as F\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.optim as optim\n",
    "import torch.optim.lr_scheduler as lr_scheduler\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "import torchvision\n",
    "import torchvision.datasets\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import time\n",
    "\n",
    "from snntorch import spikegen\n",
    "import matplotlib.pyplot as plt\n",
    "import snntorch.spikeplot as splt\n",
    "from IPython.display import HTML\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "from apex.parallel import DistributedDataParallel as DDP\n",
    "\n",
    "import random\n",
    "import datetime\n",
    "\n",
    "import json\n",
    "\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "''' ë ˆí¼ëŸ°ìŠ¤\n",
    "https://spikingjelly.readthedocs.io/zh-cn/0.0.0.0.4/spikingjelly.datasets.html#module-spikingjelly.datasets\n",
    "https://github.com/GorkaAbad/Sneaky-Spikes/blob/main/datasets.py\n",
    "https://github.com/GorkaAbad/Sneaky-Spikes/blob/main/how_to.md\n",
    "https://github.com/nmi-lab/torchneuromorphic\n",
    "https://snntorch.readthedocs.io/en/latest/snntorch.spikevision.spikedata.html#shd\n",
    "'''\n",
    "\n",
    "import snntorch\n",
    "from snntorch.spikevision import spikedata\n",
    "\n",
    "import modules.spikingjelly;\n",
    "from modules.spikingjelly.datasets.dvs128_gesture import DVS128Gesture\n",
    "from modules.spikingjelly.datasets.cifar10_dvs import CIFAR10DVS\n",
    "from modules.spikingjelly.datasets.n_mnist import NMNIST\n",
    "# from modules.spikingjelly.datasets.es_imagenet import ESImageNet\n",
    "from modules.spikingjelly.datasets import split_to_train_test_set\n",
    "from modules.spikingjelly.datasets.n_caltech101 import NCaltech101\n",
    "from modules.spikingjelly.datasets import pad_sequence_collate, padded_sequence_mask\n",
    "\n",
    "import modules.torchneuromorphic as torchneuromorphic\n",
    "\n",
    "import wandb\n",
    "\n",
    "from torchviz import make_dot\n",
    "import graphviz\n",
    "from turtle import shape\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# my module import\n",
    "from modules import *\n",
    "\n",
    "# modules í´ë”ì— ìƒˆëª¨ë“ˆ.py ë§Œë“¤ë©´\n",
    "# modules/__init__py íŒŒì¼ì— form .ìƒˆëª¨ë“ˆ import * í•˜ì…ˆ\n",
    "# ê·¸ë¦¬ê³  ìƒˆëª¨ë“ˆ.pyì—ì„œ from modules.ìƒˆëª¨ë“ˆ import * í•˜ì…ˆ\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "from matplotlib.ft2font import EXTERNAL_STREAM\n",
    "\n",
    "\n",
    "def my_snn_system(devices = \"0,1,2,3\",\n",
    "                    single_step = False, # True # False\n",
    "                    unique_name = 'main',\n",
    "                    my_seed = 42,\n",
    "                    TIME = 10,\n",
    "                    BATCH = 256,\n",
    "                    IMAGE_SIZE = 32,\n",
    "                    which_data = 'CIFAR10',\n",
    "                    # CLASS_NUM = 10,\n",
    "                    data_path = '/data2',\n",
    "                    rate_coding = True,\n",
    "    \n",
    "                    lif_layer_v_init = 0.0,\n",
    "                    lif_layer_v_decay = 0.6,\n",
    "                    lif_layer_v_threshold = 1.2,\n",
    "                    lif_layer_v_reset = 0.0,\n",
    "                    lif_layer_sg_width = 1,\n",
    "\n",
    "                    # synapse_conv_in_channels = IMAGE_PIXEL_CHANNEL,\n",
    "                    synapse_conv_kernel_size = 3,\n",
    "                    synapse_conv_stride = 1,\n",
    "                    synapse_conv_padding = 1,\n",
    "\n",
    "                    synapse_trace_const1 = 1,\n",
    "                    synapse_trace_const2 = 0.6,\n",
    "\n",
    "                    # synapse_fc_out_features = CLASS_NUM,\n",
    "\n",
    "                    pre_trained = False,\n",
    "                    convTrue_fcFalse = True,\n",
    "\n",
    "                    cfg = [64, 64],\n",
    "                    net_print = False, # True # False\n",
    "                    \n",
    "                    pre_trained_path = \"net_save/save_now_net.pth\",\n",
    "                    learning_rate = 0.0001,\n",
    "                    epoch_num = 200,\n",
    "                    tdBN_on = False,\n",
    "                    BN_on = False,\n",
    "\n",
    "                    surrogate = 'sigmoid',\n",
    "\n",
    "                    BPTT_on = False,\n",
    "\n",
    "                    optimizer_what = 'SGD', # 'SGD' 'Adam', 'RMSprop'\n",
    "                    scheduler_name = 'no',\n",
    "                    \n",
    "                    ddp_on = False, # DECREPATED # fALSE\n",
    "\n",
    "                    dvs_clipping = 1, \n",
    "                    dvs_duration = 25_000,\n",
    "\n",
    "\n",
    "                    DFA_on = False, # True # False\n",
    "                    trace_on = False, \n",
    "                    OTTT_input_trace_on = False, # True # False\n",
    "                    \n",
    "                    exclude_class = True, # True # False # gestureì—ì„œ 10ë²ˆì§¸ í´ë˜ìŠ¤ ì œì™¸\n",
    "\n",
    "                    merge_polarities = False, # True # False # tonic dvs dataset ì—ì„œ polarities í•©ì¹˜ê¸°\n",
    "                    denoise_on = True, \n",
    "\n",
    "                    extra_train_dataset = 0, # DECREPATED # data_loaderì—ì„œ train datasetì„ ëª‡ê°œ ë” ì“¸ê±´ì§€ \n",
    "\n",
    "                    num_workers = 2,\n",
    "                    chaching_on = True,\n",
    "                    pin_memory = True, # True # False\n",
    "                    \n",
    "                    UDA_on = False,  # DECREPATED # uda\n",
    "                    alpha_uda = 1.0, # DECREPATED # uda\n",
    "\n",
    "                    bias = True,\n",
    "\n",
    "                    last_lif = False,\n",
    "                        \n",
    "                    temporal_filter = 1, \n",
    "                    initial_pooling = 1,\n",
    "\n",
    "                    temporal_filter_accumulation = False,\n",
    "\n",
    "                    quantize_bit_list=[],\n",
    "                    scale_exp=[],\n",
    "\n",
    "                    timestep_sums_threshold = 15,\n",
    "\n",
    "                    loser_encourage_mode = False, # True # False\n",
    "                    \n",
    "                    lif_layer_sg_width2 = None,\n",
    "                    lif_layer_v_threshold2 = None,\n",
    "                    learning_rate2 = None,\n",
    "                    init_scaling = None,\n",
    "                    ):\n",
    "    ## í•¨ìˆ˜ ë‚´ ëª¨ë“  ë¡œì»¬ ë³€ìˆ˜ ì €ì¥ ########################################################\n",
    "    hyperparameters = locals()\n",
    "    print('param', hyperparameters,'\\n')\n",
    "    hyperparameters['current epoch'] = 0\n",
    "    ######################################################################################\n",
    "\n",
    "    ## hyperparameter check #############################################################\n",
    "    if single_step == True:\n",
    "        assert BPTT_on == False and tdBN_on == False \n",
    "    if tdBN_on == True:\n",
    "        assert BPTT_on == True\n",
    "    if pre_trained == True:\n",
    "        print('\\n\\n')\n",
    "        print(\"Caution! pre_trained is True\\n\\n\"*3)    \n",
    "    if DFA_on == True:\n",
    "        assert single_step == True and BPTT_on == False \n",
    "    # assert single_step == DFA_on, 'DFAë‘ single_stepê³µì¡´í•˜ê²Œí•´ë¼'\n",
    "    if trace_on:\n",
    "        assert BPTT_on == False and single_step == True\n",
    "    if OTTT_input_trace_on == True:\n",
    "        assert BPTT_on == False and single_step == True #and trace_on == True\n",
    "    if temporal_filter > 1:\n",
    "        assert convTrue_fcFalse == False\n",
    "    if which_data == 'n_tidigits_tonic':\n",
    "        assert merge_polarities == False\n",
    "    ######################################################################################\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "    ## wandb ì„¸íŒ… ###################################################################\n",
    "    current_time = datetime.datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "    wandb.config.update(hyperparameters)\n",
    "    wandb.run.name = f'lr_{learning_rate}_{unique_name}_{which_data}_tstep{TIME}'\n",
    "    wandb.define_metric(\"summary_val_acc\", summary=\"max\")\n",
    "    # wandb.run.log_code(\".\", \n",
    "    #                     include_fn=lambda path: path.endswith(\".py\") or path.endswith(\".ipynb\"),\n",
    "    #                     exclude_fn=lambda path: 'logs/' in path or 'net_save/' in path or 'result_save/' in path or 'trying/' in path or 'wandb/' in path or 'private/' in path or '.git/' in path or 'tonic' in path or 'torchneuromorphic' in path or 'spikingjelly' in path \n",
    "    #                     )\n",
    "    ###################################################################################\n",
    "\n",
    "\n",
    "\n",
    "    ## gpu setting ##################################################################################################################\n",
    "    os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\" \n",
    "    os.environ[\"CUDA_VISIBLE_DEVICES\"]= devices\n",
    "    ###################################################################################################################################\n",
    "\n",
    "\n",
    "    ## seed setting ##################################################################################################################\n",
    "    seed_assign(my_seed)\n",
    "    ###################################################################################################################################\n",
    "    \n",
    "\n",
    "    ## data_loader ê°€ì ¸ì˜¤ê¸° ##################################################################################################################\n",
    "    # data loader, pixel channel, class num\n",
    "    train_data_split_indices = []\n",
    "    train_loader, test_loader, synapse_conv_in_channels, CLASS_NUM, train_data_count = data_loader(\n",
    "            which_data,\n",
    "            data_path, \n",
    "            rate_coding, \n",
    "            BATCH, \n",
    "            IMAGE_SIZE,\n",
    "            ddp_on,\n",
    "            TIME*temporal_filter, \n",
    "            dvs_clipping,\n",
    "            dvs_duration,\n",
    "            exclude_class,\n",
    "            merge_polarities,\n",
    "            denoise_on,\n",
    "            my_seed,\n",
    "            extra_train_dataset,\n",
    "            num_workers,\n",
    "            chaching_on,\n",
    "            pin_memory,\n",
    "            train_data_split_indices,) \n",
    "    synapse_fc_out_features = CLASS_NUM\n",
    "    synapse_fc_out_features = 10\n",
    "\n",
    "    print('\\nlen(train_loader):', len(train_loader), 'BATCH:', BATCH, 'train_data_count:', train_data_count) \n",
    "    print('len(test_loader):', len(test_loader), 'BATCH:', BATCH)\n",
    "\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    print(f\"\\ndevice ==> {device}\\n\")\n",
    "    if device == \"cpu\":\n",
    "        print(\"=\"*50,\"\\n[WARNING]\\n[WARNING]\\n[WARNING]\\n: cpu mode\\n\\n\",\"=\"*50)\n",
    "\n",
    "    ### network setting #######################################################################################################################\n",
    "    if (convTrue_fcFalse == False):\n",
    "        net = REBORN_MY_SNN_FC(cfg, synapse_conv_in_channels*temporal_filter, IMAGE_SIZE//initial_pooling, synapse_fc_out_features,\n",
    "                    synapse_trace_const1, synapse_trace_const2, \n",
    "                    lif_layer_v_init, lif_layer_v_decay, \n",
    "                    lif_layer_v_threshold, lif_layer_v_reset,\n",
    "                    lif_layer_sg_width,\n",
    "                    tdBN_on,\n",
    "                    BN_on, TIME,\n",
    "                    surrogate,\n",
    "                    BPTT_on,\n",
    "                    DFA_on,\n",
    "                    bias,\n",
    "                    single_step,\n",
    "                    last_lif,\n",
    "                    trace_on,\n",
    "                    quantize_bit_list,\n",
    "                    scale_exp,\n",
    "                    ANPI_MODE=False,\n",
    "                    lif_layer_sg_width2=lif_layer_sg_width2,\n",
    "                    lif_layer_v_threshold2=lif_layer_v_threshold2,\n",
    "                    init_scaling=init_scaling).to(device)\n",
    "    else:\n",
    "        net = REBORN_MY_SNN_CONV(cfg, synapse_conv_in_channels, IMAGE_SIZE//initial_pooling,\n",
    "                    synapse_conv_kernel_size, synapse_conv_stride, \n",
    "                    synapse_conv_padding, synapse_trace_const1, \n",
    "                    synapse_trace_const2, \n",
    "                    lif_layer_v_init, lif_layer_v_decay, \n",
    "                    lif_layer_v_threshold, lif_layer_v_reset,\n",
    "                    lif_layer_sg_width,\n",
    "                    synapse_fc_out_features, \n",
    "                    tdBN_on,\n",
    "                    BN_on, TIME,\n",
    "                    surrogate,\n",
    "                    BPTT_on,\n",
    "                    DFA_on,\n",
    "                    bias,\n",
    "                    single_step,\n",
    "                    last_lif,\n",
    "                    trace_on,\n",
    "                    quantize_bit_list,\n",
    "                    scale_exp).to(device)\n",
    "\n",
    "    net = torch.nn.DataParallel(net) \n",
    "    \n",
    "    if pre_trained == True:\n",
    "        # 1. ì „ì²´ state_dict ë¡œë“œ\n",
    "        checkpoint = torch.load(pre_trained_path)\n",
    "\n",
    "        # 2. í˜„ì¬ ëª¨ë¸ì˜ state_dict ê°€ì ¸ì˜¤ê¸°\n",
    "        model_dict = net.state_dict()\n",
    "\n",
    "        # 3. 'SYNAPSE'ê°€ í¬í•¨ëœ keyë§Œ í•„í„°ë§ (í˜„ì¬ ëª¨ë¸ì—ë„ ì¡´ì¬í•˜ëŠ” keyë§Œ)\n",
    "        filtered_dict = {k: v for k, v in checkpoint.items() if ('weight' in k or 'bias' in k) and k in model_dict}\n",
    "\n",
    "        # 4. ì—…ë°ì´íŠ¸ëœ í‚¤ ì¶œë ¥\n",
    "        print(\"ğŸ”„ ì—…ë°ì´íŠ¸ëœ SYNAPSE ê´€ë ¨ ë ˆì´ì–´ë“¤:\")\n",
    "        for k in filtered_dict.keys():\n",
    "            print(f\" - {k}\")\n",
    "\n",
    "        # 5. ëª¨ë¸ dict ì—…ë°ì´íŠ¸ ë° ë¡œë”©\n",
    "        model_dict.update(filtered_dict)\n",
    "        net.load_state_dict(model_dict)\n",
    "    \n",
    "    net = net.to(device)\n",
    "    if (net_print == True):\n",
    "        print(net)    \n",
    "\n",
    "    print(f\"\\n========================================================\\nTrainable parameters: {sum(p.numel() for p in net.parameters() if p.requires_grad):,}\\n========================================================\\n\")\n",
    "    ####################################################################################################################################\n",
    "    \n",
    "\n",
    "    # # wandb logging ###########################################\n",
    "    # wandb.watch(net, log=\"all\", log_freq = 10) #gradient, parameter loggingí•´ì¤Œ\n",
    "    # ###########################################################\n",
    "\n",
    "    ## criterion ########################################## # loss êµ¬í•´ì£¼ëŠ” ì¹œêµ¬\n",
    "    def my_cross_entropy_loss(logits, targets):\n",
    "        # logits: (batch_size, num_classes)\n",
    "        # targets: (batch_size,) -> í´ë˜ìŠ¤ ì¸ë±ìŠ¤\n",
    "        log_probs = F.log_softmax(logits, dim=1)  # log(p_i)\n",
    "        loss = F.nll_loss(log_probs, targets)\n",
    "        # print(loss.shape)\n",
    "        return loss\n",
    "    \n",
    "    # class CustomLossFunction(torch.autograd.Function):\n",
    "    #     @staticmethod\n",
    "    #     def forward(ctx, input, target):\n",
    "    #         ctx.save_for_backward(input, target)\n",
    "    #         return F.cross_entropy(input, target)\n",
    "\n",
    "    #     @staticmethod\n",
    "    #     def backward(ctx, grad_output):\n",
    "    #         # MAE ìŠ¤íƒ€ì¼ì˜ gradientë¥¼ í‰ë‚´ëƒ„\n",
    "    #         input, target = ctx.saved_tensors\n",
    "    #         input_argmax = input.argmax(dim=1)\n",
    "    #         input_one_hot = torch.zeros_like(input).scatter_(1, input_argmax.unsqueeze(1), 1.0)\n",
    "    #         target_one_hot = torch.zeros_like(input).scatter_(1, target.unsqueeze(1), 1.0)\n",
    "    #         # print('grad_output', grad_output) # ì´ê±° ê± 1.0ì„\n",
    "    #         return input_one_hot - target_one_hot, None  # targetì—ëŠ” gradient ì—†ìŒ\n",
    "    \n",
    "\n",
    "    print(\"ì‘ì€ê±¸í¬ê²Œ\")\n",
    "    print(\"ì‘ì€ê±¸í¬ê²Œ\")\n",
    "    print(\"ì‘ì€ê±¸í¬ê²Œ\")\n",
    "    print(\"ì‘ì€ê±¸í¬ê²Œ\")\n",
    "    class CustomLossFunction(torch.autograd.Function):\n",
    "        @staticmethod\n",
    "        def forward(ctx, input, target):\n",
    "            ctx.save_for_backward(input, target)\n",
    "            return F.cross_entropy(input, target)\n",
    "\n",
    "        @staticmethod\n",
    "        def backward(ctx, grad_output):\n",
    "            input, target = ctx.saved_tensors\n",
    "            assert input.shape[0] == 1 and target.shape[0] == 1, \"Batch size must be 1 for this custom loss function.\"\n",
    "            batch_size, num_classes = input.shape\n",
    "\n",
    "            target_0 = [0,1,2,3,4]\n",
    "            target_1 = [5,6,7,8,9]\n",
    "            input_argmax = input.argmax(dim=1)\n",
    "            input_one_hot = torch.zeros_like(input).scatter_(1, input_argmax.unsqueeze(1), 1.0)\n",
    "\n",
    "            if (target.item() == 0) and (input_argmax.item() in target_0) or \\\n",
    "                (target.item() == 1) and (input_argmax.item() in target_1):\n",
    "                return input_one_hot - input_one_hot, None  \n",
    "            else:\n",
    "                if target.item() == 0:\n",
    "                    input_slice = input[:, 0:5]\n",
    "                    if loser_encourage_mode:\n",
    "                        input_argmin = input_slice.argmin(dim=1)\n",
    "                    else:\n",
    "                        input_argmin = input_slice.argmax(dim=1)\n",
    "                elif target.item() == 1:\n",
    "                    input_slice = input[:, 5:10] \n",
    "                    if loser_encourage_mode:\n",
    "                        input_argmin = input_slice.argmin(dim=1) + 5\n",
    "                    else:\n",
    "                        input_argmin = input_slice.argmax(dim=1) + 5\n",
    "                else:\n",
    "                    raise ValueError(f\"Unexpected target: {target.item()}\")\n",
    "\n",
    "                # gradient ë°©í–¥ì„ argmin ìª½ìœ¼ë¡œ\n",
    "                modified_target_one_hot = torch.zeros_like(input).scatter_(1, input_argmin.unsqueeze(1), 1.0)\n",
    "\n",
    "                return input_one_hot - modified_target_one_hot, None\n",
    "\n",
    "    # Wrapper module\n",
    "    class CustomCriterion(torch.nn.Module):\n",
    "        def __init__(self):\n",
    "            super().__init__()\n",
    "\n",
    "        def forward(self, input, target):\n",
    "            return CustomLossFunction.apply(input, target)\n",
    "\n",
    "    # criterion = nn.CrossEntropyLoss().to(device)\n",
    "    criterion = CustomCriterion().to(device)\n",
    "    \n",
    "    # if (OTTT_sWS_on == True):\n",
    "    #     # criterion = nn.CrossEntropyLoss().to(device)\n",
    "        # criterion = lambda y_t, target_t: ((1 - 0.05) * F.cross_entropy(y_t, target_t) + 0.05 * F.mse_loss(y_t, F.one_hot(target_t, CLASS_NUM).float())) / TIME \n",
    "    #     if which_data == 'DVS_GESTURE':\n",
    "    #         criterion = lambda y_t, target_t: ((1 - 0.001) * F.cross_entropy(y_t, target_t) + 0.001 * F.mse_loss(y_t, F.one_hot(target_t, CLASS_NUM).float())) / TIME \n",
    "    ####################################################\n",
    "\n",
    "    ## optimizer, scheduler ########################################################################\n",
    "    class MySGD(torch.optim.Optimizer):\n",
    "        def __init__(self, params, lr=0.01, momentum=0.0, quantize_bit_list=[], scale_exp=[], net=None):\n",
    "            if momentum < 0.0 or momentum >= 1.0:\n",
    "                raise ValueError(f\"Invalid momentum value: {momentum}\")\n",
    "            \n",
    "            defaults = {'lr': lr, 'momentum': momentum}\n",
    "            super(MySGD, self).__init__(params, defaults)\n",
    "            self.step_count = 0\n",
    "            self.quantize_bit_list = quantize_bit_list\n",
    "            # self.quantize_bit_list = []\n",
    "            self.scale_exp = scale_exp\n",
    "            self.param_to_name = {param: name for name, param in net.module.named_parameters()} if net else {}\n",
    "            self.additional_dw_weight = 1.0\n",
    "\n",
    "        @torch.no_grad()\n",
    "        def step(self):\n",
    "            \"\"\"ëª¨ë“  íŒŒë¼ë¯¸í„°ì— ëŒ€í•´ gradient descent ìˆ˜í–‰\"\"\"\n",
    "            loss = None\n",
    "            for group in self.param_groups:\n",
    "                # lr = group['lr']\n",
    "                momentum = group['momentum']\n",
    "                for param in group['params']:\n",
    "                    if param.grad is None:\n",
    "                        continue\n",
    "                    name = self.param_to_name.get(param, 'unknown')\n",
    "\n",
    "                    if 'layers.1.fc.weight' in name:\n",
    "                        lr = learning_rate\n",
    "                    elif 'layers.4.fc.weight' in name:\n",
    "                        lr = learning_rate2\n",
    "                    elif 'layers.7.fc.weight' in name:\n",
    "                        lr = 1.0\n",
    "\n",
    "                    # gradientë¥¼ ì´ìš©í•´ íŒŒë¼ë¯¸í„° ì—…ë°ì´íŠ¸\n",
    "                    d_p = param.grad\n",
    "\n",
    "                    if momentum > 0.0:\n",
    "                        param_state = self.state[param]\n",
    "                        if 'momentum_buffer' not in param_state:\n",
    "                            # momentum buffer ì´ˆê¸°í™”\n",
    "                            buf = param_state['momentum_buffer'] = torch.clone(d_p).detach()\n",
    "                        else:\n",
    "                            buf = param_state['momentum_buffer']\n",
    "                            buf.mul_(momentum).add_(d_p)\n",
    "                            # buf *= momentum \n",
    "                            # buf += d_p\n",
    "                        d_p = buf\n",
    "\n",
    "                    dw = -lr*d_p\n",
    "                                        \n",
    "                    # if 'layers.7.fc.weight' in name or 'layers.7.fc.bias' in name:\n",
    "                    #     dw = dw * 0.5\n",
    "\n",
    "                    if len(self.quantize_bit_list) != 0:\n",
    "                        if 'layers.1.fc.weight' in name:\n",
    "                            dw_bit = self.quantize_bit_list[0]\n",
    "                            if self.scale_exp != []:\n",
    "                                exp = self.scale_exp[0][0]\n",
    "                                scale_dw = 2**exp\n",
    "                            else:\n",
    "                                max_dw = dw.abs().max().item()\n",
    "                                assert max_dw > 0, f\"max_dw is zero for parameter {param.name if hasattr(param, 'name') else 'unknown'}\"\n",
    "                                scale_dw = 2**math.ceil(math.log2(max_dw / (2**(dw_bit-1) -1)))\n",
    "                        elif 'layers.1.fc.bias' in name:\n",
    "                            dw_bit = self.quantize_bit_list[0]\n",
    "                            if self.scale_exp != []:\n",
    "                                exp = self.scale_exp[0][1]\n",
    "                                scale_dw = 2**exp\n",
    "                            else:\n",
    "                                max_dw = dw.abs().max().item()\n",
    "                                assert max_dw > 0, f\"max_dw is zero for parameter {param.name if hasattr(param, 'name') else 'unknown'}\"\n",
    "                                scale_dw = 2**math.ceil(math.log2(max_dw / (2**(dw_bit-1) -1)))\n",
    "                        elif 'layers.4.fc.weight' in name:\n",
    "                            dw_bit = self.quantize_bit_list[1]\n",
    "                            if self.scale_exp != []:\n",
    "                                exp = self.scale_exp[1][0]\n",
    "                                scale_dw = 2**exp\n",
    "                            else:\n",
    "                                max_dw = dw.abs().max().item()\n",
    "                                assert max_dw > 0, f\"max_dw is zero for parameter {param.name if hasattr(param, 'name') else 'unknown'}\"\n",
    "                                scale_dw = 2**math.ceil(math.log2(max_dw / (2**(dw_bit-1) -1)))\n",
    "                        elif 'layers.4.fc.bias' in name:\n",
    "                            dw_bit = self.quantize_bit_list[1]\n",
    "                            if self.scale_exp != []:\n",
    "                                exp = self.scale_exp[1][1]\n",
    "                                scale_dw = 2**exp\n",
    "                            else:\n",
    "                                max_dw = dw.abs().max().item()\n",
    "                                assert max_dw > 0, f\"max_dw is zero for parameter {param.name if hasattr(param, 'name') else 'unknown'}\"\n",
    "                                scale_dw = 2**math.ceil(math.log2(max_dw / (2**(dw_bit-1) -1)))\n",
    "                        elif 'layers.7.fc.weight' in name:\n",
    "                            dw_bit = self.quantize_bit_list[2]\n",
    "                            if self.scale_exp != []:\n",
    "                                exp = self.scale_exp[2][0]\n",
    "                                scale_dw = 2**exp\n",
    "                            else:\n",
    "                                max_dw = dw.abs().max().item()\n",
    "                                assert max_dw > 0, f\"max_dw is zero for parameter {param.name if hasattr(param, 'name') else 'unknown'}\"\n",
    "                                scale_dw = 2**math.ceil(math.log2(max_dw / (2**(dw_bit-1) -1)))\n",
    "                        elif 'layers.7.fc.bias' in name:\n",
    "                            dw_bit = self.quantize_bit_list[2]\n",
    "                            if self.scale_exp != []:\n",
    "                                exp = self.scale_exp[2][1]\n",
    "                                scale_dw = 2**exp\n",
    "                                \n",
    "                            else:\n",
    "                                max_dw = dw.abs().max().item()\n",
    "                                assert max_dw > 0, f\"max_dw is zero for parameter {param.name if hasattr(param, 'name') else 'unknown'}\"\n",
    "                                scale_dw = 2**math.ceil(math.log2(max_dw / (2**(dw_bit-1) -1)))\n",
    "                        else:\n",
    "                            assert False, f\"Unknown parameter name: {name}\"\n",
    "\n",
    "\n",
    "                        # print(f'dw_bit{dw_bit}, exp{exp}')\n",
    "                        # print(f'name {name}, d_p: {d_p.shape}, unique elements: {d_p.unique().numel()}, values: {d_p.unique().tolist()}')\n",
    "                        # print(f'name {name}, dw: {dw.shape}, unique elements: {dw.unique().numel()}, values: {dw.unique().tolist()}')\n",
    "                        # dw = torch.clamp((dw / scale_dw + 0).round(), -2**(dw_bit-1) + 1, 2**(dw_bit-1) - 1) * scale_dw\n",
    "                        dw = torch.clamp(round_away_from_zero(dw / scale_dw + 0), -2**(dw_bit-1) + 1, 2**(dw_bit-1) - 1) * scale_dw\n",
    "                        # print(f'name {name}, dw_post: {dw.shape}, unique elements: {dw.unique().numel()}, values: {dw.unique().tolist()}')\n",
    "                    \n",
    "                    if 'layers.1.fc.weight' in name:\n",
    "                        ooo_fifo = 2\n",
    "                    elif 'layers.4.fc.weight' in name:\n",
    "                        ooo_fifo = 1\n",
    "                    elif 'layers.7.fc.weight' in name:\n",
    "                        ooo_fifo = 0\n",
    "                    else:\n",
    "                        assert False\n",
    "                            \n",
    "                    \n",
    "                    dw = dw * self.additional_dw_weight\n",
    "                    if ooo_fifo > 0:\n",
    "                        # ====== FIFO ì²˜ë¦¬ ======\n",
    "                        param_state = self.state[param]\n",
    "                        if 'fifo_buffer' not in param_state:\n",
    "                            param_state['fifo_buffer'] = []\n",
    "\n",
    "                        fifo = param_state['fifo_buffer']\n",
    "                        fifo.append(dw.clone())  # clone() to detach from current graph\n",
    "\n",
    "                        if len(fifo) == ooo_fifo+1:\n",
    "                            oldest_dw = fifo.pop(0)\n",
    "                            param.add_(oldest_dw)\n",
    "                    else: \n",
    "                        param.add_(dw)\n",
    "                        # param -= dw ìœ„ ì—°ì‚°ì´ë‘ ë‹¤ë¦„. inmemoryì—°ì‚°ì´ë¼ ì¢€ ë‹¤ë¥¸ ë“¯\n",
    "            return loss\n",
    "    \n",
    "    if(optimizer_what == 'SGD'):\n",
    "        optimizer = MySGD(net.parameters(), lr=learning_rate, momentum=0.0, quantize_bit_list=quantize_bit_list, scale_exp=scale_exp, net=net)\n",
    "        # optimizer = optim.SGD(net.parameters(), lr=learning_rate, momentum=0.0)\n",
    "        print(optimizer)\n",
    "    elif(optimizer_what == 'Adam'):\n",
    "        optimizer = torch.optim.Adam(net.parameters(), lr=learning_rate)\n",
    "        # optimizer = torch.optim.Adam(net.parameters(), lr=0.00001)\n",
    "        # optimizer = torch.optim.Adam(net.parameters(), lr=learning_rate/256 * BATCH, weight_decay=1e-4)\n",
    "        # optimizer = optim.Adam(net.parameters(), lr=learning_rate, weight_decay=0, betas=(0.9, 0.999))\n",
    "    elif(optimizer_what == 'RMSprop'):\n",
    "        pass\n",
    "\n",
    "\n",
    "    if (scheduler_name == 'StepLR'):\n",
    "        scheduler = lr_scheduler.StepLR(optimizer, step_size=10, gamma=0.1)\n",
    "    elif (scheduler_name == 'ExponentialLR'):\n",
    "        scheduler = lr_scheduler.ExponentialLR(optimizer, gamma=0.95)\n",
    "    elif (scheduler_name == 'ReduceLROnPlateau'):\n",
    "        scheduler = lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.1, patience=10)\n",
    "    elif (scheduler_name == 'CosineAnnealingLR'):\n",
    "        # scheduler = lr_scheduler.CosineAnnealingLR(optimizer, eta_min=0, T_max=50)\n",
    "        scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, eta_min=0, T_max=epoch_num)\n",
    "    elif (scheduler_name == 'OneCycleLR'):\n",
    "        scheduler = lr_scheduler.OneCycleLR(optimizer, max_lr=0.1, steps_per_epoch=len(train_loader), epochs=epoch_num)\n",
    "    else:\n",
    "        pass # 'no' scheduler\n",
    "    ## optimizer, scheduler ########################################################################\n",
    "\n",
    "\n",
    "    tr_acc = 0\n",
    "    tr_correct = 0\n",
    "    tr_total = 0\n",
    "    tr_acc_best = 0\n",
    "    tr_epoch_loss_temp = 0\n",
    "    tr_epoch_loss = 0\n",
    "    val_acc_best = 0\n",
    "    val_acc_now = 0\n",
    "    val_loss = 0\n",
    "    iter_of_val = False\n",
    "    max_activation_accul = 0\n",
    "    total_backward_count = 0\n",
    "    real_backward_count = 0\n",
    "    #======== EPOCH START ==========================================================================================\n",
    "    for epoch in range(epoch_num):\n",
    "        epoch_start_time = time.time()\n",
    "        print('total_backward_count', total_backward_count, 'real_backward_count',real_backward_count, f'{100*real_backward_count/(total_backward_count+0.00000001):7.3f}%')\n",
    "        if epoch == 1:\n",
    "            for name, module in net.named_modules():\n",
    "                if isinstance(module, Feedback_Receiver):\n",
    "                    print(f\"[{name}] weight_fb parameter count: {module.weight_fb.numel():,}\")\n",
    "        # optimizer.additional_dw_weight = 1.0 if epoch % 2 ==0 else 0.0\n",
    "        optimizer.additional_dw_weight = 1.0\n",
    "        max_val_box = []\n",
    "        max_val_scale_exp_8bit_box = []\n",
    "        max_val_scale_exp_16bit_box = []\n",
    "        perc_95_box = []\n",
    "        perc_95_scale_exp_8bit_box = []\n",
    "        perc_95_scale_exp_16bit_box = []\n",
    "        perc_99_box = []\n",
    "        perc_99_scale_exp_8bit_box = []\n",
    "        perc_99_scale_exp_16bit_box = []\n",
    "        perc_999_box = []\n",
    "        perc_999_scale_exp_8bit_box = []\n",
    "        perc_999_scale_exp_16bit_box = []\n",
    "        ##### weight í”„ë¦°íŠ¸ ######################################################################\n",
    "        for name, param in net.module.named_parameters():\n",
    "            if ('weight' in name or 'bias' in name) and ('1' in name or '4' in name or '7' in name):\n",
    "                \n",
    "                data = param.detach().cpu().numpy().flatten()\n",
    "                abs_data = np.abs(data)\n",
    "\n",
    "                # í†µê³„ëŸ‰ ê³„ì‚°\n",
    "                mean = np.mean(data)\n",
    "                std = np.std(data)\n",
    "                abs_mean = np.mean(abs_data)\n",
    "                abs_std = np.std(abs_data)\n",
    "                eps = 1e-15\n",
    "\n",
    "                # ì ˆëŒ€ê°’ ê¸°ë°˜ max, percentiles\n",
    "                max_val = abs_data.max()\n",
    "                max_val_scale_exp_8bit = math.ceil(math.log2((eps+max_val)/ (2**(8-1) -1)))\n",
    "                max_val_scale_exp_16bit = math.ceil(math.log2((eps+max_val)/ (2**(16-1) -1)))\n",
    "                perc_95 = np.percentile(abs_data, 95)\n",
    "                perc_95_scale_exp_8bit = math.ceil(math.log2((eps+perc_95)/ (2**(8-1) -1)))\n",
    "                perc_95_scale_exp_16bit = math.ceil(math.log2((eps+perc_95)/ (2**(16-1) -1)))\n",
    "                perc_99 = np.percentile(abs_data, 99)\n",
    "                perc_99_scale_exp_8bit = math.ceil(math.log2((eps+perc_99)/ (2**(8-1) -1)))\n",
    "                perc_99_scale_exp_16bit = math.ceil(math.log2((eps+perc_99)/ (2**(16-1) -1)))\n",
    "                perc_999 = np.percentile(abs_data, 99.9)\n",
    "                perc_999_scale_exp_8bit = math.ceil(math.log2((eps+perc_999)/ (2**(8-1) -1)))\n",
    "                perc_999_scale_exp_16bit = math.ceil(math.log2((eps+perc_999)/ (2**(16-1) -1)))\n",
    "                \n",
    "                max_val_box.append(max_val)\n",
    "                max_val_scale_exp_8bit_box.append(max_val_scale_exp_8bit)\n",
    "                max_val_scale_exp_16bit_box.append(max_val_scale_exp_16bit)\n",
    "                perc_95_box.append(perc_95)\n",
    "                perc_95_scale_exp_8bit_box.append(perc_95_scale_exp_8bit)\n",
    "                perc_95_scale_exp_16bit_box.append(perc_95_scale_exp_16bit)\n",
    "                perc_99_box.append(perc_99)\n",
    "                perc_99_scale_exp_8bit_box.append(perc_99_scale_exp_8bit)\n",
    "                perc_99_scale_exp_16bit_box.append(perc_99_scale_exp_16bit)\n",
    "                perc_999_box.append(perc_999)\n",
    "                perc_999_scale_exp_8bit_box.append(perc_999_scale_exp_8bit)\n",
    "                perc_999_scale_exp_16bit_box.append(perc_999_scale_exp_16bit)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "                # if epoch % 5 == 0 or epoch < 3:\n",
    "                #     print(\"=> Plotting weight and bias distributions...\")\n",
    "                #     # ê·¸ë˜í”„ ê·¸ë¦¬ê¸°\n",
    "                #     plt.figure(figsize=(6, 4))\n",
    "                #     plt.hist(data, bins=100, alpha=0.7, color='skyblue')\n",
    "                #     plt.axvline(x=max_val, color='red', linestyle='--', label=f'Max: {max_val:.4f}')\n",
    "                #     plt.axvline(x=-max_val, color='red', linestyle='--')\n",
    "                #     plt.axvline(x=perc_95, color='green', linestyle='--', label=f'95%: {perc_95:.4f}')\n",
    "                #     plt.axvline(x=-perc_95, color='green', linestyle='--')\n",
    "                #     plt.axvline(x=perc_99, color='orange', linestyle='--', label=f'99%: {perc_99:.4f}')\n",
    "                #     plt.axvline(x=-perc_99, color='orange', linestyle='--')\n",
    "                #     plt.axvline(x=perc_999, color='purple', linestyle='--', label=f'99.9%: {perc_999:.4f}')\n",
    "                #     plt.axvline(x=-perc_999, color='purple', linestyle='--')\n",
    "                    \n",
    "                #     # ì œëª©ì— í†µê³„ê°’ í¬í•¨\n",
    "                #     title = (\n",
    "                #         f\"{name}, Epoch {epoch}\\n\"\n",
    "                #         f\"mean={mean:.4f}, std={std:.4f}, \"\n",
    "                #         f\"|mean|={abs_mean:.4f}, |std|={abs_std:.4f}\\n\"\n",
    "                #         f\"Scale 8bit max = { max_val_scale_exp_8bit}, \"\n",
    "                #         f\"Scale 16bit max = {max_val_scale_exp_16bit}\\n\"\n",
    "                #         f\"Scale 8bit p999 = {perc_999_scale_exp_8bit }, \"\n",
    "                #         f\"Scale 16bit p999 = {perc_999_scale_exp_16bit }\\n\"\n",
    "                #         f\"Scale 8bit p99 = {perc_99_scale_exp_8bit }, \"\n",
    "                #         f\"Scale 16bit p99 = { perc_99_scale_exp_16bit}\\n\"\n",
    "                #         f\"Scale 8bit p95 = { perc_95_scale_exp_8bit}, \"\n",
    "                #         f\"Scale 16bit p95 = { perc_95_scale_exp_16bit}\"\n",
    "                #     )\n",
    "                #     plt.title(title)\n",
    "                #     plt.xlabel('Value')\n",
    "                #     plt.ylabel('Frequency')\n",
    "                #     plt.grid(True)\n",
    "                #     plt.legend()\n",
    "                #     plt.tight_layout()\n",
    "                #     plt.show()\n",
    "        ##### weight í”„ë¦°íŠ¸ ######################################################################\n",
    "\n",
    "        ####### iterator : input_loading & tqdmì„ í†µí•œ progress_bar ìƒì„±###################\n",
    "        # if epoch %2 == 0:\n",
    "        #     iterator = enumerate(train_loader, 0)\n",
    "        # else:\n",
    "        #     iterator = enumerate(test_loader, 0)\n",
    "        iterator = enumerate(train_loader, 0)\n",
    "        # iterator = tqdm(iterator, total=len(train_loader), desc='train', dynamic_ncols=True, position=0, leave=True)\n",
    "        ##################################################################################   \n",
    "\n",
    "        train_spike_distribution = []\n",
    "        train_predicted_distribution = []\n",
    "        ###### ITERATION START ##########################################################################################################\n",
    "        for i, data in iterator:\n",
    "            net.train() # train ëª¨ë“œë¡œ ë°”ê¿”ì¤˜ì•¼í•¨\n",
    "            ### data loading & semi-pre-processing ################################################################################\n",
    "            if len(data) == 2:\n",
    "                inputs, labels = data\n",
    "                # ì²˜ë¦¬ ë¡œì§ ì‘ì„±\n",
    "            elif len(data) == 3:\n",
    "                inputs, labels, x_len = data\n",
    "            else:\n",
    "                assert False, 'data length is not 2 or 3'\n",
    "            #######################################################################################################################\n",
    "                \n",
    "            ## batch í¬ê¸° ######################################\n",
    "            real_batch = labels.size(0)\n",
    "            ###########################################################\n",
    "\n",
    "            # ì°¨ì› ì „ì²˜ë¦¬\n",
    "            ###########################################################################################################################        \n",
    "            if (which_data == 'DVS_CIFAR10' or which_data == 'DVS_GESTURE' or which_data == 'DVS_GESTURE_TONIC' or which_data == 'DVS_CIFAR10_2' or which_data == 'NMNIST' or which_data == 'NMNIST_TONIC' or which_data == 'N_CALTECH101' or which_data == 'n_tidigits' or which_data == 'heidelberg'):\n",
    "                # inputs: [Batch, Time, Channel, Height, Width]\n",
    "                inputs = inputs.permute(1, 0, 2, 3, 4)\n",
    "            elif (which_data == 'n_tidigits_tonic'):\n",
    "                inputs = inputs.unsqueeze(-1)\n",
    "                inputs = inputs.permute(1, 0, 2, 3, 4)\n",
    "                # labels = torch.tensor(labels) \n",
    "            elif rate_coding == True :\n",
    "                inputs = spikegen.rate(inputs, num_steps=TIME)\n",
    "            else :\n",
    "                inputs = inputs.repeat(TIME, 1, 1, 1, 1)\n",
    "            # inputs: [Time, Batch, Channel, Height, Width]  \n",
    "            ####################################################################################################################### \n",
    "\n",
    "                            \n",
    "            if i == 1:\n",
    "                # SYNAPSE_FCì— ìˆëŠ” sparsity_print_and_reset() ì‹¤í–‰\n",
    "                for name, module in net.module.named_modules():\n",
    "                    if isinstance(module, SYNAPSE_FC):\n",
    "                        module.sparsity_print_and_reset()\n",
    "                        \n",
    "                            \n",
    "            ## initial pooling #######################################################################\n",
    "            if (initial_pooling > 1):\n",
    "                pool = nn.MaxPool2d(kernel_size=2)\n",
    "                num_pooling_layers = int(math.log2(initial_pooling))\n",
    "                # Time, Batch, Channel ì°¨ì›ì€ ê·¸ëŒ€ë¡œ ë‘ê³ , Height, Width ì°¨ì›ì— ëŒ€í•´ì„œë§Œ pooling ì ìš©\n",
    "                shape_temp = inputs.shape\n",
    "                inputs = inputs.reshape(shape_temp[0]*shape_temp[1], shape_temp[2], shape_temp[3], shape_temp[4])\n",
    "                for _ in range(num_pooling_layers):\n",
    "                    inputs = pool(inputs)\n",
    "                inputs = inputs.reshape(shape_temp[0], shape_temp[1], shape_temp[2], shape_temp[3]//initial_pooling, shape_temp[4]//initial_pooling)\n",
    "            ## initial pooling #######################################################################\n",
    "            \n",
    "            \n",
    "                        \n",
    "            ## ë°ì´í„°ë§ˆë‹¤ TIMESTEPSë‹¤ë¥´ë‹¤ ########################################################\n",
    "            hetero_timesteps = True\n",
    "            if hetero_timesteps == True:\n",
    "                assert real_batch == 1\n",
    "                this_data_timesteps = inputs.shape[0]\n",
    "                TIME = this_data_timesteps//temporal_filter\n",
    "                net.module.change_timesteps(TIME) # netì— TIME ì„¤ì •\n",
    "            ## ë°ì´í„°ë§ˆë‹¤ TIMESTEPSë‹¤ë¥´ë‹¤ ########################################################\n",
    "            \n",
    "\n",
    "            \n",
    "            ## temporal filtering ####################################################################\n",
    "            shape_temp = inputs.shape\n",
    "            if (temporal_filter > 1):\n",
    "                slice_bucket = []\n",
    "                for t_temp in range(TIME):\n",
    "                    start = t_temp * temporal_filter\n",
    "                    end = start + temporal_filter\n",
    "                    # inputs # [Time, Batch, Channel, Height, Width]\n",
    "                    # inputs # [Batch, Channel, Height,Time, Width]\n",
    "                    # inputs # [Batch, Channel, Height,Time * Width]\n",
    "                    slice_concat = torch.movedim(inputs[start:end], 0, -2).reshape(shape_temp[1],shape_temp[2],shape_temp[3],-1)\n",
    "                    \n",
    "                    if temporal_filter_accumulation == True:\n",
    "                        if t_temp == 0:\n",
    "                            slice_bucket.append(slice_concat)\n",
    "                        else:\n",
    "                            slice_bucket.append(slice_concat+slice_bucket[t_temp-1])\n",
    "                    else:\n",
    "                        slice_bucket.append(slice_concat)\n",
    "\n",
    "                inputs = torch.stack(slice_bucket, dim=0)\n",
    "                if temporal_filter_accumulation == True and dvs_clipping > 0:\n",
    "                    inputs = (inputs != 0.0).float()\n",
    "            ## temporal filtering ####################################################################\n",
    "            ####################################################################################################################### \n",
    "            \n",
    "            # if hetero_timesteps == True:\n",
    "            #     assert real_batch == 1\n",
    "            #     # inputs # [Time, Batch, Channel, Height, Width]\n",
    "            #     # inputs timestpeë³„ë¡œ sumê°’ì´ 10ë¯¸ë§Œì¼ ì‹œ ì œì™¸\n",
    "            #     # time stepë³„ í•© ê³„ì‚°: shape = [T]\n",
    "            #     timestep_sums = inputs.sum(dim=(1,2,3,4))  # sum over (B, C, H, W)\n",
    "\n",
    "            #     # 10 ì´ìƒì¸ íƒ€ì„ìŠ¤í…ë§Œ ì„ íƒ\n",
    "            #     valid_timesteps = timestep_sums >= timestep_sums_threshold\n",
    "            #     assert valid_timesteps.sum().item() != 0, \"No valid timesteps found. Check your data preprocessing.\"\n",
    "\n",
    "            #     # í•´ë‹¹ íƒ€ì„ìŠ¤í…ë§Œ ì¶”ì¶œ\n",
    "            #     inputs = inputs[valid_timesteps]\n",
    "            #     TIME = inputs.shape[0] # validí•œ time stepì˜ ê°œìˆ˜\n",
    "            #     net.module.change_timesteps(TIME) # netì— TIME ì„¤ì •\n",
    "            train_spike_distribution.append(TIME)\n",
    "\n",
    "            # # dvs ë°ì´í„° ì‹œê°í™” ì½”ë“œ (í™•ì¸ í•„ìš”í•  ì‹œ ì¨ë¼)\n",
    "            # ##############################################################################################\n",
    "            # dvs_visualization(inputs, labels, TIME, BATCH, my_seed)\n",
    "            # #####################################################################################################\n",
    "\n",
    "            ## to (device) #######################################\n",
    "            inputs = inputs.to(device).to(torch.float)\n",
    "            labels = labels.to(device).to(torch.long)\n",
    "            ###########################################################\n",
    "\n",
    "            # ## gradient ì´ˆê¸°í™” #######################################\n",
    "            # optimizer.zero_grad()\n",
    "            # ###########################################################\n",
    "                            \n",
    "            if merge_polarities == True:\n",
    "                inputs = inputs[:,:,0:1,:,:]\n",
    "\n",
    "            if single_step == False:\n",
    "                # netì— ë„£ì–´ì¤„ë•ŒëŠ” batchê°€ ì ¤ ì• ì°¨ì›ìœ¼ë¡œ ì™€ì•¼í•¨. # dataparallelë•Œë§¤##############################\n",
    "                # inputs: [Time, Batch, Channel, Height, Width]   \n",
    "                inputs = inputs.permute(1, 0, 2, 3, 4) # netì— ë„£ì–´ì¤„ë•ŒëŠ” batchê°€ ì ¤ ì• ì°¨ì›ìœ¼ë¡œ ì™€ì•¼í•¨. # dataparallelë•Œë§¤\n",
    "                # inputs: [Batch, Time, Channel, Height, Width] \n",
    "                #################################################################################################\n",
    "            else:\n",
    "                labels = labels.repeat(TIME, 1)\n",
    "                ## first inputë„ ottt trace ì ìš©í•˜ê¸° ìœ„í•œ ì½”ë“œ (validation ì‹œì—ëŠ” í•„ìš”X) ##########################\n",
    "                if trace_on == True and OTTT_input_trace_on == True:\n",
    "                    spike = inputs\n",
    "                    trace = torch.full_like(spike, fill_value = 0.0, dtype = torch.float, requires_grad=False)\n",
    "                    inputs = []\n",
    "                    for t in range(TIME):\n",
    "                        trace[t] = trace[t-1]*synapse_trace_const2 + spike[t]*synapse_trace_const1\n",
    "                        inputs += [[spike[t], trace[t]]]\n",
    "                ##################################################################################################\n",
    "\n",
    "\n",
    "            bp_timestep = random.randint(0, TIME - 1)  # 0 ~ TIME-1 ì¤‘ í•˜ë‚˜ ì„ íƒ\n",
    "            if single_step == False:\n",
    "                ### input --> net --> output #####################################################\n",
    "                outputs = net(inputs)\n",
    "                ##################################################################################\n",
    "                ## loss, backward ##########################################\n",
    "                iter_loss = criterion(outputs, labels)\n",
    "                iter_loss.backward()\n",
    "                ############################################################\n",
    "                ## weight ì—…ë°ì´íŠ¸!! ##################################\n",
    "                optimizer.step()\n",
    "                ################################################################\n",
    "            else:\n",
    "                outputs_all = []\n",
    "                iter_loss = 0.0\n",
    "                for t in range(TIME):\n",
    "                    optimizer.step() # full step time update\n",
    "                    optimizer.zero_grad()\n",
    "                    ### input[t] --> net --> output_one_time #########################################\n",
    "                    outputs_one_time = net(inputs[t])\n",
    "                    ##################################################################################\n",
    "                    one_time_loss = criterion(outputs_one_time, labels[t].contiguous())\n",
    "                    one_time_loss.backward() # one_time backward\n",
    "                    iter_loss += one_time_loss.data\n",
    "                    outputs_all.append(outputs_one_time.detach())\n",
    "\n",
    "                    total_backward_count = total_backward_count + 1\n",
    "                    outputs_one_time_argmax = ((outputs_one_time.detach()).argmax(dim=1) >= 5).long()\n",
    "                    real_backward_count = real_backward_count + (outputs_one_time_argmax != labels[t]).sum().item()\n",
    "\n",
    "                    # optimizer.additional_dw_weight = 1.0 if t == bp_timestep else 0.0\n",
    "                outputs_all = torch.stack(outputs_all, dim=1)\n",
    "                outputs = outputs_all.mean(1) # otttêº¼ ì“¸ë•Œ\n",
    "                labels = labels[0]\n",
    "                iter_loss /= TIME\n",
    "\n",
    "            tr_epoch_loss_temp += iter_loss.data/len(train_loader)\n",
    "\n",
    "            ## net ê·¸ë¦¼ ì¶œë ¥í•´ë³´ê¸° #################################################################\n",
    "            # print('ì‹œê°í™”')\n",
    "            # make_dot(outputs, params=dict(list(net.named_parameters()))).render(\"net_torchviz\", format=\"png\")\n",
    "            # return 0\n",
    "            ##################################################################################\n",
    "\n",
    "            #### batch ì–´ê¸‹ë‚¨ ë°©ì§€ ###############################################\n",
    "            assert real_batch == outputs.size(0), f'batch size is not same. real_batch: {real_batch}, outputs.size(0): {outputs.size(0)}'\n",
    "            #######################################################################\n",
    "            \n",
    "\n",
    "            ####### training accruacy save for print ###############################\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total = real_batch\n",
    "            \n",
    "            # target_0 = [0,1,2,3,4]\n",
    "            # target_1 = [5,6,7,8,9]\n",
    "            predicted = (predicted >= 5).long()\n",
    "            train_predicted_distribution.append(predicted.cpu().numpy())\n",
    "\n",
    "\n",
    "            correct = (predicted == labels).sum().item()\n",
    "            iter_acc = correct / total\n",
    "            tr_total += total\n",
    "            tr_correct += correct\n",
    "            iter_acc_string = f'epoch-{epoch:<3} iter_acc:{100 * iter_acc:7.2f}%, lr={[f\"{lr:9.7f}\" for lr in (param_group[\"lr\"] for param_group in optimizer.param_groups)]}'\n",
    "            iter_acc_string2 = f'epoch-{epoch:<3} lr={[f\"{lr:9.7f}\" for lr in (param_group[\"lr\"] for param_group in optimizer.param_groups)]}'\n",
    "            ################################################################\n",
    "            \n",
    "\n",
    "            ##### validation ##################################################################################################################################\n",
    "            # if True :\n",
    "            if i == len(train_loader)-1 :\n",
    "                \n",
    "                \n",
    "                train_predicted_distribution = np.array(train_predicted_distribution)\n",
    "                unique_vals, counts = np.unique(train_predicted_distribution, return_counts=True)\n",
    "                for val, count in zip(unique_vals, counts):\n",
    "                    print(f\"train - Value {val}: {count} occurrences\")\n",
    "\n",
    "                print(f'train_spike_distribution.mean {np.mean(train_spike_distribution):.6f}, min {np.min(train_spike_distribution)}, max {np.max(train_spike_distribution)}')\n",
    "\n",
    "\n",
    "                iter_of_val = True\n",
    "\n",
    "                tr_acc = tr_correct/tr_total\n",
    "                tr_correct = 0\n",
    "                tr_total = 0\n",
    "\n",
    "                val_loss = 0\n",
    "                correct_val = 0\n",
    "                total_val = 0\n",
    "                \n",
    "                test_spike_distribution = []\n",
    "                test_predicted_distribution = []\n",
    "                with torch.no_grad():\n",
    "                    net.eval() # eval ëª¨ë“œë¡œ ë°”ê¿”ì¤˜ì•¼í•¨ \n",
    "                    # for data_val in train_loader:\n",
    "                    for data_val in test_loader:\n",
    "                    # for data_val in test_loader:\n",
    "                        ## data_val loading & semi-pre-processing ##########################################################\n",
    "                        if len(data_val) == 2:\n",
    "                            inputs_val, labels_val = data_val\n",
    "                        elif len(data_val) == 3:\n",
    "                            inputs_val, labels_val, x_len = data_val\n",
    "                        else:\n",
    "                            assert False, 'data_val length is not 2 or 3'\n",
    "                            \n",
    "                        ## batch í¬ê¸° ######################################\n",
    "                        real_batch = labels_val.size(0)\n",
    "                        ###########################################################\n",
    "\n",
    "                        if (which_data == 'DVS_CIFAR10' or which_data == 'DVS_GESTURE' or which_data == 'DVS_GESTURE_TONIC' or which_data == 'DVS_CIFAR10_2' or which_data == 'NMNIST' or which_data == 'NMNIST_TONIC' or which_data == 'N_CALTECH101' or which_data == 'n_tidigits' or which_data == 'heidelberg'):\n",
    "                            inputs_val = inputs_val.permute(1, 0, 2, 3, 4)\n",
    "                        elif (which_data == 'n_tidigits_tonic'):\n",
    "                            inputs_val = inputs_val.unsqueeze(-1)\n",
    "                            inputs_val = inputs_val.permute(1, 0, 2, 3, 4)\n",
    "                            # labels_val = torch.tensor(labels_val)\n",
    "                        elif rate_coding == True :\n",
    "                            inputs_val = spikegen.rate(inputs_val, num_steps=TIME)\n",
    "                        else :\n",
    "                            inputs_val = inputs_val.repeat(TIME, 1, 1, 1, 1)\n",
    "                        # inputs_val: [Time, Batch, Channel, Height, Width]  \n",
    "                        ###################################################################################################\n",
    "\n",
    "                        \n",
    "                        ## initial pooling #######################################################################\n",
    "                        if (initial_pooling > 1):\n",
    "                            pool = nn.MaxPool2d(kernel_size=2)\n",
    "                            num_pooling_layers = int(math.log2(initial_pooling))\n",
    "                            # Time, Batch, Channel ì°¨ì›ì€ ê·¸ëŒ€ë¡œ ë‘ê³ , Height, Width ì°¨ì›ì— ëŒ€í•´ì„œë§Œ pooling ì ìš©\n",
    "                            shape_temp = inputs_val.shape\n",
    "                            inputs_val = inputs_val.reshape(shape_temp[0]*shape_temp[1], shape_temp[2], shape_temp[3], shape_temp[4])\n",
    "                            for _ in range(num_pooling_layers):\n",
    "                                inputs_val = pool(inputs_val)\n",
    "                            inputs_val = inputs_val.reshape(shape_temp[0], shape_temp[1], shape_temp[2], shape_temp[3]//initial_pooling, shape_temp[4]//initial_pooling)\n",
    "                        ## initial pooling #######################################################################\n",
    "                        \n",
    "                        ## ë°ì´í„°ë§ˆë‹¤ TIMESTEPSë‹¤ë¥´ë‹¤ ########################################################\n",
    "                        hetero_timesteps = True\n",
    "                        if hetero_timesteps == True:\n",
    "                            assert real_batch == 1\n",
    "                            this_data_timesteps = inputs_val.shape[0]\n",
    "                            TIME = this_data_timesteps//temporal_filter\n",
    "                            net.module.change_timesteps(TIME) # netì— TIME ì„¤ì •\n",
    "                        ## ë°ì´í„°ë§ˆë‹¤ TIMESTEPSë‹¤ë¥´ë‹¤ ########################################################\n",
    "                        \n",
    "\n",
    "\n",
    "                        ## temporal filtering ####################################################################\n",
    "                        shape_temp = inputs_val.shape\n",
    "                        if (temporal_filter > 1):\n",
    "                            slice_bucket = []\n",
    "                            for t_temp in range(TIME):\n",
    "                                start = t_temp * temporal_filter\n",
    "                                end = start + temporal_filter\n",
    "                                slice_concat = torch.movedim(inputs_val[start:end], 0, -2).reshape(shape_temp[1],shape_temp[2],shape_temp[3],-1)\n",
    "                                \n",
    "                                if temporal_filter_accumulation == True:\n",
    "                                    if t_temp == 0:\n",
    "                                        slice_bucket.append(slice_concat)\n",
    "                                    else:\n",
    "                                        slice_bucket.append(slice_concat+slice_bucket[t_temp-1])\n",
    "                                else:\n",
    "                                    slice_bucket.append(slice_concat)\n",
    "                            inputs_val = torch.stack(slice_bucket, dim=0)\n",
    "                            if temporal_filter_accumulation == True and dvs_clipping > 0:\n",
    "                                inputs_val = (inputs_val != 0.0).float()\n",
    "                        ## temporal filtering ####################################################################\n",
    "                        \n",
    "                                    \n",
    "                        # if hetero_timesteps == True:\n",
    "                        #     assert real_batch == 1\n",
    "                        #     # inputs_val # [Time, Batch, Channel, Height, Width]\n",
    "                        #     # inputs_val timestpeë³„ë¡œ sumê°’ì´ 10ë¯¸ë§Œì¼ ì‹œ ì œì™¸\n",
    "                        #     # time stepë³„ í•© ê³„ì‚°: shape = [T]\n",
    "                        #     timestep_sums = inputs_val.sum(dim=(1,2,3,4))  # sum over (B, C, H, W)\n",
    "\n",
    "                        #     # 10 ì´ìƒì¸ íƒ€ì„ìŠ¤í…ë§Œ ì„ íƒ\n",
    "                        #     valid_timesteps = timestep_sums >= timestep_sums_threshold\n",
    "                        #     assert valid_timesteps.sum().item() != 0, \"No valid timesteps found. Check your data preprocessing.\"\n",
    "\n",
    "                        #     # í•´ë‹¹ íƒ€ì„ìŠ¤í…ë§Œ ì¶”ì¶œ\n",
    "                        #     inputs_val = inputs_val[valid_timesteps]\n",
    "                        #     TIME = inputs_val.shape[0] # validí•œ time stepì˜ ê°œìˆ˜\n",
    "                        #     net.module.change_timesteps(TIME) # netì— TIME ì„¤ì •\n",
    "                        test_spike_distribution.append(TIME)\n",
    "                        \n",
    "                        \n",
    "                        \n",
    "                        # # dvs ë°ì´í„° ì‹œê°í™” ì½”ë“œ (í™•ì¸ í•„ìš”í•  ì‹œ ì¨ë¼)\n",
    "                        # ##############################################################################################\n",
    "                        # dvs_visualization(inputs_val, labels_val, TIME, BATCH, my_seed)\n",
    "                        # #####################################################################################################\n",
    "\n",
    "                        inputs_val = inputs_val.to(torch.float).to(device)\n",
    "                        labels_val = labels_val.to(torch.long).to(device)\n",
    "                        \n",
    "                        if merge_polarities == True:\n",
    "                            inputs_val = inputs_val[:,:,0:1,:,:]\n",
    "\n",
    "                        ## network ì—°ì‚° ì‹œì‘ ############################################################################################################\n",
    "                        if single_step == False:\n",
    "                            outputs = net(inputs_val.permute(1, 0, 2, 3, 4)) #inputs_val: [Batch, Time, Channel, Height, Width]  \n",
    "                            val_loss += criterion(outputs, labels_val)/len(test_loader)\n",
    "                        else:\n",
    "                            outputs_all = []\n",
    "                            for t in range(TIME):\n",
    "                                outputs = net(inputs_val[t])\n",
    "                                val_loss_temp = criterion(outputs, labels_val)\n",
    "                                outputs_all.append(outputs.detach())\n",
    "                                val_loss += (val_loss_temp.data/TIME)/len(test_loader)\n",
    "                            outputs_all = torch.stack(outputs_all, dim=1)\n",
    "                            outputs = outputs_all.mean(1)\n",
    "                            \n",
    "                            if max_activation_accul < outputs.abs().max().item() * TIME * (2**(-scale_exp[2][0])):\n",
    "                                max_activation_accul = outputs.abs().max().item() * TIME * (2**(-scale_exp[2][0]))\n",
    "                                print(f\"max_activation_accul updated: {max_activation_accul:.2f} at epoch {epoch}, iter {i}\")\n",
    "                       \n",
    "                        #################################################################################################################################\n",
    "\n",
    "                        _, predicted = torch.max(outputs.data, 1)\n",
    "                        total_val += real_batch\n",
    "                        assert real_batch == outputs.size(0), f'batch size is not same. real_batch: {real_batch}, outputs.size(0): {outputs.size(0)}'\n",
    "                                    \n",
    "                        predicted = (predicted >= 5).long()\n",
    "                        correct_val += (predicted == labels_val).sum().item()\n",
    "                        test_predicted_distribution.append(predicted.cpu().numpy())\n",
    "\n",
    "                    print(f'test_spike_distribution.mean {np.mean(test_spike_distribution):.6f}, min {np.min(test_spike_distribution)}, max {np.max(test_spike_distribution)}')\n",
    "\n",
    "                    test_predicted_distribution = np.array(test_predicted_distribution)\n",
    "                    unique_vals, counts = np.unique(test_predicted_distribution, return_counts=True)\n",
    "                    for val, count in zip(unique_vals, counts):\n",
    "                        print(f\"test - Value {val}: {count} occurrences\")\n",
    "                    val_acc_now = correct_val / total_val\n",
    "\n",
    "                if val_acc_best < val_acc_now:\n",
    "                    val_acc_best = val_acc_now\n",
    "                    # wandb í‚¤ë©´ state_dictì•„ë‹Œê±°ëŠ” ì €ì¥ ì•ˆë¨\n",
    "                    # network save\n",
    "                    torch.save(net.state_dict(), f\"net_save/save_now_net_weights_{unique_name}.pth\")\n",
    "\n",
    "\n",
    "                if tr_acc_best < tr_acc:\n",
    "                    tr_acc_best = tr_acc\n",
    "\n",
    "                tr_epoch_loss = tr_epoch_loss_temp\n",
    "                tr_epoch_loss_temp = 0\n",
    "\n",
    "            ####################################################################################################################################################\n",
    "            \n",
    "            ## progress bar update ############################################################################################################\n",
    "            epoch_end_time = time.time()\n",
    "            epoch_time = epoch_end_time - epoch_start_time\n",
    "            if iter_of_val == False:\n",
    "                # iterator.set_description(f\"{iter_acc_string}, iter_loss:{iter_loss:10.6f}\") \n",
    "                pass \n",
    "            else:\n",
    "                # iterator.set_description(f\"{iter_acc_string2}, tr/val_loss:{tr_epoch_loss:10.6f}/{val_loss:10.6f}, tr:{100 * tr_acc:7.2f}%, tr_best:{100 * tr_acc_best:7.2f}%, val:{100 * val_acc_now:7.2f}%, val_best:{100 * val_acc_best:7.2f}%\")  \n",
    "                print(f\"{iter_acc_string2}, tr/val_loss:{tr_epoch_loss:10.6f}/{val_loss:10.6f}, val:{100 * val_acc_now:7.2f}%, val_best:{100 * val_acc_best:7.2f}%, tr:{100 * tr_acc:7.2f}%, tr_best:{100 * tr_acc_best:7.2f}%, epoch time: {epoch_time:.2f} seconds, {epoch_time/60:.2f} minutes\")\n",
    "                iter_of_val = False\n",
    "            ####################################################################################################################################\n",
    "            \n",
    "            ## wandb logging ############################################################################################################\n",
    "            if i == len(train_loader)-1 :\n",
    "                wandb.log({\"iter_acc\": iter_acc})\n",
    "                wandb.log({\"tr_acc\": tr_acc})\n",
    "                wandb.log({\"val_acc_now\": val_acc_now})\n",
    "                wandb.log({\"val_acc_best\": val_acc_best})\n",
    "                wandb.log({\"summary_val_acc\": val_acc_now})\n",
    "                wandb.log({\"epoch\": epoch})\n",
    "                wandb.log({\"val_loss\": val_loss}) \n",
    "                wandb.log({\"tr_epoch_loss\": tr_epoch_loss}) \n",
    "                # wandb.log({\"max_val_scale_exp_8bit_1w\": max_val_scale_exp_8bit_box[0]}) \n",
    "                # wandb.log({\"max_val_scale_exp_8bit_1b\": max_val_scale_exp_8bit_box[1]})\n",
    "                # wandb.log({\"max_val_scale_exp_8bit_2w\": max_val_scale_exp_8bit_box[2]}) \n",
    "                # wandb.log({\"max_val_scale_exp_8bit_2b\": max_val_scale_exp_8bit_box[3]}) \n",
    "                # wandb.log({\"max_val_scale_exp_8bit_3w\": max_val_scale_exp_8bit_box[4]}) \n",
    "                # wandb.log({\"max_val_scale_exp_8bit_3b\": max_val_scale_exp_8bit_box[5]})\n",
    "\n",
    "                # wandb.log({\"perc_999_scale_exp_8bit_1w\": perc_999_scale_exp_8bit_box[0]}) \n",
    "                # wandb.log({\"perc_999_scale_exp_8bit_1b\": perc_999_scale_exp_8bit_box[1]})\n",
    "                # wandb.log({\"perc_999_scale_exp_8bit_2w\": perc_999_scale_exp_8bit_box[2]}) \n",
    "                # wandb.log({\"perc_999_scale_exp_8bit_2b\": perc_999_scale_exp_8bit_box[3]}) \n",
    "                # wandb.log({\"perc_999_scale_exp_8bit_3w\": perc_999_scale_exp_8bit_box[4]}) \n",
    "                # wandb.log({\"perc_999_scale_exp_8bit_3b\": perc_999_scale_exp_8bit_box[5]}) \n",
    "\n",
    "                for name, module in net.module.named_modules():\n",
    "                    if isinstance(module, SYNAPSE_FC):\n",
    "                        module.sparsity_print_and_reset()\n",
    "                \n",
    "                if epoch > 0:\n",
    "                    assert val_acc_best > 0.2\n",
    "                elif epoch > 10:\n",
    "                    assert val_acc_best > 0.4\n",
    "                elif epoch > 30:\n",
    "                    assert val_acc_best > 0.5\n",
    "                elif epoch > 100:\n",
    "                    assert val_acc_best > 0.6\n",
    "                    \n",
    "            ####################################################################################################################################\n",
    "            \n",
    "        ###### ITERATION END ##########################################################################################################\n",
    "\n",
    "        ## scheduler update #############################################################################\n",
    "        if (scheduler_name != 'no'):\n",
    "            if (scheduler_name == 'ReduceLROnPlateau'):\n",
    "                scheduler.step(val_loss)\n",
    "            else:\n",
    "                scheduler.step()\n",
    "        #################################################################################################\n",
    "        \n",
    "    #======== EPOCH END ==========================================================================================\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# unique_name = 'main' ## ì´ê±° ì„¤ì •í•˜ë©´ ìƒˆë¡œìš´ ê²½ë¡œì— ëª¨ë‘ save\n",
    "# wandb.init(project= f'my_snn {unique_name}',save_code=False, dir='/data2/bh_wandb', tags=[\"common\"])\n",
    "# ## wandb ê³¼ê±° í•˜ì´í¼íŒŒë¼ë¯¸í„° ê°€ì ¸ì™€ì„œ ë¶™ì—¬ë„£ê¸° (devices unique_nameì€ ë‹ˆê°€ í• ë‹¹í•´ë¼)#################################\n",
    "# param = {'devices': '3', 'single_step': True, 'unique_name': 'main', 'my_seed': 42, 'TIME': 10, 'BATCH': 16, 'IMAGE_SIZE': 128, 'which_data': 'DVS_GESTURE_TONIC', 'data_path': '/data2', 'rate_coding': False, 'lif_layer_v_init': 0, 'lif_layer_v_decay': 0.25, 'lif_layer_v_threshold': 0.75, 'lif_layer_v_reset': 0, 'lif_layer_sg_width': 4, 'synapse_conv_kernel_size': 3, 'synapse_conv_stride': 1, 'synapse_conv_padding': 1, 'synapse_trace_const1': 1, 'synapse_trace_const2': 0, 'pre_trained': False, 'convTrue_fcFalse': False, 'cfg': [200, 200], 'net_print': True, 'pre_trained_path': 'net_save/save_now_net_weights_{unique_name}.pth', 'learning_rate': 0.001, 'epoch_num': 100, 'tdBN_on': False, 'BN_on': False, 'surrogate': 'hard_sigmoid', 'BPTT_on': False, 'optimizer_what': 'SGD', 'scheduler_name': 'no', 'ddp_on': False, 'dvs_clipping': 2, 'dvs_duration': 25000, 'DFA_on': True, 'trace_on': True, 'OTTT_input_trace_on': False, 'exclude_class': True, 'merge_polarities': False, 'denoise_on': True, 'extra_train_dataset': 0, 'num_workers': 2, 'chaching_on': True, 'pin_memory': True, 'UDA_on': False, 'alpha_uda': 1, 'bias': True, 'last_lif': False, 'temporal_filter': 5, 'initial_pooling': 8}\n",
    "# my_snn_system(devices = '0',single_step = param['single_step'],unique_name = unique_name,my_seed = param['my_seed'],TIME = param['TIME'],BATCH = param['BATCH'],IMAGE_SIZE = param['IMAGE_SIZE'],which_data = param['which_data'],data_path = param['data_path'],rate_coding = param['rate_coding'],lif_layer_v_init = param['lif_layer_v_init'],lif_layer_v_decay = param['lif_layer_v_decay'],lif_layer_v_threshold = param['lif_layer_v_threshold'],lif_layer_v_reset = param['lif_layer_v_reset'],lif_layer_sg_width = param['lif_layer_sg_width'],synapse_conv_kernel_size = param['synapse_conv_kernel_size'],synapse_conv_stride = param['synapse_conv_stride'],synapse_conv_padding = param['synapse_conv_padding'],synapse_trace_const1 = param['synapse_trace_const1'],synapse_trace_const2 = param['synapse_trace_const2'],pre_trained = param['pre_trained'],convTrue_fcFalse = param['convTrue_fcFalse'],cfg = param['cfg'],net_print = param['net_print'],pre_trained_path = param['pre_trained_path'],learning_rate = param['learning_rate'],epoch_num = param['epoch_num'],tdBN_on = param['tdBN_on'],BN_on = param['BN_on'],surrogate = param['surrogate'],BPTT_on = param['BPTT_on'],optimizer_what = param['optimizer_what'],scheduler_name = param['scheduler_name'],ddp_on = param['ddp_on'],dvs_clipping = param['dvs_clipping'],dvs_duration = param['dvs_duration'],DFA_on = param['DFA_on'],trace_on = param['trace_on'],OTTT_input_trace_on = param['OTTT_input_trace_on'],exclude_class = param['exclude_class'],merge_polarities = param['merge_polarities'],denoise_on = param['denoise_on'],extra_train_dataset = param['extra_train_dataset'],num_workers = param['num_workers'],chaching_on = param['chaching_on'],pin_memory = param['pin_memory'],UDA_on = param['UDA_on'],alpha_uda = param['alpha_uda'],bias = param['bias'],last_lif = param['last_lif'],temporal_filter = param['temporal_filter'],initial_pooling = param['initial_pooling'],temporal_filter_accumulation= param['temporal_filter_accumulation'])\n",
    "# #############################################################################\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ### my_snn control board (Gesture) ########################\n",
    "# decay = 0.5 # 0.0 # 0.875 0.25 0.125 0.75 0.5\n",
    "# # nda 0.25 # ottt 0.5\n",
    "\n",
    "# unique_name = 'main'\n",
    "# run_name = datetime.datetime.now().strftime(\"%Y%m%d_%H%M%S_\") + f\"{datetime.datetime.now().microsecond // 1000:03d}\"\n",
    "\n",
    "# wandb.init(project=f'my_snn NTIDIGITS SWEEP LOSER ONOFF new251129',save_code=False, dir='/data2/bh_wandb', tags=[\"common\"])\n",
    "\n",
    "\n",
    "# my_snn_system(  devices = \"5\",\n",
    "#                 single_step = True, # True # False # DFA_onì´ë‘ ê°™ì´ ê°€ë¼\n",
    "#                 unique_name = run_name,\n",
    "#                 my_seed = 42,\n",
    "#                 TIME = 4, # dvscifar 10 # ottt 6 or 10 # nda 10  # ì œì‘í•˜ëŠ” dvsì—ì„œ TIMEë„˜ê±°ë‚˜ ì ìœ¼ë©´ ìë¥´ê±°ë‚˜ PADDINGí•¨\n",
    "#                 BATCH = 1, # batch norm í• ê±°ë©´ 2ì´ìƒìœ¼ë¡œ í•´ì•¼í•¨   # nda 256   #  ottt 128\n",
    "#                 IMAGE_SIZE = 8, # dvscifar 48 # MNIST 28 # CIFAR10 32 # PMNIST 28 #NMNIST 34 # GESTURE 128\n",
    "#                 # dvsgesture 128, dvs_cifar2 128, nmnist 34, n_caltech101 180,240, n_tidigits 64, heidelberg 700, \n",
    "#                 # n_tidigits_tonic 8\n",
    "\n",
    "#                 # DVS_CIFAR10 í• ê±°ë©´ time 10ìœ¼ë¡œ í•´ë¼\n",
    "#                 which_data = 'n_tidigits_tonic',\n",
    "# # 'CIFAR100' 'CIFAR10' 'MNIST' 'FASHION_MNIST' 'DVS_CIFAR10' 'PMNIST'ì•„ì§\n",
    "# # 'DVS_GESTURE', 'DVS_GESTURE_TONIC','n_tidigits_tonic', 'DVS_CIFAR10_2','NMNIST','NMNIST_TONIC','CIFAR10','N_CALTECH101','n_tidigits','heidelberg'\n",
    "#                 # CLASS_NUM = 10,\n",
    "#                 data_path = '/data2', # YOU NEED TO CHANGE THIS\n",
    "#                 rate_coding = False, # True # False\n",
    "\n",
    "#                 lif_layer_v_init = 0.0,\n",
    "#                 lif_layer_v_decay = decay,\n",
    "#                 lif_layer_v_threshold = 256,   #nda 0.5  #ottt 1.0\n",
    "#                 lif_layer_v_reset = 10000.0, # 10000ì´ìƒì€ hardreset (ë‚´ LIFì“°ê¸°ëŠ” í•¨ ã…‡ã…‡)\n",
    "#                 lif_layer_sg_width = 4.0, # 2.570969004857107 # sigmoidë¥˜ì—ì„œëŠ” alphaê°’ 4.0, rectangleë¥˜ì—ì„œëŠ” widthê°’ 0.5\n",
    "\n",
    "#                 # synapse_conv_in_channels = IMAGE_PIXEL_CHANNEL,\n",
    "#                 synapse_conv_kernel_size = 3,\n",
    "#                 synapse_conv_stride = 1,\n",
    "#                 synapse_conv_padding = 1,\n",
    "\n",
    "#                 synapse_trace_const1 = 1, # í˜„ì¬ traceêµ¬í•  ë•Œ í˜„ì¬ spikeì— ê³±í•´ì§€ëŠ” ìƒìˆ˜. ê± 1ë¡œ ë‘ì…ˆ.\n",
    "#                 synapse_trace_const2 = decay, # í˜„ì¬ traceêµ¬í•  ë•Œ ì§ì „ traceì— ê³±í•´ì§€ëŠ” ìƒìˆ˜. lif_layer_v_decayì™€ ê°™ê²Œ í•  ê²ƒì„ ì¶”ì²œ\n",
    "\n",
    "#                 # synapse_fc_out_features = CLASS_NUM,\n",
    "\n",
    "#                 pre_trained = False, # True # False\n",
    "#                 convTrue_fcFalse = False, # True # False\n",
    "\n",
    "#                 # 'P' for average pooling, 'D' for (1,1) aver pooling, 'M' for maxpooling, 'L' for linear classifier, [  ] for residual block\n",
    "#                 # convì—ì„œ 10000 ì´ìƒì€ depth-wise separable (BPTTë§Œ ì§€ì›), 20000ì´ìƒì€ depth-wise (BPTTë§Œ ì§€ì›)\n",
    "#                 # cfg = ['M', 'M', 32, 'P', 32, 'P', 32, 'P'], \n",
    "#                 # cfg = ['M', 'M', 64, 'P', 64, 'P', 64, 'P'], \n",
    "#                 # cfg = ['M', 'M', 64, 'M', 96, 'M', 128, 'M'], \n",
    "#                 cfg = [200, 200], \n",
    "#                 # cfg = ['M', 'M', 64, 'M', 96], \n",
    "#                 # cfg = ['M', 'M', 64, 'M', 96, 'L', 512, 512], \n",
    "#                 # cfg = ['M', 'M', 64], \n",
    "#                 # cfg = [64, 124, 64, 124],\n",
    "#                 # cfg = ['M','M',512], \n",
    "#                 # cfg = [512], \n",
    "#                 # cfg = ['M', 'M', 64, 128, 'P', 128, 'P'], \n",
    "#                 # cfg = ['M','M',512],\n",
    "#                 # cfg = ['M',200],\n",
    "#                 # cfg = [200,200],\n",
    "#                 # cfg = ['M','M',200,200],\n",
    "#                 # cfg = ([200],[200],[200],[2]), # (feature extractor, classifier, domain adapter, # of domain)\n",
    "#                 # cfg = (['M','M',200],[200],[200],[2]), # (feature extractor, classifier, domain adapter, # of domain)\n",
    "#                 # cfg = ['M',200,200],\n",
    "#                 # cfg = ['M','M',1024,512,256,128,64],\n",
    "#                 # cfg = [200,200],\n",
    "#                 # cfg = [12], #fc\n",
    "#                 # cfg = [12, 'M', 48, 'M', 12], \n",
    "#                 # cfg = [64,[64,64],64], # ëì— linear classifier í•˜ë‚˜ ìë™ìœ¼ë¡œ ë¶™ìŠµë‹ˆë‹¤\n",
    "#                 # cfg = [64, 128, 'P', 256, 256, 'P', 512, 512, 'P', 512, 512, 'D'], #ottt\n",
    "#                 # cfg = [64, 128, 'P', 256, 256, 'P', 512, 512, 'P', 512, 512], \n",
    "#                 # cfg = [64, 128, 'M', 256, 256, 'M', 512, 512, 'M', 512, 512], \n",
    "#                 # cfg = [64, 'P', 128, 'P', 256, 256, 'P', 512, 512, 512, 512, 'D'], # nda\n",
    "#                 # cfg = [64, 'P', 128, 'P', 256, 256, 'P', 512, 512, 512, 512], # nda 128pixel\n",
    "#                 # cfg = [64, 'P', 128, 'P', 256, 256, 'P', 512, 512, 512, 512, 'L', 4096, 4096],\n",
    "#                 # cfg = [20001,10001], # depthwise, separable\n",
    "#                 # cfg = [64,20064,10001], # vanilla conv, depthwise, separable\n",
    "#                 # cfg = [8, 'P', 8, 'P', 8, 'P', 8,'P', 8, 'P'],\n",
    "#                 # cfg = [],        \n",
    "                \n",
    "#                 net_print = True, # True # False # Trueë¡œ í•˜ê¸¸ ì¶”ì²œ\n",
    "                \n",
    "#                 # pre_trained_path = f\"net_save/save_now_net_weights_{unique_name}.pth\",\n",
    "#                 pre_trained_path = f\"net_save/save_now_net_weights_20250704_185524_987.pth\",\n",
    "#                 # learning_rate = 0.001, #0.1 bptt, #0.01 ottt, # default 0.001  # ottt 0.1 # nda 0.001 # 0.00936191669529645\n",
    "#                 learning_rate = 2, #0.1 bptt, #0.01 ottt, # default 0.001  # ottt 0.1 # nda 0.001 # 0.00936191669529645\n",
    "#                 epoch_num = 200,\n",
    "#                 tdBN_on = False,  # True # False\n",
    "#                 BN_on = False,  # True # False\n",
    "                \n",
    "#                 surrogate = 'hard_sigmoid', # 'sigmoid' 'rectangle' 'rough_rectangle' 'hard_sigmoid'\n",
    "                \n",
    "#                 BPTT_on = False,  # True # False # Trueì´ë©´ BPTT, Falseì´ë©´ OTTT  # depthwise, separableì€ BPTTë§Œ ê°€ëŠ¥\n",
    "                \n",
    "#                 optimizer_what = 'SGD', # 'SGD' 'Adam', 'RMSprop'\n",
    "#                 scheduler_name = 'no', # 'no' 'StepLR' 'ExponentialLR' 'ReduceLROnPlateau' 'CosineAnnealingLR' 'OneCycleLR'\n",
    "                \n",
    "#                 ddp_on = False, # DECREPATED # fALSE\n",
    "\n",
    "#                 dvs_clipping = 1, #ì¼ë°˜ì ìœ¼ë¡œ 1 ë˜ëŠ” 2 # 100msë•ŒëŠ” 5 # ìˆ«ìë§Œí¼ í¬ë©´ spike ì•„ë‹ˆë©´ ê± 0\n",
    "#                 # gesture, cifar-dvs2, nmnist, ncaltech101\n",
    "#                 # gesture: 100_000c1-5, 25_000c5, 10_000c5, 1_000c5, 1_000_000c5\n",
    "\n",
    "#                 dvs_duration = 2, # 0 ì•„ë‹ˆë©´ time sampling # dvs number sampling OR time sampling # gesture, cifar-dvs2, nmnist, ncaltech101\n",
    "#                 # ìˆëŠ” ë°ì´í„°ë“¤ #gesture 100_000 25_000 10_000 1_000 1_000_000 #nmnist 10000 #nmnist_tonic 10_000 25_000\n",
    "#                 # í•œ ìˆ«ìê°€ 1usì¸ë“¯ (spikingjellyì½”ë“œì—ì„œ)\n",
    "#                 # í•œ ì¥ì— 50 timestepë§Œ ìƒì‚°í•¨. ì‹«ìœ¼ë©´ my_snn/trying/spikingjelly_dvsgestureì˜__init__.py ë¥¼ ì°¸ê³ í•´ë´\n",
    "#                 # nmnist 5_000us, gestureëŠ” 100_000us, 25_000us\n",
    "\n",
    "#                 DFA_on = True, # True # False # single_stepì´ë‘ ê°™ì´ ì¼œì•¼ ë¨.\n",
    "\n",
    "#                 trace_on = False,   # True # False\n",
    "#                 OTTT_input_trace_on = False, # True # False # ë§¨ ì²˜ìŒ inputì— trace ì ìš© # trace_on Falseë©´ ì˜ë¯¸ì—†ìŒ.\n",
    "\n",
    "#                 exclude_class = True, # True # False # gestureì—ì„œ 10ë²ˆì§¸ í´ë˜ìŠ¤ ì œì™¸\n",
    "\n",
    "#                 merge_polarities = False, # True # False # tonic dvs dataset ì—ì„œ polarities í•©ì¹˜ê¸°\n",
    "#                 denoise_on = False, # True # False # &&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&\n",
    "\n",
    "#                 extra_train_dataset = 9, \n",
    "\n",
    "#                 num_workers = 2, # local wslì—ì„œëŠ” 2ê°€ ë§ê³ , ì„œë²„ì—ì„œëŠ” 4ê°€ ì¢‹ë”ë¼.\n",
    "#                 chaching_on = False, # True # False # only for certain datasets (gesture_tonic, nmnist_tonic)\n",
    "#                 pin_memory = True, # True # False \n",
    "\n",
    "#                 UDA_on = False,  # DECREPATED # uda\n",
    "#                 alpha_uda = 1.0, # DECREPATED # uda\n",
    "\n",
    "#                 bias = False, # True # False \n",
    "\n",
    "#                 last_lif = False, # True # False \n",
    "\n",
    "#                 temporal_filter = 8, \n",
    "#                 initial_pooling = 1,\n",
    "\n",
    "#                 temporal_filter_accumulation = False, # True # False \n",
    "\n",
    "#                 quantize_bit_list=[8,8,8],\n",
    "#                 scale_exp=[[0,0],[0,0],[0,0]], \n",
    "#                 # quantize_bit_list=[],\n",
    "#                 # scale_exp=[], \n",
    "#                 timestep_sums_threshold = 0,\n",
    "\n",
    "#                 loser_encourage_mode = False,# True # False\n",
    "                \n",
    "#                 lif_layer_sg_width2 = 16.0,\n",
    "#                 lif_layer_v_threshold2 = 512.0,\n",
    "#                 learning_rate2 = 1,\n",
    "#                 # init_scaling = [10000+ 12,10000+ 12,10000+ 11],\n",
    "#                 init_scaling = [1/2,1/4,1/16],\n",
    "#                 ) \n",
    "\n",
    "# # num_workers = 4 * num_GPU (or 8, 16, 2 * num_GPU)\n",
    "# # entry * batch_size * num_worker = num_GPU * GPU_throughtput\n",
    "# # num_workers = batch_size / num_GPU\n",
    "# # num_workers = batch_size / num_CPU\n",
    "\n",
    "# # sigmoidì™€ BNì´ ìˆì–´ì•¼ ì˜ëœë‹¤.\n",
    "# # average pooling  \n",
    "# # ì´ ë‚«ë‹¤. \n",
    "\n",
    "# # ndaì—ì„œëŠ” decay = 0.25, threshold = 0.5, width =1, surrogate = rectangle, batch = 256, tdBN = True\n",
    "# ## OTTT ì—ì„œëŠ” decay = 0.5, threshold = 1.0, surrogate = sigmoid, batch = 128, BN = True\n",
    "\n",
    "# wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: e4xyk7iu with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBATCH: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBN_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tBPTT_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tDFA_on: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tIMAGE_SIZE: 8\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tOTTT_input_trace_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tTIME: 8\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tUDA_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \talpha_uda: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbias: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcfg: [200, 200]\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tchaching_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tconvTrue_fcFalse: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdata_path: /data2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tddp_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdenoise_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdvs_clipping: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdvs_duration: 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepoch_num: 200\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \texclude_class: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \textra_train_dataset: 9\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tinit_scaling_0: 0.5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tinit_scaling_1: 0.25\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tinit_scaling_2: 0.0625\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tinitial_pooling: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlast_lif: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate2: 8\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_sg_width: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_sg_width2: 32\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_decay: 0.5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_init: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_reset: 10000\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_threshold: 2048\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlif_layer_v_threshold2: 256\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tloser_encourage_mode: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmerge_polarities: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmy_seed: 34058\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnet_print: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_workers: 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer_what: SGD\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tpin_memory: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tpre_trained: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tpre_trained_path: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tquantize_bit_list_0: 8\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tquantize_bit_list_1: 8\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tquantize_bit_list_2: 8\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \trate_coding: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tscale_exp_1w: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tscale_exp_2w: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tscale_exp_3w: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tscheduler_name: no\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsingle_step: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsurrogate: hard_sigmoid\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_conv_kernel_size: 3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_conv_padding: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_conv_stride: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_trace_const1: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsynapse_trace_const2: 0.5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \ttdBN_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \ttemporal_filter: 8\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \ttemporal_filter_accumulation: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \ttimestep_sums_threshold: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \ttrace_on: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \twhich_data: n_tidigits_tonic\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mbhkim003\u001b[0m (\u001b[33mbhkim003-seoul-national-university\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.23.1 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.17.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/data2/bh_wandb/wandb/run-20251226_142720-e4xyk7iu</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20NTIDIGITS%20SWEEP%20LOSER%20ONOFF%20new251129/runs/e4xyk7iu' target=\"_blank\">smooth-sweep-4</a></strong> to <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20NTIDIGITS%20SWEEP%20LOSER%20ONOFF%20new251129' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20NTIDIGITS%20SWEEP%20LOSER%20ONOFF%20new251129/sweeps/mg47irsg' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20NTIDIGITS%20SWEEP%20LOSER%20ONOFF%20new251129/sweeps/mg47irsg</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20NTIDIGITS%20SWEEP%20LOSER%20ONOFF%20new251129' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20NTIDIGITS%20SWEEP%20LOSER%20ONOFF%20new251129</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20NTIDIGITS%20SWEEP%20LOSER%20ONOFF%20new251129/sweeps/mg47irsg' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20NTIDIGITS%20SWEEP%20LOSER%20ONOFF%20new251129/sweeps/mg47irsg</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20NTIDIGITS%20SWEEP%20LOSER%20ONOFF%20new251129/runs/e4xyk7iu' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20NTIDIGITS%20SWEEP%20LOSER%20ONOFF%20new251129/runs/e4xyk7iu</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'single_step' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'my_seed' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'TIME' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BATCH' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'IMAGE_SIZE' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'which_data' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'data_path' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'rate_coding' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_init' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_decay' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_threshold' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_reset' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_sg_width' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_conv_kernel_size' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_conv_stride' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_conv_padding' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_trace_const1' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'synapse_trace_const2' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'pre_trained' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'convTrue_fcFalse' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'cfg' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'net_print' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'pre_trained_path' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'epoch_num' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'tdBN_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BN_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'surrogate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'BPTT_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'optimizer_what' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'scheduler_name' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'ddp_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'dvs_clipping' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'dvs_duration' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'DFA_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'trace_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'OTTT_input_trace_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'exclude_class' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'merge_polarities' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'denoise_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'extra_train_dataset' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'num_workers' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'chaching_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'pin_memory' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'UDA_on' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'alpha_uda' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'bias' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'last_lif' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'temporal_filter' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'initial_pooling' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'temporal_filter_accumulation' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'timestep_sums_threshold' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_sg_width2' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lif_layer_v_threshold2' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'learning_rate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'learning_rate2' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'loser_encourage_mode' was locked by 'sweep' (ignored update).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "param {'devices': '2', 'single_step': True, 'unique_name': '20251226_142726_739', 'my_seed': 34058, 'TIME': 8, 'BATCH': 1, 'IMAGE_SIZE': 8, 'which_data': 'n_tidigits_tonic', 'data_path': '/data2', 'rate_coding': False, 'lif_layer_v_init': 0, 'lif_layer_v_decay': 0.5, 'lif_layer_v_threshold': 2048, 'lif_layer_v_reset': 10000, 'lif_layer_sg_width': 1, 'synapse_conv_kernel_size': 3, 'synapse_conv_stride': 1, 'synapse_conv_padding': 1, 'synapse_trace_const1': 1, 'synapse_trace_const2': 0.5, 'pre_trained': False, 'convTrue_fcFalse': False, 'cfg': [200, 200], 'net_print': True, 'pre_trained_path': '', 'epoch_num': 200, 'tdBN_on': False, 'BN_on': False, 'surrogate': 'hard_sigmoid', 'BPTT_on': False, 'optimizer_what': 'SGD', 'scheduler_name': 'no', 'ddp_on': False, 'dvs_clipping': 1, 'dvs_duration': 2, 'DFA_on': True, 'trace_on': False, 'OTTT_input_trace_on': False, 'exclude_class': True, 'merge_polarities': False, 'denoise_on': False, 'extra_train_dataset': 9, 'num_workers': 2, 'chaching_on': False, 'pin_memory': True, 'UDA_on': False, 'alpha_uda': 1, 'bias': False, 'last_lif': False, 'temporal_filter': 8, 'initial_pooling': 1, 'temporal_filter_accumulation': False, 'quantize_bit_list': [8, 8, 8], 'scale_exp': [[0, 0], [0, 0], [0, 0]], 'timestep_sums_threshold': 0, 'lif_layer_sg_width2': 32, 'lif_layer_v_threshold2': 256, 'init_scaling': [0.5, 0.25, 0.0625], 'learning_rate': 2, 'learning_rate2': 8, 'loser_encourage_mode': False} \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Target word: 2\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Target word: 2\n",
      "\n",
      "\n",
      "\n",
      "train_dataset length = 4030, test_dataset length = 452\n",
      "\n",
      "len(train_loader): 4030 BATCH: 1 train_data_count: 4030\n",
      "len(test_loader): 452 BATCH: 1\n",
      "\n",
      "device ==> cuda\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " layer_count 1\n",
      "weight bias bit 8\n",
      "weight exp, bias exp 0 0\n",
      "bit_for_output 0 exp_for_output None \n",
      "\n",
      "\n",
      "\n",
      "======================================================================================\n",
      "======================================================================================\n",
      "======================================================================================\n",
      "bit 8 percentile 0.999\n",
      "======================================================================================\n",
      "======================================================================================\n",
      "======================================================================================\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "LIF 1 sg_bit 4 self.sg_width 1, self.v_threshold 2048\n",
      "\n",
      "\n",
      "++++++++++++++++++++++++\n",
      "\n",
      " lif layer 1 v_bit: 17, v_exp: 0\n",
      "\n",
      "++++++++++++++++++++++++++++++++++++++++++++++\n",
      "\n",
      "\n",
      "\n",
      " layer_count 2\n",
      "weight bias bit 8\n",
      "weight exp, bias exp 0 0\n",
      "bit_for_output 0 exp_for_output None \n",
      "\n",
      "\n",
      "\n",
      "======================================================================================\n",
      "======================================================================================\n",
      "======================================================================================\n",
      "bit 8 percentile 0.999\n",
      "======================================================================================\n",
      "======================================================================================\n",
      "======================================================================================\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "LIF 2 sg_bit 4 self.sg_width 32, self.v_threshold 256\n",
      "\n",
      "\n",
      "++++++++++++++++++++++++\n",
      "\n",
      " lif layer 2 v_bit: 16, v_exp: 0\n",
      "\n",
      "++++++++++++++++++++++++++++++++++++++++++++++\n",
      "\n",
      "\n",
      "\n",
      " layer_count 3\n",
      "weight bias bit 8\n",
      "weight exp, bias exp 0 0\n",
      "bit_for_output 0 exp_for_output None \n",
      "\n",
      "\n",
      "\n",
      "======================================================================================\n",
      "======================================================================================\n",
      "======================================================================================\n",
      "bit 8 percentile 0.999\n",
      "======================================================================================\n",
      "======================================================================================\n",
      "======================================================================================\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataParallel(\n",
      "  (module): REBORN_MY_SNN_FC(\n",
      "    (layers): REBORN_MY_Sequential(\n",
      "      (0): DimChanger_for_FC()\n",
      "      (1): SYNAPSE_FC(in_features=512, out_features=200, TIME=8, bias=False, sstep=True, time_different_weight=False, layer_count=1, quantize_bit_list=[8, 8, 8], scale_exp=[[0, 0], [0, 0], [0, 0]], ANPI_MODE=False, init_scaling=[0.5, 0.25, 0.0625])\n",
      "      (2): LIF_layer(v_init=0, v_decay=0.5, v_threshold=2048, v_reset=10000, sg_width=1, surrogate=hard_sigmoid, BPTT_on=False, trace_const1=1, trace_const2=0.5, TIME=8, sstep=True, trace_on=False, layer_count=1, scale_exp=[[0, 0], [0, 0], [0, 0]], ANPI_MODE=False)\n",
      "      (3): Feedback_Receiver(connect_features=10, count=0, single_step=True, ANPI_MODE=False)\n",
      "      (4): SYNAPSE_FC(in_features=200, out_features=200, TIME=8, bias=False, sstep=True, time_different_weight=False, layer_count=2, quantize_bit_list=[8, 8, 8], scale_exp=[[0, 0], [0, 0], [0, 0]], ANPI_MODE=False, init_scaling=[0.5, 0.25, 0.0625])\n",
      "      (5): LIF_layer(v_init=0, v_decay=0.5, v_threshold=256, v_reset=10000, sg_width=32, surrogate=hard_sigmoid, BPTT_on=False, trace_const1=1, trace_const2=0.5, TIME=8, sstep=True, trace_on=False, layer_count=2, scale_exp=[[0, 0], [0, 0], [0, 0]], ANPI_MODE=False)\n",
      "      (6): Feedback_Receiver(connect_features=10, count=1, single_step=True, ANPI_MODE=False)\n",
      "      (7): SYNAPSE_FC(in_features=200, out_features=10, TIME=8, bias=False, sstep=True, time_different_weight=False, layer_count=3, quantize_bit_list=[8, 8, 8], scale_exp=[[0, 0], [0, 0], [0, 0]], ANPI_MODE=False, init_scaling=[0.5, 0.25, 0.0625])\n",
      "      (DFA_top): Top_Gradient(single_step=True)\n",
      "    )\n",
      "  )\n",
      ")\n",
      "\n",
      "========================================================\n",
      "Trainable parameters: 144,400\n",
      "========================================================\n",
      "\n",
      "ì‘ì€ê±¸í¬ê²Œ\n",
      "ì‘ì€ê±¸í¬ê²Œ\n",
      "ì‘ì€ê±¸í¬ê²Œ\n",
      "ì‘ì€ê±¸í¬ê²Œ\n",
      "MySGD (\n",
      "Parameter Group 0\n",
      "    lr: 2\n",
      "    momentum: 0.0\n",
      ")\n",
      "total_backward_count 0 real_backward_count 0   0.000%\n",
      "fc layer 1 self.abs_max_out: 64.0\n",
      "lif layer 1 self.abs_max_v: 64.0\n",
      "inFeed spike.shape torch.Size([1, 200]) self.weight_fb.shape torch.Size([10, 200])\n",
      "new_weights[i] tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "new_weights[i] tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "new_weights[i] tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "new_weights[i] tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "new_weights[i] tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "new_weights[i] tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "new_weights[i] tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "new_weights[i] tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "new_weights[i] tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "new_weights[i] tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1.], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "inFeed spike.shape torch.Size([1, 200]) self.weight_fb.shape torch.Size([10, 200])\n",
      "new_weights[i] tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "new_weights[i] tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "new_weights[i] tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "new_weights[i] tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "new_weights[i] tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "new_weights[i] tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "new_weights[i] tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "new_weights[i] tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "new_weights[i] tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "new_weights[i] tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1.], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "fc layer 1 self.abs_max_out: 1112.0\n",
      "lif layer 1 self.abs_max_v: 1125.5\n",
      "fc layer 1 self.abs_max_out: 1783.0\n",
      "lif layer 1 self.abs_max_v: 2109.0\n",
      "layer   1  Sparsity: 89.7949%\n",
      "layer   1  average_sram_cycle_util: 0.0000%\n",
      "layer   2  Sparsity: 100.0000%\n",
      "layer   2  average_sram_cycle_util: 0.0000%\n",
      "layer   3  Sparsity: 100.0000%\n",
      "layer   3  average_sram_cycle_util: 0.0000%\n",
      "lif layer 1 self.abs_max_v: 2321.5\n",
      "fc layer 2 self.abs_max_out: 60.0\n",
      "lif layer 2 self.abs_max_v: 60.0\n",
      "fc layer 1 self.abs_max_out: 2793.0\n",
      "lif layer 1 self.abs_max_v: 3617.0\n",
      "fc layer 2 self.abs_max_out: 109.0\n",
      "lif layer 2 self.abs_max_v: 109.0\n",
      "fc layer 1 self.abs_max_out: 2880.0\n",
      "lif layer 1 self.abs_max_v: 3870.0\n",
      "fc layer 2 self.abs_max_out: 195.0\n",
      "lif layer 2 self.abs_max_v: 218.5\n",
      "fc layer 1 self.abs_max_out: 3234.0\n",
      "lif layer 1 self.abs_max_v: 4091.0\n",
      "fc layer 1 self.abs_max_out: 3803.0\n",
      "lif layer 1 self.abs_max_v: 4577.5\n",
      "fc layer 2 self.abs_max_out: 199.0\n",
      "fc layer 2 self.abs_max_out: 224.0\n",
      "lif layer 2 self.abs_max_v: 224.0\n",
      "fc layer 1 self.abs_max_out: 5210.0\n",
      "lif layer 1 self.abs_max_v: 5711.5\n",
      "fc layer 2 self.abs_max_out: 322.0\n",
      "lif layer 2 self.abs_max_v: 322.0\n",
      "fc layer 3 self.abs_max_out: 7.0\n",
      "fc layer 2 self.abs_max_out: 323.0\n",
      "lif layer 2 self.abs_max_v: 383.5\n",
      "fc layer 3 self.abs_max_out: 17.0\n",
      "fc layer 2 self.abs_max_out: 326.0\n",
      "lif layer 2 self.abs_max_v: 414.5\n",
      "fc layer 3 self.abs_max_out: 19.0\n",
      "fc layer 1 self.abs_max_out: 5227.0\n",
      "fc layer 3 self.abs_max_out: 20.0\n",
      "fc layer 3 self.abs_max_out: 23.0\n",
      "fc layer 2 self.abs_max_out: 377.0\n",
      "lif layer 2 self.abs_max_v: 440.0\n",
      "lif layer 2 self.abs_max_v: 476.5\n",
      "lif layer 1 self.abs_max_v: 5891.5\n",
      "fc layer 2 self.abs_max_out: 449.0\n",
      "lif layer 2 self.abs_max_v: 512.5\n",
      "fc layer 2 self.abs_max_out: 459.0\n",
      "fc layer 1 self.abs_max_out: 5670.0\n",
      "fc layer 1 self.abs_max_out: 6150.0\n",
      "lif layer 1 self.abs_max_v: 6150.0\n",
      "fc layer 2 self.abs_max_out: 511.0\n",
      "fc layer 1 self.abs_max_out: 6813.0\n",
      "lif layer 1 self.abs_max_v: 6813.0\n",
      "fc layer 3 self.abs_max_out: 25.0\n",
      "fc layer 1 self.abs_max_out: 7108.0\n",
      "lif layer 1 self.abs_max_v: 7108.0\n",
      "fc layer 1 self.abs_max_out: 7495.0\n",
      "lif layer 1 self.abs_max_v: 7495.0\n",
      "fc layer 3 self.abs_max_out: 33.0\n",
      "lif layer 2 self.abs_max_v: 534.5\n",
      "lif layer 2 self.abs_max_v: 568.0\n",
      "fc layer 1 self.abs_max_out: 7535.0\n",
      "lif layer 1 self.abs_max_v: 8127.5\n",
      "fc layer 1 self.abs_max_out: 7787.0\n",
      "fc layer 1 self.abs_max_out: 8095.0\n",
      "fc layer 1 self.abs_max_out: 8342.0\n",
      "lif layer 1 self.abs_max_v: 8342.0\n",
      "fc layer 1 self.abs_max_out: 8483.0\n",
      "lif layer 1 self.abs_max_v: 8483.0\n",
      "fc layer 1 self.abs_max_out: 8760.0\n",
      "lif layer 1 self.abs_max_v: 8760.0\n",
      "fc layer 1 self.abs_max_out: 8956.0\n",
      "lif layer 1 self.abs_max_v: 8956.0\n",
      "fc layer 1 self.abs_max_out: 9089.0\n",
      "lif layer 1 self.abs_max_v: 9210.0\n",
      "fc layer 2 self.abs_max_out: 531.0\n",
      "fc layer 1 self.abs_max_out: 9200.0\n",
      "fc layer 1 self.abs_max_out: 10465.0\n",
      "lif layer 1 self.abs_max_v: 10465.0\n",
      "fc layer 1 self.abs_max_out: 10858.0\n",
      "lif layer 1 self.abs_max_v: 10858.0\n",
      "fc layer 1 self.abs_max_out: 11201.0\n",
      "lif layer 1 self.abs_max_v: 11201.0\n",
      "fc layer 2 self.abs_max_out: 553.0\n",
      "lif layer 2 self.abs_max_v: 597.5\n",
      "fc layer 1 self.abs_max_out: 11518.0\n",
      "lif layer 1 self.abs_max_v: 12100.0\n",
      "fc layer 1 self.abs_max_out: 11585.0\n",
      "fc layer 1 self.abs_max_out: 11898.0\n",
      "fc layer 2 self.abs_max_out: 562.0\n",
      "fc layer 3 self.abs_max_out: 42.0\n",
      "fc layer 1 self.abs_max_out: 12024.0\n",
      "fc layer 2 self.abs_max_out: 571.0\n",
      "fc layer 1 self.abs_max_out: 12947.0\n",
      "lif layer 1 self.abs_max_v: 12947.0\n",
      "fc layer 2 self.abs_max_out: 572.0\n",
      "lif layer 2 self.abs_max_v: 651.5\n",
      "fc layer 2 self.abs_max_out: 578.0\n",
      "fc layer 2 self.abs_max_out: 590.0\n",
      "fc layer 2 self.abs_max_out: 600.0\n",
      "fc layer 2 self.abs_max_out: 608.0\n",
      "fc layer 2 self.abs_max_out: 612.0\n",
      "fc layer 2 self.abs_max_out: 620.0\n",
      "lif layer 2 self.abs_max_v: 652.0\n",
      "fc layer 1 self.abs_max_out: 13347.0\n",
      "lif layer 1 self.abs_max_v: 13347.0\n",
      "lif layer 1 self.abs_max_v: 13717.5\n",
      "fc layer 1 self.abs_max_out: 13558.0\n",
      "fc layer 2 self.abs_max_out: 630.0\n",
      "lif layer 2 self.abs_max_v: 689.5\n",
      "fc layer 2 self.abs_max_out: 656.0\n",
      "fc layer 2 self.abs_max_out: 687.0\n",
      "fc layer 3 self.abs_max_out: 44.0\n",
      "fc layer 1 self.abs_max_out: 14327.0\n",
      "lif layer 1 self.abs_max_v: 14327.0\n",
      "lif layer 2 self.abs_max_v: 758.0\n",
      "fc layer 2 self.abs_max_out: 690.0\n",
      "fc layer 2 self.abs_max_out: 704.0\n",
      "fc layer 3 self.abs_max_out: 45.0\n",
      "fc layer 2 self.abs_max_out: 709.0\n",
      "fc layer 2 self.abs_max_out: 715.0\n",
      "fc layer 2 self.abs_max_out: 734.0\n",
      "lif layer 2 self.abs_max_v: 779.0\n",
      "fc layer 1 self.abs_max_out: 15153.0\n",
      "lif layer 1 self.abs_max_v: 15153.0\n",
      "fc layer 2 self.abs_max_out: 742.0\n",
      "fc layer 2 self.abs_max_out: 753.0\n",
      "fc layer 2 self.abs_max_out: 770.0\n",
      "fc layer 2 self.abs_max_out: 779.0\n",
      "fc layer 2 self.abs_max_out: 780.0\n",
      "lif layer 2 self.abs_max_v: 780.0\n",
      "fc layer 2 self.abs_max_out: 784.0\n",
      "lif layer 2 self.abs_max_v: 784.0\n",
      "fc layer 1 self.abs_max_out: 15883.0\n",
      "lif layer 1 self.abs_max_v: 15883.0\n",
      "fc layer 2 self.abs_max_out: 802.0\n",
      "lif layer 2 self.abs_max_v: 802.0\n",
      "fc layer 2 self.abs_max_out: 816.0\n",
      "lif layer 2 self.abs_max_v: 816.0\n",
      "fc layer 3 self.abs_max_out: 46.0\n",
      "fc layer 2 self.abs_max_out: 832.0\n",
      "lif layer 2 self.abs_max_v: 832.0\n",
      "fc layer 2 self.abs_max_out: 837.0\n",
      "lif layer 2 self.abs_max_v: 837.0\n",
      "fc layer 2 self.abs_max_out: 851.0\n",
      "lif layer 2 self.abs_max_v: 851.0\n",
      "lif layer 2 self.abs_max_v: 916.0\n",
      "fc layer 2 self.abs_max_out: 855.0\n",
      "fc layer 1 self.abs_max_out: 16022.0\n",
      "lif layer 1 self.abs_max_v: 16022.0\n",
      "fc layer 2 self.abs_max_out: 864.0\n",
      "fc layer 3 self.abs_max_out: 51.0\n",
      "fc layer 3 self.abs_max_out: 52.0\n",
      "fc layer 2 self.abs_max_out: 878.0\n",
      "fc layer 3 self.abs_max_out: 55.0\n",
      "fc layer 1 self.abs_max_out: 16140.0\n",
      "lif layer 1 self.abs_max_v: 16140.0\n",
      "fc layer 3 self.abs_max_out: 57.0\n",
      "fc layer 1 self.abs_max_out: 17064.0\n",
      "lif layer 1 self.abs_max_v: 17064.0\n",
      "fc layer 1 self.abs_max_out: 17685.0\n",
      "lif layer 1 self.abs_max_v: 17685.0\n",
      "fc layer 2 self.abs_max_out: 889.0\n",
      "fc layer 2 self.abs_max_out: 890.0\n",
      "fc layer 3 self.abs_max_out: 58.0\n",
      "fc layer 2 self.abs_max_out: 907.0\n"
     ]
    }
   ],
   "source": [
    "# sweep í•˜ëŠ” ì½”ë“œ, ìœ„ ì…€ ì£¼ì„ì²˜ë¦¬ í•´ì•¼ ë¨.\n",
    "\n",
    "# ì´ëŸ° ì›Œë‹ ëœ¨ëŠ” ê±°ëŠ” ê± ë„ˆê°€ main ì•ˆì—ì„œ  wandb.config.update(hyperparameters)í•  ë•Œ ë¬¼ë ¤ì„œì„. ì–´ì°¨í”¼ ê·¼ë° sweepì—ì„œ ì§€ì •í•œ ê±¸ë¡œ ë®ì–´ì§ \n",
    "# wandb: WARNING Config item 'BATCH' was locked by 'sweep' (ignored update).\n",
    "target_word=2\n",
    "unique_name_hyper = 'main'\n",
    "sweep_configuration = {\n",
    "    'method': 'random', # 'random', 'bayes', 'grid'\n",
    "    'name': f'my_snn_sweep{datetime.datetime.now().strftime(\"%Y%m%d_%H%M%S\")}_targetword{target_word}_new251129',\n",
    "    'metric': {'goal': 'maximize', 'name': 'val_acc_best'},\n",
    "    'parameters': \n",
    "    {\n",
    "        # \"devices\": {\"values\": [\"1\"]},\n",
    "        \"single_step\": {\"values\": [True]},\n",
    "        # \"unique_name\": {\"values\": [unique_name_hyper]},\n",
    "        \"my_seed\": {\"min\": 1, \"max\": 42000},\n",
    "        # \"my_seed\": {\"values\": [42]},\n",
    "        \"TIME\": {\"values\": [8]},\n",
    "        \"BATCH\": {\"values\": [1]},\n",
    "        \"IMAGE_SIZE\": {\"values\": [8]},\n",
    "        \"which_data\": {\"values\": ['n_tidigits_tonic']},\n",
    "        \"data_path\": {\"values\": ['/data2']},\n",
    "        \"rate_coding\": {\"values\": [False]},\n",
    "        \"lif_layer_v_init\": {\"values\": [0.0]},\n",
    "        \"lif_layer_v_decay\": {\"values\": [0.5]},\n",
    "        \"lif_layer_v_threshold\": {\"values\": [2048.0]},\n",
    "        \"lif_layer_v_threshold2\": {\"values\": [256.0]},\n",
    "        \"lif_layer_v_reset\": {\"values\": [10000.0]},\n",
    "        \"lif_layer_sg_width\": {\"values\": [1.0]},\n",
    "        \"lif_layer_sg_width2\": {\"values\": [32.0]},\n",
    "        # \"lif_layer_sg_width\": {\"values\": [4.0, 6.0, 10.0, 15.0, 20.0]},\n",
    "\n",
    "        \"synapse_conv_kernel_size\": {\"values\": [3]},\n",
    "        \"synapse_conv_stride\": {\"values\": [1]},\n",
    "        \"synapse_conv_padding\": {\"values\": [1]},\n",
    "\n",
    "        \"synapse_trace_const1\": {\"values\": [1]},\n",
    "        \"synapse_trace_const2\": {\"values\": [0.5]},\n",
    "\n",
    "        \"pre_trained\": {\"values\": [False]},\n",
    "        \"convTrue_fcFalse\": {\"values\": [False]},\n",
    "\n",
    "        \"cfg\": {\"values\": [[200,200]]},\n",
    "\n",
    "        \"net_print\": {\"values\": [True]},\n",
    "\n",
    "        \"pre_trained_path\": {\"values\": [\"\"]},\n",
    "        \"learning_rate\": {\"values\": [2.0]},\n",
    "        \"learning_rate2\": {\"values\": [8.0]}, \n",
    "        \"epoch_num\": {\"values\": [200]}, \n",
    "        \"tdBN_on\": {\"values\": [False]},\n",
    "        \"BN_on\": {\"values\": [False]},\n",
    "\n",
    "        \"surrogate\": {\"values\": ['hard_sigmoid']},\n",
    "\n",
    "        \"BPTT_on\": {\"values\": [False]},\n",
    "\n",
    "        \"optimizer_what\": {\"values\": ['SGD']},\n",
    "        \"scheduler_name\": {\"values\": ['no']},\n",
    "\n",
    "        \"ddp_on\": {\"values\": [False]},\n",
    "\n",
    "        \"dvs_clipping\": {\"values\": [1]}, \n",
    "\n",
    "        \"dvs_duration\": {\"values\": [target_word]}, \n",
    "\n",
    "        \"DFA_on\": {\"values\": [True]},\n",
    "\n",
    "        \"trace_on\": {\"values\": [False]},\n",
    "        \"OTTT_input_trace_on\": {\"values\": [False]},\n",
    "\n",
    "        \"exclude_class\": {\"values\": [True]},\n",
    "\n",
    "        \"merge_polarities\": {\"values\": [False]},\n",
    "        \"denoise_on\": {\"values\": [False]},\n",
    "\n",
    "        \"extra_train_dataset\": {\"values\": [9]},\n",
    "\n",
    "        \"num_workers\": {\"values\": [2]},\n",
    "        \"chaching_on\": {\"values\": [False]},\n",
    "        \"pin_memory\": {\"values\": [True]},\n",
    "\n",
    "        \"UDA_on\": {\"values\": [False]},\n",
    "        \"alpha_uda\": {\"values\": [1.0]},\n",
    "\n",
    "        \"bias\": {\"values\": [False]},\n",
    "\n",
    "        \"last_lif\": {\"values\": [False]},\n",
    "\n",
    "        \"temporal_filter\": {\"values\": [8]},\n",
    "        \"initial_pooling\": {\"values\": [1]},\n",
    "\n",
    "        \"temporal_filter_accumulation\": {\"values\": [False]},\n",
    "\n",
    "        \"quantize_bit_list_0\": {\"values\": [8]},\n",
    "        \"quantize_bit_list_1\": {\"values\": [8]},\n",
    "        \"quantize_bit_list_2\": {\"values\": [8]},\n",
    "\n",
    "        \"scale_exp_1w\": {\"values\": [0]},\n",
    "        # # \"scale_exp_1b\": {\"values\": [-11,-10,-9,-8,-7,-6]},\n",
    "\n",
    "        \"scale_exp_2w\": {\"values\": [0]},\n",
    "        # # \"scale_exp_2b\": {\"values\": [-10,-9,-8]},\n",
    "\n",
    "        \"scale_exp_3w\": {\"values\": [0]},\n",
    "        # # \"scale_exp_3b\": {\"values\": [-10,-9,-8,-7,-6]},\n",
    "\n",
    "        \"timestep_sums_threshold\": {\"values\": [0]},\n",
    "\n",
    "        \"loser_encourage_mode\": {\"values\": [False]},\n",
    "        \n",
    "        \"init_scaling_0\": {\"values\": [1/2]},\n",
    "        \"init_scaling_1\": {\"values\": [1/4]},\n",
    "        \"init_scaling_2\": {\"values\": [1/16]},\n",
    "     }\n",
    "}\n",
    "\n",
    "def hyper_iter():\n",
    "    ### my_snn control board ########################\n",
    "    wandb.init(save_code=False, dir='/data2/bh_wandb', tags=[\"sweep\"])\n",
    "\n",
    "    my_snn_system(  \n",
    "        devices  =  \"2\",\n",
    "        single_step  =  wandb.config.single_step,\n",
    "        unique_name  =  datetime.datetime.now().strftime(\"%Y%m%d_%H%M%S_\") + f\"{datetime.datetime.now().microsecond // 1000:03d}\",\n",
    "        my_seed  =  wandb.config.my_seed,\n",
    "        TIME  =  wandb.config.TIME,\n",
    "        BATCH  =  wandb.config.BATCH,\n",
    "        IMAGE_SIZE  =  wandb.config.IMAGE_SIZE,\n",
    "        which_data  =  wandb.config.which_data,\n",
    "        data_path  =  wandb.config.data_path,\n",
    "        rate_coding  =  wandb.config.rate_coding,\n",
    "        lif_layer_v_init  =  wandb.config.lif_layer_v_init,\n",
    "        lif_layer_v_decay  =  wandb.config.lif_layer_v_decay,\n",
    "        lif_layer_v_threshold  =  wandb.config.lif_layer_v_threshold,\n",
    "        lif_layer_v_reset  =  wandb.config.lif_layer_v_reset,\n",
    "        lif_layer_sg_width  =  wandb.config.lif_layer_sg_width,\n",
    "        synapse_conv_kernel_size  =  wandb.config.synapse_conv_kernel_size,\n",
    "        synapse_conv_stride  =  wandb.config.synapse_conv_stride,\n",
    "        synapse_conv_padding  =  wandb.config.synapse_conv_padding,\n",
    "        synapse_trace_const1  =  wandb.config.synapse_trace_const1,\n",
    "        synapse_trace_const2  =  wandb.config.synapse_trace_const2,\n",
    "        pre_trained  =  wandb.config.pre_trained,\n",
    "        convTrue_fcFalse  =  wandb.config.convTrue_fcFalse,\n",
    "        cfg  =  wandb.config.cfg,\n",
    "        net_print  =  wandb.config.net_print,\n",
    "        pre_trained_path  =  wandb.config.pre_trained_path,\n",
    "        learning_rate  =  wandb.config.learning_rate,\n",
    "        epoch_num  =  wandb.config.epoch_num,\n",
    "        tdBN_on  =  wandb.config.tdBN_on,\n",
    "        BN_on  =  wandb.config.BN_on,\n",
    "        surrogate  =  wandb.config.surrogate,\n",
    "        BPTT_on  =  wandb.config.BPTT_on,\n",
    "        optimizer_what  =  wandb.config.optimizer_what,\n",
    "        scheduler_name  =  wandb.config.scheduler_name,\n",
    "        ddp_on  =  wandb.config.ddp_on,\n",
    "        dvs_clipping  =  wandb.config.dvs_clipping,\n",
    "        dvs_duration  =  wandb.config.dvs_duration,\n",
    "        DFA_on  =  wandb.config.DFA_on,\n",
    "        trace_on  =  wandb.config.trace_on,\n",
    "        OTTT_input_trace_on  =  wandb.config.OTTT_input_trace_on,\n",
    "        exclude_class  =  wandb.config.exclude_class,\n",
    "        merge_polarities  =  wandb.config.merge_polarities,\n",
    "        denoise_on  =  wandb.config.denoise_on,\n",
    "        extra_train_dataset  =  wandb.config.extra_train_dataset,\n",
    "        num_workers  =  wandb.config.num_workers,\n",
    "        chaching_on  =  wandb.config.chaching_on,\n",
    "        pin_memory  =  wandb.config.pin_memory,\n",
    "        UDA_on  =  wandb.config.UDA_on,\n",
    "        alpha_uda  =  wandb.config.alpha_uda,\n",
    "        bias  =  wandb.config.bias,\n",
    "        last_lif  =  wandb.config.last_lif,\n",
    "        temporal_filter  =  wandb.config.temporal_filter,\n",
    "        initial_pooling  =  wandb.config.initial_pooling,\n",
    "        temporal_filter_accumulation  =  wandb.config.temporal_filter_accumulation,\n",
    "\n",
    "        quantize_bit_list  =  [wandb.config.quantize_bit_list_0,wandb.config.quantize_bit_list_1,wandb.config.quantize_bit_list_2],\n",
    "        scale_exp = [[wandb.config.scale_exp_1w,wandb.config.scale_exp_1w],[wandb.config.scale_exp_2w,wandb.config.scale_exp_2w],[wandb.config.scale_exp_3w,wandb.config.scale_exp_3w]],\n",
    "        timestep_sums_threshold  =  wandb.config.timestep_sums_threshold,\n",
    "        loser_encourage_mode  =  wandb.config.loser_encourage_mode,\n",
    "        lif_layer_sg_width2  =  wandb.config.lif_layer_sg_width2,\n",
    "        lif_layer_v_threshold2  =  wandb.config.lif_layer_v_threshold2,\n",
    "        learning_rate2  =  wandb.config.learning_rate2,\n",
    "        init_scaling = [wandb.config.init_scaling_0,wandb.config.init_scaling_1,wandb.config.init_scaling_2],\n",
    "                        ) \n",
    "    # sigmoidì™€ BNì´ ìˆì–´ì•¼ ì˜ëœë‹¤.\n",
    "    # average pooling\n",
    "    # ì´ ë‚«ë‹¤. \n",
    "    \n",
    "    # ndaì—ì„œëŠ” decay = 0.25, threshold = 0.5, width =1, surrogate = rectangle, batch = 256, tdBN = True\n",
    "    ## OTTT ì—ì„œëŠ” decay = 0.5, threshold = 1.0, surrogate = sigmoid, batch = 128, BN = True\n",
    "\n",
    "sweep_id = 'mg47irsg'\n",
    "# sweep_id = wandb.sweep(sweep=sweep_configuration, project=f'my_snn NTIDIGITS SWEEP LOSER ONOFF new251129')\n",
    "wandb.agent(sweep_id, function=hyper_iter, count=10000, project=f'my_snn NTIDIGITS SWEEP LOSER ONOFF new251129')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aedat2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
