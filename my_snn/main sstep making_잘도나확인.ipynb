{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copyright (c) 2024 Byeonghyeon Kim \n",
    "# github site: https://github.com/bhkim003/ByeonghyeonKim\n",
    "# email: bhkim003@snu.ac.kr\n",
    " \n",
    "# Permission is hereby granted, free of charge, to any person obtaining a copy of\n",
    "# this software and associated documentation files (the \"Software\"), to deal in\n",
    "# the Software without restriction, including without limitation the rights to\n",
    "# use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of\n",
    "# the Software, and to permit persons to whom the Software is furnished to do so,\n",
    "# subject to the following conditions:\n",
    " \n",
    "# The above copyright notice and this permission notice shall be included in all\n",
    "# copies or substantial portions of the Software.\n",
    " \n",
    "# THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\n",
    "# IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS\n",
    "# FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR\n",
    "# COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER\n",
    "# IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN\n",
    "# CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_8321/2809884579.py:45: DeprecationWarning: The module snntorch.spikevision is deprecated. For loading neuromorphic datasets, we recommend using the Tonic project: https://github.com/neuromorphs/tonic\n",
      "  from snntorch.spikevision import spikedata\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.optim as optim\n",
    "import torch.optim.lr_scheduler as lr_scheduler\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "import torchvision\n",
    "import torchvision.datasets\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import time\n",
    "\n",
    "from snntorch import spikegen\n",
    "import matplotlib.pyplot as plt\n",
    "import snntorch.spikeplot as splt\n",
    "from IPython.display import HTML\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "from apex.parallel import DistributedDataParallel as DDP\n",
    "\n",
    "import random\n",
    "import datetime\n",
    "\n",
    "import json\n",
    "\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "''' 레퍼런스\n",
    "https://spikingjelly.readthedocs.io/zh-cn/0.0.0.0.4/spikingjelly.datasets.html#module-spikingjelly.datasets\n",
    "https://github.com/GorkaAbad/Sneaky-Spikes/blob/main/datasets.py\n",
    "https://github.com/GorkaAbad/Sneaky-Spikes/blob/main/how_to.md\n",
    "https://github.com/nmi-lab/torchneuromorphic\n",
    "https://snntorch.readthedocs.io/en/latest/snntorch.spikevision.spikedata.html#shd\n",
    "'''\n",
    "\n",
    "import snntorch\n",
    "from snntorch.spikevision import spikedata\n",
    "\n",
    "from spikingjelly.datasets.dvs128_gesture import DVS128Gesture\n",
    "from spikingjelly.datasets.cifar10_dvs import CIFAR10DVS\n",
    "from spikingjelly.datasets.n_mnist import NMNIST\n",
    "# from spikingjelly.datasets.es_imagenet import ESImageNet\n",
    "from spikingjelly.datasets import split_to_train_test_set\n",
    "from spikingjelly.datasets.n_caltech101 import NCaltech101\n",
    "from spikingjelly.datasets import pad_sequence_collate, padded_sequence_mask\n",
    "\n",
    "import torchneuromorphic\n",
    "\n",
    "import wandb\n",
    "\n",
    "from torchviz import make_dot\n",
    "import graphviz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x600 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# my module import\n",
    "from modules import *\n",
    "\n",
    "# modules 폴더에 새모듈.py 만들면\n",
    "# modules/__init__py 파일에 form .새모듈 import * 하셈\n",
    "# 그리고 새모듈.py에서 from modules.새모듈 import * 하셈\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    " # dvs 데이터 시각화 코드\n",
    " ##############################################################################################\n",
    "            # mapping = {\n",
    "            #     0: 'Hand Clapping',\n",
    "            #     1: 'Right Hand Wave',\n",
    "            #     2: 'Left Hand Wave',\n",
    "            #     3: 'Right Arm CW',\n",
    "            #     4: 'Right Arm CCW',\n",
    "            #     5: 'Left Arm CW',\n",
    "            #     6: 'Left Arm CCW',\n",
    "            #     7: 'Arm Roll',\n",
    "            #     8: 'Air Drums',\n",
    "            #     9: 'Air Guitar',\n",
    "            #     10: 'Other'\n",
    "            # }\n",
    "def dvs_visualization(inputs, labels, TIME, BATCH):\n",
    "            \n",
    "    what_input = random.randint(0, BATCH - 1)\n",
    "    inputs_for_view = inputs.permute(1, 0, 2, 3, 4)\n",
    "    for i in range(TIME):\n",
    "        # 예시 데이터 생성\n",
    "        data1 = inputs_for_view[what_input][i][0].numpy()  # torch tensor를 numpy 배열로 변환\n",
    "        data2 = inputs_for_view[what_input][i][1].numpy()  # torch tensor를 numpy 배열로 변환\n",
    "\n",
    "        # 데이터 플로팅\n",
    "        fig, axs = plt.subplots(1, 2, figsize=(12, 6))  # 1행 2열의 subplot 생성\n",
    "\n",
    "        # 첫 번째 subplot에 데이터1 플로팅\n",
    "        im1 = axs[0].imshow(data1, cmap='viridis', interpolation='nearest')\n",
    "        axs[0].set_title(f'Channel 0\\nLabel: {labels[what_input]}  Time: {i}')  # 라벨값 맵핑하여 제목에 추가\n",
    "        axs[0].set_xlabel('X axis')\n",
    "        axs[0].set_ylabel('Y axis')\n",
    "        axs[0].grid(False)\n",
    "        fig.colorbar(im1, ax=axs[0])  # Color bar 추가\n",
    "\n",
    "        # 두 번째 subplot에 데이터2 플로팅\n",
    "        im2 = axs[1].imshow(data2, cmap='viridis', interpolation='nearest')\n",
    "        axs[1].set_title(f'Channel 1\\nLabel: {labels[what_input]}  Time: {i}')  # 라벨값 맵핑하여 제목에 추가\n",
    "        axs[1].set_xlabel('X axis')\n",
    "        axs[1].set_ylabel('Y axis')\n",
    "        axs[1].grid(False)\n",
    "        fig.colorbar(im2, ax=axs[1])  # Color bar 추가\n",
    "\n",
    "        plt.tight_layout()  # subplot 간 간격 조정\n",
    "        plt.show()\n",
    "    sys.exit(\"종료\")\n",
    "\n",
    "######################################################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_snn_system(devices = \"0,1,2,3\",\n",
    "                    single_step = False, # True # False\n",
    "                    unique_name = 'main',\n",
    "                    my_seed = 42,\n",
    "                    TIME = 10,\n",
    "                    BATCH = 256,\n",
    "                    IMAGE_SIZE = 32,\n",
    "                    which_data = 'CIFAR10',\n",
    "                    # CLASS_NUM = 10,\n",
    "                    data_path = '/data2',\n",
    "                    rate_coding = True,\n",
    "    \n",
    "                    lif_layer_v_init = 0.0,\n",
    "                    lif_layer_v_decay = 0.6,\n",
    "                    lif_layer_v_threshold = 1.2,\n",
    "                    lif_layer_v_reset = 0.0,\n",
    "                    lif_layer_sg_width = 1,\n",
    "\n",
    "                    # synapse_conv_in_channels = IMAGE_PIXEL_CHANNEL,\n",
    "                    synapse_conv_kernel_size = 3,\n",
    "                    synapse_conv_stride = 1,\n",
    "                    synapse_conv_padding = 1,\n",
    "                    synapse_conv_trace_const1 = 1,\n",
    "                    synapse_conv_trace_const2 = 0.6,\n",
    "\n",
    "                    # synapse_fc_out_features = CLASS_NUM,\n",
    "                    synapse_fc_trace_const1 = 1,\n",
    "                    synapse_fc_trace_const2 = 0.6,\n",
    "\n",
    "                    pre_trained = False,\n",
    "                    convTrue_fcFalse = True,\n",
    "                    cfg = [64, 64],\n",
    "                    net_print = False, # True # False\n",
    "                    weight_count_print = False, # True # False\n",
    "                    pre_trained_path = \"net_save/save_now_net.pth\",\n",
    "                    learning_rate = 0.0001,\n",
    "                    epoch_num = 200,\n",
    "                    verbose_interval = 100, #숫자 크게 하면 꺼짐\n",
    "                    validation_interval = 10, #숫자 크게 하면 꺼짐\n",
    "                    tdBN_on = False,\n",
    "                    BN_on = False,\n",
    "\n",
    "                    surrogate = 'sigmoid',\n",
    "\n",
    "                    gradient_verbose = False,\n",
    "\n",
    "                    BPTT_on = False,\n",
    "\n",
    "                    optimizer_what = 'SGD', # 'SGD' 'Adam', 'RMSprop'\n",
    "                    scheduler_name = 'no',\n",
    "                    \n",
    "                    ddp_on = True,\n",
    "\n",
    "                    nda_net = False,\n",
    "                    \n",
    "                    domain_il_epoch = 0, # over 0, then domain il mode on\n",
    "\n",
    "                    dvs_clipping = True, \n",
    "                    dvs_duration = 1000000,\n",
    "\n",
    "                    OTTT_sWS_on = True, # True # False\n",
    "                  ):\n",
    "    if OTTT_sWS_on == True:\n",
    "        assert BPTT_on == False and tdBN_on == False and convTrue_fcFalse == True\n",
    "    if single_step == True:\n",
    "        assert BPTT_on == False and tdBN_on == False\n",
    "\n",
    "    ## 함수 내 모든 로컬 변수 저장 ########################################################\n",
    "    hyperparameters = locals()\n",
    "    hyperparameters['current epoch'] = 0\n",
    "    ######################################################################################\n",
    "    \n",
    "    \n",
    "    ## wandb 세팅 ###################################################################\n",
    "    current_time = datetime.datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "    wandb.config.update(hyperparameters)\n",
    "    wandb.run.name = f'lr_{learning_rate}_{unique_name}_{which_data}_tstep{TIME}'\n",
    "    wandb.define_metric(\"summary_val_acc\", summary=\"max\")\n",
    "    ###################################################################################\n",
    "\n",
    "\n",
    "\n",
    "    ## gpu setting ##################################################################################################################\n",
    "    os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\" \n",
    "    os.environ[\"CUDA_VISIBLE_DEVICES\"]= devices\n",
    "    ###################################################################################################################################\n",
    "\n",
    "\n",
    "    ## seed setting ##################################################################################################################\n",
    "    torch.manual_seed(my_seed)\n",
    "    ###################################################################################################################################\n",
    "\n",
    "\n",
    "    ## data_loader 가져오기 ##################################################################################################################\n",
    "    # data loader, pixel channel, class num\n",
    "    train_loader, test_loader, synapse_conv_in_channels, CLASS_NUM = data_loader(\n",
    "            which_data,\n",
    "            data_path, \n",
    "            rate_coding, \n",
    "            BATCH, \n",
    "            IMAGE_SIZE,\n",
    "            ddp_on,\n",
    "            TIME,\n",
    "            dvs_clipping,\n",
    "            dvs_duration)\n",
    "    synapse_fc_out_features = CLASS_NUM\n",
    "    ###########################################################################################################################################\n",
    "\n",
    "    \n",
    "    ## parameter number calculator (안 중요함) ##################################################################################################################\n",
    "    params_num = 0\n",
    "    img_size = IMAGE_SIZE \n",
    "    bias_param = 1 # 1 or 0\n",
    "    classifier_making = False\n",
    "    if (convTrue_fcFalse == True):\n",
    "        past_kernel = synapse_conv_in_channels\n",
    "        for kernel in cfg:\n",
    "            if (classifier_making == False):\n",
    "                if (type(kernel) == list):\n",
    "                    for residual_kernel in kernel:\n",
    "                        if (residual_kernel >= 10000 and residual_kernel < 20000): # separable\n",
    "                            residual_kernel -= 10000\n",
    "                            params_num += (synapse_conv_kernel_size**2 + bias_param) * past_kernel\n",
    "                            params_num += (1**2 * past_kernel + bias_param) * residual_kernel\n",
    "                            past_kernel = residual_kernel  \n",
    "                        elif (residual_kernel >= 20000 and residual_kernel < 30000): # depthwise\n",
    "                            residual_kernel -= 20000\n",
    "                            # 'past_kernel' should be same with 'kernel'\n",
    "                            params_num += (synapse_conv_kernel_size**2 + bias_param) * past_kernel\n",
    "                            past_kernel = residual_kernel  \n",
    "                        else:\n",
    "                            params_num += residual_kernel * ((synapse_conv_kernel_size**2) * past_kernel + bias_param)\n",
    "                            past_kernel = residual_kernel\n",
    "                elif (kernel == 'P' or kernel == 'M'):\n",
    "                    img_size = img_size // 2\n",
    "                elif (kernel == 'D'):\n",
    "                    img_size = 1\n",
    "                elif (kernel == 'L'):\n",
    "                    classifier_making = True\n",
    "                    past_kernel = past_kernel * (img_size**2)\n",
    "                else:\n",
    "                    if (kernel >= 10000 and kernel < 20000): # separable\n",
    "                        kernel -= 10000\n",
    "                        params_num += (synapse_conv_kernel_size**2 + bias_param) * past_kernel\n",
    "                        params_num += (1**2 * past_kernel + bias_param) * kernel\n",
    "                        past_kernel = kernel  \n",
    "                    elif (kernel >= 20000 and kernel < 30000): # depthwise\n",
    "                        kernel -= 20000\n",
    "                        # 'past_kernel' should be same with 'kernel'\n",
    "                        params_num += (synapse_conv_kernel_size**2 + bias_param) * past_kernel\n",
    "                        past_kernel = kernel  \n",
    "                    else:\n",
    "                        params_num += kernel * (synapse_conv_kernel_size**2 * past_kernel + bias_param)\n",
    "                        past_kernel = kernel    \n",
    "            else: # classifier making\n",
    "                params_num += (past_kernel + bias_param) * kernel\n",
    "                past_kernel = kernel\n",
    "        \n",
    "        \n",
    "        if classifier_making == False:\n",
    "            past_kernel = past_kernel*img_size*img_size\n",
    "\n",
    "        params_num += (past_kernel + bias_param) * synapse_fc_out_features\n",
    "    else:\n",
    "        past_in_channel = synapse_conv_in_channels*img_size*img_size\n",
    "        for in_channel in cfg:\n",
    "            if (type(in_channel) == list):\n",
    "                for residual_in_channel in in_channel:\n",
    "                    params_num += (past_in_channel + bias_param) * residual_in_channel\n",
    "                    past_in_channel = residual_in_channel\n",
    "            # elif (in_channel == 'M'): #it's a holy FC layer!\n",
    "            #     img_size = img_size // 2\n",
    "            else:\n",
    "                print('past_in_channel', past_in_channel)\n",
    "                print('bias_param', bias_param)\n",
    "                print('in_channel', in_channel)\n",
    "                params_num += (past_in_channel + bias_param) * in_channel\n",
    "                past_in_channel = in_channel\n",
    "        params_num += (past_in_channel + bias_param) * synapse_fc_out_features\n",
    "    ###########################################################################################################################################\n",
    "\n",
    "\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "    ### network setting #######################################################################################################################\n",
    "    if pre_trained == False:\n",
    "        if (convTrue_fcFalse == False):\n",
    "            if (single_step == False):\n",
    "                net = MY_SNN_FC(cfg, synapse_conv_in_channels, IMAGE_SIZE, synapse_fc_out_features,\n",
    "                            synapse_fc_trace_const1, synapse_fc_trace_const2, \n",
    "                            lif_layer_v_init, lif_layer_v_decay, \n",
    "                            lif_layer_v_threshold, lif_layer_v_reset,\n",
    "                            lif_layer_sg_width,\n",
    "                            tdBN_on,\n",
    "                            BN_on, TIME,\n",
    "                            surrogate,\n",
    "                            BPTT_on).to(device)\n",
    "        else:\n",
    "            if (single_step == False):\n",
    "                net = MY_SNN_CONV(cfg, synapse_conv_in_channels, IMAGE_SIZE,\n",
    "                            synapse_conv_kernel_size, synapse_conv_stride, \n",
    "                            synapse_conv_padding, synapse_conv_trace_const1, \n",
    "                            synapse_conv_trace_const2, \n",
    "                            lif_layer_v_init, lif_layer_v_decay, \n",
    "                            lif_layer_v_threshold, lif_layer_v_reset,\n",
    "                            lif_layer_sg_width,\n",
    "                            synapse_fc_out_features, synapse_fc_trace_const1, synapse_fc_trace_const2,\n",
    "                            tdBN_on,\n",
    "                            BN_on, TIME,\n",
    "                            surrogate,\n",
    "                            BPTT_on,\n",
    "                            OTTT_sWS_on).to(device)\n",
    "            else:\n",
    "                net = MY_SNN_CONV_ottt_sstep(cfg, synapse_conv_in_channels, IMAGE_SIZE,\n",
    "                            synapse_conv_kernel_size, synapse_conv_stride, \n",
    "                            synapse_conv_padding, synapse_conv_trace_const1, \n",
    "                            synapse_conv_trace_const2, \n",
    "                            lif_layer_v_init, lif_layer_v_decay, \n",
    "                            lif_layer_v_threshold, lif_layer_v_reset,\n",
    "                            lif_layer_sg_width,\n",
    "                            synapse_fc_out_features, synapse_fc_trace_const1, synapse_fc_trace_const2,\n",
    "                            tdBN_on,\n",
    "                            BN_on, TIME,\n",
    "                            surrogate,\n",
    "                            BPTT_on,\n",
    "                            OTTT_sWS_on).to(device)\n",
    "        if (nda_net == True):\n",
    "            net = VGG(cfg = cfg, num_classes=10, batch_norm = tdBN_on, in_c = synapse_conv_in_channels, \n",
    "                      lif_layer_v_threshold=lif_layer_v_threshold, lif_layer_v_decay=lif_layer_v_decay, lif_layer_sg_width=lif_layer_sg_width)\n",
    "            net.T = TIME\n",
    "        net = torch.nn.DataParallel(net) #나중에풀어줘\n",
    "    else:\n",
    "        net = torch.load(pre_trained_path)\n",
    "\n",
    "    net = net.to(device)\n",
    "    if (net_print == True):\n",
    "        print(net)        \n",
    "    ####################################################################################################################################\n",
    "    \n",
    "\n",
    "    ## wandb logging ###########################################\n",
    "    wandb.watch(net, log=\"all\", log_freq = 10) #gradient, parameter logging해줌\n",
    "    ############################################################\n",
    "\n",
    "    ## param num and memory estimation except BN with MY own calculation some lines above ##########################################\n",
    "    real_param_num = sum(p.numel() for p in net.parameters() if p.requires_grad)\n",
    "    if (weight_count_print == True):\n",
    "        for name, param in net.named_parameters():\n",
    "            if param.requires_grad:\n",
    "                print(f'Layer: {name} | Number of parameters: {param.numel()}')\n",
    "    # Batch norm 있으면 아래 두 개 서로 다를 수 있음.\n",
    "    # assert real_param_num == params_num, f'parameter number is not same. real_param_num: {real_param_num}, params_num: {params_num}'    \n",
    "    print('='*50)\n",
    "    print(f\"My Num of PARAMS: {params_num:,}, system's param_num : {real_param_num:,}\")\n",
    "    memory = params_num / 8 / 1024 / 1024 # MB\n",
    "    precision = 32\n",
    "    memory = memory * precision \n",
    "    print(f\"Memory: {memory:.2f}MiB at {precision}-bit\")\n",
    "    print('='*50)\n",
    "    ##############################################################################################################################\n",
    "\n",
    "\n",
    "\n",
    "    ## criterion ########################################## # loss 구해주는 친구\n",
    "    criterion = nn.CrossEntropyLoss().to(device)\n",
    "    if (OTTT_sWS_on == True):\n",
    "        # criterion = nn.CrossEntropyLoss().to(device)\n",
    "        criterion = lambda y_t, target_t: ((1 - 0.05) * F.cross_entropy(y_t, target_t) + 0.05 * F.mse_loss(y_t, F.one_hot(target_t, CLASS_NUM).float())) / TIME \n",
    "    ####################################################\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "    ## optimizer, scheduler ########################################################################\n",
    "    if(optimizer_what == 'SGD'):\n",
    "        # optimizer = optim.SGD(net.parameters(), lr=learning_rate, momentum=0.9)\n",
    "        optimizer = optim.SGD(net.parameters(), lr=learning_rate, momentum=0.9, weight_decay=0)\n",
    "    elif(optimizer_what == 'Adam'):\n",
    "        # optimizer = torch.optim.Adam(net.parameters(), lr=0.00001)\n",
    "        optimizer = torch.optim.Adam(net.parameters(), lr=learning_rate/256 * BATCH, weight_decay=1e-4)\n",
    "        # optimizer = optim.Adam(net.parameters(), lr=learning_rate, weight_decay=0, betas=(0.9, 0.999))\n",
    "    elif(optimizer_what == 'RMSprop'):\n",
    "        pass\n",
    "\n",
    "\n",
    "    if (scheduler_name == 'StepLR'):\n",
    "        scheduler = lr_scheduler.StepLR(optimizer, step_size=10, gamma=0.1)\n",
    "    elif (scheduler_name == 'ExponentialLR'):\n",
    "        scheduler = lr_scheduler.ExponentialLR(optimizer, gamma=0.95)\n",
    "    elif (scheduler_name == 'ReduceLROnPlateau'):\n",
    "        scheduler = lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.1, patience=10)\n",
    "    elif (scheduler_name == 'CosineAnnealingLR'):\n",
    "        # scheduler = lr_scheduler.CosineAnnealingLR(optimizer, eta_min=0, T_max=50)\n",
    "        scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, eta_min=0, T_max=epoch_num)\n",
    "    elif (scheduler_name == 'OneCycleLR'):\n",
    "        scheduler = lr_scheduler.OneCycleLR(optimizer, max_lr=0.1, steps_per_epoch=len(train_loader), epochs=100)\n",
    "    else:\n",
    "        pass # 'no' scheduler\n",
    "    ## optimizer, scheduler ########################################################################\n",
    "\n",
    "\n",
    "    tr_acc = 0\n",
    "    tr_correct = 0\n",
    "    tr_total = 0\n",
    "    val_acc = 0\n",
    "    val_acc_now = 0\n",
    "    elapsed_time_val = 0\n",
    "    iter_acc_array = np.array([])\n",
    "    tr_acc_array = np.array([])\n",
    "    val_acc_now_array = np.array([])\n",
    "    #======== EPOCH START ==========================================================================================\n",
    "    for epoch in range(epoch_num):\n",
    "        print('EPOCH', epoch)\n",
    "        epoch_start_time = time.time()\n",
    "\n",
    "        # if (domain_il_epoch>0 and which_data == 'PMNIST'):\n",
    "        #     k = epoch // domain_il_epoch\n",
    "        #     xtrain=data[k]['train']['x']\n",
    "        #     ytrain=data[k]['train']['y']\n",
    "        #     xtest =data[k]['test']['x']\n",
    "        #     ytest =data[k]['test']['y']\n",
    "\n",
    "        \n",
    "        ####### iterator : input_loading & tqdm을 통한 progress_bar 생성###################\n",
    "        iterator = enumerate(train_loader, 0)\n",
    "        if (ddp_on == True):\n",
    "            if torch.distributed.get_rank() == 0:   \n",
    "                iterator = tqdm(iterator, total=len(train_loader), desc='train', dynamic_ncols=True, position=0, leave=True)\n",
    "        else:\n",
    "            iterator = tqdm(iterator, total=len(train_loader), desc='train', dynamic_ncols=True, position=0, leave=True)\n",
    "        ##################################################################################   \n",
    "        \n",
    "        #### validation_interval이 batch size보다 작을 시 validation_interval을 batch size로 맞춰줌#############\n",
    "        validation_interval2 = validation_interval\n",
    "        if (validation_interval > len(iterator)):\n",
    "            validation_interval2 = len(iterator)\n",
    "        ##################################################################################################\n",
    "\n",
    "\n",
    "\n",
    "        ###### ITERATION START ##########################################################################################################\n",
    "        for i, data in iterator:\n",
    "            iter_one_train_time_start = time.time()\n",
    "            net.train() # train 모드로 바꿔줘야함\n",
    "\n",
    "            ### data loading & semi-pre-processing ################################################################################\n",
    "            if len(data) == 2:\n",
    "                inputs, labels = data\n",
    "                # 처리 로직 작성\n",
    "            elif len(data) == 3:\n",
    "                inputs, labels, x_len = data\n",
    "                # print('x_len',x_len)\n",
    "                # mask = padded_sequence_mask(x_len)\n",
    "                # max_time_step = x_len.max()\n",
    "                # min_time_step = x_len.min()\n",
    "            # print('inputs',inputs.size(),'\\nlabels',labels.size())\n",
    "                    \n",
    "            if (which_data == 'n_tidigits'):\n",
    "                inputs = inputs.permute(0, 1, 3, 2, 4)\n",
    "                labels = labels[:, 0, :]\n",
    "                labels = torch.argmax(labels, dim=1)\n",
    "            elif (which_data == 'heidelberg'):\n",
    "                inputs = inputs.view(5, 1000, 1, 700, 1)\n",
    "                print(\"\\n\\n\\n경고!!!! heidelberg 이거 타임스텝이랑 채널 잘 바꿔줘라!!!\\n\\n\\n\\n\")\n",
    "            # print('inputs',inputs.size(),'\\nlabels',labels.size())\n",
    "            # print(labels)\n",
    "                \n",
    "            if (which_data == 'DVS_CIFAR10' or which_data == 'DVS_GESTURE' or which_data == 'DVS_CIFAR10_2' or which_data == 'NMNIST' or which_data == 'N_CALTECH101' or which_data == 'n_tidigits' or which_data == 'heidelberg'):\n",
    "                inputs = inputs.permute(1, 0, 2, 3, 4)\n",
    "            elif rate_coding == True :\n",
    "                inputs = spikegen.rate(inputs, num_steps=TIME)\n",
    "            else :\n",
    "                inputs = inputs.repeat(TIME, 1, 1, 1, 1)\n",
    "            # inputs: [Time, Batch, Channel, Height, Width]  \n",
    "            ####################################################################################################################### \n",
    "                \n",
    "\n",
    "                \n",
    "            # # dvs 데이터 시각화 코드 (확인 필요할 시 써라)\n",
    "            # ##############################################################################################\n",
    "            # dvs_visualization(inputs, labels, TIME, BATCH)\n",
    "            # ######################################################################################################\n",
    "\n",
    "\n",
    "            ## device로 보내주기 ######################################\n",
    "            real_batch = labels.size(0)\n",
    "            ###########################################################\n",
    "\n",
    "\n",
    "            ## gradient 초기화 #######################################\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            ###########################################################\n",
    "\n",
    "\n",
    "            if single_step == False:\n",
    "                # net에 넣어줄때는 batch가 젤 앞 차원으로 와야함. # dataparallel때매##############################\n",
    "                # inputs: [Time, Batch, Channel, Height, Width]   \n",
    "                inputs = inputs.permute(1, 0, 2, 3, 4) # net에 넣어줄때는 batch가 젤 앞 차원으로 와야함. # dataparallel때매\n",
    "                # inputs: [Batch, Time, Channel, Height, Width] \n",
    "                #################################################################################################\n",
    "            else:\n",
    "                labels = labels.repeat(TIME, 1)\n",
    "\n",
    "            \n",
    "\n",
    "            if single_step == False:\n",
    "                ### input --> net --> output #####################################################\n",
    "                outputs = net(inputs)\n",
    "                ##################################################################################\n",
    "                ## loss, backward ##########################################\n",
    "                loss = criterion(outputs, labels)\n",
    "                loss.backward()\n",
    "                ############################################################\n",
    "                ## weight 업데이트!! ##################################\n",
    "                optimizer.step()\n",
    "                ################################################################\n",
    "            else:\n",
    "                outputs_all = []\n",
    "                loss = 0.0\n",
    "                for t in range(TIME):\n",
    "                    outputs_one_time = net(inputs[t])\n",
    "                    one_time_loss = criterion(outputs_one_time, labels[t].contiguous())\n",
    "                    one_time_loss.backward() # one_time backward\n",
    "                    loss += one_time_loss.data\n",
    "                    outputs_all.append(outputs_one_time.detach())\n",
    "                optimizer.step() # full step time update\n",
    "                outputs_all = torch.stack(outputs_all, dim=1)\n",
    "                outputs = outputs_all.mean(1) # ottt꺼 쓸때\n",
    "                labels = labels[0]\n",
    "                \n",
    "\n",
    "            ## net 그림 출력해보기 #################################################################\n",
    "            # print('시각화')\n",
    "            # make_dot(outputs, params=dict(list(net.named_parameters()))).render(\"net_torchviz\", format=\"png\")\n",
    "            # return 0\n",
    "            ##################################################################################\n",
    "\n",
    "            #### batch 어긋남 방지 ###############################################\n",
    "            assert real_batch == outputs.size(0), f'batch size is not same. real_batch: {real_batch}, outputs.size(0): {outputs.size(0)}'\n",
    "            #######################################################################\n",
    "            \n",
    "\n",
    "            ####### training accruacy save for print ###############################\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total = real_batch\n",
    "            correct = (predicted == labels).sum().item()\n",
    "            iter_acc = correct / total\n",
    "            tr_total += total\n",
    "            tr_correct += correct\n",
    "            if i % verbose_interval == verbose_interval-1:\n",
    "                print(f'{epoch}-{i} training acc: {100 * iter_acc:.2f}%, lr={[f\"{lr}\" for lr in (param_group[\"lr\"] for param_group in optimizer.param_groups)]}, val_acc: {100 * val_acc_now:.2f}%')\n",
    "            iter_acc_string = f'{epoch}-{i}/{len(train_loader)} iter_acc: {100 * iter_acc:.2f}%, lr={[f\"{lr}\" for lr in (param_group[\"lr\"] for param_group in optimizer.param_groups)]}'\n",
    "            ################################################################\n",
    "            \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "            iter_one_train_time_end = time.time()\n",
    "            elapsed_time = iter_one_train_time_end - iter_one_train_time_start  # 실행 시간 계산\n",
    "\n",
    "            if (i % verbose_interval == verbose_interval-1):\n",
    "                print(f\"iter_one_train_time: {elapsed_time} seconds, last one_val_time: {elapsed_time_val} seconds\\n\")\n",
    "\n",
    "            ##### validation ##################################################################################################################################\n",
    "            if i % validation_interval2 == validation_interval2-1:\n",
    "                iter_one_val_time_start = time.time()\n",
    "                tr_acc = tr_correct/tr_total\n",
    "                tr_correct = 0\n",
    "                tr_total = 0\n",
    "                correct = 0\n",
    "                total = 0\n",
    "                with torch.no_grad():\n",
    "                    net.eval() # eval 모드로 바꿔줘야함 \n",
    "                    for data in test_loader:\n",
    "                        ## data loading & semi-pre-processing ##########################################################\n",
    "                        if len(data) == 2:\n",
    "                            inputs, labels = data\n",
    "                            # 처리 로직 작성\n",
    "                        elif len(data) == 3:\n",
    "                            inputs, labels, x_len = data\n",
    "                            # print('x_len',x_len)\n",
    "                            # mask = padded_sequence_mask(x_len)\n",
    "                            # max_time_step = x_len.max()\n",
    "                            # min_time_step = x_len.min()\n",
    "                            # B, T, *spatial_dims = inputs.shape\n",
    "\n",
    "                        if (which_data == 'DVS_CIFAR10' or which_data == 'DVS_GESTURE' or which_data == 'DVS_CIFAR10_2' or which_data == 'NMNIST' or which_data == 'N_CALTECH101' or which_data == 'n_tidigits' or which_data == 'heidelberg'):\n",
    "                            inputs = inputs.permute(1, 0, 2, 3, 4)\n",
    "                        elif rate_coding == True :\n",
    "                            inputs = spikegen.rate(inputs, num_steps=TIME)\n",
    "                        else :\n",
    "                            inputs = inputs.repeat(TIME, 1, 1, 1, 1)\n",
    "                        # inputs: [Time, Batch, Channel, Height, Width]  \n",
    "                        ###################################################################################################\n",
    "\n",
    "                        inputs = inputs.to(device)\n",
    "                        labels = labels.to(device)\n",
    "                        real_batch = labels.size(0)\n",
    "\n",
    "                        if single_step == False:\n",
    "                            outputs = net(inputs.permute(1, 0, 2, 3, 4)) #inputs: [Batch, Time, Channel, Height, Width]  \n",
    "                            val_loss = criterion(outputs, labels)\n",
    "                        else:\n",
    "                            val_loss=0\n",
    "                            outputs_all = []\n",
    "                            for t in range(TIME):\n",
    "                                outputs = net(inputs[t])\n",
    "                                loss = criterion(outputs, labels)\n",
    "                                outputs_all.append(outputs.detach())\n",
    "                                val_loss += loss.data\n",
    "                            outputs_all = torch.stack(outputs_all, dim=1)\n",
    "                            outputs = outputs_all.mean(1)\n",
    "\n",
    "\n",
    "                        _, predicted = torch.max(outputs.data, 1)\n",
    "                        total += real_batch\n",
    "                        assert real_batch == outputs.size(0), f'batch size is not same. real_batch: {real_batch}, outputs.size(0): {outputs.size(0)}'\n",
    "                        correct += (predicted == labels).sum().item()\n",
    "\n",
    "                    val_acc_now = correct / total\n",
    "                    # print(f'{epoch}-{i} validation acc: {100 * val_acc_now:.2f}%, lr={[f\"{lr:.10f}\" for lr in (param_group[\"lr\"] for param_group in optimizer.param_groups)]}')\n",
    "\n",
    "                iter_one_val_time_end = time.time()\n",
    "                elapsed_time_val = iter_one_val_time_end - iter_one_val_time_start  # 실행 시간 계산\n",
    "                # print(f\"iter_one_val_time: {elapsed_time_val} seconds\")\n",
    "\n",
    "                # network save\n",
    "                if val_acc < val_acc_now:\n",
    "                    val_acc = val_acc_now\n",
    "                    # torch.save(net.state_dict(), f\"net_save/save_now_net_weights_{unique_name}.pth\")\n",
    "                    # torch.save(net, f\"net_save/save_now_net_{unique_name}.pth\")\n",
    "                    # torch.save(net.module.state_dict(), f\"net_save/save_now_net_weights2_{unique_name}.pth\")\n",
    "                    # torch.save(net.module, f\"net_save/save_now_net2_{unique_name}.pth\")\n",
    "            ####################################################################################################################################################\n",
    "            iterator.set_description(f\"iter_acc: {iter_acc_string}, iter_loss: {loss}, val_acc: {100 * val_acc_now:.2f}%\")  \n",
    "            wandb.log({\"iter_acc\": iter_acc}, step=i+epoch*len(train_loader))\n",
    "            wandb.log({\"tr_acc\": tr_acc}, step=i+epoch*len(train_loader))\n",
    "            wandb.log({\"val_acc_now\": val_acc_now}, step=i+epoch*len(train_loader))\n",
    "            wandb.log({\"summary_val_acc\": val_acc_now})\n",
    "            iter_acc_array = np.append(iter_acc_array, iter_acc)\n",
    "            tr_acc_array = np.append(tr_acc_array, tr_acc)\n",
    "            val_acc_now_array = np.append(val_acc_now_array, val_acc_now)\n",
    "            base_name = f'{current_time}'\n",
    "            iter_acc_file_name_time = f'result_save/{base_name}_iter_acc_array_{unique_name}.npy'\n",
    "            tr_acc_file_name_time = f'result_save/{base_name}_tr_acc_array_{unique_name}.npy'\n",
    "            val_acc_file_name_time = f'result_save/{base_name}_val_acc_now_array_{unique_name}.npy'\n",
    "            hyperparameters_file_name_time = f'result_save/{base_name}_hyperparameters_{unique_name}.json'\n",
    "\n",
    "            hyperparameters['current epoch'] = epoch\n",
    "\n",
    "            ### 모듈 세이브: 덮어쓰기 하기 싫으면 주석 풀어서 사용 (시간마다 새로 쓰기) 비추천 ########################\n",
    "            # np.save(iter_acc_file_name_time, iter_acc_array)\n",
    "            # np.save(tr_acc_file_name_time, iter_acc_array)\n",
    "            # np.save(val_acc_file_name_time, val_acc_now_array)\n",
    "            # with open(hyperparameters_file_name_time, 'w') as f:\n",
    "            #     json.dump(hyperparameters, f, indent=4)\n",
    "            #########################################################################################################\n",
    "\n",
    "            ## 모듈 세이브 ###########################################################################################\n",
    "            # np.save(f'result_save/iter_acc_array_{unique_name}.npy', iter_acc_array)\n",
    "            # np.save(f'result_save/tr_acc_array_{unique_name}.npy', tr_acc_array)\n",
    "            # np.save(f'result_save/val_acc_now_array_{unique_name}.npy', val_acc_now_array)\n",
    "            # with open(f'result_save/hyperparameters_{unique_name}.json', 'w') as f:\n",
    "            #     json.dump(hyperparameters, f, indent=4)\n",
    "            ##########################################################################################################\n",
    "        ###### ITERATION END ##########################################################################################################\n",
    "                \n",
    "\n",
    "        ## scheduler update #############################################################################\n",
    "        if (scheduler_name != 'no'):\n",
    "            if (scheduler_name == 'ReduceLROnPlateau'):\n",
    "                scheduler.step(val_loss)\n",
    "            else:\n",
    "                scheduler.step()\n",
    "        #################################################################################################\n",
    "        \n",
    "        # 실행 시간 계산\n",
    "        epoch_time_end = time.time()\n",
    "        print(f\"epoch_time: {epoch_time_end - epoch_start_time} seconds\\n\") \n",
    "    #======== EPOCH END ==========================================================================================\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mbhkim003\u001b[0m (\u001b[33mbhkim003-seoul-national-university\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.17.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/nfs/home/bhkim003/github_folder/ByeonghyeonKim/my_snn/wandb/run-20240724_195601-oncy21dq</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/oncy21dq' target=\"_blank\">fallen-shape-69</a></strong> to <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/oncy21dq' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/oncy21dq</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "DataParallel(\n",
      "  (module): MY_SNN_CONV_ottt_sstep(\n",
      "    (layers): OTTTSequential(\n",
      "      (0): SYNAPSE_CONV_trace_sstep()\n",
      "      (1): LIF_layer_trace_sstep()\n",
      "      (2): Scale()\n",
      "      (3): SYNAPSE_CONV_trace_sstep()\n",
      "      (4): LIF_layer_trace_sstep()\n",
      "      (5): Scale()\n",
      "      (6): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
      "      (7): SYNAPSE_CONV_trace_sstep()\n",
      "      (8): LIF_layer_trace_sstep()\n",
      "      (9): Scale()\n",
      "      (10): SYNAPSE_CONV_trace_sstep()\n",
      "      (11): LIF_layer_trace_sstep()\n",
      "      (12): Scale()\n",
      "      (13): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
      "      (14): SYNAPSE_CONV_trace_sstep()\n",
      "      (15): LIF_layer_trace_sstep()\n",
      "      (16): Scale()\n",
      "      (17): SYNAPSE_CONV_trace_sstep()\n",
      "      (18): LIF_layer_trace_sstep()\n",
      "      (19): Scale()\n",
      "      (20): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
      "      (21): SYNAPSE_CONV_trace_sstep()\n",
      "      (22): LIF_layer_trace_sstep()\n",
      "      (23): Scale()\n",
      "      (24): SYNAPSE_CONV_trace_sstep()\n",
      "      (25): LIF_layer_trace_sstep()\n",
      "      (26): Scale()\n",
      "      (27): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "      (28): DimChanger_for_FC_sstep()\n",
      "      (29): SYNAPSE_FC_trace_sstep()\n",
      "    )\n",
      "  )\n",
      ")\n",
      "==================================================\n",
      "My Num of PARAMS: 9,225,610, system's param_num : 9,228,362\n",
      "Memory: 35.19MiB at 32-bit\n",
      "==================================================\n",
      "EPOCH 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "iter_acc: 0-390/391 iter_acc: 52.50%, lr=['0.1'], iter_loss: 0.21983318030834198, val_acc: 50.46%: 100%|██████████| 391/391 [03:06<00:00,  2.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch_time: 186.79969382286072 seconds\n",
      "\n",
      "EPOCH 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "iter_acc: 1-390/391 iter_acc: 57.50%, lr=['0.09999725846827562'], iter_loss: 0.19812683761119843, val_acc: 60.60%: 100%|██████████| 391/391 [02:59<00:00,  2.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch_time: 179.86214804649353 seconds\n",
      "\n",
      "EPOCH 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "iter_acc: 2-390/391 iter_acc: 63.75%, lr=['0.09998903417374229'], iter_loss: 0.14398472011089325, val_acc: 69.75%: 100%|██████████| 391/391 [02:57<00:00,  2.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch_time: 177.9391486644745 seconds\n",
      "\n",
      "EPOCH 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "iter_acc: 3-390/391 iter_acc: 66.25%, lr=['0.0999753280182866'], iter_loss: 0.1151777133345604, val_acc: 73.55%: 100%|██████████| 391/391 [03:03<00:00,  2.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch_time: 183.47263288497925 seconds\n",
      "\n",
      "EPOCH 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "iter_acc: 4-390/391 iter_acc: 77.50%, lr=['0.09995614150494293'], iter_loss: 0.11797098815441132, val_acc: 74.04%: 100%|██████████| 391/391 [03:09<00:00,  2.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch_time: 189.22718834877014 seconds\n",
      "\n",
      "EPOCH 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "iter_acc: 5-390/391 iter_acc: 77.50%, lr=['0.0999314767377287'], iter_loss: 0.13464386761188507, val_acc: 77.97%: 100%|██████████| 391/391 [03:08<00:00,  2.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch_time: 188.22753357887268 seconds\n",
      "\n",
      "EPOCH 6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "iter_acc: 6-390/391 iter_acc: 78.75%, lr=['0.09990133642141359'], iter_loss: 0.10266422480344772, val_acc: 79.43%: 100%|██████████| 391/391 [03:05<00:00,  2.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch_time: 186.09957265853882 seconds\n",
      "\n",
      "EPOCH 7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "iter_acc: 7-390/391 iter_acc: 83.75%, lr=['0.0998657238612229'], iter_loss: 0.08485345542430878, val_acc: 81.45%: 100%|██████████| 391/391 [03:06<00:00,  2.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch_time: 186.65022468566895 seconds\n",
      "\n",
      "EPOCH 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "iter_acc: 8-390/391 iter_acc: 75.00%, lr=['0.09982464296247523'], iter_loss: 0.09754413366317749, val_acc: 82.28%: 100%|██████████| 391/391 [03:05<00:00,  2.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch_time: 185.56348633766174 seconds\n",
      "\n",
      "EPOCH 9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "iter_acc: 9-390/391 iter_acc: 75.00%, lr=['0.099778098230154'], iter_loss: 0.08073090016841888, val_acc: 81.91%: 100%|██████████| 391/391 [03:07<00:00,  2.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch_time: 187.79250860214233 seconds\n",
      "\n",
      "EPOCH 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "iter_acc: 10-390/391 iter_acc: 78.75%, lr=['0.09972609476841367'], iter_loss: 0.07601461559534073, val_acc: 84.13%: 100%|██████████| 391/391 [03:04<00:00,  2.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch_time: 184.24861407279968 seconds\n",
      "\n",
      "EPOCH 11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "iter_acc: 11-390/391 iter_acc: 86.25%, lr=['0.09966863828001983'], iter_loss: 0.07904863357543945, val_acc: 83.62%: 100%|██████████| 391/391 [03:09<00:00,  2.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch_time: 189.99521136283875 seconds\n",
      "\n",
      "EPOCH 12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "iter_acc: 12-390/391 iter_acc: 83.75%, lr=['0.09960573506572391'], iter_loss: 0.09042832255363464, val_acc: 85.42%: 100%|██████████| 391/391 [03:06<00:00,  2.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch_time: 186.90590929985046 seconds\n",
      "\n",
      "EPOCH 13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "iter_acc: 13-390/391 iter_acc: 81.25%, lr=['0.09953739202357219'], iter_loss: 0.07250454276800156, val_acc: 86.61%: 100%|██████████| 391/391 [03:02<00:00,  2.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch_time: 182.87558245658875 seconds\n",
      "\n",
      "EPOCH 14\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "iter_acc: 14-390/391 iter_acc: 83.75%, lr=['0.09946361664814943'], iter_loss: 0.09405820071697235, val_acc: 86.02%: 100%|██████████| 391/391 [02:56<00:00,  2.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch_time: 176.42890691757202 seconds\n",
      "\n",
      "EPOCH 15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "iter_acc: 15-390/391 iter_acc: 83.75%, lr=['0.0993844170297569'], iter_loss: 0.0586007796227932, val_acc: 86.70%: 100%|██████████| 391/391 [03:00<00:00,  2.17it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch_time: 180.4627890586853 seconds\n",
      "\n",
      "EPOCH 16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "iter_acc: 16-390/391 iter_acc: 82.50%, lr=['0.09929980185352526'], iter_loss: 0.10188736766576767, val_acc: 87.00%: 100%|██████████| 391/391 [03:10<00:00,  2.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch_time: 190.2986936569214 seconds\n",
      "\n",
      "EPOCH 17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "iter_acc: 17-390/391 iter_acc: 90.00%, lr=['0.0992097803984621'], iter_loss: 0.06819678097963333, val_acc: 87.09%: 100%|██████████| 391/391 [03:00<00:00,  2.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch_time: 180.89619946479797 seconds\n",
      "\n",
      "EPOCH 18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "iter_acc: 18-390/391 iter_acc: 83.75%, lr=['0.09911436253643445'], iter_loss: 0.05594190955162048, val_acc: 88.09%: 100%|██████████| 391/391 [03:02<00:00,  2.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch_time: 182.66498637199402 seconds\n",
      "\n",
      "EPOCH 19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "iter_acc: 19-390/391 iter_acc: 87.50%, lr=['0.09901355873108611'], iter_loss: 0.07549135386943817, val_acc: 87.60%: 100%|██████████| 391/391 [03:03<00:00,  2.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch_time: 183.34105801582336 seconds\n",
      "\n",
      "EPOCH 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "iter_acc: 20-390/391 iter_acc: 88.75%, lr=['0.09890738003669029'], iter_loss: 0.07653224468231201, val_acc: 88.00%: 100%|██████████| 391/391 [03:03<00:00,  2.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch_time: 183.61269402503967 seconds\n",
      "\n",
      "EPOCH 21\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "iter_acc: 21-390/391 iter_acc: 88.75%, lr=['0.09879583809693737'], iter_loss: 0.08398060500621796, val_acc: 87.84%: 100%|██████████| 391/391 [03:04<00:00,  2.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch_time: 184.51070499420166 seconds\n",
      "\n",
      "EPOCH 22\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "iter_acc: 22-390/391 iter_acc: 92.50%, lr=['0.09867894514365802'], iter_loss: 0.05498407036066055, val_acc: 88.09%: 100%|██████████| 391/391 [02:55<00:00,  2.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch_time: 175.92850613594055 seconds\n",
      "\n",
      "EPOCH 23\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "iter_acc: 23-390/391 iter_acc: 90.00%, lr=['0.09855671399548181'], iter_loss: 0.11585753411054611, val_acc: 89.46%: 100%|██████████| 391/391 [03:03<00:00,  2.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch_time: 183.55969309806824 seconds\n",
      "\n",
      "EPOCH 24\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "iter_acc: 24-390/391 iter_acc: 96.25%, lr=['0.09842915805643157'], iter_loss: 0.07352716475725174, val_acc: 89.30%: 100%|██████████| 391/391 [03:01<00:00,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch_time: 181.8733606338501 seconds\n",
      "\n",
      "EPOCH 25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "iter_acc: 25-390/391 iter_acc: 92.50%, lr=['0.09829629131445343'], iter_loss: 0.0650666132569313, val_acc: 89.41%: 100%|██████████| 391/391 [03:59<00:00,  1.63it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch_time: 240.03222584724426 seconds\n",
      "\n",
      "EPOCH 26\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "iter_acc: 26-390/391 iter_acc: 97.50%, lr=['0.09815812833988292'], iter_loss: 0.11035826802253723, val_acc: 89.15%: 100%|██████████| 391/391 [04:26<00:00,  1.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch_time: 266.4082021713257 seconds\n",
      "\n",
      "EPOCH 27\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "iter_acc: 27-390/391 iter_acc: 91.25%, lr=['0.09801468428384717'], iter_loss: 0.0968332588672638, val_acc: 89.78%: 100%|██████████| 391/391 [04:23<00:00,  1.49it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch_time: 263.4714105129242 seconds\n",
      "\n",
      "EPOCH 28\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "iter_acc: 28-390/391 iter_acc: 90.00%, lr=['0.09786597487660338'], iter_loss: 0.1360936313867569, val_acc: 88.95%: 100%|██████████| 391/391 [04:27<00:00,  1.46it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch_time: 268.09420347213745 seconds\n",
      "\n",
      "EPOCH 29\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "iter_acc: 29-390/391 iter_acc: 93.75%, lr=['0.09771201642581387'], iter_loss: 0.08932002633810043, val_acc: 89.78%: 100%|██████████| 391/391 [04:14<00:00,  1.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch_time: 255.10908842086792 seconds\n",
      "\n",
      "EPOCH 30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "iter_acc: 30-390/391 iter_acc: 92.50%, lr=['0.09755282581475772'], iter_loss: 0.07019299268722534, val_acc: 89.91%: 100%|██████████| 391/391 [04:05<00:00,  1.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch_time: 245.5512716770172 seconds\n",
      "\n",
      "EPOCH 31\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "iter_acc: 31-390/391 iter_acc: 92.50%, lr=['0.09738842050047931'], iter_loss: 0.0696248859167099, val_acc: 89.97%: 100%|██████████| 391/391 [04:49<00:00,  1.35it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch_time: 290.1440763473511 seconds\n",
      "\n",
      "EPOCH 32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "iter_acc: 32-390/391 iter_acc: 96.25%, lr=['0.09721881851187408'], iter_loss: 0.05756644904613495, val_acc: 90.66%: 100%|██████████| 391/391 [04:34<00:00,  1.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch_time: 274.88340735435486 seconds\n",
      "\n",
      "EPOCH 33\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "iter_acc: 33-390/391 iter_acc: 98.75%, lr=['0.0970440384477113'], iter_loss: 0.07053720206022263, val_acc: 90.67%: 100%|██████████| 391/391 [04:45<00:00,  1.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch_time: 285.81780982017517 seconds\n",
      "\n",
      "EPOCH 34\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "iter_acc: 34-390/391 iter_acc: 95.00%, lr=['0.0968640994745946'], iter_loss: 0.0767139196395874, val_acc: 90.36%: 100%|██████████| 391/391 [04:10<00:00,  1.56it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch_time: 250.18330717086792 seconds\n",
      "\n",
      "EPOCH 35\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "iter_acc: 35-390/391 iter_acc: 91.25%, lr=['0.0966790213248601'], iter_loss: 0.07280676066875458, val_acc: 90.47%: 100%|██████████| 391/391 [04:04<00:00,  1.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch_time: 244.57452654838562 seconds\n",
      "\n",
      "EPOCH 36\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "iter_acc: 36-390/391 iter_acc: 90.00%, lr=['0.09648882429441259'], iter_loss: 0.07537270337343216, val_acc: 90.70%: 100%|██████████| 391/391 [04:13<00:00,  1.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch_time: 253.86888694763184 seconds\n",
      "\n",
      "EPOCH 37\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "iter_acc: 37-390/391 iter_acc: 97.50%, lr=['0.09629352924049978'], iter_loss: 0.07228220254182816, val_acc: 90.65%: 100%|██████████| 391/391 [04:01<00:00,  1.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch_time: 242.00875234603882 seconds\n",
      "\n",
      "EPOCH 38\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "iter_acc: 38-390/391 iter_acc: 93.75%, lr=['0.09609315757942506'], iter_loss: 0.05795593187212944, val_acc: 90.76%: 100%|██████████| 391/391 [04:33<00:00,  1.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch_time: 273.4603452682495 seconds\n",
      "\n",
      "EPOCH 39\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "iter_acc: 39-390/391 iter_acc: 97.50%, lr=['0.09588773128419908'], iter_loss: 0.0689907819032669, val_acc: 90.31%: 100%|██████████| 391/391 [04:25<00:00,  1.47it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch_time: 266.1317226886749 seconds\n",
      "\n",
      "EPOCH 40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "iter_acc: 40-390/391 iter_acc: 97.50%, lr=['0.09567727288213007'], iter_loss: 0.07373195886611938, val_acc: 91.08%: 100%|██████████| 391/391 [04:18<00:00,  1.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch_time: 259.1409990787506 seconds\n",
      "\n",
      "EPOCH 41\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "iter_acc: 41-390/391 iter_acc: 95.00%, lr=['0.09546180545235346'], iter_loss: 0.06563118100166321, val_acc: 91.47%: 100%|██████████| 391/391 [04:07<00:00,  1.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch_time: 247.91387128829956 seconds\n",
      "\n",
      "EPOCH 42\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "iter_acc: 42-390/391 iter_acc: 97.50%, lr=['0.09524135262330101'], iter_loss: 0.08198333531618118, val_acc: 91.02%: 100%|██████████| 391/391 [04:03<00:00,  1.61it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch_time: 243.2050862312317 seconds\n",
      "\n",
      "EPOCH 43\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "iter_acc: 43-390/391 iter_acc: 90.00%, lr=['0.09501593857010972'], iter_loss: 0.045796677470207214, val_acc: 91.10%: 100%|██████████| 391/391 [04:07<00:00,  1.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch_time: 247.28993201255798 seconds\n",
      "\n",
      "EPOCH 44\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "iter_acc: 44-390/391 iter_acc: 97.50%, lr=['0.09478558801197068'], iter_loss: 0.07334693521261215, val_acc: 91.30%: 100%|██████████| 391/391 [02:58<00:00,  2.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch_time: 179.10973238945007 seconds\n",
      "\n",
      "EPOCH 45\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "iter_acc: 45-390/391 iter_acc: 95.00%, lr=['0.09455032620941842'], iter_loss: 0.07827743142843246, val_acc: 91.45%: 100%|██████████| 391/391 [03:09<00:00,  2.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch_time: 190.1740219593048 seconds\n",
      "\n",
      "EPOCH 46\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "iter_acc: 46-390/391 iter_acc: 97.50%, lr=['0.09431017896156076'], iter_loss: 0.06969204545021057, val_acc: 90.90%: 100%|██████████| 391/391 [03:16<00:00,  1.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch_time: 197.0273082256317 seconds\n",
      "\n",
      "EPOCH 47\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "iter_acc: 47-390/391 iter_acc: 97.50%, lr=['0.09406517260324962'], iter_loss: 0.06783393025398254, val_acc: 91.63%: 100%|██████████| 391/391 [03:30<00:00,  1.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch_time: 211.10242581367493 seconds\n",
      "\n",
      "EPOCH 48\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "iter_acc: 48-390/391 iter_acc: 96.25%, lr=['0.09381533400219319'], iter_loss: 0.07515931129455566, val_acc: 90.84%: 100%|██████████| 391/391 [03:10<00:00,  2.05it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch_time: 190.9898226261139 seconds\n",
      "\n",
      "EPOCH 49\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "iter_acc: 49-390/391 iter_acc: 97.50%, lr=['0.09356069055600949'], iter_loss: 0.09008507430553436, val_acc: 91.14%: 100%|██████████| 391/391 [03:29<00:00,  1.87it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch_time: 209.26180338859558 seconds\n",
      "\n",
      "EPOCH 50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "iter_acc: 50-390/391 iter_acc: 96.25%, lr=['0.09330127018922195'], iter_loss: 0.09113170206546783, val_acc: 91.57%: 100%|██████████| 391/391 [03:18<00:00,  1.97it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch_time: 198.21781492233276 seconds\n",
      "\n",
      "EPOCH 51\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "iter_acc: 51-390/391 iter_acc: 98.75%, lr=['0.0930371013501972'], iter_loss: 0.09315484762191772, val_acc: 91.30%: 100%|██████████| 391/391 [03:34<00:00,  1.83it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch_time: 214.21790146827698 seconds\n",
      "\n",
      "EPOCH 52\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "iter_acc: 52-390/391 iter_acc: 92.50%, lr=['0.09276821300802535'], iter_loss: 0.07455512136220932, val_acc: 91.55%: 100%|██████████| 391/391 [03:23<00:00,  1.92it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch_time: 203.9627342224121 seconds\n",
      "\n",
      "EPOCH 53\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "iter_acc: 53-390/391 iter_acc: 98.75%, lr=['0.09249463464934321'], iter_loss: 0.08551381528377533, val_acc: 91.58%: 100%|██████████| 391/391 [03:07<00:00,  2.09it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch_time: 187.674476146698 seconds\n",
      "\n",
      "EPOCH 54\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "iter_acc: 54-390/391 iter_acc: 98.75%, lr=['0.09221639627510077'], iter_loss: 0.07874483615159988, val_acc: 91.55%: 100%|██████████| 391/391 [03:22<00:00,  1.93it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch_time: 202.6011347770691 seconds\n",
      "\n",
      "EPOCH 55\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "iter_acc: 55-390/391 iter_acc: 97.50%, lr=['0.09193352839727122'], iter_loss: 0.0693407654762268, val_acc: 92.00%: 100%|██████████| 391/391 [03:00<00:00,  2.17it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch_time: 180.59844589233398 seconds\n",
      "\n",
      "EPOCH 56\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "iter_acc: 56-390/391 iter_acc: 97.50%, lr=['0.09164606203550499'], iter_loss: 0.06659053266048431, val_acc: 91.67%: 100%|██████████| 391/391 [03:21<00:00,  1.94it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch_time: 201.28884625434875 seconds\n",
      "\n",
      "EPOCH 57\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "iter_acc: 57-390/391 iter_acc: 97.50%, lr=['0.0913540287137281'], iter_loss: 0.08170193433761597, val_acc: 91.47%: 100%|██████████| 391/391 [03:02<00:00,  2.14it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch_time: 182.7330777645111 seconds\n",
      "\n",
      "EPOCH 58\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "iter_acc: 58-390/391 iter_acc: 97.50%, lr=['0.09105746045668521'], iter_loss: 0.07273052632808685, val_acc: 91.78%: 100%|██████████| 391/391 [03:27<00:00,  1.88it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch_time: 207.79045581817627 seconds\n",
      "\n",
      "EPOCH 59\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "iter_acc: 59-390/391 iter_acc: 98.75%, lr=['0.09075638978642771'], iter_loss: 0.042938411235809326, val_acc: 91.70%: 100%|██████████| 391/391 [03:24<00:00,  1.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch_time: 204.70860838890076 seconds\n",
      "\n",
      "EPOCH 60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "iter_acc: 60-390/391 iter_acc: 96.25%, lr=['0.09045084971874738'], iter_loss: 0.05988059937953949, val_acc: 91.85%: 100%|██████████| 391/391 [02:56<00:00,  2.22it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch_time: 176.66552734375 seconds\n",
      "\n",
      "EPOCH 61\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "iter_acc: 61-390/391 iter_acc: 96.25%, lr=['0.09014087375955573'], iter_loss: 0.09032443165779114, val_acc: 91.65%: 100%|██████████| 391/391 [02:59<00:00,  2.17it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch_time: 180.17144012451172 seconds\n",
      "\n",
      "EPOCH 62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "iter_acc: 62-390/391 iter_acc: 97.50%, lr=['0.08982649590120982'], iter_loss: 0.07800906896591187, val_acc: 91.75%: 100%|██████████| 391/391 [03:05<00:00,  2.11it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch_time: 185.87698817253113 seconds\n",
      "\n",
      "EPOCH 63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "iter_acc: 63-390/391 iter_acc: 96.25%, lr=['0.08950775061878452'], iter_loss: 0.08473827689886093, val_acc: 92.04%: 100%|██████████| 391/391 [03:53<00:00,  1.68it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch_time: 233.506826877594 seconds\n",
      "\n",
      "EPOCH 64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "iter_acc: 64-390/391 iter_acc: 98.75%, lr=['0.089184672866292'], iter_loss: 0.06561294198036194, val_acc: 92.00%: 100%|██████████| 391/391 [03:33<00:00,  1.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch_time: 213.96638345718384 seconds\n",
      "\n",
      "EPOCH 65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "iter_acc: 65-390/391 iter_acc: 95.00%, lr=['0.08885729807284856'], iter_loss: 0.06125485897064209, val_acc: 91.64%: 100%|██████████| 391/391 [02:57<00:00,  2.21it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch_time: 177.50676488876343 seconds\n",
      "\n",
      "EPOCH 66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "iter_acc: 66-390/391 iter_acc: 100.00%, lr=['0.08852566213878947'], iter_loss: 0.08262740075588226, val_acc: 91.67%: 100%|██████████| 391/391 [03:14<00:00,  2.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch_time: 194.7998719215393 seconds\n",
      "\n",
      "EPOCH 67\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "iter_acc: 67-390/391 iter_acc: 96.25%, lr=['0.08818980143173213'], iter_loss: 0.05341711640357971, val_acc: 92.04%: 100%|██████████| 391/391 [03:07<00:00,  2.09it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch_time: 187.26699090003967 seconds\n",
      "\n",
      "EPOCH 68\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "iter_acc: 68-390/391 iter_acc: 96.25%, lr=['0.08784975278258783'], iter_loss: 0.061360668390989304, val_acc: 91.74%: 100%|██████████| 391/391 [04:05<00:00,  1.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch_time: 245.3001790046692 seconds\n",
      "\n",
      "EPOCH 69\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "iter_acc: 69-390/391 iter_acc: 98.75%, lr=['0.08750555348152299'], iter_loss: 0.06053036078810692, val_acc: 92.29%: 100%|██████████| 391/391 [03:53<00:00,  1.67it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch_time: 234.03155827522278 seconds\n",
      "\n",
      "EPOCH 70\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "iter_acc: 70-390/391 iter_acc: 98.75%, lr=['0.08715724127386973'], iter_loss: 0.07410945743322372, val_acc: 91.97%: 100%|██████████| 391/391 [02:59<00:00,  2.18it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch_time: 179.42003440856934 seconds\n",
      "\n",
      "EPOCH 71\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "iter_acc: 71-390/391 iter_acc: 97.50%, lr=['0.08680485435598673'], iter_loss: 0.08101749420166016, val_acc: 91.50%: 100%|██████████| 391/391 [04:10<00:00,  1.56it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch_time: 250.30630207061768 seconds\n",
      "\n",
      "EPOCH 72\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "iter_acc: 72-390/391 iter_acc: 96.25%, lr=['0.0864484313710706'], iter_loss: 0.0700424537062645, val_acc: 92.04%: 100%|██████████| 391/391 [04:06<00:00,  1.59it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch_time: 246.7883415222168 seconds\n",
      "\n",
      "EPOCH 73\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "iter_acc: 73-390/391 iter_acc: 95.00%, lr=['0.08608801140491813'], iter_loss: 0.05126051604747772, val_acc: 91.84%: 100%|██████████| 391/391 [03:01<00:00,  2.15it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch_time: 181.96234822273254 seconds\n",
      "\n",
      "EPOCH 74\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "iter_acc: 74-390/391 iter_acc: 97.50%, lr=['0.0857236339816402'], iter_loss: 0.0554540678858757, val_acc: 92.16%: 100%|██████████| 391/391 [02:57<00:00,  2.20it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch_time: 177.54482746124268 seconds\n",
      "\n",
      "EPOCH 75\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "iter_acc: 75-390/391 iter_acc: 95.00%, lr=['0.0853553390593274'], iter_loss: 0.08429455757141113, val_acc: 91.90%: 100%|██████████| 391/391 [03:04<00:00,  2.12it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch_time: 184.5422236919403 seconds\n",
      "\n",
      "EPOCH 76\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "iter_acc: 76-390/391 iter_acc: 95.00%, lr=['0.08498316702566831'], iter_loss: 0.059028707444667816, val_acc: 91.83%: 100%|██████████| 391/391 [03:13<00:00,  2.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch_time: 193.34610056877136 seconds\n",
      "\n",
      "EPOCH 77\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "iter_acc: 77-390/391 iter_acc: 97.50%, lr=['0.08460715869352037'], iter_loss: 0.09316088259220123, val_acc: 92.10%: 100%|██████████| 391/391 [02:59<00:00,  2.18it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch_time: 179.44090008735657 seconds\n",
      "\n",
      "EPOCH 78\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "iter_acc: 78-390/391 iter_acc: 96.25%, lr=['0.08422735529643446'], iter_loss: 0.08217059075832367, val_acc: 91.92%: 100%|██████████| 391/391 [03:03<00:00,  2.13it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch_time: 183.85005593299866 seconds\n",
      "\n",
      "EPOCH 79\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "iter_acc: 79-390/391 iter_acc: 97.50%, lr=['0.08384379848413306'], iter_loss: 0.06613031029701233, val_acc: 92.08%: 100%|██████████| 391/391 [03:00<00:00,  2.17it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch_time: 180.58957386016846 seconds\n",
      "\n",
      "EPOCH 80\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "iter_acc: 80-390/391 iter_acc: 98.75%, lr=['0.08345653031794294'], iter_loss: 0.0633472353219986, val_acc: 92.01%: 100%|██████████| 391/391 [03:00<00:00,  2.17it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch_time: 180.67837619781494 seconds\n",
      "\n",
      "EPOCH 81\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "iter_acc: 81-390/391 iter_acc: 98.75%, lr=['0.08306559326618262'], iter_loss: 0.06705271452665329, val_acc: 92.48%: 100%|██████████| 391/391 [03:07<00:00,  2.09it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch_time: 187.59840965270996 seconds\n",
      "\n",
      "EPOCH 82\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "iter_acc: 82-390/391 iter_acc: 96.25%, lr=['0.08267103019950531'], iter_loss: 0.09225263446569443, val_acc: 92.16%: 100%|██████████| 391/391 [03:06<00:00,  2.09it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch_time: 187.15315914154053 seconds\n",
      "\n",
      "EPOCH 83\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "iter_acc: 83-390/391 iter_acc: 98.75%, lr=['0.08227288438619755'], iter_loss: 0.1145591139793396, val_acc: 92.08%: 100%|██████████| 391/391 [03:00<00:00,  2.17it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch_time: 180.36896109580994 seconds\n",
      "\n",
      "EPOCH 84\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "iter_acc: 84-390/391 iter_acc: 97.50%, lr=['0.0818711994874345'], iter_loss: 0.06754499673843384, val_acc: 91.79%: 100%|██████████| 391/391 [03:05<00:00,  2.11it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch_time: 185.4943253993988 seconds\n",
      "\n",
      "EPOCH 85\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "iter_acc: 85-390/391 iter_acc: 97.50%, lr=['0.08146601955249189'], iter_loss: 0.06023787707090378, val_acc: 91.41%: 100%|██████████| 391/391 [03:03<00:00,  2.13it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch_time: 183.87380003929138 seconds\n",
      "\n",
      "EPOCH 86\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "iter_acc: 86-390/391 iter_acc: 97.50%, lr=['0.08105738901391554'], iter_loss: 0.08711182326078415, val_acc: 91.61%: 100%|██████████| 391/391 [03:07<00:00,  2.09it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch_time: 187.43342232704163 seconds\n",
      "\n",
      "EPOCH 87\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "iter_acc: 87-390/391 iter_acc: 98.75%, lr=['0.08064535268264884'], iter_loss: 0.06941714882850647, val_acc: 92.47%: 100%|██████████| 391/391 [03:19<00:00,  1.96it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch_time: 199.51277661323547 seconds\n",
      "\n",
      "EPOCH 88\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "iter_acc: 88-390/391 iter_acc: 98.75%, lr=['0.08022995574311877'], iter_loss: 0.1119183897972107, val_acc: 92.32%: 100%|██████████| 391/391 [04:11<00:00,  1.55it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch_time: 252.0534040927887 seconds\n",
      "\n",
      "EPOCH 89\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "iter_acc: 89-389/391 iter_acc: 96.88%, lr=['0.0798112437482808'], iter_loss: 0.24602597951889038, val_acc: 92.32%: 100%|█████████▉| 390/391 [03:49<00:00,  1.78it/s] "
     ]
    }
   ],
   "source": [
    "### my_snn control board ########################\n",
    "decay = 0.5 # 0.875 0.25 0.125 0.75 0.5\n",
    "# nda 0.25 # ottt 0.5\n",
    "\n",
    "unique_name = 'main' ## 이거 설정하면 새로운 경로에 모두 save\n",
    "wandb.init(project= f'my_snn {unique_name}')\n",
    "my_snn_system(  devices = \"2\",\n",
    "                single_step = True, # True # False\n",
    "                unique_name = unique_name,\n",
    "                my_seed = 42,\n",
    "                TIME = 6 , # dvscifar 10 # ottt 6 or 10 # nda 10  # 제작하는 dvs에서 TIME넘거나 적으면 자르거나 PADDING함\n",
    "                BATCH = 128, # batch norm 할거면 2이상으로 해야함   # nda 256   #  ottt 128\n",
    "                IMAGE_SIZE = 32, # dvscifar 48 # MNIST 28 # CIFAR10 32 # PMNIST 28\n",
    "                # dvsgesture 128, dvs_cifar2 128, nmnist 34, n_caltech101 180,240, n_tidigits 64, heidelberg 700, \n",
    "                #pmnist는 28로 해야 됨. 나머지는 바꿔도 돌아는 감.\n",
    "\n",
    "                # DVS_CIFAR10 할거면 time 10으로 해라\n",
    "                which_data = 'CIFAR10',\n",
    "# 'CIFAR100' 'CIFAR10' 'MNIST' 'FASHION_MNIST' 'DVS_CIFAR10' 'PMNIST'아직\n",
    "# 'DVS_GESTURE','DVS_CIFAR10_2','NMNIST','N_CALTECH101','n_tidigits','heidelberg'\n",
    "                # CLASS_NUM = 10,\n",
    "                data_path = '/data2', # YOU NEED TO CHANGE THIS\n",
    "                rate_coding = False, # True # False\n",
    "\n",
    "                lif_layer_v_init = 0.0,\n",
    "                lif_layer_v_decay = decay,\n",
    "                lif_layer_v_threshold = 1.0,  # 10000이상으로 하면 NDA LIF 씀. #nda 0.5  #ottt 1.0\n",
    "                lif_layer_v_reset = 0, # 10000이상은 hardreset (내 LIF쓰기는 함 ㅇㅇ)\n",
    "                lif_layer_sg_width = 1.0, # # surrogate sigmoid 쓸 때는 의미없음\n",
    "\n",
    "                # synapse_conv_in_channels = IMAGE_PIXEL_CHANNEL,\n",
    "                synapse_conv_kernel_size = 3,\n",
    "                synapse_conv_stride = 1,\n",
    "                synapse_conv_padding = 1,\n",
    "                synapse_conv_trace_const1 = 1,\n",
    "                synapse_conv_trace_const2 = decay, # lif_layer_v_decay\n",
    "\n",
    "                # synapse_fc_out_features = CLASS_NUM,\n",
    "                synapse_fc_trace_const1 = 1,\n",
    "                synapse_fc_trace_const2 = decay, # lif_layer_v_decay\n",
    "\n",
    "                pre_trained = False, # True # False\n",
    "                convTrue_fcFalse = True, # True # False\n",
    "\n",
    "                # 'P' for average pooling, 'D' for (1,1) aver pooling, 'M' for maxpooling, 'L' for linear classifier, [  ] for residual block\n",
    "                # conv에서 10000 이상은 depth-wise separable (BPTT만 지원), 20000이상은 depth-wise (BPTT만 지원)\n",
    "                # cfg = [64],\n",
    "                # cfg = [64,[64,64],64], # 끝에 linear classifier 하나 자동으로 붙습니다\n",
    "                cfg = [64, 128, 'P', 256, 256, 'P', 512, 512, 'P', 512, 512, 'D'], #ottt\n",
    "                # cfg = [64, 128, 'P', 256, 256, 'P', 512, 512, 'P', 512, 512], #ottt\n",
    "                # cfg = [64, 128, 'M', 256, 256, 'M', 512, 512, 'M', 512, 512], # ottt \n",
    "                # cfg = [64, 'P', 128, 'P', 256, 256, 'P', 512, 512, 512, 512, 'D'], # nda\n",
    "                # cfg = [64, 'P', 128, 'P', 256, 256, 'P', 512, 512, 512, 512], # nda 128pixel\n",
    "                # cfg = [64, 'P', 128, 'P', 256, 256, 'P', 512, 512, 512, 512, 'L', 4096, 4096],\n",
    "                # cfg = [20001,10001], # depthwise, separable\n",
    "                # cfg = [64,20064,10001], # vanilla conv, depthwise, separable\n",
    "                # cfg = [8, 'P', 8, 'P', 8, 'P', 8,'P', 8, 'P'],\n",
    "                # cfg = [], \n",
    "                \n",
    "                net_print = True, # True # False\n",
    "                weight_count_print = False, # True # False\n",
    "                \n",
    "                pre_trained_path = f\"net_save/save_now_net_{unique_name}.pth\",\n",
    "                learning_rate = 0.1, # default 0.001  # ottt 0.1 0.00001 # nda 0.001 \n",
    "                epoch_num = 300,\n",
    "                verbose_interval = 999999999, #숫자 크게 하면 꺼짐 #걍 중간중간 iter에서 끊어서 출력\n",
    "                validation_interval = 999999999, #숫자 크게 하면 에포크 마지막 iter 때 val 함\n",
    "\n",
    "                tdBN_on = False,  # True # False\n",
    "                BN_on = False,  # True # False\n",
    "                \n",
    "                surrogate = 'sigmoid', # 'rectangle' 'sigmoid' 'rough_rectangle'\n",
    "                \n",
    "                gradient_verbose = False,  # True # False  # weight gradient 각 layer마다 띄워줌\n",
    "\n",
    "                BPTT_on = False,  # True # False # True이면 BPTT, False이면 OTTT  # depthwise, separable은 BPTT만 가능\n",
    "                optimizer_what = 'SGD', # 'SGD' 'Adam', 'RMSprop'\n",
    "                scheduler_name = 'CosineAnnealingLR', # 'no' 'StepLR' 'ExponentialLR' 'ReduceLROnPlateau' 'CosineAnnealingLR' 'OneCycleLR'\n",
    "                \n",
    "                ddp_on = False,   # True # False\n",
    "\n",
    "                nda_net = False,   # True # False\n",
    "\n",
    "                domain_il_epoch = 0, # over 0, then domain il mode on # pmnist 쓸거면 HLOP 코드보고 더 디벨롭하셈. 지금 개발 hold함.\n",
    "                \n",
    "                dvs_clipping = True, # dvs zero&one  # gesture, cifar-dvs2, nmnist, ncaltech101\n",
    "                dvs_duration = 1000000, # 0 아니면 time sampling # dvs number sampling OR time sampling # gesture, cifar-dvs2, nmnist, ncaltech101\n",
    "                #있는 데이터들 #gesture 1000000 #nmnist 10000\n",
    "\n",
    "                OTTT_sWS_on = True, # True # False # BPTT끄고, CONV에만 적용됨.\n",
    "                \n",
    "                ) \n",
    "# sigmoid와 BN이 있어야 잘된다.\n",
    "# average pooling\n",
    "# 이 낫다. \n",
    " \n",
    "# nda에서는 decay = 0.25, threshold = 0.5, width =1, surrogate = rectangle, batch = 256, tdBN = True\n",
    "## OTTT 에서는 decay = 0.5, threshold = 1.0, surrogate = sigmoid, batch = 128, BN = True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # sweep 하는 코드, 위 셀 주석처리 해야 됨.\n",
    "\n",
    "# unique_name_hyper = 'main'\n",
    "# sweep_configuration = {\n",
    "#     'method': 'bayes',\n",
    "#     'name': 'my_snn_sweep',\n",
    "#     'metric': {'goal': 'maximize', 'name': 'val_acc_now'},\n",
    "#     'parameters': \n",
    "#     {\n",
    "#         \"learning_rate\": {\"values\": [0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9,1.0,1.1,1.2,1.3,1.4,1.5,1.6,1.7,1.8,1.9,2.0]},\n",
    "#         \"batch_size\": {\"values\": [64, 96, 128]},\n",
    "#         \"decay\": {\"values\": [0.3,0.4,0.5,0.6,0.7,0.8,0.875,0.9]},\n",
    "#      }\n",
    "# }\n",
    "\n",
    "# def hyper_iter():\n",
    "#     ### my_snn control board ########################\n",
    "#     unique_name = unique_name_hyper ## 이거 설정하면 새로운 경로에 모두 save\n",
    "    \n",
    "#     wandb.init()\n",
    "#     learning_rate  =  wandb.config.learning_rate\n",
    "#     batch_size  =  wandb.config.batch_size\n",
    "#     decay  =  wandb.config.decay\n",
    "\n",
    "#     my_snn_system(  devices = \"3\",\n",
    "#                     single_step = True, # True # False\n",
    "#                     unique_name = unique_name,\n",
    "#                     my_seed = 42,\n",
    "#                     TIME = 6 , # dvscifar 10 # ottt 6 or 10 # nda 10  # 제작하는 dvs에서 TIME넘거나 적으면 자르거나 PADDING함\n",
    "#                     BATCH = batch_size, # batch norm 할거면 2이상으로 해야함   # nda 256   #  ottt 128\n",
    "#                     IMAGE_SIZE = 32, # dvscifar 48 # MNIST 28 # CIFAR10 32 # PMNIST 28\n",
    "#                     # dvsgesture 128, dvs_cifar2 128, nmnist 34, n_caltech101 180,240, n_tidigits 64, heidelberg 700, \n",
    "#                     #pmnist는 28로 해야 됨. 나머지는 바꿔도 돌아는 감.\n",
    "\n",
    "#                     # DVS_CIFAR10 할거면 time 10으로 해라\n",
    "#                     which_data = 'CIFAR10',\n",
    "#     # 'CIFAR100' 'CIFAR10' 'MNIST' 'FASHION_MNIST' 'DVS_CIFAR10' 'PMNIST'아직\n",
    "#     # 'DVS_GESTURE','DVS_CIFAR10_2','NMNIST','N_CALTECH101','n_tidigits','heidelberg'\n",
    "#                     # CLASS_NUM = 10,\n",
    "#                     data_path = '/data2', # YOU NEED TO CHANGE THIS\n",
    "#                     rate_coding = False, # True # False\n",
    "\n",
    "#                     lif_layer_v_init = 0.0,\n",
    "#                     lif_layer_v_decay = decay,\n",
    "#                     lif_layer_v_threshold = 1.0,  # 10000이상으로 하면 NDA LIF 씀. #nda 0.5  #ottt 1.0\n",
    "#                     lif_layer_v_reset = 0, # 10000이상은 hardreset (내 LIF쓰기는 함 ㅇㅇ)\n",
    "#                     lif_layer_sg_width = 1.0, # # surrogate sigmoid 쓸 때는 의미없음\n",
    "\n",
    "#                     # synapse_conv_in_channels = IMAGE_PIXEL_CHANNEL,\n",
    "#                     synapse_conv_kernel_size = 3,\n",
    "#                     synapse_conv_stride = 1,\n",
    "#                     synapse_conv_padding = 1,\n",
    "#                     synapse_conv_trace_const1 = 1,\n",
    "#                     synapse_conv_trace_const2 = decay, # lif_layer_v_decay\n",
    "\n",
    "#                     # synapse_fc_out_features = CLASS_NUM,\n",
    "#                     synapse_fc_trace_const1 = 1,\n",
    "#                     synapse_fc_trace_const2 = decay, # lif_layer_v_decay\n",
    "\n",
    "#                     pre_trained = False, # True # False\n",
    "#                     convTrue_fcFalse = True, # True # False\n",
    "\n",
    "#                     # 'P' for average pooling, 'D' for (1,1) aver pooling, 'M' for maxpooling, 'L' for linear classifier, [  ] for residual block\n",
    "#                     # conv에서 10000 이상은 depth-wise separable (BPTT만 지원), 20000이상은 depth-wise (BPTT만 지원)\n",
    "#                     # cfg = [64],\n",
    "#                     # cfg = [64,[64,64],64], # 끝에 linear classifier 하나 자동으로 붙습니다\n",
    "#                     cfg = [64, 128, 'P', 256, 256, 'P', 512, 512, 'P', 512, 512, 'D'], #ottt\n",
    "#                     # cfg = [64, 128, 'P', 256, 256, 'P', 512, 512, 'P', 512, 512], #ottt\n",
    "#                     # cfg = [64, 128, 'M', 256, 256, 'M', 512, 512, 'M', 512, 512], # ottt \n",
    "#                     # cfg = [64, 'P', 128, 'P', 256, 256, 'P', 512, 512, 512, 512, 'D'], # nda\n",
    "#                     # cfg = [64, 'P', 128, 'P', 256, 256, 'P', 512, 512, 512, 512], # nda 128pixel\n",
    "#                     # cfg = [64, 'P', 128, 'P', 256, 256, 'P', 512, 512, 512, 512, 'L', 4096, 4096],\n",
    "#                     # cfg = [20001,10001], # depthwise, separable\n",
    "#                     # cfg = [64,20064,10001], # vanilla conv, depthwise, separable\n",
    "#                     # cfg = [8, 'P', 8, 'P', 8, 'P', 8,'P', 8, 'P'],\n",
    "#                     # cfg = [], \n",
    "                    \n",
    "#                     net_print = True, # True # False\n",
    "#                     weight_count_print = False, # True # False\n",
    "                    \n",
    "#                     pre_trained_path = f\"net_save/save_now_net_{unique_name}.pth\",\n",
    "#                     learning_rate = learning_rate, # default 0.001  # ottt 0.1 0.00001 # nda 0.001 \n",
    "#                     epoch_num = 4,\n",
    "#                     verbose_interval = 999999999, #숫자 크게 하면 꺼짐 #걍 중간중간 iter에서 끊어서 출력\n",
    "#                     validation_interval = 999999999, #숫자 크게 하면 에포크 마지막 iter 때 val 함\n",
    "\n",
    "#                     tdBN_on = False,  # True # False\n",
    "#                     BN_on = False,  # True # False\n",
    "                    \n",
    "#                     surrogate = 'sigmoid', # 'rectangle' 'sigmoid' 'rough_rectangle'\n",
    "                    \n",
    "#                     gradient_verbose = False,  # True # False  # weight gradient 각 layer마다 띄워줌\n",
    "\n",
    "#                     BPTT_on = False,  # True # False # True이면 BPTT, False이면 OTTT  # depthwise, separable은 BPTT만 가능\n",
    "#                     optimizer_what = 'SGD', # 'SGD' 'Adam', 'RMSprop'\n",
    "#                     scheduler_name = 'CosineAnnealingLR', # 'no' 'StepLR' 'ExponentialLR' 'ReduceLROnPlateau' 'CosineAnnealingLR' 'OneCycleLR'\n",
    "                    \n",
    "#                     ddp_on = False,   # True # False\n",
    "\n",
    "#                     nda_net = False,   # True # False\n",
    "\n",
    "#                     domain_il_epoch = 0, # over 0, then domain il mode on # pmnist 쓸거면 HLOP 코드보고 더 디벨롭하셈. 지금 개발 hold함.\n",
    "                    \n",
    "#                     dvs_clipping = True, # dvs zero&one  # gesture, cifar-dvs2, nmnist, ncaltech101\n",
    "#                     dvs_duration = 1000000, # 0 아니면 time sampling # dvs number sampling OR time sampling # gesture, cifar-dvs2, nmnist, ncaltech101\n",
    "#                     #있는 데이터들 #gesture 1000000 #nmnist 10000\n",
    "\n",
    "#                     OTTT_sWS_on = True, # True # False # BPTT끄고, CONV에만 적용됨.\n",
    "                    \n",
    "#                     ) \n",
    "#     # sigmoid와 BN이 있어야 잘된다.\n",
    "#     # average pooling\n",
    "#     # 이 낫다. \n",
    "    \n",
    "#     # nda에서는 decay = 0.25, threshold = 0.5, width =1, surrogate = rectangle, batch = 256, tdBN = True\n",
    "#     ## OTTT 에서는 decay = 0.5, threshold = 1.0, surrogate = sigmoid, batch = 128, BN = True\n",
    "\n",
    "\n",
    "# sweep_id = wandb.sweep(sweep=sweep_configuration, project=f'my_snn {unique_name_hyper}')\n",
    "# wandb.agent(sweep_id, function=hyper_iter, count=1000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "# import matplotlib.pyplot as plt\n",
    "# import json\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# def pad_array_to_match_length(array1, array2):\n",
    "#     if len(array1) > len(array2):\n",
    "#         padded_array2 = np.pad(array2, (0, len(array1) - len(array2)), 'constant')\n",
    "#         return array1, padded_array2\n",
    "#     elif len(array2) > len(array1):\n",
    "#         padded_array1 = np.pad(array1, (0, len(array2) - len(array1)), 'constant')\n",
    "#         return padded_array1, array2\n",
    "#     else:\n",
    "#         return array1, array2\n",
    "# def load_hyperparameters(filename=f'result_save/hyperparameters_{unique_name}.json'):\n",
    "#     with open(filename, 'r') as f:\n",
    "#         return json.load(f)\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# current_time = '20240628_110116'\n",
    "# base_name = f'{current_time}'\n",
    "# iter_acc_file_name = f'result_save/{base_name}_iter_acc_array_{unique_name}.npy'\n",
    "# val_acc_file_name = f'result_save/{base_name}_val_acc_now_array_{unique_name}.npy'\n",
    "# hyperparameters_file_name = f'result_save/{base_name}_hyperparameters_{unique_name}.json'\n",
    "\n",
    "# ### if you want to just see most recent train and val acc###########################\n",
    "# iter_acc_file_name = f'result_save/iter_acc_array_{unique_name}.npy'\n",
    "# tr_acc_file_name = f'result_save/tr_acc_array_{unique_name}.npy'\n",
    "# val_acc_file_name = f'result_save/val_acc_now_array_{unique_name}.npy'\n",
    "# hyperparameters_file_name = f'result_save/hyperparameters_{unique_name}.json'\n",
    "\n",
    "# loaded_iter_acc_array = np.load(iter_acc_file_name)*100\n",
    "# loaded_tr_acc_array = np.load(tr_acc_file_name)*100\n",
    "# loaded_val_acc_array = np.load(val_acc_file_name)*100\n",
    "# hyperparameters = load_hyperparameters(hyperparameters_file_name)\n",
    "\n",
    "# loaded_iter_acc_array, loaded_val_acc_array = pad_array_to_match_length(loaded_iter_acc_array, loaded_val_acc_array)\n",
    "# loaded_iter_acc_array, loaded_tr_acc_array = pad_array_to_match_length(loaded_iter_acc_array, loaded_tr_acc_array)\n",
    "# loaded_val_acc_array, loaded_tr_acc_array = pad_array_to_match_length(loaded_val_acc_array, loaded_tr_acc_array)\n",
    "\n",
    "# top_iter_acc = np.max(loaded_iter_acc_array)\n",
    "# top_tr_acc = np.max(loaded_tr_acc_array)\n",
    "# top_val_acc = np.max(loaded_val_acc_array)\n",
    "\n",
    "# which_data = hyperparameters['which_data']\n",
    "# BPTT_on = hyperparameters['BPTT_on']\n",
    "# current_epoch = hyperparameters['current epoch']\n",
    "# surrogate = hyperparameters['surrogate']\n",
    "# cfg = hyperparameters['cfg']\n",
    "# tdBN_on = hyperparameters['tdBN_on']\n",
    "# BN_on = hyperparameters['BN_on']\n",
    "\n",
    "\n",
    "# iterations = np.arange(len(loaded_iter_acc_array))\n",
    "\n",
    "# # 그래프 그리기\n",
    "# plt.figure(figsize=(10, 5))\n",
    "# plt.plot(iterations, loaded_iter_acc_array, label='Iter Accuracy', color='g', alpha=0.2)\n",
    "# plt.plot(iterations, loaded_tr_acc_array, label='Training Accuracy', color='b')\n",
    "# plt.plot(iterations, loaded_val_acc_array, label='Validation Accuracy', color='r')\n",
    "\n",
    "# # # 텍스트 추가\n",
    "# # plt.text(0.05, 0.95, f'Top Training Accuracy: {100*top_iter_acc:.2f}%', transform=plt.gca().transAxes, fontsize=12, verticalalignment='top', horizontalalignment='left', color='blue')\n",
    "# # plt.text(0.05, 0.90, f'Top Validation Accuracy: {100*top_val_acc:.2f}%', transform=plt.gca().transAxes, fontsize=12, verticalalignment='top', horizontalalignment='left', color='red')\n",
    "# # 텍스트 추가\n",
    "# plt.text(0.5, 0.10, f'Top Training Accuracy: {top_tr_acc:.2f}%', transform=plt.gca().transAxes, fontsize=12, verticalalignment='top', horizontalalignment='center', color='blue')\n",
    "# plt.text(0.5, 0.05, f'Top Validation Accuracy: {top_val_acc:.2f}%', transform=plt.gca().transAxes, fontsize=12, verticalalignment='top', horizontalalignment='center', color='red')\n",
    "\n",
    "# plt.xlabel('Iterations')\n",
    "# plt.ylabel('Accuracy [%]')\n",
    "\n",
    "# # 그래프 제목에 하이퍼파라미터 정보 추가\n",
    "# title = f'Training and Validation Accuracy over Iterations\\n\\nData: {which_data}, BPTT: {\"On\" if BPTT_on else \"Off\"}, Current Epoch: {current_epoch}, Surrogate: {surrogate},\\nCFG: {cfg}, tdBN: {\"On\" if tdBN_on else \"Off\"}, BN: {\"On\" if BN_on else \"Off\"}'\n",
    "\n",
    "# plt.title(title)\n",
    "\n",
    "# plt.legend(loc='lower right')\n",
    "# plt.xlim(0)  # x축을 0부터 시작\n",
    "# plt.grid(True)\n",
    "# plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nfs",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
