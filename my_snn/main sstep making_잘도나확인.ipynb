{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copyright (c) 2024 Byeonghyeon Kim \n",
    "# github site: https://github.com/bhkim003/ByeonghyeonKim\n",
    "# email: bhkim003@snu.ac.kr\n",
    " \n",
    "# Permission is hereby granted, free of charge, to any person obtaining a copy of\n",
    "# this software and associated documentation files (the \"Software\"), to deal in\n",
    "# the Software without restriction, including without limitation the rights to\n",
    "# use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of\n",
    "# the Software, and to permit persons to whom the Software is furnished to do so,\n",
    "# subject to the following conditions:\n",
    " \n",
    "# The above copyright notice and this permission notice shall be included in all\n",
    "# copies or substantial portions of the Software.\n",
    " \n",
    "# THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\n",
    "# IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS\n",
    "# FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR\n",
    "# COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER\n",
    "# IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN\n",
    "# CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_35668/2809884579.py:45: DeprecationWarning: The module snntorch.spikevision is deprecated. For loading neuromorphic datasets, we recommend using the Tonic project: https://github.com/neuromorphs/tonic\n",
      "  from snntorch.spikevision import spikedata\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.optim as optim\n",
    "import torch.optim.lr_scheduler as lr_scheduler\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "import torchvision\n",
    "import torchvision.datasets\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import time\n",
    "\n",
    "from snntorch import spikegen\n",
    "import matplotlib.pyplot as plt\n",
    "import snntorch.spikeplot as splt\n",
    "from IPython.display import HTML\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "from apex.parallel import DistributedDataParallel as DDP\n",
    "\n",
    "import random\n",
    "import datetime\n",
    "\n",
    "import json\n",
    "\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "''' 레퍼런스\n",
    "https://spikingjelly.readthedocs.io/zh-cn/0.0.0.0.4/spikingjelly.datasets.html#module-spikingjelly.datasets\n",
    "https://github.com/GorkaAbad/Sneaky-Spikes/blob/main/datasets.py\n",
    "https://github.com/GorkaAbad/Sneaky-Spikes/blob/main/how_to.md\n",
    "https://github.com/nmi-lab/torchneuromorphic\n",
    "https://snntorch.readthedocs.io/en/latest/snntorch.spikevision.spikedata.html#shd\n",
    "'''\n",
    "\n",
    "import snntorch\n",
    "from snntorch.spikevision import spikedata\n",
    "\n",
    "from spikingjelly.datasets.dvs128_gesture import DVS128Gesture\n",
    "from spikingjelly.datasets.cifar10_dvs import CIFAR10DVS\n",
    "from spikingjelly.datasets.n_mnist import NMNIST\n",
    "# from spikingjelly.datasets.es_imagenet import ESImageNet\n",
    "from spikingjelly.datasets import split_to_train_test_set\n",
    "from spikingjelly.datasets.n_caltech101 import NCaltech101\n",
    "from spikingjelly.datasets import pad_sequence_collate, padded_sequence_mask\n",
    "\n",
    "import torchneuromorphic\n",
    "\n",
    "import wandb\n",
    "\n",
    "from torchviz import make_dot\n",
    "import graphviz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x600 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# my module import\n",
    "from modules import *\n",
    "\n",
    "# modules 폴더에 새모듈.py 만들면\n",
    "# modules/__init__py 파일에 form .새모듈 import * 하셈\n",
    "# 그리고 새모듈.py에서 from modules.새모듈 import * 하셈\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    " # dvs 데이터 시각화 코드\n",
    " ##############################################################################################\n",
    "            # mapping = {\n",
    "            #     0: 'Hand Clapping',\n",
    "            #     1: 'Right Hand Wave',\n",
    "            #     2: 'Left Hand Wave',\n",
    "            #     3: 'Right Arm CW',\n",
    "            #     4: 'Right Arm CCW',\n",
    "            #     5: 'Left Arm CW',\n",
    "            #     6: 'Left Arm CCW',\n",
    "            #     7: 'Arm Roll',\n",
    "            #     8: 'Air Drums',\n",
    "            #     9: 'Air Guitar',\n",
    "            #     10: 'Other'\n",
    "            # }\n",
    "def dvs_visualization(inputs, labels, TIME, BATCH):\n",
    "            \n",
    "    what_input = random.randint(0, BATCH - 1)\n",
    "    inputs_for_view = inputs.permute(1, 0, 2, 3, 4)\n",
    "    for i in range(TIME):\n",
    "        # 예시 데이터 생성\n",
    "        data1 = inputs_for_view[what_input][i][0].numpy()  # torch tensor를 numpy 배열로 변환\n",
    "        data2 = inputs_for_view[what_input][i][1].numpy()  # torch tensor를 numpy 배열로 변환\n",
    "\n",
    "        # 데이터 플로팅\n",
    "        fig, axs = plt.subplots(1, 2, figsize=(12, 6))  # 1행 2열의 subplot 생성\n",
    "\n",
    "        # 첫 번째 subplot에 데이터1 플로팅\n",
    "        im1 = axs[0].imshow(data1, cmap='viridis', interpolation='nearest')\n",
    "        axs[0].set_title(f'Channel 0\\nLabel: {labels[what_input]}  Time: {i}')  # 라벨값 맵핑하여 제목에 추가\n",
    "        axs[0].set_xlabel('X axis')\n",
    "        axs[0].set_ylabel('Y axis')\n",
    "        axs[0].grid(False)\n",
    "        fig.colorbar(im1, ax=axs[0])  # Color bar 추가\n",
    "\n",
    "        # 두 번째 subplot에 데이터2 플로팅\n",
    "        im2 = axs[1].imshow(data2, cmap='viridis', interpolation='nearest')\n",
    "        axs[1].set_title(f'Channel 1\\nLabel: {labels[what_input]}  Time: {i}')  # 라벨값 맵핑하여 제목에 추가\n",
    "        axs[1].set_xlabel('X axis')\n",
    "        axs[1].set_ylabel('Y axis')\n",
    "        axs[1].grid(False)\n",
    "        fig.colorbar(im2, ax=axs[1])  # Color bar 추가\n",
    "\n",
    "        plt.tight_layout()  # subplot 간 간격 조정\n",
    "        plt.show()\n",
    "    sys.exit(\"종료\")\n",
    "\n",
    "######################################################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_snn_system(devices = \"0,1,2,3\",\n",
    "                    single_step = False, # True # False\n",
    "                    unique_name = 'main',\n",
    "                    my_seed = 42,\n",
    "                    TIME = 10,\n",
    "                    BATCH = 256,\n",
    "                    IMAGE_SIZE = 32,\n",
    "                    which_data = 'CIFAR10',\n",
    "                    # CLASS_NUM = 10,\n",
    "                    data_path = '/data2',\n",
    "                    rate_coding = True,\n",
    "    \n",
    "                    lif_layer_v_init = 0.0,\n",
    "                    lif_layer_v_decay = 0.6,\n",
    "                    lif_layer_v_threshold = 1.2,\n",
    "                    lif_layer_v_reset = 0.0,\n",
    "                    lif_layer_sg_width = 1,\n",
    "\n",
    "                    # synapse_conv_in_channels = IMAGE_PIXEL_CHANNEL,\n",
    "                    synapse_conv_kernel_size = 3,\n",
    "                    synapse_conv_stride = 1,\n",
    "                    synapse_conv_padding = 1,\n",
    "                    synapse_conv_trace_const1 = 1,\n",
    "                    synapse_conv_trace_const2 = 0.6,\n",
    "\n",
    "                    # synapse_fc_out_features = CLASS_NUM,\n",
    "                    synapse_fc_trace_const1 = 1,\n",
    "                    synapse_fc_trace_const2 = 0.6,\n",
    "\n",
    "                    pre_trained = False,\n",
    "                    convTrue_fcFalse = True,\n",
    "                    cfg = [64, 64],\n",
    "                    net_print = False, # True # False\n",
    "                    weight_count_print = False, # True # False\n",
    "                    pre_trained_path = \"net_save/save_now_net.pth\",\n",
    "                    learning_rate = 0.0001,\n",
    "                    epoch_num = 200,\n",
    "                    verbose_interval = 100, #숫자 크게 하면 꺼짐\n",
    "                    validation_interval = 10, #숫자 크게 하면 꺼짐\n",
    "                    tdBN_on = False,\n",
    "                    BN_on = False,\n",
    "\n",
    "                    surrogate = 'sigmoid',\n",
    "\n",
    "                    gradient_verbose = False,\n",
    "\n",
    "                    BPTT_on = False,\n",
    "\n",
    "                    optimizer_what = 'SGD', # 'SGD' 'Adam', 'RMSprop'\n",
    "                    scheduler_name = 'no',\n",
    "                    \n",
    "                    ddp_on = True,\n",
    "\n",
    "                    nda_net = False,\n",
    "                    \n",
    "                    domain_il_epoch = 0, # over 0, then domain il mode on\n",
    "\n",
    "                    dvs_clipping = True, \n",
    "                    dvs_duration = 1000000,\n",
    "\n",
    "                    OTTT_sWS_on = True, # True # False\n",
    "                  ):\n",
    "    if OTTT_sWS_on == True:\n",
    "        assert BPTT_on == False and tdBN_on == False and convTrue_fcFalse == True\n",
    "    if single_step == True:\n",
    "        assert BPTT_on == False and tdBN_on == False\n",
    "\n",
    "    ## 함수 내 모든 로컬 변수 저장 ########################################################\n",
    "    hyperparameters = locals()\n",
    "    hyperparameters['current epoch'] = 0\n",
    "    ######################################################################################\n",
    "    \n",
    "    \n",
    "    ## wandb 세팅 ###################################################################\n",
    "    current_time = datetime.datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "    wandb.config.update(hyperparameters)\n",
    "    wandb.run.name = f'lr_{learning_rate}_{unique_name}_{which_data}_tstep{TIME}'\n",
    "    wandb.define_metric(\"summary_val_acc\", summary=\"max\")\n",
    "    ###################################################################################\n",
    "\n",
    "\n",
    "\n",
    "    ## gpu setting ##################################################################################################################\n",
    "    os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\" \n",
    "    os.environ[\"CUDA_VISIBLE_DEVICES\"]= devices\n",
    "    ###################################################################################################################################\n",
    "\n",
    "\n",
    "    ## seed setting ##################################################################################################################\n",
    "    torch.manual_seed(my_seed)\n",
    "    ###################################################################################################################################\n",
    "\n",
    "\n",
    "    ## data_loader 가져오기 ##################################################################################################################\n",
    "    # data loader, pixel channel, class num\n",
    "    train_loader, test_loader, synapse_conv_in_channels, CLASS_NUM = data_loader(\n",
    "            which_data,\n",
    "            data_path, \n",
    "            rate_coding, \n",
    "            BATCH, \n",
    "            IMAGE_SIZE,\n",
    "            ddp_on,\n",
    "            TIME,\n",
    "            dvs_clipping,\n",
    "            dvs_duration)\n",
    "    synapse_fc_out_features = CLASS_NUM\n",
    "    ###########################################################################################################################################\n",
    "\n",
    "    \n",
    "    ## parameter number calculator (안 중요함) ##################################################################################################################\n",
    "    params_num = 0\n",
    "    img_size = IMAGE_SIZE \n",
    "    bias_param = 1 # 1 or 0\n",
    "    classifier_making = False\n",
    "    if (convTrue_fcFalse == True):\n",
    "        past_kernel = synapse_conv_in_channels\n",
    "        for kernel in cfg:\n",
    "            if (classifier_making == False):\n",
    "                if (type(kernel) == list):\n",
    "                    for residual_kernel in kernel:\n",
    "                        if (residual_kernel >= 10000 and residual_kernel < 20000): # separable\n",
    "                            residual_kernel -= 10000\n",
    "                            params_num += (synapse_conv_kernel_size**2 + bias_param) * past_kernel\n",
    "                            params_num += (1**2 * past_kernel + bias_param) * residual_kernel\n",
    "                            past_kernel = residual_kernel  \n",
    "                        elif (residual_kernel >= 20000 and residual_kernel < 30000): # depthwise\n",
    "                            residual_kernel -= 20000\n",
    "                            # 'past_kernel' should be same with 'kernel'\n",
    "                            params_num += (synapse_conv_kernel_size**2 + bias_param) * past_kernel\n",
    "                            past_kernel = residual_kernel  \n",
    "                        else:\n",
    "                            params_num += residual_kernel * ((synapse_conv_kernel_size**2) * past_kernel + bias_param)\n",
    "                            past_kernel = residual_kernel\n",
    "                elif (kernel == 'P' or kernel == 'M'):\n",
    "                    img_size = img_size // 2\n",
    "                elif (kernel == 'D'):\n",
    "                    img_size = 1\n",
    "                elif (kernel == 'L'):\n",
    "                    classifier_making = True\n",
    "                    past_kernel = past_kernel * (img_size**2)\n",
    "                else:\n",
    "                    if (kernel >= 10000 and kernel < 20000): # separable\n",
    "                        kernel -= 10000\n",
    "                        params_num += (synapse_conv_kernel_size**2 + bias_param) * past_kernel\n",
    "                        params_num += (1**2 * past_kernel + bias_param) * kernel\n",
    "                        past_kernel = kernel  \n",
    "                    elif (kernel >= 20000 and kernel < 30000): # depthwise\n",
    "                        kernel -= 20000\n",
    "                        # 'past_kernel' should be same with 'kernel'\n",
    "                        params_num += (synapse_conv_kernel_size**2 + bias_param) * past_kernel\n",
    "                        past_kernel = kernel  \n",
    "                    else:\n",
    "                        params_num += kernel * (synapse_conv_kernel_size**2 * past_kernel + bias_param)\n",
    "                        past_kernel = kernel    \n",
    "            else: # classifier making\n",
    "                params_num += (past_kernel + bias_param) * kernel\n",
    "                past_kernel = kernel\n",
    "        \n",
    "        \n",
    "        if classifier_making == False:\n",
    "            past_kernel = past_kernel*img_size*img_size\n",
    "\n",
    "        params_num += (past_kernel + bias_param) * synapse_fc_out_features\n",
    "    else:\n",
    "        past_in_channel = synapse_conv_in_channels*img_size*img_size\n",
    "        for in_channel in cfg:\n",
    "            if (type(in_channel) == list):\n",
    "                for residual_in_channel in in_channel:\n",
    "                    params_num += (past_in_channel + bias_param) * residual_in_channel\n",
    "                    past_in_channel = residual_in_channel\n",
    "            # elif (in_channel == 'M'): #it's a holy FC layer!\n",
    "            #     img_size = img_size // 2\n",
    "            else:\n",
    "                print('past_in_channel', past_in_channel)\n",
    "                print('bias_param', bias_param)\n",
    "                print('in_channel', in_channel)\n",
    "                params_num += (past_in_channel + bias_param) * in_channel\n",
    "                past_in_channel = in_channel\n",
    "        params_num += (past_in_channel + bias_param) * synapse_fc_out_features\n",
    "    ###########################################################################################################################################\n",
    "\n",
    "\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "    ### network setting #######################################################################################################################\n",
    "    if pre_trained == False:\n",
    "        if (convTrue_fcFalse == False):\n",
    "            if (single_step == False):\n",
    "                net = MY_SNN_FC(cfg, synapse_conv_in_channels, IMAGE_SIZE, synapse_fc_out_features,\n",
    "                            synapse_fc_trace_const1, synapse_fc_trace_const2, \n",
    "                            lif_layer_v_init, lif_layer_v_decay, \n",
    "                            lif_layer_v_threshold, lif_layer_v_reset,\n",
    "                            lif_layer_sg_width,\n",
    "                            tdBN_on,\n",
    "                            BN_on, TIME,\n",
    "                            surrogate,\n",
    "                            BPTT_on).to(device)\n",
    "        else:\n",
    "            if (single_step == False):\n",
    "                net = MY_SNN_CONV(cfg, synapse_conv_in_channels, IMAGE_SIZE,\n",
    "                            synapse_conv_kernel_size, synapse_conv_stride, \n",
    "                            synapse_conv_padding, synapse_conv_trace_const1, \n",
    "                            synapse_conv_trace_const2, \n",
    "                            lif_layer_v_init, lif_layer_v_decay, \n",
    "                            lif_layer_v_threshold, lif_layer_v_reset,\n",
    "                            lif_layer_sg_width,\n",
    "                            synapse_fc_out_features, synapse_fc_trace_const1, synapse_fc_trace_const2,\n",
    "                            tdBN_on,\n",
    "                            BN_on, TIME,\n",
    "                            surrogate,\n",
    "                            BPTT_on,\n",
    "                            OTTT_sWS_on).to(device)\n",
    "            else:\n",
    "                net = MY_SNN_CONV_ottt_sstep(cfg, synapse_conv_in_channels, IMAGE_SIZE,\n",
    "                            synapse_conv_kernel_size, synapse_conv_stride, \n",
    "                            synapse_conv_padding, synapse_conv_trace_const1, \n",
    "                            synapse_conv_trace_const2, \n",
    "                            lif_layer_v_init, lif_layer_v_decay, \n",
    "                            lif_layer_v_threshold, lif_layer_v_reset,\n",
    "                            lif_layer_sg_width,\n",
    "                            synapse_fc_out_features, synapse_fc_trace_const1, synapse_fc_trace_const2,\n",
    "                            tdBN_on,\n",
    "                            BN_on, TIME,\n",
    "                            surrogate,\n",
    "                            BPTT_on,\n",
    "                            OTTT_sWS_on).to(device)\n",
    "        if (nda_net == True):\n",
    "            net = VGG(cfg = cfg, num_classes=10, batch_norm = tdBN_on, in_c = synapse_conv_in_channels, \n",
    "                      lif_layer_v_threshold=lif_layer_v_threshold, lif_layer_v_decay=lif_layer_v_decay, lif_layer_sg_width=lif_layer_sg_width)\n",
    "            net.T = TIME\n",
    "        net = torch.nn.DataParallel(net) #나중에풀어줘\n",
    "    else:\n",
    "        net = torch.load(pre_trained_path)\n",
    "\n",
    "    net = net.to(device)\n",
    "    if (net_print == True):\n",
    "        print(net)        \n",
    "    ####################################################################################################################################\n",
    "    \n",
    "\n",
    "    ## wandb logging ###########################################\n",
    "    wandb.watch(net, log=\"all\", log_freq = 10) #gradient, parameter logging해줌\n",
    "    ############################################################\n",
    "\n",
    "    ## param num and memory estimation except BN with MY own calculation some lines above ##########################################\n",
    "    real_param_num = sum(p.numel() for p in net.parameters() if p.requires_grad)\n",
    "    if (weight_count_print == True):\n",
    "        for name, param in net.named_parameters():\n",
    "            if param.requires_grad:\n",
    "                print(f'Layer: {name} | Number of parameters: {param.numel()}')\n",
    "    # Batch norm 있으면 아래 두 개 서로 다를 수 있음.\n",
    "    # assert real_param_num == params_num, f'parameter number is not same. real_param_num: {real_param_num}, params_num: {params_num}'    \n",
    "    print('='*50)\n",
    "    print(f\"My Num of PARAMS: {params_num:,}, system's param_num : {real_param_num:,}\")\n",
    "    memory = params_num / 8 / 1024 / 1024 # MB\n",
    "    precision = 32\n",
    "    memory = memory * precision \n",
    "    print(f\"Memory: {memory:.2f}MiB at {precision}-bit\")\n",
    "    print('='*50)\n",
    "    ##############################################################################################################################\n",
    "\n",
    "\n",
    "\n",
    "    ## criterion ########################################## # loss 구해주는 친구\n",
    "    criterion = nn.CrossEntropyLoss().to(device)\n",
    "    if (OTTT_sWS_on == True):\n",
    "        # criterion = nn.CrossEntropyLoss().to(device)\n",
    "        criterion = lambda y_t, target_t: ((1 - 0.05) * F.cross_entropy(y_t, target_t) + 0.05 * F.mse_loss(y_t, F.one_hot(target_t, CLASS_NUM).float())) / TIME \n",
    "    ####################################################\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "    ## optimizer, scheduler ########################################################################\n",
    "    if(optimizer_what == 'SGD'):\n",
    "        # optimizer = optim.SGD(net.parameters(), lr=learning_rate, momentum=0.9)\n",
    "        optimizer = optim.SGD(net.parameters(), lr=learning_rate, momentum=0.9, weight_decay=0)\n",
    "    elif(optimizer_what == 'Adam'):\n",
    "        # optimizer = torch.optim.Adam(net.parameters(), lr=0.00001)\n",
    "        optimizer = torch.optim.Adam(net.parameters(), lr=learning_rate/256 * BATCH, weight_decay=1e-4)\n",
    "        # optimizer = optim.Adam(net.parameters(), lr=learning_rate, weight_decay=0, betas=(0.9, 0.999))\n",
    "    elif(optimizer_what == 'RMSprop'):\n",
    "        pass\n",
    "\n",
    "\n",
    "    if (scheduler_name == 'StepLR'):\n",
    "        scheduler = lr_scheduler.StepLR(optimizer, step_size=10, gamma=0.1)\n",
    "    elif (scheduler_name == 'ExponentialLR'):\n",
    "        scheduler = lr_scheduler.ExponentialLR(optimizer, gamma=0.95)\n",
    "    elif (scheduler_name == 'ReduceLROnPlateau'):\n",
    "        scheduler = lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.1, patience=10)\n",
    "    elif (scheduler_name == 'CosineAnnealingLR'):\n",
    "        # scheduler = lr_scheduler.CosineAnnealingLR(optimizer, eta_min=0, T_max=50)\n",
    "        scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, eta_min=0, T_max=epoch_num)\n",
    "    elif (scheduler_name == 'OneCycleLR'):\n",
    "        scheduler = lr_scheduler.OneCycleLR(optimizer, max_lr=0.1, steps_per_epoch=len(train_loader), epochs=100)\n",
    "    else:\n",
    "        pass # 'no' scheduler\n",
    "    ## optimizer, scheduler ########################################################################\n",
    "\n",
    "\n",
    "    tr_acc = 0\n",
    "    tr_correct = 0\n",
    "    tr_total = 0\n",
    "    val_acc = 0\n",
    "    val_acc_now = 0\n",
    "    elapsed_time_val = 0\n",
    "    iter_acc_array = np.array([])\n",
    "    tr_acc_array = np.array([])\n",
    "    val_acc_now_array = np.array([])\n",
    "    #======== EPOCH START ==========================================================================================\n",
    "    for epoch in range(epoch_num):\n",
    "        print('EPOCH', epoch)\n",
    "        epoch_start_time = time.time()\n",
    "\n",
    "        # if (domain_il_epoch>0 and which_data == 'PMNIST'):\n",
    "        #     k = epoch // domain_il_epoch\n",
    "        #     xtrain=data[k]['train']['x']\n",
    "        #     ytrain=data[k]['train']['y']\n",
    "        #     xtest =data[k]['test']['x']\n",
    "        #     ytest =data[k]['test']['y']\n",
    "\n",
    "        \n",
    "        ####### iterator : input_loading & tqdm을 통한 progress_bar 생성###################\n",
    "        iterator = enumerate(train_loader, 0)\n",
    "        if (ddp_on == True):\n",
    "            if torch.distributed.get_rank() == 0:   \n",
    "                iterator = tqdm(iterator, total=len(train_loader), desc='train', dynamic_ncols=True, position=0, leave=True)\n",
    "        else:\n",
    "            iterator = tqdm(iterator, total=len(train_loader), desc='train', dynamic_ncols=True, position=0, leave=True)\n",
    "        ##################################################################################   \n",
    "        \n",
    "        #### validation_interval이 batch size보다 작을 시 validation_interval을 batch size로 맞춰줌#############\n",
    "        validation_interval2 = validation_interval\n",
    "        if (validation_interval > len(iterator)):\n",
    "            validation_interval2 = len(iterator)\n",
    "        ##################################################################################################\n",
    "\n",
    "\n",
    "\n",
    "        ###### ITERATION START ##########################################################################################################\n",
    "        for i, data in iterator:\n",
    "            iter_one_train_time_start = time.time()\n",
    "            net.train() # train 모드로 바꿔줘야함\n",
    "\n",
    "            ### data loading & semi-pre-processing ################################################################################\n",
    "            if len(data) == 2:\n",
    "                inputs, labels = data\n",
    "                # 처리 로직 작성\n",
    "            elif len(data) == 3:\n",
    "                inputs, labels, x_len = data\n",
    "                # print('x_len',x_len)\n",
    "                # mask = padded_sequence_mask(x_len)\n",
    "                # max_time_step = x_len.max()\n",
    "                # min_time_step = x_len.min()\n",
    "            # print('inputs',inputs.size(),'\\nlabels',labels.size())\n",
    "                    \n",
    "            if (which_data == 'n_tidigits'):\n",
    "                inputs = inputs.permute(0, 1, 3, 2, 4)\n",
    "                labels = labels[:, 0, :]\n",
    "                labels = torch.argmax(labels, dim=1)\n",
    "            elif (which_data == 'heidelberg'):\n",
    "                inputs = inputs.view(5, 1000, 1, 700, 1)\n",
    "                print(\"\\n\\n\\n경고!!!! heidelberg 이거 타임스텝이랑 채널 잘 바꿔줘라!!!\\n\\n\\n\\n\")\n",
    "            # print('inputs',inputs.size(),'\\nlabels',labels.size())\n",
    "            # print(labels)\n",
    "                \n",
    "            if (which_data == 'DVS_CIFAR10' or which_data == 'DVS_GESTURE' or which_data == 'DVS_CIFAR10_2' or which_data == 'NMNIST' or which_data == 'N_CALTECH101' or which_data == 'n_tidigits' or which_data == 'heidelberg'):\n",
    "                inputs = inputs.permute(1, 0, 2, 3, 4)\n",
    "            elif rate_coding == True :\n",
    "                inputs = spikegen.rate(inputs, num_steps=TIME)\n",
    "            else :\n",
    "                inputs = inputs.repeat(TIME, 1, 1, 1, 1)\n",
    "            # inputs: [Time, Batch, Channel, Height, Width]  \n",
    "            ####################################################################################################################### \n",
    "                \n",
    "\n",
    "                \n",
    "            # # dvs 데이터 시각화 코드 (확인 필요할 시 써라)\n",
    "            # ##############################################################################################\n",
    "            # dvs_visualization(inputs, labels, TIME, BATCH)\n",
    "            # ######################################################################################################\n",
    "\n",
    "\n",
    "            ## device로 보내주기 ######################################\n",
    "            real_batch = labels.size(0)\n",
    "            ###########################################################\n",
    "\n",
    "\n",
    "            ## gradient 초기화 #######################################\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            ###########################################################\n",
    "\n",
    "\n",
    "            if single_step == False:\n",
    "                # net에 넣어줄때는 batch가 젤 앞 차원으로 와야함. # dataparallel때매##############################\n",
    "                # inputs: [Time, Batch, Channel, Height, Width]   \n",
    "                inputs = inputs.permute(1, 0, 2, 3, 4) # net에 넣어줄때는 batch가 젤 앞 차원으로 와야함. # dataparallel때매\n",
    "                # inputs: [Batch, Time, Channel, Height, Width] \n",
    "                #################################################################################################\n",
    "            else:\n",
    "                labels = labels.repeat(TIME, 1)\n",
    "\n",
    "            \n",
    "\n",
    "            if single_step == False:\n",
    "                ### input --> net --> output #####################################################\n",
    "                outputs = net(inputs)\n",
    "                ##################################################################################\n",
    "                ## loss, backward ##########################################\n",
    "                loss = criterion(outputs, labels)\n",
    "                loss.backward()\n",
    "                ############################################################\n",
    "                ## weight 업데이트!! ##################################\n",
    "                optimizer.step()\n",
    "                ################################################################\n",
    "            else:\n",
    "                outputs_all = []\n",
    "                loss = 0.0\n",
    "                for t in range(TIME):\n",
    "                    outputs_one_time = net(inputs[t])\n",
    "                    one_time_loss = criterion(outputs_one_time, labels[t].contiguous())\n",
    "                    one_time_loss.backward() # one_time backward\n",
    "                    loss += one_time_loss.data\n",
    "                    outputs_all.append(outputs_one_time.detach())\n",
    "                optimizer.step() # full step time update\n",
    "                outputs_all = torch.stack(outputs_all, dim=1)\n",
    "                outputs = outputs_all.mean(1) # ottt꺼 쓸때\n",
    "                labels = labels[0]\n",
    "                \n",
    "\n",
    "            ## net 그림 출력해보기 #################################################################\n",
    "            # print('시각화')\n",
    "            # make_dot(outputs, params=dict(list(net.named_parameters()))).render(\"net_torchviz\", format=\"png\")\n",
    "            # return 0\n",
    "            ##################################################################################\n",
    "\n",
    "            #### batch 어긋남 방지 ###############################################\n",
    "            assert real_batch == outputs.size(0), f'batch size is not same. real_batch: {real_batch}, outputs.size(0): {outputs.size(0)}'\n",
    "            #######################################################################\n",
    "            \n",
    "\n",
    "            ####### training accruacy save for print ###############################\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total = real_batch\n",
    "            correct = (predicted == labels).sum().item()\n",
    "            iter_acc = correct / total\n",
    "            tr_total += total\n",
    "            tr_correct += correct\n",
    "            if i % verbose_interval == verbose_interval-1:\n",
    "                print(f'{epoch}-{i} training acc: {100 * iter_acc:.2f}%, lr={[f\"{lr}\" for lr in (param_group[\"lr\"] for param_group in optimizer.param_groups)]}, val_acc: {100 * val_acc_now:.2f}%')\n",
    "            iter_acc_string = f'{epoch}-{i}/{len(train_loader)} iter_acc: {100 * iter_acc:.2f}%, lr={[f\"{lr}\" for lr in (param_group[\"lr\"] for param_group in optimizer.param_groups)]}'\n",
    "            ################################################################\n",
    "            \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "            iter_one_train_time_end = time.time()\n",
    "            elapsed_time = iter_one_train_time_end - iter_one_train_time_start  # 실행 시간 계산\n",
    "\n",
    "            if (i % verbose_interval == verbose_interval-1):\n",
    "                print(f\"iter_one_train_time: {elapsed_time} seconds, last one_val_time: {elapsed_time_val} seconds\\n\")\n",
    "\n",
    "            ##### validation ##################################################################################################################################\n",
    "            if i % validation_interval2 == validation_interval2-1:\n",
    "                iter_one_val_time_start = time.time()\n",
    "                tr_acc = tr_correct/tr_total\n",
    "                tr_correct = 0\n",
    "                tr_total = 0\n",
    "                correct = 0\n",
    "                total = 0\n",
    "                with torch.no_grad():\n",
    "                    net.eval() # eval 모드로 바꿔줘야함 \n",
    "                    for data in test_loader:\n",
    "                        ## data loading & semi-pre-processing ##########################################################\n",
    "                        if len(data) == 2:\n",
    "                            inputs, labels = data\n",
    "                            # 처리 로직 작성\n",
    "                        elif len(data) == 3:\n",
    "                            inputs, labels, x_len = data\n",
    "                            # print('x_len',x_len)\n",
    "                            # mask = padded_sequence_mask(x_len)\n",
    "                            # max_time_step = x_len.max()\n",
    "                            # min_time_step = x_len.min()\n",
    "                            # B, T, *spatial_dims = inputs.shape\n",
    "\n",
    "                        if (which_data == 'DVS_CIFAR10' or which_data == 'DVS_GESTURE' or which_data == 'DVS_CIFAR10_2' or which_data == 'NMNIST' or which_data == 'N_CALTECH101' or which_data == 'n_tidigits' or which_data == 'heidelberg'):\n",
    "                            inputs = inputs.permute(1, 0, 2, 3, 4)\n",
    "                        elif rate_coding == True :\n",
    "                            inputs = spikegen.rate(inputs, num_steps=TIME)\n",
    "                        else :\n",
    "                            inputs = inputs.repeat(TIME, 1, 1, 1, 1)\n",
    "                        # inputs: [Time, Batch, Channel, Height, Width]  \n",
    "                        ###################################################################################################\n",
    "\n",
    "                        inputs = inputs.to(device)\n",
    "                        labels = labels.to(device)\n",
    "                        real_batch = labels.size(0)\n",
    "\n",
    "                        if single_step == False:\n",
    "                            outputs = net(inputs.permute(1, 0, 2, 3, 4)) #inputs: [Batch, Time, Channel, Height, Width]  \n",
    "                            val_loss = criterion(outputs, labels)\n",
    "                        else:\n",
    "                            val_loss=0\n",
    "                            outputs_all = []\n",
    "                            for t in range(TIME):\n",
    "                                outputs = net(inputs[t])\n",
    "                                loss = criterion(outputs, labels)\n",
    "                                outputs_all.append(outputs.detach())\n",
    "                                val_loss += loss.data\n",
    "                            outputs_all = torch.stack(outputs_all, dim=1)\n",
    "                            outputs = outputs_all.mean(1)\n",
    "\n",
    "\n",
    "                        _, predicted = torch.max(outputs.data, 1)\n",
    "                        total += real_batch\n",
    "                        assert real_batch == outputs.size(0), f'batch size is not same. real_batch: {real_batch}, outputs.size(0): {outputs.size(0)}'\n",
    "                        correct += (predicted == labels).sum().item()\n",
    "\n",
    "                    val_acc_now = correct / total\n",
    "                    # print(f'{epoch}-{i} validation acc: {100 * val_acc_now:.2f}%, lr={[f\"{lr:.10f}\" for lr in (param_group[\"lr\"] for param_group in optimizer.param_groups)]}')\n",
    "\n",
    "                iter_one_val_time_end = time.time()\n",
    "                elapsed_time_val = iter_one_val_time_end - iter_one_val_time_start  # 실행 시간 계산\n",
    "                # print(f\"iter_one_val_time: {elapsed_time_val} seconds\")\n",
    "\n",
    "                # network save\n",
    "                if val_acc < val_acc_now:\n",
    "                    val_acc = val_acc_now\n",
    "                    # torch.save(net.state_dict(), f\"net_save/save_now_net_weights_{unique_name}.pth\")\n",
    "                    # torch.save(net, f\"net_save/save_now_net_{unique_name}.pth\")\n",
    "                    # torch.save(net.module.state_dict(), f\"net_save/save_now_net_weights2_{unique_name}.pth\")\n",
    "                    # torch.save(net.module, f\"net_save/save_now_net2_{unique_name}.pth\")\n",
    "            ####################################################################################################################################################\n",
    "            iterator.set_description(f\"iter_acc: {iter_acc_string}, iter_loss: {loss}, val_acc: {100 * val_acc_now:.2f}%\")  \n",
    "            wandb.log({\"iter_acc\": iter_acc}, step=i+epoch*len(train_loader))\n",
    "            wandb.log({\"tr_acc\": tr_acc}, step=i+epoch*len(train_loader))\n",
    "            wandb.log({\"val_acc_now\": val_acc_now}, step=i+epoch*len(train_loader))\n",
    "            wandb.log({\"summary_val_acc\": val_acc_now})\n",
    "            iter_acc_array = np.append(iter_acc_array, iter_acc)\n",
    "            tr_acc_array = np.append(tr_acc_array, tr_acc)\n",
    "            val_acc_now_array = np.append(val_acc_now_array, val_acc_now)\n",
    "            base_name = f'{current_time}'\n",
    "            iter_acc_file_name_time = f'result_save/{base_name}_iter_acc_array_{unique_name}.npy'\n",
    "            tr_acc_file_name_time = f'result_save/{base_name}_tr_acc_array_{unique_name}.npy'\n",
    "            val_acc_file_name_time = f'result_save/{base_name}_val_acc_now_array_{unique_name}.npy'\n",
    "            hyperparameters_file_name_time = f'result_save/{base_name}_hyperparameters_{unique_name}.json'\n",
    "\n",
    "            hyperparameters['current epoch'] = epoch\n",
    "\n",
    "            ### 모듈 세이브: 덮어쓰기 하기 싫으면 주석 풀어서 사용 (시간마다 새로 쓰기) 비추천 ########################\n",
    "            # np.save(iter_acc_file_name_time, iter_acc_array)\n",
    "            # np.save(tr_acc_file_name_time, iter_acc_array)\n",
    "            # np.save(val_acc_file_name_time, val_acc_now_array)\n",
    "            # with open(hyperparameters_file_name_time, 'w') as f:\n",
    "            #     json.dump(hyperparameters, f, indent=4)\n",
    "            #########################################################################################################\n",
    "\n",
    "            ## 모듈 세이브 ###########################################################################################\n",
    "            # np.save(f'result_save/iter_acc_array_{unique_name}.npy', iter_acc_array)\n",
    "            # np.save(f'result_save/tr_acc_array_{unique_name}.npy', tr_acc_array)\n",
    "            # np.save(f'result_save/val_acc_now_array_{unique_name}.npy', val_acc_now_array)\n",
    "            # with open(f'result_save/hyperparameters_{unique_name}.json', 'w') as f:\n",
    "            #     json.dump(hyperparameters, f, indent=4)\n",
    "            ##########################################################################################################\n",
    "        ###### ITERATION END ##########################################################################################################\n",
    "                \n",
    "\n",
    "        ## scheduler update #############################################################################\n",
    "        if (scheduler_name != 'no'):\n",
    "            if (scheduler_name == 'ReduceLROnPlateau'):\n",
    "                scheduler.step(val_loss)\n",
    "            else:\n",
    "                scheduler.step()\n",
    "        #################################################################################################\n",
    "        \n",
    "        # 실행 시간 계산\n",
    "        epoch_time_end = time.time()\n",
    "        print(f\"epoch_time: {epoch_time_end - epoch_start_time} seconds\\n\") \n",
    "    #======== EPOCH END ==========================================================================================\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mbhkim003\u001b[0m (\u001b[33mbhkim003-seoul-national-university\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.17.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/nfs/home/bhkim003/github_folder/ByeonghyeonKim/my_snn/wandb/run-20240724_194247-2e4fimgb</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/2e4fimgb' target=\"_blank\">summer-frog-68</a></strong> to <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/2e4fimgb' target=\"_blank\">https://wandb.ai/bhkim003-seoul-national-university/my_snn%20main/runs/2e4fimgb</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "DataParallel(\n",
      "  (module): MY_SNN_CONV_ottt_sstep(\n",
      "    (layers): OTTTSequential(\n",
      "      (0): SYNAPSE_CONV_trace_sstep()\n",
      "      (1): LIF_layer_trace_sstep()\n",
      "      (2): Scale()\n",
      "      (3): SYNAPSE_CONV_trace_sstep()\n",
      "      (4): LIF_layer_trace_sstep()\n",
      "      (5): Scale()\n",
      "      (6): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
      "      (7): SYNAPSE_CONV_trace_sstep()\n",
      "      (8): LIF_layer_trace_sstep()\n",
      "      (9): Scale()\n",
      "      (10): SYNAPSE_CONV_trace_sstep()\n",
      "      (11): LIF_layer_trace_sstep()\n",
      "      (12): Scale()\n",
      "      (13): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
      "      (14): SYNAPSE_CONV_trace_sstep()\n",
      "      (15): LIF_layer_trace_sstep()\n",
      "      (16): Scale()\n",
      "      (17): SYNAPSE_CONV_trace_sstep()\n",
      "      (18): LIF_layer_trace_sstep()\n",
      "      (19): Scale()\n",
      "      (20): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
      "      (21): SYNAPSE_CONV_trace_sstep()\n",
      "      (22): LIF_layer_trace_sstep()\n",
      "      (23): Scale()\n",
      "      (24): SYNAPSE_CONV_trace_sstep()\n",
      "      (25): LIF_layer_trace_sstep()\n",
      "      (26): Scale()\n",
      "      (27): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "      (28): DimChanger_for_FC_sstep()\n",
      "      (29): SYNAPSE_FC_trace_sstep()\n",
      "    )\n",
      "  )\n",
      ")\n",
      "==================================================\n",
      "My Num of PARAMS: 9,225,610, system's param_num : 9,228,362\n",
      "Memory: 35.19MiB at 32-bit\n",
      "==================================================\n",
      "EPOCH 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "iter_acc: 0-0/391 iter_acc: 11.72%, lr=['0.1'], iter_loss: 2.1897177696228027, val_acc: 0.00%:   0%|          | 1/391 [00:01<07:40,  1.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1171875\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "iter_acc: 0-10/391 iter_acc: 12.50%, lr=['0.1'], iter_loss: 2.196640968322754, val_acc: 0.00%:   3%|▎         | 11/391 [00:05<02:30,  2.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "iter_acc: 0-20/391 iter_acc: 10.94%, lr=['0.1'], iter_loss: 2.1795616149902344, val_acc: 0.00%:   5%|▌         | 21/391 [00:08<02:17,  2.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.109375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "iter_acc: 0-30/391 iter_acc: 12.50%, lr=['0.1'], iter_loss: 2.1751058101654053, val_acc: 0.00%:   8%|▊         | 31/391 [00:12<02:26,  2.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "iter_acc: 0-40/391 iter_acc: 19.53%, lr=['0.1'], iter_loss: 2.0856008529663086, val_acc: 0.00%:  10%|█         | 41/391 [00:17<02:13,  2.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1953125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "iter_acc: 0-50/391 iter_acc: 21.09%, lr=['0.1'], iter_loss: 2.031451463699341, val_acc: 0.00%:  13%|█▎        | 51/391 [00:20<02:04,  2.73it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2109375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "iter_acc: 0-60/391 iter_acc: 23.44%, lr=['0.1'], iter_loss: 1.9072198867797852, val_acc: 0.00%:  16%|█▌        | 61/391 [00:24<02:06,  2.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.234375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "iter_acc: 0-70/391 iter_acc: 22.66%, lr=['0.1'], iter_loss: 1.971724271774292, val_acc: 0.00%:  18%|█▊        | 71/391 [00:29<02:13,  2.40it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2265625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "iter_acc: 0-80/391 iter_acc: 21.88%, lr=['0.1'], iter_loss: 1.937985897064209, val_acc: 0.00%:  21%|██        | 81/391 [00:33<01:55,  2.68it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.21875\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "iter_acc: 0-90/391 iter_acc: 24.22%, lr=['0.1'], iter_loss: 1.8941519260406494, val_acc: 0.00%:  23%|██▎       | 91/391 [00:36<01:51,  2.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2421875\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "iter_acc: 0-100/391 iter_acc: 28.91%, lr=['0.1'], iter_loss: 1.8601794242858887, val_acc: 0.00%:  26%|██▌       | 101/391 [00:40<01:50,  2.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2890625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "iter_acc: 0-110/391 iter_acc: 28.12%, lr=['0.1'], iter_loss: 1.8220648765563965, val_acc: 0.00%:  28%|██▊       | 111/391 [00:44<01:49,  2.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.28125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "iter_acc: 0-120/391 iter_acc: 32.81%, lr=['0.1'], iter_loss: 1.822894811630249, val_acc: 0.00%:  31%|███       | 121/391 [00:48<01:41,  2.67it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.328125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "iter_acc: 0-130/391 iter_acc: 25.00%, lr=['0.1'], iter_loss: 1.845144510269165, val_acc: 0.00%:  34%|███▎      | 131/391 [00:52<01:42,  2.53it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "iter_acc: 0-140/391 iter_acc: 26.56%, lr=['0.1'], iter_loss: 1.7695602178573608, val_acc: 0.00%:  36%|███▌      | 141/391 [00:56<01:37,  2.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.265625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "iter_acc: 0-150/391 iter_acc: 31.25%, lr=['0.1'], iter_loss: 1.723581314086914, val_acc: 0.00%:  39%|███▊      | 151/391 [01:00<01:28,  2.71it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "iter_acc: 0-160/391 iter_acc: 30.47%, lr=['0.1'], iter_loss: 1.6593009233474731, val_acc: 0.00%:  41%|████      | 161/391 [01:04<01:28,  2.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3046875\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "iter_acc: 0-170/391 iter_acc: 35.94%, lr=['0.1'], iter_loss: 1.7545313835144043, val_acc: 0.00%:  44%|████▎     | 171/391 [01:08<01:22,  2.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.359375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "iter_acc: 0-180/391 iter_acc: 36.72%, lr=['0.1'], iter_loss: 1.6405390501022339, val_acc: 0.00%:  46%|████▋     | 181/391 [01:11<01:17,  2.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3671875\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "iter_acc: 0-190/391 iter_acc: 36.72%, lr=['0.1'], iter_loss: 1.7015174627304077, val_acc: 0.00%:  49%|████▉     | 191/391 [01:15<01:14,  2.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3671875\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "iter_acc: 0-200/391 iter_acc: 44.53%, lr=['0.1'], iter_loss: 1.5349280834197998, val_acc: 0.00%:  51%|█████▏    | 201/391 [01:20<01:17,  2.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4453125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "iter_acc: 0-210/391 iter_acc: 42.19%, lr=['0.1'], iter_loss: 1.5948231220245361, val_acc: 0.00%:  54%|█████▍    | 211/391 [01:24<01:08,  2.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.421875\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "iter_acc: 0-220/391 iter_acc: 39.06%, lr=['0.1'], iter_loss: 1.6874350309371948, val_acc: 0.00%:  57%|█████▋    | 221/391 [01:28<01:02,  2.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.390625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "iter_acc: 0-230/391 iter_acc: 39.06%, lr=['0.1'], iter_loss: 1.6067249774932861, val_acc: 0.00%:  59%|█████▉    | 231/391 [01:32<01:14,  2.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.390625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "iter_acc: 0-240/391 iter_acc: 35.94%, lr=['0.1'], iter_loss: 1.7301197052001953, val_acc: 0.00%:  62%|██████▏   | 241/391 [01:36<00:56,  2.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.359375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "iter_acc: 0-250/391 iter_acc: 42.19%, lr=['0.1'], iter_loss: 1.469311237335205, val_acc: 0.00%:  64%|██████▍   | 251/391 [01:40<00:55,  2.53it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.421875\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "iter_acc: 0-260/391 iter_acc: 39.06%, lr=['0.1'], iter_loss: 1.589125394821167, val_acc: 0.00%:  67%|██████▋   | 261/391 [01:44<00:51,  2.50it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.390625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "iter_acc: 0-270/391 iter_acc: 30.47%, lr=['0.1'], iter_loss: 1.6584250926971436, val_acc: 0.00%:  69%|██████▉   | 271/391 [01:49<00:51,  2.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3046875\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "iter_acc: 0-280/391 iter_acc: 39.84%, lr=['0.1'], iter_loss: 1.5150566101074219, val_acc: 0.00%:  72%|███████▏  | 281/391 [01:53<00:41,  2.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3984375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "iter_acc: 0-290/391 iter_acc: 41.41%, lr=['0.1'], iter_loss: 1.642518162727356, val_acc: 0.00%:  74%|███████▍  | 291/391 [01:57<00:38,  2.60it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4140625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "iter_acc: 0-300/391 iter_acc: 31.25%, lr=['0.1'], iter_loss: 1.620697021484375, val_acc: 0.00%:  77%|███████▋  | 301/391 [02:02<00:37,  2.41it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "iter_acc: 0-310/391 iter_acc: 42.97%, lr=['0.1'], iter_loss: 1.532922387123108, val_acc: 0.00%:  80%|███████▉  | 311/391 [02:06<00:30,  2.64it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4296875\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "iter_acc: 0-320/391 iter_acc: 47.66%, lr=['0.1'], iter_loss: 1.455384373664856, val_acc: 0.00%:  82%|████████▏ | 321/391 [02:10<00:25,  2.70it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4765625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "iter_acc: 0-330/391 iter_acc: 38.28%, lr=['0.1'], iter_loss: 1.676748514175415, val_acc: 0.00%:  85%|████████▍ | 331/391 [02:13<00:22,  2.71it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3828125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "iter_acc: 0-340/391 iter_acc: 40.62%, lr=['0.1'], iter_loss: 1.6009624004364014, val_acc: 0.00%:  87%|████████▋ | 341/391 [02:17<00:19,  2.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.40625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "iter_acc: 0-350/391 iter_acc: 50.78%, lr=['0.1'], iter_loss: 1.4546102285385132, val_acc: 0.00%:  90%|████████▉ | 351/391 [02:21<00:14,  2.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5078125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "iter_acc: 0-360/391 iter_acc: 41.41%, lr=['0.1'], iter_loss: 1.5961799621582031, val_acc: 0.00%:  92%|█████████▏| 361/391 [02:25<00:11,  2.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4140625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "iter_acc: 0-370/391 iter_acc: 53.91%, lr=['0.1'], iter_loss: 1.2970210313796997, val_acc: 0.00%:  95%|█████████▍| 371/391 [02:29<00:07,  2.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5390625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "iter_acc: 0-380/391 iter_acc: 48.44%, lr=['0.1'], iter_loss: 1.419586420059204, val_acc: 0.00%:  97%|█████████▋| 381/391 [02:33<00:03,  2.61it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.484375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "iter_acc: 0-389/391 iter_acc: 51.56%, lr=['0.1'], iter_loss: 1.4603748321533203, val_acc: 0.00%: 100%|█████████▉| 390/391 [02:36<00:00,  2.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.425\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "iter_acc: 0-390/391 iter_acc: 42.50%, lr=['0.1'], iter_loss: 0.220193013548851, val_acc: 52.06%: 100%|██████████| 391/391 [02:57<00:00,  2.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch_time: 177.77717661857605 seconds\n",
      "\n",
      "EPOCH 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "iter_acc: 1-0/391 iter_acc: 42.97%, lr=['0.09999725846827562'], iter_loss: 1.4844014644622803, val_acc: 52.06%:   0%|          | 1/391 [00:00<02:43,  2.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4296875\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "iter_acc: 1-10/391 iter_acc: 53.12%, lr=['0.09999725846827562'], iter_loss: 1.403048038482666, val_acc: 52.06%:   3%|▎         | 11/391 [00:04<02:27,  2.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.53125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "iter_acc: 1-20/391 iter_acc: 44.53%, lr=['0.09999725846827562'], iter_loss: 1.4832648038864136, val_acc: 52.06%:   5%|▌         | 21/391 [00:09<02:54,  2.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4453125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "iter_acc: 1-30/391 iter_acc: 55.47%, lr=['0.09999725846827562'], iter_loss: 1.4393479824066162, val_acc: 52.06%:   8%|▊         | 31/391 [00:13<02:20,  2.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5546875\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "iter_acc: 1-40/391 iter_acc: 39.84%, lr=['0.09999725846827562'], iter_loss: 1.5450115203857422, val_acc: 52.06%:  10%|█         | 41/391 [00:17<02:11,  2.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3984375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "iter_acc: 1-50/391 iter_acc: 50.78%, lr=['0.09999725846827562'], iter_loss: 1.3955087661743164, val_acc: 52.06%:  13%|█▎        | 51/391 [00:21<02:09,  2.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5078125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "iter_acc: 1-60/391 iter_acc: 53.12%, lr=['0.09999725846827562'], iter_loss: 1.2884862422943115, val_acc: 52.06%:  16%|█▌        | 61/391 [00:25<02:11,  2.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.53125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "iter_acc: 1-70/391 iter_acc: 52.34%, lr=['0.09999725846827562'], iter_loss: 1.4022064208984375, val_acc: 52.06%:  18%|█▊        | 71/391 [00:29<02:02,  2.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5234375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "iter_acc: 1-80/391 iter_acc: 49.22%, lr=['0.09999725846827562'], iter_loss: 1.4556443691253662, val_acc: 52.06%:  21%|██        | 81/391 [00:33<01:55,  2.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4921875\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "iter_acc: 1-90/391 iter_acc: 48.44%, lr=['0.09999725846827562'], iter_loss: 1.4629511833190918, val_acc: 52.06%:  23%|██▎       | 91/391 [00:36<01:54,  2.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.484375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "iter_acc: 1-100/391 iter_acc: 55.47%, lr=['0.09999725846827562'], iter_loss: 1.3882136344909668, val_acc: 52.06%:  26%|██▌       | 101/391 [00:40<01:49,  2.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5546875\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "iter_acc: 1-110/391 iter_acc: 41.41%, lr=['0.09999725846827562'], iter_loss: 1.3585550785064697, val_acc: 52.06%:  28%|██▊       | 111/391 [00:44<01:50,  2.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4140625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "iter_acc: 1-120/391 iter_acc: 53.91%, lr=['0.09999725846827562'], iter_loss: 1.3276844024658203, val_acc: 52.06%:  31%|███       | 121/391 [00:49<01:52,  2.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5390625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "iter_acc: 1-130/391 iter_acc: 58.59%, lr=['0.09999725846827562'], iter_loss: 1.4044194221496582, val_acc: 52.06%:  34%|███▎      | 131/391 [00:54<01:41,  2.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5859375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "iter_acc: 1-140/391 iter_acc: 57.81%, lr=['0.09999725846827562'], iter_loss: 1.3625913858413696, val_acc: 52.06%:  36%|███▌      | 141/391 [00:57<01:37,  2.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.578125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "iter_acc: 1-150/391 iter_acc: 49.22%, lr=['0.09999725846827562'], iter_loss: 1.4086624383926392, val_acc: 52.06%:  39%|███▊      | 151/391 [01:01<01:32,  2.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4921875\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "iter_acc: 1-160/391 iter_acc: 42.97%, lr=['0.09999725846827562'], iter_loss: 1.4536871910095215, val_acc: 52.06%:  41%|████      | 161/391 [01:05<01:30,  2.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4296875\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "iter_acc: 1-170/391 iter_acc: 54.69%, lr=['0.09999725846827562'], iter_loss: 1.3727422952651978, val_acc: 52.06%:  44%|████▎     | 171/391 [01:09<01:24,  2.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.546875\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "iter_acc: 1-180/391 iter_acc: 56.25%, lr=['0.09999725846827562'], iter_loss: 1.2100310325622559, val_acc: 52.06%:  46%|████▋     | 181/391 [01:13<01:21,  2.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "iter_acc: 1-190/391 iter_acc: 57.03%, lr=['0.09999725846827562'], iter_loss: 1.2749890089035034, val_acc: 52.06%:  49%|████▉     | 191/391 [01:17<01:20,  2.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5703125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "iter_acc: 1-200/391 iter_acc: 55.47%, lr=['0.09999725846827562'], iter_loss: 1.140990138053894, val_acc: 52.06%:  51%|█████▏    | 201/391 [01:21<01:11,  2.64it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5546875\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "iter_acc: 1-210/391 iter_acc: 54.69%, lr=['0.09999725846827562'], iter_loss: 1.2327455282211304, val_acc: 52.06%:  54%|█████▍    | 211/391 [01:26<01:18,  2.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.546875\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "iter_acc: 1-220/391 iter_acc: 51.56%, lr=['0.09999725846827562'], iter_loss: 1.305238962173462, val_acc: 52.06%:  57%|█████▋    | 221/391 [01:30<01:11,  2.39it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.515625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "iter_acc: 1-230/391 iter_acc: 53.12%, lr=['0.09999725846827562'], iter_loss: 1.285125494003296, val_acc: 52.06%:  59%|█████▉    | 231/391 [01:34<01:04,  2.48it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.53125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "iter_acc: 1-240/391 iter_acc: 53.91%, lr=['0.09999725846827562'], iter_loss: 1.2580736875534058, val_acc: 52.06%:  62%|██████▏   | 241/391 [01:38<01:00,  2.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5390625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "iter_acc: 1-250/391 iter_acc: 57.03%, lr=['0.09999725846827562'], iter_loss: 1.30508291721344, val_acc: 52.06%:  64%|██████▍   | 251/391 [01:43<01:23,  1.69it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5703125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "iter_acc: 1-260/391 iter_acc: 54.69%, lr=['0.09999725846827562'], iter_loss: 1.1397587060928345, val_acc: 52.06%:  67%|██████▋   | 261/391 [01:47<00:51,  2.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.546875\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "iter_acc: 1-270/391 iter_acc: 58.59%, lr=['0.09999725846827562'], iter_loss: 1.2436730861663818, val_acc: 52.06%:  69%|██████▉   | 271/391 [01:51<00:45,  2.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5859375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "iter_acc: 1-280/391 iter_acc: 46.88%, lr=['0.09999725846827562'], iter_loss: 1.4787213802337646, val_acc: 52.06%:  72%|███████▏  | 281/391 [01:55<00:41,  2.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.46875\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "iter_acc: 1-290/391 iter_acc: 55.47%, lr=['0.09999725846827562'], iter_loss: 1.2418959140777588, val_acc: 52.06%:  74%|███████▍  | 291/391 [01:59<00:38,  2.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5546875\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "iter_acc: 1-300/391 iter_acc: 54.69%, lr=['0.09999725846827562'], iter_loss: 1.3166749477386475, val_acc: 52.06%:  77%|███████▋  | 301/391 [02:03<00:35,  2.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.546875\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "iter_acc: 1-310/391 iter_acc: 57.03%, lr=['0.09999725846827562'], iter_loss: 1.2840076684951782, val_acc: 52.06%:  80%|███████▉  | 311/391 [02:07<00:31,  2.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5703125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "iter_acc: 1-320/391 iter_acc: 58.59%, lr=['0.09999725846827562'], iter_loss: 1.1896201372146606, val_acc: 52.06%:  82%|████████▏ | 321/391 [02:11<00:29,  2.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5859375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "iter_acc: 1-330/391 iter_acc: 53.91%, lr=['0.09999725846827562'], iter_loss: 1.2572981119155884, val_acc: 52.06%:  85%|████████▍ | 331/391 [02:15<00:22,  2.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5390625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "iter_acc: 1-340/391 iter_acc: 60.16%, lr=['0.09999725846827562'], iter_loss: 1.137863278388977, val_acc: 52.06%:  87%|████████▋ | 341/391 [02:20<00:20,  2.47it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6015625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "iter_acc: 1-350/391 iter_acc: 57.81%, lr=['0.09999725846827562'], iter_loss: 1.210634469985962, val_acc: 52.06%:  90%|████████▉ | 351/391 [02:25<00:17,  2.32it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.578125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "iter_acc: 1-360/391 iter_acc: 60.94%, lr=['0.09999725846827562'], iter_loss: 1.1937758922576904, val_acc: 52.06%:  92%|█████████▏| 361/391 [02:28<00:11,  2.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.609375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "iter_acc: 1-370/391 iter_acc: 62.50%, lr=['0.09999725846827562'], iter_loss: 1.102381706237793, val_acc: 52.06%:  95%|█████████▍| 371/391 [02:32<00:07,  2.64it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "iter_acc: 1-380/391 iter_acc: 61.72%, lr=['0.09999725846827562'], iter_loss: 1.0602134466171265, val_acc: 52.06%:  97%|█████████▋| 381/391 [02:36<00:03,  2.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6171875\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "iter_acc: 1-389/391 iter_acc: 57.03%, lr=['0.09999725846827562'], iter_loss: 1.2911427021026611, val_acc: 52.06%: 100%|█████████▉| 390/391 [02:40<00:00,  2.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "iter_acc: 1-390/391 iter_acc: 51.25%, lr=['0.09999725846827562'], iter_loss: 0.16959747672080994, val_acc: 63.07%: 100%|██████████| 391/391 [02:58<00:00,  2.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch_time: 178.4301266670227 seconds\n",
      "\n",
      "EPOCH 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "iter_acc: 2-0/391 iter_acc: 52.34%, lr=['0.09998903417374229'], iter_loss: 1.259758472442627, val_acc: 63.07%:   0%|          | 1/391 [00:00<02:31,  2.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5234375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "iter_acc: 2-10/391 iter_acc: 65.62%, lr=['0.09998903417374229'], iter_loss: 1.0999952554702759, val_acc: 63.07%:   3%|▎         | 11/391 [00:04<02:31,  2.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.65625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "iter_acc: 2-20/391 iter_acc: 57.81%, lr=['0.09998903417374229'], iter_loss: 1.1990221738815308, val_acc: 63.07%:   5%|▌         | 21/391 [00:09<02:28,  2.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.578125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "iter_acc: 2-30/391 iter_acc: 52.34%, lr=['0.09998903417374229'], iter_loss: 1.2352794408798218, val_acc: 63.07%:   8%|▊         | 31/391 [00:12<02:15,  2.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5234375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "iter_acc: 2-40/391 iter_acc: 60.94%, lr=['0.09998903417374229'], iter_loss: 1.0873582363128662, val_acc: 63.07%:  10%|█         | 41/391 [00:16<02:17,  2.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.609375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "iter_acc: 2-50/391 iter_acc: 65.62%, lr=['0.09998903417374229'], iter_loss: 1.1166532039642334, val_acc: 63.07%:  13%|█▎        | 51/391 [00:22<02:24,  2.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.65625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "iter_acc: 2-60/391 iter_acc: 60.94%, lr=['0.09998903417374229'], iter_loss: 1.1776552200317383, val_acc: 63.07%:  16%|█▌        | 61/391 [00:26<02:11,  2.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.609375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "iter_acc: 2-70/391 iter_acc: 50.78%, lr=['0.09998903417374229'], iter_loss: 1.3218410015106201, val_acc: 63.07%:  18%|█▊        | 71/391 [00:30<02:08,  2.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5078125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "iter_acc: 2-80/391 iter_acc: 61.72%, lr=['0.09998903417374229'], iter_loss: 1.1691782474517822, val_acc: 63.07%:  21%|██        | 81/391 [00:34<01:59,  2.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6171875\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "iter_acc: 2-90/391 iter_acc: 56.25%, lr=['0.09998903417374229'], iter_loss: 1.2672598361968994, val_acc: 63.07%:  23%|██▎       | 91/391 [00:40<03:55,  1.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "iter_acc: 2-100/391 iter_acc: 60.16%, lr=['0.09998903417374229'], iter_loss: 1.2348997592926025, val_acc: 63.07%:  26%|██▌       | 101/391 [00:44<01:53,  2.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6015625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "iter_acc: 2-110/391 iter_acc: 50.00%, lr=['0.09998903417374229'], iter_loss: 1.333737850189209, val_acc: 63.07%:  28%|██▊       | 111/391 [00:48<01:45,  2.66it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "iter_acc: 2-120/391 iter_acc: 61.72%, lr=['0.09998903417374229'], iter_loss: 1.1108853816986084, val_acc: 63.07%:  31%|███       | 121/391 [00:52<01:50,  2.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6171875\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "iter_acc: 2-130/391 iter_acc: 60.94%, lr=['0.09998903417374229'], iter_loss: 1.176263689994812, val_acc: 63.07%:  34%|███▎      | 131/391 [00:56<01:43,  2.52it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.609375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "iter_acc: 2-140/391 iter_acc: 66.41%, lr=['0.09998903417374229'], iter_loss: 1.0738214254379272, val_acc: 63.07%:  36%|███▌      | 141/391 [01:00<01:34,  2.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6640625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "iter_acc: 2-150/391 iter_acc: 67.97%, lr=['0.09998903417374229'], iter_loss: 1.11995267868042, val_acc: 63.07%:  39%|███▊      | 151/391 [01:04<01:38,  2.44it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6796875\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "iter_acc: 2-160/391 iter_acc: 59.38%, lr=['0.09998903417374229'], iter_loss: 1.1530147790908813, val_acc: 63.07%:  41%|████      | 161/391 [01:08<01:25,  2.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.59375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "iter_acc: 2-170/391 iter_acc: 59.38%, lr=['0.09998903417374229'], iter_loss: 1.1627490520477295, val_acc: 63.07%:  44%|████▎     | 171/391 [01:12<01:27,  2.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.59375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "iter_acc: 2-180/391 iter_acc: 58.59%, lr=['0.09998903417374229'], iter_loss: 1.1276488304138184, val_acc: 63.07%:  46%|████▋     | 181/391 [01:17<01:20,  2.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5859375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "iter_acc: 2-190/391 iter_acc: 55.47%, lr=['0.09998903417374229'], iter_loss: 1.283094882965088, val_acc: 63.07%:  49%|████▉     | 191/391 [01:21<01:19,  2.53it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5546875\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "iter_acc: 2-200/391 iter_acc: 64.84%, lr=['0.09998903417374229'], iter_loss: 1.066792368888855, val_acc: 63.07%:  51%|█████▏    | 201/391 [01:26<01:39,  1.91it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6484375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "iter_acc: 2-210/391 iter_acc: 60.94%, lr=['0.09998903417374229'], iter_loss: 1.148625135421753, val_acc: 63.07%:  54%|█████▍    | 211/391 [01:32<01:38,  1.82it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.609375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "iter_acc: 2-220/391 iter_acc: 64.06%, lr=['0.09998903417374229'], iter_loss: 1.0632219314575195, val_acc: 63.07%:  57%|█████▋    | 221/391 [01:36<01:06,  2.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.640625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "iter_acc: 2-230/391 iter_acc: 62.50%, lr=['0.09998903417374229'], iter_loss: 1.1638598442077637, val_acc: 63.07%:  59%|█████▉    | 231/391 [01:40<00:59,  2.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "iter_acc: 2-240/391 iter_acc: 53.12%, lr=['0.09998903417374229'], iter_loss: 1.2846168279647827, val_acc: 63.07%:  62%|██████▏   | 241/391 [01:44<00:59,  2.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.53125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "iter_acc: 2-250/391 iter_acc: 56.25%, lr=['0.09998903417374229'], iter_loss: 1.2125595808029175, val_acc: 63.07%:  64%|██████▍   | 251/391 [01:48<00:55,  2.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "iter_acc: 2-260/391 iter_acc: 55.47%, lr=['0.09998903417374229'], iter_loss: 1.1887726783752441, val_acc: 63.07%:  67%|██████▋   | 261/391 [01:53<00:57,  2.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5546875\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "iter_acc: 2-270/391 iter_acc: 67.97%, lr=['0.09998903417374229'], iter_loss: 0.995171844959259, val_acc: 63.07%:  69%|██████▉   | 271/391 [01:57<00:46,  2.59it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6796875\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "iter_acc: 2-280/391 iter_acc: 62.50%, lr=['0.09998903417374229'], iter_loss: 1.095526099205017, val_acc: 63.07%:  72%|███████▏  | 281/391 [02:01<00:44,  2.47it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "iter_acc: 2-290/391 iter_acc: 64.06%, lr=['0.09998903417374229'], iter_loss: 1.0839650630950928, val_acc: 63.07%:  74%|███████▍  | 291/391 [02:05<00:37,  2.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.640625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "iter_acc: 2-300/391 iter_acc: 69.53%, lr=['0.09998903417374229'], iter_loss: 1.0744001865386963, val_acc: 63.07%:  77%|███████▋  | 301/391 [02:09<00:33,  2.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6953125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "iter_acc: 2-310/391 iter_acc: 63.28%, lr=['0.09998903417374229'], iter_loss: 1.0559026002883911, val_acc: 63.07%:  80%|███████▉  | 311/391 [02:13<00:35,  2.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6328125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "iter_acc: 2-320/391 iter_acc: 64.06%, lr=['0.09998903417374229'], iter_loss: 1.1034866571426392, val_acc: 63.07%:  82%|████████▏ | 321/391 [02:17<00:28,  2.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.640625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "iter_acc: 2-330/391 iter_acc: 67.19%, lr=['0.09998903417374229'], iter_loss: 0.9695225358009338, val_acc: 63.07%:  85%|████████▍ | 331/391 [02:21<00:23,  2.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.671875\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "iter_acc: 2-340/391 iter_acc: 68.75%, lr=['0.09998903417374229'], iter_loss: 1.0097699165344238, val_acc: 63.07%:  87%|████████▋ | 341/391 [02:25<00:21,  2.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6875\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "iter_acc: 2-350/391 iter_acc: 70.31%, lr=['0.09998903417374229'], iter_loss: 1.0345796346664429, val_acc: 63.07%:  90%|████████▉ | 351/391 [02:29<00:15,  2.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.703125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "iter_acc: 2-360/391 iter_acc: 61.72%, lr=['0.09998903417374229'], iter_loss: 1.16530442237854, val_acc: 63.07%:  92%|█████████▏| 361/391 [02:34<00:12,  2.37it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6171875\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "iter_acc: 2-370/391 iter_acc: 63.28%, lr=['0.09998903417374229'], iter_loss: 1.0808219909667969, val_acc: 63.07%:  95%|█████████▍| 371/391 [02:39<00:08,  2.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6328125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "iter_acc: 2-380/391 iter_acc: 61.72%, lr=['0.09998903417374229'], iter_loss: 1.1028881072998047, val_acc: 63.07%:  97%|█████████▋| 381/391 [02:44<00:04,  2.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6171875\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "iter_acc: 2-389/391 iter_acc: 72.66%, lr=['0.09998903417374229'], iter_loss: 1.0611579418182373, val_acc: 63.07%: 100%|█████████▉| 390/391 [02:49<00:00,  1.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "iter_acc: 2-390/391 iter_acc: 56.25%, lr=['0.09998903417374229'], iter_loss: 0.13838112354278564, val_acc: 69.26%: 100%|██████████| 391/391 [03:09<00:00,  2.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch_time: 189.89742946624756 seconds\n",
      "\n",
      "EPOCH 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "iter_acc: 3-0/391 iter_acc: 66.41%, lr=['0.0999753280182866'], iter_loss: 0.9416620135307312, val_acc: 69.26%:   0%|          | 1/391 [00:00<02:44,  2.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6640625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "iter_acc: 3-10/391 iter_acc: 69.53%, lr=['0.0999753280182866'], iter_loss: 0.9350513815879822, val_acc: 69.26%:   3%|▎         | 11/391 [00:04<02:26,  2.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6953125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "iter_acc: 3-20/391 iter_acc: 64.84%, lr=['0.0999753280182866'], iter_loss: 1.1948983669281006, val_acc: 69.26%:   5%|▌         | 21/391 [00:09<02:27,  2.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6484375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "iter_acc: 3-30/391 iter_acc: 63.28%, lr=['0.0999753280182866'], iter_loss: 1.1057802438735962, val_acc: 69.26%:   8%|▊         | 31/391 [00:13<02:18,  2.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6328125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "iter_acc: 3-40/391 iter_acc: 64.84%, lr=['0.0999753280182866'], iter_loss: 1.067117691040039, val_acc: 69.26%:  10%|█         | 41/391 [00:17<02:13,  2.63it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6484375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "iter_acc: 3-50/391 iter_acc: 64.84%, lr=['0.0999753280182866'], iter_loss: 1.0434707403182983, val_acc: 69.26%:  13%|█▎        | 51/391 [00:20<02:09,  2.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6484375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "iter_acc: 3-60/391 iter_acc: 64.06%, lr=['0.0999753280182866'], iter_loss: 1.0548486709594727, val_acc: 69.26%:  16%|█▌        | 61/391 [00:24<02:03,  2.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.640625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "iter_acc: 3-70/391 iter_acc: 65.62%, lr=['0.0999753280182866'], iter_loss: 0.9812283515930176, val_acc: 69.26%:  18%|█▊        | 71/391 [00:28<02:06,  2.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.65625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "iter_acc: 3-80/391 iter_acc: 60.94%, lr=['0.0999753280182866'], iter_loss: 1.1133246421813965, val_acc: 69.26%:  21%|██        | 81/391 [00:33<02:34,  2.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.609375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "iter_acc: 3-90/391 iter_acc: 61.72%, lr=['0.0999753280182866'], iter_loss: 1.1209241151809692, val_acc: 69.26%:  23%|██▎       | 91/391 [00:38<02:56,  1.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6171875\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "iter_acc: 3-100/391 iter_acc: 65.62%, lr=['0.0999753280182866'], iter_loss: 1.0483063459396362, val_acc: 69.26%:  26%|██▌       | 101/391 [00:42<01:59,  2.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.65625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "iter_acc: 3-110/391 iter_acc: 68.75%, lr=['0.0999753280182866'], iter_loss: 0.9342044591903687, val_acc: 69.26%:  28%|██▊       | 111/391 [00:46<01:45,  2.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6875\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "iter_acc: 3-120/391 iter_acc: 61.72%, lr=['0.0999753280182866'], iter_loss: 1.1165357828140259, val_acc: 69.26%:  31%|███       | 121/391 [00:50<01:43,  2.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6171875\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "iter_acc: 3-130/391 iter_acc: 72.66%, lr=['0.0999753280182866'], iter_loss: 0.9076790809631348, val_acc: 69.26%:  34%|███▎      | 131/391 [00:56<03:02,  1.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7265625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "iter_acc: 3-140/391 iter_acc: 70.31%, lr=['0.0999753280182866'], iter_loss: 0.9192605018615723, val_acc: 69.26%:  36%|███▌      | 141/391 [01:00<01:39,  2.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.703125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "iter_acc: 3-150/391 iter_acc: 64.84%, lr=['0.0999753280182866'], iter_loss: 1.1004817485809326, val_acc: 69.26%:  39%|███▊      | 151/391 [01:05<01:38,  2.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6484375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "iter_acc: 3-160/391 iter_acc: 59.38%, lr=['0.0999753280182866'], iter_loss: 1.098219633102417, val_acc: 69.26%:  41%|████      | 161/391 [01:10<01:56,  1.97it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.59375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "iter_acc: 3-170/391 iter_acc: 67.97%, lr=['0.0999753280182866'], iter_loss: 0.9810896515846252, val_acc: 69.26%:  44%|████▎     | 171/391 [01:16<01:38,  2.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6796875\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "iter_acc: 3-180/391 iter_acc: 64.84%, lr=['0.0999753280182866'], iter_loss: 1.1093965768814087, val_acc: 69.26%:  46%|████▋     | 181/391 [01:20<01:24,  2.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6484375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "iter_acc: 3-190/391 iter_acc: 67.97%, lr=['0.0999753280182866'], iter_loss: 0.9647483229637146, val_acc: 69.26%:  49%|████▉     | 191/391 [01:24<01:15,  2.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6796875\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "iter_acc: 3-200/391 iter_acc: 63.28%, lr=['0.0999753280182866'], iter_loss: 1.1052907705307007, val_acc: 69.26%:  51%|█████▏    | 201/391 [01:28<01:14,  2.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6328125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "iter_acc: 3-210/391 iter_acc: 60.16%, lr=['0.0999753280182866'], iter_loss: 1.1483299732208252, val_acc: 69.26%:  54%|█████▍    | 211/391 [01:32<01:09,  2.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6015625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "iter_acc: 3-220/391 iter_acc: 64.06%, lr=['0.0999753280182866'], iter_loss: 1.0055230855941772, val_acc: 69.26%:  57%|█████▋    | 221/391 [01:35<01:06,  2.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.640625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "iter_acc: 3-230/391 iter_acc: 67.97%, lr=['0.0999753280182866'], iter_loss: 0.9843496084213257, val_acc: 69.26%:  59%|█████▉    | 231/391 [01:41<01:48,  1.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6796875\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "iter_acc: 3-240/391 iter_acc: 72.66%, lr=['0.0999753280182866'], iter_loss: 0.9015178680419922, val_acc: 69.26%:  62%|██████▏   | 241/391 [01:45<01:04,  2.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7265625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "iter_acc: 3-250/391 iter_acc: 64.06%, lr=['0.0999753280182866'], iter_loss: 1.028914213180542, val_acc: 69.26%:  64%|██████▍   | 251/391 [01:50<00:54,  2.59it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.640625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "iter_acc: 3-260/391 iter_acc: 61.72%, lr=['0.0999753280182866'], iter_loss: 1.046525478363037, val_acc: 69.26%:  67%|██████▋   | 261/391 [01:54<00:48,  2.69it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6171875\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "iter_acc: 3-270/391 iter_acc: 62.50%, lr=['0.0999753280182866'], iter_loss: 1.0828149318695068, val_acc: 69.26%:  69%|██████▉   | 271/391 [01:58<00:51,  2.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "iter_acc: 3-280/391 iter_acc: 60.16%, lr=['0.0999753280182866'], iter_loss: 1.0633172988891602, val_acc: 69.26%:  72%|███████▏  | 281/391 [02:02<00:41,  2.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6015625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "iter_acc: 3-290/391 iter_acc: 64.84%, lr=['0.0999753280182866'], iter_loss: 1.0399634838104248, val_acc: 69.26%:  74%|███████▍  | 291/391 [02:06<00:42,  2.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6484375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "iter_acc: 3-300/391 iter_acc: 65.62%, lr=['0.0999753280182866'], iter_loss: 1.032879114151001, val_acc: 69.26%:  77%|███████▋  | 301/391 [02:10<00:34,  2.59it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.65625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "iter_acc: 3-310/391 iter_acc: 70.31%, lr=['0.0999753280182866'], iter_loss: 0.8701926469802856, val_acc: 69.26%:  80%|███████▉  | 311/391 [02:14<00:30,  2.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.703125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "iter_acc: 3-320/391 iter_acc: 66.41%, lr=['0.0999753280182866'], iter_loss: 1.0740208625793457, val_acc: 69.26%:  82%|████████▏ | 321/391 [02:18<00:26,  2.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6640625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "iter_acc: 3-330/391 iter_acc: 69.53%, lr=['0.0999753280182866'], iter_loss: 0.9181245565414429, val_acc: 69.26%:  85%|████████▍ | 331/391 [02:22<00:22,  2.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6953125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "iter_acc: 3-340/391 iter_acc: 60.94%, lr=['0.0999753280182866'], iter_loss: 1.0602360963821411, val_acc: 69.26%:  87%|████████▋ | 341/391 [02:28<00:26,  1.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.609375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "iter_acc: 3-350/391 iter_acc: 65.62%, lr=['0.0999753280182866'], iter_loss: 1.1089916229248047, val_acc: 69.26%:  90%|████████▉ | 351/391 [02:32<00:15,  2.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.65625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "iter_acc: 3-360/391 iter_acc: 70.31%, lr=['0.0999753280182866'], iter_loss: 0.9683647751808167, val_acc: 69.26%:  92%|█████████▏| 361/391 [02:37<00:13,  2.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.703125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "iter_acc: 3-370/391 iter_acc: 68.75%, lr=['0.0999753280182866'], iter_loss: 0.9411826729774475, val_acc: 69.26%:  95%|█████████▍| 371/391 [02:42<00:07,  2.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6875\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "iter_acc: 3-380/391 iter_acc: 67.97%, lr=['0.0999753280182866'], iter_loss: 1.0259621143341064, val_acc: 69.26%:  97%|█████████▋| 381/391 [02:46<00:03,  2.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6796875\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "iter_acc: 3-389/391 iter_acc: 61.72%, lr=['0.0999753280182866'], iter_loss: 1.1243417263031006, val_acc: 69.26%: 100%|█████████▉| 390/391 [02:50<00:00,  2.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "iter_acc: 3-390/391 iter_acc: 66.25%, lr=['0.0999753280182866'], iter_loss: 0.11543139070272446, val_acc: 73.27%: 100%|██████████| 391/391 [03:09<00:00,  2.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch_time: 189.54013466835022 seconds\n",
      "\n",
      "EPOCH 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "iter_acc: 4-0/391 iter_acc: 73.44%, lr=['0.09995614150494293'], iter_loss: 0.8873854279518127, val_acc: 73.27%:   0%|          | 1/391 [00:00<02:44,  2.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.734375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "iter_acc: 4-10/391 iter_acc: 70.31%, lr=['0.09995614150494293'], iter_loss: 0.924592912197113, val_acc: 73.27%:   3%|▎         | 11/391 [00:04<02:30,  2.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.703125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "iter_acc: 4-20/391 iter_acc: 70.31%, lr=['0.09995614150494293'], iter_loss: 0.9446913003921509, val_acc: 73.27%:   5%|▌         | 21/391 [00:08<02:24,  2.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.703125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "iter_acc: 4-30/391 iter_acc: 66.41%, lr=['0.09995614150494293'], iter_loss: 1.064887285232544, val_acc: 73.27%:   8%|▊         | 31/391 [00:12<02:28,  2.43it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6640625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "iter_acc: 4-40/391 iter_acc: 66.41%, lr=['0.09995614150494293'], iter_loss: 0.9694122076034546, val_acc: 73.27%:  10%|█         | 41/391 [00:16<02:16,  2.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6640625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "iter_acc: 4-50/391 iter_acc: 63.28%, lr=['0.09995614150494293'], iter_loss: 1.01361083984375, val_acc: 73.27%:  13%|█▎        | 51/391 [00:20<02:12,  2.57it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6328125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "iter_acc: 4-60/391 iter_acc: 73.44%, lr=['0.09995614150494293'], iter_loss: 0.9134587645530701, val_acc: 73.27%:  16%|█▌        | 61/391 [00:24<02:07,  2.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.734375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "iter_acc: 4-70/391 iter_acc: 70.31%, lr=['0.09995614150494293'], iter_loss: 0.9313748478889465, val_acc: 73.27%:  18%|█▊        | 71/391 [00:28<02:07,  2.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.703125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "iter_acc: 4-80/391 iter_acc: 74.22%, lr=['0.09995614150494293'], iter_loss: 0.8400238156318665, val_acc: 73.27%:  21%|██        | 81/391 [00:32<02:01,  2.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7421875\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "iter_acc: 4-89/391 iter_acc: 71.09%, lr=['0.09995614150494293'], iter_loss: 0.9300594925880432, val_acc: 73.27%:  23%|██▎       | 90/391 [00:35<02:02,  2.45it/s]"
     ]
    }
   ],
   "source": [
    "### my_snn control board ########################\n",
    "decay = 0.5 # 0.875 0.25 0.125 0.75 0.5\n",
    "# nda 0.25 # ottt 0.5\n",
    "\n",
    "unique_name = 'main' ## 이거 설정하면 새로운 경로에 모두 save\n",
    "wandb.init(project= f'my_snn {unique_name}')\n",
    "my_snn_system(  devices = \"2\",\n",
    "                single_step = True, # True # False\n",
    "                unique_name = unique_name,\n",
    "                my_seed = 42,\n",
    "                TIME = 6 , # dvscifar 10 # ottt 6 or 10 # nda 10  # 제작하는 dvs에서 TIME넘거나 적으면 자르거나 PADDING함\n",
    "                BATCH = 128, # batch norm 할거면 2이상으로 해야함   # nda 256   #  ottt 128\n",
    "                IMAGE_SIZE = 32, # dvscifar 48 # MNIST 28 # CIFAR10 32 # PMNIST 28\n",
    "                # dvsgesture 128, dvs_cifar2 128, nmnist 34, n_caltech101 180,240, n_tidigits 64, heidelberg 700, \n",
    "                #pmnist는 28로 해야 됨. 나머지는 바꿔도 돌아는 감.\n",
    "\n",
    "                # DVS_CIFAR10 할거면 time 10으로 해라\n",
    "                which_data = 'CIFAR10',\n",
    "# 'CIFAR100' 'CIFAR10' 'MNIST' 'FASHION_MNIST' 'DVS_CIFAR10' 'PMNIST'아직\n",
    "# 'DVS_GESTURE','DVS_CIFAR10_2','NMNIST','N_CALTECH101','n_tidigits','heidelberg'\n",
    "                # CLASS_NUM = 10,\n",
    "                data_path = '/data2', # YOU NEED TO CHANGE THIS\n",
    "                rate_coding = False, # True # False\n",
    "\n",
    "                lif_layer_v_init = 0.0,\n",
    "                lif_layer_v_decay = decay,\n",
    "                lif_layer_v_threshold = 1.0,  # 10000이상으로 하면 NDA LIF 씀. #nda 0.5  #ottt 1.0\n",
    "                lif_layer_v_reset = 0, # 10000이상은 hardreset (내 LIF쓰기는 함 ㅇㅇ)\n",
    "                lif_layer_sg_width = 1.0, # # surrogate sigmoid 쓸 때는 의미없음\n",
    "\n",
    "                # synapse_conv_in_channels = IMAGE_PIXEL_CHANNEL,\n",
    "                synapse_conv_kernel_size = 3,\n",
    "                synapse_conv_stride = 1,\n",
    "                synapse_conv_padding = 1,\n",
    "                synapse_conv_trace_const1 = 1,\n",
    "                synapse_conv_trace_const2 = decay, # lif_layer_v_decay\n",
    "\n",
    "                # synapse_fc_out_features = CLASS_NUM,\n",
    "                synapse_fc_trace_const1 = 1,\n",
    "                synapse_fc_trace_const2 = decay, # lif_layer_v_decay\n",
    "\n",
    "                pre_trained = False, # True # False\n",
    "                convTrue_fcFalse = True, # True # False\n",
    "\n",
    "                # 'P' for average pooling, 'D' for (1,1) aver pooling, 'M' for maxpooling, 'L' for linear classifier, [  ] for residual block\n",
    "                # conv에서 10000 이상은 depth-wise separable (BPTT만 지원), 20000이상은 depth-wise (BPTT만 지원)\n",
    "                # cfg = [64],\n",
    "                # cfg = [64,[64,64],64], # 끝에 linear classifier 하나 자동으로 붙습니다\n",
    "                cfg = [64, 128, 'P', 256, 256, 'P', 512, 512, 'P', 512, 512, 'D'], #ottt\n",
    "                # cfg = [64, 128, 'P', 256, 256, 'P', 512, 512, 'P', 512, 512], #ottt\n",
    "                # cfg = [64, 128, 'M', 256, 256, 'M', 512, 512, 'M', 512, 512], # ottt \n",
    "                # cfg = [64, 'P', 128, 'P', 256, 256, 'P', 512, 512, 512, 512, 'D'], # nda\n",
    "                # cfg = [64, 'P', 128, 'P', 256, 256, 'P', 512, 512, 512, 512], # nda 128pixel\n",
    "                # cfg = [64, 'P', 128, 'P', 256, 256, 'P', 512, 512, 512, 512, 'L', 4096, 4096],\n",
    "                # cfg = [20001,10001], # depthwise, separable\n",
    "                # cfg = [64,20064,10001], # vanilla conv, depthwise, separable\n",
    "                # cfg = [8, 'P', 8, 'P', 8, 'P', 8,'P', 8, 'P'],\n",
    "                # cfg = [], \n",
    "                \n",
    "                net_print = True, # True # False\n",
    "                weight_count_print = False, # True # False\n",
    "                \n",
    "                pre_trained_path = f\"net_save/save_now_net_{unique_name}.pth\",\n",
    "                learning_rate = 0.1, # default 0.001  # ottt 0.1 0.00001 # nda 0.001 \n",
    "                epoch_num = 300,\n",
    "                verbose_interval = 999999999, #숫자 크게 하면 꺼짐 #걍 중간중간 iter에서 끊어서 출력\n",
    "                validation_interval = 999999999, #숫자 크게 하면 에포크 마지막 iter 때 val 함\n",
    "\n",
    "                tdBN_on = False,  # True # False\n",
    "                BN_on = False,  # True # False\n",
    "                \n",
    "                surrogate = 'sigmoid', # 'rectangle' 'sigmoid' 'rough_rectangle'\n",
    "                \n",
    "                gradient_verbose = False,  # True # False  # weight gradient 각 layer마다 띄워줌\n",
    "\n",
    "                BPTT_on = False,  # True # False # True이면 BPTT, False이면 OTTT  # depthwise, separable은 BPTT만 가능\n",
    "                optimizer_what = 'SGD', # 'SGD' 'Adam', 'RMSprop'\n",
    "                scheduler_name = 'CosineAnnealingLR', # 'no' 'StepLR' 'ExponentialLR' 'ReduceLROnPlateau' 'CosineAnnealingLR' 'OneCycleLR'\n",
    "                \n",
    "                ddp_on = False,   # True # False\n",
    "\n",
    "                nda_net = False,   # True # False\n",
    "\n",
    "                domain_il_epoch = 0, # over 0, then domain il mode on # pmnist 쓸거면 HLOP 코드보고 더 디벨롭하셈. 지금 개발 hold함.\n",
    "                \n",
    "                dvs_clipping = True, # dvs zero&one  # gesture, cifar-dvs2, nmnist, ncaltech101\n",
    "                dvs_duration = 1000000, # 0 아니면 time sampling # dvs number sampling OR time sampling # gesture, cifar-dvs2, nmnist, ncaltech101\n",
    "                #있는 데이터들 #gesture 1000000 #nmnist 10000\n",
    "\n",
    "                OTTT_sWS_on = True, # True # False # BPTT끄고, CONV에만 적용됨.\n",
    "                \n",
    "                ) \n",
    "# sigmoid와 BN이 있어야 잘된다.\n",
    "# average pooling\n",
    "# 이 낫다. \n",
    " \n",
    "# nda에서는 decay = 0.25, threshold = 0.5, width =1, surrogate = rectangle, batch = 256, tdBN = True\n",
    "## OTTT 에서는 decay = 0.5, threshold = 1.0, surrogate = sigmoid, batch = 128, BN = True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # sweep 하는 코드, 위 셀 주석처리 해야 됨.\n",
    "\n",
    "# unique_name_hyper = 'main'\n",
    "# sweep_configuration = {\n",
    "#     'method': 'bayes',\n",
    "#     'name': 'my_snn_sweep',\n",
    "#     'metric': {'goal': 'maximize', 'name': 'val_acc_now'},\n",
    "#     'parameters': \n",
    "#     {\n",
    "#         \"learning_rate\": {\"values\": [0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9,1.0,1.1,1.2,1.3,1.4,1.5,1.6,1.7,1.8,1.9,2.0]},\n",
    "#         \"batch_size\": {\"values\": [64, 96, 128]},\n",
    "#         \"decay\": {\"values\": [0.3,0.4,0.5,0.6,0.7,0.8,0.875,0.9]},\n",
    "#      }\n",
    "# }\n",
    "\n",
    "# def hyper_iter():\n",
    "#     ### my_snn control board ########################\n",
    "#     unique_name = unique_name_hyper ## 이거 설정하면 새로운 경로에 모두 save\n",
    "    \n",
    "#     wandb.init()\n",
    "#     learning_rate  =  wandb.config.learning_rate\n",
    "#     batch_size  =  wandb.config.batch_size\n",
    "#     decay  =  wandb.config.decay\n",
    "\n",
    "#     my_snn_system(  devices = \"3\",\n",
    "#                     single_step = True, # True # False\n",
    "#                     unique_name = unique_name,\n",
    "#                     my_seed = 42,\n",
    "#                     TIME = 6 , # dvscifar 10 # ottt 6 or 10 # nda 10  # 제작하는 dvs에서 TIME넘거나 적으면 자르거나 PADDING함\n",
    "#                     BATCH = batch_size, # batch norm 할거면 2이상으로 해야함   # nda 256   #  ottt 128\n",
    "#                     IMAGE_SIZE = 32, # dvscifar 48 # MNIST 28 # CIFAR10 32 # PMNIST 28\n",
    "#                     # dvsgesture 128, dvs_cifar2 128, nmnist 34, n_caltech101 180,240, n_tidigits 64, heidelberg 700, \n",
    "#                     #pmnist는 28로 해야 됨. 나머지는 바꿔도 돌아는 감.\n",
    "\n",
    "#                     # DVS_CIFAR10 할거면 time 10으로 해라\n",
    "#                     which_data = 'CIFAR10',\n",
    "#     # 'CIFAR100' 'CIFAR10' 'MNIST' 'FASHION_MNIST' 'DVS_CIFAR10' 'PMNIST'아직\n",
    "#     # 'DVS_GESTURE','DVS_CIFAR10_2','NMNIST','N_CALTECH101','n_tidigits','heidelberg'\n",
    "#                     # CLASS_NUM = 10,\n",
    "#                     data_path = '/data2', # YOU NEED TO CHANGE THIS\n",
    "#                     rate_coding = False, # True # False\n",
    "\n",
    "#                     lif_layer_v_init = 0.0,\n",
    "#                     lif_layer_v_decay = decay,\n",
    "#                     lif_layer_v_threshold = 1.0,  # 10000이상으로 하면 NDA LIF 씀. #nda 0.5  #ottt 1.0\n",
    "#                     lif_layer_v_reset = 0, # 10000이상은 hardreset (내 LIF쓰기는 함 ㅇㅇ)\n",
    "#                     lif_layer_sg_width = 1.0, # # surrogate sigmoid 쓸 때는 의미없음\n",
    "\n",
    "#                     # synapse_conv_in_channels = IMAGE_PIXEL_CHANNEL,\n",
    "#                     synapse_conv_kernel_size = 3,\n",
    "#                     synapse_conv_stride = 1,\n",
    "#                     synapse_conv_padding = 1,\n",
    "#                     synapse_conv_trace_const1 = 1,\n",
    "#                     synapse_conv_trace_const2 = decay, # lif_layer_v_decay\n",
    "\n",
    "#                     # synapse_fc_out_features = CLASS_NUM,\n",
    "#                     synapse_fc_trace_const1 = 1,\n",
    "#                     synapse_fc_trace_const2 = decay, # lif_layer_v_decay\n",
    "\n",
    "#                     pre_trained = False, # True # False\n",
    "#                     convTrue_fcFalse = True, # True # False\n",
    "\n",
    "#                     # 'P' for average pooling, 'D' for (1,1) aver pooling, 'M' for maxpooling, 'L' for linear classifier, [  ] for residual block\n",
    "#                     # conv에서 10000 이상은 depth-wise separable (BPTT만 지원), 20000이상은 depth-wise (BPTT만 지원)\n",
    "#                     # cfg = [64],\n",
    "#                     # cfg = [64,[64,64],64], # 끝에 linear classifier 하나 자동으로 붙습니다\n",
    "#                     cfg = [64, 128, 'P', 256, 256, 'P', 512, 512, 'P', 512, 512, 'D'], #ottt\n",
    "#                     # cfg = [64, 128, 'P', 256, 256, 'P', 512, 512, 'P', 512, 512], #ottt\n",
    "#                     # cfg = [64, 128, 'M', 256, 256, 'M', 512, 512, 'M', 512, 512], # ottt \n",
    "#                     # cfg = [64, 'P', 128, 'P', 256, 256, 'P', 512, 512, 512, 512, 'D'], # nda\n",
    "#                     # cfg = [64, 'P', 128, 'P', 256, 256, 'P', 512, 512, 512, 512], # nda 128pixel\n",
    "#                     # cfg = [64, 'P', 128, 'P', 256, 256, 'P', 512, 512, 512, 512, 'L', 4096, 4096],\n",
    "#                     # cfg = [20001,10001], # depthwise, separable\n",
    "#                     # cfg = [64,20064,10001], # vanilla conv, depthwise, separable\n",
    "#                     # cfg = [8, 'P', 8, 'P', 8, 'P', 8,'P', 8, 'P'],\n",
    "#                     # cfg = [], \n",
    "                    \n",
    "#                     net_print = True, # True # False\n",
    "#                     weight_count_print = False, # True # False\n",
    "                    \n",
    "#                     pre_trained_path = f\"net_save/save_now_net_{unique_name}.pth\",\n",
    "#                     learning_rate = learning_rate, # default 0.001  # ottt 0.1 0.00001 # nda 0.001 \n",
    "#                     epoch_num = 4,\n",
    "#                     verbose_interval = 999999999, #숫자 크게 하면 꺼짐 #걍 중간중간 iter에서 끊어서 출력\n",
    "#                     validation_interval = 999999999, #숫자 크게 하면 에포크 마지막 iter 때 val 함\n",
    "\n",
    "#                     tdBN_on = False,  # True # False\n",
    "#                     BN_on = False,  # True # False\n",
    "                    \n",
    "#                     surrogate = 'sigmoid', # 'rectangle' 'sigmoid' 'rough_rectangle'\n",
    "                    \n",
    "#                     gradient_verbose = False,  # True # False  # weight gradient 각 layer마다 띄워줌\n",
    "\n",
    "#                     BPTT_on = False,  # True # False # True이면 BPTT, False이면 OTTT  # depthwise, separable은 BPTT만 가능\n",
    "#                     optimizer_what = 'SGD', # 'SGD' 'Adam', 'RMSprop'\n",
    "#                     scheduler_name = 'CosineAnnealingLR', # 'no' 'StepLR' 'ExponentialLR' 'ReduceLROnPlateau' 'CosineAnnealingLR' 'OneCycleLR'\n",
    "                    \n",
    "#                     ddp_on = False,   # True # False\n",
    "\n",
    "#                     nda_net = False,   # True # False\n",
    "\n",
    "#                     domain_il_epoch = 0, # over 0, then domain il mode on # pmnist 쓸거면 HLOP 코드보고 더 디벨롭하셈. 지금 개발 hold함.\n",
    "                    \n",
    "#                     dvs_clipping = True, # dvs zero&one  # gesture, cifar-dvs2, nmnist, ncaltech101\n",
    "#                     dvs_duration = 1000000, # 0 아니면 time sampling # dvs number sampling OR time sampling # gesture, cifar-dvs2, nmnist, ncaltech101\n",
    "#                     #있는 데이터들 #gesture 1000000 #nmnist 10000\n",
    "\n",
    "#                     OTTT_sWS_on = True, # True # False # BPTT끄고, CONV에만 적용됨.\n",
    "                    \n",
    "#                     ) \n",
    "#     # sigmoid와 BN이 있어야 잘된다.\n",
    "#     # average pooling\n",
    "#     # 이 낫다. \n",
    "    \n",
    "#     # nda에서는 decay = 0.25, threshold = 0.5, width =1, surrogate = rectangle, batch = 256, tdBN = True\n",
    "#     ## OTTT 에서는 decay = 0.5, threshold = 1.0, surrogate = sigmoid, batch = 128, BN = True\n",
    "\n",
    "\n",
    "# sweep_id = wandb.sweep(sweep=sweep_configuration, project=f'my_snn {unique_name_hyper}')\n",
    "# wandb.agent(sweep_id, function=hyper_iter, count=1000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "# import matplotlib.pyplot as plt\n",
    "# import json\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# def pad_array_to_match_length(array1, array2):\n",
    "#     if len(array1) > len(array2):\n",
    "#         padded_array2 = np.pad(array2, (0, len(array1) - len(array2)), 'constant')\n",
    "#         return array1, padded_array2\n",
    "#     elif len(array2) > len(array1):\n",
    "#         padded_array1 = np.pad(array1, (0, len(array2) - len(array1)), 'constant')\n",
    "#         return padded_array1, array2\n",
    "#     else:\n",
    "#         return array1, array2\n",
    "# def load_hyperparameters(filename=f'result_save/hyperparameters_{unique_name}.json'):\n",
    "#     with open(filename, 'r') as f:\n",
    "#         return json.load(f)\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# current_time = '20240628_110116'\n",
    "# base_name = f'{current_time}'\n",
    "# iter_acc_file_name = f'result_save/{base_name}_iter_acc_array_{unique_name}.npy'\n",
    "# val_acc_file_name = f'result_save/{base_name}_val_acc_now_array_{unique_name}.npy'\n",
    "# hyperparameters_file_name = f'result_save/{base_name}_hyperparameters_{unique_name}.json'\n",
    "\n",
    "# ### if you want to just see most recent train and val acc###########################\n",
    "# iter_acc_file_name = f'result_save/iter_acc_array_{unique_name}.npy'\n",
    "# tr_acc_file_name = f'result_save/tr_acc_array_{unique_name}.npy'\n",
    "# val_acc_file_name = f'result_save/val_acc_now_array_{unique_name}.npy'\n",
    "# hyperparameters_file_name = f'result_save/hyperparameters_{unique_name}.json'\n",
    "\n",
    "# loaded_iter_acc_array = np.load(iter_acc_file_name)*100\n",
    "# loaded_tr_acc_array = np.load(tr_acc_file_name)*100\n",
    "# loaded_val_acc_array = np.load(val_acc_file_name)*100\n",
    "# hyperparameters = load_hyperparameters(hyperparameters_file_name)\n",
    "\n",
    "# loaded_iter_acc_array, loaded_val_acc_array = pad_array_to_match_length(loaded_iter_acc_array, loaded_val_acc_array)\n",
    "# loaded_iter_acc_array, loaded_tr_acc_array = pad_array_to_match_length(loaded_iter_acc_array, loaded_tr_acc_array)\n",
    "# loaded_val_acc_array, loaded_tr_acc_array = pad_array_to_match_length(loaded_val_acc_array, loaded_tr_acc_array)\n",
    "\n",
    "# top_iter_acc = np.max(loaded_iter_acc_array)\n",
    "# top_tr_acc = np.max(loaded_tr_acc_array)\n",
    "# top_val_acc = np.max(loaded_val_acc_array)\n",
    "\n",
    "# which_data = hyperparameters['which_data']\n",
    "# BPTT_on = hyperparameters['BPTT_on']\n",
    "# current_epoch = hyperparameters['current epoch']\n",
    "# surrogate = hyperparameters['surrogate']\n",
    "# cfg = hyperparameters['cfg']\n",
    "# tdBN_on = hyperparameters['tdBN_on']\n",
    "# BN_on = hyperparameters['BN_on']\n",
    "\n",
    "\n",
    "# iterations = np.arange(len(loaded_iter_acc_array))\n",
    "\n",
    "# # 그래프 그리기\n",
    "# plt.figure(figsize=(10, 5))\n",
    "# plt.plot(iterations, loaded_iter_acc_array, label='Iter Accuracy', color='g', alpha=0.2)\n",
    "# plt.plot(iterations, loaded_tr_acc_array, label='Training Accuracy', color='b')\n",
    "# plt.plot(iterations, loaded_val_acc_array, label='Validation Accuracy', color='r')\n",
    "\n",
    "# # # 텍스트 추가\n",
    "# # plt.text(0.05, 0.95, f'Top Training Accuracy: {100*top_iter_acc:.2f}%', transform=plt.gca().transAxes, fontsize=12, verticalalignment='top', horizontalalignment='left', color='blue')\n",
    "# # plt.text(0.05, 0.90, f'Top Validation Accuracy: {100*top_val_acc:.2f}%', transform=plt.gca().transAxes, fontsize=12, verticalalignment='top', horizontalalignment='left', color='red')\n",
    "# # 텍스트 추가\n",
    "# plt.text(0.5, 0.10, f'Top Training Accuracy: {top_tr_acc:.2f}%', transform=plt.gca().transAxes, fontsize=12, verticalalignment='top', horizontalalignment='center', color='blue')\n",
    "# plt.text(0.5, 0.05, f'Top Validation Accuracy: {top_val_acc:.2f}%', transform=plt.gca().transAxes, fontsize=12, verticalalignment='top', horizontalalignment='center', color='red')\n",
    "\n",
    "# plt.xlabel('Iterations')\n",
    "# plt.ylabel('Accuracy [%]')\n",
    "\n",
    "# # 그래프 제목에 하이퍼파라미터 정보 추가\n",
    "# title = f'Training and Validation Accuracy over Iterations\\n\\nData: {which_data}, BPTT: {\"On\" if BPTT_on else \"Off\"}, Current Epoch: {current_epoch}, Surrogate: {surrogate},\\nCFG: {cfg}, tdBN: {\"On\" if tdBN_on else \"Off\"}, BN: {\"On\" if BN_on else \"Off\"}'\n",
    "\n",
    "# plt.title(title)\n",
    "\n",
    "# plt.legend(loc='lower right')\n",
    "# plt.xlim(0)  # x축을 0부터 시작\n",
    "# plt.grid(True)\n",
    "# plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nfs",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
